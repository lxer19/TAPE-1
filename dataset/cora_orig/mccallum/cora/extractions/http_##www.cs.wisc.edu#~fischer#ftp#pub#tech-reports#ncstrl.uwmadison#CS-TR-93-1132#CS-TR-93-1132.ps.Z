URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-93-1132/CS-TR-93-1132.ps.Z
Refering-URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-93-1132/
Root-URL: http://www.cs.wisc.edu
Title: A STATE MACHINE APPROACH TO RELIABLE AND DYNAMICALLY RECONFIGURABLE DISTRIBUTED SYSTEMS  
Author: by ALVIN SEK SEE LIM 
Degree: A thesis submitted in partial fulfillment of the requirements for the degree of Doctor of Philosophy (Computer Sciences) at the  
Date: 1993  
Affiliation: UNIVERSITY OF WISCONSIN-MADISON  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Aggarwal, S., D. Barbara, and K. Z. Meth, </author> <title> ``SPANNER A Tool for the Specification, Analysis, and Evaluation of Protocols,'' </title> <journal> IEEE Transactions on Software Engineering SE-13(12) pp. </journal> <month> 1218-1237 (December </month> <year> 1987). </year>
Reference: [2] <author> Aggarwal, S., D. Barbara, and K. Z. Meth, </author> <title> ``A Software Environment for the Specification and Analysis of Problems in Coordination and Concurrency,'' </title> <journal> IEEE Transactions on Software Engineering SE-14(5) pp. </journal> <month> 280-289 (March </month> <year> 1988). </year>
Reference: [3] <author> Aggarwal, S., C. Courcoubetis, and P. Wolper, </author> <title> ``Adding Liveness Properties to coupled Finite-State Machines,'' </title> <journal> ACM Transactions on Programming Languages and Systems 12(2) pp. </journal> <month> 303-339 (April </month> <year> 1990). </year>
Reference: [4] <author> Aho, Alfred V., John E. Hopcroft, and Jeffery D. Ullman, </author> <title> The Design and Analysis of Computer Algorithms, </title> <publisher> Addison-Wesley (1974). </publisher>
Reference-contexts: The space complexity is also O (n s + t s ). Since a subgraph G of a scope may contain cycles, we need to transform G into an acyclic |&gt;- equivalent graph. This algorithm is based on the algorithm for computing strongly connected components described in <ref> [4] </ref>. The main procedure transform performs a depth-first search through G and transforms strongly connected components into acyclic subgraphs as they are found. Strongly connected components are detected using depth-first number k, low link number L and a stack STACK 90 as described in [4]. <p> computing strongly connected components described in <ref> [4] </ref>. The main procedure transform performs a depth-first search through G and transforms strongly connected components into acyclic subgraphs as they are found. Strongly connected components are detected using depth-first number k, low link number L and a stack STACK 90 as described in [4]. At each node v, we add two stacks v.B that records all back edges originating at the descendents of v and v.C that records all cross and forward edges originating at the descendents of v.
Reference: [5] <author> Andler, S., </author> <title> ``Predicate Path Expression,'' </title> <booktitle> Proceedings of the 6th ACM Symposium on Programming Languages, </booktitle> <pages> pp. </pages> <month> 226-236 (January </month> <year> 1979). </year>
Reference-contexts: Furthermore, we can describe hierarchies of finite-state machines using abstraction and composition more easily than with Petri nets. The ability to express abstraction and composition also distinguishes our work from path expression <ref> [5, 17] </ref>. 2.2. Failure Recovery There are two major classes of techniques to reliable distributed systems: physical redundancy, implementing multiple copies of hardware or software; and time redundancy, re-executing operations of failed and affected processes. An example of physical redundancy is replicated servers. <p> The specification of a group of processes can be used for composing higher level groups where individual process behavior is hidden at higher levels. As will be discussed in Chapter 4, a composite specification has the power of predicate path expressions <ref> [5, 17] </ref> or serializability constraints to synchronize independently programmed processes. 2.3. Dynamic Reconfiguration Durra [8] and HPC [55] deal primarily with the problem of structural reconfiguration, where groups of modules can be recomposed via links, but did not deal with the problem of maintaining state consistency.
Reference: [6] <author> Badrinath, B. R. and Krithi Ramamritham, </author> <title> ``Semantic-based Concurrency Control: Beyond Commutativity,'' </title> <booktitle> Proceedings of the Third International Conference on Data Engineering, </booktitle> <pages> pp. </pages> <month> 304-311 </month> <year> (1987). </year>
Reference-contexts: Isolation is enforced in transactions to simplify recovery but it restricts the range of permissible synchronization. Even in implementations of transactions, recovery methods have been known to affect concurrency control <ref> [6, 31, 88] </ref>. In more general applications, we believe the right approach is to allow general 14 synchronization and yet provide appropriate mechanisms to control recovery. <p> Recovering to an intermediate state requires analysis of actual dependencies from the partial-order semantics of the distributed application. We can determine actual dependency more accurately than in transaction management which can only determine dependency conservatively based on conflict tables, defining either commutativity [87] or recoverability <ref> [6] </ref>. Furthermore, by analyzing the application semantics, we can also preserve consistency for non-rollback recovery operations, such as corrective operations, compensation and reset. The above examples show the importance of dealing with the partial-order semantics of many distributed applications.
Reference: [7] <author> Bancilhon, Francois, Won Kim, and Henry F. Korth, </author> <title> ``A Model of CAD Transactions,'' </title> <booktitle> Proceedings of the 11th International Conference on Very Large Data Bases, </booktitle> <pages> pp. </pages> <month> 25-33 </month> <year> (1985). </year>
Reference-contexts: Even in implementations of transactions, recovery methods have been known to affect concurrency control [6, 31, 88]. In more general applications, we believe the right approach is to allow general 14 synchronization and yet provide appropriate mechanisms to control recovery. While some work <ref> [7, 28, 35, 77, 87] </ref> extends the traditional transaction concept by exploiting semantic knowledge to provide more concurrency, we have started from a general synchronization environment and made it reliable. There is a limitation on extending transactions because all transactions must eventually satisfy the serializability or recoverability criteria. <p> In atomic abstract data types, as in ACTA [20], the burden of analyzing commutativity (or dependency) between operations is placed on the programmers. Optimistic approaches [35, 49] also require committed transactions to be serializable. Cooperative transactions <ref> [7] </ref> extend basic nested transactions [63], but still require the partial order of lower level nested transactions to be equivalent to a total order of operations invoked by subtransactions of the cooperating transaction. <p> The major disadvantage of a smaller granularity is the high overhead of beginning and committing transactions. A straightforward but unsatisfactory solution to reduce this overhead is by defining these sub-operations as cooperating transactions in a nested transaction model <ref> [7] </ref>, where intermediate results of cooperating transactions are visible to each other. When a sub-transaction fails, all cooperating transactions within the parent 25 transaction must be aborted, resulting in wasted computation and physical work.
Reference: [8] <author> Barbacci, M. R., C. B. Weinstock, and J. M. Wing, </author> <booktitle> ``Programming at the Processor-Memory-Switch Level,'' Proc. 10th Int. Conf. on Software Engineering, </booktitle> <address> p. </address> <year> 1928 </year> <month> (April </month> <year> 1988). </year>
Reference-contexts: As will be discussed in Chapter 4, a composite specification has the power of predicate path expressions [5, 17] or serializability constraints to synchronize independently programmed processes. 2.3. Dynamic Reconfiguration Durra <ref> [8] </ref> and HPC [55] deal primarily with the problem of structural reconfiguration, where groups of modules can be recomposed via links, but did not deal with the problem of maintaining state consistency. HPC provides the mechanisms for users to define abstraction and composition of processes. <p> Software designers must specify the states at which specialized save (restore) operations may begin (end). Unlike the systems discussed so far, Durra <ref> [8] </ref> and HPC [25, 55] do not deal with the problem of transferring states but rather concentrate on the problem of structural reconfiguration where groups of modules can be recomposed via modification of communication links.
Reference: [9] <author> Beeri, Catriel, Philip A. Bernstein, and Nathan Goodman, </author> <title> ``A Model for Concurrency in Nested Transactions Systems,'' </title> <journal> Journal of the ACM 36(2) pp. </journal> <month> 230-269 (April </month> <year> 1989). </year>
Reference-contexts: It is thus weaker than serializability and linearizability discussed below. In much work on databases and distributed system, a similar criterion used for transactions (sequences of operations) is serializability <ref> [9, 10, 31, 66] </ref>. Two sequences of transactions are equivalent if the dependence relation between every pair of transactions in both sequences are identical [24, 66]. <p> Once we have identified these properties, we do not need execution sequences for analyzing a particular application. Instead we use the behavior FSM specification for analyzing the correctness of recovery using a suffix of the execution sequence. This approach contrasts with most other works <ref> [9, 31, 45, 64] </ref> that use a history log for analyzing and verifying the correctness of recovery of individual applications. 62 63 In this chapter, we describe the notion of execution sequences, equivalence between execution sequences, how they are modified by normal and recovery operations and how they are used to
Reference: [10] <author> Bernstein, Philip A., Vassos Hadzilacos, and Nathan Goodman, </author> <title> Concurrency Control and Recovery in Database Systems, </title> <publisher> Addison-Wesley Publishing Company (1987). </publisher>
Reference-contexts: Based on this notion of consistency, we introduce a general set of conditions that guarantee the correctness of recovery and dynamic reconfiguration. Existing concurrency and recovery correctness conditions based on some notion of sequentiality <ref> [10, 51] </ref> preserve consistency in a conservative way by isolating intermediate results of atomic operations. This is inappropriate in many distributed applications where intermediate results of a process may be visible to other processes and their operations may not be serialized. <p> It is thus weaker than serializability and linearizability discussed below. In much work on databases and distributed system, a similar criterion used for transactions (sequences of operations) is serializability <ref> [9, 10, 31, 66] </ref>. Two sequences of transactions are equivalent if the dependence relation between every pair of transactions in both sequences are identical [24, 66]. <p> However, the FSM model is useful for many distributed applications such as automated manufacturing [23, 67]. In the following, we compare the correctness conditions of existing backward and forward recovery techniques with our correctness conditions. In Section 8.3.1 and 8.3.2, we show that two important existing backward recovery methods <ref> [10, 72, 77, 86] </ref>, satisfy the conditions for correctness of backward recovery. In Section 8.3.3 and 8.3.4, we describe how some existing forward recovery methods satisfy the correctness conditions for recovery. 8.3.1. <p> In Section 8.3.3 and 8.3.4, we describe how some existing forward recovery methods satisfy the correctness conditions for recovery. 8.3.1. Restore and Undo Traditional methods of transactional recovery based on restore and undo <ref> [10, 64, 88] </ref> satisfy the correctness condition for backward recovery defined in Section 8.2.1. Restore can be represented by a recovery transition that leaves the current basic state and enters a previous basic state that may be of arbitrary distance away.
Reference: [11] <author> Bihari, Thomas A. and Karsten Schwan, </author> <title> ``Dynamic Adaptation of Real-Time Software,'' </title> <journal> ACM Transactions on Computer Systems 9(2) pp. </journal> <month> 143-174 (May, </month> <year> 1991). </year>
Reference-contexts: We have the following design goals to make dynamic reconfiguration mechanisms efficient and general. First, processes should be allowed to interact arbitrarily without unnecessary restrictions. Existing work on dynamic reconfiguration <ref> [11, 16, 47] </ref> is based on transactions as a model of process interaction. As discussed in Chapter 3 and in [13], transactions restrict the way processes can synchronize among one another. Second, we should not mandate quiescence of all affected processes before dynamic reconfiguration can begin. <p> The policy for selecting a new configuration is the responsibility of either a software designer or application-specific adaptation software. For example, by analyzing a failure, the adaptation software may automatically select a new configuration that avoids the failed component and uses an alternate software or processor <ref> [11] </ref>. However, here we will not address the problem of selecting a new 131 configuration from an analysis of failure. Different types of reconfiguration may be specified by designers or adaption software by selecting an appropriate set of reconfiguration transitions.
Reference: [12] <author> Birman, Kenneth and T. Joseph, </author> <title> ``Exploiting Virtual Synchrony in Distributed Systems,'' </title> <booktitle> Proc. 11th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pp. </pages> <month> 123-138 (November </month> <year> 1987). </year>
Reference-contexts: An example of physical redundancy is replicated servers. Despite the failure of some servers, the service will still be provided as long as at least one server is functional. ISIS/Meta <ref> [12, 60] </ref> provides mechanisms and an environment for monitoring and controlling fault-tolerant distributed applications using replicated servers. In [75], a state machine model has been used for designing reliable distributed systems based on replication. There are two main problems with the replication approach.
Reference: [13] <author> Birman, Kenneth P., </author> <title> ``Maintaining Consistency in Distributed Systems,'' </title> <type> Technical Report TR91-1240, </type> <institution> Department of Computer Sciences, Cornell University, Upson Hall, </institution> <address> Ithaca, NY 14853 (November 12, </address> <year> 1991). </year>
Reference-contexts: The drawback of preserving the serializability and failure atomicity properties is that they restrict the types of synchronization that can be specified. The mismatch between the properties of atomic transactions and the characteristics of general distributed systems is discussed in <ref> [13] </ref>. Instead of making incremental extensions to transactions, this thesis explores a new approach based on a general synchronization model of process interaction. It allows software designers to specify general interactive behavior. <p> First, processes should be allowed to interact arbitrarily without unnecessary restrictions. Existing work on dynamic reconfiguration [11, 16, 47] is based on transactions as a model of process interaction. As discussed in Chapter 3 and in <ref> [13] </ref>, transactions restrict the way processes can synchronize among one another. Second, we should not mandate quiescence of all affected processes before dynamic reconfiguration can begin. The approach in [47] requires all affected processes to be in quiescent states before a reconfiguration can begin.
Reference: [14] <author> Birman, Kenneth P. and Thomas A. Joseph, </author> <title> ``Exploiting Replication in Distributed Systems,'' </title> <note> pp. 319-367 in Distributed Systems, </note> <editor> Sape Mullender (ed.), </editor> <publisher> ACM Press, Addison-Wesley Publishing Company (1989). </publisher>
Reference-contexts: Basic machines and managers may interact with an external semantic information facility that maintains information that is not easily represented by a finite-state machine model, such as counters, hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh 1 It is possible to improve the fault-tolerance of the centralized consistency control manager through various replication techniques <ref> [14, 75] </ref>.
Reference: [15] <author> Black, Andrew P., </author> <title> ``Understanding Transactions in the Operating System Context,'' </title> <journal> Operating Systems Review 25(1) pp. </journal> <month> 73-76 (January </month> <year> 1991). </year>
Reference-contexts: This allows uniform control of the normal execution as well as different techniques for failure recovery and reconfiguration. Other work has concentrated on allowing designers to customize a limited set of application-specific techniques only for recovery management. Several researchers <ref> [15, 34, 57, 78] </ref> support customizable recovery techniques by separating the underlying mechanisms from the policies that are associated with various recovery techniques and options. These systems provide the basic mechanisms for supporting transactions, e.g. transaction creation and commit, logging, and recovery management. <p> These systems provide the basic mechanisms for supporting transactions, e.g. transaction creation and commit, logging, and recovery management. They differ in the level at which the recovery management primitives are exposed. Black <ref> [15] </ref> proposed an approach of exposing the mechanism for implementing and selecting abstractions that characterize transactions, such as atomicity, consistency, isolation and persistence.
Reference: [16] <author> Bloom, T., </author> <title> ``Dynamic Module Replacement in a Distributed System,'' </title> <type> Technical Report MIT/LCS/TR-303, </type> <institution> MIT Laboratory for Computer Science (March 1983). </institution>
Reference-contexts: Since it is based on transaction concepts, dynamic reconfiguration is done only at "quiescent" states of modules. We avoid this limitation by allowing users to reconfigure modules at arbitrary legal states as long as appropriate recovery and reconfiguration transitions are defined. Bloom <ref> [16] </ref> built a dynamic reconfiguration facility over the transaction mechanism of Argus. It provides a framework for analyzing the legality of replacing objects and managing states of replaced objects. <p> Two existing systems that provide a uniform framework are based on transactions and have the restrictions discussed in Section 2.2. The first is the Argus transaction mechanism [56, 57] with the extension of dynamic reconfiguration mechanism by Bloom <ref> [16] </ref>. Argus, however, does not provide support for incorporating new recovery techniques, such as compensation used in forward recovery. Furthermore, the reconfiguration mechanism has the limitations discussed in Section 2.3. Conic [47, 48] gives only a partial framework; providing support for dynamic reconfiguration but little support for recovery management. <p> We have the following design goals to make dynamic reconfiguration mechanisms efficient and general. First, processes should be allowed to interact arbitrarily without unnecessary restrictions. Existing work on dynamic reconfiguration <ref> [11, 16, 47] </ref> is based on transactions as a model of process interaction. As discussed in Chapter 3 and in [13], transactions restrict the way processes can synchronize among one another. Second, we should not mandate quiescence of all affected processes before dynamic reconfiguration can begin. <p> Some operations that take a long time to complete will delay a reconfiguration unnecessarily. Furthermore, reconfiguration operations may take some time to complete. Third, a new configuration should be unconstrained by the properties of the old configuration. Bloom pioneered a work <ref> [16] </ref> dealing only with a special case of the dynamic reconfiguration problem where the new configuration must be a superset of the old configuration. Her legality conditions for dynamic reconfiguration (or replacement) do not allow the removal of any behavior 111 112 in the old configuration. <p> This reconfiguration combines replacement with relocation. 10.2.1. Replacement Software modules often undergo changes to improve performance, remove bugs, or add new functions. A new version of a basic machine may dynamically replace another basic machine. The conditions for legal dynamic replacement discussed in <ref> [16] </ref> are as follows. First, the behavior of a replacing basic machine must preserve the behavior of the replaced machine, i.e. the replacing basic machine must allow any sequence of transitions that is allowed by the replaced machine. However, new sequences of transitions may be allowed by the replacing machine. <p> Comparison with Other Dynamic Reconfiguration Techniques The two main advantages of our system are: (1) we allow dynamic reconfiguration of applications that may interact in complex ways and (2) we allow greater concurrency, than other systems <ref> [16, 58] </ref>, by breaking reconfiguration paths into segments to allow unaffected processes execute at transient configurations between segments. (A reconfiguration path is partitioned only if the cost is outweighed by the benefits of higher concurrency resulting from partitioning.) However, compared to those transactional systems, we incur the additional cost of finding <p> In the following, we compare our approach to other techniques only for applications with finite-state processes. 10.3.1. Module Replacement in Argus Bloom <ref> [16] </ref> introduced a framework for checking legality of dynamic module replacement based on the transaction mechanisms of Argus [56, 57]. Processes interact entirely through the client-server model. The transaction mechanisms provided by Argus preserve interactive consistency. <p> Our approach does not require processes to be quiescent before reconfiguration as in other systems [58, 69]. Furthermore, we allow applications to interact in complex ways, whereas other systems <ref> [16, 58] </ref> only permit reconfiguration of applications based on transactions. 11.3. Future Work There are many areas of future research that will enhance the work presented here, e.g. specification environment, analysis of more synchronization problems, linguistic support and tools, compilation and performance tuning of implementations.
Reference: [17] <author> Campbell, R. H. and A. N. Habermann, </author> <title> ``The Specification of Process Synchronization by Path Expressions,'' </title> <note> pp. 89-102 in Lecture Notes in Computer Science, Springer-Verlag (1974). 147 148 </note>
Reference-contexts: Furthermore, we can describe hierarchies of finite-state machines using abstraction and composition more easily than with Petri nets. The ability to express abstraction and composition also distinguishes our work from path expression <ref> [5, 17] </ref>. 2.2. Failure Recovery There are two major classes of techniques to reliable distributed systems: physical redundancy, implementing multiple copies of hardware or software; and time redundancy, re-executing operations of failed and affected processes. An example of physical redundancy is replicated servers. <p> The specification of a group of processes can be used for composing higher level groups where individual process behavior is hidden at higher levels. As will be discussed in Chapter 4, a composite specification has the power of predicate path expressions <ref> [5, 17] </ref> or serializability constraints to synchronize independently programmed processes. 2.3. Dynamic Reconfiguration Durra [8] and HPC [55] deal primarily with the problem of structural reconfiguration, where groups of modules can be recomposed via links, but did not deal with the problem of maintaining state consistency.
Reference: [18] <author> Chandy, K. Mani and Leslie Lamport, </author> <title> ``Distributed Snapshots: Determining Global States of Distributed Systems,'' </title> <journal> ACM Transactions on Computer Systems 3(1) pp. </journal> <month> 63-75 (February </month> <year> 1985). </year>
Reference-contexts: We chose to use these words because they accurately describe our intended concept. Throughout this thesis, we will use the term in the sense defined here. 18 19 notion of global state consistency described in <ref> [18, 39, 44] </ref>, which is defined at the level of message communication abstraction. By examining the specified behavior of an application, we can determine if a process is semantically dependent on information or conditions established by another process. <p> Effects of Modifying Execution Sequences on Consistency From the definition of interactive consistency in Section 3.1, consistency is preserve if information established by a process that enable another process to execute some operations is not erased by some recovery operations. This notion of consistency is similar to those in <ref> [18, 39, 44] </ref>. To analyze consistency, we must rely on the actual executions of the processes represented by an execution sequence.
Reference: [19] <author> Choobineh, Fred and Rajan Suri, (eds.), </author> <title> Flexible Manufacturing Systems: Current Issues and Models, </title> <institution> Industrial Engineering and Manufacturing Press, Institute of Industrial Engineers, Atlanta, Georgia (1986). </institution>
Reference-contexts: Furthermore, these applications may involve frequent recovery from exceptional conditions as well as regularly scheduled reconfiguration or installation of new modules. Distributed applications with these characteristics include computer-aided automated manufacturing <ref> [19, 23, 26, 41, 73] </ref>, multi-transaction database activities [27, 83], network service applications [74, 82], and process control [76]. A major problem in these applications is maintaining consistency in the presence of concurrency, failure and reconfiguration.
Reference: [20] <author> Chrysanthis, Panayiotis K. and Krithi Ramamritham, </author> <title> ``ACTA: A Framework for Specifying and Reasoning about Transaction Structure and Behavior,'' </title> <booktitle> Proceedings of the ACM-SIGMOD Conference on Management of Data, </booktitle> <pages> pp. </pages> <month> 194-203 (May </month> <year> 1990). </year>
Reference-contexts: This is inappropriate for many distributed applications that usually involve non-serializable and non-recoverable operations as will be discussed in Section 3.4. Atomic abstract data types [77, 87] require transactions to be serializable after non-dependent operations are commuted. In atomic abstract data types, as in ACTA <ref> [20] </ref>, the burden of analyzing commutativity (or dependency) between operations is placed on the programmers. Optimistic approaches [35, 49] also require committed transactions to be serializable. <p> Using more accurate dependencies reduces the "cascade" effect during recovery, thus reducing wastage of computation. We presented an algorithm for computing necessary precedence automatically from a restricted product machine. Besides computing accurate dependencies, this algorithm frees software designers from analyzing dependencies and commutativity between operations as in other work <ref> [20, 77, 87] </ref>. To check for some causes of failure, we presented algorithms for detecting synchronization problems such as deadlock, possible livelock and starvation. We also presented an algorithm for computing recovery paths that preserve consistency.
Reference: [21] <author> Clarke, E. M., E. A. Emerson, and A. P. Sistla, </author> <title> ``Automatic Verification of Finite-State Concurrent Systems Using Temporal Logic Specifications,'' </title> <journal> ACM Transactions on Programming Languages and Systems 8(2) pp. </journal> <month> 244-263 (April </month> <year> 1986). </year>
Reference-contexts: Synchronization Several state-transition approaches to specifying distributed applications have been used in the past. Lam and Shankar [50] use a finite state machine model for specifying and verifying communication protocols from a user's description of the properties. Clarke, et. al. <ref> [21] </ref>, use another approach for automatic verification of concurrent systems using temporal logic [59] specifications provided by the users. CCS [62] is suitable for detecting deadlock but not starvation or livelock without requiring users to specify these properties using modal logic [84].
Reference: [22] <author> Detlefs, David L., Maurice P. Herlihy, and Jeannette M. Wing, </author> <title> ``Inheritence of Synchronization and Recovery Properties in Avalon/c++,'' </title> <note> Computer 21(12) pp. </note> <month> 57-69 (December </month> <year> 1988). </year>
Reference-contexts: Other variations [42, 43, 71] of this recovery technique also do not exploit semantics of the application to detect actual dependence. Another common approach to reliable distributed systems is based on atomic transactions <ref> [22, 56, 57, 77, 78] </ref> that preserve the following properties: all-or-nothing, consistency, isolation, and durability [32]. The all-or-nothing property guarantees that either the transaction completes or it has no effect even though it may have failed.
Reference: [23] <author> Duffie, Neil A., Ramesh Chitturi, and Jong-I Mou, </author> <title> ``Fault-tolerant Heterachical Control of Heterogeneous Manufacturing System Entities,'' </title> <journal> Journal of Manufacturing Systems 7(4) pp. </journal> <month> 315-328 </month> <year> (1988). </year>
Reference-contexts: Furthermore, these applications may involve frequent recovery from exceptional conditions as well as regularly scheduled reconfiguration or installation of new modules. Distributed applications with these characteristics include computer-aided automated manufacturing <ref> [19, 23, 26, 41, 73] </ref>, multi-transaction database activities [27, 83], network service applications [74, 82], and process control [76]. A major problem in these applications is maintaining consistency in the presence of concurrency, failure and reconfiguration. <p> Existing recovery techniques, including those that exploit application-specific semantics, satisfy these conditions for correctness of recovery. In this thesis, we concentrate on applications such as automated manufacturing where distributed computerized control systems are increasing in number and complexity <ref> [23, 26, 41] </ref>. This work is also applicable to other application domains. Consider an automated manufacturing system that requires coordination of several workstations and material handling robots to produce a family of products from streams of raw material. Systems like this pose many challenging problems. <p> Scope and Assumptions In this thesis, we restrict our scope to applications with finite-state behavior to simplify automated checking of dependency and consistency. The finite-state machine model is useful in many distributed applications such as computer control of automated manufacturing <ref> [23, 67] </ref>. Systems with infinite state behavior, such as unbounded FIFO channels and other systems described in [70], will require an extension to the analysis described here. However, the definition of consistency and the conditions for preserving consistency are applicable to infinite as well as finite-state systems. <p> However, the FSM model is useful for many distributed applications such as automated manufacturing <ref> [23, 67] </ref>. In the following, we compare the correctness conditions of existing backward and forward recovery techniques with our correctness conditions. In Section 8.3.1 and 8.3.2, we show that two important existing backward recovery methods [10, 72, 77, 86], satisfy the conditions for correctness of backward recovery.
Reference: [24] <author> Eswaran, K.P., J.N. Gray, R.A. Lorie, </author> <title> and I.L. Traiger, ``The Notion of Consistency and Predicate Locks in a Database System,'' </title> <journal> Communications of the ACM 19(11) pp. </journal> <month> 624-633 (November </month> <year> 1976). </year>
Reference-contexts: In much work on databases and distributed system, a similar criterion used for transactions (sequences of operations) is serializability [9, 10, 31, 66]. Two sequences of transactions are equivalent if the dependence relation between every pair of transactions in both sequences are identical <ref> [24, 66] </ref>. A transaction T i is dependent on T j if T j writes a data item whose value is then read by T i .
Reference: [25] <author> Friedberg, Stuart Arthur, </author> <title> ``Hierarchical Process Composition: Dynamic Maintenance of Structure in a Distributed Environment,'' </title> <type> Technical Report 294, Ph.D. Thesis, </type> <institution> Department of Computer Sciences, University of Rochester (1988). </institution>
Reference-contexts: Software designers must specify the states at which specialized save (restore) operations may begin (end). Unlike the systems discussed so far, Durra [8] and HPC <ref> [25, 55] </ref> do not deal with the problem of transferring states but rather concentrate on the problem of structural reconfiguration where groups of modules can be recomposed via modification of communication links.
Reference: [26] <author> Fussell, Paul A., P. K. Wright, and David Bourne, </author> <title> ``A Design of a Controller as a Component of a Robotic Manufacturing System,'' </title> <journal> Journal of Manufacturing Systems 3(1) pp. </journal> <month> 1-11 </month> <year> (1984). </year>
Reference-contexts: Furthermore, these applications may involve frequent recovery from exceptional conditions as well as regularly scheduled reconfiguration or installation of new modules. Distributed applications with these characteristics include computer-aided automated manufacturing <ref> [19, 23, 26, 41, 73] </ref>, multi-transaction database activities [27, 83], network service applications [74, 82], and process control [76]. A major problem in these applications is maintaining consistency in the presence of concurrency, failure and reconfiguration. <p> Existing recovery techniques, including those that exploit application-specific semantics, satisfy these conditions for correctness of recovery. In this thesis, we concentrate on applications such as automated manufacturing where distributed computerized control systems are increasing in number and complexity <ref> [23, 26, 41] </ref>. This work is also applicable to other application domains. Consider an automated manufacturing system that requires coordination of several workstations and material handling robots to produce a family of products from streams of raw material. Systems like this pose many challenging problems.
Reference: [27] <author> Garcia-Molina, Hector, Dieter Gawlick, Johannes Klein, Karl Kleissner, and Kenneth Salem, </author> <title> ``Coordinating Multi-Transaction Activities,'' </title> <institution> CS-TR-247-90, Computer Sciences Department, Princeton University (February 1990). </institution>
Reference-contexts: Furthermore, these applications may involve frequent recovery from exceptional conditions as well as regularly scheduled reconfiguration or installation of new modules. Distributed applications with these characteristics include computer-aided automated manufacturing [19, 23, 26, 41, 73], multi-transaction database activities <ref> [27, 83] </ref>, network service applications [74, 82], and process control [76]. A major problem in these applications is maintaining consistency in the presence of concurrency, failure and reconfiguration. Atomic transactions are commonly used to simplify the management of concurrency and failure by preserving serializability and failure atomicity. <p> For example, the processing of a purchase order (i.e. an activity) in some company 24 2 4 6 8 9 10 12 14 16 18 20 22 R 2 R 4 (after Figure 10.4/b of [73]) involves a collection of steps: phone call, enter order, billing, inventory, shipping <ref> [27] </ref>. The activity starts with a phone call to order certain merchandise. The order is entered into the database and the system then initiates concurrent processing of billing and inventory. Shipping is initiated only when both billing and inventory processing are completed.
Reference: [28] <author> Garcia-Molina, Hector and K. Salem, </author> <title> ``Using Semantic Knowledge for Transaction Processing in a Distributed Database,'' </title> <journal> ACM Transactions on Database Systems 8(2) pp. </journal> <month> 186-213 (June </month> <year> 1983). </year>
Reference-contexts: Even in implementations of transactions, recovery methods have been known to affect concurrency control [6, 31, 88]. In more general applications, we believe the right approach is to allow general 14 synchronization and yet provide appropriate mechanisms to control recovery. While some work <ref> [7, 28, 35, 77, 87] </ref> extends the traditional transaction concept by exploiting semantic knowledge to provide more concurrency, we have started from a general synchronization environment and made it reliable. There is a limitation on extending transactions because all transactions must eventually satisfy the serializability or recoverability criteria. <p> For example, processes that involve non-serializable interaction (Section 1.2) cannot be implemented as transactions. Many research projects have concentrated on improving concurrency by commuting operations using application semantics or abstract data type specifications <ref> [28, 77, 86] </ref>. Even in these approaches, commuted operations must eventually satisfy the serializability criteria. 3.3. <p> By the isolation property, the intermediate results of a transaction are not visible to other transactions. This implies no operation of a transaction is dependent on an operation of another uncommitted transaction, satisfying the dependence condition. 8.3.2. Atomic Abstract Data Types Various works <ref> [28, 77, 86] </ref> have exploited semantic information to increase the level of concurrency among transactions and optimize failure recovery. We will take Weihl's work [86, 87] as a representative one. <p> The conditions for recovery and reconfiguration enable us to improve efficiency by allowing permuting and substituting transitions whenever permitted by the behavior specification. By analyzing specific product states in the (potential) behavior of an application, our method computes more accurate dependencies than other work on transactions <ref> [28, 77, 87] </ref> which specifies only commutativity of operations for all product states. Using more accurate dependencies reduces the "cascade" effect during recovery, thus reducing wastage of computation. We presented an algorithm for computing necessary precedence automatically from a restricted product machine.
Reference: [29] <author> Gouda, M. G. and C. K. Chang, </author> <title> ``A Technique for Proving Liveness of Communicating Finite State Machines with Examples,'' </title> <booktitle> Proceedings of the Third Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pp. </pages> <month> 38-49 (August </month> <year> 1984). </year>
Reference-contexts: A similar approach for verifying liveness has been used by Gouda, et. al. <ref> [29, 30] </ref>, although they did not discuss the general case where only a subset of the machines is involved and did not allow the problems to be avoided dynamically.
Reference: [30] <author> Gouda, M. G., C. H. Chow, and S. S. Lam, </author> <title> ``On The Decidability of Livelock Detection in Networks of Communicating Finite State Machines,'' Proceedings of IFIP Workshop on Protocol Specification, Testing, and Verification IV pp. </title> <publisher> 47-56 Elsevier Science Publishers B. V., </publisher> <year> (1985). </year>
Reference-contexts: A similar approach for verifying liveness has been used by Gouda, et. al. <ref> [29, 30] </ref>, although they did not discuss the general case where only a subset of the machines is involved and did not allow the problems to be avoided dynamically.
Reference: [31] <author> Hadzilacos, Vassos, </author> <title> ``A Theory of Reliability in Database Systems,'' </title> <journal> Journal of the ACM 35(1) pp. </journal> <month> 121-145 (January </month> <year> 1988). </year>
Reference-contexts: The all-or-nothing property guarantees that either the transaction completes or it has no effect even though it may have failed. This property is sometimes called recoverability <ref> [31] </ref> which allows uncommitted transactions to be aborted without invalidating the semantics of committed ones. The consistency property ensures that when the system starts in a consistent state, a transaction will bring it to another consistent state. <p> Isolation is enforced in transactions to simplify recovery but it restricts the range of permissible synchronization. Even in implementations of transactions, recovery methods have been known to affect concurrency control <ref> [6, 31, 88] </ref>. In more general applications, we believe the right approach is to allow general 14 synchronization and yet provide appropriate mechanisms to control recovery. <p> It is thus weaker than serializability and linearizability discussed below. In much work on databases and distributed system, a similar criterion used for transactions (sequences of operations) is serializability <ref> [9, 10, 31, 66] </ref>. Two sequences of transactions are equivalent if the dependence relation between every pair of transactions in both sequences are identical [24, 66]. <p> Once we have identified these properties, we do not need execution sequences for analyzing a particular application. Instead we use the behavior FSM specification for analyzing the correctness of recovery using a suffix of the execution sequence. This approach contrasts with most other works <ref> [9, 31, 45, 64] </ref> that use a history log for analyzing and verifying the correctness of recovery of individual applications. 62 63 In this chapter, we describe the notion of execution sequences, equivalence between execution sequences, how they are modified by normal and recovery operations and how they are used to <p> On the other hand, all operations that commute can always be permuted. Thus, permutativity property subsumes commutativity property that is described in [87]. 64 The notion of execution sequence is similar to history in <ref> [31, 45, 64, 87] </ref>. We however use execution sequences only for reasoning about the properties of the augmented FSM's that will guarantee correctness of recovery.
Reference: [32] <author> Haerder, Theo and A. Reuter, </author> <title> ``Principles of Transaction-Oriented Database Recovery,'' </title> <journal> Computing Surveys 15(4) pp. </journal> <month> 287-317 (December </month> <year> 1983). </year>
Reference-contexts: Other variations [42, 43, 71] of this recovery technique also do not exploit semantics of the application to detect actual dependence. Another common approach to reliable distributed systems is based on atomic transactions [22, 56, 57, 77, 78] that preserve the following properties: all-or-nothing, consistency, isolation, and durability <ref> [32] </ref>. The all-or-nothing property guarantees that either the transaction completes or it has no effect even though it may have failed. This property is sometimes called recoverability [31] which allows uncommitted transactions to be aborted without invalidating the semantics of committed ones. <p> When a failure occurs after a consistent historical state S p , operations before S p need not be recovered. While existing approaches <ref> [32, 43, 72] </ref> to avoiding domino effect of cascaded abort are based on recovery blocks, we analyze the semantics of the applications encoded in the restricted product graph and determine the appropriate consistent historical states, e.g. using dominator states, in which all processes take checkpoints.
Reference: [33] <author> Hailpern, Brent and Gail E. Kaiser, </author> <title> ``Dynamic Reconfiguration in an Object-Based Programming Language with Distributed Shared Data,'' </title> <booktitle> Proc. 11th International Conference on Distributed Computing Systems, </booktitle> <pages> pp. </pages> <month> 73-80 (May, </month> <year> 1991). </year>
Reference-contexts: Other aspects of dynamic reconfiguration has been addressed in other work and are omitted here. Dynamic reconfiguration, implemented in Polylith [69], addressed the practical problem of capturing and restoring states although they did not address the issues of maintaining state consistency. In <ref> [33] </ref>, Hailpern and Kaiser mainly address the problem of maintaining type consistency during dynamic 16 reconfiguration. In this paper, we will not address those aspects of reconfiguration that relate to safety, protection, and heterogeneity. 2.4. Uniform Support Framework A support framework for distributed applications should have two important characteristics.
Reference: [34] <author> Haskin, Roger, Yoni Malachi, Wayne Sawdon, and Gregory Chan, </author> <title> ``Recovery Management in QuickSilver,'' </title> <journal> ACM Transactions on Computer Systems 6(1) pp. </journal> <month> 82-108 (February </month> <year> 1988). </year> <month> 149 </month>
Reference-contexts: This allows uniform control of the normal execution as well as different techniques for failure recovery and reconfiguration. Other work has concentrated on allowing designers to customize a limited set of application-specific techniques only for recovery management. Several researchers <ref> [15, 34, 57, 78] </ref> support customizable recovery techniques by separating the underlying mechanisms from the policies that are associated with various recovery techniques and options. These systems provide the basic mechanisms for supporting transactions, e.g. transaction creation and commit, logging, and recovery management. <p> They differ in the level at which the recovery management primitives are exposed. Black [15] proposed an approach of exposing the mechanism for implementing and selecting abstractions that characterize transactions, such as atomicity, consistency, isolation and persistence. QuickSilver <ref> [34] </ref> exposes a set of primitives that is at a lower level than most other systems, such as Camelot [78] and Argus [57], and permits servers to implement their own recoverable storage and log recovery.
Reference: [35] <author> Herlihy, Maurice, </author> <title> ``Apologizing Versus Asking Permission: Optimistic Concurrency Control for Abstract Data Types,'' </title> <journal> ACM Transactions on Database Systems 15(1) pp. </journal> <month> 96-124 (March </month> <year> 1990). </year>
Reference-contexts: Even in implementations of transactions, recovery methods have been known to affect concurrency control [6, 31, 88]. In more general applications, we believe the right approach is to allow general 14 synchronization and yet provide appropriate mechanisms to control recovery. While some work <ref> [7, 28, 35, 77, 87] </ref> extends the traditional transaction concept by exploiting semantic knowledge to provide more concurrency, we have started from a general synchronization environment and made it reliable. There is a limitation on extending transactions because all transactions must eventually satisfy the serializability or recoverability criteria. <p> Atomic abstract data types [77, 87] require transactions to be serializable after non-dependent operations are commuted. In atomic abstract data types, as in ACTA [20], the burden of analyzing commutativity (or dependency) between operations is placed on the programmers. Optimistic approaches <ref> [35, 49] </ref> also require committed transactions to be serializable. Cooperative transactions [7] extend basic nested transactions [63], but still require the partial order of lower level nested transactions to be equivalent to a total order of operations invoked by subtransactions of the cooperating transaction.
Reference: [36] <author> Herlihy, Maurice P. and Jeannette M. Wing, </author> <title> ``Axioms for Concurrent Objects,'' </title> <booktitle> Proceedings of the 14th ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pp. </pages> <month> 12-26 (January </month> <year> 1987). </year>
Reference-contexts: Linearizability The linearizability criterion removes some of the restrictions of the serializability criteria by allowing concurrent executions of operations that access shared data objects as long as the results do not violate the semantics of the abstract data types <ref> [36, 37] </ref>. It provides the illusion that each operation appears to take effect instantaneously at some point in time in the interval in which it was executed.
Reference: [37] <author> Herlihy, Maurice P. and Jeannette M. Wing, </author> <title> ``Linearizability: A Correctness Condition for Concurrent Objects,'' </title> <journal> ACM Transactions on Programming Languages and Systems 12(3) pp. </journal> <month> 463-492 (July </month> <year> 1990). </year>
Reference-contexts: Linearizability The linearizability criterion removes some of the restrictions of the serializability criteria by allowing concurrent executions of operations that access shared data objects as long as the results do not violate the semantics of the abstract data types <ref> [36, 37] </ref>. It provides the illusion that each operation appears to take effect instantaneously at some point in time in the interval in which it was executed. <p> A dequeue operation that returns an a is thus legal since it assumes one of the sequential executions. To ensure linearizability, enqueue and dequeue operations must be implemented using special techniques and operators, e.g. atomic swap operations. As mentioned in <ref> [37] </ref>, linearizability is applicable only for maintaining consistency of concurrent execution and not failure recovery since there is no counterpart of failure atomicity.
Reference: [38] <author> Horman, Kluas, </author> <title> ``Programming of the Robot Cell,'' in Robot Technology and Applications, edited by Ulrich Rembold, </title> <publisher> Marcel Dekker, Inc., </publisher> <address> New York, New York (1990). </address>
Reference-contexts: Otherwise, if B must be recovered to state S 0 , then process C must be recovered since it is dependent on B. Another example of a non-linearizable behavior in manufacturing applications is the assembly of workpieces by multiple cooperating robots. Figure 3.3 shows the precedence graph <ref> [38] </ref> of the various assembly operations (picking and placing) on the following workpieces: sideplates, levers, shafts, locking pins. For instance, operations E and F must be completed before operation H begins. <p> new lever spacer locking pin locking pin sideplate locking pin locking pin locking pin locking pin locking pin locking pin at pos02 at pos03 at pos04 at pos05 at pos06 at pos09 at pos10 at pos11 at pos12 at pos13 A G I J L M (after Figure 6.7 of <ref> [38] </ref>) operations A and K) is not linearizable with either the concurrent operations H or E. Yet another example is a manufacturing assembly system that involves several manufacturing cells in a factory floor. Figure 3.4 shows the precedence diagram of the assembly system [73] with multiple assembly cells.
Reference: [39] <author> Johnson, David B. and Willy Zwaenepoel, </author> <title> ``Recovery in Distributed Systems Using Optimistic Message Logging and Checkpointing,'' </title> <booktitle> Proceedings of the Seventh ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pp. 171-181 (August 15-17, </pages> <year> 1988). </year>
Reference-contexts: Recovery of a failed process may not affect another process if the other does not actually depend on the failed process (though there may be apparent dependencies). Other approaches that allow general and irregular interaction patterns, such as message-logging and checkpointing <ref> [39, 79] </ref>, do not exploit semantics of the application to improve recovery in the presence of failure and aborts. By analyzing the behavior of applications, we can also improve efficiency by checkpointing only states that would be most important for recovery purposes. <p> A good system should allow general synchronization and at the same time provide efficient recovery. 13 A common approach to reliable distributed systems is rollback recovery based on message-logging and checkpointing <ref> [39, 44, 72, 79] </ref>. Interactions through messages are used to determine a consistent recovery line; that is, a set of checkpoint states of each process. Determining a consistent recovery line solely from interaction information is too conservative because some interactions may not be crucial to the execution of some processes. <p> We chose to use these words because they accurately describe our intended concept. Throughout this thesis, we will use the term in the sense defined here. 18 19 notion of global state consistency described in <ref> [18, 39, 44] </ref>, which is defined at the level of message communication abstraction. By examining the specified behavior of an application, we can determine if a process is semantically dependent on information or conditions established by another process. <p> Effects of Modifying Execution Sequences on Consistency From the definition of interactive consistency in Section 3.1, consistency is preserve if information established by a process that enable another process to execute some operations is not erased by some recovery operations. This notion of consistency is similar to those in <ref> [18, 39, 44] </ref>. To analyze consistency, we must rely on the actual executions of the processes represented by an execution sequence. <p> Our system allows complex, non-atomic interactions between long-lived, repetitive, or cyclic processes without requiring designer-specified commutativity of operations or a limited range of synchronization and sequencing constraints. Although some approaches also permit complex synchronization constraints, such as message-logging and checkpointing <ref> [39, 79] </ref>, they do not exploit the semantics of applications to improve recovery. We took interactive consistency, rather than serial execution, as the model for correct execution. This allows recovery and reconfiguration of applications with partial-order semantics: a larger group than serializable or linearizable applications.
Reference: [40] <author> Jones, Anita K. and William A. Wulf, </author> <title> ``Towards the Design of Secure Systems,'' </title> <journal> Software Practice and Experience 5 pp. </journal> <month> 321-336 </month> <year> (1975). </year>
Reference-contexts: The runtime mechanism that performs these task is independent of the policies software designers may specify through the model. The well-known separation of policy and mechanism <ref> [40, 54] </ref> has not been previously applied to synchronization, reliability and reconfiguration of distributed systems. machine specifications are compiled statically and how a consistency control manager provides the common control mechanism.
Reference: [41] <author> Jones, Albert T. and Charles R. McLean, </author> <title> ``A Proposed Hierarchical Control Model for Automated Manufacturing Systems,'' </title> <journal> Journal of Manufacturing Systems 5(1) pp. </journal> <month> 15-25 </month> <year> (1986). </year>
Reference-contexts: Furthermore, these applications may involve frequent recovery from exceptional conditions as well as regularly scheduled reconfiguration or installation of new modules. Distributed applications with these characteristics include computer-aided automated manufacturing <ref> [19, 23, 26, 41, 73] </ref>, multi-transaction database activities [27, 83], network service applications [74, 82], and process control [76]. A major problem in these applications is maintaining consistency in the presence of concurrency, failure and reconfiguration. <p> Existing recovery techniques, including those that exploit application-specific semantics, satisfy these conditions for correctness of recovery. In this thesis, we concentrate on applications such as automated manufacturing where distributed computerized control systems are increasing in number and complexity <ref> [23, 26, 41] </ref>. This work is also applicable to other application domains. Consider an automated manufacturing system that requires coordination of several workstations and material handling robots to produce a family of products from streams of raw material. Systems like this pose many challenging problems. <p> With hierarchical design, we can limit the size of the finite-state machine describing the behavior of each module. This assumption is reasonable in automated manufacturing where control is clustered in groups at each level in the factory hierarchy: workstation, manufacturing cell, shop floor, factory, and corporation <ref> [41] </ref>. Applications can be modularly specified whereby only abstracted behavior of each module is visible to higher level modules. Each module should contain few processes whose collective behavior can be specified by a reasonably small finite-state machine.
Reference: [42] <author> Kim, K. H., </author> <title> ``Approach to Mechanization of the Conversation Scheme Based on Monitor,'' </title> <journal> IEEE Transactions on Software Engineering SE-8(3) pp. </journal> <month> 189-197 (May </month> <year> 1982). </year>
Reference-contexts: The cost of logging messages to stable storage and the analysis required to merge independent message logs can be prohibitive, especially for distributed applications involving many messages. Other variations <ref> [42, 43, 71] </ref> of this recovery technique also do not exploit semantics of the application to detect actual dependence. Another common approach to reliable distributed systems is based on atomic transactions [22, 56, 57, 77, 78] that preserve the following properties: all-or-nothing, consistency, isolation, and durability [32].
Reference: [43] <author> Kim, K. H., </author> <title> ``Programmer-Transparent Coordination of Recovering Concurrent Processes: Philosophy and Rules for Efficient Implementation,'' </title> <journal> IEEE Transactions on Software Engineering 14(6) pp. </journal> <month> 810-821 (June </month> <year> 1988). </year>
Reference-contexts: The cost of logging messages to stable storage and the analysis required to merge independent message logs can be prohibitive, especially for distributed applications involving many messages. Other variations <ref> [42, 43, 71] </ref> of this recovery technique also do not exploit semantics of the application to detect actual dependence. Another common approach to reliable distributed systems is based on atomic transactions [22, 56, 57, 77, 78] that preserve the following properties: all-or-nothing, consistency, isolation, and durability [32]. <p> When a failure occurs after a consistent historical state S p , operations before S p need not be recovered. While existing approaches <ref> [32, 43, 72] </ref> to avoiding domino effect of cascaded abort are based on recovery blocks, we analyze the semantics of the applications encoded in the restricted product graph and determine the appropriate consistent historical states, e.g. using dominator states, in which all processes take checkpoints.
Reference: [44] <author> Koo, Richard and Sam Toueg, </author> <title> ``Checkpointing and Rollback-Recovery for Distributed Systems,'' </title> <journal> IEEE Transactions on Software Engineering SE-13(1) pp. </journal> <month> 23-31 (January </month> <year> 1987). </year>
Reference-contexts: A good system should allow general synchronization and at the same time provide efficient recovery. 13 A common approach to reliable distributed systems is rollback recovery based on message-logging and checkpointing <ref> [39, 44, 72, 79] </ref>. Interactions through messages are used to determine a consistent recovery line; that is, a set of checkpoint states of each process. Determining a consistent recovery line solely from interaction information is too conservative because some interactions may not be crucial to the execution of some processes. <p> We chose to use these words because they accurately describe our intended concept. Throughout this thesis, we will use the term in the sense defined here. 18 19 notion of global state consistency described in <ref> [18, 39, 44] </ref>, which is defined at the level of message communication abstraction. By examining the specified behavior of an application, we can determine if a process is semantically dependent on information or conditions established by another process. <p> Effects of Modifying Execution Sequences on Consistency From the definition of interactive consistency in Section 3.1, consistency is preserve if information established by a process that enable another process to execute some operations is not erased by some recovery operations. This notion of consistency is similar to those in <ref> [18, 39, 44] </ref>. To analyze consistency, we must rely on the actual executions of the processes represented by an execution sequence. <p> Checkpointing Consistent Historical States As described Section 7.1, we assume the existence of at least one consistent (firewall) historical state S p . A state S p can be created using known techniques for checkpointing global states of the processes, either conservatively <ref> [44] </ref> or optimistically [79]. S p may move with the normal execution resulting in a reduction in the recovery scope and the length of the recovery path. Conversely, we do not require every product state entered to be checkpointed.
Reference: [45] <author> Korth, Henry F., Eliezer Levy, and Abraham Silberschatz, </author> <title> ``A Formal Approach to Recovery by Compensating Transactions,'' </title> <booktitle> Proceedings of the 16th International Conference on Very Large Data Bases, </booktitle> <pages> pp. </pages> <month> 95-106 (August </month> <year> 1990). </year>
Reference-contexts: Once we have identified these properties, we do not need execution sequences for analyzing a particular application. Instead we use the behavior FSM specification for analyzing the correctness of recovery using a suffix of the execution sequence. This approach contrasts with most other works <ref> [9, 31, 45, 64] </ref> that use a history log for analyzing and verifying the correctness of recovery of individual applications. 62 63 In this chapter, we describe the notion of execution sequences, equivalence between execution sequences, how they are modified by normal and recovery operations and how they are used to <p> On the other hand, all operations that commute can always be permuted. Thus, permutativity property subsumes commutativity property that is described in [87]. 64 The notion of execution sequence is similar to history in <ref> [31, 45, 64, 87] </ref>. We however use execution sequences only for reasoning about the properties of the augmented FSM's that will guarantee correctness of recovery. <p> The notion of dependence in <ref> [45, 64, 87] </ref> is based not only on the ordering in a history log (which can be incidental) but also on a separate synchronization arbitrator, such as a conflict table. <p> In our model, the system automatically determines the actual dependence between operations and finds the sequence of recovery operations to a consistent state. A restricted form of compensation is compensating transactions defined in <ref> [45] </ref>. It is restrictive in the sense that compensating transactions must be serializable with other transactions. Compensating transactions are recovery operations that undo the results established by transactions that have been committed and whose results may have been made visible to other (dependent) transactions. <p> Compensating transactions are recovery operations that undo the results established by transactions that have been committed and whose results may have been made visible to other (dependent) transactions. In this discussion, we use the notion of "dependence" defined in <ref> [45] </ref>: a transaction A is dependent on B if A reads data written by B. <p> We can satisfy the first constraint in our model by requiring that the compensating recovery transition returns to the start basic state of the transition representing the compensated-for transaction. The second constraint is satisfied by specifying serializable synchronization constraints on compensating recovery transitions. In <ref> [45] </ref>, the third constraint is satisfied by ensuring that the compensating and dependent transactions commute (or R-commute with respect to some relation R on database states). <p> If dependent transactions happen before the compensated-for transaction, reinstating the compensated-for transactions by the compensating transactions will not invalidate the dependent (by their definition) transactions. We can thus find a recovery state that satisfies the dependence condition for correctness of recovery. In <ref> [45] </ref>, compensation takes place when no dependent transaction is affected, with respect to some relation R. In contrast, our model enables the system to detect dependent transactions that are not commutable with the compensated-for transaction and force a recovery on those transactions.
Reference: [46] <author> Korth, Henry F. and Gregory D. Speegle, </author> <title> ``Formal Model of Correctness Without Serializability,'' </title> <booktitle> Proceedings of the ACM-SIGMOD Conference on Management of Data, </booktitle> <pages> pp. </pages> <month> 379-386 (September </month> <year> 1988). </year>
Reference-contexts: The behavior of each process can be programmed independently without considering how other concurrent processes might be hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh 1 Any non-sequential behavior of a transaction is internal and is not observable by external processes. This is true even in "non-serializable" transactions <ref> [46, 87] </ref> if we commute non-dependent operations. 15 affected. Allowable interactions between processes are defined separately in a composite specification for the group of processes. We allow groups of processes to be hierarchically composed.
Reference: [47] <author> Kramer, Jeff and Jeff Magee, </author> <title> ``The Evolving Philosophers Problem: Dynamic Change Management,'' </title> <journal> IEEE Transactions on Software Engineering 16(11) pp. </journal> <month> 1293-1306 (November </month> <year> 1990). </year>
Reference-contexts: HPC provides the mechanisms for users to define abstraction and composition of processes. This thesis supplements systems like HPC and Durra by preserving state information during exceptional operations such as dynamic reconfiguration and recovery. Conic <ref> [47, 48, 58] </ref> differs from HPC and Durra by managing state consistency correctly during dynamic reconfiguration. It allows user to create and dynamically interconnect modules through well-defined interfaces. Since it is based on transaction concepts, dynamic reconfiguration is done only at "quiescent" states of modules. <p> The first is the Argus transaction mechanism [56, 57] with the extension of dynamic reconfiguration mechanism by Bloom [16]. Argus, however, does not provide support for incorporating new recovery techniques, such as compensation used in forward recovery. Furthermore, the reconfiguration mechanism has the limitations discussed in Section 2.3. Conic <ref> [47, 48] </ref> gives only a partial framework; providing support for dynamic reconfiguration but little support for recovery management. We have separated the control mechanism from the recovery and reconfiguration policies that ensure preservation of consistency. <p> We have the following design goals to make dynamic reconfiguration mechanisms efficient and general. First, processes should be allowed to interact arbitrarily without unnecessary restrictions. Existing work on dynamic reconfiguration <ref> [11, 16, 47] </ref> is based on transactions as a model of process interaction. As discussed in Chapter 3 and in [13], transactions restrict the way processes can synchronize among one another. Second, we should not mandate quiescence of all affected processes before dynamic reconfiguration can begin. <p> As discussed in Chapter 3 and in [13], transactions restrict the way processes can synchronize among one another. Second, we should not mandate quiescence of all affected processes before dynamic reconfiguration can begin. The approach in <ref> [47] </ref> requires all affected processes to be in quiescent states before a reconfiguration can begin. Some operations that take a long time to complete will delay a reconfiguration unnecessarily. Furthermore, reconfiguration operations may take some time to complete. <p> Neither the reconfiguration mechanisms nor the application need be implemented as transactions since consistency of states in the new configuration is preserved by analyzing dependencies automatically. 10.3.2. Conic Dynamic reconfiguration in Conic <ref> [47, 58] </ref> is also based on transactions. It requires each process that may communicate with those being reconfigured to be at a quiescent state before reconfiguration can begin. A quiescent state is one in which no process sends any message or expects a response from a process being removed.
Reference: [48] <author> Kramer, J. and J. Magee, </author> <title> ``Dynamic Configuration for Distributed Systems,'' </title> <journal> IEEE Transaction on Software Engineering SE-11(4) pp. </journal> <month> 424-436 (April </month> <year> 1985). </year>
Reference-contexts: HPC provides the mechanisms for users to define abstraction and composition of processes. This thesis supplements systems like HPC and Durra by preserving state information during exceptional operations such as dynamic reconfiguration and recovery. Conic <ref> [47, 48, 58] </ref> differs from HPC and Durra by managing state consistency correctly during dynamic reconfiguration. It allows user to create and dynamically interconnect modules through well-defined interfaces. Since it is based on transaction concepts, dynamic reconfiguration is done only at "quiescent" states of modules. <p> The first is the Argus transaction mechanism [56, 57] with the extension of dynamic reconfiguration mechanism by Bloom [16]. Argus, however, does not provide support for incorporating new recovery techniques, such as compensation used in forward recovery. Furthermore, the reconfiguration mechanism has the limitations discussed in Section 2.3. Conic <ref> [47, 48] </ref> gives only a partial framework; providing support for dynamic reconfiguration but little support for recovery management. We have separated the control mechanism from the recovery and reconfiguration policies that ensure preservation of consistency.
Reference: [49] <author> Kung, H. T. and J. T. Robinson, </author> <title> ``On Optimistic Methods for Concurrency Control,'' </title> <journal> ACM Transactions on Database Systems 6(2) pp. </journal> <month> 213-226 (June </month> <year> 1981). </year>
Reference-contexts: Atomic abstract data types [77, 87] require transactions to be serializable after non-dependent operations are commuted. In atomic abstract data types, as in ACTA [20], the burden of analyzing commutativity (or dependency) between operations is placed on the programmers. Optimistic approaches <ref> [35, 49] </ref> also require committed transactions to be serializable. Cooperative transactions [7] extend basic nested transactions [63], but still require the partial order of lower level nested transactions to be equivalent to a total order of operations invoked by subtransactions of the cooperating transaction.
Reference: [50] <author> Lam, Simon S. and A. Udaya Shankar, </author> <title> ``A Relational Notation for State Transition Systems,'' </title> <journal> IEEE Transaction on Software Engineering 16(7)(July 1990). </journal>
Reference-contexts: We also discuss other work that provides uniform support for different recovery techniques and compare with our goal of uniformly supporting these three aspects of distributed system. 2.1. Synchronization Several state-transition approaches to specifying distributed applications have been used in the past. Lam and Shankar <ref> [50] </ref> use a finite state machine model for specifying and verifying communication protocols from a user's description of the properties. Clarke, et. al. [21], use another approach for automatic verification of concurrent systems using temporal logic [59] specifications provided by the users.
Reference: [51] <author> Lamport, Leslie, </author> <title> ``How to Make a Multiprocessor Computer That Correctly Executes Multiprocess Programs,'' </title> <journal> IEEE Transactions on Computers C-28(9) pp. </journal> <month> 690-691 (September </month> <year> 1979). </year>
Reference-contexts: Based on this notion of consistency, we introduce a general set of conditions that guarantee the correctness of recovery and dynamic reconfiguration. Existing concurrency and recovery correctness conditions based on some notion of sequentiality <ref> [10, 51] </ref> preserve consistency in a conservative way by isolating intermediate results of atomic operations. This is inappropriate in many distributed applications where intermediate results of a process may be visible to other processes and their operations may not be serialized. <p> Serializability A simple criterion for preserving interactive consistency is to enforce sequential ordering of the operations. A weaker (and more efficient) criterion than strict sequential ordering is to ensure that the interleaved execution of operations is equivalent to a sequentially ordered execution. Sequential consistency is defined in <ref> [51] </ref> as, "The result of an execution is the same as if the operations had been executed in the order specified by the (sequential) program." (While this notion of consistency originated in the context of multiprocessors, it is also applicable to distributed systems.) This notion of sequential consistency does not place
Reference: [52] <author> Lamport, Leslie, </author> <title> ``Specifying Concurrent Program Modules,'' </title> <journal> ACM Transactions on Programming Languages and Systems 5(2) pp. </journal> <month> 190-222 (April </month> <year> 1983). </year> <month> 150 </month>
Reference-contexts: Our basic interpretation of finite-state machines is similar to <ref> [52] </ref> in that states are clean-points (instantaneous) and transitions represent operations requiring some time. This contrasts with the traditional interpretation of finite-state machines where machines may be in a state for a duration of time (possibly executing some operations) and transitions are instantaneous. <p> Basic transitions take a finite time to complete and are non-atomic, i.e. failure may occur in the midst of them. Our interpretation of finite-state machines is similar to Lamport's model <ref> [52] </ref> in that states are clean-points and transitions represent operations requiring some time. Software designers specify basic machines purely in term of their own sequential operations without describing synchronization with other basic machines. Each basic machine executes independently but may interact with others. Product Machines.
Reference: [53] <author> Lamport, Leslie, Robert Shostak, and Marshall Pease, </author> <title> ``The Byzantine Generals Problem,'' </title> <journal> ACM Transaction on Programming Languages and Systems 4(3) pp. </journal> <month> 382-401 (July </month> <year> 1982). </year>
Reference-contexts: Our notion of interactive consistency is at a higher semantic level than the hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh 1 We use the term interactive consistency in a different technical sense from other literature <ref> [53, 80] </ref>. We chose to use these words because they accurately describe our intended concept. Throughout this thesis, we will use the term in the sense defined here. 18 19 notion of global state consistency described in [18, 39, 44], which is defined at the level of message communication abstraction.
Reference: [54] <author> Lampson, Butler W., </author> <title> ``Protection,'' </title> <booktitle> Proceedings of the 5th Princeton Symposium on Information Sciences and Systems, </booktitle> <pages> pp. </pages> <address> 437-443 Princeton University,, </address> <month> (March </month> <year> 1971). </year> <note> Also in ACM Operating Systems Review, 8, 1, January 1974, </note> <author> p. </author> <month> 18-24 </month>
Reference-contexts: The runtime mechanism that performs these task is independent of the policies software designers may specify through the model. The well-known separation of policy and mechanism <ref> [40, 54] </ref> has not been previously applied to synchronization, reliability and reconfiguration of distributed systems. machine specifications are compiled statically and how a consistency control manager provides the common control mechanism.
Reference: [55] <author> LeBlanc, T. J. and S. A. Friedberg, </author> <title> ``Hierarchical Process Composition in Distributed Operating Systems,'' </title> <booktitle> Proc. 5th Int. Conf. on Distributed Computing Systems, </booktitle> <pages> pp. </pages> <month> 26-34 (May </month> <year> 1985). </year>
Reference-contexts: As will be discussed in Chapter 4, a composite specification has the power of predicate path expressions [5, 17] or serializability constraints to synchronize independently programmed processes. 2.3. Dynamic Reconfiguration Durra [8] and HPC <ref> [55] </ref> deal primarily with the problem of structural reconfiguration, where groups of modules can be recomposed via links, but did not deal with the problem of maintaining state consistency. HPC provides the mechanisms for users to define abstraction and composition of processes. <p> Software designers must specify the states at which specialized save (restore) operations may begin (end). Unlike the systems discussed so far, Durra [8] and HPC <ref> [25, 55] </ref> do not deal with the problem of transferring states but rather concentrate on the problem of structural reconfiguration where groups of modules can be recomposed via modification of communication links.
Reference: [56] <author> Liskov, B., D. Curtis, P. Johnson, and R. Scheifler, </author> <title> ``Implementation of Argus,'' </title> <booktitle> Proceedings of the 11th Symposium on Operating Systems, </booktitle> <pages> pp. </pages> <month> 111-122 (November </month> <year> 1987). </year>
Reference-contexts: Other variations [42, 43, 71] of this recovery technique also do not exploit semantics of the application to detect actual dependence. Another common approach to reliable distributed systems is based on atomic transactions <ref> [22, 56, 57, 77, 78] </ref> that preserve the following properties: all-or-nothing, consistency, isolation, and durability [32]. The all-or-nothing property guarantees that either the transaction completes or it has no effect even though it may have failed. <p> The framework should be responsible for maintaining consistency and making it transparent to the software designer. Two existing systems that provide a uniform framework are based on transactions and have the restrictions discussed in Section 2.2. The first is the Argus transaction mechanism <ref> [56, 57] </ref> with the extension of dynamic reconfiguration mechanism by Bloom [16]. Argus, however, does not provide support for incorporating new recovery techniques, such as compensation used in forward recovery. Furthermore, the reconfiguration mechanism has the limitations discussed in Section 2.3. <p> In the following, we compare our approach to other techniques only for applications with finite-state processes. 10.3.1. Module Replacement in Argus Bloom [16] introduced a framework for checking legality of dynamic module replacement based on the transaction mechanisms of Argus <ref> [56, 57] </ref>. Processes interact entirely through the client-server model. The transaction mechanisms provided by Argus preserve interactive consistency. For example, a sequence of transitions representing a replacement is implemented as an atomic transaction. <p> Finally, an important long-term future task is the implementation of a general distributed computing environment that supports reliable and dynamically reconfigurable distributed applications based on the work here similarly to the way Camelot (Encina) [78] and Argus <ref> [56, 57] </ref> support reliability in general distributed applications based on transactions. Appendix A A Glossary of Terms The following terms are given specific technical meanings in the thesis. Some terms may be used in a different technical sense in the literature.
Reference: [57] <author> Liskov, B. and R. W. Scheifler, </author> <title> ``Guardians and actions: Linguistic Support for Robust , Distributed Programs,'' </title> <journal> ACM Transaction on Programming Languages and Systems 5(3) pp. </journal> <month> 381-404 (July </month> <year> 1983). </year>
Reference-contexts: Other variations [42, 43, 71] of this recovery technique also do not exploit semantics of the application to detect actual dependence. Another common approach to reliable distributed systems is based on atomic transactions <ref> [22, 56, 57, 77, 78] </ref> that preserve the following properties: all-or-nothing, consistency, isolation, and durability [32]. The all-or-nothing property guarantees that either the transaction completes or it has no effect even though it may have failed. <p> The framework should be responsible for maintaining consistency and making it transparent to the software designer. Two existing systems that provide a uniform framework are based on transactions and have the restrictions discussed in Section 2.2. The first is the Argus transaction mechanism <ref> [56, 57] </ref> with the extension of dynamic reconfiguration mechanism by Bloom [16]. Argus, however, does not provide support for incorporating new recovery techniques, such as compensation used in forward recovery. Furthermore, the reconfiguration mechanism has the limitations discussed in Section 2.3. <p> This allows uniform control of the normal execution as well as different techniques for failure recovery and reconfiguration. Other work has concentrated on allowing designers to customize a limited set of application-specific techniques only for recovery management. Several researchers <ref> [15, 34, 57, 78] </ref> support customizable recovery techniques by separating the underlying mechanisms from the policies that are associated with various recovery techniques and options. These systems provide the basic mechanisms for supporting transactions, e.g. transaction creation and commit, logging, and recovery management. <p> Black [15] proposed an approach of exposing the mechanism for implementing and selecting abstractions that characterize transactions, such as atomicity, consistency, isolation and persistence. QuickSilver [34] exposes a set of primitives that is at a lower level than most other systems, such as Camelot [78] and Argus <ref> [57] </ref>, and permits servers to implement their own recoverable storage and log recovery. While these systems are 17 based on concepts of transactions, we include other recovery techniques, such as compensation and exception, as well as reconfiguration operations in distributed applications with general and non serializable inter-process interactions. <p> In the following, we compare our approach to other techniques only for applications with finite-state processes. 10.3.1. Module Replacement in Argus Bloom [16] introduced a framework for checking legality of dynamic module replacement based on the transaction mechanisms of Argus <ref> [56, 57] </ref>. Processes interact entirely through the client-server model. The transaction mechanisms provided by Argus preserve interactive consistency. For example, a sequence of transitions representing a replacement is implemented as an atomic transaction. <p> Finally, an important long-term future task is the implementation of a general distributed computing environment that supports reliable and dynamically reconfigurable distributed applications based on the work here similarly to the way Camelot (Encina) [78] and Argus <ref> [56, 57] </ref> support reliability in general distributed applications based on transactions. Appendix A A Glossary of Terms The following terms are given specific technical meanings in the thesis. Some terms may be used in a different technical sense in the literature.
Reference: [58] <author> Magee, J., J. Kramer, and M. Sloman, </author> <title> ``Constructing Distributed Systems in Conic,'' </title> <journal> IEEE Transactions on Software Engineering 15(6) pp. </journal> <month> 663-675 (June </month> <year> 1989). </year>
Reference-contexts: HPC provides the mechanisms for users to define abstraction and composition of processes. This thesis supplements systems like HPC and Durra by preserving state information during exceptional operations such as dynamic reconfiguration and recovery. Conic <ref> [47, 48, 58] </ref> differs from HPC and Durra by managing state consistency correctly during dynamic reconfiguration. It allows user to create and dynamically interconnect modules through well-defined interfaces. Since it is based on transaction concepts, dynamic reconfiguration is done only at "quiescent" states of modules. <p> Comparison with Other Dynamic Reconfiguration Techniques The two main advantages of our system are: (1) we allow dynamic reconfiguration of applications that may interact in complex ways and (2) we allow greater concurrency, than other systems <ref> [16, 58] </ref>, by breaking reconfiguration paths into segments to allow unaffected processes execute at transient configurations between segments. (A reconfiguration path is partitioned only if the cost is outweighed by the benefits of higher concurrency resulting from partitioning.) However, compared to those transactional systems, we incur the additional cost of finding <p> Neither the reconfiguration mechanisms nor the application need be implemented as transactions since consistency of states in the new configuration is preserved by analyzing dependencies automatically. 10.3.2. Conic Dynamic reconfiguration in Conic <ref> [47, 58] </ref> is also based on transactions. It requires each process that may communicate with those being reconfigured to be at a quiescent state before reconfiguration can begin. A quiescent state is one in which no process sends any message or expects a response from a process being removed. <p> Using a related algorithm, we can break a reconfiguration path into segments to allow greater concurrency of unaffected processes at transient configurations between segments. Our approach does not require processes to be quiescent before reconfiguration as in other systems <ref> [58, 69] </ref>. Furthermore, we allow applications to interact in complex ways, whereas other systems [16, 58] only permit reconfiguration of applications based on transactions. 11.3. <p> Our approach does not require processes to be quiescent before reconfiguration as in other systems [58, 69]. Furthermore, we allow applications to interact in complex ways, whereas other systems <ref> [16, 58] </ref> only permit reconfiguration of applications based on transactions. 11.3. Future Work There are many areas of future research that will enhance the work presented here, e.g. specification environment, analysis of more synchronization problems, linguistic support and tools, compilation and performance tuning of implementations.
Reference: [59] <author> Manna, Z. and A. Pnueli, </author> <title> ``Verification of Concurrent Programs: A Temporal Proof System,'' pp. </title> <booktitle> 163-255 in Foundations of Computer Science IV, Distributed Systems: Part 2 (J.W. </booktitle> <editor> DeBakker and J. Van Leuwen, </editor> <booktitle> eds.), </booktitle> <institution> Center for Mathematics and Computer Science (CWI), </institution> <address> Amsterdam (1983). </address>
Reference-contexts: Lam and Shankar [50] use a finite state machine model for specifying and verifying communication protocols from a user's description of the properties. Clarke, et. al. [21], use another approach for automatic verification of concurrent systems using temporal logic <ref> [59] </ref> specifications provided by the users. CCS [62] is suitable for detecting deadlock but not starvation or livelock without requiring users to specify these properties using modal logic [84].
Reference: [60] <author> Marzullo, Keith, Robert Cooper, Mark Wood, and Kenneth Birman, </author> <title> ``Tools for Distributed Application Management ,'' TR 90-1136, </title> <institution> Department of Computer Science, Cornell University (July 1990). </institution>
Reference-contexts: An example of physical redundancy is replicated servers. Despite the failure of some servers, the service will still be provided as long as at least one server is functional. ISIS/Meta <ref> [12, 60] </ref> provides mechanisms and an environment for monitoring and controlling fault-tolerant distributed applications using replicated servers. In [75], a state machine model has been used for designing reliable distributed systems based on replication. There are two main problems with the replication approach.
Reference: [61] <author> Mili, Ali, </author> <title> ``Towards a Theory of Forward Error Recovery,'' </title> <journal> IEEE Transactions on Software Engineering SE-11(8 ) pp. </journal> <month> 735-748 (August </month> <year> 1985). </year>
Reference-contexts: In this discussion, let S f be a state in F. Figure 7.1 shows some future states in a restricted product machine. S f is similar to a future final 69 70 S c S f S f S f E c F E r state defined in <ref> [61] </ref> with two exceptions. First, we consider not just the final states but any state in any path from S c to the final states. The set of future states may be restricted to significant states, i.e. states where useful application-specific work has been performed.
Reference: [62] <author> Milner, Robin, </author> <title> A Calculus of Communicating Systems, </title> <publisher> Springer Verlay, </publisher> <address> New York (1980). </address>
Reference-contexts: Lam and Shankar [50] use a finite state machine model for specifying and verifying communication protocols from a user's description of the properties. Clarke, et. al. [21], use another approach for automatic verification of concurrent systems using temporal logic [59] specifications provided by the users. CCS <ref> [62] </ref> is suitable for detecting deadlock but not starvation or livelock without requiring users to specify these properties using modal logic [84]. SPANNER [1-3] allows detection of deadlocks but requires users to specify the liveness properties in terms of finite state machines to verify them.
Reference: [63] <author> Moss, J. Eliot B., </author> <title> ``Nested Transactions: An Approach to Reliable Distributed Computing,'' </title> <type> Ph.D. Dissertation, </type> <institution> Department of Electrical Engineering and Computer Science, </institution> <address> MIT (April 1981). </address>
Reference-contexts: In atomic abstract data types, as in ACTA [20], the burden of analyzing commutativity (or dependency) between operations is placed on the programmers. Optimistic approaches [35, 49] also require committed transactions to be serializable. Cooperative transactions [7] extend basic nested transactions <ref> [63] </ref>, but still require the partial order of lower level nested transactions to be equivalent to a total order of operations invoked by subtransactions of the cooperating transaction.
Reference: [64] <author> Moss, J. E. B., N. D. Griffeth, and M. H. Graham, </author> <booktitle> ``Abstraction in Recovery Management ,'' Proceedings of the 1986 ACM SIGMOD Conference, </booktitle> <pages> pp. </pages> <month> 72-83 (May 28-30, </month> <year> 1986). </year>
Reference-contexts: Instead of using block structures and enforcing isolation and recoverability, we deal with operation dependencies by detecting all operations dependent on an aborted process and forcing them to recover. This is a generalization of the restorability property <ref> [64] </ref> where all operations that depend (transitively) on a recovered operation must themselves be recovered. This definition does not assume a particular recovery method, i.e. recovery methods include not only rollback recovery but also forward compensating and corrective recovery. <p> Once we have identified these properties, we do not need execution sequences for analyzing a particular application. Instead we use the behavior FSM specification for analyzing the correctness of recovery using a suffix of the execution sequence. This approach contrasts with most other works <ref> [9, 31, 45, 64] </ref> that use a history log for analyzing and verifying the correctness of recovery of individual applications. 62 63 In this chapter, we describe the notion of execution sequences, equivalence between execution sequences, how they are modified by normal and recovery operations and how they are used to <p> On the other hand, all operations that commute can always be permuted. Thus, permutativity property subsumes commutativity property that is described in [87]. 64 The notion of execution sequence is similar to history in <ref> [31, 45, 64, 87] </ref>. We however use execution sequences only for reasoning about the properties of the augmented FSM's that will guarantee correctness of recovery. <p> The notion of dependence in <ref> [45, 64, 87] </ref> is based not only on the ordering in a history log (which can be incidental) but also on a separate synchronization arbitrator, such as a conflict table. <p> In Section 8.3.3 and 8.3.4, we describe how some existing forward recovery methods satisfy the correctness conditions for recovery. 8.3.1. Restore and Undo Traditional methods of transactional recovery based on restore and undo <ref> [10, 64, 88] </ref> satisfy the correctness condition for backward recovery defined in Section 8.2.1. Restore can be represented by a recovery transition that leaves the current basic state and enters a previous basic state that may be of arbitrary distance away.
Reference: [65] <author> Naylor, A. and R. A. Volz, </author> <title> ``Design of Integrated Manufacturing System Control Software ,'' IEEE Transaction on Systems, </title> <journal> Man, and Cybernetics SMC-17(6) pp. </journal> <month> 881-897 (November/December </month> <year> 1987). </year>
Reference-contexts: Such program changes are common for many reasons: improvements in production processes, engineering design changes, or quick switches to producing a different part in a family of related parts, etc. Today's automated manufacturing software is poor at reconfiguration without downtime. Approaches in <ref> [65, 85] </ref> require the manufacturing system to be stopped for newly generated software to be installed and initiated. They do not address the problem of maintaining consistency of other components that interact with the changed components.
Reference: [66] <author> Papadimitriou, Christos H., </author> <title> ``The Serializability of Concurrent Database Updates,'' </title> <journal> Journal of the Association for Computing Machinery 26(4) pp. </journal> <month> 631-653 (October </month> <year> 1979). </year>
Reference-contexts: It is thus weaker than serializability and linearizability discussed below. In much work on databases and distributed system, a similar criterion used for transactions (sequences of operations) is serializability <ref> [9, 10, 31, 66] </ref>. Two sequences of transactions are equivalent if the dependence relation between every pair of transactions in both sequences are identical [24, 66]. <p> In much work on databases and distributed system, a similar criterion used for transactions (sequences of operations) is serializability [9, 10, 31, 66]. Two sequences of transactions are equivalent if the dependence relation between every pair of transactions in both sequences are identical <ref> [24, 66] </ref>. A transaction T i is dependent on T j if T j writes a data item whose value is then read by T i .
Reference: [67] <author> Pathak, Dhiraj K. and Bruce H. Krogh, </author> <title> ``Concurrent Operation Specification Language, COSL, for Low-Level Manufacturing Control,'' </title> <booktitle> Computer in Industry 12(2) pp. </booktitle> <month> 107-122 (May </month> <year> 1989). </year>
Reference-contexts: Scope and Assumptions In this thesis, we restrict our scope to applications with finite-state behavior to simplify automated checking of dependency and consistency. The finite-state machine model is useful in many distributed applications such as computer control of automated manufacturing <ref> [23, 67] </ref>. Systems with infinite state behavior, such as unbounded FIFO channels and other systems described in [70], will require an extension to the analysis described here. However, the definition of consistency and the conditions for preserving consistency are applicable to infinite as well as finite-state systems. <p> It is intrinsic to the synchronization problem. (In Section 4.7 and 5.3, we discuss the algorithms used to detect the possibility of deadlock or starvation in this example.) To illustrate behavior involving complex interaction that cannot be sequentialized, we describe an example of a manufacturing application from <ref> [67] </ref>. There are two die-stamping machines and a conveyor-based workpiece-replacement mechanism (Figure 4.3). By assigning appropriate values to its actuators, each die-stamping machine stamps a workpiece held between two stops at the conveyor. <p> In contrast to the approach used in <ref> [67] </ref>, our approach does not require the designer to specify the complete global flow control of the operations and is less susceptible to human error. This example also illustrates how we can express any arbitrary interaction that can be expressed in path expressions. <p> However, the FSM model is useful for many distributed applications such as automated manufacturing <ref> [23, 67] </ref>. In the following, we compare the correctness conditions of existing backward and forward recovery techniques with our correctness conditions. In Section 8.3.1 and 8.3.2, we show that two important existing backward recovery methods [10, 72, 77, 86], satisfy the conditions for correctness of backward recovery.
Reference: [68] <author> Peterson, James L., </author> <title> Petri Net Theory and the Modeling of Systems, </title> <publisher> Prentice-Hall (1981). </publisher>
Reference-contexts: However, our model contains additional features that enable software desigers to characterize the behavior of applications in 11 12 the presence of failure, recovery and dynamic reconfiguration. We also allow hierarchical composition of finite-state machines. Other models such as Petri nets <ref> [68] </ref> have been successfully used to model distributed systems. Petri nets have operational semantics and behavior specifications that cannot be easily used for checking consistency. We choose the finite-state machine model because it enables us to analyze consistency in the presence of failure automatically.
Reference: [69] <author> Purtilo, James M. and Christine R. Hofmeiser, </author> <title> ``Dynamic Reconfiguration of Distributed Programs,'' </title> <booktitle> Proc. 11th International Conference on Distributed Computing Systems, </booktitle> <pages> pp. </pages> <month> 560-571 (May, </month> <year> 1991). </year>
Reference-contexts: Our work also allows more general synchronization and interaction between objects than client-server transactions. Other aspects of dynamic reconfiguration has been addressed in other work and are omitted here. Dynamic reconfiguration, implemented in Polylith <ref> [69] </ref>, addressed the practical problem of capturing and restoring states although they did not address the issues of maintaining state consistency. In [33], Hailpern and Kaiser mainly address the problem of maintaining type consistency during dynamic 16 reconfiguration. <p> We can overcome this problem by forcing processes to recover to states where reconfiguration may begin. Recovery of those processes being removed does not waste any computation. 136 10.3.3. Others Polylith <ref> [69] </ref> addressed the problem of capturing and restoring state but ignored the problem of maintaining consistency of those states. They limit the amount of state information that needs to be saved and restored by defining specialized encode and decode functions. <p> Using a related algorithm, we can break a reconfiguration path into segments to allow greater concurrency of unaffected processes at transient configurations between segments. Our approach does not require processes to be quiescent before reconfiguration as in other systems <ref> [58, 69] </ref>. Furthermore, we allow applications to interact in complex ways, whereas other systems [16, 58] only permit reconfiguration of applications based on transactions. 11.3.
Reference: [70] <author> Ramadge, Peter J. G. and W. Murray Wonham, </author> <title> ``The Control of Discrete Event Systems,'' </title> <booktitle> Proceedings of the IEEE 77(1) pp. </booktitle> <month> 81-98 (January </month> <year> 1989). </year>
Reference-contexts: The finite-state machine model is useful in many distributed applications such as computer control of automated manufacturing [23, 67]. Systems with infinite state behavior, such as unbounded FIFO channels and other systems described in <ref> [70] </ref>, will require an extension to the analysis described here. However, the definition of consistency and the conditions for preserving consistency are applicable to infinite as well as finite-state systems. Most applications in our target environments permit modular design.
Reference: [71] <author> Randell, Brian, </author> <title> ``System Structure for Software Fault Tolerance,'' </title> <journal> IEEE Transactions on Software Engineering SE-1(2) pp. </journal> <month> 220-232 (June </month> <year> 1975). </year> <month> 151 </month>
Reference-contexts: The cost of logging messages to stable storage and the analysis required to merge independent message logs can be prohibitive, especially for distributed applications involving many messages. Other variations <ref> [42, 43, 71] </ref> of this recovery technique also do not exploit semantics of the application to detect actual dependence. Another common approach to reliable distributed systems is based on atomic transactions [22, 56, 57, 77, 78] that preserve the following properties: all-or-nothing, consistency, isolation, and durability [32].
Reference: [72] <author> Randell, B., P. A. Lee, and P. C. Treleavan, </author> <title> ``Reliability Issues in Computing System Design,'' </title> <journal> Computing Surveys 10(2) pp. </journal> <month> 123-165 (June </month> <year> 1978). </year>
Reference-contexts: A good system should allow general synchronization and at the same time provide efficient recovery. 13 A common approach to reliable distributed systems is rollback recovery based on message-logging and checkpointing <ref> [39, 44, 72, 79] </ref>. Interactions through messages are used to determine a consistent recovery line; that is, a set of checkpoint states of each process. Determining a consistent recovery line solely from interaction information is too conservative because some interactions may not be crucial to the execution of some processes. <p> When a failure occurs after a consistent historical state S p , operations before S p need not be recovered. While existing approaches <ref> [32, 43, 72] </ref> to avoiding domino effect of cascaded abort are based on recovery blocks, we analyze the semantics of the applications encoded in the restricted product graph and determine the appropriate consistent historical states, e.g. using dominator states, in which all processes take checkpoints. <p> However, the FSM model is useful for many distributed applications such as automated manufacturing [23, 67]. In the following, we compare the correctness conditions of existing backward and forward recovery techniques with our correctness conditions. In Section 8.3.1 and 8.3.2, we show that two important existing backward recovery methods <ref> [10, 72, 77, 86] </ref>, satisfy the conditions for correctness of backward recovery. In Section 8.3.3 and 8.3.4, we describe how some existing forward recovery methods satisfy the correctness conditions for recovery. 8.3.1.
Reference: [73] <author> Ranky, Paul G., </author> <title> Computer Integrated Manufacturing, </title> <booktitle> Prentice-Hall International, </booktitle> <address> UK, </address> <publisher> Ltd., </publisher> <address> Great Britain (1986). </address>
Reference-contexts: Furthermore, these applications may involve frequent recovery from exceptional conditions as well as regularly scheduled reconfiguration or installation of new modules. Distributed applications with these characteristics include computer-aided automated manufacturing <ref> [19, 23, 26, 41, 73] </ref>, multi-transaction database activities [27, 83], network service applications [74, 82], and process control [76]. A major problem in these applications is maintaining consistency in the presence of concurrency, failure and reconfiguration. <p> Yet another example is a manufacturing assembly system that involves several manufacturing cells in a factory floor. Figure 3.4 shows the precedence diagram of the assembly system <ref> [73] </ref> with multiple assembly cells. The nodes represent operations and the directed edges represent the precedence relations between operations. Nodes are partitioned into groups of operations to be executed in each robotized assembly cell: R 1 , R 2 , R 3 and R 4 . <p> For example, the processing of a purchase order (i.e. an activity) in some company 24 2 4 6 8 9 10 12 14 16 18 20 22 R 2 R 4 (after Figure 10.4/b of <ref> [73] </ref>) involves a collection of steps: phone call, enter order, billing, inventory, shipping [27]. The activity starts with a phone call to order certain merchandise. The order is entered into the database and the system then initiates concurrent processing of billing and inventory.
Reference: [74] <author> Rodeheffer, Thomas L. and Michael D. Schroeder, </author> <title> ``Automatic Reconfiguration in Autonet,'' </title> <booktitle> Proceedings of the 13th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pp. 183-197 (October 13-16, </pages> <year> 1991). </year>
Reference-contexts: Furthermore, these applications may involve frequent recovery from exceptional conditions as well as regularly scheduled reconfiguration or installation of new modules. Distributed applications with these characteristics include computer-aided automated manufacturing [19, 23, 26, 41, 73], multi-transaction database activities [27, 83], network service applications <ref> [74, 82] </ref>, and process control [76]. A major problem in these applications is maintaining consistency in the presence of concurrency, failure and reconfiguration. Atomic transactions are commonly used to simplify the management of concurrency and failure by preserving serializability and failure atomicity.
Reference: [75] <author> Schneider, Fred B., </author> <title> ``Implementing Fault-Tolerant Services Using the State Machine Approach: A Tutorial,'' </title> <journal> ACM Computing Surveys 22(4) pp. </journal> <month> 299-319 (December </month> <year> 1990). </year>
Reference-contexts: An example of physical redundancy is replicated servers. Despite the failure of some servers, the service will still be provided as long as at least one server is functional. ISIS/Meta [12, 60] provides mechanisms and an environment for monitoring and controlling fault-tolerant distributed applications using replicated servers. In <ref> [75] </ref>, a state machine model has been used for designing reliable distributed systems based on replication. There are two main problems with the replication approach. First, accesses to replicated servers need to be synchronized correctly to maintain consistency. Second, the cost of replicating very large objects can be prohibitive. <p> Basic machines and managers may interact with an external semantic information facility that maintains information that is not easily represented by a finite-state machine model, such as counters, hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh 1 It is possible to improve the fault-tolerance of the centralized consistency control manager through various replication techniques <ref> [14, 75] </ref>.
Reference: [76] <author> Schoeffler, James D., </author> <title> ``Distributed Computer Systems for Industrial Process Control,'' </title> <journal> IEEE Computer 17(2) pp. </journal> <month> 11-18 (February </month> <year> 1984). </year>
Reference-contexts: Furthermore, these applications may involve frequent recovery from exceptional conditions as well as regularly scheduled reconfiguration or installation of new modules. Distributed applications with these characteristics include computer-aided automated manufacturing [19, 23, 26, 41, 73], multi-transaction database activities [27, 83], network service applications [74, 82], and process control <ref> [76] </ref>. A major problem in these applications is maintaining consistency in the presence of concurrency, failure and reconfiguration. Atomic transactions are commonly used to simplify the management of concurrency and failure by preserving serializability and failure atomicity.
Reference: [77] <author> Schwarz, Peter M. and Alfred Z. Spector, </author> <title> ``Synchronizing Shared Abstract Types,'' </title> <journal> ACM Transactions on Computer Systems 2(3) pp. </journal> <month> 223-250 (August </month> <year> 1984). </year>
Reference-contexts: Other variations [42, 43, 71] of this recovery technique also do not exploit semantics of the application to detect actual dependence. Another common approach to reliable distributed systems is based on atomic transactions <ref> [22, 56, 57, 77, 78] </ref> that preserve the following properties: all-or-nothing, consistency, isolation, and durability [32]. The all-or-nothing property guarantees that either the transaction completes or it has no effect even though it may have failed. <p> Even in implementations of transactions, recovery methods have been known to affect concurrency control [6, 31, 88]. In more general applications, we believe the right approach is to allow general 14 synchronization and yet provide appropriate mechanisms to control recovery. While some work <ref> [7, 28, 35, 77, 87] </ref> extends the traditional transaction concept by exploiting semantic knowledge to provide more concurrency, we have started from a general synchronization environment and made it reliable. There is a limitation on extending transactions because all transactions must eventually satisfy the serializability or recoverability criteria. <p> There is a limitation on extending transactions because all transactions must eventually satisfy the serializability or recoverability criteria. This is inappropriate for many distributed applications that usually involve non-serializable and non-recoverable operations as will be discussed in Section 3.4. Atomic abstract data types <ref> [77, 87] </ref> require transactions to be serializable after non-dependent operations are commuted. In atomic abstract data types, as in ACTA [20], the burden of analyzing commutativity (or dependency) between operations is placed on the programmers. Optimistic approaches [35, 49] also require committed transactions to be serializable. <p> For example, processes that involve non-serializable interaction (Section 1.2) cannot be implemented as transactions. Many research projects have concentrated on improving concurrency by commuting operations using application semantics or abstract data type specifications <ref> [28, 77, 86] </ref>. Even in these approaches, commuted operations must eventually satisfy the serializability criteria. 3.3. <p> However, the FSM model is useful for many distributed applications such as automated manufacturing [23, 67]. In the following, we compare the correctness conditions of existing backward and forward recovery techniques with our correctness conditions. In Section 8.3.1 and 8.3.2, we show that two important existing backward recovery methods <ref> [10, 72, 77, 86] </ref>, satisfy the conditions for correctness of backward recovery. In Section 8.3.3 and 8.3.4, we describe how some existing forward recovery methods satisfy the correctness conditions for recovery. 8.3.1. <p> By the isolation property, the intermediate results of a transaction are not visible to other transactions. This implies no operation of a transaction is dependent on an operation of another uncommitted transaction, satisfying the dependence condition. 8.3.2. Atomic Abstract Data Types Various works <ref> [28, 77, 86] </ref> have exploited semantic information to increase the level of concurrency among transactions and optimize failure recovery. We will take Weihl's work [86, 87] as a representative one. <p> The conditions for recovery and reconfiguration enable us to improve efficiency by allowing permuting and substituting transitions whenever permitted by the behavior specification. By analyzing specific product states in the (potential) behavior of an application, our method computes more accurate dependencies than other work on transactions <ref> [28, 77, 87] </ref> which specifies only commutativity of operations for all product states. Using more accurate dependencies reduces the "cascade" effect during recovery, thus reducing wastage of computation. We presented an algorithm for computing necessary precedence automatically from a restricted product machine. <p> Using more accurate dependencies reduces the "cascade" effect during recovery, thus reducing wastage of computation. We presented an algorithm for computing necessary precedence automatically from a restricted product machine. Besides computing accurate dependencies, this algorithm frees software designers from analyzing dependencies and commutativity between operations as in other work <ref> [20, 77, 87] </ref>. To check for some causes of failure, we presented algorithms for detecting synchronization problems such as deadlock, possible livelock and starvation. We also presented an algorithm for computing recovery paths that preserve consistency.
Reference: [78] <author> Spector, Alfred Z., Dean Thompson, Randy F. Pausch, Jeffrey L. Eppinger, Dan Duchamp, Richard Draves, Dean S. Daniels, and Joshua J. Bloch, ``Camelot: </author> <title> A Distributed Transaction Facility for Mach amd the Internet An Interim Report,'' </title> <institution> Technical Report CMU-CS-87-129 , Department of Computer Science, Carnegie Mellon University (June 17, </institution> <year> 1987). </year>
Reference-contexts: Other variations [42, 43, 71] of this recovery technique also do not exploit semantics of the application to detect actual dependence. Another common approach to reliable distributed systems is based on atomic transactions <ref> [22, 56, 57, 77, 78] </ref> that preserve the following properties: all-or-nothing, consistency, isolation, and durability [32]. The all-or-nothing property guarantees that either the transaction completes or it has no effect even though it may have failed. <p> This allows uniform control of the normal execution as well as different techniques for failure recovery and reconfiguration. Other work has concentrated on allowing designers to customize a limited set of application-specific techniques only for recovery management. Several researchers <ref> [15, 34, 57, 78] </ref> support customizable recovery techniques by separating the underlying mechanisms from the policies that are associated with various recovery techniques and options. These systems provide the basic mechanisms for supporting transactions, e.g. transaction creation and commit, logging, and recovery management. <p> Black [15] proposed an approach of exposing the mechanism for implementing and selecting abstractions that characterize transactions, such as atomicity, consistency, isolation and persistence. QuickSilver [34] exposes a set of primitives that is at a lower level than most other systems, such as Camelot <ref> [78] </ref> and Argus [57], and permits servers to implement their own recoverable storage and log recovery. <p> Finally, an important long-term future task is the implementation of a general distributed computing environment that supports reliable and dynamically reconfigurable distributed applications based on the work here similarly to the way Camelot (Encina) <ref> [78] </ref> and Argus [56, 57] support reliability in general distributed applications based on transactions. Appendix A A Glossary of Terms The following terms are given specific technical meanings in the thesis. Some terms may be used in a different technical sense in the literature.
Reference: [79] <author> Strom, Robert E. and Shuala Yemini, </author> <title> ``Optimistic Recovery in Distributed Systems,'' </title> <journal> ACM Transactions on Computer Systems 3(3) pp. </journal> <month> 204-226 (August </month> <year> 1985). </year>
Reference-contexts: Recovery of a failed process may not affect another process if the other does not actually depend on the failed process (though there may be apparent dependencies). Other approaches that allow general and irregular interaction patterns, such as message-logging and checkpointing <ref> [39, 79] </ref>, do not exploit semantics of the application to improve recovery in the presence of failure and aborts. By analyzing the behavior of applications, we can also improve efficiency by checkpointing only states that would be most important for recovery purposes. <p> A good system should allow general synchronization and at the same time provide efficient recovery. 13 A common approach to reliable distributed systems is rollback recovery based on message-logging and checkpointing <ref> [39, 44, 72, 79] </ref>. Interactions through messages are used to determine a consistent recovery line; that is, a set of checkpoint states of each process. Determining a consistent recovery line solely from interaction information is too conservative because some interactions may not be crucial to the execution of some processes. <p> Checkpointing Consistent Historical States As described Section 7.1, we assume the existence of at least one consistent (firewall) historical state S p . A state S p can be created using known techniques for checkpointing global states of the processes, either conservatively [44] or optimistically <ref> [79] </ref>. S p may move with the normal execution resulting in a reduction in the recovery scope and the length of the recovery path. Conversely, we do not require every product state entered to be checkpointed. <p> Our system allows complex, non-atomic interactions between long-lived, repetitive, or cyclic processes without requiring designer-specified commutativity of operations or a limited range of synchronization and sequencing constraints. Although some approaches also permit complex synchronization constraints, such as message-logging and checkpointing <ref> [39, 79] </ref>, they do not exploit the semantics of applications to improve recovery. We took interactive consistency, rather than serial execution, as the model for correct execution. This allows recovery and reconfiguration of applications with partial-order semantics: a larger group than serializable or linearizable applications.
Reference: [80] <author> Strong, Ray, </author> <title> ``Interactive Consistency,'' pp. 125-137 in Dependability of Resilient Computers, </title> <editor> T. Anderson (ed.), </editor> <booktitle> BSP Professional Book (1989). </booktitle>
Reference-contexts: Our notion of interactive consistency is at a higher semantic level than the hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh 1 We use the term interactive consistency in a different technical sense from other literature <ref> [53, 80] </ref>. We chose to use these words because they accurately describe our intended concept. Throughout this thesis, we will use the term in the sense defined here. 18 19 notion of global state consistency described in [18, 39, 44], which is defined at the level of message communication abstraction.
Reference: [81] <author> Tarjan, Robert, </author> <title> ``Depth-First Search and Linear Graph Algorithms,'' </title> <journal> SIAM J. Comput. </journal> <pages> 1(2) pp. </pages> <month> 146-160 (June </month> <year> 1972). </year>
Reference-contexts: The outline of the algorithm is as follows. (1) Identify all SCC, C 1 , ..., C N , in the restricted product graph G using Tarjan's algorithm <ref> [81] </ref>. (For this algorithm, each node not in any strongly connected component forms a singleton SCC.) Generate a strong reduction graph G as follow: nodes of G are SCC's of G and an arc C i fi C j exists in G if and only if there is a transition x
Reference: [82] <author> Twidle, K. and M. Sloman, </author> <title> ``Domain Based Configuration and Name Management for Distributed Systems,'' </title> <booktitle> Proc. Workshop on Future Trends of Distributed Computing Systems in 1990's, IEEE Computer Society, </booktitle> <month> (September </month> <year> 1988). </year>
Reference-contexts: Furthermore, these applications may involve frequent recovery from exceptional conditions as well as regularly scheduled reconfiguration or installation of new modules. Distributed applications with these characteristics include computer-aided automated manufacturing [19, 23, 26, 41, 73], multi-transaction database activities [27, 83], network service applications <ref> [74, 82] </ref>, and process control [76]. A major problem in these applications is maintaining consistency in the presence of concurrency, failure and reconfiguration. Atomic transactions are commonly used to simplify the management of concurrency and failure by preserving serializability and failure atomicity.
Reference: [83] <author> Wachter, Helmut, </author> <title> ``ConTract: A Means for Improving Reliability in Distributed Computing,'' </title> <booktitle> Proceedings of COMPCON Spring 1991, </booktitle> <month> (February </month> <year> 1991). </year>
Reference-contexts: Furthermore, these applications may involve frequent recovery from exceptional conditions as well as regularly scheduled reconfiguration or installation of new modules. Distributed applications with these characteristics include computer-aided automated manufacturing [19, 23, 26, 41, 73], multi-transaction database activities <ref> [27, 83] </ref>, network service applications [74, 82], and process control [76]. A major problem in these applications is maintaining consistency in the presence of concurrency, failure and reconfiguration. Atomic transactions are commonly used to simplify the management of concurrency and failure by preserving serializability and failure atomicity.
Reference: [84] <author> Walker, D. J., </author> <title> ``Automated Analysis of Mutual Exclusion Algorithms using CCS,'' </title> <institution> ECS-LFCS-89-91, Department of Computer Science, University of Edinburgh (August 1989). </institution>
Reference-contexts: Clarke, et. al. [21], use another approach for automatic verification of concurrent systems using temporal logic [59] specifications provided by the users. CCS [62] is suitable for detecting deadlock but not starvation or livelock without requiring users to specify these properties using modal logic <ref> [84] </ref>. SPANNER [1-3] allows detection of deadlocks but requires users to specify the liveness properties in terms of finite state machines to verify them.
Reference: [85] <author> Weck, M. and E. Kohen, </author> <title> ``Configurable Control Software for FMS,'' pp. 437-445 in Software for Discrete Manufacturing: </title> <booktitle> Proceedings of the 6th International IFIP/IFAC Conference of Software for Discrete Manufacturing, </booktitle> , <address> Paris, France (June 1985). </address>
Reference-contexts: Such program changes are common for many reasons: improvements in production processes, engineering design changes, or quick switches to producing a different part in a family of related parts, etc. Today's automated manufacturing software is poor at reconfiguration without downtime. Approaches in <ref> [65, 85] </ref> require the manufacturing system to be stopped for newly generated software to be installed and initiated. They do not address the problem of maintaining consistency of other components that interact with the changed components.
Reference: [86] <author> Weihl, William E., </author> <title> ``Specification and Implementation of Atomic Data Types,'' </title> <type> Ph.D. dissertation, </type> <institution> MIT/LCS/TR-314, Massachusetts Institute of Technology, </institution> <address> Cambridge (March 1984). </address>
Reference-contexts: For example, processes that involve non-serializable interaction (Section 1.2) cannot be implemented as transactions. Many research projects have concentrated on improving concurrency by commuting operations using application semantics or abstract data type specifications <ref> [28, 77, 86] </ref>. Even in these approaches, commuted operations must eventually satisfy the serializability criteria. 3.3. <p> However, the FSM model is useful for many distributed applications such as automated manufacturing [23, 67]. In the following, we compare the correctness conditions of existing backward and forward recovery techniques with our correctness conditions. In Section 8.3.1 and 8.3.2, we show that two important existing backward recovery methods <ref> [10, 72, 77, 86] </ref>, satisfy the conditions for correctness of backward recovery. In Section 8.3.3 and 8.3.4, we describe how some existing forward recovery methods satisfy the correctness conditions for recovery. 8.3.1. <p> By the isolation property, the intermediate results of a transaction are not visible to other transactions. This implies no operation of a transaction is dependent on an operation of another uncommitted transaction, satisfying the dependence condition. 8.3.2. Atomic Abstract Data Types Various works <ref> [28, 77, 86] </ref> have exploited semantic information to increase the level of concurrency among transactions and optimize failure recovery. We will take Weihl's work [86, 87] as a representative one. <p> Atomic Abstract Data Types Various works [28, 77, 86] have exploited semantic information to increase the level of concurrency among transactions and optimize failure recovery. We will take Weihl's work <ref> [86, 87] </ref> as a representative one. In [87], applications are implemented in terms of abstract data types and semantics of abstract data types are used to define two notions of commutativity between sequences of transitions.
Reference: [87] <author> Weihl, William E., </author> <title> ``Commutativity-based Concurrency Control for Abstract Data Types,'' </title> <journal> IEEE Transactions on Computers C-37(12) pp. </journal> <month> 1488-1505 (December </month> <year> 1988). </year>
Reference-contexts: Even in implementations of transactions, recovery methods have been known to affect concurrency control [6, 31, 88]. In more general applications, we believe the right approach is to allow general 14 synchronization and yet provide appropriate mechanisms to control recovery. While some work <ref> [7, 28, 35, 77, 87] </ref> extends the traditional transaction concept by exploiting semantic knowledge to provide more concurrency, we have started from a general synchronization environment and made it reliable. There is a limitation on extending transactions because all transactions must eventually satisfy the serializability or recoverability criteria. <p> There is a limitation on extending transactions because all transactions must eventually satisfy the serializability or recoverability criteria. This is inappropriate for many distributed applications that usually involve non-serializable and non-recoverable operations as will be discussed in Section 3.4. Atomic abstract data types <ref> [77, 87] </ref> require transactions to be serializable after non-dependent operations are commuted. In atomic abstract data types, as in ACTA [20], the burden of analyzing commutativity (or dependency) between operations is placed on the programmers. Optimistic approaches [35, 49] also require committed transactions to be serializable. <p> The behavior of each process can be programmed independently without considering how other concurrent processes might be hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh 1 Any non-sequential behavior of a transaction is internal and is not observable by external processes. This is true even in "non-serializable" transactions <ref> [46, 87] </ref> if we commute non-dependent operations. 15 affected. Allowable interactions between processes are defined separately in a composite specification for the group of processes. We allow groups of processes to be hierarchically composed. <p> Recovering to an intermediate state requires analysis of actual dependencies from the partial-order semantics of the distributed application. We can determine actual dependency more accurately than in transaction management which can only determine dependency conservatively based on conflict tables, defining either commutativity <ref> [87] </ref> or recoverability [6]. Furthermore, by analyzing the application semantics, we can also preserve consistency for non-rollback recovery operations, such as corrective operations, compensation and reset. The above examples show the importance of dealing with the partial-order semantics of many distributed applications. <p> On the other hand, all operations that commute can always be permuted. Thus, permutativity property subsumes commutativity property that is described in <ref> [87] </ref>. 64 The notion of execution sequence is similar to history in [31, 45, 64, 87]. We however use execution sequences only for reasoning about the properties of the augmented FSM's that will guarantee correctness of recovery. <p> On the other hand, all operations that commute can always be permuted. Thus, permutativity property subsumes commutativity property that is described in [87]. 64 The notion of execution sequence is similar to history in <ref> [31, 45, 64, 87] </ref>. We however use execution sequences only for reasoning about the properties of the augmented FSM's that will guarantee correctness of recovery. <p> The notion of dependence in <ref> [45, 64, 87] </ref> is based not only on the ordering in a history log (which can be incidental) but also on a separate synchronization arbitrator, such as a conflict table. <p> Atomic Abstract Data Types Various works [28, 77, 86] have exploited semantic information to increase the level of concurrency among transactions and optimize failure recovery. We will take Weihl's work <ref> [86, 87] </ref> as a representative one. In [87], applications are implemented in terms of abstract data types and semantics of abstract data types are used to define two notions of commutativity between sequences of transitions. <p> Atomic Abstract Data Types Various works [28, 77, 86] have exploited semantic information to increase the level of concurrency among transactions and optimize failure recovery. We will take Weihl's work [86, 87] as a representative one. In <ref> [87] </ref>, applications are implemented in terms of abstract data types and semantics of abstract data types are used to define two notions of commutativity between sequences of transitions. <p> The conditions for recovery and reconfiguration enable us to improve efficiency by allowing permuting and substituting transitions whenever permitted by the behavior specification. By analyzing specific product states in the (potential) behavior of an application, our method computes more accurate dependencies than other work on transactions <ref> [28, 77, 87] </ref> which specifies only commutativity of operations for all product states. Using more accurate dependencies reduces the "cascade" effect during recovery, thus reducing wastage of computation. We presented an algorithm for computing necessary precedence automatically from a restricted product machine. <p> Using more accurate dependencies reduces the "cascade" effect during recovery, thus reducing wastage of computation. We presented an algorithm for computing necessary precedence automatically from a restricted product machine. Besides computing accurate dependencies, this algorithm frees software designers from analyzing dependencies and commutativity between operations as in other work <ref> [20, 77, 87] </ref>. To check for some causes of failure, we presented algorithms for detecting synchronization problems such as deadlock, possible livelock and starvation. We also presented an algorithm for computing recovery paths that preserve consistency.

References-found: 87

