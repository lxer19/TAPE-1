URL: http://http.icsi.berkeley.edu/ftp/global/pub/ai/stolcke/icslp94-mpm.ps.Z
Refering-URL: http://http.icsi.berkeley.edu/ftp/global/pub/ai/stolcke/
Root-URL: http://http.icsi.berkeley.edu
Email: fwooters,stolckeg@icsi.berkeley.edu  
Title: MULTIPLE-PRONUNCIATION LEXICAL MODELING IN A SPEAKER INDEPENDENT SPEECH UNDERSTANDING SYSTEM  
Author: Chuck Wooters Andreas Stolcke 
Address: 1947 Center St. Suite 600, Berkeley, CA 94704, USA  
Affiliation: International Computer Science Institute  
Note: To appear in ICLSP-94  
Abstract: One of the sources of difficulty in speech recognition and understanding is the variability due to alternate pronunciations of words. To address the issue we have investigated the use of multiple-pronunciation models (MPMs) in the decoding stage of a speaker-independent speech understanding system. In this paper we address three important issues regarding MPMs: (a) Model construction: How can MPMs be built from available data without human intervention? (b) Model embedding: How should MPM construction interact with the training of the sub-word unit models on which they are based? (c) Utility: Do they help in speech recognition? Automatic, data-driven MPM construction is accomplished using a structural HMM induction algorithm. The resulting MPMs are trained jointlywith a multi-layer perceptron functioning as a phonetic likelihood estimator. The experiments reported here demonstrate that MPMs can significantly improve speech recognition results over standard single pronunciation models. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> K. F. Lee. </author> <title> Automatic Speech Recognition: The Development of the SPHINX System. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1989. </year>
Reference-contexts: Despite the seemingly obvious advantage of MPMs, there has been conflicting evidence as to whether they can improve the performance of speech recognition systems. Some researchers <ref> [1] </ref> have not shown any improvements in recognition performance through the use of MPMs. Others [2, 3] have demonstrated significant improvements in performance. There are several factors that likely contribute to these conflicting reports. One such factor is the difficulty in constructing the MPMs.
Reference: [2] <author> M. Cohen. </author> <title> Phonological Structures for Speech Recognition. </title> <type> PhD thesis, </type> <institution> University of California, Berkeley, </institution> <year> 1989. </year>
Reference-contexts: Despite the seemingly obvious advantage of MPMs, there has been conflicting evidence as to whether they can improve the performance of speech recognition systems. Some researchers [1] have not shown any improvements in recognition performance through the use of MPMs. Others <ref> [2, 3] </ref> have demonstrated significant improvements in performance. There are several factors that likely contribute to these conflicting reports. One such factor is the difficulty in constructing the MPMs. <p> The improvement found with MPMs over the single pronunciation version is significant at the .01 level. 4.2 Multiple vs. most likely pronunciations The SP lexicon used in the previous comparison was derived from an independent source and held fixed while adapting the other parts of the system. Other research <ref> [2] </ref> suggest that a substantial improvement can be gained by simply selecting the single most likely pronunciation for each word (as opposed to, say, one obtained from a dictionary). Choosing the most likely pronunciation from a training corpus is a simple form of adaptation within the space of SP models.
Reference: [3] <author> C. Wooters. </author> <title> Lexical Modeling in a Speaker Independent Speech Understanding System. </title> <type> PhD thesis, </type> <institution> University of California, Berkeley, </institution> <year> 1993. </year>
Reference-contexts: Despite the seemingly obvious advantage of MPMs, there has been conflicting evidence as to whether they can improve the performance of speech recognition systems. Some researchers [1] have not shown any improvements in recognition performance through the use of MPMs. Others <ref> [2, 3] </ref> have demonstrated significant improvements in performance. There are several factors that likely contribute to these conflicting reports. One such factor is the difficulty in constructing the MPMs. <p> Indeed, we have observed that the best results are obtained by combining the lexicon obtained in the first iteration with the MLP trained in the second iteration. 4 MODEL EVALUATION 4.1 Multiple vs. single pronunciations Previous experiments using the approach described here <ref> [3] </ref> addressed whether multiple-pronunciation modeling in the BeRP system could give improvements over the traditional single-pronunciationHMM word models. This comparison was based on a 2,319 training utterance corpus and a 364 utterance test set. <p> The 3 For this reason it is not meaningful to calculate perplexity for this particular corpus, but in <ref> [3] </ref>, the perplexity of a 227 sentence subset screened for out-of-vocabulary words was estimated as 10.6. Roughly one-third of the sentences in the test set had either out-of-vocabulary words or out-of-grammar word pairs.
Reference: [4] <author> Daniel Jurafsky, Chuck Wooters, Gary Tajchman, Jonathan Segal, Andreas Stolcke, Eric Fosler, and Nelson Morgan. </author> <title> The Berkeley Restaurant Project. These proceedings. 5 The number of pronunciations is computed as the exponential of the entropy of the paths through an HMM, i.e., the `pronunciation perplexity.' </title>
Reference-contexts: Dept. of Defense We have tested our approach within the context of the Berkeley Restaurant Project (BeRP) <ref> [4] </ref>. BeRP is a medium-sized vocabulary, speaker-independent speech understanding system whose domain is knowledge about restaurants in the city of Berkeley. The BeRP system is similar to other spontaneous speech understanding systems that have been developed recently [5, 6]. <p> We are currently studying adaptive approaches that change the prior probabilities of the paths in a word model based on estimates of the speaker's accent type, especially for native vs. non-native speakers <ref> [4] </ref>. More fine-grained synchrony among pronunciation variants is also likely, e.g., whether a speaker generally tends to flap certain stops. Modeling such subword regularities would require revising the straightforward word-based approach.
Reference: [5] <author> P. Price. </author> <title> Evaluation of spoken language systems: The ATIS domain. </title> <booktitle> In Proc. Third DARPA Speech and Language Workshop, </booktitle> <pages> pages 91-95, </pages> <address> Hidden Valey, PA, </address> <month> June </month> <year> 1990. </year>
Reference-contexts: BeRP is a medium-sized vocabulary, speaker-independent speech understanding system whose domain is knowledge about restaurants in the city of Berkeley. The BeRP system is similar to other spontaneous speech understanding systems that have been developed recently <ref> [5, 6] </ref>. One of the distinguishing characteristics of BeRP is that it uses a speech recognizer that combines neural networks and Hidden Markov Models (HMMs). The neural network is a Multilayer Perceptron (MLP) which is used to estimate the acoustic likelihoods for the HMMs [7].
Reference: [6] <author> V. Zue, J. Glass, D. Goodine, H. Leung, M. Phillips, and S. Seneff. </author> <title> The VOYAGER speech understanding system: Preliminary development and evaluation. </title> <booktitle> In Proceedings Int'l Conference on Acoustics Speech and Signal Processing, </booktitle> <pages> pages 73-76, </pages> <address> Albuquerque, New Mexico, </address> <year> 1990. </year>
Reference-contexts: BeRP is a medium-sized vocabulary, speaker-independent speech understanding system whose domain is knowledge about restaurants in the city of Berkeley. The BeRP system is similar to other spontaneous speech understanding systems that have been developed recently <ref> [5, 6] </ref>. One of the distinguishing characteristics of BeRP is that it uses a speech recognizer that combines neural networks and Hidden Markov Models (HMMs). The neural network is a Multilayer Perceptron (MLP) which is used to estimate the acoustic likelihoods for the HMMs [7].
Reference: [7] <author> H. Bourlard and N. Morgan. </author> <title> Connectionist Speech Recognition A Hybrid Approach. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1993. </year>
Reference-contexts: One of the distinguishing characteristics of BeRP is that it uses a speech recognizer that combines neural networks and Hidden Markov Models (HMMs). The neural network is a Multilayer Perceptron (MLP) which is used to estimate the acoustic likelihoods for the HMMs <ref> [7] </ref>. In the next sections we present the details of this approach.
Reference: [8] <author> H. Bourlard and C. J. Wellekens. </author> <title> Links between Markov models and multilayer perceptrons. </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, </journal> <volume> 12(2) </volume> <pages> 1167-1178, </pages> <year> 1990. </year>
Reference-contexts: The two processes of adaptation and reestimation are carried out sequentially and may be iterated in order to further tailor the models to the speech recognizer and the training data. Adaptation. The adaptation procedure begins with a Viterbi <ref> [8] </ref> alignment of the training data to the general word models. During Viterbi alignment, a single path representing one of the alternate pronunciations of a word is chosen for each instance of the word in the training corpus.
Reference: [9] <author> A. Stolcke and S. Omohundro. </author> <title> Best-first model merging for Hidden Markov Model induction. </title> <type> Technical report, </type> <institution> International Computer Science Institute, 1947 Center St., </institution> <address> Suite 600, Berkeley, CA 94704, </address> <year> 1994. </year> <month> TR-94-003. </month>
Reference-contexts: Reestimation. The technique that is used to reestimate the probabilities of each of the paths through an HMM is based on an algorithm for automatically inducing HMM structure from a set of samples <ref> [9] </ref>. The algorithm begins with the construction of an initial HMM that just replicates the data (i.e. the paths representing the alternate pronunciations). Each path contains one state for each of the phonemes in the pronunciation. <p> The prior used is a combination of a term involving the description length (number of bits needed to encode) the model's structure, and a Dirichlet prior over the transitions and emissions <ref> [9] </ref>. as to give the currently best posterior. The parameters of the prior are tunable to determine the degree of generalization; in particular, the algorithm may be used to simply minimize the HMM structure without introducing new pronunciations. <p> Two MP versions were tested: merging without generalization, i.e., the lexicon contained only observed pronunciations, and merging with generalization. The prior parameters, and hence the amount of generalization were not specially tuned for this task; we reused a configuration from a previous experiment involving TIMIT data <ref> [9] </ref>. The embedded training procedure was identical except for the use of different word models in each alignment step. <p> From a linguistic perspective, the automated building of MPMs can be seen as a form of phonological learning; as such, it should be compared to alternative learning approaches, such as inducing pronunciations based on local phoneme contexts [12, 13]. Experiments on isolated TIMIT word pronunciations <ref> [9] </ref> have shown a significant improvement (measured in phone perplexity) when using the merging algorithm to infer new pronunciations from observed ones.
Reference: [10] <author> L. E. Baum, T. Pitrie, G. Soules, and N. Weiss. </author> <title> A maximization technique occurring in the statistical analysis of probabilistic functions in Markov chains. </title> <journal> The Annals of Mathematical Statistics, </journal> <volume> 41(1) </volume> <pages> 164-171, </pages> <year> 1970. </year>
Reference-contexts: Once the HMM structure with a (locally) maximal posterior is found, the HMM parameters are set using standard maximum-likelihood estimation <ref> [10] </ref>. One of the features of the HMM merging algorithm is that it can induce an HMM that is capable of generalizing to previously unseen pronunciations.
Reference: [11] <author> A. P. Dempster, N. M. Laird, and D. B. Rubin. </author> <title> Maximum likelihood from incomplete data via the EM algorithm. </title> <journal> Journal of the Royal Statistical Society, Series B, </journal> <volume> 34 </volume> <pages> 1-38, </pages> <year> 1977. </year>
Reference-contexts: The MLP training uses cross-validation to avoid overfitting; 10% of the total training corpus are typically set aside for this purpose. We can view this iterative embedded training procedure as an approximate version of the Expectation Maximization (EM) algorithm commonly used for maximum-likelihood estimation with incomplete data <ref> [11] </ref>. The Viterbi alignment step approximates the E-step, estimating the unobserved labels at each time frame, whereas the MLP training and word model induction realize the M-step, i.e., maximizing model parameters relative to the estimates of the E-step.
Reference: [12] <author> Francine R. Chen. </author> <title> Identification of contextual factors for pronunciation networks. </title> <booktitle> In Proceedings IEEE Conference on Acoustics, Speech and Signal Processing, </booktitle> <volume> volume 2, </volume> <pages> pages 753-756, </pages> <address> Albu-querque, NM, </address> <month> April </month> <year> 1990. </year>
Reference-contexts: From a linguistic perspective, the automated building of MPMs can be seen as a form of phonological learning; as such, it should be compared to alternative learning approaches, such as inducing pronunciations based on local phoneme contexts <ref> [12, 13] </ref>. Experiments on isolated TIMIT word pronunciations [9] have shown a significant improvement (measured in phone perplexity) when using the merging algorithm to infer new pronunciations from observed ones.
Reference: [13] <author> Michael D. Riley. </author> <title> A statistical model for generating pronunciation networks. </title> <booktitle> In Proceedings IEEE Conference on Acoustics, Speech and Signal Processing, </booktitle> <volume> volume 2, </volume> <pages> pages 737-740, </pages> <address> Toronto, </address> <month> May </month> <year> 1991. </year>
Reference-contexts: From a linguistic perspective, the automated building of MPMs can be seen as a form of phonological learning; as such, it should be compared to alternative learning approaches, such as inducing pronunciations based on local phoneme contexts <ref> [12, 13] </ref>. Experiments on isolated TIMIT word pronunciations [9] have shown a significant improvement (measured in phone perplexity) when using the merging algorithm to infer new pronunciations from observed ones.
References-found: 13

