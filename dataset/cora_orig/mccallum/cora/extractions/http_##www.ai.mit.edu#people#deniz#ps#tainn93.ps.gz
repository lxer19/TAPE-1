URL: http://www.ai.mit.edu/people/deniz/ps/tainn93.ps.gz
Refering-URL: http://www.ai.mit.edu/people/deniz/papers.html
Root-URL: 
Email: email: deniz@ai.mit.edu, mdlm@ai.mit.edu  
Title: Dynamic Hill Climbing: Overcoming the limita- tions of optimization techniques  
Author: Deniz Yuret and Michael de la Maza 
Address: Cambridge, MA 02139, USA.  
Affiliation: Numinous Noetics Group, Artificial Intelligence Laboratory, Massachusetts Institute of Technology,  
Abstract: This paper describes a novel search algorithm, called dynamic hill climbing, that borrows ideas from genetic algorithms and hill climbing techniques. Unlike both genetic and hill climbing algorithms, dynamic hill climbing has the ability to dynamically change its coordinate frame during the course of an optimization. Furthermore, the algorithm moves from a coarse-grained search to a fine-grained search of the function space by changing its mutation rate and uses a diversity-based distance metric to ensure that it searches new regions of the space. Dynamic hill climbing is empirically compared to a traditional genetic algorithm using De Jong's well-known five function test suite [4] and is shown to vastly surpass the performance of the genetic algorithm, often finding better solutions using only 1% as many function evaluations. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. Ackley. </author> <title> A Connectionist Machine for Genetic Hillclimbing. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, </address> <year> 1987. </year>
Reference-contexts: 1 Introduction Genetic algorithms [13, 10] have been applied to a wide variety of optimization problems ranging from the traveling salesman problem [12, 16] to protein structure [14, 6] to horse racing [5]. Likewise, hill climbing techniques have been used to partition graphs <ref> [1] </ref>, to learn behaviors in robots [3], and to construct Steiner systems [9]. In this paper we combine the strengths of these two algorithms into a single system that outperforms the traditional genetic algorithm on De Jong's test suite [4]. <p> Hill climbing techniques, such as gradient descent, use local information about a search space to find optima. For unimodal functions, hill climbing techniques easily outperform most other methods, but for more complicated functions hill climbing tech-niques are apt to get stuck in local optima. Ackley <ref> [1] </ref> combines genetic algorithms with hill climbing to produce an algorithm called Stochastic Iterated Genetic Hillclimbing (SIGH). Although the motivations behind our algorithm and SIGH are similar, the algorithms themselves are quite different.
Reference: [2] <author> T. Back and F. Hoffmeister. </author> <title> A user's guide to GENEsYs 1.0. Software package documentation, </title> <year> 1992. </year>
Reference-contexts: Each graph shows the best individual averaged over ten runs. The global optimum of the first four functions is 0 and the global optimum of the fifth function is approximately 1. The GENEsYs 1.0 package <ref> [2] </ref> was used to implement the traditional genetic algorithm, while the dynamic hill climbing algorithm was implemented using a custom C program. (A) Sphere function (B) Rosenbrock's saddle function (C) Step function (D) Quartic function with noise (E) Shekel's foxholes function (F) Mean number of function evaluations for dynamic hill climbing
Reference: [3] <author> P. David and B. Kuipers. </author> <title> Learning hill-climbing functions as a strategy for generating behaviors in mobile robots. </title> <type> Technical Report AI90-137, </type> <institution> University of Texas at Austin, </institution> <year> 1990. </year>
Reference-contexts: 1 Introduction Genetic algorithms [13, 10] have been applied to a wide variety of optimization problems ranging from the traveling salesman problem [12, 16] to protein structure [14, 6] to horse racing [5]. Likewise, hill climbing techniques have been used to partition graphs [1], to learn behaviors in robots <ref> [3] </ref>, and to construct Steiner systems [9]. In this paper we combine the strengths of these two algorithms into a single system that outperforms the traditional genetic algorithm on De Jong's test suite [4].
Reference: [4] <author> K. De Jong. </author> <title> Analysis of the Behavior of a Class of Genetic Adaptive Systems. </title> <type> PhD thesis, </type> <institution> University of Michigan, </institution> <address> Ann Arbor, </address> <year> 1975. </year>
Reference-contexts: Likewise, hill climbing techniques have been used to partition graphs [1], to learn behaviors in robots [3], and to construct Steiner systems [9]. In this paper we combine the strengths of these two algorithms into a single system that outperforms the traditional genetic algorithm on De Jong's test suite <ref> [4] </ref>. This algorithm introduces two new ideas, dynamic coordinate change and exploitation of local minima, that, to the best of our knowledge, have not been used in other search algorithms. Genetic algorithms are patterned after biological systems. They maintain a population of individuals that undergo crossover and mutation.
Reference: [5] <author> M. de la Maza. </author> <title> A SEAGUL visits the race track. </title> <booktitle> In Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <pages> pages 208-212, </pages> <year> 1989. </year>
Reference-contexts: 1 Introduction Genetic algorithms [13, 10] have been applied to a wide variety of optimization problems ranging from the traveling salesman problem [12, 16] to protein structure [14, 6] to horse racing <ref> [5] </ref>. Likewise, hill climbing techniques have been used to partition graphs [1], to learn behaviors in robots [3], and to construct Steiner systems [9].
Reference: [6] <author> M. de la Maza and B. Tidor. </author> <title> Increased flexibility in genetic algorithms: The use of variable Boltzmann selective pressure to control propagation. </title> <booktitle> In Proceedings of the ORCA CSTS Conference: Computer Science and Operations Research: New Developments in Their Interfaces, </booktitle> <pages> pages 425-440, </pages> <year> 1992. </year>
Reference-contexts: 1 Introduction Genetic algorithms [13, 10] have been applied to a wide variety of optimization problems ranging from the traveling salesman problem [12, 16] to protein structure <ref> [14, 6] </ref> to horse racing [5]. Likewise, hill climbing techniques have been used to partition graphs [1], to learn behaviors in robots [3], and to construct Steiner systems [9].
Reference: [7] <author> L. Eshelman. </author> <title> The CHC adaptive search algorithm: How to have safe search when engaging in nontraditional genetic recombination. </title> <booktitle> In Foundations of Genetic Algorithms, </booktitle> <pages> pages 265-283, </pages> <year> 1991. </year>
Reference-contexts: We repeated these experiments with our algorithm and in all the functions except quartic, dynamic hill climbing found the global optimum. In quartic the best individual had a fitness of -0.72559. Eshelman <ref> [7] </ref> introduces a genetic algorithm, called CHC, that has a highly conservative selection scheme and a highly disruptive recombination operator.
Reference: [8] <author> L. J. Eshelman, R. A. Caruana, and J. D. Schaffer. </author> <title> Biases in the crossover landscape. </title> <booktitle> In Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <pages> pages 10-19, </pages> <year> 1989. </year>
Reference: [9] <author> P. Gibbons and R. Mathon. </author> <title> The use of hill-climbing to construct orthogonal Steiner triple systems. </title> <type> Technical Report 263/92, </type> <institution> University of Toronto, </institution> <year> 1992. </year>
Reference-contexts: Likewise, hill climbing techniques have been used to partition graphs [1], to learn behaviors in robots [3], and to construct Steiner systems <ref> [9] </ref>. In this paper we combine the strengths of these two algorithms into a single system that outperforms the traditional genetic algorithm on De Jong's test suite [4].
Reference: [10] <author> D. Goldberg. </author> <title> Genetic Algorithms in Search, Optimization and Machine Learning. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1989. </year>
Reference-contexts: 1 Introduction Genetic algorithms <ref> [13, 10] </ref> have been applied to a wide variety of optimization problems ranging from the traveling salesman problem [12, 16] to protein structure [14, 6] to horse racing [5].
Reference: [11] <author> D. E. Goldberg. </author> <title> An investigation of niche and species formation in genetic function optimization. </title> <booktitle> In Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <pages> pages 42-50, </pages> <year> 1989. </year>
Reference-contexts: This is an idea that has been explored by several researchers <ref> [17, 11] </ref>. In the standard genetic algorithm techniques, whenever one individual reaches a local optimum, its chance of survival surpasses the others, it stays alive too many generations, and eventually the rest of the population converges to that single point.
Reference: [12] <author> J. Grefenstette, R. Gopal, B. Rosmaita, and D. van Gucht. </author> <title> Genetic algorithms for the traveling salesman problem. </title> <booktitle> In Proceedings of an International Conference on Genetic Algorithms and their Applications, </booktitle> <pages> pages 160-165, </pages> <year> 1985. </year>
Reference-contexts: 1 Introduction Genetic algorithms [13, 10] have been applied to a wide variety of optimization problems ranging from the traveling salesman problem <ref> [12, 16] </ref> to protein structure [14, 6] to horse racing [5]. Likewise, hill climbing techniques have been used to partition graphs [1], to learn behaviors in robots [3], and to construct Steiner systems [9].
Reference: [13] <author> J.H. Holland. </author> <title> Adaptation in Natural and Artificial Systems. </title> <publisher> University of Michigan Press, </publisher> <address> Ann Arbor, </address> <year> 1975. </year>
Reference-contexts: 1 Introduction Genetic algorithms <ref> [13, 10] </ref> have been applied to a wide variety of optimization problems ranging from the traveling salesman problem [12, 16] to protein structure [14, 6] to horse racing [5].
Reference: [14] <author> R.S. Judson. </author> <title> Teaching polymers to fold. </title> <journal> Journal of Physical Chemistry, </journal> <volume> 96 </volume> <pages> 10102-10104, </pages> <year> 1992. </year>
Reference-contexts: 1 Introduction Genetic algorithms [13, 10] have been applied to a wide variety of optimization problems ranging from the traveling salesman problem [12, 16] to protein structure <ref> [14, 6] </ref> to horse racing [5]. Likewise, hill climbing techniques have been used to partition graphs [1], to learn behaviors in robots [3], and to construct Steiner systems [9].
Reference: [15] <author> D. Whitley. </author> <title> The GENITOR algorithm and selection pressure: Why rank-based allocation of reproductive trials is best. </title> <booktitle> In Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <pages> pages 116-121, </pages> <year> 1989. </year>
Reference-contexts: With the exception of Rosenbrock's saddle function, dynamic hill climbing requires only 4% to 22% as many function evaluations as this highly tuned genetic algorithm. Whitley <ref> [15] </ref> describes GENITOR, a genetic algorithm that uses rank based selection and argues that it outperforms a traditional genetic algorithm. The Shekel's foxholes function is used to compare the GENITOR algorithm to the traditional genetic algorithm.
Reference: [16] <author> D. Whitley, T. Starkweather, and D'Ann Fuquay. </author> <title> Scheduling problems and traveling salesmen: The genetic edge recombination operator. </title> <booktitle> In Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <pages> pages 133-140, </pages> <year> 1989. </year>
Reference-contexts: 1 Introduction Genetic algorithms [13, 10] have been applied to a wide variety of optimization problems ranging from the traveling salesman problem <ref> [12, 16] </ref> to protein structure [14, 6] to horse racing [5]. Likewise, hill climbing techniques have been used to partition graphs [1], to learn behaviors in robots [3], and to construct Steiner systems [9].
Reference: [17] <author> P.H. Winston. </author> <booktitle> Artificial Intelligence. </booktitle> <publisher> Addison-Wesley Publishing Company, </publisher> <address> Reading, MA, third edition, </address> <year> 1992. </year>
Reference-contexts: The main reasons for the failure of the hill climber are explained in <ref> [17] </ref>. The algorithm can get stuck in a local optimum (the foothill problem), it can get stuck in mostly flat surfaces with few sharp peaks (the plateau problem), or it can get stuck because the direction of ascent is not within our directions of motion (the ridge problem). <p> This is an idea that has been explored by several researchers <ref> [17, 11] </ref>. In the standard genetic algorithm techniques, whenever one individual reaches a local optimum, its chance of survival surpasses the others, it stays alive too many generations, and eventually the rest of the population converges to that single point.
Reference: [18] <author> A. Wright. </author> <title> Genetic algorithms for real parameter optimization. </title> <booktitle> In Foundations of Genetic Algorithms, </booktitle> <pages> pages 205-218, </pages> <year> 1991. </year>
Reference-contexts: Figure 1 shows that dynamic hill climbing produces an individual with a fitness of approximately 1, which is the global optimum, in fewer than 1100 trials, hence outperforming the GENITOR algorithm. Wright <ref> [18] </ref> studies genetic algorithms that use real parameters instead of binary strings. He runs the genetic algorithm for 1000 trials and reports the fitness of the best individual over 1000 runs.
References-found: 18

