URL: http://www.informatik.hu-berlin.de/~cbr-ws/GWCBR98/PAPERS/Lenz.ps.gz
Refering-URL: http://www.informatik.hu-berlin.de/~cbr-ws/GWCBR98/program.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: lenz@informatik.hu-berlin.de  
Title: Textual CBR and Information Retrieval A Comparison  
Author: Mario Lenz 
Address: Axel-Springer-Str. 54a, D-10099 Berlin  
Affiliation: Dept. of Computer Science, Humboldt University Berlin  
Abstract: In recent years, quite a number of projects started to apply case-based reasoning technology to textual documents instead of highly structured cases. For this the term Textual CBR has been coined. In this paper, we give an overview over the main ideas of Textual CBR and compare it with Information Retrieval techniques. We also present some preliminary results obtained from three projects performed which further demonstrate major advantages of Textual CBR. Keywords: Textual case-based reasoning, document management, knowledge acquisition.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Burke, K. Hammond, V. Kulyukin, S. Lytinen, N. Tomuro, and S. </author> <title> Schoenberg. Question Answering from Frequently Asked Question Files. </title> <journal> AI Magazine, </journal> <pages> pages 57-66, </pages> <year> 1997. </year>
Reference-contexts: For details, the reader is referred to the corresponding publications. 4.2 Related Work As mentioned before, some other projects addressed topics concerned with Textual CBR in recent years. In the following we can only list some of these. 4.2.1 FAQFinder The FAQFinder project <ref> [1] </ref>, too, tries to apply CBR technology in combination with other techniques to document management. In particular, FAQFinder's goal is to answer natural language questions by retrieving these from frequently asked questions (FAQ) files from USENET news groups FAQs.
Reference: [2] <author> J. J. Daniels and E. L. Rissland. </author> <title> What You Saw Is What You Want: Using Cases to Seed Information. </title> <booktitle> In Leake and Plaza [4], </booktitle> <pages> pages 325-336. </pages>
Reference-contexts: This would not be possible in the scenario of FAQFinder where the semantic base (i.e. WordNet) is the same for all news group topics. 4.2.2 SPIRE SPIRE uses a completely different approach for dealing with textual cases <ref> [2] </ref>.
Reference: [3] <author> M. Kunze and A. Hubner. </author> <title> CBR on Semi-structured Documents: </title> <booktitle> The ExperienceBook and the FAllQ Project (in this volume). </booktitle> <year> 1998. </year>
Reference-contexts: Often, these features may cover more than a single keyword, an example might be the expression Customer Administration Module which represents a certain functionality in one of our project applications <ref> [3, 5] </ref>. * As a Textual CBR system is domain-specific, the Ambiguity Problem is avoided to a great extend. * Again by carefully analyzing the domain under consideration, a similarity measure can be constructed which goes beyond term frequency weighting, e.g. by considering a domain specific thesaurus, ontologies present in the <p> to derive similarities between words which are part of each other. 4 Discussion 4.1 Results from Performed Projects In recent months, we performed three major projects concerned with Textual CBR: * the FAllQ project [5] for document management and hotline support in a telecommunica tions company; * the ExperienceBook project <ref> [3] </ref> providing support for UNIX system administrators; * the CBR-Answers project (http://www.informatik.hu-berlin.de/~cbr-ws/CBR-Answers) serving as a basis for a hotline support system developed for Siemens SIMATIC Customer Sup port and dealing with German documents. In these projects, we employed the methods described in this article for building domain-specific Textual CBR applications.
Reference: [4] <editor> D. B. Leake and E. Plaza, editors. </editor> <booktitle> Case-Based Reasoning Research and Development, Proc. ICCBR-97, Lecture Notes in Artificial Intelligence, </booktitle> <volume> 1266. </volume> <publisher> Springer Verlag, </publisher> <year> 1997. </year>
Reference: [5] <author> M. Lenz and H.-D. Burkhard. </author> <title> CBR for Document Retrieval The FAllQ Project. </title> <booktitle> In Leake and Plaza [4], </booktitle> <pages> pages 84-93. </pages>
Reference-contexts: Often, these features may cover more than a single keyword, an example might be the expression Customer Administration Module which represents a certain functionality in one of our project applications <ref> [3, 5] </ref>. * As a Textual CBR system is domain-specific, the Ambiguity Problem is avoided to a great extend. * Again by carefully analyzing the domain under consideration, a similarity measure can be constructed which goes beyond term frequency weighting, e.g. by considering a domain specific thesaurus, ontologies present in the <p> That's why, for projects on German texts we used some heuristic procedures to derive similarities between words which are part of each other. 4 Discussion 4.1 Results from Performed Projects In recent months, we performed three major projects concerned with Textual CBR: * the FAllQ project <ref> [5] </ref> for document management and hotline support in a telecommunica tions company; * the ExperienceBook project [3] providing support for UNIX system administrators; * the CBR-Answers project (http://www.informatik.hu-berlin.de/~cbr-ws/CBR-Answers) serving as a basis for a hotline support system developed for Siemens SIMATIC Customer Sup port and dealing with German documents.
Reference: [6] <author> M. M. Richter. </author> <title> The knowledge contained in similarity measures. Invited Talk on the ICCBR-95, </title> <note> 1995. http://wwwagr.informatik.uni-kl.de/~lsa/CBR/Richtericcbr95remarks.html. </note>
Reference-contexts: Since CBR is a knowledge-based technique, building a CBR system explicitly includes a knowledge acquisition process. In terms of the knowledge container model introduced by Richter <ref> [6] </ref>, this includes (a) the collection of cases; (b) the definition of an index vocabulary for cases; (c) the construction of a similarity measure; (d) the specification of adaptation knowledge.
Reference: [7] <author> E. Riloff and W. Lehnert. </author> <title> Information extraction as a basis for high-precision text classification. </title> <journal> ACM Transactions on Information Systems, </journal> <volume> 12(3) </volume> <pages> 296-333, </pages> <year> 1994. </year>
Reference-contexts: Obviously, a better representation for this kind of information is to use attribute-value pairs which, however, have to be obtained from the texts automatically. For this, we applied techniques which originate in the area of Information Extraction (cf. <ref> [7] </ref> for an overview). More precisely, we defined a number of triggers which indicate that a piece of text might contain an expression suitable for an attribute-value based representation. <p> It cannot be used for similarity assessment etc. 4.2.3 Information Extraction Information Extraction (IE) is an area related to Information Retrieval, Machine Learning and others. IE attempts to extract structured knowledge from textual descriptions <ref> [7] </ref>. Several sub-tasks exist which reach from recognizing names, places etc. (Named Entity Recognition) to filling script-like structures from a given story (Scenario Template Extraction). As described in Section 3.1.2, we employed such techniques in order to obtain further case features from the textual descriptions, such as certain attribute values.
Reference: [8] <author> G. Salton and M. McGill. </author> <title> Introduction to Modern Information Retrieval. </title> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <year> 1983. </year>
Reference-contexts: Quite a number of successful IR systems now exist on the market, including search engines for the WWW. While any of these systems has its own characteristics, nearly all implement one of the following two basic models: The Vector Space Model <ref> [8] </ref> encodes the elements of the index vocabulary by means of a large vector.
Reference: [9] <author> H. R. </author> <title> Turtle. Inference Networks for Document Retrieval. </title> <type> PhD thesis, </type> <institution> University of Massa-chusetts Amherst, USA, </institution> <year> 1991. </year>
Reference-contexts: Similarity of documents, finally, is determined by comparing the vectors representing these document, e.g. by calculating the cosine measure. Alternatively, in the Inference Network model <ref> [9] </ref>, documents are represented by certain nodes in a graph which also contains nodes for index terms, query terms etc. These nodes are connected with arcs which are weighted according to observed probabilities in a document collection.
References-found: 9

