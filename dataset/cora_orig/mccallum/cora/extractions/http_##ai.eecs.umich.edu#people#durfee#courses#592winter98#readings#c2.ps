URL: http://ai.eecs.umich.edu/people/durfee/courses/592winter98/readings/c2.ps
Refering-URL: http://ai.eecs.umich.edu/people/durfee/courses/592winter98/index.html
Root-URL: http://www.cs.umich.edu
Title: 2 Multiagent Systems and Societies of Agents Accept a course of action Reject a course
Author: Michael N. Huhns and Larry M. Stephens 
Note: Propose a course of action  
Date: 2.1 Introduction  
Abstract: Agents operate and exist in some environment, which typically is both computational and physical. The environment might be open or closed, and it might or might not contain other agents. Although there are situations where an agent can operate usefully by itself, the increasing interconnection and networking of computers is making such situations rare, and in the usual state of affairs the agent interacts with other agents. Whereas the previous chapter defined the structure and characteristics of an individual agent, the focus of this chapter is on systems with multiple agents. At times, the number of agents may be too numerous to deal with them individually, and it is then more convenient to deal with them collectively, as a society of agents. In this chapter, we will learn how to analyze, describe, and design environments in which agents can operate effectively and interact with each other productively. The environments will provide a computational infrastructure for such interactions to take place. The infrastructure will include protocols for agents to communicate and protocols for agents to interact. Communication protocols enable agents to exchange and understand messages. Interaction protocols enable agents to have conversations, which for our purposes are structured exchanges of messages. As a concrete example of these, a communication protocol might specify that the following types of messages can be exchanged between two agents: 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> John L. Austin. </author> <title> How to do Things with Words. </title> <publisher> Clarendon, Oxford, </publisher> <address> UK, </address> <year> 1962. </year>
Reference-contexts: A popular basis for analyzing human communication is speech act theory <ref> [1, 39] </ref>. Speech act theory views human natural language as actions, such as requests, suggestions, commitments, and replies. For example, when you request something, you are not simply making a statement, but creating the request itself.
Reference: 2. <author> Will Briggs and Diane Cook. </author> <title> Flexible Social Laws. </title> <booktitle> In Proc. 14th IJCAI , 1995. </booktitle>
Reference: 3. <author> Birgit Burmeister, Afsaneh Haddadi, and Kurt Sundermeyer. </author> <title> Generic Configurable Cooperation Protocols for Multi-Agent Systems. </title> <booktitle> In Proceedings of the 3rd European Workshop on Modelling Autonomous Agents in a Multi-Agent World (MAAMAW), </booktitle> <year> 1993. </year>
Reference: 4. <author> Stefan Bussman and Jurgen Muller. </author> <title> A Communication Architecture for Cooperating Agents. </title> <journal> Computers and Artificial Intelligence, </journal> <volume> Vol. 12, No. 1, </volume> <pages> pages 37-53, </pages> <year> 1993. </year>
Reference: 5. <author> Cristiano Castelfranchi. </author> <title> Commitments: From individual intentions to groups and organizations. </title> <booktitle> In Proceedings of the International Conference on Multiagent Systems, </booktitle> <pages> pages 41-48, </pages> <year> 1995. </year>
Reference-contexts: These 2.4 Societies of Agents 35 must be carefully distinguished from internal commitments. Social commitments have been studied by a number of researchers, including [17, 28]. There are a number of definitions in the literature, which add components such as witnesses <ref> [5] </ref> or contexts [41]. Social commitments are a flexible means through which the behavior of autonomous agents is constrained.
Reference: 6. <author> Man Kit Chang. SANP: </author> <title> A Communication Level Protocol for Supporting Machine-to-Machine Negotiation in Organization. </title> <type> MS Thesis, </type> <institution> U. of British Columbia, Vancouver, B.C., Canada, </institution> <year> 1991. </year>
Reference: 7. <author> Rosaria Conte and Cristiano Castelfranchi. </author> <title> Cognitive and Social Action. </title> <publisher> UCL Press, </publisher> <address> London, </address> <year> 1995. </year>
Reference-contexts: Further, economic models of agency, although quite general in principle, are typically limited in practice. This is because the value functions that are tractable essentially reduce an agent to a selfish agent. <ref> [7] </ref> argue that a self-interested agent need not be selfish, because it may have other interests than its immediate personal gain. This is certainly true in many cases when describing humans, and is likely to be a richer assumption for modeling artificial agents in settings that are appropriately complex.
Reference: 8. <author> Daniel D. Corkill, Kevin Q. Gallagher, and Kelly E. Murray. </author> <title> GBB: A Generic Blackboard Development System. </title> <booktitle> In Proc. AAAI-86 , Philadelphia, PA, </booktitle> <pages> pages 1008-1014, </pages> <year> 1986. </year>
Reference: 9. <author> Randall Davis and Reid G. Smith. </author> <title> Negotiation as a Metaphor for Distributed Problem solving. </title> <journal> Artificial Intelligence, </journal> <volume> Vol. 20, No. 1, </volume> <pages> pages 63-109, </pages> <month> January </month> <year> 1983. </year>
Reference-contexts: and award cycles Multiagent planning: planning agents have the responsibility for task assignment Organizational structure: agents have fixed responsibilities for particular tasks. methods are described in the sections that follow. agents 2.3.3 Contract Net Of the above mechanisms, the best known and most widely applied is the contract net protocol <ref> [44, 9] </ref>. The contract net protocol is an interaction protocol for cooperative problem solving among agents. It is modeled on the contracting mechanism 2.3 Agent Interaction Protocols 23 used by businesses to govern the exchange of goods and services.
Reference: 10. <author> Jon Doyle. </author> <title> A Truth Maintenance System. </title> <journal> Artificial Intelligence, </journal> <volume> Vol. 12, No. 3, </volume> <pages> pages 231-272, </pages> <year> 1979. </year>
Reference-contexts: The connections of the economic approaches with human-oriented negotiation and argumentation have not yet been fully worked out. 2.3.6 Multiagent Belief Maintenance A multiagent truth-maintenance system can serve as a detailed example of a high-level interaction among agents. A truth-maintenance system (TMS) <ref> [10] </ref> is designed to ensure the integrity of an agent's knowledge, which should be stable, well-founded, and logically consistent.
Reference: 11. <author> Edmund H. Durfee. </author> <title> Coordination of Distributed Problem Solvers. </title> <publisher> Kluwer, </publisher> <year> 1988. </year>
Reference-contexts: In cases where the agents have similar goals or common problems, as in distributed problem solving (DPS), the objective of the protocols is to maintain globally coherent performance of the agents without violating autonomy, i.e., without explicit global control <ref> [11] </ref>.
Reference: 12. <author> Edmund H. Durfee and Thomas A. Montgomery. </author> <title> A Hierarchical Protocol for Coordinating Multiagent Behaviors. </title> <booktitle> In Proc. AAAI-90, </booktitle> <year> 1990. </year>
Reference: 13. <author> Edmund H. Durfee, Victor R. Lesser, and Daniel D. Corkill. </author> <title> Coherent cooperation among communicating problem solvers. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-36(11):1275-1291, </volume> <year> 1987. </year>
Reference-contexts: Task decomposition might be done spatially, based on the layout of information sources or decision points, or functionally, according to the expertise of available agents. Once tasks are decomposed, they can be distributed according to the following criteria <ref> [13] </ref>: Avoid overloading critical resources Assign tasks to agents with matching capabilities Make an agent with a wide view assign tasks to other agents Assign overlapping responsibilities to agents to achieve coherence Assign highly interdependent tasks to agents in spatial or semantic proximity.
Reference: 14. <author> Adam Farquhar, Richard Fikes, and James Rice. </author> <title> The Ontolingua Server: A tool for Collaborative Ontology Construction. </title> <type> Technical Report KSL-96-26, </type> <institution> Knowledge Systems Laboratory, Stanford University, </institution> <month> September </month> <year> 1996. </year> <note> 2.7 References 41 </note>
Reference-contexts: Ontology editors, such as those developed at Stanford <ref> [14] </ref> and the University of South Carolina [32], are typically frame-based knowledge-representation systems that allow users to define ontologies and their components: classes, instances, relationships, and functions. Figure 2.4 shows an example of such an ontology.
Reference: 15. <author> Tim Finin, Don McKay, and Rich Fritzson. </author> <title> An Overview of KQML: A knowledge query and mnaipulation language. </title> <type> Technical Report, </type> <institution> U. of Maryland CS Department, </institution> <year> 1992. </year>
Reference-contexts: KQML is still a work in progress and its semantics have not been completely defined. Labrou and Finin [31] have recently proposed a new KQML specification that refines the original draft <ref> [15] </ref>. However, there is yet no offical KQML specification that agent builders can rely on. 2.2.7 Knowledge Interchange Format Agents need descriptions of real-world things. The descriptions could be expressed in natural languages, such as English and Japanese, which are capable of describing a wide variety of things and situations.
Reference: 16. <author> S. Fiske and S. E. Taylor. </author> <title> Social Cognition. </title> <publisher> Addison Wesley, </publisher> <address> New York, </address> <year> 1984. </year>
Reference: 17. <author> Les Gasser. </author> <title> Social conceptions of knowledge and action: DAI foundations and open systems semantics. </title> <journal> Artificial Intelligence, </journal> <volume> 47 </volume> <pages> 107-138, </pages> <year> 1991. </year>
Reference-contexts: Social commitments are the commitments of an agent to another agent. These 2.4 Societies of Agents 35 must be carefully distinguished from internal commitments. Social commitments have been studied by a number of researchers, including <ref> [17, 28] </ref>. There are a number of definitions in the literature, which add components such as witnesses [5] or contexts [41]. Social commitments are a flexible means through which the behavior of autonomous agents is constrained.
Reference: 18. <editor> Les Gasser and Michael N. Huhns, editors. </editor> <booktitle> Distributed Artificial Intelligence, Volume II. </booktitle> <publisher> Pitman Publishing, </publisher> <address> London, </address> <year> 1989. </year>
Reference-contexts: The use of intelligent, distributed modules combines all four of these techniques, yielding a distributed artificial intelligence (DAI) approach <ref> [25, 18] </ref>. In accord with this approach, computational agents need to be distributed and embedded throughout the enterprise. The agents could function as intelligent application programs, active information resources, "wrappers" that surround and buffer conventional components, and on-line network services.
Reference: 19. <author> N. Gilbert and J. E. Doran, </author> <title> editors. Simulating Societies: The Computer Simulation of Social Phenomena. </title> <booktitle> In Proceedings of the Symposium on Simulating Societies. </booktitle> <publisher> University College Press, </publisher> <address> London, </address> <year> 1994. </year>
Reference: 20. <editor> N.Gilbert and R.Conte, editors. </editor> <booktitle> Artificial Societies: Computer Simulation of Social Life. </booktitle> <publisher> University College Press, </publisher> <address> London, </address> <year> 1995. </year>
Reference: 21. <author> Afsaneh Haddadi. </author> <title> Towards a Pragmatic Theory of Interactions. </title> <booktitle> In Proc. International Conference on MultiAgent Systems (ICMAS), </booktitle> <address> San Francisco, </address> <year> 1995. </year>
Reference-contexts: This clarifies the conditions of satisfaction for different kinds of messages. To provide a flavor of this approach, we show in the following example how the commitments that an agent might make as part of a negotiation are formalized <ref> [21] </ref>: 8x (x 6= y) ^ :(P recommit a y x ) ^ (Goal y Eventually (Achieves y )) ^ (W illing y ) () (Intend y Eventually (Achieves y )) This rule states that an agent forms and maintains its commitment to achieve individually iff (1) it has not precommitted
Reference: 22. <author> Peter Haddawy. </author> <title> Believing change and changing belief. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics Special Issue on Higher-Order Uncertainty, </journal> <volume> 26(5), </volume> <year> 1996. </year>
Reference-contexts: One of the oldest applications of economic rationality is in decision-theoretic planning, which models the costs and effects of actions quantitatively and probabilistically. For many applications, where the probabilities can be estimated reliably, this leads to highly effective plans of actions <ref> [24, 22] </ref>. The need to maximize preferences essentially requires that there be a scalar representation for all the true preferences of an agent. In other words, all of the preferences must be reduced to a single scalar that can be compared effectively with other scalars.
Reference: 23. <author> Carl Hewitt. </author> <title> Open Information Systems Semantics for Distributed Artificial Intelligence. </title> <journal> Artificial Intelligence, </journal> <volume> Vol. 47, </volume> <pages> pages 79-106, </pages> <year> 1991. </year>
Reference: 24. <author> Eric Horvitz and Geoffrey Rutledge. </author> <title> Time-dependent utility and action under uncertainty. </title> <booktitle> In Proceedings of the 7th Conference on Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 151-158, </pages> <year> 1991. </year>
Reference-contexts: One of the oldest applications of economic rationality is in decision-theoretic planning, which models the costs and effects of actions quantitatively and probabilistically. For many applications, where the probabilities can be estimated reliably, this leads to highly effective plans of actions <ref> [24, 22] </ref>. The need to maximize preferences essentially requires that there be a scalar representation for all the true preferences of an agent. In other words, all of the preferences must be reduced to a single scalar that can be compared effectively with other scalars.
Reference: 25. <author> M. N. Huhns, U. Mukhopadhyay, L. M. Stephens, and R. D. Bonnell. </author> <title> DAI for Document Retrieval: The MINDS Project. </title> <editor> In M. N. Huhns, editor, </editor> <booktitle> Distributed Artificial Intelligence. </booktitle> <publisher> Pittman, </publisher> <address> London, </address> <year> 1987. </year>
Reference-contexts: The use of intelligent, distributed modules combines all four of these techniques, yielding a distributed artificial intelligence (DAI) approach <ref> [25, 18] </ref>. In accord with this approach, computational agents need to be distributed and embedded throughout the enterprise. The agents could function as intelligent application programs, active information resources, "wrappers" that surround and buffer conventional components, and on-line network services.
Reference: 26. <author> Michael N. Huhns and Munindar P. Singh. </author> <title> A Mediated Approach to Open, Large-Scale Information Management. </title> <booktitle> In Proc. IEEE Int. Phoenix Conf. on Computers and Communications, </booktitle> <year> 1995. </year>
Reference: 27. <author> Michael N. Huhns and David M. Bridgeland. </author> <title> Multiagent Truth Maintenance. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> Vol. 21, No. 6, </volume> <pages> pages 1437-1445, </pages> <month> December </month> <year> 1991. </year>
Reference-contexts: However, it is important for a group of agents to be able to assess and maintain the integrity of communicated information, as well as of their own knowledge. A multiagent TMS can provide this integrity <ref> [27] </ref>. We consider a modified justification-based TMS, in which every datum has a set of justifications and an associated status of INTERNAL (believed, because of a valid local justification), EXTERNAL (believed, because another agent asserted it), or OUT (disbelieved).
Reference: 28. <author> N. R. Jennings. </author> <title> Commitments and conventions: The foundation of coordination in multi-agent systems. </title> <journal> The Knowledge Engineering Review , 2(3) </journal> <pages> 223-250, </pages> <year> 1993. </year>
Reference-contexts: Social commitments are the commitments of an agent to another agent. These 2.4 Societies of Agents 35 must be carefully distinguished from internal commitments. Social commitments have been studied by a number of researchers, including <ref> [17, 28] </ref>. There are a number of definitions in the literature, which add components such as witnesses [5] or contexts [41]. Social commitments are a flexible means through which the behavior of autonomous agents is constrained.
Reference: 29. <author> Nick R. Jennings. </author> <title> Coordination Techniques for distributed Artificial Intelligence. </title> <editor> In G. M. P. O'Hare and N. R. Jennings, editors, </editor> <booktitle> Foundations of Distributed Artificial Intelligence, </booktitle> <pages> pages 187-210. </pages> <publisher> John Wiley & Sons, Inc., </publisher> <address> New York, </address> <year> 1996. </year>
Reference-contexts: Determining the approach for each of the phases is a matter of system design. While the distributed goal search formalism has been used frequently to characterize both global and local problems, the key agent structures are commitment and convention <ref> [29] </ref>. Commitments are viewed as pledges to undertake a specified course of action, while conventions provide a means of managing commitments in changing circumstances.
Reference: 30. <author> R. Kakehi and M. Tokoro. </author> <title> A Negotiation Protocol for Conflict Resolution in Multi-Agent Environments. </title> <booktitle> In Proc. </booktitle> <pages> ICICIS , pages 185-196, </pages> <year> 1993. </year>
Reference: 31. <author> Yannis Labrou and Tim Finin. </author> <title> A Semantics approach for KQML|a general purpose communication language for software agents. </title> <booktitle> In Proc. Int. Conf on Information and Knowledge Management , 1994. </booktitle>
Reference-contexts: In the advertise example above, if Agent2 sent the message to a facilator agent, then other agents could query the facilitator to find out about Agent2's capabilities. KQML is still a work in progress and its semantics have not been completely defined. Labrou and Finin <ref> [31] </ref> have recently proposed a new KQML specification that refines the original draft [15]. However, there is yet no offical KQML specification that agent builders can rely on. 2.2.7 Knowledge Interchange Format Agents need descriptions of real-world things.
Reference: 32. <author> Kuha Mahalingam and Michael N. Huhns. </author> <title> An Ontology Tool for Distributed Information Environments. </title> <booktitle> IEEE Computer , 30(6) </booktitle> <pages> 80-83, </pages> <month> June </month> <year> 1997. </year>
Reference-contexts: Ontology editors, such as those developed at Stanford [14] and the University of South Carolina <ref> [32] </ref>, are typically frame-based knowledge-representation systems that allow users to define ontologies and their components: classes, instances, relationships, and functions. Figure 2.4 shows an example of such an ontology.
Reference: 33. <author> Robin Milner. </author> <title> Elements of Interaction. </title> <journal> CACM , Vol. </journal> <volume> 36, No. 1, </volume> <pages> pages 78-89, </pages> <year> 1993. </year>
Reference: 34. <author> Yoram Moses and Moshe Tenenholtz. </author> <title> On Computational Aspects of Artificial Social Systems. </title> <booktitle> In Proc. 11th DAI Workshop, </booktitle> <address> Glen Arbor, MI, </address> <year> 1992. </year> <title> 42 Multiagent Systems and Societies of Agents </title>
Reference-contexts: Each agent is required to do its share to achieve the common goal by the group itself or a subgroup. Each agent adopts a request to do its share. Beyond social dependencies, social laws may govern the behaviors of large numbers of agents in a society. See <ref> [34] </ref> for a treatment of this concept. 36 Multiagent Systems and Societies of Agents 2.5 Conclusions This chapter described elements of a computational environment that are needed for the interaction of multiple software agents.
Reference: 35. <author> R. Neches, R. Fikes, T. Finin, R. Gruber, R. Patil, T. Senator, and W. Swartout. </author> <title> Enabling technology for knowledge sharing. </title> <journal> AI Magazine, </journal> <volume> 12(3) </volume> <pages> 36-56, </pages> <month> Fall </month> <year> 1991. </year>
Reference-contexts: KQML assumes asynchronous communications; the fields :reply-with from a sender and :in-reply-to from a responding agent link an outgoing message with an expected response. KQML is part of a broad research effort to develop a methodology for distributing information among different systems <ref> [35] </ref>. One part of the effort involves defining the Knowledge Interchange Format (KIF), a formal syntax for representing knowledge. Described in the next section, KIF is largely based on first-order predicate calculus.
Reference: 36. <author> Jeffrey S. Rosenschein and Gilad Zlotkin. </author> <title> Rules of Encounter. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1994. </year>
Reference-contexts: Distribution: the mechanism should not require a central decision maker. Symmetry: the mechanism should not be biased against any agent for arbitrary or inappropriate reasons. An articulate and entertaining treatment of these concepts is found in <ref> [36] </ref>. In particular, three types of environments have been identified: worth-oriented domains, state-oriented domains, and task-oriented domains.
Reference: 37. <author> Jeffrey S. Rosenschein and Gilad Zlotkin. </author> <title> Designing conventions for automated negotiation. </title> <journal> AI Magazine, </journal> <pages> pages 29-46, </pages> <year> 1994. </year>
Reference-contexts: Interaction protocols govern the exchange of a series of messages among agents|a conversation. Several interaction protocols have been devised for systems of agents. In cases where the agents have conflicting goals or are simply self-interested, the objective of the protocols is to maximize the payoffs (utilities) of the agents <ref> [37] </ref>. In cases where the agents have similar goals or common problems, as in distributed problem solving (DPS), the objective of the protocols is to maintain globally coherent performance of the agents without violating autonomy, i.e., without explicit global control [11]. <p> The second approach is based on an assumption that the agents are economically rational. Further, the set of agents must be small, they must have a common language and common problem abstraction, and they must reach a common solution. Under these assumptions, Rosenschein and Zlotkin <ref> [37] </ref> developed a unified negotiation protocol. Agents that follow this protocol create a deal, that is, a joint plan between the agents that would satisfy all of their goals.
Reference: 38. <author> Stuart J. Russell and Peter Norvig. </author> <title> Artificial Intelligence: A Modern Approach. </title> <publisher> Prentice Hall, </publisher> <address> Upper Saddle River, NJ, </address> <year> 1995. </year>
Reference-contexts: These generalize the presentation in <ref> [38] </ref>. 2.2 Agent Communications 5 2.2 Agent Communications We first provide a basic definition for an agent, which we need in order to describe the languages and protocols needed by multiagent systems. Fundamentally, an agent is an active object with the ability to perceive, reason, and act.
Reference: 39. <author> John R. Searle. </author> <title> Speech Acts: An Essay in the Philosophy of Language. </title> <publisher> Cambridge U. Press, </publisher> <year> 1970. </year>
Reference-contexts: A popular basis for analyzing human communication is speech act theory <ref> [1, 39] </ref>. Speech act theory views human natural language as actions, such as requests, suggestions, commitments, and replies. For example, when you request something, you are not simply making a statement, but creating the request itself.
Reference: 40. <author> Herbert Simon. </author> <booktitle> The Sciences of the Artificial. </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, MA, third edition, </address> <year> 1996. </year>
Reference-contexts: It is helpful if there is some form of organization among the agents. Also, social commitments can be a means to achieving coherence, which is addressed in Section 2.4. Section 2.3.7 discusses another means, based on economic principles of markets. In this regard, Simon <ref> [40] </ref> argues eloquently that although markets are excellent for clearing all goods, i.e., finding a price at which everything is sold, they are less effective in computing optimal allocations of resources. Organizational structures are essential for that purpose.
Reference: 41. <author> Munindar P. Singh. </author> <title> Commitments among autonomous agents in information-rich environments. </title> <booktitle> In Proceedings of the 8th European Workshop on Modelling Autonomous Agents in a Multi-Agent World (MAAMAW), </booktitle> <year> 1997. </year>
Reference-contexts: These 2.4 Societies of Agents 35 must be carefully distinguished from internal commitments. Social commitments have been studied by a number of researchers, including [17, 28]. There are a number of definitions in the literature, which add components such as witnesses [5] or contexts <ref> [41] </ref>. Social commitments are a flexible means through which the behavior of autonomous agents is constrained.
Reference: 42. <author> Munindar P. Singh. </author> <title> "Considerations on Agent Communication," </title> <booktitle> presented at FIPA Workshop, </booktitle> <year> 1997. </year>
Reference-contexts: Meaning is a combination of semantics and pragmatics. Agents communicate in order to understand and be understood, so it is important to consider the different dimensions of meaning that are associated with communication <ref> [42] </ref>. Descriptive vs. Prescriptive. Some messages describe phenomena, while others prescribe behavior. Descriptions are important for human comprehension, but are difficult for agents to mimic. Appropriately, then, most agent communication languages are designed for the exchange of information about activities and behavior. Personal vs. Conventional Meaning.
Reference: 43. <author> Munindar P. Singh. </author> <title> A Semantics for Speech Acts. </title> <journal> Annals of Mathematics and AI , Vol.8, </journal> <volume> No.I-II, </volume> <pages> pages 47-71, </pages> <year> 1993. </year>
Reference-contexts: Types Communicative Action Illocutionary Force Expected Result Assertion Inform Acceptance Query Question Reply Reply Inform Acceptance Request Request Explanation Inform Agreement Command Request Permission Inform Acceptance Refusal Inform Acceptance Offer/Bid Inform Acceptance Acceptance Agreement Proposal Inform Offer/Bid Confirmation Retraction Denial Other types of messages, derived from work on speech-act theory <ref> [43] </ref>, are listed in Table 2.4. 2.2.4 Communication Levels Communication protocols are typically specified at several levels.
Reference: 44. <author> Reid G. Smith. </author> <title> The Contract Net Protocol: High Level Communication and Control in a Distributed Problem Solver. </title> <journal> IEEE Transactions on Computers, </journal> <volume> Vol. C-29, No. 12, </volume> <pages> pages 1104-1113, </pages> <month> December </month> <year> 1980. </year>
Reference-contexts: and award cycles Multiagent planning: planning agents have the responsibility for task assignment Organizational structure: agents have fixed responsibilities for particular tasks. methods are described in the sections that follow. agents 2.3.3 Contract Net Of the above mechanisms, the best known and most widely applied is the contract net protocol <ref> [44, 9] </ref>. The contract net protocol is an interaction protocol for cooperative problem solving among agents. It is modeled on the contracting mechanism 2.3 Agent Interaction Protocols 23 used by businesses to govern the exchange of goods and services.
Reference: 45. <author> Reid G. Smith and Randall Davis. </author> <title> Frameworks for Cooperation in Distributed Problem Solving. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> Vol. SMC-11, No. 1, </volume> <pages> pages 61-70, </pages> <month> January </month> <year> 1981. </year>
Reference: 46. <author> Katia Sycara. </author> <title> Resolving Goal Conflicts via Negotiation. </title> <booktitle> In Proc. </booktitle> <pages> AAAI-88 , pages 245-250, </pages> <year> 1988. </year>
Reference: 47. <author> Michael P. Wellman. </author> <title> A computational market model for distributed configuration design. </title> <booktitle> AI EDAM , 9 </booktitle> <pages> 125-133, </pages> <year> 1995. </year>
Reference-contexts: few well defined issues to be decided. 32 Multiagent Systems and Societies of Agents i Q (OUT) i S (IN) @ @ @ @ @ + T (OUT) i U (IN) Agent 1 Agent 2 produced by the multiagent TMS algorithm Computational economies, based on market mechanisms, are another approach <ref> [47] </ref>. These are effective for coordinating the activities of many agents with minimal direct communication among the agents. The research challenge is to build computational economies to solve specific problems of distributed resource allocation.
Reference: 48. <author> Eric Werner. </author> <title> Cooperating Agents: A unified theory of communication and social structure. </title> <editor> In L. Gasser and M. Huhns, editors, </editor> <booktitle> Distributed Artificial Intelligence, </booktitle> <volume> Volume II, </volume> <pages> pages 3-36. </pages> <publisher> Pittman, </publisher> <address> London, </address> <year> 1989. </year>
Reference: 49. <author> Gio Wiederhold. </author> <title> Mediators in the Architecture of Future Information Systems, </title> <journal> IEEE Computer , Vol. </journal> <volume> 25, No. 3, </volume> <pages> pages 38-49, </pages> <month> March </month> <year> 1992. </year>
Reference: 50. <author> Carson Woo and Frederick H. </author> <title> Lochovsky. </title> <journal> Knowledge Communication in Intelligent Information Systems. International Journal of Intelligent and Cooperative Information Systems, </journal> <volume> Vol. 1, No. 1, </volume> <pages> pages 203-228, </pages> <year> 1992. </year>
References-found: 50

