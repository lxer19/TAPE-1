URL: http://www.cs.wustl.edu/cs/techreports/1994/wucs-94-01.ps.Z
Refering-URL: http://www.cs.wustl.edu/cs/cs/publications.html
Root-URL: 
Email: pwgoldb@cs.sandia.gov  sg@cs.wustl.edu  
Title: Learning One-Dimensional Geometric Patterns Under One-Sided Random Misclassification Noise  
Author: Paul W. Goldberg Sally A. Goldman 
Note: This research was performed while visiting Washington University. Currently supported by the U.S. Department of Energy under contract DE-AC04-76AL85000. Supported in part by NSF Grant CCR-9110108 and an NSF NYI Grant CCR-9357707.  
Date: May 12, 1994  
Address: MS 1110 P.O. Box 5800 Albuquerque, NM 87185-1110  St. Louis, MO 63130  
Affiliation: Department 1423 Sandia National Laboratories,  Dept. of Computer Science Washington University  
Pubnum: WUCS-94-01  
Abstract-found: 0
Intro-found: 1
Reference: [AL88] <author> Dana Angluin and Philip Laird. </author> <title> Learning from noisy examples. </title> <journal> Machine Learning, </journal> <volume> 2(4) </volume> <pages> 343-370, </pages> <year> 1988. </year>
Reference-contexts: In this work we consider a variant of the PAC model in which the negative examples from the oracle, EX, are corrupted by random misclassification noise. (This noise model is just a variation of the model of random misclassification noise introduced by Angluin and Laird <ref> [AL88] </ref> except here only negative examples are corrupted by the noise process.) Namely, we assume that for some noise rate every negative example drawn from EX is randomly and independently labeled as positive with probability - and labeled as negative with probability (1 -).
Reference: [BEHW89] <author> Anselm Blumer, Andrzej Ehrenfeucht, David Haussler, and Manfred K. Warmuth. </author> <title> Learnability and the Vapnik-Chervonenkis dimension. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 36(4) </volume> <pages> 929-965, </pages> <month> October </month> <year> 1989. </year>
Reference-contexts: Hence both parameters are needed as upper bounds on concept and instance complexities. We now present our algorithm for learning C k;n in the noise-free setting. Our algorithm is an Occam algorithm (see <ref> [BEHW89] </ref>). Namely, it draws a sufficiently large sample of size m 1 (polynomial in k; lg n; 1=*, and lg 1=ffi) and then outputs a consistent hypothesis from H k+1 . <p> Then it is easily shown that r 2 (k + 1) lg m 1 . Finally, the hypothesis output is the intersection of the r concepts obtained in this manner. By the results of Blumer, et al. <ref> [BEHW89] </ref> we get that the VC-dimension of H k+1 is at most 2dr lg (3r) where d = 2 (k + 1) log 16en (k + 1) and r = 2 (k + 1) lg m 1 , and thus any hypothesis that is consistent with a sample of size m
Reference: [Gol92] <author> Paul W. Goldberg. </author> <title> PAC Learning Geometrical Figures. </title> <type> PhD thesis, </type> <institution> University of Edinburgh, </institution> <year> 1992. </year> <month> 22 </month>
Reference-contexts: For ease of exposition, we assume that and-p are known, however, our results can be easily modified to work as long as an upperbound on both quantities is provided. 5 Learning C k;n in the Noise-Free Setting The problem of learning one-dimensional geometric patterns has been previously studied by Goldberg <ref> [Gol92, Gol93] </ref>. He has developed an algorithm to PAC-learn C n;n in the noise-free setting [Gol93]. Our algorithm to learn C k;n is obtained by making straightforward modifications to Goldberg's algorithm. However, the modifications needed to handle the false positive errors are significantly more involved. <p> He has developed an algorithm to PAC-learn C n;n in the noise-free setting [Gol93]. Our algorithm to learn C k;n is obtained by making straightforward modifications to Goldberg's algorithm. However, the modifications needed to handle the false positive errors are significantly more involved. We also note that Goldberg <ref> [Gol92] </ref> has shown that it is N P -complete to find a sphere in the given metric space (i.e. one-dimensional patterns of points on the line under the Hausdorff metric) consistent with a given set of positive and negative examples of an unknown sphere in the given metric space.
Reference: [Gol93] <author> Paul W. Goldberg. </author> <title> Geometrical pattern learning. </title> <type> Unpublished Manuscript, </type> <month> April </month> <year> 1993. </year>
Reference-contexts: For ease of exposition, we assume that and-p are known, however, our results can be easily modified to work as long as an upperbound on both quantities is provided. 5 Learning C k;n in the Noise-Free Setting The problem of learning one-dimensional geometric patterns has been previously studied by Goldberg <ref> [Gol92, Gol93] </ref>. He has developed an algorithm to PAC-learn C n;n in the noise-free setting [Gol93]. Our algorithm to learn C k;n is obtained by making straightforward modifications to Goldberg's algorithm. However, the modifications needed to handle the false positive errors are significantly more involved. <p> He has developed an algorithm to PAC-learn C n;n in the noise-free setting <ref> [Gol93] </ref>. Our algorithm to learn C k;n is obtained by making straightforward modifications to Goldberg's algorithm. However, the modifications needed to handle the false positive errors are significantly more involved.
Reference: [GJ93] <author> Paul W. Goldberg and Mark R. Jerrum. </author> <title> Bounding the Vapnik-Chervonenkis dimension of Concept Classes Parameterized by Real Numbers. </title> <booktitle> Conference on Computational Learning Theory, </booktitle> <month> July </month> <year> 1993. </year>
Reference-contexts: To give even further evidence that the class of one-dimensional patterns is significantly more complex than the union of intervals on the real line, observe that the consistency problem for that class is trivial to solve. Finally, the results of Goldberg and Jerrum <ref> [GJ93] </ref> can be used to show that the Vapnik-Chervonenkis dimension of C k;n 2k log (8enk) = O (k lg n). We observe that as either k or n increases, and the other is held fixed, then the VC dimension can increase without limit.
Reference: [Gru83] <author> P.M. Gruber. </author> <title> Approximation of convex bodies. In P.M. </title> <editor> Gruber and P.M. Willis, editors, </editor> <title> Convexity and its applications. </title> <publisher> Brikhauser Verlag, </publisher> <year> 1983. </year>
Reference-contexts: Each instance is a configuration of n points on the real line, where it is labeled according to whether or not it visually resembles the target pattern. To capture the notion of visual resemblance we use the Hausdorff metric (for example, see Gruber <ref> [Gru83] </ref>). Informally, two geometric patterns P and Q resemble each other under the Hausdorff metric, if every point on one pattern is "close" to some point on the other pattern.
Reference: [Hoe63] <author> Wassily Hoeffding. </author> <title> Probability inequalities for sums of bounded random variables. </title> <journal> Journal of the American Statistical Association, </journal> <volume> 58(301) </volume> <pages> 13-30, </pages> <month> March </month> <year> 1963. </year>
Reference-contexts: To compute the size of the sample (as a function of m 1 , -, p , p + , and ffi) we use Hoeffding's Inequality <ref> [Hoe63] </ref> (also referred as a form of Chernoff bounds) as stated below: Lemma 1 (Hoeffding's Inequality) Let Y 1 ; : : : ; Y m be a sequence of m independent Bernoulli trials, each succeeding with probability p.
Reference: [HTP + 92] <author> Jiawei Hong, Xiaonan Tan, Brian Pinette, Richard Weiss, and Edward M. Riseman. </author> <title> Image-based homing. </title> <journal> IEEE Control Systems Magazine, </journal> <volume> 12(1) </volume> <pages> 38-45, </pages> <year> 1992. </year>
Reference-contexts: It is also crucial that the landmark matching algorithm can be performed in real-time. To reduce the processing time required by the landmark matching algorithm, some are proposing the use of imaging systems that generate a one-dimensional array of light intensities taken at eye-level <ref> [HTP + 92, LL90, Pin93, SA88] </ref>. We now briefly describe one such imaging system (see Hong et al. [HTP + 92] and Pinnette [Pin93]). <p> To reduce the processing time required by the landmark matching algorithm, some are proposing the use of imaging systems that generate a one-dimensional array of light intensities taken at eye-level [HTP + 92, LL90, Pin93, SA88]. We now briefly describe one such imaging system (see Hong et al. <ref> [HTP + 92] </ref> and Pinnette [Pin93]). In their robot a spherical mirror is mounted above an upward-pointing camera on a robot thus enabling it to instantaneously obtain a 360 degree view of the world. See Figure 2 for a picture of such a robot.
Reference: [LL90] <author> Todd S. Levitt and Daryl T. Lawton. </author> <title> Qualitative navigation for mobile robots. </title> <journal> Artificial Intelligence, </journal> <volume> 44(3): </volume> <pages> 305-360, </pages> <year> 1990. </year>
Reference-contexts: It is also crucial that the landmark matching algorithm can be performed in real-time. To reduce the processing time required by the landmark matching algorithm, some are proposing the use of imaging systems that generate a one-dimensional array of light intensities taken at eye-level <ref> [HTP + 92, LL90, Pin93, SA88] </ref>. We now briefly describe one such imaging system (see Hong et al. [HTP + 92] and Pinnette [Pin93]).
Reference: [Lit88] <author> Nick Littlestone. </author> <title> Learning when irrelevant attributes abound: A new linear-threshold algorithm. </title> <journal> Machine Learning, </journal> <volume> 2 </volume> <pages> 285-318, </pages> <year> 1988. </year>
Reference-contexts: As in previous work on learning with a large number of irrelevant attributes in the Boolean domain (e.g. Littlestone's work <ref> [Lit88] </ref>), our algorithm's sample complexity (the best dual to a mistake-bound) depends polynomially on k and lg n. This paper is organized as follows. In the next section we formally define the concept class of one-dimensional geometric patterns.
Reference: [Pin93] <author> Brian Pinette. </author> <title> Image-Based Navigation Through Large-Scaled Environments. </title> <type> PhD thesis, </type> <institution> University of Massachusetts, Amherst, </institution> <month> November </month> <year> 1993. </year>
Reference-contexts: It is crucial that the robot be able to recognize whether or not it is in the vicinity of a given landmark from a visual image taken from the robot's current location. We shall refer to this problem as the landmark matching problem. In his doctoral thesis, Pinette <ref> [Pin93] </ref> says that "any general navigation algorithm must be able to match landmarks by their appearance." Namely, when performing navigation a robot plans a path by moving between known landmarks, tracking landmarks as it goes. <p> It is also crucial that the landmark matching algorithm can be performed in real-time. To reduce the processing time required by the landmark matching algorithm, some are proposing the use of imaging systems that generate a one-dimensional array of light intensities taken at eye-level <ref> [HTP + 92, LL90, Pin93, SA88] </ref>. We now briefly describe one such imaging system (see Hong et al. [HTP + 92] and Pinnette [Pin93]). <p> We now briefly describe one such imaging system (see Hong et al. [HTP + 92] and Pinnette <ref> [Pin93] </ref>). In their robot a spherical mirror is mounted above an upward-pointing camera on a robot thus enabling it to instantaneously obtain a 360 degree view of the world. See Figure 2 for a picture of such a robot. <p> If one's goal is to determine if the robot is standing exactly at position L, then the pattern matching approach can easily be implemented to work well. However, in reality, the matching algorithm must determine if the robot is in the vicinity of L 7 Not available electronically. thesis <ref> [Pin93] </ref>.) 8 Not available electronically. thesis [Pin93].) 9 (i.e. in a circle centered around L). Because the visual image may change significantly as small movements around L are made, the pattern matching approach encounters difficulties. <p> However, in reality, the matching algorithm must determine if the robot is in the vicinity of L 7 Not available electronically. thesis <ref> [Pin93] </ref>.) 8 Not available electronically. thesis [Pin93].) 9 (i.e. in a circle centered around L). Because the visual image may change significantly as small movements around L are made, the pattern matching approach encounters difficulties.
Reference: [SA88] <author> Hisashi Suzuki and Suguru Arimoto. </author> <title> Visual control of autonomous mobile robot based on self-organizing model for pattern learning. </title> <journal> Journal of Robotic Systems, </journal> <volume> 5(5) </volume> <pages> 453-470, </pages> <year> 1988. </year>
Reference-contexts: It is also crucial that the landmark matching algorithm can be performed in real-time. To reduce the processing time required by the landmark matching algorithm, some are proposing the use of imaging systems that generate a one-dimensional array of light intensities taken at eye-level <ref> [HTP + 92, LL90, Pin93, SA88] </ref>. We now briefly describe one such imaging system (see Hong et al. [HTP + 92] and Pinnette [Pin93]).
Reference: [Val84] <author> Leslie Valiant. </author> <title> A theory of the learnable. </title> <journal> Communications of the ACM, </journal> <volume> 27(11) </volume> <pages> 1134-1142, </pages> <month> November </month> <year> 1984. </year>
Reference-contexts: locations not in the vicinity of the landmark), we can construct a hypothesis that can accurately predict whether or not the robot is near the given landmark. 4 The Learning Model and Model of Noise We assume the reader is familiar with the PAC learning model as define by Valiant <ref> [Val84] </ref>. As commonly done, we allow the learner to output any polynomially evaluatable hypothesis. We now describe the hypothesis class used here.
Reference: [Val91] <author> Leslie Valiant. </author> <title> A view of computational learning theory. In C.W. Gear, editor, NEC Research Symposium: Computation and Cognition. </title> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1991. </year> <month> 23 </month>
Reference-contexts: Finally, the concept class C k;n that we study is defined as follows: C k;n = fc P j P is a configuration of k points on the real lineg. As is standard in the neural network literature, we assume the unit cost model of real computation. (See Valiant <ref> [Val91] </ref> for a discussion of why this assumption is typically appropriate for geometric domains.) As discussed in the introduction, n may be significantly greater than k. For example, the learner may be asked to predict if a configuration of 100 points is contained within a sphere defined by 3 points.
References-found: 14

