URL: http://www.cs.berkeley.edu/~eanders/projects/netram/usenix-netram.ps
Refering-URL: http://www.cs.berkeley.edu/~eanders/projects/netram/
Root-URL: 
Title: Experience with Two Implementations of Network RAMAugust Experience with Two Implementations of Network RAM Network
Author: Eric Anderson Alan Mainwaring Jeanna Neefe Chad Yoshikawa Tom Anderson David Culler David Patterson 
Address: Berkeley  
Affiliation: Computer Science Division University of California at  
Note: 9, 1995 ABSTRACT Please do not distribute! 1  1.0 Introduction  Although discussed for years [CG90, FZ91, ILP93, KP91, MDP95], three factors make it especially attractive today:  
Abstract: With the emergence of switched, high-bandwidth networks and new low-latency communication paradigms, machines can access remote memory much faster than local disk. This motivates using remote memory as the backing store for virtual memory pages. We implemented two systems to explore this idea: a user-level library and a swap device driver. Our results demonstrate (1) that Network RAM is feasible, (2) that programs that page significantly run faster using Network RAM, and (3) that current virtual memory systems have significant overheads that will limit network paging performance as communication costs decrease. 
Abstract-found: 1
Intro-found: 1
Reference: [AGV94] <author> T. Anderson, D. Ghormley, A. Vahdat. </author> <title> Toward Efficient, Portable, and Robust Extension of Operating System Functionality, </title> <note> submitted for publication. </note>
Reference: [ACP95] <author> T. Anderson, D. Culler, D. Patterson et al., </author> <title> A Case for NOW (Network or Workstations), </title> <booktitle> IEEE Micro, </booktitle> <year> 1995. </year>
Reference-contexts: We avoided unnecessary kernel modifications and focused on portable interfaces. This facilitated rapid prototyping and instrumentation, increased portability and focused our attention on the relevant overheads. We assume our NRAM implementations will be used in a network of workstations (NOW) <ref> [ACP95] </ref>. NOWs are likely to be connected by the high performance network that NRAM requires. We also assume a global resource manager [Zho*92, VGA94] to identify nodes with free memory. 2.1 User-level Memory Manager This implementation of NRAM is used by calling a custom malloc library.
Reference: [Arp*94] <author> R. Arpaci, A. Dusseau, A. Vahdat, T. Anderson, and D. Patterson, </author> <title> The Interaction of Parallel and Sequen tial Workloads on a Network of Workstations, </title> <note> submitted for publication. </note>
Reference-contexts: Low-latency communication paradigms such as Active Messages [vEi*92] can expose the full performance of these networks by drastically reducing associated communication overheads. 3. Substantial free memory exists on idle machines in the network. <ref> [Arp*94] </ref> observes that in a 50-machine network of workstations, at least 30 are classified as idle at any given time. One goal of virtual memory is to transparently move pages between disk and memory.
Reference: [Asa94] <author> S. Asami, </author> <title> Evaluating Network RAM via Paging, slide presentation, </title> <institution> Berkeley NOW group retreat, </institution> <month> June </month> <year> 1994. </year>
Reference: [BBV95] <author> A. Basu, V. Buch, and W. Vogels and T. von Eicken, U-Net: </author> <title> A User-Level Network Interface for Parallel and Distributed Computing, </title> <booktitle> Proc. of the 1995 Symposium on Operating Systems Principles, </booktitle> <month> December </month> <year> 1995. </year>
Reference-contexts: As with previous studies, we also found that TCP/IP limits performance, and that 10 Mbit Ethernet is too slow to make NRAM useful. However, on-going research in Active Messages <ref> [Mart94, BBV95] </ref> is successfully addressing TCP/IP overheads and new networks such as Myrinet and ATM are providing high bandwidth communication. (We intend to use a fast message layer for our final paper.) We also observed some significant virtual memory overheads in current operating systems (Solaris, HPUX and OSF) will limit performance.
Reference: [BCS93] <author> E. Biagioni, E. Cooper, and R. Sansom. </author> <title> Designing a practical ATM LAN. </title> <journal> IEEE Network, </journal> (7)2:32-39, March 1993.: 
Reference-contexts: 1.0 Introduction Network RAM (NRAM) uses memory on remote machines as the backing store for virtual memory pages. Although discussed for years [CG90, FZ91, ILP93, KP91, MDP95], three factors make it especially attractive today: 1. Switched, high-bandwidth, low-latency networks such as Myrinet [Sei94] and ATM <ref> [BCS93] </ref> can offer much higher performance than bus-based networks such as Ethernet. 2. Low-latency communication paradigms such as Active Messages [vEi*92] can expose the full performance of these networks by drastically reducing associated communication overheads. 3.
Reference: [CG90] <author> D. Comer and J. Griffoen. </author> <title> A New Design for Distributed Systems: </title> <booktitle> The Remote Memory Model Proceed ings of the USENIX Summer Conference, </booktitle> <pages> pp. 127-135, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: 1.0 Introduction Network RAM (NRAM) uses memory on remote machines as the backing store for virtual memory pages. Although discussed for years <ref> [CG90, FZ91, ILP93, KP91, MDP95] </ref>, three factors make it especially attractive today: 1. Switched, high-bandwidth, low-latency networks such as Myrinet [Sei94] and ATM [BCS93] can offer much higher performance than bus-based networks such as Ethernet. 2. <p> However, in contrast to our portable block device driver, this system involves kernel changes including modifications to the VM code, additions to the address space data structures (so that certain pages can be marked exempt from NRAM), and kernel calls to support the interface. <ref> [CG90] </ref> describes a similar implementation, built on a heterogeneous mix of SUN 3/50s, MicroVaxs, and others. Like our system, pages are sent over the network to remote servers that can off-load memory to disk if needed.
Reference: [CKL*94] <author> D. Culler, Kim Keeton, L. Liu, A. Mainwaring, R. Martin, S. Rodrigues, K. Wright, </author> <title> Generic Active Message Specification, </title> <institution> Computer Science Division White Paper, University of California at Berkeley, </institution> <month> August </month> <year> 1994. </year>
Reference: [CS91] <author> H. Chartock and P. Snyder. </author> <title> Virtual Swap Space in SunOS Sun Microsystems White Paper, </title> <year> 1991. </year>
Reference: [FZ91] <author> E. W. Felten, J.Zahorjan, </author> <title> Issues in the Implementation of a Remote Memory Paging System, </title> <institution> Computer Sci ence Department, University of Washington, </institution> <year> 1990. </year>
Reference-contexts: 1.0 Introduction Network RAM (NRAM) uses memory on remote machines as the backing store for virtual memory pages. Although discussed for years <ref> [CG90, FZ91, ILP93, KP91, MDP95] </ref>, three factors make it especially attractive today: 1. Switched, high-bandwidth, low-latency networks such as Myrinet [Sei94] and ATM [BCS93] can offer much higher performance than bus-based networks such as Ethernet. 2. <p> DISK All DRAM vs. NRAM NRAM vs. DISK swim mgrid page_seq page_madv vlsi_small vlsi_large Speedups Experience with Two Implementations of Network RAMAugust 9, 1995 ABSTRACT - Please do not distribute! 8 5.0 Related Work <ref> [FZ91] </ref> considers issues faced when building a remote pager, including reliability and policy. The proposed system is built on the Topaz operating system, and allows applications to mark memory explicitly for remote paging. The system involves a clerk thread with functionality similar to that of our user-level page server.
Reference: [GMS87] <author> R. Gingell, J. Moran and W. Shannon, </author> <title> Virtual Memory Architecture in SunOS, Sun Microsystems White Paper, </title> <year> 1987. </year>
Reference: [ILP93] <author> L. Iftode, K. Li, K. Peterson, </author> <title> Memory Servers for Multicomputers, </title> <booktitle> Digest of Papers. COMPCON Spring 1993. </booktitle>
Reference-contexts: 1.0 Introduction Network RAM (NRAM) uses memory on remote machines as the backing store for virtual memory pages. Although discussed for years <ref> [CG90, FZ91, ILP93, KP91, MDP95] </ref>, three factors make it especially attractive today: 1. Switched, high-bandwidth, low-latency networks such as Myrinet [Sei94] and ATM [BCS93] can offer much higher performance than bus-based networks such as Ethernet. 2. <p> Like our system, pages are sent over the network to remote servers that can off-load memory to disk if needed. However, servers are dedicated, not NRAM clients. <ref> [ILP93] </ref> describes a system built on an Intel iPC/860 multicomputer, where nodes that are known to be idle are utilized for fast backing store.
Reference: [KH89] <author> Kai Li and Paul Hudak. </author> <title> Memory Coherence in Shared Virtual Memory Systems. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 7(4) </volume> <pages> 321-359, </pages> <month> November </month> <year> 1989. </year>
Reference: [KP91] <author> K. Li and K. Petersen, </author> <title> Evaluation of Memory System Extensions., </title> <booktitle> Proceedings of the 18th International Symposium on Computer Architecture, </booktitle> <pages> pages 84-93, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: 1.0 Introduction Network RAM (NRAM) uses memory on remote machines as the backing store for virtual memory pages. Although discussed for years <ref> [CG90, FZ91, ILP93, KP91, MDP95] </ref>, three factors make it especially attractive today: 1. Switched, high-bandwidth, low-latency networks such as Myrinet [Sei94] and ATM [BCS93] can offer much higher performance than bus-based networks such as Ethernet. 2. <p> Furthermore, the OSF/1 device driver is operating system dependent unlike our portable user-level memory manager. The idea of using solid state devices as a faster form of secondary storage has been noted at least since [Smit91]. In <ref> [KP91] </ref>, the idea of extended memory is explored. In this case, fast main memory is a cache for pages kept in slower and less expensive extended memory.
Reference: [McA90] <author> D. Mc Namee and K. Armstrong. </author> <title> Extending the Mach External Pager Interface to Accommodate User level Page Replacement Policies, </title> <booktitle> USENIX Workshop Proceedings: Mach, </booktitle> <year> 1990. </year>
Reference: [Mart94] <author> R. Martin, HPAM: </author> <title> An Active Message Layer for a Network of HP Workstations, Hot Interconnects II, </title> <month> August </month> <year> 1994. </year>
Reference-contexts: As with previous studies, we also found that TCP/IP limits performance, and that 10 Mbit Ethernet is too slow to make NRAM useful. However, on-going research in Active Messages <ref> [Mart94, BBV95] </ref> is successfully addressing TCP/IP overheads and new networks such as Myrinet and ATM are providing high bandwidth communication. (We intend to use a fast message layer for our final paper.) We also observed some significant virtual memory overheads in current operating systems (Solaris, HPUX and OSF) will limit performance.
Reference: [MDP95] <author> E. Markatos, G. Dramitinos, and K. Papachristos, </author> <title> Implementation and Evaluation of a REmote Memory Pager, </title> <type> Tech Report 129, </type> <institution> FORTH/ICS. </institution>
Reference-contexts: 1.0 Introduction Network RAM (NRAM) uses memory on remote machines as the backing store for virtual memory pages. Although discussed for years <ref> [CG90, FZ91, ILP93, KP91, MDP95] </ref>, three factors make it especially attractive today: 1. Switched, high-bandwidth, low-latency networks such as Myrinet [Sei94] and ATM [BCS93] can offer much higher performance than bus-based networks such as Ethernet. 2. <p> Thus, issues such as reliability and idle memory detection were not considerations. Perhaps the closest implementation in design and context is <ref> [MDP95] </ref>. Here, a remote memory pager was built using a device driver for the OSF/1 Kernel much like our device driver implementation for Solaris. The context of the NRAM system is also a NOW and reliability measures including mirroring and more space efficient parity measures were implemented.
Reference: [NO94] <author> G. Nguyen and N. Oza, </author> <title> On the Use of Network DRAM in LAPACK Programs, </title> <institution> University of California at Berkeley, class project, </institution> <month> November </month> <year> 1994. </year>
Reference: [NL91] <author> B. Nitzberg and V. Lo, </author> <title> Distributed Shared Memory: A Survey of Issues and Algorithms, </title> <month> August </month> <year> 1991. </year> <title> Experience with Two Implementations of Network RAMAugust 9, 1995 ABSTRACT - Please do not distribute! 10 </title>
Reference: [Paro94] <author> B. Parody. </author> <title> Measurement of Multiprocessor Performance, </title> <journal> Open Forum, </journal> <volume> 7(3) </volume> <pages> 7-13, </pages> <month> September </month> <year> 1994. </year>
Reference: [Patr94] <author> D. Patterson, </author> <title> presentation to Graduate Computer Architecture class at the University of California at Berke ley, </title> <month> Autumn </month> <year> 1994. </year>
Reference: [Ras88] <editor> Rashid, R.F., et al., </editor> <title> Machine-Independent Virtual Memory Management for Paged Uniprocessor and Multi processor Architectures, </title> <journal> IEEE Transactions on Computers, </journal> <volume> Vol. 37 No. </volume> <month> 8 (August </month> <year> 1988), </year> <pages> pp. 896-908. </pages>
Reference: [Sei94] <author> Chuck Seitz. </author> <title> Myrinet - A Gigabit-per-Second Local-Area Network. Talk presented at Hot Interconnects II, </title> <month> August </month> <year> 1994. </year>
Reference-contexts: 1.0 Introduction Network RAM (NRAM) uses memory on remote machines as the backing store for virtual memory pages. Although discussed for years [CG90, FZ91, ILP93, KP91, MDP95], three factors make it especially attractive today: 1. Switched, high-bandwidth, low-latency networks such as Myrinet <ref> [Sei94] </ref> and ATM [BCS93] can offer much higher performance than bus-based networks such as Ethernet. 2. Low-latency communication paradigms such as Active Messages [vEi*92] can expose the full performance of these networks by drastically reducing associated communication overheads. 3.
Reference: [SBAB94] <author> V. Singhal, C. Pixley, A. Aziz, R. K. Brayton, </author> <note> Delaying Safeness for More Flexibility, submitted for publication. </note>
Reference: [Smit91] <author> A. Smith, </author> <title> Input/Output Optimizations and Disk Architectures: A Survey, </title> <journal> Performance Evaluation, </journal> <volume> Vol. 1, </volume> <year> 1981, </year> <pages> pp. 104-117. </pages>
Reference-contexts: Furthermore, the OSF/1 device driver is operating system dependent unlike our portable user-level memory manager. The idea of using solid state devices as a faster form of secondary storage has been noted at least since <ref> [Smit91] </ref>. In [KP91], the idea of extended memory is explored. In this case, fast main memory is a cache for pages kept in slower and less expensive extended memory.
Reference: [Snyd90] <author> P. Snyder, tmpfs: </author> <title> A Virtual Memory File System, </title> <booktitle> Proceedings of the Autumn 1990 EUUG Conference, </booktitle> <pages> pp. 241-248, </pages> <address> EUUG, Nice France, </address> <month> October </month> <year> 1990. </year>
Reference-contexts: system continues to manage application virtual address spaces using its standard policies and mechanisms, such as page clustering, (3) all applications can reap the performance benefits of network paging without modification, and (4) files written to /tmp are NRAM pageable if /tmp has been mounted on the Solaris tmpfs filesystem <ref> [Snyd90] </ref>. 3.0 Results Our two implementations provide different views of NRAM performance. The user-level memory manager is portable allowing us to measure overheads on several platforms.
Reference: [VGA94] <author> A. Vahdat, D. Ghormley and T. Anderson. </author> <title> Efficient, Portable, and Robust Extension of Operating System Functionality, </title> <month> December, </month> <year> 1994. </year> <institution> UC Berkeley Technical Report CS-94-842 </institution>
Reference-contexts: We assume our NRAM implementations will be used in a network of workstations (NOW) [ACP95]. NOWs are likely to be connected by the high performance network that NRAM requires. We also assume a global resource manager <ref> [Zho*92, VGA94] </ref> to identify nodes with free memory. 2.1 User-level Memory Manager This implementation of NRAM is used by calling a custom malloc library. The application initializes the library by specifying the amount of memory to use for the local NRAM page cache.
Reference: [vEi*92] <author> T. von Eicken, D. Culler, S. Goldstein and K. Schauser, </author> <title> Active Messages: a Mechanism for Integrated Communication and Computation, </title> <booktitle> Proc. 19th Annual International Symposium on Computer Architecture, </booktitle> <pages> pp. 256-257, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: Although discussed for years [CG90, FZ91, ILP93, KP91, MDP95], three factors make it especially attractive today: 1. Switched, high-bandwidth, low-latency networks such as Myrinet [Sei94] and ATM [BCS93] can offer much higher performance than bus-based networks such as Ethernet. 2. Low-latency communication paradigms such as Active Messages <ref> [vEi*92] </ref> can expose the full performance of these networks by drastically reducing associated communication overheads. 3. Substantial free memory exists on idle machines in the network. [Arp*94] observes that in a 50-machine network of workstations, at least 30 are classified as idle at any given time.
Reference: [Zho*92] <author> S. Zhou, J. Wang, X. Zheng, and P. Delissle, </author> <title> Utopia: A Load Sharing Facility for Large Heterogenous Dis tributed Computing Systems, </title> <type> Technical Report CSRI-257, </type> <institution> University of Toronto, </institution> <year> 1992. </year>
Reference-contexts: We assume our NRAM implementations will be used in a network of workstations (NOW) [ACP95]. NOWs are likely to be connected by the high performance network that NRAM requires. We also assume a global resource manager <ref> [Zho*92, VGA94] </ref> to identify nodes with free memory. 2.1 User-level Memory Manager This implementation of NRAM is used by calling a custom malloc library. The application initializes the library by specifying the amount of memory to use for the local NRAM page cache.
References-found: 29

