URL: ftp://ftp.cs.wpi.edu/pub/techreports/94-4.ps.gz
Refering-URL: http://cs.wpi.edu/Resources/techreports/index.html
Root-URL: 
Email: email: fstaylor,hachem,smsg@cs.wpi.edu  
Phone: phone: (508) 831-f5409,5669,5449g Fax: (508) 831-5776  
Title: Analyzing BANG and NIBGF files using the Capitalist model (Draft)  
Author: Stephen Taylor, Nabil Hachem, and Stanley Selkow 
Address: Worcester, MA 01609, USA  
Affiliation: Department of Computer Science Worcester Polytechnic Institute  
Abstract: The method is applied to formal analysis of the BANG and NIBGF directory structures. The average cost for search and insertion is found to be logarithmic in the file size. The order constant is quite small and depends on the capacity of a bucket. Simulation confirms the analytic results. This first use of the Capitalist model suggests its usefulness to the analysis of other multidimensional file structures. 
Abstract-found: 1
Intro-found: 1
Reference: [AS64] <author> Milton Abramowitz and Irene A. </author> <title> Stegun. Handbook of Mathematical Functions. </title> <publisher> Dover, </publisher> <year> 1964. </year>
Reference: [Ben75] <author> J.L. Bentley. </author> <title> Multidimensional binary search trees used for associative searching. </title> <journal> CACM, </journal> <volume> 18(9), </volume> <month> Septem-ber </month> <year> 1975. </year>
Reference-contexts: 1 Introduction Multi-dimensional bucket files are data structures for storing records with many fields or keys. A bucket will contain records which are relatively close to one another if the records are regarded as points in metric space. A variety of such structures have been proposed, among them the K-d-tree <ref> [Ben75] </ref>, the Quadtree [FB74], the Grid File [NHS84], the h-B tree [LS90], and the two structures discussed in this paper, the BANG file [Fre87] and the NIBGF [OM91]. Our particular interest is in comparing file structures and algorithms with formal mathematical analysis.
Reference: [BY89] <author> Ricardo A. Baeza-Yates. </author> <title> Modeling splits in files structures. </title> <journal> Acta Informatica, </journal> <volume> 26(4) </volume> <pages> 349-362, </pages> <month> February </month> <year> 1989. </year>
Reference-contexts: and used it in the analysis of [Yao79], he did not examine it in detail; the bulk of that analysis deals with transformations between ""fringe" subtrees. * The Capitalist model tracks the statistic "keys per bucket" rather than its dual, "data-space per key." * It unifies the "ideal hashing" of <ref> [BY89] </ref> and "equally probable key-intervals" in a single concept. 2 . . . .. . . . . . . . . . . .
Reference: [Com79] <author> Douglas Comer. </author> <title> The ubiquitous B-tree. </title> <journal> Computing Surveys, </journal> <volume> 11(2), </volume> <month> June </month> <year> 1979. </year>
Reference-contexts: Per-Bucket approximation Depending on the access method, there may be various numbers of keys stored in each bucket. For example, data buckets in B-trees or B + -trees are always at least half full <ref> [Com79] </ref> (unless the file has only one bucket.) BANG files have data buckets which range in utilization from one-third to entirely full. The per-Bucket approximation ignores these variations. It assumes that each bucket is equally likely to receive new insertions, and ultimately to split, independent of its current utilization.
Reference: [FB74] <author> R.A. Finkel and J.L. Bentley. </author> <title> Quad trees: a data structure for retrieval on composite keys. </title> <journal> Acta Informatica, </journal> <volume> 4(1) </volume> <pages> 1-9, </pages> <year> 1974. </year>
Reference-contexts: A bucket will contain records which are relatively close to one another if the records are regarded as points in metric space. A variety of such structures have been proposed, among them the K-d-tree [Ben75], the Quadtree <ref> [FB74] </ref>, the Grid File [NHS84], the h-B tree [LS90], and the two structures discussed in this paper, the BANG file [Fre87] and the NIBGF [OM91]. Our particular interest is in comparing file structures and algorithms with formal mathematical analysis.
Reference: [Fla83] <author> Philippe Flajolet. </author> <title> On the performance evaluation of extendible hashing and trie searching. </title> <journal> Acta Infor-matica, </journal> <volume> 20(4), </volume> <year> 1983. </year>
Reference-contexts: We find that the average height of a node in the directory tree is logarithmic in the number of buckets. In Section 2 we introduce the Capitalist model of file growth as an aid to analyzing file structures. It is contrasted with the Bernoulli and Poisson models developed by <ref> [FNPS79, Reg85, Fla83] </ref>. In Section 3 we draw upon the file description from [OM92], recasting the notation somewhat. We analyze data bucket splits and apply one variant of the Capitalist model to obtain a probability distribution for the directory tree height in the BANG file.
Reference: [FNPS79] <author> Ronald Fagin, Jurg Nievergelt, Nicholas Pippenger, and H. Raymond Strong. </author> <title> Extendible hashing a fast access method for dynamic files. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 4(3), </volume> <year> 1979. </year>
Reference-contexts: We find that the average height of a node in the directory tree is logarithmic in the number of buckets. In Section 2 we introduce the Capitalist model of file growth as an aid to analyzing file structures. It is contrasted with the Bernoulli and Poisson models developed by <ref> [FNPS79, Reg85, Fla83] </ref>. In Section 3 we draw upon the file description from [OM92], recasting the notation somewhat. We analyze data bucket splits and apply one variant of the Capitalist model to obtain a probability distribution for the directory tree height in the BANG file. <p> In this model the number of records in the file has the Poisson distribution, and the probability distributions for the buckets are independent, and have Poisson distributions. 1 Uniformity is a property of the model as introduced by <ref> [FNPS79] </ref>, not of a Bernoulli or binomial distribution. Clearly each bucket could have a Bernoulli distribution with a different probability p b . 1 The problem with both of these models is that useful analysis using them assumes a uniform distribution over a finite keyspace.
Reference: [Fre87] <author> Michael Freeston. </author> <title> The BANG file: a new kind of grid file. </title> <booktitle> In 1987 ACM-SIGMOD Conference, </booktitle> <pages> pages 260-269, </pages> <year> 1987. </year>
Reference-contexts: A variety of such structures have been proposed, among them the K-d-tree [Ben75], the Quadtree [FB74], the Grid File [NHS84], the h-B tree [LS90], and the two structures discussed in this paper, the BANG file <ref> [Fre87] </ref> and the NIBGF [OM91]. Our particular interest is in comparing file structures and algorithms with formal mathematical analysis. Analytic models permit asymptotic comparisons between algorithms with a nicety unachievable by performance monitoring or simulation. A recurring problem of formal analysis is to provide mathematically tractable models of structures. <p> One subset of the possible physical implementations include NIBGF directories. We postpone discussion of the physical implementation until section 4, where we compare BANG and NIBGF. 3.1 The BANG Directory Tree A BANG file <ref> [Fre87, OM91] </ref> contains k-field records which are each mapped to a point in [0; 1] k . The file has a directory tree or forest of trees which has one node for each data bucket in the file. <p> Our graphs in figures (14) and (15) illustrate this. 6 Simulations We coded a metered virtual-memory implementation of a two-dimensional NIBGF [OM92] variant of the BANG file <ref> [Fre87] </ref> and created files with large numbers of buckets, using uniform and normal distributions and bucket capacities of 5, 30, 60, 120 and 500 tuples.
Reference: [GKP88] <author> Ronald L. Graham, Donald E. Knuth, and Oren Patashnik. </author> <title> Concrete Mathematics / A Foundation for Computer Science. </title> <publisher> Addison-Wesley, </publisher> <year> 1988. </year>
Reference-contexts: expected number of buckets before the split, n l;n , the expected number of new buckets from a peer split at level l, p P l;n the expected number of new buckets from a subspace split at level l 1, p S l1;n The expressions in square brackets are what <ref> [GKP88] </ref> calls `Iverson's convention,' cited there as originating in [Ive62]. [P ] represents the value 1 when P is true. When the conditions is not true, the value of the entire term, for example, (n+p P ) l;n [0 l &lt; n] is 0.
Reference: [HB92] <author> Nabil I. Hachem and P. Bruce Berra. </author> <title> New order preserving access methods for very large files derived from linear hashing. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 4(1), </volume> <month> February </month> <year> 1992. </year>
Reference-contexts: A recurring problem of formal analysis is to provide mathematically tractable models of structures. Commonly used modeling techniques include: Fractional Progress, the analysis of a file in terms of percentage of transition from one mode to another <ref> [Lar85, HB92] </ref>; this fades into Demographics, which studies the populations in various modes [Yao79, Lom81]; and Geometric Transformation, which makes the structure under study similar or equivalent to some other, well-known one [LS90, OM92].
Reference: [Ive62] <author> Kenneth E. Iverson. </author> <title> A Programming Language. </title> <publisher> Wiley, </publisher> <year> 1962. </year>
Reference-contexts: , the expected number of new buckets from a peer split at level l, p P l;n the expected number of new buckets from a subspace split at level l 1, p S l1;n The expressions in square brackets are what [GKP88] calls `Iverson's convention,' cited there as originating in <ref> [Ive62] </ref>. [P ] represents the value 1 when P is true. When the conditions is not true, the value of the entire term, for example, (n+p P ) l;n [0 l &lt; n] is 0. This convention keeps the boundary conditions visible during the generating function transforms which follow.
Reference: [Knu73] <author> Donald E. Knuth. </author> <title> The art of computer programming, Vol 3, Sorting and Searching. </title> <publisher> Addison-Wesley, </publisher> <year> 1973. </year>
Reference-contexts: Taking cost of a typical sequential search from <ref> [Knu73] </ref> as 5h=2 + 3 and a typical binary search as 18 lg h + 12 (again these are for h representing maximum depth of the directory, not average) we can solve: 5h=2 + 3 &lt; 18 lg h + 12 A numerical solution gives h &lt; 42:6 as the domain
Reference: [Lar85] <author> Per -Ake Larson. </author> <title> Performance analysis of a single-file version of linear hashing. </title> <journal> Computer Journal, </journal> <volume> 28(3), </volume> <year> 1985. </year>
Reference-contexts: A recurring problem of formal analysis is to provide mathematically tractable models of structures. Commonly used modeling techniques include: Fractional Progress, the analysis of a file in terms of percentage of transition from one mode to another <ref> [Lar85, HB92] </ref>; this fades into Demographics, which studies the populations in various modes [Yao79, Lom81]; and Geometric Transformation, which makes the structure under study similar or equivalent to some other, well-known one [LS90, OM92].
Reference: [Lit80] <author> Witold Litwin. </author> <title> Linear hashing: a new tool for file and table addressing. </title> <booktitle> In VLDB, </booktitle> <pages> pages 212-223, </pages> <year> 1980. </year>
Reference-contexts: Therefore, buckets which cover areas that have had equal numbers of previous insertions are expected to have equal probability of an insertion, independent of the total area of the key-domain which they cover. Clearly the model is not applicable to all file structures. For example, in Linear Hashing <ref> [Lit80] </ref>, full buckets lead into overflow chains.
Reference: [Lom81] <author> David B. Lomet. </author> <title> Digital B-trees. </title> <booktitle> In Proceedings of the 7th Conference on Very Large Data Bases, </booktitle> <pages> pages 333-343, </pages> <month> September </month> <year> 1981. </year>
Reference-contexts: Commonly used modeling techniques include: Fractional Progress, the analysis of a file in terms of percentage of transition from one mode to another [Lar85, HB92]; this fades into Demographics, which studies the populations in various modes <ref> [Yao79, Lom81] </ref>; and Geometric Transformation, which makes the structure under study similar or equivalent to some other, well-known one [LS90, OM92]. Modeling simplifications include studying a structure only as it grows, or only at an hypothesized steady state. <p> However, it seems like a reasonable model. The graph of figure (13) permits us to estimate the asymptotic utilization lim x!1 xb <ref> [Lom81] </ref> provides a solution for steady-state file utilization when S of the data on a split goes to one bucket and (1 S) to another; that solution is given as U = S log 1 1 S When S = 1 2 , this gives us the well-known utilization for a
Reference: [LS90] <author> David B. Lomet and Betty Salzberg. </author> <title> The hB-tree: A multiattribute indexing method with good guaranteed performance. </title> <journal> TODS, </journal> <volume> 15(4), </volume> <month> December </month> <year> 1990. </year>
Reference-contexts: A bucket will contain records which are relatively close to one another if the records are regarded as points in metric space. A variety of such structures have been proposed, among them the K-d-tree [Ben75], the Quadtree [FB74], the Grid File [NHS84], the h-B tree <ref> [LS90] </ref>, and the two structures discussed in this paper, the BANG file [Fre87] and the NIBGF [OM91]. Our particular interest is in comparing file structures and algorithms with formal mathematical analysis. Analytic models permit asymptotic comparisons between algorithms with a nicety unachievable by performance monitoring or simulation. <p> Fractional Progress, the analysis of a file in terms of percentage of transition from one mode to another [Lar85, HB92]; this fades into Demographics, which studies the populations in various modes [Yao79, Lom81]; and Geometric Transformation, which makes the structure under study similar or equivalent to some other, well-known one <ref> [LS90, OM92] </ref>. Modeling simplifications include studying a structure only as it grows, or only at an hypothesized steady state. Especially relevant to us are assumptions about the data distribution; the simplest assumption is that data is uniformly distributed.
Reference: [NHS84] <author> J. Nievergelt, H. Hinterberger, and K. C. Sevcik. </author> <title> The grid file: An adaptable, symmetric multikey file structure. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 9(1), </volume> <month> March </month> <year> 1984. </year>
Reference-contexts: A bucket will contain records which are relatively close to one another if the records are regarded as points in metric space. A variety of such structures have been proposed, among them the K-d-tree [Ben75], the Quadtree [FB74], the Grid File <ref> [NHS84] </ref>, the h-B tree [LS90], and the two structures discussed in this paper, the BANG file [Fre87] and the NIBGF [OM91]. Our particular interest is in comparing file structures and algorithms with formal mathematical analysis.
Reference: [OM91] <author> Aris Ouksel and Otto Mayer. </author> <title> The nested interpolation based grid file. </title> <booktitle> In Mathematical Fundamentals of Database Systems, </booktitle> <pages> pages 173-187. </pages> <publisher> Springer-Verlag, </publisher> <year> 1991. </year>
Reference-contexts: A variety of such structures have been proposed, among them the K-d-tree [Ben75], the Quadtree [FB74], the Grid File [NHS84], the h-B tree [LS90], and the two structures discussed in this paper, the BANG file [Fre87] and the NIBGF <ref> [OM91] </ref>. Our particular interest is in comparing file structures and algorithms with formal mathematical analysis. Analytic models permit asymptotic comparisons between algorithms with a nicety unachievable by performance monitoring or simulation. A recurring problem of formal analysis is to provide mathematically tractable models of structures. <p> One subset of the possible physical implementations include NIBGF directories. We postpone discussion of the physical implementation until section 4, where we compare BANG and NIBGF. 3.1 The BANG Directory Tree A BANG file <ref> [Fre87, OM91] </ref> contains k-field records which are each mapped to a point in [0; 1] k . The file has a directory tree or forest of trees which has one node for each data bucket in the file.
Reference: [OM92] <author> M. Aris Ouksel and Otto Mayer. </author> <title> A robust and efficient spatial data structure. </title> <journal> Acta Informatica, </journal> <volume> 29, </volume> <year> 1992. </year>
Reference-contexts: Fractional Progress, the analysis of a file in terms of percentage of transition from one mode to another [Lar85, HB92]; this fades into Demographics, which studies the populations in various modes [Yao79, Lom81]; and Geometric Transformation, which makes the structure under study similar or equivalent to some other, well-known one <ref> [LS90, OM92] </ref>. Modeling simplifications include studying a structure only as it grows, or only at an hypothesized steady state. Especially relevant to us are assumptions about the data distribution; the simplest assumption is that data is uniformly distributed. <p> In Section 2 we introduce the Capitalist model of file growth as an aid to analyzing file structures. It is contrasted with the Bernoulli and Poisson models developed by [FNPS79, Reg85, Fla83]. In Section 3 we draw upon the file description from <ref> [OM92] </ref>, recasting the notation somewhat. We analyze data bucket splits and apply one variant of the Capitalist model to obtain a probability distribution for the directory tree height in the BANG file. Finally we discuss performance implications with respect to NIBGF. <p> Based on our understanding of the expected height of a directory node, we can immediately predict that the binary search to determine directory level is not likely to be very valuable. In their analysis of search costs, <ref> [OM92] </ref> suggest that lg h is likely bounded by a small constant. We agree; our analysis shows that lg h = lg (p S ln n). <p> For very large bucket sizes, (and uniform distributions), it will be be very improbable to put as few as 1/3 of the data points into a partition. Our graphs in figures (14) and (15) illustrate this. 6 Simulations We coded a metered virtual-memory implementation of a two-dimensional NIBGF <ref> [OM92] </ref> variant of the BANG file [Fre87] and created files with large numbers of buckets, using uniform and normal distributions and bucket capacities of 5, 30, 60, 120 and 500 tuples.
Reference: [Ore83] <author> J. Orenstein. </author> <title> Multidimensional tries used for associative searching. </title> <booktitle> In Proceecdings of the ninth International Conference on Very Large Data Bases, </booktitle> <pages> pages 132-141, </pages> <year> 1983. </year>
Reference-contexts: A descriptor string for a data point can be generated by a perfect shu*e, or Z-ordering <ref> [Ore83] </ref> of the bit values of its k coordinates into a binary string. In Figure 1, which illustrates a two-dimensional file with three data buckets, the root node subspace descriptor would be the empty string "", corresponding to the entire unit square.
Reference: [Reg85] <author> Mireille Regnier. </author> <title> Analysis of grid file algorithms. </title> <journal> BIT, </journal> <volume> 25 </volume> <pages> 335-357, </pages> <year> 1985. </year> <month> 28 </month>
Reference-contexts: We find that the average height of a node in the directory tree is logarithmic in the number of buckets. In Section 2 we introduce the Capitalist model of file growth as an aid to analyzing file structures. It is contrasted with the Bernoulli and Poisson models developed by <ref> [FNPS79, Reg85, Fla83] </ref>. In Section 3 we draw upon the file description from [OM92], recasting the notation somewhat. We analyze data bucket splits and apply one variant of the Capitalist model to obtain a probability distribution for the directory tree height in the BANG file. <p> In a continuous distribution, in the limit as bucket sizes decrease, probabilities of the respective halves of a split bucket converge to one-half. One could imagine a discontinuous function for which the probabilities converge to p 6= (1 p); <ref> [Reg85] </ref> carries out an analysis of grid files for such a distribution function. In the antithesis of continuity, the relative probabilities of the halves of a split bucket might have any value. Of course p + q = 1, but p might have any value between 0 and 1.
Reference: [Tay] <author> Stephen Taylor. </author> <title> An approach for analysis of multidimensional files. Dissertation proposal and on-going work. </title>
Reference: [Yao79] <author> Andrew Chi-Chih Yao. </author> <title> On random 2-3 trees. </title> <journal> Acta Informatica, </journal> <volume> 9(2) </volume> <pages> 159-170, </pages> <year> 1979. </year> <month> 29 </month>
Reference-contexts: Commonly used modeling techniques include: Fractional Progress, the analysis of a file in terms of percentage of transition from one mode to another [Lar85, HB92]; this fades into Demographics, which studies the populations in various modes <ref> [Yao79, Lom81] </ref>; and Geometric Transformation, which makes the structure under study similar or equivalent to some other, well-known one [LS90, OM92]. Modeling simplifications include studying a structure only as it grows, or only at an hypothesized steady state. <p> We outline the basis for two variants of this model: the per-key and the per-bucket approximations. Per-Key approximation The per-Key approximation is a straightforward form of the Capitalist principle. A version of the per-Key approximation was first used by <ref> [Yao79] </ref> in his fringe analysis of the B-tree. Each key in the file is assumed to stake a claim to a portion of the dataspace. <p> Furthermore, for non-uniformly distributed data, the areas covered by buckets are likely to be much better approximations to areas of equal record density than other a priori estimates like equal area. Related Work The Capitalist model differs from <ref> [Yao79] </ref> and related work by Baeza-Yates in that * Although Yao formulated the idea of equally-probable intervals, and used it in the analysis of [Yao79], he did not examine it in detail; the bulk of that analysis deals with transformations between ""fringe" subtrees. * The Capitalist model tracks the statistic "keys <p> Related Work The Capitalist model differs from <ref> [Yao79] </ref> and related work by Baeza-Yates in that * Although Yao formulated the idea of equally-probable intervals, and used it in the analysis of [Yao79], he did not examine it in detail; the bulk of that analysis deals with transformations between ""fringe" subtrees. * The Capitalist model tracks the statistic "keys per bucket" rather than its dual, "data-space per key." * It unifies the "ideal hashing" of [BY89] and "equally probable key-intervals" in a single
References-found: 23

