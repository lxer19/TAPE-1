URL: http://wwwipd.ira.uka.de/~prechelt/Biblio/stop_tricks1997.ps.gz
Refering-URL: 
Root-URL: 
Email: (prechelt@ira.uka.de)  
Title: Early Stopping but when?  
Author: Lutz Prechelt 
Address: D-76128 Karlsruhe; Germany  
Affiliation: Fakultat fur Informatik; Universitat Karlsruhe  
Abstract: Validation can be used to detect when overfitting starts during supervised training of a neural network; training is then stopped before convergence to avoid the overfitting ("early stopping"). The exact criterion used for validation-based early stopping, however, is usually chosen in an ad-hoc fashion or training is stopped interactively. This trick describes how to select a stopping criterion in a systematic fashion; it is a trick for either speeding learning procedures or improving generalization, whichever is more important in the particular situation. An empirical investigation on multi-layer perceptrons shows that there exists a tradeoff between training time and generalization: From the given mix of 1296 training runs using different 12 problems and 24 different network architectures I conclude slower stopping criteria allow for small improvements in generalization (here: about 4% on average), but cost much more training time (here: about factor 4 longer on average).
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> S. Amari, N. Murata, K.-R. Muller, M. Finke, and H. Yang. </author> <booktitle> Statistical theory of overtraining is cross-validation effective? In [23], </booktitle> <pages> pages 176-182, </pages> <year> 1996. </year>
Reference-contexts: learning tasks lead to which differences in stopping criteria behavior. 4 Why this works Detailed theoretical analyses of the error curves cannot yet be done for the most interesting cases such as sigmoidal multi-layer perceptrons trained on a modest number of examples; today they are possible for restricted scenarios only <ref> [1, 2, 3, 24] </ref> and do usually not aim at finding the optimal stopping criterion in a way comparable to the present work. <p> If we train long enough, the error will be dominated by the complexity error (phase III). Therefore, there is a phase during training, when the approximation and complexity (or: bias and variance) components of the error compete but none of them dominates (phase II). See Amari et al. <ref> [1, 2] </ref> for yet another view of the training process, using a geometrical interpretation. The task of early stopping as described in the present work is to detect when phase II ends and the dominance of the variance part begins. <p> Published theoretical results on early stopping appear to provide some nice techniques for practical application: Wang et al. [24] offer a method for computing the stopping point based on complexity considerations | without using a separate validation set at all. This could save precious training examples. Amari et al. <ref> [1, 2] </ref> compute the optimal split proportion of training data into training and validation set. On the other hand, unfortunately, the practical applicability of these theoretical analyses is severely restricted. Wang et al.'s analysis applies to networks where only output weights are being trained; no hidden layer training is captured.
Reference: 2. <author> S. Amari, N. Murata, K.-R. Muller, M. Finke, and H. Yang. </author> <title> Aymptotic statistical theory of overtraining and cross-validation. </title> <journal> IEEE Trans. on Neural Networks, </journal> <volume> 8(5) </volume> <pages> 985-996, </pages> <month> September </month> <year> 1997. </year>
Reference-contexts: learning tasks lead to which differences in stopping criteria behavior. 4 Why this works Detailed theoretical analyses of the error curves cannot yet be done for the most interesting cases such as sigmoidal multi-layer perceptrons trained on a modest number of examples; today they are possible for restricted scenarios only <ref> [1, 2, 3, 24] </ref> and do usually not aim at finding the optimal stopping criterion in a way comparable to the present work. <p> If we train long enough, the error will be dominated by the complexity error (phase III). Therefore, there is a phase during training, when the approximation and complexity (or: bias and variance) components of the error compete but none of them dominates (phase II). See Amari et al. <ref> [1, 2] </ref> for yet another view of the training process, using a geometrical interpretation. The task of early stopping as described in the present work is to detect when phase II ends and the dominance of the variance part begins. <p> Published theoretical results on early stopping appear to provide some nice techniques for practical application: Wang et al. [24] offer a method for computing the stopping point based on complexity considerations | without using a separate validation set at all. This could save precious training examples. Amari et al. <ref> [1, 2] </ref> compute the optimal split proportion of training data into training and validation set. On the other hand, unfortunately, the practical applicability of these theoretical analyses is severely restricted. Wang et al.'s analysis applies to networks where only output weights are being trained; no hidden layer training is captured.
Reference: 3. <author> Pierre Baldi and Yves Chauvin. </author> <title> Temporal evolution of generalization during learning in linear networks. </title> <journal> Neural Computation, </journal> <volume> 3 </volume> <pages> 589-603, </pages> <year> 1991. </year>
Reference-contexts: learning tasks lead to which differences in stopping criteria behavior. 4 Why this works Detailed theoretical analyses of the error curves cannot yet be done for the most interesting cases such as sigmoidal multi-layer perceptrons trained on a modest number of examples; today they are possible for restricted scenarios only <ref> [1, 2, 3, 24] </ref> and do usually not aim at finding the optimal stopping criterion in a way comparable to the present work.
Reference: 4. <editor> Jack D. Cowan, Gerald Tesauro, and J. Alspector, editors. </editor> <booktitle> Advances in Neural Information Processing Systems 6, </booktitle> <address> San Mateo, CA, 1994. </address> <publisher> Morgan Kaufman Publishers Inc. </publisher>
Reference: 5. <author> Yann Le Cun, John S. Denker, and Sara A. Solla. </author> <title> Optimal brain damage. </title> <booktitle> In [22], </booktitle> <pages> pages 598-605, </pages> <year> 1990. </year>
Reference-contexts: There are basically two ways to fight overfitting: reducing the number of dimensions of the parameter space or reducing the effective size of each dimension. Techniques for reducing the number of parameters are greedy constructive learning [7], pruning <ref> [5, 12, 14] </ref>, or weight sharing [18]. Techniques for reducing the size of each parameter dimension are regularization, such as weight decay [13] and others [25], or early stopping [17]. See also [8, 20] for an overview and [9] for an experimental comparison.
Reference: 6. <author> Scott E. Fahlman. </author> <title> An empirical study of learning speed in back-propagation networks. </title> <type> Technical Report CMU-CS-88-162, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <address> Pittsburgh, PA, </address> <month> September </month> <year> 1988. </year>
Reference-contexts: RPROP is a fast backpropagation variant that is about as fast as quickprop <ref> [6] </ref> but more stable without adjustment of the parameters. RPROP requires epoch learning, i.e., the weights are updated only once per epoch. Therefore, the algorithm is fast without parameter tuning for small training sets but not recommendable for large training sets.
Reference: 7. <author> Scott E. Fahlman and Christian Lebiere. </author> <booktitle> The Cascade-Correlation learning architecture. In [22], </booktitle> <pages> pages 524-532, </pages> <year> 1990. </year>
Reference-contexts: There are basically two ways to fight overfitting: reducing the number of dimensions of the parameter space or reducing the effective size of each dimension. Techniques for reducing the number of parameters are greedy constructive learning <ref> [7] </ref>, pruning [5, 12, 14], or weight sharing [18]. Techniques for reducing the size of each parameter dimension are regularization, such as weight decay [13] and others [25], or early stopping [17]. See also [8, 20] for an overview and [9] for an experimental comparison.
Reference: 8. <author> Emile Fiesler (efiesler@idiap.ch). </author> <title> Comparative bibliography of ontogenic neural networks. </title> <note> (submitted for publication), </note> <year> 1994. </year>
Reference-contexts: Techniques for reducing the number of parameters are greedy constructive learning [7], pruning [5, 12, 14], or weight sharing [18]. Techniques for reducing the size of each parameter dimension are regularization, such as weight decay [13] and others [25], or early stopping [17]. See also <ref> [8, 20] </ref> for an overview and [9] for an experimental comparison.
Reference: 9. <author> William Finnoff, Ferdinand Hergert, and Hans Georg Zimmermann. </author> <title> Improving model selection by nonconvergent methods. </title> <booktitle> Neural Networks, </booktitle> <volume> 6 </volume> <pages> 771-783, </pages> <year> 1993. </year>
Reference-contexts: Techniques for reducing the size of each parameter dimension are regularization, such as weight decay [13] and others [25], or early stopping [17]. See also [8, 20] for an overview and <ref> [9] </ref> for an experimental comparison. Early stopping is widely used because it is simple to understand and implement and has been reported to be superior to regularization methods in many cases, e.g. in [9]. 1.2 The basic early stopping technique In most introductory papers on supervised neural network training one can <p> See also [8, 20] for an overview and <ref> [9] </ref> for an experimental comparison. Early stopping is widely used because it is simple to understand and implement and has been reported to be superior to regularization methods in many cases, e.g. in [9]. 1.2 The basic early stopping technique In most introductory papers on supervised neural network training one can find a diagram similar to the one shown in Figure 1.
Reference: 10. <author> Stuart Geman, Elie Bienenstock, and Rene Doursat. </author> <title> Neural networks and the bias/variance dilemma. </title> <journal> Neural Computation, </journal> <volume> 4 </volume> <pages> 1-58, </pages> <year> 1992. </year>
Reference-contexts: 1 Early stopping is not quite as simple 1.1 Why early stopping? When training a neural network, one is usually interested in obtaining a network with optimal generalization performance. However, all standard neural network architectures such as the fully connected multi-layer perceptron are prone to overfitting <ref> [10] </ref>: While the network seems to get better and better, i.e., the error on the training set decreases, at some point during training it actually begins to get worse again, i.e., the error on unseen examples increases. <p> However, a simplification of the analysis performed by Wang et al. [24] or the alternative view induced by the bias/variance decomposition of the error as described by Geman et al. <ref> [10] </ref> can give some insights why early stopping behaves as it does. At the beginning of training (phase I), the error is dominated by what Wang et al. call the approximation error | the network has hardly learned anything and is still very biased.
Reference: 11. <editor> Stephen J. Hanson, Jack D. Cowan, and C. Lee Giles, editors. </editor> <booktitle> Advances in Neural Information Processing Systems 5, </booktitle> <address> San Mateo, CA, 1993. </address> <publisher> Morgan Kaufman Publishers Inc. </publisher>
Reference: 12. <author> Babak Hassibi and David G. Stork. </author> <title> Second order derivatives for network pruning: Optimal brain surgeon. </title> <booktitle> In [11], </booktitle> <pages> pages 164-171, </pages> <year> 1993. </year>
Reference-contexts: There are basically two ways to fight overfitting: reducing the number of dimensions of the parameter space or reducing the effective size of each dimension. Techniques for reducing the number of parameters are greedy constructive learning [7], pruning <ref> [5, 12, 14] </ref>, or weight sharing [18]. Techniques for reducing the size of each parameter dimension are regularization, such as weight decay [13] and others [25], or early stopping [17]. See also [8, 20] for an overview and [9] for an experimental comparison.
Reference: 13. <author> Anders Krogh and John A. Hertz. </author> <title> A simple weight decay can improve generalization. </title> <booktitle> In [16], </booktitle> <pages> pages 950-957, </pages> <year> 1992. </year>
Reference-contexts: Techniques for reducing the number of parameters are greedy constructive learning [7], pruning [5, 12, 14], or weight sharing [18]. Techniques for reducing the size of each parameter dimension are regularization, such as weight decay <ref> [13] </ref> and others [25], or early stopping [17]. See also [8, 20] for an overview and [9] for an experimental comparison.
Reference: 14. <author> Asriel U. Levin, Todd K. Leen, and John E. Moody. </author> <title> Fast pruning using principal components. </title> <booktitle> In [4], </booktitle> <year> 1994. </year>
Reference-contexts: There are basically two ways to fight overfitting: reducing the number of dimensions of the parameter space or reducing the effective size of each dimension. Techniques for reducing the number of parameters are greedy constructive learning [7], pruning <ref> [5, 12, 14] </ref>, or weight sharing [18]. Techniques for reducing the size of each parameter dimension are regularization, such as weight decay [13] and others [25], or early stopping [17]. See also [8, 20] for an overview and [9] for an experimental comparison.
Reference: 15. <editor> Richard P. Lippmann, John E. Moody, and David S. Touretzky, editors. </editor> <booktitle> Advances in Neural Information Processing Systems 3, </booktitle> <address> San Mateo, CA, 1991. </address> <publisher> Morgan Kauf-man Publishers Inc. </publisher>
Reference: 16. <editor> John E. Moody, Stephen J. Hanson, and Richard P. Lippmann, editors. </editor> <booktitle> Advances in Neural Information Processing Systems 4, </booktitle> <address> San Mateo, CA, 1992. </address> <publisher> Morgan Kauf-man Publishers Inc. </publisher>
Reference: 17. <author> N. Morgan and H. Bourlard. </author> <title> Generalization and parameter estimation in feedfor-ward nets: Some experiments. </title> <booktitle> In [22], </booktitle> <pages> pages 630-637, </pages> <year> 1990. </year>
Reference-contexts: Techniques for reducing the number of parameters are greedy constructive learning [7], pruning [5, 12, 14], or weight sharing [18]. Techniques for reducing the size of each parameter dimension are regularization, such as weight decay [13] and others [25], or early stopping <ref> [17] </ref>. See also [8, 20] for an overview and [9] for an experimental comparison.
Reference: 18. <author> Steven J. Nowlan and Geoffrey E. Hinton. </author> <title> Simplifying neural networks by soft weight-sharing. </title> <journal> Neural Computation, </journal> <volume> 4(4) </volume> <pages> 473-493, </pages> <year> 1992. </year>
Reference-contexts: There are basically two ways to fight overfitting: reducing the number of dimensions of the parameter space or reducing the effective size of each dimension. Techniques for reducing the number of parameters are greedy constructive learning [7], pruning [5, 12, 14], or weight sharing <ref> [18] </ref>. Techniques for reducing the size of each parameter dimension are regularization, such as weight decay [13] and others [25], or early stopping [17]. See also [8, 20] for an overview and [9] for an experimental comparison.
Reference: 19. <author> Lutz Prechelt. </author> <title> PROBEN1 | A set of benchmarks and benchmarking rules for neural network training algorithms. </title> <type> Technical Report 21/94, </type> <institution> Fakultat fur Informatik, Universitat Karlsruhe, Germany, </institution> <month> September </month> <year> 1994. </year> <note> Anonymous FTP: /pub/papers/techreports/1994/1994-21.ps.gz on ftp.ira.uka.de. </note>
Reference-contexts: All criteria where evaluated simultaneously, i.e., each single training run returned one result for each of the criteria. This approach reduces the variance of the estimation. Learning tasks: Twelve different problems were used, all from the Proben1 NN benchmark set <ref> [19] </ref>. All problems are real datasets from realistic application domains; they form a sample of a broad class of domains, but none of them exhibits extreme nonlinearity. The problems have between 8 and 120 inputs, between 1 and 19 outputs, and between 214 and 7200 examples. <p> All criteria are more or less instable for the building, cancer, and thyroid problems. In particular, all GL criteria have huge problems with the building problem, whose dataset 1 is the only one that is partitioned non-randomly; it uses chronological order of examples, see <ref> [19] </ref>. The slower variants of the other criteria types are nicely robust in this case. Similar statements apply when one analyzes the influence of only large or only small network topologies separately (not shown in any figure or table).
Reference: 20. <author> Russel Reed. </author> <title> Pruning algorithms | a survey. </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> 4(5) </volume> <pages> 740-746, </pages> <year> 1993. </year>
Reference-contexts: Techniques for reducing the number of parameters are greedy constructive learning [7], pruning [5, 12, 14], or weight sharing [18]. Techniques for reducing the size of each parameter dimension are regularization, such as weight decay [13] and others [25], or early stopping [17]. See also <ref> [8, 20] </ref> for an overview and [9] for an experimental comparison.
Reference: 21. <author> Martin Riedmiller and Heinrich Braun. </author> <title> A direct adaptive method for faster back-propagation learning: The RPROP algorithm. </title> <booktitle> In Proc. of the IEEE Intl. Conf. on Neural Networks, </booktitle> <pages> pages 586-591, </pages> <address> San Francisco, CA, </address> <month> April </month> <year> 1993. </year>
Reference-contexts: For each of the network topologies and each dataset, two runs were made with linear output units and one with sigmoidal output units using the activation function f (x) = x=(1 + jxj). Training algorithm: All runs were done using the RPROP training algorithm <ref> [21] </ref> using the squared error function and the parameters + = 1:1, = 0:5, 0 2 0:05 : : : 0:2 randomly per weight, max = 50, min = 0, initial weights 0:5 : : : 0:5 randomly.
Reference: 22. <editor> David S. Touretzky, editor. </editor> <booktitle> Advances in Neural Information Processing Systems 2, </booktitle> <address> San Mateo, CA, 1990. </address> <publisher> Morgan Kaufman Publishers Inc. </publisher>
Reference: 23. <editor> D.S. Touretzky, M.C. Mozer, and M.E. Hasselmo, editors. </editor> <booktitle> Advances in Neural Information Processing Systems 8, </booktitle> <address> Cambridge, MA, 1996. </address> <publisher> MIT Press. </publisher>
Reference: 24. <author> Changfeng Wang, Santosh S. Venkatesh, and J. Stephen Judd. </author> <title> Optimal stopping and effective machine complexity in learning. </title> <booktitle> In [4], </booktitle> <year> 1994. </year>
Reference-contexts: learning tasks lead to which differences in stopping criteria behavior. 4 Why this works Detailed theoretical analyses of the error curves cannot yet be done for the most interesting cases such as sigmoidal multi-layer perceptrons trained on a modest number of examples; today they are possible for restricted scenarios only <ref> [1, 2, 3, 24] </ref> and do usually not aim at finding the optimal stopping criterion in a way comparable to the present work. <p> However, a simplification of the analysis performed by Wang et al. <ref> [24] </ref> or the alternative view induced by the bias/variance decomposition of the error as described by Geman et al. [10] can give some insights why early stopping behaves as it does. <p> The task of early stopping as described in the present work is to detect when phase II ends and the dominance of the variance part begins. Published theoretical results on early stopping appear to provide some nice techniques for practical application: Wang et al. <ref> [24] </ref> offer a method for computing the stopping point based on complexity considerations | without using a separate validation set at all. This could save precious training examples. Amari et al. [1, 2] compute the optimal split proportion of training data into training and validation set.
Reference: 25. <author> Andreas S. Weigend, David E. Rumelhart, and Bernardo A. Huberman. </author> <title> Generalization by weight-elimination with application to forecasting. </title> <booktitle> In [15], </booktitle> <pages> pages 875-882, </pages> <year> 1991. </year> <title> This article was processed using the L A T E X macro package with LLNCS style </title>
Reference-contexts: Techniques for reducing the number of parameters are greedy constructive learning [7], pruning [5, 12, 14], or weight sharing [18]. Techniques for reducing the size of each parameter dimension are regularization, such as weight decay [13] and others <ref> [25] </ref>, or early stopping [17]. See also [8, 20] for an overview and [9] for an experimental comparison.
References-found: 25

