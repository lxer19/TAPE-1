URL: http://www.cis.upenn.edu/~gbierner/research/TraumaTalk/amia98.ps.gz
Refering-URL: http://www.cis.upenn.edu/~gbierner/research/TraumaTalk/index.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: gbierner@linc.cis.upenn.edu  
Title: TraumaTalk: Content-to-Speech Generation for Decision Support at Point of Care  
Author: Gann Bierner 
Affiliation: Department of Computer and Information Science University of Pennsylvania  
Abstract: Communicating information in clinical environments is a crucial concern for medical decision support systems. Some systems can provide this support through text output that can be read by the clinician either from a screen or hard copy. However, it has been noted that speech is often a more appropriate way of conveying information, especially in cases where the decision maker's eyes are already committed to another task or in cases where the telephone is the mode of communication. Some systems synthesize speech directly from text, while others piece together bits of pre-recorded human speech. In both such systems, producing correct intonation is vital because intonation, in English and other languages, both aids the listener's comprehension and conveys discourse meaning not necessarily evident in the words alone. Although systems that use text-to-speech or human recorded speech segments sometimes attempt to provide good intonation, they are severely hampered by the fact that intonation spans entire clauses. Systems that put together phonemes, words, or phrases fail to capture this. My research provides a content-to-speech system that provides spoken decision support for trauma care that is correctly intoned over full clauses. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> L. Lenert, D. Michaelson, M. Bergen, and M. Parineh. </author> <title> Use of synthesized speech in automated computer interviews. </title> <type> Technical Report 3, </type> <institution> Stanford University, Stanford Center for the Study of Patient Preferences, </institution> <year> 1996. </year>
Reference-contexts: However, it has been noted that speech is often a more appropriate way of conveying information, especially in cases where the decision maker's eyes are already committed to another task or in cases where the telephone is the mode of communication <ref> [2, 1] </ref>. Some systems synthesize speech directly from text, while others piece together bits of pre-recorded human speech.
Reference: [2] <author> L. Lenert, D. Michaelson, C. Flowers, and M. Bergen. </author> <title> Impact: an object-oriented graphical environment for contruction of multimedia patient interviewing software. </title> <editor> In R. Gardner, editor, </editor> <booktitle> Proc. of the 19th Annual Symposium on Computer Applications in Medical Care, </booktitle> <address> Philadelphia, </address> <year> 1995. </year>
Reference-contexts: However, it has been noted that speech is often a more appropriate way of conveying information, especially in cases where the decision maker's eyes are already committed to another task or in cases where the telephone is the mode of communication <ref> [2, 1] </ref>. Some systems synthesize speech directly from text, while others piece together bits of pre-recorded human speech.
Reference: [3] <author> J. Pierrehumbert and J. Hirschberg. </author> <title> The meaning of intonational contours in the interpretation of discourse. </title> <booktitle> In Intentions in Communication, </booktitle> <pages> pages 271-312, </pages> <year> 1990. </year>
Reference-contexts: Some systems synthesize speech directly from text, while others piece together bits of pre-recorded human speech. In both such systems, producing correct intonation is vital because intonation, in English and other languages, both aids the listener's comprehension and conveys discourse meaning not necessarily evident in the words alone <ref> [8, 3] </ref>. Although systems that use text-to-speech or human recorded speech segments sometimes attempt to provide good intonation, they are severely hampered by the fact that intonation spans entire clauses. Systems that put together phonemes, words, or phrases fail to capture this. <p> Background Intonation Intonation can be described as the assignment to an utterance of particular melodies, consisting of boundary tones and pitch accents. We use Pierre-humbert's notation <ref> [3] </ref> where the prosodic building blocks are H and L which conform respectively to the intuitive notion of high and low pitch. Pitch accents consist of Ls and Hs connected with `+' signs, with a `*' somewhere in the string.
Reference: [4] <author> S. Prevost and M. Steedman. </author> <title> Specifying intonation from context for speech synthesis. </title> <journal> Speech Communication, </journal> <pages> pages 139-153, </pages> <year> 1994. </year>
Reference-contexts: Abdomen, on the other hand, differentiates the abdominal x-ray from the previously mentioned chest x-ray and therefore receives contrastive stress. We use an algorithm from computing contrastive stress devised by Prevost <ref> [4] </ref>. Given an entity, the algorithm first computes a set of all of its alternatives currently in the discourse.
Reference: [5] <author> J. Sowa. </author> <title> Conceptual graphs. </title> <journal> IBM Journal of Research and Development, </journal> <month> July, </month> <year> 1976. </year>
Reference-contexts: Intuitively, more tenuously related entities contrast less than those more strongly related. Therefore their contrasting properties are given less contrastive stress. Contrasting Entities Given an alternative set, the algorithm must determine the differentiating properties of its members. An entity representation in terms of conceptual graphs <ref> [5] </ref> allows us to do this. The nodes of a conceptual graph are concepts (rectangular boxes) or relations (eliptical boxes), where concepts may be connected only to relations and relations to concepts. Semantically, conceptual graphs are equivalent to first order logic.
Reference: [6] <author> R. Sproat, </author> <title> editor. Multilingual Text-to-Speech Synthesis: The Bell Labs Approach. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, </address> <month> October </month> <year> 1997. </year>
Reference-contexts: This detrimentally affects intelligibility and may cause the physician difficulty in understanding the utterance. When not faced with intonational choices that require some understanding of context, text-to-speech systems such as TTS <ref> [6] </ref> often do a reasonable job. (TTS is the system we use to realize our annotated text as synthesized speech.) Therefore, TraumaTalk heavily annotates entities with prosodic clues but allows TTS to handle most other aspects of the sentence.
Reference: [7] <author> M. Steedman. </author> <title> Structure and intonation. </title> <booktitle> Language, </booktitle> <volume> 67 </volume> <pages> 260-296, </pages> <year> 1991. </year>
Reference-contexts: The "Meaning" of Intonation Prosodic melodies divide an utterance into prosodic constituents that correspond to its theme and rheme. The theme of an utterance is the open proposition that is currently under scrutiny. The rheme of the utterance provides a specific entity that satisfies the proposition. More formally, Steedman <ref> [7] </ref> defines theme and rheme as in (2). (2) Theme: The alternative set associated with an utterance. Rheme: Restricts the alternative set. (3) Who is on call? (Dr.
Reference: [8] <author> P. Taylor, H. Shimodaira, S. Isard, S. King, and J. Kowtko. </author> <title> Using prosodic information to constrain language models for spoken dialogue. </title> <booktitle> In Proc. of the 2nd Int'l Symposium on Spoken Dialogue, </booktitle> <pages> pages 129-132, </pages> <address> Philadelphia, </address> <month> October </month> <year> 1996. </year>
Reference-contexts: Some systems synthesize speech directly from text, while others piece together bits of pre-recorded human speech. In both such systems, producing correct intonation is vital because intonation, in English and other languages, both aids the listener's comprehension and conveys discourse meaning not necessarily evident in the words alone <ref> [8, 3] </ref>. Although systems that use text-to-speech or human recorded speech segments sometimes attempt to provide good intonation, they are severely hampered by the fact that intonation spans entire clauses. Systems that put together phonemes, words, or phrases fail to capture this.
Reference: [9] <author> B. Webber, S. Carberry, J. Clarke, A. Gertner, T. Harvey, R. Rymon, and R. </author> <title> Washington. Providing decision support in multiple trauma management: Recognizing multiple goals, adopting multiple intentions. </title> <journal> Submitted to the Artificial Intelligence Journal, special issue on Artificial Intelligence in Medicine, </journal> <month> September </month> <year> 1997. </year>
Reference-contexts: Introduction Communicating information in clinical environments is a crucial concern for medical decision support systems. Some systems can provide this support through text output that will be read by the clinician either from a screen or hard copy <ref> [9] </ref>. However, it has been noted that speech is often a more appropriate way of conveying information, especially in cases where the decision maker's eyes are already committed to another task or in cases where the telephone is the mode of communication [2, 1]. <p> Systems that put together phonemes, words, or phrases fail to capture this. Our research provides a content-to-speech system that provides spoken decision support for trauma care that is correctly intoned over full clauses. TraumAID, TraumaTIQ, and TraumaGEN <ref> [9] </ref> comprise a system that provides decision support for emergency room physicians by formulating a plan, assessing the physician's orders against this plan, and then communicating the resulting critique in coherent text segments.
References-found: 9

