URL: ftp://ftp.cs.columbia.edu/pub/CAVE/papers/nayar/nayar-murase-nene-parametric-appearance.ps
Refering-URL: http://www.cs.columbia.edu/~sameer/publications.html
Root-URL: http://www.cs.columbia.edu
Title: 6 Parametric Appearance Representation  
Author: Shree K. Nayar Hiroshi Murase Sameer A. Nene 
Affiliation: Columbia University  NTT Basic Research Laboratory  Columbia University  
Abstract: In contrast to the traditional approach, the recognition problem is formulated as one of matching appearance rather than shape. For any given vision task, all possible appearance variations define its visual workspace. A set of images is obtained by coarsely sampling the workspace. The image set is compressed to obtain a low-dimensional subspace, called the eigen-space, in which the visual workspace is represented as a continuous appearance manifold. Given an unknown input image, the recognition system first projects the image to eigenspace. The parameters of the vision task are recognized based on the exact position of the projection on the appearance manifold. The proposed appearance representation has several applications in visual perception. As examples, a real-time recognition system with 20 complex objects, an illumination planning technique for robust object recognition, and a real-time visual positioning and tracking system are described. The simplicity and generality of the proposed ideas have led to the development of a comprehensive software library for appearance modeling and matching.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Baker and S. K. Nayar, </author> <title> "A Theory of Pattern Rejection," </title> <type> Tech. Rep. </type> <institution> CUCS-013-95, Dept. of Computer Science, Columbia Univ., </institution> <month> May </month> <year> 1995. </year>
Reference-contexts: Two different techniques have been tested for determining the closest manifold point, one is based on binary search [30] and other uses an input-output mapping network [15]. We have achieved further speed-up in recognition by developing a comprehensive theory and a novel algorithm for pattern rejection <ref> [1] </ref>. Will appearance representation suffice? Given the large number of parameters that affect appearance, it does not suggest itself as a replacement for shape representation. In fact, our experiments on recognition and robot tracking show that appearance models are in many ways complementary to shape models. <p> Recently, it was shown that the notion of pattern rejection <ref> [1] </ref> can be used to very quickly eliminate a large fraction of classes (manifolds) stored in the database. The result is a small set of candidates that can be viewed as a substantially reduced database for the input vector (pattern) in question.
Reference: [2] <author> A. H. Barr, </author> <title> "Superquadric and Angle Preserving Transformations," </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> Vol. 1, No. 1, </volume> <pages> pp. 11-23, </pages> <month> Jan. </month> <year> 1981. </year>
Reference: [3] <author> P. J. Besl and R. C. Jain, </author> <title> "Three-Dimensional Object Recognition," </title> <journal> Computing Surveys, </journal> <volume> Vol. 17, No. 1, </volume> <pages> pp. 75-145, </pages> <month> Mar. </month> <year> 1985. </year>
Reference-contexts: 1. Introduction Vision research has placed significant emphasis on the development of compact and descriptive shape representations for object recognition <ref> [39, 3, 23] </ref>. This has lead to the creation of a variety of novel representations, including, generalized cylinders [4], superquadrics [2][33], extended gaussian images [10], parametric bicubic patches [23] and differential geometric representations [5], only to name 131 132 NAYAR, MURASE, AND NENE a few.
Reference: [4] <author> T. O. Binford, </author> <title> "Generalized Cylinder Representation," </title> <booktitle> Encyclopedia of Artificial Intelligence, </booktitle> <editor> S. C. Sahpiro, Ed., </editor> <publisher> John Wiley & Sons, </publisher> <address> New York, </address> <pages> pp. 321-323, </pages> <year> 1987. </year>
Reference-contexts: 1. Introduction Vision research has placed significant emphasis on the development of compact and descriptive shape representations for object recognition [39, 3, 23]. This has lead to the creation of a variety of novel representations, including, generalized cylinders <ref> [4] </ref>, superquadrics [2][33], extended gaussian images [10], parametric bicubic patches [23] and differential geometric representations [5], only to name 131 132 NAYAR, MURASE, AND NENE a few. While these representations are all useful in specific application domains, each has been found to have its own drawbacks.
Reference: [5] <author> M. Brady, J. Ponce, A. Yuille, and H. Asada, </author> <title> "Describing Surfaces," Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> Vol. 32, </volume> <pages> pp. 1-28, </pages> <year> 1985. </year>
Reference-contexts: This has lead to the creation of a variety of novel representations, including, generalized cylinders [4], superquadrics [2][33], extended gaussian images [10], parametric bicubic patches [23] and differential geometric representations <ref> [5] </ref>, only to name 131 132 NAYAR, MURASE, AND NENE a few. While these representations are all useful in specific application domains, each has been found to have its own drawbacks. This has kept researchers in search for more powerful representations.
Reference: [6] <author> W. H Chen, H. Smith, and S. C. Fralick, </author> <title> "A Fast Computational Algorithm for the Discrete Cosine Transform," </title> <journal> IEEE Transactions on Communications, </journal> <volume> Vol. 25, </volume> <pages> pp. 1004-1009, </pages> <year> 1977. </year>
Reference-contexts: They observe that the computation of ~ Q from the image matrix P is itself expensive. Therefore, each image in P is divided into "blocks" and image data in each block is compressed using the discrete cosine transform (DCT) <ref> [6] </ref>. Due to spatial correlation within an image, each image block is typically represented by a small number of DCT coefficients. Further, blocks at the same location in consecutive images are often highly correlated and have the same DCT coefficients.
Reference: [7] <author> R. T. Chin and C. R. Dyer, </author> <title> "Model-Based Recognition in Robot Vision," </title> <journal> ACM Computing Surveys, </journal> <volume> Vol. 18, No. 1, </volume> <pages> pp. 67-108, </pages> <year> 1986. </year>
Reference: [8] <author> R. Epstein, P. W. Hallinan, and A. L. Yuille, </author> <title> "52 Eigenimages Suffice: An Empirical Investigation of Low-Dimensional Lighting Models," </title> <booktitle> Proc. of 158 NAYAR, MURASE, AND NENE IEEE Workshop on Physics Based Modeling in Computer Vision, </booktitle> <pages> pp. 108-116, </pages> <address> Boston, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: Alternatively, the dimensionality of the illumination manifold is exactly 3. This result is supported by a detailed empirical investigation reported recently in <ref> [8] </ref>. In [26] we use the above bound on the manifold dimensionality to show that novel images of the object can be recognized from just three projections on the illumination manifold without the explicit construction of the manifold.
Reference: [9] <author> K. Fukunaga, </author> <title> Introduction to Statistical Pattern Recognition, </title> <publisher> Academic Press, </publisher> <address> London, </address> <year> 1990. </year>
Reference-contexts: The problem then is to compress this large image set to a low-dimensional representation of object appearance. A well-known image compression or coding technique is based on principal component analysis, also known as the Karhunen-Loeve transform [32] <ref> [9] </ref>. It uses the eigenvectors of an image set as orthogonal bases for representing individual 6. PARAMETRIC APPEARANCE REPRESENTATION 133 images in the set.
Reference: [10] <author> B. K. P. Horn, </author> <title> "Extended Gaussian Images," </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> Vol. 72, No. 12, </volume> <pages> pp. 1671-1686, </pages> <month> Dec. </month> <year> 1984. </year>
Reference-contexts: 1. Introduction Vision research has placed significant emphasis on the development of compact and descriptive shape representations for object recognition [39, 3, 23]. This has lead to the creation of a variety of novel representations, including, generalized cylinders [4], superquadrics [2][33], extended gaussian images <ref> [10] </ref>, parametric bicubic patches [23] and differential geometric representations [5], only to name 131 132 NAYAR, MURASE, AND NENE a few. While these representations are all useful in specific application domains, each has been found to have its own drawbacks. This has kept researchers in search for more powerful representations.
Reference: [11] <author> A. S. </author> <title> Householder, The theory of matrices in numerical analysis, </title> <publisher> Dover Publications, </publisher> <address> New York, </address> <year> 1964. </year>
Reference-contexts: Displacements are in three dimensions (x, y, ). Histograms of absolute positioning error (in mm) for (g) 5-D eigenspace and (h) 10-D eigenspace. 152 NAYAR, MURASE, AND NENE ifolds, and orthogonalization <ref> [11] </ref> of multiple subspaces. Finally, the recognition module includes efficient search implementations [30] that find manifold points that lie closest to novel input projections. All four modules can be accessed via an intuitive graphical interface built on X/Motif.
Reference: [12] <author> R. A. Hummel, </author> <title> "Feature Detection Using Basis Functions," </title> <journal> Computer Graphics and Image Processing, </journal> <volume> Vol. 9, </volume> <pages> pp. 40-55, </pages> <year> 1979. </year>
Reference-contexts: A suitable compression technique is based on principal component analysis [32], where the eigenvectors of the image set are computed and used as orthogonal bases for representing individual images. Principal component analysis has been previously used in computer vision for deriving basis functions for feature detection <ref> [12] </ref> [13], representing human face images [42], and recognizing face images [43] [34]. Though, in general, all the eigenvectors of an image set are required for perfect reconstruction of any particular image, only a few are sufficient for visual recognition.
Reference: [13] <author> R. Lenz, </author> <title> "Optimal Filters for the Detection of Linear Patterns in 2-D and Higher Dimensional Images," </title> <journal> Pattern Recognition, </journal> <volume> Vol. 20, No. 2, </volume> <pages> pp. 163-172, </pages> <year> 1987. </year>
Reference-contexts: A suitable compression technique is based on principal component analysis [32], where the eigenvectors of the image set are computed and used as orthogonal bases for representing individual images. Principal component analysis has been previously used in computer vision for deriving basis functions for feature detection [12] <ref> [13] </ref>, representing human face images [42], and recognizing face images [43] [34]. Though, in general, all the eigenvectors of an image set are required for perfect reconstruction of any particular image, only a few are sufficient for visual recognition.
Reference: [14] <author> N. K. Logothetis, J. Pauls, H. H. Bulthoff, and T. Poggio, </author> <title> "View-dependent object recognition by monkeys," </title> <booktitle> Current Biology, </booktitle> <volume> Vol. 4, No. 5, </volume> <pages> pp. 401-414, </pages> <year> 1994. </year>
Reference: [15] <author> S. Mukherjee and S. K. Nayar, </author> <title> "Optimal RBF Networks for Visual Learning," </title> <booktitle> Proc. of Fifth Int'l. Conf. on Computer Vision, </booktitle> <address> Boston, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: Two different techniques have been tested for determining the closest manifold point, one is based on binary search [30] and other uses an input-output mapping network <ref> [15] </ref>. We have achieved further speed-up in recognition by developing a comprehensive theory and a novel algorithm for pattern rejection [1]. Will appearance representation suffice? Given the large number of parameters that affect appearance, it does not suggest itself as a replacement for shape representation. <p> This algorithm uses a carefully designed data structure to facilitate quick search through the multi-dimensional ei-genspace in O ( k log 2 n ). This approach is particularly effective when the number of manifold points is relatively small. The second approach <ref> [15] </ref> uses three-layered radial basis function (RBF) networks proposed by Poggio and Girosi [36] to learn the mapping between input points and manifold parameters (object number and pose). The complexity of the network approach depends on the number of networks used and their sizes. In [15] a new framework is introduced <p> The second approach <ref> [15] </ref> uses three-layered radial basis function (RBF) networks proposed by Poggio and Girosi [36] to learn the mapping between input points and manifold parameters (object number and pose). The complexity of the network approach depends on the number of networks used and their sizes. In [15] a new framework is introduced that uses the wavelet integral transform for finding the smallest RBF network to accomplish any given input-output mapping. The performance of the network based scheme is generally comparable to that of the binary search approach. <p> The network implicitly interpolates, or reconstructs, manifolds from the discrete eigenspace points f j and therefore does not require the use of spline interpolation followed by the resampling of manifolds. This advantage however comes with a slight sacrifice in parameter estimation accuracy <ref> [15] </ref>. 5. Object recognition and pose estimation We have used appearance models for 3-D object recognition and pose estimation [18] [19].
Reference: [16] <author> H. Murakami and V. Kumar, </author> <title> "Efficient Calculation of Primary Images from a Set of Images," </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, </journal> <volume> Vol. 4, No. 5, </volume> <pages> pp. 511-515, </pages> <month> Sept. </month> <year> 1982. </year>
Reference-contexts: A few of the representative algorithms are summarized in Appendix A. In some of our systems we have used a fast implementation [31] of the algorithm proposed by Murakami and Kumar <ref> [16] </ref> and in others the STA algorithm of Murase and Lindenbaum [17]. <p> It has four primary modules: image manipulation, sub-space computation, manifold generation, and recognition. Image manipulation includes image segmentation, scale and brightness normalization, image-vector conversions, and tools for maintaining large image databases. Subspace computation, the second module, computes eigenvectors and eigenvalues of large image sets using the approach outlined in <ref> [16] </ref>. The manifold generation module can be used for projecting image (or feature) sets to subspaces, B-spline interpolation [41] of subspace projections to produce multivariate manifolds, dense resampling of man 6. <p> Singular Value Decomposition: If the number of images M is much smaller than the number of pixels N in each image, a much more efficient algorithm may be used. This algorithm, described by Murakami and Kumar <ref> [16] </ref>, uses the implicit covariance matrix ~ Q, where: ~ Q = P T P (21) Note that ~ Q is an M fi M matrix and therefore much smaller than Q when the number of images in P is smaller than the number of pixels in each image. <p> Using the conjugate gradient algorithm described above, the M eigenvectors of ~ Q can be computed. These can be computed much faster than the first M eigenvectors of Q due to the disparity in the sizes of the two matrices. Using singular value decomposition (SVD), Murakami and Kumar <ref> [16] </ref> show that the M largest eigen-values and the corresponding eigenvectors of Q can be determined from the M eigenvalues and eigenvectors of ~ Q as: i = ~ i 1 Here, i and e i are the i th eigenvalue and eigenvector of Q, while ~ i and ~ e
Reference: [17] <author> H. Murase and M. Lindenbaum, </author> <title> "Spatial Temporal Adaptive Method for Partial Eigenstructure Decomposition of Large Images," </title> <type> NTT Technical Report No. 6527, </type> <month> Mar. </month> <year> 1992. </year>
Reference-contexts: A few of the representative algorithms are summarized in Appendix A. In some of our systems we have used a fast implementation [31] of the algorithm proposed by Murakami and Kumar [16] and in others the STA algorithm of Murase and Lindenbaum <ref> [17] </ref>. On a Sun IPX workstation, for instance, 20 eigenvectors of a set of 100 images (each 128x128 in size) can be computed in about 3 minutes, and 20 eigenvectors of a 1000 image set in less than 4 hours. <p> Since we are only interested in the first k eigenvectors of Q, where k &lt; M , the SVD algorithm can be used. It is not viable, however, when more than M eigenvectors are needed. Spatial Temporal Adaptive: Murase and Lindenbaum <ref> [17] </ref> have proposed the spatial temporal adaptive (STA) algorithm that takes the above SVD algorithm one step further to achieve substantial improvements in computational efficiency. They observe that the computation of ~ Q from the image matrix P is itself expensive.
Reference: [18] <author> H. Murase and S. K. Nayar, </author> <title> "Learning Object Models from Appearance," </title> <booktitle> Proc. of AAAI, </booktitle> <address> Washington D. C., </address> <month> July </month> <year> 1993. </year>
Reference-contexts: To achieve scale invariance we force all images in an acquired image set to be of the same size. For instance, in a recognition task an object region is segmented from the scene and scale normalized <ref> [18] </ref> to fit a predetermined image size. This ensures that the recognition system is invariant to magnification, i.e. 6. PARAMETRIC APPEARANCE REPRESENTATION 135 the distance of the object from the image sensor. <p> This advantage however comes with a slight sacrifice in parameter estimation accuracy [15]. 5. Object recognition and pose estimation We have used appearance models for 3-D object recognition and pose estimation <ref> [18] </ref> [19]. During model acquisition, each object is placed on a computer-controlled turntable (see Fig.1) and its pose is varied about a single axis, namely, the axis 140 NAYAR, MURASE, AND NENE of rotation of the turntable.
Reference: [19] <author> H. Murase and S. K. Nayar, </author> <title> "Visual Learning and Recognition of 3D Objects from Appearance," </title> <journal> International Journal of Computer Vision, </journal> <volume> Vol. 14, No. 1, </volume> <pages> pp. 5-24, </pages> <year> 1995. </year>
Reference-contexts: This observation has led to the exploration of view-based approaches to object recognition (see [37][43][14][44][38] for examples). It motivates us to take an extreme approach to visual representation. What we seek is not a representation of shape but rather appearance <ref> [19] </ref>, encoded in which are brightness variations caused by three-dimensional shape, surface reflectance properties, sensor parameters, and illumination conditions. Given the number of factors at work, it is immediate that an appearance representation that captures all possible variations is simply impractical. <p> The eigenspace for the image set is constructed and all object images (learning samples) are projected to it to obtain a set of points. These points lie on a manifold that is parametrized by pose and illumination. The manifold is constructed from the discrete points by spline interpolation <ref> [19] </ref>. For the class of objects with linear reflectance models, we have analyzed the effect of illumination on the structure of the manifold [26]. In was shown that, in the case of an ideal diffuse object with arbitrary texture, three illumination directions are sufficient to construct the entire illumination manifold. <p> This advantage however comes with a slight sacrifice in parameter estimation accuracy [15]. 5. Object recognition and pose estimation We have used appearance models for 3-D object recognition and pose estimation [18] <ref> [19] </ref>. During model acquisition, each object is placed on a computer-controlled turntable (see Fig.1) and its pose is varied about a single axis, namely, the axis 140 NAYAR, MURASE, AND NENE of rotation of the turntable. <p> The manifolds reside in 10-D eigenspaces and are parameterized by a single pose parameter 1 and a single illumination direction parameter 2 . Several experiments were conducted to verify the accuracy of recognition and pose estimation <ref> [19] </ref>. For the four objects in Fig.2. a total of 1080 test images were used. These images were taken at object poses that lie in between the ones used to obtain the learning samples. <p> Fig.3 (a) illustrates the sensitivity of recognition rate to the number of eigenspace dimensions. Clearly, the discriminating power of the eigenspace is expected to increase with the number of dimensions. The recognition rate is found to be poor if less than 4 dimensions 6. PARAMETRIC APPEARANCE REPRESENTATION 141 <ref> [19] </ref>). The manifolds reside in 10-D eigenspace but are displayed here in 3-D. They are parametrized by object pose ( 1 ) and illumination direction ( 2 ). 142 NAYAR, MURASE, AND NENE are used but approaches unity as the dimensionality is increased to 10. <p> The complete recognition process, including, segmentation, scale and brightness normalization, image projection in eigenspace, and search for the closest object and pose is accomplished in less than 1 second on the Sun workstation. The robustness of this system was tested using 6. PARAMETRIC APPEARANCE REPRESENTATION 143 Fig.2 (from <ref> [19] </ref>). (a) Recognition rate plotted as a function of the number of eigenspace dimensions used. (b) Recognition rate plotted as a function of the number of discrete poses of each object used in the learning stage. <p> Discussion In this section, we briefly discuss several issues related to the proposed learning and recognition scheme. Some of these may be viewed as merits while others as limitations that suggest research problems for the future (also see <ref> [19] </ref>). * Appearance Based Approach: Both learning as well as recognition are done using just two-dimensional images. This is in strong contrast to traditional recognition algorithms that require the extraction of geometric features such as edges, lines, or geometric invariants. <p> In object recognition, learning and classification require the segmentation of object regions. In structured environments, the background can be controlled, in which case, simple thresholding is sufficient for robust segmentation. In the case of moving objects, simple background subtraction algorithms can be effective for segmentation <ref> [19] </ref>. In the context of general scenes, however, segmentation poses serious problems. The method, as described here, also requires that the objects not be occluded. Since it is based on direct appearance matching, it cannot handle substantial degrees of occlusion.
Reference: [20] <author> H. Murase and S. K. Nayar, </author> <title> "Illumination Planning for Object Recognition in Structured Environments," </title> <booktitle> Proc. of IEEE Conf. on Computer Vision and Pattern Recognition, Seattle, </booktitle> <pages> pp. 31-38, </pages> <month> June </month> <year> 1994. </year> <title> 6. PARAMETRIC APPEARANCE REPRESENTATION 159 </title>
Reference-contexts: Parametric appearance models have been applied to a variety of problems besides object recognition, such as, illumination planning for robust recognition <ref> [20] </ref> [21], visual positioning and tracking [25], and temporal inspection of complex parts [27]. These applications have demonstrated that the techniques underlying appearance modeling and matching are general. <p> For instance, the robustness of the recognition system described in section 5 can be maximized by selecting a source direction that makes the objects of interest maximally different from each other in the correlation sense <ref> [20] </ref> [21]. Consider two objects, say p and q, from the set used to compute the eigenspace. <p> In that case, the optimal source direction maximizes the minimum distance between points in eigenspace that represent different objects. In <ref> [20] </ref>, the above planning strategy was used to optimize the robustness of a recognition system similar to the one described in section 5. given illumination direction [21]. <p> For instance, in <ref> [20] </ref> optimization of illumination color is described and demonstrated. The planning approach can also be used to simultaneously optimize multiple parameters. The only requirement is that these parameters be varied during the acquisition of the planning image set.
Reference: [21] <author> H. Murase and S. K. Nayar, </author> <title> "Illumination Planning for Object Recognition Using Parametric Eigenspaces," </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, </journal> <volume> Vol. 16, No. 12, </volume> <pages> pp. 1219-1227, </pages> <month> Jan. </month> <year> 1995. </year>
Reference-contexts: Parametric appearance models have been applied to a variety of problems besides object recognition, such as, illumination planning for robust recognition [20] <ref> [21] </ref>, visual positioning and tracking [25], and temporal inspection of complex parts [27]. These applications have demonstrated that the techniques underlying appearance modeling and matching are general. This has motivated us to develop a comprehensive software package [31] for appearance matching that is presently being used at several research institutions. <p> In the first case, the average absolute pose error computed using all 1080 images is 0.5 degrees, while in the second case the average error is 1.0 degree. The sensitivity of recognition to image noise and segmentation error is analyzed in <ref> [21] </ref>. 6. Automated real-time recognition system Based on the above results, we implemented a recognition system with 20 objects in its database (see Fig.4). These objects vary from smoothly curved shapes with uniform reflectance, to fairly complex shapes with intricate textures and specularities. <p> For instance, the robustness of the recognition system described in section 5 can be maximized by selecting a source direction that makes the objects of interest maximally different from each other in the correlation sense [20] <ref> [21] </ref>. Consider two objects, say p and q, from the set used to compute the eigenspace. <p> The minimum of all these distances, say d l , represents the worst case for the entire object set. The source direction ~ l that maximizes d l is then the optimal source direction for the object set. Fig.5 shows eigenspace curves of two objects used in our experiments <ref> [21] </ref>, for a particular illumination direction. The solid line segment illustrates the shortest distance between the two curves. If in a particular application the poses of the objects are fixed, the eigenspace representation of each object, for a given illumination, is reduced from a curve to a point. <p> In that case, the optimal source direction maximizes the minimum distance between points in eigenspace that represent different objects. In [20], the above planning strategy was used to optimize the robustness of a recognition system similar to the one described in section 5. given illumination direction <ref> [21] </ref>. The shortest distance (thick line segment) between the two curves represents the worst case poses for which the objects appear most similar in the correlation sense.
Reference: [22] <author> H. Murase and S. K. Nayar, </author> <title> "Image Spotting of 3D Objects Using the Parametric Eigenspace Representation," </title> <booktitle> Proc. of 9th Scandinavian Conference on Image Analysis, </booktitle> <pages> pp. 325-332, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: On the other hand, when occlusion effects are not negli 134 NAYAR, MURASE, AND NENE gible, shape models offer solutions in the form of partial matching that is more challenging in the case appearance matching <ref> [22] </ref>. Parametric appearance models have been applied to a variety of problems besides object recognition, such as, illumination planning for robust recognition [20] [21], visual positioning and tracking [25], and temporal inspection of complex parts [27]. These applications have demonstrated that the techniques underlying appearance modeling and matching are general. <p> Since it is based on direct appearance matching, it cannot handle substantial degrees of occlusion. Segmentation and occlusion therefore present challenging research directions for appearance based recognition. Our initial investigation of this topic has resulted in a technique that performs partial matching followed by appearance voting <ref> [22] </ref>. * Computations for Learning: For problems that involve multiple work-spaces (as in object recognition) or a large number of workspace parameters, the appearance manifolds can be expensive to compute both in time and memory requirements.
Reference: [23] <author> V. S. Nalwa, </author> <title> A Guided Tour of Computer Vision, </title> <publisher> Addison Wesley, </publisher> <year> 1993. </year>
Reference-contexts: 1. Introduction Vision research has placed significant emphasis on the development of compact and descriptive shape representations for object recognition <ref> [39, 3, 23] </ref>. This has lead to the creation of a variety of novel representations, including, generalized cylinders [4], superquadrics [2][33], extended gaussian images [10], parametric bicubic patches [23] and differential geometric representations [5], only to name 131 132 NAYAR, MURASE, AND NENE a few. <p> 1. Introduction Vision research has placed significant emphasis on the development of compact and descriptive shape representations for object recognition [39, 3, 23]. This has lead to the creation of a variety of novel representations, including, generalized cylinders [4], superquadrics [2][33], extended gaussian images [10], parametric bicubic patches <ref> [23] </ref> and differential geometric representations [5], only to name 131 132 NAYAR, MURASE, AND NENE a few. While these representations are all useful in specific application domains, each has been found to have its own drawbacks. This has kept researchers in search for more powerful representations.
Reference: [24] <author> S. K. Nayar, K. Ikeuchi, and T. Kanade, </author> <title> "Shape from Interreflections," </title> <journal> International Journal of Computer Vision, </journal> <volume> Vol. 2, No. 3, </volume> <pages> pp. 173-195, </pages> <year> 1991. </year>
Reference-contexts: This last property results from the fact that a concave Lambertian surface with all its interreflections behaves exactly like another Lambertian surface without interreflections but with a different set of normals and albedo values <ref> [24] </ref>. For ideal diffuse objects, these results have direct implications on the efficiency of both learning and recognition, as they dramatically reduce the number of images needed for appearance representation.
Reference: [25] <author> S. K. Nayar, H. Murase, and S. A. Nene, </author> <title> "Learning, Positioning, and Tracking Visual Appearance," </title> <booktitle> Proc. of IEEE Int'l. Conf. on Robotics and Automation, </booktitle> <address> San Diego, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: Parametric appearance models have been applied to a variety of problems besides object recognition, such as, illumination planning for robust recognition [20] [21], visual positioning and tracking <ref> [25] </ref>, and temporal inspection of complex parts [27]. These applications have demonstrated that the techniques underlying appearance modeling and matching are general. This has motivated us to develop a comprehensive software package [31] for appearance matching that is presently being used at several research institutions. <p> The parametric appearance representation has been used to develop an effective solution to the visual servoing problem <ref> [25] </ref>. Our implementation uses the hand-eye system shown in Fig.6. First, a sizable image window is selected that represents the appearance of the object when the robot is in the desired position.
Reference: [26] <author> S. K. Nayar and H. Murase, </author> <title> "On the Dimensionality of Illumination in Ei-genspace," </title> <type> Tech. Rep. </type> <institution> CUCS-021-94, Dept. of Computer Science, Columbia Univ., </institution> <month> Aug. </month> <year> 1994. </year> <note> Revised Sept. </note> <year> 1995. </year>
Reference-contexts: These points lie on a manifold that is parametrized by pose and illumination. The manifold is constructed from the discrete points by spline interpolation [19]. For the class of objects with linear reflectance models, we have analyzed the effect of illumination on the structure of the manifold <ref> [26] </ref>. In was shown that, in the case of an ideal diffuse object with arbitrary texture, three illumination directions are sufficient to construct the entire illumination manifold. This result drastically reduces the number of images required in the learning stage. Recognition and pose estimation can be summarized as follows. <p> In contrast, the function space associated with object reflectance is more concise and hence conducive to analysis. It is possible to establish, under certain reflectance assumptions, a closed-form relationship between illumination parameters and manifold structure <ref> [26] </ref>. Given that the eigenspaces we use are linear subspaces, the class of linear reflectance functions [35][40] is of particular interest to us. It turns out that for this reflectance class the structure of the illumination manifold is completely determined from a small number of samples of the manifold. <p> Alternatively, the dimensionality of the illumination manifold is exactly 3. This result is supported by a detailed empirical investigation reported recently in [8]. In <ref> [26] </ref> we use the above bound on the manifold dimensionality to show that novel images of the object can be recognized from just three projections on the illumination manifold without the explicit construction of the manifold. <p> Its application domain therefore can be safely expected to broaden with time. Further, when assumptions regarding surface reflectance are feasible, we have shown that upper bounds on the dimensionality of the appearance manifold can be derived and the learning samples reduced <ref> [26] </ref>. * Computations for Recognition: Though the learning process poses large memory requirements and is computationally intensive, it is done off-line. The time taken to learn a visual workspace is generally not as crucial as the time needed for image recognition.
Reference: [27] <author> S. K. Nayar, S. A. Nene, and H. Murase, </author> <title> "Subspace Methods for Robot Vision," </title> <journal> IEEE Trans. on Robotics and Automation, </journal> <note> Special issue on "Vision-Based Control of Robot Manipulators," to appear in 1996. Also Tech. Rep. </note> <institution> CUCS-06-95, Dept. of Computer Science, Columbia Univ., </institution> <month> Mar. </month> <year> 1995. </year>
Reference-contexts: Parametric appearance models have been applied to a variety of problems besides object recognition, such as, illumination planning for robust recognition [20] [21], visual positioning and tracking [25], and temporal inspection of complex parts <ref> [27] </ref>. These applications have demonstrated that the techniques underlying appearance modeling and matching are general. This has motivated us to develop a comprehensive software package [31] for appearance matching that is presently being used at several research institutions.
Reference: [28] <author> S. K. Nayar, S. A. Nene, and H. Murase, </author> <title> "Real-Time 100 Object Recognition System," </title> <type> Tech. Rep. </type> <institution> CUCS-021-95, Dept. of Computer Science, Columbia Univ., </institution> <month> Sept. </month> <year> 1995. </year>
Reference-contexts: A histogram of the absolute pose error is shown in Fig.4 (c); the average and standard deviation of the absolute pose error were found to be 1.59 degrees and 1.53 degrees, respectively. Recently, we have extended the capability of the above system <ref> [28] </ref>. It now includes 100 objects in its database and uses as input vectors the three bands of a color image sensor. This allows the system to distinguish between objects that are identical in shape but differ in spectral characteristics. <p> Recognition of 100 or more objects can therefore be accomplished in real-time (frame-rate of 30 Hz) using simple and inexpensive hardware <ref> [28] </ref>. In contrast, most 3-D CAD model based recognition algorithms are too slow for practical applications.
Reference: [29] <author> S. K. Nayar, S. Baker, and H. Murase, </author> <title> "Parametric Feature Detection," </title> <type> Tech. Rep. </type> <institution> CUCS-028-95, Dept. of Computer Science, Columbia Univ., </institution> <month> Oct. </month> <year> 1995. </year>
Reference-contexts: The concept of appearance matching can be used as a general framework for the design and implementation of detectors for parametrized features <ref> [29] </ref>. For robustness, the features are modeled in detail to precisely capture their appearances in the physical world. In addition, optical and sensing artifacts are incorporated to achieve realistic feature models in image domain. Each feature is then represented as a densely sampled parameterized manifold in Hilbert space. <p> Each feature is then represented as a densely sampled parameterized manifold in Hilbert space. The concepts of parameter reduction by normalization, dimension reduction, pattern rejection, and efficient search are employed to achieve compact feature manifolds and efficient detection. Detectors have 6. PARAMETRIC APPEARANCE REPRESENTATION 155 been implemented <ref> [29] </ref> for five specific features, namely, step edge, roof edge, line, corner, and circular disc. The tools discussed in this chapter have allowed us to generate all five of these detectors using the same procedure by simply inputing different feature models. <p> The tools discussed in this chapter have allowed us to generate all five of these detectors using the same procedure by simply inputing different feature models. Detailed experiments on the robustness of detection and the accuracy of parameter estimation are reported in <ref> [29] </ref>. Appendix A. Computing eigenvectors of large image sets Let P be an N fiM image matrix, where M is the total number of images and N the number of pixels in each image.
Reference: [30] <author> S. A. Nene and S. K. Nayar, </author> <title> "Algorithm and Architecture for High Dimensional Search," </title> <type> Tech. Rep. </type> <institution> CUCS-030-95, Dept. of Computer Science, Columbia Univ., </institution> <month> Oct. </month> <year> 1995. </year>
Reference-contexts: This normalized image is projected to eigenspace. The closest manifold reveals the identity of the object and exact position of the closest point on the manifold determines pose and illumination direction. Two different techniques have been tested for determining the closest manifold point, one is based on binary search <ref> [30] </ref> and other uses an input-output mapping network [15]. We have achieved further speed-up in recognition by developing a comprehensive theory and a novel algorithm for pattern rejection [1]. <p> The computational complexity is O ( K n ) where n is the number of manifold points and K is the dimensionality of the eigenspace. We have implemented two alternative schemes. The first is an efficient technique for binary search in multiple dimensions <ref> [30] </ref>. This algorithm uses a carefully designed data structure to facilitate quick search through the multi-dimensional ei-genspace in O ( k log 2 n ). This approach is particularly effective when the number of manifold points is relatively small. <p> Displacements are in three dimensions (x, y, ). Histograms of absolute positioning error (in mm) for (g) 5-D eigenspace and (h) 10-D eigenspace. 152 NAYAR, MURASE, AND NENE ifolds, and orthogonalization [11] of multiple subspaces. Finally, the recognition module includes efficient search implementations <ref> [30] </ref> that find manifold points that lie closest to novel input projections. All four modules can be accessed via an intuitive graphical interface built on X/Motif. SLAM has been licensed to several academic and industrial research institutions. appearance modeling and recognition problems in vision. 11.
Reference: [31] <author> S. A. Nene, S. K. Nayar, H. Murase, </author> <title> "SLAM: A Software Library for Appearance Matching," </title> <booktitle> Proc. of ARPA IU Workshop, </booktitle> <address> Monterey, </address> <month> Nov. </month> <year> 1994. </year>
Reference-contexts: These applications have demonstrated that the techniques underlying appearance modeling and matching are general. This has motivated us to develop a comprehensive software package <ref> [31] </ref> for appearance matching that is presently being used at several research institutions. We conclude with a brief discussion on the salient features of appearance matching and our most recent results on the topic. 2. Computing appearance models We begin by presenting a general procedure for acquiring appearance models. <p> Fast algorithms for solving this problem have been a topic of active research in the area of image coding/compression and pattern recognition. A few of the representative algorithms are summarized in Appendix A. In some of our systems we have used a fast implementation <ref> [31] </ref> of the algorithm proposed by Murakami and Kumar [16] and in others the STA algorithm of Murase and Lindenbaum [17]. <p> SLAM: A Software Library for Appearance Matching As is evident from the above results, the parametric eigenspace representation can serve as the basis for solving a variety of real-world vision problems. In view of this, a software package named SLAM <ref> [31] </ref> was developed as a general tool for appearance modeling and recognition problems. The package is coded in C++ and uses advanced object-oriented programming techniques to achieve high space/time efficiency. It has four primary modules: image manipulation, sub-space computation, manifold generation, and recognition.
Reference: [32] <author> E. Oja, </author> <title> Subspace methods of Pattern Recognition, </title> <publisher> Res. Studies Press, </publisher> <address> Hert-fordshire, </address> <year> 1983. </year>
Reference-contexts: The problem then is to compress this large image set to a low-dimensional representation of object appearance. A well-known image compression or coding technique is based on principal component analysis, also known as the Karhunen-Loeve transform <ref> [32] </ref> [9]. It uses the eigenvectors of an image set as orthogonal bases for representing individual 6. PARAMETRIC APPEARANCE REPRESENTATION 133 images in the set. <p> The obvious step is to take advantage of this and compress the large set to a low-dimensional representation that captures the key appearance characteristics of the visual workspace. A suitable compression technique is based on principal component analysis <ref> [32] </ref>, where the eigenvectors of the image set are computed and used as orthogonal bases for representing individual images. Principal component analysis has been previously used in computer vision for deriving basis functions for feature detection [12] [13], representing human face images [42], and recognizing face images [43] [34]. <p> Note that each eigenvector is of size N , i.e. the size of an image. These K eigenvectors constitute our eigenspace; it is an approximation to a complete Hilbert space with N dimensions. A variety of criteria have been suggested for selecting K for any given image set <ref> [32] </ref>. In most of our applications, we have found eigenspaces of 20 or less dimensions to be more than adequate. 2.3. <p> Consider two images ^ i m and ^ i n that belong to the image set used to compute an eigenspace. Let the points f m and f n be the eigenspace projections of the two images. It is well-known in pattern recognition theory <ref> [32] </ref> that each of the images can be expressed in terms of its projection: ^ i m = i=1 where c is once again the average of the entire image set. <p> Here, we briefly describe three algorithms. We refer to these as the conjugate gradient, singular value decomposition, and spatial temporal adaptive algorithms. Each algorithm may be viewed as a modification of the previous one. The first two of these algorithms are described in detail in <ref> [32] </ref>. Conjugate Gradient: A practical approach to computing the eigenvectors of large matrices is to use iterative methods. A reasonably efficient iterative scheme that suggests itself is the conjugate gradient method. There are several variations to the conjugate gradient approach [45].
Reference: [33] <author> A. P. Pentland, </author> <title> "Perceptual Organization and the Representation of Natural Form," </title> <journal> Artificial Intelligence, </journal> <volume> Vol. 28, </volume> <pages> pp. 293-331, </pages> <year> 1986. </year> <note> 160 NAYAR, MURASE, AND NENE </note>
Reference: [34] <author> A. Pentland, B. Moghaddam, and T. Starner, </author> <title> "View-Based and Modular Eigenspaces for Face Recognition," </title> <booktitle> Proc. of IEEE Conf. on Computer Vision and Pattern Recognition, </booktitle> <address> Seattle, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: Principal component analysis has been previously used in computer vision for deriving basis functions for feature detection [12] [13], representing human face images [42], and recognizing face images [43] <ref> [34] </ref>. Though, in general, all the eigenvectors of an image set are required for perfect reconstruction of any particular image, only a few are sufficient for visual recognition. These eigenvec-tors constitute the dimensions of the eigenspace, or image subspace, in which the visual workspace is compactly represented.
Reference: [35] <author> A. P. Petrov, </author> <title> "Color and Grassman-Cayley coordinates of shape," in Human Vision, Visual Processing and Digital Display II, </title> <booktitle> SPIE Proc., </booktitle> <volume> Vol. 1453, </volume> <pages> pp. 342-352, </pages> <year> 1991. </year>
Reference: [36] <author> T. Poggio and F. Girosi, </author> <title> "Networks for Approximation and Learning," </title> <journal> Proc. of the IEEE, </journal> <volume> Vol. 78, No. 9, </volume> <pages> pp. 1481-1497, </pages> <month> Sept. </month> <year> 1990. </year>
Reference-contexts: This approach is particularly effective when the number of manifold points is relatively small. The second approach [15] uses three-layered radial basis function (RBF) networks proposed by Poggio and Girosi <ref> [36] </ref> to learn the mapping between input points and manifold parameters (object number and pose). The complexity of the network approach depends on the number of networks used and their sizes.
Reference: [37] <author> T. Poggio and S. Edelman, </author> <title> "A network that learns to recognize 3D objects," </title> <journal> Nature, </journal> <volume> Vol. 343, </volume> <pages> pp. 263-266, </pages> <year> 1990. </year>
Reference: [38] <author> A. R. Pope and D. G. Lowe, </author> <title> "Learning Object Recognition Models from Images," </title> <booktitle> Proc. of Fourth Int'l. Conf. on Computer Vision, </booktitle> <pages> pp. 296-301, </pages> <address> Berlin, </address> <month> May </month> <year> 1993. </year>
Reference: [39] <author> A. A. G. Requicha, </author> <title> "Representation of Rigid Solids: Theory, Methods and Systems," </title> <journal> Computing Surveys, </journal> <volume> Vol. 12, No. 4, </volume> <pages> pp. </pages> <address> 1-437-464, </address> <month> Dec. </month> <year> 1980. </year>
Reference-contexts: 1. Introduction Vision research has placed significant emphasis on the development of compact and descriptive shape representations for object recognition <ref> [39, 3, 23] </ref>. This has lead to the creation of a variety of novel representations, including, generalized cylinders [4], superquadrics [2][33], extended gaussian images [10], parametric bicubic patches [23] and differential geometric representations [5], only to name 131 132 NAYAR, MURASE, AND NENE a few.
Reference: [40] <author> A. Shashua, </author> <title> "On Photometric Issues in 3D Visual Recognition from a Single 2D Image," </title> <type> Tech. Rep., </type> <institution> Artificial Intelligence Lab., MIT, </institution> <year> 1993. </year>
Reference: [41] <author> D. F. Rogers, </author> <title> Mathematical Elements for Computer Graphics, 2nd ed., </title> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <year> 1990. </year>
Reference-contexts: Hence, the discrete points obtained by projecting all the discrete samples of the workspace can be assumed to lie on a manifold that represents a continuous appearance function. The discrete points are interpolated to obtain this manifold. In our implementation, we have used a standard quadratic B-spline interpolation algorithm <ref> [41] </ref>. The resulting manifold can be expressed as: f (q) = f ( q 1 ; q 2 ; :::::::; q m ) (8) 6. <p> Subspace computation, the second module, computes eigenvectors and eigenvalues of large image sets using the approach outlined in [16]. The manifold generation module can be used for projecting image (or feature) sets to subspaces, B-spline interpolation <ref> [41] </ref> of subspace projections to produce multivariate manifolds, dense resampling of man 6. PARAMETRIC APPEARANCE REPRESENTATION 151 The image window (white box) shown was used for learning and positioning. (b) Parametric appearance representation of the visual workspace displayed in 3-D. Robot displacements are in two dimensions (x and y).
Reference: [42] <author> L. Sirovich and M. Kirby, </author> <title> "Low dimensional procedure for the characterization of human faces," </title> <journal> Journal of Optical Society of America, </journal> <volume> Vol. 4, No. 3, </volume> <pages> pp. 519-524, </pages> <year> 1987. </year>
Reference-contexts: Principal component analysis has been previously used in computer vision for deriving basis functions for feature detection [12] [13], representing human face images <ref> [42] </ref>, and recognizing face images [43] [34]. Though, in general, all the eigenvectors of an image set are required for perfect reconstruction of any particular image, only a few are sufficient for visual recognition.
Reference: [43] <author> M. A. Turk and A. P. Pentland, </author> <title> "Face Recognition Using Eigenfaces," </title> <booktitle> Proc. of IEEE Conf. on Computer Vision and Pattern Recognition, </booktitle> <pages> pp. 586-591, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: Principal component analysis has been previously used in computer vision for deriving basis functions for feature detection [12] [13], representing human face images [42], and recognizing face images <ref> [43] </ref> [34]. Though, in general, all the eigenvectors of an image set are required for perfect reconstruction of any particular image, only a few are sufficient for visual recognition. These eigenvec-tors constitute the dimensions of the eigenspace, or image subspace, in which the visual workspace is compactly represented.
Reference: [44] <author> J. Weng, N. Ahuja, and T. S. Huang, </author> <title> "Learning recognition and segmentation of 3-d objects from 2-d images," </title> <booktitle> Proc. of Fourth Int'l Conf. on Computer Vision, </booktitle> <pages> pp. 121-128, </pages> <address> Berlin, </address> <month> May </month> <year> 1993. </year>
Reference: [45] <author> X. Yang, T. K. Sarkar, and E. Arvas, </author> <title> "A Survey of Conjugate Gradient Algorithms for Solution of Extreme Eigen-Problems of a Symmetric Matrix," </title> <journal> IEEE Trans. on Acoustics, Speech and Signal Processing, </journal> <volume> Vol. 37, No. 10, </volume> <pages> pp. 1550-1555, </pages> <month> Oct. </month> <year> 1989. </year>
Reference-contexts: Conjugate Gradient: A practical approach to computing the eigenvectors of large matrices is to use iterative methods. A reasonably efficient iterative scheme that suggests itself is the conjugate gradient method. There are several variations to the conjugate gradient approach <ref> [45] </ref>. The problem is formulated as one of finding the eigenvalues and eigenvectors that maximize a scalar function.
References-found: 45

