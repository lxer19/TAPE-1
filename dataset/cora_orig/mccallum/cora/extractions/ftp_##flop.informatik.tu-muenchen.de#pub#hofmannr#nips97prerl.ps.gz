URL: ftp://flop.informatik.tu-muenchen.de/pub/hofmannr/nips97prerl.ps.gz
Refering-URL: http://www.ph.tn.tudelft.nl/PRInfo/reports/msg00376.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Nonlinear Markov Networks for Continuous Variables  
Author: Reimar Hofmann and Volker Tresp 
Address: 81730 Munchen, Germany  
Affiliation: Siemens AG, Corporate Technology Information and Communications  
Note: Accepted for publication at NIPS*97.  
Abstract: In this paper we address the problem of learning the structure in nonlinear Markov networks with continuous variables. Markov networks are well suited to model relationships which do not exhibit a natural causal ordering. We use neural network structures to model the quantitative relationships between variables. Using two data sets we show that interesting structures can be found using our approach. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Geman, S., and Geman, D. </author> <year> (1984). </year> <title> Stochastic relaxations, Gibbs distributions and the Bayesian restoration of images. </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence PAMI-6 (no. </journal> 6):721-42 Hofmann, R. (1997). Inference in Markov Blanket Models. Technical report, in preparation. 
Reference-contexts: This is the case in image processing where the variables typically represent the grey levels of pixels and the graph encourages smootheness in the values of neighboring pixels <ref> (Markov random fields, Geman and Geman, 1984) </ref>. We believe that Markov networks might be a useful representation in many domains where the concept of cause and effect is somewhat artificial.
Reference: <author> Pearl, J. </author> <year> (1988). </year> <title> Probabilistic reasoning in intelligent systems. </title> <address> San Mateo: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Note, that a state whose clique functions have large values has high probability. The theorem of Hammersley and Clifford states that the normalized product in equation 1 embodies all the conditional independencies portrayed by the graph <ref> (Pearl, 1988) </ref> 2 for any choice of the g i . If the graph is sparse, i.e. if many conditional independencies exist then the cliques might be small and the product will be over low dimensional functions. <p> It should be noted that Bayesian networks and Markov networks differ in which specific independencies they can represent <ref> (Pearl, 1988) </ref>. 1 To simplify the discussion we will assume strict positivity for the rest of this paper. For some of the statements weaker conditions may also be sufficient. <p> If the underlying true probability density is known the structure in a Markov network can be found using either the edge deletion method or the Markov boundary method <ref> (Pearl, 1988) </ref>. The edge deletion method uses the fact that variables a and b are not connected by an edge if and only if a and b are independent given all other variables. Evaluating this test for each pair of variables reveals the structure of the network.
Reference: <author> Whittaker, J. </author> <year> (1990). </year> <title> Graphical models in applied multivariate statistics. </title> <address> Chichester, UK: </address> <publisher> John Wiley and Sons. </publisher>
Reference-contexts: Whereas the graphical structure in Markov networks might be known a priori in some cases, the focus of this work is the case that structure is unknown and must be infered from data. For both discrete variables and linear relationships between continuous variables algorithms for structure learning exist <ref> (Whittaker, 1990) </ref>. Here we address the problem of learning structure for Markov networks of continuous variables where the relationships between variables are nonlinear. In particular we use neural networks for approximating the dependency between a variable and fl To whom correspondence should be addressed. y Reimar.Hofmann@mchp.siemens.de Volker.Tresp@mchp.siemens.de its Markov boundary.
References-found: 3

