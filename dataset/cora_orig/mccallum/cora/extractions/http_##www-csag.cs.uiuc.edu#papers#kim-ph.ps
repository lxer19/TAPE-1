URL: http://www-csag.cs.uiuc.edu/papers/kim-ph.ps
Refering-URL: http://www-csag.cs.uiuc.edu/papers/index.html
Root-URL: http://www.cs.uiuc.edu
Note: c Copyright by Jae H. Kim, 1997  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> L. Kleinrock. </author> <title> Queueing Systems: Volumes I and II. </title> <editor> J. </editor> <publisher> Wiley and Sons, </publisher> <address> New York, NY, </address> <year> 1976. </year>
Reference-contexts: INTRODUCTION Over the last thirty years, network theories, architectures, and implementation technologies have improved network performance dramatically, providing more efficient and reliable routing algorithms, better network topologies, congestion- and flow-control mechanisms, better utilization of shared media, and more efficient switching techniques <ref> [1, 2, 3, 4, 5, 6, 7] </ref>. Two decades later, short-haul multicomputer interconnection networks have also developed in parallel, both following the trail of long-haul, general networks and contributing to their architectural improvements [3, 8, 5, 9, 10, 11, 12, 13].
Reference: [2] <author> A. S. Tanenbaum. </author> <title> Computer Networks. </title> <publisher> Prentice-Hall, </publisher> <address> Upper Saddle River, NJ, </address> <year> 1996. </year>
Reference-contexts: INTRODUCTION Over the last thirty years, network theories, architectures, and implementation technologies have improved network performance dramatically, providing more efficient and reliable routing algorithms, better network topologies, congestion- and flow-control mechanisms, better utilization of shared media, and more efficient switching techniques <ref> [1, 2, 3, 4, 5, 6, 7] </ref>. Two decades later, short-haul multicomputer interconnection networks have also developed in parallel, both following the trail of long-haul, general networks and contributing to their architectural improvements [3, 8, 5, 9, 10, 11, 12, 13]. <p> Note that this is a slightly simpler categorization than the five types (CBR, Real-Time VBR, Non-Real-Time VBR, ABR and UBR) recently suggested by the ATM Forum <ref> [2, 52] </ref>. * Constant Bit Rate (CBR): Uncompressed audio and video streams belong to this category, in which packets are generated at a fixed interval and uniform rate. These traffic types have been widely used for interactive media communications, so bandwidth and/or delay bounds should be guaranteed.
Reference: [3] <author> R. Metcalfe and D. Boggs. </author> <title> "Ethernet: Distributed packet-switching for local computer networks," </title> <journal> Communications of the Association for Computing Machinery, </journal> <volume> vol. 19, no. 7, </volume> <pages> pp. 395-404, </pages> <month> July </month> <year> 1976. </year>
Reference-contexts: INTRODUCTION Over the last thirty years, network theories, architectures, and implementation technologies have improved network performance dramatically, providing more efficient and reliable routing algorithms, better network topologies, congestion- and flow-control mechanisms, better utilization of shared media, and more efficient switching techniques <ref> [1, 2, 3, 4, 5, 6, 7] </ref>. Two decades later, short-haul multicomputer interconnection networks have also developed in parallel, both following the trail of long-haul, general networks and contributing to their architectural improvements [3, 8, 5, 9, 10, 11, 12, 13]. <p> Two decades later, short-haul multicomputer interconnection networks have also developed in parallel, both following the trail of long-haul, general networks and contributing to their architectural improvements <ref> [3, 8, 5, 9, 10, 11, 12, 13] </ref>. During this period, architects of both network types have focused on how to allocate and utilize restricted network resources efficiently to provide higher throughput and lower average latency.
Reference: [4] <author> J. Postel, C. Sunshine, and D. Cohen. </author> <title> "The ARPA Internet protocol," </title> <journal> Computer Networks, </journal> <volume> vol. 5, </volume> <pages> pp. 261-71, </pages> <month> Aug. </month> <year> 1981. </year>
Reference-contexts: INTRODUCTION Over the last thirty years, network theories, architectures, and implementation technologies have improved network performance dramatically, providing more efficient and reliable routing algorithms, better network topologies, congestion- and flow-control mechanisms, better utilization of shared media, and more efficient switching techniques <ref> [1, 2, 3, 4, 5, 6, 7] </ref>. Two decades later, short-haul multicomputer interconnection networks have also developed in parallel, both following the trail of long-haul, general networks and contributing to their architectural improvements [3, 8, 5, 9, 10, 11, 12, 13].
Reference: [5] <institution> Fiber-Distributed Data Interface (FDDI)|Token Ring Media Access Control (MAC), American National Standards Institute, </institution> <month> July </month> <year> 1987. </year>
Reference-contexts: INTRODUCTION Over the last thirty years, network theories, architectures, and implementation technologies have improved network performance dramatically, providing more efficient and reliable routing algorithms, better network topologies, congestion- and flow-control mechanisms, better utilization of shared media, and more efficient switching techniques <ref> [1, 2, 3, 4, 5, 6, 7] </ref>. Two decades later, short-haul multicomputer interconnection networks have also developed in parallel, both following the trail of long-haul, general networks and contributing to their architectural improvements [3, 8, 5, 9, 10, 11, 12, 13]. <p> Two decades later, short-haul multicomputer interconnection networks have also developed in parallel, both following the trail of long-haul, general networks and contributing to their architectural improvements <ref> [3, 8, 5, 9, 10, 11, 12, 13] </ref>. During this period, architects of both network types have focused on how to allocate and utilize restricted network resources efficiently to provide higher throughput and lower average latency.
Reference: [6] <author> V. Jacobson. </author> <title> "Congestion avoidance and control," </title> <booktitle> in Proceedings of ACM SIGCOMM, Standford, </booktitle> <address> CA, </address> <year> 1988, </year> <pages> pp. 314-329. </pages>
Reference-contexts: INTRODUCTION Over the last thirty years, network theories, architectures, and implementation technologies have improved network performance dramatically, providing more efficient and reliable routing algorithms, better network topologies, congestion- and flow-control mechanisms, better utilization of shared media, and more efficient switching techniques <ref> [1, 2, 3, 4, 5, 6, 7] </ref>. Two decades later, short-haul multicomputer interconnection networks have also developed in parallel, both following the trail of long-haul, general networks and contributing to their architectural improvements [3, 8, 5, 9, 10, 11, 12, 13].
Reference: [7] <author> I. Leslie, D. McAuley, and D. Tennenhouse. </author> <title> "ATM everywhere?," </title> <journal> IEEE Network, </journal> <volume> vol. 7, no. 2, </volume> <pages> pp. 40-46, </pages> <month> March </month> <year> 1993. </year>
Reference-contexts: INTRODUCTION Over the last thirty years, network theories, architectures, and implementation technologies have improved network performance dramatically, providing more efficient and reliable routing algorithms, better network topologies, congestion- and flow-control mechanisms, better utilization of shared media, and more efficient switching techniques <ref> [1, 2, 3, 4, 5, 6, 7] </ref>. Two decades later, short-haul multicomputer interconnection networks have also developed in parallel, both following the trail of long-haul, general networks and contributing to their architectural improvements [3, 8, 5, 9, 10, 11, 12, 13].
Reference: [8] <author> P. Kermani and L. Kleinrock. </author> <title> "Virtual cut-through: A new computer communications switching technique," </title> <journal> Computer Networks, </journal> <volume> vol. 3, no. 4, </volume> <pages> pp. 267-86, </pages> <year> 1979. </year>
Reference-contexts: Two decades later, short-haul multicomputer interconnection networks have also developed in parallel, both following the trail of long-haul, general networks and contributing to their architectural improvements <ref> [3, 8, 5, 9, 10, 11, 12, 13] </ref>. During this period, architects of both network types have focused on how to allocate and utilize restricted network resources efficiently to provide higher throughput and lower average latency. <p> and implementation cost, are compared to existing algorithms via analysis and simulations. 40 CHAPTER 3 INITIAL STUDY: EVALUATION OF THE TANDEM SERVERNET APPROACH Since the first development of multicomputers a decade ago, interconnection networks have developed dramatically in such areas as connection topologies, switching strategies, routing algorithms, flow control, etc. <ref> [8, 24, 26, 89, 90, 91, 92] </ref>. The main focus of network architects has been on efficient network resource utilization to improve throughput and average latency.
Reference: [9] <author> T. Feng. </author> <title> "A survey of interconnection networks," </title> <journal> IEEE Transactions on Computers, </journal> <volume> vol. C-14, no. 12, </volume> <pages> pp. 12-27, </pages> <month> Dec. </month> <year> 1981. </year> <month> 208 </month>
Reference-contexts: Two decades later, short-haul multicomputer interconnection networks have also developed in parallel, both following the trail of long-haul, general networks and contributing to their architectural improvements <ref> [3, 8, 5, 9, 10, 11, 12, 13] </ref>. During this period, architects of both network types have focused on how to allocate and utilize restricted network resources efficiently to provide higher throughput and lower average latency.
Reference: [10] <author> W. Dally and C. Seitz. </author> <title> "Deadlock-free message routing in multiprocessor interconnec-tion networks," </title> <journal> IEEE Transactions on Computers, </journal> <volume> vol. C-36, no. 5, </volume> <pages> pp. 547-53, </pages> <month> May </month> <year> 1987. </year>
Reference-contexts: Two decades later, short-haul multicomputer interconnection networks have also developed in parallel, both following the trail of long-haul, general networks and contributing to their architectural improvements <ref> [3, 8, 5, 9, 10, 11, 12, 13] </ref>. During this period, architects of both network types have focused on how to allocate and utilize restricted network resources efficiently to provide higher throughput and lower average latency.
Reference: [11] <author> J. Ngai and C. Seitz. </author> <title> "A framework for adaptive routing in multicomputer networks," </title> <booktitle> in Proceedings of the 1989 ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <address> Santa Fe, NM, </address> <year> 1989, </year> <pages> pp. 1-9. </pages>
Reference-contexts: Two decades later, short-haul multicomputer interconnection networks have also developed in parallel, both following the trail of long-haul, general networks and contributing to their architectural improvements <ref> [3, 8, 5, 9, 10, 11, 12, 13] </ref>. During this period, architects of both network types have focused on how to allocate and utilize restricted network resources efficiently to provide higher throughput and lower average latency.
Reference: [12] <author> W. J. Dally. </author> <title> "Virtual channel flow control," </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> vol. 3, no. 2, </volume> <pages> pp. 194-205, </pages> <year> 1992. </year>
Reference-contexts: Two decades later, short-haul multicomputer interconnection networks have also developed in parallel, both following the trail of long-haul, general networks and contributing to their architectural improvements <ref> [3, 8, 5, 9, 10, 11, 12, 13] </ref>. During this period, architects of both network types have focused on how to allocate and utilize restricted network resources efficiently to provide higher throughput and lower average latency.
Reference: [13] <author> C. Seitz. </author> <title> "Myrinet a gigabit-per-second local-area network," </title> <booktitle> in Proceedings of the IEEE Hot Interconnects Symposium, </booktitle> <address> Palo Alto, CA, </address> <year> 1994. </year>
Reference-contexts: Two decades later, short-haul multicomputer interconnection networks have also developed in parallel, both following the trail of long-haul, general networks and contributing to their architectural improvements <ref> [3, 8, 5, 9, 10, 11, 12, 13] </ref>. During this period, architects of both network types have focused on how to allocate and utilize restricted network resources efficiently to provide higher throughput and lower average latency.
Reference: [14] <author> T. Perry. </author> <title> "The trials and travails of interactive TV," </title> <journal> IEEE Spectrum, </journal> <pages> pp. 22-28, </pages> <month> April </month> <year> 1996. </year>
Reference-contexts: Enabled by high bandwidth, continuous multimedia applications naturally arise and become new major customers of the increased computer network capacities. These applications include desktop video conferencing, media-on-demand, remote learning, video libraries, HDTV, home shopping, and Computer Supported Cooperative Work (CSCW) <ref> [14, 15, 16, 17] </ref>. In addition to higher communication bandwidth requirements, multimedia applications also require a completely different type of network services, Quality of Service (QoS).
Reference: [15] <author> C. Basile et al. </author> <title> "The U.S. HDTV standard: The grand alliance," </title> <journal> IEEE Spectrum, </journal> <pages> pp. 36-45, </pages> <month> Apr. </month> <year> 1995. </year>
Reference-contexts: Enabled by high bandwidth, continuous multimedia applications naturally arise and become new major customers of the increased computer network capacities. These applications include desktop video conferencing, media-on-demand, remote learning, video libraries, HDTV, home shopping, and Computer Supported Cooperative Work (CSCW) <ref> [14, 15, 16, 17] </ref>. In addition to higher communication bandwidth requirements, multimedia applications also require a completely different type of network services, Quality of Service (QoS).
Reference: [16] <author> M. Nelson, M. Linton, and S. Owicki. </author> <title> "A highly available, scalable ITV system," </title> <booktitle> in Proceedings of the Symposium on Operating Systems Principles, </booktitle> <address> Copper Mountain Resort, CO, </address> <year> 1995, </year> <pages> pp. 54-67. </pages>
Reference-contexts: Enabled by high bandwidth, continuous multimedia applications naturally arise and become new major customers of the increased computer network capacities. These applications include desktop video conferencing, media-on-demand, remote learning, video libraries, HDTV, home shopping, and Computer Supported Cooperative Work (CSCW) <ref> [14, 15, 16, 17] </ref>. In addition to higher communication bandwidth requirements, multimedia applications also require a completely different type of network services, Quality of Service (QoS).
Reference: [17] <author> R. Kouzes, J. Myers, and W. Wulf. "Collaboratories: </author> <title> Doing science on the internet," </title> <journal> Computer, </journal> <volume> vol. 29, no. 8, </volume> <pages> pp. 40-46, </pages> <month> Aug. </month> <year> 1996. </year>
Reference-contexts: Enabled by high bandwidth, continuous multimedia applications naturally arise and become new major customers of the increased computer network capacities. These applications include desktop video conferencing, media-on-demand, remote learning, video libraries, HDTV, home shopping, and Computer Supported Cooperative Work (CSCW) <ref> [14, 15, 16, 17] </ref>. In addition to higher communication bandwidth requirements, multimedia applications also require a completely different type of network services, Quality of Service (QoS).
Reference: [18] <institution> Advanced Queueing Techniques in the Cisco IOS, Cisco Systems, Inc., </institution> <address> San Jose, CA, </address> <year> 1995. </year> <note> Cisco Systems white paper available from http://cio.cisco.com/warp/public/732/ Multi/index.html. </note>
Reference-contexts: Also, voice communication delays between conferencing end nodes must be kept continuously at less than a few hundred milliseconds <ref> [18, 19] </ref>. Traditionally, different communication services, such as voice and data communications, have been supported in different physical networks (telephone and computer networks) by different switching mechanisms (time-division circuit switching and packet switching). <p> In general, switches developed for workgroup or local-area networks provide simple and limited resource controls to reduce implementation costs. For instance, the IBM Switch-on-a-chip [85, 86] does not support any service control at all, and the Cisco LightStream 100 <ref> [18] </ref> switch supports only two levels of priority to give low delays to real-time traffic. Other 36 switches developed for backbone networks provide more flexible service controls because more costs are tolerable, but still in a limited way by using a small number of queues and limited priority levels. <p> NewBridge's VIVID ATM switches support four logical queues per port [87]. The Cisco LightStream 2020 switch supports both priority-based (four priorities) and weighted fair queueing with 16 queues <ref> [18] </ref>. While being able to provide different services to different traffic types, they are far from connection-based service controls due to limited control resources. On the other hand, some vendors take more aggressive approaches in supporting a much larger range of traffic types and network services. <p> table also shows that even with very large-scale systems, more than 1,024 nodes and frame sizes of up to 1,000 packet slots, long messages of up to 4 Kbytes are guaranteed to be delivered within 20 msecs, which is much less than the delay bounds required for interactive video/audio applications <ref> [18, 19] </ref>. Note that existing multicomputer networks with round-robin arbitration, for instance, the Intel Paragon [24] and Cray T3E [99], can theoretically provide delay guarantees of a few days for 1,024 node configurations.
Reference: [19] <author> D. Gall. </author> <title> "MPEG: A vedio compression standard for multimedia applications," </title> <journal> Communications of the ACM, </journal> <volume> vol. 34, no. 4, </volume> <pages> pp. 46-58, </pages> <month> Apr. </month> <year> 1991. </year> <month> 209 </month>
Reference-contexts: Also, voice communication delays between conferencing end nodes must be kept continuously at less than a few hundred milliseconds <ref> [18, 19] </ref>. Traditionally, different communication services, such as voice and data communications, have been supported in different physical networks (telephone and computer networks) by different switching mechanisms (time-division circuit switching and packet switching). <p> table also shows that even with very large-scale systems, more than 1,024 nodes and frame sizes of up to 1,000 packet slots, long messages of up to 4 Kbytes are guaranteed to be delivered within 20 msecs, which is much less than the delay bounds required for interactive video/audio applications <ref> [18, 19] </ref>. Note that existing multicomputer networks with round-robin arbitration, for instance, the Intel Paragon [24] and Cray T3E [99], can theoretically provide delay guarantees of a few days for 1,024 node configurations.
Reference: [20] <author> D. Jadav and A. Choudhary. </author> <title> "Designing and implementing high-performance media--on-demand servers," </title> <booktitle> IEEE Parallel & Distributed Technology, </booktitle> <pages> pp. 29-39, </pages> <month> Summer </month> <year> 1995. </year>
Reference-contexts: clarity, disks are shown separately), are connected by high-performance switches (SW ). 1.1 Scalable Multimedia Servers Parallel computers, multicomputers and workstation clusters are accepted as good candidates for large-scale multimedia servers because they meet the requirements of high processing power, reliability, and above all, high-bandwidth I/O at a low cost <ref> [20] </ref>. Recently, a number of parallel computer vendors have begun to exploit these new application areas of multimedia and data servers [21, 22]. data will be distributed across the nodes. Service requests are accepted through external network interfaces which use standard network adapters such as HIPPI, FDDI, ATM or ethernet. <p> The rectangles and circles represent switches and processing nodes, respectively. audio and video communications. Even multicomputer systems dedicated to multimedia services need to support non-real-time traffic, including control messages or background data transmissions <ref> [20] </ref>. Hence, the need for integrated-service, short-haul networks which can efficiently support a wide range of network traffic types has been increasing rapidly. 1.2 Limitations of Fixed-Arbitration Switches Unfortunately, existing switch designs cannot support both bursty data and real-time communications at the same time.
Reference: [21] <author> R. Buck. </author> <title> "The Oracle media server for nCUBE massively parallel systems," </title> <booktitle> in Proceedings of the International Parallel Processing Symposium, </booktitle> <address> Cancun, Mexico, </address> <year> 1994, </year> <pages> pp. 670-673. </pages>
Reference-contexts: Recently, a number of parallel computer vendors have begun to exploit these new application areas of multimedia and data servers <ref> [21, 22] </ref>. data will be distributed across the nodes. Service requests are accepted through external network interfaces which use standard network adapters such as HIPPI, FDDI, ATM or ethernet.
Reference: [22] <editor> R. Haskin and R. Williams. "Tiger Shark," </editor> <booktitle> in Proceedings of the IEEE Hot Interconnects Symposium, </booktitle> <address> Palo Alto, CA, </address> <year> 1995. </year>
Reference-contexts: Recently, a number of parallel computer vendors have begun to exploit these new application areas of multimedia and data servers <ref> [21, 22] </ref>. data will be distributed across the nodes. Service requests are accepted through external network interfaces which use standard network adapters such as HIPPI, FDDI, ATM or ethernet.
Reference: [23] <institution> The Connection Machine CM-5 Technical Summary, Thinking Machines Corporation, </institution> <address> Cambridge, MA, </address> <month> October </month> <year> 1991. </year>
Reference-contexts: For instance, most existing multicomputer network switches such as the Thinking Machine's CM5 <ref> [23] </ref>, Intel Paragon [24], Cray T3D [25] and IBM SP2 [26] adopt simple arbitration strategies such as round-robin (RR) or first-come-first-serve (FCFS), which distribute resources uniformly to local traffic. <p> However, it is applied to switch ports, not network connections. To our knowledge, the ServerNet is the first integration of network resource control in multicomputer network routers. 4 Usually, multicomputer network switches support links shorter than 100m <ref> [23, 24, 25, 26, 28] </ref>; whereas, LAN and WAN span from a few kilometers to a few thousand kilometers. 39 In the remainder of the dissertation, we explore service disciplines for high-speed, low--cost multicomputer networks.
Reference: [24] <institution> Paragon XP/S Product Overview, Intel Corporation, </institution> <address> Portland, OR, </address> <year> 1991. </year>
Reference-contexts: For instance, most existing multicomputer network switches such as the Thinking Machine's CM5 [23], Intel Paragon <ref> [24] </ref>, Cray T3D [25] and IBM SP2 [26] adopt simple arbitration strategies such as round-robin (RR) or first-come-first-serve (FCFS), which distribute resources uniformly to local traffic. While permitting high-speed switching, simple arbitration mechanisms have limited ability to provide high performance to contemporary multicomputer networks, as well as support integrated-service networks. <p> While the worst-case delay bound can be derived for network parameters such as network topology, location of communicating nodes, and switch implementation details, the bound determined in this way is generally too large to be useful. For instance, in the Intel Paragon with 1,024 nodes <ref> [24] </ref>, a packet delay can be theoretically as large as several days. <p> However, it is applied to switch ports, not network connections. To our knowledge, the ServerNet is the first integration of network resource control in multicomputer network routers. 4 Usually, multicomputer network switches support links shorter than 100m <ref> [23, 24, 25, 26, 28] </ref>; whereas, LAN and WAN span from a few kilometers to a few thousand kilometers. 39 In the remainder of the dissertation, we explore service disciplines for high-speed, low--cost multicomputer networks. <p> and implementation cost, are compared to existing algorithms via analysis and simulations. 40 CHAPTER 3 INITIAL STUDY: EVALUATION OF THE TANDEM SERVERNET APPROACH Since the first development of multicomputers a decade ago, interconnection networks have developed dramatically in such areas as connection topologies, switching strategies, routing algorithms, flow control, etc. <ref> [8, 24, 26, 89, 90, 91, 92] </ref>. The main focus of network architects has been on efficient network resource utilization to improve throughput and average latency. <p> However, the arbitration logic is easily pipelined so that its impact on clock speed is minimal. The router operates at 50MHz, comparable to other commercial wormhole-routed switches such as the IBM SP1/2 [26], Meiko CS-2 [102] and Intel Paragon <ref> [24] </ref>. Moreover, compared to other simple routers, the ServerNet router also includes much more complicated logic for fault tolerance, which takes approximately 15% of the overall gate count. Considering the additional complexity as well, arbitration overhead surely has little impact on the switch operation speed. <p> Note that existing multicomputer networks with round-robin arbitration, for instance, the Intel Paragon <ref> [24] </ref> and Cray T3E [99], can theoretically provide delay guarantees of a few days for 1,024 node configurations. It should be emphasized that the delay bounds we derived above hold true independent of network states or other connections' behaviors.
Reference: [25] <institution> Cray T3D System Architecture Overview, Cray Research, Inc., Eagan, MN, </institution> <month> March </month> <year> 1993. </year>
Reference-contexts: For instance, most existing multicomputer network switches such as the Thinking Machine's CM5 [23], Intel Paragon [24], Cray T3D <ref> [25] </ref> and IBM SP2 [26] adopt simple arbitration strategies such as round-robin (RR) or first-come-first-serve (FCFS), which distribute resources uniformly to local traffic. While permitting high-speed switching, simple arbitration mechanisms have limited ability to provide high performance to contemporary multicomputer networks, as well as support integrated-service networks. <p> However, it is applied to switch ports, not network connections. To our knowledge, the ServerNet is the first integration of network resource control in multicomputer network routers. 4 Usually, multicomputer network switches support links shorter than 100m <ref> [23, 24, 25, 26, 28] </ref>; whereas, LAN and WAN span from a few kilometers to a few thousand kilometers. 39 In the remainder of the dissertation, we explore service disciplines for high-speed, low--cost multicomputer networks. <p> For example, the unbalanced usage of virtual channels required for deadlock prevention disrupts the topological symmetry of torus networks, which in general need two virtual channels to break link dependency cycles <ref> [25, 90, 98] </ref>. All of the messages to cross arbitrarily selected date lines (e.g., nodes at the end of each dimension) are assigned to one virtual channel, and others to the other virtual channel. More details on how they prevent deadlocks are in [90]. <p> However, it would be interesting to observe how network-resource control, in general, can be applied to such symmetric topology networks. Note that torus networks are currently being used in several commercial multicomputers such as Cray T3D <ref> [25] </ref> and T3E [99], and Fujitsu AP3000 [98]. biasing are used, respectively. We follow the virtual channel assignment method described in [100], where virtual channels are decided when packets are injected. <p> This is true especially for the networks in which the switch buffer size is large enough to contain more than a packet, as in, for instance, the Tandem ServerNet [28], IBM SP1/2 [26], and Cray T3D/T3E networks <ref> [25, 63] </ref>. The frame size in RCQ and SG networks is fixed at 16 packet slots, which is the maximum number of independent traffic streams a physical link can support at a time.
Reference: [26] <author> C.B. Stunkel, D.G. Shea, D.G. Grice, P.H. Hochschild, and M. Tsao. </author> <title> "The SP1 high-performance switch," </title> <booktitle> in Proceedings of the Scalable High Performance Computing Conference, </booktitle> <address> Knoxville, TN,, </address> <month> May </month> <year> 1994, </year> <pages> pp. 150-157. </pages> <note> Available from http:// ibm.tc.cornell.edu/ibm/pps/doc/hps.ps. </note>
Reference-contexts: For instance, most existing multicomputer network switches such as the Thinking Machine's CM5 [23], Intel Paragon [24], Cray T3D [25] and IBM SP2 <ref> [26] </ref> adopt simple arbitration strategies such as round-robin (RR) or first-come-first-serve (FCFS), which distribute resources uniformly to local traffic. While permitting high-speed switching, simple arbitration mechanisms have limited ability to provide high performance to contemporary multicomputer networks, as well as support integrated-service networks. <p> However, it is applied to switch ports, not network connections. To our knowledge, the ServerNet is the first integration of network resource control in multicomputer network routers. 4 Usually, multicomputer network switches support links shorter than 100m <ref> [23, 24, 25, 26, 28] </ref>; whereas, LAN and WAN span from a few kilometers to a few thousand kilometers. 39 In the remainder of the dissertation, we explore service disciplines for high-speed, low--cost multicomputer networks. <p> and implementation cost, are compared to existing algorithms via analysis and simulations. 40 CHAPTER 3 INITIAL STUDY: EVALUATION OF THE TANDEM SERVERNET APPROACH Since the first development of multicomputers a decade ago, interconnection networks have developed dramatically in such areas as connection topologies, switching strategies, routing algorithms, flow control, etc. <ref> [8, 24, 26, 89, 90, 91, 92] </ref>. The main focus of network architects has been on efficient network resource utilization to improve throughput and average latency. <p> However, the arbitration logic is easily pipelined so that its impact on clock speed is minimal. The router operates at 50MHz, comparable to other commercial wormhole-routed switches such as the IBM SP1/2 <ref> [26] </ref>, Meiko CS-2 [102] and Intel Paragon [24]. Moreover, compared to other simple routers, the ServerNet router also includes much more complicated logic for fault tolerance, which takes approximately 15% of the overall gate count. <p> In general, output queueing provides 87 significantly better performance than input queueing by reducing the head-of-line (HOL) blocking [104]. Some commercial multicomputer switches such as the IBM SP1/2 <ref> [26] </ref> actually implement output queueing for higher throughput. More importantly, output queueing makes it easier to distribute link bandwidth to demanding connections. Alternatively, for efficient utilization of buffer capacity in the switch, output buffers can be integrated into a large shared central buffer pool. <p> This is true especially for the networks in which the switch buffer size is large enough to contain more than a packet, as in, for instance, the Tandem ServerNet [28], IBM SP1/2 <ref> [26] </ref>, and Cray T3D/T3E networks [25, 63]. The frame size in RCQ and SG networks is fixed at 16 packet slots, which is the maximum number of independent traffic streams a physical link can support at a time. <p> Two topologies, other than meshes, are examined, hypercube and fat-tree, both of which are widely accepted in commercial multicomputer networks <ref> [26, 89, 102, 114] </ref>. Figure 6.13 illustrates node connections used in the experiment, each of which has the same number of nodes (16) as the mesh network in the previous section. Note that there are many possible variations on a fat-tree other than the one shown in the figure. <p> Mesh Hypercube Fat-tree Diameter 7 4 3 Average distance 4.5 2.9 2.7 Total Links 64 64 32 As in the mesh network, the hypercube network uses dimension-order routing. The fat-tree network uses random routing, as in existing multicomputer networks <ref> [26, 89, 102] </ref>, but in this case, a randomly-selected routing path is preserved for an entire session, not only for each packet. For the same number of nodes, these networks have different diameters, average distances and network capacities from mesh-connected networks, which are summarized in Table 6.2.
Reference: [27] <author> R. Mraz. </author> <title> "Reducing the variance of point-to-point transfers for parallel real-time programs," </title> <booktitle> IEEE Parallel & Distributed Technology, </booktitle> <pages> pp. 20-31, </pages> <month> Winter </month> <year> 1994. </year>
Reference-contexts: However, in addition to this, network-resource control can also improve the performance of traditional data communications substantially. For instance, network-resource control can reduce the variance in communication delays, which can improve parallel applications execution time significantly <ref> [27] </ref>. For transaction systems or large-scale networks for multiusers, network-resource control can be used to deliver fair service to end-users, ensuring that each user receives an equal share of network resources. Network performance guarantees can also be used to reduce communication protocol overheads. <p> The simple logic of the ALU-biasing arbitration mechanism introduces only about 10% overhead in transistors. (4) The resource-control scheme provides a range of system-level support. For instance, ALU-biased routers can improve the performance of many parallel applications by reducing the variance in communication delays <ref> [27] </ref>. Also, with ALU-biased routers, we can achieve uniform resource utilization even in the simpler asymmetric or arbitrary connection topologies. Its capability to support arbitrary network topologies makes system scaling much simpler.
Reference: [28] <author> R. Horst. "TNet: </author> <title> A reliable system area network," </title> <booktitle> IEEE Micro, </booktitle> <pages> pp. 37-45, </pages> <month> February </month> <year> 1995. </year>
Reference-contexts: Network performance guarantees can also be used to reduce communication protocol overheads. For instance, reliable computing can obtain substantial benefits from guaranteed 1 communication performance <ref> [28] </ref>. If the network guarantees the upper bound of packet delivery time, a designer can set the timeout value just above the worst-case latency, thereby reducing network resource waste significantly. <p> Actually, the ideas of resource control and service guarantees have come to be accepted by multicomputer network designers. In the recently introduced ServerNet routers <ref> [28] </ref>, Tandem implemented a novel architecture for network resource control called ALU-biasing arbitration. This arbitration scheme allocates output link bandwidth to input links proportionally to their reserved bandwidth. ServerNet is scalable parallel computing systems that are interconnected via high-speed wormhole routers. <p> However, it is applied to switch ports, not network connections. To our knowledge, the ServerNet is the first integration of network resource control in multicomputer network routers. 4 Usually, multicomputer network switches support links shorter than 100m <ref> [23, 24, 25, 26, 28] </ref>; whereas, LAN and WAN span from a few kilometers to a few thousand kilometers. 39 In the remainder of the dissertation, we explore service disciplines for high-speed, low--cost multicomputer networks. <p> In these networks, maintaining symmetricity in their topologies makes incremental system expansion difficult. In order to support emerging multimedia applications and new architectures issues, network resources must be controlled more flexibly at each router. Recently, Tandem introduced the ServerNet routers <ref> [28] </ref>, which implement a novel architecture for network-resource control called ALU-biasing arbitration. This network architecture is qualitatively different from most existing quantity-oriented multicomputer networks, potentially providing a higher quality of service. <p> Also note that in this chapter we intentionally use term router rather than switch, not because they have fundamental differences, but simply because the terminology is widely used in the multicomputer networks community, including the original paper introducing ServerNet <ref> [28] </ref>. 3.1 Tandem ServerNet Architecture Overview ServerNet 1 is a reliable system-area network supporting high-speed communications between processors and I/O devices. <p> The point-to-point connected, packet-switching network provides not only a high bandwidth of 50 MB/sec per link and a low router delay of 300 ns, but also flexibility to support the next-generation I/O requirement. Figure 3.1 shows 1 It was originally referred to as TNet (Trusted Network) in <ref> [28] </ref>. 42 (a) (b) and (b) the ServerNet router architecture. a Tandem cluster architecture where two redundant ServerNet networks further improve reliability supported by router-level fault-tolerance. The figure also shows the router architecture, which is 6x6 wormhole-routed with a buffer queue of 96 bytes given to each input port. <p> In terms of worst-case queueing and scheduling delays, packet switching has no significant difference from cut-through or wormhole-routed networks. This is true especially for the networks in which the switch buffer size is large enough to contain more than a packet, as in, for instance, the Tandem ServerNet <ref> [28] </ref>, IBM SP1/2 [26], and Cray T3D/T3E networks [25, 63]. The frame size in RCQ and SG networks is fixed at 16 packet slots, which is the maximum number of independent traffic streams a physical link can support at a time.
Reference: [29] <author> S. McCanne and V. Jacobson. </author> <title> "vic: A flexible framework for packet video," </title> <booktitle> in Proceedings of ACM Multimedia, </booktitle> <address> San Francisco, CA, </address> <month> November </month> <year> 1995, </year> <pages> pp. 511-22. 210 </pages>
Reference-contexts: Examples include video conferencing tools over the Internet <ref> [29, 30, 31] </ref> or video/audio broadcasting tools [32, 33]. These tools provide flexible functions for encoding and flow control at transport or upper layers to compensate for unpredictable network performance. These approaches are attractive because they support multimedia communications on existing network hardware.
Reference: [30] <author> R. Frederick. </author> <title> "Experience with real-time software video compression," </title> <booktitle> in Proceedings of the Sixth International Workshop on Packet Video, </booktitle> <month> Sept. </month> <year> 1994. </year>
Reference-contexts: Examples include video conferencing tools over the Internet <ref> [29, 30, 31] </ref> or video/audio broadcasting tools [32, 33]. These tools provide flexible functions for encoding and flow control at transport or upper layers to compensate for unpredictable network performance. These approaches are attractive because they support multimedia communications on existing network hardware.
Reference: [31] <author> T. Dorcey. </author> <title> "CU-SeeMe desktop videoconferencing software," </title> <journal> Connexions, </journal> <volume> vol. 9, no. 3, </volume> <month> March </month> <year> 1995. </year>
Reference-contexts: Examples include video conferencing tools over the Internet <ref> [29, 30, 31] </ref> or video/audio broadcasting tools [32, 33]. These tools provide flexible functions for encoding and flow control at transport or upper layers to compensate for unpredictable network performance. These approaches are attractive because they support multimedia communications on existing network hardware.
Reference: [32] <institution> Guide to the VDOLive Video Server & Tools, VDOnet Corporation, </institution> <address> Palo Alto, CA. </address> <note> Available from http://www.vdo.net. </note>
Reference-contexts: Examples include video conferencing tools over the Internet [29, 30, 31] or video/audio broadcasting tools <ref> [32, 33] </ref>. These tools provide flexible functions for encoding and flow control at transport or upper layers to compensate for unpredictable network performance. These approaches are attractive because they support multimedia communications on existing network hardware.
Reference: [33] <institution> Delivering time-based information over the Internet, Progressive Networks, </institution> <address> Seattle, WA. </address> <note> Available from http://www.realaudio.com/help/content/http vs ra.html. </note>
Reference-contexts: Examples include video conferencing tools over the Internet [29, 30, 31] or video/audio broadcasting tools <ref> [32, 33] </ref>. These tools provide flexible functions for encoding and flow control at transport or upper layers to compensate for unpredictable network performance. These approaches are attractive because they support multimedia communications on existing network hardware.
Reference: [34] <author> L. Zhang, S. Deering, D. Estrin, S. Shenker, and D. Zappala. "RSVP: </author> <title> A new resource ReSerVation Protocol," </title> <journal> IEEE Network, </journal> <volume> vol. 7, no. 5, </volume> <pages> pp. 8-18, </pages> <month> Sept. </month> <year> 1993. </year>
Reference-contexts: However, they serve only as a partial solution with limited QoS, including low frame rates and small page sizes and, most importantly, large and irregular packet drop rates. Eventually, to support QoS requirements, these software approaches will be complemented by more sophisticated network-resource control mechanisms <ref> [34] </ref> and intelligent switch architectures, which is the main topic of this dissertation. Network-resource control for providing service guarantees has long been a critical issue in real-time communications and many algorithms have been suggested for service guarantees 7 [35, 36, 37, 38, 39, 40, 41, 42].
Reference: [35] <author> L. Zhang. </author> <title> "Virtual clock: A new traffic control algorithm for packet switching networks," </title> <booktitle> in Proceedings of ACM SIGCOMM, </booktitle> <address> Philadelphia, PA, </address> <year> 1990, </year> <pages> pp. 19-29. </pages>
Reference-contexts: Network-resource control for providing service guarantees has long been a critical issue in real-time communications and many algorithms have been suggested for service guarantees 7 <ref> [35, 36, 37, 38, 39, 40, 41, 42] </ref>. However, in spite of their potential benefits, few existing computer networks actually adopt resource control mechanisms for service guarantees. This is primarily because the cost, complexity, or resource waste of existing solutions can easily overwhelm their expected benefits. <p> This is primarily because the cost, complexity, or resource waste of existing solutions can easily overwhelm their expected benefits. One of the widely accepted approaches to network service guarantees is to dynamically manage packet priorities based on each connection's requested service (or reserved resources) and traffic history <ref> [37, 35, 38, 40, 41] </ref>. By transmitting packets in their priority order, this approach can provide bandwidth and delay bounds guarantees. Also, it supports a variety of traffic types (real-time and best-effort) efficiently in a single framework. <p> While these approaches permit simpler control at the switch, they can sometimes provide only limited controllability. 1 They are also called sorted-priority mechanism [58] or time-stamp based scheme [66]. 24 Table 2.1: Classification of existing algorithms. Delay-Oriented Bandwidth-Oriented Priority-Based CODA [68] FQ [37] RACE [69] VC <ref> [35] </ref> TDC [70] PGPS [38] DEDD [40] SCFQ [57] JEDD [71] FFQ [58] RCSD [39] Non-Work-Conserving Work-Conserving Frame-Based SG [36] WRR [72] HRR [43] DRR [73] Most priority-based scheduling algorithms share common disciplines, but can appear quite different based on their motivations and targeting applications. <p> Also, with the source-level rate control, buffering overflow can be avoided with a limited buffering capacity at the switch. A similar scheme to FQ and PGPS called Virtual Clock (VC) has been developed by Zhang <ref> [35] </ref>, which can guarantee arbitrary amounts of bandwidth reserved for each end-user, but permitting much simpler implementation than them. Network bandwidth is controlled using an index value, virtual clock, of each virtual connection, which reflects the amount of reserved bandwidth and traffic history through the connection. <p> This kind of coupling effect can be observed in any network with shared queues that avoids packet drops by using flow control. One obvious solution is to manage a separate queue per possible connection, as assumed in <ref> [35, 37] </ref>, so that the traffic of a connection can never be blocked by other connection traffic. However, this approach is rather complex for low-cost, high-performance network routers. <p> This approach not only guarantees reserved bandwidth to each connection, but it also uniformly schedules packets of a connection. Fair Queueing [37], PGPS [38] and Virtual Clock <ref> [35] </ref> belong to this category. Unfortunately, these algorithms require large implementation complexity [79, 77]. Many researchers have developed approximate algorithms to make the basic idea feasible [82, 57, 83, 58], but they still need complicated control logic for priority comparisons. <p> The Available Bit Rate (ABR) traffic model has neither the fixed interval between traffic bursts nor fixed burst size. It generates traffic of train model <ref> [35] </ref>, where two independent random variables are used for intermessage intervals and message sizes. Because simulated traffic bandwidth is dependent on simulated link bandwidth, we represent the traffic rate relative to the basic CBR traffic stream, which reserves a packet slot per frame time (r slot bandwidth in Table 6.1). <p> The dynamic buffering scheme is similar in buffer management to dynamic buffer sharing for connection queues in priority-based schemes (e.g., Virtual Clock <ref> [35] </ref> and Fair Queueing [37]). However, two differences between their queueing schemes should be made clear. First, the number of queues in an RCQ port is independent of and can be much less than the number of connections. <p> In addition to increasing the range of supported connection bandwidth, this hierarchical scheme helps schedule packets for the same connection more uniformly inside each frame, just as in priority-based approaches (e.g., Virtual Clock <ref> [35] </ref> and Fair Queueing [37]), but with relatively negligible overhead.
Reference: [36] <author> S. J. Golestani. </author> <title> "Congestion-free communication in high-speed packet networks," </title> <journal> IEEE Transactions on Communications, </journal> <volume> vol. 39, no. 12, </volume> <pages> pp. 1802-1812, </pages> <month> Dec. </month> <year> 1991. </year>
Reference-contexts: Network-resource control for providing service guarantees has long been a critical issue in real-time communications and many algorithms have been suggested for service guarantees 7 <ref> [35, 36, 37, 38, 39, 40, 41, 42] </ref>. However, in spite of their potential benefits, few existing computer networks actually adopt resource control mechanisms for service guarantees. This is primarily because the cost, complexity, or resource waste of existing solutions can easily overwhelm their expected benefits. <p> Several researchers have proposed simpler solutions which share the basic idea of allocating a certain number of packet slots to each connection (in proportion to reserved bandwidth) in a fixed frame time (similar to time-division circuit multiplexing) <ref> [36, 43, 39] </ref>. Compared to priority-based schemes, these frame-based schemes can provide guaranteed services at a much lower control complexity. However, this approach wastes precious network bandwidth when some connections do not fully utilize their reserved portions. Consequently, the frame-based approach has limitations in efficiently supporting bursty, best-effort communications. <p> Delay-Oriented Bandwidth-Oriented Priority-Based CODA [68] FQ [37] RACE [69] VC [35] TDC [70] PGPS [38] DEDD [40] SCFQ [57] JEDD [71] FFQ [58] RCSD [39] Non-Work-Conserving Work-Conserving Frame-Based SG <ref> [36] </ref> WRR [72] HRR [43] DRR [73] Most priority-based scheduling algorithms share common disciplines, but can appear quite different based on their motivations and targeting applications. <p> Merging multiple connections with the same traffic characteristics and service requirements seems to be an effective technique to reduce queueing and scheduling overhead. However, merged connections can lose each traffic smoothness due to interactions with each other. For details, see <ref> [36] </ref>. 3 A token bucket is different from a leaky bucket in that limited burstiness is allowed in the former but not in the latter. 29 giving higher priority to packets with lower virtual clock values, the Virtual Clock discipline guarantees the reserved bandwidth to each connection. <p> waste is motivated by two major observations: (1) input traffic regulation at the network entrance, such as a leaky bucket [47], is not sufficient because the smoothness at the injection level cannot be preserved inside of the network due to irregular and unpredictable interactions of a number of traffic streams <ref> [36] </ref>, and (2) many real-time communications only require that packets are delivered within the delay bound, no faster than that, so extra bandwidth may not be useful to such real-time communications. Stop-and-Go (SG) [36] is a well-known example of non-work-conserving service disciplines. <p> preserved inside of the network due to irregular and unpredictable interactions of a number of traffic streams <ref> [36] </ref>, and (2) many real-time communications only require that packets are delivered within the delay bound, no faster than that, so extra bandwidth may not be useful to such real-time communications. Stop-and-Go (SG) [36] is a well-known example of non-work-conserving service disciplines. During each frame interval, the source for each connection is strictly limited to inject, at most, as many packets as reserved packet slots, and each switch transmits all and only packets which have arrived during the last frame time. <p> As a compromise, many researchers suggest that several frame sizes be used together to reduce the coupling problem, which can eliminate the limitation to some extent with increased control complexity <ref> [36, 43] </ref>. 2.3.3 Combined virtual network approaches Many algorithms, typically Fair Queueing and similar ones, extend conventional data communication networks to provide guaranteed services. Consequently, these approaches support different traffic types in an integrated framework. <p> The delay bounds for SG and RCQ are similar. Assuming global clocks for frame synchronizations, the packet delay in the SG network is bounded by D pkt 2 fi T frame fi H; because a packet takes, at most, two frame times at each switch along the path <ref> [36] </ref>. This is two times larger than that of the RCQ network. An important advantage of SG over RCQ is that SG provides small delay jitter bounds of, at most, one frame time, which helps to reduce smoothing buffers at the receiver nodes. <p> However, as observed above, the frame size has been shown to be a dominating factor in the implementation cost, so we cannot reduce the granularity as much as needed. As a compromising solution, a hierarchical frame structure has been suggested by other researchers <ref> [36, 43] </ref>, where the switch supports multiple sets of frame sizes simultaneously, each of which is used for different bandwidth granularity. The integration of the queueing and scheduling mechanism in RCQ makes the implementation of such hierarchical framing much easier. <p> Thus, it cannot efficiently support both communications with low delay bounds requirements and communications with a low bandwidth requirement. In previous work <ref> [36] </ref>, hierarchical framing was proposed as a solution, which can also be applied to the RCQ switch with a corresponding increase in implementation complexity. 8.3 Other Factors to be Considered Our suggested algorithm and its implementation may still be beyond the budget of many commercial multicomputer network designers.
Reference: [37] <author> A. Demers, S. Keshav, and S. Shenker. </author> <title> "Analysis and simulations of a fair queueing algorithm," </title> <booktitle> in Proceedings of ACM SIGCOMM, </booktitle> <address> Austin, TX, </address> <year> 1989, </year> <pages> pp. 3-12. </pages>
Reference-contexts: Network-resource control for providing service guarantees has long been a critical issue in real-time communications and many algorithms have been suggested for service guarantees 7 <ref> [35, 36, 37, 38, 39, 40, 41, 42] </ref>. However, in spite of their potential benefits, few existing computer networks actually adopt resource control mechanisms for service guarantees. This is primarily because the cost, complexity, or resource waste of existing solutions can easily overwhelm their expected benefits. <p> This is primarily because the cost, complexity, or resource waste of existing solutions can easily overwhelm their expected benefits. One of the widely accepted approaches to network service guarantees is to dynamically manage packet priorities based on each connection's requested service (or reserved resources) and traffic history <ref> [37, 35, 38, 40, 41] </ref>. By transmitting packets in their priority order, this approach can provide bandwidth and delay bounds guarantees. Also, it supports a variety of traffic types (real-time and best-effort) efficiently in a single framework. <p> While these approaches permit simpler control at the switch, they can sometimes provide only limited controllability. 1 They are also called sorted-priority mechanism [58] or time-stamp based scheme [66]. 24 Table 2.1: Classification of existing algorithms. Delay-Oriented Bandwidth-Oriented Priority-Based CODA [68] FQ <ref> [37] </ref> RACE [69] VC [35] TDC [70] PGPS [38] DEDD [40] SCFQ [57] JEDD [71] FFQ [58] RCSD [39] Non-Work-Conserving Work-Conserving Frame-Based SG [36] WRR [72] HRR [43] DRR [73] Most priority-based scheduling algorithms share common disciplines, but can appear quite different based on their motivations and targeting applications. <p> Compared to the conventional FCFS scheme, this new queueing and scheduling scheme improves protection and fairness dramatically. This idea was refined by Demers et al. to generalize and consequently overcome limitations of the original fair queueing that assumes equal-sized packets and equal amounts of services to end-users <ref> [37] </ref>. The new algorithm called Fair Queueing (FQ) guarantees equal bandwidth allocation to each virtual connection by emulating bit-by-bit, round-robin scheduling at the packet level. Each packet is assigned the virtual round number when it would complete transmission under bit-by-bit, round-robin scheduling. <p> This kind of coupling effect can be observed in any network with shared queues that avoids packet drops by using flow control. One obvious solution is to manage a separate queue per possible connection, as assumed in <ref> [35, 37] </ref>, so that the traffic of a connection can never be blocked by other connection traffic. However, this approach is rather complex for low-cost, high-performance network routers. <p> briefly revisit the related work covered in Chapter 2), we present our algorithm, which is a combination of frame-based scheduling with shared queueing. 4.2.1 Scheduling: priority-based or frame-based? The ideal scheduling discipline is based on infinitesimal units, where for every cycle, data amounts proportional to reserved bandwidth are served instantaneously <ref> [37, 38] </ref>. However, such a model is not realistic; all practical systems schedule packet-by-packet whose sizes are limited by a fixed-amount of overheads for multiplexing information. <p> This approach not only guarantees reserved bandwidth to each connection, but it also uniformly schedules packets of a connection. Fair Queueing <ref> [37] </ref>, PGPS [38] and Virtual Clock [35] belong to this category. Unfortunately, these algorithms require large implementation complexity [79, 77]. Many researchers have developed approximate algorithms to make the basic idea feasible [82, 57, 83, 58], but they still need complicated control logic for priority comparisons. <p> The improvement issues in frame-based scheduling networks to support such applications are discussed in more detail in Chapter 7. A generic frame-based scheduling algorithm can be described as follows, using the similar notations as in <ref> [37, 57, 58] </ref>, which can be considered as a superset of the previous work-conserving, frame-based algorithms: 94 Notation: F rame : The current system frame number, unique per output link. <p> The dynamic buffering scheme is similar in buffer management to dynamic buffer sharing for connection queues in priority-based schemes (e.g., Virtual Clock [35] and Fair Queueing <ref> [37] </ref>). However, two differences between their queueing schemes should be made clear. First, the number of queues in an RCQ port is independent of and can be much less than the number of connections. <p> In addition to increasing the range of supported connection bandwidth, this hierarchical scheme helps schedule packets for the same connection more uniformly inside each frame, just as in priority-based approaches (e.g., Virtual Clock [35] and Fair Queueing <ref> [37] </ref>), but with relatively negligible overhead.
Reference: [38] <author> A. Parekh and R. Gallager. </author> <title> "A generalized processor sharing approach to flow control in integrated services networks the single node case," </title> <booktitle> in Proceedings of IEEE INFOCOM, </booktitle> <address> Florence, Italy, </address> <year> 1992, </year> <pages> pp. 915-924. </pages>
Reference-contexts: Network-resource control for providing service guarantees has long been a critical issue in real-time communications and many algorithms have been suggested for service guarantees 7 <ref> [35, 36, 37, 38, 39, 40, 41, 42] </ref>. However, in spite of their potential benefits, few existing computer networks actually adopt resource control mechanisms for service guarantees. This is primarily because the cost, complexity, or resource waste of existing solutions can easily overwhelm their expected benefits. <p> This is primarily because the cost, complexity, or resource waste of existing solutions can easily overwhelm their expected benefits. One of the widely accepted approaches to network service guarantees is to dynamically manage packet priorities based on each connection's requested service (or reserved resources) and traffic history <ref> [37, 35, 38, 40, 41] </ref>. By transmitting packets in their priority order, this approach can provide bandwidth and delay bounds guarantees. Also, it supports a variety of traffic types (real-time and best-effort) efficiently in a single framework. <p> Moreover, if each connection accumulates credits for its idle time, unpredictability in traffic arrival patterns makes network resource control nearly impossible. This definition of bandwidth guarantees is similar to those used in other works <ref> [38, 57, 58] </ref>. Delay bounds guarantees For distributed real-time applications in which messages arrive later than deadlines lose their value either partially or completely, delay bounds must be guaranteed. For communications such as distributed control messages, which require absolute delay bounds, guarantee must be deterministic. <p> Delay-Oriented Bandwidth-Oriented Priority-Based CODA [68] FQ [37] RACE [69] VC [35] TDC [70] PGPS <ref> [38] </ref> DEDD [40] SCFQ [57] JEDD [71] FFQ [58] RCSD [39] Non-Work-Conserving Work-Conserving Frame-Based SG [36] WRR [72] HRR [43] DRR [73] Most priority-based scheduling algorithms share common disciplines, but can appear quite different based on their motivations and targeting applications. <p> FQ requires large overhead for priority calculation because it emulates a bit-by-bit fluid-flow model. Details on priority calculation are discussed in [79]. Parekh and Gallager also introduced a nearly identical approach to Fair Queueing called Packet-by-Packet General Processor Sharing (PGPS) <ref> [38, 80] </ref>. Their basic contribution is to show that fair scheduling mechanisms can also be used to guarantee delay bounds when well-defined traffic rate controls are used at network entrances. <p> Our efforts at analysis indicate that even for a bandwidth allocation algorithm as simple as ALU biasing, system dynamics can be remarkably subtle and complicated. The analysis shown below is more complicated than those done for other priority-based algorithms as in <ref> [38, 58] </ref>. This is partly because ServerNet targets high-speed communications, so delay bounds analyses in much finer units are desirable. <p> We believe that this is partly because it is much easier to control bandwidth than latency, but more importantly because it is widely known that we can get delay bounds guarantees automatically once bandwidth is guaranteed. Although this is true for some approaches suggested for long-haul networks <ref> [38] </ref>, implementation of such schemes is prohibitively expensive. Their control complexity stems from the purpose of providing uniform interleaving of different traffic streams with different reserved bandwidth. On the other hand, a low-cost compromise as in ServerNet makes delay guarantees more difficult. <p> briefly revisit the related work covered in Chapter 2), we present our algorithm, which is a combination of frame-based scheduling with shared queueing. 4.2.1 Scheduling: priority-based or frame-based? The ideal scheduling discipline is based on infinitesimal units, where for every cycle, data amounts proportional to reserved bandwidth are served instantaneously <ref> [37, 38] </ref>. However, such a model is not realistic; all practical systems schedule packet-by-packet whose sizes are limited by a fixed-amount of overheads for multiplexing information. <p> This approach not only guarantees reserved bandwidth to each connection, but it also uniformly schedules packets of a connection. Fair Queueing [37], PGPS <ref> [38] </ref> and Virtual Clock [35] belong to this category. Unfortunately, these algorithms require large implementation complexity [79, 77]. Many researchers have developed approximate algorithms to make the basic idea feasible [82, 57, 83, 58], but they still need complicated control logic for priority comparisons.
Reference: [39] <author> H. Zhang and D. Ferrari. </author> <title> "Rate-controlled static-priority queueing," </title> <booktitle> in Proceedings of IEEE INFOCOM, </booktitle> <address> San Francisco, CA, </address> <year> 1993, </year> <pages> pp. 227-236. 211 </pages>
Reference-contexts: Network-resource control for providing service guarantees has long been a critical issue in real-time communications and many algorithms have been suggested for service guarantees 7 <ref> [35, 36, 37, 38, 39, 40, 41, 42] </ref>. However, in spite of their potential benefits, few existing computer networks actually adopt resource control mechanisms for service guarantees. This is primarily because the cost, complexity, or resource waste of existing solutions can easily overwhelm their expected benefits. <p> Several researchers have proposed simpler solutions which share the basic idea of allocating a certain number of packet slots to each connection (in proportion to reserved bandwidth) in a fixed frame time (similar to time-division circuit multiplexing) <ref> [36, 43, 39] </ref>. Compared to priority-based schemes, these frame-based schemes can provide guaranteed services at a much lower control complexity. However, this approach wastes precious network bandwidth when some connections do not fully utilize their reserved portions. Consequently, the frame-based approach has limitations in efficiently supporting bursty, best-effort communications. <p> Delay-Oriented Bandwidth-Oriented Priority-Based CODA [68] FQ [37] RACE [69] VC [35] TDC [70] PGPS [38] DEDD [40] SCFQ [57] JEDD [71] FFQ [58] RCSD <ref> [39] </ref> Non-Work-Conserving Work-Conserving Frame-Based SG [36] WRR [72] HRR [43] DRR [73] Most priority-based scheduling algorithms share common disciplines, but can appear quite different based on their motivations and targeting applications. <p> However, beyond that, it shares the same scheduling mechanism with other priority-based schemes, so it still requires much complexity. Hybrid approaches While these bandwidth-oriented algorithms also guarantee delay bounds, they are limited in that the smallest delay bounds are determined by reserved bandwidth. In <ref> [39, 75] </ref>, Zhang and Ferrari suggested a framework called Rate-Controlled Service Discipline that can control bandwidth and delay bounds independently with separation of the servers into rate controllers and schedulers. <p> A similar idea has been proposed by many other researchers 35 as well and, in fact, most non-work-conserving algorithms were suggested to be combined with independent best-effort traffic queueing systems that can exploit bandwidth unclaimed by real-time traffic <ref> [39, 40, 41, 43] </ref>. While optimally supporting extreme traffic types requiring either efficiency or guaranteed services, this approach is limited in supporting a range of traffic spectrums that require both efficiency and guaranteed services.
Reference: [40] <author> D. Ferrari and D. Verma. </author> <title> "A scheme for real-time channel establishment in wide-area networks," </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> vol. 8, no. 3, </volume> <pages> pp. 368-379, </pages> <month> Apr. </month> <year> 1990. </year>
Reference-contexts: Network-resource control for providing service guarantees has long been a critical issue in real-time communications and many algorithms have been suggested for service guarantees 7 <ref> [35, 36, 37, 38, 39, 40, 41, 42] </ref>. However, in spite of their potential benefits, few existing computer networks actually adopt resource control mechanisms for service guarantees. This is primarily because the cost, complexity, or resource waste of existing solutions can easily overwhelm their expected benefits. <p> This is primarily because the cost, complexity, or resource waste of existing solutions can easily overwhelm their expected benefits. One of the widely accepted approaches to network service guarantees is to dynamically manage packet priorities based on each connection's requested service (or reserved resources) and traffic history <ref> [37, 35, 38, 40, 41] </ref>. By transmitting packets in their priority order, this approach can provide bandwidth and delay bounds guarantees. Also, it supports a variety of traffic types (real-time and best-effort) efficiently in a single framework. <p> For communications such as distributed control messages, which require absolute delay bounds, guarantee must be deterministic. However, for other applications, such as telecommunications, for which small portions of traffic loss are tolerable, guarantees can be statistical, potentially reducing control complexity and improving network efficiency <ref> [40, 48] </ref>. One of the important factors to be considered in evaluating network qualities related to delay-bound guarantees is the basic communication unit at application layers, which determines the unit size for delivery guarantees at lower communication layers. <p> Delay-Oriented Bandwidth-Oriented Priority-Based CODA [68] FQ [37] RACE [69] VC [35] TDC [70] PGPS [38] DEDD <ref> [40] </ref> SCFQ [57] JEDD [71] FFQ [58] RCSD [39] Non-Work-Conserving Work-Conserving Frame-Based SG [36] WRR [72] HRR [43] DRR [73] Most priority-based scheduling algorithms share common disciplines, but can appear quite different based on their motivations and targeting applications. <p> More reliable approaches are to give priorities to packets dynamically depending on traffic history not static priorities to connections. A well-known example of such dynamic priority schemes is Delay Earliest-Due-Date (DEDD) introduced in <ref> [40] </ref> and further refined in [41]. At connection setup time, the required end-to-end delay bound is split into multiple smaller delay bounds for each switch along the path. <p> A similar idea has been proposed by many other researchers 35 as well and, in fact, most non-work-conserving algorithms were suggested to be combined with independent best-effort traffic queueing systems that can exploit bandwidth unclaimed by real-time traffic <ref> [39, 40, 41, 43] </ref>. While optimally supporting extreme traffic types requiring either efficiency or guaranteed services, this approach is limited in supporting a range of traffic spectrums that require both efficiency and guaranteed services.
Reference: [41] <author> D. Kandlur, K. Shin, and D. Ferrari. </author> <title> "Real-time communication in multihop networks," </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> vol. 5, no. 10, </volume> <pages> pp. 1044-1056, </pages> <month> Oct. </month> <year> 1994. </year>
Reference-contexts: Network-resource control for providing service guarantees has long been a critical issue in real-time communications and many algorithms have been suggested for service guarantees 7 <ref> [35, 36, 37, 38, 39, 40, 41, 42] </ref>. However, in spite of their potential benefits, few existing computer networks actually adopt resource control mechanisms for service guarantees. This is primarily because the cost, complexity, or resource waste of existing solutions can easily overwhelm their expected benefits. <p> This is primarily because the cost, complexity, or resource waste of existing solutions can easily overwhelm their expected benefits. One of the widely accepted approaches to network service guarantees is to dynamically manage packet priorities based on each connection's requested service (or reserved resources) and traffic history <ref> [37, 35, 38, 40, 41] </ref>. By transmitting packets in their priority order, this approach can provide bandwidth and delay bounds guarantees. Also, it supports a variety of traffic types (real-time and best-effort) efficiently in a single framework. <p> More reliable approaches are to give priorities to packets dynamically depending on traffic history not static priorities to connections. A well-known example of such dynamic priority schemes is Delay Earliest-Due-Date (DEDD) introduced in [40] and further refined in <ref> [41] </ref>. At connection setup time, the required end-to-end delay bound is split into multiple smaller delay bounds for each switch along the path. The switch schedules packets to satisfy the switch delay bound of each connection by giving higher priority to the one with the earliest delay bound. <p> A similar idea has been proposed by many other researchers 35 as well and, in fact, most non-work-conserving algorithms were suggested to be combined with independent best-effort traffic queueing systems that can exploit bandwidth unclaimed by real-time traffic <ref> [39, 40, 41, 43] </ref>. While optimally supporting extreme traffic types requiring either efficiency or guaranteed services, this approach is limited in supporting a range of traffic spectrums that require both efficiency and guaranteed services.
Reference: [42] <author> J. Hyman, A. Lazar, and G. Pacifici. </author> <title> "Real-time scheduling with quality of service constraints," </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> vol. 9, no. 7, </volume> <pages> pp. 1052-1063, </pages> <month> Sept. </month> <year> 1991. </year>
Reference-contexts: Network-resource control for providing service guarantees has long been a critical issue in real-time communications and many algorithms have been suggested for service guarantees 7 <ref> [35, 36, 37, 38, 39, 40, 41, 42] </ref>. However, in spite of their potential benefits, few existing computer networks actually adopt resource control mechanisms for service guarantees. This is primarily because the cost, complexity, or resource waste of existing solutions can easily overwhelm their expected benefits. <p> Output queueing requires high-bandwidth connections between input and output modules inside a switch, which must be able to transfer packets at a speed k times the link speed. The high bandwidth connection can be implemented by using multiple broadcasting buses <ref> [42, 105] </ref> or replicated crossbars [106]. In [107], a compromise between the internal bandwidth requirement of the output queueing switch and performance is suggested, dropping packets when too many packets arrive for an output channel simultaneously. Unfortunately, the dropping scheme cannot be applied to the network for deterministic service guarantee.
Reference: [43] <author> C. Kalmanek, H. Kanakia, and S. Keshav. </author> <title> "Rate controlled servers for very high-speed networks," </title> <booktitle> in Proceedings of IEEE Global Telecommunications Conference, </booktitle> <address> San Diego, CA, </address> <year> 1990, </year> <pages> pp. </pages> <address> 300.3.1 - 300.3.9. </address>
Reference-contexts: Several researchers have proposed simpler solutions which share the basic idea of allocating a certain number of packet slots to each connection (in proportion to reserved bandwidth) in a fixed frame time (similar to time-division circuit multiplexing) <ref> [36, 43, 39] </ref>. Compared to priority-based schemes, these frame-based schemes can provide guaranteed services at a much lower control complexity. However, this approach wastes precious network bandwidth when some connections do not fully utilize their reserved portions. Consequently, the frame-based approach has limitations in efficiently supporting bursty, best-effort communications. <p> Delay-Oriented Bandwidth-Oriented Priority-Based CODA [68] FQ [37] RACE [69] VC [35] TDC [70] PGPS [38] DEDD [40] SCFQ [57] JEDD [71] FFQ [58] RCSD [39] Non-Work-Conserving Work-Conserving Frame-Based SG [36] WRR [72] HRR <ref> [43] </ref> DRR [73] Most priority-based scheduling algorithms share common disciplines, but can appear quite different based on their motivations and targeting applications. For better understanding, they are classified again into delay-oriented schemes and bandwidth-oriented schemes, depending on whether their primary goal is to provide delay bounds or bandwidth guarantees. <p> In addition, it has the problem of vulnerability to ill-behaved users. When a user transmits traffic at a higher rate than reserved, then other users may not receive proper services. Hierarchical Round Robin <ref> [43] </ref> is similar to the SG discipline in that bandwidth is controlled by the number of packet slots reserved in a frame time. As in SG, each connection reserves a fixed number of slots out of a fixed-size frame. <p> As a compromise, many researchers suggest that several frame sizes be used together to reduce the coupling problem, which can eliminate the limitation to some extent with increased control complexity <ref> [36, 43] </ref>. 2.3.3 Combined virtual network approaches Many algorithms, typically Fair Queueing and similar ones, extend conventional data communication networks to provide guaranteed services. Consequently, these approaches support different traffic types in an integrated framework. <p> A similar idea has been proposed by many other researchers 35 as well and, in fact, most non-work-conserving algorithms were suggested to be combined with independent best-effort traffic queueing systems that can exploit bandwidth unclaimed by real-time traffic <ref> [39, 40, 41, 43] </ref>. While optimally supporting extreme traffic types requiring either efficiency or guaranteed services, this approach is limited in supporting a range of traffic spectrums that require both efficiency and guaranteed services. <p> However, as observed above, the frame size has been shown to be a dominating factor in the implementation cost, so we cannot reduce the granularity as much as needed. As a compromising solution, a hierarchical frame structure has been suggested by other researchers <ref> [36, 43] </ref>, where the switch supports multiple sets of frame sizes simultaneously, each of which is used for different bandwidth granularity. The integration of the queueing and scheduling mechanism in RCQ makes the implementation of such hierarchical framing much easier.
Reference: [44] <author> A. Campbell, G. Coulson, and D. Hutchison. </author> <title> "A quality of service architecture," </title> <journal> ACM SIGCOMM Computer Communications Review, </journal> <volume> vol. 14, </volume> <pages> pp. 6-27, </pages> <year> 1994. </year>
Reference-contexts: Network service controls involve an admission control policy, monitoring and traffic regulations, routing, flow control, and service disciplines at switches such as scheduling and queueing <ref> [44, 45, 46, 47, 48, 49, 50, 51] </ref>. Amongst these, this dissertation focuses on issues related to scheduling and queueing mechanisms at a switch, which are fundamental requirements for any guaranteed services in distributed systems. This chapter presents general background on these issues.
Reference: [45] <author> J. Bae and T. Suda. </author> <title> "Survey of traffic control schemes and protocols in ATM networks," </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> vol. 79, no. 2, </volume> <pages> pp. 170-189, </pages> <month> Feb. </month> <year> 1991. </year>
Reference-contexts: Network service controls involve an admission control policy, monitoring and traffic regulations, routing, flow control, and service disciplines at switches such as scheduling and queueing <ref> [44, 45, 46, 47, 48, 49, 50, 51] </ref>. Amongst these, this dissertation focuses on issues related to scheduling and queueing mechanisms at a switch, which are fundamental requirements for any guaranteed services in distributed systems. This chapter presents general background on these issues.
Reference: [46] <author> C. M. Aras, J. F. Kurose, D. S. Reeves, and H. Schulzrinne. </author> <title> "Real-time communication in packet-switched networks," </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> vol. 82, no. 1, </volume> <pages> pp. 122-139, </pages> <month> January </month> <year> 1994. </year>
Reference-contexts: Network service controls involve an admission control policy, monitoring and traffic regulations, routing, flow control, and service disciplines at switches such as scheduling and queueing <ref> [44, 45, 46, 47, 48, 49, 50, 51] </ref>. Amongst these, this dissertation focuses on issues related to scheduling and queueing mechanisms at a switch, which are fundamental requirements for any guaranteed services in distributed systems. This chapter presents general background on these issues.
Reference: [47] <author> J. Turner. </author> <title> "New directions in communications (or which way to the information age?)," </title> <journal> IEEE Communications Magazine, </journal> <volume> vol. 24, no. 10, </volume> <pages> pp. 8-15, </pages> <month> Oct. </month> <year> 1986. </year>
Reference-contexts: Network service controls involve an admission control policy, monitoring and traffic regulations, routing, flow control, and service disciplines at switches such as scheduling and queueing <ref> [44, 45, 46, 47, 48, 49, 50, 51] </ref>. Amongst these, this dissertation focuses on issues related to scheduling and queueing mechanisms at a switch, which are fundamental requirements for any guaranteed services in distributed systems. This chapter presents general background on these issues. <p> Their basic contribution is to show that fair scheduling mechanisms can also be used to guarantee delay bounds when well-defined traffic rate controls are used at network entrances. When the maximum bursti-ness of each connection is strictly constrained by a source-level rate-control mechanism such as a token bucket 3 <ref> [47, 66, 81] </ref>, the worst-case congestion inside the network is limited, so deterministic delay bounds can be guaranteed. The delay bound of a connection is determined solely by the amount of reserved bandwidth and allowed traffic burstiness. <p> The switch-level rate control at the cost of bandwidth waste is motivated by two major observations: (1) input traffic regulation at the network entrance, such as a leaky bucket <ref> [47] </ref>, is not sufficient because the smoothness at the injection level cannot be preserved inside of the network due to irregular and unpredictable interactions of a number of traffic streams [36], and (2) many real-time communications only require that packets are delivered within the delay bound, no faster than that, so <p> Traffic congestion is usually constrained by either a source-level rate control <ref> [47] </ref> or a feedback-based flow control [108]. While the former approach helps to provide guaranteed services inside the network and also build simpler switches, the latter approach allows connections to exploit network bandwidth more efficiently, so it is accepted by most existing multicomputer networks.
Reference: [48] <author> J. Kurose. </author> <title> "Open issues and challenges in providing quality of service guarantees in high-speed networks," </title> <journal> ACM Computer Communications Review, </journal> <volume> vol. 23, no. 1, </volume> <pages> pp. 6-15, </pages> <month> Jan. </month> <year> 1993. </year> <month> 212 </month>
Reference-contexts: Network service controls involve an admission control policy, monitoring and traffic regulations, routing, flow control, and service disciplines at switches such as scheduling and queueing <ref> [44, 45, 46, 47, 48, 49, 50, 51] </ref>. Amongst these, this dissertation focuses on issues related to scheduling and queueing mechanisms at a switch, which are fundamental requirements for any guaranteed services in distributed systems. This chapter presents general background on these issues. <p> For communications such as distributed control messages, which require absolute delay bounds, guarantee must be deterministic. However, for other applications, such as telecommunications, for which small portions of traffic loss are tolerable, guarantees can be statistical, potentially reducing control complexity and improving network efficiency <ref> [40, 48] </ref>. One of the important factors to be considered in evaluating network qualities related to delay-bound guarantees is the basic communication unit at application layers, which determines the unit size for delivery guarantees at lower communication layers.
Reference: [49] <author> C. Baransel, W. Dobosiewicz, and P. Gburzynski. </author> <title> "Routing in multihop packet switch-ing networks: Gb/s challenge," </title> <journal> IEEE Network, </journal> <volume> vol. 9, no. 3, </volume> <pages> pp. 38-61, </pages> <month> May/June </month> <year> 1995. </year>
Reference-contexts: Network service controls involve an admission control policy, monitoring and traffic regulations, routing, flow control, and service disciplines at switches such as scheduling and queueing <ref> [44, 45, 46, 47, 48, 49, 50, 51] </ref>. Amongst these, this dissertation focuses on issues related to scheduling and queueing mechanisms at a switch, which are fundamental requirements for any guaranteed services in distributed systems. This chapter presents general background on these issues.
Reference: [50] <author> Q. Ma, P. Steenkiste, and H. Zhang. </author> <title> "Routing high-bandwidth traffic in max-min fair share networks," </title> <booktitle> in Proceedings of ACM SIGCOMM, </booktitle> <address> New York, NY, </address> <year> 1996, </year> <pages> pp. 206-218. </pages>
Reference-contexts: Network service controls involve an admission control policy, monitoring and traffic regulations, routing, flow control, and service disciplines at switches such as scheduling and queueing <ref> [44, 45, 46, 47, 48, 49, 50, 51] </ref>. Amongst these, this dissertation focuses on issues related to scheduling and queueing mechanisms at a switch, which are fundamental requirements for any guaranteed services in distributed systems. This chapter presents general background on these issues.
Reference: [51] <author> S. Lam, S. Chow, and D. Yau. </author> <title> "An algorithm for lossless smoothing of MPEG video," </title> <booktitle> in Proceedings of ACM SIGCOMM, </booktitle> <address> London, UK, </address> <year> 1994, </year> <pages> pp. 281-293. </pages>
Reference-contexts: Network service controls involve an admission control policy, monitoring and traffic regulations, routing, flow control, and service disciplines at switches such as scheduling and queueing <ref> [44, 45, 46, 47, 48, 49, 50, 51] </ref>. Amongst these, this dissertation focuses on issues related to scheduling and queueing mechanisms at a switch, which are fundamental requirements for any guaranteed services in distributed systems. This chapter presents general background on these issues. <p> While these coding techniques reduce average traffic rates substantially up to 50:1 or beyond, coded outputs show large fluctuations at the traffic rate. Many trace data of MPEG video streams show that burstiness measured as the ratio of peak rate to average rate commonly reaches 3-5 <ref> [51, 54, 56] </ref>. The unpredictable variation of traffic rates make efficient support for this traffic type difficult. Reserving network resources based on peak rates may waste resources, but in contrast, reserving resources based on average rates may fail to support traffic variations.
Reference: [52] <author> A. </author> <title> Alles. "ATM internetworking," Cisco Systems, Inc., </title> <type> Tech. Rep., </type> <month> May </month> <year> 1995. </year> <note> Available from http://cio.cisco.com/warp/public/614/12.html. </note>
Reference-contexts: Note that this is a slightly simpler categorization than the five types (CBR, Real-Time VBR, Non-Real-Time VBR, ABR and UBR) recently suggested by the ATM Forum <ref> [2, 52] </ref>. * Constant Bit Rate (CBR): Uncompressed audio and video streams belong to this category, in which packets are generated at a fixed interval and uniform rate. These traffic types have been widely used for interactive media communications, so bandwidth and/or delay bounds should be guaranteed. <p> Moreover, service guarantees are not only required for real-time applications, but are also useful to non-real-time applications as well. Minimum bandwidth guarantees can provide fairness, progress guarantees, and predictable delay bounds. For such purposes, the ATM Forum suggests minimum bandwidth guarantees to ABR best-effort traffic <ref> [52] </ref>.
Reference: [53] <author> M. Prycker. </author> <title> Asynchronous Transfer Mode: Solution for Broadband ISDN. </title> <booktitle> Prentice-Hall International, </booktitle> <address> London, UK, </address> <year> 1995. </year>
Reference-contexts: MPEG-1/2/4, JPEG, or H.261) and parameters (e.g., the interframe-to-intraframe ratio and quantization scale). For instance, MPEG-1 targets output rates 15 of 1.2 Mbps on average for VCR quality images and MPEG-2 targets 3 to 100 Mbps for a range of qualities <ref> [53, 54] </ref>. Also, the MPEG-1/audio coding standard provides CD quality stereo (1.5 Mbps) sounds at 256 Kbps [55]. While these coding techniques reduce average traffic rates substantially up to 50:1 or beyond, coded outputs show large fluctuations at the traffic rate.
Reference: [54] <author> P. Pancha and M. E. Zarki. </author> <title> "MPEG coding for variable bit rate video transmission," </title> <journal> IEEE Communications Magazine, </journal> <volume> vol. 32, no. 5, </volume> <pages> pp. 54-66, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: MPEG-1/2/4, JPEG, or H.261) and parameters (e.g., the interframe-to-intraframe ratio and quantization scale). For instance, MPEG-1 targets output rates 15 of 1.2 Mbps on average for VCR quality images and MPEG-2 targets 3 to 100 Mbps for a range of qualities <ref> [53, 54] </ref>. Also, the MPEG-1/audio coding standard provides CD quality stereo (1.5 Mbps) sounds at 256 Kbps [55]. While these coding techniques reduce average traffic rates substantially up to 50:1 or beyond, coded outputs show large fluctuations at the traffic rate. <p> While these coding techniques reduce average traffic rates substantially up to 50:1 or beyond, coded outputs show large fluctuations at the traffic rate. Many trace data of MPEG video streams show that burstiness measured as the ratio of peak rate to average rate commonly reaches 3-5 <ref> [51, 54, 56] </ref>. The unpredictable variation of traffic rates make efficient support for this traffic type difficult. Reserving network resources based on peak rates may waste resources, but in contrast, reserving resources based on average rates may fail to support traffic variations.
Reference: [55] <author> D. Pan. </author> <title> "A tutorial on MPEG/audio compression," </title> <booktitle> IEEE Multimedia, </booktitle> <pages> pp. 60-74, </pages> <month> Summer </month> <year> 1995. </year>
Reference-contexts: For instance, MPEG-1 targets output rates 15 of 1.2 Mbps on average for VCR quality images and MPEG-2 targets 3 to 100 Mbps for a range of qualities [53, 54]. Also, the MPEG-1/audio coding standard provides CD quality stereo (1.5 Mbps) sounds at 256 Kbps <ref> [55] </ref>. While these coding techniques reduce average traffic rates substantially up to 50:1 or beyond, coded outputs show large fluctuations at the traffic rate. Many trace data of MPEG video streams show that burstiness measured as the ratio of peak rate to average rate commonly reaches 3-5 [51, 54, 56].
Reference: [56] <author> D. Reininger and D. Raychaudhuri. </author> <title> "Statistical multiplexing of VBR MPEG compressed video on ATM networks," </title> <booktitle> in Proceedings of IEEE INFOCOM, </booktitle> <address> San Francisco, CA, </address> <year> 1993, </year> <pages> pp. 919-926. </pages>
Reference-contexts: While these coding techniques reduce average traffic rates substantially up to 50:1 or beyond, coded outputs show large fluctuations at the traffic rate. Many trace data of MPEG video streams show that burstiness measured as the ratio of peak rate to average rate commonly reaches 3-5 <ref> [51, 54, 56] </ref>. The unpredictable variation of traffic rates make efficient support for this traffic type difficult. Reserving network resources based on peak rates may waste resources, but in contrast, reserving resources based on average rates may fail to support traffic variations. <p> This is because its reserved bandwidth allows only one packet to be transmitted during a 1 The range is selected by observing a few sets of MPEG trace data <ref> [56] </ref>. MPEG traffic shows periodic variation of the burst size (IBBPBB...), but our traffic model neglects such periodicity because different compression techniques yield much different traffic patterns. 123 frame time. <p> By reducing raw bandwidth and storage requirements, data compression helps to support more streams at one time. However, wide variations in compressed data rates make it difficult to achieve service guarantees and efficiency simultaneously. As a compromise, researchers have suggested statistical service guarantees to such traffic <ref> [56, 111] </ref>, where each connection for VBR traffic reserving average (not peak) bandwidth is given only probabilistical (not deterministic) guarantees on delay bounds or packet loss rates. This kind of service can be supported best with scheduling algorithms that can provide efficient network utilization, as well as accurate resource control.
Reference: [57] <author> S. Golestani. </author> <title> "A self-clocked fair queueing scheme for broadband applications," </title> <booktitle> in Proceedings of IEEE INFOCOM, </booktitle> <address> Toronto, Canada, </address> <year> 1994, </year> <pages> pp. 636-646. </pages>
Reference-contexts: Moreover, if each connection accumulates credits for its idle time, unpredictability in traffic arrival patterns makes network resource control nearly impossible. This definition of bandwidth guarantees is similar to those used in other works <ref> [38, 57, 58] </ref>. Delay bounds guarantees For distributed real-time applications in which messages arrive later than deadlines lose their value either partially or completely, delay bounds must be guaranteed. For communications such as distributed control messages, which require absolute delay bounds, guarantee must be deterministic. <p> Delay-Oriented Bandwidth-Oriented Priority-Based CODA [68] FQ [37] RACE [69] VC [35] TDC [70] PGPS [38] DEDD [40] SCFQ <ref> [57] </ref> JEDD [71] FFQ [58] RCSD [39] Non-Work-Conserving Work-Conserving Frame-Based SG [36] WRR [72] HRR [43] DRR [73] Most priority-based scheduling algorithms share common disciplines, but can appear quite different based on their motivations and targeting applications. <p> With the large number of queues provided, it is unlikely for multiple connections to collide. Also, it approximates scheduling of FQ with a strict round-robin algorithm. It trades off fairness and traffic isolations of ideal fair queueing for simple implementation. In <ref> [57] </ref>, Golestani suggests a simple mechanism which can provide fairness of FQ, but at a much lower complexity. <p> Fair Queueing [37], PGPS [38] and Virtual Clock [35] belong to this category. Unfortunately, these algorithms require large implementation complexity [79, 77]. Many researchers have developed approximate algorithms to make the basic idea feasible <ref> [82, 57, 83, 58] </ref>, but they still need complicated control logic for priority comparisons. On the other hand, frame-based scheduling is simpler, but it is claimed to have the problem of large delay bounds. <p> The improvement issues in frame-based scheduling networks to support such applications are discussed in more detail in Chapter 7. A generic frame-based scheduling algorithm can be described as follows, using the similar notations as in <ref> [37, 57, 58] </ref>, which can be considered as a superset of the previous work-conserving, frame-based algorithms: 94 Notation: F rame : The current system frame number, unique per output link. <p> However, because other similar algorithms such as Fair Queueing, which are more complicated do not share the problem; its details are not discussed here. Our focus is to compare priority-based approaches in general (VC, as an example) to RCQ. The limitation of VC is described in detail in <ref> [57] </ref>. 118 frame in RCQ, respectively.
Reference: [58] <author> D. Stiliadis and A. Varma. </author> <title> "Design and analysis of frame-based queueing: A new traffic scheduling algorithm for packet-switched networks," </title> <booktitle> in Proceedings of SIGMETRICS, </booktitle> <address> Philadelphia, PA, </address> <year> 1996, </year> <pages> pp. 104-115. 213 </pages>
Reference-contexts: Moreover, if each connection accumulates credits for its idle time, unpredictability in traffic arrival patterns makes network resource control nearly impossible. This definition of bandwidth guarantees is similar to those used in other works <ref> [38, 57, 58] </ref>. Delay bounds guarantees For distributed real-time applications in which messages arrive later than deadlines lose their value either partially or completely, delay bounds must be guaranteed. For communications such as distributed control messages, which require absolute delay bounds, guarantee must be deterministic. <p> By reserving a certain number of packet slots per frame time, connections are guaranteed with bandwidth and delay bounds. While these approaches permit simpler control at the switch, they can sometimes provide only limited controllability. 1 They are also called sorted-priority mechanism <ref> [58] </ref> or time-stamp based scheme [66]. 24 Table 2.1: Classification of existing algorithms. Delay-Oriented Bandwidth-Oriented Priority-Based CODA [68] FQ [37] RACE [69] VC [35] TDC [70] PGPS [38] DEDD [40] SCFQ [57] JEDD [71] FFQ [58] RCSD [39] Non-Work-Conserving Work-Conserving Frame-Based SG [36] WRR [72] HRR [43] DRR [73] Most priority-based <p> switch, they can sometimes provide only limited controllability. 1 They are also called sorted-priority mechanism <ref> [58] </ref> or time-stamp based scheme [66]. 24 Table 2.1: Classification of existing algorithms. Delay-Oriented Bandwidth-Oriented Priority-Based CODA [68] FQ [37] RACE [69] VC [35] TDC [70] PGPS [38] DEDD [40] SCFQ [57] JEDD [71] FFQ [58] RCSD [39] Non-Work-Conserving Work-Conserving Frame-Based SG [36] WRR [72] HRR [43] DRR [73] Most priority-based scheduling algorithms share common disciplines, but can appear quite different based on their motivations and targeting applications. <p> Recently, Stiliadis and Varma suggested a different approach to provide fairness of FQ without fluid-flow emulation complexity <ref> [58] </ref>. Their new scheduling algorithm, Frame-based Fair Queueing (FFQ), is basically similar to SCFQ except that it uses the notion of frame for managing system virtual time, which can guarantee much lower delay bounds than SCFQ. <p> Our efforts at analysis indicate that even for a bandwidth allocation algorithm as simple as ALU biasing, system dynamics can be remarkably subtle and complicated. The analysis shown below is more complicated than those done for other priority-based algorithms as in <ref> [38, 58] </ref>. This is partly because ServerNet targets high-speed communications, so delay bounds analyses in much finer units are desirable. <p> Fair Queueing [37], PGPS [38] and Virtual Clock [35] belong to this category. Unfortunately, these algorithms require large implementation complexity [79, 77]. Many researchers have developed approximate algorithms to make the basic idea feasible <ref> [82, 57, 83, 58] </ref>, but they still need complicated control logic for priority comparisons. On the other hand, frame-based scheduling is simpler, but it is claimed to have the problem of large delay bounds. <p> The improvement issues in frame-based scheduling networks to support such applications are discussed in more detail in Chapter 7. A generic frame-based scheduling algorithm can be described as follows, using the similar notations as in <ref> [37, 57, 58] </ref>, which can be considered as a superset of the previous work-conserving, frame-based algorithms: 94 Notation: F rame : The current system frame number, unique per output link.
Reference: [59] <author> D. Wiltzius, L. Berc, and S. Devadhar. "BAGNet: </author> <title> Experiences with an ATM metropolitan-area network," </title> <address> ConneXions, </address> <month> March </month> <year> 1996. </year>
Reference-contexts: Recent developments in communication technologies make switching speeds rather than transmission speeds the major performance bottleneck. High-speed optical fibers of several gigabits per second are being used in several high-speed network testbeds <ref> [59, 60, 61, 62] </ref> and even higher link bandwidths appear in multicomputer networks using parallel copper cables, for instance, the peak link bandwidth of 600MB/s (or 4.8Gbps) in the Cray T3E network [63].
Reference: [60] <author> C. E. Catlett. </author> <title> "In search of gigabit applications," </title> <journal> IEEE Communications Magazine, </journal> <volume> vol. 30, no. 4, </volume> <pages> pp. 42-51, </pages> <month> April </month> <year> 1992. </year>
Reference-contexts: Recent developments in communication technologies make switching speeds rather than transmission speeds the major performance bottleneck. High-speed optical fibers of several gigabits per second are being used in several high-speed network testbeds <ref> [59, 60, 61, 62] </ref> and even higher link bandwidths appear in multicomputer networks using parallel copper cables, for instance, the peak link bandwidth of 600MB/s (or 4.8Gbps) in the Cray T3E network [63].
Reference: [61] <author> D. Clark et al. </author> <title> "The AURORA gigabit testbed," </title> <journal> Computer Networks and ISDN Systems, </journal> <volume> vol. 25, </volume> <pages> pp. 599-621, </pages> <year> 1993. </year>
Reference-contexts: Recent developments in communication technologies make switching speeds rather than transmission speeds the major performance bottleneck. High-speed optical fibers of several gigabits per second are being used in several high-speed network testbeds <ref> [59, 60, 61, 62] </ref> and even higher link bandwidths appear in multicomputer networks using parallel copper cables, for instance, the peak link bandwidth of 600MB/s (or 4.8Gbps) in the Cray T3E network [63].
Reference: [62] <author> M. N. Ransom. </author> <title> "The VISTAnet gigabit network testbed," </title> <journal> Journal of High Speed Networks, </journal> <volume> vol. 1, </volume> <pages> pp. 49-60, </pages> <year> 1992. </year>
Reference-contexts: Recent developments in communication technologies make switching speeds rather than transmission speeds the major performance bottleneck. High-speed optical fibers of several gigabits per second are being used in several high-speed network testbeds <ref> [59, 60, 61, 62] </ref> and even higher link bandwidths appear in multicomputer networks using parallel copper cables, for instance, the peak link bandwidth of 600MB/s (or 4.8Gbps) in the Cray T3E network [63].
Reference: [63] <author> S. Scott and G. Thorson. </author> <title> "The Cray T3E network: Adaptive routing in a high performance 3d torus," </title> <booktitle> in Proceedings of the IEEE Hot Interconnects Symposium, </booktitle> <address> Palo Alto, CA, </address> <month> Aug. </month> <year> 1996. </year>
Reference-contexts: High-speed optical fibers of several gigabits per second are being used in several high-speed network testbeds [59, 60, 61, 62] and even higher link bandwidths appear in multicomputer networks using parallel copper cables, for instance, the peak link bandwidth of 600MB/s (or 4.8Gbps) in the Cray T3E network <ref> [63] </ref>. On the other hand, the basic motivation for integrated-service networks, sharing link bandwidth to provide a wide range of network services, requires more complicated functionality in switches. <p> This is true especially for the networks in which the switch buffer size is large enough to contain more than a packet, as in, for instance, the Tandem ServerNet [28], IBM SP1/2 [26], and Cray T3D/T3E networks <ref> [25, 63] </ref>. The frame size in RCQ and SG networks is fixed at 16 packet slots, which is the maximum number of independent traffic streams a physical link can support at a time. <p> Even when considering dynamic sharing of buffers over multiple output ports, a few million transistors only for scheduling and queueing logic only are over the implementation budget of most contemporary multicomputer switches. However, recent technical trends of large-scale switches of a few million transistors <ref> [63, 116] </ref> and increasing circuit integration not only make RCQ feasible in a single chip but also make the transistor counters a less important factor than run time scheduling overheads. 7.3 Implementation Considerations As we observed above, the implementation cost of the RCQ network depends on several network design parameters including <p> One of the clear trends in multicomputer networks is increasing transistor counts and buffer space in a switch, mainly due to improving circuit integration technology. It is not uncommon to observe highly integrated switch chips with more than 2-3 million transistors <ref> [63, 85, 116] </ref>. Within such large switch chips, it would be not difficult to integrate RCQ. In addition, the large buffer space in such switches will also help RCQ support bursty traffic more efficiently.
Reference: [64] <author> A. A. Chien. </author> <title> "A cost and performance model for k-ary n-cube wormhole routers," </title> <booktitle> in Proceedings of the IEEE Hot Interconnects Symposium, </booktitle> <address> Palo Alto, CA, </address> <month> Aug. </month> <year> 1993. </year>
Reference-contexts: While switches consist of many components, we focus here on the costs of the two parts, scheduling and queueing logic, which are crucial components in supporting integrated-service networks. Because costs for other basic components have been studied before <ref> [64, 65] </ref>, our study examines and quantifies the additional costs of switches for integrated-service networks. With the cost analysis, we can also compare relative implementation costs of 23 different scheduling algorithms. <p> Because costs for these basic components have been studied before <ref> [64, 65] </ref>, our study reveals the additional costs of switches for integrated-service networks. Although switches for different scheduling algorithms can be implemented best in slightly different ways, their fundamental differences in implementation complexity come from scheduling and buffering support. As a cost metric, the number of transistors is estimated.
Reference: [65] <author> K. Aoyama and A. A. Chien. </author> <title> "The cost of adaptivity and virtual lanes in a wormhole router," </title> <journal> Journal of VLSI Design, Special Issue on Interconnection Networks, </journal> <volume> vol. 2, no. 4, </volume> <pages> pp. 315-333, </pages> <month> Apr. </month> <year> 1995. </year>
Reference-contexts: While switches consist of many components, we focus here on the costs of the two parts, scheduling and queueing logic, which are crucial components in supporting integrated-service networks. Because costs for other basic components have been studied before <ref> [64, 65] </ref>, our study examines and quantifies the additional costs of switches for integrated-service networks. With the cost analysis, we can also compare relative implementation costs of 23 different scheduling algorithms. <p> Because costs for these basic components have been studied before <ref> [64, 65] </ref>, our study reveals the additional costs of switches for integrated-service networks. Although switches for different scheduling algorithms can be implemented best in slightly different ways, their fundamental differences in implementation complexity come from scheduling and buffering support. As a cost metric, the number of transistors is estimated.
Reference: [66] <author> D. Clark, S. Shenkar, and L. Zhang. </author> <title> "Supporting real-time applications in an integrated services packet network: Architecture and mechanism," </title> <booktitle> in Proceedings of ACM SIGCOMM, </booktitle> <address> Baltimore, MD, </address> <year> 1992, </year> <pages> pp. 14-26. </pages>
Reference-contexts: By reserving a certain number of packet slots per frame time, connections are guaranteed with bandwidth and delay bounds. While these approaches permit simpler control at the switch, they can sometimes provide only limited controllability. 1 They are also called sorted-priority mechanism [58] or time-stamp based scheme <ref> [66] </ref>. 24 Table 2.1: Classification of existing algorithms. <p> Their basic contribution is to show that fair scheduling mechanisms can also be used to guarantee delay bounds when well-defined traffic rate controls are used at network entrances. When the maximum bursti-ness of each connection is strictly constrained by a source-level rate-control mechanism such as a token bucket 3 <ref> [47, 66, 81] </ref>, the worst-case congestion inside the network is limited, so deterministic delay bounds can be guaranteed. The delay bound of a connection is determined solely by the amount of reserved bandwidth and allowed traffic burstiness.
Reference: [67] <author> H. Zhang and S. Keshav. </author> <title> "Comparison of rate-based service disciplines," </title> <booktitle> in Proceedings of ACM SIGCOMM, </booktitle> <address> Zurich, Switzerland, </address> <year> 1991, </year> <pages> pp. 113-122. </pages>
Reference-contexts: In contrast to priority-based schemes, in frame-based schemes, bandwidth and delay bounds are coupled via frames. Frame-based schemes are usually further classified into work-conserving and non-work-conserving, depending on whether or not each switch does rate control <ref> [67] </ref>. In work-conserving switches, if there are packets pending for idle channels, they are transmitted through the channels immediately. In contrast, non-work-conserving switches may enforce additional delays to packets even if the target output channels are idle. <p> Some approaches take advantage of both priority-based and frame-based schemes by mechanically combining multiple schemes in a single network. These combined approaches are discussed 25 separately later. Similar analyses and comparisons of existing algorithms are also found in <ref> [67, 74, 75] </ref>. 2.3.1 Priority-based algorithms In order to control bandwidth and delay bounds for connections, a switch must be able to schedule packets for transmission in the order other than that of their arrival.
Reference: [68] <author> K. Toda, K. Nishida, E. Takahashi, N. Michell, and Y. Yamaguchi. </author> <title> "Design and implementation of a priority forwarding router chip for real-time interconnection networks," </title> <journal> International Journal of Mini and Microcomputers, </journal> <volume> vol. 17, no. 1, </volume> <pages> pp. 42-51, </pages> <month> Jan. </month> <year> 1995. </year> <month> 214 </month>
Reference-contexts: While these approaches permit simpler control at the switch, they can sometimes provide only limited controllability. 1 They are also called sorted-priority mechanism [58] or time-stamp based scheme [66]. 24 Table 2.1: Classification of existing algorithms. Delay-Oriented Bandwidth-Oriented Priority-Based CODA <ref> [68] </ref> FQ [37] RACE [69] VC [35] TDC [70] PGPS [38] DEDD [40] SCFQ [57] JEDD [71] FFQ [58] RCSD [39] Non-Work-Conserving Work-Conserving Frame-Based SG [36] WRR [72] HRR [43] DRR [73] Most priority-based scheduling algorithms share common disciplines, but can appear quite different based on their motivations and targeting applications. <p> By always transmitting packets with higher priorities, the switch can guarantee node delay bounds to high-priority connections. A good example is a prioritized, packet-switching router for the CODA real-time parallel machine <ref> [68] </ref>. In the router, each input port is given a priority queue so that higher-priority packets can bypass lower-priority ones. A unique technique in this router is priority forwarding-when higher priority packets are blocked by lower-priority ones, the priority values of the latter are updated to those of the former. <p> However, Virtual Clock pays a large penalty for its flexibility; even with full hardware implementations, it needs log N depth comparisons to determine the highest priority packet. Note that special hardware designs for priority queues can reduce the scheduling time further by using parallel comparisons and bidirectional shift registers <ref> [77, 68] </ref>, but it increases the implementation complexity dramatically. For instance, a hardware sequencer implemented by Chao [77] needs 150K transistors for sequencing 256 packets in parallel. 1 To reduce the comparison domain, this technique is not considered.
Reference: [69] <author> B. Kuszmaul. </author> <title> "The RACE network architecture," </title> <booktitle> in Proceedings of the IEEE Inter--national Parallel Processing Symposium, </booktitle> <address> Santa Barbara, CA, </address> <year> 1995, </year> <pages> pp. 508-513. </pages>
Reference-contexts: While these approaches permit simpler control at the switch, they can sometimes provide only limited controllability. 1 They are also called sorted-priority mechanism [58] or time-stamp based scheme [66]. 24 Table 2.1: Classification of existing algorithms. Delay-Oriented Bandwidth-Oriented Priority-Based CODA [68] FQ [37] RACE <ref> [69] </ref> VC [35] TDC [70] PGPS [38] DEDD [40] SCFQ [57] JEDD [71] FFQ [58] RCSD [39] Non-Work-Conserving Work-Conserving Frame-Based SG [36] WRR [72] HRR [43] DRR [73] Most priority-based scheduling algorithms share common disciplines, but can appear quite different based on their motivations and targeting applications. <p> This scheme can be used to avoid the priority conversion problem that high-priority packets can be indirectly blocked by lower priority ones over multiple routers. Another interesting example is the RACE network for embedded parallel systems, where circuit switching is used and high-priority requests can preempt low-priority circuits <ref> [69] </ref>. These architectures provide low-cost, high-performance networks while supporting control messages with tight real-time constraints of a few microseconds range.
Reference: [70] <author> J. Jonsson and J. Vasell. </author> <title> "A comparative study of methods for time-deterministic message delivery in a multiprocessor architecture," </title> <booktitle> in Proceedings of the IEEE International Parallel Processing Symposium, </booktitle> <address> Honolulu, HI, </address> <year> 1996, </year> <pages> pp. 392-398. </pages>
Reference-contexts: While these approaches permit simpler control at the switch, they can sometimes provide only limited controllability. 1 They are also called sorted-priority mechanism [58] or time-stamp based scheme [66]. 24 Table 2.1: Classification of existing algorithms. Delay-Oriented Bandwidth-Oriented Priority-Based CODA [68] FQ [37] RACE [69] VC [35] TDC <ref> [70] </ref> PGPS [38] DEDD [40] SCFQ [57] JEDD [71] FFQ [58] RCSD [39] Non-Work-Conserving Work-Conserving Frame-Based SG [36] WRR [72] HRR [43] DRR [73] Most priority-based scheduling algorithms share common disciplines, but can appear quite different based on their motivations and targeting applications. <p> When each connection is restricted to inject packets at maximum arrival rates, each connection is guaranteed its delay bound depending on its priority (unless link capacity is overbooked). A good example of this scheme is the Time-Deterministic Communication (TDC) switch <ref> [70] </ref>. A request for a new connection is accepted when a path exists with enough extra bandwidth, and its worst-case packet delay is determined based on existing connections' traffic rates. Each switch simply transmits packets in the order of priorities and jitter is controlled at the destination.
Reference: [71] <author> D. Verma, H. Zhang, and D. Ferrari. </author> <title> "Delay jitter control for real-time communication in a packet switching network," </title> <booktitle> in Proceedings of Tricomm'91, </booktitle> <address> Chapel Hill, NC, </address> <year> 1991, </year> <pages> pp. 35-46. </pages>
Reference-contexts: Delay-Oriented Bandwidth-Oriented Priority-Based CODA [68] FQ [37] RACE [69] VC [35] TDC [70] PGPS [38] DEDD [40] SCFQ [57] JEDD <ref> [71] </ref> FFQ [58] RCSD [39] Non-Work-Conserving Work-Conserving Frame-Based SG [36] WRR [72] HRR [43] DRR [73] Most priority-based scheduling algorithms share common disciplines, but can appear quite different based on their motivations and targeting applications. <p> A minor modification to the DEDD service discipline also provides small jitter values in addition to delay bounds guarantee. Jitter 27 Earliest-Due-Date (JEDD) <ref> [71] </ref> adds regulators at the inputs of the switch to enforce extra delays to the packets which have arrived earlier than expected, so every packet of a connection experiences the same switch delay. It may require more switch complexity.
Reference: [72] <author> M. Katevenis, S. Sidiropoulos, and C. Courcoubetis. </author> <title> "Weighted round-robin cell multiplexing in a general-purpose atm switch chip," </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> vol. 9, no. 8, </volume> <pages> pp. 1265-1279, </pages> <month> Oct. </month> <year> 1991. </year>
Reference-contexts: Delay-Oriented Bandwidth-Oriented Priority-Based CODA [68] FQ [37] RACE [69] VC [35] TDC [70] PGPS [38] DEDD [40] SCFQ [57] JEDD [71] FFQ [58] RCSD [39] Non-Work-Conserving Work-Conserving Frame-Based SG [36] WRR <ref> [72] </ref> HRR [43] DRR [73] Most priority-based scheduling algorithms share common disciplines, but can appear quite different based on their motivations and targeting applications. <p> Work-conserving approaches A possible approach to use the simplicity of frame-by-frame bandwidth control but without resource waste, is to relax connections to use any slots rather than fixed slots and allow frame sizes to vary depending on traffic. In <ref> [72] </ref>, Katevenis et al. introduced a simple hardware mechanism called Weighted Round Robin (WRR) to implement uniform round-robin between connections with different service weights. A counter increases with a cycle, which is decoded to decide which connection has the highest priority at each cycle. <p> While they try to find exact service ordering of all packets, this algorithm only decides which frames they belong to and their service orders inside the frame are undefined, permitting much simpler implementation. Note that WRR <ref> [72] </ref> and DRR [73] can be interpreted as different implementations of the algorithm with different packet ordering inside each frame; semi-uniform in WRR or round-robin in DRR. 4.2.2 Queueing: connection-based or shared? In spite of its simplicity compared to other scheduling algorithms, a naive implementation of frame-based scheduling still requires a
Reference: [73] <author> M. Shreedhar and George Varghese. </author> <title> "Efficient fair queueing using deficit round robin," </title> <booktitle> in Proceedings of ACM SIGCOMM, </booktitle> <address> Cambridge, MA, </address> <year> 1995, </year> <pages> pp. 231-242. </pages>
Reference-contexts: Delay-Oriented Bandwidth-Oriented Priority-Based CODA [68] FQ [37] RACE [69] VC [35] TDC [70] PGPS [38] DEDD [40] SCFQ [57] JEDD [71] FFQ [58] RCSD [39] Non-Work-Conserving Work-Conserving Frame-Based SG [36] WRR [72] HRR [43] DRR <ref> [73] </ref> Most priority-based scheduling algorithms share common disciplines, but can appear quite different based on their motivations and targeting applications. For better understanding, they are classified again into delay-oriented schemes and bandwidth-oriented schemes, depending on whether their primary goal is to provide delay bounds or bandwidth guarantees. <p> However, it has the drawback of wasting cycles when the selected connection is idle. Shreedhar and Varghese introduced another flexible, yet simple, scheduling discipline called Deficit Round Robin (DRR), which can support different packet sizes and different amounts of bandwidth allocation to different connections <ref> [73] </ref>. Each connection is given a counter value which is increased by its own quantum value at the beginning of each round and decreased by the size of each transmitted packet. Connections' relative bandwidth shares are determined by the quantum values. <p> This algorithm is similar to Stop-and-Go in that both algorithms schedule packets frame-based. However, in contrast to Stop-and-Go which uses fixed-size frames, so wasting un 1 Deficit Round Robin (DRR) is similar <ref> [73] </ref>. 2 Stop-and-Go is this case, except that it is non-work-conserving. 96 claimed packet slots, this algorithm adjusts frame sizes depending on traffic behaviors. Their differences are illustrated in Figure 4.3. Also, this algorithm is much simpler compared to priority-based scheduling such as Fair Queueing or Virtual Clock. <p> While they try to find exact service ordering of all packets, this algorithm only decides which frames they belong to and their service orders inside the frame are undefined, permitting much simpler implementation. Note that WRR [72] and DRR <ref> [73] </ref> can be interpreted as different implementations of the algorithm with different packet ordering inside each frame; semi-uniform in WRR or round-robin in DRR. 4.2.2 Queueing: connection-based or shared? In spite of its simplicity compared to other scheduling algorithms, a naive implementation of frame-based scheduling still requires a significant amount of
Reference: [74] <author> H. Zhang. </author> <title> "Service disciplines for guaranteed performance service in packet-switching networks," </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> vol. 83, no. 10, </volume> <month> Oct. </month> <year> 1995. </year>
Reference-contexts: Some approaches take advantage of both priority-based and frame-based schemes by mechanically combining multiple schemes in a single network. These combined approaches are discussed 25 separately later. Similar analyses and comparisons of existing algorithms are also found in <ref> [67, 74, 75] </ref>. 2.3.1 Priority-based algorithms In order to control bandwidth and delay bounds for connections, a switch must be able to schedule packets for transmission in the order other than that of their arrival.
Reference: [75] <author> H. Zhang and D. Ferrari. </author> <title> "Rate-controlled service disciplines," </title> <journal> Journal of High Speed Networking, </journal> <volume> vol. 3, no. 4, </volume> <pages> pp. 389-412, </pages> <month> Feb. </month> <year> 1994. </year>
Reference-contexts: Some approaches take advantage of both priority-based and frame-based schemes by mechanically combining multiple schemes in a single network. These combined approaches are discussed 25 separately later. Similar analyses and comparisons of existing algorithms are also found in <ref> [67, 74, 75] </ref>. 2.3.1 Priority-based algorithms In order to control bandwidth and delay bounds for connections, a switch must be able to schedule packets for transmission in the order other than that of their arrival. <p> However, beyond that, it shares the same scheduling mechanism with other priority-based schemes, so it still requires much complexity. Hybrid approaches While these bandwidth-oriented algorithms also guarantee delay bounds, they are limited in that the smallest delay bounds are determined by reserved bandwidth. In <ref> [39, 75] </ref>, Zhang and Ferrari suggested a framework called Rate-Controlled Service Discipline that can control bandwidth and delay bounds independently with separation of the servers into rate controllers and schedulers.
Reference: [76] <author> J. B. Nagle. </author> <title> "On packet switches with infinite storage," </title> <journal> IEEE Transactions on Communications, </journal> <volume> vol. COM-35, no. 4, </volume> <pages> pp. 435-438, </pages> <month> Apr. </month> <year> 1987. </year>
Reference-contexts: Bandwidth-oriented approaches In contrast to the algorithms discussed so far which focus on delay bounds, many widely accepted approaches aim to control bandwidth as the first class. The basic idea has been developed by Nagle for providing effective congestion control and fair services in the conventional datagram networks <ref> [76] </ref>. In order to decouple traffic for different communications, separate queues are suggested and they are served in round-robin. Compared to the conventional FCFS scheme, this new queueing and scheduling scheme improves protection and fairness dramatically.
Reference: [77] <author> H. Chao. </author> <title> "A novel architecture for queue management in the ATM network," </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> vol. 9, no. 7, </volume> <pages> pp. 1110-8, </pages> <month> Sept. </month> <year> 1991. </year>
Reference-contexts: First, for servicing packets in other than their arrival orders, FQ requires per-connection queueing. The other primary source of complexity is to sort (schedule) packets in the order of increasing priorities, which requires special hardware support to reduce scheduling delays <ref> [77, 78] </ref>. <p> This approach not only guarantees reserved bandwidth to each connection, but it also uniformly schedules packets of a connection. Fair Queueing [37], PGPS [38] and Virtual Clock [35] belong to this category. Unfortunately, these algorithms require large implementation complexity <ref> [79, 77] </ref>. Many researchers have developed approximate algorithms to make the basic idea feasible [82, 57, 83, 58], but they still need complicated control logic for priority comparisons. On the other hand, frame-based scheduling is simpler, but it is claimed to have the problem of large delay bounds. <p> However, Virtual Clock pays a large penalty for its flexibility; even with full hardware implementations, it needs log N depth comparisons to determine the highest priority packet. Note that special hardware designs for priority queues can reduce the scheduling time further by using parallel comparisons and bidirectional shift registers <ref> [77, 68] </ref>, but it increases the implementation complexity dramatically. For instance, a hardware sequencer implemented by Chao [77] needs 150K transistors for sequencing 256 packets in parallel. 1 To reduce the comparison domain, this technique is not considered. <p> Note that special hardware designs for priority queues can reduce the scheduling time further by using parallel comparisons and bidirectional shift registers [77, 68], but it increases the implementation complexity dramatically. For instance, a hardware sequencer implemented by Chao <ref> [77] </ref> needs 150K transistors for sequencing 256 packets in parallel. 1 To reduce the comparison domain, this technique is not considered. <p> To decide the highest priority packet, N comparators are also needed. By reusing some of the counters, VC would be feasible at much lower costs, but at increased run time scheduling overheads. Conversely, faster VC switches can be implemented with more expensive hardware support <ref> [77] </ref>. Consequently, the scheduling logic for VC requires about 1 million transistors. With reduced component sizes, as well as their reduced quantities, ALU scheduling logic requires about 10,000 transistors, only 1% of VC scheduling logic. Compared to VC, RCQ needs only 20% of the scheduling logic.
Reference: [78] <author> R. Brown. </author> <title> "Calendar queues: A fast O(1) priority queue implementation for the simulation event set problem," </title> <journal> Communications of the ACM, </journal> <volume> vol. 31, no. 10, </volume> <pages> pp. 1220-1227, </pages> <month> Oct. </month> <year> 1988. </year> <month> 215 </month>
Reference-contexts: First, for servicing packets in other than their arrival orders, FQ requires per-connection queueing. The other primary source of complexity is to sort (schedule) packets in the order of increasing priorities, which requires special hardware support to reduce scheduling delays <ref> [77, 78] </ref>.
Reference: [79] <author> S. Keshav. </author> <title> "On the efficient implementation of fair queueing," </title> <journal> Journal of Internet--working Research and Experience, </journal> <volume> vol. 2, </volume> <pages> pp. 157-173, </pages> <month> Sept. </month> <year> 1991. </year>
Reference-contexts: FQ requires large overhead for priority calculation because it emulates a bit-by-bit fluid-flow model. Details on priority calculation are discussed in <ref> [79] </ref>. Parekh and Gallager also introduced a nearly identical approach to Fair Queueing called Packet-by-Packet General Processor Sharing (PGPS) [38, 80]. Their basic contribution is to show that fair scheduling mechanisms can also be used to guarantee delay bounds when well-defined traffic rate controls are used at network entrances. <p> This approach not only guarantees reserved bandwidth to each connection, but it also uniformly schedules packets of a connection. Fair Queueing [37], PGPS [38] and Virtual Clock [35] belong to this category. Unfortunately, these algorithms require large implementation complexity <ref> [79, 77] </ref>. Many researchers have developed approximate algorithms to make the basic idea feasible [82, 57, 83, 58], but they still need complicated control logic for priority comparisons. On the other hand, frame-based scheduling is simpler, but it is claimed to have the problem of large delay bounds. <p> A more practical approach seems to manage packets for each connection separately in its own queue and compare only the head packets of each queue because frame numbers of the packets in the same connections monotonically increase <ref> [79] </ref>. However, even with the per-connection queueing, the complexity still increases with the number of connections supported. Moreover, in this case, we have to manage a separate FIFO queue for each connection, which gives rise to additional overhead.
Reference: [80] <author> A. Parekh and R. Gallager. </author> <title> "A generalized processor sharing approach to flow control in integrated services networks themultiple node case," </title> <booktitle> in Proceedings of IEEE INFOCOM, </booktitle> <address> San Francisco, CA, </address> <year> 1993, </year> <pages> pp. 521-530. </pages>
Reference-contexts: FQ requires large overhead for priority calculation because it emulates a bit-by-bit fluid-flow model. Details on priority calculation are discussed in [79]. Parekh and Gallager also introduced a nearly identical approach to Fair Queueing called Packet-by-Packet General Processor Sharing (PGPS) <ref> [38, 80] </ref>. Their basic contribution is to show that fair scheduling mechanisms can also be used to guarantee delay bounds when well-defined traffic rate controls are used at network entrances.
Reference: [81] <author> R. Cruz. </author> <title> "A calculus for network delay, Part I: Network elements in isolation," </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> vol. 37, no. 1, </volume> <pages> pp. 114-131, </pages> <month> Jan. </month> <year> 1991. </year>
Reference-contexts: Their basic contribution is to show that fair scheduling mechanisms can also be used to guarantee delay bounds when well-defined traffic rate controls are used at network entrances. When the maximum bursti-ness of each connection is strictly constrained by a source-level rate-control mechanism such as a token bucket 3 <ref> [47, 66, 81] </ref>, the worst-case congestion inside the network is limited, so deterministic delay bounds can be guaranteed. The delay bound of a connection is determined solely by the amount of reserved bandwidth and allowed traffic burstiness. <p> First-Come-First-Serve vs. RCQ In general, First-Come-First-Serve (FCFS) switches cannot guarantee services to a traffic stream because the behavior depends completely on behavior of other connections sharing the switches. However, with strict constraints on traffic rates, this simple arbitration technique can also be practically applied to applications requiring guaranteed services <ref> [81, 109] </ref>.
Reference: [82] <author> P. McKenney. </author> <title> "Stochastic fairness queueing," </title> <booktitle> in Proceedings of IEEE INFOCOM, </booktitle> <address> San Francisco, CA, </address> <year> 1990, </year> <pages> pp. 733-740. </pages>
Reference-contexts: One of the first approaches to implement FQ in datagram networks is Stochastic Fair Queueing (SFQ), proposed by McKenney, which is a probabilistic variant of fair queueing <ref> [82] </ref>. It uses simple hashing functions to map a source-destination address pair, as in Internet gateways, to its corresponding queue. With the large number of queues provided, it is unlikely for multiple connections to collide. Also, it approximates scheduling of FQ with a strict round-robin algorithm. <p> Fair Queueing [37], PGPS [38] and Virtual Clock [35] belong to this category. Unfortunately, these algorithms require large implementation complexity [79, 77]. Many researchers have developed approximate algorithms to make the basic idea feasible <ref> [82, 57, 83, 58] </ref>, but they still need complicated control logic for priority comparisons. On the other hand, frame-based scheduling is simpler, but it is claimed to have the problem of large delay bounds.
Reference: [83] <author> J. Rexford, A. Greenberg, and F. Bonomi. </author> <title> "Hardware-efficient fair queueing architectures for high-speed networks," </title> <booktitle> in Proceedings of IEEE INFOCOM, </booktitle> <address> San Francisco, CA, </address> <year> 1996. </year>
Reference-contexts: This simplifies implementation while keeping the fairness of the original Fair Queueing. In 30 <ref> [83] </ref>, Rexford et al. show that this approach provides many additional benefits for low-cost implementation, introducing ideas such as sorting bins and hierarchical fair queueing which can support many connections in high-speed networks. <p> Fair Queueing [37], PGPS [38] and Virtual Clock [35] belong to this category. Unfortunately, these algorithms require large implementation complexity [79, 77]. Many researchers have developed approximate algorithms to make the basic idea feasible <ref> [82, 57, 83, 58] </ref>, but they still need complicated control logic for priority comparisons. On the other hand, frame-based scheduling is simpler, but it is claimed to have the problem of large delay bounds.
Reference: [84] <author> Y. Ofek and M. Yung. </author> <title> "The integrated MetaNet architecture: A switch-based multimedia LAN for parallel computing and real-time traffic," </title> <booktitle> in Proceedings of IEEE INFOCOM, </booktitle> <address> Toronto, Canada, </address> <year> 1994, </year> <pages> pp. 802-811. </pages>
Reference-contexts: Alternatively, integrated services can also be supported by combining multiple networks developed for different traffic types. In this way, different traffic types will be served by independent modules optimally designed for it. For instance, MetaNet <ref> [84] </ref> consists of two networks that are independent except for sharing physical links: a wormhole-routed network with deflection routing which provides high bandwidth and low delays to best-effort traffic and a real-time network which is similar to Stop-and-Go except for a synchronized frame structure with a global clock.
Reference: [85] <author> A.P.J. Engbersen. </author> <title> "IBM's ATM switching technology," </title> <note> 1995. IBM white paper available from http://www.zurich.ibm.com/SWOCPWP/SWOCPWP. </note>
Reference-contexts: In general, switches developed for workgroup or local-area networks provide simple and limited resource controls to reduce implementation costs. For instance, the IBM Switch-on-a-chip <ref> [85, 86] </ref> does not support any service control at all, and the Cisco LightStream 100 [18] switch supports only two levels of priority to give low delays to real-time traffic. <p> One of the clear trends in multicomputer networks is increasing transistor counts and buffer space in a switch, mainly due to improving circuit integration technology. It is not uncommon to observe highly integrated switch chips with more than 2-3 million transistors <ref> [63, 85, 116] </ref>. Within such large switch chips, it would be not difficult to integrate RCQ. In addition, the large buffer space in such switches will also help RCQ support bursty traffic more efficiently.
Reference: [86] <author> W.E. Denzel, A.P.J. Engbersen, and I. Iliadis. </author> <title> "A flexible shared-buffer switch for ATM at gb/s rates," </title> <journal> Computer Networks and ISDN Systems, </journal> <volume> vol. 27, </volume> <pages> pp. 611-624, </pages> <month> Jan. </month> <year> 1995. </year>
Reference-contexts: In general, switches developed for workgroup or local-area networks provide simple and limited resource controls to reduce implementation costs. For instance, the IBM Switch-on-a-chip <ref> [85, 86] </ref> does not support any service control at all, and the Cisco LightStream 100 [18] switch supports only two levels of priority to give low delays to real-time traffic.
Reference: [87] <institution> ATM Virtual Router Architecture, Newbridge Networks Corporation, Hern-don, VA, </institution> <year> 1995. </year> <note> Newbridge Networks white paper available from http:// www.vivid.newbridge.com/documents/vivid-architecture.html. 216 </note>
Reference-contexts: Other 36 switches developed for backbone networks provide more flexible service controls because more costs are tolerable, but still in a limited way by using a small number of queues and limited priority levels. NewBridge's VIVID ATM switches support four logical queues per port <ref> [87] </ref>. The Cisco LightStream 2020 switch supports both priority-based (four priorities) and weighted fair queueing with 16 queues [18]. While being able to provide different services to different traffic types, they are far from connection-based service controls due to limited control resources.
Reference: [88] <institution> ForeThought Bandwidth Management, Fore Systems, Inc., </institution> <address> Warrendale, PA, </address> <year> 1995. </year> <note> Fore Systems white paper available from http://www.fore.com/html/products/whitep/ whitep.html. </note>
Reference-contexts: For instance, the Fore ASX-200WG/BX ATM switch provides up to 12K queues per output port and 381 priority levels (127 levels for each CBR, VBR and ABR traffic type) <ref> [88] </ref>. These switches require complicated control logic and huge buffer space, usually implemented with a microprocessor and more than several megabytes memory per switch [88], which are inappropriately expensive for multicomputer routers mostly implemented in a single ASIC chip. <p> Fore ASX-200WG/BX ATM switch provides up to 12K queues per output port and 381 priority levels (127 levels for each CBR, VBR and ABR traffic type) <ref> [88] </ref>. These switches require complicated control logic and huge buffer space, usually implemented with a microprocessor and more than several megabytes memory per switch [88], which are inappropriately expensive for multicomputer routers mostly implemented in a single ASIC chip. Also, it is not yet clear what kind of service guarantees such switches can provide to end users. 2.4 Low-Cost, High-Speed Solutions? In summary, a variety of previous work has explored scheduling and queueing disciplines.
Reference: [89] <author> C. Leiserson, Z. Abuhamdeh, D. Douglas, C. Feynman, M. Ganmukhi, J. Hill, W. Hillis, B. Kuszmaul, M. Pierre, D. Wells, M. Wong, S. Yang, and R. Zak. </author> <title> "The network architecture of the Connection Machine CM-5," </title> <booktitle> in Proceedings of the Symposium on Parallel Algorithms and Architectures, </booktitle> <address> San Diego, CA, </address> <year> 1992, </year> <pages> pp. 272-285. </pages> <note> Available from ftp://cmns.think.com/doc/Papers/net.ps.Z. </note>
Reference-contexts: and implementation cost, are compared to existing algorithms via analysis and simulations. 40 CHAPTER 3 INITIAL STUDY: EVALUATION OF THE TANDEM SERVERNET APPROACH Since the first development of multicomputers a decade ago, interconnection networks have developed dramatically in such areas as connection topologies, switching strategies, routing algorithms, flow control, etc. <ref> [8, 24, 26, 89, 90, 91, 92] </ref>. The main focus of network architects has been on efficient network resource utilization to improve throughput and average latency. <p> Two topologies, other than meshes, are examined, hypercube and fat-tree, both of which are widely accepted in commercial multicomputer networks <ref> [26, 89, 102, 114] </ref>. Figure 6.13 illustrates node connections used in the experiment, each of which has the same number of nodes (16) as the mesh network in the previous section. Note that there are many possible variations on a fat-tree other than the one shown in the figure. <p> Mesh Hypercube Fat-tree Diameter 7 4 3 Average distance 4.5 2.9 2.7 Total Links 64 64 32 As in the mesh network, the hypercube network uses dimension-order routing. The fat-tree network uses random routing, as in existing multicomputer networks <ref> [26, 89, 102] </ref>, but in this case, a randomly-selected routing path is preserved for an entire session, not only for each packet. For the same number of nodes, these networks have different diameters, average distances and network capacities from mesh-connected networks, which are summarized in Table 6.2.
Reference: [90] <author> W. J. Dally and C. Seitz. </author> <title> "The torus routing chip," </title> <journal> Distributed Computing, </journal> <volume> vol. 1, no. 3, </volume> <pages> pp. 187-196, </pages> <year> 1986. </year>
Reference-contexts: and implementation cost, are compared to existing algorithms via analysis and simulations. 40 CHAPTER 3 INITIAL STUDY: EVALUATION OF THE TANDEM SERVERNET APPROACH Since the first development of multicomputers a decade ago, interconnection networks have developed dramatically in such areas as connection topologies, switching strategies, routing algorithms, flow control, etc. <ref> [8, 24, 26, 89, 90, 91, 92] </ref>. The main focus of network architects has been on efficient network resource utilization to improve throughput and average latency. <p> For example, the unbalanced usage of virtual channels required for deadlock prevention disrupts the topological symmetry of torus networks, which in general need two virtual channels to break link dependency cycles <ref> [25, 90, 98] </ref>. All of the messages to cross arbitrarily selected date lines (e.g., nodes at the end of each dimension) are assigned to one virtual channel, and others to the other virtual channel. More details on how they prevent deadlocks are in [90]. <p> All of the messages to cross arbitrarily selected date lines (e.g., nodes at the end of each dimension) are assigned to one virtual channel, and others to the other virtual channel. More details on how they prevent deadlocks are in <ref> [90] </ref>. Note that ServerNet does not provide virtual channels, so it cannot directly support the torus topology due to deadlocks. However, it would be interesting to observe how network-resource control, in general, can be applied to such symmetric topology networks. <p> We follow the virtual channel assignment method described in [100], where virtual channels are decided when packets are injected. It is slightly different from the method described in <ref> [90] </ref>, where messages change virtual channels in the network when crossing the date line. In both RR and ALU networks, each virtual channel (rather than physical channels) is considered as an entity for scheduling, round-robin or bandwidth allocation.
Reference: [91] <author> J. Duato. </author> <title> "On the design of deadlock-free adaptive routing algorithms for multicom-puters: </title> <booktitle> design methodologies," in Proceedings of Parallel Architectures and Languages Europe, </booktitle> <address> Eindhoven, Netherlands, </address> <year> 1991, </year> <pages> pp. 390-405. </pages>
Reference-contexts: and implementation cost, are compared to existing algorithms via analysis and simulations. 40 CHAPTER 3 INITIAL STUDY: EVALUATION OF THE TANDEM SERVERNET APPROACH Since the first development of multicomputers a decade ago, interconnection networks have developed dramatically in such areas as connection topologies, switching strategies, routing algorithms, flow control, etc. <ref> [8, 24, 26, 89, 90, 91, 92] </ref>. The main focus of network architects has been on efficient network resource utilization to improve throughput and average latency.
Reference: [92] <author> A. A. Chien and J. H. Kim. </author> <title> "Planar-adaptive routing: Low-cost adaptive networks for multiprocessors," </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> vol. 42, no. 1, </volume> <pages> pp. 91-123, </pages> <month> Feb. </month> <year> 1995. </year>
Reference-contexts: and implementation cost, are compared to existing algorithms via analysis and simulations. 40 CHAPTER 3 INITIAL STUDY: EVALUATION OF THE TANDEM SERVERNET APPROACH Since the first development of multicomputers a decade ago, interconnection networks have developed dramatically in such areas as connection topologies, switching strategies, routing algorithms, flow control, etc. <ref> [8, 24, 26, 89, 90, 91, 92] </ref>. The main focus of network architects has been on efficient network resource utilization to improve throughput and average latency.
Reference: [93] <author> W. J. Dally. </author> <title> "Performance analysis of k-ary n-cube interconnection networks," </title> <journal> IEEE Transactions on Computers, </journal> <volume> vol. 39, no. 6, </volume> <pages> pp. 775-85, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: Moreover, controllable or predictable delays can also be used to optimize communication protocols and their implementations. While there has been a wide array of analyses for wormhole-routed networks to model average case performance <ref> [93, 94, 95, 96] </ref>, we know of none that have focused on worst-case latency. Our efforts at analysis indicate that even for a bandwidth allocation algorithm as simple as ALU biasing, system dynamics can be remarkably subtle and complicated.
Reference: [94] <author> A. Agarwal. </author> <title> "Performance tradeoffs in multithreaded processors," </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> vol. 3, no. 5, </volume> <pages> pp. 525-539, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: Moreover, controllable or predictable delays can also be used to optimize communication protocols and their implementations. While there has been a wide array of analyses for wormhole-routed networks to model average case performance <ref> [93, 94, 95, 96] </ref>, we know of none that have focused on worst-case latency. Our efforts at analysis indicate that even for a bandwidth allocation algorithm as simple as ALU biasing, system dynamics can be remarkably subtle and complicated.
Reference: [95] <author> F. Hady and B.L. Menezes. </author> <title> "The performance of crossbar-based binary hypercubes," </title> <journal> IEEE Transactions on Computers. </journal> <note> To be published. </note>
Reference-contexts: Moreover, controllable or predictable delays can also be used to optimize communication protocols and their implementations. While there has been a wide array of analyses for wormhole-routed networks to model average case performance <ref> [93, 94, 95, 96] </ref>, we know of none that have focused on worst-case latency. Our efforts at analysis indicate that even for a bandwidth allocation algorithm as simple as ALU biasing, system dynamics can be remarkably subtle and complicated.
Reference: [96] <author> J. H. Kim and A. A. Chien. </author> <title> "Network performance under bimodal traffic loads," </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> vol. 28, no. 1, </volume> <pages> pp. 43-64, </pages> <month> July </month> <year> 1995. </year> <month> 217 </month>
Reference-contexts: Moreover, controllable or predictable delays can also be used to optimize communication protocols and their implementations. While there has been a wide array of analyses for wormhole-routed networks to model average case performance <ref> [93, 94, 95, 96] </ref>, we know of none that have focused on worst-case latency. Our efforts at analysis indicate that even for a bandwidth allocation algorithm as simple as ALU biasing, system dynamics can be remarkably subtle and complicated. <p> This is an interesting issue but beyond the scope of this dissertation, so it is not discussed further. Our previous work covers in detail the related issues, including the impact of packet interleaving on the average latency of messages with different sizes <ref> [96, 112, 113] </ref>. 6.3.4 Integrated services with CBR+VBR+ABR traffic Many existing networks and most networks in the near future need to support a wide range of applications which will require different traffic characteristics and communication services.
Reference: [97] <author> J. N. Mailhot. </author> <title> "A comparative study of routing and flow control strategies in k-ary n-cube networks," </title> <institution> Massachusetts Institute of Technology, Boston, MA, B.S. </institution> <type> thesis, </type> <year> 1988. </year>
Reference-contexts: This is because mesh networks are asymmetric, so link utilization is inherently unbalanced; links in the center are utilized more than links at the edge, forming a bottleneck <ref> [97] </ref>. The round-robin scheduling simply gives more bandwidth of these highly utilized links to nodes in the center, saturating nodes at the edge at much lower load rates. <p> Also, scalability issues require expandable network topologies, even arbitrary expandable ones. ALU-biased routers help to achieve uniform resource utilization in these nonuniform networks. 3 Similar unbalanced link utilization in torus networks has been observed in the previous work as well <ref> [97, 100, 101] </ref>. (a) Meshes (b) Tori 3.4.4 Network efficiency The scheduling policy in the router also has an influence on the overall network efficiency because each traffic flow in the network will have different impacts on other traffic.
Reference: [98] <institution> Parallel Server AP3000, Fujitsu Limited, Kawasaki, Japan. </institution> <note> Available from http:// www.fujitsu.co.jp/hypertext/Products/Info process/hpc/ap3000-e/index.html. </note>
Reference-contexts: For example, the unbalanced usage of virtual channels required for deadlock prevention disrupts the topological symmetry of torus networks, which in general need two virtual channels to break link dependency cycles <ref> [25, 90, 98] </ref>. All of the messages to cross arbitrarily selected date lines (e.g., nodes at the end of each dimension) are assigned to one virtual channel, and others to the other virtual channel. More details on how they prevent deadlocks are in [90]. <p> However, it would be interesting to observe how network-resource control, in general, can be applied to such symmetric topology networks. Note that torus networks are currently being used in several commercial multicomputers such as Cray T3D [25] and T3E [99], and Fujitsu AP3000 <ref> [98] </ref>. biasing are used, respectively. We follow the virtual channel assignment method described in [100], where virtual channels are decided when packets are injected. It is slightly different from the method described in [90], where messages change virtual channels in the network when crossing the date line.
Reference: [99] <author> S. L. Scott. </author> <title> "Synchronization and communication in the T3E multiprocessor," </title> <booktitle> in Architectural Support for Programming Languages and Operating Systems (ASPLOS-VII), </booktitle> <address> Cambridge, MA, </address> <month> Oct. </month> <year> 1996, </year> <pages> pp. 26-36. </pages> <note> Available from http://reality.sgi.com/ sls craypark/Papers/asplos96.html. </note>
Reference-contexts: However, it would be interesting to observe how network-resource control, in general, can be applied to such symmetric topology networks. Note that torus networks are currently being used in several commercial multicomputers such as Cray T3D [25] and T3E <ref> [99] </ref>, and Fujitsu AP3000 [98]. biasing are used, respectively. We follow the virtual channel assignment method described in [100], where virtual channels are decided when packets are injected. <p> Note that existing multicomputer networks with round-robin arbitration, for instance, the Intel Paragon [24] and Cray T3E <ref> [99] </ref>, can theoretically provide delay guarantees of a few days for 1,024 node configurations. It should be emphasized that the delay bounds we derived above hold true independent of network states or other connections' behaviors.
Reference: [100] <author> S. Scott and G. Thorson. </author> <title> "Optimized routing in the Cray T3D," </title> <booktitle> in Proceedings of the Parallel Computer Routing and Communication Workshop, </booktitle> <address> Seattle, Washington, </address> <year> 1994, </year> <pages> pp. 281-294. </pages> <note> Springer-Verlag Lecture Notes in Computer Science No. 853. </note>
Reference-contexts: Note that torus networks are currently being used in several commercial multicomputers such as Cray T3D [25] and T3E [99], and Fujitsu AP3000 [98]. biasing are used, respectively. We follow the virtual channel assignment method described in <ref> [100] </ref>, where virtual channels are decided when packets are injected. It is slightly different from the method described in [90], where messages change virtual channels in the network when crossing the date line. <p> In the ALU-biased network, the maximum-to-minimum throughput ratio decreases to 1.98, improving by a factor of 2.5 compared to the RR network. In <ref> [100] </ref>, a mechanism has been introduced to assign virtual channels in torus networks more evenly. It first determines source-destination node pairs, which are free to use either virtual channel without causing deadlocks, and then carefully assigns them virtual channels to improve global balance. <p> Also, scalability issues require expandable network topologies, even arbitrary expandable ones. ALU-biased routers help to achieve uniform resource utilization in these nonuniform networks. 3 Similar unbalanced link utilization in torus networks has been observed in the previous work as well <ref> [97, 100, 101] </ref>. (a) Meshes (b) Tori 3.4.4 Network efficiency The scheduling policy in the router also has an influence on the overall network efficiency because each traffic flow in the network will have different impacts on other traffic.
Reference: [101] <author> V. Adve and M. Vernon. </author> <title> "Performance analysis of mesh interconnection networks with deterministic routing," </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> vol. 5, no. 3, </volume> <pages> pp. 225-46, </pages> <year> 1994. </year>
Reference-contexts: Also, scalability issues require expandable network topologies, even arbitrary expandable ones. ALU-biased routers help to achieve uniform resource utilization in these nonuniform networks. 3 Similar unbalanced link utilization in torus networks has been observed in the previous work as well <ref> [97, 100, 101] </ref>. (a) Meshes (b) Tori 3.4.4 Network efficiency The scheduling policy in the router also has an influence on the overall network efficiency because each traffic flow in the network will have different impacts on other traffic.
Reference: [102] <author> M. Homewood and M. McLaren. </author> <title> "Meiko CS-2 interconnect Elan Elite design," </title> <booktitle> in Proceedings of the IEEE Hot Interconnects Symposium, </booktitle> <address> Palo Alto, CA, </address> <month> August </month> <year> 1993. </year>
Reference-contexts: However, the arbitration logic is easily pipelined so that its impact on clock speed is minimal. The router operates at 50MHz, comparable to other commercial wormhole-routed switches such as the IBM SP1/2 [26], Meiko CS-2 <ref> [102] </ref> and Intel Paragon [24]. Moreover, compared to other simple routers, the ServerNet router also includes much more complicated logic for fault tolerance, which takes approximately 15% of the overall gate count. Considering the additional complexity as well, arbitration overhead surely has little impact on the switch operation speed. <p> Two topologies, other than meshes, are examined, hypercube and fat-tree, both of which are widely accepted in commercial multicomputer networks <ref> [26, 89, 102, 114] </ref>. Figure 6.13 illustrates node connections used in the experiment, each of which has the same number of nodes (16) as the mesh network in the previous section. Note that there are many possible variations on a fat-tree other than the one shown in the figure. <p> Mesh Hypercube Fat-tree Diameter 7 4 3 Average distance 4.5 2.9 2.7 Total Links 64 64 32 As in the mesh network, the hypercube network uses dimension-order routing. The fat-tree network uses random routing, as in existing multicomputer networks <ref> [26, 89, 102] </ref>, but in this case, a randomly-selected routing path is preserved for an entire session, not only for each packet. For the same number of nodes, these networks have different diameters, average distances and network capacities from mesh-connected networks, which are summarized in Table 6.2.
Reference: [103] <author> J. H. Kim and A. A. Chien. </author> <title> "Rotating combined queueing (RCQ): Bandwidth and latency guarantees in low-cost, high-performance networks," </title> <booktitle> in Proceedings of the International Symposium on Computer Architecture, </booktitle> <address> Philadelphia, PA, </address> <year> 1996, </year> <pages> pp. 226-236. </pages>
Reference-contexts: In this chapter, we present a service discipline based on the latter approach. We first describe the switch model assumed for our discussion. Then we introduce a novel service discipline, called Rotating Combined Queueing (RCQ) <ref> [103] </ref>, which simplifies both scheduling and queueing processes substantially, making service guarantees in low-cost, high-speed switching networks feasible. We then roughly compare, via simulations, the quality of service of RCQ networks to those of ServerNet observed in the previous chapter.
Reference: [104] <author> M. Karol, M. Hluchyj, and S. Morgan. </author> <title> "Input versus output queueing on a space-division packet switch," </title> <journal> IEEE Transactions on Communications, </journal> <volume> vol. COM-35, no. 12, </volume> <pages> pp. 1347-1356, </pages> <month> Dec. </month> <year> 1987. </year> <month> 218 </month>
Reference-contexts: In general, output queueing provides 87 significantly better performance than input queueing by reducing the head-of-line (HOL) blocking <ref> [104] </ref>. Some commercial multicomputer switches such as the IBM SP1/2 [26] actually implement output queueing for higher throughput. More importantly, output queueing makes it easier to distribute link bandwidth to demanding connections.
Reference: [105] <author> R. Gidron. "TeraNet: </author> <title> A multi-gigabits per second ATM network," </title> <journal> Computer Com--munications, </journal> <volume> vol. 15, no. 3, </volume> <pages> pp. 143-152, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: Output queueing requires high-bandwidth connections between input and output modules inside a switch, which must be able to transfer packets at a speed k times the link speed. The high bandwidth connection can be implemented by using multiple broadcasting buses <ref> [42, 105] </ref> or replicated crossbars [106]. In [107], a compromise between the internal bandwidth requirement of the output queueing switch and performance is suggested, dropping packets when too many packets arrive for an output channel simultaneously. Unfortunately, the dropping scheme cannot be applied to the network for deterministic service guarantee.
Reference: [106] <author> H. Ahmadi, W. Denzel, C. Murphy, and E. </author> <title> Port. "A high-performance switch fabric for integrated circuit and packet switching," </title> <booktitle> in Proceedings of IEEE INFOCOM, </booktitle> <address> New Orleans, LA, </address> <year> 1988, </year> <pages> pp. 9-18. </pages>
Reference-contexts: Output queueing requires high-bandwidth connections between input and output modules inside a switch, which must be able to transfer packets at a speed k times the link speed. The high bandwidth connection can be implemented by using multiple broadcasting buses [42, 105] or replicated crossbars <ref> [106] </ref>. In [107], a compromise between the internal bandwidth requirement of the output queueing switch and performance is suggested, dropping packets when too many packets arrive for an output channel simultaneously. Unfortunately, the dropping scheme cannot be applied to the network for deterministic service guarantee.
Reference: [107] <author> Y. Yeh, M. Hluchyj, and A. Acampora. </author> <title> "The knockout switch: A simple, modular architecture for high-performance packet switching," </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> vol. SAC-5, no. 8, </volume> <pages> pp. 1274-1283, </pages> <month> Oct. </month> <year> 1987. </year>
Reference-contexts: Output queueing requires high-bandwidth connections between input and output modules inside a switch, which must be able to transfer packets at a speed k times the link speed. The high bandwidth connection can be implemented by using multiple broadcasting buses [42, 105] or replicated crossbars [106]. In <ref> [107] </ref>, a compromise between the internal bandwidth requirement of the output queueing switch and performance is suggested, dropping packets when too many packets arrive for an output channel simultaneously. Unfortunately, the dropping scheme cannot be applied to the network for deterministic service guarantee.
Reference: [108] <author> H. T. Kung, R. Morris, T. Charuhas, and D. Lin. </author> <title> "Use of link-by-link flow control in maximizing ATM networks performance: Simulation results," </title> <booktitle> in Proceedings of the IEEE Hot Interconnects Symposium, </booktitle> <address> Palo Alto, CA, </address> <year> 1993, </year> <pages> pp. 79-89. </pages>
Reference-contexts: Traffic congestion is usually constrained by either a source-level rate control [47] or a feedback-based flow control <ref> [108] </ref>. While the former approach helps to provide guaranteed services inside the network and also build simpler switches, the latter approach allows connections to exploit network bandwidth more efficiently, so it is accepted by most existing multicomputer networks.
Reference: [109] <author> R. Cruz. </author> <title> "A calculus for network delay, Part II: Network analysis," </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> vol. 37, no. 1, </volume> <pages> pp. 132-141, </pages> <month> Jan. </month> <year> 1991. </year>
Reference-contexts: First-Come-First-Serve vs. RCQ In general, First-Come-First-Serve (FCFS) switches cannot guarantee services to a traffic stream because the behavior depends completely on behavior of other connections sharing the switches. However, with strict constraints on traffic rates, this simple arbitration technique can also be practically applied to applications requiring guaranteed services <ref> [81, 109] </ref>. <p> average rate of input stream (normalized with respect to link capacity), respectively, the end-to-end packet (or single-packet message) delay in the FCFS network is bounded by D pkt P (1 n) + 1 ! where n and H indicate the number of supported connections and maximum distance in hops, respectively <ref> [109] </ref>. While this simple modification to FCFS networks provides delay-bound guarantees, this approach has limitations in supporting integrated-service networks. First of all, the input-traffic model controlled by token buckets cannot support best-effort, bursty traffic efficiently because traffic rates are restricted conservatively. <p> Note that even periodic input streams (then, = 0) can have large delay bounds because the 116 periodicity cannot be preserved inside the network. However, in RCQ networks, the delay bounds are much lower, increasing linearly with the distance, independent of network status or other traffic behaviors. In <ref> [109] </ref>, it is also shown that the delay bounds in FCFS networks can be reduced significantly by inserting a (; ) rate regulator for each connection in internal switch ports as well.
Reference: [110] <author> D. Stiliadis and A. Varma. </author> <title> "Latency-rate servers: A general model for analysis of traffic scheduling algorithms," </title> <booktitle> in Proceedings of INFOCOM, </booktitle> <address> San Francisco, CA, </address> <year> 1996. </year>
Reference-contexts: Assuming that connection i's queue is empty along the path, the worst-case packet delay of connection i in a VC network is derived in <ref> [110] </ref> as follows: D pkt;i i=0 P max + i ; where P max and P i indicate the maximum packet size of any connection and connection i, respectively, and C and i indicate link bandwidth and connection i's reserved bandwidth, respectively.
Reference: [111] <author> D. Ferrari, A. Banerjee, and H. Zhang. </author> <title> "Network support for multimedia: A discussion of the Tenet approach," </title> <journal> Computer Networks and ISDN Systems, </journal> <volume> vol. 26, </volume> <pages> pp. 1267-1280, </pages> <year> 1994. </year>
Reference-contexts: By reducing raw bandwidth and storage requirements, data compression helps to support more streams at one time. However, wide variations in compressed data rates make it difficult to achieve service guarantees and efficiency simultaneously. As a compromise, researchers have suggested statistical service guarantees to such traffic <ref> [56, 111] </ref>, where each connection for VBR traffic reserving average (not peak) bandwidth is given only probabilistical (not deterministic) guarantees on delay bounds or packet loss rates. This kind of service can be supported best with scheduling algorithms that can provide efficient network utilization, as well as accurate resource control.
Reference: [112] <author> J. H. Kim and A. A. Chien. </author> <title> "The impact of packetization in wormhole-routed networks," </title> <booktitle> in Proceedings of PARLE, </booktitle> <address> Munich, Germany, </address> <month> June </month> <year> 1993, </year> <pages> pp. 242-253. </pages>
Reference-contexts: This is an interesting issue but beyond the scope of this dissertation, so it is not discussed further. Our previous work covers in detail the related issues, including the impact of packet interleaving on the average latency of messages with different sizes <ref> [96, 112, 113] </ref>. 6.3.4 Integrated services with CBR+VBR+ABR traffic Many existing networks and most networks in the near future need to support a wide range of applications which will require different traffic characteristics and communication services.
Reference: [113] <author> J. H. Kim and A. A. Chien. </author> <title> "Evaluation of wormhole routed networks under hybrid traffic loads," </title> <booktitle> in Proceedings of the Hawaii International Conference on System Sciences, </booktitle> <address> Maui, HI, </address> <month> January </month> <year> 1993, </year> <journal> vol. </journal> <volume> 1, </volume> <pages> pp. 276-85. 219 </pages>
Reference-contexts: This is an interesting issue but beyond the scope of this dissertation, so it is not discussed further. Our previous work covers in detail the related issues, including the impact of packet interleaving on the average latency of messages with different sizes <ref> [96, 112, 113] </ref>. 6.3.4 Integrated services with CBR+VBR+ABR traffic Many existing networks and most networks in the near future need to support a wide range of applications which will require different traffic characteristics and communication services.
Reference: [114] <editor> B. Duzett. </editor> <booktitle> "nCUBE3 communications architecture," in Proceedings of the IEEE Sym--posium on Hot Interconnects, </booktitle> <address> Palo Alto, CA, </address> <year> 1994. </year>
Reference-contexts: Two topologies, other than meshes, are examined, hypercube and fat-tree, both of which are widely accepted in commercial multicomputer networks <ref> [26, 89, 102, 114] </ref>. Figure 6.13 illustrates node connections used in the experiment, each of which has the same number of nodes (16) as the mesh network in the previous section. Note that there are many possible variations on a fat-tree other than the one shown in the figure.
Reference: [115] <institution> Data Book for the Mitsubishi M6007x and M6008x Series Gate Array Families, Mit-subishi Electronic Devices Group, </institution> <address> Yokohama, Japan, </address> <month> March </month> <year> 1993. </year>
Reference-contexts: The numbers of transistors are estimated based on 0.8 m gate array library data provided by Mitsubishi <ref> [115] </ref> as summarized in Table 7.3.
Reference: [116] <author> M. Galles. </author> <title> "Scalable pipelined interconnect for distributed endpoint routing: The SGI SPIDER chip," </title> <booktitle> in Proceedings of the IEEE Hot Interconnects Symposium, </booktitle> <address> Palo Alto, CA, </address> <year> 1996. </year>
Reference-contexts: Even when considering dynamic sharing of buffers over multiple output ports, a few million transistors only for scheduling and queueing logic only are over the implementation budget of most contemporary multicomputer switches. However, recent technical trends of large-scale switches of a few million transistors <ref> [63, 116] </ref> and increasing circuit integration not only make RCQ feasible in a single chip but also make the transistor counters a less important factor than run time scheduling overheads. 7.3 Implementation Considerations As we observed above, the implementation cost of the RCQ network depends on several network design parameters including <p> One of the clear trends in multicomputer networks is increasing transistor counts and buffer space in a switch, mainly due to improving circuit integration technology. It is not uncommon to observe highly integrated switch chips with more than 2-3 million transistors <ref> [63, 85, 116] </ref>. Within such large switch chips, it would be not difficult to integrate RCQ. In addition, the large buffer space in such switches will also help RCQ support bursty traffic more efficiently.
Reference: [117] <institution> MMX Technology, Intel Corporation, </institution> <address> Santa Clara, CA. </address> <note> Available from http:// developer.intel.com/drg/mmx. </note>
Reference-contexts: This is partly because of the significant amount of processing power required for multimedia data processing and partly because of inefficient protocols inherited from traditional data communications. However, recent hardware support for multimedia data processing (e.g., MMX-supported microprocessors <ref> [117] </ref>) and the development of new protocols specialized for multimedia communications [118] eliminate such bottlenecks, increasing the demand for network capacity substantially. This trend of requiring fast switches is also observed in traditional data communications as well.
Reference: [118] <author> Z. Chen, S. Tan, R. H. Campbell, and Y. Li. </author> <title> "Real time video and audio in the world wide web," </title> <booktitle> in Proceedings of WWW4, Boston, </booktitle> <address> MA, </address> <year> 1995. </year>
Reference-contexts: This is partly because of the significant amount of processing power required for multimedia data processing and partly because of inefficient protocols inherited from traditional data communications. However, recent hardware support for multimedia data processing (e.g., MMX-supported microprocessors [117]) and the development of new protocols specialized for multimedia communications <ref> [118] </ref> eliminate such bottlenecks, increasing the demand for network capacity substantially. This trend of requiring fast switches is also observed in traditional data communications as well.
Reference: [119] <author> S. Pakin, M. Lauria, and A. Chien. </author> <title> "High performance messaging on workstations: Illinois Fast Messages (FM) for Myrinet," </title> <booktitle> in Proceedings of Supercomputing, </booktitle> <address> San Diego, CA, </address> <month> Dec. </month> <year> 1995. </year> <note> Available from http://www-csag.cs.uiuc.edu/papers/myrinet-fm-sc95.ps. </note>
Reference-contexts: This trend of requiring fast switches is also observed in traditional data communications as well. Many researchers have explored the causes of communication overhead at end nodes, improved the existing protocols and their implementations, or developed new communication subsystems <ref> [119, 120, 121] </ref>. In parallel, many architectural changes in communication subsystems have been suggested, for instance, high-bandwidth datapaths [122, 123] and tighter coupling of communication subsystems to microprocessors [121, 124, 125]. With increasing 184 multimedia communications, these architectural changes demand high network performance more than ever.
Reference: [120] <author> C. Dalton, G. Watson, D. Banks, C. Calamvokis, A. Edwards, and J. Lumley. </author> <title> "Afterburner," </title> <journal> IEEE Network, </journal> <volume> vol. 7, no. 4, </volume> <pages> pp. 36-43, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: This trend of requiring fast switches is also observed in traditional data communications as well. Many researchers have explored the causes of communication overhead at end nodes, improved the existing protocols and their implementations, or developed new communication subsystems <ref> [119, 120, 121] </ref>. In parallel, many architectural changes in communication subsystems have been suggested, for instance, high-bandwidth datapaths [122, 123] and tighter coupling of communication subsystems to microprocessors [121, 124, 125]. With increasing 184 multimedia communications, these architectural changes demand high network performance more than ever.
Reference: [121] <author> R. B. Gillett. </author> <title> "Memory Channel network for PCI," </title> <journal> IEEE Micro, </journal> <volume> vol. 16, no. 1, </volume> <pages> pp. 12-18, </pages> <month> Feb. </month> <year> 1996. </year> <note> Available from http://www.computer.org/pubs/micro/web/m1gil.pdf. </note>
Reference-contexts: This trend of requiring fast switches is also observed in traditional data communications as well. Many researchers have explored the causes of communication overhead at end nodes, improved the existing protocols and their implementations, or developed new communication subsystems <ref> [119, 120, 121] </ref>. In parallel, many architectural changes in communication subsystems have been suggested, for instance, high-bandwidth datapaths [122, 123] and tighter coupling of communication subsystems to microprocessors [121, 124, 125]. With increasing 184 multimedia communications, these architectural changes demand high network performance more than ever. <p> In parallel, many architectural changes in communication subsystems have been suggested, for instance, high-bandwidth datapaths [122, 123] and tighter coupling of communication subsystems to microprocessors <ref> [121, 124, 125] </ref>. With increasing 184 multimedia communications, these architectural changes demand high network performance more than ever.
Reference: [122] <author> T. Shanley and D. Anderson. </author> <title> PCI System Architecture. </title> <publisher> MindShare, Inc., </publisher> <address> Reading, MA, </address> <year> 1995. </year>
Reference-contexts: Many researchers have explored the causes of communication overhead at end nodes, improved the existing protocols and their implementations, or developed new communication subsystems [119, 120, 121]. In parallel, many architectural changes in communication subsystems have been suggested, for instance, high-bandwidth datapaths <ref> [122, 123] </ref> and tighter coupling of communication subsystems to microprocessors [121, 124, 125]. With increasing 184 multimedia communications, these architectural changes demand high network performance more than ever.
Reference: [123] <institution> The Ultra 1 Architecture, Sun Microsystems Computer Company, Mountain View, CA. </institution> <note> Technical white paper available from http://www.sun.com/desktop/products/Ultra1. 220 </note>
Reference-contexts: Many researchers have explored the causes of communication overhead at end nodes, improved the existing protocols and their implementations, or developed new communication subsystems [119, 120, 121]. In parallel, many architectural changes in communication subsystems have been suggested, for instance, high-bandwidth datapaths <ref> [122, 123] </ref> and tighter coupling of communication subsystems to microprocessors [121, 124, 125]. With increasing 184 multimedia communications, these architectural changes demand high network performance more than ever.
Reference: [124] <author> D. S. Henry and C. F. Joerg. </author> <title> "A tightly-coupled processor-network interface," </title> <booktitle> in Pro--ceedings of the Fifth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS-V), </booktitle> <address> Boston, MA, </address> <month> October </month> <year> 1992, </year> <pages> pp. 111-122. </pages> <note> Available from ftp://csg-ftp.lcs.mit.edu/pub/papers/csgmemo/memo-342.ps.gz. </note>
Reference-contexts: In parallel, many architectural changes in communication subsystems have been suggested, for instance, high-bandwidth datapaths [122, 123] and tighter coupling of communication subsystems to microprocessors <ref> [121, 124, 125] </ref>. With increasing 184 multimedia communications, these architectural changes demand high network performance more than ever.
Reference: [125] <author> T. Shimizu, T. Horie, and H. Ishihata. </author> <title> "Low-latency message communication support for the AP1000," </title> <booktitle> in Proceedings of the 19th Annual International Symposium on Computer Architecture, </booktitle> <address> Gold Coast, Australia, </address> <year> 1992, </year> <pages> pp. 288-297. </pages> <note> Available from ftp:// fcapwide.fujitsu.co.jp/ap1000/english/isca/isca 92.ps.Z. </note>
Reference-contexts: In parallel, many architectural changes in communication subsystems have been suggested, for instance, high-bandwidth datapaths [122, 123] and tighter coupling of communication subsystems to microprocessors <ref> [121, 124, 125] </ref>. With increasing 184 multimedia communications, these architectural changes demand high network performance more than ever.
Reference: [126] <author> V. Karamcheti and A. Chien. </author> <title> "Software overhead in messaging layers: Where does the time go?," </title> <booktitle> in Proceedings of the Sixth Symposium on Architectural Support for Programming Languages and Operating Systems (ASPLOS-VI), </booktitle> <address> San Jose, CA, </address> <month> October </month> <year> 1994, </year> <pages> pp. 51-60, </pages> <institution> Association for Computing Machinery. </institution> <note> Available from http://www-csag.cs.uiuc.edu/papers/asplos94.ps. </note>
Reference-contexts: Although we discussed its primitive benefits including fairness and uniform resource utilization, the full benefits of predictable and semi-synchronous communications on overall application performance are still unknown. Interestingly, several recent studies <ref> [126, 127, 128] </ref> have argued that hardware support for communication protocols may improve the overall communication performance. While possibly reducing raw network performance, hardware for network service control may eventually contribute to overall system performance by balancing software messaging layers and underlying hardware performance.
Reference: [127] <author> T. Callahan and S. Goldstein. "NIFDY: </author> <title> A low overhead, high throughput network interface," </title> <booktitle> in Proceedings of the International Symposium on Computer Architecture, </booktitle> <address> Santa Margherita Ligure, Italy, </address> <year> 1995, </year> <pages> pp. 230-241. </pages>
Reference-contexts: Although we discussed its primitive benefits including fairness and uniform resource utilization, the full benefits of predictable and semi-synchronous communications on overall application performance are still unknown. Interestingly, several recent studies <ref> [126, 127, 128] </ref> have argued that hardware support for communication protocols may improve the overall communication performance. While possibly reducing raw network performance, hardware for network service control may eventually contribute to overall system performance by balancing software messaging layers and underlying hardware performance.

References-found: 127

