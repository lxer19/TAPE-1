URL: http://www.speech.sri.com/people/konig/papers/nips92.ps
Refering-URL: http://www.speech.sri.com/people/konig/resume.html
Root-URL: 
Title: Modeling Consistency in a Speaker Independent Continuous Speech Recognition System  
Author: Yochai Konig, Nelson Morgan, Chuck Wooters Victor Abrash, Michael Cohen, Horacio Franco 
Address: 1947 Center Street, Suite 600 Berkeley, CA 94704, USA.  333 Ravenswood Ave. Menlo Park, CA 94025, USA  
Affiliation: International Computer Science Institute  SRI International  
Abstract: We would like to incorporate speaker-dependent consistencies, such as gender, in an otherwise speaker-independent speech recognition system. In this paper we discuss a Gender Dependent Neural Network (GDNN) which can be tuned for each gender, while sharing most of the speaker independent parameters. We use a classification network to help generate gender-dependent phonetic probabilities for a statistical (HMM) recognition system. The gender classification net predicts the gender with high accuracy, 98.3% on a Resource Management test set. However, the integration of the GDNN into our hybrid HMM-neural network recognizer provided an improvement in the recognition score that is not statistically significant on a Resource Management test set.
Abstract-found: 1
Intro-found: 1
Reference: [ Abrash et al., 1992 ] <author> V. Abrash, H. Franco, M. Cohen, N. Morgan, and Y. Konig. </author> <title> Connectionist gender adaptation in a hybrid neural network / hidden markov model speech recognition system. </title> <booktitle> In Proc. Int'l Conf. on Spoken Lang. Processing, </booktitle> <address> Banff, Canada, </address> <month> October </month> <year> 1992. </year>
Reference-contexts: We will give a short description of some related work, followed by an explanation of the two steps described above. We conclude with some discussion and thoughts about future work. 2 RELATED AND PREVIOUS WORK Our previous experiments with the Gender-Dependent Neural Network (GDNN) are described in <ref> [ Abrash et al., 1992; Konig and Morgan, 1992 ] </ref> . Other researchers have worked on related problems. For example Hampshire and Waibel presented the Meta-Pi architecture [ Hampshire and Waibel, 1990 ] .
Reference: [ Bourlard and Morgan, 1991 ] <author> H. Bourlard and N. Morgan. </author> <title> Merging multilayer perceptrons & hidden markov models: Some experiments in continuous speech recognition. </title> <editor> In E. Gelenbe, editor, </editor> <booktitle> Artificial Neural Networks: Advances and Applications. </booktitle> <publisher> North Holland Press, </publisher> <year> 1991. </year>
Reference-contexts: 1 INTRODUCTION Earlier work <ref> [ Bourlard and Morgan, 1991 ] </ref> has shown the ability of Multilayer Perceptrons (MLPs) to estimate emission probabilities for Hidden Markov Models (HMM).
Reference: [ Cohen et al., 1993 ] <author> M. Cohen, H. Franco, N. Morgan, D. Rumelhart, and V. Abrash. </author> <title> Context-dependent multiple distribution phonetic modeling. </title> <editor> In C.L. Giles, Hanson S.J, and J.D. Cowan, editors, </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> volume 5. </volume> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, </address> <year> 1993. </year>
Reference-contexts: In this hybrid HMM/MLP recognizer, it was shown that these estimates led to improved performance over standard estimation techniques when a fairly simple HMM was used. More recent results have shown improvements using hybrid HMM/MLP probability estimation over a state-of-the-art pure HMM-based system <ref> [ Cohen et al., 1993; Renals et al., 1992 ] </ref> . Some speaker dependencies exist in common parametric representations of speech, and it is possible that making the dependencies explicit may improve performance for a given speaker (essentially enabling the recognizer to soften the influence of the speaker dependency). <p> The results are summarized in table 1, and are achieved using the standard Resource Management wordpair grammar (perplexity = 60) with a simple context-independent HMM recognizer. We should note here that these results are all somewhat worse than our other results published in <ref> [ Renals et al., 1992; Cohen et al., 1993 ] </ref> , as the latter were achieved using SRI's phonological models, and these were done with a single-pronunciation single-state HMM (with each state repeated for a rough duration model). 5 DISCUSSION AND FUTURE WORK The best results were achieved by the GDNN
Reference: [ Hampshire and Waibel, 1990 ] <author> J.B. Hampshire and A. Waibel. </author> <title> Connectionist architectures for multi-speaker phoneme recognition. </title> <editor> In D.S. Touretzky, editor, </editor> <booktitle> Advances in Neural Information Processing Systems 2, </booktitle> <address> San mateo, CA, 1990. </address> <publisher> Morgan Kaufman. </publisher>
Reference-contexts: Other researchers have worked on related problems. For example Hampshire and Waibel presented the Meta-Pi architecture <ref> [ Hampshire and Waibel, 1990 ] </ref> . The building blocks for the Meta-Pi architecture are multiple TDNN's that are trained to recognize the speech of an individual speaker.
Reference: [ Huang et al., 1991 ] <author> X.D. Huang, K.F. Lee, and A. Waibel. </author> <title> Connectionist speaker normalization and its application to speech recognition. </title> <booktitle> In Neural Networks for Siganl Processing, proc. of 1991 IEEE Workshop,, </booktitle> <address> Princeton, New Jersey, </address> <month> October </month> <year> 1991. </year>
Reference-contexts: Another example of related work is speaker normalization, which attempts to minimize between-speaker variations by transforming the data of a new speaker to that of a reference speaker, and then applying the speaker dependent system for the reference speaker <ref> [ Huang et al., 1991 ] </ref> . 3 THE CLASSIFICATION NET In order to classify the gender of a new speaker we need features that distinguish between speakers, in contrast to the features that are used for phoneme recognition that are chosen to suppress speaker variations.
Reference: [ Konig and Morgan, 1992 ] <author> Y. Konig and N. Morgan. Gdnn: </author> <title> A gender -dependent neural network for continuous speech recognition. </title> <booktitle> In Proc. international Joint Conference on Neural Networks, </booktitle> <address> Baltimore, Maryland, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: We will give a short description of some related work, followed by an explanation of the two steps described above. We conclude with some discussion and thoughts about future work. 2 RELATED AND PREVIOUS WORK Our previous experiments with the Gender-Dependent Neural Network (GDNN) are described in <ref> [ Abrash et al., 1992; Konig and Morgan, 1992 ] </ref> . Other researchers have worked on related problems. For example Hampshire and Waibel presented the Meta-Pi architecture [ Hampshire and Waibel, 1990 ] . <p> This approach has the potential disadvantages of doubling the number of parameters in the system, and of not sharing the gender independent parameters. We have experimented with a such a net <ref> [ Konig and Morgan, 1992 ] </ref> and it improved our result over the baseline system. We present here a hybrid GDNN architecture that has the flexibility to tune itself to each gender.
Reference: [ Morgan and Bourlard, 1992 ] <author> N. Morgan and H. Bourlard. </author> <title> Factoring neural networks by a statistical method. </title> <journal> Neural Computation, </journal> (4):835-838, 1992. 
Reference-contexts: This factorization is realized by two separate MLP's: P (malejdata) is estimated by the classification net described above, and P (phonejmale; data) is realized by our GDNN described below. For further description on how to factorize probabilities by neural networks see <ref> [ Morgan and Bourlard, 1992 ] </ref> . The final likelihood for the male case can be expressed as: P (datajphone; male) = P (phonejmale; data) fi P (malejdata) fi P (data) P (phonejmale) fi P (male) (1) Note that during recognition, P (data) can be ignored.
Reference: [ Murveit et al., 1990 ] <author> H. Murveit, M. Weintraub, and M. Cohen. </author> <title> Training set issues in sri's decipher speech recognition system. </title> <booktitle> In Proc. speech and Natural Language Workshop, </booktitle> <pages> pages 337-340, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: This limit is our starting point for this study. Even with this limited information, we can incorporate constraints on analysis that rely on the same speaker producing all the frames in an utterance, thus ensuring consistency. As has been observed for some mainstream Hidden Markov Models (HMM) systems <ref> [ Murveit et al., 1990 ] </ref> , given enough training data, separate phonetic models for male and female speakers can be used to improve performance. Our first attack on consistency, then, is to incorporate gender consistency in the recognition process.
Reference: [ Renals et al., 1992 ] <author> S. Renals, N. Morgan, M. Cohen, H. Franco, and H. Bourlard. </author> <title> Connectionist probability estimation in the decipher speech recognition system. </title> <booktitle> In Proceedings IEEE Intl. Conf. on Acoustics, Speech, and Signal Processing, </booktitle> <address> San Francisco, California, </address> <month> March </month> <year> 1992. </year> <note> IEEE. </note>
Reference-contexts: In this hybrid HMM/MLP recognizer, it was shown that these estimates led to improved performance over standard estimation techniques when a fairly simple HMM was used. More recent results have shown improvements using hybrid HMM/MLP probability estimation over a state-of-the-art pure HMM-based system <ref> [ Cohen et al., 1993; Renals et al., 1992 ] </ref> . Some speaker dependencies exist in common parametric representations of speech, and it is possible that making the dependencies explicit may improve performance for a given speaker (essentially enabling the recognizer to soften the influence of the speaker dependency). <p> The results are summarized in table 1, and are achieved using the standard Resource Management wordpair grammar (perplexity = 60) with a simple context-independent HMM recognizer. We should note here that these results are all somewhat worse than our other results published in <ref> [ Renals et al., 1992; Cohen et al., 1993 ] </ref> , as the latter were achieved using SRI's phonological models, and these were done with a single-pronunciation single-state HMM (with each state repeated for a rough duration model). 5 DISCUSSION AND FUTURE WORK The best results were achieved by the GDNN
References-found: 9

