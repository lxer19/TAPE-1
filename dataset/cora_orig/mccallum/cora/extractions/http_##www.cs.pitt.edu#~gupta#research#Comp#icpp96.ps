URL: http://www.cs.pitt.edu/~gupta/research/Comp/icpp96.ps
Refering-URL: http://www.cs.pitt.edu/~gupta/research/dm.html
Root-URL: 
Title: A Timestamp-based Selective Invalidation Scheme for Multiprocessor Cache Coherence  
Author: Xin Yuan Rami Melhem Rajiv Gupta 
Address: Pittsburgh Pittsburgh, PA 15260  
Affiliation: Department of Computer Science University of  
Abstract: Among all software cache coherence strategies, the ones that are based on the concept of timestamps show the greatest potential in terms of cache performance. The early timestamp methods suffer from high hardware overhead. Improvements have been proposed to reduce hardware overhead at the expense of either increasing runtime overhead or sacrificing cache performance. In this paper, we discuss the limitations of the previous timestamp-based methods and propose a new software cache coherence scheme. Our scheme exploits the inter-level locality with significantly less hardware support than the early times-tamp methods while introducing only constant run-time overhead for each epoch during the execution of a program. Simulation results show that the proposed scheme achieves higher performance than the previous schemes with comparable hardware overhead. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Aho, A.V., Sethi, R. and Ullman, J.D. </author> <booktitle> "Compilers: Principles, Techniques and Tools." </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1986. </year>
Reference-contexts: The next write level in the innermost loop is considered as the next write level. In this way, TBSIS always captures the locality inside the loop. Using epoch flow graph [6], the next write level information can be obtained in two steps. First, using the algorithm in <ref> [1] </ref>, we determine the looping structures in the flow graph. Then, for each memory reference, the compiler searches forward for all the writes to the same variable that can be reached by the reference in the flow graph.
Reference: [2] <author> Bailey, D. et al. </author> <title> "The NAS Parallel Benchmarks." </title> <type> RNR Technical report, </type> <institution> RNR-94-007, </institution> <month> March, </month> <year> 1994. </year>
Reference-contexts: The second program tscf, is a program that simulates the evolution of a self-gravitating system using a self consistent field approach. The third program ep is the NAS's embarrassingly parallel benchmark <ref> [2] </ref>. The outermost loop iteration number of the ep program is reduced by a factor of 256 to shorten the simulation time. Table 2 shows the general characteristics of the three benchmarks used in our experiment. The epoch number is obtained from the execution of the program on 32 processors.
Reference: [3] <author> H. Cheong and A. </author> <title> Veidenbaum "Compiler-directed Cache Management for Multiprocessor." </title> <journal> IEEE Computer, </journal> <volume> 23(6) </volume> <pages> 39-47, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: Among the existing software controlled cache coherence schemes, the methods based on the concept of timestamps are more effective in preserving cache lines across task boundaries than other software methods [4, 9]. The early timestamp-based methods, such as the version control method <ref> [3] </ref> and the timestamp method [10], use an explicit timestamp table to store the current version number for each variable. They also use an additional field in each cache line to store the version number of the cache line. <p> Data variables are classified into private, shared read-only and shared read-write. Only shared read-write variables can cause cache coherence problems. When we refer to a variable, it is assumed to be a shared read-write variable. 3 Timestamp Based Methods The Version Control Method In the version control method <ref> [3] </ref>, the current version number (CVN) for each variable is kept in the variable ID table in each processor. An entire array is treated as a single variable. For the method to be efficient, the variable ID table must be accessed in parallel with the cache access. <p> It is simple to ensure a coherent cache by using the ILN field and the invalidation instruction. For example, the compiler may provide each memory reference with ILN equal to the current level number. TBSIS is then reduced to the simple invalidation scheme <ref> [3] </ref> which can only exploit the intra-level locality. To exploit maximum locality, the compiler should always try to set ILN to the next write level number. 4.3 Software Support The major task of software support is to determine the next write level number for each memory reference.
Reference: [4] <author> H. Cheong, </author> <title> "Life-span strategy A Compiler-based Approach to Cache Coherence." </title> <booktitle> In Proceedings of 1992 International Conference on Supercomputing, </booktitle> <year> 1992. </year>
Reference-contexts: Among the existing software controlled cache coherence schemes, the methods based on the concept of timestamps are more effective in preserving cache lines across task boundaries than other software methods <ref> [4, 9] </ref>. The early timestamp-based methods, such as the version control method [3] and the timestamp method [10], use an explicit timestamp table to store the current version number for each variable.
Reference: [5] <author> T. Chiueh, </author> <title> "A Generational Algorithm to Multiprocessor Cache Coherence." </title> <booktitle> In Proceedings of the 1993 International Conference on Parallel Processing, </booktitle> <pages> pages I20-I24, </pages> <year> 1993. </year>
Reference-contexts: Although the cache performance of these methods approaches that of the hardware schemes, the maintenance of the table and the additional timestamp field introduces hardware and runtime overheads. The later methods, such as TS1 with a 1 bit timestamp [8], the generational algorithm <ref> [5] </ref> and the two-phase invalidation scheme (TPI) [6], try to reduce these overheads. TS1 avoids most of the hardware overhead by eliminating the timestamp table and reducing the additional times-tamp field to one bit for each cache line. <p> The compiler is responsible for determining the VGN for all the memory references. By using a common CVN, the generational algorithm eliminates the variable ID table and the problems associated with it. However, <ref> [5] </ref> does not address some important issues. For example, it is not clear how the VGNs of the cache lines are updated for the variables modified in a level.
Reference: [6] <author> L. Choi and P. </author> <title> Yew "A Compiler-Directed Cache Coherence Scheme with Improved Intertask Locality." </title> <booktitle> In Supercomputing'94, </booktitle> <pages> pages 773-782, </pages> <year> 1994. </year>
Reference-contexts: The later methods, such as TS1 with a 1 bit timestamp [8], the generational algorithm [5] and the two-phase invalidation scheme (TPI) <ref> [6] </ref>, try to reduce these overheads. TS1 avoids most of the hardware overhead by eliminating the timestamp table and reducing the additional times-tamp field to one bit for each cache line. <p> Therefore, the stale cache copies are detected by comparing the timestamp field with the last write epoch number. When the current epoch counter overflows, an explicit invalidation instruction is used to invalidate the cache lines. As shown in <ref> [6] </ref>, the method can preserve most of the localities with reasonable hardware and runtime overhead. Furthermore, interprocedural analysis techniques can be incorporated in this method to preserve the locality across procedure boundaries [7]. <p> If there is a backward branch involved, the memory reference is inside a loop. The next write level in the innermost loop is considered as the next write level. In this way, TBSIS always captures the locality inside the loop. Using epoch flow graph <ref> [6] </ref>, the next write level information can be obtained in two steps. First, using the algorithm in [1], we determine the looping structures in the flow graph.
Reference: [7] <author> L. Choi and P. </author> <title> Yew "Interprocedural Array Data-Flow Analysis for Cache Coherence." </title> <booktitle> In 8th Intl. Workshop on Languages and Compilers for Parallel Comp., </booktitle> <pages> pages 6.1-6.15, </pages> <month> Aug. </month> <year> 1995. </year>
Reference-contexts: As shown in [6], the method can preserve most of the localities with reasonable hardware and runtime overhead. Furthermore, interprocedural analysis techniques can be incorporated in this method to preserve the locality across procedure boundaries <ref> [7] </ref>. The limitation of this method is that it does not always handle nested looping structures shown in Fig. 2 effectively.
Reference: [8] <author> E.Darnell and K. </author> <title> Kennedy "Cache Coherence Using Local Knowledge." </title> <booktitle> In Supercomputing'93, </booktitle> <pages> pages 720-729, </pages> <year> 1993. </year>
Reference-contexts: Although the cache performance of these methods approaches that of the hardware schemes, the maintenance of the table and the additional timestamp field introduces hardware and runtime overheads. The later methods, such as TS1 with a 1 bit timestamp <ref> [8] </ref>, the generational algorithm [5] and the two-phase invalidation scheme (TPI) [6], try to reduce these overheads. TS1 avoids most of the hardware overhead by eliminating the timestamp table and reducing the additional times-tamp field to one bit for each cache line. <p> Thus, the cache will always contain valid cache lines. The performance and overhead of this scheme depends heavily on the mechanism used to invalidate the stale cache lines. Two implementations of the invalidation mechanism are proposed in <ref> [8] </ref>. The simple and inexpensive invalidation mechanism uses a low level invalidate instruction which could invalidate either a particular line or a particular page. The high level invalidate would then loop over the proper range of pages and lines. <p> Using this simple serial scheme, the invalidation overhead is O ( P n i=1 (s i )), where s i is the size of the ith section to be invalidated. A faster, but more complex invalidation method was proposed in <ref> [8] </ref> and [9]. This parallel scheme requires a full associated address tag memory. A bit mask is used to determine which addresses to invalidate. <p> In summary, TS1 effectively preserves the reuses of a cache line. Using precise invalidation, this scheme can achieve the best cache hit ratio that any software cache coherence method based on local knowledge can possibly achieve <ref> [8] </ref>. The limitation is the runtime overhead. The exploitation of higher cache hit ratio by using precise invalidation results in larger runtime overhead. Therefore, it is desirable to develop a mechanism to perform the invalidation more effectively. <p> The processor also needs to support the memory reference instructions Read ILN and Write ILN. Both instructions are augmented with an extra ILN field. Beside the traditional operations, these instructions also update the ILN fields in the cache lines. 4.2 The Scheme TBSIS is a generalization of TS1 <ref> [8] </ref>. The main idea is still to explicitly invalidate the stale cache copies if the variable is modified in the current epoch. By using more bits as timestamp for each cache line and augmenting the compiler support, the explicit invalidation in TBSIS can be carried out more efficiently.
Reference: [9] <author> A. Louri and H. Sung. </author> <title> "A Compiler Directed Cache Coherence Scheme With Fast and Parallel Explicit Invalidation." </title> <booktitle> In Proc. of the 1992 International Conference on Parallel Processing, </booktitle> <pages> pages 2-9, </pages> <month> Aug </month> <year> 1992. </year>
Reference-contexts: Among the existing software controlled cache coherence schemes, the methods based on the concept of timestamps are more effective in preserving cache lines across task boundaries than other software methods <ref> [4, 9] </ref>. The early timestamp-based methods, such as the version control method [3] and the timestamp method [10], use an explicit timestamp table to store the current version number for each variable. <p> Using this simple serial scheme, the invalidation overhead is O ( P n i=1 (s i )), where s i is the size of the ith section to be invalidated. A faster, but more complex invalidation method was proposed in [8] and <ref> [9] </ref>. This parallel scheme requires a full associated address tag memory. A bit mask is used to determine which addresses to invalidate.
Reference: [10] <author> S. Min and J. Baer. </author> <title> "Design and Analysis of a Scalable Cache Coherence Scheme Based on Clocks and Timestamps." </title> <journal> IEEE Trans. on Parallel and Dist. Systems, </journal> <volume> 3(1) </volume> <pages> 25-44, </pages> <month> Jan. </month> <year> 1992. </year>
Reference-contexts: Among the existing software controlled cache coherence schemes, the methods based on the concept of timestamps are more effective in preserving cache lines across task boundaries than other software methods [4, 9]. The early timestamp-based methods, such as the version control method [3] and the timestamp method <ref> [10] </ref>, use an explicit timestamp table to store the current version number for each variable. They also use an additional field in each cache line to store the version number of the cache line. <p> The cache line is valid only if its BVN is bigger than or equal to the corresponding variable's CVN. The version control method is effective in preserving the reuse of cache lines. The major limitation of this method is the hardware and runtime overhead. The timestamp method <ref> [10] </ref> is not discussed here because it is similar to the version control method. The TS1 Method In TS1, one additional bit, referred to as the epoch bit, is required for each cache line. The compiler determines the levels and the variables modified in each level.
References-found: 10

