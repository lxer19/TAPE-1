URL: http://www.cs.toronto.edu/~greiner/PAPERS/DeltaDelta.ps
Refering-URL: http://www.cs.toronto.edu/~greiner/PAPERS/
Root-URL: 
Email: fgreiner, bharat, gamg@scr.siemens.com  
Title: An Optimized Theory Revision Module  
Author: Russell Greiner, R. Bharat Rao and Glenn Meredith 
Address: Princeton, NJ 08540  
Affiliation: Siemens Corporate Research,  
Abstract: Theory revision systems typically use a set of theory-to-theory transformations f k g to hill-climb from a given initial theory to a new theory whose empirical accuracy, over a given set of labeled training instances fc j g, is a local maximum. At the heart of each such process is an "evaluator", which compares the accuracy of the current theory KB with that of each of its "neighbors" f k (KB)g, with the goal of determining which neighbor has the highest accuracy. The obvious "wrapper" evaluator simply evaluates each individual neighbor theory KB k = k (KB) on each instance c j . As it can be very expensive to evaluate a single theory on a single instance, and there can be a great many training instances and a huge number of neighbors, this approach can be prohibitively slow. We present an alternative system which employs a smarter evaluator that quickly computes the accuracy of a transformed theory k (KB) by "looking inside" KB and reasoning about the effects of the k transformation. We compare the performance of with the naive wrapper system on real-world theories obtained from a fielded expert system, and find that runs over 35 times faster than , while attaining the same accuracy. This paper also discusses 's source of power. Keywords: theory revision, efficient algorithm, hill-climbing system Multiple Submissions: We have submited a related version of this paper to AAAI96. fl We gratefully acknowledge the many helpful comments on this report from George Drastal, Chandra Mouleeswaran and Geoff Towell. 
Abstract-found: 1
Intro-found: 1
Reference: [Coh90] <author> William W. Cohen. </author> <title> Learning from textbook knowledge: A case study. </title> <booktitle> In Proceeding of AAAI-90, </booktitle> <year> 1990. </year>
Reference-contexts: As no efficient algorithm is guaranteed to find the globally-optimal theory (assuming P 6= N P ; see [Gre95]), most theory revision systems are implemented as hill-climbing processes; cf., <ref> [Pol85, MB88, Coh90, OM94, CS90, WP93, LDRG94] </ref>. On each step, these revision systems compute the empirical accuracy, over the given set of examples, of the current theory KB and each of KB's "neighbors", where each neighbor is a slight modification of KB. <p> Related Research There are, of course, other theory revision systems, which also start from an initial domain theory obtained from experts, and iteratively modify that theory to obtain a theory with improved accuracy on a set of training cases; cf., <ref> [Pol85, MB88, Coh90, OM94, WP93, CS90] </ref>. Most of these systems focus on Horn clause knowledge bases or decision trees, which differ from the hypothesis space of fault hierarchies searched by (although fault hierarchies can be translated into these representations).
Reference: [CS90] <author> Susan Craw and Derek Sleeman. </author> <title> Automating the refinement of knowledge-based systems. In L.C. </title> <editor> Aiello, editor, </editor> <booktitle> Proceedings of ECAI 90. </booktitle> <publisher> Pitman, </publisher> <year> 1990. </year>
Reference-contexts: As no efficient algorithm is guaranteed to find the globally-optimal theory (assuming P 6= N P ; see [Gre95]), most theory revision systems are implemented as hill-climbing processes; cf., <ref> [Pol85, MB88, Coh90, OM94, CS90, WP93, LDRG94] </ref>. On each step, these revision systems compute the empirical accuracy, over the given set of examples, of the current theory KB and each of KB's "neighbors", where each neighbor is a slight modification of KB. <p> Related Research There are, of course, other theory revision systems, which also start from an initial domain theory obtained from experts, and iteratively modify that theory to obtain a theory with improved accuracy on a set of training cases; cf., <ref> [Pol85, MB88, Coh90, OM94, WP93, CS90] </ref>. Most of these systems focus on Horn clause knowledge bases or decision trees, which differ from the hypothesis space of fault hierarchies searched by (although fault hierarchies can be translated into these representations).
Reference: [Gre95] <author> Russell Greiner. </author> <title> The complexity of theory revision. </title> <booktitle> In Proceedings of IJCAI-95, </booktitle> <year> 1995. </year>
Reference-contexts: A "theory revision" system uses a set of labeled training examples to modify the incorrect theory, seeking a new theory that is more accurate. As no efficient algorithm is guaranteed to find the globally-optimal theory (assuming P 6= N P ; see <ref> [Gre95] </ref>), most theory revision systems are implemented as hill-climbing processes; cf., [Pol85, MB88, Coh90, OM94, CS90, WP93, LDRG94].
Reference: [GRM95] <author> Russell Greiner, R. Bharat Rao, and Glenn Meredith. </author> <title> An optimized theory revision module. </title> <type> Technical Report SCR-95-TR-538, </type> <institution> Siemens Corporate Research, </institution> <year> 1995. </year>
Reference-contexts: Further, single revisions suggested by the existing systems can radically change the structure of the fault hierarchy (see [LDRG94] for further discussion). This paper, in particular, focuses on the efficiency of our system; the extended tech-report <ref> [GRM95] </ref> discusses how this compares with the efficiency measures used in other revision systems. It also provides a more comprehensive literature survey. 2 Framework 2.1 Theory (Fault Hierarchy) and Instances This subsection first defines the structures of theories ("fault hierarchies") and "problem instances". <p> Stated more precisely, will only consider the subset of the transformations, returned by the RTi Eligible routine, call the set RT I (KB; N ; c j ), which excludes many transformations for which diff 0 ( 0 ; c j ) = 0. (The extended <ref> [GRM95] </ref> presents the actual implementation, which uses the () and t () values, defined below.) Of course, many other theory revision systems use some variant of this basic idea | viz., they too focus on the subset of transformations that appear "relevant" for at least one instance. <p> Instead, it uses the () and t () values to produce the information it needs, directly. The extended <ref> [GRM95] </ref> supplies the many (tedious) details required to specify exactly how to use this information effectively, which basically requires a non-trivial case statement for each of the four types of transformation. <p> As both systems are implemented within the same framework, and share essentially the same overhead code, we attribute the remaining 36:3=32:9 = 1:10 (i.e., 10%) improvement to 's use of its Quick Evaluation process. 9 Finally, the extended <ref> [GRM95] </ref> presents this data in more detail, and also describes how much the various ideas (RT I ,RT P ,RT M and QE) contribute to the overall speedup.
Reference: [JKP94] <author> George H. John, Ron Kohavi, and Karl Pfleger. </author> <title> Irrelevant features and the subset selection problem. </title> <booktitle> In Proceedings of the Eleventh International Machine Learning Conference, </booktitle> <pages> pages 121-129, </pages> <address> N.J., 1994. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Section 3 then focuses on the "evaluator" component of the revision process, which computes the accuracy of each neighbor. It first presents the obvious implementation of such an evaluator which simply evaluates each individual neighboring theory on each instance; this approach resembles the "wrapper" model <ref> [JKP94] </ref>, currently used when evaluating different sets of features in inductive inference tasks. 1 Unfortunately, as it can be very expensive to evaluate a single theory on a single instance, and worse, there can be a great many examples and a huge number of neighbors, this approach is prohibitively slow.
Reference: [LDRG94] <author> Pat Langley, George Drastal, R. Bharat Rao, and Russell Greiner. </author> <title> Theory revision in fault hierarchies. </title> <booktitle> In Proceedings of The Fifth International Workshop on Principles of Diagnosis (DX-94), </booktitle> <address> New Paltz, NY, </address> <year> 1994. </year>
Reference-contexts: As no efficient algorithm is guaranteed to find the globally-optimal theory (assuming P 6= N P ; see [Gre95]), most theory revision systems are implemented as hill-climbing processes; cf., <ref> [Pol85, MB88, Coh90, OM94, CS90, WP93, LDRG94] </ref>. On each step, these revision systems compute the empirical accuracy, over the given set of examples, of the current theory KB and each of KB's "neighbors", where each neighbor is a slight modification of KB. <p> Finally, Section 5 generalizes the specific ideas underlying . Of course, a revision system, even a very efficient one, will only be used if it returns a more accurate theory. The earlier <ref> [LDRG94] </ref> demonstrates that the underlying revision 1 Of course, our theory revision task is significantly different from the feature-selection task for which the Wrapper model was designed. <p> However, the transformations suggested by typically do not correspond to one-step revisions suggested by existing systems. Further, single revisions suggested by the existing systems can radically change the structure of the fault hierarchy (see <ref> [LDRG94] </ref> for further discussion). This paper, in particular, focuses on the efficiency of our system; the extended tech-report [GRM95] discusses how this compares with the efficiency measures used in other revision systems. <p> Here, the revision system will recur, seeking a new KB 00 2 N (KB 0 ) that is better than this KB 0 , and so forth; see <ref> [LDRG94] </ref>.
Reference: [MB88] <author> S. Muggleton and W. Buntine. </author> <title> Machine invention of first order predicates by inverting resolution. </title> <booktitle> In Proceedings of IML-88, </booktitle> <pages> pages 339-51. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1988. </year>
Reference-contexts: As no efficient algorithm is guaranteed to find the globally-optimal theory (assuming P 6= N P ; see [Gre95]), most theory revision systems are implemented as hill-climbing processes; cf., <ref> [Pol85, MB88, Coh90, OM94, CS90, WP93, LDRG94] </ref>. On each step, these revision systems compute the empirical accuracy, over the given set of examples, of the current theory KB and each of KB's "neighbors", where each neighbor is a slight modification of KB. <p> Related Research There are, of course, other theory revision systems, which also start from an initial domain theory obtained from experts, and iteratively modify that theory to obtain a theory with improved accuracy on a set of training cases; cf., <ref> [Pol85, MB88, Coh90, OM94, WP93, CS90] </ref>. Most of these systems focus on Horn clause knowledge bases or decision trees, which differ from the hypothesis space of fault hierarchies searched by (although fault hierarchies can be translated into these representations).
Reference: [OM94] <author> Dirk Ourston and Raymond J. Mooney. </author> <title> Theory refinement combining analytical and empirical methods. </title> <journal> Artificial Intelligence, </journal> <volume> 66(2) </volume> <pages> 273-310, </pages> <year> 1994. </year>
Reference-contexts: As no efficient algorithm is guaranteed to find the globally-optimal theory (assuming P 6= N P ; see [Gre95]), most theory revision systems are implemented as hill-climbing processes; cf., <ref> [Pol85, MB88, Coh90, OM94, CS90, WP93, LDRG94] </ref>. On each step, these revision systems compute the empirical accuracy, over the given set of examples, of the current theory KB and each of KB's "neighbors", where each neighbor is a slight modification of KB. <p> Related Research There are, of course, other theory revision systems, which also start from an initial domain theory obtained from experts, and iteratively modify that theory to obtain a theory with improved accuracy on a set of training cases; cf., <ref> [Pol85, MB88, Coh90, OM94, WP93, CS90] </ref>. Most of these systems focus on Horn clause knowledge bases or decision trees, which differ from the hypothesis space of fault hierarchies searched by (although fault hierarchies can be translated into these representations).
Reference: [Pol85] <author> P.G. Politakis. </author> <title> Empirical Analysis for Expert Systems. </title> <booktitle> Pitman Research Notes in Artificial Intelligence, </booktitle> <year> 1985. </year>
Reference-contexts: As no efficient algorithm is guaranteed to find the globally-optimal theory (assuming P 6= N P ; see [Gre95]), most theory revision systems are implemented as hill-climbing processes; cf., <ref> [Pol85, MB88, Coh90, OM94, CS90, WP93, LDRG94] </ref>. On each step, these revision systems compute the empirical accuracy, over the given set of examples, of the current theory KB and each of KB's "neighbors", where each neighbor is a slight modification of KB. <p> Related Research There are, of course, other theory revision systems, which also start from an initial domain theory obtained from experts, and iteratively modify that theory to obtain a theory with improved accuracy on a set of training cases; cf., <ref> [Pol85, MB88, Coh90, OM94, WP93, CS90] </ref>. Most of these systems focus on Horn clause knowledge bases or decision trees, which differ from the hypothesis space of fault hierarchies searched by (although fault hierarchies can be translated into these representations).
Reference: [WP93] <author> James Wogulis and Michael J. Pazzani. </author> <title> A methodology for evaluating theory revision systems: Results with Audrey II. </title> <booktitle> In Proceedings of IJCAI-93, </booktitle> <pages> pages 1128-1134, </pages> <year> 1993. </year> <month> 13 </month>
Reference-contexts: As no efficient algorithm is guaranteed to find the globally-optimal theory (assuming P 6= N P ; see [Gre95]), most theory revision systems are implemented as hill-climbing processes; cf., <ref> [Pol85, MB88, Coh90, OM94, CS90, WP93, LDRG94] </ref>. On each step, these revision systems compute the empirical accuracy, over the given set of examples, of the current theory KB and each of KB's "neighbors", where each neighbor is a slight modification of KB. <p> Related Research There are, of course, other theory revision systems, which also start from an initial domain theory obtained from experts, and iteratively modify that theory to obtain a theory with improved accuracy on a set of training cases; cf., <ref> [Pol85, MB88, Coh90, OM94, WP93, CS90] </ref>. Most of these systems focus on Horn clause knowledge bases or decision trees, which differ from the hypothesis space of fault hierarchies searched by (although fault hierarchies can be translated into these representations).
References-found: 10

