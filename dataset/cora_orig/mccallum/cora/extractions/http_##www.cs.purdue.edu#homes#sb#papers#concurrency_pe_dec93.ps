URL: http://www.cs.purdue.edu/homes/sb/papers/concurrency_pe_dec93.ps
Refering-URL: http://www.cs.purdue.edu/homes/sb/papers/LIST.html
Root-URL: http://www.cs.purdue.edu
Title: Macromolecular Electron Density Averaging on Distributed Memory MIMD Systems  
Author: Dan C. Marinescu, John R. Rice, Marius A. Cornea-Hasegan Robert E. Lynch Michael G. Rossmann 
Note: Work supported in part by NSF grant 9119388, by grants from NSF and NIH to M.G. Rossmann, and by a Lucille P. Malkey award for the expansion of structural  
Date: January 14, 1994  
Affiliation: Department of Computer Sciences  Departments of Computer Sciences and Mathematics and  Department of Biological Sciences Purdue University  studies at Purdue University.  
Abstract: The paper discusses algorithms and programs for electron density averaging using a distributed memory MIMD system. Electron density averaging is a computationally intensive step needed for phase refinement and extension in the computation of the 3-D structure of macromolecules like proteins and viruses. The determination of a single structure may require thousands of hours of CPU time for traditional supercomputers. The approach discussed in this paper leads to a reduction by one to two orders of magnitude of the computing time. The program runs on an Intel iPSC/860 and on the Touchstone Delta system and uses a user controlled shared virtual memory and a dynamic load balancing mechanism. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Cornea-Hasegan, M.A., D.C. Marinescu, and Z. Zhang, </author> <title> "An analysis of data management schemes for distributed memory MIMD systems", </title> <institution> CSD-TR-92-074, Computer Science Department, Purdue University, </institution> <year> (1992). </year>
Reference-contexts: For the problems of interest the average working set of a brick is between 500 and 1000 bricks <ref> [1] </ref>. 5 Load Balancing In this section, two strategies for load balancing are discussed: a static one and a hybrid one, combining static and dynamic allocation. In the static load balancing approach, the bricks are divided evenly among the P 1 processing elements. <p> In this case the size of the VBA stored in each PE is small and each PE can still dedicate to the RBA enough space to hold the largest brick working set. A new implementation of the electron density averaging is discussed in detail in <ref> [1] </ref>. It uses a different data management scheme by distributing the data space across nodes. This eliminates the I/O bottleneck and makes the problem scalable. A new work allocation policy 31 exploits the iterative nature of this computation. <p> Problem 2 has higher resolution and more grid points than Problem 1. Table 7 goes here. Table 8 gives the execution times for Problem 2, on submeshes of different sizes of the 512 node Intel Touchstone Delta mesh using the new version of the electron density averaging program <ref> [1] </ref>. Table 8 goes here. The speedup for larger numbers of PEs are lower than expected, due to the large overhead for loading the program on hundreds of processors.
Reference: [2] <author> Fox, G., et. al., </author> <title> Solving Problems on Concurrent Processors, </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> (1988). </year>
Reference: [3] <author> Touchstone Delta System, </author> <title> User's Guide, </title> <publisher> Intel, </publisher> <year> 1991. </year> <month> 33 </month>
Reference-contexts: The VBA for the electron density averaging program uses two direct access files, a read-only file for the original data (electron density and the mask for all grid points), and a write-only file for the averaged electron density. The two files are accessed using the Concurrent File System, <ref> [3] </ref>. Each file consists of (N B + 1) records: record 0 is a file descriptor and each subsequent record consists of one brick. The total size of the VBA is 2b fi (N B + 1) bytes.
Reference: [4] <author> Rossmann, M. G., </author> <title> The Molecular Replacement Method, </title> <publisher> Gordon and Breach, </publisher> <year> (1972). </year>
Reference-contexts: In general for such large molecules, the phases of the Fourier coefficients F h;k;` cannot be determined experimentally. But, initial estimates of phases for some low resolution coefficients can be computed approximately from crude models of the macromolecules (see <ref> [4] </ref>). 5 Given the phases and the experimentally observed structure amplitudes, Fast Fourier Trans--forms (FFTs) can be used to obtain an approximate electron density distribution at points of a grid x i;j;k = (x i ; y j ; z k ), 1 i n x , 1 j n y
Reference: [5] <author> Rossmann, M. G., R. McKenna, L. Tong, D. Xia, J-B. Dai, H. Wu, H-K. Choi, and R. E. Lynch, </author> <title> "Molecular replacement real-space averaging", </title> <journal> J. Appl. Cryst. </journal> <volume> 25 (1992), </volume> <pages> 166-180. </pages>
Reference-contexts: The electron density at points in the solvent are flattened, that is, set equal to a constant. A detailed discussion of the averaging is described in <ref> [5] </ref>. Sections 3, 4, and 5 of this paper describe some of the details of our implementation of this process on an MIMD system. We outline subsequent procedures, which we also intend to implement on an MIMD system.

References-found: 5

