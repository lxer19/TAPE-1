URL: ftp://cse.ogi.edu/pub/tech-reports/1994/94-014.ps.gz
Refering-URL: ftp://cse.ogi.edu/pub/tech-reports/README.html
Root-URL: http://www.cse.ogi.edu
Email: -casas,konuru,otto,prouty,walpole-@cse.ogi.edu  email: otto@cse.ogi.edu,  
Phone: Phone: 503-690-1486, FAX: 503-690-1553  
Title: Adaptive Load Migration Systems for PVM 1 of 23 Adaptive Load Migration Systems for PVM  
Author: Jeremy Casas, Ravi Konuru, Steve W. Otto, Robert Prouty, Jonathan Walpole Steve W. Otto 
Note: Presenting Author:  
Date: March 1994  
Address: Box 91000 Portland, Oregon 97291-1000 USA  
Affiliation: Department of Computer Science and Engineering Oregon Graduate Institute of Science Technology  
Abstract: Adaptive load distribution is necessary for parallel applications to coexist effectively with other jobs in a network of shared heterogeneous workstations. We present three methods that provide such support for PVM applications. Two of these methods, MPVM and UPVM, adapt to changes in the workstation environment by transparently migrating the virtual processors (VPs) of the parallel application. A VP in MPVM is a Unix pr ocess, while UPVM defines light-weight, process-like VPs. The third method, ADM, is a programming methodology for writing programs that perform adaptive load distribution through data movement. These methods are discussed and compared in terms of effectiveness, usability, and performance. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Adam Beguelin, Jack Dongarra, Al Geist, Robert Manchek, and Vaidy Sunderam, </author> <title> Heterogeneous Network Computing, </title> <booktitle> Proceedings of the Sixth SIAM Conference on Parallel Processing, </booktitle> <year> 1993. </year>
Reference: [2] <author> Jack Dongarra, Al Geist, Robert Manchek, and Vaidy Sunderam, </author> <title> Integrated PVM Framework Supports Heterogeneous Network Computing, </title> <booktitle> Computers in Physics, </booktitle> <month> April </month> <year> 1993, </year> <pages> pp. 166-75. </pages>
Reference: [3] <author> Adam Beguelin, Jack Dongarra, Al Geist, Robert Manchek, Steve W. Otto, and Jonathan Walpole, </author> <title> PVM: Experiences, Current Status and Future Directions, </title> <booktitle> in proceedings, Supercomputing 93, </booktitle> <publisher> IEEE Computer Society Press, Los Alamitos, CA, </publisher> <pages> pages 765-6, </pages> <month> November </month> <year> 1993. </year>
Reference-contexts: The GS is also responsible for initiat Adaptive Load Migration Systems for PVM 4 of 23 ing a migration by signalling the pvmds. The global schedular is part of the lar ger, Concurrent Processing Environment (CPE), which is an ongoing research effort <ref> [3] </ref>. 2.1 MPVM MPVM is an extension of PVM to support transparent migration of process-based VPs. Migrating a process of a parallel application involves capturing the current execution state and transferring this state to another host.
Reference: [4] <author> Michael K. Litzkow, Miron Livny, and Matt W. </author> <title> Mutka, Condor - A Hunter of Idle W orksta-tions, </title> <booktitle> Proceedings of the 8th IEEE International Conference on Distributed Computing Systems, </booktitle> <pages> pp. 104-11, </pages> <address> San Jose, CA, </address> <month> June </month> <year> 1988. </year>
Reference-contexts: The main advantage of such a system is that it allows the computing power of widely available, general-purpose workstations networks (worknets) to be harnessed for parallel processing. Because these worknets are idle or partially idle much of the time <ref> [4] </ref>, they are an attractive source of effectively free processing power. Shared, general-purpose worknets have certain key characteristics that af fect execution of parallel applications. First, sharing implies that the load on individual processors and the network varies dynamically. This unpredictable variability can drastically degrade parallel application performance.
Reference: [5] <author> Ravi Konuru, Jeremy Casas, Steve W. Otto, Robert Prouty, and Jonathan Walpole, </author> <title> A User-Level Process Package for PVM, </title> <booktitle> to appear in proceedings, 1994 Scalable High-Performance Computing Conference, </booktitle> <address> Knoxville, TN, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: Migration events are initiated and controlled by a global scheduler that is external to the application. The second system, UPVM, is a virtual processor (VP) package that supports multi-threading and transparent migration for PVM applications <ref> [5] </ref>. The virtual processors are called User Level Processes (ULPs) and can be thought of as lightweight, Unix-like processes that are independently migratable. UPVM also supports a source-code compatible PVM interface often requiring no modif ication to the application source. <p> Questions concerning heterogeneity, implementation and portability of the package, and transparency to parallel applications are addressed later, in Section 3.0. Some performance figures are given in Section 4.0. 2.2 UPVM UPVM is a package that supports multi-threading and transparent migration for PVM applications <ref> [5] </ref>. Though the MPVM package gives a transparent migration capability , UPVM provides a set of smaller entities than processes to migrate, allowing load redistribution at a finer granularity. <p> In addition, UPVM adds extra information for remote messages that results in mar ginally slower remote communication than MPVM. However, if an application is divided into more than one VP per node, an application will run faster since UPVM optimizes local communication <ref> [5] </ref>. Table 3. PVM vs. UPVM, showing the effect of any possible overhead during normal (no migration) execution. Table 3 shows the results for SPMD_opt.
Reference: [6] <author> Robert Prouty, Steve W. Otto, and Jonathan Walpole, </author> <title> Adaptive Execution of Data Parallel Computations on Networks of Heterogeneous Workstations, </title> <type> Technical Report CSE-94-012, </type> <institution> Dept. of Computer Science, Oregon Graduate Institute of Science & Technology, </institution> <year> 1994. </year> <title> Adaptive Load Migration Systems for PVM 23 of 23 </title>
Reference-contexts: The virtual processors are called User Level Processes (ULPs) and can be thought of as lightweight, Unix-like processes that are independently migratable. UPVM also supports a source-code compatible PVM interface often requiring no modif ication to the application source. Finally, Adaptive Data Movement (ADM) <ref> [6] </ref> is an application-level methodology that provides programmers with an infrastructure for developing adaptive computations based on work redistribution. Unlike MPVM and UPVM that support work distribution by migrating VPs, ADM provides work distribution through data movement by the application. The rest of this paper is organized as follows.
Reference: [7] <author> Michael Litzkow and Marvin Solomon, </author> <title> Supporting Checkpointing and Process Migration Outside the Unix Kernel, </title> <booktitle> Usenix Winter 1992 Technical Conference, </booktitle> <pages> pp. 283-90, </pages> <month> January </month> <year> 1992. </year>
Reference-contexts: The implementation tries to be machine-independent. The migration mechanism, however , is somewhat machine and operating system dependent. We have attempted to limit the dependence on the OS by using generic features found in most versions of Unix <ref> [7] </ref>. As long as a process can take a snapshot of its register context and determine the extents of its writable data, heap, and stack space at runtime, porting is not dif ficult.
Reference: [8] <author> Etienne Barnard and Ronald Cole, </author> <title> A Neural-net Training Program Based on Conjugate Gradient Optimization, </title> <type> Technical Report CSE-89-014, </type> <institution> Oregon Graduate Institute of Science & T echnol-ogy, </institution> <year> 1989. </year>
Reference-contexts: Since these measures are application dependent, we apply the three methods to Opt, a neural-network classifying application based on conjugate-gradient optimization <ref> [8] </ref>. Opt is generally employed as a speech classifier utilizing large (500KB to 400MB) training sets as input. A training set consists of a series of oating point vectors. These vectors, called exemplars, represent digitized speech sound.
Reference: [9] <author> Allan Bricker, Michael Litzkow, and Miron Livny, </author> <type> Condor Technical Summary, </type> <institution> Computer Sciences Department, University of Wisconsin - Madison, </institution> <month> October 91. </month>
Reference: [10] <author> Nenad Nedeljkovic and Michael J. Quinn, </author> <title> Data-Parallel Programming on a Network of Heterogeneous Workstations, </title> <journal> Concurrency: Practice and Experience , volume 5(4), </journal> <pages> pages 257-268, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: Data Parallel C (DPC) is a parallel programming environment <ref> [10] </ref> composed of a compiler and run-time that export a SIMD, shared-address-space model operated upon by a user specified number of VPs. The number of VPs is usually much lar ger than the number of processors. The multi-computer DPC compiler TABLE 6.
Reference: [11] <author> N. Carriero, D. Galernter, D. Kaminsky, and J. Westbrook, </author> <title> Adaptive Parallelism with Piranha, </title> <note> available via anonymous ftp from dept-gw.cs.yale.edu as pub/piranha.ps.Z </note> . 
Reference-contexts: Specifically, VP migration is possible only at the beginning or end of code segments that emulate a single VP. Piranha <ref> [11] </ref> is a system for adaptive parallel programming implemented on top of Linda. Piranha is very similar to ADM in that the application programmer structures the program in a certain way and writes certain functions that allow the application to adapt to a dynamic environment.
Reference: [12] <author> The Message-Passing Interface Forum, </author> <title> Document for a Standard Message-Passing Interface, </title> <institution> University of Tennessee Computer Science technical report, CS-93-214, </institution> <month> November, </month> <year> 1993. </year>
Reference: [13] <author> The Message-Passing Interface Forum, </author> <title> MPI: A Message-Passing Interface, </title> <booktitle> in proceedings, Supercomputing 93, </booktitle> <publisher> IEEE Computer Society Press, Los Alamitos, CA, </publisher> <pages> pp. 878-83. </pages>
References-found: 13

