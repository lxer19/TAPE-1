URL: ftp://ftp.nj.nec.com/pub/giles/papers/AAAI-97.intelligent.file.organization.ps.Z
Refering-URL: http://www.ph.tn.tudelft.nl/PRInfo/reports/msg00337.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: kuvayev@cs.umass.edu  fgiles,philbin,henryg@research.nj.nec.com  
Title: Intelligent Methods for File System Optimization  
Author: Leo Kuvayev C. L. Giles and J. Philbin and H. Cejtin 
Address: Amherst, MA 01002  4 Independence Way Princeton, NJ 08540  
Affiliation: Department of Computer Science University of Massachusetts  NEC Research Institute  
Abstract: The speed of I/O components is a major limitation of the speed of all other major components in today's computer systems. Motivated by this, we investigated several algorithms for efficient and intelligent organization of files on a hard disk. Total access time may be decreased if files with temporal locality also have spatial locality. Three intelligent methods based on file type, frequency, and transition probabilities information showed up to 60% savings of total I/O time over the naive placement of files. More computation-ally intensive hill climbing and genetic algorithms approaches did not outperform statistical methods. The experiments were run on a real and simulated hard drive in single and multiple user environments. 
Abstract-found: 1
Intro-found: 1
Reference: <author> English, R., and Stepanov, A. </author> <year> 1992. </year> <title> Loge: a self-organizing disk controller. </title> <booktitle> In USENIX Winter, </booktitle> <pages> 238-252. </pages>
Reference-contexts: The history of cache hits and misses for each file was used to calculate the optimal prefetch amount. (Rosenblum & Ousterhout 1991) argued that files tend to be read in the same patterns that they are written and proposed to write data sequentially on disk. Other work by <ref> (English & Stepanov 1992) </ref> investigated several heuristics for dynamical placement of file blocks. Our work is focused instead on global reshu*ing of file system that reduces access time for reading. Another approach for optimizing file systems includes (Tuel 1978) where the optimal reorganization intervals for linearly growing files is discussed.
Reference: <author> Ganger, G.; Worthington, B.; Hou, R.; and Patt, Y. </author> <year> 1993. </year> <title> Disk subsystem load balancing: disk stripping vs. conventional data placement. </title> <booktitle> In IEEE. </booktitle>
Reference-contexts: Our work is focused instead on global reshu*ing of file system that reduces access time for reading. Another approach for optimizing file systems includes (Tuel 1978) where the optimal reorganization intervals for linearly growing files is discussed. Disk striping, proposed in <ref> (Ganger et al. 1993) </ref>, uniformly spreads data sets across the disks in the subsystem and essentially randomizes the disk accessed by each request. This randomization effectively handles both fixed and floating load imbalance. More details on ways to optimize a file system can be found in (Kuvayev et al. 1996).
Reference: <author> Holland, J. </author> <year> 1975. </year> <title> Adaptation in Natural and Artificial Systems. </title> <publisher> University of Michigan Press. </publisher>
Reference-contexts: The average seek time per access is the value returned by an evaluation function. Hill climbing algorithm is a common search method. The orderings are altered slightly and evaluated on the training traces. The best ordering improves gradually over time. Genetic algorithms is another popular search method <ref> (Holland 1975) </ref>. The idea is to mimic the nature's laws of evolution and natural selection. Initially there is a population of 300 random file orderings. All of them are tested on the historical traces and sorted in the ascending seek time order.
Reference: <author> Horne, B.; Giles, C.; and Philbin, J. </author> <year> 1996. </year> <title> A method for optimizing file system organization. </title> <type> Technical report, </type> <institution> NECI, Princeton, NJ. </institution>
Reference-contexts: If we know the transition probabilities among the file accesses the optimal solution could be found in O (n!) time by looking at all possible file placements F. This solution is infeasible for typical file systems. <ref> (Horne, Giles, & Philbin 1996) </ref> propose to place files one by one at locally optimal locations. Such locations are determined by evaluating a cost function, which mea-sures the expected amount of head movement. This approach uses previous history to predict the transition probabilities of file accesses.
Reference: <author> Kuvayev, L.; Giles, C.; Philbin, J.; and Cejtin, H. </author> <year> 1996. </year> <title> The impact of intelligent methods on file system optimization. </title> <type> Technical report, </type> <institution> NECI, Princeton, NJ. </institution>
Reference-contexts: This randomization effectively handles both fixed and floating load imbalance. More details on ways to optimize a file system can be found in <ref> (Kuvayev et al. 1996) </ref>. Various Placement Strategies There are many possible file placement strategies. In this study, we experimented with five of them. We call them naive, contiguous, type based, frequency based, and markovian placements. Their pictorial representation is shown in Figure 1. Naive Placement.
Reference: <author> Madhyastha, T. </author> <year> 1996. </year> <title> Intelligent, adaptive file system policies. </title> <booktitle> Frontiers of Massively Parallel Computation. </booktitle>
Reference-contexts: The work by (McKusick et al. 1984) proposes to partition a disk into cylinder groups consisting of several consecutive cylinders. The files that are frequently accessed together, e.g. inodes of the files in the same directory, are stored in the same cylinder group. <ref> (Madhyastha 1996) </ref> devised a trained learning mechanism to recognize access patterns and automatically select appropriate caching strategies. The pattern classification was performed by neural networks. (Shih, Lee, & Ong 1990) presented algorithms for an adaptive prefetch design. They are based on the observed sequentialities of files during program execution.
Reference: <author> McKusick, M.; Joy, W.; Le*er, S.; and Fabry, R. </author> <year> 1984. </year> <title> A fast file system for unix. </title> <journal> ACM Transactions on Computer Systems 2(3) </journal> <pages> 181-197. </pages>
Reference-contexts: We propose several strategies that can be implemented in linear time. Related Work Problems with file system performance have been dealt with extensively in the literature, see (Smith 1981) for a survey. The work by <ref> (McKusick et al. 1984) </ref> proposes to partition a disk into cylinder groups consisting of several consecutive cylinders.
Reference: <author> Rosenblum, M., and Ousterhout, J. </author> <year> 1991. </year> <title> The design and implementation of a log-structured file system. </title> <booktitle> In Proceedings of 13th ACM Symposium on Operating Systems Principles, </booktitle> <pages> 1-15. </pages>
Reference-contexts: They are based on the observed sequentialities of files during program execution. The history of cache hits and misses for each file was used to calculate the optimal prefetch amount. <ref> (Rosenblum & Ousterhout 1991) </ref> argued that files tend to be read in the same patterns that they are written and proposed to write data sequentially on disk. Other work by (English & Stepanov 1992) investigated several heuristics for dynamical placement of file blocks.
Reference: <author> Shih, F.; Lee, T.-C.; and Ong, S. </author> <year> 1990. </year> <title> A file-based adaptive prefetch caching design. </title> <booktitle> In IEEE. </booktitle>
Reference-contexts: The files that are frequently accessed together, e.g. inodes of the files in the same directory, are stored in the same cylinder group. (Madhyastha 1996) devised a trained learning mechanism to recognize access patterns and automatically select appropriate caching strategies. The pattern classification was performed by neural networks. <ref> (Shih, Lee, & Ong 1990) </ref> presented algorithms for an adaptive prefetch design. They are based on the observed sequentialities of files during program execution.
Reference: <author> Smith, A. </author> <year> 1981. </year> <title> Input/output optimization and disk architectures: A survey. Perform. </title> <journal> Eval. </journal> <volume> 1 </volume> <pages> 104-117. </pages>
Reference-contexts: However, for a large file system with many thousands of files even the quadratic solution is prohibitively expensive. We propose several strategies that can be implemented in linear time. Related Work Problems with file system performance have been dealt with extensively in the literature, see <ref> (Smith 1981) </ref> for a survey. The work by (McKusick et al. 1984) proposes to partition a disk into cylinder groups consisting of several consecutive cylinders.
Reference: <author> Tuel, W. </author> <year> 1978. </year> <title> Optimum reorganization points for linearly growing files. </title> <journal> ACM Transactions on Database Systems 3(1) </journal> <pages> 32-40. </pages>
Reference-contexts: Other work by (English & Stepanov 1992) investigated several heuristics for dynamical placement of file blocks. Our work is focused instead on global reshu*ing of file system that reduces access time for reading. Another approach for optimizing file systems includes <ref> (Tuel 1978) </ref> where the optimal reorganization intervals for linearly growing files is discussed. Disk striping, proposed in (Ganger et al. 1993), uniformly spreads data sets across the disks in the subsystem and essentially randomizes the disk accessed by each request. This randomization effectively handles both fixed and floating load imbalance.
References-found: 11

