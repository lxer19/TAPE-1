URL: ftp://ftp.eecs.umich.edu/people/fessler/ps/tr-286-sage-1-31.ps.Z
Refering-URL: http://www.eecs.umich.edu/systems/TechReportList.html
Root-URL: http://www.eecs.umich.edu
Title: SPACE-ALTERNATING GENERALIZED EM ALGORITHMS FOR PENALIZED MAXIMUM-LIKELIHOOD IMAGE RECONSTRUCTION  Approved for public release; distribution unlimited  
Author: Jeffrey A. Fessler and Alfred O. Hero and 
Date: February 1994  286  
Address: Ann Arbor, MI 48109-2122  Ann Arbor, MI 48109-2122  
Affiliation: COMMUNICATIONS SIGNAL PROCESSING LABORATORY Department of Electrical Engineering and Computer Science The University of Michigan  Division of Nuclear Medicine Department of Internal Medicine The University of Michigan  
Pubnum: Technical Report No.  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> L A Shepp and Y Vardi. </author> <title> Maximum likelihood reconstruction for emission tomography. </title> <journal> IEEE Transactions on Medical Imaging, </journal> <volume> 1(2) </volume> <pages> 113-122, </pages> <month> October </month> <year> 1982. </year>
Reference-contexts: 1 This work was supported in part by DOE Grant DE-FG02-87ER60561, NSF grant BCS-9024370 and NIH grants CA-54362-02 and CA-60711-01. I. INTRODUCTION Imaging techniques with Poisson measurement statistics include: positron emission tomography (PET) <ref> [1] </ref>, single photon emission computed tomography (SPECT), gamma astronomy, various microscopy methods [2, 3], and photon-limited optical imaging [4]. <p> In particular, the sequential update of our SAGE algorithms allows us to use small hidden-data spaces that are considerably less informative than the ordinary complete-data space for image reconstruction, which leads to fast monotonic convergence. Images reconstructed purely by using the maximum likelihood criterion <ref> [1, 17] </ref> have been found to be unacceptably noisy. A variety of methods have been proposed to reduce this noise, usually with some concordant resolution tradeoff. <p> MAXIMUM LIKELIHOOD In this section we first review the linear Poisson model that is often used in image reconstruction problems, and summarize the classical EM algorithm (ML-EM-1) for maximizing the likelihood <ref> [1, 17] </ref>. We then introduce a new complete-data space that leads to a new, faster converging EM algorithm: ML-EM-3. Even less informative hidden-data spaces lead to new SAGE algorithms that converge faster than both ML-EM-3 and the line-search accelerated EM algorithm (ML-LINU) [58].
Reference: [2] <author> S Joshi and M I Miller. </author> <title> Maximum a posteriori estimation with good's roughness for three-dimensional optical-sectioning microscopy. </title> <journal> J. Optical Society Amer. Ser. A, </journal> <volume> 10(5) </volume> <pages> 1078-1085, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: 1 This work was supported in part by DOE Grant DE-FG02-87ER60561, NSF grant BCS-9024370 and NIH grants CA-54362-02 and CA-60711-01. I. INTRODUCTION Imaging techniques with Poisson measurement statistics include: positron emission tomography (PET) [1], single photon emission computed tomography (SPECT), gamma astronomy, various microscopy methods <ref> [2, 3] </ref>, and photon-limited optical imaging [4]. Statistical methods for image reconstruction or restoration, such as maximum likelihood (ML), penalized maximum-likelihood (PML), or maximum a posteriori (MAP), are computationally challenging due to the transcendental form of the Poisson log-likelihood.
Reference: [3] <author> T J Holmes. </author> <title> Blind deconvolution of quantum-limited incoherent imagery: maximum-likelihood approach. </title> <journal> J. Optical Society Amer. Ser. A, </journal> <volume> 9(7) </volume> <pages> 1052-1061, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: 1 This work was supported in part by DOE Grant DE-FG02-87ER60561, NSF grant BCS-9024370 and NIH grants CA-54362-02 and CA-60711-01. I. INTRODUCTION Imaging techniques with Poisson measurement statistics include: positron emission tomography (PET) [1], single photon emission computed tomography (SPECT), gamma astronomy, various microscopy methods <ref> [2, 3] </ref>, and photon-limited optical imaging [4]. Statistical methods for image reconstruction or restoration, such as maximum likelihood (ML), penalized maximum-likelihood (PML), or maximum a posteriori (MAP), are computationally challenging due to the transcendental form of the Poisson log-likelihood.
Reference: [4] <author> D L Snyder, A M Hammoud, and R L White. </author> <title> Image recovery from data acquired with a charge-couple-device camera. </title> <journal> J. Optical Society Amer. Ser. A, </journal> <volume> 10(5) </volume> <pages> 1014-1023, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: I. INTRODUCTION Imaging techniques with Poisson measurement statistics include: positron emission tomography (PET) [1], single photon emission computed tomography (SPECT), gamma astronomy, various microscopy methods [2, 3], and photon-limited optical imaging <ref> [4] </ref>. Statistical methods for image reconstruction or restoration, such as maximum likelihood (ML), penalized maximum-likelihood (PML), or maximum a posteriori (MAP), are computationally challenging due to the transcendental form of the Poisson log-likelihood.
Reference: [5] <author> A P Dempster, N M Laird, and D B Rubin. </author> <title> Maximum likelihood from incomplete data via the EM algorithm. </title> <journal> Journal of the Royal Statistical Society Series B, </journal> <volume> 39(1) </volume> <pages> 1-38, </pages> <year> 1977. </year>
Reference-contexts: The difficulty is exacerbated when one includes smoothness penalties or priors, since these functionals further couple the parameters. EM algorithms <ref> [5] </ref> have proven to be somewhat useful in such problems, except for two important drawbacks. The first problem is convergence rate: EM algorithms converge slowly, particularly when one includes the additive effects of "background" events such as random coincidences [6], scatter [7, 8], dark-current [9], or background cosmic radiation. <p> The second problem is that the M-step of the EM algorithm becomes intractable when one includes smoothness penalties in the objective function. Since image reconstruction is ill-posed, such penalties are often very desirable. Unlike the statistical applications that motivated the development of the EM algorithm <ref> [5] </ref>, there is usually no "missing data" in image reconstruction problems. Here the EM algorithm serves primarily as a computational tool that replaces one difficult maximization problem with a recursion of easier maximizations. <p> A sequential update eliminates the coupling problem introduced by smoothness penalties. Sauer and Bouman [10] have explained the rapid convergence of certain sequential updates using a novel frequency domain analysis. Although Dempster et al. <ref> [5] </ref> showed that the convergence rates of EM algorithms are related to the Fisher information matrices of their complete-data spaces, this property does not appear to have been widely appreciated or exploited. We have previously shown that reducing Fisher information can lead to remarkable improvements in convergence rates [11-16]. <p> Rather than requiring a strict maximization in (3), one could settle simply for local maxima [16], or for mere increases in OE i , in analogy with GEM algorithms <ref> [5] </ref>. These generalizations provide the opportunity to further refine the tradeoff between convergence rate and computation per-iteration. C. Convergence Properties It follows from (2) and (3) that the sequence of estimates f i g generated by any SAGE algorithm will monotonically increase the objective ( i ). <p> kj ( i k A k =2] k + m k ): k = B k + B 2 A k # : (40) Strictly speaking, this method is actually a type of GEM algorithm since maximizing OE ffi does not yield the maximum of OE 3 (; i ) <ref> [5] </ref>. We have found empirically and theoretically [16] that PML-DePierro-3 converges slightly slower than PML-GEM-3 on a serial computer. Indeed, one can compare (40) with (39) to see that PML-DePierro-3 takes slightly smaller steps than PML-GEM-3.
Reference: [6] <author> D G Politte and D L Snyder. </author> <title> Corrections for accidental coincidences and attenuation in maximum-likelihood image reconstruction for positron-emission tomography. </title> <journal> IEEE Transactions on Medical Imaging, </journal> <volume> 10(1) </volume> <pages> 82-89, </pages> <month> March </month> <year> 1991. </year>
Reference-contexts: EM algorithms [5] have proven to be somewhat useful in such problems, except for two important drawbacks. The first problem is convergence rate: EM algorithms converge slowly, particularly when one includes the additive effects of "background" events such as random coincidences <ref> [6] </ref>, scatter [7, 8], dark-current [9], or background cosmic radiation. The second problem is that the M-step of the EM algorithm becomes intractable when one includes smoothness penalties in the objective function. Since image reconstruction is ill-posed, such penalties are often very desirable. <p> The Fisher in formation of the parameter vector for the observed data Y evaluated at the ML estimate ^ is F Y ( ^ ) = Efr 2 fi fi 2 ML-EM-1 is essentially the ML-IB algorithm of <ref> [6] </ref>. The ML-IA algorithm of [6] has a more informative complete-data space and slower convergence [12]. = A 0 diag n o 1 whereas the Fisher information for X 1 is diagonal: F X 1 ( ^ ) = diag n o (provided ^ is positive.) One can show that F <p> The Fisher in formation of the parameter vector for the observed data Y evaluated at the ML estimate ^ is F Y ( ^ ) = Efr 2 fi fi 2 ML-EM-1 is essentially the ML-IB algorithm of <ref> [6] </ref>. The ML-IA algorithm of [6] has a more informative complete-data space and slower convergence [12]. = A 0 diag n o 1 whereas the Fisher information for X 1 is diagonal: F X 1 ( ^ ) = diag n o (provided ^ is positive.) One can show that F X 1 &gt; F Y
Reference: [7] <author> M E Daube-Witherspoon, R E Carson, Y Yan, and T K Yap. </author> <title> Scatter correction in maximum likelihood reconstruction of PET data. </title> <booktitle> In Conf. Record of the IEEE Nuclear Science Symposium and Medical Imaging Conference, </booktitle> <year> 1992. </year>
Reference-contexts: EM algorithms [5] have proven to be somewhat useful in such problems, except for two important drawbacks. The first problem is convergence rate: EM algorithms converge slowly, particularly when one includes the additive effects of "background" events such as random coincidences [6], scatter <ref> [7, 8] </ref>, dark-current [9], or background cosmic radiation. The second problem is that the M-step of the EM algorithm becomes intractable when one includes smoothness penalties in the objective function. Since image reconstruction is ill-posed, such penalties are often very desirable.
Reference: [8] <author> J E Bowsher, D R Gilland, C E Floyd, R J Jaszczak, V E Johnson, and R E Coleman. </author> <title> Three-dimensional iterative reconstruction for SPECT. Journal of Nuclear Medicine (Abstract Book), </title> <address> 33(5):879, </address> <year> 1992. </year>
Reference-contexts: EM algorithms [5] have proven to be somewhat useful in such problems, except for two important drawbacks. The first problem is convergence rate: EM algorithms converge slowly, particularly when one includes the additive effects of "background" events such as random coincidences [6], scatter <ref> [7, 8] </ref>, dark-current [9], or background cosmic radiation. The second problem is that the M-step of the EM algorithm becomes intractable when one includes smoothness penalties in the objective function. Since image reconstruction is ill-posed, such penalties are often very desirable.
Reference: [9] <author> R Molina and B D Ripley. </author> <title> Deconvolution in optical astronomy. A Bayesian approach. In P Barone, </title>
Reference-contexts: EM algorithms [5] have proven to be somewhat useful in such problems, except for two important drawbacks. The first problem is convergence rate: EM algorithms converge slowly, particularly when one includes the additive effects of "background" events such as random coincidences [6], scatter [7, 8], dark-current <ref> [9] </ref>, or background cosmic radiation. The second problem is that the M-step of the EM algorithm becomes intractable when one includes smoothness penalties in the objective function. Since image reconstruction is ill-posed, such penalties are often very desirable.
References-found: 9

