URL: http://www.math.macalester.edu/~fox/cs88/papers/intell.ps
Refering-URL: http://www.math.macalester.edu/~fox/cs88/readings.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: etzioni@cs.washington.edu  
Phone: (206) 685-3035  
Title: Intelligence without Robots (A Reply to Brooks)  
Author: Oren Etzioni 
Date: December 18, 1994  
Note: Appears in AI Magazine, Dec. '93.  
Address: Seattle, WA 98195  
Affiliation: Department of Computer Science and Engineering University of Washington  
Abstract: out Reason," Brooks argues for studying complete agents in real-world environments and for mobile robots as the foundation for AI research. This article argues that, even if we seek to investigate complete agents in real-world environments, robotics is neither necessary nor sufficient as a basis for AI research. The article proposes real-world software environments, such as operating systems or databases, as a complementary substrate for intelligent-agents research, and considers the relative advantages of software environments as testbeds for AI. First, the cost, effort, and expertise necessary to develop and systematically experiment with software artifacts are relatively low. Second, software environments circumvent many thorny, but peripheral, research issues that are inescapable in physical environments. Brooks's mobile robots tug AI towards a bottom-up focus in which the mechanics of perception and mobility mingle inextricably with, or even supersede, core AI research. In contrast, the softbots (software robots) we are advocating facilitate the study of classical AI problems in real-world (albeit, software) domains. For example, our UNIX 1 softbot has led us to investigate planning with incomplete information, interleaving planning and execution, and a host of related high-level issues. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P. Agre and D. Chapman. </author> <title> What are Plans for? In Designing Autonomous Agents, </title> <address> pages 17-34. MIT/Elsevier, </address> <year> 1990. </year> <month> 8 </month>
Reference-contexts: Similarly, an agent satisfies the goal on (a,b) by updating its internal model to include the effects of executing the action stack (a,b), not by interacting with the external world. This "practice of allowing primitive actions to traffic in constant symbols" hides an important problem <ref> [1] </ref>. Since physical entities do not have tags associated with them, saying "I correspond to internal symbol a," an agent operating in the physical world has to develop methods that reliably map from perceptual experiences in the world to internal representations and conversely.
Reference: [2] <author> Y. Arens, C. Y. Chee, C.-N. Hsu, and C. A. Knoblock. </author> <title> Retrieving and integrating data from multiple information sources. </title> <journal> International Journal on Intelligent and Cooperative Information Systems, </journal> <note> 1993. In press. </note>
Reference-contexts: The article proposes real-world software environments, such as operating systems or databases, as a substrate for intelligent-agents research. Over the years, software environments have been explored as domains for machine learning [5, 6], intelligent user interfaces [21], planning <ref> [2] </ref>, distributed AI [17, 19], and more. We argue for a unified conception: complete, intelligent agents that interact with real-world software environments by issuing commands and interpreting the environments' feedback.
Reference: [3] <author> R. A. Brooks. </author> <title> Intelligence without reason. </title> <booktitle> In Proceedings of the Twelveth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 569-595, </pages> <address> Sam Mateo, California, 1991. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Introduction In his recent papers, entitled "Intelligence without Representation" [4] and "Intelligence without Reason" <ref> [3] </ref>, Brooks propounds a number of positions including: * Complete agents in real-world environments: "At each step we should build complete intelligent systems that we let loose in the real world with real sensing and real action" [4, page 140]. * Robotics as the foundation for AI: "The agents should be <p> world with real sensing and real action" [4, page 140]. * Robotics as the foundation for AI: "The agents should be embodied as mobile robots: : : the new approach can be extended to cover the whole story, both with regards to building intelligent systems and to understanding human intelligence." <ref> [3, page 585] </ref>. This article argues that, even if we accept Brooks's first position and seek to build complete agents in real-world environments, we need not accept robotics as the foundation for AI. Clearly, robotics is an important and challenging enterprise, with much to contribute to AI. <p> However, the article challenges Brooks's position that the primary path to progress in AI is "to study intelligence from the bottom up, concentrating on physical systems (e.g., mobile robots), situated in the world, autonomously carrying out tasks of various sorts" <ref> [3, page 569] </ref>. The article proposes real-world software environments, such as operating systems or databases, as a substrate for intelligent-agents research. Over the years, software environments have been explored as domains for machine learning [5, 6], intelligent user interfaces [21], planning [2], distributed AI [17, 19], and more. <p> In short, softbots satisfy every facet of Brooks's engineering methodology. 2 Symbol Grounding Argument Brooks claims that "only through a physical grounding can any internal symbolic or other system find a place to bottom out, and give `meaning' to the processing going on within the system" <ref> [3, page 584] </ref>. Standard semantic accounts of representational languages define `meaning' and `truth' in terms of an underlying model or logical interpretation. But what do the symbols in the underlying model mean? Brooks argues that only the physical world can ground an agent's internal representation. <p> For instance, Brooks describes how Shakey, SRI's mobile robot, operated in rooms where "the walls were of a uniform color, and carefully lighted, with dark rubber baseboards, making clear boundaries with the lighter colored floor : : : " <ref> [3] </ref>. More recent AI robots operate in more realistic environments, but are restricted to simple tasks such as avoiding walls and fetching soda cans. <p> Brooks acknowledges the frustrations and pragmatic difficulties attendant on AI research utilizing mobile robotic agents. The mean time between failures, for one of his robots, was as short as fifteen minutes <ref> [3, page 587] </ref>. <p> Second, rebooting a workstation and restoring a softbot "from disk" is much easier than fixing a broken gripper in a physical 2 Note that, in contrast to Brooks <ref> [3, page 578] </ref>, we believe that classical approaches (e.g., current work on knowledge representation and on planning) still have much to contribute to AI. 5 robot or identifying and replacing a malfunctioning chip.
Reference: [4] <author> R. A. Brooks. </author> <title> Intelligence without representation. </title> <journal> Artificial Intelligence, </journal> <volume> 47 </volume> <pages> 139-160, </pages> <year> 1991. </year>
Reference-contexts: Introduction In his recent papers, entitled "Intelligence without Representation" <ref> [4] </ref> and "Intelligence without Reason" [3], Brooks propounds a number of positions including: * Complete agents in real-world environments: "At each step we should build complete intelligent systems that we let loose in the real world with real sensing and real action" [4, page 140]. * Robotics as the foundation for <p> In his recent papers, entitled "Intelligence without Representation" [4] and "Intelligence without Reason" [3], Brooks propounds a number of positions including: * Complete agents in real-world environments: "At each step we should build complete intelligent systems that we let loose in the real world with real sensing and real action" <ref> [4, page 140] </ref>. * Robotics as the foundation for AI: "The agents should be embodied as mobile robots: : : the new approach can be extended to cover the whole story, both with regards to building intelligent systems and to understanding human intelligence." [3, page 585]. <p> Engineering Methodology Argument Brooks writes, ": : : I, and others, believe that human level intelligence is too complex and little understood to be correctly decomposed into the right subpieces at the moment and even if we knew the subpieces we still wouldn't know the right interfaces between them." <ref> [4, page 140] </ref>. As Mitchell et al. put it: "[the] reductionist research strategy has reached the point of diminishing returns." [16, page 352]. <p> in the real world: "with a simplified world: : : it is very easy to accidentally build a submodule of the systems which happens to rely on some of those simplified properties: : : the disease spreads and the complete system depends in a subtle way on the simplified world" <ref> [4, page 150] </ref>. Thus, Brooks is opposed to simulated worlds. After all, the infamous Blocksworld is just yesterday's simulated world. The softbot paradigm escapes these quandaries by committing to full realism at every step. Softbots operate in dynamic, real-world environments that are not engineered by the softbots' designers. <p> Humans arrived a mere 2.5 million years ago, and invented writing only recently. Brooks writes "this suggests that problem solving behavior, language, expert knowledge and application, and reason, are all pretty simple once the essence of being and reacting are available" <ref> [4, page 141] </ref>. Based on this observation, Brooks advocates studying intelligence `bottom up,' starting with insects, eventually moving up to reptiles, and so on. Whatever the merits of Brooks's bottom-up research strategy, his evolutionary argument 3 has to be elaborated. <p> Conducting experiments using mobile robots is often time-consuming and difficult. Experiments are frequently hampered by a wide variety of hardware difficulties and malfunctions <ref> [4, 20] </ref>. Days and even weeks go by in which the robot is not operational. Even when the robot is operational, the mean time between failures can be short. As a result, carrying out empirical AI research using robots can be quite tedious and slow. <p> work with physical Creatures is a nontrivial and time consuming activity: : : as of mid-1987, our work in learning is held up by the need to build a new sort of video camera and high-speed low-power processing box to run specially developed vision algorithms at 10 frames per second." <ref> [4, page 158] </ref>. Thus, software task environments have a number of pragmatic advantages over physical ones. First, the mean time between hardware failures is much greater for a workstation supporting a software environment than for a mobile robot. <p> A priori arguments only carry so much weight, though. The real test of the softbot paradigm is whether it will yield fundamental contributions to core AI. Our language for planning with incomplete information (uwl [7]) is a modest example, but the jury is still out. To paraphrase Brooks <ref> [4, page 158] </ref>, only experiments with real softbots in real software worlds can answer the natural doubts about our approach. Time will tell.
Reference: [5] <author> L. Dent, J. Boticario, J. McDermott, T. Mitchell, and D. Zabowski. </author> <title> A Personal Learning Apprentice. </title> <booktitle> In Proceedings of AAAI-92, </booktitle> <pages> pages 96-103, </pages> <address> Sam Mateo, California, July 1992. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: The article proposes real-world software environments, such as operating systems or databases, as a substrate for intelligent-agents research. Over the years, software environments have been explored as domains for machine learning <ref> [5, 6] </ref>, intelligent user interfaces [21], planning [2], distributed AI [17, 19], and more. We argue for a unified conception: complete, intelligent agents that interact with real-world software environments by issuing commands and interpreting the environments' feedback. <p> Some simple examples are: * Filtering electronic mail, and sending routine messages such as meeting reminders, talk announcements, and so on. * Scheduling meetings <ref> [5, 14] </ref>. * Performing system maintenance tasks (e.g., around-the-clock intrusion detection).
Reference: [6] <author> T. G. Dietterich. </author> <title> Constraint Propagation Techniques for theory-driven data interpretation. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <year> 1984. </year>
Reference-contexts: The article proposes real-world software environments, such as operating systems or databases, as a substrate for intelligent-agents research. Over the years, software environments have been explored as domains for machine learning <ref> [5, 6] </ref>, intelligent user interfaces [21], planning [2], distributed AI [17, 19], and more. We argue for a unified conception: complete, intelligent agents that interact with real-world software environments by issuing commands and interpreting the environments' feedback.
Reference: [7] <author> O. Etzioni, S. Hanks, D. Weld, D. Draper, N. Lesh, and M. Williamson. </author> <title> An approach to planning with incomplete information. </title> <booktitle> In Proceedings of the Third International Conference on Principles of Knowledge representation and reasoning, </booktitle> <pages> pages 115-125, </pages> <address> Sam Mateo, California, 1992. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: A priori arguments only carry so much weight, though. The real test of the softbot paradigm is whether it will yield fundamental contributions to core AI. Our language for planning with incomplete information (uwl <ref> [7] </ref>) is a modest example, but the jury is still out. To paraphrase Brooks [4, page 158], only experiments with real softbots in real software worlds can answer the natural doubts about our approach. Time will tell. <p> Furthermore, as new system facilities become available, the shell scripts would need to be continually updated and modified. In contrast, the softbot represents UNIX commands (and applications such as netfind) as strips-style operators, and utilizes general-purpose planning algorithms to dynamically generate a plan that satisfies the user's goals <ref> [7, 8] </ref>. Once the softbot "knows" about a new facility, that facility becomes immediately available to its planning process, and is automatically invoked to satisfy relevant user goals. Furthermore, unlike a shell script, the softbot is not locked into a rigid control flow.
Reference: [8] <author> O. Etzioni, N. Lesh, and R. Segal. </author> <title> Building softbots for unix (preliminary report). </title> <type> Unpublished Manuscript, </type> <year> 1992. </year>
Reference-contexts: Time will tell. A UNIX Softbot (INSERT SECTION) To make the softbot paradigm concrete we briefly describe a general-purpose UNIX softbot (called Rodney 3 ) under development at the University of Washington. See <ref> [8] </ref> for a comprehensive description of Rodney. Rodney accepts high-level user goals and dynamically synthesizes the appropriate sequence of UNIX commands. Rodney executes the sequence, recovering from errors and retrying commands if necessary. The following are examples of the types of requests that Rodney handles successfully: 1. <p> Furthermore, as new system facilities become available, the shell scripts would need to be continually updated and modified. In contrast, the softbot represents UNIX commands (and applications such as netfind) as strips-style operators, and utilizes general-purpose planning algorithms to dynamically generate a plan that satisfies the user's goals <ref> [7, 8] </ref>. Once the softbot "knows" about a new facility, that facility becomes immediately available to its planning process, and is automatically invoked to satisfy relevant user goals. Furthermore, unlike a shell script, the softbot is not locked into a rigid control flow.
Reference: [9] <author> O. Etzioni and R. Segal. </author> <title> Softbots as testbeds for machine learning. </title> <booktitle> In Working Notes of the AAAI Spring Symposium on Knowledge Assimilation, </booktitle> <address> Menlo Park, CA, 1992. </address> <publisher> AAAI Press. </publisher>
Reference-contexts: We argue for a unified conception: complete, intelligent agents that interact with real-world software environments by issuing commands and interpreting the environments' feedback. We refer to such agents as softbots (soft ware robots) <ref> [9] </ref>: * A softbot's effectors are commands transmitted to the external environment in order to change its state (e.g., UNIX shell commands such as mv or compress). * A softbot's sensors are commands that provide the softbot with information about its external world (e.g., pwd or ls in UNIX).
Reference: [10] <author> S. J. Gould. The Panda's Thumb. W. W. </author> <title> Norton, </title> <address> New York, NY, </address> <year> 1980. </year>
Reference-contexts: As Gould puts it in a popular account, "the fossil record with its abrupt transitions offers no support for gradual change, and the principle of natural selection does not require it|selection can operate rapidly" <ref> [10, page 188] </ref>. We should not underestimate the amount of evolutionary change underlying our higher cognitive functions. The vagaries of evolutionary theory aside, Brooks does not explain why biological evolu tion is relevant to AI research methodology.
Reference: [11] <author> R. E. Kahn and V. G. Cerf. </author> <title> An open architecture for a digital library system and a plan for its development. </title> <type> Technical report, </type> <institution> Corporation for National Research Initiatives, </institution> <month> March </month> <year> 1988. </year>
Reference-contexts: This section presents an independent argument for softbots. The argument has both weak and strong versions. The weak version is straight forward. Software environments (e.g., databases, computer networks, operating systems) are the subject of intense study in computer science; software agents are gaining prominence outside AI (e.g., Knowbots <ref> [11] </ref>), demonstrating their intrinsic interest. Software environments are not idealizations of physical environments; developing softbots is a difficult and exciting challenge in its own right.
Reference: [12] <author> L. Kleinrock. </author> <title> Distributed systems. </title> <journal> Computer, </journal> <volume> 18 </volume> <pages> 90-103, </pages> <month> November </month> <year> 1985. </year>
Reference-contexts: Brooks emphasizes that an agent ought to have some purpose; it ought to be useful (cf. [18]). The preponderance of problems such as feature shock (the paralysis a user feels when facing a bewildering array of complex, poorly-documented features <ref> [12] </ref>) and information anxiety (a user's emotional response to the increasing volume and diversity of electronic data [15, 22]) suggest that there is no shortage of useful tasks for a softbot.
Reference: [13] <author> P. Langley and M. Drummond. </author> <title> Toward an experimental science of planning. </title> <editor> In K. P. Sycara, editor, </editor> <booktitle> Proceedings of the workshop on innovative approaches to planning, scheduling, and control, </booktitle> <address> Sam Mateo, California, 1990. </address> <publisher> Morgran Kaufmann. </publisher>
Reference-contexts: As a result, software experiments are easier to perform, control, and repeat than robotic experiments, facilitating systematic experimental research of the sort advocated by <ref> [13] </ref> and others. In addition, software facilitates the dissemination and replication of research results. It is straight forward to distribute multiple copies of a softbot, whereas the distribution of research-prototype robots is difficult. Software environments are particularly well-suited for agent research.
Reference: [14] <author> P. Maes and R. Kozierok. </author> <title> Learning interface agents. </title> <booktitle> In Proceedings of INTERCHI-93, </booktitle> <year> 1993. </year>
Reference-contexts: Some simple examples are: * Filtering electronic mail, and sending routine messages such as meeting reminders, talk announcements, and so on. * Scheduling meetings <ref> [5, 14] </ref>. * Performing system maintenance tasks (e.g., around-the-clock intrusion detection).
Reference: [15] <author> E. Messinger, K. Shoens, J. Thomas, and A. Luniewski. </author> <title> Rufus: the information spunge. </title> <type> Technical Report RJ 8294, </type> <institution> IBM Almaden research center, </institution> <month> August </month> <year> 1991. </year> <month> 9 </month>
Reference-contexts: The preponderance of problems such as feature shock (the paralysis a user feels when facing a bewildering array of complex, poorly-documented features [12]) and information anxiety (a user's emotional response to the increasing volume and diversity of electronic data <ref> [15, 22] </ref>) suggest that there is no shortage of useful tasks for a softbot. Some simple examples are: * Filtering electronic mail, and sending routine messages such as meeting reminders, talk announcements, and so on. * Scheduling meetings [5, 14]. * Performing system maintenance tasks (e.g., around-the-clock intrusion detection).
Reference: [16] <author> T. M. Mitchell, J. Allen, P. Chalasani, J. Cheng, O. Etzioni, M. Ringuette, and J. C. Schlimmer. Theo: </author> <title> A framework for self-improving systems. </title> <editor> In K. VanLehn, editor, </editor> <booktitle> Architectures for Intelligence. </booktitle> <publisher> Lawrence Erlbaum, </publisher> <address> Hillsdale, NJ., </address> <year> 1991. </year>
Reference-contexts: As Mitchell et al. put it: "[the] reductionist research strategy has reached the point of diminishing returns." <ref> [16, page 352] </ref>. While both statements are quite strong, it seems clear that developing complete or integrated agent architectures has a distinct methodological advantage: the researcher is less likely to make unrealistic assumptions about the interfaces between different components of the architecture and about what each component will compute.
Reference: [17] <author> J. Rosenschein. </author> <title> Synchronization of Multi-Agent Plans. </title> <booktitle> In Proceedings of AAAI-82, </booktitle> <year> 1982. </year>
Reference-contexts: The article proposes real-world software environments, such as operating systems or databases, as a substrate for intelligent-agents research. Over the years, software environments have been explored as domains for machine learning [5, 6], intelligent user interfaces [21], planning [2], distributed AI <ref> [17, 19] </ref>, and more. We argue for a unified conception: complete, intelligent agents that interact with real-world software environments by issuing commands and interpreting the environments' feedback.
Reference: [18] <author> R. C. </author> <title> Schank. </title> <journal> Where's the AI? AI Magazine, </journal> <volume> 12(4) </volume> <pages> 38-49, </pages> <year> 1991. </year>
Reference-contexts: To succeed, softbots have to make sense of the flow of information through their limited bandwidth sensors, and respond appropriately. Brooks emphasizes that an agent ought to have some purpose; it ought to be useful (cf. <ref> [18] </ref>).
Reference: [19] <author> Y. Shoham. </author> <title> Agent-oriented programming. </title> <journal> Artificial Intelligence, </journal> <volume> 60(1) </volume> <pages> 51-92, </pages> <month> March </month> <year> 1993. </year>
Reference-contexts: The article proposes real-world software environments, such as operating systems or databases, as a substrate for intelligent-agents research. Over the years, software environments have been explored as domains for machine learning [5, 6], intelligent user interfaces [21], planning [2], distributed AI <ref> [17, 19] </ref>, and more. We argue for a unified conception: complete, intelligent agents that interact with real-world software environments by issuing commands and interpreting the environments' feedback.
Reference: [20] <author> M. Tan. </author> <title> Cost-sensitive Robot Learning. </title> <type> PhD thesis, </type> <institution> Carnegie Mellon University, </institution> <year> 1991. </year> <note> Available as technical report CMU-CS-91-134. </note>
Reference-contexts: Conducting experiments using mobile robots is often time-consuming and difficult. Experiments are frequently hampered by a wide variety of hardware difficulties and malfunctions <ref> [4, 20] </ref>. Days and even weeks go by in which the robot is not operational. Even when the robot is operational, the mean time between failures can be short. As a result, carrying out empirical AI research using robots can be quite tedious and slow.
Reference: [21] <author> R. Wilensky, D. Chin, M. Luria, J. Martin, J. Mayfield, and D. Wu. </author> <title> The Berkeley UNIX Consultant project. </title> <journal> Computational Linguistics, </journal> <volume> 14(4) </volume> <pages> 35-84, </pages> <year> 1988. </year>
Reference-contexts: The article proposes real-world software environments, such as operating systems or databases, as a substrate for intelligent-agents research. Over the years, software environments have been explored as domains for machine learning [5, 6], intelligent user interfaces <ref> [21] </ref>, planning [2], distributed AI [17, 19], and more. We argue for a unified conception: complete, intelligent agents that interact with real-world software environments by issuing commands and interpreting the environments' feedback.

References-found: 21

