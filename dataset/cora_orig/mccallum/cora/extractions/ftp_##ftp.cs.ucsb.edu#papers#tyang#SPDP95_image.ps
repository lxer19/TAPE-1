URL: ftp://ftp.cs.ucsb.edu/papers/tyang/SPDP95_image.ps
Refering-URL: http://www.cs.ucsb.edu/Research/pkhoros/
Root-URL: http://www.cs.ucsb.edu
Email: f chlee, tyang, yfwangg@cs.ucsb.edu  
Title: Partitioning and Scheduling for Parallel Image Processing Operations  
Author: Cheolwhan Lee Tao Yang Yuan-Fang Wang 
Address: Santa Barbara, CA 93106  
Affiliation: Department of Computer Science University of California  
Abstract: Many computer vision and image processing (CVIP) operations can be represented as a sequence of tasks with nested loops, specified by the visual programming language Khoros. This paper addresses the automatic partitioning and scheduling of such operations on distributed memory multiprocessors. The major difficulties in determining the optimal image data distribution for each task are that the number of processors available and the size of the input image may vary at the run time, and the cost of some image processing operations may be data-dependent. This paper proposes a compile-time processor assignment and data partitioning scheme that optimizes the average run-time performance of task chains with nested loops by considering the data redistribution overheads and possible run-time parameter variations. This paper presents the theoretical analysis and experimental results on a Meiko CS-2 distributed memory machine. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Annaratone et al., </author> <title> The Warp Computer: Architecture, Implementation and Performance, </title> <journal> IEEE Trans. Computers, </journal> <volume> Vol. C-36, No. 12, </volume> <month> Dec. </month> <year> 1987, </year> <pages> pp. 1523-1538. </pages>
Reference-contexts: 1 Introduction Many Computer Vision and Image Processing (CVIP) algorithms processes significant data parallelism [21, 22], and much research in parallel CVIP has focused on parallelizing individual algorithms <ref> [1, 2, 9, 16] </ref>. However, optimizing individual tasks in an operation does not guarantee the optimal global performance. In distributed memory architectures, each task may employ different data partitioning and processor allocation schemes, and data migration overhead between tasks may be significant.
Reference: [2] <author> P. K. Biswas, J. Mukherjee, and B. N. Chatterji, </author> <title> Component Labeling in Pyramid Architecture, </title> <journal> Pattern Recognition, </journal> <volume> Vol. 26, No. 7, </volume> <year> 1993, </year> <pages> pp. 1099-1115. </pages>
Reference-contexts: 1 Introduction Many Computer Vision and Image Processing (CVIP) algorithms processes significant data parallelism [21, 22], and much research in parallel CVIP has focused on parallelizing individual algorithms <ref> [1, 2, 9, 16] </ref>. However, optimizing individual tasks in an operation does not guarantee the optimal global performance. In distributed memory architectures, each task may employ different data partitioning and processor allocation schemes, and data migration overhead between tasks may be significant.
Reference: [3] <author> S. Chakrabarti, J. Demmel, and K. Yelick, </author> <title> Modeling the Benefits of Mixed Data and Task Parallelism, </title> <booktitle> To appear in Proc. of ACM SPAA, </booktitle> <address> Santa Barabra, </address> <year> 1995. </year>
Reference-contexts: Library-based parallel systems were discussed in [8, 15]. Our work differs from the above in exploiting both the task and data parallelism on distributed memory architectures. Scheduling task and data parallelism has recently been studied for program compilation <ref> [3, 13, 18, 19, 24] </ref>. The optimization function in [18, 19] is for maximizing the throughput with fixed task parameters. The work in [3, 13] deals with DAGs of fixed data distribution and processor parameters, but not with graphs with loops. <p> Scheduling task and data parallelism has recently been studied for program compilation [3, 13, 18, 19, 24]. The optimization function in [18, 19] is for maximizing the throughput with fixed task parameters. The work in <ref> [3, 13] </ref> deals with DAGs of fixed data distribution and processor parameters, but not with graphs with loops. In [5], techniques for optimizing the data distribution are presented for nested loops, which can be viewed as the optimization for one macro task.
Reference: [4] <author> J. Choi, J.J. Dongarra, R. Pozo, and D. W. Walker, ScaLA-PACK: </author> <title> A scalable linear algebra library for distributed memory concurrent computers, </title> <booktitle> Proc. of the 4th Symp. on Massively Parallel Computing, </booktitle> <year> 1992, </year> <pages> pp. 120-127. </pages>
Reference-contexts: The user employs Khoros visual programming language to specify CVIP operations as task graphs. The system will then determine suitable processor assignment and image data partitioning schemes and generates parallel codes by employing existing parallel routines such as ScaLAPACK <ref> [4] </ref>. In this paper, we assume that a task graph is a chain of data-parallel tasks with nested loops. The goal of optimization is to achieve the minimum overall processing time by assigning multiple processors to each task.
Reference: [5] <author> M. Gupta and P. Banerjee, </author> <title> Demonstration of Automatic Data Partitioning Techniques for Parallelizing Compilers on Multi-computers, </title> <journal> IEEE Trans. Parallel and Distributed Systems, </journal> <volume> Vol. 3, No. 2, </volume> <month> Mar. </month> <year> 1992, </year> <pages> pp. 179-193. </pages>
Reference-contexts: The optimization function in [18, 19] is for maximizing the throughput with fixed task parameters. The work in [3, 13] deals with DAGs of fixed data distribution and processor parameters, but not with graphs with loops. In <ref> [5] </ref>, techniques for optimizing the data distribution are presented for nested loops, which can be viewed as the optimization for one macro task.
Reference: [6] <author> A. Gerasoulis and T. Yang, </author> <title> On the Granularity and Clustering of Directed Acyclic Task Graphs, </title> <journal> IEEE Trans. Parallel and Distributed Systems, </journal> <volume> Vol. 4, No. 6, </volume> <month> June </month> <year> 1993, </year> <pages> pp. 686-701. </pages>
Reference-contexts: For the block-cyclic partitioning, we assume that the blocking factor b in the cyclic pattern is fixed such that the computation time is greater than the communication time for an efficient parallel implementation <ref> [6] </ref>.
Reference: [7] <author> L. H. Jamieson, et al., </author> <title> Parallel Scalable Libraries and Algorithms for Computer Vision, </title> <booktitle> Proceedings of the 12th IAPR Int. Conf. on Pattern Recognition, </booktitle> <address> Jerusalem, Israel, </address> <month> Oct. </month> <year> 1994, </year> <pages> pp. 223-228. </pages>
Reference-contexts: Noted that an algorithm may have different performance using different distribution patterns. For example, the 2D "row-column" parallel FFT algorithm using the row or column partition outperforms the 2D decimation FFT algorithm adopting a block partition for small problem-size/machine-size ratios in coarse-grained machines <ref> [7] </ref>. Since we will employ existing parallel algorithm libraries to execute individual tasks in a graph, the possibility that some tasks may be implemented with a few fixed choices of data distribution must be considered.
Reference: [8] <author> L. H. Jamieson, E. J. Delp, J. N. Patel, C.-C. Wang, and A. A. Khokhar, </author> <title> A Library-Based Program Development Environment for Parallel Image Processing, </title> <booktitle> Proceedings of Scalable Parallel Libraries Conference, </booktitle> <institution> Mississippi State Univ., Missis-sippi, </institution> <month> Oct. </month> <year> 1993, </year> <pages> pp. 187-194. </pages>
Reference-contexts: For example, [11] discussed static and dynamic design/scheduling strategies for image processing. DISC [23] uses a dynamic scheduling scheme for data-dependent tasks and conditional branches on a dynamic reconfigurable and repartionable machine (PASM). Library-based parallel systems were discussed in <ref> [8, 15] </ref>. Our work differs from the above in exploiting both the task and data parallelism on distributed memory architectures. Scheduling task and data parallelism has recently been studied for program compilation [3, 13, 18, 19, 24].
Reference: [9] <author> J. F. Jeng and S. Sahni, </author> <title> Reconfigurable Mesh Algorithms for the Hough Transform, </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> Vol. 20, </volume> <year> 1994, </year> <pages> pp. 69-77. </pages>
Reference-contexts: 1 Introduction Many Computer Vision and Image Processing (CVIP) algorithms processes significant data parallelism [21, 22], and much research in parallel CVIP has focused on parallelizing individual algorithms <ref> [1, 2, 9, 16] </ref>. However, optimizing individual tasks in an operation does not guarantee the optimal global performance. In distributed memory architectures, each task may employ different data partitioning and processor allocation schemes, and data migration overhead between tasks may be significant.
Reference: [10] <author> C. H. Koelbel, D. B. Loveman, R. S. Schreiber, G. L. Steele Jr., and M. E. Zosel, </author> <title> The High Performance Fortran Handbook, </title> <publisher> MIT Press, </publisher> <address> Cambridge, Mass., </address> <year> 1994. </year>
Reference-contexts: Let T be a task in a task graph G and let p be the number of processors available. We assume that task T will use all p processors and T employs one of the following six data distribution schemes based on the High-Performance Fortran standard <ref> [10] </ref>: row, column, row-cyclic, column-cyclic, block, and block-cyclic partitions. The assignment of computation in each task to the p processors is based on the data distribution pattern assumed for that particular task. Noted that an algorithm may have different performance using different distribution patterns.
Reference: [11] <author> S.-Y. Lee and J. K. Aggarwal, </author> <title> A System Design/Scheduling Strategy for Parallel Image Processing, </title> <journal> IEEE Trans. PAMI, </journal> <volume> Vol. 12, No. 2, </volume> <month> Feb. </month> <year> 1990, </year> <pages> pp. 194-204. </pages>
Reference-contexts: The goal of optimization is to achieve the minimum overall processing time by assigning multiple processors to each task. We present an algorithm that determines task data distribution schemes to optimize the average global run-time performance. Several research groups have recently studied the scheduling of CVIP operations. For example, <ref> [11] </ref> discussed static and dynamic design/scheduling strategies for image processing. DISC [23] uses a dynamic scheduling scheme for data-dependent tasks and conditional branches on a dynamic reconfigurable and repartionable machine (PASM). Library-based parallel systems were discussed in [8, 15].
Reference: [12] <author> C. Lee, Y. F. Wang and T. Yang, </author> <title> Static Global Scheduling for Optimal Computer Vision and Image Processing Operations on Distributed-Memory Multiprocessors, </title> <type> Tech. Rep., </type> <institution> TRCS94-23, Dept. of Computer Science, UCSB, </institution> <year> 1994. </year> <note> A part of this paper will appear in Proc. of Inter. Conf. on Computer Analysis of Images and Patterns. </note> <month> Sep. </month> <pages> 6-8, </pages> <year> 1995. </year>
Reference-contexts: We have developed a scheduling scheme as a first step to realize a parallel visual programming system based on Khoros <ref> [12, 14] </ref>. Our goal is to facilitate the migration from a single-processor paradigm to a multiprocessor one in a transparent manner for parallel CVIP operations. The user employs Khoros visual programming language to specify CVIP operations as task graphs. <p> The advantage of finding a good average schedule is that there is no need to produce multiple codes tuned for different parameter settings. 3 Optimization Strategies and the Scheduling Algorithm In order to develop an accurate cost model for each task, we have developed a taxonomy of CVIP operations <ref> [12] </ref> to classify data dependent and data independent operations and to tabulate the costs of many pixel and masking operations widely used in CVIP. The data redistribution cost can also be modeled based on all-to-all communication primitives, e.g. [17]. <p> The data redistribution cost can also be modeled based on all-to-all communication primitives, e.g. [17]. We have also derived data redistribution costs between any two data distribution schemes in the HPF standard <ref> [12] </ref>. <p> This experiment shows the effectiveness of scheduling with different parame scheduled parallel program over the sequential program in MEIKO CS-2. The right figure plots the performance improvement ratio over unscheduled code. ter settings. More details can be found in <ref> [12] </ref>. 5 Concluding Remarks Our partitioning and scheduling schemes take advantage of domain knowledge and optimizes image data partitioning and processor assignment based on their global performance. We address the issue of run-time parameter variations to make static scheduling results more practical and flexible.
Reference: [13] <author> S. Ramaswamy, S. Sapatnekar, and P. Banerjee, </author> <title> A convex programming approach for exploiting data and functional parallelism. </title> <booktitle> In Proc. of 1994 Inter. Conf. on Parallel Processing, </booktitle> <volume> Vol. 2, </volume> <pages> pp. 116-125. </pages>
Reference-contexts: Library-based parallel systems were discussed in [8, 15]. Our work differs from the above in exploiting both the task and data parallelism on distributed memory architectures. Scheduling task and data parallelism has recently been studied for program compilation <ref> [3, 13, 18, 19, 24] </ref>. The optimization function in [18, 19] is for maximizing the throughput with fixed task parameters. The work in [3, 13] deals with DAGs of fixed data distribution and processor parameters, but not with graphs with loops. <p> Scheduling task and data parallelism has recently been studied for program compilation [3, 13, 18, 19, 24]. The optimization function in [18, 19] is for maximizing the throughput with fixed task parameters. The work in <ref> [3, 13] </ref> deals with DAGs of fixed data distribution and processor parameters, but not with graphs with loops. In [5], techniques for optimizing the data distribution are presented for nested loops, which can be viewed as the optimization for one macro task.
Reference: [14] <author> J. Rasure and S. Kubica, </author> <title> The Khoros Application Development Environment, </title> <publisher> Khoral Research Inc., </publisher> <address> Albuquerque, New Mexico, </address> <year> 1992. </year>
Reference-contexts: We have developed a scheduling scheme as a first step to realize a parallel visual programming system based on Khoros <ref> [12, 14] </ref>. Our goal is to facilitate the migration from a single-processor paradigm to a multiprocessor one in a transparent manner for parallel CVIP operations. The user employs Khoros visual programming language to specify CVIP operations as task graphs.
Reference: [15] <author> A. P. Reeves, </author> <title> Parallel Programming for Computer Vision, </title> <journal> IEEE Software, </journal> <volume> Vol. 8, No. 6, </volume> <month> Nov. </month> <year> 1991, </year> <pages> pp. 51-59. </pages>
Reference-contexts: For example, [11] discussed static and dynamic design/scheduling strategies for image processing. DISC [23] uses a dynamic scheduling scheme for data-dependent tasks and conditional branches on a dynamic reconfigurable and repartionable machine (PASM). Library-based parallel systems were discussed in <ref> [8, 15] </ref>. Our work differs from the above in exploiting both the task and data parallelism on distributed memory architectures. Scheduling task and data parallelism has recently been studied for program compilation [3, 13, 18, 19, 24].
Reference: [16] <author> H. J. Siegel, J. B. Armstrong, and D. W. Watson, </author> <title> Mapping Computer-Vision-Related Tasks onto Reconfigurable Parallel-Processing Systems, </title> <journal> IEEE Computer, </journal> <volume> Vol. 25, No. 2, </volume> <month> Feb. </month> <year> 1992, </year> <month> pp.54-63. </month>
Reference-contexts: 1 Introduction Many Computer Vision and Image Processing (CVIP) algorithms processes significant data parallelism [21, 22], and much research in parallel CVIP has focused on parallelizing individual algorithms <ref> [1, 2, 9, 16] </ref>. However, optimizing individual tasks in an operation does not guarantee the optimal global performance. In distributed memory architectures, each task may employ different data partitioning and processor allocation schemes, and data migration overhead between tasks may be significant.
Reference: [17] <author> R. Thakur and A. Choudhary, </author> <title> All-to-all communication on meshes with wormhole routing, </title> <booktitle> Proc. of 1994 Inter. Parallel Processing Symposium, </booktitle> <pages> pp 561-565. </pages>
Reference-contexts: The data redistribution cost can also be modeled based on all-to-all communication primitives, e.g. <ref> [17] </ref>. We have also derived data redistribution costs between any two data distribution schemes in the HPF standard [12].
Reference: [18] <author> J. Subhlok, D. O'Hallaron, T. Gross, P. Dinda, and J. Webb, </author> <title> Communication and memory requirements as the basis for mapping task and data parallel programs. </title> <booktitle> In Proc. of Supercomputing '94, </booktitle> <pages> pp. 330-339. </pages>
Reference-contexts: Library-based parallel systems were discussed in [8, 15]. Our work differs from the above in exploiting both the task and data parallelism on distributed memory architectures. Scheduling task and data parallelism has recently been studied for program compilation <ref> [3, 13, 18, 19, 24] </ref>. The optimization function in [18, 19] is for maximizing the throughput with fixed task parameters. The work in [3, 13] deals with DAGs of fixed data distribution and processor parameters, but not with graphs with loops. <p> Library-based parallel systems were discussed in [8, 15]. Our work differs from the above in exploiting both the task and data parallelism on distributed memory architectures. Scheduling task and data parallelism has recently been studied for program compilation [3, 13, 18, 19, 24]. The optimization function in <ref> [18, 19] </ref> is for maximizing the throughput with fixed task parameters. The work in [3, 13] deals with DAGs of fixed data distribution and processor parameters, but not with graphs with loops.
Reference: [19] <author> J. Subhlok and G. Vondran, </author> <title> Optimal mapping of sequences of data parallel tasks, </title> <booktitle> To appear in Proc. of ACM PPoPP, </booktitle> <address> Santa Barbara, </address> <year> 1995. </year>
Reference-contexts: Library-based parallel systems were discussed in [8, 15]. Our work differs from the above in exploiting both the task and data parallelism on distributed memory architectures. Scheduling task and data parallelism has recently been studied for program compilation <ref> [3, 13, 18, 19, 24] </ref>. The optimization function in [18, 19] is for maximizing the throughput with fixed task parameters. The work in [3, 13] deals with DAGs of fixed data distribution and processor parameters, but not with graphs with loops. <p> Library-based parallel systems were discussed in [8, 15]. Our work differs from the above in exploiting both the task and data parallelism on distributed memory architectures. Scheduling task and data parallelism has recently been studied for program compilation [3, 13, 18, 19, 24]. The optimization function in <ref> [18, 19] </ref> is for maximizing the throughput with fixed task parameters. The work in [3, 13] deals with DAGs of fixed data distribution and processor parameters, but not with graphs with loops.
Reference: [20] <author> M. Turk and A. Pentland, </author> <title> Eigenfaces for Recognition, </title> <journal> In Journal of Cognitive Neuroscience, </journal> <volume> Vol. 3, No. 1, </volume> <month> Mar. </month> <year> 1991, </year> <pages> pp. 71-86. </pages>
Reference-contexts: We use a tree to depict the nested loop control structure in an input task graph. Fig. 1 gives an example of the task graph which represents the eigen image computation <ref> [20] </ref>. The first loop is for computing an average image of the input image ensemble.
Reference: [21] <author> J. A. Webb, </author> <title> High Performance Computing in Image Processing and Computer Vision, </title> <booktitle> Proceedings of 12th IAPR Int. Conf. on Pattern Recognition, </booktitle> <address> Jerusalem, Israel, </address> <month> Oct. </month> <year> 1994, </year> <pages> pp. 218-222. </pages>
Reference-contexts: 1 Introduction Many Computer Vision and Image Processing (CVIP) algorithms processes significant data parallelism <ref> [21, 22] </ref>, and much research in parallel CVIP has focused on parallelizing individual algorithms [1, 2, 9, 16]. However, optimizing individual tasks in an operation does not guarantee the optimal global performance.
Reference: [22] <author> C. C. Weems, et al., </author> <title> Parallel Processing in the DARPA Strategic Computing Vision Program, </title> <journal> IEEE Expert, </journal> <volume> Vol. 6, No. 5, </volume> <month> Oct. </month> <year> 1991, </year> <pages> pp. 23-38. </pages>
Reference-contexts: 1 Introduction Many Computer Vision and Image Processing (CVIP) algorithms processes significant data parallelism <ref> [21, 22] </ref>, and much research in parallel CVIP has focused on parallelizing individual algorithms [1, 2, 9, 16]. However, optimizing individual tasks in an operation does not guarantee the optimal global performance.
Reference: [23] <author> F. Weil, L. H. Jamieson, and E. J. Delp, </author> <title> Dynamic Intelligent Scheduling and Control of Reconfigurable Parallel Architectures for Computer Vision/Image Processing, </title> <journal> J. of Parallel and Distributed Computing, </journal> <volume> Vol. 13, </volume> <year> 1991, </year> <pages> pp. 273-285. </pages>
Reference-contexts: We present an algorithm that determines task data distribution schemes to optimize the average global run-time performance. Several research groups have recently studied the scheduling of CVIP operations. For example, [11] discussed static and dynamic design/scheduling strategies for image processing. DISC <ref> [23] </ref> uses a dynamic scheduling scheme for data-dependent tasks and conditional branches on a dynamic reconfigurable and repartionable machine (PASM). Library-based parallel systems were discussed in [8, 15]. Our work differs from the above in exploiting both the task and data parallelism on distributed memory architectures. <p> We address the issue of run-time parameter variations to make static scheduling results more practical and flexible. Our future work is to extend this framework and incorporate the run-time scheduling approach <ref> [23] </ref> to perform both static and dynamic optimizations. Acknowledgments Cheolwhan Lee was partially supported by a Sam-sung Humantech fellowship, Y. F. Wang partially by the Alexandria Digital Library Project, and Tao Yang partially by NSF CCR-9409695 and the Alexandria Digital Library Project.
Reference: [24] <author> T. Yang and A. Gerasoulis, </author> <title> PYRROS: Static Task Scheduling and Code Generation for Message Passing Multiprocessors, </title> <booktitle> Proc. of 6th ACM Int. Conf. on Supercomputing, </booktitle> <address> Washington D.C., </address> <month> Jul. </month> <year> 1992, </year> <pages> pp. 428-437. </pages>
Reference-contexts: Library-based parallel systems were discussed in [8, 15]. Our work differs from the above in exploiting both the task and data parallelism on distributed memory architectures. Scheduling task and data parallelism has recently been studied for program compilation <ref> [3, 13, 18, 19, 24] </ref>. The optimization function in [18, 19] is for maximizing the throughput with fixed task parameters. The work in [3, 13] deals with DAGs of fixed data distribution and processor parameters, but not with graphs with loops.
References-found: 24

