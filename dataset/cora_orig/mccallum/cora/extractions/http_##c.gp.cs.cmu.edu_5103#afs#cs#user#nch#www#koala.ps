URL: http://c.gp.cs.cmu.edu:5103/afs/cs/user/nch/www/koala.ps
Refering-URL: http://c.gp.cs.cmu.edu:5103/afs/cs/user/nch/www/koala.html
Root-URL: http://www.cs.cmu.edu
Email: nch@research.bell-labs.com  
Title: Scalable Document Fingerprinting (Extended Abstract)  
Author: Nevin Heintze 
Address: Murray Hill, NJ 07974  
Affiliation: Bell Laboratories  
Abstract: This paper presents an online system that provides reliable search results using modest resources and scales up to data sets of the order of a million documents. Our system provides a practical compromise between storage requirements, immunity to noise introduced by document conversion and security needs for plagiarism applications. We present both quantitative analysis and empirical results to argue that our design is feasible and effective. A web-based prototype system is accessible via the URL http://www.cs.cmu.edu/afs/cs/user/nch/www/koala.html. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> C. Anderson, "Robocops: </author> <title> Stewart and Feder's mechanized misconduct search", </title> <journal> Nature, </journal> <volume> 350(6318) </volume> <pages> 454-455, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: Moreover, these approaches are not well suited for detecting partial matches involving modified documents. The second approach involves the registration and storage of documents and subsequent textual matching with new documents to track copies and modified versions <ref> [1, 6, 11] </ref>. This approach has been used in a number of implemented systems [2, 7, 8, 9]. In this paper we consider the general problem of textual matching for document search and plagiarism/copyright applications.
Reference: [2] <author> S. Brin, J. Davis and H. Garcia-Molina, </author> <title> "Copy Detection Mechanisms for Digital Documents", </title> <booktitle> Proceedings of the ACM SIGMOD Annual Conference, </booktitle> <month> May </month> <year> 1995. </year>
Reference-contexts: The second approach involves the registration and storage of documents and subsequent textual matching with new documents to track copies and modified versions [1, 6, 11]. This approach has been used in a number of implemented systems <ref> [2, 7, 8, 9] </ref>. In this paper we consider the general problem of textual matching for document search and plagiarism/copyright applications.
Reference: [3] <author> J. Brassil, S. Low, N. Maxemchuk and L. O'Gorman, </author> <title> "Electronic Marking and Identification Techniques to Discourage Document Copying", </title> <journal> Journal on Selected Areas in Communications, </journal> <volume> Volume 13, Number 8, </volume> <month> October </month> <year> 1995. </year>
Reference-contexts: On another front, there is increasing concern about plagiarism of coursework papers at the college undergraduate and graduate level. There are two approaches to this plagiarism/copyright problem. In the first, digital sig natures or watermarks are included in a document <ref> [3, 10] </ref>. These signatures may involve the use of particular word spacings or checksums of components of a document. Unfortunately, these signatures can often be deleted (particularly if the document is translated from one format to another).
Reference: [4] <author> P. J. Denning, </author> <title> "Plagiarism in the web", Editorial, </title> <journal> Communications of the ACM, </journal> <volume> 38(12), </volume> <month> December </month> <year> 1995. </year>
Reference-contexts: This kind of plagiarism has been successfully carried out in the past and was the subject of a recent editorial in the Communications of the ACM <ref> [4] </ref>. Arguably it was inevitable that the individual involved would be discovered. What is surprising is the scope of his activities, the time it took before he was discovered, and that he was able to continue with some success even after his case was well known.
Reference: [5] <author> U. Manber, </author> <title> "Finding similar files in a large file system", </title> <booktitle> Proceedings of the 1994 USENIX Conference, </booktitle> <pages> pp. 1-10, </pages> <month> January </month> <year> 1994. </year>
Reference: [6] <author> A. Parker and J. O. Hamblen, </author> <title> "Computer algorithms for plagiarism detection", </title> <journal> IEEE Transactions on Education, </journal> <volume> 32(2) </volume> <pages> 94-99, </pages> <month> May </month> <year> 1989. </year>
Reference-contexts: Moreover, these approaches are not well suited for detecting partial matches involving modified documents. The second approach involves the registration and storage of documents and subsequent textual matching with new documents to track copies and modified versions <ref> [1, 6, 11] </ref>. This approach has been used in a number of implemented systems [2, 7, 8, 9]. In this paper we consider the general problem of textual matching for document search and plagiarism/copyright applications.
Reference: [7] <author> N. Shivakumar and H. Garcia-Molina, </author> <note> "SCAM: </note>
Reference-contexts: The second approach involves the registration and storage of documents and subsequent textual matching with new documents to track copies and modified versions [1, 6, 11]. This approach has been used in a number of implemented systems <ref> [2, 7, 8, 9] </ref>. In this paper we consider the general problem of textual matching for document search and plagiarism/copyright applications. <p> We present both quantitative and empirical analysis of our system. A web-based prototype system called Koala is accessible via the URL http://www.cs.cmu.edu/afs/cs/user/nch/www/koala.html. Related Work Most closely related to our work is the Stanford Digital Library work on SCAM <ref> [7, 8, 9] </ref>. Their approach uses relative word frequencies. Similarity between documents is based on a modified cosine similarity measure.
References-found: 7

