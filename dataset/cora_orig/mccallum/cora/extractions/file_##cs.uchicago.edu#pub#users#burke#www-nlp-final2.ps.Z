URL: file://cs.uchicago.edu/pub/users/burke/www-nlp-final2.ps.Z
Refering-URL: http://cs-www.uchicago.edu/~burke/writing.html
Root-URL: 
Title: Natural Language Processing in the FAQ Finder System:  
Abstract: Results and Prospects Abstract This paper describes some recent results regarding the employment of natural language processing techniques in the FAQ Finder system. FAQ Finder is a natural language question-answering system that uses files of frequently-asked questions as its knowledge base. Unlike AI question-answering systems that focus on the generation of new answers, FAQ Finder retrieves existing ones found in frequently-asked question files. FAQ Finder uses a combination of statistical and natural language techniques to match user questions against known question/answer pairs from FAQ files. We strove in our experiments to identify the contribution of these techniques to the overall success of the system. One unexpected result was that our parsing technique was not contributing as much to the system's performance as we expected. We discuss some of the reasons why this may have been the case, and describe further natural language processing research designed to address the system's current needs. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Buckley, C. </author> <year> 1985. </year> <title> Implementation of the SMART Information Retrieval Retrieval [sic] System. </title> <type> Technical Report 85-686, </type> <institution> Cornell University. </institution>
Reference-contexts: The FAQ Finder system Input to FAQ Finder is a question, typed by the user in natural language. The first step for the system is to narrow the search for a matching FAQ question to a single FAQ file. This is done using the SMART information retrieval system <ref> (Buckley, 1985) </ref>. The user question is treated as a set of index terms to be matched against the overall content of individual FAQ files.
Reference: <author> Burke, R., Hammond, K. & Cooper, E., </author> <year> 1996. </year> <title> Knowledge-based information retrieval from semi-structured text. </title> <booktitle> In AAAI Workshop on Internet-based Information Systems, </booktitle> <pages> pp. 9-15. </pages> <publisher> AAAI. </publisher>
Reference: <author> Collins, A. M. and Quillian, M. R. </author> <year> 1972. </year> <title> How to Make a Language User. </title> <editor> In E. Tulving and W. Donaldson, </editor> <booktitle> Organization of Memory. </booktitle> <address> New York: </address> <publisher> Academic Press. </publisher>
Reference-contexts: We found that unrestricted marker passing, using all networks in which a term appears, led to too many spurious matches, a common problem in marker passing systems in general <ref> (Collins & Quillian, 1972) </ref>. We tried several approaches to disambiguate terms to a single WordNet network. Our first attempt was to use an existing part-of-speech tagger, the Xerox Tag-ger (Cutting, et al., 1992).
Reference: <author> Cutting, D., Kupiec, J., Pederson, J., & Sibun, P. </author> <year> 1992. </year> <title> A Practical Part-of-Speech Tagger. </title> <booktitle> In Proceedings of the Third Conference on Applied Natural Language Processing. ACL. </booktitle>
Reference-contexts: We tried several approaches to disambiguate terms to a single WordNet network. Our first attempt was to use an existing part-of-speech tagger, the Xerox Tag-ger <ref> (Cutting, et al., 1992) </ref>. This system uses a hidden Markov model learned from a large corpus of English text to statistically determine the most likely sense for any given word in the context of a sentence.
Reference: <author> Grady Ward. </author> <year> 1994. </year> <title> Moby Part-of-Speech II (data file). </title>
Reference-contexts: Our next attempt at identifying unambiguous part-of-speech information was to use natural language parsing. We built a simple context-free grammar for questions, and implemented it in a bottom-up chart parser. The parser's lexicon was compiled from a combination of the on-line Oxford English dictionary and the Moby part-of-speech dictionary <ref> (Grady Ward, 1994) </ref>. A successful parse would resolve syntactic category ambiguities of individual lexical items in a question (e.g., whether "name" in the above example is a noun or a verb).
Reference: <author> Grady Ward, </author> <type> 3449 Martha Ct., </type> <address> Arcata CA. </address>
Reference: <author> Hammond, K., Burke, R., Martin, C. & Lytinen, S, </author> <year> 1995. </year> <title> FAQ Finder: A Case-Based Approach to Knowledge Navigation. </title> <booktitle> In Proceedings of the Eleventh Conference on Artificial Intelligence for Applications. </booktitle> <address> Los Angeles: </address> <publisher> IEEE Computer Society Press. </publisher>
Reference: <author> Lang, K. L.; Graesser, A. C.; Dumais, S. T. and Kil-man, D. </author> <year> 1992. </year> <title> Question Asking in Human-Computer Interfaces. </title> <editor> In T. Lauer, E. Peacock and A. C. </editor> <booktitle> Graesser Questions and Information Systems (pp. </booktitle> <pages> 131-165). </pages> <address> Hillsdale, NJ: </address> <publisher> Lawrence Erlbaum Assoc. </publisher>
Reference: <author> Lehnert, W. G. </author> <year> 1978. </year> <title> The Process of Question An swering. </title> <address> Hillsdale, NJ: </address> <publisher> Lawrence Erlbaum Assoc. </publisher>
Reference: <author> Mallery, J. C. </author> <year> 1994. </year> <title> A Common LISP Hypermedia Server. </title> <booktitle> In Proceedings of The First International Conference on The World-Wide Web, </booktitle> <address> Geneva: </address> <publisher> CERN. </publisher>
Reference-contexts: Current Status As of this writing, the FAQ Finder is implemented in approximately 9000 lines of Allegro Common Lisp. Another 1000 lines of Lisp code is devoted to the generation of HTML for the system's web interface. The program runs under the CL-HTTP server <ref> (Mallery, 1994) </ref>. Currently the system incorporates 187 FAQ files, but we are in the process of building the system's FAQ file library, aiming to cover all of the files in the USENET FAQ file archive 1 that are in question-answer format, approximately 1000 files.
Reference: <author> Miller, G. A. </author> <year> 1995. </year> <title> WordNet: A Lexical Database for English. </title> <journal> Communications of the ACM, </journal> <volume> 38(11). </volume>
Reference-contexts: Shallow lexical semantics in WordNet FAQ Finder obtains its knowledge of shallow lexical semantics from WordNet, a semantic network of English words <ref> (Miller, 1995) </ref>. The WordNet system provides a system of relations between words and "synonym sets," and between synonym sets themselves. The level of knowledge representation does not go much deeper than the words themselves, but there is an impressive coverage of basic lexical relations.
Reference: <author> Ogden, W. C. </author> <year> 1988. </year> <title> Using natural language interfaces. </title>
Reference: <editor> In M. Helander (Ed.), </editor> <booktitle> Handbook of human-computer interaction (pp. </booktitle> <pages> 205-235). </pages> <address> New York: </address> <publisher> North-Holland. </publisher>
Reference: <author> Quillian, M. R. </author> <year> 1968. </year> <title> Semantic Memory. In Semantic Information Processing, Marvin Minsky, </title> <publisher> ed., </publisher> <pages> pp. 216-270. </pages> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Salton, Gerard, ed. </author> <year> 1971. </year> <title> The SMART Retrieval System: Experiments in Automatic Document Processing. </title> <address> Englewood Cliffs, NJ: </address> <publisher> Prentice-Hall. </publisher>
Reference: <author> Salton, G., & McGill, M. </author> <year> 1983. </year> <title> Introduction to modern information retrieval. </title> <address> New York: </address> <publisher> McGraw-Hill. </publisher>
Reference-contexts: A question-answer (QA) pair is represented by a term vector, a sparse vector that associates a significance value with each term in the QA pair. The significance value that we use is commonly-known as tfidf, which stands for term frequency times log of inverse document frequency <ref> (Salton & McGill, 1983) </ref>.
Reference: <author> Souther, A.; Acker, L.; Lester, J. and Porter, B. </author> <year> 1989. </year> <title> Using view types to generate explanations in intelligent tutoring systems. </title> <booktitle> In Proceedings of the Eleventh Annual conference of the Cognitive Science Society (pp. </booktitle> <pages> 123-130). </pages> <address> Hillsdale, NJ: </address> <publisher> Lawrence Erlbaum Assoc. </publisher>
References-found: 17

