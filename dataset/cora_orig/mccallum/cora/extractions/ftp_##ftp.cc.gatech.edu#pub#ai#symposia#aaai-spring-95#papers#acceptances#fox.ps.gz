URL: ftp://ftp.cc.gatech.edu/pub/ai/symposia/aaai-spring-95/papers/acceptances/fox.ps.gz
Refering-URL: ftp://ftp.cc.gatech.edu/pub/ai/symposia/aaai-spring-95/papers/finals.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: fsfox,leakeg@cs.indiana.edu  
Title: Modeling Case-based Planning for Repairing Reasoning Failures  
Author: Susan Fox David B. Leake 
Address: Bloomington, IN 47405  
Affiliation: Computer Science Department Indiana University  
Abstract: One application of models of reasoning behavior is to allow a reasoner to introspectively detect and repair failures of its own reasoning process. We address the issues of the transferability of such models versus the specificity of the knowledge in them, the kinds of knowledge needed for self-modeling and how that knowledge is structured, and the evaluation of introspective reasoning systems. We present the ROBBIE system which implements a model of its planning processes to improve the planner in response to reasoning failures. We show how ROBBIE's hierarchical model balances model generality with access to implementation-specific details, and discuss the qualitative and quantitative measures we have used for evaluating its introspective component. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Alterman, R. </author> <year> (1986). </year> <title> An adaptive planner. </title> <booktitle> In Proceedings of the Fifth National Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 65-69 Philadelphia, PA. </address> <publisher> AAAI. </publisher>
Reference: <author> Birnbaum, L., Collins, G., Brand, M., Freed, M., Krulwich, B., & Pryor, L. </author> <year> (1991). </year> <title> A model-based approach to the construction of adaptive case-based planning systems. In Bareiss, </title> <editor> R. (Ed.), </editor> <booktitle> Proceedings of the Case-Based Reasoning Workshop, </booktitle> <pages> pp. </pages> <address> 215-224 San Mateo. </address> <publisher> DARPA, Morgan Kaufmann, Inc. </publisher>
Reference: <author> Birnbaum, L., Collins, G., Freed, M., & Krulwich, B. </author> <year> (1990). </year> <title> Model-based diagnosis of planning failures. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 318-323 Boston, MA. </address> <publisher> AAAI. </publisher>
Reference: <author> Collins, G., Birnbaum, L., Krulwich, B., & Freed, M. </author> <year> (1993). </year> <title> The role of self-models in learning to plan. </title> <booktitle> In Foundations of Knowledge Aquisition: Machine Learning, </booktitle> <pages> pp. 83-116. </pages> <publisher> Kluwer Academic Publishers. </publisher>
Reference: <author> Cox, M. </author> <year> (1995). </year> <title> Representing mental events (or the lack thereof). </title> <booktitle> In Proceedings of the 1995 AAAI Spring Symposium on Representing Mental States and Mechanisms. </booktitle> <publisher> (in press). </publisher>
Reference: <author> Cox, M. & Freed, M. </author> <year> (1994). </year> <title> Using knowledge of cognitive behavior to learn from failure. </title> <booktitle> In Proceedings of the Seventh International Conference on Systems Research, Informatics and Cybernetics, </booktitle> <pages> pp. 142-147 Baden-Baden, </pages> <address> Germany. </address>
Reference-contexts: There are several different recent approaches to the task of introspective reasoning: RAPTER (Freed & Collins, 1994a, 1994b) uses expectations about a reactive planning task to diagnose and repair failures, Meta-AQUA <ref> (Ram & Cox, 1994) </ref> maintains a set of templates for reasoning failures with applicable repairs to apply to failed reasoning traces, Au-tognostic (Stroulia & Goel, 1994) uses an Structure-Behavior-Function model of its own reasoning to find learning opportunities, and IULIAN (Oehlmann, Edwards, & Sleeman, 1994, 1995) uses questions about its own <p> Strou-lia's Autognostic (Stroulia & Goel, 1994) applies an existing kind of model (used for modeling physical machines) to implement a self-model and successfully applied the model and mechanisms to two independent systems (Kritik2 (Stroulia & Goel, 1992) and Router (Goel, Callantine, Shankar, & Chan-drasekaran, 1991)). Meta-AQUA <ref> (Ram & Cox, 1994) </ref> uses abstract descriptions of reasoning traces that might arise un der any similar reasoning/explanation task. Evaluating self-modeling systems It is often problematic in AI to explain exactly what a given system has accomplished besides showing some implementation is possible.
Reference: <author> Firby, R. J. </author> <year> (1989). </year> <title> Adaptive Execution in Complex Dynamic Worlds. </title> <type> Ph.D. thesis, </type> <institution> Yale University, Computer Science Department. </institution> <type> Technical Report 672. </type>
Reference-contexts: That performance task is performed by a case-based planner (Ham-mond, 1989; Alterman, 1986; Kolodner, 1993), combined with a simple reactive-style execution system <ref> (Firby, 1989) </ref>. Overarching the performance task is the task of learning introspectively about the planning and execution process itself, which is done using model-based reasoning about the sys tem's own reasoning process (Birnbaum et al., 1991; Collins, Birnbaum, Krulwich, & Freed, 1993; Birnbaum, Collins, Freed, & Krulwich, 1990).
Reference: <author> Fox, S. & Leake, D. </author> <year> (1994). </year> <title> Using introspective reasoning to guide index refinement in case-based reasoning. </title> <booktitle> In Proceedings of the Sixteenth Annual Conference of the Cognitive Science Society, </booktitle> <pages> pp. </pages> <address> 324-329 Atlanta, GA. </address> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference-contexts: Our approach, ROBBIE 1 <ref> (Fox & Leake, 1994) </ref>, models the desired behavior of its underlying case-based planning component as a set of expectations about the behavior of the system during the planning process. <p> The model structure preserves as much generality as possible by maintaining a hierarchy of assertions (expectations) which keep task- and implementation-specific details separate from generalities that might be more transferable to other tasks and domains <ref> (Fox & Leake, 1994) </ref>. 1 Re-Organization of Behavior By Introspective Evaluation Evaluating the method: Evaluation of AI systems is important to verify that the claims made about their performance actually hold. <p> We are in the process of performing extensive experiments to test ROB-BIE's performance over long sequences of problems. By collecting statistics on the success of the system with and without introspective learning, we can quantify its effect. Some tentative and preliminary results are in <ref> (Fox & Leake, 1994) </ref>. We have completed one set of experiments (described above) which used the number of successful cases over a sequence and the percentage of cases in memory considered during retrieval to reveal differences in ROBBIE performance with and without introspective reasoning.
Reference: <author> Freed, M. & Collins, G. </author> <year> (1994a). </year> <title> Adapting routines to improve task coordination. </title> <booktitle> In Proceedings of the 1994 Conference on AI Planning Systems, </booktitle> <pages> pp. 255-259. </pages>
Reference-contexts: All these tasks require knowledge about how the system reasons, and what the expected results of that reasoning are. There are several different recent approaches to the task of introspective reasoning: RAPTER <ref> (Freed & Collins, 1994a, 1994b) </ref> uses expectations about a reactive planning task to diagnose and repair failures, Meta-AQUA (Ram & Cox, 1994) maintains a set of templates for reasoning failures with applicable repairs to apply to failed reasoning traces, Au-tognostic (Stroulia & Goel, 1994) uses an Structure-Behavior-Function model of its own
Reference: <author> Freed, M. & Collins, G. </author> <year> (1994b). </year> <title> Learning to prevent task interactions. </title> <editor> In desJardins, M. & Ram, A. (Eds.), </editor> <booktitle> Proceedings of the 1994 AAAI Spring Symposium on Goal-driven Learning, </booktitle> <pages> pp. 28-35. </pages> <publisher> AAAI Press. </publisher>
Reference-contexts: Many other systems have also approached the problem of generality of mechanism and transferability. Cox & Freed (1994) identify knowledge about how general and specific knowledge combines as a key element for a self-reasoning system. Freed's RAPTER <ref> (Freed & Collins, 1994b) </ref> uses a general set of representations for expectations and repairs, and a general mechanism to manipulate them, while the content of its representations is specific to the RAPTER system.
Reference: <author> Goel, A., Callantine, T., Shankar, M., & Chandrasekaran, B. </author> <year> (1991). </year> <title> Representation, organization, and use of topographic models of physical spaces for route planning. </title> <booktitle> In Proceedings of the Seventh IEEE Conference on AI Applications, </booktitle> <pages> pp. 308-314. </pages> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: Strou-lia's Autognostic (Stroulia & Goel, 1994) applies an existing kind of model (used for modeling physical machines) to implement a self-model and successfully applied the model and mechanisms to two independent systems (Kritik2 (Stroulia & Goel, 1992) and Router <ref> (Goel, Callantine, Shankar, & Chan-drasekaran, 1991) </ref>). Meta-AQUA (Ram & Cox, 1994) uses abstract descriptions of reasoning traces that might arise un der any similar reasoning/explanation task. Evaluating self-modeling systems It is often problematic in AI to explain exactly what a given system has accomplished besides showing some implementation is possible.
Reference: <author> Hammond, C. </author> <year> (1989). </year> <title> Case-Based Planning: Viewing Planning as a Memory Task. </title> <publisher> Academic Press, </publisher> <address> San Diego. </address>
Reference: <author> Kolodner, J. </author> <year> (1993). </year> <title> Case-Based Reasoning. </title> <publisher> Morgan Kauf-man, </publisher> <address> San Mateo, CA. </address>
Reference: <author> Krulwich, B., Birnbaum, L., & Collins, G. </author> <year> (1992). </year> <title> Learning several lessons from one experience. </title> <booktitle> In Proceedings of the Fourteenth Annual Conference of the Cognitive Science Society, </booktitle> <pages> pp. </pages> <address> 242-247 Bloomington, </address> <publisher> IN. Cognitive Science Society. </publisher>
Reference: <author> Leake, D. </author> <year> (1992). </year> <title> Evaluating Explanations: A Content Theory. </title> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hillsdale, NJ. </address>
Reference: <author> Oehlmann, R., Edwards, P., & Sleeman, D. </author> <year> (1994). </year> <title> Changing the viewpoint: re-indexing by introspective questioning. </title> <booktitle> In Proceedings of the Sixteenth Annual Conference of the Cognitive Science Society, </booktitle> <pages> pp. 675-680. </pages> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference-contexts: a reactive planning task to diagnose and repair failures, Meta-AQUA (Ram & Cox, 1994) maintains a set of templates for reasoning failures with applicable repairs to apply to failed reasoning traces, Au-tognostic (Stroulia & Goel, 1994) uses an Structure-Behavior-Function model of its own reasoning to find learning opportunities, and IULIAN <ref> (Oehlmann, Edwards, & Sleeman, 1994, 1995) </ref> uses questions about its own reasoning and knowledge to re-index its memory and to regulate its processing.
Reference: <author> Oehlmann, R., Edwards, P., & Sleeman, D. </author> <year> (1995). </year> <title> Introspection planning: representing metacognitive experience. </title> <booktitle> In Proceedings of the 1995 AAAI Spring Symposium on Representing Mental States and Mechanisms. </booktitle> <publisher> (in press). </publisher>
Reference: <author> Ram, A. </author> <year> (1989). </year> <title> Question-driven understanding: An integrated theory of story understanding, memory and learning. </title> <type> Ph.D. thesis, </type> <institution> Yale University, New Haven, CT. Computer Science Department Technical Report 710. </institution>
Reference: <author> Ram, A. & Cox, M. </author> <year> (1994). </year> <title> Introspective reasoning using meta-explanations for multistrategy learning. </title> <editor> In Michalski, R. & Tecuci, G. (Eds.), </editor> <booktitle> Machine Learning: A multistrategy approach Vol. IV, </booktitle> <pages> pp. 349-377. </pages> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: There are several different recent approaches to the task of introspective reasoning: RAPTER (Freed & Collins, 1994a, 1994b) uses expectations about a reactive planning task to diagnose and repair failures, Meta-AQUA <ref> (Ram & Cox, 1994) </ref> maintains a set of templates for reasoning failures with applicable repairs to apply to failed reasoning traces, Au-tognostic (Stroulia & Goel, 1994) uses an Structure-Behavior-Function model of its own reasoning to find learning opportunities, and IULIAN (Oehlmann, Edwards, & Sleeman, 1994, 1995) uses questions about its own <p> Strou-lia's Autognostic (Stroulia & Goel, 1994) applies an existing kind of model (used for modeling physical machines) to implement a self-model and successfully applied the model and mechanisms to two independent systems (Kritik2 (Stroulia & Goel, 1992) and Router (Goel, Callantine, Shankar, & Chan-drasekaran, 1991)). Meta-AQUA <ref> (Ram & Cox, 1994) </ref> uses abstract descriptions of reasoning traces that might arise un der any similar reasoning/explanation task. Evaluating self-modeling systems It is often problematic in AI to explain exactly what a given system has accomplished besides showing some implementation is possible.
Reference: <author> Riesbeck, C. </author> <year> (1981). </year> <title> Failure-driven reminding for incremental learning. </title> <booktitle> In Proceedings of the Seventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 115-120 Vancouver, </address> <institution> B.C. IJCAI. </institution>
Reference: <author> Schank, R. </author> <year> (1986). </year> <title> Explanation Patterns: Understanding Mechanically and Creatively. </title> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hillsdale, NJ. </address>
Reference: <author> Stroulia, E. & Goel, A. </author> <year> (1992). </year> <title> Generic teleological mechanisms and their use in case adaptation. </title> <booktitle> In Proceedings of the Fourteenth Annual Conference of the Cognitive Science Society, </booktitle> <pages> pp. </pages> <address> 319-324 Bloomington, </address> <publisher> IN. Cognitive Science Society. </publisher>
Reference-contexts: Strou-lia's Autognostic (Stroulia & Goel, 1994) applies an existing kind of model (used for modeling physical machines) to implement a self-model and successfully applied the model and mechanisms to two independent systems (Kritik2 <ref> (Stroulia & Goel, 1992) </ref> and Router (Goel, Callantine, Shankar, & Chan-drasekaran, 1991)). Meta-AQUA (Ram & Cox, 1994) uses abstract descriptions of reasoning traces that might arise un der any similar reasoning/explanation task.
Reference: <author> Stroulia, E. & Goel, A. </author> <year> (1994). </year> <title> Task structures: what to learn?. </title> <editor> In desJardins, M. & Ram, A. (Eds.), </editor> <booktitle> Proceedings of the 1994 AAAI Spring Symposium on Goal-driven Learning, </booktitle> <pages> pp. 112-121. </pages> <publisher> AAAI Press. </publisher>
Reference-contexts: different recent approaches to the task of introspective reasoning: RAPTER (Freed & Collins, 1994a, 1994b) uses expectations about a reactive planning task to diagnose and repair failures, Meta-AQUA (Ram & Cox, 1994) maintains a set of templates for reasoning failures with applicable repairs to apply to failed reasoning traces, Au-tognostic <ref> (Stroulia & Goel, 1994) </ref> uses an Structure-Behavior-Function model of its own reasoning to find learning opportunities, and IULIAN (Oehlmann, Edwards, & Sleeman, 1994, 1995) uses questions about its own reasoning and knowledge to re-index its memory and to regulate its processing. <p> Freed's RAPTER (Freed & Collins, 1994b) uses a general set of representations for expectations and repairs, and a general mechanism to manipulate them, while the content of its representations is specific to the RAPTER system. Strou-lia's Autognostic <ref> (Stroulia & Goel, 1994) </ref> applies an existing kind of model (used for modeling physical machines) to implement a self-model and successfully applied the model and mechanisms to two independent systems (Kritik2 (Stroulia & Goel, 1992) and Router (Goel, Callantine, Shankar, & Chan-drasekaran, 1991)). <p> Other work has been less explicit about concrete means of evaluating systems. Cox (1995) has described classes of reasoning behavior and failures that people experience, and that systems which model reasoning behavior should address; that set provides a qualitative guide for judging models of reasoning. Autognostic <ref> (Stroulia & Goel, 1994) </ref> provides another kind of evaluation by directly proving the applicability of its model to different underlying systems. We have begun evaluating ROBBIE using a practically-oriented criterion: the addition of introspective reasoning should produce quantitative as well as qualitative improvements in the performance of the overall system.
References-found: 23

