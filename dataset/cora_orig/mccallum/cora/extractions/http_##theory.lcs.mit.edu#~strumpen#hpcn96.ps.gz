URL: http://theory.lcs.mit.edu/~strumpen/hpcn96.ps.gz
Refering-URL: http://theory.lcs.mit.edu/~strumpen/
Root-URL: 
Email: email: fstrumpen,ramkumar,tomc,reddyg@eng.uiowa.edu  
Title: Perspectives for High Performance Computing in Workstation Networks  
Author: Volker Strumpen, Balkrishna Ramkumar, Thomas L. Casavant and Sudhakar M. Reddy 
Address: Iowa, Iowa City, Iowa 52242  
Affiliation: Department of Electrical and Computer Engineering, University of  
Abstract: Networks of workstations have become increasingly popular for high performance computing. However, in order to become a real alternative for MPPs, reliability and efficiency issues must be tackled. In this paper, we identify the key challenges for very large workstation networks, and describe implementation techniques at system software level to overcome these problems. CROWN, a testbed for experimenting with these mechanisms is briefly discussed.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Thomas E. Anderson, David E. Culler, David A. Patterson, </author> <title> and the NOW team. A case for NOW (networks of workstations). </title> <journal> IEEE Micro, </journal> <volume> 15(1):5464, </volume> <month> February </month> <year> 1995. </year> <note> (URL http://now.cs.berkeley.edu/Papers/case.ps). </note>
Reference-contexts: Future performance development. We argue that the context for addressing the two problems identified above is a virtually dedicated network of high performance workstations which runs an operating system with a shifted protection boundary. In contrast to skimming idle cycles, as done by most other projects such as NOW <ref> [1] </ref> or PVM [11], our notion of a virtually dedicated system is a single-user system that provides quantitative predictability of resources and increased reliability. To avoid complete physical dedication, virtual dedication provides weaker guarantees for quality of service. <p> This kind of network computing on workstations has gained considerable attention since the PVM [11] and MPI [25] projects have attracted many users. Similar projects tackling the system level of network computing include <ref> [1, 5, 12, 14, 15, 16, 18, 29] </ref>. The technological developments eventually leading to NOWs as a primary compute resource have been analyzed in [1, 29]. PVM [11] is the most popular message passing system to date. <p> Similar projects tackling the system level of network computing include [1, 5, 12, 14, 15, 16, 18, 29]. The technological developments eventually leading to NOWs as a primary compute resource have been analyzed in <ref> [1, 29] </ref>. PVM [11] is the most popular message passing system to date. It provides a runtime library that is focused on a portable programmer interface for heterogeneous network computing. The user base of PVM is the scientific computing community. <p> PVM is not intended as a general purpose computing environment, but as a parallel programmer interface. Therefore, the PVM project does not tackle the challenges of the underlying system. In fact, PVM or MPI [25] are popular candidates for a programmer interface of CROWN. The Berkeley NOW project <ref> [1] </ref> focuses on providing a network of workstations as a general purpose computer. The reasoning for NOW is very similar to that of CROWN. However, the goals and philosophies are different. The philosophy of NOW does not rate parallel computing as a topic of primary importance. Instead, [1] states: : : <p> Berkeley NOW project <ref> [1] </ref> focuses on providing a network of workstations as a general purpose computer. The reasoning for NOW is very similar to that of CROWN. However, the goals and philosophies are different. The philosophy of NOW does not rate parallel computing as a topic of primary importance. Instead, [1] states: : : : the challenge is to make NOW a win for all users it should deliver at least the interactive performance of a dedicated workstation while providing the aggregate resources of the network for demanding sequential and parallel programs.
Reference: 2. <author> D. Banks and M. Prudence. </author> <title> A high-performance network architecture for a PA-RISC work-station. </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> 11(2):191202, </volume> <month> February </month> <year> 1993. </year>
Reference-contexts: The numbers reported are similar to the communication latency hiding capability of stock workstation hardware reported in [29]. The effects of reducing the copies in the communication protocol's data path are reported in <ref> [2, 6, 7, 23, 31, 32] </ref>. All these approaches have a common objective: Increasing performance while maintaining existing protection mechanisms or boundaries. We argue that these approaches tackle only the tip of the iceberg. Abandoning nearly all kernel protection will allow for substantial performance improvements.
Reference: 3. <author> Gordon Bell. </author> <title> Ultracomputers a teraflop before its time. </title> <journal> Communications of the ACM, </journal> <volume> 35(8):2747, </volume> <month> August </month> <year> 1992. </year>
Reference-contexts: The most important mandate for HPC in the years to come will be to be able to address such applications for a wide community of users. This will require the following three system characteristics: (1) Scalability, with respect to workstation and network generations <ref> [3] </ref> as well as performance and system configuration; (2) Accessibility of the system to a geographically dispersed community of users; (3) Affordability of the system to this community of users. Supercomputers, MPPs, and current NOW-based systems do not effectively satisfy one or more of these requirements.
Reference: 4. <author> Brian N. Bershad, Craig Chambers, Susan Eggers, Chris Maeda, Dylan McNamee, Przemyslaw Pardyak, Stefan Savage, and Emin Gun Sirer. </author> <title> SPIN an extensible microkernel for application-specific operating system services. </title> <type> Technical Report UWCSE-94-03-03, </type> <institution> Department of Computer Science and Engineering, University of Washington, </institution> <month> February </month> <year> 1994. </year> <note> (URL ftp://ftp.cs.washington.edu/tr/1994/03/ UW-CSE-94-03-03.PS.Z). </note>
Reference-contexts: A large amount of work concentrates on shifting functionalities out of the kernel into the application's non-privileged user-level, ranging from communication protocols [7, 20, 31] to new customizable operating system design <ref> [4, 8, 19, 24] </ref>. Performance can also be improved by keeping the data path within the kernel and prevent it from crossing the kernel-user boundary to avoid unnecessary context switches. This is advantageous for applications that stream data from one device to another.
Reference: 5. <author> Robert D. Blumofe, Christopher F. Joerg, Bradley C. Kuszmaul, Charles E. Leiserson, Keith H. Randall, and Yuli Zhou. Cilk: </author> <title> An efficient multithreaded runtime system. </title> <booktitle> In 5th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, pages 207216, </booktitle> <address> Santa Barbara, California, </address> <month> July </month> <year> 1995. </year>
Reference-contexts: This kind of network computing on workstations has gained considerable attention since the PVM [11] and MPI [25] projects have attracted many users. Similar projects tackling the system level of network computing include <ref> [1, 5, 12, 14, 15, 16, 18, 29] </ref>. The technological developments eventually leading to NOWs as a primary compute resource have been analyzed in [1, 29]. PVM [11] is the most popular message passing system to date.
Reference: 6. <author> Jose C. Brustoloni and Brian N. Berschad. </author> <title> Simple protocol processing for high-bandwidth low-latency networking. </title> <type> Technical Report CMU-CS-93-132, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <month> March </month> <year> 1992. </year>
Reference-contexts: The numbers reported are similar to the communication latency hiding capability of stock workstation hardware reported in [29]. The effects of reducing the copies in the communication protocol's data path are reported in <ref> [2, 6, 7, 23, 31, 32] </ref>. All these approaches have a common objective: Increasing performance while maintaining existing protection mechanisms or boundaries. We argue that these approaches tackle only the tip of the iceberg. Abandoning nearly all kernel protection will allow for substantial performance improvements.
Reference: 7. <author> Peter Druschel and Larry L. Peterson. Fbufs: </author> <title> A high-bandwidth cross-domain trans-fer facility. </title> <booktitle> In 14th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 189202, </pages> <address> Asheville, North Carolina, </address> <month> December </month> <year> 1993. </year> <note> (URL file://ftp.cs.arizona.edu/ xkernel/Papers/fbuf.ps). </note>
Reference-contexts: A large amount of work concentrates on shifting functionalities out of the kernel into the application's non-privileged user-level, ranging from communication protocols <ref> [7, 20, 31] </ref> to new customizable operating system design [4, 8, 19, 24]. Performance can also be improved by keeping the data path within the kernel and prevent it from crossing the kernel-user boundary to avoid unnecessary context switches. <p> The numbers reported are similar to the communication latency hiding capability of stock workstation hardware reported in [29]. The effects of reducing the copies in the communication protocol's data path are reported in <ref> [2, 6, 7, 23, 31, 32] </ref>. All these approaches have a common objective: Increasing performance while maintaining existing protection mechanisms or boundaries. We argue that these approaches tackle only the tip of the iceberg. Abandoning nearly all kernel protection will allow for substantial performance improvements.
Reference: 8. <author> Dawson R. Engler, M. Frans Kaashoek, and James W. O'Toole, Jr. </author> <title> The operat-ing system kernel as a secure programmable machine. </title> <note> To appear in Operating Systems Review, Special Issue on Extensible Operating Systems, 1995. (URL http://www.pdos.lcs.mit.edu/engler/xsigops.ps). </note>
Reference-contexts: A large amount of work concentrates on shifting functionalities out of the kernel into the application's non-privileged user-level, ranging from communication protocols [7, 20, 31] to new customizable operating system design <ref> [4, 8, 19, 24] </ref>. Performance can also be improved by keeping the data path within the kernel and prevent it from crossing the kernel-user boundary to avoid unnecessary context switches. This is advantageous for applications that stream data from one device to another.
Reference: 9. <author> Kevin Fall and Joseph Pasquale. </author> <title> Exploiting in-kernel data paths to improve I/O throughput and CPU availability. </title> <booktitle> In 1993 Winter USENIX Conference, </booktitle> <pages> pages 327333, </pages> <address> San Diego, California, </address> <month> January </month> <year> 1993. </year> <institution> USENIX Association. </institution>
Reference-contexts: Performance can also be improved by keeping the data path within the kernel and prevent it from crossing the kernel-user boundary to avoid unnecessary context switches. This is advantageous for applications that stream data from one device to another. Fall and Pasquale <ref> [9] </ref> report increased data transfer bandwidth as well as a higher availability of the CPU for other useful (interleaved) computation. The numbers reported are similar to the communication latency hiding capability of stock workstation hardware reported in [29].
Reference: 10. <author> ATM Forum. </author> <title> ATM User-Network Interface Specification. </title> <publisher> Prentice-Hall, </publisher> <address> New Jersey, </address> <year> 1995. </year>
Reference-contexts: The Internet, which currently connects open systems is not dedicated, and the resources available to a single user are not predictable. Future networking technologies such as ATM that should provide guaranteed bandwidth to a virtual channel <ref> [10] </ref> are promising. If this bandwidth can be negotiated, it is straightforward to incorporate ATM networks into a market model that offer quality of service based on cost.
Reference: 11. <author> A. Geist, A. Beguelin, J. Dongarra, W. Jiang, R. Manchek, and V. Sunderam. </author> <title> PVM: Parallel Virtual Machine A Users' Guide and Tutorial for Networked Parallel Computing. </title> <publisher> MIT Press, </publisher> <address> Cambridge, </address> <year> 1994. </year>
Reference-contexts: We argue that the context for addressing the two problems identified above is a virtually dedicated network of high performance workstations which runs an operating system with a shifted protection boundary. In contrast to skimming idle cycles, as done by most other projects such as NOW [1] or PVM <ref> [11] </ref>, our notion of a virtually dedicated system is a single-user system that provides quantitative predictability of resources and increased reliability. To avoid complete physical dedication, virtual dedication provides weaker guarantees for quality of service. <p> The general idea arising from this situation has been to skim off the idle cycles from time-shared workstations, and make them available for parallel computing. This kind of network computing on workstations has gained considerable attention since the PVM <ref> [11] </ref> and MPI [25] projects have attracted many users. Similar projects tackling the system level of network computing include [1, 5, 12, 14, 15, 16, 18, 29]. The technological developments eventually leading to NOWs as a primary compute resource have been analyzed in [1, 29]. PVM [11] is the most popular <p> attention since the PVM <ref> [11] </ref> and MPI [25] projects have attracted many users. Similar projects tackling the system level of network computing include [1, 5, 12, 14, 15, 16, 18, 29]. The technological developments eventually leading to NOWs as a primary compute resource have been analyzed in [1, 29]. PVM [11] is the most popular message passing system to date. It provides a runtime library that is focused on a portable programmer interface for heterogeneous network computing. The user base of PVM is the scientific computing community.
Reference: 12. <author> David Gelernter and David Kaminsky. </author> <title> Supercomputing out of recycled garbage: Preliminary experience with Piranha. </title> <booktitle> In 1992 ACM International Conference on Supercomputing, </booktitle> <pages> pages 417427, </pages> <address> Washington, D.C., </address> <month> July </month> <year> 1992. </year>
Reference-contexts: This kind of network computing on workstations has gained considerable attention since the PVM [11] and MPI [25] projects have attracted many users. Similar projects tackling the system level of network computing include <ref> [1, 5, 12, 14, 15, 16, 18, 29] </ref>. The technological developments eventually leading to NOWs as a primary compute resource have been analyzed in [1, 29]. PVM [11] is the most popular message passing system to date.
Reference: 13. <author> Jim Gray. </author> <title> A census of tandem systems. </title> <journal> IEEE Transactions on Reliability, </journal> <volume> 39(4):409418, </volume> <month> October </month> <year> 1990. </year>
Reference-contexts: Only with a sound organization that ensures security, and is capable of motivating owners of machines to participate in a very large configuration, can this problem be solved. Reliability. Usually, reliability is being viewed as an absolute characteristic of systems that must be delivered at any cost. Tandem systems <ref> [13, 17] </ref> are an example of this approach. Another notion of reliability is the probabilistic performability measure [22] which combines performance and dependability, and models the accomplishment (reward) made by the system at user-level.
Reference: 14. <author> Andrew S. Grimshaw, William A. Wulf, James C. French, Alfred C. Weaver, and Paul F. Reynolds, Jr. Legion: </author> <title> The next logical step towards a nationwide virtual computer. </title> <type> Technical Report CS-94-21, </type> <institution> Department of Computer Science, University of Virginia, </institution> <month> June </month> <year> 1994. </year>
Reference-contexts: This kind of network computing on workstations has gained considerable attention since the PVM [11] and MPI [25] projects have attracted many users. Similar projects tackling the system level of network computing include <ref> [1, 5, 12, 14, 15, 16, 18, 29] </ref>. The technological developments eventually leading to NOWs as a primary compute resource have been analyzed in [1, 29]. PVM [11] is the most popular message passing system to date.
Reference: 15. <author> Laxmikant V. Kale. </author> <title> The Chare kernel parallel programming language and system. </title> <booktitle> In International Conference on Parallel Processing, </booktitle> <volume> volume II, </volume> <pages> pages 1725. </pages> <publisher> IEEE, </publisher> <month> August </month> <year> 1990. </year>
Reference-contexts: This kind of network computing on workstations has gained considerable attention since the PVM [11] and MPI [25] projects have attracted many users. Similar projects tackling the system level of network computing include <ref> [1, 5, 12, 14, 15, 16, 18, 29] </ref>. The technological developments eventually leading to NOWs as a primary compute resource have been analyzed in [1, 29]. PVM [11] is the most popular message passing system to date.
Reference: 16. <author> H. T. Kung, R. Sansom, S. Schlick, P. A. Steenkiste, M. Arnould, F. J. Bitz, E. C. Cooper, O. Manzilcioglu, D. Ombres, and B. Zill. </author> <title> Network-based multicomputers: An emerging parallel architecture. </title> <booktitle> In Supercomputing '91, </booktitle> <pages> pages 664673, </pages> <address> Albuquerque, New Mexico, </address> <month> November </month> <year> 1991. </year>
Reference-contexts: This kind of network computing on workstations has gained considerable attention since the PVM [11] and MPI [25] projects have attracted many users. Similar projects tackling the system level of network computing include <ref> [1, 5, 12, 14, 15, 16, 18, 29] </ref>. The technological developments eventually leading to NOWs as a primary compute resource have been analyzed in [1, 29]. PVM [11] is the most popular message passing system to date.
Reference: 17. <author> Inhwan Lee and Ravishankar K. Iyer. </author> <title> Faults, symptoms, and software fault tolerance in the tandem guardian90 operating system. </title> <booktitle> In 23rd International Symposium on Fault-Tolerant Computing, pages 2029, </booktitle> <year> 1993. </year>
Reference-contexts: Only with a sound organization that ensures security, and is capable of motivating owners of machines to participate in a very large configuration, can this problem be solved. Reliability. Usually, reliability is being viewed as an absolute characteristic of systems that must be delivered at any cost. Tandem systems <ref> [13, 17] </ref> are an example of this approach. Another notion of reliability is the probabilistic performability measure [22] which combines performance and dependability, and models the accomplishment (reward) made by the system at user-level.
Reference: 18. <author> M. J. Litzkow, M. Livny, and M. W. </author> <title> Mutka. Condor a hunter of idle workstations. </title> <booktitle> In 8th International Conference on Distributed Computing Systems, </booktitle> <pages> pages 104111, </pages> <address> San Jose, California, </address> <month> July </month> <year> 1988. </year>
Reference-contexts: This kind of network computing on workstations has gained considerable attention since the PVM [11] and MPI [25] projects have attracted many users. Similar projects tackling the system level of network computing include <ref> [1, 5, 12, 14, 15, 16, 18, 29] </ref>. The technological developments eventually leading to NOWs as a primary compute resource have been analyzed in [1, 29]. PVM [11] is the most popular message passing system to date.
Reference: 19. <author> Steven Lucco. </author> <title> Bridge integrated multiserver project, </title> <note> 1995. (URL http://www.cs. cmu.edu/afs/cs/project/sfi/www/top.html). </note>
Reference-contexts: A large amount of work concentrates on shifting functionalities out of the kernel into the application's non-privileged user-level, ranging from communication protocols [7, 20, 31] to new customizable operating system design <ref> [4, 8, 19, 24] </ref>. Performance can also be improved by keeping the data path within the kernel and prevent it from crossing the kernel-user boundary to avoid unnecessary context switches. This is advantageous for applications that stream data from one device to another.
Reference: 20. <author> Chris Maeda and Brian N. Bershad. </author> <title> Protocol service decomposition for high-performance networking. </title> <booktitle> In 14th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 244255, </pages> <address> Asheville, North Carolina, </address> <month> December </month> <year> 1993. </year>
Reference-contexts: A large amount of work concentrates on shifting functionalities out of the kernel into the application's non-privileged user-level, ranging from communication protocols <ref> [7, 20, 31] </ref> to new customizable operating system design [4, 8, 19, 24]. Performance can also be improved by keeping the data path within the kernel and prevent it from crossing the kernel-user boundary to avoid unnecessary context switches.
Reference: 21. <author> Miroslaw Malek, Andreas Polze, and Matthias Werner. </author> <title> A framework for responsive paral-lel computing in network-based systems. </title> <booktitle> In International Workshop on Advanced Parallel Processing Technologies, </booktitle> <pages> pages 335343, </pages> <address> Bejing, China, </address> <month> September </month> <year> 1995. </year>
Reference-contexts: A large body of work exists on fault tolerance above the operating system level to enhance the reliability of parallel programs. Some efforts consider fault tolerance at all levels of system design, for example the responsive systems approach <ref> [21] </ref>. However, there is no agreement on how to provide application fault tolerance transparently in general. Today's availability of workstations is not suited for large-scale network computing. Wood [34] analyzed the availability of a `typical' client/server architecture comprising 1,000 desktop machines.
Reference: 22. <author> John F. Meyer. Performability: </author> <title> A retrospective and some pointers to the future. Performance Evaluation, </title> <address> 14(34):139156, </address> <month> February </month> <year> 1992. </year>
Reference-contexts: Reliability. Usually, reliability is being viewed as an absolute characteristic of systems that must be delivered at any cost. Tandem systems [13, 17] are an example of this approach. Another notion of reliability is the probabilistic performability measure <ref> [22] </ref> which combines performance and dependability, and models the accomplishment (reward) made by the system at user-level. Up to now, fault tolerance issues have been treated extensively at the hardware and operating system level.
Reference: 23. <author> Ron Minnich, Dan Burns, and Frank Hady. </author> <title> The memory-integrated network interface. </title> <journal> IEEE Micro, </journal> <volume> 15(1):1120, </volume> <month> February </month> <year> 1995. </year>
Reference-contexts: The numbers reported are similar to the communication latency hiding capability of stock workstation hardware reported in [29]. The effects of reducing the copies in the communication protocol's data path are reported in <ref> [2, 6, 7, 23, 31, 32] </ref>. All these approaches have a common objective: Increasing performance while maintaining existing protection mechanisms or boundaries. We argue that these approaches tackle only the tip of the iceberg. Abandoning nearly all kernel protection will allow for substantial performance improvements.
Reference: 24. <author> Allen B. Montz, David Mosberger, Sean W. O'Malley, Larry L. Peterson, Todd A. Proebsting, and John H. Hartman. </author> <title> Scout: A communications-oriented operating system. </title> <type> Technical Report TR 94-20, </type> <institution> Department of Computer Science, University of Arizona, </institution> <month> June </month> <year> 1994. </year>
Reference-contexts: A large amount of work concentrates on shifting functionalities out of the kernel into the application's non-privileged user-level, ranging from communication protocols [7, 20, 31] to new customizable operating system design <ref> [4, 8, 19, 24] </ref>. Performance can also be improved by keeping the data path within the kernel and prevent it from crossing the kernel-user boundary to avoid unnecessary context switches. This is advantageous for applications that stream data from one device to another.
Reference: 25. <author> MPI: </author> <title> A Message-Passing Interface Standard. Message Passing Interface Forum, </title> <month> April </month> <year> 1994. </year> <title> (Distribution: </title> <type> netlib). </type>
Reference-contexts: The general idea arising from this situation has been to skim off the idle cycles from time-shared workstations, and make them available for parallel computing. This kind of network computing on workstations has gained considerable attention since the PVM [11] and MPI <ref> [25] </ref> projects have attracted many users. Similar projects tackling the system level of network computing include [1, 5, 12, 14, 15, 16, 18, 29]. The technological developments eventually leading to NOWs as a primary compute resource have been analyzed in [1, 29]. <p> The user base of PVM is the scientific computing community. PVM is not intended as a general purpose computing environment, but as a parallel programmer interface. Therefore, the PVM project does not tackle the challenges of the underlying system. In fact, PVM or MPI <ref> [25] </ref> are popular candidates for a programmer interface of CROWN. The Berkeley NOW project [1] focuses on providing a network of workstations as a general purpose computer. The reasoning for NOW is very similar to that of CROWN. However, the goals and philosophies are different.
Reference: 26. <author> J. H. Saltzer, D. P. Reed, and D. D. Clark. </author> <title> End-to-end argmuments in system design. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 2(4):277288, </volume> <month> November </month> <year> 1984. </year>
Reference-contexts: Up to now, fault tolerance issues have been treated extensively at the hardware and operating system level. Several subsystems of operating systems have been designed with respect to the end-to-end argument <ref> [26] </ref> that address fault tolerance issues at the operating system level. A large body of work exists on fault tolerance above the operating system level to enhance the reliability of parallel programs. Some efforts consider fault tolerance at all levels of system design, for example the responsive systems approach [21].
Reference: 27. <author> Chris Sander, Reinhard Schneider, and Pieter Stouten. </author> <title> The human genome and high perfor-mance computing in molecular biology. </title> <editor> In H. W. Meuer, editor, Supercomputer'92, </editor> <booktitle> Anwendungen, Architekturen, Trends, </booktitle> <pages> pages 3248. </pages> <publisher> Springer-Verlag, </publisher> <year> 1992. </year>
Reference-contexts: Vector supercomputers are expensive and MPPs are not cost-effective and often considered difficult to program. NOWs suffer from high latencies and scheduling overhead that is endemic in time-shared environments. and includes an estimate for the necessary computation power of a protein folding problem <ref> [27] </ref>. The most important mandate for HPC in the years to come will be to be able to address such applications for a wide community of users.
Reference: 28. <author> Volker Strumpen. </author> <title> Coupling Hundreds of Workstations for Parallel Molecular Sequence Analysis. </title> <journal> Software Practice and Experience, </journal> <volume> 25(3):291304, </volume> <month> March </month> <year> 1995. </year>
Reference-contexts: Accessibility. Whereas accessibility has been demonstrated in a large academic environment comprising about 1,000 machines <ref> [28] </ref>, this issue is a major psychological and administrative problem in general. Only with a sound organization that ensures security, and is capable of motivating owners of machines to participate in a very large configuration, can this problem be solved. Reliability.
Reference: 29. <author> Volker Strumpen. </author> <title> The Network Machine. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, Swiss Federal Institute of Technoloy (ETH) Zurich, </institution> <year> 1995. </year> <note> (URL ftp://ftp.inf. ethz.ch/pub/publications/dissertations/th11227.ps.Z). </note>
Reference-contexts: Fall and Pasquale [9] report increased data transfer bandwidth as well as a higher availability of the CPU for other useful (interleaved) computation. The numbers reported are similar to the communication latency hiding capability of stock workstation hardware reported in <ref> [29] </ref>. The effects of reducing the copies in the communication protocol's data path are reported in [2, 6, 7, 23, 31, 32]. All these approaches have a common objective: Increasing performance while maintaining existing protection mechanisms or boundaries. We argue that these approaches tackle only the tip of the iceberg. <p> This kind of network computing on workstations has gained considerable attention since the PVM [11] and MPI [25] projects have attracted many users. Similar projects tackling the system level of network computing include <ref> [1, 5, 12, 14, 15, 16, 18, 29] </ref>. The technological developments eventually leading to NOWs as a primary compute resource have been analyzed in [1, 29]. PVM [11] is the most popular message passing system to date. <p> Similar projects tackling the system level of network computing include [1, 5, 12, 14, 15, 16, 18, 29]. The technological developments eventually leading to NOWs as a primary compute resource have been analyzed in <ref> [1, 29] </ref>. PVM [11] is the most popular message passing system to date. It provides a runtime library that is focused on a portable programmer interface for heterogeneous network computing. The user base of PVM is the scientific computing community.
Reference: 30. <author> Volker Strumpen and Thomas L. Casavant. </author> <title> Implementing Communication Latency Hiding in High-Latency Computer Networks. </title> <booktitle> In High-Performance Computing and Networking, </booktitle> <volume> LNCS 919, </volume> <pages> pages 8693. </pages> <publisher> Springer-Verlag, </publisher> <address> Milano, Italy, </address> <month> May </month> <year> 1995. </year>
Reference-contexts: We argue that these approaches tackle only the tip of the iceberg. Abandoning nearly all kernel protection will allow for substantial performance improvements. Besides speeding up hardware access locally, system functionalities involving network access such as interprocess communication <ref> [30] </ref>, file access, scheduling, replication of checkpoints and recovery need to be accelerated or hidden.
Reference: 31. <author> Moti N. Thadani and Yousef A. Khalidi. </author> <title> An efficient zero-copy I/O framework for UNIX. </title> <type> Technical Report SMLI TR-95-39, </type> <institution> Sun Microsystems Laboratories, </institution> <month> May </month> <year> 1995. </year>
Reference-contexts: A large amount of work concentrates on shifting functionalities out of the kernel into the application's non-privileged user-level, ranging from communication protocols <ref> [7, 20, 31] </ref> to new customizable operating system design [4, 8, 19, 24]. Performance can also be improved by keeping the data path within the kernel and prevent it from crossing the kernel-user boundary to avoid unnecessary context switches. <p> The numbers reported are similar to the communication latency hiding capability of stock workstation hardware reported in [29]. The effects of reducing the copies in the communication protocol's data path are reported in <ref> [2, 6, 7, 23, 31, 32] </ref>. All these approaches have a common objective: Increasing performance while maintaining existing protection mechanisms or boundaries. We argue that these approaches tackle only the tip of the iceberg. Abandoning nearly all kernel protection will allow for substantial performance improvements.
Reference: 32. <author> C. A. Thekkath, H. M. Levy, and E. D. Lazowska. </author> <title> Efficient support for multicomputing on ATM networks. </title> <type> Technical Report 93-04-03, </type> <institution> Department of Computer Science and Engineering, University of Washington, </institution> <month> April </month> <year> 1993. </year>
Reference-contexts: The numbers reported are similar to the communication latency hiding capability of stock workstation hardware reported in [29]. The effects of reducing the copies in the communication protocol's data path are reported in <ref> [2, 6, 7, 23, 31, 32] </ref>. All these approaches have a common objective: Increasing performance while maintaining existing protection mechanisms or boundaries. We argue that these approaches tackle only the tip of the iceberg. Abandoning nearly all kernel protection will allow for substantial performance improvements.
Reference: 33. <author> Robert Wahbe, Steven Lucco, Thomas E. Anderson, and Susan L. Graham. </author> <title> Efficient software-based fault isolation. </title> <booktitle> In 14th ACM Symposium on Operating Systems Principles, pages 203216, </booktitle> <address> Asheville, North Carolina, </address> <month> December </month> <year> 1993. </year>
Reference-contexts: However, this will not always be possible. We do not know yet, which method will be the best. Nevertheless, there are several options prone to investigation: Runtime checks might be necessary which could be based on techniques such as software based fault isolation <ref> [33] </ref>.
Reference: 34. <author> Alan Wood. </author> <title> Predicting client/server availability. </title> <journal> IEEE Computer, </journal> <volume> 28(4):4148, </volume> <month> April </month> <year> 1995. </year> <title> This article was processed using the L A T E X macro package with LLNCS style </title>
Reference-contexts: For such a system to be viable and effective, two technical challenges have to be overcome: Reliability: A very large geographically distributed system of workstations suffer from poor availability. Figure 2 illustrates the availability of workstations based on failure data gathered by Wood <ref> [34] </ref>. The dramatic loss of availability with growing numbers of processors prevents scalability. Efficiency: The current Internet is flooded by information retrieval traffic and has become essentially unusable for HPC. Furthermore, the overheads and poor reliability of conventional operating systems are likely to hinder efficient HPC. Fig. 1. <p> Some efforts consider fault tolerance at all levels of system design, for example the responsive systems approach [21]. However, there is no agreement on how to provide application fault tolerance transparently in general. Today's availability of workstations is not suited for large-scale network computing. Wood <ref> [34] </ref> analyzed the availability of a `typical' client/server architecture comprising 1,000 desktop machines. He found that over a one year period, a single machine was available on average 97.7 % of the time.
References-found: 34

