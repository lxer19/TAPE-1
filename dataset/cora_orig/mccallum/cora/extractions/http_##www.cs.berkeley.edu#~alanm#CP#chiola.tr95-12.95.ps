URL: http://www.cs.berkeley.edu/~alanm/CP/chiola.tr95-12.95.ps
Refering-URL: http://www.cs.berkeley.edu/~alanm/CP/bib.html
Root-URL: 
Title: Operating System Support for Fast Communications in a Network of Workstations  
Author: G. Chiola and G. Ciaccio 
Date: May 9, 1996,  
Web: URL: "http://www.disi.unige.it/"  
Address: Genova  
Affiliation: DISI, Universita di  Technical  
Pubnum: Report DISI-TR-96-12  
Abstract: The use of workstations connected by a fast Local Area Network (LAN) is a very appealing idea to implement a low-cost parallel processing platform. Asynchronous processes are easily run in parallel on several computing units in such a hardware platform. Inter-process communication is the most difficult feature for such a system to implement with an acceptable level of performance. Standard software environments (such as PVM and MPI) have been conceived and implemented which allow the application programmer to write well structured parallel code with a high degree of independence with respect to the hardware platform. However, implementations of MPI primitives in a Network Of Workstations (NOW) usually do not provide satisfactory performance compared to the same program run on a "real parallel platform." We claim that this inefficiency is mainly due to lack of efficient operating system support for communication in a LAN environment. We show how a standard, Unix-like operating system can be modified in order to provide efficient support for "active message" communications that can be viewed as a primitive form of interprocess communication in a distributed environment. We provide some preliminary results obtained from an experimental implementation of an active message layer based on modifications of the Linux kernel called GAMMA (Genoa Active Message MAchine).
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> V. Sunderam. </author> <title> PVM: A framework for parallel distributed computing. </title> <journal> Concurrency: Practice and Experience, </journal> <pages> pages 315-339, </pages> <month> December </month> <year> 1990. </year>
Reference-contexts: In the last few years research on the topic has led to a number of standard parallel programming environments such as PVM <ref> [1] </ref> and MPI [2], that are becoming de-facto standards and that allow transparent porting of parallel applications on different platforms.
Reference: [2] <author> The Message Passing Interface Forum. </author> <title> MPI: A message passing interface standard. </title> <type> Technical report, </type> <institution> University of Tennessee, Knoxville, Tennessee, </institution> <year> 1995. </year> <note> URL ftp://ftp.mcs.anl.gov/pub/mpi/mpi-1.jun95/mpi-report.ps. </note>
Reference-contexts: In the last few years research on the topic has led to a number of standard parallel programming environments such as PVM [1] and MPI <ref> [2] </ref>, that are becoming de-facto standards and that allow transparent porting of parallel applications on different platforms.
Reference: [3] <author> T. von Eicken, A. Basu, V. Buch, and W. Vogels. U-Net: </author> <title> A user-level network interface for parallel and distributed computing. </title> <booktitle> In Proc. 15th ACM Symp. on Operating Systems Principles, </booktitle> <address> Copper Mountain, Colorado, </address> <month> December </month> <year> 1995. </year> <note> ACM Press. URL http://www.cs.cornell.edu/Info/Projects/U-Net/sosp.ps. </note>
Reference-contexts: We are mainly interested in the first issue, even though we believe that a re-design of the protocol stack architecture could improve performance also in the second case, as already proven in <ref> [3] </ref>. <p> In order to experiment this idea we also chose a standard operating system for which source code is freely available, namely the Linux system in its experimental version 1.3.72. A somehow similar approach was followed also by researchers at Cornell University in the framework of the U-net project <ref> [3] </ref>. <p> However we do not expect the overhead of the MPI implementation over GAMMA to increase message latency in a substantial way. The comparison with the U-net emulation of active messages <ref> [3] </ref> appears instead to be fair (data are desumed from the cited paper). In this case the hardware platform is constituted by 60 MHz SuperSPARC workstations connected by 140 MHz ATM.
Reference: [4] <author> G. Burns, R. Daoud, and J. Vaigl. LAM: </author> <title> An open cluster environment for MPI. </title> <type> Technical report, </type> <institution> Ohio Supercomputer Center, Columbus, Ohio, </institution> <year> 1994. </year> <note> URL http://www.epm.ornl.gov/~walker/mpi/papers/lam-mpi.ps. 15 </note>
Reference-contexts: We are mainly interested in the first issue, even though we believe that a re-design of the protocol stack architecture could improve performance also in the second case, as already proven in [3]. Today's implementations of PVM and MPI environments on NOW platforms <ref> [4, 5] </ref> are based on daemons that use (inefficient) Unix IPC primitives implemented on top of huge communication protocols developed a long time ago that had completely different goals as compared to the actual purposes they are mostly used for today.
Reference: [5] <author> W. Gropp and E. Lusk. </author> <title> User's guide for mpich, a portable implementation of MPI. </title> <type> Technical Report MCS-TM-ANL-96/6, </type> <institution> Argonne National Lab., University of Chicago, </institution> <year> 1996. </year> <note> URL ftp://info.mcs.anl.gov/pub/mpi/userguide.ps. </note>
Reference-contexts: We are mainly interested in the first issue, even though we believe that a re-design of the protocol stack architecture could improve performance also in the second case, as already proven in [3]. Today's implementations of PVM and MPI environments on NOW platforms <ref> [4, 5] </ref> are based on daemons that use (inefficient) Unix IPC primitives implemented on top of huge communication protocols developed a long time ago that had completely different goals as compared to the actual purposes they are mostly used for today.
Reference: [6] <author> T. von Eicken, D.E. Culler, S.C. Goldstein, and K.E. Schauser. </author> <title> Active messages: A mechanism for integrated communication and computation. </title> <booktitle> In Proc. 19th Int. Symp. on Computer Architecture, </booktitle> <address> Gold Coast, Australia, May 1992. </address> <publisher> ACM Press. </publisher>
Reference-contexts: Active Messages were originally proposed by researchers at the University of California at Berke-ley <ref> [6] </ref>, as a flexible and efficient low-level communication mechanism aimed at reducing communication overhead and allowing communication to overlap computation. The efficiency of the Active Messages communication mechanisms lies in the fact that they do not require message buffering.
Reference: [7] <institution> Connection machine CM-5 technical summary. </institution> <type> Technical report, </type> <institution> Thinking Machines Corporation, Cambridge, Massachusetts, </institution> <year> 1992. </year>
Reference-contexts: The efficiency of the Active Messages communication mechanisms lies in the fact that they do not require message buffering. A well known application of Active Messages as operating system support for fast interconnection networks is the Active Message Layer introduced by Thinking Machines Co. in the CM-5 platform <ref> [7] </ref>. In that case a minimal set of communication primitives was identified and supported in an efficient way by modifying the kernel of a Unix operating system.
Reference: [8] <author> L.T. Liu and D.E. Culler. </author> <title> Measurement of active message performance on the CM-5. </title> <type> Technical Report CSD-94-807, </type> <institution> Computer Science Dept., University of California at Berkeley, </institution> <month> May </month> <year> 1994. </year> <note> URL ftp://cs-tr.cs.berkeley.edu/pub/tech-reports/csd/csd-94-807/all.ps. </note>
Reference-contexts: Throughput and message delay as experienced by applications can thus be very close to the limit posed by the hardware devices <ref> [8] </ref>. The same idea has been followed and is still currently being followed even by others such as the FM project [9] developed by researchers of the University of Illinois at Urbana Champain on a fast LAN called Myrinet instead of the Fat Tree interconnection network of the CM-5 platform.
Reference: [9] <author> S. Pakin, M. Lauria, and A. Chien. </author> <title> High performance messaging on workstations: Illinois fast messages (FM) for myrinet computation. </title> <booktitle> In Proc. Supercomputing '95, </booktitle> <address> San Diego, California, 1995. </address> <publisher> ACM Press. </publisher> <address> URL http://www-csag.cs.uiuc.edu/papers/myrinet-fm-sc95.ps. </address>
Reference-contexts: Throughput and message delay as experienced by applications can thus be very close to the limit posed by the hardware devices [8]. The same idea has been followed and is still currently being followed even by others such as the FM project <ref> [9] </ref> developed by researchers of the University of Illinois at Urbana Champain on a fast LAN called Myrinet instead of the Fat Tree interconnection network of the CM-5 platform.
Reference: [10] <author> The Computer Engineering Group. </author> <title> P ARM A 2 project: Parma PARallel MAchine. </title> <type> Technical report, </type> <institution> Dip. Ingegneria dell'Informazione, University of Parma, </institution> <month> October </month> <year> 1995. </year>
Reference-contexts: In the initial phases of the project we worked in cooperation with collegues at the Department of Information Engineering of the University of Parma who were independently developing a project called PARMA 2 <ref> [10] </ref> under the coordination of professor Gianni Conte. Looking closer at some implementations of MPI on Linux NOWs (such as LAM and MPICH) we realized that even very low level MPI primitives were implemented on top of Unix sockets. <p> The formula was tested against delay measured for 1KByte packets resulting in an error rate lower than 1%. Using results provided by our collegues working on the PARMA 2 Project <ref> [10, Table 2.1] </ref> we can compare our estimates with ping-pong applications implemented over MPI on various platforms. Table 3 reports some of the results obtained by the PARMA 2 group in which the GAMMA results are integrated.
Reference: [11] <author> G. Chiola and A. Ferscha. </author> <title> Performance comparable design of efficient synchronization protocols for distributed simulation. </title> <booktitle> In Proc. </booktitle> <institution> MASCOTS'95, Durham, North Carolina, </institution> <month> January </month> <year> 1995. </year> <note> IEEE-CS Press. URL ftp://ftp.disi.unige.it/person/ChiolaG/mascots95.ps.gz. </note>
Reference-contexts: Capitalizing on previous experience with the use of the active message layer CMAML provided by the CM-5 platform <ref> [11] </ref> we then started to wonder about the feasibility of a direct implementation of a similar set of active message primitives in the Linux kernel. We came to the conclusion that a substantial revision of the kernel structure and organization for communication was needed.
Reference: [12] <author> T. Sterling, D.J. Becker, D. Savarese, J.E. Dorband, U.A. Ranawake, and C.V. Packer. BE-OWULF: </author> <title> A parallel workstation for scientific computation. </title> <booktitle> In Proc. 24th Int. Conf. on Parallel Processing, </booktitle> <address> Oconomowoc, Wisconsin, </address> <month> August </month> <year> 1995. </year> <note> URL http://cesdis.gsfc.nasa.gov/linux/beowulf/icpp95.html. 16 </note>
Reference-contexts: especially true when we consider that a small amount of scalability can also be obtained at a very low cost by using more than one cheap, standard LAN to support higher throughputs for the interconnection of a larger number of processors as already experimented, for instance, in the Beowulf project <ref> [12] </ref>. In conclusion, we think that the preliminary results of our experiment are quite encouraging and that it surely makes sense to propose the inclusion of a small set of communication primitives, implemented according to an accurate, performance-oriented approach into a standard operating system kernel.
References-found: 12

