URL: http://www.cs.umn.edu/Users/dept/users/du/papers/interconnect.ps
Refering-URL: http://www.cs.umn.edu/Users/dept/users/du/papers/
Root-URL: http://www.cs.umn.edu
Title: A Multi-Stage Interconnection Network with Packet Diverting and Limited Combining  
Author: Capabilities Sheau-Ru Tong and David H.C. Du 
Keyword: Key Words: Multi-stage Interconnection Network, Hotspot, Congestion Control, Packet Diverting, Combining Network.  
Date: January 11, 1993  
Address: 200 Union St. S.E., Minneapolis, MN, 55455.  
Affiliation: Computer Science Department University of Minnesota  
Abstract: Multi-stage Interconnection Networks (MINs) have been demonstrated to be one of the most cost-effective and useful communication media between processors and memory modules in parallel processing systems. In the last decade, several multiprocessor systems have been built based on this architecture. Though MINs are fairly flexible in handling varieties of traffic loads, the performance will be degraded by hotspot traffic. This is commonly known as tree saturation effect. This situation becomes worse with increasing system size. The existing combining network approach, by NYU Ultracomputer, is considered to be one of the most effective ways to alleviate the tree saturation problem. However, the combining network approach offers no performance advantage for non-hotspot traffic. This paper proposes a new approach to alleviate the tree saturation problem and at the same time improve performance of the MIN. In the proposed approach, each switch has certain packet diverting capability. Packet diverting allows packets from an intermediate switch element to bypass several subsequent stages and join with regular paths at a later stage. This helps to reduce the inner switch blocking in the MIN. This diverting capability is coupled together with a limited combining capability. Limited combining means hotspot packets are combined by the combining logics deployed at certain stages. The proposed scheme is shown to outperform the existing combining network approach. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> L.A.Cohn, </author> <title> "A Conceptual Approach to General Purpose Parallel Computer Architecture,"Ph.D. </title> <type> dissertation, </type> <institution> Columbia Univ.,New York,1983. </institution>
Reference: [2] <author> D. M. Dias and M. Kumar, </author> <title> "Preventing Congestion in Multistage Networks in the Presence of Hotspots," </title> <booktitle> in Proc. IEEE Int. Conf. Parallel Processing.,pp. </booktitle> <address> I-9-13, </address> <year> 1989. </year>
Reference-contexts: But non-combinable or non-uniform data access patterns can also occur (e.g., a specific array access patterns, non-combinable updates to a hotspot or transient heavy load on a memory module rather than to a specific data item <ref> [2] </ref>). In the traffic control approach, instead of providing a complicated combining network, simple hardware is added to each switch and a traffic control strategy is enforced to avoid the negative effects of tree saturation. In [6], a simple discarding strategy is employed. <p> The processor having sent the discarded 6 packet will be notified by an acknowledgment hardware and will retransmit the packet later. Another more comprehensive approach is proposed in <ref> [2] </ref>. The basic congestion control scheme is accomplished by rejecting an incoming packet, if a queue contains a packet to the same destination. The rejected packet is freshly appended to the tail of its queue.
Reference: [3] <author> D. M. Dias and J.R.Jump, </author> <title> "Analysis and Simulation of buffered Delta Networks," </title> <journal> in IEEE Trans. Comput., </journal> <month> pp.273-282,April </month> <year> 1981. </year>
Reference-contexts: In each clock cycle, only one packet is forwarded to the next stage and the other contesting packets are stored in the queue. The packets queued in an output port are forwarded to the next stage, in subsequent clock cycles. It has been shown <ref> [3] </ref> that the buffered MIN can improve the system throughput utilizing a pipelining effect among successive stage buffers. 1 In this paper log refers to log 2 . 2 However, this simple solution may not suffice all the time.
Reference: [4] <author> S. Dickey, et al., </author> <title> "A VLSI Combining Network for the NYU Ultracomputer," </title> <booktitle> in Proc. Int'l Conf. Computer Design, </booktitle> <pages> pp. </pages> <address> 110- 113, </address> <month> Oct. </month> <year> 1985. </year>
Reference: [5] <author> A. Gottlieb, </author> <title> et al.,"The NYU Ultracomputer-Designing a MIND, Shared Memory Parallel Machine," </title> <journal> in IEEE Trans. Comput., </journal> <volume> vol. C-32, pp.175-189, </volume> <month> Feb. </month> <year> 1983. </year>
Reference-contexts: Packets are either fed into a normal packet queue or a hotspot packet queue according to their packet types. In a like manner in <ref> [5] </ref> and [10], we assume that there is a field in the packet header to indicate 11 the packet type. The normal packet queue is a FIFO queue and can accept one packet per clock cycle. <p> Moreover, hierarchical modular construction is feasible by rearranging the switch elements. 26 6 Performance Evaluation We compare the performance of the proposed scheme with two other schemes: the basic scheme (which has no traffic control mechanism at all) and the combining network scheme (which is proposed in <ref> [5] </ref>). Our focus is to show the simulation results on the maximum achievable normalized throughput r upper and the average packet delay D. We denote the average packet delay for hotspot and normal packets by D h and D n respectively.
Reference: [6] <author> W. S. Ho and D. L. Eager, </author> <title> "A novel strategy for controlling hotspot congestion," </title> <booktitle> in Proc. IEEE 1989 Int. Conf. Parallel Processing., </booktitle> <address> pp.I-14-18, </address> <year> 1989. </year>
Reference-contexts: In the traffic control approach, instead of providing a complicated combining network, simple hardware is added to each switch and a traffic control strategy is enforced to avoid the negative effects of tree saturation. In <ref> [6] </ref>, a simple discarding strategy is employed. When a contention occurs at a switch and the contention packets are destined to the same memory module, one packet is randomly chosen to be discarded while the other is forwarded to the appropriate output port.
Reference: [7] <author> M.Kumar and G.F. Pfister, </author> <title> "The Onset of Hotspot Contention," </title> <booktitle> in Proc. IEEE Int. Conf.Parallel Processing, </booktitle> <volume> pp.28- 34, </volume> <month> Aug. </month> <year> 1986. </year>
Reference-contexts: This is called tree saturation effect [9]. The effect not only blocks the hotspot traffic, but may also block the normal traffic. Therefore, the system throughput is severely deteriorated. The tree saturation may also occur in some 3 specific data access patterns for several applications. Kumar and Pfister <ref> [7] </ref> pointed out that a hotspot needs to be in existence only for a short period of time before the tree saturation effect is felt. Also, after the hotspot is eliminated, it can take a long time for the effect to totally disappear.
Reference: [8] <author> H.T. Kung, </author> <title> "Synchronized and Asynchronous Parallel Algorithms for Multiprocessors," Parallel Algorithms and Complexity, </title> <publisher> Academic Press, </publisher> <address> pp.153-200, </address> <year> 1976. </year>
Reference-contexts: Hence, even if hotspot packets are served at a low rate, progress of the running processes will not be affected. However, this assumption may not be valid for a synchronous parallel algorithm model <ref> [8] </ref> in which frequently a number of parallelly executing processes need to be synchronized before they can proceed any further. Thus, a low service rate of hotspot packets may slow down the program execution. For this reason, a higher service rate is in demand.
Reference: [9] <author> G.F.Pfister and V. A. Norton, </author> " <title> Hot Spot Contention and Combining in Multistage Interconnection Networks," </title> <journal> in IEEE Trans. Comput., </journal> <volume> pp.943-948,Oct. </volume> <year> 1985. </year>
Reference-contexts: If a hotspot is accessed by all processors for a period of time, then a system wide logical tree of saturated output queues (rooted at the output queue that is connected to the hotspot memory module) is formed. This is called tree saturation effect <ref> [9] </ref>. The effect not only blocks the hotspot traffic, but may also block the normal traffic. Therefore, the system throughput is severely deteriorated. The tree saturation may also occur in some 3 specific data access patterns for several applications. <p> Also, after the hotspot is eliminated, it can take a long time for the effect to totally disappear. It has been shown <ref> [9] </ref> that the degradation becomes worse with increasing system size. Several schemes have been proposed to alleviate the tree saturation effect. They can be categorized into two different classes: a software or hardware approach. In the software approach [15], a reprogramming technique is employed to avoid the occurrences of hotspots. <p> The saturation effect propagates stage by stage back to the processor end. Finally, a system-wide tree of saturated output queues is formed, and all processors are blocked from transmission. This is the so called tree saturation effect <ref> [9] </ref>. Let us assume M i be the only hotspot memory module and e be the link connected to M i .
Reference: [10] <author> G. F. Pfister, et al., </author> " <title> The IBM Research Parallel Processor Prototype(RP3): Introduction and Architecture," </title> <booktitle> in Proc. IEEE Int. Conf. Parallel Processing, </booktitle> <pages> pp. 764-771, </pages> <month> Aug. </month> <year> 1985. </year>
Reference-contexts: During the return trip, the packets will have to be duplicated (de-combined) according to the information stored in the wait buffer. The NYU Ultracomputer [4][5], the Columbia CHoPP (or GEM)[12][1] and the IBM RP3 <ref> [10] </ref> are designed based on this strategy. Lee, et al.[19] pointed out that the two-way combining may not be effective and suggested a three-way combining. It is clear that with the provision of combining and de-combining capabilities in a MIN, hotspot traffic can be effectively reduced. <p> Lee, et al.[19] pointed out that the two-way combining may not be effective and suggested a three-way combining. It is clear that with the provision of combining and de-combining capabilities in a MIN, hotspot traffic can be effectively reduced. Nevertheless, as pointed out in <ref> [10] </ref>, the high hardware complexity of the combining network makes it more reasonable to fabricate the combining network by high-density NMOS or CMOS rather than by high-speed TTL or ECL. Thus, the combining network may slow down the system, and/or the overall cost may be prohibitedly high. <p> Packets are either fed into a normal packet queue or a hotspot packet queue according to their packet types. In a like manner in [5] and <ref> [10] </ref>, we assume that there is a field in the packet header to indicate 11 the packet type. The normal packet queue is a FIFO queue and can accept one packet per clock cycle.
Reference: [11] <author> R. D. Rettberg, W. R. Crowther, P. P. Carvey, R. S. Tomlinson, </author> <title> "The Monarch Parallel Processor Hardware Design," </title> <journal> IEEE Computer Magazine, </journal> <pages> pp. 18-30, </pages> <month> April </month> <year> 1990. </year>
Reference: [12] <author> H. Sullivan, T.Bashkow, and D.Klappholtz, </author> " <title> A Large Scale Homogeneous, Fully Distributed Parallel Machine," </title> <booktitle> in Proc. Fourth Annu. Symp. Comput. Architecture,pp. </booktitle> <pages> 105-124, </pages> <month> April </month> <year> 1977. </year>
Reference: [13] <author> N. F. Tzeng, </author> <title> "A cost-Effective Combining Structure for Large-Scale Shared-Memory Multiprocessors," </title> <journal> in IEEE Trans. Comput. Vol.41, </journal> <volume> No.11, </volume> <month> Nov. </month> <year> 1992, </year> <pages> pp. 1420-1429. </pages>
Reference-contexts: Thus, the combining network may slow down the system, and/or the overall cost may be prohibitedly high. An alternative design belonging to this subclass, which provides competitive performance and reduces the cost to O (1= log N ) of the previous design, is proposed in <ref> [13] </ref>. The key idea is to extract the combining and de-combining logics from switch elements to form a tree-structured combining network. Hotspot packets are not combined until the amount of the accumulated hotspot packets at some stages are large enough to slow down the overall throughput.
Reference: [14] <author> C. L. Wu and T. Y. Feng, </author> <title> "On a class of Multistage Interconnection Networks," </title> <journal> IEEE Trans. Comput.,vol. C-29, </journal>
Reference-contexts: However, the same principle is also applicable to other equivalent networks <ref> [14] </ref>. All processors and memory modules are labeled 0 to N -1 (from top to bottom). A processor (memory module) with the address i is denoted as P i (M i ). Each switch element contains two output queues.
Reference: [15] <author> P.C. Yew, N.F. Tzeng, D.H. Lawrie, </author> <title> "Distributing Hot-Spot Addressing in Large-Scale Multiprocessors." </title> <journal> in IEEE Trans. Comput. </journal> <volume> C-36(4), </volume> <month> April </month> <year> 1987,pp. </year> <pages> 388-395. 37 </pages>
Reference-contexts: It has been shown [9] that the degradation becomes worse with increasing system size. Several schemes have been proposed to alleviate the tree saturation effect. They can be categorized into two different classes: a software or hardware approach. In the software approach <ref> [15] </ref>, a reprogramming technique is employed to avoid the occurrences of hotspots. This assumes that the hotspot locations are known. However, for any arbitrary application, it may not be easy to identify hotspot locations. <p> They can be classified into two categories. The first category is a software approach that hinges on the identification of the program segments that cause hotspots and requires the reprogramming of these segments in a manner that hotspots do not arise <ref> [15] </ref>. This strategy has the advantage of avoiding a high cost and complexity of hardware design, and achieves a considerable performance improvement. However, the assumption here is that the segments causing hotspots can be pre-identified and reprogrammed in a desired manner without costing too much extra computation.
Reference: [16] <author> Nian-Feng Tzeng, </author> <title> "Alleviating the Impact of Tree Saturation on Multistage Interconnec--tion Network Performance," </title> <journal> Journal of Parallel and Distributed Computing, </journal> <month> Dec. </month> <year> 1991, </year> <pages> pp. 107-117. </pages>
Reference-contexts: The rejected packet is freshly appended to the tail of its queue. In this scheme, in addition to the acknowledgment hardware, the queues must have associative comparison capability. Tzeng <ref> [16] </ref> and Peir [17] proposed schemes which deploy either multiple input buffers or multiple output buffers in each switch element to provide several independent paths. Those schemes avoid hotspot traffic monopolizing all buffer space such that other normal packets can be delivered without serious blocking.
Reference: [17] <author> J.K. Peir and Y.H. Lee, </author> <title> "Improving Multistage Network performance under Uniform and Hot-spot Traffics," </title> <booktitle> Proc. 2nd IEEE Symposium on Parallel and Distributed Processing, </booktitle> <month> Dec. </month> <year> 1990, </year> <pages> pp. 548-551. </pages>
Reference-contexts: The rejected packet is freshly appended to the tail of its queue. In this scheme, in addition to the acknowledgment hardware, the queues must have associative comparison capability. Tzeng [16] and Peir <ref> [17] </ref> proposed schemes which deploy either multiple input buffers or multiple output buffers in each switch element to provide several independent paths. Those schemes avoid hotspot traffic monopolizing all buffer space such that other normal packets can be delivered without serious blocking.
Reference: [18] <author> M.C. Wong, </author> <title> "A Combining Omega Network: Performance vs Implementation," </title> <journal> IBM Research Report, </journal> <volume> RC 11977, </volume> <month> June </month> <year> 1986. </year>
Reference-contexts: In Figure 7, we present one possible design of hotspot packet queue which can support multiple combining and is a modification of the associative comparison design proposed in <ref> [18] </ref>. Similar to the original design, there are two columns: IN and CHUTE columns. Packets enter the IN column sequentially. A newly arrived packet is compared to all packet (s) in the IN column.
Reference: [19] <author> G. Lee, </author> <title> C.P. Kruskal, D.J. Kuck, "The Effectiveness of Combining in Shared Memory Parallel Computers in the Presence of 'Hot Spots'," </title> <booktitle> in Proc. 1986 Int. Conf. Parallel Processing, </booktitle> <month> Aug. </month> <year> 1986, </year> <pages> pp. 35-41. 38 </pages>
References-found: 19

