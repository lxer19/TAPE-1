URL: http://www.cs.colorado.edu/~klauser/papers/hpcn94.ps.gz
Refering-URL: http://www.cs.colorado.edu/~klauser/publications.html
Root-URL: http://www.cs.colorado.edu
Email: email: [aklauser,rposch]@iaik.tu-graz.ac.at  
Title: Distributed File Caching in Parallel Architectures Utilizing High Speed Networks  
Author: Artur Klauser and Reinhard Posch 
Address: Klosterwiesgasse 32/I 8010 Graz, Austria  
Affiliation: Institut fur Angewandte Informationsverarbeitung und Kommunikationstechnologie Technische Universitat Graz  
Abstract: To obtain well scalable services in distributed and parallel systems, critical parts of these services must be distributed to avoid bottlenecks, thus reducing server processing load and consumed network bandwidth. This work investigates the distribution of the file service by distributed block-level file caches, also called client caches. Fixed-size client caches with various cache coherency schemes are compared with a server cache and a variable-size client cache model, in order to reveal useful caching distribution concepts.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Mary G. Baker, John H. Hartman, Michael D. Kupfer, Ken W. Shirriff, and John K. Ousterhout. </author> <title> Measurements of a Distributed File System. </title> <type> Technical report, </type> <institution> University of California at Berkeley, Computer Science Division, </institution> <month> July </month> <year> 1991. </year> <booktitle> Also appeared in Proceedings of the 13th Symposium on Operating Systems Principles, </booktitle> <month> Oct. </month> <year> 1991. </year>
Reference-contexts: Proteus is an execution driven simulator that interleaves the execution of the application with the simulation of the underlying PN hardware and communication subsystem. The simulated models are fed with the Sprite File System trace data <ref> [1] </ref> from the University of California at Berkeley. Read and write trace events are fed into the simulator as fast as the simulated caching model is able to handle them.
Reference: 2. <author> A. Beguelin, J. Dongarra, G. Geist, W. Jiang, R. Manchek, K. Moore, and V. Sunderam. </author> <title> The PVM Project, 1993. </title> <institution> Oak Ridge National Laboratory, Oak Ridge, Tennessee. </institution>
Reference-contexts: On the hardware side both consist of a collection of independent compute nodes, interconnected by a high speed network. On the software side there are communication libraries available, like PVM <ref> [2] </ref>, P4, Parmacs, Linda, and soon MPI [7], that provide equal functionality for both types of systems. To be unrestricted by computers and networks currently in use, this study is based on a simulation approach. The advantages of using a simulator instead of real hardware are obvious.
Reference: 3. <author> Eric A. Brewer, Chrysanthos N. Dellarocas, Adrian Colbrool, and William E. Weihl. Proteus: </author> <title> A High-Performance Parallel-Architecture Simulator. </title> <type> Technical Report MIT/LCS/TR-516, </type> <institution> Massachusetts Institute of Technology, Laboratory for Computer Science, </institution> <month> September </month> <year> 1991. </year>
Reference-contexts: all): server is always in consistent state; clients write through shared and private files WSS (write share sequential): clients write-through shared files only; server is consistent WSC (write share concurrent): clients do not cache shared files; clients and server are consistent 4 Simulation The public domain parallel architecture simulator Proteus <ref> [3] </ref> has been used to evaluate the presented caching policies. Proteus is an execution driven simulator that interleaves the execution of the application with the simulation of the underlying PN hardware and communication subsystem.
Reference: 4. <author> George F. Coulouris and Jean Dollimore. </author> <title> Distributed Systems: Concepts and Design. </title> <address> Addison-Wessley, </address> <year> 1988. </year> <note> ISBN 0-201-18059-6. </note>
Reference-contexts: The advantages of using a simulator instead of real hardware are obvious. Among these, easy configurability and exact repeatability play an important role. The simulations are based on a client-server computing model <ref> [4] </ref>. Our special interest is the file service where block-level caching approaches are investigated. By comparing server caching with a number of client caching models we try to gain insight into distributed caching approaches. In Sec. 2 the computing model and network structure are presented.
Reference: 5. <author> M. Z. Ghanem. </author> <title> Dynamic Partitioning of the Main Memory Using the Working Set Concept. </title> <journal> IBM Journal of Research and Dev., </journal> <volume> 19(9) </volume> <pages> 445-450, </pages> <month> September </month> <year> 1975. </year>
Reference-contexts: The approach taken has similarities to cache partitioning schemes for centralized systems as reported by Stone et al. [8, 9] and Ghanem <ref> [5] </ref> Simulation studies with varying cache sizes show that a variable-size client cache scheme exhibits almost the same miss rate as a single big server cache.This is also shown in Fig. 1.
Reference: 6. <author> Artur Klauser. </author> <title> A Simulation Study for Distributed File Caching in High-Performance Parallel Architectures. </title> <type> Master's thesis, </type> <institution> Graz University of Technology, Austria, Department of Applied Information Processing, </institution> <month> January </month> <year> 1994. </year>
Reference-contexts: A more detailed description of the models can be found in <ref> [6] </ref>.
Reference: 7. <author> Message Passing Interface Forum. </author> <title> Draft Document for a Standard Message-Passing Interface. </title> <type> Technical report, </type> <institution> Univ. of Tennessee, Knoxville, Tennessee, </institution> <month> Nov. </month> <year> 1993. </year>
Reference-contexts: On the hardware side both consist of a collection of independent compute nodes, interconnected by a high speed network. On the software side there are communication libraries available, like PVM [2], P4, Parmacs, Linda, and soon MPI <ref> [7] </ref>, that provide equal functionality for both types of systems. To be unrestricted by computers and networks currently in use, this study is based on a simulation approach. The advantages of using a simulator instead of real hardware are obvious.
Reference: 8. <author> Harold S. Stone, John Turek, and Joel L. Wolf. </author> <title> Optimal Partitioning of Cache Memory. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 41(9) </volume> <pages> 1054-1068, </pages> <month> September </month> <year> 1992. </year>
Reference-contexts: The approach taken has similarities to cache partitioning schemes for centralized systems as reported by Stone et al. <ref> [8, 9] </ref> and Ghanem [5] Simulation studies with varying cache sizes show that a variable-size client cache scheme exhibits almost the same miss rate as a single big server cache.This is also shown in Fig. 1.
Reference: 9. <author> Dominique Thiebaut, Harold S. Stone, and Joel L. Wolf. </author> <title> Improving Disk Cache Hit-Ratios Through Cache Partitioning. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 41(6) </volume> <pages> 665-676, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: The approach taken has similarities to cache partitioning schemes for centralized systems as reported by Stone et al. <ref> [8, 9] </ref> and Ghanem [5] Simulation studies with varying cache sizes show that a variable-size client cache scheme exhibits almost the same miss rate as a single big server cache.This is also shown in Fig. 1.
References-found: 9

