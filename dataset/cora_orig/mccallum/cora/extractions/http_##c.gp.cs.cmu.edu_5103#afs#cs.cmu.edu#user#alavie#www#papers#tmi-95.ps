URL: http://c.gp.cs.cmu.edu:5103/afs/cs.cmu.edu/user/alavie/www/papers/tmi-95.ps
Refering-URL: http://c.gp.cs.cmu.edu:5103/afs/cs.cmu.edu/user/alavie/www/publications.html
Root-URL: http://www.cs.cmu.edu
Email: lori.levin@nl.cs.cmu.edu  
Title: Using Context in Machine Translation of Spoken Language  
Author: Lori Levin Oren Glickman Yan Qu Donna Gates Alon Lavie Carolyn P. Rose Carol Van Ess-Dykema Alex Waibel 
Note: U.S. Department of Defense  
Address: (USA)  
Affiliation: Carnegie Mellon University  Karlsruhe.  
Abstract: We report on techniques for using discourse context to reduce ambiguity and improve translation accuracy in a multi-lingual (Spanish, German, and English) spoken language translation system. The techniques involve statistical models as well as knowledge-based models including discourse plan inference. This work is carried out in the context of the Janus project at Carnegie Mellon University and the University of 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Woszczyna, N. Aoki-Waibel, F.D. Buo, N. Coccaro, K. Horiguchi, T. Kemp, A. Lavie, A. McNair, T. Polzin, I. Rogina, C.P. Rose, T. Schultz, B. Suhm, M. Tomita, A. Waibel. </author> <title> JANUS 93: Towards Spontaneous Speech Translation, </title> <booktitle> In ICASSP, </booktitle> <year> 1994. </year>
Reference: [2] <author> S. R. Young. </author> <title> Use of Dialog, Pragmatics and Semantics to Enhance Speech Recognition, </title> <journal> Speech Communication, </journal> <volume> 9, </volume> <year> 1990, </year> <pages> pages 551-564. </pages>
Reference-contexts: There has been much recent work on using context to constrain spoken language processing. Most of this work involves making predictions about possible sequences of utterances and using these predictions to limit the search space of the speech recognizer or some other component (See <ref> [2] </ref>, [3], [4], [5], [6], [7], [8], [9]). The goal of such an approach is to increase the accuracy of the top best hypothesis of the speech recognizer, which is then passed on to the language processing components of the system.
Reference: [3] <author> W. Ward, S. Young. </author> <title> Flexible Use of Semantic Constraints in Speech Recognition, </title> <booktitle> In IEEE International Conference on Acoustics, Speech and Signal Processing, Minneapolis, 1993, </booktitle> <volume> Vol. 2, </volume> <pages> pp. 49-50 </pages>
Reference-contexts: There has been much recent work on using context to constrain spoken language processing. Most of this work involves making predictions about possible sequences of utterances and using these predictions to limit the search space of the speech recognizer or some other component (See [2], <ref> [3] </ref>, [4], [5], [6], [7], [8], [9]). The goal of such an approach is to increase the accuracy of the top best hypothesis of the speech recognizer, which is then passed on to the language processing components of the system.
Reference: [4] <author> S. R. Young, A. G. Hauptmann, W. H. Ward, E. T. Smith, P. Werner. </author> <title> High Level Knowledge Sources in Usable Speech Recognition Systems, </title> <journal> Communications of the ACM, </journal> <volume> Volume 32 Number 2, </volume> <month> February </month> <year> 1989, </year> <note> p 183 - 194. </note>
Reference-contexts: There has been much recent work on using context to constrain spoken language processing. Most of this work involves making predictions about possible sequences of utterances and using these predictions to limit the search space of the speech recognizer or some other component (See [2], [3], <ref> [4] </ref>, [5], [6], [7], [8], [9]). The goal of such an approach is to increase the accuracy of the top best hypothesis of the speech recognizer, which is then passed on to the language processing components of the system.
Reference: [5] <author> H. Iida, T. Yamaoka, H. Arita. </author> <title> Predicting the Next Utterance Linguistic Expressions Using Contextual Information, </title> <journal> IEICE Trans. Inf. & Suyst., </journal> <volume> Vol. E76-D, No. 1, </volume> <month> January </month> <year> 1993. </year>
Reference-contexts: There has been much recent work on using context to constrain spoken language processing. Most of this work involves making predictions about possible sequences of utterances and using these predictions to limit the search space of the speech recognizer or some other component (See [2], [3], [4], <ref> [5] </ref>, [6], [7], [8], [9]). The goal of such an approach is to increase the accuracy of the top best hypothesis of the speech recognizer, which is then passed on to the language processing components of the system.
Reference: [6] <author> N. Reithinger, E. Maier. </author> <booktitle> Utilizing Statistical Dialogue Act Processing in Verb-mobil In Proceedings of the ACL, </booktitle> <year> 1995. </year>
Reference-contexts: There has been much recent work on using context to constrain spoken language processing. Most of this work involves making predictions about possible sequences of utterances and using these predictions to limit the search space of the speech recognizer or some other component (See [2], [3], [4], [5], <ref> [6] </ref>, [7], [8], [9]). The goal of such an approach is to increase the accuracy of the top best hypothesis of the speech recognizer, which is then passed on to the language processing components of the system.
Reference: [7] <author> N. </author> <title> Reithinger. </title> <booktitle> Some Experiments in Speech Act Prediction In Proceedings of AAAI Spring Symposium, </booktitle> <year> 1995. </year>
Reference-contexts: There has been much recent work on using context to constrain spoken language processing. Most of this work involves making predictions about possible sequences of utterances and using these predictions to limit the search space of the speech recognizer or some other component (See [2], [3], [4], [5], [6], <ref> [7] </ref>, [8], [9]). The goal of such an approach is to increase the accuracy of the top best hypothesis of the speech recognizer, which is then passed on to the language processing components of the system.
Reference: [8] <author> J. Alexandersson, E. Maiser, N. Reithinger. </author> <title> A Robust and Efficient Three-Layered Dialogue Component for a Speech-to-Speech Translation System In Proceedings of the EACL, </title> <address> Dublin, </address> <year> 1995. </year>
Reference-contexts: Most of this work involves making predictions about possible sequences of utterances and using these predictions to limit the search space of the speech recognizer or some other component (See [2], [3], [4], [5], [6], [7], <ref> [8] </ref>, [9]). The goal of such an approach is to increase the accuracy of the top best hypothesis of the speech recognizer, which is then passed on to the language processing components of the system.
Reference: [9] <author> G. Hanrieder, G. Gorz. </author> <title> Robust Parsing of Spoken Dialogue Using Contextual Knowledge and Recognition Probabilities To appear in Proceedings of ESCA Workshop on Spoken Dialogue Systems, </title> <year> 1995. </year>
Reference-contexts: Most of this work involves making predictions about possible sequences of utterances and using these predictions to limit the search space of the speech recognizer or some other component (See [2], [3], [4], [5], [6], [7], [8], <ref> [9] </ref>). The goal of such an approach is to increase the accuracy of the top best hypothesis of the speech recognizer, which is then passed on to the language processing components of the system.
Reference: [10] <author> L.J. Mayfield, M. Gavalda, Y-H. Seo, B. Suhm, W. Ward, A. </author> <title> Waibel Concept-Based Parsing For Speech Translation, </title> <booktitle> In Proceedings of the Sixth International Conference on Theoretical and Methodological Issues in Machine Translation, </booktitle> <year> 1995. </year>
Reference-contexts: Using a lattice parser can thus reduce time and space complexity relative to parsing a corresponding N-best list. Selection of the correct path through the lattice is accomplished during parsing when more information is available. 1 Another approach being pursued in parallel in the Janus project is described in <ref> [10] </ref> Lattices, however, are potentially inefficient because of their size. We apply four steps to make them more tractable ([?]). The first step involves cleaning the lattice by mapping all non-human noises and pauses into a generic pause. Consecutive pauses are then adjoined to one long pause.
Reference: [11] <author> Oren Glickman. </author> <title> Using Domain Knowledge to Improve End to End Performance in a Speech Translation System, </title> <type> Technical Report, </type> <institution> Laboratory for Computational Linguisitcs, Carnegie Mellon University, </institution> <year> 1995. </year>
Reference: [12] <author> A. Lavie, M. Tomita. </author> <title> GLR* An Efficient Noise-skipping Parsing Algorithm for Context-free Grammars, </title> <booktitle> In Proceedings of Third International Workshop on Parsing Technologies, </booktitle> <year> 1993, </year> <pages> pp. 123-134 </pages>
Reference: [13] <author> A. Lavie. </author> <title> An Integrated Heuristic for Partial Parse Evaluation, </title> <booktitle> In Proceedings of 32nd Annual Meeting of the ACL, </booktitle> <year> 1994 </year>
Reference-contexts: Each of the resulting sub-lattices are passed on to the parser, the first component of the translation process. Parsing a word lattice involves finding all paths of connecting words within the lattice that are grammatical. The GLR* ([12], <ref> [13] </ref>) parser skips parts of the utterance that it cannot incorporate into a well-formed structure. Thus it is well-suited to domains in which extra-grammaticality is common. <p> The different types of ambiguities encountered in Spanish-to-English translation are summarized in Figure 6. The following subsections describe the disambiguation methods that we tested. Our sentence-based disambiguation methods are implemented within the GLR* parser ([12] <ref> [13] </ref>) and its accompanying grammar. One method is knowledge-based, involving preferences that are explicitly encoded in grammar rules. The other is statistical, involving probabilities of actions in the LR parsing table.
Reference: [14] <author> L. Lambert and S. Carberry. </author> <title> Modeling negotiation subdialogues. </title> <booktitle> In Proceedings of the ACL, </booktitle> <year> 1992. </year>
Reference: [15] <author> L. Lambert. </author> <title> Recognizing Complex Discourse Acts: A Tripartite Plan-Based Models of Dialogue. </title> <type> PhD thesis, </type> <institution> University of Delaware, </institution> <month> September </month> <year> 1993. </year>
Reference: [16] <author> C. P. Rose. </author> <title> Plan-based discourse processor for negotiation dialogues. </title> <journal> Unpublished ms, </journal> <month> January </month> <year> 1995. </year>
Reference-contexts: A separate inference chain is created for each possible speech act. Preferences for picking one inference chain over another are determined by the focusing heuristics, which provide ordered expectations of discourse actions given the existing plan tree. A detailed description of the focusing heuristics can be found in <ref> [16] </ref> and [17]. We are currently conducting experiments to see how the plan tree and focusing heuristics can help to disambiguate multiple ILT outputs from the parser. We have obtained some preliminary results concerning resolving ambiguities in sentence types (statement, query-if, query-ref, fixed-expression, fragment) in the ILT outputs.
Reference: [17] <author> C. P. Rose, B. Di Eugenio, L. S. Levin, C. Van Ess-Dykema. </author> <title> Discourse Processing of Dialogues with Multiple Threads To appear in Proceedings of the ACL, </title> <year> 1995. </year>
Reference-contexts: Preferences for picking one inference chain over another are determined by the focusing heuristics, which provide ordered expectations of discourse actions given the existing plan tree. A detailed description of the focusing heuristics can be found in [16] and <ref> [17] </ref>. We are currently conducting experiments to see how the plan tree and focusing heuristics can help to disambiguate multiple ILT outputs from the parser. We have obtained some preliminary results concerning resolving ambiguities in sentence types (statement, query-if, query-ref, fixed-expression, fragment) in the ILT outputs.
References-found: 17

