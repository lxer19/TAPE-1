URL: file://ftp.cs.utexas.edu/pub/mooney/papers/lab-aaai-94.ps.Z
Refering-URL: http://www.cs.utexas.edu/users/cthomp/pubs.html
Root-URL: 
Email: cthomp@cs.utexas.edu, mooney@cs.utexas.edu  
Title: Inductive Learning For Abductive Diagnosis  
Author: Cynthia A. Thompson and Raymond J. Mooney 
Address: Austin, TX 78712  
Affiliation: Department of Computer Sciences University of Texas  
Date: 1994  
Note: Appears in Proceedings of the 12th National Conference on Artificial Intelligence pp. 664-669, The MIT Press,  
Abstract: A new inductive learning system, Lab (Learning for ABduction), is presented which acquires abductive rules from a set of training examples. The goal is to find a small knowledge base which, when used ab-ductively, diagnoses the training examples correctly and generalizes well to unseen examples. This contrasts with past systems that inductively learn rules that are used deductively. Each training example is associated with potentially multiple categories (disorders), instead of one as with typical learning systems. Lab uses a simple hill-climbing algorithm to efficiently build a rule base for a set-covering abductive system. Lab has been experimentally evaluated and compared to other learning systems and an expert knowledge base in the domain of diagnosing brain damage due to stroke. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Charniak, E. and McDermott, D. </author> <year> (1985). </year> <title> Introduction to AI. </title> <address> Reading, MA: </address> <publisher> Addison-Wesley. </publisher>
Reference-contexts: Background on Abductive Diagnosis Parsimonious Covering Abduction is informally defined as finding the best explanation for a set of observations, or inferring cause from effect. A standard logical definition of an ab-ductive explanation is a consistent set of assumptions which, together with background knowledge, entails a set of observations <ref> (Charniak and McDermott, 1985) </ref>. Our method for performing abduction is the set-covering approach presented in (Peng and Reggia, 1990). Although a simple, propositional model, it is capable of solving many real-world problems. In addition, it is no more restrictive than most inductive learning systems, which use discrete-valued feature vectors.
Reference: <author> Cooper, G. G. and Herskovits, E. </author> <year> (1992). </year> <title> A Bayesian method for the induction of probabilistic networks from data. </title> <journal> Machine Learning, </journal> <volume> 9 </volume> <pages> 309-347. </pages>
Reference: <author> Elstein, A., l. Shulman, and Sprafka, S. </author> <year> (1978). </year> <title> Medical Problem Solving AnAnalysis of Clinical Reasoning. </title> <publisher> Harvard University Press. </publisher>
Reference-contexts: Studies of human diagnosticians have demonstrated their use of abductive reasoning <ref> (Elstein et al., 1978) </ref>. For example, doctors know the causes behind a patients' symptoms and when a new case is seen, they can work "backwards" given the symptoms to hypothesize the disease or diseases which are present.
Reference: <author> Geiger, D., Paz, A., and Pearl, J. </author> <year> (1990). </year> <title> Learning causal trees from dependence information. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pages 770-776. </pages> <month> Boston,MA. </month>
Reference: <author> Josephson, J. R., Chandrasekaran, B., Smith, J. R., and Tanner, M. C. </author> <year> (1987). </year> <title> A mechanism for forming composite explanatory hypotheses. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> 17(3) </volume> <pages> 445-454. </pages>
Reference-contexts: Abductive methods have proven useful in applications such as diagnosing brain damage due to stroke (Tuhrim et al., 1991) and identifying red-cell antibodies in blood <ref> (Josephson et al., 1987) </ref>. Abductive methods are particularly useful in domains such as these, where multiple faults or disorders are fairly common. Most inductive work on diagnosis assumes there is a single disorder (classification) for each example.
Reference: <author> Kulikowski, C. A. and Weiss, S. M. </author> <year> (1991). </year> <title> Computer Systems That Learn Classification and Prediction Methods from Statistics, Neural Nets, </title> <booktitle> Machine Learning, and Expert Systems. </booktitle> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Note then that intersection accuracy is the average of precision and recall. A fourth measure, specificity, defined as T =C , measures the accuracy over disorders not present. Sensitivity, specificity, and standard accuracy are discussed in <ref> (Kulikowski and Weiss, 1991) </ref>. Finally, the accuracy of a rule base over a set of examples can be computed by averaging the appropriate score over all examples.
Reference: <author> Levesque, H. J. </author> <year> (1989). </year> <title> A knowledge-level account of abduction. </title> <booktitle> In Proceedings of the Eleventh International Joint conference on Artificial intelligence, </booktitle> <pages> pages 1061-1067. </pages> <address> De-troit, MI. </address>
Reference: <author> Michalski, R. S. and Chilausky, S. </author> <year> (1980). </year> <title> Learning by being told and learning from examples: An experimental comparison of the two methods of knowledge acquisition in the context of developing an expert system for soybean disease diagnosis. </title> <journal> Journal of Policy Analysis and Information Systems, </journal> <volume> 4(2) </volume> <pages> 126-161. </pages>
Reference-contexts: Introduction Most work in symbolic concept acquisition assumes a deductive model of classification in which an example is a member of a concept if it satisfies a logical specification represented in disjunctive normal form (DNF) <ref> (Michalski and Chilausky, 1980) </ref>, a decision tree (Quinlan, 1986), or a set of Horn clauses (Quinlan, 1990).
Reference: <author> Mooney, R. J. </author> <title> (to appear). Encouraging experimental results on learning CNF. </title> <booktitle> Machine Learning. </booktitle>
Reference: <author> Ng, H. T. </author> <year> (1992). </year> <title> A General Abductive System with Applications to Plan Recognition and Diagnosis. </title> <type> PhD thesis, </type> <institution> Austin, TX: University of Texas. </institution> <note> Also appears as Artificial Intelligence Laboratory Technical Report AI 92-177. </note>
Reference-contexts: The Peng and Reggia model is equivalent to logical abduction with a simple propositional domain theory composed of the rules fd ! m j (d; m) 2 Cg <ref> (Ng, 1992) </ref>. We will also write the elements of C as rules of the form d ! m. Therefore, C can be viewed as the knowledge base or domain theory for abductive diagnosis. <p> Also, the method needs to be extended to produce more complex abductive knowledge bases that include causal chaining (Peng and Reggia, 1990), rules with multiple antecedents, incompatible disorders, and predicate logic <ref> (Ng, 1992) </ref>. Conclusion Abduction is an increasingly popular approach to multiple-disorder diagnosis. However, the problem of automatically learning abductive rule bases from training examples has not previously been addressed.
Reference: <author> Pearl, J. </author> <year> (1988). </year> <title> Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. </title> <address> San Mateo,CA: </address> <publisher> Morgan Kaufmann, Inc. </publisher>
Reference-contexts: However, there are many systems which learn to perform diagnosis, and many abductive reasoning methods. We have already mentioned systems which learn deduc tive rules, both in the introduction and in our com-parisons with ID3 and PFoil. One other method that seems particularly well-suited to diagnosis is Bayesian Networks <ref> (Pearl, 1988) </ref>. There have been several attempts to learn Bayesian Networks (Cooper and Her-skovits, 1992; Geiger et al., 1990), but they have not been tested in realistic diagnostic domains. Future Work There are many opportunities for future work.
Reference: <author> Peng, Y. and Reggia, J. A. </author> <year> (1990). </year> <title> Abductive Inference Models for Diagnostic Problem-Solving. </title> <address> New York: </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: This paper concerns inducing from examples a knowledge base that is suitable for abduc-tive reasoning. We focus on abductive diagnosis using the model of <ref> (Peng and Reggia, 1990) </ref>. <p> A standard logical definition of an ab-ductive explanation is a consistent set of assumptions which, together with background knowledge, entails a set of observations (Charniak and McDermott, 1985). Our method for performing abduction is the set-covering approach presented in <ref> (Peng and Reggia, 1990) </ref>. Although a simple, propositional model, it is capable of solving many real-world problems. In addition, it is no more restrictive than most inductive learning systems, which use discrete-valued feature vectors. Some definitions from their work are needed in what follows. <p> We will also write the elements of C as rules of the form d ! m. Therefore, C can be viewed as the knowledge base or domain theory for abductive diagnosis. For the abductive portion of our algorithm, we use the Bipartite algorithm of <ref> (Peng and Reggia, 1990) </ref>, which returns all minimal diagnoses. One immediate problem is the typically large number of diagnoses generated. Thus, following Occam's razor, we first eliminate all but the minimum covers and select one of them at random as the system diagnosis. <p> Second, backtracking or beam search could be used to increase training set accuracy. A second opportunity for improvement is to reduce the number of diagnoses returned to only one during both training and testing. One way this could be done is by adding probability to abduction, as in <ref> (Peng and Reggia, 1990) </ref>. Third, there is room to improve the efficiency of the system. The average training time with 40 examples is 230 seconds, versus 4 to 5 seconds for ID3 and PFoil. <p> Finally, experiments in other domains are desirable; however we know of no other existing data sets for multiple-disorder diagnosis. Also, the method needs to be extended to produce more complex abductive knowledge bases that include causal chaining <ref> (Peng and Reggia, 1990) </ref>, rules with multiple antecedents, incompatible disorders, and predicate logic (Ng, 1992). Conclusion Abduction is an increasingly popular approach to multiple-disorder diagnosis. However, the problem of automatically learning abductive rule bases from training examples has not previously been addressed.
Reference: <author> Quinlan, J. </author> <year> (1990). </year> <title> Learning logical definitions from relations. </title> <journal> Machine Learning, </journal> <volume> 5(3) </volume> <pages> 239-266. </pages>
Reference-contexts: Introduction Most work in symbolic concept acquisition assumes a deductive model of classification in which an example is a member of a concept if it satisfies a logical specification represented in disjunctive normal form (DNF) (Michalski and Chilausky, 1980), a decision tree (Quinlan, 1986), or a set of Horn clauses <ref> (Quinlan, 1990) </ref>. However, recent research in diagnosis, plan recognition, object recognition, and other areas of AI has found that abduction, finding a set of assumptions that imply or explain a set of observations, is frequently a more appropriate and useful mode of reasoning (Charniak and McDermott, 1985; Levesque, 1989). <p> The neural network used has one output bit per disorder, and the number of hidden units is 10% of the number of disorders plus the number of manifestations. PFoil is a propositional version of Foil <ref> (Quinlan, 1990) </ref> which learns DNF rules. The primary simplification of PFoil compared to Foil is that it only needs to deal with fixed examples rather than the expanding tuples of Foil. ID3 and PFoil are typically used for single category tasks.
Reference: <author> Quinlan, J. R. </author> <year> (1986). </year> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1(1) </volume> <pages> 81-106. </pages>
Reference-contexts: Introduction Most work in symbolic concept acquisition assumes a deductive model of classification in which an example is a member of a concept if it satisfies a logical specification represented in disjunctive normal form (DNF) (Michalski and Chilausky, 1980), a decision tree <ref> (Quinlan, 1986) </ref>, or a set of Horn clauses (Quinlan, 1990).
Reference: <author> Rumelhart, D. E., Hinton, G. E., and Williams, J. R. </author> <year> (1986). </year> <title> Learning internal representations by error propagation. </title> <editor> In Rumelhart, D. E. and McClelland, J. L., editors, </editor> <booktitle> Parallel Distributed Processing, </booktitle> <volume> Vol. I, </volume> <pages> pages 318-362. </pages> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: In addition, we obtained the accompanying abductive knowledge base generated by an expert, which consists of 648 rules. We ran our experiments with Lab, ID3 (Quin-lan, 1986), PFoil (Mooney, to appear), and a neural network using standard backpropagation <ref> (Rumelhart et al., 1986) </ref> with one hidden layer. The neural network used has one output bit per disorder, and the number of hidden units is 10% of the number of disorders plus the number of manifestations. PFoil is a propositional version of Foil (Quinlan, 1990) which learns DNF rules.
Reference: <author> Swets, J. A. </author> <year> (1969). </year> <title> Effectiveness of information retrieval methods. </title> <journal> American Documentation, </journal> <pages> pages 72-89. </pages>
Reference-contexts: Third, sensitivity is defined by T + =C + , and measures accuracy over the disorders actually present, an important measure in diagnosis. Sensitivity is also called recall by <ref> (Swets, 1969) </ref> and others, who also define precision as T + =S. Note then that intersection accuracy is the average of precision and recall. A fourth measure, specificity, defined as T =C , measures the accuracy over disorders not present.
Reference: <author> Thompson, C. A. </author> <year> (1993). </year> <title> Inductive Learning for Abduc-tive Diagnosis. </title> <type> Master's thesis, </type> <institution> Austin, TX: University of Texas at Austin. </institution>
Reference-contexts: By removing related rules, we enforce a bias towards a minimum rule base and help maintain as high an accuracy as possible. The computational complexity of Lab can be shown to be O (N jDj 2 jM j 2 ), where N is the number of examples in E <ref> (Thompson, 1993) </ref>. Example of Lab Let us illustrate the workings of Lab with an example. <p> In addition, the abductive rule base is arguably easier to comprehend than either the decision tree learned by ID3 or the disjuncts returned by PFoil, since the rules are in the causal direction. See <ref> (Thompson, 1993) </ref> for an example rule base learned by Lab. Related Work Since no other system learns abductive knowledge bases, no direct comparisons are possible. However, there are many systems which learn to perform diagnosis, and many abductive reasoning methods.
Reference: <author> Tuhrim, S., Reggia, J., and Goodall, S. </author> <year> (1991). </year> <title> An experimental study of criteria for hypothesis plausibility. </title> <journal> Journal of Experimental and Theoretical Artificial Intelligence, </journal> <volume> 3 </volume> <pages> 129-144. </pages>
Reference-contexts: For example, doctors know the causes behind a patients' symptoms and when a new case is seen, they can work "backwards" given the symptoms to hypothesize the disease or diseases which are present. Abductive methods have proven useful in applications such as diagnosing brain damage due to stroke <ref> (Tuhrim et al., 1991) </ref> and identifying red-cell antibodies in blood (Josephson et al., 1987). Abductive methods are particularly useful in domains such as these, where multiple faults or disorders are fairly common. Most inductive work on diagnosis assumes there is a single disorder (classification) for each example. <p> To test this hypothesis, we used actual patient data from the domain of diagnosing brain damage due to stroke. We used fifty of the patient cases discussed in <ref> (Tuhrim et al., 1991) </ref>. 1 In this database, there are twenty-five different brain areas which can be damaged, effecting the presence of thirty-seven symptom types, each with an average of four values, for a total of 155 attribute-value pairs. 1 We were only able to obtain fifty out of the 100
References-found: 18

