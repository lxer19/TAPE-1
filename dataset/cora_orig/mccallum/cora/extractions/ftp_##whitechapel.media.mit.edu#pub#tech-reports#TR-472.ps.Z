URL: ftp://whitechapel.media.mit.edu/pub/tech-reports/TR-472.ps.Z
Refering-URL: http://www-white.media.mit.edu/cgi-bin/tr_pagemaker/
Root-URL: http://www.media.mit.edu
Email: ftanzeem,clarkson,jebara,sandyg@media.mit.edu  
Title: Multimodal Person Recognition using Unconstrained Audio and Video  
Author: Tanzeem Choudhury, Brian Clarkson, Tony Jebara, Alex Pentland 
Address: Cambridge, MA 02139  
Affiliation: Perceptual Computing Group MIT Media Laboratory  
Abstract: We propose a person identification technique that can recognize and verify people from unconstrained video and audio. We do not expect fully frontal face image or clean speech as our input. Our recognition algorithm can detect and compensate for pose variation and changes in the auditory background and also select the most reliable video frame and audio clip to use for recognition. We also use 3D depth information of a human head to detect the presence of an actual person as opposed to an image of that person. Our system achieves 100% recognition and verification rates on natural real-time input with 26 registered clients. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Ali Azarbayejani and Alex Pentland. </author> <title> Recursive estimation of motion, structure and focal length. </title> <journal> IEEE Pattern Analysis and Machine Intelligence, </journal> <year> 1995. </year>
Reference-contexts: Using this pose estimate and a 3D head model we warp the detected face to a frontal view. This frontal face then undergoes histogram fitting to normalize it's illumination. For a detailed description of the face detection and tracking please refer to <ref> [9, 1] </ref>. 2.2 Eigenspace Modeling Once a face has been detected and its features identified, the image region containing the face is sent for recognition. The face finding stage gives us only an approximation of the feature locations.
Reference: [2] <author> David J. Beymer. </author> <title> Face recognition under varying pose. </title> <journal> A.I. </journal> <volume> Memo No. 1461, </volume> <year> 1993. </year>
Reference-contexts: Researchers have proposed different techniques that can handle varying pose by using template maching techniques or by modeling the pose variations as manifolds or subspaces in a high dimensional image space <ref> [2, 7, 5, 11] </ref>. The main goal of this paper is to recognize a person using unconstrained audio and video information. We also derive a confidence scoring which allows us to identify the reliable video frames and audio clips that can be used for recognition.
Reference: [3] <author> F. Bimbot, H. Hutter, C. Jaboulet, J. Koolwaaij, J. Lind-berg, and J. Pierrot. </author> <title> Speaker verification in the telephone network: Research activities in the cave project. </title> <type> Technical report, </type> <institution> PTT Telecom, ENST, IDIAP, KTH, KUN, and Ubilab, </institution> <year> 1997. </year>
Reference-contexts: However, convolutional and additive noise in the audio signal will cause a mismatch between the model and test distributions, resulting in poor recognition performance <ref> [10, 3] </ref>. Even if the audio channel is kept consistent so as to minimize convolutional noise, there will always be the problem of additive noise in natural scenarios. Deconvolutional techniques such as RASTA [8] have had substantial success in matching the spectral response of different auditory channels. <p> Deconvolutional techniques such as RASTA [8] have had substantial success in matching the spectral response of different auditory channels. However, severe drops in performance are still evident with even small amounts of additive noise. Work done by <ref> [3] </ref> has suggested that the presence of noise doesn't necessarily degrade recognition pefor-mance. They compared their system's error rates on a clean database (YOHO) and a more realistic database (SESP). When training and testing were done on the same database the error rates were comparable.
Reference: [4] <author> G. J. Brown. </author> <title> Computational Auditory Scene Analysis: A representational approach. </title> <type> PhD thesis, </type> <institution> University of Sheffield, </institution> <year> 1992. </year>
Reference-contexts: A simple solution is to adapt the threshold or equivalently scale the energy. The system keeps a running estimate of the energy statistics and continually normalizes the energy to zero mean and unit variance (similar to Brown's onset detector <ref> [4] </ref>).
Reference: [5] <author> Brenden Frey Antonio Colmenarez and Thomas Huang. </author> <title> Mixture of local linear subspaces for face recognition. </title> <booktitle> In International Conference on Computer Vision and Pattern Recognition. </booktitle>
Reference-contexts: Researchers have proposed different techniques that can handle varying pose by using template maching techniques or by modeling the pose variations as manifolds or subspaces in a high dimensional image space <ref> [2, 7, 5, 11] </ref>. The main goal of this paper is to recognize a person using unconstrained audio and video information. We also derive a confidence scoring which allows us to identify the reliable video frames and audio clips that can be used for recognition.
Reference: [6] <author> M.J.F. Gales and S.J. Young. </author> <title> Robust continuous speech recognition using parallel model combination. </title> <type> Technical report, </type> <institution> Cambride University, </institution> <year> 1994. </year>
Reference-contexts: So given only the clean speech models and recordings of the background noise, our adaptation technique can estimate the appropriate noisy speech models. The model adaptation procedure (which is related to the parallel model combination algorithm of <ref> [6] </ref>) is based on estimating HMMs for noisy speech from HMMs separately trained on speech and noise.
Reference: [7] <author> Daniel Graham and Nigel Allinson. </author> <title> Face recognition from unfamiliar views: Subspace methods and pose dependency. </title> <booktitle> In Third International Conference on Automatic Face and Gesture Recognition. </booktitle>
Reference-contexts: Researchers have proposed different techniques that can handle varying pose by using template maching techniques or by modeling the pose variations as manifolds or subspaces in a high dimensional image space <ref> [2, 7, 5, 11] </ref>. The main goal of this paper is to recognize a person using unconstrained audio and video information. We also derive a confidence scoring which allows us to identify the reliable video frames and audio clips that can be used for recognition.
Reference: [8] <author> Hynek Hermansky, Nelson Morgan, Aruna Bayya, and Phil Kohn. </author> <title> Rasta-plp speech analysis. </title> <type> ICSI Technical Report TR-91-069, </type> <year> 1991. </year>
Reference-contexts: Even if the audio channel is kept consistent so as to minimize convolutional noise, there will always be the problem of additive noise in natural scenarios. Deconvolutional techniques such as RASTA <ref> [8] </ref> have had substantial success in matching the spectral response of different auditory channels. However, severe drops in performance are still evident with even small amounts of additive noise. Work done by [3] has suggested that the presence of noise doesn't necessarily degrade recognition pefor-mance.
Reference: [9] <author> Tony Jebara and Alex Pentland. </author> <title> Parameterized structure from motion for 3d adaptive feedback tracking of faces. </title> <booktitle> In IEEE Conference on Computer Vision and Pattern Recognition. </booktitle>
Reference-contexts: Using this pose estimate and a 3D head model we warp the detected face to a frontal view. This frontal face then undergoes histogram fitting to normalize it's illumination. For a detailed description of the face detection and tracking please refer to <ref> [9, 1] </ref>. 2.2 Eigenspace Modeling Once a face has been detected and its features identified, the image region containing the face is sent for recognition. The face finding stage gives us only an approximation of the feature locations.
Reference: [10] <author> Jiyong Ma and Wen Gao. </author> <title> Text-independent speaker identification based on spectral weighting functions. </title> <booktitle> AVBPA Proceedings, </booktitle> <year> 1997. </year>
Reference-contexts: However, convolutional and additive noise in the audio signal will cause a mismatch between the model and test distributions, resulting in poor recognition performance <ref> [10, 3] </ref>. Even if the audio channel is kept consistent so as to minimize convolutional noise, there will always be the problem of additive noise in natural scenarios. Deconvolutional techniques such as RASTA [8] have had substantial success in matching the spectral response of different auditory channels.
Reference: [11] <author> Juwei Lu Stan Z. Li. </author> <title> Generalizing capacity of face database for face recognition. </title> <booktitle> In Third International Conference on Automatic Face and Gesture Recognition. </booktitle>
Reference-contexts: Researchers have proposed different techniques that can handle varying pose by using template maching techniques or by modeling the pose variations as manifolds or subspaces in a high dimensional image space <ref> [2, 7, 5, 11] </ref>. The main goal of this paper is to recognize a person using unconstrained audio and video information. We also derive a confidence scoring which allows us to identify the reliable video frames and audio clips that can be used for recognition.
References-found: 11

