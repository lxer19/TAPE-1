URL: http://www-control.eng.cam.ac.uk/sl1/rpaa/rpaa.ps
Refering-URL: http://www-control.eng.cam.ac.uk/Homepage/Papers.html
Root-URL: 
Email: email: sl1@eng.cam.ac.uk  email: kg@eng.cam.ac.uk  
Title: Robust performance and adaptation using receding horizon H 1 control of time varying systems.  
Author: Sanjay Lall Keith Glover 
Address: Cambridge CB2 1PZ England  Cambridge CB2 1PZ England  
Affiliation: Department of Engineering Cambridge University  Department of Engineering Cambridge University  
Abstract: In this paper we construct suboptimal H 1 controllers which satisfy a new robust performance condition, using the receding horizon technique. A method is described for the synthesis of H 1 controllers online, making use of the exact plant model only on a finite interval extending into the future. Inequalities based on the two Riccati differential equation solution to the finite horizon H 1 problem are derived, and the resulting freedom is exploited to construct H 1 controllers which have a closed loop induced norm less than a prespecified value for all plants within a set, which is described in terms of the future variation of the plant. Dual results, with a possible adaptive interpretation, are also constructed. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> T. Ba~sar and P. Bernhard. </author> <title> H 1 Optimal Control and Related Minimax Design Problems. A Dynamic Game Approach. Systems and Control: Foundations and Applications. </title> <publisher> Birkhauser, </publisher> <year> 1991. </year>
Reference-contexts: 1 Introduction The construction of H 1 controllers for finite dimensional linear systems has been derived in a number of ways, using operator theory, the state space solutions in [4], using game theoretic techniques <ref> [1] </ref>, and in the time domain [11]. The time domain and game theoretic techniques both allow solution of finite horizon problems with non-zero initial conditions, and therefore allow a receding horizon control formulation. <p> Similarly for N as the strategy space for player w. We will consider dynamic game problems of the form inf sup Z t f jz (t)j fl jw (t)j dt + x (t f ) Q f x (t f ): This problem is solved in <ref> [1] </ref>, where it is shown that if there exists a saddle point to the above problem, then the infimising feedback strategy for u gives a control law which satisifies the finite horizon H 1 condition sup kzk 2 &lt; fl where the 2-norms are defined on the interval [t 0 ; <p> We will denote the strategy spaces for u and w by ^ M and ^ N respectively, the spaces of causal functions of y. We state the following certainty equivalence principle which can be obtained from <ref> [1, Theorem 5.1] </ref>. Theorem 6 (Ba~sar and Bernhard [1]). <p> We will denote the strategy spaces for u and w by ^ M and ^ N respectively, the spaces of causal functions of y. We state the following certainty equivalence principle which can be obtained from [1, Theorem 5.1]. Theorem 6 (Ba~sar and Bernhard <ref> [1] </ref>). Define G (x (t 0 ); u [0;t] ; w [0;t] ) = t 0 0 2 0 + V (t; x (t )) where V (t; x (t )) is the value of the game in the state feedback case as defined above. <p> In this case G t (0; 0; w) &lt; 0 with equality for the worst case w. See for example Basar and Bernhard <ref> [1] </ref>, Limebeer et al [9]. We will write Y (t) = (t; t 0 ; Q 0 ) for the solution to the above Riccati equation with boundary condition (t 0 ; t 0 ; Q 0 ) = Q 0 .
Reference: [2] <author> T. Ba~sar and G. J. Olsder. </author> <title> Dynamic Noncooperative Game Theory. </title> <booktitle> Mathematics in Science and Engineering. </booktitle> <publisher> Academic Press, </publisher> <year> 1982. </year>
Reference: [3] <author> R. W. Brockett. </author> <title> Finite Dimensional Linear Systems. </title> <publisher> Wiley, </publisher> <year> 1970. </year>
Reference: [4] <author> J. C. Doyle, K. Glover, P. P. Khargonekar, and B. A. Francis. </author> <title> State-space solutions to standard H 2 and H 1 control problems. </title> <journal> IEEE Transactions on Automatic Control, </journal> <volume> 34(8) </volume> <pages> 831-847, </pages> <month> August </month> <year> 1989. </year>
Reference-contexts: 1 Introduction The construction of H 1 controllers for finite dimensional linear systems has been derived in a number of ways, using operator theory, the state space solutions in <ref> [4] </ref>, using game theoretic techniques [1], and in the time domain [11]. The time domain and game theoretic techniques both allow solution of finite horizon problems with non-zero initial conditions, and therefore allow a receding horizon control formulation. <p> Essentially the above results rely on monotonicity and convergence of solutions to the Riccati differential equation associated with the state feedback H 1 problem and the corresponding differential game. Since the estimator and its associated Riccati equation can be constructed by dual arguments <ref> [4] </ref>, the question arises as to what the dual estimation problem is in the moving horizon case.
Reference: [5] <author> K. Glover and J. C. Doyle. </author> <title> State-space formulae for all stabilizing controllers that satisfy an H 1 -norm bound and relations to risk sensitivity. </title> <journal> Systems and Control Letters, </journal> <volume> 11 </volume> <pages> 167-172, </pages> <year> 1988. </year>
Reference: [6] <author> W. H. Kwon, A. M. Bruckstein, and T. Kailath. </author> <title> Sta bilizing state-feedback design via the moving horizon method. </title> <journal> International Journal of Control, </journal> <volume> 37(3) </volume> <pages> 631-643, </pages> <year> 1983. </year>
Reference-contexts: Later these results were extended by Lall and Glover [8] to allow a quadratic terminal state weight. The linear quadratic moving horizon problem was studied by Kwon <ref> [6, 7] </ref>, but in this case there is no global suboptimal property satisfied, and the only criterion which was desired was stability.
Reference: [7] <author> W. H. Kwon and A. E. Pearson. </author> <title> A modified quadratic cost problem and feedback stabilization of a linear system. </title> <journal> IEEE Transactions on Automatic Control, </journal> <volume> 22(5) </volume> <pages> 838-842, </pages> <month> October </month> <year> 1977. </year>
Reference-contexts: Later these results were extended by Lall and Glover [8] to allow a quadratic terminal state weight. The linear quadratic moving horizon problem was studied by Kwon <ref> [6, 7] </ref>, but in this case there is no global suboptimal property satisfied, and the only criterion which was desired was stability.
Reference: [8] <author> S. Lall and K. Glover. </author> <title> A game theoretic approach to moving horizon control. </title> <editor> In D. Clarke, editor, </editor> <title> Advances in Model-Based Predictive Control. </title> <publisher> Oxford University Press, </publisher> <year> 1994. </year>
Reference-contexts: Later these results were extended by Lall and Glover <ref> [8] </ref> to allow a quadratic terminal state weight. The linear quadratic moving horizon problem was studied by Kwon [6, 7], but in this case there is no global suboptimal property satisfied, and the only criterion which was desired was stability. <p> We will write the solution to this equation as Z (t) = (t; t f ; Q f ) for the solution to the above Riccati equation with boundary condition Z (t f ; t f ; Q f ) = Q f : In the receding horizon formulation in <ref> [11, 8] </ref> the problem formulation was as follows. At each time t, solve inf sup Z t+T jz (r)j fl jw (r)j dr 0 For each time t there is a new optimization problem, and a new controller designed which is implemented only at time t. <p> At each time t, solve inf sup Z t+T jz (r)j fl jw (r)j dr 0 For each time t there is a new optimization problem, and a new controller designed which is implemented only at time t. In <ref> [8] </ref> it was shown that provided Q f (t) satisfied certain conditions, then the resulting controller would be stable. Further, the resulting controller satisfies the H 1 criterion sup w kwk 2 &lt; fl, where the signal norms are defined over the whole interval [t 0 ; 1). <p> All plants which are equal up until time T ahead of the current time, subject to this condition, will be controlled with this performance level, and in this sense this gives a new robust performance condition. In this paper we generalise the results of <ref> [10, 8] </ref>, in particular to the case when the update of the controller is not continuous but discrete.
Reference: [9] <author> D. J. Limebeer, B. D. O. Anderson, P. P. Khar gonekar, and M. Green. </author> <title> A game theoretic approach to H 1 control for time varying systems. </title> <journal> SIAM Journal on Control and Optimization, </journal> <volume> 30(2) </volume> <pages> 262-283, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: In this case G t (0; 0; w) &lt; 0 with equality for the worst case w. See for example Basar and Bernhard [1], Limebeer et al <ref> [9] </ref>. We will write Y (t) = (t; t 0 ; Q 0 ) for the solution to the above Riccati equation with boundary condition (t 0 ; t 0 ; Q 0 ) = Q 0 .
Reference: [10] <author> G. Tadmor. </author> <title> Receding horizon revisited: An easy way to robustly stabilize an LTV system. </title> <journal> Systems and Control Letters, </journal> <volume> 18 </volume> <pages> 285-294, </pages> <year> 1992. </year>
Reference-contexts: Then at time t + ffi, the optimization is again performed, with the cost function applied to the interval [t + ffi; t + T + ffi]. The use of game theoretic techniques to solve a moving horizon H 1 problem was first applied by Tadmor <ref> [10] </ref>, where it was shown that with a terminal state constraint, the receding horizon control law not only gave stability, but also gave an infinite horizon H 1 norm bound. Later these results were extended by Lall and Glover [8] to allow a quadratic terminal state weight. <p> All plants which are equal up until time T ahead of the current time, subject to this condition, will be controlled with this performance level, and in this sense this gives a new robust performance condition. In this paper we generalise the results of <ref> [10, 8] </ref>, in particular to the case when the update of the controller is not continuous but discrete.
Reference: [11] <author> G. Tadmor. </author> <title> The standard H 1 problem and the maximum principle: the general linear case. </title> <journal> SIAM Journal on Control and Optimization, </journal> <volume> 31(4) </volume> <pages> 813-846, </pages> <year> 1993. </year>
Reference-contexts: 1 Introduction The construction of H 1 controllers for finite dimensional linear systems has been derived in a number of ways, using operator theory, the state space solutions in [4], using game theoretic techniques [1], and in the time domain <ref> [11] </ref>. The time domain and game theoretic techniques both allow solution of finite horizon problems with non-zero initial conditions, and therefore allow a receding horizon control formulation. <p> We will write the solution to this equation as Z (t) = (t; t f ; Q f ) for the solution to the above Riccati equation with boundary condition Z (t f ; t f ; Q f ) = Q f : In the receding horizon formulation in <ref> [11, 8] </ref> the problem formulation was as follows. At each time t, solve inf sup Z t+T jz (r)j fl jw (r)j dr 0 For each time t there is a new optimization problem, and a new controller designed which is implemented only at time t. <p> sup Z t f jz (t)j fl jw (t)j dt + x (t f ) Q f x (t f ) K X x (t i ) i x (t i ) If we rewrite this as a standard problem with discontinuous C 1 matrix, it is solved by Tadmor <ref> [11] </ref> using Riccati integral equations to avoid difficulties with the disconti-nuities. This can be rewritten as a Riccati differential equation with jumps as follows.
Reference: [12] <author> P. Whittle. </author> <title> Risk-sensitive optimal control. Wiley In terscience series in Systems and Optimization. </title> <publisher> Wiley, </publisher> <year> 1990. </year>
References-found: 12

