URL: http://www.cs.berkeley.edu/~carson/papers/cvpr97.ps.gz
Refering-URL: http://www.cs.berkeley.edu/~carson/papers/cvpr97.html
Root-URL: 
Email: fcarson,sjb,hayit,malikg@cs.berkeley.edu  
Title: Region-Based Image Querying  
Author: Chad Carson, Serge Belongie, Hayit Greenspan, and Jitendra Malik 
Address: Berkeley, CA 94720  
Affiliation: Computer Science Division University of California at Berkeley  
Abstract: Retrieving images from large and varied collections using image content as a key is a challenging and important problem. In this paper we present a new image representation which provides a transformation from the raw pixel data to a small set of localized coherent regions in color and texture space. This so-called blobworld representation is based on segmentation using the Expectation-Maximization algorithm on combined color and texture features. The texture features we use for the segmentation arise from a new approach to texture description and scale selection. We describe a system that uses the blobworld representation to retrieve images. An important and unique aspect of the system is that, in the context of similarity-based querying, the user is allowed to view the internal representation of the submitted image and the query results. Similar systems do not offer the user this view into the workings of the system; consequently, the outcome of many queries on these systems can be quite inexplicable, despite the availability of knobs for adjusting the similarity metric. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E. Adelson and Y. Weiss. </author> <title> A unified mixture framework for motion segmentation: Incorporating spatial coherence and estimating the number of models. </title> <journal> In Proc. IEEE Comput. Soc. Conf. Comp. Vision and Pattern Recogn., </journal> <pages> pages 321-326, </pages> <year> 1996. </year>
Reference-contexts: Earlier work has used the EM algorithm to perform segmentation based on motion <ref> [1, 3] </ref>, but EM has not previously been used on joint color and texture. 2 The blobworld image representation The blobworld representation is related to the notion of photographic or artistic scene composition.
Reference: [2] <editor> J. Ashley et al. </editor> <title> Automatic and semiautomatic methods for image annotation and retrieval in QBIC. </title> <booktitle> In SPIE Proc. Storage and Retrieval for Image and Video Databases, </booktitle> <pages> pages 24-35, </pages> <year> 1995. </year>
Reference-contexts: The system then displays a selection of potential matches to those criteria, sorted by a score of the appropriateness of the match. Region segmentation is largely manual, but the most recent versions of QBIC <ref> [2] </ref> contain simple automated segmentation facilities. Photobook [22] incorporates more sophisticated representations of texture and a degree of automatic segmentation. Other examples of systems that identify materials using low-level image properties include Virage [13], Candid [17], and Chabot [21].
Reference: [3] <author> S. Ayer and H. Sawney. </author> <title> Layered representation of motion video using robust maximum-likelihood estimation of mixture models and MDL encoding. </title> <booktitle> In Proc. Int. Conf. Comp. Vision, </booktitle> <pages> pages 777-784, </pages> <year> 1995. </year>
Reference-contexts: Earlier work has used the EM algorithm to perform segmentation based on motion <ref> [1, 3] </ref>, but EM has not previously been used on joint color and texture. 2 The blobworld image representation The blobworld representation is related to the notion of photographic or artistic scene composition.
Reference: [4] <author> S. Belongie, C. Carson, H. Greenspan, and J. Malik. </author> <title> Recognition of images in large databases using a learning framework. </title> <type> Technical Report 97-939, </type> <institution> U.C. Berkeley CS Division, </institution> <year> 1997. </year>
Reference-contexts: Details can be found in <ref> [4] </ref>. 6 images are tigers; tiger images make up 5% of the database. images are zebras, while less than 2% of the images in the database are zebras. top 50 images are airplanes (34% are eagles); 5% of the database images are airplanes, 5% eagles. top 50 images are sunsets; about
Reference: [5] <author> J. Bigun. </author> <title> Local symmetry features in image processing. </title> <type> PhD thesis, </type> <institution> Linkoping University, </institution> <year> 1988. </year>
Reference-contexts: At each pixel location, M (x; y) is a 2 fi 2 symmetric positive semidefinite matrix; thus it provides us with three pieces of information about each pixel. Rather than work with the raw entries in M , it is more common to deal with its eigenstructure <ref> [5, 7] </ref>. Consider a fixed scale and pixel location, let 1 and 2 ( 1 2 ) denote the eigenvalues of M at that location, and let denote the argument of the principal eigenvector.
Reference: [6] <author> A. Dempster, N. Laird, and D. Rubin. </author> <title> Maximum likelihood from incomplete data via the EM algorithm. </title> <journal> J. Royal Statistical Soc., Ser. B, </journal> <volume> 39(1) </volume> <pages> 1-38, </pages> <year> 1977. </year>
Reference-contexts: In order to divide these points into groups, we make use of the Expectation-Maximization (EM) algorithm <ref> [6] </ref> to determine the maximum likelihood parameters of a mixture of K Gaussians inside the 6-D feature space. The EM algorithm is used for finding maximum likelihood parameter estimates when there is missing or incomplete data.
Reference: [7] <author> W. Forstner. </author> <title> A framework for low level feature extraction. </title> <booktitle> In Proc. Europ. Conf. Comp. Vision, </booktitle> <year> 1994. </year>
Reference-contexts: However, this scheme ignores the fact that for large values and saturations, hue differences are more perceptually relevant than saturation and value differences. 2.1.2 Texture Texture is a well-researched property of image regions, and many texture descriptors have been proposed, including multi-orientation filter banks [12, 19] and the second-moment matrix <ref> [7, 10] </ref>. We will not elaborate here on the classical approaches to texture segmentation and classification, both of which are challenging and well-studied tasks. Rather, we introduce a new perspective related to texture descriptors and texture grouping motivated by the content-based retrieval task. <p> At each pixel location, M (x; y) is a 2 fi 2 symmetric positive semidefinite matrix; thus it provides us with three pieces of information about each pixel. Rather than work with the raw entries in M , it is more common to deal with its eigenstructure <ref> [5, 7] </ref>. Consider a fixed scale and pixel location, let 1 and 2 ( 1 2 ) denote the eigenvalues of M at that location, and let denote the argument of the principal eigenvector. <p> Scale selection We may think of as controlling the size of the integration window around each pixel within which the outer product of the gradient vectors is averaged. has been called the integration scale or artificial scale by various authors <ref> [7, 10] </ref> to distinguish it from the natural scale used in linear smoothing of raw image intensities.
Reference: [8] <author> D. Forsyth and M. Fleck. </author> <title> Body plans. </title> <journal> In Proc. IEEE Comput. Soc. Conf. Comp. Vision and Pattern Recogn., </journal> <year> 1997. </year>
Reference-contexts: While much work remains to be done in the field of shape description, some possibilities include perimeter-based descriptions such as Fourier descriptors [14] and boundary-based footprint matching [16], moment-based approaches [14], and body-plan recognition <ref> [8] </ref>. Acknowledgments We would like to thank David Forsyth, Joe Hellerstein, Ginger Ogle, and Robert Wilensky for useful discussions related to this work.
Reference: [9] <author> W. T. Freeman and E. H. Adelson. </author> <title> The design and use of steerable filters. </title> <journal> In IEEE Trans. Pattern Analysis and Machine Intelligence, </journal> <volume> volume 13, </volume> <pages> pages 891-906, </pages> <year> 1991. </year>
Reference-contexts: We define polarity as p = E + + E 1 Strictly speaking, eqn. (1) is a sliding inner product, not a convolution, since (x; y) is spatially variant. 2 The polarity is related to the quadrature phase as discussed in <ref> [9, 11] </ref>. (a) and (b) have stripes (1-D flow) of different frequencies and orientations, (c) is a region of 2-D texture, (d) contains an edge, and (e) is a uniform region.
Reference: [10] <author> J. Garding and T. Lindeberg. </author> <title> Direct computation of shape cues using scale-adapted spatial derivative operators. </title> <journal> Int. J. of Comp. Vision, </journal> <volume> 17, </volume> <month> Feb </month> <year> 1996. </year>
Reference-contexts: However, this scheme ignores the fact that for large values and saturations, hue differences are more perceptually relevant than saturation and value differences. 2.1.2 Texture Texture is a well-researched property of image regions, and many texture descriptors have been proposed, including multi-orientation filter banks [12, 19] and the second-moment matrix <ref> [7, 10] </ref>. We will not elaborate here on the classical approaches to texture segmentation and classification, both of which are challenging and well-studied tasks. Rather, we introduce a new perspective related to texture descriptors and texture grouping motivated by the content-based retrieval task. <p> Scale selection We may think of as controlling the size of the integration window around each pixel within which the outer product of the gradient vectors is averaged. has been called the integration scale or artificial scale by various authors <ref> [7, 10] </ref> to distinguish it from the natural scale used in linear smoothing of raw image intensities. <p> Quantitatively, we declare a pixel to be uniform if its mean contrast across scale is less than 0:1. Another method of scale selection that has been proposed <ref> [10] </ref> is based on localizing extrema across scale of an invariant of M , such as the trace or determinant. <p> The other two, which are taken from M fl , are the anisotropy, defined as a = 1 2 = 1 , and the normalized texture contrast 3 , defined as c = 2 p 1 + 2 . These are related to derived quantities reported in <ref> [10] </ref>. 2.1.3 Combining color and texture features The final color/texture descriptor for a given pixel consists of six values: three for color and three for texture. The three color components are the color-cone coordinates found after spatial averaging using a Gaussian at the selected scale.
Reference: [11] <author> G. H. Granlund and H. Knutsson. </author> <title> Signal Processing for Computer Vision. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1995. </year>
Reference-contexts: We define polarity as p = E + + E 1 Strictly speaking, eqn. (1) is a sliding inner product, not a convolution, since (x; y) is spatially variant. 2 The polarity is related to the quadrature phase as discussed in <ref> [9, 11] </ref>. (a) and (b) have stripes (1-D flow) of different frequencies and orientations, (c) is a region of 2-D texture, (d) contains an edge, and (e) is a uniform region.
Reference: [12] <author> H. Greenspan et al. </author> <title> Learning texture discrimination rules in a multiresolution system. </title> <journal> IEEE Trans. Pattern Analysis and Machine Intelligence, </journal> <volume> 16(9) </volume> <pages> 894-901, </pages> <year> 1994. </year>
Reference-contexts: However, this scheme ignores the fact that for large values and saturations, hue differences are more perceptually relevant than saturation and value differences. 2.1.2 Texture Texture is a well-researched property of image regions, and many texture descriptors have been proposed, including multi-orientation filter banks <ref> [12, 19] </ref> and the second-moment matrix [7, 10]. We will not elaborate here on the classical approaches to texture segmentation and classification, both of which are challenging and well-studied tasks. Rather, we introduce a new perspective related to texture descriptors and texture grouping motivated by the content-based retrieval task.
Reference: [13] <author> A. Gupta and R. Jain. </author> <title> Visual information retrieval. </title> <journal> Comm. Assoc. Comp. Mach., </journal> <volume> 40(5), </volume> <month> May </month> <year> 1997. </year>
Reference-contexts: Region segmentation is largely manual, but the most recent versions of QBIC [2] contain simple automated segmentation facilities. Photobook [22] incorporates more sophisticated representations of texture and a degree of automatic segmentation. Other examples of systems that identify materials using low-level image properties include Virage <ref> [13] </ref>, Candid [17], and Chabot [21]. None of these systems codes spatial organization in a way that supports object queries. Classical object recognition techniques rely on clean segmentation of the object from the rest of the image and are designed for fixed, geometric objects such as machine parts.
Reference: [14] <author> A. Jain. </author> <title> Fundamentals of digital image processing. </title> <publisher> Prentice Hall, </publisher> <year> 1989. </year>
Reference-contexts: While much work remains to be done in the field of shape description, some possibilities include perimeter-based descriptions such as Fourier descriptors <ref> [14] </ref> and boundary-based footprint matching [16], moment-based approaches [14], and body-plan recognition [8]. Acknowledgments We would like to thank David Forsyth, Joe Hellerstein, Ginger Ogle, and Robert Wilensky for useful discussions related to this work. <p> While much work remains to be done in the field of shape description, some possibilities include perimeter-based descriptions such as Fourier descriptors <ref> [14] </ref> and boundary-based footprint matching [16], moment-based approaches [14], and body-plan recognition [8]. Acknowledgments We would like to thank David Forsyth, Joe Hellerstein, Ginger Ogle, and Robert Wilensky for useful discussions related to this work.
Reference: [15] <author> J.-S. Jang, C.-T. Sun, and E. Mizutani. </author> <title> Neuro-Fuzzy and Soft Computing. </title> <publisher> Prentice Hall, </publisher> <year> 1997. </year>
Reference-contexts: This score is 1 if the blobs are identical in all relevant features; it decreases as the match becomes less perfect. 3. Take i = max j ij . The compound query score for the database image is calculated using fuzzy-logic operations <ref> [15] </ref>. For example, if the query is like-blob-1 and (like-blob-2 or like-blob-3), the overall score for the image is minf 1 ; maxf 2 ; 3 gg. The user can also specify a weighting i for each atomic query.
Reference: [16] <author> A. Kalvin et al. </author> <title> Two-dimensional model-based boundary matching using footprints. </title> <journal> Int. J. Rob. Res., </journal> <volume> 5 </volume> <pages> 38-55, </pages> <year> 1986. </year>
Reference-contexts: While much work remains to be done in the field of shape description, some possibilities include perimeter-based descriptions such as Fourier descriptors [14] and boundary-based footprint matching <ref> [16] </ref>, moment-based approaches [14], and body-plan recognition [8]. Acknowledgments We would like to thank David Forsyth, Joe Hellerstein, Ginger Ogle, and Robert Wilensky for useful discussions related to this work.
Reference: [17] <author> P. Kelly, M. Cannon, and D. Hush. </author> <title> Query by image example: the comparison algorithm for navigating digital image databases (CANDID) approach. </title> <booktitle> In SPIE Proc. Storage and Retrieval for Image and Video Databases, </booktitle> <pages> pages 238-249, </pages> <year> 1995. </year>
Reference-contexts: Region segmentation is largely manual, but the most recent versions of QBIC [2] contain simple automated segmentation facilities. Photobook [22] incorporates more sophisticated representations of texture and a degree of automatic segmentation. Other examples of systems that identify materials using low-level image properties include Virage [13], Candid <ref> [17] </ref>, and Chabot [21]. None of these systems codes spatial organization in a way that supports object queries. Classical object recognition techniques rely on clean segmentation of the object from the rest of the image and are designed for fixed, geometric objects such as machine parts.
Reference: [18] <author> T. Leung and J. Malik. </author> <title> Detecting, localizing and grouping repeated scene elements from an image. </title> <booktitle> In Proc. Europ. Conf. Comp. Vision, </booktitle> <year> 1996. </year>
Reference-contexts: We can think of E + and E as measures of how many gradient vectors in W are on the positive side and negative side of the dominant orientation, respectively. Note that p ranges from 0 to 1. A similar measure is used in <ref> [18] </ref> to distinguish a flow pattern from an edge. The behavior of the polarity p in typical image regions can be summarized as follows (see Fig. 1): Edge: The presence of an edge is signaled by p holding values close to 1 for all .
Reference: [19] <author> J. Malik and P. Perona. </author> <title> Preattentive texture discrimination with early vision mechanisms. </title> <journal> J. Opt. Soc. Am. A, </journal> <volume> 7(5) </volume> <pages> 923-932, </pages> <year> 1990. </year>
Reference-contexts: However, this scheme ignores the fact that for large values and saturations, hue differences are more perceptually relevant than saturation and value differences. 2.1.2 Texture Texture is a well-researched property of image regions, and many texture descriptors have been proposed, including multi-orientation filter banks <ref> [12, 19] </ref> and the second-moment matrix [7, 10]. We will not elaborate here on the classical approaches to texture segmentation and classification, both of which are challenging and well-studied tasks. Rather, we introduce a new perspective related to texture descriptors and texture grouping motivated by the content-based retrieval task.
Reference: [20] <author> W. Niblack et al. </author> <title> The QBIC project: querying images by content using colour, texture and shape. </title> <booktitle> In SPIE Proc. Storage and Retrieval for Image and Video Databases, </booktitle> <year> 1993. </year>
Reference-contexts: the blobworld representation, from features through segmentation to region description, and in Section 3 we present a query system based on blobworld, as well as results from queries in a collection of highly varied natural images. 1.1 Background The best-known image database system is IBM's Query by Image Content (QBIC) <ref> [20] </ref>, which allows an operator to specify various properties of a desired image. The system then displays a selection of potential matches to those criteria, sorted by a score of the appropriateness of the match.
Reference: [21] <author> V. Ogle and M. Stonebraker. Chabot: </author> <title> Retrieval from a relational database of images. </title> <journal> IEEE Computer, </journal> <volume> 28(9), </volume> <month> Sep </month> <year> 1995. </year>
Reference-contexts: Photobook [22] incorporates more sophisticated representations of texture and a degree of automatic segmentation. Other examples of systems that identify materials using low-level image properties include Virage [13], Candid [17], and Chabot <ref> [21] </ref>. None of these systems codes spatial organization in a way that supports object queries. Classical object recognition techniques rely on clean segmentation of the object from the rest of the image and are designed for fixed, geometric objects such as machine parts.
Reference: [22] <author> A. Pentland, R. Picard, and S. Sclaroff. Photobook: </author> <title> Content-based manipulation of image databases. </title> <journal> Int. J. of Comp. Vision, </journal> <note> to appear. </note>
Reference-contexts: The system then displays a selection of potential matches to those criteria, sorted by a score of the appropriateness of the match. Region segmentation is largely manual, but the most recent versions of QBIC [2] contain simple automated segmentation facilities. Photobook <ref> [22] </ref> incorporates more sophisticated representations of texture and a degree of automatic segmentation. Other examples of systems that identify materials using low-level image properties include Virage [13], Candid [17], and Chabot [21]. None of these systems codes spatial organization in a way that supports object queries.
Reference: [23] <author> J. Ponce, A. Zisserman, and M. </author> <title> Hebert. </title> <booktitle> Object Representation in Computer VisionII. Number 1144 in LNCS. </booktitle> <publisher> Springer, </publisher> <year> 1996. </year>
Reference-contexts: Neither constraint holds in our case: the shape, size, and color of objects like cheetahs and polar bears are quite variable, and segmentation is imperfect. Clearly, classical object recognition does not apply. More recent techniques <ref> [23] </ref> can identify specific objects drawn from a finite (on the order of 100) collection, but no present technique is effective at the general image analysis task, which requires both image segmentation and image classification.
Reference: [24] <author> B. Ripley. </author> <title> Pattern Recognition and Neural Networks. </title> <publisher> Cam-bridge University Press, </publisher> <year> 1996. </year>
Reference-contexts: Such a system must use machine learning to create some representation of the categories or objects; it would not be practical for a designer to hand-code the hun dreds or thousands of classifiers that would be required for an interesting system.We have performed experiments using a simple Bayes classifier <ref> [24] </ref> on a discretized version of blobworld.
Reference: [25] <author> J. Rissanen. </author> <title> Modeling by shortest data description. </title> <journal> Auto-matica, </journal> <volume> 14 </volume> <pages> 465-471, </pages> <year> 1978. </year>
Reference-contexts: Ideally we would like to choose that value of K that best suits the natural number of groups present in the image. One readily available notion of goodness of fit is the log-likelihood. Given this indicator, we can apply the Minimum Description Length (MDL) principle <ref> [25] </ref> to select among values of K. As a consequence of this principle, when models using two values of K fit the 4 data equally well, the simpler model will be chosen. For our experiments, K ranges from 2 to 5.
Reference: [26] <author> L. Schiff, N. Van House, and M. H. Butler. </author> <title> Unpublished study of image database users. </title>
Reference-contexts: The shortcomings of these systems are due both to the image representations they use and to their methods of accessing those representations to find images: * While users often would like to find images containing particular objects (things) <ref> [26] </ref>, most existing image retrieval systems represent images based only on their fl CVPR '97 Workshop on Content-Based Access of Image and Video Libraries.
Reference: [27] <author> U. Shaft and R. Ramakrishnan. </author> <title> Data modeling and querying in the PIQ image DBMS. </title> <journal> IEEE Data Engineering Bulletin, </journal> <volume> 19(4), </volume> <month> Dec </month> <year> 1996. </year>
Reference-contexts: In the sense discussed in <ref> [27] </ref>, the blobworld descriptors constitute an example of a summary representation in that they are concise and relatively easy to process in a querying framework. Blobworld is distinct from color-layout matching as in QBIC in that it is designed to find objects or parts of objects.
Reference: [28] <author> D. Yarowsky. </author> <title> Word-sense disambiguation using statistical models of Roget's categories trained on large corpora. </title> <booktitle> In Proc. Fourteenth Int. Conf. Computational Linguistics, </booktitle> <pages> pages 454-460, </pages> <month> Aug. </month> <year> 1992. </year> <month> 8 </month>
Reference-contexts: Often in the case of text searches this results from the use of ambiguous keywords, such as bank or interest <ref> [28] </ref>. Unfortunately, with image queries it is not always so clear why things go wrong.
References-found: 28

