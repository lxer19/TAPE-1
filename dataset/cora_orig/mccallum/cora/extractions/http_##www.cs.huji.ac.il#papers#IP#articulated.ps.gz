URL: http://www.cs.huji.ac.il/papers/IP/articulated.ps.gz
Refering-URL: http://www.cs.huji.ac.il/papers/IP/index.html
Root-URL: 
Title: Constraint-Fusion for Interpretation of Articulated Objects  
Author: Yacov Hel-Or Michael Werman 
Address: 76100 Rehovot, Israel 91904 Jerusalem, Israel  
Affiliation: Department of Computer Science Department of Computer Science The Weizmann Institute of Science The Hebrew University of Jerusalem  
Abstract: This paper presents a method for interpretation of modeled objects that is general enough to cover articulated and other types of constrained models. The flexibility between components of the model are expressed as spatial constraints which are fused into the pose estimation during the interpretation process. The constraint fusion assists in obtaining the correct interpretation and in reducing the search of possible correspondences. The proposed method can handle any constraint (including inequalities) between any number of different components of the model. The framework is based on Kalman filtering. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> N. Ayache. </author> <title> Artificial Vision for Mobile Robots Stereo Vision and Multisensory Perception. </title> <publisher> MIT Press, </publisher> <year> 1991. </year>
Reference-contexts: In other words the actual measurements are considered soft constraints whereas the constraints are considered strong. The fusion of the actual measurements and the constraints during the pose estimation process is performed using the Kalman filter and it is in accord with <ref> [1] </ref>. The fusion of a constraint into the pose estimation enables us to predict the possible locations of associated components which have not been interpreted yet. Thus, simple comparison between this prediction and the possible measurements to be matched can eliminate irrelevant correspondences and helps us in the interpretation exploration.
Reference: [2] <author> R. Basri. </author> <title> The Recognition of 3-D Solid Objects from 2-D Images. </title> <type> PhD thesis, </type> <institution> Weizmann Institute of Science, </institution> <month> Oct. </month> <year> 1990. </year>
Reference-contexts: This correspondence is necessary in localization procedures which are based on local features of the model. Both, the positioning and the interpretation problems are well documented in the literature (for reviews see <ref> [15, 16, 2] </ref>) however, the majority of the papers deal with 3D rigid objects and little attention has been given to articulated or constrained objects (e.g. [3, 6, 11, 13]). fl This research has been sponsered by the U.S. Office of Naval Research under Grant N00014-93-1202, R&T Project Code 4424341-01.
Reference: [3] <author> A. Beinglass and H.J. Wolfson. </author> <title> Articulated object recognition, or: How to generalize the generalized hough transform. </title> <booktitle> In CVPR, </booktitle> <pages> pages 461-466, </pages> <year> 1991. </year>
Reference-contexts: Both, the positioning and the interpretation problems are well documented in the literature (for reviews see [15, 16, 2]) however, the majority of the papers deal with 3D rigid objects and little attention has been given to articulated or constrained objects (e.g. <ref> [3, 6, 11, 13] </ref>). fl This research has been sponsered by the U.S. Office of Naval Research under Grant N00014-93-1202, R&T Project Code 4424341-01. An articulated object is an object composed of a set of rigid components connected at joints which allow certain degrees of freedom. <p> We call these kind of models constrained models. Existing methods that deal with constrained objects are restricted to deal with articulated models (e.g. <ref> [3, 6, 11, 13] </ref>). They deal with constraints that are due to prismatic or revolute joints. In this paper we present a general framework that can deal with all types of spatial constraints and is not limited to any particular type.
Reference: [4] <author> R.A. Brooks. </author> <title> Model-based 3-D interpretation of 2-D images. </title> <journal> T-PAMI, </journal> <volume> 5 </volume> <pages> 140-150, </pages> <year> 1983. </year>
Reference-contexts: Lowe [11] follows this method and estimates the free parameters of the viewpoint and of the model using Newton iterations. A similar method was used by Brooks <ref> [4] </ref> in the well known system ACRONYM. Mulligan et. al. [13] use the same approach for estimating the positions of an excavator's arm.
Reference: [5] <author> W.E.L. </author> <title> Grimson. Recognition of object families using parameterized models. </title> <booktitle> In ICCV, </booktitle> <pages> pages 93-101, </pages> <year> 1987. </year>
Reference-contexts: In this method it is possi-ble to follow the pose estimation by an assessment of the current interpretation by testing whether the estimated position of neighboring components satisfy the constraints defined between them (up to a predefined threshold). Grimson <ref> [6, 5] </ref> follows this paradigm in order to identify a family of objects which differ in scale-factor, stretch factor or the angles between parts.
Reference: [6] <author> W.E.L. </author> <title> Grimson. On the recognition of parametrized 2-D objects. </title> <journal> IJCV, </journal> <volume> 2 </volume> <pages> 353-372, </pages> <year> 1989. </year>
Reference-contexts: Both, the positioning and the interpretation problems are well documented in the literature (for reviews see [15, 16, 2]) however, the majority of the papers deal with 3D rigid objects and little attention has been given to articulated or constrained objects (e.g. <ref> [3, 6, 11, 13] </ref>). fl This research has been sponsered by the U.S. Office of Naval Research under Grant N00014-93-1202, R&T Project Code 4424341-01. An articulated object is an object composed of a set of rigid components connected at joints which allow certain degrees of freedom. <p> We call these kind of models constrained models. Existing methods that deal with constrained objects are restricted to deal with articulated models (e.g. <ref> [3, 6, 11, 13] </ref>). They deal with constraints that are due to prismatic or revolute joints. In this paper we present a general framework that can deal with all types of spatial constraints and is not limited to any particular type. <p> In this method it is possi-ble to follow the pose estimation by an assessment of the current interpretation by testing whether the estimated position of neighboring components satisfy the constraints defined between them (up to a predefined threshold). Grimson <ref> [6, 5] </ref> follows this paradigm in order to identify a family of objects which differ in scale-factor, stretch factor or the angles between parts.
Reference: [7] <author> Y. Hel-Or. </author> <title> Pose Estimation from Uncertain Sensory Data. </title> <type> PhD thesis, </type> <institution> Inst. of Computer Sciense, The Hebrew University of Jerusalem, </institution> <year> 1993. </year>
Reference-contexts: There are computational aspects that were not covered in this paper such as methods to stabilize the convergence, parallelization techniques and methods to speed up the computation and to reduce the time complexity using Optimal Smoothing. This techniques is described in <ref> [7] </ref>.
Reference: [8] <author> Y. Hel-Or and M. Werman. </author> <title> Recognition and localization of articulated and constrained objects. </title> <note> submitted to the IJCV, </note> <month> October </month> <year> 1993. </year>
Reference-contexts: In addition local iterations [12] are performed in order to reduce the influence of the linearization effect on the final solution. Detailed explanation with full equations about the measurements and constraints fusion can be found in <ref> [8] </ref>. The sequential fusion of the measurements is possible due to the assumption that there is no correlation between the noise of different measurements (i.e. covfu i ; u j g = 0 where i 6= j). <p> Figures 2c and 2d show the corresponding results as synthetic images created from the estimated location vector. As can be seen, there is high correlation between the real model location and the synthesized reconstruction. More results on the pose estimation process can be seen in <ref> [10, 8] </ref>. The correspondence between the measured data and the model points was found according to the interpretation process we described. Figure 3 shows a limited part of the interpretation tree (I.T.) which is constructed for the desk lamp interpretation.
Reference: [9] <author> Y. Hel-Or and M. Werman. </author> <title> Absolute orienta-tion from uncertain data: A unified approach. </title> <booktitle> In CVPR, </booktitle> <pages> pages 77-82, </pages> <year> 1992. </year>
Reference-contexts: The information obtained from a measurement ^ u k;j is fused into the solution T with the same manner as we fuse measurements for a rigid object pose estimation. Detailed explanation of such a process can be found in <ref> [9] </ref>. The information obtained from a constraint is fused as described in Section 5.1. <p> The interpretation method for each component is similar to that for a rigid body, as presented in <ref> [9] </ref>, where in our case there is additional a priori information about T k from the previously fused constraints. <p> In the case where every component contains several model points, there is no need to restrict the measurements to be 3D since the pose of the component can be estimated from projections (2D measurements) <ref> [9] </ref>. 8 Results We applied our method to estimate the position of a real articulated 3D object from 2D images. The articulated model used, is a desk lamp shown in Figure 2, having 5 degrees of freedom.
Reference: [10] <author> Y. Hel-Or and M. Werman. </author> <title> Model based pose estimation of articulated and constrained objects. </title> <booktitle> In the 3 rd ECCV, </booktitle> <address> May,1994. </address>
Reference-contexts: In this paper we present a general framework that can deal with all types of spatial constraints and is not limited to any particular type. Our method solves the interpretation and the localization problems simultaneously where constraints and measurements are considered and fused incrementally. In a previous paper <ref> [10] </ref> we described a method for the localization problem using incremental constraint fusion but there we assumed that the correspondence is given. <p> Examples and results of applying the pose determination process on real and simulated data can be seen in <ref> [10] </ref>. 6 The Measurement Interpretation Using the incremental approach described above we adopt the techniques which solve the interpretation problem by a pruning search in the correspondence space. These techniques regard the correspondence problem as a search problem in a graph (Interpretation Tree). <p> Figures 2c and 2d show the corresponding results as synthetic images created from the estimated location vector. As can be seen, there is high correlation between the real model location and the synthesized reconstruction. More results on the pose estimation process can be seen in <ref> [10, 8] </ref>. The correspondence between the measured data and the model points was found according to the interpretation process we described. Figure 3 shows a limited part of the interpretation tree (I.T.) which is constructed for the desk lamp interpretation.
Reference: [11] <author> D.G. Lowe. </author> <title> Fitting parametrized 3-D models to images. </title> <journal> T-PAMI, </journal> <volume> 13 </volume> <pages> 441-450, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: Both, the positioning and the interpretation problems are well documented in the literature (for reviews see [15, 16, 2]) however, the majority of the papers deal with 3D rigid objects and little attention has been given to articulated or constrained objects (e.g. <ref> [3, 6, 11, 13] </ref>). fl This research has been sponsered by the U.S. Office of Naval Research under Grant N00014-93-1202, R&T Project Code 4424341-01. An articulated object is an object composed of a set of rigid components connected at joints which allow certain degrees of freedom. <p> We call these kind of models constrained models. Existing methods that deal with constrained objects are restricted to deal with articulated models (e.g. <ref> [3, 6, 11, 13] </ref>). They deal with constraints that are due to prismatic or revolute joints. In this paper we present a general framework that can deal with all types of spatial constraints and is not limited to any particular type. <p> The remaining parameters are estimated during the estimation process, and the interpretation process is directed to be consistent with the current estimated parameters. Lowe <ref> [11] </ref> follows this method and estimates the free parameters of the viewpoint and of the model using Newton iterations. A similar method was used by Brooks [4] in the well known system ACRONYM. Mulligan et. al. [13] use the same approach for estimating the positions of an excavator's arm. <p> This results in a more complex and less stable solution especially when using iterative methods based on linear approximation of the nonlinear equations (such as in <ref> [11] </ref>). 4 Constraints Fusion Method In the two kinds of methods described in the last section there is no direct consideration of constraints in the pose estimation process; the constraints are not considered in the divide and conquer methods and they are eliminated, by reducing the number of estimated parameters, in
Reference: [12] <author> P.S. Maybeck. </author> <title> Stochastic Models, Estimation, </title> <journal> and Control, </journal> <volume> volume 1. </volume> <publisher> Academic Press, </publisher> <year> 1979. </year>
Reference-contexts: The accuracy of the estimate increases, as additional measurements are fused, i.e. k k1 ( k1 k is nonnegative definite). Fusion of a constraint or a real measurement into the solution is performed, using the extended Kalman f ilter (E.K.F.) <ref> [12] </ref>. In addition local iterations [12] are performed in order to reduce the influence of the linearization effect on the final solution. Detailed explanation with full equations about the measurements and constraints fusion can be found in [8]. <p> The accuracy of the estimate increases, as additional measurements are fused, i.e. k k1 ( k1 k is nonnegative definite). Fusion of a constraint or a real measurement into the solution is performed, using the extended Kalman f ilter (E.K.F.) <ref> [12] </ref>. In addition local iterations [12] are performed in order to reduce the influence of the linearization effect on the final solution. Detailed explanation with full equations about the measurements and constraints fusion can be found in [8].
Reference: [13] <author> I.J. Mulligan, A.K. Mackworth, and P.D. Lawrence. </author> <title> A model-based vision system for manipulator position sensing. In Workshop on Interpretation of 3D Scenes, </title> <address> Austin, Texas, </address> <pages> pages 186-193, </pages> <year> 1989. </year>
Reference-contexts: Both, the positioning and the interpretation problems are well documented in the literature (for reviews see [15, 16, 2]) however, the majority of the papers deal with 3D rigid objects and little attention has been given to articulated or constrained objects (e.g. <ref> [3, 6, 11, 13] </ref>). fl This research has been sponsered by the U.S. Office of Naval Research under Grant N00014-93-1202, R&T Project Code 4424341-01. An articulated object is an object composed of a set of rigid components connected at joints which allow certain degrees of freedom. <p> We call these kind of models constrained models. Existing methods that deal with constrained objects are restricted to deal with articulated models (e.g. <ref> [3, 6, 11, 13] </ref>). They deal with constraints that are due to prismatic or revolute joints. In this paper we present a general framework that can deal with all types of spatial constraints and is not limited to any particular type. <p> Lowe [11] follows this method and estimates the free parameters of the viewpoint and of the model using Newton iterations. A similar method was used by Brooks [4] in the well known system ACRONYM. Mulligan et. al. <ref> [13] </ref> use the same approach for estimating the positions of an excavator's arm. The main problem in the method of parameter reduction is the need for defining the dependence of each measurement on all the free parameters during the estimation process.
Reference: [14] <author> A. Shmuel and M. Werman. </author> <title> Active vision: 3D depth from an image sequence. </title> <booktitle> In ICPR, </booktitle> <pages> pages 48-54, </pages> <year> 1990. </year>
Reference-contexts: Measurements of the 3D location of the points and the measurement uncertainty were obtained from stereo image pairs. This data is noisy due to digitization, inconsistent lighting and imprecise feature matching. The uncertainty due to noise were modeled according to the auto-correlation of the image features <ref> [14] </ref>. We estimated the pose of the lamp components from the noisy 3D measurements and from the constraints using our technique. The evaluated vector is a 23 3 dimensional location vector composed of the 23 locations of the model points.
Reference: [15] <author> R.Y. Tsai. </author> <title> A versatile camera calibration technique for high-accuracy 3D machine vision metrology using off-the-shelf tv cameras and lenses. </title> <journal> IEEE Journal of Robotics and Automation, </journal> <volume> 3(4) </volume> <pages> 323-344, </pages> <month> Aug </month> <year> 1987. </year>
Reference-contexts: This correspondence is necessary in localization procedures which are based on local features of the model. Both, the positioning and the interpretation problems are well documented in the literature (for reviews see <ref> [15, 16, 2] </ref>) however, the majority of the papers deal with 3D rigid objects and little attention has been given to articulated or constrained objects (e.g. [3, 6, 11, 13]). fl This research has been sponsered by the U.S. Office of Naval Research under Grant N00014-93-1202, R&T Project Code 4424341-01.

References-found: 15

