URL: http://http.cs.berkeley.edu/~ss/papers/vlsisys93.ps.gz
Refering-URL: http://http.cs.berkeley.edu/~ss/papers.html
Root-URL: 
Title: RAID-II: Design and Implementation of a Large Scale Disk Array Controller 1  
Author: R. H. Katz, P. M. Chen, A. L. Drapeau, E. K. Lee, K. Lutz, E. L. Miller, S. Seshan, D. A. Patterson 
Address: Berkeley, CA 94720  
Affiliation: Computer Science Division Electrical Engineering and Computer Science Department University of California, Berkeley  
Note: Page 1 of 17  
Abstract: We describe the implementation of a large scale disk array controller and subsystem incorporating over 100 high performance 3.5" disk drives. It is designed to provide 40 MB/s sustained performance and 40 GB capacity in three 19" racks. The array controller forms an integral part of a file server that attaches to a Gb/s local area network. The controller implements a high bandwidth interconnect between an interleaved memory, an XOR calculation engine, the network interface (HIPPI), and the disk interfaces (SCSI). The system is now functionally operational, and we are tuning its performance. We review the design decisions, history, and lessons learned from this three year university implementation effort to construct a truly large scale system assembly. 
Abstract-found: 1
Intro-found: 1
Reference: [Chervenak 91] <author> A. L. Chervenak, R. H. Katz, </author> <title> Performance Measurements of the First RAID Prototype, </title> <booktitle> Proceedings ACM SIGMETRICS Conference, </booktitle> <address> San Diego, CA, </address> <month> (May </month> <year> 1991). </year>
Reference-contexts: While we had hoped the design would be disk limited, <ref> [Chervenak 91] </ref> discovered numerous performance bottlenecks. The most serious is the servers memory system, which limited application throughput to only 2.3 MB/s. I/O operations caused excessive memory-to-memory copies and cache ushes. The array did better on small random reads, achieving nearly 300 per second before the server becomes CPU-limited.
Reference: [Katz 92] <author> R. H. Katz, </author> <title> High Performance Network and Channel-Based Storage, </title> <booktitle> Proceedings of the IEEE, V. </booktitle> <volume> 80, </volume> <editor> N. </editor> <volume> 8, </volume> <month> (August </month> <year> 1992). </year>
Reference-contexts: We also discuss the Ultranet Gb/s local area network and lessons we learned from our first prototype. More details on the underlying technologies can be found in <ref> [Katz 92] </ref>. 2.1. Redundant Arrays of Inexpensive Disks RAIDs (Redundant Arrays of Inexpensive Disks) are disk system organizations that store redundant data to achieve high availability. Methods that improve availability through data redundancy always sacrifice some storage capacity and write bandwidth. <p> As described above, our original plan was to use a single wide, high bandwidth bus to interconnect the HIPPI interfaces, the SCSI disk interfaces, and the memory system. This is similar in style to the organization of the strategy HIPPI RAID-3 product described in <ref> [Katz 92] </ref>. We made considerable progress on this design, but we were forced to abandon it in mid-1990 when we learned that the OS designers could not force network headers to be aligned on eight byte boundaries.
Reference: [Lee 92] <author> E. K. Lee, P. M. Chen, J. H. Hartman, A. L. Drapeau, E. L. Miller, R. H. Katz, G. A. Gibson, D. A. Patterson, </author> <title> RAID-II: A Scalable Storage Architecture for High-Bandwidth Network File Service, </title> <type> Technical Report UCB/CSD 92/672, </type> <month> (February </month> <year> 1992). </year>
Reference-contexts: Our hardware design effort has focused on building a large, double-sided printed circuit board in surface mount technology that integrates several commercially available subsystems. The distributed file services are being developed within Sprite <ref> [Lee 92] </ref>. This paper describes the design context, goals, and constraints for RAID-II, a disk array controller that interfaces a file server with a Gb/s local area network. The rest of the paper is organized as follows.
Reference: [Patterson 88] <author> D. A. Patterson, G. A. Gibson, R. H. Katz, </author> <title> The Case for RAID: Redundant Arrays of Inexpensive Disks, </title> <booktitle> Proceedings ACM SIGMOD Conference, </booktitle> <address> Chicago, IL, </address> <month> (May </month> <year> 1988), </year> <pages> pp. 106113. </pages>
Reference-contexts: Methods that improve availability through data redundancy always sacrifice some storage capacity and write bandwidth. Alternative RAID organizations tradeoff between availability, I/O performance, and the redundancy overhead <ref> [Patterson 88] </ref>. The organization best suited for high availability and high I/O operation and data rate is the parity array (RAID Level 5). We describe it and the SCSI device interface next. RAID Level 5: Interleaved Parity The array is partitioned into independent recovery groups of N data disks each.
Reference: [Rosenblum 91] <author> M. Rosenblum, J. Ousterhout, </author> <title> The Design and Implementation of a Log-structured File System, </title> <booktitle> Proc. ACM Symp. on Operating Systems Principles, </booktitle> <month> (October </month> <year> 1991). </year>
Reference-contexts: Thus, the array write rate is reduced to 25% of a conventional disk system. The Log Structured File System developed at Berkeley circumvents this problem by treating disk as an append-only medium to which large segments are written. Parity can be computed in advance for these large, stripe-oriented writes <ref> [Rosenblum 91] </ref>. Small Computer System Interface SCSI is the storage interface supported by small formfactor disk drives. It views a disk drive as a linear byte stream; its detailed structure in terms of sectors, tracks, and cylinders is not visible.
References-found: 5

