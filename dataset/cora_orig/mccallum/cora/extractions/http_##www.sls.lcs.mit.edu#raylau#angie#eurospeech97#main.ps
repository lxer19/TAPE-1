URL: http://www.sls.lcs.mit.edu/raylau/angie/eurospeech97/main.ps
Refering-URL: http://www.sls.lcs.mit.edu/raylau/publications.html
Root-URL: 
Email: http://www.sls.lcs.mit.edu, mailto:fraylau, seneffg@mit.edu  
Title: PROVIDING SUBLEXICAL CONSTRAINTS FOR WORD SPOTTING WITHIN THE ANGIE FRAMEWORK 1 a feasible framework for
Author: Raymond Lau and Stephanie Seneff 
Note: ANGIE provides  
Address: Cambridge, Massachusetts 02139 USA  
Affiliation: Spoken Language Systems Group Laboratory for Computer Science Massachusetts Institute of Technology  
Abstract: We describe our recent work in implementing a word-spotting system based on the ANGIE framework and the effects of varying the nature of the sublexical constraints placed upon the word-spotter's filler model. ANGIE is a framework for modelling speech where the morphological and phonological substructures of words are jointly characterized by a context-free grammar and are represented in a multi-layered hierarchical structure. In this representation, the upper layers capture syllabification, morphology, and stress, the preterminal layer represents phonemics, and the bottom terminal categories are the phones. ANGIE provides a flexible framework where we can explore the effects of sublex-ical constraints within a word-spotting environment. Our experiments with spotting city names in ATIS validate the intuition that increasing the constraints present in the model improves performance, from 85.3 FOM for phone bigram to 89.3 FOM for a word lexicon. They also empirically strengthens our belief that 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> G. Chung and S. Seneff, </author> <title> Hierarchical duration modeling for speech recognition using the ANGIE framework, </title> <booktitle> in Proc. Eurospeech '97, </booktitle> <address> Rhodes, Greece, </address> <month> Sept. </month> <year> 1997. </year> <note> These proceedings. </note>
Reference: [2] <author> D. A. Dahl, M. Bates, M. Brown, W. Fisher, K. Hunicke-Smith, D. Pallett, C. Pao, A. Rudnicky, and E. Shriberg, </author> <title> Expanding the scope of the ATIS task: The ATIS-3 corpus, </title> <booktitle> in Proc. ARPA Human Language Technology Workshop '92, </booktitle> <address> Plainsboro, NJ, </address> <pages> pp. 4550, </pages> <month> Mar. </month> <year> 1992. </year>
Reference: [3] <author> A. S. Manos, </author> <title> A study on out-of-vocabulary word mod-elling for a segment-based keyword spotting system, </title> <type> Master's thesis, </type> <institution> Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, </institution> <address> Cambridge, MA, </address> <month> Apr. </month> <year> 1996. </year>
Reference-contexts: From top to bottom, the layers shown are: sentence, word, morphology, syllabification, phonemics, and phonetics. word spotter (e.g., <ref> [3] </ref>, [5], [6]). We naturally believe that a similar conclusion holds for subword lexical modelling as well. Since the ANGIE framework (discussed in detail in the next section) makes it easy to vary the types of sub-word lexical constraints imposed, we explore their impact in the present work. 2.
Reference: [4] <author> D. B. Paul, </author> <title> Efficient A fl stack decoder algorithm for continuous speech recognition with a stochastic language model, </title> <type> Tech. Rep. TR 930, </type> <institution> MIT Lincoln Laboratory, </institution> <month> July </month> <year> 1991. </year>
Reference-contexts: We experimented with several normalization and pruning schemes to no avail. Instead, we decided to change our search control strategy altogether. We settled upon a variant of the stack decoder suggested in <ref> [4] </ref>. Our search operates as follows: 1. Initialize the stack with a null theory. 2. Of the shortest (in terms of ending time) theories, pop the best (highest scoring) theory off the stack. 3.
Reference: [5] <author> J. Rohlicek, P. Jeanrenaud, K. Ng, H. Gish, B. Musicus, and M. Shiu, </author> <title> Phonetic training and language modeling for word spotting, </title> <booktitle> in Proc. ICASSP '93, </booktitle> <address> Minneapolis, MN, </address> <pages> pp. </pages> <address> II459II462, </address> <month> Apr. </month> <year> 1993. </year>
Reference-contexts: From top to bottom, the layers shown are: sentence, word, morphology, syllabification, phonemics, and phonetics. word spotter (e.g., [3], <ref> [5] </ref>, [6]). We naturally believe that a similar conclusion holds for subword lexical modelling as well. Since the ANGIE framework (discussed in detail in the next section) makes it easy to vary the types of sub-word lexical constraints imposed, we explore their impact in the present work. 2.
Reference: [6] <author> R. C. Rose, </author> <title> Definition of subword acoustic units for wordspotting, </title> <booktitle> in Proc. Eurospeech '93, </booktitle> <address> Berlin, Germany, </address> <pages> pp. 10491052, </pages> <month> Sept. </month> <year> 1993. </year>
Reference-contexts: From top to bottom, the layers shown are: sentence, word, morphology, syllabification, phonemics, and phonetics. word spotter (e.g., [3], [5], <ref> [6] </ref>). We naturally believe that a similar conclusion holds for subword lexical modelling as well. Since the ANGIE framework (discussed in detail in the next section) makes it easy to vary the types of sub-word lexical constraints imposed, we explore their impact in the present work. 2.
Reference: [7] <author> S. Seneff, R. Lau, and H. Meng, </author> <title> ANGIE: A new framework for speech analysis based on morpho-phonological modelling, </title> <booktitle> in Proc. ICSLP '96, Philadel-phia, PA, </booktitle> <volume> vol. 1, </volume> <pages> pp. 110113, </pages> <month> Oct. </month> <year> 1996. </year> <note> URL http://www.sls.lcs.mit.edu/raylau/icslp96 angie.pdf. </note>
Reference-contexts: Finally, knowledge of the subword structure provided by an ANGIE parse also permits us to potentially improve our acoustic modelling. Later, we will discuss some related work involving hierarchical duration modelling and its impact on word-spotting performance. 3. ANGIE BASED WORD-SPOTTER We previously reported in <ref> [7] </ref> on the feasibility of the ANGIE framework in two intermediate speech recognition tasks: phonemic-to-phonetic alignment and phonetic recognition. Word-spotting provides a natural next task to tackle. <p> Besides reducing the search complexity greatly, this also mitigates sparse data problems which tend to occur across word boundaries. So far, the system we have presented resembles very much the phonetic recognizer we used in <ref> [7] </ref>. However, several critical changes were needed. The best-first search strategy used by our phonetic recognizer proved to be unworkable in the context of a word-spotter. We have found that the issues involved in normalizing short vs. long theories so that their scores can be reasonably compared are extremely complex.
Reference: [8] <institution> The road rally word-spotting corpora (RDRALLY1), </institution> <month> Sept. </month> <year> 1991. </year> <note> NIST Speech Disc 6-1.1. </note>
Reference-contexts: For testing, we use the Dec '93 test set. Our word-spotting task is 39 city names. Given the keyword hypotheses generated, as described in the previous section, we plot a receiver operating characteristics (ROC) curve and compute a figure of merit (FOM) according to the procedure prescribed in <ref> [8] </ref>. 5. VARYING THE FILLER We have run a series of experiments with our ANGIE word-spotter where we varied the subword modelling of the filler. In all cases, the full ANGIE model was used to model the keywords.
Reference: [9] <author> V. Zue, J. Glass, M. Phillips, and S. Seneff, </author> <title> The MIT SUMMIT speech recognition system: A progress report, </title> <booktitle> in Proc. DARPA Speech and Natural Language Workshop Feb '89, </booktitle> <address> Philadelphia, PA, </address> <pages> pp. 179189, </pages> <month> Feb. </month> <year> 1989. </year>
Reference: [10] <author> V. Zue, S. Seneff, J. Polifroni, M. Phillips, C. Pao, D. God-deau, J. Glass, and E. Brill, </author> <title> The MIT ATIS system: </title> <booktitle> De-cember 1993 progress report, in Proc. ARPA Spoken Language Technology Workshop '94, </booktitle> <address> Plainsboro, NJ, </address> <pages> pp. 66 71, </pages> <month> Mar. </month> <year> 1994. </year>
References-found: 10

