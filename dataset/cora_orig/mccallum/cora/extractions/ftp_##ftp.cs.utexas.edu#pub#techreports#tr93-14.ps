URL: ftp://ftp.cs.utexas.edu/pub/techreports/tr93-14.ps
Refering-URL: http://www.cs.utexas.edu/users/vlr/pub.html
Root-URL: 
Title: Implementation of Parallel Graph Algorithms on a Massively Parallel SIMD Computer with Virtual Processing  
Author: Tsan-sheng Hsu Vijaya Ramachandran Nathaniel Dean 
Keyword: Key words and phrases: parallel algortithms, graph algorithms, implementation, virtual processing, MasPar.  
Note: Supported by NSF Grant CCR-90-23059 and Texas Advanced Research Projects Grant 003658480. Also supported by an IBM graduate fellowship.  
Date: July 22, 1993  
Address: Austin, TX 78712  Morristown, NJ 07960  
Affiliation: Department of Computer Sciences University of Texas at Austin  Combinatorics and Optimization Research Bell Communications Research  
Abstract: We describe our implementation of several PRAM graph algorithms on the massively parallel computer MasPar MP-1 with 16,384 processors. Our implementation incorporated virtual processing and we present extensive test data. In a previous project [13], we reported the implementation of a set of parallel graph algorithms with the constraint that the maximum input size was restricted to be no more than the physical number of processors on the MasPar. The MasPar language MPL that we used for our code does not support virtual processing. In this paper, we describe a method of simulating virtual processors on the MasPar. We re-coded and fine-tuned our earlier parallel graph algorithms to incorporate the usage of virtual processors. Under the current implementation scheme, there is no limit on the number of virtual processors that one can use in the program as long as there is enough main memory to store all the data required during the computation. We also give two general optimization techniques to speed up our computation. We tested our code with virtual processing on test graphs with various edge densities. We also compared the performance data for our parallel code with the performance data of sequential code for these problems. We found that the extra overhead for simulating virtual processors is moderate and the performance of our code tracks theoretical predictions quite well, although real-time speed-ups are quite small since the MasPar processors are rather slow. In addition, our parallel code using virtual processing runs on much larger size inputs than our sequential code. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Anderson and J. Setubal. </author> <title> On the parallel implementation of Goldberg's maximum flow algorithm. </title> <booktitle> In Proc. 4th ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pages 168-177, </pages> <year> 1992. </year>
Reference-contexts: 1 Introduction This paper describes an on-going project for implementing parallel graph algorithms on the massively parallel machine MasPar MP-1. There has been a fair amount of prior work on implementing parallel algorithms on massively parallel machines <ref> [1, 5, 9, 10, 11, 25, 29] </ref> since the completion of the first phase of our project reported in [13]. However, most of this work has been targeted towards solving problems that are highly structured and are not very difficult to scale up.
Reference: [2] <author> B. Awerbuch and Y. Shiloach. </author> <title> New connectivity and MSF algorithms for shu*e-exchange network and PRAM. </title> <journal> IEEE Tran. on Computers, </journal> <pages> pages 1258-1263, </pages> <month> October </month> <year> 1987. </year>
Reference-contexts: package in [29] can only handle the case when the number of virtual processors simulated by each physical processor is a power of two, our code inherited the same restriction. 13 5.2.2 Graph Application Routines We implemented parallel algorithms for the following problems using the above kernel. (1) Spanning forest <ref> [2] </ref>. (2) Minimum cost spanning forest [2]. (3) Cut edges [31]. (4) Ear decomposition of a two-edge connected undirected graph [31]. (5) Open ear decomposition of a biconnected undirected graph [31] (this algorithm was not implemented in [13]). (6) Strong orientation of a two-edge connected undirected graph [31]. 6 Performance Analysis <p> the case when the number of virtual processors simulated by each physical processor is a power of two, our code inherited the same restriction. 13 5.2.2 Graph Application Routines We implemented parallel algorithms for the following problems using the above kernel. (1) Spanning forest <ref> [2] </ref>. (2) Minimum cost spanning forest [2]. (3) Cut edges [31]. (4) Ear decomposition of a two-edge connected undirected graph [31]. (5) Open ear decomposition of a biconnected undirected graph [31] (this algorithm was not implemented in [13]). (6) Strong orientation of a two-edge connected undirected graph [31]. 6 Performance Analysis We tested our code by generating <p> The function value of each fitted curve is the running time in seconds. 6.4.1 Finding a Spanning Forest For the parallel implementation, we modified the CRCW PRAM algorithm in <ref> [2] </ref> for finding connected components to find a spanning forest of the input graph. The original algorithm partitions the set of vertices into a set of disjoint sets such that vertices in each set are in the same connected component. Initially, the algorithm puts a vertex in each set. <p> The corresponding fitted curves for the sequential performance data when the data is within the main memory are 0:17x 0 , 0:17x 0 , and 0:15x 0 . 6.4.2 Finding a Minimum Spanning Forest For the parallel implementation, we modified the algorithm in <ref> [2] </ref> for finding connected components to find a minimum cost spanning forest for the input graph. This algorithm also partitions the graph into disjoint sets of vertices.
Reference: [3] <author> T. Blank. </author> <title> The MasPar MP-1 architecture. </title> <booktitle> In Proc. of COMPCON Spring 90 - 35th IEEE Computer Society International Conference, </booktitle> <pages> pages 20-40, </pages> <year> 1990. </year>
Reference-contexts: All of its parallel processors synchronously execute the same instruction at the same time. A simplified version of its architecture is shown in Figure 1. For details, see <ref> [3] </ref>. Each physical processor (called a PE) is a 4-bit CPU with 64 kilobytes of main memory and a unique ID ranging from 0 to 16,383. Through the emulation of microcode, each PE can perform operations on 8-bit, 16-bit, 32-bit, and 64-bit data.
Reference: [4] <author> G. E. Blelloch. </author> <title> Scan Primitives and Parallel Vector Models. </title> <type> PhD thesis, </type> <institution> M.I.T., </institution> <month> October </month> <year> 1989. </year>
Reference-contexts: In view of the above, a natural strategy is to use parallel algorithms developed on an abstract parallel machine model. Several abstract models that are closely related to real parallel machine architectures have been proposed <ref> [4, 8, 12, 33] </ref>. Instead of using a new model, we have performed a direct implementation of parallel algorithms based on the popular PRAM model [14, 15, 32]. <p> The reason for our choice is that in our implementation of parallel algorithms, we frequently need to use operations that can utilize the locality of data (e.g. the prefix sum (scan) operator <ref> [4] </ref>). This type of data partitioning enables us to preserve the locality of data.
Reference: [5] <author> G. E. Blelloch, C. E. Leiserson, B. M. Maggs, C. G. Plaxton, S. J. Smith, and M. Zagha. </author> <title> A comparison of sorting algorithms for the Connection Machine CM-2. </title> <booktitle> In Proc. 3th ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pages 3-16, </pages> <year> 1991. </year>
Reference-contexts: 1 Introduction This paper describes an on-going project for implementing parallel graph algorithms on the massively parallel machine MasPar MP-1. There has been a fair amount of prior work on implementing parallel algorithms on massively parallel machines <ref> [1, 5, 9, 10, 11, 25, 29] </ref> since the completion of the first phase of our project reported in [13]. However, most of this work has been targeted towards solving problems that are highly structured and are not very difficult to scale up. <p> However, these supports for using virtual processors come with the penalty of having a very large overhead. Programs that want to achieve a high percentage of machine utilization are either coded in low level programming language (e.g. the Paris language in the Connection Machine <ref> [5] </ref>) or coded in a language that does not support virtual processing (e.g. the MPL language in the MasPar [13, 29]). We have used the latter approach in the current work. Our results are reported in the following sections which are organized as follows. <p> For parallel algorithms using this approach, see [17, 30]. However, this time-consuming process must be carried out each time a new architecture arrives. This approach may be useful for some of the very important subroutines used in the machine (e.g. sorting <ref> [5, 29] </ref>). However, for complicated combinatorial problems, reinventing different algorithms for different architectures tends not to be a feasible solution. As the problems get more complicated, it takes longer time to derive efficient algorithms.
Reference: [6] <author> R. P. Brent. </author> <title> The parallel evaluation of general arithmetic expressions. </title> <journal> J. ACM, </journal> <volume> 21 </volume> <pages> 201-206, </pages> <year> 1974. </year>
Reference-contexts: However, the parallel primitives coded can be used with any number of processors by invoking Brent's scheduling principle <ref> [6, 15] </ref> to simulate several virtual processors on one physical processor. To do this, we extended our mapping scheme to handle the allocation and simulation of virtual processors. The extended mapping will be described in Section 4.2.
Reference: [7] <author> N. Dean, M. Mevenkamp, and C. L. Monma. NETPAD: </author> <title> An interface graphics system for network modeling and optimization. </title> <booktitle> In Proc. Computer Science & Operations Research: New Developments in their Interfaces, </booktitle> <pages> pages 231-243. </pages> <publisher> Pergamon Press, </publisher> <year> 1992. </year>
Reference-contexts: The likely reason is that we use a depth-first search in our sequential programs, which is a recursive program whose depth of recursion could be as large as the number of nodes in the graph. Our sequential programs were implemented with the help of the graph package NETPAD <ref> [7] </ref> developed in Bellcore as described in [13]. NETPAD uses a lot of extra memory in creating a standard graph data structure. Thus we might save space by coding the sequential algorithms from scratch.
Reference: [8] <author> E. Dekel, D. Nassimi, and S. Sahni. </author> <title> Parallel matrix and graph algorithms. </title> <journal> SIAM J. Comput., </journal> <volume> 10 </volume> <pages> 657-675, </pages> <year> 1981. </year>
Reference-contexts: In view of the above, a natural strategy is to use parallel algorithms developed on an abstract parallel machine model. Several abstract models that are closely related to real parallel machine architectures have been proposed <ref> [4, 8, 12, 33] </ref>. Instead of using a new model, we have performed a direct implementation of parallel algorithms based on the popular PRAM model [14, 15, 32].
Reference: [9] <author> B. Dixon and A. K. Lenstra. </author> <title> Factoring integers using SIMD sieves. </title> <type> Manuscript, </type> <year> 1992. </year>
Reference-contexts: 1 Introduction This paper describes an on-going project for implementing parallel graph algorithms on the massively parallel machine MasPar MP-1. There has been a fair amount of prior work on implementing parallel algorithms on massively parallel machines <ref> [1, 5, 9, 10, 11, 25, 29] </ref> since the completion of the first phase of our project reported in [13]. However, most of this work has been targeted towards solving problems that are highly structured and are not very difficult to scale up.
Reference: [10] <author> B. Dixon and A. K. Lenstra. </author> <title> Massively parallel elliptic curve factoring. </title> <type> Manuscript, </type> <year> 1992. </year>
Reference-contexts: 1 Introduction This paper describes an on-going project for implementing parallel graph algorithms on the massively parallel machine MasPar MP-1. There has been a fair amount of prior work on implementing parallel algorithms on massively parallel machines <ref> [1, 5, 9, 10, 11, 25, 29] </ref> since the completion of the first phase of our project reported in [13]. However, most of this work has been targeted towards solving problems that are highly structured and are not very difficult to scale up.
Reference: [11] <author> W. Hightower, J. Prins, and J. Reif. </author> <title> Implementations of randomized sorting on large parallel machines. </title> <booktitle> In Proc. 4th ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pages 158-167, </pages> <year> 1992. </year>
Reference-contexts: 1 Introduction This paper describes an on-going project for implementing parallel graph algorithms on the massively parallel machine MasPar MP-1. There has been a fair amount of prior work on implementing parallel algorithms on massively parallel machines <ref> [1, 5, 9, 10, 11, 25, 29] </ref> since the completion of the first phase of our project reported in [13]. However, most of this work has been targeted towards solving problems that are highly structured and are not very difficult to scale up.
Reference: [12] <author> W. D. Hillis and G. L. Steele Jr. </author> <title> Data parallel algorithms. </title> <journal> Communications of the ACM, </journal> <volume> 29 </volume> <pages> 1170-1183, </pages> <year> 1986. </year>
Reference-contexts: In view of the above, a natural strategy is to use parallel algorithms developed on an abstract parallel machine model. Several abstract models that are closely related to real parallel machine architectures have been proposed <ref> [4, 8, 12, 33] </ref>. Instead of using a new model, we have performed a direct implementation of parallel algorithms based on the popular PRAM model [14, 15, 32].
Reference: [13] <author> T.-s. Hsu, V. Ramachandran, and N. Dean. </author> <title> Implementation of parallel graph algorithms on the MasPar. </title> <note> In AMS Proc. of DIMACS Workshop on Computational Support for 25 Discrete Math., to appear. Also available as TR-92-38, </note> <institution> Dept. of Comp. Sci., Univ. of Texas at Austin. </institution>
Reference-contexts: There has been a fair amount of prior work on implementing parallel algorithms on massively parallel machines [1, 5, 9, 10, 11, 25, 29] since the completion of the first phase of our project reported in <ref> [13] </ref>. However, most of this work has been targeted towards solving problems that are highly structured and are not very difficult to scale up. The focus of our work is on solving graph-theoretical problems for which the algorithms require large amounts of non-oblivious memory accesses. In [13], we reported the implementation <p> our project reported in <ref> [13] </ref>. However, most of this work has been targeted towards solving problems that are highly structured and are not very difficult to scale up. The focus of our work is on solving graph-theoretical problems for which the algorithms require large amounts of non-oblivious memory accesses. In [13], we reported the implementation of several parallel graph algorithms on the Mas-Par MP-1 using the parallel language MPL [19, 20] which is an extension of the C language. <p> The MPL language provides a very efficient way of using the MasPar with the drawback of requiring the specification of the physical organization of the processors used in the program. Our implementation in <ref> [13] </ref> used an edge list data structure to store the input graph. An undirected edge (u; v) was stored twice as one directed edge from u to v and another directed edge from v to u. <p> Programs that want to achieve a high percentage of machine utilization are either coded in low level programming language (e.g. the Paris language in the Connection Machine [5]) or coded in a language that does not support virtual processing (e.g. the MPL language in the MasPar <ref> [13, 29] </ref>). We have used the latter approach in the current work. Our results are reported in the following sections which are organized as follows. Section 2 gives our implementation strategy and the programming environment of the MasPar MP-1. Section 3 gives a high-level description of our implementation. <p> Then we implemented efficient parallel graph algorithms developed on the PRAM model by calling routines in the kernel. Our experience with implementing PRAM graph algorithms on the MASPAR MP-1 as reported in this paper and in <ref> [13] </ref> supports our viewpoint that efficient PRAM algorithms are adaptable to run on real machines. <p> A PE that participates in a computation step is called active. Any step that uses plural variables will be executed by each active PE. For details, see <ref> [13, 26] </ref>. It is important to note that the current version of the MPL language does not support the use of virtual processors. <p> Thus we had to design and implement our own scheme for virtual processing. 3 High-Level Description of Our Implementation In our earlier implementation of parallel graph algorithms without virtual processing <ref> [13] </ref>, we first provided a general mapping between the architecture of the MasPar and the schematic 4 5 structure of the PRAM model. This mapping scheme took advantage of some of the special properties of the MasPar, although it was not fine-tuned for each individual routine. <p> We implemented a set of parallel graph algorithms without virtual processing by calling the parallel primitives we coded and routines provided in the system library as reported in <ref> [13] </ref>. Due to the constraints imposed by the programming environment on the MasPar, the above implementation requires the size of the input to be no more than the number of available physical processors. <p> To do this, we extended our mapping scheme to handle the allocation and simulation of virtual processors. The extended mapping will be described in Section 4.2. Using our original code when no virtual processors are used <ref> [13] </ref> as a blueprint and the extended mapping as a guideline, we transformed our code to handle the allocation of virtual processors. Since the MPL language does not support virtual processing, we had to implement our own scheme for virtual processing. <p> Since the MPL language does not support virtual processing, we had to implement our own scheme for virtual processing. To do this, we re-coded and fine-tuned the set of parallel primitives identified in <ref> [13] </ref> and several system library routines to handle the allocation of virtual processors efficiently. Then we implemented a set of parallel graph algorithms by calling these parallel primitives and system routines. <p> Then we implemented a set of parallel graph algorithms by calling these parallel primitives and system routines. The primitives and graph algorithms we implemented are described in Section 5. 4 Mapping Strategy In this section, we briefly describe the mapping scheme we used in <ref> [13] </ref> to map the PRAM model onto the MasPar architecture. We then describe the mapping scheme we used in allocating virtual processors. 4.1 Mapping of the PRAM Model onto the MasPar Architecture We briefly summarize the mapping scheme used in [13] to map a PRAM onto the MasPar architecture when the <p> section, we briefly describe the mapping scheme we used in <ref> [13] </ref> to map the PRAM model onto the MasPar architecture. We then describe the mapping scheme we used in allocating virtual processors. 4.1 Mapping of the PRAM Model onto the MasPar Architecture We briefly summarize the mapping scheme used in [13] to map a PRAM onto the MasPar architecture when the two machines have the same number of processors. We mapped part of the local memory in each PE and the local memory of the ACU onto the PRAM global 6 memory. <p> We put common read-only data into the local memory bank of the ACU and arranged for the ACU to broadcast the needed data to all PE's. We illustrate the mapping in Figure 2. More details of this mapping can be found in <ref> [13] </ref>. 4.2 Mapping of the Virtual Processors onto the MasPar Architecture In our programs, each virtual processor (or VPE) is given a unique ID ranging from 0 to vnproc 1, where vnproc is the number of virtual processors. (Note that nproc is the number of physical processors and they are organized <p> This type of data partitioning enables us to preserve the locality of data. Once our code decided on the vpr value, each plural variable allocated in the code in 7 <ref> [13] </ref> was transformed into a plural array of vpr elements in our new code. (The selection of the vpr value is discussed at the end of Section 5.1.3.) The ith element in the jth physical processor corresponded to the local copy of virtual processor (j 1)vpr +i. <p> Variables used in the code in <ref> [13] </ref> without the plural attribute were not changed in our new code. An extra flag (called active) in each virtual processor was allocated in our new code to indicate whether its corresponding virtual processor was active during each step of computation. <p> Since computing an Euler tour is one of the most common subroutines on trees used by parallel graph algorithms, we saved time by using this mapping. 5.1.3 Undirected Graph In our implementation without virtual processing <ref> [13] </ref>, a general undirected graph was represented by a list of edges. Each edge had two copies with the two end points interchanged. We placed an edge on a MasPar PE with the requirement that the two copies of the edge have to be located on adjacent PE's. <p> Data within each segment are rotated in a way similar to the rotation routine described in (2). (4) Range minimum [36]. (5) Euler tour construction [36]. (6) Preorder numbering [36]. (7) Least common ancestor [36]. When implementing the above routines in the kernel without virtual processing <ref> [13] </ref>, we also used the following routines that are provided in the system library. (1) Sorting. (2) Prefix sums. (3) Inter-processor communication. (4) Data combining. In our implementation of parallel algorithm with virtual processing, we also used the above routines. <p> parallel algorithms for the following problems using the above kernel. (1) Spanning forest [2]. (2) Minimum cost spanning forest [2]. (3) Cut edges [31]. (4) Ear decomposition of a two-edge connected undirected graph [31]. (5) Open ear decomposition of a biconnected undirected graph [31] (this algorithm was not implemented in <ref> [13] </ref>). (6) Strong orientation of a two-edge connected undirected graph [31]. 6 Performance Analysis We tested our code by generating test graphs and measuring the performance of the code on these test graphs. <p> In addition to testing our parallel code for the problems listed in Section 5.2.2, we also took the implementation of their corresponding sequential algorithms described in <ref> [13] </ref> and tested them on large inputs using SUN SPARC workstations. The corresponding sets of performance data were compared and studied. Note that a MasPar MP-1 PE is about 200 times slower than a SUN SPARC II and about 230 times slower than a SUN SPARC 10/41. <p> Then we describe the way we tested our programs and the curve-fitting scheme we performed on the sets of performance data. Finally, we analyze the performance data. Since no curve-fitting was performed in our earlier work without virtual processing <ref> [13] </ref>, for completeness, we include the data from [13] in our performance analysis using curve fitting. 6.1 Generation of Test Graphs We tested our programs using graphs of three different edge densities as described in Section 5.1.3 and [13]. <p> Then we describe the way we tested our programs and the curve-fitting scheme we performed on the sets of performance data. Finally, we analyze the performance data. Since no curve-fitting was performed in our earlier work without virtual processing <ref> [13] </ref>, for completeness, we include the data from [13] in our performance analysis using curve fitting. 6.1 Generation of Test Graphs We tested our programs using graphs of three different edge densities as described in Section 5.1.3 and [13]. <p> Since no curve-fitting was performed in our earlier work without virtual processing <ref> [13] </ref>, for completeness, we include the data from [13] in our performance analysis using curve fitting. 6.1 Generation of Test Graphs We tested our programs using graphs of three different edge densities as described in Section 5.1.3 and [13]. For testing the code for finding a spanning forest and a minimum spanning forest, we generated test graphs from the class of random graphs G n;m as described in [13]. <p> of Test Graphs We tested our programs using graphs of three different edge densities as described in Section 5.1.3 and <ref> [13] </ref>. For testing the code for finding a spanning forest and a minimum spanning forest, we generated test graphs from the class of random graphs G n;m as described in [13]. In addition, a random cost in the range from 0 to 99,999 (with repetition) on each edge, instead of from 0 to 999 as used in [13], was generated for testing the routine for finding a minimum spanning forest. <p> a spanning forest and a minimum spanning forest, we generated test graphs from the class of random graphs G n;m as described in <ref> [13] </ref>. In addition, a random cost in the range from 0 to 99,999 (with repetition) on each edge, instead of from 0 to 999 as used in [13], was generated for testing the routine for finding a minimum spanning forest. Test graphs with a given edge density, a given size, and a given property (e.g. biconnec-tivity) were generated using a similar method described in [13]. <p> repetition) on each edge, instead of from 0 to 999 as used in <ref> [13] </ref>, was generated for testing the routine for finding a minimum spanning forest. Test graphs with a given edge density, a given size, and a given property (e.g. biconnec-tivity) were generated using a similar method described in [13]. We generated a biconnected test graph with n vertices and m edges by first generating an empty graph with n vertices. 14 We then chose a random length k, 3 k n, and k isolated vertices at random. <p> After connecting all isolated vertices, we randomly added edges until all m edges were generated. A two-edge connected test graph with n vertices and m edges was generated in a similar fashion by "growing" ears that could possibly be cycles <ref> [13] </ref>. The test graphs for finding cut edges were generated as in [13]. 6.2 Testing Scheme For each size and sparsity, we generated four different test graphs. We ran each program on each test graph for 10 iterations and recorded the average of the 40 trials. <p> A two-edge connected test graph with n vertices and m edges was generated in a similar fashion by "growing" ears that could possibly be cycles <ref> [13] </ref>. The test graphs for finding cut edges were generated as in [13]. 6.2 Testing Scheme For each size and sparsity, we generated four different test graphs. We ran each program on each test graph for 10 iterations and recorded the average of the 40 trials. The results are plotted in figures 7 - 18. <p> The rest of the programs used 32 kilobytes for the largest-sized inputs that we have tested. We spent about 2 months to obtain all of our performance data. We ran the set of sequential algorithms implemented in <ref> [13] </ref> on a SUN SPARC 10/41 machine with 32 megabytes of memory and about 80 megabytes of swapping space on input sizes greater than 16,384. <p> Our sequential programs were implemented with the help of the graph package NETPAD [7] developed in Bellcore as described in <ref> [13] </ref>. NETPAD uses a lot of extra memory in creating a standard graph data structure. Thus we might save space by coding the sequential algorithms from scratch. <p> For all problems, we could handle input whose sizes are 4 to 5 times larger using our parallel code. The performance data when the input size is within 16,384 is taken from <ref> [13] </ref>. In [13], sequential programs were run on a SPARC II workstation for input sizes up to 16,384; parallel programs without virtual processing were run on a MasPar MP-1 computer with 16,384 processors using 4 kilobytes of memory per PE. 6.3 Least-Squares Curve Fitting We applied the least-squares fit package in <p> For all problems, we could handle input whose sizes are 4 to 5 times larger using our parallel code. The performance data when the input size is within 16,384 is taken from <ref> [13] </ref>. In [13], sequential programs were run on a SPARC II workstation for input sizes up to 16,384; parallel programs without virtual processing were run on a MasPar MP-1 computer with 16,384 processors using 4 kilobytes of memory per PE. 6.3 Least-Squares Curve Fitting We applied the least-squares fit package in Mathematica [38] <p> The data for programs without virtual processing is taken from <ref> [13] </ref>. In the following, x denotes the size of the input and x 0 is the size of the input in units of 10,000. <p> The data for parallel programs without virtual processing is from <ref> [13] </ref>. 0:31x 0 , 0:25x 0 , and 0:22x 0 . 6.5 Overhead for Implementing Virtual Processors We compared the amount of time used by our parallel programs with and without virtual processing. The performance data is shown in Table 1. <p> The performance data with no virtual processing is from <ref> [13] </ref>. Our implementation of parallel algorithms with virtual processing had excellent speed-ups on dense graphs and intermediate-density graphs in relation to the implementation without virtual processing. <p> We wrote more than 12,000 lines of parallel code for the set of parallel graph algorithms that we implemented with virtual processing. All of the work reported here (include testing) was done within one year. Note that 4,000 lines of parallel code were written in 12 weeks in <ref> [13] </ref> for the same set of parallel programs with no virtual processing. We consider our strategy for implementing parallel graph algorithms to be promising. * We examined the variation in data we obtained on the four different test graphs of a given size and a given edge density. <p> There are many avenues for future work. We list some of them. * The lack of a good graph manipulation package like NETPAD for handling large graphs 23 makes it difficult to debug our programs. In <ref> [13] </ref>, NETPAD was able to help the debugging and testing of our parallel implementation after we built an interface to use it on the MasPar. In our current implementation, the sizes of the graphs became too large for NETPAD to handle.
Reference: [14] <author> J. JaJa. </author> <title> An Introduction to Parallel Algorithms. </title> <publisher> Addison-Wesley, </publisher> <year> 1992. </year>
Reference-contexts: Several abstract models that are closely related to real parallel machine architectures have been proposed [4, 8, 12, 33]. Instead of using a new model, we have performed a direct implementation of parallel algorithms based on the popular PRAM model <ref> [14, 15, 32] </ref>. Although the PRAM is an idealized theoretical model that does not capture the real cost of performing inter-processor communications on the MasPar, we believe that it provides a good abstract model for developing parallel algorithms.
Reference: [15] <author> R. M. Karp and V. Ramachandran. </author> <title> Parallel algorithms for shared-memory machines. </title> <editor> In J. van Leeuwen, editor, </editor> <booktitle> Handbook of Theoretical Computer Science, </booktitle> <pages> pages 869-941. </pages> <publisher> North Holland, </publisher> <year> 1990. </year>
Reference-contexts: Several abstract models that are closely related to real parallel machine architectures have been proposed [4, 8, 12, 33]. Instead of using a new model, we have performed a direct implementation of parallel algorithms based on the popular PRAM model <ref> [14, 15, 32] </ref>. Although the PRAM is an idealized theoretical model that does not capture the real cost of performing inter-processor communications on the MasPar, we believe that it provides a good abstract model for developing parallel algorithms. <p> However, the parallel primitives coded can be used with any number of processors by invoking Brent's scheduling principle <ref> [6, 15] </ref> to simulate several virtual processors on one physical processor. To do this, we extended our mapping scheme to handle the allocation and simulation of virtual processors. The extended mapping will be described in Section 4.2. <p> These routines are as follows. (1) List ranking <ref> [15] </ref>. (2) Rotation. This routine rotates the data stored in a processor with ID i to the processor with ID (i + d) mod P , where d is an input to the routine and P is the number of PE's in the system. (3) Segmented rotation.
Reference: [16] <author> B. W. Kernighan and D. M. Ritchie. </author> <title> The C Programming language. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1988. </year> <note> Second Edition. </note>
Reference-contexts: We used the MPL high-level programming language for coding our programs. The current version of the MPL compiler [19, 20] is an extension of the ANSI C language <ref> [16] </ref> with data parallel constructs and a library of parallel primitives. (For details of the MPL language, see [23, 24]. An introduction to MPL is also given in [26].) In MPL, a variable can be declared with or without the attribute plural.
Reference: [17] <author> F. T. Leighton. </author> <title> Introduction to Parallel Algorithms and Architectures: Arrays, Trees, Hypercubes. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1992. </year>
Reference-contexts: Since parallel machines are widely diverse in their architectures, one can take advantage of the special properties offered by an architecture and fine-tune the algorithms to run well on a particular machine. For parallel algorithms using this approach, see <ref> [17, 30] </ref>. However, this time-consuming process must be carried out each time a new architecture arrives. This approach may be useful for some of the very important subroutines used in the machine (e.g. sorting [5, 29]). <p> This mapping scheme will be described in Section 4.1. (This approach has been used in simulating PRAM algorithms on various parallel architectures, e.g. see the section on simulating PRAM algorithms in <ref> [17] </ref>. However, most of the previous results do not have any implementation details and provide no performance data.) Using this mapping, we then coded each simple parallel primitive on the MasPar. While coding each primitive, we utilized the special properties of the MasPar to fine-tune our code.
Reference: [18] <author> C. Leiserson, Z. S. Abuhamdeh, D. Douglas, C. R. Feynmann, M. Ganmukhi, J. Hill, W. D. Hillis, B. Kuszmaul, M. St. Pierre, D. Wells, M. Wong, S-W Yang, and R. Zak. </author> <title> The network architecture of the Connection Machine CM-5. </title> <booktitle> In Proc. 4th ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pages 272-287, </pages> <year> 1992. </year>
Reference-contexts: A major advantage in using massively parallel machines with virtual processing is that we can solve problems on large-sized inputs that cannot be handled by conventional sequential machines. Several parallel machines offer the convenience of using virtual processors in their high-level programming languages. For example, the Connection Machine <ref> [18] </ref> offers the support of using virtual processors with the assistance of the hardware and microcodes in the C fl programming language. The parallel Fortran language used in the MasPar also supports the usage of virtual processors.
Reference: [19] <institution> MasPar Computer Co. </institution> <note> MasPar Parallel Application Language (MPL) Reference manual, version 2.0 edition, </note> <month> March </month> <year> 1991. </year>
Reference-contexts: The focus of our work is on solving graph-theoretical problems for which the algorithms require large amounts of non-oblivious memory accesses. In [13], we reported the implementation of several parallel graph algorithms on the Mas-Par MP-1 using the parallel language MPL <ref> [19, 20] </ref> which is an extension of the C language. The MPL language provides a very efficient way of using the MasPar with the drawback of requiring the specification of the physical organization of the processors used in the program. <p> In comparison, SUN SPARC II is more than 200 times faster than a MasPar PE, while SUN SPARC 10/41 is more than 230 times faster. We used the MPL high-level programming language for coding our programs. The current version of the MPL compiler <ref> [19, 20] </ref> is an extension of the ANSI C language [16] with data parallel constructs and a library of parallel primitives. (For details of the MPL language, see [23, 24].
Reference: [20] <author> MasPar Computer Co. </author> <title> MasPar Parallel Application Language (MPL) User Guide, </title> <note> version 2.0 edition, </note> <month> March </month> <year> 1991. </year>
Reference-contexts: The focus of our work is on solving graph-theoretical problems for which the algorithms require large amounts of non-oblivious memory accesses. In [13], we reported the implementation of several parallel graph algorithms on the Mas-Par MP-1 using the parallel language MPL <ref> [19, 20] </ref> which is an extension of the C language. The MPL language provides a very efficient way of using the MasPar with the drawback of requiring the specification of the physical organization of the processors used in the program. <p> This is called the global router. Processors can communicate with each other by using the global router. Mesh communications are about 200 times faster than global routing requests for transmitting 32-bit data <ref> [20, 28] </ref>. The MasPar also has an Array Control Unit (ACU) for controlling the PE's and executing sequential instructions. The MasPar PE is a very slow processor. <p> In comparison, SUN SPARC II is more than 200 times faster than a MasPar PE, while SUN SPARC 10/41 is more than 230 times faster. We used the MPL high-level programming language for coding our programs. The current version of the MPL compiler <ref> [19, 20] </ref> is an extension of the ANSI C language [16] with data parallel constructs and a library of parallel primitives. (For details of the MPL language, see [23, 24].
Reference: [21] <institution> MasPar Computer Co. MasPar System Overview, </institution> <note> version 2.0 edition, </note> <month> March </month> <year> 1991. </year>
Reference-contexts: The basic primitives should be fine-tuned for the real 3 machine, but the overall structure of a complex PRAM algorithm can be mapped directly on to the real machine. 2.2 Programming Environment The MasPar computer <ref> [21] </ref> is a fine-grained massively parallel single-instruction-multiple-data (SIMD) computer. All of its parallel processors synchronously execute the same instruction at the same time. A simplified version of its architecture is shown in Figure 1. For details, see [3].
Reference: [22] <institution> MasPar Computer Co. </institution> <note> MasPar Data Display Library (MPDDL) Reference manual, version 3.0, rev. a6 edition, </note> <month> July </month> <year> 1992. </year>
Reference-contexts: The virtual processors are arranged into a 2-dimensional vnxproc fi vnyproc mesh. For our implementation, we used the so-called hierarchical partitioning scheme <ref> [22] </ref>. Each physical processor simulated a vprfi1 sub-mesh of virtual processors.
Reference: [23] <institution> MasPar Computer Co. </institution> <note> MasPar Parallel Application Language (MPL) Reference manual, version 3.0, rev. a3 edition, </note> <month> July </month> <year> 1992. </year>
Reference-contexts: We used the MPL high-level programming language for coding our programs. The current version of the MPL compiler [19, 20] is an extension of the ANSI C language [16] with data parallel constructs and a library of parallel primitives. (For details of the MPL language, see <ref> [23, 24] </ref>. An introduction to MPL is also given in [26].) In MPL, a variable can be declared with or without the attribute plural.
Reference: [24] <author> MasPar Computer Co. </author> <title> MasPar Parallel Application Language (MPL) User Guide, </title> <note> version 3.1, rev. a3 edition, </note> <month> November </month> <year> 1992. </year>
Reference-contexts: We used the MPL high-level programming language for coding our programs. The current version of the MPL compiler [19, 20] is an extension of the ANSI C language [16] with data parallel constructs and a library of parallel primitives. (For details of the MPL language, see <ref> [23, 24] </ref>. An introduction to MPL is also given in [26].) In MPL, a variable can be declared with or without the attribute plural.
Reference: [25] <author> B. Narendran and P. Tiwari. </author> <title> Polynomial root-finding: Analysis and computational investigation of a parallel algorithm. </title> <booktitle> In Proc. 4th ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pages 178-187, </pages> <year> 1992. </year>
Reference-contexts: 1 Introduction This paper describes an on-going project for implementing parallel graph algorithms on the massively parallel machine MasPar MP-1. There has been a fair amount of prior work on implementing parallel algorithms on massively parallel machines <ref> [1, 5, 9, 10, 11, 25, 29] </ref> since the completion of the first phase of our project reported in [13]. However, most of this work has been targeted towards solving problems that are highly structured and are not very difficult to scale up.
Reference: [26] <author> R. Pickering and J. Cook. </author> <title> A first course in programming the DECmpp/Sx. </title> <type> Technical report, </type> <institution> para//lab, Dept. of Informatics, Univ. of Bergen, N-5020 Bergen, Norway, </institution> <year> 1993. </year> <title> Series of Parallel Processing: A Self-Study Introduction. </title> <type> 26 </type>
Reference-contexts: The current version of the MPL compiler [19, 20] is an extension of the ANSI C language [16] with data parallel constructs and a library of parallel primitives. (For details of the MPL language, see [23, 24]. An introduction to MPL is also given in <ref> [26] </ref>.) In MPL, a variable can be declared with or without the attribute plural. A plural variable has a local copy (possibly with different values) in each PE, while a variable without the plural attribute has only one copy in the ACU. <p> A PE that participates in a computation step is called active. Any step that uses plural variables will be executed by each active PE. For details, see <ref> [13, 26] </ref>. It is important to note that the current version of the MPL language does not support the use of virtual processors.
Reference: [27] <author> L. Prechelt. </author> <title> Comparison of MasPar MP-1 and MP-2 communication operations. </title> <type> Tech--nical Report 16/93, </type> <institution> Institute fur Programmstrukturen und Datenorganisation, Fakultat fur Informatik, Universitat Karlsruhe, Germany, </institution> <month> April </month> <year> 1993. </year>
Reference-contexts: The limitation of only having 64 kilobytes of memory per physical processor prevents us from running inputs of larger sizes. No support from the operating system for using virtual memory also inhibits us from running larger examples. It is reported in <ref> [27] </ref> that the new MasPar MP-2 upgrades the raw computation power of each individual processor while keeping its communication hardware and limitation of memory space unchanged.
Reference: [28] <author> L. Prechelt. </author> <title> Measurements of MasPar MP-1216A communication operations. </title> <type> Technical Report 01/93, </type> <institution> Institute fur Programmstrukturen und Datenorganisation, Fakultat fur Informatik, Universitat Karlsruhe, Germany, </institution> <month> January </month> <year> 1993. </year>
Reference-contexts: This is called the global router. Processors can communicate with each other by using the global router. Mesh communications are about 200 times faster than global routing requests for transmitting 32-bit data <ref> [20, 28] </ref>. The MasPar also has an Array Control Unit (ACU) for controlling the PE's and executing sequential instructions. The MasPar PE is a very slow processor.
Reference: [29] <author> J. F. Prins and J. A. Smith. </author> <title> Parallel sorting of large arrays on the MasPar MP-1. </title> <booktitle> In Proc. 3rd Symp. on the Frontiers of Massively Parallel Computation, </booktitle> <pages> pages 59-64, </pages> <year> 1990. </year>
Reference-contexts: 1 Introduction This paper describes an on-going project for implementing parallel graph algorithms on the massively parallel machine MasPar MP-1. There has been a fair amount of prior work on implementing parallel algorithms on massively parallel machines <ref> [1, 5, 9, 10, 11, 25, 29] </ref> since the completion of the first phase of our project reported in [13]. However, most of this work has been targeted towards solving problems that are highly structured and are not very difficult to scale up. <p> Programs that want to achieve a high percentage of machine utilization are either coded in low level programming language (e.g. the Paris language in the Connection Machine [5]) or coded in a language that does not support virtual processing (e.g. the MPL language in the MasPar <ref> [13, 29] </ref>). We have used the latter approach in the current work. Our results are reported in the following sections which are organized as follows. Section 2 gives our implementation strategy and the programming environment of the MasPar MP-1. Section 3 gives a high-level description of our implementation. <p> For parallel algorithms using this approach, see [17, 30]. However, this time-consuming process must be carried out each time a new architecture arrives. This approach may be useful for some of the very important subroutines used in the machine (e.g. sorting <ref> [5, 29] </ref>). However, for complicated combinatorial problems, reinventing different algorithms for different architectures tends not to be a feasible solution. As the problems get more complicated, it takes longer time to derive efficient algorithms. <p> For our implementation, we used the so-called hierarchical partitioning scheme [22]. Each physical processor simulated a vprfi1 sub-mesh of virtual processors. Thus given an nxprocfi nyproc 2-dimensional mesh, the virtual machine being simulated is an (nxprocvpr)finyproc 2-dimensional mesh. (The implementation of bitonic sort <ref> [29] </ref> with virtual processing used the same mapping scheme as ours.) We illustrate the mapping in Figure 3. <p> Since the MasPar does not provide virtual processing for these system routines, we coded and fine-tuned all of these routines with virtual processing except sorting. For sorting with virtual processing, we used the package developed in <ref> [29] </ref>. Since the sorting package in [29] can only handle the case when the number of virtual processors simulated by each physical processor is a power of two, our code inherited the same restriction. 13 5.2.2 Graph Application Routines We implemented parallel algorithms for the following problems using the above kernel. <p> Since the MasPar does not provide virtual processing for these system routines, we coded and fine-tuned all of these routines with virtual processing except sorting. For sorting with virtual processing, we used the package developed in <ref> [29] </ref>. Since the sorting package in [29] can only handle the case when the number of virtual processors simulated by each physical processor is a power of two, our code inherited the same restriction. 13 5.2.2 Graph Application Routines We implemented parallel algorithms for the following problems using the above kernel. (1) Spanning forest [2]. (2) Minimum <p> Work should be done for graph manipulation (especially visualization) packages on large graphs. * Our current implementation requires that vpr, the number of virtual processors simulated by each physical processor, be a power of 2 because of a bitonic sorting package <ref> [29] </ref> that we are using. We would like to replace this sorting package by a sorting routine that can simulate any number of virtual processors per physical processor. * We note that our current implementation has a very large overhead on sparse graphs.
Reference: [30] <author> M. J. Quinn. </author> <title> Designing Efficient Algorithms for Parallel Computers. </title> <publisher> McGraw-Hill, </publisher> <year> 1987. </year>
Reference-contexts: Since parallel machines are widely diverse in their architectures, one can take advantage of the special properties offered by an architecture and fine-tune the algorithms to run well on a particular machine. For parallel algorithms using this approach, see <ref> [17, 30] </ref>. However, this time-consuming process must be carried out each time a new architecture arrives. This approach may be useful for some of the very important subroutines used in the machine (e.g. sorting [5, 29]).
Reference: [31] <author> V. Ramachandran. </author> <title> Parallel open ear decomposition with applications to graph bicon-nectivity and triconnectivity. </title> <editor> In J. H. Reif, editor, </editor> <booktitle> Synthesis of Parallel Algorithms, </booktitle> <pages> pages 275-340. </pages> <publisher> Morgan-Kaufmann, </publisher> <year> 1993. </year>
Reference-contexts: Parallel algorithms developed on the PRAM model are often very modular in structure (or have parallel primitives). Problems are solved by calling these parallel primitives. For solving undirected graph problems, a set of parallel primitives required for constructing an ear decomposition has proved to be very useful <ref> [31, 37] </ref>. Our parallel implementation follows this approach. We first built a kernel which consists of commonly used routines in parallel graph algorithms. Then we implemented efficient parallel graph algorithms developed on the PRAM model by calling routines in the kernel. <p> number of virtual processors simulated by each physical processor is a power of two, our code inherited the same restriction. 13 5.2.2 Graph Application Routines We implemented parallel algorithms for the following problems using the above kernel. (1) Spanning forest [2]. (2) Minimum cost spanning forest [2]. (3) Cut edges <ref> [31] </ref>. (4) Ear decomposition of a two-edge connected undirected graph [31]. (5) Open ear decomposition of a biconnected undirected graph [31] (this algorithm was not implemented in [13]). (6) Strong orientation of a two-edge connected undirected graph [31]. 6 Performance Analysis We tested our code by generating test graphs and measuring <p> a power of two, our code inherited the same restriction. 13 5.2.2 Graph Application Routines We implemented parallel algorithms for the following problems using the above kernel. (1) Spanning forest [2]. (2) Minimum cost spanning forest [2]. (3) Cut edges <ref> [31] </ref>. (4) Ear decomposition of a two-edge connected undirected graph [31]. (5) Open ear decomposition of a biconnected undirected graph [31] (this algorithm was not implemented in [13]). (6) Strong orientation of a two-edge connected undirected graph [31]. 6 Performance Analysis We tested our code by generating test graphs and measuring the performance of the code on these test graphs. <p> 13 5.2.2 Graph Application Routines We implemented parallel algorithms for the following problems using the above kernel. (1) Spanning forest [2]. (2) Minimum cost spanning forest [2]. (3) Cut edges <ref> [31] </ref>. (4) Ear decomposition of a two-edge connected undirected graph [31]. (5) Open ear decomposition of a biconnected undirected graph [31] (this algorithm was not implemented in [13]). (6) Strong orientation of a two-edge connected undirected graph [31]. 6 Performance Analysis We tested our code by generating test graphs and measuring the performance of the code on these test graphs. <p> (1) Spanning forest [2]. (2) Minimum cost spanning forest [2]. (3) Cut edges <ref> [31] </ref>. (4) Ear decomposition of a two-edge connected undirected graph [31]. (5) Open ear decomposition of a biconnected undirected graph [31] (this algorithm was not implemented in [13]). (6) Strong orientation of a two-edge connected undirected graph [31]. 6 Performance Analysis We tested our code by generating test graphs and measuring the performance of the code on these test graphs. <p> corresponding fitted curves for the sequential performance data when the data is within the main memory are 0:1x 0 log x 0 + 5:44, 0:056x 0 log x 0 + 1:78, and 0:049x 0 log x 0 + 1:22. 6.4.3 Finding All Cut Edges Our parallel implementation is based on <ref> [31] </ref>. <p> This can be determined by using the Euler 18 tour technique and the range minimum queries. For sequential implementation, we used a linear time algorithm for finding all cut edges in the graph based on depth-first search <ref> [31] </ref>. The performance data without and with virtual processing are shown in Figures 11 and 12 respectively. <p> The corresponding fitted curves for the sequential performance data when the data is within the main memory are 0:22x 0 , 0:18x 0 , and 0:16x 0 . 6.4.4 Finding an Ear Decomposition For the parallel implementation, we used the PRAM parallel algorithm in <ref> [31] </ref> for finding an ear decomposition on a 2-edge connected graph by calling the sorting routine, routines in the kernel and the routine for finding a spanning forest. For sequential implementation, we used a linear time algorithm for finding an ear decomposition based on depth-first search [31]. <p> PRAM parallel algorithm in <ref> [31] </ref> for finding an ear decomposition on a 2-edge connected graph by calling the sorting routine, routines in the kernel and the routine for finding a spanning forest. For sequential implementation, we used a linear time algorithm for finding an ear decomposition based on depth-first search [31]. The performance data without and with virtual processing are shown in Figures 13 and 14 respectively. <p> The corresponding fitted curves for the sequential performance data when the data is within the main memory are 0:57x 0 , 0:72x 0 , and 0:68x 0 . 6.4.5 Finding an Open Ear Decomposition For the parallel implementation, we used the PRAM algorithm in <ref> [31] </ref> for finding an open ear decomposition. This routine is obtained by modifying the ear decomposition algorithm 19 mentioned in the previous section. The sequential ear decomposition algorithm mentioned in the previous section [31] also finds an open ear decomposition on a biconnected graph. <p> . 6.4.5 Finding an Open Ear Decomposition For the parallel implementation, we used the PRAM algorithm in <ref> [31] </ref> for finding an open ear decomposition. This routine is obtained by modifying the ear decomposition algorithm 19 mentioned in the previous section. The sequential ear decomposition algorithm mentioned in the previous section [31] also finds an open ear decomposition on a biconnected graph. The performance data without and with virtual processing are shown in Figures 15 and 16 respectively.
Reference: [32] <author> J. H. Reif, </author> <title> editor. Synthesis of Parallel Algorithms. </title> <publisher> Morgan-Kaufmann, </publisher> <year> 1993. </year>
Reference-contexts: Several abstract models that are closely related to real parallel machine architectures have been proposed [4, 8, 12, 33]. Instead of using a new model, we have performed a direct implementation of parallel algorithms based on the popular PRAM model <ref> [14, 15, 32] </ref>. Although the PRAM is an idealized theoretical model that does not capture the real cost of performing inter-processor communications on the MasPar, we believe that it provides a good abstract model for developing parallel algorithms.
Reference: [33] <author> J. T. Schwartz. </author> <title> Ultracomputers. </title> <journal> ACM Trans. on Programming Languages and Systems, </journal> <volume> 2 </volume> <pages> 484-521, </pages> <month> October </month> <year> 1980. </year>
Reference-contexts: In view of the above, a natural strategy is to use parallel algorithms developed on an abstract parallel machine model. Several abstract models that are closely related to real parallel machine architectures have been proposed <ref> [4, 8, 12, 33] </ref>. Instead of using a new model, we have performed a direct implementation of parallel algorithms based on the popular PRAM model [14, 15, 32].
Reference: [34] <author> R. E. Tarjan. </author> <title> Depth-first search and linear graph algorithms. </title> <journal> SIAM J. Comput., </journal> <volume> 1 </volume> <pages> 146-160, </pages> <year> 1972. </year>
Reference-contexts: For sequential implementation, we used a linear time algorithm for finding a strong orientation based on a recursive version of depth-first search <ref> [34] </ref>. The performance data without and with virtual processing are shown in Figures 17 and 18 respectively.
Reference: [35] <author> R. E. Tarjan. </author> <title> Data Structures and Network Algorithms. </title> <publisher> SIAM Press, </publisher> <address> Philadelphia, PA, </address> <year> 1983. </year>
Reference-contexts: Once the merge is completed, the edge that caused the merging is marked as one of the edges in the minimum cost spanning forest. For sequential implementation, we implemented the O (n + m log n)-time Kruskal's algorithm <ref> [35] </ref> for finding a minimum cost spanning forest. Although faster algorithms are known for this problem, we implemented Kruskal's algorithm for its simplicity. The performance data without and with virtual processing are shown in Figures 9 and 10 respectively.
Reference: [36] <author> R. E. Tarjan and U. Vishkin. </author> <title> An efficient parallel biconnectivity algorithm. </title> <journal> SIAM J. Comput., </journal> <volume> 14 </volume> <pages> 862-874, </pages> <year> 1985. </year>
Reference-contexts: We store data in each processor and partition the set of processors into sequences of consecutive segments. This routine rotates the data stored in each processor within each segment. Data within each segment are rotated in a way similar to the rotation routine described in (2). (4) Range minimum <ref> [36] </ref>. (5) Euler tour construction [36]. (6) Preorder numbering [36]. (7) Least common ancestor [36]. <p> This routine rotates the data stored in each processor within each segment. Data within each segment are rotated in a way similar to the rotation routine described in (2). (4) Range minimum <ref> [36] </ref>. (5) Euler tour construction [36]. (6) Preorder numbering [36]. (7) Least common ancestor [36]. When implementing the above routines in the kernel without virtual processing [13], we also used the following routines that are provided in the system library. (1) Sorting. (2) Prefix sums. (3) Inter-processor communication. (4) Data combining. <p> This routine rotates the data stored in each processor within each segment. Data within each segment are rotated in a way similar to the rotation routine described in (2). (4) Range minimum <ref> [36] </ref>. (5) Euler tour construction [36]. (6) Preorder numbering [36]. (7) Least common ancestor [36]. When implementing the above routines in the kernel without virtual processing [13], we also used the following routines that are provided in the system library. (1) Sorting. (2) Prefix sums. (3) Inter-processor communication. (4) Data combining. <p> This routine rotates the data stored in each processor within each segment. Data within each segment are rotated in a way similar to the rotation routine described in (2). (4) Range minimum <ref> [36] </ref>. (5) Euler tour construction [36]. (6) Preorder numbering [36]. (7) Least common ancestor [36]. When implementing the above routines in the kernel without virtual processing [13], we also used the following routines that are provided in the system library. (1) Sorting. (2) Prefix sums. (3) Inter-processor communication. (4) Data combining.
Reference: [37] <author> U. Vishkin. </author> <title> Structural parallel algorithmics. </title> <booktitle> In Proc. 18th ICALP, </booktitle> <volume> volume LNCS #510, </volume> <pages> pages 363-380. </pages> <publisher> Springer-Verlag, </publisher> <year> 1991. </year>
Reference-contexts: Parallel algorithms developed on the PRAM model are often very modular in structure (or have parallel primitives). Problems are solved by calling these parallel primitives. For solving undirected graph problems, a set of parallel primitives required for constructing an ear decomposition has proved to be very useful <ref> [31, 37] </ref>. Our parallel implementation follows this approach. We first built a kernel which consists of commonly used routines in parallel graph algorithms. Then we implemented efficient parallel graph algorithms developed on the PRAM model by calling routines in the kernel.

References-found: 37

