URL: ftp://ftp.cc.gatech.edu/pub/coc/tech_reports/1996/GIT-CC-96-04.ps.Z
Refering-URL: http://www.cs.gatech.edu/tech_reports/index.96.html
Root-URL: 
Title: Improving Protocol Performance by Dynamic Control of Communication Resources  
Author: Daniela Ivan-Ro~su Karsten Schwan 
Keyword: Quality of Service  
Address: Atlanta, Georgia 30332-0280  
Affiliation: College of Computing Georgia Institute of Technology  
Pubnum: GIT-CC-96-04  
Email: fdaniela, schwang@cc.gatech.edu  
Date: February 1996  
Abstract: A problem frequently faced by complex distributed applications is to control the interaction of their communication and computational activities such that they jointly adhere to desired performance and timing requirements. This research presents the COMM adapt communication infrastructure that can cope with dynamic variations in user programs' processing and QoS fl requirements, by permitting the on-line adaptation of a protocol's resource usage to currently available resources and application requirements. A key feature of COMM adapt is its dynamic (auto-)configurability, which is its support of on-line configuration transparent to application programs. Such configuration is performed by a heuristic that accommodates changes in a connection's resource requirements by reallocating resources based on its knowledge of actual resource usage of the active connections in the system. The heuristic's design and implementation are based on extensive investigations of the manner in which the assignment of protocol tasks to underlying processing resources can influence communication latency and throughput. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Banerjea and D. F. et al. </author> <title> The tenet real-time protocol suite: Design, implementation, and experiences. </title> <journal> IEEE/ACM Transactions on networking vol.4, </journal> <volume> no.1, </volume> <month> Feb. </month> <year> 1996. </year>
Reference-contexts: B09332478 1 Quality of Service [25]. Similarly, both the performance and the predictability of real-time applications are improved if bounds on communication delays can guaranteed <ref> [23, 1] </ref>. This paper focusses on one element of end-to-end communication delays: the overheads of communication processing. Specifically, we posit that the reduction of such overheads requires the dynamic control of the resources used in communication processing. <p> A simple experiment illustrates the operation of COMM adapt 's auto-configuration mechanism. 4.1 Configuration Model In COMM adapt , a connection is defined by its input and the output streams, each with its own traffic and QoS requirements. Similar to <ref> [1] </ref>, for each stream the traffic requirements are described by average inter-arrival time (X ave ), minimum inter-arrival time (X min ), averaging interval (I), and maximum message size (S max ).
Reference: [2] <author> N. Bhatti and R. Schlichting. </author> <title> A system for constructing configurable high-level protocols. </title> <booktitle> Proc. SIGCOMM, </booktitle> <year> 1995. </year>
Reference-contexts: The dynamic auto-configurability mechanism in COMM adapt is designed for the layered protocol model, but we posit that similar mechanisms can provide benefits to protocol architectures like HOPS [9], F-CSS [34], or to the micro-protocols described in <ref> [2] </ref>. Toward this end, the minimal requirements imposed by the CI model is to permit the runtime estimation of resource requirements and of the actual usage for each connection in the system. Future Work.
Reference: [3] <author> T. Bihari and K. Schwan. </author> <title> Dynamic adaptation of real-time software. </title> <journal> ACM Transactions on Computer Systems, vol.9, no.2, </journal> <pages> pages 143-174, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: However, note that auto-configuration is also used in recent work that deals with dynamic changes in video traffic mapped to the QoS guarantees offered by ATM networks [30], and that it has proven useful in past research on guaranteeing the predictable behavior of real-time applications <ref> [3, 8] </ref>. The policies and algorithms making autonomous runtime resource allocation decisions for communication protocols comprise COMM adapt 's auto-configuration mechanism. In the prototype presented in this paper, auto-configuration controls CPU resources. <p> The efficiency of such enactment strongly depends on the flexibility of the CI architecture and of its interface to the underlying resources. * Meta-level configurabil-ity control mechanisms, which serve to adapt the decision mechanism (e.g., algorithms for resource management, decision-making policies) to specific applications or sets of requirements <ref> [3] </ref>.
Reference: [4] <author> P. Druschel, L. Peterson, and B. Davie. </author> <title> Experiences with a high-speed network adapter: A software perspective. </title> <booktitle> Proc. SIGCOMM, </booktitle> <pages> pages 2-13, </pages> <year> 1994. </year>
Reference-contexts: The adapter offers a direct interface to the user space as done by most adapters with embedded processing resources <ref> [4, 5] </ref>. The interface available at the application level follows the model of the high performance ATM interface described in [24]: zero copy, gather/scatter facilities, early demultiplexing, per connection send and receive request queues, request driven receive (incoming messages are dropped if no posted receive).
Reference: [5] <author> A. Edwards, G. Watson, J. Lumley, et al. </author> <title> User-space protocols deliver high performance to applications on a low-cost gb/s lan. </title> <booktitle> Proc. SIGCOMM, </booktitle> <pages> pages 14-23, </pages> <year> 1994. </year>
Reference-contexts: The adapter offers a direct interface to the user space as done by most adapters with embedded processing resources <ref> [4, 5] </ref>. The interface available at the application level follows the model of the high performance ATM interface described in [24]: zero copy, gather/scatter facilities, early demultiplexing, per connection send and receive request queues, request driven receive (incoming messages are dropped if no posted receive).
Reference: [6] <author> E. Felten. </author> <title> Protocol compilation: High-performance communication for parallel programs. </title> <type> U. </type> <institution> of Washington, Dept. Computer Science and Eng., TR 93-09-09, </institution> <year> 1993. </year>
Reference-contexts: For instance, the performance of scientific parallel codes has been shown to improve when computations and their associated communications are scheduled jointly, using compiler information <ref> [6] </ref> or using runtime knowledge of communication delays fl Funded in part by DARPA through the Honeywell Technology Center under Contract No. B09332478 1 Quality of Service [25]. Similarly, both the performance and the predictability of real-time applications are improved if bounds on communication delays can guaranteed [23, 1].
Reference: [7] <author> A. Garg. </author> <title> Parallel streams: a multi-processor implementation. </title> <booktitle> Proc. USENIX, </booktitle> <pages> pages 163-176, </pages> <month> Winter'90. </month>
Reference-contexts: Da-CaPo [22] is an environment where the processes that execute the protocol related computations stacks can handle dynamic variations in the resource requirements, but no details are provided on the corresponding mechanisms. The ADAPTIVE system [27] enables only application-level adaptation decisions. The parallel STREAMS implementation in <ref> [7] </ref> offers only user-directed stream configuration, and the policy for runtime scheduling of communication related tasks ignores QoS requirements. The framework presented in [34] supports QoS requirements in the context of functionally decomposed protocol stacks by CI-level connection-time configuration decisions that minimize protocol functions and their processing requirements.
Reference: [8] <author> P. Gopinath and R. Gupta. </author> <title> Compiler-assisted adaptive scheduling in real-time systems. </title> <booktitle> 7th IEEE Workshop on Real-Time Operating Systems and Software, </booktitle> <pages> pages 62-69, </pages> <year> 1990. </year>
Reference-contexts: However, note that auto-configuration is also used in recent work that deals with dynamic changes in video traffic mapped to the QoS guarantees offered by ATM networks [30], and that it has proven useful in past research on guaranteeing the predictable behavior of real-time applications <ref> [3, 8] </ref>. The policies and algorithms making autonomous runtime resource allocation decisions for communication protocols comprise COMM adapt 's auto-configuration mechanism. In the prototype presented in this paper, auto-configuration controls CPU resources.
Reference: [9] <author> Z. Haas. </author> <title> A protocol structure for high-speed communication over broadband isdn. </title> <journal> IEEE Network Magazine, </journal> <pages> pages 64-70, </pages> <month> Jan. </month> <year> 1991. </year>
Reference-contexts: The dynamic auto-configurability mechanism in COMM adapt is designed for the layered protocol model, but we posit that similar mechanisms can provide benefits to protocol architectures like HOPS <ref> [9] </ref>, F-CSS [34], or to the micro-protocols described in [2]. Toward this end, the minimal requirements imposed by the CI model is to permit the runtime estimation of resource requirements and of the actual usage for each connection in the system. Future Work.
Reference: [10] <author> N. Hutchinson and L. Peterson. </author> <title> The x-kernel: An architecture for implementing network protocols. </title> <journal> IEEE Trans. on Software Engineering, </journal> <volume> 17(1), </volume> <pages> pages 64-76, </pages> <month> Jan. </month> <year> 1991. </year>
Reference-contexts: In addition, protocols implemented with COMM adapt may be tailored to satisfy application-specific communication needs by their flexible composition from sets of protocol modules <ref> [10] </ref>. <p> In contrast, the CI may make allocation decisions based on current communication behavior and on actual levels of resource utilization and availability. This auto-configuration attribute of the CI distinguishes our research from other current and past work on configurable communication systems <ref> [10, 17, 22, 26, 27, 34, 16] </ref>. <p> The need for such mechanisms has already been established by previous work in configurable communication systems <ref> [10, 22, 27, 34] </ref>. Due to our interest in auto-configuration, the specific research issue addressed by COMM adapt is the difficulty of accurately estimating and then responding to the runtime behavior of complex applications with numerous communication streams. <p> COMM adapt differs from previous work on configurable protocols in its support for constructing protocols that are auto-configurable at runtime in their functionality and performance. For instance, in the x-Kernel <ref> [10, 21] </ref>, each connection is bound to a specific resource assignment/protocol stack at the time of connection establishment. Da-CaPo [22] is an environment where the processes that execute the protocol related computations stacks can handle dynamic variations in the resource requirements, but no details are provided on the corresponding mechanisms.
Reference: [11] <author> K. Jeffay. </author> <title> The real-time producer/consumer paradigm: A paradigm for the construction of efficient, predictable real-time systems. </title> <booktitle> Proc. ACM/SIGAPP Symposium on Applied Computing, </booktitle> <pages> pages 769-804, </pages> <year> 1993. </year> <month> 16 </month>
Reference-contexts: Systems permitting such reservations include commercial multiprocessors like SUN Solaris SMPs and supercomputers like the Convex machines, and they include systems offering real-time capabilities like the Rialto Operating System [14], the YARTOS kernel <ref> [11, 12] </ref>, and RT-Mach with the processor capacity reservation-based scheduling described in [18]. This paper's measurements are performed on a commercial parallel machine, a KSR-2 supercomputer running multiple communicating processes each using the COMM adapt prototype, with the KSR's interconnection network emulating the underlying network typically employed for inter-process communications.
Reference: [12] <author> K. Jeffay and D. Bennett. </author> <title> A rate-based execution abstraction for multimedia computing. </title> <booktitle> Proc. 5th Intl. Workshop on Network and Operating System Support for Digital Audio and Video, </booktitle> <year> 1995. </year>
Reference-contexts: Systems permitting such reservations include commercial multiprocessors like SUN Solaris SMPs and supercomputers like the Convex machines, and they include systems offering real-time capabilities like the Rialto Operating System [14], the YARTOS kernel <ref> [11, 12] </ref>, and RT-Mach with the processor capacity reservation-based scheduling described in [18]. This paper's measurements are performed on a commercial parallel machine, a KSR-2 supercomputer running multiple communicating processes each using the COMM adapt prototype, with the KSR's interconnection network emulating the underlying network typically employed for inter-process communications. <p> Note that the above model assumes that the system level scheduler is guaranteeing the assigned CPU percentage. Such schedulers have been presented in [18], [14] and <ref> [12] </ref>. Given this model, the goal of the auto-configuration decision in COMM adapt is to comply with the available resources (see 1), rate requirements (see 2), and to minimize message latency.
Reference: [13] <author> R. Jha, M. Muhammad, S. Yalamanchili, D. I.- R. K. Schwan, and C. DeCastro. </author> <title> Adaptive resource allocation for embedded parallel applications. </title> <booktitle> conference submission, </booktitle> <month> Aug. </month> <year> 1996. </year>
Reference-contexts: Large-scale applications with which this system is being evaluated include groupware and collaborative applications transporting significant amounts of data and performing substantial processing on such data [32], traditional high performance codes like the parallel global atmospheric model described in [15], and embedded real-time applications, as described in <ref> [13] </ref>. These applications are being constructed jointly with other faculty in the confines of the `Distributed Laboratories' project at Geor-gia Tech. This project's general goals are to enable multiple scientists to jointly solve their problems with computational instruments residing on heterogeneous, networked computing engines.
Reference: [14] <author> M. Jones, P. Leach, R. Draves, and J. Barrera. </author> <title> Modular real-time resource management in the rialto operating system. </title> <booktitle> Proc.of the 5th Workshop on Hot Topics in Operating Systems, </booktitle> <pages> pages 12-17, </pages> <year> 1995. </year>
Reference-contexts: Systems permitting such reservations include commercial multiprocessors like SUN Solaris SMPs and supercomputers like the Convex machines, and they include systems offering real-time capabilities like the Rialto Operating System <ref> [14] </ref>, the YARTOS kernel [11, 12], and RT-Mach with the processor capacity reservation-based scheduling described in [18]. <p> Note that the above model assumes that the system level scheduler is guaranteeing the assigned CPU percentage. Such schedulers have been presented in [18], <ref> [14] </ref> and [12]. Given this model, the goal of the auto-configuration decision in COMM adapt is to comply with the available resources (see 1), rate requirements (see 2), and to minimize message latency.
Reference: [15] <author> T. Kindler, K. Schwan, et al. </author> <title> A parallel spectral model for atmospheric transport processes. </title> <institution> Georgia Institute of Technology, College of Computing, TR GIT-CC-95-17, </institution> <year> 1995. </year>
Reference-contexts: Since COMM adapt is implemented with a portable user-level threads library [20], it can also be run on other parallel machines, including SUN Solaris and SGI multiprocessors. The development of COMM adapt has been driven by our experiences with both high performance and real-time applications <ref> [15, 19] </ref>. <p> Large-scale applications with which this system is being evaluated include groupware and collaborative applications transporting significant amounts of data and performing substantial processing on such data [32], traditional high performance codes like the parallel global atmospheric model described in <ref> [15] </ref>, and embedded real-time applications, as described in [13]. These applications are being constructed jointly with other faculty in the confines of the `Distributed Laboratories' project at Geor-gia Tech.
Reference: [16] <author> R. Kravets, K. Calvert, and K. Schwan. </author> <title> Dynamically configurable communication protocols and distribued applications: Motivation and experience. </title> <type> Technical Report GIT-CC-96-16, </type> <institution> Georgia Institute of Technology, </institution> <year> 1996. </year>
Reference-contexts: In contrast, the CI may make allocation decisions based on current communication behavior and on actual levels of resource utilization and availability. This auto-configuration attribute of the CI distinguishes our research from other current and past work on configurable communication systems <ref> [10, 17, 22, 26, 27, 34, 16] </ref>.
Reference: [17] <author> B. Lindgren, B. Krupczak, M. Ammar, and K. Schwan. </author> <title> Parallel and configurable protocols: Experiences with a prototype and an architectural framework. </title> <institution> Georgia Institute of Technology, GIT-CC-93-22, </institution> <year> 1993. </year>
Reference-contexts: In contrast, the CI may make allocation decisions based on current communication behavior and on actual levels of resource utilization and availability. This auto-configuration attribute of the CI distinguishes our research from other current and past work on configurable communication systems <ref> [10, 17, 22, 26, 27, 34, 16] </ref>. <p> These characteristics make COMM adapt appropriate for servicing complex systems with dynamic and/or hard to accurately stated QoS requirements. Related Work. The COMM adapt prototype is loosely based on the previous work of <ref> [17] </ref> who only comment on the necessity of runtime adjustments in the mapping of protocol modules to processors. COMM adapt differs from previous work on configurable protocols in its support for constructing protocols that are auto-configurable at runtime in their functionality and performance.
Reference: [18] <author> C. Mercer and H. Tokuda. </author> <title> An evaluation of priority consistency in protocol architectures. </title> <booktitle> Proc. IEEE 16th Real-Time Systems Symposium, </booktitle> <address> Oct.1991. </address>
Reference-contexts: Systems permitting such reservations include commercial multiprocessors like SUN Solaris SMPs and supercomputers like the Convex machines, and they include systems offering real-time capabilities like the Rialto Operating System [14], the YARTOS kernel [11, 12], and RT-Mach with the processor capacity reservation-based scheduling described in <ref> [18] </ref>. This paper's measurements are performed on a commercial parallel machine, a KSR-2 supercomputer running multiple communicating processes each using the COMM adapt prototype, with the KSR's interconnection network emulating the underlying network typically employed for inter-process communications. <p> Note that the above model assumes that the system level scheduler is guaranteeing the assigned CPU percentage. Such schedulers have been presented in <ref> [18] </ref>, [14] and [12]. Given this model, the goal of the auto-configuration decision in COMM adapt is to comply with the available resources (see 1), rate requirements (see 2), and to minimize message latency.
Reference: [19] <author> Mori and N. N. I. S. L. Wasano. </author> <title> A benchmark for advanced real-time systems. </title> <type> personal communication, </type> <year> 1994. </year>
Reference-contexts: Since COMM adapt is implemented with a portable user-level threads library [20], it can also be run on other parallel machines, including SUN Solaris and SGI multiprocessors. The development of COMM adapt has been driven by our experiences with both high performance and real-time applications <ref> [15, 19] </ref>.
Reference: [20] <author> B. Mukherjee. </author> <title> A portable and reconfigurable threads package. </title> <booktitle> In Proceedings of Sun User Group Technical Conference, </booktitle> <pages> pages 101-112, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: This paper's measurements are performed on a commercial parallel machine, a KSR-2 supercomputer running multiple communicating processes each using the COMM adapt prototype, with the KSR's interconnection network emulating the underlying network typically employed for inter-process communications. Since COMM adapt is implemented with a portable user-level threads library <ref> [20] </ref>, it can also be run on other parallel machines, including SUN Solaris and SGI multiprocessors. The development of COMM adapt has been driven by our experiences with both high performance and real-time applications [15, 19].
Reference: [21] <author> E. Nahum, D. Yates, J. Kurose, and D. Towsley. </author> <title> Performance issues in parallelized network protocols. </title> <booktitle> Proc. 1st Symposium on OSDI, </booktitle> <pages> pages 125-137, </pages> <year> 1994. </year>
Reference-contexts: Each experiment runs until the metrics of interest reach the 95% confidence interval. Consistent with other studies reported in the literature <ref> [28, 21] </ref>, the following factors are varied across experiments, : (1) protocol task assignments (see Figure 5), (2) number of concurrent connections; (3) message size, (4) protocol processing requirements (reliability, checksum, encryption), and (5) transmission rate (bounded 10Mbits/sec 0.05% or unbounded). <p> Fixed parameters are: the size of processor pool for message parallel configurations, and the buffer pool and window size. Experimental results are consistent with previously reported work, including the results in <ref> [28, 21] </ref>. For instance, at high communication rates, a message parallel configuration results in higher overall performance than a connectional parallel one (see Figure 7). More importantly, our experiments offer a number of basic insights directly related to our interest in dynamic QoS con trol. <p> configurations, including (1) that pipelined CI configurations on a small number of processors may yield performance comparable to message and connectional parallel configurations (in contrast to statements made in [27]) and (2) that the NI bottleneck may restrict the performance of the highly parallel communication architectures proposed in previous studies <ref> [28, 21] </ref>. The philosophy behind our auto-configuration approach may be summarized by the following statement: a prompt CI-level decision based on the observed traffic characteristics may keep performance within acceptable limits while accommodating an application program's dynamic resource requirements. <p> COMM adapt differs from previous work on configurable protocols in its support for constructing protocols that are auto-configurable at runtime in their functionality and performance. For instance, in the x-Kernel <ref> [10, 21] </ref>, each connection is bound to a specific resource assignment/protocol stack at the time of connection establishment. Da-CaPo [22] is an environment where the processes that execute the protocol related computations stacks can handle dynamic variations in the resource requirements, but no details are provided on the corresponding mechanisms. <p> Our study of the various CI configurations focusing on per connection performance (throughput, latency and predictability) is different from similar studies reported in the literature which focus only on aggregate throughput. [28] reports on the influence of the synchronization and context-switching overheads on connectional and message parallel configurations; <ref> [21] </ref> analyzes the scalability of a parallel x-kernel implementation for message parallel configurations. Moreover, these stud 15 ies ignore pipelined configurations, since those are considered [27] to have prohibitive synchronization and communication overheads.
Reference: [22] <author> T. Plagemann, B. Platter, et al. </author> <title> Modules as building blocks for protocol configuration. </title> <booktitle> Proc. International Conference on Network Protocol, </booktitle> <year> 1993. </year>
Reference-contexts: In contrast, the CI may make allocation decisions based on current communication behavior and on actual levels of resource utilization and availability. This auto-configuration attribute of the CI distinguishes our research from other current and past work on configurable communication systems <ref> [10, 17, 22, 26, 27, 34, 16] </ref>. <p> The need for such mechanisms has already been established by previous work in configurable communication systems <ref> [10, 22, 27, 34] </ref>. Due to our interest in auto-configuration, the specific research issue addressed by COMM adapt is the difficulty of accurately estimating and then responding to the runtime behavior of complex applications with numerous communication streams. <p> COMM adapt differs from previous work on configurable protocols in its support for constructing protocols that are auto-configurable at runtime in their functionality and performance. For instance, in the x-Kernel [10, 21], each connection is bound to a specific resource assignment/protocol stack at the time of connection establishment. Da-CaPo <ref> [22] </ref> is an environment where the processes that execute the protocol related computations stacks can handle dynamic variations in the resource requirements, but no details are provided on the corresponding mechanisms. The ADAPTIVE system [27] enables only application-level adaptation decisions.
Reference: [23] <author> J. Rexford, J. Dolter, and K. Shin. </author> <title> Hardware support for controlled interaction of guaranteed and best-effort communication. </title> <booktitle> Workshop on Parallel and Distributed Real-Time Systems, </booktitle> <pages> pages 188-193, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: B09332478 1 Quality of Service [25]. Similarly, both the performance and the predictability of real-time applications are improved if bounds on communication delays can guaranteed <ref> [23, 1] </ref>. This paper focusses on one element of end-to-end communication delays: the overheads of communication processing. Specifically, we posit that the reduction of such overheads requires the dynamic control of the resources used in communication processing.
Reference: [24] <author> M. Rosu. </author> <title> Processor controlled off-processor i/o. </title> <institution> Cornell University, Dept.Computer Science TR 95-1538, </institution> <year> 1995. </year>
Reference-contexts: The adapter offers a direct interface to the user space as done by most adapters with embedded processing resources [4, 5]. The interface available at the application level follows the model of the high performance ATM interface described in <ref> [24] </ref>: zero copy, gather/scatter facilities, early demultiplexing, per connection send and receive request queues, request driven receive (incoming messages are dropped if no posted receive). The network fiber is emulated by a set of shared memory buffers mapped into the sending and receiving address spaces. <p> In addition, we are considering using COMM adapt for real-time and high performance communications via an optimized ATM device interface described in <ref> [24] </ref>. Acknowledgments. We acknowledge Prof. Sud-hakar Yalamanchili for helpful discussions on mapping algorithms.
Reference: [25] <author> J. Saltz, G. Edjlali, et al. </author> <title> Data parallel programming in an adaptive environment. </title> <booktitle> Proc. of the 9th International Parallel Processing Symposium, </booktitle> <pages> pages 812-819, </pages> <year> 1995. </year>
Reference-contexts: B09332478 1 Quality of Service <ref> [25] </ref>. Similarly, both the performance and the predictability of real-time applications are improved if bounds on communication delays can guaranteed [23, 1]. This paper focusses on one element of end-to-end communication delays: the overheads of communication processing.
Reference: [26] <author> S. Saxena, J. K. Peacock, et al. </author> <title> Pitfalls in multi-threading svr4 streams and other weightless processes. </title> <booktitle> Proc. USENIX, </booktitle> <pages> pages 85-96, </pages> <month> Winter'93. </month>
Reference-contexts: In contrast, the CI may make allocation decisions based on current communication behavior and on actual levels of resource utilization and availability. This auto-configuration attribute of the CI distinguishes our research from other current and past work on configurable communication systems <ref> [10, 17, 22, 26, 27, 34, 16] </ref>.
Reference: [27] <author> D. Schmidt, D. Box, and T. Suda. </author> <title> Adaptive. a dynamically assembled protocol transformation, integration, and evaluation environment. </title> <journal> Journal of Concurrency: Practice and Experience, Jun.93. </journal>
Reference-contexts: In contrast, the CI may make allocation decisions based on current communication behavior and on actual levels of resource utilization and availability. This auto-configuration attribute of the CI distinguishes our research from other current and past work on configurable communication systems <ref> [10, 17, 22, 26, 27, 34, 16] </ref>. <p> The need for such mechanisms has already been established by previous work in configurable communication systems <ref> [10, 22, 27, 34] </ref>. Due to our interest in auto-configuration, the specific research issue addressed by COMM adapt is the difficulty of accurately estimating and then responding to the runtime behavior of complex applications with numerous communication streams. <p> levels to well-behaved connections while simultaneously accommodating runtime traffic variations else where; * interesting insights on the behavior of different CI configurations, including (1) that pipelined CI configurations on a small number of processors may yield performance comparable to message and connectional parallel configurations (in contrast to statements made in <ref> [27] </ref>) and (2) that the NI bottleneck may restrict the performance of the highly parallel communication architectures proposed in previous studies [28, 21]. <p> Da-CaPo [22] is an environment where the processes that execute the protocol related computations stacks can handle dynamic variations in the resource requirements, but no details are provided on the corresponding mechanisms. The ADAPTIVE system <ref> [27] </ref> enables only application-level adaptation decisions. The parallel STREAMS implementation in [7] offers only user-directed stream configuration, and the policy for runtime scheduling of communication related tasks ignores QoS requirements. <p> Moreover, these stud 15 ies ignore pipelined configurations, since those are considered <ref> [27] </ref> to have prohibitive synchronization and communication overheads. In contrast, we do consider such configurations and take advantage of their efficiency and flexibility, especially when the CI is run only on a small number of processors (e.g., 2-3).
Reference: [28] <author> D. Schmidt and T. Suda. </author> <title> Measuring the performance of parallel message-based process architectures. </title> <booktitle> IEEE INFOCOM, </booktitle> <year> 1995. </year>
Reference-contexts: Each experiment runs until the metrics of interest reach the 95% confidence interval. Consistent with other studies reported in the literature <ref> [28, 21] </ref>, the following factors are varied across experiments, : (1) protocol task assignments (see Figure 5), (2) number of concurrent connections; (3) message size, (4) protocol processing requirements (reliability, checksum, encryption), and (5) transmission rate (bounded 10Mbits/sec 0.05% or unbounded). <p> Fixed parameters are: the size of processor pool for message parallel configurations, and the buffer pool and window size. Experimental results are consistent with previously reported work, including the results in <ref> [28, 21] </ref>. For instance, at high communication rates, a message parallel configuration results in higher overall performance than a connectional parallel one (see Figure 7). More importantly, our experiments offer a number of basic insights directly related to our interest in dynamic QoS con trol. <p> configurations, including (1) that pipelined CI configurations on a small number of processors may yield performance comparable to message and connectional parallel configurations (in contrast to statements made in [27]) and (2) that the NI bottleneck may restrict the performance of the highly parallel communication architectures proposed in previous studies <ref> [28, 21] </ref>. The philosophy behind our auto-configuration approach may be summarized by the following statement: a prompt CI-level decision based on the observed traffic characteristics may keep performance within acceptable limits while accommodating an application program's dynamic resource requirements. <p> Our study of the various CI configurations focusing on per connection performance (throughput, latency and predictability) is different from similar studies reported in the literature which focus only on aggregate throughput. <ref> [28] </ref> reports on the influence of the synchronization and context-switching overheads on connectional and message parallel configurations; [21] analyzes the scalability of a parallel x-kernel implementation for message parallel configurations. Moreover, these stud 15 ies ignore pipelined configurations, since those are considered [27] to have prohibitive synchronization and communication overheads.
Reference: [29] <author> D. Schmidt and T. Suda. </author> <title> Transport system architectures for high-performance communications subsystems. </title> <journal> IEEE Journal on Selected Areas in Comm., </journal> <volume> vol.11,No.4, </volume> <month> May 93. </month>
Reference-contexts: More specifically, we are interested in how to achieve high throughput and resource utilization while keeping waiting times within predictable limits. The configurations considered in this study are (see Figure 5): * connectional parallel connections (config.c), where a processor is handling only the mes sages of its assigned connections <ref> [29] </ref>; * message parallel connections (config.m), where any processor may process (completely) any message (from any connection) [29]; and * quasi-pipelined connections (config.1p, config.2p, config.4p), where a processor is assigned one or more protocol modules and their processing is based on shepherding. In the classical pipeline [29], each protocol module is <p> The configurations considered in this study are (see Figure 5): * connectional parallel connections (config.c), where a processor is handling only the mes sages of its assigned connections <ref> [29] </ref>; * message parallel connections (config.m), where any processor may process (completely) any message (from any connection) [29]; and * quasi-pipelined connections (config.1p, config.2p, config.4p), where a processor is assigned one or more protocol modules and their processing is based on shepherding. In the classical pipeline [29], each protocol module is assigned its own processor. <p> of its assigned connections <ref> [29] </ref>; * message parallel connections (config.m), where any processor may process (completely) any message (from any connection) [29]; and * quasi-pipelined connections (config.1p, config.2p, config.4p), where a processor is assigned one or more protocol modules and their processing is based on shepherding. In the classical pipeline [29], each protocol module is assigned its own processor. This makes the achievable peformance (i.e., throughput, latency) fixed with the implementation specific protocol decomposition.
Reference: [30] <author> P. Schneck, E. Zegura, and K. Schwan. Drrm: </author> <title> Dynamic resource reservation manager. </title> <booktitle> Proc. of IC3N, </booktitle> <year> 1996. </year>
Reference-contexts: However, note that auto-configuration is also used in recent work that deals with dynamic changes in video traffic mapped to the QoS guarantees offered by ATM networks <ref> [30] </ref>, and that it has proven useful in past research on guaranteeing the predictable behavior of real-time applications [3, 8]. The policies and algorithms making autonomous runtime resource allocation decisions for communication protocols comprise COMM adapt 's auto-configuration mechanism. In the prototype presented in this paper, auto-configuration controls CPU resources.
Reference: [31] <author> K. Schwan and M. Ahamad. </author> <title> Cobs configurable objects for high performance systems. </title> <note> http://www.cc.gatech.edu/systems/projects/COBS/, 1995. </note>
Reference-contexts: As part of this work, we will integrate the COMM adapt infrastructure into CORBA-compliant, high performance, object-based middleware now being constructed at Geor-gia Tech, called COBS <ref> [31] </ref>. The intent of COBS is to permit applications to configure object implementations to their specific needs.
Reference: [32] <author> K. Schwan, G. Eisen-hauer, V. Martin, B. Schroeder, and J. Vetter. </author> <title> From interactive high performance applications to distributed laboratories. </title> <journal> journal submission, </journal> <month> July </month> <year> 1996. </year>
Reference-contexts: The intent of COBS is to permit applications to configure object implementations to their specific needs. Large-scale applications with which this system is being evaluated include groupware and collaborative applications transporting significant amounts of data and performing substantial processing on such data <ref> [32] </ref>, traditional high performance codes like the parallel global atmospheric model described in [15], and embedded real-time applications, as described in [13]. These applications are being constructed jointly with other faculty in the confines of the `Distributed Laboratories' project at Geor-gia Tech.
Reference: [33] <author> R. Sharma and S. Kesav. </author> <title> Signaling and operating systems support for native-mode atm applications. </title> <booktitle> Proc. SIGCOMM, </booktitle> <pages> pages 149-157, </pages> <year> 1994. </year>
Reference-contexts: The composition process consist of linking together the appropriate protocol modules in the order in which they should process a message. COMM adapt 's protocol stacks are non-multiplexing. This preserves the connection identity at all levels of protocol processing, thereby enabling better support for connection-specific QoS <ref> [33] </ref> and for flexible composition of application-specific protocols.
Reference: [34] <author> M. Zitterbart, B. Stiller, and A. Tantaway. </author> <title> A model for flexible high-performance communication subsystems. </title> <journal> IEEE Journal on Selected Areas in Comm., </journal> <volume> 11(4), </volume> <month> May </month> <year> 1993. </year> <month> 17 </month>
Reference-contexts: In contrast, the CI may make allocation decisions based on current communication behavior and on actual levels of resource utilization and availability. This auto-configuration attribute of the CI distinguishes our research from other current and past work on configurable communication systems <ref> [10, 17, 22, 26, 27, 34, 16] </ref>. <p> The need for such mechanisms has already been established by previous work in configurable communication systems <ref> [10, 22, 27, 34] </ref>. Due to our interest in auto-configuration, the specific research issue addressed by COMM adapt is the difficulty of accurately estimating and then responding to the runtime behavior of complex applications with numerous communication streams. <p> The ADAPTIVE system [27] enables only application-level adaptation decisions. The parallel STREAMS implementation in [7] offers only user-directed stream configuration, and the policy for runtime scheduling of communication related tasks ignores QoS requirements. The framework presented in <ref> [34] </ref> supports QoS requirements in the context of functionally decomposed protocol stacks by CI-level connection-time configuration decisions that minimize protocol functions and their processing requirements. <p> The dynamic auto-configurability mechanism in COMM adapt is designed for the layered protocol model, but we posit that similar mechanisms can provide benefits to protocol architectures like HOPS [9], F-CSS <ref> [34] </ref>, or to the micro-protocols described in [2]. Toward this end, the minimal requirements imposed by the CI model is to permit the runtime estimation of resource requirements and of the actual usage for each connection in the system. Future Work.
References-found: 34

