URL: ftp://info.mcs.anl.gov/pub/tech_reports/reports/P490.ps.Z
Refering-URL: http://www.mcs.anl.gov/publications/abstracts/abstracts95.htm
Root-URL: http://www.mcs.anl.gov
Phone: 2  
Title: Language Constructs and Runtime Systems for Compositional Parallel Programming  
Author: Ian Foster and Carl Kesselman 
Address: Argonne, IL 60439, U.S.A.  Pasadena, CA 91125, U.S.A.  
Affiliation: 1 Mathematics and Computer Science Division, Argonne National Laboratory,  Beckman Institute, California Institute of Technology,  
Abstract: In task-parallel programs, diverse activities can take place concurrently, and communication and synchronization patterns are complex and not easily predictable. Previous work has identified compositionality as an important design principle for task-parallel programs. In this paper, we discuss alternative approaches to the realization of this principle. We first provide a review and critical analysis of Strand, an early compositional programming language. We examine the strengths of the Strand approach and also its weaknesses, which we attribute primarily to the use of a specialized language. Then, we present an alternative programming language framework that overcomes these weaknesses. This framework uses simple extensions to existing sequential languages (C ++ and Fortran) and a common runtime system to provide a basis for the construction of large, task-parallel programs. We also discuss the runtime system techniques required to support these languages on parallel and distributed computer systems. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Ackerman, W.: </author> <title> Data flow Languages. </title> <booktitle> Computer 15(2), </booktitle> <year> (1982), </year> <pages> 15-25 </pages>
Reference-contexts: These goals motivate the design both of Strand and of the CC ++ and Fortran M languages described below. 2.1 Strand Design The Strand language integrated ideas from earlier work in parallel logic programming [8], dataflow computing <ref> [1] </ref>, and imperative programming [15] to provide a simple task-parallel programming language based on four related ideas: single assignment variables, a global, shared namespace, parallel composition as the only method of program composition, and a foreign language interface. 2 Single-assignment variables provide a unified mechanism for both synchronization and communi-cation. <p> All variables in Strand follow the single-assignment rule <ref> [1] </ref>: a variable is set at most once and subsequently cannot change. Any attempt by a program component to read a variable before it has been assigned a value will cause the program component to block. All synchronization operations are implemented via reading and writing these variables.
Reference: 2. <author> Chandy, K. M., Foster, I.: </author> <title> A deterministic notation for cooperating processes. </title> <type> Preprint, </type> <institution> Argonne National Laboratory (1993) </institution>
Reference-contexts: FM constructs allow 6 the programmer to control process placement by specifying the mapping of processes to virtual computers: arrays of virtual processors. Mapping decisions do not effect program semantics. A novel aspect of the FM extensions is that even complex programs can be guaranteed to be deterministic <ref> [2] </ref>. In summary, FM integrates parallel composition with sequential execution. It uses channels both to provide a uniform global address space and to implement compositional interactions between program components. 4 Runtime Systems Compilers for parallel languages rely on the existence of a runtime system.
Reference: 3. <author> Chandy, K. M., Kesselman, C.: </author> <title> CC ++ : A declarative concurrent object-oriented programming notation. Research Directions in Object Oriented Programming, </title> <publisher> MIT Press (1993) </publisher>
Reference-contexts: The language extensions can be used to construct libraries supporting a range of programming models, including message passing (MPCL), data parallelism (A++, HPF), and parallelism extracted automatically from derivative computations (ADIFOR). 3.1 Compositional C ++ Compositional C ++ <ref> [3] </ref>, or CC ++ , is a general-purpose parallel programming language based on C ++ . CC ++ defines six new keywords, designed to provide an essential set of capabilities from which many different types of parallel programs could be constructed.
Reference: 4. <author> Chandy, K. M., Kesselman, C.: </author> <title> The derivation of compositional programs. </title> <booktitle> Proc. 1992 Joint Intl Conf. and Symp. on Logic Programming, </booktitle> <publisher> MIT Press (1992) </publisher>
Reference-contexts: Single-assignment variables provide both an interaction mechanism based on monotonic operations on shared state, and a uniform address space; parallel composition provides a concurrent interleaving. (State changes on single-assignment variables are monotonic in that the value of a variable cannot be changed once written <ref> [4] </ref>.) Together, these mechanisms ensure that neither the order in which program components execute, nor the location of this execution, affect the result computed. Other mechanisms can provide the same capabilities. <p> Thus, in designing CC ++ , our approach was to provide constructs that would enable rather than guarantee the construction of compositional modules. In most instances, compositional modules can be obtained by following simple programming conventions <ref> [4] </ref>. 5 CC ++ provides three different mechanisms for creating threads of control: the parallel block, the parallel loop, and spawned functions. The first two have a parbegin/parend semantics, while the spawned function creates an independent thread. CC ++ borrows the idea of a single-assignment variable from Strand.
Reference: 5. <author> Chandy, K. M., Misra, J.: </author> <title> Parallel Program Design. </title> <publisher> Addison-Wesley (1988) </publisher>
Reference-contexts: language means that program development tools such as debuggers and execution profilers have to be developed from scratch; it also hinders the application of existing sequential development tools to sequential code modules. 2.3 Program Composition Notation In a related research project stimulated in part by Strand and the Unity system <ref> [5] </ref>, Chandy and Tay-lor investigated the feasibility of integrating single-assignment variables and concurrent composition with conventional imperative programming. This led to the development of Program Composition Notation (PCN) [6]. Like Strand, PCN provides a parallel programming model based on single-assignment variables, a global address space, and concurrent composition.
Reference: 6. <author> Chandy, K. M., Taylor, S.: </author> <title> An Introduction to Parallel Programming. </title> <publisher> Jones and Bartlett (1992) </publisher>
Reference-contexts: This led to the development of Program Composition Notation (PCN) <ref> [6] </ref>. Like Strand, PCN provides a parallel programming model based on single-assignment variables, a global address space, and concurrent composition. Its major contribution is to show how this model can be integrated with the conventional world of "multiple-assignment" variables and sequential composition.
Reference: 7. <author> Chapman, B., Mehrotra, P., Zima, H.: </author> <title> Programming in Vienna Fortran. </title> <note> Scientific Programming 1(1) (1992) 31-50 </note>
Reference-contexts: For example, the various languages that have been developed to support data-parallel programming achieve both these goals, albeit for a restricted class of programs <ref> [7, 9, 17] </ref>. Data-parallel programs exploit the parallelism inherent in applying the same operation to all or most elements of large data structures. Data-parallel languages avoid unwanted interactions by enforcing sequential semantics.
Reference: 8. <author> Clark, K., Gregory, S.: </author> <title> A relational language for parallel programming. </title> <booktitle> Proc. 1981 ACM Conf. on Functional Programming Languages and Computer Architectures (1981) 171-178 </booktitle>
Reference-contexts: These goals motivate the design both of Strand and of the CC ++ and Fortran M languages described below. 2.1 Strand Design The Strand language integrated ideas from earlier work in parallel logic programming <ref> [8] </ref>, dataflow computing [1], and imperative programming [15] to provide a simple task-parallel programming language based on four related ideas: single assignment variables, a global, shared namespace, parallel composition as the only method of program composition, and a foreign language interface. 2 Single-assignment variables provide a unified mechanism for both synchronization
Reference: 9. <author> Fox, G., Hiranandani, S., Kennedy, K., Koelbel, C., Kremer, U., Tseng, C., Wu, M.: </author> <title> Fortran D language specification. </title> <institution> Rice University TR90-141 (1990) </institution>
Reference-contexts: For example, the various languages that have been developed to support data-parallel programming achieve both these goals, albeit for a restricted class of programs <ref> [7, 9, 17] </ref>. Data-parallel programs exploit the parallelism inherent in applying the same operation to all or most elements of large data structures. Data-parallel languages avoid unwanted interactions by enforcing sequential semantics.
Reference: 10. <author> Foster, I., Avalani, B., Choudhary, A., Xu, M., </author> <title> A compilation system that integrates High Performance Fortran and Fortran M. </title> <booktitle> Proc. 1994 Scalable High Performance Computing Conf., </booktitle> <publisher> IEEE Computer Science Press (1994) 293-300 </publisher>
Reference-contexts: FM is designed to support both the modular construction of large parallel programs and the development of libraries implementing other programming paradigms. For example, FM libraries have been used to integrate SPMD message-passing computations and data-parallel HPF programs into a task-parallel framework <ref> [10] </ref>, and to implement distributed data structures. Although simple, the FM extensions provide the essential mechanisms required for compositional programming. Program components can encapsulate arbitrary concurrent computations and can be reused in any environment. Concepts such as pointers and dynamic memory allocation are foreign to Fortran 77.
Reference: 11. <author> Foster, I., Chandy, K. M.: </author> <title> Fortran M: A language for modular parallel programming. </title> <journal> J. </journal> <note> Parallel and Distributed Computing (to appear) </note>
Reference-contexts: In summary, CC ++ integrates parallel composition with sequential execution. It uses global pointers to provide a uniform global address space and sync variables and atomic functions to implement compositional interactions between program components. 3.2 Fortran M Fortran M (FM) <ref> [11] </ref> is a small set of extensions to Fortran 77 for task-parallel programming. FM is designed to support both the modular construction of large parallel programs and the development of libraries implementing other programming paradigms.
Reference: 12. <author> Foster, I., Kesselman, C., Tuecke, S.: </author> <title> Nexus: Runtime support for task-parallel programming languages. </title> <type> Preprint, </type> <institution> Argonne National Laboratory (1994) </institution>
Reference-contexts: This approach is taken in the runtime system called Nexus that is used by both CC ++ and FM compilers. 7 Nexus Interface. Nexus provides five basic abstractions: nodes, contexts, threads, global pointers, and remote service requests <ref> [12] </ref>. Associated services provide direct support for light-weight threading, address space management, communication, and synchronization. A computation consists of a set of threads, each executing in an address space called a context.
Reference: 13. <author> Foster, I., Taylor, S.: Strand: </author> <title> New Concepts in Parallel Programming. </title> <publisher> Prentice Hall (1989) </publisher>
Reference: 14. <author> Hoare, C. A. R.: </author> <title> Monitors: An operating system structuring concept. </title> <journal> Commun. </journal> <note> ACM 17(10) (1974) 549-557 </note>
Reference-contexts: Within an instance of a given C ++ class, only one atomic function is allowed to execute at a time. The operations specified in the body of an atomic function execute without interference. Thus, an atomic function is like a monitor <ref> [14] </ref>. If all accesses to a shared C ++ variable takes place within the body of an atomic function, than the resulting program is compositional. The remaining aspects of C ++ deal with the allocation of computation to processors and the methods used to access data on different processors.
Reference: 15. <author> Hoare, C. A. R.: </author> <title> Communicating Sequential Processes. </title> <publisher> Prentice Hall (1984) </publisher>
Reference-contexts: These goals motivate the design both of Strand and of the CC ++ and Fortran M languages described below. 2.1 Strand Design The Strand language integrated ideas from earlier work in parallel logic programming [8], dataflow computing [1], and imperative programming <ref> [15] </ref> to provide a simple task-parallel programming language based on four related ideas: single assignment variables, a global, shared namespace, parallel composition as the only method of program composition, and a foreign language interface. 2 Single-assignment variables provide a unified mechanism for both synchronization and communi-cation.
Reference: 16. <author> Kesselman, C.: </author> <title> Implementing parallel programming paradigms in CC ++ . Proc. Workshop on Parallel Environments and Tools, </title> <note> SIAM (to appear) </note>
Reference-contexts: CC ++ defines six new keywords, designed to provide an essential set of capabilities from which many different types of parallel programs could be constructed. For example, we can write CC ++ libraries that implement parallel programming paradigms such as synchronous virtual channels, actors, data flow, and concurrent aggregates <ref> [16] </ref>. CC ++ is not a purely compositional programming language. In order to guarantee composition-ality, unacceptable restrictions would have to be made on the C ++ constructs that are available in CC ++ .
Reference: 17. <author> Koelbel, C., Loveman, D., Schreiber, R., Steele, G., Zosel, M.: </author> <title> The High Performance Fortran Handbook. </title> <note> MIT Press (1994) 18. </note> <author> von Eicken, T., Culler, D., Goldstein, S., Schauser, K.: </author> <title> TAM | A compiler controlled threaded abstract machine. </title> <editor> J. </editor> <booktitle> Parallel and Distributed Computing (1992) 10 </booktitle>
Reference-contexts: For example, the various languages that have been developed to support data-parallel programming achieve both these goals, albeit for a restricted class of programs <ref> [7, 9, 17] </ref>. Data-parallel programs exploit the parallelism inherent in applying the same operation to all or most elements of large data structures. Data-parallel languages avoid unwanted interactions by enforcing sequential semantics.
References-found: 17

