URL: http://www.cse.ogi.edu/Sparse/paper/stoltz.scalardd.journal.94.ps
Refering-URL: http://www.cse.ogi.edu/Sparse/sparse.scalardd.html
Root-URL: http://www.cse.ogi.edu
Email: fstoltz,mwolfeg@cse.ogi.edu  
Phone: (503) 690-1121 ext. 7404  
Title: Detecting Value-Based Scalar Dependence  
Author: Eric Stoltz and Michael Wolfe 
Keyword: Key Words: Data dependence; value-based dependence; scalars; SSA  
Address: P.O. Box 91000 Portland, OR 97291-1000  
Affiliation: Department of Computer Science and Engineering Oregon Graduate Institute of Science Technology  
Abstract: Precise value-based data dependence analysis for scalars is useful for advanced compiler optimizations. The new method presented here for flow and output dependence uses Factored Use and Def chains (FUD chains), our interpretation and extension of Static Single Assignment. It is precise with respect to conditional control flow and dependence vectors. Our method detects dependences which are independent with respect to arbitrary loop nesting, as well as loop-carried dependences. A loop-carried dependence is further classified as being carried from the previous iteration, with distance 1, or from any previous iteration, with direction &lt;. This precision cannot be achieved by traditional analysis, such as dominator information or reaching definitions. To compute anti- and input dependence, we use Factored Redef-Use chains, which are related to FUD chains. We are not aware of any prior work which explicitly deals with scalar data dependence utilizing a sparse graph representation. 1 A preliminary version of this paper appeared in the Seventh Annual Workshop on Languages and Compilers for Parallel 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. V. Aho, R. Sethi, and J. D. Ullman. </author> <booktitle> Compilers: Principles, Techniques, and Tools. </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1986. </year>
Reference-contexts: This occurs in irreducible flow graphs <ref> [1] </ref>. Informally, a directed graph is irreducible when 9 there exists a cycle with more than one entry. This corresponds to unstructured code in which a loop has multiple points of entry. <p> Certain scientific codes, such as Spice in the Perfect Club Benchmark suite [8], contain numerous such anomalies. Natural loops in our CFG are identified by a back edge in which the head dominates the tail <ref> [1] </ref>. Thus, a cycle with more than one entry point will not be classified as a loop in our intermediate representation. However, definitions may still occur within these cycles, which will result in a -function being placed at the merge.
Reference: [2] <author> J. R. Allen. </author> <title> Dependence analysis for subscripted variables and its application to program transformations. </title> <type> PhD dissertation, </type> <institution> Rice Univ., Dept. Mathematical Sciences, </institution> <month> April </month> <year> 1983. </year> <note> (available from Univ. Microfilms Inc., document 83-14916). 34 </note>
Reference-contexts: Thus, the compiler must conservatively assume that a flow dependence might exist whenever there is a path from a definition to a use, and so on for the other types of dependence. These common address-based definitions of flow, output, anti-, and input dependence can be found in many references <ref> [2, 3, 21, 23] </ref>. Value-based dependence relations are a subset of the address-based dependence relations [14].
Reference: [3] <author> John R. Allen and Ken Kennedy. </author> <title> Automatic translation of Fortran programs to vector form. </title> <journal> ACM Trans. on Programming Languages and Systems, </journal> <volume> 9(4) </volume> <pages> 491-542, </pages> <month> October </month> <year> 1987. </year>
Reference-contexts: Thus, the compiler must conservatively assume that a flow dependence might exist whenever there is a path from a definition to a use, and so on for the other types of dependence. These common address-based definitions of flow, output, anti-, and input dependence can be found in many references <ref> [2, 3, 21, 23] </ref>. Value-based dependence relations are a subset of the address-based dependence relations [14].
Reference: [4] <author> Robert A. Ballance, Arthur B. Maccabe, and Karl J. Ottenstein. </author> <title> The Program Dependence Web: A representation supporting control-, data-, and demand-driven interpretation of imperative languages. </title> <booktitle> In Proc. ACM SIGPLAN '90 Conf. on Programming Language Design and Implementation, </booktitle> <pages> pages 257-271, </pages> <address> White Plains, NY, </address> <month> June </month> <year> 1990. </year>
Reference-contexts: We have previously described how to use FUD chains for other scalar analysis methods, such as induction variable detection and constant propagation [11, 17]. The concepts of FUD chains are described in Section 2. Other intermediate representations, such as dependence flow graphs [13] or the program dependence web <ref> [4] </ref>, could also be used with similar algorithms; those representations contain enough information to find the actual dependences, though they do not represent the dependence relations explicitly.
Reference: [5] <author> Michael Burke, Ron Cytron, Jeanne Ferrante, and Wilson Hsieh. </author> <title> Automatic generation of nested, fork-join parallelism. </title> <journal> The Journal of Supercomputing, </journal> <volume> 3(2) </volume> <pages> 71-88, </pages> <month> July </month> <year> 1989. </year>
Reference-contexts: In other cases, privatization of scalar variables is possible when they are detected as being involved in only loop-independent dependences <ref> [5, 18] </ref>. In this example: 3 loop if TEST then x = : : : else x = : : : endif : : : = x endloop all flow dependences for x are loop-independent, so x can be privatized for each loop iteration.
Reference: [6] <author> Jong-Deok Choi, Ron Cytron, and Jeanne Ferrante. </author> <title> Automatic construction of sparse data flow evaluation graphs. </title> <booktitle> In Conf. Record 18th Annual ACM Symp. Principles of Programming Languages, </booktitle> <pages> pages 55-66, </pages> <address> Orlando, Florida, </address> <month> January </month> <year> 1991. </year>
Reference-contexts: The -placement algorithm [9] is used (with slight modifications) to place -functions wherever two or more downward-exposed uses or definitions merge [15]. (To be precise, -functions are placed wherever two basic block nodes with nonidentity transfer functions for "reaching uses" meet, similar to the technique employed by sparse evaluation graphs <ref> [6] </ref>.) The chaining algorithm (originally called "renaming") is modified to keep a stack of current uses for each variable (instead of a stack of current definitions), and employs -functions 25 S 1 : T ff = : : : S 2 : if ( P ) then S 3 : :
Reference: [7] <author> Jong-Deok Choi, Ron Cytron, and Jeanne Ferrante. </author> <title> On the efficient engineering of ambitious program analysis. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 20(2) </volume> <pages> 105-114, </pages> <month> February </month> <year> 1994. </year>
Reference-contexts: This gives rise to the FUD chains referred to in the previous section. For theoretical details on SSA graph construction the reader is referred to papers by Cytron et al. [9] and Choi et al. <ref> [7] </ref>, while details of FUD chain construction can also be found elsewhere [15, 16]. 1 All variables are considered to have an initial "definition" at Entry.
Reference: [8] <author> George Cybenko, Lyle Kipp, Lynn Pointer, and David Kuck. </author> <title> Supercomputer performance evaluation and the Perfect Benchmarks. </title> <booktitle> In International Conference on Supercomputing, </booktitle> <pages> pages 254 - 266, </pages> <month> March </month> <year> 1990. </year>
Reference-contexts: This corresponds to unstructured code in which a loop has multiple points of entry. Although it has been shown that irreducible flow graphs do not occur with high frequency, we must still address the problem. Certain scientific codes, such as Spice in the Perfect Club Benchmark suite <ref> [8] </ref>, contain numerous such anomalies. Natural loops in our CFG are identified by a back edge in which the head dominates the tail [1]. Thus, a cycle with more than one entry point will not be classified as a loop in our intermediate representation. <p> two dependences: S 7 ffi (&lt;;?) S 10 and S 1 ffi f 19 3.4 Measuring Algorithm 1 on Scientific Benchmarks How often do the cases in Figure 3 occur? To discover the usefulness of our method, we ran our algorithm over the scientific benchmarks contained in the Perfect Club <ref> [8] </ref>, RiCEPS, and Mendez suites. In order to keep the investigation at a level which is easy to analyze, this set of data only counted flow dependences in which the source and sink of the dependence were within the same inner loop.
Reference: [9] <author> Ron Cytron, Jeanne Ferrante, Barry K. Rosen, Mark N. Wegman, and F. Kenneth Zadeck. </author> <title> Efficiently computing Static Single Assignment form and the control dependence graph. </title> <journal> ACM Trans. on Programming Languages and Systems, </journal> <volume> 13(4) </volume> <pages> 451-490, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: We will show this situation occurs frequently in our benchmark programs. Our analysis is based on Factored Use and Definition chains (FUD chains). FUD chains are our 5 implementation and interpretation of the Static Single Assignment (SSA) form <ref> [9] </ref> of a program, with extensions. We have previously described how to use FUD chains for other scalar analysis methods, such as induction variable detection and constant propagation [11, 17]. The concepts of FUD chains are described in Section 2. <p> This gives rise to the FUD chains referred to in the previous section. For theoretical details on SSA graph construction the reader is referred to papers by Cytron et al. <ref> [9] </ref> and Choi et al. [7], while details of FUD chain construction can also be found elsewhere [15, 16]. 1 All variables are considered to have an initial "definition" at Entry. Since this definition is an artifact of SSA and FUD chains [9], we denote it as ff, indicating that there <p> is referred to papers by Cytron et al. <ref> [9] </ref> and Choi et al. [7], while details of FUD chain construction can also be found elsewhere [15, 16]. 1 All variables are considered to have an initial "definition" at Entry. Since this definition is an artifact of SSA and FUD chains [9], we denote it as ff, indicating that there is no downward-exposed definition for the variable along that path. 7 2.2 Reference Chaining The general process of providing pointers (links) between arbitrary pairs of definition sites and usage sites of a variable is called reference chaining. <p> For convenience, the first argument always points to the unique reaching definition from outside the loop, while the second argument points to the last definition within the loop body. Since -functions are placed at dominance frontiers <ref> [9] </ref> of variable definition sites, and the loop-header basic block dominates all blocks contained within the loop, we note a crucial property of loop-header - functions: a loop-header -function for variable v exists iff there is a definition of v within the loop. 2.4 Irreducible Graphs Since we identify natural loops <p> FRDU chains are built with the same methods used to build FUD chains, except uses are treated like definitions and definitions are treated like uses (additionally, a definition kills all previous downward-exposed uses). The -placement algorithm <ref> [9] </ref> is used (with slight modifications) to place -functions wherever two or more downward-exposed uses or definitions merge [15]. (To be precise, -functions are placed wherever two basic block nodes with nonidentity transfer functions for "reaching uses" meet, similar to the technique employed by sparse evaluation graphs [6].) The chaining algorithm <p> We experimentally compared the number of -functions as a function of referenced variables (Figure 8) and program size (Figure 9). These graphs show that the growth in data structures is linear in both cases. While linear data structure growth in practice has been demonstrated for -functions <ref> [9, 12, 15] </ref>, this data supports the contention that other kinds of reference chain merge operators also exhibit linear behavior.
Reference: [10] <author> Paul Feautrier. </author> <title> Dataflow analysis of array and scalar references. </title> <journal> International Journal of Parallel Programming, </journal> <volume> 20(1) </volume> <pages> 23-54, </pages> <year> 1991. </year>
Reference-contexts: A great deal of work has also been done to find dependence due to pointer aliasing. Little has been written about data dependence analysis for scalar references, except to refer to standard data flow analysis [18], to treat a scalar as a degenerate array <ref> [10] </ref>, or to use simple methods based on the dominator relationship or the syntactic structure of the program. We begin with a review of the four types of address-based dependences.
Reference: [11] <author> Michael P. Gerlek, Eric Stoltz, and Michael Wolfe. </author> <title> Beyond induction variables: Detecting and classifying sequences using a demand-driven SSA form. </title> <note> To appear in TOPLAS. </note>
Reference-contexts: FUD chains are our 5 implementation and interpretation of the Static Single Assignment (SSA) form [9] of a program, with extensions. We have previously described how to use FUD chains for other scalar analysis methods, such as induction variable detection and constant propagation <ref> [11, 17] </ref>. The concepts of FUD chains are described in Section 2.
Reference: [12] <author> Paul Havlak. </author> <title> Interprocedural Symbolic Analysis. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, Rice University, </institution> <year> 1994. </year>
Reference-contexts: We experimentally compared the number of -functions as a function of referenced variables (Figure 8) and program size (Figure 9). These graphs show that the growth in data structures is linear in both cases. While linear data structure growth in practice has been demonstrated for -functions <ref> [9, 12, 15] </ref>, this data supports the contention that other kinds of reference chain merge operators also exhibit linear behavior.
Reference: [13] <author> Richard Johnson and Keshav Pingali. </author> <title> Dependence-based program analysis. </title> <booktitle> In Proc. ACM SIGPLAN '93 Conf. on Programming Language Design and Implementation, </booktitle> <pages> pages 78-89, </pages> <address> Albuquerque, NM, </address> <month> June </month> <year> 1993. </year>
Reference-contexts: We have previously described how to use FUD chains for other scalar analysis methods, such as induction variable detection and constant propagation [11, 17]. The concepts of FUD chains are described in Section 2. Other intermediate representations, such as dependence flow graphs <ref> [13] </ref> or the program dependence web [4], could also be used with similar algorithms; those representations contain enough information to find the actual dependences, though they do not represent the dependence relations explicitly.
Reference: [14] <author> Vadim Maslov. </author> <title> Lazy array data-flow dependence analysis. </title> <booktitle> In Conf. Record 21st Annual ACM Symp. Principles of Programming Languages, </booktitle> <pages> pages 311-325, </pages> <address> Portland, OR, </address> <month> January </month> <year> 1994. </year>
Reference-contexts: These common address-based definitions of flow, output, anti-, and input dependence can be found in many references [2, 3, 21, 23]. Value-based dependence relations are a subset of the address-based dependence relations <ref> [14] </ref>. The difference is explained by a simple example: 2 S 1 : A = B - 1 S 3 : A = B + C The address-based definition of dependence includes S 1 ffi f S 4 for A and S 1 ffi a S 4 for B. <p> In this paper we present a new approach to finding data dependence for scalar variables. Our approach has several features, one of which is that it computes value-based dependence, not just address-based dependence. Value-based dependence is more precise <ref> [14] </ref>; using value-based dependence reduces the number of dependence relations and may allow more optimizations. Another feature is that our method computes precise dependence distance, when precision is possible, or imprecise dependence vectors otherwise. Precise dependence distance is important for many optimizations, such as instruction scheduling, software pipelining and parallelization.
Reference: [15] <author> Eric Stoltz. </author> <title> Intermediate Compiler Analysis via Reference Chaining. </title> <type> PhD thesis, </type> <institution> Department of Computer Science and Engineering, Oregon Graduate Institute of Science & Technology, </institution> <note> expected January, </note> <year> 1995. </year>
Reference-contexts: This gives rise to the FUD chains referred to in the previous section. For theoretical details on SSA graph construction the reader is referred to papers by Cytron et al. [9] and Choi et al. [7], while details of FUD chain construction can also be found elsewhere <ref> [15, 16] </ref>. 1 All variables are considered to have an initial "definition" at Entry. <p> When information other than reaching definitions is desired within the CFG, such as reaching or reachable uses, we need to generalize the notion of merging data-flow information. The concept of the -function can be extended to encompass merging downward- or upward-exposed information in general <ref> [15] </ref>. For the purposes of this article, we look at the -function, which is a merge operator that coalesces downward-exposed uses at confluence points in the CFG (necessary to detect anti- and input dependence). <p> This allows more precise interprocedural analysis. See one of the authors' forthcoming thesis for more detail <ref> [15] </ref>. 23 Program Total # Flow Ave. # Links Total # Output Ave. # Links Dependences Traversed Dependences Traversed PERFECT club adm 12055 9.0 8357 11.9 bdna 4808 1.4 2089 2.7 dyfesm 2203 1.9 885 3.4 flo52 4726 3.8 2323 7.3 mg3d 6886 1.7 2142 3.0 ocean 6511 14.4 5121 5.7 <p> The -placement algorithm [9] is used (with slight modifications) to place -functions wherever two or more downward-exposed uses or definitions merge <ref> [15] </ref>. (To be precise, -functions are placed wherever two basic block nodes with nonidentity transfer functions for "reaching uses" meet, similar to the technique employed by sparse evaluation graphs [6].) The chaining algorithm (originally called "renaming") is modified to keep a stack of current uses for each variable (instead of a <p> We experimentally compared the number of -functions as a function of referenced variables (Figure 8) and program size (Figure 9). These graphs show that the growth in data structures is linear in both cases. While linear data structure growth in practice has been demonstrated for -functions <ref> [9, 12, 15] </ref>, this data supports the contention that other kinds of reference chain merge operators also exhibit linear behavior.
Reference: [16] <author> Eric Stoltz, Michael P. Gerlek, and Michael Wolfe. </author> <title> Extended SSA with factored use-def chains to support optimization and parallelism. </title> <booktitle> In Proc. of 27th Annual Hawaii International Conference on System Sciences, </booktitle> <pages> pages 43-52, </pages> <month> January </month> <year> 1994. </year>
Reference-contexts: This gives rise to the FUD chains referred to in the previous section. For theoretical details on SSA graph construction the reader is referred to papers by Cytron et al. [9] and Choi et al. [7], while details of FUD chain construction can also be found elsewhere <ref> [15, 16] </ref>. 1 All variables are considered to have an initial "definition" at Entry. <p> encounter a killing definition for the variable being analyzed; this means that the flow dependence must be to the subsequent iteration, and its distance is 1. 3.2 Algorithm 1: Precisely Detecting Scalar Flow Dependence An algorithm for detection of scalar flow dependences within a single loop has been presented previously <ref> [16] </ref>. To extend this algorithm for nested loops, several issues need to be addressed. First, we must provide a recursive routine, to allow arbitrary nesting. Second, the distance and/or direction of the dependence 12 must be accurate in terms of all loops which contain the dependence.
Reference: [17] <author> Eric Stoltz, Michael Wolfe, and Michael P. Gerlek. </author> <title> Constant propagation: A fresh, demand-driven look. </title> <booktitle> In Symposium on Applied Computing, </booktitle> <address> Phoenix, AZ, </address> <month> March </month> <year> 1994. </year> <note> ACM SIGAPP. </note>
Reference-contexts: FUD chains are our 5 implementation and interpretation of the Static Single Assignment (SSA) form [9] of a program, with extensions. We have previously described how to use FUD chains for other scalar analysis methods, such as induction variable detection and constant propagation <ref> [11, 17] </ref>. The concepts of FUD chains are described in Section 2.
Reference: [18] <author> Chau-Wen Tseng. </author> <title> An optimizing Fortran D compiler for MIMD distributed-memory machines. </title> <type> PhD Dissertation TR93-199, </type> <institution> Rice University, Dept. of Computer Science, </institution> <month> January </month> <year> 1993. </year> <month> 35 </month>
Reference-contexts: A great deal of work has also been done to find dependence due to pointer aliasing. Little has been written about data dependence analysis for scalar references, except to refer to standard data flow analysis <ref> [18] </ref>, to treat a scalar as a degenerate array [10], or to use simple methods based on the dominator relationship or the syntactic structure of the program. We begin with a review of the four types of address-based dependences. <p> In other cases, privatization of scalar variables is possible when they are detected as being involved in only loop-independent dependences <ref> [5, 18] </ref>. In this example: 3 loop if TEST then x = : : : else x = : : : endif : : : = x endloop all flow dependences for x are loop-independent, so x can be privatized for each loop iteration.
Reference: [19] <author> Michael E. Wolf. </author> <title> Improving locality and parallelism in nested loops. </title> <type> PhD Dissertation COMP TR. </type> <institution> CSL-TR-92-538, Stanford Univ., Dept. Computer Science, </institution> <month> August </month> <year> 1992. </year>
Reference-contexts: Algorithm 4 provides the details to detect all statement-based input dependences, which is also based upon the modifications made to Figures 4 and 5. Detecting value-based input dependence can be useful for optimizing locality of reference, achieving better memory-hierarchy 28 (i.e. cache) performance <ref> [19] </ref>.
Reference: [20] <author> Michael Wolfe. </author> <title> Techniques for improving the inherent parallelism in programs. M.S. </title> <type> thesis UIUCDCS-R-78-929, </type> <institution> Univ. Illinois, Dept. Computer Science, </institution> <month> July </month> <year> 1978. </year>
Reference-contexts: Sometimes an exact distance cannot be computed; in that case, a less precise abstraction is used, called a direction vector <ref> [20, 22] </ref>.
Reference: [21] <author> Michael Wolfe. </author> <title> Optimizing supercompilers for supercomputers. </title> <type> PhD Dissertation UIUCDCS-R-82-1105, </type> <institution> Univ. Illinois, Dept. Computer Science, </institution> <month> October </month> <year> 1982. </year> <note> (available from Univ. Microfilms Inc., document 83-03027). </note>
Reference-contexts: Thus, the compiler must conservatively assume that a flow dependence might exist whenever there is a path from a definition to a use, and so on for the other types of dependence. These common address-based definitions of flow, output, anti-, and input dependence can be found in many references <ref> [2, 3, 21, 23] </ref>. Value-based dependence relations are a subset of the address-based dependence relations [14].
Reference: [22] <author> Michael Wolfe. </author> <title> Optimizing Supercompilers for Supercomputers. </title> <booktitle> Research Monographs in Parallel and Distributed Computing. </booktitle> <publisher> Pitman Publishing, </publisher> <address> London, </address> <year> 1989. </year> <note> (also available from MIT Press). </note>
Reference-contexts: Sometimes an exact distance cannot be computed; in that case, a less precise abstraction is used, called a direction vector <ref> [20, 22] </ref>.
Reference: [23] <author> Michael Wolfe and Utpal Banerjee. </author> <title> Data dependence and its application to parallel processing. </title> <journal> International J. Parallel Programming, </journal> <volume> 16(2) </volume> <pages> 137-178, </pages> <month> April </month> <year> 1987. </year> <month> 36 </month>
Reference-contexts: Thus, the compiler must conservatively assume that a flow dependence might exist whenever there is a path from a definition to a use, and so on for the other types of dependence. These common address-based definitions of flow, output, anti-, and input dependence can be found in many references <ref> [2, 3, 21, 23] </ref>. Value-based dependence relations are a subset of the address-based dependence relations [14].
References-found: 23

