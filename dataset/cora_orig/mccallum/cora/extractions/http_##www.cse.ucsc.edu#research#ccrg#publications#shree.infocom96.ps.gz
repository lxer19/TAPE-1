URL: http://www.cse.ucsc.edu/research/ccrg/publications/shree.infocom96.ps.gz
Refering-URL: http://www.cse.ucsc.edu/research/ccrg/publications.html
Root-URL: http://www.cse.ucsc.edu
Title: Congestion-Oriented Shortest Multipath Routing  
Author: Shree Murthy J.J. Garcia-Luna-Aceves 
Address: Santa Cruz, CA 95064  
Affiliation: Computer Engineering Department University of California  
Abstract: We present a framework for the modeling of multipath routing in connectionless networks that dynamically adapt to network congestion. The basic routing protocol uses a short-term metric based on hop-by-hop credits to reduce congestion over a given link, and a long-term metric based on end-to-end path delay to reduce delays from a source to a given destination. A worst-case bound on the end-to-end path delay is derived under three architectural assumptions: each router adopts weighted fair queueing (or packetized generalized processor sharing) service discipline on a per destination basis, a permit-bucket filter is used at each router to regulate traffic flow on a per destination basis, and all paths are loop free. The shortest multipath routing protocol regulates the parameters of the destination-oriented permit buckets and guarantees that all portions of a multipath are loop free. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. Bertsekas. </author> <title> Dynamic behavior of shortest path routing algorithms for communication networks. </title> <journal> IEEE Trans. Automat. Control, AC-27, </journal> <volume> pp.60-74, </volume> <year> 1982. </year>
Reference-contexts: However, as has been documented in <ref> [1] </ref>, allowing a single-path routing algorithm to react to congestion can lead to unstable oscillatory behavior.
Reference: [2] <author> D.P. Bertsekas and R.G. Gallager. </author> <title> Data Networks. </title> <publisher> Prentice Hall, </publisher> <year> 1992. </year>
Reference-contexts: Router i adjusts M AD i j depending on the congestion level of the network. If router i finds a feasible successor, it remains passive and updates its routing-table entry as in the Distributed Bellman-Ford algorithm <ref> [2] </ref>. Alternatively, if router i cannot find a feasible successor, it first sets its distance equal to the addition of the distance reported by its current successor plus the cost of the link to that neighbor. The router also sets its maximum allowable distance equal to its new distance.
Reference: [3] <author> R.L. Cruz. </author> <title> A calculus for network delay, Part II: Network Analysis. </title> <journal> IEEE Trans. Inform. Theory, Vol.37, </journal> <volume> pp.132-141, </volume> <year> 1991. </year>
Reference-contexts: At each node, traffic to destination j is constrained by a permit bucket filter. The worst-case delay and backlog is upper bounded by an additive scheme due to Cruz <ref> [3] </ref>. The rate at which the packets are serviced at each node depends on the permit bucket or leaky bucket parameters i j and i a given destination j. The parameter i j gives the permit bucket size and i j the credit generation rate at node i.
Reference: [4] <author> A. Demers, S. Keshav, and S. Shenker. </author> <title> Analysis and simulation of a fair queueing algorithm. </title> <booktitle> In ACM SIGCOMM, </booktitle> <address> pp.1-12, </address> <year> 1989. </year>
Reference-contexts: Scheduling at a node is done by maintaining permit bucket filters at each node for all active destinations. A weighted fair queueing mechanism is used for fairness <ref> [4] </ref>. Routing is done on a hop-by-hop basis independently at each node. To forward packets to a given destination, the protocol uses two routing metrics: a short-term metric based on hop-by-hop credits to reduce congestion along a link, and a long-term metric based on path-delay to minimize end-to-end delay.
Reference: [5] <author> J.J. Garcia-Luna-Aceves. </author> <title> Loop-free routing using diffusing computation. </title> <journal> IEEE/ACM Trans. Networking, Vol.1, No.1, </journal> <volume> pp.130-141, </volume> <month> Feb </month> <year> 1993. </year>
Reference-contexts: Permit buckets consist of permits or tokens fed by periodic updates of credits. To schedule packet transmission, we assume a packet-by-packet generalized processor sharing (PGPS) server [9] at each node. To establish loop-free multipaths, we extend prior results on loop-free single-path routing algorithms introduced in <ref> [5] </ref>. This results in a congestion-oriented multipath routing architecture that uses a short-term metric based on hop-by-hop credits to reduce congestion over a given link, and a long-term metric based on end-to-end path delay to reduce delay from source to destination. <p> Given the capacity of each link, the utilization of the link can also be determined. Credits are reassigned to upstream neighbors depending on the traffic flow on each of the incoming links. A multipath routing algorithm based on DUAL <ref> [5] </ref> maintains multiple loop-free paths. Each time the network state changes, paths are recomputed and the new network state is obtained. This is made possible by the periodic exchange of routing information. Each node maintains a routing table, a distance table, a link cost table and a link credit table. <p> constant K times the total available credits; therefore, D j (t) = t i : l2SM i W CR jl (t): D jl (t) (12) Multiple loop-free paths from each node to a destination are maintained by means of a shortest multipath routing algorithm (SMRA), which is based on DUAL <ref> [5] </ref>. Any change in distance is notified by event-driven update messages. <p> From router i's standpoint, a feasible successor toward destination j is a neighbor router k that satisfies the maximum allowable distance condition (MADC) given by the following two equations <ref> [5] </ref>: D j = D jk + d ik = M infD i D jk &lt; M AD j (13) where M AD i j is the maximum allowable distance for destination j, and is equal to the minimum value obtained for D i j since the last time router i <p> Multiple changes in link cost or availability are handled by ensuring that a given node is waiting to complete the processing of at most one query at any given time. The mechanism used to accomplish this is specified in <ref> [5] </ref>, and is such that a node can be either passive or in one of four active states, and it processes any pending update or distance increases that occurred while it was active. <p> Maximum Allowable Distance Condition When nodes choose their successors using SMC, the path from source to destination obtained as a result of this is loop free at every instant. The proof of correctness and loop-freedom of SMRA is basically the same as that provided in <ref> [5] </ref> for DUAL. 4. Worst-Case Steady-State Delays In this section, we derive an upper bound on the end-to-end steady-state path delay from node i to destination j (D ifl j ) as a function of the credits available through each path under steady state.
Reference: [6] <author> H.T Kung, Blackwell. T, and Chapman. A. </author> <title> Credit-based flow control for ATM networks: credit update protocol, adaptive credit allocation, and statistical multiplexing. </title> <booktitle> In ACM SIGCOMM, </booktitle> <address> pp.101-14, London, UK, </address> <month> Aug/Sept </month> <year> 1994. </year>
Reference-contexts: This can be done either by estimating the credits available as in <ref> [6] </ref> or by explicitly sending a marker. We opt for the estimation mechanism. Here, credits are sent to the immediate upstream neighbor, i.e., they propagate only one hop. The update period used for updating routing information is considered as one round-trip delay by a data packet.
Reference: [7] <author> Shree Murthy and J.J. Garcia-Luna-Aceves. </author> <title> Congestion-oriented shortest multipath routing. </title> <type> UCSC-Technical Report, </type> <month> Oct. </month> <year> 1995. </year>
Reference-contexts: The update flag indicates whether the entry is an update (u i j = 0), a query (u i j = 1) or a reply to a query (u i A detailed specification of SMRA is given in <ref> [7] </ref>. A router i can be active or passive for destination j at any given time. Node i is active for destination j if it is waiting for at least one reply from a neighbor, and is passive otherwise.
Reference: [8] <author> C. Ozveren, R. Simcoe, and G. Varghese. </author> <title> Reliable and efficient hop-by-hop flow control. </title> <booktitle> In ACM SIGCOMM, </booktitle> <address> pp.89-100, </address> <year> 1994. </year>
Reference-contexts: The correctness of the credit based mechanism (i.e., showing that it has no deadlocks and that packets are not dropped) can be proven in a similar way as for virtual-circuit connections <ref> [8] </ref>.
Reference: [9] <author> A.K. Parekh and R.G. Gallager. </author> <title> A Generalized Processor Sharing Approach to Flow Control in Integrated Services Networks: The Single-Node Case. </title> <journal> IEEE/ACM Trans. Networking, Vol.1, No.3, </journal> <volume> pp.344-357, </volume> <month> June </month> <year> 1993. </year>
Reference-contexts: Permit buckets consist of permits or tokens fed by periodic updates of credits. To schedule packet transmission, we assume a packet-by-packet generalized processor sharing (PGPS) server <ref> [9] </ref> at each node. To establish loop-free multipaths, we extend prior results on loop-free single-path routing algorithms introduced in [5]. <p> The packet-by-packet generalized processor sharing (PGPS) scheme is used at each server <ref> [9] </ref>. Packets are transmitted as individual entities. A packet is said to have arrived only after the last bit has been received at a node. The server picks up the first packet that would complete service if no additional packets would arrive. <p> This definition is much the same given in <ref> [9] </ref>, the only difference being that here we maintain leaky-bucket parameters for each active destination rather than for each session. Destination-based credits are aggregated at each node.
Reference: [10] <author> A.K. Parekh and Robert G. Gallager. </author> <title> A generalized processor sharing approach to flow control in integrated services networks: The multiple node case. </title> <journal> IEEE/ACM Trans. Networking, Vol.2, No.2, </journal> <volume> pp.137-150, </volume> <month> April </month> <year> 1994. </year>
Reference-contexts: Section 2. describes the network model used in our protocol. Section 3. gives a detailed description of the new routing protocol. Section 4. derives worst-case steady-state delay bounds for packets accepted into the network by extending the analysis described in <ref> [10] </ref>. Section 5. presents our conclusions. 2. Network Model A computer network is modeled as an undirected finite graph represented by G (N; E), where N is the set of nodes and E is the set of edges or links connecting the nodes. <p> any path from a source to a given destination can contribute to the flow to that destination, each node is modeled as a PGPS server to regulate the incoming traffic, instead of just having a simple scheduling discipline at the intermediate nodes as can be assumed in a connection-oriented architecture <ref> [10] </ref>. This scheme, along with the credit-based congestion control mechanism, ensures that the bursty nature of sources does not affect the routing architecture. <p> Path delay can also be interpreted as the time it would take for a destination j backlog to clear when there are no more arrivals after time t. Parekh and Gallager have analyzed worst-case session delay in a connection-oriented network architecture <ref> [10] </ref>. We adopt a similar approach for each destination in a connectionless architecture. To do this, we assume a stable topology in which all routers have finite distances to each other. <p> With these constraints, the bound on the delay for a given destination can be obtained using a similar approach as in <ref> [10] </ref>. The delay on a link (i; k) (per hop delay) d i jk for a given destination j is the sum of the queueing delay and the propagation delay on that link. <p> At every node, each destination is constrained independently by a permit bucket scheme. Following Parekh and Gallager's approximation <ref> [10] </ref>, we assume the links to be of infinite capacity. The results for the infinite capacity case upper-bound the finite capacity case. In other words, the results of infinite capacity can be used for any finite speed link.
References-found: 10

