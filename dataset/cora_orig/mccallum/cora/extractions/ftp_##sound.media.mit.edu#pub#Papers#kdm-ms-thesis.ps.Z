URL: ftp://sound.media.mit.edu/pub/Papers/kdm-ms-thesis.ps.Z
Refering-URL: http://sound.media.mit.edu/papers.html
Root-URL: http://www.media.mit.edu
Title: A Computational Model of Spatial Hearing  
Author: by Keith Dana Martin Barry L. Vercoe Patrick M. Zurek 
Degree: (1993) Submitted to the Department of Electrical Engineering and Computer Science in partial fulfillment of the requirements for the degree of Master of Science in Electrical Engineering at the  All rights reserved. Author  Certified by  Professor of Media Arts and Sciences Thesis Supervisor Certified by  Thesis Supervisor Accepted by Frederic R. Morgenthaler Chairman, Departmental Committee on Graduate Students  
Date: June 1995  May 18, 1995  
Affiliation: B.S. (distinction), Cornell University  MASSACHUSETTS INSTITUTE OF TECHNOLOGY  c Massachusetts Institute of Technology 1995.  Department of Electrical Engineering and Computer Science  Principal Research Scientist Research Laboratory of Electronics  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> J. Blauert. </author> <title> Spatial Hearing. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1983. </year>
Reference-contexts: Excellent overviews of the cues used for localization and their relative importance may be found in <ref> [1] </ref> and [18]. 2.1.1 The "duplex" theory of localization Near the turn of the century, Lord Rayleigh made a series of observations that have strongly influenced how many researchers think about localization [24]. <p> In contrast, most investigations of human localization performance suggest that localization blur is much larger for sources at rear positions <ref> [1, 18] </ref>.
Reference: [2] <author> J. Blauert and W. Cobben. </author> <title> "Some Consideration of Binaural Cross Correlation Analysis". </title> <journal> Acustica, </journal> <volume> 39(2) </volume> <pages> 96-104, </pages> <year> 1978. </year>
Reference-contexts: One of the many cross-correlation-based models is the one considered by Blauert and Cobben, which employs a running , or short-time cross-correlation that operates on the outputs of band-pass channels intended to model the frequency-analysis function of the cochlea <ref> [2] </ref>. Their simple model of lateralization based on interaural time differences was extended by Lindemann to deal with interaural intensity differences and non-stationary signals, including a model of the precedence effect [16]. Gaik further extended the model by incorporating a notion of "natural" combinations of IIDs and ITDs [9]. <p> By squaring the signal and its Hilbert transform, summing the two signals, and taking the square root, the envelope signal may be extracted. Alternatively, the physiology of the cochlea suggests a half-wave rectification and smoothing algorithm [22]. This approach has been used by many authors (e.g., <ref> [2] </ref>), but the non-linearity of the half-wave rectifier implied by the cochlear physiology is difficult to analyze in terms of frequency domain effects and has thus not been used in the current model. A third alternative is the "square-and-smooth" method that is adopted in the current model. <p> It is possible to arrive at the spectrum in (b) by appropriate filtering of the spectrum in (f). the limit is set to 800 Hz, which is the value chosen by Blauert and Cobben <ref> [2] </ref>. <p> This effect can be seen in of measurement noise. input spectrum. Each (fi) marks the position of an onset detected in the signal (see Interaural phase delays The IPD is estimated by a running cross-correlator similar to those proposed by Blauert <ref> [2] </ref> and Lindemann [16]: IPD (t) = argmax t 1 t )R k (t 0 + 2 Here, L k (t) and R k (t) are the signals in the kth channel of the left and right ear filter banks respectively, w (t) is a window function, and t is limited <p> The window used by Blauert is a decaying exponential with a time constant 23 of a few milliseconds <ref> [2] </ref>. In the current model, we use a window of the form: w (t) = Ate t=t ; (3:4) with an effective "width" of 4-5 ms. In the current implementation, the running cross-correlation is sampled in t .
Reference: [3] <author> M. Bodden. </author> <title> "Modeling human sound-source localization and the cocktail-party-effect". </title> <journal> acta acustica, </journal> <volume> 1 </volume> <pages> 43-55, </pages> <year> 1993. </year>
Reference-contexts: Gaik further extended the model by incorporating a notion of "natural" combinations of IIDs and ITDs [9]. Most recently, Bodden demonstrated that the model could be used for source separation in a multiple-speaker speech context for sources located in the horizontal plane <ref> [3] </ref>. Another important lateralization model based on cross-correlation is the one proposed by Stern, Zeiberg, and Trahiotis [29, 31, 28, 32]. Their model addresses the issue of combining binaural information across frequency. As in the Blauert/Cobben model, the cross-correlation operator is applied to the outputs of band-pass filters.
Reference: [4] <author> A. S. Bregman. </author> <title> Auditory Scene Analysis. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1990. </year>
Reference: [5] <author> J. Chen, B. D. Van Veen, and K. E. Hecox. </author> <title> "A spatial feature extraction and regularization model for the head-related transfer function". </title> <journal> J. Acoust. Soc. Am., </journal> <volume> 97(1) </volume> <pages> 439-452, </pages> <year> 1995. </year>
Reference-contexts: The choice of kernel positions is important, and the optimal choice may depend on the characteristics of the surface to be approximated. In this thesis, we choose the kernel positions to be spaced by approximately 10 ffi great circle arcs. According to the results in <ref> [5] </ref>, this spacing is on the verge of under-sampling the data. Unfortunately, a more dense sampling is problematic with our limited data set, as will be discussed shortly. The MMSE interpolation method works extremely well for approximating noise-free functions with some "smoothness" constraints. <p> The interaural difference data, however, has no well-defined smoothness constraints and is certainly not noise-free (noise may be present both in the original HRTF measurements and in the interaural difference template calculations). The results in <ref> [5] </ref> suggest that the surfaces do have an underlying smoothness or regularity, but our data may be under-sampled to some degree.
Reference: [6] <author> H. S. Colburn and N. I. Durlach. </author> <title> "Models of Binaural Interaction". </title> <booktitle> In Handbook of Perception. Vol. IV, chapter 11, </booktitle> <pages> pages 467-518. </pages> <publisher> Academic Press, </publisher> <year> 1978. </year>
Reference-contexts: These models seek to estimate both the azimuth (horizontal position) and elevation (vertical position) of sound sources. In this section, we briefly describe some of these existing models. 2.2.1 Lateralization models ("1D" localization) Many of the early lateralization models are reviewed in <ref> [6] </ref>. Of the early models, perhaps the most influential was the neural model proposed by Jeffress ([13]), which sketches out a physiologically plausible method of extracting interaural time cues from eardrum signals.
Reference: [7] <author> N. I. Durlach. </author> <title> "A Decision Model for Psychophysics". </title> <type> RLE Technical Report, </type> <institution> Massachusetts Institute of Technology, </institution> <year> 1968. </year>
Reference-contexts: This IID will be called the just-noticeable interaural intensity difference. Similarly, we might measure the smallest interaural delay t which results in a different perception from the baseline ITD = 0. In "A Decision Model for Psychophysics," Durlach interprets the significance of such JND measurements <ref> [7] </ref>. Following his derivation, we first assume that the presentation of a stimulus gives rise to a unidimensional perceptual variable and that the mapping from the physical variable to the perceptual variable is monotonic.
Reference: [8] <author> N. I. Durlach, A. Rigopulos, X. D. Pang, W. S. Woods, A. Kulkarni, H. S. Colburn, and E. M. Wenzel. </author> <title> "On the Externalization of Auditory Images". </title> <journal> Presence, </journal> <volume> 1(2) </volume> <pages> 251-257, </pages> <month> Spring </month> <year> 1992. </year>
Reference-contexts: None of the models described in this section have attempted to model the precedence effect. 2 It has been suggested that laboratory generated distortions of IIDs and ITDs which do not arise in the "real world" may result in sound events that appear to occur inside the head <ref> [8, 9] </ref>. 14 Chapter 3 Form of the Model 3.1 Design Overview 3.1.1 Localization cues used in the current model As described in Chapter 2, there are several types of localization cues available.
Reference: [9] <author> W. Gaik. </author> <title> "Combined evaluation of interaural time and intensity differences: Psy-choacoustic results and computer modeling". </title> <journal> J. Acoust. Soc. Am., </journal> <volume> 94(1) </volume> <pages> 98-110, </pages> <year> 1993. </year>
Reference-contexts: Their simple model of lateralization based on interaural time differences was extended by Lindemann to deal with interaural intensity differences and non-stationary signals, including a model of the precedence effect [16]. Gaik further extended the model by incorporating a notion of "natural" combinations of IIDs and ITDs <ref> [9] </ref>. Most recently, Bodden demonstrated that the model could be used for source separation in a multiple-speaker speech context for sources located in the horizontal plane [3]. Another important lateralization model based on cross-correlation is the one proposed by Stern, Zeiberg, and Trahiotis [29, 31, 28, 32]. <p> None of the models described in this section have attempted to model the precedence effect. 2 It has been suggested that laboratory generated distortions of IIDs and ITDs which do not arise in the "real world" may result in sound events that appear to occur inside the head <ref> [8, 9] </ref>. 14 Chapter 3 Form of the Model 3.1 Design Overview 3.1.1 Localization cues used in the current model As described in Chapter 2, there are several types of localization cues available.
Reference: [10] <author> B. Gardner and K. Martin. </author> <title> "HRTF Measurements of a KEMAR Dummy-Head Microphone". </title> <type> Perceptual Computing Technical Report #280, </type> <institution> MIT Media Lab, </institution> <month> May </month> <year> 1994. </year>
Reference-contexts: This property is important, as it allows the impulse response of the system to be obtained by cross-correlation of the measured response with the original noise signal [25, 33]. The measurement process is presented in greater detail in <ref> [10] </ref> and [11]. In total, 710 positions were measured. Test signal synthesis In the absence of reverberation and nearby acoustically reflective objects, the acoustic signals at the eardrums consist entirely of the direct sound from the sound source.
Reference: [11] <author> W. G. Gardner and K. D. Martin. </author> <title> "HRTF measurements of a KEMAR". </title> <journal> J. Acoust. Soc. Am., </journal> <volume> 97(6), </volume> <year> 1995. </year>
Reference-contexts: An example of this is shown in Figure 2-1, which shows the variation of the IID with frequency and elevation along the 60 ffi cone of confusion for a KEMAR dummy-head microphone <ref> [11] </ref>. It has been shown that HRTF data can be used effectively to synthesize localization cues in signals intended for presentation over headphones. With care, it is even possible 10 confusion (IID data derived from measurements of a KEMAR dummy-head microphone [11]). to achieve externalization 1 of synthesized sound sources with <p> ffi cone of confusion for a KEMAR dummy-head microphone <ref> [11] </ref>. It has been shown that HRTF data can be used effectively to synthesize localization cues in signals intended for presentation over headphones. With care, it is even possible 10 confusion (IID data derived from measurements of a KEMAR dummy-head microphone [11]). to achieve externalization 1 of synthesized sound sources with headphone presentation. Wightman and Kistler have shown that the information contained in the HRTFs is sufficient to explain localization performance in both azimuth and elevation [34, 35]. <p> This property is important, as it allows the impulse response of the system to be obtained by cross-correlation of the measured response with the original noise signal [25, 33]. The measurement process is presented in greater detail in [10] and <ref> [11] </ref>. In total, 710 positions were measured. Test signal synthesis In the absence of reverberation and nearby acoustically reflective objects, the acoustic signals at the eardrums consist entirely of the direct sound from the sound source.
Reference: [12] <author> R. M. Hershkowitz and N. I. Durlach. </author> <title> "Interaural Time and Amplitude jnds for a 500-Hz Tone". </title> <journal> J. Acoust. Soc. Am., </journal> <volume> 46(6 (Part </volume> 2)):1464-1467, 1969. 
Reference-contexts: The probability of correct response is monotonically related to the variable: d 0 = With this decision model, we consider the interaural JND measurements reported by Hershkowitz and Durlach <ref> [12] </ref>. For a 500 Hz tone, the authors report the just-noticeable intensity and time-delay differences. Using a forced-choice paradigm, they report the JND as the interaural difference increment which results in a probability of correct response of 0:75, which corresponds to d 0 ' 1:349. <p> Since d 0 ' 1, these JNDs are nearly the same as the standard deviation, , of the perceptual noise. The data in <ref> [12] </ref> can not be extrapolated to other stimulus frequencies, but as a first approximation, we might assume that the perceptual variance is the same in all frequency channels. These results may be used to guide the relative weighting of cues in our localization model.
Reference: [13] <author> L. A. Jeffress. </author> <title> "A place theory of sound localization". </title> <journal> Journal of Comparative and Physiological Psychology, </journal> <volume> 41 </volume> <pages> 35-39, </pages> <year> 1948. </year> <month> 60 </month>
Reference: [14] <author> G. F. Kuhn. </author> <title> "Physical Acoustics and Measurements Pertaining to Directional Hearing". </title> <editor> In W. A. Yost and G. Gourevitch, editors, </editor> <booktitle> Directional Hearing, chapter 1, </booktitle> <pages> pages 3-25. </pages> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1987. </year>
Reference-contexts: Many researchers have solved the acoustic wave equation for such a configuration with sound sources at various positions, and while the resulting solution is rather complicated, some useful approximations have been made. One such approximation, for ITDs, is presented by Kuhn <ref> [14] </ref>: ITD ' &gt; &lt; 3a c sin inc at low frequencies 2a c sin inc at high frequencies ; (2:1) where a is the radius of the sphere used to model the head, c is the speed of sound, and inc is the angle between the median plane and a <p> Because of the influence of the pinna (the outer "flange" of the ear), the shape of the head, and their variation across listeners, simple approximations for the IID are not as applicable as those made for the ITD <ref> [14] </ref>. When the IID and ITD are modeled in this way, Woodworth's "cones of confusion" arise [37]. For a given set of interaural measurements (IID and ITD), there exists a locus of points for which those measurements are constant.
Reference: [15] <author> C. Lim and R. O. Duda. </author> <title> "Estimating the Azimuth and Elevation of a Sound Source from the Output of a Cochlear Model". </title> <booktitle> In Preprint for the 28th Asilomar Conference on Signals, Systems, and Computers, </booktitle> <address> Pacific Grove, CA, </address> <month> October </month> <year> 1994. </year>
Reference-contexts: Three such models, however, are the spectral-cue localization model proposed by Zakarauskas and Cynader [38], and the models based on interaural differences proposed by Wight-man, Kistler, and Perkins [36] and by Lim and Duda <ref> [15] </ref>. The model proposed by Zakarauskas and Cynader is based on the extraction of monaural cues from the spectrum received at the eardrum.
Reference: [16] <author> W. Lindemann. </author> <title> "Extension of a binaural cross-correlation model by contralateral inhibition. I. Simulation of lateralization for stationary signals". </title> <journal> J. Acoust. Soc. Am., </journal> <volume> 80(6) </volume> <pages> 1608-1622, </pages> <year> 1986. </year>
Reference-contexts: Their simple model of lateralization based on interaural time differences was extended by Lindemann to deal with interaural intensity differences and non-stationary signals, including a model of the precedence effect <ref> [16] </ref>. Gaik further extended the model by incorporating a notion of "natural" combinations of IIDs and ITDs [9]. Most recently, Bodden demonstrated that the model could be used for source separation in a multiple-speaker speech context for sources located in the horizontal plane [3]. <p> This effect can be seen in of measurement noise. input spectrum. Each (fi) marks the position of an onset detected in the signal (see Interaural phase delays The IPD is estimated by a running cross-correlator similar to those proposed by Blauert [2] and Lindemann <ref> [16] </ref>: IPD (t) = argmax t 1 t )R k (t 0 + 2 Here, L k (t) and R k (t) are the signals in the kth channel of the left and right ear filter banks respectively, w (t) is a window function, and t is limited to the range
Reference: [17] <author> E. A. Macpherson. </author> <title> "A Computer Model of Binaural Localization for Stereo Imaging Measurement". </title> <journal> J. Audio Eng. Soc., </journal> <volume> 39(9) </volume> <pages> 604-622, </pages> <year> 1991. </year>
Reference-contexts: Among these is the model proposed by Macpherson, which uses a simplified model of the cochlea as a front-end for estimating azimuth and "image width" of sources in the "front half" of the horizontal plane <ref> [17] </ref>. Estimates are made from measures of the IID and ITD in various frequency bands. The model is designed to work with impulsive and continuous signals, but uses different algorithms for the two types of signals, and includes no mechanism to determine which type of signal it is operating upon.
Reference: [18] <author> J. C. Middlebrooks and D. M. Green. </author> <title> "Sound Localization by Human Listeners". Annu. </title> <journal> Rev. Psychol., </journal> <volume> 42 </volume> <pages> 135-159, </pages> <year> 1991. </year>
Reference-contexts: Excellent overviews of the cues used for localization and their relative importance may be found in [1] and <ref> [18] </ref>. 2.1.1 The "duplex" theory of localization Near the turn of the century, Lord Rayleigh made a series of observations that have strongly influenced how many researchers think about localization [24]. <p> the symmetry present in the spherical head model, there are no cues available to resolve positional ambiguity on a given cone of confusion. 2.1.3 Head-related transfer functions It is generally accepted that the cues used for localization are embodied in the free-field to eardrum, or head-related , transfer function (HRTF) <ref> [18] </ref>. An HRTF is a measure of the acoustic transfer function between a point in space and the eardrum of the listener. <p> This topic will be discussed in detail in Section 3.3.3. 2.1.4 Monaural and dynamic cues In addition to the interaural cues described above, there are several other useful localization cues, including monaural spectral cues, distance cues, and dynamic cues imparted by head movements. These cues are reviewed briefly in <ref> [18] </ref>. Spectral cues are in general related to the "shape" of the HRTF functions, possibly including the location of "ridges" and "notches" in the monaural spectrum. These cues may be extracted by making assumptions about the source spectrum. <p> Such cues have been dismissed by some researchers as insignificant for explaining localization performance in general, but they certainly can play a role in resolving some otherwise ambiguous situations <ref> [18] </ref>. 2.1.5 The precedence effect In a reverberant environment, "direct" sound from a sound source arrives at a given position slightly before energy reflected from various surfaces in the acoustic space. <p> In contrast, most investigations of human localization performance suggest that localization blur is much larger for sources at rear positions <ref> [1, 18] </ref>.
Reference: [19] <author> B. C. J. Moore. </author> <title> An Introduction to the Psychology of Hearing. </title> <publisher> Academic Press, </publisher> <address> Boston, MA, </address> <year> 1989. </year>
Reference-contexts: The constant Q nature of the filter bank is a loose fit to the critical bandwidths reported for the human ear <ref> [19] </ref>. The "shape" of the filters is a result of the design technique, and is not intended to be a close match to cochlear tuning curves. 3.2.3 Envelope processing There are several reasonable approaches to extracting the envelope of a band-pass signal.
Reference: [20] <author> A. V. Oppenheim and R. W. Schafer. </author> <title> Discrete-Time Signal Processing. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1989. </year>
Reference: [21] <author> A. V. Oppenheim and A. S. Willsky. </author> <title> Signals and Systems. </title> <publisher> Prentice-Hall, </publisher> <address> Engle-wood Cliffs, NJ, </address> <year> 1983. </year>
Reference: [22] <author> J. O. Pickles. </author> <title> An Introduction to the Physiology of Hearing. </title> <publisher> Academic Press, </publisher> <address> Boston, MA, </address> <year> 1988. </year>
Reference-contexts: By squaring the signal and its Hilbert transform, summing the two signals, and taking the square root, the envelope signal may be extracted. Alternatively, the physiology of the cochlea suggests a half-wave rectification and smoothing algorithm <ref> [22] </ref>. This approach has been used by many authors (e.g., [2]), but the non-linearity of the half-wave rectifier implied by the cochlear physiology is difficult to analyze in terms of frequency domain effects and has thus not been used in the current model.
Reference: [23] <author> B. Rakerd and W. M. Hartmann. </author> <title> "Localization of sound in rooms, II: The effects of a single reflecting surface". </title> <journal> J. Acoust. Soc. Am., </journal> <volume> 78 </volume> <pages> 524-533, </pages> <year> 1985. </year>
Reference-contexts: The sharp rise in blur for sources near the median plane results from the fact that all interaural difference cues are very small for positions near the median plane. 49 reliable, and discount the other set <ref> [23] </ref>. The current model has no provision for determining which cues are more reliable. In order to facilitate comparisons with human responses, it was decided to modify the model slightly.
Reference: [24] <author> L. </author> <title> Rayleigh. "On our perception of sound direction". </title> <journal> Philos. Mag., </journal> <volume> 13 </volume> <pages> 214-232, </pages> <year> 1907. </year>
Reference-contexts: Excellent overviews of the cues used for localization and their relative importance may be found in [1] and [18]. 2.1.1 The "duplex" theory of localization Near the turn of the century, Lord Rayleigh made a series of observations that have strongly influenced how many researchers think about localization <ref> [24] </ref>. Rayleigh observed that sound arriving at a listener from sources located away from the median (mid-sagittal) plane would result in differences in the signals observed at a listener's ears.
Reference: [25] <author> D. D. Rife and J. Vanderkooy. </author> <title> "Transfer-Function Measurements using Maximum-Length Sequences". </title> <journal> J. Audio Eng. Soc., </journal> <volume> 37(6) </volume> <pages> 419-444, </pages> <year> 1989. </year>
Reference-contexts: This property is important, as it allows the impulse response of the system to be obtained by cross-correlation of the measured response with the original noise signal <ref> [25, 33] </ref>. The measurement process is presented in greater detail in [10] and [11]. In total, 710 positions were measured. Test signal synthesis In the absence of reverberation and nearby acoustically reflective objects, the acoustic signals at the eardrums consist entirely of the direct sound from the sound source.
Reference: [26] <author> B. M. Sayers and E. C. Cherry. </author> <title> "Mechanism of binaural fusion in the hearing of speech". </title> <journal> J. Acoust. Soc. Am., </journal> <volume> 29 </volume> <pages> 973-987, </pages> <year> 1957. </year>
Reference-contexts: Jeffress's model was the precursor of many cross-correlation-based models, including an early one presented by Sayers and Cherry in 1957 <ref> [26] </ref>. One of the many cross-correlation-based models is the one considered by Blauert and Cobben, which employs a running , or short-time cross-correlation that operates on the outputs of band-pass channels intended to model the frequency-analysis function of the cochlea [2].
Reference: [27] <author> E. A. G. Shaw. </author> <title> "Transformation of sound pressure level fron the free field to the eardrum in the horizontal plane". </title> <journal> J. Acoust. Soc. Am., </journal> <volume> 56(6) </volume> <pages> 1848-1861, </pages> <year> 1975. </year>
Reference-contexts: HRTFs vary considerably from person to person, but the types of distortions imparted by the head and pinna follow some general patterns, so meaningful comparisons may be made. Quantitative data on "average" HRTFs and differences between listeners are presented by Shaw in <ref> [27] </ref>. At a given position, the IID and ITD can be extracted as functions of frequency from the complex ratio of the left and right ear HRTFs (i.e., the interaural spectrum).
Reference: [28] <author> R. M. Stern and C. Trahiotis. </author> <title> "The Role of Consistency of Interaural Timing Over Frequency in Binaural Lateralization". </title> <editor> In Y. Cazals, L. Demany, and K. Horner, editors, </editor> <booktitle> Proceedings of the Ninth International Symposium on Auditory Physiology and Perception, </booktitle> <address> Carcans, France. </address> <publisher> Pergamon, Oxford, </publisher> <year> 1991. </year> <month> 61 </month>
Reference-contexts: Most recently, Bodden demonstrated that the model could be used for source separation in a multiple-speaker speech context for sources located in the horizontal plane [3]. Another important lateralization model based on cross-correlation is the one proposed by Stern, Zeiberg, and Trahiotis <ref> [29, 31, 28, 32] </ref>. Their model addresses the issue of combining binaural information across frequency. As in the Blauert/Cobben model, the cross-correlation operator is applied to the outputs of band-pass filters.
Reference: [29] <author> R. M. Stern, A. S. Zeiberg, and C. Trahiotis. </author> <title> "Lateralization of complex binaural stimuli: A weighted-image model". </title> <journal> J. Acoust. Soc. Am., </journal> <volume> 84(1) </volume> <pages> 156-165, </pages> <year> 1988. </year>
Reference-contexts: Most recently, Bodden demonstrated that the model could be used for source separation in a multiple-speaker speech context for sources located in the horizontal plane [3]. Another important lateralization model based on cross-correlation is the one proposed by Stern, Zeiberg, and Trahiotis <ref> [29, 31, 28, 32] </ref>. Their model addresses the issue of combining binaural information across frequency. As in the Blauert/Cobben model, the cross-correlation operator is applied to the outputs of band-pass filters.
Reference: [30] <author> C. W. Therrien. </author> <title> Decision Estimation and Classification. </title> <publisher> John Wiley & Sons, </publisher> <address> New York, NY, </address> <year> 1992. </year>
Reference-contexts: This metric is the Mahalanobis distance between the two stimuli <ref> [30] </ref>. With the position estimator used in this model, we may use this definition of perceptual distance to estimate the localization blur 1 that will be exhibited by the model at various positions.
Reference: [31] <author> C. Trahiotis and R. M. Stern. </author> <title> "Lateralization of bands of noise: Effects of bandwidth and differences of interaural time and phase". </title> <journal> J. Acoust. Soc. Am., </journal> <volume> 86(4) </volume> <pages> 1285-1293, </pages> <year> 1989. </year>
Reference-contexts: Most recently, Bodden demonstrated that the model could be used for source separation in a multiple-speaker speech context for sources located in the horizontal plane [3]. Another important lateralization model based on cross-correlation is the one proposed by Stern, Zeiberg, and Trahiotis <ref> [29, 31, 28, 32] </ref>. Their model addresses the issue of combining binaural information across frequency. As in the Blauert/Cobben model, the cross-correlation operator is applied to the outputs of band-pass filters.
Reference: [32] <author> C. Trahiotis and R. M. Stern. </author> <title> "Across-frequency interaction in lateralization of complex binaural stimuli". </title> <journal> J. Acoust. Soc. Am., </journal> <volume> 96(6) </volume> <pages> 3804-3806, </pages> <year> 1994. </year>
Reference-contexts: Most recently, Bodden demonstrated that the model could be used for source separation in a multiple-speaker speech context for sources located in the horizontal plane [3]. Another important lateralization model based on cross-correlation is the one proposed by Stern, Zeiberg, and Trahiotis <ref> [29, 31, 28, 32] </ref>. Their model addresses the issue of combining binaural information across frequency. As in the Blauert/Cobben model, the cross-correlation operator is applied to the outputs of band-pass filters.
Reference: [33] <author> J. Vanderkooy. </author> <title> "Aspects of MLS Measuring Systems". </title> <journal> J. Audio Eng. Soc., </journal> <volume> 42(4) </volume> <pages> 219-231, </pages> <year> 1994. </year>
Reference-contexts: This property is important, as it allows the impulse response of the system to be obtained by cross-correlation of the measured response with the original noise signal <ref> [25, 33] </ref>. The measurement process is presented in greater detail in [10] and [11]. In total, 710 positions were measured. Test signal synthesis In the absence of reverberation and nearby acoustically reflective objects, the acoustic signals at the eardrums consist entirely of the direct sound from the sound source.
Reference: [34] <author> F. L. Wightman and D. J. Kistler. </author> <title> "Headphone simulation of free-field listening. I: Stimulus Synthesis". </title> <journal> J. Acoust. Soc. Am., </journal> <volume> 85(2) </volume> <pages> 858-867, </pages> <year> 1989. </year>
Reference-contexts: Wightman and Kistler have shown that the information contained in the HRTFs is sufficient to explain localization performance in both azimuth and elevation <ref> [34, 35] </ref>. HRTFs vary considerably from person to person, but the types of distortions imparted by the head and pinna follow some general patterns, so meaningful comparisons may be made. Quantitative data on "average" HRTFs and differences between listeners are presented by Shaw in [27].
Reference: [35] <author> F. L. Wightman and D. J. Kistler. </author> <title> "Headphone simulation of free-field listening. II: Verification". </title> <journal> J. Acoust. Soc. Am., </journal> <volume> 85(2) </volume> <pages> 868-878, </pages> <year> 1989. </year>
Reference-contexts: Wightman and Kistler have shown that the information contained in the HRTFs is sufficient to explain localization performance in both azimuth and elevation <ref> [34, 35] </ref>. HRTFs vary considerably from person to person, but the types of distortions imparted by the head and pinna follow some general patterns, so meaningful comparisons may be made. Quantitative data on "average" HRTFs and differences between listeners are presented by Shaw in [27].
Reference: [36] <author> F. L. Wightman, D. J. Kistler, and M. E. Perkins. </author> <title> "A New Approach to the Study of Human Sound Localization". </title> <editor> In W. A. Yost and G. Gourevitch, editors, </editor> <booktitle> Directional Hearing, chapter 2, </booktitle> <pages> pages 26-48. </pages> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1987. </year>
Reference-contexts: Three such models, however, are the spectral-cue localization model proposed by Zakarauskas and Cynader [38], and the models based on interaural differences proposed by Wight-man, Kistler, and Perkins <ref> [36] </ref> and by Lim and Duda [15]. The model proposed by Zakarauskas and Cynader is based on the extraction of monaural cues from the spectrum received at the eardrum. <p> Both algorithms proceed to estimate the HRTF spectrum that has modified the source spectrum. The model was able to localize sound sources in the median plane with 1 ffi resolution, which is much better than human performance. In <ref> [36] </ref>, the authors summarize a model wherein IID spectrum templates were constructed from HRTF data. Gaussian noise was added to these templates and the results fed to a pattern recognition algorithm in an attempt to determine if sufficient information was available to distinguish position based on the IID spectrum alone.
Reference: [37] <author> R. S. Woodworth. </author> <title> Experimental Psychology. </title> <publisher> Holt, </publisher> <address> New York, </address> <year> 1938. </year>
Reference-contexts: When the IID and ITD are modeled in this way, Woodworth's "cones of confusion" arise <ref> [37] </ref>. For a given set of interaural measurements (IID and ITD), there exists a locus of points for which those measurements are constant. A cone, with axis collinear with the interaural axis, is a fair approximation of this surface.
Reference: [38] <author> P. Zakarauskas and M. S. Cynader. </author> <title> "A computational theory of spectral cue localization". </title> <journal> J. Acoust. Soc. Am., </journal> <volume> 94(3) </volume> <pages> 1323-1331, </pages> <year> 1993. </year>
Reference-contexts: A computational model based on spectral cues is presented by Zakarauskas and Cynader in <ref> [38] </ref>. Localization cues for distance are not particularly well understood. The variation of signal level with distance is one potential cue, but it is useful only in regard to changes or with known source signals. <p> Macpherson includes a simple model of the precedence effect which operates on impulsive signals only. 2.2.2 Azimuth and elevation ("2D" localization) Few efforts have been made to model localization in more than one dimension. Three such models, however, are the spectral-cue localization model proposed by Zakarauskas and Cynader <ref> [38] </ref>, and the models based on interaural differences proposed by Wight-man, Kistler, and Perkins [36] and by Lim and Duda [15]. The model proposed by Zakarauskas and Cynader is based on the extraction of monaural cues from the spectrum received at the eardrum. <p> At present, monaural spectral cues are ignored, because there already exists a localization model based on them <ref> [38] </ref>. It is suggested that a spectral-cue localization model will provide an essential complement to the current model. Cues based on head movements are dismissed because of their relative non-importance ([18]) and because their use in a model precludes the use of prerecorded test signals.
Reference: [39] <author> P. M. Zurek. </author> <title> "The precedence effect and its possible role in the avoidance of interaural ambiguities". </title> <journal> J. Acoust. Soc. Am., </journal> <volume> 67(3) </volume> <pages> 952-964, </pages> <year> 1980. </year>
Reference-contexts: It is not clear how the precedence effect operates across different frequency bands [40]. Quantitative measures of the precedence effect are presented by Zurek in <ref> [39] </ref>, and a model has been proposed which might explain the experimental evidence [40]. The basic form of the model is shown in Figure 2-2. 12 2.2 Previous work on localization models A number of spatial hearing models have been developed. <p> Corresponding curves for the other values of d 0 were not qualitatively different; thus, they have not been included. 5.3 Tests of the precedence effect To test the operation of the precedence effect model, we employed stimuli used by Zurek to quantify the precedence effect in humans <ref> [39] </ref>. In the first experiment, two short noise bursts are presented in succession, the first diotic and the second containing a pure interaural delay or intensity difference. As the delay between the two bursts varied, Zurek measured IID and ITD JNDs in the trailing burst. <p> On a given trial, the trailing burst contained either a pure interaural delay or a pure intensity difference. An in-depth description of the stimuli may be found in <ref> [39] </ref>. In total, stimuli were presented with 11 different inter-burst delays, ranging from 0 to 20 ms. In Zurek's original experiment, JNDs were measured for IID and ITD at each inter-burst delay. <p> The ITD was probed in 25 s increments from 25 s to 325 s, and the IID was probed in 1 dB increments from 1 dB to 15 dB. There were three repetitions of each condition. An in-depth description of the stimuli may be found in <ref> [39] </ref>. As in Experiment 1, the results of this experiment are difficult to interpret. As before, the model was programmed to dismiss IID cues in stimuli used to measure the ITD JND, and vice-versa. As before, the spatial-likelihood map was integrated over elevation to yield a lateralization estimate.
Reference: [40] <author> P. M. Zurek. </author> <title> "The Precedence Effect". </title> <editor> In W. A. Yost and G. Gourevitch, editors, </editor> <booktitle> Directional Hearing, chapter 4, </booktitle> <pages> pages 85-105. </pages> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1987. </year>
Reference-contexts: To that end, an intermediate goal of the current project is to provide a mechanism which simulates the "precedence effect" that is exhibited by human listeners <ref> [40] </ref>. 1.3 An outline of this thesis This is chapter one, the Introduction, which describes the motivation and goals driving the current research. Chapter 2, Background, gives a brief overview of the relevant results in spatial hearing research, particularly in regard to the "cues" used for localization. <p> For evolutionary reasons, it may have been important for localization to be based on the direct sound, which generally reveals the true location of the sound source <ref> [40] </ref>. Regardless of the reason of origin of the precedence effect, it is true that localization cues are weighted more heavily by the auditory system at the onsets of sounds. <p> This temporal weighting has been observed in many contexts, and the phenomenon has been known by many names, including the "precedence effect", the "Haas effect," the "law of the first wavefront," the "first-arrival effect," and the "auditory suppression effect" <ref> [40] </ref>. The precedence effect, as it has just been described, is a relatively short term effect, with changes in weighting operating on a time scale of milliseconds. <p> In contrast to this, it has been shown that localization perception changes on the time scale of hundreds of milliseconds, and localization is fairly robust in the presence of reverberation, which operates on a time scale of thousands of milliseconds <ref> [40] </ref>. The mechanism that causes the precedence effect to occur is not well understood, but it has been demonstrated that it is not the result of forward masking, and that it is not due to the suppression of binaural cues alone. <p> It has also been shown that transients (i.e., sharp changes in energy level) must be present in the sound signal for the precedence effect to occur. It is not clear how the precedence effect operates across different frequency bands <ref> [40] </ref>. Quantitative measures of the precedence effect are presented by Zurek in [39], and a model has been proposed which might explain the experimental evidence [40]. <p> It is not clear how the precedence effect operates across different frequency bands <ref> [40] </ref>. Quantitative measures of the precedence effect are presented by Zurek in [39], and a model has been proposed which might explain the experimental evidence [40]. The basic form of the model is shown in Figure 2-2. 12 2.2 Previous work on localization models A number of spatial hearing models have been developed. Notably, most of them fall into the "one-dimensional localization" category. <p> As mentioned previously, there is evidence that onsets are particularly important portions of the signal for purposes of localization. This is demonstrated by their importance in relation to the precedence effect <ref> [40] </ref>. Extraction method The model searches for energy peaks in the various filter bank channels by looking for maxima in the envelope signals. These "onsets" are found by a simple peak-picking algorithm coupled with a suppression mechanism. <p> The model proposed by Zurek (see Figure 2-2) suggests that a sharp onset should suppress localization information (including other onsets) occurring over approximately the next 10 ms <ref> [40] </ref>. <p> Since the envelope signals are low pass in nature, under-sampling of the cross-correlation function is not an issue. 3.3 Position Estimation 3.3.1 Precedence effect model The precedence effect model is based upon the one proposed by Zurek (see Figure 2-2 and <ref> [40] </ref>). We assume that the inhibition (or suppression) described in the model applies to the localization cues, rather than an actual position estimate. Further, we make the assumption that the inhibition operates independently in the various filter-bank channels. It is unknown whether these assumptions are valid.
Reference: [41] <author> P. M. Zurek. </author> <title> "A note on onset effects in binaural hearing". </title> <journal> J. Acoust. Soc. Am., </journal> <volume> 93(2) </volume> <pages> 1200-1201, </pages> <year> 1993. </year>
Reference-contexts: In this thesis, we further divide the ITD into two components, the interaural phase, or fine-structure, delay (IPD) and the interaural envelope, or gating, delay (IED). It has been shown that humans are sensitive to both types of delay <ref> [41] </ref>.
References-found: 41

