URL: ftp://whitechapel.media.mit.edu/pub/tech-reports/TR-449.ps.Z
Refering-URL: http://www-white.media.mit.edu/cgi-bin/tr_pagemaker/
Root-URL: http://www.media.mit.edu
Title: Recognition using Probabilistic Parsing  
Author: A. F. Bobick and Y. A. Ivanov 
Address: 20 Ames St., Cambridge, MA 02139  
Affiliation: Room E15-383, The Media Laboratory Massachusetts Institute of Technology  
Note: Action  
Abstract: M.I.T Media Laboratory Perceptual Computing Section Technical Report No. 449 Submitted to: IEEE CVPR'98 Abstract A new approach to the recognition of temporal behaviors and activities is presented. The fundamental idea, inspired by work in speech recognition, is to divide the inference problem into two levels. The lower level is performed using standard independent probabilistic temporal event detectors such as hidden Markov models (HMMs) to propose candidate detections of low level temporal features. The outputs of these detectors provide the input stream for a stochastic context-free grammar parsing mechanism. The grammar and parser provide longer range temporal constraints, disambiguate uncertain low level detections, and allow the inclusion of a priori knowledge about the structure of temporal events in a given domain. To achieve such a system we provide techniques for generating a discrete symbol stream from continuous low level detectors, for enforcing temporal exclusion constraints during parsing, and for generating a control method for low level feature application based upon the current parsing state. We demonstrate the approach in several experiments using both visual and other sensing data. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. F. Bobick and A. D. Wilson. </author> <title> A state-based tech nique for the summarization and recognition of gesture. </title> <booktitle> Proc. Int. Conf. Comp. Vis., </booktitle> <year> 1995. </year>
Reference-contexts: In particular, there has been emphasis on activities or behaviors where the entity to be recognized may be considered as a stochastically predictable sequence of states. The greatest number of examples come form work in gesture recognition <ref> [14, 1, 13] </ref> where analogies to speech and handwriting recognition inspired researchers to devise hidden Markov model methods for the classification of gestures.
Reference: [2] <author> Aaron F. Bobick. </author> <title> Movement, activity, and action: The role of knowledge in the perception of motion. </title> <journal> In Philosophical Transactions Royal Society London B, </journal> <year> 1997. </year>
Reference-contexts: 1 Intoduction: stochastic action recognition In the last several years there has been a tremendous growth in the amount of computer vision research aimed at understanding action. As noted by Bobick <ref> [2] </ref> these efforts have ranged from the interpretation of basic movements such as recognizing someone walking or sitting, to the more abstract task of providing a Newtonian physics description of of the motion of several objects.
Reference: [3] <author> M. Brand. </author> <title> Understanding manipulation in video. </title> <booktitle> In AFGR96, </booktitle> <pages> pages 94-99, </pages> <year> 1996. </year>
Reference: [4] <author> J.D. </author> <title> Courtney. Automatic video indexing via object motion analysis. </title> <journal> PR, </journal> <volume> 30(4) </volume> <pages> 607-625, </pages> <month> April </month> <year> 1997. </year>
Reference: [5] <author> T.J. Darrell and A.P. Pentland. </author> <title> Space-time gestures. </title> <booktitle> Proc. Comp. Vis. and Pattern Rec., </booktitle> <pages> pages 335-340, </pages> <year> 1993. </year>
Reference-contexts: At run-time each of these HMMs performs a Viterbi parse ([10]) of the incoming signal and computes the likelihood of the gesture primitive. The run-time algorithm used by the HMMs to recognize the words of the gesture vocabulary is a version of <ref> [5] </ref> which performs a "backward" match of the signal over a window of a reasonable size. At each time step the algorithm outputs the estimated likelihood of the sequence which ends at the current sample as well as the length of this sequence.
Reference: [6] <author> Charniak. E. </author> <title> Statistical Language Learning. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts and London, Eng-land, </address> <year> 1993. </year>
Reference-contexts: Both authors formulate fairly universal events, common to monitoring applications, based on blob interaction primitives. Using combined probabilistic-syntactic approaches to problems of vision is shown in [16] and [7]. Examples of probabilistic parsing in speech processing can be found in literature (eg. <ref> [9, 6] </ref>, etc.). In particular, [15] developing probabilistic extensions to Earley context-free parser is of interest. 3 Probabilistic input formation To recognize the components of the model vocabulary, we train one HMM per atomic gesture.
Reference: [7] <author> K.S. Fu. </author> <title> A step towards unification of syntactic and statistical pattern recognition. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> PAMI 8(3) </volume> <pages> 398-404, </pages> <month> May </month> <year> 1986. </year>
Reference-contexts: Both authors formulate fairly universal events, common to monitoring applications, based on blob interaction primitives. Using combined probabilistic-syntactic approaches to problems of vision is shown in [16] and <ref> [7] </ref>. Examples of probabilistic parsing in speech processing can be found in literature (eg. [9, 6], etc.). In particular, [15] developing probabilistic extensions to Earley context-free parser is of interest. 3 Probabilistic input formation To recognize the components of the model vocabulary, we train one HMM per atomic gesture.
Reference: [8] <author> Yuri Ivanov and Aaron Bobick. </author> <title> Probabilistic parsing in action recognition. </title> <type> Tr 450, </type> <institution> MIT Media Lab, Vision and Modeling Group, </institution> <year> 1997. </year>
Reference-contexts: For complete details refer to [15] and <ref> [8] </ref>. 3 Recursive correction needs to be applied. 3 line shows a possible parse. The two rectangles drawn around samples 2 and 4 show the "spurious symbols" for this parse and which need to be ignored for the derivation to be contiguous.
Reference: [9] <author> F. Jelinek, J.D. Lafferty, and R.L. Mercer. </author> <title> Basic methods of probabilistic context free grammars. </title> <editor> In Pietro Laface and Renato Di Mori, editors, </editor> <booktitle> Speech Recognition and Understanding. Recent Advances, Trends, and Applications, volume F75 of NATO Advanced Study Institute, </booktitle> <pages> pages 345-360. </pages> <publisher> Springer Ver-lag, </publisher> <address> Berlin, </address> <month> July </month> <year> 1992. </year>
Reference-contexts: Both authors formulate fairly universal events, common to monitoring applications, based on blob interaction primitives. Using combined probabilistic-syntactic approaches to problems of vision is shown in [16] and [7]. Examples of probabilistic parsing in speech processing can be found in literature (eg. <ref> [9, 6] </ref>, etc.). In particular, [15] developing probabilistic extensions to Earley context-free parser is of interest. 3 Probabilistic input formation To recognize the components of the model vocabulary, we train one HMM per atomic gesture.
Reference: [10] <author> L. R. Rabiner and B. H. Juang. </author> <title> Fundamentals of speech recognition. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, </address> <year> 1993. </year>
Reference: [11] <author> Max Rudolf. </author> <title> The Grammar of Conducting. A Com prehensive Guide to Baton Techniques and Interpretation. </title> <publisher> Schimmer Books, </publisher> <address> New York, </address> <year> 1994. </year> <month> 6 </month>
Reference-contexts: It is easy to think of conducting gestures as of complex gestures consisting of a combination of simpler parts, for which we can write down a grammar (coincidentally, a book describing baton techniques, written by a famous conductor Max Rudolf <ref> [11] </ref> is called "The Grammar of Conducting"). We capture the data from a person, who is a trained conductor and who uses natural conducting gestures. The task we are attempting to solve is the following.
Reference: [12] <author> Robert Schalkoff. </author> <title> Pattern Recognition: Statistical, Structural and Neural Approaches. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1992. </year>
Reference-contexts: A review of syntactic pattern recognition and related methods can be found in <ref> [12] </ref>. There are many examples of attempts to enforce semantic constraints in recognition of visual data. For instance, Courtney ([4]) uses structural approach to interpreting action in surveillance setting.
Reference: [13] <author> J. Schlenzig, E. Hunter, and R. Jain. </author> <title> Recursive iden tification of gesture inputs using hidden markov models. </title> <booktitle> Proc. Second Annual Conference on Applications of Computer Vision, </booktitle> <pages> pages 187-194, </pages> <month> December </month> <year> 1994. </year>
Reference-contexts: In particular, there has been emphasis on activities or behaviors where the entity to be recognized may be considered as a stochastically predictable sequence of states. The greatest number of examples come form work in gesture recognition <ref> [14, 1, 13] </ref> where analogies to speech and handwriting recognition inspired researchers to devise hidden Markov model methods for the classification of gestures.
Reference: [14] <author> T. E. Starner and A. Pentland. </author> <title> Visual recognition of American Sign Language using hidden markov models. </title> <booktitle> In Proc. of the Intl. Workshop on Automatic Face-and Gesture-Recognition, </booktitle> <address> Zurich, </address> <year> 1995. </year>
Reference-contexts: In particular, there has been emphasis on activities or behaviors where the entity to be recognized may be considered as a stochastically predictable sequence of states. The greatest number of examples come form work in gesture recognition <ref> [14, 1, 13] </ref> where analogies to speech and handwriting recognition inspired researchers to devise hidden Markov model methods for the classification of gestures.
Reference: [15] <author> A. Stolcke. </author> <title> Bayesian Learning of Probabilistic Lan guage Models. </title> <type> PhD thesis, </type> <institution> University of California at Berkeley, </institution> <year> 1994. </year>
Reference-contexts: Both authors formulate fairly universal events, common to monitoring applications, based on blob interaction primitives. Using combined probabilistic-syntactic approaches to problems of vision is shown in [16] and [7]. Examples of probabilistic parsing in speech processing can be found in literature (eg. [9, 6], etc.). In particular, <ref> [15] </ref> developing probabilistic extensions to Earley context-free parser is of interest. 3 Probabilistic input formation To recognize the components of the model vocabulary, we train one HMM per atomic gesture. <p> For complete details refer to <ref> [15] </ref> and [8]. 3 Recursive correction needs to be applied. 3 line shows a possible parse. The two rectangles drawn around samples 2 and 4 show the "spurious symbols" for this parse and which need to be ignored for the derivation to be contiguous.
Reference: [16] <author> W. G. Tsai and K. S. Fu. </author> <title> Attributed grammars a tool for combining syntatctic and statistical approaches to pattern recognition. </title> <journal> In IEEE Transactions on Systems, Man and Cybernetics, volume SMC-10, </journal> <volume> number 12, </volume> <pages> pages 873-885, </pages> <year> 1980. </year>
Reference-contexts: Grammatical approach to visual data recognition was used by Brand ([3]), who uses a simple non-stochastic grammar to recognize sequences of discrete events. Both authors formulate fairly universal events, common to monitoring applications, based on blob interaction primitives. Using combined probabilistic-syntactic approaches to problems of vision is shown in <ref> [16] </ref> and [7]. Examples of probabilistic parsing in speech processing can be found in literature (eg. [9, 6], etc.).
Reference: [17] <author> Christopher Wren, Ali Azarbayejani, Trevor Darrell, and Alex Pentland. Pfinder: </author> <title> Real-time tracking of the human body. </title> <journal> IEEE Trans. Pattern Analysis and Machine Intelligence, </journal> <volume> 19(7) </volume> <pages> 780-785, </pages> <month> July </month> <year> 1997. </year> <month> 7 </month>
Reference-contexts: for simplicity: G square : SQUARE ! RH [0:5] j LH [0:5] LH ! BOT DU TOP UD [1:0] j RL [0:5] j LR [0:5] LR ! left-right [1:0] UD ! up-down [1:0] RL ! right-left [1:0] DU ! down-up [1:0] We receive input data from a "Stive" vision system <ref> [17] </ref>, shown in figure 5. The system uses stereo algorithms to determine x-y-z position of person's hands and head. At a frame rate of approximately 20 frames a second, the "Square" data set consists of 150 - 200 samples for each experiment.
References-found: 17

