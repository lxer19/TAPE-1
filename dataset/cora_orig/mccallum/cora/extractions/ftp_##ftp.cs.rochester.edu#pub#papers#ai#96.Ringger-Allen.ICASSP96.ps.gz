URL: ftp://ftp.cs.rochester.edu/pub/papers/ai/96.Ringger-Allen.ICASSP96.ps.gz
Refering-URL: http://www.cs.rochester.edu/u/ringger/research/icassp-96.html
Root-URL: 
Email: fringger, jamesg@cs.rochester.edu  
Title: ERROR CORRECTION VIA A POST-PROCESSOR FOR CONTINUOUS SPEECH RECOGNITION  
Author: Eric K. Ringger James F. Allen 
Address: Rochester; Rochester, New York 14627-0226  
Affiliation: Department of Computer Science; University of  
Abstract: This paper presents a new technique for overcoming several types of speech recognition errors by post-processing the output of a continuous speech recognizer. The post-processor output contains fewer errors, thereby making interpretation by higher-level modules, such as a parser, in a speech understanding system more reliable. The primary advantage to the post-processing approach over existing approaches for overcoming SR errors lies in its ability to introduce options that are not available in the SR module's output. This work provides evidence for the claim that a modern continuous speech recognizer can be used successfully in "black-box" fashion for robustly interpreting spontaneous utterances in a dialogue with a human. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. F. Allen, G. Ferguson, B. Miller, and E. Ringger. </author> <title> Spoken Dialogue and Interactive Planning. </title> <booktitle> In Proceedings of the ARPA SLST Workshop, </booktitle> <address> San Mateo Cali-fornia, </address> <month> January </month> <year> 1995. </year> <title> ARPA, </title> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Even state of the art recognizers such as Sphinx-II [7] 1 and a recognizer built using HTK [14] 2 achieve less than 60% word accuracy on fluent speech collected from conversations about a specific problem with the Trains-95 system <ref> [1] </ref>. Here are a few examples of the kinds of errors that occur when recognizing spontaneous utterances.
Reference: [2] <author> L. R. Bahl, F. Jelinek, and R. Mercer. </author> <title> A Maximum Likelihood Approach to Continuous Speech Recognition. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI), </journal> <volume> 5(2) </volume> <pages> 179-190, </pages> <month> March </month> <year> 1983. </year>
Reference-contexts: By applying Bayes' rule, we derive a simple expression for the most likely pre-channel sequence ^e 1;n . The derivation is similar to the derivation of the statistical approach to SR (as explained in <ref> [2, 8] </ref>): ^e 1;n = argmax e 1;n 0 The first factor, P [e 1;n ], models the formation of English utterances by the speaker. It is the listener's model of the speaker's language.
Reference: [3] <author> P. F. Brown, J. Cocke, S. A. Della Pietra, V. J. Della Pietra, F. Jelinek, J. D. Lafferty, R. L. Mercer, and P. S. Roossin. </author> <title> A Statistical Approach to Machine Translation. </title> <journal> Computational Linguistics, </journal> <volume> 16(2) </volume> <pages> 79-85, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: Existing rescoring tactics cannot do so (c.f. [4, 12]). 2. THE MODELS AND ALGORITHM A statistical model for automatically translating individual sentences between two human languages was proposed by Brown et al. <ref> [3] </ref>. While this approach to translation has its critics, we can adapt the same idea to the process of transcribing a spoken utterance.
Reference: [4] <author> Y. Chow and R. Schwartz. </author> <title> The n-best algorithm: An efficient procedure for finding top n sentence hypotheses. </title> <booktitle> In Proceedings of the Second DARPA Workshop on Speech and Natural Language, </booktitle> <pages> pages 199-202, </pages> <address> San Ma-teo, California, </address> <month> October </month> <year> 1989. </year> <title> DARPA, </title> <publisher> Morgan Kauf-mann. </publisher>
Reference-contexts: Such errors can be corrected by the post-processing techniques discussed here. Finally, the primary advantage to the post-processing approach over existing approaches for overcoming SR errors lies in its ability to introduce options that are not available in the SR module's output. Existing rescoring tactics cannot do so (c.f. <ref> [4, 12] </ref>). 2. THE MODELS AND ALGORITHM A statistical model for automatically translating individual sentences between two human languages was proposed by Brown et al. [3]. While this approach to translation has its critics, we can adapt the same idea to the process of transcribing a spoken utterance.
Reference: [5] <author> J. G. E. Forney. </author> <title> The Viterbi Algorithm. </title> <booktitle> In Proceedings of IEEE, </booktitle> <volume> volume 61, </volume> <pages> pages 266-278. </pages> <publisher> IEEE, </publisher> <year> 1973. </year>
Reference-contexts: We use a Viterbi beam search for this purpose (c.f. <ref> [5, 11] </ref>). 2.2. Enhancements to the Models To improve the language model, we use higher-order n-grams, thereby assuming that each word in e 1;n is dependent on its n 1 predecessors. We also use back-off n-gram models for combating the problem of sparse training data [9].
Reference: [6] <author> P. Heeman and J. F. Allen. </author> <title> The Trains 93 Dialogues. </title> <type> Trains Technical Note 94-2, </type> <institution> Department of Computer Science, University of Rochester, Rochester, </institution> <address> NY, 14627, </address> <month> March </month> <year> 1995. </year>
Reference-contexts: Hence, some of the error is attributable to the moderate occurrence of out-of-vocabulary (OOV) words. 2 For this experiment involving the HTK-based recognizer, the acoustic model and the word-based language model were trained on the Trains Dialogue Corpus <ref> [6] </ref> (collected prior to the creation of the Trains-95 system). 3 In the examples, the HYP tag indicates the SR system's hypothesis, and the REF tag indicates the reference transcription.
Reference: [7] <author> X. D. Huang, F. Alleva, H. W. Hon, M. Y. Hwang, K. F. Lee, and R. Rosenfeld. </author> <title> The Sphinx-II Speech Recognition System: An Overview. </title> <booktitle> Computer, Speech and Language, </booktitle> <year> 1993. </year>
Reference-contexts: 1. INTRODUCTION Existing methods for continuous speech recognition do not perform as well on spontaneous speech as we would hope. Even state of the art recognizers such as Sphinx-II <ref> [7] </ref> 1 and a recognizer built using HTK [14] 2 achieve less than 60% word accuracy on fluent speech collected from conversations about a specific problem with the Trains-95 system [1]. Here are a few examples of the kinds of errors that occur when recognizing spontaneous utterances.
Reference: [8] <author> F. Jelinek. </author> <title> Self-Organized Language Modeling for Speech Recognition. </title> <booktitle> Reprinted in [13]: </booktitle> <pages> 450-506, </pages> <year> 1990. </year>
Reference-contexts: By applying Bayes' rule, we derive a simple expression for the most likely pre-channel sequence ^e 1;n . The derivation is similar to the derivation of the statistical approach to SR (as explained in <ref> [2, 8] </ref>): ^e 1;n = argmax e 1;n 0 The first factor, P [e 1;n ], models the formation of English utterances by the speaker. It is the listener's model of the speaker's language.
Reference: [9] <author> S. M. Katz. </author> <title> Estimation of probabilities from sparse data for the language model component of a speech rec-ognizer. </title> <booktitle> In IEEE Transactions on Acoustics, Speech, and Signal Processing, </booktitle> <pages> pages 400-401. </pages> <publisher> IEEE, IEEE, </publisher> <month> March </month> <year> 1987. </year>
Reference-contexts: Enhancements to the Models To improve the language model, we use higher-order n-grams, thereby assuming that each word in e 1;n is dependent on its n 1 predecessors. We also use back-off n-gram models for combating the problem of sparse training data <ref> [9] </ref>. For the channel model, we relax the constraint that replacement errors be aligned on a word by word basis, since not all recognition errors consist of simple replacement of 2 one word by another. Some errors appear as the break-up of one word into shorter words.
Reference: [10] <author> K.-F. Lee. </author> <title> Automatic Speech Recognition: the Development of the SPHINX System. </title> <publisher> Kluwer Academic, </publisher> <address> Boston, London, </address> <year> 1989. </year>
Reference-contexts: This suggests that the SR module does indeed belong as a component of the noisy channel. One poorly modeled phenomenon is assimilation of phonetic features. Most SR engines model phonemes in a context-dependent fashion (e.g., see <ref> [10] </ref>), and some attempt to model cross-word co-articulation effects (c.f. [10] also). However, as speaking speeds vary, the SR's models may not be well suited to the affected speech signal. Such errors can be corrected by the post-processing techniques discussed here. <p> This suggests that the SR module does indeed belong as a component of the noisy channel. One poorly modeled phenomenon is assimilation of phonetic features. Most SR engines model phonemes in a context-dependent fashion (e.g., see <ref> [10] </ref>), and some attempt to model cross-word co-articulation effects (c.f. [10] also). However, as speaking speeds vary, the SR's models may not be well suited to the affected speech signal. Such errors can be corrected by the post-processing techniques discussed here.
Reference: [11] <author> B. Lowerre and R. Reddy. </author> <title> The Harpy Speech Understanding System. In Trends in Speech Recognition. </title> <institution> Speech Science Publications, Apple Valley, Minnesota, </institution> <year> 1986. </year> <note> Reprinted in [13]: 576-586. </note>
Reference-contexts: We use a Viterbi beam search for this purpose (c.f. <ref> [5, 11] </ref>). 2.2. Enhancements to the Models To improve the language model, we use higher-order n-grams, thereby assuming that each word in e 1;n is dependent on its n 1 predecessors. We also use back-off n-gram models for combating the problem of sparse training data [9].
Reference: [12] <author> M. Rayner, D. Carter, V. Digalakis, and P. Price. </author> <title> Combining Knowledge Sources to Reorder N -best Speech Hypothesis Lists. </title> <booktitle> In Proceedings ARPA Human Language Technology Workshop, </booktitle> <pages> pages 212-217. ARPA, </pages> <month> March </month> <year> 1994. </year>
Reference-contexts: Such errors can be corrected by the post-processing techniques discussed here. Finally, the primary advantage to the post-processing approach over existing approaches for overcoming SR errors lies in its ability to introduce options that are not available in the SR module's output. Existing rescoring tactics cannot do so (c.f. <ref> [4, 12] </ref>). 2. THE MODELS AND ALGORITHM A statistical model for automatically translating individual sentences between two human languages was proposed by Brown et al. [3]. While this approach to translation has its critics, we can adapt the same idea to the process of transcribing a spoken utterance.
Reference: [13] <author> A. Waibel and K.-F. Lee, </author> <title> editors. Readings in Speech Recognition. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, </address> <year> 1990. </year>
Reference: [14] <author> S. J. Young and P. C. Woodland. </author> <title> HTK: Hidden Markov Model Toolkit. </title> <institution> Entropic Research Laboratory, </institution> <address> Wash-ington, D.C., </address> <year> 1993. </year> <month> 4 </month>
Reference-contexts: 1. INTRODUCTION Existing methods for continuous speech recognition do not perform as well on spontaneous speech as we would hope. Even state of the art recognizers such as Sphinx-II [7] 1 and a recognizer built using HTK <ref> [14] </ref> 2 achieve less than 60% word accuracy on fluent speech collected from conversations about a specific problem with the Trains-95 system [1]. Here are a few examples of the kinds of errors that occur when recognizing spontaneous utterances.
References-found: 14

