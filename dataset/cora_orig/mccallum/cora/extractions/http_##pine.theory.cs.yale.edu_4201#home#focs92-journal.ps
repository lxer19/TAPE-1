URL: http://pine.theory.cs.yale.edu:4201/home/focs92-journal.ps
Refering-URL: http://pine.theory.cs.yale.edu:4201/home/focs92-abstract.html
Root-URL: http://www.cs.yale.edu
Title: RANDOMIZED CONSENSUS IN EXPECTED O(N log 2 N) OPERATIONS PER PROCESSOR  
Author: JAMES ASPNES AND ORLI WAARTS 
Abstract: This paper presents a new randomized algorithm for achieving consensus among asynchronous processors that communicate by reading and writing shared registers. The fastest previously known algorithm requires a processor to perform an expected O(n 2 log n) read and write operations in the worst case. In our algorithm, each processor executes at most an expected O(n log 2 n) read and write operations, which is close to the trivial lower bound of (n). All previously known polynomial-time consensus algorithms were structured around a shared coin protocol [4] in which each processor repeatedly adds random 1 votes to a common pool. Consequently, in all of these protocols, the worst case expected bound on the number of read and write operations done by a single processor is asymptotically no better than the bound on the total number of read and write operations done by all of the processors together. We succeed in breaking this tradition by allowing the processors to cast votes of increasing weights. This grants the adversary greater control since he can choose from up to n different weights (one for each processor) when determining the weight of the next vote to be cast. We prove that our shared coin protocol is correct nevertheless using martingale arguments. 1
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> K. Abrahamson, </author> <title> On achieving consensus using a shared memory, </title> <booktitle> in Proceedings of the Seventh ACM SIGACT-SIGOPS Symposium on Principles of Distributed Computing, </booktitle> <month> Aug. </month> <year> 1988, </year> <pages> pp. 291-302. </pages>
Reference-contexts: Chor, Israeli, and Li [10] provided the first solution to the problem, but their solution deviated from the standard model by assuming that the processor can flip a coin and write the result in a single atomic step. Abrahamson <ref> [1] </ref> demonstrated that consensus is possible even for the standard model, but his protocol required an exponential expected number of steps. Since then a number of polynomial-work consensus protocols have been proposed.
Reference: [2] <author> N. Alon and J. H. Spencer, </author> <title> The Probabilistic Method, </title> <publisher> John Wiley and Sons, </publisher> <year> 1992. </year>
Reference-contexts: If we are interested only in the tails of the distribution of S n , we can get a tighter bound using Azuma's inequality, a martingale analogue of the standard Chernoff bound [9] for sums of independent random variables. The usual form of this bound (see <ref> [2, 25] </ref>) assumes that the difference variables X i satisfy jX i j 1. This restriction is too severe for our purposes, so below we prove a generalization of the inequality. In order to do so we will need the following technical lemma. Lemma 4.4.
Reference: [3] <author> J. Aspnes, </author> <title> Time- and space-efficient randomized consensus, </title> <journal> Journal of Algorithms, </journal> <volume> 14 (1993), </volume> <pages> pp. 414-431. </pages>
Reference-contexts: Protocols that use bounded registers have been proposed by Attiya, Dolev, and Shavit [5] (running time O (n 3 )), by Aspnes <ref> [3] </ref> (running time O (n 2 (p 2 + n)), where p is the number of active processors), by Bracha and Rachman [7] (running time O (n (p 2 + n))), and by Dwork, Herlihy, Plotkin and Waarts [13] (immediate application of what they call time-lapse snapshots and with the same <p> The rest of the paper is organized as follows. The next section describes the intuition behind our solution while emphasizing the main difference between our solution and that in <ref> [3, 4, 5, 7, 8, 13, 24] </ref>. Section 3 describes our shared coin protocol. Section 4 reviews martingales and derives some of their properties. Section 5 contains the proof of correctness of our shared coin protocol. A discussion of the results appears in Section 6. 2. <p> The underlying technique for building a weak shared coin has not changed substantially since the protocol described in [4]; each processor repeatedly adds random 1 votes to a common pool until either the total vote is far from the origin <ref> [3, 4, 5, 7, 13] </ref> or until a predetermined number of votes have been cast [8, 24]. <p> There are two main difficulties that this approach entails; the first is that careful 4 The term agreement parameter was first used by Saks et al [24] in place of the more melodramatic but less descriptive term defiance probability of Aspnes and Herlihy [4]. Aspnes <ref> [3] </ref> used a bias parameter, equal to 1=2 minus the agreement parameter; however, this quantity is not as useful as the agreement parameter in the context of a multi-round consensus protocol. 3 1 procedure shared coin () 2 begin 3 my reg (variance; vote) (0; 0) 4 t 1 5 repeat <p> Shared coin protocol. adjustment of the weight function and other parameters of the protocol is necessary to make sure that it performs correctly. More importantly, correctness proofs for previous shared coins based on random walks or voting <ref> [3, 4, 5, 7, 8, 13, 24] </ref> considered only equally weighted votes, and have therefore been able to treat the sequence of votes as a sequence of independent random variables using a substitution argument.
Reference: [4] <author> J. Aspnes and M. Herlihy, </author> <title> Fast randomized consensus using shared memory, </title> <journal> Journal of Algorithms, </journal> <volume> 11 (1990), </volume> <pages> pp. 441-461. </pages>
Reference-contexts: Abrahamson [1] demonstrated that consensus is possible even for the standard model, but his protocol required an exponential expected number of steps. Since then a number of polynomial-work consensus protocols have been proposed. Protocols that use unbounded registers have been proposed by Aspnes and Herlihy <ref> [4] </ref> (the first polynomial-time algorithm), by Saks, Shavit, and Woll [24] (optimized for the case where processors run in lock step), and by Bracha and Rachman [8] (running time O (n 2 log n)). <p> of all currently known wait-free consensus protocols, obtaining a protocol in which a processor executes at most an expected O (n log 2 n) read and write operations, which is close to the trivial lower bound of (n). 2 To do this we introduce a new weak shared coin protocol <ref> [4] </ref> that is based on a combination of the shared coin protocol described by Bracha and Rachman [8] and a new technique called weighted voting, where votes of faster processors carry more weight. 3 We believe that our weighted voting technique will find applications in other wait-free shared memory problems such <p> The rest of the paper is organized as follows. The next section describes the intuition behind our solution while emphasizing the main difference between our solution and that in <ref> [3, 4, 5, 7, 8, 13, 24] </ref>. Section 3 describes our shared coin protocol. Section 4 reviews martingales and derives some of their properties. Section 5 contains the proof of correctness of our shared coin protocol. A discussion of the results appears in Section 6. 2. <p> value 2 As discussed in Section 6, this gain in per-processor performance involves a slight increase in the total work performed by all processors when compared with the Bracha-Rachman protocol. 3 The consensus protocol can be constructed around our shared coin protocol using the established techniques of Aspnes and Herlihy <ref> [4] </ref>. 2 b 2 f0; 1g the probability that all processors see b must be at least a constant ffi (the agreement parameter of the coin), regardless of scheduler behavior. 4 Aspnes and Herlihy [4] showed that given a weak shared coin with constant agreement parameter it is possible to construct <p> can be constructed around our shared coin protocol using the established techniques of Aspnes and Herlihy <ref> [4] </ref>. 2 b 2 f0; 1g the probability that all processors see b must be at least a constant ffi (the agreement parameter of the coin), regardless of scheduler behavior. 4 Aspnes and Herlihy [4] showed that given a weak shared coin with constant agreement parameter it is possible to construct a consensus protocol by executing the coin repeatedly within a rounds-based framework which detects agreement. <p> So to construct a fast consensus protocol one need only construct a fast weak shared coin. The underlying technique for building a weak shared coin has not changed substantially since the protocol described in <ref> [4] </ref>; each processor repeatedly adds random 1 votes to a common pool until either the total vote is far from the origin [3, 4, 5, 7, 13] or until a predetermined number of votes have been cast [8, 24]. <p> The underlying technique for building a weak shared coin has not changed substantially since the protocol described in [4]; each processor repeatedly adds random 1 votes to a common pool until either the total vote is far from the origin <ref> [3, 4, 5, 7, 13] </ref> or until a predetermined number of votes have been cast [8, 24]. <p> There are two main difficulties that this approach entails; the first is that careful 4 The term agreement parameter was first used by Saks et al [24] in place of the more melodramatic but less descriptive term defiance probability of Aspnes and Herlihy <ref> [4] </ref>. <p> Shared coin protocol. adjustment of the weight function and other parameters of the protocol is necessary to make sure that it performs correctly. More importantly, correctness proofs for previous shared coins based on random walks or voting <ref> [3, 4, 5, 7, 8, 13, 24] </ref> considered only equally weighted votes, and have therefore been able to treat the sequence of votes as a sequence of independent random variables using a substitution argument. <p> The consensus protocol can then be constructed around it using the established techniques of Aspnes and Herlihy <ref> [4] </ref> with only a constant-factor increase in the number of operations done by each processor. 9 This work leads to several interesting questions. First, our voting scheme implicitly gives higher priority to operations done by processors that have already performed many operations.
Reference: [5] <author> H. Attiya, D. Dolev, and N. Shavit, </author> <title> Bounded polynomial randomized consensus, </title> <booktitle> in Proceedings of the Eighth ACM Symposium on Principles of Distributed Computing, </booktitle> <month> Aug. </month> <year> 1989, </year> <pages> pp. 281-294. </pages>
Reference-contexts: Protocols that use bounded registers have been proposed by Attiya, Dolev, and Shavit <ref> [5] </ref> (running time O (n 3 )), by Aspnes [3] (running time O (n 2 (p 2 + n)), where p is the number of active processors), by Bracha and Rachman [7] (running time O (n (p 2 + n))), and by Dwork, Herlihy, Plotkin and Waarts [13] (immediate application of <p> The rest of the paper is organized as follows. The next section describes the intuition behind our solution while emphasizing the main difference between our solution and that in <ref> [3, 4, 5, 7, 8, 13, 24] </ref>. Section 3 describes our shared coin protocol. Section 4 reviews martingales and derives some of their properties. Section 5 contains the proof of correctness of our shared coin protocol. A discussion of the results appears in Section 6. 2. <p> The underlying technique for building a weak shared coin has not changed substantially since the protocol described in [4]; each processor repeatedly adds random 1 votes to a common pool until either the total vote is far from the origin <ref> [3, 4, 5, 7, 13] </ref> or until a predetermined number of votes have been cast [8, 24]. <p> Shared coin protocol. adjustment of the weight function and other parameters of the protocol is necessary to make sure that it performs correctly. More importantly, correctness proofs for previous shared coins based on random walks or voting <ref> [3, 4, 5, 7, 8, 13, 24] </ref> considered only equally weighted votes, and have therefore been able to treat the sequence of votes as a sequence of independent random variables using a substitution argument.
Reference: [6] <author> P. Billingsley, </author> <title> Probability and Measure, </title> <publisher> John Wiley and Sons, </publisher> <editor> second ed., </editor> <year> 1986. </year>
Reference-contexts: However, the sign of each vote is determined by a fair coin flip that the scheduler cannot predict in advance, and so despite all the scheduler's powers, the expected value of each vote before it is cast is always 0. This is the primary requirement of a martingale process <ref> [6, 15, 21] </ref>. Under the right conditions, martingales have many similarities to sequences of sums of independent random variables. In particular, martingale analogues of the Central Limit Theorem and Chernoff bounds will be used in the proof of correctness. 3. The Shared Coin Protocol. <p> But because the casino is fair and the gambler cannot predict the future, the expected change in the gambler's fortune at any play is always 0. We will need to use a very general definition of a martingale <ref> [6, 15, 21] </ref>. The simplest definition of a martingale says that the expected value of S i+1 given S 1 ; S 2 ; : : : ; S i is just S i . <p> The tool used to represent the information known at any point in time will be a concept from measure theory, a -algebra. 6 The description given here is informal; more complete definitions can be found in [15, Sections IV.3, IV.4, and V.11] or <ref> [6] </ref>. 4.1. Knowledge, -algebras, and measurability. Recall that any probabilistic statement is always made in the context of some (possibly implicit) sample space.
Reference: [7] <author> G. Bracha and O. Rachman, </author> <title> Approximated counters and randomized consensus, </title> <type> Tech. Report 662, </type> <institution> Technion, </institution> <year> 1990. </year> <title> [8] , Randomized consensus in expected O(n 2 log n) operations, </title> <booktitle> in Proceedings of the Fifth International Workshop on Distributed Algorithms, </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1991. </year>
Reference-contexts: Protocols that use bounded registers have been proposed by Attiya, Dolev, and Shavit [5] (running time O (n 3 )), by Aspnes [3] (running time O (n 2 (p 2 + n)), where p is the number of active processors), by Bracha and Rachman <ref> [7] </ref> (running time O (n (p 2 + n))), and by Dwork, Herlihy, Plotkin and Waarts [13] (immediate application of what they call time-lapse snapshots and with the same running time as [7]). <p> (n 2 (p 2 + n)), where p is the number of active processors), by Bracha and Rachman <ref> [7] </ref> (running time O (n (p 2 + n))), and by Dwork, Herlihy, Plotkin and Waarts [13] (immediate application of what they call time-lapse snapshots and with the same running time as [7]). The main goal of a wait-free algorithm is usually to minimize the worst case expected bound on the work done by a single processor. <p> The rest of the paper is organized as follows. The next section describes the intuition behind our solution while emphasizing the main difference between our solution and that in <ref> [3, 4, 5, 7, 8, 13, 24] </ref>. Section 3 describes our shared coin protocol. Section 4 reviews martingales and derives some of their properties. Section 5 contains the proof of correctness of our shared coin protocol. A discussion of the results appears in Section 6. 2. <p> The underlying technique for building a weak shared coin has not changed substantially since the protocol described in [4]; each processor repeatedly adds random 1 votes to a common pool until either the total vote is far from the origin <ref> [3, 4, 5, 7, 13] </ref> or until a predetermined number of votes have been cast [8, 24]. <p> Shared coin protocol. adjustment of the weight function and other parameters of the protocol is necessary to make sure that it performs correctly. More importantly, correctness proofs for previous shared coins based on random walks or voting <ref> [3, 4, 5, 7, 8, 13, 24] </ref> considered only equally weighted votes, and have therefore been able to treat the sequence of votes as a sequence of independent random variables using a substitution argument.
Reference: [9] <author> H. Chernoff, </author> <title> A measure of asymptotic efficiency for tests of a hypothesis based on the sum of observations, </title> <journal> Annals of Mathematical Statistics, </journal> <volume> 23 (1952), </volume> <pages> pp. 493-407. </pages>
Reference-contexts: If we are interested only in the tails of the distribution of S n , we can get a tighter bound using Azuma's inequality, a martingale analogue of the standard Chernoff bound <ref> [9] </ref> for sums of independent random variables. The usual form of this bound (see [2, 25]) assumes that the difference variables X i satisfy jX i j 1. This restriction is too severe for our purposes, so below we prove a generalization of the inequality.
Reference: [10] <author> B. Chor, A. Israeli, and M. Li, </author> <title> Wait-free consensus using asynchronous hardware., </title> <journal> SIAM Journal on Computing, </journal> <volume> 23 (1994), </volume> <pages> pp. 701-712. </pages> <booktitle> Preliminary version appears in Proceedings of the 6th ACM SIGACT-SIGOPS Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 86-97, </pages> <year> 1987. </year>
Reference-contexts: of this work appeared in the proceedings of the Thirty-Third IEEE Sym posium on Foundations of Computer Science. 1 by interleaving.) Remarkably, it has been shown that the ability of the scheduler to stop even a single processor is sufficient to prevent consensus from being solved by a deterministic algorithm <ref> [10, 12, 16, 20, 22] </ref>. Nevertheless, it can be solved by randomized protocols in which each processor is guaranteed to decide after a finite expected number of steps. <p> Nevertheless, it can be solved by randomized protocols in which each processor is guaranteed to decide after a finite expected number of steps. Chor, Israeli, and Li <ref> [10] </ref> provided the first solution to the problem, but their solution deviated from the standard model by assuming that the processor can flip a coin and write the result in a single atomic step.
Reference: [11] <author> B. Chor and L. Moscovici, </author> <title> Solvability in asynchronous environments, </title> <booktitle> in 30th Annual Symposium on Foundations of Computer Science, </booktitle> <month> Oct. </month> <year> 1989, </year> <pages> pp. 422-427. </pages>
Reference-contexts: It can be used to obtain wait-free implementations of arbitrary abstract data types with atomic operations [20, 23]. Consensus is also complete for distributed decision tasks <ref> [11] </ref> in the sense that it can be used to solve all such tasks that have a wait-free solution. Consensus is often viewed as a game played between a set of processors and an adversary scheduler.
Reference: [12] <author> D. Dolev, C. Dwork, and L. Stockmeyer, </author> <title> On the minimal synchronism needed for distributed consensus, </title> <journal> J. Assoc. Comput. Mach., </journal> <volume> 34 (1987), </volume> <pages> pp. 77-97. </pages>
Reference-contexts: of this work appeared in the proceedings of the Thirty-Third IEEE Sym posium on Foundations of Computer Science. 1 by interleaving.) Remarkably, it has been shown that the ability of the scheduler to stop even a single processor is sufficient to prevent consensus from being solved by a deterministic algorithm <ref> [10, 12, 16, 20, 22] </ref>. Nevertheless, it can be solved by randomized protocols in which each processor is guaranteed to decide after a finite expected number of steps.
Reference: [13] <author> C. Dwork, M. Herlihy, S. Plotkin, and O. Waarts, </author> <title> Time-lapse snapshots, </title> <booktitle> in Proceedings of Israel Symposium on the Theory of Computing and Systems, </booktitle> <year> 1992. </year>
Reference-contexts: Dolev, and Shavit [5] (running time O (n 3 )), by Aspnes [3] (running time O (n 2 (p 2 + n)), where p is the number of active processors), by Bracha and Rachman [7] (running time O (n (p 2 + n))), and by Dwork, Herlihy, Plotkin and Waarts <ref> [13] </ref> (immediate application of what they call time-lapse snapshots and with the same running time as [7]). The main goal of a wait-free algorithm is usually to minimize the worst case expected bound on the work done by a single processor. <p> The rest of the paper is organized as follows. The next section describes the intuition behind our solution while emphasizing the main difference between our solution and that in <ref> [3, 4, 5, 7, 8, 13, 24] </ref>. Section 3 describes our shared coin protocol. Section 4 reviews martingales and derives some of their properties. Section 5 contains the proof of correctness of our shared coin protocol. A discussion of the results appears in Section 6. 2. <p> The underlying technique for building a weak shared coin has not changed substantially since the protocol described in [4]; each processor repeatedly adds random 1 votes to a common pool until either the total vote is far from the origin <ref> [3, 4, 5, 7, 13] </ref> or until a predetermined number of votes have been cast [8, 24]. <p> Shared coin protocol. adjustment of the weight function and other parameters of the protocol is necessary to make sure that it performs correctly. More importantly, correctness proofs for previous shared coins based on random walks or voting <ref> [3, 4, 5, 7, 8, 13, 24] </ref> considered only equally weighted votes, and have therefore been able to treat the sequence of votes as a sequence of independent random variables using a substitution argument.
Reference: [14] <author> C. Dwork, M. Herlihy, and O. Waarts, </author> <title> Bounded round numbers, </title> <booktitle> in Proceedings of the 12th ACM SIGACT-SIGOPS Symposium on Principles of Distributed Computing, </booktitle> <month> Aug. </month> <year> 1993, </year> <pages> pp. </pages> <month> 53-64. </month> <title> 9 Due to the unbounded round structure of [4], the resulting consensus protocol assumes unbounded registers. We believe these unbounded registers can be eliminated using the bounded round numbers construction of Dwork, Herlihy and Waarts [14]. </title> <type> 20 </type>
Reference: [15] <author> W. Feller, </author> <title> An Introduction to Probability Theory and Its Applications, </title> <journal> vol. </journal> <volume> 2, </volume> <publisher> John Wiley and Sons, </publisher> <editor> second ed., </editor> <year> 1971. </year>
Reference-contexts: However, the sign of each vote is determined by a fair coin flip that the scheduler cannot predict in advance, and so despite all the scheduler's powers, the expected value of each vote before it is cast is always 0. This is the primary requirement of a martingale process <ref> [6, 15, 21] </ref>. Under the right conditions, martingales have many similarities to sequences of sums of independent random variables. In particular, martingale analogues of the Central Limit Theorem and Chernoff bounds will be used in the proof of correctness. 3. The Shared Coin Protocol. <p> But because the casino is fair and the gambler cannot predict the future, the expected change in the gambler's fortune at any play is always 0. We will need to use a very general definition of a martingale <ref> [6, 15, 21] </ref>. The simplest definition of a martingale says that the expected value of S i+1 given S 1 ; S 2 ; : : : ; S i is just S i . <p> The tool used to represent the information known at any point in time will be a concept from measure theory, a -algebra. 6 The description given here is informal; more complete definitions can be found in <ref> [15, Sections IV.3, IV.4, and V.11] </ref> or [6]. 4.1. Knowledge, -algebras, and measurability. Recall that any probabilistic statement is always made in the context of some (possibly implicit) sample space. <p> The random variable E [X j F] is called the conditional expectation of X with respect to F <ref> [15, Section V.11] </ref>. Intuitively, the first condition on E [X j F ] says that it reveals no information not already found in F . <p> See <ref> [15, Section V.11] </ref>. 4.2. Definition of a martingale. We now have the tools to define a martingale when the information available at each point in time is not limited to just the values of earlier random variables.
Reference: [16] <author> M. J. Fischer, N. A. Lynch, and M. S. Paterson, </author> <title> Impossibility of distributed commit with one faulty process, </title> <journal> J. Assoc. Comput. Mach., </journal> <volume> 32 (1985), </volume> <pages> pp. 374-382. </pages>
Reference-contexts: of this work appeared in the proceedings of the Thirty-Third IEEE Sym posium on Foundations of Computer Science. 1 by interleaving.) Remarkably, it has been shown that the ability of the scheduler to stop even a single processor is sufficient to prevent consensus from being solved by a deterministic algorithm <ref> [10, 12, 16, 20, 22] </ref>. Nevertheless, it can be solved by randomized protocols in which each processor is guaranteed to decide after a finite expected number of steps.
Reference: [17] <author> P. Hall and C. Heyde, </author> <title> Martingale Limit Theory and Its Application, </title> <publisher> Academic Press, </publisher> <year> 1980. </year>
Reference-contexts: Limit theorems. Many results that hold for sums of independent random variables carry over in modified form to martingales. For example, the following theorem of Hall and Heyde <ref> [17, Theorem 3.9] </ref> is a martingale version of the classical Central Limit Theorem: Theorem 4.2 ([17]). Let fS i ; F i g be a zero-mean martingale. Let V 2 n = i=1 E X 2 fl and let 0 &lt; ffi 1.
Reference: [18] <author> P. R. Halmos, </author> <title> Invariants of certain stochastic transformations: </title> <journal> The mathematical theory of gambling systems, Duke Mathematical Journal, </journal> <volume> 5 (1939), </volume> <pages> pp. 461-478. </pages>
Reference-contexts: A zero-mean martingale is a martingale for which E [S i ] = 0. 4.3. Gambling systems. A remarkably useful theorem, which has its origins in the study of gambling systems, is due to Halmos <ref> [18] </ref>. We restate his theorem below in modern notation: Theorem 4.1. Let fS i ; F i g ; 1 i n be a martingale with difference sequence fX i g.
Reference: [19] <author> G. Hardy, J. Littlewood, and G. P olya, </author> <title> Inequalities, </title> <publisher> Cambridge University Press, </publisher> <editor> second ed., </editor> <year> 1952. </year>
Reference-contexts: Let (x) = x A =A and let be any strictly increasing function such that 1 is concave. Then for any non-negative fx i g, if P n i=1 (x i ) K, then P n Proof. Since 1 is concave, we have 1 n 1 n <ref> [19, Theorem 92] </ref>. Simple algebraic manipulation yields X X (x i ) 1 n = 1 1 X x i A 1 K Hence P Letting be the identity function we have 1 (x) = (Ax) 1=A , which is concave for A 1.
Reference: [20] <author> M. Herlihy, </author> <title> Wait-free synchronization, </title> <journal> ACM Trans. Prog. Lang. Syst., </journal> <volume> 13 (1991), </volume> <pages> pp. 124-149. </pages>
Reference-contexts: Reads and writes to such a register can be viewed as occurring at a single instant of time. Consensus is fundamental to synchronization without mutual exclusion and hence lies at the heart of the more general problem of constructing highly concurrent data structures <ref> [20] </ref>. It can be used to obtain wait-free implementations of arbitrary abstract data types with atomic operations [20, 23]. Consensus is also complete for distributed decision tasks [11] in the sense that it can be used to solve all such tasks that have a wait-free solution. <p> Consensus is fundamental to synchronization without mutual exclusion and hence lies at the heart of the more general problem of constructing highly concurrent data structures [20]. It can be used to obtain wait-free implementations of arbitrary abstract data types with atomic operations <ref> [20, 23] </ref>. Consensus is also complete for distributed decision tasks [11] in the sense that it can be used to solve all such tasks that have a wait-free solution. Consensus is often viewed as a game played between a set of processors and an adversary scheduler. <p> of this work appeared in the proceedings of the Thirty-Third IEEE Sym posium on Foundations of Computer Science. 1 by interleaving.) Remarkably, it has been shown that the ability of the scheduler to stop even a single processor is sufficient to prevent consensus from being solved by a deterministic algorithm <ref> [10, 12, 16, 20, 22] </ref>. Nevertheless, it can be solved by randomized protocols in which each processor is guaranteed to decide after a finite expected number of steps.
Reference: [21] <author> P. Kopp, </author> <title> Martingales and Stochastic Integrals, </title> <publisher> Cambridge University Press, </publisher> <year> 1984. </year>
Reference-contexts: However, the sign of each vote is determined by a fair coin flip that the scheduler cannot predict in advance, and so despite all the scheduler's powers, the expected value of each vote before it is cast is always 0. This is the primary requirement of a martingale process <ref> [6, 15, 21] </ref>. Under the right conditions, martingales have many similarities to sequences of sums of independent random variables. In particular, martingale analogues of the Central Limit Theorem and Chernoff bounds will be used in the proof of correctness. 3. The Shared Coin Protocol. <p> But because the casino is fair and the gambler cannot predict the future, the expected change in the gambler's fortune at any play is always 0. We will need to use a very general definition of a martingale <ref> [6, 15, 21] </ref>. The simplest definition of a martingale says that the expected value of S i+1 given S 1 ; S 2 ; : : : ; S i is just S i .
Reference: [22] <author> M. C. Loui and H. H. Abu-Amara, </author> <title> Memory requirements for agreement among unreliable asynchronous processes, </title> <booktitle> in Advances in Computing Research, </booktitle> <editor> F. P. Preparata, ed., </editor> <volume> vol. 4, </volume> <publisher> JAI Press, </publisher> <year> 1987. </year>
Reference-contexts: of this work appeared in the proceedings of the Thirty-Third IEEE Sym posium on Foundations of Computer Science. 1 by interleaving.) Remarkably, it has been shown that the ability of the scheduler to stop even a single processor is sufficient to prevent consensus from being solved by a deterministic algorithm <ref> [10, 12, 16, 20, 22] </ref>. Nevertheless, it can be solved by randomized protocols in which each processor is guaranteed to decide after a finite expected number of steps.
Reference: [23] <author> S. A. Plotkin, </author> <title> Sticky bits and universality of consensus, </title> <booktitle> in Proceedings of the Eighth ACM Symposium on Principles of Distributed Computing, </booktitle> <month> Aug. </month> <year> 1989, </year> <pages> pp. 159-176. </pages>
Reference-contexts: Consensus is fundamental to synchronization without mutual exclusion and hence lies at the heart of the more general problem of constructing highly concurrent data structures [20]. It can be used to obtain wait-free implementations of arbitrary abstract data types with atomic operations <ref> [20, 23] </ref>. Consensus is also complete for distributed decision tasks [11] in the sense that it can be used to solve all such tasks that have a wait-free solution. Consensus is often viewed as a game played between a set of processors and an adversary scheduler.
Reference: [24] <author> M. Saks, N. Shavit, and H. Woll, </author> <title> Optimal time randomized consensus | making resilient algorithms fast in practice, </title> <booktitle> in Proceedings of the Second Annual ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <year> 1991, </year> <pages> pp. 351-362. </pages>
Reference-contexts: Since then a number of polynomial-work consensus protocols have been proposed. Protocols that use unbounded registers have been proposed by Aspnes and Herlihy [4] (the first polynomial-time algorithm), by Saks, Shavit, and Woll <ref> [24] </ref> (optimized for the case where processors run in lock step), and by Bracha and Rachman [8] (running time O (n 2 log n)). <p> The rest of the paper is organized as follows. The next section describes the intuition behind our solution while emphasizing the main difference between our solution and that in <ref> [3, 4, 5, 7, 8, 13, 24] </ref>. Section 3 describes our shared coin protocol. Section 4 reviews martingales and derives some of their properties. Section 5 contains the proof of correctness of our shared coin protocol. A discussion of the results appears in Section 6. 2. <p> a weak shared coin has not changed substantially since the protocol described in [4]; each processor repeatedly adds random 1 votes to a common pool until either the total vote is far from the origin [3, 4, 5, 7, 13] or until a predetermined number of votes have been cast <ref> [8, 24] </ref>. Any processor that sees a nonnegative total vote decides 1, and those that see a negative total vote decide 0. (The differences between the protocols are largely in how termination is detected and how the counter for the vote is implemented.) There are many advantages to this approach. <p> There are two main difficulties that this approach entails; the first is that careful 4 The term agreement parameter was first used by Saks et al <ref> [24] </ref> in place of the more melodramatic but less descriptive term defiance probability of Aspnes and Herlihy [4]. <p> Shared coin protocol. adjustment of the weight function and other parameters of the protocol is necessary to make sure that it performs correctly. More importantly, correctness proofs for previous shared coins based on random walks or voting <ref> [3, 4, 5, 7, 8, 13, 24] </ref> considered only equally weighted votes, and have therefore been able to treat the sequence of votes as a sequence of independent random variables using a substitution argument.
Reference: [25] <author> J. Spencer, </author> <title> Ten Lectures on the Probabilistic Method, </title> <institution> Society for Industrial and Applied Mathematics, </institution> <year> 1987. </year> <month> 21 </month>
Reference-contexts: If we are interested only in the tails of the distribution of S n , we can get a tighter bound using Azuma's inequality, a martingale analogue of the standard Chernoff bound [9] for sums of independent random variables. The usual form of this bound (see <ref> [2, 25] </ref>) assumes that the difference variables X i satisfy jX i j 1. This restriction is too severe for our purposes, so below we prove a generalization of the inequality. In order to do so we will need the following technical lemma. Lemma 4.4.
References-found: 24

