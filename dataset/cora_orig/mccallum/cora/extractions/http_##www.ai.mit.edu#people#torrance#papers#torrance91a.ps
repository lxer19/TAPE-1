URL: http://www.ai.mit.edu/people/torrance/papers/torrance91a.ps
Refering-URL: http://www.ai.mit.edu/people/torrance/papers/papers.html
Root-URL: 
Email: torrance@ai.mit.edu  
Title: Proposal for Research in Automatic Synthesis of Behavior-Based Robot Control Architectures  
Author: Mark C. Torrance 
Date: October 29, 1991  
Affiliation: Artificial Intelligence Laboratory Massachusetts Institute of Technology  
Abstract: I intend to investigate strategies and algorithms for automatically generating collections of behaviors interacting in a subsumption architecture that will perform well on a task as described in an external, model-based representation. I expect to find that by exploiting the incremental improvability of the subsumption architecture, my automatic programming system will be able to synthesize programs for subsumption-based robots able to perform complicated tasks. My intention is to create an integrated subsumption-based robot that can accept new goals and modify its behavior to achieve them, and that can use external punishment or reward received to adjust its strategies for achieving its goals.
Abstract-found: 1
Intro-found: 1
Reference: [ Agre and Chapman, 1990 ] <author> Philip E. Agre and David Chapman. </author> <title> What are plans for? Robotics and Autonomous Systems, </title> <booktitle> 6 </booktitle> <pages> 17-34, </pages> <year> 1990. </year>
Reference-contexts: I am interested not only in compiling model-based descriptions into programs, but more in interactive systems that are able to accept new goals in a human representation and try to achieve 2 See also <ref> [ Agre and Chapman, 1990, Chapman, 1990 ] </ref> . 3 the goals, accepting reinforcement from the user to guide their performance.
Reference: [ Brooks, 1986 ] <author> Rodney A. Brooks. </author> <title> A robust layered control system for a mobile robot. </title> <journal> IEEE Journal of Robotics and Automation, </journal> <volume> 2(1), </volume> <month> March </month> <year> 1986. </year>
Reference-contexts: 1 Background Brooks has developed the subsumption architecture for autonomous robots <ref> [ Brooks, 1986 ] </ref> . Traditional robot control architectures preprocess sensor information into abstracted internal representations that are acted on by a central planner, then instantiate the results to become actions that can be executed by the robot.
Reference: [ Brooks, 1991 ] <author> Rodney A. Brooks. </author> <title> The role of learning in autonomous robots. </title> <booktitle> In Proceedings of Conference on Computational Learning Theory, </booktitle> <address> Santa Cruz, CA, </address> <month> August </month> <year> 1991. </year>
Reference-contexts: I plan to define a new architecture as a way to integrate high level constructs such as goals in a human-friendly representation with effective physical robots such as those programmed with Brooks' behavior language. In <ref> [ Brooks, 1991 ] </ref> , Brooks argues that "reasonable challenges for things that autonomous robots in the real world should learn" include: 1. representations of the world that help in some task 2. aspects of instances of sensors and actuators (this is sometimes called calibration) 3. the ways in which individual <p> It is this kind of synthesis that I hope to achieve. Brooks, in <ref> [ Brooks, 1991 ] </ref> , points out that learning from a clean slate, or tabula rasa learning, is impractical and unnecessary in real world robots. I would not work on learning merely for the sake of regenerating programs that we already know how to write.
Reference: [ Chapman, 1990 ] <author> David Chapman. </author> <title> Vision, Instruction, and Action. </title> <type> PhD thesis, </type> <institution> Massachusetts Institute of Technology Artificial Intelligence Laboratory, </institution> <month> April </month> <year> 1990. </year>
Reference-contexts: I am interested not only in compiling model-based descriptions into programs, but more in interactive systems that are able to accept new goals in a human representation and try to achieve 2 See also <ref> [ Agre and Chapman, 1990, Chapman, 1990 ] </ref> . 3 the goals, accepting reinforcement from the user to guide their performance.
Reference: [ Fikes et al., 1972 ] <author> Richard E. Fikes, Peter E. Hart, and Nils J. Nilsson. </author> <title> Learning and executing generalized robot plans. </title> <journal> Artificial Intelligence, </journal> <volume> 3 </volume> <pages> 251-288, </pages> <year> 1972. </year>
Reference-contexts: In particular, I think the restriction of writing the controller in the behavior language may make the algorithm more complicated than it needs to be. It may also be harder to abstract the principles behind the controller onto other base architectures. 4 Representation of Goals In classical planning literature <ref> [ Fikes et al., 1972 ] </ref> , goals are often desired states of the world, expressed as sets of predicates or properties that should be true of the world when the robot has worked correctly. For these embedded subsumption robots, the character of goals is often different.
Reference: [ Kaelbling and Rosenschein, 1990 ] <author> Leslie Pack Kaelbling and Stanley J. Rosenschein. </author> <title> Action and planning in embedded agents. </title> <booktitle> Robotics and Autonomous Systems, </booktitle> <volume> 6 </volume> <pages> 35-48, </pages> <year> 1990. </year>
Reference-contexts: One part of this problem may be thought of as writing a compiler from model-based descriptions of tasks into programs in the subsumption architecture. Work has been done on similar compilation using different target architectures by <ref> [ Kaelbling and Rosenschein, 1990 ] </ref> (situated automata) and others 2 . <p> An example that was pointed out to me by Phillip Bogle is that I said I want the system to choose a set of behaviors and parameters that seems correlated with good 3 See <ref> [ Kaelbling and Rosenschein, 1990 ] </ref> . 4 A comment from Ian Horswill. 6 feedback on similar problems. He argues that determining whether problems are similar is in itself a difficult and open area of research.
Reference: [ Maes and Brooks, 1990 ] <author> Pattie Maes and Rodney A. Brooks. </author> <title> Learning to coordinate behaviors. </title> <booktitle> In Proceedings Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pages 796-802, </pages> <address> Boston, MA, </address> <month> 29 July - 3 August </month> <year> 1990. </year> <booktitle> American Association for Artificial Intelligence, </booktitle> <publisher> AAAI Press / The MIT Press. </publisher>
Reference-contexts: For some tasks, the relationship between the task and the environment is such that sensors can readily tell how well the task is being performed <ref> [ Maes and Brooks, 1990 ] </ref> . For other interesting tasks, I conjecture that in order to assign credit or blame it would be necessary to construct a more complicated world model than can be built from just the sensors needed to perform the task correctly.
Reference: [ Mataric, 1990 ] <editor> Maja J. Mataric. </editor> <title> A distributed model for mobile robot environment-learning and navigation. </title> <type> Master's thesis, </type> <institution> Massachusetts Institute of Technology Artificial Intelligence Laboratory, </institution> <month> May </month> <year> 1990. </year> <month> 8 </month>
Reference-contexts: A goal for a subsumption robot will typically not be a state of the world, but rather will be a set of constraints on the behavior of the robot conditioned on certain environmental situations. An example may make this more clear. In <ref> [ Mataric, 1990 ] </ref> , Toto performs a goal-directed navigation task. Toto's program builds up a representation of the world in terms of locations, and can be directed to proceed to a particular location by a user activating nodes corresponding to that location within the robot's network. <p> This would be an extension of the control algorithm to one that more directly implements the performance of a task. Maja Mataric has done some unpublished work on an algorithm for learning action sequences within behavior language programs based on her work on active representations <ref> [ Mataric, 1990 ] </ref> . This sequence learning only works when the goal is represented to the robot as an activation of a particular part of its internal representation.
References-found: 8

