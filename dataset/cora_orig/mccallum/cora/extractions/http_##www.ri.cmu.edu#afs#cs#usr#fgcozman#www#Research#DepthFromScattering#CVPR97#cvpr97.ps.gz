URL: http://www.ri.cmu.edu/afs/cs/usr/fgcozman/www/Research/DepthFromScattering/CVPR97/cvpr97.ps.gz
Refering-URL: http://www.ri.cmu.edu/afs/cs/usr/fgcozman/www/Research/DepthFromScattering/CVPR97/CVPR97.html
Root-URL: 
Email: @cs.cmu.edu  
Title: Depth from Scattering  
Author: Fabio Cozman Eric Krotkov f fgcozman, epk g 
Web: http://www.cs.cmu.edu/~f fgcozman, epk g  
Address: Pittsburgh  
Affiliation: Robotics Institute, Carnegie Mellon University,  
Abstract: Light power is affected when it crosses the atmosphere; there is a simple, albeit non-linear, relationship between the radiance of an image at any given wavelength and the distance between object and viewer. This phenomenon is called atmospheric scattering and has been extensively studied by physicists and me-terologists. We present the first analysis of this phenomenon from an image understanding perspective: we investigate a group of techniques for extraction of depth cues solely from the analysis of atmospheric scattering effects in images. Depth from scattering techniques are discussed for indoor and outdoor environments, and experimental tests with real images are presented. We have found that depth cues in outdoor scenes can be recovered with surprising accuracy and can be used as an additional information source for autonomous vehicles. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E. L. Brown and K. Deffenbacher. </author> <title> Perception and the Senses. </title> <publisher> Oxford University Press, </publisher> <year> 1979. </year>
Reference-contexts: Investigators have studied atmospheric scattering with distinct goals. Physicists and navigators seek to predict how a particular atmosphere affects visual perception; computer graphics researchers simulate scattering rather than measure its effect in practice [4, 6]. Artists have used simulated atmospheric effects in paintings at least since the Renaissance <ref> [1] </ref>. Our purpose is new: we use atmospheric scattering as a beneficial source of information about geometric rela tionships among objects and a viewer. Light power and intensity are modified principally by scattering when light crosses the atmosphere.
Reference: [2] <author> F. G. Cozman and E. Krotkov. </author> <title> Position estimation from outdoor visual landmarks for teleoperation of lunar rovers. </title> <booktitle> Proc. Third IEEE Workshop on Applications of Computer Vision, </booktitle> <pages> pages 156-161, </pages> <month> December </month> <year> 1996. </year>
Reference-contexts: Images were taken from a tripod containing a color camera over a rotary platform, a compass, a dual-axis inclinometer and a GPS system <ref> [2] </ref>. A panorama is formed by merging the images by the Kuglin/Hines method [5, 9].
Reference: [3] <author> B. K. P. Horn. </author> <title> Understanding image intensities. </title> <journal> Artificial Intelligence, </journal> <volume> 8(2) </volume> <pages> 201-231, </pages> <year> 1977. </year>
Reference-contexts: Power decreases with distance by the inverse square law so power decreases with d 2 ; on the other hand, intensity at a receiver increases with square of distance d 2 , because the solid angle subtended by the receiver corresponds to a larger area on the object <ref> [3] </ref>. Appendix A shows how the two effects cancel each other, so that the dependency of distance remains restricted to the exponential term. <p> Consider the line from the center of ffiM to ffiO; call ff the angle between this line and the optical axis of the lens and the angle between the line and the normal at ffiO (a similar construction is used by Horn to derive radiometric properties of lenses <ref> [3] </ref>). First, since the solid angles of ffiO and ffiM must be equal as seen from the lens, we have the equality A (ffiO) A (ffiM) = cos ff cos f .
Reference: [4] <author> R. V. Klassen. </author> <title> Modeling the effect of the atmosphere on light. </title> <journal> ACM Transactions on Graphics, </journal> <volume> 6(3) </volume> <pages> 215-237, </pages> <month> July </month> <year> 1987. </year>
Reference-contexts: We use the phrase depth from scattering to refer to such techniques. Investigators have studied atmospheric scattering with distinct goals. Physicists and navigators seek to predict how a particular atmosphere affects visual perception; computer graphics researchers simulate scattering rather than measure its effect in practice <ref> [4, 6] </ref>. Artists have used simulated atmospheric effects in paintings at least since the Renaissance [1]. Our purpose is new: we use atmospheric scattering as a beneficial source of information about geometric rela tionships among objects and a viewer. <p> If particles in the atmosphere are spherical or small, light is scattered symmetrically with respect to incident rays of light <ref> [4] </ref>. We represent the portion of light that is scattered by a function B (; ), the angular scattering function. The variable is the angle between the incident ray of light and the emanating ray of light; is the wavelength.
Reference: [5] <author> C. D. Kuglin and D. C. Hines. </author> <title> The phase correlation image alignment method. </title> <booktitle> Proc. of the IEEE Int. Conf. on Cybernetics and Society, </booktitle> <pages> pages 163-165, </pages> <month> September </month> <year> 1975. </year>
Reference-contexts: Images were taken from a tripod containing a color camera over a rotary platform, a compass, a dual-axis inclinometer and a GPS system [2]. A panorama is formed by merging the images by the Kuglin/Hines method <ref> [5, 9] </ref>. The top of Figure 2 shows a mosaic made from a sequence of images taken by the river Allegheny.The mountains in the scene are numbered from 1 to 5; we refer to them as m i , i 2 f1 : : : 5g.
Reference: [6] <author> N. L. Max. </author> <title> Atmospheric illumination and shadows. </title> <journal> SIGGRAPH, </journal> <volume> 20(4) </volume> <pages> 117-123, </pages> <month> August </month> <year> 1986. </year>
Reference-contexts: We use the phrase depth from scattering to refer to such techniques. Investigators have studied atmospheric scattering with distinct goals. Physicists and navigators seek to predict how a particular atmosphere affects visual perception; computer graphics researchers simulate scattering rather than measure its effect in practice <ref> [4, 6] </ref>. Artists have used simulated atmospheric effects in paintings at least since the Renaissance [1]. Our purpose is new: we use atmospheric scattering as a beneficial source of information about geometric rela tionships among objects and a viewer.
Reference: [7] <author> E. J. </author> <title> McCartney. Optics of the Atmosphere. </title> <publisher> John Wiley and Sons, Inc., </publisher> <address> New York, </address> <year> 1976. </year>
Reference-contexts: 1 Introduction Observers of outdoor scenery witness a variety of atmospheric effects caused by light scattering: the sky is blue, distant mountains appear bluer than nearby mountains, a flashlight beam is reflected back by a foggy environment. Such phenomena have been actively studied by physicists, meterologists and navigators <ref> [7, 8] </ref>. In this paper, we present the first analysis of atmospheric scattering from an image understanding perspective. We investigate techniques that extract depth cues from atmospheric scattering effects in images. We use the phrase depth from scattering to refer to such techniques. <p> The first successful model of scattering was developed by Lord Rayleigh in 1871, after a long period where researchers postulated that the sky was blue due to the presence of water in the atmosphere <ref> [7] </ref>. If particles in the atmosphere are spherical or small, light is scattered symmetrically with respect to incident rays of light [4]. We represent the portion of light that is scattered by a function B (; ), the angular scattering function. <p> The distance between object and viewer is d. As rays of light are deflected by particles, the power of light conveyed by the beam decreases. For a differential portion of the trajectory, power decreases as dP = fiP dd <ref> [7] </ref>, where P o () is the power of the source and fi () is called the extinction coefficient 1 . <p> We still would need the extinction coefficient fi in order to obtain d. Expression (3) yields: exp (fid) = C S Values of fi that are reasonably valid for clean air and different types of fog have been collected <ref> [7] </ref>. It is unlikely that, in any given experiment, these values will be accurate. Scattering varies significantly with the density and type of particles in the atmosphere, making the precise measurement of fi a complex undertaking.
Reference: [8] <author> W. E. K. Middleton. </author> <title> Vision Through the Atmosphere. </title> <institution> University of Toronto Press, </institution> <year> 1952. </year>
Reference-contexts: 1 Introduction Observers of outdoor scenery witness a variety of atmospheric effects caused by light scattering: the sky is blue, distant mountains appear bluer than nearby mountains, a flashlight beam is reflected back by a foggy environment. Such phenomena have been actively studied by physicists, meterologists and navigators <ref> [7, 8] </ref>. In this paper, we present the first analysis of atmospheric scattering from an image understanding perspective. We investigate techniques that extract depth cues from atmospheric scattering effects in images. We use the phrase depth from scattering to refer to such techniques. <p> o () in the absence of scattering and distance d from the viewer, the intensity measured by the viewer I () is: I () = I o () exp (fi ()d) : (2) 1 Atmospheric absorption is incorporated into this model by a slight increase in the value of fi <ref> [8] </ref>. 2.2 Sky intensity Even though light power is attenuated by direct scattering, there is another effect, also due to scattering, which increases the power in a light beam. We now model this phenomenon using some additional assumptions. <p> Assumption 3 Each ray of light is scattered once. The first assumption is reasonable for the sky, and can possibly be approximated in large indoor environments. The second assumption is an approximation based on empirical observations <ref> [8] </ref>. In order to reduce the complexity of the scattering model above, we make the following assumption: Assumption 4 The variation of across an object located relatively far away is small enough so that its effect in I o ()B (;) fi () is negligible. <p> If a viewer were to look at a point infinitely far away (d ! 1), the perceived intensity would be S (), solely caused by atmospheric scattering. 2.3 Combining scattering effects The two effects above, attenuation and sky intensity, are additive due to the linear character of light propagation <ref> [8] </ref>. Suppose an object located at distance d has intensity I o () when imaged in a vacuum. In the presence of atmosphere the intensity is: I () = exp (fi ()d)I o () + (1 exp (fi ()d)S (): So far we have kept the dependencies on wavelength explicit. <p> For the distances involved in our experiments (between 1000 to 3000 meters), there is no appreciable "blueing" effect. For larger particles, wavelength selectivity decreases remarkably. For dense concentrations of clean water droplets such that visibility falls below 1000 meters (a situation defined as fog <ref> [8] </ref>), the dependence on wavelength becomes negligible. Due to such considerations, we drop the dependency on in the remainder of this paper, since it has no effect relevant to our experiments.
Reference: [9] <author> R. Szeliski. </author> <title> Image mosaicing for tele-reality applications. </title> <type> Technical Report CRL94/2, </type> <institution> DEC Cam-bridge Research Lab, </institution> <month> May </month> <year> 1994. </year>
Reference-contexts: Images were taken from a tripod containing a color camera over a rotary platform, a compass, a dual-axis inclinometer and a GPS system [2]. A panorama is formed by merging the images by the Kuglin/Hines method <ref> [5, 9] </ref>. The top of Figure 2 shows a mosaic made from a sequence of images taken by the river Allegheny.The mountains in the scene are numbered from 1 to 5; we refer to them as m i , i 2 f1 : : : 5g.
References-found: 9

