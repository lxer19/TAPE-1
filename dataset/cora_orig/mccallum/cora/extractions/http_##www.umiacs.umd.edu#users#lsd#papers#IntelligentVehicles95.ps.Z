URL: http://www.umiacs.umd.edu/users/lsd/papers/IntelligentVehicles95.ps.Z
Refering-URL: http://www.umiacs.umd.edu/users/lsd/pubs.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Detection of Independently Moving Objects in Passive Video  
Author: Carlos Morimoto Daniel DeMenthon Larry Davis Rama Chellappa Randal Nelson 
Address: College Park, MD 20742  Rochester, Rochester, NY 14627  
Affiliation: Computer Vision Laboratory, Center for Automation Research University of Maryland,  Department of Computer Science University of  
Abstract: We present two different approaches for the identification of independently moving objects (IMOs) and demonstrate their application to outdoor imagery taken from a moving autonomous vehicle. Both approaches involve image stabilization followed by an analysis of the stabilized image sequence. The stabilization reduces the effects of the movement of the autonomous vehicle, facilitating the detection of the IMOs. In the first approach, IMOs are detected based on a filtering approach that integrates the results of velocity tuned filters over several frames. In the second approach IMOs are identified by constraints on allowable values of the optic flow field after stabilization. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> C.H.Anderson, P.J. Burt, and G.S. van der Wal. </author> <title> Change Detection and Tracking Using Pyramid Transform Techniques. </title> <booktitle> Proc. SPIE Conference on Intelligent Robots and Computer Vision, </booktitle> <address> Boston MA, </address> <year> 1985, </year> <pages> 300-305. </pages>
Reference-contexts: One simple method for detecting IMOs from stationary cameras is to take the difference between image frames taken a short time apart and select the non-zero regions of the resulting image <ref> [1] </ref>. Assuming that the scene background does not change, the non-zero regions must correspond to moving objects.
Reference: [2] <author> P. Burt and P. Anandan. </author> <title> Image Stabilization by Registration to a Reference Mosaic. </title> <booktitle> In Proc. of ARPA Image Understanding Workshop, </booktitle> <pages> pages 425-434, </pages> <address> Monterey, CA, </address> <month> Novem-ber </month> <year> 1994. </year>
Reference-contexts: Image stabilization has been used for several other purposes including video compression [6] and recovery of egomotion [4]. A large variety of schemes have been described. For example, Burt et al. <ref> [2] </ref> use a 2D affine model and a hierarchical image registration algorithm which was implemented in special parallel hardware to perform stabilization in real-time, while Davis et al. [3] propose (among other methods) 3D models and the computation of flow to eliminate 3D rotation.
Reference: [3] <author> L.S.Davis, R. Bajcsky, R. Nelson, and M. Her-man. </author> <title> RSTA on the Move. </title> <booktitle> In Proc. of ARPA Image Understanding Workshop, </booktitle> <pages> pages 435-456, </pages> <address> Monterey, CA, </address> <month> November </month> <year> 1994. </year>
Reference-contexts: A large variety of schemes have been described. For example, Burt et al. [2] use a 2D affine model and a hierarchical image registration algorithm which was implemented in special parallel hardware to perform stabilization in real-time, while Davis et al. <ref> [3] </ref> propose (among other methods) 3D models and the computation of flow to eliminate 3D rotation. Yao et al. [9] use multiple visual cues and an extended Kalman filter for the estimation of the desired 3D motion parameters that are used for stabilization.
Reference: [4] <author> M. Irani, B. Rousso, and S. Peleg. </author> <title> Recovery of Ego-Motion Using Image Stabilization. </title> <booktitle> In Proc. of IEEE Conf. on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 454-460, </pages> <address> Seattle, WA, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: While simple mechanical stabilization only removes the high frequency movements, our electronic stabilizer can remove the effects of a larger class of motions at a lower cost. Image stabilization has been used for several other purposes including video compression [6] and recovery of egomotion <ref> [4] </ref>. A large variety of schemes have been described.
Reference: [5] <author> B. Jahne. </author> <title> Spatio-Temporal Image Processing. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, Heidelberg, </address> <year> 1993. </year>
Reference-contexts: The point of maximum correlation is selected as best match, but the feature itself is selected as a reliable one only when the maximum correlation is higher than 90%. For reliable features, we further refine the feature displacement using the fast subpixel correlation matching described in Jahne <ref> [5] </ref>, which fits a second order polynomial surface around the point of maximum correlation in the correlation image instead of using the original grey level images.
Reference: [6] <author> O.J. Kwon, R. Chellappa, and C.H. Mori-moto. </author> <title> Motion Compensated Subband Coding of Video Acquired from a Moving Platform. </title> <booktitle> In Proc. of IEEE International Conf. on Acoustics, Speech, and Signal Processing, </booktitle> <address> Detroit, MI, </address> <year> 1995. </year>
Reference-contexts: While simple mechanical stabilization only removes the high frequency movements, our electronic stabilizer can remove the effects of a larger class of motions at a lower cost. Image stabilization has been used for several other purposes including video compression <ref> [6] </ref> and recovery of egomotion [4]. A large variety of schemes have been described.
Reference: [7] <author> H.C. Liu, T.H. Hong, M. Herman and R. Chellappa. </author> <title> A General Motion Model and Spatio-Temporal Filters for Computing Optical Flow. </title> <type> Technical Report, </type> <institution> University of Maryland at College Park, Center for Automation Research, CAR-TR-741, </institution> <month> October </month> <year> 1994. </year>
Reference-contexts: We are currently working on a better way of dynamically selecting features based on an optical flow computation algorithm developed by Liu et al. <ref> [7] </ref>. When forward-translation motion is dominant, regions where the optical flow is small correspond in general to distant parts of the scene.
Reference: [8] <author> R. Nelson. </author> <title> Qualitative Detection of Motion by a Moving Observer. </title> <journal> International Journal of Computer Vision 7, </journal> <pages> 33-46, </pages> <month> November </month> <year> 1991. </year>
Reference-contexts: As an alternative, our second approach uses a qualitative method for detecting independently moving objects based on available knowledge about the motion of the camera, which can be obtained from the computation of normal flow <ref> [8] </ref>. This approach requires a weaker form of stabilization in which only rotation effects need to be removed from the sequence. IMOs are identified by constraints on allowable values of the optical flow field for the resultant translation-only image sequences. <p> We can also detect objects moving in the range of 12 to 24 km/h at 100 m by accumulating evidence from 3 consecutive processed frames. Trying to detect even faster objects would not be reliable because evidence from only 2 frames could be used. 4 Qualitative Detection Nelson <ref> [8] </ref> suggests a qualitative method of detecting independently moving objects termed constraint ray filtering.
Reference: [9] <author> Y.S. Yao, P. Burlina, R. Chellappa, and T.H. Wu. </author> <title> Electronic Image Stabilization. </title> <booktitle> International Conference on Image Processing, </booktitle> <year> 1995. </year>
Reference-contexts: Yao et al. <ref> [9] </ref> use multiple visual cues and an extended Kalman filter for the estimation of the desired 3D motion parameters that are used for stabilization.
Reference: [10] <author> Q. Zheng, and R. Chellappa. </author> <title> A Computational Vision Approach to Image Registration. </title> <journal> IEEE Transactions on Image Processing, </journal> <volume> vol. 2, no. 3, </volume> <month> July </month> <year> 1993. </year> <pages> pp. 311-326. </pages>
Reference-contexts: on VTFs, is presented in section 3 and the second, based on qualitative knowledge of the camera motion, is presented in section 4. 2 Image Stabilization The main component of our image stabilization system is a frame to frame registration algorithm similar to the one developed by Zheng and Chel-lappa <ref> [10] </ref>, modified in order to obtain near real-time performance.
References-found: 10

