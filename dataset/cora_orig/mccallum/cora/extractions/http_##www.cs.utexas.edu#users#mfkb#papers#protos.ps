URL: http://www.cs.utexas.edu/users/mfkb/papers/protos.ps
Refering-URL: http://www.cs.utexas.edu/users/mfkb/papers/
Root-URL: 
Title: Concept Learning and Heuristic Classification in Weak-Theory Domains 1  
Author: Bruce W. Porter Ray Bareiss Robert C. Holte 
Note: 1 Support for this research was provided by grants from the Army Research Office (ARO-DAAG29-84-K-0060), and the National Science Foundation (IRI-8620052), and by contributions from Apple Corporation, Texas Instruments, and the Cray Foundation. This research was conducted in the  
Address: Austin, Texas 78712  Nashville, Tennessee 37235  Ottawa, Ontario, Canada K1N 6N5  
Affiliation: Department of Computer Sciences, University of Texas,  Computer Science Department, Vanderbilt University,  Computer Science Department, University of Ottawa,  Department of Computer Sciences, University of Texas at Austin.  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> J.S. Aikins. </author> <title> A representation scheme using both frames and rules. </title> <editor> In B.G. Buchanan and E.H. Shortliffe, editors, </editor> <title> Rule Based Expert Systems. </title> <publisher> Addison-Wesley, </publisher> <year> 1984. </year>
Reference-contexts: It determines which features are important for a successful match. If an important feature is absent from the case description, Protos attempts to infer it from the case features using matching knowledge. Unlike the models used by other expectation-driven classifiers <ref> [58, 1, 42] </ref>, exemplars are specific and numerous. Usually, case features and exemplar features match directly, and the range of category exemplars provides models for both typical and atypical cases. Knowledge-based matching is a uniform-cost, heuristic search.
Reference: [2] <author> J. </author> <title> Amsterdam. Some philosophical problems with formal learning theory. </title> <booktitle> Proceedings of AAAI-88, </booktitle> <pages> pages 580-584, </pages> <year> 1988. </year>
Reference-contexts: In most domains, superficial features do not suffice to define generalizations. Generalizations such as cup [61] and hammer [15] are defined in terms of function, not form. Categories such as infected by pseudomonas [53] and seedless grape <ref> [2] </ref> are generalizations defined in terms that are not readily perceivable in the context of classification. When abstract features are required to define generalizations, a gap exists between the case language and the generalization language. This gap may be bridged in two ways. <p> In summary, generalization-based methods are not likely to perform as well as exemplar-based methods in domains with weak theories. Furthermore, domains with weak theories are far more common, in practical applications, than domains with strong, tractable theories. Other weaknesses of generalization-based methods are given in <ref> [55, 51, 2, 12, 62] </ref>. 6 Given: a set of exemplar-based categories C = fc 1 ; c 2 ; : : : ; c n g and a case (NewCase) to classify.
Reference: [3] <author> E.R. Bareiss. </author> <title> Exemplar-Based Knowledge Acquisition. </title> <publisher> Academic Press, </publisher> <year> 1989. </year> <note> (Also available as a PhD dissertation from the Department of Computer Science, </note> <institution> University of Texas at Austin). </institution>
Reference-contexts: Protos's design includes solutions to these two problems. The design principles are introduced with simple, familiar examples and demonstrated with a large-scale application of Protos to clinical audiology. Complete details of Protos are given in <ref> [3] </ref>, and a Common Lisp reconstruction, available for distribution, is documented in [19]. 4.1 Simple Exemplar-Based Concept Learning and Classification and identifies the hard problems. Concepts are represented extensionally with a collection of exemplars described with features in the case language.
Reference: [4] <author> E.R. Bareiss, B.W. Porter, and K.S. Murray. </author> <title> Gaining autonomy during knowledge ac quisition. </title> <type> Technical Report AI89-97, </type> <institution> University of Texas at Austin, Computer Sciences Department, </institution> <year> 1989. </year>
Reference-contexts: Most existing concept learning and knowledge acquisition programs do not gain autonomy, and so are appropriate for only a single stage of a knowledge base's development <ref> [4] </ref>. For example, ETS [7] and ROGET [6] create a knowledge base by eliciting the basic terminology and conceptual structure of a domain. However, they are inappropriate for later stages of development such as refinement and reformulation.
Reference: [5] <author> E.R. Bareiss, B.W. Porter, and K.S. Murray. </author> <title> Supporting start-to-finish development of knowledge bases. </title> <booktitle> Machine Learning, </booktitle> <year> 1989. </year> <note> (to appear in Volume 3, Number 6). </note>
Reference-contexts: However, they are inappropriate for later stages of development such as refinement and reformulation. A full discussion of this issue and a survey of existing programs, including Protos, is given in <ref> [5] </ref>. 4 3 Weaknesses of Generalization-Based Methods for Learn ing and Classification Almost all programs that learn to classify are generalization-based, in the sense that they create or use explicit, abstract generalizations.
Reference: [6] <author> J.S. Bennett. ROGET: </author> <title> A knowledge-based system for acquiring the conceptual structure of a diagnostic expert system. </title> <journal> Automated Reasoning, </journal> <volume> 1(1) </volume> <pages> 49-74, </pages> <year> 1985. </year>
Reference-contexts: Most existing concept learning and knowledge acquisition programs do not gain autonomy, and so are appropriate for only a single stage of a knowledge base's development [4]. For example, ETS [7] and ROGET <ref> [6] </ref> create a knowledge base by eliciting the basic terminology and conceptual structure of a domain. However, they are inappropriate for later stages of development such as refinement and reformulation.
Reference: [7] <author> J. Boose. </author> <title> Personal construct theory and the transfer of expertise. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 27-33, </pages> <year> 1984. </year>
Reference-contexts: Most existing concept learning and knowledge acquisition programs do not gain autonomy, and so are appropriate for only a single stage of a knowledge base's development [4]. For example, ETS <ref> [7] </ref> and ROGET [6] create a knowledge base by eliciting the basic terminology and conceptual structure of a domain. However, they are inappropriate for later stages of development such as refinement and reformulation.
Reference: [8] <author> L.K. Branting. </author> <title> Integrating generalizations with exemplar-based reasoning. </title> <booktitle> In Proceed ings of the Eleventh Cognitive Science Society Conference, </booktitle> <year> 1989. </year>
Reference-contexts: This research and Ken Murray's both use a large-scale, multifunctional knowledge base for the domain of plant anatomy, physiology, and development [43]. The third shortcoming of 27 Protos is its very restricted explanation language. Karl Branting's research <ref> [8] </ref> explores the representation and reuse of complex explanations for automated reasoning in weak-theory domains, using as a testbed the domain of Worker's Compensation case law. Acknowledgements Many of our colleagues have contributed to this research. Dr.
Reference: [9] <author> L. Brooks. </author> <title> Non-analytic concept formation and the memory for instances. </title> <editor> In E. Rosch and B.B. Lloyd, editors, </editor> <booktitle> Cognition and Categorization, </booktitle> <pages> pages 169-211. </pages> <publisher> Erlbaum, </publisher> <address> Hills-dale, NJ, </address> <year> 1978. </year> <month> 28 </month>
Reference-contexts: As in machine learning, early psychological research assumed that generalization was automatic; researchers focused on what is abstracted and how generalization is performed, rather than whether cases are generalized [32]. Recent research indicates that people resist generalization and retain cases. For example, Medin [32] and Brooks <ref> [9] </ref> found that people classify previously seen cases by direct matching. Tversky and Kahneman [57] found that people estimate the frequency of a class or the probability of an event by their ability to recall instances of the class or event.
Reference: [10] <author> W.J. Clancey. </author> <title> Extensions to rules for explanation and tutoring. </title> <editor> In B.G. Buchanan and E.H. Shortliffe, editors, </editor> <booktitle> Rule Based Expert Systems, </booktitle> <pages> pages 531-568. </pages> <publisher> Addison-Wesley, </publisher> <year> 1984. </year>
Reference-contexts: First, explanations are used for only two purposes: to justify classifying a case in a particular way and to establish the degree of similarity of two cases. Explanations are not used to teach domain knowledge or to elaborate previous explanations (see <ref> [10, 38] </ref> for recent research on these tasks).
Reference: [11] <author> W.J. Clancey. </author> <title> Heuristic classification. </title> <journal> Artificial Intelligence, </journal> <volume> 27 </volume> <pages> 289-350, </pages> <year> 1985. </year>
Reference-contexts: There is no known way to determine membership in these categories directly from a case description, but it can be determined using knowledge-based inference, such as an exhaustive 9-ply look-ahead based on the knowledge of the rules of chess. The "heuristic classification method" described by Clancey <ref> [11] </ref> is tailored to domains in which cases are described with features that do not directly indicate category membership. It explicitly includes "the important twist of relating concepts in different classification hierarchies by nonhierarchical, uncertain inferences"[11, p. 290].
Reference: [12] <author> P. Clark. </author> <title> A comparison of rule and exemplar-based learning systems. </title> <editor> In Pavel Brazdil, editor, </editor> <booktitle> Proceedings of the International Workshop on Machine Learning, Meta-Reasoning, and Logic. </booktitle> <institution> University of Porto, Portugal, </institution> <year> 1988. </year>
Reference-contexts: In summary, generalization-based methods are not likely to perform as well as exemplar-based methods in domains with weak theories. Furthermore, domains with weak theories are far more common, in practical applications, than domains with strong, tractable theories. Other weaknesses of generalization-based methods are given in <ref> [55, 51, 2, 12, 62] </ref>. 6 Given: a set of exemplar-based categories C = fc 1 ; c 2 ; : : : ; c n g and a case (NewCase) to classify.
Reference: [13] <author> P. Clark and T. Niblett. </author> <title> The CN2 induction algorithm. </title> <journal> Machine Learning, </journal> <volume> 3(4) </volume> <pages> 261-283, </pages> <year> 1989. </year>
Reference-contexts: Generalization-based programs are either simple or theory-based, depending on whether the language with which cases are described (called the case language) and the language with which generalizations are expressed (called the generalization language) are closely related or entirely different. Examples of simple programs are ID3 [44], CN2 <ref> [13] </ref>, and connectionist programs (e.g., [49]). Examples of theory-based programs are explanation-based programs (e.g., [16, 36]) and similarity-based programs that use background knowledge (e.g., [37, 35, 26, 21]). Both types of generalization-based programs have been applied successfully. A case language usually consists of intrinsic, readily perceivable features.
Reference: [14] <author> P. Cohen and A. Howe. </author> <title> How evaluation guides AI research. </title> <journal> The AI Magazine, </journal> <pages> pages 35-43, </pages> <month> Winter </month> <year> 1988. </year>
Reference-contexts: After this training, Protos's classification accuracy was compared with that of clinicians and several learning programs. Protos compared favorably with the best clinician and was significantly better than the other programs. Finally, an "ablation study" <ref> [14] </ref> identified the aspects of Protos that are primarily responsible for its success. Section 5 describes the evaluation. Section 6 summarizes the research. We conclude that exemplar-based learning and classification is appropriate and effective for domains lacking a strong domain theory. <p> To determine the degree to which Protos's high classification accuracy depended on these two types of knowledge, an ablation study <ref> [14] </ref> was conducted in which various combinations of Protos's knowledge were used to classify the audiology test cases. Because this type of study would be very difficult to run on Protos itself, a program, called M-Protos, was constructed specifically for these experiments.
Reference: [15] <author> J.H. Connell and M. Brady. </author> <title> Generating and generalizing models of visual objects. </title> <journal> Artificial Intelligence, </journal> <volume> 31 </volume> <pages> 159-183, </pages> <year> 1987. </year>
Reference-contexts: For example, in a simulated blocks world, the superficial features shape, size, color, and relative position suffice to define generalizations such as arch, stack, and large, red block. In most domains, superficial features do not suffice to define generalizations. Generalizations such as cup [61] and hammer <ref> [15] </ref> are defined in terms of function, not form. Categories such as infected by pseudomonas [53] and seedless grape [2] are generalizations defined in terms that are not readily perceivable in the context of classification.
Reference: [16] <author> G. DeJong and R. Mooney. </author> <title> Explanation-based learning: An alternative view. </title> <journal> Machine Learning, </journal> <volume> 1(2), </volume> <year> 1986. </year>
Reference-contexts: Examples of simple programs are ID3 [44], CN2 [13], and connectionist programs (e.g., [49]). Examples of theory-based programs are explanation-based programs (e.g., <ref> [16, 36] </ref>) and similarity-based programs that use background knowledge (e.g., [37, 35, 26, 21]). Both types of generalization-based programs have been applied successfully. A case language usually consists of intrinsic, readily perceivable features. Such features are called superficial.
Reference: [17] <author> T.G. Dietterich. </author> <booktitle> Annual review of computer science. Machine Learning, </booktitle> <volume> 4, </volume> <year> 1990. </year> <note> (to appear). </note>
Reference-contexts: Small numerical differences in featural importance values, which ought to be negligible, can accumulate during match-strength calculation and distort the similarity estimate. * expert-supplied explanations of relations between concepts can be overly general, and inadvertently "explain away" the significant differences between unrelated cases. (cf. "promiscuous theories" in <ref> [17] </ref>.) By causing the similarity of unrelated cases to be overestimated while causing the similarity of related cases to be accurately estimated, matching knowledge can result in the misclassification of cases that would be correctly classified using a simple feature-counting measure of similarity.
Reference: [18] <author> R.T. Duran. </author> <title> Concept learning with incomplete data sets. </title> <type> Master's thesis, </type> <institution> Department of Computer Science, University of Texas at Austin, </institution> <year> 1988. </year> <note> (Available as technical report AI88-82). </note>
Reference-contexts: In [44], Quinlan describes four ways to adapt ID3 to cope with incomplete case descriptions. Each of these variants of ID3 was implemented, applied to the 200 audiology training cases, and evaluated by classifying the 26 audiology test cases with the resulting decision trees <ref> [18] </ref>. None of the variants of ID3 achieved high classification accuracy. The highest accuracy, a mere 38%, was achieved by treating "missing" as a feature-value. The other variants, which represent various methods of estimating missing features, achieved considerably lower classification accuracies.
Reference: [19] <author> D.L. Dvorak. </author> <title> A guide to CL-Protos: An exemplar-based learning apprentice. </title> <type> Technical Report AI88-87, </type> <institution> Department of Computer Science, University of Texas at Austin, </institution> <year> 1988. </year>
Reference-contexts: Protos's design includes solutions to these two problems. The design principles are introduced with simple, familiar examples and demonstrated with a large-scale application of Protos to clinical audiology. Complete details of Protos are given in [3], and a Common Lisp reconstruction, available for distribution, is documented in <ref> [19] </ref>. 4.1 Simple Exemplar-Based Concept Learning and Classification and identifies the hard problems. Concepts are represented extensionally with a collection of exemplars described with features in the case language.
Reference: [20] <author> P.J. Feltovich, P.E. Johnson, J.H. Moller, </author> <title> and D.B. Swanson. LCS: the role and devel opment of medical knowlege in diagnostic expertise. </title> <editor> In W.J. Clancey and E.H. Short-liffe, editors, </editor> <booktitle> Readings in Medical Artificial Intelligence, </booktitle> <pages> pages 275-319. </pages> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1984. </year>
Reference-contexts: Quinlan claims that "in practice, an ignorance level of even 10% is unlikely" [44, p. 7 From years of teaching, our domain expert believes that novice audiologists frequently rely on unnecessary data. The reliance of novice diagnosticians on unnecessary data has also been reported in formal studies, e.g., <ref> [20] </ref>. 99]. * Missing features are randomly distributed across cases. The methods perform poorly on the audiology data because the data exhibits neither of these properties. The data has an ignorance level exceeding 50%. 8 Furthermore, missing features are not distributed randomly throughout the audiology data set.
Reference: [21] <author> N.S. Flann and T.G. Dietterich. </author> <title> Selecting appropriate representations for learning from examples. </title> <booktitle> Proceedings of AAAI-87, </booktitle> <year> 1987. </year>
Reference-contexts: Examples of simple programs are ID3 [44], CN2 [13], and connectionist programs (e.g., [49]). Examples of theory-based programs are explanation-based programs (e.g., [16, 36]) and similarity-based programs that use background knowledge (e.g., <ref> [37, 35, 26, 21] </ref>). Both types of generalization-based programs have been applied successfully. A case language usually consists of intrinsic, readily perceivable features. Such features are called superficial.
Reference: [22] <author> A.L. Gardner. </author> <title> An Artificial Intelligence Approach to Legal Reasoning. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <year> 1984. </year>
Reference-contexts: Indeed, few domains have perfect domain theories, tractable or otherwise. Legal reasoning, for example, almost always involves open-textured concepts, i.e., concepts having only a weak domain theory <ref> [22, 23] </ref>. The fact that many fields of diagnostic expertise lack a perfect domain theory is indicated by the widespread use of certainty factors in expert systems. When a perfect domain theory does exist, it is often intractable.
Reference: [23] <author> H.L.A. Hart. </author> <title> Positivism and the separation of law and morals. </title> <journal> Harvard Law Review, </journal> <volume> 71 </volume> <pages> 593-629, </pages> <year> 1958. </year>
Reference-contexts: Indeed, few domains have perfect domain theories, tractable or otherwise. Legal reasoning, for example, almost always involves open-textured concepts, i.e., concepts having only a weak domain theory <ref> [22, 23] </ref>. The fact that many fields of diagnostic expertise lack a perfect domain theory is indicated by the widespread use of certainty factors in expert systems. When a perfect domain theory does exist, it is often intractable.
Reference: [24] <author> K.J. Holyoak and A.L. Glass. </author> <title> The role of contradictions and counterexamples in the rejection of false sentences. </title> <journal> Journal of Verbal Learning and Verbal Behavior, </journal> <volume> 14 </volume> <pages> 215-239, </pages> <year> 1975. </year>
Reference-contexts: Tversky and Kahneman [57] found that people estimate the frequency of a class or the probability of an event by their ability to recall instances of the class or event. Holyoak and Glass <ref> [24] </ref> found that people reject false statements by recalling category exemplars for which the statement is untrue. For a range of cognitive tasks, these studies emphasize retaining, recalling, and matching category exemplars, rather than reasoning with category-wide abstractions.
Reference: [25] <author> D. Kibler and D. Aha. </author> <title> Learning representative exemplars of concepts: An initial case study. In Pat Langley, editor, </title> <booktitle> Proceedings of the Fourth International Workshop on Machine Learning, </booktitle> <pages> pages 24-30. </pages> <address> Los Altos: </address> <publisher> Morgan Kaufmann, </publisher> <year> 1987. </year>
Reference-contexts: Although the ignorance level is very high, important features either were given or were inferable. Unimportant features, which may be missing in some cases and present in others, have little effect on the matching process. 5.4 The Classification Accuracy Achieved by Simple Exemplar Based Programs Kibler and Aha <ref> [25] </ref> describe three similarity-based exemplar learning programs, called Proximity, Growth, and Shrink. Like Protos, these programs learn by retaining exemplars, and they classify a test case by assigning it to the category of the exemplar that best matches the test case.
Reference: [26] <author> Y. Kodratoff and J.G. Ganascia. </author> <title> Improving the generalization step in learning. In R.S. </title> <editor> Michalski, J.G. Carbonell, and T.M. Mitchell, editors, </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach, </booktitle> <volume> volume 2, </volume> <pages> pages 215-244. </pages> <address> Los Altos: </address> <publisher> Morgan Kaufmann, </publisher> <year> 1986. </year>
Reference-contexts: Examples of simple programs are ID3 [44], CN2 [13], and connectionist programs (e.g., [49]). Examples of theory-based programs are explanation-based programs (e.g., [16, 36]) and similarity-based programs that use background knowledge (e.g., <ref> [37, 35, 26, 21] </ref>). Both types of generalization-based programs have been applied successfully. A case language usually consists of intrinsic, readily perceivable features. Such features are called superficial.
Reference: [27] <author> J. L. Kolodner. </author> <title> Maintaining organization in a dynamic long-term memory. </title> <journal> Cognitive Science, </journal> <volume> 7(4) </volume> <pages> 243-280, </pages> <year> 1983. </year>
Reference-contexts: This section describes this knowledge, how it is used (see the upper part of Figure 7) and how it is learned (see the lower part of Figure 7). The first type of indexing knowledge, remindings, indexes categories and exemplars by a new case's features (cf., <ref> [50, 27] </ref> and "cue validity" in [45]). Protos uses remindings as cues to the case's classification. A reminding from a feature to a category, such as backrest indexing chair (Figure 8), suggests that the category is the most general classification for cases described with the feature.
Reference: [28] <author> J.L. Kolodner. </author> <title> Extending problem solver capabilities through case-based inference. </title> <booktitle> In Proceedings of the Fourth International Workshop on Machine Learning, </booktitle> <pages> pages 167-178, </pages> <year> 1987. </year>
Reference-contexts: The third type of indexing knowledge, exemplar differences, indexes exemplars by the features that distinguish them from exemplars with similar descriptions (cf., "indexing of failures" in <ref> [54, 28, 29] </ref>). After finding an exemplar that matches a new case, Protos hillclimbs to the best matching exemplar (step 7.8). For example, if the case partially matches chair2, but has the unmatched feature armrests, chair1 is suggested by the exemplar difference relating chair1 to chair2 (Figure 8).
Reference: [29] <author> J.L. Kolodner and R.M. Kolodner. </author> <title> Using experience in clinical problem solving. </title> <type> Tech nical Report GIT-ICS-85/21, </type> <institution> School of Info. and Computer Science, Georgia Institute of Technology, </institution> <year> 1985. </year>
Reference-contexts: The third type of indexing knowledge, exemplar differences, indexes exemplars by the features that distinguish them from exemplars with similar descriptions (cf., "indexing of failures" in <ref> [54, 28, 29] </ref>). After finding an exemplar that matches a new case, Protos hillclimbs to the best matching exemplar (step 7.8). For example, if the case partially matches chair2, but has the unmatched feature armrests, chair1 is suggested by the exemplar difference relating chair1 to chair2 (Figure 8).
Reference: [30] <author> R.S. Mallory. </author> <title> Sources of classification accuracy in Protos. </title> <type> Technical Report AI89-XX, </type> <institution> Department of Computer Science, University of Texas at Austin, </institution> <year> 1989. </year> <month> (forthcoming). </month>
Reference-contexts: And indeed, when the programs were implemented and tested, Shrink and Growth achieved a classification accuracy of 65%, and Proximity achieved a classification accuracy of 77% <ref> [30] </ref>. The method of calculating match strength in Kibler and Aha's programs can be replaced with Protos's method by assuming that no distinct features are equivalent and that all features have the same importance. <p> When this was done, the performance of Shrink and Growth did not change, but Proximity achieved a classification accuracy of only 62% <ref> [30] </ref>. This suggests that the low-level details of Protos's match strength calculation could be improved. 8 Very high ignorance may be quite common in practice. <p> M-Protos differs from Protos in many ways, notably that it cannot acquire knowledge. However, its classification process is sufficiently similar to Protos's that the results of the experiments apply equally to M-Protos and Protos. Details of M-Protos and of the experimental results are given in <ref> [30] </ref>. In the absence of indexing knowledge, M-Protos matches all exemplars with the given test case. In the absence of matching knowledge, M-Protos reduces the match strength a fixed amount for every feature in the exemplar that does not occur in the test case.
Reference: [31] <author> L.T. McCarty and N.S. Sridharan. </author> <title> A computational theory of legal argument. </title> <type> Technical Report LRP-TR-13, </type> <institution> Laboratory for Computer Science Research, Rutgers University, </institution> <year> 1982. </year>
Reference-contexts: A perfect domain theory includes matching knowledge sufficient to match all the members of a category with each other. When this is available, the category can be represented with a single exemplar, called a prototype <ref> [31, 55] </ref>. When a perfect theory is not available, the category can still be represented, fairly accurately, by using several exemplars.
Reference: [32] <author> D.L. Medin, </author> <title> G.I. Dewey, and T.D. Murphy. Relationships between item and category learning: Evidence that abstraction is not automatic. </title> <journal> Journal of Experimental Pyschol-ogy: Learning, Memory and Cognition, </journal> <volume> 9(4) </volume> <pages> 607-625, </pages> <year> 1983. </year>
Reference-contexts: Psychological experiments, devised to distinguish between the generalization-based approach and the exemplar-based approach, support the exemplar-based approach. As in machine learning, early psychological research assumed that generalization was automatic; researchers focused on what is abstracted and how generalization is performed, rather than whether cases are generalized <ref> [32] </ref>. Recent research indicates that people resist generalization and retain cases. For example, Medin [32] and Brooks [9] found that people classify previously seen cases by direct matching. <p> As in machine learning, early psychological research assumed that generalization was automatic; researchers focused on what is abstracted and how generalization is performed, rather than whether cases are generalized <ref> [32] </ref>. Recent research indicates that people resist generalization and retain cases. For example, Medin [32] and Brooks [9] found that people classify previously seen cases by direct matching. Tversky and Kahneman [57] found that people estimate the frequency of a class or the probability of an event by their ability to recall instances of the class or event. <p> A reminding from a feature to an exemplar, such as pedestal indexing chair1 (Figure 8), suggests that the exemplar will match cases described with the feature (cf., "idiosyncratic information" in <ref> [32] </ref>). Each reminding has an associated strength, which is used to order the list of candidate exemplars. When searching for an exemplar that matches a new case, Protos first collects remind-ings to categories (step 7.1 in Figure 7).
Reference: [33] <editor> D.L. Medin and M.M. Schaffer. </editor> <title> Context theory of classification learning. </title> <journal> Psychological Review, </journal> <volume> 85 </volume> <pages> 207-238, </pages> <year> 1978. </year>
Reference-contexts: For a range of cognitive tasks, these studies emphasize retaining, recalling, and matching category exemplars, rather than reasoning with category-wide abstractions. To account for this data, psychological theories propose models involving exemplar-based concept learning and classification <ref> [46, 33, 34, 55, 50] </ref>. The simple exemplar-based method uses no domain theory. However, domain theory is indispensable for solving the hard problems indicated in Figure 2. For example, determining the strength of the match between an exemplar and a case requires knowing the basis for category membership. <p> The first is 8 hi spurious, medium line means moderately important, and thick line means essential.) relations among concepts, for example "seat enables holds (person)." The second type of matching knowledge is featural importances. As defined by Medin and Schaffer <ref> [33] </ref>, this is knowledge of the "differential salience" of an exemplar's features to its category. For example, the wheels feature of chair1 is spurious to the category chair, and the seat feature is essential. Section 4.2.1 describes Protos's acquisition of matching knowledge. <p> The overall match strength is the product of these factors for all of the exemplar's features (cf., the similarity function of Medin and Schaffer's Context Model <ref> [33] </ref>). An important property of this definition of match strength is that matching numerous unimportant features does not compensate for failing to match an important one. Using matching knowledge, the similarity of related cases is more accurately estimated.
Reference: [34] <author> D.L. Medin and E.E. Smith. </author> <title> Concepts and concept formation. </title> <journal> Annual Review of Psychology, </journal> <volume> 35 </volume> <pages> 113-138, </pages> <year> 1984. </year>
Reference-contexts: For a range of cognitive tasks, these studies emphasize retaining, recalling, and matching category exemplars, rather than reasoning with category-wide abstractions. To account for this data, psychological theories propose models involving exemplar-based concept learning and classification <ref> [46, 33, 34, 55, 50] </ref>. The simple exemplar-based method uses no domain theory. However, domain theory is indispensable for solving the hard problems indicated in Figure 2. For example, determining the strength of the match between an exemplar and a case requires knowing the basis for category membership.
Reference: [35] <author> R.S. Michalski. </author> <title> A theory and methodology of inductive learning. In R.S. </title> <editor> Michalski, J.G. Carbonell, and T.M. Mitchell, editors, </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach, volume 1. </booktitle> <address> Palo Alto: </address> <publisher> Tioga Publishing, </publisher> <year> 1983. </year>
Reference-contexts: Examples of simple programs are ID3 [44], CN2 [13], and connectionist programs (e.g., [49]). Examples of theory-based programs are explanation-based programs (e.g., [16, 36]) and similarity-based programs that use background knowledge (e.g., <ref> [37, 35, 26, 21] </ref>). Both types of generalization-based programs have been applied successfully. A case language usually consists of intrinsic, readily perceivable features. Such features are called superficial.
Reference: [36] <author> T.M. Mitchell, R.M. Keller, and S.T. Kedar-Cabelli. </author> <title> Explanation-based generalization: A unifying view. </title> <journal> Machine Learning, </journal> <volume> 1(1) </volume> <pages> 47-80, </pages> <year> 1986. </year> <month> 30 </month>
Reference-contexts: Examples of simple programs are ID3 [44], CN2 [13], and connectionist programs (e.g., [49]). Examples of theory-based programs are explanation-based programs (e.g., <ref> [16, 36] </ref>) and similarity-based programs that use background knowledge (e.g., [37, 35, 26, 21]). Both types of generalization-based programs have been applied successfully. A case language usually consists of intrinsic, readily perceivable features. Such features are called superficial. <p> The developers of theory-based programs have acknowledged this severe limitation <ref> [36] </ref>, and have recently begun trying to adapt their programs to work with weak theories. We anticipate that generalization-based programs will not adapt well to weak theories.
Reference: [37] <author> T.M. Mitchell, P.E. Utgoff, and R. Banerji. </author> <title> Learning by experimentation: Acquiring and refining problem solving heuristics. In R.S. </title> <editor> Michalski, J.G. Carbonell, and T.M. Mitchell, editors, </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach, </booktitle> <volume> volume 1, </volume> <pages> pages 163-190. </pages> <address> Palo Alto: </address> <publisher> Tioga Publishing, </publisher> <year> 1983. </year>
Reference-contexts: Examples of simple programs are ID3 [44], CN2 [13], and connectionist programs (e.g., [49]). Examples of theory-based programs are explanation-based programs (e.g., [16, 36]) and similarity-based programs that use background knowledge (e.g., <ref> [37, 35, 26, 21] </ref>). Both types of generalization-based programs have been applied successfully. A case language usually consists of intrinsic, readily perceivable features. Such features are called superficial.
Reference: [38] <author> J. D. Moore and W.R. Swartout. </author> <title> A reactive approach to explanation. </title> <booktitle> In Fourth Inter national Workshop on Natural Language Generation, </booktitle> <year> 1989. </year>
Reference-contexts: First, explanations are used for only two purposes: to justify classifying a case in a particular way and to establish the degree of similarity of two cases. Explanations are not used to teach domain knowledge or to elaborate previous explanations (see <ref> [10, 38] </ref> for recent research on these tasks).
Reference: [39] <author> G.L. Murphy and D.L. Medin. </author> <title> The role of theories in conceptual coherence. </title> <journal> Psycho logical Review, </journal> <volume> 92 </volume> <pages> 289-316, </pages> <year> 1985. </year>
Reference-contexts: The simple exemplar-based method uses no domain theory. However, domain theory is indispensable for solving the hard problems indicated in Figure 2. For example, determining the strength of the match between an exemplar and a case requires knowing the basis for category membership. Murphy and Medin <ref> [39] </ref> argue that domain theory provides this basis and adds coherence to a collection of otherwise dissimilar exemplars.
Reference: [40] <author> K.S. Murray. KI: </author> <title> An experiment in automating knowledge acquisition. </title> <type> Technical Report AI88-90, </type> <institution> Department of Computer Science, University of Texas at Austin, </institution> <year> 1988. </year>
Reference-contexts: The first shortcoming is that Protos adds new knowledge without considering its relation to existing knowledge. This allows inconsistencies to go undetected until they cause a classification or explanation failure, which is sometimes undesirable. Ken Murray's research <ref> [41, 40] </ref> explores the task of integrating new information into existing knowledge. The second shortcoming of Protos is that it does not adapt its explanations to different users.
Reference: [41] <author> K.S. Murray and B.W. Porter. </author> <title> Developing a tool for knowledge integration: Initial results. </title> <booktitle> In Proceedings of the Third Knowledge Acquisition for Knowledge-based Systems Workshop, </booktitle> <year> 1988. </year>
Reference-contexts: The first shortcoming is that Protos adds new knowledge without considering its relation to existing knowledge. This allows inconsistencies to go undetected until they cause a classification or explanation failure, which is sometimes undesirable. Ken Murray's research <ref> [41, 40] </ref> explores the task of integrating new information into existing knowledge. The second shortcoming of Protos is that it does not adapt its explanations to different users.
Reference: [42] <author> H.P. Nii, E.A. Feigenbaum, J.J. Anton, and A.J. Rockmore. Signal-to-symbol transfor mation: </author> <title> HASP/SIAP case study. </title> <journal> The AI Magazine, </journal> <pages> pages 23-35, </pages> <month> Spring </month> <year> 1982. </year>
Reference-contexts: It determines which features are important for a successful match. If an important feature is absent from the case description, Protos attempts to infer it from the case features using matching knowledge. Unlike the models used by other expectation-driven classifiers <ref> [58, 1, 42] </ref>, exemplars are specific and numerous. Usually, case features and exemplar features match directly, and the range of category exemplars provides models for both typical and atypical cases. Knowledge-based matching is a uniform-cost, heuristic search.
Reference: [43] <author> B. Porter, J. Lester, K. Murray, K. Pittman, A. Souther, L. Acker, and T. Jones. </author> <title> AI research in the context of a multifunctional knowledge base: The Botany Knowledge Base project. </title> <type> Technical Report AI88-88, </type> <institution> Department of Computer Science, University of Texas at Austin, </institution> <year> 1988. </year>
Reference-contexts: The research of Liane Acker, James Lester, and Art Souther [56] explores the generation of coherent explanations that can vary in viewpoint and level of abstraction. This research and Ken Murray's both use a large-scale, multifunctional knowledge base for the domain of plant anatomy, physiology, and development <ref> [43] </ref>. The third shortcoming of 27 Protos is its very restricted explanation language. Karl Branting's research [8] explores the representation and reuse of complex explanations for automated reasoning in weak-theory domains, using as a testbed the domain of Worker's Compensation case law.
Reference: [44] <author> J.R. Quinlan. </author> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1(1) </volume> <pages> 81-106, </pages> <year> 1986. </year>
Reference-contexts: Generalization-based programs are either simple or theory-based, depending on whether the language with which cases are described (called the case language) and the language with which generalizations are expressed (called the generalization language) are closely related or entirely different. Examples of simple programs are ID3 <ref> [44] </ref>, CN2 [13], and connectionist programs (e.g., [49]). Examples of theory-based programs are explanation-based programs (e.g., [16, 36]) and similarity-based programs that use background knowledge (e.g., [37, 35, 26, 21]). Both types of generalization-based programs have been applied successfully. A case language usually consists of intrinsic, readily perceivable features. <p> However, the clinical supervisors found the case descriptions adequate. 7 5.3 The Classification Accuracy Achieved by ID3 The incompleteness of the case descriptions was also an obstacle for ID3, a well-known concept formation program that learns decision trees from examples. In <ref> [44] </ref>, Quinlan describes four ways to adapt ID3 to cope with incomplete case descriptions. Each of these variants of ID3 was implemented, applied to the 200 audiology training cases, and evaluated by classifying the 26 audiology test cases with the resulting decision trees [18]. <p> None of the variants of ID3 achieved high classification accuracy. The highest accuracy, a mere 38%, was achieved by treating "missing" as a feature-value. The other variants, which represent various methods of estimating missing features, achieved considerably lower classification accuracies. In <ref> [44] </ref>, the methods of estimating missing features perform well on data with the following properties: * The percentage of features that are missing, called the "ignorance level," is very small.
Reference: [45] <author> E. Rosch. </author> <title> Principles of categorization. </title> <editor> In E. Rosch and B.B. Lloyd, editors, Cognition and Categorization. </editor> <address> Hillsdale, NJ:Erlbaum, </address> <year> 1978. </year>
Reference-contexts: The first type of indexing knowledge, remindings, indexes categories and exemplars by a new case's features (cf., [50, 27] and "cue validity" in <ref> [45] </ref>). Protos uses remindings as cues to the case's classification. A reminding from a feature to a category, such as backrest indexing chair (Figure 8), suggests that the category is the most general classification for cases described with the feature.
Reference: [46] <author> E. Rosch. </author> <title> Prototype classification and logical classification: The two systems. In E.K. Scholnick, editor, New Trends in Conceptual Representation: Challenges to Piaget's Theory? Hillsdale, </title> <address> NJ:Erlbaum, </address> <year> 1983. </year>
Reference-contexts: For a range of cognitive tasks, these studies emphasize retaining, recalling, and matching category exemplars, rather than reasoning with category-wide abstractions. To account for this data, psychological theories propose models involving exemplar-based concept learning and classification <ref> [46, 33, 34, 55, 50] </ref>. The simple exemplar-based method uses no domain theory. However, domain theory is indispensable for solving the hard problems indicated in Figure 2. For example, determining the strength of the match between an exemplar and a case requires knowing the basis for category membership.
Reference: [47] <author> E. Rosch and C.B. Mervis. </author> <title> Family resemblance: Studies in the internal structure of categories. </title> <journal> Cognitive Psychology, </journal> <volume> 7 </volume> <pages> 573-605, </pages> <year> 1975. </year>
Reference-contexts: With a very weak domain theory, an accurate representation of a category may require many exemplars. The polymorphy of a category is the amount of unexplained variability among the members of a category <ref> [47] </ref>. In domains with a strong theory, the polymorphy of most categories will be low. In domains with a weak theory, the polymorphy of categories can vary considerably (e.g., see Figure 15 in Section 5.1). <p> For example, given a case with remindings to chair but no remindings to particular exemplars, Protos attempts to match the case with chair1 before chair2 (Figure 8). Prototypicality is a heuristic estimate of the psychological notion of "family resemblance" <ref> [47] </ref>, which is the degree to which an exemplar is similar to other category members.
Reference: [48] <author> K. Ruberg, S.M. Cornick, and K.A. James. </author> <title> House calls: Building and maintaining a diagnostic rule-base. </title> <editor> In J.H. Boose and B.R. Gaines, editors, </editor> <booktitle> Proceedings of the 3rd Knowledge Acquisition for Knowledge-Based Systems Workshop. </booktitle> <institution> Computer Science Department, University of Calgary, Canada, </institution> <year> 1988. </year>
Reference-contexts: When this was done, the performance of Shrink and Growth did not change, but Proximity achieved a classification accuracy of only 62% [30]. This suggests that the low-level details of Protos's match strength calculation could be improved. 8 Very high ignorance may be quite common in practice. For example, <ref> [48] </ref> reports a 50% ignorance level. 25 5.5 The Effect of Deleting Knowledge from Protos on Classifica tion Accuracy Protos derived indexing and matching knowledge from the explanations supplied by the expert.
Reference: [49] <editor> D. Rumelhart and J. McClelland, editors. </editor> <booktitle> Parallel Distributed Processing, volume 1. </booktitle> <address> Cambridge, MA: </address> <publisher> MIT Press, </publisher> <year> 1986. </year> <month> 31 </month>
Reference-contexts: Examples of simple programs are ID3 [44], CN2 [13], and connectionist programs (e.g., <ref> [49] </ref>). Examples of theory-based programs are explanation-based programs (e.g., [16, 36]) and similarity-based programs that use background knowledge (e.g., [37, 35, 26, 21]). Both types of generalization-based programs have been applied successfully. A case language usually consists of intrinsic, readily perceivable features. Such features are called superficial.
Reference: [50] <author> R.C. Schank. </author> <title> Dynamic Memory: A Theory of Reminding and Learning in Computers and People. </title> <publisher> Cambridge University Press, </publisher> <year> 1982. </year>
Reference-contexts: For a range of cognitive tasks, these studies emphasize retaining, recalling, and matching category exemplars, rather than reasoning with category-wide abstractions. To account for this data, psychological theories propose models involving exemplar-based concept learning and classification <ref> [46, 33, 34, 55, 50] </ref>. The simple exemplar-based method uses no domain theory. However, domain theory is indispensable for solving the hard problems indicated in Figure 2. For example, determining the strength of the match between an exemplar and a case requires knowing the basis for category membership. <p> This section describes this knowledge, how it is used (see the upper part of Figure 7) and how it is learned (see the lower part of Figure 7). The first type of indexing knowledge, remindings, indexes categories and exemplars by a new case's features (cf., <ref> [50, 27] </ref> and "cue validity" in [45]). Protos uses remindings as cues to the case's classification. A reminding from a feature to a category, such as backrest indexing chair (Figure 8), suggests that the category is the most general classification for cases described with the feature.
Reference: [51] <editor> R.C. Schank, G.C. Collins, and L.E. Hunter. </editor> <booktitle> Transcending inductive category formation in learning. The Behavioral and Brain Sciences, </booktitle> <year> 1986. </year>
Reference-contexts: In summary, generalization-based methods are not likely to perform as well as exemplar-based methods in domains with weak theories. Furthermore, domains with weak theories are far more common, in practical applications, than domains with strong, tractable theories. Other weaknesses of generalization-based methods are given in <ref> [55, 51, 2, 12, 62] </ref>. 6 Given: a set of exemplar-based categories C = fc 1 ; c 2 ; : : : ; c n g and a case (NewCase) to classify.
Reference: [52] <author> A.D. Shapiro. </author> <title> Structured Induction in Expert Systems. </title> <publisher> Addison-Wesley, </publisher> <year> 1987. </year>
Reference-contexts: For example, the rules of chess constitute a perfect, but intractable, theory of "winning position." Even for chess endgames involving very few pieces and analyzed extensively in textbooks, the rules constitute an intractable theory, and the existing tractable theories are far from perfect <ref> [52] </ref>. The developers of theory-based programs have acknowledged this severe limitation [36], and have recently begun trying to adapt their programs to work with weak theories. We anticipate that generalization-based programs will not adapt well to weak theories.
Reference: [53] <institution> E.H. Shortliffe. MYCIN: Computer-Based Medical Consultations. </institution> <address> New York: </address> <publisher> American Elsevier, </publisher> <year> 1976. </year>
Reference-contexts: It is not necessary to mention evidence against the classification or evidence pertaining to other possible classifications. For example, to explain how a particu 2 Terms appear in boldface when they are defined. 3 lar conclusion was reached, Mycin <ref> [53] </ref> lists only the satisfied rules leading to the conclusion; it does not list the rules leading, with less confidence, to different conclusions. Finally, an explanation can be constructed by a simple transformation of the inferential path that leads to a classification. <p> In most domains, superficial features do not suffice to define generalizations. Generalizations such as cup [61] and hammer [15] are defined in terms of function, not form. Categories such as infected by pseudomonas <ref> [53] </ref> and seedless grape [2] are generalizations defined in terms that are not readily perceivable in the context of classification. When abstract features are required to define generalizations, a gap exists between the case language and the generalization language. This gap may be bridged in two ways.
Reference: [54] <author> R.L. Simpson. </author> <title> A Computer Model of Case-Based Reasoning in Problem Solving: An Investigation in the Domain of Dispute Mediation. </title> <type> PhD thesis, </type> <institution> School of Information and Computer Science, Georgia Institute of Technology, </institution> <year> 1985. </year>
Reference-contexts: The third type of indexing knowledge, exemplar differences, indexes exemplars by the features that distinguish them from exemplars with similar descriptions (cf., "indexing of failures" in <ref> [54, 28, 29] </ref>). After finding an exemplar that matches a new case, Protos hillclimbs to the best matching exemplar (step 7.8). For example, if the case partially matches chair2, but has the unmatched feature armrests, chair1 is suggested by the exemplar difference relating chair1 to chair2 (Figure 8).
Reference: [55] <author> E. Smith and D. Medin. </author> <title> Categories and Concepts. </title> <publisher> Cambridge: Harvard University Press, </publisher> <year> 1981. </year>
Reference-contexts: In summary, generalization-based methods are not likely to perform as well as exemplar-based methods in domains with weak theories. Furthermore, domains with weak theories are far more common, in practical applications, than domains with strong, tractable theories. Other weaknesses of generalization-based methods are given in <ref> [55, 51, 2, 12, 62] </ref>. 6 Given: a set of exemplar-based categories C = fc 1 ; c 2 ; : : : ; c n g and a case (NewCase) to classify. <p> For a range of cognitive tasks, these studies emphasize retaining, recalling, and matching category exemplars, rather than reasoning with category-wide abstractions. To account for this data, psychological theories propose models involving exemplar-based concept learning and classification <ref> [46, 33, 34, 55, 50] </ref>. The simple exemplar-based method uses no domain theory. However, domain theory is indispensable for solving the hard problems indicated in Figure 2. For example, determining the strength of the match between an exemplar and a case requires knowing the basis for category membership. <p> A perfect domain theory includes matching knowledge sufficient to match all the members of a category with each other. When this is available, the category can be represented with a single exemplar, called a prototype <ref> [31, 55] </ref>. When a perfect theory is not available, the category can still be represented, fairly accurately, by using several exemplars.
Reference: [56] <author> A. Souther, L. Acker, J. Lester, and B. Porter. </author> <title> Using view types to generate explanations in intelligent tutoring systems. </title> <booktitle> In Proceedings of the Eleventh Cognitive Science Society Conference, </booktitle> <year> 1989. </year>
Reference-contexts: Ken Murray's research [41, 40] explores the task of integrating new information into existing knowledge. The second shortcoming of Protos is that it does not adapt its explanations to different users. The research of Liane Acker, James Lester, and Art Souther <ref> [56] </ref> explores the generation of coherent explanations that can vary in viewpoint and level of abstraction. This research and Ken Murray's both use a large-scale, multifunctional knowledge base for the domain of plant anatomy, physiology, and development [43]. The third shortcoming of 27 Protos is its very restricted explanation language.
Reference: [57] <author> A. Tversky and D. Kahneman. </author> <title> Judgment under uncertainty: Heuristics and biases. </title> <journal> Science, </journal> <volume> 185 </volume> <pages> 1124-1131, </pages> <year> 1974. </year>
Reference-contexts: Recent research indicates that people resist generalization and retain cases. For example, Medin [32] and Brooks [9] found that people classify previously seen cases by direct matching. Tversky and Kahneman <ref> [57] </ref> found that people estimate the frequency of a class or the probability of an event by their ability to recall instances of the class or event. Holyoak and Glass [24] found that people reject false statements by recalling category exemplars for which the statement is untrue.
Reference: [58] <author> S.M. Weiss, A.K. Casimir, and S. Amarel. </author> <title> A model-based method for computer-aided medical decision-making. </title> <journal> Artificial Intelligence, </journal> <volume> 11 </volume> <pages> 145-172, </pages> <year> 1978. </year>
Reference-contexts: It determines which features are important for a successful match. If an important feature is absent from the case description, Protos attempts to infer it from the case features using matching knowledge. Unlike the models used by other expectation-driven classifiers <ref> [58, 1, 42] </ref>, exemplars are specific and numerous. Usually, case features and exemplar features match directly, and the range of category exemplars provides models for both typical and atypical cases. Knowledge-based matching is a uniform-cost, heuristic search.
Reference: [59] <editor> M.R. Wick, C.L. Paris, W.R. Swartout, and W.B. Thompson, editors. </editor> <booktitle> Proceedings of the AAAI'88 Workshop on Explanation. American Association for Artificial Intelligence, </booktitle> <year> 1988. </year>
Reference-contexts: Explanation, in the broadest sense, includes a variety of inference methods for reasoning, learning, and communicating <ref> [59] </ref>. However, we have adopted a simplified notion of explanation in order to concentrate on other aspects of the task. The main simplifying assumptions, similar to those made in first-generation expert systems, are as follows.
Reference: [60] <author> P.H. Winston. </author> <title> Learning structural descriptions from examples. </title> <editor> In P.H. Winston, editor, </editor> <booktitle> The Psychology of Computer Vision, </booktitle> <pages> pages 157-209. </pages> <publisher> McGraw-Hill, </publisher> <year> 1975. </year>
Reference-contexts: For example, if the case partially matches chair2, but has the unmatched feature armrests, chair1 is suggested by the exemplar difference relating chair1 to chair2 (Figure 8). Protos learns an exemplar difference by matching a new case to a "near miss" <ref> [60] </ref> before matching the case to an exemplar preferred by the expert (step 7.12). The near miss and the preferred exemplar may be members of the same category or different categories. Protos 17 relates them by their differences to improve classification accuracy on subsequent cases.
Reference: [61] <author> P.H. Winston, T.O. Binford, B. Katz, and M. Lowry. </author> <title> Learning physical descriptions from functional definitions, examples, and precedents. </title> <booktitle> Proceedings of AAAI-83, </booktitle> <pages> pages 433-439, </pages> <year> 1983. </year>
Reference-contexts: For example, in a simulated blocks world, the superficial features shape, size, color, and relative position suffice to define generalizations such as arch, stack, and large, red block. In most domains, superficial features do not suffice to define generalizations. Generalizations such as cup <ref> [61] </ref> and hammer [15] are defined in terms of function, not form. Categories such as infected by pseudomonas [53] and seedless grape [2] are generalizations defined in terms that are not readily perceivable in the context of classification.
Reference: [62] <author> L. Wittgenstein. </author> <title> Philosophical Investigations. </title> <address> New York: </address> <publisher> MacMillan, </publisher> <year> 1953. </year> <month> 32 </month>
Reference-contexts: In summary, generalization-based methods are not likely to perform as well as exemplar-based methods in domains with weak theories. Furthermore, domains with weak theories are far more common, in practical applications, than domains with strong, tractable theories. Other weaknesses of generalization-based methods are given in <ref> [55, 51, 2, 12, 62] </ref>. 6 Given: a set of exemplar-based categories C = fc 1 ; c 2 ; : : : ; c n g and a case (NewCase) to classify.
References-found: 62

