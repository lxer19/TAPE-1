URL: ftp://speech.cse.ogi.edu/pub/docs/voice_dial-7-95.ps
Refering-URL: http://www.cse.ogi.edu/CSLU/publications/publications.html
Root-URL: http://www.cse.ogi.edu
Title: A New Approach to Voice Dialing  
Author: Neena Jain 
Degree: B.Tech., Indian Institute of Technology, Bombay, India, 1992 A thesis submitted to the faculty of the Oregon Graduate Institute of Science Technology in partial fulfillment of the requirements for the degree Master of Science in Electrical Engineering  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Jun Noguchi, Shinsuke Sakai, Kaichiro Hatazaki, Ken-ichi Iso and Takoe Watanabe. </author> <title> An Automatic Voice Dialing System developed on PC Speech I/O Platform. </title> <booktitle> In Proceedings of the International Conference on Spoken Language Processing, </booktitle> <volume> volume 2, </volume> <pages> pages 699-702, </pages> <address> Yokohama, Japan, </address> <month> September </month> <year> 1994. </year> <journal> The Acoustical Society of Japan. </journal>
Reference-contexts: Nynex, Sprint and Cellular One are few of the companies which offer this service. Since this is a commercial application, there is very little literature available on the algorithms used in these voice dialing systems. Noguchi <ref> [1] </ref> has described a voice dialing system for PC based platforms. This system requires entries in the database in the form of Kana characters. A speaker independent speech recognizer is used for recognizing the speech.
Reference: [2] <author> D. Geller, R. Haeb-Umbach and H. Ney. </author> <title> Improvements in speech recognition for voice dialing in the car environment. </title> <booktitle> Proceedings of Speech Processing in Adverse Conditions, </booktitle> <pages> pages 203-206, </pages> <month> November </month> <year> 1992. </year>
Reference-contexts: A speaker independent speech recognizer is used for recognizing the speech. The main drawback of this system is that it can work only for the Japanese language wherein the pronunciation can be obtained directly from the Kana characters. Geller <ref> [2] </ref> has described a voice dialing system for the car environment. The main focus of this system was to suppress noise in vehicles. It is based on whole-word Hidden Markov Models (HMM).
Reference: [3] <author> L. R. Rabiner and J. G. Wilpon. </author> <title> Some performance benchmarks for isolated word speech recognition systems. </title> <booktitle> Computer Speech and Language, </booktitle> <volume> 2 </volume> <pages> 343-357, </pages> <year> 1987. </year>
Reference-contexts: This system requires about 1280 floating point numbers to represent each word. 3 1.4 The Approach Traditional speaker dependent recognition systems are based on parameters derived from the acoustic signal <ref> [3] </ref>. The approach presented in this thesis uses the symbolic string produced by a speech recognizer to represent the word or phrase. The user decides the set of words or phrases to be used. <p> In a system used by millions of people storage becomes a critical issue; the more parameters needed to represent word models, the more storage is required. Storage is expensive, both because more disk space is needed, and because more data must be accessed quickly. Small vocabulary speaker dependent systems <ref> [3] </ref> typically use about 12 LPC coefficients for every 10 msec of speech. Hence for one second of speech, 19.2 K bits are needed (assuming 16 bits are needed to represent each floating point number). <p> This lead to rejection of about 15% of the utterances. 22 3.4 Comparison with DTW Dynamic Time Warping (DTW) with LPC features can be considered as one of the state-of-the art classification systems for speaker dependent recognition <ref> [3] </ref>. DTW is a very efficient method of achieving non-linear normalization of the time axis of the speech signal [11].
Reference: [4] <author> Ronald Cole, David G. Novick, Mark Fanty, Pieter Vermeulen, Stephen Sutton, Dan Burnett and Johan Schalkwyk. </author> <title> A prototype Voice-Response Questionnaire for the U.S. Census. </title> <booktitle> In Proceedings of the International Conference on Spoken Language Processing, </booktitle> <volume> volume 2, </volume> <pages> pages 683-686, </pages> <address> Yokohama, Japan, </address> <month> September </month> <year> 1994. </year> <journal> The Acoustical Society of Japan. </journal>
Reference-contexts: The speaker independent recognizers are used for fixed vocabulary recognition. During registration, speaker independent recognizers are used for yes-no type recognition to confirm answers and for digit recognition of phone numbers associated with the labels. These recognizers were developed at CSLU <ref> [4] </ref> and a detailed description is beyond the scope of this thesis. A Speaker dependent system uses the speaker's voice to recognize speech. Typically, this process involves creating word models based on acoustic parameters of the speaker's words.
Reference: [5] <author> Jay Naik. </author> <title> Speaker verification over the telephone network: Databases, algorithms and performance assessment. In ESCA Workshop on Automatic Speaker Recognition, </title> <booktitle> Identification and Verification, </booktitle> <pages> pages 31-37, </pages> <address> Martigny, Switzerland, </address> <month> April </month> <year> 1994. </year> <institution> Ger-ard Chollet, IDIAP Research Center, Case Postale 609, CH-1920 Martigny, Switzer-land (esca@idiap.ch). </institution>
Reference-contexts: Since the voice dialing system accesses an individual's database and dials out, it is important to prevent fraudulent use of this service. Speaker verification offers a unique way of performing personal identification verification (PIV) <ref> [5] </ref> over the telephone network because: 1. it is based on a specific user's voice which is suitable for a telephone based system. 2. it can co-exist with speech recognition systems. 3. user preference is higher than other biometric verificators. 4. different levels of security can be easily achieved through different <p> Smaller training period is another advantage of a fixed-text system. In this thesis, only fixed-text systems have been investigated. 4.2.2 Existing Verification Systems There are a variety of speaker verification systems reported in literature with very low equal error rates. References [13], <ref> [5] </ref> and [14] provide detailed reviews of the existing speaker verification systems.
Reference: [6] <author> Hynek Hermansky. </author> <title> Perceptual linear predictive (PLP) analysis of speech. </title> <journal> Journal of Acoustical Society of America, </journal> <volume> 87(4) </volume> <pages> 1738-1752, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: Endpoint detection helps in removing the unnecessary silence before and after the label. 2. Feature Extraction The next step is to generate features for each 6 msec time frame. This is done by extracting PLP <ref> [6] </ref> coefficients from each frame of the chopped waveform. Seventh order PLP coefficients along with logarithm of energy are computed for each frame. The analysis window size is 10 msec. Two features corresponding to voicing are also computed. <p> It can be concluded that the LPC gives higher performance than PLP. This is expected since PLP has been designed to smooth over the speaker dependent features <ref> [6] </ref>. 36 It is observed that the method of averaging features over the interval of the phoneme leads to a better performance than the method of picking a particular frame. Stressed vowels are more distinguishing than nasals or other unstressed vowels (given this system).
Reference: [7] <author> E. Barnard and R. A. Cole. </author> <title> A neural-net training program based on conjugate-gradient optimization. </title> <type> Technical Report CSE, </type> <institution> Oregon Graduate Institute of Science and Technology, </institution> <month> 89(014), July </month> <year> 1989. </year>
Reference-contexts: The multi-layer Perceptron (MLP) is a feed forward network with one or more hidden layers. A weight is attached to each connection between the neurons. A three layered MLP trained with the conjugate-gradient optimization algorithm <ref> [7] </ref> was used to assign phoneme scores to each individual time frame. The OGI stories database [8] was used for training this MLP. A total of 39 phonemes were used for representing speech. The exact details of the training and the architecture are described in [9].
Reference: [8] <author> Ronald Cole , Mark Fanty , Mike Noel and Terri Lander. </author> <title> Telephone Speech Corpus Development at CSLU. </title> <booktitle> In Proceedings of the International Conference on Spoken 45 46 Language Processing, </booktitle> <volume> volume 4, </volume> <pages> pages 1815-1818, </pages> <address> Yokohama, Japan, </address> <month> September </month> <year> 1994. </year> <journal> The Acoustical Society of Japan. </journal>
Reference-contexts: A weight is attached to each connection between the neurons. A three layered MLP trained with the conjugate-gradient optimization algorithm [7] was used to assign phoneme scores to each individual time frame. The OGI stories database <ref> [8] </ref> was used for training this MLP. A total of 39 phonemes were used for representing speech. The exact details of the training and the architecture are described in [9]. <p> A general English bigram grammar is used in this system. This grammar consists of the probabilities of each of the 39 phonemes being followed by each other. These transition values were computed from the large phonetically labelled OGI stories database <ref> [8] </ref>. The minimum and maximum durations of each phoneme are also used for constraining the search. The Viterbi search algorithm uses the grammar and the duration constraints to find the maximum scoring phonetic sequence given the frame-by-frame output scores. <p> In the second system, 20th order LPC cepstral coefficients were computed for every 10 msec of speech. These were then quantized by using Vector Quantization [12]. The code-book used for quantizing was generated by using the OGI stories database <ref> [8] </ref>. 2 different codebooks were used for quantizing the lower and the upper 10 LPC coefficients. The size of each of the codebooks was 512. The quantized vectors were used to build the reference templates for each label. During testing, the unknown speech vector was quantized using the same codebook.
Reference: [9] <author> Li Jiang. </author> <title> Neural network based context-dependent modelling for speech recognition. </title> <institution> Research Proficiency Report, Department of Computer Science and Engineering, Ore-gon Graduate Institute of Science and Technology, </institution> <month> May </month> <year> 1994. </year>
Reference-contexts: The OGI stories database [8] was used for training this MLP. A total of 39 phonemes were used for representing speech. The exact details of the training and the architecture are described in <ref> [9] </ref>. The 70 features corresponding to each frame are given as input to the MLP and output values for each phoneme are recorded. 13 These values represent the probability of the frame being in a certain phonetic state [10]. 4.
Reference: [10] <author> Boulard H. and Wellekens C. J. </author> <title> Links between markov models and multi-layer perceptrons. </title> <journal> IEEE Trans. Pattern Analysis and Machine Intelligence, </journal> <volume> 12(12) </volume> <pages> 1167-1178, </pages> <month> December </month> <year> 1990. </year>
Reference-contexts: The 70 features corresponding to each frame are given as input to the MLP and output values for each phoneme are recorded. 13 These values represent the probability of the frame being in a certain phonetic state <ref> [10] </ref>. 4. Search A Viterbi search is used for generating the phonetic string for each spoken word or phrase. The Viterbi search maps frame scores to phonemes. It is constrained in two ways bigram grammar and duration. A general English bigram grammar is used in this system.
Reference: [11] <author> H. Sakoe and S. Chiba. </author> <title> Dynamic programming algorithm optimization for spoken word recognition. </title> <journal> IEEE Trans. of Acoustics, Speech and Signal Proc., </journal> <volume> ASSP-26:43-49, </volume> <month> February </month> <year> 1978. </year>
Reference-contexts: DTW is a very efficient method of achieving non-linear normalization of the time axis of the speech signal <ref> [11] </ref>. This non-linear normalization is important because of the fluctuations in the speaking rate within a speaker. 2 systems based on DTW with LPC coefficients were developed to observe the trade-offs in recognition accuracy with number of parameters used. <p> It was decided to use Euclidean distance to measure the distance between the reference feature vector and the test feature vector. In the case of larger number of segments, some experiments were also performed with DTW <ref> [11] </ref> as a matching tool. The following sections indicate the effects of these various parameters. Effect of number of segments The aim of this experiment was to examine the effect of the number of segments on the performance.
Reference: [12] <author> J. H. Juang, D. Y. Wong and A. H. </author> <title> Gray . Distortion performance of vector quantization for lpc voice coding. </title> <journal> IEEE Trans. of Acoustics, Speech and Signal Proc., </journal> <volume> ASSP-30(2):294-304, </volume> <month> April </month> <year> 1982. </year>
Reference-contexts: The reference template with the best match ie: the smallest distance was declared as the output of the recognition system. In the second system, 20th order LPC cepstral coefficients were computed for every 10 msec of speech. These were then quantized by using Vector Quantization <ref> [12] </ref>. The code-book used for quantizing was generated by using the OGI stories database [8]. 2 different codebooks were used for quantizing the lower and the upper 10 LPC coefficients. The size of each of the codebooks was 512.
Reference: [13] <author> Sadaoki Furui. </author> <title> An overview of speaker recognition technology. In ESCA Workshop on Automatic Speaker Recognition, </title> <booktitle> Identification and Verification, </booktitle> <pages> pages 1-9, </pages> <address> Martigny, Switzerland, </address> <month> April </month> <year> 1994. </year> <type> Gerard Chollet, </type> <institution> IDIAP Research Center, Case Postale 609, CH-1920 Martigny, Switzerland (esca@idiap.ch). </institution>
Reference-contexts: Smaller training period is another advantage of a fixed-text system. In this thesis, only fixed-text systems have been investigated. 4.2.2 Existing Verification Systems There are a variety of speaker verification systems reported in literature with very low equal error rates. References <ref> [13] </ref>, [5] and [14] provide detailed reviews of the existing speaker verification systems. <p> The receiver operating characteristics (ROC) can be used for assigning this threshold. The ROC curve is obtained by assigning two probabilities, the probability of correct acceptance and the probability of incorrect acceptance, to the vertical and horizontal axes respectively, and varying the decision threshold <ref> [13] </ref>. In this thesis, the EER has been used as a measure of performance. There are three different results to be considered. 1. Acceptance of correct speaker using the correct codeword. 41 2. Rejection of incorrect speaker using the correct codeword. 3. Rejection of incorrect speaker using an incorrect codeword. <p> In practice, there are only 3 examples of the speaker saying the password. The speaker-specific threshold cannot be reliably estimated from 3 speech files and hence have not been used. Normalization of scores has shown significant improvement <ref> [13] </ref>, [17] since it reduces the variations across channels and hand sets. This normalization was done using "cohort" groups in a text dependent SVS using a combination of only digits as the password. The "cohort" group consists of speakers whose models are close to the claimed identity.
Reference: [14] <author> Frederic Bimbot, Gerard Chollet and Andrea Paolini. </author> <title> Assessment methodology for speaker verification and identification systems. In ESCA Workshop on Automatic Speaker Recognition, </title> <booktitle> Identification and Verification, </booktitle> <pages> pages 75-82, </pages> <address> Martigny, Switzer-land, </address> <month> April </month> <year> 1994. </year> <type> Gerard Chollet, </type> <institution> IDIAP Research Center, Case Postale 609, CH-1920 Martigny, Switzerland (esca@idiap.ch). </institution>
Reference-contexts: Smaller training period is another advantage of a fixed-text system. In this thesis, only fixed-text systems have been investigated. 4.2.2 Existing Verification Systems There are a variety of speaker verification systems reported in literature with very low equal error rates. References [13], [5] and <ref> [14] </ref> provide detailed reviews of the existing speaker verification systems.
Reference: [15] <author> J. P. Eatock and J. S. Mason. </author> <title> A quantitative assessment of the relative speaker discriminating properties of phonemes. </title> <booktitle> In IEEE Proceedings of International Conference on Acoustics, Speech and Signal Proc., </booktitle> <volume> volume 1, </volume> <pages> pages 133-136, </pages> <address> Adelaide, Australia, April 1994. Piscataway, N.J., </address> <publisher> IEEE. </publisher>
Reference-contexts: Each human being has a unique characteristic way of saying phonemes. Some phonemes have been shown to be more distinguishing than others <ref> [15] </ref>, [16]. The aim of this approach is to use these distinguishing phonemes for verification. During training, the phonetic string representing the password is obtained by the general purpose neural net classifier as described in chapter 3. <p> Effect of type of phonemes The aim of this experiment was to decide which group of phonemes should be used for representing the speaker. Since nasals and vowels have been shown to be more distinguishing than other phonemes <ref> [15] </ref>, certain sub-classes of phonemes were selected for representing the speaker.
Reference: [16] <author> Eluned S. Parris and Michael J. Carey. </author> <title> Discriminative phonemes for speaker identification. </title> <booktitle> In Proceedings of the International Conference on Spoken Language Processing, </booktitle> <volume> volume 4, </volume> <pages> pages 1843-1846, </pages> <address> Yokohama, Japan, </address> <month> September </month> <year> 1994. </year> <journal> The Acoustical Society of Japan. </journal>
Reference-contexts: Each human being has a unique characteristic way of saying phonemes. Some phonemes have been shown to be more distinguishing than others [15], <ref> [16] </ref>. The aim of this approach is to use these distinguishing phonemes for verification. During training, the phonetic string representing the password is obtained by the general purpose neural net classifier as described in chapter 3.
Reference: [17] <author> A. E. Rosenberg, Joel DeLong, Chin-Hui Lee, Biing-Hwang Juang and Frank K. Soong. </author> <title> The use of cohort normalized scores for speaker verification. </title> <booktitle> In Proceedings 47 of the International Conference on Spoken Language Processing, </booktitle> <volume> volume 1, </volume> <pages> pages 599-602, </pages> <address> Banff, Canada, </address> <month> September </month> <year> 1992. </year> <institution> University of Alberta. </institution>
Reference-contexts: In practice, there are only 3 examples of the speaker saying the password. The speaker-specific threshold cannot be reliably estimated from 3 speech files and hence have not been used. Normalization of scores has shown significant improvement [13], <ref> [17] </ref> since it reduces the variations across channels and hand sets. This normalization was done using "cohort" groups in a text dependent SVS using a combination of only digits as the password. The "cohort" group consists of speakers whose models are close to the claimed identity.
Reference: [18] <author> Sadaoki Furui. </author> <title> Cepstral analysis technique for automatic speaker verification. </title> <journal> IEEE Trans. of Acoustic, Speech and Signal Proc., </journal> <volume> 29(2) </volume> <pages> 254-272, </pages> <year> 1981. </year>
Reference-contexts: The models of these "cohort" speakers are used for normalizing the verification score before comparing with a threshold. This technique could not be used since the proposed system is text-dependent with no restrictions on the choice of the password. Normalization performed in the parameter domain, spectral equalization, <ref> [18] </ref> has been shown to be effective for text-dependent SVS based on long utterances. This normalization could not be performed in the proposed system because the utterances are short (less than a second).
Reference: [19] <author> L. R. Rabiner and B. Juang. </author> <title> Fundamentals of Speech Recognition. </title> <address> New York, </address> <publisher> Prentice Hall, </publisher> <year> 1993. </year>
Reference: [20] <author> C. Myers, L. R. Rabiner and A. E. Rosenberg. </author> <title> Performance tradeoffs in dynamic time warping algorithms for isolated word recognition. </title> <journal> IEEE Trans. of Acoustics, Speech and Signal Proc., </journal> <volume> ASSP-28(6):623-635, </volume> <month> December </month> <year> 1980. </year>
Reference: [21] <author> Alex Waibel and Kai-Fu Lee. </author> <title> Readings in Speech Recognition. </title> <address> San Francisco, </address> <publisher> Morgan Kaufmann Publishers,Inc, </publisher> <year> 1990. </year>
References-found: 21

