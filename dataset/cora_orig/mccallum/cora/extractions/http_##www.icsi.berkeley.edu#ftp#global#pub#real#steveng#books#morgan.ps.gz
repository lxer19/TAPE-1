URL: http://www.icsi.berkeley.edu/ftp/global/pub/real/steveng/books/morgan.ps.gz
Refering-URL: http://www.icsi.berkeley.edu/ftp/global/pub/real/steveng/books/
Root-URL: http://www.icsi.berkeley.edu
Title: Chapter 8 Auditory-Based Strategies for ASR  
Note: 8.1 Overview  
Abstract: Caveat to the Reader: This is a VERY PRELIMINARY DRAFT. It comes from the writings of 3 authors (Morgan, Hermansky, and Bourlard), and there is still significant work required smoothing, references, figures, etc. all need revision. Still, the basic content probably does not differ substantially from the final chapter. In this chapter we establish the general characteristics of the difficulties of automatic speech recognition (ASR), describe speech representations that have been used for this problem, with a special focus on measures that are in some sense modeled on the human auditory system, explore some issues in the application of these measures in complete speech recognition systems, and end with conclusions and directions for the future. Speech recognition systems have been designed by engineers for over 40 years. The performance of these systems has improved significantly in this period, and often can be usefully applied to significant real-world tasks (for instance, the AT&T 5-word recognizer that is used to recognize words such as "operator"). However, they are still primitive in comparison with the human example, and even the best of them still degrades significantly under realistic conditions that are handled quite well by humans. Listeners can readily understand speech on an arbitrary 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Abeles, M., </author> <title> Corticonics Neural Circuits of the Cerebral Cortex," </title> <publisher> Cambridge University Press, </publisher> <year> 1991. </year>
Reference-contexts: For a description of biological neural networks, see <ref> [1] </ref>; for a good discussion of ANNs as used for pattern recognition, see [8, 99]. The initial way of using ANNs for classification problems was to consider the ANN as general, nonlinear, form of discriminant function.
Reference: [2] <author> Aikawa, K., Singer, H., Kawahara, H., & Tohkura, Y., </author> <title> "A dynamic cepstrum incorporating time-frequency masking and its application to continuous speech recognition," </title> <booktitle> Proc. IEEE Intl. Conf. on Acoustics, Speech, & Signal Processing (Minneapolis, MN), </booktitle> <pages> pp. </pages> <address> II-668-671, </address> <year> 1993. </year>
Reference-contexts: More recently, techniques such as Multi-Vector Input [80] combined either with MLP [13, 70, 108] or with Linear Discriminant Analysis (LDA) [68], [20],[48], Dynamic (Delta) Features [41], RASTA Processing [59], short-term cepstral mean removal [101], Dynamic Cepstrum <ref> [2] </ref>, or Probabilistic Optimum Filtering [87], are emerging as a post-processing techniques which operate on a sequences of the short-term feature vectors. The strength of such approaches may lie in their expansion of the "local" view of speech to that segmental blocks that range from phonetic to syllabic lengths.
Reference: [3] <author> Aitkin, L., Dunlop, C., and Webster, W., </author> <title> "Click-evoked response patterns of single units in the medial geniculate body of the cat," </title> <journal> Journal of Neurophysiology, </journal> <volume> vol. 29, </volume> <pages> pp. 109-123, </pages> <year> 1966. </year>
Reference-contexts: On top of obvious engineering reasons, it indeed appears that the short-term memory of the auditory periphery in mammals (exhibited, e.g., by forward masking (see, 8.5. ISSUES IN ASR SYSTEMS 33 e.g., [111]), the firing rate adaptation constant (see, e.g., <ref> [3] </ref>), and the buildup of loudness (see, e.g., [107])) is at least of the order of about 200 ms. This means that the peripheral human auditory system can effectively integrate rather large (about syllable sized) time-spans of the audio signal.
Reference: [4] <author> Allen, J.B., </author> <title> "How do humans process and recognize speech?," </title> <journal> IEEE Trans. on Speech and Audio Processing, </journal> <volume> vol. 2, no. 4, pp.567-577, </volume> <year> 1994. </year>
Reference-contexts: Such a scheme may have fundamental limitations. Different approaches to alleviate this problem are currently investigated and are briefly discussed below. Across-time vs across-frequency analysis The work of Fletcher and his colleagues [38] (see the insightful review of his work in <ref> [4] </ref>) suggest that the decoding of the linguistic message is based on decisions within narrow frequency bands that are processed quite independently of each other.
Reference: [5] <author> Applebaum, T.H. and Hanson, </author> <title> B.A., "Regression features for recognition of speech in quiet and in noise," </title> <booktitle> Proc. IEEE Intl. Conf. on Acoustics, Speech, and Signal Processing (Toronto, Canada), </booktitle> <pages> pp. 985-959, </pages> <year> 1991. </year>
Reference-contexts: Depending on the task, the optimal time spans on which those delta features are computed vary between 50 ms [42] and 200 ms <ref> [5] </ref> This success may be attributed to the fact that dynamic features contribute new information that was previously unavailable to the pattern classification component of an ASR system: the information about the surroundings of the current short-term segment. 2.
Reference: [6] <author> Arai, T., M. Pavel, H. Hermansky, and C. Avendano: </author> <title> "Perception of Speech With High-Passed. Low-Passed, and Band-Passed Spectral Envelopes", </title> <booktitle> to be published in Proc. Intl. Conf. on Spoken Language Processing 96 (Philadephia, </booktitle> <address> PA), </address> <year> 1996. </year>
Reference-contexts: In related work, As noteed above, Drullman [30, 31] recently found dominance of the modulation frequencies around 4-6 Hz for speech communication. Inspired by Drullman's experiments, Arai et al. <ref> [6] </ref> have initiated series of similar experiments 8.3. ACOUSTIC ANALYSIS IN ASR 17 using slightly different signal processing paradigm which are based on the residual-excited LPC vocoder and aiming for band-pass processing of trajectories of spectral envelopes [6]. Their results, shown in Fig. 8.4 , confirm and extend Drullman's. <p> Inspired by Drullman's experiments, Arai et al. <ref> [6] </ref> have initiated series of similar experiments 8.3. ACOUSTIC ANALYSIS IN ASR 17 using slightly different signal processing paradigm which are based on the residual-excited LPC vocoder and aiming for band-pass processing of trajectories of spectral envelopes [6]. Their results, shown in Fig. 8.4 , confirm and extend Drullman's.
Reference: [7] <author> Avendano, C., S. van Vureen, and H. Hermansky: </author> <title> "Optimizing RASTA Filters on Corrupted Speech," </title> <booktitle> to be published in Proc. Intl. Conf. on Spoken Language Processing 96 (Philade-phia, </booktitle> <address> PA), </address> <year> 1996. </year> <note> 53 54 BIBLIOGRAPHY </note>
Reference-contexts: Results, shown in Fig.8.7, are consistent with data from human forward masking experiments, including the nonlinearity with respect to masker amplitude. In a related set of experiments reported in <ref> [7] </ref>, linear discriminant analysis (LDA) was used to design an optimal set of RASTA-like filters to maximize discriminability between phoneme classes in TIMIT, NTIMIT, and NTIMIT transmitted through a cellular telephony system.
Reference: [8] <author> Bishop, </author> <title> C.M., Neural Networks for Pattern Classification, </title> <publisher> Claren-don Press Oxford, </publisher> <year> 1995. </year>
Reference-contexts: For a description of biological neural networks, see [1]; for a good discussion of ANNs as used for pattern recognition, see <ref> [8, 99] </ref>. The initial way of using ANNs for classification problems was to consider the ANN as general, nonlinear, form of discriminant function. Furthermore, ANNs have also been proved to be able, in theory, to generate any nonlinear regression functions. <p> For early discussion of this, see [11, 96]; for a deeper treatment of ANNs for statistical pattern recognition, see <ref> [8, 99] </ref>. In this case, there is typically one ANN output unit for each possible 28 CHAPTER 8. AUDITORY-BASED STRATEGIES FOR ASR class of = f! 1 ; : : : ; ! k ; : : : ; ! K g.
Reference: [9] <author> Bladon, A. and G. </author> <title> Fant( 1978): A two-formant model and the cardinal vowels, </title> <type> STL-QPRS 1, 1-8, </type> <institution> Royal Institute of Technology, Stock-holm. </institution>
Reference-contexts: ACOUSTIC ANALYSIS IN ASR 15 3-4 Bark spectral bands, therefore being capable of merging several speech formants. * Itahashi and Yokoyama [69] found that a second spectral peak of the three-peak (6th order) Mel-LPC model is a good approximation to the perceptual effective second formant F2' <ref> [9] </ref>. * Similarly to Mel-LPC, the 5th order PLP analysis of 18 synthetic cardinal vowels yields results which agree well with Bladon's and Fant's perceptual experiments [55].
Reference: [10] <author> Bladon, A.W. </author> <year> (1983): </year> <title> Two-formant models of vowel perception: shortcomings and enhancements, </title> <booktitle> Speech Communication 2, </booktitle> <pages> pp. 305-313, </pages> <year> 1983. </year>
Reference-contexts: Moreover, the bandwidths of the PLP model preserve information about spread of the underlying formant clusters, thus alleviating a fundamental objection <ref> [39, 10] </ref> to the F2' concept (see [55] for evidence and discussion). * Hermansky and Broad [61, 19] speculate that one of the reasons for the intelligibility of child speech might be the ability of human speech perception to simplify formant structure, as well as to focus on global and less
Reference: [11] <author> Bourlard, H., and Wellekens, C.J., </author> <title> "Links between Markov models and multilayer perceptrons," </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, </journal> <volume> vol. 12, no. 12, </volume> <pages> pp. 1167-1178, </pages> <year> 1990. </year>
Reference-contexts: However, in the late 1980's, it was shown (and, probably, "redicov-ered") that another more general and more powerful approach was to use ANNs as estimators of the posterior probabilities of class membership. For early discussion of this, see <ref> [11, 96] </ref>; for a deeper treatment of ANNs for statistical pattern recognition, see [8, 99]. In this case, there is typically one ANN output unit for each possible 28 CHAPTER 8. <p> This conclusion has been confirmed experimentally and was an important link between HMMs and ANNs <ref> [11] </ref>. Several ANNs have been studied to solve sub-tasks of the ASR problem. However, none of these approaches could address the problem of continuous speech recognition and of time alignment (and segmentation, when required), which is efficiently solved by HMMs and dynamic programming.
Reference: [12] <author> H. Bourlard and S. Dupont: </author> <title> "A new ASR approach based on independent processing and re-combination of partial frequency bands," </title> <booktitle> Proc. </booktitle> <address> ICSLP96, </address> <month> October </month> <year> 1996 </year>
Reference: [13] <author> Bourlard, H. and Morgan, N., </author> <title> Connectionist Speech Recognition </title> - 
Reference-contexts: The main emphasis in these models seemed to be on relatively short-term temporal phenomena. More recently, techniques such as Multi-Vector Input [80] combined either with MLP <ref> [13, 70, 108] </ref> or with Linear Discriminant Analysis (LDA) [68], [20],[48], Dynamic (Delta) Features [41], RASTA Processing [59], short-term cepstral mean removal [101], Dynamic Cepstrum [2], or Probabilistic Optimum Filtering [87], are emerging as a post-processing techniques which operate on a sequences of the short-term feature vectors. <p> STATISTICAL SPEECH RECOGNITION 23 Parametrization and Likelihood Estimation Starting from the general formulation of HMMs, one has first to identify the assumptions that are necessary to define a useful parameter set to make the computation of P (XjM ) feasible. It can be shown that, provided several assumptions <ref> [13] </ref>, the (global) probability P (XjM ) can be expressed and computed in terms of (local) probabilities p (x n j!(q j )) and p (q j jq i ), respectively referred to as emission and transition probabilities. <p> For a good earlier review of the different approaches using neural networks for speech recognition, see [77]. For a more recent (though personal) perspective, see <ref> [13] </ref> or [83]. For a good overview of ANNs for speech processing in general, see [82]. <p> Once the ANN is trained, its output values can be used as probabilities in dynamic programming to find a better segmentation, which provides a new segmentation and new targets to train further the ANN. Again, convergence of this iterative process (still to a local optimum) can be proved. See <ref> [13] </ref> for a full description of this, together with the (numerous) modifications required to turn this basic scheme into a state of the art system. <p> It also appears that in fair comparisons (i.e. using the same feature set, underlying HMM, and language model), this approach consistently shows significant improvements over systems using conventional HMM approaches <ref> [13] </ref>. A partially recurrent approach to this same hybrid system has also done very well on the same large vocabulary tasks [100]. 8.4. <p> In this case, an optimal span of 90 ms has usually been re ported <ref> [13] </ref>. The multi-vector input technique then relies on the classifier to discover the relative importance of time-advanced and time-delayed speech analysis vectors for the classification of the given speech instant. 4.
References-found: 13

