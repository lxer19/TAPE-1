URL: http://www.aic.nrl.navy.mil/~gordon/papers/ml90.ps
Refering-URL: http://www.aic.nrl.navy.mil/~gordon/pubs.html
Root-URL: 
Email: (gref@aic.nrl.navy.mil)  
Title: Explanations of Empirically Derived Reactive Plans  
Phone: 1990.  
Author: Diana F. Gordon (gordon@aic.nrl.navy.mil) John J. Grefenstette 
Affiliation: Navy Center for Applied Research in Artificial Intelligence Naval Research Laboratory,  
Address: Austin, TX,  Code 5514 Washington, D.C. 20375-5000  
Note: In the Proceedings of the Seventh International Conference on Machine Learning,  
Abstract: Given an adequate simulation model of the task environment and payoff function that measures the quality of partially successful plans, competition-based heuristics such as genetic algorithms can develop high performance reactive rules for interesting sequential decision tasks. We have previously described an implemented system, called SAMUEL, for learning reactive plans and have shown that the system can successfully learn rules for a laboratory scale tactical problem. In this paper, we describe a method for deriving explanations to justify the success of such empirically derived rule sets. The method consists of inferring plausible subgoals and then explaining how the reactive rules trigger a sequence of actions (i.e., a stra tegy) to satisfy the subgoals. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Agre, P. and Chapman, D. </author> <year> (1987). </year> <title> Pengi: An implementation of a theory of activity. </title> <booktitle> Proceedings of the Sixth National Conference on Artificial Intelligence. </booktitle>
Reference: <author> Erickson, M. and Zytkow, J. </author> <year> (1988). </year> <title> Utilizing experience for improving the tactical manager. </title> <booktitle> Proceedings of the Fifth International Conference on Machine Learning. </booktitle> <address> Ann Arbor, MI. </address>
Reference-contexts: A study of the effects of sensor noise on appears in (Schultz, Ramsey & Grefenstette, 1990). 2 The Evasive Maneuvers Problem We have tested SAMUEL initially in the context of a particular task called Evasive Maneuvers (EM), inspired in part by <ref> (Erickson and Zytkow, 1988) </ref>. In the EM simulation, there are two objects of interest, a plane and a missile, which maneuver in a two-dimensional world. The object is to control the turning rate of the plane to avoid being hit by the approaching missile.
Reference: <author> Forbus, K. </author> <year> (1984). </year> <title> Qualitative process theory. </title> <booktitle> Artificial Intelligence, </booktitle> <pages> 24(1-3). </pages> <publisher> North-Holland Publishing Company, </publisher> <address> Amsterdam, The Netherlands. </address>
Reference-contexts: Explaining failure to satisfy subgoals is presented as future work. Creating justifications for successful subgoal satisfaction requires the development of a domain theory that captures important results of particular actions. We are adapting Forbus's Qualitative Process Theory <ref> (Forbus, 1984) </ref> for the interpretation of the empirically derived rules similarly to the way this theory is adapted in (Gervasio, 1989). Qualitative Process Theory (QP Theory) expresses common sense notions about qualitative relationships between objects. We are currently using QP Theory to define processes relevant to EM. <p> Qualitative Process Theory (QP Theory) expresses common sense notions about qualitative relationships between objects. We are currently using QP Theory to define processes relevant to EM. A process is defined in <ref> (Forbus, 1984) </ref> as something that acts through time to change the parameters of objects in a situation. Example processes are fluid and heat flow, boiling, and motion. We define an EM process below. The individuals are the objects on which the process acts.
Reference: <author> Gervasio, M. and DeJong, G. </author> <year> (1989). </year> <title> Explanation-based learning of reactive operators. </title> <booktitle> Proceedings of the Sixth International Workshop on Machine Learning. </booktitle> <address> Ithica, NY. </address> <publisher> Morgan Kauf-mann Publishers, Inc. </publisher>
Reference-contexts: Creating justifications for successful subgoal satisfaction requires the development of a domain theory that captures important results of particular actions. We are adapting Forbus's Qualitative Process Theory (Forbus, 1984) for the interpretation of the empirically derived rules similarly to the way this theory is adapted in <ref> (Gervasio, 1989) </ref>. Qualitative Process Theory (QP Theory) expresses common sense notions about qualitative relationships between objects. We are currently using QP Theory to define processes relevant to EM. A process is defined in (Forbus, 1984) as something that acts through time to change the parameters of objects in a situation. <p> Once a partial domain theory exists, it is possible to create plausible explanations of the events that occurred during an EM episode. Explanations are derived by creating proofs using the process rela - tions similarly to <ref> (Gervasio, 1989) </ref>. The proof begins with an observable but noncontrollable subgoal and terminates when a change in a controllable parameter has been found that is believed to have caused subgoal satisfaction. The body of the proof consists of QP Theory relational rules, such as those presented above.
Reference: <author> Grefenstette, J. </author> <year> (1988). </year> <title> Credit assignment in rule discovery system based on genetic algorithms. </title> <journal> Machine Learning, </journal> <volume> 3(2/3). </volume> <publisher> Kluwer Academic Publishers, </publisher> <address> Hingham, MA. </address>
Reference-contexts: We have been investigating the usefulness of genetic algorithms and other competition-based heuristics <ref> (Grefenstette, 1988) </ref> to learn high performance reactive rules in the absence of a strong domain theory. The approach has been implemented in a system called SAMUEL (Grefenstette, 1989). <p> This work is part of an on-going study of genetic algorithms for learning tactical plans. The current system is detailed in (Grefenstette, Ramsey & Schultz, 1990). An analysis of the credit assignment methods in appears in <ref> (Grefenstette, 1988) </ref>. A study of the effects of sensor noise on appears in (Schultz, Ramsey & Grefenstette, 1990). 2 The Evasive Maneuvers Problem We have tested SAMUEL initially in the context of a particular task called Evasive Maneuvers (EM), inspired in part by (Erickson and Zytkow, 1988). <p> In the case of unsuccessful evasion, partial credit is given reflecting the plane's survival time (see (Grefenstette et. al, 1990)). Each decision rule is assigned a numeric strength that serves as a prediction of the rule's utility. The system uses incremental credit assignment methods <ref> (Grefenstette, 1988) </ref> to update the rule strengths based on feedback from the critic received at the end of the episode. Experiments have shown that SAMUEL can learn high-performance rule sets (plans) for this task (Gre-fenstette, 1989).
Reference: <author> Grefenstette, J. </author> <year> (1989). </year> <title> A system for learning control strategies with genetic algorithms. </title> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms. </booktitle> <address> Fairfax, VA: </address> <publisher> Morgan Kauf-mann. </publisher>
Reference-contexts: We have been investigating the usefulness of genetic algorithms and other competition-based heuristics (Grefenstette, 1988) to learn high performance reactive rules in the absence of a strong domain theory. The approach has been implemented in a system called SAMUEL <ref> (Grefenstette, 1989) </ref>. One of the important differences between SAMUEL and many other genetic learning systems is that SAMUEL learns rules expressed in a high level rule language. The use of a symbolic rule language is intended to facilitate the incorporation of more powerful learning methods into the system where appropriate. <p> Each plan is evaluated by testing its performance in controlling the world model through the performance module. Genetic operators, such as crossover and mutation, produce plausible new plans from high performance precursors. Experiments have shown that SAMUEL learns highly effective reactive plans for laboratory scale tactical problems <ref> (Grefenstette, 1989) </ref>. However, even though the individual rules of a plan can be interpreted, the strategy underlying the plan is often not apparent. We are currently expanding our focus to include the derivation of explanations of SAMUEL's reactive rules.
Reference: <author> Grefenstette, J., Ramsey, C. and Schultz, A. </author> <year> (1990). </year> <title> Learning sequential decision rules using simulation models and competition. To appear in Machine Learning Journal. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Hingham, MA. </address>
Reference-contexts: The remainder of the paper is devoted to describing our research on the topic of generating explanations of reactive plans. This work is part of an on-going study of genetic algorithms for learning tactical plans. The current system is detailed in <ref> (Grefenstette, Ramsey & Schultz, 1990) </ref>. An analysis of the credit assignment methods in appears in (Grefenstette, 1988). <p> This work is part of an on-going study of genetic algorithms for learning tactical plans. The current system is detailed in (Grefenstette, Ramsey & Schultz, 1990). An analysis of the credit assignment methods in appears in (Grefenstette, 1988). A study of the effects of sensor noise on appears in <ref> (Schultz, Ramsey & Grefenstette, 1990) </ref>. 2 The Evasive Maneuvers Problem We have tested SAMUEL initially in the context of a particular task called Evasive Maneuvers (EM), inspired in part by (Erickson and Zytkow, 1988). <p> The critic module provides numeric feedback at the end of each episode that measures the extent to which the missile has been successfully evaded. In the case of unsuccessful evasion, partial credit is given reflecting the plane's survival time (see <ref> (Grefenstette et. al, 1990) </ref>). Each decision rule is assigned a numeric strength that serves as a prediction of the rule's utility. The system uses incremental credit assignment methods (Grefenstette, 1988) to update the rule strengths based on feedback from the critic received at the end of the episode.
Reference: <author> Minton, S., Carbonell, J., Knoblock, C., Kuokka, D., Etzioni, O., and Gil, Y. </author> <year> (1989). </year> <title> Explanation-based learning: A problem-solving perspective. </title> <institution> Carnegie-Mellon University Technical Report Number CMU-CS-89-103. </institution>
Reference: <author> Mitchell, T. </author> <year> (1983). </year> <title> Learning by experimentation: Acquiring and refining problem-solving heuristics. </title> <editor> In R. Michalski, J. Carbonell, </editor> <booktitle> and T. </booktitle>
Reference: <editor> Mitchell (Eds.), </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach (Vol. </booktitle> <volume> 1). </volume> <publisher> Tioga Publishing Co., </publisher> <address> Palo Alto, CA. </address>
Reference: <author> Mitchell, T., Keller, R. and Kedar-Cabelli, S. </author> <year> (1986). </year> <title> Explanation-based generalization: A unifying view. </title> <journal> Machine Learning, </journal> <volume> 1(1). </volume> <publisher> Kluwer Academic Publishers, </publisher> <address> Hingham, MA. </address>
Reference-contexts: The second direction for future research consists of generating new decision rules from the explanations. If a subgoal is satisfied, and an explanation is generated for subgoal satisfaction, then the system can generalize the explanation (perhaps using the explanation-based learning methods of <ref> (Mitchell, Keller & Kedar-Cabelli, 1986) </ref>) and then use the generalized explanation to generate new decision rules. Given a successful explanation, SAMUEL's performance can benefit by the creation of new decision rules that are expected to achieve the same results as the rules from which the explanation is formed.
Reference: <author> Sammut, C. and Banerji, R. </author> <year> (1986). </year> <title> Learning concepts by asking questions. </title> <editor> In R. Michalski, </editor> <publisher> J. </publisher>
Reference-contexts: The process of generating decision rules from generalized explanations is one of rule specialization. We are currently considering using ideas from MARVIN <ref> (Sammut and Banerji, 1986) </ref> for designing the rule specialization process. Once new decision rules have been created, they can be fed back into SAMUEL's performance module to augment the existing rule sets. These modified rule sets may then be empirically evaluated using the EM simulator.
Reference: <editor> Carbonell, and T. Mitchell (Eds.), </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach (Vol. </booktitle> <volume> 2). </volume> <publisher> Morgan Kaufmann Publishers, </publisher> <address> Los Altos, CA. </address>
Reference: <author> Schoppers, M. </author> <year> (1987). </year> <title> Universal plans for reactive robots in unpredictable environments. </title> <booktitle> Proceedings of the Tenth International Joint Conference on Artifi cial Intelligence. </booktitle>
Reference: <author> Schultz, A., Ramsey, C. and Grefenstette, J. </author> <year> (1990). </year> <title> Simulation-assisted learning by competition: Effects of noise differences between training model and target environment. </title> <booktitle> In Proceedings of the Seventh International Machine Learning Conference. </booktitle> <address> Austin, TX: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: The remainder of the paper is devoted to describing our research on the topic of generating explanations of reactive plans. This work is part of an on-going study of genetic algorithms for learning tactical plans. The current system is detailed in <ref> (Grefenstette, Ramsey & Schultz, 1990) </ref>. An analysis of the credit assignment methods in appears in (Grefenstette, 1988). <p> This work is part of an on-going study of genetic algorithms for learning tactical plans. The current system is detailed in (Grefenstette, Ramsey & Schultz, 1990). An analysis of the credit assignment methods in appears in (Grefenstette, 1988). A study of the effects of sensor noise on appears in <ref> (Schultz, Ramsey & Grefenstette, 1990) </ref>. 2 The Evasive Maneuvers Problem We have tested SAMUEL initially in the context of a particular task called Evasive Maneuvers (EM), inspired in part by (Erickson and Zytkow, 1988).
References-found: 15

