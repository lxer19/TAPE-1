URL: http://www.cs.nmsu.edu/lldap/jicslp98/p5.ps.gz
Refering-URL: http://www.cs.nmsu.edu/lldap/jicslp98/accepted.html
Root-URL: http://www.cs.nmsu.edu
Email: fepontell,gupta,wiebeg@cs.nmsu.edu, david@crl.nmsu.edu  
Title: Natural Language Multiprocessing: A Case Study  
Author: Enrico Pontelli Gopal Gupta Janyce Wiebe David Farwell 
Affiliation: Dept. Computer Science and Computing Research Laboratory New Mexico State University  
Abstract: This paper presents two case studies of parallelization of large Natural Language Processing (NLP) applications using a parallel logic programming system (called "ACE") that automatically exploits implicit parallelism. The first system considered is Artwork, a system for semantic disambiguation, speech act resolution, and temporal reference resolution. The second system is ULTRA, a multilingual translation system. Both applications were originally developed in Prolog without any consideration for parallel processing. The results obtained confirm that NLP is a ripe area for exploitation of parallelism. Most previous work on parallelism in NLP focused primarily on parallelizing the parsing phase of language processing. The case studies presented here show that parallelism is also present in the semantic and discourse processing phases, which are often the most computationally intensive part of the application. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Adriaens, G., and Hahn, U. </author> <year> 1994. </year> <title> Parallel Natural Language Processing. </title> <publisher> Ablex Publishing. </publisher>
Reference-contexts: The annotator is written in Prolog, so the annotation process itself can be parallelized. 5 Comparison with Other Work Experience shows that NLP applications are highly parallel in nature. Although considerable research has been proposed in using parallelism for NLP (see <ref> [1] </ref> for a review of approaches to parallel NLP), most of the approaches are based on ad-hoc and hand-made parallelization of NLP applications. There has been research in the past in parallelizing the parsing phase of NLP [5], including some that use a logic programming approach [12, 18].
Reference: [2] <author> Ali, K., and Karlsson, R. </author> <year> 1990. </year> <title> The Muse Or-parallel Prolog.. In NACLP. </title> <publisher> MIT Press. </publisher>
Reference-contexts: Given that parallelism can be exploited automatically, existing Prolog-based NLP applications can also be par-allelized, by porting them with little or no effort to parallel systems. Fast parallel implementations of Prolog are currently available (e.g., <ref> [2] </ref>) or about to be released into the public domain, including the ACE system [7] used in this work. <p> the body of a clause, and at runtime these goals to do not compete for any unbound variable. (iii) Dependent and-parallelism (DAP) arises when two or more goals of a clause access common variables and are executed in parallel. 2.1 The ACE System The ACE model [7, 14] uses stack-copying <ref> [2] </ref> and recomputation [7] to efficiently support combined or- and independent and-parallel execution of logic programs. ACE represents an efficient combination of or- and independent and-parallelism in the sense that penalties for supporting either form of parallelism are paid only when that form of parallelism is actually exploited. <p> This efficiency in execution is accomplished by introducing the concept of teams of processors and extending the stack-copying techniques to deal with this new processor organization. 2 Or-Parallelism in ACE: ACE exploits or-parallelism by using a stack copying approach <ref> [2] </ref>. In this approach, a set of processing agents (processors in the case of MUSE, teams of processors in the case of ACE|as explained later) working in or-parallel maintain a separate but identical address space (i.e. they allocate their data structures starting at the same logical addresses).
Reference: [3] <author> M. Carlson and G. Gupta (eds.) </author> <year> 1996. </year> <journal> Journal of Logic Progr. </journal> <pages> 29(1-3). </pages>
Reference-contexts: This is mostly due to the increasing computational requirements of these applications, which were not satisfied by the older slow implementations of declarative languages. Even though implementations of these languages comparable in efficiency to imperative languages are available today (e.g., <ref> [3] </ref>), past experience has discouraged designers of NLP systems from using them. The computational demands of today's NLP systems have reached the level where they are challenging for even the most efficiently implementable programming paradigms, including imperative languages.
Reference: [4] <author> DeGroot, D. </author> <year> 1984. </year> <title> Restricted AND-Parallelism. </title> <booktitle> In Conf. on 5th Generation Computer Systems. </booktitle>
Reference-contexts: Dependencies are detected at run-time by executing some simple tests introduced by the parallelizing compiler. ACE adopts the technique originally designed by DeGroot <ref> [4] </ref> and refined by Hermenegildo [8] of annotating the program at compile time with Conditional Graph Expressions (CGEs): (h conditions i ) B 1 & & B n ) where hconditionsi is a conjunction of simple tests on variables appearing in the clause that verifies whether the arguments share any variables
Reference: [5] <author> Devos M. et al. </author> <year> 1988. </year> <title> The Parallel Expert Parser. </title> <booktitle> In Proceedings of COLING. </booktitle>
Reference-contexts: Although considerable research has been proposed in using parallelism for NLP (see [1] for a review of approaches to parallel NLP), most of the approaches are based on ad-hoc and hand-made parallelization of NLP applications. There has been research in the past in parallelizing the parsing phase of NLP <ref> [5] </ref>, including some that use a logic programming approach [12, 18]. More recently, the Eu-PAGE systems [11] has been proposed, a parser generator capable of producing parallel parsers (based on PVM). However, not much parallelism has been extracted from other phases of NLP systems.
Reference: [6] <author> Farwell, D., and Wilks, Y. </author> <year> 1991. </year> <title> ULTRA: A multilingual machine translator. In Mach. </title> <publisher> Transl. Summit. </publisher>
Reference-contexts: It can currently translate between five languages (Chinese, English, German, Spanish, and Japanese) with vocabularies in each language based on about 10; 000 word senses. The multilingual system is based on a language-independent interlingual representation (IR) <ref> [6] </ref> for representing expressions as elements of linguistic acts of communication (e.g., asking questions, describing the world, promising that things will get done, etc.). Translation can be viewed as the use of the target language to express the same act as the one expressed in the source language. <p> Translation can be viewed as the use of the target language to express the same act as the one expressed in the source language. The IR is then used as the basis for analyzing or for generating expressions as elements of such acts in each of the languages <ref> [6] </ref>. Each individual language system is independent and has its own rules to associate the appropriate IRs to each expression of the language. <p> Currently most of the language components are implemented as context-free grammars with complex categories. The system uses relaxation techniques (grammatical relaxation, semantic relaxation, and structure relaxation) to provide robustness by giving preferred or "near miss" translations <ref> [6] </ref>. In addition, the adoption of language-independent semantic and pragmatic procedures allows, given a context, the selection of the best IR from the set of possible IRs for a given expression. The use of Prolog allowed the design of a highly declarative and perfectly bidirectional application. <p> In the case of ULTRA the goal of parallelization was quickly achieved with limited effort, thanks to the clean and declarative programming style adopted by the programmers who developed the system, necessitated by the requirement that computations be reversible <ref> [6] </ref>. In the case of Artwork the system had been developed following a more "imperative" approach in the code organization. We invested some effort in reorganizing some parts of the code and this proved effective in increasing the amount of and-parallelism.
Reference: [7] <author> Gupta, G., Pontelli, E. et al. </author> <year> 1994. </year> <title> ACE: And/Or-parallel Copying-based Execution of Logic Programs. </title> <booktitle> In Proc. ICLP'94, </booktitle> <pages> 93-109. </pages> <publisher> MIT Press. </publisher>
Reference-contexts: Given that parallelism can be exploited automatically, existing Prolog-based NLP applications can also be par-allelized, by porting them with little or no effort to parallel systems. Fast parallel implementations of Prolog are currently available (e.g., [2]) or about to be released into the public domain, including the ACE system <ref> [7] </ref> used in this work. In this work we present two case studies in which two large NLP applications, independently developed with no goal of parallelization in mind, have been studied and parallelized using the ACE parallel Prolog system. <p> the query or in the body of a clause, and at runtime these goals to do not compete for any unbound variable. (iii) Dependent and-parallelism (DAP) arises when two or more goals of a clause access common variables and are executed in parallel. 2.1 The ACE System The ACE model <ref> [7, 14] </ref> uses stack-copying [2] and recomputation [7] to efficiently support combined or- and independent and-parallel execution of logic programs. <p> a clause, and at runtime these goals to do not compete for any unbound variable. (iii) Dependent and-parallelism (DAP) arises when two or more goals of a clause access common variables and are executed in parallel. 2.1 The ACE System The ACE model [7, 14] uses stack-copying [2] and recomputation <ref> [7] </ref> to efficiently support combined or- and independent and-parallel execution of logic programs. ACE represents an efficient combination of or- and independent and-parallelism in the sense that penalties for supporting either form of parallelism are paid only when that form of parallelism is actually exploited. <p> Thus, the the notion of or-agent is mapped to the notion of team of processors while the notion of and-agent is mapped to the notion of processors inside a team (i.e. each processor is an and-agent). Different approaches to incremental copying and heuristics have been developed <ref> [7] </ref>. ACE has shown remarkable performance results on a large selection of programs (Figure 1 presents the speedup curves obtained on some benchmarks).
Reference: [8] <author> Hermenegildo, M. et al. </author> <year> 1995. </year> <title> Incremental analysis of logic programs. In ICLP95. </title> <publisher> MIT Press. </publisher> <pages> 11 </pages>
Reference-contexts: Dependencies are detected at run-time by executing some simple tests introduced by the parallelizing compiler. ACE adopts the technique originally designed by DeGroot [4] and refined by Hermenegildo <ref> [8] </ref> of annotating the program at compile time with Conditional Graph Expressions (CGEs): (h conditions i ) B 1 & & B n ) where hconditionsi is a conjunction of simple tests on variables appearing in the clause that verifies whether the arguments share any variables with arguments of other goals, <p> A modular reorganization of the code and the use of incremental analysis techniques <ref> [8] </ref> will improve the speed of annotation. The annotator is written in Prolog, so the annotation process itself can be parallelized. 5 Comparison with Other Work Experience shows that NLP applications are highly parallel in nature.
Reference: [9] <author> Hirschman L. et al. </author> <year> 1988. </year> <title> Or-parallel Speedup in Natural Language Processing. In ICLP88. </title> <publisher> MIT Press. </publisher>
Reference-contexts: More recently, the Eu-PAGE systems [11] has been proposed, a parser generator capable of producing parallel parsers (based on PVM). However, not much parallelism has been extracted from other phases of NLP systems. The main exception to this is the PUNDIT system <ref> [9] </ref> which exploits (only) or-parallelism from an NLP system coded in Prolog running on a simulated parallel environment. The PUNDIT system is about 3,000 lines long.
Reference: [10] <author> Levin, L. et al. </author> <year> 1995. </year> <title> Using Context in the Machine Translation of Spoken Language. </title> <booktitle> In Proc. Theoretical and Methodological Issues in Machine Translation. </booktitle>
Reference-contexts: The input to the system is the output of a semantic parser developed as part of the Enthusiast speech-to-speech machine translation project at CMU <ref> [10] </ref>; it determines, among other things, what type of event each utterance is about, and who the participants are. The output of the parser is ambiguous, so must be disambiguated by the Artwork system. The first of the discourse ambiguities addressed involves a prominent view of language as goal-oriented behavior. <p> Wiebe et al. (1997) present the results of the system performing this task on unseen, held-out test data, taking as input the ambiguous output of the semantic parser (which itself takes as input the output of a speech recognition system <ref> [10] </ref>). The system performs well, and comparable results on similar tasks have not been published elsewhere. The system parallelized in this work is an earlier version which performed speech-act and temporal reference resolution, but not semantic disambiguation.
Reference: [11] <author> Manousopoulou A. et al. </author> <year> 1997. </year> <title> Automatic Generation of Portable Parallel Natural Language Parsers. In ICTAI. </title> <publisher> IEEE Computer Society. </publisher>
Reference-contexts: There has been research in the past in parallelizing the parsing phase of NLP [5], including some that use a logic programming approach [12, 18]. More recently, the Eu-PAGE systems <ref> [11] </ref> has been proposed, a parser generator capable of producing parallel parsers (based on PVM). However, not much parallelism has been extracted from other phases of NLP systems.
Reference: [12] <author> Matsumoto, Y. </author> <year> 1986. </year> <title> A Parallel Parsing System for Natural Language Analysis. </title> <booktitle> In Int. Conf. on Logic Programming. </booktitle> <publisher> Springer Verlag. </publisher>
Reference-contexts: There has been research in the past in parallelizing the parsing phase of NLP [5], including some that use a logic programming approach <ref> [12, 18] </ref>. More recently, the Eu-PAGE systems [11] has been proposed, a parser generator capable of producing parallel parsers (based on PVM). However, not much parallelism has been extracted from other phases of NLP systems.
Reference: [13] <author> Pereira, F. and Shieber, S.M. </author> <year> 1987. </year> <title> Prolog and Natural-Language Analysis. </title> <publisher> Cambridge University Press. </publisher>
Reference-contexts: 1 Introduction Logic programming has been for a long time one of the programming paradigms of choice for the development of NLP systems. Logic programming languages (e.g., Prolog) offer features such as backtracking, unification, and symbolic data representation which greatly facilitate the development of NLP applications <ref> [13] </ref>. In recent years the use of declarative languages, such as Prolog and Lisp, for NLP applications has declined. This is mostly due to the increasing computational requirements of these applications, which were not satisfied by the older slow implementations of declarative languages.
Reference: [14] <author> Pontelli, E. </author> <year> 1997. </year> <title> High-Performance Parallel Execution of Prolog Programs. </title> <type> Ph.D. Dissertation, </type> <institution> NMSU. </institution>
Reference-contexts: the query or in the body of a clause, and at runtime these goals to do not compete for any unbound variable. (iii) Dependent and-parallelism (DAP) arises when two or more goals of a clause access common variables and are executed in parallel. 2.1 The ACE System The ACE model <ref> [7, 14] </ref> uses stack-copying [2] and recomputation [7] to efficiently support combined or- and independent and-parallel execution of logic programs.
Reference: [15] <author> Pontelli, E., Gupta, G. et al. </author> <year> 1997. </year> <title> Automatic Compile-time Parallelization of Prolog Programs for DAP. In ICLP97. </title> <publisher> MIT Press. </publisher>
Reference-contexts: The ACE compiler was used to identify potential sources of parallelism. Additionally, the rich output of the ACE static analyzer <ref> [15] </ref> (e.g., sharing information) allowed us to identify features of the program that were limiting the parallelism exploitable. Very few hand-modifications of the original code were needed to considerably improve the speedups achieved, as discussed in the next subsection. <p> The analyzer was quite successful in detecting parallelism in the program. At the highest level, IAP was exploited by allowing concurrent translation of successive phrases belonging to the source text. The translation of each phrase was marked as a potential source of DAP by the dependent and-parallel analyzer <ref> [15] </ref>, as illustrated below: ctrans (Src lg,Trg lg,In,Out) :- (dep ([I rep])-&gt; (analyse (Srg lg,In,I rep) & generate (Trg lg,I rep,Out)); 8 Out String = "&lt; unable to translate &gt;"). where '&' denotes a parallel conjunction and the dep annotation identifies the source of dependency (shared variable).
Reference: [16] <author> Reithinger, N. et al. </author> <year> 1995. </year> <title> Utilizing statistical dialogue act processing in verbmobil. </title> <booktitle> In ACL, </booktitle> <pages> 116-122. </pages>
Reference-contexts: These actions are called speech acts. The task of an understanding system is to recognize which speech acts the speaker is performing with his or her utterances <ref> [16, 17, 20] </ref>. Consider the utterance "2 to 4" (dos a cuatro), a common type of utterance in the scheduling dialogs.
Reference: [17] <author> Rose, C. et al. </author> <year> 1995. </year> <title> Discourse processing of dialogues with multiple threads. </title> <booktitle> In Proceedings of ACL, </booktitle> <pages> 31-38. </pages>
Reference-contexts: These actions are called speech acts. The task of an understanding system is to recognize which speech acts the speaker is performing with his or her utterances <ref> [16, 17, 20] </ref>. Consider the utterance "2 to 4" (dos a cuatro), a common type of utterance in the scheduling dialogs.
Reference: [18] <author> Trehan, R. et al. </author> <year> 1988. </year> <title> A Parallel Chart Parser for the CCND Languages. In ICLP88. </title> <publisher> MIT Press. </publisher>
Reference-contexts: There has been research in the past in parallelizing the parsing phase of NLP [5], including some that use a logic programming approach <ref> [12, 18] </ref>. More recently, the Eu-PAGE systems [11] has been proposed, a parser generator capable of producing parallel parsers (based on PVM). However, not much parallelism has been extracted from other phases of NLP systems.
Reference: [19] <author> M. Walker and J. Moore (eds.) </author> <year> 1997. </year> <note> Computational Linguistics 23(1). </note>
Reference-contexts: Only recently have major efforts been invested in empirical investigations of computational theories of discourse processing (see, for example, the special issue of Computational Linguistics devoted to empirical studies in discourse <ref> [19] </ref>). The Artwork project is one such NLP project, funded by the Department of Defense. It targets scheduling dialogs, dialogs in which the participants schedule a meeting with one another.
Reference: [20] <author> Wiebe J. et al. </author> <year> 1996. </year> <title> ARTWORK: Discourse Processing in Machine Translation of Dialog. </title> <type> Technical Report MCCS96294, </type> <institution> Computing Research Laboratory. </institution>
Reference-contexts: These actions are called speech acts. The task of an understanding system is to recognize which speech acts the speaker is performing with his or her utterances <ref> [16, 17, 20] </ref>. Consider the utterance "2 to 4" (dos a cuatro), a common type of utterance in the scheduling dialogs. <p> Very few hand-modifications of the original code were needed to considerably improve the speedups achieved, as discussed in the next subsection. Ambiguity in NLP gives rise to a "combinatorial explosion" of possible interpretations. Consequently, Artwork may take up to a couple of hours to process a dialog <ref> [20] </ref>. Artwork offers a great deal of inherent parallelism to exploit, including or-parallelism and both DAP and IAP. To process each utterance, the system applies all rules in its knowledge base. Each rule that matches the utterance fires, producing a partial representation.
Reference: [21] <author> Wiebe J. et al. </author> <year> 1997. </year> <title> An Empirical Approach to Temporal Reference Resolution. </title> <booktitle> In Proceedings 2nd Conference on Empirical Methods in NLP. </booktitle> <pages> 12 </pages>
Reference-contexts: The speaker might be suggesting that they meet from 2 to 4; they might be confirming that 2 to 4 is the time currently being discussed; they might, with the right intonation, be accepting 2 to 4; and so on. The other kind of discourse ambiguity addressed is temporal <ref> [21] </ref>. The Artwork system tracks the times being talked about, determining implicit contextual information. For example, when a speaker refers to "2 to 4 am", Artwork looks back at the previous utterances, and decides which day, date, and month are being referred to.
References-found: 21

