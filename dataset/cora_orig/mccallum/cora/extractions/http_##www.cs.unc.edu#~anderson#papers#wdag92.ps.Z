URL: http://www.cs.unc.edu/~anderson/papers/wdag92.ps.Z
Refering-URL: http://www.cs.unc.edu/~anderson/papers.html
Root-URL: http://www.cs.unc.edu
Title: The Granularity of Waiting (Extended Abstract)  
Author: James H. Anderson Jae-Heon Yang Mohamed G. Gouda 
Keyword: Atomicity, busy-waiting, conditional mutual exclusion, idle-waiting, implementations, linearizability, mutual exclusion, shared data, synchronization primitives.  
Date: April 1992  
Abstract: We examine the "granularity" of statements of the form "await B ! S", where B is a boolean expression over program variables and S is a multiple-assignment. We consider two classes of such statements to have the same granularity iff any statement of one class can be implemented without busy-waiting by using statements of the other class. Two key results are presented. First, we show that statements of the form "await B ! S" can be implemented without busy-waiting by using simpler statements of the form "await X", "X := y", and "y := X", where y is a private boolean variable and X is a shared singler-reader, multi-writer boolean variable. Second, we show that if busy-waiting is not allowed, then there is no general mechanism for implementing statements of the form "await B", where B is an N -writer expression, using only assignment statements and statements of the form "await C", where C is an (N 1)-writer expression. It follows from these results that the granularity of waiting depends primarily on the number of processes that may write each program variable. These results also show that, from a computational standpoint, operations that combine both waiting and assignment, such as the P semaphore primitive, are not fundamental. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Y. Afek, H. Attiya, D. Dolev, E. Gafni, M. Merritt, and N. Shavit, </author> <title> "Atomic Snapshots of Shared Memory", </title> <booktitle> Proceedings of the Ninth Annual Symposium on Principles of Distributed Computing , 1990, </booktitle> <pages> pp. 1-14. </pages>
Reference: [2] <author> J. Anderson, </author> <title> "Composite Registers", </title> <booktitle> Proceedings of the Ninth Annual Symposium on Principles of Distributed Computing, </booktitle> <year> 1990, </year> <pages> pp. 15-30. 14 </pages>
Reference: [3] <author> J. Anderson and M. Gouda, </author> <title> "A Criterion for Atomicity", </title> <journal> Formal Aspects of Computing: The International Journal of Formal Methods, </journal> <note> to appear. </note>
Reference-contexts: Characterizing this class of programs would thus shed light on the validity of traditional atomicity criteria such as Reynolds' Rule <ref> [3, 14, 17] </ref>.
Reference: [4] <author> J. Anderson and B. Groselj, </author> <title> "Pseudo Read-Modify-Write Operations: Bounded Wait-Free Implementations", </title> <booktitle> Proceedings of the Fifth International Workshop on Distributed Algorithms, Lecture Notes in Computer Science 579, </booktitle> <publisher> Springer Verlag, </publisher> <pages> pp. 52-70. </pages>
Reference: [5] <author> G. Andrews, </author> <title> Concurrent Programming: </title> <booktitle> Principles and Practice, </booktitle> <publisher> The Benjamin/Cummings Publishing Company, Inc., </publisher> <address> Redwood City, California, </address> <year> 1991. </year>
Reference-contexts: If busy-waiting is allowed, then it is straightforward to use a solution to the mutual exclusion problem to obtain a program that solves the conditional mutual exclusion problem. In particular, consider the program given in Figure 1, which is taken from <ref> [5] </ref>. In this program, ENTRY and EXIT denote entry and exit sections from an N -process solution to the mutual exclusion problem. In order to execute its critical section, process i repeatedly executes ENTRY and EXIT, checking B [i] in between.
Reference: [6] <author> J. Aspnes and M. Herlihy, </author> <title> "Wait-Free Data Structures in the Asynchronous PRAM Model", </title> <booktitle> Proceedings of the Second Annual ACM Symposium on Parallel Architectures and Algorithms, </booktitle> <month> July, </month> <year> 1990. </year>
Reference: [7] <author> E. Dijkstra, </author> <title> A Discipline of Programming, </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1976. </year>
Reference: [8] <author> E. Dijkstra, </author> <title> "A Personal Summary of the Gries-Owicki Theory", </title> <address> EWD554, </address> <month> March, </month> <year> 1976. </year> <title> In Selected Writings on Computing: A Personal Perspective, </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1982. </year>
Reference: [9] <author> M. Herlihy and J. Wing, </author> <title> "Linearizability: A Correctness Condition for Concurrent Objects", </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> Vol. 12, No. 3, </volume> <year> 1990, </year> <pages> pp. 463-492. </pages>
Reference: [10] <author> K. Hwang and F. Briggs, </author> <booktitle> Computer Architecture and Parallel Processing , McGraw-Hill, </booktitle> <year> 1984. </year>
Reference: [11] <author> A. Israeli and M. Li, </author> <title> "Bounded time-stamps", </title> <booktitle> Proceedings of the 28th IEEE Symposium on Foundations of Computer Science, </booktitle> <year> 1987, </year> <pages> pp. 371-382. </pages>
Reference: [12] <author> J. Kessels, </author> <title> "Arbitration Without Common Modifiable Variables", </title> <journal> Acta Informatica, </journal> <volume> Vol. 17, </volume> <year> 1982, </year> <pages> pp. 135-141. </pages>
Reference-contexts: Such a solution, consisting of two processes u and v, is depicted in Figure 3. The program is similar to the two-process solution given by Peterson in [18] and also to that given by Kessels in <ref> [12] </ref>, but uses only single-reader, single-writer boolean variables. The two variables T [u] and T [v] together correspond to the variable TURN of Peterson's algorithm, and are used as a tie-breaker in the event that both processes attempt to enter their critical sections at the same time.
Reference: [13] <author> L. Lamport, </author> <title> "On Interprocess Communication, Parts I and II", </title> <journal> Distributed Computing , Vol. </journal> <volume> 1, </volume> <year> 1986, </year> <pages> pp. 77-101. </pages>
Reference: [14] <author> L. Lamport, </author> <title> "win and sin: Predicate Transformers for Concurrency", </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> Vol. 12, No. 3, </volume> <year> 1990, </year> <pages> pp. 396-428. </pages>
Reference-contexts: Characterizing this class of programs would thus shed light on the validity of traditional atomicity criteria such as Reynolds' Rule <ref> [3, 14, 17] </ref>.
Reference: [15] <author> M. Li, J. Tromp, and P. Vitanyi, </author> <title> "How to Construct Wait-Free Variables", </title> <booktitle> Proceedings of International Colloquium on Automata, Languages, and Programming, Lecture Notes in Computer Science 372, </booktitle> <pages> pp. 488-505, </pages> <publisher> Springer Verlag, </publisher> <year> 1989. </year>
Reference: [16] <author> J. Mellor-Crummey and M. Scott, </author> <title> "Algorithms for Scalable Synchronization on Shared-Memory Multiprocessors", </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> Vol. 9, No. 1, </volume> <month> February, </month> <year> 1991, </year> <pages> pp. 21-65. </pages>
Reference-contexts: This stands in sharp contrast to the case of previous implementations, such as that given in Figure 1, where busy-waiting on complicated "global" predicates is employed. In a recent paper by Mellor-Crummey and Scott <ref> [16] </ref>, it is shown that busy-waiting on global predicates is best avoided if programs are required to be scalable, as such busy-waiting induces an unacceptable degree of memory and interconnect contention. Our results can be generalized to allow programs with await statements that have multiple guards.
Reference: [17] <author> S. Owicki and D. Gries, </author> <title> "An Axiomatic Proof Technique for Parallel Programs I", </title> <journal> Acta Informatica, </journal> <volume> Vol. 6, </volume> <year> 1976, </year> <pages> pp. 319-340. </pages>
Reference-contexts: Characterizing this class of programs would thus shed light on the validity of traditional atomicity criteria such as Reynolds' Rule <ref> [3, 14, 17] </ref>.
Reference: [18] <author> G. Peterson, </author> <title> "Myths About the Mutual Exclusion Problem", </title> <journal> Information Processing Letters, </journal> <volume> Vol. 12, No. 3, </volume> <month> June, </month> <year> 1981, </year> <pages> pp. 115-116. </pages>
Reference-contexts: It is this aspect of the conditional mutual exclusion problem that makes a solution without busy-waiting problematic. A program that solves the conditional mutual exclusion problem without busy-waiting is given in given in <ref> [18] </ref>. Processes "transit" through N + 1 levels numbered from 0 to N . Starting from level N; processes compete to enter level 0. A process at level 0 executes its critical section. Q [u] represents process u's current level, and u:q is a private copy of Q [u]. <p> It follows that, in order to solve the N -process case, it suffices to solve the two-process case. Such a solution, consisting of two processes u and v, is depicted in Figure 3. The program is similar to the two-process solution given by Peterson in <ref> [18] </ref> and also to that given by Kessels in [12], but uses only single-reader, single-writer boolean variables.
Reference: [19] <author> J. Peterson and A. Silberschatz, </author> <title> Operating System Concepts, </title> <publisher> Addison-Wesley, </publisher> <year> 1985. </year> <month> 15 </month>
References-found: 19

