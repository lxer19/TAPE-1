URL: http://dimacs.rutgers.edu/techps/1993/93-72.ps
Refering-URL: http://dimacs.rutgers.edu/TechnicalReports/1993.html
Root-URL: http://www.cs.rutgers.edu
Title: Symmetric Quasi-Definite Matrices  
Author: Robert J. Vanderbei 
Keyword: K  
Note: E A T  
Address: New Brunswick, NJ 08903  
Affiliation: Rutgers University  
Pubnum: DIMACS 93-72  
Abstract: We say that a symmetric matrix K is quasi-definite if it has the form where E and F are symmetric positive definite matrices. Although such matrices are indefinite, we show that any symmetric permutation of a quasi-definite matrix yields a factorization LDL T . We apply this result to obtain a new approach for solving the symmetric indefinite systems arising in interior-point methods for linear and quadratic programming. These systems are typically solved either by reducing to a positive definite system or by performing a Bunch-Parlett factorization of the full indefinite system at every iteration. Ours is an intermediate approach based on reducing to a quasi-definite system. This approach entails less fill-in than further reducing to a positive definite system but is based on a static ordering and is therefore more efficient than performing Bunch-Parlett factorizations of the original indefinite system. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> I. Adler and R.D.C. Monteiro. </author> <title> Limiting behavior of the affine scaling continuous trajectories for linear programming. </title> <type> Technical Report ESRC 88-9, </type> <institution> Engineering Systems Research Center, University of California - Berkeley, </institution> <year> 1988. </year>
Reference-contexts: We now return to the question of numerical stability in the context of interior-point methods. It was proved in <ref> [1] </ref> that strict complementarity holds in the limit (at least in the case of continuous trajectories of the affine scaling algorithm but it seems to be true in general).
Reference: [2] <author> J.R. Bunch and L.C. Kaufman. </author> <title> Some stable methods for calculating inertia and solving symmetric linear equations. </title> <journal> Mathematics of Computation, </journal> <volume> 31 </volume> <pages> 163-179, </pages> <year> 1977. </year>
Reference-contexts: This suggestion was first put forth by researchers in Stanford's Systems Optimization Laboratory ([5], [19], [9]) and by Turner [20]. Subsequently, Fourer and Mehrotra [6] began experimenting with the indefinite system approach. All of these papers rely on doing a Bunch-Parlett ([3], <ref> [2] </ref>) factorization of the indefinite system. Solving the indefinite system mitigates the fill-in caused when dense columns are present, but Bunch-Parlett factorizations tend to be more com 9 putationally burdensome.
Reference: [3] <author> J.R. Bunch and B.N. Parlett. </author> <title> Direct methods for solving symmetric indefinite systems of linear equations. </title> <journal> SIAM Journal on Numerical Analysis, </journal> <volume> 8 </volume> <pages> 639-655, </pages> <year> 1971. </year>
Reference: [4] <author> Y.C. Cheng, D.J. Houck, J.M.Liu, M.S. Meketon, L. Slutsman, R.J. Vanderbei, and P. Wang. </author> <title> The AT&T KORBX system. </title> <journal> AT&T Tech. Journal, </journal> <volume> 68 </volume> <pages> 7-19, </pages> <year> 1989. </year>
Reference-contexts: W )y = ( + AXZ 1 ): (3:5) The advantage of this approach is that the matrix AXZ 1 A T + Y 1 W is symmetric and positive definite, so that well-known and well-behaved methods such as Cholesky factorization (which was used in the implementations described in [14], <ref> [4] </ref>, [17], [15], [18], [12], [23], [21], [13]) or preconditioned conjugate gradient (used in the implementations described in [4], [11], [16]) can be used to solve systems involving this matrix. <p> AXZ 1 A T + Y 1 W is symmetric and positive definite, so that well-known and well-behaved methods such as Cholesky factorization (which was used in the implementations described in [14], <ref> [4] </ref>, [17], [15], [18], [12], [23], [21], [13]) or preconditioned conjugate gradient (used in the implementations described in [4], [11], [16]) can be used to solve systems involving this matrix. However, the disadvantage is that AXZ 1 A T can be quite dense compared to A if A has dense columns.
Reference: [5] <author> A.L. Forsgren and W. Murray. </author> <title> Newton methods for large-scale linear equality-constrained minimization. </title> <type> Technical Report SOL 90-6, </type> <institution> Department of Operations Research, Stanford University, </institution> <year> 1990. </year>
Reference: [6] <author> R. Fourer and S. Mehrotra. </author> <title> Performance of an augmented system approach for solving least-squares problems in an interior-point method for linear programming. </title> <institution> Dept. of Ind. Eng. and Mgmt. Sci., Northwestern Univ., </institution> <address> Evanston, IL, </address> <year> 1991. </year>
Reference-contexts: Recent papers have suggested that it might be better to solve indefinite systems such as (3.3) at every iteration. This suggestion was first put forth by researchers in Stanford's Systems Optimization Laboratory ([5], [19], [9]) and by Turner [20]. Subsequently, Fourer and Mehrotra <ref> [6] </ref> began experimenting with the indefinite system approach. All of these papers rely on doing a Bunch-Parlett ([3], [2]) factorization of the indefinite system. Solving the indefinite system mitigates the fill-in caused when dense columns are present, but Bunch-Parlett factorizations tend to be more com 9 putationally burdensome.
Reference: [7] <author> D.M. Gay. </author> <title> Electronic mail distribution of linear programming test problems. </title> <journal> Mathematical Programming Society COAL Newslettter, </journal> <volume> 13 </volume> <pages> 10-12, </pages> <year> 1985. </year>
Reference-contexts: Using our code, we computed the ratio of the largest to the smallest of the absolute values of the diagonal elements of D on the last iteration of the algorithm. On the eighty or so test problems in the NETLIB suite <ref> [7] </ref> this ratio ranged between 1.0e+19 and infinity (infinity means that an exact zero appeared on the diagonal, which can happen when rank deficiency occurs due to primal degeneracy). These ratios are tabulated in Tables 1 and 2.
Reference: [8] <author> A. George and J. Liu. </author> <title> Computer Solution of Large Sparse Positive Definite Systems. </title> <publisher> Prentice-Hall, </publisher> <year> 1981. </year>
Reference-contexts: Hence, it is clear that no factorization of (2.1) exists. (2) The matrix " 1 0 is factorizable but not strongly factorizable, since (2.1) is a symmetric permutation of this matrix. When a factorization exists, it is unique. This is a well-known result. See, e.g. <ref> [8] </ref>. In the remainder of this section, we show that symmetric quasi-definite matrices form a class of strongly factorizable matrices. Theorem 2 Symmetric quasi-definite matrices are strongly factorizable. 5 Proof. Fix a permutation matrix P .
Reference: [9] <author> P.E. Gill, W. Murray, D.B. Ponceleon, and M.A. Saunders. </author> <title> Precondi-tioners for indefinite systems arising in optimization. </title> <journal> SIAM J. Matrix Anal. Appl., </journal> <volume> 13(1) </volume> <pages> 292-311, </pages> <year> 1992. </year>
Reference-contexts: Recent papers have suggested that it might be better to solve indefinite systems such as (3.3) at every iteration. This suggestion was first put forth by researchers in Stanford's Systems Optimization Laboratory ([5], [19], <ref> [9] </ref>) and by Turner [20]. Subsequently, Fourer and Mehrotra [6] began experimenting with the indefinite system approach. All of these papers rely on doing a Bunch-Parlett ([3], [2]) factorization of the indefinite system.
Reference: [10] <author> G.H. Golub and C.F. VanLoan. </author> <title> Matrix Computations. </title> <publisher> The Johns Hop-kins University Press, </publisher> <address> 2 edition, </address> <year> 1989. </year>
Reference-contexts: If t is close to one, the factorization is stable (see <ref> [10] </ref> page 136). Larger values indicate less stability. For the matrix in (2.3), t = 1 + 1=* whereas for its symmetric permutation we get t = (3 + *)=2, which is clearly much better.
Reference: [11] <author> N.K. Karmarkar and K.G. Ramakrishnan. </author> <title> Implementation and computational results of the Karmarkar algorithm for linear programming, using an iterative method for computing projections. </title> <type> Technical report, </type> <institution> AT&T Bell Labs, </institution> <address> Murray Hill, NJ, </address> <year> 1989. </year> <month> 19 </month>
Reference-contexts: 1 A T + Y 1 W is symmetric and positive definite, so that well-known and well-behaved methods such as Cholesky factorization (which was used in the implementations described in [14], [4], [17], [15], [18], [12], [23], [21], [13]) or preconditioned conjugate gradient (used in the implementations described in [4], <ref> [11] </ref>, [16]) can be used to solve systems involving this matrix. However, the disadvantage is that AXZ 1 A T can be quite dense compared to A if A has dense columns.
Reference: [12] <author> I.J. Lustig, R.E. Marsten, and D.F. Shanno. </author> <title> On implementing Mehro--tra's predictor-corrector interior point method for linear programming. </title> <type> Technical Report SOR 90-03, </type> <institution> Dept. of Civil Engineering and Operations Research, Princeton Univ., </institution> <month> April </month> <year> 1990. </year>
Reference-contexts: + AXZ 1 ): (3:5) The advantage of this approach is that the matrix AXZ 1 A T + Y 1 W is symmetric and positive definite, so that well-known and well-behaved methods such as Cholesky factorization (which was used in the implementations described in [14], [4], [17], [15], [18], <ref> [12] </ref>, [23], [21], [13]) or preconditioned conjugate gradient (used in the implementations described in [4], [11], [16]) can be used to solve systems involving this matrix. However, the disadvantage is that AXZ 1 A T can be quite dense compared to A if A has dense columns.
Reference: [13] <author> I.J. Lustig, R.E. Marsten, and D.F. Shanno. </author> <title> Computational experience with a primal-dual interior point method for linear programming. </title> <journal> Lin. Alg. and Appl., </journal> <volume> 152 </volume> <pages> 191-222, </pages> <year> 1991. </year>
Reference-contexts: ): (3:5) The advantage of this approach is that the matrix AXZ 1 A T + Y 1 W is symmetric and positive definite, so that well-known and well-behaved methods such as Cholesky factorization (which was used in the implementations described in [14], [4], [17], [15], [18], [12], [23], [21], <ref> [13] </ref>) or preconditioned conjugate gradient (used in the implementations described in [4], [11], [16]) can be used to solve systems involving this matrix. However, the disadvantage is that AXZ 1 A T can be quite dense compared to A if A has dense columns.
Reference: [14] <author> R.E. Marsten, M.J. Saltzman, D.F. Shanno, G.S. Pierce, and J.F. Ballintijn. </author> <title> Implementation of a dual interior point algorithm for linear programming. </title> <journal> ORSA Journal on Computing, </journal> <volume> 1 </volume> <pages> 287-297, </pages> <year> 1989. </year>
Reference-contexts: 1 W )y = ( + AXZ 1 ): (3:5) The advantage of this approach is that the matrix AXZ 1 A T + Y 1 W is symmetric and positive definite, so that well-known and well-behaved methods such as Cholesky factorization (which was used in the implementations described in <ref> [14] </ref>, [4], [17], [15], [18], [12], [23], [21], [13]) or preconditioned conjugate gradient (used in the implementations described in [4], [11], [16]) can be used to solve systems involving this matrix.
Reference: [15] <author> K.A. McShane, C.L. Monma, and D.F. Shanno. </author> <title> An implementation of a primal-dual interior point method for linear programming. </title> <journal> ORSA Journal on Computing, </journal> <volume> 1 </volume> <pages> 70-83, </pages> <year> 1989. </year>
Reference-contexts: = ( + AXZ 1 ): (3:5) The advantage of this approach is that the matrix AXZ 1 A T + Y 1 W is symmetric and positive definite, so that well-known and well-behaved methods such as Cholesky factorization (which was used in the implementations described in [14], [4], [17], <ref> [15] </ref>, [18], [12], [23], [21], [13]) or preconditioned conjugate gradient (used in the implementations described in [4], [11], [16]) can be used to solve systems involving this matrix. However, the disadvantage is that AXZ 1 A T can be quite dense compared to A if A has dense columns.
Reference: [16] <author> S. Mehrotra. </author> <title> Implementations of affine scaling methods: Approximate solutions of systems of linear equations using preconditioned conjugate gradient methods. </title> <type> Technical Report 89-04, </type> <institution> Dept. of Ind. Eng. and Mgmt. Sci., Northwestern Univ., </institution> <address> Evanston, IL, </address> <year> 1989. </year>
Reference-contexts: A T + Y 1 W is symmetric and positive definite, so that well-known and well-behaved methods such as Cholesky factorization (which was used in the implementations described in [14], [4], [17], [15], [18], [12], [23], [21], [13]) or preconditioned conjugate gradient (used in the implementations described in [4], [11], <ref> [16] </ref>) can be used to solve systems involving this matrix. However, the disadvantage is that AXZ 1 A T can be quite dense compared to A if A has dense columns. Recent papers have suggested that it might be better to solve indefinite systems such as (3.3) at every iteration.
Reference: [17] <author> S. Mehrotra. </author> <title> Implementations of affine scaling methods: towards faster implementations with complete Cholesky factor in use. </title> <type> Technical Report 89-15, </type> <institution> Dept. of Ind. Eng. and Mgmt. Sci., Northwestern Univ., </institution> <address> Evanston, IL, </address> <year> 1989. </year>
Reference-contexts: )y = ( + AXZ 1 ): (3:5) The advantage of this approach is that the matrix AXZ 1 A T + Y 1 W is symmetric and positive definite, so that well-known and well-behaved methods such as Cholesky factorization (which was used in the implementations described in [14], [4], <ref> [17] </ref>, [15], [18], [12], [23], [21], [13]) or preconditioned conjugate gradient (used in the implementations described in [4], [11], [16]) can be used to solve systems involving this matrix. However, the disadvantage is that AXZ 1 A T can be quite dense compared to A if A has dense columns.
Reference: [18] <author> S. Mehrotra. </author> <title> On the implementation of a (primal-dual) interior point method. </title> <type> Technical Report 90-03, </type> <institution> Dept. of Ind. Eng. and Mgmt. Sci., Northwestern Univ., </institution> <address> Evanston, IL, </address> <year> 1990. </year>
Reference-contexts: ( + AXZ 1 ): (3:5) The advantage of this approach is that the matrix AXZ 1 A T + Y 1 W is symmetric and positive definite, so that well-known and well-behaved methods such as Cholesky factorization (which was used in the implementations described in [14], [4], [17], [15], <ref> [18] </ref>, [12], [23], [21], [13]) or preconditioned conjugate gradient (used in the implementations described in [4], [11], [16]) can be used to solve systems involving this matrix. However, the disadvantage is that AXZ 1 A T can be quite dense compared to A if A has dense columns.
Reference: [19] <author> D.B. Ponceleon. </author> <title> Barrier methods for large-scale quadratic programming. </title> <type> Technical Report SOL 91-2, </type> <institution> Stanford University, </institution> <month> October </month> <year> 1991. </year>
Reference-contexts: Recent papers have suggested that it might be better to solve indefinite systems such as (3.3) at every iteration. This suggestion was first put forth by researchers in Stanford's Systems Optimization Laboratory ([5], <ref> [19] </ref>, [9]) and by Turner [20]. Subsequently, Fourer and Mehrotra [6] began experimenting with the indefinite system approach. All of these papers rely on doing a Bunch-Parlett ([3], [2]) factorization of the indefinite system.
Reference: [20] <author> K. Turner. </author> <title> Computing projections for the Karmarkar algorithm. </title> <journal> Linear Algebra and Its Applications, </journal> <volume> 152 </volume> <pages> 141-154, </pages> <year> 1991. </year>
Reference-contexts: Recent papers have suggested that it might be better to solve indefinite systems such as (3.3) at every iteration. This suggestion was first put forth by researchers in Stanford's Systems Optimization Laboratory ([5], [19], [9]) and by Turner <ref> [20] </ref>. Subsequently, Fourer and Mehrotra [6] began experimenting with the indefinite system approach. All of these papers rely on doing a Bunch-Parlett ([3], [2]) factorization of the indefinite system.
Reference: [21] <author> R.J. Vanderbei. </author> <title> A brief description of ALPO. </title> <journal> OR Letters, </journal> <pages> pages 531-534, </pages> <year> 1991. </year>
Reference-contexts: 1 ): (3:5) The advantage of this approach is that the matrix AXZ 1 A T + Y 1 W is symmetric and positive definite, so that well-known and well-behaved methods such as Cholesky factorization (which was used in the implementations described in [14], [4], [17], [15], [18], [12], [23], <ref> [21] </ref>, [13]) or preconditioned conjugate gradient (used in the implementations described in [4], [11], [16]) can be used to solve systems involving this matrix. However, the disadvantage is that AXZ 1 A T can be quite dense compared to A if A has dense columns.
Reference: [22] <author> R.J. Vanderbei. </author> <title> Loqo users manual. </title> <type> Technical Report SOR 92-5, </type> <institution> Prince-ton, University, </institution> <year> 1992. </year>
Reference-contexts: For example, our code, which is called LOQO and is described in <ref> [22, 24] </ref>, uses such a conservative approach. This code actually uses four tiers. The 12 first tier corresponds to all variables except those that are free variables and those associated with dense columns. The second tier consists of all inequality constraints and the dense columns.
Reference: [23] <author> R.J. Vanderbei. </author> <title> ALPO: Another linear program optimizer. </title> <journal> ORSA Journal on Computing, </journal> <volume> 5 </volume> <pages> 134-146, </pages> <year> 1993. </year> <month> 20 </month>
Reference-contexts: AXZ 1 ): (3:5) The advantage of this approach is that the matrix AXZ 1 A T + Y 1 W is symmetric and positive definite, so that well-known and well-behaved methods such as Cholesky factorization (which was used in the implementations described in [14], [4], [17], [15], [18], [12], <ref> [23] </ref>, [21], [13]) or preconditioned conjugate gradient (used in the implementations described in [4], [11], [16]) can be used to solve systems involving this matrix. However, the disadvantage is that AXZ 1 A T can be quite dense compared to A if A has dense columns.

References-found: 23

