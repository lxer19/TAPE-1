URL: ftp://ftp.cs.uoregon.edu/pub/lo/noncontig.ps.gz
Refering-URL: http://www.cs.uoregon.edu/research/DistributedComputing/archive.html
Root-URL: http://www.cs.uoregon.edu
Email: Email: lo, kurtw, wliu@cs.uoregon.edu  Email: nitzberg@nas.nasa.gov  
Phone: Tel: (503) 346-4408  Tel: (415) 604-4513  
Title: Non-contiguous Processor Allocation Algorithms for Mesh-connected Multicomputers 1  
Author: Virginia Lo, Kurt Windisch, and Wanqian Liu Bill Nitzberg 
Keyword: resource management, scheduling, processor allocation, non-contiguous, fragmentation, mesh  
Address: OR 97403  Moffett Field, CA 94035  
Affiliation: Department of Computer and Information Science University of Oregon, Eugene,  NAS Systems Division, NASA Ames Research Center,  
Abstract: Current processor allocation techniques for highly parallel systems are typically restricted to contiguous allocation strategies for which performance suffers significantly due to the inherent problem of fragmentation. As a result, message passing systems have yet to achieve the high utilization levels exhibited by traditional vector supercomputers. We are investigating processor allocation algorithms which lift the restriction on contiguity of processors in order to address the problem of fragmentation. Three non-contiguous processor allocation strategies: Paging allocation, Random allocation and the Multiple Buddy Strategy (MBS) are proposed and studied in this paper. Simulations compare the performance of the non-contiguous strategies with that of several well-known contiguous algorithms. We show that non-contiguous allocation algorithms perform better overall than the contiguous ones, even when message-passing contention is considered. We also present the results of experiments on an Intel Paragon XP/S-15 with 208 nodes that show non-contiguous allocation is feasible with current technologies. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Al-Dhelaan and B. Bose. </author> <title> A new strategy for processor allocation in an n-CUBE multiprocessor. </title> <booktitle> In Proceedings of the International Phoenix Conference on Computers and Communication, </booktitle> <pages> pages 114-118, </pages> <month> March </month> <year> 1989. </year>
Reference: [2] <author> D. H. Bailey, E. Barszcz, L. Dagum, and H. D. Simon. </author> <title> NAS parallel benchmark results 3-94. </title> <type> Technical Report Technical Report RNR-94-006, </type> <institution> NASA Ames Research Center, Moffett Field, </institution> <address> CA 94035-1000, </address> <month> March </month> <year> 1994. </year>
Reference-contexts: The message-passing experiments implement five communication patterns, in which n processors allocated to a job communicate with each other: all-to-all broadcast, one-to-all broadcast, the n-body 20 computation, fast fourier transform (FFT) [16], and multigrid (MG) from the NAS parallel benchmarks <ref> [2] </ref>. These cover many communications patterns used very frequently by highly parallel applications and provide a spectrum of message passing complexity ranging from O (n) to O (n 2 ). <p> We ran two, four, and six copies of selected NAS Parallel Benchmarks <ref> [2] </ref> simultaneously and found no measurable performance difference compared with running the benchmarks one at a time on a dedicated system.
Reference: [3] <author> S. Bhattacharya, L. M. Ni, and W. Tsai. </author> <title> Lookahead processor allocation in mesh-connected massively parallel computers. </title> <type> Technical report, </type> <institution> University of Minnesota (Bhattacharya and Tsai) and Michigan State University (Ni), </institution> <year> 1993. </year>
Reference-contexts: Although no statistics have been compiled for mesh systems, we believe the same trend will be exhibited under the assumption of contiguity. Thus, improved performance requires exploration of other alternatives, including scheduling policies <ref> [3] </ref> [21] [24] and the approach we propose: non-contiguous allocation. 3 Non-contiguous Allocation Strategies 3.1 Random Allocation Strategy One of the most straightforward non-contiguous allocation strategies is the Random allocation strategy, under which a request for k processors is satisfied with k randomly selected processors.
Reference: [4] <author> J. Carbajal, D. Cameron, and Y. Zhu. </author> <title> Node allocation for the mesh-connected paragon supercomputer. </title> <type> Personal communication, </type> <month> April </month> <year> 1994. </year>
Reference-contexts: Another allocation scheme developed for the Intel Paragon accepts three types of job requests: the number of processors needed, a contiguous rectangle, or a list of specified nodes and rectangles which are not necessarily contiguous. Rectangles are found using the Line-Sweep Strategy <ref> [4] </ref> which is adapted from an algorithm for the Largest Rectangle Problem in computational geometry. Limits of Contiguous Allocation Krueger et al. have shown in [15] that increasingly sophisticated contiguous processor allocation algorithms do not significantly influence the performance of hypercube systems.
Reference: [5] <author> M. Chen and K. G. Shin. </author> <title> Processor allocation in an n-CUBE multiprocessor using gray codes. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-36(12):1396-1407, </volume> <month> December </month> <year> 1987. </year>
Reference-contexts: Each job requests a subcube of size sufficient to accommodate the job's needs. The techniques that have been proposed include the Buddy and Gray Code Strategies <ref> [5] </ref> and later refinements for greater recognition [1][9] [13], These schemes were adapted for use in commercial hypercube-based systems such as the Intel iPSC/860 and nCUBE machines. <p> For contiguous allocation, since the minimal enclosing rectangle of the allocation is the allocation itself, the dispersal ratio will always be 0, which represents no contention with other jobs. 3.4.2 Dynamic Optimality An allocation strategy is statically optimal, as defined by Chen and Shin <ref> [5] </ref>, if and only if the strategy can accommodate any valid sequence of job requests, in which each individual job requests no more 13 processors than remain free after allocating all preceding jobs.
Reference: [6] <author> M. Chen and K. G. Shin. </author> <title> Processor allocation in an n-CUBE multiprocessor using gray codes. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-36(12):1396-1407, </volume> <month> December </month> <year> 1987. </year>
Reference-contexts: Definition 4 A processor allocation strategy is dynamically optimal when it can accommodate any allocation and deallocation sequence. If r i in the sequence is limited to be non-negative, i.e. no deallocation can be involved, static optimality as defined in <ref> [6] </ref> is achieved. Theorem 1 A processor allocation strategy is dynamically optimal if and only if it suffers from neither internal nor external fragmentation. Proof: 1. Soundness: Assume that an allocation strategy is optimal but suffers from either internal or external fragmentation, or both.
Reference: [7] <author> P. Chuang and N. Tzeng. </author> <title> An efficient submesh allocation strategy for mesh computer systems. </title> <booktitle> In 1991 International Conference on Distributed Computer Systems, </booktitle> <pages> pages 256-263, </pages> <year> 1991. </year>
Reference-contexts: Frame Sliding Chuang and Tzeng proposed an improved strategy called the frame sliding strategy <ref> [7] </ref>. It is applicable to any mesh system and any shape of submesh request, thus it has no internal fragmentation. <p> analyze the performance of a range of scheduling algorithms in conjunction with both contiguous and non-contiguous allocation. 4.1 Fragmentation Experiments The first set of experiments, studying the effects of fragmentation on system utilization and job response time, are modeled after the simulation experiments conducted in previous allocation strategy research [31] <ref> [7] </ref> [15]. In these experiments, jobs arrive, delay for an amount of time taken from an exponential distribution, and then depart. Message-passing is not modeled. The contiguous allocation strategies simulated in these experiments are First Fit, Best Fit [31], and Frame Sliding [7]. 15 From the non-contiguous strategies, we only present <p> experiments conducted in previous allocation strategy research [31] <ref> [7] </ref> [15]. In these experiments, jobs arrive, delay for an amount of time taken from an exponential distribution, and then depart. Message-passing is not modeled. The contiguous allocation strategies simulated in these experiments are First Fit, Best Fit [31], and Frame Sliding [7]. 15 From the non-contiguous strategies, we only present the results for the Paging algorithms. With respect to the fragmentation measured in this experiment, P aging indexing scheme (0) performs identically, for all indexing schemes, to the Random and the Multiple Buddy strategies.
Reference: [8] <author> W. J. Dally and C. L. Seitz. </author> <title> The torus routing chip. </title> <booktitle> Distributed Computing, </booktitle> <year> 1986. </year>
Reference: [9] <author> S. Dutt and J. P. Hayes. </author> <title> Subcube allocation in hypercube computers. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 40(3) </volume> <pages> 341-352, </pages> <month> March </month> <year> 1991. </year> <month> 30 </month>
Reference: [10] <author> D. G. Feitelson. </author> <title> A survey of scheduling in multiprogrammed parallel systems. </title> <type> Technical Report RC 19790 (87657), </type> <institution> IBM Research Division, T.J. Watson Research Center, </institution> <address> Yorktown Heights, NY 10598, </address> <month> October </month> <year> 1994. </year>
Reference-contexts: Furthermore, non-contiguous allocation is compatible with adaptive processor allocation schemes [23], in which a job may increase or decrease its allocation at runtime and supports straightforward extensions for fault tolerance. We focus on the class of parallel systems that use variable partitioning to allocate jobs <ref> [10] </ref>. Independent user jobs arrive in the system, requesting a particular sized partition of the system's processors. If an arriving job can not be run immediately, due to a lack of free processors or other waiting jobs, the job is diverted to the system waiting queue.
Reference: [11] <author> M. L. Fulgham and L. Snyder. </author> <title> Performance of chaos and oblivious routers under non-uniform traffic. </title> <type> Technical report, </type> <institution> University of Washington, </institution> <year> 1993. </year>
Reference: [12] <author> Intel Corp. </author> <title> Paragon network queuing system manual. </title> <month> October </month> <year> 1993. </year>
Reference: [13] <author> J. Kim, C. R. Das, and W. Lin. </author> <title> A top-down processor allocation scheme for hypercube computers. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 2(1) </volume> <pages> 20-30, </pages> <month> January </month> <year> 1991. </year>
Reference-contexts: Each job requests a subcube of size sufficient to accommodate the job's needs. The techniques that have been proposed include the Buddy and Gray Code Strategies [5] and later refinements for greater recognition [1][9] <ref> [13] </ref>, These schemes were adapted for use in commercial hypercube-based systems such as the Intel iPSC/860 and nCUBE machines. Contiguous and Non-contiguous Allocation in the Intel Paragon The effectiveness of non-contiguous processor allocation has been demonstrated on a 400 node Paragon housed at the San Diego Supercomputing Center.
Reference: [14] <author> D. E. Knuth. </author> <title> Fundamental Algorithms: Volume I. </title> <publisher> Addison Wesley, </publisher> <year> 1973. </year>
Reference-contexts: Work by Phillip Krueger, et al. [15], describes the performance limitations of all contiguous allocation schemes and thus motivates our investigation of non-contiguous approaches. 2-D Buddy The two-dimensional buddy strategy, a generalization of the one-dimensional binary buddy system for memory management [26] <ref> [14] </ref>, is proposed by Li and Cheng [17] as an allocation strategy for a mesh connected system.
Reference: [15] <author> P. Krueger, T. Lai, and V. A. Dixit-Radiya. </author> <title> Job scheduling is more important than processor allocation for hypercube computers. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 5(5) </volume> <pages> 488-497, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: External fragmentation exists when a sufficient number of processors are available to satisfy a request, but they cannot be allocated contiguously. Experimental evidence has shown that little improvement in performance can be realized by refinements of contiguous allocation algorithms <ref> [15] </ref>. As a result, recent research efforts have focused on the choice of job scheduling policies and their impact on contiguous allocation schemes. Our research takes a different approach to overcoming the limitations of contiguous allocation. <p> Variations of these conventional algorithms, as well as an interesting algorithm with similarities to MBS, have been implemented on real mesh and hypercube systems. Work by Phillip Krueger, et al. <ref> [15] </ref>, describes the performance limitations of all contiguous allocation schemes and thus motivates our investigation of non-contiguous approaches. 2-D Buddy The two-dimensional buddy strategy, a generalization of the one-dimensional binary buddy system for memory management [26] [14], is proposed by Li and Cheng [17] as an allocation strategy for a mesh <p> Rectangles are found using the Line-Sweep Strategy [4] which is adapted from an algorithm for the Largest Rectangle Problem in computational geometry. Limits of Contiguous Allocation Krueger et al. have shown in <ref> [15] </ref> that increasingly sophisticated contiguous processor allocation algorithms do not significantly influence the performance of hypercube systems. Their simulations of four well-known hypercube allocation strategies, which are equally significant for mesh systems, realized limited improvements despite the differing abilities of these algorithms to reduce fragmentation and recognize available subcubes. <p> the performance of a range of scheduling algorithms in conjunction with both contiguous and non-contiguous allocation. 4.1 Fragmentation Experiments The first set of experiments, studying the effects of fragmentation on system utilization and job response time, are modeled after the simulation experiments conducted in previous allocation strategy research [31] [7] <ref> [15] </ref>. In these experiments, jobs arrive, delay for an amount of time taken from an exponential distribution, and then depart. Message-passing is not modeled.
Reference: [16] <author> V. Kumar, A. Grama, A. Gupta, and G. Karypis. </author> <title> Introduction to Parallel Computing. </title> <publisher> Benjamin Cummings Publishing Company, Inc., </publisher> <year> 1994. </year>
Reference-contexts: This results in packet blocking time, due to contention, which can be measured in the simulation. The message-passing experiments implement five communication patterns, in which n processors allocated to a job communicate with each other: all-to-all broadcast, one-to-all broadcast, the n-body 20 computation, fast fourier transform (FFT) <ref> [16] </ref>, and multigrid (MG) from the NAS parallel benchmarks [2]. These cover many communications patterns used very frequently by highly parallel applications and provide a spectrum of message passing complexity ranging from O (n) to O (n 2 ).
Reference: [17] <author> K. Li and K. Cheng. </author> <title> A two-dimensional buddy system for dynamic resource allocation in a parti-tionable mesh connected system. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 12 </volume> <pages> 79-83, </pages> <year> 1991. </year>
Reference-contexts: Work by Phillip Krueger, et al. [15], describes the performance limitations of all contiguous allocation schemes and thus motivates our investigation of non-contiguous approaches. 2-D Buddy The two-dimensional buddy strategy, a generalization of the one-dimensional binary buddy system for memory management [26] [14], is proposed by Li and Cheng <ref> [17] </ref> as an allocation strategy for a mesh connected system. <p> It is an extension of the 2-D buddy strategy <ref> [17] </ref>, which has both internal and external fragmentation problems. MBS eliminates fragmentation by applying the non-contiguous model to the mesh system, while still maintaining contiguity within individual blocks.
Reference: [18] <author> W. Liu, V. M. Lo, K. Windisch, and B. Nitzberg. </author> <title> Non-contiguous processor allocation algorithms for distributed memory multicomputers. </title> <booktitle> In Proceedings of Supercomputing 1994, </booktitle> <pages> pages 227-236, </pages> <year> 1994. </year> <title> Best student paper award. </title>
Reference: [19] <author> B. MacCabe and K. McCurley. </author> <title> SUNMOS for the Intel Paragon. </title> <type> unpublished, </type> <year> 1993. </year>
Reference-contexts: In addition to using the operating system supplied by Intel, Paragon OS release 1.1, we ran worst-case contention tests under SUNMOS, a minimal operating system developed by Sandia National Labs and the University of New Mexico <ref> [19] </ref>. 25 One would expect message contention to have a noticeable impact on performance; however, we were unable to measure any performance degradation on real applications due to contention.
Reference: [20] <author> M. H. MacDougall. </author> <title> Simulating Computer Systems: Techniques and Tools. </title> <publisher> The MIT Press, </publisher> <year> 1987. </year>
Reference: [21] <author> P. Mohapatra, C. Yu, C. R. Das, and J. Kim. </author> <title> A lazy scheduling scheme for improving hypercube performance. </title> <booktitle> In International Conference on Parallel Processing, </booktitle> <year> 1993. </year>
Reference-contexts: Although no statistics have been compiled for mesh systems, we believe the same trend will be exhibited under the assumption of contiguity. Thus, improved performance requires exploration of other alternatives, including scheduling policies [3] <ref> [21] </ref> [24] and the approach we propose: non-contiguous allocation. 3 Non-contiguous Allocation Strategies 3.1 Random Allocation Strategy One of the most straightforward non-contiguous allocation strategies is the Random allocation strategy, under which a request for k processors is satisfied with k randomly selected processors.
Reference: [22] <author> R. Moore and M. Wan. </author> <title> Intel Paragon allocation algorithms. </title> <type> Personal communication, </type> <year> 1995. </year> <month> 31 </month>
Reference: [23] <author> V. K. Naik, S. K. Setia, and M. S. Squillante. </author> <title> Performance analysis of job scheduling policies in parallel supercomputing environments. </title> <booktitle> In Proceedings of Supercomputing 1993, </booktitle> <pages> pages 824-833, </pages> <year> 1993. </year>
Reference-contexts: As we shall show, non-contiguous allocation offers several significant advantages over contiguous schemes, including the elimination of internal and external fragmentation and low allocation and deallocation overheads. Furthermore, non-contiguous allocation is compatible with adaptive processor allocation schemes <ref> [23] </ref>, in which a job may increase or decrease its allocation at runtime and supports straightforward extensions for fault tolerance. We focus on the class of parallel systems that use variable partitioning to allocate jobs [10].
Reference: [24] <author> B. Narahari and R. Krishnamurti. </author> <title> Scheduling independent tasks on partitionable hypercube multiprocessors. </title> <booktitle> In Proceedings of the International Parallel Processing Symposium, </booktitle> <year> 1993. </year>
Reference-contexts: Although no statistics have been compiled for mesh systems, we believe the same trend will be exhibited under the assumption of contiguity. Thus, improved performance requires exploration of other alternatives, including scheduling policies [3] [21] <ref> [24] </ref> and the approach we propose: non-contiguous allocation. 3 Non-contiguous Allocation Strategies 3.1 Random Allocation Strategy One of the most straightforward non-contiguous allocation strategies is the Random allocation strategy, under which a request for k processors is satisfied with k randomly selected processors.
Reference: [25] <author> L. M. Ni and P. K. McKinley. </author> <title> A survey of wormhole routing techniques in direct networks. </title> <journal> IEEE Trans. Computers, </journal> <year> 1993. </year>
Reference-contexts: Although messages from other jobs may pass through this new partition, the 2 new job holds these processors exclusively until it finishes running. At this time, it departs the system and its processors are freed for use by other incoming jobs. Current communication technologies like wormhole routing <ref> [25] </ref> enable us to consider non-contiguous allocation, since the number of hops between processors is not the dominant factor determining message latency. However, we also note that non-contiguous allocation introduces potential problems due to message contention because the messages occupy more links, yielding potential communication interference with other jobs. <p> These routing switches are connected by two uni-directional channels to neighboring switches in the mesh and to the corresponding processor elements. The flow control mechanism governing flit movement (flits are the smallest unit of data transmission in the network) is wormhole routing <ref> [25] </ref>. Messages originate from a processor element and their flits traverse the network in pipeline fashion to their destination processor.
Reference: [26] <author> J. L. Peterson and T. A. Norman. </author> <title> Buddy systems. </title> <journal> Communications of the ACM, </journal> <volume> 20(6) </volume> <pages> 421-431, </pages> <month> June </month> <year> 1977. </year>
Reference-contexts: Work by Phillip Krueger, et al. [15], describes the performance limitations of all contiguous allocation schemes and thus motivates our investigation of non-contiguous approaches. 2-D Buddy The two-dimensional buddy strategy, a generalization of the one-dimensional binary buddy system for memory management <ref> [26] </ref> [14], is proposed by Li and Cheng [17] as an allocation strategy for a mesh connected system.
Reference: [27] <author> C. L. Seitz. </author> <title> The cosmic cube. </title> <journal> Communications of the ACM, </journal> <volume> 28(1) </volume> <pages> 22-33, </pages> <month> January </month> <year> 1985. </year>
Reference-contexts: In the one-to-all broadcast pattern, a randomly selected processor sends a message to every other processor in the job, loading the network with O (n) simultaneous messages per iteration. The n-body communication pattern, described in <ref> [27] </ref>, loads the network with O (n) simultaneous messages per iteration, that are directed in a ring pattern. The 2D FFT pattern sends O (n log n) messages, and the NAS Multigrid sends O (n) messages.
Reference: [28] <author> B. VanVoorst, S. Seidel, and E. Barszcz. </author> <title> Profiling the communication workload of an iPSC/860. </title> <booktitle> In Scalable High Performance Computing Conference, </booktitle> <month> May </month> <year> 1994. </year>
Reference-contexts: The poor operating system performance will likely be corrected in future releases of the Paragon OS, but the level of contention for of small messages will likely remain low. VanVoorst, et. al. <ref> [28] </ref>, measured the workload of the Intel iPSC/860 system at NAS for ten days, and found that 87% of all messages are, in fact, one kilobyte or less. So, at least for a class of scientific applications, large messages may not be a significant issue.
Reference: [29] <author> K. Windisch, V. M. Lo, and B. Bose. </author> <title> Contiguous and non-contiguous processor allocation algorithms for k-ary n-cubes. </title> <booktitle> In Proceedings of the International Conference on Parallel Processing, </booktitle> <year> 1995. </year> <note> To appear. </note>
Reference-contexts: We compare the performance of three non-contiguous processor allocation strategies: Random, Paging, and the Multiple Buddy Strategy (MBS), with three well-known contiguous allocation schemes: Frame Sliding, First Fit, and Best Fit. These strategies represent a continuum with respect to degree of contiguity. As we have shown in <ref> [29] </ref>, these strategies are also directly applicable to processor allocation in k-ary n-cubes which include the hypercube and torus.
Reference: [30] <author> K. Windisch, J. V. Miller, and V. Lo. Procsimity: </author> <title> an experimental tool for processor allocation and scheduling in highly parallel systems. </title> <booktitle> In Proceedings of the Fifth Symposium on the Frontiers of Massively Parallel Computation, </booktitle> <pages> pages 414-421, </pages> <month> February </month> <year> 1995. </year>
Reference-contexts: Our discrete event simulator, ProcSimity <ref> [30] </ref>, is a multicomputer simulator supporting experimentation with selected allocation and scheduling algorithms on architectures with a range of network topologies and several current routing and flow control mechanisms.
Reference: [31] <author> Y. Zhu. </author> <title> Efficient processor allocation strategies for mesh-connected parallel computers. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 16 </volume> <pages> 328-337, </pages> <year> 1992. </year>
Reference-contexts: This 4 strategy has better performance than the 2-D buddy strategy. However, (1) it has higher allocation overhead, O (n); (2) it suffers from large external fragmentation; and (3) it cannot recognize all possible free submeshes. First Fit and Best Fit In <ref> [31] </ref>, Zhu proposed the first fit and best fit strategies, which can be applied for contiguous submesh requests of arbitrary sizes and have the ability to recognize all free submeshes in a system. <p> which analyze the performance of a range of scheduling algorithms in conjunction with both contiguous and non-contiguous allocation. 4.1 Fragmentation Experiments The first set of experiments, studying the effects of fragmentation on system utilization and job response time, are modeled after the simulation experiments conducted in previous allocation strategy research <ref> [31] </ref> [7] [15]. In these experiments, jobs arrive, delay for an amount of time taken from an exponential distribution, and then depart. Message-passing is not modeled. The contiguous allocation strategies simulated in these experiments are First Fit, Best Fit [31], and Frame Sliding [7]. 15 From the non-contiguous strategies, we only <p> modeled after the simulation experiments conducted in previous allocation strategy research <ref> [31] </ref> [7] [15]. In these experiments, jobs arrive, delay for an amount of time taken from an exponential distribution, and then depart. Message-passing is not modeled. The contiguous allocation strategies simulated in these experiments are First Fit, Best Fit [31], and Frame Sliding [7]. 15 From the non-contiguous strategies, we only present the results for the Paging algorithms. With respect to the fragmentation measured in this experiment, P aging indexing scheme (0) performs identically, for all indexing schemes, to the Random and the Multiple Buddy strategies. <p> The results measured in these experiments are all consistent with those reported by Zhu in <ref> [31] </ref> for the contiguous Frame Sliding, First Fit and Best Fit strategies. These fragmentation experiments indicate that non-contiguous allocation is far superior to contiguous in terms of its ability to utilize the processors.
References-found: 31

