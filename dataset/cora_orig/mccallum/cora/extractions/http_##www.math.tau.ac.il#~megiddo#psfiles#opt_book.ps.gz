URL: http://www.math.tau.ac.il/~megiddo/psfiles/opt_book.ps.gz
Refering-URL: http://www.math.tau.ac.il/~megiddo/pub.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Maximizing Concave Functions in Fixed Dimension  
Author: Edith Cohen Nimrod Megiddo 
Address: Stanford, CA 94305  San Jose, CA 95120-6099  Israel.  
Affiliation: Department of Computer Science, Stanford University,  and IBM Almaden Research Center.  IBM Almaden Research Center,  and School of Mathematical Sciences, Tel Aviv University, Tel Aviv,  
Abstract: In [3, 5, 2] the authors introduced a technique which enabled them to solve the parametric minimum cycle problem with a fixed number of parameters in strongly polynomial time. In the current paper 1 we present this technique as a general tool. In order to allow for an independent reading of this paper, we repeat some of the definitions and propositions given in [3, 5, 2]. Some proofs are not repeated, however, and instead we supply the interested reader with appropriate pointers. Suppose Q R d is a convex set given as an intersection of k halfspaces, and let g : Q ! R be a concave function that is computable by a piecewise affine algorithm (i.e., roughly, an algorithm that performs only multiplications by scalars, additions, and comparisons of intermediate values which depend on the input). Assume that such an algorithm A is given and the maximal number of operations required by A on any input (i.e., point in Q) is T . We show that under these assumptions, for any fixed d, the function g can be maximized in a number of operations polynomial in k and T . We also present a general framework for parametric extensions of problems where this technique can be used to obtain strongly polynomial algorithms. Norton, Plotkin, and Tardos [12] applied a similar scheme and presented additional applications. Keywords: Complexity, concave-cost network flow, capacitated, global optimization, local optimization. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> K. L. Clarkson. </author> <title> Linear programming in O(n fi 3 d 2 ) time. </title> <journal> Information Processing Let., </journal> <volume> 22 </volume> <pages> 21-27, </pages> <year> 1986. </year>
Reference-contexts: We then define the notions of maximum and concavity of g with respect to the lexicographic order as follows. We say that a function g : Q R d ! R ` is concave with respect to the lexicographic order lex if for every ff 2 <ref> [0; 1] </ref> and x; y 2 Q, Applications where the range of g is R 2 were given in [6]. In Section 2. we define the problem. In Section 3. we introduce the subproblem of hyperplane queries, which is essential for the design of our algorithm. <p> The function fl (d) arises from the multi-dimensional search [11]. It follows from <ref> [1, 8] </ref> that fl (d) = 3 O (d 2 ) . 5. The algorithm The algorithm described below solves Problem 2.8. It finds a vector fl 2 rel int fl, unless g is unbounded.
Reference: [2] <author> E. Cohen. </author> <title> Combinatorial Algorithms for Optimization Problems. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, Stanford University, Stanford, </institution> <address> Ca., </address> <year> 1991. </year>
Reference-contexts: It is easy to verify that A fi evaluates the function g fi for any vector 2 Q fi , and performs the stated number of operations. Proposition 2.7. If fi 2 fl g then g fi is a weak approximation of g. Proof: See <ref> [5, 2] </ref> for a proof. The goal is to solve the following problem: Problem 2.8. <p> The set C may be viewed as a certificate for the fact that the maximum of the function g does not exceed g ( fl ). In the current paper we do not discuss the details of solving the optional part of the problem. See <ref> [5, 2] </ref> for an existence proof and an algorithm which finds such a set. We propose an algorithm for Problem 2.8. In any fixed dimension d, the total number of operations performed by this algorithm is bounded by a polynomial in T (A) and k. <p> It follows from Proposition 2.7 that the pieces of g active in a minimal weak approximation have the value t (0) at (0) . Thus, a minimal weak approximation of the function g (0) is a minimal weak approximation of g. It follows from analysis done in <ref> [5, 2] </ref> that by using O (d 3 ) operations we can construct a minimal weak approximation of g (0) . Furthermore, the number of pieces involved in a minimal weak approximation is at most 2d. <p> Observe that this conclusion could not have been made if the algorithm considered the values of g, rather than the values of the restriction g 2 , at the hyperplanes f1g and f3g. 4. Employing multi-dimensional search The definitions and propositions stated in this section appeared in <ref> [3, 5, 2] </ref>. They are presented here to allow for an independent reading of this paper. For proofs, the reader is referred to [3, 5, 2]. The multi-dimensional search problem was defined and used in [11] for solving linear programming problems in fixed dimension. <p> Employing multi-dimensional search The definitions and propositions stated in this section appeared in <ref> [3, 5, 2] </ref>. They are presented here to allow for an independent reading of this paper. For proofs, the reader is referred to [3, 5, 2]. The multi-dimensional search problem was defined and used in [11] for solving linear programming problems in fixed dimension. In this section we employ it to achieve better time bounds. Definition 4.1. <p> Lueker, Megiddo and Ramachandran [9] gave a polylogarithmic time parallel algorithm for the problem which uses a quasipolynomial number of processors. The best known time bounds for the problem were given in <ref> [7, 2] </ref>. Cosares, using nested parametrization, extended Megiddo's strong polynomiality result to allow objective functions which have a fixed number of nonzero coefficients. This result can be further extended to include the following.
Reference: [3] <author> E. Cohen and N. Megiddo. </author> <title> Strongly polynomial and NC algorithms for detecting cycles in dynamic graphs. </title> <booktitle> In Proc. 21st Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 523-534. </pages> <publisher> ACM, </publisher> <year> 1989. </year>
Reference-contexts: Observe that this conclusion could not have been made if the algorithm considered the values of g, rather than the values of the restriction g 2 , at the hyperplanes f1g and f3g. 4. Employing multi-dimensional search The definitions and propositions stated in this section appeared in <ref> [3, 5, 2] </ref>. They are presented here to allow for an independent reading of this paper. For proofs, the reader is referred to [3, 5, 2]. The multi-dimensional search problem was defined and used in [11] for solving linear programming problems in fixed dimension. <p> Employing multi-dimensional search The definitions and propositions stated in this section appeared in <ref> [3, 5, 2] </ref>. They are presented here to allow for an independent reading of this paper. For proofs, the reader is referred to [3, 5, 2]. The multi-dimensional search problem was defined and used in [11] for solving linear programming problems in fixed dimension. In this section we employ it to achieve better time bounds. Definition 4.1. <p> If the algorithm A is inherently sequential, then the total number of operations is O (kT (A)C (A) d ). 8. Parametric extensions of problems The technique described in this paper was employed in <ref> [3, 5] </ref> to get algorithms for the parametric extensions of the minimum cycle and the minimum cycle-mean problems.
Reference: [4] <author> E. Cohen and N. Megiddo. </author> <title> Maximizing concave functions in fixed dimension. </title> <type> Technical Report RJ 7656 (71103), </type> <institution> IBM Almaden Research Center, </institution> <address> San Jose, CA 95120-6099, </address> , <month> August </month> <year> 1990. </year>
Reference: [5] <author> E. Cohen and N. Megiddo. </author> <title> Strongly polynomial time and NC algorithms for detecting cycles in periodic graphs. </title> <type> Technical Report RJ 7587 (70764), </type> <institution> IBM Almaden Research Center, </institution> <address> San Jose, CA 95120-6099, </address> , <month> July </month> <year> 1990. </year>
Reference-contexts: It is easy to verify that A fi evaluates the function g fi for any vector 2 Q fi , and performs the stated number of operations. Proposition 2.7. If fi 2 fl g then g fi is a weak approximation of g. Proof: See <ref> [5, 2] </ref> for a proof. The goal is to solve the following problem: Problem 2.8. <p> The set C may be viewed as a certificate for the fact that the maximum of the function g does not exceed g ( fl ). In the current paper we do not discuss the details of solving the optional part of the problem. See <ref> [5, 2] </ref> for an existence proof and an algorithm which finds such a set. We propose an algorithm for Problem 2.8. In any fixed dimension d, the total number of operations performed by this algorithm is bounded by a polynomial in T (A) and k. <p> It follows from Proposition 2.7 that the pieces of g active in a minimal weak approximation have the value t (0) at (0) . Thus, a minimal weak approximation of the function g (0) is a minimal weak approximation of g. It follows from analysis done in <ref> [5, 2] </ref> that by using O (d 3 ) operations we can construct a minimal weak approximation of g (0) . Furthermore, the number of pieces involved in a minimal weak approximation is at most 2d. <p> Observe that this conclusion could not have been made if the algorithm considered the values of g, rather than the values of the restriction g 2 , at the hyperplanes f1g and f3g. 4. Employing multi-dimensional search The definitions and propositions stated in this section appeared in <ref> [3, 5, 2] </ref>. They are presented here to allow for an independent reading of this paper. For proofs, the reader is referred to [3, 5, 2]. The multi-dimensional search problem was defined and used in [11] for solving linear programming problems in fixed dimension. <p> Employing multi-dimensional search The definitions and propositions stated in this section appeared in <ref> [3, 5, 2] </ref>. They are presented here to allow for an independent reading of this paper. For proofs, the reader is referred to [3, 5, 2]. The multi-dimensional search problem was defined and used in [11] for solving linear programming problems in fixed dimension. In this section we employ it to achieve better time bounds. Definition 4.1. <p> If the algorithm A is inherently sequential, then the total number of operations is O (kT (A)C (A) d ). 8. Parametric extensions of problems The technique described in this paper was employed in <ref> [3, 5] </ref> to get algorithms for the parametric extensions of the minimum cycle and the minimum cycle-mean problems.
Reference: [6] <author> E. Cohen and N. Megiddo. </author> <title> Complexity analysis and algorithms for some flow problems. </title> <booktitle> In Proc. 2nd ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <pages> pages 120-130. ACM-SIAM, </pages> <year> 1991. </year>
Reference-contexts: We say that a function g : Q R d ! R ` is concave with respect to the lexicographic order lex if for every ff 2 [0; 1] and x; y 2 Q, Applications where the range of g is R 2 were given in <ref> [6] </ref>. In Section 2. we define the problem. In Section 3. we introduce the subproblem of hyperplane queries, which is essential for the design of our algorithm. In Section 4. we discuss the multi-dimensional search technique which we utilize for improving our time bounds. <p> It is easy to verify that the conditions of Theorem 8.2 hold. Hence, this class of problems also has a strongly polynomial time algorithm, and a polylogarithmic time parallel algorithm which uses a quasipolynomial number of processors. Parametric flow problems. Theorem 8.2 was applied in <ref> [6] </ref> to generate strongly polynomial algorithms for parametric flow problems with a fixed number of param 13 eters and to some constrained flow problems with a fixed number of additional con-straints. Complementing results showing the P-completeness of these problems when the number of parameters is not fixed, were also given.
Reference: [7] <author> E. Cohen and N. Megiddo. </author> <title> Improved algorithms for linear inequalities with two variables per inequality. </title> <booktitle> In Proc. 23rd Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 145-155. </pages> <publisher> ACM, </publisher> <year> 1991. </year>
Reference-contexts: Lueker, Megiddo and Ramachandran [9] gave a polylogarithmic time parallel algorithm for the problem which uses a quasipolynomial number of processors. The best known time bounds for the problem were given in <ref> [7, 2] </ref>. Cosares, using nested parametrization, extended Megiddo's strong polynomiality result to allow objective functions which have a fixed number of nonzero coefficients. This result can be further extended to include the following.
Reference: [8] <author> M. E. Dyer. </author> <title> On a multidimensional search technique and its application to the Euclidean one-center problem. </title> <journal> SIAM J. Comput., </journal> <volume> 15 </volume> <pages> 725-738, </pages> <year> 1986. </year>
Reference-contexts: The function fl (d) arises from the multi-dimensional search [11]. It follows from <ref> [1, 8] </ref> that fl (d) = 3 O (d 2 ) . 5. The algorithm The algorithm described below solves Problem 2.8. It finds a vector fl 2 rel int fl, unless g is unbounded.
Reference: [9] <author> G. S. Lueker, N. Megiddo, and V. Ramachandran. </author> <title> Linear programming with two variables per inequality in poly log time. </title> <journal> SIAM J. Comput., </journal> <volume> 19(6) </volume> <pages> 1000-1010, </pages> <year> 1990. </year>
Reference-contexts: Adding variables to LP's with two variables per inequality. Linear programming problems with at most two variables in each constraint and in the objective function were shown to have a strongly polynomial time algorithm by Megiddo [10]. Lueker, Megiddo and Ramachandran <ref> [9] </ref> gave a polylogarithmic time parallel algorithm for the problem which uses a quasipolynomial number of processors. The best known time bounds for the problem were given in [7, 2].
Reference: [10] <author> N. Megiddo. </author> <title> Towards a genuinely polynomial algorithm for linear programming. </title> <journal> SIAM J. Comput., </journal> <volume> 12 </volume> <pages> 347-353, </pages> <year> 1983. </year>
Reference-contexts: Additional applications were found by Norton, Plotkin, and Tardos [12]. Adding variables to LP's with two variables per inequality. Linear programming problems with at most two variables in each constraint and in the objective function were shown to have a strongly polynomial time algorithm by Megiddo <ref> [10] </ref>. Lueker, Megiddo and Ramachandran [9] gave a polylogarithmic time parallel algorithm for the problem which uses a quasipolynomial number of processors. The best known time bounds for the problem were given in [7, 2].
Reference: [11] <author> N. Megiddo. </author> <title> Linear programming in linear time when the dimension is fixed. </title> <journal> J. Assoc. Comput. Mach., </journal> <volume> 31 </volume> <pages> 114-127, </pages> <year> 1984. </year> <month> 14 </month>
Reference-contexts: Otherwise, the decision can be made by considering a neighborhood of the maximum of the function relative to H 0 , searching for a direction of ascent from that point. This principle is explained in detail in <ref> [11] </ref>. For a hyperplane H 0 R d , we wish to decide on which side of H 0 the set rel int fl lies. <p> By solving a linear program with d variables and k + 1 constraints, we determine whether or not H 0 " Q = ;, and if so, we determine which side of H 0 contains Q. It follows from <ref> [11] </ref> that this can be done in O (k) time. If H 0 " Q 6= ;, then the oracle problem solves the original problem, when g is restricted to H 0 . If g is unbounded on H 0 the oracle reveals that. <p> An algorithm for the oracle problem is given in Section 3.. A call to the oracle is costly. Therefore, one wishes to solve many hyperplane queries with a small number of oracle calls. In Section 4. we discuss the multi-dimensional search technique (introduced in <ref> [11] </ref>). 3. Hyperplane queries For a hyperplane H R d , we solve Problem 2.9 for g relative to H. Theorem 3.1. <p> Employing multi-dimensional search The definitions and propositions stated in this section appeared in [3, 5, 2]. They are presented here to allow for an independent reading of this paper. For proofs, the reader is referred to [3, 5, 2]. The multi-dimensional search problem was defined and used in <ref> [11] </ref> for solving linear programming problems in fixed dimension. In this section we employ it to achieve better time bounds. Definition 4.1. <p> The function fl (d) arises from the multi-dimensional search <ref> [11] </ref>. It follows from [1, 8] that fl (d) = 3 O (d 2 ) . 5. The algorithm The algorithm described below solves Problem 2.8. It finds a vector fl 2 rel int fl, unless g is unbounded. <p> Step 2. Denote by P the intersection of the halfspaces in H. (i) Compute fl 2 rel int P " Q. This amounts to a linear programming problem with d variables and jHj constraints, and hence it can be solved in O (jHj) sequential time <ref> [11] </ref>. Note that the size of H is bounded by the number of oracle calls. (ii) If L fmg is not constant on R d , that is, not all of m 1 ; m 2 ; . . . ; m d equal zero, then g is unbounded.
Reference: [12] <author> C. H. Norton, S. A. Plotkin, and E. Tardos. </author> <title> Using separation algorithms in fixed dimension. </title> <booktitle> In Proc. 1st ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <pages> pages 377-387. ACM-SIAM, </pages> <year> 1990. </year> <month> 15 </month>
Reference-contexts: Below we present some applications of Theorem 8.2. Additional applications were found by Norton, Plotkin, and Tardos <ref> [12] </ref>. Adding variables to LP's with two variables per inequality. Linear programming problems with at most two variables in each constraint and in the objective function were shown to have a strongly polynomial time algorithm by Megiddo [10].
References-found: 12

