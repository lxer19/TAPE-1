URL: ftp://ftp.cs.virginia.edu/pub/techreports/CS-91-21.ps.Z
Refering-URL: ftp://ftp.cs.virginia.edu/pub/techreports/README.html
Root-URL: http://www.cs.virginia.edu
Title: One Dimensional Motion Tailoring for the Disabled: A User Study  
Author: Randy Pausch, Laura Vogtle and Matthew Conway 
Note: This work was supported in part by the National Science Foundation, the Science Applications International Corporation, the Virginia Engineering Foundation, the Virginia Center for Innovative Technology, and the United Cerebral Palsy Foundation.  
Date: October 7, 1991  
Affiliation: Computer Science  
Pubnum: Report No. TR-91-21  
Abstract-found: 0
Intro-found: 1
Reference: [Bird] <author> J. Scully, Ascension Technology Corporation, </author> <title> PO Box 527, </title> <type> Burlington, VT 05402. U.S. Patent #4,849,692. </type>
Reference-contexts: For future trials, we will elimi attachment site able-bodied CP head 2 1 Right Wrist 5 2 Left Wrist 5 5 Left Elbow 2 0 Table 1: Body Attachment Points nate the need for this by switching to alternative tracking technologies that are less sensitive to metal <ref> [Bird] </ref>. CP is often accompanied by poor vision [Wolraich]; we acquired a large monitor and made sure that the subjects were seated close enough that they could easily see the ball and paddle. We explained to the children that they were helping us experiment with a new device.
Reference: [Bolt] <author> R. </author> <title> Bolt, Put-That-There: Voice & Gesture at the Graphics Interface, </title> <booktitle> Computer Graphics, 14,3 (1980), </booktitle> <pages> pp. 262-270. </pages>
Reference-contexts: Recognition of three-dimensional gestures has also been attempted, but again the main emphasis has been on converting the body motions into discrete symbols that are interpreted as commands to the system <ref> [Bolt, Bux-ton] </ref>. Systems have attempted to recognize static gestures for the deaf alphabet and motions for a subset of American Sign Language. All of these approaches are based on converting three-dimensional signals into a discrete stream of tokens.
Reference: [Buxton] <author> W. Buxton, E. Fiume, R. Hill, A. Lee and C. Woo, </author> <title> Continuous hand-gesture driven input, </title> <booktitle> Proceedings of Graphics Interface 83, </booktitle> <pages> pp. 191-195. </pages>
Reference: [Foley] <author> J. D. Foley, </author> <title> Interfaces for Advanced Computing, </title> <publisher> Scientific American, </publisher> <month> October, </month> <year> 1987, </year> <pages> 127-135. </pages>
Reference-contexts: The pilots faceshield contains targeting crosshairs, and as the pilots helmet moves with his head, the system computes the angle of his gaze [Furness]. More detailed tracking is performed in three dimensional drawing or sculpting applications [Schmandt], and virtual reality systems, where sensors attached to gloves <ref> [Foley] </ref> pro vide three-dimensional signals that are mapped into motions in synthetic worlds shown on traditional or head-mounted displays. These systems perform mappings from position and orientation information, but the mappings are significantly less complicated than those we propose.
Reference: [Furness] <author> T. A. Furness, </author> <title> Super Cockpit: Virtual Crew Systems, </title> <institution> Armstrong Aerospace Medical Research Laboratory, </institution> <year> 1988. </year>
Reference-contexts: For example, advanced military systems exist which map pilot head motion into weapon trajectories. The pilots faceshield contains targeting crosshairs, and as the pilots helmet moves with his head, the system computes the angle of his gaze <ref> [Furness] </ref>. More detailed tracking is performed in three dimensional drawing or sculpting applications [Schmandt], and virtual reality systems, where sensors attached to gloves [Foley] pro vide three-dimensional signals that are mapped into motions in synthetic worlds shown on traditional or head-mounted displays.
Reference: [Girson] <author> A. Girson and R. Williams, </author> <title> Articulator-Based Synthesis For Conversational Speech, </title> <booktitle> International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <month> April, </month> <year> 1990. </year>
Reference: [Liang] <author> J. Liang, C. Shaw, and M. Green, </author> <title> On Temporal-Spatial Realism in the Virtual Reality Environment, </title> <booktitle> Proceedings of UIST: the Annual ACM SIGGRAPH Symposium on User Interface Software and Technology, </booktitle> <month> November, </month> <year> 1991. </year>
Reference-contexts: The Polhemus tracker is not as accurate a device as a joystick; more importantly, there is a hardware latency of approximately 85ms <ref> [Liang] </ref> which makes the game noticeably harder to play. In order to keep the tracker lag from dominating our results, we had our able-bodied subjects use the Polhe-mus and Tailor-mapping software.
Reference: [Pausch90] <author> R. Pausch and R. Williams, Tailor: </author> <title> Creating Custom User Interfaces Based on Gesture, </title> <booktitle> Proceedings of UIST: the Annual ACM SIGGRAPH Symposium on User Interface Software and Technology, </booktitle> <month> October, </month> <year> 1990, </year> <pages> pp. 123-134. </pages>
Reference-contexts: Such an individual is capable of generating a useful control signal, but no existing physical device exists to interpret it. Tailors long term goal is to generate an interface for each user which will allow him to produce real-time analog control signals with his best physical motion <ref> [Pausch90] </ref>.
Reference: [Pausch92] <author> R. Pausch and R. Williams, </author> <title> Giving CANDY to Children: User-Tailored Gesture Input Driving an Articulator-Based Speech Synthesizer, </title> <journal> Communications of the ACM. </journal> <note> To appear. </note>
Reference: [Polhemus] <institution> Apparatus for Generating a Nutating Electromagnetic Field, Jack Kulpersfp, Polhemus Navigation Sciences, Inc., </institution> <year> 1977. </year> <type> U.S. Patent Number 4,017,858 </type>
Reference-contexts: The physical setup includes an IBM-compatible 386 personal computer with a color VGA display and either a 14 or 19 inch monitor. The playing field is a square 420 pixels on a side, and the paddle is 95 pixels wide. Our tracker is a Polhemus Isotrak TM <ref> [Polhemus] </ref>. The balls speed was always one of three fixed values: slow = 33 pixels per second, ; medium = 64 pixels per second; fast = 178 pixels per second .
Reference: [Raibert] <author> M. Raibert. </author> <title> Legged robots. </title> <journal> Communications of the ACM, Volume29, </journal> <volume> Number 6, </volume> <month> June </month> <year> 1986, </year> <pages> pages 499-514. </pages>
Reference-contexts: We are also grateful to Freder-ick Brooks, Jr. of UNC Chapel Hill, whose suggestion of videotaping the trials led to several insights. The decomposition of the two-dimensional problem into its one-dimensional components is an idea borrowed from Marc Raibert <ref> [Raibert] </ref>. Finally, we would like to thank our subjects and their families, without whose help this research would not have been possible.
Reference: [Schmandt] <author> C. Schmandt, </author> <title> Spatial Input/Display Correspondence in a Stereoscopic Computer Graphic Work Station, </title> <journal> Computer Graphics, </journal> <month> July, </month> <year> 1983, </year> <pages> pp. 253-261. </pages>
Reference-contexts: The pilots faceshield contains targeting crosshairs, and as the pilots helmet moves with his head, the system computes the angle of his gaze [Furness]. More detailed tracking is performed in three dimensional drawing or sculpting applications <ref> [Schmandt] </ref>, and virtual reality systems, where sensors attached to gloves [Foley] pro vide three-dimensional signals that are mapped into motions in synthetic worlds shown on traditional or head-mounted displays. These systems perform mappings from position and orientation information, but the mappings are significantly less complicated than those we propose.
Reference: [Schmidt] <author> R. Schmidt, </author> <title> Motor Control and Learning; </title>
Reference-contexts: This produced cognitive trouble for the children whose target curves were predominantly horizontal, in much the same way that rotating a mouse 90 degrees makes it almost impossible to use. Other researchers have also found that stimulus and response need to be organized in spatially similar ways <ref> [Schmidt] </ref>. What we found interesting was that the two orientations, horizontal and vertical, were sufficient. The other things we learned during the pilot studies involved our interaction with the subjects. <p> More simply, they may be unable to organize and initiate muscular actions to produce a prompt motor response. Alternatively, maintaining the paddle in a ready position required more control at an access site <ref> [Schmidt] </ref>. The children with CP typically could not manage this, therefore returned to a consistent resting place. None of our subjects, either those with CP or able-bodied, had a conscious awareness of the location of the target curve.
References-found: 13

