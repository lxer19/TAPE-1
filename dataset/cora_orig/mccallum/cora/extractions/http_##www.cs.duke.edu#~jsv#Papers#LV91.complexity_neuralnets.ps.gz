URL: http://www.cs.duke.edu/~jsv/Papers/LV91.complexity_neuralnets.ps.gz
Refering-URL: http://www.cs.duke.edu/~jsv/Papers/catalog/node46.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Author: Lin and Jeffrey Scott Vitter 
Address: Providence, R. I. 02912-1910  
Affiliation: Department of Computer Science Brown University  
Note: Jyh-Han  
Abstract: Complexity Results on Learning by Neural Nets fl Abstract We consider the computational complexity of learning by neural nets. We are interested in how hard it is to design appropriate neural net architectures and to train neural nets for general and specialized learning tasks. Our main result shows that the training problem for 2-cascade neural nets (which have only two non-input nodes, one of which is hidden) is N P-complete, which implies that finding an optimal net (in terms of the number of non-input units) that is consistent with a set of examples is also N P-complete. This result also demonstrates a surprising gap between the computational complexities of one-node (perceptron) and two-node neural net training problems, since the perceptron training problem can be solved in polynomial time by linear programming techniques. We conjecture that training a k-cascade neural net, which is a classical threshold network training problem, is also N P-complete, for each fixed k 2. We also show that the problem of finding an optimal perceptron (in terms of the number of non-zero weights) consistent with a set of training examples is N P-hard. Our neural net learning model encapsulates the idea of modular neural nets, which is a popular approach to overcoming the scaling problem in training neural nets. We investigate how much easier the training problem becomes if the class of concepts to be learned is known a priori and the net architecture is allowed to be sufficiently non-optimal. Finally, we classify several neural net optimization problems within the polynomial-time hierarchy. 
Abstract-found: 1
Intro-found: 1
Reference: <author> E. Baum and D. </author> <title> Haussler [1989]. "What Size Net Gives Valid Generalization?", </title> <booktitle> Neural Computation, 1(2) (1989), </booktitle> <pages> 151-160. </pages>
Reference: <author> A. Blum and R. L. </author> <title> Rivest [1988]. "Training a 3-Node Neural Network is N P-Complete," </title> <booktitle> Proceedings of the First ACM Workshop on the Computational Learning Theory, </booktitle> <address> Cambridge, MA (August 1988), </address> <pages> 9-18. </pages>
Reference: <author> A. Blumer, A. Ehrenfeucht, D. Haussler, and M. K. </author> <title> Warmuth [1989]. "Learnability and the Vapnik-Chervonenkis Dimension," </title> <journal> Journal of the Association for Computing Machinery, </journal> <month> 36(4) (October </month> <year> 1989), </year> <pages> 929-965. </pages>
Reference: <author> M. L. </author> <month> Dertouzos </month> <year> [1965]. </year> <title> Threshold Logic: A Synthesis Approach, </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA (1965). </address>
Reference: <author> M. R. Garey and D. S. </author> <title> Johnson [1979]. Computers and intractability: A Guide to the Theory of N P-completeness, </title> <editor> W. H. </editor> <publisher> Freeman and Co., </publisher> <address> San Francisco, CA (1979). </address>
Reference: <author> D. </author> <title> Haussler [1988]. "Quantifying Inductive Bias: AI Learning Algorithms and Valiant's Learning Framework," </title> <journal> Artificial Intelligence, </journal> <volume> 36 (1988), </volume> <pages> 177-221. </pages>
Reference: <author> G. E. </author> <title> Hinton [1989]. "Connectionist Learning Procedures," </title> <journal> Artificial Intelligence, </journal> <volume> 40 (1989), </volume> <pages> 185-234. </pages>
Reference: <author> J. S. </author> <title> Judd [1987]. "Complexity of Connectionist Learning with Various Node Functions," </title> <type> COINS Technical Report No. 87-60, </type> <institution> University of Massachusetts (July 1987). </institution>
Reference: <author> J. S. </author> <title> Judd [1988]. "On the Complexity of Loading Shallow Neural Networks," </title> <journal> Journal of Complexity, </journal> <volume> 4 (1988), </volume> <pages> 177-192. </pages>
Reference: <author> W. J. </author> <month> Masek </month> <year> [1978]. </year> <title> "Some N P-Complete Set Cover Problems," </title> <institution> MIT Laboratory for Computer Science, </institution> <type> unpublished manuscript. </type>
Reference: <author> D. E. Rumelhart, G. E. Hinton, and R. J. </author> <title> Williams [1986]. "Learning Internal Representations by Error Propagation," Parallel Distributed Processing, </title> <editor> edited by D. E. Rumelhart and J. E. McClel-land, </editor> <publisher> MIT Press, </publisher> <address> Cambridge, MA (1986), </address> <pages> 318-362. </pages>
Reference: <author> L. J. </author> <title> Stockmeyer [1977]. "The Polynomial-Time Hierarchy," </title> <booktitle> Theoretical Computer Science, 3 (1977), </booktitle> <pages> 1-22. </pages>
Reference: <author> L. J. Stockmeyer and A. R. </author> <title> Meyer [1973]. "Word Problems Requiring Exponential Time: Preliminary Report," </title> <booktitle> Proceedings of the Fifth Annual Symposium on the Theory of Computing (1973), </booktitle> <pages> 1-9. </pages>
Reference: <author> L. G. </author> <title> Valiant [1984]. "A Theory of the Learnable," </title> <journal> Communications of the ACM, </journal> <month> 27(11) (November </month> <year> 1984), </year> <pages> 1134-1142. </pages>
Reference: <author> A. </author> <title> Weibel [1989]. "Modular Construction of Time-Delay Neural Networks for Speech Recognition," </title> <booktitle> Neural Computation, 1 (1989), </booktitle> <pages> 39-46. </pages>
Reference: <author> A. Weibel and J. </author> <title> Hampshire [1989]. "Building Blocks for Speech," </title> <journal> Byte, </journal> <month> August </month> <year> 1989, </year> <pages> 235-242. </pages>
Reference: <author> C. </author> <title> Wrathall [1977]. "Complete Sets and the Polynomial-Time Hierarchy," </title> <booktitle> Theoretical Computer Science, 3 (1977), </booktitle> <pages> 23-33. </pages>
References-found: 17

