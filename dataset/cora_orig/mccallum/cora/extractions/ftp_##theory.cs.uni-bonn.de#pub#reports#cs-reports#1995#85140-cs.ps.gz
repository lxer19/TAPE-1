URL: ftp://theory.cs.uni-bonn.de/pub/reports/cs-reports/1995/85140-cs.ps.gz
Refering-URL: http://cs.uni-bonn.de/info5/publications/CS-1995-en.html
Root-URL: http://cs.uni-bonn.de
Title: Almost Optimal Sublinear Time Parallel Recognition Algorithms for Three Subclasses of Cfl's  
Author: Lawrence L. Larmore Wojciech Rytter 
Abstract:  
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Aho, J. Hopcroft, J. Ullman, </author> <title> The design and analysis of computer algorithms, </title> <publisher> Addison-Wesley (1974). </publisher>
Reference-contexts: Our simulation will take O (n 1ff ) "large" steps sequentially. Each large step, working in logarithmic parallel time, advances the computation by at least h, except perhaps the last step. Thus, the simulation is a combination of a sequential and parallel computation. We refer the reader to <ref> [1] </ref> or [7] for the definition of a one-way deterministic pushdown automaton (DPDA for short). Let A be a DPDA. Assume that we are given an input text w of length n. We can assume that in each step the height of the stack changes by 1 or 1.
Reference: [2] <author> M. J. Atallah, S. R. Kosaraju, L. L. Larmore, G. L. Miller, and S-H. Teng. </author> <title> Constructing trees in parallel, </title> <booktitle> Proc. 1 st Symp. on Parallel Algorithms and Architectures (1989), </booktitle> <pages> pp. 499-533. </pages>
Reference-contexts: The recurrence is: f (source) = identity of the semiring f (x) = y!x f (y) weight (y; x) if x 6= source We briefly review the parallel algorithm of <ref> [2] </ref> and [10]. Consider any small square within the grid graph, i.e., the subgraph of all nodes in the square of size d whose upper left corner is (a; b), together with all edges between those nodes, for given a, b, and d. <p> Also, using matrix multiplication, X can be computed in O (log 2 d) time using d 3 = log 2 d processors (see <ref> [2] </ref>). It follows that f (sink) can be computed in O (log 2 n) time using n 3 = log 2 n processors. from the values of f on line k by using the matrices for all basic subsquares at level k. <p> Theorem 4.1 There exists a parallel algorithm for recognition of linear context free languages which requires O (n 1ff ) time and O (n 2+ff ) work. Proof. We describe an algorithm which combines the matrix multiplication techniques of <ref> [2] </ref> and [10] with dynamic programming. The grid graph is partitioned into squares of order n ff , as shown 12 in Figure 8. The interiors of these squares, which we call basic subsquares, are disjoint. Note that there are O (n 22ff ) basic subsquares. <p> Analysis: Step I takes O (log n) time using n= log n processors. Step II takes O (n log 2 n) time using n 3ff = log 2 n processors for each basic subsquare using the algorithm of <ref> [2] </ref>, and therefore O (log 2 n) time and n 2+ff = log 2 n processors altogether. Using Brent's theorem, we obtain a time of O (n 1ff log n) using n 1+2ff = log n processors.
Reference: [3] <author> L. Banachowski, A. Kreczmar, W. Rytter, </author> <title> Analysis of algorithms and data structures, </title> <publisher> Addison-Wesley (1991). </publisher>
Reference-contexts: Denote by w [i; j] the substring a i+1 : : : a j . The recognition problem is to determine whether w is generated by G. We explain the main ideas using the algebraic framework of composition systems <ref> [3] </ref>. The composition system corresponding to a given grammar G and the input string w is a triple S = (N; ; init), where N = f (A; i; j) : A 2 V N and 0 i &lt; j n g The elements of N are called items.
Reference: [4] <author> M. Chytil, M. Crochemore, B. Monien, and W. Rytter, </author> <title> On the parallel recognition of unambiguous context-free languages, </title> <booktitle> Theoretical Computer Science 81, </booktitle> <pages> pp. 311-316. </pages>
Reference-contexts: Assume X S k and the set S 0 is precomputed. Then Step 2.1 can be performed in O (log n) time with n 1+2ff processors. Proof. Point (1). We refer the reader to <ref> [4] </ref>, where it was shown that the closure of set of initial items (elements of init) for an unambiguous grammar can be found in O (log 2 n) time, with the number of processors proportional to the number of edges of the dependency graph, which is O (n 1+2ff ). <p> Point (2). According to <ref> [4] </ref> the set of vertices from which a node of X is reachable can be computed in O (log n) time, with the number of processors proportional to the number of edges, using a version of parallel tree contraction and a special property of the graph G k , namely uniqueness <p> node of X is reachable can be computed in O (log n) time, with the number of processors proportional to the number of edges, using a version of parallel tree contraction and a special property of the graph G k , namely uniqueness of paths from one vertex to another <ref> [4] </ref>. The two preceding lemmas directly imply the main result of this section: Theorem 2.7 Assume an unambiguous CFL is given by a context-free grammar. <p> The assigned processors sequentially simulate n ff steps of the DPDA. If there are n processors, this requires O (n ff ) time. An algorithm which works in O (log 2 n) time using n 1+ff processors can be constructed as a version of an algorithm in <ref> [4] </ref>. (2) The shortcuts can be computed by iterating the operator Succ logarithmically many times. For each configuration x, one processor suffices. same level, followed by a pop or a push move, respectively.
Reference: [5] <author> A. Gibbons, W. Rytter, </author> <title> Efficient parallel algorithms, </title> <publisher> Cambridge University Press (1988). </publisher>
Reference-contexts: Each large step is performed in parallel in O (log n) time, and there are O (n 1ff ) such steps which are executed consecutively. The larger ff is, the faster the algorithm. Throughout this paper, we use the CREW PRAM model of parallel computation (see for example <ref> [5] </ref>). 2 Parallel recognition of unambiguous CFL's We use a version of the algorithm presented in [8] for parallel computation of some dynamic programming recurrences.
Reference: [6] <author> M. A. Harrison, </author> <title> Introduction to formal language theory, </title> <publisher> Addison Wesley (1978). </publisher>
Reference-contexts: Without loss of generality, G is in Chomsky normal form, and there are no useless symbols (see <ref> [6] </ref>). Assume we are given an input string w = a 1 a 2 : : : a n . Denote by w [i; j] the substring a i+1 : : : a j . The recognition problem is to determine whether w is generated by G.
Reference: [7] <author> J. Hopcroft, J. Ullman, </author> <title> The design and analysis of computer algorithms, </title> <publisher> Addison-Wesley (1974). </publisher>
Reference-contexts: Each large step, working in logarithmic parallel time, advances the computation by at least h, except perhaps the last step. Thus, the simulation is a combination of a sequential and parallel computation. We refer the reader to [1] or <ref> [7] </ref> for the definition of a one-way deterministic pushdown automaton (DPDA for short). Let A be a DPDA. Assume that we are given an input text w of length n. We can assume that in each step the height of the stack changes by 1 or 1.
Reference: [8] <author> L. L. Larmore, W. Rytter, </author> <title> An optimal sublinear time parallel algorithm for some dynamic programming problems, </title> <booktitle> Information Processing Letters 52 (1994), </booktitle> <pages> pp. 31-34. </pages>
Reference-contexts: The larger ff is, the faster the algorithm. Throughout this paper, we use the CREW PRAM model of parallel computation (see for example [5]). 2 Parallel recognition of unambiguous CFL's We use a version of the algorithm presented in <ref> [8] </ref> for parallel computation of some dynamic programming recurrences.
Reference: [9] <author> B. Monien, W. Rytter, and H. Schapers, </author> <title> Fast recognition of deterministic CFL's with a smaller number of processors, </title> <booktitle> Theoretical Computer Science 116 (1993), </booktitle> <pages> pp. 421-429. </pages>
Reference: [10] <author> W. Rytter, </author> <title> On the parallel computation of costs of paths on a grid graph, </title> <booktitle> Information Processing Letters 29 (1988), </booktitle> <pages> pp. 71-74. </pages>
Reference-contexts: Any linear context-free language is generated by a grammar where every production is of the form A ! aB, A ! Ba, or A ! a. It was shown in <ref> [10] </ref> that the problem of recognition of linear context-free languages can be reduced to the sum-of-path-weights problem over a grid graph, a special kind of directed acyclic graph. The nodes of a grid graph form a square array, and all edges point one position down or to the right. <p> Each edge has a weight, which is a binary relation over the set of nonterminals. The set of such relations forms a semiring with the operation being composition of relations. We refer the reader to <ref> [10] </ref> for more details of how the recognition problem for linear context-free languages reduces to a more general problem related to paths on a grid graph. In the general sum-of-path-weights problem, each edge in the grid graph has a weight, which is a member of a semiring. <p> The recurrence is: f (source) = identity of the semiring f (x) = y!x f (y) weight (y; x) if x 6= source We briefly review the parallel algorithm of [2] and <ref> [10] </ref>. Consider any small square within the grid graph, i.e., the subgraph of all nodes in the square of size d whose upper left corner is (a; b), together with all edges between those nodes, for given a, b, and d. <p> Theorem 4.1 There exists a parallel algorithm for recognition of linear context free languages which requires O (n 1ff ) time and O (n 2+ff ) work. Proof. We describe an algorithm which combines the matrix multiplication techniques of [2] and <ref> [10] </ref> with dynamic programming. The grid graph is partitioned into squares of order n ff , as shown 12 in Figure 8. The interiors of these squares, which we call basic subsquares, are disjoint. Note that there are O (n 22ff ) basic subsquares.
References-found: 10

