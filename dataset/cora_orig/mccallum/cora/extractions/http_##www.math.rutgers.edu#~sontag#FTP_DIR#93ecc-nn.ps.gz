URL: http://www.math.rutgers.edu/~sontag/FTP_DIR/93ecc-nn.ps.gz
Refering-URL: http://www.math.rutgers.edu/~sontag/papers.html
Root-URL: 
Title: NEURAL NETWORKS FOR CONTROL  
Author: Eduardo D. Sontag 
Address: New Brunswick, NJ 08903, USA  
Affiliation: Department of Mathematics, Rutgers University  
Abstract: This paper starts by placing neural net techniques in a general nonlinear control framework. After that, several basic theoretical results on networks are surveyed. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <editor> Albertini, F., and E.D. Sontag, </editor> <title> "For neural networks, function determines form," Neural Networks, </title> <note> to appear. See also Proc. IEEE Conf. </note> <institution> Decision and Control, </institution> <address> Tucson, Dec. 1992, </address> <publisher> IEEE Publications, </publisher> <year> 1992, </year> <pages> pp. 26-31. </pages>
Reference-contexts: Assume that the inputs u are real numbers uniformly distributed in the interval <ref> [0; 1] </ref> and that the set of functions F consists of the functions f k (u) := H (sin (ku)), over all positive integers k. That is, f k (u) is 1 if sin (ku) &gt; 0 and zero otherwise. <p> i ) for i = 1; : : : ; s but f j (u) 6= f (u). (Recall that the set of values of (sin (lu 1 ); : : : ; sin (lu s ); sin (lu)), as l ranges over the positive inte gers, is dense in <ref> [1; 1] </ref> s+1 .) Since the learner is not able to decide, on the basis of the observed data, if f = f k or f = f j , the prediction ^ f (u) cannot be made with any degree of reliability. <p> Contrast this example with the following one, at the other extreme: the functions F are now of the type f a (x) := H (x a), with a 2 <ref> [0; 1] </ref>. The concepts to be identified are the sets of the form fx &gt; ag. Identifying the concept means identifying the 24 cut point a. <p> This is a generic set of triples, in the sense that the entries of the ones that do not satisfy the property are zeroes of certain nontrivial multivariable polynomials. Finally, let: ~ S (n; m; p) = (A; B; C; ) fi n;m;p : Then, in <ref> [1] </ref>, the following result was proved: Assume that is odd and sat isfies property (*). Then ~ ^ if and only if and ^ are sign-permutation equivalent. An analogous result can be proved when is not odd, resulting in simply permutation equivalence.
Reference: [2] <author> Albertini, F., E.D. Sontag, and V. Maillot, </author> <title> "Uniqueness of weights for neural networks," in Artificial Neural Networks with Applications in Speech and Vision (R. Mammone, </title> <editor> ed.), </editor> <publisher> Chapman and Hall, </publisher> <address> London, </address> <year> 1993, </year> <note> to appear. </note>
Reference-contexts: His proof was based on explicit computations for the particular function tanh (x). An alternative proof is possible, using analytic continuations and residues, and allows a more general result to be established (see <ref> [2] </ref> for details): Assume that is a real-analytic function, and it extends to an analytic function : C ! C defined on a subset D C of the form: D = fz j jIm zj g n fz 0 ; z 0 g for some &gt; 0, where Im z 0
Reference: [3] <author> Anthony, M., </author> <title> and N.L. Biggs, Computational Learning Theory: An Introduction, </title> <publisher> Cambridge U. Press, </publisher> <year> 1992. </year>
Reference-contexts: The next few paragraphs introduce the basic ideas, using terminology from learning theory; for more details see for instance the textbook <ref> [3] </ref>. In the PAC paradigm, a "learner" has access to data given by a labeled sample S = (u 1 ; y 1 ); : : : ; (u s ; y s ).
Reference: [4] <author> Aubin, </author> <title> J.-P., </title> <journal> Mathematical Methods of Artificial Intelligence, </journal> <note> to appear. </note>
Reference-contexts: Now one may attempt to minimize max x J (; x) over . This is the type of approach taken, for example, in <ref> [4] </ref>, in which the viability problem (make the state stay in a desired set) is attacked using neural net controllers. (The minimax character of the problem makes it suitable for nondifferentiable optimization techniques.) Estimate a Lyapunov or Bellman Function.
Reference: [5] <author> Baker, W.L., and J.A. Farrell, </author> <title> "An introduction to connectionist learning control systems," </title> <booktitle> in [39]. </booktitle>
Reference-contexts: Most recent major control conferences have had introductory courses devoted to the topic, and, in addition, many good overviews are available in the general literature; see for instance the papers <ref> [5] </ref>, [20], [7], [16], and other papers in the books [27] and [39].
Reference: [6] <author> Barron, </author> <title> A.R., "Neural net approximation," </title> <booktitle> in Proc. Seventh Yale Workshop on Adaptive and Learning Systems, </booktitle> <institution> Yale University, </institution> <year> 1992, </year> <pages> pp. 69-72. </pages>
Reference-contexts: In that case, it was remarked that f -f (ff) is in the closed convex hull of fV H (u b)g (in the uniform norm, and hence also in L 2 for any finite measure on [ff; fi]). Generalizing, Barron in <ref> [6] </ref> suggested defining a function f : Q ! IR, where Q is a bounded subset of IR m , to have "bounded variation with respect to halfspaces" if this property holds: there exists a real number V so that, for some q 2 Q, f -f (q) is in the <p> for each u 2 Q, and that C f = R IR m k!kj ~ f (!)jd! &lt; 1: Then, V f;Q 2C f . (Norm of ! is standard Euclidean norm.) For the spaces ff j C f kg; k a fixed constant, Barron also proved (see references in <ref> [6] </ref>) that approximations by linear subspaces of dimension n would result in a worst-case error of at least O (n 1=d ), which is asymptotically worse than O (1= p n) when d &gt; 2.
Reference: [7] <author> Barto, </author> <title> A.G., "Connectionist learning for control: An overview," </title> <booktitle> in [27]. </booktitle>
Reference-contexts: Most recent major control conferences have had introductory courses devoted to the topic, and, in addition, many good overviews are available in the general literature; see for instance the papers [5], [20], <ref> [7] </ref>, [16], and other papers in the books [27] and [39]. <p> This is done by adjusting after a complete "training" event, by means of, typically, a gradient descent step. The "adaptive critic" work by Barto and others (see <ref> [7] </ref> and the many references there) is one exam ple of this approach, which is especially attractive when the overall goal is ill-defined in quantitative terms.
Reference: [8] <author> Baum, E.B., and D. Haussler, </author> <title> "What size net gives valid generalization?," </title> <booktitle> Neural Computation 1(1989): </booktitle> <pages> 151-160. </pages>
Reference-contexts: So the VC dimension completely characterizes learnability with respect to unknown distributions; in fact, the constant "c" in the sample complexity bound given earlier is a simple function of the number vc (F), independent of F itself. It follows from the results in <ref> [8] </ref> that, for the class H (F n;;m ) of classifiers implementable by 1HL nets with with n hidden units and m inputs (n and m fixed) and activation = H, vc (F ) &lt; dmn (1 + log (n)); for a small constant d.
Reference: [9] <author> Blum, A., and R.L. Rivest, </author> <title> "Training a 3-node neural network is NP-complete," </title> <booktitle> in Advances in Neural Information Processing Systems 2 (D.S. </booktitle> <editor> Touretzky, ed), </editor> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1990, </year> <pages> pp. 9-18. </pages>
Reference-contexts: complexity of the loading problem: do there exist weights that satisfy the desired objective? For fixed input dimension and Heaviside activations, this becomes essentially a linear programming problem, but even for such activations, the problem is NP-hard when scaling with respect to the number of input or output dimensions; see <ref> [9] </ref> and [21] for much on this issue. 4.5 Learnability and VC Dimension One of the main current approaches to defining and understanding the question of learning, which after all underlies much of the reason for the use of neural nets in control, is based on the probably approximately correct ("PAC")
Reference: [10] <author> Blumer, A., A. Ehrenfeucht, D. Haussler, and M. Warmuth, </author> <title> "Classifying learnable geometric concepts with the Vapnik-Chervonenkis dimension," </title> <booktitle> in Proc. 18th. Annual ACM Symposium on Theory of Computing , pp. </booktitle> <pages> 273-282, </pages> <publisher> ACM, Salem, </publisher> <year> 1986. </year>
Reference-contexts: Vapnik-Chervonenkis dimension vc (F) is the supremum (possibly infinite) of the set of integers for which there is some set S of cardinality that can be shattered by F . (Thus, vc (F) is at least as large as the capacity c (F) defined earlier.) The main result, due to <ref> [10] </ref>, but closely related to previous results in statistics (see [38]) is: The class F is learnable if and only if vc (F) &lt; 1.
Reference: [11] <author> Carroll, S.M., and B.W. Dickinson, B.W., </author> <title> "Construction of neural nets using the Radon transform," </title> <booktitle> in Proc. 1989 Int. Joint Conf. Neural Networks, </booktitle> <pages> pp. </pages> <publisher> I: </publisher> <pages> 607-611. </pages>
Reference-contexts: Instead of polynomials, one can also base the reduction proof on Fourier expansions. For this, it is enough to see that trigonometric polynomials satisfy the conditions of the Stone-Weierstrass Theorem. Other proofs use various algorithms for reconstruction from projections, such as Radon transforms (see <ref> [11] </ref>). In conclusion, universality guarantees that functions of the type (5) are dense in C 0 . One can also establish density results for L q 20 spaces, q &lt; 1, on compact sets, simply using for those spaces the density of continuous functions.
Reference: [12] <author> Chen, F.C., and H.K. Khalil, </author> <title> "Adaptive control of nonlinear systems using neural networks," </title> <booktitle> Proc. IEEE Conf. Decision and Control, Hawaii, </booktitle> <address> Dec. 1990, </address> <publisher> IEEE Publications, </publisher> <year> 1990. </year>
Reference-contexts: In general, however, there are absolutely no guarantees that such a procedure solves the tracking problem, and only simulations are offered in the literature to justify the approach. (An exception are certain local convergence results; see e.g. <ref> [12] </ref>.) Moreover, the control problem itself was capable of being trivially solved by feedback linearization, once that the plant was identified.
Reference: [13] <author> Cybenko, G., </author> <title> "Approximation by superpositions of a sigmoidal function," Math. Control, Signals, </title> <booktitle> and Systems 2(1989): </booktitle> <pages> 303-314. </pages>
Reference-contexts: Then, is a universal activation if and only if it is not a polynomial . Previous results along these lines were obtained in [19], which established that any which is continuous, nonconstant, and bounded is universal (see also <ref> [13] </ref> and [20:(59,85)] for related older results). The proof in [22] is based essentially on two steps: First, one reduces, by convolution, to the case in which is infinitely differentiable (and non-polynomial).
Reference: [14] <author> Darken, C., M. Donahue, L. Gurvits, and E. Sontag, </author> <title> "Rate of approximation results motivated by robust neural network learning," </title> <note> submitted. 39 </note>
Reference-contexts: Note that the approximations, as they use Maurey-type arguments, hold a priori only in L 2 (or other Hilbert spaces). Indeed, these arguments are false for approximation in L 1 , if the set G is arbitrary (see <ref> [14] </ref> for this and related remarks). However, Barron in the above reference was also able to prove a similar result for the particular case in which G corresponds to characteristic functions of half-spaces, using a deeper result due to Dudley.
Reference: [15] <author> Flick, T.E., L.K. Jones, R.G. Priest, and C. Herman, </author> <title> "Pattern classifi-cation using projection pursuit," </title> <booktitle> Pattern Recognition 23(1990): </booktitle> <pages> 1367-1376. </pages>
Reference-contexts: are used in statistics and pattern classification, in particular when applying projection pursuit techniques, which incrementally build f by choosing the directions B i , i = 1; : : : ; r in a systematic way so as to minimize an approximation or classification error criterion; see for instance <ref> [15] </ref>. Note that F ;m is precisely the set of those multiridge functions for which there are scalars c i such that i = c i for all i.
Reference: [16] <author> Franklin, J.A., </author> <title> "Historical perspective and state of the art in connectionist learning control," </title> <booktitle> Proc. IEEE Conf. Decision and Control, </booktitle> <address> Tampa, Dec. 1989, </address> <publisher> IEEE Publications, </publisher> <year> 1989. </year>
Reference-contexts: Most recent major control conferences have had introductory courses devoted to the topic, and, in addition, many good overviews are available in the general literature; see for instance the papers [5], [20], [7], <ref> [16] </ref>, and other papers in the books [27] and [39].
Reference: [17] <author> Haussler, D., </author> <title> "Decision theoretic generalizations of the PAC model for neural net and other learning applications," </title> <booktitle> Information and Computation 100(1992): </booktitle> <pages> 78-150. </pages>
Reference-contexts: Thus sigmoidal nets appear to have some special properties, vis a vis other possible more general parametric classes of functions, at least from a learnability viewpoint. Other results on finiteness of learning, but from a more statistical viewpoint (nonlinear regression, estimation of joint densities), are given in <ref> [17] </ref>, where metric entropy estimates are obtained for networks with bounded weights. The results on learnability just explained extend to other classes of feedforward nets, including 2HL nets (defined below) and nets involving products of inputs ("high order nets"), but such more general results will 26 not be reviewed here.
Reference: [18] <author> Hertz, J., A. Krogh, and R.G. Palmer, </author> <title> Introduction to the Theory of Neural Computation, </title> <publisher> Addison-Wesley, </publisher> <address> Redwood City, </address> <year> 1991. </year>
Reference-contexts: See the textbook <ref> [18] </ref> for a clear and well-written, if mathematically incomplete, introduction to neural nets. Motivating the use of nets is the belief |still not theoretically justified| that in some sense they are an especially appropriate family of parameterized models.
Reference: [19] <author> Hornik, K., </author> <title> "Approximation capabilities of multilayer feedforward networks," </title> <booktitle> Neural Networks 4(1991): </booktitle> <pages> 251-257. </pages>
Reference-contexts: Then, is a universal activation if and only if it is not a polynomial . Previous results along these lines were obtained in <ref> [19] </ref>, which established that any which is continuous, nonconstant, and bounded is universal (see also [13] and [20:(59,85)] for related older results). The proof in [22] is based essentially on two steps: First, one reduces, by convolution, to the case in which is infinitely differentiable (and non-polynomial). <p> One can also establish density results for L q 20 spaces, q &lt; 1, on compact sets, simply using for those spaces the density of continuous functions. Approximation results on noncompact spaces, in L q but for finite measures, are also possible but considerably harder; see <ref> [19] </ref>. It is false, on the other hand, that one can do uniform approximation of more or less arbitrary discontinuous functions, that is, approximation in L 1 , even on compact sets. <p> Pick any which has the property that twice continuously differentiable functions can be approximated uniformly, together with their derivatives, using 1HL nets (most interesting twice-differentiable scalar nonlinearities will do; see <ref> [19] </ref>).
Reference: [20] <author> Hunt, K.J., D. Sbarbaro, R. Zbikowski, and P.J. Gawthrop, </author> <title> "Neural networks for control systems: A survey," </title> <type> Automatica 28(1992): </type> <pages> 1083-1122. </pages>
Reference-contexts: 1 Introduction The field commonly referred to as "neuro-" or "connectionist" control has been the focus of a tremendous amount of activity in the past few years. As emphasized in <ref> [20] </ref>, work in this and related areas represents to a great extent a return to the ideas of Norbert Wiener, who in his 1940s work on "cybernetics" drew no boundaries between the fields now called artificial intelligence, information theory, and control theory. <p> Most recent major control conferences have had introductory courses devoted to the topic, and, in addition, many good overviews are available in the general literature; see for instance the papers [5], <ref> [20] </ref>, [7], [16], and other papers in the books [27] and [39]. <p> This paper was written in part while visiting Siemens Corporate Research, Princeton. 1 direct citations; a reference such as: [20:175] will mean "item [175] in the bibliography given in the paper <ref> [20] </ref>." 1.1 Learning and Adaptive Control One of the main advantages claimed for neurocontrollers is their alleged ability to "learn" and "generalize" from partial data.
Reference: [21] <author> Judd, J.S., </author> <title> Neural Network Design and the Complexity of Learning, </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1990. </year>
Reference-contexts: the loading problem: do there exist weights that satisfy the desired objective? For fixed input dimension and Heaviside activations, this becomes essentially a linear programming problem, but even for such activations, the problem is NP-hard when scaling with respect to the number of input or output dimensions; see [9] and <ref> [21] </ref> for much on this issue. 4.5 Learnability and VC Dimension One of the main current approaches to defining and understanding the question of learning, which after all underlies much of the reason for the use of neural nets in control, is based on the probably approximately correct ("PAC") model proposed
Reference: [22] <author> Leshno, M., V.Ya. Lin, A. Pinkus, and S. Schocken, </author> <title> "Multilayer feed-forward networks with a non-polynomial activation function can approximate any function," </title> <booktitle> Neural Networks, </booktitle> <year> 1993, </year> <note> to appear. </note>
Reference-contexts: But most nonlinear functions are universal. A conclusive result has recently been obtained and is as follows; see <ref> [22] </ref>: Assume that is locally Riemann integrable, that is, it is continuous except at most in a set of measure zero, and it is bounded on each compact. Then, is a universal activation if and only if it is not a polynomial . <p> Then, is a universal activation if and only if it is not a polynomial . Previous results along these lines were obtained in [19], which established that any which is continuous, nonconstant, and bounded is universal (see also [13] and [20:(59,85)] for related older results). The proof in <ref> [22] </ref> is based essentially on two steps: First, one reduces, by convolution, to the case in which is infinitely differentiable (and non-polynomial).
Reference: [23] <author> Livstone, M.M., J.A. Farrell, and W.L. Baker, </author> <title> "A computationally efficient algorithm for training recurrent connectionist networks," </title> <booktitle> in Proc. Amer. Automatic Control Conference, </booktitle> <address> Chicago, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: The estimate ^x [tjt] can be used instead of x. (If only partial observations are available, an output mapping y = h (x) + ~ 2 may be assumed instead of the identity, and a similar procedure may be followed.) See for instance [25] and <ref> [23] </ref> for this type of parametric nonlinear adaptive control approach.
Reference: [24] <author> Macintyre, M., and E.D. Sontag, </author> <title> "Finiteness results for sigmoidal `neural' networks," </title> <booktitle> in Proc. 25th Annual Symp. Theory Computing, </booktitle> <address> San Diego, </address> <month> May </month> <year> 1993, </year> <note> to appear. </note>
Reference-contexts: Again here, intp () = 2=3 ; and one can also show that 2=3 intp ( s ) 1 for the standard sigmoid (the proof of the upper bound in this latter case involves some algebraic geometry; the value may be infinite for more general 22 sigmoids; see also <ref> [24] </ref>). Furthermore, the inequality intp () 1=3 holds for any universal nonlinearity. Obtaining the precise value for s is a very interesting open problem. Note that the above discussion focused on general bounds on what can be achieved. <p> It is easy to construct examples of sigmoids, even extremely well-behaved ones (analytic and squashing, for instance) for which the VC dimension of the class H (F n;;m ) is infinite; see [34]. However, for the stan dard sigmoid, a recent result in <ref> [24] </ref> proves that vc (F ) &lt; 1, so neural nets with activation s are also learnable. Thus sigmoidal nets appear to have some special properties, vis a vis other possible more general parametric classes of functions, at least from a learnability viewpoint.
Reference: [25] <author> Matthews, M., </author> <title> "A state-space approach to adaptive nonlinear filtering using recurrent neural networks," </title> <booktitle> Proc. 1990 IASTED Symp. on Artificial Intelligence Applications and Neural Networks, </booktitle> <address> Zurich, </address> <pages> pp. 197-200, </pages> <month> July </month> <year> 1990. </year>
Reference-contexts: The estimate ^x [tjt] can be used instead of x. (If only partial observations are available, an output mapping y = h (x) + ~ 2 may be assumed instead of the identity, and a similar procedure may be followed.) See for instance <ref> [25] </ref> and [23] for this type of parametric nonlinear adaptive control approach.
Reference: [26] <author> McBride, L.E., </author> <title> and K.S. Narendra, "Optimization of time-varying systems," </title> <journal> IEEE Trans. Autom. Control , 10(1965): </journal> <pages> 289-294. </pages>
Reference-contexts: convenience.) Viewing the parameters as constant states, the second term can be obtained by solving the variational or linearized equation along the trajectory corresponding to the control u (), for the system obtained when using the current parameters ; see for instance Theorem 1 in [33]. (One "old" reference is <ref> [26] </ref>.) Such an approach is known in network circles as the "real time recurrent learning" algorithm, and it is often pointed out that it involves a fairly large amount of variables, as the full fundamental solution (an n fi n matrix of functions) must be solved for.
Reference: [27] <author> Miller, T., R.S. Sutton, and P.J. Werbos (eds.), </author> <title> Neural networks For Control, </title> <publisher> MIT Press, </publisher> <address> Cambridge, </address> <year> 1990. </year>
Reference-contexts: Most recent major control conferences have had introductory courses devoted to the topic, and, in addition, many good overviews are available in the general literature; see for instance the papers [5], [20], [7], [16], and other papers in the books <ref> [27] </ref> and [39].
Reference: [28] <author> Niranjan, M. and F. Fallside, </author> <title> "Neural networks and radial basis functions in classifying static speech patterns," </title> <booktitle> Computer Speech and Language 4 (1990): </booktitle> <pages> 275-289. </pages>
Reference-contexts: The weights are "programmable" parameters that are then numerically adjusted in order to model a plant or a controller. In some of the literature, see e.g. <ref> [28] </ref>, each scalar nonlinear unit acts on a scalar quantity equal to the distance between the incoming signal and a reference (vector) value; this is in contrast to operating on a linear combination of the components of the incoming signal, and gives rise to "radial basis function" nets, which are not
Reference: [29] <author> Pisier, G., </author> <title> "Remarques sur un resultat non publie de B. </title> <institution> Maurey," in Seminaire d'analyse fonctionelle 1980-1981 , Ecole Polytechnique, Palaiseau, </institution> <year> 1981. </year>
Reference-contexts: The rest of this section reviews some of the basic results in question. The main tool is the following Lemma, which is often attributed to Maurey (see <ref> [29] </ref>): Let G be a bounded subset of a Hilbert space H, with kgk fl for all g 2 G, and let G n be the subset of H consisting of all convex combinations of at most n elements of G.
Reference: [30] <author> Polycarpou, </author> <title> M.M., and P.A. Ioannou, "Neural networks and on-line approximators for adaptive control," </title> <booktitle> in Proc. Seventh Yale Workshop on Adaptive and Learning Systems, </booktitle> <pages> pp. 93-798, </pages> <institution> Yale University, </institution> <year> 1992. </year> <month> 40 </month>
Reference-contexts: Lyapunov techniques for parameter identification |possibly in conjunction with sliding mode robust control, to handle the regions where the true f differs considerably from the best possible model of the form F (x; )| can be proved to converge in various senses; see especially [32], as well as for instance <ref> [30] </ref>.
Reference: [31] <author> Siegelmann, H.T., and E.D. Sontag, </author> <title> "Some results on computing with `neural nets'," </title> <booktitle> Proc. IEEE Conf. Decision and Control, </booktitle> <address> Tucson, Dec. 1992, </address> <publisher> IEEE Publications, </publisher> <year> 1992, </year> <pages> pp. 1476-1481. </pages>
Reference-contexts: The proof if not hard, and it involves first simply using universality in order to approximate the right-hand side of the original equation, and then introducing dynamics for the "hidden units" consistently with the equations. This second part requires a little care; for details, see <ref> [31] </ref>. 35 Thus, recurrent nets approximate a wide class of nonlinear plants. Note, however, that approximations are only valid on compact subsets of the state space and for finite time, so that many interesting dynamical characteristics are not reflected. <p> As with bilinear systems, it is obvious that if one imposes extra stability assumptions ("fading memory" type) it will be possible to obtain global approximations, but this is probably not very useful, as stability is often a goal of control rather than an assumption. 5.2 Computation The paper <ref> [31] </ref>, and the references given there, dealt with computational capabilities of recurrent networks, seen from the point of view of classical formal language theory.
Reference: [32] <author> Slotine,J.-J., and R.M. Sanner, </author> <title> "Neural networks for adaptive control and recursive identification: a theoretical framework," in Perspectives In Control (H.L. </title> <editor> Trentelman and J.C. Willems, eds.), </editor> <publisher> Birkhauser, </publisher> <address> Boston, </address> <year> 1993. </year>
Reference-contexts: this procedure, or one based on Lyapunov techniques for parameter identification |possibly in conjunction with sliding mode robust control, to handle the regions where the true f differs considerably from the best possible model of the form F (x; )| can be proved to converge in various senses; see especially <ref> [32] </ref>, as well as for instance [30].
Reference: [33] <author> Sontag, E.D., </author> <title> Mathematical Control Theory: Deterministic Finite Dimensional Systems, </title> <publisher> Springer, </publisher> <address> New York, </address> <year> 1990. </year>
Reference-contexts: If needed, one may assume that the control values themselves appear in y, and this is useful to keep in mind when the controller will consist of separate subsystems, as done later. This setup can be formalized in various ways, using abstract definitions of control systems as in <ref> [33] </ref>, but the current discussion will be completely intuitive. 3 2.2 Learning Control Structure The first refinement of the basic control paradigm that one may consider is the splitting of the controller into a fixed part and a "learning" or adaptable part; see the Figure (the signal flow is drawn from <p> at present, and it is the main reason for concentrating below instead on the basic representation, learnability, and feedback control questions involved. 7 2.5 Other Techniques for Control When systems are not feedback linearizable, nonlinear control becomes a very hard problem, even leaving aside identification issues (as an illustration, see <ref> [33] </ref>, Section 4.8, and the many references given there, for stabilization questions). There are several adaptation approaches which have been popular in neurocontrol and which correspond to various combinations of tuners and parametric models. <p> parameters are omitted, for notational convenience.) Viewing the parameters as constant states, the second term can be obtained by solving the variational or linearized equation along the trajectory corresponding to the control u (), for the system obtained when using the current parameters ; see for instance Theorem 1 in <ref> [33] </ref>. (One "old" reference is [26].) Such an approach is known in network circles as the "real time recurrent learning" algorithm, and it is often pointed out that it involves a fairly large amount of variables, as the full fundamental solution (an n fi n matrix of functions) must be solved <p> Now, the proof of Theorem 12 in <ref> [33] </ref> shows that there is a neighborhood V of zero, independent of n, where exponential stability will hold, for all n sufficiently large, because f (x; k n (x))=A n x + g n (x), with A n ! A and with g n (x) being o (x) uniformly on x <p> Now continuity of solutions on the right-hand side gives the result globally on K.) In general, smooth (or even continuous) stabilizers fail to exist, as discussed for instance in <ref> [33] </ref>, Section 4.8 and references there. Thus 1HLN feedback laws, with continuous , do not provide a rich enough class of controllers. This motivates the search for discontinuous feedback. <p> Use the notation = (A; B; C; ); omitting if obvious from the context. One interprets the above data (A; B; C) as defining a controlled and observed dynamical system evolving in IR n (in the standard sense of control theory; 33 see e.g. <ref> [33] </ref>) by means of a differential equation _x = ~ (Ax + Bu) ; y = Cx in continuous-time (dot indicates time derivative), or a difference equation x + = ~ (Ax + Bu) ; y = Cx in discrete-time ("+" indicates a unit time shift). <p> For any choice of positive integers n; m; p; denote by S c n;m;p the set of all triples of matrices (A; B; C), A 2 R nfin , B 2 R nfim , C 2 R pfin which are "canonical" (observable and controllable, as in <ref> [33] </ref>, section 5.5). This is a generic set of triples, in the sense that the entries of the ones that do not satisfy the property are zeroes of certain nontrivial multivariable polynomials.
Reference: [34] <author> Sontag, E.D., </author> <title> "Feedforward nets for interpolation and classification," </title> <journal> J. Comp. Syst. Sci. </journal> <volume> 45(1992): </volume> <pages> 20-48. </pages>
Reference-contexts: Consider the property (*): 9 c s.t. is differentiable at c and 0 (c) 6= 0: Then, for classification, the following results are given in <ref> [34] </ref>: clsf (H) = 1=3; clsf d (H) = 2=3; clsf () 2=3 assuming that is sigmoidal and (*) holds. <p> It is easy to construct examples of sigmoids, even extremely well-behaved ones (analytic and squashing, for instance) for which the VC dimension of the class H (F n;;m ) is infinite; see <ref> [34] </ref>. However, for the stan dard sigmoid, a recent result in [24] proves that vc (F ) &lt; 1, so neural nets with activation s are also learnable.
Reference: [35] <author> Sontag, E.D., </author> <title> "Feedback stabilization using two-hidden-layer nets," </title> <journal> IEEE Trans. Neural Networks 3 (1992): </journal> <pages> 981-990. </pages>
Reference-contexts: On the other hand, it can be shown that every system that is stabilizable, by whatever k, can also be stabilized using 2HL nets with discontinuous activations (under mild technical conditions, and using sampled control). See <ref> [35] </ref> for details. To summarize, if stabilization requires discontinuities in feedback laws, it may be the case that no possible 1HL net stabilizes. <p> It is trivial to see that in general discontinuous functions are needed, so nets with continuous cannot be used. However, and this is the interesting part, <ref> [35] </ref> establishes that nets with just one hidden layer, even if discontinuous is allowed, are not enough to guarantee the solution of all such problems. <p> More surprisingly, 1HLN feedback laws, even with H activations, are not in general enough |intuitively, one is again trying to solve inverse problems| but two hidden layer nets using H (and having direct i/o connections) are always sufficient. More precisely, <ref> [35] </ref> shows that the weakest possible type of open-loop asymptotic controllability is sufficient to imply the existence of (sampled) controllers built using such two-hidden layer nets, which stabilize on compact subsets of the state space.
Reference: [36] <author> Sontag, E.D., and H.J. Sussmann, </author> <title> "Backpropagation separates where perceptrons do," </title> <booktitle> Neural Networks, </booktitle> <volume> 4(1991): </volume> <pages> 243-249. </pages>
Reference-contexts: Among the many numerical complications that arise when following such a procedure are the possibilities of (1) non-global local minima, and (2) multiple global minimizers. The first issue was dealt with by many different authors |see for instance <ref> [36] </ref> and the references there| and will not be reviewed here.
Reference: [37] <author> Sussmann, H.J., </author> <title> "Uniqueness of the weights for minimal feedforward nets with a given input-output map," </title> <booktitle> Neural Networks 5(1992): </booktitle> <pages> 589-593. </pages>
Reference-contexts: With these notations, beh (u) = c 0 + P n As in <ref> [37] </ref>, is called irreducible if the following properties hold: c i 6= 0 for each i = 1; : : : ; n; B i 6= 0 for each i = 1; : : : ; n; and (B i ; b 0i ) 6= (B j ; b 0j ) <p> However, the most interesting activation for neural network applications is (x) = tanh (x), or equivalently after a linear transformation, the standard sigmoid 1 1+e x . In this case, Sussmann showed in <ref> [37] </ref> that the ip property, and hence the desired uniqueness statement, hold. His proof was based on explicit computations for the particular function tanh (x).
Reference: [38] <author> Vapnik, V.N., </author> <title> Estimation of Dependencies Based on Empirical Data, </title> <publisher> Springer, </publisher> <address> Berlin, </address> <year> 1982. </year>
Reference-contexts: Very closely related ideas appeared in statistics even earlier, in the work of Vapnik and Chervonenkis |see the excellent book <ref> [38] </ref>| and the interactions between statistics and computer science are the subject of much current research. The next few paragraphs introduce the basic ideas, using terminology from learning theory; for more details see for instance the textbook [3]. <p> This leads computationally to the loading question discussed earlier. In the statistics literature |see <ref> [38] </ref>| this "naive technique" is a particular case of what is called empirical risk minimization. The above discussion corresponds to being able to learn uniformly with respect to unknown input distributions. <p> the set of integers for which there is some set S of cardinality that can be shattered by F . (Thus, vc (F) is at least as large as the capacity c (F) defined earlier.) The main result, due to [10], but closely related to previous results in statistics (see <ref> [38] </ref>) is: The class F is learnable if and only if vc (F) &lt; 1.
Reference: [39] <author> White, D.A., and D.A. Sofge (eds.), </author> <title> Handbook of Intelligent Control: Neural, Fuzzy and Adaptive Approaches, </title> <publisher> Van Nostrand Reinhold, </publisher> <address> NY, </address> <year> 1992. </year>
Reference-contexts: Most recent major control conferences have had introductory courses devoted to the topic, and, in addition, many good overviews are available in the general literature; see for instance the papers [5], [20], [7], [16], and other papers in the books [27] and <ref> [39] </ref>.
Reference: [40] <author> Weiss, </author> <title> S.M., and C.A. Kulikowski, Computer Systems That Learn, </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1991. </year> <month> 41 </month>
Reference-contexts: Statistical studies. In network learning systems, all the usual issues associated to estimation arise: the tradeoff between variance and bias (or, in AI terms, between generality and generalization). Cross-validation and other techniques are often applied; see for instance the book <ref> [40] </ref> for much on this topic. Studies of the effect of incremental (on-line) versus "all at once" (batch or off-line) learning. In actual applications that involve gradient descent, often the complete gradient is not computed at each stage, but an approximation is used, which involves only new data.
References-found: 40

