URL: ftp://ftp.cs.washington.edu/tr/1994/09/UW-CSE-94-09-07.PS.Z
Refering-URL: http://www.cs.washington.edu/research/tr/tr-by-title.html
Root-URL: 
Phone: (206) 685-2094; fax: (206) 543-2969  
Title: A Framework for Selective Recompilation in the Presence of Complex Intermodule Dependencies  
Author: Craig Chambers, Jeffrey Dean and David Grove 
Note: -chambers,jdean,grove-@cs.washington.edu  
Abstract: Department of Computer Science and Engineering, FR-35 University of Washington Seattle, Washington 98195 USA Technical Report 94-09-07 September 1994 
Abstract-found: 1
Intro-found: 1
Reference: [Adams et al. 94] <author> Rolf Adams, Walter Tichy, and Annette Weinert. </author> <title> The Cost of Selective Recompilation and Environment Processing. </title> <journal> ACM Transactions on Software Engineering and Methodology, </journal> <volume> 3(1):328, </volume> <month> January </month> <year> 1994. </year>
Reference-contexts: Selective recompilation attempts to minimize the amount of code that must be recompiled to maintain the correctness of the generated code with respect to a programs source code. Adams et al. provides an overview of several techniques and a quantitative comparison of their effectiveness in reducing compilation time <ref> [Adams et al. 94] </ref>.
Reference: [Burke & Torczon 93] <author> Michael Burke and Linda Torczon. </author> <title> Interprocedural Optimization: Eliminating Unnecessary Recompilation. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 15(3):367399, </volume> <month> July </month> <year> 1993. </year>
Reference-contexts: Burke and Torczon describe several schemes for performing selective recompilation in the face of common interprocedural optimizations for procedural languages <ref> [Burke & Torczon 93] </ref>. Under their compilation model, each procedure has several associated interprocedural summary sets. The simplest form of selective recompilation is to recompile a procedure whenever the body of the procedure changes or when an interprocedural set used during the compilation of the procedure changes.
Reference: [Chambers & Ungar 91] <author> Craig Chambers and David Ungar. </author> <title> Making Pure Object-Oriented Languages Practical. </title> <booktitle> In Proceedings OOPSLA 91, </booktitle> <pages> pages 115, </pages> <month> November </month> <year> 1991. </year> <journal> Published as ACM SIGPLAN Notices, </journal> <volume> volume 26, number 11. </volume>
Reference-contexts: One proven approach applies static class analysis to determine the possible class (es) of the receiver of a message and then performs method lookup at compile-time in an effort to replace the expensive dynamically-bound message send with a cheaper statically-bound procedure call <ref> [Chambers & Ungar 91] </ref>. Subsequent optimizations such as interprocedural analysis or inlining can further speed the call. These optimizations can improve performance by a factor of 5 to 20 in programs that send messages frequently [Chambers 92].
Reference: [Chambers 92] <author> Craig Chambers. </author> <title> The Design and Implementation of the SELF Compiler, an Optimizing Compiler for Object-Oriented Programming Languages. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <month> March </month> <year> 1992. </year>
Reference-contexts: Subsequent optimizations such as interprocedural analysis or inlining can further speed the call. These optimizations can improve performance by a factor of 5 to 20 in programs that send messages frequently <ref> [Chambers 92] </ref>. To perform compile-time method lookup, the compiler examines portions of the class inheritance graph, thereby introducing non-local dependencies between selected attributes of class declarations and pieces of optimized code. To enable incremental recompilation, the compiler must track these relationships between source code and optimized code.
Reference: [Chambers 93] <author> Craig Chambers. </author> <title> The Cecil Language: Specification and Rationale. </title> <type> Technical Report TR-93-03-05, </type> <institution> Department of Computer Science and Engineering. University of Washington, </institution> <month> March </month> <year> 1993. </year>
Reference-contexts: We used our framework to develop a highly-selective dependency mechanism for the Cecil object-oriented language <ref> [Chambers 93] </ref>.
Reference: [Chambers et al. 89] <author> Craig Chambers, David Ungar, and Elgin Lee. </author> <title> An Efficient Implementation of SELF a Dynamically-Typed Object-Oriented Language Based on Prototypes. </title> <booktitle> In Proceedings OOPSLA 89, </booktitle> <pages> pages 4970, </pages> <month> October </month> <year> 1989. </year> <journal> Published as ACM SIGPLAN Notices, </journal> <volume> volume 24, number 10. </volume>
Reference-contexts: selectivity than a header file system, the optimizing compiler for the SELF object-oriented language [Ungar & Smith 87] uses a fine-grained dependency graph structure linking each compiled procedure to the individual pieces of declarations, such as method declarations and class inheritance links, on which the methods compilation and optimization depended <ref> [Chambers et al. 89] </ref>. Additionally, the SELF system includes a special no-other-methods pseudo-declaration with each class that represents the absence of any other methods in the class.
Reference: [Dausmann 85] <author> M. Dausmann. </author> <title> Informationstrukuren und Verfahren fr die getrennte bersetzung von Program-mteilen. </title> <type> Technical report, </type> <note> GMD-Bericht 155, </note> <editor> R. </editor> <publisher> Oldenburg Verlag, </publisher> <address> Munich, Germany, </address> <year> 1985. </year>
Reference-contexts: Moreover, since it is likely that many implementations will depend on the same groups of declarations, automatic factoring nodes inserted by our framework can help reduce the space cost for the fine-grained dependency graph. Attribute recompilation <ref> [Dausmann 85] </ref> extends smart recompilation to allow dependencies to depend on particular attributes of declarations, rather than depending on the whole declaration. For example, suppose B impl depends only on the size of structure S, not on the individual elements of the structure.
Reference: [Feldman 79] <author> Stuart I. Feldman. </author> <title> Makea computer program for maintaining computer programs. </title> <journal> Software Practice and Experience, </journal> <volume> 9(4):255265, </volume> <year> 1979. </year>
Reference-contexts: For example, for a 2 A Framework for Selective Recompilation in the Presence of Complex Intermodule Dependencies compiler, a coarse-grained dependency structure can be maintained, say at the file-level granularity as in UNIX make <ref> [Feldman 79] </ref>, which would be space-efficient but not very selective. Alternatively, a finer-grained dependency structure can be maintained that is selective but space-consuming.
Reference: [Goldberg & Robson 83] <author> Adele Goldberg and David Robson. </author> <title> Smalltalk-80: The Lanaguge and its Implementation. </title> <address> Addision-Wesley, Reading, MA, </address> <year> 1983. </year>
Reference-contexts: This section describes our dependency system and compares its selectivity and space requirements to that of several alternative mechanisms. 3.1 Compile-Time Method Lookup In object oriented languages, dynamic dispatch (introduced by message sends in Smalltalk <ref> [Goldberg & Robson 83] </ref> and virtual function calls in C++ [Stroustrup 91]) is often a major source of runtime inefficiency. Effective optimization of programs that use dynamic dispatch heavily requires the elimination of as many of the dispatches as possible.
Reference: [Hall et al. 93] <author> M.W. Hall, J.M. Mellor-Crummey, A. Carle, and R. Rodriguez. FIAT: </author> <title> A Framework for Interproce-dural Analysis and Transformation. </title> <booktitle> In The Sixth Anunual Workshop on Parallel Languages and Compilers, </booktitle> <month> August </month> <year> 1993. </year>
Reference-contexts: The FIAT system improves on this by computing interprocedural summary information lazily <ref> [Hall et al. 93] </ref>. Using our dependency framework, however, the computation and update of the interprocedural summary information could be made incremental, with the framework only invalidating and recomputing those summary sets that are out of date.
Reference: [MS et al. 93] <author> Alberto Marchetti-Spaccamela, Umberto Nanni, and Hans Rohnert. </author> <title> On-line Graph Algorithms for Incremental Compilation. </title> <editor> In Jan van Leeuwen, editor, </editor> <booktitle> Graph-Theoretic Concepts in Computer Science, number 790 in Lecture Notes in Computer Science, </booktitle> <pages> pages 7086, </pages> <address> Utrecht, The Netherlands, June 1993. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: In the worst case, this algorithm could visit all nodes downstream of n, which could be of size O (N) where N is the number of nodes in the dependency graph. A similar algorithm for incremental maintenance of a topological ordering was described by Marchetti-Spaccamela, Nanni, and Rohnert <ref> [MS et al. 93] </ref>. 2.3 Factoring Nodes Fine-grained dependencies can support more precise invalidation than coarser-grained dependency representations. However, a naive representation of fine-grained dependencies can consume expansive amounts of storage. To reduce the size of the dependence graph, our framework provides the notion of factoring.
Reference: [Newbery 89] <author> Frances J. Newbery. </author> <title> Edge Concentration: A Method for Clustering Directed Graphs. </title> <booktitle> ACM SIGSOFT Sofware Engineering Notes, </booktitle> <address> 17(7):7685, </address> <month> November </month> <year> 1989. </year>
Reference-contexts: Newbery describes a related algorithm to factor bipartite graphs, with the goal of reducing the number of edge crossings when the graph is displayed <ref> [Newbery 89] </ref>.
Reference: [Shao & Appel 93] <author> Zhong Shao and Andrew W. Appel. </author> <title> Smartest Recompilation. </title> <booktitle> In Conference Record of the Twentieth Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, </booktitle> <pages> pages 439450, </pages> <address> Charleston, South Carolina, </address> <month> January </month> <year> 1993. </year>
Reference-contexts: For example, suppose B impl depends only on the size of structure S, not on the individual elements of the structure. This can be * In smartest recompilation <ref> [Shao & Appel 93] </ref>, modules are compiled independently to avoid creating intermodule dependencies, and so smartest recompilation has no need of an intermodule dependency mechanism.
Reference: [Stroustrup 91] <author> Bjarne Stroustrup. </author> <title> The C++ Programming Language (second edition). </title> <address> Addision-Wesley, Reading, MA, </address> <year> 1991. </year> <month> 17 </month>
Reference-contexts: This section describes our dependency system and compares its selectivity and space requirements to that of several alternative mechanisms. 3.1 Compile-Time Method Lookup In object oriented languages, dynamic dispatch (introduced by message sends in Smalltalk [Goldberg & Robson 83] and virtual function calls in C++ <ref> [Stroustrup 91] </ref>) is often a major source of runtime inefficiency. Effective optimization of programs that use dynamic dispatch heavily requires the elimination of as many of the dispatches as possible.
References-found: 14

