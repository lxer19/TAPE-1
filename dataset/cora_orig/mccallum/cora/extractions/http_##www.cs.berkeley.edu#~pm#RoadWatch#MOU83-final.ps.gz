URL: http://www.cs.berkeley.edu/~pm/RoadWatch/MOU83-final.ps.gz
Refering-URL: http://www.cs.berkeley.edu/~pm/RoadWatch/traffic-pubs.html
Root-URL: 
Author: J. Malik and S. Russell J. Weber, T. Huang and D. Koller 
Affiliation: Computer Science Division University of California  
Note: Principal Investigators:  Other authors:  
Abstract: A Machine Vision Based Surveillance System for California Roads PATH project MOU-83 Final Report 
Abstract-found: 1
Intro-found: 1
Reference: [AOJJ89] <author> S. Andersen, K. Olesen, F. V. Jensen, and F. Jensen. </author> <title> Hugin* a shell for building bayesian belief universes for exp ert systems. </title> <booktitle> In Proc. of the 10th Int'l Joint Conference on Artificial Intel ligence, </booktitle> <year> 1989. </year>
Reference-contexts: Thus, evidence accumulated over time is always integrated into the current belief network model [Nic92, Kja93]. 3.2 Traffic network structure The symbolic reasoning component for our system is built on the HUGIN inference engine for belief networks <ref> [AOJJ89] </ref>. Figure 4 shows an example belief network fragment for a single vehicle. Figure 5 shows the fragment projected over one time slice. For each vehicle in a traffic scene, there is a separate belief network corresponding to it.
Reference: [Gel74] <author> Arthur Gelb, </author> <title> editor. Applied Optimal Estimation. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA., </address> <year> 1974. </year>
Reference-contexts: Two primary factors that complicate this task are noisy sensors, which yield imprecise measurements, and vehicle occlusions, which make it more difficult to identify and disambiguate vehicles. To address the problem of noisy measurements, we employ vehicle motion models that are updated in a Kalman filter <ref> [Gel74] </ref> formalism, thus yielding most likely estimates based on accumulated observations. The tracking is performed in a world coordinate system. This is accomplished by projecting the points on the image onto the road plane.
Reference: [HKM + 94] <author> T. Huang, D. Koller, J. Malik, G. Ogasawara, B. Rao, S. Russell, and J.Weber. </author> <title> Automatic symbolic traffic scene analysis using belief networks. </title> <booktitle> In Proceedings of the 12th National Conference on Artificial Intelligence, </booktitle> <pages> pages 966-972, </pages> <address> Seattle, WA, July 31-Aug. 4, </address> <year> 1994. </year>
Reference-contexts: These enhancements are described in more detail in <ref> [HKM + 94] </ref>. 4 Results with Real-World Traffic Scenes We have tested our system on both real-world image sequences and syntheticly generated sequences. The synthetic sequences were used for simulating stalls and accidents (which can not be planned for the filming schedule).
Reference: [HKN91] <author> N. Heinze, W. Kruger, and H.-H. Nagel. </author> <title> Berechnung von bewegungsverben zur beschreibung von aus bildfolgen gewonnenen trajektorien in straenverkehrsszenen. </title> <journal> Informatik - Forschung und Entwicklung, </journal> <volume> 6 </volume> <pages> 51-61, </pages> <year> 1991. </year> <month> 12 </month>
Reference-contexts: They also provide a natural framework for expressing knowledge about typical traffic behavior, allowing more accurate analyses from a given sensor stream. Symbolic traffic scene analysis using vision-based surveillance systems has been previously investigated by several research groups <ref> [SBSZ87, KHH91, HKN91, HOR93] </ref>. The challenges of this approach include identifying vehicles despite imprecise video data and changing lighting conditions, tracking individual vehicles despite their overlapping with each other, and efficiently providing high-level descriptions based on evidence accumulated over time.
Reference: [HOR93] <author> T. Huang, G. Ogasawara, and S. Russell. </author> <title> Symbolic traffic scene analysis using dynamic belief networks. </title> <booktitle> In AAAI Workshop on AI in IVHS, </booktitle> <address> Washington D.C., </address> <year> 1993. </year>
Reference-contexts: They also provide a natural framework for expressing knowledge about typical traffic behavior, allowing more accurate analyses from a given sensor stream. Symbolic traffic scene analysis using vision-based surveillance systems has been previously investigated by several research groups <ref> [SBSZ87, KHH91, HKN91, HOR93] </ref>. The challenges of this approach include identifying vehicles despite imprecise video data and changing lighting conditions, tracking individual vehicles despite their overlapping with each other, and efficiently providing high-level descriptions based on evidence accumulated over time.
Reference: [KHH91] <author> D. Koller, N. Heinze, and H.-H. Nagel. </author> <title> Algorithmic characterization of vehicle trajectories from image sequences by motion verbs. </title> <booktitle> In IEEE Conf. on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 90-95, </pages> <address> Lahaina, Maui, Hawaii, </address> <month> June 3-6, </month> <year> 1991. </year>
Reference-contexts: They also provide a natural framework for expressing knowledge about typical traffic behavior, allowing more accurate analyses from a given sensor stream. Symbolic traffic scene analysis using vision-based surveillance systems has been previously investigated by several research groups <ref> [SBSZ87, KHH91, HKN91, HOR93] </ref>. The challenges of this approach include identifying vehicles despite imprecise video data and changing lighting conditions, tracking individual vehicles despite their overlapping with each other, and efficiently providing high-level descriptions based on evidence accumulated over time.
Reference: [Kil92] <author> Michael Kilger. </author> <title> A shadow handler in a video-based real-time traffic monitoring system. </title> <booktitle> In IEEE Workshop on Applications of Computer Vision, </booktitle> <pages> pages 10601066, </pages> <address> Palm Springs, CA, </address> <year> 1992. </year>
Reference-contexts: Reliable background estimation, which is critical for accurate identification of moving "blobs", is made more difficult as lighting conditions change. We perform this initialization step by using a modified version of the moving object segmentation method suggested by [KvB90] and implemented by <ref> [Kil92] </ref>. Our method employs a Kalman filter-based adaptive background model. This allows the background estimate to evolve as the weather and time of day affect lighting conditions. <p> As a result, separate vehicles may be tracked as a single, large vehicle if the shadow of one vehicle extends to the other vehicle. Other vision-based surveillance systems have come upon this 11 same problem and simple heuristics have been developed to deal with it <ref> [Kil92] </ref>. We will be looking into both histogramming methods and the use of color information to help alleviate this problem.
Reference: [Kja93] <author> Uffe Kjaerulff. </author> <title> User's guide to dhugin. </title> <type> Technical report, </type> <institution> Institute of Electronic Systems, Aalborg University, </institution> <year> 1993. </year>
Reference-contexts: As new slices are added to the network, older slices are removed. Before a slice is removed, its influence is "rolled-up" into the next slice by recomputing probability tables for certain nodes in that slice. Thus, evidence accumulated over time is always integrated into the current belief network model <ref> [Nic92, Kja93] </ref>. 3.2 Traffic network structure The symbolic reasoning component for our system is built on the HUGIN inference engine for belief networks [AOJJ89]. Figure 4 shows an example belief network fragment for a single vehicle. Figure 5 shows the fragment projected over one time slice. <p> This approach does not allow dynamic alteration of the belief network structure, but it greatly improves performance by eliminating the need for network re-compilation after every time slice. The dHUGIN package <ref> [Kja93] </ref> provides extensions to HUGIN for dynamic belief networks, but it does not provide the flexibility of our first approach for changing the network structure 9 from one time slice to the next, and it does not provide the performance speedup of our second approach.
Reference: [KvB90] <author> Klaus-Peter Karmann and Achim von Brandt. </author> <title> Moving object recognition us-ing an adaptive background memory. In V Cappellini, editor, Time-Varying Image Processing and Moving Object Recognition, 2. </title> <publisher> Elsevier, </publisher> <address> Amsterdam, The Netherlands, </address> <year> 1990. </year>
Reference-contexts: Reliable background estimation, which is critical for accurate identification of moving "blobs", is made more difficult as lighting conditions change. We perform this initialization step by using a modified version of the moving object segmentation method suggested by <ref> [KvB90] </ref> and implemented by [Kil92]. Our method employs a Kalman filter-based adaptive background model. This allows the background estimate to evolve as the weather and time of day affect lighting conditions.
Reference: [KWM93] <author> Dieter Koller, Joseph Weber, and Jitendra Malik. </author> <title> Robust multiple car tracking with occlusion reasoning. </title> <type> Technical Report UCB/CSD 93/780, </type> <institution> Computer Science Division (EECS), University of California, Berkeley, </institution> <year> 1993. </year>
Reference-contexts: The gains ff 1 and ff 2 are based on estimates of the rate of change of the background. For a complete description, we refer the reader to <ref> [KWM93] </ref>. A block diagram for the low-level vision and tracking components is shown in figure 2. The track initiation and occlusion reasoning are performed in image coordinates while the tracking is performed in real world coordinates. <p> To avoid these artificial shifts and to obtain reasonable tracks, we employ an explicit occlusion reasoning algorithm, which compensates for overlapping vehicles. The occlusion reasoning algorithm works because the traffic scene geometry is known and because motion is assumed to be constrained to the ground plane <ref> [KWM93] </ref>. This knowledge makes it possible to determine a depth ordering among the objects in the scene, and this depth ordering defines the order in which objects are able to occlude each other. object, object 2, contains an segment that is occluded by object 1.
Reference: [KWM94] <author> D. Koller, J. Weber, and J. Malik. </author> <title> Robust multiple car tracking with occlu-sion reasoning. </title> <booktitle> In Proc. Third European Conference on Computer Vision, </booktitle> <pages> pages 189-196, </pages> <address> Stockholm, Sweden, </address> <month> May 2-6, </month> <year> 1994, </year> <title> J.-O. </title> <booktitle> Eklundh (ed.),Lecture Notes in Computer Science 800-801, </booktitle> <publisher> Springer-Verlag, </publisher> <address> Berlin, Heidelberg, New York, </address> <year> 1994. </year>
Reference-contexts: Finally, an AVCS would need information about the actions of neighboring vehicles and the condition of traffic lanes ahead to control an automated car moving along a freeway [NS91]. In this paper, we describe a prototype system in which we have successfully combined a robust, vision-based traffic surveillance system <ref> [KWM94] </ref> with a dynamic belief network dedicated to analyzing traffic scenes. Unlike conventional loop detectors, which are buried underneath highways to count vehicles, video monitoring systems are less disruptive and less costly to install. They also have greater range and allow for more detailed descriptions of traffic situations. <p> We have achieved improvements in performance, reliability, and accuracy by applying a new approach for detecting and tracking vehicles, by explicitly reasoning about vehicle occlusions <ref> [KWM94] </ref>, and by devising techniques for fast belief network update, localized reasoning, and flexible node semantics. 2 Low-Level Machine Vision-Based Surveillance Our traffic surveillance system is based on the block diagram shown in figure 1.
Reference: [LW89] <author> S. L. Lauritzen and N. Wermuth. </author> <title> Graphical models for associations between vari-ables, some of which are qualitative and some quantitative. </title> <journal> Annals of Statistics, </journal> <volume> 17 </volume> <pages> 31-57, </pages> <year> 1989. </year>
Reference-contexts: Besides continuing to refine the network design and to optimize its performance, we are investigating methods for enabling the symbolic reasoner to handle mixed networks with both continuous and discrete variables <ref> [LW89] </ref>. This offers the opportunity for greater performance over purely discrete networks, and it seems reasonable, since sensor variables such as vehicle positions and velocities are adequately modeled as Gaussians. The symbolic rea- soner can also be enhanced to provide other types of descriptions, such as driver behaviors.
Reference: [Nic92] <author> A. Nicholson. </author> <title> Monitoring discrete environments using dynamic belief networks. </title> <type> Phd thesis, </type> <institution> Oxford University, </institution> <year> 1992. </year>
Reference-contexts: As new slices are added to the network, older slices are removed. Before a slice is removed, its influence is "rolled-up" into the next slice by recomputing probability tables for certain nodes in that slice. Thus, evidence accumulated over time is always integrated into the current belief network model <ref> [Nic92, Kja93] </ref>. 3.2 Traffic network structure The symbolic reasoning component for our system is built on the HUGIN inference engine for belief networks [AOJJ89]. Figure 4 shows an example belief network fragment for a single vehicle. Figure 5 shows the fragment projected over one time slice. <p> This is especially important at dusk or dawn, when the surveillance system will see both vehicle outlines and vehicle tail lights. Finally, by including a simple sensor failure model, the network can detect and diagnose sensor failure, while continuing to track vehicles using remaining sensor inputs <ref> [Nic92] </ref>. Testing on various lighting conditions has brought out one of the shortcomings of our system. This is the effect that long shadows have on the tracking. Our initialization procedure begins with the difference between the present frame and an image of the road surface without vehicles.
Reference: [NS91] <author> A. Niehaus and R.F. Stengel. </author> <title> Rule-based guidance for vehicle highway driving in the presence o f uncertainty. </title> <booktitle> In Proceedings of the 1991 American Control Conference, </booktitle> <year> 1991. </year>
Reference-contexts: An ATMS also could analyze local traffic at intersections to identify those with higher risk of accidents. Finally, an AVCS would need information about the actions of neighboring vehicles and the condition of traffic lanes ahead to control an automated car moving along a freeway <ref> [NS91] </ref>. In this paper, we describe a prototype system in which we have successfully combined a robust, vision-based traffic surveillance system [KWM94] with a dynamic belief network dedicated to analyzing traffic scenes.
Reference: [Pea88] <author> J. Pearl. </author> <title> Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. </title> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, CA, </address> <year> 1988. </year>
Reference-contexts: To accomplish this, our symbolic reasoner uses multiple, per-vehicle dynamic belief networks with fast roll-up. 5 3.1 Concepts Belief networks are directed acyclic graphs in which nodes represent random variables (usually discrete) and arcs represent causal connections among the variables <ref> [Pea88] </ref>. Associated with each node is a probability table that provides conditional probabilities of the node's possible states given each possible state of its parents. When values are observed for a subset of the nodes, posterior probability distributions can be computed for any of the remaining nodes. <p> For example, Front Ypos.t and Front Ydot.t in figure 4 refer to "the vehicle in front of the current vehicle". Since the actual vehicle in front may change, these "indexical" <ref> [Pea88] </ref> nodes do not correspond to a specific vehicle. Instead, a preprocessing step uses sensor data to determine which vehicles are currently in front of each other and then sets those node states accordingly.

References-found: 15

