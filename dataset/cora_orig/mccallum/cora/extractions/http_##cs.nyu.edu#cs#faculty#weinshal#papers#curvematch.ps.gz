URL: http://cs.nyu.edu/cs/faculty/weinshal/papers/curvematch.ps.gz
Refering-URL: http://cs.nyu.edu/cs/faculty/weinshal/papers.html
Root-URL: http://www.cs.nyu.edu
Email: email: fyoram,daphnag@cs.huji.ac.il  
Title: Flexible Syntactic Matching of Curves and its Application to Automatic Hierarchical Classification of Silhouettes  
Author: Yoram Gdalyahu and Daphna Weinshall 
Address: 91904 Jerusalem, Israel  
Affiliation: Institute of Computer Science, The Hebrew University  
Abstract: The organization of image databases can rely upon different aspects of image similarity. Here we extract silhouettes from images of three dimensional objects, and rely upon curve similarity for image classification. We propose a flexible curve matching algorithm and demonstrate by extensive experiments that it can perform qualitative matching between weakly similar silhouettes. Occluding contours are matched under partial occlusion and change of viewpoint, and even when the two objects are different (such as the two side views of a horse and a cow). Based on the qualitative syntactic matching, the dissimilarity between every two images in a database is estimated using a proximity measure. Hence we represent the database as a complete graph, with nodes representing the images and dissimilarity values assigning weights to the edges. Our scheme avoids the embedding of images in a vector space. A robust clustering algorithm, which is based on a physical ferromagnet model, is used to find the hierarchical structure underlying the image collection. We tested our scheme with a database of 90 real images of 6 objects, some of them very different, others rather similar. We get a perfect hierarchical classification of these images into 6 classes of objects belonging to 3 different families. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Ansari N., Delp E., </author> <title> "Partial shape recognition: a landmark based approach", </title> <type> PAMI 12, </type> <pages> 470-489, </pages> <year> 1990. </year>
Reference-contexts: There are no syntactic algorithms available which satisfactorily solve both of these problems. If invariant attributes are used, the first problem is immediately addressed, but then the resolution problem either remains unsolved <ref> [1, 17, 28] </ref> or it is addressed by constructing for each curve a cascade of representations at different scales [3, 32, 42]. Moreover, invariant attributes are either non-local (e.g., length that is measured in units of the total curve length), or they are non-interruptible (see discussion in section 2.2.5). <p> For example, in [28] the orientation of a line segment is measured with respect to its successor, hence the opening of a gap between segments introduces ambiguity into the representation (see figure 8). In [17] the attributes which describe curve fragments are Fourier coefficients, a measure called "sphericity" in <ref> [1] </ref>. Both are invariant attributes, but non-interruptible 6 . Moreover, it seems to be impossible to find operators on invariant attributes that are equivalent to smoothing in real space. <p> Dense matching methods provide measures of dissimilarity like the "elastic distance" [5, 13, 34], proximity matching methods use the (average) residual distance between matched points <ref> [1, 24, 47] </ref>, spread primitive matching methods make use of a similar measure (but residual distances are defined between shape primitives which are not necessarily points) [10, 27], and finally syntactic matching methods provide the "edit distance" [17, 33, 39, 42] as a dissimilarity measure. <p> Our approach is to combine syntactic matching with a proximity measure (in this sense our method resembles that of <ref> [1] </ref>). That is, we establish feature correspondence using syntactic matching (as described in section 2.2), and then evaluate the dissimilarity according to the residual distances between matched points.
Reference: [2] <author> Arkin E., Paul Chew L., Huttenlocher D., Kedem K. and Mitchel J., </author> <title> "An efficiently computable metric for comparing polygonal shapes", </title> <type> PAMI 13, </type> <pages> 209-216, </pages> <year> 1991. </year>
Reference-contexts: Dense matching is usually formulated as a parameterization problem, with some cost function to be minimized. The cost might be defined as the "elastic energy" needed to transform one curve to the other [5, 9, 11], but other alternatives exist <ref> [2, 16, 13, 31] </ref>. The main drawbacks of these methods are their high computational complexity (which is reduced significantly if only key points are matched), and the fact that none of them is invariant under both 2D rotation and scaling. <p> The conversion of residual distances into a dissimilarity measure is explained in section 3.2. For the reader who wonders why we can't directly minimize the residual distances by proximity matching the answer is provided in section 3.1, where we also show that the Hausdorff proximity criterion <ref> [2, 20, 21] </ref>, which is not based on any prior feature pairing, is not adequate to our purpose. 3.1 Direct proximity minimization The efficient minimization of a proximity criterion, like the average distance between matched points or the Hausdorff distance, is addressed in many papers.
Reference: [3] <author> Asada H. and Brady M., </author> <title> "The curvature primal sketch", </title> <type> PAMI 8, </type> <pages> 2-14, </pages> <year> 1986. </year>
Reference-contexts: If invariant attributes are used, the first problem is immediately addressed, but then the resolution problem either remains unsolved [1, 17, 28] or it is addressed by constructing for each curve a cascade of representations at different scales <ref> [3, 32, 42] </ref>. Moreover, invariant attributes are either non-local (e.g., length that is measured in units of the total curve length), or they are non-interruptible (see discussion in section 2.2.5).
Reference: [4] <author> Ayach N. and Faugeras O., </author> <title> "HYPER: a new approach for the recognition and positioning of two dimensional objects", </title> <type> PAMI 8, </type> <pages> 44-54, </pages> <year> 1986. </year>
Reference-contexts: The idea behind proximity matching methods is to search for the best matching while permitting the rotation, translation and scaling (to be called alignment transformation) of each curve, such that the distances between matched key points are minimized <ref> [4, 22, 24, 43] </ref>. Consequently these methods are rather slow; moreover, if scaling is permitted an erroneous shrinking of one feature set may result, followed by the matching of the entire set with a small number of features from the other set.
Reference: [5] <author> Basri R., Costa L., Geiger D. and Jacobs D., </author> <title> "Determining the similarity of deformable shapes" IEEE Workshop on Physics Based Modeling in Computer Vision, </title> <type> 135-143, </type> <year> 1995. </year>
Reference-contexts: Dense matching is usually formulated as a parameterization problem, with some cost function to be minimized. The cost might be defined as the "elastic energy" needed to transform one curve to the other <ref> [5, 9, 11] </ref>, but other alternatives exist [2, 16, 13, 31]. The main drawbacks of these methods are their high computational complexity (which is reduced significantly if only key points are matched), and the fact that none of them is invariant under both 2D rotation and scaling. <p> More specifically, let us follow the classification of methods proposed in sec tion 2.1: We distinguished between dense matching and feature matching, and divided feature matching into three categories: proximity matching, spread primitive matching, and syntactic matching. Dense matching methods provide measures of dissimilarity like the "elastic distance" <ref> [5, 13, 34] </ref>, proximity matching methods use the (average) residual distance between matched points [1, 24, 47], spread primitive matching methods make use of a similar measure (but residual distances are defined between shape primitives which are not necessarily points) [10, 27], and finally syntactic matching methods provide the "edit distance"
Reference: [6] <author> Bhanu B. and Faugeras O., </author> <title> "Shape matching of two dimensional objects", </title> <type> PAMI 6, </type> <pages> 137-155, </pages> <year> 1984. </year>
Reference-contexts: But in the absence of any ordering information (like in stereo matching of many small fragments of curves), the matching algorithm may be called "spread primitive matching". In this category we find algorithms that seek isomorphism between attributed relational graphs <ref> [6, 27, 10] </ref>, and algorithms that look for the largest set of mutually compatible matches.
Reference: [7] <author> Blatt M., Wiseman S. and Domany E., </author> <title> "Data clustering using a model granular magnet", </title> <booktitle> Neural Computation 9, </booktitle> <pages> 1805-1842, </pages> <year> 1997. </year>
Reference-contexts: In our work we use an algorithm which is based on a physical magnetic model <ref> [7] </ref>. Note that the problem of clustering is ill posed, and different techniques are suitable for different problems. The algorithm that we use determines the number of clusters in a (true) hierarchical manner, and tolerates to some extent violations of metric properties (namely, violation of the triangle inequality). <p> Instead, an algorithm which seems to be especially suitable for our data is based on an analogy to a granular ferromagnet <ref> [7] </ref>. This is a relaxation model, where points are able to "interact" with each other, and reach some steady state. Points may influence each other directly or through other mediating points, hence the model is suitable for chained data.
Reference: [8] <author> Bolles R. and Cain R., </author> <title> "Recognizing and locating partially visible objects: the focus feature method", </title> <journal> Int. J. Robotics Res. </journal> <volume> 1, </volume> <pages> 57-81, </pages> <year> 1982. </year>
Reference-contexts: Here, compatibility means an agreement on the induced coordinate transformation, and a few techniques exist to find the largest set of mutually compatible matches (e.g., clustering in Hough space [37], geometrical hashing [26], and clique finding in an association graph <ref> [8, 25, 12] </ref>). For our purpose of matching complex outlines, it is advantageous to use the natural order of primitives and there is no need to solve the more general problem, which requires additional computational cost.
Reference: [9] <author> Brint A. and Brady M., </author> <title> "Stereo matching of curves", </title> <booktitle> Image and vision computing 8, </booktitle> <pages> 50-56, </pages> <year> 1990. </year>
Reference-contexts: Dense matching is usually formulated as a parameterization problem, with some cost function to be minimized. The cost might be defined as the "elastic energy" needed to transform one curve to the other <ref> [5, 9, 11] </ref>, but other alternatives exist [2, 16, 13, 31]. The main drawbacks of these methods are their high computational complexity (which is reduced significantly if only key points are matched), and the fact that none of them is invariant under both 2D rotation and scaling.
Reference: [10] <author> Christmas W., Kittler J. and Petrou M., </author> <title> "Structural matching in computer vision using probabilistic relaxation", </title> <type> PAMI 17, </type> <pages> 749-764, </pages> <year> 1995. </year>
Reference-contexts: But in the absence of any ordering information (like in stereo matching of many small fragments of curves), the matching algorithm may be called "spread primitive matching". In this category we find algorithms that seek isomorphism between attributed relational graphs <ref> [6, 27, 10] </ref>, and algorithms that look for the largest set of mutually compatible matches. <p> We note that a linear measure has been widely used by others <ref> [38, 39, 28, 10] </ref>. The non linear measure used by [27] differs from ours in exactly the same way as discussed above concerning length. <p> matching methods provide measures of dissimilarity like the "elastic distance" [5, 13, 34], proximity matching methods use the (average) residual distance between matched points [1, 24, 47], spread primitive matching methods make use of a similar measure (but residual distances are defined between shape primitives which are not necessarily points) <ref> [10, 27] </ref>, and finally syntactic matching methods provide the "edit distance" [17, 33, 39, 42] as a dissimilarity measure.
Reference: [11] <author> Cohen I., Ayache N. and Sulger P., </author> <title> "Tracking points on deformable objects using curvature information", </title> <booktitle> Proc. of ECCV, </booktitle> <pages> 458-466, </pages> <year> 1992. </year>
Reference-contexts: Dense matching is usually formulated as a parameterization problem, with some cost function to be minimized. The cost might be defined as the "elastic energy" needed to transform one curve to the other <ref> [5, 9, 11] </ref>, but other alternatives exist [2, 16, 13, 31]. The main drawbacks of these methods are their high computational complexity (which is reduced significantly if only key points are matched), and the fact that none of them is invariant under both 2D rotation and scaling.
Reference: [12] <author> Davis L., </author> <title> "Shape matching using relaxation techniques", </title> <type> PAMI 1, </type> <pages> 60-72, </pages> <year> 1979. </year>
Reference-contexts: Here, compatibility means an agreement on the induced coordinate transformation, and a few techniques exist to find the largest set of mutually compatible matches (e.g., clustering in Hough space [37], geometrical hashing [26], and clique finding in an association graph <ref> [8, 25, 12] </ref>). For our purpose of matching complex outlines, it is advantageous to use the natural order of primitives and there is no need to solve the more general problem, which requires additional computational cost.
Reference: [13] <author> Del Bimbo A. and Pala P., </author> <title> "Visual image retrieval by elastic matching of user sketches", </title> <type> PAMI 19, </type> <pages> 121-132, </pages> <year> 1997. </year>
Reference-contexts: Dense matching is usually formulated as a parameterization problem, with some cost function to be minimized. The cost might be defined as the "elastic energy" needed to transform one curve to the other [5, 9, 11], but other alternatives exist <ref> [2, 16, 13, 31] </ref>. The main drawbacks of these methods are their high computational complexity (which is reduced significantly if only key points are matched), and the fact that none of them is invariant under both 2D rotation and scaling. <p> More specifically, let us follow the classification of methods proposed in sec tion 2.1: We distinguished between dense matching and feature matching, and divided feature matching into three categories: proximity matching, spread primitive matching, and syntactic matching. Dense matching methods provide measures of dissimilarity like the "elastic distance" <ref> [5, 13, 34] </ref>, proximity matching methods use the (average) residual distance between matched points [1, 24, 47], spread primitive matching methods make use of a similar measure (but residual distances are defined between shape primitives which are not necessarily points) [10, 27], and finally syntactic matching methods provide the "edit distance"
Reference: [14] <author> Duda O. and Hart E., </author> <title> "Pattern classification and scene analysis", </title> <publisher> Wiley-Interscience, </publisher> <address> New York, </address> <year> 1973. </year>
Reference-contexts: Among the available pairwise clustering techniques are agglomerative algorithms (such as single link or complete link), methods of connected components and mutual neighborhoods, methods of graph cuts, stochastic methods and nonparametric density estimation methods <ref> [14, 15, 19, 23, 36, 48] </ref>. In our work we use an algorithm which is based on a physical magnetic model [7]. Note that the problem of clustering is ill posed, and different techniques are suitable for different problems.
Reference: [15] <author> Fukunaga K., </author> <title> "Introduction to statistical pattern recognition", </title> <publisher> Academic Press, </publisher> <address> San Diego, </address> <year> 1990. </year> <title> short version in Proc. </title> <booktitle> of IEEE Conf. on Computer Vision & Pattern Recognition, </booktitle> <month> June </month> <year> 1998 </year> <month> 18 </month>
Reference-contexts: Among the available pairwise clustering techniques are agglomerative algorithms (such as single link or complete link), methods of connected components and mutual neighborhoods, methods of graph cuts, stochastic methods and nonparametric density estimation methods <ref> [14, 15, 19, 23, 36, 48] </ref>. In our work we use an algorithm which is based on a physical magnetic model [7]. Note that the problem of clustering is ill posed, and different techniques are suitable for different problems.
Reference: [16] <author> Geiger D., Gupta A., Costa L. and Vlontzos J., </author> <title> "Dynamic programming for detecting, tracking and matching deformable contours", </title> <type> PAMI 17, </type> <pages> 294-302, </pages> <year> 1995. </year>
Reference-contexts: Dense matching is usually formulated as a parameterization problem, with some cost function to be minimized. The cost might be defined as the "elastic energy" needed to transform one curve to the other [5, 9, 11], but other alternatives exist <ref> [2, 16, 13, 31] </ref>. The main drawbacks of these methods are their high computational complexity (which is reduced significantly if only key points are matched), and the fact that none of them is invariant under both 2D rotation and scaling.
Reference: [17] <author> Gorman J., Mitchell O. and Kuhl F., </author> <title> "Partial shape recognition using Dynamic programming", </title> <type> PAMI 10, </type> <pages> 257-266, </pages> <year> 1988. </year>
Reference-contexts: There are no syntactic algorithms available which satisfactorily solve both of these problems. If invariant attributes are used, the first problem is immediately addressed, but then the resolution problem either remains unsolved <ref> [1, 17, 28] </ref> or it is addressed by constructing for each curve a cascade of representations at different scales [3, 32, 42]. Moreover, invariant attributes are either non-local (e.g., length that is measured in units of the total curve length), or they are non-interruptible (see discussion in section 2.2.5). <p> For example, in [28] the orientation of a line segment is measured with respect to its successor, hence the opening of a gap between segments introduces ambiguity into the representation (see figure 8). In <ref> [17] </ref> the attributes which describe curve fragments are Fourier coefficients, a measure called "sphericity" in [1]. Both are invariant attributes, but non-interruptible 6 . Moreover, it seems to be impossible to find operators on invariant attributes that are equivalent to smoothing in real space. <p> 13, 34], proximity matching methods use the (average) residual distance between matched points [1, 24, 47], spread primitive matching methods make use of a similar measure (but residual distances are defined between shape primitives which are not necessarily points) [10, 27], and finally syntactic matching methods provide the "edit distance" <ref> [17, 33, 39, 42] </ref> as a dissimilarity measure. As we mentioned in section 2.1, dense matching methods are not efficient enough for our purpose which involve the comparison of thousands of complex curves under arbitrary changes of orientation and scale.
Reference: [18] <author> Gregor J. and Thomason M., </author> <title> "Dynamic programming alignment of sequences representing cyclic patterns", </title> <type> PAMI 15, </type> <pages> 129-135, </pages> <year> 1993. </year>
Reference-contexts: Hence, many syntactical matching methods are inspired by efficient and well known string comparison algorithms, which use edit operations (substitution, deletion and insertion) to transform one string to the other <ref> [44, 30, 18] </ref>. The pattern recognition problem is different from the string matching problem in two major aspects, however: first, in pattern recognition invariance to certain geometrical transformations is desired; second, a resolution degradation (or smoothing) may create a completely different list of elements in the syntactical representation.
Reference: [19] <author> Hofmann T. and Buhmann J., </author> <title> "Pairwise data clustering by deterministic annealing", </title> <type> PAMI 19, </type> <pages> 1-14, </pages> <year> 1997. </year>
Reference-contexts: Among the available pairwise clustering techniques are agglomerative algorithms (such as single link or complete link), methods of connected components and mutual neighborhoods, methods of graph cuts, stochastic methods and nonparametric density estimation methods <ref> [14, 15, 19, 23, 36, 48] </ref>. In our work we use an algorithm which is based on a physical magnetic model [7]. Note that the problem of clustering is ill posed, and different techniques are suitable for different problems.
Reference: [20] <author> Huttenlocher D., Klanderman G. and Rucklidge W., </author> <title> "Comparing images using the Hausdorff distance", </title> <type> PAMI 15, </type> <pages> 850-863, </pages> <year> 1993. </year>
Reference-contexts: The conversion of residual distances into a dissimilarity measure is explained in section 3.2. For the reader who wonders why we can't directly minimize the residual distances by proximity matching the answer is provided in section 3.1, where we also show that the Hausdorff proximity criterion <ref> [2, 20, 21] </ref>, which is not based on any prior feature pairing, is not adequate to our purpose. 3.1 Direct proximity minimization The efficient minimization of a proximity criterion, like the average distance between matched points or the Hausdorff distance, is addressed in many papers.
Reference: [21] <author> Huttenlocher D., Lilien R. and Olson C., </author> <title> "Object recognition using subspace methods",Proc. </title> <publisher> ECCV (Cambridge), </publisher> <pages> 536-545, </pages> <year> 1996. </year>
Reference-contexts: The conversion of residual distances into a dissimilarity measure is explained in section 3.2. For the reader who wonders why we can't directly minimize the residual distances by proximity matching the answer is provided in section 3.1, where we also show that the Hausdorff proximity criterion <ref> [2, 20, 21] </ref>, which is not based on any prior feature pairing, is not adequate to our purpose. 3.1 Direct proximity minimization The efficient minimization of a proximity criterion, like the average distance between matched points or the Hausdorff distance, is addressed in many papers.
Reference: [22] <author> Huttenlocher D. and Ullman S., </author> <title> "Object recognition using alignment", </title> <booktitle> Proc. ICCV (London), </booktitle> <pages> 102-111, </pages> <year> 1987. </year>
Reference-contexts: The idea behind proximity matching methods is to search for the best matching while permitting the rotation, translation and scaling (to be called alignment transformation) of each curve, such that the distances between matched key points are minimized <ref> [4, 22, 24, 43] </ref>. Consequently these methods are rather slow; moreover, if scaling is permitted an erroneous shrinking of one feature set may result, followed by the matching of the entire set with a small number of features from the other set.
Reference: [23] <author> Jain A. and Dubes R., </author> <title> "Algorithms for clustering data", </title> <publisher> Prentice Hall, </publisher> <address> NJ, </address> <year> 1988. </year>
Reference-contexts: Among the available pairwise clustering techniques are agglomerative algorithms (such as single link or complete link), methods of connected components and mutual neighborhoods, methods of graph cuts, stochastic methods and nonparametric density estimation methods <ref> [14, 15, 19, 23, 36, 48] </ref>. In our work we use an algorithm which is based on a physical magnetic model [7]. Note that the problem of clustering is ill posed, and different techniques are suitable for different problems.
Reference: [24] <author> Kamger-Parsi B., Margalit M. and Rozenfeld A., </author> <title> "Matching general polygonal arcs", CVGIP: </title> <booktitle> image understanding 53, </booktitle> <pages> 227-234, </pages> <year> 1991. </year>
Reference-contexts: The idea behind proximity matching methods is to search for the best matching while permitting the rotation, translation and scaling (to be called alignment transformation) of each curve, such that the distances between matched key points are minimized <ref> [4, 22, 24, 43] </ref>. Consequently these methods are rather slow; moreover, if scaling is permitted an erroneous shrinking of one feature set may result, followed by the matching of the entire set with a small number of features from the other set. <p> Dense matching methods provide measures of dissimilarity like the "elastic distance" [5, 13, 34], proximity matching methods use the (average) residual distance between matched points <ref> [1, 24, 47] </ref>, spread primitive matching methods make use of a similar measure (but residual distances are defined between shape primitives which are not necessarily points) [10, 27], and finally syntactic matching methods provide the "edit distance" [17, 33, 39, 42] as a dissimilarity measure.
Reference: [25] <author> Koch M. and Kashyap R., </author> <title> "Using polygons to recognize and locate partially occluded objects", </title> <type> PAMI 9, </type> <pages> 483-494, </pages> <year> 1987. </year>
Reference-contexts: Here, compatibility means an agreement on the induced coordinate transformation, and a few techniques exist to find the largest set of mutually compatible matches (e.g., clustering in Hough space [37], geometrical hashing [26], and clique finding in an association graph <ref> [8, 25, 12] </ref>). For our purpose of matching complex outlines, it is advantageous to use the natural order of primitives and there is no need to solve the more general problem, which requires additional computational cost.
Reference: [26] <author> Lamdan Y., Schwartz J. and Wolfson H., </author> <title> "Affine invariant model based object recognition", </title> <journal> IEEE trans. on Robotics and Automation 6, </journal> <pages> 578-589, </pages> <year> 1990. </year>
Reference-contexts: Here, compatibility means an agreement on the induced coordinate transformation, and a few techniques exist to find the largest set of mutually compatible matches (e.g., clustering in Hough space [37], geometrical hashing <ref> [26] </ref>, and clique finding in an association graph [8, 25, 12]). For our purpose of matching complex outlines, it is advantageous to use the natural order of primitives and there is no need to solve the more general problem, which requires additional computational cost.
Reference: [27] <author> Li S., </author> <title> "Matching: invariant to translations, rotations and scale changes", </title> <booktitle> Pattern Recognition 25, </booktitle> <pages> 583-594, </pages> <year> 1992. </year>
Reference-contexts: But in the absence of any ordering information (like in stereo matching of many small fragments of curves), the matching algorithm may be called "spread primitive matching". In this category we find algorithms that seek isomorphism between attributed relational graphs <ref> [6, 27, 10] </ref>, and algorithms that look for the largest set of mutually compatible matches. <p> Local and scale invariant matching methods usually replace ` by the normalized length `=` 0 , defining the scale similarity function as S ` (`=` 0 ; ` 0 =` 0 0 ). For example, the ratio between normalized lengths `=` 0 0 is used in <ref> [28, 27] </ref> (with global normalization the difference j`=L` 0 =L 0 j can be used [42, 38]). The ratio between normalized lengths may be viewed as the ratio between the relative scale c = `=` 0 and the reference relative scale c 0 = ` 0 =` 0 0 . <p> We are familiar with only one other definition of a symmetric, bounded and scale invariant measure for segment length similarity <ref> [27] </ref>. However, their matching algorithm is not syntactic and is very dif ferent from ours. In addition, there is an important qualitative difference between the two definitions (see figure 2), where our measure is more suitable for flexible matching. <p> Left: The binary relation used by Li <ref> [27] </ref> to measure scale similarity is exp (jlog (c=c0)j=) with = 0:5. Right: Our measure function (equation 1) is not sensitive to small scale changes, since it is flat near the line c = c 0 . even if there is a small discrepancy between their orientations. <p> We note that a linear measure has been widely used by others [38, 39, 28, 10]. The non linear measure used by <ref> [27] </ref> differs from ours in exactly the same way as discussed above concerning length. <p> matching methods provide measures of dissimilarity like the "elastic distance" [5, 13, 34], proximity matching methods use the (average) residual distance between matched points [1, 24, 47], spread primitive matching methods make use of a similar measure (but residual distances are defined between shape primitives which are not necessarily points) <ref> [10, 27] </ref>, and finally syntactic matching methods provide the "edit distance" [17, 33, 39, 42] as a dissimilarity measure.
Reference: [28] <author> Liu H. and Srinath M., </author> <title> "Partial shape classification using contour matching in distance transformation", </title> <type> PAMI 12, </type> <pages> 1072-1079, </pages> <year> 1990. </year>
Reference-contexts: There are no syntactic algorithms available which satisfactorily solve both of these problems. If invariant attributes are used, the first problem is immediately addressed, but then the resolution problem either remains unsolved <ref> [1, 17, 28] </ref> or it is addressed by constructing for each curve a cascade of representations at different scales [3, 32, 42]. Moreover, invariant attributes are either non-local (e.g., length that is measured in units of the total curve length), or they are non-interruptible (see discussion in section 2.2.5). <p> Local and scale invariant matching methods usually replace ` by the normalized length `=` 0 , defining the scale similarity function as S ` (`=` 0 ; ` 0 =` 0 0 ). For example, the ratio between normalized lengths `=` 0 0 is used in <ref> [28, 27] </ref> (with global normalization the difference j`=L` 0 =L 0 j can be used [42, 38]). The ratio between normalized lengths may be viewed as the ratio between the relative scale c = `=` 0 and the reference relative scale c 0 = ` 0 =` 0 0 . <p> We note that a linear measure has been widely used by others <ref> [38, 39, 28, 10] </ref>. The non linear measure used by [27] differs from ours in exactly the same way as discussed above concerning length. <p> The benefit of using invariant attributes is efficiency. The drawback is that invariant attributes cannot be smoothed by merging, and they are either non local or non interruptible. For example, in <ref> [28] </ref> the orientation of a line segment is measured with respect to its successor, hence the opening of a gap between segments introduces ambiguity into the representation (see figure 8). In [17] the attributes which describe curve fragments are Fourier coefficients, a measure called "sphericity" in [1].
Reference: [29] <author> Lu C. and Dunham J., </author> <title> "Shape matching using polygon approximation and dynamic alignment", </title> <type> PRL 14, </type> <pages> 945-949, </pages> <year> 1993. </year>
Reference-contexts: Moreover, we claim in section 3.1 that proximity matching is not adequate for weakly similar curves. As an alternative to the alignment transformation, features may be mapped to an intrinsic invariant coordinate frame <ref> [29, 34, 35] </ref>; the drawback of this approach is that it is global, as the entire curve is needed to correctly compute the mapping.
Reference: [30] <author> Marzal A. and Vidal E., </author> <title> "Computation of normalized edit distance and applications", </title> <type> PAMI 15, </type> <pages> 926-932, </pages> <year> 1993. </year>
Reference-contexts: Hence, many syntactical matching methods are inspired by efficient and well known string comparison algorithms, which use edit operations (substitution, deletion and insertion) to transform one string to the other <ref> [44, 30, 18] </ref>. The pattern recognition problem is different from the string matching problem in two major aspects, however: first, in pattern recognition invariance to certain geometrical transformations is desired; second, a resolution degradation (or smoothing) may create a completely different list of elements in the syntactical representation. <p> The matrix is symmetric with vanishing diagonal elements, but the triangle inequality in not necessarily obeyed. (This would also be the case had we used the generalized short version in Proc. of IEEE Conf. on Computer Vision & Pattern Recognition, June 1998 14 Hausdorff distance or the normalized edit distance <ref> [30] </ref>) 8 . The dissimilarity data obtained from comparing silhouettes of three dimensional objects viewed from different orientations seems to posses a large degree of "chaining effect", where related images are not necessarily similar, but they are connected through a chain of images that are similar to each other.
Reference: [31] <author> McConnell R., Kwok R., Curlander J., Kober W. and Pang S., </author> <title> "-S Correlation and dynamic time warping: two methods for tracking ice floes in SAR images", </title> <journal> IEEE trans. on geoscience and remote sensing 29, </journal> <pages> 1004-1012, </pages> <year> 1991. </year>
Reference-contexts: Dense matching is usually formulated as a parameterization problem, with some cost function to be minimized. The cost might be defined as the "elastic energy" needed to transform one curve to the other [5, 9, 11], but other alternatives exist <ref> [2, 16, 13, 31] </ref>. The main drawbacks of these methods are their high computational complexity (which is reduced significantly if only key points are matched), and the fact that none of them is invariant under both 2D rotation and scaling.
Reference: [32] <author> Mokhtarian F. and Mackworth A., </author> <title> "Scale-based description and recognition of planar curves and two-dimensional shapes", </title> <type> PAMI 8, </type> <pages> 34-44, </pages> <year> 1986. </year>
Reference-contexts: If invariant attributes are used, the first problem is immediately addressed, but then the resolution problem either remains unsolved [1, 17, 28] or it is addressed by constructing for each curve a cascade of representations at different scales <ref> [3, 32, 42] </ref>. Moreover, invariant attributes are either non-local (e.g., length that is measured in units of the total curve length), or they are non-interruptible (see discussion in section 2.2.5).
Reference: [33] <author> Rocha J. and Pavlidis T. </author> <title> "A shape analysis model with applications to a character recognition system", </title> <type> PAMI 16, </type> <pages> 393-404, </pages> <year> 1994. </year>
Reference-contexts: Moreover, invariant attributes are either non-local (e.g., length that is measured in units of the total curve length), or they are non-interruptible (see discussion in section 2.2.5). Using variant attributes is less efficient, but provides the possibility to define a merge operator which can handle noise <ref> [33, 38, 39] </ref>, and might be useful (if correctly defined) in handling resolution change. However, the methods using variant attributes could not ensure rotation and scale invariance. <p> Finally, the combined similarity measure is de fined as the weighted sum: S = w 1 S ` + S The weight w 1 (which equals 1 in all our experiments) controls the decoupling of scale and orientation similarity. In <ref> [33] </ref> a coupled measure is used: the segments are superimposed at one end, and their dissimilarity is proportional to the distance between their other ends. <p> However, this measure is too complicated for our case, and it has the additional drawback that it is sensitive to the arbitrary reference scale and orientation (in the character recognition task of <ref> [33] </ref> it is assumed that char acters are of the same scale and properly aligned). 2.2.2 Syntactic operations: gaps and merges The goal of a classical string edit algorithm is to find a sequence of elementary edit operations, which transform one string into the other at a minimal cost. <p> 13, 34], proximity matching methods use the (average) residual distance between matched points [1, 24, 47], spread primitive matching methods make use of a similar measure (but residual distances are defined between shape primitives which are not necessarily points) [10, 27], and finally syntactic matching methods provide the "edit distance" <ref> [17, 33, 39, 42] </ref> as a dissimilarity measure. As we mentioned in section 2.1, dense matching methods are not efficient enough for our purpose which involve the comparison of thousands of complex curves under arbitrary changes of orientation and scale.
Reference: [34] <author> Sclaroff S. and Pentland A., </author> <title> "Modal matching for correspondence and recognition", </title> <type> PAMI 17, </type> <pages> 545-561, </pages> <year> 1995. </year>
Reference-contexts: Moreover, we claim in section 3.1 that proximity matching is not adequate for weakly similar curves. As an alternative to the alignment transformation, features may be mapped to an intrinsic invariant coordinate frame <ref> [29, 34, 35] </ref>; the drawback of this approach is that it is global, as the entire curve is needed to correctly compute the mapping. <p> More specifically, let us follow the classification of methods proposed in sec tion 2.1: We distinguished between dense matching and feature matching, and divided feature matching into three categories: proximity matching, spread primitive matching, and syntactic matching. Dense matching methods provide measures of dissimilarity like the "elastic distance" <ref> [5, 13, 34] </ref>, proximity matching methods use the (average) residual distance between matched points [1, 24, 47], spread primitive matching methods make use of a similar measure (but residual distances are defined between shape primitives which are not necessarily points) [10, 27], and finally syntactic matching methods provide the "edit distance"
Reference: [35] <author> Shapiro L. and Brady M., </author> <title> "Feature based correspondence: an eigenvector approach", </title> <booktitle> Image and vision computing 10, </booktitle> <pages> 283-288, </pages> <year> 1992. </year>
Reference-contexts: Moreover, we claim in section 3.1 that proximity matching is not adequate for weakly similar curves. As an alternative to the alignment transformation, features may be mapped to an intrinsic invariant coordinate frame <ref> [29, 34, 35] </ref>; the drawback of this approach is that it is global, as the entire curve is needed to correctly compute the mapping.
Reference: [36] <author> Shi J. and Malik J., </author> <title> "Normalized cuts and image segmentation", </title> <booktitle> Proc. of CVPR, </booktitle> <pages> 731-737, </pages> <year> 1997. </year>
Reference-contexts: Among the available pairwise clustering techniques are agglomerative algorithms (such as single link or complete link), methods of connected components and mutual neighborhoods, methods of graph cuts, stochastic methods and nonparametric density estimation methods <ref> [14, 15, 19, 23, 36, 48] </ref>. In our work we use an algorithm which is based on a physical magnetic model [7]. Note that the problem of clustering is ill posed, and different techniques are suitable for different problems.
Reference: [37] <author> Stockman G., Kopstein S. and Benett S., </author> <title> "Matching images to models for registration and object detection via clustering", </title> <type> PAMI 4, </type> <pages> 229-241, </pages> <year> 1982. </year>
Reference-contexts: Here, compatibility means an agreement on the induced coordinate transformation, and a few techniques exist to find the largest set of mutually compatible matches (e.g., clustering in Hough space <ref> [37] </ref>, geometrical hashing [26], and clique finding in an association graph [8, 25, 12]). For our purpose of matching complex outlines, it is advantageous to use the natural order of primitives and there is no need to solve the more general problem, which requires additional computational cost.
Reference: [38] <author> Tsai W. and Yu S., </author> <title> "Attributed string matching with merging for shape recognition", </title> <type> PAMI 7, </type> <pages> 453-462, </pages> <year> 1985. </year>
Reference-contexts: Moreover, invariant attributes are either non-local (e.g., length that is measured in units of the total curve length), or they are non-interruptible (see discussion in section 2.2.5). Using variant attributes is less efficient, but provides the possibility to define a merge operator which can handle noise <ref> [33, 38, 39] </ref>, and might be useful (if correctly defined) in handling resolution change. However, the methods using variant attributes could not ensure rotation and scale invariance. <p> For example, the ratio between normalized lengths `=` 0 0 is used in [28, 27] (with global normalization the difference j`=L` 0 =L 0 j can be used <ref> [42, 38] </ref>). The ratio between normalized lengths may be viewed as the ratio between the relative scale c = `=` 0 and the reference relative scale c 0 = ` 0 =` 0 0 . We define a different measure of similarity between the two scales. <p> We note that a linear measure has been widely used by others <ref> [38, 39, 28, 10] </ref>. The non linear measure used by [27] differs from ours in exactly the same way as discussed above concerning length. <p> The algorithm cannot handle occlusions or partial distortions, and massive preprocessing is required to prepare the cascade Merging was defined as an operation on attributes by <ref> [38] </ref>, who also applied the technique to Chinese character recognition [39]. Their algorithm suffers from some drawbacks concerning invariance and locality 2 ; below we concentrate on their merging mechanism, and compare it to our own. <p> Assume that the two line segments characterized by (` 1 ; 1 ) and (` 2 ; 2 ) are to be merged into one segment (`; ). In <ref> [38] </ref> ` = ` 1 + ` 2 , and is the weighted average between 1 and 2 , with weights ` 1 =(` 1 + ` 2 ) and ` 2 =(` 1 + ` 2 ), and with the necessary cyclic corrections 3 . <p> If the line segments are viewed as vectors oriented in the direction of propagation along the contour, then the merging operation of any number of segments is simply their vectorial sum. 4 . of syntactical representations for each curve, with consistent fragment hierarchy. 2 The primitives used by <ref> [38] </ref> are line segments, the attributes are relative length (with respect to the total length) and absolute orientation (with respect to the first segment). <p> A coarser approximation is obtained. (c) Merging according to Tsai and Yu <ref> [38] </ref>. The new polygon is not a good approximation. Compare the polygonal approximation after merging with the polygon that would have been obtained had the curve been first smoothed and then approximated. The two polygons are not identical, since smoothing may cause displacement of features (vertices).
Reference: [39] <author> Tsay Y. and Tsai W., </author> <title> "Attributed string matching by split and merge for on-line chinese character recognition", </title> <type> PAMI 15, </type> <pages> 180-185, </pages> <year> 1993. </year>
Reference-contexts: Moreover, invariant attributes are either non-local (e.g., length that is measured in units of the total curve length), or they are non-interruptible (see discussion in section 2.2.5). Using variant attributes is less efficient, but provides the possibility to define a merge operator which can handle noise <ref> [33, 38, 39] </ref>, and might be useful (if correctly defined) in handling resolution change. However, the methods using variant attributes could not ensure rotation and scale invariance. <p> We note that a linear measure has been widely used by others <ref> [38, 39, 28, 10] </ref>. The non linear measure used by [27] differs from ours in exactly the same way as discussed above concerning length. <p> The algorithm cannot handle occlusions or partial distortions, and massive preprocessing is required to prepare the cascade Merging was defined as an operation on attributes by [38], who also applied the technique to Chinese character recognition <ref> [39] </ref>. Their algorithm suffers from some drawbacks concerning invariance and locality 2 ; below we concentrate on their merging mechanism, and compare it to our own. <p> 13, 34], proximity matching methods use the (average) residual distance between matched points [1, 24, 47], spread primitive matching methods make use of a similar measure (but residual distances are defined between shape primitives which are not necessarily points) [10, 27], and finally syntactic matching methods provide the "edit distance" <ref> [17, 33, 39, 42] </ref> as a dissimilarity measure. As we mentioned in section 2.1, dense matching methods are not efficient enough for our purpose which involve the comparison of thousands of complex curves under arbitrary changes of orientation and scale.
Reference: [40] <author> Tversky A., </author> <title> "Features of similarity", </title> <journal> Psychological Review 84, </journal> <pages> 327-352, </pages> <year> 1977. </year>
Reference-contexts: over all interacting pairs of images, and J ij is a positive interaction strength between image i and image j which decays with 8 Note that the violation of metric properties is known to exist in the function underlying our human notion of similarity between both semantic and perceptual stimuli <ref> [40] </ref>. 9 Agglomerative clustering of N points starts with N clusters and merges at each step the closest two clusters. The single link version defines the distance between clusters as the minimal distance between two of their members.
Reference: [41] <author> N. Ueda and S. Suzuki, </author> <title> "Automatic shape model acquisition using multiscale segment matching", </title> <booktitle> Proc. of ICPR, </booktitle> <year> 1990, </year> <pages> 897-902. </pages>
Reference: [42] <author> Ueda N. and Suzuki S., </author> <title> "Learning visual models from shape contours using multiscale covex/concave structure matching", </title> <type> PAMI 15, </type> <pages> 337-352, </pages> <year> 1993. </year>
Reference-contexts: If invariant attributes are used, the first problem is immediately addressed, but then the resolution problem either remains unsolved [1, 17, 28] or it is addressed by constructing for each curve a cascade of representations at different scales <ref> [3, 32, 42] </ref>. Moreover, invariant attributes are either non-local (e.g., length that is measured in units of the total curve length), or they are non-interruptible (see discussion in section 2.2.5). <p> For example, the ratio between normalized lengths `=` 0 0 is used in [28, 27] (with global normalization the difference j`=L` 0 =L 0 j can be used <ref> [42, 38] </ref>). The ratio between normalized lengths may be viewed as the ratio between the relative scale c = `=` 0 and the reference relative scale c 0 = ` 0 =` 0 0 . We define a different measure of similarity between the two scales. <p> We use segment merging as the syntactic homologue of curve smoothing, accomplishing noise reduction by local resolution degradation. Segment merging, if defined correctly, should simplify a contour representation by changing its scale from fine to coarse. A similar approach was taken in <ref> [42] </ref>, but their use of invariant attributes made it impossible to realize the merge operator as an operation on attributes. Specifically, there is no analytical relation between the attributes being merged to the attributes of the new primitive. <p> Instead, a cascade of alternative representations was used, each one obtained by a different Gaussian smoothing of the two dimensional curve; a primitive sequence is replaced by its "ancestor" in the scale space description 1 . 1 The primitive elements used in <ref> [42] </ref> are convex and concave fragments, which are bounded by inflection points. The attributes are the fragment length divided by total curve length (a non-local attribute), and the accumulated tangent angle along the fragment (a non-interruptible attribute). <p> Both are invariant attributes, but non-interruptible 6 . Moreover, it seems to be impossible to find operators on invariant attributes that are equivalent to smoothing in real space. Instead, a cascade of different scale representations must be used <ref> [42] </ref>, where 6 The Fourier coefficients are normalized individually, which means that if every fragment undergoes a different rigid or scaling transformation, the representation remains unchanged. The sphericity representation behaves in the same way. <p> 13, 34], proximity matching methods use the (average) residual distance between matched points [1, 24, 47], spread primitive matching methods make use of a similar measure (but residual distances are defined between shape primitives which are not necessarily points) [10, 27], and finally syntactic matching methods provide the "edit distance" <ref> [17, 33, 39, 42] </ref> as a dissimilarity measure. As we mentioned in section 2.1, dense matching methods are not efficient enough for our purpose which involve the comparison of thousands of complex curves under arbitrary changes of orientation and scale.
Reference: [43] <author> Umeyama S., </author> <title> "Parameterized point pattern matching and its application to recognition of object families", </title> <type> PAMI 15, </type> <pages> 136-144, </pages> <year> 1993. </year>
Reference-contexts: The idea behind proximity matching methods is to search for the best matching while permitting the rotation, translation and scaling (to be called alignment transformation) of each curve, such that the distances between matched key points are minimized <ref> [4, 22, 24, 43] </ref>. Consequently these methods are rather slow; moreover, if scaling is permitted an erroneous shrinking of one feature set may result, followed by the matching of the entire set with a small number of features from the other set.
Reference: [44] <author> Wang Y. and Pavlidis T., </author> <title> "Optimal correspondence of string subsequences", </title> <type> PAMI 12, </type> <pages> 1080-1086, </pages> <year> 1990. </year>
Reference-contexts: Hence, many syntactical matching methods are inspired by efficient and well known string comparison algorithms, which use edit operations (substitution, deletion and insertion) to transform one string to the other <ref> [44, 30, 18] </ref>. The pattern recognition problem is different from the string matching problem in two major aspects, however: first, in pattern recognition invariance to certain geometrical transformations is desired; second, a resolution degradation (or smoothing) may create a completely different list of elements in the syntactical representation.
Reference: [45] <author> Wang S. and Swendsen R., </author> <title> "Cluster Monte Carlo algorithms", </title> <journal> Physica A 167, </journal> <pages> 565-579, </pages> <year> 1990. </year>
Reference-contexts: The essence of the algorithm can be understood as replacing the dissimilarities between images by the time correlations that are measured in the analog system. The measurement of these correlations is done by an efficient Monte Carlo simulation method <ref> [45] </ref>. Then, points which are highly correlated are grouped together into one cluster. If there is hierarchical structure in the data, the scenario described above repeats itself at higher temperatures.
Reference: [46] <author> Weinshall D. and Werman M., </author> <title> "On View Likelihood and Stability", </title> <type> PAMI 19, </type> <pages> 97-108, </pages> <year> 1997. </year>
Reference-contexts: Note that preservation of shape under change of viewpoint is a quality that defines "canonical" or "stable" views. Stable images of 3D objects were proposed as the representative images in an appearance based approach to object representation <ref> [46] </ref>. The last example (figure 12) shows matching of human limbs at different body configurations.
Reference: [47] <author> Werman M. and Weinshall D., </author> <title> "Similarity and Affine Invariant Distance Between Point Sets", </title> <type> PAMI 17, </type> <pages> 810-814, </pages> <year> 1995. </year>
Reference-contexts: Dense matching methods provide measures of dissimilarity like the "elastic distance" [5, 13, 34], proximity matching methods use the (average) residual distance between matched points <ref> [1, 24, 47] </ref>, spread primitive matching methods make use of a similar measure (but residual distances are defined between shape primitives which are not necessarily points) [10, 27], and finally syntactic matching methods provide the "edit distance" [17, 33, 39, 42] as a dissimilarity measure.
Reference: [48] <author> Wu Z. and Leahy R., </author> <title> "An optimal graph theoretic approach to data clustering: theory and its application to image segmentation", </title> <type> PAMI 15, </type> <pages> 1101-1113, </pages> <year> 1993. </year>
Reference-contexts: Among the available pairwise clustering techniques are agglomerative algorithms (such as single link or complete link), methods of connected components and mutual neighborhoods, methods of graph cuts, stochastic methods and nonparametric density estimation methods <ref> [14, 15, 19, 23, 36, 48] </ref>. In our work we use an algorithm which is based on a physical magnetic model [7]. Note that the problem of clustering is ill posed, and different techniques are suitable for different problems.
References-found: 48

