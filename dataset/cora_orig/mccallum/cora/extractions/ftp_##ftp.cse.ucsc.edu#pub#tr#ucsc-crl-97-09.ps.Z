URL: ftp://ftp.cse.ucsc.edu/pub/tr/ucsc-crl-97-09.ps.Z
Refering-URL: ftp://ftp.cse.ucsc.edu/pub/tr/README.html
Root-URL: http://www.cse.ucsc.edu
Title: Hybrid Spectral/Iterative Partitioning  
Author: Jason Y. Zien, Pak K. Chan, Martine Schlag 
Address: Santa Cruz, CA 95064 USA  
Affiliation: Baskin Center for Computer Engineering Computer Sciences University of California, Santa Cruz  
Date: April 29, 1997  
Pubnum: UCSC-CRL-97-09  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> C. J. Alpert and A. B. Kahng. </author> <title> Geometric embeddings for faster (and better) multi-way netlist partitioning. </title> <type> Technical Report CSD TR-920052, </type> <institution> UCLA, </institution> <month> October </month> <year> 1992. </year>
Reference-contexts: Another approach is to view each row of X d as a coordinate for the vertex. The partitioning problem can then be solved by using geometric clustering algorithms <ref> [1] </ref>. Another view is to think of each row of X d as a d-dimensional vector.
Reference: [2] <author> C. J. Alpert and A. B. Kahng. </author> <title> Geometric embeddings for faster and better multi-way netlist partitioning. </title> <booktitle> In Proc. ACM/IEEE Design Automation Conference, </booktitle> <pages> pages 743-748, </pages> <year> 1993. </year>
Reference-contexts: With clique expansion, the primary factor affecting the outcome is the choice of edge weights. Some possibilities include 1 d1 , 2 1:5 [18] which is optimized for placement, or 4 d (d1) <ref> [2] </ref> which is optimized for partitioning, or one which is optimized for k-way partitioning [21]. 6.2 Star Graph We develop a new hypergraph to graph conversion model, based on using the star graph (Figure 6.1c). The first use the star expansion in spectral partitioning was reported in [11].
Reference: [3] <author> C. J. Alpert and So-Zen Yao. </author> <title> Spectral partitioning: The more eigenvectors, the better. </title> <booktitle> In Proceedings of the 32nd ACM/IEEE Design Automation Conference, </booktitle> <month> June </month> <year> 1995. </year>
Reference-contexts: Spectral Partitioning and Vectors 3 Spectral Partitioning and Vectors In this section, we will give a brief overview of spectral partitioning. Since much of this theory has been published in the past, we will not repeat it here. The interested reader may refer to other papers <ref> [24, 23, 3, 18, 44] </ref> for more details. Assume we are given a graph with n vertices, and we wish to find k partitions of this graph. Let v i be vertex i and deg (v i ) be the degree of v i . <p> Partitions can then be formed by grouping vertices together based on the angle between vectors [10] or by scaling X d and optimizing for the maximum sum vector partitioning cost (discussed in the next section) <ref> [3] </ref>. 3. <p> In maximum sum vector partitioning, the scaled matrix of eigenvectors is represented by V d = M X d p (H d fl d ) where X d and fl d satisfy QX d = M X d fl d . This is a generalization of the work of <ref> [3, 18] </ref> who used V d = X d p where X d and fl d satisfy QX d = X d fl d . Let the vector i, 1 i n be row i of V d . <p> We will derive a new proof of the maximum sum vector partitioning problem. Our proof is simpler than the proof in <ref> [3] </ref> and also more general, because it takes vertex sizes into account. <p> Multi-way Partitioning Past work has focused on using the second eigenvector for generating two-way partitions [36, 22]. For example, in the EIG1 algorithm [23], each possible partitioning of vertices on the line was checked to find the best ratio-cut cost solution (Figure 5.4). Alpert and Yao <ref> [3] </ref> extended the concept to multiple dimensions and multiple eigenvectors by generating linear orderings using space-filling curves. Our approach lies somewhere between those two approaches. Our focus is to solve the k-way partitioning problem for small values of k, such as 2,3, or 4. <p> For star graphs, we introduce a hyperedge which is connected to an arbitrary vertex in each of the components. Another approach to handling disconnected graphs is to use higher-order eigenvectors. Alpert <ref> [3] </ref> used up to ten eigenvectors in creating partitions. Shau [39] used different pairs of eigenvectors (1st and 2nd; 2nd and 3rd; 1st and 3rd) in his experiments. Pairwise selection of higher-order eigenvectors would be easy to implement in our partitioner, if necessary.
Reference: [4] <author> Charles J. Alpert, Lars W. Hagen, and Andrew B. Kahng. </author> <title> A hybrid multilevel/genetic approach for circuit partitioning. </title> <booktitle> In Proceedings of the ACM/SIGDA Physical Design Workshop, </booktitle> <pages> pages 100-105, </pages> <year> 1996. </year>
Reference-contexts: In [14], they developed a clustering algorithm by collapsing cliques into supernodes, and then running the KLFM algorithm on the contracted graph. These methods were subsequently improved upon by using multiple levels of contraction (instead of just one level), and iterative improvement at each level of the hierarchy <ref> [26, 28, 27, 4, 44] </ref>. Current state-of-the-art partitioners use the multi-level (hierarchical) approach as shown in Figure 2.3. A hypergraph is reduced in size by pre-clustering nodes or matching nodes together (Figure 2.2). A matching of a graph is a set of edges whose vertices are non-overlapping.
Reference: [5] <author> Charles J. Alpert, Jen-Hsin Huang, and Andrew B. Kahng. </author> <title> Multilevel circuit partitioning. </title> <booktitle> In 34th Design Automation Conference, </booktitle> <volume> volume 34, </volume> <year> 1997. </year>
Reference-contexts: A new k-way improvement method which we call Rotary KLFM. 3. The (current) best known 3-way and 4-way hypergraph partitioning results. Our hybrid algorithm produces an average improvement of 27.9% over GFM [33] for 3-way partitions, 48.7% improvement over GFM for 4-way partitions, and 67.5% improvement over ML F <ref> [5] </ref> for 4-way partitions. 2 Background 2.1 State-of-the-Art Partitioners The classic Kernighan-Lin/Fiduccia-Mattheyses (KLFM) algorithm even today is used as the basis for most modern iterative partitioning algorithms. This algorithm combines a greedy hill-climbing approach with a simple backtracking step, as shown in Figure 2.1. <p> Many researchers have only used one level of contraction to perform partitioning [19, 13, 14], or a fixed number of levels, such as three [44]. Other researchers have chosen to contract the graph until the number of nodes in the graph reaches a target size, such as 35 nodes <ref> [5] </ref>, 100 nodes [28] or 200 nodes [26]. For four-way partitioning, contraction was limited to 100 nodes in [5]. <p> Other researchers have chosen to contract the graph until the number of nodes in the graph reaches a target size, such as 35 nodes <ref> [5] </ref>, 100 nodes [28] or 200 nodes [26]. For four-way partitioning, contraction was limited to 100 nodes in [5]. We ran some benchmarks using the graphs p1 ga, p2 ga, t2, t3, t4, t5, t6 for the unit-size and actual-size vertex tests, with the geometric mean of the total number of cuts shown shown in Table 6.4 and 6.5. <p> Results are 2x the total number of hyperedges cut using unit-size vertices. 7.4 Comparison against ML F and GORDIAN We compared our hybrid algorithm to the ML F <ref> [5] </ref> and GORDIAN algorithms [30] as reported in [5]. We also report the results of our KFMC method for comparison. These tests use unit vertex sizes with a balance factor of bal = 0:1 and we used the StarF graph model. <p> Results are 2x the total number of hyperedges cut using unit-size vertices. 7.4 Comparison against ML F and GORDIAN We compared our hybrid algorithm to the ML F <ref> [5] </ref> and GORDIAN algorithms [30] as reported in [5]. We also report the results of our KFMC method for comparison. These tests use unit vertex sizes with a balance factor of bal = 0:1 and we used the StarF graph model.
Reference: [6] <author> E. R. Barnes. </author> <title> Partitioning the nodes of a graph. </title> <booktitle> Proceedings of Graph Theory with Applications to Algorithms and Computer Science, </booktitle> <pages> pages 57-72, </pages> <year> 1985. </year>
Reference-contexts: Background 1. A new hybrid spectral/iterative partitioning algorithm. This is the first algorithm that simultaneously combines iterative and spectral information in a multi-level partitioning framework. Previously, researchers have combined the two approaches by finding a solution using a spectral algorithm and then performing iterative improvement on it <ref> [6, 25, 44] </ref>. The simultaneous use of spectral and traditional gain costs was found in [11], where a single-pass constructive heuristic was used to create partitions using the weighted sum of the cut gain and a spectral cost function.
Reference: [7] <author> E.R. Barnes. </author> <title> An algorithm for partitioning the nodes of a graph. </title> <journal> SIAM Journal on Algorithm and Discrete Method, </journal> <volume> 3 </volume> <pages> 541-550, </pages> <month> December </month> <year> 1982. </year> <note> 28 References </note>
Reference-contexts: For instance, some researchers have sought to find a k-way partitioning solution by finding the binary partition assignment matrix which satisfies partitioning constraints that is closest to the n fi k eigenvector matrix X k using a transportation problem <ref> [7, 8] </ref>. Another approach is to view each row of X d as a coordinate for the vertex. The partitioning problem can then be solved by using geometric clustering algorithms [1]. Another view is to think of each row of X d as a d-dimensional vector.
Reference: [8] <author> E.R. Barnes, Anthony Vanelli, and James Q. Walker. </author> <title> A new heuristic for partitioning the nodes of a graph. </title> <journal> SIAM Journal on Algorithm and Discrete Method, </journal> <volume> 1(3) </volume> <pages> 299-305, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: For instance, some researchers have sought to find a k-way partitioning solution by finding the binary partition assignment matrix which satisfies partitioning constraints that is closest to the n fi k eigenvector matrix X k using a transportation problem <ref> [7, 8] </ref>. Another approach is to view each row of X d as a coordinate for the vertex. The partitioning problem can then be solved by using geometric clustering algorithms [1]. Another view is to think of each row of X d as a d-dimensional vector.
Reference: [9] <author> P. Bertin, D. Roncin, and J. Vuillemin. </author> <title> Programmable active memories: A performance assessment. </title> <booktitle> In 1 st International ACM/SIGDA Workshop on Field Programmable Gate Arrays, </booktitle> <address> Berkeley, CA, </address> <pages> pages 57-59. </pages> <publisher> ACM, </publisher> <month> February </month> <year> 1992. </year>
Reference-contexts: Graphs are simply hypergraphs where all hyperedges are incident upon exactly two vertices. Partitioning algorithms are useful in many areas, such as circuit placement [15] [24], minimizing communication in parallel processing simulations [42], optimizing the organization of large computer networks, and circuit implementation in field-programmable gate arrays (FPGAs) [34], <ref> [9] </ref>, [12], [40]. Since partitioning with balance constraints is NP-complete [20], we must resort to heuristics to solve the problem. 1.2 Contributions This paper describes a new multi-way, hybrid spectral/iterative, graph partitioning algorithm.
Reference: [10] <author> P. K. Chan, M. D. F. Schlag, and J. Y. Zien. </author> <title> Spectral k-way ratio-cut partitioning and clustering. </title> <journal> IEEE Trans. on CAD, </journal> <volume> 13(9) </volume> <pages> 1088-1096, </pages> <month> September </month> <year> 1994. </year>
Reference-contexts: The partitioning problem can then be solved by using geometric clustering algorithms [1]. Another view is to think of each row of X d as a d-dimensional vector. Partitions can then be formed by grouping vertices together based on the angle between vectors <ref> [10] </ref> or by scaling X d and optimizing for the maximum sum vector partitioning cost (discussed in the next section) [3]. 3.
Reference: [11] <author> Pak K. Chan, M. D. F. Schlag, and Jason Y. Zien. </author> <title> Spectral-based multiway fpga partitioning. </title> <journal> IEEE Trans. on CAD, </journal> <volume> 15(5) </volume> <pages> 554-560, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: Previously, researchers have combined the two approaches by finding a solution using a spectral algorithm and then performing iterative improvement on it [6, 25, 44]. The simultaneous use of spectral and traditional gain costs was found in <ref> [11] </ref>, where a single-pass constructive heuristic was used to create partitions using the weighted sum of the cut gain and a spectral cost function. That heuristic was only a constructive heuristic, and not used for iterative improvement. <p> The primary problem is that the EIG1 algorithm only gives one starting point. Although it may be a very good one, it is not necessarily the best one for iterative improvement. We believe that a more integrated hybrid approach can utilize the strengths of both methods. In <ref> [11] </ref>, they introduced a single-pass heuristic which constructed partitions based on the weighted sum of the edges cut and orthogonality (which was calculated using the eigenvectors of the graph). The algorithm was only used to construct partitions, and could not be used for iterative improvement. <p> The first use the star expansion in spectral partitioning was reported in <ref> [11] </ref>. Although the 6. Issues in Multi-level Spectral Partitioning 19 paper described star graphs, it did not present any significant quantitative or theoretical evaluation of the model. We derive an edge weighting function for the star graph, and we experimentally evaluate the performance of the star graph model.
Reference: [12] <author> Pak K. Chan, Martine Schlag, and Marcelo Martin. Borg: </author> <title> A reconfigurable prototyping board using field- programmable gate arrays. </title> <type> Technical Report UCSC-CRL-91-45, </type> <institution> Board of Studies in Computer Engineering, University of California at Santa Cruz, </institution> <address> Santa Cruz, CA 95064, </address> <month> November </month> <year> 1991. </year>
Reference-contexts: Partitioning algorithms are useful in many areas, such as circuit placement [15] [24], minimizing communication in parallel processing simulations [42], optimizing the organization of large computer networks, and circuit implementation in field-programmable gate arrays (FPGAs) [34], [9], <ref> [12] </ref>, [40]. Since partitioning with balance constraints is NP-complete [20], we must resort to heuristics to solve the problem. 1.2 Contributions This paper describes a new multi-way, hybrid spectral/iterative, graph partitioning algorithm.
Reference: [13] <author> Chung-Kuan Cheng and Yen-Chuen Wei. </author> <title> An improved two-way partitioning algorithm with stable performance. </title> <journal> IEEE Transactions on Computer-Aided Design, </journal> <volume> 10(12), </volume> <month> December </month> <year> 1991. </year>
Reference-contexts: Because KLFM algorithms are so sensitive to initial starting points, some researchers have sought ways to create more stable performance by using clustering and multiple levels of hierarchy. A top-down approach to finding clusters in circuits was implemented by Wei and Cheng <ref> [41, 42, 13] </ref>. They used the ratio-cut partitioning algorithm to recursively subdivide a circuit into many small clusters. The ratio-cut cost function is the ratio of edges cut over the product of the partition sizes, E c jP 1 jjP 2 j . <p> The best solutions may be precluded due to the contraction algorithm. This is offset by the fact that more levels of iterative improvement can be run when there are more hierarchical levels. Many researchers have only used one level of contraction to perform partitioning <ref> [19, 13, 14] </ref>, or a fixed number of levels, such as three [44]. Other researchers have chosen to contract the graph until the number of nodes in the graph reaches a target size, such as 35 nodes [5], 100 nodes [28] or 200 nodes [26].
Reference: [14] <author> Jason Cong and M'Lissa Smith. </author> <title> A parallel bottom-up clustering algorithm with applications to circuit partitioning in vlsi design. </title> <booktitle> In Proc. ACM/IEEE Design Automation Conference, </booktitle> <pages> pages 755-760, </pages> <year> 1993. </year>
Reference-contexts: In <ref> [14] </ref>, they developed a clustering algorithm by collapsing cliques into supernodes, and then running the KLFM algorithm on the contracted graph. <p> The best solutions may be precluded due to the contraction algorithm. This is offset by the fact that more levels of iterative improvement can be run when there are more hierarchical levels. Many researchers have only used one level of contraction to perform partitioning <ref> [19, 13, 14] </ref>, or a fixed number of levels, such as three [44]. Other researchers have chosen to contract the graph until the number of nodes in the graph reaches a target size, such as 35 nodes [5], 100 nodes [28] or 200 nodes [26].
Reference: [15] <author> Alfred E. Dunlop and Brian W. Kernighan. </author> <title> A procedure for placement of standard-cell vlsi circuits. </title> <journal> IEEE Transactions on Computer-Aided Design, </journal> <volume> 4(1) </volume> <pages> 92-98, </pages> <month> January </month> <year> 1985. </year>
Reference-contexts: Graphs are simply hypergraphs where all hyperedges are incident upon exactly two vertices. Partitioning algorithms are useful in many areas, such as circuit placement <ref> [15] </ref> [24], minimizing communication in parallel processing simulations [42], optimizing the organization of large computer networks, and circuit implementation in field-programmable gate arrays (FPGAs) [34], [9], [12], [40].
Reference: [16] <author> Shantanu Dutt and Wenyong Deng. </author> <title> Vlsi circuit partitioning by cluster-removal using iterative improvement techniques. </title> <type> Technical Report CJA-PDW96, </type> <institution> University of Minnesota, Dept. of Electrical Engineering, Minneapolis, MN, </institution> <month> Nov. </month> <year> 1995. </year>
Reference-contexts: Improvements have been made in the selection of moves by biasing clusters of neighbors to be moved in sequence (the CLIP algorithm <ref> [16] </ref>), detecting clusters [16], and breaking ties in gain by using look-ahead [31]). KLFM algorithms require a large number of random starts to obtain good partitioning solutions. <p> Improvements have been made in the selection of moves by biasing clusters of neighbors to be moved in sequence (the CLIP algorithm <ref> [16] </ref>), detecting clusters [16], and breaking ties in gain by using look-ahead [31]). KLFM algorithms require a large number of random starts to obtain good partitioning solutions. <p> With all of the above difficulties, it is no wonder that for bipartitioning with balance constraints, spectral algorithms have been found to be 4% worse than the standard KLFM algorithm and 18.8% worse than more advanced iterative partitioning algorithms <ref> [16] </ref>. What if we could combine spectral information with iterative improvement algorithms to obtain one unified method which combines the advantages of both methods? We could utilize the global information from a spectral algorithm within an iterative partitioning framework and gain the benefits of both methods. 5. <p> The spectral gain is negated when the target destination is not the same partition as the last moved vertex. This encourages groups of vertices to move to the same target destination in connected groups, similar to the FM-CLIP algorithm <ref> [16] </ref>. When ff = 1, and fi = 0, our algorithm behaves like the standard KLFM algorithm. When fi is greater than 0, then the spectral gain information is used to influence the selection of the vertices. We experimented with two methods of incorporating spectral information.
Reference: [17] <author> C. M. Fiduccia and R. M. Mattheyses. </author> <title> A linear-time heuristic for improving network partitions. </title> <booktitle> In Proceedings of the 19th Design Automation Conference, </booktitle> <pages> pages 175-181. </pages> <publisher> ACM, </publisher> <year> 1982. </year>
Reference-contexts: In contrast, our current work provides a much more tightly coupled integration of spectral and iterative improvement methods. The main contributions of our work include the use of circular orderings to generate multiple initial partitions, using spectral information within a Kernighan-Lin/Fiduccia-Mattheyses iterative improvement algorithm <ref> [29, 17] </ref> to break ties in gain, and using spectral information to break out of local minima which may trap standard iterative improvement algorithms. 2. A new k-way improvement method which we call Rotary KLFM. 3. The (current) best known 3-way and 4-way hypergraph partitioning results.
Reference: [18] <author> Jonatahan Alexander Frankle. </author> <title> Circuit placement methods using multiple eigenvectors and linear probe techniques. </title> <type> Technical Report UCB/ERL M87/32, </type> <institution> University of California, Berkeley, Electronics Research Laboratory, Berkeley, </institution> <address> CA, </address> <month> May </month> <year> 1987. </year> <type> Ph.D. Dissertation. </type>
Reference-contexts: Spectral Partitioning and Vectors 3 Spectral Partitioning and Vectors In this section, we will give a brief overview of spectral partitioning. Since much of this theory has been published in the past, we will not repeat it here. The interested reader may refer to other papers <ref> [24, 23, 3, 18, 44] </ref> for more details. Assume we are given a graph with n vertices, and we wish to find k partitions of this graph. Let v i be vertex i and deg (v i ) be the degree of v i . <p> A spreading constraint, x T x = 1 is used to spread the vertices out. The trivial solution, where all vertices are placed at a single point, corresponds to the eigenvector associated with the smallest eigenvalue, is often ignored. Many researchers have used the second eigenvector to form partitions <ref> [18, 36, 23] </ref>. A variation of this which takes vertex sizes into account was proposed in [44]. Different researchers have chosen to use different numbers of eigenvectors in creating partitions. <p> In maximum sum vector partitioning, the scaled matrix of eigenvectors is represented by V d = M X d p (H d fl d ) where X d and fl d satisfy QX d = M X d fl d . This is a generalization of the work of <ref> [3, 18] </ref> who used V d = X d p where X d and fl d satisfy QX d = X d fl d . Let the vector i, 1 i n be row i of V d . <p> More general methods for searching for solutions in a multi-dimensional solution space using vector probes were described in <ref> [18] </ref>. Since our vertices are embedded in a plane, we can systematically generate many different bipartitions using that placement. Using a planar embedding is a natural extension of [22], which used the second eigenvector to create an optimal placement of vertices on a line. <p> In clique expansion, an edge is connected between all pairs of vertices incident on a degree d hyperedge, creating a total of d (d1) 2 edges. With clique expansion, the primary factor affecting the outcome is the choice of edge weights. Some possibilities include 1 d1 , 2 1:5 <ref> [18] </ref> which is optimized for placement, or 4 d (d1) [2] which is optimized for partitioning, or one which is optimized for k-way partitioning [21]. 6.2 Star Graph We develop a new hypergraph to graph conversion model, based on using the star graph (Figure 6.1c). <p> We call this the StarD weighting model. We could alternatively optimize our weights for the quadratic placement objective function. We derive the best weighting of edges in the star graph by examining the highest and lowest cost placements along a unit span, following the same method as <ref> [18] </ref>. The extreme cases are shown in represent single vertices. The concentric circle symbol represents multiple vertices placed at the same point. Let w represent the weight of a star graph's edge, which we will calculate below.
Reference: [19] <author> Jorn Garbers, Hans Jurgen Promel, and Angelika Steger. </author> <title> Finding clusters in vlsi circuits. </title> <booktitle> In ICCAD, </booktitle> <pages> pages 520-523, </pages> <year> 1990. </year>
Reference-contexts: They created a contracted graph by collapsing each cluster into a supernode. They partitioned this contracted graph, then re-expanded it and ran their ratio-cut iterative improvement algorithm upon the expanded graph. Other researchers have tried bottom-up clustering algorithms for improving results. In <ref> [19] </ref>, they created a linear-time clustering algorithm to find well-connected clusters using graph connectivity properties. In [35], they performed clustering based on Rent's rule, and then executed the KLFM 2. <p> The best solutions may be precluded due to the contraction algorithm. This is offset by the fact that more levels of iterative improvement can be run when there are more hierarchical levels. Many researchers have only used one level of contraction to perform partitioning <ref> [19, 13, 14] </ref>, or a fixed number of levels, such as three [44]. Other researchers have chosen to contract the graph until the number of nodes in the graph reaches a target size, such as 35 nodes [5], 100 nodes [28] or 200 nodes [26].
Reference: [20] <author> Michael R. Garey and David S. Johnson. </author> <title> Computers and Intractability: A Guide to the Theory of NP-Completeness. </title> <editor> W. H. </editor> <publisher> Freeman and Company, </publisher> <address> NY, NY, </address> <year> 1979. </year>
Reference-contexts: Partitioning algorithms are useful in many areas, such as circuit placement [15] [24], minimizing communication in parallel processing simulations [42], optimizing the organization of large computer networks, and circuit implementation in field-programmable gate arrays (FPGAs) [34], [9], [12], [40]. Since partitioning with balance constraints is NP-complete <ref> [20] </ref>, we must resort to heuristics to solve the problem. 1.2 Contributions This paper describes a new multi-way, hybrid spectral/iterative, graph partitioning algorithm. We describe the theory behind our new spectral/iterative algorithm, show how to combine spectral and iterative partitioners, and present experimental results which validate our algorithm.
Reference: [21] <author> Scott W. Hadley, Brian L. Mark, and Anthony Vannelli. </author> <title> An efficient eigenvector approach for finding netlist partitions. </title> <journal> IEEE Transactions on CAD, </journal> <volume> 11(7) </volume> <pages> 885-892, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: With clique expansion, the primary factor affecting the outcome is the choice of edge weights. Some possibilities include 1 d1 , 2 1:5 [18] which is optimized for placement, or 4 d (d1) [2] which is optimized for partitioning, or one which is optimized for k-way partitioning <ref> [21] </ref>. 6.2 Star Graph We develop a new hypergraph to graph conversion model, based on using the star graph (Figure 6.1c). The first use the star expansion in spectral partitioning was reported in [11]. Although the 6.
Reference: [22] <author> Lars Hagen and Andrew Kahng. </author> <title> Fast spectral methods for ratio cut partitioning and clustering. </title> <booktitle> In Proceedings of the IEEE International Conference on Computer-Aided Design, </booktitle> <pages> pages 10-12, </pages> <year> 1991. </year>
Reference-contexts: Multi-way Partitioning Past work has focused on using the second eigenvector for generating two-way partitions <ref> [36, 22] </ref>. For example, in the EIG1 algorithm [23], each possible partitioning of vertices on the line was checked to find the best ratio-cut cost solution (Figure 5.4). Alpert and Yao [3] extended the concept to multiple dimensions and multiple eigenvectors by generating linear orderings using space-filling curves. <p> More general methods for searching for solutions in a multi-dimensional solution space using vector probes were described in [18]. Since our vertices are embedded in a plane, we can systematically generate many different bipartitions using that placement. Using a planar embedding is a natural extension of <ref> [22] </ref>, which used the second eigenvector to create an optimal placement of vertices on a line. The reason why we generate many initial partitions, rather than picking only the best one for iterative improvement is because the iterative improvement itself is very sensitive to the starting solution.
Reference: [23] <author> Lars Hagen and Andrew Kahng. </author> <title> New spectral methods for ratio cut partitioning and clustering. </title> <journal> IEEE Transactions on CAD, </journal> <volume> 11(9) </volume> <pages> 1074-1085, </pages> <month> September </month> <year> 1992. </year>
Reference-contexts: Spectral Partitioning and Vectors 3 Spectral Partitioning and Vectors In this section, we will give a brief overview of spectral partitioning. Since much of this theory has been published in the past, we will not repeat it here. The interested reader may refer to other papers <ref> [24, 23, 3, 18, 44] </ref> for more details. Assume we are given a graph with n vertices, and we wish to find k partitions of this graph. Let v i be vertex i and deg (v i ) be the degree of v i . <p> A spreading constraint, x T x = 1 is used to spread the vertices out. The trivial solution, where all vertices are placed at a single point, corresponds to the eigenvector associated with the smallest eigenvalue, is often ignored. Many researchers have used the second eigenvector to form partitions <ref> [18, 36, 23] </ref>. A variation of this which takes vertex sizes into account was proposed in [44]. Different researchers have chosen to use different numbers of eigenvectors in creating partitions. <p> Appendix A gives experimental verification of our embedding choice. 4. Hybrid Spectral/Iterative Partitioning 9 4 Hybrid Spectral/Iterative Partitioning Researchers have tried to combine spectral and iterative partitioners by using the result of the EIG1 spectral partitioner <ref> [23] </ref> as the initial partition of an iterative improvement algorithm. The results were inferior to using random starts [25]. The primary problem is that the EIG1 algorithm only gives one starting point. Although it may be a very good one, it is not necessarily the best one for iterative improvement. <p> Multi-way Partitioning Past work has focused on using the second eigenvector for generating two-way partitions [36, 22]. For example, in the EIG1 algorithm <ref> [23] </ref>, each possible partitioning of vertices on the line was checked to find the best ratio-cut cost solution (Figure 5.4). Alpert and Yao [3] extended the concept to multiple dimensions and multiple eigenvectors by generating linear orderings using space-filling curves. Our approach lies somewhere between those two approaches.
Reference: [24] <author> Kenneth M. Hall. </author> <title> An r-dimensional quadratic placement algorithm. </title> <journal> Management Sciences, </journal> <volume> 17(3) </volume> <pages> 219-229, </pages> <month> November </month> <year> 1970. </year> <institution> The Institute of Management Sciences, Providence, RI. </institution>
Reference-contexts: Graphs are simply hypergraphs where all hyperedges are incident upon exactly two vertices. Partitioning algorithms are useful in many areas, such as circuit placement [15] <ref> [24] </ref>, minimizing communication in parallel processing simulations [42], optimizing the organization of large computer networks, and circuit implementation in field-programmable gate arrays (FPGAs) [34], [9], [12], [40]. <p> Spectral Partitioning and Vectors 3 Spectral Partitioning and Vectors In this section, we will give a brief overview of spectral partitioning. Since much of this theory has been published in the past, we will not repeat it here. The interested reader may refer to other papers <ref> [24, 23, 3, 18, 44] </ref> for more details. Assume we are given a graph with n vertices, and we wish to find k partitions of this graph. Let v i be vertex i and deg (v i ) be the degree of v i . <p> Spectral partitioning is based upon using the eigenvectors associated with the smallest eigenvalues of the Laplacian, Q. The eigenvectors are actually the solution to a relaxed version of the partitioning problem, often referred to as the quadratic placement problem <ref> [24] </ref>. This relaxed problem optimizes the total sum of squared wiring distance of the nodes in a graph. For instance, the quadratic cost of a one-dimensional (linear) placement of nodes is z = 1 2 i=1 j=1 (x i x j ) 2 a i;j .
Reference: [25] <author> Scott Hauck and Gaetano Borriello. </author> <title> An evaluation of bipartitioning techniques. </title> <note> submitted to, IEEE Transactions on CAD, </note> <year> 1996. </year>
Reference-contexts: Background 1. A new hybrid spectral/iterative partitioning algorithm. This is the first algorithm that simultaneously combines iterative and spectral information in a multi-level partitioning framework. Previously, researchers have combined the two approaches by finding a solution using a spectral algorithm and then performing iterative improvement on it <ref> [6, 25, 44] </ref>. The simultaneous use of spectral and traditional gain costs was found in [11], where a single-pass constructive heuristic was used to create partitions using the weighted sum of the cut gain and a spectral cost function. <p> Hybrid Spectral/Iterative Partitioning 9 4 Hybrid Spectral/Iterative Partitioning Researchers have tried to combine spectral and iterative partitioners by using the result of the EIG1 spectral partitioner [23] as the initial partition of an iterative improvement algorithm. The results were inferior to using random starts <ref> [25] </ref>. The primary problem is that the EIG1 algorithm only gives one starting point. Although it may be a very good one, it is not necessarily the best one for iterative improvement. We believe that a more integrated hybrid approach can utilize the strengths of both methods.
Reference: [26] <author> Bruce Hendrickson and Robert Leland. </author> <title> A multilevel algorithm for partitioning graphs. </title> <type> Technical Report SAND93-1301 * UC-405, </type> <institution> Sandia National Laboratories, </institution> <address> Albuquerque, New Mexico, </address> <year> 1993. </year> <note> References 29 </note>
Reference-contexts: In [14], they developed a clustering algorithm by collapsing cliques into supernodes, and then running the KLFM algorithm on the contracted graph. These methods were subsequently improved upon by using multiple levels of contraction (instead of just one level), and iterative improvement at each level of the hierarchy <ref> [26, 28, 27, 4, 44] </ref>. Current state-of-the-art partitioners use the multi-level (hierarchical) approach as shown in Figure 2.3. A hypergraph is reduced in size by pre-clustering nodes or matching nodes together (Figure 2.2). A matching of a graph is a set of edges whose vertices are non-overlapping. <p> Another approach, which we call Extended KLFM, involves extending the gain cost function in KLFM algorithms to directly support iterative moves from any one partition to any other partition <ref> [37, 26] </ref>. There are k (k 1) possible directions of movement for vertices at each step. We propose a new k-way iterative improvement method, Rotary KLFM which lies somewhere between the two improvement methods described above. In Rotary KLFM, each partition is used in turn as the target partition. <p> Other researchers have chosen to contract the graph until the number of nodes in the graph reaches a target size, such as 35 nodes [5], 100 nodes [28] or 200 nodes <ref> [26] </ref>. For four-way partitioning, contraction was limited to 100 nodes in [5].
Reference: [27] <author> George Karypis and Vipin Kumar. </author> <title> Analysis of multilevel graph partitioning. </title> <type> Technical Report 95-037, </type> <institution> University of Minnesota, Dept. of Computer Science, </institution> <month> August </month> <year> 1995. </year>
Reference-contexts: In [14], they developed a clustering algorithm by collapsing cliques into supernodes, and then running the KLFM algorithm on the contracted graph. These methods were subsequently improved upon by using multiple levels of contraction (instead of just one level), and iterative improvement at each level of the hierarchy <ref> [26, 28, 27, 4, 44] </ref>. Current state-of-the-art partitioners use the multi-level (hierarchical) approach as shown in Figure 2.3. A hypergraph is reduced in size by pre-clustering nodes or matching nodes together (Figure 2.2). A matching of a graph is a set of edges whose vertices are non-overlapping. <p> The contraction method plays a key role in not only reducing the problem size, but also influencing the final solution. We chose to use the heavy edge matching cost function <ref> [27] </ref>. This cost function contracts the edges with the highest weights, which would be the most undesirable to cut.
Reference: [28] <author> George Karypis and Vipin Kumar. </author> <title> A fast and high quality multilevel scheme for partitioning irregular graphs. </title> <type> Technical Report 95-035, </type> <institution> University of Minnesota, Dept. of Computer Science, </institution> <month> July </month> <year> 1995. </year>
Reference-contexts: In [14], they developed a clustering algorithm by collapsing cliques into supernodes, and then running the KLFM algorithm on the contracted graph. These methods were subsequently improved upon by using multiple levels of contraction (instead of just one level), and iterative improvement at each level of the hierarchy <ref> [26, 28, 27, 4, 44] </ref>. Current state-of-the-art partitioners use the multi-level (hierarchical) approach as shown in Figure 2.3. A hypergraph is reduced in size by pre-clustering nodes or matching nodes together (Figure 2.2). A matching of a graph is a set of edges whose vertices are non-overlapping. <p> Other researchers have chosen to contract the graph until the number of nodes in the graph reaches a target size, such as 35 nodes [5], 100 nodes <ref> [28] </ref> or 200 nodes [26]. For four-way partitioning, contraction was limited to 100 nodes in [5].
Reference: [29] <author> B. W. Kernighan and S. Lin. </author> <title> An efficient heuristic procedure for partitioning graphs. </title> <journal> Bell Systems Technical Journal, </journal> <volume> 49(2) </volume> <pages> 291-307, </pages> <month> February </month> <year> 1970. </year>
Reference-contexts: In contrast, our current work provides a much more tightly coupled integration of spectral and iterative improvement methods. The main contributions of our work include the use of circular orderings to generate multiple initial partitions, using spectral information within a Kernighan-Lin/Fiduccia-Mattheyses iterative improvement algorithm <ref> [29, 17] </ref> to break ties in gain, and using spectral information to break out of local minima which may trap standard iterative improvement algorithms. 2. A new k-way improvement method which we call Rotary KLFM. 3. The (current) best known 3-way and 4-way hypergraph partitioning results. <p> We can decompose partitioning into two important phases: the generation of k initial partitions and the refinement of the solution. For iterative improvement partitioners, one obvious choice is to start with many random k-way partitions and improve upon the result. Another method makes use of an existing 2-way partitioner <ref> [29, 32] </ref>: Repeatedly apply a 2-way partitioning algorithm until the desired number of partitions is reached or constraints have been satisfied. <p> Both methods have the consequence that the early partitionings may adversely affect the quality of later partitions. Once k partitions have been created, iterative improvement can be used to refine the solution. Kernighan and Lin <ref> [29] </ref> suggested performing 2-way iterative improvement to each of the k (k1) pairs of partitions (we call this Pairwise KLFM).
Reference: [30] <author> J. M. Kleinhans, G. Sigl, F. M. Johannes, and K. J. Antreich. Gordian: </author> <title> Vlsi placement by quadratic programming and slicing optimization. </title> <journal> IEEE Transactions on CAD, </journal> <volume> 10(3) </volume> <pages> 356-365, </pages> <year> 1991. </year>
Reference-contexts: Results are 2x the total number of hyperedges cut using unit-size vertices. 7.4 Comparison against ML F and GORDIAN We compared our hybrid algorithm to the ML F [5] and GORDIAN algorithms <ref> [30] </ref> as reported in [5]. We also report the results of our KFMC method for comparison. These tests use unit vertex sizes with a balance factor of bal = 0:1 and we used the StarF graph model.
Reference: [31] <author> Balakrishnan Krishnamurthy. </author> <title> An improved min-cut algorithm for partitioning vlsi networks. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 33(5) </volume> <pages> 438-446, </pages> <month> May </month> <year> 1984. </year>
Reference-contexts: Improvements have been made in the selection of moves by biasing clusters of neighbors to be moved in sequence (the CLIP algorithm [16]), detecting clusters [16], and breaking ties in gain by using look-ahead <ref> [31] </ref>). KLFM algorithms require a large number of random starts to obtain good partitioning solutions. Because KLFM algorithms are so sensitive to initial starting points, some researchers have sought ways to create more stable performance by using clustering and multiple levels of hierarchy.
Reference: [32] <author> Roman Kuznar, Franc Brglez, and Krzysztof Kozminski. </author> <title> Partitioning digital circuits for implementation in multiple fpga ics. </title> <type> Technical Report Technical Report 93-03, </type> <institution> MCNC Center for Microelectronic Systems Technologies, Research Triangle Park, NC, </institution> <month> March </month> <year> 1993. </year>
Reference-contexts: We can decompose partitioning into two important phases: the generation of k initial partitions and the refinement of the solution. For iterative improvement partitioners, one obvious choice is to start with many random k-way partitions and improve upon the result. Another method makes use of an existing 2-way partitioner <ref> [29, 32] </ref>: Repeatedly apply a 2-way partitioning algorithm until the desired number of partitions is reached or constraints have been satisfied.
Reference: [33] <author> Lung-Tien Liu, Mign-Ter Kuo, Shih-Chen Huang, and Chung-Kuan Cheng. </author> <title> A gradient method on the initial partition of fiduccia-mattheyses algorithm. </title> <booktitle> In ICCAD, </booktitle> <year> 1995. </year>
Reference-contexts: A new k-way improvement method which we call Rotary KLFM. 3. The (current) best known 3-way and 4-way hypergraph partitioning results. Our hybrid algorithm produces an average improvement of 27.9% over GFM <ref> [33] </ref> for 3-way partitions, 48.7% improvement over GFM for 4-way partitions, and 67.5% improvement over ML F [5] for 4-way partitions. 2 Background 2.1 State-of-the-Art Partitioners The classic Kernighan-Lin/Fiduccia-Mattheyses (KLFM) algorithm even today is used as the basis for most modern iterative partitioning algorithms. <p> Currently, there are no direct comparisons among Pairwise KLFM, Extended KLFM, and Rotary KLFM. We compare our Rotary KLFM method to the Extended KLFM implementation of <ref> [33] </ref> in Section 7, however, because of underlying differences between the iterative improvement algorithms, the comparison is not equal. Each method has its own advantages. The advantage of Pairwise KLFM is that any existing 2-way iterative improvement heuristic can be used to improve k-way partitions. <p> However, as k increases, we see consistently better results with HYBRID, which uses the spectral embedding for generating initial partitions. 7.3 Comparison against GFM and Primal-Dual We compared the total number of hyperedges cut by our hybrid algorithms to the GFM <ref> [33] </ref> and Primal-Dual (PD) algorithm [43]. These tests use the actual vertex sizes (which were obtained from Andrew Kahng of UCLA). We omitted graph t5 because in four-way partitioning, the largest 7. <p> Each partition was allowed a balance factor of bal = 0:5, and we used the CliqueD clique model. Tables 7.4 and 7.5 show the results of our hybrid partitioner compared with the previously published results of <ref> [33] </ref>. The last row, GMEAN, is the geometric mean over all of the circuits. In the three-way partitioning, our HYBRIDA method gives a 23.1% improvement, and HYBRID gives a 27.9% improvement over GFM. In four-way partitioning, HYBRIDA is 48.7% better than GFM and HYBRID is 46.9% better than GFM.
Reference: [34] <author> Daniel P. Lopresti. </author> <title> Rapid implementation of a genetic sequence comparator using field-programmable logic arrays. </title> <booktitle> In Proceedings of the Advanced Research in VLSI Conference at the University of Calfornia, </booktitle> <address> Santa Cruz, </address> <pages> pages 138-152. </pages> <publisher> The MIT Press, </publisher> <address> Cambridge, </address> <year> 1991. </year>
Reference-contexts: Graphs are simply hypergraphs where all hyperedges are incident upon exactly two vertices. Partitioning algorithms are useful in many areas, such as circuit placement [15] [24], minimizing communication in parallel processing simulations [42], optimizing the organization of large computer networks, and circuit implementation in field-programmable gate arrays (FPGAs) <ref> [34] </ref>, [9], [12], [40]. Since partitioning with balance constraints is NP-complete [20], we must resort to heuristics to solve the problem. 1.2 Contributions This paper describes a new multi-way, hybrid spectral/iterative, graph partitioning algorithm.
Reference: [35] <author> Tak-Kwong Ng, John Oldfield, and Vijay Pitchumani. </author> <title> Improvements of a mincut partition algorithm. </title> <booktitle> In ICCAD, </booktitle> <pages> pages 470-473, </pages> <year> 1987. </year>
Reference-contexts: They partitioned this contracted graph, then re-expanded it and ran their ratio-cut iterative improvement algorithm upon the expanded graph. Other researchers have tried bottom-up clustering algorithms for improving results. In [19], they created a linear-time clustering algorithm to find well-connected clusters using graph connectivity properties. In <ref> [35] </ref>, they performed clustering based on Rent's rule, and then executed the KLFM 2.
Reference: [36] <author> Alex Pothen, Horst D. Simon, and Kang-Pu Lious. </author> <title> Partitioning sparse matrices with eigenvec-tors of graphs. </title> <journal> SIAM Journal Matrix Analysis Appl., </journal> <volume> 11(3) </volume> <pages> 430-452, </pages> <month> July </month> <year> 1990. </year>
Reference-contexts: A spreading constraint, x T x = 1 is used to spread the vertices out. The trivial solution, where all vertices are placed at a single point, corresponds to the eigenvector associated with the smallest eigenvalue, is often ignored. Many researchers have used the second eigenvector to form partitions <ref> [18, 36, 23] </ref>. A variation of this which takes vertex sizes into account was proposed in [44]. Different researchers have chosen to use different numbers of eigenvectors in creating partitions. <p> Multi-way Partitioning Past work has focused on using the second eigenvector for generating two-way partitions <ref> [36, 22] </ref>. For example, in the EIG1 algorithm [23], each possible partitioning of vertices on the line was checked to find the best ratio-cut cost solution (Figure 5.4). Alpert and Yao [3] extended the concept to multiple dimensions and multiple eigenvectors by generating linear orderings using space-filling curves.
Reference: [37] <author> Laura A. Sanchis. </author> <title> Multiple-way network partitioning. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 38(1) </volume> <pages> 62-74, </pages> <month> January </month> <year> 1989. </year>
Reference-contexts: Another approach, which we call Extended KLFM, involves extending the gain cost function in KLFM algorithms to directly support iterative moves from any one partition to any other partition <ref> [37, 26] </ref>. There are k (k 1) possible directions of movement for vertices at each step. We propose a new k-way iterative improvement method, Rotary KLFM which lies somewhere between the two improvement methods described above. In Rotary KLFM, each partition is used in turn as the target partition.
Reference: [38] <author> D. G. Schweikert and B. W. Kernighan. </author> <title> A proper model for the partitioning of electrical circuits. </title> <booktitle> Proceedings of the 9th Design Automation Workshop, </booktitle> <address> Dallas, TX, </address> <pages> pages 57-62, </pages> <month> June </month> <year> 1979. </year>
Reference-contexts: 1 Introduction 1.1 The Problem This paper examines the hypergraph partitioning problem, whose goal is to divide a large system of connected components into several smaller subsystems. A hypergraph, which is a generalization of the graph model <ref> [38] </ref>, is used as an abstract representation of a more specific problem. A hypergraph is composed of vertices (nodes) having arbitrary sizes, and weighted hyperedges which connect the vertices together. <p> In the past, most researchers have simply performed a clique expansion <ref> [38] </ref> on hyperedges, shown in Figure 6.1b. In clique expansion, an edge is connected between all pairs of vertices incident on a degree d hyperedge, creating a total of d (d1) 2 edges. With clique expansion, the primary factor affecting the outcome is the choice of edge weights.
Reference: [39] <author> Jengie Shau. </author> <title> Spectral partitioning with diagonal perturbations. </title> <type> Technical report, </type> <institution> University of California, </institution> <address> Santa Cruz, Santa Cruz, CA, </address> <month> March </month> <year> 1997. </year> <title> M.S. </title> <type> Thesis. </type>
Reference-contexts: For star graphs, we introduce a hyperedge which is connected to an arbitrary vertex in each of the components. Another approach to handling disconnected graphs is to use higher-order eigenvectors. Alpert [3] used up to ten eigenvectors in creating partitions. Shau <ref> [39] </ref> used different pairs of eigenvectors (1st and 2nd; 2nd and 3rd; 1st and 3rd) in his experiments. Pairwise selection of higher-order eigenvectors would be easy to implement in our partitioner, if necessary.
Reference: [40] <author> Douglas A. Thomae, Thomas A. Peterson, and David E. Van den Bout. </author> <title> The anyboard rapid prototyping environment. </title> <booktitle> In Proceedings of the Advanced Research in VLSI Conference at the University of Calfornia, </booktitle> <address> Santa Cruz, </address> <pages> pages 356-370. </pages> <publisher> The MIT Press, </publisher> <address> Cambridge, </address> <year> 1991. </year>
Reference-contexts: Partitioning algorithms are useful in many areas, such as circuit placement [15] [24], minimizing communication in parallel processing simulations [42], optimizing the organization of large computer networks, and circuit implementation in field-programmable gate arrays (FPGAs) [34], [9], [12], <ref> [40] </ref>. Since partitioning with balance constraints is NP-complete [20], we must resort to heuristics to solve the problem. 1.2 Contributions This paper describes a new multi-way, hybrid spectral/iterative, graph partitioning algorithm.
Reference: [41] <author> Yen-Chuen Wei and Chung-Kuan Cheng. </author> <title> A two-level two-way partitioning algorithm. </title> <booktitle> In Proceedings of the IEEE International Conference on Computer-Aided Design, </booktitle> <pages> pages 516-519, </pages> <year> 1990. </year>
Reference-contexts: Because KLFM algorithms are so sensitive to initial starting points, some researchers have sought ways to create more stable performance by using clustering and multiple levels of hierarchy. A top-down approach to finding clusters in circuits was implemented by Wei and Cheng <ref> [41, 42, 13] </ref>. They used the ratio-cut partitioning algorithm to recursively subdivide a circuit into many small clusters. The ratio-cut cost function is the ratio of edges cut over the product of the partition sizes, E c jP 1 jjP 2 j .
Reference: [42] <author> Yen-Chuen Wei, Chung-Kuan Cheng, and Ze'ev Wurman. </author> <title> Multiple-level partitioning: An application to the very large-scale hardware simulator. </title> <journal> IEEE Journal of Solid-State Circuits, </journal> <volume> 26(5) </volume> <pages> 706-716, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: Graphs are simply hypergraphs where all hyperedges are incident upon exactly two vertices. Partitioning algorithms are useful in many areas, such as circuit placement [15] [24], minimizing communication in parallel processing simulations <ref> [42] </ref>, optimizing the organization of large computer networks, and circuit implementation in field-programmable gate arrays (FPGAs) [34], [9], [12], [40]. Since partitioning with balance constraints is NP-complete [20], we must resort to heuristics to solve the problem. 1.2 Contributions This paper describes a new multi-way, hybrid spectral/iterative, graph partitioning algorithm. <p> Because KLFM algorithms are so sensitive to initial starting points, some researchers have sought ways to create more stable performance by using clustering and multiple levels of hierarchy. A top-down approach to finding clusters in circuits was implemented by Wei and Cheng <ref> [41, 42, 13] </ref>. They used the ratio-cut partitioning algorithm to recursively subdivide a circuit into many small clusters. The ratio-cut cost function is the ratio of edges cut over the product of the partition sizes, E c jP 1 jjP 2 j .
Reference: [43] <author> C. W. Yeh, C. K. Cheng, and T. T. Lin. </author> <title> A general purpose multiple-way partitioning algorithm. </title> <journal> IEEE Transactions on CAD, </journal> <pages> pages 1480-1488, </pages> <year> 1994. </year>
Reference-contexts: However, as k increases, we see consistently better results with HYBRID, which uses the spectral embedding for generating initial partitions. 7.3 Comparison against GFM and Primal-Dual We compared the total number of hyperedges cut by our hybrid algorithms to the GFM [33] and Primal-Dual (PD) algorithm <ref> [43] </ref>. These tests use the actual vertex sizes (which were obtained from Andrew Kahng of UCLA). We omitted graph t5 because in four-way partitioning, the largest 7.
Reference: [44] <author> Jason Y. Zien, Martine D. F. Schlag, and Pak K. Chan. </author> <title> Multi-level spectral hypergraph partitioning with arbitrary vertex sizes. </title> <booktitle> In ICCAD, </booktitle> <pages> pages 201-204, </pages> <year> 1996. </year> <title> 30 A. Embedding Choices Average Cost Best Cost Method Unit Size Actual Size Unit Size Actual Size Standard Eigenvectors 163.8 152.7 143.3 129.5 Scaled Standard 159.0 205.4 143.3 156.0 Generalized Eigenvectors 162.3 157.8 141.5 138.2 Scaled Generalized 158.2 150.7 139.5 129.1 Table A.1: Comparison of embedding types for balanced partition tests. Numbers are the geometric mean of 2x the hyperedges cut for seven benchmarks. </title>
Reference-contexts: Background 1. A new hybrid spectral/iterative partitioning algorithm. This is the first algorithm that simultaneously combines iterative and spectral information in a multi-level partitioning framework. Previously, researchers have combined the two approaches by finding a solution using a spectral algorithm and then performing iterative improvement on it <ref> [6, 25, 44] </ref>. The simultaneous use of spectral and traditional gain costs was found in [11], where a single-pass constructive heuristic was used to create partitions using the weighted sum of the cut gain and a spectral cost function. <p> In [14], they developed a clustering algorithm by collapsing cliques into supernodes, and then running the KLFM algorithm on the contracted graph. These methods were subsequently improved upon by using multiple levels of contraction (instead of just one level), and iterative improvement at each level of the hierarchy <ref> [26, 28, 27, 4, 44] </ref>. Current state-of-the-art partitioners use the multi-level (hierarchical) approach as shown in Figure 2.3. A hypergraph is reduced in size by pre-clustering nodes or matching nodes together (Figure 2.2). A matching of a graph is a set of edges whose vertices are non-overlapping. <p> Spectral Partitioning and Vectors 3 Spectral Partitioning and Vectors In this section, we will give a brief overview of spectral partitioning. Since much of this theory has been published in the past, we will not repeat it here. The interested reader may refer to other papers <ref> [24, 23, 3, 18, 44] </ref> for more details. Assume we are given a graph with n vertices, and we wish to find k partitions of this graph. Let v i be vertex i and deg (v i ) be the degree of v i . <p> Many researchers have used the second eigenvector to form partitions [18, 36, 23]. A variation of this which takes vertex sizes into account was proposed in <ref> [44] </ref>. Different researchers have chosen to use different numbers of eigenvectors in creating partitions. To be general, let us assume we are using d eigenvectors, where d is the desired number of dimensions we use, so X d is our n fi d relaxed solution. <p> This is offset by the fact that more levels of iterative improvement can be run when there are more hierarchical levels. Many researchers have only used one level of contraction to perform partitioning [19, 13, 14], or a fixed number of levels, such as three <ref> [44] </ref>. Other researchers have chosen to contract the graph until the number of nodes in the graph reaches a target size, such as 35 nodes [5], 100 nodes [28] or 200 nodes [26]. For four-way partitioning, contraction was limited to 100 nodes in [5].
References-found: 44

