URL: http://www.cse.ogi.edu/Sparse/paper/wolfe.pldi.92.ps
Refering-URL: http://www.cse.ogi.edu/Sparse/sparse.sequence.html
Root-URL: http://www.cse.ogi.edu
Title: Beyond Induction Variables  
Author: Michael Wolfe 
Affiliation: Oregon Graduate Institute of Science and Technology  
Abstract: Induction variable detection is usually closely tied to the strength reduction optimization. This paper studies induction variable analysis from a different perspective, that of finding induction variables for data dependence analysis. While classical induction variable analysis techniques have been used successfully up to now, we have found a simple algorithm based on the the Static Single Assignment form of a program that finds all linear induction variables in a loop. Moreover, this algorithm is easily extended to find induction variables in multiple nested loops, to find nonlinear induction variables, and to classify other integer scalar assignments in loops, such as monotonic, periodic and wraparound variables. Some of these other variables are now classified using ad hoc pattern recognition, while others are not analyzed by current compilers. Giving a unified approach improves the speed of compilers and allows a more general classification scheme. We also show how to use these variables in data dependence testing. 
Abstract-found: 1
Intro-found: 1
Reference: [ACK81] <author> F. E. Allen, John Cocke, and Ken Kennedy. </author> <title> Reduction of operator strength. </title> <editor> In Steven S. Muchnick and Neil D. Jones, editors, </editor> <title> Program Flow Analysis: </title> <booktitle> Theory and Applications, </booktitle> <pages> pages 79-101. </pages> <publisher> Prentice-Hall, </publisher> <year> 1981. </year>
Reference-contexts: of the early improvements in induction variable analysis was to extend the definition of basic induction variables to the maximal set of variables which are assigned by simple expressions of the form: i = j k where j and k are invariants or induction variables (note j may be zero) <ref> [CK77, ACK81] </ref>. This allows mutually-defined induction variables, such as: j = n L2: loop . . . . . . . . . endloop where c and k are invariants in the loop. With each induction variable a compiler associates its initial value and its increment, or step.
Reference: [AK87] <author> John R. Allen and Ken Kennedy. </author> <title> Automatic translation of Fortran programs to vector form. </title> <journal> ACM Trans. on Programming Languages and Systems, </journal> <volume> 9(4) </volume> <pages> 491-542, </pages> <month> Oc-tober </month> <year> 1987. </year>
Reference-contexts: Dependence testing for linear induction variables is generally well-covered in the literature <ref> [AK87, BCKT79, GKT91, MHL91] </ref>. Banerjee presents some algorithms for handling polynomial induction variables in his MS thesis [Ban76]. After a brief review, we focus on dependence with wrap-around variables, monotonic variables and periodic variables. <p> 1 to n loop L24: for j = i+1 to n loop A (i,j) = A (i-1,j) Modern dependence analysis applied to this example will typically find a dependence distance vector, with one distance computed for each nested loop; see the tons of literature on this subject for further details <ref> [AK87, BCKT79, GKT91, MHL91] </ref>. In this case, the distance vector is (1; 0), meaning distance one in the i loop and distance zero in the j loop.
Reference: [ASU86] <author> A. V. Aho, R. Sethi, and J. D. Ull-man. </author> <booktitle> Compilers: Principles, Techniques, and Tools. </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1986. </year>
Reference-contexts: Our algorithm is based on the Static Single Assignment form of the program. 2 Induction Variables and Static Single Assignment An induction variable is typically defined in compiler texts as a variable whose value is systematically incremented or decremented by a constant value in a loop <ref> [ASU86, FL88] </ref>.
Reference: [AWZ88] <author> B. Alpern, M.N. Wegman, and F.K. Zadeck. </author> <title> Detecting equality of variables in programs. </title> <booktitle> In Conf. Record 15th Annual ACM Symp. Principles of Programming Languages [POP88], </booktitle> <pages> pages 1-11. </pages>
Reference-contexts: The reader is encouraged to read the SSA paper [CFR + 91] for more details on these algorithms, and <ref> [AWZ88, RWZ88, WZ91] </ref> for details on applications of the SSA form.
Reference: [Ban76] <author> Utpal Banerjee. </author> <title> Data dependence in ordinary programs. M.S. </title> <type> thesis UIUCDCS-R-76-837, </type> <institution> Univ. Illinois, Dept. Computer Science, </institution> <month> November </month> <year> 1976. </year>
Reference-contexts: Dependence testing for linear induction variables is generally well-covered in the literature [AK87, BCKT79, GKT91, MHL91]. Banerjee presents some algorithms for handling polynomial induction variables in his MS thesis <ref> [Ban76] </ref>. After a brief review, we focus on dependence with wrap-around variables, monotonic variables and periodic variables. The algorithm used to classify variables will actually classify each subexpression as one of the generalized variable types. Thus, each subscript expression will be classified as an induction expression, monotonic expression, etc.
Reference: [Ban91] <author> Utpal Banerjee. </author> <title> Unimodular transformations of double loops. </title> <editor> In Nicolau et al. </editor> <booktitle> [NGGP91], </booktitle> <pages> pages 192-219. </pages>
Reference-contexts: It may also force compilers to implement loop skewing and loop interchanging as a single transformation [Wol86]; this has been formulated in the past as a linear transformation on the index set [KMW67], and is currently in vogue as "unimodular transformations" <ref> [WL91, Ban91] </ref>. 7 Summary and Conclusions We have shown a fast and simple algorithm for classifying all induction variables in a loop; this algorithm is linear in the size of the SSA graph, not iterative. The algorithm is a somewhat obvious application of Tar-jan's SCR algorithm on the SSA graph.
Reference: [BCKT79] <author> Utpal Banerjee, Shyh-Ching Chen, David J. Kuck, and Ross A. Towle. </author> <title> Time and parallel processor bounds for Fortran-like loops. </title> <journal> IEEE Trans. on Computers, </journal> <volume> C-28(9):660-670, </volume> <month> September </month> <year> 1979. </year>
Reference-contexts: Dependence testing for linear induction variables is generally well-covered in the literature <ref> [AK87, BCKT79, GKT91, MHL91] </ref>. Banerjee presents some algorithms for handling polynomial induction variables in his MS thesis [Ban76]. After a brief review, we focus on dependence with wrap-around variables, monotonic variables and periodic variables. <p> at zero (or one) with a step of one; thus the loop: for i = 2 to 11 by 3 loop A (i) will be changed to: for i = 0 to (11-2)/3 loop A (i*3+2) This transformation was initially designed to simplify the formulation of data dependence testing algorithms <ref> [BCKT79] </ref>. Since normalization always puts the loop lower limits into subscript expressions, it can complicate life for simple dependence analyzers when the lower limit contains other variables, as shown by the work on Parafrase [SLY90]. <p> 1 to n loop L24: for j = i+1 to n loop A (i,j) = A (i-1,j) Modern dependence analysis applied to this example will typically find a dependence distance vector, with one distance computed for each nested loop; see the tons of literature on this subject for further details <ref> [AK87, BCKT79, GKT91, MHL91] </ref>. In this case, the distance vector is (1; 0), meaning distance one in the i loop and distance zero in the j loop.
Reference: [BMO90] <author> Robert A. Ballance, Arthur B. Maccabe, and Karl J. Ottenstein. </author> <title> The program dependence web: A representation supporting control-, data-, and demand-driven interpretation of imperative languages. </title> <booktitle> In Proc. ACM SIGPLAN '90 Conf. on Programming Language Design and Implementation, </booktitle> <pages> pages 257-271, </pages> <address> White Plains, NY, </address> <month> June </month> <year> 1990. </year>
Reference-contexts: Proper engineering can make this a low-cost insertion, but it would have been nice if there had already been an SSA name to distinguish the value of the variable upon loop exit. The loop exit gating function used in the Program Dependence Web <ref> [BMO90] </ref> serves exactly this purpose. While we don't feel we need all the generality of the PDW, we are investigating adding some of its elements to the factored use-def chains used in our compiler internal representation. In one other place the SSA representation is less precise than we would like.
Reference: [CFR + 91] <author> Ron Cytron, Jeanne Ferrante, Barry K. Rosen, Mark N. Wegman, and F. Kenneth Zadeck. </author> <title> Efficiently computing static sin-gle assignment form and the control dependence graph. </title> <journal> ACM Trans. on Programming Languages and Systems, </journal> <volume> 13(4) </volume> <pages> 451-490, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: The reader is encouraged to read the SSA paper <ref> [CFR + 91] </ref> for more details on these algorithms, and [AWZ88, RWZ88, WZ91] for details on applications of the SSA form.
Reference: [CK77] <author> John Cocke and Ken Kennedy. </author> <title> An algorithm for reduction of operator strength. </title> <journal> Communications ACM, </journal> 20(11) 850-856, November 1977. 
Reference-contexts: of the early improvements in induction variable analysis was to extend the definition of basic induction variables to the maximal set of variables which are assigned by simple expressions of the form: i = j k where j and k are invariants or induction variables (note j may be zero) <ref> [CK77, ACK81] </ref>. This allows mutually-defined induction variables, such as: j = n L2: loop . . . . . . . . . endloop where c and k are invariants in the loop. With each induction variable a compiler associates its initial value and its increment, or step.
Reference: [EHLP92] <author> Rudolf Eigenmann, Jay Hoeflinger, Zhi-yuan Li, and David Padua. </author> <title> Experience in the automatic parallelization of four Perfect benchmark programs. </title> <editor> In Ut-pal Banerjee, David Gelernter, Alexandru Nicolau, and David A. Padua, editors, </editor> <booktitle> Languages and Compilers for Parallel Computing. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1992. </year> <note> (to appear). </note>
Reference-contexts: 1 ; j 4 ) L20: for k = 1 to i loop j 4 = (j 3 ; j 5 ) endloop endloop k 3 = hL18; hL17; 0; 204i; 2i It is interesting to note that the case of generalized induction variables found to be so difficult in <ref> [EHLP92] </ref> is simple in this framework. Their given example has a doubly nested loop where the inner loop is triangular, that is, its upper limit depends on the outer loop index variable, as in Figure 9.
Reference: [FL88] <author> Charles N. Fischer and Richard J. LeBlanc, Jr. </author> <title> Crafting a Compiler. </title> <address> Benjamin-Cummings, Menlo Park, CA, </address> <year> 1988. </year>
Reference-contexts: Our algorithm is based on the Static Single Assignment form of the program. 2 Induction Variables and Static Single Assignment An induction variable is typically defined in compiler texts as a variable whose value is systematically incremented or decremented by a constant value in a loop <ref> [ASU86, FL88] </ref>.
Reference: [GKT91] <author> Gina Goff, Ken Kennedy, and Chau-Wen Tseng. </author> <title> Practical dependence testing. </title> <booktitle> In Proc. ACM SIGPLAN '91 Conference on Programming Language Design and Implementation [SIG91], </booktitle> <pages> pages 15-29. </pages>
Reference-contexts: Dependence testing for linear induction variables is generally well-covered in the literature <ref> [AK87, BCKT79, GKT91, MHL91] </ref>. Banerjee presents some algorithms for handling polynomial induction variables in his MS thesis [Ban76]. After a brief review, we focus on dependence with wrap-around variables, monotonic variables and periodic variables. <p> 1 to n loop L24: for j = i+1 to n loop A (i,j) = A (i-1,j) Modern dependence analysis applied to this example will typically find a dependence distance vector, with one distance computed for each nested loop; see the tons of literature on this subject for further details <ref> [AK87, BCKT79, GKT91, MHL91] </ref>. In this case, the distance vector is (1; 0), meaning distance one in the i loop and distance zero in the j loop.
Reference: [IT88] <author> Fran~cois Irigoin and Remi Triolet. </author> <title> Supern-ode partitioning. </title> <booktitle> In Conf. Record 15th Annual ACM Symp. Principles of Programming Languages [POP88], </booktitle> <pages> pages 319-329. </pages>
Reference-contexts: More likely, use of this induction variable representation will force compilers to abandon the direction vector dependence representation, which has been criticized by many researchers as too coarse <ref> [IT88] </ref>. A direction vector encodes the sign of the elements of the distance vector; while less precise in general, it can be used effectively when the distance vector is not constant.
Reference: [KMW67] <author> Richard M. Karp, Raymond E. Miller, and Shmuel Winograd. </author> <title> The organization of computations for uniform recurrence equations. </title> <journal> J. ACM, </journal> <volume> 14(3) </volume> <pages> 563-590, </pages> <month> July </month> <year> 1967. </year>
Reference-contexts: It may also force compilers to implement loop skewing and loop interchanging as a single transformation [Wol86]; this has been formulated in the past as a linear transformation on the index set <ref> [KMW67] </ref>, and is currently in vogue as "unimodular transformations" [WL91, Ban91]. 7 Summary and Conclusions We have shown a fast and simple algorithm for classifying all induction variables in a loop; this algorithm is linear in the size of the SSA graph, not iterative.
Reference: [MHL91] <author> Dror E. Maydan, John L. Hennessy, and Monica S. Lam. </author> <title> Efficient and exact data dependence analysis. </title> <booktitle> In Proc. ACM SIGPLAN '91 Conference on Programming Language Design and Implementation [SIG91], </booktitle> <pages> pages 1-14. </pages>
Reference-contexts: Dependence testing for linear induction variables is generally well-covered in the literature <ref> [AK87, BCKT79, GKT91, MHL91] </ref>. Banerjee presents some algorithms for handling polynomial induction variables in his MS thesis [Ban76]. After a brief review, we focus on dependence with wrap-around variables, monotonic variables and periodic variables. <p> 1 to n loop L24: for j = i+1 to n loop A (i,j) = A (i-1,j) Modern dependence analysis applied to this example will typically find a dependence distance vector, with one distance computed for each nested loop; see the tons of literature on this subject for further details <ref> [AK87, BCKT79, GKT91, MHL91] </ref>. In this case, the distance vector is (1; 0), meaning distance one in the i loop and distance zero in the j loop.
Reference: [NGGP91] <editor> Alexandru Nicolau, David Gelern-ter, Thomas Gross, and David Padua, editors. </editor> <booktitle> Advances in Languages and Compilers for Parallel Computing. Research Monographs in Parallel and Distributed Computing. </booktitle> <publisher> MIT Press, </publisher> <address> Boston, </address> <year> 1991. </year>
Reference: [POP88] <editor> Conf. </editor> <booktitle> Record 15th Annual ACM Symp. Principles of Programming Languages, </booktitle> <address> San Diego, CA, </address> <month> January </month> <year> 1988. </year>
Reference: [PW86] <author> David A. Padua and Michael Wolfe. </author> <title> Advanced compiler optimizations for supercomputers. </title> <journal> Communications ACM, </journal> <volume> 29(12) </volume> <pages> 1184-1201, </pages> <month> December </month> <year> 1986. </year>
Reference-contexts: One of these is called a wrap-around variable <ref> [PW86] </ref>, such as im1 below: im1 = n L9: for i = 1 to n loop A (i) = A (im1) + : : : endloop In all iterations but the first, the value of im1 is equal to i-1; in the first iteration, however, im1 has some other value, usually
Reference: [RWZ88] <author> B.K. Rosen, M.N. Wegman, and F.K. Zadeck. </author> <title> Global value numbers and redundant computations. </title> <booktitle> In Conf. Record 15th Annual ACM Symp. Principles of Programming Languages [POP88], </booktitle> <pages> pages 12-27. </pages>
Reference-contexts: The reader is encouraged to read the SSA paper [CFR + 91] for more details on these algorithms, and <ref> [AWZ88, RWZ88, WZ91] </ref> for details on applications of the SSA form.
Reference: [SIG91] <editor> Proc. </editor> <booktitle> ACM SIGPLAN '91 Conference on Programming Language Design and Implementation, </booktitle> <address> Toronto, </address> <month> June </month> <year> 1991. </year>
Reference: [SLY90] <author> Zhiyu Shen, Zhiyuan Li, and Pen-Chung Yew. </author> <title> An empirical study of Fortran programs for parallelizing compilers. </title> <journal> IEEE Trans. Parallel and Distributed Systems, </journal> <volume> 1(3) </volume> <pages> 356-364, </pages> <month> July </month> <year> 1990. </year>
Reference-contexts: Since normalization always puts the loop lower limits into subscript expressions, it can complicate life for simple dependence analyzers when the lower limit contains other variables, as shown by the work on Parafrase <ref> [SLY90] </ref>. For this reason, and because it can adversely affect the kinds of transformations allowed in programs (such as loop interchanging), this author has in the past argued against implementing loop normalization [Wol86]. It is interesting to note that this formulation of induction variables essentially normalizes all loops.
Reference: [Tar72] <author> R. Tarjan. </author> <title> Depth-first search and linear graph algorithms. </title> <journal> SIAM J. Comput., </journal> <volume> 1(2) </volume> <pages> 146-160, </pages> <month> June </month> <year> 1972. </year>
Reference-contexts: Edges from the LD vertices correspond to the ssalink field. 3.1 Basic Linear Induction Variables Our algorithm to find the induction variables is based on Tarjan's well-known algorithm to find strongly connected regions (SCRs) in directed graphs <ref> [Tar72] </ref>. The primary observation is that each basic linear induction variable will belong to a nontrivial SCR in the SSA graph. Each such SCR in the SSA graph must include a loop-header -function, since all values cycling around the loop must pass through a -function.
Reference: [WB87] <author> Michael Wolfe and Utpal Banerjee. </author> <title> Data dependence and its application to parallel processing. </title> <journal> International J. Parallel Programming, </journal> <volume> 16(2) </volume> <pages> 137-178, </pages> <month> April </month> <year> 1987. </year>
Reference-contexts: Often, dependence distance or direction information can be found, determining that the solution only occurs when (for instance) i 00 i 0 = 1 or i 0 &lt; i 00 <ref> [WB87] </ref>. This information is critical to many optimization algorithms. In the case where one of the expressions has the wrap-around attribute, the same dependence equation can be constructed and solved, but the dependence relation should be flagged as holding only after k iterations, the order of the wrap-around variable.
Reference: [WL91] <author> Michael E. Wolf and Monica S. Lam. </author> <title> An algorithmic approach to compound loop transformations. </title> <editor> In Nicolau et al. </editor> <booktitle> [NGGP91], </booktitle> <pages> pages 243-259. </pages>
Reference-contexts: It may also force compilers to implement loop skewing and loop interchanging as a single transformation [Wol86]; this has been formulated in the past as a linear transformation on the index set [KMW67], and is currently in vogue as "unimodular transformations" <ref> [WL91, Ban91] </ref>. 7 Summary and Conclusions We have shown a fast and simple algorithm for classifying all induction variables in a loop; this algorithm is linear in the size of the SSA graph, not iterative. The algorithm is a somewhat obvious application of Tar-jan's SCR algorithm on the SSA graph.
Reference: [Wol86] <author> Michael Wolfe. </author> <title> Loop skewing: The wavefront method revisited. </title> <journal> International J. Parallel Programming, </journal> <volume> 15(4) </volume> <pages> 279-294, </pages> <month> August </month> <year> 1986. </year>
Reference-contexts: For this reason, and because it can adversely affect the kinds of transformations allowed in programs (such as loop interchanging), this author has in the past argued against implementing loop normalization <ref> [Wol86] </ref>. It is interesting to note that this formulation of induction variables essentially normalizes all loops. <p> A direction vector encodes the sign of the elements of the distance vector; while less precise in general, it can be used effectively when the distance vector is not constant. It may also force compilers to implement loop skewing and loop interchanging as a single transformation <ref> [Wol86] </ref>; this has been formulated in the past as a linear transformation on the index set [KMW67], and is currently in vogue as "unimodular transformations" [WL91, Ban91]. 7 Summary and Conclusions We have shown a fast and simple algorithm for classifying all induction variables in a loop; this algorithm is linear
Reference: [WZ91] <author> Mark N. Wegman and F. Kenneth Zadeck. </author> <title> Constant propagation with conditional branches. </title> <journal> ACM Trans. on Programming Languages and Systems, </journal> <volume> 13(2) </volume> <pages> 181-210, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: The reader is encouraged to read the SSA paper [CFR + 91] for more details on these algorithms, and <ref> [AWZ88, RWZ88, WZ91] </ref> for details on applications of the SSA form. <p> The other members of the family differ only by a constant in the initial value. Often the initial value coming in from outside the loop can be evaluated and substituted, using an algorithm such as constant propagation <ref> [WZ91] </ref>. Actually, the rules for basic linear induction variables can be relaxed a bit. As long as the variable is incremented by the same amount on each path through the loop, the compiler can classify it as an induction variable. An example is shown in Figure 3.
References-found: 27

