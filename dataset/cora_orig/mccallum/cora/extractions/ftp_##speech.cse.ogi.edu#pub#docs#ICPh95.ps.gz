URL: ftp://speech.cse.ogi.edu/pub/docs/ICPh95.ps.gz
Refering-URL: http://www.cse.ogi.edu/CSLU/publications/publications.html
Root-URL: http://www.cse.ogi.edu
Email: tlander@cse.ogi.edu  
Title: Multi-language Speech Database: Creation and Phonetic Labeling Agreement  for Spoken Language Understanding  
Author: Terri Lander, Beatrice Oshika, Ronald A. Cole, and Mark Fanty 
Address: Portland, Oregon USA  
Affiliation: Center  Oregon Graduate Institute of Science and Technology  
Abstract: The focus of the paper is the evaluation of inter-labeler reliability on broad phonetic transcriptions when la-belers do not necessarily know the language they are labeling. We provide an analysis of label disagreements, presenting results from six languages, English, French, German, Japanese, Spanish, and Vietnamese with a total of 2 minutes of continuous labeled speech. Labeler agreement across languages ranges from 41 percent with detailed label to label comparisons to 91 percent when less fine comparisons were made. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Y.K. Muthusamy R.A. Cole, </author> <title> and B.T. Oshika, "The OGI Multi-language Telephone Speech Corpus", </title> <booktitle> The International Conference on Spoken Language Proceedings, </booktitle> <address> Banff, Alberta, Canada, </address> <month> Oct </month> <year> 1992, </year> <pages> pp 895-898. </pages>
Reference-contexts: INTRODUCTION This paper describes research on a large multi-language speech database being collected at the Oregon Graduate Institute (OGI). The Center for Spoken Language Understanding (CSLU) at OGI has been developing multi-language telephone speech corpora for the last 5 years. An earlier corpus <ref> [1] </ref> contained data from 11 languages with 90 speakers per language.
Reference: [2] <author> T. Lander, S.T. Metzler, </author> <title> "The CSLU Labeling Guide", </title> <address> CSLU, Ore-gon, </address> <month> February, </month> <year> 1994. </year>
Reference-contexts: Up to one minute of spontaneous speech and responses to questions are being transcribed at the orthographic level by two native talkers, with disagreement resolution. A standard method for transcribing continuous speech, including pauses and nonspeech sounds has been developed <ref> [2] </ref>. In addition, trained linguists will label two one-minute sections from each language at the broad phonetic level using Worldbet [3]. 1 An earlier study [4] compared agreement of broad phonetic labels by both native and non-native talkers of five different languages.
Reference: [3] <author> J.L. Hieronymus. </author> <title> "Ascii phonetic symbols for the world's languages: </title> <institution> Worldbet". AT&T Bell Laboratories Technical Memo, </institution> <year> 1994. </year>
Reference-contexts: A standard method for transcribing continuous speech, including pauses and nonspeech sounds has been developed [2]. In addition, trained linguists will label two one-minute sections from each language at the broad phonetic level using Worldbet <ref> [3] </ref>. 1 An earlier study [4] compared agreement of broad phonetic labels by both native and non-native talkers of five different languages. Label agreement between native speakers averaged 68%, while agreement between non-natives was much less consistent at 34%. <p> Label agreement between native speakers averaged 68%, while agreement between non-natives was much less consistent at 34%. This paper reports on results from labeled speech in six languages, and includes an analysis of phonetic categories on 1 Phonetic label sets were developed by Dr. James Hieronymus, author of <ref> [3] </ref>. which labelers most disagree, with pos-sible explanations of such variation. TRANSCRIPTIONS Transcription was supported by the OGI speech tools [5] which display the waveform and corresponding spectrogram. Transcribers were able to play any part of the waveform multiple times as needed.
Reference: [4] <author> R. Cole, B.T. Oshika, M. Noel, T. Lander, M. Fanty, </author> <title> "Labeler Agreement in Phonetic Labeling of Continuous Speech", </title> <booktitle> Proceedings ICSLP94, </booktitle> <address> Yokohama, Japan, </address> <month> September </month> <year> 1993, </year> <pages> pp. 2131-2134. </pages>
Reference-contexts: A standard method for transcribing continuous speech, including pauses and nonspeech sounds has been developed [2]. In addition, trained linguists will label two one-minute sections from each language at the broad phonetic level using Worldbet [3]. 1 An earlier study <ref> [4] </ref> compared agreement of broad phonetic labels by both native and non-native talkers of five different languages. Label agreement between native speakers averaged 68%, while agreement between non-natives was much less consistent at 34%. <p> vowel reduction: A) high, mid low, B) front, central, back, C) high-front, low-front, central, high-back and low-back D) contains the average number of reference segments A B C D FR 62 73 62 45 JA 75 78 77 57 VT 52 62 56 27 DISCUSSION As a follow up to <ref> [4] </ref> we wanted to do a more careful error analysis of labeler disagreement. In the present experiment, labeler agreement across languages ranges from 41 percent with detailed label to label comparisons to 91 percent when less fine comparisons were made. This compares to 33% and 83% in [4]. <p> follow up to <ref> [4] </ref> we wanted to do a more careful error analysis of labeler disagreement. In the present experiment, labeler agreement across languages ranges from 41 percent with detailed label to label comparisons to 91 percent when less fine comparisons were made. This compares to 33% and 83% in [4]. Perhaps using orthographies in addition to labeling and comparing test data prior to actual labeling helped to raise over all agreement.
Reference: [5] <author> CSLU. </author> <title> "OGI speech tools user's manual," </title> <type> Technical report, </type> <institution> Center for Spoken Language Understanding, Ore-gon Graduate Institute, </institution> <year> 1993. </year>
Reference-contexts: James Hieronymus, author of [3]. which labelers most disagree, with pos-sible explanations of such variation. TRANSCRIPTIONS Transcription was supported by the OGI speech tools <ref> [5] </ref> which display the waveform and corresponding spectrogram. Transcribers were able to play any part of the waveform multiple times as needed. The labelers used Worldbet, an ASCII rendering of the IPA for broad phonetic transcriptions. Worldbet attempts to represent phonetic and phonemic distinctions within a single level of transcription.
References-found: 5

