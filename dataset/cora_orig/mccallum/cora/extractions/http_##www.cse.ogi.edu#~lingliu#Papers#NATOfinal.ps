URL: http://www.cse.ogi.edu/~lingliu/Papers/NATOfinal.ps
Refering-URL: http://www.cse.ogi.edu/~lingliu/courses/cse583/reading.html
Root-URL: http://www.cse.ogi.edu
Title: Interoperability in Large-scale Distributed Information Delivery Systems  
Author: Ling Liu, Ling Ling Yan, and M. Tamer Ozsu 
Address: Edmonton, Alberta, Canada T6G 2H1  
Affiliation: University of Alberta, Department of Computing Science  
Abstract: In this paper we address interoperability issues in large-scale distributed information delivery systems. Architecturally, we classify existing approaches and systems into two paradigms: Multidatabase management-based paradigm and Mediator-based information delivery paradigm, and analyze the techniques used in each. Technically, we describe a number of data delivery characteristics in terms of delivery protocols, delivery modes, and delivery frequencies. We further use these characteristics to discuss and compare several data delivery schemes. We argue that an advanced distributed information system must incorporate different types of information delivery so that the system can be optimized according to various criteria, such as network traffic and heterogeneity and constant evolution of online information sources. To illustrate the architectural aspect and technical aspect of distributed information delivery systems, we review a number of research prototype systems to demonstrate the various implementation approaches used in practice, and the different solutions to the interoperability issues addressed in the paper. 
Abstract-found: 1
Intro-found: 1
Reference: [AAFZ95] <author> S. Acharya, R. Alonso, M. Franklin, and S. Zdonik. </author> <title> Broadcast disks: Data management for asymmetric communications environments. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on Management of Data, </booktitle> <address> San Jose, CA, </address> <month> May </month> <year> 1995. </year>
Reference-contexts: Space limitation prevents us from being exhaustive. 4.1 Broadcast Disks Approach to Information Dissemination The broadcast disks approach <ref> [AAFZ95, AFZ97, FZ96] </ref> to information dissemination uses a periodic push-based data delivery with broadcast protocol. The broadcast disks paradigm is based on a cyclic broadcast of objects (e.g., pages) and a corresponding collection of client cache management techniques. 12 Ling Liu, Ling Ling Yan, M.
Reference: [Aea91] <author> Ahmed and et al. </author> <title> The pagasus heterogeneous multidatabase system. </title> <journal> IEEE Computer, </journal> <volume> 24(12), </volume> <year> 1991. </year>
Reference-contexts: The mapping from each local schema to the global schema is often expressed in a common SQL-like language, such 4 Ling Liu, Ling Ling Yan, M. Tamer Ozsu as HOSQL in the Pegasus system <ref> [Aea91] </ref> or SQL/M in the UniSQL/M system [Kea93]. Although the enforcement of a single global schema through data integration yields full transparency for uniform access, component databases have much restricted autonomy, scalability and their evolution becomes difficult.
Reference: [AFZ97] <author> S. Acharya, M. Franklin, and S. Zdonik. </author> <title> Balancing push and pull for data broadcast. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on Management of Data, </booktitle> <address> Tucson, Arizona, </address> <month> May </month> <year> 1997. </year>
Reference-contexts: As the scale and rate of changes for online information continues to grow, the Publish/Subscribe mechanism attracts increasing popularity as a promising way of disseminating information over networks. Triggers and change notifications in active database systems bear some resemblance to the Publish/Subscribe protocol based on point-to-point communication <ref> [AFZ97] </ref>. The Publish/Subscribe mechanisms may not be beneficial when the interest of clients changes irregularly because in such situations clients may be continually interrupted to filter data that is not of interest to them. A typical example is the various online news groups. <p> It is obvious that using broadcast is beneficial when multiple clients are interested in the same items. The tradeoffs of broadcast mechanisms depend upon the number of clients who have the commonality of interest and the volume of information that are of interest to a large number of clients <ref> [FZ96, AFZ97] </ref>. 8 Ling Liu, Ling Ling Yan, M. Tamer Ozsu 3.2 Data Delivery Modes With the rapid growth of the volume and variety of information available online, combined with the constant increase of information consumers, it is no longer efficient to use a single mode of data delivery. <p> Space limitation prevents us from being exhaustive. 4.1 Broadcast Disks Approach to Information Dissemination The broadcast disks approach <ref> [AAFZ95, AFZ97, FZ96] </ref> to information dissemination uses a periodic push-based data delivery with broadcast protocol. The broadcast disks paradigm is based on a cyclic broadcast of objects (e.g., pages) and a corresponding collection of client cache management techniques. 12 Ling Liu, Ling Ling Yan, M. <p> A broadcast schedule is generated based on the number of disks, the relative frequencies of each disk and the assignments of data items to the disks on which these items are to be broadcast <ref> [AFZ97] </ref>. Interesting to note is that the multi-levels are in fact superimposed on a single broadcast channel by interleaving the data items of the various levels in a manner that results in the desired relative frequencies. <p> Currently, an integrated dissemination-based information system is under development as a continuation to the Broadcast Disks project at Brown university and University of Maryland, aiming at supporting a wider range of ways to deliver data to clients <ref> [AFZ97] </ref>. 4.2 Carnot The Carnot Project [CHS91, WCH + 93] at MCC has developed and assembled a large set of generic facilities for managing integrated enterprise information. These facilities are organized into five sets of services: communication services, support services, distribution services, semantic services, and access services.
Reference: [BBa97] <author> R. Bayardo, W. Bohrer, and R. Brice and et al. </author> <title> Semantic Integration of Information in Open and Dynamic Environments. </title> <booktitle> In SIGMOD'97, </booktitle> <year> 1997. </year>
Reference-contexts: A partial query evaluation model where the answer to a query is another query is also studied, which defines semantics of accessing unavailable data sources [TRV96]. 4.5 InfoSleuth InfoSleuth <ref> [BBa97] </ref> is a mediator-based project at MCC that extends Carnot technology to meet the challenge presented by the World Wide Web.
Reference: [BDHS96] <author> P. Buneman, S.B. Davidson, G.G. Hillebrand, and D. Suciu. </author> <title> A Query Language and Optimization Techniques for Unstructured Data. </title> <booktitle> In SIGMOD 96, </booktitle> <pages> pages 505-516, </pages> <year> 1996. </year>
Reference-contexts: The labelled-tree structures like those in OEM can represent all sorts of data structures equally well and have a great potential in supporting integration of heterogeneous data. Query and manipulation language and optimization techniques are being developed for this new data model <ref> [BDHS96] </ref>. 4.8 Comparison with respect to Data Delivery Capabilities In previous sections we have described several projects or prototype systems in terms of the capabilities and mechanisms they use to process queries through mediators and wrappers and the support they provides for interoperability and scalable distributed object management.
Reference: [Bet94] <author> Mark Betz. </author> <title> Interoperable objects: laying the foundation for distributed object computing. Dr. Dobb's Journal: Software Tools for Professional Programmer, </title> <month> October </month> <year> 1994. </year>
Reference-contexts: Distributed interoperable objects are objects that support a level of interoperability beyond the traditional object computing boundaries imposed by programming languages, data models, process address space, and network interface <ref> [Bet94] </ref>. The abstractions of distributed interoperable objects are captured and utilized by the distributed object management services to schedule and control the remote data access and delivery.
Reference: [Cea94] <author> R. Cattell and et al. </author> <title> The Object Database Standard: ODMG-93 (Release 1.1). </title> <publisher> Morgan Kaufmann, </publisher> <year> 1994. </year>
Reference-contexts: It requires the definition of a common object model and a common object query language. Recent activities in the OMG and the ODMG standard <ref> [Cea94] </ref>, which extends the OMG object model to the database interoperability, are important milestones for distributed object management. 2.2 Mediator-Based Paradigm Mediator-based information integration architecture has evolved from an initial proposal by Gio Wiederhold in [Wie92] and elaborated through the intelligent information integration (I 3 ) program [Wie95].
Reference: [CHS91] <author> C. Collet, M. Huhns, and W. Shen. </author> <title> Resource Integration Using a Large Knowledge Base in Carnot. </title> <journal> IEEE Computer, </journal> <volume> 24(12) </volume> <pages> 55-62, </pages> <month> December </month> <year> 1991. </year> <note> Interoperability in Information Delivery Systems 35 </note>
Reference-contexts: Currently, an integrated dissemination-based information system is under development as a continuation to the Broadcast Disks project at Brown university and University of Maryland, aiming at supporting a wider range of ways to deliver data to clients [AFZ97]. 4.2 Carnot The Carnot Project <ref> [CHS91, WCH + 93] </ref> at MCC has developed and assembled a large set of generic facilities for managing integrated enterprise information. These facilities are organized into five sets of services: communication services, support services, distribution services, semantic services, and access services. The Carnot architecture is shown in Figure 1.
Reference: [DDO96] <author> A. Dogac, C. Dengi, </author> <title> and M.T. Ozsu. Building Interoperable Databases on Distributed Object Management Platforms. </title> <note> Communication of ACM (to appear), </note> <year> 1996. </year>
Reference-contexts: Decision on relevant source selection is based on the InfoSleuth ontology, a body of metadata that describes agents' knowledge and their relationships with one another. 4.6 MIND The METU INteroperable DBMS (MIND) <ref> [DDO96] </ref> is an implemented mul-tidatabase system that supports integrated access to multiple heterogeneous and autonomous databases. MIND can access Oracle 7, Sybase, Adabas and MOOD, a home grown OODB developed at METU, Turkey. The canonical data model and query language of MIND are object-oriented.
Reference: [EDNO96] <author> C. Evrendilek, A. Dogac, S. Nural, and F. Ozcan. </author> <title> Query Optimization in Multidatabase Systems. </title> <note> Journal of Distributed and Parallel Databases (to appear), </note> <year> 1996. </year>
Reference-contexts: Schema integration in MIND is performed by DBAs using an object definition language that allows specification of interfaces of objects in the global schema and how they relate to objects exported by various data sources. MIND also develops some query processing techniques, especially in global query optimization <ref> [EDNO96, ONK + 96] </ref>, including (1) cost-based global query optimization in case of data replication. This technique deals with site selection issues in cases when a subquery can be executed at more than one site. (2) cost-based inter-site join optimization.
Reference: [FZ96] <author> M. Franklin and S. </author> <title> Zdonik. </title> <journal> Dissemination-based information systems. IEEE Bulletin of the Technical Committee on Data Engineering, </journal> <volume> 19(3) </volume> <pages> 20-30, </pages> <month> Septem-ber </month> <year> 1996. </year>
Reference-contexts: One example of such technology is to combine and interleave the user-initiated, comprehensive search-based data delivery with the server-initiated dissemination of relevant information. In this section we describe a number of data delivery characteristics <ref> [FZ96] </ref> in terms of protocols, delivery modes, and delivery frequencies, and use these characteristics to discuss and compare several data delivery schemes. 3.1 Data Delivery Protocols Data delivery is defined as the process of delivering information from a set of information sources (servers) to a set of information consumers (clients). <p> The Broadcast mechanism delivers information to clients periodically. Clients who require access to a data item need to wait until the item appears. There are two typical types of broadcasting: selective broadcast (or so called multicast) and random broadcast <ref> [FZ96] </ref>. Selective broadcast delivers data to a list of known clients and is typically implemented through a router that maintains the list of recipients. Random broadcast, on the other hand, sends information over a medium on which the set of clients who can listen is not known a priori. <p> It is obvious that using broadcast is beneficial when multiple clients are interested in the same items. The tradeoffs of broadcast mechanisms depend upon the number of clients who have the commonality of interest and the volume of information that are of interest to a large number of clients <ref> [FZ96, AFZ97] </ref>. 8 Ling Liu, Ling Ling Yan, M. Tamer Ozsu 3.2 Data Delivery Modes With the rapid growth of the volume and variety of information available online, combined with the constant increase of information consumers, it is no longer efficient to use a single mode of data delivery. <p> Space limitation prevents us from being exhaustive. 4.1 Broadcast Disks Approach to Information Dissemination The broadcast disks approach <ref> [AAFZ95, AFZ97, FZ96] </ref> to information dissemination uses a periodic push-based data delivery with broadcast protocol. The broadcast disks paradigm is based on a cyclic broadcast of objects (e.g., pages) and a corresponding collection of client cache management techniques. 12 Ling Liu, Ling Ling Yan, M. <p> If we have two levels of disk frequency, say 2:1, data item A has a higher priority than data items B and C. Thus, a broadcast schedule would generate the following broadcasting pattern: "A, B, A, C, ..." <ref> [FZ96] </ref>. One of the difficulties in deciding how to structure a broadcast schedule is that the server must use its knowledge to reason about the needs of the clients who require disseminated data. Intelligent management of client caches is a key to solving this problem.
Reference: [Kea93] <author> W. Kim and et al. </author> <title> On resolving semantic heterogeneity in multidatabase systems. Distributed and Parallel Databases, </title> <type> 1(3), </type> <year> 1993. </year>
Reference-contexts: The mapping from each local schema to the global schema is often expressed in a common SQL-like language, such 4 Ling Liu, Ling Ling Yan, M. Tamer Ozsu as HOSQL in the Pegasus system [Aea91] or SQL/M in the UniSQL/M system <ref> [Kea93] </ref>. Although the enforcement of a single global schema through data integration yields full transparency for uniform access, component databases have much restricted autonomy, scalability and their evolution becomes difficult.
Reference: [LP97] <author> Ling Liu and Calton Pu. </author> <title> An adaptive object-oriented approach to integration and access of heterogeneous information sources. DISTRIBUTED AND PARALLEL DATABASES: </title> <journal> An International Journal, </journal> <volume> 5(2), </volume> <year> 1997. </year>
Reference-contexts: In other situations, there is a mix of user interface and application code. Finally, there are situations in which user interface code provides direct access to functionalities of one or more of the four services. 4.3 DIOM The DIOM project <ref> [LPL96, LP97] </ref> presents a concrete implementation of the mediator-based interoperability management infrastructure described in Section 2.2. Users may pose queries to DIOM on the fly, namely queries can be specified independently of the structure, the content, or the existence of information sources. <p> The semantic attachment operations and the consumers' query profiles are the main techniques that are used for resolving semantics heterogeneity implied in the query results <ref> [LP97] </ref>. 4.4 DISCO DISCO, the Distributed Information Search COmponent [TRV96, TRV97], adopts the general mediator-based paradigm, and can be seen as another concrete instance of the mediator-based approach. The DISCO mediator data model is based on ODMG-93 data model specification.
Reference: [LPBZ96] <author> Ling Liu, Calton Pu, R. Barga, and T. Zhou. </author> <title> Differential evaluation of continual queries. </title> <booktitle> In IEEE Proceedings of the 16th International Conference on Distributed Computing Systems, </booktitle> <address> Hong Kong, </address> <month> May 27-30 </month> <year> 1996. </year>
Reference-contexts: When new data items are created or existing ones are updated, the servers (information providers) publish the updated information to the subscribers whose profiles match the items. 3.2.3 Hybrid Mode. The hybrid mode of data delivery combines the client-pull and server-push mechanisms. The continual query approach described in <ref> [LPBZ96] </ref> presents one possible way of combining the pull and push modes, namely, the transfer of information from servers to clients is first initiated by a client pull and the subsequent transfer of updated information to clients is initiated by a server push. <p> In addition to Broadcast Disks project which implements a push-based data delivery system with broadcast protocol, all the others are pull-only data delivery systems, although the DIOM project has developed techniques for supporting continual queries <ref> [LPBZ96] </ref>, which use hybrid mode of data delivery with publish/subscribe protocol. Table 2 shows a brief comparison of these systems with respect to the variety of data delivery capabilities. Table 2.
Reference: [LPL96] <author> L. Liu, C. Pu, and Y. Lee. </author> <title> An adaptive approach to query mediation across heterogeneous databases. </title> <booktitle> In Proceedings of the International Conference on Coopertive Information Systems, </booktitle> <address> Brussels, </address> <month> June 19-21 </month> <year> 1996. </year>
Reference-contexts: In other situations, there is a mix of user interface and application code. Finally, there are situations in which user interface code provides direct access to functionalities of one or more of the four services. 4.3 DIOM The DIOM project <ref> [LPL96, LP97] </ref> presents a concrete implementation of the mediator-based interoperability management infrastructure described in Section 2.2. Users may pose queries to DIOM on the fly, namely queries can be specified independently of the structure, the content, or the existence of information sources.
Reference: [Man92] <editor> F. Manola et al. </editor> <title> Distributed Object Management. </title> <journal> International Journal of Intelligent and Cooperative Information Systems, </journal> <volume> 1(1), </volume> <month> March </month> <year> 1992. </year>
Reference-contexts: With the MIND approach, the interface of Person objects is not known to the ORB. The fact that MIND does not allow registration of fine-granularity objects makes MIND different from the distributed object management approach towards database interoperability as described in <ref> [Man92] </ref>, where all objects in all databases form an object space that is accessible via the ORB. The way MIND uses CORBA is largely as a sophisticated communication 20 Ling Liu, Ling Ling Yan, M.
Reference: [Mea92] <editor> F. Manola and et al. </editor> <title> Distributed object management. </title> <journal> International Journal of Intelligent and Cooperative Information Systems, </journal> <volume> 1(1), </volume> <month> March </month> <year> 1992. </year>
Reference-contexts: The heterogeneity problems are resolved at the schema integration stage. This approach cannot scale well when new sources need to be added into an existing multidatabase system. Also the component schemas cannot evolve without the consent from the integrated schema. The distributed object management approach <ref> [Mea92, ODV93] </ref> generalizes the federated approach by modeling heterogeneous databases of different levels of granularity as objects in a distributed object space. It requires the definition of a common object model and a common object query language.
Reference: [ODV93] <author> T. Ozsu, U. Dayal, and P. Valduriez. </author> <title> Distributed Object Management. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1993. </year>
Reference-contexts: The heterogeneity problems are resolved at the schema integration stage. This approach cannot scale well when new sources need to be added into an existing multidatabase system. Also the component schemas cannot evolve without the consent from the integrated schema. The distributed object management approach <ref> [Mea92, ODV93] </ref> generalizes the federated approach by modeling heterogeneous databases of different levels of granularity as objects in a distributed object space. It requires the definition of a common object model and a common object query language.
Reference: [ONK + 96] <author> F. Ozcan, S. Nural, P. Koksal, C. Evrendilek, and A. Dogac. </author> <title> Dynamic Query Optimization on a Distributed Object Management Platform. </title> <booktitle> In Proceedings of Fifth International Conference on Information and Knowledge Management (CIKM), </booktitle> <address> Maryland, USA, </address> <year> 1996. </year>
Reference-contexts: Schema integration in MIND is performed by DBAs using an object definition language that allows specification of interfaces of objects in the global schema and how they relate to objects exported by various data sources. MIND also develops some query processing techniques, especially in global query optimization <ref> [EDNO96, ONK + 96] </ref>, including (1) cost-based global query optimization in case of data replication. This technique deals with site selection issues in cases when a subquery can be executed at more than one site. (2) cost-based inter-site join optimization.
Reference: [PAGM96] <author> Y. Papakonstantinou, S. Abiteboul, and H. Garcia-Molina. </author> <title> Object Fusion in Mediator Systems. </title> <booktitle> In VLDB 96, </booktitle> <address> Bombay, India, </address> <month> September </month> <year> 1996. </year>
Reference-contexts: This technique is still cost-based but is dynamic in that it uses partial results at run time, do some cost estimation and determine the next step. This approach reduces uncertainties in cost estimation. 4.7 TSIMMIS The TSIMMIS project at Stanford [PGMW95] [PGGMU95] [PGMU96] <ref> [PAGM96] </ref> represents a big step away from most previous work. Rather than a semantically rich, structured data model, TSIMMIS uses a self-describing model, the Object Exchange Model (OEM) for expressing integration and for querying. <p> In [PGGMU95], an approach for developing OEM wrappers for semi- or unstructured data sources is described. In [PGMU96], an OEM-based mediation language and its implementation is described. This language allows creation of integrated views in the mediator that removes various types of semantic conflicts. In <ref> [PAGM96] </ref>, an approach for object matching (referred to as object fusion in 22 Ling Liu, Ling Ling Yan, M. Tamer Ozsu this paper) using OEM is described. This approach allows resolution of instance level conflicts. An approach for global optimization of queries posed against these "fused" object is also described.
Reference: [PGGMU95] <author> Y. Papakonstantinou, A. Gupta, H. Garcia-Molina, and J. </author> <note> Ullman. </note>
Reference-contexts: This technique is still cost-based but is dynamic in that it uses partial results at run time, do some cost estimation and determine the next step. This approach reduces uncertainties in cost estimation. 4.7 TSIMMIS The TSIMMIS project at Stanford [PGMW95] <ref> [PGGMU95] </ref> [PGMU96] [PAGM96] represents a big step away from most previous work. Rather than a semantically rich, structured data model, TSIMMIS uses a self-describing model, the Object Exchange Model (OEM) for expressing integration and for querying. <p> This view can then be queried. Query processing in TSIMMIS leverages deductive database techniques; it includes view expansion and execution plan generation. In [PGMW95], various aspects of the OEM model are defined and discussed. In <ref> [PGGMU95] </ref>, an approach for developing OEM wrappers for semi- or unstructured data sources is described. In [PGMU96], an OEM-based mediation language and its implementation is described. This language allows creation of integrated views in the mediator that removes various types of semantic conflicts. <p> It must be possible to "talk" to the data source. A wrapper is used to remove idiosyncrasies of the data source. 2. Semantic integration. Scalability requires that both steps be performed rapidly. For 1, this requires rapid, if not automatic, wrapper generation. Various enabling techniques have already been developed <ref> [PGGMU95] </ref>. Much is known about how 2 can be done; the scalability aspect of it has not been well addressed. The traditional approach is to derive an integrated view from all the data sources in a monolithic integration specification.
References-found: 21

