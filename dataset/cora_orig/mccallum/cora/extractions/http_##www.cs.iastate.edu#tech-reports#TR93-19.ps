URL: http://www.cs.iastate.edu/tech-reports/TR93-19.ps
Refering-URL: http://www.cs.iastate.edu/tech-reports/catalog.html
Root-URL: 
Title: Static Analysis of Cache Performance for Real-Time Programming TR93-19  
Author: Jai Rawat 
Address: 226 Atanasoff Ames, IA 50011  
Affiliation: Iowa State University of Science and Technology Department of Computer Science  
Date: November 17, 1993  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> J. L. Hennessy and D. A. Patterson, </author> <title> Computer Architecture: A Quantitative Approach, </title> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <year> 1990. </year>
Reference-contexts: To assume that no memory operations hit the system caches underestimates actual system performance by a factor of ten or more <ref> [1] </ref>. It is therefore very desirable to be able to predict the cache hit rates of real-time tasks. 1 The term task is used to denote a piece of code in any language throughout this paper. <p> For a fully associative cache, S = 1 and A = N . * Replacement policy Our analysis supports only Random replacement policy. The current trend in computer architecture is to use random replacement policy as it is straightforward to implement and provides reasonably good performance <ref> [1] </ref>. Other replacement policies involve a large run-time overhead in terms of bookkeeping and are difficult to analyze statically. If explicit cache control is available (e.g. a cache flush instruc tion), our analysis uses this control to improve the accuracy of prediction. <p> Rather, our 37 analysis simply assumes that all loops execute ten times. This restriction will be removed in the near future. Target Machine: DLX DLX (pronounced "Deluxe") is a simple load/store machine <ref> [1] </ref>. Like most recent load/store machines, DLX emphasizes * A simple load/store instruction set * Design for pipeline efficiency * An easily decoded instruction set * Efficiency as a compiler target DLX represents recent RISC machines and provides a good architectural model for study.
Reference: [2] <author> A. C. Shaw and P. Y. Chang, </author> <title> A Source-Level Tool for Predicting Deterministic Execution Times of Programs, </title> <institution> University of Washington Seattle Technical Report # 89-09-12. </institution>
Reference-contexts: RELATED WORK The importance of execution time prediction for real-time systems can not be over-emphasized. Many researchers have attempted to develop tools for predicting the worst-case times required to execute a task. Park and Shaw have developed a source-level tool for predicting deterministic execution times of programs <ref> [2] </ref>. Their tool is based on formal timing schema that are defined for each source level construct (procedures, statements, expressions). The tool accepts a program written in a subset of C and iteration bounds for each loop, and produces predictions for best-case and worst-case execution times.
Reference: [3] <author> A. Mok, P. Amerasinghe, M. Chen and K. Tantisirivat, </author> <title> Evaluating Tight Execution Time Bounds of Programs by Annotations, </title> <booktitle> Sixth IEEE Workshop on Real-Time Operating Systems and Software, </booktitle> <month> May </month> <year> 1989, </year> <pages> 272-279. </pages>
Reference-contexts: Furthermore, these experimental results are based on a MC68010 processor with no cache. Also, since analysis focuses on source code, the technique does not fully account for compile-time optimizations. Mok has also developed tools for the prediction of worst-case execution time of a task <ref> [3] </ref>. His tool operates at the assembly-language level but does not deal with caching. Recently, many experimental languages have been proposed which provide constructs to specify real-time constraints.
Reference: [4] <author> D. B. Kirk, </author> <title> SMART Cache Design for Predictable Muti-Processing, </title> <booktitle> Workshop on Architecture Aspects of Real-Time Systems at the Real-Time Systems Symposium, </booktitle> <address> San Antonio, TX, </address> <month> Dec. </month> <year> 1991. </year>
Reference-contexts: Either they assume there is no cache, or they assume the worst possible caching scenario. The few researchers who have addressed cache performance issues in real-time systems have generally suggested new cache designs or caching policies <ref> [4, 5] </ref>. But present real-time applications must run on systems with traditional caches. Thus, it is desirable to develop techniques for worst-case cache performance analysis of systems that use traditional cache designs. Surprisingly, existing literature does not address static analysis of cache performance in real-time systems.
Reference: [5] <author> H. T. Lin and W. S. Liou, </author> <title> Using Cache to Improve Task Schedulability in Hard Real-Time Systems, </title> <booktitle> Workshop on Architecture Aspects of Real-Time Systems at the Real-Time Systems Symposium, </booktitle> <address> San Antonio, TX, </address> <month> Dec. </month> <year> 1991. </year> <month> 53 </month>
Reference-contexts: Either they assume there is no cache, or they assume the worst possible caching scenario. The few researchers who have addressed cache performance issues in real-time systems have generally suggested new cache designs or caching policies <ref> [4, 5] </ref>. But present real-time applications must run on systems with traditional caches. Thus, it is desirable to develop techniques for worst-case cache performance analysis of systems that use traditional cache designs. Surprisingly, existing literature does not address static analysis of cache performance in real-time systems.
Reference: [6] <author> F. C. Chow and J. L. Hennessy, </author> <title> The Priority-Based Coloring Approach to Register Allocation, </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 12, </volume> <month> 4 (Oct. </month> <year> 1990), </year> <pages> 501-536. </pages>
Reference-contexts: The analysis then uses data-flow analysis techniques to predict the maximum number of cache misses for the given code segment. Our technique is similar to the priority-based coloring approach to register allocation used by Chow and Hennessy <ref> [6] </ref>. The problem of register allocation is to determine which variables can be assigned registers. The first step is to identify the variables with overlapping lifetimes. The second step actually allocates registers to variables such that no variables with overlapping lifetimes use the same register.
Reference: [7] <author> A. V. Aho, R. Sethi and J. D. Ullman, </author> <booktitle> Compilers: Principles, Techniques, and Tools, </booktitle> <publisher> Addison-Wesley Publishing Company, </publisher> <year> 1988. </year>
Reference-contexts: Section 3:0:3 discusses the grouping algorithm in detail. Two live ranges lrM ax (v) and lrM in (v) are computed for each variable v. The process involves solving separately for the live and reaching data-flow attributes. We use data-flow analysis <ref> [7] </ref> to compute these attributes. The live attribute is solved by backward iteration through the control-flow graph. A variable is live at block i if there is a possible reference of the variable at either block i or at some point leading from block i. <p> But if a live range contains only part of a loop, the number of potential cache misses is equal to the number of times the corresponding loop executes. Assuming only natural loops <ref> [7] </ref>, a block can be a part of more than one loop only if the loops are nested. <p> This information is not always available. 31 References to unknown memory locations are called ambiguous references <ref> [7] </ref>. The most usual form of ambiguous reference is the use of a pointer. For example, the assignment y = flq represents a reference to x only if q points to x. This section describes our handling of ambiguous references. <p> The other primary source of inaccuracies is ambiguous references. Currently we assume that an ambiguous reference can reference any variable. This assumption is overly conservative. More careful tracing of ambiguous references <ref> [7] </ref> could reduce the set of variables each ambiguous reference might access. Given this, we could construct one live range for each set of ambiguous references sharing the same set of possible references.
Reference: [8] <author> C. W. Fraser and D. R. Hanson, </author> <title> A Code Generation Interface for ANSI C, </title> <note> Research Report CS-TR-270-90, </note> <month> July </month> <year> 1990. </year>
Reference-contexts: It is a popular model for experimental research. We introduced a cache flush instruction into the DLX instruction set which allowed us to test our results with explicit cache control. Compiler: lcc We modified the back end of lcc <ref> [8, 9] </ref> to generate code for the DLX architecture. lcc is a retargetable compiler for ANSI C which is smaller and faster than most other C compilers. We chose lcc because it has a target-independent front end so we only had to modify the back end.
Reference: [9] <author> C. W. Fraser and D. R. Hanson, </author> <title> A Retargetable Compiler for ANSI C, </title> <journal> SIGPLAN Notices, </journal> <volume> 26, </volume> <month> 10 (Oct. </month> <year> 1991), </year> <pages> 29-43. </pages>
Reference-contexts: It is a popular model for experimental research. We introduced a cache flush instruction into the DLX instruction set which allowed us to test our results with explicit cache control. Compiler: lcc We modified the back end of lcc <ref> [8, 9] </ref> to generate code for the DLX architecture. lcc is a retargetable compiler for ANSI C which is smaller and faster than most other C compilers. We chose lcc because it has a target-independent front end so we only had to modify the back end.
Reference: [10] <author> R. E. Grisworld and M. T. Grisworld, </author> <title> The Icon Programming Language, </title> <publisher> Prentice-Hall, Inc., </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1983. </year>
Reference: [11] <author> B. W. Kernighan and D. M. Ritchie, </author> <title> The C Programming Language, </title> <publisher> Prentice-Hall, Inc., </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1978. </year>
Reference: [12] <author> A. C. Shaw, </author> <title> Reasoning About Time in Higher-Level Language Software, </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 13, </volume> <month> 7 (July </month> <year> 1989), </year> <pages> 875-889. </pages>
Reference: [13] <author> P. Puschner and Ch. Koza, </author> <title> Calculating the Maximum Execution Time of Real-Time Programs, </title> <journal> The Journal of Real-Time Systems, </journal> <volume> 1 (1989), </volume> <pages> 159-176. </pages>
Reference: [14] <author> C. Y. Park and A. C. Shaw, </author> <title> Experiments with a Program Timing Tool Based on a Source Level Timing Schema, </title> <booktitle> IEEE Computer, </booktitle> <month> May </month> <year> 1991, </year> <pages> 48-56. 54 </pages>
Reference: [15] <author> K. B. Kenny and K. Lin, </author> <title> A measurement-based performance analyzer for real-time programs, </title> <institution> University of Illinois at Urbana-Champaign Report UIUCDCS-R-90-1606, </institution> <year> 1990. </year>
Reference: [16] <author> K. B. Kenny and K. Lin, </author> <title> Building Flexible Real-Time Systems Using the Flex Language, </title> <booktitle> IEEE Computer, </booktitle> <month> May </month> <year> 1991, </year> <pages> 70-78. </pages>
Reference: [17] <author> B. Cogswell and Z. Segall, </author> <title> MACS: A Predictable Architecture for Real-Time Systems, </title> <booktitle> Proceedings of the Twelfth Real-Time Systems Symposium, </booktitle> <address> San Antonio, TX, </address> <month> Dec. </month> <year> 1991, </year> <pages> 296-305. </pages>
References-found: 17

