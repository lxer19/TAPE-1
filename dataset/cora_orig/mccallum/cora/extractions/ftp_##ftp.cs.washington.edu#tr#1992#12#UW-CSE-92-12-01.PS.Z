URL: ftp://ftp.cs.washington.edu/tr/1992/12/UW-CSE-92-12-01.PS.Z
Refering-URL: http://www.cs.washington.edu/research/tr/tr-by-title.html
Root-URL: 
Title: Bounds on Sample Space Size for Matrix Product Verification  
Author: Donald D. Chinn Rakesh K. Sinha 
Date: November 28, 1992  
Address: Seattle, Washington, U.S.A. 98195  
Affiliation: Department of Computer Science and Engineering, FR-35 University of Washington  
Abstract: We show that the size of any sample space that could be used in Freivalds' probabilistic matrix product verification algorithm for n fi n matrices is at least n1 * if the error probability is at most *. We also provide a characterization of any sample space for which Freivalds' algorithm has error probability at most *. We then provide a generalization of Freivalds' algorithm and provide matching lower and upper bounds on the error probability in terms of the sample space size and running time.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> N. Alon, O. Goldreich, J. H-astad, and R. Peralta. </author> <title> Simple constructions of almost k-wise independent random variables. </title> <booktitle> In 31st Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 544-553, </pages> <address> St. Louis, MO, </address> <month> October </month> <year> 1990. </year> <note> IEEE. </note>
Reference-contexts: They gave two constructions, both of which achieve constant error probability. Their first construction is of size O (n) but works only for matrices over GF (2). The second construction works for matrices over an arbitrary ring but is of fi (n 2 ) size. Alon et al. <ref> [1] </ref> gave three constructions for the case of matrices over GF (2). The sample spaces they constructed are each of size ( n 2*1 ) 2 , where * is the error probability of Algorithm 2. <p> Can we find a smaller S such that Algorithm 2 works? For example, can we use a pseudorandom number generator that uses o (log 2 n) random bits, such as the almost k-wise generators of Naor and Naor [8], Alon et al. <ref> [1] </ref>, and Even et al. [3], to generate the n-vectors of S for Algorithm 2 and still achieve an O (n 2 ) running time? Section 2 answers this last question in the negative by providing a lower bound on the size of the sample space in terms of the error
Reference: [2] <author> D. Coppersmith and S. Winograd. </author> <title> Matrix multiplication via arithmetic progressions. </title> <journal> Journal of Symbolic Computation, </journal> <volume> 9 </volume> <pages> 251-280, </pages> <year> 1990. </year>
Reference-contexts: Contrast this with the best known deterministic algorithm for matrix product verification, which performs matrix multiplication on A and B. Multiplication of two n fi n matrices takes O (n 2:376 ) steps <ref> [2] </ref>. Instead of choosing v from the set f0; 1g n , let us allow step 1 of Algorithm 1 to choose v from an arbitrary set of n-vectors S. (Throughout this paper, we use vector to mean a tuple of elements from D.) Algorithm 2 1.
Reference: [3] <author> G. Even, O. Goldreich, M. Luby, N. Nisan, and B. Velickovic. </author> <title> Approximations of general independent distributions. </title> <booktitle> In Proceedings of the Twenty Fourth Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 10-16, </pages> <address> Victoria, BC, Canada, </address> <month> May </month> <year> 1992. </year>
Reference-contexts: Can we find a smaller S such that Algorithm 2 works? For example, can we use a pseudorandom number generator that uses o (log 2 n) random bits, such as the almost k-wise generators of Naor and Naor [8], Alon et al. [1], and Even et al. <ref> [3] </ref>, to generate the n-vectors of S for Algorithm 2 and still achieve an O (n 2 ) running time? Section 2 answers this last question in the negative by providing a lower bound on the size of the sample space in terms of the error probability.
Reference: [4] <author> R. Freivalds. </author> <title> Fast probabilistic algorithms. </title> <booktitle> In Mathematical Foundations of Computer Science: Proceedings, 8th Symposium, volume 74 of Lecture Notes in Computer Science, </booktitle> <pages> pages 57-69. </pages> <publisher> Springer-Verlag, </publisher> <year> 1979. </year> <month> 10 </month>
Reference-contexts: We are assuming that all our matrices are over some integral domain D. A probabilistic algorithm with one-sided error solves the matrix product verification problem if it rejects with probability 1 if AB = C, and accepts with probability at least 1 2 if Freivalds' <ref> [4] </ref> original matrix product verification algorithm is to choose a v 2 f0; 1g n from the 2 n possible n-vectors and test whether (AB)v = Cv.
Reference: [5] <author> I. N. Herstein. </author> <title> Topics in Algebra. </title> <publisher> John Wiley & Sons, </publisher> <address> second edition, </address> <year> 1975. </year>
Reference-contexts: Let D be an integral domain. A D-module is like a vector space except that the scalars are from D, which is not necessarily a field. See <ref> [5] </ref> for a more careful and general definition. (Modules are in general defined for rings.) Definition 13: Let M be a D-module. Let v 1 ; : : : ; v r 2 M .
Reference: [6] <author> T. Kimbrel and R. K. Sinha. </author> <title> A probabilistic algorithm for verfiying matrix products using O(n 2 ) time and log 2 n + O(1) random bits. </title> <type> Technical Report TR 91-08-06, </type> <institution> University of Washington Department of Computer Science and Engineering, </institution> <month> August </month> <year> 1991. </year> <note> To appear in Information Processing Letters. </note>
Reference-contexts: Alon et al. [1] gave three constructions for the case of matrices over GF (2). The sample spaces they constructed are each of size ( n 2*1 ) 2 , where * is the error probability of Algorithm 2. Kimbrel and Sinha <ref> [6] </ref> constructed a sample space of size l * such that the error probability for Algorithm 2 is no more than *. <p> Algorithm 3 still runs in O (n 2 ) time with error probability at most *, yet uses only dlog 2 (n 1)e + l * ) random bits <ref> [6, Theorem 5] </ref>. In particular, if * = 1 2 , then Algorithm 3 uses only dlog 2 (n 1)e + 1 random bits. <p> Here we give an explicit algorithm that achieves this error probability. We assume that the elements of our matrices are from an integral domain that has at least r elements. For the special case of small prime fields GF (p), we can use techniques similar to Kimbrel and Sinha <ref> [6, Section 4] </ref> to achieve the same error probability by increasing the running time by a factor of log p r.
Reference: [7] <author> John D. Lipson. </author> <title> Elements of Algebra and Algebraic Computing. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1981. </year>
Reference-contexts: Since m is non-zero, at least one of these polynomials is non-zero. Since each of these polynomials has degree at most q 1, there are at most q 1 values of l for which all these equations are satisfied <ref> [7, Theorem 2, Section IV.3.3] </ref>. The running time of the algorithm is O (n 2 w), since t = P Corollary 12: If wr n * , then there is a choice of W of cardinality w such that the error probability of Algorithm 4 is at most *. <p> Let D be an integral domain. The field of quotients of D, denoted Q (D), bears the same relation to D as the field of rational numbers to the integral domain of integers. See <ref> [7, Section IV.2.2] </ref> for a precise definition. Elements of Q (D) can be represented by a pair of elements (a; b) from D, where b is non-zero, and a is zero if and only if the element represented in Q (D) is zero.
Reference: [8] <author> J. Naor and M. Naor. </author> <title> Small-bias probability spaces: efficient constructions and applications. </title> <booktitle> In Proceedings of the Twenty Second Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 213-223, </pages> <address> Baltimore, MD, </address> <month> May </month> <year> 1990. </year> <month> 11 </month>
Reference-contexts: If we can find a smaller sample space S such that Algorithm 2 still has constant error probability then we can reduce the number of random bits needed to solve the matrix product verification problem. Naor and Naor <ref> [8] </ref> were the first to construct a polynomial size sample space for Algorithm 2. They gave two constructions, both of which achieve constant error probability. Their first construction is of size O (n) but works only for matrices over GF (2). <p> Can we find a smaller S such that Algorithm 2 works? For example, can we use a pseudorandom number generator that uses o (log 2 n) random bits, such as the almost k-wise generators of Naor and Naor <ref> [8] </ref>, Alon et al. [1], and Even et al. [3], to generate the n-vectors of S for Algorithm 2 and still achieve an O (n 2 ) running time? Section 2 answers this last question in the negative by providing a lower bound on the size of the sample space in
References-found: 8

