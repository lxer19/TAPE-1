URL: http://www.cs.berkeley.edu/~remzi/Conferences/SOSP97/hac.ps.gz
Refering-URL: http://www.cs.berkeley.edu/~remzi/Conferences/SOSP97/
Root-URL: 
Email: fcastro,adya,liskov,andrug@lcs.mit.edu  
Title: HAC: Hybrid Adaptive Caching for Distributed Storage Systems  
Author: Miguel Castro Atul Adya Barbara Liskov Andrew C. Myers 
Address: 545 Technology Square, Cambridge, MA 02139  
Affiliation: MIT Laboratory for Computer Science,  
Date: October 1997  
Note: Appears in the Proceedings of the ACM Symposium on Operating System Principles (SOSP '97), Saint-Malo, France,  
Abstract: This paper presents HAC, a novel technique for managing the client cache in a distributed, persistent object storage system. HAC is a hybrid between page and object caching that combines the virtues of both while avoiding their disadvantages. It achieves the low miss penalties of a page-caching system, but is able to perform well even when locality is poor, since it can discard pages while retaining their hot objects. It realizes the potentially lower miss rates of object-caching systems, yet avoids their problems of fragmentation and high overheads. Furthermore, HAC is adaptive: when locality is good it behaves like a page-caching system, while if locality is poor it behaves like an object-caching system. It is able to adjust the amount of cache space devoted to pages dynamically so that space in the cache can be used in the way that best matches the needs of the application. The paper also presents results of experiments that indicate that HAC outperforms other object storage systems across a wide range of cache sizes and workloads; it performs substantially better on the expected workloads, which have low to moderate locality. Thus we show that our hybrid, adaptive approach is the cache management technique of choice for distributed, persistent object systems. 
Abstract-found: 1
Intro-found: 1
Reference: [AGLM95] <author> A. Adya, R. Gruber, B. Liskov, and U. Maheshwari. </author> <title> Efficient optimistic concurrency control using loosely synchronized clocks. </title> <booktitle> In ACM SIGMOD Int. Conf. on Management of Data, </booktitle> <pages> pages 23-34, </pages> <address> San Jose, CA, </address> <month> May </month> <year> 1995. </year>
Reference-contexts: The methods are implemented in a type-safe language called Theta [LCD + 94]. To speed up applications, client machines cache copies of persistent objects. Clients communicate with servers only to fetch pages or commit transactions; we use optimistic concurrency control <ref> [AGLM95, Gru97] </ref> to serialize transactions. <p> Good performance for a distributed object storage system requires good solutions for client cache management, storage management at servers, and concurrency control for transactions. Performance studies of our previous implementation, Thor-0, showed its techniques for server storage management [Ghe95] and concurrency control <ref> [AGLM95, Gru97] </ref> 2 worked well and therefore these were retained in Thor-1. 2.1 Servers Servers store objects on disk in pages and maintain a page cache in main memory to speedup client fetch requests. <p> This imposes an overhead of at least an extra 8 bytes per object for the LRU information, which increases the client cache miss rate and also increases hit times substantially by adding up to three extra processor cache misses per object access. HAC uses fine-grained concurrency control <ref> [AGLM95, Gru97] </ref> and some objects in a cached page may be invalidated (when they become stale) while the rest of the page remains valid. We set the usage of invalid objects to 0, which ensures their timely removal from the cache.
Reference: [Bis77] <author> P. B. Bishop. </author> <title> Computer systems with a very large address space and garbage collection. </title> <type> Technical Report MIT-LCS-TR-178, </type> <institution> MIT Lab for Computer Science, </institution> <month> May </month> <year> 1977. </year>
Reference-contexts: Orefs refer to objects at the same server; objects point to objects at other servers indirectly via surrogates. A surrogate is a small object that contains the identifier of the target object's server and its oref within that server; this is similar to designs proposed in <ref> [Bis77, Mos90, DLMM94] </ref>. Surrogates will not impose much penalty in either space or time, assuming the database can be partitioned among servers so that inter-server references are rare and are followed rarely; we believe these are realistic assumptions. Object headers are also 32 bits.
Reference: [Bla93] <author> M. </author> <title> Blaze. Caching in Large-Scale Distributed File Systems. </title> <type> Technical Report TR-397-92, </type> <institution> Princeton University, </institution> <month> Jan. </month> <year> 1993. </year>
Reference-contexts: In a configuration with a realistic hit rate of 23% (measured by Blaze <ref> [Bla93] </ref> in distributed file systems), the foreground replacement overheads in T1 and T1 would be 11% and 16% of the disk time alone.
Reference: [BOS91] <author> P. Butterworth, A. Otis, and J. Stein. </author> <title> The GemStone database management system. </title> <journal> Comm. of the ACM, </journal> <volume> 34(10) </volume> <pages> 64-77, </pages> <month> Oct. </month> <year> 1991. </year>
Reference-contexts: 1 Introduction In distributed persistent storage systems, servers provide persistent storage for information accessed by applications running at clients <ref> [LAC + 96, C + 89, WD94, LLOW91, BOS91] </ref>. This research was supported in part by DARPA contract DABT63-95-C-005, monitored by Army Fort Huachuca, and in part by DARPA contract N00014-91-J-4136, monitored by the Office of Naval Research. M. Castro is supported by a PRAXIS XXI fellowship.
Reference: [C + 89] <author> M. Carey et al. </author> <title> Storage management for objects in EXODUS. </title> <editor> In W. Kim and F. Lochovsky, editors, </editor> <title> Object-Oriented Concepts, Databases, and Applications. </title> <publisher> Addison-Wesley, </publisher> <year> 1989. </year>
Reference-contexts: 1 Introduction In distributed persistent storage systems, servers provide persistent storage for information accessed by applications running at clients <ref> [LAC + 96, C + 89, WD94, LLOW91, BOS91] </ref>. This research was supported in part by DARPA contract DABT63-95-C-005, monitored by Army Fort Huachuca, and in part by DARPA contract N00014-91-J-4136, monitored by the Office of Naval Research. M. Castro is supported by a PRAXIS XXI fellowship.
Reference: [C + 94a] <author> M. J. Carey et al. </author> <title> A Status Report on the OO7 OODBMS Benchmarking Effort. </title> <booktitle> In ACM Conf. on Object-Oriented Programming Systems, Languages, and Applications (OOPSLA), </booktitle> <pages> pages 414-426, </pages> <year> 1994. </year>
Reference-contexts: To analyze the sensitivity of HAC to different workloads, we also designed our own dynamic traversals of the OO7 database, which are similar to the multi-user OO7 benchmark <ref> [C + 94a] </ref>, but execute a more mixed set of operations.
Reference: [C + 94b] <author> M. J. Carey et al. </author> <title> Shoring up persistent applications. </title> <booktitle> In ACM SIGMOD Int. Conf. on Management of Data, </booktitle> <pages> pages 383-394, </pages> <address> Minneapolis, MN, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: GOM uses 96-bit pointers and has 12-byte per-object overheads at the server. Kemper and Kossmann [KK94] show that the cache management strategy used in GOM leads to a lower miss rate than the eager copying strategy used by object-caching systems <ref> [C + 94b, KK90, WD92, KGBW90] </ref> which fetch pages from the server. The eager copying strategy copies objects from the page buffer to the object buffer on first use and copies modified objects back to their home pages when a transaction commits.
Reference: [CAL97] <author> M. Castro, A. Adya, and B. Liskov. </author> <title> Lazy reference counting for transactional storage systems. </title> <type> Technical Report MIT-LCS-TM-567, </type> <institution> MIT Lab for Computer Science, </institution> <month> June </month> <year> 1997. </year>
Reference-contexts: Instead, reference counts are corrected lazily when a transaction commits, to account for the modifications performed during the transaction. This scheme is described in detail 3 in <ref> [CAL97] </ref>, where it is shown to have low overheads. In-cache pointers are 32 bits, which is the pointer size on most machines.
Reference: [CDN94] <author> M. J. Carey, D. J. DeWitt, and J. F. Naughton. </author> <title> The OO7 benchmark. </title> <type> Technical Report; Revised Version dated 7/21/1994 1140, </type> <institution> University of Wisconsin-Madison, </institution> <year> 1994. </year> <month> ftp://ftp.cs.wisc.edu/OO7. </month>
Reference-contexts: Section 4.5 analyzes the overall performance of our system, and Section 4.6 shows how it performs when objects are both read and written. 4.1 Experimental Setup Before presenting the analysis, we describe the experimental setup. Our workloads are based on the OO7 benchmark <ref> [CDN94] </ref>; this benchmark is intended to match the characteristics of many different CAD/CAM/CASE applications, but does not model any specific application. The OO7 database contains a tree of assembly objects, with leaves pointing to three composite parts chosen randomly from among 500 such objects. <p> In our implementation, the small database takes up 4.2 MB and the medium database takes up 37.8 MB. The objects in the databases are clustered into 8 KB pages using time of creation as described in the OO7 specification <ref> [CDN94] </ref>. The databases were stored by a server on a Seagate ST-32171N disk, with a peak transfer rate of 15.2 MB/s, an average read seek time of 9.4 ms, and an average rotational latency of 4.17 ms [Sea97]. The databases were accessed by a single client.
Reference: [CFZ94] <author> M. Carey, M. Franklin, and M. Zaharioudakis. </author> <title> Fine-Grained Sharing in a Page Server OODBMS. </title> <booktitle> In ACM SIGMOD Int. Conf. on Management of Data, </booktitle> <pages> pages 359-370, </pages> <month> may </month> <year> 1994. </year>
Reference-contexts: We set the usage of invalid objects to 0, which ensures their timely removal from the cache. In contrast, page-caching systems that use fine-grained concurrency control (e.g., adaptive callback locking <ref> [CFZ94] </ref>, which does concurrency control by adaptively locking either objects or pages) waste cache space holding invalid objects because they always cache full pages. 3.2.2 Frame Usage Computation We could implement replacement by evicting the objects with the lowest usage in the cache, but this approach may pick objects from a
Reference: [CK89] <author> E. E. Chang and R. H. Katz. </author> <title> Exploiting inheritance and structure semantics for effective clustering and buffering in an object-oriented dbms. </title> <booktitle> In ACM SIGMOD Int. Conf. on Management of Data, </booktitle> <pages> pages 348-357, </pages> <address> Portland, OR, </address> <month> May </month> <year> 1989. </year>
Reference-contexts: Page caching achieves low miss penalties because it is simple to fetch and replace fixed-size units; it can also achieve low miss rates provided clustering of objects into pages is good. However, it is not possible to have good clustering for all application access patterns <ref> [TN92, CK89, Day95] </ref>. Furthermore, access patterns may evolve over time, and reclustering will lag behind because effective clustering algorithms are very expensive [TN92] and are performed infrequently. <p> Chang and Katz <ref> [CK89] </ref> observed that real CAD applications had similar access patterns. Furthermore, it is also expensive to collect the statistics necessary to run good clustering algorithms and to reorganize the objects in the database according to the result of the algorithm [GKM96, MK94].
Reference: [CLFL95] <author> J. S. Chase, H. M. Levy, M. J. Feeley, and E. D. Lazowska. </author> <title> Sharing and protection in a single-address-space operating system. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 12(1) </volume> <pages> 271-307, </pages> <month> Feb. </month> <year> 1995. </year>
Reference-contexts: However, our server identifiers can be larger than 32 bits; the only impact on the system is that surrogates will be bigger. In contrast, most systems that support large address spaces use very large pointers, e.g., 64 <ref> [CLFL95, LAC + 96] </ref>, 96 [Kos95], or even 128-bit pointers [WD92].
Reference: [Cor69] <author> F. J. Corbato. </author> <title> A Paging Experiment with the Multics System, </title> <booktitle> in Festschrift: In Honor of P. M. Morse, </booktitle> <pages> pages 217-228. </pages> <publisher> MIT Press, </publisher> <year> 1969. </year>
Reference-contexts: We use a value of 20 for E (see Section 4.1). We add new members to the candidate set using a variant of the CLOCK algorithm <ref> [Cor69] </ref>. We organize the cache as a circular array of frames and maintain a primary scan pointer and N secondary scan pointers into this array; these pointers are equidistant from each other in the array.
Reference: [D + 90] <editor> O. Deux et al. </editor> <title> The story of O2. </title> <journal> IEEE Trans. on Knowledge and Data Engineering, </journal> <volume> 2(1) </volume> <pages> 91-108, </pages> <month> Mar. </month> <year> 1990. </year>
Reference: [Day95] <author> M. Day. </author> <title> Client cache management in a distributed object database. </title> <type> Technical Report MIT/LCS/TR-652, </type> <institution> MIT Laboratory for Computer Science, </institution> <year> 1995. </year>
Reference-contexts: Page caching achieves low miss penalties because it is simple to fetch and replace fixed-size units; it can also achieve low miss rates provided clustering of objects into pages is good. However, it is not possible to have good clustering for all application access patterns <ref> [TN92, CK89, Day95] </ref>. Furthermore, access patterns may evolve over time, and reclustering will lag behind because effective clustering algorithms are very expensive [TN92] and are performed infrequently. <p> To choose these values, we ran various hot traversals including static traversals T1 and T1-, the dynamic traversal with 80% of object accesses performed by T1 operations and 20% by T1 operations, and another very dynamic shifting traversal described by Day <ref> [Day95] </ref>. The experiments varied the cache sizes and the values of the parameters across the studied range reported in the table.
Reference: [DLMM94] <author> M. Day, B. Liskov, U. Maheshwari, and A. C. Myers. </author> <title> References to remote mobile objects in Thor. </title> <journal> ACM Letters on Programming Languages and Systems (LOPLAS), </journal> <pages> pages 115-126, </pages> <month> Mar. </month> <year> 1994. </year>
Reference-contexts: Orefs refer to objects at the same server; objects point to objects at other servers indirectly via surrogates. A surrogate is a small object that contains the identifier of the target object's server and its oref within that server; this is similar to designs proposed in <ref> [Bis77, Mos90, DLMM94] </ref>. Surrogates will not impose much penalty in either space or time, assuming the database can be partitioned among servers so that inter-server references are rare and are followed rarely; we believe these are realistic assumptions. Object headers are also 32 bits.
Reference: [Ghe95] <author> S. Ghemawat. </author> <title> The Modified Object Buffer: a Storage Man-amement Technique for Object-Oriented Databases. </title> <type> PhD thesis, </type> <institution> Massachusetts Institute of Technology, </institution> <year> 1995. </year>
Reference-contexts: Good performance for a distributed object storage system requires good solutions for client cache management, storage management at servers, and concurrency control for transactions. Performance studies of our previous implementation, Thor-0, showed its techniques for server storage management <ref> [Ghe95] </ref> and concurrency control [AGLM95, Gru97] 2 worked well and therefore these were retained in Thor-1. 2.1 Servers Servers store objects on disk in pages and maintain a page cache in main memory to speedup client fetch requests. <p> Earlier work [OS94, WD95] has shown that this leads to poor performance if it is necessary to immediately read the objects' pages from disk to install them in the database. We avoid this cost by using the modified object buffer (MOB) architecture <ref> [Ghe95] </ref>. The server maintains an in-memory MOB that holds the latest versions of objects modified by recent transactions. <p> Object-caching systems must ship modified objects to servers at commit time. This can lead to poor performance if it is necessary to immediately read the objects' pages from disk in order to install the objects in their pages. We avoid this performance problem using the modified object buffer architecture <ref> [Ghe95] </ref>, which allows these installations to be performed in the background. 5 Conclusions This paper has described a new technique for managing the client cache in a distributed persistent object system.
Reference: [GKM96] <author> C. Gerlhof, A. Kemper, and G. Moerkotte. </author> <title> On the cost of monitoring and reorganization of object bases for clustering. </title> <booktitle> Sigmod Record, </booktitle> <volume> 25(3) </volume> <pages> 22-27, </pages> <month> September </month> <year> 1996. </year>
Reference-contexts: Chang and Katz [CK89] observed that real CAD applications had similar access patterns. Furthermore, it is also expensive to collect the statistics necessary to run good clustering algorithms and to reorganize the objects in the database according to the result of the algorithm <ref> [GKM96, MK94] </ref>.
Reference: [GR93] <author> J. Gray and A. Reuter. </author> <title> Transaction Processing: Concepts and Techniques. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, California, </address> <year> 1993. </year>
Reference-contexts: We have found experimentally that R = 2=3 works well; Section 4.1 describes the sensitivity experiments we used to determine the value of R and other system parameters. HAC uses a no-steal <ref> [GR93] </ref> cache management policy, i.e., objects that were modified by a transaction cannot be evicted from the cache until the transaction commits. <p> For completeness, we now show results for traversals with updates. Figure 14 presents elapsed times for cold traversals T1, T2a and T2b of the medium database running with a 12 MB client cache. The figure also shows the time to commit the transactions. HAC uses a no-steal <ref> [GR93] </ref> cache management policy: modifications are sent to the server only when a transaction commits, and the modified objects cannot be evicted from the client cache until this happens.
Reference: [Gru97] <author> R. Gruber. </author> <title> Optimism vs. Locking: A Study of Concurrency Control for Client-Server Object-Oriented Databases. </title> <type> PhD thesis, </type> <institution> MIT, </institution> <month> Feb. </month> <year> 1997. </year>
Reference-contexts: The methods are implemented in a type-safe language called Theta [LCD + 94]. To speed up applications, client machines cache copies of persistent objects. Clients communicate with servers only to fetch pages or commit transactions; we use optimistic concurrency control <ref> [AGLM95, Gru97] </ref> to serialize transactions. <p> Good performance for a distributed object storage system requires good solutions for client cache management, storage management at servers, and concurrency control for transactions. Performance studies of our previous implementation, Thor-0, showed its techniques for server storage management [Ghe95] and concurrency control <ref> [AGLM95, Gru97] </ref> 2 worked well and therefore these were retained in Thor-1. 2.1 Servers Servers store objects on disk in pages and maintain a page cache in main memory to speedup client fetch requests. <p> This imposes an overhead of at least an extra 8 bytes per object for the LRU information, which increases the client cache miss rate and also increases hit times substantially by adding up to three extra processor cache misses per object access. HAC uses fine-grained concurrency control <ref> [AGLM95, Gru97] </ref> and some objects in a cached page may be invalidated (when they become stale) while the rest of the page remains valid. We set the usage of invalid objects to 0, which ensures their timely removal from the cache.
Reference: [JS94] <author> T. Johnson and D. Shasha. </author> <title> A low overhead high performance buffer replacement algorithm. </title> <booktitle> In Proceedings of International Conference on Very Large Databases, </booktitle> <pages> pages 439-450, </pages> <year> 1994. </year>
Reference-contexts: compaction based on their last computed usage; objects within the frame are retained or discarded based on how their usage compares to that of their frame. 3.2.1 Object Usage Computation It has been shown that cache replacement algorithms which take into account both recency and frequency of accesses - 2Q <ref> [JS94] </ref>, LRU-K [OOW93] and frequency-based replacement [RD90] can outperform LRU because they can evict recently used pages that are used infrequently. However, the algorithms that have been proposed so far have high space and time overheads.
Reference: [KGBW90] <author> W. Kim, J. F. Garza, N. Ballou, and D. Woelk. </author> <title> Architecture of the ORION next-generation database system. </title> <journal> IEEE Trans. on Knowledge and Data Engineering, </journal> <volume> 2(1) </volume> <pages> 109-124, </pages> <month> Mar. </month> <year> 1990. </year>
Reference-contexts: GOM uses 96-bit pointers and has 12-byte per-object overheads at the server. Kemper and Kossmann [KK94] show that the cache management strategy used in GOM leads to a lower miss rate than the eager copying strategy used by object-caching systems <ref> [C + 94b, KK90, WD92, KGBW90] </ref> which fetch pages from the server. The eager copying strategy copies objects from the page buffer to the object buffer on first use and copies modified objects back to their home pages when a transaction commits.
Reference: [KK90] <author> T. Kaehler and G. Krasner. </author> <booktitle> LOOMLarge Object-Oriented Memory for Smalltalk-80 Systems, </booktitle> <pages> pages 298-307. </pages> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <address> San Mateo, CA, </address> <year> 1990. </year>
Reference-contexts: It is not practical to represent object pointers as orefs in the client cache because each pointer dereference would require a table lookup to translate the name into the object's memory location. Therefore, clients perform pointer swizzling <ref> [KK90, Mos92, WD92] </ref>, i.e., replace the orefs in objects' instance variables by virtual memory pointers to speed up pointer traversals. HAC uses indirect pointer swiz-zling [KK90], i.e., the oref is translated to a pointer to an entry in an indirection table and the entry points to the target object. <p> Therefore, clients perform pointer swizzling [KK90, Mos92, WD92], i.e., replace the orefs in objects' instance variables by virtual memory pointers to speed up pointer traversals. HAC uses indirect pointer swiz-zling <ref> [KK90] </ref>, i.e., the oref is translated to a pointer to an entry in an indirection table and the entry points to the target object. <p> GOM uses 96-bit pointers and has 12-byte per-object overheads at the server. Kemper and Kossmann [KK94] show that the cache management strategy used in GOM leads to a lower miss rate than the eager copying strategy used by object-caching systems <ref> [C + 94b, KK90, WD92, KGBW90] </ref> which fetch pages from the server. The eager copying strategy copies objects from the page buffer to the object buffer on first use and copies modified objects back to their home pages when a transaction commits.
Reference: [KK94] <author> A. Kemper and D. Kossmann. </author> <title> Dual-buffer strategies in object bases. </title> <booktitle> In 20th Int. Conf. on Very Large Data Bases (VLDB), </booktitle> <pages> pages 427-438, </pages> <address> Santiago, Chile, </address> <year> 1994. </year>
Reference-contexts: However, object caching has two problems: objects are variable-sized units, which leads to storage fragmentation, and there are many more objects than pages, which leads to high overhead for bookkeeping and for maintaining per-object usage statistics. Dual buffering <ref> [KK94] </ref> partitions the client cache stati cally into a page cache and an object cache. <p> If instead F is freed, its copy of o is moved to P (if o is retained) instead of being compacted as usual. In either case, we avoid both extra work and foreground overhead. In contrast, the eager approach in <ref> [KK94] </ref> copies o into P when P is fetched; this increases the miss penalty because the object is copied in the foreground, and wastes effort if P is compacted soon after but o is not evicted. 3.2 Replacement Policy It is more difficult to achieve low space and time overheads in <p> We explain in Section 4.2.3 why experiments showing that HAC outperforms FPC allow us to conclude that it would do even better in a comparison with QuickStore. To show HAC achieves lower miss rates than dual-buffering systems, we compare its miss rate with that of GOM <ref> [KK94] </ref>, the dual-buffering system with the lowest miss rates in the literature. GOM partitions the client cache statically into object and page buffers, each managed using a perfect LRU replacement policy. <p> To reduce fragmentation, storage is managed using a buddy system. GOM's database is clustered (like ours) using time of creation. GOM uses 96-bit pointers and has 12-byte per-object overheads at the server. Kemper and Kossmann <ref> [KK94] </ref> show that the cache management strategy used in GOM leads to a lower miss rate than the eager copying strategy used by object-caching systems [C + 94b, KK90, WD92, KGBW90] which fetch pages from the server. <p> Since GOM partitions the client cache into object and page buffers statically, all data for GOM were obtained by manual tuning of the buffer sizes to achieve the best possible <ref> [KK94] </ref> performance; the sizes of the buffers were tuned for each cache size and for each traversal (e.g., tuning was different for T1 and T2b). The results for GOM were obtained from Kossmann [Kos97].
Reference: [Kos95] <author> D. Kossmann. </author> <title> Efficient Main-Memory Management of Persistent Objects. </title> <address> Shaker-Verlag, 52064 Aachen, Germany, </address> <year> 1995. </year> <type> PhD thesis, </type> <institution> RWTH Aachen. </institution>
Reference-contexts: However, our server identifiers can be larger than 32 bits; the only impact on the system is that surrogates will be bigger. In contrast, most systems that support large address spaces use very large pointers, e.g., 64 [CLFL95, LAC + 96], 96 <ref> [Kos95] </ref>, or even 128-bit pointers [WD92]. <p> Usage bits are much cheaper in both space and time than maintaining either an LRU chain or the data structures used by 2Q, LRU-K and frequency based replacement. For example, the system described in <ref> [Kos95] </ref> uses a doubly linked list to implement LRU. <p> We conservatively did not correct the cache sizes for HAC and HAC-BIG to account for our 16-byte indirection table entries because GOM uses a resident object table that introduces a 36-byte overhead for each object <ref> [Kos95, Kos97] </ref>. The most important point is that HAC-BIG outperforms GOM even though GOM's results required manual tuning of the sizes of the object and page buffers. Of course, in a real system, such tuning would not be possible, and a poor adjustment can hurt performance.
Reference: [Kos97] <author> D. Kossmann. </author> <title> Private communication. </title> <address> June 30, </address> <year> 1997. </year>
Reference-contexts: The results for GOM were obtained from Kossmann <ref> [Kos97] </ref>. We introduce HAC-BIG to separate the performance effects of smaller objects and better cache management, which in combination cause HAC to outperform GOM at all cache sizes. <p> We conservatively did not correct the cache sizes for HAC and HAC-BIG to account for our 16-byte indirection table entries because GOM uses a resident object table that introduces a 36-byte overhead for each object <ref> [Kos95, Kos97] </ref>. The most important point is that HAC-BIG outperforms GOM even though GOM's results required manual tuning of the sizes of the object and page buffers. Of course, in a real system, such tuning would not be possible, and a poor adjustment can hurt performance.
Reference: [LAC + 96] <author> B. Liskov, A. Adya, M. Castro, M. Day, S. Ghemawat, R. Gruber, U. Maheshwari, A. C. Myers, and L. Shrira. </author> <title> Safe and efficient sharing of persistent objects in Thor. </title> <booktitle> In ACM SIGMOD Int. Conf. on Management of Data, </booktitle> <pages> pages 318-329, </pages> <month> June </month> <year> 1996. </year>
Reference-contexts: 1 Introduction In distributed persistent storage systems, servers provide persistent storage for information accessed by applications running at clients <ref> [LAC + 96, C + 89, WD94, LLOW91, BOS91] </ref>. This research was supported in part by DARPA contract DABT63-95-C-005, monitored by Army Fort Huachuca, and in part by DARPA contract N00014-91-J-4136, monitored by the Office of Naval Research. M. Castro is supported by a PRAXIS XXI fellowship. <p> HAC maintains usage statistics on a per-object basis using a novel technique with low space and time overheads. The technique combines both recency and frequency information to make good replacement decisions. HAC has been incorporated in Thor-1, a new implementation of the Thor object database <ref> [LAC + 96] </ref>; it retains the server storage management and concurrency control techniques of our previous implementation, Thor-0, but uses HAC for client cache management. The high performance of Thor-1 is furthermore achieved by adherence to two design principles: think small, and be lazy. <p> However, our server identifiers can be larger than 32 bits; the only impact on the system is that surrogates will be bigger. In contrast, most systems that support large address spaces use very large pointers, e.g., 64 <ref> [CLFL95, LAC + 96] </ref>, 96 [Kos95], or even 128-bit pointers [WD92]. <p> The exception code line shows the cost introduced by code to generate or check for various types of exceptions (e.g., array bounds and integer overflow). This overhead is due to our implementation of the type-safe language Theta <ref> [LAC + 96] </ref>. The concurrency control checks line shows what we pay for providing transactions. <p> HAC-FG performs up to 61% faster than FPC-NO in this workload. We also compared the performance of Thor-1 with Thor-0, our previous implementation, which had been shown to outperform all other systems as long as the working set of a traversal fit in the client cache <ref> [LAC + 96] </ref>. We found that HAC enabled Thor-1 to outperform Thor-0 on all workloads, and to do substantially better on traversals where the working set did not fit in the client cache. 15 4.6 Traversals With Updates All the experiments we presented so far ran read-only traversals.
Reference: [LCD + 94] <author> B. Liskov, D. Curtis, M. Day, S. Ghemawhat, R. Gruber, P. Johnson, and A. C. Myers. </author> <title> Theta reference manual. Programming Methodology Group Memo 88, </title> <institution> MIT Lab. for Computer Science, </institution> <month> Feb. </month> <year> 1994. </year> <note> Also available at http://www.pmg.lcs.mit.edu/papers/thetaref/. </note>
Reference-contexts: Applications interact with Thor by calling methods of objects; these calls occur within atomic transactions. The methods are implemented in a type-safe language called Theta <ref> [LCD + 94] </ref>. To speed up applications, client machines cache copies of persistent objects. Clients communicate with servers only to fetch pages or commit transactions; we use optimistic concurrency control [AGLM95, Gru97] to serialize transactions.
Reference: [LLOW91] <author> C. Lamb, G. Landis, J. Orenstein, and D. Weinreb. </author> <title> The Ob-jectStore database system. </title> <journal> Comm. of the ACM, </journal> <volume> 34(10) </volume> <pages> 50-63, </pages> <month> Oct. </month> <year> 1991. </year>
Reference-contexts: 1 Introduction In distributed persistent storage systems, servers provide persistent storage for information accessed by applications running at clients <ref> [LAC + 96, C + 89, WD94, LLOW91, BOS91] </ref>. This research was supported in part by DARPA contract DABT63-95-C-005, monitored by Army Fort Huachuca, and in part by DARPA contract N00014-91-J-4136, monitored by the Office of Naval Research. M. Castro is supported by a PRAXIS XXI fellowship. <p> HAC could also be used within a server cache. In persistent object systems, objects are clustered in fixed-size pages on disk, and pages are much larger than most objects [Sta84]. Most systems manage the client cache using page caching <ref> [LLOW91, WD94, SKW92] </ref>: when a miss occurs, the client evicts a page from its cache and fetches the missing object's page from the server.
Reference: [MBMS95] <author> J. C. Mogul, J. F. Barlett, R. N. Mayo, and A. Srivastava. </author> <title> Performance Implications of Multiple Pointer Sizes. </title> <booktitle> In USENIX 1995 Tech. Conf. on UNIX and Advanced Computing Systems, </booktitle> <pages> pages 187-200, </pages> <address> New Orleans, LA, </address> <year> 1995. </year>
Reference-contexts: New versions are written to the MOB when transactions commit; when the MOB fills up, versions are written to their disk pages in the background. 2.2 Page and Object Format Keeping objects small at both servers and clients is important because it has a large impact on performance <ref> [WD94, MBMS95] </ref>. Our objects are small primarily because object references (or orefs) are only 32 bits. Orefs refer to objects at the same server; objects point to objects at other servers indirectly via surrogates.
Reference: [MK94] <author> W. J. McIver and R. King. </author> <title> Self adaptive, on-line recluster-ing of complex object data. </title> <booktitle> In ACM SIGMOD Int. Conf. on Management of Data, </booktitle> <pages> pages 407-418, </pages> <address> Minneapolis, MN, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: Chang and Katz [CK89] observed that real CAD applications had similar access patterns. Furthermore, it is also expensive to collect the statistics necessary to run good clustering algorithms and to reorganize the objects in the database according to the result of the algorithm <ref> [GKM96, MK94] </ref>.
Reference: [Mos90] <author> J. E. B. Moss. </author> <title> Design of the Mneme persistent object store. </title> <journal> ACM Transactions on Information Systems (TOIS), </journal> <volume> 8(2) </volume> <pages> 103-139, </pages> <month> Apr. </month> <year> 1990. </year> <month> 17 </month>
Reference-contexts: Orefs refer to objects at the same server; objects point to objects at other servers indirectly via surrogates. A surrogate is a small object that contains the identifier of the target object's server and its oref within that server; this is similar to designs proposed in <ref> [Bis77, Mos90, DLMM94] </ref>. Surrogates will not impose much penalty in either space or time, assuming the database can be partitioned among servers so that inter-server references are rare and are followed rarely; we believe these are realistic assumptions. Object headers are also 32 bits.
Reference: [Mos92] <author> J. E. B. Moss. </author> <title> Working with persistent objects: To swizzle or not to swizzle. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 18(3) </volume> <pages> 657-673, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: It is not practical to represent object pointers as orefs in the client cache because each pointer dereference would require a table lookup to translate the name into the object's memory location. Therefore, clients perform pointer swizzling <ref> [KK90, Mos92, WD92] </ref>, i.e., replace the orefs in objects' instance variables by virtual memory pointers to speed up pointer traversals. HAC uses indirect pointer swiz-zling [KK90], i.e., the oref is translated to a pointer to an entry in an indirection table and the entry points to the target object. <p> Both pointer swizzling and installation of objects, i.e., allocating an entry for the object in the indirection table, are performed lazily. Pointers are swizzled the first time they are loaded from an instance variable into a register <ref> [Mos92, WD92] </ref>; the extra bit in the oref is used to determine whether a pointer has been swizzled or not. Objects are installed in the indirection table the first time a pointer to them is swizzled. The size of an indirection table entry is 16 bytes.
Reference: [MS95] <author> M. McAuliffe and M. Solomon. </author> <title> A trace-based simulation of pointer swizzling techniques. </title> <booktitle> In Int. Conf. on Data Engineering (ICDE), </booktitle> <pages> pages 52-61, </pages> <month> Mar. </month> <year> 1995. </year>
Reference-contexts: Indirection allows HAC to move and evict objects from the client cache with low overhead; indirection has also been found to simplify page eviction in a page-caching system <ref> [MS95] </ref>. HAC uses a novel lazy reference counting mechanism to discard entries from the indirection table. The reference count in an entry is incremented whenever a pointer is swiz-zled and decremented when objects are evicted, but no reference count updates are performed when objects are modified.
Reference: [Ont92] <author> Ontos, Inc., Lowell, MA. </author> <title> Ontos Reference Manual, </title> <year> 1992. </year>
Reference: [OOW93] <author> E. J. O'Neil, P. E. O'Neil, and G. Weikum. </author> <title> The LRU-K page replacement algorithm for database disk buffering. </title> <booktitle> In ACM SIGMOD Int. Conf. on Management of Data, </booktitle> <pages> pages 297-306, </pages> <address> Washington, D.C., </address> <month> May </month> <year> 1993. </year>
Reference-contexts: on their last computed usage; objects within the frame are retained or discarded based on how their usage compares to that of their frame. 3.2.1 Object Usage Computation It has been shown that cache replacement algorithms which take into account both recency and frequency of accesses - 2Q [JS94], LRU-K <ref> [OOW93] </ref> and frequency-based replacement [RD90] can outperform LRU because they can evict recently used pages that are used infrequently. However, the algorithms that have been proposed so far have high space and time overheads. <p> The secondary pointers are used to ensure the timely eviction of uninstalled objects, i.e., objects that have not been used since their page was fetched into the cache. These objects are good candidates for eviction provided they have not been fetched too recently into the cache <ref> [OOW93, RD90] </ref>. The secondary pointers are used to find frames with a large number of uninstalled objects. For each secondary pointer, HAC determines the number of installed objects in S contiguous frames starting at that scan pointer and then advances the pointer by S.
Reference: [OS94] <author> J. O'Toole and L. Shrira. </author> <title> Opportunistic log: Efficient installation reads in a reliable object server. </title> <booktitle> In Proceedings of the Symp. on Operating System Design and Implementation (OSDI), </booktitle> <pages> pages 39-48, </pages> <address> Monterey, CA, </address> <year> 1994. </year>
Reference-contexts: Because client caches in HAC may hold objects without their containing pages, we must ship modified objects (and not their containing pages) to servers at commit time. Earlier work <ref> [OS94, WD95] </ref> has shown that this leads to poor performance if it is necessary to immediately read the objects' pages from disk to install them in the database. We avoid this cost by using the modified object buffer (MOB) architecture [Ghe95].
Reference: [OS95] <author> J. O'Toole and L. Shrira. </author> <title> Shared data management needs adaptive methods. </title> <booktitle> In Proceedings of IEEE Workshop on Hot Topics in Operating Systems, </booktitle> <address> Orcas Island, </address> <year> 1995. </year>
Reference-contexts: To our knowledge, HAC is the first adaptive caching system. O'Toole and Shrira <ref> [OS95] </ref> present a simulation study of an adaptive caching system, but they focus on avoiding reads to install modifications at servers and ignore storage management issues. HAC partitions the client cache into page frames and fetches entire pages from the server.
Reference: [RD90] <author> J. Robinson and N. Devarakonda. </author> <title> Data cache management using frequency-based replacement. </title> <booktitle> In Proceedings of ACM SIGMETRICS Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 134-142, </pages> <year> 1990. </year>
Reference-contexts: usage; objects within the frame are retained or discarded based on how their usage compares to that of their frame. 3.2.1 Object Usage Computation It has been shown that cache replacement algorithms which take into account both recency and frequency of accesses - 2Q [JS94], LRU-K [OOW93] and frequency-based replacement <ref> [RD90] </ref> can outperform LRU because they can evict recently used pages that are used infrequently. However, the algorithms that have been proposed so far have high space and time overheads. <p> Our decay rule is identical to the one used to decay reference counts in <ref> [RD90] </ref>, but its purpose is quite different. Usage bits are much cheaper in both space and time than maintaining either an LRU chain or the data structures used by 2Q, LRU-K and frequency based replacement. For example, the system described in [Kos95] uses a doubly linked list to implement LRU. <p> The secondary pointers are used to ensure the timely eviction of uninstalled objects, i.e., objects that have not been used since their page was fetched into the cache. These objects are good candidates for eviction provided they have not been fetched too recently into the cache <ref> [OOW93, RD90] </ref>. The secondary pointers are used to find frames with a large number of uninstalled objects. For each secondary pointer, HAC determines the number of installed objects in S contiguous frames starting at that scan pointer and then advances the pointer by S.
Reference: [Sea97] <institution> Seagate Technology, Inc. </institution> <note> http://www.seagate.com/, 1997. </note>
Reference-contexts: The databases were stored by a server on a Seagate ST-32171N disk, with a peak transfer rate of 15.2 MB/s, an average read seek time of 9.4 ms, and an average rotational latency of 4.17 ms <ref> [Sea97] </ref>. The databases were accessed by a single client. Both the server and the client ran on DEC 3000/400 Alpha workstations, each with a 133 MHz Alpha 21064 processor, 128 MB of memory and OSF/1 version 3.2.
Reference: [SKW92] <author> V. Singhal, S. V. Kakkad, and P. R. Wilson. </author> <title> Texas: An efficient, portable persistent store. </title> <booktitle> In 5th Int. Workshop on Persistent Object Systems (POS), </booktitle> <pages> pages 11-33, </pages> <address> San Miniato, Italy, </address> <month> Sept. </month> <year> 1992. </year>
Reference-contexts: HAC could also be used within a server cache. In persistent object systems, objects are clustered in fixed-size pages on disk, and pages are much larger than most objects [Sta84]. Most systems manage the client cache using page caching <ref> [LLOW91, WD94, SKW92] </ref>: when a miss occurs, the client evicts a page from its cache and fetches the missing object's page from the server.
Reference: [Sta84] <author> J. W. Stamos. </author> <title> Static grouping of small objects to enhance performance of a paged virtual memory. </title> <journal> ACM Trans. on Programming Languages and Systems (TOPLAS), </journal> <volume> 2(2) </volume> <pages> 155-180, </pages> <month> May </month> <year> 1984. </year>
Reference-contexts: HAC could also be used within a server cache. In persistent object systems, objects are clustered in fixed-size pages on disk, and pages are much larger than most objects <ref> [Sta84] </ref>. Most systems manage the client cache using page caching [LLOW91, WD94, SKW92]: when a miss occurs, the client evicts a page from its cache and fetches the missing object's page from the server.
Reference: [TN92] <author> M. Tsangaris and J. F. Naughton. </author> <title> On the performance of object clustering techniques. </title> <booktitle> In ACM SIGMOD Int. Conf. on Management of Data, </booktitle> <pages> pages 144-153, </pages> <address> San Diego, CA, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: Page caching achieves low miss penalties because it is simple to fetch and replace fixed-size units; it can also achieve low miss rates provided clustering of objects into pages is good. However, it is not possible to have good clustering for all application access patterns <ref> [TN92, CK89, Day95] </ref>. Furthermore, access patterns may evolve over time, and reclustering will lag behind because effective clustering algorithms are very expensive [TN92] and are performed infrequently. <p> However, it is not possible to have good clustering for all application access patterns [TN92, CK89, Day95]. Furthermore, access patterns may evolve over time, and reclustering will lag behind because effective clustering algorithms are very expensive <ref> [TN92] </ref> and are performed infrequently. Therefore, pages contain both hot objects, which are likely to be used by an application in the near future, and cold objects, which are not likely to be used soon. <p> Note that T6 accesses many fewer objects than the other traversals. In general, some traversals will match the database clustering well while others will not, and we believe that on average, one cannot expect traversals to use a large fraction of each page. For example, Tsangaris and Naughton <ref> [TN92] </ref> found it was possible to achieve good average use by means of impractical and expensive clustering algorithms; an O (n 2:4 ) algorithm achieved average use between 17% and 91% depending on the workload, while an O (n log n) algorithm achieved average use between 15% and 41% on the <p> These high costs bound the achievable frequency of reclusterings and increase the likelihood of mismatches between the current workload and the workload used to train the clustering algorithm; these mismatches can significantly reduce the fraction of a page that is used <ref> [TN92] </ref>. 8 The OO7 database clustering matches traversal T6 poorly but matches traversals T1, T2a and T2b well; our results show that on average T6 uses only 3% of each page whereas the other traversals use 49%.
Reference: [WD92] <author> S. White and D. DeWitt. </author> <title> A performance study of alternative object faulting and pointer swizzling strategies. </title> <booktitle> In 18th Int. Conf. on Very Large Data Bases (VLDB), </booktitle> <pages> pages 419-431, </pages> <address> Vancouver, British Columbia, </address> <month> Aug. </month> <year> 1992. </year>
Reference-contexts: However, our server identifiers can be larger than 32 bits; the only impact on the system is that surrogates will be bigger. In contrast, most systems that support large address spaces use very large pointers, e.g., 64 [CLFL95, LAC + 96], 96 [Kos95], or even 128-bit pointers <ref> [WD92] </ref>. <p> It is not practical to represent object pointers as orefs in the client cache because each pointer dereference would require a table lookup to translate the name into the object's memory location. Therefore, clients perform pointer swizzling <ref> [KK90, Mos92, WD92] </ref>, i.e., replace the orefs in objects' instance variables by virtual memory pointers to speed up pointer traversals. HAC uses indirect pointer swiz-zling [KK90], i.e., the oref is translated to a pointer to an entry in an indirection table and the entry points to the target object. <p> Both pointer swizzling and installation of objects, i.e., allocating an entry for the object in the indirection table, are performed lazily. Pointers are swizzled the first time they are loaded from an instance variable into a register <ref> [Mos92, WD92] </ref>; the extra bit in the oref is used to determine whether a pointer has been swizzled or not. Objects are installed in the indirection table the first time a pointer to them is swizzled. The size of an indirection table entry is 16 bytes. <p> GOM uses 96-bit pointers and has 12-byte per-object overheads at the server. Kemper and Kossmann [KK94] show that the cache management strategy used in GOM leads to a lower miss rate than the eager copying strategy used by object-caching systems <ref> [C + 94b, KK90, WD92, KGBW90] </ref> which fetch pages from the server. The eager copying strategy copies objects from the page buffer to the object buffer on first use and copies modified objects back to their home pages when a transaction commits.
Reference: [WD94] <author> S. J. White and D. J. DeWitt. </author> <title> QuickStore: A high performance mapped object store. </title> <booktitle> In ACM SIGMOD Int. Conf. on Management of Data, </booktitle> <pages> pages 395-406, </pages> <address> Minneapolis, MN, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: 1 Introduction In distributed persistent storage systems, servers provide persistent storage for information accessed by applications running at clients <ref> [LAC + 96, C + 89, WD94, LLOW91, BOS91] </ref>. This research was supported in part by DARPA contract DABT63-95-C-005, monitored by Army Fort Huachuca, and in part by DARPA contract N00014-91-J-4136, monitored by the Office of Naval Research. M. Castro is supported by a PRAXIS XXI fellowship. <p> HAC could also be used within a server cache. In persistent object systems, objects are clustered in fixed-size pages on disk, and pages are much larger than most objects [Sta84]. Most systems manage the client cache using page caching <ref> [LLOW91, WD94, SKW92] </ref>: when a miss occurs, the client evicts a page from its cache and fetches the missing object's page from the server. <p> New versions are written to the MOB when transactions commit; when the MOB fills up, versions are written to their disk pages in the background. 2.2 Page and Object Format Keeping objects small at both servers and clients is important because it has a large impact on performance <ref> [WD94, MBMS95] </ref>. Our objects are small primarily because object references (or orefs) are only 32 bits. Orefs refer to objects at the same server; objects point to objects at other servers indirectly via surrogates. <p> In contrast, most systems that support large address spaces use very large pointers, e.g., 64 [CLFL95, LAC + 96], 96 [Kos95], or even 128-bit pointers [WD92]. In Quickstore <ref> [WD94] </ref>, which also uses 32-bit pointers to address large databases, storage compaction at servers is very expensive because all references to an object must be corrected when it is moved (whereas our design makes it easy to avoid fragmentation). 2.3 Clients The client cache is partitioned into a set of page-sized <p> and because the replacement overhead increases quickly with S. 4.2 Miss Rate This section shows that HAC achieves lower miss rates than the best page-caching, and dual-buffering systems in the literature. 4.2.1 Systems Studied We show that HAC achieves lower miss rates than page-caching systems by comparing it to QuickStore <ref> [WD94] </ref>, which is the best page-caching system in the literature. Quick-Store uses a CLOCK algorithm to manage the client cache. <p> The QuickStore results were obtained with a 12 MB client cache and were reported in <ref> [WD94] </ref>. HAC and FPC use a smaller cache size, adjusted to account for the size of the indirection table in traversal T1: HAC used a 7.7 MB cache, FPC used a 9.4 MB cache. <p> Furthermore, QuickStore's conversion overhead is much higher than HAC's when it is not possible to map disk pages to the virtual memory frames described by its mapping objects; the authors of <ref> [WD94] </ref> present results that show an increase in the total time for a cold T1 traversal of 38% in this case. 12% for T1 , 16% for T1, and 17% for T1 + . <p> Furthermore, T2b runs only 26% slower than T1 in HAC, whereas in QuickStore T2b runs 3.5 times slower than T1 (mostly because of the recovery overhead of shipping updates to the server due to insufficient client cache space) <ref> [WD94] </ref>. Object-caching systems must ship modified objects to servers at commit time. This can lead to poor performance if it is necessary to immediately read the objects' pages from disk in order to install the objects in their pages.
Reference: [WD95] <author> S. J. White and D. J. DeWitt. </author> <title> Implementing crash recovery in QuickStore: A performance study. </title> <booktitle> In ACM SIGMOD Int. Conf. on Management of Data, </booktitle> <pages> pages 187-198, </pages> <address> San Jose, CA, </address> <month> June </month> <year> 1995. </year> <month> 18 </month>
Reference-contexts: Because client caches in HAC may hold objects without their containing pages, we must ship modified objects (and not their containing pages) to servers at commit time. Earlier work <ref> [OS94, WD95] </ref> has shown that this leads to poor performance if it is necessary to immediately read the objects' pages from disk to install them in the database. We avoid this cost by using the modified object buffer (MOB) architecture [Ghe95].
References-found: 46

