URL: ftp://sound.media.mit.edu/pub/Papers/kdm-TR385.ps.gz
Refering-URL: http://sound.media.mit.edu/papers.html
Root-URL: http://www.media.mit.edu
Title: Blackboard System for Automatic Transcription of Simple Polyphonic Music  
Author: Keith D. Martin 
Address: 20 Ames St., Cambridge, MA 02139  
Affiliation: Room E15-401, The Media Laboratory Massachusetts Institute of Technology  
Note: A  
Abstract: M.I.T Media Laboratory Perceptual Computing Section Technical Report No. 385 Abstract A novel computational system has been constructed which is capable of transcribing piano performances of four-voice Bach chorales written in the style of 18th century counterpoint. The system is based on the blackboard architecture, which combines top-down and bottom-up processing with a representation that is natural for the stated musical domain. Knowledge about auditory physiology, physical sound production, and musical practice has been successfully integrated in the current implementation. This report describes the system and its performance, highlighting its current limitations and describing some avenues of future work.
Abstract-found: 1
Intro-found: 1
Reference: [Bilmes 1993] <author> Jeff Bilmes. </author> <title> Timing is of the essence: Perceptual and computational techniques for representing, learning, and reproducing expressive timing in percussive rhythm. </title> <type> Master's thesis, </type> <institution> MIT Media Laboratory, </institution> <year> 1993. </year>
Reference-contexts: Maher improved upon Moorer's system by relaxing the interval constraints, at the expense of requiring that the two instruments occupy mutually exclusive pitch ranges [Ma-her 1989, Maher 1990]. After Moorer, several systems were constructed which performed polyphonic transcription of percussive music, with varying degrees of success <ref> [Stautner 1982, Schloss 1985, Bilmes 1993] </ref>. In 1993, Hawley described a system which purported to transcribe polyphonic piano performances [Hawley 1993].
Reference: [Davis et al.1977] <author> Randall Davis, Bruce Buchanan, and Edward Shortliffe. </author> <title> "Production Rules as a Representation for a Knowledge-Based Consultation Program". </title> <journal> Artificial Intelligence, </journal> <volume> 8 </volume> <pages> 15-45, </pages> <year> 1977. </year>
Reference-contexts: The Note rating function is based on a simple evidence aggregation method, as described in <ref> [Davis et al.1977] </ref>. The first five Partials are considered, and each may contribute up to 0.4 evidence (either positive or negative). Both positive and negative evidence are tallied, and are then combined to form the rating.
Reference: [Dorken et al.1992] <author> Erkan Dorken, Evangelos Milios, and S. Hamid Nawab. </author> <title> "Knowledge-Based Signal Processing Application". </title> <editor> In Alan V. Op-penheim and S. Hamid Nawab, editors, </editor> <booktitle> Symbolic and Knowledge-Based Signal Processing, chapter 9, </booktitle> <pages> pages 303-330. </pages> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1992. </year>
Reference: [Ellis 1992] <author> Daniel P. W. Ellis. </author> <title> A perceptual representation of audio. </title> <type> Master's thesis, </type> <institution> Massachusetts Institute of Technology, </institution> <month> February </month> <year> 1992. </year>
Reference-contexts: It tacitly makes several assumptions about the acoustic signal, namely that all notes in a chord are struck simultaneously and that the sounded notes do not modulate in pitch. These limitations might be addressed by a more complicated initial signal analysis, perhaps like the track analysis described by Ellis <ref> [Ellis 1992] </ref>. While the current system suffers from a number of limitations, it marks an important first step toward a working automatic transcription tool. The flexibility of the blackboard approach is its greatest asset, making it possible to seamlessly integrate knowledge from multiple domains into a single system.
Reference: [Ellis 1995] <author> Daniel P. W. Ellis. </author> <title> Mid-level representation for computational auditory scene analysis. </title> <booktitle> In Proc. of the Computational Auditory Scene Analysis Workshop; 1995 International Joint Conference on Artificial Intelligence, </booktitle> <address> Montreal, Canada, </address> <month> August </month> <year> 1995. </year>
Reference-contexts: Such a system will "perceive" chord quality and tonality more directly, perhaps through a mechanism based on the correlogram [Slaney and Lyon 1993]. Weft analysis also appears to be a worthy area of pursuit <ref> [Ellis 1995] </ref>.
Reference: [Hawley 1993] <author> Michael Hawley. </author> <title> Structure out of Sound. </title> <type> PhD thesis, </type> <institution> MIT Media Laboratory, </institution> <year> 1993. </year>
Reference-contexts: After Moorer, several systems were constructed which performed polyphonic transcription of percussive music, with varying degrees of success [Stautner 1982, Schloss 1985, Bilmes 1993]. In 1993, Hawley described a system which purported to transcribe polyphonic piano performances <ref> [Hawley 1993] </ref>. His approach was based on a differential spectrum analysis (similar to taking the difference of two adjacent FFT frames in a short-time Fourier transform) and was reported to be fairly successful, largely because piano notes do not modulate in pitch.
Reference: [Katayose and Inokuchi 1989] <author> Haruhiro Katayose and Seiji Inokuchi. </author> <title> "The Kansei Music System". </title> <journal> Computer Music Journal, </journal> <volume> 13(4) </volume> <pages> 72-77, </pages> <year> 1989. </year>
Reference-contexts: A research group at Osaka University in Japan has conducted research into automatic transcription for many years <ref> [Katayose and Inokuchi 1989] </ref>. Unfortu 1: In this context, interval corresponds to the number of semi-tones separating two simultaneously sounded notes.
Reference: [Klassner et al.1995] <author> Frank Klassner, Victor Lesser, and Hamid Nawab. </author> <title> "The IPUS Blackboard Architecture as a Framework for Computational Auditory Scene Analysis". </title> <booktitle> In Proc. of the Computational 12 Auditory Scene Analysis Workshop; 1995 Interna--tional Joint Conference on Artificial Intelligence, </booktitle> <address> Montreal, Quebec, </address> <year> 1995. </year>
Reference: [Maher 1989] <author> Robert Crawford Maher. </author> <title> An Approach for the Separation of Voices in Composite Musical Signals. </title> <type> PhD thesis, </type> <institution> University of Illinois at Urbana-Champaign, </institution> <year> 1989. </year>
Reference: [Maher 1990] <author> Robert C. Maher. </author> <title> "Evaluation of a Method for Separating Digitized Duet Signals". </title> <journal> J. Audio Eng. Soc., </journal> <volume> 38(12), </volume> <month> December </month> <year> 1990. </year>
Reference-contexts: Maher improved upon Moorer's system by relaxing the interval constraints, at the expense of requiring that the two instruments occupy mutually exclusive pitch ranges <ref> [Ma-her 1989, Maher 1990] </ref>. After Moorer, several systems were constructed which performed polyphonic transcription of percussive music, with varying degrees of success [Stautner 1982, Schloss 1985, Bilmes 1993]. In 1993, Hawley described a system which purported to transcribe polyphonic piano performances [Hawley 1993].
Reference: [Moorer 1975] <author> James A. Moorer. </author> <title> On the segmentation and analysis of continuous musical sound by digital computer. </title> <type> PhD thesis, </type> <institution> Department of Music, Stan-ford University, Stanford, </institution> <address> CA, </address> <month> May </month> <year> 1975. </year>
Reference-contexts: The history of automatic music transcription dates back at least 25 years. In the early 1970s, Moorer built a system for transcribing duets <ref> [Moorer 1975] </ref>. His system was limited, succeeding only on music with two instruments of different timbres and frequency ranges, and with strict limitations on the allowable simultaneous intervals 1 in the performance.
Reference: [Nii 1986] <author> H. Penni Nii. </author> <title> "Blackboard Systems: The Blackboard Model of Problem Solving and the Evolution of Blackboard Architectures". </title> <journal> The AI Magazine, </journal> <pages> pages 38-53, </pages> <month> Summer </month> <year> 1986. </year>
Reference-contexts: Continuing the metaphor, the system includes a collection of "knowledge sources" corresponding to the experts. An excellent introduction to the history of blackboard systems may be found in <ref> [Nii 1986] </ref>. 1.3 A limited transcription domain It is unrealistic to expect that an initial foray into polyphonic transcription will be successful on all possible musical input signals.
Reference: [Scheirer 1995] <author> Eric D. Scheirer. </author> <title> Extracting expressive performance information from recorded music. </title> <type> Master's thesis, </type> <institution> Program in Media Arts and Science, Massachusetts Institute of Technology, </institution> <year> 1995. </year>
Reference-contexts: These parameters are not sufficient to reproduce a perceptually equivalent "copy" of the original performance, as loudness and timbre are ignored (see <ref> [Scheirer 1995] </ref> for an attempt to achieve perceptual equivalence in score-guided transcriptions of piano performances), but they go a long way toward forming a useful symbolic representation of the music. The history of automatic music transcription dates back at least 25 years.
Reference: [Schloss 1985] <author> W. Andrew Schloss. </author> <title> On the Automatic Transcription of Percussive Music | from Acoustical Signal to High-Level Analysis. </title> <type> PhD thesis, </type> <institution> CCRMA - Stanford University, </institution> <month> May </month> <year> 1985. </year>
Reference-contexts: Maher improved upon Moorer's system by relaxing the interval constraints, at the expense of requiring that the two instruments occupy mutually exclusive pitch ranges [Ma-her 1989, Maher 1990]. After Moorer, several systems were constructed which performed polyphonic transcription of percussive music, with varying degrees of success <ref> [Stautner 1982, Schloss 1985, Bilmes 1993] </ref>. In 1993, Hawley described a system which purported to transcribe polyphonic piano performances [Hawley 1993].
Reference: [Slaney and Lyon 1993] <author> Malcolm Slaney and Richard F. Lyon. </author> <title> "On the importance of time | a temporal representation of sound". </title> <editor> In Martin Cooke, Steve Beet, and Malcolm Crawford, editors, </editor> <booktitle> Visual Representations of Speech Signals, </booktitle> <pages> pages 95-116. </pages> <publisher> John Wiley & Sons, </publisher> <year> 1993. </year>
Reference-contexts: Currently, we are rethinking the computational approach taken in this research, with the explicit goal of constructing a system that more closely resembles human musical understanding. Such a system will "perceive" chord quality and tonality more directly, perhaps through a mechanism based on the correlogram <ref> [Slaney and Lyon 1993] </ref>. Weft analysis also appears to be a worthy area of pursuit [Ellis 1995].
Reference: [Slaney 1995] <author> M. Slaney. </author> <title> "A critique of pure audition". </title> <booktitle> In Proc. of the Computational Auditory Scene Analysis Workshop; 1995 International Joint Conference on Artificial Intelligence, </booktitle> <address> Montreal, Canada, </address> <month> August </month> <year> 1995. </year>
Reference: [Stautner 1982] <author> John Stautner. </author> <title> The auditory transform. </title> <type> Master's thesis, </type> <institution> MIT, </institution> <year> 1982. </year>
Reference-contexts: Maher improved upon Moorer's system by relaxing the interval constraints, at the expense of requiring that the two instruments occupy mutually exclusive pitch ranges [Ma-her 1989, Maher 1990]. After Moorer, several systems were constructed which performed polyphonic transcription of percussive music, with varying degrees of success <ref> [Stautner 1982, Schloss 1985, Bilmes 1993] </ref>. In 1993, Hawley described a system which purported to transcribe polyphonic piano performances [Hawley 1993].
Reference: [Winograd and Nawab 1995] <author> Joseph M. Winograd and S. Hamid Nawab. </author> <title> "A C++ Software Environment for the Development of Embedded Signal Processing Systems". </title> <booktitle> In Proceedings of the IEEE ICASSP-95, </booktitle> <address> Detroit, MI, </address> <month> May </month> <year> 1995. </year>
Reference: [Winograd 1994] <author> Joseph M. Winograd. </author> <title> Ipus c++ platform version 0.1 user's manual. </title> <type> Technical report, </type> <institution> Dept. of Electrical, Computer, and Systems Engineering, Boston University, </institution> <year> 1994. </year> <month> 13 </month>
References-found: 19

