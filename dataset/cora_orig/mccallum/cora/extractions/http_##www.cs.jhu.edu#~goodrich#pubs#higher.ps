URL: http://www.cs.jhu.edu/~goodrich/pubs/higher.ps
Refering-URL: http://www.cs.jhu.edu/~goodrich/pubs/index.html
Root-URL: http://www.cs.jhu.edu
Email: amato@cs.uiuc.edu goodrich@cs.jhu.edu ramos@cs.uiuc.edu  
Title: Parallel Algorithms for Higher-Dimensional Convex Hulls (Preliminary Version)  
Author: NANCY M. AMATO MICHAEL T. GOODRICH EDGAR A. RAMOS 
Affiliation: ICSI Texas A&M Univ. Johns Hopkins Univ. Univ. of Illinois  
Abstract: We give fast randomized and deterministic parallel methods for constructing convex hulls in IR d , for any fixed d. Our methods are for the weakest shared-memory model, the EREW PRAM, and have optimal work bounds (with high probability for the randomized methods). In particular, we show that the convex hull of n points in IR d can be constructed in O(log n) time using O(n log n + n bd=2c ) work, with high probability. We also show that it can be constructed deterministically in O(log 2 n) time using O(n log n) work for d = 3 and in O(log n) time using O(n bd=2c log c(dd=2ebd=2c) n) work, for d 4, where c &gt; 0 is a constant, which is optimal for even d 4. We also show how to make our 3-dimensional methods output-sensitive with only a small increase in running time. These methods can be applied to other problems as well. A variation of the convex hull algorithm for even dimensions deterministically constructs a (1=r)-cutting of n hy-perplanes in IR d in O(log n) time using optimal O(nr d1 ) work; when r = n, we obtain their arrangement and a point location data structure for it. With appropriate modifications, our deterministic 3-dimensional convex hull algorithm can be used to compute, in the same resource bounds, the intersection of n balls of equal radius in IR 3 . This leads to a sequential algorithm for computing the diameter of a point set in IR 3 with running time O(n log 3 n), which is arguably simpler than an algorithm with the same running time by Br onnimann et al. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P. K. Agarwal, M. Sharir, and S. Toledo. </author> <title> Applications of parametric searching in geometric optimization. </title> <booktitle> In Proc. 3rd ACM-SIAM Sympos. Discrete Algorithms, </booktitle> <pages> pages 72-82, </pages> <year> 1992. </year>
Reference-contexts: It is also the easiest to simulate on more-realistic parallel models, and, by a scheme due to Cole [16, 17], algorithms for this model can sometimes be used to derive faster sequential parametric searching algorithms (e.g., see <ref> [1, 11, 43] </ref>) than would be possible using concurrent-read parallel methods. Our methods are all based upon a parallel divide-and-conquer scheme, where one subdivides the space into cells that should contain fewer halfspaces and then recurses on each cell in parallel. <p> Part (3) follows from a straightforward parallelization of a result of Matousek [41]. As it turns out, these size bounds are too large to be of direct use in our convex hull algorithms, however. 2.1 Semi-nets Let Y be a subset of X, and let a parameter r 2 <ref> [1; n] </ref> be given. Further, let N Y (s; X) denote the number of ranges from X generated by F (Y ) of size s such that Y " R = ;. We say such ranges are missed by Y . <p> Since A is a (1=r)-approximation, jA " Rj jAj (jRj=n 1=2r). Thus, for each range R given weight t ! in (2) there is a corresponding range A " R given weight at least (2t 1) ! in (3). Therefore, since (2t 1) ! t ! for t 2 <ref> [1; r] </ref>, X N Y (tn=r; X) maxft ! ; 1g = O (f 0 (2r)); which is O (f 0 (r)) by assumption. <p> Chazelle [9] shows that such a (1=r)-cutting can be constructed in O (nr d1 ) time, for any r 2 <ref> [1; n] </ref>, and Matousek [41] shows that such a cutting can be constructed in O (n log r) time for r n ff , for some small constant ff &gt; 0 that depends upon d. <p> Goodrich [27] gives parallel analogues to these results, showing that (1=r)- cuttings of size O (r d ) can be constructed in O (log n log r) time in the EREW PRAM model with O (nr d1 ) work for any r 2 <ref> [1; n] </ref> (the log r factor is removed in subsection 3.5) and with O (n log r) work for r n ff . For the purposes of convex hull construction, however, these results are not quite what we need, for a generic (1=r)- cutting has too many simplices. <p> Matousek [39] shows that an l-shallow (1=r)-cutting of n hyperplanes in IR d of size O (r bd=2c (l (r=n) + 1) dd=2e ) can be constructed in polynomial time for any r 2 <ref> [1; n] </ref>, and in O (n log r) time for r n ff . Our construction loosely follows his. Let Y be a given subset of H.
Reference: [2] <author> A. Aggarwal, B. Chazelle, L. Guibas, C. O'Dunlaing, and C. Yap. </author> <title> Parallel computational geometry. </title> <journal> Algorithmica, </journal> <volume> 3 </volume> <pages> 293-327, </pages> <year> 1988. </year>
Reference-contexts: Optimal deterministic 2-dimensional convex hull algorithms running in O (log n) time using O (n log n) work for the CREW PRAM were given by Atallah and Goodrich [6, 7] and Ag-garwal et al. <ref> [2] </ref>, and for the EREW PRAM by Miller and Stout [44]. For 3-dimensional convex hulls, using n processors on a CREW PRAM, O (log 3 n) time was achieved by Chow [14] and Aggarwal et al. [2], O (log 2 n log fl n) time was obtained by Dadoun and Kirkpatrick <p> CREW PRAM were given by Atallah and Goodrich [6, 7] and Ag-garwal et al. <ref> [2] </ref>, and for the EREW PRAM by Miller and Stout [44]. For 3-dimensional convex hulls, using n processors on a CREW PRAM, O (log 3 n) time was achieved by Chow [14] and Aggarwal et al. [2], O (log 2 n log fl n) time was obtained by Dadoun and Kirkpatrick [20], and O (log 2 n) time was achieved Amato and Preparata [3].
Reference: [3] <author> N. M. Amato and F. P. Preparata. </author> <title> The parallel 3D convexhull problem revisited. </title> <journal> Internat. J. Comput. Geom. Appl., </journal> <volume> 2(2) </volume> <pages> 163-173, </pages> <year> 1992. </year>
Reference-contexts: convex hulls, using n processors on a CREW PRAM, O (log 3 n) time was achieved by Chow [14] and Aggarwal et al. [2], O (log 2 n log fl n) time was obtained by Dadoun and Kirkpatrick [20], and O (log 2 n) time was achieved Amato and Preparata <ref> [3] </ref>. For some time, the only solution to the 3-dimensional convex hull problem optimal with respect to time or work was the O (log n) time and O (n log n) work randomized algorithm for the CREW PRAM of Reif and Sen [51]. <p> at each stage, time O (log n 0 ) with n 0 - polynomial probability can be achieved by stopping the recursion when n = O (log k n 0 ) for an appropriate k, and then finishing with a nonoptimal algorithm, for example the algorithm of Amato and Preparata <ref> [3] </ref>. The total expected work is O (n 0 log n 0 ) (and O (n 0 log 2 n 0 ) with n 0 -polynomial probability). To obtain optimal work with n 0 -polynomial probability, we use the polling technique of Reif and Sen [51].
Reference: [4] <author> N. M. Amato and F. P. Preparata. </author> <title> An NC 1 parallel 3D convex hull algorithm. </title> <booktitle> In Proc. 9th Annu. ACM Sympos. Comput. Geom., </booktitle> <pages> pages 289-297, </pages> <year> 1993. </year>
Reference-contexts: Recently, by de 1 Throughout this paper we assume d is a fixed constant. randomizing Reif and Sen's algorithm, Goodrich obtained an O (log 2 n) time work-optimal method for the EREW PRAM, and a time-optimal method using O (n 1+* ) work was given by Amato and Preparata <ref> [4] </ref> for the CREW PRAM, where * &gt; 0 is any fixed constant. There is also a parallel output-sensitive algorithm by Ghouse and Goodrich [25]. <p> We examine the resource bounds of one level in the recursion for a sample size r = n * , 0 &lt; * &lt; 1. We construct (and triangulate) R " in O (log n) time using O (n 2* log n) work <ref> [4] </ref>. <p> 0 ) be as follows: Run A (n 0 ) until subproblems of size n ff 0 , 0 &lt; ff &lt; 1 are obtained, for each middle stage where n ff 0 n log n 0 do failure sweeping, and substitute the last stages by the deterministic algorithm of <ref> [4] </ref>. We summarize the results in the following theorem. Both solve open problems of Reif and Sen [51].
Reference: [5] <author> P. Assouad. </author> <title> Densite et dimension. </title> <journal> Ann. Inst. Fourier, Grenoble, </journal> <volume> 3 </volume> <pages> 232-282, </pages> <year> 1983. </year>
Reference-contexts: The that is at least 1 1=2 n ffi , for some constant ffi &gt; 0. VC-exponent <ref> [5] </ref> 3 of such a set system is the infimum of all numbers k such that jF (Y )j is O (jY j k ).
Reference: [6] <author> M. J. Atallah and M. T. Goodrich. </author> <title> Efficient parallel solutions to some geometric problems. </title> <journal> J. Parallel Distrib. Comput., </journal> <volume> 3 </volume> <pages> 492-507, </pages> <year> 1986. </year>
Reference-contexts: Optimal deterministic 2-dimensional convex hull algorithms running in O (log n) time using O (n log n) work for the CREW PRAM were given by Atallah and Goodrich <ref> [6, 7] </ref> and Ag-garwal et al. [2], and for the EREW PRAM by Miller and Stout [44].
Reference: [7] <author> M. J. Atallah and M. T. Goodrich. </author> <title> Parallel algorithms for some functions of two convex polygons. </title> <journal> Algorithmica, </journal> <volume> 3 </volume> <pages> 535-548, </pages> <year> 1988. </year>
Reference-contexts: Optimal deterministic 2-dimensional convex hull algorithms running in O (log n) time using O (n log n) work for the CREW PRAM were given by Atallah and Goodrich <ref> [6, 7] </ref> and Ag-garwal et al. [2], and for the EREW PRAM by Miller and Stout [44].
Reference: [8] <author> Herve Bronnimann, Bernard Chazelle, and Jir Matousek. </author> <title> Product range spaces, sensitive sampling, </title> <booktitle> and derandomization. In Proc. 34th Annu. IEEE Sympos. Found. Comput. Sci. (FOCS 93), </booktitle> <pages> pages 400-409, </pages> <year> 1993. </year>
Reference-contexts: For some time, the only solutions optimal in higher dimensions were the randomized incremental algorithm of Clarkson and Shor [15], and the subsequent randomized method of Seidel [56]. Recently, Chazelle [10] gave the first deterministic algorithm that is optimal in higher dimensions, which was simplified by Bronnimann et al. <ref> [8] </ref>. The optimality of the above algorithms is measured with respect to the worst-case size complexity of the resulting convex hull. <p> with parametric search [43] as in previous works [11, 40], we obtain a sequential algorithm for computing the diameter of a point set in IR 3 with running time O (n log 3 n) that is arguably simpler than the algorithm with the same running time by Bronnimann et al. <ref> [8] </ref>. We present some important constructions for hyperplane set systems in the next section. <p> The relation was pointed out by Clarkson and Shor [15] who gave optimal O (n log n) time random ized algorithms for both problems. Deterministically, the current best algorithms have running times O (n log n) and O (n log 3 n) respectively <ref> [8] </ref>. The algorithms we describe here match those running times and are arguably simpler 8 . Ball intersection.
Reference: [9] <author> B. Chazelle. </author> <title> Cutting hyperplanes for divide-and-conquer. </title> <journal> Discrete Comput. Geom., </journal> <volume> 9(2) </volume> <pages> 145-158, </pages> <year> 1993. </year>
Reference-contexts: In our optimal deterministic method for even dimensions we get around the size blow-up problem by using a shallow-cutting analogue to a partition sparsity concept introduced by Chazelle <ref> [9] </ref>. Finally, we get around the size blow-up problem for the 3-dimensional halfspace intersection by using a new pruning computation, which removes halfspaces that cannot ultimately contribute vertices to the final intersection. <p> Chazelle and Friedman [12] show that there exists a (1=r)- cutting of size O (r d ), where the size of a (1=r)-cutting C is the number of simplices in C. Chazelle <ref> [9] </ref> shows that such a (1=r)-cutting can be constructed in O (nr d1 ) time, for any r 2 [1; n], and Matousek [41] shows that such a cutting can be constructed in O (n log r) time for r n ff , for some small constant ff &gt; 0 that <p> We can also easily construct the new conflict lists with this complexity. If Y has order !, then the total size and work bounds are as claimed above. On the surface this appears to be no better than the existing (1=r)-cutting constructions <ref> [9, 12, 27, 41] </ref>, for in the standard hyperplane set system jT (Y )j is O (r d ). <p> Proof: The proof follows that of Lemmas 2.4 and 2.9 to establish the semi-net and shallowness properties for Y . This also establishes the first term in the size bound for jT (Y )j. Thus, we have only to establish the second term in that bound. Chazelle <ref> [9] </ref> shows that jV (A; s)j can be used to estimate jV (H; s)j: fi fi jV (H; s)j jV (A; s)j fi fi 1 Thus, (r=jAj) d jV (A; s)j is O ((jAj=n) d jV (H; s)j+1), which establishes the lemma. <p> In particular, A (H) can be constructed in O (log n) time using O (n d ) work in the EREW PRAM model. The hierarchical structure obtained can be used to perform point location, as indicated by Chazelle <ref> [9] </ref>. Since we are interested in the ability to answer simultaneous queries, we construct for each s 2 C i the point location data structure of Dobkin and Lipton [21].
Reference: [10] <author> B. Chazelle. </author> <title> An optimal convex hull algorithm in any fixed dimension. </title> <journal> Discrete Comput. Geom., </journal> <volume> 10 </volume> <pages> 377-409, </pages> <year> 1993. </year>
Reference-contexts: For some time, the only solutions optimal in higher dimensions were the randomized incremental algorithm of Clarkson and Shor [15], and the subsequent randomized method of Seidel [56]. Recently, Chazelle <ref> [10] </ref> gave the first deterministic algorithm that is optimal in higher dimensions, which was simplified by Bronnimann et al. [8]. The optimality of the above algorithms is measured with respect to the worst-case size complexity of the resulting convex hull. <p> re-written b 0t&lt;1 r X jF tn (X)j (r=n) D t (D+2) : Clarkson and Shor [15] show (using a slightly different no tation) that X jF s (X)j C (k) D f 0 (n=k); 5 Our definition of a semi-net is motivated by the (1=r)-semi-cutting notion introduced by Chazelle <ref> [10] </ref>, as well as proof techniques given in [12, 27, 38]. for some constant C &gt; 0. <p> This concept was introduced by Chazelle <ref> [10] </ref>, extended to the parallel domain by Goodrich [27], and, more recently, used by Pellegrini [46] in the design of efficient sequential data structures. <p> As mentioned above, Chazelle <ref> [10] </ref> gives a sequential deterministic method for intersecting d-dimensional half-spaces that is optimal, but which is difficult to parallelize. This is because it involves a seemingly inherently-sequential application of the conditional probabilities derandomization method.
Reference: [11] <author> B. Chazelle, H. Edelsbrunner, L. Guibas, and M. Sharir. </author> <title> Diameter, width, closest line pair and parametric searching. </title> <journal> Discrete Comput. Geom., </journal> <volume> 10 </volume> <pages> 183-196, </pages> <year> 1993. </year>
Reference-contexts: It is also the easiest to simulate on more-realistic parallel models, and, by a scheme due to Cole [16, 17], algorithms for this model can sometimes be used to derive faster sequential parametric searching algorithms (e.g., see <ref> [1, 11, 43] </ref>) than would be possible using concurrent-read parallel methods. Our methods are all based upon a parallel divide-and-conquer scheme, where one subdivides the space into cells that should contain fewer halfspaces and then recurses on each cell in parallel. <p> Using the algorithm for ball intersection together with parametric search [43] as in previous works <ref> [11, 40] </ref>, we obtain a sequential algorithm for computing the diameter of a point set in IR 3 with running time O (n log 3 n) that is arguably simpler than the algorithm with the same running time by Bronnimann et al. [8]. <p> Diameter. Using the algorithm for ball intersection together with parametric search [43] as in previous works <ref> [11, 40] </ref>, we obtain a sequential algorithm for the diameter problem with running time O (n log 3 n). First, we need to make the ball intersection algorithm into an oracle that determines whether D &gt; r, D &lt; r or D = r.
Reference: [12] <author> B. Chazelle and J. Friedman. </author> <title> A deterministic view of random sampling and its use in geometry. </title> <journal> Combinatorica, </journal> <volume> 10(3) </volume> <pages> 229-249, </pages> <year> 1990. </year>
Reference-contexts: The next lemma implies that a suitably-defined random sample is a (1=r)-semi-net, even if it is defined by random variables that are only k-wise independent. It is a k-wise independent version of a result of Chazelle and Friedman <ref> [12] </ref>. Lemma 2.2 Let (X; F ) be an F -generated set system with constant VC-exponent D. <p> (r=n) D t (D+2) : Clarkson and Shor [15] show (using a slightly different no tation) that X jF s (X)j C (k) D f 0 (n=k); 5 Our definition of a semi-net is motivated by the (1=r)-semi-cutting notion introduced by Chazelle [10], as well as proof techniques given in <ref> [12, 27, 38] </ref>. for some constant C &gt; 0. Thus, the expectation (1) is at most bCf 0 (r) + b 1tr which can be bounded by bCf 0 (r) + b 1tr for some constant a &gt; 1, provided that f 0 is non-decreasing. <p> In hyperplane set systems the ranges are H js sets. A (1=r)-cutting [38] of H is a partition C of (possibly unbounded) d-simplices that cover IR d and such that jH js j n=r for each s 2 C. Chazelle and Friedman <ref> [12] </ref> show that there exists a (1=r)- cutting of size O (r d ), where the size of a (1=r)-cutting C is the number of simplices in C. <p> In addition, define T (Y ) to be the set of simplices in a canonical triangulation <ref> [12] </ref> of the arrangement A (Y ) of Y , restricted to those simplices in F 0 (Y ). <p> Proof: We use an adaptation of proof techniques used by Chazelle and Friedman <ref> [12] </ref> and Matousek [38]. For each simplex s in T (Y ), if jH js j &gt; n=r, then we form a (1=t)-cutting C s of size at most O (t d+1 ) for H js , where t = jH js jr=n. <p> We can also easily construct the new conflict lists with this complexity. If Y has order !, then the total size and work bounds are as claimed above. On the surface this appears to be no better than the existing (1=r)-cutting constructions <ref> [9, 12, 27, 41] </ref>, for in the standard hyperplane set system jT (Y )j is O (r d ).
Reference: [13] <author> B. Chazelle and J. Matousek. </author> <title> Derandomizing an output-sensitive convex hull algorithm in three dimensions. </title> <type> Technical report, </type> <institution> Dept. Comput. Sci., Princeton Univ., </institution> <year> 1992. </year>
Reference-contexts: The first output-sensitive algorithm, due to Kirkpatrick and Seidel [33], computed the convex hull in IR 2 in O (n log h) time. Clarkson and Shor [15] gave an optimal randomized output-sensitive solution for 3-dimensional convex hulls, which was optimally derandomized by Chazelle and Matousek <ref> [13] </ref>. In higher dimensions, the only deterministic output-sensitive method known, due to Seidel [55], runs in time O (n 2 +h log n), which can be slightly improved to O (n 2 (2=(bd=2c+1))+* + h log n), for any fixed * &gt; 0, using a technique of Matousek [42]. <p> algorithm using optimal O (n log h) work, where h = jH " j, but increased running time O (log 3 n), by applying the technique used in the sequential randomized output-sensitive method of Clarkson and Shor [15], which was also used in its deran-domized version by Chazelle and Matousek <ref> [13] </ref>. Suppose that we know the value of h = jH " j, and that h &lt; n * , for some * &gt; 0 (otherwise the O (n log n) work method suffices). By Theorem 2.10 (3), we obtain a 0 shallow (1=h)-cutting of size O (h).
Reference: [14] <author> A. L. Chow. </author> <title> Parallel algorithms for geometric problems. </title> <type> Ph.D. thesis, </type> <institution> Dept. Comput. Sci., Univ. Illinois, Urbana, IL, </institution> <year> 1980. </year>
Reference-contexts: For 3-dimensional convex hulls, using n processors on a CREW PRAM, O (log 3 n) time was achieved by Chow <ref> [14] </ref> and Aggarwal et al. [2], O (log 2 n log fl n) time was obtained by Dadoun and Kirkpatrick [20], and O (log 2 n) time was achieved Amato and Preparata [3].
Reference: [15] <author> K. L. Clarkson and P. W. Shor. </author> <title> Applications of random sampling in computational geometry, II. </title> <journal> Discrete Comput. Geom., </journal> <volume> 4 </volume> <pages> 387-421, </pages> <year> 1989. </year>
Reference-contexts: For some time, the only solutions optimal in higher dimensions were the randomized incremental algorithm of Clarkson and Shor <ref> [15] </ref>, and the subsequent randomized method of Seidel [56]. Recently, Chazelle [10] gave the first deterministic algorithm that is optimal in higher dimensions, which was simplified by Bronnimann et al. [8]. <p> Accounting for output size, the lower bound becomes W (h + n log h), where h is the size of the convex hull. The first output-sensitive algorithm, due to Kirkpatrick and Seidel [33], computed the convex hull in IR 2 in O (n log h) time. Clarkson and Shor <ref> [15] </ref> gave an optimal randomized output-sensitive solution for 3-dimensional convex hulls, which was optimally derandomized by Chazelle and Matousek [13]. <p> Section 3 we give our convex hull methods for d 4, and we give some specialized methods for d = 3 in Section 4. 2 Hyperplane Set Systems We begin by describing a general framework for set systems, which is most similar to a framework given by Clarkson and Shor <ref> [15] </ref>. Let (X; F ) be an F -generated set system, i.e., let X be a set of n elements and let F be a function, called the generator function, that maps subsets of X to subsets of 2 X , whose elements are commonly referred to as ranges. <p> Thus, we can bound (1) by b 0tr r (X)j (r=n) D minft (D+!+2) ; 1g maxft ! ; 1g; which can be re-written b 0t&lt;1 r X jF tn (X)j (r=n) D t (D+2) : Clarkson and Shor <ref> [15] </ref> show (using a slightly different no tation) that X jF s (X)j C (k) D f 0 (n=k); 5 Our definition of a semi-net is motivated by the (1=r)-semi-cutting notion introduced by Chazelle [10], as well as proof techniques given in [12, 27, 38]. for some constant C &gt; 0. <p> For any simplex s, let H js denote the set of hyperplanes of H intersecting the interior of s. The set H js is often referred to as the conflict list for s relative to H <ref> [15] </ref>. In hyperplane set systems the ranges are H js sets. A (1=r)-cutting [38] of H is a partition C of (possibly unbounded) d-simplices that cover IR d and such that jH js j n=r for each s 2 C. <p> The structure of the algorithm is similar to the sub-optimal method for IR d of Section 3.1. This general approach was first used for IR 3 by Clarkson and Shor <ref> [15] </ref> in their sequential randomized output-sensitive algorithm, and was also used in the randomized parallel algorithm of Reif and Sen [51] for the CREW PRAM model. We select a random sample R H, construct the convex polyhedron R " , and triangulate its boundary. <p> Next, for each simplex s 2 S R , we find the conflict list H js HnR. This method is then applied recursively to each simplex s 2 S R , with input H js , to compute H " js " s. Clarkson and Shor <ref> [15] </ref> show that, for appropriate constants c 0 and c 1 , both of the following conditions hold with probability at least 1=2: (i) P c 1 (n=r) log r. <p> The fact that the contours can be used to identify the trivial faces was noted by Clarkson and Shor <ref> [15] </ref>, and was also used in the parallel algorithm of Reif and Sen [51]. Lemma 4.3 After removing trivial faces, jH c j = O (n). <p> We obtain a deterministic output-sensitive parallel algorithm using optimal O (n log h) work, where h = jH " j, but increased running time O (log 3 n), by applying the technique used in the sequential randomized output-sensitive method of Clarkson and Shor <ref> [15] </ref>, which was also used in its deran-domized version by Chazelle and Matousek [13]. Suppose that we know the value of h = jH " j, and that h &lt; n * , for some * &gt; 0 (otherwise the O (n log n) work method suffices). <p> The interest in this object originates in its relevance to the computation of the diameter of X, the largest distance between any pair of points in X. The relation was pointed out by Clarkson and Shor <ref> [15] </ref> who gave optimal O (n log n) time random ized algorithms for both problems. Deterministically, the current best algorithms have running times O (n log n) and O (n log 3 n) respectively [8]. The algorithms we describe here match those running times and are arguably simpler 8 .
Reference: [16] <author> R. Cole. </author> <title> Slowing down sorting networks to obtain faster sorting algorithms. </title> <journal> J. ACM, </journal> <volume> 34 </volume> <pages> 200-208, </pages> <year> 1987. </year>
Reference-contexts: Our methods are for the EREW PRAM, which is the weakest of the synchronous shared-memory models. It is also the easiest to simulate on more-realistic parallel models, and, by a scheme due to Cole <ref> [16, 17] </ref>, algorithms for this model can sometimes be used to derive faster sequential parametric searching algorithms (e.g., see [1, 11, 43]) than would be possible using concurrent-read parallel methods. <p> One can verify that the game of Cole <ref> [16, 17] </ref> can be played on the computation graph of the algorithm for constructing a (1=c)- approximation, so that the log log n factor is saved. The bound O (n log 3 n) on the running time follows.
Reference: [17] <author> R. Cole. </author> <title> Parallel merge sort. </title> <journal> SIAM J. Comput., </journal> <volume> 17(4) </volume> <pages> 770-785, </pages> <year> 1988. </year>
Reference-contexts: Our methods are for the EREW PRAM, which is the weakest of the synchronous shared-memory models. It is also the easiest to simulate on more-realistic parallel models, and, by a scheme due to Cole <ref> [16, 17] </ref>, algorithms for this model can sometimes be used to derive faster sequential parametric searching algorithms (e.g., see [1, 11, 43]) than would be possible using concurrent-read parallel methods. <p> The trivial faces can be identified by labeling each contour edge with the halfspaces that define it, and lexicographically sorting the labels; this takes O (log n) time using O (n log n) work on an EREW PRAM <ref> [17] </ref>. The fact that the contours can be used to identify the trivial faces was noted by Clarkson and Shor [15], and was also used in the parallel algorithm of Reif and Sen [51]. Lemma 4.3 After removing trivial faces, jH c j = O (n). <p> One can verify that the game of Cole <ref> [16, 17] </ref> can be played on the computation graph of the algorithm for constructing a (1=c)- approximation, so that the log log n factor is saved. The bound O (n log 3 n) on the running time follows.
Reference: [18] <author> R. Cole and U. Vishkin. </author> <title> Approximate parallel scheduling, part i: the basic technique with applications to optimal parallel list ranking in logarithmic time. </title> <journal> SIAM Journal on Computing, </journal> <volume> 17(1) </volume> <pages> 128-142, </pages> <year> 1988. </year>
Reference-contexts: We then complete the algorithm as above using this S. This gives us the following: 6 This is a probabilistic analogue of a result of Cole and Vishkin <ref> [18] </ref>.
Reference: [19] <author> S. A. Cook, C. Dwork, and R. Reischuk. </author> <title> Upper and lower time bounds for parallel random access machines without simultaneous writes. </title> <journal> SIAM J. Comput., </journal> <volume> 15 </volume> <pages> 87-97, </pages> <year> 1986. </year>
Reference-contexts: The parallel construction of the convex hull has also received much attention. For exclusive-write PRAMs (the EREW and CREW models) it is known that W (log n) time is required to compute the convex hull in IR d , d 2 <ref> [19] </ref>. Optimal deterministic 2-dimensional convex hull algorithms running in O (log n) time using O (n log n) work for the CREW PRAM were given by Atallah and Goodrich [6, 7] and Ag-garwal et al. [2], and for the EREW PRAM by Miller and Stout [44].
Reference: [20] <author> N. Dadoun and D. G. Kirkpatrick. </author> <title> Parallel construction of subdivision hierarchies. </title> <journal> J. Comput. Syst. Sci., </journal> <volume> 39 </volume> <pages> 153-165, </pages> <year> 1989. </year>
Reference-contexts: For 3-dimensional convex hulls, using n processors on a CREW PRAM, O (log 3 n) time was achieved by Chow [14] and Aggarwal et al. [2], O (log 2 n log fl n) time was obtained by Dadoun and Kirkpatrick <ref> [20] </ref>, and O (log 2 n) time was achieved Amato and Preparata [3].
Reference: [21] <author> D. P. Dobkin and R. J. Lipton. </author> <title> Multidimensional searching problems. </title> <journal> SIAM J. Comput., </journal> <volume> 5 </volume> <pages> 181-186, </pages> <year> 1976. </year>
Reference-contexts: The hierarchical structure obtained can be used to perform point location, as indicated by Chazelle [9]. Since we are interested in the ability to answer simultaneous queries, we construct for each s 2 C i the point location data structure of Dobkin and Lipton <ref> [21] </ref>. This reduces the problem to point location in a collection of slabs, a collection of hy-perplanes restricted to an infinite prism whose section is a simplex, so that they do not intersect inside the prism.
Reference: [22] <author> D.P. Dobkin and D.G. Kirkpatrick. </author> <title> Fast detection of polyhedral intersection. </title> <journal> Theoretical Computer Science, </journal> <volume> 27 </volume> <pages> 241-253, </pages> <year> 1983. </year>
Reference-contexts: (n log n) work in the EREW PRAM model. (iv) The conflict lists B s can be computed using point location in an arrangement of hyperplanes as in [40] by using the mentioned linearization technique. (Alternatively, in a sequential algorithm, the conflict lists can be obtained using a hierarchical decomposition <ref> [22] </ref> to determine a first intersection point between each bounding sphere and the boundary of R " , and then walking to determine all the intersection.) (v) The contours are computed using a two-dimensional version of the same method (note that each portion of contour lies on a type of cylindrical
Reference: [23] <author> H. Edelsbrunner. </author> <title> Algorithms in Combinatorial Geometry, </title> <booktitle> volume 10 of EATCS Monographs on Theoretical Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <address> Heidelberg, West Germany, </address> <year> 1987. </year>
Reference-contexts: Besides being of interest in its own right, the convex hull construction problem has as a dual the important problem of computing the intersection of n halfspaces. Moreover, the construction of d-dimensional Delaunay triangulations and Voronoi diagrams can be reduced to the construction of (d + 1)-dimensional convex hulls <ref> [23] </ref>. <p> In IR d , the size of the convex hull of n points is Q (n bd=2c ) in the worst case, and its construction requires W (n log n + n bd=2c ) work <ref> [23, 48] </ref>. fl This research supportedin part by an AT&T Bell LaboratoriesGraduate Fellowship and by NSF Grant CCR-9315696. y This research supported by the NSF under Grants IRI-9116843 and CCR-9300079.
Reference: [24] <author> H. Edelsbrunner and E. Mucke. </author> <title> Three-dimensional alpha shapes. </title> <journal> ACM Trans. on Graphics, </journal> <note> 1994. To appear. </note>
Reference-contexts: By well-known reductions, this theorem immediately implies deterministic optimal-work parallel methods for 3-dimensional Delaunay triangulations and Voronoi diagrams, which have a wide number of applications (see e.g., <ref> [24] </ref>). 3.5 Cuttings, arrangements, & point location The same method used to construct convex hulls for even dimensions, when applied to the whole arrangement A (H) of hyperplanes H rather than to a single cell, can be used to construct (1=r)-cuttings for H with optimal work O (nr d1 ) (when
Reference: [25] <author> M. Ghouse and M. T. Goodrich. </author> <title> In-place techniques for parallel convex hull algorithms. </title> <booktitle> In Proc. 3rd ACM Sympos. Parallel Algorithms Architect., </booktitle> <pages> pages 192-203, </pages> <year> 1991. </year>
Reference-contexts: There is also a parallel output-sensitive algorithm by Ghouse and Goodrich <ref> [25] </ref>. Using the CRCW PRAM model, they give an O (log n) time and O (n log h) work method for IR 2 , and an O (log 2 n) time and O (minfn log 2 h; n log ng) work method for IR 3 . <p> Then one can perform all n tasks in O (log n + t log log n) time using O (nw) work on an EREW PRAM, with n-exponential probability. Proof: (Sketch) The method is based upon be a combination of parallel divide-and-conquer and failure sweeping <ref> [25, 36] </ref>. If n is smaller than some suitably large constant, we solve the duration-unknown scheduling problem by replicating the n tasks a constant number of times and running all copies in parallel. <p> Since n decreases as the algorithm progresses, we need a second technique to boost the degrading exponential probability to n 0 -exponential. This is achieved with the failure sweeping technique <ref> [25, 36] </ref>. <p> By Theorem 2.10 (3), we obtain a 0 shallow (1=h)-cutting of size O (h). Everything proceeds as before except the contours are computed using a parallel version of Kirkpatrick and Seidel's [33] output-sensitive planar convex hull algorithm, due to Ghouse and Goodrich <ref> [25] </ref>, which can be implemented to run in O (log 2 n) time using O (n log h) work on an EREW PRAM. Note that since the contours are part of H " , their size is bounded by h.
Reference: [26] <author> M. T. Goodrich. </author> <title> Constructing arrangements optimally in parallel. </title> <journal> Discrete Comput. Geom., </journal> <volume> 9 </volume> <pages> 371-385, </pages> <year> 1993. </year>
Reference-contexts: This provides an EREW PRAM analogue to a CREW PRAM result of Goodrich <ref> [26] </ref>. Theorem 3.5 Given a set H of n hyperplanes in IR d , a (1=r)-cutting for H of size O (r d ) can be constructed in O (log n) time using O (nr d1 ) work in the EREW PRAM model.
Reference: [27] <author> M. T. Goodrich. </author> <title> Geometric partitioning made easier, even in parallel. </title> <booktitle> In Proc. 9th Annu. ACM Sympos. Comput. Geom., </booktitle> <pages> pages 73-82, </pages> <year> 1993. </year>
Reference-contexts: Proof: Part (1) is a special case of a result of Goodrich <ref> [27] </ref> for set systems with finite VC-exponent. Part (2) follows by taking a random sample of size O (n * r 2 ), which by a Chernoff bound (e.g., see [29]), can be shown to form a (1=r)-approximation with n-exponential probability. <p> Proof: Goodrich <ref> [27] </ref> shows that if Y is defined as above, then with probability at least 3/4, jY j = r Q (r 1=2 ). Let F s (X) denote the set of ranges in F (X) of size s. <p> denote the probability Pr (R 2 F (Y )) and we let p 2 denote the probability Pr (Y " R = ; j R 2 F (Y )), then we can re-write (1) as X X r p 1 p 2 maxft ! ; 1g: Using a result from <ref> [27] </ref>, we can bound p 1 by minfb=t (kD)=2 ; 1g, for some constant b &gt; 1. Moreover, this requires just (k D)-wise independence [27]. <p> R 2 F (Y )), then we can re-write (1) as X X r p 1 p 2 maxft ! ; 1g: Using a result from <ref> [27] </ref>, we can bound p 1 by minfb=t (kD)=2 ; 1g, for some constant b &gt; 1. Moreover, this requires just (k D)-wise independence [27]. Thus, since each range in F (Y ) is determined by at most D triggers, we can bound p 2 by (r=n) D using the additional D-wise independence available in the random variables. <p> (r=n) D t (D+2) : Clarkson and Shor [15] show (using a slightly different no tation) that X jF s (X)j C (k) D f 0 (n=k); 5 Our definition of a semi-net is motivated by the (1=r)-semi-cutting notion introduced by Chazelle [10], as well as proof techniques given in <ref> [12, 27, 38] </ref>. for some constant C &gt; 0. Thus, the expectation (1) is at most bCf 0 (r) + b 1tr which can be bounded by bCf 0 (r) + b 1tr for some constant a &gt; 1, provided that f 0 is non-decreasing. <p> Goodrich <ref> [27] </ref> gives parallel analogues to these results, showing that (1=r)- cuttings of size O (r d ) can be constructed in O (log n log r) time in the EREW PRAM model with O (nr d1 ) work for any r 2 [1; n] (the log r factor is removed in <p> This can be done deterministically in O (log n) time using O ((n=r)t ! ) work, for some constant ! &gt; d + 1, by a method of Goodrich <ref> [27] </ref>. We can also easily construct the new conflict lists with this complexity. If Y has order !, then the total size and work bounds are as claimed above. <p> We can also easily construct the new conflict lists with this complexity. If Y has order !, then the total size and work bounds are as claimed above. On the surface this appears to be no better than the existing (1=r)-cutting constructions <ref> [9, 12, 27, 41] </ref>, for in the standard hyperplane set system jT (Y )j is O (r d ). <p> This concept was introduced by Chazelle [10], extended to the parallel domain by Goodrich <ref> [27] </ref>, and, more recently, used by Pellegrini [46] in the design of efficient sequential data structures. Define V (H; s) to be the set of all vertices in an arrangement A (H) of a set of hyperplanes, H, that are in the interior of a simplex s. <p> problem in IR 3 of size n can be solved in the EREW PRAM model with work O (n log n) and time O (log n) with n-polynomial probability, and in the CREW PRAM model with the same bounds with n-exponential probability. 4.3 Deterministic and output sensitive algo rithms Goodrich <ref> [27] </ref> has derandomized Reif and Sen's [51] three-dimensional convex hull algorithm to obtain a deterministic algorithm with optimal work and O (log 2 n) time on an EREW PRAM. His techniques [27] can be applied to our algorithm yielding a simpler deterministic algorithm with the same resource bounds. <p> the CREW PRAM model with the same bounds with n-exponential probability. 4.3 Deterministic and output sensitive algo rithms Goodrich <ref> [27] </ref> has derandomized Reif and Sen's [51] three-dimensional convex hull algorithm to obtain a deterministic algorithm with optimal work and O (log 2 n) time on an EREW PRAM. His techniques [27] can be applied to our algorithm yielding a simpler deterministic algorithm with the same resource bounds. <p> Using the techniques of <ref> [27] </ref>, that sample can be obtained in O (log 2 n) time with O (n log n) work in the EREW PRAM model. (iv) The conflict lists B s can be computed using point location in an arrangement of hyperplanes as in [40] by using the mentioned linearization technique. (Alternatively, in <p> The problem with the approximation construction is that it consists of O (log n) stages each requiring the construction of a (1=c)-approximation, for some constant c, using O (n) work as described in <ref> [27] </ref>, which in turn requires Q (log log n) stages (so a running time O (n log 3 n log log n) can be achieved).
Reference: [28] <author> R. L. Graham. </author> <title> An efficient algorithm for determining the convex hull of a finite planar set. </title> <journal> Inform. Process. Lett., </journal> <volume> 1 </volume> <pages> 132-133, </pages> <year> 1972. </year>
Reference-contexts: A portion of this effort was done while this author was visiting the University of Illinois at Urbana-Champaign. z This research supported in part by NSF Grant CCR-9118874. 1.1 Related work Optimal deterministic sequential algorithms have long been known for the cases d = 2; 3 <ref> [28, 47] </ref>. In higher dimensions, d 4, Seidel proposed two deterministic algorithms. His first algorithm [54] ran in O (n log n + n dd=2e ) time 1 , which is optimal for even d, and later he gave an O (n bd=2c log n) solution [55].
Reference: [29] <author> T. Hagerup and C. Rub. </author> <title> A guided tour of Chernoff bounds. </title> <journal> Information Processing Letters, </journal> <volume> 33(10) </volume> <pages> 305-308, </pages> <year> 1990. </year>
Reference-contexts: Proof: Part (1) is a special case of a result of Goodrich [27] for set systems with finite VC-exponent. Part (2) follows by taking a random sample of size O (n * r 2 ), which by a Chernoff bound (e.g., see <ref> [29] </ref>), can be shown to form a (1=r)-approximation with n-exponential probability. Part (3) follows from a straightforward parallelization of a result of Matousek [41]. <p> We then perform a parallel prefix computation to compress all the unfinished tasks into an array of size n 3=4 , if possible. Finally, we make n 1=6 copies of each unfinished task and run all these copies in parallel. In the full version we show, using Chernoff bounds <ref> [29] </ref>, that this scheme runs in the claimed bounds with n-exponential probability. Again, assuming that S is a (1=r)-semi-net, the total running time is therefore O (log n) using O (n bd=2c ) work, with n-exponential probability.
Reference: [30] <author> D. Haussler and E. Welzl. </author> <title> Epsilon-nets and simplex range queries. </title> <journal> Discrete Comput. Geom., </journal> <volume> 2 </volume> <pages> 127-151, </pages> <year> 1987. </year>
Reference-contexts: We say such ranges are missed by Y . Define f 0 (r) to be the 3 There is a related notion, known as the VC-dimension <ref> [30, 37] </ref>, and this is subsumed in the above definition, since a set system with VC-dimension d has VC-exponent d as well [53, 57]. 4 Note that the probability is on the event that the construction yields a (1=r)-approximation, not on the running time. expected number of missed ranges generated by
Reference: [31] <author> A. Heppes. </author> <title> Beweis einer vermutung von a. </title> <journal> vazsonyi. Acta Math. Acad. Sci. Hungar., </journal> <volume> 7 </volume> <pages> 463-466, </pages> <year> 1956. </year>
Reference-contexts: Let B = B (X; r) = fb (x; r) : x 2 Xg. We are interested in computing the intersection B " of these balls, a convex body with linear boundary complexity <ref> [31] </ref>. The interest in this object originates in its relevance to the computation of the diameter of X, the largest distance between any pair of points in X.
Reference: [32] <author> H. Karloff and Y. Mansour. </author> <title> On construction of k-wise independent random variables. </title> <booktitle> In Proc. ACM Sympos. Theory of Computing, </booktitle> <pages> pages 564-573, </pages> <year> 1994. </year>
Reference-contexts: Proof: (Sketch) Given Lemma 2.2, the proof is a straightforward application of the limited independence parallel de-randomization technique (e.g., see Luby [34, 35] or Karloff and Mansour <ref> [32] </ref>). The only possibly difficult step in the above proof is in the computation of f 0 (r) for a given set system.
Reference: [33] <author> D. G. Kirkpatrick and R. Seidel. </author> <title> The ultimate planar convex hull algorithm? SIAM J. </title> <journal> Comput., </journal> <volume> 15 </volume> <pages> 287-299, </pages> <year> 1986. </year>
Reference-contexts: Accounting for output size, the lower bound becomes W (h + n log h), where h is the size of the convex hull. The first output-sensitive algorithm, due to Kirkpatrick and Seidel <ref> [33] </ref>, computed the convex hull in IR 2 in O (n log h) time. Clarkson and Shor [15] gave an optimal randomized output-sensitive solution for 3-dimensional convex hulls, which was optimally derandomized by Chazelle and Matousek [13]. <p> By Theorem 2.10 (3), we obtain a 0 shallow (1=h)-cutting of size O (h). Everything proceeds as before except the contours are computed using a parallel version of Kirkpatrick and Seidel's <ref> [33] </ref> output-sensitive planar convex hull algorithm, due to Ghouse and Goodrich [25], which can be implemented to run in O (log 2 n) time using O (n log h) work on an EREW PRAM.
Reference: [34] <author> M. Luby. </author> <title> A simple parallel algorithm for the maximal independent set problem. </title> <journal> SIAM J. Comput., </journal> <volume> 15(4) </volume> <pages> 1036-1053, </pages> <year> 1986. </year>
Reference-contexts: Proof: (Sketch) Given Lemma 2.2, the proof is a straightforward application of the limited independence parallel de-randomization technique (e.g., see Luby <ref> [34, 35] </ref> or Karloff and Mansour [32]). The only possibly difficult step in the above proof is in the computation of f 0 (r) for a given set system.
Reference: [35] <author> M. Luby. </author> <title> Removing randomness in parallel computation without a processor penalty. </title> <booktitle> In Proc. IEEE Sympos. Foundations of Computer Science, </booktitle> <pages> pages 162-173, </pages> <year> 1988. </year>
Reference-contexts: Proof: (Sketch) Given Lemma 2.2, the proof is a straightforward application of the limited independence parallel de-randomization technique (e.g., see Luby <ref> [34, 35] </ref> or Karloff and Mansour [32]). The only possibly difficult step in the above proof is in the computation of f 0 (r) for a given set system.
Reference: [36] <author> Y. Matias and U. Vishkin. </author> <title> Converting high probability into nearly-constant timewith applications to parallel hashing. </title> <booktitle> In 23rd ACM Symp. on Theory of Computing, </booktitle> <pages> pages 307-316, </pages> <year> 1991. </year>
Reference-contexts: Then one can perform all n tasks in O (log n + t log log n) time using O (nw) work on an EREW PRAM, with n-exponential probability. Proof: (Sketch) The method is based upon be a combination of parallel divide-and-conquer and failure sweeping <ref> [25, 36] </ref>. If n is smaller than some suitably large constant, we solve the duration-unknown scheduling problem by replicating the n tasks a constant number of times and running all copies in parallel. <p> Since n decreases as the algorithm progresses, we need a second technique to boost the degrading exponential probability to n 0 -exponential. This is achieved with the failure sweeping technique <ref> [25, 36] </ref>.
Reference: [37] <author> J. Matousek. </author> <title> Approximations and optimal geometric divide-and-conquer. </title> <booktitle> In Proc. 23rd Annu. ACM Sympos. Theory Comput., </booktitle> <pages> pages 505-511, </pages> <year> 1991. </year> <note> Also to appear in J. </note> <institution> Comput. Syst. Sci. </institution>
Reference-contexts: Let us therefore assume for the remainder of this section that we are dealing with set systems with finite VC-exponent. Adapting a definition from [57], we say that a (1=r)- approximation <ref> [37] </ref> of X is a subset Y such that, for any R 2 F (X), fi fi jY " Rj jXj fi fi &lt; r Matousek [37] shows how to compute a (1=r)- approximation of size O (r 2 log r) in O (nr O (1) ) time. <p> Adapting a definition from [57], we say that a (1=r)- approximation <ref> [37] </ref> of X is a subset Y such that, for any R 2 F (X), fi fi jY " Rj jXj fi fi &lt; r Matousek [37] shows how to compute a (1=r)- approximation of size O (r 2 log r) in O (nr O (1) ) time. <p> We say such ranges are missed by Y . Define f 0 (r) to be the 3 There is a related notion, known as the VC-dimension <ref> [30, 37] </ref>, and this is subsumed in the above definition, since a set system with VC-dimension d has VC-exponent d as well [53, 57]. 4 Note that the probability is on the event that the construction yields a (1=r)-approximation, not on the running time. expected number of missed ranges generated by
Reference: [38] <author> J. Matousek. </author> <title> Cutting hyperplane arrangements. </title> <journal> Discrete Comput. Geom., </journal> <volume> 6 </volume> <pages> 385-406, </pages> <year> 1991. </year>
Reference-contexts: (r=n) D t (D+2) : Clarkson and Shor [15] show (using a slightly different no tation) that X jF s (X)j C (k) D f 0 (n=k); 5 Our definition of a semi-net is motivated by the (1=r)-semi-cutting notion introduced by Chazelle [10], as well as proof techniques given in <ref> [12, 27, 38] </ref>. for some constant C &gt; 0. Thus, the expectation (1) is at most bCf 0 (r) + b 1tr which can be bounded by bCf 0 (r) + b 1tr for some constant a &gt; 1, provided that f 0 is non-decreasing. <p> For any simplex s, let H js denote the set of hyperplanes of H intersecting the interior of s. The set H js is often referred to as the conflict list for s relative to H [15]. In hyperplane set systems the ranges are H js sets. A (1=r)-cutting <ref> [38] </ref> of H is a partition C of (possibly unbounded) d-simplices that cover IR d and such that jH js j n=r for each s 2 C. <p> Proof: We use an adaptation of proof techniques used by Chazelle and Friedman [12] and Matousek <ref> [38] </ref>. For each simplex s in T (Y ), if jH js j &gt; n=r, then we form a (1=t)-cutting C s of size at most O (t d+1 ) for H js , where t = jH js jr=n.
Reference: [39] <author> J. Matousek. </author> <title> Reporting points in halfspaces. </title> <journal> Comput. Geom. Theory Appl., </journal> <volume> 2(3) </volume> <pages> 169-186, </pages> <year> 1992. </year>
Reference-contexts: Eventually, this blow-up leads to the total problem size becoming too large to process optimally. We get around this problem using a number of new ideas. For example, in our randomized method for d 4 we show how to use a parallel analogue to Matousek's shallow-cutting lemma <ref> [39] </ref>, together with a technique we call biased sampling, to garbage collect the size blow-up after a certain number of iterations. (Incidentally, this biased sampling technique was recently discovered independently in a slightly different form by Rajasekaran and Ramaswami [49].) In addition, so as to get an n-polynomial probability 2 bound, <p> We can do better than this, however, by restricting the way ranges are generated in our set system. 2.3 Shallow cuttings The first such restriction we consider is to shallow cuttings <ref> [39] </ref>. Let o denote a fixed origin with respect to IR d . Define the level of a point p 2 IR d relative to H to be the number of hyperplanes in H that are crossed by the open segment op. <p> Given l n, a collection C of simplices in IR d is an l-shallow (1=r)-cutting of H if the simplices in C cover all points of level at most l (and possibly more than this) and if jH js j n=r for each s 2 S. Matousek <ref> [39] </ref> shows that an l-shallow (1=r)-cutting of n hyperplanes in IR d of size O (r bd=2c (l (r=n) + 1) dd=2e ) can be constructed in polynomial time for any r 2 [1; n], and in O (n log r) time for r n ff .
Reference: [40] <author> J. Matousek and O. Schwarzkopf. </author> <title> A deterministic algorithm for the three-dimensional diameter problem. </title> <booktitle> In Proc. 25th Annu. ACM Sympos. Theory Comput., </booktitle> <pages> pages 478-484, </pages> <year> 1993. </year>
Reference-contexts: Using the algorithm for ball intersection together with parametric search [43] as in previous works <ref> [11, 40] </ref>, we obtain a sequential algorithm for computing the diameter of a point set in IR 3 with running time O (n log 3 n) that is arguably simpler than the algorithm with the same running time by Bronnimann et al. [8]. <p> We only describe the necessary variations, further details are given in the full version. Some of the other required ingredients have been described in <ref> [40] </ref>. (i) A point o in the interior can be determined using techniques similar to those for solving linear programming problems, in O (log 2 n) time with O (n) work. (ii) For a sample R B, R " can be computed by a brute force method. <p> A canonical triangulation S R can be obtained as follows <ref> [40] </ref>: the boundary is triangulated by drawing for each face and vertex the segment of great circle on the face through the vertex and the poles; then the trapezoids on the boundary are joined to the interior point o to form bricks. (iii) For brick s 2 S R , let <p> Our set system consists of sets B s . In <ref> [40] </ref>, using a linearization technique, it is shown that a sample R of size r = n * with appropriate properties (jB s j c 1 (n=r) log r for each s and P s2S R jB s j c 2 n) can be computed in O (n log n) time. <p> Using the techniques of [27], that sample can be obtained in O (log 2 n) time with O (n log n) work in the EREW PRAM model. (iv) The conflict lists B s can be computed using point location in an arrangement of hyperplanes as in <ref> [40] </ref> by using the mentioned linearization technique. (Alternatively, in a sequential algorithm, the conflict lists can be obtained using a hierarchical decomposition [22] to determine a first intersection point between each bounding sphere and the boundary of R " , and then walking to determine all the intersection.) (v) The contours <p> Diameter. Using the algorithm for ball intersection together with parametric search [43] as in previous works <ref> [11, 40] </ref>, we obtain a sequential algorithm for the diameter problem with running time O (n log 3 n). First, we need to make the ball intersection algorithm into an oracle that determines whether D &gt; r, D &lt; r or D = r. <p> Using the linearization technique of <ref> [40] </ref>, this becomes a problem of point location among hyperplanes. The total work is O (n log n). If at any moment, a point is not in any brick then D &gt; r.
Reference: [41] <author> J. Matousek. </author> <title> Efficient partition trees. </title> <journal> Discrete Comput. Geom., </journal> <volume> 8 </volume> <pages> 315-334, </pages> <year> 1992. </year>
Reference-contexts: Part (2) follows by taking a random sample of size O (n * r 2 ), which by a Chernoff bound (e.g., see [29]), can be shown to form a (1=r)-approximation with n-exponential probability. Part (3) follows from a straightforward parallelization of a result of Matousek <ref> [41] </ref>. As it turns out, these size bounds are too large to be of direct use in our convex hull algorithms, however. 2.1 Semi-nets Let Y be a subset of X, and let a parameter r 2 [1; n] be given. <p> Chazelle [9] shows that such a (1=r)-cutting can be constructed in O (nr d1 ) time, for any r 2 [1; n], and Matousek <ref> [41] </ref> shows that such a cutting can be constructed in O (n log r) time for r n ff , for some small constant ff &gt; 0 that depends upon d. <p> We can also easily construct the new conflict lists with this complexity. If Y has order !, then the total size and work bounds are as claimed above. On the surface this appears to be no better than the existing (1=r)-cutting constructions <ref> [9, 12, 27, 41] </ref>, for in the standard hyperplane set system jT (Y )j is O (r d ).
Reference: [42] <author> J. Matousek. </author> <title> Linear optimization queries. </title> <journal> J. Algorithms, </journal> <volume> 14 </volume> <pages> 432-448, </pages> <year> 1993. </year> <title> The results combined with results of O. </title> <note> Schwarzkopf also appear in Proc. 8th ACM Sympos. Comput. Geom., </note> <year> 1992, </year> <pages> pages 16-25. </pages>
Reference-contexts: In higher dimensions, the only deterministic output-sensitive method known, due to Seidel [55], runs in time O (n 2 +h log n), which can be slightly improved to O (n 2 (2=(bd=2c+1))+* + h log n), for any fixed * &gt; 0, using a technique of Matousek <ref> [42] </ref>. All of these methods for d 3 seem inherently sequential. The parallel construction of the convex hull has also received much attention.
Reference: [43] <author> N. Megiddo. </author> <title> Applying parallel computation algorithms in the design of serial algorithms. </title> <journal> J. ACM, </journal> <volume> 30 </volume> <pages> 852-865, </pages> <year> 1983. </year>
Reference-contexts: It is also the easiest to simulate on more-realistic parallel models, and, by a scheme due to Cole [16, 17], algorithms for this model can sometimes be used to derive faster sequential parametric searching algorithms (e.g., see <ref> [1, 11, 43] </ref>) than would be possible using concurrent-read parallel methods. Our methods are all based upon a parallel divide-and-conquer scheme, where one subdivides the space into cells that should contain fewer halfspaces and then recurses on each cell in parallel. <p> We also show that with appropriate modifications, our deterministic 3-dimensional convex hull algorithm can be used to compute, in the same resource bounds, the intersection of n balls of equal radius in IR 3 . Using the algorithm for ball intersection together with parametric search <ref> [43] </ref> as in previous works [11, 40], we obtain a sequential algorithm for computing the diameter of a point set in IR 3 with running time O (n log 3 n) that is arguably simpler than the algorithm with the same running time by Bronnimann et al. [8]. <p> Diameter. Using the algorithm for ball intersection together with parametric search <ref> [43] </ref> as in previous works [11, 40], we obtain a sequential algorithm for the diameter problem with running time O (n log 3 n). First, we need to make the ball intersection algorithm into an oracle that determines whether D &gt; r, D &lt; r or D = r.
Reference: [44] <author> R. Miller and Q. F. Stout. </author> <title> Efficient parallel convex hull algorithms. </title> <journal> IEEE Trans. Comput., </journal> <volume> C-37(12):1605-1618, </volume> <year> 1988. </year>
Reference-contexts: Optimal deterministic 2-dimensional convex hull algorithms running in O (log n) time using O (n log n) work for the CREW PRAM were given by Atallah and Goodrich [6, 7] and Ag-garwal et al. [2], and for the EREW PRAM by Miller and Stout <ref> [44] </ref>. <p> We can construct the contours in O (log n) time and O (n log n) work using the optimal EREW PRAM planar convex hull algorithm of Miller and Stout <ref> [44] </ref>. Note that all halfspaces contributing an edge to a contour contribute a face to H " .
Reference: [45] <author> W. Paul, U. Vishkin, and H. Wagener. </author> <title> Parallel dictionaries on 2-3 trees. </title> <booktitle> In Proceedings of the Tenth ICALP, </booktitle> <pages> pages 597-609, </pages> <year> 1983. </year>
Reference-contexts: The closest point queries needed to construct the rays can be done by binary search on the contours in O (log n) time using O (n) work on an EREW PRAM <ref> [45] </ref>. The following lemma shows that after pruning jH nc j = O (n). Lemma 4.2 A halfspace h 2 H nc is pinned to at most one simplex s 2 S R .
Reference: [46] <author> M. Pellegrini. </author> <title> On point location and motion planning among sim-plicies. </title> <booktitle> In Proc. ACM Sympos. Theory of Computing, </booktitle> <pages> pages 95-104, </pages> <year> 1994. </year>
Reference-contexts: This concept was introduced by Chazelle [10], extended to the parallel domain by Goodrich [27], and, more recently, used by Pellegrini <ref> [46] </ref> in the design of efficient sequential data structures. Define V (H; s) to be the set of all vertices in an arrangement A (H) of a set of hyperplanes, H, that are in the interior of a simplex s.
Reference: [47] <author> F. P. Preparata and S. J. Hong. </author> <title> Convex hulls of finite sets of points in two and three dimensions. </title> <journal> Commun. ACM, </journal> <volume> 20 </volume> <pages> 87-93, </pages> <year> 1977. </year>
Reference-contexts: A portion of this effort was done while this author was visiting the University of Illinois at Urbana-Champaign. z This research supported in part by NSF Grant CCR-9118874. 1.1 Related work Optimal deterministic sequential algorithms have long been known for the cases d = 2; 3 <ref> [28, 47] </ref>. In higher dimensions, d 4, Seidel proposed two deterministic algorithms. His first algorithm [54] ran in O (n log n + n dd=2e ) time 1 , which is optimal for even d, and later he gave an O (n bd=2c log n) solution [55].
Reference: [48] <author> F. P. Preparata and M. I. Shamos. </author> <title> Computational Geometry: an Introduction. </title> <publisher> Springer-Verlag, </publisher> <address> New York, NY, </address> <year> 1985. </year>
Reference-contexts: In IR d , the size of the convex hull of n points is Q (n bd=2c ) in the worst case, and its construction requires W (n log n + n bd=2c ) work <ref> [23, 48] </ref>. fl This research supportedin part by an AT&T Bell LaboratoriesGraduate Fellowship and by NSF Grant CCR-9315696. y This research supported by the NSF under Grants IRI-9116843 and CCR-9300079.
Reference: [49] <author> S. Rajasekaran and S. Ramaswami. </author> <title> Optimal parallel randomized algorithms for the Voronoi diagram of line segments in the plane and related problems. </title> <booktitle> In Proc. 10th Annu. ACM Sympos. </booktitle> <institution> Comput. Geom., </institution> <year> 1994. </year>
Reference-contexts: show how to use a parallel analogue to Matousek's shallow-cutting lemma [39], together with a technique we call biased sampling, to garbage collect the size blow-up after a certain number of iterations. (Incidentally, this biased sampling technique was recently discovered independently in a slightly different form by Rajasekaran and Ramaswami <ref> [49] </ref>.) In addition, so as to get an n-polynomial probability 2 bound, rather than just an expected-time bound, 2 We use n-polynomial to refer to a probability that is at least 11=n c , for some constant c 1; we use n-exponential to refer to a probability we use a duration-unknown
Reference: [50] <author> E. A. Ramos. </author> <title> An algorithm for intersecting equal radius balls r 3 . Technical Report UIUCDCS-R-94-1851, </title> <institution> Dept. of Computer Science, University of Illinois at Urbana-Champaign, </institution> <year> 1994. </year>
Reference-contexts: For this each point of X is located inside a brick 8 Previous work, using only elementary techniques (not using geometric sampling) could only achieve running times O (n log 2 n) and O (n log 5 n) respectively <ref> [50] </ref>. s 2 S R in each stage of the algorithm. Using the linearization technique of [40], this becomes a problem of point location among hyperplanes. The total work is O (n log n). If at any moment, a point is not in any brick then D &gt; r.
Reference: [51] <author> J.H. Reif and S. Sen. </author> <title> Optimal parallel randomized algorithms for three-dimensional convex hulls and related problems. </title> <journal> SIAM J. Com-put., </journal> <volume> 21(3) </volume> <pages> 466-485, </pages> <year> 1992. </year>
Reference-contexts: For some time, the only solution to the 3-dimensional convex hull problem optimal with respect to time or work was the O (log n) time and O (n log n) work randomized algorithm for the CREW PRAM of Reif and Sen <ref> [51] </ref>. <p> Finally, we get around the size blow-up problem for the 3-dimensional halfspace intersection by using a new pruning computation, which removes halfspaces that cannot ultimately contribute vertices to the final intersection. This type of technique was first introduced by Reif and Sen <ref> [51] </ref> in their randomized 3-dimensional halfspace intersection algorithm. Our pruning computation is quite different from theirs, however, and is considerably simpler. <p> This general approach was first used for IR 3 by Clarkson and Shor [15] in their sequential randomized output-sensitive algorithm, and was also used in the randomized parallel algorithm of Reif and Sen <ref> [51] </ref> for the CREW PRAM model. We select a random sample R H, construct the convex polyhedron R " , and triangulate its boundary. <p> We construct (and triangulate) R " in O (log n) time using O (n 2* log n) work [4]. As noted by Reif and Sen <ref> [51] </ref>, the set of sim-plices cut by a halfspace h 2 HnR can be found by locating the point D (h) in the arrangement A (G), where G = fD (p)jp 2 V [ og, V is the vertex set of R " , and D is the standard duality transform <p> same the constant-factor blow-up problem as the method for IR d of Section 3.1, i.e., over the O (log log n) recursive calls the total size of the subproblems can only be bounded by O (n log O (1) n). 4.1.1 Pruning In their CREW PRAM algorithm, Reif and Sen <ref> [51] </ref> overcome this size blow-up problem by first constructing T " , where T is a subset of the halfspaces in H that are known to be bounding halfspaces of H " . They then use T " to identify redundant halfspaces in Hn (T [ R). <p> The fact that the contours can be used to identify the trivial faces was noted by Clarkson and Shor [15], and was also used in the parallel algorithm of Reif and Sen <ref> [51] </ref>. Lemma 4.3 After removing trivial faces, jH c j = O (n). Proof: This follows from the facts that jH " j = O (n), a halfspace retained in H c js contributes a vertex to H " s , and vertices have degree three (assuming nondegeneracy). <p> The total expected work is O (n 0 log n 0 ) (and O (n 0 log 2 n 0 ) with n 0 -polynomial probability). To obtain optimal work with n 0 -polynomial probability, we use the polling technique of Reif and Sen <ref> [51] </ref>. This applies to the EREW PRAM model. n 0 -exponential probability. To achieve even higher probability we need two tools. The first one is to obtain a good sample at each stage with n-exponential probability using Theorem 2.10 to obtain a 0-shallow (1=r)-cutting in the CREW PRAM model. <p> We summarize the results in the following theorem. Both solve open problems of Reif and Sen <ref> [51] </ref>. <p> n can be solved in the EREW PRAM model with work O (n log n) and time O (log n) with n-polynomial probability, and in the CREW PRAM model with the same bounds with n-exponential probability. 4.3 Deterministic and output sensitive algo rithms Goodrich [27] has derandomized Reif and Sen's <ref> [51] </ref> three-dimensional convex hull algorithm to obtain a deterministic algorithm with optimal work and O (log 2 n) time on an EREW PRAM. His techniques [27] can be applied to our algorithm yielding a simpler deterministic algorithm with the same resource bounds. <p> B nc js can be computed by first recursively computing B c js and then using a hierarchical decomposition (b 2 B nc js if js " 6 b). Note that in the recursive computation always B nc js is empty. This was used in <ref> [51] </ref>. (vii) The detection and removal of trivial faces is similar to that for the case of halfspaces, we only point out that a single ball can contribute more than one piece of trivial face inside a brick s. Diameter.
Reference: [52] <author> J.H. Reif and S.Sen. </author> <title> Randomized algorithms for binary search and load balancing on fixed connection networks with geometric applications. </title> <booktitle> In Proc. 2nd ACM Sympos. Parallel Algorithms Architect., </booktitle> <pages> pages 327-337, </pages> <year> 1990. </year>
Reference-contexts: The deterministic result for the EREW PRAM model uses an appropriate replication of the data structure, while the randomized result uses a technique of Reif and Sen <ref> [52] </ref>. 4 3-Dimensional Convex Hulls Let H be a set of n halfspaces in IR 3 containing a known point o.
Reference: [53] <author> N. Sauer. </author> <title> On the density of families of sets. </title> <journal> J. Combin. Theory Ser. A, </journal> <volume> 13 </volume> <pages> 145-147, </pages> <year> 1972. </year>
Reference-contexts: We say such ranges are missed by Y . Define f 0 (r) to be the 3 There is a related notion, known as the VC-dimension [30, 37], and this is subsumed in the above definition, since a set system with VC-dimension d has VC-exponent d as well <ref> [53, 57] </ref>. 4 Note that the probability is on the event that the construction yields a (1=r)-approximation, not on the running time. expected number of missed ranges generated by an r-sized (fully independent) random sample S of X (with all such samples equally likely).
Reference: [54] <author> R. Seidel. </author> <title> A convex hull algorithm optimal for point sets in even dimensions. M.Sc. </title> <type> thesis, </type> <institution> Dept. Comput. Sci., Univ. British Columbia, Vancouver, BC, </institution> <year> 1981. </year> <type> Report 81/14. </type>
Reference-contexts: In higher dimensions, d 4, Seidel proposed two deterministic algorithms. His first algorithm <ref> [54] </ref> ran in O (n log n + n dd=2e ) time 1 , which is optimal for even d, and later he gave an O (n bd=2c log n) solution [55].
Reference: [55] <author> R. Seidel. </author> <title> Constructing higher-dimensional convex hulls at logarithmic cost per face. </title> <booktitle> In Proc. 18th Annu. ACM Sympos. Theory Comput., </booktitle> <pages> pages 404-413, </pages> <year> 1986. </year>
Reference-contexts: In higher dimensions, d 4, Seidel proposed two deterministic algorithms. His first algorithm [54] ran in O (n log n + n dd=2e ) time 1 , which is optimal for even d, and later he gave an O (n bd=2c log n) solution <ref> [55] </ref>. For some time, the only solutions optimal in higher dimensions were the randomized incremental algorithm of Clarkson and Shor [15], and the subsequent randomized method of Seidel [56]. <p> Clarkson and Shor [15] gave an optimal randomized output-sensitive solution for 3-dimensional convex hulls, which was optimally derandomized by Chazelle and Matousek [13]. In higher dimensions, the only deterministic output-sensitive method known, due to Seidel <ref> [55] </ref>, runs in time O (n 2 +h log n), which can be slightly improved to O (n 2 (2=(bd=2c+1))+* + h log n), for any fixed * &gt; 0, using a technique of Matousek [42]. All of these methods for d 3 seem inherently sequential.
Reference: [56] <author> R. Seidel. </author> <title> Small-dimensional linear programming and convex hulls made easy. </title> <journal> Discrete Comput. Geom., </journal> <volume> 6 </volume> <pages> 423-434, </pages> <year> 1991. </year>
Reference-contexts: For some time, the only solutions optimal in higher dimensions were the randomized incremental algorithm of Clarkson and Shor [15], and the subsequent randomized method of Seidel <ref> [56] </ref>. Recently, Chazelle [10] gave the first deterministic algorithm that is optimal in higher dimensions, which was simplified by Bronnimann et al. [8]. The optimality of the above algorithms is measured with respect to the worst-case size complexity of the resulting convex hull.
Reference: [57] <author> V. N. Vapnik and A. Y. Chervonenkis. </author> <title> On the uniform convergenceof relative frequencies of events to their probabilities. </title> <journal> Theory Probab. Appl., </journal> <volume> 16 </volume> <pages> 264-280, </pages> <year> 1971. </year>
Reference-contexts: That is, each range in R 2 F (Y ) is determined by at most d (d + 1) trigger hyperplanes. Let us therefore assume for the remainder of this section that we are dealing with set systems with finite VC-exponent. Adapting a definition from <ref> [57] </ref>, we say that a (1=r)- approximation [37] of X is a subset Y such that, for any R 2 F (X), fi fi jY " Rj jXj fi fi &lt; r Matousek [37] shows how to compute a (1=r)- approximation of size O (r 2 log r) in O (nr <p> We say such ranges are missed by Y . Define f 0 (r) to be the 3 There is a related notion, known as the VC-dimension [30, 37], and this is subsumed in the above definition, since a set system with VC-dimension d has VC-exponent d as well <ref> [53, 57] </ref>. 4 Note that the probability is on the event that the construction yields a (1=r)-approximation, not on the running time. expected number of missed ranges generated by an r-sized (fully independent) random sample S of X (with all such samples equally likely).
References-found: 57

