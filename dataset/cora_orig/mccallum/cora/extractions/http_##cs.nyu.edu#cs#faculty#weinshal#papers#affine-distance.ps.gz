URL: http://cs.nyu.edu/cs/faculty/weinshal/papers/affine-distance.ps.gz
Refering-URL: http://cs.nyu.edu/cs/faculty/weinshal/papers.html
Root-URL: http://www.cs.nyu.edu
Title: Similarity and Affine Invariant Distances Between 2D Point Sets  
Author: Michael Werman and Daphna Weinshall 
Keyword: image matching, pattern analysis, 2D affine in-variance, 2D similarity invariance, image metric.  
Date: 17(8):810-814, 1995 1  
Note: IEEE Transactions on Pattern Analysis and Machine Intelligence,  
Abstract: We develop expressions for measuring the distance between 2D point sets, which are invariant to either 2D affine transformations or 2D similarity transformations of the sets, and assuming a known correspondence between the point sets. We discuss the image normalization to be applied to the images before their comparison so that the computed distance is symmetric with respect to the two images. We then give a general (metric) definition of the distance between images, which leads to the same expressions for the similarity and affine cases. This definition avoids ad-hoc decisions about normalization. Moreover, it makes it possible to compute the distance between images under different conditions, including cases where the images are treated asymmetrically. We demonstrate these results with real and simulated images. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> K. Fukunaga. </author> <title> Introduction to statistical pattern recognition. </title> <publisher> Academic Press, </publisher> <address> Boston, </address> <year> 1990. </year>
Reference-contexts: This method is related to the Whitening transformation, a linear transformation of data which transforms its covariance matrix into the unit matrix <ref> [1, 4] </ref>. This transformation does not preserve Euclidean distances. In Section 2 we give the expression for the distance between images up to 2D similarity transformations, which Dept. of Computer Science, The Hebrew University, 91904, Jerusalem, Israel, werman@cs.huji.ac.il, daphna@cs.huji.ac.il, This research was sponsored by the U.S.
Reference: [2] <author> G. H. Golub and C. F. Van Loan. </author> <title> Matrix Computations. </title> <publisher> Johns Hopkins University Press, </publisher> <address> Baltimore, </address> <year> 1989. </year>
Reference-contexts: Thus a natural distance between images matched up to similarity is the distance between their corresponding four-dimensional subspaces, and the distance between images matched up to affine transformation is the distance between their corresponding six-dimensional sub-spaces. We use the following distance between subspaces <ref> [2] </ref>: a subspace of R 2k can be identified with the matrix that corresponds to the linear operator of orthogonal projection into that subspace. The distance between subspaces is the norm of the difference between their corresponding projection matrices.
Reference: [3] <author> A. Rosenfeld and A. C. Kak. </author> <title> Digital picture processing. </title> <publisher> Academic Press, </publisher> <address> Boston, </address> <year> 1982. </year>
Reference-contexts: However, under the weak perspective (scaled orthographic) projection model assumed here, it is possible to remove the effects of certain camera transformations, such as rotations about the optical axis and translations. More specifically, there exist standard methods of image normalization with respect to the following image transformations <ref> [3] </ref>: Translations: the image is shifted so that its centroid is at the origin. Rotations: the image is rotated so that its principal axis has some standard orientation.
Reference: [4] <author> J. Sprinzak and M. Werman. </author> <title> Affine point matching. </title> <journal> Pattern Recognition Letters, </journal> <year> 1993. </year>
Reference-contexts: This method is related to the Whitening transformation, a linear transformation of data which transforms its covariance matrix into the unit matrix <ref> [1, 4] </ref>. This transformation does not preserve Euclidean distances. In Section 2 we give the expression for the distance between images up to 2D similarity transformations, which Dept. of Computer Science, The Hebrew University, 91904, Jerusalem, Israel, werman@cs.huji.ac.il, daphna@cs.huji.ac.il, This research was sponsored by the U.S.
Reference: [5] <author> D. Weinshall, M. Werman, and N. Tishby. </author> <title> Stability and likelihood of views of three dimensional objects. </title> <booktitle> In ECCV, </booktitle> <pages> pages 24-35, </pages> <year> 1994. </year>
Reference-contexts: This approach defines distance measures between images that have metric properties. We show that both definitions are equivalent, leading to the same expressions. Finally, Section 4 contains examples with real and simulated images (see <ref> [5] </ref> for a more advanced use of metric). 2 Normalization and comparison We assume here objects composed of n three dimensional fiducial points. <p> 0.412 0.341 0.854 Table 1: The similarity and affine distances between three images of a tiger, shown in Fig. 3, to a reference image shown in Fig. 2. demonstrate that both the affine and similarity distances increase with the inter-view distance on the viewing sphere. 5 Discussion: an application In <ref> [5] </ref> we used these expressions to analyze the stability and likelihood of 2D images of 3D objects. There we compared different images of the same 3D object, and we therefore used the three 2D image metrics developed above.
References-found: 5

