URL: http://www.cs.umn.edu/Research/Agassiz/Paper/choi.tpds.compiler.ps.Z
Refering-URL: http://www.cs.umn.edu/Research/Agassiz/agassiz_pubs.html
Root-URL: http://www.cs.umn.edu
Email: Email: lchoi@csrd.uiuc.edu  Email: yew@cs.umn.edu  
Title: Compiler Analysis for Cache Coherence: Interprocedural Array Data-Flow Analysis and Its Impacts on Cache Performance 1  
Author: Lynn Choi Pen-Chung Yew 
Keyword: Compiler, Interprocedural Analysis, Data-Flow Analysis, Cache Coherence, Shared-Memory Multiprocessors.  
Address: 1308 West Main Street Urbana, IL 61801  Building  200 Union Street, SE Minneapolis, MN 55455-0159  
Affiliation: Center for Supercomputing Research and Development University of Illinois at Urbana-Champaign  4-192 EE/CS  Department of Computer Science University of Minnesota  
Abstract: In this paper, we present compiler algorithms for detecting references to stale data in shared-memory multiprocessors. The algorithm consists of two key analysis techniques, stale reference detection and locality preserving analysis. While the stale reference detection finds the memory reference patterns that may violate cache coherence, the locality preserving analysis minimizes the number of such stale references by analyzing both temporal and spatial reuses. By computing the regions referenced by arrays inside loops, we extend the previous scalar algorithms [8] for more precise analysis. We develop a full interprocedural array data-flow algorithm, which performs both bottom-up side-effect analysis and top-down context analysis on the procedure call graph to further exploit locality across procedure boundaries. The interprocedural algorithm eliminates cache invalidations at procedure boundaries, which were assumed in the previous compiler algorithms [9]. We have fully implemented the algorithm in the Polaris par-allelizing compiler [27]. Using execution-driven simulations on Perfect Club benchmarks, we demonstrate how unnecessary cache misses can be eliminated by the automatic stale reference detection. The algorithm can be used to implement cache coherence in the shared-memory multiprocessors that do not have hardware directories, such as Cray T3D [20]. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. V. Adve, V. S. Adve, M. D. Hill, and M. K. Vernon. </author> <title> Comparison of Hardware and Software Cache Coherence Schemes. </title> <booktitle> Proceedings of the 18th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 298-308, </pages> <month> May </month> <year> 1991. </year> <month> 30 </month>
Reference-contexts: They usually require compile time analysis to detect possible stale data accesses and to invalidate stale cache entries. Although the performance of such schemes have been demonstrated through simulations, most of those studies assume either perfect compile-time analysis or analytical models without real compiler implementations <ref> [1, 6, 17, 23, 25, 26] </ref>. It is still unknown how effectively the compiler can detect potential stale references and what kind of performance can be obtained by using a real compiler.
Reference: [2] <author> A. Agarwal et al. </author> <title> The MIT Alewife Machine: A Large-Scale Distributed-Memory Multiprocessor. </title> <booktitle> Proceedings of Workshop on Scalable Shared Memory Multiprocessors, </booktitle> <year> 1991. </year>
Reference-contexts: Having multiple cached copies of a shared memory location, however, can lead to erroneous program behavior unless they are maintained coherent. Existing solutions for large-scale multiprocessors include hardware directory-based coherence protocols, which have been studied in many research machines <ref> [2, 21, 22] </ref>. Although these hardware schemes can precisely identify stale data by maintaining sharing information at runtime, they substantially increase the hardware cost for the directory storage and require complex directory and cache controllers.
Reference: [3] <author> R. Ballance, A. Maccabe, and K. Ottenstein. </author> <title> The Program Dependence Web: a Representation Supporting Control Data- and Demand-Driven Interpretation of Imperative Languages. </title> <booktitle> Proceedings of the SIGPLAN '90 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 257-271, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: We use a combination of interval and data-flow analysis techniques to determine memory reference patterns which can lead to stale data accesses. To obtain more precise array access information, we compute the array region referenced by each array reference. Gated single assignment (GSA) <ref> [3] </ref> form is used to compute equality and comparison between the array regions involving symbolic expressions. Two key analysis techniques are used to identify potentially stale references: (1) stale reference pattern detection, and (2) locality preserving analysis. <p> Static single assignment (SSA) [16] is a representation of a program in which each use of a variable is reached by exactly a single definition of the variable. It allows us to track the value of a variable by its name. Gated single assignment (GSA) <ref> [3] </ref> introduces three types of pseudo-assignment functions, which are extensions of the OE functions used in SSA: * fl (cond, value1, value2) : for OE function located immediately after an IF statement.
Reference: [4] <author> M. Berry and others. </author> <title> The Perfect Club Benchmarks: Effective Performance Evaluation of Supercomputers. </title> <journal> International Journal of Supercomputer Applications, </journal> <volume> 3(3) </volume> <pages> 5-40, </pages> <month> Fall, </month> <year> 1989. </year>
Reference-contexts: This algorithm eliminates cache invalidations, which are assumed by all previous compiler-directed coherence schemes, and allows the locality of programs to be preserved across procedure boundaries. All of these compiler algorithms have been implemented in the Polaris parallelizing compiler, and experimentation results on Perfect Club benchmarks <ref> [4] </ref> are discussed. Execution-driven simulations are used to verify the compiler marking and to demonstrate the performance of automatic stale reference detection. <p> For a more precise array analysis, we construct GSA interprocedurally using side effect (MAYMOD) information with additional flow analysis. 5 Experimentation We have implemented all the compiler algorithms in the Polaris parallelizing compiler. In this section, we demonstrate how different compiler algorithms affect the performance. Perfect Club benchmark suites <ref> [4] </ref> are chosen as our target applications. They are first parallelized by the Polaris compiler. In the parallelized codes, the parallelism is expressed in terms of DOALL loops.
Reference: [5] <author> D. Callahan and K. Kennedy. </author> <title> Analysis of Interprocedural Side Effects in a Parallel Programming Environment. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 5 </volume> <pages> 517-550, </pages> <year> 1988. </year>
Reference-contexts: A subarray consists of a subscripted variable and one or more ranges for some of the indices in its subscript expression. A range is represented by a lower bound, a upper bound and a stride. The notion of a subarray is an extension to the regular section used in <ref> [5] </ref>. <p> There have been many studies on array data-flow algorithms. Granston proposed algorithms to detect redundant array references [19]. Feautrier [18] gave an algorithm to calculate them exactly. Pugh [29] developed some exact techniques that are substantially faster than Feautrier's. Our implementation is based on regular section analysis <ref> [5] </ref>, which is less accurate but allows large programs to be analyzed efficiently. 6.2 Code generation for other compiler-directed schemes In Lifespan strategy [7], memory-reads should be issued for all the potentially stale references. In addition, we need to compute the N-bit vector for all the read and write references.
Reference: [6] <author> Y.-C. Chen and A. Veidenbaum. </author> <title> Comparison and Analysis of Software and Directory Coherence Schemes. </title> <booktitle> Proceedings Supercomputing'91, </booktitle> <pages> pages 818-829, </pages> <month> November </month> <year> 1991. </year>
Reference-contexts: They usually require compile time analysis to detect possible stale data accesses and to invalidate stale cache entries. Although the performance of such schemes have been demonstrated through simulations, most of those studies assume either perfect compile-time analysis or analytical models without real compiler implementations <ref> [1, 6, 17, 23, 25, 26] </ref>. It is still unknown how effectively the compiler can detect potential stale references and what kind of performance can be obtained by using a real compiler.
Reference: [7] <author> H. Cheong. </author> <title> Life Span Strategy A Compiler-Based Approach to Cache Coherence. </title> <booktitle> Proceedings of the 1992 International Conference on Supercomputing, </booktitle> <month> July </month> <year> 1992. </year>
Reference-contexts: Although these hardware schemes can precisely identify stale data by maintaining sharing information at runtime, they substantially increase the hardware cost for the directory storage and require complex directory and cache controllers. As an alternative, compiler-directed techniques <ref> [7, 9, 10, 15, 11, 17, 23, 24, 31] </ref> can be used to maintain coherence. In this approach, cache coherence is maintained locally without directory hardware, thus avoiding the complexity and overhead associated with hardware directories. <p> Execution-driven simulations are used to verify the compiler marking and to demonstrate the performance of automatic stale reference detection. The techniques developed here are general enough to be applicable to other compiler-directed coherence schemes <ref> [7, 9, 15] </ref>. 2 Background 2.1 Stale reference condition Memory event ordering Let's first define the ordering of events which leads to a stale reference. <p> Assuming only DOALL types of parallelism (i.e. no dependences among concurrent tasks), memory events (1) to (3) should occur in different epochs. Otherwise, there are dependences among concurrent tasks. To detect stale data reference from a source program, the previous compiler algorithms <ref> [8, 7, 31] </ref> look for the following memory reference patterns that consist of (a) a read or a write, (b) one or more epoch boundaries, (c) a write, (d) one or more epoch boundaries, and (e) a read. <p> In scalar analysis, even a write to a single element of an array is interpreted as a write to the entire array. This conservative scalar analysis often creates unnecessary cache misses, through either invalidations or redundant accesses to 5 the main memory <ref> [7, 9, 15] </ref>. These unnecessary memory accesses can be avoided by using a more precise analysis. In the following, we will demonstrate how automatic stale reference detection can be used to maintain coherence by developing both intra- and interprocedural array data-flow algorithms. <p> Pugh [29] developed some exact techniques that are substantially faster than Feautrier's. Our implementation is based on regular section analysis [5], which is less accurate but allows large programs to be analyzed efficiently. 6.2 Code generation for other compiler-directed schemes In Lifespan strategy <ref> [7] </ref>, memory-reads should be issued for all the potentially stale references. In addition, we need to compute the N-bit vector for all the read and write references. The bit vector is used to invalidate cache copies created by each read or write reference before a new version is created.
Reference: [8] <author> H. Cheong and A. Veidenbaum. </author> <title> Stale Data Detection and Coherence Enforcement Using Flow Analysis. </title> <booktitle> Proceedings of the 1988 International Conference on Parallel Processing, I, </booktitle> <address> Architecture:138-145, </address> <month> August </month> <year> 1988. </year>
Reference-contexts: Assuming only DOALL types of parallelism (i.e. no dependences among concurrent tasks), memory events (1) to (3) should occur in different epochs. Otherwise, there are dependences among concurrent tasks. To detect stale data reference from a source program, the previous compiler algorithms <ref> [8, 7, 31] </ref> look for the following memory reference patterns that consist of (a) a read or a write, (b) one or more epoch boundaries, (c) a write, (d) one or more epoch boundaries, and (e) a read. <p> And, the cache hit is determined by comparing the value with the timetag of the addressed cache copy. Figure 2 shows a sample program and the memory operations generated by a compiler for both SC and TPI schemes. 2.3 Array data-flow analysis Previous compiler algorithms <ref> [8, 15] </ref> treat an entire array as a single variable, leading to a conservative estimation of potential stale references. <p> For a target reference with no reaching definition inside a procedure, we issue a Time-Read with the minimum offset, implying that the referenced data item can be potentially modified before entering the procedure. This is an improvement over previous algorithms <ref> [8, 12] </ref> that use cache invalidation at the beginning of a procedure since only global and formal variables are affected by the unknown context information. We propagate definitions through the flow graph and increment their offsets when they cross scheduling edges. <p> These additional Time-Reads are unnecessary and can be eliminated by more precise interprocedural analysis in ALG3. 6 Discussion 6.1 Previous work There have been several studies on compiler algorithms for stale reference detection <ref> [8, 15] </ref>. Among them, only Cheong and Veidenbaum included a compiler implementation study using Parafrase 1 [8] . They pioneered a combination of scalar data-flow analysis and graph algorithms to find potentially stale references. <p> These additional Time-Reads are unnecessary and can be eliminated by more precise interprocedural analysis in ALG3. 6 Discussion 6.1 Previous work There have been several studies on compiler algorithms for stale reference detection [8, 15]. Among them, only Cheong and Veidenbaum included a compiler implementation study using Parafrase 1 <ref> [8] </ref> . They pioneered a combination of scalar data-flow analysis and graph algorithms to find potentially stale references. In [15], we proposed a simpler algorithm that eliminates the graph construction phase of [8], but it may overestimate potentially stale references by summarizing information from multiple control flow paths. <p> Among them, only Cheong and Veidenbaum included a compiler implementation study using Parafrase 1 <ref> [8] </ref> . They pioneered a combination of scalar data-flow analysis and graph algorithms to find potentially stale references. In [15], we proposed a simpler algorithm that eliminates the graph construction phase of [8], but it may overestimate potentially stale references by summarizing information from multiple control flow paths. Both algorithms treat each array as a single variable. There have been many studies on array data-flow algorithms. Granston proposed algorithms to detect redundant array references [19]. <p> The bottom-up side effect analysis replaces each call site with summary side effect information from its descendants, while the top-down context analysis propagates the context of predecessors to each procedure. This eliminates cache invalidations used by previous algorithms <ref> [8] </ref>, and allows the locality of programs to be preserved across procedure boundaries. We have implemented these algorithms in the Polaris parallelizing compiler [27], and measured the performance driven by the new compiler algorithms by running execution-driven simulations of five Perfect benchmarks.
Reference: [9] <author> H. Cheong and A. Veidenbaum. </author> <title> A Cache Coherence Scheme with Fast Selective Invalidation. </title> <booktitle> Proceedings of the 15th Annual International Symposium on Computer Architecture, </booktitle> <month> June </month> <year> 1988. </year>
Reference-contexts: Although these hardware schemes can precisely identify stale data by maintaining sharing information at runtime, they substantially increase the hardware cost for the directory storage and require complex directory and cache controllers. As an alternative, compiler-directed techniques <ref> [7, 9, 10, 15, 11, 17, 23, 24, 31] </ref> can be used to maintain coherence. In this approach, cache coherence is maintained locally without directory hardware, thus avoiding the complexity and overhead associated with hardware directories. <p> Execution-driven simulations are used to verify the compiler marking and to demonstrate the performance of automatic stale reference detection. The techniques developed here are general enough to be applicable to other compiler-directed coherence schemes <ref> [7, 9, 15] </ref>. 2 Background 2.1 Stale reference condition Memory event ordering Let's first define the ordering of events which leads to a stale reference. <p> In scalar analysis, even a write to a single element of an array is interpreted as a write to the entire array. This conservative scalar analysis often creates unnecessary cache misses, through either invalidations or redundant accesses to 5 the main memory <ref> [7, 9, 15] </ref>. These unnecessary memory accesses can be avoided by using a more precise analysis. In the following, we will demonstrate how automatic stale reference detection can be used to maintain coherence by developing both intra- and interprocedural array data-flow algorithms. <p> Using another pass of def-def or use-def chain analysis, the N-bit vector can be computed by using the offset field similar to the two-phase invalidation scheme. It is also straightforward to apply our algorithm for the fast selective invalidation scheme <ref> [9] </ref>. All the potentially stale references marked are issued as memory-reads, while cache invalidate operations should be inserted at every epoch boundary. Overall, the stale reference detection algorithm can be used for any hardware or software coherence techniques.
Reference: [10] <author> H. Cheong and A. Veidenbaum. </author> <title> A Version Control Approach To Cache Coherence. </title> <booktitle> Proceedings of the 1989 ACM/SIGARCH International Conference on Supercomputing, </booktitle> <month> June </month> <year> 1989. </year>
Reference-contexts: Although these hardware schemes can precisely identify stale data by maintaining sharing information at runtime, they substantially increase the hardware cost for the directory storage and require complex directory and cache controllers. As an alternative, compiler-directed techniques <ref> [7, 9, 10, 15, 11, 17, 23, 24, 31] </ref> can be used to maintain coherence. In this approach, cache coherence is maintained locally without directory hardware, thus avoiding the complexity and overhead associated with hardware directories.
Reference: [11] <author> T. Chiueh. </author> <title> A Generational Approach to Software-Controlled Multiprocessor Cache Coherence. </title> <booktitle> Proceedings of the 1993 International Conference on Parallel Processing, </booktitle> <month> August </month> <year> 1993. </year>
Reference-contexts: Although these hardware schemes can precisely identify stale data by maintaining sharing information at runtime, they substantially increase the hardware cost for the directory storage and require complex directory and cache controllers. As an alternative, compiler-directed techniques <ref> [7, 9, 10, 15, 11, 17, 23, 24, 31] </ref> can be used to maintain coherence. In this approach, cache coherence is maintained locally without directory hardware, thus avoiding the complexity and overhead associated with hardware directories.
Reference: [12] <author> Lynn Choi and Pen-Chung Yew. </author> <title> Eliminating Stale Data References through Array Data-Flow Analysis. </title> <note> To appear in IEEE International Parallel Processing Symposium, </note> <month> April. </month> <year> 1996. </year>
Reference-contexts: For a target reference with no reaching definition inside a procedure, we issue a Time-Read with the minimum offset, implying that the referenced data item can be potentially modified before entering the procedure. This is an improvement over previous algorithms <ref> [8, 12] </ref> that use cache invalidation at the beginning of a procedure since only global and formal variables are affected by the unknown context information. We propagate definitions through the flow graph and increment their offsets when they cross scheduling edges. <p> Invalidation-based intraprocedural algorithm (ALG1) This algorithm performs stale reference detection on a per-procedure basis <ref> [12] </ref>. To avoid the complications caused by unknown side effects, cache invalidation operations are inserted after each call site and at the beginning of a procedure. 2. <p> This suggests that it is important to exploit data locality across procedural boundaries. By avoiding cache invalidations, a simple modified intraprocedural algorithm eliminates up to 26.0% of the cache misses for a compiler-directed scheme, compared to an existing invalidation-based algorithm <ref> [12] </ref>. With the full interprocedural analysis, up to 10.8% of additional cache misses can be removed. Acknowledgments The research described in this paper was supported in part by the NSF Grant No. MIP 89-20891 and MIP 93-07910.
Reference: [13] <author> Lynn Choi and Pen-Chung Yew. </author> <title> Interprocedural Array Data-Flow Analysis for Cache Coherence. Proceedings of the Eighth International Workshop on Languages and Compilers for Parallel Computing '95, </title> <note> also avaiable as CSRD Technical Report No. 1427, </note> <month> Aug. </month> <year> 1995. </year>
Reference: [14] <author> Lynn Choi and Pen-Chung Yew. </author> <title> Hardware and Compiler-Directed Cache Coherence in Large-Scale Multiprocessors: Design Considerations and Performance Study. </title> <journal> submitted to IEEE Transactions on Parallel and Distributed Systems, </journal> <month> Feb. </month> <year> 1996. </year>
Reference-contexts: This operation bypasses the cache to avoid accessing the potentially stale cached data, and replaces the cached data with the up-to-date copy by directly accessing the main memory. 2 For a detailed description of these compiler-directed coherence schemes, please refer to the companion paper <ref> [14] </ref>. Two-phase invalidation scheme (TPI) 2 This scheme improves the SC scheme by keeping track of runtime cache states locally. <p> All the simulations assume a 16-processor, distributed shared-memory architecture with each processor containing an on-chip 64-KB direct-mapped cache with 4-word cache lines. The detailed description of our experimentation methodology and simulations are described in the companion paper <ref> [14] </ref>. 23 Compiler algorithms We use three different compiler algorithms to generate memory oper-ations for the software cache-bypass scheme (SC) and the two-phase invalidation scheme (TPI). 1. Invalidation-based intraprocedural algorithm (ALG1) This algorithm performs stale reference detection on a per-procedure basis [12].
Reference: [15] <author> Lynn Choi and Pen-Chung Yew. </author> <title> A Compiler-Directed Cache Coherence Scheme with Improved Intertask Locality. </title> <booktitle> Proceedings of the ACM/IEEE Supercomputing'94, </booktitle> <pages> pages 773-782, </pages> <month> Nov. </month> <year> 1994. </year>
Reference-contexts: Although these hardware schemes can precisely identify stale data by maintaining sharing information at runtime, they substantially increase the hardware cost for the directory storage and require complex directory and cache controllers. As an alternative, compiler-directed techniques <ref> [7, 9, 10, 15, 11, 17, 23, 24, 31] </ref> can be used to maintain coherence. In this approach, cache coherence is maintained locally without directory hardware, thus avoiding the complexity and overhead associated with hardware directories. <p> Execution-driven simulations are used to verify the compiler marking and to demonstrate the performance of automatic stale reference detection. The techniques developed here are general enough to be applicable to other compiler-directed coherence schemes <ref> [7, 9, 15] </ref>. 2 Background 2.1 Stale reference condition Memory event ordering Let's first define the ordering of events which leads to a stale reference. <p> And, the cache hit is determined by comparing the value with the timetag of the addressed cache copy. Figure 2 shows a sample program and the memory operations generated by a compiler for both SC and TPI schemes. 2.3 Array data-flow analysis Previous compiler algorithms <ref> [8, 15] </ref> treat an entire array as a single variable, leading to a conservative estimation of potential stale references. <p> In scalar analysis, even a write to a single element of an array is interpreted as a write to the entire array. This conservative scalar analysis often creates unnecessary cache misses, through either invalidations or redundant accesses to 5 the main memory <ref> [7, 9, 15] </ref>. These unnecessary memory accesses can be avoided by using a more precise analysis. In the following, we will demonstrate how automatic stale reference detection can be used to maintain coherence by developing both intra- and interprocedural array data-flow algorithms. <p> These additional Time-Reads are unnecessary and can be eliminated by more precise interprocedural analysis in ALG3. 6 Discussion 6.1 Previous work There have been several studies on compiler algorithms for stale reference detection <ref> [8, 15] </ref>. Among them, only Cheong and Veidenbaum included a compiler implementation study using Parafrase 1 [8] . They pioneered a combination of scalar data-flow analysis and graph algorithms to find potentially stale references. <p> Among them, only Cheong and Veidenbaum included a compiler implementation study using Parafrase 1 [8] . They pioneered a combination of scalar data-flow analysis and graph algorithms to find potentially stale references. In <ref> [15] </ref>, we proposed a simpler algorithm that eliminates the graph construction phase of [8], but it may overestimate potentially stale references by summarizing information from multiple control flow paths. Both algorithms treat each array as a single variable. There have been many studies on array data-flow algorithms.
Reference: [16] <author> Ron Cytron, Jeanne Ferrante, and Barry K. Rosen. </author> <title> Efficiently Computing Static Single Assignment Form and the Control Dependence Graph. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 13(4) </volume> <pages> 451-490, </pages> <month> Oct. </month> <year> 1991. </year>
Reference-contexts: Static single assignment (SSA) <ref> [16] </ref> is a representation of a program in which each use of a variable is reached by exactly a single definition of the variable. It allows us to track the value of a variable by its name. <p> A backward demand-driven symbolic analysis is used next to compute values and conditions across the confluence points of the control flow graph [30]. In addition to the above 3 functions, another function called ff (array, subscript, value) <ref> [16] </ref> is used to replace the array assignment statement. The semantics of the ff function is that a part of the array will take the value for the specified subscript while the rest of the array will remain as before. This representation maintains the single assignment property for the arrays.
Reference: [17] <author> E. Darnell and K. Kennedy. </author> <title> Cache Coherence Using Local Knowledge. </title> <booktitle> Proceedings of the Supercomputing '93, </booktitle> <pages> pages 720-729, </pages> <month> November </month> <year> 1993. </year>
Reference-contexts: Although these hardware schemes can precisely identify stale data by maintaining sharing information at runtime, they substantially increase the hardware cost for the directory storage and require complex directory and cache controllers. As an alternative, compiler-directed techniques <ref> [7, 9, 10, 15, 11, 17, 23, 24, 31] </ref> can be used to maintain coherence. In this approach, cache coherence is maintained locally without directory hardware, thus avoiding the complexity and overhead associated with hardware directories. <p> They usually require compile time analysis to detect possible stale data accesses and to invalidate stale cache entries. Although the performance of such schemes have been demonstrated through simulations, most of those studies assume either perfect compile-time analysis or analytical models without real compiler implementations <ref> [1, 6, 17, 23, 25, 26] </ref>. It is still unknown how effectively the compiler can detect potential stale references and what kind of performance can be obtained by using a real compiler.
Reference: [18] <author> Paul Feautrier. </author> <title> Dataflow Analysis of Array and Scalar References. </title> <journal> International Journal of Parallel Programming, </journal> <volume> 20(1), </volume> <month> Feb. </month> <year> 1991. </year>
Reference-contexts: Both algorithms treat each array as a single variable. There have been many studies on array data-flow algorithms. Granston proposed algorithms to detect redundant array references [19]. Feautrier <ref> [18] </ref> gave an algorithm to calculate them exactly. Pugh [29] developed some exact techniques that are substantially faster than Feautrier's.
Reference: [19] <author> Elana D. Granston and Alexander V. Veidenbaum. </author> <title> Detecting Redundant Accesses to Array Data. </title> <booktitle> Proceedings of the Supercomputing '91, </booktitle> <month> Nov. </month> <year> 1991. </year>
Reference-contexts: Both algorithms treat each array as a single variable. There have been many studies on array data-flow algorithms. Granston proposed algorithms to detect redundant array references <ref> [19] </ref>. Feautrier [18] gave an algorithm to calculate them exactly. Pugh [29] developed some exact techniques that are substantially faster than Feautrier's.
Reference: [20] <author> Cray Research Inc. </author> <title> Cray T3D System Architecture Overview. </title> <month> Mar. </month> <year> 1993. </year>
Reference: [21] <author> J. Kuskin, D. Ofelt, M. Heinrich, and J. Heinlein et al. </author> <title> The Stanford FLASH Multiprocessor. </title> <booktitle> Proceedings of The 21st Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 302-313, </pages> <month> April 18-21, </month> <year> 1994. </year> <month> 31 </month>
Reference-contexts: Having multiple cached copies of a shared memory location, however, can lead to erroneous program behavior unless they are maintained coherent. Existing solutions for large-scale multiprocessors include hardware directory-based coherence protocols, which have been studied in many research machines <ref> [2, 21, 22] </ref>. Although these hardware schemes can precisely identify stale data by maintaining sharing information at runtime, they substantially increase the hardware cost for the directory storage and require complex directory and cache controllers.
Reference: [22] <author> D. Lenoski, J. Laudon, K. Gharachorloo, A. Gupta, and J. Hennessy. </author> <title> The Directory-Based Cache Coherence Protocol for the DASH Computer. </title> <booktitle> Proceedings of the 17th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 148-159, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: Having multiple cached copies of a shared memory location, however, can lead to erroneous program behavior unless they are maintained coherent. Existing solutions for large-scale multiprocessors include hardware directory-based coherence protocols, which have been studied in many research machines <ref> [2, 21, 22] </ref>. Although these hardware schemes can precisely identify stale data by maintaining sharing information at runtime, they substantially increase the hardware cost for the directory storage and require complex directory and cache controllers.
Reference: [23] <author> A. Louri and H. Sung. </author> <title> A Compiler Directed Cache Coherence Scheme with Fast and Parallel Explicit Invalidation. </title> <booktitle> Proceedings of the 1992 International Conference on Parallel Processing, I, </booktitle> <address> Architecture:2-9, </address> <month> August </month> <year> 1992. </year>
Reference-contexts: Although these hardware schemes can precisely identify stale data by maintaining sharing information at runtime, they substantially increase the hardware cost for the directory storage and require complex directory and cache controllers. As an alternative, compiler-directed techniques <ref> [7, 9, 10, 15, 11, 17, 23, 24, 31] </ref> can be used to maintain coherence. In this approach, cache coherence is maintained locally without directory hardware, thus avoiding the complexity and overhead associated with hardware directories. <p> They usually require compile time analysis to detect possible stale data accesses and to invalidate stale cache entries. Although the performance of such schemes have been demonstrated through simulations, most of those studies assume either perfect compile-time analysis or analytical models without real compiler implementations <ref> [1, 6, 17, 23, 25, 26] </ref>. It is still unknown how effectively the compiler can detect potential stale references and what kind of performance can be obtained by using a real compiler.
Reference: [24] <author> S. L. Min and J.-L. Baer. </author> <title> A Timestamp-based Cache Coherence Scheme. </title> <booktitle> Proceedings of the 1989 International Conference on Parallel Processing, </booktitle> <address> I:23-32, </address> <year> 1989. </year>
Reference-contexts: Although these hardware schemes can precisely identify stale data by maintaining sharing information at runtime, they substantially increase the hardware cost for the directory storage and require complex directory and cache controllers. As an alternative, compiler-directed techniques <ref> [7, 9, 10, 15, 11, 17, 23, 24, 31] </ref> can be used to maintain coherence. In this approach, cache coherence is maintained locally without directory hardware, thus avoiding the complexity and overhead associated with hardware directories.
Reference: [25] <author> S. L. Min and J.-L. Baer. </author> <title> Design and Analysis of a Scalable Cache Coherence Scheme Based on Clocks and Timestamps. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 3(1) </volume> <pages> 25-44, </pages> <month> January </month> <year> 1992. </year>
Reference-contexts: They usually require compile time analysis to detect possible stale data accesses and to invalidate stale cache entries. Although the performance of such schemes have been demonstrated through simulations, most of those studies assume either perfect compile-time analysis or analytical models without real compiler implementations <ref> [1, 6, 17, 23, 25, 26] </ref>. It is still unknown how effectively the compiler can detect potential stale references and what kind of performance can be obtained by using a real compiler.
Reference: [26] <author> F. Mounes-Toussi and D. Lilja. </author> <title> The Potential of Compile-Time Analysis to Adapt the Cache Coherence Enforcement Strategy to the Data Sharing Characteristics. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <year> 1995. </year>
Reference-contexts: They usually require compile time analysis to detect possible stale data accesses and to invalidate stale cache entries. Although the performance of such schemes have been demonstrated through simulations, most of those studies assume either perfect compile-time analysis or analytical models without real compiler implementations <ref> [1, 6, 17, 23, 25, 26] </ref>. It is still unknown how effectively the compiler can detect potential stale references and what kind of performance can be obtained by using a real compiler.
Reference: [27] <author> D. A. Padua, R. Eigenmann, J. Hoeflinger, P. Peterson, P. Tu, S. Weatherford, and K. Faign. </author> <title> Polaris: A New-Generation Parallelizing Compiler for MPPs. In CSRD Rept. No. </title> <type> 1306. </type> <institution> Univ. of Illinois at Urbana-Champaign., </institution> <month> June, </month> <year> 1993. </year>
Reference-contexts: It is still unknown how effectively the compiler can detect potential stale references and what kind of performance can be obtained by using a real compiler. In this paper, we develop and implement both intraprocedural and interprocedural compiler algorithms on the Polaris parallelizing compiler <ref> [27] </ref> to test the feasibility and performance of compiler-directed coherence schemes. We use a combination of interval and data-flow analysis techniques to determine memory reference patterns which can lead to stale data accesses. To obtain more precise array access information, we compute the array region referenced by each array reference. <p> This eliminates cache invalidations used by previous algorithms [8], and allows the locality of programs to be preserved across procedure boundaries. We have implemented these algorithms in the Polaris parallelizing compiler <ref> [27] </ref>, and measured the performance driven by the new compiler algorithms by running execution-driven simulations of five Perfect benchmarks. Our results show that, for most benchmarks, the compiler algorithms can improve cache utilization significantly by caching remote shared data.
Reference: [28] <author> D. K. Poulsen and P.-C. Yew. </author> <title> Execution-Driven Tools for Parallel Simulation of Parallel Architectures and Applications. </title> <booktitle> Proceedings of the Supercomputing 93, </booktitle> <pages> pages 860-869, </pages> <month> Nov. </month> <year> 1993. </year>
Reference-contexts: They are first parallelized by the Polaris compiler. In the parallelized codes, the parallelism is expressed in terms of DOALL loops. Then, we process the parallelized source codes using both scalar and array flow analysis versions of the algorithms given in sections 3 and 4.2. Execution-driven simulations <ref> [28] </ref> are used to verify the compiler algorithm and to evaluate the performance of compiler-directed coherence schemes. All the simulations assume a 16-processor, distributed shared-memory architecture with each processor containing an on-chip 64-KB direct-mapped cache with 4-word cache lines.
Reference: [29] <author> William Pugh and David Wonnacott. </author> <title> An Evaluation of Exact Methods for Analysis of Value-based Array Data Dependences. </title> <booktitle> Sixth Annual Workshop on Programming Languages and Compilers for Parallel Computing, </booktitle> <month> August </month> <year> 1993. </year>
Reference-contexts: Both algorithms treat each array as a single variable. There have been many studies on array data-flow algorithms. Granston proposed algorithms to detect redundant array references [19]. Feautrier [18] gave an algorithm to calculate them exactly. Pugh <ref> [29] </ref> developed some exact techniques that are substantially faster than Feautrier's.
Reference: [30] <author> Peng Tu. </author> <title> Automatic Array Privatization and Demand-Driven Symbolic Analysis. </title> <type> Technical report, </type> <institution> Univ. of Illinois at Urbana-Champaign, Dept. of Computer Science, </institution> <year> 1995. </year> <type> Ph.D. Thesis. </type>
Reference-contexts: The data values to be analyzed include scalar variables, subscripted variables, and subarrays <ref> [30] </ref>. A subscripted variable consists of an array identifier and a subscript expression, representing a single array element referenced. A subarray consists of a subscripted variable and one or more ranges for some of the indices in its subscript expression. <p> In the global symbolic forward substitution, information is propagated until it terminates at the confluence points in the control flow graph. A backward demand-driven symbolic analysis is used next to compute values and conditions across the confluence points of the control flow graph <ref> [30] </ref>. In addition to the above 3 functions, another function called ff (array, subscript, value) [16] is used to replace the array assignment statement.
Reference: [31] <author> A. V. Veidenbaum. </author> <title> A Compiler-Assisted Cache Coherence Solution for Multiprocessors. </title> <booktitle> Proceedings of the 1986 International Conference on Parallel Processing, </booktitle> <pages> pages 1029-1035, </pages> <month> August </month> <year> 1986. </year>
Reference-contexts: Although these hardware schemes can precisely identify stale data by maintaining sharing information at runtime, they substantially increase the hardware cost for the directory storage and require complex directory and cache controllers. As an alternative, compiler-directed techniques <ref> [7, 9, 10, 15, 11, 17, 23, 24, 31] </ref> can be used to maintain coherence. In this approach, cache coherence is maintained locally without directory hardware, thus avoiding the complexity and overhead associated with hardware directories. <p> The techniques developed here are general enough to be applicable to other compiler-directed coherence schemes [7, 9, 15]. 2 Background 2.1 Stale reference condition Memory event ordering Let's first define the ordering of events which leads to a stale reference. The following sequence of events <ref> [31] </ref> creates a stale reference at runtime: (1) Processor P i reads or writes to a memory location x at time T a ; (2) Another processor, P j (j 6= i) later writes to x at time T b (&gt; T a ); (3) Processor P i reads the copy <p> Assuming only DOALL types of parallelism (i.e. no dependences among concurrent tasks), memory events (1) to (3) should occur in different epochs. Otherwise, there are dependences among concurrent tasks. To detect stale data reference from a source program, the previous compiler algorithms <ref> [8, 7, 31] </ref> look for the following memory reference patterns that consist of (a) a read or a write, (b) one or more epoch boundaries, (c) a write, (d) one or more epoch boundaries, and (e) a read.
Reference: [32] <author> Michael E. Wolf. </author> <title> Improving Locality and Parallelism in Nested Loops. </title> <type> Technical report, </type> <institution> Stanford University, Dept. of Computer Science, </institution> <month> August </month> <year> 1992. </year> <type> Ph.D. Thesis. </type>
Reference-contexts: The algorithm considers implicit RAW (read-after-write) and WAW (write-after-write) dependences caused by multi-word cache lines (see section 2.1). To further refine reference marking, two locality preserving analysis techniques are used to exploit both temporal and spatial reuses <ref> [32] </ref> in a program. To refine reference marking for both group temporal and spatial reuses, we mark the initial occurrence of upwardly-exposed uses in a program region for potentially stale data references. <p> Since each potentially stale reference implies a remote memory access instead of a cache hit, we should minimize the number of potentially stale references marked at compile time by utilizing both the temporal and spatial locality in a program as much as possible. Wolf <ref> [32] </ref> discussed 4 different types of reuses in a loop as shown in Table 2. Note that the self reuses are inherently loop-specific while group reuses are not.
References-found: 32

