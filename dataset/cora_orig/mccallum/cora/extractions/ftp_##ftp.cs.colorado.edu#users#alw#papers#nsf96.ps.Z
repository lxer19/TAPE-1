URL: ftp://ftp.cs.colorado.edu/users/alw/papers/nsf96.ps.Z
Refering-URL: http://www.cs.colorado.edu/users/alw/AvailablePubs.html
Root-URL: http://www.cs.colorado.edu
Email: fjcook,alwg@cs.colorado.edu  
Title: Discovery and Validation of Processes  
Author: Jonathan E. Cook and Alexander L. Wolf 
Address: Boulder, CO 80309 USA  
Affiliation: Department of Computer Science University of Colorado  
Date: May, 1996  
Note: From the Proceedings of the NSF Workshop on Workflow and Process Automation, Athens, Georgia,  
Abstract: We are developing automated data analysis methods to help organizations understand, improve, and control their processes. The methods use process event data to reveal significant behavioral characteristics of processes. The two main areas we are addressing are process discovery and process validation. Process discovery uses event data to create formal models of processes that can be used to understand an organization's processes. Process validation uncovers discrepancies between an organization's intended processes and the processes actually followed. We have implemented prototype discovery and validation tools within a common event-data analysis framework called Balboa. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M.G. Bradac, D.E. Perry, and L.G. Votta. </author> <title> Prototyping a Process Monitoring Experiment. </title> <journal> IEEE Transactions on Software Engineering, </journal> 20(10) 774-784, October 1994. 
Reference-contexts: But these foundations for decision making can be unreliable if they are not drawn from hard data describing the processes. Fortunately, a substantial body of work is growing in the area of process data collection and analysis (e.g., <ref> [1, 4, 5] </ref>). In particular, both manual and automated methods are being developed to collect data describing the significant events occurring during the execution of processes by an organization. In concert, methods are being developed to analyze those data to uncover the key characteristics and anomalous behaviors of processes.
Reference: [2] <author> J.E. Cook and A.L. Wolf. </author> <title> Toward Metrics for Process Validation. </title> <booktitle> In Proceedings of the Third International Conference on the Software Process, </booktitle> <pages> pages 33-44. </pages> <publisher> IEEE Computer Society, </publisher> <month> October </month> <year> 1994. </year>
Reference-contexts: The goal is to create models with which one can reliably reason about the suitability of changes. Second, we are developing methods for automated process validation, which is the use of event data to uncover discrepancies between an organization's intended processes and the processes actually followed <ref> [2] </ref>. Deviations from intended processes occur for many reasons, both good and bad. But in all cases, deviations indicate places where something important may be happening. The process discovery and validation methods have been implemented as tools within a more general event-data analysis framework called Balboa.
Reference: [3] <author> J.E. Cook and A.L. Wolf. </author> <title> Automating Process Discovery through Event-Data Analysis. </title> <booktitle> In Proceedings of the 17th International Conference on Software Engineering, </booktitle> <pages> pages 73-82. </pages> <institution> Association for Computer Machinery, </institution> <month> April </month> <year> 1995. </year>
Reference-contexts: Our work contributes to this effort in two major ways. First, we are developing methods for automated process discovery, which is the use of event data to generate formal models of processes <ref> [3] </ref>. The goal is to create models with which one can reliably reason about the suitability of changes. Second, we are developing methods for automated process validation, which is the use of event data to uncover discrepancies between an organization's intended processes and the processes actually followed [2].
Reference: [4] <author> S.L. Pfleeger and H.D. Rombach. </author> <title> Special Section on Measurement-based Process Improvement. </title> <journal> IEEE Software, </journal> <volume> 11(4) </volume> <pages> 9-85, </pages> <month> July </month> <year> 1994. </year>
Reference-contexts: But these foundations for decision making can be unreliable if they are not drawn from hard data describing the processes. Fortunately, a substantial body of work is growing in the area of process data collection and analysis (e.g., <ref> [1, 4, 5] </ref>). In particular, both manual and automated methods are being developed to collect data describing the significant events occurring during the execution of processes by an organization. In concert, methods are being developed to analyze those data to uncover the key characteristics and anomalous behaviors of processes.
Reference: [5] <author> A.L. Wolf and D.S. Rosenblum. </author> <title> A Study in Software Process Data Capture and Analysis. </title> <booktitle> In Proceedings of the Second International Conference on the Software Process, </booktitle> <pages> pages 115-124. </pages> <publisher> IEEE Computer Society, </publisher> <month> February </month> <year> 1993. </year>
Reference-contexts: But these foundations for decision making can be unreliable if they are not drawn from hard data describing the processes. Fortunately, a substantial body of work is growing in the area of process data collection and analysis (e.g., <ref> [1, 4, 5] </ref>). In particular, both manual and automated methods are being developed to collect data describing the significant events occurring during the execution of processes by an organization. In concert, methods are being developed to analyze those data to uncover the key characteristics and anomalous behaviors of processes.
Reference: [6] <editor> A.L. Wolf and D.S. Rosenblum. </editor> <booktitle> Process-centered Environments (Only) Support Environment-centered Processes. In Proceedings of the 8th International Software Process Workshop, </booktitle> <pages> pages 148-149, </pages> <month> March </month> <year> 1993. </year>
Reference-contexts: Current methods either use human-intensive methods, such as direct observations, or use automated methods, such as on-line monitoring. The former are high cost and fallible, while the latter bias the data toward on-line activities <ref> [6] </ref>. Both are subject to questions of privacy. Likewise, further work needs to be done in the area of process data analysis. We are currently pursuing this in two directions.
References-found: 6

