URL: http://www.ai.mit.edu/projects/transit/dpga/dpga-fpd96.ps.Z
Refering-URL: http://www.ai.mit.edu/projects/transit/dpga_prototype_documents.html
Root-URL: 
Email: andre@mit.edu  
Phone: (617) 253-5868  FAX: (617) 253-5060  
Title: Dynamically Programmable Gate Arrays: A Step Toward Increased Computational Density  
Author: Andr e DeHon 
Address: NE43-791, 545 Technology Sq., Cambridge, MA 02139  
Affiliation: MIT Artificial Intelligence Laboratory  
Note: FPD'96 Fourth Canadian Workshop of Field-Programmable Devices May 13-14, 1996, Toronto, Canada  
Abstract: Field-Programmable Gate Arrays are interesting, general-purpose computational devices because (1) they have high computational density and (2) they have fine-grained control of their computationalresources since each gate is independently controlled. The earlier provides them with a potential 10fi advantage in raw peak performance density versus modern microprocessors. The later can afford a 32fi advantage on random bit-level computations. Nonetheless, typical FPGA usage seldom extracts this full density advantage. DPGAs are less computation-ally dense than FPGAs, but allow most applications to achieve greater, yielded computational density. The key to unraveling this potential paradox lies in distinguishing instruction density from active computing density. Since the storage space for a single instruction is inherently smaller than the computational element it controls, packing several instructions per computational unit increases the aggregate instruction capacity of the device without a significant reduction in computational density. The number of different instructions executed per computational task often limits the effective computational density. As a result, DPGAs can meet the throughput requirements of many computing tasks with 3-4fi less area than conventional FPGAs. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Paul Chow, Soon Ong Seo, Dennis Au, Terrence Choy, Bahram Fallah, David Lewis, Cherry Li, and Jonathan Rose. </author> <title> A 1.2m CMOS FPGA using Cascaded Logic Blocks and Segmented Routing. </title> <editor> In Will Moore and Wayne Luk, editors, </editor> <booktitle> FPGAs, </booktitle> <pages> pages 91-102. </pages> <publisher> Abingdon EE&CS Books, </publisher> <address> 15 Harcourt Way, Abingdon, OX14 1NV, UK, </address> <year> 1991. </year>
Reference-contexts: We know, for example, that a four input Lookup Table (4-LUT) occupies roughly 640K 2 (e.g. 0.16mm 2 in a 1 CMOS processor ( = 0:5)) <ref> [1] </ref> [9]. Thus, we get a 4-LUT density of 1.6 4-LUTs per one million 2 of area. At the same time, we notice that the descriptive density of 4-LUT designs can be much greater than the 4-LUT density just observed. <p> Consequently, we effectively evaluate a design with N d = N LUT design = 21 4-LUTs with N 0 d = N a = 28 physical 4-LUTs. Typical LUT delay, including a moderate amount of local interconnect traversal, is 7 ns [9] <ref> [1] </ref>.
Reference: [2] <author> Andr e DeHon. </author> <title> DPGA Utilization and Application. </title> <booktitle> In Proceedings of the 1996 International Symposium on Field Programmable Gate Arrays. </booktitle> <address> ACM/SIGDA, </address> <month> February </month> <year> 1996. </year> <note> Extended version available as Transit Note #129, available via anonymous FTP transit.ai.mit.edu:transit-notes/ tn129.ps.Z. Anonymous FTP transit.ai. mit.edu:papers/dpga-use-fpga96.ps.Z. </note>
Reference-contexts: In this section, we have examined one task in depth. See <ref> [2] </ref> for a broader look at multicontext applications. 4 Device Sizing One thing which is clear from Table 2 is that there is an optimal ratio between N d and N a which varies with the desired throughput requirements.
Reference: [3] <author> Andr e DeHon. </author> <title> Entropy, Counting, and Programmable Interconnect. </title> <booktitle> In Proceedings of the 1996 International Symposium on Field Programmable Gate Arrays. </booktitle> <address> ACM/SIGDA, </address> <month> February </month> <year> 1996. </year> <note> Extended version available as Transit Note #128, available via anonymous transit.ai.mit. edu:transit-notes/tn128.ps.Z. Anonymous FTP transit.ai.mit.edu:papers/ entropy-fpga96.ps.Z. </note>
Reference-contexts: In fact, there is good reason to believe that we can use much less than 200 bits to describe each 4-LUT computation <ref> [3] </ref>, making even greater densities achievable in practice. Returning to our original question, we see that there are two components which combine to define the requisite area for our general-purpose device: 1. N d the total number of 4-LUTs in the design the descriptive complexity 2.
Reference: [4] <author> Robert Francis. </author> <title> Technology Mapping for Lookup-Table Based Field-Programmable Gate Arrays. </title> <type> PhD thesis, </type> <institution> University of Toronto, </institution> <year> 1992. </year>
Reference-contexts: We will take an ASCII Hex!binary converter as our example. we care about the latency of this operation, a mapping which minimizes the critical path length using SIS [8] and Chortle <ref> [4] </ref> has a path length of 3 and requires 21 4-LUTs. circuit topology. 3.1 Traditional Pipelining for Throughput If we cared only about achieving the highest throughput, we would fully pipeline this implementation such that it took in a new character on each cycle and output its encoding three cycles later.
Reference: [5] <author> Paul Gronowski, Peter Bannon, Michael Bertone, Randel Blake-Campos, Gregory Bouchard, William Bowhill, David Carlson, Ruben Castelino, Dale Donchin, Richard Fromm, Mary Gowan, Anil Jain, Bruce Loughlin, Shekhar Mehta, Jeanne Meyer, Robert Mueller, Andy Olesin, Tung Pham, Ronald Preston, and Paul Robinfeld. </author> <title> A 433MHz 64b Quad-Issue RISC Microprocessor. </title> <booktitle> In 1996 IEEE International Solid-State Circuits Conference, Digst of Technical Papers, </booktitle> <pages> pages 222-223. </pages> <publisher> IEEE, </publisher> <month> February </month> <year> 1996. </year>
Reference-contexts: The MIPS-X [6] assembly code is shown in Figure 5; for the sake of comparison, we assume the 4 cycle path which occurs when converting an ASCII decimal digit. The DEC Alpha <ref> [5] </ref> implementation assumes that the conversion is performed by table lookup and the table is already loaded into the on-chip data cache; the conversion takes one add and one lookup, each of which take up half a cycle since the Alpha can issue two instruction per cycle.
Reference: [6] <author> Mark Horowitz, John Hennessy, Paul Chow, Glenn Gu-lak, John Acken, Anant Agarwal, Chorng-Yeung Chu, Scott McFarling, Steven Przybylski, Steven Richard-son, Arturo Salz, Richard Simoni, Don Stark, Peter Steenkiste, Steven Tjiang, and Malcom Wing. </author> <title> A 32b Microprocessor with On-Chip 2K byte Instruction Cache. </title> <booktitle> In 1987 IEEE InternationalSolid-State Circuits Conference, Digst of Technical Papers, </booktitle> <pages> pages 30-31. </pages> <publisher> IEEE, </publisher> <month> February </month> <year> 1987. </year>
Reference-contexts: Also included is the atoh: //c in r1 //2-9 instructions blt r1,#48,zero bgt r1,#57,try40 bne r0,r0,done try40: blt r1,#65,zero bgt r1,#70,zero sub r1,#55,r2 bne r0,r0,done zero: addi r0,r0,r2 done: effective area required for two different processor implementations of this task. The MIPS-X <ref> [6] </ref> assembly code is shown in Figure 5; for the sake of comparison, we assume the 4 cycle path which occurs when converting an ASCII decimal digit.
Reference: [7] <author> David Jones and David Lewis. </author> <title> A Time-Multiplexed FPGA Architecture for Logic Emulation. </title> <booktitle> In Proceedings of the IEEE 1995 Custom Integrated Circuits Conference, </booktitle> <pages> pages 495-498. </pages> <publisher> IEEE, </publisher> <month> May </month> <year> 1995. </year>
Reference-contexts: One way to achieve this is to associate a pool of memory with each active LUT. This pool serves the same role as a register file in a traditional processor. VEGA <ref> [7] </ref> uses this approach achieving: A compute N d A LUT descript Where: 120K 2 A LUT descript 170K 2 when: 256 N a A similar alternative is to move the flip-flop which normally lives at the output of a LUT to its inputs and to replicate this for each described
Reference: [8] <author> Ellen M. Sentovich, Kanwar Jit Singh, Luciano Lavagno, Cho Moon, Rajeev Murgai, Alexander Sal-danha, Hamid Savoj, Paul R. Stephan, Robert K. Bray-ton, and Alberto Sangiovanni-Vincentelli. </author> <title> SIS: A System for Sequential Circuit Synthesis. </title> <institution> UCB/ERL M92/41, University of California, Berkeley, Department of Electrical Engineering and Computer Science, University of California, Berkeley, </institution> <address> CA 94720, </address> <month> May </month> <year> 1992. </year>
Reference-contexts: We will take an ASCII Hex!binary converter as our example. we care about the latency of this operation, a mapping which minimizes the critical path length using SIS <ref> [8] </ref> and Chortle [4] has a path length of 3 and requires 21 4-LUTs. circuit topology. 3.1 Traditional Pipelining for Throughput If we cared only about achieving the highest throughput, we would fully pipeline this implementation such that it took in a new character on each cycle and output its encoding
Reference: [9] <author> Edward Tau, Ian Eslick, Derrick Chen, Jeremy Brown, and Andr e DeHon. </author> <title> A First Generation DPGA Implementation. </title> <booktitle> In Proceedings of the Third Canadian Workshop on Field-Programmable Devices, </booktitle> <pages> pages 138-143, </pages> <month> May </month> <year> 1995. </year> <note> Anonymous FTP transit.ai.mit. edu:papers/dpga-proto-fpd95.ps.Z. </note>
Reference-contexts: We know, for example, that a four input Lookup Table (4-LUT) occupies roughly 640K 2 (e.g. 0.16mm 2 in a 1 CMOS processor ( = 0:5)) [1] <ref> [9] </ref>. Thus, we get a 4-LUT density of 1.6 4-LUTs per one million 2 of area. At the same time, we notice that the descriptive density of 4-LUT designs can be much greater than the 4-LUT density just observed. <p> Dynamically Programmable Gate Arrays (DPGAs), do just that, packing several configuration memories for each ac tive LUT and switching element (Figure 1). From our own experience with the DPGA <ref> [9] </ref>: A LUT 560K 2 A LUT config mem 20K 2 The base LUT area is generally consistent with other FPGA implementations. <p> Consequently, we effectively evaluate a design with N d = N LUT design = 21 4-LUTs with N 0 d = N a = 28 physical 4-LUTs. Typical LUT delay, including a moderate amount of local interconnect traversal, is 7 ns <ref> [9] </ref> [1]. <p> The total latency then is 21 ns, as before. The throughput at the 7 ns clock rate is 48 MHz. If we do not pipeline the configuration read, as was the case for the DPGA prototype <ref> [9] </ref>, the configuration read adds another 2.5 ns to the LUT delay, making for a total latency of 28.5 ns and a throughput of 35 MHz.
References-found: 9

