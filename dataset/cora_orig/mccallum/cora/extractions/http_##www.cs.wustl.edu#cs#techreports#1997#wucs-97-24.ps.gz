URL: http://www.cs.wustl.edu/cs/techreports/1997/wucs-97-24.ps.gz
Refering-URL: http://www.cs.wustl.edu/~cytron/nsf9628218/1997.html
Root-URL: 
Title: Reducing Web Latencies Using Precomputed Hints  
Author: Girish P. Chandranmenon George Varghese wucs-- 
Note: This work was supported by National Science Foundation under grant NCR-9628218  
Address: Campus Box 1045  One Brookings Drive St. Louis, MO 63130-4899  
Affiliation: Department of Computer Science  Washington University  
Date: February 25, 1997  
Abstract: Current network technology is bandwidth-rich but latency-poor; thus round-trip delays will dominate access latency for web traffic. We describe four new techniques that reduce the round-trips needed for web accesses. The techniques are based on the paradigm of preprocessing a web page to collect information about links and inline data in the page. Stored Address Binding almost always eliminates the DNS lookup (which can cost seconds) at the start of a transaction. In Informed Server Proxying, a server tells its client that it has cached pages referenced in a page the client just retrieved; this allows the client to retrieve the pages from its current connection, instead of creating a new connection. In Selective Link Redirect, a server can direct its client to any server that has cached a page referenced in the current document; this allows cooperating servers to balance load. Finally, Auto Inline Download allows a server to send inline data such as images and applets, without additional client requests. We describe implementations and measurements of these techniques. 
Abstract-found: 1
Intro-found: 1
Reference: [AW96] <author> M. Arlit and C. Williamson. </author> <title> Web server workload characterization: The search for invariants. </title> <booktitle> In In proceedings of SIGMETRICS'96, </booktitle> <month> May </month> <year> 1996. </year>
Reference-contexts: These techniques can help but are not sufficient. Caching depends on locality patterns which may not hold as users explore new links; [WAS + 96] finds the locality of reference to be only 50% with high miss penalties for proxy cache misses. Also, <ref> [AW96] </ref> found that about a third of the files and bytes are accessed only once; this implies that caching at the server is tricky.
Reference: [BLC95] <author> T. Berners-Lee and D. Connolly. </author> <title> Hypertext markup language - 2.0. </title> <type> RFC 1866, </type> <month> November </month> <year> 1995. </year>
Reference: [BLFN96] <author> Tim Berners-Lee, Roy T. Fielding, and Henrik Frystyk Nielsen. </author> <title> Hypertext transfer protocol - http/1.0. Informational RFC 1945, </title> <month> May </month> <year> 1996. </year>
Reference: [Bri95] <author> T. Brisco. </author> <title> Dns support for load balancing. </title> <type> RFC 1794, </type> <month> April </month> <year> 1995. </year> <title> 6 Our compilation requirements are also quite modest, involving parsing of the HTML file, potentially doing DNS requests, and resolving all the inline data associated with the page. Reducing Web Latencies Using Precomputed Hints 18 </title>
Reference-contexts: Auto Image Download reduces the number of requests to 1 per document by automatically downloading all inline data in a single response. Both these schemes need to be carefully compared to other proposed optimizations for the same purposes: DNS Load Balancing, Cooperating Caching Servers and Pipelining. DNS Load Balancing <ref> [Bri95] </ref> has been proposed for use among a set of machines that together implement a server proxy for one site. The scheme uses DNS to provide multiple addresses for the same name; each time a host makes a request, DNS will return a random permutation of the addresses.
Reference: [CDN + 96] <author> Anawat Chankhunthod, Peter B. Danzig, Chuck Neerdaels, Michael F. Schwartz, and Kurt J. Worrell. </author> <title> A hierarchical internet object cache. </title> <booktitle> In USENIX 1996 Annual Technical Conference, </booktitle> <pages> pages 153-163, </pages> <month> January </month> <year> 1996. </year>
Reference-contexts: This helps the client avoid additional connections to the original server of the document. By contrast, in a normal server proxy (or a web server accelerator) <ref> [CDN + 96] </ref>, the proxy takes over the web server's identity (port 80 in the TCP world). From then on, all requests to the server must go through the proxy.
Reference: [FB96] <author> N. Freed and N. Borenstein. </author> <title> Multipurpose internet mail extensions. RFC 2045, </title> <institution> Network Working Group, </institution> <month> November </month> <year> 1996. </year>
Reference-contexts: The first three schemes compile information about the URLs of links in a web page; the fourth scheme adds information about inline data. These hints are prepended to the web page as MIME <ref> [FB96] </ref> headers and are expected to be generated by a compiler or preprocessor for the web page. A summary of our ideas, in the context of some earlier schemes, is given in Theorem 2.
Reference: [FGM + 97] <author> R. Fielding, J. Gettys, J. Mogul, H. Frystyk, and T Bernes-Lee. </author> <title> Hypertext transfer protocol - http/1.1. RFC 2068, </title> <month> January </month> <year> 1997. </year>
Reference: [GS97] <author> Linda Geppert and William Sweet. </author> <title> Introduction. </title> <journal> IEEE Spectrum, </journal> <volume> 34(1) </volume> <pages> 23-26, </pages> <month> January </month> <year> 1997. </year>
Reference: [HC94] <author> Mark Handley and Jon Crowcroft. </author> <title> The World Wide Web Beneath the Surf. </title> <publisher> UCL Press, </publisher> <year> 1994. </year>
Reference-contexts: Why does a Web access require more than one round-trip time? <ref> [HC94] </ref> describes the operation of the web in detail. A Web document is identified by a Uniform Resource Locator (URL), which contains a host name and the name of a file on that host.
Reference: [Hei96] <author> J. Heidemann. </author> <title> Performance interactions between p-http and tcp implementation. http://www.isi.edu/lsam/publications/phttp tcp interactions/, </title> <month> November </month> <year> 1996. </year>
Reference-contexts: A summary of our ideas, in the context of some earlier schemes, is given in Theorem 2. A more detailed comparison with earlier work is in Section 2. 1 In this table we have not included the additional waits due to interactions between HTTP and the underlying transport protocol <ref> [Hei96] </ref>. Reducing Web Latencies Using Precomputed Hints 3 Idea Added information benefit Stored Address Binding (SAB) IP address of the host name in the URL Avoid DNS lookup at clients Informed Server Proxy ing (ISP) A flag for each URL indicating whether the server has cached the referenced document.
Reference: [LA94] <author> A. Luotonen and K Altis. </author> <title> World wide web proxies. </title> <journal> Computer Networks and ISDN Systems, </journal> <volume> 27(2), </volume> <year> 1994. </year>
Reference: [MLB95] <author> R. Malpani, J. Lorch, and D. Berger. </author> <title> Making world wide web caching servers cooperate. </title> <booktitle> In In 4th International World Wide Web Conference, </booktitle> <pages> pages 107-117, </pages> <month> December </month> <year> 1995. </year>
Reference-contexts: Thus, DNS based load balancing does not react to the actual load at the server. On the other hand, our SLR scheme can dynamically redirect the request to one of the cooperative servers. SLR does not depend on DNS to balance load. Cooperating Caching Servers <ref> [MLB95] </ref> describes a protocol for load sharing among caching proxies. In this scheme, a client picks one caching server as its master proxy, and if the master does not have the document that the client requested, it multicasts a query to the proxy group. <p> Then, the client can make another request to that proxy and retrieve the document. Our load balancing scheme, Selective Link Redirect, is different from <ref> [MLB95] </ref>. SLR is used by a server to redirect further requests (not the current request) to other lightly loaded servers. Thus SLR does not require additional latency in accessing the currently requested document.
Reference: [Moc87] <author> P. Mockapetris. </author> <title> Domain names-concepts and facilities. </title> <type> RFC 1034, </type> <month> April </month> <year> 1987. </year>
Reference-contexts: A Web document is identified by a Uniform Resource Locator (URL), which contains a host name and the name of a file on that host. Given a URL, a browser, such as Netscape or Mosaic, queries a domain name server (DNS <ref> [Moc87] </ref>) for the address of the host, establishes a connection to the host using its address, and finally makes a request for the file identified by the URL.
Reference: [Mog95a] <author> J. C. </author> <title> Mogul. </title> <booktitle> The case for persistent connection http. In Proceedings of the ACM SIGCOMM '95 Symposium, </booktitle> <pages> pages 299-313, </pages> <month> September </month> <year> 1995. </year>
Reference-contexts: Prefetching documents is problematic because a user may traverse only a small set of the links associated with a page; without knowing the user's tastes, prefetching wastes network bandwidth and dilutes caches. Persistent-HTTP <ref> [Mog95a] </ref> eliminates extra connection set up for inline data requests but does not remove the other latencies described in Theorem 1. 1.1. Contributions In this paper, we propose four new ideas to reduce latencies due to round-trip times. <p> The last column lists specific disadvantages of each scheme. The normal HTTP protocol (first row) makes n separate connections for each document (web page plus n 1 inline images), n separate requests per document, and one DNS lookup per server. Persistent HTTP <ref> [Mog95a] </ref> (incorporated into HTTP 1.1) reduces the number of connections to one per server (multiple documents at the same server can be accessed over the same connection). Prefetching (third row) does not reduce the number of connections, requests or DNS lookups.
Reference: [Mog95b] <author> J. C. Mogul. </author> <title> Operating systems support for busy internet servers. </title> <note> WRL Technical Note TN-49, </note> <month> May </month> <year> 1995. </year>
Reference-contexts: The scheme uses DNS to provide multiple addresses for the same name; each time a host makes a request, DNS will return a random permutation of the addresses. The idea is to have clients connect to different machines at different times, resulting in balanced load. However, according to Mogul <ref> [Mog95b] </ref>, DNS based load balancing schemes do not work well. Once the client has done one lookup, it tends to use the same address repeatedly. Thus, DNS based load balancing does not react to the actual load at the server.
Reference: [NGSP97] <author> Henrik Frystyk Nielsen, Jim Gettys, Anselm Baird Smith, and Eric Prud'hommeaux. </author> <title> Initial http/1.1 performance tests. </title> <note> http://www.w3.org/pub/WWW/Protocols/HTTP/Performance/Pipeline.html, January 1997. </note>
Reference-contexts: But most of the writes in our experiment were not small; if we transferred 100 byte images, there might have been significant reduction in the number of packets when we use AID with tcp nodelay set to 0. Since Nagle's algorithm can introduce delays, <ref> [NGSP97] </ref> advocates disabling it. With AID, we may not have to disable Nagle's algorithm.
Reference: [WAS + 96] <author> S. Williams, M. Abrams, C. R. Standridge, Ghaleb Abdulla, and Edward A. Fox. </author> <title> Removal policies in network caches for world wide web documents. </title> <booktitle> In Proceedings of the ACM SIGCOMM '96 Symposium, </booktitle> <pages> pages 293-305, </pages> <month> October </month> <year> 1996. </year>
Reference-contexts: The most common techniques to reduce such round trip delays are caching (e.g., at users and in proxies) and prefetching documents associated with hyperlinks. These techniques can help but are not sufficient. Caching depends on locality patterns which may not hold as users explore new links; <ref> [WAS + 96] </ref> finds the locality of reference to be only 50% with high miss penalties for proxy cache misses. Also, [AW96] found that about a third of the files and bytes are accessed only once; this implies that caching at the server is tricky.
References-found: 17

