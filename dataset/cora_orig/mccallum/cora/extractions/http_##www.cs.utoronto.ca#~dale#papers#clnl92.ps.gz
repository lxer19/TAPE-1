URL: http://www.cs.utoronto.ca/~dale/papers/clnl92.ps.gz
Refering-URL: http://www.cs.utoronto.ca/~dale/
Root-URL: 
Email: wcohen@research.att.com  greiner@learning.siemens.com  dale@cs.toronto.edu  
Title: Probabilistic Hill-Climbing global optimum is often intractable, many practical learning systems use sim ple forms
Author: William W. Cohen Russell Greiner Dale Schuurmans 
Note: finding the  of  correct  Appears in Computational Learning Theory and Natural Learning Systems, Volume 2, MIT Press, 1992. Much of this work was performed at the University of Toronto, supported by the Institute for Robotics and Intelligent Systems and by an operating grant from the National Science and Engineering Research Council of Canada. All three authors gratefully acknowledge receiving many helpful comments from David Mitchell and the anonymous reviewers.  
Address: Murray Hill, NJ 07974  Princeton, NJ 08540  Toronto, Ontario M5S 1A4  
Affiliation: AT&T Bell Laboratories  Siemens Corporate Research  Department of Computer Science University of Toronto  
Abstract: Many learning tasks involve searching through a discrete space of performance distribution of problems, which typically is unknown. This paper formulates the problem estimated on the basis of their performance on random test cases. We present and prove elements, seeking an element whose future utility is expected to be high. As the task of
Abstract-found: 1
Intro-found: 1
Reference: [BD88] <author> Mark Boddy and Thomas Dean. </author> <title> Solving time dependent planning problems. </title> <type> Technical report, </type> <institution> Brown University, </institution> <year> 1988. </year>
Reference-contexts: Note#2. We can view palo as a variant on anytime algorithms <ref> [BD88, DB88] </ref> as, at any time, palo provides a usable result (here, the performance element produced at the j th iteration, PE j ), with the property that later elements are better than earlier ones; i.e., i &gt; j means C [ PE i ] &gt; C [ PE j ]
Reference: [BFOS84] <author> L. Breiman, J. Friedman, JR. Olshen, and C. Stone. </author> <title> Classification and Regression Trees. </title> <publisher> Wadsworth and Brooks, </publisher> <address> Monterey, CA, </address> <year> 1984. </year>
Reference-contexts: 1 Introduction Many learning tasks can be viewed as a search through a space of possible performance elements [BMSJ78], seeking an element that is optimal, under some utility measure. For example, many inductive systems seek optimal classification functions that correctly label as many examples as possible <ref> [BFOS84] </ref>; and many speed-up learning systems try to produce optimally efficient problem solving systems [DeJ88, MCK + 89, LNR87]. <p> Examples of such transformations include flipping the parity of a variable within a boolean formula, splitting a node in a decision tree <ref> [BFOS84] </ref>, reordering the clauses in prolog program [GJ92] or adding a new macro rule to a problem solver [GD91]. palo uses a set of sample queries drawn at random from the P r ( ) distribution to climb incrementally from the initial PE 1 to a new PE 2 = t
Reference: [BMSJ78] <author> Bruce G. Buchanan, Thomas M. Mitchell, Reid G. Smith, and C. R. Johnson, Jr. </author> <title> Models of learning systems. </title> <booktitle> In Encyclopedia of Computer Science and Technology, </booktitle> <volume> volume 11. </volume> <publisher> Dekker, </publisher> <year> 1978. </year>
Reference-contexts: 1 Introduction Many learning tasks can be viewed as a search through a space of possible performance elements <ref> [BMSJ78] </ref>, seeking an element that is optimal, under some utility measure. For example, many inductive systems seek optimal classification functions that correctly label as many examples as possible [BFOS84]; and many speed-up learning systems try to produce optimally efficient problem solving systems [DeJ88, MCK + 89, LNR87].
Reference: [Bol85] <author> B. Bollobas. </author> <title> Random Graphs. </title> <publisher> Academic Press, </publisher> <year> 1985. </year>
Reference-contexts: how confident we should be that C [ PE 0 ] &gt; C [ PE j ] and whether any "T -neighbor" of PE j (i.e., any t k (PE j ) ) is more than * better than PE j ; see the proof in Appendix A. 2 See <ref> [Bol85, p. 12] </ref>. These are also called "Hoeffding's Inequalities". N.b., these inequalities holds for essentially arbitrary distributions, not just normal distributions, subject only to the minor constraint that the random variables fd i g are bounded. Probabilistic Hill-Climbing 7 3.2 Notes and Extensions to palo Note#1.
Reference: [Che52] <author> Herman Chernoff. </author> <title> A measure of asymptotic efficiency for tests of a hypothesis based on the sums of observations. </title> <journal> Annals of Mathematical Statistics, </journal> <volume> 23 </volume> <pages> 493-507, </pages> <year> 1952. </year>
Reference-contexts: This average tends to the true population mean = C [ PE ff ] C [ PE fi ] as n ! 1; i.e., = lim n!1 Y n . Chernoff bounds <ref> [Che52] </ref> describe the probable rate of convergence: the probability that "Y n is more than + fl" goes to 0 exponentially fast as n increases; and for a fixed n, exponentially as fl increases.
Reference: [DB88] <author> Thomas Dean and Mark Boddy. </author> <title> An analysis of time-dependent planning. </title> <booktitle> In Proceedings of AAAI-88, </booktitle> <pages> pages 49-54, </pages> <month> August </month> <year> 1988. </year> <title> Probabilistic Hill-Climbing 13 </title>
Reference-contexts: Note#2. We can view palo as a variant on anytime algorithms <ref> [BD88, DB88] </ref> as, at any time, palo provides a usable result (here, the performance element produced at the j th iteration, PE j ), with the property that later elements are better than earlier ones; i.e., i &gt; j means C [ PE i ] &gt; C [ PE j ]
Reference: [DeJ88] <author> Gerald DeJong. </author> <booktitle> AAAI workshop on Explanation-Based Learning. Sponsored by AAAI, </booktitle> <year> 1988. </year>
Reference-contexts: For example, many inductive systems seek optimal classification functions that correctly label as many examples as possible [BFOS84]; and many speed-up learning systems try to produce optimally efficient problem solving systems <ref> [DeJ88, MCK + 89, LNR87] </ref>. In each case, the utility of the candidate performance elements is defined as the value of some scoring function, averaged over the natural distribution of samples (queries, tests, problems, : : : ) that the system will encounter.
Reference: [GD91] <author> Jonathan Gratch and Gerald DeJong. </author> <title> A hybrid approach to guaranteed effective control strategies. </title> <booktitle> In Proceedings of IWML-91, </booktitle> <pages> pages 509-13, </pages> <address> Evanston, Illinois, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: In addition, many speed-up learning methods can also be viewed as using hill-climbing to improve the expected performance of a problem solver: this view is clearly articulated in <ref> [GD91] </ref>. Unfortunately, even finding a locally optimal element can be problematic as it depends critically on the query distribution, which is often unknown. <p> Examples of such transformations include flipping the parity of a variable within a boolean formula, splitting a node in a decision tree [BFOS84], reordering the clauses in prolog program [GJ92] or adding a new macro rule to a problem solver <ref> [GD91] </ref>. palo uses a set of sample queries drawn at random from the P r ( ) distribution to climb incrementally from the initial PE 1 to a new PE 2 = t i (PE 1 ) using one t i 2 T , then onto a third PE 3 = <p> This constraint is trivially satisfied if the total number of transformations jT j is finite. It also holds in certain important situations where T is infinite. Consider, for example, a typical EBL (Explanation-Based Learning) system that uses operator composition to Probabilistic Hill-Climbing 8 transform performance elements <ref> [GD91] </ref>: Given an initial performance element PE 1 with n operators, palo can consider 2 distinct new performance elements, each formed by adding to PE 1 a new n + 1 st operator that is the result of composing two of PE 1 's existing n operators.
Reference: [GJ92] <author> Russell Greiner and Igor Jurisica. </author> <title> A statistical approach to solving the EBL utility problem. </title> <booktitle> In Proceedings of AAAI-92, </booktitle> <address> San Jose, </address> <year> 1992. </year>
Reference-contexts: For example, in context of seeking a good classification function, each PE 2 PE may be a particular decision tree [Qui86], or a specific boolean formula [Hau88], or a credulous prioritized default theory [Gre92]. Within the context of speed-up learning, <ref> [GJ92] </ref> views each PE 2 PE as a particular prolog program, where all of the programs in PE include exactly the same clauses, but differ in the order of these clauses. <p> Examples of such transformations include flipping the parity of a variable within a boolean formula, splitting a node in a decision tree [BFOS84], reordering the clauses in prolog program <ref> [GJ92] </ref> or adding a new macro rule to a problem solver [GD91]. palo uses a set of sample queries drawn at random from the P r ( ) distribution to climb incrementally from the initial PE 1 to a new PE 2 = t i (PE 1 ) using one t <p> : c ij [ PE i ; PE j ; q ] c ij + fl (PE i ; PE j ) Probabilistic Hill-Climbing 9 By inspection, fl [ PE i ; PE j ] is necessarily less than 2; hence fl max (PE j ) is always under . <ref> [GJ92] </ref> presents an example of a situation where fl max (PE j ) t . Second, [Gre92] presents a variant of our palo algorithm, that differs by taking samples one at a time, rather than in batches of size n j . <p> This reduces the total number of "PE on q" calls to jSj; see <ref> [GJ92] </ref> for an example of this approach. Note#6. <p> several other approaches as, for Probabilistic Hill-Climbing 10 example, we do not assume that this distribution of problems will be uniform [Gol79], nor that it will necessarily correspond to any particular collection of "benchmark challenge problems" [Kel87]. 4 Conclusion Applications: Several related papers present specific applications of this palo system. <ref> [GJ92] </ref> illustrates how this approach fits into the framework of "explanation-based learning" systems, and in particular, that how this analysis extends and formalizes [Min88]'s "utility analysis". It also presents empirical evidence that this system does work effectively.
Reference: [Gol79] <author> A. Goldberg. </author> <title> An average case complexity analysis of the satisfiability problem. </title> <booktitle> In Proceedings of the 4th Workshop on Automated Deduction, </booktitle> <pages> pages 1-6, </pages> <address> Austin, TX, </address> <year> 1979. </year>
Reference-contexts: This "average case analysis" differs from several other approaches as, for Probabilistic Hill-Climbing 10 example, we do not assume that this distribution of problems will be uniform <ref> [Gol79] </ref>, nor that it will necessarily correspond to any particular collection of "benchmark challenge problems" [Kel87]. 4 Conclusion Applications: Several related papers present specific applications of this palo system. [GJ92] illustrates how this approach fits into the framework of "explanation-based learning" systems, and in particular, that how this analysis extends and
Reference: [Gre91] <author> Russell Greiner. </author> <title> Finding the optimal derivation strategy in a redundant knowledge base. </title> <journal> Artificial Intelligence, </journal> <volume> 50(1) </volume> <pages> 95-116, </pages> <year> 1991. </year>
Reference-contexts: There are (at least) two potential problems with implementing such a learning system: First, the task of identifying the globally optimal element is intractable for many spaces; cf., [Hau88], <ref> [Gre91] </ref>. A common solution to this problem is to use a hill-climbing approach to find a locally optimal solution. Two well-known inductive learning systems that use this approach are id3 [Qui86], which uses a greedy technique to reduce the expected entropy of a decision tree, and backprop [Hin89].
Reference: [Gre92] <author> Russell Greiner. </author> <title> Probabilistic hill-climbing: Theory and applications. </title> <booktitle> In Proceedings of CSCSI-92, </booktitle> <address> Vancouver, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: For example, in context of seeking a good classification function, each PE 2 PE may be a particular decision tree [Qui86], or a specific boolean formula [Hau88], or a credulous prioritized default theory <ref> [Gre92] </ref>. Within the context of speed-up learning, [GJ92] views each PE 2 PE as a particular prolog program, where all of the programs in PE include exactly the same clauses, but differ in the order of these clauses. <p> Second, <ref> [Gre92] </ref> presents a variant of our palo algorithm, that differs by taking samples one at a time, rather than in batches of size n j . <p> It also presents empirical evidence that this system does work effectively. Other papers, notably <ref> [Gre92] </ref>, demonstrate the generality of this approach by presenting various other instantiations of the palo system, each using its own set of transformations to find a near-optimal element within a particular set of performance elements, where optimality is defined in terms of efficiency, accuracy or categoricity.
Reference: [Hau88] <author> David Haussler. </author> <title> Quantifying inductive bias: AI learning algorithms and Valiant's learning framework. </title> <booktitle> Artificial Intelligence, </booktitle> <pages> pages 177-221, </pages> <year> 1988. </year>
Reference-contexts: There are (at least) two potential problems with implementing such a learning system: First, the task of identifying the globally optimal element is intractable for many spaces; cf., <ref> [Hau88] </ref>, [Gre91]. A common solution to this problem is to use a hill-climbing approach to find a locally optimal solution. Two well-known inductive learning systems that use this approach are id3 [Qui86], which uses a greedy technique to reduce the expected entropy of a decision tree, and backprop [Hin89]. <p> For example, in context of seeking a good classification function, each PE 2 PE may be a particular decision tree [Qui86], or a specific boolean formula <ref> [Hau88] </ref>, or a credulous prioritized default theory [Gre92]. Within the context of speed-up learning, [GJ92] views each PE 2 PE as a particular prolog program, where all of the programs in PE include exactly the same clauses, but differ in the order of these clauses.
Reference: [Hau90] <author> David Haussler. </author> <title> Decision theoretic generalizations of the PAC model for neural net and other learning applications. </title> <type> Technical Report UCSC-CRL-91-02, </type> <institution> Department of Computer Science, UC Santa Cruz, </institution> <month> December </month> <year> 1990. </year>
Reference-contexts: Contributions: This report first poses two of the problems that can arise in learning systems that try to identify a performance element whose expected cost is optimal <ref> [Vap82, Hau90] </ref>: viz., that the distribution is usually unknown and that finding a globally optimal performance element can be intractable. It then presents the palo algorithm which addresses these shortcomings by using statistical techniques to approximate the distribution and by hill-climbing, efficiently, to produce a locally optimal element.
Reference: [Hin89] <author> Geoff Hinton. </author> <title> Connectionist learning procedures. </title> <journal> Artificial Intelligence, </journal> <volume> 40(1-3):185-234, </volume> <month> September </month> <year> 1989. </year>
Reference-contexts: A common solution to this problem is to use a hill-climbing approach to find a locally optimal solution. Two well-known inductive learning systems that use this approach are id3 [Qui86], which uses a greedy technique to reduce the expected entropy of a decision tree, and backprop <ref> [Hin89] </ref>. In addition, many speed-up learning methods can also be viewed as using hill-climbing to improve the expected performance of a problem solver: this view is clearly articulated in [GD91].
Reference: [Kel87] <author> Richard M. Keller. </author> <title> Defining operationality for explanation-based learning. </title> <booktitle> In Proceedings of AAAI-87, </booktitle> <pages> pages 482-87, </pages> <address> Seattle, </address> <month> July </month> <year> 1987. </year>
Reference-contexts: This "average case analysis" differs from several other approaches as, for Probabilistic Hill-Climbing 10 example, we do not assume that this distribution of problems will be uniform [Gol79], nor that it will necessarily correspond to any particular collection of "benchmark challenge problems" <ref> [Kel87] </ref>. 4 Conclusion Applications: Several related papers present specific applications of this palo system. [GJ92] illustrates how this approach fits into the framework of "explanation-based learning" systems, and in particular, that how this analysis extends and formalizes [Min88]'s "utility analysis".
Reference: [LNR87] <author> John E. Laird, Allan Newell, and Paul S. Rosenbloom. </author> <title> SOAR: An architecture of general intelligence. </title> <journal> Artificial Intelligence, </journal> <volume> 33(3), </volume> <year> 1987. </year> <title> Probabilistic Hill-Climbing 14 </title>
Reference-contexts: For example, many inductive systems seek optimal classification functions that correctly label as many examples as possible [BFOS84]; and many speed-up learning systems try to produce optimally efficient problem solving systems <ref> [DeJ88, MCK + 89, LNR87] </ref>. In each case, the utility of the candidate performance elements is defined as the value of some scoring function, averaged over the natural distribution of samples (queries, tests, problems, : : : ) that the system will encounter.
Reference: [MCK + 89] <author> Steven Minton, Jaime Carbonell, C.A. Knoblock, D.R. Kuokka, Oren Etzioni, and Y. Gil. </author> <title> Explanation-based learning: A problem solving perspective. </title> <journal> Artificial Intelligence, </journal> <volume> 40(1-3):63-119, </volume> <month> September </month> <year> 1989. </year>
Reference-contexts: For example, many inductive systems seek optimal classification functions that correctly label as many examples as possible [BFOS84]; and many speed-up learning systems try to produce optimally efficient problem solving systems <ref> [DeJ88, MCK + 89, LNR87] </ref>. In each case, the utility of the candidate performance elements is defined as the value of some scoring function, averaged over the natural distribution of samples (queries, tests, problems, : : : ) that the system will encounter.
Reference: [Min88] <author> Steven Minton. </author> <title> Learning Search Control Knowledge: An Explanation-Based Approach. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Hingham, MA, </address> <year> 1988. </year>
Reference: [MMS85] <author> Thomas M. Mitchell, Sridhar Mahadevan, and Louis I. Steinberg. </author> <title> LEAP: A learning apprentice for VLSI design. </title> <booktitle> In Proceedings of IJCAI-85, </booktitle> <pages> pages 573-80, </pages> <address> Los Angeles, </address> <month> August </month> <year> 1985. </year>
Reference-contexts: Note#6. The samples that palo uses may be supplied by a user of the performance system who is simply posing questions relevant to his current applications; in this case, palo is unobtrusively gathering statistics as the user is solving his own problems <ref> [MMS85] </ref>. palo must then compare the behavior of the current performance element with that of each alternative element; as discussed in Note 5 above, this can be done efficiently in some situations.
Reference: [Qui86] <author> J. R. Quinlan. </author> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1(1) </volume> <pages> 81-106, </pages> <year> 1986. </year>
Reference-contexts: A common solution to this problem is to use a hill-climbing approach to find a locally optimal solution. Two well-known inductive learning systems that use this approach are id3 <ref> [Qui86] </ref>, which uses a greedy technique to reduce the expected entropy of a decision tree, and backprop [Hin89]. In addition, many speed-up learning methods can also be viewed as using hill-climbing to improve the expected performance of a problem solver: this view is clearly articulated in [GD91]. <p> For example, in context of seeking a good classification function, each PE 2 PE may be a particular decision tree <ref> [Qui86] </ref>, or a specific boolean formula [Hau88], or a credulous prioritized default theory [Gre92].
Reference: [Val84] <author> Leslie G. Valiant. </author> <title> A theory of the learnable. </title> <journal> Communications of the ACM, </journal> <volume> 27(11) </volume> <pages> 1134-42, </pages> <year> 1984. </year>
Reference-contexts: As the name suggests, this is related to standard "Probably Approximately Correct", or PAC, learning <ref> [Val84] </ref>. Probabilistic Hill-Climbing 3 is statistically likely to be an incremental improvement over PE i and the performance of the final element PE m is a local optimal in the space searched by the learner.
Reference: [Vap82] <author> V.N. Vapnik. </author> <title> Estimation of Dependences Based on Empirical Data. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1982. </year>
Reference-contexts: Contributions: This report first poses two of the problems that can arise in learning systems that try to identify a performance element whose expected cost is optimal <ref> [Vap82, Hau90] </ref>: viz., that the distribution is usually unknown and that finding a globally optimal performance element can be intractable. It then presents the palo algorithm which addresses these shortcomings by using statistical techniques to approximate the distribution and by hill-climbing, efficiently, to produce a locally optimal element.
References-found: 23

