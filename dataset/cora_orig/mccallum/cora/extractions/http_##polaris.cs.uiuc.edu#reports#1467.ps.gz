URL: http://polaris.cs.uiuc.edu/reports/1467.ps.gz
Refering-URL: http://polaris.cs.uiuc.edu/tech_reports.html
Root-URL: http://www.cs.uiuc.edu
Email: xia,torrella@csrd.uiuc.edu  
Title: Improving the Data Cache Performance of Multiprocessor Operating Systems 1  
Author: Chun Xia and Josep Torrellas 
Address: IL 61801  
Affiliation: Center for Supercomputing Research and Development University of Illinois at Urbana-Champaign,  
Abstract: Bus-based shared-memory multiprocessors with coherent caches have recently become very popular. To achieve high performance, these systems rely on increasingly sophisticated cache hierarchies. However, while these machines often run loads with substantial operating system activity, performance measurements have consistently indicated that the operating system uses the data cache hierarchy poorly. In this paper, we address the issue of how to eliminate most of the data cache misses in a multiprocessor operating system while still using off-the-shelf processors. We use a performance monitor to examine traces of a 4-processor machine running four system-intensive loads under UNIX. Based on our observations, we propose hardware and software support that targets block operations, coherence activity, and cache conflicts. For block operations, simple cache bypassing or prefetching schemes are undesirable. Instead, it is best to use a DMA-like scheme that pipelines the data transfer in the bus without involving the processor. Coherence misses are handled with data privatization and relocation, and the use of updates for a small core of shared variables. Finally, the remaining miss hot spots are handled with data prefetching. Overall, our simulations show that all these optimizations combined eliminate or hide 75% of the operating system data misses in 32-Kbyte primary caches. Furthermore, they speed up the operating system by 19%. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Agarwal, J. Hennessy, and M. Horowitz. </author> <title> Cache Performance of Operating System and Multiprogramming Workloads. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 6(4) </volume> <pages> 393-431, </pages> <month> November </month> <year> 1988. </year>
Reference-contexts: Unfortunately, work by many researchers has consistently indicated that the operating system does not use the cache hierarchy very efficiently. While this is true for both instruction and data caches, in this paper we focus on the data caches exclusively. For example, Agarwal et al <ref> [1] </ref> pointed out the many cache misses caused by the operating system. 1 This work was supported in part by the National Science Foundation under grants NSF Young Investigator Award MIP 94-57436 and RIA MIP 93-08098; ARPA Contract No. DABT63-95-C-0097; and NASA Contract No. NAG-1-613.
Reference: [2] <author> T. Anderson, H. Levy, B. Bershad, and E. Lazowska. </author> <title> The Interaction of Architecture and Operating System Design. </title> <booktitle> In Proceedings of the 4th International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 108-120, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: DABT63-95-C-0097; and NASA Contract No. NAG-1-613. Similarly, Maynard et al [15] found out that kernel data miss rates are usually higher than application data miss rates. Ousterhout [17] and Anderson et al <ref> [2] </ref> emphasized the many costly activities performed by the operating system like block copying. Chen and Bershad [9] reported that memory system accesses by the operating system have a high cost and that block operations are particularly costly.
Reference: [3] <editor> J. B. </editor> <address> Andrews. </address>
Reference-contexts: We use a hardware performance monitor <ref> [3] </ref> that gathers uninter-rupted traces of application and operating system references in real time without introducing significant perturbation. The performance monitor has one probe connected to each of the four processors.
References-found: 3

