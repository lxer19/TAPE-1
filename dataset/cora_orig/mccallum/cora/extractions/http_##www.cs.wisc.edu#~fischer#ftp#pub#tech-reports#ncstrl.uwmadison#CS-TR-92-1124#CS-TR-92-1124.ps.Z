URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-92-1124/CS-TR-92-1124.ps.Z
Refering-URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-92-1124/
Root-URL: http://www.cs.wisc.edu
Title: Object Exploration By Purposive, Dynamic Viewpoint Adjustment  
Author: Kiriakos N. Kutulakos Charles R. Dyer Vladimir J. Lumelsky 
Keyword: Index terms: Purposive and qualitative vision, autonomous exploration, moving point of observation, surface visibility, provably-correct algorithms, generic smooth object surfaces, global surface geometry, occluding contour, visual events  
Note: The support of the National Science Foundation under grants IRI-9022608 and IRI-9196106 is gratefully acknowledged.  
Address: Madison, Wisconsin 53706  Madison, Wisconsin 53706  
Affiliation: Computer Sciences Department University of Wisconsin  Mechanical Engineering Department University of Wisconsin  
Abstract: Technical Report #1124 November 1992 Abstract We present a viewing strategy for exploring the surface of an unknown object (i.e., making all of its points visible) by purposefully controlling the motion of an active observer. It is based on a simple relation between (1) the instantaneous direction of motion of the observer, (2) the visibility of points projecting to the occluding contour, and (3) the surface normal at those points: If the dot product of the surface normal at such points and the observer's velocity is positive, the visibility of the points is guaranteed under an infinitesimal viewpoint change. We show that this leads to an object exploration strategy in which the observer purposefully controls its motion based on the occluding contour in order to impose structure on the set of surface points explored, make its representation simple and qualitative, and provably solve the exploration problem for smooth generic surfaces of arbitrary shape. Unlike previous approaches where exploration is cast as a discrete process (i.e., asking where to look next?) and where the successful exploration of arbitrary objects is not guaranteed, our approach demonstrates that dynamic viewpoint control through directed observer motion leads to a qualitative exploration strategy that is provably-correct, depends only on the dynamic appearance of the occluding contour, and does not require the recovery of detailed three-dimensional shape descriptions from every position of the observer. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. Marr, </author> <title> Vision. </title> <publisher> Freeman, </publisher> <year> 1982. </year>
Reference-contexts: 1 Introduction There has been considerable interest in active vision approaches that control the viewpoint of the observer (i.e., position) by following the principle of least commitment <ref> [1] </ref>. These approaches attempt to recover a three-dimensional description of objects in the scene from the current position before deciding where to move next [2].
Reference: [2] <author> P. Whaite and F. P. Ferrie, </author> <title> "From uncertainty to visual exploration," </title> <journal> IEEE Trans. Pattern Anal. Machine Intell., </journal> <volume> vol. 13, no. 10, </volume> <pages> pp. 1038-1049, </pages> <year> 1991. </year>
Reference-contexts: These approaches attempt to recover a three-dimensional description of objects in the scene from the current position before deciding where to move next <ref> [2] </ref>. Consequently, they require considerable processing on each image, and sophisticated sensor configurations are required for deriving detailed information about the geometry of the object from each position [3, 4].
Reference: [3] <author> S. A. Hutchinson and A. Kak, </author> <title> "Planning sensing strategies in a robot work cell with multi-sensor capabilities," </title> <journal> IEEE Trans. Robotics Automat., </journal> <volume> vol. 5, no. 6, </volume> <pages> pp. 765-783, </pages> <year> 1989. </year>
Reference-contexts: Consequently, they require considerable processing on each image, and sophisticated sensor configurations are required for deriving detailed information about the geometry of the object from each position <ref> [3, 4] </ref>.
Reference: [4] <author> J. Maver and R. </author> <title> Bajcsy, "Occlusions and the next view planning," </title> <booktitle> in Proc. IEEE Robotics Automat. Conf., </booktitle> <pages> pp. 1806-1811, </pages> <year> 1992. </year>
Reference-contexts: Consequently, they require considerable processing on each image, and sophisticated sensor configurations are required for deriving detailed information about the geometry of the object from each position <ref> [3, 4] </ref>. <p> Previous approaches that controlled viewpoint in order to induce the visibility of occluded parts of an object considered the process to be discrete: Viewpoint changes were determined by a sequence of observer positions <ref> [4, 15-18] </ref> generated by going through a three-step cycle: (1) Recover a detailed description of the visible or the occluded portions of the object from the current position of the observer, (2) merge this description with those produced from all previous positions, and (3) move to a new position. <p> This makes it very hard to predict the effectiveness or the performance of heuristic approaches to the exploration problem where, for example, substantial amounts of occlusion may be present. This is also the case for approaches using general optimization criteria for controlling the viewpoint of the observer <ref> [4] </ref> since their properties are highly dependent on the optimization criterion used, and their correctness and performance are hard to predict for objects bounded by surfaces with complicated geometry.
Reference: [5] <author> Y. Aloimonos, </author> <title> "Purposive and qualitative active vision," </title> <booktitle> in Proc. Int. Conf. on Pattern Recognition, </booktitle> <pages> pp. 346-360, </pages> <year> 1990. </year>
Reference-contexts: Consequently, they require considerable processing on each image, and sophisticated sensor configurations are required for deriving detailed information about the geometry of the object from each position [3, 4]. On the other hand, although previous approaches following the purposive vision paradigm <ref> [5] </ref> have been used to control viewing parameters such as focus, vergence and fixation for tasks like obstacle avoidance and tracking, the ability to direct the observer's motion for exploring an unknown object has not been exploited.
Reference: [6] <author> K. N. Kutulakos and C. R. Dyer, </author> <title> "Recovering shape by purposive viewpoint adjustment," </title> <booktitle> in Proc. Computer Vision and Pattern Recognition, </booktitle> <pages> pp. 16-22, </pages> <year> 1992. </year>
Reference-contexts: The main idea of our approach is to use an active (i.e., mobile) observer that purposefully directs its motion in order to achieve and maintain a specific geometric relationship with the object <ref> [6, 7] </ref>. We show that the ability to control the viewpoint of the observer in a continuous fashion through directed observer motion considerably simplifies the mathematical formulation of the object exploration problem. <p> These observations suggest that dynamic control of the observer's viewpoint can force the evolution of the appearance of the object to be locally predictable in time. Hence, this evolution can be controlled by directing the observer's motion. In <ref> [6] </ref> we showed that by appropriately controlling the evolution of the object appearance based on sparse and quickly-computable visual information (curvature measurements on the occluding contour), the mathematical formulation of the problem of recovering surface shape information becomes considerably simplified and leads to a qualitative, active vision strategy for solving it. <p> In particular, p rim will remain on the rim; it will be visible (i.e. it will remain on the occlusion boundary) unless the line connecting c (t) and p rim is along an asymptotic direction of the surface at p rim <ref> [6] </ref>. Following the same analysis as in [6] it can be shown that if p rim is hyperbolic, p will be occluded by a point in the neighborhood of p rim . If p rim is elliptic, p will remain visible but leave the occlusion boundary. <p> In particular, p rim will remain on the rim; it will be visible (i.e. it will remain on the occlusion boundary) unless the line connecting c (t) and p rim is along an asymptotic direction of the surface at p rim <ref> [6] </ref>. Following the same analysis as in [6] it can be shown that if p rim is hyperbolic, p will be occluded by a point in the neighborhood of p rim . If p rim is elliptic, p will remain visible but leave the occlusion boundary.
Reference: [7] <author> S. Hutchinson, </author> <title> "Exploiting visual constraints in robot motion planning," </title> <booktitle> in Proc. IEEE Robotics Automat. Conf., </booktitle> <pages> pp. 1722-1727, </pages> <year> 1991. </year>
Reference-contexts: The main idea of our approach is to use an active (i.e., mobile) observer that purposefully directs its motion in order to achieve and maintain a specific geometric relationship with the object <ref> [6, 7] </ref>. We show that the ability to control the viewpoint of the observer in a continuous fashion through directed observer motion considerably simplifies the mathematical formulation of the object exploration problem.
Reference: [8] <author> R. Bajcsy and M. Campos, </author> <title> "Active and exploratory perception," CVGIP: </title> <booktitle> Image Understanding, </booktitle> <volume> vol. 56, no. 1, </volume> <pages> pp. 31-40, </pages> <year> 1992. </year>
Reference: [9] <author> D. H. Ballard and C. M. Brown, </author> <booktitle> "Principles of animate vision," CVGIP: Image Understanding, </booktitle> <volume> vol. 56, no. 1, </volume> <pages> pp. 3-21, </pages> <year> 1992. </year> <note> Special Issue on Purposive, Qualitative, Active Vision. </note>
Reference: [10] <author> J. S. </author> <title> Bay, "A fully autonomous active sensor-based exploration concept for shape-sensing robots," </title> <journal> IEEE Trans. Syst. Man Cybern., </journal> <volume> vol. 21, no. 4, </volume> <pages> pp. 850-860, </pages> <year> 1991. </year>
Reference: [11] <author> R. Curwen, A. Blake, and A. Zisserman, </author> <title> "Real-time visual tracking for surveillance and path planning," </title> <booktitle> in Proc. 2nd European Conf. on Computer Vision, </booktitle> <pages> pp. 879-883, </pages> <year> 1992. </year>
Reference: [12] <author> C. Laugier, A. Ijel, and J. Troccaz, </author> <title> "Combining vision based information and partial geometric models in automatic grasping," </title> <booktitle> in Proc. IEEE Robotics Automat. Conf., </booktitle> <pages> pp. 676-682, </pages> <year> 1990. </year>
Reference-contexts: This type of behavior is particularly important for a number of tasks, such as generating three-dimensional object-centered descriptions that cover the entire surface of a non-convex object, searching for surface markings during object recognition, avoiding occlusion during object grasping <ref> [12, 13] </ref>, and object model acquisition by obtaining a series of aspects [14] that completely describes the object.
Reference: [13] <author> J. Y. Zheng et al., </author> <title> "Active camera controlling for manipulation," </title> <booktitle> in Proc. Computer Vision and Pattern Recognition, </booktitle> <pages> pp. 413-418, </pages> <year> 1991. </year>
Reference-contexts: This type of behavior is particularly important for a number of tasks, such as generating three-dimensional object-centered descriptions that cover the entire surface of a non-convex object, searching for surface markings during object recognition, avoiding occlusion during object grasping <ref> [12, 13] </ref>, and object model acquisition by obtaining a series of aspects [14] that completely describes the object.
Reference: [14] <author> M. Seibert and A. M. Waxman, </author> <title> "Adaptive 3-d object recognition from multiple views," </title> <journal> IEEE Trans. Pattern Anal. and Machine Intell., </journal> <volume> vol. 14, no. 2, </volume> <pages> pp. 107-124, </pages> <year> 1992. </year>
Reference-contexts: type of behavior is particularly important for a number of tasks, such as generating three-dimensional object-centered descriptions that cover the entire surface of a non-convex object, searching for surface markings during object recognition, avoiding occlusion during object grasping [12, 13], and object model acquisition by obtaining a series of aspects <ref> [14] </ref> that completely describes the object.
Reference: [15] <author> C. I. Connoly, </author> <title> "The determination of next best views," </title> <booktitle> in Proc. IEEE Robotics Automat. Conf., </booktitle> <pages> pp. 432-435, </pages> <year> 1985. </year> <month> 36 </month>
Reference-contexts: An important characteristic of these strategies is that they try to select a sequence of view 3 points where the appearance of the object is as different as possible from those at all previous viewpoints. For example, Connoly <ref> [15] </ref> attempted to find a viewpoint that maximizes the area of object surface points that will be visible for the first time.
Reference: [16] <author> G. Hager and M. Mintz, </author> <title> "Searching for information," </title> <booktitle> in Proc. Workshop on Spatial Reason--ing and Multi-Sensor Fusion, </booktitle> <pages> pp. 313-322, </pages> <year> 1987. </year>
Reference: [17] <author> S. Lee and H. Hahn, </author> <title> "An optimal sensing strategy for recognition and localization of 3-d natural quadric objects," </title> <journal> IEEE Trans. Pattern Anal. Machine Intell., </journal> <volume> vol. 13, no. 10, </volume> <pages> pp. 1018-1037, </pages> <year> 1991. </year>
Reference: [18] <author> M. J. Swain and M. Stricker, eds., </author> <title> Promising Directions in Active Vision, </title> <institution> University of Chicago, </institution> <month> November </month> <year> 1991. </year> <title> Written by the attendees of the NSF Active Vision Workshop. </title>
Reference: [19] <author> J. J. Koenderink, </author> <title> Solid Shape. </title> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: We feel that theoretical work on the object exploration problem is necessary for two reasons. First, the visual complexity of an object can be significant even when it is bounded by a simple non-convex surface (e.g., a sphere with a dent <ref> [19] </ref>). This makes it very hard to predict the effectiveness or the performance of heuristic approaches to the exploration problem where, for example, substantial amounts of occlusion may be present. <p> In our analysis we assume that the object is bounded by a smooth and generic surface <ref> [19] </ref>. Generic surfaces are surfaces whose topological and geometrical characteristics are stable under infinitesimal perturbations. They correspond to a very general class of surfaces since an infinitesimal perturbation of a non-generic smooth surface will make it generic. <p> P d2&lt; for which there is a plane in the family tangent to a parabolic surface point is a zero-measure subset on the sphere of possible plane orientations. 20 number of points on the surface having the same normal, a number that depends on the folds of the Gauss map <ref> [19] </ref>. Currently, several algorithms exist that solve variations of the abstract graph exploration problem (e.g., [28]). <p> Since c (t) is stable, this circumnavigation event corresponds to a T-junction in the occluding contour with L (t) being the associated bitangent ray <ref> [19] </ref>. <p> The occurrence of the second type of event poses special problems for the circumnavigation 8 If the position of the observer is not stable, this circumnavigation event corresponds to a change in the topology of the occluding contour <ref> [19] </ref>.
Reference: [20] <author> R. Cipolla and A. Blake, </author> <title> "The dynamic analysis of apparent contours," </title> <booktitle> in Proc. 3rd Int. Conf. on Computer Vision, </booktitle> <pages> pp. 616-623, </pages> <year> 1990. </year>
Reference-contexts: On the other hand, if the exploration process is used for the purpose of building a three-dimensional object description, dynamic control of the observer's viewpoint implies that successive views of the object will be very similar, making the shape recovery problem well-posed and the fusion of multiple views easier <ref> [20] </ref>. Furthermore, by employing a moving observer our approach is well-suited for building dynamic, viewer-centered object representations where the dynamic, viewpoint-dependent appearance of objects is modelled explicitly [21]. 1.2 Dynamic, Purposive Object Exploration In our approach, viewpoint control and visual processing are continuous, interdependent processes that occur simultaneously. <p> More importantly, this connection allows us to use the occluding contour and the visible rim as our basic forms of visual input: The occluding contour provides all the information necessary for recovering surface shape by a moving observer <ref> [20, 23, 8 25] </ref>, and the dynamics of its appearance can be used for substantially constraining algorithmic search when exploration is combined with recognition tasks [26]. <p> From a practical standpoint, the recovery of sparse, qualitative visual information such as the occluding contour imposes a relatively light computational burden on the observer, making the occluding contour suitable for problems requiring its real-time detection and tracking <ref> [20, 27, 25] </ref>. To see how the evolution of the exploration frontier and the dynamics of the occluding contour are related, note that changes in the exploration frontier occur when unexplored points on the surface become visible. <p> When the field of view is restricted, the only additional mechanism required is a fixation and tracking mechanism used to track a segment of the occluding contour (e.g., see <ref> [20] </ref>). 11 3. If N (p rim ) v (t) = 0, (a) p rim will either remain on the occlusion boundary or become occluded, and (b) the visibility of p is completely determined by the local shape of the surface at p rim and by v (t). Proof. <p> In the following, we refer to the segments of the occlusion boundary that satisfy the above inequality as the strip-generating segments at time t. The strips produced by these segments can be considered as families of curves on the surface, indexed by the time parameter t <ref> [20] </ref>, forming a two-dimensional subset of the surface. <p> Therefore, the computation of ffi a and ffi b can be performed by computing, at every position of the observer, the distance of these endpoints from the motion plane (Figure 3 (b)) using an approach such as the one by Cipolla and Blake <ref> [20] </ref>. 3.2 Formulating the Object Exploration Problem The cylindrical shape of the strips and the structured motion of the observer can be used to simplify the structure of the exploration frontier considerably. <p> For example, the simple viewing strategy presented for exploring cylindrical strips of an object surface can be easily implemented as a front-end motion control module for other procedures that recover surface curvature information from the deformation of the occluding contour <ref> [20, 27] </ref>. We are currently in the process of implementing this exploration strategy for exploring and recovering the shape of cylindrical strips 34 on synthetic object surfaces. At a theoretical level, we are also investigating strip exploration strategies that guarantee the convergence of the exploration process. 35
Reference: [21] <author> W. B. Seales and C. R. Dyer, </author> <title> "Viewpoint from occluding contour," CVGIP: </title> <booktitle> Image Understanding, </booktitle> <volume> vol. 55, no. 2, </volume> <pages> pp. 198-211, </pages> <year> 1992. </year>
Reference-contexts: Furthermore, by employing a moving observer our approach is well-suited for building dynamic, viewer-centered object representations where the dynamic, viewpoint-dependent appearance of objects is modelled explicitly <ref> [21] </ref>. 1.2 Dynamic, Purposive Object Exploration In our approach, viewpoint control and visual processing are continuous, interdependent processes that occur simultaneously.
Reference: [22] <author> J. J. Gibson, </author> <title> The Ecological Approach to Visual Perception. </title> <publisher> Houghton Mi*in, </publisher> <year> 1979. </year>
Reference-contexts: The main result of Section 2 is Theorem 2.1, which can be thought as a formal analog of Gibson's law of reversible occlusion <ref> [22] </ref>. The second part of the paper, presented in Section 3, builds on this basic result to formally develop an exploration strategy for the case where the object is bounded by a single, smooth, generic surface.
Reference: [23] <author> P. Giblin and R. Weiss, </author> <title> "Reconstruction of surfaces from profiles," </title> <booktitle> in Proc. 1st Int. Conf. on Computer Vision, </booktitle> <pages> pp. 136-144, </pages> <year> 1987. </year>
Reference-contexts: More importantly, this connection allows us to use the occluding contour and the visible rim as our basic forms of visual input: The occluding contour provides all the information necessary for recovering surface shape by a moving observer <ref> [20, 23, 8 25] </ref>, and the dynamics of its appearance can be used for substantially constraining algorithmic search when exploration is combined with recognition tasks [26]. <p> Proof. By definition, circumnavigation events occur iff (1) f is not continuous, or (2) the assumptions of Theorem 2.1 do not hold. Discontinuities of f occur iff the line L (t) connecting c (t) and g (t) is along a direction for which the pedal curve <ref> [23] </ref> w () of the smooth curve ff has a cusp at . In [23] Giblin and Weiss showed that cusp points on w () occur iff is the direction of an inflectional tangent, i.e., when L (t) is tangent at an inflection point of ff, i.e., Event 1 (Figure 8 <p> Discontinuities of f occur iff the line L (t) connecting c (t) and g (t) is along a direction for which the pedal curve <ref> [23] </ref> w () of the smooth curve ff has a cusp at . In [23] Giblin and Weiss showed that cusp points on w () occur iff is the direction of an inflectional tangent, i.e., when L (t) is tangent at an inflection point of ff, i.e., Event 1 (Figure 8 (a) at time t 1 ).
Reference: [24] <author> J. J. Koenderink, </author> <title> "An internal representation for solid shape based on the topological properties of the apparent contour," in Image Understanding 1985-86 (W. </title> <editor> Richards and S. Ullman, </editor> <booktitle> eds.), </booktitle> <pages> pp. 257-285, </pages> <address> Norwood, NJ: </address> <publisher> Ablex Publishing Co., </publisher> <year> 1987. </year>
Reference-contexts: The visible rim consists of the rim points that are visible. The connection between the evolution of the exploration frontier and the dynamics of the occluding contour is a very important one because the geometry and topology of the occluding contour has been widely studied (e.g., <ref> [24] </ref>). <p> Since p rim and p are occlusion boundary points, their visibility is determined by the sign of N (p rim ) [p rim c (t)] <ref> [24] </ref>. In particular, for any visible surface point x we have N (x) [x c (t)] &lt; 0. <p> From Meunsier's Theorem [30], the normal curvature of S along L (t) is 0, i.e., L (t) is along an asymptotic direction of S at g (t). 29 Hence, if c (t) is a stable position, g (t) is a cusp point on the visible rim <ref> [24] </ref>; the circumnavigation event in this case corresponds to a cusp point crossing the motion plane 8 (Figure 8 (c)). Now, without loss of generality, suppose that the observer is circumnavigating ff in the clockwise direction.
Reference: [25] <author> R. Vaillant and O. D. Faugeras, </author> <title> "Using extremal boundaries for 3-d object modeling," </title> <journal> IEEE Trans. Pattern Anal. Machine Intell., </journal> <volume> vol. 14, no. 2, </volume> <pages> pp. 157-173, </pages> <year> 1992. </year>
Reference-contexts: From a practical standpoint, the recovery of sparse, qualitative visual information such as the occluding contour imposes a relatively light computational burden on the observer, making the occluding contour suitable for problems requiring its real-time detection and tracking <ref> [20, 27, 25] </ref>. To see how the evolution of the exploration frontier and the dynamics of the occluding contour are related, note that changes in the exploration frontier occur when unexplored points on the surface become visible.
Reference: [26] <author> R. Basri and S. Ullman, </author> <title> "The alignment of objects with smooth surfaces," </title> <booktitle> in Proc. 2nd Int. Conf. on Computer Vision, </booktitle> <pages> pp. 482-488, </pages> <year> 1988. </year>
Reference-contexts: visible rim as our basic forms of visual input: The occluding contour provides all the information necessary for recovering surface shape by a moving observer [20, 23, 8 25], and the dynamics of its appearance can be used for substantially constraining algorithmic search when exploration is combined with recognition tasks <ref> [26] </ref>. From a practical standpoint, the recovery of sparse, qualitative visual information such as the occluding contour imposes a relatively light computational burden on the observer, making the occluding contour suitable for problems requiring its real-time detection and tracking [20, 27, 25].
Reference: [27] <author> A. Blake, M. Brady, R. Cipolla, Z. Xie, and A. Zisserman, </author> <title> "Visual navigation around curved obstacles," </title> <booktitle> in Proc. IEEE Robotics Automat. Conf., </booktitle> <pages> pp. 2490-2495, </pages> <year> 1991. </year>
Reference-contexts: From a practical standpoint, the recovery of sparse, qualitative visual information such as the occluding contour imposes a relatively light computational burden on the observer, making the occluding contour suitable for problems requiring its real-time detection and tracking <ref> [20, 27, 25] </ref>. To see how the evolution of the exploration frontier and the dynamics of the occluding contour are related, note that changes in the exploration frontier occur when unexplored points on the surface become visible. <p> For example, the simple viewing strategy presented for exploring cylindrical strips of an object surface can be easily implemented as a front-end motion control module for other procedures that recover surface curvature information from the deformation of the occluding contour <ref> [20, 27] </ref>. We are currently in the process of implementing this exploration strategy for exploring and recovering the shape of cylindrical strips 34 on synthetic object surfaces. At a theoretical level, we are also investigating strip exploration strategies that guarantee the convergence of the exploration process. 35
Reference: [28] <author> V. J. Lumelsky, </author> <title> "A comparative study on the path length performance of maze-searching and robot motion planning algorithms," </title> <journal> IEEE Trans. Robotics Automat., </journal> <volume> vol. 7, no. 1, </volume> <pages> pp. 57-66, </pages> <year> 1991. </year>
Reference-contexts: We use results from the 17 differential topology of surfaces that allow us to represent the surface as a graph and to reduce the exploration process to an abstract graph exploration problem <ref> [28] </ref>. The graph representation of the surface we employ is a direct generalization of a tree-like representation developed by Koenderink for the qualitative description of gray-scale images [29]. <p> Currently, several algorithms exist that solve variations of the abstract graph exploration problem (e.g., <ref> [28] </ref>). Second, the approach allows the use of a qualitative representation of the exploration frontier containing only the information necessary for solving the exploration problem: The exploration frontier is represented by the set of vertices in the graph adjacent to at least one traversed and one untraversed edge. <p> The automaton can leave v by traversing a previously 21 untraversed edge incident to v and then marking it traversed, or it can backtrack by traversing the edge e in the opposite direction. Existing algorithms for exploring an arbitrary, unknown graph rely on depth-first search (e.g., Tarry's algorithm <ref> [28] </ref>).
Reference: [29] <author> J. J. Koenderink and A. J. van Doorn, </author> <title> "A description of the structure of visual images in terms of an ordered hierarchy of light and dark blobs," </title> <booktitle> in Proc. Second Int. Visual Psychophysics and Medical Imaging Conf., </booktitle> <pages> pp. 173-176, </pages> <year> 1981. </year>
Reference-contexts: The graph representation of the surface we employ is a direct generalization of a tree-like representation developed by Koenderink for the qualitative description of gray-scale images <ref> [29] </ref>. To see how such a representation can be derived for a given surface S, fix a plane P 0 in the family of parallel motion planes selected by the observer.
Reference: [30] <author> M. P. D. Carmo, </author> <title> Differential Geometry of Curves and Surfaces. </title> <address> Englewood Cliffs, NJ: </address> <publisher> Prentice-Hall Inc., </publisher> <year> 1976. </year>
Reference-contexts: To see the changes in the occluding contour that correspond to this event, let g (t) be a visible rim point for which L (t) is tangent to ff at an inflection point. From Meunsier's Theorem <ref> [30] </ref>, the normal curvature of S along L (t) is 0, i.e., L (t) is along an asymptotic direction of S at g (t). 29 Hence, if c (t) is a stable position, g (t) is a cusp point on the visible rim [24]; the circumnavigation event in this case corresponds
Reference: [31] <author> L. R. Nackman, </author> <title> "Two-dimensional critical point configuration graphs," </title> <journal> IEEE Trans. Pattern Anal. Machine Intell., </journal> <volume> vol. 6, no. 4, </volume> <pages> pp. 442-450, </pages> <year> 1984. </year> <month> 37 </month>
References-found: 31

