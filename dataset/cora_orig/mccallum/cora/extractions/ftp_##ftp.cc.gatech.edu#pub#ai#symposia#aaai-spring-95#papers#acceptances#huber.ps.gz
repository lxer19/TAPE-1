URL: ftp://ftp.cc.gatech.edu/pub/ai/symposia/aaai-spring-95/papers/acceptances/huber.ps.gz
Refering-URL: ftp://ftp.cc.gatech.edu/pub/ai/symposia/aaai-spring-95/papers/finals.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: fmarcush, durfeeg@engin.umich.edu  
Title: On Acting Together: Without Communication  
Author: Marcus J. Huber Edmund H. Durfee 
Keyword: Distributed Artificial Intelligence, Cooperation, Coordination, and Conflict  
Address: 1101 Beal Avenue Ann Arbor, Michigan 48109-2110  
Affiliation: Artificial Intelligence Laboratory The University of Michigan  
Abstract: It is important, in situations where teams of agents can commit to joint, long-term objectives, that the agents be able to identify when the team objective is no longer important, or is futile. Prior work has typically assumed that agents should believe that joint commitments hold unless explicitly told otherwise by other agents. In this paper, we argue that this assumption expects too much from the communication channels and from agents that initiate the abandonment of the commitment. A more general, robust method for monitoring a joint commitment is to make each agent responsible for acquiring evidence that supports or refutes the contention of the sustained commitment. While this evidence can include explicit messages from others, it also can include observations made by the agent and interpretations of those observations. We thus build from formal notions of commitment to collective goals, and conventions for explicit maintenance of beliefs about commitments, and extend this work to allow observations and the consideration of imperfect communication channels. Our approach has been implemented and tested in the application domain of cooperative robotic reconnaissance in a sometimes hostile environment. 
Abstract-found: 1
Intro-found: 1
Reference: [ Halpern and Moses, 1984 ] <author> Halpern,Joseph Y. </author> <title> and Moses,Yoram . Knowledge and common knowledge in a distributed environment. </title> <booktitle> In Third ACM Conference on Principles of Distributed Computing, </booktitle> <year> 1984. </year>
Reference-contexts: Second, communication in practical systems is uncertain to successfully convey unambiguous information <ref> [ Halpern and Moses, 1984 ] </ref> , so achieving common knowledge of the status of team commitments might be problematic. Third, it could be obvious to the other agents that the commitment has been dropped solely from observations.
Reference: [ Huber et al., 1994a ] <author> Huber,Marcus J. , Durfee,Edmund H. , and Wellman,Michael P. </author> . <title> The automated mapping of plans for plan recognition. </title> <booktitle> In Workshop on Distributed Artificial Intelligence, </booktitle> <pages> pages 137-152, </pages> <address> Lake Quinalt, WA, </address> <month> July </month> <year> 1994. </year>
Reference-contexts: For a more thorough account of belief networks, see, for example, [ Pearl, 1988 ] or [ Neapolitan, 1990 ] . Converting plan models into representations conducive to plan recognition is normally a difficult and time consuming operation. In <ref> [ Huber et al., 1994a; Huber et al., 1994b ] </ref> we describe a methodology that we have developed by which plans such as those shown above can automatically be converted into belief networks. <p> These procedures handle a broad class of plans, including those with sequential actions, conditional branching, subgoal ing, and iteration. In general, the procedures take plan constructs and build portions of belief networks that model those constructs. See <ref> [ Huber et al., 1994a; Huber et al., 1994b ] </ref> for a full description of the transformation methods. Experiments To this point, we have discussed the general issues involved with extending the communication-based Joint Persistent Goal definition of Levesque et al to be less reliant on communication. <p> The domain of our example is that of military reconnaisance, where two (or more) cooperative agents are engaged in performing a bounding overwatch. In of the bounding overwatch task. These four KAs are added to those of the definition of Joint Persistent Goal and, using the transformation methods of <ref> [ Huber et al., 1994a; Huber et al., 1994b ] </ref> , our system maps this collection of KAs into a belief network, starting with the competing top-level goals of the joint goal achieve WG performed bound (i.e. in the JPG KAs in section Plan Embodiment, replace p with performed bound), and <p> In these figures, the highlighted nodes with the scissor icon above them indicates that the nodes are fully detailed in a belief network in a later figure. We have shown in previous work <ref> [ Huber et al., 1994a ] </ref> that the belief network for the four KAs above permits useful queries to be made concerning the beliefs of the observed agent (e.g. "Is the other agent performing a bound?", "Is there an enemy in the vicinity?", etc.) In general, the behavior of the belief
Reference: [ Huber et al., 1994b ] <author> Huber,Marcus J. , Durfee,Edmund H. , and Wellman,Michael P. </author> . <title> The automated mapping of plans for plan recognition. </title> <booktitle> In Proceedings of the Tenth Conference on Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 344-351, </pages> <address> Seattle, Wash-ington, </address> <month> July </month> <year> 1994. </year>
Reference-contexts: For a more thorough account of belief networks, see, for example, [ Pearl, 1988 ] or [ Neapolitan, 1990 ] . Converting plan models into representations conducive to plan recognition is normally a difficult and time consuming operation. In <ref> [ Huber et al., 1994a; Huber et al., 1994b ] </ref> we describe a methodology that we have developed by which plans such as those shown above can automatically be converted into belief networks. <p> These procedures handle a broad class of plans, including those with sequential actions, conditional branching, subgoal ing, and iteration. In general, the procedures take plan constructs and build portions of belief networks that model those constructs. See <ref> [ Huber et al., 1994a; Huber et al., 1994b ] </ref> for a full description of the transformation methods. Experiments To this point, we have discussed the general issues involved with extending the communication-based Joint Persistent Goal definition of Levesque et al to be less reliant on communication. <p> The domain of our example is that of military reconnaisance, where two (or more) cooperative agents are engaged in performing a bounding overwatch. In of the bounding overwatch task. These four KAs are added to those of the definition of Joint Persistent Goal and, using the transformation methods of <ref> [ Huber et al., 1994a; Huber et al., 1994b ] </ref> , our system maps this collection of KAs into a belief network, starting with the competing top-level goals of the joint goal achieve WG performed bound (i.e. in the JPG KAs in section Plan Embodiment, replace p with performed bound), and
Reference: [ Huber et al., 1994c ] <author> Huber,Marcus J. , Lee,Jaeho , Kenny,Patrick , and Durfee,Edmund H. </author> . <title> UM-PRS V2.7 Programmer and User Guide. </title> <institution> The University of Michigan, </institution> <address> 1101 Beal Avenue, Ann Arbor MI 48109, </address> <month> Oct </month> <year> 1994. </year>
Reference-contexts: While this could be done in a number of plan execution systems, in this paper we detail more precisely how it can be supported in UM-PRS <ref> [ Huber et al., 1994c ] </ref> , our variant of Georgeff et al's PRS [ Ingrand et al., 1992 ] . <p> For the sake of comparison, we will look at the case of joint goals for two agents. And, as was mentioned earlier, we will illustrate the implementation in the syntax of UM-PRS <ref> [ Huber et al., 1994c ] </ref> , an implementation of the Procedural Reasoning System (PRS) [ Ingrand et al., 1992 ] . In this section, we first give a general overview of UM-PRS and then show how some of the JPG definitions can be implemented within UM-PRS. <p> Furthermore, iteration and branching are accomplished through while, do, or, and and actions. Comments are preceded by "//" symbols. Refer to <ref> [ Huber et al., 1994c ] </ref> for a complete description of the runtime semantics of UM-PRS. We will discuss the semantics that are relevant, as needed. Joint Persistent Knowledge Areas We show the KAs that embodies the definition of a Weak Mutual Goal from section Joint Commitment in Figure 1.
Reference: [ Ingrand et al., 1992 ] <institution> Ingrand,Francois , Georgeff,Michael , and Rao,Anand . An architecture for real-time reasoning and system control. IEEE Expert, </institution> <month> 7(6) </month> <pages> 34-44, </pages> <month> December </month> <year> 1992. </year>
Reference-contexts: While this could be done in a number of plan execution systems, in this paper we detail more precisely how it can be supported in UM-PRS [ Huber et al., 1994c ] , our variant of Georgeff et al's PRS <ref> [ Ingrand et al., 1992 ] </ref> . The representation explicitly captures the context under which commitments should be believed to hold, and thus agents following conventions that cause them to update each other upon commitment abandonment can use these mechanisms. <p> For the sake of comparison, we will look at the case of joint goals for two agents. And, as was mentioned earlier, we will illustrate the implementation in the syntax of UM-PRS [ Huber et al., 1994c ] , an implementation of the Procedural Reasoning System (PRS) <ref> [ Ingrand et al., 1992 ] </ref> . In this section, we first give a general overview of UM-PRS and then show how some of the JPG definitions can be implemented within UM-PRS. UM-PRS supports all of the standard planning constructs such as conditional branching, context, iteration, subgoaling, etc.
Reference: [ Jennings, 1993 ] <author> Jennings,Nick R. </author> . <title> Commitments and conventions: The foundation of coordination in multi-agent systems. </title> <journal> Knowledge Engineering Review, </journal> <volume> 8(3) </volume> <pages> 223-250, </pages> <year> 1993. </year>
Reference-contexts: Levesque et al [ Levesque et al., 1990 ] have developed an explicit representation of joint goals and commitments, along with an implicit (hardwired) response to commitment abandonment. Jennings <ref> [ Jennings, 1993 ] </ref> has followed up that work with an explicit representation to joint plans and responsibilities, along with explicit (rule-based) responses to commitment abandonment.
Reference: [ Levesque et al., 1990 ] <author> Levesque,Hector J. , Cohen,Philip R. , and Nunes,Jose H. T. </author> . <title> On acting together. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 94-99, </pages> <month> July </month> <year> 1990. </year>
Reference-contexts: Thus, it is important for an agent that is part of a team to represent its commitment to team objectives and reason about when to abandon that commitment. Levesque et al <ref> [ Levesque et al., 1990 ] </ref> have developed an explicit representation of joint goals and commitments, along with an implicit (hardwired) response to commitment abandonment. <p> Joint Commitment The idea of individual members of a team forming a joint commitment to a team goal is not new. In <ref> [ Levesque et al., 1990 ] </ref> , Levesque, Cohen, and Nunes developed a formal definition of such a joint commitment. <p> For complete definitions, see <ref> [ Levesque et al., 1990 ] </ref> . Below, we present the most important definitions, those of Weak Mutual Goal (WMG), Weak Goal (WG), and Joint Persistent Goal (JPG), respectively.
Reference: [ Neapolitan, 1990 ] <author> Neapolitan,Richard E. </author> . <title> Probabilistic Reasoning in Expert Systems. </title> <publisher> John Wiley and Sons, </publisher> <year> 1990. </year>
Reference-contexts: For a more thorough account of belief networks, see, for example, [ Pearl, 1988 ] or <ref> [ Neapolitan, 1990 ] </ref> . Converting plan models into representations conducive to plan recognition is normally a difficult and time consuming operation.
Reference: [ Pearl, 1988 ] <editor> Pearl,Judea . Probabilistic Reasoning in Intelligent Systems: </editor> <title> Networks of Plausible Inference. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1988. </year>
Reference-contexts: Each random variable ranges over a domain of outcomes, with a conditional probability distribution specifying the probabilities for each state for given all combinations of outcome values for the predecessors of the random variable in the network. For a more thorough account of belief networks, see, for example, <ref> [ Pearl, 1988 ] </ref> or [ Neapolitan, 1990 ] . Converting plan models into representations conducive to plan recognition is normally a difficult and time consuming operation.
References-found: 9

