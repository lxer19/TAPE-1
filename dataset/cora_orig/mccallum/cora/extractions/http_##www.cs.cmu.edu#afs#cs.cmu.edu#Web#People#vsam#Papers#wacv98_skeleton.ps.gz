URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/Web/People/vsam/Papers/wacv98_skeleton.ps.gz
Refering-URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/Web/People/vsam/iubapage.html
Root-URL: 
Email: email: fhironobujajlg@cs.cmu.edu  
Title: Real-time human motion analysis by image skeletonization  
Author: Hironobu Fujiyoshi Alan J. Lipton 
Web: URL: http://www.cs.cmu.edu/~ vsam  
Address: 5000 Forbes Avenue, Pittsburgh, PA, 15213  
Affiliation: The Robotics Institute. Carnegie Mellon University.  
Abstract: In this paper, a process is described for analysing the motion of a human target in a video stream. Moving targets are detected and their boundaries extracted. From these, a "star" skeleton is produced. Two motion cues are determined from this skeletonization: body posture, and cyclic motion of skeleton segments. These cues are used to determine human activities such as walking or running, and even potentially, the target's gait. Unlike other methods, this does not require an a priori human model, or a large number of "pixels on target". Furthermore, it is computationally inexpensive, and thus ideal for real-world video applications such as outdoor video surveillance. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> C. Anderson, P. Burt, G. </author> <title> van der Wal "Change detection and tracking using pyramid transformation techniques" SPIE Intelligent Robots and Computer Vision Vol. </title> <booktitle> 579, </booktitle> <pages> pp. 72-78, </pages> <year> 1985 </year>
Reference-contexts: System analysis and conclusions are presented in sections 5 and 6. 2 Real-time target extraction The initial stage of the human motion analysis problem is the extraction of moving targets from a video stream. There are three conventional approaches to moving target detection: temporal differencing (two-frame or three-frame) <ref> [1] </ref>, background subtraction [5, 10] and optical flow (see [2] for an excellent discussion). Temporal differencing is very adaptive to dynamic environments, but generally does a poor job of extracting all relevant feature pixels.
Reference: [2] <author> J. Barron, D. Fleet, S. </author> <title> Beauchemin "Performance of Optical Flow Techniques" International Journal of Computer Vision, </title> <journal> Vol. </journal> <volume> 12, no. 1, </volume> <pages> pp. 42-77, </pages> <month> Jan. </month> <year> 1994 </year>
Reference-contexts: There are three conventional approaches to moving target detection: temporal differencing (two-frame or three-frame) [1], background subtraction [5, 10] and optical flow (see <ref> [2] </ref> for an excellent discussion). Temporal differencing is very adaptive to dynamic environments, but generally does a poor job of extracting all relevant feature pixels. Background subtraction provides the most complete feature data, but is extremely sensitive to dynamic scene changes due to lighting and extraneous events.
Reference: [3] <author> J. Davis, A. </author> <title> Bobick "The representation and recognition of human movement using temporal templates" Proceedings of IEEE CVPR 97, </title> <journal> pp. </journal> <volume> 928 - 934, </volume> <year> 1997 </year>
Reference: [4] <author> E. Grimson, P. </author> <title> Viola "A Forest of Sensors" DARPA - VSAM workshop, </title> <month> Nov. </month> <year> 1997 </year>
Reference-contexts: Unlike the models of both [5] and [10], this statistical model incorporates noise measurements to determine foreground pixels, rather than a simple threshold. This idea is inspired by <ref> [4] </ref>. If a pixel has a value which is more than 2 from p n , then it is considered a foreground pixel. At this point a multiple hypothesis approach is used for determining its behavior.
Reference: [5] <author> I. Haritaoglu, D. Harwood, L. S. </author> <title> Davis "W 4 Who? When? Where? What? A Real Time System for Detecting and Tracking People" FGR98 submitted, </title> <year> 1998 </year>
Reference-contexts: Human motion analysis is one such research area. There have been several good human detection schemes, such as [8] which use static imagery. But detecting and analyzing human motion in real time from video imagery has only recently become viable with algorithms like Pfinder [10] and W 4 <ref> [5] </ref>. These algorithms represent a good first step to the problem of recognizing and analyzing humans, but they still have some drawbacks. <p> There are three conventional approaches to moving target detection: temporal differencing (two-frame or three-frame) [1], background subtraction <ref> [5, 10] </ref> and optical flow (see [2] for an excellent discussion). Temporal differencing is very adaptive to dynamic environments, but generally does a poor job of extracting all relevant feature pixels. <p> Optical flow can be used to detect independently moving targets in the presence of camera motion, however most optical flow computation methods are very complex and are inapplicable to real-time algorithms without specialized hardware. The approach presented here is similar to that taken in <ref> [5] </ref> and is an attempt to make background subtraction more robust to environmental dynamism. The notion is to use an adaptive background model to accommodate changes to the background while maintaining the ability to detect independently moving targets. <p> The filter is imple mented: p n+1 = ffp n+1 + (1 ff)p n n+1 = ffjp n+1 p n+1 j + (1 ff) n (2) where ff = t fi f , and f is the frame rate. Unlike the models of both <ref> [5] </ref> and [10], this statistical model incorporates noise measurements to determine foreground pixels, rather than a simple threshold. This idea is inspired by [4]. If a pixel has a value which is more than 2 from p n , then it is considered a foreground pixel. <p> So the method can be scaled for different levels of target complexity. An interesting application of this scalability is the ability to measure the complexity of a target by examining the number of extremal points extracted as a function of smoothing. Other analysis techniques <ref> [10, 6, 5] </ref>, require a priori models of humans such as the cardboard model in order to analyze human activities. Using the skele-tonization approach, no such models are required, so the method can be applied to other objects like animals and vehicles (see Figure 4).
Reference: [6] <author> S. Ju, M. Black, Y. </author> <note> Yacoob "Cardboard People: </note>
Reference-contexts: In general, they work by detecting features (such as hands, feet and head), tracking them, and fitting them to some a priori human model such as the cardboard model of Ju et al <ref> [6] </ref>. There are two main drawbacks of these systems in their present forms: they are completely human specific, and they require a great deal of image-based information in order to work effectively. <p> So the method can be scaled for different levels of target complexity. An interesting application of this scalability is the ability to measure the complexity of a target by examining the number of extremal points extracted as a function of smoothing. Other analysis techniques <ref> [10, 6, 5] </ref>, require a priori models of humans such as the cardboard model in order to analyze human activities. Using the skele-tonization approach, no such models are required, so the method can be applied to other objects like animals and vehicles (see Figure 4).
References-found: 6

