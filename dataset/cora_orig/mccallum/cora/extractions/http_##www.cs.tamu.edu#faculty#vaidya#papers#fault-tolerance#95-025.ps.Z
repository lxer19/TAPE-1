URL: http://www.cs.tamu.edu/faculty/vaidya/papers/fault-tolerance/95-025.ps.Z
Refering-URL: http://www.cs.tamu.edu/faculty/vaidya/Vaidya-ftc.html
Root-URL: http://www.cs.tamu.edu
Title: Distributed Shared Memory: Recoverable and Non-recoverable Limited Update Protocols  
Author: Jai-Hoon Kim Nitin H. Vaidya 
Keyword: Index Terms: distributed shared memory, fault-tolerance, update protocol, release consistency.  
Address: College Station, TX 77843-3112  
Affiliation: Department of Computer Science Texas A&M University  
Pubnum: Technical Report 95-025  
Email: E-mail: jhkim@cs.tamu.edu  
Phone: Phone: (409) 847-8609 FAX: (409) 847-8578  
Date: May 1995  
Abstract: In the recent years, many protocols for implementing Distributed shared Memory (DSM) have been proposed. The implementations can be broadly divided into two classes: invalidation-based schemes and update-based schemes. Many approaches have also been proposed to make the DSM system recoverable from a failure. However, much of this work is restricted to reliable DSM based on invalidation. In this report, we propose a reliable DSM that uses a limited update protocol and the release consistency model. In this update protocol, multiple copies of each page may be maintained at different nodes. However, it is also possible for a page to exist in only one node, as some copies of the page may be invalidated. We propose an implementation that makes the limited update protocol recoverable from a single node failure, by guaranteeing that at least two copies of each page exist. The proposed recoverable DSM incorporates the release consistency model. The report presents preliminary evaluation of the recoverable DSM (using trace-driven simulation). It is shown that the overhead of making the DSM recoverable is small. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Archibald, </author> <title> "A cache coherence approach for large multiprocessor systems," </title> <booktitle> in International Conference on Supercomputing, </booktitle> <pages> pp. 337-345, </pages> <month> July </month> <year> 1988. </year>
Reference-contexts: This protocol is called the limited update protocol, and is based on a similar protocol for cache-coherence in hardware shared memory systems <ref> [1, 7] </ref>. The proposed reliable DSM can tolerate a single node failure without significant recovery overhead. Also, the proposed scheme incorporates the release consistency model. For future reference, note that we use the terms node and processor interchangeably. <p> This protocol is similar to two protocols previously proposed for maintaining sequential consistency in hardware caches <ref> [1, 7] </ref>. The advantage of this protocol is that it facilitates a simple implementation of a recoverable DSM. The basic idea of the limited protocol is to update those copies of a page that are expected to be used in the near future, while selectively invalidating other copies. <p> If no node performs consecutive L updates to the page, then at least two nodes must have a copy of the page (namely, the two most recent "updaters" of the page). Generalization of the Limited Update Protocol Unlike other similar schemes <ref> [1, 7] </ref>, implemented in hardware caches (with sequential consistency), the software implementation can be more flexible. Note that the limited update protocol is designed for the release consistency model, unlike [1, 7]. <p> Generalization of the Limited Update Protocol Unlike other similar schemes <ref> [1, 7] </ref>, implemented in hardware caches (with sequential consistency), the software implementation can be more flexible. Note that the limited update protocol is designed for the release consistency model, unlike [1, 7]. <p> The simulation results presented above suggest that the cost of the recoverable scheme is comparable or smaller than that of the non-recoverable scheme, for all values of the limit. 5 Related Work As discussed earlier, the limited update protocol is based on <ref> [1, 7] </ref>. As the focus of this report is on recoverable DSM, we now summarize the related work in this area. Many recoverable DSM schemes have been presented in the literature. Many of them use stable storage (disk) to save recovery data [22, 21, 18, 11, 10, 5].
Reference: [2] <author> M. Banatre, A. Ge*aut, and C. Morin, </author> <title> "Tolerating node failures in cache only memory architectures," </title> <type> Tech. Rep. 853, </type> <institution> INRIA, </institution> <year> 1994. </year>
Reference-contexts: Many recoverable DSM schemes have been presented in the literature. Many of them use stable storage (disk) to save recovery data [22, 21, 18, 11, 10, 5]. Some of them use main memory for checkpointing, replicating shared memory or logging the shared memory accesses <ref> [20, 2, 4, 15, 9, 13] </ref>. Proposed recoverable DSM belongs to the second category (uses main memory). [20], like proposed protocol, is based on update (full-replication) protocol, while [2, 4, 15, 9, 13] are based on invalidate (read-replication) protocol. <p> Some of them use main memory for checkpointing, replicating shared memory or logging the shared memory accesses [20, 2, 4, 15, 9, 13]. Proposed recoverable DSM belongs to the second category (uses main memory). [20], like proposed protocol, is based on update (full-replication) protocol, while <ref> [2, 4, 15, 9, 13] </ref> are based on invalidate (read-replication) protocol. Stumm and Zhou extended four basic DSM algorithms to tolerate single node failures [20]. One of their algorithms is for an update protocol. <p> Additionally, our scheme supports release consistency. Backward error recovery on a Cache Only Memory Architecture is implemented using the standard memories by Banatre et al. <ref> [2] </ref>. (A similar scheme was implemented on an Intel Paragon by Kermarrec et al. [13].) This scheme periodically take system-wide consistent checkpoints. <p> Our scheme also maintains at least two copies of a page, however, the scheme is based on an update protocol, unlike [4]. Additionally, our protocol incorporates the release consistency model, unlike the sequential consistency model used in [4] as well as <ref> [2, 13] </ref> Neves et al. presented a checkpoint protocol for a multi-threaded distributed shared memory system based on the entry consistency memory model [15]. Their algorithm needs to maintain log of shared data accesses in the volatile memory. These logs are used to reconstruct failed processes from the last checkpoint.
Reference: [3] <author> E. Brewer and C. Dellarocas, Proteus User Documentation, </author> <year> 1992. </year>
Reference-contexts: We used trace-driven simulation method for the experiments. As a preliminary test, we generated synthetic trace data by using a trace generator. The trace generator can produce trace data according to the memory access behavior which we can define as input. We also modified the Proteus <ref> [3] </ref> to produce trace data for shared memory operations, acquire, release, read, and write.
Reference: [4] <author> L. Brown and J. Wu, </author> <title> "Dynamic snooping in a fault-tolerant distributed shared memory," </title> <booktitle> in Symposium on Distributed Computing Systems, </booktitle> <pages> pp. 218-226, </pages> <year> 1994. </year>
Reference-contexts: Many recoverable DSM schemes have been presented in the literature. Many of them use stable storage (disk) to save recovery data [22, 21, 18, 11, 10, 5]. Some of them use main memory for checkpointing, replicating shared memory or logging the shared memory accesses <ref> [20, 2, 4, 15, 9, 13] </ref>. Proposed recoverable DSM belongs to the second category (uses main memory). [20], like proposed protocol, is based on update (full-replication) protocol, while [2, 4, 15, 9, 13] are based on invalidate (read-replication) protocol. <p> Some of them use main memory for checkpointing, replicating shared memory or logging the shared memory accesses [20, 2, 4, 15, 9, 13]. Proposed recoverable DSM belongs to the second category (uses main memory). [20], like proposed protocol, is based on update (full-replication) protocol, while <ref> [2, 4, 15, 9, 13] </ref> are based on invalidate (read-replication) protocol. Stumm and Zhou extended four basic DSM algorithms to tolerate single node failures [20]. One of their algorithms is for an update protocol. <p> After a node fails, all nodes need to rollback to the last checkpoint. Brown and Wu presented recoverable DSM, based on an invalidate protocol, that can tolerate single point failure <ref> [4] </ref>. A dynamic snooper keeps a backup copy of each page and takes over if the page owner fails. The snooper keeps track of the page contents, location of page replicas, and the identity of the page owner. The snooper can respond on behalf of a failed owner. <p> The snooper can respond on behalf of a failed owner. Our scheme also maintains at least two copies of a page, however, the scheme is based on an update protocol, unlike <ref> [4] </ref>. Additionally, our protocol incorporates the release consistency model, unlike the sequential consistency model used in [4] as well as [2, 13] Neves et al. presented a checkpoint protocol for a multi-threaded distributed shared memory system based on the entry consistency memory model [15]. <p> The snooper can respond on behalf of a failed owner. Our scheme also maintains at least two copies of a page, however, the scheme is based on an update protocol, unlike <ref> [4] </ref>. Additionally, our protocol incorporates the release consistency model, unlike the sequential consistency model used in [4] as well as [2, 13] Neves et al. presented a checkpoint protocol for a multi-threaded distributed shared memory system based on the entry consistency memory model [15]. Their algorithm needs to maintain log of shared data accesses in the volatile memory.
Reference: [5] <author> G. Cabillic, G. Muller, and I. Puaut, </author> <title> "The performance of consistent checkpointing in distributed shared memory systems," </title> <type> Tech. Rep. 924, </type> <institution> INRIA, </institution> <year> 1995. </year>
Reference-contexts: As the focus of this report is on recoverable DSM, we now summarize the related work in this area. Many recoverable DSM schemes have been presented in the literature. Many of them use stable storage (disk) to save recovery data <ref> [22, 21, 18, 11, 10, 5] </ref>. Some of them use main memory for checkpointing, replicating shared memory or logging the shared memory accesses [20, 2, 4, 15, 9, 13].
Reference: [6] <author> J. B. Carter, </author> <title> Efficient Distributed Shared Memory Based On Multi-Protocol Release Consistency. </title> <type> PhD thesis, </type> <institution> Rice University, </institution> <month> Sept. </month> <year> 1993. </year>
Reference-contexts: Many applications programmed for a multiprocessor system with shared memory can be executed in DSM without significant modifications. Many approaches have been proposed to implement distributed shared memory <ref> [6, 8, 14, 19] </ref>. The DSM implementations are based on write-invalidation and/or write-update. In the past, write-update protocols were often inefficient due to the overhead of updating multiple copies of a page. However, the recent implementations of DSM use relaxed memory consistency models such as release consistency [6]. <p> The DSM implementations are based on write-invalidation and/or write-update. In the past, write-update protocols were often inefficient due to the overhead of updating multiple copies of a page. However, the recent implementations of DSM use relaxed memory consistency models such as release consistency <ref> [6] </ref>. For such implementations, write-update protocols are often superior than write-invalidate protocols. A simple implementation of a write-update protocol is likely to be inefficient, as many copies of a page may be updated, even if some of them are not going to be accessed in the future. <p> Release Consistency Here we present only a brief overview of release consistency, as necessary to describe the proposed reliable DSM scheme. The release consistency protocol is based on the observation that, in a typical program, accesses to shared variables are separated by synchronization operations in release consistency <ref> [6] </ref>, these operations are termed acquire and release. If an access by a process to some shared data is likely to cause a race condition, then the process first performs an acquire operation. When the process has completed its accesses to the shared data, it performs a release operation. <p> It is conceivable that some node A may access a page infrequently in this case, it is advantageous to invalidate the page's copy at node A (as compared to updating it whenever some other node modifies it). Carter et al. <ref> [6] </ref> suggest a time-out protocol to determine when a page copy should be invalidated essentially, the local copy of a page at node A is invalidated if it is not accessed by node A for a significant duration of time. <p> The basic idea of the limited protocol is to update those copies of a page that are expected to be used in the near future, while selectively invalidating other copies. Now we summarize the limited update protocol. Information Structure We assume an implementation that is similar to Munin <ref> [6] </ref>, with a few modifications to facilitate limited updates. Each node maintains an information structure for each page resident in its memory. <p> The copyset at different nodes, that have a copy of the same page, may be different. In general, a node may not know exactly which other nodes have a copy of the page <ref> [6] </ref>. However, when a node performs an update (when it does a release ), at the end of the update protocol, that node knows precisely the set of nodes, that hold the copies of the page, that were updated. <p> It is a simple matter to modify the update protocol to obtain the value of the update-counter for the modified page, from each node that received the update. This observation will be used in the recoverable DSM. * probOwner: Points towards the "owner" of the page <ref> [6] </ref>. 3 * back-up: To be explained later. Note that each node maintains the above structure for each page in its local memory. <p> Thus, the limited update protocol invalidates those pages that are accessed "less frequently" - the protocol can be tuned to a given application by a proper choice of limit L. As discussed later, the limit can also be changed dynamically. Update-counter is analogous to timeout mechanism in Munin <ref> [6] </ref>. Our scheme bounds the update overhead by using a limit L on the number of updates without an intervening local access, while timeout approach uses the freeze time mechanism. <p> Note that the limited update protocol is designed for the release consistency model, unlike [1, 7]. The above protocol can be generalized in four ways, as summarized below: * Multiple Consistency Protocol: Multiple consistency protocol was presented by Carter <ref> [6] </ref>, which can perform efficiently by using the appropriate protocol for each data object of different access pattern, The generalized limited update approach can provide a different protocol for each page by adjusting the limit parameter independently for each page. <p> However, TOP-1 needs additional hardware design, cache mode register (to specify a cache mode: update mode and invalidate mode) and CH (Cache Hit) bus line (to indicate a snoop hit). Hybrid protocol is also implemented in Munin <ref> [6] </ref> by using the timeout mechanism. When a node writes and its update is propagated to other nodes, default copies are updated, while some copies are self-invalidated if the copies are not locally accessed for more than the freeze time since the last update. <p> We assume that the DSM system consists of 16 nodes, and that the page size is 1024 bytes. For the simulation, we assume an implementation similar to Munin, i.e., based on the dynamic distributed ownership mechanism <ref> [6] </ref>. Cost Measurement On a page fault, the number of messages required varies because of the dynamic distributed ownership mechanism.
Reference: [7] <author> F. Dahlgren, M. Dubois, and P. Stenstrom, </author> <title> "Combined performance gains of simple cache protocol extentions," </title> <booktitle> in Proceedings of the 21st Annual International Symposium on Computer Architecture, </booktitle> <pages> pp. 187-197, </pages> <month> Apr. </month> <year> 1994. </year>
Reference-contexts: This protocol is called the limited update protocol, and is based on a similar protocol for cache-coherence in hardware shared memory systems <ref> [1, 7] </ref>. The proposed reliable DSM can tolerate a single node failure without significant recovery overhead. Also, the proposed scheme incorporates the release consistency model. For future reference, note that we use the terms node and processor interchangeably. <p> This protocol is similar to two protocols previously proposed for maintaining sequential consistency in hardware caches <ref> [1, 7] </ref>. The advantage of this protocol is that it facilitates a simple implementation of a recoverable DSM. The basic idea of the limited protocol is to update those copies of a page that are expected to be used in the near future, while selectively invalidating other copies. <p> If no node performs consecutive L updates to the page, then at least two nodes must have a copy of the page (namely, the two most recent "updaters" of the page). Generalization of the Limited Update Protocol Unlike other similar schemes <ref> [1, 7] </ref>, implemented in hardware caches (with sequential consistency), the software implementation can be more flexible. Note that the limited update protocol is designed for the release consistency model, unlike [1, 7]. <p> Generalization of the Limited Update Protocol Unlike other similar schemes <ref> [1, 7] </ref>, implemented in hardware caches (with sequential consistency), the software implementation can be more flexible. Note that the limited update protocol is designed for the release consistency model, unlike [1, 7]. <p> The simulation results presented above suggest that the cost of the recoverable scheme is comparable or smaller than that of the non-recoverable scheme, for all values of the limit. 5 Related Work As discussed earlier, the limited update protocol is based on <ref> [1, 7] </ref>. As the focus of this report is on recoverable DSM, we now summarize the related work in this area. Many recoverable DSM schemes have been presented in the literature. Many of them use stable storage (disk) to save recovery data [22, 21, 18, 11, 10, 5].
Reference: [8] <author> S. Eggers and R. Katz, </author> <title> "A characterization of sharing in parallel prograns and its application to coherency protocol evaluation," </title> <booktitle> in Proceedings of the 15th Annual International Symposium on Computer Architecture, </booktitle> <pages> pp. 373-382, </pages> <month> May </month> <year> 1988. </year>
Reference-contexts: Many applications programmed for a multiprocessor system with shared memory can be executed in DSM without significant modifications. Many approaches have been proposed to implement distributed shared memory <ref> [6, 8, 14, 19] </ref>. The DSM implementations are based on write-invalidation and/or write-update. In the past, write-update protocols were often inefficient due to the overhead of updating multiple copies of a page. However, the recent implementations of DSM use relaxed memory consistency models such as release consistency [6].
Reference: [9] <author> T. Fuchi and M. Tokoro, </author> <title> "A mechanism for recoverable shared virtual memory," </title> <year> 1994. </year>
Reference-contexts: Many recoverable DSM schemes have been presented in the literature. Many of them use stable storage (disk) to save recovery data [22, 21, 18, 11, 10, 5]. Some of them use main memory for checkpointing, replicating shared memory or logging the shared memory accesses <ref> [20, 2, 4, 15, 9, 13] </ref>. Proposed recoverable DSM belongs to the second category (uses main memory). [20], like proposed protocol, is based on update (full-replication) protocol, while [2, 4, 15, 9, 13] are based on invalidate (read-replication) protocol. <p> Some of them use main memory for checkpointing, replicating shared memory or logging the shared memory accesses [20, 2, 4, 15, 9, 13]. Proposed recoverable DSM belongs to the second category (uses main memory). [20], like proposed protocol, is based on update (full-replication) protocol, while <ref> [2, 4, 15, 9, 13] </ref> are based on invalidate (read-replication) protocol. Stumm and Zhou extended four basic DSM algorithms to tolerate single node failures [20]. One of their algorithms is for an update protocol. <p> Their algorithm needs to maintain log of shared data accesses in the volatile memory. These logs are used to reconstruct failed processes from the last checkpoint. Fuchi and Tokoro proposed a mechanism for recoverable shared virtual memory <ref> [9] </ref>. Their scheme maintains backup process for every primary process. When the primary process sends/receives a message to/from another process (or writes/reads a shared memory), the primary process sends this information to backup process so that the backup process can log the events of the primary process.
Reference: [10] <author> G. Janakiraman and Y. Tamir, </author> <title> "Coordinated checkpointing-rollback error recovery for distributed shared memory multicomputer," </title> <booktitle> in 13th Symposium on Reliable Distributed Systems, </booktitle> <month> Oct. </month> <year> 1994. </year>
Reference-contexts: As the focus of this report is on recoverable DSM, we now summarize the related work in this area. Many recoverable DSM schemes have been presented in the literature. Many of them use stable storage (disk) to save recovery data <ref> [22, 21, 18, 11, 10, 5] </ref>. Some of them use main memory for checkpointing, replicating shared memory or logging the shared memory accesses [20, 2, 4, 15, 9, 13].
Reference: [11] <author> B. Janssens and W. K. Fuchs, </author> <title> "Relaxing consistency in recoverable distributed shared memory," </title> <booktitle> in Proc. 23rd Int. Symp. on Fault-Tolerant Computing, </booktitle> <pages> pp. 155-163, </pages> <year> 1993. </year> <month> 23 </month>
Reference-contexts: As the focus of this report is on recoverable DSM, we now summarize the related work in this area. Many recoverable DSM schemes have been presented in the literature. Many of them use stable storage (disk) to save recovery data <ref> [22, 21, 18, 11, 10, 5] </ref>. Some of them use main memory for checkpointing, replicating shared memory or logging the shared memory accesses [20, 2, 4, 15, 9, 13]. <p> Above two scheme are similar to our scheme in the sense that they use volatile memory and provide recoverability from a single point of failure. However, they recover processes by a "replay" mechanism, whereas in our scheme no replay is necessary. Janssens and Fuchs <ref> [11] </ref> present a recoverable DSM that uses relaxed consistency models. However, their approach is based on checkpointing, and results in a large number of checkpoints.
Reference: [12] <author> P. Keleher, A. L. Cox, and W. Zwaenepoel, </author> <title> "Lazy release consistency for software distributed shared memory," </title> <booktitle> in Proceedings of the 19th Annual International Symposium on Computer Architecture, </booktitle> <pages> pp. 13-21, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: We assume that an acquire and release are implemented as special procedures using a message passing library an acquire is assumed to require three messages, similar to <ref> [12] </ref>. On a release, two messages are required per copy of the modified pages one for sending a request and the other for acknowledgment. Some application programs traced using Proteus use semaphores to achieve synchronization we appropriately interpreted these as acquires and releases.
Reference: [13] <author> A.-M. Kermarrec, G. Cabillic, A. Ge*aut, C. Morin, and I. Puaut, </author> <title> "A recoverable distributed shared memory integrating coherence and recoverability," </title> <type> Tech. Rep. 897, </type> <institution> INRIA, </institution> <year> 1995. </year>
Reference-contexts: Many recoverable DSM schemes have been presented in the literature. Many of them use stable storage (disk) to save recovery data [22, 21, 18, 11, 10, 5]. Some of them use main memory for checkpointing, replicating shared memory or logging the shared memory accesses <ref> [20, 2, 4, 15, 9, 13] </ref>. Proposed recoverable DSM belongs to the second category (uses main memory). [20], like proposed protocol, is based on update (full-replication) protocol, while [2, 4, 15, 9, 13] are based on invalidate (read-replication) protocol. <p> Some of them use main memory for checkpointing, replicating shared memory or logging the shared memory accesses [20, 2, 4, 15, 9, 13]. Proposed recoverable DSM belongs to the second category (uses main memory). [20], like proposed protocol, is based on update (full-replication) protocol, while <ref> [2, 4, 15, 9, 13] </ref> are based on invalidate (read-replication) protocol. Stumm and Zhou extended four basic DSM algorithms to tolerate single node failures [20]. One of their algorithms is for an update protocol. <p> Additionally, our scheme supports release consistency. Backward error recovery on a Cache Only Memory Architecture is implemented using the standard memories by Banatre et al. [2]. (A similar scheme was implemented on an Intel Paragon by Kermarrec et al. <ref> [13] </ref>.) This scheme periodically take system-wide consistent checkpoints. Recovery data are replicated and mixed with current data in node memories in a transparent way using an extended 17 18 19 20 21 coherence protocol based on invalidate protocol. <p> Our scheme also maintains at least two copies of a page, however, the scheme is based on an update protocol, unlike [4]. Additionally, our protocol incorporates the release consistency model, unlike the sequential consistency model used in [4] as well as <ref> [2, 13] </ref> Neves et al. presented a checkpoint protocol for a multi-threaded distributed shared memory system based on the entry consistency memory model [15]. Their algorithm needs to maintain log of shared data accesses in the volatile memory. These logs are used to reconstruct failed processes from the last checkpoint.
Reference: [14] <author> K. Li and P. Hudak, </author> <title> "Memory coherence in shared virtual memory systems," </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> vol. 7, </volume> <pages> pp. 321-359, </pages> <month> Nov. </month> <year> 1989. </year>
Reference-contexts: Many applications programmed for a multiprocessor system with shared memory can be executed in DSM without significant modifications. Many approaches have been proposed to implement distributed shared memory <ref> [6, 8, 14, 19] </ref>. The DSM implementations are based on write-invalidation and/or write-update. In the past, write-update protocols were often inefficient due to the overhead of updating multiple copies of a page. However, the recent implementations of DSM use relaxed memory consistency models such as release consistency [6].
Reference: [15] <author> N. Neves, M. Castro, and P. Guedes, </author> <title> "A checkpoint protocol for an entry consistent shared memory system," </title> <booktitle> in Symposium on Principles of Distributed Computing, </booktitle> <pages> pp. 121-129, </pages> <month> Aug. </month> <year> 1994. </year>
Reference-contexts: Many recoverable DSM schemes have been presented in the literature. Many of them use stable storage (disk) to save recovery data [22, 21, 18, 11, 10, 5]. Some of them use main memory for checkpointing, replicating shared memory or logging the shared memory accesses <ref> [20, 2, 4, 15, 9, 13] </ref>. Proposed recoverable DSM belongs to the second category (uses main memory). [20], like proposed protocol, is based on update (full-replication) protocol, while [2, 4, 15, 9, 13] are based on invalidate (read-replication) protocol. <p> Some of them use main memory for checkpointing, replicating shared memory or logging the shared memory accesses [20, 2, 4, 15, 9, 13]. Proposed recoverable DSM belongs to the second category (uses main memory). [20], like proposed protocol, is based on update (full-replication) protocol, while <ref> [2, 4, 15, 9, 13] </ref> are based on invalidate (read-replication) protocol. Stumm and Zhou extended four basic DSM algorithms to tolerate single node failures [20]. One of their algorithms is for an update protocol. <p> Additionally, our protocol incorporates the release consistency model, unlike the sequential consistency model used in [4] as well as [2, 13] Neves et al. presented a checkpoint protocol for a multi-threaded distributed shared memory system based on the entry consistency memory model <ref> [15] </ref>. Their algorithm needs to maintain log of shared data accesses in the volatile memory. These logs are used to reconstruct failed processes from the last checkpoint. Fuchi and Tokoro proposed a mechanism for recoverable shared virtual memory [9]. Their scheme maintains backup process for every primary process.
Reference: [16] <author> B. Nitzberg and V. Lo, </author> <title> "Distributed shared memory: A survey of issues and algorithms," </title> <journal> IEEE Computer, </journal> <volume> vol. 24, </volume> <pages> pp. 52-60, </pages> <month> Aug. </month> <year> 1991. </year>
Reference-contexts: 1 Introduction Distributed shared memory (DSM) systems have many advantages over message passing systems <ref> [19, 16] </ref>. Since DSM provides a user a simple shared memory abstraction, the user does not have to be concerned with data movement between hosts. Many applications programmed for a multiprocessor system with shared memory can be executed in DSM without significant modifications.
Reference: [17] <author> N. Oba, A. Moriwaki, and S. Shimizu, "Top-1: </author> <title> A snoop-cache-based multiprocessor," </title> <booktitle> in Proc. 1990 International Phoenix Conference on Computers and Communication, </booktitle> <pages> pp. 101-108, </pages> <month> Oct. </month> <year> 1990. </year>
Reference-contexts: TOP-1 <ref> [17] </ref>, a tightly coupled snoop-cache-based multiprocessor, has a hybrid coherence protocol which allows an update protocol and an invalidate protocol, which can be dynamically changed, to coexist simultaneously.
Reference: [18] <author> G. Richard and M. Singhal, </author> <title> "Using logging and asynchronous checkpointing to implement recoverable distributed shared memory," </title> <booktitle> in 12th Symposium on Reliable Distributed Systems, </booktitle> <year> 1993. </year>
Reference-contexts: As the focus of this report is on recoverable DSM, we now summarize the related work in this area. Many recoverable DSM schemes have been presented in the literature. Many of them use stable storage (disk) to save recovery data <ref> [22, 21, 18, 11, 10, 5] </ref>. Some of them use main memory for checkpointing, replicating shared memory or logging the shared memory accesses [20, 2, 4, 15, 9, 13].
Reference: [19] <author> M. Stumm and S. Zhou, </author> <title> "Algorithms implementing distributed shared memory," </title> <booktitle> IEEE Computer, </booktitle> <pages> pp. 54-64, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: 1 Introduction Distributed shared memory (DSM) systems have many advantages over message passing systems <ref> [19, 16] </ref>. Since DSM provides a user a simple shared memory abstraction, the user does not have to be concerned with data movement between hosts. Many applications programmed for a multiprocessor system with shared memory can be executed in DSM without significant modifications. <p> Many applications programmed for a multiprocessor system with shared memory can be executed in DSM without significant modifications. Many approaches have been proposed to implement distributed shared memory <ref> [6, 8, 14, 19] </ref>. The DSM implementations are based on write-invalidation and/or write-update. In the past, write-update protocols were often inefficient due to the overhead of updating multiple copies of a page. However, the recent implementations of DSM use relaxed memory consistency models such as release consistency [6].
Reference: [20] <author> M. Stumm and S. Zhou, </author> <title> "Fault tolerant distributed shared memory algorithms," </title> <booktitle> in Proceedings of International Conference on Parallel and Distributed Processing, </booktitle> <pages> pp. 719-724, </pages> <year> 1990. </year>
Reference-contexts: The copy with the largest version number is the most up-to-date copy (this is similar to <ref> [20] </ref>). If a node fails after it has written to a page, but before it has performed a release, then the modifications made by the node are lost when the node fails. <p> Many recoverable DSM schemes have been presented in the literature. Many of them use stable storage (disk) to save recovery data [22, 21, 18, 11, 10, 5]. Some of them use main memory for checkpointing, replicating shared memory or logging the shared memory accesses <ref> [20, 2, 4, 15, 9, 13] </ref>. Proposed recoverable DSM belongs to the second category (uses main memory). [20], like proposed protocol, is based on update (full-replication) protocol, while [2, 4, 15, 9, 13] are based on invalidate (read-replication) protocol. <p> Some of them use main memory for checkpointing, replicating shared memory or logging the shared memory accesses [20, 2, 4, 15, 9, 13]. Proposed recoverable DSM belongs to the second category (uses main memory). <ref> [20] </ref>, like proposed protocol, is based on update (full-replication) protocol, while [2, 4, 15, 9, 13] are based on invalidate (read-replication) protocol. Stumm and Zhou extended four basic DSM algorithms to tolerate single node failures [20]. One of their algorithms is for an update protocol. <p> Proposed recoverable DSM belongs to the second category (uses main memory). <ref> [20] </ref>, like proposed protocol, is based on update (full-replication) protocol, while [2, 4, 15, 9, 13] are based on invalidate (read-replication) protocol. Stumm and Zhou extended four basic DSM algorithms to tolerate single node failures [20]. One of their algorithms is for an update protocol. But, implementations of our algorithm is different because their algorithm is based on update protocol where all copies of a page are updated, whereas our scheme is based on "limited" update protocol (some copies are invalidated to reduce overhead).
Reference: [21] <author> V.-O. Tam and M. Hsu, </author> <title> "Fast recovery in distributed shared virtual memory systems," </title> <booktitle> in Symposium on Distributed Computing Systems, </booktitle> <pages> pp. 38-45, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: As the focus of this report is on recoverable DSM, we now summarize the related work in this area. Many recoverable DSM schemes have been presented in the literature. Many of them use stable storage (disk) to save recovery data <ref> [22, 21, 18, 11, 10, 5] </ref>. Some of them use main memory for checkpointing, replicating shared memory or logging the shared memory accesses [20, 2, 4, 15, 9, 13].
Reference: [22] <author> K.-L. Wu and W. K. Fuchs, </author> <title> "Recoverable distributed shared virtual memory: Memory coherence and storage structures," </title> <booktitle> in Proc. 19th Int. Symp. on Fault-Tolerant Computing, </booktitle> <pages> pp. 520-527, </pages> <year> 1989. </year> <month> 24 </month>
Reference-contexts: As the focus of this report is on recoverable DSM, we now summarize the related work in this area. Many recoverable DSM schemes have been presented in the literature. Many of them use stable storage (disk) to save recovery data <ref> [22, 21, 18, 11, 10, 5] </ref>. Some of them use main memory for checkpointing, replicating shared memory or logging the shared memory accesses [20, 2, 4, 15, 9, 13].
References-found: 22

