URL: http://www.research.microsoft.com/~dbwilson/exact/user.ps
Refering-URL: http://www.research.microsoft.com/~dbwilson/
Root-URL: http://www.research.microsoft.com
Title: Contemporary Mathematics Coupling from the Past: a User's Guide  
Author: James Propp and David Wilson 
Abstract: The Markov chain Monte Carlo method is a general technique for obtaining samples from a probability distribution. In earlier work, we showed that for many applications one can modify the Markov chain Monte Carlo method so as to remove all bias in the output resulting from the biased choice of an initial state for the chain; we have called this method Coupling From The Past (CFTP). Here we describe this method in a fashion that should make our ideas accessible to researchers from diverse areas. Our expository strategy is to avoid proofs and focus on sample applications. 
Abstract-found: 1
Intro-found: 1
Reference: [A1] <author> D. Aldous, </author> <title> A random walk construction of uniform spanning trees and uniform labelled trees, </title> <note> SIAM Journal on Discrete Mathematics 3 (1990), 450-465. </note>
Reference-contexts: In the first case, the CFTP algorithm is effectively equivalent to the random walk method of Aldous <ref> [A1] </ref> and Broder [B]; in the second case, the CFTP algorithm is effectively equivalent to the random walk method of Kandel, Matias, Unger, and Winkler [KMUW]. Finally, we stress that CFTP is only one of many schemes for generating random spanning arborescences; see [PW2] for others. 6.
Reference: [A2] <author> D. Aldous, </author> <title> On simulating a Markov chain stationary distribution when transition probabilities are unknown, </title> <editor> in: D. Aldous, P. Diaconis, J. Spencer, and J. M. Steele, editors, </editor> <booktitle> "Discrete Probability and Algorithms", volume 72 of IMA Volumes in Mathematics and its Applications, </booktitle> <pages> 1-9, </pages> <publisher> Springer-Verlag 1995. </publisher>
Reference-contexts: It might seem that, under this stipulation, no solution to the problem is possible, but in fact a solution was found by Asmussen, Glynn, and Thorisson [AGT]. However, their algorithm was not very efficient. Subsequently Aldous <ref> [A2] </ref> and Lovasz and Winkler [LW] found faster procedures (although the algorithm of Al-dous involves controlled but non-zero error). The CFTP-based solution given below is even faster than that of Lovasz and Winkler.
Reference: [AGT] <author> S. Asmussen, P. Glynn, and H. Thorisson, </author> <title> Stationary detection in the initial transient problem, </title> <booktitle> ACM Transactions on Modeling and Computer Simulation 2 (1992), </booktitle> <pages> 130-157. </pages>
Reference-contexts: It might seem that, under this stipulation, no solution to the problem is possible, but in fact a solution was found by Asmussen, Glynn, and Thorisson <ref> [AGT] </ref>. However, their algorithm was not very efficient. Subsequently Aldous [A2] and Lovasz and Winkler [LW] found faster procedures (although the algorithm of Al-dous involves controlled but non-zero error). The CFTP-based solution given below is even faster than that of Lovasz and Winkler.
Reference: [AT] <author> V. Anantharam and P. Tsoucas, </author> <title> A proof of the Markov chain tree theorem, </title> <journal> Statistics and Probability Letters 8 (1989), </journal> <pages> 189-192. </pages>
Reference-contexts: It is well known that is the unique stationary probability measure for this Markov chain on the set of arborescences of G. (This bit of folklore was first published by Anantharam and Tsoucas <ref> [AT] </ref>.) If two arborescences have the same root, there is an obvious way to simulate their future jointly, by having the root take the same random walk in G. This coupling has the property that the two arborescences will continue to have the same root.
Reference: [BF] <author> A. A. Borovkov and S. G. Foss, </author> <title> Stochastically recursive sequences and their generalizations, </title> <booktitle> Siberian Advances in Mathematics 2 (1992), </booktitle> <pages> 16-81. </pages>
Reference-contexts: As an historical aside, we mention that the conceptual ingredients of CFTP were in the air even before the versatility of the method was made clear in [PW1]. Precursors include Letac [Le], Thorisson [T], and Borovkov and Foss <ref> [BF] </ref>. Even back in the 1970's, one can find foreshadowings in the work of Ted Harris (on the contact process, the exclusion model, random stirrings, and coalescing and annihilating random walks), David Griffeath (on additive and cancellative interacting particle systems), and Richard Arratia (on coalescing Brownian motion).
Reference: [B] <author> A. Broder, </author> <title> Generating random spanning trees, </title> <booktitle> in: "30th Annual Symposium on Foundations of Computer Science" (1989), </booktitle> <pages> 442-447. </pages>
Reference-contexts: In the first case, the CFTP algorithm is effectively equivalent to the random walk method of Aldous [A1] and Broder <ref> [B] </ref>; in the second case, the CFTP algorithm is effectively equivalent to the random walk method of Kandel, Matias, Unger, and Winkler [KMUW]. Finally, we stress that CFTP is only one of many schemes for generating random spanning arborescences; see [PW2] for others. 6.
Reference: [D] <author> P. Diaconis, </author> <title> Backwards composition of random maps, survey article in preparation. </title>
Reference-contexts: For an interesting attempt to embed CFTP in a general probabilistic framework, see the article by Foss and Tweedie [FT]. For a discussion of the many uses of the notion of backwards composition of random maps, see the forthcoming survey 4 JAMES PROPP AND DAVID WILSON article by Diaconis <ref> [D] </ref>. For an on-line bibliography on perfect random sampling using Markov chains, see http://dimacs.rutgers.edu/~dbwilson/exact.html. 3. The hard-core model The states of this model are given by subsets of the vertex-set of a finite graph G, or equivalently, by 0; 1-valued functions on the vertex-set.
Reference: [F] <author> J. A. Fill, </author> <title> An interruptible algorithm for perfect sampling via Markov chains, </title> <note> preprint (1997); to appear in Annals of Applied Probability. </note>
Reference-contexts: For a significant step in this direction, see the article of Fill <ref> [F] </ref>. Another way to address the problem of bias caused by user impatience is given by work of Glynn and Heidelberger [GH].
Reference: [FT] <author> S. G. Foss and R. L. Tweedie, </author> <title> Perfect simulation and backward coupling, to appear in Stochastic Models. </title>
Reference-contexts: However, in this article we will focus on situations in which this simple state of affairs does not prevail. For an interesting attempt to embed CFTP in a general probabilistic framework, see the article by Foss and Tweedie <ref> [FT] </ref>. For a discussion of the many uses of the notion of backwards composition of random maps, see the forthcoming survey 4 JAMES PROPP AND DAVID WILSON article by Diaconis [D]. For an on-line bibliography on perfect random sampling using Markov chains, see http://dimacs.rutgers.edu/~dbwilson/exact.html. 3.
Reference: [GH] <author> P. W. Glynn and P. Heidelberger, </author> <title> Bias properties of budget constrained simulations, </title> <booktitle> Operations Research 38 (1990), </booktitle> <pages> 801-814. </pages>
Reference-contexts: For a significant step in this direction, see the article of Fill [F]. Another way to address the problem of bias caused by user impatience is given by work of Glynn and Heidelberger <ref> [GH] </ref>.
Reference: [HLM] <author> O. Haggstrom, M. N. M. Van Lieshout, and J. Mtller, </author> <title> Characterisation results and Markov chain Monte Carlo algorithms including exact simulation for some spatial point processes, </title> <type> Technical Report R-96-2040, </type> <institution> Aalborg University (1996). </institution>
Reference-contexts: This approach of Kendall was further developed by Haggstrom and Nelander [HN]. Also, Haggstrom, Van Lieshout, and Mtller <ref> [HLM] </ref> have proposed an algorithm for the special case of penetrable spheres that is simpler than Kendall's and works faster, though it is not as amenable to generalization. It should also be mentioned that CFTP may have theoretical as well as practical significance for such models.
Reference: [HN] <author> O. Haggstrom and K. Nelander, </author> <title> Exact sampling from anti-monotone systems, </title> <note> preprint (1997). </note>
Reference-contexts: It should be mentioned that Haggstrom and Nelander <ref> [HN] </ref> have another approach to the hard-core model, in which only one vertex at a time needs to be modified, and that their approach makes use of the very interesting notion of anti-monotone CFTP which has its roots in the work of Kendall on repulsive point-processes. <p> This approach of Kendall was further developed by Haggstrom and Nelander <ref> [HN] </ref>. Also, Haggstrom, Van Lieshout, and Mtller [HLM] have proposed an algorithm for the special case of penetrable spheres that is simpler than Kendall's and works faster, though it is not as amenable to generalization.
Reference: [KMUW] <author> D. Kandel, Y. Matias, R. Unger, and P. Winkler, </author> <title> Shu*ing biological sequences, </title> <booktitle> Discrete Applied Mathematics 71 (1996), </booktitle> <pages> 171-185. </pages>
Reference-contexts: In the first case, the CFTP algorithm is effectively equivalent to the random walk method of Aldous [A1] and Broder [B]; in the second case, the CFTP algorithm is effectively equivalent to the random walk method of Kandel, Matias, Unger, and Winkler <ref> [KMUW] </ref>. Finally, we stress that CFTP is only one of many schemes for generating random spanning arborescences; see [PW2] for others. 6.
Reference: [K] <author> W. S. Kendall, </author> <title> Perfect simulation for the area-interaction point process, </title> <note> to appear in Probability Perspective. </note>
Reference-contexts: To paraphrase Wilfrid Kendall, one of the first to jump into the fray: "We must now be more ambitious about our simulation objectives. We can no longer be content merely with long-run approximations to equilibrium distributions but instead must strive after perfection" <ref> [K] </ref>. Coupling from the past (hereafter CFTP) is based on what Kendall calls stochastic flows (in discrete or continuous time). We restrict attention for now to the discrete-time, finite-state version. <p> However, there is a kind of monotonicity in the model, and Kendall <ref> [K] </ref> figured out a way to exploit this. (Strictly speaking, the system is monotonic in the attractive case and anti-monotonic in the repulsive case; for now, we focus on the attractive case.) Kendall effectively constructs a continuous-time stochastic flow.
Reference: [KSW] <author> J. H. Kim, P. Shor, and P. Winkler, </author> <title> Random independent sets, </title> <note> article in preparation. </note>
Reference-contexts: There are many situations in which this is the case for non-obvious reasons, e.g., the hardcore model on a bipartite graph <ref> [KSW] </ref>. However, in this article we will focus on situations in which this simple state of affairs does not prevail. For an interesting attempt to embed CFTP in a general probabilistic framework, see the article by Foss and Tweedie [FT].
Reference: [Le] <author> G. Letac, </author> <title> A contraction principle for certain Markov chains and its applications, </title> <booktitle> Contemporary Mathematics 50 (1986), </booktitle> <pages> 263-273. </pages>
Reference-contexts: As an historical aside, we mention that the conceptual ingredients of CFTP were in the air even before the versatility of the method was made clear in [PW1]. Precursors include Letac <ref> [Le] </ref>, Thorisson [T], and Borovkov and Foss [BF].
Reference: [LW] <author> L. Lovasz and P. Winkler, </author> <title> Exact mixing in an unknown Markov chain, </title> <journal> Electronic Journal of Combinatorics 2 (1995), </journal> <note> paper #R15. </note>
Reference-contexts: It might seem that, under this stipulation, no solution to the problem is possible, but in fact a solution was found by Asmussen, Glynn, and Thorisson [AGT]. However, their algorithm was not very efficient. Subsequently Aldous [A2] and Lovasz and Winkler <ref> [LW] </ref> found faster procedures (although the algorithm of Al-dous involves controlled but non-zero error). The CFTP-based solution given below is even faster than that of Lovasz and Winkler.
Reference: [Lo] <author> R. M. Loynes, </author> <title> The stability of a queue with non-independent inter-arrival and service times, </title> <booktitle> Proceedings of the Cambridge Philosophical Society 58 (1962), </booktitle> <pages> 497-520. </pages>
Reference-contexts: One can even see traces of the idea in the work of Loynes <ref> [Lo] </ref> thirty-five years ago. 2.
Reference: [LRS] <author> M. Luby, D. Randall, and A. Sinclair, </author> <title> Markov chain algorithms for planar lattice structures, </title> <booktitle> in: Proceedings of the 36th IEEE Symposium on Foundations of Computing (1995), </booktitle> <pages> 150-159. </pages>
Reference-contexts: regardless of how quickly or slowly they are generated. (See section 7 for a discussion of how to avoid subtle sources of error arising from the variability of the running time of the procedure.) Even if one has rigorously proved that rapid mixing occurs (as Randall et al. have done <ref> [LRS] </ref> and [MR] for the particular application for which CFTP was originally invented), CFTP may be preferable to the usual Markov chain Monte Carlo strategy of running the system until it is "well-mixed" (e.g., running the system until the variation distance between ~ and is less than 10 6 ).
Reference: [LV] <author> M. Luby and E. Vigoda, </author> <title> Approximately counting up to four (extended abstract), </title> <booktitle> in: Proceedings of the Twenty-Ninth Annual ACM Symposium on Theory of Computing (1995), </booktitle> <pages> 150-159. </pages>
Reference-contexts: We denote this probability distribution by . That is, (S) = jSj =Z where S is a state, jSj is the number of particles in that state, and Z = P Luby and Vigoda <ref> [LV] </ref> provide a simple Markov chain Monte Carlo procedure for randomizing an initial hard-core state. The random moves they consider are determined by a pair of adjacent vertices u; v and a pair of numbers i; j with (i; j) equal to (0; 0), (0; 1), or (1; 0).
Reference: [MR] <author> N. Madras and D. Randall, </author> <title> Factoring graphs to bound mixing rates, </title> <booktitle> in: Proceedings of the 37th IEEE Symposium on Foundations of Computing (1996), </booktitle> <pages> 194-203. </pages>
Reference-contexts: how quickly or slowly they are generated. (See section 7 for a discussion of how to avoid subtle sources of error arising from the variability of the running time of the procedure.) Even if one has rigorously proved that rapid mixing occurs (as Randall et al. have done [LRS] and <ref> [MR] </ref> for the particular application for which CFTP was originally invented), CFTP may be preferable to the usual Markov chain Monte Carlo strategy of running the system until it is "well-mixed" (e.g., running the system until the variation distance between ~ and is less than 10 6 ).
Reference: [MG] <author> D. Murdoch and P. Green, </author> <title> Exact sampling from a continuous state space, </title> <note> to appear in the Scandinavian Journal of Statistics. </note>
Reference-contexts: Such joint realizations of two processes can allow one to prove comparative assertions that might otherwise be quite difficult to establish. Finally, we mention that the article of Murdoch and Greene <ref> [MG] </ref> has other interesting applications of CFTP to continuous state-spaces. 5.
Reference: [PW1] <author> J. Propp and D. Wilson, </author> <title> Exact sampling with coupled Markov chains and applications to statistical mechanics, </title> <booktitle> Random Structure and Algorithms 9 (1996), </booktitle> <pages> 223-252. </pages>
Reference-contexts: More often, one merely hopes that this is the case, and the possibility that one's samples are contaminated with substantial initialization bias cannot be ruled out with complete confidence. The "coupling from the past" procedure introduced in <ref> [PW1] </ref> provides one way of getting around this problem. Where it is applicable, this method delivers samples that are governed by itself, rather than ~. In the past two years, many researchers have found ways to apply the basic idea in a wide variety of settings. <p> As an historical aside, we mention that the conceptual ingredients of CFTP were in the air even before the versatility of the method was made clear in <ref> [PW1] </ref>. Precursors include Letac [Le], Thorisson [T], and Borovkov and Foss [BF]. <p> Failure to abide by this principle "voids the warranty" of our algorithm. We showed in <ref> [PW1] </ref> that, as long as the nature of P guarantees (almost sure) eventual coalescence, and as long as P bears a suitable relationship to the distribution , the CFTP sample will be distributed according to . <p> We will give several applications of the CFTP philosophy, and conclude with some words of warning about the proper use of CFTP algorithms. The article <ref> [PW1] </ref> gives many examples of situations in which CFTP works by virtue of monotonicity.
Reference: [PW2] <author> J. Propp and D. Wilson, </author> <title> How to get a perfectly random sample from a generic Markov chain and generate a random spanning tree of a directed graph, </title> <note> to appear in the Journal of Algorithms (SODA '96 special issue). </note>
Reference-contexts: We define the weight of an arborescence as the product of the weights of its constituent arcs. This determines a unique probability distribution on the set of arborescences for which the probability of each arborescence is proportional to its weight. Propp and Wilson <ref> [PW2] </ref> consider the problem of sampling from this distribution . <p> Finally, detecting when coalescence has occurred is simple: one merely checks that f [v] is defined for all v other than the root. Hence we can use CFTP to generate random rooted spanning trees, via prepended excursions; further details can be found in <ref> [PW2] </ref>. 8 JAMES PROPP AND DAVID WILSON If one wants to use CFTP to generate a random spanning arborescence of a graph without specifying a root, then one might think one needs a way to couple histories in which two arborescences start out with different roots. <p> That is, one might try to do away with the notion of excursions and simply let the stochastic flow advance one step at a time, so that eventually the roots coincide. Such an approach might be workable, but we have proposed a different way. Specifically, in <ref> [PW2] </ref> we suggest that one first choose a random vertex r to serve as the root, where r is governed by the steady-state distribution for the random walk on G, and then apply the procedure for finding a random arborescence with root r. <p> A CFTP-based procedure for choosing such an r is described in the next section (although the non-CFTP-based method called cycle-popping, described in <ref> [PW2] </ref>, is likely to be superior in most applications). <p> Finally, we stress that CFTP is only one of many schemes for generating random spanning arborescences; see <ref> [PW2] </ref> for others. 6. Random state of an unknown Markov chain Now we come to a problem that in a sense encompasses all the cases we have discussed so far: the problem of sampling from the steady-state distribution () of a general Markov chain. <p> We denote the vertex set of G by X, and denote the steady-state distribution on X by . Propp and Wilson <ref> [PW2] </ref> give a CFTP-based algorithm that lets one sample from this distribution . COUPLING FROM THE PAST: A USER'S GUIDE 9 Our goal is to define suitable random maps from X to X in which many states are mapped into a single state. <p> Ideally, the expected duration of the walk should be on the order of the cover-time for the random walk. Propp and Wilson <ref> [PW2] </ref> show that by using the random walk itself to estimate its own cover-time, one gets an algorithm that generates a random state distributed according to in expected time at most 15 times the cover time.
Reference: [RT] <author> D. Randall and P. Tetali, </author> <title> Analyzing Glauber dynamics by comparison of Markov chains (extended abstract), </title> <note> preprint (1997). </note>
Reference-contexts: Work of Randall and Tetali <ref> [RT] </ref>, in conjunction with the Luby-Vigoda result, implies that the single-site heat-bath Markov chain studied by Haggstrom and Nelander is also rapidly mixing for 1 3 . 4.
Reference: [T] <author> H. Thorisson, </author> <title> Backward limits, </title> <booktitle> Annals of Probability 16 (1988), </booktitle> <pages> 914-924. </pages> <institution> 12 JAMES PROPP AND DAVID WILSON Department of Mathematics, Massachusetts Institute of Technology, Cambridge, Massachusetts 02139 E-mail address: propp@math.mit.edu Institute for Advanced Study, Princeton, </institution> <address> New Jersey 08540 E-mail address: dbwilson@math.ias.edu </address>
Reference-contexts: As an historical aside, we mention that the conceptual ingredients of CFTP were in the air even before the versatility of the method was made clear in [PW1]. Precursors include Letac [Le], Thorisson <ref> [T] </ref>, and Borovkov and Foss [BF].
References-found: 26

