URL: http://www.isi.edu/isd/VET/s-p-att.ps
Refering-URL: http://www.isi.edu/isd/VET/vet-body.html
Root-URL: http://www.isi.edu
Email: hill@negev.jpl.nasa.gov johnson@isi.edu  
Title: Situated Plan Attribution  
Author: Randall W. Hill, Jr. W. Lewis Johnson 
Note: To appear in the Journal of Artificial Intelligence in Education. Copyright 1995, Association for the Advancement of Computing in Education.  
Address: 4800 Oak Grove Drive M/S 525-3631 4676 Admiralty Way Pasadena, CA 91109-8099 Marina del Rey, CA 90292-6695  
Affiliation: Jet Propulsion Laboratory Caltech USC Information Sciences Institute  
Abstract: Plan recognition techniques frequently make rigid assumptions about the student's plans, and invest substantial effort to infer unobservable properties of the student. The pedagogical benefits of plan recognition analysis are not always obvious. We claim that these difficulties can be overcome if greater attention is paid to the situational context of the student's activity and the pedagogical tasks which plan recognition is intended to support. This paper describes an approach to plan recognition called situated plan attribution that takes these factors into account. It devotes varying amounts of effort to the interpretation process, focusing the greatest effort on interpreting impasse points, i.e., points where the student encounters some difficulty completing the task. This approach has been implemented and evaluated in the context of the REACT tutor, a trainer for operators of deep space communications stations. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Allemang, D. </author> <year> (1990). </year> <type> Understanding Programs as Devices . Ph.D Thesis, </type> <institution> The Ohio State University, </institution> <year> 1990. </year>
Reference-contexts: Pathfinder (Calistri, 1990) requires knowledge of the probabilities of various misconceptions. The computational costs of these systems increases when students deviate from standard plans, because the systems try to generate complete interpretations of the students actions. Other systems such as that of (Murray, 1986) and <ref> (Allemang, 1990) </ref> rely on theorem proving techniques which are intrinsically expensive to apply. As it turns out, complex plan recognition algorithms are largely superfluous for situated tasks. The above approaches assume that one must analyze the plan in order to determine whether or not it is faulty.
Reference: <author> Anderson, J.R., Boyle, C.F., Corbett, A.T., and Lewis, M.W. </author> <year> (1990). </year> <title> Cognitive modeling and intelligent tutoring. </title> <booktitle> Artificial Intelligence , 42, </booktitle> <year> 1990: </year> <pages> 7-49. </pages>
Reference-contexts: Finally, they tend to be unfocused they do not target their analysis on those situations where tutorial intervention is warranted. For instance, intelligent tutors that use model tracing <ref> (Anderson et al., 1990) </ref> to interpret student actions tend to intervene whenever the student wanders off of a correct solution path; this intervention policy is potentially 1 Portions of this paper are based on the AAAI-94 paper entitled "Situated Plan Attribution for Intelligent Tutoring Systems." (Hill & Johnson, 1994) disruptive and <p> Therefore the situated plan attribution approach involves simultaneous monitoring of the student's actions and the simulated environment, without expensive plan analyses. Model tracing systems such as that of <ref> (Anderson et al, 1990) </ref> encounter difficulties that are in many ways similar to those of plan recognition systems. In the model tracing approach, an executable model of the student's performance is constructed and used to simulate the mental activities of the student that would account for an observed behavior.
Reference: <author> Azarewicz, J., Fala, G. and Fink, R. and Heighecker, C. </author> <year> (1986). </year> <title> Plan recognition for airborne tactical decision making. </title> <booktitle> Proceedings of the Fifth National Conference on Artificial Intelligence , pp. </booktitle> <pages> 805-811, </pages> <year> 1986. </year>
Reference-contexts: Introduction Plan recognition and agent modeling capabilities are valuable for intelligent tutoring (Corbett et al., 1990; Johnson, 1986), as well as other areas such as natural language processing (Charniak & Goldman, 1991), expert consultation (Calistri, 1990), and tactical decision making <ref> (Azarewicz et al., 1986) </ref>. However, such capabilities are difficult to implement and employ effectively, for the following reasons. Plan recognition techniques can be rigid-they assume the agent is following a known plan step by step, and have difficulty interpreting deviations from the plan.
Reference: <author> Brown, J.S. & VanLehn, K. </author> <year> (1982). </year> <title> Repair theory: A generative theory of bugs in procedural skills. </title> <journal> Cognitive Science, </journal> <volume> 4, </volume> 1982 379-426. 
Reference: <author> Brown, J.S., </author> <year> (1990). </year> <title> Towards a new epistemology for learning. </title> <editor> In Frasson, C., and Gauthier, G., </editor> <booktitle> Intelligent Tutoring Systems: At the Crossroads of Artificial Intelligence and Education, </booktitle> <pages> pp. 266-282. </pages> <address> Norwood, NJ: </address> <publisher> Ablex Publishing Corporation, </publisher> <year> 1990. </year>
Reference: <author> Burns, H.L. & Capps, C.G. </author> <year> (1988). </year> <title> Foundations of intelligent tutoring systems: An introduction. Foundations of Intelligent Tutoring Systems. Edited by Martha C. </title> <editor> Polson and J. Jeffrey Richardson. </editor> <address> Hillsdale, New Jersey: </address> <publisher> Lawrence Erlbaum Associates Publishers, </publisher> <year> 1988. </year>
Reference-contexts: The result is an efficient tutor that can interact in real time with a student. The resulting architecture looks different than a stereotypical intelligent tutoring system <ref> (Burns & Capps, 1988) </ref> that contains modular pieces labeled expert model, student model, tutor model, and so on. Though these are identifiable functions in REACT, they cease to have relevance from an architectural point of view once the knowledge of these functions has been compiled.
Reference: <author> Calistri, R.J. </author> <year> (1990). </year> <title> Classifying and detecting plan-based misconceptions for robust plan recognition. </title> <type> Ph.D. diss., Technical Report No. </type> <institution> CS-90-11, Department of Computer Science, Brown University, </institution> <year> 1990. </year>
Reference-contexts: Introduction Plan recognition and agent modeling capabilities are valuable for intelligent tutoring (Corbett et al., 1990; Johnson, 1986), as well as other areas such as natural language processing (Charniak & Goldman, 1991), expert consultation <ref> (Calistri, 1990) </ref>, and tactical decision making (Azarewicz et al., 1986). However, such capabilities are difficult to implement and employ effectively, for the following reasons. Plan recognition techniques can be rigid-they assume the agent is following a known plan step by step, and have difficulty interpreting deviations from the plan. <p> PROUST (Johnson, 1986) is tolerant of plan variations and novel plans, but it requires detailed knowledge of the kinds of plan deviations that may be expected. Pathfinder <ref> (Calistri, 1990) </ref> requires knowledge of the probabilities of various misconceptions. The computational costs of these systems increases when students deviate from standard plans, because the systems try to generate complete interpretations of the students actions.
Reference: <author> Clancey, W.J., </author> <year> (1993). </year> <title> Guidon-Manage revisited: a socio-technical systems approach. </title> <journal> Journal of Artificial Intelligence in Education, </journal> <volume> Vol. 4, no. 1, </volume> <pages> pp. 5-34, </pages> <year> 1993. </year>
Reference: <author> Corbett, A.T., Anderson, J.R. & Patterson, E.G. </author> <year> (1990). </year> <title> Student Modeling and Tutoring Flexibility in the Lisp Intelligent Tutoring System. Intelligent Tutoring Systems: </title> <booktitle> At the Crossroads of Artificial Intelligence and Education. </booktitle> <publisher> Ablex, </publisher> <year> 1990. </year>
Reference: <author> Charniak, E. & Goldman, R. </author> <year> (1991). </year> <title> A probabilistic model of plan recognition. </title> <booktitle> Proceedings of the Ninth National Conference on Artificial Intelligence. </booktitle> <year> 1991. </year>
Reference-contexts: Introduction Plan recognition and agent modeling capabilities are valuable for intelligent tutoring (Corbett et al., 1990; Johnson, 1986), as well as other areas such as natural language processing <ref> (Charniak & Goldman, 1991) </ref>, expert consultation (Calistri, 1990), and tactical decision making (Azarewicz et al., 1986). However, such capabilities are difficult to implement and employ effectively, for the following reasons.
Reference: <author> Fayyad, K. & Cooper, L. </author> <year> (1992). </year> <title> Representing operations procedures using temporal dependency networks. </title> <booktitle> Proceedings of the Second International Symposium on Ground Data Systems for Space Mission Operations , SPACEOPS-92, </booktitle> <address> Pasadena, CA, </address> <month> 16-20 November </month> <year> 1992. </year>
Reference-contexts: For each type of mission the temporal precedence relationships among the plans is modeled with a directed graph structure called a temporal dependency network (TDN) <ref> (Fayyad & Cooper, 1992) </ref>. A plan has a name and three attributes: state, execution status and goal status. The state of a plan can be either active or inactive; a plan is considered to be active once all of its predecessors in the TDN have been successfully completed.
Reference: <author> Firby, R.J. </author> <year> (1987). </year> <title> An investigation into reactive planning in complex domains. </title> <booktitle> Proceedings of the Sixth National Conference on Artificial Intelligence, </booktitle> <pages> pp. 202-206, </pages> <year> 1987. </year>
Reference: <author> Hammond, K.J. </author> <year> (1990). </year> <title> Explaining and repairing plans that fail*. </title> <journal> Artificial Intelligence, </journal> <volume> 45, </volume> <year> (1990) </year> <month> 173-228. </month>
Reference-contexts: As with the case of a goal failure impasse, subgoals are also formed to verify the operator's preconditions, repair unsatisfied preconditions, and verify its postconditions. The problem solving in REACT bears a resemblance to the approach in CHEF <ref> (Hammond, 1990) </ref>: the general strategy is to notice a failure, build an explanation for it, use the explanation to determine a repair strategy, and so on.
Reference: <author> Georgeff, M.P. & Lansky, A. </author> <year> (1987). </year> <title> Reactive reasoning and planning. </title> <booktitle> Proceedings of the Sixth National Conference on Artificial Intelligence, </booktitle> <pages> pp. 677-682, </pages> <year> 1987. </year>
Reference: <author> Hill, R.W.(1993). </author> <title> Impasse-driven tutoring for reactive skill acquisition. </title> <type> Ph.D. </type> <institution> diss. University of Southern California, </institution> <address> Los Angeles, California, </address> <year> 1993. </year>
Reference-contexts: These tutors will operate within immersive virtual environments, affording a wider variety of interactions between trainees and simulated environments. JPL and USC / ISI are also examining K-12 science education as a potential application area for situated plan attribution techniques. Evaluation A pilot study was conducted to evaluate REACT <ref> (see Hill, 1993 for more details.) </ref> We hypothesized that situated plan attribution would be able to recognize and interpret student impasses and that the resulting tutoring would help students acquire skill in the LMC domain.
Reference: <author> Hill, R.W. & Johnson, W.L. </author> <year> (1994). </year> <title> Situated plan attribution for intelligent tutoring systems. </title> <booktitle> Proceedings of the Twelfth National Conference on Artificial Intelligence, </booktitle> <pages> pp. 499-505, </pages> <address> Seattle, Washington, </address> <year> 1994. </year>
Reference-contexts: tutors that use model tracing (Anderson et al., 1990) to interpret student actions tend to intervene whenever the student wanders off of a correct solution path; this intervention policy is potentially 1 Portions of this paper are based on the AAAI-94 paper entitled "Situated Plan Attribution for Intelligent Tutoring Systems." <ref> (Hill & Johnson, 1994) </ref> disruptive and does not appear to be based on an analysis of whether it is appropriate to intervene. This paper describes an approach to plan recognitio n called situated plan attribution that takes these factors into account.
Reference: <author> Hill, R.W. & Johnson, W.L. </author> <year> (1993a). </year> <title> Designing an intelligent tutoring system based on a reactive model of skill acquisition. </title> <booktitle> Proceedings of the World Conference on Artificial Intelligence in Education (AI-ED 93) , pp. </booktitle> <pages> 273-281, </pages> <address> Edinburgh, Scotland, </address> <year> 1993. </year>
Reference-contexts: Therefore, it is apparent that some form of online guidance or coaching is necessary in order to ensure that students learn effectively. In order to determine how best to design a tutor for this task, a cognitive mode l of students interacting with simulated devices was constructed <ref> (Hill & Johnson, 1993a) </ref>. One of the key conclusions from this study is that tutorial interaction should center around impasse points . <p> Tutor Improves with Experience REACT was implemented to take advantage of Soar's learning capability. One consequence of having a tutor that learns is that its efficiency improves with ex perience. Since it is desirable to interact with the student as close to the impasse point as possible <ref> (Hill & Johnson, 1993a) </ref>, a highly efficient problem solving scheme is desirable. As the tutor gains experience with different student impasses, the knowledge of how to recognize and interpret these impasses is summarized in new Soar productions called chunks.
Reference: <author> Hill, R.W. & Johnson, W.L. </author> <year> (1993b). </year> <title> Impasse-driven tutoring for reactive skill acquisition. </title> <booktitle> Proceedings of the 1993 Conference on Intelligent Computer-Aided Training and Virtual Environment Technology (ICAT-VET-93), </booktitle> <institution> NASA/Johnson Space Center, Houston, Texas, </institution> <month> May 5-7, </month> <year> 1993. </year>
Reference: <author> Johnson, W.L. </author> <year> (1986). </year> <title> Intention-based diagnosis of novice programming errors . Los Altos, </title> <address> CA: </address> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <year> 1986. </year>
Reference-contexts: Furthermore, the set of possible procedures is quite large, so constructing a complete plan library would be difficult. El iminating the assumptions that lead to rigidity tends to increase the complexity of the knowledge base and the computational cost of the plan recognition algorithms. PROUST <ref> (Johnson, 1986) </ref> is tolerant of plan variations and novel plans, but it requires detailed knowledge of the kinds of plan deviations that may be expected. Pathfinder (Calistri, 1990) requires knowledge of the probabilities of various misconceptions. <p> Note, however, that concern with cognition in a situated context has not led us to abandon intelligent tutoring as an objective. We remain convinced that an understanding of the trainee's intentions is essential in order to make sense of errors when they occur <ref> (Johnson, 1986) </ref>. When an impasse occurs, it is appropriate to refer to such intentions, if that helps trainees to better understand the cause of the impasse.
Reference: <author> Kaelbling, </author> <title> L.P. (1987). An architecture for intelligent reactive systems. Reasoning about Actions and Plans: </title> <booktitle> Proceedings of the 1986 Workshop, </booktitle> <pages> pp. 395-410, </pages> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <year> 1987. </year>
Reference: <author> Kautz, H.A. & Allen, J.F. </author> <year> (1986). </year> <title> Generalized plan recognition. </title> <booktitle> Proceedings of the National Conference on Artificial Intelligence, </booktitle> <address> Philadelphia, PA, </address> <year> 1986. </year>
Reference-contexts: This flexibility avoids the rigidity problems of other techniques such as Kautz and Allen's deductive approach <ref> (Kautz & Allen, 1986) </ref>, which assumes that all possible ways of performing an action are known, and every action is a step in a known plan. <p> Our stance is thus consistent with that of (Self, 1990), who argues that to make student modeling tractable one must focus on realistic, useful objectives. Plan recognition approaches such as that of <ref> (Kautz & Allen, 1986) </ref> and (Vilain, 1990) are inappropriate for domains such as the DSN because they are rigid, i.e., they make strong assumptions about the task and the knowledge employed to perform it, and do not degrade gracefully when those assumptions are violated.
Reference: <author> Laird, J.E., Newell, A. & Rosenbloom, P.S. </author> <year> (1987). </year> <title> Soar: An architecture for general intelligence. </title> <journal> Artificial Intelligence , 33, </journal> 1987 1-64. 
Reference: <author> Maes, P. </author> <year> (1989). </year> <title> How to do the right thing. </title> <journal> Connection Science , Vol. </journal> <volume> 1, No. 3, </volume> <year> 1989. </year>
Reference: <author> Munro, A., Johnson, M.C., Surmon, D.S. & Wogulis, J.L. </author> <year> (1993). </year> <title> Attribute-centered simulation authoring for instruction. </title> <booktitle> Proceedings of AI-ED 93, World Conference on Artificial Intelligence in Education, </booktitle> <pages> pp. 82-89, </pages> <address> Edinburgh, Scotland; 23-27 August 1993. </address>
Reference-contexts: The initial version of the REACT tutor incorporated custom-built simulations of the devices in the DSN communication link. Our current work makes use of the RIDES simulation authoring package <ref> (Munro et al., 1993) </ref> as a base. Yet it was evident from the beginning that a simulation alone would be insufficient as a training system. It is not always evident to novices, or even to experts, why particular directives fail and are rejected.
Reference: <author> Murray, W.R. </author> <year> (1986). </year> <title> Automatic program debugging for intelligent tutoring systems. </title> <type> Ph.D thesis, </type> <institution> University of Texas at Austin, Computer Science Dept., </institution> <year> 1986. </year>
Reference-contexts: Pathfinder (Calistri, 1990) requires knowledge of the probabilities of various misconceptions. The computational costs of these systems increases when students deviate from standard plans, because the systems try to generate complete interpretations of the students actions. Other systems such as that of <ref> (Murray, 1986) </ref> and (Allemang, 1990) rely on theorem proving techniques which are intrinsically expensive to apply. As it turns out, complex plan recognition algorithms are largely superfluous for situated tasks. The above approaches assume that one must analyze the plan in order to determine whether or not it is faulty.
Reference: <author> Newell, A. </author> <year> (1990). </year> <title> Unified Theories of Cognition. </title> <publisher> Harvard University Press, </publisher> <year> 1990. </year>
Reference: <author> Reiser, B.J., Beekelaar, R., Tyle, A., and Merrill, D. </author> <year> (1991). </year> <title> GIL: Scaffolding learning to program with reasoning-congruent representations. </title> <booktitle> The International Conference on the Learning Sciences: Proceedings of the 1991 Conference, </booktitle> <pages> pp. 382-388, </pages> <address> Charlottesville, VA: </address> <publisher> AACE, </publisher> <year> 1991. </year>
Reference-contexts: Even in these domains there may be useful environmental cues to exploit. For example, intelligent tutors for programming tend not to take advantage of feedback from actually running the student's program, although recent work such as GIL is making such feedback more readily available to the student <ref> (Reiser et al., 1991) </ref>. Example Problem To illustrate how REACT works we will now describe an example from our task domain.
Reference: <author> Rosenbloom, P.S. & Newell, A. </author> <year> (1986). </year> <title> The chunking of goal hierar chies: a generalized model of practice. </title> <booktitle> Machine Learning , Volume II, </booktitle> <pages> pp. </pages> <note> 247- 288, </note> <editor> edited by Ryszard S. Michalski, Jaime G. Carbonell, and Tom M. Mitchell, </editor> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <address> Los Altos, California, </address> <year> 1986. </year>
Reference: <author> Self, J.A. </author> <year> (1990). </year> <title> Bypassing the intractable problem of student modeling. </title> <editor> In Frasson, C. and Gauthier, G., eds., </editor> <booktitle> Intelligent Tutoring Systems: At the Crossroads of Artificial Intelligence and Education, </booktitle> <publisher> Ablex, </publisher> <address> Norwood, NJ, </address> <pages> pp. 107-123, </pages> <year> 1990. </year>
Reference-contexts: This means that much of the computational cost of typical plan recognition or student modeling techniques can be avoided. Our stance is thus consistent with that of <ref> (Self, 1990) </ref>, who argues that to make student modeling tractable one must focus on realistic, useful objectives.
Reference: <author> Suchman, L.A., </author> <year> (1987). </year> <title> Plans and situated actions: the problem of human-machine communication . New York: </title> <publisher> Cambridge University Press, </publisher> <year> 1987. </year>
Reference-contexts: In keeping with the idea that knowledge is socially constructed (Wittgenstein, 1953) we model the problem solving process in terms similar to those used by practitioners, e.g., missions, procedures, and directives in the DSN domain. Plans play a role similar to that advocated by <ref> (Suchman, 1987) </ref>: they orient action, but do not dictate action in detail. Procedures in the DSN domain are plans in this sense.
Reference: <author> Tambe, M. & Rosenbloom, P.S. </author> <year> (1994). </year> <title> Event tracking in a dynamic multi-agent environment. </title> <type> USC / ISI tech report no. </type> <institution> ISI-RR-393, </institution> <year> 1994. </year>
Reference-contexts: The abilityto mix goal-directed and reactive behavior has also been found to be important for situated agents which must model the intentions of other agents <ref> (Tambe & Rosenbloom, 1994) </ref>. We will describe a tutor that implements this approach for a situated training task. It incorporates components for tracing plans, monitoring the environment, adapting plans, and explaining to students how to deal with problematic situations and plan failures.
Reference: <author> Tambe, M., Johnson, W.L., Jones, R.M., Koss, F., Laird, J.E., Rosenbloom, P.S., and Schwamb, K., </author> <year> 1995. </year> <title> Intelligent agents for interactive simulation environments, </title> <journal> AI Magazine, </journal> <note> Spring 1995, in press. </note>
Reference: <author> VanLehn, K. </author> <year> (1982). </year> <title> Bugs are not enough: Empirical studies of bugs, impasses and repairs in procedural skills. </title> <journal> The Journal of Mathematical Behavior, </journal> <volume> 3, </volume> 1982 3-71. 
Reference: <author> VanLehn, K. </author> <year> (1983). </year> <title> Felicity conditions for human skill acquisition: Validating an AI-based theory. </title> <type> Tech. Report CIS-21. </type> <institution> Palo Alto, CA: Xerox Palo Alto Research Center. </institution>
Reference: <author> VanLehn, K. </author> <year> (1988). </year> <title> Toward a theory of impasse-driven learning. Learning Issues for Intelligent Tutoring Systems. </title> <editor> Edited by Heinz Mandl and Alan Lesgold. </editor> <address> New York: </address> <publisher> Springer-Verlag, </publisher> 1988 19-41. 
Reference-contexts: An impasse is defined in this work to be an obstacle to problem solving that results from either a lack of knowledge or from incorrect knowledge (Brown & VanLehn, 1982; VanLehn, 1982, 1983; Hill, 1993). Our results agree with the results of earlier studies <ref> (e.g., VanLehn, 1988) </ref> that suggest that such impasse points are natural learning opportunities. When the student is at an impasse, he or she naturally seeks information that can be used to overcome the impasse and continue the task.
Reference: <author> Vilain, M. </author> <year> (1990). </year> <title> Getting serious about parsing plans: a grammatical analysis of plan recognition. </title> <booktitle> Proceedings of the Eighth National Conference on Artificial Intelligence, (AAAI-90), </booktitle> <pages> pp. 190-197, </pages> <address> 29 July - 3 August 1990, </address> <publisher> AAAI Press / MIT Press, </publisher> <address> Menlo Park, CA. </address>
Reference-contexts: Our stance is thus consistent with that of (Self, 1990), who argues that to make student modeling tractable one must focus on realistic, useful objectives. Plan recognition approaches such as that of (Kautz & Allen, 1986) and <ref> (Vilain, 1990) </ref> are inappropriate for domains such as the DSN because they are rigid, i.e., they make strong assumptions about the task and the knowledge employed to perform it, and do not degrade gracefully when those assumptions are violated.
Reference: <author> Ward, B. </author> <year> (1991). </year> <title> ET-Soar: Toward an ITS for theory-based representations. </title> <type> Ph.D. </type> <institution> diss., CMU-CS-91-146, School of Computer Science, Carnegie Mellon University, </institution> <address> Pittsburgh, PA. </address>
Reference-contexts: The modeling process can be underconstrained , postulating mental activities that are difficult to infer from the agent's observable actions. An example of this style of modeling can be seen in <ref> (Ward, 1991) </ref>, where the tutor attempts to track the student by generating production paths that could have led to an observed action. Finally, they tend to be unfocused they do not target their analysis on those situations where tutorial intervention is warranted. <p> In cases where the student takes the wrong action, the model tracer must also contain mal-rules that would simulate the student's faulty mental model that resulted in the wrong action being taken. Such executable cognitive models can be quite detailed-in extreme cases such as the system of <ref> (Ward, 1991) </ref>, internal cognitive processes such as perception are modeled as well.
Reference: <author> Warren, K.C., Goodman, B.A. & Maciorowski, S.M. </author> <year> (1993). </year> <title> A software architecture for intelligent tutoring systems. </title> <booktitle> Proceedings of the World Conference on Artificial Intelligence in Education (AI-ED 93) , Edinburgh, </booktitle> <address> Scotland, </address> <year> 1993. </year>
Reference: <author> Wittgenstein, W., </author> <year> 1953. </year> <title> Philosophical Investigations . New York: </title> <publisher> Macmillan Publishing Co., </publisher> <year> 1953. </year>
Reference-contexts: Therefore tutoring systems should attend to the student's situation as well and direct less effort at trying to guess what is going on in the student's head. In keeping with the idea that knowledge is socially constructed <ref> (Wittgenstein, 1953) </ref> we model the problem solving process in terms similar to those used by practitioners, e.g., missions, procedures, and directives in the DSN domain. Plans play a role similar to that advocated by (Suchman, 1987): they orient action, but do not dictate action in detail.
References-found: 39

