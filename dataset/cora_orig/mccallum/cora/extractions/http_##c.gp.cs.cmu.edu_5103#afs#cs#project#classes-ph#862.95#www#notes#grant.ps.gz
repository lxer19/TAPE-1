URL: http://c.gp.cs.cmu.edu:5103/afs/cs/project/classes-ph/862.95/www/notes/grant.ps.gz
Refering-URL: http://c.gp.cs.cmu.edu:5103/afs/cs/project/classes-ph/862.95/www/862.html
Root-URL: http://www.cs.cmu.edu
Title: Visibility Algorithms in Image Synthesis  
Author: DAVIS Nelson L. Max Kenneth I. Joy Franklin C. Crow 
Degree: By Charles Wayne Grant M.S. (University of California, Davis) 1981 DISSERTATION Submitted in partial satisfaction of the requirements for the degree of DOCTOR OF PHILOSOPHY in Computer Science in the GRADUATE DIVISION of the  Approved:  Committee in Charge  
Date: 1992  
Affiliation: UNIVERSITY OF CALIFORNIA  
Abstract-found: 0
Intro-found: 1
Reference: [Amanatides84] <author> John Amanatides, </author> <title> "Ray Tracing with Cones," </title> <journal> Computer Graphics, </journal> <volume> Vol. 18, No. </volume> <booktitle> 3 (Proceedings of ACM SIGGRAPH 84), </booktitle> <month> July </month> <year> 1984. </year>
Reference-contexts: New techniques for extending the painter's algorithm to use approximate geometric information for antialiasing of correlated and uncorrelated object edges is presented in the next chapter. Cone tracing <ref> [Amanatides84] </ref> is an extension of the ray tracing algorithm to use approximate geometric information with every sample ray. This algorithm is very effective in quickly and accurately antialiasing simple cases where regular ray tracing would require many sample rays.
Reference: [Arvo86] <author> James Arvo, </author> <title> "Forward Ray Tracing," Course Notes: Tutorial on Ray Tracing, </title> <booktitle> ACM SIGGRAPH 86, </booktitle> <address> Dallas, Texas, </address> <note> August 1986 (unpublished). </note>
Reference-contexts: Combining a ray tracing second pass with a diffuse radiosity first pass gives a system that can handle the light paths LD fl S fl E [Sil-lion89]. Using "backwards" ray tracing to distribute illumination from the light sources to the surfaces in the scene is another approach <ref> [Arvo86] </ref>. This backwards ray tracing can identify illumination boundaries (shadows and caustics) much more accurately than a radiosity solution with uses non-diffuse form factors.
Reference: [Arvo87] <author> James Arvo, David Kirk, </author> <title> "Fast Ray Tracing by Ray Classification," </title> <journal> Computer Graphics, </journal> <volume> Vol. </volume> <pages> 21, </pages> <note> No. 4 (Proceedings of SIGGRAPH 87), July 1987 (reprinted in [Joy87]). </note>
Reference-contexts: With subdivision algorithms there are many choices of how the subdivision can be made defining different dimensions in a subdivision algorithm space, but there is no single basis algorithm. Subdivision can be two-dimensional [Warnock69] [Weiler77] [Franklin80] or three-dimensional [Fuchs79] [Fuchs80] [Fujimoto86] [Glassner84] [Samet90] or higher dimensional <ref> [Arvo87] </ref> [Grant85] [Glassner88]. The subdivisions can be specified in screen coordinates based on dividing the image [Warnock69] [Catmull78] [Catmull84] or in object coor dinates based on dividing the scene independent of the viewpoint [Fujimoto86].
Reference: [Appel67] <author> A. Appel, </author> <title> "The Notion of Quantitative Invisibility and the Machine Rendering of Solids," </title> <booktitle> Proceedings of the ACM National Conference, 1967 (reprinted in [Freeman80]). </booktitle>
Reference-contexts: There were no continuous visible surface algorithms at that time. Four visible line algorithms ([Roberts63] [Galimberti69] [Loutrell67] <ref> [Appel67] </ref>) were also considered. The taxonomy that resulted from this study is shown in figure 2.6. This figure and its interpretation is one of the important results of this study. There were several associations noted in the taxonomy.
Reference: [Appel68a] <author> A. Appel, </author> <title> "Some Techniques for Shading Machine Renderings of Solids," </title> <booktitle> Proceedings of AFIPS Spring Joint Computer Conference, </booktitle> <volume> Vol. </volume> <month> 32 </month> <year> 1968. </year>
Reference-contexts: The visible regions are tested when the image formation algorithm determines that they are visible. Each illumination test is independent of previous tests and no additional data structures specific to illumination are used. Any point sampling image formation algorithm can use ray tracing for the illumination test <ref> [Appel68a] </ref>. The most common example of this is when ray tracing is also used as the image formation algorithm. Some visibility algorithms (e.g. the z-buffer and painter's algorithms) do not have to hold all the primitives in memory at one time.
Reference: [Appel68b] <author> A. Appel, </author> <title> "On Calculating the Illusion of Reality," </title> <booktitle> IFIP, </booktitle> <year> 1968. </year>
Reference-contexts: The ray tracing visibility algorithm for illumination can be combined with any of the other visibility algorithms for image formation yielding five other straightforward systems in this paradigm. The scan line-ray tracing combination has been described previously [Ap-pel68a] <ref> [Appel68b] </ref> [Cook84]. The non-ray tracing visibility algorithms are not suitable for use in the illumination test in zero-dimensional direct independent paradigm systems, because they only work efficiently for determining the visibility of large arrays of pixels and are not efficient processing single pixel visibility tests from different viewpoints.
Reference: [Atherton78] <author> Peter Atherton, Kevin Weiler, Donald P. Greenberg, </author> <title> "Polygon Shadow Generation," </title> <journal> Computer Graphics, </journal> <volume> Vol. 12, No. </volume> <booktitle> 3 (Proceedings of ACM SIGGRAPH 78), </booktitle> <month> August </month> <year> 1978. </year>
Reference-contexts: Continuous visible surface algorithms, which take polygons as input and produce the visible parts of the polygons as output, are examples of algorithms that can be used for direct illumination with uniform representation. <ref> [Atherton78] </ref> generates shadows by this uniform representation method using their continuous visible surface algorithm [Weiler77]. Input polygons are passed through the illumination pass of the continuous visible surface algorithm. Each polygon is divided 91 into illuminated (visible to the light source) and shadowed (hidden to the light source) polygons. <p> The second pass of the pure preprocessing algorithm, image formation, can be any visibility algorithm. This yields twelve different basic types of pure preprocessing systems. Only the subdivision-subdivision combination has been published <ref> [Atherton78] </ref>, so the eleven other combinations can be considered new systems predicted by this classification. (If the push plane continuous algorithm and the presorted ray trace, scan Z-buffer, scan painter's, scan ray trace and scan presorted ray trace point sampling algorithms are considered then the number of possible pure preprocessing systems
Reference: [Balch87] <author> Tucker Balch, </author> <type> Personal communication 1987. </type>
Reference-contexts: As the line encounters each segment end point an element is added or removed on the active list. The list is kept in depth sorted order and, assuming no polygon intersections occur, only changes when an element is added or removed. A one-dimensional continuous z-buffer algorithm was implemented by <ref> [Balch87] </ref>. In this scheme spans are stored on each scan line. Each span contains two x-values and two z-values. Polygons are processed in any order and spans are depth compared and entered into the scan line data structures. A one-dimensional continuous painter's algorithm is logical extension.
Reference: [Barr81] <author> Alan H. Barr, </author> <title> "Superquadrics and Angle-preserving Transformations," </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> Vol. 1, No. 1, </volume> <month> January </month> <year> 1981 </year>
Reference-contexts: here in figure 2.2. * Polygons [Sutherland73] * Implicit surfaces f (x; y; z) = 0. ffi Quadric surfaces Ax 2 +By 2 +Cz 2 +Dxy+Exz +F yx+Gx+H y+J z +K = 0 [Weiss66] [Goldstein71] ffi Superquadric surfaces Ax n + By n + Cz n + D = 0 <ref> [Barr81] </ref> [Franklin81] ffi Blobby particles K P all objects f (object; x; y; z) = 0 [Blinn82] * Parametric surfaces S = F (u; v) ffi Bi-cubic parametric patches [Catmull74] [Catmull75] ffi Superquadric surfaces (parametric form) [Barr81] [Franklin81] ffi Triangular patches [Sederberg84] * Procedural primitives ffi Particles [Reeves83] ffi Densities [Kajiya84] <p> Superquadric surfaces Ax n + By n + Cz n + D = 0 <ref> [Barr81] </ref> [Franklin81] ffi Blobby particles K P all objects f (object; x; y; z) = 0 [Blinn82] * Parametric surfaces S = F (u; v) ffi Bi-cubic parametric patches [Catmull74] [Catmull75] ffi Superquadric surfaces (parametric form) [Barr81] [Franklin81] ffi Triangular patches [Sederberg84] * Procedural primitives ffi Particles [Reeves83] ffi Densities [Kajiya84] ffi Fractals [Fournier82] 2.2.2 Light Source Modeling Light enters a scene through or is generated by objects called light sources. Light sources of varying complexity are possible.
Reference: [Barr86] <author> Alan H. Barr, </author> <title> "Ray Tracing Deformed Surfaces," </title> <journal> Computer Graphics, </journal> <volume> Vol. 20, No. </volume> <booktitle> 4 (Proceedings of ACM SIGGRAPH 86), </booktitle> <month> August </month> <year> 1986. </year>
Reference-contexts: The most complex type of object allows the index of refraction to vary throughout the interior of the object which causes the light to travel along curved paths in the object. This problem requires one to solve a differential equation initial value problem to trace a ray <ref> [Barr86] </ref>. This complicates everything so much that this effect is never used in image synthesis except for special purpose systems designed only to calculate this effect, for example: simulating mirages [Kallman86] [Berger90] [Musgrave90] [Lehn92]. The main object/light interaction is reflection.
Reference: [Baum89] <author> Baum, Daniel R, Holly E. Rushmeier, James M. Winget, </author> <title> "Improving Radios-ity Solutions Through the Use of Analytically Determined Form-factors," </title> <journal> Computer Graphics, </journal> <volume> Vol. 23, No. </volume> <booktitle> 2 (Proceedings of ACM SIGGRAPH 89), </booktitle> <month> July </month> <year> 1989. </year>
Reference-contexts: Thus with this technique it may be wasteful to precompute all the form factors. The form factors are usually generated on the fly during the iteration. The form factors are usually approximated by using a z-buffer algorithm called the "hemi-cube" [Cohen85], although more accurate techniques ae possible <ref> [Baum89] </ref>. This basic z-buffer algorithm is only good for pure diffuse reflections, LD fl E. One of the greatest difficulties with radiosity algorithms is creating a suitable dis-cretization of the scene.
Reference: [Beatty82] <author> John C. Beatty, Kellogg S. </author> <title> Booth, </title> <booktitle> IEEE Tutorial: Computer Graphics, </booktitle> <publisher> IEEE Computer Society Press, </publisher> <address> Silver Spring, MD 1982. </address>
Reference: [Bentley79] <author> J. L. Bentley, J. H. Friedman, </author> <title> "Data Structures for Range Searching," </title> <journal> ACM Computing Surveys, </journal> <volume> Vol. 11, No. 4, </volume> <month> December </month> <year> 1979. </year>
Reference-contexts: The locations of subdivisions can be made independent of the data in the scene [Franklin80] [Catmull78] [Catmull84] or at significant object points [Fuchs79] [Fuchs80] [Weiler77]. The subdivisions can be orthogonal to the coordinate axes [Samet90] <ref> [Bentley79] </ref> [Cat-mull78] [Catmull84] [Glassner84] [Kaplan85] [Warnock69] or at arbitrary angles [Fuchs79] [Fuchs80] [Weiler77]. The subdivision can be at a fixed resolution [Franklin80] [Cat-mull78] [Catmull84] or adaptive hierarchically [Fuchs79] [Fuchs80] [Glassner84] [Ka-plan85] [Warnock69] [Samet90]. <p> One possible sorting order was overlooked in this study, sorting in all three dimensions at the same time, the (XYZ) order. This sorting order corresponds to algorithms that use a three-dimensional data structure and sort such as the octree [Samet90], BSP tree [Fuchs79] [Fuchs80] or k-d tree <ref> [Bentley79] </ref>. The use of coherence to speed algorithms has not advanced much. One reason for this is that the average size primitive has shrunk over the years as computer generated scenes get more and more complex. Thus the amount of available coherence gets smaller and smaller.
Reference: [Berger90] <author> Marc Berger, Terry Trout, </author> <title> "Ray Tracing Mirages," </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> Vol. 10, No. 3, </volume> <month> May </month> <year> 1990. </year> <month> 167 </month>
Reference-contexts: This problem requires one to solve a differential equation initial value problem to trace a ray [Barr86]. This complicates everything so much that this effect is never used in image synthesis except for special purpose systems designed only to calculate this effect, for example: simulating mirages [Kallman86] <ref> [Berger90] </ref> [Musgrave90] [Lehn92]. The main object/light interaction is reflection.
Reference: [Bergeron86] <author> Philippe Bergeron, </author> <title> "A General Version of Crow's Shadow Volumes," </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> Vol. 6, No. </volume> <month> 9 </month> <year> 1986. </year>
Reference-contexts: The painter's algorithm, the scan line algorithm, the scan plane algorithm, and some subdivision algorithms are suitable. Ray tracing, z-buffer, and some forms of subdivision algorithms are not suitable. The only published examples of direct incremental algorithms are scan line shadow algorithms [Crow77a] <ref> [Bergeron86] </ref> [Max86a]. "Shadow polygons" are added to the input database. These polygons start at the edges of ordinary polygons and extend away from the light source. The shadow polygons enclose the volume of space which is shadowed by the ordinary polygon.
Reference: [Berlin85] <author> E. P. </author> <title> Berlin, "Efficiency Considerations in Image Synthesis," </title> <booktitle> Course Notes: Tutorial on State of the Art in Image Synthesis, SIGGRAPH 85, </booktitle> <address> San Francisco, California, </address> <note> July 1985 (unpublished). </note>
Reference-contexts: Substuting a polygon tree for the frame buffer of the painter's algorithm would yield a BSP-tree based continuous algorithm. Like the octree and voxel subdivisions, the BSP-tree has also been used as a preprocessing subdvision step for other algorithms <ref> [Berlin85] </ref> [Garcia86] [Chin89]. 3.4.3 Combinations of Algorithms 3.4.3.1 One-dimensional Continuous Algorithms Most algorithms, in practice, combine techniques from several of the basic algorithms.
Reference: [Blinn82] <author> James F. </author> <title> Blinn, "A Generalization of Algebraic Surface Drawing," </title> <journal> ACM Transactions on Graphics, </journal> <volume> Vol 1, No. 3, </volume> <month> July </month> <year> 1982. </year>
Reference-contexts: ffi Quadric surfaces Ax 2 +By 2 +Cz 2 +Dxy+Exz +F yx+Gx+H y+J z +K = 0 [Weiss66] [Goldstein71] ffi Superquadric surfaces Ax n + By n + Cz n + D = 0 [Barr81] [Franklin81] ffi Blobby particles K P all objects f (object; x; y; z) = 0 <ref> [Blinn82] </ref> * Parametric surfaces S = F (u; v) ffi Bi-cubic parametric patches [Catmull74] [Catmull75] ffi Superquadric surfaces (parametric form) [Barr81] [Franklin81] ffi Triangular patches [Sederberg84] * Procedural primitives ffi Particles [Reeves83] ffi Densities [Kajiya84] ffi Fractals [Fournier82] 2.2.2 Light Source Modeling Light enters a scene through or is generated by <p> However, both terms are frequently used interchangeably. 28 simply adding the corresponding intersection routines. If explicitly solving for intersections can not be done, then numerical approximation techniques can be used <ref> [Blinn82] </ref> [Hanrahan83] [Joy86] [Kajiya82] [Kajiya83] [Sweeney86] [Toth85]. Many optimizations are possible in the ray tracing algorithm.
Reference: [Bouknight69] <author> Jack W. Bouknight, </author> <title> "An Improved Procedure for Generation of Half-tone Computer Graphics Representations," </title> <institution> University of Illinois, Coordinated Science laboratory, R-432, </institution> <month> September </month> <year> 1969. </year>
Reference-contexts: Now the intensity of the illumination in the scene is a function of position within the scene. This simple model was used in some 9 early image synthesis efforts with the light source positioned at the view point [Wylie67] <ref> [Bouknight69] </ref>. This conveniently prevented any shadows or dark surfaces oriented away from the light source from being visible. Real scenes have much more complicated illumination patterns than that produced by a single point light source. <p> This analysis of visibility algorithms was performed between 1972 and 1973. This study focused on the structures of the algorithms in use or envisioned at that time. Each of the eight visible surface algorithms studied (six published at the time [Watkins69] <ref> [Bouknight69] </ref> [Romney70] [Warnock69] [Newell72] [Schumacker69]) solved essentially the same version of the visibility problem, point sampling with planar polygons. There were no continuous visible surface algorithms at that time. Four visible line algorithms ([Roberts63] [Galimberti69] [Loutrell67] [Appel67]) were also considered. <p> Many algorithms have been published which refer to themselves as scan line algorithms <ref> [Bouknight69] </ref> [Max90] [Watkins69] [Wylie67]. These algorithms use the concept of subdivision into scan lines, but the processing on each scan line differs. What we describe here is the simplest brute-force point-sampling techninque which is consistent with the method of scan line subdivision. <p> However, there is much more data available now, and some of the fundamental assumptions have changed. SSS did succeed in identifying examples of most of the major algorithms that are in use today: scan line [Watkins69], <ref> [Bouknight69] </ref>, [Romney70], painter's [Newell72], [Schumacker69], subdivision [Warnock69], z-buffer (brute force), and ray tracing (brute force). Only the scan plane algorithms which were first published in [Hamlin77] were not anticipated.
Reference: [Bouknight70a] <author> J. W. Bouknight, K. C. Kelley, </author> <title> "An Algorithm for Producing Halftone Computer Graphics Presentations with Shadows and Movable Light Sources," </title> <booktitle> Proceedings of AFIPS Spring Joint Computer Conference, </booktitle> <volume> Vol. 36, </volume> <year> 1970. </year>
Reference-contexts: Some systems store a list of surfaces that could potentially shadow primitives in each region of space. These lists allow an optimization of direct independent class umbra algorithms to avoid testing against all other primitives. The first algorithm using this optimization was presented by <ref> [Bouknight70a] </ref>. A slightly different version was later presented by [Haines86] as a ray tracing shadow accelerator. The depth buffer shadow algorithm of [Williams78] is the most popular algorithm of this class.
Reference: [Bouknight70b] <author> Jack W. Bouknight, </author> <title> "A Procedure for the Generation of Three-dimensional Half-toned Computer Graphics Presentations," </title> <journal> Communications of the ACM, </journal> <volume> Vol. 13, No. </volume> <pages> 9, </pages> <note> September 1970 (reprinted in [Freeman80]). </note>
Reference: [Brotman84] <author> Lynn Shapiro Brotman, Norman I. Badler, </author> <title> "Generating Soft Shadows with a Depth Buffer Algorithm," </title> <journal> IEEE Computer Graphics & Applications, </journal> <volume> Vol. 4, No. 10, </volume> <month> October </month> <year> 1984. </year>
Reference-contexts: Real light sources usually have some finite size surface that emits light rather than a single point. This type of area light source has been modeled and approximated in several ways. A collection of point sources can approximate an area source <ref> [Brotman84] </ref>. Light sources can also be directly specified as areas [Nishita83] [Cook84]. It is also possible for the light emitting part of a light source to be distributed over a volume of space rather than on a surface, if the light source itself is at least partially transparent. <p> A representation of the locations of the visible regions is generated in the first pass. In the second pass each visible region is tested against each primitive to determine if the primitive obscures the light source. <ref> [Brotman84] </ref> presents an algorithm along these lines that operates entirely in the image formation coordinate system using the z-buffer algorithm. First the image formation pass creates a point sampled representation of the visible objects. <p> Since <ref> [Brotman84] </ref> is similar to [Williams78] except the orders of the passes are reversed and the coordinate systems are different, it is interesting to consider what would happen if the order of the passes of [Brotman84] were reversed. <p> Since <ref> [Brotman84] </ref> is similar to [Williams78] except the orders of the passes are reversed and the coordinate systems are different, it is interesting to consider what would happen if the order of the passes of [Brotman84] were reversed. Would this generate an algorithm similar to [Williams78] without sampling errors? This inverted algorithm would in the first pass scan convert all polygons and shadow polygons in image space. <p> This large data structure would be held in memory in the first pass. The size of this data structure, which is dependent on scene complexity, makes this algorithm impractical for complex scenes. <ref> [Brotman84] </ref> was able to avoid having all this data in memory at any one time by structuring the illumination calculations as a postprocess after the image formation pass. It is probably possible to use a different representation of the visible regions in a [Brotman84]-like algorithm: spans or areas, yielding different algorithms <p> The double scan plane system does have the potential advantage of creating fewer polygon fragments than subdivision based systems. This system has not been implemented. 6.6 Umbra: Postprocessing Systems The postprocessing system of <ref> [Brotman84] </ref> uses point samples of depth (0-d). It should be possible to use 1-d depth spans and possibly 2-d areas with similar postpro cessing systems.
Reference: [Campbell90] <author> A. T. Campbell, Donald S. Fussel, </author> <title> "Adaptive Mesh Generation for Global Diffuse Illumination," </title> <journal> Computer Graphics, </journal> <volume> Vol. 24, No. </volume> <booktitle> 4 (Proceedings of ACM SIGGRPAPH 90), </booktitle> <month> August </month> <year> 1990. </year>
Reference-contexts: It is desirable to use small elements where illumination changes rapidly, such as at shadow boundaries, but it is wasteful to use small elements in areas of uniform illumination. Methods for adaptively subdividing the elements [Cohen86] <ref> [Campbell90] </ref> [Heckbert90] help a great deal. [Hanrahan90] [Hanrahan91] presents a 98 method of subdivision and solving the resulting approximate matrix equation to a fixed error tolerance in linear time.
Reference: [Carpenter84] <author> Loren Carpenter, </author> <title> "The A-buffer, an Antialiased Hidden Surface Method," </title> <journal> Computer Graphics, </journal> <volume> Vol. </volume> <pages> 18, </pages> <note> No. 3 (Proceedings of ACM SIGGRAPH 84), July 1984 (reprinted in [Joy87]). </note>
Reference-contexts: Antialiasing is required in all visibility determination stages in the image synthesis process, not just the final image formation stage. With respect to computer graphics, aliasing was first extensively discussed by [Crow77b]. Since then attempts to reduce this problem have been an extensive area of research [Crow81] [Feibush80] <ref> [Carpenter84] </ref> [Catmull78] [Catmull84] [Cook84] [Cook86] [Dippe85a] [Dippe85b] [Duff85] [Fiume83] [Fujimoto83] [Grant85] [Hourcade85] [Lee85] [Max85] [Max90] [Porter84] [Reeves87] [Szabo83] [Whit-ted82]. 2.3.2.1 Signals and Samples For the purposed of this discussion, a continuous signal is a function which is defined almost everywhere within some domain. 4 For example, the two-dimensional signal representing the <p> Some variants of the point sampling algorithms described here do visibility calculations at a finite number of points but actually do integrals over small areas at each pixel for antialiasing <ref> [Carpenter84] </ref>. The sample points are used to generate an approximation of the subpixel areas. These algorithms will still be considered point sampling algorithms, since the visibility calculations are point sampled. <p> Graphics hardware devices frequently implement the z-buffer algorithm in hardware or microcode. Storing only a single value per pixel in the z-buffer makes the algorithm subject to distance quantization and distance aliasing errors. The A-buffer algorithm <ref> [Carpenter84] </ref> is an extension of the z-buffer algorithm that uses a subpixel coverage mask stored at each pixel (among other things) to provide for finer resolution lateral information, but only a single depth value is stored. [Duff85] has a scheme for compositing images where distance is interpolated between z-buffer samples and <p> An accurate contribution for this polygon to the pixel can be calculated based on a weighted integral, or an approximation can be made. This kind of idea is used in several extended algorithms. The A-buffer algorithm of <ref> [Carpenter84] </ref> is an example of this technique. The algorithm is an extension of the z-buffer algorithm. <p> DBSS's are restricted to values that can be point sampled, such as depth and surface normal, at each shadow buffer pixel. Some additional types of information stored in the shadow buffer would allow more accurate shadow calculations (locations of primitive edges within a pixel <ref> [Carpenter84] </ref>, silhouette edges [Hourcade85], "alpha" coverage values [Hourcade85], indices to identify objects [Hourcade85], bits to flag which adjacent pixels are covered by the same object with a scheme similar to [Duff85], or other non-point-sampled geometric information), but this additional information could not be calculated by the depth buffer visible surface algorithm <p> It is possible to combine the Shadow Mask Sweep concept for shadow generation with different algorithms for visible surface determination. This may make the sorting and subdivision requirements simpler. Clearly one combination that will work well is to use the z-buffer algorithm (one of the antialiased versions by <ref> [Carpenter84] </ref> or [Duff85]) for visible surface determination, and use the shadow mask sweep version of the painter's algorithm for the shadows. The advantage here is that these visible surface algorithms can render primitives presented in any order. Therefore the objects need only be sorted with respect to the light source.
Reference: [Catmull74] <author> Edwin E. Catmull, </author> <title> "A Subdivision Algorithm for Computer Display of Curved Surfaces," </title> <type> Ph.D. Thesis, </type> <institution> University of Utah, </institution> <month> December </month> <year> 1974. </year>
Reference-contexts: z +K = 0 [Weiss66] [Goldstein71] ffi Superquadric surfaces Ax n + By n + Cz n + D = 0 [Barr81] [Franklin81] ffi Blobby particles K P all objects f (object; x; y; z) = 0 [Blinn82] * Parametric surfaces S = F (u; v) ffi Bi-cubic parametric patches <ref> [Catmull74] </ref> [Catmull75] ffi Superquadric surfaces (parametric form) [Barr81] [Franklin81] ffi Triangular patches [Sederberg84] * Procedural primitives ffi Particles [Reeves83] ffi Densities [Kajiya84] ffi Fractals [Fournier82] 2.2.2 Light Source Modeling Light enters a scene through or is generated by objects called light sources. Light sources of varying complexity are possible. <p> The depth value of the projected object space point is used independent of its location within the pixel. As long as at least one object point is projected to somewhere within each pixel covered by the object, scan conversion can be done by simple object space subdivision techniques. <ref> [Catmull74] </ref> [Catmull75] used this technique in the original z-buffer implementation to draw bi-cubic parametric 27 patches. With this approximation errors can occur for closely spaced surfaces. 3.1.1.2 The Painter's Algorithm The painter's algorithm is also known as an a priori depth priority algorithm or a list priority algorithm. <p> &gt; &gt; &gt; &gt; &gt; : No Subdivision 8 &gt; &gt; &gt; &gt; &gt; &gt; &gt; : For Each Pixel Test Each Object ( Test First Presorted Ray Trace 2 Test Last Ray Trace [Whitted79] For Each Object Test Each Pixel ( Test First Painter's [Newell72] Test Last - Z-buffer <ref> [Catmull74] </ref> Subdivide by X 8 &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; : For Each Pixel Test Each Object 8 &gt; &gt; &gt; : Test First Global Presorted Scan Ray Trace 2 Test Mid Local Presorted Scan Ray Trace 2 Test Last Scan Ray
Reference: [Catmull75] <author> Edwin E. Catmull, </author> <title> "Computer Display of Curved Surfaces," </title> <journal> Conference on Computer Graphics, Pattern Recognition, and Data Structures, </journal> <note> May 1975 (reprinted in [Freeman80]). </note>
Reference-contexts: +K = 0 [Weiss66] [Goldstein71] ffi Superquadric surfaces Ax n + By n + Cz n + D = 0 [Barr81] [Franklin81] ffi Blobby particles K P all objects f (object; x; y; z) = 0 [Blinn82] * Parametric surfaces S = F (u; v) ffi Bi-cubic parametric patches [Catmull74] <ref> [Catmull75] </ref> ffi Superquadric surfaces (parametric form) [Barr81] [Franklin81] ffi Triangular patches [Sederberg84] * Procedural primitives ffi Particles [Reeves83] ffi Densities [Kajiya84] ffi Fractals [Fournier82] 2.2.2 Light Source Modeling Light enters a scene through or is generated by objects called light sources. Light sources of varying complexity are possible. <p> The depth value of the projected object space point is used independent of its location within the pixel. As long as at least one object point is projected to somewhere within each pixel covered by the object, scan conversion can be done by simple object space subdivision techniques. [Catmull74] <ref> [Catmull75] </ref> used this technique in the original z-buffer implementation to draw bi-cubic parametric 27 patches. With this approximation errors can occur for closely spaced surfaces. 3.1.1.2 The Painter's Algorithm The painter's algorithm is also known as an a priori depth priority algorithm or a list priority algorithm.
Reference: [Catmull78] <author> Edwin E. Catmull, </author> <title> "A Hidden Surface Algorithm with Anti-aliasing," </title> <journal> Computer Graphics, </journal> <volume> Vol. 12, No. 3, </volume> <month> August </month> <year> 1978, </year> <note> (Proceedings of ACM SIGGRAPH 78) (reprinted in [Beatty82]). </note>
Reference-contexts: Antialiasing is required in all visibility determination stages in the image synthesis process, not just the final image formation stage. With respect to computer graphics, aliasing was first extensively discussed by [Crow77b]. Since then attempts to reduce this problem have been an extensive area of research [Crow81] [Feibush80] [Carpenter84] <ref> [Catmull78] </ref> [Catmull84] [Cook84] [Cook86] [Dippe85a] [Dippe85b] [Duff85] [Fiume83] [Fujimoto83] [Grant85] [Hourcade85] [Lee85] [Max85] [Max90] [Porter84] [Reeves87] [Szabo83] [Whit-ted82]. 2.3.2.1 Signals and Samples For the purposed of this discussion, a continuous signal is a function which is defined almost everywhere within some domain. 4 For example, the two-dimensional signal representing the color <p> This method of antialiasing has come to be know as "area averaging." But even this simple formation has only been implemented for polygonal areas of integration. The earliest continuous visibility algorithm to calculate this integral over exact polygon boundaries <ref> [Catmull78] </ref> used a constant weighting function over a one pixel square region of integration. This result was improved by [Feibush80] to an integration region larger than a single pixel and to arbitrary finite-extent radially-symmetric weighting functions. <p> So far, continuous algorithms have been developed only for polygons. The earliest continuous algorithms were [Warnock69], [Hamlin77] and [Weiler77]. Although all of these algorithms processed areas in a continuous manner, they all point sampled the continuous data for conversion to raster format. <ref> [Catmull78] </ref> was the first algorithm to filter the continuous output before sampling as part of the antialiasing process. There are two basic classes of continuous algorithms: scan plane algorithms and subdivision algorithms. <p> This sorting order was overlooked by SSS. Many of the possible combinations of choices of subdivision criteria shown here have yet to be implemented. Deciding exactly when and where to divide to simplify the subproblems is the major difference between algorithms in this family. Algorithms such as <ref> [Catmull78] </ref> [Franklin80] [Catmull84] perform a uniform subdivision in two dimensions to fixed subproblems independent of the input data. <p> Subdivision can be two-dimensional [Warnock69] [Weiler77] [Franklin80] or three-dimensional [Fuchs79] [Fuchs80] [Fujimoto86] [Glassner84] [Samet90] or higher dimensional [Arvo87] [Grant85] [Glassner88]. The subdivisions can be specified in screen coordinates based on dividing the image [Warnock69] <ref> [Catmull78] </ref> [Catmull84] or in object coor dinates based on dividing the scene independent of the viewpoint [Fujimoto86]. The locations of subdivisions can be made independent of the data in the scene [Franklin80] [Catmull78] [Catmull84] or at significant object points [Fuchs79] [Fuchs80] [Weiler77]. <p> The subdivisions can be specified in screen coordinates based on dividing the image [Warnock69] <ref> [Catmull78] </ref> [Catmull84] or in object coor dinates based on dividing the scene independent of the viewpoint [Fujimoto86]. The locations of subdivisions can be made independent of the data in the scene [Franklin80] [Catmull78] [Catmull84] or at significant object points [Fuchs79] [Fuchs80] [Weiler77]. The subdivisions can be orthogonal to the coordinate axes [Samet90] [Bentley79] [Cat-mull78] [Catmull84] [Glassner84] [Kaplan85] [Warnock69] or at arbitrary angles [Fuchs79] [Fuchs80] [Weiler77].
Reference: [Catmull84] <author> Edwin E. Catmull, </author> <title> "An Analytic Visible Surface Algorithm for Independent Pixel Processing," </title> <journal> Computer Graphics Vol. </journal> <volume> 18, No. 3, </volume> <booktitle> (Proceedings of ACM SIGGRAPH 84), </booktitle> <month> July </month> <year> 1984. </year>
Reference-contexts: With respect to computer graphics, aliasing was first extensively discussed by [Crow77b]. Since then attempts to reduce this problem have been an extensive area of research [Crow81] [Feibush80] [Carpenter84] [Catmull78] <ref> [Catmull84] </ref> [Cook84] [Cook86] [Dippe85a] [Dippe85b] [Duff85] [Fiume83] [Fujimoto83] [Grant85] [Hourcade85] [Lee85] [Max85] [Max90] [Porter84] [Reeves87] [Szabo83] [Whit-ted82]. 2.3.2.1 Signals and Samples For the purposed of this discussion, a continuous signal is a function which is defined almost everywhere within some domain. 4 For example, the two-dimensional signal representing the color of <p> The symmetry allowed the number of parameters describing the integral to be reduced low enough so that a lookup table could be used to perform the integration. This greatly reduced the cost of the integration. <ref> [Catmull84] </ref> claimed that the [Feibush80] lookup table technique could be easily extended for pixel values varying linearly in x and y. <p> This sorting order was overlooked by SSS. Many of the possible combinations of choices of subdivision criteria shown here have yet to be implemented. Deciding exactly when and where to divide to simplify the subproblems is the major difference between algorithms in this family. Algorithms such as [Catmull78] [Franklin80] <ref> [Catmull84] </ref> perform a uniform subdivision in two dimensions to fixed subproblems independent of the input data. <p> Subdivision can be two-dimensional [Warnock69] [Weiler77] [Franklin80] or three-dimensional [Fuchs79] [Fuchs80] [Fujimoto86] [Glassner84] [Samet90] or higher dimensional [Arvo87] [Grant85] [Glassner88]. The subdivisions can be specified in screen coordinates based on dividing the image [Warnock69] [Catmull78] <ref> [Catmull84] </ref> or in object coor dinates based on dividing the scene independent of the viewpoint [Fujimoto86]. The locations of subdivisions can be made independent of the data in the scene [Franklin80] [Catmull78] [Catmull84] or at significant object points [Fuchs79] [Fuchs80] [Weiler77]. <p> The subdivisions can be specified in screen coordinates based on dividing the image [Warnock69] [Catmull78] <ref> [Catmull84] </ref> or in object coor dinates based on dividing the scene independent of the viewpoint [Fujimoto86]. The locations of subdivisions can be made independent of the data in the scene [Franklin80] [Catmull78] [Catmull84] or at significant object points [Fuchs79] [Fuchs80] [Weiler77]. The subdivisions can be orthogonal to the coordinate axes [Samet90] [Bentley79] [Cat-mull78] [Catmull84] [Glassner84] [Kaplan85] [Warnock69] or at arbitrary angles [Fuchs79] [Fuchs80] [Weiler77]. The subdivision can be at a fixed resolution [Franklin80] [Cat-mull78] [Catmull84] or adaptive hierarchically [Fuchs79] [Fuchs80] [Glassner84] [Ka-plan85] [Warnock69] <p> The locations of subdivisions can be made independent of the data in the scene [Franklin80] [Catmull78] <ref> [Catmull84] </ref> or at significant object points [Fuchs79] [Fuchs80] [Weiler77]. The subdivisions can be orthogonal to the coordinate axes [Samet90] [Bentley79] [Cat-mull78] [Catmull84] [Glassner84] [Kaplan85] [Warnock69] or at arbitrary angles [Fuchs79] [Fuchs80] [Weiler77]. The subdivision can be at a fixed resolution [Franklin80] [Cat-mull78] [Catmull84] or adaptive hierarchically [Fuchs79] [Fuchs80] [Glassner84] [Ka-plan85] [Warnock69] [Samet90]. <p> of the data in the scene [Franklin80] [Catmull78] <ref> [Catmull84] </ref> or at significant object points [Fuchs79] [Fuchs80] [Weiler77]. The subdivisions can be orthogonal to the coordinate axes [Samet90] [Bentley79] [Cat-mull78] [Catmull84] [Glassner84] [Kaplan85] [Warnock69] or at arbitrary angles [Fuchs79] [Fuchs80] [Weiler77]. The subdivision can be at a fixed resolution [Franklin80] [Cat-mull78] [Catmull84] or adaptive hierarchically [Fuchs79] [Fuchs80] [Glassner84] [Ka-plan85] [Warnock69] [Samet90]. <p> This would require a continuous visible surface algorithm to be invoked at each pixel to determine the contributions to that pixel. This type of extension gives us a continuous algorithm, presorted in depth, with a preliminary subdivision to pixel boundaries. This was done in <ref> [Catmull84] </ref>. This extension makes the algorithm a typical example of an extended (or combination) continuous algorithm and no longer very similar to the point sampled painter's algorithm.
Reference: [Chang83] <author> Arther G. Chang, </author> <title> "Parallel Architectural Support for Ray Tracing Graphics Techniques," </title> <type> Master's Report. </type> <institution> Computer Science Department, University of California, Berkeley, </institution> <month> August </month> <year> 1983. </year> <month> 168 </month>
Reference-contexts: Each ray processor maintains the value of the closest intersection in its local memory. Processors can also be assigned to objects with the rays pipelined through all the object processors <ref> [Chang83] </ref>. A similar software organization can be used on vector processors [Max81] [Plunkett85]. A ray broadcasting architecture is not efficient for object based parallelism since results must be accumulated and compared for each ray. Pipelining the rays allows the intersection test results to be propagated with the ray.
Reference: [Chen85] <author> Lih-Shyang Chen, Gabor T. Herman, R. Anthony Reynolds, Jayaram K. Udupa, </author> <title> "Surface Shading in Cuberille Environments," </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> Vol. 5 No. 15, </volume> <month> December </month> <year> 1985. </year>
Reference-contexts: &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; : 8 &gt; &gt; &gt; &gt; &gt; &gt; &gt; : Object Based ( Presorted - 3d Presort 1 Non-presorted - BSP-tree [Fuchs79] Space Based ( Uniform - Voxel <ref> [Chen85] </ref> Hierarchical - Octree [Samet90] 2d &gt; &gt; &gt; &gt; &gt; &gt; &gt; &lt; Object Based ( Presorted Sorted Clipper [Weiler77] Non-presorted Clipper [Grant85] Space Based ( Uniform - 2d Grid [Franklin80] Hierarchical - Quadtree [Warnock69] Point Sampled Only 8 &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; <p> The octree subdivision is usually not used directly as the primary visibility algorithm. It is more frequently used as a preprocessing step to reduce the complexity some other visibility algorithm such as [Glassner84]. 3.4.2.6 Voxel Regular subdivison of three-dimensional space is common for volume rendering systems <ref> [Chen85] </ref> [Levoy88]. Like the octree sudivision it yields a regular pattern of subre gion overlaps from a given viewpoint. The voxel subdivision and traversal has been used effectively for a hybrid accelerated ray tracing algorithm [Fujimoto86].
Reference: [Chen91] <author> Shenchang Eric Chen, Holly E. Rushmeier, Gavin Miller, Douglas Turner, </author> <title> "A Progressive Multi-pass Method for Global Illumination," </title> <journal> Computer Graphics, </journal> <volume> Vol. 25, No. </volume> <booktitle> 4 (Proceedings of ACM SIGGRAPH 91), </booktitle> <month> July </month> <year> 1991. </year>
Reference-contexts: Small bright objects are better handled by backwards ray tracing. Small bright sections of larger objects have the same problem, these could be formed by caustics. <ref> [Chen91] </ref> presents a complete system which solves this problem by reclassifying bright areas as light sources and using backwards ray tracing from these light sources. Low intensity surfaces are handled using a radiosity solution with non-diffuse form factors. Image formation is done by distribution ray tracing.
Reference: [Chin89] <author> Norman Chin, Steven Feiner, </author> <title> "Near Real-Time Shadow Generation Using BSP-trees," </title> <journal> Computer Graphics, </journal> <volume> Vol. 23, No. </volume> <booktitle> 2 (Proceedings of SIGGRAPH 89), </booktitle> <month> July </month> <year> 1989. </year>
Reference-contexts: Substuting a polygon tree for the frame buffer of the painter's algorithm would yield a BSP-tree based continuous algorithm. Like the octree and voxel subdivisions, the BSP-tree has also been used as a preprocessing subdvision step for other algorithms [Berlin85] [Garcia86] <ref> [Chin89] </ref>. 3.4.3 Combinations of Algorithms 3.4.3.1 One-dimensional Continuous Algorithms Most algorithms, in practice, combine techniques from several of the basic algorithms. As mentioned previously, some scan line algorithms perform the vertical subdivision on each scan line separately and then use a continuous algorithm on the resulting lower dimensional subproblems. <p> The results of this illumination test are used to shade the span. This is a one-dimensional test version of the direct independent class of systems. 93 If the image formation algorithm produces two-dimensional continuous visible areas, each area can be tested for illumination as a unit. [Garcia86] <ref> [Chin89] </ref> presents such an area based direct independent algorithm using a single BSP-tree as the data structure for image formation and illumination testing. <p> This algorithm uses a triangle intersection routine very similar to a ray intersection routine used in ray tracing. Creating a one-dimensional extension of zero-dimensional ray tracing. A two-dimensional direct independent illumination test using a BSP-tree has been implemented by [Garcia86] <ref> [Chin89] </ref>. The beam tracing system of [Heckbert84] is also a two-dimensional direct independent system. Various different two-dimensional systems are possible by using different data structures and subdivision strategies in the illumination test. This assumes that these data structures are already present for use in image formation.
Reference: [Cleary86] <author> J. G. Cleary, B. M. Wyvill, G. M. Birtwistle, R. </author> <title> Vatti "Multiprocessor Ray Tracing," </title> <journal> Computer Graphics Forum, </journal> <volume> Vol. 5, No. </volume> <month> 1 March </month> <year> 1986. </year>
Reference-contexts: This has recently been used as a technique for speeding up ray 47 tracing. [Fujimoto86] uses a three-dimensional space-based uniform subdivision. [Ka-plan85] and [Glassner84] use a three-dimensional space-based hierarchical subdivision. [Rubin80] and [Kay86] use a three-dimensional object-based hierarchical subdivision. [Dippe84] uses a three-dimensional space-based semi-regular subdivision. <ref> [Cleary86] </ref> compares two-dimensional and three-dimensional space-based regular subdivision techniques for ray tracing on a multiprocessor. [Fuchs79] [Fuchs80] uses a three-dimensional object-based subdivision as a preprocessing step for the painter's algorithm. [Franklin80] has shown that proper subdivision can reduce the complexity of visible surface determination to linear in the number of objects
Reference: [Cohen85] <author> Michael F. Cohen, Donald P. Greenberg, </author> <title> "The Hemi-cube: a Radiosity Solution for Complex Environments," </title> <journal> Computer Graphics, </journal> <volume> Vol. </volume> <pages> 19, </pages> <note> No. 3 (Proceedings of ACM SIGGRAPH 85), July 1985 (reprinted in [Joy87]). </note>
Reference-contexts: The usual two-dimensional spatial antialiasing is also included. In the distribution ray tracing systems the resulting high dimensional integral is solved using Monte Carlo integration techniques. 5.2.6 Diffuse Radiosity Rendering Equation The radiosity system, as first presented [Goral84] <ref> [Cohen85] </ref>, is a method for calculating diffuse interreflections, (i.e. part of the indirect illumination) based on methods used in the field of radiative heat transfer [Sparrow78]. <p> This matrix equation is shown below: i o = e + F i o There are two main approaches for solving the resulting matrix equations. These are called shooting and gathering methods. The first radiosity system [Goral84] used Gaussian elimination with partial pivoting to directly solve the matrix equation. <ref> [Cohen85] </ref> was the first to use gathering methods. Because the matrix F is a diagonally-dominate positive-definite matrix, the system is easy to solve with a vari ety of techniques. The efficient Gauss-Siedel iterative technique was used by [Cohen85]. <p> [Goral84] used Gaussian elimination with partial pivoting to directly solve the matrix equation. <ref> [Cohen85] </ref> was the first to use gathering methods. Because the matrix F is a diagonally-dominate positive-definite matrix, the system is easy to solve with a vari ety of techniques. The efficient Gauss-Siedel iterative technique was used by [Cohen85]. One step in the iteration involves solving for a new value of one element of the vector i o n by substituting the current values of the vector i o into the right hand side of the equation and evaluating one line of the matrix multiplication. <p> Thus with this technique it may be wasteful to precompute all the form factors. The form factors are usually generated on the fly during the iteration. The form factors are usually approximated by using a z-buffer algorithm called the "hemi-cube" <ref> [Cohen85] </ref>, although more accurate techniques ae possible [Baum89]. This basic z-buffer algorithm is only good for pure diffuse reflections, LD fl E. One of the greatest difficulties with radiosity algorithms is creating a suitable dis-cretization of the scene.
Reference: [Cohen86] <author> Michael F. Cohen, Donald P. Greenberg, David S. Immel, Phillip J. Brock, </author> <title> "An Efficient Radiosity Approach for Realistic Image Synthesis," </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> Vol. 6, No. 3, </volume> <month> March </month> <year> 1986. </year>
Reference-contexts: It is desirable to use small elements where illumination changes rapidly, such as at shadow boundaries, but it is wasteful to use small elements in areas of uniform illumination. Methods for adaptively subdividing the elements <ref> [Cohen86] </ref> [Campbell90] [Heckbert90] help a great deal. [Hanrahan90] [Hanrahan91] presents a 98 method of subdivision and solving the resulting approximate matrix equation to a fixed error tolerance in linear time.
Reference: [Cook84] <author> Robert L. Cook, Thomas Porter, Loren Carpenter, </author> <title> "Distributed Ray Tracing," </title> <journal> Computer Graphics, </journal> <volume> Vol. </volume> <pages> 18, </pages> <note> No. 3 (Proceedings of ACM SIGGRAPH 84), July 1984 (reprinted in [Joy87]). </note>
Reference-contexts: This type of area light source has been modeled and approximated in several ways. A collection of point sources can approximate an area source [Brotman84]. Light sources can also be directly specified as areas [Nishita83] <ref> [Cook84] </ref>. It is also possible for the light emitting part of a light source to be distributed over a volume of space rather than on a surface, if the light source itself is at least partially transparent. A cloud of glowing gas is an example of such a volume source. <p> With respect to computer graphics, aliasing was first extensively discussed by [Crow77b]. Since then attempts to reduce this problem have been an extensive area of research [Crow81] [Feibush80] [Carpenter84] [Catmull78] [Catmull84] <ref> [Cook84] </ref> [Cook86] [Dippe85a] [Dippe85b] [Duff85] [Fiume83] [Fujimoto83] [Grant85] [Hourcade85] [Lee85] [Max85] [Max90] [Porter84] [Reeves87] [Szabo83] [Whit-ted82]. 2.3.2.1 Signals and Samples For the purposed of this discussion, a continuous signal is a function which is defined almost everywhere within some domain. 4 For example, the two-dimensional signal representing the color of a <p> Monte Carlo techniques do introduce random noise into the output. The magnitude of this noise can be reduced by increasing the number of samples. This random noise is much less visually disturbing than regular patterns. <ref> [Cook84] </ref> [Dippe85b] [Lee85] [Cook86] have shown that varying the locations of the super samples by adding small random offsets caused dramatic improvements in perceived image quality. This is called jittered sampling. <p> Point light sources, perfect mirror reflections, perfect transparency, a single moment in time, and a single fixed viewpoint yield the simple ray tracing paradigm. Area light sources, glossy reflections and refractions, and depth of field yield the more complex distribution ray tracing paradigm. <ref> [Cook84] </ref> originally called the first system in this paradigm "distributed ray tracing," but later many people felt that the name implied distributed pro cessing. [Heckbert90] has suggested the name "distribution ray tracing" hoping that it would be clearer that sample distributions are involved. <p> The ray tracing visibility algorithm for illumination can be combined with any of the other visibility algorithms for image formation yielding five other straightforward systems in this paradigm. The scan line-ray tracing combination has been described previously [Ap-pel68a] [Appel68b] <ref> [Cook84] </ref>. The non-ray tracing visibility algorithms are not suitable for use in the illumination test in zero-dimensional direct independent paradigm systems, because they only work efficiently for determining the visibility of large arrays of pixels and are not efficient processing single pixel visibility tests from different viewpoints.
Reference: [Cook86] <author> Robert L. Cook, </author> <title> "Stochastic Sampling in Computer Graphics," </title> <journal> ACM Transactions on Graphics, </journal> <volume> Vol. 5, No. 1, </volume> <month> January </month> <year> 1986. </year>
Reference-contexts: With respect to computer graphics, aliasing was first extensively discussed by [Crow77b]. Since then attempts to reduce this problem have been an extensive area of research [Crow81] [Feibush80] [Carpenter84] [Catmull78] [Catmull84] [Cook84] <ref> [Cook86] </ref> [Dippe85a] [Dippe85b] [Duff85] [Fiume83] [Fujimoto83] [Grant85] [Hourcade85] [Lee85] [Max85] [Max90] [Porter84] [Reeves87] [Szabo83] [Whit-ted82]. 2.3.2.1 Signals and Samples For the purposed of this discussion, a continuous signal is a function which is defined almost everywhere within some domain. 4 For example, the two-dimensional signal representing the color of a polygonal <p> Monte Carlo techniques do introduce random noise into the output. The magnitude of this noise can be reduced by increasing the number of samples. This random noise is much less visually disturbing than regular patterns. [Cook84] [Dippe85b] [Lee85] <ref> [Cook86] </ref> have shown that varying the locations of the super samples by adding small random offsets caused dramatic improvements in perceived image quality. This is called jittered sampling.
Reference: [Cook87] <author> Robert L. Cook, Loren Carpenter, Edwin E. Catmull, </author> <title> "The Reyes Image Rendering Architecture," </title> <journal> Computer Graphics, </journal> <volume> Vol. 21, No. </volume> <booktitle> 4 (Proceedings of ACM SIGGRAPH 87), </booktitle> <month> July </month> <year> 1987. </year>
Reference-contexts: The algorithms which scan convert primitives, sequentially (z-buffer, painter's) or in parallel (scan line), usually take advantage of the regular spacing of the samples and use fast incremental techniques to step from pixel to pixel. Jittered sampling makes these steps uneven and slows these algorithms. <ref> [Cook87] </ref> describes "REYES" an extended z-buffer algorithm with jittered supersampling. Ray tracing is suitable for any kind of sampling scheme since it is easy to send sample rays in any sequence of directions.
Reference: [Crow77a] <author> Franklin C. Crow, </author> <title> "Shadow Algorithms for Computer Graphics," </title> <journal> Computer Graphics, </journal> <volume> Vol. </volume> <pages> 11, </pages> <note> No. 2 (Proceedings of ACM SIGGRAPH 77), July 1977 (reprinted in [Beatty82]). </note>
Reference-contexts: The painter's algorithm, the scan line algorithm, the scan plane algorithm, and some subdivision algorithms are suitable. Ray tracing, z-buffer, and some forms of subdivision algorithms are not suitable. The only published examples of direct incremental algorithms are scan line shadow algorithms <ref> [Crow77a] </ref> [Bergeron86] [Max86a]. "Shadow polygons" are added to the input database. These polygons start at the edges of ordinary polygons and extend away from the light source. The shadow polygons enclose the volume of space which is shadowed by the ordinary polygon. <p> This advantage is neutralized in the scan line shadow system because the 94 many shadow polygons (there are more shadow polygons than ordinary polygons) extend across most of the scan lines. This problem can be reduced by only using the silhouette edges of the objects to generate shadow polygons <ref> [Crow77a] </ref>, but this introduces the complexity of identifying the silhouette edges in an algorithm that otherwise treats each polygon independently. [Max86a] applies a clever change in coordinate systems to avoid this major inefficiency in the regular image space scan line shadow algorithm. <p> Systems using the scan line visible surface algorithm are the classic examples of this paradigm <ref> [Crow77a] </ref> [Berg eron86] [Max86a]. Since this paradigm involves making one pass thorough the data, the visibility algorithms for illumination and image formation are restricted to operate using the same ordering of primitives.
Reference: [Crow77b] <author> Franklin C. Crow, </author> <title> "The Aliasing Problem in Computer-generated Shaded Images," </title> <journal> Communications of the ACM, </journal> <volume> Vol. 20, No. 11, </volume> <month> November </month> <year> 1977. </year>
Reference-contexts: Proper antialiasing is absolutely essential to creating realistic images. Antialiasing is required in all visibility determination stages in the image synthesis process, not just the final image formation stage. With respect to computer graphics, aliasing was first extensively discussed by <ref> [Crow77b] </ref>. <p> In simple systems the weighting function is held constant over some interval and zero elsewhere. Using a more complex weighting function improves the filtering characteristics but makes the integration much harder. <ref> [Crow77b] </ref> used a rectangular approximation to polygon areas weighted by arbitrary positive separable filter kernels. The rectangular approximation of the region of integration (instead of exact polygon edges) allowed the use of the more complex weighting function and intensity varying linearly in x and y.
Reference: [Crow81] <author> Franklin C. Crow, </author> <title> "A Comparison of Antialiasing Techniques," </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> Vol. 1, No. 1, </volume> <month> January </month> <year> 1981. </year>
Reference-contexts: Antialiasing is required in all visibility determination stages in the image synthesis process, not just the final image formation stage. With respect to computer graphics, aliasing was first extensively discussed by [Crow77b]. Since then attempts to reduce this problem have been an extensive area of research <ref> [Crow81] </ref> [Feibush80] [Carpenter84] [Catmull78] [Catmull84] [Cook84] [Cook86] [Dippe85a] [Dippe85b] [Duff85] [Fiume83] [Fujimoto83] [Grant85] [Hourcade85] [Lee85] [Max85] [Max90] [Porter84] [Reeves87] [Szabo83] [Whit-ted82]. 2.3.2.1 Signals and Samples For the purposed of this discussion, a continuous signal is a function which is defined almost everywhere within some domain. 4 For example, the two-dimensional signal
Reference: [Crow82] <author> Franklin. C. Crow, </author> <title> "A More Flexible Image Generation Environment," </title> <journal> Computer Graphics, </journal> <volume> Vol. 16, No. </volume> <booktitle> 3 (Proceedings of ACM SIGGRAPH 82), </booktitle> <month> July </month> <year> 1982. </year>
Reference-contexts: The basic painter's algorithm can be performed in FTB order by adding a single bit coverage flag to each pixel. FTB was used in the Evans and Sutherland CT5 flight simulator [Schumacker80], a hardware line drawing system [Wein78], and <ref> [Crow82] </ref>. This flag is initialized to indicate that the pixel has not been painted (i.e. is uncovered). When the first (closest) primitive paints over this pixel, the bit is set to indicate that it is now covered. <p> An ff value of one represents complete coverage (opacity) while an ff value of zero represents no coverage (complete transparency). This technique has been extensively used with the painter's algorithm and so-called "2 1/2D" rendering systems <ref> [Crow82] </ref> [Levoy77] [Max85] [Reeves83] [Reeves85] [Stern79] [Wallace81]. The exact value of the intensity contributions of two possibly overlapping antialiased polygon fragments to the intensity of a pixel is a complex calculation which depends on the exact positions of the edges. <p> FTB order was used in the system described in <ref> [Crow82] </ref> but the use of FTB order was not described in the paper. [Porter84] developed a compositing operator assuming that all primitives are uncorrelated. Here we develop a compositing operator using the opposite assumption that all primitives are correlated (ie. negative correlation as defined previously in figure 4.6b).
Reference: [Crow84] <author> Franklin C. Crow, </author> <title> "Summed-area Tables for Texture Mapping," </title> <journal> /it Computer Graphics, </journal> <volume> Vol. 18, No. </volume> <booktitle> 3 (Proceeding of ACM SIGGRAPH 84), </booktitle> <month> July </month> <year> 1984. </year>
Reference-contexts: The problem here is complicated by the fact that the shadow mask (texture map) changes each time it is used. This defeats most preprocessing schemes. Ordinarily very efficient techniques used for static textures, such as summed area tables <ref> [Crow84] </ref>, become very inefficient for dynamic textures. A brute force weighted average of all shadow mask pixels involved is probably optimal within a constant factor in terms of time complexity, since each of those pixels will have to be examined and possibly changed as part of the compositing process.
Reference: [Crow86] <author> Franklin C. </author> <title> Crow, </title> <type> Personal Communication, </type> <month> August </month> <year> 1986. </year> <month> 169 </month>
Reference-contexts: There are primitives for which the uncorrelated edge assumption holds quite well. Particle systems, since particle locations are assumed to be uncorrelated, and semi transparent volumes are examples of such primitives. 58 59 4.2.4.2 Assuming Correlated Objects The following sections are based on the suggestion of <ref> [Crow86] </ref> that painting in FTB order could to solve the background leakage problem. FTB order was used in the system described in [Crow82] but the use of FTB order was not described in the paper. [Porter84] developed a compositing operator assuming that all primitives are uncorrelated.
Reference: [Crow92] <author> Franklin C. </author> <title> Crow, </title> <type> Personal Communication, </type> <month> August </month> <year> 1992. </year>
Reference-contexts: by X 8 &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; : For Each Pixel Test Each Object 8 &gt; &gt; &gt; : Test First Global Presorted Scan Ray Trace 2 Test Mid Local Presorted Scan Ray Trace 2 Test Last Scan Ray Trace <ref> [Crow92] </ref> (Conley) For Each Object Test Each Pixel 8 &gt; &gt; &gt; : Test First Global Scan Painter's [Schumacker69] Test Mid Local Scan Painter's [Sutherland73] Test Last Scan Z-buffer [Myers75] Subdivide by X and Y &gt; &gt; &gt; &lt; Test First Global Presorted Scan Line 2 Test Mid Local Presorted Scan <p> The structure of the algorithm is shown in figure 3.9. This algorithm was implemented by Bob Conley at Ohio State <ref> [Crow92] </ref>.
Reference: [Dippe84] <author> Mark Dippe, John Swensen, </author> <title> "An Adaptive Subdivision Algorithm and Parallel Architecture for Realistic Image Synthesis," </title> <journal> Computer Graphics, </journal> <volume> Vol. 18, No. </volume> <booktitle> 3 (Proceedings of ACM SIGGRAPH 84), </booktitle> <month> July </month> <year> 1984. </year>
Reference-contexts: To utilize object and pixel parallelism, sequential object space subdivision techniques which avoid O (pxy) intersection tests, and avoid database access bottlenecks is complex task with many tradeoffs. Object space can be divided between processors with rays passed between adjacent processors <ref> [Dippe84] </ref>. A fast sequential algorithm can be used within each processor on a subset of the global data. [Dippe84] also uses a dynamic data redistribution scheme for improving the load balancing. The scan line algorithm has several steps with parts that can be executed in parallel [Kaplan79]. <p> Object space can be divided between processors with rays passed between adjacent processors <ref> [Dippe84] </ref>. A fast sequential algorithm can be used within each processor on a subset of the global data. [Dippe84] also uses a dynamic data redistribution scheme for improving the load balancing. The scan line algorithm has several steps with parts that can be executed in parallel [Kaplan79]. The initial sorting of primitives into the Y-buckets can be done in parallel. <p> This has recently been used as a technique for speeding up ray 47 tracing. [Fujimoto86] uses a three-dimensional space-based uniform subdivision. [Ka-plan85] and [Glassner84] use a three-dimensional space-based hierarchical subdivision. [Rubin80] and [Kay86] use a three-dimensional object-based hierarchical subdivision. <ref> [Dippe84] </ref> uses a three-dimensional space-based semi-regular subdivision. [Cleary86] compares two-dimensional and three-dimensional space-based regular subdivision techniques for ray tracing on a multiprocessor. [Fuchs79] [Fuchs80] uses a three-dimensional object-based subdivision as a preprocessing step for the painter's algorithm. [Franklin80] has shown that proper subdivision can reduce the complexity of visible surface determination
Reference: [Dippe85a] <author> Mark A. Z. Dippe, </author> <title> "Antialiasing in Computer Graphics," </title> <type> PhD. Dissertation, </type> <institution> University of California, Berkeley, </institution> <month> April </month> <year> 1985. </year>
Reference-contexts: With respect to computer graphics, aliasing was first extensively discussed by [Crow77b]. Since then attempts to reduce this problem have been an extensive area of research [Crow81] [Feibush80] [Carpenter84] [Catmull78] [Catmull84] [Cook84] [Cook86] <ref> [Dippe85a] </ref> [Dippe85b] [Duff85] [Fiume83] [Fujimoto83] [Grant85] [Hourcade85] [Lee85] [Max85] [Max90] [Porter84] [Reeves87] [Szabo83] [Whit-ted82]. 2.3.2.1 Signals and Samples For the purposed of this discussion, a continuous signal is a function which is defined almost everywhere within some domain. 4 For example, the two-dimensional signal representing the color of a polygonal scene <p> The [Feibush80] technique was extended to linear movement of polygons with an arbitrary finite-extent radially-symmetric time-space weighting function by [Grant85]. [Lien84] shows how to integrate arbitrary polynomials over n-dimensional polyhedra using a similar scheme. This can be used for filtering with polynomial weighting functions. <ref> [Dippe85a] </ref> uses a different approach and uses spatial-temporal tetrahedral Bezier patches as primitives.
Reference: [Dippe85b] <author> Mark A. Z. Dippe, </author> <title> Erling Henry Wold "Antialiasing Through Stochastic Sampling," </title> <journal> Computer Graphics, </journal> <volume> Vol. 19, No. </volume> <booktitle> 3 (Proceedings of ACM SIG-GRAPH 85), </booktitle> <month> July </month> <year> 1985. </year>
Reference-contexts: With respect to computer graphics, aliasing was first extensively discussed by [Crow77b]. Since then attempts to reduce this problem have been an extensive area of research [Crow81] [Feibush80] [Carpenter84] [Catmull78] [Catmull84] [Cook84] [Cook86] [Dippe85a] <ref> [Dippe85b] </ref> [Duff85] [Fiume83] [Fujimoto83] [Grant85] [Hourcade85] [Lee85] [Max85] [Max90] [Porter84] [Reeves87] [Szabo83] [Whit-ted82]. 2.3.2.1 Signals and Samples For the purposed of this discussion, a continuous signal is a function which is defined almost everywhere within some domain. 4 For example, the two-dimensional signal representing the color of a polygonal scene with <p> Monte Carlo techniques do introduce random noise into the output. The magnitude of this noise can be reduced by increasing the number of samples. This random noise is much less visually disturbing than regular patterns. [Cook84] <ref> [Dippe85b] </ref> [Lee85] [Cook86] have shown that varying the locations of the super samples by adding small random offsets caused dramatic improvements in perceived image quality. This is called jittered sampling. <p> Techniques for improving the rate of convergence and hence reducing the number of samples required are called variance reduction techniques. The study of variance reduction techniques applied to image synthesis applications is an active new area of research <ref> [Dippe85b] </ref> [Lee85] [Kajiya86]. 2.4 A Previous Classification of Visibility Algorithms The 1973 taxonomy of Sutherland, Sproull, and Schumacker [Sutherland73] [Suther-land74] is still the most important development in the field of algorithms to solve the visibility problem.
Reference: [Duff85] <author> Tom Duff, </author> <title> "Compositing 3-d Rendered Images," </title> <journal> Computer Graphics, </journal> <volume> Vol. </volume> <pages> 19, </pages> <note> No. 3 (Proceedings of ACM SIGGRAPH'85), July 1985 (reprinted in [Joy87]). </note>
Reference-contexts: With respect to computer graphics, aliasing was first extensively discussed by [Crow77b]. Since then attempts to reduce this problem have been an extensive area of research [Crow81] [Feibush80] [Carpenter84] [Catmull78] [Catmull84] [Cook84] [Cook86] [Dippe85a] [Dippe85b] <ref> [Duff85] </ref> [Fiume83] [Fujimoto83] [Grant85] [Hourcade85] [Lee85] [Max85] [Max90] [Porter84] [Reeves87] [Szabo83] [Whit-ted82]. 2.3.2.1 Signals and Samples For the purposed of this discussion, a continuous signal is a function which is defined almost everywhere within some domain. 4 For example, the two-dimensional signal representing the color of a polygonal scene with the <p> The A-buffer algorithm [Carpenter84] is an extension of the z-buffer algorithm that uses a subpixel coverage mask stored at each pixel (among other things) to provide for finer resolution lateral information, but only a single depth value is stored. <ref> [Duff85] </ref> has a scheme for compositing images where distance is interpolated between z-buffer samples and subpixel resolution object intersections can be inferred. <p> of information stored in the shadow buffer would allow more accurate shadow calculations (locations of primitive edges within a pixel [Carpenter84], silhouette edges [Hourcade85], "alpha" coverage values [Hourcade85], indices to identify objects [Hourcade85], bits to flag which adjacent pixels are covered by the same object with a scheme similar to <ref> [Duff85] </ref>, or other non-point-sampled geometric information), but this additional information could not be calculated by the depth buffer visible surface algorithm without giving up some or all of its advantages. DBSS's based on these restrictions will have some predictable problems. <p> Because the slope of the surface is directly represented in the p1-buffer and used with the x and y coordinates of the transformed point to calculate the depth, large surface slopes do not cause self-shadowing errors. <ref> [Duff85] </ref> uses a related scheme to store a bi-linear depth representation using only one depth value per pixel. The depth value at the corner of each pixel is stored and the depth at interior of the pixel is determined by interpolation between the corner values. <p> This may make the sorting and subdivision requirements simpler. Clearly one combination that will work well is to use the z-buffer algorithm (one of the antialiased versions by [Carpenter84] or <ref> [Duff85] </ref>) for visible surface determination, and use the shadow mask sweep version of the painter's algorithm for the shadows. The advantage here is that these visible surface algorithms can render primitives presented in any order. Therefore the objects need only be sorted with respect to the light source.
Reference: [Feibush80] <author> Eliot A. Feibush, Marc Levoy, Robert L. Cook, </author> <title> "Synthetic Texturing Using Digital Filters," </title> <journal> Computer Graphics, </journal> <volume> Vol. </volume> <pages> 14, </pages> <note> No. 3 (Proceedings of SIG-GRAPH 80) July 1980 (reprinted in [Joy87]). </note>
Reference-contexts: Antialiasing is required in all visibility determination stages in the image synthesis process, not just the final image formation stage. With respect to computer graphics, aliasing was first extensively discussed by [Crow77b]. Since then attempts to reduce this problem have been an extensive area of research [Crow81] <ref> [Feibush80] </ref> [Carpenter84] [Catmull78] [Catmull84] [Cook84] [Cook86] [Dippe85a] [Dippe85b] [Duff85] [Fiume83] [Fujimoto83] [Grant85] [Hourcade85] [Lee85] [Max85] [Max90] [Porter84] [Reeves87] [Szabo83] [Whit-ted82]. 2.3.2.1 Signals and Samples For the purposed of this discussion, a continuous signal is a function which is defined almost everywhere within some domain. 4 For example, the two-dimensional signal representing <p> The earliest continuous visibility algorithm to calculate this integral over exact polygon boundaries [Catmull78] used a constant weighting function over a one pixel square region of integration. This result was improved by <ref> [Feibush80] </ref> to an integration region larger than a single pixel and to arbitrary finite-extent radially-symmetric weighting functions. The symmetry allowed the number of parameters describing the integral to be reduced low enough so that a lookup table could be used to perform the integration. <p> The symmetry allowed the number of parameters describing the integral to be reduced low enough so that a lookup table could be used to perform the integration. This greatly reduced the cost of the integration. [Catmull84] claimed that the <ref> [Feibush80] </ref> lookup table technique could be easily extended for pixel values varying linearly in x and y. The [Feibush80] technique was extended to linear movement of polygons with an arbitrary finite-extent radially-symmetric time-space weighting function by [Grant85]. [Lien84] shows how to integrate arbitrary polynomials over n-dimensional polyhedra using a similar scheme. <p> This greatly reduced the cost of the integration. [Catmull84] claimed that the <ref> [Feibush80] </ref> lookup table technique could be easily extended for pixel values varying linearly in x and y. The [Feibush80] technique was extended to linear movement of polygons with an arbitrary finite-extent radially-symmetric time-space weighting function by [Grant85]. [Lien84] shows how to integrate arbitrary polynomials over n-dimensional polyhedra using a similar scheme.
Reference: [Fishman80] <author> B. Fishman, B. Schachter, </author> <title> "Computer Display of Height Fields," </title> <journal> Computers and Graphics, </journal> <volume> Vol. 5, No. </volume> <month> 2 </month> <year> 1980. </year>
Reference-contexts: It is also the case that simple depth rela tionships exist for volume rendering regularly sampled volumes using projection methods [Levoy88] [Frieder85], non-regularly sampled volumes [Max90b], particle systems [Reeves83] [Reeves85], and height fields <ref> [Fishman80] </ref>. For a more general and efficient solution [Fuchs79] [Fuchs80] uses a binary space partition (BSP) tree to store the objects in the scene. This BSP tree can then be easily traversed in depth priority order.
Reference: [Fiume83] <author> Eugene Fiume, Alain Fournier, Larry Rudolph, </author> <title> "A Parallel Scan Conversion Algorithm with Anti-aliasing for a General-purpose Ultracomputer," </title> <journal> Computer Graphics, </journal> <volume> Vol. 17, No. </volume> <booktitle> 3 (Proceedings of ACM SIGGRAPH 83), </booktitle> <month> July </month> <year> 1983. </year>
Reference-contexts: With respect to computer graphics, aliasing was first extensively discussed by [Crow77b]. Since then attempts to reduce this problem have been an extensive area of research [Crow81] [Feibush80] [Carpenter84] [Catmull78] [Catmull84] [Cook84] [Cook86] [Dippe85a] [Dippe85b] [Duff85] <ref> [Fiume83] </ref> [Fujimoto83] [Grant85] [Hourcade85] [Lee85] [Max85] [Max90] [Porter84] [Reeves87] [Szabo83] [Whit-ted82]. 2.3.2.1 Signals and Samples For the purposed of this discussion, a continuous signal is a function which is defined almost everywhere within some domain. 4 For example, the two-dimensional signal representing the color of a polygonal scene with the color <p> The z-buffer algorithm is easily run in parallel because the basic operations are very independent [Parke80] <ref> [Fiume83] </ref>. Different processors can scan convert different parts of the same primitives into different sections of the image in parallel [Fuchs81] [Fuchs83]. Different processors can also be processing different primitives into the same section of the image at the same time [Fuchs89].
Reference: [Fournier82] <author> Alain Fournier, Don Fussell, Loren C. Carpenter, </author> <title> "Computer Rendering of Stochastic Models," </title> <journal> Communications of the ACM, </journal> <volume> Vol. 25, No. 6, </volume> <month> June </month> <year> 1982. </year>
Reference-contexts: Blobby particles K P all objects f (object; x; y; z) = 0 [Blinn82] * Parametric surfaces S = F (u; v) ffi Bi-cubic parametric patches [Catmull74] [Catmull75] ffi Superquadric surfaces (parametric form) [Barr81] [Franklin81] ffi Triangular patches [Sederberg84] * Procedural primitives ffi Particles [Reeves83] ffi Densities [Kajiya84] ffi Fractals <ref> [Fournier82] </ref> 2.2.2 Light Source Modeling Light enters a scene through or is generated by objects called light sources. Light sources of varying complexity are possible. The simplest possible assumption is that illumination is perfectly uniform throughout the scene. In image synthesis this type of illumination model is called ambient illumination.
Reference: [Franklin80] <author> Wm. Randolph Franklin, </author> <title> "A Linear Time Exact Hidden Surface Algorithm," </title> <journal> Computer Graphics, </journal> <volume> Vol. 14, No. </volume> <booktitle> 3 (Proceedings of ACM SIGGRAPH 80), </booktitle> <month> July </month> <year> 1980. </year>
Reference-contexts: This sorting order was overlooked by SSS. Many of the possible combinations of choices of subdivision criteria shown here have yet to be implemented. Deciding exactly when and where to divide to simplify the subproblems is the major difference between algorithms in this family. Algorithms such as [Catmull78] <ref> [Franklin80] </ref> [Catmull84] perform a uniform subdivision in two dimensions to fixed subproblems independent of the input data. <p> With subdivision algorithms there are many choices of how the subdivision can be made defining different dimensions in a subdivision algorithm space, but there is no single basis algorithm. Subdivision can be two-dimensional [Warnock69] [Weiler77] <ref> [Franklin80] </ref> or three-dimensional [Fuchs79] [Fuchs80] [Fujimoto86] [Glassner84] [Samet90] or higher dimensional [Arvo87] [Grant85] [Glassner88]. The subdivisions can be specified in screen coordinates based on dividing the image [Warnock69] [Catmull78] [Catmull84] or in object coor dinates based on dividing the scene independent of the viewpoint [Fujimoto86]. <p> The subdivisions can be specified in screen coordinates based on dividing the image [Warnock69] [Catmull78] [Catmull84] or in object coor dinates based on dividing the scene independent of the viewpoint [Fujimoto86]. The locations of subdivisions can be made independent of the data in the scene <ref> [Franklin80] </ref> [Catmull78] [Catmull84] or at significant object points [Fuchs79] [Fuchs80] [Weiler77]. The subdivisions can be orthogonal to the coordinate axes [Samet90] [Bentley79] [Cat-mull78] [Catmull84] [Glassner84] [Kaplan85] [Warnock69] or at arbitrary angles [Fuchs79] [Fuchs80] [Weiler77]. The subdivision can be at a fixed resolution [Franklin80] [Cat-mull78] [Catmull84] or adaptive hierarchically [Fuchs79] [Fuchs80] [Glassner84] <p> made independent of the data in the scene <ref> [Franklin80] </ref> [Catmull78] [Catmull84] or at significant object points [Fuchs79] [Fuchs80] [Weiler77]. The subdivisions can be orthogonal to the coordinate axes [Samet90] [Bentley79] [Cat-mull78] [Catmull84] [Glassner84] [Kaplan85] [Warnock69] or at arbitrary angles [Fuchs79] [Fuchs80] [Weiler77]. The subdivision can be at a fixed resolution [Franklin80] [Cat-mull78] [Catmull84] or adaptive hierarchically [Fuchs79] [Fuchs80] [Glassner84] [Ka-plan85] [Warnock69] [Samet90]. <p> : Object Based ( Presorted - 3d Presort 1 Non-presorted - BSP-tree [Fuchs79] Space Based ( Uniform - Voxel [Chen85] Hierarchical - Octree [Samet90] 2d &gt; &gt; &gt; &gt; &gt; &gt; &gt; &lt; Object Based ( Presorted Sorted Clipper [Weiler77] Non-presorted Clipper [Grant85] Space Based ( Uniform - 2d Grid <ref> [Franklin80] </ref> Hierarchical - Quadtree [Warnock69] Point Sampled Only 8 &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; : No <p> Extending the algorithm to handle case 3 is required. One can handle this case directly or allow subdivision along slanted lines after the lowest level of orthogonal subdivision. 3.4.2.2 2d Grid Algorithm <ref> [Franklin80] </ref> performs a similar subdivision in image space into simpler regions. The subdivision is done to a fixed uniform resolution over the entire image. [Franklin80] shows that if the resolution is based on the number of input primitives and the primitives are uniformly distributed in the scene then the average complexity <p> One can handle this case directly or allow subdivision along slanted lines after the lowest level of orthogonal subdivision. 3.4.2.2 2d Grid Algorithm <ref> [Franklin80] </ref> performs a similar subdivision in image space into simpler regions. The subdivision is done to a fixed uniform resolution over the entire image. [Franklin80] shows that if the resolution is based on the number of input primitives and the primitives are uniformly distributed in the scene then the average complexity of each region will be constant. <p> The voxel subdivision and traversal has been used effectively for a hybrid accelerated ray tracing algorithm [Fujimoto86]. Regular subdivision, like octree subdivision, is usually not used directly for visibility determination, but as a preprocess for other algorithms. A three-dimensional extension of <ref> [Franklin80] </ref> seems possible and would likely have similar average time complexity. 3.4.2.7 BSP-tree Algorithm The BSP-tree is a binary tree which at each node divides space with an arbitrary plane. <p> three-dimensional space-based hierarchical subdivision. [Rubin80] and [Kay86] use a three-dimensional object-based hierarchical subdivision. [Dippe84] uses a three-dimensional space-based semi-regular subdivision. [Cleary86] compares two-dimensional and three-dimensional space-based regular subdivision techniques for ray tracing on a multiprocessor. [Fuchs79] [Fuchs80] uses a three-dimensional object-based subdivision as a preprocessing step for the painter's algorithm. <ref> [Franklin80] </ref> has shown that proper subdivision can reduce the complexity of visible surface determination to linear in the number of objects for uniformly distributed primitives. 3.5 Reevaluation of Sutherland, Sproull, and Schumacker SSS made many valid observations based on the visibility algorithms of the time.
Reference: [Franklin81] <author> Wm. Randolph Franklin, Alan H. Barr, </author> <title> "Faster Calculation of Super-quadric Shapes," </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> Vol. 1, No. 3, </volume> <month> July </month> <year> 1981. </year>
Reference-contexts: in figure 2.2. * Polygons [Sutherland73] * Implicit surfaces f (x; y; z) = 0. ffi Quadric surfaces Ax 2 +By 2 +Cz 2 +Dxy+Exz +F yx+Gx+H y+J z +K = 0 [Weiss66] [Goldstein71] ffi Superquadric surfaces Ax n + By n + Cz n + D = 0 [Barr81] <ref> [Franklin81] </ref> ffi Blobby particles K P all objects f (object; x; y; z) = 0 [Blinn82] * Parametric surfaces S = F (u; v) ffi Bi-cubic parametric patches [Catmull74] [Catmull75] ffi Superquadric surfaces (parametric form) [Barr81] [Franklin81] ffi Triangular patches [Sederberg84] * Procedural primitives ffi Particles [Reeves83] ffi Densities [Kajiya84] ffi <p> surfaces Ax n + By n + Cz n + D = 0 [Barr81] <ref> [Franklin81] </ref> ffi Blobby particles K P all objects f (object; x; y; z) = 0 [Blinn82] * Parametric surfaces S = F (u; v) ffi Bi-cubic parametric patches [Catmull74] [Catmull75] ffi Superquadric surfaces (parametric form) [Barr81] [Franklin81] ffi Triangular patches [Sederberg84] * Procedural primitives ffi Particles [Reeves83] ffi Densities [Kajiya84] ffi Fractals [Fournier82] 2.2.2 Light Source Modeling Light enters a scene through or is generated by objects called light sources. Light sources of varying complexity are possible.
Reference: [Freeman80] <editor> Herbert Freeman, (Ed.), </editor> <booktitle> Tutorial and Selected Readings in Interactive Computer Graphics, IEEE, </booktitle> <address> New York 1982. </address>
Reference: [Frieder85] <author> Gideon Frieder, Dan Gordon, R. Anthony Reynolds, </author> <title> "Back-to-front Display of Voxel-based Objects," </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> Vol. 5, No. </volume> <month> 1 January </month> <year> 1985. </year>
Reference-contexts: If only a restricted class of scenes are allowed so that the depth ordering is known a priori, this algorithm is very efficient [Schumacker69]. It is also the case that simple depth rela tionships exist for volume rendering regularly sampled volumes using projection methods [Levoy88] <ref> [Frieder85] </ref>, non-regularly sampled volumes [Max90b], particle systems [Reeves83] [Reeves85], and height fields [Fishman80]. For a more general and efficient solution [Fuchs79] [Fuchs80] uses a binary space partition (BSP) tree to store the objects in the scene. This BSP tree can then be easily traversed in depth priority order.
Reference: [Fuchs79] <author> Henry Fuchs, Zvi M. Kedem, Bruce F. Naylor, </author> <title> "Predetermining Visibility Priority in 3-d Scenes (Preliminary Report)," </title> <journal> Computer Graphics, </journal> <volume> Vol 13, No. </volume> <booktitle> 2 (Proceedings of ACM SIGGRAPH 79), </booktitle> <month> August </month> <year> 1979. </year>
Reference-contexts: It is also the case that simple depth rela tionships exist for volume rendering regularly sampled volumes using projection methods [Levoy88] [Frieder85], non-regularly sampled volumes [Max90b], particle systems [Reeves83] [Reeves85], and height fields [Fishman80]. For a more general and efficient solution <ref> [Fuchs79] </ref> [Fuchs80] uses a binary space partition (BSP) tree to store the objects in the scene. This BSP tree can then be easily traversed in depth priority order. <p> Algorithms such as [Warnock69] and others using octree or quadtree data structures use object information to decide whether to subdivide, but only subdivide when necessary at fixed locations in a hierarchical manner and only divide to a fixed maximum depth, the size of a pixel. Algorithms such as <ref> [Fuchs79] </ref> [Fuchs80] 31 [Weiler77] subdivide directly at the locations of the objects. Subdivision can be performed in two dimensions in the image coordinate system [Warnock69] or in the object coordinate system in three dimensions as in [Fuchs79] [Fuchs80]. <p> Algorithms such as <ref> [Fuchs79] </ref> [Fuchs80] 31 [Weiler77] subdivide directly at the locations of the objects. Subdivision can be performed in two dimensions in the image coordinate system [Warnock69] or in the object coordinate system in three dimensions as in [Fuchs79] [Fuchs80]. Subdivision methods can divide the problem into smaller subproblems and then use some other visibility algorithm to solve the subproblems. <p> With subdivision algorithms there are many choices of how the subdivision can be made defining different dimensions in a subdivision algorithm space, but there is no single basis algorithm. Subdivision can be two-dimensional [Warnock69] [Weiler77] [Franklin80] or three-dimensional <ref> [Fuchs79] </ref> [Fuchs80] [Fujimoto86] [Glassner84] [Samet90] or higher dimensional [Arvo87] [Grant85] [Glassner88]. The subdivisions can be specified in screen coordinates based on dividing the image [Warnock69] [Catmull78] [Catmull84] or in object coor dinates based on dividing the scene independent of the viewpoint [Fujimoto86]. <p> The locations of subdivisions can be made independent of the data in the scene [Franklin80] [Catmull78] [Catmull84] or at significant object points <ref> [Fuchs79] </ref> [Fuchs80] [Weiler77]. The subdivisions can be orthogonal to the coordinate axes [Samet90] [Bentley79] [Cat-mull78] [Catmull84] [Glassner84] [Kaplan85] [Warnock69] or at arbitrary angles [Fuchs79] [Fuchs80] [Weiler77]. The subdivision can be at a fixed resolution [Franklin80] [Cat-mull78] [Catmull84] or adaptive hierarchically [Fuchs79] [Fuchs80] [Glassner84] [Ka-plan85] [Warnock69] [Samet90]. <p> The locations of subdivisions can be made independent of the data in the scene [Franklin80] [Catmull78] [Catmull84] or at significant object points <ref> [Fuchs79] </ref> [Fuchs80] [Weiler77]. The subdivisions can be orthogonal to the coordinate axes [Samet90] [Bentley79] [Cat-mull78] [Catmull84] [Glassner84] [Kaplan85] [Warnock69] or at arbitrary angles [Fuchs79] [Fuchs80] [Weiler77]. The subdivision can be at a fixed resolution [Franklin80] [Cat-mull78] [Catmull84] or adaptive hierarchically [Fuchs79] [Fuchs80] [Glassner84] [Ka-plan85] [Warnock69] [Samet90]. <p> the scene [Franklin80] [Catmull78] [Catmull84] or at significant object points <ref> [Fuchs79] </ref> [Fuchs80] [Weiler77]. The subdivisions can be orthogonal to the coordinate axes [Samet90] [Bentley79] [Cat-mull78] [Catmull84] [Glassner84] [Kaplan85] [Warnock69] or at arbitrary angles [Fuchs79] [Fuchs80] [Weiler77]. The subdivision can be at a fixed resolution [Franklin80] [Cat-mull78] [Catmull84] or adaptive hierarchically [Fuchs79] [Fuchs80] [Glassner84] [Ka-plan85] [Warnock69] [Samet90]. The subdivision can be based on presorting the input primitives [Weiler77] or the input primitives can be processed in any order. 3.4 A New Classification of Visibility Algorithms In this section the new taxonomy of the basic visibility algorithms is presented. <p> Z Direction Plane Push 2 Subdivision 8 &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; : 8 &gt; &gt; &gt; &gt; &gt; &gt; &gt; : Object Based ( Presorted - 3d Presort 1 Non-presorted - BSP-tree <ref> [Fuchs79] </ref> Space Based ( Uniform - Voxel [Chen85] Hierarchical - Octree [Samet90] 2d &gt; &gt; &gt; &gt; &gt; &gt; &gt; &lt; Object Based ( Presorted Sorted Clipper [Weiler77] Non-presorted Clipper [Grant85] Space Based ( Uniform - 2d Grid [Franklin80] Hierarchical - Quadtree [Warnock69] Point Sampled Only 8 &gt; &gt; &gt; &gt; <p> Like the octree and voxel methods, this is a technique for subdividing and traversing space in an order consistant with visibility calculations. The BSP-tree was first used as the sorting pass for the painter's algorithm <ref> [Fuchs79] </ref>. Substuting a polygon tree for the frame buffer of the painter's algorithm would yield a BSP-tree based continuous algorithm. <p> ray 47 tracing. [Fujimoto86] uses a three-dimensional space-based uniform subdivision. [Ka-plan85] and [Glassner84] use a three-dimensional space-based hierarchical subdivision. [Rubin80] and [Kay86] use a three-dimensional object-based hierarchical subdivision. [Dippe84] uses a three-dimensional space-based semi-regular subdivision. [Cleary86] compares two-dimensional and three-dimensional space-based regular subdivision techniques for ray tracing on a multiprocessor. <ref> [Fuchs79] </ref> [Fuchs80] uses a three-dimensional object-based subdivision as a preprocessing step for the painter's algorithm. [Franklin80] has shown that proper subdivision can reduce the complexity of visible surface determination to linear in the number of objects for uniformly distributed primitives. 3.5 Reevaluation of Sutherland, Sproull, and Schumacker SSS made many valid <p> One possible sorting order was overlooked in this study, sorting in all three dimensions at the same time, the (XYZ) order. This sorting order corresponds to algorithms that use a three-dimensional data structure and sort such as the octree [Samet90], BSP tree <ref> [Fuchs79] </ref> [Fuchs80] or k-d tree [Bentley79]. The use of coherence to speed algorithms has not advanced much. One reason for this is that the average size primitive has shrunk over the years as computer generated scenes get more and more complex.
Reference: [Fuchs80] <author> Henry Fuchs, Zvi M. Kedem, Bruce F. Naylor, </author> <title> "On Visible Surface Generation by a Priori Tree Structures," </title> <journal> Computer Graphics, </journal> <volume> Vol. 14, </volume> <booktitle> No.3 (Proceedings of ACM SIGGRAPH 80), </booktitle> <month> July </month> <year> 1980. </year> <month> 170 </month>
Reference-contexts: It is also the case that simple depth rela tionships exist for volume rendering regularly sampled volumes using projection methods [Levoy88] [Frieder85], non-regularly sampled volumes [Max90b], particle systems [Reeves83] [Reeves85], and height fields [Fishman80]. For a more general and efficient solution [Fuchs79] <ref> [Fuchs80] </ref> uses a binary space partition (BSP) tree to store the objects in the scene. This BSP tree can then be easily traversed in depth priority order. <p> Algorithms such as [Warnock69] and others using octree or quadtree data structures use object information to decide whether to subdivide, but only subdivide when necessary at fixed locations in a hierarchical manner and only divide to a fixed maximum depth, the size of a pixel. Algorithms such as [Fuchs79] <ref> [Fuchs80] </ref> 31 [Weiler77] subdivide directly at the locations of the objects. Subdivision can be performed in two dimensions in the image coordinate system [Warnock69] or in the object coordinate system in three dimensions as in [Fuchs79] [Fuchs80]. <p> Algorithms such as [Fuchs79] <ref> [Fuchs80] </ref> 31 [Weiler77] subdivide directly at the locations of the objects. Subdivision can be performed in two dimensions in the image coordinate system [Warnock69] or in the object coordinate system in three dimensions as in [Fuchs79] [Fuchs80]. Subdivision methods can divide the problem into smaller subproblems and then use some other visibility algorithm to solve the subproblems. <p> With subdivision algorithms there are many choices of how the subdivision can be made defining different dimensions in a subdivision algorithm space, but there is no single basis algorithm. Subdivision can be two-dimensional [Warnock69] [Weiler77] [Franklin80] or three-dimensional [Fuchs79] <ref> [Fuchs80] </ref> [Fujimoto86] [Glassner84] [Samet90] or higher dimensional [Arvo87] [Grant85] [Glassner88]. The subdivisions can be specified in screen coordinates based on dividing the image [Warnock69] [Catmull78] [Catmull84] or in object coor dinates based on dividing the scene independent of the viewpoint [Fujimoto86]. <p> The locations of subdivisions can be made independent of the data in the scene [Franklin80] [Catmull78] [Catmull84] or at significant object points [Fuchs79] <ref> [Fuchs80] </ref> [Weiler77]. The subdivisions can be orthogonal to the coordinate axes [Samet90] [Bentley79] [Cat-mull78] [Catmull84] [Glassner84] [Kaplan85] [Warnock69] or at arbitrary angles [Fuchs79] [Fuchs80] [Weiler77]. The subdivision can be at a fixed resolution [Franklin80] [Cat-mull78] [Catmull84] or adaptive hierarchically [Fuchs79] [Fuchs80] [Glassner84] [Ka-plan85] [Warnock69] [Samet90]. <p> The locations of subdivisions can be made independent of the data in the scene [Franklin80] [Catmull78] [Catmull84] or at significant object points [Fuchs79] <ref> [Fuchs80] </ref> [Weiler77]. The subdivisions can be orthogonal to the coordinate axes [Samet90] [Bentley79] [Cat-mull78] [Catmull84] [Glassner84] [Kaplan85] [Warnock69] or at arbitrary angles [Fuchs79] [Fuchs80] [Weiler77]. The subdivision can be at a fixed resolution [Franklin80] [Cat-mull78] [Catmull84] or adaptive hierarchically [Fuchs79] [Fuchs80] [Glassner84] [Ka-plan85] [Warnock69] [Samet90]. <p> scene [Franklin80] [Catmull78] [Catmull84] or at significant object points [Fuchs79] <ref> [Fuchs80] </ref> [Weiler77]. The subdivisions can be orthogonal to the coordinate axes [Samet90] [Bentley79] [Cat-mull78] [Catmull84] [Glassner84] [Kaplan85] [Warnock69] or at arbitrary angles [Fuchs79] [Fuchs80] [Weiler77]. The subdivision can be at a fixed resolution [Franklin80] [Cat-mull78] [Catmull84] or adaptive hierarchically [Fuchs79] [Fuchs80] [Glassner84] [Ka-plan85] [Warnock69] [Samet90]. The subdivision can be based on presorting the input primitives [Weiler77] or the input primitives can be processed in any order. 3.4 A New Classification of Visibility Algorithms In this section the new taxonomy of the basic visibility algorithms is presented. <p> 47 tracing. [Fujimoto86] uses a three-dimensional space-based uniform subdivision. [Ka-plan85] and [Glassner84] use a three-dimensional space-based hierarchical subdivision. [Rubin80] and [Kay86] use a three-dimensional object-based hierarchical subdivision. [Dippe84] uses a three-dimensional space-based semi-regular subdivision. [Cleary86] compares two-dimensional and three-dimensional space-based regular subdivision techniques for ray tracing on a multiprocessor. [Fuchs79] <ref> [Fuchs80] </ref> uses a three-dimensional object-based subdivision as a preprocessing step for the painter's algorithm. [Franklin80] has shown that proper subdivision can reduce the complexity of visible surface determination to linear in the number of objects for uniformly distributed primitives. 3.5 Reevaluation of Sutherland, Sproull, and Schumacker SSS made many valid observations <p> One possible sorting order was overlooked in this study, sorting in all three dimensions at the same time, the (XYZ) order. This sorting order corresponds to algorithms that use a three-dimensional data structure and sort such as the octree [Samet90], BSP tree [Fuchs79] <ref> [Fuchs80] </ref> or k-d tree [Bentley79]. The use of coherence to speed algorithms has not advanced much. One reason for this is that the average size primitive has shrunk over the years as computer generated scenes get more and more complex. Thus the amount of available coherence gets smaller and smaller.
Reference: [Fuchs81] <author> Henry Fuchs, John Poulton, </author> <title> "Pixel-planes : a VLSI-oriented Design for a Raster Graphics Engine," </title> <booktitle> VLSI Design, </booktitle> <volume> Vol. 3, No. 3, </volume> <year> 1981. </year>
Reference-contexts: The z-buffer algorithm is easily run in parallel because the basic operations are very independent [Parke80] [Fiume83]. Different processors can scan convert different parts of the same primitives into different sections of the image in parallel <ref> [Fuchs81] </ref> [Fuchs83]. Different processors can also be processing different primitives into the same section of the image at the same time [Fuchs89].
Reference: [Fuchs83] <author> Henry Fuchs, Gregory D. Abram, Eric D. Grant, </author> <title> "Near Real-time Shaded Display of Rigid Objects," </title> <journal> Computer Graphics, </journal> <volume> Vol. 17, No. </volume> <booktitle> 3 (Proceedings of ACM SIGGRAPH 83), </booktitle> <month> July </month> <year> 1983. </year>
Reference-contexts: The z-buffer algorithm is easily run in parallel because the basic operations are very independent [Parke80] [Fiume83]. Different processors can scan convert different parts of the same primitives into different sections of the image in parallel [Fuchs81] <ref> [Fuchs83] </ref>. Different processors can also be processing different primitives into the same section of the image at the same time [Fuchs89].
Reference: [Fuchs85] <author> Henry Fuchs, Jack Goldfeather, Jeff P. Hultquist, Susan Spach, John D. Austin, Frederick P. Brooks Jr, John G. Eyles, John Poulton, </author> <title> "Fast Spheres, Shadows, Textures, Transparencies, and Image Enhancements in Pixel-planes," </title> <journal> Computer Graphics, </journal> <volume> Vol. 19, No. </volume> <booktitle> 3 (Proceedings of ACM SIGGRAPH 85), </booktitle> <month> July </month> <year> 1985. </year>
Reference-contexts: A shading pass is then conducted once the illumination is determined. This algorithm does not have the illumination determination errors of [Williams78] because all sampling is done at the same set of sample points in the same coordinate system. <ref> [Fuchs85] </ref> implement this algorithm on the massively parallel pixel-planes machine, which can perform the many tests at each pixel in parallel.
Reference: [Fuchs89] <author> Henry Fuchs, John Poulton, John G. Eyles, Trey Greer, Jack Goldfeather, David Ellsworth, Steve Molnar, Greg Turk, Brice Tebbs, Laura Israel, </author> <title> "Pixel-Planes 5: A Heterogenoius Multiprocessor Graphics System Using Processor-Enhanced Memories," </title> <journal> Computer Graphics, </journal> <volume> Vol. 23, No. </volume> <booktitle> 3 (Proceedings of ACM SIGGRAPH 89), </booktitle> <month> July </month> <year> 1989. </year>
Reference-contexts: Different processors can scan convert different parts of the same primitives into different sections of the image in parallel [Fuchs81] [Fuchs83]. Different processors can also be processing different primitives into the same section of the image at the same time <ref> [Fuchs89] </ref>. This can be done by synchronizing on operations in the frame and depth buffers, or by keeping separate frame and depth buffers for each processor and merging the buffers after all primitives are processed [Weinberg81] [Molnar92].
Reference: [Fujimoto83] <author> Akira Fujimoto, </author> <title> Kansei Iwata "Jag-free Images on Raster Displays," </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> Vol. 3, No. 9, </volume> <month> December </month> <year> 1983. </year>
Reference-contexts: With respect to computer graphics, aliasing was first extensively discussed by [Crow77b]. Since then attempts to reduce this problem have been an extensive area of research [Crow81] [Feibush80] [Carpenter84] [Catmull78] [Catmull84] [Cook84] [Cook86] [Dippe85a] [Dippe85b] [Duff85] [Fiume83] <ref> [Fujimoto83] </ref> [Grant85] [Hourcade85] [Lee85] [Max85] [Max90] [Porter84] [Reeves87] [Szabo83] [Whit-ted82]. 2.3.2.1 Signals and Samples For the purposed of this discussion, a continuous signal is a function which is defined almost everywhere within some domain. 4 For example, the two-dimensional signal representing the color of a polygonal scene with the color defined
Reference: [Fujimoto86] <author> Akira Fujimoto, Takayuki Tanaka, Kansei Iwata, </author> <title> "ARTS: Accelerated Ray-tracing System," </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> Vol. 6, No. 4, </volume> <month> April </month> <year> 1986. </year>
Reference-contexts: The first section with an intersection terminates the process without testing farther sections. Different researchers have used various policies for dividing the object space into sections <ref> [Fujimoto86] </ref> [Glassner84] [Kaplan85]. The ray tracing algorithm that we consider for classification in this chapter does not include any of the enhancements mentioned in this paragraph, however these enhancements are necessary in real systems to give acceptable performance.. <p> With subdivision algorithms there are many choices of how the subdivision can be made defining different dimensions in a subdivision algorithm space, but there is no single basis algorithm. Subdivision can be two-dimensional [Warnock69] [Weiler77] [Franklin80] or three-dimensional [Fuchs79] [Fuchs80] <ref> [Fujimoto86] </ref> [Glassner84] [Samet90] or higher dimensional [Arvo87] [Grant85] [Glassner88]. The subdivisions can be specified in screen coordinates based on dividing the image [Warnock69] [Catmull78] [Catmull84] or in object coor dinates based on dividing the scene independent of the viewpoint [Fujimoto86]. <p> Subdivision can be two-dimensional [Warnock69] [Weiler77] [Franklin80] or three-dimensional [Fuchs79] [Fuchs80] <ref> [Fujimoto86] </ref> [Glassner84] [Samet90] or higher dimensional [Arvo87] [Grant85] [Glassner88]. The subdivisions can be specified in screen coordinates based on dividing the image [Warnock69] [Catmull78] [Catmull84] or in object coor dinates based on dividing the scene independent of the viewpoint [Fujimoto86]. The locations of subdivisions can be made independent of the data in the scene [Franklin80] [Catmull78] [Catmull84] or at significant object points [Fuchs79] [Fuchs80] [Weiler77]. The subdivisions can be orthogonal to the coordinate axes [Samet90] [Bentley79] [Cat-mull78] [Catmull84] [Glassner84] [Kaplan85] [Warnock69] or at arbitrary angles [Fuchs79] [Fuchs80] [Weiler77]. <p> Like the octree sudivision it yields a regular pattern of subre gion overlaps from a given viewpoint. The voxel subdivision and traversal has been used effectively for a hybrid accelerated ray tracing algorithm <ref> [Fujimoto86] </ref>. Regular subdivision, like octree subdivision, is usually not used directly for visibility determination, but as a preprocess for other algorithms. <p> The subdivision reduces the size of the problems that the rest of the algorithm must solve. This has recently been used as a technique for speeding up ray 47 tracing. <ref> [Fujimoto86] </ref> uses a three-dimensional space-based uniform subdivision. [Ka-plan85] and [Glassner84] use a three-dimensional space-based hierarchical subdivision. [Rubin80] and [Kay86] use a three-dimensional object-based hierarchical subdivision. [Dippe84] uses a three-dimensional space-based semi-regular subdivision. [Cleary86] compares two-dimensional and three-dimensional space-based regular subdivision techniques for ray tracing on a multiprocessor. [Fuchs79] [Fuchs80] uses a <p> In research environments, the most popular algorithm has been ray tracing, because of the great flexibility of the algorithm. Early ray tracing algorithms suffered from great slowness and severe aliasing, but many recent advances have made ray tracing competitive with the other algorithms, especially subdivision preprocessing <ref> [Fujimoto86] </ref> [Glassner84] [Kaplan85]. Ray tracing is no longer the brute-force technique it once was. 3.7 Summary In this chapter a new taxonomy of visible surface algorithms has been presented. This taxonomy is based on the basic structure of the algorithms studied. <p> This is the basis for many advanced combination visibility algorithms: use a subdivision algorithm to build a spatial data structure then use this data structure to control ray tracing. The three dimensional subdivision-ray tracing combination has proven to be very useful <ref> [Fujimoto86] </ref> [Glassner84] [Kaplan85]. 4.1.4 Global Presorted Scan Ray Trace Algorithm The scan presorted ray trace algorithm starts by subdividing the scene into scan lines. Then the presorted ray trace algorithm is applied to each scan line. The active objects on the scan line are sorted by depth.
Reference: [Galimberti69] <author> R. Galimberti, U. Montanari, </author> <title> "An Algorithm for Hidden Line Elimination," </title> <journal> Communications of the ACM, </journal> <volume> Vol. 12, No. 4, </volume> <month> April </month> <year> 1969. </year>
Reference-contexts: Each of the eight visible surface algorithms studied (six published at the time [Watkins69] [Bouknight69] [Romney70] [Warnock69] [Newell72] [Schumacker69]) solved essentially the same version of the visibility problem, point sampling with planar polygons. There were no continuous visible surface algorithms at that time. Four visible line algorithms ([Roberts63] <ref> [Galimberti69] </ref> [Loutrell67] [Appel67]) were also considered. The taxonomy that resulted from this study is shown in figure 2.6. This figure and its interpretation is one of the important results of this study. There were several associations noted in the taxonomy.
Reference: [Garcia86] <author> A. Garcia, </author> <title> "Efficient Rendering of Synthetic Images," </title> <type> Ph.D. Thesis, </type> <institution> Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, </institution> <year> 1986. </year>
Reference-contexts: Substuting a polygon tree for the frame buffer of the painter's algorithm would yield a BSP-tree based continuous algorithm. Like the octree and voxel subdivisions, the BSP-tree has also been used as a preprocessing subdvision step for other algorithms [Berlin85] <ref> [Garcia86] </ref> [Chin89]. 3.4.3 Combinations of Algorithms 3.4.3.1 One-dimensional Continuous Algorithms Most algorithms, in practice, combine techniques from several of the basic algorithms. As mentioned previously, some scan line algorithms perform the vertical subdivision on each scan line separately and then use a continuous algorithm on the resulting lower dimensional subproblems. <p> The results of this illumination test are used to shade the span. This is a one-dimensional test version of the direct independent class of systems. 93 If the image formation algorithm produces two-dimensional continuous visible areas, each area can be tested for illumination as a unit. <ref> [Garcia86] </ref> [Chin89] presents such an area based direct independent algorithm using a single BSP-tree as the data structure for image formation and illumination testing. <p> This algorithm uses a triangle intersection routine very similar to a ray intersection routine used in ray tracing. Creating a one-dimensional extension of zero-dimensional ray tracing. A two-dimensional direct independent illumination test using a BSP-tree has been implemented by <ref> [Garcia86] </ref> [Chin89]. The beam tracing system of [Heckbert84] is also a two-dimensional direct independent system. Various different two-dimensional systems are possible by using different data structures and subdivision strategies in the illumination test. This assumes that these data structures are already present for use in image formation.
Reference: [Glassner84] <author> Andrew S. Glassner, </author> <title> "Space Subdivision for Fast Ray Tracing," </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> Vol. 4, No. 10, </volume> <month> October </month> <year> 1984. </year>
Reference-contexts: The first section with an intersection terminates the process without testing farther sections. Different researchers have used various policies for dividing the object space into sections [Fujimoto86] <ref> [Glassner84] </ref> [Kaplan85]. The ray tracing algorithm that we consider for classification in this chapter does not include any of the enhancements mentioned in this paragraph, however these enhancements are necessary in real systems to give acceptable performance.. <p> With subdivision algorithms there are many choices of how the subdivision can be made defining different dimensions in a subdivision algorithm space, but there is no single basis algorithm. Subdivision can be two-dimensional [Warnock69] [Weiler77] [Franklin80] or three-dimensional [Fuchs79] [Fuchs80] [Fujimoto86] <ref> [Glassner84] </ref> [Samet90] or higher dimensional [Arvo87] [Grant85] [Glassner88]. The subdivisions can be specified in screen coordinates based on dividing the image [Warnock69] [Catmull78] [Catmull84] or in object coor dinates based on dividing the scene independent of the viewpoint [Fujimoto86]. <p> The locations of subdivisions can be made independent of the data in the scene [Franklin80] [Catmull78] [Catmull84] or at significant object points [Fuchs79] [Fuchs80] [Weiler77]. The subdivisions can be orthogonal to the coordinate axes [Samet90] [Bentley79] [Cat-mull78] [Catmull84] <ref> [Glassner84] </ref> [Kaplan85] [Warnock69] or at arbitrary angles [Fuchs79] [Fuchs80] [Weiler77]. The subdivision can be at a fixed resolution [Franklin80] [Cat-mull78] [Catmull84] or adaptive hierarchically [Fuchs79] [Fuchs80] [Glassner84] [Ka-plan85] [Warnock69] [Samet90]. <p> The subdivisions can be orthogonal to the coordinate axes [Samet90] [Bentley79] [Cat-mull78] [Catmull84] <ref> [Glassner84] </ref> [Kaplan85] [Warnock69] or at arbitrary angles [Fuchs79] [Fuchs80] [Weiler77]. The subdivision can be at a fixed resolution [Franklin80] [Cat-mull78] [Catmull84] or adaptive hierarchically [Fuchs79] [Fuchs80] [Glassner84] [Ka-plan85] [Warnock69] [Samet90]. The subdivision can be based on presorting the input primitives [Weiler77] or the input primitives can be processed in any order. 3.4 A New Classification of Visibility Algorithms In this section the new taxonomy of the basic visibility algorithms is presented. <p> A two-dimensional quadtree data structure can be used to hold the image generated from binary octree objects. The octree subdivision is usually not used directly as the primary visibility algorithm. It is more frequently used as a preprocessing step to reduce the complexity some other visibility algorithm such as <ref> [Glassner84] </ref>. 3.4.2.6 Voxel Regular subdivison of three-dimensional space is common for volume rendering systems [Chen85] [Levoy88]. Like the octree sudivision it yields a regular pattern of subre gion overlaps from a given viewpoint. The voxel subdivision and traversal has been used effectively for a hybrid accelerated ray tracing algorithm [Fujimoto86]. <p> The subdivision reduces the size of the problems that the rest of the algorithm must solve. This has recently been used as a technique for speeding up ray 47 tracing. [Fujimoto86] uses a three-dimensional space-based uniform subdivision. [Ka-plan85] and <ref> [Glassner84] </ref> use a three-dimensional space-based hierarchical subdivision. [Rubin80] and [Kay86] use a three-dimensional object-based hierarchical subdivision. [Dippe84] uses a three-dimensional space-based semi-regular subdivision. [Cleary86] compares two-dimensional and three-dimensional space-based regular subdivision techniques for ray tracing on a multiprocessor. [Fuchs79] [Fuchs80] uses a three-dimensional object-based subdivision as a preprocessing step for the <p> In research environments, the most popular algorithm has been ray tracing, because of the great flexibility of the algorithm. Early ray tracing algorithms suffered from great slowness and severe aliasing, but many recent advances have made ray tracing competitive with the other algorithms, especially subdivision preprocessing [Fujimoto86] <ref> [Glassner84] </ref> [Kaplan85]. Ray tracing is no longer the brute-force technique it once was. 3.7 Summary In this chapter a new taxonomy of visible surface algorithms has been presented. This taxonomy is based on the basic structure of the algorithms studied. There are two main divisions, point sampling and continuous algorithms. <p> This is the basis for many advanced combination visibility algorithms: use a subdivision algorithm to build a spatial data structure then use this data structure to control ray tracing. The three dimensional subdivision-ray tracing combination has proven to be very useful [Fujimoto86] <ref> [Glassner84] </ref> [Kaplan85]. 4.1.4 Global Presorted Scan Ray Trace Algorithm The scan presorted ray trace algorithm starts by subdividing the scene into scan lines. Then the presorted ray trace algorithm is applied to each scan line. The active objects on the scan line are sorted by depth.
Reference: [Glassner88] <author> Andrew S. Glassner, </author> <title> "Spacetime Ray Tracing for Animation," </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> Vol. 8, No. 2, </volume> <month> March </month> <year> 1988. </year>
Reference-contexts: With subdivision algorithms there are many choices of how the subdivision can be made defining different dimensions in a subdivision algorithm space, but there is no single basis algorithm. Subdivision can be two-dimensional [Warnock69] [Weiler77] [Franklin80] or three-dimensional [Fuchs79] [Fuchs80] [Fujimoto86] [Glassner84] [Samet90] or higher dimensional [Arvo87] [Grant85] <ref> [Glassner88] </ref>. The subdivisions can be specified in screen coordinates based on dividing the image [Warnock69] [Catmull78] [Catmull84] or in object coor dinates based on dividing the scene independent of the viewpoint [Fujimoto86].
Reference: [Goldstein71] <author> R. A. Goldstein, R. Nagel, </author> <title> "3d Visual Simulation," </title> <journal> Simulation, </journal> <volume> Vol. 16 No. 1, </volume> <month> January </month> <year> 1971. </year>
Reference-contexts: Some of the different types of primitives are listed here in figure 2.2. * Polygons [Sutherland73] * Implicit surfaces f (x; y; z) = 0. ffi Quadric surfaces Ax 2 +By 2 +Cz 2 +Dxy+Exz +F yx+Gx+H y+J z +K = 0 [Weiss66] <ref> [Goldstein71] </ref> ffi Superquadric surfaces Ax n + By n + Cz n + D = 0 [Barr81] [Franklin81] ffi Blobby particles K P all objects f (object; x; y; z) = 0 [Blinn82] * Parametric surfaces S = F (u; v) ffi Bi-cubic parametric patches [Catmull74] [Catmull75] ffi Superquadric surfaces (parametric
Reference: [Goral84] <author> Cindy M. Goral, Kenneth E. Torrance, Donald P. Greenberg, </author> <title> "Modeling the Interaction of Light Between Diffuse Surfaces," </title> <journal> Computer Graphics, </journal> <volume> Vol. 18, No. </volume> <booktitle> 3 (Proceedings of ACM SIGGRAPH 84), </booktitle> <month> July </month> <year> 1984. </year>
Reference-contexts: The usual two-dimensional spatial antialiasing is also included. In the distribution ray tracing systems the resulting high dimensional integral is solved using Monte Carlo integration techniques. 5.2.6 Diffuse Radiosity Rendering Equation The radiosity system, as first presented <ref> [Goral84] </ref> [Cohen85], is a method for calculating diffuse interreflections, (i.e. part of the indirect illumination) based on methods used in the field of radiative heat transfer [Sparrow78]. <p> This matrix equation is shown below: i o = e + F i o There are two main approaches for solving the resulting matrix equations. These are called shooting and gathering methods. The first radiosity system <ref> [Goral84] </ref> used Gaussian elimination with partial pivoting to directly solve the matrix equation. [Cohen85] was the first to use gathering methods. Because the matrix F is a diagonally-dominate positive-definite matrix, the system is easy to solve with a vari ety of techniques.
Reference: [Gonzales77] <author> Rafael C. Gonzales, Paul Wintz, </author> <title> Digital Image Processing, </title> <publisher> Addison-Westly Publishing Company, </publisher> <address> Reading, Massachesetts, </address> <year> 1977. </year>
Reference-contexts: Aliasing can occur when a continuous signal is sampled and then reconstructed from the samples. A fundamental result of signal processing is that a continuous signal can be sampled and reconstructed exactly only if the sampling frequency is at least twice the highest frequency present in the continuous signal <ref> [Gonzales77] </ref>. If there are any frequencies in the continuous signal that are above this limit, which is called the Nyquist limit, they will produce a sequence of samples that could have been produced from a signal that was entirely below the Nyquist limit.
Reference: [Gouraud71] <institution> Henri Gouraud "Computer Display of Curved Surfaces," </institution> <note> IEEE Transactions on Computers, Vol. C-20, No. 6, June 1971 (reprinted in [Freeman80]). 171 </note>
Reference-contexts: Perfectly diffuse (Lambertion) reflection is the simplest case. This was the first BRDF approximation used in computer graphics <ref> [Gouraud71] </ref>. This approximation is a function of only one variable (the polar angle of the incoming light).
Reference: [Grant85] <author> Charles W. Grant, </author> <title> "Integrated Analytic Spatial and Temporal Anti-aliasing for Polyhedra in 4-space," </title> <journal> Computer Graphics, </journal> <volume> Vol. 19, No. </volume> <booktitle> 3 (Proceedings of ACM SIGGRAPH 85), </booktitle> <month> July </month> <year> 1985. </year>
Reference-contexts: With respect to computer graphics, aliasing was first extensively discussed by [Crow77b]. Since then attempts to reduce this problem have been an extensive area of research [Crow81] [Feibush80] [Carpenter84] [Catmull78] [Catmull84] [Cook84] [Cook86] [Dippe85a] [Dippe85b] [Duff85] [Fiume83] [Fujimoto83] <ref> [Grant85] </ref> [Hourcade85] [Lee85] [Max85] [Max90] [Porter84] [Reeves87] [Szabo83] [Whit-ted82]. 2.3.2.1 Signals and Samples For the purposed of this discussion, a continuous signal is a function which is defined almost everywhere within some domain. 4 For example, the two-dimensional signal representing the color of a polygonal scene with the color defined on <p> This greatly reduced the cost of the integration. [Catmull84] claimed that the [Feibush80] lookup table technique could be easily extended for pixel values varying linearly in x and y. The [Feibush80] technique was extended to linear movement of polygons with an arbitrary finite-extent radially-symmetric time-space weighting function by <ref> [Grant85] </ref>. [Lien84] shows how to integrate arbitrary polynomials over n-dimensional polyhedra using a similar scheme. This can be used for filtering with polynomial weighting functions. [Dippe85a] uses a different approach and uses spatial-temporal tetrahedral Bezier patches as primitives. <p> With subdivision algorithms there are many choices of how the subdivision can be made defining different dimensions in a subdivision algorithm space, but there is no single basis algorithm. Subdivision can be two-dimensional [Warnock69] [Weiler77] [Franklin80] or three-dimensional [Fuchs79] [Fuchs80] [Fujimoto86] [Glassner84] [Samet90] or higher dimensional [Arvo87] <ref> [Grant85] </ref> [Glassner88]. The subdivisions can be specified in screen coordinates based on dividing the image [Warnock69] [Catmull78] [Catmull84] or in object coor dinates based on dividing the scene independent of the viewpoint [Fujimoto86]. <p> 8 &gt; &gt; &gt; &gt; &gt; &gt; &gt; : Object Based ( Presorted - 3d Presort 1 Non-presorted - BSP-tree [Fuchs79] Space Based ( Uniform - Voxel [Chen85] Hierarchical - Octree [Samet90] 2d &gt; &gt; &gt; &gt; &gt; &gt; &gt; &lt; Object Based ( Presorted Sorted Clipper [Weiler77] Non-presorted Clipper <ref> [Grant85] </ref> Space Based ( Uniform - 2d Grid [Franklin80] Hierarchical - Quadtree [Warnock69] Point Sampled Only 8 &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; <p> The polygon tree data structure allows the clipping to many different subregions proceed efficiently in a recursive manner. One advantage of this algorithm is that its simple depth comparison allows it to easily be extended to higher dimensions. <ref> [Grant85] </ref> used this algorithm to do four-dimensional 45 (x, y, z, t) continuous visibility determination for motion blur. 3.4.2.4 Sorted Clipper Algorithm In the clipper algorithm described in the previous section, the polygons can appear in the input in any order.
Reference: [Grant87a] <author> Charles W. Grant, </author> <title> "Visibility Theory in Image Synthesis: thesis proposal," A background survey and PhD. </title> <type> thesis topic proposal. </type> <institution> University of California, Davis, </institution> <month> January </month> <year> 1987. </year>
Reference-contexts: This taxonomy is summarized in figure 3.7. It is based on the relationships between algorithms discussed in the previous section. A preliminary version of this taxonomy appeared in <ref> [Grant87a] </ref> [Grant87b]. This figure is analogous to the taxonomy of Sutherland, Sproull, and Schumacker in figure 2.6 in summarizing the key results of existing algorithms. In chapter 4 the new visibility predicted by this taxonomy algorithms are described.
Reference: [Grant87b] <author> Charles W. Grant, </author> <title> "A Preliminary Taxonomy of Visible Surface Algorithms," </title> <booktitle> Workshop on Rendering Algorithms and Systems, Graphics Interface 87, </booktitle> <address> Toronto, Ontario, </address> <note> April 5-6 1987 (unpublished). </note>
Reference-contexts: This taxonomy is summarized in figure 3.7. It is based on the relationships between algorithms discussed in the previous section. A preliminary version of this taxonomy appeared in [Grant87a] <ref> [Grant87b] </ref>. This figure is analogous to the taxonomy of Sutherland, Sproull, and Schumacker in figure 2.6 in summarizing the key results of existing algorithms. In chapter 4 the new visibility predicted by this taxonomy algorithms are described. <p> This is determined by which version of the painter's algorithm from chapter 4 is being used. A system which uses only uncorrelated primitives can use the simple uncorrelated compositing operator of [Porter84]. SMS systems using particles or volume densities were implemented and described in <ref> [Grant87b] </ref>.
Reference: [Grant87c] <author> Charles W. Grant, </author> <title> "The Shadow Mask Sweep Family of Shadow Algorithms," </title> <institution> UCRL-95948, Lawrence Livermore National Laboratory, Livermore, Cal-ifornia, </institution> <month> January </month> <year> 1987. </year>
Reference-contexts: Some preliminary results of this research were reported in <ref> [Grant87c] </ref>. That work is extended in this section by using the more powerful dynamic correlation operators described in section 4.2.5. 6.5.1.1 The Shadow Mask The shadow mask is a two dimensional antialiased raster that describes the distribution of illumination across a single slice through object space.
Reference: [Grant90] <author> Charles W. Grant, </author> <title> "Depth Buffer Shadow Algorithms," </title> <institution> Lawrence Livermore National Laboratory, UCRL-102856, Livermore, California, </institution> <month> January </month> <year> 1990. </year>
Reference-contexts: In a related effort, [Reeves87] presents a modified version of [Williams78] by adding "percentage closer filtering" to produce soft shadow boundaries, but this did not address the most significant problems of the original algorithm. Some preliminary results of the research in this section were reported in <ref> [Grant90] </ref>. [Woo92] later independently developed and implemented the idea of using two depth values. The data structure used for shadow testing in a DBSS is a two dimensional depth map of the scene from the point of view of the light source.
Reference: [Hackathorn77] <author> Ronald J. Hackathorn, "ANIMA II: </author> <title> A 3-D Color Animation System," </title> <journal> Computer Graphics, </journal> <volume> Vol. 11, No. </volume> <booktitle> 2 (Proceedings of ACM SIGGRPAH 77), </booktitle> <month> July </month> <year> 1977. </year>
Reference-contexts: Only one scan line of the image and depth buffer are in memory at a time. This organization was used by [Myers75] <ref> [Hackathorn77] </ref> for polygons and [Porter78] for spheres.
Reference: [Haines86] <author> Eric A. Haines, Donald P. Greenberg, </author> <title> "The Light Buffer: A Ray Tracer Shadow Testing Accelerator," </title> <journal> IEEE Computer Graphics and Applicaitons, </journal> <volume> Vol. 6, No. 9, </volume> <month> September </month> <year> 1986. </year>
Reference-contexts: Several two-dimensional subdivisions, one for the view from each light source, are used by <ref> [Haines86] </ref> but this requires memory proportional to the number of light sources. For the simple brute force algorithm with pixel parallelism, a method of broadcasting one object at a time to all ray processors is sufficient. Each ray processor maintains the value of the closest intersection in its local memory. <p> These lists allow an optimization of direct independent class umbra algorithms to avoid testing against all other primitives. The first algorithm using this optimization was presented by [Bouknight70a]. A slightly different version was later presented by <ref> [Haines86] </ref> as a ray tracing shadow accelerator. The depth buffer shadow algorithm of [Williams78] is the most popular algorithm of this class. It uses a two-dimensional sampled representation of the locations of the illuminated surfaces in the light sources image coordinate system.
Reference: [Hamlin77] <author> Griffith Jr. Hamlin, William C. Gear, </author> <title> "Raster Scan Hidden Surface Algorithm Techniques," </title> <journal> Computer Graphics, </journal> <volume> Vol. </volume> <pages> 11, </pages> <note> No. 2 (Proceedings of ACM SIGGRAPH 77), July 1977 (reprinted in [Freeman80]). </note>
Reference-contexts: Thus their areas can easily be used as regions of integration. A polygon is also very easy to specify by listing the coordinates of the vertices. So far, continuous algorithms have been developed only for polygons. The earliest continuous algorithms were [Warnock69], <ref> [Hamlin77] </ref> and [Weiler77]. Although all of these algorithms processed areas in a continuous manner, they all point sampled the continuous data for conversion to raster format. [Catmull78] was the first algorithm to filter the continuous output before sampling as part of the antialiasing process. <p> At each step a list of interesting points generated by intersections of active objects must be maintained so that the next interesting point can be predicted. This type algorithm has been implemented by <ref> [Hamlin77] </ref> [Sechrest81] and [Sequin85]. 3.1.2.2 Subdivision Algorithms The subdivision visibility algorithms operate on the principle of divide and conquer. That is, if the problem is divided into subproblems then the subproblems will usually be smaller and easier to solve. <p> &gt; &gt; &gt; &gt; &gt; &gt; &gt; &lt; Continuous or Point Sampled 8 &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; : Sweep Methods ( Y Direction Scan Plane <ref> [Hamlin77] </ref> Z Direction Plane Push 2 Subdivision 8 &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; : 8 &gt; &gt; &gt; &gt; &gt; &gt; &gt; : Object Based ( Presorted - 3d Presort 1 Non-presorted - BSP-tree <p> SSS did succeed in identifying examples of most of the major algorithms that are in use today: scan line [Watkins69], [Bouknight69], [Romney70], painter's [Newell72], [Schumacker69], subdivision [Warnock69], z-buffer (brute force), and ray tracing (brute force). Only the scan plane algorithms which were first published in <ref> [Hamlin77] </ref> were not anticipated. The two outrageously expensive brute force algorithms described in their study turned out to be the two most popular algorithms of today: the ray tracing and z-buffer algorithms.
Reference: [Hanrahan83] <author> Patrich Hanrahan, </author> <title> "Ray Tracing Algebraic Surfaces," </title> <journal> Computer Graphics, </journal> <volume> Vol. 17, No. </volume> <booktitle> 3 (Proceedings of ACM SIGGRAPH 83), </booktitle> <month> July, </month> <year> 1983. </year>
Reference-contexts: However, both terms are frequently used interchangeably. 28 simply adding the corresponding intersection routines. If explicitly solving for intersections can not be done, then numerical approximation techniques can be used [Blinn82] <ref> [Hanrahan83] </ref> [Joy86] [Kajiya82] [Kajiya83] [Sweeney86] [Toth85]. Many optimizations are possible in the ray tracing algorithm.
Reference: [Hanrahan90] <author> Patrich Hanrahan, David B. Salzman, </author> <title> "A Rapid Hierarchical Radios-ity Algoirthm for Unoccluded Environements," in Photosimulation, </title> <journal> Realism and Physics in Computer Graphics, </journal> <note> K. Bouatouch (Ed.), Springer-Verlag, 1991 (also in Princeton University CS-TR-281-90). </note>
Reference-contexts: It is desirable to use small elements where illumination changes rapidly, such as at shadow boundaries, but it is wasteful to use small elements in areas of uniform illumination. Methods for adaptively subdividing the elements [Cohen86] [Campbell90] [Heckbert90] help a great deal. <ref> [Hanrahan90] </ref> [Hanrahan91] presents a 98 method of subdivision and solving the resulting approximate matrix equation to a fixed error tolerance in linear time.
Reference: [Hanrahan91] <author> Patrich Hanrahan, David Salzman, Larry Aupperle, </author> <title> "A Rapid Hierarchical Radiosity Algorithm", </title> <journal> Computer Graphics, </journal> <volume> Vol. 25, No. </volume> <booktitle> 4 (Proceedins of ACM SIGGRAPH 91), </booktitle> <month> July, </month> <year> 1991. </year>
Reference-contexts: It is desirable to use small elements where illumination changes rapidly, such as at shadow boundaries, but it is wasteful to use small elements in areas of uniform illumination. Methods for adaptively subdividing the elements [Cohen86] [Campbell90] [Heckbert90] help a great deal. [Hanrahan90] <ref> [Hanrahan91] </ref> presents a 98 method of subdivision and solving the resulting approximate matrix equation to a fixed error tolerance in linear time.
Reference: [He91] <author> Xiao D. He, Kenneth E. Torrance, Francois X. Sillion, Donald P. Greenberg, </author> <title> "A Comprehansive Physical Model for Light Reflection," </title> <journal> Computer Graphics, </journal> <volume> Vol. 25, No. </volume> <booktitle> 4 (Proceedings of ACM SIGGRAPH 91), </booktitle> <month> July, </month> <year> 1991. </year>
Reference-contexts: One attempt to use a wave model of light on the macro scale in image synthesis produced very discouraging results [Moravec81] and no other efforts have followed. On the micro scale <ref> [He91] </ref> has used the wave model for calculating surface reflectance properties but this is outside the scope of image synthesis. In this dissertation we will consider that the surface reflectance properties are known in advance and that they are inputs to the problem of image synthesis. <p> These rough surfaces do not reflect or refract a given ray in a unique direction, but scatter the ray over some distribution of directions which is a function of the roughness. The reflection model of <ref> [He91] </ref> includes a mirror specular component and a rough reflection component. 2.2.8 Indirect Illumination Determination Indirect illumination models how light is distributed between objects, rather than light which propagates directly from the light sources. There are several ways that light can propagate between objects.
Reference: [Heckbert84] <author> Paul S. Heckbert, and Patrich Hanrahan, </author> <title> "Beam Tracing Polygonal Objects," </title> <journal> Computer Graphics, </journal> <volume> Vol. 18, No. </volume> <booktitle> 3 (Proceedings of ACM SIGGRAPH 84), </booktitle> <month> July, </month> <year> 1984. </year> <month> 172 </month>
Reference-contexts: When a continuous algorithm is used for image formation, such as beam tracing <ref> [Heckbert84] </ref>, then the algorithm is two-dimensional. 5.1.6.5 The Distribution Ray Tracing Paradigm The distribution ray tracing paradigm starts with a more complex direct image for mation subproblem. Two-dimensional image formation can be combined with a one-dimensional time interval, and a two-dimensional range of viewpoint over a simulated camera lens. <p> All other visibility algorithms require many samples or pixels to be generated from a single viewpoint for efficient operation. Ray tracing experiences aliasing problems because of its point sampling nature. <ref> [Heckbert84] </ref> presents an extension to ray tracing where polygonal beams are traced through a scene and intersected with primitives. This greatly helps the aliasing problem, but introduces many restrictions on the types of scene which can be rendered. <p> This algorithm uses a triangle intersection routine very similar to a ray intersection routine used in ray tracing. Creating a one-dimensional extension of zero-dimensional ray tracing. A two-dimensional direct independent illumination test using a BSP-tree has been implemented by [Garcia86] [Chin89]. The beam tracing system of <ref> [Heckbert84] </ref> is also a two-dimensional direct independent system. Various different two-dimensional systems are possible by using different data structures and subdivision strategies in the illumination test. This assumes that these data structures are already present for use in image formation.
Reference: [Heckbert86] <author> Paul S. Heckbert, </author> <title> "Survey of Texture Mapping," </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> Vol. 6, No. 11, </volume> <booktitle> November 1986 (also in Proceeding of Graphics Interface 86). </booktitle>
Reference-contexts: What is required is that the area formed by projecting the section of the object in the current pixel onto the shadow mask be suitably filtered before the sample is taken. <ref> [Heckbert86] </ref> surveys techniques for sampling and filtering static texture maps. The problem here is complicated by the fact that the shadow mask (texture map) changes each time it is used. This defeats most preprocessing schemes.
Reference: [Heckbert90] <author> Paul S. Heckbert, </author> <title> "Adaptive Radiosity Textures for Bidirectional Ray Tracing," </title> <journal> Computer Graphics, </journal> <volume> Vol. 24, No. 4, </volume> <booktitle> (Proceedings of ACM SIGGRAPH 91), </booktitle> <month> August </month> <year> 1991. </year>
Reference-contexts: Addressed Utah direct image formation only Shadows direct image formation and direct illumination Ray Tracing direct image formation, indirect image formation, and direct illumination Diffuse Radiosity direct image formation, direct illumination, and indirect illumination Full Rendering Equation direct and indirect illumination and direct and indirect image formation subproblems they address. <ref> [Heckbert90] </ref> introduces a useful notation for describing the different light paths which each paradigm or system attempts to model. <p> Area light sources, glossy reflections and refractions, and depth of field yield the more complex distribution ray tracing paradigm. [Cook84] originally called the first system in this paradigm "distributed ray tracing," but later many people felt that the name implied distributed pro cessing. <ref> [Heckbert90] </ref> has suggested the name "distribution ray tracing" hoping that it would be clearer that sample distributions are involved. <p> It is desirable to use small elements where illumination changes rapidly, such as at shadow boundaries, but it is wasteful to use small elements in areas of uniform illumination. Methods for adaptively subdividing the elements [Cohen86] [Campbell90] <ref> [Heckbert90] </ref> help a great deal. [Hanrahan90] [Hanrahan91] presents a 98 method of subdivision and solving the resulting approximate matrix equation to a fixed error tolerance in linear time.
Reference: [Heckbert91] <author> Paul S. Heckbert, </author> <title> "Sumulating Global Illumination Using Adaptive Meshing," </title> <type> PhD Thesis, </type> <institution> CS Division, University of California, Berkeley, </institution> <month> June </month> <year> 1991, </year> <type> Tech Report UCB/CSD 91/636. </type>
Reference-contexts: The process of image synthesis was formulated as an integral equation called the "pixel equation" by [Whitted85] (this was pre-radiosity). This was generalized into the "rendering equation" by [Kajiya86]. <ref> [Heckbert91] </ref> identified the two methods used in computer graphics for solving this Fredholm integral equation of the second kind and equation for global illumination. The two methods are examples of the finite element method (FEM) and the Monte Carlo method. <p> Texture maps associated with each surface describing the illumination distribution on the surface are an example of a non-uniform representation in a pure preprocessing umbra algorithm. This is similar to <ref> [Heckbert91] </ref> which proposes using texture maps for holding radiosity information in a full rendering equation system. The pure preprocessing algorithms are limited in that the results of the illumination determination must be presented in a form which the image formation algorithm can accept as input.
Reference: [Hourcade85] <author> Charles J. Hourcade, A. Nicolas, </author> <title> "Algorithms for Antialiased Cast Shadows," </title> <journal> Computers and Graphics, </journal> <volume> Vol. 9, No. </volume> <month> 3 </month> <year> 1985. </year>
Reference-contexts: With respect to computer graphics, aliasing was first extensively discussed by [Crow77b]. Since then attempts to reduce this problem have been an extensive area of research [Crow81] [Feibush80] [Carpenter84] [Catmull78] [Catmull84] [Cook84] [Cook86] [Dippe85a] [Dippe85b] [Duff85] [Fiume83] [Fujimoto83] [Grant85] <ref> [Hourcade85] </ref> [Lee85] [Max85] [Max90] [Porter84] [Reeves87] [Szabo83] [Whit-ted82]. 2.3.2.1 Signals and Samples For the purposed of this discussion, a continuous signal is a function which is defined almost everywhere within some domain. 4 For example, the two-dimensional signal representing the color of a polygonal scene with the color defined on the <p> One must restrict the algorithm to convex objects (which can not shadow themselves), or adopt a complex subdivision scheme for assigning surface identifiers to concave objects. A subdivision based method along these lines is presented by <ref> [Hourcade85] </ref>. Some systems store a list of surfaces that could potentially shadow primitives in each region of space. These lists allow an optimization of direct independent class umbra algorithms to avoid testing against all other primitives. The first algorithm using this optimization was presented by [Bouknight70a]. <p> DBSS's are restricted to values that can be point sampled, such as depth and surface normal, at each shadow buffer pixel. Some additional types of information stored in the shadow buffer would allow more accurate shadow calculations (locations of primitive edges within a pixel [Carpenter84], silhouette edges <ref> [Hourcade85] </ref>, "alpha" coverage values [Hourcade85], indices to identify objects [Hourcade85], bits to flag which adjacent pixels are covered by the same object with a scheme similar to [Duff85], or other non-point-sampled geometric information), but this additional information could not be calculated by the depth buffer visible surface algorithm without giving up <p> Some additional types of information stored in the shadow buffer would allow more accurate shadow calculations (locations of primitive edges within a pixel [Carpenter84], silhouette edges <ref> [Hourcade85] </ref>, "alpha" coverage values [Hourcade85], indices to identify objects [Hourcade85], bits to flag which adjacent pixels are covered by the same object with a scheme similar to [Duff85], or other non-point-sampled geometric information), but this additional information could not be calculated by the depth buffer visible surface algorithm without giving up some or all of <p> Some additional types of information stored in the shadow buffer would allow more accurate shadow calculations (locations of primitive edges within a pixel [Carpenter84], silhouette edges <ref> [Hourcade85] </ref>, "alpha" coverage values [Hourcade85], indices to identify objects [Hourcade85], bits to flag which adjacent pixels are covered by the same object with a scheme similar to [Duff85], or other non-point-sampled geometric information), but this additional information could not be calculated by the depth buffer visible surface algorithm without giving up some or all of its advantages.
Reference: [Immel86] <author> David S. Immel, Michael F. Cohen, Donald P. Greenberg, </author> <title> "A Radiosity Method for Non-diffuse Environments," </title> <journal> Computer Graphics, </journal> <volume> Vol. 20, No. </volume> <booktitle> 4 (Proceedings of ACM SIGGRAPH 86), </booktitle> <month> August </month> <year> 1986. </year>
Reference-contexts: Ray tracing can also be used to calculate form factors which take specular reflections into account [Shao88]. This uses the light paths L (DjS) fl E, but the specular reflections are quantized and averaged by the discretization of the scene into elements. <ref> [Immel86] </ref> uses a scheme for non-diffuse reflection where directional form factors are used. This gives a huge matrix (E fi N by E fi N ) where E is the number of elements and N is the number of possible directions for reflections.
Reference: [Joy86] <author> Kenneth I. Joy, Murthy N. Bhetanabhotla, </author> <title> "Ray Tracing Parametric Surface Patches Utilizing Numerical Techniques and Ray Coherence," </title> <journal> Computer Graphics, </journal> <volume> Vol. </volume> <pages> 20, </pages> <note> No. 4 (Proceedings of ACM SIGGRAPH 86), August 1986 (reprinted in [Joy87]). </note>
Reference-contexts: However, both terms are frequently used interchangeably. 28 simply adding the corresponding intersection routines. If explicitly solving for intersections can not be done, then numerical approximation techniques can be used [Blinn82] [Hanrahan83] <ref> [Joy86] </ref> [Kajiya82] [Kajiya83] [Sweeney86] [Toth85]. Many optimizations are possible in the ray tracing algorithm.
Reference: [Joy88] <author> Kenneth I. Joy, Charles W. Grant, Nelson L. Max, </author> <title> Lansing Hatfield, Tutorial: Computer Graphics: Image Synthesis, </title> <publisher> IEEE Computer Society Press, </publisher> <address> Washington, D.C 1988. </address>
Reference: [Joy92] <author> Kenneth I. Joy, </author> <title> "Accurate Depth Buffer Shadow Maps", </title> <booktitle> to appear in Proceedings of COMPUGRAPHICS 92, </booktitle> <address> Lisbon, Portugal, </address> <month> December </month> <year> 1992. </year>
Reference-contexts: Adaptive sampling is difficult for algorithms which hold the entire image in memory, because the resolution is fixed. Changing the resolution would force another pass through the input data. Although if the input data has already been subdivided for parallel processing this could be practical. <ref> [Joy92] </ref> uses a similar technique for varying the spacial resolution of the shadow depth buffers in a parallel processing shadow system based on the z-buffer visibility algorithm. Jittered sampling is possible for all the point sampled algorithms.
Reference: [Kajiya82] <author> James T. Kajiya, </author> <title> "Ray Tracing Parametric Patches," </title> <journal> Computer Graphics, </journal> <volume> Vol. 16, </volume> <booktitle> No.3 (Proceedings of ACM SIGGRAPH 82), </booktitle> <month> July, </month> <year> 1982. </year>
Reference-contexts: However, both terms are frequently used interchangeably. 28 simply adding the corresponding intersection routines. If explicitly solving for intersections can not be done, then numerical approximation techniques can be used [Blinn82] [Hanrahan83] [Joy86] <ref> [Kajiya82] </ref> [Kajiya83] [Sweeney86] [Toth85]. Many optimizations are possible in the ray tracing algorithm. If some simple test can determine that an object or group of objects can not possibly intersect a given ray, then each of those objects does not need to be explicitly tested for intersection with the ray.
Reference: [Kajiya83] <author> James T. Kajiya, </author> <title> "New Techniques for Ray Tracing Procedurally Defined Objects," </title> <journal> Computer Graphics, </journal> <volume> Vol. 17, No. </volume> <booktitle> 3 (Proceedings of ACM SIGGRAPH 83), </booktitle> <month> July </month> <year> 1983, </year> <journal> also in ACM Transactions on Graphics, </journal> <volume> Vol. 2, No. 3, </volume> <month> July </month> <year> 1983. </year>
Reference-contexts: However, both terms are frequently used interchangeably. 28 simply adding the corresponding intersection routines. If explicitly solving for intersections can not be done, then numerical approximation techniques can be used [Blinn82] [Hanrahan83] [Joy86] [Kajiya82] <ref> [Kajiya83] </ref> [Sweeney86] [Toth85]. Many optimizations are possible in the ray tracing algorithm. If some simple test can determine that an object or group of objects can not possibly intersect a given ray, then each of those objects does not need to be explicitly tested for intersection with the ray.
Reference: [Kajiya84] <author> James T. Kajiya, Brian P. Von Herzen, </author> <title> "Ray Tracing Volume Densities," </title> <journal> Computer Graphics, </journal> <volume> Vol. 18. No. </volume> <booktitle> 3 (Proceedings of ACM SIGGRAPH 84), </booktitle> <month> August </month> <year> 1986. </year>
Reference-contexts: [Barr81] [Franklin81] ffi Blobby particles K P all objects f (object; x; y; z) = 0 [Blinn82] * Parametric surfaces S = F (u; v) ffi Bi-cubic parametric patches [Catmull74] [Catmull75] ffi Superquadric surfaces (parametric form) [Barr81] [Franklin81] ffi Triangular patches [Sederberg84] * Procedural primitives ffi Particles [Reeves83] ffi Densities <ref> [Kajiya84] </ref> ffi Fractals [Fournier82] 2.2.2 Light Source Modeling Light enters a scene through or is generated by objects called light sources. Light sources of varying complexity are possible. The simplest possible assumption is that illumination is perfectly uniform throughout the scene. <p> Nonuniform density clouds are as easy to render as uniform density clouds with this method. This produces results equivalent to the slab method of [Voss83] without the restrictions on viewing position (mentioned by 160 161 162 <ref> [Kajiya84] </ref>), and equivalent to the low albedo ray tracing approximation of [Kajiya84] at much lower cost in time and intermediate storage. It is possible to combine the Shadow Mask Sweep concept for shadow generation with different algorithms for visible surface determination. This may make the sorting and subdivision requirements simpler. <p> Nonuniform density clouds are as easy to render as uniform density clouds with this method. This produces results equivalent to the slab method of [Voss83] without the restrictions on viewing position (mentioned by 160 161 162 <ref> [Kajiya84] </ref>), and equivalent to the low albedo ray tracing approximation of [Kajiya84] at much lower cost in time and intermediate storage. It is possible to combine the Shadow Mask Sweep concept for shadow generation with different algorithms for visible surface determination. This may make the sorting and subdivision requirements simpler.
Reference: [Kajiya86] <author> James T. Kajiya, </author> <title> "The Rendering Equation," </title> <journal> Computer Graphics, </journal> <volume> Vol. 20, No. </volume> <booktitle> 4 (Proceedings of ACM SIGGRAPH 86), </booktitle> <month> August </month> <year> 1986. </year>
Reference-contexts: The simplest is the diffuse reflection of light between objects. Much more complex is the specular reflection and refraction of light from light sources onto objects via other objects. In image synthesis these directional reflection and refraction effects are called caustics <ref> [Kajiya86] </ref> [Mitchel92]. In optics the term caustic refers to the locus of points of singularity in the mapping from light source to the illuminated surface (i.e. the edges of the bright regions of focused light). In computer graphics the entire bright spot is sometimes, somewhat incorrectly, called a caustic. <p> Techniques for improving the rate of convergence and hence reducing the number of samples required are called variance reduction techniques. The study of variance reduction techniques applied to image synthesis applications is an active new area of research [Dippe85b] [Lee85] <ref> [Kajiya86] </ref>. 2.4 A Previous Classification of Visibility Algorithms The 1973 taxonomy of Sutherland, Sproull, and Schumacker [Sutherland73] [Suther-land74] is still the most important development in the field of algorithms to solve the visibility problem. <p> : : = 1 Diffuse Radiosity 4 + 2 + 2 + : : : = 1 Rendering Equation 4 + 4 + 4 + : : : = 1 5.2 The Rendering Equation Formulation of Image Synthesis In this section the rendering equation formulation of the image synthesis problem <ref> [Kajiya86] </ref> is presented. We will see that each image synthesis paradigm can be described by how it approximates the rendering equation in either the integral equation form or the Neumann series form. <p> The process of image synthesis was formulated as an integral equation called the "pixel equation" by [Whitted85] (this was pre-radiosity). This was generalized into the "rendering equation" by <ref> [Kajiya86] </ref>. [Heckbert91] identified the two methods used in computer graphics for solving this Fredholm integral equation of the second kind and equation for global illumination. The two methods are examples of the finite element method (FEM) and the Monte Carlo method. <p> This gives a huge matrix (E fi N by E fi N ) where E is the number of elements and N is the number of possible directions for reflections. The quantization in space and in direction of reflection leaves very noticeable and objectionable artifacts in the images. <ref> [Kajiya86] </ref> performed the first direct extension of distribution ray tracing to add the effect of diffuse interreflections. Each ray was calculated independently resulting in many rays and slow convergence. Diffuse surface and the detection of indirect illumination via caustics required shooting many rays in all directions. <p> integral technique helped speed up the stochastic integration, but it was still too slow to converge to acceptable noise levels. [Ward88] uses a ray tracing method for image formation and illumination, but saves the illumination information in an auxiliary data structure so that it can be reused by nearby rays. <ref> [Kajiya86] </ref> had to recalculate this information for each image formation sample ray. In general conventional ray tracing techniques do poorly on the diffuse interreflection component of global illumination because many rays are required to get an accurate estimate of illumination from all directions.
Reference: [Kallman86] <author> Jeffery S. </author> <title> Kallman, </title> <type> Personal communication 1986. </type>
Reference-contexts: This problem requires one to solve a differential equation initial value problem to trace a ray [Barr86]. This complicates everything so much that this effect is never used in image synthesis except for special purpose systems designed only to calculate this effect, for example: simulating mirages <ref> [Kallman86] </ref> [Berger90] [Musgrave90] [Lehn92]. The main object/light interaction is reflection.
Reference: [Kaplan79] <author> Michael R. Kaplan, Donald P. Greenberg, </author> <title> "Parallel Processing Techniques for Hidden Surface Algorithms," </title> <journal> Computer Graphics, </journal> <volume> Vol. 13, No. </volume> <booktitle> 2 (Proceedings of SIGGRAPH 79), </booktitle> <month> August </month> <year> 1979. </year> <month> 173 </month>
Reference-contexts: A fast sequential algorithm can be used within each processor on a subset of the global data. [Dippe84] also uses a dynamic data redistribution scheme for improving the load balancing. The scan line algorithm has several steps with parts that can be executed in parallel <ref> [Kaplan79] </ref>. The initial sorting of primitives into the Y-buckets can be done in parallel. Updating the active list as the algorithm moves from scan line to scan line is sequential, but each update has many parts that can be done in parallel.
Reference: [Kaplan85] <author> Michael R. Kaplan, </author> <title> "Space Tracing: a Constant Time Ray Tracer," Course Notes: Tutorial on State of the Art in Image Synthesis, </title> <note> SIGGRAPH 85, July 1985 (Unpublished). </note>
Reference-contexts: The first section with an intersection terminates the process without testing farther sections. Different researchers have used various policies for dividing the object space into sections [Fujimoto86] [Glassner84] <ref> [Kaplan85] </ref>. The ray tracing algorithm that we consider for classification in this chapter does not include any of the enhancements mentioned in this paragraph, however these enhancements are necessary in real systems to give acceptable performance.. <p> The locations of subdivisions can be made independent of the data in the scene [Franklin80] [Catmull78] [Catmull84] or at significant object points [Fuchs79] [Fuchs80] [Weiler77]. The subdivisions can be orthogonal to the coordinate axes [Samet90] [Bentley79] [Cat-mull78] [Catmull84] [Glassner84] <ref> [Kaplan85] </ref> [Warnock69] or at arbitrary angles [Fuchs79] [Fuchs80] [Weiler77]. The subdivision can be at a fixed resolution [Franklin80] [Cat-mull78] [Catmull84] or adaptive hierarchically [Fuchs79] [Fuchs80] [Glassner84] [Ka-plan85] [Warnock69] [Samet90]. <p> In research environments, the most popular algorithm has been ray tracing, because of the great flexibility of the algorithm. Early ray tracing algorithms suffered from great slowness and severe aliasing, but many recent advances have made ray tracing competitive with the other algorithms, especially subdivision preprocessing [Fujimoto86] [Glassner84] <ref> [Kaplan85] </ref>. Ray tracing is no longer the brute-force technique it once was. 3.7 Summary In this chapter a new taxonomy of visible surface algorithms has been presented. This taxonomy is based on the basic structure of the algorithms studied. There are two main divisions, point sampling and continuous algorithms. <p> This is the basis for many advanced combination visibility algorithms: use a subdivision algorithm to build a spatial data structure then use this data structure to control ray tracing. The three dimensional subdivision-ray tracing combination has proven to be very useful [Fujimoto86] [Glassner84] <ref> [Kaplan85] </ref>. 4.1.4 Global Presorted Scan Ray Trace Algorithm The scan presorted ray trace algorithm starts by subdividing the scene into scan lines. Then the presorted ray trace algorithm is applied to each scan line. The active objects on the scan line are sorted by depth.
Reference: [Kay86] <author> Timothy L. Kay, James T. Kajiya, </author> <title> "Ray Tracing Complex Scenes," </title> <journal> Computer Graphics, </journal> <volume> Vol. 20, No. </volume> <booktitle> 4 (Proceedings of ACM SIGGRAPH 86), </booktitle> <month> August </month> <year> 1986. </year>
Reference-contexts: Many methods are in use for these techniques. The oldest and most popular is a hierarchical series of bounding extents to group objects into units which can be, in most cases, trivially rejected for further testing as a unit [Rubin80]. <ref> [Kay86] </ref> traverses this hierarchical data structure in an intelligent manner greatly increasing efficiency. Newer techniques divide the object space into sections and each section contains a list of the primitives in that section. Each ray is passed from section to section starting with the section closest to the view point. <p> The subdivision reduces the size of the problems that the rest of the algorithm must solve. This has recently been used as a technique for speeding up ray 47 tracing. [Fujimoto86] uses a three-dimensional space-based uniform subdivision. [Ka-plan85] and [Glassner84] use a three-dimensional space-based hierarchical subdivision. [Rubin80] and <ref> [Kay86] </ref> use a three-dimensional object-based hierarchical subdivision. [Dippe84] uses a three-dimensional space-based semi-regular subdivision. [Cleary86] compares two-dimensional and three-dimensional space-based regular subdivision techniques for ray tracing on a multiprocessor. [Fuchs79] [Fuchs80] uses a three-dimensional object-based subdivision as a preprocessing step for the painter's algorithm. [Franklin80] has shown that proper subdivision can
Reference: [Kelly92] <author> Michael Kelly, Stephanie Winner, Kirk Gould, </author> <title> "A Scalable Hardware Render Accelerator Using a Modified Scanline Algorithm," </title> <journal> Computer Graphics, </journal> <volume> Vol. 26, No. </volume> <booktitle> 2 (Proceedings of ACM SIGGRAPH 92), </booktitle> <month> July </month> <year> 1992. </year>
Reference-contexts: A frame store is not needed in such a system if pixels can be generated fast enough to keep up with the television scan rate. Today the system constraints are different, so scan line algorithms are not usually implemented in hardware, but research continues on this subject <ref> [Kelly92] </ref>. 3.1.2 Continuous Algorithms Continuous algorithms have the advantage that an exact description of visible features is returned. No information is lost to sampling. Continuous filtering algorithms can be applied to the output resulting in high quality antialiasing. Continuous algorithms involve much more calculation than point sampling algorithms. <p> Updating the active list as the algorithm moves from scan line to scan line is sequential, but each update has many parts that can be done in parallel. Once initialized, the operations on each scan line can be performed in parallel with other scan lines <ref> [Kelly92] </ref>. The per object operations involved in updating the objects data as the algorithm moves across the pixels in a scan line can be done in parallel at each pixel.
Reference: [Lee85] <author> Mark E. Lee, Richard A. Redner, Samuel P. Uselton, </author> <title> "Statistically Optimized Sampling for Distributed Ray Tracing," </title> <journal> Computer Graphics, </journal> <volume> Vol. 19, No. </volume> <booktitle> 3 (Proceedings of ACM SIGGRAPH 85), </booktitle> <month> July, </month> <year> 1985. </year>
Reference-contexts: With respect to computer graphics, aliasing was first extensively discussed by [Crow77b]. Since then attempts to reduce this problem have been an extensive area of research [Crow81] [Feibush80] [Carpenter84] [Catmull78] [Catmull84] [Cook84] [Cook86] [Dippe85a] [Dippe85b] [Duff85] [Fiume83] [Fujimoto83] [Grant85] [Hourcade85] <ref> [Lee85] </ref> [Max85] [Max90] [Porter84] [Reeves87] [Szabo83] [Whit-ted82]. 2.3.2.1 Signals and Samples For the purposed of this discussion, a continuous signal is a function which is defined almost everywhere within some domain. 4 For example, the two-dimensional signal representing the color of a polygonal scene with the color defined on the interiors <p> Monte Carlo techniques do introduce random noise into the output. The magnitude of this noise can be reduced by increasing the number of samples. This random noise is much less visually disturbing than regular patterns. [Cook84] [Dippe85b] <ref> [Lee85] </ref> [Cook86] have shown that varying the locations of the super samples by adding small random offsets caused dramatic improvements in perceived image quality. This is called jittered sampling. <p> Techniques for improving the rate of convergence and hence reducing the number of samples required are called variance reduction techniques. The study of variance reduction techniques applied to image synthesis applications is an active new area of research [Dippe85b] <ref> [Lee85] </ref> [Kajiya86]. 2.4 A Previous Classification of Visibility Algorithms The 1973 taxonomy of Sutherland, Sproull, and Schumacker [Sutherland73] [Suther-land74] is still the most important development in the field of algorithms to solve the visibility problem.
Reference: [Lee92] <editor> Sing H. Lee, (Ed.), </editor> <booktitle> Selected Papers on Computer-Generated Holograms and Diffractive Optics, Society of Photo-Optical Instrumentation Engineers, </booktitle> <address> Belling-ham Washington 1992. </address>
Reference-contexts: Work in the related field of synthetic holography has the same kinds of limitations <ref> [Lee92] </ref> but they are much worse when applied to the geometries necessary in image synthesis.
Reference: [Lehn92] <author> W. H. Lehn, W. Friesen, </author> <title> "Simulation of Mirages," </title> <journal> Applied Optics, </journal> <volume> Vol. 31, No. 9, </volume> <month> March </month> <year> 1992. </year>
Reference-contexts: This problem requires one to solve a differential equation initial value problem to trace a ray [Barr86]. This complicates everything so much that this effect is never used in image synthesis except for special purpose systems designed only to calculate this effect, for example: simulating mirages [Kallman86] [Berger90] [Musgrave90] <ref> [Lehn92] </ref>. The main object/light interaction is reflection.
Reference: [Levoy77] <author> Marc Levoy, </author> <title> "A Color Animation System Based on the Multiplane Technique," </title> <journal> Computer Graphics, </journal> <volume> Vol. 11, No. </volume> <booktitle> 2 (Proceedings of ACM SIGGRAPH 77), </booktitle> <month> August </month> <year> 1977. </year>
Reference-contexts: Scenes with many tiny polygons smaller than a pixel will cause the A-buffer to be very large, because many polygons will be visible at each pixel. The digital compositing techniques formalized in [Porter84] (and used previously in <ref> [Levoy77] </ref> [Stern79] [Wallace81]) are another example of using approximate geometric information for antialiasing. In this algorithm the painter's algorithm is extended to include with each pixel a number which describes the fraction of the pixel that is covered by primitives. <p> An ff value of one represents complete coverage (opacity) while an ff value of zero represents no coverage (complete transparency). This technique has been extensively used with the painter's algorithm and so-called "2 1/2D" rendering systems [Crow82] <ref> [Levoy77] </ref> [Max85] [Reeves83] [Reeves85] [Stern79] [Wallace81]. The exact value of the intensity contributions of two possibly overlapping antialiased polygon fragments to the intensity of a pixel is a complex calculation which depends on the exact positions of the edges.
Reference: [Levoy88] <author> Marc Levoy, </author> <title> "Display of Surfaces from Volume Data," </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> Vol. 8, No. 3, </volume> <month> May </month> <year> 1988. </year>
Reference-contexts: If only a restricted class of scenes are allowed so that the depth ordering is known a priori, this algorithm is very efficient [Schumacker69]. It is also the case that simple depth rela tionships exist for volume rendering regularly sampled volumes using projection methods <ref> [Levoy88] </ref> [Frieder85], non-regularly sampled volumes [Max90b], particle systems [Reeves83] [Reeves85], and height fields [Fishman80]. For a more general and efficient solution [Fuchs79] [Fuchs80] uses a binary space partition (BSP) tree to store the objects in the scene. This BSP tree can then be easily traversed in depth priority order. <p> The octree subdivision is usually not used directly as the primary visibility algorithm. It is more frequently used as a preprocessing step to reduce the complexity some other visibility algorithm such as [Glassner84]. 3.4.2.6 Voxel Regular subdivison of three-dimensional space is common for volume rendering systems [Chen85] <ref> [Levoy88] </ref>. Like the octree sudivision it yields a regular pattern of subre gion overlaps from a given viewpoint. The voxel subdivision and traversal has been used effectively for a hybrid accelerated ray tracing algorithm [Fujimoto86].
Reference: [Lien84] <author> Sheue-ling Lien, James T. Kajiya, </author> <title> "A Symbolic Method for Calculating the Integral Propertices of Arbitrary Nonconvex Polyhedra," </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> Vol. 4, No. 10, </volume> <month> October, </month> <year> 1984. </year>
Reference-contexts: This greatly reduced the cost of the integration. [Catmull84] claimed that the [Feibush80] lookup table technique could be easily extended for pixel values varying linearly in x and y. The [Feibush80] technique was extended to linear movement of polygons with an arbitrary finite-extent radially-symmetric time-space weighting function by [Grant85]. <ref> [Lien84] </ref> shows how to integrate arbitrary polynomials over n-dimensional polyhedra using a similar scheme. This can be used for filtering with polynomial weighting functions. [Dippe85a] uses a different approach and uses spatial-temporal tetrahedral Bezier patches as primitives.
Reference: [Loutrell67] <author> P. P. Loutrell, </author> <title> "A Solution to the Hidden-line Problem for Computer-drawn Polyhedra," </title> <institution> Dept. of Electrical Engineering, </institution> <address> New York University, Brox, New York, </address> <note> Tech Report 400-167, September 1967 (Available from University Microfilm, </note> <institution> Ann Arbor, Michigan). </institution>
Reference-contexts: Each of the eight visible surface algorithms studied (six published at the time [Watkins69] [Bouknight69] [Romney70] [Warnock69] [Newell72] [Schumacker69]) solved essentially the same version of the visibility problem, point sampling with planar polygons. There were no continuous visible surface algorithms at that time. Four visible line algorithms ([Roberts63] [Galimberti69] <ref> [Loutrell67] </ref> [Appel67]) were also considered. The taxonomy that resulted from this study is shown in figure 2.6. This figure and its interpretation is one of the important results of this study. There were several associations noted in the taxonomy.
Reference: [Max81] <author> Nelson L. </author> <title> Max "Vectorized Procedural Models for Natural Terrain: Waves and Islands in the Sunset," </title> <journal> Computer Graphics, </journal> <volume> Vol. 15, </volume> <booktitle> No.3 (Proceedings of ACM SIGGRAPH 81), </booktitle> <month> August </month> <year> 1981. </year>
Reference-contexts: Each ray processor maintains the value of the closest intersection in its local memory. Processors can also be assigned to objects with the rays pipelined through all the object processors [Chang83]. A similar software organization can be used on vector processors <ref> [Max81] </ref> [Plunkett85]. A ray broadcasting architecture is not efficient for object based parallelism since results must be accumulated and compared for each ray. Pipelining the rays allows the intersection test results to be propagated with the ray.
Reference: [Max85] <author> Nelson L. Max, Douglas M. Lerner, </author> <title> "A Two-and-a-half-d Motion-blur Algorithm," </title> <journal> Computer Graphics, </journal> <volume> Vol. 19, No. </volume> <booktitle> 3 (Proceedings of ACM SIGGRAPH 85), </booktitle> <address> July,1985. </address>
Reference-contexts: With respect to computer graphics, aliasing was first extensively discussed by [Crow77b]. Since then attempts to reduce this problem have been an extensive area of research [Crow81] [Feibush80] [Carpenter84] [Catmull78] [Catmull84] [Cook84] [Cook86] [Dippe85a] [Dippe85b] [Duff85] [Fiume83] [Fujimoto83] [Grant85] [Hourcade85] [Lee85] <ref> [Max85] </ref> [Max90] [Porter84] [Reeves87] [Szabo83] [Whit-ted82]. 2.3.2.1 Signals and Samples For the purposed of this discussion, a continuous signal is a function which is defined almost everywhere within some domain. 4 For example, the two-dimensional signal representing the color of a polygonal scene with the color defined on the interiors of <p> An ff value of one represents complete coverage (opacity) while an ff value of zero represents no coverage (complete transparency). This technique has been extensively used with the painter's algorithm and so-called "2 1/2D" rendering systems [Crow82] [Levoy77] <ref> [Max85] </ref> [Reeves83] [Reeves85] [Stern79] [Wallace81]. The exact value of the intensity contributions of two possibly overlapping antialiased polygon fragments to the intensity of a pixel is a complex calculation which depends on the exact positions of the edges.
Reference: [Max86a] <author> Nelson L. Max, </author> <title> "Atmospheric Illumination and Shadows," </title> <journal> Computer Graphics, </journal> <volume> Vol. 20, No. </volume> <booktitle> 3 (Proceedings of ACM SIGGRAPH 86), </booktitle> <month> August </month> <year> 1986. </year>
Reference-contexts: The painter's algorithm, the scan line algorithm, the scan plane algorithm, and some subdivision algorithms are suitable. Ray tracing, z-buffer, and some forms of subdivision algorithms are not suitable. The only published examples of direct incremental algorithms are scan line shadow algorithms [Crow77a] [Bergeron86] <ref> [Max86a] </ref>. "Shadow polygons" are added to the input database. These polygons start at the edges of ordinary polygons and extend away from the light source. The shadow polygons enclose the volume of space which is shadowed by the ordinary polygon. <p> This problem can be reduced by only using the silhouette edges of the objects to generate shadow polygons [Crow77a], but this introduces the complexity of identifying the silhouette edges in an algorithm that otherwise treats each polygon independently. <ref> [Max86a] </ref> applies a clever change in coordinate systems to avoid this major inefficiency in the regular image space scan line shadow algorithm. By using scan lines arranged so that each one intersects the projection of the point light source, the shadow interaction between scan lines is eliminated. <p> Six choices of algorithm to build the data structure and six choices of image formation algorithm yield thirty-six combinations. The coordinate system for such systems would be similar to that used by <ref> [Max86a] </ref>. A linear interpolation of depth values across the spans is trivial with this representation, making piecewise constant spans uninteresting. Spans for the two closest surfaces can be saved to give an illumination test improvement similar to the zero-dimensional case with two surfaces. This yields and additional thirty-six possible algorithms. <p> Systems using the scan line visible surface algorithm are the classic examples of this paradigm [Crow77a] [Berg eron86] <ref> [Max86a] </ref>. Since this paradigm involves making one pass thorough the data, the visibility algorithms for illumination and image formation are restricted to operate using the same ordering of primitives.
Reference: [Max86b] <author> Nelson L. Max, </author> <title> "Shadows for Bump-Mapped Surfaces," Advanced Computer Graphics. </title> <editor> T. L. Kunii (Ed.) </editor> <booktitle> (Proceedings of Computer Graphics, </booktitle> <address> Tokyo 86), </address> <publisher> Springer Verlag, </publisher> <address> Berlin, </address> <year> 1986. </year> <month> 174 </month>
Reference: [Max86c] <author> Nelson L. Max, </author> <title> "Light Diffusion Through Clouds and Haze," Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> Vol. </volume> <month> 33 </month> <year> 1986. </year>
Reference-contexts: A more realistic assumption, in the case where the medium is homogeneous, involves an attenuation that is an exponential function of distance to the light source. Linear and quadratic approximations have also been used [Whitted82] <ref> [Max86c] </ref>. 2.2.4 Local Object/Light Interaction Modeling Objects in synthetic images are usually opaque and all object/light interaction occurs at the surface of the object. This type of model provides a good approximation of the surfaces of many common types of real materials, such as wood, paper, metal and soil.
Reference: [Max87] <author> Nelson L. Max, </author> <title> "Unified Sun and Sky Illumination for Shadows of Trees," CVGIP: Graphical Models and Image Processing, </title> <journal> Vol. </journal> <volume> 53, No. 3, </volume> <month> May </month> <year> 1991. </year>
Reference-contexts: The entire sky can be considered to be a large hemispherical light source with an intensity that varies with location on the hemisphere. Such a light source has been used by [Nishita86] and <ref> [Max87] </ref> to calculate realistic outdoor scenes. 2.2.3 Light Propagation Modeling This subproblem addresses the simple case of modeling the light passing through free space or some transparent medium without interacting with opaque objects. The interaction with opaque objects will be handled as next subproblem. <p> This would also greatly increase the amount of calcula tions required to sweep the shadow mask, making this algorithm much less efficient. A technique is developed in <ref> [Max87] </ref> for efficiently calculating the direct sun illumination and the diffuse sky illumination on the ground under trees with shadows and penumbras using Fast Fourier Transforms, in the restricted case where the shadowing objects are all assumed to be at the same height and the shadow mask is parallel to the
Reference: [Max90] <author> Nelson L. Max, </author> <title> "Antialiasing Scan Line Data," </title> <journal> IEEE Computer Graphics and Applicatinos, </journal> <volume> Vol. 10, No. 1, </volume> <month> January </month> <year> 1990. </year>
Reference-contexts: With respect to computer graphics, aliasing was first extensively discussed by [Crow77b]. Since then attempts to reduce this problem have been an extensive area of research [Crow81] [Feibush80] [Carpenter84] [Catmull78] [Catmull84] [Cook84] [Cook86] [Dippe85a] [Dippe85b] [Duff85] [Fiume83] [Fujimoto83] [Grant85] [Hourcade85] [Lee85] [Max85] <ref> [Max90] </ref> [Porter84] [Reeves87] [Szabo83] [Whit-ted82]. 2.3.2.1 Signals and Samples For the purposed of this discussion, a continuous signal is a function which is defined almost everywhere within some domain. 4 For example, the two-dimensional signal representing the color of a polygonal scene with the color defined on the interiors of the <p> This yields the two algorithm classes: continuous algorithms and point sampled algorithms. Hybrid algorithms which are part continuous and part point sampled are also possible (such as [Watkins69] <ref> [Max90] </ref> which are scan line algorithms that sample in the Y dimension but solve a reduced dimensionality continuous visibility problem on each scan line). Hybrid algorithms which combine techniques from more than one basic algorithm and other extensions of the basic algorithms are considered later in this chapter. <p> Many algorithms have been published which refer to themselves as scan line algorithms [Bouknight69] <ref> [Max90] </ref> [Watkins69] [Wylie67]. These algorithms use the concept of subdivision into scan lines, but the processing on each scan line differs. What we describe here is the simplest brute-force point-sampling techninque which is consistent with the method of scan line subdivision. <p> More complex cases are only approximate because of the approximate geometric representation of the coverage of the "cone." Scan line algorithms which perform more accurate geometric calculations along the direction of the scan lines, than between the scan lines, have been used [Watkins69] <ref> [Max90] </ref>. This technique works well for large polygons except where polygon edges align parallel to the scan lines. It is possible to use very high resolution samples in the direction of the scan lines at low cost since typically long runs of samples will have the same polygon visible. <p> It is possible to use very high resolution samples in the direction of the scan lines at low cost since typically long runs of samples will have the same polygon visible. It is also possible to use a reduced dimensionality continuous visibility algorithm within the scan line <ref> [Max90] </ref> which will calculate exact visibility extents in the X dimension but sample along the Y dimension. 37 3.3 Relationships Between Visibility Algorithms 3.3.1 Point Sampling Algorithms Four point sampling algorithms are used in the bulk of today's image synthesis work.
Reference: [Max90b] <author> Nelson L. Max, Pat Hanrahan, Roger Crawfis, </author> <title> "Area and Volume Coherence for Efficient Visualization of 3d Scalear Functions," </title> <journal> Computer Graphics, </journal> <volume> Vol. 24, No. 5, </volume> <month> November </month> <year> 1990. </year>
Reference-contexts: If only a restricted class of scenes are allowed so that the depth ordering is known a priori, this algorithm is very efficient [Schumacker69]. It is also the case that simple depth rela tionships exist for volume rendering regularly sampled volumes using projection methods [Levoy88] [Frieder85], non-regularly sampled volumes <ref> [Max90b] </ref>, particle systems [Reeves83] [Reeves85], and height fields [Fishman80]. For a more general and efficient solution [Fuchs79] [Fuchs80] uses a binary space partition (BSP) tree to store the objects in the scene. This BSP tree can then be easily traversed in depth priority order.
Reference: [McKenna87] <author> Michael McKenna, </author> <title> "Worst-case Optimal Hidden-surface Removal," </title> <journal> ACM Transactions on Graphics, </journal> <volume> Vol. 6, No. 1, </volume> <month> January </month> <year> 1987. </year>
Reference-contexts: Continuous algorithms have been published that have a worst case time complexity of O (p 2 ) which is optimum worst case behavior <ref> [McKenna87] </ref>. 3.2.2 Memory Usage Data Stored Auxiliary per pixel primitives data structures Algorithm in memory in memory in memory Z-buffer RGBZ 1 no Painters pass1 none all yes Painters pass2 RGB 1 no Ray Tracing none all no Scan Line none all yes Scan Plane n/a all yes Subdivision n/a all
Reference: [Mehlhorn84] <author> Kurt Mehlhorn, </author> <title> Multi-dimensional Searching and Computational Geometry, </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1984. </year>
Reference-contexts: There are two basic classes of continuous algorithms: scan plane algorithms and subdivision algorithms. These algorithms are described in the following two sections. 3.1.2.1 The Scan Plane Algorithm The scan plane visibility algorithms operate similar to scan plane algorithms for other problems in computational geometry [Preparata85] <ref> [Mehlhorn84] </ref>. Basically a plane is scanned through the three-dimensional data and calculations are performed only at "interesting" places in the data where things change. Between these interesting places, things are assumed to be continuous.
Reference: [Miller86] <author> Gavin S. P. Miller, </author> <title> "The Definition and Rendering of Terrain Maps," </title> <journal> Computer Graphics, </journal> <volume> Vol. 20, No. </volume> <booktitle> 4 (Proceedings of ACM SIGGRAPH 86), </booktitle> <month> August </month> <year> 1986. </year>
Reference: [Mitchel92] <author> Don Mitchel, Pat Hanrahan, </author> <title> "Illumination from Curved Reflectors," </title> <journal> Computer Graphics, </journal> <volume> Vol. 26, No. </volume> <booktitle> 2 (Proceedings of ACM SIGGRAPH 92), </booktitle> <month> July, </month> <year> 1992. </year>
Reference-contexts: The simplest is the diffuse reflection of light between objects. Much more complex is the specular reflection and refraction of light from light sources onto objects via other objects. In image synthesis these directional reflection and refraction effects are called caustics [Kajiya86] <ref> [Mitchel92] </ref>. In optics the term caustic refers to the locus of points of singularity in the mapping from light source to the illuminated surface (i.e. the edges of the bright regions of focused light). In computer graphics the entire bright spot is sometimes, somewhat incorrectly, called a caustic.
Reference: [Molnar92] <author> Steven Molnar, John Eyles, John Poulton, "PixelFlow: </author> <title> High-Speed Rendering Using Image Composition," </title> <journal> Computer Graphics, </journal> <volume> Vol. 26, No. </volume> <booktitle> 2 (Proceedings of SIGGRPAH 92), </booktitle> <month> July </month> <year> 1992. </year>
Reference-contexts: This can be done by synchronizing on operations in the frame and depth buffers, or by keeping separate frame and depth buffers for each processor and merging the buffers after all primitives are processed [Weinberg81] <ref> [Molnar92] </ref>. It is not difficult to use both object parallelism and image subdivision parallelism at the same time. The only real difficult problem is load balancing when different parts of the image have different complexities and some primitives are much larger than others [Whitman92]. The painter's algorithm is very sequential.
Reference: [Moravec81] <author> Hans P. Moravec, </author> <title> "3D Graphics and the Wave Theory," </title> <journal> Computer Graphics, </journal> <volume> Vol. 15, No. </volume> <booktitle> 3 (Proceedings of ACM SIGGRAPH 81), </booktitle> <month> August </month> <year> 1981. </year>
Reference-contexts: Reflections and refractions are calculated by simple approximations as properties of surfaces and interfaces rather than as boundary conditions for wave equa tions. One attempt to use a wave model of light on the macro scale in image synthesis produced very discouraging results <ref> [Moravec81] </ref> and no other efforts have followed. On the micro scale [He91] has used the wave model for calculating surface reflectance properties but this is outside the scope of image synthesis. <p> On the other hand, the wavefront propagation algorithm treats light as a complex-valued wave phenomenon, which propagates in spherical wave fronts from every point in the scene. Some experiments have been reported that use the wave model of light for image synthesis (see <ref> [Moravec81] </ref>), but the results have been discouraging due to limitations on primitive sizes and spacing, massive amounts of data and calculations, serious diffraction problems, and coherent light speckle.
Reference: [Muller86] <author> H. Muller, </author> <title> "Image Generation by Space Sweep," </title> <journal> Computer Graphics Forum, </journal> <volume> Vol. </volume> <month> 5 </month> <year> 1986. </year>
Reference: [Musgrave90] <author> F. Kenton Musgrave, </author> <title> "A Note of Ray Tracing Mirages," </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> Vol. 10, No. 6, </volume> <month> November </month> <year> 1990. </year>
Reference-contexts: This problem requires one to solve a differential equation initial value problem to trace a ray [Barr86]. This complicates everything so much that this effect is never used in image synthesis except for special purpose systems designed only to calculate this effect, for example: simulating mirages [Kallman86] [Berger90] <ref> [Musgrave90] </ref> [Lehn92]. The main object/light interaction is reflection.
Reference: [Myers75] <author> A. J. Myers, </author> <title> "An Efficient Visible Surface Program," </title> <note> Technical Report to the National Science Foundation, Grant No. DCR 74-00768A01 1975. </note>
Reference-contexts: Test First Global Presorted Scan Ray Trace 2 Test Mid Local Presorted Scan Ray Trace 2 Test Last Scan Ray Trace [Crow92] (Conley) For Each Object Test Each Pixel 8 &gt; &gt; &gt; : Test First Global Scan Painter's [Schumacker69] Test Mid Local Scan Painter's [Sutherland73] Test Last Scan Z-buffer <ref> [Myers75] </ref> Subdivide by X and Y &gt; &gt; &gt; &lt; Test First Global Presorted Scan Line 2 Test Mid Local Presorted Scan Line 2 Test Last Scan Line [Wylie67] 1 Uninvestigated new algorithm. 2 New algorithm described in chapter 4. 41 Ray Trace Whitted 79 Z-buffer Catmull 74 Presorted Ray Trace <p> Only one scan line of the image and depth buffer are in memory at a time. This organization was used by <ref> [Myers75] </ref> [Hackathorn77] for polygons and [Porter78] for spheres.
Reference: [Naylor86] <author> B. F. Naylor, W.C. Thibault, </author> <title> "Application of BSP Trees to Ray-tracing and CSG Evaluation," </title> <type> Technical Report, </type> <institution> GIT-ICS 86/03, School of Information and Computer Science, Georgia Institute of Technology, Atlanta, Georgia 1986. </institution>
Reference: [Newell72] <author> M. E. Newell, R. G. Newell, T. L. Sancha, </author> <title> "A Solution to the Hidden Surface Problem," </title> <booktitle> Proceedings of the ACM 1972 National Conference (reprinted in [Freeman80]). </booktitle>
Reference-contexts: This analysis of visibility algorithms was performed between 1972 and 1973. This study focused on the structures of the algorithms in use or envisioned at that time. Each of the eight visible surface algorithms studied (six published at the time [Watkins69] [Bouknight69] [Romney70] [Warnock69] <ref> [Newell72] </ref> [Schumacker69]) solved essentially the same version of the visibility problem, point sampling with planar polygons. There were no continuous visible surface algorithms at that time. Four visible line algorithms ([Roberts63] [Galimberti69] [Loutrell67] [Appel67]) were also considered. The taxonomy that resulted from this study is shown in figure 2.6. <p> No tests are performed in the second pass. The method for initially sorting the objects into the depth priority list is the crucial factor for determining the efficiency of this algorithm <ref> [Newell72] </ref>. If only a restricted class of scenes are allowed so that the depth ordering is known a priori, this algorithm is very efficient [Schumacker69]. <p> &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; : No Subdivision 8 &gt; &gt; &gt; &gt; &gt; &gt; &gt; : For Each Pixel Test Each Object ( Test First Presorted Ray Trace 2 Test Last Ray Trace [Whitted79] For Each Object Test Each Pixel ( Test First Painter's <ref> [Newell72] </ref> Test Last - Z-buffer [Catmull74] Subdivide by X 8 &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; : For Each Pixel Test Each Object 8 &gt; &gt; &gt; : Test First Global Presorted Scan Ray Trace 2 Test Mid Local Presorted Scan Ray Trace <p> However, there is much more data available now, and some of the fundamental assumptions have changed. SSS did succeed in identifying examples of most of the major algorithms that are in use today: scan line [Watkins69], [Bouknight69], [Romney70], painter's <ref> [Newell72] </ref>, [Schumacker69], subdivision [Warnock69], z-buffer (brute force), and ray tracing (brute force). Only the scan plane algorithms which were first published in [Hamlin77] were not anticipated. <p> The maximum error occurs when the light source and view point directions are perpendicular. Subdividing the primitives will fix this problem for any type of primitive. Subdivision techniques for resolving conflicts in the painter's algorithm are discussed in <ref> [Newell72] </ref> and [Newman79]. The overlap tests used in this technique must be extended to test for overlap from two view points. This priority conflict error is assumed not to occur with particle systems.
Reference: [Newman79] <author> William M. Newman, Robert F. Sproull, </author> <title> Principles of Interactive Computer Graphics, Second Edition, </title> <publisher> McGraw Hill Book Company, </publisher> <address> New York 1979. </address> <month> 175 </month>
Reference-contexts: The maximum error occurs when the light source and view point directions are perpendicular. Subdividing the primitives will fix this problem for any type of primitive. Subdivision techniques for resolving conflicts in the painter's algorithm are discussed in [Newell72] and <ref> [Newman79] </ref>. The overlap tests used in this technique must be extended to test for overlap from two view points. This priority conflict error is assumed not to occur with particle systems.
Reference: [Nishita83] <author> Tomoyuki Nishita, Eihachiro Hakamae, </author> <title> "Half-tone Representation of 3-d Objects Illuminated by Area Sources or Polyhedron Sources," </title> <address> COMPSAC83, </address> <month> November </month> <year> 1983. </year>
Reference-contexts: This type of area light source has been modeled and approximated in several ways. A collection of point sources can approximate an area source [Brotman84]. Light sources can also be directly specified as areas <ref> [Nishita83] </ref> [Cook84]. It is also possible for the light emitting part of a light source to be distributed over a volume of space rather than on a surface, if the light source itself is at least partially transparent. <p> This approach is still very expensive since a complete visibility problem and illumination integral must be solved for each pixel in the image formation phase. The illumination can be calculated on a coarser scale and intermediate values approximated by interpolation <ref> [Nishita83] </ref> with a resulting loss of accuracy. The same anti-aliasing and parallel processing considerations for the umbra paradigm are present with the penumbra paradigm. 96 5.3.10 Ray Tracing Paradigms Ray tracing paradigm systems are very similar algorithmically. They all calculate visibility in the direction from the viewpoint into the scene.
Reference: [Nishita85a] <author> Tomoyuki Nishita, Isao Okamura, Eihachiro Nakamae, </author> <title> "Shading Models for Point and Linear Sources," </title> <journal> ACM Transactions on Graphics, </journal> <volume> Vol. 4, No. </volume> <month> 2 </month> <year> 1985. </year>
Reference-contexts: The simplest case is to assume that this intensity is constant. A large class of physical light sources, such as spotlights and flashlights, can be approximated by radially symmetric intensity distributions about an axis in a particular direction. These types of light sources have been modeled by [Verbeck84] and <ref> [Nishita85a] </ref>. [Warn83] has simulated photographer's lamps with flaps. The entire sky can be considered to be a large hemispherical light source with an intensity that varies with location on the hemisphere.
Reference: [Nishita85b] <author> Tomoyuki Nishita, Eihachiro Nakamae, </author> <title> "Continuous Tone Representation of Three Dimensional Objects Taking Account of Shadows and Interreflection," </title> <journal> Computer Graphics, </journal> <volume> Vol. 19, No. </volume> <booktitle> 3 (Proceedings of ACM SIGGRAPH 85), </booktitle> <month> July </month> <year> 1985. </year>
Reference: [Nishita86] <author> Tomoyuki Nishita, Eihachiro Nakamae, </author> <title> "Continuous tone representation of three dimensional objects illuminated by sky light," </title> <journal> Computer Graphics, </journal> <volume> Vol. 20, No. </volume> <booktitle> 4 (Proceedings of ACM SIGGRAPH 86), </booktitle> <month> August </month> <year> 1986. </year>
Reference-contexts: The entire sky can be considered to be a large hemispherical light source with an intensity that varies with location on the hemisphere. Such a light source has been used by <ref> [Nishita86] </ref> and [Max87] to calculate realistic outdoor scenes. 2.2.3 Light Propagation Modeling This subproblem addresses the simple case of modeling the light passing through free space or some transparent medium without interacting with opaque objects. The interaction with opaque objects will be handled as next subproblem.
Reference: [Nishita90] <author> T. Nishita, K. Kanada, E. Nakamae, </author> <title> "High Quality Rendering of Parametric Surfaces by Using a Robust Scanline Algorithm," CG International 90, </title> <editor> T. S. Chua, T. L. Kunii (Eds.) </editor> <publisher> Springer-Verlag, </publisher> <address> Tokyo, </address> <year> 1990. </year>
Reference-contexts: This is the zero-dimensional test version of the direct independent of systems systems. If the image formation algorithm produces continuous one-dimensional visible spans along a scan line, each span can be tested for illumination as a unit. <ref> [Nishita90] </ref> presents such a span based direct independent algorithm for bi-cubic patches. The image formation algorithm determines horizontal spans on the patches which are completely visible. Each one-dimensional span is then tested for visibility from the light source. The results of this illumination test are used to shade the span. <p> A one-dimensional direct independent illumination test has been implemented in a scan line system by <ref> [Nishita90] </ref> which illuminates spans across bicubic patches. This algorithm uses a triangle intersection routine very similar to a ray intersection routine used in ray tracing. Creating a one-dimensional extension of zero-dimensional ray tracing. A two-dimensional direct independent illumination test using a BSP-tree has been implemented by [Garcia86] [Chin89].
Reference: [Nurmi85] <author> O. Nurmi, </author> <title> "A Fast Line-sweep Algorithm for Hidden Line Elimination," </title> <journal> BIT, </journal> <volume> Vol. 25, No. </volume> <month> 3 </month> <year> 1985. </year>
Reference: [Okino84] <author> Norio Okino, Yukinori Kakazu, Masamichi Morimoto, </author> <title> "Extended Depth-buffer Algorithms for Hidden-surface Visualization," </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> Vol. 4, No. 5, </volume> <month> May </month> <year> 1984. </year>
Reference: [Parke80] <author> Frederic I. Parke, </author> <title> "Simulation and Expected Performance Analysis of Multiple Processor Z-buffer Systems," </title> <journal> Computer Graphics, </journal> <volume> Vol. 14, No. </volume> <booktitle> 3 (Proceedings of ACM SIGGRAPH 80), </booktitle> <month> July </month> <year> 1980. </year>
Reference-contexts: The z-buffer algorithm is easily run in parallel because the basic operations are very independent <ref> [Parke80] </ref> [Fiume83]. Different processors can scan convert different parts of the same primitives into different sections of the image in parallel [Fuchs81] [Fuchs83]. Different processors can also be processing different primitives into the same section of the image at the same time [Fuchs89].
Reference: [Bui-Tuong75] <author> Bui-Tuong Phong, </author> <title> "Illumination for Computer Generated Pictures," </title> <journal> Communications of the ACM, </journal> <volume> Vol. 18, No. </volume> <pages> 6, </pages> <note> June 1975 (reprinted in [Beatty82]) (UTEC-CSC-73-129 Dept. </note> <institution> of Computer Science, University of Utah). </institution>
Reference: [Plunkett85] <author> David J. Plunkett, Michael J. Bailey, </author> <title> "The Vectorization of a Ray-tracing Algorithm for Improved Execution Speed," </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> Vol. 5 No. 8, </volume> <month> August </month> <year> 1985. </year>
Reference-contexts: Each ray processor maintains the value of the closest intersection in its local memory. Processors can also be assigned to objects with the rays pipelined through all the object processors [Chang83]. A similar software organization can be used on vector processors [Max81] <ref> [Plunkett85] </ref>. A ray broadcasting architecture is not efficient for object based parallelism since results must be accumulated and compared for each ray. Pipelining the rays allows the intersection test results to be propagated with the ray.
Reference: [Porter78] <author> Thomas K. </author> <title> Porter, </title> <journal> "Spherical Shading" Computer Graphics. </journal> <volume> Vol. 12, No. </volume> <booktitle> 3 (Proceedings of ACM SIGGRAPH 78), </booktitle> <month> August </month> <year> 1978. </year>
Reference-contexts: Only one scan line of the image and depth buffer are in memory at a time. This organization was used by [Myers75] [Hackathorn77] for polygons and <ref> [Porter78] </ref> for spheres. <p> Uncorrelated Objects If the uncorrelated position assumption holds (as in figure 4.6a) then it is easy to see that the amount of the area of the back polygon that is visible in the resulting pixel is calculated exactly by the uncorrelated compositing operator, OVER u , shown in figure 4.7. <ref> [Porter78] </ref> describes two methods of storing the color information in this four channel format.
Reference: [Porter84] <author> Thomas K. Porter, Tom Duff, </author> <title> "Compositing Digital Images," </title> <journal> Computer Graphics, </journal> <volume> Vol. </volume> <pages> 18, </pages> <note> No. 3 (Proceedings of ACM SIGGRAPH 84), July 1984 (reprinted in [Joy87]). </note>
Reference-contexts: With respect to computer graphics, aliasing was first extensively discussed by [Crow77b]. Since then attempts to reduce this problem have been an extensive area of research [Crow81] [Feibush80] [Carpenter84] [Catmull78] [Catmull84] [Cook84] [Cook86] [Dippe85a] [Dippe85b] [Duff85] [Fiume83] [Fujimoto83] [Grant85] [Hourcade85] [Lee85] [Max85] [Max90] <ref> [Porter84] </ref> [Reeves87] [Szabo83] [Whit-ted82]. 2.3.2.1 Signals and Samples For the purposed of this discussion, a continuous signal is a function which is defined almost everywhere within some domain. 4 For example, the two-dimensional signal representing the color of a polygonal scene with the color defined on the interiors of the polygons <p> Storage at each pixel is no longer constant, but depends on scene complexity. Scenes with many tiny polygons smaller than a pixel will cause the A-buffer to be very large, because many polygons will be visible at each pixel. The digital compositing techniques formalized in <ref> [Porter84] </ref> (and used previously in [Levoy77] [Stern79] [Wallace81]) are another example of using approximate geometric information for antialiasing. In this algorithm the painter's algorithm is extended to include with each pixel a number which describes the fraction of the pixel that is covered by primitives. <p> This advantage is shared with all FTB painter's algorithms, and all two-pass BTF painter's algorithms. The subpixel coverage mask enhancement of the painter's algorithm does not introduce any errors or approximations not present in the non-antialiased painter's algorithm. 4.2.4 Compositing Algorithms with A Priori Correlation Assumptions <ref> [Porter84] </ref> has formalized a technique of representing and operating on images that use a single coverage value (called ff) which represents the percentage of "coverage" of the pixel. Geometric information about the location of the coverage within the pixel is not calculated, stored, or used. <p> In this section we will assume that the correlations of the polygons are known before phase two of the painter's algorithm begins. Subsection 4.2.4.1 explores algorithms using the assumption that all edges are uncorrelated with all others. This was the original assumption made by <ref> [Porter84] </ref>. This assumption is good for particle systems and semi-transparent volumes. Subsection 4.2.4.2 explores algorithms that make the opposite assumption, that all edges are correlated (negative correlation as defined in figure 4.6b). This assumption is good for objects subdivided into many small polygons. <p> FTB order was used in the system described in [Crow82] but the use of FTB order was not described in the paper. <ref> [Porter84] </ref> developed a compositing operator assuming that all primitives are uncorrelated. Here we develop a compositing operator using the opposite assumption that all primitives are correlated (ie. negative correlation as defined previously in figure 4.6b). Specifically we assume that correlated primitives occur in layers. <p> The SMS algorithm can use objects with uncorrelated or correlated edges and shadows with uncorrelated or correlated edges. This is determined by which version of the painter's algorithm from chapter 4 is being used. A system which uses only uncorrelated primitives can use the simple uncorrelated compositing operator of <ref> [Porter84] </ref>. SMS systems using particles or volume densities were implemented and described in [Grant87b].
Reference: [Preparata85] <author> Franco P. Preparata, Michael Ian Shamos, </author> <title> Computational Geometry: An Introduction, </title> <publisher> Springer Verlag, </publisher> <address> New York, </address> <year> 1985. </year>
Reference-contexts: There are two basic classes of continuous algorithms: scan plane algorithms and subdivision algorithms. These algorithms are described in the following two sections. 3.1.2.1 The Scan Plane Algorithm The scan plane visibility algorithms operate similar to scan plane algorithms for other problems in computational geometry <ref> [Preparata85] </ref> [Mehlhorn84]. Basically a plane is scanned through the three-dimensional data and calculations are performed only at "interesting" places in the data where things change. Between these interesting places, things are assumed to be continuous.
Reference: [Reeves83] <author> William T. Reeves, </author> <title> "Particle Systems aTechnique for Modelling a Class of Fuzzy Objects," </title> <journal> Computer Graphics Vol. </journal> <volume> 17, No. </volume> <booktitle> 3 (Proceedings of ACM SIG-GRAPH 83), </booktitle> <month> July </month> <year> 1983. </year> <month> 176 </month>
Reference-contexts: D = 0 [Barr81] [Franklin81] ffi Blobby particles K P all objects f (object; x; y; z) = 0 [Blinn82] * Parametric surfaces S = F (u; v) ffi Bi-cubic parametric patches [Catmull74] [Catmull75] ffi Superquadric surfaces (parametric form) [Barr81] [Franklin81] ffi Triangular patches [Sederberg84] * Procedural primitives ffi Particles <ref> [Reeves83] </ref> ffi Densities [Kajiya84] ffi Fractals [Fournier82] 2.2.2 Light Source Modeling Light enters a scene through or is generated by objects called light sources. Light sources of varying complexity are possible. The simplest possible assumption is that illumination is perfectly uniform throughout the scene. <p> It is also the case that simple depth rela tionships exist for volume rendering regularly sampled volumes using projection methods [Levoy88] [Frieder85], non-regularly sampled volumes [Max90b], particle systems <ref> [Reeves83] </ref> [Reeves85], and height fields [Fishman80]. For a more general and efficient solution [Fuchs79] [Fuchs80] uses a binary space partition (BSP) tree to store the objects in the scene. This BSP tree can then be easily traversed in depth priority order. <p> Since the exact geometric relationship between the two objects is not known, the OVER opera tor assumes a particular geometric relationship that the object edges are uncorrelated. This works well for randomly placed and oriented objects <ref> [Reeves83] </ref> [Reeves85], but fails for highly correlated arrangements of primitives, such as a grid of polygons. New techniques for extending the painter's algorithm to use approximate geometric information for antialiasing of correlated and uncorrelated object edges is presented in the next chapter. <p> An ff value of one represents complete coverage (opacity) while an ff value of zero represents no coverage (complete transparency). This technique has been extensively used with the painter's algorithm and so-called "2 1/2D" rendering systems [Crow82] [Levoy77] [Max85] <ref> [Reeves83] </ref> [Reeves85] [Stern79] [Wallace81]. The exact value of the intensity contributions of two possibly overlapping antialiased polygon fragments to the intensity of a pixel is a complex calculation which depends on the exact positions of the edges. The definitions of the major cases of interest are shown in figure 4.6.
Reference: [Reeves85] <author> William T. Reeves, Ricki Blau, </author> <title> "Approximate and Probabilistic Algorithms for Shading and Rendering Structured Particle Systems," </title> <journal> Computer Graphics, </journal> <volume> Vol. 19, No. </volume> <booktitle> 3 (Proceedings of AMC SIGGRAPH 85) July 1985. </booktitle>
Reference-contexts: It is also the case that simple depth rela tionships exist for volume rendering regularly sampled volumes using projection methods [Levoy88] [Frieder85], non-regularly sampled volumes [Max90b], particle systems [Reeves83] <ref> [Reeves85] </ref>, and height fields [Fishman80]. For a more general and efficient solution [Fuchs79] [Fuchs80] uses a binary space partition (BSP) tree to store the objects in the scene. This BSP tree can then be easily traversed in depth priority order. <p> Since the exact geometric relationship between the two objects is not known, the OVER opera tor assumes a particular geometric relationship that the object edges are uncorrelated. This works well for randomly placed and oriented objects [Reeves83] <ref> [Reeves85] </ref>, but fails for highly correlated arrangements of primitives, such as a grid of polygons. New techniques for extending the painter's algorithm to use approximate geometric information for antialiasing of correlated and uncorrelated object edges is presented in the next chapter. <p> An ff value of one represents complete coverage (opacity) while an ff value of zero represents no coverage (complete transparency). This technique has been extensively used with the painter's algorithm and so-called "2 1/2D" rendering systems [Crow82] [Levoy77] [Max85] [Reeves83] <ref> [Reeves85] </ref> [Stern79] [Wallace81]. The exact value of the intensity contributions of two possibly overlapping antialiased polygon fragments to the intensity of a pixel is a complex calculation which depends on the exact positions of the edges. The definitions of the major cases of interest are shown in figure 4.6.
Reference: [Reeves87] <author> William T. Reeves, David H. Salesin, Robert L. Cook, </author> <title> "Rendering An-tialiased Shadows with Depth Maps," </title> <journal> Computer Graphics, </journal> <volume> Vol 21, No. </volume> <booktitle> 4 (Proceedings of ACM SIGGRAPH'87), </booktitle> <month> July </month> <year> 1987. </year>
Reference-contexts: With respect to computer graphics, aliasing was first extensively discussed by [Crow77b]. Since then attempts to reduce this problem have been an extensive area of research [Crow81] [Feibush80] [Carpenter84] [Catmull78] [Catmull84] [Cook84] [Cook86] [Dippe85a] [Dippe85b] [Duff85] [Fiume83] [Fujimoto83] [Grant85] [Hourcade85] [Lee85] [Max85] [Max90] [Porter84] <ref> [Reeves87] </ref> [Szabo83] [Whit-ted82]. 2.3.2.1 Signals and Samples For the purposed of this discussion, a continuous signal is a function which is defined almost everywhere within some domain. 4 For example, the two-dimensional signal representing the color of a polygonal scene with the color defined on the interiors of the polygons and <p> Third, consider the values of adjacent pixels in the shadow buffer to help reduce some aliasing artifacts. These techniques preserve all the desirable properties of the depth buffer visible surface algorithm while yielding more accurate shadows. In a related effort, <ref> [Reeves87] </ref> presents a modified version of [Williams78] by adding "percentage closer filtering" to produce soft shadow boundaries, but this did not address the most significant problems of the original algorithm. <p> Small object aliasing is a fundamental prob lem with point sampled algorithms and can be avoided only by not using small objects (of course the definition of "small" changes as the resolution increases). Sharp shadow edges can be blurred by using percentage closer filtering <ref> [Reeves87] </ref>, although this also introduces blurring in some undesirable places. The jagged shadow edges problem can be suppressed through using high resolution shadow depth buffers. If the shadow depth buffer is about twice the resolution of the final image this is usually not a problem. <p> This backface culling removes the self-canceling error property of smooth terminators, but yields a significant speedup in the scan conversion. 145 146 147 148 Percentage closer filtering <ref> [Reeves87] </ref> is very effective at blurring the shadow of an edge cast on another surface. It, however, does blur shadow edges in places where this is an error. In figure 6.39 the p2-buffer with neighborhood search is used with percentage closer filtering (compare with figure 6.29 without neighborhood searching).
Reference: [Roberts63] <author> L. G. Roberts, </author> <title> Machine Perception of 3d Solids, </title> <type> TR 315 Lincoln Laboratory, </type> <institution> MIT 1963. </institution>
Reference: [Rodgers85] <author> David F. Rodgers, </author> <title> Procedural Elements for Computer Graphics, </title> <publisher> McGraw-Hill Book Company, </publisher> <address> New York 1985. </address>
Reference-contexts: Point light sources obeying the inverse square law can yield images with a very wide dynamic range of intensities, too wide to represent on a CRT or film. <ref> [Rodgers85] </ref> uses an inverse linear function, 1=(k + distance), to reduce the dynamic range. Divergence is frequently 10 completely ignored in simple systems.
Reference: [Romney70] <author> G. W. </author> <title> Romney "Computer Assisted Assembly and Rendering of Solids," </title> <institution> Dept. of Computer Science, University of Utah, </institution> <month> TR-4-20 </month> <year> 1970. </year>
Reference-contexts: This analysis of visibility algorithms was performed between 1972 and 1973. This study focused on the structures of the algorithms in use or envisioned at that time. Each of the eight visible surface algorithms studied (six published at the time [Watkins69] [Bouknight69] <ref> [Romney70] </ref> [Warnock69] [Newell72] [Schumacker69]) solved essentially the same version of the visibility problem, point sampling with planar polygons. There were no continuous visible surface algorithms at that time. Four visible line algorithms ([Roberts63] [Galimberti69] [Loutrell67] [Appel67]) were also considered. <p> However, there is much more data available now, and some of the fundamental assumptions have changed. SSS did succeed in identifying examples of most of the major algorithms that are in use today: scan line [Watkins69], [Bouknight69], <ref> [Romney70] </ref>, painter's [Newell72], [Schumacker69], subdivision [Warnock69], z-buffer (brute force), and ray tracing (brute force). Only the scan plane algorithms which were first published in [Hamlin77] were not anticipated.
Reference: [Rossignac86] <author> Jaroslaw R. Rossignac, Aristides A. G. Requicha, </author> <title> "Depth-Buffering Display Techniques for Constructive Solid Geometry," </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> Vol. 6, No. 9, </volume> <month> September </month> <year> 1986. </year>
Reference: [Rubin80] <author> Steven M. Rubin, Turner Whitted, </author> <title> "A 3-Dimensional Representation for Fast Rendering of Complex Scenes," </title> <journal> Computer Graphics, </journal> <volume> Vol. 14, No. </volume> <booktitle> 3 (Proceedings of ACM SIGGRAPH 80), </booktitle> <month> July </month> <year> 1980. </year>
Reference-contexts: Many methods are in use for these techniques. The oldest and most popular is a hierarchical series of bounding extents to group objects into units which can be, in most cases, trivially rejected for further testing as a unit <ref> [Rubin80] </ref>. [Kay86] traverses this hierarchical data structure in an intelligent manner greatly increasing efficiency. Newer techniques divide the object space into sections and each section contains a list of the primitives in that section. <p> The subdivision reduces the size of the problems that the rest of the algorithm must solve. This has recently been used as a technique for speeding up ray 47 tracing. [Fujimoto86] uses a three-dimensional space-based uniform subdivision. [Ka-plan85] and [Glassner84] use a three-dimensional space-based hierarchical subdivision. <ref> [Rubin80] </ref> and [Kay86] use a three-dimensional object-based hierarchical subdivision. [Dippe84] uses a three-dimensional space-based semi-regular subdivision. [Cleary86] compares two-dimensional and three-dimensional space-based regular subdivision techniques for ray tracing on a multiprocessor. [Fuchs79] [Fuchs80] uses a three-dimensional object-based subdivision as a preprocessing step for the painter's algorithm. [Franklin80] has shown that proper
Reference: [Samet90] <author> Hannen Samet, </author> <title> Applications of Spatial Data Structures, </title> <publisher> Addison-Westley Publishing Company, </publisher> <address> Reading, Massachusetts 1990. </address>
Reference-contexts: With subdivision algorithms there are many choices of how the subdivision can be made defining different dimensions in a subdivision algorithm space, but there is no single basis algorithm. Subdivision can be two-dimensional [Warnock69] [Weiler77] [Franklin80] or three-dimensional [Fuchs79] [Fuchs80] [Fujimoto86] [Glassner84] <ref> [Samet90] </ref> or higher dimensional [Arvo87] [Grant85] [Glassner88]. The subdivisions can be specified in screen coordinates based on dividing the image [Warnock69] [Catmull78] [Catmull84] or in object coor dinates based on dividing the scene independent of the viewpoint [Fujimoto86]. <p> The locations of subdivisions can be made independent of the data in the scene [Franklin80] [Catmull78] [Catmull84] or at significant object points [Fuchs79] [Fuchs80] [Weiler77]. The subdivisions can be orthogonal to the coordinate axes <ref> [Samet90] </ref> [Bentley79] [Cat-mull78] [Catmull84] [Glassner84] [Kaplan85] [Warnock69] or at arbitrary angles [Fuchs79] [Fuchs80] [Weiler77]. The subdivision can be at a fixed resolution [Franklin80] [Cat-mull78] [Catmull84] or adaptive hierarchically [Fuchs79] [Fuchs80] [Glassner84] [Ka-plan85] [Warnock69] [Samet90]. <p> The subdivisions can be orthogonal to the coordinate axes <ref> [Samet90] </ref> [Bentley79] [Cat-mull78] [Catmull84] [Glassner84] [Kaplan85] [Warnock69] or at arbitrary angles [Fuchs79] [Fuchs80] [Weiler77]. The subdivision can be at a fixed resolution [Franklin80] [Cat-mull78] [Catmull84] or adaptive hierarchically [Fuchs79] [Fuchs80] [Glassner84] [Ka-plan85] [Warnock69] [Samet90]. The subdivision can be based on presorting the input primitives [Weiler77] or the input primitives can be processed in any order. 3.4 A New Classification of Visibility Algorithms In this section the new taxonomy of the basic visibility algorithms is presented. This taxonomy is summarized in figure 3.7. <p> &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; : 8 &gt; &gt; &gt; &gt; &gt; &gt; &gt; : Object Based ( Presorted - 3d Presort 1 Non-presorted - BSP-tree [Fuchs79] Space Based ( Uniform - Voxel [Chen85] Hierarchical - Octree <ref> [Samet90] </ref> 2d &gt; &gt; &gt; &gt; &gt; &gt; &gt; &lt; Object Based ( Presorted Sorted Clipper [Weiler77] Non-presorted Clipper [Grant85] Space Based ( Uniform - 2d Grid [Franklin80] Hierarchical - Quadtree [Warnock69] Point Sampled Only 8 &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; <p> In fact no sort at all yields the previous clipper algorithm. The sort merely improves the efficiency of the algorithm. This technnique was used in [Weiler77]. 3.4.2.5 Octree Algorithm An octree is a recursive subdivision of a cube into octants <ref> [Samet90] </ref>. It is the tree-dimensional extension of the quadtree. The orthogonal nature of the subdivision gives a regular pattern of subregions overlapping and obscuring adjacent subregions from a given viewpoint. This regular pattern allows the octree to be easily traversed in an order consistant with visibility calculations. <p> One possible sorting order was overlooked in this study, sorting in all three dimensions at the same time, the (XYZ) order. This sorting order corresponds to algorithms that use a three-dimensional data structure and sort such as the octree <ref> [Samet90] </ref>, BSP tree [Fuchs79] [Fuchs80] or k-d tree [Bentley79]. The use of coherence to speed algorithms has not advanced much. One reason for this is that the average size primitive has shrunk over the years as computer generated scenes get more and more complex.
Reference: [Schumacker69] <author> R. A. Schumacker, B. Brand, M. Gilliland, W. Sharp, </author> <title> "Study for Applying Computer Generated Images to Visual Simulation," AFHRL-TR-69-14, </title> <type> U.S. </type> <institution> Air Force Human Resources Laboratory, </institution> <month> September </month> <year> 1969. </year>
Reference-contexts: This analysis of visibility algorithms was performed between 1972 and 1973. This study focused on the structures of the algorithms in use or envisioned at that time. Each of the eight visible surface algorithms studied (six published at the time [Watkins69] [Bouknight69] [Romney70] [Warnock69] [Newell72] <ref> [Schumacker69] </ref>) solved essentially the same version of the visibility problem, point sampling with planar polygons. There were no continuous visible surface algorithms at that time. Four visible line algorithms ([Roberts63] [Galimberti69] [Loutrell67] [Appel67]) were also considered. The taxonomy that resulted from this study is shown in figure 2.6. <p> The method for initially sorting the objects into the depth priority list is the crucial factor for determining the efficiency of this algorithm [Newell72]. If only a restricted class of scenes are allowed so that the depth ordering is known a priori, this algorithm is very efficient <ref> [Schumacker69] </ref>. It is also the case that simple depth rela tionships exist for volume rendering regularly sampled volumes using projection methods [Levoy88] [Frieder85], non-regularly sampled volumes [Max90b], particle systems [Reeves83] [Reeves85], and height fields [Fishman80]. <p> For Each Pixel Test Each Object 8 &gt; &gt; &gt; : Test First Global Presorted Scan Ray Trace 2 Test Mid Local Presorted Scan Ray Trace 2 Test Last Scan Ray Trace [Crow92] (Conley) For Each Object Test Each Pixel 8 &gt; &gt; &gt; : Test First Global Scan Painter's <ref> [Schumacker69] </ref> Test Mid Local Scan Painter's [Sutherland73] Test Last Scan Z-buffer [Myers75] Subdivide by X and Y &gt; &gt; &gt; &lt; Test First Global Presorted Scan Line 2 Test Mid Local Presorted Scan Line 2 Test Last Scan Line [Wylie67] 1 Uninvestigated new algorithm. 2 New algorithm described in chapter 4. <p> Only one scan line is in memory at a time. This one line at a time organization was used by <ref> [Schumacker69] </ref>. The term "global" indicates that a single global sort of all objects is performed. <p> However, there is much more data available now, and some of the fundamental assumptions have changed. SSS did succeed in identifying examples of most of the major algorithms that are in use today: scan line [Watkins69], [Bouknight69], [Romney70], painter's [Newell72], <ref> [Schumacker69] </ref>, subdivision [Warnock69], z-buffer (brute force), and ray tracing (brute force). Only the scan plane algorithms which were first published in [Hamlin77] were not anticipated.
Reference: [Schumacker80] <author> Robert A. Schumacker, </author> <title> "A New Visual System Architecture," </title> <booktitle> Second Interservice/Industry Training Equipment Conference, </booktitle> <month> November </month> <year> 1980. </year>
Reference-contexts: The basic painter's algorithm can be performed in FTB order by adding a single bit coverage flag to each pixel. FTB was used in the Evans and Sutherland CT5 flight simulator <ref> [Schumacker80] </ref>, a hardware line drawing system [Wein78], and [Crow82]. This flag is initialized to indicate that the pixel has not been painted (i.e. is uncovered). When the first (closest) primitive paints over this pixel, the bit is set to indicate that it is now covered. <p> Using super sampling for antialiasing does not introduce any errors or approximations not present in the non-antialiased painter's algorithm. 4.2.3 Subpixel Coverage Mask Compositing Algorithms The subpixel coverage mask extension of the painter's algorithm is a simplification of super sampling <ref> [Schumacker80] </ref>. For super sampling, each final pixel stores s color values for the s samples per pixel. For the subpixel coverage mask extension, each final pixel stores only one color value and a coverage mask of s bits.
Reference: [Sechrest81] <author> Stuart Sechrest, Donald P. Greenberg, </author> <title> "A Visible Polygon Reconstruction Algorithm," </title> <journal> ACM Transactions on Graphics, </journal> <volume> Vol. 1, No. </volume> <pages> 1, </pages> <note> 1982 (also in Proceedings of ACM SIGGRAPH 81). </note>
Reference-contexts: At each step a list of interesting points generated by intersections of active objects must be maintained so that the next interesting point can be predicted. This type algorithm has been implemented by [Hamlin77] <ref> [Sechrest81] </ref> and [Sequin85]. 3.1.2.2 Subdivision Algorithms The subdivision visibility algorithms operate on the principle of divide and conquer. That is, if the problem is divided into subproblems then the subproblems will usually be smaller and easier to solve.
Reference: [Sederberg84] <author> Thomas W. Sederberg, David C. Anderson, </author> <title> "Ray Tracing of Steiner Patches," </title> <journal> Computer Graphics, </journal> <volume> Vol. 18, No. </volume> <booktitle> 3 (Proceedings of ACM SIGGRAPH 84), </booktitle> <month> July, </month> <year> 1984. </year>
Reference-contexts: By n + Cz n + D = 0 [Barr81] [Franklin81] ffi Blobby particles K P all objects f (object; x; y; z) = 0 [Blinn82] * Parametric surfaces S = F (u; v) ffi Bi-cubic parametric patches [Catmull74] [Catmull75] ffi Superquadric surfaces (parametric form) [Barr81] [Franklin81] ffi Triangular patches <ref> [Sederberg84] </ref> * Procedural primitives ffi Particles [Reeves83] ffi Densities [Kajiya84] ffi Fractals [Fournier82] 2.2.2 Light Source Modeling Light enters a scene through or is generated by objects called light sources. Light sources of varying complexity are possible. The simplest possible assumption is that illumination is perfectly uniform throughout the scene.
Reference: [Segal92] <author> Mark Segal, Carl Korobkin, Rolf van Widenfelt, Jim Foran, Paul Haeberli, </author> <title> "Fast Shadows and Lighting Effects Using Texture Mapping," </title> <journal> Computer Graphics, </journal> <volume> Vol. 26, No. </volume> <booktitle> 2 (Proceedings of ACM SIGGRAPH 92), </booktitle> <month> July </month> <year> 1992. </year>
Reference-contexts: Thus the amount of available coherence gets smaller and smaller. This may change as the use of hardware texture mapping becomes more common in image synthesis <ref> [Segal92] </ref>, but probably not. 48 3.6 Evaluation of Current Visibility Algorithms In practice, the theoretical image quality advantages of the continuous algorithms are far outweighed by their tremendous complexity and the limited primitives and effects they can support. Usually only polygons are supported with no indirect effects.
Reference: [Sequin85] <author> Carlo H. Sequin, Paul R. Wensley, </author> <title> "Visible Feature Return at Object Resolution," </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> Vol. 5, No. 5, </volume> <month> May </month> <year> 1985. </year> <month> 177 </month>
Reference-contexts: At each step a list of interesting points generated by intersections of active objects must be maintained so that the next interesting point can be predicted. This type algorithm has been implemented by [Hamlin77] [Sechrest81] and <ref> [Sequin85] </ref>. 3.1.2.2 Subdivision Algorithms The subdivision visibility algorithms operate on the principle of divide and conquer. That is, if the problem is divided into subproblems then the subproblems will usually be smaller and easier to solve.
Reference: [Shao88] <author> Min-Zhi Shao, Qun-Sheng Peng, You-Dong Liang, </author> <title> "A New Radiosity Approach by Procedural Refinements for Realistic Image Synthesis," </title> <journal> Computer Graphics, </journal> <volume> Vol. 22, No. </volume> <booktitle> 4 (Proceedins of ACM SIGGRAPH 88), </booktitle> <month> August </month> <year> 1988. </year>
Reference-contexts: This takes into account the light paths L (DjG) fl E. Ray tracing can also be used to calculate form factors which take specular reflections into account <ref> [Shao88] </ref>. This uses the light paths L (DjS) fl E, but the specular reflections are quantized and averaged by the discretization of the scene into elements. [Immel86] uses a scheme for non-diffuse reflection where directional form factors are used.
Reference: [Shinya87] <author> Mikio Shinya, Tokiichiro Takahashi, Seiichiro Naito, </author> <title> "Principles and Applications of Pencil Tracing," </title> <journal> Computer Graphics, </journal> <volume> Vol. 21, No. </volume> <booktitle> 4 (Proceedings of ACM SIGGAPH 87), </booktitle> <month> July </month> <year> 1987. </year>
Reference-contexts: Usually only single rays are transformed or small displacements from a ray are approximated by affine transformations <ref> [Shinya87] </ref>. So far we have assumed perfectly smooth surfaces. The final level of complexity that has been used in indirect image formation in image synthesis is reflections and refractions from rough surfaces.
Reference: [Sillion89] <author> Francois Sillion, Claude Puech, </author> <title> "A General Two-Pass Method Integrating Specular and Diffuse Reflection," </title> <journal> Computer Graphics, </journal> <volume> Vol. 23, No. </volume> <booktitle> 3 (proceedings of ACM SIGGRAPH 89), </booktitle> <month> July </month> <year> 1989. </year>
Reference-contexts: This backwards ray tracing can identify illumination boundaries (shadows and caustics) much more accurately than a radiosity solution with uses non-diffuse form factors. A bi-directional ray tracing scheme would handle light paths LS fl DS fl E, while a bi-directional ray tracing system combined with a diffuse radiosity <ref> [Sillion89] </ref> could handle the light paths LS fl D fl S fl E. Performing form factor calculations with ray tracing allows some specular reflections to participate 99 in the radiosity part of this calculation. This allows light paths of LS fl (DjS) fl S fl E which looks completely general.
Reference: [Slepian72] <author> D. Slepian, </author> <title> "On Bandwidth," </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> Vol. </volume> <month> 64 </month> <year> 1972. </year>
Reference-contexts: In practice no filtering is perfect. Some of the conflicting assumptions placed on imperfectly bandlimited signals in the real world and a theory to deal with them are discussed in <ref> [Slepian72] </ref>. This filtering out of the high frequency components has the visual effect of blurring the image slightly. In figure 2.5, the bottom shows a triangle sampled and reconstructed without filtering.
Reference: [Sparrow78] <author> E. M. </author> <title> Sparrow, Radiation Heat Transfer , McGraw-Hill Book Company, </title> <address> New York 1978. </address>
Reference-contexts: systems the resulting high dimensional integral is solved using Monte Carlo integration techniques. 5.2.6 Diffuse Radiosity Rendering Equation The radiosity system, as first presented [Goral84] [Cohen85], is a method for calculating diffuse interreflections, (i.e. part of the indirect illumination) based on methods used in the field of radiative heat transfer <ref> [Sparrow78] </ref>. Systems in the radiosity paradigm take a different approach than the rectangle rule or Monte Carlo evaluations of the Neumann series version of the rendering equation that we have seen for previous paradigms. The radiosity paradigm applies a version of the finite element method to solve for global illumination.
Reference: [Stern79] <author> Garland Stern, </author> <title> "SoftCel An Application of Raster Scan Graphics to Conventional Cel Animation," </title> <journal> Computer Graphics, </journal> <volume> Vol. 13, No. </volume> <booktitle> 2 (Proceedings of ACM SIGGRAPH 79), </booktitle> <month> August </month> <year> 1979. </year>
Reference-contexts: Scenes with many tiny polygons smaller than a pixel will cause the A-buffer to be very large, because many polygons will be visible at each pixel. The digital compositing techniques formalized in [Porter84] (and used previously in [Levoy77] <ref> [Stern79] </ref> [Wallace81]) are another example of using approximate geometric information for antialiasing. In this algorithm the painter's algorithm is extended to include with each pixel a number which describes the fraction of the pixel that is covered by primitives. <p> An ff value of one represents complete coverage (opacity) while an ff value of zero represents no coverage (complete transparency). This technique has been extensively used with the painter's algorithm and so-called "2 1/2D" rendering systems [Crow82] [Levoy77] [Max85] [Reeves83] [Reeves85] <ref> [Stern79] </ref> [Wallace81]. The exact value of the intensity contributions of two possibly overlapping antialiased polygon fragments to the intensity of a pixel is a complex calculation which depends on the exact positions of the edges. The definitions of the major cases of interest are shown in figure 4.6.
Reference: [Stockham72] <author> Thomas G. Stockham, </author> <title> "Image Processing in the Context of a Visual Model," </title> <booktitle> Proceedings of the IEEE , Vol. </booktitle> ?, <volume> No. 6, </volume> <month> July </month> <year> 1972. </year>
Reference-contexts: Unfortunately, the error perceived by the human visual system has not been quantified well enough, so is not yet possible to define this ideal system <ref> [Stockham72] </ref>. 2.2 Subproblems of Image Synthesis Based on a simulation of light propagation in the real world, the complete process of image synthesis can be divided into the following subproblems: Object modeling Light source modeling Light propagation modeling Local object/light interaction modeling Direct image formation (from the viewpoint of the camera)
Reference: [Sutherland73] <author> Ivan E. Sutherland, Robert F. Sproull, Robert A. Schumacker, </author> <title> Sorting and the Hidden-Surface Problem, </title> <booktitle> Proceedings for the AFIPS National Conference, Vol. 42 1973 (reprinted in [Freeman80]). </booktitle>
Reference-contexts: Introduction 1.1 Purpose In 1973 and 1974 Sutherland, Sproull, and Schumacker (SSS) published the first systematic study of "hidden surface algorithms" 1 <ref> [Sutherland73] </ref> [Sutherland74]. This study provided a coherent framework for understanding all visibility algorithms being used at that time. There were 12 algorithms in their study. Many new visibility algorithms have been published since this seminal study. <p> Similarly the equation (s) of 8 the line or a plane containing each edge can be useful sometimes. Many different types of primitives have been used in image synthesis. Some of the different types of primitives are listed here in figure 2.2. * Polygons <ref> [Sutherland73] </ref> * Implicit surfaces f (x; y; z) = 0. ffi Quadric surfaces Ax 2 +By 2 +Cz 2 +Dxy+Exz +F yx+Gx+H y+J z +K = 0 [Weiss66] [Goldstein71] ffi Superquadric surfaces Ax n + By n + Cz n + D = 0 [Barr81] [Franklin81] ffi Blobby particles K P <p> The study of variance reduction techniques applied to image synthesis applications is an active new area of research [Dippe85b] [Lee85] [Kajiya86]. 2.4 A Previous Classification of Visibility Algorithms The 1973 taxonomy of Sutherland, Sproull, and Schumacker <ref> [Sutherland73] </ref> [Suther-land74] is still the most important development in the field of algorithms to solve the visibility problem. This seminal paper discusses twelve visibility algorithms and attempts to draw conclusions about the problem in general. <p> 8 &gt; &gt; &gt; : Test First Global Presorted Scan Ray Trace 2 Test Mid Local Presorted Scan Ray Trace 2 Test Last Scan Ray Trace [Crow92] (Conley) For Each Object Test Each Pixel 8 &gt; &gt; &gt; : Test First Global Scan Painter's [Schumacker69] Test Mid Local Scan Painter's <ref> [Sutherland73] </ref> Test Last Scan Z-buffer [Myers75] Subdivide by X and Y &gt; &gt; &gt; &lt; Test First Global Presorted Scan Line 2 Test Mid Local Presorted Scan Line 2 Test Last Scan Line [Wylie67] 1 Uninvestigated new algorithm. 2 New algorithm described in chapter 4. 41 Ray Trace Whitted 79 Z-buffer <p> Only one scan line is in memory at a time. The term "local" indicates that no global sort of all primitives occurs. This is the organization suggested by <ref> [Sutherland73] </ref> called the untried sorting order. The structure of this algorithm is shown in figure 3.11. The important difference between the global and local scan painter's algorithms is the time of the depth sort.
Reference: [Sutherland74] <author> Ivan E. Sutherland, Robert F. Sproull, Robert A. Schumacker, </author> <title> A Characterization of Ten Hidden Surface Algorithms. </title> <journal> ACM Computing Surveys Vol. </journal> <note> 6 1974 (reprinted in [Beatty82]). </note>
Reference-contexts: Introduction 1.1 Purpose In 1973 and 1974 Sutherland, Sproull, and Schumacker (SSS) published the first systematic study of "hidden surface algorithms" 1 [Sutherland73] <ref> [Sutherland74] </ref>. This study provided a coherent framework for understanding all visibility algorithms being used at that time. There were 12 algorithms in their study. Many new visibility algorithms have been published since this seminal study. <p> 72 Schumacker 69 Comparison algorithms Object space 8 &gt; &gt; &gt; : Edge/edge comparison ( Galimberti 69 Loutrell 67 Appel 67 Edge/volume comparison Roberts 63 ZYX Newell and Schumacker ZXY Uninteresting Variant YXZ Romney, Watkins, Bouknight XYZ Uninteresting Variant YZX Untried XZY Uninteresting Variant (XY)Z Warnock Z (XY) Schumacker from <ref> [Sutherland74] </ref> 23 time. Those orders with the X sort preceding the Y sort were thought to be trivial variations, uninteresting for raster scan output devices. The Z dimension is assumed to be "different" in some sense to the X and Y dimensions resulting in the classification being asymmetric. <p> This extends and replaces the taxonomy of SSS <ref> [Sutherland74] </ref> to apply to more modern algorithms. We have identified that there are six fundamental types of visibility algorithms in use. We identify thirteen combinations of the techniques used by the basic point sampling algorithms. Four of these are the basic point sampling algorithms.
Reference: [Sweeney86] <author> Michael A. J. Sweeney, Richard H. </author> <title> Bartels, </title> <journal> "Ray Tracing Free-form B-spline Surfaces" IEEE Computer Graphics and Applications, </journal> <volume> Vol. 6, No. 2, </volume> <month> Febru-ary </month> <year> 1986. </year>
Reference-contexts: However, both terms are frequently used interchangeably. 28 simply adding the corresponding intersection routines. If explicitly solving for intersections can not be done, then numerical approximation techniques can be used [Blinn82] [Hanrahan83] [Joy86] [Kajiya82] [Kajiya83] <ref> [Sweeney86] </ref> [Toth85]. Many optimizations are possible in the ray tracing algorithm. If some simple test can determine that an object or group of objects can not possibly intersect a given ray, then each of those objects does not need to be explicitly tested for intersection with the ray.
Reference: [Szabo83] <author> Nicholas S. Szabo, </author> , <title> "Digital Image Anomalies: Static and Dynamic" Computer image generation, </title> <editor> Bruce J. Schachter (Ed.), </editor> <publisher> John Wiley & Sons, </publisher> <address> New York 1983. </address>
Reference-contexts: With respect to computer graphics, aliasing was first extensively discussed by [Crow77b]. Since then attempts to reduce this problem have been an extensive area of research [Crow81] [Feibush80] [Carpenter84] [Catmull78] [Catmull84] [Cook84] [Cook86] [Dippe85a] [Dippe85b] [Duff85] [Fiume83] [Fujimoto83] [Grant85] [Hourcade85] [Lee85] [Max85] [Max90] [Porter84] [Reeves87] <ref> [Szabo83] </ref> [Whit-ted82]. 2.3.2.1 Signals and Samples For the purposed of this discussion, a continuous signal is a function which is defined almost everywhere within some domain. 4 For example, the two-dimensional signal representing the color of a polygonal scene with the color defined on the interiors of the polygons and undefined <p> blink on and off, cause large moving objects to crawl in discrete steps, give the appearance of ants running on moving edges as the jaggies move from frame to frame, as well as, the classic temporal aliasing effect of wheels appearing to slow down and reverse direction on moving vehicles <ref> [Szabo83] </ref>. 2.3.3 Antialiasing Techniques Aliasing is caused by high frequency components present in the image before sampling. Aliasing can be prevented by filtering the image to remove the high frequency 18 19 components before performing the sampling. Two approaches have been used to perform this filtering.
Reference: [Toth85] <author> Daniel L. </author> <title> Toth , "On Ray Tracing Parametric Surfaces," </title> <journal> Computer Graphics, </journal> <volume> Vol. 19, </volume> <booktitle> No.3 (Proceedings of ACM SIGGRAPH 85), </booktitle> <month> July </month> <year> 1985. </year>
Reference-contexts: However, both terms are frequently used interchangeably. 28 simply adding the corresponding intersection routines. If explicitly solving for intersections can not be done, then numerical approximation techniques can be used [Blinn82] [Hanrahan83] [Joy86] [Kajiya82] [Kajiya83] [Sweeney86] <ref> [Toth85] </ref>. Many optimizations are possible in the ray tracing algorithm. If some simple test can determine that an object or group of objects can not possibly intersect a given ray, then each of those objects does not need to be explicitly tested for intersection with the ray.
Reference: [Verbeck84] <author> Channing P. Verbeck, Donald P. Greenberg, </author> <title> "A Comprehensive Light-Source Description for Computer Graphics," </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> Vol. 4, No. 7, </volume> <month> July </month> <year> 1984. </year>
Reference-contexts: The simplest case is to assume that this intensity is constant. A large class of physical light sources, such as spotlights and flashlights, can be approximated by radially symmetric intensity distributions about an axis in a particular direction. These types of light sources have been modeled by <ref> [Verbeck84] </ref> and [Nishita85a]. [Warn83] has simulated photographer's lamps with flaps. The entire sky can be considered to be a large hemispherical light source with an intensity that varies with location on the hemisphere.
Reference: [Voss83] <author> Richard Voss, </author> <title> "Random Fractal Forgeries," State-of-the-Art in Image Synthesis Seminar. </title> <note> Presented at ACM SIGGRAPH 83 1983. 178 </note>
Reference-contexts: Drawing clouds as volume densities using this algorithm produces the single scattering model of interreflection and attenuation. Nonuniform density clouds are as easy to render as uniform density clouds with this method. This produces results equivalent to the slab method of <ref> [Voss83] </ref> without the restrictions on viewing position (mentioned by 160 161 162 [Kajiya84]), and equivalent to the low albedo ray tracing approximation of [Kajiya84] at much lower cost in time and intermediate storage.
Reference: [Wallace81] <author> Bruce A. Wallace, </author> , <title> "Merging and Transformation of Raster Images for Cartoon Animation," </title> <journal> Computer Graphics, </journal> <volume> Vol. 15, No. </volume> <booktitle> 3 (Proceedings of ACM SIGGRAPH 81), </booktitle> <month> August </month> <year> 1981. </year>
Reference-contexts: Scenes with many tiny polygons smaller than a pixel will cause the A-buffer to be very large, because many polygons will be visible at each pixel. The digital compositing techniques formalized in [Porter84] (and used previously in [Levoy77] [Stern79] <ref> [Wallace81] </ref>) are another example of using approximate geometric information for antialiasing. In this algorithm the painter's algorithm is extended to include with each pixel a number which describes the fraction of the pixel that is covered by primitives. <p> An ff value of one represents complete coverage (opacity) while an ff value of zero represents no coverage (complete transparency). This technique has been extensively used with the painter's algorithm and so-called "2 1/2D" rendering systems [Crow82] [Levoy77] [Max85] [Reeves83] [Reeves85] [Stern79] <ref> [Wallace81] </ref>. The exact value of the intensity contributions of two possibly overlapping antialiased polygon fragments to the intensity of a pixel is a complex calculation which depends on the exact positions of the edges. The definitions of the major cases of interest are shown in figure 4.6.
Reference: [Wallace87] <author> John R. Wallace, Michael F. Cohen, and Donald P. Greenberg, </author> <title> "A Two-Pass Solution to the Rendering Equation: A Synthesis of Ray Tracing and Ra-diosity Methods," </title> <journal> Computer Graphics, </journal> <volume> Vol. 21, No. </volume> <booktitle> 4 (Proceedings of ACM SIG-GRAPH 87), </booktitle> <month> July </month> <year> 1987. </year>
Reference-contexts: Diffuse radiosity can be extended by adding specular reflections into form factor calculations. An extended z-buffer algorithm for computing form factors with glossy reflecting surfaces is used by <ref> [Wallace87] </ref>. A secondary low resolution z-buffer is used at each glossy surface that is visible, to test for indirect visibility in the reflected direction. This takes into account the light paths L (DjG) fl E.
Reference: [Wallace89] <author> John R. Wallace, K. A. Elmquist, Eric A. Haines, </author> <title> "A Ray Tracing Algorithm for Progressive Radiosity," </title> <journal> Computer Graphics, </journal> <volume> Vol. 23, No. </volume> <booktitle> 3 (Proceedings of ACM SIGGRAPH 89), </booktitle> <month> July </month> <year> 1989. </year>
Reference: [Ward88] <author> Gregory J. Ward, Francis M. Rubinstein, Robert D. </author> <title> Clear, "A Ray Tracing Solution for Diffuse Interreflection," </title> <journal> Computer Graphics, </journal> <volume> Vol. 22, No. </volume> <booktitle> 4 (proceedings of ACM SIGGRAPH 88), </booktitle> <month> August </month> <year> 1989. </year>
Reference-contexts: Diffuse surface and the detection of indirect illumination via caustics required shooting many rays in all directions. A Feynman path integral technique helped speed up the stochastic integration, but it was still too slow to converge to acceptable noise levels. <ref> [Ward88] </ref> uses a ray tracing method for image formation and illumination, but saves the illumination information in an auxiliary data structure so that it can be reused by nearby rays. [Kajiya86] had to recalculate this information for each image formation sample ray.
Reference: [Warnock69] <author> John E. Warnock, </author> <title> "A Hidden Surface Algorithm for Computer Generated Half-Tone Pictures, </title> <institution> "TR RADC-TR-69-249 Dept. of CS U of Utah June, </institution> <year> 1969. </year>
Reference-contexts: This analysis of visibility algorithms was performed between 1972 and 1973. This study focused on the structures of the algorithms in use or envisioned at that time. Each of the eight visible surface algorithms studied (six published at the time [Watkins69] [Bouknight69] [Romney70] <ref> [Warnock69] </ref> [Newell72] [Schumacker69]) solved essentially the same version of the visibility problem, point sampling with planar polygons. There were no continuous visible surface algorithms at that time. Four visible line algorithms ([Roberts63] [Galimberti69] [Loutrell67] [Appel67]) were also considered. The taxonomy that resulted from this study is shown in figure 2.6. <p> Thus their areas can easily be used as regions of integration. A polygon is also very easy to specify by listing the coordinates of the vertices. So far, continuous algorithms have been developed only for polygons. The earliest continuous algorithms were <ref> [Warnock69] </ref>, [Hamlin77] and [Weiler77]. Although all of these algorithms processed areas in a continuous manner, they all point sampled the continuous data for conversion to raster format. [Catmull78] was the first algorithm to filter the continuous output before sampling as part of the antialiasing process. <p> Deciding exactly when and where to divide to simplify the subproblems is the major difference between algorithms in this family. Algorithms such as [Catmull78] [Franklin80] [Catmull84] perform a uniform subdivision in two dimensions to fixed subproblems independent of the input data. Algorithms such as <ref> [Warnock69] </ref> and others using octree or quadtree data structures use object information to decide whether to subdivide, but only subdivide when necessary at fixed locations in a hierarchical manner and only divide to a fixed maximum depth, the size of a pixel. <p> Algorithms such as [Fuchs79] [Fuchs80] 31 [Weiler77] subdivide directly at the locations of the objects. Subdivision can be performed in two dimensions in the image coordinate system <ref> [Warnock69] </ref> or in the object coordinate system in three dimensions as in [Fuchs79] [Fuchs80]. Subdivision methods can divide the problem into smaller subproblems and then use some other visibility algorithm to solve the subproblems. <p> Thus, the z-buffer 2 No continuous visible surface algorithms had been published as of 1974. <ref> [Warnock69] </ref> was used strictly for point sampled output. 38 and painter's algorithms are duals with respect to the time of depth determination. <p> With subdivision algorithms there are many choices of how the subdivision can be made defining different dimensions in a subdivision algorithm space, but there is no single basis algorithm. Subdivision can be two-dimensional <ref> [Warnock69] </ref> [Weiler77] [Franklin80] or three-dimensional [Fuchs79] [Fuchs80] [Fujimoto86] [Glassner84] [Samet90] or higher dimensional [Arvo87] [Grant85] [Glassner88]. The subdivisions can be specified in screen coordinates based on dividing the image [Warnock69] [Catmull78] [Catmull84] or in object coor dinates based on dividing the scene independent of the viewpoint [Fujimoto86]. <p> Subdivision can be two-dimensional <ref> [Warnock69] </ref> [Weiler77] [Franklin80] or three-dimensional [Fuchs79] [Fuchs80] [Fujimoto86] [Glassner84] [Samet90] or higher dimensional [Arvo87] [Grant85] [Glassner88]. The subdivisions can be specified in screen coordinates based on dividing the image [Warnock69] [Catmull78] [Catmull84] or in object coor dinates based on dividing the scene independent of the viewpoint [Fujimoto86]. The locations of subdivisions can be made independent of the data in the scene [Franklin80] [Catmull78] [Catmull84] or at significant object points [Fuchs79] [Fuchs80] [Weiler77]. <p> The locations of subdivisions can be made independent of the data in the scene [Franklin80] [Catmull78] [Catmull84] or at significant object points [Fuchs79] [Fuchs80] [Weiler77]. The subdivisions can be orthogonal to the coordinate axes [Samet90] [Bentley79] [Cat-mull78] [Catmull84] [Glassner84] [Kaplan85] <ref> [Warnock69] </ref> or at arbitrary angles [Fuchs79] [Fuchs80] [Weiler77]. The subdivision can be at a fixed resolution [Franklin80] [Cat-mull78] [Catmull84] or adaptive hierarchically [Fuchs79] [Fuchs80] [Glassner84] [Ka-plan85] [Warnock69] [Samet90]. <p> The subdivisions can be orthogonal to the coordinate axes [Samet90] [Bentley79] [Cat-mull78] [Catmull84] [Glassner84] [Kaplan85] <ref> [Warnock69] </ref> or at arbitrary angles [Fuchs79] [Fuchs80] [Weiler77]. The subdivision can be at a fixed resolution [Franklin80] [Cat-mull78] [Catmull84] or adaptive hierarchically [Fuchs79] [Fuchs80] [Glassner84] [Ka-plan85] [Warnock69] [Samet90]. The subdivision can be based on presorting the input primitives [Weiler77] or the input primitives can be processed in any order. 3.4 A New Classification of Visibility Algorithms In this section the new taxonomy of the basic visibility algorithms is presented. This taxonomy is summarized in figure 3.7. <p> Presorted - 3d Presort 1 Non-presorted - BSP-tree [Fuchs79] Space Based ( Uniform - Voxel [Chen85] Hierarchical - Octree [Samet90] 2d &gt; &gt; &gt; &gt; &gt; &gt; &gt; &lt; Object Based ( Presorted Sorted Clipper [Weiler77] Non-presorted Clipper [Grant85] Space Based ( Uniform - 2d Grid [Franklin80] Hierarchical - Quadtree <ref> [Warnock69] </ref> Point Sampled Only 8 &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; : No Subdivision 8 &gt; &gt; <p> Eventually the contents of each small subdivision are simple enough to handle by a few basic rules. This technique was used in <ref> [Warnock69] </ref> in a point sampling algorithm, but the algorithm is easily extended to produce continuous output since all intermediate calculations are continuous. In [Warnock69] subdivision stopped at the size of a pixel, wheither or not the region was sufficiently simple. <p> Eventually the contents of each small subdivision are simple enough to handle by a few basic rules. This technique was used in <ref> [Warnock69] </ref> in a point sampling algorithm, but the algorithm is easily extended to produce continuous output since all intermediate calculations are continuous. In [Warnock69] subdivision stopped at the size of a pixel, wheither or not the region was sufficiently simple. <p> However, there is much more data available now, and some of the fundamental assumptions have changed. SSS did succeed in identifying examples of most of the major algorithms that are in use today: scan line [Watkins69], [Bouknight69], [Romney70], painter's [Newell72], [Schumacker69], subdivision <ref> [Warnock69] </ref>, z-buffer (brute force), and ray tracing (brute force). Only the scan plane algorithms which were first published in [Hamlin77] were not anticipated. <p> The terms depth priority, list priority, and comparison do not seem to distinguish sufficiently between the six basic algorithms and are not used in the new taxonomy. The possibility of continuous visible surface algorithms was unanticipated, although the <ref> [Warnock69] </ref> algorithm was very close. The sorting order conclusions are still valid for point sampled algorithms. The three-dimensional space of point sampling algorithms in figure 3.8 is based on similar observations as the list of sorting orders in figure 2.7.
Reference: [Warn83] <author> David R. Warn, </author> <title> "Lighting Controls for Synthetic Images," </title> <journal> Computer Graphics, </journal> <volume> Vol. 17, No. </volume> <booktitle> 3 (Proceedings of ACM SIGGRAPH 83), </booktitle> <month> July </month> <year> 1983. </year>
Reference-contexts: A large class of physical light sources, such as spotlights and flashlights, can be approximated by radially symmetric intensity distributions about an axis in a particular direction. These types of light sources have been modeled by [Verbeck84] and [Nishita85a]. <ref> [Warn83] </ref> has simulated photographer's lamps with flaps. The entire sky can be considered to be a large hemispherical light source with an intensity that varies with location on the hemisphere.
Reference: [Watkins69] <author> Gary S. Watkins, </author> <title> "A Hardware Compatible Algorithm for Generating Visible Surfaces from 3d Data," </title> <booktitle> Proceedings of the 8th UAIDE Annual Meeting 1969. </booktitle>
Reference-contexts: This analysis of visibility algorithms was performed between 1972 and 1973. This study focused on the structures of the algorithms in use or envisioned at that time. Each of the eight visible surface algorithms studied (six published at the time <ref> [Watkins69] </ref> [Bouknight69] [Romney70] [Warnock69] [Newell72] [Schumacker69]) solved essentially the same version of the visibility problem, point sampling with planar polygons. There were no continuous visible surface algorithms at that time. Four visible line algorithms ([Roberts63] [Galimberti69] [Loutrell67] [Appel67]) were also considered. <p> This yields the two algorithm classes: continuous algorithms and point sampled algorithms. Hybrid algorithms which are part continuous and part point sampled are also possible (such as <ref> [Watkins69] </ref> [Max90] which are scan line algorithms that sample in the Y dimension but solve a reduced dimensionality continuous visibility problem on each scan line). Hybrid algorithms which combine techniques from more than one basic algorithm and other extensions of the basic algorithms are considered later in this chapter. <p> Many algorithms have been published which refer to themselves as scan line algorithms [Bouknight69] [Max90] <ref> [Watkins69] </ref> [Wylie67]. These algorithms use the concept of subdivision into scan lines, but the processing on each scan line differs. What we describe here is the simplest brute-force point-sampling techninque which is consistent with the method of scan line subdivision. <p> More complex cases are only approximate because of the approximate geometric representation of the coverage of the "cone." Scan line algorithms which perform more accurate geometric calculations along the direction of the scan lines, than between the scan lines, have been used <ref> [Watkins69] </ref> [Max90]. This technique works well for large polygons except where polygon edges align parallel to the scan lines. It is possible to use very high resolution samples in the direction of the scan lines at low cost since typically long runs of samples will have the same polygon visible. <p> However, there is much more data available now, and some of the fundamental assumptions have changed. SSS did succeed in identifying examples of most of the major algorithms that are in use today: scan line <ref> [Watkins69] </ref>, [Bouknight69], [Romney70], painter's [Newell72], [Schumacker69], subdivision [Warnock69], z-buffer (brute force), and ray tracing (brute force). Only the scan plane algorithms which were first published in [Hamlin77] were not anticipated.
Reference: [Watkins70] <author> Gary S. </author> <title> Watkins , "A Real-Time Visible Surface Algorithm," </title> <institution> Dept. of Computer Science, University of Utah, UTECH-CSC-70-101, </institution> <month> June </month> <year> 1970. </year>
Reference: [Weiss66] <author> Ruth A. </author> <title> Weiss , "BE VISION: A Package of IBM 7090 FORTRAN Programs to Draw Orthographic Views of Combinations of Plane and Quadric Surfaces," </title> <journal> JACM, </journal> <volume> Vol. 13, No. </volume> <pages> 2, </pages> <note> April 1966 (reprinted in [Beatty82]). </note>
Reference-contexts: Some of the different types of primitives are listed here in figure 2.2. * Polygons [Sutherland73] * Implicit surfaces f (x; y; z) = 0. ffi Quadric surfaces Ax 2 +By 2 +Cz 2 +Dxy+Exz +F yx+Gx+H y+J z +K = 0 <ref> [Weiss66] </ref> [Goldstein71] ffi Superquadric surfaces Ax n + By n + Cz n + D = 0 [Barr81] [Franklin81] ffi Blobby particles K P all objects f (object; x; y; z) = 0 [Blinn82] * Parametric surfaces S = F (u; v) ffi Bi-cubic parametric patches [Catmull74] [Catmull75] ffi Superquadric surfaces
Reference: [Weiler77] <author> Kevin Weiler, Peter Atherton, </author> <title> "Hidden Surface Removal Using Polygon Area Sorting," </title> <journal> Computer Graphics, </journal> <volume> Vol. 11, No. </volume> <booktitle> 3 (Proceedings of ACM SIG-GRAPH 77), </booktitle> <month> July </month> <year> 1977. </year>
Reference-contexts: Thus their areas can easily be used as regions of integration. A polygon is also very easy to specify by listing the coordinates of the vertices. So far, continuous algorithms have been developed only for polygons. The earliest continuous algorithms were [Warnock69], [Hamlin77] and <ref> [Weiler77] </ref>. Although all of these algorithms processed areas in a continuous manner, they all point sampled the continuous data for conversion to raster format. [Catmull78] was the first algorithm to filter the continuous output before sampling as part of the antialiasing process. <p> Algorithms such as [Fuchs79] [Fuchs80] 31 <ref> [Weiler77] </ref> subdivide directly at the locations of the objects. Subdivision can be performed in two dimensions in the image coordinate system [Warnock69] or in the object coordinate system in three dimensions as in [Fuchs79] [Fuchs80]. <p> With subdivision algorithms there are many choices of how the subdivision can be made defining different dimensions in a subdivision algorithm space, but there is no single basis algorithm. Subdivision can be two-dimensional [Warnock69] <ref> [Weiler77] </ref> [Franklin80] or three-dimensional [Fuchs79] [Fuchs80] [Fujimoto86] [Glassner84] [Samet90] or higher dimensional [Arvo87] [Grant85] [Glassner88]. The subdivisions can be specified in screen coordinates based on dividing the image [Warnock69] [Catmull78] [Catmull84] or in object coor dinates based on dividing the scene independent of the viewpoint [Fujimoto86]. <p> The locations of subdivisions can be made independent of the data in the scene [Franklin80] [Catmull78] [Catmull84] or at significant object points [Fuchs79] [Fuchs80] <ref> [Weiler77] </ref>. The subdivisions can be orthogonal to the coordinate axes [Samet90] [Bentley79] [Cat-mull78] [Catmull84] [Glassner84] [Kaplan85] [Warnock69] or at arbitrary angles [Fuchs79] [Fuchs80] [Weiler77]. The subdivision can be at a fixed resolution [Franklin80] [Cat-mull78] [Catmull84] or adaptive hierarchically [Fuchs79] [Fuchs80] [Glassner84] [Ka-plan85] [Warnock69] [Samet90]. <p> The locations of subdivisions can be made independent of the data in the scene [Franklin80] [Catmull78] [Catmull84] or at significant object points [Fuchs79] [Fuchs80] <ref> [Weiler77] </ref>. The subdivisions can be orthogonal to the coordinate axes [Samet90] [Bentley79] [Cat-mull78] [Catmull84] [Glassner84] [Kaplan85] [Warnock69] or at arbitrary angles [Fuchs79] [Fuchs80] [Weiler77]. The subdivision can be at a fixed resolution [Franklin80] [Cat-mull78] [Catmull84] or adaptive hierarchically [Fuchs79] [Fuchs80] [Glassner84] [Ka-plan85] [Warnock69] [Samet90]. The subdivision can be based on presorting the input primitives [Weiler77] or the input primitives can be processed in any order. 3.4 A New Classification of Visibility Algorithms In this <p> be orthogonal to the coordinate axes [Samet90] [Bentley79] [Cat-mull78] [Catmull84] [Glassner84] [Kaplan85] [Warnock69] or at arbitrary angles [Fuchs79] [Fuchs80] <ref> [Weiler77] </ref>. The subdivision can be at a fixed resolution [Franklin80] [Cat-mull78] [Catmull84] or adaptive hierarchically [Fuchs79] [Fuchs80] [Glassner84] [Ka-plan85] [Warnock69] [Samet90]. The subdivision can be based on presorting the input primitives [Weiler77] or the input primitives can be processed in any order. 3.4 A New Classification of Visibility Algorithms In this section the new taxonomy of the basic visibility algorithms is presented. This taxonomy is summarized in figure 3.7. <p> &gt; &gt; : 8 &gt; &gt; &gt; &gt; &gt; &gt; &gt; : Object Based ( Presorted - 3d Presort 1 Non-presorted - BSP-tree [Fuchs79] Space Based ( Uniform - Voxel [Chen85] Hierarchical - Octree [Samet90] 2d &gt; &gt; &gt; &gt; &gt; &gt; &gt; &lt; Object Based ( Presorted Sorted Clipper <ref> [Weiler77] </ref> Non-presorted Clipper [Grant85] Space Based ( Uniform - 2d Grid [Franklin80] Hierarchical - Quadtree [Warnock69] Point Sampled Only 8 &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; <p> The sort does not need to be exact for the algorithm to work correctly. In fact no sort at all yields the previous clipper algorithm. The sort merely improves the efficiency of the algorithm. This technnique was used in <ref> [Weiler77] </ref>. 3.4.2.5 Octree Algorithm An octree is a recursive subdivision of a cube into octants [Samet90]. It is the tree-dimensional extension of the quadtree. The orthogonal nature of the subdivision gives a regular pattern of subregions overlapping and obscuring adjacent subregions from a given viewpoint. <p> Continuous visible surface algorithms, which take polygons as input and produce the visible parts of the polygons as output, are examples of algorithms that can be used for direct illumination with uniform representation. [Atherton78] generates shadows by this uniform representation method using their continuous visible surface algorithm <ref> [Weiler77] </ref>. Input polygons are passed through the illumination pass of the continuous visible surface algorithm. Each polygon is divided 91 into illuminated (visible to the light source) and shadowed (hidden to the light source) polygons. The shading parameters of each polygon are adjusted to reflect its illumination status.
Reference: [Wein78] <author> M. Wein, P. Tanner, G. Bechthold, N. Burtnyk, </author> <title> "Hidden Line Removal for Vector Graphics," </title> <journal> Computer Graphics, </journal> <volume> Vol. 12, No. </volume> <booktitle> 3 (Proceedings of ACM SIG-GRAPH 78), </booktitle> <month> August </month> <year> 1978. </year>
Reference-contexts: The basic painter's algorithm can be performed in FTB order by adding a single bit coverage flag to each pixel. FTB was used in the Evans and Sutherland CT5 flight simulator [Schumacker80], a hardware line drawing system <ref> [Wein78] </ref>, and [Crow82]. This flag is initialized to indicate that the pixel has not been painted (i.e. is uncovered). When the first (closest) primitive paints over this pixel, the bit is set to indicate that it is now covered.
Reference: [Weinberg81] <author> Richard Weinberg, </author> <title> "Parallel Processing Image Synthesis and Anti-Aliasing," </title> <journal> Computer Graphics, </journal> <volume> Vol. 15, No. </volume> <booktitle> 3 (Proceedings of ACM SIGGRAPH 81), </booktitle> <month> August </month> <year> 1981. </year>
Reference-contexts: This can be done by synchronizing on operations in the frame and depth buffers, or by keeping separate frame and depth buffers for each processor and merging the buffers after all primitives are processed <ref> [Weinberg81] </ref> [Molnar92]. It is not difficult to use both object parallelism and image subdivision parallelism at the same time. The only real difficult problem is load balancing when different parts of the image have different complexities and some primitives are much larger than others [Whitman92].
Reference: [Whitman92] <author> Scott R. Whitman, </author> <title> Multiprocessor Methods for Computer Graphics Rendering, </title> <publisher> Jones and Bartlett Publishers, </publisher> <address> Boston, </address> <year> 1992. </year>
Reference-contexts: It is not difficult to use both object parallelism and image subdivision parallelism at the same time. The only real difficult problem is load balancing when different parts of the image have different complexities and some primitives are much larger than others <ref> [Whitman92] </ref>. The painter's algorithm is very sequential. The first pass is a geometric sort which has always been done sequentially. It may be possible to design an object parallel sorting algorithm for the painter's algorithm, but none as yet been proposed.
Reference: [Whitted79] <author> Turner Whitted, </author> <title> "An Improved Illumination Model for Shaded Display," </title> <journal> Communications of the ACM, </journal> <volume> Vol. 23, No. </volume> <pages> 6, </pages> <note> June 1980 (also in Proceedings of ACM SIGGRAPH'79, abstract only, July 1979) (reprinted in [Joy87]). 179 </note>
Reference-contexts: &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; : No Subdivision 8 &gt; &gt; &gt; &gt; &gt; &gt; &gt; : For Each Pixel Test Each Object ( Test First Presorted Ray Trace 2 Test Last Ray Trace <ref> [Whitted79] </ref> For Each Object Test Each Pixel ( Test First Painter's [Newell72] Test Last - Z-buffer [Catmull74] Subdivide by X 8 &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; : For Each Pixel Test Each Object 8 &gt; &gt; &gt; : Test First Global Presorted <p> The difference between the paradigms is that the light sources, e, are now two-dimensional, instead of zero-dimensional. This raises the dimensionality of the integral and the visibility problems. 5.2.4 Simple Ray Tracing Rendering Equation Conventional ray tracing as presented by <ref> [Whitted79] </ref> is very effective at direct image formation, indirect image formation (mirror reflections, transparency, refraction) and direct illumination (shadows). By restricting all rays to be point samples a wide variety of curved surfaces are easily handled. <p> Since multiple diffuse reflections are not calculated the ambient term, vSa is 86 used to approximate this light contribution, as in the previous paradigms. Solving this equation by regularly sampled ray tracing to a fixed depth is performing a numerical integration using the rectangle rule. <ref> [Whitted79] </ref> and others have proposed using supplementary samples to improve accuracy in regions where intensity variation is detected. 5.2.5 Distribution Ray Tracing Rendering Equation The rendering equation for the distribution ray tracing paradigm is: i = ve + vSve + vS s vSve + (vS s ) 2 vSve + : <p> These techniques are applicable, with their limitations, to both the simple ray tracing paradigm and the distribution ray tracing paradigm. 5.3.11 Simple Ray Tracing Paradigm Conventional ray tracing as presented by <ref> [Whitted79] </ref> is very effective at direct image formation, indirect image formation (mirror reflections, transparency, refraction) and direct illumination (shadows). By restricting all rays to be point samples curved surfaces are easily handled. In the original formation it does not address indirect illumination.
Reference: [Whitted82] <author> Turner Whitted, David M. Weimer, </author> <title> "A Software Testbed for the Development of 3d Raster Graphics Systems," </title> <journal> ACM Transactions on Graphics, </journal> <volume> Vol. 1, No. </volume> <pages> 1, </pages> <note> January 1982 also in Computer Graphics, Vol. 15, No. 3 (Proceedings of ACM SIGGRAPH 81), August 1981 (reprinted in [Joy87]). </note>
Reference-contexts: Usually this interaction is also ignored by assuming that the propagating medium is perfectly transparent. A more realistic assumption, in the case where the medium is homogeneous, involves an attenuation that is an exponential function of distance to the light source. Linear and quadratic approximations have also been used <ref> [Whitted82] </ref> [Max86c]. 2.2.4 Local Object/Light Interaction Modeling Objects in synthetic images are usually opaque and all object/light interaction occurs at the surface of the object. This type of model provides a good approximation of the surfaces of many common types of real materials, such as wood, paper, metal and soil. <p> The horizontal spans can specify the x-coordinate and z-coordinate of the endpoints exactly, yielding an algorithm that is sampled in the y dimension and continuous in the x dimension. This is very similar to, but simpler than, the trapezoidal spans of <ref> [Whitted82] </ref>. Using any of these types of data structures with one-dimensional samples would yield new data-structure-assisted-query image synthesis systems. Six choices of algorithm to build the data structure and six choices of image formation algorithm yield thirty-six combinations.
Reference: [Whitted85] <author> Turner Whitted, Robert L. Cook, </author> <title> "A Comprehensive Shading Model," </title> <booktitle> Course Notes: Tutorial on State of the Art in Image Synthesis, SIGGRAPH 85, </booktitle> <address> San Francisco, California, </address> <note> July 1985 (unpublished) (updated version reprinted in [Joy87]). </note>
Reference-contexts: We will see that each image synthesis paradigm can be described by how it approximates the rendering equation in either the integral equation form or the Neumann series form. The process of image synthesis was formulated as an integral equation called the "pixel equation" by <ref> [Whitted85] </ref> (this was pre-radiosity). This was generalized into the "rendering equation" by [Kajiya86]. [Heckbert91] identified the two methods used in computer graphics for solving this Fredholm integral equation of the second kind and equation for global illumination.
Reference: [Williams78] <author> Lance Williams, </author> <title> "Casting Curved Shadows on Curved Surfaces," </title> <journal> Computer Graphics, </journal> <note> Vol 12, No. 3 (Proceedings of ACM SIGGRAPH 78), August 1978 (reprinted in [Joy87]). </note>
Reference-contexts: new classification theories. * The plane push algorithm, a new basic continuous visibility algorithm. * Extended painter's algorithms with antialiasing, this corrects a major drawback of very useful basic algorithm. * The Z2, P1, and P2 shadow systems, extended image synthesis systems based on the depth buffer shadow system of <ref> [Williams78] </ref>, with improved image quality. * The shadow mask sweep systems, a set of new image synthesis systems using the painter's algorithm. 3 1.3 Plan of Development Chapter 1 is this introduction, including purpose, results summary, and plan of devel opment. <p> Storing and using a single depth value here has the same sampling problems associated with sampling the shadow depth buffer in the depth buffer shadow system of <ref> [Williams78] </ref> described in chapters 5 and 6. It is difficult to tell when you are really close. Storing two depth values with each pixel, representing the depth interval at the pixel which is spanned by the correlated polygons, is much cleaner. <p> Surfaces on the boundary are illuminated. This type of test is subject to error when the actual surface does not match the stored representation exactly, for example a curved surface represented by a mesh of small polygons. Dealing with this type of accuracy problem is discussed by <ref> [Williams78] </ref> and further explored in chapter 6. A surface identifier can be stored which uniquely tells what particular surface is illuminated in a given region. This way a surface-id number comparison can be used for illumination tests. <p> These lists allow an optimization of direct independent class umbra algorithms to avoid testing against all other primitives. The first algorithm using this optimization was presented by [Bouknight70a]. A slightly different version was later presented by [Haines86] as a ray tracing shadow accelerator. The depth buffer shadow algorithm of <ref> [Williams78] </ref> is the most popular algorithm of this class. It uses a two-dimensional sampled representation of the locations of the illuminated surfaces in the light sources image coordinate system. This is a depth map with respect to the light source. <p> If after all polygons have been processed in the second pass a pixel has not been marked, then it is considered illuminated. A shading pass is then conducted once the illumination is determined. This algorithm does not have the illumination determination errors of <ref> [Williams78] </ref> because all sampling is done at the same set of sample points in the same coordinate system. [Fuchs85] implement this algorithm on the massively parallel pixel-planes machine, which can perform the many tests at each pixel in parallel. Since [Brotman84] is similar to [Williams78] except the orders of the passes <p> have the illumination determination errors of <ref> [Williams78] </ref> because all sampling is done at the same set of sample points in the same coordinate system. [Fuchs85] implement this algorithm on the massively parallel pixel-planes machine, which can perform the many tests at each pixel in parallel. Since [Brotman84] is similar to [Williams78] except the orders of the passes are reversed and the coordinate systems are different, it is interesting to consider what would happen if the order of the passes of [Brotman84] were reversed. Would this generate an algorithm similar to [Williams78] without sampling errors? This inverted algorithm would in the first <p> Since [Brotman84] is similar to <ref> [Williams78] </ref> except the orders of the passes are reversed and the coordinate systems are different, it is interesting to consider what would happen if the order of the passes of [Brotman84] were reversed. Would this generate an algorithm similar to [Williams78] without sampling errors? This inverted algorithm would in the first pass scan convert all polygons and shadow polygons in image space. Each pixel would hold a list of depth intervals which described the extents of the various shadow volumes at that pixel. <p> Changing what type information is stored at each sample point can yield new systems. The system of <ref> [Williams78] </ref> stores 101 illumination image formation algorithm algorithm old subdivision subdivision new subdivision scan plane new subdivision z-buffer new subdivision painter's new subdivision ray trace new subdivision scan line new scan plane subdivision new scan plane scan plane new scan plane z-buffer new scan plane painter's new scan plane ray trace <p> These possible new systems are not further developed here. Sampling Number of Piecewise Piecewise Dimension Surfaces Constant Linear 0-d 1 old (1) new (23) new (24) 1-d 1 new (36) 2-d 1 new (12) 6.3.1 Zero-Dimensional Depth Buffer Shadow Systems The depth buffer shadow system (DBSS) of <ref> [Williams78] </ref> is very powerful, but it suffers from several important problems such as aliasing and incorrect self-shadowing of simple surfaces. This section attempts to reduce these problems by applying three improvements. <p> Third, consider the values of adjacent pixels in the shadow buffer to help reduce some aliasing artifacts. These techniques preserve all the desirable properties of the depth buffer visible surface algorithm while yielding more accurate shadows. In a related effort, [Reeves87] presents a modified version of <ref> [Williams78] </ref> by adding "percentage closer filtering" to produce soft shadow boundaries, but this did not address the most significant problems of the original algorithm. Some preliminary results of the research in this section were reported in [Grant90]. [Woo92] later independently developed and implemented the idea of using two depth values. <p> Increasing the resolution of the shadow buffer alone does not help this problem. As shown in figure 6.5, individual shadow buffer pixels are no longer visible, but an elaborate moire pattern of incorrect self-shadowing has appeared as the sampling grids of the shadow buffer and image formation buffer beat. <ref> [Williams78] </ref> addresses this self-shadowing problem by adding a small bias value to the depth of each sample in the shadow buffer. This can be a constant value or allowed to vary stochastically between pixels. <p> This can probably be done with additional calculations with each sample. Based on our experiments, we conclude that these new systems represent a useful improvement over the widely used system of <ref> [Williams78] </ref>. These new systems provide more accurate shadows, solving the self-shadowing problem for most cases, without incurring much increase in compute time and preserving all the advantages of the depth buffer visible surface algorithm.
Reference: [Woo92] <author> Andrew Woo, </author> <title> "Shadow Depth Map Revisited," in Graphics Gems III, </title> <editor> David Kirk (Ed.), </editor> <publisher> Academic Press Inc, </publisher> <address> Boston, </address> <year> 1992. </year>
Reference-contexts: In a related effort, [Reeves87] presents a modified version of [Williams78] by adding "percentage closer filtering" to produce soft shadow boundaries, but this did not address the most significant problems of the original algorithm. Some preliminary results of the research in this section were reported in [Grant90]. <ref> [Woo92] </ref> later independently developed and implemented the idea of using two depth values. The data structure used for shadow testing in a DBSS is a two dimensional depth map of the scene from the point of view of the light source.
Reference: [Wylie67] <author> C. Wylie, G. W. Romney, D. C. Evans, A. C. Erdahl, </author> <title> "Halftone Perspective Drawings by Computer," </title> <booktitle> Proceedings of AFIPS Fall Joint Computer Conference, </booktitle> <year> 1967. </year>
Reference-contexts: Now the intensity of the illumination in the scene is a function of position within the scene. This simple model was used in some 9 early image synthesis efforts with the light source positioned at the view point <ref> [Wylie67] </ref> [Bouknight69]. This conveniently prevented any shadows or dark surfaces oriented away from the light source from being visible. Real scenes have much more complicated illumination patterns than that produced by a single point light source. <p> Many algorithms have been published which refer to themselves as scan line algorithms [Bouknight69] [Max90] [Watkins69] <ref> [Wylie67] </ref>. These algorithms use the concept of subdivision into scan lines, but the processing on each scan line differs. What we describe here is the simplest brute-force point-sampling techninque which is consistent with the method of scan line subdivision. <p> Pixel 8 &gt; &gt; &gt; : Test First Global Scan Painter's [Schumacker69] Test Mid Local Scan Painter's [Sutherland73] Test Last Scan Z-buffer [Myers75] Subdivide by X and Y &gt; &gt; &gt; &lt; Test First Global Presorted Scan Line 2 Test Mid Local Presorted Scan Line 2 Test Last Scan Line <ref> [Wylie67] </ref> 1 Uninvestigated new algorithm. 2 New algorithm described in chapter 4. 41 Ray Trace Whitted 79 Z-buffer Catmull 74 Presorted Ray Trace Painter's Schumacker 69 Scan Ray Trace Scan Z-buffer Porter 78 Scan Presorted Ray Trace Scan Painter's SSS Untried 74 Scan Line Wylie 67 last depth testing time first
Reference: [Wyvill86] <author> Geoff Wyvill, Tosiyasu L. Kunii, Yasuto Shirai, </author> <title> "Space Division for Ray Tracing in CSG," </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> Vol. 6, No. 4, </volume> <month> April </month> <year> 1986. </year>
References-found: 191

