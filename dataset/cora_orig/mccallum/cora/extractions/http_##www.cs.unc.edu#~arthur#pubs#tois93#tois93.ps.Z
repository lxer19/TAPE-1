URL: http://www.cs.unc.edu/~arthur/pubs/tois93/tois93.ps.Z
Refering-URL: http://www.cs.unc.edu/~arthur/pubs/tois93/tois93.html
Root-URL: http://www.cs.unc.edu
Title: Evaluating 3D Task Performance for Fish Tank Virtual Worlds 1  
Author: Kevin W. Arthur Kellogg S. Booth Colin Ware 
Keyword: CR Categories and Subject Descriptors: I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism, I.3.6 [Computer Graphics]: Interaction Techniques. General Terms: Human Factors Additional Keywords and Phrases: Virtual Reality, Virtual Worlds, Head-Coupled Display, Stereopsis.  
Address: New Brunswick  
Affiliation: University of British Columbia  University of  
Date: 3, July 1993, Pages 239-265.  
Note: In ACM Transactions on Information Systems, Vol. 11, No.  
Abstract: Fish tank virtual reality" refers to the use of a standard graphics workstation to achieve real-time display of three-dimensional scenes using stereopsis and dynamic head-coupled perspective. Fish tank VR has a number of advantages over head-mounted immersion VR which make it more practical for many applications. After discussing the characteristics of fish tank VR, we describe a set of three experiments conducted to study the benefits of fish tank VR over a traditional workstation graphics display. These experiments tested user performance under two conditions: (a) whether or not stereoscopic display was used and (b) whether or not the perspective display was coupled dynamically to the positions of a user's eyes. Subjects using a comparison protocol consistently preferred head-coupling without stereo over stereo without head-coupling. Error rates in a tree tracing task similar to one used by Sollenberger and Milgram showed an order of magnitude improvement for head-coupled stereo over a static (non-head-coupled) display and the benefits gained by head-coupling were more significant than those gained from stereo alone. The final experiment examined two factors that are often associated with human performance in virtual worlds: the lag (or latency) in receiving and processing tracker data and the rate at which frames are updated. For the tree tracing task, lag had a larger impact on performance than did frame update rate, with lag having a multiplicative effect on response time. We discuss the relevance of these results for the display of complex three-dimensional data and highlight areas requiring further study. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Peter R. Atherton and Linda R. Caporael, </author> <title> A subjective judgment study of polygon based curved surface imagery, </title> <booktitle> Proceedings of CHI '85 (April, </booktitle> <year> 1985), </year> <pages> 27-34. </pages>
Reference-contexts: better than alternative models which propose only an additive effect for lag. 4.3 Auxiliary 3D cues Atherton and Caporael assessed the quality of 3D images by subjective rankings to determine the degree of polygonalization required to adequately approximate a sphere and the relative effectiveness of three commonly used shading models <ref> [1] </ref>. Meyer, et al., used subjective pair-wise comparisons to assess the quality of radiosity-based global illumination models for rendering 3D scenes [23]. <p> X child = X parent + HorizontalSpacing child fi Rand () Y child = Y parent + V erticalSpacing child fi (1:0 + 0:25 fi Rand ()) Z child = Z parent + HorizontalSpacing child fi Rand () The function Rand () returns a uniform random number in the range <ref> [1; +1] </ref>. The two trees constructed for each trial were displayed side-by-side separated by a distance of 1.0 cm.
Reference: [2] <author> Baecker, Ronald M. </author> <title> Digital video display systems and dynamic graphics. </title> <booktitle> Proceedings of SIGGRAPH '79. In Computer Graphics, </booktitle> <volume> 13, </volume> <month> 2 (August </month> <year> 1979), </year> <pages> 48-56. </pages>
Reference-contexts: The frame rate or update rate is the number of times per second that an image or scene is changed. Baecker emphasized the difference between refresh rate and frame rate in his survey paper on dynamic raster graphics <ref> [2] </ref>.
Reference: [3] <author> Blanchard, Chuck, Scott Burgess, Young Harvill, Jaron Lanier, Ann Lasko, Mark Oberman, and Michael Teitel. </author> <title> Reality built for two: A virtual reality tool. </title> <booktitle> Proceedings of the 1992 ACM Symposium on Interactive 3D Graphics. Special issue of Computer Graphics (1990), </booktitle> <pages> 35-36. </pages>
Reference: [4] <author> Brooks, Frederick P., Jr. </author> <title> Walkthrough Adynamic graphics system for simulating virtual buildings. </title> <booktitle> Proceedings of the 1986 ACM Workshop on Interactive 3D Graphics. Special issue of Computer Graphics (1986), </booktitle> <pages> 9-21. </pages>
Reference-contexts: But head mounted displays suffer from a number of difficulties that are not nearly as bothersome in a standard workstation display. Fortunately, immersion is not necessary for all applications. Only a few applications, such as entertainment or building walk-through systems, really need the full power of immersion VR <ref> [4] </ref>. There are a number of good reasons to settle for something less. Cost is one reason. Immersion VR is still quite expensive. Many current systems use two high-performance workstations to compute images, one for each eye [3][30]. Cost will not always be a problem, however.
Reference: [5] <author> Carlbom, Ingrid and J. Paciorek. </author> <title> Planar geometric projections and viewing transformations. </title> <journal> ACM Computing Surveys, </journal> <month> 10 (December </month> <year> 1978), </year> <pages> 465-502. </pages>
Reference-contexts: Conventional computer graphics display applications, in the absence of head tracking capability, employ a perspective projection according to a single viewpoint, usually translated from the center of the screen perpendicular to its surface. Non-perpendicular viewing projections have been discussed in the literature <ref> [5] </ref>, but are seldom used except in flight simulators where one or more of the display surfaces is mounted at an angle to the principal direction of view [29].
Reference: [6] <author> Chung, James C. </author> <title> A comparison of head-tracked and non-head-tracked steering modes in the targeting of radiotherapy treatment beams. </title> <booktitle> Proceedings of the 1992 ACM Symposium on Interactive 3D Graphics. Special issue of Computer Graphics (1992), </booktitle> <pages> 193-196. </pages>
Reference-contexts: Subjects performed best with the head-coupled perspective. The mouse-controlled condition generally decreased performance. A similar type of experimental study, this time using immersion VR, was performed by Chung <ref> [6] </ref>. Subjects performed a task under various head-coupled and non-head-coupled conditions using a 6D mouse, joystick, Spaceball, or no device at all for interaction. The task was taken from an application in radiation therapy treatment.
Reference: [7] <author> Codella, Christopher, Reza Jalili, Lawrence Koved, J. Bryan Lewis, Daniel T. Ling, James S. Lipscomb, David A. Rabenhorst, Chu P. Wang, Alan Norton, Paula Sweeney, and Greg Turk. </author> <title> Interactive simulation in a multi-person virtual world. </title> <booktitle> Proceedings of CHI '92 (1992), </booktitle> <pages> 329-334. 18 </pages>
Reference-contexts: The software also runs on various IBM RS/6000 workstations; none of the ones we use has a monitor capable of 60 Hz stereo, but this is apparently possible given an appropriate monitor and synchronization hardware <ref> [7] </ref>. 7 5.2 Head-coupled perspective A necessary component for rendering a 2D image of a 3D scene is the determination of the correct projection to use for transforming points and geometric primitives in 3-space into points in 2-space. Most commonly, orthographic or perspective projections are employed.
Reference: [8] <author> Deering, Michael. </author> <title> High resolution virtual reality. </title> <booktitle> Proceedings of SIGGRAPH '92. In Computer Graphics, </booktitle> <volume> 26, </volume> <month> 2 (July </month> <year> 1992), </year> <pages> 195-202. </pages>
Reference-contexts: A head-coupled display is one in which the calculation of a viewing transformation, usually including perspective, is based on the position of a user's head. Other commonly used terms for this type of display include head-tracked display, used by Deering <ref> [8] </ref> and others, and viewpoint dependent imaging, used by Fisher [13]. The head-coupling technique has been employed in various guises since the early 1980's. Head-coupling assumes a fixed relationship between the position and orientation of a user's head and the position (s) and orientation (s) of the user's eye (s). <p> They propose a system using precomputed perspective images, and tracking only the horizontal movements of a user to minimize the number of images which must be computed. Deering <ref> [8] </ref> discussed the technical components required to create a high quality 3D display on a monitor using head-coupled perspective and stereoscopic display.
Reference: [9] <author> Diamond, R., A. Wynn, K. Thomsen and J. Turner. </author> <title> Three-dimensional perception for one-eyed guys. Computational Crystallography. </title> <publisher> Oxford, Clarendon Press (1982). </publisher>
Reference-contexts: Diamond, et al., generated head-coupled perspective wire-frame images with head positions obtained by using a video camera to track a light bulb placed on a user's head <ref> [9] </ref>. Venolia and Williams describe a similar system using a Polhemus tracker and stereo shutter glasses to provide stereoscopic images with head-coupled perspective [34].
Reference: [10] <author> Ellis, Stephen R. </author> <title> Nature and origins of virtual environments: A bibliographic essay. </title> <journal> Computing Systems in Engineering, </journal> <volume> 2, 4, </volume> <year> (1991), </year> <pages> 321-347. </pages>
Reference-contexts: A more general discussion of human factors issues for virtual reality can be found in the survey article by Ellis <ref> [10] </ref> and the collection of papers in [11]. 5 4.1 Fish Tank Virtual Reality Some of the first work on this type of display took place in the early 1980's.
Reference: [11] <author> Ellis, Stephen R. </author> <title> (editor) with M.K. Kaiser and A.J. Grunwald. Pictorial communication in virtual and real environments, Taylor and Francis (1991). </title>
Reference-contexts: A more general discussion of human factors issues for virtual reality can be found in the survey article by Ellis [10] and the collection of papers in <ref> [11] </ref>. 5 4.1 Fish Tank Virtual Reality Some of the first work on this type of display took place in the early 1980's. Fisher used a fixed monitor with head-tracking to provide different views to the observer by way of precomputed images stored on a video disc [13].
Reference: [12] <author> Fairchild, K.M., E.E. Poltrock and G.W. Furnas. SemNet: </author> <title> Three-dimensional graphic representations of large knowledge bases. In Cognitive Science and Its Applications for Human-Computer Interaction. </title> <editor> Raymond Guindon (editor), </editor> <publisher> Lawrence Erelbaum (1988), </publisher> <pages> 201-233. </pages>
Reference: [13] <author> Fisher, Scott S. </author> <title> Viewpoint dependent imaging: An interactive stereoscopic display. Processing and Display of Three-Dimensional Data, </title> <editor> S. Benton (editor), </editor> <booktitle> Proc. SPIE, 367 (1982), </booktitle> <pages> 41-45. </pages>
Reference-contexts: Other commonly used terms for this type of display include head-tracked display, used by Deering [8] and others, and viewpoint dependent imaging, used by Fisher <ref> [13] </ref>. The head-coupling technique has been employed in various guises since the early 1980's. Head-coupling assumes a fixed relationship between the position and orientation of a user's head and the position (s) and orientation (s) of the user's eye (s). <p> Fisher used a fixed monitor with head-tracking to provide different views to the observer by way of precomputed images stored on a video disc <ref> [13] </ref>. Diamond, et al., generated head-coupled perspective wire-frame images with head positions obtained by using a video camera to track a light bulb placed on a user's head [9].
Reference: [14] <author> Fisher, S. S., M. McGreevy, J. Humphries, and W. Robinett. </author> <title> Virtual environment display system. </title> <booktitle> Proceedings of the 1986 ACM Workshop on Interactive 3D Graphics. Special issue of Computer Graphics (1986), </booktitle> <pages> 9-21. </pages>
Reference: [15] <author> Foley, J.D. and A. Van Dam. </author> <title> Fundamentals of Interactive Computer Graphics, </title> <publisher> Addison-Wesley Publishing Company (1982). </publisher>
Reference: [16] <author> Foley, J. D., A. Van Dam, S. K. Feiner, and J. F. </author> <title> Hughes Computer Graphics: </title> <booktitle> Principles and Practice, The Systems Programming Series, </booktitle> <publisher> Addison-Wesley Publishing Company. </publisher> <year> (1990). </year>
Reference: [17] <author> Friedmann, Martin, Thad Starner, and Alex Pentland. </author> <title> Device synchronization using an optimal linear filter. </title> <booktitle> Proceedings of the 1992 ACM Symposium on Interactive 3D Graphics. Special issue of Computer Graphics (1992), </booktitle> <pages> 57-62. </pages>
Reference-contexts: They suggest the use of a predictive Kalman filter to compensate for lag, as do Friedmann, et al. <ref> [17] </ref>. One must be careful, however, that the prediction method does not introduce undesirable artifacts into the data. In particular, overshoot or amplification of the sensor noise can occur. These artifacts become apparent when the prediction interval is chosen to be too large.
Reference: [18] <author> Howard, I.P. and T. Heckman. </author> <title> Circular vection as a function of the relative sizes, distances and positions of two competing visual displays. </title> <journal> Perception, </journal> <volume> 18, 5 (1989), </volume> <pages> 657-665. </pages>
Reference-contexts: The term "vection" is usually used to refer to the feeling of self movement when a large field display is moved with respect to an observer. Recent evidence indicates that the effect can be achieved with even a small field of view <ref> [18] </ref>. Howard and Heckman suggest that one of the important factors in eliciting vection is the perceived distance of a moving visual image, with images that are perceived as furthest away contributing the most.
Reference: [19] <author> Eric M. Howlett. </author> <title> Wide angle orthostereo. </title> <booktitle> Proc. SPIE, Stereoscopic displays and applications (1990). </booktitle>
Reference: [20] <author> Jacob, Robert J.K. </author> <title> What you look at is what you get: Eye movement-based interaction techniques. </title> <booktitle> Proceedings of CHI '90 (1990), </booktitle> <pages> 11-18. </pages>
Reference: [21] <author> Liang, Jiandong, Chris Shaw, and Mark Green. </author> <title> On temporal-spatial realism in the virtual reality environment. </title> <booktitle> In Proceedings of ACM UIST '91 (1991), </booktitle> <pages> 19-25. </pages>
Reference-contexts: The other is to measure the effect that these inaccuracies have on the performance of VR users. Both are important. 6 Liang, Shaw and Green <ref> [21] </ref> measured the lag inherent in the hardware processing performed by the Polhemus IsoTrak device and found a delay of approximately 110 msec (newer trackers from Polhemus have improved lag, reportedly less than 20 msec).
Reference: [22] <author> MacKenzie, I. Scott and Colin Ware. </author> <title> Lag as a determinant of human performance in interactive systems. </title> <booktitle> Proceedings of INTERCHI '93 Conference on Human Factors in Computing Systems (April 1993). </booktitle>
Reference-contexts: For example, with a sampling rate of 20 Hz, a prediction interval of no more than 150 msec would be tolerable. MacKenzie and Ware <ref> [22] </ref> have studied the effect of lag on a 2D Fitt's law target selection task. Analysis of response times and error rates showed that a model in which lag has a multiplicative effect on Fitts's index of difficulty accounts for 95% of the variance in the data.
Reference: [23] <author> Meyer, Gary W., Holly E. Rushmeier, Michael F. Cohen, Donald P. Greenberg and Kenneth E. Torrance, </author> <title> An experimental evaluation of computer graphics imagery, </title> <journal> ACM Transactions on Computer Graphics, </journal> <volume> 5, </volume> <month> 1 (January, </month> <year> 1986), </year> <pages> 30-50. 19 </pages>
Reference-contexts: Meyer, et al., used subjective pair-wise comparisons to assess the quality of radiosity-based global illumination models for rendering 3D scenes <ref> [23] </ref>.
Reference: [24] <author> McKenna, Michael. </author> <title> Interactive viewpoint control and three-dimensional operations. </title> <booktitle> Proceedings of the 1992 ACM Symposium on Interactive 3D Graphics. Special issue of Computer Graphics (1992), </booktitle> <pages> 53-56. </pages>
Reference-contexts: Deering takes into account a number of effects in his derivation, including the distortions due to the curvature and thickness of display screen. McKenna <ref> [24] </ref> reported on experiments conducted with three types of monocular displays, all employing head tracking. The first was a stable high-resolution monitor with head-coupled perspective.
Reference: [25] <author> Newman, W. M. and R. F. Sproull. </author> <title> Fundamentals of Interactive Graphics. </title> <publisher> McGraw-Hill (1972). </publisher>
Reference: [26] <author> Newman, W. M. and R. F. Sproull. </author> <title> Principles of Interactive Computer Graphics, Second Edition. </title> <publisher> McGraw-Hill (1979). </publisher>
Reference: [27] <author> Robertson, G.G., J.D. Mackinlay and S.K. Card. </author> <title> Cone trees: animated 3D visualizations of hierarchical information. </title> <booktitle> Proceedings of CHI '91 (1991), </booktitle> <pages> 189-194. </pages>
Reference: [28] <author> Robinett, Warren and Jannick P. Rolland. </author> <title> A computational model for the stereoscopic optics of a head-mounted display. Presence, </title> <type> 1, </type> <month> 1 </month> <year> (1992), </year> <pages> 45-62. </pages>
Reference: [29] <editor> Schachter, Bruce J. (editor). </editor> <booktitle> Computer Image Generation. </booktitle> <publisher> John Wiley and Sons, </publisher> <address> New York (1983). </address>
Reference-contexts: Non-perpendicular viewing projections have been discussed in the literature [5], but are seldom used except in flight simulators where one or more of the display surfaces is mounted at an angle to the principal direction of view <ref> [29] </ref>. In fish tank VR systems, a user's head is tracked so that by moving his or her head, a user can view the scene from different angles. This requires computing the correct off-axis perspective projection to accommodate the corresponding eye positions.
Reference: [30] <author> Shaw, Chris, Jiandong Liang, Mark Green, and Yunqi Sun. </author> <title> The decoupled simulation model for virtual reality systems. </title> <booktitle> Proceedings of CHI '92 (1992), </booktitle> <pages> 321-328. </pages>
Reference: [31] <author> Smith, K.U. </author> <title> Delayed Sensory Feedback and Behaviour. </title> <publisher> W.B. Saunders, </publisher> <address> Philadelphia (1962). </address>
Reference: [32] <author> Sollenberger, Randy L., and Paul Milgram. </author> <title> A comparative study of rotational and stereoscopic computer graphic depth cues. </title> <booktitle> Proceedings of the Human Factors Society 35th Annual Meeting, </booktitle> <address> San Francisco (1991), </address> <pages> 1452-1456. </pages>
Reference-contexts: Subjects were given a task very similar to one designed by Sollenberger and Milgram <ref> [32] </ref> who tested the ability of observers to perceive arterial branching in brain scan data under different viewing conditions. Two trees consisting of straight line segments were constructed in 3-space and placed side-by-side so that a large number of the branches overlapped (see Figure 5). <p> Overall, the error rates obtained are lower than those obtained by Sollenberger and Milgram <ref> [32] </ref>, but the pattern is strikingly similar despite the differences in the stimulus trees, the viewing conditions and the experimental protocols.
Reference: [33] <author> Sutherland, Ivan. </author> <title> A head-mounted three dimensional display. </title> <booktitle> Proceedings of the Fall Joint Computer Conference, AFIPS Conference Proceedings, 33 (1968), </booktitle> <pages> 757-764. </pages>
Reference-contexts: 1 Introduction Recently, considerable interest has been shown in the area of virtual reality (VR). The idea was first introduced by Ivan Sutherland in the late 1960's when he developed a research prototype of a head-mounted display <ref> [33] </ref>. It was popularized almost two decades later when off-the-shelf systems started to become practical for virtual reality [4][14].
Reference: [34] <author> Venolia, D. and L. Williams. </author> <title> Virtual integral holography. Extracting Meaning from Complex Data: Processing, Display, Interaction, </title> <booktitle> Proc. SPIE, </booktitle> <address> 1259 (Santa Clara, CA, </address> <month> February </month> <year> 1990), </year> <pages> 99-105. </pages>
Reference-contexts: Venolia and Williams describe a similar system using a Polhemus tracker and stereo shutter glasses to provide stereoscopic images with head-coupled perspective <ref> [34] </ref>. They propose a system using precomputed perspective images, and tracking only the horizontal movements of a user to minimize the number of images which must be computed.
Reference: [35] <author> Wallach, H. and D.H. O'Connell. </author> <title> The kinetic depth effect. </title> <journal> Journal of Experimental Psychology, </journal> <volume> 45 (1953), </volume> <pages> 205-217. </pages>
Reference-contexts: Both studies found combined motion and stereo to be more effective than either in isolation. It can be argued that the improvements seen with head-coupling in the tree tracing task are not due to the head-coupling as such, but rather to the motion-induced depth <ref> [35] </ref>. Our current evidence does not counter this objection.
Reference: [36] <author> Wanger, Leonard. </author> <title> The effect of shadow quality on the perception of spatial relationships in computer generated images. </title> <booktitle> Proceedings of the 1992 ACM Symposium on Interactive 3D Graphics. Special issue of Computer Graphics (1992), </booktitle> <pages> 39-42. </pages>
Reference: [37] <author> Wanger, Leonard R., James A. Ferwerda, and Donald P. Greenberg. </author> <title> Perceiving spatial relationships in computer-generated images. </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> 12, </volume> <month> 3 (May </month> <year> 1992), </year> <pages> 44-59. </pages>
Reference: [38] <author> Ware, Colin and Steven Osborne. </author> <title> Exploration and virtual camera control in virtual three dimensional environments. Proceedings of the 1990 ACM Symposium on Interactive 3D Graphics. </title> <journal> Special issue of Computer Graphics, </journal> <volume> 24, 2, </volume> <year> (1990) </year> <month> 175-183. </month>
Reference-contexts: The best overall rating was for a constrained head-tracked viewing mode with no additional input device, referred to as "orbital" mode. Ware and Osborne report on the experimental study of different metaphors for navigation through virtual worlds <ref> [38] </ref>. Their experimental system used a fixed non-head-coupled monitor display and a six degree-of-freedom hand-held tracker.

References-found: 38

