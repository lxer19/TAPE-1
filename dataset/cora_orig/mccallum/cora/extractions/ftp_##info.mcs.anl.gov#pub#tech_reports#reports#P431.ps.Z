URL: ftp://info.mcs.anl.gov/pub/tech_reports/reports/P431.ps.Z
Refering-URL: http://www.mcs.anl.gov/publications/abstracts/abstracts94.htm
Root-URL: http://www.mcs.anl.gov
Email: fxiaobai,bischofg@mcs.anl.gov  
Title: A Basis-Kernel Representation of Orthogonal Matrices  
Author: Xiaobai Sun and Christian Bischof 
Keyword: Key words. Orthogonal Matrices, Block Elimination, Orthogonality Condition, Basis-Kernel Representation, Cayley Transform, Householder Matrices.  
Note: Argonne Preprint MCS-P431-0594  
Address: Argonne, IL 60439  
Affiliation: Mathematics and Computer Science Division Argonne National Laboratory  
Abstract: In this paper we introduce a new representation of orthogonal matrices. We show that any orthogonal matrix can be represented in the form Q = I Y SY T , which we call the basis-kernel representation of Q. We show that the kernel S can be chosen to be triangular and show how the familiar representation of an orthogonal matrix as a product of Householder matrices can be directly derived from a representation with triangular kernel. We also show that there exists an, in some sense, minimal orthogonal transformation for solving the block elimination problem. We explore how the basis Y determines the subspaces that Q acts on in a nontrivial fashion, and how S determines the way Q acts on this subspace. We derive a canonical representation that explicitly shows how Q partitions R n into three invariant subspaces in which it acts as the identity, a reflector, and a rotator, respectively. We also derive a generalized Cayley representation for arbitrary orthogonal matrices, which illuminates the degrees of freedom we have in choosing orthogonal matrices acting on a predetermined subspace. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E. Anderson, Z. Bai, C. Bischof, J. Demmel, J. Dongarra, J. DuCroz, A. Greenbaum, S. Hammarling, A. McKenney, S. Ostrouchov, and D. Sorensen. </author> <title> LAPACK User's Guide. </title> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1992. </year>
Reference-contexts: x amounts to reflecting x with respect to the line spanned by the vector (cos (=2); sin (=2)) T : Householder Reflector: H = H (v) = I fivv T ; fiv T vfi = 2fi: (3) This representation of Householder matrices is used in the LINPACK [4] and LAPACK <ref> [1] </ref> libraries. The condition on v and fi in (3) covers all choices for v and fi that result in an orthogonal matrix H. In particular, it includes the degenerate case fi = 0 where H is the identity matrix I.
Reference: [2] <author> Christian H. Bischof and Per Christian Hansen. </author> <title> Structure-preserving and rank-revealing QR factorizations. </title> <journal> SIAM Journal on Scientific and Statistical Computing, </journal> <volume> 12(6) </volume> <pages> 1332-1350, </pages> <month> November </month> <year> 1991. </year>
Reference: [3] <author> Tony F. Chan. </author> <title> An improved algorithm for computing the singular value decomposition. </title> <journal> ACM Transactions on Mathematical Software, </journal> <volume> 8 </volume> <pages> 72-83, </pages> <year> 1982. </year>
Reference: [4] <author> J. J. Dongarra, J. R. Bunch, C. B. Moler, and G. W. Stewart. </author> <title> LINPACK Users' Guide. </title> <publisher> SIAM Press, </publisher> <address> Philadelphia, </address> <year> 1979. </year> <month> 18 </month>
Reference-contexts: to a vector x amounts to reflecting x with respect to the line spanned by the vector (cos (=2); sin (=2)) T : Householder Reflector: H = H (v) = I fivv T ; fiv T vfi = 2fi: (3) This representation of Householder matrices is used in the LINPACK <ref> [4] </ref> and LAPACK [1] libraries. The condition on v and fi in (3) covers all choices for v and fi that result in an orthogonal matrix H. In particular, it includes the degenerate case fi = 0 where H is the identity matrix I.
Reference: [5] <author> F. R. Gantmacher. </author> <title> Applications of the Theory of Matrices. </title> <publisher> Interscience Publications, Inc., </publisher> <year> 1959. </year>
Reference-contexts: We also derive a canonical form that makes explicit how Q partitions R n into a couple of subspaces in which it acts as the identity, a reflector or a rotator. In Section 4 we derive a generalized form, applicable to arbitrary orthogonal matrices, of the Cayley representation <ref> [5] </ref>. The generalized Cayley form shows that, in a specified active space of dimension k, there are k (k 1)=2 degrees of freedom in choosing a nonsymmetric matrix while there is one and only one symmetric matrix. <p> Conversely, an orthogonal matrix Q can be represented in one of the above forms with some skew-symmetric matrix B as long as Q does not have eigenvalues at both 1 and 1. Representation (18) is known as the Cayley representation <ref> [5] </ref> or the Cayley transform of B. 16 Note that the Cayley representation does not include symmetric orthogo-nal matrices except I and I, nor does it include the nonsymmetric matrices that have both a nontrivial "inactive" subspace and a nontrivial "active" reflection subspace.
Reference: [6] <author> Gene H. Golub and Charles F. Van Loan. </author> <title> Matrix Computations. </title> <publisher> The Johns Hopkins Press, </publisher> <address> Baltimore, 2nd edition, </address> <year> 1989. </year>
Reference-contexts: 1 Introduction Orthogonal transformations are a well-known tool in numerical linear algebra and are used extensively in decompositions such as the QR factor ization, tridiagonalization, bidiagonalization, Hessenberg reduction, or the eigenvalue or singular value decomposition of a matrix (see, for example, <ref> [6, 10] </ref>). The orthogonal transformations employed are usually compositions of the following elementary transformations: fl This work was supported by the Applied and Computational Mathematics Program, Advanced Research Projects Agency, under contract DM28E04120, and by the Office of Scientific Computing, U.S. Department of Energy, under Contract W-31-109-Eng-38. <p> An orthogonal matrix, however, has more than one representation with an upper (lower) triangular kernel. Let Q (Y; S) be a representation with upper triangular kernel S. There is an orthogonal matrix U such that U T SU is also upper triangular <ref> [6, p. 385] </ref>, and hence Q (Y U; U T SU ) is another representation of Q with triangular kernel. From the compact WY representation we know that the product of k Householder matrices can be expressed in basis-kernel form. The converse holds true as well.
Reference: [7] <author> Chiara Puglisi. </author> <title> Modification of the Householder method based on the compact WY representation. </title> <journal> SIAM Journal on Scientific and Statistical Computing, </journal> <volume> 3(3) </volume> <pages> 723-726, </pages> <year> 1992. </year>
Reference: [8] <author> Robert Schreiber and Beresford Parlett. </author> <title> Block reflectors: </title> <journal> Theory and computation. SIAM Journal on Numerical Analysis, </journal> <volume> 25(1) </volume> <pages> 189-205, </pages> <year> 1988. </year>
Reference-contexts: For each vector x, H (v)x is the reflection of x with respect to the hyperplane R (v) ? . The concept of reflectors was further developed by Schreiber and Parlett <ref> [8] </ref> to block reflectors Q = I 2Y Y T ; Y T Y = I; Y 2 R mfik : (6) Note that the reflectors we have mentioned so far are all symmetric. <p> Example 3 Q (Y; S) is orthogonal if S = 2 (Y T Y ) y ; where B y denotes a pseudo-inverse of the matrix B [12]. Such a singular and symmetric kernel was first introduced in <ref> [8] </ref>.
Reference: [9] <author> Robert Schreiber and Charles Van Loan. </author> <title> A storage efficient WY representation for products of Householder transformations. </title> <journal> SIAM Journal on Scientific and Statistical Computing, </journal> <volume> 10(1) </volume> <pages> 53-57, </pages> <year> 1989. </year>
Reference-contexts: With a triangular matrix S, this representation was first introduced as the compact WY representation by Schreiber and Van Loan <ref> [9] </ref>, as a way of expressing the product of k Householder matrices in a computationally more advantageous form.
Reference: [10] <author> G. W. Stewart. </author> <title> Introduction to Matrix Computation. </title> <publisher> Academic Press, Inc., </publisher> <address> New York, </address> <year> 1973. </year>
Reference-contexts: 1 Introduction Orthogonal transformations are a well-known tool in numerical linear algebra and are used extensively in decompositions such as the QR factor ization, tridiagonalization, bidiagonalization, Hessenberg reduction, or the eigenvalue or singular value decomposition of a matrix (see, for example, <ref> [6, 10] </ref>). The orthogonal transformations employed are usually compositions of the following elementary transformations: fl This work was supported by the Applied and Computational Mathematics Program, Advanced Research Projects Agency, under contract DM28E04120, and by the Office of Scientific Computing, U.S. Department of Energy, under Contract W-31-109-Eng-38.
Reference: [11] <author> G. W. Stewart. </author> <title> The efficient generation of random orthogonal matrices with an application to condition estimators. </title> <journal> SIAM Journal on Numerical Analysis, </journal> <volume> 17 </volume> <pages> 403-409, </pages> <year> 1980. </year>
Reference-contexts: S 1 (Y T S 2 (Y 1 ; Y 2 ) T : Using this formula, one can, for example, quickly assemble random orthogonal matrices in a "binary-tree" like fashion from lower-degree random orthog onal matrices, deriving, in effect, a parallel block version of the Householder-oriented approach by Stewart <ref> [11] </ref>. 10 2.4 Block Orthogonal Transformations The following theorem shows that, if there is an orthogonal transformation that transforms an m fi k matrix A into a matrix B, k &lt; m, the degree of Q concerned need not be larger than k.
Reference: [12] <author> G. W. Stewart and J. Sun. </author> <title> Matrix Perturbation Theory. </title> <publisher> Academic Press, Inc., </publisher> <address> New York, </address> <year> 1991. </year>
Reference-contexts: Given Y , we now show some examples of choices for S such that the orthogonality condition is satisfied. Example 3 Q (Y; S) is orthogonal if S = 2 (Y T Y ) y ; where B y denotes a pseudo-inverse of the matrix B <ref> [12] </ref>. Such a singular and symmetric kernel was first introduced in [8].
Reference: [13] <author> Homer F. Walker. </author> <title> Implementation of the GMRES method using Householder transformations. </title> <journal> SIAM Journal on Scientific and Statistical Computing, </journal> <volume> 9(1) </volume> <pages> 152-163, </pages> <year> 1988. </year> <month> 19 </month>
References-found: 13

