URL: http://www.cs.cornell.edu/Info/People/coleman/PAPERS/CS97_1641.ps
Refering-URL: http://www.cs.cornell.edu/Info/People/coleman/papers.html
Root-URL: 
Title: Combining Trust Region and Affine Scaling for Linearly Constrained Nonconvex Minimization global convergence is achieved
Author: Thomas F. Coleman and Yuying Li 
Keyword: Key words. trust region, Dikin-affine scaling, an interior point method, Newton, reflection  
Note: The  
Affiliation: Computer Science Department, Cornell University  
Abstract: Technical Report CORNELLCS: TR97-1641 Abstract. An interior point method is proposed for a general nonlinear (nonconvex) minimization with linear inequality constraints. This method is a combination of the trust region idea for nonlinearity and affine scaling technique for constraints. Using this method, the original objective function is monotonically decreased. In the proposed approach, a Newton step is derived directly from the complementarity conditions. A trust region subproblem is formed which yields an approximate Newton step as its solution asymptotically. The objective function of the trust region subproblem is the quadratic approximation to the original objective function plus an augmented quadratic convex term. Similar to an augmented Lagrangian function, this augmentation adds positive curvature in the range space of the constraint normals. Computational results of a two-dimensional trust region implementation are reported for large-scale problems. Preliminary experiments suggest that this method can be effective; a relatively small number of function evaluations are required for some medium and large test problems. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> N. K. Adler, M. Resende, and G. Veiga, </author> <title> An implementation of karmarkar's algorithm for linear programming, </title> <booktitle> Mathematical Programming, </booktitle> <month> 44 </month> <year> (1989). </year>
Reference-contexts: Despite the absence of a polynomial convergence property, an affine scaling method is the only type of interior point method which monotonically decreases the original objective function; it stands out for its simplicity and typically good computational performance, e.g., <ref> [1, 5, 33] </ref>. There has been great interest in generalizing interior point methods to nonlinear (nonconvex) programming problems, e.g., [16, 36, 9, 12, 14, 35, 25, 19, 4]. However, 1 Research partially supported by the Applied Mathematical Sciences Research Program (KC-04-02) of the Office of Energy Research of the U.S.
Reference: [2] <author> M. A. Branch, T. F. Coleman, and Y. Li, </author> <title> A subspace, interior and conjugate gradient method for large-scale bound-constrained minimization, </title> <type> Tech. Report TR95-1525, </type> <institution> Computer Science Department, Cornell University, </institution> <year> 1995. </year>
Reference-contexts: Monotonicity offers a natural connection to the original problem. Monotonicity and the simplicity of an affine scaling method makes it particularly appealing and suitable for constrained nonconvex minimization. Based on this philosophy, Newton type affine scaling algorithms have been considered for various structured linear and nonlinear programming problems <ref> [8, 7, 26, 9, 27, 25, 2, 14] </ref>. These methods represent a generalization of the affine scaling methods to piecewise linear and nonlinear minimization. Such algorithms have fast local convergence and typically solve a large problem in a small number of iterations. <p> Explicit effort can be made to facilitate staying away from boundary and achieve further decrease. A special line search has been used in [8] for linear l 1 problems. For a nonlinear minimization with bound constraints, a reflection line search and its effectiveness is illustrated in <ref> [9, 10, 2] </ref>. We now examine a similar reflection technique for the problem (1.1) with linear inequality constraints. Assume that x k is the current strictly feasible point and d k is an approximate solution to the trust region subproblem (3.11).
Reference: [3] <author> R. Byrd, R. Schnabel, and G. Shultz, </author> <title> Parallel quasi-Newton methods for unconstrained optimization, </title> <type> tech. report, </type> <institution> Department of Computer Science, University of Colorado, </institution> <year> 1988. </year>
Reference-contexts: A Two-dimensional Trust Region Algorithm. Computing a solution to the full-space trust region subproblem (3.11) can be too costly for a large scale problem (1.1). Similar to a subspace approach for unconstrained minimization <ref> [3] </ref>, an appropriate small-dimensional trust region subproblem can be used to approximate the full space trust region subproblem, e.g., min k (d) + 2 subject to Ad S 1 k k (d; ^ d)k 2 k : Here S k denotes a small-dimensional subspace in &lt; n+m , e.g., jS k
Reference: [4] <author> R. H. Byrd, J. C. Gilbert, and J. Nocedal, </author> <title> A trust region method based on interior point techniques for nonlinear programming, </title> <type> Tech. Report OTC96/02, </type> <institution> Optimization Technology Center, Northwestern University, </institution> <year> 1996. </year>
Reference-contexts: There has been great interest in generalizing interior point methods to nonlinear (nonconvex) programming problems, e.g., <ref> [16, 36, 9, 12, 14, 35, 25, 19, 4] </ref>. However, 1 Research partially supported by the Applied Mathematical Sciences Research Program (KC-04-02) of the Office of Energy Research of the U.S. <p> For a convex programming problem, primal and dual feasibility together with complementarity sufficiently characterize a solution. Extension of a primal and dual method to a general nonconvex problem has proven to be difficult and challenging <ref> [16, 14, 19, 4] </ref>. The first order necessary conditions is no longer sufficient in characterizing a local minimizer for a nonconvex minimization problem. For example, a 2-norm penalty function has been used to measure satisfaction of the first order necessary conditions for a nonconvex problem in [16].
Reference: [5] <author> Y.-C. Chen, D. J. Houck, J.-M. Liu, M. Meketon, R. J. V. L. Slutsman, and P. Wang, </author> <title> The AR&T KORBX System, </title> <journal> AT&T Tecnnical Journal, </journal> <year> (1989). </year>
Reference-contexts: Despite the absence of a polynomial convergence property, an affine scaling method is the only type of interior point method which monotonically decreases the original objective function; it stands out for its simplicity and typically good computational performance, e.g., <ref> [1, 5, 33] </ref>. There has been great interest in generalizing interior point methods to nonlinear (nonconvex) programming problems, e.g., [16, 36, 9, 12, 14, 35, 25, 19, 4]. However, 1 Research partially supported by the Applied Mathematical Sciences Research Program (KC-04-02) of the Office of Energy Research of the U.S.
Reference: [6] <author> T. F. Coleman, </author> <title> Large-scale numerical optimization: Introduction and overview, </title> <booktitle> in Encyclopedia of Computer Science and Technology, </booktitle> <editor> A. Kent and J. G. Williams, eds., </editor> <publisher> Marcel Dekker, INC., </publisher> <year> 1993, </year> <pages> pp. 167-195. </pages>
Reference-contexts: Nonlinear objective functions f (x) are chosen from two classes: the nonlinear test problem collection for unconstrained minimization [29], and the molecule minimization problem. In the latter, the objective function f (x) has the following formulation <ref> [22, 6] </ref>, f (x) = (i;j)2S 2 d 2 where x i denotes the position of the atom and d ij is the known distance between a pair of atoms (i; j).

Reference: [12] <author> T. F. Coleman and J. Liu, </author> <title> An interior Newton method for quadratic programming, </title> <type> Tech. Report TR93-1388, </type> <institution> Computer Science Department, Cornell University, </institution> <year> 1993. </year>
Reference-contexts: There has been great interest in generalizing interior point methods to nonlinear (nonconvex) programming problems, e.g., <ref> [16, 36, 9, 12, 14, 35, 25, 19, 4] </ref>. However, 1 Research partially supported by the Applied Mathematical Sciences Research Program (KC-04-02) of the Office of Energy Research of the U.S.
Reference: [13] <author> A. R. Conn, N. I. M. Gould, and P. L. Toint, </author> <title> Testing a class of methods for solving minimization problems with simple bounds on the variables, </title> <journal> Mathematics of Computation, </journal> <volume> 50 (1988), </volume> <pages> pp. 399-430. </pages>
Reference-contexts: A reflection technique described in x3.5 is incorporated. The details of the implemented two-dimensional subspace algorithm are described in FIG. 4.1. A large scale nonlinear minimization test problem (1.1) is generated in a similar fashion to the test problems for a nonlinear minimization subject to simple bounds <ref> [9, 13] </ref>. Nonlinear objective functions f (x) are chosen from two classes: the nonlinear test problem collection for unconstrained minimization [29], and the molecule minimization problem. <p> Solving an unconstrained minimization problem first, the constraints Ax b are formulated in a fashion similar to the bound constraints in the test problems used in <ref> [9, 13] </ref>. For the results reported subsequently, computation is terminated when either k tol or f (x k ) f (x k+1 ) tol; where tol equals 10 8 . Table 4.1 lists the number of function evaluations required for each testing problem using standard nonlinear test functions.
Reference: [14] <author> J. E. Dennis, M. H. Jr., and L. N. Vicente, </author> <title> Trust-region interior-point sqp algorithms for a class of nonlinear programming problems, </title> <type> Tech. Report TR94-45, </type> <institution> Department of Computational and Applied Mathematics, Rice University, </institution> <year> 1994. </year>
Reference-contexts: There has been great interest in generalizing interior point methods to nonlinear (nonconvex) programming problems, e.g., <ref> [16, 36, 9, 12, 14, 35, 25, 19, 4] </ref>. However, 1 Research partially supported by the Applied Mathematical Sciences Research Program (KC-04-02) of the Office of Energy Research of the U.S. <p> Monotonicity offers a natural connection to the original problem. Monotonicity and the simplicity of an affine scaling method makes it particularly appealing and suitable for constrained nonconvex minimization. Based on this philosophy, Newton type affine scaling algorithms have been considered for various structured linear and nonlinear programming problems <ref> [8, 7, 26, 9, 27, 25, 2, 14] </ref>. These methods represent a generalization of the affine scaling methods to piecewise linear and nonlinear minimization. Such algorithms have fast local convergence and typically solve a large problem in a small number of iterations. <p> For a convex programming problem, primal and dual feasibility together with complementarity sufficiently characterize a solution. Extension of a primal and dual method to a general nonconvex problem has proven to be difficult and challenging <ref> [16, 14, 19, 4] </ref>. The first order necessary conditions is no longer sufficient in characterizing a local minimizer for a nonconvex minimization problem. For example, a 2-norm penalty function has been used to measure satisfaction of the first order necessary conditions for a nonconvex problem in [16].
Reference: [15] <author> I. Dikin, </author> <title> Iterative solution of problems of linear and quadratic programming, </title> <journal> Doklady Akademiia Nauk SSSR, </journal> <volume> 174 (1967), </volume> <pages> pp. 747-748. </pages>
Reference-contexts: Interior point methods share a common characteristic: they avoid approaching the boundary prematurely. The majority of interior point methods can be interpreted as following the central path to optimality, e.g., [21, 31]. The exception is the classical affine scaling algorithm <ref> [15, 33] </ref>. An affine scaling method uses a diagonal scaling technique to compute a damped step which ultimately leads to convergence to a solution.
Reference: [16] <author> A. S. El-Bakry, R. A. Tapia, T. Tsuchiya, and T. Zhang, </author> <title> On the formulation and theory of the Newton interior-point method for nonlinear programming, </title> <year> (1992). </year>
Reference-contexts: There has been great interest in generalizing interior point methods to nonlinear (nonconvex) programming problems, e.g., <ref> [16, 36, 9, 12, 14, 35, 25, 19, 4] </ref>. However, 1 Research partially supported by the Applied Mathematical Sciences Research Program (KC-04-02) of the Office of Energy Research of the U.S. <p> For a convex programming problem, primal and dual feasibility together with complementarity sufficiently characterize a solution. Extension of a primal and dual method to a general nonconvex problem has proven to be difficult and challenging <ref> [16, 14, 19, 4] </ref>. The first order necessary conditions is no longer sufficient in characterizing a local minimizer for a nonconvex minimization problem. For example, a 2-norm penalty function has been used to measure satisfaction of the first order necessary conditions for a nonconvex problem in [16]. <p> The first order necessary conditions is no longer sufficient in characterizing a local minimizer for a nonconvex minimization problem. For example, a 2-norm penalty function has been used to measure satisfaction of the first order necessary conditions for a nonconvex problem in <ref> [16] </ref>. This method does not necessarily converge to a local minimizer of the original minimization problem since the second order necessary conditions may fail to hold. We believe that monotonic decrease of the original objective function, if achievable, is an important property of a minimization algorithm for nonconvex problems.
Reference: [17] <author> A. V. Fiacco and G. P. McCormick, </author> <title> Nonlinear Programming: Sequential Unconstrained Minimization Techniques, </title> <publisher> John Wiley and Sons, </publisher> <year> 1968. </year>
Reference-contexts: For (1.1), this perturbed complementarity conditions correspond to diag (Ax b) = e and A T rf (x) = 0: The parameter &gt; 0 is decreased to zero as a solution is approached. Fiacco and McCormick <ref> [17] </ref> first considered this perturbed KKT condition for an inequality constrained nonlinear programming problem. If f (x) is convex, the solution to this nonlinear system, as the parameter &gt; 0 varies, defines a central path in the strictly feasible region.
Reference: [18] <author> R. Fletcher, </author> <title> Practical Methods of Optimization: Volume 2, Constrained Optimization, </title> <publisher> John Wiley and Sons, </publisher> <year> 1981. </year>
Reference-contexts: An Affine Scaling Newton Approach. The first order optimality conditions of a constrained minimization problem consist of the complementarity conditions, primal feasibility, and dual feasibility. The following is a classical characterization of a local minimizer of the linearly constrained problem (1.1), e.g., see Fletcher <ref> [18] </ref>.
Reference: [19] <author> A. Forsgren and P. E. Gill, </author> <title> Primal-dual interior methods for nonconvex nonlinear programming, </title> <type> Tech. Report NA 96-3, </type> <institution> Department of Mathematics, University of California, </institution> <address> San Diego, </address> <year> 1996. </year>
Reference-contexts: There has been great interest in generalizing interior point methods to nonlinear (nonconvex) programming problems, e.g., <ref> [16, 36, 9, 12, 14, 35, 25, 19, 4] </ref>. However, 1 Research partially supported by the Applied Mathematical Sciences Research Program (KC-04-02) of the Office of Energy Research of the U.S. <p> For a convex programming problem, primal and dual feasibility together with complementarity sufficiently characterize a solution. Extension of a primal and dual method to a general nonconvex problem has proven to be difficult and challenging <ref> [16, 14, 19, 4] </ref>. The first order necessary conditions is no longer sufficient in characterizing a local minimizer for a nonconvex minimization problem. For example, a 2-norm penalty function has been used to measure satisfaction of the first order necessary conditions for a nonconvex problem in [16].
Reference: [20] <author> P. E. Gill, W. Murray, and M. H. Wright, </author> <title> Practical Optimization, </title> <publisher> Academic Press, </publisher> <year> 1981. </year>
Reference-contexts: The augmented term 1 2 d T A T D 1 k C k Ad in the objective function of the subproblem (3.4) serves a similar purpose to the augmented Lagrangian function for a constrained minimization problem <ref> [20] </ref>: it adds positive curvature in the space spanned by the constraint normals. <p> A negative curvature direction of (3.15) can be 10 computed by either a partial Cholesky factorization <ref> [20] </ref> or using a conjugate gradient process with an incomplete Cholesky factorization as a preconditioner. An effective subspace S k can be formed from the first and second order approximate solutions to the trust region subproblem (3.5).
Reference: [21] <author> C. C. Gonzaga, </author> <title> Path following methods for linear programming, </title> <journal> SIAM Review, </journal> <volume> 34 (1992), </volume> <pages> pp. 167-227. </pages>
Reference-contexts: Interior point methods share a common characteristic: they avoid approaching the boundary prematurely. The majority of interior point methods can be interpreted as following the central path to optimality, e.g., <ref> [21, 31] </ref>. The exception is the classical affine scaling algorithm [15, 33]. An affine scaling method uses a diagonal scaling technique to compute a damped step which ultimately leads to convergence to a solution. <p> The majority of interior point methods are based on the view that it is worthwhile to sacrifice decrease of the original objective function in order to gain centrality, e.g., <ref> [21, 31] </ref>. This view may not be reasonable for nonconvex problems; achieving centrality can cause loss of information provided by the initial point and possibly cause convergence to a local minimizer with a higher objective function value than that of the initial point.
Reference: [22] <author> B. A. Hendrickson, </author> <title> The molecule problem: Determining conformation from pairwise distances, </title> <type> Cornell University Ph.D thesis, </type> <institution> Computer Science, </institution> <year> 1991. </year>
Reference-contexts: Nonlinear objective functions f (x) are chosen from two classes: the nonlinear test problem collection for unconstrained minimization [29], and the molecule minimization problem. In the latter, the objective function f (x) has the following formulation <ref> [22, 6] </ref>, f (x) = (i;j)2S 2 d 2 where x i denotes the position of the atom and d ij is the known distance between a pair of atoms (i; j).
Reference: [23] <author> M. Kojima, S. Mizuno, and A. Yoshise, </author> <title> A primal-dual interior point method for linear programming, in Progress in Mathematical Programming Interior-point and Related Methods, </title> <editor> N. Megiddo, ed., </editor> <publisher> Springer-Verlag, </publisher> <year> 1989. </year>
Reference-contexts: Complementarity has played a central role in the successful primal-dual interior point methods for linear and convex programming problems. The primal dual interior point method <ref> [23] </ref>, proposed by Kojima, Mizuno and Yoshise in 1987, maintains both the primal-dual strict feasibility and can be considered as a damped Newton process on the perturbed complementarity conditions.
Reference: [24] <author> R. Kranich, </author> <title> Interior point methods for mathematical programming: A bibliograph, </title> <type> tech. report, </type> <note> Available through NETLIB: send e-mail to netlib@research.att.com containing the message "send intbib.bib from bib. </note>
Reference-contexts: 1. Introduction. Interior point methods have proven to be an efficient approach for solving large scale linear and convex programming problems: see <ref> [24] </ref> for a comprehensive bibliography. An appealing property of these methods is that a small number of iterations is typically required to obtain an accurate solution for a large problem.
Reference: [25] <author> Y. Li, </author> <title> A Newton acceleration of the Weiszfeld algorithm for minimizing the sum of Euclidean 21 distances, </title> <note> Computational Optimization and Applications, to appear. </note>
Reference-contexts: There has been great interest in generalizing interior point methods to nonlinear (nonconvex) programming problems, e.g., <ref> [16, 36, 9, 12, 14, 35, 25, 19, 4] </ref>. However, 1 Research partially supported by the Applied Mathematical Sciences Research Program (KC-04-02) of the Office of Energy Research of the U.S. <p> Monotonicity offers a natural connection to the original problem. Monotonicity and the simplicity of an affine scaling method makes it particularly appealing and suitable for constrained nonconvex minimization. Based on this philosophy, Newton type affine scaling algorithms have been considered for various structured linear and nonlinear programming problems <ref> [8, 7, 26, 9, 27, 25, 2, 14] </ref>. These methods represent a generalization of the affine scaling methods to piecewise linear and nonlinear minimization. Such algorithms have fast local convergence and typically solve a large problem in a small number of iterations. <p> For l p problems and minimization of the sums of Euclidean distances, the resulting algorithms become a natural enhancement of the classical IRLS and Weiszfeld algorithms <ref> [26, 25] </ref>. 2 We consider the problem of minimizing a general nonlinear (nonconvex) function subject to linear inequality constraints, min f (x) subject to Ax b;(1.1) where A T = [a 1 ; ; a m ] 2 &lt; nfim . Let F def = fx : Ax bg. <p> Sufficient Decrease Conditions for the First and Second Order Optimality Conditions (AS.1), (AS.2) and (AS.3) are closely related to the sufficient decrease conditions proposed for the bound constrained minimization problem [9] and the nonlinear l 1 problem <ref> [25] </ref>. In [11], these conditions will be rigorously analyzed to establish convergence properties for the linearly constrained minimization (1.1). Essentially, under reasonable assumptions, if (AS.1) is satisfied at each iteration, then any limit point of fx k g will satisfy the complementarity conditions.
Reference: [26] <author> Y. Li, </author> <title> A globally convergent method for l p problems, </title> <journal> SIAM Journal on Optimization, </journal> <year> (1993), </year> <pages> pp. 609-629. </pages>
Reference-contexts: Monotonicity offers a natural connection to the original problem. Monotonicity and the simplicity of an affine scaling method makes it particularly appealing and suitable for constrained nonconvex minimization. Based on this philosophy, Newton type affine scaling algorithms have been considered for various structured linear and nonlinear programming problems <ref> [8, 7, 26, 9, 27, 25, 2, 14] </ref>. These methods represent a generalization of the affine scaling methods to piecewise linear and nonlinear minimization. Such algorithms have fast local convergence and typically solve a large problem in a small number of iterations. <p> For l p problems and minimization of the sums of Euclidean distances, the resulting algorithms become a natural enhancement of the classical IRLS and Weiszfeld algorithms <ref> [26, 25] </ref>. 2 We consider the problem of minimizing a general nonlinear (nonconvex) function subject to linear inequality constraints, min f (x) subject to Ax b;(1.1) where A T = [a 1 ; ; a m ] 2 &lt; nfim . Let F def = fx : Ax bg.
Reference: [27] <author> Y. Li, </author> <title> A trust region and affine scaling method for nonlinearly constrained minimization, </title> <type> Tech. Report TR 94-1463, </type> <institution> Computer Science Department, Cornell University, </institution> <year> 1994, </year> <note> (Submitted to SIAM J. Optimization). </note>
Reference-contexts: Monotonicity offers a natural connection to the original problem. Monotonicity and the simplicity of an affine scaling method makes it particularly appealing and suitable for constrained nonconvex minimization. Based on this philosophy, Newton type affine scaling algorithms have been considered for various structured linear and nonlinear programming problems <ref> [8, 7, 26, 9, 27, 25, 2, 14] </ref>. These methods represent a generalization of the affine scaling methods to piecewise linear and nonlinear minimization. Such algorithms have fast local convergence and typically solve a large problem in a small number of iterations.
Reference: [28] <author> R. Monteriro, T. Tsuchiya, and Y. Wang, </author> <title> A simplified global convergence proof of the affine scaling algorithm, </title> <journal> Annals of Operation Research, </journal> <year> (1993). </year>
Reference-contexts: Its choice is important for the convergence properties of an affine scaling method for linear programming <ref> [28, 32] </ref>. It is also possible to maintain strict dual feasibility, &gt; 0. However, since global convergence is achieved by monotonic decrease of f (x), and maintaining dual feasibility can lead to a smaller stepsize, we allow violation of dual feasibility.
Reference: [29] <author> J. J. Mor e, B. S. Garbow, and K. E. Hillstrom, </author> <title> Testing unconstrained optimization software, </title> <journal> ACM Transactions on Mathematical Software, </journal> <volume> 7 (1981), </volume> <pages> pp. 17-41. </pages>
Reference-contexts: A large scale nonlinear minimization test problem (1.1) is generated in a similar fashion to the test problems for a nonlinear minimization subject to simple bounds [9, 13]. Nonlinear objective functions f (x) are chosen from two classes: the nonlinear test problem collection for unconstrained minimization <ref> [29] </ref>, and the molecule minimization problem. In the latter, the objective function f (x) has the following formulation [22, 6], f (x) = (i;j)2S 2 d 2 where x i denotes the position of the atom and d ij is the known distance between a pair of atoms (i; j).
Reference: [30] <author> C. SUN, </author> <title> Dealing with dense rows in the solution of sparse linear least squares, </title> <type> Tech. Report CTC95TR227, </type> <institution> Cornell Theory Center, Cornell University, </institution> <year> 1995. </year>
Reference-contexts: Computational Experience. To illustrate its potential, preliminary computational experience is reported for our TRAM implementation. A trust region subproblem is solved via a two dimensional approximation as described in x3.4. The projected gradient g k is computed using a sparse least squares solver, e.g., <ref> [30] </ref>. A reflection technique described in x3.5 is incorporated. The details of the implemented two-dimensional subspace algorithm are described in FIG. 4.1. A large scale nonlinear minimization test problem (1.1) is generated in a similar fashion to the test problems for a nonlinear minimization subject to simple bounds [9, 13].
Reference: [31] <author> M. Todd, </author> <title> Potential-reduction methods in mathematical programming, </title> <type> Tech. Report TR1112, </type> <institution> School of Operations Research and Industrial Engineering, Cornell University, </institution> <year> 1995. </year>
Reference-contexts: Interior point methods share a common characteristic: they avoid approaching the boundary prematurely. The majority of interior point methods can be interpreted as following the central path to optimality, e.g., <ref> [21, 31] </ref>. The exception is the classical affine scaling algorithm [15, 33]. An affine scaling method uses a diagonal scaling technique to compute a damped step which ultimately leads to convergence to a solution. <p> The majority of interior point methods are based on the view that it is worthwhile to sacrifice decrease of the original objective function in order to gain centrality, e.g., <ref> [21, 31] </ref>. This view may not be reasonable for nonconvex problems; achieving centrality can cause loss of information provided by the initial point and possibly cause convergence to a local minimizer with a higher objective function value than that of the initial point.
Reference: [32] <author> T. Tsuchiya and R. Monteriro, </author> <title> Superlinear convergence of the affine scaling algorithm, </title> <booktitle> Mathematical Programming, </booktitle> <year> (1996). </year>
Reference-contexts: Its choice is important for the convergence properties of an affine scaling method for linear programming <ref> [28, 32] </ref>. It is also possible to maintain strict dual feasibility, &gt; 0. However, since global convergence is achieved by monotonic decrease of f (x), and maintaining dual feasibility can lead to a smaller stepsize, we allow violation of dual feasibility.
Reference: [33] <author> R. J. Vanderbei, M. S. Meketon, and B. A. Freedman, </author> <title> A modification of Karmarkar's linear programming algorithm, </title> <journal> Algorithmica, </journal> <volume> 1 (1986), </volume> <pages> pp. 395-407. </pages>
Reference-contexts: Interior point methods share a common characteristic: they avoid approaching the boundary prematurely. The majority of interior point methods can be interpreted as following the central path to optimality, e.g., [21, 31]. The exception is the classical affine scaling algorithm <ref> [15, 33] </ref>. An affine scaling method uses a diagonal scaling technique to compute a damped step which ultimately leads to convergence to a solution. <p> Despite the absence of a polynomial convergence property, an affine scaling method is the only type of interior point method which monotonically decreases the original objective function; it stands out for its simplicity and typically good computational performance, e.g., <ref> [1, 5, 33] </ref>. There has been great interest in generalizing interior point methods to nonlinear (nonconvex) programming problems, e.g., [16, 36, 9, 12, 14, 35, 25, 19, 4]. However, 1 Research partially supported by the Applied Mathematical Sciences Research Program (KC-04-02) of the Office of Energy Research of the U.S.
Reference: [34] <author> S. Vavasis, </author> <title> Stable numerical algorithms for equilibrium systems, </title> <type> Tech. Report 92-1280, </type> <institution> Computer Science Dept., Cornell University, </institution> <year> 1992. </year>
Reference-contexts: The disadvantage of using the symmetric n-by-n linear system (3.15) rather than the unsymmetric (m + n)-by-(m + n) linear system (3.3) is the increasing ill-condition of (3.15) as a solution is approached. The stability of the related linear system for linear programming has been studied <ref> [37, 34] </ref>. Similar issues are yet to be investigated for the linear system (3.15) for a nonlinear programming problem (1.1). 3.5. A Reflection Line Search. The effectiveness of an interior point method depends, in part, on the ability to avoid getting close to the boundary prematurely.
Reference: [35] <author> M. H. Wright, </author> <title> Some properties of hte hessian of the logarithmic barrier function, </title> <journal> Mathematical Programming, </journal> <volume> 67 (1994), </volume> <pages> pp. 265-295. </pages>
Reference-contexts: There has been great interest in generalizing interior point methods to nonlinear (nonconvex) programming problems, e.g., <ref> [16, 36, 9, 12, 14, 35, 25, 19, 4] </ref>. However, 1 Research partially supported by the Applied Mathematical Sciences Research Program (KC-04-02) of the Office of Energy Research of the U.S.
Reference: [36] <author> S. Wright, </author> <title> An interior point algorithm for linearly constrained optimization, </title> <journal> SIAM J. Optimization, </journal> <volume> 2 (1992), </volume> <pages> pp. </pages> <month> 450-473. </month> <title> [37] , Modified cholesky factorizations in interior-point algorithms for linear programming, </title> <type> Tech. Report MCS-P600-0596, </type> <institution> Mathematics and Computer Science Division, Argonne National Laboratory, </institution> <year> 1996. </year> <month> 22 </month>
Reference-contexts: There has been great interest in generalizing interior point methods to nonlinear (nonconvex) programming problems, e.g., <ref> [16, 36, 9, 12, 14, 35, 25, 19, 4] </ref>. However, 1 Research partially supported by the Applied Mathematical Sciences Research Program (KC-04-02) of the Office of Energy Research of the U.S.
References-found: 31

