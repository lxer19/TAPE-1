URL: file://ftp.cis.ohio-state.edu/pub/hpce/tensor/Papers/HPCAsia95-sorting.ps.gz
Refering-URL: http://www.cis.ohio-state.edu/~chh/Publication/tensor-papers.html
Root-URL: 
Title: Design and Implementation of an Efficient Sorting Algorithm on Vector Multiprocessors  
Author: J. H. Lu C.-H. Huang P. Sadayappan and R. W. Johnson 
Keyword: Bitonic merging, Sorting, Tensor product, Stride permutation, Parallel processing, Vector multiprocessor.  
Abstract: In this paper, we present the implementation of sorting algorithms based on bitonic mergers on vector multiprocessors. A programming methodology based on tensor products is used to design and implement these algorithms. We first demonstrate this methodology by expressing Batcher's bitonic merger in a tensor product formulation. Using the algebraic theory of tensor products, several variations of Batcher's bitonic merger are obtained. Programming characteristics of these formulas are described. An efficient sorting algorithm is constructed from these formulas. Finally, performance results for generated sorting codes on the Cray Y-MP are presented and compared with the Cray SciLib sorting routine. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> K. E. Batcher. </author> <title> Sorting networks and their appli cations. </title> <booktitle> In 1968 Spring Joint Computer Cong, AFIPS Conf., </booktitle> <address> Washington D.C., </address> <pages> pages 307-314, </pages> <year> 1968. </year>
Reference-contexts: 1 Introduction Efficient parallel sorting of large arrays is a non-trivial problem and has been widely studied in the literature. Batcher developed the odd-even merging network and the bitonic merging network, based on the observation that the merges of two lists can be done concurrently <ref> [1] </ref>. Those principles lead to efficient "sorting-by-merging" parallel sorting algorithms on sorting networks. The idea is to sort a list of data elements "bottom-up" and assemble sorted smaller lists into larger lists by merging. <p> Performance implications of those tensor product formulas are discussed. Sorting algorithms based on bitonic merging algorithms are also presented. 3.1 Bitonic Merging Algorithms Batcher presented that many of the comparisons needed to merge two lists can be done in parallel <ref> [1] </ref>. One of the methods proposed by Batcher is the bitonic merging algorithm. A bitonic merger B N takes an input bitonic sequence of size N , and the output is a sorted sequence in non-decreasing order.
Reference: [2] <author> A. Graham. </author> <title> Kronecker Products and Matrix Cal culus: With Applications. </title> <publisher> Ellis Horwood Limited, </publisher> <year> 1981. </year>
Reference-contexts: In this paper, we introduce a tensor product formulation of bitonic sort algorithms and use a programming methodology based on tensor products for implementing those algorithms on a vector multiprocessor, the Cray Y-MP. Tensor products, also known as Kronecker products, have been previously used for matrix calculus <ref> [2, 3] </ref>. This notation has also been used for designing high performance block recursive numerical algorithms such as fast Fourier transforms [5, 4] and Strassen's matrix multiplication algorithm [5, 8]. The tensor product formulations of these algorithms have been used to generate efficient parallel and vector programs for shared-memory multiprocessors. <p> Performance results on an eight-processor Cray Y-MP are presented. Conclusions are included in Section 5. 2 An Overview of the Tensor Product Notation In this section, the tensor product notation and some properties are described. For details on the tensor product notation, the reader is referred to <ref> [2, 3] </ref>. Definition 2.1 (Tensor Product) Let A and B be two matrices of size m fi n and p fi q, respectively.
Reference: [3] <author> R. A. Horn and C. R. Johnson. </author> <title> Topics in Ma trix Analysis. </title> <publisher> Cambridge University Press, </publisher> <address> Cam-bridge, </address> <year> 1991. </year>
Reference-contexts: In this paper, we introduce a tensor product formulation of bitonic sort algorithms and use a programming methodology based on tensor products for implementing those algorithms on a vector multiprocessor, the Cray Y-MP. Tensor products, also known as Kronecker products, have been previously used for matrix calculus <ref> [2, 3] </ref>. This notation has also been used for designing high performance block recursive numerical algorithms such as fast Fourier transforms [5, 4] and Strassen's matrix multiplication algorithm [5, 8]. The tensor product formulations of these algorithms have been used to generate efficient parallel and vector programs for shared-memory multiprocessors. <p> Performance results on an eight-processor Cray Y-MP are presented. Conclusions are included in Section 5. 2 An Overview of the Tensor Product Notation In this section, the tensor product notation and some properties are described. For details on the tensor product notation, the reader is referred to <ref> [2, 3] </ref>. Definition 2.1 (Tensor Product) Let A and B be two matrices of size m fi n and p fi q, respectively. <p> If N = rst, then L N t = (L rt t ) All of these properties follow from the definition or simple applications of preceding properties (see <ref> [3] </ref>). 3 Tensor Product Formulation for Sorting Algorithms In this section, we present various bitonic merging algorithms using the tensor product notation. Performance implications of those tensor product formulas are discussed.
Reference: [4] <author> J.R. Johnson, R.W. Johnson, D. Rodriguez, and R. Tolimieri. </author> <title> A methodology for designing, modifying and implementing fourier transform algorithms on various architectures. </title> <journal> Circuits Sys tems Signal Process, </journal> <volume> 9(4) </volume> <pages> 450-500, </pages> <year> 1990. </year>
Reference-contexts: Tensor products, also known as Kronecker products, have been previously used for matrix calculus [2, 3]. This notation has also been used for designing high performance block recursive numerical algorithms such as fast Fourier transforms <ref> [5, 4] </ref> and Strassen's matrix multiplication algorithm [5, 8]. The tensor product formulations of these algorithms have been used to generate efficient parallel and vector programs for shared-memory multiprocessors. <p> Note that I n B is the direct sum of n copies of B. I n B = n1 2 4 . . . 3 5 mnfimn Tensor permutations are sometimes called array index permutations and they are explored in more detail in <ref> [4] </ref>. One of the permutations that arise fre quently is the stride permutation. Definition 2.4 (Stride Permutation) L mn i e n j e m L mn n is referred to as the stride permutation of size mn with stride distance n. <p> In a tensor product formula I r S 2 I S , identity matrices can be implemented as either parallel operations or vector operations <ref> [4, 5] </ref>. We use j [I]j to denote parallel operations and j&lt;I&gt;j to denote vector operations. For example, we can parallelize and vectorize I r i1 S r I r ki as j [I r i1 ]jS r j&lt;I r ki&gt;j.
Reference: [5] <author> R. W. Johnson, C.-H. Huang, and J. R. Johnson. </author> <title> Multilinear algebra and parallel programming. </title> <journal> Journal of Supercomputing, </journal> <volume> 5 </volume> <pages> 189-218, </pages> <year> 1991. </year>
Reference-contexts: Tensor products, also known as Kronecker products, have been previously used for matrix calculus [2, 3]. This notation has also been used for designing high performance block recursive numerical algorithms such as fast Fourier transforms <ref> [5, 4] </ref> and Strassen's matrix multiplication algorithm [5, 8]. The tensor product formulations of these algorithms have been used to generate efficient parallel and vector programs for shared-memory multiprocessors. <p> Tensor products, also known as Kronecker products, have been previously used for matrix calculus [2, 3]. This notation has also been used for designing high performance block recursive numerical algorithms such as fast Fourier transforms [5, 4] and Strassen's matrix multiplication algorithm <ref> [5, 8] </ref>. The tensor product formulations of these algorithms have been used to generate efficient parallel and vector programs for shared-memory multiprocessors. A tensor product formula is built from vectors and matrices combined under the usual vector operations of componentwise addition and multiplication, matrix product and tensor product. <p> In a tensor product formula I r S 2 I S , identity matrices can be implemented as either parallel operations or vector operations <ref> [4, 5] </ref>. We use j [I]j to denote parallel operations and j&lt;I&gt;j to denote vector operations. For example, we can parallelize and vectorize I r i1 S r I r ki as j [I r i1 ]jS r j&lt;I r ki&gt;j.
Reference: [6] <author> S. D. Kaushik, S. Sharma, and C.-H. Huang. </author> <title> An algebraic theory for modeling multistage interconnection networks. </title> <journal> Journal of Information Science and Engineering, </journal> <note> 1993. To appear. </note>
Reference-contexts: We then prove the equivalence relationship between this tensor product formulas and the tensor product formulas of other bitonic merging algorithms. These formulas expresse the topology of the omega and inverse omega multistage interconnection networks as studied in <ref> [6] </ref>. We then present a general code generation strategy from tensor product formulas and use it to implement sorting algorithms on the Cray Y-MP. Finally, we demonstrate the use of formula manipulation based on algebraic theory to derive a new sorting algorithm which is suited to this particular architecture. <p> Omega Bitonic Merger) B r k = i=1 L r k i k Y h r k1 (T r I r k1 ) Lemmas 3.1 and 3.2 are called the omega and inverse omega bitonic mergers because they can be implemented on the omega and inverse omega multistage interconnection networks <ref> [6, 9, 10] </ref>, respectively. The omega bitonic merger and the inverse omega bitonic merger can be fully parallelized or vectorized. The stride permutation L r k r k1 affects the data access pattern. <p> Note that the formula in Lemma 3.3 is not unique for fully parallelized and vectorized implementation of bitonic mergers. Based on the functional equivalence relationship among a class of multistage interconnection networks <ref> [6, 12, 13] </ref>, it is possible to realize bitonic merging by using other multistage interconnection networks through reconfiguration. We will present tensor product formulation of sorting algorithms based on omega bitonic mergers.
Reference: [7] <author> D. E. Knuth. </author> <booktitle> The art of computer programming, </booktitle> <volume> Vol. 3. </volume> <publisher> Addison Wesley Publ. Co., </publisher> <address> Reading, Mass, </address> <year> 1974. </year>
Reference-contexts: Knuth provided detailed discussions of various sorting networks and suggested that the simple structure of Batcher's bitonic merger leads to a parallel sorting algorithm which is as fast as the odd-even merging algorithm but considerably easier to implement <ref> [7] </ref>. In this paper, we introduce a tensor product formulation of bitonic sort algorithms and use a programming methodology based on tensor products for implementing those algorithms on a vector multiprocessor, the Cray Y-MP. Tensor products, also known as Kronecker products, have been previously used for matrix calculus [2, 3]. <p> Note that any cyclic rotation of a bitonic sequence is a bitonic sequence and any subsequence of a bitonic sequence is also a bitonic sequence. Bitonic merging is explored in more detail in <ref> [7] </ref> Given an input bitonic sequence of size N = pq, we can view this vector as a p fi q matrix stored in row major order.
Reference: [8] <author> B. Kumar, C.-H. Huang, P. Sadayappan, and R.W. Johnson. </author> <title> A tensor product formulation of Strassen's matrix multiplication algorithm with memory reduction. </title> <journal> Scientific Programming. </journal> <note> To appear. </note>
Reference-contexts: Tensor products, also known as Kronecker products, have been previously used for matrix calculus [2, 3]. This notation has also been used for designing high performance block recursive numerical algorithms such as fast Fourier transforms [5, 4] and Strassen's matrix multiplication algorithm <ref> [5, 8] </ref>. The tensor product formulations of these algorithms have been used to generate efficient parallel and vector programs for shared-memory multiprocessors. A tensor product formula is built from vectors and matrices combined under the usual vector operations of componentwise addition and multiplication, matrix product and tensor product.
Reference: [9] <author> T. Lang. </author> <title> Interconnections between processors and memory modules using shu*e-exchange networks. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C 25(5) </volume> <pages> 496-503, </pages> <year> 1976. </year>
Reference-contexts: Omega Bitonic Merger) B r k = i=1 L r k i k Y h r k1 (T r I r k1 ) Lemmas 3.1 and 3.2 are called the omega and inverse omega bitonic mergers because they can be implemented on the omega and inverse omega multistage interconnection networks <ref> [6, 9, 10] </ref>, respectively. The omega bitonic merger and the inverse omega bitonic merger can be fully parallelized or vectorized. The stride permutation L r k r k1 affects the data access pattern.
Reference: [10] <author> D. K. Lawrie. </author> <title> Access and alignment of data in an array processor. </title> <journal> IEEE Transactions on Com puters, </journal> <volume> C-24(12):1145-1155, </volume> <year> 1975. </year>
Reference-contexts: Omega Bitonic Merger) B r k = i=1 L r k i k Y h r k1 (T r I r k1 ) Lemmas 3.1 and 3.2 are called the omega and inverse omega bitonic mergers because they can be implemented on the omega and inverse omega multistage interconnection networks <ref> [6, 9, 10] </ref>, respectively. The omega bitonic merger and the inverse omega bitonic merger can be fully parallelized or vectorized. The stride permutation L r k r k1 affects the data access pattern.
Reference: [11] <author> W. A. Martin. </author> <title> Sorting. </title> <journal> Computing Surveys, </journal> <volume> 3(4) </volume> <pages> 148-174, </pages> <month> Dec. </month> <year> 1971. </year>
Reference-contexts: Cloud State University, St. Cloud, MN 56301 although better networks have been constructed for particular data sizes <ref> [11] </ref>. Knuth provided detailed discussions of various sorting networks and suggested that the simple structure of Batcher's bitonic merger leads to a parallel sorting algorithm which is as fast as the odd-even merging algorithm but considerably easier to implement [7].
Reference: [12] <author> C.-L. Wu and T. Feng. </author> <title> On a class of multistage interconnection networks. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-29(8):694-702, </volume> <year> 1980. </year>
Reference-contexts: Note that the formula in Lemma 3.3 is not unique for fully parallelized and vectorized implementation of bitonic mergers. Based on the functional equivalence relationship among a class of multistage interconnection networks <ref> [6, 12, 13] </ref>, it is possible to realize bitonic merging by using other multistage interconnection networks through reconfiguration. We will present tensor product formulation of sorting algorithms based on omega bitonic mergers.
Reference: [13] <author> C.-L. Wu and T. Feng. </author> <title> The reverse exchange interconnection network. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-29(9):801-810, </volume> <year> 1980. </year>
Reference-contexts: Note that the formula in Lemma 3.3 is not unique for fully parallelized and vectorized implementation of bitonic mergers. Based on the functional equivalence relationship among a class of multistage interconnection networks <ref> [6, 12, 13] </ref>, it is possible to realize bitonic merging by using other multistage interconnection networks through reconfiguration. We will present tensor product formulation of sorting algorithms based on omega bitonic mergers.
Reference: [14] <author> M. Zagha and G. E. Blelloch. </author> <title> Radix sort for vector multiprocessors. </title> <booktitle> In Proc. of Intl. Conf. on Supercomputing, </booktitle> <pages> pages 712-721, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: The two key issues of performance optimization are maximizing vector length and minimizing stride distance. Measured performance results have shown that these generated sorting codes have better performance than the Cray SciLib sorting routine. In <ref> [14] </ref>, a radix sort for integer keys implemented on an eight processor Cray Y-MP was discussed. Radix sort has better serial time complexity than comparison-based sorts, such as bitonic sort, since for n keys it runs in O (n) time instead of O (nlg 2 n).
References-found: 14

