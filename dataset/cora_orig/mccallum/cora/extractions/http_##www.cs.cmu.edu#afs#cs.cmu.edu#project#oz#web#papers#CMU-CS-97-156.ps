URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/project/oz/web/papers/CMU-CS-97-156.ps
Refering-URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/project/oz/web/papers.html
Root-URL: 
Title: An Oz-Centric Review of Interactive Drama and Believable Agents  
Author: Michael Mateas 
Address: Pittsburgh, PA 15213  
Affiliation: School of Computer Science Carnegie Mellon University  
Date: June 1997  
Pubnum: CMU-CS-97-156  
Abstract: Believable agents are autonomous agents that exhibit rich personalities. Interactive dramas take place in virtual worlds inhabited by characters (believable agents) with whom an audience interacts. In the course of this interaction, the audience experiences a story (lives a plot arc). This report presents the research philosophy behind the Oz Project, a research group at CMU that has spent the last ten years studying believable agents and interactive drama. The report then surveys current work from an Oz perspective. This research was partially supported by a grant from Intel Corporation. The views and conclusions contained in this document are those of the author and should not be interpreted as representing the official policies, either expressed or implied, of Intel Corporation. 
Abstract-found: 1
Intro-found: 1
Reference: [OZ articles] <editor> Articles written by the OZ Project (CMU) On-line articles available about the OZ project. </editor> <title> Articles include overall descriptions of the goals of the project, the action architecture, the emotion architecture, and natural language generation (for the text based worlds). </title> <note> Oz Articles: http://www.cs.cmu.edu/afs/cs.cmu.edu/project/oz/web/papers.html </note>
Reference: [SAG articles] <institution> Articles written by the Software Agents Group (MIT Media Lab) On-line articles from the Software Agents Group. </institution> <note> Articles relevant to believable agents are listed under "Modeling Synthetic Characters: </note> <editor> Applications and Techniques." </editor> <title> Articles include descriptions of ALIVE, </title> <booktitle> action-selection architectures, and the role of artificial life in entertainment. Software Agents Group Articles: </booktitle> <address> http://lcs.www.media.mit.edu/groups/agents/papers.html </address>
Reference: [VTP articles] <institution> Articles written by the Virtual Theater Project (Stanford) On-line articles available about the Virtual Theater Project. </institution> <note> Articles include descriptions of their approach to emotion, personality, and user control of improvisational puppets. Virtual Theater Project Articles: http://www-ksl.stanford.edu/projects/cait/publicity.html </note>

Reference: [Agre 88a] <institution> The Dynamic Structure of Everyday Life Phil Agre. A.I. Memo 1085. Artificial Intelligence Lab. MIT. </institution> <month> October </month> <year> 1988. </year> <type> Agre's Ph.D. thesis. </type> <month> Describes Pengi, </month> <title> a program that can play a video game called Pengo. Pengi is able to play the game without employing any traditional planning. The Dynamic Structure of Everyday Life: </title> <publisher> ftp://publications.ai.mit.edu/ai-publications/1000-1499/AITR-1085/AITR-1085.ps </publisher>
Reference: [Agree 88b] <author> What are plans for? Phil Agre and David Chapman. </author> <title> A.I. Memo 1050a. </title> <booktitle> Artificial Intelligence Lab. </booktitle> <publisher> MIT. </publisher> <month> September </month> <year> 1988. </year> <title> Argues for a view of plans as plans-for-communication (as opposed to the classic view of plans-as-programs). What are plans for?: </title> <publisher> ftp://publications.ai.mit.edu/ai-publications/1000-1499/AIM-1050A.ps </publisher>
Reference: [Bledsoe 86] <editor> I Had a Dream: </editor> <publisher> AAAI Presidential Address, </publisher> <month> 19 August, </month> <year> 1985. </year> <title> Woody Bledsoe. </title> <journal> AI Magazine, </journal> <month> Spring </month> <year> 1986, </year> <pages> pp 57-61. </pages> <booktitle> Bledsoe describes the dream that brought him (and many AI researchers) into AI research in the first place: the dream of building computer companions. </booktitle>
Reference-contexts: This Dream, to build companions such as Data on Startrek, has motivated many workers in the field of AI. Woody Bledsoe, a former president of AAAI, captured this dream nicely in his 1985 Presidential Address <ref> [Bledsoe 86] </ref>. In describing the dream that motivated his career in AI, he opened: Twenty-five years ago I had a dream, a daydream, if you will. A dream shared with many of you.
Reference: [Brooks 91] <editor> Intelligence Without Reason Rodney Brooks. </editor> <booktitle> A.I. Memo 1293. Artificial Intelligence Lab. </booktitle> <publisher> MIT. </publisher> <month> April </month> <year> 1991. </year> <title> Argues for a situated, embodied, semantic-symbol-free approach to achieving intelligence in artificial systems. Intelligence Without Reason: </title> <publisher> ftp://publications.ai.mit.edu/ai-publications/1000-1499/AIM-1293.ps.Z </publisher>
Reference: [Brooks 90] <editor> Elephants Don't Play Chess Rodney Brooks. </editor> <booktitle> Robotics and Autonomous Systems 6, </booktitle> <year> 1990. </year> <pages> pp. 3-15. </pages> <note> Argues for a situated, embodied, semantic-symbol-free approach to achieving intelligence in artificial systems. </note>
Reference: [Cohen 97] <author> Neo: </author> <title> Learning Conceptual Knowledge by Sensorimotor Interaction with an Environment Paul R. </title> <editor> Cohen, Marc S. Atkin, Tim Oates, and Carole R. Beal. </editor> <booktitle> Proceedings of the First International Conference on Autonomous Agents, </booktitle> <pages> pp. 170-177. </pages> <address> Marina del Rey, CA. </address> <month> February 5-8, </month> <year> 1997. </year> <title> Describes a simulated baby who learns concepts by "physically" interacting with a simulated world. This work comes out of the Neo project. </title>
Reference-contexts: The hope is that as Cog interacts with the world, it will begin developing intellectual capabilities similar to a human. The guiding hypothesis is that much of human intelligence is the result of sensory-motor interactions with the environment as constrained by human bodies. Neo <ref> [Cohen 97] </ref>, at the University of Massachusetts, is a virtual baby living in a simulated world. Neo, like Cog, starts with simple sensory-motor reflexes. As Neo interacts with its world, it learns concepts through a hierarchical sequence of abstractions on streams of sensory-motor data.
Reference: [Damasio 94] <author> Descartes' Error: </author> <title> Emotion, Reason and the Human Brain Antonio Damasio. </title> <publisher> Avon Books. </publisher> <year> 1994. </year> <title> Describes recent research findings in neuropsychology which seem to indicate that emotion plays a fundamental role in human intelligence. Much of traditional cognitive psychology and artificial intelligence has assumed that emotion is not critical to understanding intelligence. </title>
Reference: [Egri 46] <author> The Art of Dramatic Writing: </author> <title> Its Basis in the Creative Interpretation of Human Motives Lajos Egri. </title> <publisher> Simon and Schuster. </publisher> <year> 1946. </year> <title> Describes how plays work via a theory which relates character, motive and story. </title>
Reference-contexts: Drama = Character + Story + Presentation Artists building non-interactive dramas (e.g. movies, books) have commented on the importance of both character and story for authoring powerful, dramatic experiences. For example, Lajos Egri, in the Art of Dramatic Writing <ref> [Egri 46] </ref>, has this to say about premise (i.e. plot or story). "No idea, and no situation, was ever strong enough to carry you through to its logical conclusion without a clear-cut premise. <p> So believability is this good thing that we want characters to have. After examining the writings of several character artists including The Illusion of Life [Thomas 81], Chuck Amuck [Jones 89], and The Art of Dramatic Writing <ref> [Egri 46] </ref>, the Oz group defined a set of requirements for believability including the following: Personality - Rich personality should infuse everything that a character does, from they way they talk and move to the way they think. What makes characters interesting are their unique ways doing things.
Reference: [Elliot 97] <editor> I Picked Up Catapia and Other Stories: </editor> <title> A Multimodal Approach to Expressivity for "Emotionally Intelligent" Agents Clark Elliott. </title> <booktitle> Proceedings of the First International Conference on Autonomous Agents, </booktitle> <pages> pp. 451-457. </pages> <address> Marina del Rey, CA. </address> <month> February 5-8, </month> <year> 1997. </year> <title> Describes an agent which communicates emotionally with people using speech recognition, text-to-speech conversion, real-time morphed schematic faces and music. This work comes out of the Affective Reasoning Project. Affective Reasoning Project: </title> <address> http://condor.depaul.edu/~elliott/ar.html </address>
Reference: [Fujita 97] <author> An Open Architecture for Robot Entertainment Masahiro Fujita and Koji Kageyama. </author> <booktitle> Proceedings of the First International Conference on Autonomous Agents, </booktitle> <pages> pp. 435-442. </pages> <address> Marina del Rey, CA. </address> <month> February 5-8, </month> <year> 1997. </year> <title> Describes a standard defined by Sony Corporation for household entertainment robots. </title>
Reference-contexts: Since the character itself is not that complex, the emotional intensity surrounding Tamagocchi may be related to its ubiquitous presence. At Agents 97, Sony demoed a robot dog as an example of their OpenR standard for household entertainment robots <ref> [Fujita 97] </ref>. The dog responds to colors, audible tones, and physical touch on its head. The most impressive feature of the dog was its fluid, lifelike movements. As an example, it can smoothly lay down, place its head on its paws, then get back up.
Reference: [Galyean 95] <author> Narrative Guidance of Interactivity Tinsley A. Galyean III. </author> <type> Ph.D. thesis, </type> <institution> Media Arts and Sciences, MIT, </institution> <month> June </month> <year> 1995. </year>
Reference-contexts: When a sensor has the value now, it begins looking for its associated event to happen in the world. When an actuator has the value now, it makes its associated event happen in the world. The final script-and-demon system I'll discuss is the plot control mechanism in Galyean's Dogmatix <ref> [Galyean 95] </ref>. Galyean makes an analogy between the action selection problem in behavioral agents and the event selection problem in plot control. At each point in time, a behavioral agent must select one (or in general, some small subset) behavior from its pool of possible behaviors.
Reference: [Grand 97] <author> Creatures: </author> <title> Artificial Life Autonomous Software Agents for Home Entertainment Stephen Grand, </title> <editor> Dave Cliff, and Anil Malhotra. </editor> <booktitle> Proceedings of the First International Conference on Autonomous Agents, </booktitle> <address> Marina del Rey, California, USA, </address> <month> February </month> <year> 1997, </year> <pages> pp 22-29. </pages> <note> Describes the architecture behind virtual pets which employ Alife technology (see Cyberlife). Cyberlife: http://www.cyberlife.co.uk/ </note>
Reference: [Hara 96] <editor> A Face Robot Able to Recognize and Produce Facial Expression Fumio Hara and Hiroshi Kobayashi. </editor> <booktitle> Proceedings of the 1996 IEEE/RSJ International Conference on Intelligent Robots and Systems, Senri Life Science Center, </booktitle> <address> Osaka, Japan, </address> <month> November 4-8, </month> <year> 1996, </year> <title> pp 1600-1607. Describes a robot with a human-like face that can recognize and produce human facial expressions. </title>
Reference-contexts: Japanese robotics researchers are building physical humanoids (e.g. JSK [Jouhou] , Waseda Humanoid Project [Waseda]). Examples of this work include a robot that can swing on a swingset [Inaba 96], and a robot with a 3D face <ref> [Hara 96] </ref> that can recognize and produce facial expressions. Such work has focused primarily on the engineering necessary to build and control a complex, jointed humanoid. These robots are not yet capable of sophisticated, autonomous behavior.
Reference: [Hayes-Roth 96] <editor> Acting in Character B. Hayes-Roth, R. van Gent, D. Huber. </editor> <booktitle> Proceedings of the AAAI Workshop on AI and Entertainment, </booktitle> <year> 1996. </year> <title> Describes a system that portrays a role change between a master and a servant. The master and servant improvise within the constraints of a script. Acting in Character: </title> <publisher> ftp://www-ksl.stanford.edu/pub/KSL_Reports/KSL-96-13.ps </publisher>
Reference-contexts: Script-and-demon systems can be used to provide this granularity of control. Two examples are Galyean's event selection system and Pinhanez's interval scripts (described above). Hayes-Roth's master/servant scenario <ref> [Hayes-Roth 96] </ref> is another example of scene level control. In this system, which is not interactive (the user doesn't play a character), a master and servant play out a power struggle which can end in the master and servant switching roles. The script issues directives to the characters.
Reference: [Inaba 96] <institution> Real-Time Vision-Based Control of Swing Motion by a Human-form Robot Using the Remote-Brained Approach Masayuki Inaba, </institution> <note> Ken'ichiro Nagasaka, </note> <editor> Fumio Kanehiro, Satoshi Kagami, Hirochika Inoue. </editor> <booktitle> Proceedings of the 1996 IEEE/RSJ International Conference on Intelligent Robots and Systems, Senri Life Science Center, </booktitle> <address> Osaka, Japan, </address> <month> November 4-8, </month> <year> 1996, </year> <title> pp 15-22. Describes a humanoid robot that can swing on a swing using visual tracking for control. </title>
Reference-contexts: Japanese robotics researchers are building physical humanoids (e.g. JSK [Jouhou] , Waseda Humanoid Project [Waseda]). Examples of this work include a robot that can swing on a swingset <ref> [Inaba 96] </ref>, and a robot with a 3D face [Hara 96] that can recognize and produce facial expressions. Such work has focused primarily on the engineering necessary to build and control a complex, jointed humanoid. These robots are not yet capable of sophisticated, autonomous behavior.
Reference: [Jones 89] <author> Chuck Amuck: </author> <title> The Life and Times of an Animated Cartoonist Chuck Jones. </title> <editor> Farrar, Straus and Giroux. </editor> <year> 1989. </year> <title> The autobiography of Chuck Jones, an animator at Warner Bros. Describes the Warner Bros. approach to creating characters and story. </title>
Reference-contexts: For example, Bugs Bunny is a believable character, but not a realistic character. So believability is this good thing that we want characters to have. After examining the writings of several character artists including The Illusion of Life [Thomas 81], Chuck Amuck <ref> [Jones 89] </ref>, and The Art of Dramatic Writing [Egri 46], the Oz group defined a set of requirements for believability including the following: Personality - Rich personality should infuse everything that a character does, from they way they talk and move to the way they think.
Reference: [Kelso 93] <author> Dramatic Presence Margaret Kelso, Peter Weyhrauch, Joseph Bates. </author> <title> Presence: </title> <journal> The Journal of Teleoperators and Virtual Environments, </journal> <volume> Vol. 2, Num. 1, </volume> <publisher> MIT Press, </publisher> <month> Winter </month> <year> 1993. </year> <title> Describes a series of live experiments to test the effect of interactive freedom on the dramatic experience. Also includes a description of plot graphs. Dramatic Presence: </title> <address> http://www.cs.cmu.edu/afs/cs.cmu.edu/project/oz/web/papers/CMU-CS-92-195.ps </address>
Reference-contexts: Such systems can be characterized as script-and-demon systems. The script specifies a linear or branching sequence of events. These events can be guarded by demons that won't let the event happen unless some preconditions on the state of the world have been satisfied. Plot graphs <ref> [Kelso 93] </ref>, an early approach to drama in the Oz project, are one example of such a system. A plot graph lays out scenes in a directed acyclic graph (DAG). The arcs represent the must-precede relationship.
Reference: [Laurel 91] <author> Computers as Theater Brenda Laurel. Addison-Wesley, </author> <year> 1991. </year> <title> Draws on Aristotle's theory of drama to define a new approach to designing dramatic human-computer interfaces. </title>
Reference: [Laurel 86] <institution> Toward the Design of a Computer-Based Interactive Fantasy System Brenda Laurel. </institution> <type> Ph.D. thesis, </type> <institution> Drama department, Ohio State University, </institution> <year> 1986. </year> <title> Describes a hypothetical drama manager that guides an interactive story experience. </title>
Reference-contexts: Story is predestination; interaction is freedom. Thus the conflict. Some have resolved the conflict by saying that interactive story is impossible. Others have redefined the notion of story to have less structure; whatever emerges from interaction is defined as story. Brenda Laurel, in her 1986 thesis <ref> [Laurel 86] </ref>, described a hypothetical expert system that causes a structured story to happen in the face of interaction. While the technology is different, the Oz drama manager takes this approach of simultaneously honoring story structure and interaction.
Reference: [Lebowitz 85] <editor> Story Telling as Planning and Learning Michael Lebowitz. </editor> <volume> Poetics 14, </volume> <year> 1985. </year> <pages> pp. </pages> <month> 483-502. </month> <title> Describes the use of plan-like plot-fragments in UNIVERSE, a system that writes soap opera-like stories. </title>
Reference-contexts: Still higher on the spectrum are systems that generate novel stories. Unfortunately, the examples of such systems are not interactive; the systems generate a textual story that is read by the user. Universe <ref> [Lebowitz 85, 84] </ref> tells a serial soap-opera-like story. Characters are described by sets of attributes. Example attributes are interpersonal relationships (e.g. ex-spouse, div-mom), stereotypes (e.g. party-goer, egomaniac), and goals (e.g. become-famous, associate-right). A library of plot fragments (plans) serves as the raw material for composing stories.
Reference: [Lebowitz 84] <editor> Creating Characters in a Story-Telling Universe Michael Lebowitz. </editor> <volume> Poetics 13, </volume> <year> 1984. </year> <pages> pp. </pages> <month> 171-194. </month> <title> Describes the representations of characters in UNIVERSE, a system that writes soap opera-like stories. </title>
Reference: [Lester 97] <editor> Increasing Believability in Animated Pedagogical Agents James Lester and Brian Stone (IntelliMedia). </editor> <booktitle> Proceedings of the First International Conference on Autonomous Agents, </booktitle> <pages> pp. 16-21. </pages> <address> Marina del Rey, CA. </address> <month> February 5-8, </month> <year> 1997. </year> <title> Describes a competition-based behavior sequencing engine which produces life-like behavior while maintaining pedagogical appropriateness (e.g. don't distract a learner with some fancy behavior when they are problem solving). Increasing Believability in Animated Pedagogical Agents: </title> <note> http://www.csc.ncsu.edu/eos/users/l/lester/Public/auton-agents-97.ps IntelliMedia: http://www.csc.ncsu.edu/eos/users/l/lester/www/imedia/ </note>
Reference: [Loyall 97a] <author> Believable Agents A. Bryan Loyall. </author> <type> Ph.D. thesis, Tech report CMU-CS-97-123, </type> <institution> Carnegie Mellon University, </institution> <month> May </month> <year> 1997. </year> <title> Describes requirements for believability derived from the character arts. These requirements motivate the description of Hap, an agent language designed to facilitate writing believable agents. The thesis then describes several examples of agents written in Hap. Finally, a method for doing believable, embodied natural language generation in Hap is described. This work is part of the Oz Project. Oz Project: </title> <address> http://www.cs.cmu.edu/afs/cs.cmu.edu/project/oz/web/oz.html </address>
Reference-contexts: But builders of interactive characters must concern themselves explicitly with building agent architectures that support these requirements. Chapter 2 of Bryan Loyall's thesis <ref> [Loyall 97a] </ref> offers a more detailed analysis of the requirements for believability. Classical vs. behavioral AI To begin thinking about how to meet the Illusion of Life believability requirement, let's explore the distinction between classical and behavioral AI.

Reference: [McCloud 93] <author> Understanding Comics: </author> <title> The Invisible Art Scott McCloud. </title> <address> HarperCollins. </address> <year> 1993. </year> <note> Written in comic book form, this book describes the semiotics of comics. </note>
Reference: [Meehan 76] <author> The Metanovel James Meehan. </author> <type> Ph.D. Dissertation. </type> <institution> Yale University. </institution> <year> 1976. </year> <title> Describes a system that generates Aesop fable-like stories. It generates stories by using planning to achieve the goals of characters. </title>
Reference-contexts: Stories are told by composing these plot fragments. In addition, the system learns new plot fragments by generalizing old ones. Tail-spin <ref> [Meehan 76] </ref> tells Aesop-fable-like stories. It does not use a library of plot fragments. Instead, stories are generated purely by trying to accomplish the (sometimes conflicting) goals of characters. Both these systems view story telling as a planning problem. Bringsjord's [Bringsjord] work is a modern example of non-interactive story generation.
Reference: [Neal Reilly 97] <editor> A Methodology for Building Believable Social Agents W. Scott Neal Reilly. </editor> <booktitle> Proceedings of the First International Conference on Autonomous Agents, </booktitle> <pages> pp. 114-121. </pages> <address> Marina del Rey, CA. </address> <month> February 5-8, </month> <year> 1997. </year> <title> Describes a methodology for building social behaviors on a character-by-character basis. The philosophy behind this approach is that generic taxonomies of social behavior and personality are inappropriate for building believable characters. This work comes out of the OZ Project. Oz Project: </title> <address> http://www.cs.cmu.edu/afs/cs.cmu.edu/project/oz/web/oz.html </address>
Reference: [Neal Reilly 96] <author> Believable Social and Emotional Agents W. Scott Neal Reilly. </author> <type> Ph.D. thesis. Tech report CMU-CS-96-138, </type> <institution> Carnegie Mellon University, </institution> <month> May </month> <year> 1996. </year> <title> Describes a system that maintains emotional state and a methodology for incorporating emotion into the behaviors of believable agents. The thesis then describes a methodology for building believable social behaviors. This work is part of the Oz Project. Believable Social and Emotional Agents: http://www.cs.cmu.edu/afs/cs.cmu.edu/project/oz/web/papers/CMU-CS-96-138-1sided.ps Oz Project: </title> <address> http://www.cs.cmu.edu/afs/cs.cmu.edu/project/oz/web/oz.html </address>
Reference-contexts: The author communicates the character's personality and mood by tuning probabilities for selecting one action over another. Both IMPROV and Oz share an author-centered point of view. However Hap (the Oz believable agent language) provides more support for expressing complex control relationships among behaviors. In addition, Em <ref> [Neal Reilly 96] </ref>provides support for maintaining complex emotional state (something that would have to be done manually using the IMPROV language). On the other hand, the procedural animation portion of the IMPROV scripting language provides more language support for animating control points on the model.
Reference: [Perlin 96] <author> Improv: </author> <title> A system for Scripting Interactive Actors in Virtual Worlds Ken Perlin, </title> <editor> Athomas Goldberg. </editor> <booktitle> Proceedings of SIGRAPH 96, </booktitle> <pages> pp. 205-216. </pages> <address> New Orleans, LA. </address> <month> Aug. </month> <year> 1996. </year> <title> Describes the interactive character architecture of the Improv project. An animation engine manipulates the control points of a graphical model. A behavior engine allows the user to specify higher level scripts which control the characters motions. The scripts are written in an English-like scripting language (reminiscent of HyperTalk). Improv: A system for Scripting Interactive Actors in Virtual Worlds: </title> <note> http://www.mrl.nyu.edu/improv/sig-paper96/ Improv project: http://www.mrl.nyu.edu/improv/index.html </note>
Reference: [Pinhanez 97] <author> Interval Scripts: </author> <title> A Design Paradigm for Story-Based Interactive Systems Cladio Pinhanez. </title> <booktitle> Proceedings of CHI97, </booktitle> <address> Atlanta, GA, USA, </address> <month> March 22-27, </month> <title> pp 287-294. Describes a method whereby interaction can be scripted with a temporal calculus that represents the relationships between intervals. A constraint propagation mechanism is used to determine the temporal value (past, now, future, or some mixed state) of each interval. Intervals can be associated with sensors and effectors. Interval Scripts: A Design Paradigm for Story-Based Interactive Systems: </title> <note> http://pinhanez.www.media.mit.edu/cgi-bin/tr_pagemaker#TR391 Claudio Pinhanez: http://pinhanez.www.media.mit.edu/people/pinhanez/ </note>
Reference-contexts: These are ways that the drama manager can influence the world. Hints make it more likely that the user will move into the next scene; obstacles slow the user down. Demons recognize when a user has completed a scene. Another example, Pinhanez's Interval Scripts <ref> [Pinhanez 97] </ref>, represents the script by using a temporal calculus to record temporal relationships among intervals. Some of these intervals are connected to sensors (demons) that wait for events to occur in the world; other's are connected to actuators that make events happen in the world.
Reference: [Rich 97] <author> COLLAGEN: </author> <title> When Agents Collaborate with People Charles Rich and Candace L. Sidner. </title> <booktitle> Proceedings of the First International Conference on Autonomous Agents, </booktitle> <pages> pp. 284-291. </pages> <address> Marina del Rey, CA. </address> <month> February 5-8, </month> <year> 1997. </year> <title> Describes a toolkit that supports the construction of agents who follow the rules of collaborative discourse. This work comes out of MERL. </title> <address> MERL: http://www.merl.com/ </address>
Reference: [Thomas 81] <author> The Illusion of Life: Disney Animation Frank Thomas and Ollie Johnston. Hyperion. </author> <year> 1981. </year> <title> Written by two Disney animators, this book describes the history of animation at Disney and what techniques the animators developed to make their characters seem believable. This book has been highly influential in the OZ Project at CMU. Oz Project: </title> <address> http://www.cs.cmu.edu/afs/cs.cmu.edu/project/oz/web/oz.html </address>
Reference-contexts: This is not the same thing as realism. For example, Bugs Bunny is a believable character, but not a realistic character. So believability is this good thing that we want characters to have. After examining the writings of several character artists including The Illusion of Life <ref> [Thomas 81] </ref>, Chuck Amuck [Jones 89], and The Art of Dramatic Writing [Egri 46], the Oz group defined a set of requirements for believability including the following: Personality - Rich personality should infuse everything that a character does, from they way they talk and move to the way they think.
Reference: [Thorison 96] <author> Communicative Humanoids: </author> <title> A Computational Model of Psychosocial Dialogue Skills Kristinn Thorison. </title> <type> PhD Thesis. </type> <institution> MIT Media Laboratory, </institution> <year> 1996. </year> <title> Describes a system called Gandalf that models human dialog competence in order to communicate with a human using speech and gesture in realtime. Communicative Humanoids: A Computational Model of Psychosocial Dialogue Skills: </title> <note> http://kris.www.media.mit.edu/people/kris/abstr.html Kristinn Thorison: http://kris.www.media.mit.edu/people/kris/ </note>
Reference: [Wavish 97] <editor> Virtual Actors that Can Perform Scripts and Improvise Roles Peter Wavish and David Connah. </editor> <booktitle> Proceedings of the First International Conference on Autonomous Agents, </booktitle> <pages> pp. 317-322. </pages> <address> Marina del Rey, CA. </address> <month> February 5-8, </month> <year> 1997. </year> <title> Describes a script based architecture developed at Phillips Research Labs for controlling virtual characters. </title>
Reference: [Weizenbaum 66] <institution> ELIZA -- A computer program for the study of natural language communication between man and machine J. </institution> <address> Weizenbaum. </address> <booktitle> Communications of the ACM 9(1) </booktitle> <pages> 36-45, </pages> <year> 1966. </year> <title> Original paper describing ELIZA, a template-based pattern-matching program that simulates the conversational patterns of a non-directive therapist. </title>
Reference-contexts: Providing a believable agent with a physical body is an interesting research direction to pursue. The combination of rich behavior, personality, and physicality could produce a powerful audience response. Chatterbots Chatterbots are programs that engage in conversation. The original chatterbot is Eliza <ref> [Weizenbaum 66] </ref>, a program that uses sentence template matching to simulate the conversation of a non-directive therapist. Julia [Julia] is a chatterbot that connects to multi-user dungeons (MUD). Besides engaging in conversation, Julia has a simple memory that remembers what's been said to her and where she's been.
Reference: [Weyhrauch 97] <author> Guiding Interactive Drama Peter Weyhrauch. </author> <type> Ph.D. thesis, Tech report CMU-CS-97-109, </type> <institution> Carnegie Mellon University, </institution> <month> January </month> <year> 1997. </year> <title> Describes the Oz drama manager, a search-based system for guiding an interactive story experience. This work is part of the Oz project. Oz Project: </title> <address> http://www.cs.cmu.edu/afs/cs.cmu.edu/project/oz/web/oz.html </address>
Reference-contexts: While the technology is different, the Oz drama manager takes this approach of simultaneously honoring story structure and interaction. Oz drama manager The Oz drama manager <ref> [Weyhrauch 97] </ref> controls a story at the level of plot points. Plot points are "important moments" in a story. In an hour and a half film, there may be 12-15 of them.
References-found: 38

