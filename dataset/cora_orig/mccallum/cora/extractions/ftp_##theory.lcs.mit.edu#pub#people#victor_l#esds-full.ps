URL: ftp://theory.lcs.mit.edu/pub/people/victor_l/esds-full.ps
Refering-URL: http://theory.lcs.mit.edu/~victor_l/papers/PODC96.html
Root-URL: 
Title: Eventually-Serializable Data Services  
Author: Alan Fekete David Gupta Victor Luchangco Nancy Lynch Alex Shvartsman 
Address: Madsen Building F09, University of Sydney, NSW 2006, Australia.  Cambridge, MA 02139.  191 Auditorium Rd. U-155, University of Connecticut, Storrs, CT  
Affiliation: Basser Department of Computer Science,  Laboratory for Computer Science, Massachusetts Institute of Technology,  Computer Science and Engineering Dept.,  
Note: This work was supported by ARPA contract F19628-95-C-0118, AFOSR-ONR contract F49620-94-1-0199, AFOSR contract F49620-97-1-0337, and NSF contract 9225124-CCR.  
Date: March 18, 1998  06269.  
Abstract: Data replication is used in distributed systems to improve availability, to increase throughput and to eliminate single points of failures. The disadvantage of replication is the additional effort required to maintain consistency among replicas when serializing operation requests submitted by clients. In some settings, e.g., distributed directory services, it is acceptable to have transient inconsistencies as long as a consistent view of data is eventually established through a well-specified serialization of operations. Clear specification of the consistency guarantees offered by a replicated data service is important in making such services usable. We present a new specification for distributed data services that trades off immediate consistency guarantees for improved system availability and efficiency, while ensuring the long-term consistency of the data. An eventually-serializable data service maintains the requested operations in a partial order that gravitates over time towards a total order. It provides clear and unambiguous guarantees about the immediate and long-term behavior of the system. To demonstrate its utility, we present an algorithm, based on one of Ladin, Liskov, Shrira, and Ghemawat [15], that implements this specification. Our algorithm exports the interface of the abstract service, and generalizes their algorithm by allowing general operations and greater flexibility in specifying consistency requirements. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P. Alsberg and J. Day. </author> <title> A principle for resilient sharing of distributed resources. </title> <booktitle> In Proceedings of the 2nd International Conference on Software Engineering, </booktitle> <pages> pages 627-644, </pages> <month> Oct. </month> <year> 1976. </year>
Reference-contexts: The strongest and simplest notion of consistency is atomicity, which requires the replicas to collectively emulate a single centralized object. Methods to achieve atomicity include write-all/read-one [4], primary copy <ref> [1, 26, 23] </ref>, majority consensus [27], and quorum consensus [11, 12]. Because achieving atomicity often has a high performance cost, some applications, such as directory services, are willing to tolerate some transient inconsistencies. This gives rise to different notions of consistency.
Reference: [2] <author> H. Attiya and J. Welch. </author> <title> Sequential consistency versus linearizability. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 12(2), </volume> <year> 1994. </year>
Reference-contexts: Sequential consistency [16], guaranteed by systems such as Orca [3], allows operations to be reordered as long as they remain consistent with the view of isolated clients. An inherent disparity in the performance of atomic and sequentially consistent objects has been established <ref> [2] </ref>. Other systems provide even weaker guarantees to the clients [9, 5, 10] in order to get better performance. Improving performance by providing weaker guarantees results in more complicated semantics.
Reference: [3] <author> H. Bal, M. Kaashoek, and A. Tanenbaum. Orca: </author> <title> A language for parallel programming of distributed systems. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 18(3) </volume> <pages> 190-205, </pages> <month> Mar. </month> <year> 1992. </year>
Reference-contexts: Because achieving atomicity often has a high performance cost, some applications, such as directory services, are willing to tolerate some transient inconsistencies. This gives rise to different notions of consistency. Sequential consistency [16], guaranteed by systems such as Orca <ref> [3] </ref>, allows operations to be reordered as long as they remain consistent with the view of isolated clients. An inherent disparity in the performance of atomic and sequentially consistent objects has been established [2].
Reference: [4] <author> P. Bernstein, V. Hadzilacos, and N. Goodman. </author> <title> Concurrency Control and Recovery in Database Systems. </title> <publisher> Addison-Wesley, </publisher> <year> 1987. </year>
Reference-contexts: The strongest and simplest notion of consistency is atomicity, which requires the replicas to collectively emulate a single centralized object. Methods to achieve atomicity include write-all/read-one <ref> [4] </ref>, primary copy [1, 26, 23], majority consensus [27], and quorum consensus [11, 12]. Because achieving atomicity often has a high performance cost, some applications, such as directory services, are willing to tolerate some transient inconsistencies. This gives rise to different notions of consistency.
Reference: [5] <author> A. Birrell, R. Levin, R. Needham, and M. Schroeder. Grapevine: </author> <title> An exercise in distributed computing. </title> <journal> Communications of the ACM, </journal> <volume> 25(4) </volume> <pages> 260-274, </pages> <year> 1982. </year>
Reference-contexts: An inherent disparity in the performance of atomic and sequentially consistent objects has been established [2]. Other systems provide even weaker guarantees to the clients <ref> [9, 5, 10] </ref> in order to get better performance. Improving performance by providing weaker guarantees results in more complicated semantics. Even when the behavior of the replicated objects is specified unambiguously, it is more difficult to understand and to reason about the correctness of implementations. <p> In a computing enterprise, naming and directory are important basic services used to make distributed resources accessible transparently of the resource locations or their physical addresses. Such services include Grapevine <ref> [5] </ref>, DECdns [17], DCE GDS (Global Directory Service) and CDS (Cell Directory Service) [24], ISO/OSI X.500 [14], and the Internet's DNS (Domain Name System) [13]. A directory service must be robust and it must have good response time for name lookup and translation requests in a geographically distributed setting.
Reference: [6] <author> O. Cheiner. </author> <title> Implementation and evaluation of an eventually-serializable data service. </title> <institution> Master of Engineering thesis, Massachusetts Institute of Technology, </institution> <month> Aug. </month> <year> 1997. </year>
Reference-contexts: Together with the abstract algorithm, the specification can guide the design and implementation of distributed system building blocks layered on general-purpose distributed platforms (middleware) such as DCE [24]. In a separate effort, Cheiner has implemented one such building block <ref> [6, 7] </ref>, using the algorithm in this paper as its design specification. As a proof-of-concept, several quite distinct clients that use the building block have been developed. These include a Web client, a text-oriented Unix client, and Microsoft Excel 97 client for Windows 95. <p> Section 10 suggests several ways in which the algorithm can be modified to give better performance, or take into account some pragmatic implementation issues. Finally, Section 11 presents an overview of the implementation by Cheiner <ref> [6, 7] </ref>, and gives some examples of how eventually-serializable data services may be used. 2 Preliminary Definitions and Conventions In this section, we introduce some mathematical notation and conventions that we use in this paper. <p> We close the presentation by overviewing an implementation of the eventually-serializable data service and give examples of uses of services such as ours. 11.1 An Experimental Implementation The abstract algorithm presented in this paper was used by Cheiner <ref> [6, 7] </ref> as the basis for developing an exploratory implementation of the eventually-serializable data service. This implementation incorporates some of the optimizations described above. The implementation was constructed with two main objectives in mind. <p> It was observed that latency times deteriorated linearly as the number of strict requests was increased. Thus this experiment provides evidence that the service indeed reflects a designed trade-off between consistency and performance. The reader is referred to other papers for details on the implementation and experimental results <ref> [6, 7] </ref>. 40 11.2 Directory Services and Distributed Repositories A service such as ours is well-suited for distributed directory services. In a computing enterprise, naming and directory are important basic services used to make distributed resources accessible transparently of the resource locations or their physical addresses.
Reference: [7] <author> O. Cheiner and A. Shvartsman. </author> <title> Experimental implementation of an eventually-serializable data service. </title> <type> Unpublished Manuscript, </type> <year> 1997. </year> <month> 41 </month>
Reference-contexts: Together with the abstract algorithm, the specification can guide the design and implementation of distributed system building blocks layered on general-purpose distributed platforms (middleware) such as DCE [24]. In a separate effort, Cheiner has implemented one such building block <ref> [6, 7] </ref>, using the algorithm in this paper as its design specification. As a proof-of-concept, several quite distinct clients that use the building block have been developed. These include a Web client, a text-oriented Unix client, and Microsoft Excel 97 client for Windows 95. <p> Section 10 suggests several ways in which the algorithm can be modified to give better performance, or take into account some pragmatic implementation issues. Finally, Section 11 presents an overview of the implementation by Cheiner <ref> [6, 7] </ref>, and gives some examples of how eventually-serializable data services may be used. 2 Preliminary Definitions and Conventions In this section, we introduce some mathematical notation and conventions that we use in this paper. <p> We close the presentation by overviewing an implementation of the eventually-serializable data service and give examples of uses of services such as ours. 11.1 An Experimental Implementation The abstract algorithm presented in this paper was used by Cheiner <ref> [6, 7] </ref> as the basis for developing an exploratory implementation of the eventually-serializable data service. This implementation incorporates some of the optimizations described above. The implementation was constructed with two main objectives in mind. <p> It was observed that latency times deteriorated linearly as the number of strict requests was increased. Thus this experiment provides evidence that the service indeed reflects a designed trade-off between consistency and performance. The reader is referred to other papers for details on the implementation and experimental results <ref> [6, 7] </ref>. 40 11.2 Directory Services and Distributed Repositories A service such as ours is well-suited for distributed directory services. In a computing enterprise, naming and directory are important basic services used to make distributed resources accessible transparently of the resource locations or their physical addresses.
Reference: [8] <author> J. Dongarra, S. Otto, M. Snir, and D. Walker. </author> <title> A message passing standard for MPP and workstations. </title> <journal> Communications of the ACM, </journal> <volume> 39(7) </volume> <pages> 84-90, </pages> <month> July </month> <year> 1996. </year>
Reference-contexts: The second objective was to obtain experimental observations of the trade-off between consistency and performance of the service implementation. The implementation of the service runs on a network of Unix workstations and it uses MPI <ref> [8] </ref> as its message passing mechanism. The implementation is coded in C++. The object-oriented design makes it easy to parameterize the implementation for different serial data types and to integrate it with a variety of clients.
Reference: [9] <author> M. Fischer and A. Michael. </author> <title> Sacrificing serializability to attain high availability of data in an unreliable network. </title> <booktitle> In Proceedings of the ACM Symposium on Database Systems, </booktitle> <pages> pages 70-75, </pages> <month> Mar. </month> <year> 1982. </year>
Reference-contexts: An inherent disparity in the performance of atomic and sequentially consistent objects has been established [2]. Other systems provide even weaker guarantees to the clients <ref> [9, 5, 10] </ref> in order to get better performance. Improving performance by providing weaker guarantees results in more complicated semantics. Even when the behavior of the replicated objects is specified unambiguously, it is more difficult to understand and to reason about the correctness of implementations.
Reference: [10] <author> H. Garcia-Molina, N. Lynch, B. Blaustein, C. Kaufman, and O. Schmueli. </author> <title> Notes on a reliable broadcast protocol. </title> <type> Technical memorandum, </type> <institution> Computer Corporation America, </institution> <month> Oct. </month> <year> 1985. </year>
Reference-contexts: An inherent disparity in the performance of atomic and sequentially consistent objects has been established [2]. Other systems provide even weaker guarantees to the clients <ref> [9, 5, 10] </ref> in order to get better performance. Improving performance by providing weaker guarantees results in more complicated semantics. Even when the behavior of the replicated objects is specified unambiguously, it is more difficult to understand and to reason about the correctness of implementations.
Reference: [11] <author> D. Gifford. </author> <title> Weighted voting for replicated data. </title> <booktitle> In Proceedings of the 7th ACM Symposium on Principles of Operating Systems Principles, </booktitle> <pages> pages 150-162, </pages> <month> Dec. </month> <year> 1979. </year>
Reference-contexts: The strongest and simplest notion of consistency is atomicity, which requires the replicas to collectively emulate a single centralized object. Methods to achieve atomicity include write-all/read-one [4], primary copy [1, 26, 23], majority consensus [27], and quorum consensus <ref> [11, 12] </ref>. Because achieving atomicity often has a high performance cost, some applications, such as directory services, are willing to tolerate some transient inconsistencies. This gives rise to different notions of consistency.
Reference: [12] <author> M. Herlihy. </author> <title> A quorum-consensus replication method for abstract data types. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 4(1) </volume> <pages> 32-53, </pages> <month> Feb. </month> <year> 1986. </year>
Reference-contexts: The strongest and simplest notion of consistency is atomicity, which requires the replicas to collectively emulate a single centralized object. Methods to achieve atomicity include write-all/read-one [4], primary copy [1, 26, 23], majority consensus [27], and quorum consensus <ref> [11, 12] </ref>. Because achieving atomicity often has a high performance cost, some applications, such as directory services, are willing to tolerate some transient inconsistencies. This gives rise to different notions of consistency.
Reference: [13] <author> IETF. </author> <title> RFC 1034 and RFC 1035 Domain Name System, </title> <year> 1990. </year>
Reference-contexts: Such services include Grapevine [5], DECdns [17], DCE GDS (Global Directory Service) and CDS (Cell Directory Service) [24], ISO/OSI X.500 [14], and the Internet's DNS (Domain Name System) <ref> [13] </ref>. A directory service must be robust and it must have good response time for name lookup and translation requests in a geographically distributed setting. Access to a directory service is dominated by queries and it is unnecessary for the updates to be atomic in all cases.
Reference: [14] <institution> International Standard 9594-1, </institution> <note> Information Processing Systems|Open Systems Interconnection|The Directory, </note> <author> ISO and IEC, </author> <year> 1988. </year>
Reference-contexts: In a computing enterprise, naming and directory are important basic services used to make distributed resources accessible transparently of the resource locations or their physical addresses. Such services include Grapevine [5], DECdns [17], DCE GDS (Global Directory Service) and CDS (Cell Directory Service) [24], ISO/OSI X.500 <ref> [14] </ref>, and the Internet's DNS (Domain Name System) [13]. A directory service must be robust and it must have good response time for name lookup and translation requests in a geographically distributed setting.
Reference: [15] <author> R. Ladin, B. Liskov, L. Shrira, and S. Ghemawat. </author> <title> Lazy replication: Exploiting the semantics of distributed services. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 10(4) </volume> <pages> 360-391, </pages> <month> Nov. </month> <year> 1992. </year>
Reference-contexts: In practice, replicated systems are often incompletely or ambiguously specified. 1.2 Background for our Work: Lazy Replication As it is important that our specification be applicable for real systems, we build heavily on the work of Ladin, Liskov, Shrira, and Ghemawat <ref> [15] </ref> on highly available replicated data services. They specify general conditions for such a service, and present an algorithm based on lazy replication, in which operations received by each replica are gossiped in the background. <p> Operations that are neither forced nor immediate are called causal. As long as most of the operations are causal, their algorithm [[[Comment: the algorithm of <ref> [15] </ref>]]] is very efficient. The specification in [15] is tuned for their algorithm, and exposes some of the implementation details to the clients. This makes it difficult to ascertain which are details are essential to the correctness of their algorithm, and which may changed without significant effect. <p> Operations that are neither forced nor immediate are called causal. As long as most of the operations are causal, their algorithm [[[Comment: the algorithm of <ref> [15] </ref>]]] is very efficient. The specification in [15] is tuned for their algorithm, and exposes some of the implementation details to the clients. This makes it difficult to ascertain which are details are essential to the correctness of their algorithm, and which may changed without significant effect. <p> We provide two types of operations at the client interface: (a) strict operations, which are required to be stable at the time of the response, i.e., all operations that precede it must be totally ordered, and (b) operations that may be reordered after the response is issued. As in <ref> [15] </ref>, clients may also specify constraints on the order in which operations are applied to the data object. Our specification omits implementation details, allowing users to ignore the issues of replication and distribution, while giving implementors the freedom to design the system to best satisfy the performance requirements. <p> Particular system implementations, of course, may exploit the semantics of the specific data objects to improve performance. Our algorithm is based on the lazy replication algorithm from <ref> [15] </ref>. We present a high-level formal description of the algorithm, which takes into account the replication of the data, and maintains consistency by propagating operations and bookkeeping information among replicas via gossip messages. <p> It provides a smooth combination of fast service with weak causality requirements and slower service with stronger requirements. It does not use the multipart timestamps of <ref> [15] </ref>, which we view as an optimization of the basic algorithm. By viewing the abstract algorithm as a specification for more detailed implementations, we indicate how this, and other optimizations, may be incorporated into the framework of this paper. <p> This is reasonable if the computation required by each operation is not excessive. This algorithm is based on the lazy-replication scheme of Ladin, Liskov, Shrira and Ghemawat <ref> [15] </ref>, which uses gossip messages to maintain consistency among the replicas. Each replica maintains a label for each operation it knows about. These labels may be received by gossip, or generated by the replica if no label has been gossiped to it. <p> A more sophisticated approach can involve logical timestamps, such as the multipart timestamps of <ref> [15] </ref>. 10.3 Exploiting Commutativity Assumptions The algorithm of [15] is intended to be used when most of the operations require only causal ordering, but it allows two other types of operations which provide stronger ordering constraints. <p> A more sophisticated approach can involve logical timestamps, such as the multipart timestamps of <ref> [15] </ref>. 10.3 Exploiting Commutativity Assumptions The algorithm of [15] is intended to be used when most of the operations require only causal ordering, but it allows two other types of operations which provide stronger ordering constraints. The ordering constraints on an operation are determined by the application developer, not the client, based on "permissible concurrency". <p> In the abstract algorithm, replicas send gossip messages that include information previously gossiped. If the channels are reliable and FIFO, it is possible to reduce the gossip message sizes by sending only incremental information. The use of timestamps, including logical timestamps such as the multipart timestamps of <ref> [15] </ref>, to summarize sets of operations, as noted above, also reduces the size of messages. Also, the algorithm specifies that each replica sends a separate gossip message to every other replica, resulting in a quadratic number of messages for each "round" of gossip. <p> However, the algorithm allows a replica to send the same gossip message to all other replicas, so an efficient broadcast protocol could greatly reduce the number of messages sent. 3 This condition is still very strong. A weaker variation may be sufficient for the algorithm of <ref> [15] </ref> since updates and queries are handled differently, and operations may not atomically read and write the data. 38 Signature Same as in Figure 7. State Same as in Figure 7.
Reference: [16] <author> L. Lamport. </author> <title> How to make a multiprocessor computer that correctly executes multiprocess programs. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 28(9) </volume> <pages> 690-691, </pages> <month> Sept. </month> <year> 1979. </year>
Reference-contexts: Because achieving atomicity often has a high performance cost, some applications, such as directory services, are willing to tolerate some transient inconsistencies. This gives rise to different notions of consistency. Sequential consistency <ref> [16] </ref>, guaranteed by systems such as Orca [3], allows operations to be reordered as long as they remain consistent with the view of isolated clients. An inherent disparity in the performance of atomic and sequentially consistent objects has been established [2].
Reference: [17] <author> B. Lampson. </author> <title> Desiging a global name service. </title> <booktitle> In Proceedings of the 5th ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 1-10, </pages> <month> Aug. </month> <year> 1986. </year>
Reference-contexts: In a computing enterprise, naming and directory are important basic services used to make distributed resources accessible transparently of the resource locations or their physical addresses. Such services include Grapevine [5], DECdns <ref> [17] </ref>, DCE GDS (Global Directory Service) and CDS (Cell Directory Service) [24], ISO/OSI X.500 [14], and the Internet's DNS (Domain Name System) [13]. A directory service must be robust and it must have good response time for name lookup and translation requests in a geographically distributed setting.
Reference: [18] <author> N. Lynch. </author> <title> Distributed Algorithms. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1996. </year>
Reference-contexts: This data type defines possible states of instantiated objects and operators on the objects. We use a definition similar to the variable types of <ref> [18] </ref>. <p> For a completely formal treatment, we could use a model such as the general timed automaton model <ref> [18, 20] </ref>. For this paper, however, a restricted treatment suffices, and allows us to avoid several technical details. 30 For example, we only consider admissible executions, in which time advances to infinity. 2 Rather than augment the automata with time directly, we annotate executions with the times of each event.
Reference: [19] <author> N. Lynch and F. Vaandrager. </author> <title> Forward and backward simulations Part I: </title> <journal> Untimed systems. Information and Computation, </journal> <volume> 121(2) </volume> <pages> 214-233, </pages> <month> Sept. </month> <year> 1995. </year>
Reference-contexts: by Invariant 7.20, and since TC (CSC (ops ) [ sc) is a strict partial order by Invariant 7.12, (id 0 ; id ) =2 TC (CSC (ops ) [ sc). 8 Simulation To show that ESDS-Alg meets the specification ESDS-II when the clients are well-formed, we establish a simulation <ref> [19] </ref> from A = ESDS-Alg ffi Users to S = ESDS-II ffi Users . We first note that po is a partial order on ops . Invariant 8.1 po is a strict partial order with span (po) ops. Proof: Immediate from the definition and Invariant 7.12.
Reference: [20] <author> N. Lynch and F. Vaandrager. </author> <title> Forward and backward simulations | Part II: </title> <journal> Timing-based systems. Information and Computation, </journal> <volume> 128(1) </volume> <pages> 1-25, </pages> <month> July </month> <year> 1996. </year>
Reference-contexts: For a completely formal treatment, we could use a model such as the general timed automaton model <ref> [18, 20] </ref>. For this paper, however, a restricted treatment suffices, and allows us to avoid several technical details. 30 For example, we only consider admissible executions, in which time advances to infinity. 2 Rather than augment the automata with time directly, we annotate executions with the times of each event.
Reference: [21] <author> N. A. Lynch and M. R. Tuttle. </author> <title> An introduction to Input/Output automata. </title> <journal> CWI-Quarterly, </journal> <volume> 2(3) </volume> <pages> 219-246, </pages> <month> Sept. </month> <year> 1989. </year>
Reference-contexts: fval (x; X; )g for all x 2 X, and valset (y; Y; ) = valset 0 (y; Y X; ) for all y 2 Y X, where 0 = outcome (X; ). 3 Formal model The specifications in this paper are done using a slight simplification of I/O automata <ref> [21] </ref>, ignoring aspects related to liveness. We do not deal with liveness directly in this paper. Instead, we assume bounds on the time to perform actions, and prove performance guarantees that imply liveness under those timing assumptions.
Reference: [22] <institution> Object Management Group, Framingham, MA. Common Object Request Broker Architecture, </institution> <year> 1992. </year>
Reference-contexts: In our implementation this can be accomplished by including the identifier of the name creation operation in the prev sets of the attribute creation and initialization operations. Another application of the data service is in implementing distributed information repositories for coarse-grained distributed object frameworks such as CORBA <ref> [22] </ref>. Important components of a framework is its distributed type system used to define object types, and its module implementation repository used for dynamic object dispatching [25].
Reference: [23] <author> B. Oki and B. Liskov. </author> <title> Viewstamp replication: A new primary copy method to support highly-available distributed systems. </title> <booktitle> In Proceedings of the 7th ACM Symposium on Principles of Distributed Computing, </booktitle> <month> Aug. </month> <year> 1988. </year>
Reference-contexts: The strongest and simplest notion of consistency is atomicity, which requires the replicas to collectively emulate a single centralized object. Methods to achieve atomicity include write-all/read-one [4], primary copy <ref> [1, 26, 23] </ref>, majority consensus [27], and quorum consensus [11, 12]. Because achieving atomicity often has a high performance cost, some applications, such as directory services, are willing to tolerate some transient inconsistencies. This gives rise to different notions of consistency.
Reference: [24] <institution> Open Software Foundation, </institution> <address> Cambridge, MA. </address> <note> Introduction to OSF DCE, </note> <year> 1992. </year>
Reference-contexts: By making all the assumptions and guarantees explicit, the formal framework allows us to reason carefully about the system. Together with the abstract algorithm, the specification can guide the design and implementation of distributed system building blocks layered on general-purpose distributed platforms (middleware) such as DCE <ref> [24] </ref>. In a separate effort, Cheiner has implemented one such building block [6, 7], using the algorithm in this paper as its design specification. As a proof-of-concept, several quite distinct clients that use the building block have been developed. <p> In a computing enterprise, naming and directory are important basic services used to make distributed resources accessible transparently of the resource locations or their physical addresses. Such services include Grapevine [5], DECdns [17], DCE GDS (Global Directory Service) and CDS (Cell Directory Service) <ref> [24] </ref>, ISO/OSI X.500 [14], and the Internet's DNS (Domain Name System) [13]. A directory service must be robust and it must have good response time for name lookup and translation requests in a geographically distributed setting.
Reference: [25] <author> A. Shvartsman and C. Strutt. </author> <title> Distributed object management and generic applications. </title> <institution> Computer Science TR 94-176, Brandeis University, </institution> <year> 1994. </year>
Reference-contexts: Another application of the data service is in implementing distributed information repositories for coarse-grained distributed object frameworks such as CORBA [22]. Important components of a framework is its distributed type system used to define object types, and its module implementation repository used for dynamic object dispatching <ref> [25] </ref>. In this setting the access patterns are again dominated by queries, while infrequent update requests can be propagated lazily with the guarantee of eventual consistency. One future direction may be to specify a such service using our framework.
Reference: [26] <author> M. Stonebraker. </author> <title> Concurrency control and consistency of multiple copies of data in distributed INGRES. </title> <journal> IEEE Transaction on Software Engineering, </journal> <volume> 5(3) </volume> <pages> 188-194, </pages> <month> May </month> <year> 1979. </year>
Reference-contexts: The strongest and simplest notion of consistency is atomicity, which requires the replicas to collectively emulate a single centralized object. Methods to achieve atomicity include write-all/read-one [4], primary copy <ref> [1, 26, 23] </ref>, majority consensus [27], and quorum consensus [11, 12]. Because achieving atomicity often has a high performance cost, some applications, such as directory services, are willing to tolerate some transient inconsistencies. This gives rise to different notions of consistency.
Reference: [27] <author> R. Thomas. </author> <title> A majority consensus approach to concurrency control for multiple copy databases. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 4(2) </volume> <pages> 180-209, </pages> <month> June </month> <year> 1979. </year> <month> 42 </month>
Reference-contexts: The strongest and simplest notion of consistency is atomicity, which requires the replicas to collectively emulate a single centralized object. Methods to achieve atomicity include write-all/read-one [4], primary copy [1, 26, 23], majority consensus <ref> [27] </ref>, and quorum consensus [11, 12]. Because achieving atomicity often has a high performance cost, some applications, such as directory services, are willing to tolerate some transient inconsistencies. This gives rise to different notions of consistency.
References-found: 27

