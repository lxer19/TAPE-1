URL: http://www.cs.arizona.edu/people/debray/papers/wt_dec_tree.ps
Refering-URL: http://www.cs.arizona.edu/jc/
Root-URL: http://www.cs.arizona.edu
Email: fdebray, kannan, mukulg@cs.arizona.edu  
Title: Weighted Decision Trees  
Author: Saumya Debray Sampath Kannan Mukul Paithane 
Address: Tucson, AZ 85721, USA  
Affiliation: Department of Computer Science University of Arizona  
Abstract: While decision tree compilation is a promising way to carry out guard tests efficiently, the methods given in the literature do not take into account either the execution characteristics of the program or the machine-level tradeoffs between different ways to implement branches. These methods therefore offer little or no guidance for the implementor with regard to how decision trees are to be realized on a particular machine. In this paper, we describe an approach that takes execution frequencies of different program branches, as well as the costs of alternative branch realizations, to generate decision trees. Experiments indicate that the performance of our approach is uniformly better than that of plausible alternative schemes. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. B. Ash, </author> <title> Information Theory, </title> <publisher> Dover Publications, </publisher> <address> NY, </address> <year> 1965. </year>
Reference-contexts: The weights only affect the sequencing of tests within each equivalence class. In order to describe our heuristic for ordering the tests within an equivalence class we borrow the notion of entropy (also known as the uncertainty function) from information theory <ref> [1] </ref>: Definition 2.3 Let X be a random variable that takes on a finite number of possible values x 1 ; x 2 ; : : : ; x m with probabilities p 1 ; p 2 ; : : : ; p m , respectively, such that p i &gt; <p> At first glance the choice of this particular function seems somewhat arbitrary, but it can be shown that this is the only function that satisfies some very reasonable axioms on the behaviour of an uncertainty function (see <ref> [1] </ref> for details).
Reference: [2] <author> T. Ball and J. Larus, </author> <title> "Optimally Profiling and Tracing Programs", </title> <booktitle> Proc. 19th. ACM Symp. on Principles of Programming Languages, </booktitle> <address> Albuquerque, NM, </address> <month> Jan. </month> <year> 1992, </year> <pages> pp. 59-70. </pages>
Reference-contexts: This entire discussion is predicated on being able to associate execution frequencies (or, when normalized, estimated execution probabilities) with the clauses defining a procedure. For a discussion of this issue in the context of compilers for traditional languages, see <ref> [2, 9, 10, 18, 19] </ref>; techniques for estimating execution frequencies of logic programs from their call graph structure are discussed in [3, 16].
Reference: [3] <author> S. K. Debray, </author> <title> "A Remark on Tick's Algorithm for Compile-Time Granularity Analysis", </title> <journal> Logic Programming Newsletter vol. </journal> <volume> 3 no. 1, </volume> <month> July </month> <year> 1989. </year>
Reference-contexts: For a discussion of this issue in the context of compilers for traditional languages, see [2, 9, 10, 18, 19]; techniques for estimating execution frequencies of logic programs from their call graph structure are discussed in <ref> [3, 16] </ref>. A point to note is that the techniques described in [3, 16] involve a simple and efficient linear-time traversal of the call graph of the program (i.e., a graph describing the caller-callee relationships between predicates): there is no iterative fixpoint computation of the sort encountered in global dataflow analyses. <p> For a discussion of this issue in the context of compilers for traditional languages, see [2, 9, 10, 18, 19]; techniques for estimating execution frequencies of logic programs from their call graph structure are discussed in <ref> [3, 16] </ref>. A point to note is that the techniques described in [3, 16] involve a simple and efficient linear-time traversal of the call graph of the program (i.e., a graph describing the caller-callee relationships between predicates): there is no iterative fixpoint computation of the sort encountered in global dataflow analyses.
Reference: [4] <author> M. R. Garey and D. S. Johnson, </author> <title> Computers and Intractability: A Guide to the Theory of NP-Completeness, </title> <publisher> Freeman, </publisher> <address> New York, </address> <year> 1979. </year>
Reference-contexts: Our results in this section will apply to arbitrary procedure definitions that are mutually exclusive and exhaustive (note that that the general problem of generating an optimal decision tree where the tests may not be mutually exclusive and exhaustive is NP-Complete <ref> [4] </ref>). We can show that in any procedure definition where the guards are mutually exclusive and exhaustive, there is a single equivalence class such that each guard "cares about" this class.
Reference: [5] <author> M. M. Gorlick and C. F. Kesselman, </author> <title> "Timing Prolog Programs Without Clocks", </title> <booktitle> Proc. Fourth IEEE Symp. Logic Programming, </booktitle> <address> San Francisco, CA, </address> <month> Sept. </month> <year> 1987, </year> <pages> pp. 426-432. </pages> <publisher> IEEE Press. </publisher>
Reference-contexts: Thus, the overhead of estimating execution frequencies using such techniques is small. An alternative is to profile the program on sample inputs to estimate execution frequencies: as the results of Gorlick and Kesselman <ref> [5] </ref> indicate, the overhead for this approach is also small. The primary technical contribution of this paper is to give an algorithm to construct "weighted" decision trees.
Reference: [6] <author> S. Kliger and E. Shapiro, </author> <title> "A Decision Tree Compilation Algorithm for FCP(j; : ; ?)", Proc. </title> <booktitle> Fifth Int. Conf. on Logic Programming, </booktitle> <address> Seattle, </address> <month> Aug. </month> <year> 1988, </year> <pages> pp. 1315-1336. </pages> <publisher> MIT Press. </publisher>
Reference-contexts: An alternative can be selected at runtime only if the corresponding guard tests can be satisfied. For such languages, a compilation technique called decision tree compilation seems quite promising <ref> [6, 7, 8] </ref>. The idea here is to improve program efficiency by structuring the collection of all guard tests for a procedure into a "decision tree", thereby reducing the number of redundant tests executed. <p> The idea here is to improve program efficiency by structuring the collection of all guard tests for a procedure into a "decision tree", thereby reducing the number of redundant tests executed. Algorithms for decision tree compilation have been given by Kliger and Shapiro <ref> [6, 7] </ref> and Korsloot and Tick [8]. The algorithms given by the authors cited above are concerned primarily with generating a decision tree for a set of tests by choosing an order in which the tests should be executed. <p> As far as we can tell, earlier approaches, e.g., those of Kliger and Shapiro <ref> [6, 7] </ref>, generate decision trees that consider suspension in otherwise branches, which appear to be considered at the end if none of the non-otherwise branches is taken, and therefore do not offer this flexibility. 2 3.3 The Non-Mutually Exclusive Case In this case, at any point there is a set of
Reference: [7] <author> S. Kliger and E. Shapiro, </author> <title> "From Decision Trees to Decision Graphs", </title> <booktitle> Proc. </booktitle> <address> NACLP-90, Austin, </address> <month> Oct. </month> <year> 1990, </year> <pages> pp. 97-116. </pages> <publisher> MIT Press. </publisher>
Reference-contexts: An alternative can be selected at runtime only if the corresponding guard tests can be satisfied. For such languages, a compilation technique called decision tree compilation seems quite promising <ref> [6, 7, 8] </ref>. The idea here is to improve program efficiency by structuring the collection of all guard tests for a procedure into a "decision tree", thereby reducing the number of redundant tests executed. <p> The idea here is to improve program efficiency by structuring the collection of all guard tests for a procedure into a "decision tree", thereby reducing the number of redundant tests executed. Algorithms for decision tree compilation have been given by Kliger and Shapiro <ref> [6, 7] </ref> and Korsloot and Tick [8]. The algorithms given by the authors cited above are concerned primarily with generating a decision tree for a set of tests by choosing an order in which the tests should be executed. <p> Example 2.1 Consider the following clause: p (X, Y) :- X &lt; 0, X &gt; Y | ... Previous authors have considered the notion of a clause "caring" about a test (e.g., see <ref> [7] </ref>): a clause C cares about a test g if there is a test g 0 in the guard of C such that exactly one of the tests g 0 ^ g, g 0 ^ :g is satisfiable. <p> As far as we can tell, earlier approaches, e.g., those of Kliger and Shapiro <ref> [6, 7] </ref>, generate decision trees that consider suspension in otherwise branches, which appear to be considered at the end if none of the non-otherwise branches is taken, and therefore do not offer this flexibility. 2 3.3 The Non-Mutually Exclusive Case In this case, at any point there is a set of
Reference: [8] <author> M. Korsloot and E. Tick, </author> <title> "Compilation Techniques for Nondeterminate Flat Concurrent Logic Programming Languages", </title> <booktitle> Proc. Eighth Int. Conf. on Logic Programming, </booktitle> <address> Paris, </address> <month> June </month> <year> 1991, </year> <pages> pp. 457-471. </pages> <publisher> MIT Press. </publisher>
Reference-contexts: An alternative can be selected at runtime only if the corresponding guard tests can be satisfied. For such languages, a compilation technique called decision tree compilation seems quite promising <ref> [6, 7, 8] </ref>. The idea here is to improve program efficiency by structuring the collection of all guard tests for a procedure into a "decision tree", thereby reducing the number of redundant tests executed. <p> The idea here is to improve program efficiency by structuring the collection of all guard tests for a procedure into a "decision tree", thereby reducing the number of redundant tests executed. Algorithms for decision tree compilation have been given by Kliger and Shapiro [6, 7] and Korsloot and Tick <ref> [8] </ref>. The algorithms given by the authors cited above are concerned primarily with generating a decision tree for a set of tests by choosing an order in which the tests should be executed.
Reference: [9] <author> S. McFarling, </author> <title> "Program Optimization for Instruction Caches", </title> <booktitle> Proc. Third Int. Symp. on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pp. 183-191. </pages>
Reference-contexts: This entire discussion is predicated on being able to associate execution frequencies (or, when normalized, estimated execution probabilities) with the clauses defining a procedure. For a discussion of this issue in the context of compilers for traditional languages, see <ref> [2, 9, 10, 18, 19] </ref>; techniques for estimating execution frequencies of logic programs from their call graph structure are discussed in [3, 16].
Reference: [10] <author> K. Pettis and R. C. Hansen, </author> <title> "Profile Guided Code Positioning", </title> <booktitle> Proc. SIGPLAN-90 Conf. on Programming Language Design and Implementation, </booktitle> <address> White Plains, NY, </address> <month> June </month> <year> 1990, </year> <pages> pp. 16-27. </pages>
Reference-contexts: This entire discussion is predicated on being able to associate execution frequencies (or, when normalized, estimated execution probabilities) with the clauses defining a procedure. For a discussion of this issue in the context of compilers for traditional languages, see <ref> [2, 9, 10, 18, 19] </ref>; techniques for estimating execution frequencies of logic programs from their call graph structure are discussed in [3, 16].
Reference: [11] <author> M. L. Powell, </author> <title> "A Portable Optimizing Compiler for Modula-2", </title> <booktitle> Proc. SIGPLAN-84 Symp. on Compiler Construction, </booktitle> <address> Montreal, </address> <month> June </month> <year> 1984, </year> <pages> pp. </pages> <month> 310-318. </month> <journal> SIGPLAN Notices vol. </journal> <volume> 19 no. </volume> <pages> 6. </pages>
Reference: [12] <author> V. Saraswat, K. Kahn, and J. Levy, </author> <title> "Janus: A step towards distributed constraint programming", </title> <booktitle> in Proc. 1990 North American Conf. on Logic Programming, </booktitle> <address> Austin, TX, </address> <month> Oct. </month> <year> 1990, </year> <pages> pp. 431-446. </pages> <publisher> MIT Press. </publisher>
Reference-contexts: 1 Introduction There has been a great deal of research, in recent years, on the design and implementation of concurrent logic and constraint programming languages (see, for example, <ref> [12, 13, 14, 15, 17] </ref>). Much of the implementation effort in this context has focussed on the so-called "flat" versions of these languages: here, a procedure definition consists of alternatives, each alternative preceded by a guard that consists of a set of ask actions or primitive tests.
Reference: [13] <author> E. Shapiro, </author> <title> "The Family of Concurrent Logic Programming Languages", </title> <journal> Computing Surveys, </journal> <volume> vol. 21 no. 3, </volume> <month> Sept. </month> <year> 1989, </year> <pages> pp. 412-510. </pages>
Reference-contexts: 1 Introduction There has been a great deal of research, in recent years, on the design and implementation of concurrent logic and constraint programming languages (see, for example, <ref> [12, 13, 14, 15, 17] </ref>). Much of the implementation effort in this context has focussed on the so-called "flat" versions of these languages: here, a procedure definition consists of alternatives, each alternative preceded by a guard that consists of a set of ask actions or primitive tests.
Reference: [14] <author> E. Shapiro (ed.), </author> <title> Concurrent Prolog: Collected Papers, </title> <publisher> MIT Press, </publisher> <year> 1987. </year>
Reference-contexts: 1 Introduction There has been a great deal of research, in recent years, on the design and implementation of concurrent logic and constraint programming languages (see, for example, <ref> [12, 13, 14, 15, 17] </ref>). Much of the implementation effort in this context has focussed on the so-called "flat" versions of these languages: here, a procedure definition consists of alternatives, each alternative preceded by a guard that consists of a set of ask actions or primitive tests.
Reference: [15] <author> S. Taylor, </author> <title> Parallel Logic Programming Techniques, </title> <publisher> Prentice Hall, </publisher> <year> 1989. </year>
Reference-contexts: 1 Introduction There has been a great deal of research, in recent years, on the design and implementation of concurrent logic and constraint programming languages (see, for example, <ref> [12, 13, 14, 15, 17] </ref>). Much of the implementation effort in this context has focussed on the so-called "flat" versions of these languages: here, a procedure definition consists of alternatives, each alternative preceded by a guard that consists of a set of ask actions or primitive tests.
Reference: [16] <author> E. Tick, </author> <title> "Compile-time Granularity Analysis for Parallel Logic Programming Languages", </title> <booktitle> Proc. Int. Conf. on Fifth Generation Computer Systems, </booktitle> <address> Tokyo, Japan, </address> <month> Nov. </month> <year> 1988, </year> <pages> pp. 994-1000. </pages>
Reference-contexts: For a discussion of this issue in the context of compilers for traditional languages, see [2, 9, 10, 18, 19]; techniques for estimating execution frequencies of logic programs from their call graph structure are discussed in <ref> [3, 16] </ref>. A point to note is that the techniques described in [3, 16] involve a simple and efficient linear-time traversal of the call graph of the program (i.e., a graph describing the caller-callee relationships between predicates): there is no iterative fixpoint computation of the sort encountered in global dataflow analyses. <p> For a discussion of this issue in the context of compilers for traditional languages, see [2, 9, 10, 18, 19]; techniques for estimating execution frequencies of logic programs from their call graph structure are discussed in <ref> [3, 16] </ref>. A point to note is that the techniques described in [3, 16] involve a simple and efficient linear-time traversal of the call graph of the program (i.e., a graph describing the caller-callee relationships between predicates): there is no iterative fixpoint computation of the sort encountered in global dataflow analyses.
Reference: [17] <author> K. Ueda, </author> <title> "Guarded Horn Clauses", in Concurrent Prolog: </title> <booktitle> Collected Papers, </booktitle> <volume> vol. 1, </volume> <editor> ed. E. </editor> <booktitle> Shapiro, </booktitle> <pages> pp. 140-156, </pages> <address> 1987. </address> <publisher> MIT Press. </publisher>
Reference-contexts: 1 Introduction There has been a great deal of research, in recent years, on the design and implementation of concurrent logic and constraint programming languages (see, for example, <ref> [12, 13, 14, 15, 17] </ref>). Much of the implementation effort in this context has focussed on the so-called "flat" versions of these languages: here, a procedure definition consists of alternatives, each alternative preceded by a guard that consists of a set of ask actions or primitive tests.
Reference: [18] <author> D. W. Wall, </author> <title> "Global Register Allocation at Link-time", </title> <booktitle> Proc. SIGPLAN-86 Conf. on Compiler Construction, </booktitle> <month> June </month> <year> 1986, </year> <pages> pp. 264-275. </pages>
Reference-contexts: This entire discussion is predicated on being able to associate execution frequencies (or, when normalized, estimated execution probabilities) with the clauses defining a procedure. For a discussion of this issue in the context of compilers for traditional languages, see <ref> [2, 9, 10, 18, 19] </ref>; techniques for estimating execution frequencies of logic programs from their call graph structure are discussed in [3, 16].
Reference: [19] <author> D. W. Wall, </author> <title> "Predicting Program Behavior Using Real or Estimated Profiles", </title> <booktitle> Proc. SIGPLAN-91 Conf. on Programming Language Design and Implementation, </booktitle> <month> June </month> <year> 1991, </year> <pages> pp. 59-70. </pages>
Reference-contexts: This entire discussion is predicated on being able to associate execution frequencies (or, when normalized, estimated execution probabilities) with the clauses defining a procedure. For a discussion of this issue in the context of compilers for traditional languages, see <ref> [2, 9, 10, 18, 19] </ref>; techniques for estimating execution frequencies of logic programs from their call graph structure are discussed in [3, 16].
References-found: 19

