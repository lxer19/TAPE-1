URL: http://www.cs.brandeis.edu/~mairson/Papers/icfp96.ps.gz
Refering-URL: http://www.cs.brandeis.edu/~mairson/
Root-URL: http://www.cs.brandeis.edu
Title: Optimality and inefficiency what isn't a cost model of the lambda calculus?  
Author: Julia L. Lawall Harry G. Mairson 
Address: 35042 Rennes Cedex France  Waltham, Massachusetts 02254  
Affiliation: IRISA Campus Universitaire de Beaulieu  Computer Science Department Brandeis University  
Abstract: We investigate the computational efficiency of the sharing graphs of Lamping [Lam90], Gonthier, Abadi, and Levy [GAL92], and Asperti [Asp94], designed to effect so-called optimal evaluation, with the goal of reconciling optimality, efficiency, and the clarification of reasonable cost models for the -calculus. Do these graphs suggest reasonable cost models for the -calculus? If they are optimal, are they efficient? We present a brief survey of these optimal evaluators, identifying their common characteristics, as well as their shared failures. We give a lower bound on the efficiency of sharing graphs by identifying a class of -terms that are normalizable in fi(n) time, and require fi(n) "fan interactions," but require (2 n ) bookkeeping steps. For [GAL92], we analyze this anomaly in terms of the dynamic maintenance of deBruijn indices for intermediate terms. We give another lower bound showing that sharing graphs can do (2 n ) work (via fan interactions) on graphs that have no fi-redexes. Finally, we criticize a proposed cost model for -calculus given by Frandsen and Sturtivant [FS91], showing by example that the model does not take account of the size of intermediate forms. Our example is a term requiring fi(2 n ) steps while having proposed cost fi(n). We propose some cost models that both reflect this parameter, and simultaneously reconcile key concepts from optimal reduction. 
Abstract-found: 1
Intro-found: 1
Reference: [Asp94] <author> Andrea Asperti. </author> <title> Linear logic, comonads, and optimal reductions. </title> <type> Unpublished manuscript. </type>
Reference-contexts: It was an open question for some fifteen years whether optimal reduction strategies exist, answered affirmatively by Lamping [Lam90], Kathail [Kat90], and in a simplified way by Gonthier, Abadi, and Levy [GAL92] (henceforth, GAL), as well as Asperti <ref> [Asp94] </ref>. The solution of GAL was appealing because it also gave a static semantics to -calculus in the spirit of Girard's geometry of interaction [Gir88]; this semantics has also been recently investigated as an implementation technique by Mackie [Mac95]. <p> Since no redex is ever duplicated, Lamping's evaluator is thus efficient in the number of fi-reductions and safe, or optimal. The algorithmic variations on his fundamental observation (e.g, <ref> [GAL92, Asp94] </ref>) consist of alternative low-level implementations of his sharing nodes.
Reference: [Asp95] <author> Andrea Asperti. </author> <title> ffiffi!* = 1: optimizing optimal -calculus implementations. </title> <booktitle> Proceedings, </booktitle> <address> RTA, </address> <year> 1995. </year>
Reference-contexts: Because x:y:xy contains no sharing nodes, the bookkeeping nodes serve no purpose. Asperti and Lamping have each proposed rules to eliminate these nodes. While their approaches improve performance for x:y:xy, they do not eliminate the problem of excess duplication in general. 4.1 Asperti Asperti <ref> [Asp95] </ref> observed, by way of category theory, that we can replace a croissant atop a bracket by a single wire, when we can guarantee that neither the bracket nor the croissant ever annihilate with any node in the graph. Such brackets and croissants are called safe.
Reference: [Asp96] <author> Andrea Asperti. </author> <title> On the complexity of beta--reduction. </title> <booktitle> 1996 ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pp. 110-118. </pages>
Reference-contexts: The essence of these analyses is the identification of a class of terms that require fi (2 n ) fan interactions to reduce the corresponding term to normal form, while requiring only fi (n) parallel fi-steps. A very similar result was recently and independently derived by Asperti <ref> [Asp96] </ref> in his analysis of the inherent complexity of fi-reduction. * We observe that normal order evaluation is an acceptable machine model in the sense of the orthodox Invariance Thesis. Thus the debate over cost models is largely fine structure, or the thesis is too crude. <p> Theorem 2. Optimal evaluators allow (2 n ) useless fan interactions where there are no fi-redexes to reduce. Asperti has suggested that we avoid this anomaly by considering only terms that normalize to constants <ref> [Asp96] </ref>. In this case, all functions are used, and all applications become redexes. <p> Theorem 5. If -(E) is the Frandsen-Sturtivant cost metric for evaluating a -term E, then the number of fan in teractions required by existing optimal evaluators grows as (2 -(E) ). This result was derived independently by Asperti <ref> [Asp96] </ref>, using a more complicated term having similar consequences. The reduction of E to normal form also answers a conjecture posed by Frandsen and Sturtivant [FS91]. In their paper, they identify a family of terms requiring at least 5n fi-steps to normalize, but only n parallel fi-steps. <p> By contrast, the work of brackets and croissants seems more bureaucratic. 5.2 Cost models based on fan interaction In his recent paper, Asperti has proposed a cost metric where the intrinsic complexity of a -term is the number of fan interactions incurred in the normalization of the term <ref> [Asp96] </ref>. "Intuitively," he writes, "Lamping's abstract algorithm does not seem to perform any useless operation." We comment briefly on this proposal. First, it seems undesirable to base the inherent difficulty of reducing a term on an implementation.
Reference: [Bar84] <author> Hendrik Barendregt. </author> <title> The Lambda Calculus: Its Syntax and Semantics. </title> <publisher> North Holland, </publisher> <year> 1984. </year>
Reference: [vEB90] <author> Peter van Emde Boas. </author> <title> Machine models and simulation. </title> <booktitle> Handbook of Theoretical Computer Science, volume A, </booktitle> <pages> pp. 1-66. </pages> <publisher> North Holland, </publisher> <year> 1990. </year>
Reference-contexts: Machine models: Compiler and interpreter technology relate the "two cultures" of machines and languages at a theoretical level as well as at a practical one. There is a substantial theory literature on machine simulations (see, e.g., the survey paper <ref> [vEB90] </ref>), founded on the In-variance Thesis, the modern-day version of Church's Thesis: "Reasonable" universal machines can simulate each other within a polynomially-bounded overhead in time and a constant-factor overhead in space. <p> Taste and aesthetics govern choice of a model, with a "sanity check" given by the Invariance Thesis: "Reasonable" universal machines can simulate each other within a polynomially-bounded overhead in time and a constant-factor overhead in space <ref> [vEB90] </ref>.
Reference: [Chu41] <author> Alonzo Church. </author> <title> The Calculi of Lambda-conversion. </title> <publisher> Princeton University Press, </publisher> <year> 1941. </year>
Reference: [Fie90] <author> John Field. </author> <title> On laziness and optimality in lambda interpreters: tools for specification and analysis. </title> <booktitle> 1990 ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pp. 1-15. </pages>
Reference-contexts: proposal is to be taken seriously, it implies that this concept of boundary is not essential. 5.3 Cost models based on labelled -calculus A more realistic, implementation independent cost model is immediately suggested by the (Levy)-labelled -calculus, of which there are many flavors: we have relied on the version in <ref> [Fie90] </ref>. Briefly, each subterm of the initial -term is initially annotated with a unique label. As reduction occurs, labels are concatenated according to certain rules, so that the labels encode the history of the computation.
Reference: [FS91] <author> Gudmund S. Frandsen and Carl Sturtivant. </author> <title> What is an efficient implementation of the -calculus? 1991 ACM Conference on Functional Programming and Computer Architecture (J. Hughes, </title> <publisher> ed.), </publisher> <pages> pp. 289-312. </pages>
Reference-contexts: How efficient are optimal evaluators|do they simulate machine models well? What are the relevant cost models? More generally, can we speak of the complexity of a functional program in a machine-independent way? These kinds of questions were asked in a provocative paper by Frandsen and Sturtivant <ref> [FS91] </ref>, who proposed various implementation-independent cost models for the -calculus, and showed that several well-known implementation techniques (Turner combinators [Tur79], Hughes supercombinators [Hug82]) are too inefficient to satisfy these cost models. They leave as an open question whether their cost models, while conscientiously justified, are indeed attainable. <p> This paper continues their work by analyzing optimal evaluators in the same vein. We discover that optimal reduction fails to be efficient in the sense of Frandsen and Sturtivant, even though their cost models are based on the idea of parallel reduction, borrowed from the optimal evaluation literature. While <ref> [FS91] </ref> implicitly endorses parallel reduction as a good idea with respect to efficiency, it does not analyze whether any additional computation (for example, bookkeeping to facilitate parallel reductions) is computationally prohibitive. <p> Turing machine can be simulated efficiently, using your favorite coding|<ref> [FS91] </ref> essentially gives one; [HM94] gives another. The explanation of the efficiency of the simulation is simple: the simulation does not depend in any profound way on sharing. In an attempt to define a more parsimonious cost model, Frandsen and Sturtivant [FS91] proposed the following: the cost of a reduction to normal form is the length of the the initial and final term, plus the number of parallel fi-steps. They point out that several standard combinator-based implementations (e.g., [Tur79, Hug82]) require time exponential in the cost model. <p> This result was derived independently by Asperti [Asp96], using a more complicated term having similar consequences. The reduction of E to normal form also answers a conjecture posed by Frandsen and Sturtivant <ref> [FS91] </ref>. In their paper, they identify a family of terms requiring at least 5n fi-steps to normalize, but only n parallel fi-steps. They conjectured that the ratio of ordinary to parallel fi-steps could be exponential. The reduction of E shows that the ratio can in fact be doubly exponential. <p> Not only are efficiency improvements needed for optimal reduction at the bureaucratic level, we also need a more realistic cost model. The lesson of this example is very clear: the model of <ref> [FS91] </ref> does not take into account the size of intermediate terms. Furthermore, we consider the work of the sharing nodes, even if their work is independent from fi-reduction, to be essential.
Reference: [Gir88] <author> Jean-Yves Girard. </author> <title> Geometry of interaction I: interpretation of System F. </title> <booktitle> Logic Colloquim 1988, </booktitle> <pages> pp. 221-260. </pages> <publisher> Elsevier (North Holland), </publisher> <year> 1989. </year>
Reference-contexts: The solution of GAL was appealing because it also gave a static semantics to -calculus in the spirit of Girard's geometry of interaction <ref> [Gir88] </ref>; this semantics has also been recently investigated as an implementation technique by Mackie [Mac95]. All these solutions are contributions to compiler technology since they are just rarefied forms of graph reduction.
Reference: [GAL92] <author> Georges Gonthier, Martin Abadi, and Jean-Jacques Levy. </author> <title> The geometry of optimal lambda reduction. </title> <booktitle> 1992 ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pp. 15-26. </pages>
Reference-contexts: It was an open question for some fifteen years whether optimal reduction strategies exist, answered affirmatively by Lamping [Lam90], Kathail [Kat90], and in a simplified way by Gonthier, Abadi, and Levy <ref> [GAL92] </ref> (henceforth, GAL), as well as Asperti [Asp94]. The solution of GAL was appealing because it also gave a static semantics to -calculus in the spirit of Girard's geometry of interaction [Gir88]; this semantics has also been recently investigated as an implementation technique by Mackie [Mac95]. <p> Because a lot of this literature is technical, we also provide a gentle introduction to optimal reduction that we hope is digestible to the general reader. While <ref> [GAL92] </ref> parodied Lamping as "TV Digest," we found their presentation, however brilliant, an impenetrable synthesis of the traditions of Bourbaki and Hunter Thompson. <p> Since no redex is ever duplicated, Lamping's evaluator is thus efficient in the number of fi-reductions and safe, or optimal. The algorithmic variations on his fundamental observation (e.g, <ref> [GAL92, Asp94] </ref>) consist of alternative low-level implementations of his sharing nodes. <p> The pair of nodes serves as a kind of switch, where setting both to "left" gives F (M ), and setting both "right" gives F (N ). The context semantics given in <ref> [GAL92] </ref> is an elaborate mechanism for iteratively setting these switches. 1 We annotate -nodes with the name of the bound variable for clarity. 1 2 3 4 5 Next, we consider the interaction of fan nodes (p) and (q) above.
Reference: [Gue95] <author> Stefano Guerrini. Sharing-graphs, sharing-morphisms, </author> <title> and (optimal) -graph reductions (draft). </title> <type> Unpublished manuscript. </type> <month> June 16, </month> <year> 1995. </year>
Reference-contexts: Thus Theorem 3. GAL, Lamping, and Asperti, with and without optimization, take (2 n ) bookkeeping to effect n parallel fi-steps. 4.5 Guerrini Guerrini <ref> [Gue95] </ref> shows how Asperti's stacks of brackets and croissants can be represented as integers. Rather than cancelling croissants against brackets, he shows that at the bound variable port of a lambda node it is safe to combine these integers using addition.
Reference: [Hug82] <author> John Hughes. Supercombinators: </author> <title> a new implementation method for applicative languages. </title> <booktitle> 1982 ACM Symposium on Lisp and Functional Programming, </booktitle> <pages> pp. 1-10. </pages>
Reference-contexts: can we speak of the complexity of a functional program in a machine-independent way? These kinds of questions were asked in a provocative paper by Frandsen and Sturtivant [FS91], who proposed various implementation-independent cost models for the -calculus, and showed that several well-known implementation techniques (Turner combinators [Tur79], Hughes supercombinators <ref> [Hug82] </ref>) are too inefficient to satisfy these cost models. They leave as an open question whether their cost models, while conscientiously justified, are indeed attainable. This paper continues their work by analyzing optimal evaluators in the same vein. <p> They point out that several standard combinator-based implementations (e.g., <ref> [Tur79, Hug82] </ref>) require time exponential in the cost model.
Reference: [Kat90] <author> Vinod Kathail. </author> <title> Optimal interpreters for lambda-calculus based functional languages. </title> <type> Ph.D. Thesis, </type> <institution> MIT, </institution> <month> May </month> <year> 1990. </year>
Reference-contexts: But how efficient is optimal reduction? To understand its efficiency, we also need to consider reasonable cost models for -calculus. It was an open question for some fifteen years whether optimal reduction strategies exist, answered affirmatively by Lamping [Lam90], Kathail <ref> [Kat90] </ref>, and in a simplified way by Gonthier, Abadi, and Levy [GAL92] (henceforth, GAL), as well as Asperti [Asp94].
Reference: [Lam90] <author> John Lamping. </author> <title> An algorithm for optimal lambda calculus reduction. </title> <booktitle> 1990 ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pp. 16-30. </pages>
Reference-contexts: But how efficient is optimal reduction? To understand its efficiency, we also need to consider reasonable cost models for -calculus. It was an open question for some fifteen years whether optimal reduction strategies exist, answered affirmatively by Lamping <ref> [Lam90] </ref>, Kathail [Kat90], and in a simplified way by Gonthier, Abadi, and Levy [GAL92] (henceforth, GAL), as well as Asperti [Asp94]. <p> When a -abstraction is applied, a new copy of its body is instantiated with the argument. This copying may be excessive, since other computations in the -body not depending on the argument could still be shared. Lamping <ref> [Lam90] </ref> had the great idea of economizing via partial sharing of the body. In other words, instead of copying the whole body, just copy the -node at the top of the graph representing the function, and continue to share the body of the function. <p> If these optimization rules are applied whenever possible, this system can reduce C n (id) in fi (n) steps, where id is any -expansion of x:x. 4.2 Lamping Although Lamping's algorithm <ref> [Lam90] </ref> preceeded both GAL and Asperti, it can be seen as a variant of GAL with Asperti's optimization rules built in. Like GAL, Lamping uses brackets to mark free-variable ports, and croissants to cancel free-variable brackets when a abstraction is applied.
Reference: [Levy78] <author> Jean-Jacques Levy. </author> <title> Reductions correctes et opti-males dans le lambda-calcul. </title> <address> These d'Etat, Uni-versite Paris 7, </address> <year> 1978. </year>
Reference-contexts: From this fundamental division one sees the algorithmic focus on machines, as well as the semantic focus on languages. Optimal evaluation: Optimal reduction <ref> [Levy78, Levy80] </ref>, the idea of evaluating programs "correctly" (producing a normal form if there is one) while not "duplicating work," attempted to simultaneously achieve the goals of computational efficiency and semantic clarity. These goals sit squarely between the two cultures of algorithmics and semantics.
Reference: [Levy80] <author> Jean-Jacques Levy. </author> <title> Optimal reductions in the lambda-calculus. To H. B. Curry: Essays in Combinatory Logic, Lambda Calculus and Formalism, </title> <editor> (Jonathan P. Seldin and J. Roger Hindley, </editor> <booktitle> editors), </booktitle> <pages> pp. 159-191. </pages> <publisher> Academic Press, </publisher> <year> 1980. </year>
Reference-contexts: From this fundamental division one sees the algorithmic focus on machines, as well as the semantic focus on languages. Optimal evaluation: Optimal reduction <ref> [Levy78, Levy80] </ref>, the idea of evaluating programs "correctly" (producing a normal form if there is one) while not "duplicating work," attempted to simultaneously achieve the goals of computational efficiency and semantic clarity. These goals sit squarely between the two cultures of algorithmics and semantics.
Reference: [HM94] <author> Harry G. Mairson and Fritz Henglein. </author> <title> The complexity of type inference for higher-order typed lambda calculi. </title> <journal> Journal of Functional Programming 4:4 (October 1994), </journal> <pages> pp. 435-478. </pages>
Reference-contexts: This metric can be realized (with polynomial slowdown for time, and constant expansion for space) on a Turing machine. More surprisingly, an arbitrary Turing machine can be simulated efficiently, using your favorite coding|[FS91] essentially gives one; <ref> [HM94] </ref> gives another. The explanation of the efficiency of the simulation is simple: the simulation does not depend in any profound way on sharing.
Reference: [Mac95] <author> Ian Mackie. </author> <title> The geometry of interaction machine. </title> <booktitle> 1995 ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pp. 198-208. </pages>
Reference-contexts: The solution of GAL was appealing because it also gave a static semantics to -calculus in the spirit of Girard's geometry of interaction [Gir88]; this semantics has also been recently investigated as an implementation technique by Mackie <ref> [Mac95] </ref>. All these solutions are contributions to compiler technology since they are just rarefied forms of graph reduction. In this paper, we compare and analyze the computational features of proposed optimal evaluators, explaining what design features are common, and what computational resources are required to realize these design features.
Reference: [PJ87] <editor> Simon Peyton-Jones. </editor> <booktitle> The Implementation of Functional Programming Languages. </booktitle> <publisher> Prentice-Hall, </publisher> <year> 1987. </year>
Reference-contexts: When the value of an expression is multiply used, efficiency requires that it not be evaluated more than once. When the value of an expression is never used, safety requires that it not be evaluated. Graph reduction (see, e.g., <ref> [PJ87] </ref>), used to implement lazy functional languages, compromises between these two goals: fi-reduction binds all occurrences of the parameter to a single shared graph representing the argument. When the value of some occurrence of the parameter is requested, the argument is evaluated.
Reference: [Tur79] <author> David A. Turner. </author> <title> New implementation techniques for applicative languages. </title> <booktitle> Software Practice and Experience 9 (1979), </booktitle> <pages> pp. 31-49. </pages>
Reference-contexts: models? More generally, can we speak of the complexity of a functional program in a machine-independent way? These kinds of questions were asked in a provocative paper by Frandsen and Sturtivant [FS91], who proposed various implementation-independent cost models for the -calculus, and showed that several well-known implementation techniques (Turner combinators <ref> [Tur79] </ref>, Hughes supercombinators [Hug82]) are too inefficient to satisfy these cost models. They leave as an open question whether their cost models, while conscientiously justified, are indeed attainable. This paper continues their work by analyzing optimal evaluators in the same vein. <p> They point out that several standard combinator-based implementations (e.g., <ref> [Tur79, Hug82] </ref>) require time exponential in the cost model.
References-found: 20

