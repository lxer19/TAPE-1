URL: http://renoir.csc.ncsu.edu/Faculty/Vouk/Papers/Cascon93.ps
Refering-URL: http://renoir.csc.ncsu.edu/Faculty/Vouk/vouk.se.html
Root-URL: http://www.csc.ncsu.edu
Title: Some Issues in Multi-Phase Software Reliability Modeling  
Author: M. A. Vouk and K.C. Tai 
Date: 1993  
Note: Vouk and Tai 513 Proc. CASCON 93, Toronto,  
Abstract:  
Abstract-found: 1
Intro-found: 1
Reference: [Boe89] <author> B.W. Boehm, </author> <title> Tutorial: Software Risk Management, </title> <publisher> IEEE CS Press, </publisher> <year> 1989. </year>
Reference-contexts: Several approaches have been proposed [Kho90, Mun92, Bri93]. Highly correlated nature of the early software verification and testing events may require the use of a more sophisticated, timeseries, approach [Sin92]. We illustrate some of the issues through a risk model <ref> [Ehr85, Boe89] </ref>. 3.1 Process States At the end of a nonoperational testing phase an indication of the state of the software may be available as a set of conditions. In the most general form, the conditions will be compound, and will reflect the evolution process and history of software. <p> estimation should be given as an interval rather than as a point estimate (for example, upper and lower 95% confidence bounds). 3.2 Simple Model We define risk as the probability that an undesirable event takes place and causes an operational loss, multiplied by the magnitude of the loss it causes <ref> [Ehr85, Boe89] </ref>. We consider the risk given that we know what the current state of software is. Let the undesirable event be the problem-proneness of the software in the field due to one or more categories of faults (for example, the event is transition to state S f described earlier).
Reference: [Bri93] <author> L.C. Briand, W.M. Thomas and C.J. Hetsmanski, </author> <title> "Modeling and Managing Risk Early in Software Development," </title> <booktitle> Proc. 15th ICSE, </booktitle> <pages> pp 55-65, </pages> <year> 1993. </year>
Reference-contexts: Several authors have published models that attempt to relate some early software metrics, such as, the size of the code, Halstead length, or cyclomatic number, to the failure proneness of the program <ref> [Mun92, Bri93] </ref>. <p> Risk Modeling This section addresses the use of early testing information in identification of components that may be problem-prone in the field. Several approaches have been proposed <ref> [Kho90, Mun92, Bri93] </ref>. Highly correlated nature of the early software verification and testing events may require the use of a more sophisticated, timeseries, approach [Sin92].
Reference: [Bro92] <author> S. Brocklehurst and B. Littlewood, </author> <title> "New Ways to Get Accurate Reliability Measures," </title> <journal> IEEE Software, </journal> <pages> pp. 34-42, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: The formulation of software Vouk and Tai 520 Proc. CASCON 93, Toronto, 1993 reliability models, the estimation of their parameters, and the accuracy of their predictions are somewhat controversial issues <ref> [Bro92] </ref>. Common estimation procedures include maximum likelihood, least-squares and Bayesian approaches [Mus87]. However, the highly correlated nature of the early testing process may require the use of advanced "time-series" analyses to evaluate the reliability growth.
Reference: [Chr90] <author> D.A. Christenson, S.T. Huang, and A.J. Lamperez, </author> <title> "Statistical Quality Control Applied to Code Inspections," </title> <journal> IEEE J. on Selected Areas in Communications, </journal> <volume> Vol. 8 (2), </volume> <pages> pp. 196-200, </pages> <year> 1990. </year>
Reference-contexts: They indicate the conditions that have been met during the verification and testing process. Some of the metrics derive from the past, some from the current, and some from the expected future phases. For example, M 3 may be "Coding Inspection Effort Intensity" <ref> [Chr90] </ref>, M 2 may be the current "Testing Effort Coverage", and M 1 may be the "Call Usage". Of course other drivers should also be considered.
Reference: [Cra92] <author> Cramp R., Vouk M.A., and Jones W., </author> <title> "On Operational Availability of a Large Software-Based Telecommunications System," </title> <booktitle> Proc. Third Intl. Symposium on Software Reliability Engineering, IEEE CS, </booktitle> <pages> pp. 358-366, </pages> <year> 1992. </year>
Reference-contexts: For example, we distinguish time-oriented failure-intensity (that is, failures per unit time), and test-case intensity (that is, number of failures per test case). In the case of operational testing, an excellent exposure metric is the CPU execution time <ref> [Mus87, Jon91, Cra92] </ref>, but this may not be the case in a nonoperational testing environment.
Reference: [EhP93] <author> W. Ehrlich, B. Prasanna, J. Stampfel, J. Wu, </author> <title> "Determining the Cost of A stop-Test Decision," </title> <journal> IEEE Software, </journal> <volume> Vol. 10 (2), </volume> <pages> pp. 33-42, </pages> <month> March </month> <year> 1993 </year>
Reference-contexts: Software Process Control Advanced software reliability engineering requires active guidance of the testing process based on the quality growth. Many different reliability indicators can be used to establish test stopping criteria, and guide the testing strategy <ref> [Dal90, EhP93] </ref>. But, many available reliability models are not well suited for evaluation of systems under test with other than their operational profiles. The formulation of software Vouk and Tai 520 Proc.
Reference: [Ehr85] <author> W. Ehrenberger, </author> <title> "Statistical Testing of Real Time Software," in Verification and Validation of Real-Time Software, </title> <editor> ed. W.J. Quirk, </editor> <publisher> Springer-Verlag, </publisher> <year> 1985. </year>
Reference-contexts: Several approaches have been proposed [Kho90, Mun92, Bri93]. Highly correlated nature of the early software verification and testing events may require the use of a more sophisticated, timeseries, approach [Sin92]. We illustrate some of the issues through a risk model <ref> [Ehr85, Boe89] </ref>. 3.1 Process States At the end of a nonoperational testing phase an indication of the state of the software may be available as a set of conditions. In the most general form, the conditions will be compound, and will reflect the evolution process and history of software. <p> estimation should be given as an interval rather than as a point estimate (for example, upper and lower 95% confidence bounds). 3.2 Simple Model We define risk as the probability that an undesirable event takes place and causes an operational loss, multiplied by the magnitude of the loss it causes <ref> [Ehr85, Boe89] </ref>. We consider the risk given that we know what the current state of software is. Let the undesirable event be the problem-proneness of the software in the field due to one or more categories of faults (for example, the event is transition to state S f described earlier).
Reference: [Jon91] <author> W.J. Jones, </author> <title> "Reliability Models for Large Software Systems in Industry," P ro c ee d in g s Fi r s t In t er n at i on a l Symposium on Software Reliability Engineering, </title> <journal> pp. </journal> <pages> 35-42. </pages>
Reference-contexts: For example, we distinguish time-oriented failure-intensity (that is, failures per unit time), and test-case intensity (that is, number of failures per test case). In the case of operational testing, an excellent exposure metric is the CPU execution time <ref> [Mus87, Jon91, Cra92] </ref>, but this may not be the case in a nonoperational testing environment.
Reference: [Kho90] <author> T.M. Khoshgoftaar and J.C. Munson, </author> <title> "Predicting Software Development Errors Using Software Complexity Metrics," </title> <journal> IEEE J. on Selected Areas in Communications, </journal> <volume> Vol. 8 (2), </volume> <pages> pp 253-261, </pages> <year> 1990. </year>
Reference-contexts: Risk Modeling This section addresses the use of early testing information in identification of components that may be problem-prone in the field. Several approaches have been proposed <ref> [Kho90, Mun92, Bri93] </ref>. Highly correlated nature of the early software verification and testing events may require the use of a more sophisticated, timeseries, approach [Sin92].
Reference: [Lyu92] <author> Lyu and A.P. Nikora, </author> <title> "An Empirical Approach for Software Reliability Measurement by Linear Combination Models," </title> <journal> IEEE Software, </journal> <month> July </month> <year> 1992. </year>
Reference-contexts: This oscillatory effect can make reliability growth modeling difficult, although several different approaches have been suggested <ref> [e.g., Mus87, Lyu92] </ref> .
Reference: [Mun92] <author> J.C. </author> <title> Munson and T.M. Khoshgoftaar, "The Detection of Fault-Prone Programs, </title> " <journal> IEEE Trans. on Software Engineering, </journal> <volume> Vol 18(5), </volume> <pages> pp 423-433, </pages> <year> 1992 </year>
Reference-contexts: Several authors have published models that attempt to relate some early software metrics, such as, the size of the code, Halstead length, or cyclomatic number, to the failure proneness of the program <ref> [Mun92, Bri93] </ref>. <p> Risk Modeling This section addresses the use of early testing information in identification of components that may be problem-prone in the field. Several approaches have been proposed <ref> [Kho90, Mun92, Bri93] </ref>. Highly correlated nature of the early software verification and testing events may require the use of a more sophisticated, timeseries, approach [Sin92].
Reference: [Mus87] <author> J. Musa, A. Iannino and K. Okumoto, </author> <title> S o f t w a r e Reliability (Measurement, Prediction, Application), </title> <publisher> McGraw-Hill 1987 </publisher>
Reference-contexts: For example, SRE requires testing based on an operational profile. An operational profile is a set of relative frequencies of occurrence of the operations associated with the software during its use in the field [Mus93]. Interpretation of many software reliability models assumes failure detection based on operational profiles <ref> [Mus87] </ref>. Since this assumption is usually violated during early software testing phases (for example, during unit-testing and integration-testing), assessment and control of software quality growth during nonoperational testing stages is difficult and open to interpretation. * Research supported in part by NASA Grant No. <p> This oscillatory effect can make reliability growth modeling difficult, although several different approaches have been suggested <ref> [e.g., Mus87, Lyu92] </ref> . <p> This suggests that the data also needs to be collected on the software usage, size, and any other relevant metric. Distinction needs to be made between unique failures, repeated failures, and the underlying faults <ref> [Mus87] </ref>. 2.1.2 Failure-intensity Failure-intensity is a classical SRE metric [Mus87]. It can be defined as the rate of change of the mean value function, or the number of failures per unit time. The mean value function is the average cumulative number of failures at a point in time. <p> This suggests that the data also needs to be collected on the software usage, size, and any other relevant metric. Distinction needs to be made between unique failures, repeated failures, and the underlying faults <ref> [Mus87] </ref>. 2.1.2 Failure-intensity Failure-intensity is a classical SRE metric [Mus87]. It can be defined as the rate of change of the mean value function, or the number of failures per unit time. The mean value function is the average cumulative number of failures at a point in time. <p> For example, we distinguish time-oriented failure-intensity (that is, failures per unit time), and test-case intensity (that is, number of failures per test case). In the case of operational testing, an excellent exposure metric is the CPU execution time <ref> [Mus87, Jon91, Cra92] </ref>, but this may not be the case in a nonoperational testing environment. <p> Normalization of the failure-intensities across different components may be necessary <ref> [Mus87] </ref>. One possibility is to use instantaneous or average "test-case failure-intensity", which is expressed in terms of failures per test case, or the number of unique failures per unique test case. 3. <p> The formulation of software Vouk and Tai 520 Proc. CASCON 93, Toronto, 1993 reliability models, the estimation of their parameters, and the accuracy of their predictions are somewhat controversial issues [Bro92]. Common estimation procedures include maximum likelihood, least-squares and Bayesian approaches <ref> [Mus87] </ref>. However, the highly correlated nature of the early testing process may require the use of advanced "time-series" analyses to evaluate the reliability growth. <p> Weibull-type model, using time as exposure, was considered by Wagoner [Wag73], but not in the context of nonoperational profile testing. Also, the Shick-Wolverton model can be interpreted as a special case of the Weibull model class <ref> [Shi73, Mus87] </ref>. A number of other S-shape models exist [Yam83, Ohb84, Yam86, Toh89]. The unimodal failure-intensity profile, frequently observed during nonoperational testing, is in sharp contrast with the monotonously decaying failure-intensity expected from the "classical" reliability models used with operational profile testing.
Reference: [Mus93] <author> J.D. Musa, </author> <title> "Operational profiles in Software-Reliability Engineering," </title> <journal> IEEE Software, </journal> <volume> Vol. 10 (2), </volume> <pages> pp. 14-32, </pages> <month> March </month> <year> 1993. </year>
Reference-contexts: But, some practical obstacles still remain. For example, SRE requires testing based on an operational profile. An operational profile is a set of relative frequencies of occurrence of the operations associated with the software during its use in the field <ref> [Mus93] </ref>. Interpretation of many software reliability models assumes failure detection based on operational profiles [Mus87]. <p> The components that support the basic functionalities of the system form the system basis, or root. The interaction among different components and their hierarchy can be described using the system call tree structure <ref> [Mus93] </ref>. The issues presented in this paper are based, in part, on our experiences with several large commercial systems which, for proprietary reasons, are not identified. The results are exploratory in nature, and are intended to continue the dialogue and provide incentive for further research and input on these topics. <p> A full implementation of SRE requires determination of operational profile (s) <ref> [Mus93] </ref>, and analysis of observed problems in that context. <p> Definition and use of the appropriate operational profile (s) is essential for accurate evaluation of the testing process and its effects. Lacking actual operational usage information, it may be possible to estimate it. One possibility is to use the dynamic operational deployment information and figures <ref> [Mus93] </ref>. Another, less accurate way, is to statically analyze the product component call graphs. The call graph is a treelike structure which describes the interactions between different product components and their hierarchy [Mus93]. In that context we consider two metrics. The component "Importance" and the component "Call Usage". <p> One possibility is to use the dynamic operational deployment information and figures <ref> [Mus93] </ref>. Another, less accurate way, is to statically analyze the product component call graphs. The call graph is a treelike structure which describes the interactions between different product components and their hierarchy [Mus93]. In that context we consider two metrics. The component "Importance" and the component "Call Usage". The "Importance" metric attempts to indicate the importance, and, indirectly, possible usage frequency of a component (or function).
Reference: [Ohb84] <author> M. Ohba, </author> <title> "Software Reliability Analysis Models," </title> <journal> IBM J. of Res. and Development, </journal> <volume> Vol. 28 (4), </volume> <pages> pp. 428-443, </pages> <year> 1984. </year>
Reference-contexts: Weibull-type model, using time as exposure, was considered by Wagoner [Wag73], but not in the context of nonoperational profile testing. Also, the Shick-Wolverton model can be interpreted as a special case of the Weibull model class [Shi73, Mus87]. A number of other S-shape models exist <ref> [Yam83, Ohb84, Yam86, Toh89] </ref>. The unimodal failure-intensity profile, frequently observed during nonoperational testing, is in sharp contrast with the monotonously decaying failure-intensity expected from the "classical" reliability models used with operational profile testing.
Reference: [Pau93] <author> M.C. Paulk, B. Curtis, M. B. Chrissis, and C.V. Weber, </author> <title> "Capability Maturity Model, Version 1.1," </title> <journal> IEEE Software, </journal> <pages> pp. 18-27, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: Reliable latency of less than one phase, is probably not realistic for organizations below level 4 <ref> [Pau93] </ref>. This needs to taken into account when the level and the economics of SRE implementation is considered . Acknowledgments The first author is grateful to Dr. W. Jones for many invaluable discussions of the software reliability engineering issues. About the Authors Mladen A.
Reference: [Shi73] <author> G.J. Shick and R.W. Wolverton, </author> <title> "Assessment of Software Reliability," </title> <journal> Proc. Operations Research, Physical-Verlag, </journal> <volume> Wurzburg-Wien, </volume> <pages> pp. 395-422, </pages> <year> 1973. </year>
Reference-contexts: Weibull-type model, using time as exposure, was considered by Wagoner [Wag73], but not in the context of nonoperational profile testing. Also, the Shick-Wolverton model can be interpreted as a special case of the Weibull model class <ref> [Shi73, Mus87] </ref>. A number of other S-shape models exist [Yam83, Ohb84, Yam86, Toh89]. The unimodal failure-intensity profile, frequently observed during nonoperational testing, is in sharp contrast with the monotonously decaying failure-intensity expected from the "classical" reliability models used with operational profile testing.
Reference: [Sin92] <author> N.D. Singpurwalla and R. Soyer, </author> " <title> N o n h o m o g e n o u s a u t o regressive process for tracking (software) reliability growth, and their Bayesian analysis," </title> <journal> J. of the Royal Statistical Society, </journal> <volume> B 54, </volume> <pages> 145-156, </pages> <year> 1992. </year>
Reference-contexts: Several approaches have been proposed [Kho90, Mun92, Bri93]. Highly correlated nature of the early software verification and testing events may require the use of a more sophisticated, timeseries, approach <ref> [Sin92] </ref>. We illustrate some of the issues through a risk model [Ehr85, Boe89]. 3.1 Process States At the end of a nonoperational testing phase an indication of the state of the software may be available as a set of conditions.
Reference: [Toh89] <author> Y. Tohma, R. Jacoby, Y. Murata, and M. </author> <title> Y a m a m o t o , " H y p e r Geometric Distribution Model to Estimate the Number of Residual Software Faults," </title> <booktitle> Proc. COMPSAC 89, </booktitle> <publisher> IEEE CS Press, </publisher> <pages> pp. 610-617, </pages> <year> 1989. </year>
Reference-contexts: Weibull-type model, using time as exposure, was considered by Wagoner [Wag73], but not in the context of nonoperational profile testing. Also, the Shick-Wolverton model can be interpreted as a special case of the Weibull model class [Shi73, Mus87]. A number of other S-shape models exist <ref> [Yam83, Ohb84, Yam86, Toh89] </ref>. The unimodal failure-intensity profile, frequently observed during nonoperational testing, is in sharp contrast with the monotonously decaying failure-intensity expected from the "classical" reliability models used with operational profile testing.
Reference: [Vou92] <author> Vouk M.A., </author> <title> "Using Reliability Models During Testing with NonOperational Profiles," Proc. Second Workshop on I s s u e s i n S o f t w a r e R e l i a b i l i t y Estimation, </title> <month> October 12-13, </month> <year> 1992, </year> <institution> Bellcore, Livingston, N.J. </institution>
Reference-contexts: The essentials of one such a model, described as a Rayleigh intensity model, are given in <ref> [Vou92] </ref>. The model has a unimodal intensity profile, and an S-shaped cumulative distribution function. In a more general case, the dynamics of the process translates into a Weibull failure detection model.
Reference: [Wag73] <author> W.L. Wagoner, </author> <title> "The Final Report on a Software Reliability Measurement Study," Aerospace Corporation, </title> <type> Report TOR-0074(41112)-1, </type> <year> 1973. </year>
Reference-contexts: The model has a unimodal intensity profile, and an S-shaped cumulative distribution function. In a more general case, the dynamics of the process translates into a Weibull failure detection model. Weibull-type model, using time as exposure, was considered by Wagoner <ref> [Wag73] </ref>, but not in the context of nonoperational profile testing. Also, the Shick-Wolverton model can be interpreted as a special case of the Weibull model class [Shi73, Mus87]. A number of other S-shape models exist [Yam83, Ohb84, Yam86, Toh89].
Reference: [Yam83] <author> S. Yamada, M. Ohba, and S. Osaki, </author> <title> "S-Shaped Reliability Growth Modeling for Software Error Detection," </title> <journal> IEEE Tran. on Reliability, </journal> <volume> Vol. R-32 (5), </volume> <pages> pp. 475-478, </pages> <year> 1983. </year>
Reference-contexts: Weibull-type model, using time as exposure, was considered by Wagoner [Wag73], but not in the context of nonoperational profile testing. Also, the Shick-Wolverton model can be interpreted as a special case of the Weibull model class [Shi73, Mus87]. A number of other S-shape models exist <ref> [Yam83, Ohb84, Yam86, Toh89] </ref>. The unimodal failure-intensity profile, frequently observed during nonoperational testing, is in sharp contrast with the monotonously decaying failure-intensity expected from the "classical" reliability models used with operational profile testing.
Reference: [Yam86] <author> S. Yamada, H. Ohtera, and H. Narihisa, </author> <title> "A Testing-Effort Dependent Reliability Model for Computer Programs," </title> <journal> The Trans. of the IECE of Japan, </journal> <volume> Vol. E 69 (11), </volume> <pages> pp 1217-1224, </pages> <year> 1986. </year>
Reference-contexts: Weibull-type model, using time as exposure, was considered by Wagoner [Wag73], but not in the context of nonoperational profile testing. Also, the Shick-Wolverton model can be interpreted as a special case of the Weibull model class [Shi73, Mus87]. A number of other S-shape models exist <ref> [Yam83, Ohb84, Yam86, Toh89] </ref>. The unimodal failure-intensity profile, frequently observed during nonoperational testing, is in sharp contrast with the monotonously decaying failure-intensity expected from the "classical" reliability models used with operational profile testing.
References-found: 22

