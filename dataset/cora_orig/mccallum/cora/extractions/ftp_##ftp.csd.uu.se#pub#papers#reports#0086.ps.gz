URL: ftp://ftp.csd.uu.se/pub/papers/reports/0086.ps.gz
Refering-URL: http://www.csd.uu.se/papers/reports.html
Root-URL: 
Email: e-mail: thomasl@csd.uu.se  
Title: A Continuation-Passing Style for Prolog  
Author: Thomas Lindgren 
Date: 19 August, 1994  86  
Address: Box 311 751 05 Uppsala  
Affiliation: Computing Science Department, Uppsala University  
Pubnum: ISSN 1100-0686 UPMAIL Technical Report  
Abstract: We propose a translation of Prolog (including cut, if-then-else and similar constructs) into a first-order continuation-passing style, where (almost) all predicates have one clause and all clauses are binary. The resulting programs can be used as a flexible intermediate representation for compilation with a number of advantages as compared to Warren's abstract machine and other proposals. We discuss the advantages and disadvantages of this approach. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A.W. Appel, </author> <title> Compiling With Continuations, </title> <publisher> Cambridge University Press, </publisher> <year> 1992. </year>
Reference-contexts: This is promising for advanced compilation, and has been successfully exploited in a number of compilers <ref> [20, 16, 1] </ref>. In this paper, we propose a compilation of first-order Prolog programs into continuation-passing Horn clauses. The resulting predicates are first order and have a completely deterministic control: all control decisions have been moved to the source level. <p> An example is given below, where a predicate is recognized as deterministic and a pair of state save/restore operations can be removed altogether. Since they generate higher-order terms in their translation, a subsequent pass of closure conversion <ref> [1] </ref> converts the term to a first-order 4 representation. Our algorithm directly generates first-order terms as continuations. Brisset and Ridoux also show how to translate exceptions by continuation capturing primitives. <p> For instance, free variables can be retrieved from linked environments instead of flat ones; several continuations may share a single environment (in particular, some success and failure continuations might share environments, e.g., in the style of Appel, where closures can share share bindings <ref> [1] </ref>). Other possibilities are discussed below. 5 Conclusion We have shown how to compile Prolog procedures into BCS, a continuation-based intermediate form (which happens to be directly executable).
Reference: [2] <author> A.W. Appel, Z. Shao, </author> <title> Callee-saves registers in continuation-passing style, </title> <booktitle> Lisp and Symbolic Computation (1992), </booktitle> <pages> pp. 191-221. </pages>
Reference-contexts: Bevemyr and Lindgren have previously shown how to adapt generational copying garbage collection to a standard WAM [4]; we expect to reuse that method. Shao and Appel have shown how to optimize continuation representations for a heap based implementation of SML <ref> [18, 2] </ref>. If their results can be applied to our representation, we can pass arguments in memory when registers are scarce, or pass continuations in registers when registers are plentiful.
Reference: [3] <author> A.W. Appel, Z. Shao, </author> <title> An Empirical and Analytic Study of Stack vs. Heap Cost for Languages with Closures, </title> <institution> Princeton University CS-TR-450-94, Princeton University. </institution>
Reference-contexts: Implemented straightforwardly, a BCS program allocates all data on the heap. Research in functional languages has shown that this is not necessarily worse than stack allocation given generational copying garbage collection and fast handling of write-misses in the cache <ref> [10, 3] </ref>. Bevemyr and Lindgren have previously shown how to adapt generational copying garbage collection to a standard WAM [4]; we expect to reuse that method. Shao and Appel have shown how to optimize continuation representations for a heap based implementation of SML [18, 2].
Reference: [4] <author> J. Bevemyr, T. Lindgren, </author> <title> Simple and efficient copying garbage collection for Prolog, in Programming Language Implementation and Logic Programming 1994, </title> <note> LNCS, to appear. 17 </note>
Reference-contexts: Research in functional languages has shown that this is not necessarily worse than stack allocation given generational copying garbage collection and fast handling of write-misses in the cache [10, 3]. Bevemyr and Lindgren have previously shown how to adapt generational copying garbage collection to a standard WAM <ref> [4] </ref>; we expect to reuse that method. Shao and Appel have shown how to optimize continuation representations for a heap based implementation of SML [18, 2].
Reference: [5] <author> P. Brisset, O. Ridoux, </author> <title> Continuations in Prolog, </title> <booktitle> in Proceedings of the Tenth International Conference on Logic Programming, </booktitle> <editor> ed. D.S. Warren, </editor> <publisher> MIT Press, </publisher> <year> 1993. </year>
Reference-contexts: Nilsson [17] shows how to derive the WAM choicepoint instructions by partial evaluation of a meta interpreter. Our work is distinct from the control aspects of the WAM and adds translations of other control constructs such as cut. Brisset and Ridoux <ref> [5] </ref> propose a CPS for Prolog. Since this language has -abstractions, their translation is similar to Scheme or Lisp translations discussed below, but does not explicitly manage substitutions.
Reference: [6] <author> M. Carlsson, </author> <title> On Implementing Prolog in Functional Programming, </title> <booktitle> NGC 2 (1984), </booktitle> <pages> pp. 347-359. </pages>
Reference-contexts: We believe that, mutatis mutandis, these optimizations could be carried out on our compiled programs as well. 2.4 Translations into Scheme and Lisp Several translations from Prolog into Lisp have been proposed. We take the work of Kahn and Carlsson as representative in this approach. Kahn and Carlsson <ref> [13, 6] </ref> propose the use of upward failure or downward success continuations. The former relies on using lazy streams to produce solutions, while the latter performs a procedure return on failure.
Reference: [7] <author> S.K.Debray, </author> <title> "A Simple Code Improvement Scheme for Prolog", </title> <journal> JLP 1992:13:57-88. </journal>
Reference-contexts: Our algorithm directly generates first-order terms as continuations. Brisset and Ridoux also show how to translate exceptions by continuation capturing primitives. Such operations are beyond the scope of this paper. 2.3 Optimization of Prolog using control flow graphs Debray <ref> [7] </ref> proposes several optimizations based on Prolog predicates translated into control flow graphs with success and failure edges.
Reference: [8] <author> B. Demoen, A. Marien, </author> <title> Implementation of Prolog as Binary Definite Programs, </title> <booktitle> Proceedings of the Second Russian Conference on Logic Programming, LNAI 592, </booktitle> <pages> pp. 165-176, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: This simplifies compilation but excludes some optimizations. Our representation directly admits a translation into control flow graphs, since control flow is explicit. 3 2.2 Translations in Prolog Our technique can be viewed as an extension of binarization as described by Tarau [21] and Demoen <ref> [9, 8] </ref>. Binarization translates clauses H into their (success-) continuation passing forms: H (S) call (S) H (S) B 1 (B 2 (: : : (B n (S)) : : :)) Thus, the control rule of SLD-resolution is made explicit.
Reference: [9] <author> B. Demoen, </author> <title> On the Transformation of a Prolog Program to a More Efficient Binary Program, </title> <booktitle> Proceedings of the LOPSTR'92 workshop, </booktitle> <address> Manchester, </address> <month> July </month> <year> 1992. </year>
Reference-contexts: This simplifies compilation but excludes some optimizations. Our representation directly admits a translation into control flow graphs, since control flow is explicit. 3 2.2 Translations in Prolog Our technique can be viewed as an extension of binarization as described by Tarau [21] and Demoen <ref> [9, 8] </ref>. Binarization translates clauses H into their (success-) continuation passing forms: H (S) call (S) H (S) B 1 (B 2 (: : : (B n (S)) : : :)) Thus, the control rule of SLD-resolution is made explicit.
Reference: [10] <author> A. Diwan, D. Tarditi, E. Moss, </author> <title> Memory Subsystem Performance of Programs with Intensive Heap Allocation, </title> <type> Technical report CMU-CS-93-227, </type> <institution> Carnegie-Mellon University, </institution> <year> 1993. </year>
Reference-contexts: Implemented straightforwardly, a BCS program allocates all data on the heap. Research in functional languages has shown that this is not necessarily worse than stack allocation given generational copying garbage collection and fast handling of write-misses in the cache <ref> [10, 3] </ref>. Bevemyr and Lindgren have previously shown how to adapt generational copying garbage collection to a standard WAM [4]; we expect to reuse that method. Shao and Appel have shown how to optimize continuation representations for a heap based implementation of SML [18, 2].
Reference: [11] <author> M. Felleisen, </author> <title> Transliterating Prolog into Scheme, </title> <institution> Computer Science Department Technical Report 182, Indiana University, </institution> <year> 1985. </year>
Reference-contexts: Kahn and Carlsson [14] then employ partial evaluation to produce quite good Lisp code for naive reverse with modes. Research at Indiana University showed that Horn clauses could be translated into Scheme by fairly straightforward means <ref> [11, 15] </ref> and that some care was needed to extend Prolog with continuations [12]. In particular, a generalized trail was required to suspend and resume a proof tree branch.
Reference: [12] <author> C. Haynes, </author> <title> Logic continuations, </title> <journal> JLP, </journal> <volume> 4(2) </volume> <pages> 157-176, </pages> <month> June </month> <year> 1987. </year>
Reference-contexts: Kahn and Carlsson [14] then employ partial evaluation to produce quite good Lisp code for naive reverse with modes. Research at Indiana University showed that Horn clauses could be translated into Scheme by fairly straightforward means [11, 15] and that some care was needed to extend Prolog with continuations <ref> [12] </ref>. In particular, a generalized trail was required to suspend and resume a proof tree branch.
Reference: [13] <author> K. Kahn, M. Carlsson, </author> <title> How To Implement Prolog on a Lisp Machine, in Implementations of Prolog, </title> <editor> ed. J. Campbell, Ellis Hor-wood, </editor> <year> 1984. </year>
Reference-contexts: We believe that, mutatis mutandis, these optimizations could be carried out on our compiled programs as well. 2.4 Translations into Scheme and Lisp Several translations from Prolog into Lisp have been proposed. We take the work of Kahn and Carlsson as representative in this approach. Kahn and Carlsson <ref> [13, 6] </ref> propose the use of upward failure or downward success continuations. The former relies on using lazy streams to produce solutions, while the latter performs a procedure return on failure.
Reference: [14] <author> K. Kahn, M. Carlsson, </author> <title> The Compilation of Prolog Programs without the Use of a Prolog Compiler, </title> <type> UPMAIL Technical Report 27, </type> <institution> Uppsala University 1984. </institution>
Reference-contexts: The former relies on using lazy streams to produce solutions, while the latter performs a procedure return on failure. We note that both methods to some extent bury the symmetry of success and failure continuations, and that neither method eliminates all control stacks. Kahn and Carlsson <ref> [14] </ref> then employ partial evaluation to produce quite good Lisp code for naive reverse with modes. Research at Indiana University showed that Horn clauses could be translated into Scheme by fairly straightforward means [11, 15] and that some care was needed to extend Prolog with continuations [12].
Reference: [15] <author> E. Kohlbecker, eu-Prolog, </author> <type> Technical Report 155, </type> <institution> Computer Science Department, Indiana University, </institution> <year> 1984. </year>
Reference-contexts: Kahn and Carlsson [14] then employ partial evaluation to produce quite good Lisp code for naive reverse with modes. Research at Indiana University showed that Horn clauses could be translated into Scheme by fairly straightforward means <ref> [11, 15] </ref> and that some care was needed to extend Prolog with continuations [12]. In particular, a generalized trail was required to suspend and resume a proof tree branch.
Reference: [16] <author> D. Kranz, </author> <title> Orbit: An Optimizing Compiler for Scheme, </title> <type> Doctoral Thesis, </type> <institution> Yale University, </institution> <year> 1988. </year>
Reference-contexts: This is promising for advanced compilation, and has been successfully exploited in a number of compilers <ref> [20, 16, 1] </ref>. In this paper, we propose a compilation of first-order Prolog programs into continuation-passing Horn clauses. The resulting predicates are first order and have a completely deterministic control: all control decisions have been moved to the source level. <p> Tarau has shown that allocating WAM environments on the heap simplifies the execution machinery while being competitive in execution speed to a standard WAM implementation [22, 23]. Finally, some continuation-passing compilers reintroduce stack allocation by escape analysis <ref> [20, 16] </ref>. In summary, we do not find default heap-only allocation a fatal flaw. Future work. There are several issues to be explored. First, Prolog includes a great number of features, such as higher order predicates, dynamic predicates, input/output, coroutining and so on.
Reference: [17] <author> U. Nilsson, </author> <title> Towards a methodology for the design of abstract machines for logic programming languages, </title> <journal> JLP 1993:16:163-189. </journal> <volume> 18 </volume>
Reference-contexts: Our notation avoids these problems and also allows us to directly describe indexing as a source-to-source transformation, which binarization instead delegates to an underlying abstract machine. Nilsson <ref> [17] </ref> shows how to derive the WAM choicepoint instructions by partial evaluation of a meta interpreter. Our work is distinct from the control aspects of the WAM and adds translations of other control constructs such as cut. Brisset and Ridoux [5] propose a CPS for Prolog.
Reference: [18] <author> Z. Shao, A.W. Appel, </author> <title> Space-Efficient Closure Representations, </title> <institution> Princeton University CS-TR-454-94, Princeton University. </institution>
Reference-contexts: Bevemyr and Lindgren have previously shown how to adapt generational copying garbage collection to a standard WAM [4]; we expect to reuse that method. Shao and Appel have shown how to optimize continuation representations for a heap based implementation of SML <ref> [18, 2] </ref>. If their results can be applied to our representation, we can pass arguments in memory when registers are scarce, or pass continuations in registers when registers are plentiful.
Reference: [19] <author> O. Shivers, </author> <title> Control flow analysis in Scheme, </title> <booktitle> in SIGPLAN'88 Conference on Programming Language Design and Implementation. </booktitle>
Reference-contexts: An enterprising implementation could generate full decision graphs and stack multiple save/restore operations if needed. Join points in the decision graph are then encoded by call-clauses; control flow analysis <ref> [19] </ref> will reveal the definitions calling these clauses and may enable a compiler to take advantage of the contexts of the callers. (Since we are discussing first-order Prolog without freeze/2 etc, control flow analysis is straightforward; space restrictions do not permit us to describe the algorithm used here.) Motion of save/restore
Reference: [20] <author> G.L. Steele, Rabbit: </author> <title> A Compiler for Scheme, </title> <publisher> MIT AI Memo 474, </publisher> <year> 1978. </year>
Reference-contexts: This is promising for advanced compilation, and has been successfully exploited in a number of compilers <ref> [20, 16, 1] </ref>. In this paper, we propose a compilation of first-order Prolog programs into continuation-passing Horn clauses. The resulting predicates are first order and have a completely deterministic control: all control decisions have been moved to the source level. <p> Tarau has shown that allocating WAM environments on the heap simplifies the execution machinery while being competitive in execution speed to a standard WAM implementation [22, 23]. Finally, some continuation-passing compilers reintroduce stack allocation by escape analysis <ref> [20, 16] </ref>. In summary, we do not find default heap-only allocation a fatal flaw. Future work. There are several issues to be explored. First, Prolog includes a great number of features, such as higher order predicates, dynamic predicates, input/output, coroutining and so on.
Reference: [21] <author> P. Tarau, M. Boyer, </author> <title> Elementary logic programs, </title> <editor> eds. P. Der-ansart, J. Maluszynski, </editor> <publisher> LNCS 456, Springer Verlag, </publisher> <year> 1990. </year>
Reference-contexts: This simplifies compilation but excludes some optimizations. Our representation directly admits a translation into control flow graphs, since control flow is explicit. 3 2.2 Translations in Prolog Our technique can be viewed as an extension of binarization as described by Tarau <ref> [21] </ref> and Demoen [9, 8]. Binarization translates clauses H into their (success-) continuation passing forms: H (S) call (S) H (S) B 1 (B 2 (: : : (B n (S)) : : :)) Thus, the control rule of SLD-resolution is made explicit.
Reference: [22] <author> P. Tarau, </author> <title> Low-level issues in implementing a high-performance continuation passing Prolog engine, </title> <booktitle> in Programming Language Implementation and Logic Programming '92, </booktitle> <publisher> LNCS, Springer Verlag, </publisher> <year> 1992. </year>
Reference-contexts: Tarau has shown that allocating WAM environments on the heap simplifies the execution machinery while being competitive in execution speed to a standard WAM implementation <ref> [22, 23] </ref>. Finally, some continuation-passing compilers reintroduce stack allocation by escape analysis [20, 16]. In summary, we do not find default heap-only allocation a fatal flaw. Future work. There are several issues to be explored.
Reference: [23] <author> P. Tarau, </author> <title> WAM-optimizations in BinProlog: towards a realistic Continuation Passing Prolog Engine, </title> <type> Technical Report 92-3, </type> <institution> Uni-versite de Moncton, </institution> <year> 1992. </year>
Reference-contexts: In our example, we split this into two parts: motion of save/restore operations, and finding mutually exclusive tests. Continuation representation. The BCS representation gives us freedom to vary the representation of a continuation and access to the continuation. The WAM [26] and BinWAM <ref> [23] </ref> both use a `flat' representation of an environment: in the WAM, all variables are accessed by offsets from a pointer into the stack, while the BinWAM simply creates continuation terms that correspond to flat environments. <p> Tarau has shown that allocating WAM environments on the heap simplifies the execution machinery while being competitive in execution speed to a standard WAM implementation <ref> [22, 23] </ref>. Finally, some continuation-passing compilers reintroduce stack allocation by escape analysis [20, 16]. In summary, we do not find default heap-only allocation a fatal flaw. Future work. There are several issues to be explored.
Reference: [24] <author> P.L. Van Roy, </author> <title> Can Logic Programming Execute as Fast as Imperative Programming?, </title> <type> Ph.D. Thesis, Report UCB/CSD-90-600, </type> <institution> UC Berkeley, </institution> <year> 1990. </year>
Reference-contexts: Hence, we can generate the desired code. exec (X &lt; N, cut (F,B_1 (S)), B_2 (S,F)) The Aquarius compiler <ref> [24] </ref> performs this optimization by collecting test sets and checking whether the sets are mutually exclusive. In our example, we split this into two parts: motion of save/restore operations, and finding mutually exclusive tests. Continuation representation.
Reference: [25] <author> P.L. Van Roy, A.M. Despain, </author> <title> High-performance logic programming with the Aquarius Prolog Compiler, </title> <booktitle> IEEE Computer, </booktitle> <month> Jan-uary </month> <year> 1992. </year>
Reference: [26] <author> D.H.D. Warren, </author> <title> A Prolog Instruction Set, </title> <type> SRI Report 393, </type> <institution> SRI International, </institution> <year> 1983. </year> <month> 19 </month>
Reference-contexts: The paper is concluded with a discussion of advantages and disadvantages of the proposed representation in Section 5. 2 Related work There has been considerable interest in transformations of Prolog into Scheme and partial continuation passing styles and the relation of Pro-log to intermediate representations, such as Warren's abstract machine <ref> [26] </ref>. We review earlier research in this section. 2 2.1 Warren's abstract machine As an intermediate format, it is interesting to compare our intermediate format to Warren's abstract machine, WAM [26]. * Our notation extends the scope of compilation (the `chunks' or `basic blocks') by considering actions taken on failure. * <p> into Scheme and partial continuation passing styles and the relation of Pro-log to intermediate representations, such as Warren's abstract machine <ref> [26] </ref>. We review earlier research in this section. 2 2.1 Warren's abstract machine As an intermediate format, it is interesting to compare our intermediate format to Warren's abstract machine, WAM [26]. * Our notation extends the scope of compilation (the `chunks' or `basic blocks') by considering actions taken on failure. * Indexing can be expressed as a source-to-source transformation and also extended to utilize other mutually exclusive tests to re strict the number of candidate clauses. * We can trade code <p> In our example, we split this into two parts: motion of save/restore operations, and finding mutually exclusive tests. Continuation representation. The BCS representation gives us freedom to vary the representation of a continuation and access to the continuation. The WAM <ref> [26] </ref> and BinWAM [23] both use a `flat' representation of an environment: in the WAM, all variables are accessed by offsets from a pointer into the stack, while the BinWAM simply creates continuation terms that correspond to flat environments.
References-found: 26

