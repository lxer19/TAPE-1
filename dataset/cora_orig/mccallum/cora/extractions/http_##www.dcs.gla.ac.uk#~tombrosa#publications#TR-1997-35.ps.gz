URL: http://www.dcs.gla.ac.uk/~tombrosa/publications/TR-1997-35.ps.gz
Refering-URL: http://www.dcs.gla.ac.uk/~tombrosa/publications.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: MSc in Advanced Information Systems Reflecting user information needs through query biased summaries  
Author: Anastasios Tombros 
Date: September 1997  
Affiliation: UNIVERSITY of GLASGOW Department of Computing Science  Glasgow  
Abstract-found: 0
Intro-found: 1
Reference: [Abracos & Lopes, 1997] <author> Abracos, J.; Lopes, </author> <title> G.P. Statistical methods for retrieving most significant paragraphs in newspaper articles. </title> <booktitle> In Proceedings of the ACL'97/EACL'97 Workshop on Intelligent Scalable Text Summarisation (ISTS 97), </booktitle> <pages> pp. 51-57. </pages> <address> Madrid, Spain, </address> <month> July 11 </month> <year> 1997. </year>
Reference-contexts: Luhn suggested that a useful limit is four or five nonsignificant words between significant words. This early observation seems to agree with more recent studies that show that in the English language 98% of the lexical relations occur between words within a span of 5 words in a sentence <ref> [Abracos & Lopes, 1997] </ref>. Based on these observations, the method used in the work reported here defines two words as being significantly related if both of them are significant, and between them no more than 4 nonsignificant words intervene.
Reference: [Aretoulaki, 1997] <author> Aretoulaki, M. COSY-MATS: </author> <title> An Intelligent and Scalable Summarisation Shell. </title> <booktitle> In Proceedings of the ACL'97/EACL'97 Workshop on Intelligent Scalable Text Summarization (ISTS '97). </booktitle> <address> Madrid, Spain, </address> <month> July 11 </month> <year> 1997. </year>
Reference-contexts: Moreover, it can be argued that sentence extraction systems are actually corpus-dependent, that is they rely on the exploitation of special characteristics of the document corpus, and therefore their strategies are adjusted accordingly resulting in special extraction algorithms <ref> [Aretoulaki, 1997] </ref>. This kind of dependency should not be confused with a restriction of such systems to a specific application domain. It only allows for an optimisation of the system on that specific document corpus. <p> Moreover, since the amount of knowledge that needs to be stored for robust processing is large, systems are usually compelled to specialise in a single conceptual world and application <ref> [Aretoulaki, 1997] </ref>. As a result, the flexibility of such systems is greatly restricted, along with their portability to other domains. Their components are not easily extended to accommodate additional cases or applications.
Reference: [Brandow et al., 1995] <author> Brandow, R.; Mitze, K.; Rau, </author> <title> L.F. (1995) Automatic condensation of electronic publications by sentence selection. </title> <booktitle> In Information Processing & Management, </booktitle> <volume> 31(5), </volume> <pages> pp. 675-685, </pages> <month> September </month> <year> 1995. </year>
Reference-contexts: A document summary could also be used to improve the precision of text search, as searching against a condensed version of a document may decrease the Chapter 3 Related work on the automation of text summarisation 15 probability that irrelevant text will match a query <ref> [Maizell et al., 1971; Brandow et al., 1995] </ref>. Numerous researchers have addressed the automation of document summarisation. <p> Statistical and linguistic approaches have been used for the identification of significant information within a document, but automatic comprehension of a documents content is, until now, beyond the state of the art <ref> [Brandow et al., 1995; Salton et al, 1997] </ref>. The second part of the summarisation model, summary text generation, also presents difficulties in being automated. That is the main reason why only few systems have focused on language generation techniques in order to produce the summary text. <p> For example, given that a summarisation system will be applied on documents consisting of news articles, it would be fully justifiable to take advantage of their journalistic idiosyncrasy, and to give an extra bonus score at the leading sentences of each document <ref> [Brandow et al., 1995] </ref>. A final remark about sentence extraction is that many of the criteria used to establish a measure of sentence significance rely on the assumption that the author of the document does reveal important information in specific parts of the document. <p> This evaluation method showed that the leading-text summaries received significantly higher acceptability ratings (87% as opposed to 68% for the automatically generated summaries), suggesting the inadequacy of present extraction methods <ref> [Brandow et al., 1995] </ref>. In each case, the human factor becomes deciding, either in composing the target extract or in subjectively judging its appropriateness. <p> It was uniformly noted from the sample study, that the first few sentences of each article provide a fair amount of information about the articles content. This conclusion seems to be in agreement with <ref> [Brandow et al., 1995] </ref>, who suggested that improvements (to the autosummaries) can be Chapter 4 The summarisation system 43 achieved by weighting the sentences appearing in the beginning of the articles more heavily. <p> This deficiency has usually negative effects in the acceptability of automatically generated summaries by users <ref> [Brandow et al., 1995] </ref>. However, when using a summarisation system in an operational, task-based environment, a possible way to alleviate the consequences of the incoherent summary text is by customising the summary to an information need expressed by a user through a query. <p> In that case, the summary length is defined as equal to the upper limit (six sentences). Such a value seems to be in general agreement with suggestions made by [Edmundson, 1964], and <ref> [Brandow et al., 1995] </ref>. Chapter 4 The summarisation system 54 4.7 Rationale of the system design The previous sections of this chapter have provided an insight to the architecture, and the principal design issues of the summarisation system.
Reference: [Callan, 1994] <author> Callan, J. P. </author> <title> Passage-level evidence in document retrieval. </title> <editor> In Croft, W.B. and van Rijbergen, C.J. </editor> <booktitle> (editors) Proceedings of the Seventeenth Annual ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pp. 302-310. </pages> <publisher> ACM Press, </publisher> <month> July </month> <year> 1994. </year>
Reference-contexts: Chapter 2 Basic concepts of information retrieval systems 12 Recognising the cognitive overhead imposed on users, there have been attempts to concentrate the users attention on parts of the text that possess a high density of relevant information. These methods, known as passage retrieval <ref> [Callan, 1994; Knaus et al., 1995] </ref>, instead of retrieving the full document text in response to the query, they identify and present to the user individual text passages that are more responsive to particular user needs than the full document texts.
Reference: [DeJong, 1982] <author> DeJong, G. </author> <title> An overview of the FRUMP system. </title> <editor> In Lehnert, W.G. and Ringle, M.H. </editor> <booktitle> (editors) Strategies for Natural Language Processing, </booktitle> <pages> pp. 149-172. </pages> <address> London: </address> <publisher> Lawrence Erlbaum, </publisher> <year> 1982. </year>
Reference-contexts: The main characteristics of such approaches will be discussed in the following sections. 3.4.1 Basic architecture of language generation systems Traditionally, language generation systems are divided into two modules <ref> [DeJong, 1982; McKeown et al., 1995] </ref> : a content planner which attempts to interpret the source text by selecting information to include in the summary from an underlying knowledge base, and a sentence generator which takes the conceptual representation of text produced by the content planner and realises it in natural <p> The output of Chapter 3 Related work on the automation of text summarisation 27 the content planner is an intermediate representation of the source text. The intermediate form may range from surface representations like syntactic parse trees, to representations involving conceptual primitives <ref> [DeJong, 1982] </ref>. Approaches that demand domain knowledge are usually required in order to derive a conceptual representation of the source, thus enforcing domain dependency to such systems.
Reference: [Edmundson, 1964] <author> Edmundson, </author> <title> H.P. Problems in automatic abstracting. </title> <journal> In Communications of the ACM, </journal> <volume> 7(4), </volume> <pages> pp. 259-263, </pages> <month> April </month> <year> 1964. </year>
Reference-contexts: Edmundsons evaluation schemes were based on his belief that in any document there are sentences which should be included in every summary (right answers), and there are sentences which should not be included in any summary (false answers) <ref> [Edmundson, 1964] </ref>. He therefore reduced the problem of automatically extracting sentences to form a summary, to that of reducing the number of false answers to a minimum, while at the same time selecting as many right answers as possible. <p> In the case when auto-extracts are compared to manually prepared ones, the naive assumption is adopted that only one Chapter 3 Related work on the automation of text summarisation 30 correct summary exists for every document. To prove the contrary, experiments conducted on human abstractors <ref> [Edmundson, 1964; Kupiec et al., 1995] </ref> have shown that sentence extracts, or even paragraph extracts [Salton et al., 1997], selected by different persons have a very low level of agreement. <p> It would therefore be appropriate to view a summary as a function of both the type of documents to be summarised, and the purpose for which it is actually required <ref> [Edmundson, 1964; Rush et al., 1971] </ref>. Purpose factors have a direct effect on the process of summarisation. By defining the specific function a summary may have, the actual form of the summary is defined as well. <p> In that case, the summary length is defined as equal to the upper limit (six sentences). Such a value seems to be in general agreement with suggestions made by <ref> [Edmundson, 1964] </ref>, and [Brandow et al., 1995]. Chapter 4 The summarisation system 54 4.7 Rationale of the system design The previous sections of this chapter have provided an insight to the architecture, and the principal design issues of the summarisation system.
Reference: [Edmundson, 1969] <author> Edmundson, </author> <title> H.P. New methods in automatic abstracting. </title> <journal> In Journal of the ACM, </journal> <volume> 16(2), </volume> <pages> pp. </pages> <month> 264-285 April </month> <year> 1969. </year>
Reference-contexts: Edmundson (1969) on the other hand, used a rather simple scoring function, by weighting keywords according to their frequency in the document and by summing the keyword weights for each sentence. Chapter 3 Related work on the automation of text summarisation 19 The cue method H.P. Edmundson <ref> [Edmundson, 1969] </ref> experimented with the hypothesis that certain of the words occurring in a sentence provide an indication of whether the sentence deals with important concepts. <p> Like the keyword method, a list of index terms is created for the document prior to the sentence scoring process. In the title method, candidate terms are selected from the title, subtitle and headings of the document. Edmundson <ref> [Edmundson, 1969] </ref>, who experimented with this method, assigned heavier weights to content words of the title than to content words of headings and subtitles. He then computed the final title weight for each sentence as the sum of the title weights of its constituent words. <p> Chapter 3 Related work on the automation of text summarisation 29 3.5.1 System evaluation The first attempt to carry out a thorough evaluation of a sentence extraction system was performed by H.P. Edmundson <ref> [Edmundson, 1969] </ref>. Since then, relatively little work has been carried out on the issue. <p> The model described above judges the utility of a summarisation system in the context in which it will eventually be used, and for the purposes for which it has been built. The indicative function of a summary is the one which is considered essential <ref> [Edmundson, 1969; Paice, 1990] </ref>, and therefore is the one which should be primarily evaluated. Experiments with various users coming from various backgrounds (academic researchers, authors, simple end-users) should provide a sound basis for a fair evaluation scheme. <p> However, the presentation of the results was rather equivocal, and the experimental methodology followed was not clear. 3.5.3 Performance evaluation of the extracting methods Edmundson extended his work on the evaluation of summarisation systems to the evaluation of the performance of the various sentence extraction methods <ref> [Edmundson, 1969] </ref>. He experimented with four distinct extracting methods: the keyword, cue, title and location methods. His approach involved adjusting parameters for these methods and then combining them in all possible ways. This resulted in fifteen auto-extracts being generated and scored for each document, one for each combination. <p> If a term is found in a j type token, then it is assigned a positive title score. The title score of each sentence is then defined as the sum of the title scores of its constituent words. Location method The location method <ref> [Edmundson, 1969] </ref> is based on the physical arrangement of the linguistic elements of an article. This arrangement can mainly be described in terms of the location of a sentence with respect to the limits either of its containing document, or of sections within that document. - Leading sentences. <p> No other part of the articles, when examined relatively to their limits, seems to convey significant content information. - Paragraphs. While it has been suggested that the first and last sentence of paragraphs often act as a form of summary for the specific paragraph <ref> [Edmundson, 1969] </ref> and should therefore be assigned a positive score, this is not the case in the WSJ collection. Its documents are fragmented into a large number of paragraphs, that usually consist of only a couple of sentences.
Reference: [Enders-Niggemeyer et al., 1993] <author> Enders-Niggemeyer, B.; Hobbs, J.; Sparck Jones, K. </author> <title> Summarizing Text for Intelligent Communication, </title> <type> Dagstuhl Seminar 9350. </type> <note> URL : http://www.dib.fh-hannover.de/SimSum/Abstract/, December 1993. </note>
Reference-contexts: A generator must be able to construct the best expression for a given situation by choosing between many possible options. This requires utilising a wide range of knowledge sources that provide such options, and that store them for usage in a similar case in the future. Finally, recent research <ref> [Enders-Niggemeyer et al., 1993] </ref> has suggested that automatic text summarisation should focus on the observation of human summarisation skills, and on linguistic work on discourse and text in order to derive a satisfactory theory of text structure.
Reference: [Fagan, 1987] <author> Fagan, J. L. </author> <title> Experiments in automatic phrase indexing for document retrieval: A comparison of syntactic and non-syntactic methods. </title> <type> Ph.D. Thesis, </type> <institution> Department of Computing Science, Cornell University, </institution> <address> Ithaca, New York. </address> <year> 1987. </year>
Reference-contexts: retrieved documents to his information need, there are a number of potential enhancements that could be accommodated in the design of the summarisation system developed for the purposes of this thesis. - It is believed that phrases can provide significant information about the content conveyed by documents and by queries <ref> [Fagan, 1987] </ref>. The use of phrases for content identification should therefore be investigated in the context of a summarisation system.
Reference: [Frakes & Baeza-Yates, 1992] <author> Frakes, W.B.; Baeza-Yates, R. </author> <title> (editors). Information retrieval: Data structures and algorithms. </title> <publisher> Prentice Hall, </publisher> <address> London. References 97 </address>
Reference-contexts: Each element of the vector corresponds to an index term of the Interested readers may refer to [Sparck Jones & Kay, 1973] for a comprehensive overview of linguistic approaches to automatic indexing. 5 See [Van Rijsbergen, 1979], pp. 17. 6 An extensive discussion about stemming algorithms can be found in <ref> [Frakes & Baeza-Yates, 1992] </ref>, pp 131-151.
Reference: [Goffman & Newill, 1967] <author> Goffman, W.; Newill, V. A. </author> <title> Communication and epidemic processes. </title> <journal> In Proceedings of the Royal Society, Series A, </journal> <volume> 298(1454), </volume> <pages> pp. 316-334. </pages> <month> May </month> <year> 1967. </year>
Reference-contexts: The connection of the two points should become apparent through the discussion evolved in the following paragraphs. A communication process can be thought of as a sequence of events resulting in the transmission of something called information from one object (source) to another (destination). <ref> [Goffman & Newill, 1967] </ref>. Information 1 can actually be of various forms. However, in the context of this thesis we shall restrict the notion of information to that conveyed in textual documents, and we shall therefore regard a document as a basic unit of information.
Reference: [Hand, 1997] <author> Hand, T.F. </author> <title> A proposal for a task-based evaluation of text summarisation systems. </title> <booktitle> In Proceedings of the ACL'97/EACL'97 Workshop on Intelligent Scalable Text Summarisation (ISTS '97), </booktitle> <pages> pp. 31-38. </pages> <address> Madrid, Spain, </address> <month> July 11 </month> <year> 1997. </year>
Reference-contexts: Experiments with various users coming from various backgrounds (academic researchers, authors, simple end-users) should provide a sound basis for a fair evaluation scheme. The need for a similar approach to evaluation has been acknowledged <ref> [Hand, 1997] </ref>, but yet attempts to perform a task-oriented evaluation have not been well established. An early task-based evaluation attempt was made by [Miike et al., 1994], where timing statistics and relevancy decisions based on summaries for a domainspecific summariser were recorded.
Reference: [Jacobs & Rau, 1990] <author> Jacobs, P.S.; Rau, </author> <title> L.F. Scisor: Extracting information from online news. </title> <journal> In Communications of the ACM, </journal> <volume> 33(11), </volume> <pages> pp. 88-97, </pages> <month> November </month> <year> 1990. </year>
Reference: [Keppel, 1973] <author> Keppel, G. </author> <title> Design and analysis: A researchers handbook. </title> <publisher> Prentice Hall, </publisher> <address> New Jersey. </address>
Reference-contexts: These facts are not easy to come by; they are established through observation, recording, and analysis of data generated during the observation periods <ref> [Keppel, 1973] </ref>. A common method for establishing facts is the experimental method. Little is known about the cognitive aspects of the process that leads to the formulation of a hypothesis through the observation of facts. <p> Unfortunately, this is not the case. In fact, many experiments have been rendered useless through a breakdown in the chain of logic between the initial assumptions and the final conclusions due to factors introduced which vary systematically with the different experimental treatments <ref> [Keppel, 1973] </ref>. These factors, or variables, are called irrelevant or confounding variables. Chapter 5 Experimental design 63 Consider the hypothesis we are testing: we will eventually have to use a number of subjects to test the validity of our hypothesis. <p> Clearly, the subject population is not representative of the population to which we wish to generalise the conclusions. This crucial decision can influence the ability to extend any experimental results beyond the bounds of the experiment itself, because statistical inconsistencies may arise <ref> [Keppel, 1973; Miller, 1984] </ref>. However, relevant studies have shown that although there are 15 See section 2.4 of this thesis for a discussion about the typical output of IR systems. <p> Chapter 5 Experimental design 68 risks in generalising the experimental results in such cases, an investigator may feel safe in doing so since the statistical differences introduced are generally of a small scale <ref> [Keppel, 1973] </ref>. 5.3.3 Treatment of irrelevant variables In section 5.2.2 a discussion about the methods to control the irrelevant variables introduced in an experimental design was presented. It is appropriate at this point to outline the actual control methods adopted in the specific design described in this chapter.
Reference: [Knaus et al., 1995] <author> Knaus, D.; Mittendorf, E.; Schuble, P.; Praic, S. </author> <title> Highlighting relevant passages for users of the interactive SPIDER retrieval system. </title> <booktitle> In Proceedings of the TREC-4 Conference. </booktitle>
Reference-contexts: Chapter 2 Basic concepts of information retrieval systems 12 Recognising the cognitive overhead imposed on users, there have been attempts to concentrate the users attention on parts of the text that possess a high density of relevant information. These methods, known as passage retrieval <ref> [Callan, 1994; Knaus et al., 1995] </ref>, instead of retrieving the full document text in response to the query, they identify and present to the user individual text passages that are more responsive to particular user needs than the full document texts. <p> For example, the summarisation system developed here could be evaluated against passage retrieval systems that present the user with paragraphs matching his query <ref> [Knaus et al., 1995] </ref>. - Finally, different evaluation scenarios that would measure different aspects of summarisation systems should be developed.
Reference: [Kupiec et al., 1995] <author> Kupiec, J.; Pedersen, J.; Chen, F. </author> <title> A trainable document summarizer. </title> <editor> In Fox, E.A.; Ingwersen, P.; Fidel, R. </editor> <booktitle> (editors) Proceedings of the Eighteenth Annual ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pp. 68-73. </pages> <publisher> ACM Press, </publisher> <month> July </month> <year> 1995. </year>
Reference-contexts: In the case when auto-extracts are compared to manually prepared ones, the naive assumption is adopted that only one Chapter 3 Related work on the automation of text summarisation 30 correct summary exists for every document. To prove the contrary, experiments conducted on human abstractors <ref> [Edmundson, 1964; Kupiec et al., 1995] </ref> have shown that sentence extracts, or even paragraph extracts [Salton et al., 1997], selected by different persons have a very low level of agreement.
Reference: [Lancaster, 1968] <author> Lancaster, F.W. </author> <title> Information retrieval systems: characteristics, testing and evaluation. </title> <publisher> Wiley, </publisher> <address> New York. </address>
Reference-contexts: It merely informs on the existence (or nonexistence) and whereabouts of documents relating to his request. <ref> [Lancaster, 1968] </ref>. This concise definition of the basic functions of an information retrieval (IR) system, offers a perfectly appropriate starting point around which the discussion presented in this chapter shall evolve.
Reference: [Luhn, 1958] <author> Luhn, </author> <title> H.P. The automatic creation of literature abstracts. </title> <journal> In IBM Journal of Research and Development, </journal> <volume> 2(2), </volume> <pages> pp. 159-165, </pages> <month> April </month> <year> 1958. </year>
Reference-contexts: This measure of importance is usually met in the literature as discriminating or resolving power of the index terms <ref> [Luhn, 1958; Van Rijsbergen, 1979] </ref>. 3 See [Van Rijsbergen, 1979], pp. 6. <p> Chapter 3 Related work on the automation of text summarisation 17 3.2 Automatic text summarisation by sentence extraction An early attempt that tried to address automatic summarisation was reported in a paper by H.P. Luhn published in 1958 <ref> [Luhn, 1958] </ref>. This work concentrated on the generation of extracts, that is sets of sentences from the source text, selected to provide a good indication of the sources main subject. Later research, particularly that having been reported up to about 1970, was clearly influenced by Luhns approach. <p> The methods used for identifying clues to sentence significance that have been tried by various researchers will now be discussed. Chapter 3 Related work on the automation of text summarisation 18 The keyword method This approach was introduced by Luhn <ref> [Luhn, 1958] </ref> and is based on the hypothesis that high-frequency words are indicative of the documents content and thus considered as positively relevant. Sentences that contain these frequently used words are then scored using functions of their frequency counts. <p> However, the results obtained through this kind of experimentation can not be guaranteed to establish an optimum value for the lower limit. This can only be achieved by experimentation with appropriately large samples of documents <ref> [Luhn, 1958] </ref>. The conclusions from the experimentation procedure were that a reasonable TF value for establishing the significance of a term is 7, and that this value should be adjusted according to the size of the document. The value of 7 should be applied to mediumsized documents of the collection. <p> Therefore, wherever the greatest number of frequently occurring different words are found in greatest physical proximity to each other, the probability is high that the information being conveyed is most representative of the article <ref> [Luhn, 1958] </ref>. The actual definition of the greatest physical proximity is a major aspect of this method. Luhn suggested that a useful limit is four or five nonsignificant words between significant words. <p> If in that way a sentence is separated in two or more clusters, the one with the highest significance factors is taken as the measure for that sentence. Sentence significance A scheme for computing the significance factor for a sentence was given by <ref> [Luhn, 1958] </ref>. This scheme consists of defining the extent of a cluster of related words (i.e. the actual number of words in the cluster), and dividing the square of this number by the total number of words within this cluster.
Reference: [Maizell et al., 1971] <author> Maizell, R.E.; Smith, J.F.; Singer, T.E.R. </author> <title> Abstracting scientific and technical literature: An introductory guide and text for scientists, abstractors and management. </title> <publisher> Willey-Interscience. John Willey & Sons Inc., </publisher> <address> New York, </address> <year> 1971. </year>
Reference-contexts: A document summary conventionally refers to an abstract-like condensation of a full text document, that presents succinctly the objectives, scope, and findings of a document <ref> [Maizell et al., 1971] </ref>. The minimal function that any useful summary should provide is being indicative of the sources content, hence helping a reader to decide whether looking at the whole document will be worthwhile. <p> A document summary could also be used to improve the precision of text search, as searching against a condensed version of a document may decrease the Chapter 3 Related work on the automation of text summarisation 15 probability that irrelevant text will match a query <ref> [Maizell et al., 1971; Brandow et al., 1995] </ref>. Numerous researchers have addressed the automation of document summarisation.
Reference: [Mani & Bloedorn, 1997] <author> Mani, I.; Bloedorn, E. </author> <title> Multi-document summarisation by graph search and matching. </title> <booktitle> In Proceedings of AAAI-97, </booktitle> <address> Providence Rhode Island, </address> <year> 1997. </year>
Reference: [Maybury, 1995] <author> Maybury, </author> <title> M.T. Generating summaries from event data. </title> <booktitle> In Information Processing & Management, </booktitle> <volume> 31(5), </volume> <pages> pp. 735-751, </pages> <month> September </month> <year> 1995. </year>
Reference-contexts: This general model makes a distinction between source text interpretation and summary text generation <ref> [Maybury, 1995; Sparck Jones & Enders-Niggemeyer, 1995] </ref>. The process of source text interpretation can be subdivided into: understanding the content of the document and identifying important information contained in it. <p> On the other hand, observation of summarising carried out by professional human abstractors, suggests that the modelled processes occur concurrently and are coconstraining <ref> [Maybury, 1995] </ref>. For example, in human summarising, the structure of the source document and the abstractors presuppositions and personal bias tend to emphasise some items of information while suppressing others, thus influencing processing and structure of the resulting summary.
Reference: [McKeown, 1985] <author> McKeown, K.R. </author> <title> Text Generation: Using discourse strategies and focus constraints to generate natural language text. </title> <publisher> Cambridge University Press, </publisher> <year> 1985. </year>
Reference-contexts: Furthermore, since the production of connected text (and not simply single sentences) is required, issues of discourse coherency and structure should be addressed <ref> [McKeown, 1985] </ref>. A system employing text generation should be able to determine how to organise the individual sentences by adhering to a specific organisational framework. <p> Interpretation does not require a formulation of reasons for selecting between various options for the construction of the text (e.g. why in a specific point within a sentence active voice is used instead of passive) <ref> [McKeown, 1985] </ref>. In generation of natural language, however, that is exactly what is required. A generator must be able to construct the best expression for a given situation by choosing between many possible options.
Reference: [McKeown et al., 1995] <author> McKeown, K.; Robin, J.; Kukich, K. </author> <title> Generating concise natural language summaries. </title> <booktitle> In Information Processing & Management, </booktitle> <volume> 31(5), </volume> <pages> pp. 703-733, </pages> <month> September </month> <year> 1995. </year> <note> References 98 </note>
Reference-contexts: The main characteristics of such approaches will be discussed in the following sections. 3.4.1 Basic architecture of language generation systems Traditionally, language generation systems are divided into two modules <ref> [DeJong, 1982; McKeown et al., 1995] </ref> : a content planner which attempts to interpret the source text by selecting information to include in the summary from an underlying knowledge base, and a sentence generator which takes the conceptual representation of text produced by the content planner and realises it in natural
Reference: [McKeown & Radev, 1995] <author> McKeown, K.; Radev, </author> <title> D.R. Generating summaries from multiple news articles. </title> <editor> In Fox, E.A.; Ingwersen, P.; Fidel, R. </editor> <booktitle> (editors) Proceedings of the Eighteenth Annual ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pp. 74-82. </pages> <publisher> ACM Press, </publisher> <month> July </month> <year> 1995. </year>
Reference: [Miike et al., 1994] <author> Miike, S.; Itoh, E.; Ono, K.; Sumita, K. </author> <title> A full-text retrieval system with a dynamic abstract generation function. </title> <editor> In Croft, W.B. and van Rijbergen, C.J. </editor> <booktitle> (editors) Proceedings of the Seventeenth Annual ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pp. 152-161. </pages> <publisher> ACM Press, </publisher> <month> July </month> <year> 1994. </year>
Reference-contexts: The need for a similar approach to evaluation has been acknowledged [Hand, 1997], but yet attempts to perform a task-oriented evaluation have not been well established. An early task-based evaluation attempt was made by <ref> [Miike et al., 1994] </ref>, where timing statistics and relevancy decisions based on summaries for a domainspecific summariser were recorded.
Reference: [Miller, 1984] <author> Miller, S. </author> <title> Experimental design and statistics (2 nd edition). </title> <address> NY, Routledge 1984. </address>
Reference-contexts: Little is known about the cognitive aspects of the process that leads to the formulation of a hypothesis through the observation of facts. Generally, such statements usually possess an intuitive nature; in fact very few hypotheses are actually formulated by direct deductions from some more general theory <ref> [Miller, 1984] </ref>. They mostly arise from some kind of interaction between the experimenters intuitions, theoretical ideas and factual knowledge. The best way to elaborate on the basic concepts of the experimental method is by means of an example. <p> It is obvious that these methods attempt to counterbalance the effects of the subject variables using a different approach. However, in deciding which method to use in an actual experiment, other considerations become significant. For example, the 13 For a comprehensive discussion on these methods, refer to <ref> [Miller, 1984] </ref>, pp. 10-15. 14 Similar on the variables that influence the condition under study. Chapter 5 Experimental design 64 repeated measures design requires that the subjects are employed for a long period of time, in order to participate in both experimental conditions; that may often be difficult to arrange. <p> The exact number that constitutes an optimal lower limit depends on the type of the experiment. However, it is generally accepted that the prospects for obtaining significant results through experimentation grow better as the sample is increased <ref> [Miller, 1984] </ref>. In practical terms this means that we should employ as many subjects as our time limits and resources allow. Taking these limitations into consideration, in the experiment described in this chapter two groups consisting of 10 subjects each were employed. <p> Clearly, the subject population is not representative of the population to which we wish to generalise the conclusions. This crucial decision can influence the ability to extend any experimental results beyond the bounds of the experiment itself, because statistical inconsistencies may arise <ref> [Keppel, 1973; Miller, 1984] </ref>. However, relevant studies have shown that although there are 15 See section 2.4 of this thesis for a discussion about the typical output of IR systems. <p> Otherwise, it is impossible to test the validity of the hypothesis, and therefore the problem falls outside the realm of scientific inquiry <ref> [Miller, 1984] </ref>. The factual evidence must be quantified by some specific measures that should be acquired through the experimental procedure. The actual choice of measures should facilitate the inference of conclusions: the proof or the refusal of the research hypothesis. <p> The summarisation system selects information from each document based on, among other criteria, the distribution of query terms in its constituent sentences. In this way, the generated summaries aim to help users to more 18 For a discussion on statistical methods to establish the significance of experimental results see <ref> [Miller, 1984] </ref>, pp. 48-65. Chapter 6 Presentation and analysis of the experimental results 82 easily identify the relevant to the query pieces of information that are contained in each document.
Reference: [Paice, 1981] <author> Paice, </author> <title> C.D. The automatic generation of literature abstracts: an approach based on the identification of self-indicating phrases. </title> <editor> In Oddy, R.N.; Robertson, S.E.; van Rijbergen, C.J.; Williams, P.W. </editor> <booktitle> (editors) Information retrieval research, </booktitle> <pages> pp. 172-191. </pages> <publisher> Butterworths, </publisher> <year> 1981. </year>
Reference-contexts: However, it is suggested that a satisfactory coverage of such phrases can be achieved by Chapter 3 Related work on the automation of text summarisation 20 defining as few as seven or eight distinct basic types <ref> [Paice, 1981] </ref>. Each of these basic types can be seen as a template, and all other indicator phrases can be produced by reference to the templates. Consider for instance the first two examples given above: they belong to the same basic template type, since they possess the same basic structure.
Reference: [Paice, 1990] <author> Paice, </author> <title> C.D. Constructing literature abstracts by computer: Techniques and prospects. </title> <booktitle> In Information Processing & Management, </booktitle> <volume> 26(1), </volume> <pages> pp. 171-186, </pages> <year> 1990. </year>
Reference-contexts: The most commonly used approach is to present sentence extracts of the source text, and then attempt to make them look as if they belong together by applying linguistic rules <ref> [Paice, 1990] </ref>. The model described above seems to have a pipeline-like architecture: source analysis, identification of useful information, formation of summary representation, and finally generation of the summary text. <p> Disruption of textual cohesion of the generated summary may result from the extraction of explicit references within sentences, which can only be understood by reference to material elsewhere in the text <ref> [Paice, 1990] </ref>. Anaphoric references are the most common example of such a disruption. To illustrate this problem better, consider the following example of an automatically extracted summary: The work undertaken examines Only low carbon steels were selected for experimentation. <p> If the restored sentence also contains an anaphor, the procedure must be repeated. But if several sentences (more than three) have to be reinstated because of the required antecedents of the initial sentence, then that sentence is rejected. A different approach proposed by <ref> [Paice, 1990] </ref>, deals with the detection of the unresolved anaphoric references. By applying a set of rules whenever an anaphor is recognised, this approach attempts to estimate whether the antecedent (i.e. the resolution of the anaphor) lies within the current sentence or not. <p> It can be argued that the above rule is not on a firm linguistic ground, but nevertheless it provides a reasonable solution to the problem. 3.3.2 Coverage and balance The lack of coverage and balance <ref> [Paice, 1990] </ref> of the resulting summary, is yet another weakness of extracting systems. The issue of coverage deals with containing every significant item of information in the generated summary. A document may have two, or even more, main topics. <p> In order to ensure that every important aspect of the source text is presented in the generated summary (i.e. the documents balance), various stylised arrangements are utilised. The notion of the formatted abstract was introduced by <ref> [Paice, 1990] </ref>: headings such as Purposes of study, Procedures, and Findings, can be helpful in identifying relevant portions of the summary of a research report, and also in achieving balance. Obviously, it is not only summaries that possess a structure. <p> The model described above judges the utility of a summarisation system in the context in which it will eventually be used, and for the purposes for which it has been built. The indicative function of a summary is the one which is considered essential <ref> [Edmundson, 1969; Paice, 1990] </ref>, and therefore is the one which should be primarily evaluated. Experiments with various users coming from various backgrounds (academic researchers, authors, simple end-users) should provide a sound basis for a fair evaluation scheme.
Reference: [Paice, 1993] <author> Paice, </author> <title> C.D. The identification of important concepts in highly structured technical papers. </title> <booktitle> In Proceedings of the 16 th Annual International ACM SIGIR Conference on Research & Development in IR, </booktitle> <year> 1993. </year>
Reference: [Rush et al., 1971] <author> Rush, J.E.; Salvador, R.; Zamora, A. </author> <title> Automatic abstracting and indexing. II. Production of indicative abstracts by application of contextual inference and syntactic coherence criteria. </title> <journal> In Journal of the American Society for Information Science, </journal> <volume> 22(4), </volume> <pages> pp. 260-274, </pages> <year> 1971. </year>
Reference-contexts: Null words finally, are irrelevant words that contribute neither negatively nor positively to the sentence score. The final weight for each sentence is calculated as the sum of the cue weights of its constituent words. A modification of this method <ref> [Rush et al., 1971] </ref> was motivated by the belief that opinions and subjective notions should not be included in a summary. According to this approach, there are certain cue words that provide unequivocal clues to such things as opinion and subjectivity, as well as positive notions. <p> That is, the role of a particular sentence in an extract may not be consistent with the roles of its adjacent sentences. A first simple solution to the problem of unresolved anaphoric references was given in the work reported by <ref> [Rush et al., 1971] </ref>. <p> It would therefore be appropriate to view a summary as a function of both the type of documents to be summarised, and the purpose for which it is actually required <ref> [Edmundson, 1964; Rush et al., 1971] </ref>. Purpose factors have a direct effect on the process of summarisation. By defining the specific function a summary may have, the actual form of the summary is defined as well. <p> Chapter 5 Experimental design 66 The aim of the proposed evaluation scheme is to judge the utility of a summarisation system in the context in which it will eventually be used, and for the purposes for which it has been built. According to this rationale, the indicative function <ref> [Rush et al., 1971] </ref> of a summary is the one which should be primarily evaluated.
Reference: [Salton & McGill, 1983] <author> Salton, G.; McGill, M.J. </author> <title> Introduction to modern information retrieval. </title> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <year> 1983. </year>
Reference-contexts: For documents that contain more than 40 sentences, the TF value is augmented by 10% of the increase in document size. The increase is calculated in respect to the upper limit of the medium See <ref> [Salton & McGill, 1983] </ref>, pp. 59-60. Chapter 4 The summarisation system 46 document size, i.e. 40. For example, for a document that is 50 sentences long, the increase in size is 10, and therefore the TF limit is set to: 7 + [0.1 * (10)] = 8. <p> The TF measure is not extremely efficient in identifying index terms that distinguish the documents to which they are assigned from the remainder of the corpus, since it does not take into account information from the entire document collection <ref> [Salton & McGill, 1983] </ref>. However, this is of minor importance for the purposes of text summarisation. In such a case, what is wanted is not the identification of useful index terms in relation to the entire document corpus, but the establishment of a terms significance within its containing document.
Reference: [Salton & Buckley, 1988] <author> Salton, G.; Buckley C. </author> <title> Term-Weighting Approaches in Automatic Text Retrieval. </title> <booktitle> In Information Processing and Management, </booktitle> <volume> 24(5), </volume> <pages> pp. 513-523, </pages> <year> 1988. </year>
Reference-contexts: As a consequence, a great number of variations of the above weighting schemes can be found in the literature. For a comprehensive discussion on the various weighting schemes and their implications on the process of text retrieval, readers who wish to may refer to [Van Rijsbergen, 1979], and <ref> [Salton & Buckley, 1988] </ref>. 2.3 Query operations Until now we have examined how index terms are selected from the documents of interest, and how weights are assigned to these terms according to their discriminating, or resolving, power.
Reference: [Salton et al., 1996] <author> Salton, G.; Singhal, A.; Buckley, C.; Mitra, M. </author> <title> Automatic text decomposition using text segments and text themes. </title> <booktitle> In Hypertext 96, The 7 th ACM Conference on Hypertext, </booktitle> <pages> pp. 53-65. </pages> <address> New York: </address> <publisher> ACM Press 1996. </publisher>
Reference: [Salton et al., 1997] <author> Salton, G.; Singhal, A.; Mitra, M.; Buckley, C. </author> <title> Automatic text structuring and summarisation. </title> <booktitle> In Information Processing & Management, </booktitle> <volume> 33(2), </volume> <pages> pp. 193-207, </pages> <year> 1997. </year> <note> References 99 </note>
Reference-contexts: Paragraph significance is defined in the same way as previously: the most important paragraphs are those which are related to the largest number of other paragraphs in the source document. In order to actually identify the important paragraphs, ideas from the automatic hypertext link generation research are being used <ref> [Salton et al., 1997] </ref>, but instead of producing inter-document links between various related documents, links between various paragraphs of the document are produced (intra-document links). By using a similar graph representation of the document, paragraphs with the larger number of intra-document links are selected for extraction. <p> In this way it is possible to produce longer summaries, but it is equally possible that these summaries will contain more coherent text since a paragraph contains more context <ref> [Salton et al., 1997] </ref>. 3.3 Points for discussion Sentence extraction systems allow summarisation in arbitrary domains, since they do not use any fieldspecific knowledge. <p> To prove the contrary, experiments conducted on human abstractors [Edmundson, 1964; Kupiec et al., 1995] have shown that sentence extracts, or even paragraph extracts <ref> [Salton et al., 1997] </ref>, selected by different persons have a very low level of agreement. A more striking observation is that for a given abstractor and for a given document to abstract over time, the overlap of extracted sentences is only 55%.
Reference: [Saracevic, 1969] <author> Saracevic, T. </author> <title> Comparative effects of titles, abstracts and full texts on relevance judgements. </title> <booktitle> In Proceedings of the American Society for Information Science, </booktitle> <volume> (6), </volume> <pages> pp. 293-299. </pages>
Reference-contexts: However, in the context of this thesis we shall restrict the notion of information to that conveyed in textual documents, and we shall therefore regard a document as a basic unit of information. In fact we can not adequately define information; nevertheless we comprehend its properties and effects. <ref> [Saracevic, 1969] </ref> Chapter 1 Introduction Systems whose function is the carrying out of a communication process are usually referred to as information systems. In the context of this thesis we shall concentrate on a specific category of such systems, information retrieval (IR) systems.
Reference: [Skorokhodko, 1971] <author> Skorokhodko, E.F. </author> <title> Adaptive method of automatic abstracting and indexing. </title> <booktitle> In Information Processing, </booktitle> <volume> volume 2, </volume> <pages> p.p. 1179-1182. </pages> <publisher> North-Holland Publishing Company. </publisher>
Reference: [Sparck Jones & Kay, 1973] <author> Sparck Jones, K.; Kay, M. </author> <booktitle> Linguistics and information science. </booktitle> <publisher> Academic Press, </publisher> <address> New York and London. </address>
Reference-contexts: A descriptor for each document can subsequently be defined as the set of its constituent index terms. A usual way to represent the document descriptor is by means of a binary vector. Each element of the vector corresponds to an index term of the Interested readers may refer to <ref> [Sparck Jones & Kay, 1973] </ref> for a comprehensive overview of linguistic approaches to automatic indexing. 5 See [Van Rijsbergen, 1979], pp. 17. 6 An extensive discussion about stemming algorithms can be found in [Frakes & Baeza-Yates, 1992], pp 131-151.
Reference: [Sparck Jones & Enders-Niggemeyer, 1995] <author> Sparck Jones, K.; Enders-Niggemeyer, B. </author> <title> Introduction: Automatic summarising. </title> <booktitle> In Information Processing & Management, </booktitle> <volume> 31(5), </volume> <pages> pp. 625-630, </pages> <month> September </month> <year> 1995. </year>
Reference-contexts: This general model makes a distinction between source text interpretation and summary text generation <ref> [Maybury, 1995; Sparck Jones & Enders-Niggemeyer, 1995] </ref>. The process of source text interpretation can be subdivided into: understanding the content of the document and identifying important information contained in it. <p> The system then outputs a predetermined number of top scoring sentences, that constitute the actual summary of the document. 4.2.1 Purpose factors There are generally three factors that affect summarising: input, purpose and output <ref> [Sparck Jones & Enders-Niggemeyer, 1995] </ref>.
Reference: [Sparck Jones, 1995] <author> Sparck Jones, K. </author> <title> Reflections on TREC. </title> <booktitle> In Information Processing & Management, </booktitle> <volume> 31(3), </volume> <pages> pp. 291-314, </pages> <year> 1995. </year>
Reference-contexts: The specific type of queries used, is that employed in the TREC programme (Text REtrieval Conferences) <ref> [Sparck Jones, 1995] </ref>. Briefly, we can say that TREC can be viewed as an evaluation exercise for existing IR systems, that attempts to measure specific aspects of their effectiveness. <p> The Title field for example, can be viewed as the exact query entered in an IR system by the user. The Narrative field on the other hand, clearly indicates what properties documents must have in order to be deemed relevant, thus reflecting the users needs <ref> [Sparck Jones, 1995] </ref>. The approach that was followed for generating the query terms for each topic, is based on the Title section of the queries only. <p> With respect to the relevance assessments for the TREC queries, it should be noted that documents do not have to be wholly, or even primarily, about a request topic in order to be deemed relevant <ref> [Sparck Jones, 1995] </ref>. A document may be characterised as relevant given only the facts conveyed in two independent sentences.
Reference: [Stairmand & Black, 1996] <author> Stairmand, M. A.; Black, W.J. </author> <title> Conceptual and contextual indexing using WordNet-derived lexical chains. </title> <booktitle> In Proceedings of the 18 th BCS Colloquium on information retrieval research, </booktitle> <pages> pp. 47-65. </pages> <institution> Manchester Metropolitan University, </institution> <month> March </month> <year> 1996. </year> <editor> [Van Rijsbergen, 1979] van Rijsbergen, C.J. </editor> <booktitle> Information retrieval (2 nd edition). </booktitle> <publisher> Butterworths, </publisher> <address> London. A-1 </address>
Reference-contexts: Both statistical and syntactic methods should be explored. - The use of synonyms for query terms should also be examined. It has been suggested <ref> [Stairmand & Black, 1996] </ref>, that there are limitations imposed on the process of retrieval of relevant documents by the fact that indexing of documents (and of queries) is performed by key words as opposed to key concepts. In this way concepts such as polysemy 20 and synonymy are ignored.
References-found: 40

