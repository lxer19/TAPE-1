URL: http://www.icsi.berkeley.edu/~dpwe/research/icassp97/paper.ps.gz
Refering-URL: http://www.icsi.berkeley.edu/~dpwe/research/icassp97/
Root-URL: http://www.icsi.berkeley.edu
Email: dpwe@icsi.berkeley.edu  
Title: THE WEFT: A REPRESENTATION FOR PERIODIC SOUNDS  
Author: Dan Ellis 
Address: Berkeley CA 94704  
Affiliation: International Computer Science Institute,  
Date: April 1997  
Note: to appear in the Proceedings of the International Conference on Speech and Signal Processing Munich,  Ellis The Weft 1996dec11 1  
Abstract: For the problem of separating sound mixtures, periodicity is a powerful cue used by both human listeners and automatic systems. Short-term autocorrelation of subband envelopes, as in the correlogram, accounts for much perceptual data. We present a discrete representation of common-period sounds, derived from the correlogram, for use in computational auditory scene analysis: The weft describes a sound in terms of a time-varying periodicity and a smoothed spectral envelope of the energy exhibiting that period. Wefts improve on several aspects of previous approaches by providing, without additional grouping, a single, invertible element for each detected signal , and also a provisional solution to detecting and dissociating energy of different periodicities in a single frequency channel (unlike systems which allocate whole frequency channels to one source). We define the weft, describe the analysis procedure we have devised, and illustrate its capacity to separate periodic sounds from other signals. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. S. Bregman, </author> <title> Auditory Scene Analysis, </title> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: 1. INTRODUCTION Human listeners are highly adept at interpreting the complex soundfield reaching their ears as the superposition of the output of several independent sources; this subtle process of auditory organization has attracted significant investigation both in psychoacoustics <ref> [1] </ref> and more recently via computer modeling [2,3,4]. Although human auditory scene analysis is the result of sophisticated operations at many levels, modeling work tends to focus on low-level signal processing related to the neurophysiology of the auditory periphery.
Reference: [2] <author> M. Weintraub, </author> <title> A theory and computational model of monaural auditory sound separation, </title> <type> Ph.D. dissertation, </type> <institution> Stanford Univ., </institution> <year> 1985. </year>
Reference: [3] <author> M. P. Cooke, </author> <title> Modelling auditory processing and organisation, </title> <publisher> Cambridge University Press, </publisher> <year> 1993. </year>
Reference: [4] <author> G. J. Brown, </author> <title> Computational Auditory Scene Analysis: a representational approach , Ph.D. </title> <type> thesis, </type> <institution> CS dept., Sheffield Univ, </institution> <year> 1992. </year>
Reference-contexts: However, the inputs to the model were essentially static spectra or snapshots, and the model assumed the presence of exactly two periodic sources. The full-blown Computational Auditory Scene Analysis (CASA) system of Brown <ref> [4] </ref> picked out a single periodic target from a noisy background by segmenting the time-frequency plane into locally-coherent regions he called auditory objects. A search procedure then fused these objects on the basis of consistent local periodicity contours to produce pitch-based entities. <p> Wefts are also based on the correlogram, but have the following advantages over the objects of Brown <ref> [4] </ref>: A single weft represents all the energy associated with a given period, corresponding to several of Browns objects; the costly (and physiologically implausible) stage of subsequent grouping is avoided. <p> Unfortunately, the spectral envelopes of both wefts extracted from the mixture show evidence of both formants; the factorization of periodic combinations needs additional study. female voice (taken from <ref> [4] </ref>). The points to note are: The continuously-voiced male utterance gives a single weft. Stops and fricatives interrupt the female speech resulting in a sequence of four wefts. Most time-frequency cells have contributed to both signals; factoring-out the interactions within each channel gives each voice a different spectrum. <p> 1996dec11 - 4 -60 -40 dB 400 2000 f/Hz Voices 0.0 0.2 0.4 0.6 0.8 1.0 1.2 1.4 100 400 200 1000 4000 f/Hz Weft1 0.0 0.2 0.4 0.6 0.8 1.0 1.2 100 400 Wefts2-5 0.0 0.2 0.4 0.6 0.8 1.0 1.2 time/s mixture of male and female voices from <ref> [4] </ref>. (The periodogram is displayed with an upside-down, logarithmic time axis, labeled by frequency). The lower panels show the smooth spectrum and period tracks of the five wefts extracted for this sound. The continuously-voiced male utterance is extracted as a single weft (left). <p> Nine subjects compared the original to the resyntheses and rated the quality on a percentage scale from identical (100%) to unrecognizable (0%). Ratings were 44% for the male voice and 30% for the female voice; Browns <ref> [4] </ref> resynthesis of the male voice scored 37% in the same test (his system did not extract a second voice). These resynthesis examples may be heard on the Web at http://www.icsi.berkeley.edu/~dpwe/research/icassp97/ . 5.
Reference: [5] <author> P. F. Assmann & Q. Summerfield, </author> <title> Modeling the perception of concurrent vowels: Vowels with different fundamental frequencies, </title> <journal> J. Acous. Soc. Am. </journal> <volume> 88(2), </volume> <pages> pp. 680-697, </pages> <year> 1990. </year>
Reference-contexts: The pseudoperiodicity of many real - world sound sources (notably the human vocal apparatus) gives an extremely powerful basis for the accurate separation of the characteristics of simultaneous sounds, as shown by double-vowel perception experiments <ref> [5] </ref>. The perceptual segregation of voices with differing pitches is so immediate and so strong as to suggest the operation of special-purpose dedicated neural circuitry. Considerable effort has been expended in order to construct equivalent computer models, with success only for a limited range of phenomena.
Reference: [6] <author> R. O. Duda, R. F. Lyon & M. Slaney, </author> <title> Correlograms and the separation of sounds, </title> <booktitle> Proc. IEEE Conf. on Signals, Systems and Computers, Asilomar, </booktitle> <year> 1990. </year>
Reference: [7] <author> M. Slaney & R. F. Lyon, </author> <title> On the importance of time a temporal representation of sound, in Visual Representations of Speech Signals , ed. </title> <editor> M. Cooke, S. Beet & M. Crawford, </editor> <publisher> John Wiley, </publisher> <pages> pp. 95-116, </pages> <year> 1993. </year>
Reference: [8] <author> R. Meddis & M. J. Hewitt, </author> <title> Virtual pitch and phase sensitivity of a computer model of the auditory periphery. I: Pitch identification, </title> <journal> J. Acous. Soc. Am. </journal> <volume> 89(6), </volume> <pages> pp. 2866-2882, </pages> <year> 1991. </year>
Reference-contexts: Consequently, computer models such as the correlogram [6,7] use envelope autocorrelation to reveal the periodicity of the energy in each peripheral frequency channel; this frequency-channel-versus-lag-period display can serve as the basis for isolating the spectra of mixture components. The correlogram-type model of Meddis & Hewitt <ref> [8] </ref> predicted listeners abilities to exploit pitch difference in identifying vowel mixtures very accurately. However, the inputs to the model were essentially static spectra or snapshots, and the model assumed the presence of exactly two periodic sources.
Reference: [9] <author> D. P. W. Ellis, </author> <title> Prediction-driven Computational Auditory Scene Analysis, </title> <type> Ph.D. dissertation, </type> <institution> EECS dept., M.I.T., </institution> <year> 1996. </year>
Reference-contexts: Both of these systems were constrained to allocate the whole of a frequency channel to just one source at each instant. 2. THE WEFT REPRESENTATION We developed a new representation, the weft, as part of a more general CASA system <ref> [9] </ref> which includes other sound elements for noisy and transient sounds. (Weft is the Anglo-Saxon word for the parallel fibers in woven cloth, giving the idea of a connected set of threads [10]). <p> WEFT ANALYSIS The process by which wefts are extracted from a mixture of periodic sounds is illustrated in figure 1. Successive blocks are discussed below; for greater detail, see <ref> [9] </ref>. Correlogram The input sound is passed first through a linear filterbank approximating the frequency analysis of the cochlea [11]. Each channel is then half-wave rectified and smoothed with a 1ms window to remove fine time structure. <p> A simplified analysis <ref> [9] </ref> of the situation where the excitation consists of impulses at a period much longer than the peripheral filter impulse response predicts the autocorrelation peak value, P, is given by: P = dM 2 + (1-d)N 2 (1) where N is the envelope noise floor, M is the envelope level during
Reference: [10] <author> D. P. W. Ellis & D. F. Rosenthal, </author> <title> Mid-level representations for computational auditory scene analysis, </title> <booktitle> workshop on Comp. Aud. Scene Analysis at the Intl. Joint Conf. on Artif. Intel., Montral, </booktitle> <pages> pp. 111-117, </pages> <year> 1995. </year>
Reference-contexts: THE WEFT REPRESENTATION We developed a new representation, the weft, as part of a more general CASA system [9] which includes other sound elements for noisy and transient sounds. (Weft is the Anglo-Saxon word for the parallel fibers in woven cloth, giving the idea of a connected set of threads <ref> [10] </ref>). Wefts are also based on the correlogram, but have the following advantages over the objects of Brown [4]: A single weft represents all the energy associated with a given period, corresponding to several of Browns objects; the costly (and physiologically implausible) stage of subsequent grouping is avoided.
Reference: [11] <author> M. Slaney, </author> <title> An efficient implementation of the Patterson-Holdsworth auditory filter bank, </title> <type> Tech. Report #35, </type> <institution> Apple Computer Co., </institution> <year> 1993. </year>
Reference-contexts: The period-track stores the underlying period exhibited by the weft as a function of time. The smoothspectrum records the amount of energy reflecting that period in each time-frequency cell of the analysis. Since the system is based around a cochlea filterbank <ref> [11] </ref>, frequency resolution is rather broad and highly overlapped. Weft resynthesis is straightforward, according to a traditional source-filter formulation: An impulse-train is generated from the period track. <p> WEFT ANALYSIS The process by which wefts are extracted from a mixture of periodic sounds is illustrated in figure 1. Successive blocks are discussed below; for greater detail, see [9]. Correlogram The input sound is passed first through a linear filterbank approximating the frequency analysis of the cochlea <ref> [11] </ref>. Each channel is then half-wave rectified and smoothed with a 1ms window to remove fine time structure. Short-time autocorrelation is calculated by smoothing the product of an envelope signal with delayed versions of itself.
References-found: 11

