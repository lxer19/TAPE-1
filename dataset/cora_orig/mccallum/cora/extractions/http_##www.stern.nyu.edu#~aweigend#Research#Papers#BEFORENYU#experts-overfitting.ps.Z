URL: http://www.stern.nyu.edu/~aweigend/Research/Papers/BEFORENYU/experts-overfitting.ps.Z
Refering-URL: http://www.stern.nyu.edu/~aweigend/Research/Papers/BEFORENYU/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: andreas@cs.colorado.edu  mangeas@cs.colorado.edu  
Title: Avoiding overfitting by locally matching the noise level of the data gating network discovers the
Author: Andreas S. Weigend Morgan Mangeas 
Note: the  
Address: Boulder, CO 80309-0430  1, av. du general de Gaulle, 92141 Clamart, France, and  Boulder, CO 80309-0430  
Affiliation: Department of Computer Science and Institute of Cognitive Science University of Colorado  Electricite de France, Direction des Etudes et Recherches  Department of Computer Science University of Colorado,  
Abstract: When trying to forecast the future behavior of a real-world system, two of the key problems are nonstationarity of the process (e.g., regime switching) and overfitting of the model (particularly serious for noisy processes). This articles shows how gated experts can point to solutions to these problems. The architecture, also called society of experts and mixture of experts consists of a (nonlinear) gating network and several (nonlinear) competing experts. Each expert learns a conditional mean (as usual), but each expert also has its own adaptive width. The gating network learns to assign a probability to each expert that depends on the input. This article first discusses the assumptions underlying this architecture and derives the weight update rules. It then evaluates the performance of gated experts in comparison to that of single networks, as well as to networks with two outputs, one predicting the mean, the other one the local error bar. This article also investigates the ability of gated experts to discover and characterize underlying the regimes. The results are: * there is significantly less overfitting compared to single nets, for two reasons: only subsets of the potential inputs are given to the experts and gating network (less of a curse of dimensionality), and the experts learn to match their variances to the (local) noise levels, thus only learning as This article focuses on the architecture and the overfitting problem. Applications to a computer-generated toy problem and the laser data from Santa Fe Competition are given in [Mangeas and Weigend, 1995], and the application to the real-world problem of predicting the electricity demand of France are given in [Mangeas et al., 1995]. much as the data support.
Abstract-found: 1
Intro-found: 1
Reference: [Bishop, 1994] <author> Bishop, C. M. </author> <year> (1994). </year> <title> Mixture density networks. </title> <type> Technical report, </type> <institution> Aston University. </institution>
Reference-contexts: There are approaches to predicting arbitrary probability densities; the mixture of Gaussians prior to taking the expectation value can be used <ref> [Bishop, 1994] </ref>; an alternative is the nonparametric fractional binning technique [Weigend and Srivastava, 1995].
Reference: [Bollerslev, 1986] <author> Bollerslev, T. </author> <year> (1986). </year> <title> Generalized autoregressive conditional heteroskedasticity. </title> <journal> Journal of Econometrics, </journal> <volume> 21 </volume> <pages> 307-328. </pages>
Reference-contexts: The constraint of continuity across the cut is introduced by hand (whereas it emerges naturally for gated experts). Successful applications of TAR models are typically on problems with relatively few data points (O (100)) and splits now splits are often made in an exogenous variable, such as the volatility <ref> [Engle, 1982, Bollerslev, 1986, Bollerslev et al., 1990] </ref>.
Reference: [Bollerslev et al., 1990] <author> Bollerslev, T., Chou, R. Y., Jayaraman, N., and Kroner, K. F. </author> <year> (1990). </year> <title> ARCH modeling in finance: A review of the theory and empirical evidence. </title> <journal> Journal of Econometrics, </journal> <volume> 52(1) </volume> <pages> 5-60. </pages>
Reference-contexts: The constraint of continuity across the cut is introduced by hand (whereas it emerges naturally for gated experts). Successful applications of TAR models are typically on problems with relatively few data points (O (100)) and splits now splits are often made in an exogenous variable, such as the volatility <ref> [Engle, 1982, Bollerslev, 1986, Bollerslev et al., 1990] </ref>.
Reference: [Chatfield, 1989] <author> Chatfield, C. </author> <year> (1989). </year> <title> The Analysis of Time Series. </title> <publisher> Chapman and Hall, London. </publisher>
Reference-contexts: 1 Introduction Conventional time series models are global models. They can be linear, assuming that the next is superposition of preceding <ref> [Yule, 1927, Chatfield, 1989] </ref>, or they can be nonlinear, typified as neural networks with hidden units [Lapedes and Farber, 1987, Weigend et al., 1990]. Global models are well suited to problems where the underlying dynamics is stationary.
Reference: [Doutriaux and Zipser, 1990] <author> Doutriaux, A. and Zipser, D. </author> <year> (1990). </year> <title> Unsupervised discovery of speech segments using recurrent networks. </title> <editor> In Touretzky, D. S., Elman, J. L., Sejnowski, T. J., and Hinton, G. E., editors, </editor> <booktitle> Proceedings of the 1990 Connectionist Models Summer School, </booktitle> <pages> pages 303-309, </pages> <address> San Fransisco, CA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: This approach is more fundamental than previous connectionist methods for segmentation, based on the errors [Elman, 1990], and on the activations of the hidden units <ref> [Doutriaux and Zipser, 1990] </ref>. In order to achieve reliable convergence and numerical stability, we had to combining the EM algorithm (explained in Section 2.3) with a second-order method for the nonlinear optimization.
Reference: [Elman, 1990] <author> Elman, J. L. </author> <year> (1990). </year> <title> Finding structure in time. </title> <journal> Cognitive Science, </journal> <volume> 14 </volume> <pages> 179-211. </pages>
Reference-contexts: Apart from excellent predictive performance and robustness against overfitting, gated experts lend themselves to a rigorous statistical interpretation that allows to segment the series and identify the underlying regimes. This approach is more fundamental than previous connectionist methods for segmentation, based on the errors <ref> [Elman, 1990] </ref>, and on the activations of the hidden units [Doutriaux and Zipser, 1990]. In order to achieve reliable convergence and numerical stability, we had to combining the EM algorithm (explained in Section 2.3) with a second-order method for the nonlinear optimization.
Reference: [Engle, 1982] <author> Engle, R. F. </author> <year> (1982). </year> <title> Autoregressive conditional heteroskedasticity with estimates of the variance of united kingdom inflation. </title> <journal> Econometrica, </journal> <volume> 50 </volume> <pages> 987-1007. </pages>
Reference-contexts: The constraint of continuity across the cut is introduced by hand (whereas it emerges naturally for gated experts). Successful applications of TAR models are typically on problems with relatively few data points (O (100)) and splits now splits are often made in an exogenous variable, such as the volatility <ref> [Engle, 1982, Bollerslev, 1986, Bollerslev et al., 1990] </ref>.
Reference: [Friedman, 1991] <author> Friedman, J. H. </author> <year> (1991). </year> <title> Multivariate adaptive regression splines. </title> <journal> Annals of Statistics, </journal> <volume> 19 </volume> <pages> 1-142. </pages>
Reference-contexts: Successful applications of TAR models are typically on problems with relatively few data points (O (100)) and splits now splits are often made in an exogenous variable, such as the volatility [Engle, 1982, Bollerslev, 1986, Bollerslev et al., 1990]. A more flexible model of multivariate adaptive regression splines (MARS) <ref> [Friedman, 1991] </ref> has recently been applied to forecasting of financial data [Lewis et al., 1994]. 2 The problem of estimating local noise levels is known in the statistics literature as noise heterogeneity [Seber and Wild, 1989].
Reference: [Granger, 1994] <author> Granger, C. W. J. </author> <year> (1994). </year> <title> Forecasting in economics. </title> <editor> In Weigend, A. S. and Gershenfeld, N. A., editors, </editor> <title> Time Series Prediction: </title> <booktitle> Forecasting the Future and Understanding the Past, </booktitle> <pages> pages 529-538, </pages> <address> Reading, MA. </address> <publisher> Addison-Wesley. </publisher>
Reference-contexts: However, man real-world time series are not stationary, but rather switch between different regimes. For example, the regimes of electricity demand depend on the seasons, and regimes of financial forecasts depend on the economy (e.g., recession or growth) <ref> [Granger, 1994, Hamilton, 1994] </ref>. Althoughin principlea single global model can emulate any function, including regime switching, in practice it might be very hard to learn.
Reference: [Granger and Terasvirta, 1993] <author> Granger, C. W. J. and Terasvirta, T. </author> <year> (1993). </year> <title> Modelling Nonlinear Economic Relationships. </title> <publisher> Oxford University Press, Oxford, </publisher> <address> UK. </address>
Reference-contexts: To our knowledge, neither the double-nonlinear gated experts used here nor the flexible individual noise levels for the different regimes have been used in economics or econometrics <ref> [Granger and Terasvirta, 1993, Hamilton, 1994] </ref>. 2 The rigorous probabilistic interpretation of the linear gated experts fully generalized to the gated experts discussed here.
Reference: [Hamilton, 1990] <author> Hamilton, J. D. </author> <year> (1990). </year> <title> Analysis of time series subject to changes in regime. </title> <journal> Journal of Econometrics, </journal> <volume> 45 </volume> <pages> 39-79. </pages>
Reference-contexts: In contrast to gated experts, the splits there are very simple and ad hoc; there is no underlying probabilistic interpretation. 1 More closely related to gated experts are the mixture models of the econometrics community <ref> [Hamilton, 1990, Hamilton, 1994] </ref>. Expressed in connectionist language, the mixture models used there do not have any hidden units: both the gate and all the experts are linear.
Reference: [Hamilton, 1994] <author> Hamilton, J. D. </author> <year> (1994). </year> <title> Time Series Analysis. </title> <publisher> Princeton University Press, Princeton. </publisher>
Reference-contexts: However, man real-world time series are not stationary, but rather switch between different regimes. For example, the regimes of electricity demand depend on the seasons, and regimes of financial forecasts depend on the economy (e.g., recession or growth) <ref> [Granger, 1994, Hamilton, 1994] </ref>. Althoughin principlea single global model can emulate any function, including regime switching, in practice it might be very hard to learn. <p> We use the term gated experts for nonlinear gated nonlinear experts: the input space can be split nonlinearly by using the hidden units of the gating network, and the sub-processes can be nonlinear through the hidden units of the expert networks. In contrast to related work (e.g., <ref> [Hamilton, 1994, Jordan and Jacobs, 1994] </ref>) we allow the noise-level parameter associated with each individual expert to adapt separately to the data. Different regimes can thus be fl http://www.cs.colorado.edu/~andreas/Home.html approximated with different precision. <p> In contrast to gated experts, the splits there are very simple and ad hoc; there is no underlying probabilistic interpretation. 1 More closely related to gated experts are the mixture models of the econometrics community <ref> [Hamilton, 1990, Hamilton, 1994] </ref>. Expressed in connectionist language, the mixture models used there do not have any hidden units: both the gate and all the experts are linear. <p> To our knowledge, neither the double-nonlinear gated experts used here nor the flexible individual noise levels for the different regimes have been used in economics or econometrics <ref> [Granger and Terasvirta, 1993, Hamilton, 1994] </ref>. 2 The rigorous probabilistic interpretation of the linear gated experts fully generalized to the gated experts discussed here. <p> Note that the sum inside the logarithm makes the cost function significantly more complicated than in the case of a single network. Following <ref> [Hamilton, 1994, Jordan and Xu, 1995] </ref>, we now use the Expectation-Maximization algorithm to solve the optimization problem. This algorithm is based on the assumption that some binary variables are missing.
Reference: [Jacobs et al., 1991] <author> Jacobs, R. A., Jordan, M. I., Nowlan, S. J., and Hinton, G. E. </author> <year> (1991). </year> <title> Adaptive mixtures of local experts. </title> <journal> Neural Computation, </journal> <volume> 3 </volume> <pages> 79-87. </pages>
Reference-contexts: They were introduced into the connectionist community as mixture of experts <ref> [Jacobs et al., 1991] </ref>; [Rumelhart et al., 1995] use the term society of experts. The basic idea behind gated experts is simple: rather than using a global model, we try to learn from the data several local models (experts) simultaneously with the splitting of the input space.
Reference: [Jordan and Jacobs, 1994] <author> Jordan, M. I. and Jacobs, R. A. </author> <year> (1994). </year> <title> Hierarchical mixtures of experts and the EM algorithm. </title> <journal> Neural Computation, </journal> <volume> 6 </volume> <pages> 181-214. </pages>
Reference-contexts: We use the term gated experts for nonlinear gated nonlinear experts: the input space can be split nonlinearly by using the hidden units of the gating network, and the sub-processes can be nonlinear through the hidden units of the expert networks. In contrast to related work (e.g., <ref> [Hamilton, 1994, Jordan and Jacobs, 1994] </ref>) we allow the noise-level parameter associated with each individual expert to adapt separately to the data. Different regimes can thus be fl http://www.cs.colorado.edu/~andreas/Home.html approximated with different precision. <p> An important inspiration for our work has been the introduction of mixture models into the connectionist community by Jacobs, Jordan, Nowlan and Hinton (1991), 3 and the convergence proof [Jordan and Xu, 1995]. <ref> [Jordan and Jacobs, 1994] </ref> developed a related architecture of a hierarchical mixture of linear experts (with fixed widths). [Waterhouse and Robinson, 1995] applied this architecture to time series prediction of the sunspots [Weigend et al., 1990, Nowlan and Hinton, 1992] and for nonlinear regression on an example of noise heterogeneity [Weigend
Reference: [Jordan and Xu, 1995] <author> Jordan, M. I. and Xu, L. </author> <year> (1995). </year> <title> Convergence results for the EM approach to mixtures of experts architectures. Neural Networks, </title> <publisher> (in press). </publisher>
Reference-contexts: An important inspiration for our work has been the introduction of mixture models into the connectionist community by Jacobs, Jordan, Nowlan and Hinton (1991), 3 and the convergence proof <ref> [Jordan and Xu, 1995] </ref>. [Jordan and Jacobs, 1994] developed a related architecture of a hierarchical mixture of linear experts (with fixed widths). [Waterhouse and Robinson, 1995] applied this architecture to time series prediction of the sunspots [Weigend et al., 1990, Nowlan and Hinton, 1992] and for nonlinear regression on an example <p> Note that the sum inside the logarithm makes the cost function significantly more complicated than in the case of a single network. Following <ref> [Hamilton, 1994, Jordan and Xu, 1995] </ref>, we now use the Expectation-Maximization algorithm to solve the optimization problem. This algorithm is based on the assumption that some binary variables are missing.
Reference: [Lapedes and Farber, 1987] <author> Lapedes, A. and Farber, R. </author> <year> (1987). </year> <title> Nonlinear signal processing using neural networks. </title> <type> Technical Report LA-UR-87-2662, </type> <institution> Los Alamos National Laboratory, </institution> <address> Los Alamos, NM. </address>
Reference-contexts: 1 Introduction Conventional time series models are global models. They can be linear, assuming that the next is superposition of preceding [Yule, 1927, Chatfield, 1989], or they can be nonlinear, typified as neural networks with hidden units <ref> [Lapedes and Farber, 1987, Weigend et al., 1990] </ref>. Global models are well suited to problems where the underlying dynamics is stationary. However, man real-world time series are not stationary, but rather switch between different regimes.
Reference: [Lewis et al., 1994] <author> Lewis, P. A. W., Ray, B. K., and Stevens, J. G. </author> <year> (1994). </year> <title> Modeling time series using multivariate adaptive regression splines (MARS). </title> <editor> In Weigend, A. S. and Gershenfeld, N. A., editors, </editor> <title> Time Series Prediction: </title> <booktitle> Forecasting the Future and Understanding the Past, </booktitle> <pages> pages 296-318, </pages> <address> Reading, MA. </address> <publisher> Addison-Wesley. </publisher>
Reference-contexts: A more flexible model of multivariate adaptive regression splines (MARS) [Friedman, 1991] has recently been applied to forecasting of financial data <ref> [Lewis et al., 1994] </ref>. 2 The problem of estimating local noise levels is known in the statistics literature as noise heterogeneity [Seber and Wild, 1989].
Reference: [Mangeas et al., 1995] <author> Mangeas, M., Muller, C., and Weigend, A. S. </author> <year> (1995). </year> <title> Forecasting electricity demand using a mixture of nonlinear experts. </title> <booktitle> In World Congress on Neural Networks (WCNN'95). </booktitle>
Reference-contexts: Details are given in <ref> [Mangeas et al., 1995] </ref>.
Reference: [Mangeas and Weigend, 1995] <author> Mangeas, M. and Weigend, A. S. </author> <year> (1995). </year> <title> First experiments using a mixture of nonlinear experts for time series analysis. </title> <booktitle> In World Congress on Neural Networks (WCNN'95). </booktitle>
Reference: [Muller et al., 1994] <author> Muller, K.-R., Kohlmorgen, J., and Pawelzik, K. </author> <year> (1994). </year> <title> Segmentation and identification of switching dynamics with competing neural networks. </title> <booktitle> In Proceedings of International Conference on Neural Information Processing (ICONIP'94), </booktitle> <pages> pages 213-218. </pages>
Reference-contexts: Further related work is [XU, 1994] who applies this architecture to two linear AR (2) processes, and <ref> [Muller et al., 1994] </ref> who use hard competition for a similar task.
Reference: [Nix and Weigend, 1995] <author> Nix, D. A. and Weigend, A. S. </author> <year> (1995). </year> <title> Local error bars for nonlinear regression and time series prediction. </title> <editor> In Tesauro, G., Touretzky, D. S., and Leen, T. K., editors, </editor> <booktitle> Advances in Neural Information Processing Systems 7 (NIPS*94). </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference-contexts: If we allow the width of the Gaussian to become a function of the inputs (e.g., by adding a second output unit to the network to predict the local error bar), we obtain a model for estimating the local noise level <ref> [Weigend and Nix, 1994, Nix and Weigend, 1995] </ref>. 5 In this article the output is a scalar; the generalization to a vector is straightforward. * j is the width of the Gaussian represented by expert j * P (Y = y j x; j) is the probability density associated with the
Reference: [Nowlan and Hinton, 1992] <author> Nowlan, S. J. and Hinton, G. E. </author> <year> (1992). </year> <title> Simplifying neural networks by soft weight-sharing. </title> <journal> Neural Computation, </journal> <volume> 4 </volume> <pages> 473-493. </pages>
Reference-contexts: connectionist community by Jacobs, Jordan, Nowlan and Hinton (1991), 3 and the convergence proof [Jordan and Xu, 1995]. [Jordan and Jacobs, 1994] developed a related architecture of a hierarchical mixture of linear experts (with fixed widths). [Waterhouse and Robinson, 1995] applied this architecture to time series prediction of the sunspots <ref> [Weigend et al., 1990, Nowlan and Hinton, 1992] </ref> and for nonlinear regression on an example of noise heterogeneity [Weigend and Nix, 1994].
Reference: [Perrone, 1994] <author> Perrone, M. P. </author> <year> (1994). </year> <title> General averaging results for complex optimization. </title> <editor> In Mozer, M. C., Smolensky, P., Touretzky, D. S., Elman, J. L., and Weigend, A. S., editors, </editor> <booktitle> Proceedings of the 1993 Connectionist Models Summer School, </booktitle> <pages> pages 364-371, </pages> <address> Hillsdale, NJ. </address> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference-contexts: This allows the experts to specialize and learn the areas of their responsibility, whereas simple averaging (e.g., as in <ref> [Perrone, 1994] </ref>) requires all sub-models to be equally responsible over the entire space. 2 Theory of Gated Experts This section describes the ingredients needed to specify a connectionist model: the architecture (network topology and activations functions), the cost function (in a maximum likelihood framework related to an error model), and the
Reference: [Press et al., 1992] <author> Press, W. H., Flannery, B. P., Teukolsky, S. A., and Vetterling, W. T. </author> <year> (1992). </year> <title> Numerical Recipes in C: </title> <booktitle> The Art of Scientific Computing. </booktitle> <publisher> Cambridge University Press, </publisher> <address> Cambridge. </address>
Reference-contexts: In all of our experiments, the gating network and the expert networks are nonlinear, and we use a second-order method to update the parameters in the M-step (the Broyden-Fletcher-Goldfarb-Shanno algorithm, or BFGS, see <ref> [Press et al., 1992] </ref>).
Reference: [Rumelhart et al., 1995] <author> Rumelhart, D. E., Durbin, R., Golden, R., and Chauvin, Y. </author> <year> (1995). </year> <title> Backpropagation: The basic theory. </title> <editor> In Chauvin, Y. and Rumelhart, D. E., editors, Backpropagation: </editor> <booktitle> Theory, Architectures, and Applications, pages 1-??, </booktitle> <address> Hillsdale, NJ. </address> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference-contexts: They were introduced into the connectionist community as mixture of experts [Jacobs et al., 1991]; <ref> [Rumelhart et al., 1995] </ref> use the term society of experts. The basic idea behind gated experts is simple: rather than using a global model, we try to learn from the data several local models (experts) simultaneously with the splitting of the input space. <p> in 1994. 4 If there is only a single expert and we assume a Gaussian error model with constant noise level (variance), then this is equivalent to minimizing the squared error between the output and the target value (as can be seen by taking the negative logarithm of the Gaussian) <ref> [Rumelhart et al., 1995] </ref>. <p> However, as usual, the by is a deterministic function of the input, and the noise is included in the assumption of an error model <ref> [Rumelhart et al., 1995] </ref>. We now want to evaluate goodness of the model by how well the data are predicted by the model. To be specific, we now assume each experts to describe a Gaussian.
Reference: [Seber and Wild, 1989] <author> Seber, G. A. F. and Wild, C. J. </author> <year> (1989). </year> <title> Nonlinear Regression. </title> <publisher> Wiley, </publisher> <address> New York. </address>
Reference-contexts: A more flexible model of multivariate adaptive regression splines (MARS) [Friedman, 1991] has recently been applied to forecasting of financial data [Lewis et al., 1994]. 2 The problem of estimating local noise levels is known in the statistics literature as noise heterogeneity <ref> [Seber and Wild, 1989] </ref>.
Reference: [Tong and Lim, 1980] <author> Tong, H. and Lim, K. S. </author> <year> (1980). </year> <title> Threshold autoregression, limit cycles and cyclical data. </title> <journal> J. Roy. Stat. Soc. B, </journal> <volume> 42 </volume> <pages> 245-292. </pages>
Reference-contexts: This is done on the task of predicting the electricity demand of France. 1.3 Related Work The idea of splitting an input space into subspaces is not new. In the time series community, one of the first examples is the threshold autoregressive (TAR) model <ref> [Tong and Lim, 1980] </ref>. In contrast to gated experts, the splits there are very simple and ad hoc; there is no underlying probabilistic interpretation. 1 More closely related to gated experts are the mixture models of the econometrics community [Hamilton, 1990, Hamilton, 1994].
Reference: [Waterhouse and Robinson, 1995] <author> Waterhouse, S. R. and Robinson, A. J. </author> <year> (1995). </year> <title> Non-linear prediction of acousitc vectors using hierarchical mixture of epxerts. </title> <editor> In Tesauro, G., Touretzky, D. S., and Leen, T. K., editors, </editor> <booktitle> Advances in Neural Information Processing Systems 7 (NIPS*94). </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference-contexts: important inspiration for our work has been the introduction of mixture models into the connectionist community by Jacobs, Jordan, Nowlan and Hinton (1991), 3 and the convergence proof [Jordan and Xu, 1995]. [Jordan and Jacobs, 1994] developed a related architecture of a hierarchical mixture of linear experts (with fixed widths). <ref> [Waterhouse and Robinson, 1995] </ref> applied this architecture to time series prediction of the sunspots [Weigend et al., 1990, Nowlan and Hinton, 1992] and for nonlinear regression on an example of noise heterogeneity [Weigend and Nix, 1994].
Reference: [Weigend, 1994] <author> Weigend, A. S. </author> <year> (1994). </year> <title> On overfitting and the effective number of hidden units. </title> <editor> In Mozer, M. C., Smolensky, P., Touretzky, D. S., Elman, J. L., and Weigend, A. S., editors, </editor> <booktitle> Proceedings of the 1993 Connectionist Models Summer School, </booktitle> <pages> pages 335-342, </pages> <address> Hillsdale, NJ. </address> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference-contexts: In our experience with flexible neural networks and noisy data, the cost function almost always overfits <ref> [Weigend, 1994] </ref>. The key is to choose the cost function that it learns features that generalize well such that its overfitting has little effect onto the true performance we are interested in.
Reference: [Weigend et al., 1990] <author> Weigend, A. S., Huberman, B. A., and Rumelhart, D. E. </author> <year> (1990). </year> <title> Predicting the future: A connectionist approach. </title> <journal> International Journal of Neural Systems, </journal> <volume> 1 </volume> <pages> 193-209. </pages>
Reference-contexts: 1 Introduction Conventional time series models are global models. They can be linear, assuming that the next is superposition of preceding [Yule, 1927, Chatfield, 1989], or they can be nonlinear, typified as neural networks with hidden units <ref> [Lapedes and Farber, 1987, Weigend et al., 1990] </ref>. Global models are well suited to problems where the underlying dynamics is stationary. However, man real-world time series are not stationary, but rather switch between different regimes. <p> connectionist community by Jacobs, Jordan, Nowlan and Hinton (1991), 3 and the convergence proof [Jordan and Xu, 1995]. [Jordan and Jacobs, 1994] developed a related architecture of a hierarchical mixture of linear experts (with fixed widths). [Waterhouse and Robinson, 1995] applied this architecture to time series prediction of the sunspots <ref> [Weigend et al., 1990, Nowlan and Hinton, 1992] </ref> and for nonlinear regression on an example of noise heterogeneity [Weigend and Nix, 1994]. <p> Distinguishing between the cost function and the performance part is an important degree of freedom in modeling, particularly for short data sets and noisy problems <ref> [Weigend et al., 1990] </ref>. Acknowledgments Applying a Gaussian mixture models to time series analysis was first suggested in 1991 to Andreas Weigend by Steve Nowlan. This material is based upon work supported by the National Science Foundation under Grant No. RIA ECS-9309786 to Andreas Weigend.
Reference: [Weigend and Nix, 1994] <author> Weigend, A. S. and Nix, D. A. </author> <year> (1994). </year> <title> Predictions with confidence intervals (local error bars). </title> <booktitle> In Proceedings of the International Conference on Neural Information Processing (ICONIP'94), </booktitle> <pages> pages 1207-1212, </pages> <address> Seoul, Korea. </address>
Reference-contexts: Section 3 analyzes why the gated experts help avoid overfitting and compares gated experts with a method to determine local error bars introduced in <ref> [Weigend and Nix, 1994] </ref>. This is done on the task of predicting the electricity demand of France. 1.3 Related Work The idea of splitting an input space into subspaces is not new. <p> [Jordan and Jacobs, 1994] developed a related architecture of a hierarchical mixture of linear experts (with fixed widths). [Waterhouse and Robinson, 1995] applied this architecture to time series prediction of the sunspots [Weigend et al., 1990, Nowlan and Hinton, 1992] and for nonlinear regression on an example of noise heterogeneity <ref> [Weigend and Nix, 1994] </ref>. Further related work is [XU, 1994] who applies this architecture to two linear AR (2) processes, and [Muller et al., 1994] who use hard competition for a similar task. <p> If we allow the width of the Gaussian to become a function of the inputs (e.g., by adding a second output unit to the network to predict the local error bar), we obtain a model for estimating the local noise level <ref> [Weigend and Nix, 1994, Nix and Weigend, 1995] </ref>. 5 In this article the output is a scalar; the generalization to a vector is straightforward. * j is the width of the Gaussian represented by expert j * P (Y = y j x; j) is the probability density associated with the <p> The expression in squared brackets, weighted for each experts by its relevance, is identical to the cost function derived in <ref> [Weigend and Nix, 1994] </ref> for the case of predicting local error bars" (i.e., of a network with two output units, one for the conditional mean, the other one for the conditional variance), C LEB = 2 d y (x) 2 (x) # where LEB stands for local error bars.
Reference: [Weigend and Srivastava, 1995] <author> Weigend, A. S. and Srivastava, A. N. </author> <year> (1995). </year> <title> Predicting probability distributions: A connectionist approach. </title> <journal> International Journal of Neural Systems, </journal> <volume> 6. </volume>
Reference-contexts: There are approaches to predicting arbitrary probability densities; the mixture of Gaussians prior to taking the expectation value can be used [Bishop, 1994]; an alternative is the nonparametric fractional binning technique <ref> [Weigend and Srivastava, 1995] </ref>.
Reference: [XU, 1994] <author> XU, L. </author> <year> (1994). </year> <title> Signal segmentation by finite mixture model and EM algorithm. </title> <booktitle> In Proceedings of the 1994 International Symposium on Artificial Neural Networks (ISANN'94), </booktitle> <pages> pages 453-458, </pages> <address> Tainan, Taiwan. </address>
Reference-contexts: Further related work is <ref> [XU, 1994] </ref> who applies this architecture to two linear AR (2) processes, and [Muller et al., 1994] who use hard competition for a similar task.
Reference: [Yule, 1927] <author> Yule, G. </author> <year> (1927). </year> <title> On a method of investigating periodicity in disturbed series with special reference to wolfer's sunspot numbers. </title> <journal> Phil. Trans. Roy. Soc. London, </journal> <volume> A 226 </volume> <pages> 267-298. </pages>
Reference-contexts: 1 Introduction Conventional time series models are global models. They can be linear, assuming that the next is superposition of preceding <ref> [Yule, 1927, Chatfield, 1989] </ref>, or they can be nonlinear, typified as neural networks with hidden units [Lapedes and Farber, 1987, Weigend et al., 1990]. Global models are well suited to problems where the underlying dynamics is stationary.
References-found: 34

