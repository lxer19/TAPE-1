URL: http://www.cs.umd.edu/users/north/mpeg_atm.ps.Z
Refering-URL: http://www.cs.umd.edu/users/north/resume.html
Root-URL: 
Email: north@cs.umd.edu  
Title: MPEG Video and ATM Network Cell Loss: Analysis and Experimentation  
Author: Chris North 
Date: December 5, 1995  
Address: College Park, MD 20742  
Affiliation: Human-Computer Interaction Laboratory Department of Computer Science University of Maryland,  
Abstract: The goal of this paper is to evaluate the effect of ATM network cell loss on the playback quality of transmitted MPEG video. The MPEG format and its susceptibility to data corruption is analyzed to calculate a theoretical statistical data corruption per cell loss measure. Experiments are run using an ATM network simulator with actual MPEG video to measure the effect of cell loss rate and burstiness of losses on resulting playback picture quality. Empirical results of visual information loss rates are presented, and a Human Factors study evaluates viewers subjective satisfaction of resulting picture quality. Results indicate that video quality degrades rapidly as cell loss rate increases, and a 0.1% loss rate provides an effective cutoff point of playback acceptability. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Le Gall; MPEG: </author> <title> A Video Compression Standard for Multimedia Applications; Communications of the ACM, </title> <booktitle> 34(4) </booktitle> <pages> 305-313, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: To achieve this dream of real-time networked video, many researchers believe that the combination of MPEG video compression and high speed ATM networks will provide the solution <ref> [1] </ref>. MPEG, developed by the International Organization for Standardization and named after the Motion Picture Experts Group, is the primary standard for digital coding and compression of motion picture. It is widely acclaimed for its impressive compression capability as well as its flexibility.
Reference: [2] <institution> MPEG-1; Coded Representation of Picture, Audio and Multimedia/Hypermedia Information; ISO/IEC 11172, Geneve Switzerland, </institution> <year> 1993. </year>
Reference-contexts: The standard defines the basic structures and format of the encoding, yet allows encoders enough freedom to tailor the compression to individual videos and applications, such as for intensive editing environments or for storage or transmission on an error-prone system. The MPEG-1 standard <ref> [2] </ref> focuses on a goal of compressing video to a bit rate of 1.5 Mbits/second, while maintaining reasonable picture quality. MPEG-2 builds on MPEG-1, and scales up the encoding to include multiple resolutions, bitrates, qualities, and error resilience [3].
Reference: [3] <institution> MPEG-2; Coded Representation of Picture and Audio Information; ISO/IEC 13818/Draft, Geneve Switzerland, </institution> <month> November </month> <year> 1993. </year>
Reference-contexts: The MPEG-1 standard [2] focuses on a goal of compressing video to a bit rate of 1.5 Mbits/second, while maintaining reasonable picture quality. MPEG-2 builds on MPEG-1, and scales up the encoding to include multiple resolutions, bitrates, qualities, and error resilience <ref> [3] </ref>. The computer systems research community is working heavily on the concept of Asynchronous Transfer Mode (ATM) communications networks [4]. ATM is purported to be the network protocol of the future, which will improve on existing networks in enormous ways.
Reference: [4] <author> Partridge, </author> <title> Craig; Gigabit Networking, </title> <publisher> Addison-Wesley, </publisher> <year> 1993. </year>
Reference-contexts: MPEG-2 builds on MPEG-1, and scales up the encoding to include multiple resolutions, bitrates, qualities, and error resilience [3]. The computer systems research community is working heavily on the concept of Asynchronous Transfer Mode (ATM) communications networks <ref> [4] </ref>. ATM is purported to be the network protocol of the future, which will improve on existing networks in enormous ways. ATM transmissions do not need to be synchronized to a clock.
Reference: [5] <author> Leicher, </author> <title> Christian; Hierarchical Encoding of MPEG Sequences Using Priority Encoding Transmission (PET); The International Computer Science Institute, </title> <address> Berkeley CA; TR-94-058, </address> <month> November </month> <year> 1994. </year>
Reference-contexts: In another method, a higher layer application might specially encode its data with error detection and correction information before it is packetized and transmitted by ATM. Then, the receiver can reconstruct any missing cells data from this redundant information <ref> [5] </ref>. Yet another method is to simply ignore the losses and provide tolerance in the higher level applications that use the incoming data. When sending MPEG encoded video over an ATM network, many of the envisioned future applications will decode and play the video on a real-time basis.
Reference: [6] <author> Patel, Smith, </author> <title> Rowe; Performance of a Software MPEG Video Decoder; University of California at Berkeley; ACM Multimedia Conference, </title> <year> 1993. </year>
Reference-contexts: Ten subjects participated in the experiment. All were graduate or undergraduate students at the University of Maryland and used computers on a daily basis. Each subject performed the experiment individually. The experiment was performed on a Sun SPARCstation 5, using a software MPEG decoder <ref> [6] </ref> for playback. The decoder was only able to play the video at about 1/3 speed, approximately 10 frames per second, instead of the recommended 30 fps, but was able to maintain a smooth playback.
Reference: [7] <author> Shneiderman, </author> <title> Ben; Designing the User Interface: Strategies for Effective Human-Computer Interaction, </title> <publisher> Addison-Wesley, </publisher> <year> 1993. </year>
Reference-contexts: Perhaps human viewers prefer small amounts of noise spread out over a video, rather than sudden large bursts of noise followed by perfect quality video. This coincides well with existing theory in Human Factors and user interface research 17 which indicates that users prefer consistency <ref> [7] </ref>. In fact, users may sacrifice some performance for more consistency.
References-found: 7

