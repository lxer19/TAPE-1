URL: http://www.cs.colostate.edu/~ftppub/TechReports/1996/tr96-130.ps.Z
Refering-URL: http://www.cs.colostate.edu/~ftppub/
Root-URL: 
Email: naixinli@microsoft.com  malaiya@cs.colostate.edu  
Phone: Phone: (970) 491-5792 Fax: (970) 491-2466  
Title: Fault Exposure Ratio Estimation and Applications  
Author: Li Naixin Yashwant K. Malaiya 
Note: This research was supported by a BMDO funded project monitored by ONR  
Web: WWW: http://www.cs.colostate.edu  
Address: One Microsoft Way Redmond WA 98052  Fort Collins, CO 80523  Fort Collins, CO 80523-1873  
Affiliation: Computer Science  Microsoft Corp.  Computer Science Dept. Colorado State University  Computer Science Department Colorado State University  
Pubnum: Technical Report  Technical Report CS-96-130  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> J. D. Musa, A. Iannino, K. Okumoto, </author> <title> Software Reliability Measurement, Prediction, Applications, </title> <publisher> McGraw-Hill, </publisher> <year> 1987. </year>
Reference-contexts: The data collected by Musa <ref> [1] </ref> shows that the number of additional faults introduced during the debugging process is only about 5%. Thus fi E 0 may be estimated as the initial number of faults. <p> Once we know the value of K, fi E 1 can be estimated using, fi E K (2) where T L is the linear execution time <ref> [1] </ref>, given by T L = I s Q r 1 r ; I s is the number of source lines of code; Q r is the average object instructions per source statement; r is the CPU instruction execution rate. <p> Once we have done that, we can empirically estimate FER and hence the defect removal rate. We will also be able to assess the potential techniques for enhancing the defect removal rate. The researchers have considered the following as possible factors. Program Structure: Musa et al. <ref> [1] </ref> have speculated that FER may depend on the program structure in some way. However, they suggested that for large programs, the "structuredness" (as measured by decision density) may be average out. [1]. von Mayrhauser and Teresinki [11] have suggested that FER may depend on static metrics like "loopiness" and "branchiness" <p> The researchers have considered the following as possible factors. Program Structure: Musa et al. <ref> [1] </ref> have speculated that FER may depend on the program structure in some way. However, they suggested that for large programs, the "structuredness" (as measured by decision density) may be average out. [1]. von Mayrhauser and Teresinki [11] have suggested that FER may depend on static metrics like "loopiness" and "branchiness" of the program. However, because of lack of sufficient data, the results are not conclusive [12]. <p> Another possibility is that some faults may block access to some other faults, and thus removal of some faults may allow more faults to become accesible. The logarithmic model, has been shown to have higher predictive capability in general than other two-parameter software reliability models by several researchers <ref> [14, 1, 7] </ref>. Malaiya et al [7] have shown using a number of diverse data sets that the superiority of the logarithmic model is statistically significant. <p> Trachtenberg [15] proposed a software reliability model based on Zipf's law which fitted Adam's reliability data with an very high correlation coefficient. If we regard the testing phase as a compressed form of operational use <ref> [1] </ref>, then the failure rates for different defects during the testing phase may also have similar distribution for different software projects. Further we suspect that at the beginning of system testing phase, the detectability profiles [3] of software projects may have similar shapes in accordance with the Zipf's law. <p> Let us assume that Equation 19 is applicable when when instead of instantaneous values K and D, we use their average values ^ K and ^ D, averaged over the test duration. Then we can write: ^ K = ^ D In Musa et al <ref> [1] </ref>, the values of EFER were computed assuming the exponential model. <p> The available data suggests that it occurs at about D 0 = 5. This corresponds to the minimum at approximately D = 5 fi 0:39 = 2. Further studies are needed to see if the two parameters vary with variation in the testing practices. Table 1, obtained using <ref> [1] </ref>, relates initial defect density and overall fault exposure ratio. Here 10% of the total initial defects are assumed to be present by the end of the testing phase. Table 1: ^ K vs. D 0 [1] ( ^ K in units of 10 7 ) Data Size (K) D 0 <p> Table 1, obtained using <ref> [1] </ref>, relates initial defect density and overall fault exposure ratio. Here 10% of the total initial defects are assumed to be present by the end of the testing phase. Table 1: ^ K vs. D 0 [1] ( ^ K in units of 10 7 ) Data Size (K) D 0 ^ K T1 21.7 6.89 1.87 T3 23.4 1.79 4.11 T5 2445 0.374 4.2 T16 126.1 0.357 3.03 T20 115.35 20.89 6.5 Using the form as given in Equation 16 and using the data given in
Reference: [2] <author> J. D. Musa, </author> <title> Rationale for Fault Exposure Ratio K, </title> <journal> ACM SIGSOFT Software Engineering News, </journal> <month> July </month> <year> 1991, </year> <pages> pp. 79. </pages>
Reference-contexts: Further studies are needed to see if the program structure has any influence on the FER. Program Size: Musa has also presented reasons why FER should be independent of program size <ref> [2] </ref>. Testing effectiveness: Malaiya et al. [3] have suggested that test strategies cause FER to vary. Since real testing is not random but directed, it becomes more effective in comparison with random testing as testing progresses. Their analysis of several data sets supports this hypothesis.
Reference: [3] <author> Y. K. Malaiya, A. von Mayrhauser and P. K. Srimani, </author> <title> The Nature of Fault Exposure Ratio, </title> <booktitle> Proc. International Symposium on Software Reliability Engineering, </booktitle> <month> October </month> <year> 1992, </year> <pages> pp. 23-32. </pages>
Reference-contexts: However, because of lack of sufficient data, the results are not conclusive [12]. Malaiya et al. <ref> [3] </ref> have identified a factor that depends on the program structure, but they show that its affect is counterbalanced by another factor, and thus FER should be relatively unchanged with program structure. Further studies are needed to see if the program structure has any influence on the FER. <p> Further studies are needed to see if the program structure has any influence on the FER. Program Size: Musa has also presented reasons why FER should be independent of program size [2]. Testing effectiveness: Malaiya et al. <ref> [3] </ref> have suggested that test strategies cause FER to vary. Since real testing is not random but directed, it becomes more effective in comparison with random testing as testing progresses. Their analysis of several data sets supports this hypothesis. <p> We next discuss how this model can be used in software reliability engineering. 2 Variation of FER with Fault Density The detectability of a fault is defined as the probability that the fault is detected by a randomly selected test input <ref> [3] </ref>. For truly random testing, faults with high detectability tends to be detected earlier in time, so FER should in general decline with time. However experiments with real reliability data indicates a reversal of this trend at low defect densities [3]. <p> the fault is detected by a randomly selected test input <ref> [3] </ref>. For truly random testing, faults with high detectability tends to be detected earlier in time, so FER should in general decline with time. However experiments with real reliability data indicates a reversal of this trend at low defect densities [3]. One possible explanation for this phenomenon is that at the later stages of the testing phase testing becomes more and more directed, rather than being random. <p> In <ref> [3] </ref> it is shown that the general trend observed for FER is consistent with what would be expected for a process obeying the logarithmic model. In order to relate FER to the test stage, we need a quantitative metric that measures the stage of testing. <p> Here we use defect density as a measure of the test stage, because it is independent of the project to project variation of the specific stage at which a given test phase begins. An expression for FER in terms of the testing time is derived in <ref> [3] </ref>. Here we will obtain an expression for FER in term of the fault density D, which is a function of the testing time t. <p> If we regard the testing phase as a compressed form of operational use [1], then the failure rates for different defects during the testing phase may also have similar distribution for different software projects. Further we suspect that at the beginning of system testing phase, the detectability profiles <ref> [3] </ref> of software projects may have similar shapes in accordance with the Zipf's law. If the testing activity is conducted in the same way, FER would be primarily determined by the detectability profile. <p> If the testing activity is conducted in the same way, FER would be primarily determined by the detectability profile. In case of truly random testing, FER would be an weighted average of the detectability of each individual fault <ref> [3] </ref>. Here we will obtain a form of Equation 19 that will relate the FER to the initial defect density. The exponential model assumes that FER does not change over time. The exponential model can be considered to be an approximation of the logarithmic model. <p> When enough actual failure data from system testing phase is available, one might consider to use real data and the logarithmic model to get a more accurate projection. A possible procedure to estimate the parameters of the logarithmic model can be based on the results obtained in <ref> [3] </ref>. A model relating FER with time as described by Equation 40 was proposed which characterizes the variation of FER with time t. K (t) = N (t)(1 + at) where a is a parameter depending on the "detectability profile" of the software [3]. <p> be based on the results obtained in <ref> [3] </ref>. A model relating FER with time as described by Equation 40 was proposed which characterizes the variation of FER with time t. K (t) = N (t)(1 + at) where a is a parameter depending on the "detectability profile" of the software [3]. From this model we can derive the well-known logarithmic software reliability growth model with the following interpretation for the parameters: fi L K 0 N 0 (41) 1 = a (42) The problem of estimating the parameter a need to be further investigated. <p> Obtain average of failure intensity. This provides an estimate of 0 = fi E 0 fi E 2. Empirically estimate FER and hence fi E 1 . 3. Obtain an estimate for fi E 0 as 0 =fi E For the logarithmic model, we can use results from <ref> [3] </ref>, where the parameter fi L 0 was related to initial fault exposure ratio K 0 and fi L 1 .
Reference: [4] <author> Y. K. Malaiya, A. von Mayrhauser and P. K. Srimani, </author> <title> An Examination of Fault Exposure Ratio, </title> <journal> IEEE Trans. Software Engineering, </journal> <month> Nov. </month> <year> 1993, </year> <pages> pp. 1087-1094. </pages>
Reference-contexts: If N (t) is the total number of defects still present at time t, we can show that <ref> [4] </ref>, dN (t) = T L Thus the defect finding rate dN (t) dt is proportional to the fault exposure ratio. <p> The data sets in Table 1 were collected at AT&T. High quality data sets that are available in the literature are still limited. In <ref> [4] </ref>, several other data sets were examined. When the variation of K within one AT&T data set was examined, it showed a minimum at density value 2.
Reference: [5] <author> Y. K. Malaiya, </author> <title> Early Characterization of the Defect Removal Process, </title> <booktitle> Proc. 9th Annual Software Reliability Symposium, </booktitle> <month> May </month> <year> 1991, </year> <pages> pp. </pages> <month> 6.1-6.4. </month>
Reference-contexts: An alternative way to estimate the parameters of the logarithmic model is to first estimate the parameters of the exponential model, and then use them to obtain the parameters of the logarithmic model. An approximate procedure is given in <ref> [5] </ref> 4.2 Stabilizing parameters in early test stages When failure intensity is plotted against time, it shows a lot of noise superimposed over the long term trend. When sufficient number of data points are available, we can extract the long-term trend as described by a suitable SRGM.
Reference: [6] <author> Y. K. Malaiya, A. von Mayrhauser and P.K. Srimani, </author> <title> The Constant Per Fault Hazard Rate Assumption, </title> <booktitle> Proc. 2nd Bellcore/Purdue Workshop on Issues in Software Reliability Estimation, </booktitle> <month> October, </month> <year> 1992, </year> <pages> pp. 1-9. </pages>
Reference: [7] <author> Y. K. Malaiya, N. Karunanithi and P. Verma, </author> <title> Predictability of Software Reliability Models, </title> <journal> IEEE Trans. Reliability, </journal> <month> December </month> <year> 1992, </year> <pages> pp. 539-546. </pages>
Reference-contexts: Another possibility is that some faults may block access to some other faults, and thus removal of some faults may allow more faults to become accesible. The logarithmic model, has been shown to have higher predictive capability in general than other two-parameter software reliability models by several researchers <ref> [14, 1, 7] </ref>. Malaiya et al [7] have shown using a number of diverse data sets that the superiority of the logarithmic model is statistically significant. <p> The logarithmic model, has been shown to have higher predictive capability in general than other two-parameter software reliability models by several researchers [14, 1, 7]. Malaiya et al <ref> [7] </ref> have shown using a number of diverse data sets that the superiority of the logarithmic model is statistically significant.
Reference: [8] <author> G. A. Kruger, </author> <title> Validation and Further Application of Software Reliability Growth Models, </title> <journal> Hewlett-Packard Journal, </journal> <month> April </month> <year> 1989, </year> <pages> pp. 75-79. </pages>
Reference-contexts: The data collected by Musa [1] shows that the number of additional faults introduced during the debugging process is only about 5%. Thus fi E 0 may be estimated as the initial number of faults. It has been observed <ref> [8] </ref> that in an organization, the defect density (measured in defects/thousand lines of code) at the beginning of the system test phase does not vary significantly and thus may be estimated with acceptable accuracy.
Reference: [9] <author> M. Takahashi and Y. Kamayachi, </author> <title> An Empirical Study of a Model for Program Error Prediction, in Software Reliability Models, </title> <publisher> IEEE Computer Society, </publisher> <year> 1991. </year> <pages> pp. 71-77. </pages>
Reference-contexts: Empirical methods to estimate defect density using programmer skill etc. have also been proposed <ref> [9, 10, 16] </ref>. The estimation of the other parameter fi E 1 is more complex. <p> Further research is needed to identify and quantify the effect of other factors so that K or ^ K may be estimated more accurately, just as the frequency of specification changes, etc. can enhance the accuracy of estimating the total number of defects <ref> [9] </ref>. The model can be refined further when additional data is available. If there is data available to relate K to D, then we can estimate ^ K and hence the parameter 0 of the logarithmic model (ref. Equation 45) at the beginning of system testing phase.
Reference: [10] <author> T. M. Khoshgoftar and J. C. Munson, </author> <title> The Line of Code Metric as a Predictor of Program Faults: a Critical Analysis, </title> <booktitle> Proc. COMPSAC'90, </booktitle> <pages> pp. 408-413. </pages>
Reference-contexts: Empirical methods to estimate defect density using programmer skill etc. have also been proposed <ref> [9, 10, 16] </ref>. The estimation of the other parameter fi E 1 is more complex.
Reference: [11] <author> A. von Mayrhauser and J. A. Teresinki, </author> <title> The Effects of Static Code Metrics on Dynamic Software Reliability Models, </title> <booktitle> Proc. of Symposium on Software Reliability Engineering, </booktitle> <month> April, </month> <year> 1990, </year> <pages> pp. </pages> <month> 19.1-19.13. </month>
Reference-contexts: Program Structure: Musa et al. [1] have speculated that FER may depend on the program structure in some way. However, they suggested that for large programs, the "structuredness" (as measured by decision density) may be average out. [1]. von Mayrhauser and Teresinki <ref> [11] </ref> have suggested that FER may depend on static metrics like "loopiness" and "branchiness" of the program. However, because of lack of sufficient data, the results are not conclusive [12].
Reference: [12] <author> J. M. Keables, </author> <title> Program Structure and Dynamic Models in Software Reliability: Investigation in a Simulated Environment, </title> <type> Ph.D Dissertation, </type> <institution> Computer Science Dept., Illinois Institute of Technology, </institution> <year> 1991. </year>
Reference-contexts: However, because of lack of sufficient data, the results are not conclusive <ref> [12] </ref>. Malaiya et al. [3] have identified a factor that depends on the program structure, but they show that its affect is counterbalanced by another factor, and thus FER should be relatively unchanged with program structure.
Reference: [13] <author> E. N. Adams, </author> <title> Optimizing Preventive Service of Software Products, </title> <journal> IBM Journal of Research and Development, </journal> <volume> vol. 28, no. 1, </volume> <month> January </month> <year> 1984, </year> <month> pp.2-14. </month>
Reference-contexts: Figure 2 is a plot of ln (KD) against D. These plots can be used to compare actual variation in FER in a specific case against the behavior predicted by Equation 19. 3 Estimation of Fault Exposure Ratio Adams <ref> [13] </ref> noticed that software's failure rates in operational phase had a distribution which observes Zipf's law, the failure rate of a fault i is inversely proportional to a power of i, when faults are ranked by decreasing failure rate [15].
Reference: [14] <author> W. H. Farr, </author> <title> A survey of Software Reliability Modeling and Estimation, Naval Surface Weapons Center, </title> <type> TR 82-171, </type> <month> Sept. </month> <year> 1983. </year>
Reference-contexts: Another possibility is that some faults may block access to some other faults, and thus removal of some faults may allow more faults to become accesible. The logarithmic model, has been shown to have higher predictive capability in general than other two-parameter software reliability models by several researchers <ref> [14, 1, 7] </ref>. Malaiya et al [7] have shown using a number of diverse data sets that the superiority of the logarithmic model is statistically significant.
Reference: [15] <author> M. Trachtenberg, </author> <title> Why Failure Rates Observe Zipf's Law in Operational Software, </title> <journal> IEEE Trans. Reliability, </journal> <volume> vol. 41, no. 3, </volume> <month> September </month> <year> 1992, </year> <pages> pp. 386-389. </pages>
Reference-contexts: predicted by Equation 19. 3 Estimation of Fault Exposure Ratio Adams [13] noticed that software's failure rates in operational phase had a distribution which observes Zipf's law, the failure rate of a fault i is inversely proportional to a power of i, when faults are ranked by decreasing failure rate <ref> [15] </ref>. Trachtenberg [15] proposed a software reliability model based on Zipf's law which fitted Adam's reliability data with an very high correlation coefficient. <p> Equation 19. 3 Estimation of Fault Exposure Ratio Adams [13] noticed that software's failure rates in operational phase had a distribution which observes Zipf's law, the failure rate of a fault i is inversely proportional to a power of i, when faults are ranked by decreasing failure rate <ref> [15] </ref>. Trachtenberg [15] proposed a software reliability model based on Zipf's law which fitted Adam's reliability data with an very high correlation coefficient.
Reference: [16] <author> N. Li and Y.K. Malaiya, </author> <title> ROBUST: A Next Generation Software Reliability Engineering Tool, </title> <booktitle> Proc. IEEE Int. Symp. on Software Reliability Engineering, </booktitle> <pages> pp. 375-380, </pages> <month> Oct. </month> <year> 1995. </year>
Reference-contexts: Empirical methods to estimate defect density using programmer skill etc. have also been proposed <ref> [9, 10, 16] </ref>. The estimation of the other parameter fi E 1 is more complex.
Reference: [17] <author> Y.K. Malaiya, N. Li, J. Bieman, R. Karcich and B. Skibbe, </author> <title> The Relationship between Test Coverage and Reliability, </title> <booktitle> Proc. Int. Symp. Software Reliability Engineering, </booktitle> <month> Nov. </month> <year> 1994, </year> <month> pp.186-195. </month>
Reference-contexts: This can be used to stabilize the use of the logarithmic model in the very early phases of testing. 4.3 Coverage based modeling In <ref> [17] </ref>, a model is presented that computes the defect coverage C 0 in terms of a software test coverage measure C i which may be one of block coverage, branch coverage, p-use coverage etc. <p> This approach models coverage of an enumerable (like a branch or a p-use) just like coverage of a defect. The superscript 0 indicates defects and superscript i indicates one of the test enumerables. The first parameter of Equation 46 then is <ref> [17] </ref>, p i K 0 (0) (47) Estimation of a i remains an open problem. The third parameter is given by, p i a i T L (48) This allows the possibility of empirically estimating two of the parameters. These values then can be used as initial estimates.
References-found: 17

