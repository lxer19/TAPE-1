URL: ftp://ftp.cs.indiana.edu/pub/techreports/TR375.ps.Z
Refering-URL: http://www.cs.indiana.edu/trindex.html
Root-URL: 
Title: Toward a Basis for Protocol Specification and Process Decomposition  
Author: Kamlesh Rath and Steven D. Johnson 
Note: To appear in the proceedings of the 1993 IFIP Conference on Hardware Description Languages and their Applications (CHDL '93), Ottawa, Canada, April, 1993, Elsevier.  
Date: 375  june 1993  
Affiliation: indiana university computer science department  
Pubnum: technical report no.  
Abstract-found: 0
Intro-found: 1
Reference: 1. <author> G. Borriello. </author> <title> Specification and synthesis of interface logic. </title> <booktitle> High-Level VLSI Synthesis, </booktitle> <pages> pages 153-176, </pages> <year> 1991. </year>
Reference-contexts: In a related discussion of interface specification, Boriello points out that, "the interface component has received limited attention even though it is crucial to integrating the circuit into an environment that will put it to use" <ref> [1] </ref>. However, while Boriello develops external interface specifications as a means to guide synthesis, our goal is to use them to guide design decomposition. Both sides of the protocol are involved in factoring nontrivial sequential components.
Reference: 2. <author> Tam Anh Chu. </author> <title> Synthesis of self timed VLSI circuits from graph theoritic specifications. </title> <booktitle> In Intl. Workshop on Petri Nets and Performance Models, </booktitle> <month> August </month> <year> 1987. </year>
Reference-contexts: Most formal treatments of sequential decomposition are bottom-up in the sense that they are oriented toward post-design verification. This would include most of the recent research in finite-state machine verification [3]; extensions of FSM models (e.g. [25, 24]) and Petri net theories (e.g. <ref> [2] </ref>); and model-theoretic work involving process formalisms (e.g. [20, 9]). It is typical that an area of verification research would have this orientation, and also that the top-down view would be better represented in synthesis research.
Reference: 3. <author> Ed Clarke, D. Dill, J. Burch, K. L. McMillan, and L. J. Hwang. </author> <title> Symbolic model checking: 10**20 states and beyond. </title> <booktitle> In International Workshop on Formal Methods in VLSI Design. </booktitle> <address> ACM-SIGDA, </address> <month> January </month> <year> 1991. </year>
Reference-contexts: Both sides of the protocol are involved in factoring nontrivial sequential components. Most formal treatments of sequential decomposition are bottom-up in the sense that they are oriented toward post-design verification. This would include most of the recent research in finite-state machine verification <ref> [3] </ref>; extensions of FSM models (e.g. [25, 24]) and Petri net theories (e.g. [2]); and model-theoretic work involving process formalisms (e.g. [20, 9]). It is typical that an area of verification research would have this orientation, and also that the top-down view would be better represented in synthesis research.
Reference: 4. <author> Bruce S. Davie. </author> <title> A Formal, Hierarchical Design and Validation Methodology for VLSI. </title> <type> PhD thesis, </type> <institution> University of Edinburgh, </institution> <year> 1988. </year>
Reference-contexts: Kurshan uses L-automata with language and process homomorphism [18] to verify reactive systems by stepwise reduction and refinement. He uses a bottom-up model with registers and controllers as processes at the lowest level and constructs complex systems by composing them. Davie <ref> [4] </ref> takes a top-down approach to design using verification between specification and implementation steps in CIRCAL [21]. Design partitioning is done by description of components and composing them for verification with respect to the specification.
Reference: 5. <author> Bruce S. Davie and George J. Milne. </author> <title> Contextual constraints for design and verification. </title> <editor> In Birtwistle and Subramanyam, editors, </editor> <booktitle> VLSI Specification, Verification and Synthesis, </booktitle> <pages> pages 257-265. </pages> <publisher> Kluwer, </publisher> <year> 1988. </year>
Reference-contexts: Contextual constraints, restrictions imposed by a device on its environment, are introduced to write partial specifications of a component's environment. The constraints are also used to restrict the target architecture to reduce the complexity of verification <ref> [5] </ref>. A CIRCAL 2 based transformation to partition a design is mentioned. The designer specifies a com-ponent and an algorithm is used to generate the specification of the other component (s) in the design.
Reference: 6. <author> S. Devadas and K. Keutzer. </author> <title> An Automata-Theoretic Approach to Behavioral Equivalence. </title> <booktitle> In Proceedings of the International Conference on Computer-Aided Design, </booktitle> <pages> pages 30-33, </pages> <month> November </month> <year> 1990. </year>
Reference-contexts: For simple expressions this is done by textual comparison. In general this involves verification of equivalence of logical and arithmetic expressions, and is a heuristic task <ref> [6] </ref>. Let ^u, ^v be the values in registers u, v before the procedures u = u 1 and v = u fl v in the original fac.
Reference: 7. <author> David L. Dill, Alan J. Hu, and Howard Wong-Toi. </author> <title> Checking for language inclusion using simulation preorders. </title> <editor> In Larsen and Skou, editors, </editor> <booktitle> Proceedings of Computer Aided Verification, </booktitle> <pages> pages 255-265. </pages> <publisher> Springer, </publisher> <month> July </month> <year> 1991. </year> <note> LNCS 575. </note>
Reference-contexts: In addition to Boriello's work (cited above), approaches to scheduling by Ku, Micheli [17] and Nestor et.al [22] have considered protocol-like constraints. Dill et.al have used a Buchi automata based model to verify safety and liveness properties using language containment <ref> [7] </ref>. McMillan and Dill have also modelled timing constraints as min/max constraints and used a generalized branch and bound algorithm to verify the timing specification of connected components [19]. Drusinsky and Harel have used state-charts for hierarchical description for hardware and synthesis of component machines [8].
Reference: 8. <author> Doron Drusinsky and David Harel. </author> <title> Using statecharts for hardware description and synthesis. </title> <journal> Transactions on CAD, </journal> <volume> 8(7) </volume> <pages> 798-807, </pages> <month> July </month> <year> 1989. </year>
Reference-contexts: McMillan and Dill have also modelled timing constraints as min/max constraints and used a generalized branch and bound algorithm to verify the timing specification of connected components [19]. Drusinsky and Harel have used state-charts for hierarchical description for hardware and synthesis of component machines <ref> [8] </ref>. Holzmann formulated search heuristics to reduce the search space and time for validation of communication protocols [10]. Kurshan uses L-automata with language and process homomorphism [18] to verify reactive systems by stepwise reduction and refinement.
Reference: 9. <author> Ganesh C. Gopalakrishnan, Richard M. Fujimoto, Venkatesh Akella, and Narayana S. Mani. HOP: </author> <title> A process model for synchronous hardware; semantics and experiments in process composition. Integration, </title> <journal> the VLSI journal, </journal> <volume> 8 </volume> <pages> 209-247, </pages> <year> 1989. </year>
Reference-contexts: This would include most of the recent research in finite-state machine verification [3]; extensions of FSM models (e.g. [25, 24]) and Petri net theories (e.g. [2]); and model-theoretic work involving process formalisms (e.g. <ref> [20, 9] </ref>). It is typical that an area of verification research would have this orientation, and also that the top-down view would be better represented in synthesis research. In addition to Boriello's work (cited above), approaches to scheduling by Ku, Micheli [17] and Nestor et.al [22] have considered protocol-like constraints. <p> If hf 1 ; f 2 i 62 S then (M 1 k M 2 ) N is considered unsafe. The construction of the composed machine above is similar to the "lock-step cartesian product" in HOP <ref> [9] </ref>. 12 5.4. Complementation The complement of a machine M defines its environment machine M . The complement of a machine can also be constructed from its state diagram. This is done by changing all input ports to output ports and vice versa.
Reference: 10. <author> Gerard J. Holzmann. </author> <title> Tracing protocols. </title> <editor> In Yemini, editor, </editor> <booktitle> Current Advances in Distributed Computing and Communications, </booktitle> <pages> pages 189-207. </pages> <publisher> Computer Science Press Inc, </publisher> <year> 1987. </year>
Reference-contexts: Drusinsky and Harel have used state-charts for hierarchical description for hardware and synthesis of component machines [8]. Holzmann formulated search heuristics to reduce the search space and time for validation of communication protocols <ref> [10] </ref>. Kurshan uses L-automata with language and process homomorphism [18] to verify reactive systems by stepwise reduction and refinement. He uses a bottom-up model with registers and controllers as processes at the lowest level and constructs complex systems by composing them.
Reference: 11. <author> J.E. Hopcroft and J.D. Ullman. </author> <title> Introduction to Automata Theory, Languages and Computation. </title> <publisher> Addison Wesley, </publisher> <year> 1979. </year>
Reference-contexts: The complement operation is used to create the environment machine. 5.1. Minimization A machine can be minimized by going through iterations of collapsing equivalent states and removing redundant transitions until no states or transitions can be removed. The minimization algorithm for finite state automata described in <ref> [11] </ref> can be used here. 10 Two states are equivalent if all the transitions from one state have the same label and equivalent target as the transitions from the other state.
Reference: 12. <author> Steven D. Johnson. </author> <title> Applicative programming and digital design. </title> <booktitle> In Proceedings of 11th Annual SIGACT-SIGPLAN Symposium on Principles of Programming Languages, </booktitle> <pages> pages 218-227, </pages> <year> 1984. </year>
Reference-contexts: 1. Introduction Design derivation is a branch of formal verification that deals with "correct by construction" reasoning. <ref> [12, 14, 15, 13] </ref>. A system of equivalence preserving transformations are used to derive an implementation from a specification. We can view such a derivation as a formal proof reflecting a top-down reasoning style.
Reference: 13. <author> Steven D. Johnson. </author> <title> Synthesis of Digital Designs from Recursion Equations. </title> <publisher> MIT Press, </publisher> <address> Cambridge, </address> <year> 1984. </year> <note> ACM Distinguished Dissertation 1984. </note>
Reference-contexts: 1. Introduction Design derivation is a branch of formal verification that deals with "correct by construction" reasoning. <ref> [12, 14, 15, 13] </ref>. A system of equivalence preserving transformations are used to derive an implementation from a specification. We can view such a derivation as a formal proof reflecting a top-down reasoning style.
Reference: 14. <author> Steven D. Johnson. </author> <title> Manipulating logical organization with system factorizations. </title> <editor> In Leeser and Brown, editors, </editor> <title> Hardware Specification, Verification and Synthesis: </title> <booktitle> Mathematical Aspects, volume 408 of LNCS, </booktitle> <pages> pages 260-281. </pages> <publisher> Springer, </publisher> <month> July </month> <year> 1989. </year> <booktitle> Proceedings of Mathematical Sciences Institute Workshop, </booktitle> <institution> Cornell University, </institution> <year> 1989. </year>
Reference-contexts: 1. Introduction Design derivation is a branch of formal verification that deals with "correct by construction" reasoning. <ref> [12, 14, 15, 13] </ref>. A system of equivalence preserving transformations are used to derive an implementation from a specification. We can view such a derivation as a formal proof reflecting a top-down reasoning style. <p> We have used the same kind of algebra at a higher level to deal with data abstraction in structural descriptions. A general transformation called system factorization <ref> [14] </ref> is applied to encapsulate abstract values and operations as simple sequential processes. These transformations are strong enough to replace abstract memory values in a design, with black-box SRAMs, for example [14], but they need to be further generalized to replace memories with DRAMs. <p> A general transformation called system factorization <ref> [14] </ref> is applied to encapsulate abstract values and operations as simple sequential processes. These transformations are strong enough to replace abstract memory values in a design, with black-box SRAMs, for example [14], but they need to be further generalized to replace memories with DRAMs. Such a transformation would have to incorporate the read/write protocol and account for refresh cycles.
Reference: 15. <author> Steven D. Johnson and Bhaskar Bose. </author> <title> A system for mechanized digital design derivation. </title> <editor> In Subramanyam, editor, </editor> <booktitle> Proceedings of ACM International Workshop on Formal Methods in VLSI Design, </booktitle> <month> January </month> <year> 1991. </year>
Reference-contexts: 1. Introduction Design derivation is a branch of formal verification that deals with "correct by construction" reasoning. <ref> [12, 14, 15, 13] </ref>. A system of equivalence preserving transformations are used to derive an implementation from a specification. We can view such a derivation as a formal proof reflecting a top-down reasoning style.
Reference: 16. <author> Steven D. Johnson, R.M. Wehrmeister, and B. Bose. </author> <title> On the interplay of synthesis and verification: Experiments with the FM8501 processor description. </title> <editor> In Claesen, editor, </editor> <booktitle> Applied Formal Methods for Correct VLSI Design, </booktitle> <pages> pages 385-404. </pages> <publisher> Elsevier, </publisher> <month> 17 </month> <year> 1989. </year> <month> IMEC </month> <year> 1989. </year>
Reference-contexts: We can view such a derivation as a formal proof reflecting a top-down reasoning style. In this respect it should not be viewed as an alternative for deductive (i.e., conventional theorem-prover based) verification but as an alternate mode of reasoning in design <ref> [16, 26] </ref>. We can also view derivation as a formalization of synthesis, but as a formalization it is more centrally concerned with correctness in reasoning than with automated design. <p> Such a transformation would have to incorporate the read/write protocol and account for refresh cycles. Another example of the problem is described in <ref> [16] </ref>, where the derivation of a microprocessor implementation required moving a naive functional model of memory to a process model with indefinite wait states. We think that this is also one of the key problems in raising synthesis to the system level.
Reference: 17. <author> David Ku and Giovanni De Micheli. </author> <title> Relative scheduling under timing constraints. </title> <booktitle> In Proceedings of ACM/IEEE Design Automation Conference, </booktitle> <month> June </month> <year> 1990. </year>
Reference-contexts: It is typical that an area of verification research would have this orientation, and also that the top-down view would be better represented in synthesis research. In addition to Boriello's work (cited above), approaches to scheduling by Ku, Micheli <ref> [17] </ref> and Nestor et.al [22] have considered protocol-like constraints. Dill et.al have used a Buchi automata based model to verify safety and liveness properties using language containment [7].
Reference: 18. <author> R. P. Kurshan. </author> <title> Analysis of discrete event simulation. </title> <editor> In Bakker, Roever, and Rozen-berg, editors, </editor> <booktitle> Stepwise Refinement of Distributed Systems, </booktitle> <pages> pages 414-453. </pages> <publisher> Springer-Verlag, </publisher> <month> July </month> <year> 1989. </year> <note> LNCS 430. </note>
Reference-contexts: Drusinsky and Harel have used state-charts for hierarchical description for hardware and synthesis of component machines [8]. Holzmann formulated search heuristics to reduce the search space and time for validation of communication protocols [10]. Kurshan uses L-automata with language and process homomorphism <ref> [18] </ref> to verify reactive systems by stepwise reduction and refinement. He uses a bottom-up model with registers and controllers as processes at the lowest level and constructs complex systems by composing them. Davie [4] takes a top-down approach to design using verification between specification and implementation steps in CIRCAL [21].
Reference: 19. <author> Kenneth L. McMillan and David L. Dill. </author> <title> Algorithms for interface timing verification. </title> <booktitle> In Proceedings of IEEE International Conference on Computer Design, </booktitle> <pages> pages 48-51. </pages> <publisher> IEEE Computer Society, </publisher> <month> November </month> <year> 1992. </year>
Reference-contexts: Dill et.al have used a Buchi automata based model to verify safety and liveness properties using language containment [7]. McMillan and Dill have also modelled timing constraints as min/max constraints and used a generalized branch and bound algorithm to verify the timing specification of connected components <ref> [19] </ref>. Drusinsky and Harel have used state-charts for hierarchical description for hardware and synthesis of component machines [8]. Holzmann formulated search heuristics to reduce the search space and time for validation of communication protocols [10].
Reference: 20. <author> George J. Milne. CIRCAL: </author> <title> A calculus for circuit description. </title> <journal> Integration, </journal> <volume> 1 </volume> <pages> 121-160, </pages> <year> 1983. </year>
Reference-contexts: This would include most of the recent research in finite-state machine verification [3]; extensions of FSM models (e.g. [25, 24]) and Petri net theories (e.g. [2]); and model-theoretic work involving process formalisms (e.g. <ref> [20, 9] </ref>). It is typical that an area of verification research would have this orientation, and also that the top-down view would be better represented in synthesis research. In addition to Boriello's work (cited above), approaches to scheduling by Ku, Micheli [17] and Nestor et.al [22] have considered protocol-like constraints.
Reference: 21. <author> George J. Milne. </author> <title> Design for verifiability. </title> <editor> In Leeser and Brown, editors, </editor> <title> Hardware Specification, Verification and Synthesis: </title> <journal> Mathematical Aspects, </journal> <pages> pages 1-13. </pages> <publisher> Springer, </publisher> <month> July </month> <year> 1989. </year> <note> LNCS 408. </note>
Reference-contexts: He uses a bottom-up model with registers and controllers as processes at the lowest level and constructs complex systems by composing them. Davie [4] takes a top-down approach to design using verification between specification and implementation steps in CIRCAL <ref> [21] </ref>. Design partitioning is done by description of components and composing them for verification with respect to the specification. Contextual constraints, restrictions imposed by a device on its environment, are introduced to write partial specifications of a component's environment.
Reference: 22. <author> J. A. Nestor and D. Thomas. </author> <title> Behavioral synthesis with interfaces. </title> <booktitle> In Proceedings of ICCAD, </booktitle> <month> November </month> <year> 1986. </year>
Reference-contexts: It is typical that an area of verification research would have this orientation, and also that the top-down view would be better represented in synthesis research. In addition to Boriello's work (cited above), approaches to scheduling by Ku, Micheli [17] and Nestor et.al <ref> [22] </ref> have considered protocol-like constraints. Dill et.al have used a Buchi automata based model to verify safety and liveness properties using language containment [7].
Reference: 23. <author> Kamlesh Rath, Bhaskar Bose, and Steven D. Johnson. </author> <title> Derivation of a DRAM memory interface by sequential decomposition. </title> <note> to appear in ICCD, </note> <year> 1993. </year>
Reference-contexts: An implementation of the complement of this machine is incorporated in the original machine. Successive decomposition steps result in an implementation of a network of machines that implement the high-level specification. We have used process decomposition to derive a DRAM memory sub-system for an implementation of the FM9001 microprocessor <ref> [23] </ref>. The language described here needs to be extended to allow symbolic values on control ports. The syntax is restricted in order to maintain a simple semantics. There is no mechanism to quantify time in the language.
Reference: 24. <author> Andres R. Takach and Wayne Wolf. </author> <title> Behavior FSMs for high-level synthesis and verification. </title> <type> Technical Report CE-W91-13, </type> <institution> Dept. of Electrical Engineering, Princeton University, </institution> <month> July </month> <year> 1991. </year>
Reference-contexts: Both sides of the protocol are involved in factoring nontrivial sequential components. Most formal treatments of sequential decomposition are bottom-up in the sense that they are oriented toward post-design verification. This would include most of the recent research in finite-state machine verification [3]; extensions of FSM models (e.g. <ref> [25, 24] </ref>) and Petri net theories (e.g. [2]); and model-theoretic work involving process formalisms (e.g. [20, 9]). It is typical that an area of verification research would have this orientation, and also that the top-down view would be better represented in synthesis research.
Reference: 25. <author> Wayne Wolf, Andres Takach, and Tien-Chien Lee. </author> <title> Architectural optimization methods for control-dominated machines. </title> <booktitle> High-Level VLSI Synthesis, </booktitle> <pages> pages 231-254, </pages> <year> 1991. </year>
Reference-contexts: Both sides of the protocol are involved in factoring nontrivial sequential components. Most formal treatments of sequential decomposition are bottom-up in the sense that they are oriented toward post-design verification. This would include most of the recent research in finite-state machine verification [3]; extensions of FSM models (e.g. <ref> [25, 24] </ref>) and Petri net theories (e.g. [2]); and model-theoretic work involving process formalisms (e.g. [20, 9]). It is typical that an area of verification research would have this orientation, and also that the top-down view would be better represented in synthesis research.
Reference: 26. <author> Zheng Zhu and Steven D. Johnson. </author> <title> An example of digital design transformation in an algebraic framework. </title> <editor> In Subramanyam, editor, </editor> <booktitle> Proceedings of ACM International Workshop on Formal Methods in VLSI Design, </booktitle> <month> January </month> <year> 1991. </year> <month> 18 </month>
Reference-contexts: We can view such a derivation as a formal proof reflecting a top-down reasoning style. In this respect it should not be viewed as an alternative for deductive (i.e., conventional theorem-prover based) verification but as an alternate mode of reasoning in design <ref> [16, 26] </ref>. We can also view derivation as a formalization of synthesis, but as a formalization it is more centrally concerned with correctness in reasoning than with automated design.
References-found: 26

