URL: ftp://ftp.icsi.berkeley.edu/pub/techreports/1993/tr-93-028.ps.gz
Refering-URL: http://www.icsi.berkeley.edu/techreports/1993.html
Root-URL: http://www.icsi.berkeley.edu
Email: E-mail: murer@icsi.berkeley.edu.  E-mail: jfeldman@icsi.berkeley.edu.  E-mail: clim@icsi.berkeley.edu. ICSI E-mail: mseidel@icsi.berkeley.edu.  
Title: pSather: Layered Extensions to an Object-Oriented Language for Efficient Parallel Computation  
Author: Stephan Murer Jerome A. Feldman Chu-Cheow Lim Martina-Maria Seidel 
Address: Switzerland.  Berkeley.  Berkeley.  
Affiliation: ICSI and Eidgenossische Technische Hochschule (ETH), Zurich,  ICSI and Computer Science Division, U.C.  ICSI and Computer Science Division, U.C.  
Date: December 1993  
Note: TR-93-028 (2nd revised edition)  
Abstract: pSather is a parallel extension of the existing object-oriented language Sather. It offers a shared-memory programming model which integrates both control- and data-parallel extensions. This integration increases the flexibility of the language to express different algorithms and data structures, especially on distributed-memory machines (e.g. CM-5). This report describes our design objectives and the programming language pSather in detail. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Abdullahi, E. Miranda, and G. Ringwood. </author> <title> Collection schemes for distributed garbage. </title> <booktitle> In Proceedings of the International Workshop on Memory Management (IWMM 92) - LNCS 637, </booktitle> <pages> pages 43-81. </pages> <publisher> Springer-Verlag, </publisher> <month> September </month> <year> 1992. </year>
Reference-contexts: These two approaches can be balanced by having some subset of the clusters manage exclusive regions, as determined by consideration of the architecture at hand. 9.1.2 Garbage Collection There is a large literature on distributed garbage collection techniques <ref> [1] </ref>. Current versions of pSather use uniprocessor conservative garbage collection [13] and avoid collection by conservatively identifying known garbage at compile time [48]).
Reference: [2] <author> Gul Agha. </author> <title> Actors: A Model of Concurrent Computation in Distributed Systems. </title> <publisher> The MIT Press, </publisher> <address> Cambridge Massachusetts, </address> <year> 1986. </year>
Reference-contexts: In this case, methods are defined in the threads class to activate, suspend and perform other synchronization operations (e.g. fork-join). In this model, threads are independent of data objects and multiple threads can execute on an object in parallel. * A second approach is to have active objects (actors <ref> [2] </ref>), each with its own message queue and thread of control. From the user's point of view, a thread exists to receive and service incoming message requests. <p> A design goal in pSather is suitability for efficient implementation. We therefore do not adopt the actor model <ref> [2] </ref> because of the performance costs of maintaining a message queue for each object, and disallowing parallel operations (e.g. reads) on an object.
Reference: [3] <author> Eugene Albert, Joan D. Lukas, and Guy L. Steele Jr. </author> <title> Data Parallel Computers and the FORALL Statement. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 13 </volume> <pages> 185-192, </pages> <year> 1991. </year>
Reference-contexts: There are five characteristics to note for pSather's style of data-parallelism. * The so-called "data", which are operated upon in parallel, are actually large-grained chunks (e.g. tree, array) consisting of finer-grained data (e.g. tree nodes, array elements). * Although data-parallelism was previously associated with the execution mode of SIMD machines <ref> [3] </ref>, the dist-statement moves away from this association to an SPMD form of data-parallelism in which parallel threads execute the same piece of code on different chunks, but not necessarily in lock-step. * The execution of body code is co-located with the cluster location of the corresponding chunk to ensure data
Reference: [4] <author> Pierre America. </author> <title> Issues in the Design of a Parallel Object-Oriented Language. </title> <institution> Philips Research Laboratories, Eindhoven and University of Amsterdam, </institution> <month> March 1 </month> <year> 1989. </year> <title> Part of POOL2/PTC Distribution Package. </title>
Reference-contexts: From the user's point of view, a thread exists to receive and service incoming message requests. Examples include POOL2 <ref> [4] </ref> and ABCL [24]. * In a third approach, threads of control are independent of any object in the system and managed by the system (e.g. scheduling). In this model (e.g. Hybrid [59], COOL [15]), objects are passive while threads are the loci of control. <p> In this design, the object-oriented term "message passing" in pSather does not involve communication between threads but has procedure invocation semantics instead; we might view it as message-passing between passive objects rather than threads. pSather does not need message-passing forms of parallel constructs like actors in POOL2 <ref> [4] </ref>, broadcast in Orca [6], or asynchronous reply in Natasha [20] and ConcurrentSmalltalk [67].
Reference: [5] <author> Gregory R. Andrews and Fred B. Schneider. </author> <title> Concepts and Notations for Concurrent Programming. </title> <journal> ACM Computing Surveys, </journal> <volume> 15(1) </volume> <pages> 3-43, </pages> <month> March </month> <year> 1983. </year>
Reference-contexts: We feel that this is a justifiable choice because many parallel architectures are converging to this characterization, and scalability and programmability considerations have led to many efforts at supporting distributed shared memory with NUMA characteristics. 8.3 Synchronization There are two general approaches to achieving synchronization among threads <ref> [5] </ref> | shared data or message-passing.
Reference: [6] <author> Henri E. Bal, Andrew S. Tanenbaum, and M. Frans Kaashoek. Orca: </author> <title> A language for distributed programming. </title> <journal> SIGPLAN Notices, </journal> <volume> 25(5) </volume> <pages> 17-24, </pages> <year> 1990. </year>
Reference-contexts: this design, the object-oriented term "message passing" in pSather does not involve communication between threads but has procedure invocation semantics instead; we might view it as message-passing between passive objects rather than threads. pSather does not need message-passing forms of parallel constructs like actors in POOL2 [4], broadcast in Orca <ref> [6] </ref>, or asynchronous reply in Natasha [20] and ConcurrentSmalltalk [67]. In pSather, sequential routine calls are viewed as the default synchronous mode of message-passing while the deferred-assignment statement corresponds to asynchronous message-passing. 8.2 Machine and Programming Model Some languages are more suited to certain architectures than others.
Reference: [7] <author> J. G. P. Barnes. </author> <title> An Overview of Ada. </title> <journal> Software Practice and Experience, </journal> <volume> 10(11) </volume> <pages> 851-887, </pages> <year> 1980. </year>
Reference: [8] <author> Paul S. Barth, Rishiyur S. Nikhil, and Arvind. M-Structures: </author> <title> Extending a Parallel, Non-Strict, Functional Language with State. </title> <booktitle> In Functional Programming Languages and Computer Architecture, 5th ACM Conference Proceedings, Lecture Notes in Computer Science 523, </booktitle> <pages> pages 538-568, </pages> <month> August </month> <year> 1991. </year>
Reference-contexts: It also goes into some detail in comparing parallel constructs in pSather with other approaches. This includes: * high-level synchronization constructs (gates vs. monitor [34], M-structures <ref> [8] </ref>) * constructs to support NUMA (pSather's @-operator and copy/move operations vs. object movement in Emerald [40]) * constructs to support data-parallelism (dist-statement and $DISTfTg class vs. approaches in PC++ [30], [46] and C* [35]) A more complete and detailed description of related work (which involves discussing other specific parallel object-oriented <p> The philosophy behind the design of $GATE classes resembles other synchronization constructs in other languages, such as monitors in Mesa and Concurrent Pascal [34], and M-structures <ref> [8] </ref> in Id, such that a relatively small set of powerful operations are provided, on top of which the user can build more sophisticated synchronization mechanisms. Monitors.
Reference: [9] <author> John K. Bennett. </author> <title> The Design and Implementation of Distributed Smalltalk. </title> <booktitle> In OOPSLA '87 Conference Proceedings, </booktitle> <pages> pages 318-330, </pages> <month> October 4-8 </month> <year> 1987. </year> <title> Proceedings also published as: </title> <journal> SIGPLAN Notices, </journal> <volume> Vol 22, No 12, </volume> <month> December </month> <year> 1987. </year>
Reference-contexts: In pSather, sequential routine calls are viewed as the default synchronous mode of message-passing while the deferred-assignment statement corresponds to asynchronous message-passing. 8.2 Machine and Programming Model Some languages are more suited to certain architectures than others. For example, languages such as Orca and Distributed Smalltalk <ref> [9] </ref> are aimed at distributed systems. There is no shared address space like pSather, so that an object is not directly accessible from all processors. To share objects among processes, some languages (e.g.
Reference: [10] <author> Anton Beranek. </author> <title> Data race detection based on execution replay for parallel applications. </title> <booktitle> In Proceedings of CONPAR '92, </booktitle> <pages> pages 109-114, </pages> <address> Lyon, France, </address> <month> September </month> <year> 1992. </year>
Reference-contexts: Recent research on debugging parallel programs deals with analyzing the traces by itself to detect race conditions and candidates for deadlocks <ref> [10, 36] </ref>. Using such techniques for traces of pSather programs may lead to the detection of errors that cannot be found by simply replaying the program execution. 74 10 Conclusions The problem of general purpose parallel programming remains one of the most challenging and important research tasks.
Reference: [11] <author> Brian N. Bershad, Edward D. Lazowska, and Henry M. Levy. </author> <title> PRESTO: A System for Object-Oriented Parallel Programming. </title> <journal> Software Practice and Experience, </journal> <volume> 18(8) </volume> <pages> 713-732, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: Presto <ref> [11] </ref>). In this case, methods are defined in the threads class to activate, suspend and perform other synchronization operations (e.g. fork-join).
Reference: [12] <author> H. Boehm, A. Demers, and S. Shenker. </author> <title> Mostly parallel garbage collection. </title> <booktitle> In Proceedings of the ACM SIGPLAN '91 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 157-164. </pages> <publisher> ACM, </publisher> <month> June </month> <year> 1991. </year> <title> Also available as: </title> <journal> SIGPLAN Notices Vol 26, </journal> <volume> No. 6, </volume> <month> June </month> <year> 1991. </year>
Reference-contexts: Because objects are not relocated, a mark and sweep will suffice for local collection when recovery of reference counted structures fails to provide memory. An incremental version can be implemented efficiently when hardware memory management is available <ref> [12] </ref>. If such hardware is not present, then a compiler-emitted read or write barrier (card marking) could also be used to be incremental. Whether this is necessary depends on the frequency and tolerable latency of local garbage collections, which again may be program dependent.
Reference: [13] <author> H. Boehm and M. Weiser. </author> <title> Garbage collection in an uncooperative environment. </title> <journal> Software Practice and Experience, </journal> <pages> pages 807-820, </pages> <month> September </month> <year> 1988. </year>
Reference-contexts: These two approaches can be balanced by having some subset of the clusters manage exclusive regions, as determined by consideration of the architecture at hand. 9.1.2 Garbage Collection There is a large literature on distributed garbage collection techniques [1]. Current versions of pSather use uniprocessor conservative garbage collection <ref> [13] </ref> and avoid collection by conservatively identifying known garbage at compile time [48]). There are a number of constraints that the pSather garbage collector has to meet: * To the extent possible, processors must refrain from stopping other processors from doing useful work while garbage collecting.
Reference: [14] <author> Peter A. Buhr and Richard A. Stroobosscher. </author> <title> C++ Annotated Reference Manual Version 3.4.4. </title> <institution> University of Waterloo, </institution> <month> August 18 </month> <year> 1992. </year> <title> Part of C++ Distribution Package. </title>
Reference-contexts: Thus the shared objects serve as communication channels in a machine model where each processor has a logically distinct address space. Other languages such as C++ <ref> [14] </ref> and parallel versions of Eiffel implicitly assume a uniform shared address space. The clustered machine model in pSather (section 4.1) is one of the more dis 65 tinct departures from other parallel languages.
Reference: [15] <author> Rohit Chandra, Anoop Gupta, and John L. Hennessy. </author> <title> Integrating Concurrency and Data Abstraction in a Parallel Programming Language. </title> <type> Technical Report CSL-TR-92-511, </type> <institution> Computer Systems Laboratory, Stanford University, </institution> <month> February </month> <year> 1992. </year> <month> 81 </month>
Reference-contexts: Examples include POOL2 [4] and ABCL [24]. * In a third approach, threads of control are independent of any object in the system and managed by the system (e.g. scheduling). In this model (e.g. Hybrid [59], COOL <ref> [15] </ref>), objects are passive while threads are the loci of control. Normally, the programmer does not have any explicit handle to the threads, so that he/she cannot perform operations like moving the thread object from one scheduler to another. <p> In the system-managed thread/passive object model, thread creation is usually decoupled from object operations because code blocks and/or routines are not first-class objects. Languages with this model have constructs that support explicit thread creation (e.g. the reflex operation in Hybrid [59] or invocation of parallel function in COOL <ref> [15] </ref>). pSather currently follows the third model. The threads are not however completely invisible to the user.
Reference: [16] <author> Andrew Andai Chien. </author> <title> Concurrent Aggregates (CA): An Object-Oriented Language for Fine--Grained Message-Passing Machines. </title> <type> PhD thesis, </type> <institution> MIT, </institution> <month> July </month> <year> 1990. </year> <note> Also available as: </note> <institution> MIT Artificial Intelligence Laboratory, </institution> <type> Technical Report 1248. </type>
Reference-contexts: The "loosely synchronous data parallelism" breaks away from SIMD execution and is similar to our approach. The ideas behind the class SPREADfTg were motivated by replicated objects as in [57], concurrent aggregates <ref> [16] </ref> and the spread arrays in Split-C [21]. 69 9 Future Research This report doesn't solve all problems that occur when going from Sather to pSather.
Reference: [17] <author> T. H. Cormen, C. E. Leiserson, and R. L. Rivest. </author> <title> Introduction to Algorithms. </title> <publisher> The MIT electrical engineering and computer science series. MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1990. </year>
Reference-contexts: For the details of how to determine the partner chunk in the merge steps we refer to the sorting network introduced in <ref> [17, Chapter 28] </ref>. The merge steps have to proceed in lock-step. Each new merge step depends on the results of the preceding merge steps. The merge steps proceed in two phases: First, the local chunk is merged with a remote partner chunk into a temporary vector chunk (t).
Reference: [18] <author> Thinking Machines Corporation. </author> <title> The Connection Machine CM-5 Technical Summary. </title> <institution> Thinking Machines Corporation, Cambridge Massachusetts, </institution> <month> October </month> <year> 1991. </year>
Reference-contexts: This model covers a wide range of parallel systems from shared memory multiprocessors (one single cluster) to distributed memory multiprocessors (each cluster has one processor). pSather has indeed been implemented on both shared memory multiprocessors (e.g. Sequent [50]) and distributed memory multiprocessors (e.g. CM-5 <ref> [18] </ref>). 4.2 Identification of Clusters Clusters are identified by numbers of type INT in the range between 0 and the number of clusters in the system minus one. Consequently, the @-operator (section 4.3) expects operands of type INT. Remote calls to non-existing clusters lead to runtime errors.
Reference: [19] <author> P. J. Courtois, F. Heymans, and David L. Parnas. </author> <title> Concurrent control with readers and writers. </title> <journal> Communications of the ACM, </journal> <volume> 10 </volume> <pages> 667-668, </pages> <month> October </month> <year> 1971. </year>
Reference-contexts: The readers/writers problem <ref> [19] </ref> is the classical problem of synchronizing a number of processes accessing a common resource. The resource accepts only n (n 1) readers or 1 writer at the same time.
Reference: [20] <author> Lawrence A. Crowl. </author> <title> Architectural adaptability in parallel programming. </title> <type> PhD thesis, </type> <institution> University of Rochester, </institution> <month> May </month> <year> 1991. </year>
Reference-contexts: passing" in pSather does not involve communication between threads but has procedure invocation semantics instead; we might view it as message-passing between passive objects rather than threads. pSather does not need message-passing forms of parallel constructs like actors in POOL2 [4], broadcast in Orca [6], or asynchronous reply in Natasha <ref> [20] </ref> and ConcurrentSmalltalk [67]. In pSather, sequential routine calls are viewed as the default synchronous mode of message-passing while the deferred-assignment statement corresponds to asynchronous message-passing. 8.2 Machine and Programming Model Some languages are more suited to certain architectures than others.
Reference: [21] <author> D. E. Culler, A. Dusseau, S. C. Goldstein, A. Krishnamurthy, S. Lumetta, T. von Eicken, and K. Yelick. </author> <note> Parallel programming in split-c. In to be published in Proceedings of Supercomputing 93, </note> <year> 1993. </year>
Reference-contexts: The "loosely synchronous data parallelism" breaks away from SIMD execution and is similar to our approach. The ideas behind the class SPREADfTg were motivated by replicated objects as in [57], concurrent aggregates [16] and the spread arrays in Split-C <ref> [21] </ref>. 69 9 Future Research This report doesn't solve all problems that occur when going from Sather to pSather.
Reference: [22] <author> Edsger W. Dijkstra. </author> <title> Co-operating sequential processes. </title> <editor> In F. Genuys, editor, </editor> <booktitle> Programming Languages. </booktitle> <publisher> Academic Press, </publisher> <year> 1965. </year>
Reference-contexts: Gate is a new name for the "monitor" in [27] because the name "monitor" is already used in computer science for similar but not identical concepts leading to unnecessary confusion. Although pSather gates add some new functionality they are similar to the classical shared memory synchronization primitives (semaphores <ref> [22] </ref>, monitors [38] [33] etc.). Not surprisingly, one can easily model all the classical synchronization primitives using gates. There are two versions of gates sharing the same basic functionalities: the parameterless GATE0 class and the parameterized GATEfTg class.
Reference: [23] <author> Michel Dubois, Christoph Scheurich, and Faye Briggs. </author> <title> Memory access buffering in multiprocessors. </title> <booktitle> In Proceedings of the 13th Annual Symposium on Computer Architecture, </booktitle> <pages> pages 434-442, </pages> <month> June </month> <year> 1986. </year>
Reference-contexts: The relaxed consistency model presented above is a variant of the weak consistency model <ref> [23] </ref>. However, we need to define consistency on the language level instead of the machine level, as is the case for the traditional consistency definitions. Both the intra-thread and inter-thread consistency rules place constraints on pSather implementations.
Reference: [24] <editor> Akinori Yonezawa (ed). </editor> <title> ABCL An object-oriented concurrent system. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1990. </year>
Reference-contexts: From the user's point of view, a thread exists to receive and service incoming message requests. Examples include POOL2 [4] and ABCL <ref> [24] </ref>. * In a third approach, threads of control are independent of any object in the system and managed by the system (e.g. scheduling). In this model (e.g. Hybrid [59], COOL [15]), objects are passive while threads are the loci of control.
Reference: [25] <editor> Michel Cekleov et al. SPARCCenter2000: </editor> <booktitle> Multiprocessing for the 90`s! In COMPCON spring 1993. </booktitle> <publisher> IEEE COmputer Society Press, </publisher> <month> February </month> <year> 1993. </year>
Reference-contexts: Examples for such architectures include DASH [47], Sequent [50], and Sun SPARCcenter 2000 <ref> [25] </ref>, SPARCstation 10/xx etc. In order to make use of multiple processors the language must provide means to create and synchronize multiple parallel threads of instructions. This version has been running on the Sequent and SPARCstation since early 1991.
Reference: [26] <author> Jerome A. Feldman. </author> <title> High level programming for distributed computing. </title> <journal> Communications of the ACM, </journal> <volume> 22(6) </volume> <pages> 353-368, </pages> <month> June </month> <year> 1979. </year>
Reference-contexts: approach is the use of monitors ([38], [66]) in Concurrent Pascal ([34]) and Mesa [42]; on the other hand, the message-passing approach is used in notations such as the rendezvous in Ada ([7], [65]), channels in CSP (Communicating Sequential Processes [39]) and Occam [62], and the send/receive constructs in PLITS <ref> [26] </ref>. In an object-oriented language, conceptually, objects interact among themselves by message passing. An object invokes a routine (or method) on another object or itself by sending a message to the destination object. It would therefore seem natural that object-oriented languages should adopt a message-passing approach for synchronization.
Reference: [27] <author> Jerome A. Feldman, Chu-Cheow Lim, and Franco Mazzanti. </author> <title> pSather monitors: Design, Tutorial, Rationale and Implementation. </title> <type> Technical Report TR-91-031, </type> <institution> International Computer Science Institute, Berkeley, </institution> <address> Ca., </address> <year> 1991. </year>
Reference-contexts: This paper describes the new features and how they interact with Sather 1.0 constructs, and gives examples of their use. There is some discussion of design decisions and much more can be found in <ref> [27] </ref> and [48]. We can order the features of pSather into four layers as illustrated in In section 2 we give a brief introduction into Sather 1.0 the base language for pSather. A complete description of Sather 1.0 can be found in [61]. <p> This design has been stable since summer 1991 under the old name of "monitor" and is discussed in detail in <ref> [27] </ref>. Section 3.3 contains a brief description of the gates and how they interact with the rest of the design. Sections 4-7 present material that is new since [27] and was largely motivated by distributed memory considerations. pSather continues to be based on a shared address space abstraction, but some additional <p> This design has been stable since summer 1991 under the old name of "monitor" and is discussed in detail in <ref> [27] </ref>. Section 3.3 contains a brief description of the gates and how they interact with the rest of the design. Sections 4-7 present material that is new since [27] and was largely motivated by distributed memory considerations. pSather continues to be based on a shared address space abstraction, but some additional constructs greatly help in mapping programs to distributed memories. <p> This version has been running on the Sequent and SPARCstation since early 1991. We will not give many examples and motivations for design decisions in this section because this part of pSather has not changed much since <ref> [27] </ref>. 3.1 Non-Blocking Calls: Creating Threads Each regular pSather routine call without return values can be made to a simple non-blocking (or asynchronous) call by preceding it with a deferred assignment operator (:-). <p> Gate is a new name for the "monitor" in <ref> [27] </ref> because the name "monitor" is already used in computer science for similar but not identical concepts leading to unnecessary confusion. Although pSather gates add some new functionality they are similar to the classical shared memory synchronization primitives (semaphores [22], monitors [38] [33] etc.). <p> At the end of the transaction the resource is freed by a call to either end read or end write. It is a nice example to demonstrate the binding operations on gates. More examples exposing the full flexibility of gates (under the old name "monitor") can be found in <ref> [27] </ref>. Internally the synchronization is organized around two gates, one for the readers and one for the writers. <p> Monitors. The pSather gate objects were previously called monitors <ref> [27] </ref> because of a similarity with the monitor concept in Mesa [42] and Concurrent Pascal [34]. 66 Firstly a gate operation (monitor entry procedure) guarantees a thread (process) exclusive access to the object (module). But in pSather, the gate operations are predefined since GATEfTg and GATE0 are predefined classes.
Reference: [28] <author> Jerome A. Feldman, Chu-Cheow Lim, and Thomas Rauber. </author> <title> The Shared-Memory Langauge pSather on a Distributed-Memory Multiprocessor. </title> <booktitle> In Second Workshop on Languages, Compilers, and Run-Time Environments for Distributed-Memory Multiprocessors, </booktitle> <address> Boulder, Colorado, </address> <month> Sept 30 - Oct 2 </month> <year> 1992. </year>
Reference: [29] <author> Jason Gait. </author> <title> A debugger for concurrent programs. </title> <journal> Software Practice and Experience, </journal> <volume> 15(6) </volume> <pages> 539-554, </pages> <month> June </month> <year> 1985. </year>
Reference-contexts: Instrumenting leads to a dilemma: On the one hand, the instrumentation should generate sufficient trace information that allows an identical replay of the original execution. On the other 73 hand, instrumenting the code alters the program behavior ("Probe Effect " [45], "Heisenberg Uncer--tainty " <ref> [29] </ref>.) In order to minimize such changes, instrumenting should be reduced. Instant replay is a helpful method by tracing only causalities between events rather than transmitted data, thus minimizing the amount of information to be traced. Data can be reconstructed during replay.
Reference: [30] <author> Dennis Gannon, Jenq Kuen Lee, and Srinivas Narayana. </author> <title> On Using Object Oriented Parallel Programming to Build Distributed Algebraic Abstractions. </title> <booktitle> In Proceedings of CONPAR 92 - LNCS 634. </booktitle> <publisher> Springer-Verlag, </publisher> <month> September </month> <year> 1992. </year>
Reference-contexts: This includes: * high-level synchronization constructs (gates vs. monitor [34], M-structures [8]) * constructs to support NUMA (pSather's @-operator and copy/move operations vs. object movement in Emerald [40]) * constructs to support data-parallelism (dist-statement and $DISTfTg class vs. approaches in PC++ <ref> [30] </ref>, [46] and C* [35]) A more complete and detailed description of related work (which involves discussing other specific parallel object-oriented languages) can be found in [48]. 8.1 Processes/Threads There are three general ways to create parallel processes or threads in object-oriented languages. * A thread may be explicitly treated as
Reference: [31] <author> Kouroush Gharachorloo, Anoop Gupta, and John Hennessy. </author> <title> Performance evaluation of memory consistency models for shared memory multiprocessors. </title> <booktitle> In Proceedings of the 18th Annual Symposium on Computer Architecture, </booktitle> <pages> pages 245-257, </pages> <month> June </month> <year> 1991. </year> <month> 82 </month>
Reference-contexts: We therefore relax the consistency requirements across threads as follows. The update order in thread T1 is observable by other threads when T1 performs a consistency-ensuring operation. The following pSather operations are consistency-ensuring: the forking of a child thread, the termination 7 <ref> [31] </ref> gives performance measurements for several levels of relaxed consistency. 31 of a thread, any gate operation, and the termination of a dist-statement. The inter-thread consis-tency rule states that all writes executed by T1 before an ensuring operation will be seen by other threads, before the ensuring operations executes.
Reference: [32] <author> Kouroush Gharachorloo, Daniel Lenoski, James Laudon, Phillip Gibbons, Anoop Gupta, and John Hennessy. </author> <title> Memory consistency and event ordering in scalable shared memory multiprocessors. </title> <booktitle> In Proceedings of the 17th Annual Symposium on Computer Architecture, </booktitle> <pages> pages 15-26, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: If every processor cache in a shared-memory machine needs to be synchronized on each write instruction, performance can be greatly reduced 7 . Various levels of consistency among processors have been defined and studied <ref> [32] </ref>. The strongest of these is sequential consistency [41] which guarantees that every read operation sees the most recent write to the same location.
Reference: [33] <author> Per Brinch Hansen. </author> <title> The programming language concurrent pascal. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-1:199-207, </volume> <month> June </month> <year> 1975. </year>
Reference-contexts: Although pSather gates add some new functionality they are similar to the classical shared memory synchronization primitives (semaphores [22], monitors [38] <ref> [33] </ref> etc.). Not surprisingly, one can easily model all the classical synchronization primitives using gates. There are two versions of gates sharing the same basic functionalities: the parameterless GATE0 class and the parameterized GATEfTg class.
Reference: [34] <author> Per Brinch Hansen. </author> <title> Monitors and Concurrent Pascal: A Personal History. </title> <booktitle> In Second ACM SIG-PLAN History of Programming Languages Conference (HOPL-II), </booktitle> <address> Cambridge, Massachusetts, USA, </address> <month> April 20-23 </month> <year> 1993. </year>
Reference-contexts: It also goes into some detail in comparing parallel constructs in pSather with other approaches. This includes: * high-level synchronization constructs (gates vs. monitor <ref> [34] </ref>, M-structures [8]) * constructs to support NUMA (pSather's @-operator and copy/move operations vs. object movement in Emerald [40]) * constructs to support data-parallelism (dist-statement and $DISTfTg class vs. approaches in PC++ [30], [46] and C* [35]) A more complete and detailed description of related work (which involves discussing other specific <p> Instead of providing a different construct for each commonly-used synchronization (e.g. lock vs. barrier vs. conditional wait), a gate object unifies all the common synchronizations. The philosophy behind the design of $GATE classes resembles other synchronization constructs in other languages, such as monitors in Mesa and Concurrent Pascal <ref> [34] </ref>, and M-structures [8] in Id, such that a relatively small set of powerful operations are provided, on top of which the user can build more sophisticated synchronization mechanisms. Monitors. <p> Monitors. The pSather gate objects were previously called monitors [27] because of a similarity with the monitor concept in Mesa [42] and Concurrent Pascal <ref> [34] </ref>. 66 Firstly a gate operation (monitor entry procedure) guarantees a thread (process) exclusive access to the object (module). But in pSather, the gate operations are predefined since GATEfTg and GATE0 are predefined classes.
Reference: [35] <author> Philip J. Hatcher, Anthony J. Lapadula, Robert R. Jones, Michael J. Quinn, and Ray J. An-derson. </author> <title> A Production-Quality C* Compiler for a Hypercube Multicomputer. </title> <type> Technical Report TR 90-80-3, </type> <institution> Oregon State University, Computer Science Department, </institution> <year> 1990. </year>
Reference-contexts: This includes: * high-level synchronization constructs (gates vs. monitor [34], M-structures [8]) * constructs to support NUMA (pSather's @-operator and copy/move operations vs. object movement in Emerald [40]) * constructs to support data-parallelism (dist-statement and $DISTfTg class vs. approaches in PC++ [30], [46] and C* <ref> [35] </ref>) A more complete and detailed description of related work (which involves discussing other specific parallel object-oriented languages) can be found in [48]. 8.1 Processes/Threads There are three general ways to create parallel processes or threads in object-oriented languages. * A thread may be explicitly treated as a first-class object in <p> For example, it is possible to perform the usual object operations (e.g. routine calls, iterator calls) on distributed objects just like ordinary objects. In C* <ref> [35] </ref>, the user can declare a domain data type (just like a C struct) and then use this data type to declare domain arrays.
Reference: [36] <author> David P. Helmbold, Charles E. McDowell, and Jian-Zhong Wang. </author> <title> Determining possible event orders by analyzing sequential traces. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 4(7) </volume> <pages> 827-839, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: Recent research on debugging parallel programs deals with analyzing the traces by itself to detect race conditions and candidates for deadlocks <ref> [10, 36] </ref>. Using such techniques for traces of pSather programs may lead to the detection of errors that cannot be found by simply replaying the program execution. 74 10 Conclusions The problem of general purpose parallel programming remains one of the most challenging and important research tasks.
Reference: [37] <author> John Hennessy and David Patterson. </author> <title> Computer Architecture, a Quantitative Approach. </title> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <year> 1990. </year>
Reference-contexts: Another independent question concerns when various threads reading a variable will see the newly written value. This problem arises in modern cache-based processors and is called the memory consistency problem (for which a concise introduction is given in <ref> [37] </ref>). If every processor cache in a shared-memory machine needs to be synchronized on each write instruction, performance can be greatly reduced 7 . Various levels of consistency among processors have been defined and studied [32].
Reference: [38] <author> C. A. R. Hoare. </author> <title> Monitors: an operating system structuring concept. </title> <journal> Communications of the ACM, </journal> <volume> 17 </volume> <pages> 549-557, </pages> <month> October </month> <year> 1974. </year>
Reference-contexts: Although pSather gates add some new functionality they are similar to the classical shared memory synchronization primitives (semaphores [22], monitors <ref> [38] </ref> [33] etc.). Not surprisingly, one can easily model all the classical synchronization primitives using gates. There are two versions of gates sharing the same basic functionalities: the parameterless GATE0 class and the parameterized GATEfTg class.
Reference: [39] <author> C. A. R. </author> <title> Hoare. </title> <booktitle> Communicating Sequential Processes, </booktitle> <pages> pages 136-148. </pages> <publisher> IEEE Computer Society Press, </publisher> <year> 1989. </year> <note> Also published in Communications of the ACM, </note> <month> August </month> <year> 1978, </year> <pages> pp 666-677. </pages>
Reference-contexts: An example of the shared data approach is the use of monitors ([38], [66]) in Concurrent Pascal ([34]) and Mesa [42]; on the other hand, the message-passing approach is used in notations such as the rendezvous in Ada ([7], [65]), channels in CSP (Communicating Sequential Processes <ref> [39] </ref>) and Occam [62], and the send/receive constructs in PLITS [26]. In an object-oriented language, conceptually, objects interact among themselves by message passing. An object invokes a routine (or method) on another object or itself by sending a message to the destination object.
Reference: [40] <author> Eric Jul et al. </author> <title> Fine-grained mobility in the Emerald system. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 6(1) </volume> <pages> 109-133, </pages> <month> February </month> <year> 1988. </year>
Reference-contexts: Emerald <ref> [40] </ref>) does not support migrating objects which retain their identity, because the identity of an object is its address (including the cluster location) in our simple yet efficient model. <p> It also goes into some detail in comparing parallel constructs in pSather with other approaches. This includes: * high-level synchronization constructs (gates vs. monitor [34], M-structures [8]) * constructs to support NUMA (pSather's @-operator and copy/move operations vs. object movement in Emerald <ref> [40] </ref>) * constructs to support data-parallelism (dist-statement and $DISTfTg class vs. approaches in PC++ [30], [46] and C* [35]) A more complete and detailed description of related work (which involves discussing other specific parallel object-oriented languages) can be found in [48]. 8.1 Processes/Threads There are three general ways to create parallel <p> Calls to the align routine may cause objects to be moved. 67 Similarly, Emerald <ref> [40] </ref> and pSather incorporate object placement in the language semantics. In fact, object mobility is a major design goal and affects the language design (e.g. parameter passing) of Emerald. Emerald's location-independence vs. pSather's @-operator. <p> Therefore when an object moves, activation records of its routines have to be relocated as well. This means that the runtime system has to keep track of the activation records of every movable object; this might entail high runtime costs. Jul et al <ref> [40] </ref> describes how to reduce such costs and what to update when activation records are moved. In pSather, the locus of control is independent of the object's location and is specified by the @-operator. The @-operator has the relatively simple semantics of specifying where a subthread executes.
Reference: [41] <author> Leslie Lamport. </author> <title> How to make a multiprocessor computer that correctly executes multiprocess programs. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-28(9):241-248, </volume> <month> September </month> <year> 1979. </year>
Reference-contexts: If every processor cache in a shared-memory machine needs to be synchronized on each write instruction, performance can be greatly reduced 7 . Various levels of consistency among processors have been defined and studied [32]. The strongest of these is sequential consistency <ref> [41] </ref> which guarantees that every read operation sees the most recent write to the same location.
Reference: [42] <author> Butler W. Lampson and David D. Redell. </author> <title> Experience with Processes and Monitors in Mesa. </title> <journal> Communications of the ACM, </journal> <volume> 23(2) </volume> <pages> 105-117, </pages> <month> February </month> <year> 1980. </year>
Reference-contexts: An example of the shared data approach is the use of monitors ([38], [66]) in Concurrent Pascal ([34]) and Mesa <ref> [42] </ref>; on the other hand, the message-passing approach is used in notations such as the rendezvous in Ada ([7], [65]), channels in CSP (Communicating Sequential Processes [39]) and Occam [62], and the send/receive constructs in PLITS [26]. In an object-oriented language, conceptually, objects interact among themselves by message passing. <p> Monitors. The pSather gate objects were previously called monitors [27] because of a similarity with the monitor concept in Mesa <ref> [42] </ref> and Concurrent Pascal [34]. 66 Firstly a gate operation (monitor entry procedure) guarantees a thread (process) exclusive access to the object (module). But in pSather, the gate operations are predefined since GATEfTg and GATE0 are predefined classes.
Reference: [43] <author> Thomas J. LeBlanc and John M. Mellor-Crummey. </author> <title> Debugging parallel programs with Instant Replay. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-36(4):471-482, </volume> <month> April </month> <year> 1987. </year>
Reference-contexts: Thus the program behaves identically in each execution and reexecution. In general, this is not true for pSather programs. Because of the inherent nondeterminism, the program may behave differently when reexecuted. The standard solution for this problem is instant replay <ref> [43] </ref>: The generated code is automatically instrumented such that it writes traces of its behavior during its execution. For pSather these traces must include the sequence of shared memory accesses, timing of synchronizations, etc.
Reference: [44] <author> Thomas J. LeBlanc, John M. Mellor-Crummey, and Robert J. Fowler. </author> <title> Analyzing parallel program executions using multiple views. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 9 </volume> <pages> 203-217, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: The question of which are the program and execution parameters that should be visualized and how the information should be presented in order to effectively and efficiently detect performance errors <ref> [44] </ref> is an open research issue. For the second error class no uniform debugging technique exists. Much effort is spent on the solution of this problem. But so far, no completely satisfying solution has been found.
Reference: [45] <author> Carol H. LeDoux and D. Stott Parker, Jr. </author> <title> Saving traces for Ada debugging. Ada in Use, </title> <booktitle> Proceedings of the Ada International Conference, published in ACM Ada Letters, </booktitle> <volume> 5(2) </volume> <pages> 97-108, </pages> <month> September </month> <year> 1985. </year>
Reference-contexts: Instrumenting leads to a dilemma: On the one hand, the instrumentation should generate sufficient trace information that allows an identical replay of the original execution. On the other 73 hand, instrumenting the code alters the program behavior ("Probe Effect " <ref> [45] </ref>, "Heisenberg Uncer--tainty " [29].) In order to minimize such changes, instrumenting should be reduced. Instant replay is a helpful method by tracing only causalities between events rather than transmitted data, thus minimizing the amount of information to be traced. Data can be reconstructed during replay.
Reference: [46] <author> Jenq Kuen Lee and Dennis Gannon. </author> <title> Object Oriented Parallel Programming Experiments and Results. </title> <booktitle> In Proceedings of Supercomputing '91. </booktitle> <publisher> IEEE Computer Society Press and ACM SIGARCH, </publisher> <month> November </month> <year> 1991. </year>
Reference-contexts: This includes: * high-level synchronization constructs (gates vs. monitor [34], M-structures [8]) * constructs to support NUMA (pSather's @-operator and copy/move operations vs. object movement in Emerald [40]) * constructs to support data-parallelism (dist-statement and $DISTfTg class vs. approaches in PC++ [30], <ref> [46] </ref> and C* [35]) A more complete and detailed description of related work (which involves discussing other specific parallel object-oriented languages) can be found in [48]. 8.1 Processes/Threads There are three general ways to create parallel processes or threads in object-oriented languages. * A thread may be explicitly treated as a <p> In PC++ <ref> [46] </ref>, there is the concept of a homogeneous collection of objects which is analogous to the domain array in C*. The data-parallel construct is also similar to that in C*.
Reference: [47] <author> Daniel Lenoski, James Laudon, et al. </author> <title> The Stanford Dash Multiprocessor. </title> <journal> IEEE Computer, </journal> <volume> 25(3) </volume> <pages> 63-79, </pages> <month> March </month> <year> 1992. </year> <month> 83 </month>
Reference-contexts: Current attempts to produce low-latency local networks are considered in section 9.6. True parallelism differs from concurrency in that multiple threads of control are active on the same data. This occurs in shared-memory machines like the Sequent and in the clusters of designs like the DASH <ref> [47] </ref>. It turns out that the coordination mechanisms needed for shared memory hardware are also important for the shared address space abstraction underlying pSather. Distributed computing is inherently concurrent and also differs in two other crucial ways from parallel computing. <p> Examples for such architectures include DASH <ref> [47] </ref>, Sequent [50], and Sun SPARCcenter 2000 [25], SPARCstation 10/xx etc. In order to make use of multiple processors the language must provide means to create and synchronize multiple parallel threads of instructions. This version has been running on the Sequent and SPARCstation since early 1991.
Reference: [48] <author> Chu-Cheow Lim. </author> <title> A Parallel Object-Oriented System for Realizing Reusable and Efficient Data Abstractions. </title> <type> PhD thesis, </type> <institution> University of California at Berkeley, </institution> <year> 1993. </year> <note> also available as technical report TR-93-063, </note> <institution> International Computer Science Institute. </institution>
Reference-contexts: This paper describes the new features and how they interact with Sather 1.0 constructs, and gives examples of their use. There is some discussion of design decisions and much more can be found in [27] and <ref> [48] </ref>. We can order the features of pSather into four layers as illustrated in In section 2 we give a brief introduction into Sather 1.0 the base language for pSather. A complete description of Sather 1.0 can be found in [61]. <p> Note that the weak consistency model is also satisfied by sequentially consistent implementations 9 . 8 In fact, most modern shared memory multiprocessors have weakly consistent memories and provide special instructions to enforce consistency in the memory system. 9 Our prototype implementation on CM-5 (cf. <ref> [48] </ref>) actually retains a sequentially consistent model because it is simpler to implement. <p> (pSather's @-operator and copy/move operations vs. object movement in Emerald [40]) * constructs to support data-parallelism (dist-statement and $DISTfTg class vs. approaches in PC++ [30], [46] and C* [35]) A more complete and detailed description of related work (which involves discussing other specific parallel object-oriented languages) can be found in <ref> [48] </ref>. 8.1 Processes/Threads There are three general ways to create parallel processes or threads in object-oriented languages. * A thread may be explicitly treated as a first-class object in the system (e.g. Presto [11]). <p> Current versions of pSather use uniprocessor conservative garbage collection [13] and avoid collection by conservatively identifying known garbage at compile time <ref> [48] </ref>). There are a number of constraints that the pSather garbage collector has to meet: * To the extent possible, processors must refrain from stopping other processors from doing useful work while garbage collecting.
Reference: [49] <author> Chu-Cheow Lim, Jerome A. Feldman, and Stephan Murer. </author> <title> Unifying control- and data-parallelism in an object-oriented language. </title> <booktitle> In Proceedings of the 1993 Joint Symposium on Parallel Processing, </booktitle> <address> Tokyo, Japan, </address> <month> May 17 May 19 </month> <year> 1993. </year>
Reference: [50] <author> Tom Lovett and Shreekant Thakkar. </author> <title> The Symmetry Multiprocessor System. </title> <booktitle> In Proceedings of International Conference on Parallel Processing, </booktitle> <pages> pages 303-310. </pages> <institution> Pennsylvania State University Press, University Park, </institution> <address> PA., </address> <year> 1988. </year>
Reference-contexts: Examples for such architectures include DASH [47], Sequent <ref> [50] </ref>, and Sun SPARCcenter 2000 [25], SPARCstation 10/xx etc. In order to make use of multiple processors the language must provide means to create and synchronize multiple parallel threads of instructions. This version has been running on the Sequent and SPARCstation since early 1991. <p> Figure 6 gives a user view of the model. This model covers a wide range of parallel systems from shared memory multiprocessors (one single cluster) to distributed memory multiprocessors (each cluster has one processor). pSather has indeed been implemented on both shared memory multiprocessors (e.g. Sequent <ref> [50] </ref>) and distributed memory multiprocessors (e.g. CM-5 [18]). 4.2 Identification of Clusters Clusters are identified by numbers of type INT in the range between 0 and the number of clusters in the system minus one. Consequently, the @-operator (section 4.3) expects operands of type INT.
Reference: [51] <author> Steven E. Lucco. </author> <title> Parallel Programming in a Virtual Object Space. </title> <booktitle> In Proceedings OOPSLA '87, </booktitle> <pages> pages 26-34. </pages> <publisher> ACM, </publisher> <month> December </month> <year> 1987. </year> <note> Also available as: SIGPLAN Notice Vol 22, No. 12, </note> <month> Dec </month> <year> 1987. </year>
Reference-contexts: Tarmac [52]), that automatically performs load balancing and maps allocated objects on different processors, is needed. There are however parallel object-oriented languages which support a non-uniform shared address space in a high-level manner. For example, Sloop <ref> [51] </ref> allows the programmer to specify alignment relationships among objects via calls to an align routine.
Reference: [52] <author> Steven E. Lucco and David P. Anderson. Tarmac: </author> <title> a language system substrate based on mobile memory. </title> <type> Technical Report UCB/CSD 89/525, </type> <institution> Computer Science Division (EECS), University of California, Berkeley, </institution> <address> CA 94720, </address> <month> November </month> <year> 1989. </year>
Reference-contexts: We will treat the two aspects of placement of objects | allocation and relocation | together. Some languages have a uniform shared memory model, so that if implemented on distributed memory multiprocessors, the communication costs of remote access are hidden from the programmer, and a runtime system (e.g. Tarmac <ref> [52] </ref>), that automatically performs load balancing and maps allocated objects on different processors, is needed. There are however parallel object-oriented languages which support a non-uniform shared address space in a high-level manner.
Reference: [53] <author> Yoshifumi Manabe and Makoto Imase. </author> <title> Global conditions in debugging distributed programs. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 15 </volume> <pages> 62-69, </pages> <year> 1992. </year>
Reference-contexts: Similarly, we plan to insert predicates to program replay control. One difficulty that must be dealt with is the absence of directly observable global states in distributed systems, which must be addressed for pSather programs. Some work in this direction has been done in <ref> [53, 56] </ref>. Future work will investigate which classes of predicates are needed. A sort of temporal logic is a possible candidate, since many problems when programming in parallel are timing problems. * With the ability to insert arbitrary breakpoints by checking predicates the monitoring and replay approach allows cyclical debugging.
Reference: [54] <author> Charles E. McDowell and David P. Helmbold. </author> <title> Debugging concurrent programs. </title> <journal> ACM Computing Surveys, </journal> <volume> 21(4) </volume> <pages> 593-622, </pages> <month> December </month> <year> 1989. </year>
Reference-contexts: Much effort is spent on the solution of this problem. But so far, no completely satisfying solution has been found. We plan to construct a debugging tool for pSather that mainly addresses errors of the second class by using the classic technique of cyclical debugging <ref> [54] </ref> that has proved useful for sequential programs: The sequential program is repeatedly stopped during execution, the program state examined, and the program either continued or reexecuted in order to stop at an earlier point in execution to locate an error.
Reference: [55] <author> Bertrand Meyer. </author> <title> Object-oriented Software Construction. </title> <publisher> Prentice Hall, </publisher> <address> New York, </address> <year> 1988. </year>
Reference-contexts: 1 Introduction The parallel Sather (pSather) project focuses on language and library support for general purpose parallel programming. Sather began as a smaller, simpler and faster variant of Eiffel <ref> [55] </ref>. A preliminary version [60] released in summer 1991 has developed a significant global user community. The design of Sather 1.0 [61], released in 1993, retains much of the original simplicity, but includes several additional features that were found to provide the greatest increase in functionality.
Reference: [56] <author> Barton P. Miller and Jong-Deok Choi. </author> <title> Breakpoints and halting in distributed programs. </title> <booktitle> In Proceedings of the Eighth International Conference on Distributed Computing Systems, </booktitle> <pages> pages 316-323, </pages> <year> 1988. </year>
Reference-contexts: Similarly, we plan to insert predicates to program replay control. One difficulty that must be dealt with is the absence of directly observable global states in distributed systems, which must be addressed for pSather programs. Some work in this direction has been done in <ref> [53, 56] </ref>. Future work will investigate which classes of predicates are needed. A sort of temporal logic is a possible candidate, since many problems when programming in parallel are timing problems. * With the ability to insert arbitrary breakpoints by checking predicates the monitoring and replay approach allows cyclical debugging.
Reference: [57] <author> Stephan Murer and Philipp Farber. </author> <title> A scalable distributed shared memory system. </title> <booktitle> In Proceedings of CONPAR'92-VAPP V - LNCS 634, </booktitle> <address> Lyon, France, </address> <month> September </month> <year> 1992. </year> <note> Springer-Verlag. </note>
Reference-contexts: The "loosely synchronous data parallelism" breaks away from SIMD execution and is similar to our approach. The ideas behind the class SPREADfTg were motivated by replicated objects as in <ref> [57] </ref>, concurrent aggregates [16] and the spread arrays in Split-C [21]. 69 9 Future Research This report doesn't solve all problems that occur when going from Sather to pSather.
Reference: [58] <author> Stephan Murer, Stephen Omohundro, and Clemens Szyperski. Sather iters: </author> <title> Object-oriented iteration abstraction. </title> <type> Technical Report TR-93-045, </type> <institution> International Computer Science Institute, Berkeley, </institution> <address> Ca., </address> <year> 1993. </year>
Reference-contexts: The design of Sather 1.0 [61], released in 1993, retains much of the original simplicity, but includes several additional features that were found to provide the greatest increase in functionality. These include exception handling, a form of closures, and a general iterator feature <ref> [58] </ref> that is particularly important for parallel computation. The central theme of Sather is flexible encapsulation: libraries of carefully written parameterized classes support programs that are efficient and powerful and also easy to write, read and reason about. Sather is basically, but not religiously, object-oriented. <p> Non-blocking calls to routines without any return value may be synchronized by a deferred assignment to a gate of type GATE0. 6 It is tempting to allow non-blocking calls to iters <ref> [58] </ref>, as well. For iters that only produce a stream of values but do not take a stream of values (only once-parameters) this is possible.
Reference: [59] <author> O. M. Nierstrasz. </author> <title> Active Objects in Hybrid. </title> <booktitle> In OOPSLA 1987 Conference Proceedings, </booktitle> <pages> pages 243-253, </pages> <month> Oct 4 - Oct 8 </month> <year> 1987. </year>
Reference-contexts: Examples include POOL2 [4] and ABCL [24]. * In a third approach, threads of control are independent of any object in the system and managed by the system (e.g. scheduling). In this model (e.g. Hybrid <ref> [59] </ref>, COOL [15]), objects are passive while threads are the loci of control. Normally, the programmer does not have any explicit handle to the threads, so that he/she cannot perform operations like moving the thread object from one scheduler to another. <p> Normally, the programmer does not have any explicit handle to the threads, so that he/she cannot perform operations like moving the thread object from one scheduler to another. Most languages in this model allow multiple parallel threads to execute in an object. Some (e.g. Hybrid <ref> [59] </ref>) group objects into protection domains such that at most one thread can be active in a domain. The design choice affects how threads and objects are created. <p> In the system-managed thread/passive object model, thread creation is usually decoupled from object operations because code blocks and/or routines are not first-class objects. Languages with this model have constructs that support explicit thread creation (e.g. the reflex operation in Hybrid <ref> [59] </ref> or invocation of parallel function in COOL [15]). pSather currently follows the third model. The threads are not however completely invisible to the user.
Reference: [60] <author> Stephen M. Omohundro. </author> <title> The Sather Language. </title> <type> Technical report, </type> <institution> International Computer Science Institute, Berkeley, </institution> <address> Ca., </address> <year> 1991. </year>
Reference-contexts: 1 Introduction The parallel Sather (pSather) project focuses on language and library support for general purpose parallel programming. Sather began as a smaller, simpler and faster variant of Eiffel [55]. A preliminary version <ref> [60] </ref> released in summer 1991 has developed a significant global user community. The design of Sather 1.0 [61], released in 1993, retains much of the original simplicity, but includes several additional features that were found to provide the greatest increase in functionality. <p> to -- ``g :- o.f'' in current design. fork_at (g:$GATE-T-, r:ROUT, cluster_id:INT) is end; -- The call ``fork (g,#ROUT (o.f),i)'' would be equivalent to -- ``g :- o.f@i'' in current design. end; One reason that pSather does not treat threads as first-class objects is that an older version of Sather <ref> [60] </ref> does not support any form of closure or routine as first-class objects. The new language specification has a form of closure called bound routines (section 2.4). As pSather evolves, one might imagine consolidating the deferred assignment with the normal class semantics by supporting a predefined THREADfTg class (Figure 20).
Reference: [61] <author> Stephen M. Omohundro. </author> <title> The Sather 1.0 Specification. </title> <type> Technical report, </type> <institution> International Computer Science Institute, Berkeley, Ca., </institution> <note> 1992 (in preparation). </note>
Reference-contexts: 1 Introduction The parallel Sather (pSather) project focuses on language and library support for general purpose parallel programming. Sather began as a smaller, simpler and faster variant of Eiffel [55]. A preliminary version [60] released in summer 1991 has developed a significant global user community. The design of Sather 1.0 <ref> [61] </ref>, released in 1993, retains much of the original simplicity, but includes several additional features that were found to provide the greatest increase in functionality. These include exception handling, a form of closures, and a general iterator feature [58] that is particularly important for parallel computation. <p> We can order the features of pSather into four layers as illustrated in In section 2 we give a brief introduction into Sather 1.0 the base language for pSather. A complete description of Sather 1.0 can be found in <ref> [61] </ref>. A complete grammar (including Sather) of pSather is in appendix A. Section 3 adds a second layer to the single processor model of Sather, incorporating a multiple processor shared-memory model. We introduce non-blocking routine calls for spawning parallel threads of execution. <p> We will concentrate on the relevant concepts for the purpose of this report. Most of this section consists of condensed version of <ref> [61] </ref>. Refer to this report for a full definition of the language. Sather is an object-oriented language that supports highly efficient computation, powerful abstractions for encapsulation and code reuse, a flexible interactive development environment, and constructs for ensuring code correctness. <p> One may look at the cobegin-statement as an implicit exception handler; it 1 The pSather syntax is an extension of the syntax of Sather in <ref> [61] </ref> 2 We say that an exception is passed on beyond the end of a statement if it is raised (explicitly by the raise-statement, or implicitly by an inner exception handler that could not catch the exception or the runtime system) within the body of that statement and cannot be handled
Reference: [62] <author> Dick Pountain. </author> <title> A tutorial introduction to OCCAM programming. Inmos Occam Manual. </title>
Reference-contexts: An example of the shared data approach is the use of monitors ([38], [66]) in Concurrent Pascal ([34]) and Mesa [42]; on the other hand, the message-passing approach is used in notations such as the rendezvous in Ada ([7], [65]), channels in CSP (Communicating Sequential Processes [39]) and Occam <ref> [62] </ref>, and the send/receive constructs in PLITS [26]. In an object-oriented language, conceptually, objects interact among themselves by message passing. An object invokes a routine (or method) on another object or itself by sending a message to the destination object.
Reference: [63] <author> Jr R. H. Halstead. </author> <title> Multilisp: A language for concurrent symbolic computation. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 7(4) </volume> <pages> 501-538, </pages> <month> October </month> <year> 1985. </year>
Reference-contexts: In order to not continue searching after a result has been found, the searching threads can occasionally check whether the gate got cleared, and terminate immediately if this is the case. One typical application for deferred assignments are simple futures <ref> [63] </ref>: ... g::=#GATE-T-; g :- f (x); ... -- Do something in parallel. res:=g.take; -- Wait and assign result. 3.4 Readers/Writer Synchronization with Gates In order to demonstrate some of the capabilities of gates in an object-oriented language we show the example of a library class for readers/writer synchronization (Figure 4).
Reference: [64] <author> H. W. Schmidt. </author> <title> Data-Parallel Object-Oriented Programming. </title> <booktitle> In Proc. of the Fifth Australian Supercomputer Conference, </booktitle> <institution> Melbourne (AUS): Univ. Melbourne, </institution> <month> December </month> <year> 1992. </year> <month> 84 </month>
Reference-contexts: Thus any element type which satisfies the interface can be used in the collection. This allows the code in a collection to be reused; there is no similar facility for code reuse in C*. There is also a research effort on dpSather <ref> [64] </ref> to add only "loosely synchronous data parallelism" to sequential Sather, without the notions of threads, synchronization etc. dpSather has bulk types; the elements in a bulk type is finer-grained than chunks.
Reference: [65] <institution> Reference Manual for the Ada Programming Language. United States Department of Defense, </institution> <month> July </month> <year> 1982. </year>
Reference-contexts: An example of the shared data approach is the use of monitors ([38], [66]) in Concurrent Pascal ([34]) and Mesa [42]; on the other hand, the message-passing approach is used in notations such as the rendezvous in Ada ([7], <ref> [65] </ref>), channels in CSP (Communicating Sequential Processes [39]) and Occam [62], and the send/receive constructs in PLITS [26]. In an object-oriented language, conceptually, objects interact among themselves by message passing. An object invokes a routine (or method) on another object or itself by sending a message to the destination object.
Reference: [66] <author> Peter Wegner and Scott A. Smolka. </author> <title> Processes, Tasks, and Monitors: A Comparative Study of Concurrent Programming Primitives. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-9(4):446-462, </volume> <month> July </month> <year> 1983. </year>
Reference-contexts: An example of the shared data approach is the use of monitors ([38], <ref> [66] </ref>) in Concurrent Pascal ([34]) and Mesa [42]; on the other hand, the message-passing approach is used in notations such as the rendezvous in Ada ([7], [65]), channels in CSP (Communicating Sequential Processes [39]) and Occam [62], and the send/receive constructs in PLITS [26].
Reference: [67] <author> Y. Yokote and M. Tokoro. </author> <title> Experience and evolution of Concurrent Smalltalk. </title> <booktitle> In Proceedings of OOPSLA, </booktitle> <pages> pages 406-415, </pages> <address> Orlando, Florida, </address> <month> December </month> <year> 1987. </year> <journal> ACM. </journal> <volume> 85 </volume>
Reference-contexts: does not involve communication between threads but has procedure invocation semantics instead; we might view it as message-passing between passive objects rather than threads. pSather does not need message-passing forms of parallel constructs like actors in POOL2 [4], broadcast in Orca [6], or asynchronous reply in Natasha [20] and ConcurrentSmalltalk <ref> [67] </ref>. In pSather, sequential routine calls are viewed as the default synchronous mode of message-passing while the deferred-assignment statement corresponds to asynchronous message-passing. 8.2 Machine and Programming Model Some languages are more suited to certain architectures than others.
References-found: 67

