URL: ftp://speech.cse.ogi.edu/pub/docs/icslp98percept.ps
Refering-URL: http://www.cse.ogi.edu/cslu/publications/abstracts/icslp98/abstracts.html
Root-URL: http://www.cse.ogi.edu
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> P. Bhaskararao. </author> <title> Subphonemic segment inventories for concatenative speech synthesis. </title> <booktitle> In Fundamentals of Speech Synthesis and Speech Recognition, </booktitle> <pages> pages 70-85. </pages> <publisher> John Wiley & Sons Ltd, </publisher> <year> 1994. </year>
Reference-contexts: However, we chose the reference words carefully, so that most inserted segments represent the second half of a vowel, followed by a stop consonant (category III, see Section 2.2), or a nasal stop (category I). Concatenation effects can be minimized in such cases <ref> [1] </ref>. For the segments preceeded by a glide (category II), we neglect concatenation effects, and investigate how well the perceptual changes can be predicted only by objective distances between segments.
Reference: [2] <author> A. W. Black and N. Campbell. </author> <title> Optimising selection of units from speech databases for concatenative synthesis. </title> <booktitle> In ESCA Eurospeech'95, </booktitle> <pages> pages 581-584, </pages> <year> 1995. </year>
Reference-contexts: Many concatenative synthesizers store exactly one segment for each phonetic context (e.g. diphones). Recently, researchers have addressed the challenge of selecting segments from any database of naturally spoken text. Several unit selection algorithms that rely on objective distance measures have been proposed <ref> [2, 3, 8] </ref>. In speech recognition, distance measures have been used more widely than in speech synthesis. Recognition algorithms based on template matching, using Dynamic Time Warping (DTW), applied distance measures directly.
Reference: [3] <author> R. E. Donovan. </author> <title> Trainable Speech Synthesis. </title> <type> PhD thesis, </type> <institution> Cambridge Univ. Eng. Dept., </institution> <month> June </month> <year> 1996. </year>
Reference-contexts: Many concatenative synthesizers store exactly one segment for each phonetic context (e.g. diphones). Recently, researchers have addressed the challenge of selecting segments from any database of naturally spoken text. Several unit selection algorithms that rely on objective distance measures have been proposed <ref> [2, 3, 8] </ref>. In speech recognition, distance measures have been used more widely than in speech synthesis. Recognition algorithms based on template matching, using Dynamic Time Warping (DTW), applied distance measures directly.
Reference: [4] <author> O. Ghitza and M. M. Sondhi. </author> <title> On the perceptual distance between speech segments. </title> <journal> J. of the Acoustical Soc. of Am., </journal> <volume> 101(1), </volume> <year> 1997. </year>
Reference-contexts: Time Scale Weighting Several frame distances need to be combined in order to obtain a distance between segments. In DTW algorithms, frame distances were sometimes weighted according to the amount of time warping needed. In a distance measure developed by Sondhi and Ghitza <ref> [4] </ref>, frames are weighted more heavily towards phoneme boundaries. In the results reported so far, we defined the distance between two segments as the average of their frame distances. Another choice is to take the maximum frame distance.
Reference: [5] <author> A. H. Gray and J. D. Markel. </author> <title> Distance measures for speech processing. </title> <journal> IEEE Trans. on Acoustics, Speech and Signal Processing, </journal> <volume> 24(5) </volume> <pages> 380-391, </pages> <month> October </month> <year> 1976. </year>
Reference-contexts: Conclusions reached on performance of a distance measure within a certain algorithm or application, may not be valid in a different setting. An early study comparing several distance measures was conducted by Gray and Markel <ref> [5] </ref>. They investigated mea fl This work was supported by a grant from Intel Corporation, and by the members of the CSLU Industrial Consortium. sures based on spectral and cepstral coefficients, log area ratios, and the Itakura-Saito distance. <p> However, for the purpose of unit selection in speech synthesis, we are interested in the relation between computed distance measures and human perception. We were able to find surprisingly little research on this topic, although many researchers <ref> [5, 16] </ref> have pointed out its need. An exception is the work by Quackenbush, Barnwell and Clements [14]. <p> Mahalanobis and Optimal Weighting The Mahalanobis distance is based on weighting features with the inverse of their variance. Features with low variance are boosted, and have a better chance of influencing the total distance. For speech cepstra, index weighting is an approximation of the Mahalanobis distance <ref> [5] </ref>. In the general case, the Mahanalobis distance also involves estimation of feature covariances. Because the covariances cannot be estimated reliably from limited speech data, they are usually ignored. This corresponds with assuming that the features are uncorrelated.
Reference: [6] <author> H. Hermansky. </author> <title> Perceptual linear predictive (PLP) analysis of speech. </title> <journal> J. of the Acoustical Soc. of Am., </journal> <volume> 87(4) </volume> <pages> 1738-1752, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: All but the FFT-based cepstra were computed via linear predictive coding (LPC) coefficients. Hermansky <ref> [6] </ref> proposed to compute LPC coefficients from a "perceptual spectrum," using the Bark scale and equal loudness pre-emphasis. The analysis was called perceptual linear prediction (PLP). On the other hand, current recognition systems often employ mel cepstral coefficients, obtained by taking the inverse FFT of a mel-warped spectrum. <p> In our experiments, we decided to compute the feature representations in three different ways: (1) using the FFT amplitude spectrum, (2) using a perceptual spectrum as described in <ref> [6] </ref>, (3) using a mel-warped spectrum. From Table 1 it can be seen that the PLP and mel scales improve the correlation between objective measures and the perceptual data. Mel based distances slightly outperform the PLP distances.
Reference: [7] <author> H. Hermansky and J. C. Junqua. </author> <title> Optimization of perceptually-based ASR front-end. </title> <booktitle> Proc. IEEE ICASSP, </booktitle> <volume> 9 </volume> <pages> 219-222, </pages> <year> 1988. </year>
Reference-contexts: Nocerino, Rabiner, and Klatt [13] studied the performance of several feature representations in a DTW recognizer. They concluded that warped frequency scales (such as mel scale and bark scale) did not improve performance. The opposite was found by Hermansky and Junqua <ref> [7] </ref>, and Krishnan and Rao [11], in different recog-nizers. Krishnan and Rao also found promising results for features based on line spectral frequencies. Such comparative studies give an insight into the range of distance measures that can be designed. <p> Placing weights on cepstral coefficients is called "liftering". cepstral lifter, as described by Hermansky and Junqua <ref> [7] </ref>.
Reference: [8] <author> A. J. Hunt and A. W. Black. </author> <title> Unit selection in a concatenative speech synthesis system using a large speech database. </title> <booktitle> In ICASSP'96, </booktitle> <address> Atlanta, </address> <year> 1996. </year>
Reference-contexts: Many concatenative synthesizers store exactly one segment for each phonetic context (e.g. diphones). Recently, researchers have addressed the challenge of selecting segments from any database of naturally spoken text. Several unit selection algorithms that rely on objective distance measures have been proposed <ref> [2, 3, 8] </ref>. In speech recognition, distance measures have been used more widely than in speech synthesis. Recognition algorithms based on template matching, using Dynamic Time Warping (DTW), applied distance measures directly.
Reference: [9] <author> D. Kewley-Port and B. S. Atal. </author> <title> Perceptual differences between vowels located in a limited phonetic space. </title> <journal> J. of the Acoustical Soc. of Am., </journal> <volume> 85(4), </volume> <year> 1989. </year>
Reference-contexts: We expected that variations of vowel segments would result in a relatively wide range of perceptual differences, which would allow listeners to rate them on a five-point scale (distances from 0 to 4). This is similar to perceptual experiments with synthesized vowels, such as reported by Kewley-Port and Atal <ref> [9] </ref>, and Klatt [10]. 2.2 The Test Database Every word pair in the perceptual test consists of a reference word and a modified version of this word. The reference word is realized by a diphone synthesizer, which is assumed to produce `correct' allophonic variations.
Reference: [10] <author> D. Klatt. </author> <title> Prediction of perceived phonetic distance from critical-band spectra: A first step. </title> <booktitle> In Proc. IEEE ICASSP, </booktitle> <pages> pages 1278-1281, </pages> <year> 1982. </year>
Reference-contexts: This is similar to perceptual experiments with synthesized vowels, such as reported by Kewley-Port and Atal [9], and Klatt <ref> [10] </ref>. 2.2 The Test Database Every word pair in the perceptual test consists of a reference word and a modified version of this word. The reference word is realized by a diphone synthesizer, which is assumed to produce `correct' allophonic variations.
Reference: [11] <author> S. Krishnan and P. Rao. </author> <title> A comparative study of explicit frequency and conventional signal representations for speech recognition. </title> <booktitle> Digital Signal Processing, </booktitle> <volume> 6 </volume> <pages> 249-284, </pages> <year> 1996. </year>
Reference-contexts: Nocerino, Rabiner, and Klatt [13] studied the performance of several feature representations in a DTW recognizer. They concluded that warped frequency scales (such as mel scale and bark scale) did not improve performance. The opposite was found by Hermansky and Junqua [7], and Krishnan and Rao <ref> [11] </ref>, in different recog-nizers. Krishnan and Rao also found promising results for features based on line spectral frequencies. Such comparative studies give an insight into the range of distance measures that can be designed.
Reference: [12] <author> M. Macon, A. Cronk, J. Wouters, and A. Kain. OGIresLPC: </author> <title> Diphone synthesizer using residual-excited linear prediction. </title> <type> Technical Report CSE-97-007, OGI, </type> <month> September </month> <year> 1997. </year>
Reference-contexts: Segments from different phonetic contexts are inserted, causing perceptible differences in the pronunciations of the words. A segment is set to be one half of a phoneme, which is the basic unit of our concatenative synthesizer <ref> [12] </ref>. Figure 1 illustrates this process. The number of phonetic contexts in English is very large, and we can cover only a small fraction of the phonetic spectrum in the perceptual test. Hence, we limit the substituted segments to three specific cases of vowels. These cases are explained below.
Reference: [13] <author> N. Nocerino, F. K. Soong, L. Rabiner, and D. Klatt. </author> <title> Comparative study of several distortion measures for speech recognition. </title> <journal> Speech Communication, </journal> <volume> 4 </volume> <pages> 317-331, </pages> <year> 1985. </year>
Reference-contexts: They showed that the cepstral distance with 10 to 20 coefficients is an efficient estimation of the log spectral distance, and proved other relations between the measures both in theory and experimentally. Nocerino, Rabiner, and Klatt <ref> [13] </ref> studied the performance of several feature representations in a DTW recognizer. They concluded that warped frequency scales (such as mel scale and bark scale) did not improve performance. The opposite was found by Hermansky and Junqua [7], and Krishnan and Rao [11], in different recog-nizers.
Reference: [14] <author> S. R. Quackenbush, T. P. Barnwell III, and M. A. Clements. </author> <title> Objective Measures of Speech Quality. </title> <publisher> Pren-tice Hall, </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1988. </year>
Reference-contexts: Distance measures are also important in speech coding, for use in vector quantization and as objective measures of speech quality <ref> [14] </ref>. Relatively few studies have attempted a large scale comparison of distance measures. Two reasons can be found for this. First, a distance measure is the result of many design choices, and to investigate all possible combinations is an enormous task. <p> We were able to find surprisingly little research on this topic, although many researchers [5, 16] have pointed out its need. An exception is the work by Quackenbush, Barnwell and Clements <ref> [14] </ref>. In their book, "Objective Measures of Speech Quality," they study the perceptual effects of several speech coding distortions, and investigate the potential of a large number of distance measures to predict the perceptual data.
Reference: [15] <author> F. K. Soong and B.-H. Juang. </author> <title> Line spectrum pairs (LSP) and speech data compression. </title> <booktitle> In Proc. IEEE ICASSP, </booktitle> <pages> pages 1.10.1-1.10.4, </pages> <year> 1984. </year>
Reference-contexts: This is not a big increase. Moreover, the weights do not form a pattern that can be easily interpreted. Our LSF feature representation consisted of the sums and differences of spectral pairs, which can be interpreted as spectral poles and bandwidths <ref> [15] </ref>. The optimized weights seemed to favor the middle poles of the LSF representation, and to baseline only combined mel cepstra 0.64 0.64 0.66 mel LSF 0.58 0.53 0.59 Table 3. Correlations for mel cepstra and for mel LSF.
Reference: [16] <author> J. van Santen. </author> <title> Prosodic modeling in text-to-speech synthesis. </title> <booktitle> In Proc. </booktitle> <address> Eurospeech-97, </address> <year> 1997. </year>
Reference-contexts: However, for the purpose of unit selection in speech synthesis, we are interested in the relation between computed distance measures and human perception. We were able to find surprisingly little research on this topic, although many researchers <ref> [5, 16] </ref> have pointed out its need. An exception is the work by Quackenbush, Barnwell and Clements [14].
References-found: 16

