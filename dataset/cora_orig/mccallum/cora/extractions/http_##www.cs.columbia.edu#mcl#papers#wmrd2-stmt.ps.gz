URL: http://www.cs.columbia.edu/mcl/papers/wmrd2-stmt.ps.gz
Refering-URL: http://www.cs.columbia.edu/mcl/publication.html
Root-URL: http://www.cs.columbia.edu
Email: fdjd,taitg@cs.columbia.edu  
Title: An Interface to Support Lazy Replicated File Service  
Author: Dan Duchamp and Carl D. Tait 
Address: New York, NY 10027  
Affiliation: Computer Science Department Columbia University  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> M. G. Baker et al. </author> <title> Measurements of a Distributed File System. </title> <booktitle> In Proc. Thirteenth ACM Symp. on Operating System Principles, </booktitle> <pages> pages 198-212, </pages> <month> Octo-ber </month> <year> 1991. </year>
Reference-contexts: We observe that, under workloads with little concurrent sharing, nearly all of the work done by IWB is wasted. IWB incurs the cost of multi-server communication on every write/close regardless of when the next read happens. Typically, the next read happens well into the future. The study described in <ref> [1] </ref> found that about one third of one percent of opens access files that were written by another a process at another site less than 60 seconds before.
Reference: [2] <author> H. Garcia-Molina. </author> <title> Elections in a Distributed Computing System. </title> <journal> IEEE Trans. Computers, </journal> <volume> C-31(1):48-59, </volume> <month> January </month> <year> 1982. </year>
Reference: [3] <author> J. J. Kistler and M. Satyanarayanan. </author> <title> Disconnected Operation in the Coda File System. </title> <journal> ACM Trans. Computer Systems, </journal> <volume> 10(1) </volume> <pages> 3-25, </pages> <month> February </month> <year> 1992. </year>
Reference-contexts: This is ideal for mobile clients that may not be always connected, either because a network is not available, of low quality, or too costly. Coda's previous work on disconnected operation <ref> [3] </ref> cast the problem as one with three phases: 1. Hoarding | filling the cache in advance of discon nection. 2. Emulation | providing an unchanging view of file service despite the client's disconnection. 3.
Reference: [4] <author> S. J. Mullender and P. M. B. Vitanyi. </author> <title> Distributed Match-making. </title> <journal> Algorithmica, </journal> <volume> 3(3) </volume> <pages> 367-391, </pages> <year> 1988. </year>
Reference-contexts: Through the use of read and write tokens, Echo provides replicated service and really does serialize reads and writes. Every reader sees the most recent data. This clean and strong guarantee comes at the cost of high complexity.) Implementing any level of consistency in a replicated system involves "matchmaking" <ref> [4] </ref> among servers. That is, the writer "spreads" the latest value to some servers, and the reader "searches" among some servers for the latest value. The matchmaking involved is that the two groups of servers must intersect in order for the most recent value to be read.
Reference: [5] <author> J. Ousterhout and F. Douglis. </author> <title> Beating the I/O Bottleneck: A Case for Log-structured File Systems. </title> <journal> Operating Systems Review, </journal> <volume> 23(1) </volume> <pages> 11-28, </pages> <month> Jan-uary </month> <year> 1989. </year>
Reference-contexts: Coda [8] adopts the same semantics, which it implements using callbacks. Moving data at the level of opens and closes works well for applications that may have sequential sharing, but little concurrent sharing. This trait is part of what Ousterhout has called "engineering/office applications" <ref> [5] </ref>. This workload | applications using small files, with little concurrent sharing | seems to be the standard workload assumed by most research file system designs.
Reference: [6] <author> T. Mann, A. Hisgen and G. Swart. </author> <title> An Algorithm for Data Replication. </title> <type> Technical Report 46, </type> <institution> Digital Systems Research Center, </institution> <month> June </month> <year> 1989. </year>
Reference-contexts: This workload | applications using small files, with little concurrent sharing | seems to be the standard workload assumed by most research file system designs. Other studies, even those that draw data from many different environments [7], confirm that this workload is very common. (One notable exception is Echo <ref> [6] </ref>. Through the use of read and write tokens, Echo provides replicated service and really does serialize reads and writes. Every reader sees the most recent data.
Reference: [7] <author> K. K. Ramakrishnan, P. Biswas and R. Karedla. </author> <title> Analysis of File I/O Traces in Commercial Computing Environments In Proc. </title> <booktitle> 1992 ACM SIG-METRICS and PERFORMANCE '92, </booktitle> <pages> pages 78-90. </pages> <publisher> ACM, </publisher> <month> June </month> <year> 1992. </year>
Reference-contexts: This trait is part of what Ousterhout has called "engineering/office applications" [5]. This workload | applications using small files, with little concurrent sharing | seems to be the standard workload assumed by most research file system designs. Other studies, even those that draw data from many different environments <ref> [7] </ref>, confirm that this workload is very common. (One notable exception is Echo [6]. Through the use of read and write tokens, Echo provides replicated service and really does serialize reads and writes. Every reader sees the most recent data.
Reference: [8] <author> M. Satyanarayanan et al. Coda: </author> <title> A Highly Available File System for a Distributed Workstation Environment. </title> <journal> IEEE Trans. Computers, </journal> <volume> 39(4) </volume> <pages> 447-459, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: For example, NFS uses "close-to-open" (CTO) consistency, meaning that when a process reads a file, it sees the effects made by all processes that closed the file before it opened the file. Coda <ref> [8] </ref> adopts the same semantics, which it implements using callbacks. Moving data at the level of opens and closes works well for applications that may have sequential sharing, but little concurrent sharing. This trait is part of what Ousterhout has called "engineering/office applications" [5].
Reference: [9] <author> A. Siegel, K. Birman and K. Marzullo. Deceit: </author> <title> A Flexible Distributed File System. </title> <booktitle> In Proc. 1990 Summer USENIX Technical Conf., </booktitle> <pages> pages 51-62. </pages> <publisher> USENIX, </publisher> <month> June </month> <year> 1990. </year>
Reference: [10] <author> C. Tait and D. Duchamp. </author> <title> Service Interface and Replica Consistency Algorithm for Mobile File System Clients. </title> <booktitle> In Proc. First Intl. Conf. on Parallel and Distributed Information Systems, </booktitle> <pages> pages 190-197. </pages> <publisher> IEEE, </publisher> <month> December </month> <year> 1991. </year>
Reference-contexts: We employ an important optimization to eliminate most of the searching work when there is little sharing. Our technique carries other advantages as well: simple and flexible recovery algorithms, and suitability for mobile computing. 2 A Different Approach In <ref> [10] </ref> and [11] we have proposed the idea of supporting two read calls, which we name strict read () and loose read (). With loose read (), the file system will make a "best effort" to provide the latest value, but provides no guarantee.
Reference: [11] <author> C. Tait and D. Duchamp. </author> <title> An Efficient Variable Consistency Replicated File Service. </title> <booktitle> In File Systems Workshop, </booktitle> <pages> pages 111-126. </pages> <publisher> USENIX, </publisher> <month> May </month> <year> 1992. </year>
Reference-contexts: We employ an important optimization to eliminate most of the searching work when there is little sharing. Our technique carries other advantages as well: simple and flexible recovery algorithms, and suitability for mobile computing. 2 A Different Approach In [10] and <ref> [11] </ref> we have proposed the idea of supporting two read calls, which we name strict read () and loose read (). With loose read (), the file system will make a "best effort" to provide the latest value, but provides no guarantee. <p> Our approach can be contrasted by noting that special emulation and reintegration phase are unnecessary in our scheme, since, in some sense, the "default" client-server interaction is near to what might be called disconnection. (Our method of detecting version skew is explained in <ref> [11] </ref>.) Hoarding is a separate problem that might be partially addressed by our previous work on prefetching [12]. 3 Conclusion The advantages of the method described above include: * Applications can benefit from fast read and fast write by using write () and loose read ().
Reference: [12] <author> C. Tait and D. Duchamp. </author> <title> Detection and Exploitation of File Working Sets. </title> <booktitle> In Proc. 11th Intl. Conf. on Distributed Computing Systems, </booktitle> <pages> pages 2-9. </pages> <publisher> IEEE, </publisher> <month> May </month> <year> 1991. </year>
Reference-contexts: and reintegration phase are unnecessary in our scheme, since, in some sense, the "default" client-server interaction is near to what might be called disconnection. (Our method of detecting version skew is explained in [11].) Hoarding is a separate problem that might be partially addressed by our previous work on prefetching <ref> [12] </ref>. 3 Conclusion The advantages of the method described above include: * Applications can benefit from fast read and fast write by using write () and loose read ().
References-found: 12

