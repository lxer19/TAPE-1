URL: http://www.cs.columbia.edu/~hgs/papers/Schu9502_Internet.ps.gz
Refering-URL: http://www.cs.columbia.edu/~hgs/resume/resume.html
Root-URL: http://www.cs.columbia.edu
Email: hgs@fokus.gmd.de  
Title: Internet Services: from Electronic Mail to Real-Time Multimedia  
Author: Henning Schulzrinne 
Address: Berlin, Germany  
Affiliation: GMD Fokus  
Abstract: In the first twenty years of its existence, the Internet was mainly used for email and file transfer, mostly by researchers and technical staff in American universities, government and some industrial research labs. In the last five years, this has changed dramatically, with exponential growth, new services and a transition to a commercial network. This paper describes some of the technical foundations of the new real-time multimedia services, in particular a real-time transport protocol. The paper also outlines some of the challenges to Internet technology in this transition from a research to a commercial network.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> T. Berners-Lee, R. Cailliau, A. Luotonen, H. F. Nielsen, and A. </author> <title> Secret, The world-wide web, </title> <journal> Communications ACM, </journal> <volume> vol. 37, </volume> <pages> pp. 76-82, </pages> <month> Aug. </month> <year> 1994. </year>
Reference-contexts: The most popular applications within today's Internet (by byte count) are file transfer (31.7% of NSFnet backbone traffic, November 1994), followed by WWW <ref> [1] </ref> (13.9%), network news (10.3%), electronic mail (6.1%) and multicast (5.6%). Multicast traffic, mostly audio and video, already exceeds telnet and gopher traffic (4.3% and 3.9%, respectively).
Reference: [2] <author> H. Schulzrinne, </author> <title> Voice communication across the Internet: A network voice terminal, </title> <type> Technical Report TR 92-50, </type> <institution> Dept. of Computer Science, University of Massachusetts, Amherst, Massachusetts, </institution> <month> July </month> <year> 1992. </year>
Reference-contexts: Multicast traffic, mostly audio and video, already exceeds telnet and gopher traffic (4.3% and 3.9%, respectively). Since the earliest years of the ARPAnet, there have been experiments in carrying real-time data, in particular voice, over the Internet (see <ref> [2] </ref> for a partial survey). In the following, we discuss two foundations for existing Internet multimedia applications, namely IP multicast and the real-time transport protocol. 2.1 IP Multicast Many of the applications using continuous media are by their nature multiparticipant applications.
Reference: [3] <author> C. Topolcic, </author> <title> Experimental internet stream protocol, version 2 (ST-II), Request for Comments (Experimental) RFC 1190, </title> <institution> Internet Engineering Task Force, </institution> <month> Oct. </month> <year> 1990. </year>
Reference-contexts: Rather than replicating packets at the sender, it is far more efficient to replicate within the network, as paths to different receivers diverge. There are two possible approaches to multipeer communication: sender-oriented and receiver-oriented. The sender-oriented approach is exemplified in the ST-II protocol <ref> [3] </ref>, where the sender KIVS'95 (Kommunikation in verteilten Systemen) - Chemnitz, Germany, February 20-24, 1995 (pp. 21-34) Informatik aktuell Series, Springer Verlag 1995 1 establishes connections given a list of end points.
Reference: [4] <author> S. E. Deering and D. R. Cheriton, </author> <title> Multicast routing in datagram internetworks and extended LANs, </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> vol. 8, </volume> <pages> pp. 85-110, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: This works well for small groups, but scales poorly to large and dynamic groups, as every new group member has to notify every potential sender within the group to be added to the recipient list. A receiver-oriented approach, used by IP multicast <ref> [4] </ref>, generally scales better if care is taken which routers have to manage group membership status. Within the current version of IP (IPv4), groups are identified by a subrange of IP addresses. Distribution of multicast data is limited by the IP time-to-live (ttl) field.
Reference: [5] <author> R. Hinden, </author> <title> Simple internet protocol plus white paper, Request for Comments (Informational) RFC 1710, </title> <institution> Internet Engineering Task Force, </institution> <month> oct </month> <year> 1994. </year>
Reference-contexts: Within the current version of IP (IPv4), groups are identified by a subrange of IP addresses. Distribution of multicast data is limited by the IP time-to-live (ttl) field. The next-generation IP currently under discussion <ref> [5] </ref> has a larger multicast address space and more carefully delineated regional scope, without relying on the IP ttl field. Since most Internet backbone routers do not support IP multicast, an overlay network called the MBONE [6,7] has been engineered.
Reference: [6] <author> S. Casner and S. Deering, </author> <title> First IETF Internet audiocast, </title> <journal> ACM Computer Communication Review, </journal> <volume> vol. 22, </volume> <pages> pp. 92-97, </pages> <month> July </month> <year> 1992. </year> <title> 4 Itemized monthly phone bills for a large corporation or government agency have weighed in at 40 boxes of paper. </title> <booktitle> KIVS'95 (Kommunikation in verteilten Systemen) - Chemnitz, </booktitle> <address> Germany, </address> <month> February 20-24, </month> <pages> 1995 (pp. </pages> <address> 21-34) Informatik aktuell Series, </address> <publisher> Springer Verlag 1995 11 </publisher>
Reference: [7] <author> H. Eriksson, MBONE: </author> <title> The multicast backbone, </title> <journal> Communications ACM, </journal> <volume> vol. 37, </volume> <pages> pp. 54-60, </pages> <month> Aug. </month> <year> 1994. </year>
Reference: [8] <author> N. S. Jayant, </author> <title> Effects of packet losses on waveform-coded speech, </title> <booktitle> in Proceedings of the Fifth International Conference on Computer Communications, (Atlanta, Georgia), </booktitle> <pages> pp. 275-280, </pages> <publisher> IEEE, </publisher> <month> Oct. </month> <year> 1980. </year>
Reference-contexts: Interactive audio falls into the soft real-time category, where packet losses due to missed deadlines or other causes of several percent are tolerable <ref> [8] </ref>. Real-time data may appear aperiodically (e.g., indication of exceptional conditions in a manufacturing plants) or periodically.
Reference: [9] <author> D. P. Anderson, R. Govindan, and G. Homsy, </author> <title> Design and implementation of a continuous media I/O server, </title> <booktitle> in First International Workshop on Network and Operating System Support for Digital Audio and Video, </booktitle> <address> (Berkeley, California), </address> <month> Nov. </month> <year> 1990. </year> <month> TR-90-062. </month>
Reference-contexts: Interactive audio falls into the soft real-time category, where packet losses due to missed deadlines or other causes of several percent are tolerable [8]. Real-time data may appear aperiodically (e.g., indication of exceptional conditions in a manufacturing plants) or periodically. Continuous media services <ref> [9, 10] </ref> generate data at a given, not necessarily fixed rate, independent of the network load, and impose a timing relationship between sender and receiver, that is, the data should be delivered to the user with the same rate as it was generated at the receiver.
Reference: [10] <author> D. P. Anderson, S.-Y. Tzou, R. Wahbe, R. Govindan, and M. Andrews, </author> <title> Support for continuous media in the DASH system, </title> <booktitle> in Proceedings 10th International Conference on Distributed Computer Systems, (Paris, France), </booktitle> <pages> pp. 54-61, </pages> <publisher> IEEE, </publisher> <month> May </month> <year> 1990. </year>
Reference-contexts: Interactive audio falls into the soft real-time category, where packet losses due to missed deadlines or other causes of several percent are tolerable [8]. Real-time data may appear aperiodically (e.g., indication of exceptional conditions in a manufacturing plants) or periodically. Continuous media services <ref> [9, 10] </ref> generate data at a given, not necessarily fixed rate, independent of the network load, and impose a timing relationship between sender and receiver, that is, the data should be delivered to the user with the same rate as it was generated at the receiver.
Reference: [11] <author> R. Handel and M. N. Huber, </author> <title> Integrated broadband networks: An introduction to ATM-based networks, </title> <year> 1991. </year>
Reference-contexts: An example of synchronous data is a T1 or E1 bit stream. Constant bit rate (CBR) services produce bits at a constant rate, e.g., at 64 kb/s for standard telephony audio. The term 'CBR' is principally used as one of the service categories within ATM networks <ref> [11] </ref>. Constant bit rate services can be used to carry continuous media and synchronous data. Neither continuous media, nor CBR or synchronous services require low delay between sender and receiver, even though that is typically desired.
Reference: [12] <author> R. H. </author> <title> Moffett, Echo and delay problems in some digital communication systems, </title> <journal> IEEE Communications Magazine, </journal> <volume> vol. 25, </volume> <pages> pp. 41-47, </pages> <month> Aug. </month> <year> 1987. </year>
Reference-contexts: Synchronous applications for circuit emulation can range from 64 kb/s on up, although the traditional values of 1.5 Mb/s (T1), 2.0 Mb/s (E1) and 45 Mb/s (T3) are the most important. The delay tolerance also varies widely, from 12 ms end-to-end without echo cancellation (G.164) to 400 ms (G.114) <ref> [12] </ref> if only conversational latencies and double-talk are an issue. For playback applications like video-on-demand, delays can be longer, maybe 500 ms or more, primarily limited by the responsiveness to VCR-type commands and the ability of the receiver to buffer the data. Further details are discussed in [13].
Reference: [13] <author> C . a. M. Aras, J. F. Kurose, D. S. Reeves, and H. Schulzrinne, </author> <title> Real-time communications in packet-switched networks, </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> vol. 82, </volume> <pages> pp. 122-139, </pages> <month> Jan. </month> <year> 1994. </year>
Reference-contexts: For playback applications like video-on-demand, delays can be longer, maybe 500 ms or more, primarily limited by the responsiveness to VCR-type commands and the ability of the receiver to buffer the data. Further details are discussed in <ref> [13] </ref>. Continuous media, CBR services and synchronous data all pose the same problem when carried over packet-switched networks: The network introduces delay variations (delay jitter) due to queueing at switches and routers, which the receiver compensates for by using a FIFO playout buffer.
Reference: [14] <author> L. Zhang, S. Deering, D. Estrin, S. Shenker, and D. Zappala, Rsvp: </author> <title> a new resource ReSerVation protocol, </title> <journal> IEEE Network, </journal> <volume> vol. 7, </volume> <pages> pp. 8-18, </pages> <month> Sept. </month> <year> 1993. </year>
Reference-contexts: For production-quality multimedia services, some form of resource reservation is required. No protocols are currently deployed in the Internet that achieve resource reservation; a multicast-based, receiver-driven resource reservation protocol is currently under study <ref> [14] </ref>. 2.3 Why can't we just use TCP (or XTP, : : : ) for audio and video? Generally, in an internetwork, real-time data should use a connectionless (datagram) transport layer like UDP. However, for delivering audio and video for playback, TCP may be appropriate.
Reference: [15] <author> V. Jacobson, </author> <title> Modified TCP congestion control algorithm. Note to end2end-interest mailing list., </title> <month> Apr. </month> <year> 1990. </year>
Reference-contexts: By the time the sender has discovered that the receiver is missing a packet and retransmitted it, at least one round-trip time, likely more has elapsed. (With the TCP fast retransmit algorithm <ref> [15, 16] </ref>, three additional packetization intervals beyond the round-trip time are needed.) The receiver either has to wait for the retransmission, increasing delay and incurring an audible gap in playout, or discard the retransmitted packet, defeating the TCP mechanism.
Reference: [16] <author> W. R. Stevens, </author> <title> TCP/IP illustrated: </title> <booktitle> the protocols, </booktitle> <volume> vol. </volume> <pages> 1. </pages> <address> Reading, Massachusetts: </address> <publisher> Addison-Wesley, </publisher> <year> 1994. </year>
Reference-contexts: By the time the sender has discovered that the receiver is missing a packet and retransmitted it, at least one round-trip time, likely more has elapsed. (With the TCP fast retransmit algorithm <ref> [15, 16] </ref>, three additional packetization intervals beyond the round-trip time are needed.) The receiver either has to wait for the retransmission, increasing delay and incurring an audible gap in playout, or discard the retransmitted packet, defeating the TCP mechanism. <p> Fortunately, it would be easy to turn off UDP checksumming 2 or, alternatively, develop a UDP lite protocol containing nothing but a 16-bit destination port number. For RTP, being unidirectional, the UDP source port number is not needed. The UDP length is never needed <ref> [16, p. 144] </ref>. On the other hand, it remains to be seen how well AAL1-based adapters could handle audio streams interrupted by silence detection.
Reference: [17] <author> D. Cohen, </author> <title> A network voice protocol: NVP-II, </title> <type> technical report, </type> <institution> University of Southern California/ISI, Marina del Ray, California, </institution> <month> Apr. </month> <year> 1981. </year>
Reference-contexts: The name emphasizes, however, that RTP is an end-to-end protocol. RTP traces some of its origins to early packet audio and video work within the Internet, in particular the NVP <ref> [17] </ref> and PVP [18] protocols, as well as the protocol implemented within the vat audio agent [19]. While we will not discuss it further, RTP is also designed to work with other real-time applications, such as distributed simulation or active badges [20].
Reference: [18] <author> R. Cole, </author> <title> PVP a packet video protocol, </title> <type> W-Note 28, </type> <institution> Information Sciences Institute, University of Southern California, </institution> <address> Los Angeles, California, </address> <month> Aug. </month> <year> 1981. </year>
Reference-contexts: The name emphasizes, however, that RTP is an end-to-end protocol. RTP traces some of its origins to early packet audio and video work within the Internet, in particular the NVP [17] and PVP <ref> [18] </ref> protocols, as well as the protocol implemented within the vat audio agent [19]. While we will not discuss it further, RTP is also designed to work with other real-time applications, such as distributed simulation or active badges [20].
Reference: [19] <author> V. Jacobson and S. McCanne, </author> <title> The LBL audio tool vat. Manual page, </title> <month> July </month> <year> 1992. </year>
Reference-contexts: The name emphasizes, however, that RTP is an end-to-end protocol. RTP traces some of its origins to early packet audio and video work within the Internet, in particular the NVP [17] and PVP [18] protocols, as well as the protocol implemented within the vat audio agent <ref> [19] </ref>. While we will not discuss it further, RTP is also designed to work with other real-time applications, such as distributed simulation or active badges [20]. RTP is described in an application-independent protocol specification [21], while application-specific issues are dealt with in separate profiles.
Reference: [20] <author> R. Want, A. Hopper, V. Falcao, and J. Gibbons, </author> <title> The active badge location system, </title> <journal> ACM Transactions on Information Systems, </journal> <volume> vol. 10, </volume> <pages> pp. 91-102, </pages> <month> Jan. </month> <year> 1992. </year> <note> also Olivetti Research Limited Technical Report ORL 92-1. </note>
Reference-contexts: While we will not discuss it further, RTP is also designed to work with other real-time applications, such as distributed simulation or active badges <ref> [20] </ref>. RTP is described in an application-independent protocol specification [21], while application-specific issues are dealt with in separate profiles. Currently, there is one profile for audio and video applications [22].
Reference: [21] <author> H. Schulzrinne, S. Casner, R. Frederick, and V. Jacobson, RTP: </author> <title> A transport protocol for real-time applications. Internet draft (work-in-progress) draft-ietf-avt-rtp-*.txt, </title> <month> Nov. </month> <year> 1994. </year>
Reference-contexts: While we will not discuss it further, RTP is also designed to work with other real-time applications, such as distributed simulation or active badges [20]. RTP is described in an application-independent protocol specification <ref> [21] </ref>, while application-specific issues are dealt with in separate profiles. Currently, there is one profile for audio and video applications [22]. Other drafts describe how encodings like H.261 [23], motion JPEG [24], MPEG or Cell-B [25] are to be encapsulated within RTP packets.
Reference: [22] <author> H. Schulzrinne, </author> <title> Sample profile and encodings for the use of RTP for audio and video conferences with minimal control, </title> <type> Internet Draft, </type> <institution> GMD Fokus, </institution> <month> May </month> <year> 1994. </year> <title> Work in progress. </title>
Reference-contexts: RTP is described in an application-independent protocol specification [21], while application-specific issues are dealt with in separate profiles. Currently, there is one profile for audio and video applications <ref> [22] </ref>. Other drafts describe how encodings like H.261 [23], motion JPEG [24], MPEG or Cell-B [25] are to be encapsulated within RTP packets. To avoid misunderstandings, it may help to clear up some of the things that RTP does not attempt to do. <p> For audio, samples are included without additional overhead. The header contains the following information: Payload type: A one-byte payload type identifies the kind of payload contained in the packet, for example JPEG video or GSM audio. Payload type values are defined in a profile, e.g., <ref> [22] </ref>. Having a payload type in every packet avoids connection setup and permits dynamic changes of encodings. Timestamp: A 32-bit timestamp describes the generation instant of the data contained in the packet.
Reference: [23] <author> T. Turletti and C. Huitema, </author> <title> Packetization of H.261 video streams, </title> <type> Internet Draft, </type> <institution> INRIA, </institution> <month> Sept. </month> <year> 1994. </year> <title> Work in progress. </title>
Reference-contexts: RTP is described in an application-independent protocol specification [21], while application-specific issues are dealt with in separate profiles. Currently, there is one profile for audio and video applications [22]. Other drafts describe how encodings like H.261 <ref> [23] </ref>, motion JPEG [24], MPEG or Cell-B [25] are to be encapsulated within RTP packets. To avoid misunderstandings, it may help to clear up some of the things that RTP does not attempt to do.
Reference: [24] <author> W. Fenner, L. Berc, R. Frederick, and S. McCanne, </author> <title> RTP encapsulation of JPEG-compressed video, </title> <type> Internet Draft, </type> <institution> Kaman Sciences, </institution> <month> Nov. </month> <year> 1994. </year> <title> Work in progress. </title>
Reference-contexts: RTP is described in an application-independent protocol specification [21], while application-specific issues are dealt with in separate profiles. Currently, there is one profile for audio and video applications [22]. Other drafts describe how encodings like H.261 [23], motion JPEG <ref> [24] </ref>, MPEG or Cell-B [25] are to be encapsulated within RTP packets. To avoid misunderstandings, it may help to clear up some of the things that RTP does not attempt to do. RTP has no notion of a connection; it may operate over either connection-oriented or connectionless lower-layer protocols.
Reference: [25] <author> M. F. Speer and D. Hoffman, </author> <title> RTP encapsulation of CellB video encoding, </title> <type> Internet Draft, </type> <institution> Sun Microsystems, </institution> <month> Nov. </month> <year> 1994. </year> <title> Work in progress. </title>
Reference-contexts: RTP is described in an application-independent protocol specification [21], while application-specific issues are dealt with in separate profiles. Currently, there is one profile for audio and video applications [22]. Other drafts describe how encodings like H.261 [23], motion JPEG [24], MPEG or Cell-B <ref> [25] </ref> are to be encapsulated within RTP packets. To avoid misunderstandings, it may help to clear up some of the things that RTP does not attempt to do. RTP has no notion of a connection; it may operate over either connection-oriented or connectionless lower-layer protocols.
Reference: [26] <author> W. Feller, </author> <title> An Introduction to Probability Theory and its Applications, </title> <journal> Volume 1, </journal> <volume> vol. </volume> <pages> 1. </pages> <address> New York, New York: </address> <publisher> John Wiley and Sons, </publisher> <editor> third ed., </editor> <year> 1968. </year>
Reference-contexts: If N is the number of sources and L the length of the identifier (here, 32 bits), the probability that two sources independently pick the same value can be approximated for large N <ref> [26, p. 33] </ref> as 1 exp (N 2 =2 L+1 ). For N = 1000, the probability is roughly 0.01%. If a collision should occur, all sources detecting a collision simply generate a new random number.
Reference: [27] <author> D. Mills, </author> <title> Network time protocol (v3), Request for Comments (Experimental) RFC 1305, </title> <institution> Internet Engineering Task Force, </institution> <month> apr </month> <year> 1992. </year> <note> (Obsoletes RFC1119). </note>
Reference-contexts: Currently, all video payload types use a frequency of 65,536 Hz, which was chosen based on it being a submultiple of the NTP timestamp frequency <ref> [27] </ref>. Audio encodings use their sampling rate as the timestamp frequency. Several video packets may have the same timestamp if they belong to the same video frame. The initial value of timestamps is random.
Reference: [28] <author> H. Kanakia, P. Mishra, and A. Reibman, </author> <title> An adaptive congestion control scheme for real-time packet video transport, </title> <booktitle> in SIGCOMM Symposium on Communications Architectures and Protocols, </booktitle> <address> (San Francisco, California), </address> <pages> pp. 20-31, </pages> <address> ACM/IEEE, </address> <month> Sept. </month> <year> 1993. </year> <note> KIVS'95 (Kommunikation in verteilten Systemen) - Chemnitz, Germany, February 20-24, 1995 (pp. 21-34) Informatik aktuell Series, Springer Verlag 1995 12 </note>
Reference-contexts: Loss and jitter information contained in receiver reports can be used by senders to adjust their information rate, thus achieving fair resource sharing and graceful degradation that are desirable features of packet data networks <ref> [28, 29] </ref>. 2.6.2 Intermedia Synchronization The RTCP sender reports contain an indication of real time (wallclock time) and a corresponding RTP timestamp. These two values allow the synchronization of different media, for example, lip-syncing of audio and video.
Reference: [29] <author> J.-C. Bolot, T. Turletti, and I. Wakeman, </author> <title> Scalable feedback control for multicast video distribution in the internet, </title> <booktitle> in SIGCOMM Symposium on Communications Architectures and Protocols, </booktitle> <address> (London, England), </address> <pages> pp. </pages> -, <publisher> ACM, </publisher> <month> Aug. </month> <year> 1994. </year>
Reference-contexts: Loss and jitter information contained in receiver reports can be used by senders to adjust their information rate, thus achieving fair resource sharing and graceful degradation that are desirable features of packet data networks <ref> [28, 29] </ref>. 2.6.2 Intermedia Synchronization The RTCP sender reports contain an indication of real time (wallclock time) and a corresponding RTP timestamp. These two values allow the synchronization of different media, for example, lip-syncing of audio and video.
Reference: [30] <author> E. M. Schooler, </author> <title> Distributed music: a foray into networked performance, in Network Music Festival, </title> <booktitle> (California), </booktitle> <pages> pp. </pages> -, <month> Sept. </month> <year> 1993. </year> <note> Slides only. </note>
Reference-contexts: These two values allow the synchronization of different media, for example, lip-syncing of audio and video. Naturally, if media streams from different hosts are to be synchronized, e.g., for a distributed musical performance <ref> [30] </ref>, their clocks have to be synchronized as well. KIVS'95 (Kommunikation in verteilten Systemen) - Chemnitz, Germany, February 20-24, 1995 (pp. 21-34) Informatik aktuell Series, Springer Verlag 1995 7 2.6.3 Identification RTP data packets do not identify their origin, beyond containing a 32-bit identifier.
Reference: [31] <author> J. Postel, </author> <title> Simple mail transfer protocol, Request for Comments (Standard) RFC 821, </title> <institution> Internet Engineering Task Force, </institution> <month> Aug. </month> <year> 1982. </year> <note> Obsoletes RFC0788. </note>
Reference-contexts: One of the audio agents, NEVOT, was written by the author. RTP is not meant to be implemented as a traditional kernel-level protocol, invoked, say, through a socket layer. Rather, it is part of the application itself, just as SMTP <ref> [31] </ref> is part and parcel of an MTA. The RTP-specific parts of NEVOT run to about 500 commented lines, out of a total of 16,000. Moreover, a library with about a half dozen calls can be constructed that allows to link in an RTP-capable media agent into other applications.
Reference: [32] <author> E. Shapiro, </author> <title> Virtual places a foundation for human interaction, </title> <booktitle> in Proc. of the Second World Wide Web Conference'94, </booktitle> <address> (Chicago, Illinois), </address> <month> Oct. </month> <year> 1994. </year>
Reference-contexts: Moreover, a library with about a half dozen calls can be constructed that allows to link in an RTP-capable media agent into other applications. This approach has been used to integrate NEVOT into a WWW browser <ref> [32] </ref>.
Reference: [33] <author> T. M. Levergood, A. C. Payne, J. Gettys, W. G. Treese, and L. C. Stewart, Audiofile: </author> <title> a network-transparent system for distributed audio applications, </title> <booktitle> in Proceedings of USENIX Summer Technical Conference, </booktitle> <address> (Cincinnati, </address> <publisher> Ohio), </publisher> <pages> pp. 219-236, </pages> <publisher> USENIX, </publisher> <month> June </month> <year> 1993. </year>
Reference-contexts: This allows simultaneous access of several, possibly distributed applications to a single audio device, similar in spirit to the role of the X window system in managing a single physical display. Existing client-server audio multiplexers like AudioFile <ref> [33] </ref> or NCD NetAudio [34] use TCP as the communication path between client and the audio server. As pointed out earlier, TCP is not particularly well suited for real-time applications, particularly in the wide area.
Reference: [34] <author> J. Fulton and G. Renda, </author> <title> The network audio system, in X Technical Conference, X Consortium, </title> <note> 1994. also in X Resource, Issue 9, pp. 181. </note>
Reference-contexts: This allows simultaneous access of several, possibly distributed applications to a single audio device, similar in spirit to the role of the X window system in managing a single physical display. Existing client-server audio multiplexers like AudioFile [33] or NCD NetAudio <ref> [34] </ref> use TCP as the communication path between client and the audio server. As pointed out earlier, TCP is not particularly well suited for real-time applications, particularly in the wide area.
Reference: [35] <author> P. T. Kirstein, M. J. Handley, and M. A. Sasse, </author> <title> Piloting of multimedia integrated communications for Euro-pean researchers (MICE), </title> <booktitle> in Proceedings of the International Networking Conference (INET), </booktitle> <address> (San Francisco, California), </address> <pages> pp. </pages> <institution> DCA-1 - DCA-12, Internet Society, </institution> <month> Aug. </month> <year> 1993. </year>
Reference-contexts: This tool simply regenerates the timing of packets as they were received, while a more sophisticated version would try to reconstruct the sender timing based on media timestamps, reducing the jitter visible to those listening to the recording and avoiding late losses. The MICE project <ref> [35] </ref> has shown the interoperation of traditional video conferencing applications using hardware codecs based on the H.261 video encoding standard [36, 37] and synchronous transport, with workstation-based codecs connected by the Internet [38-40].
Reference: [36] <author> CCITT, </author> <title> Video codec for audiovisual services at px64 kbit/s (H.261), CCITT White book, </title> <year> 1990. </year>
Reference-contexts: The MICE project [35] has shown the interoperation of traditional video conferencing applications using hardware codecs based on the H.261 video encoding standard <ref> [36, 37] </ref> and synchronous transport, with workstation-based codecs connected by the Internet [38-40].
Reference: [37] <author> M. Liou, </author> <title> Overview of the p x 64 kbit/s video coding standard, </title> <journal> Communications ACM, </journal> <volume> vol. 34, </volume> <pages> pp. 59-63, </pages> <month> Apr. </month> <year> 1991. </year>
Reference-contexts: The MICE project [35] has shown the interoperation of traditional video conferencing applications using hardware codecs based on the H.261 video encoding standard <ref> [36, 37] </ref> and synchronous transport, with workstation-based codecs connected by the Internet [38-40].
Reference: [38] <author> T. Turletti, </author> <title> H.261 software codec for videoconferencing over the Internet, </title> <institution> Rapports de Recherche 1834, Institut National de Recherche en Informatique et en Automatique (INRIA), Sophia-Antipolis, France, </institution> <month> Jan. </month> <year> 1993. </year>
Reference: [39] <author> J.-C. Bolot and T. Turletti, </author> <title> A rate control mechanism for packet video in the internet, </title> <booktitle> in Proceedings of the Conference on Computer Communications (IEEE Infocom), </booktitle> <address> (Toronto, Canada), </address> <month> June </month> <year> 1994. </year>
Reference: [40] <author> T. Turletti, </author> <title> The INRIA videoconferencing system IVS, </title> <journal> Connexions, </journal> <volume> vol. 8, </volume> <pages> pp. 20-24, </pages> <month> Oct. </month> <year> 1994. </year>
Reference: [41] <author> R. Frederick, </author> <title> Experiences with real-time software video compression, </title> <booktitle> in Sixth International Workshop on Packet Video, </booktitle> <month> July </month> <year> 1994. </year>
Reference-contexts: For the media sessions themselves, there is a continuing need to find video encodings suitable for software implementation. Use of the DCT-based H.261 codec and a Haar-Cosine transform based coded <ref> [41] </ref> showed that the former yields higher compression, but also can lead to ringing artifacts when reproducing writing on projected slides. For audio, the relatively long delays force the use of headphones or echo cancellation/suppression [42].
Reference: [42] <author> M. Hans and T. Levergood, </author> <title> Echo cancellation, </title> <type> Technical Report CRL 94/7, </type> <institution> Digital Equipment Corporation, Cambridge Research Lab, Cambridge, Massachusetts, </institution> <month> Oct. </month> <year> 1994. </year>
Reference-contexts: Use of the DCT-based H.261 codec and a Haar-Cosine transform based coded [41] showed that the former yields higher compression, but also can lead to ringing artifacts when reproducing writing on projected slides. For audio, the relatively long delays force the use of headphones or echo cancellation/suppression <ref> [42] </ref>. Unfortunately, with current operating systems, it is difficult to correlate the timing of output and input audio samples [43]. In the future, there appear to two alternative packet-switched approaches to carrying continuous media. The first approach carries continuous media directly in ATM, without a network layer.
Reference: [43] <author> S. McCanne, </author> <title> Echo canceler for workstation audio. Term Project paper., </title> <month> May </month> <year> 1993. </year>
Reference-contexts: For audio, the relatively long delays force the use of headphones or echo cancellation/suppression [42]. Unfortunately, with current operating systems, it is difficult to correlate the timing of output and input audio samples <ref> [43] </ref>. In the future, there appear to two alternative packet-switched approaches to carrying continuous media. The first approach carries continuous media directly in ATM, without a network layer.
Reference: [44] <author> V. Jacobson, </author> <note> sd, the LBL session directory. Manual page, </note> <month> Nov. </month> <year> 1992. </year>
Reference-contexts: satellite would be a commercially available alternative, albeit a one-directional one.) 2.9 The Internet as an Intelligent Network At a higher layer, most current real-time applications running on the MBONE are based on a TV Guide model, where sessions are advertised through certain mailing lists and/or a multicast session directory <ref> [44] </ref>. The creator of a session periodically announces the session to a well-known multicast address, using the same scope (that is, time-to-live value) as the data session itself. The directory also probes for available multicast addresses.
Reference: [45] <author> A. Eleftheriadis, S. Pejhan, and D. Anastassiou, </author> <title> Multicast group address management and connection control for multi-party applications. </title> <journal> submitted to IEEE/ACM Transactions on Networking, </journal> <month> Apr. </month> <year> 1993. </year> <note> KIVS'95 (Kommunikation in verteilten Systemen) - Chemnitz, Germany, February 20-24, 1995 (pp. 21-34) Informatik aktuell Series, Springer Verlag 1995 13 </note>
Reference-contexts: For one, there is no explicit way to notify the intended audience except by email. For small groups and spontaneous discussions, a more 'telephone-style' mode is probably appropriate, where an initiator rings up the desired participants explicitly. Multicast address assignment can be handled separately <ref> [45] </ref>. Since it is much easier to deploy new services and enhance existing one than in the telephone network, and end systems are computers rather than 'dumb' telephones, features of the much-touted 'intelligent network' could be fairly readily deployed for Internet-based real-time communications.
References-found: 45

