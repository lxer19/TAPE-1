URL: http://suif.stanford.edu/papers/lam92.ps
Refering-URL: http://suif.stanford.edu/papers/papers.html
Root-URL: 
Title: Limits of Control Flow on Parallelism  
Author: Monica S. Lam and Robert P. Wilson 
Address: CA 94305  
Affiliation: Computer Systems Laboratory Stanford University,  
Abstract: This paper discusses three techniques useful in relaxing the constraints imposed by control flow on parallelism: control dependence analysis, executing multiple flows of control simultaneously, and speculative execution. We evaluate these techniques by using trace simulations to find the limits of parallelism for machines that employ different combinations of these techniques. We have three major results. First, local regions of code have limited parallelism, and control dependence analysis is useful in extracting global parallelism from different parts of a program. Second, a superscalar processor is fundamentally limited because it cannot execute independent regions of code concurrently. Higher performance can be obtained with machines, such as multiprocessors and dataflow machines, that can simultaneously follow multiple flows of control. Finally, without speculative execution to allow instructions to execute before their control dependences are resolved, only modest amounts of parallelism can be obtained for programs with complex control flow. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. Bernstein and M. Rodeh. </author> <title> Global Instruction Scheduling for Superscalar Machines. </title> <booktitle> In Proceedings of the ACM SIGPLAN'91 Conference on Programming 11 Language Design and Implementation, </booktitle> <pages> pages 241-255, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: To reflect the limitation of following one flow of control, we also impose an ordering on the branch instructions. To model the behavior of current compilers <ref> [1] </ref>, this ordering requires all branches in the program to execute in the original sequential execution order. The CD-MF machine may follow an unlimited number of flows of control and does not require a branch ordering constraint.
Reference: [2] <author> R. P. Colwell, R. P. Nix, J. O'Donnell, D. B. Papworth, and P. K. Rodman. </author> <title> A VLIW Architecture for a Trace Scheduling Compiler. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-37(8):967-979, </volume> <month> Aug. </month> <year> 1988. </year>
Reference-contexts: Software techniques overcome instruction fetch limitations by reordering instructions. Trace scheduling identifies the most commonly executed trace and schedules the instructions within the trace as if they belong to one large basic block <ref> [2, 4] </ref>. However, implemented trace scheduling algorithms only employ very limited forms of speculation. Smith et al. extend software scheduling with hardware support for speculative execution [15]. Instructions to be speculatively executed are boosted before a conditional branch.
Reference: [3] <author> R. Cytron, J. Ferrante, B. K. Rosen, M. N. Wegman, and F. K. Zadeck. </author> <title> An Efficient Method of Computing Static Single Assignment Form. </title> <booktitle> In Proceedings of the 16th Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 25-35, </pages> <month> Jan. </month> <year> 1989. </year>
Reference-contexts: Control dependences in programs with arbitrary control flow can easily be computed in a compiler using the reverse dominance frontier algorithm <ref> [3] </ref>. <p> We then decode and analyze the instructions from the object file to determine the successors of each basic block. Using the flow graph, the analysis computes all of the immediate control dependences by finding the reverse dominance frontier of each basic block <ref> [3] </ref>. All of the instructions within a basic block are immediately control dependent on the branches in the reverse dominance frontier of the block. An instruction may be immediately control dependent on multiple branches. However, each dynamic instance of an instruction only depends immediately on one of these branches.
Reference: [4] <author> J. A. Fisher. </author> <title> Trace Scheduling: A Technique for Global Microcode Compaction. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-30(7):478-490, </volume> <month> July </month> <year> 1981. </year>
Reference-contexts: Software techniques overcome instruction fetch limitations by reordering instructions. Trace scheduling identifies the most commonly executed trace and schedules the instructions within the trace as if they belong to one large basic block <ref> [2, 4] </ref>. However, implemented trace scheduling algorithms only employ very limited forms of speculation. Smith et al. extend software scheduling with hardware support for speculative execution [15]. Instructions to be speculatively executed are boosted before a conditional branch.
Reference: [5] <author> P. Y. T. Hsu and E. S. Davidson. </author> <title> Highly Concurrent Scalar Processing. </title> <booktitle> In Proceedings of the 13th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 386-395, </pages> <month> June </month> <year> 1986. </year>
Reference-contexts: This study of abstract machines also helps to identify useful architectural features. The concept of boosting [15], which relies on software for scheduling and a small degree of hardware to support speculative execution, appears particularly promising. Another interesting concept is guarded instructions <ref> [5] </ref>. A guarded instruction is conditionally executed based on a value stored in a general register. This allows a compiler to specify some amount of control dependence information, that only the action is control dependent on the guard.
Reference: [6] <author> W. W. Hwu, T. M. Conte, and P. P. Chang. </author> <title> Comparing Software and Hardware Schemes For Reducing the Cost of Branches. </title> <booktitle> In Proceedings of the 16th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 224-233, </pages> <month> May </month> <year> 1989. </year>
Reference-contexts: The success of this approach depends on the accuracy of branch prediction. Even for non-numeric code, both hardware and software prediction algorithms have been shown to be accurate over 85% of the time <ref> [6, 8] </ref>. Extending speculative instruction fetching to speculative execution creates additional parallelism. However, unlike instruction fetching, speculatively executing an instruction may generate unwanted side effects. These side effects must be discarded if the branch prediction is incorrect. Both hardware and software techniques can be used to implement speculative execution.
Reference: [7] <author> M. Johnson. </author> <title> Superscalar Microprocessor Design. </title> <publisher> Pren-tice Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1990. </year>
Reference-contexts: However, unlike instruction fetching, speculatively executing an instruction may generate unwanted side effects. These side effects must be discarded if the branch prediction is incorrect. Both hardware and software techniques can be used to implement speculative execution. Various hardware structures have been proposed to support speculative execution <ref> [7, 11, 13, 16] </ref>. These structures store the results of the speculative instructions until the branch direction is determined. If the branch prediction was correct the results are committed, otherwise they are discarded.
Reference: [8] <author> S. McFarling and J. Hennessy. </author> <title> Reducing the Cost of Branches. </title> <booktitle> In Proceedings of the 13th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 396-404, </pages> <month> June </month> <year> 1986. </year>
Reference-contexts: The success of this approach depends on the accuracy of branch prediction. Even for non-numeric code, both hardware and software prediction algorithms have been shown to be accurate over 85% of the time <ref> [6, 8] </ref>. Extending speculative instruction fetching to speculative execution creates additional parallelism. However, unlike instruction fetching, speculatively executing an instruction may generate unwanted side effects. These side effects must be discarded if the branch prediction is incorrect. Both hardware and software techniques can be used to implement speculative execution. <p> These statistics were collected from running the benchmarks with the same inputs used in the simulations. Our prediction rates are therefore an upper bound for static branch prediction techniques. Dynamic techniques provide similar performance <ref> [8] </ref>. Table 2 shows the branch prediction rates for conditional branches in each benchmark. We do not attempt to predict computed jumps. A mispredicted branch in a trace is easily identified by comparing the actual branch outcome with the predicted outcome.
Reference: [9] <author> K. Murakami, N. Irie, M. Kuga, and S. Tomita. </author> <title> SIMP (Single Instruction stream/Multiple instruction Pipelin-ing): A Novel High-Speed Single-Processor Architecture. </title> <booktitle> In Proceedings of the 16th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 78-85, </pages> <month> May </month> <year> 1989. </year>
Reference-contexts: Control dependences in programs with arbitrary control flow can easily be computed in a compiler using the reverse dominance frontier algorithm [3]. Hardware techniques for analyzing control dependences have also been considered <ref> [9] </ref>, but they can only detect a small subset of the control independent instructions and require complex hardware. 2.3 Executing Multiple Flows of Control Control dependence analysis discovers parallelism from across different regions of code, each of which may have its own flow of control.
Reference: [10] <author> A. Nicolau and J. A. Fisher. </author> <title> Measuring the Parallelism Available for Very Long Instruction Word Architectures. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-33(11):968-976, </volume> <month> Nov. </month> <year> 1984. </year>
Reference-contexts: The reported speedups for this processor on a set of non-numeric programs range from 4.1 to 7.4. Given the assumptions of perfect memory disambiguation and a large number of functional units, these speedups are quite small. Wall's result contrasts sharply with experiments that assume perfect branch prediction <ref> [10, 12] </ref>. Since a machine with perfect branch prediction requires foreknowledge, we refer to such a machine as an oracle. The effects of control flow on parallelism are essentially eliminated on an oracle machine because all of the branch outcomes are known in advance.
Reference: [11] <author> Y. N. Patt, S. W. Melvin, W. Hwu, and M. Shebanow. </author> <title> Critical Issues Regarding HPS, A High Performance Microarchitecture. </title> <booktitle> In Proceedings of the 18th Annual Workshop on Microprogramming, </booktitle> <pages> pages 109-116, </pages> <month> Dec. </month> <year> 1985. </year>
Reference-contexts: However, unlike instruction fetching, speculatively executing an instruction may generate unwanted side effects. These side effects must be discarded if the branch prediction is incorrect. Both hardware and software techniques can be used to implement speculative execution. Various hardware structures have been proposed to support speculative execution <ref> [7, 11, 13, 16] </ref>. These structures store the results of the speculative instructions until the branch direction is determined. If the branch prediction was correct the results are committed, otherwise they are discarded.
Reference: [12] <author> E. M. Riseman and C. C. Foster. </author> <title> The Inhibition of Potential Parallelism by Conditional Jumps. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-21(12):1405-1411, </volume> <month> Dec. </month> <year> 1972. </year>
Reference-contexts: The reported speedups for this processor on a set of non-numeric programs range from 4.1 to 7.4. Given the assumptions of perfect memory disambiguation and a large number of functional units, these speedups are quite small. Wall's result contrasts sharply with experiments that assume perfect branch prediction <ref> [10, 12] </ref>. Since a machine with perfect branch prediction requires foreknowledge, we refer to such a machine as an oracle. The effects of control flow on parallelism are essentially eliminated on an oracle machine because all of the branch outcomes are known in advance.
Reference: [13] <author> J. E. Smith and A. R. Pleszkun. </author> <title> Implementation of Precise Interrupts in Pipelined Processors. </title> <booktitle> In Proceedings of the 12th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 36-44, </pages> <month> June </month> <year> 1985. </year>
Reference-contexts: However, unlike instruction fetching, speculatively executing an instruction may generate unwanted side effects. These side effects must be discarded if the branch prediction is incorrect. Both hardware and software techniques can be used to implement speculative execution. Various hardware structures have been proposed to support speculative execution <ref> [7, 11, 13, 16] </ref>. These structures store the results of the speculative instructions until the branch direction is determined. If the branch prediction was correct the results are committed, otherwise they are discarded.
Reference: [14] <author> M. D. Smith, M. Johnson, and M. A. Horowitz. </author> <title> Limits on Multiple Instruction Issue. </title> <booktitle> In Proceedings of the Third International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 290-302, </pages> <month> Apr. </month> <year> 1989. </year>
Reference-contexts: Since non-unit latency operations consume some parallelism to fill pipeline bubbles, the reported speedups do not measure all of the parallelism. Finally, we do not include any limitations on fetching instructions <ref> [14] </ref>. At the other extreme is the upper bound of the ORACLE machine. As expected, the amount of parallelism is quite large and varies significantly between benchmarks. This reflects the different types of algorithms in the programs. For example, eqntott primarily executes a quicksort function which contains few data dependences.
Reference: [15] <author> M. D. Smith, M. S. Lam, and M. A. Horowitz. </author> <title> Boosting Beyond Static Scheduling in a Superscalar Processor. </title> <booktitle> In Proceedings of the 17th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 344-354, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: However, implemented trace scheduling algorithms only employ very limited forms of speculation. Smith et al. extend software scheduling with hardware support for speculative execution <ref> [15] </ref>. Instructions to be speculatively executed are boosted before a conditional branch. These instructions are labeled so that their results are discarded or committed when the branch condition is determined. <p> Speculation is necessary to find sufficient parallelism in these programs. This study of abstract machines also helps to identify useful architectural features. The concept of boosting <ref> [15] </ref>, which relies on software for scheduling and a small degree of hardware to support speculative execution, appears particularly promising. Another interesting concept is guarded instructions [5]. A guarded instruction is conditionally executed based on a value stored in a general register.
Reference: [16] <author> G. S. Sohi and S. Vajapeyam. </author> <title> Instruction Issue Logic for High-Performance, Interruptible Pipelined Processors. </title> <booktitle> In Proceedings of the 14th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 27-34, </pages> <month> June </month> <year> 1987. </year>
Reference-contexts: However, unlike instruction fetching, speculatively executing an instruction may generate unwanted side effects. These side effects must be discarded if the branch prediction is incorrect. Both hardware and software techniques can be used to implement speculative execution. Various hardware structures have been proposed to support speculative execution <ref> [7, 11, 13, 16] </ref>. These structures store the results of the speculative instructions until the branch direction is determined. If the branch prediction was correct the results are committed, otherwise they are discarded.
Reference: [17] <author> D. W. Wall. </author> <title> Limits of Instruction-Level Parallelism. </title> <booktitle> In Proceedings of the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 176-188, </pages> <month> Apr. </month> <year> 1991. </year> <month> 12 </month>
Reference-contexts: On the other hand, if the upper bound is within expectations, the only conclusion is that the approach may be sufficient. It is only from low limits that we can draw interesting conclusions. A recent study by Wall <ref> [17] </ref> contains a surprising result that suggests a severe limitation in current approaches. One of the experiments in that study examines the performance This research was supported in part by DARPA contract N00039-91-C-0138 and by an NSF graduate fellowship. <p> Figure 5 shows the parallelism for each benchmark compared to the BASE machine. These results are comparable to Wall's results for a similar machine <ref> [17] </ref>. The differences can be attributed to procedure inlining, perfect loop unrolling, and the unlimited scheduling window in our simulator. The parallelism for the SP machine is fairly consistent across the different benchmarks. <p> Our study suggests that a more relevant characteristic for predicting the parallelism in a program is whether the control flow is data dependent. 5.4 Effects of Perfect Loop Unrolling Previous studies on limits of parallelism did not remove all of the dependences on induction variables <ref> [17] </ref>. A question often raised is whether the induction variable dependences significantly affect the results of these studies. We performed two experiments, one with and one without removing the induction variable dependences.
References-found: 17

