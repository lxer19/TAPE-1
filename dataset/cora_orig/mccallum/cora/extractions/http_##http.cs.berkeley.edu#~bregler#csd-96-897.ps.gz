URL: http://http.cs.berkeley.edu/~bregler/csd-96-897.ps.gz
Refering-URL: http://http.cs.berkeley.edu/~bregler/pubs.html
Root-URL: 
Email: email: bregler@cs.berkeley.edu, malik@cs.berkeley.edu  
Title: Learning Appearance Based Models: Hierarchical Mixtures of Experts Approach based on Generalized Second Moments  
Author: Christoph Bregler and Jitendra Malik 
Keyword: Learning, Appearance Based Object Recognition, Filter Banks, Texture Statistics, Second Moment Matrix, Mixtures of Experts, Car Classification.  
Address: Berkeley, CA 94720  
Affiliation: Computer Science Division University of California at Berkeley  
Abstract: This paper describes a new technique for object recognition based on learning appearance models. The image is decomposed into local regions which are described by a new texture representation derived from the output of multiscale, multiorientation filter banks. We call this representation Generalized Second Moments as it can be viewed as a generalization of the windowed second moment matrix representation used by Garding & Lindeberg. Class-characteristic local texture features and their global composition is learned by a hierarchical mixture of experts architecture (HME by Jordan & Jacobs). The technique is applied to a vehicle database consisting of 5 general car categories (Sedan, Van with back-doors, Van without back-doors, old Sedan, and Volkswagen Bug). This is a difficult problem with considerable in-class variation. The new technique has a 6:5% misclassification rate, compared to eigen-images which give 17:4% misclassification rate, and nearest neighbors which give 15:7% misclassification rate. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. Beymer, A. Shahsua, and T. Poggio. </author> <title> Example based image analysis and synthesis. M.I.T. </title> <journal> A.I. </journal> <volume> Memo No. 1431, </volume> <month> Nov </month> <year> 1993. </year>
Reference-contexts: More powerful techniques for object classification are multi-layer-perceptrons [22]. [3] showed successfully how appearance-based recognition can be done using such techniques. Another version of neural networks are so called Radial-Basis-Networks. Radial-basis-functions can be circular Gaussian modeling receptive fields. <ref> [1, 15] </ref> demonstrated how such networks can be used for classification and interpolation. 3.1 Mixtures of Experts The idea is the following: Experts are classifiers that are specialized on certain sub-domains. A gating function or mixture function weights the different experts and builds a combined classification hypothesis.
Reference: [2] <author> R. Brunelli and T. Poggio. </author> <title> Face Recognition: Features versus Templates. </title> <journal> IEEE Trans. Pattern Anal. Mach. Intell., </journal> <volume> 15(10) </volume> <pages> 1042-1052, </pages> <month> October </month> <year> 1993. </year>
Reference-contexts: Intermediate solutions impose explicit structure to some extent, but allow for data driven estimation of the global structural and local textural features. The domain of face recognition is a popular application for such decompositions <ref> [17, 2, 12, 11] </ref>. We propose a domain independent part decomposition using a 2D grid representation of overlapping local image regions. The image features of each local patch are represented using a new texture descriptor that we call Generalized Second Moments. <p> Object classification should be based on these local part descriptions and the relationship between the parts. The partitioning reduces the complexity greatly and invariance to the precise relation between the parts could be achieved. Examples of learning architectures that use domain specific part decompositions may be found in <ref> [2, 17, 12, 11] </ref> for face recognition. A more general decomposition based on line and circular edge segments is proposed by [21]. For our domain of vehicle classification we don't believe it is appropriate to explicitly code any part decomposition.
Reference: [3] <author> C.J.C. Burges, J.I. Ben, J.S. Denker, and Y. et al. Lecun. </author> <title> Off line recognition of handwritten postal words using neural networks. </title> <journal> International Journal of Pattern Recognition and Artificial Intelligence, </journal> <volume> 7(4) </volume> <pages> 689-704, </pages> <year> 1993. </year>
Reference-contexts: The most extreme solutions start with raw unprocessed images and show how task based feature detectors can be learned from a large image database automatically <ref> [26, 16, 20, 3, 25] </ref>. Neglecting any preprocessing is mainly motivated by the concern not to loose any useful information for the final classification. To the other extreme belong approaches that assume that mid-level representations like outlines or contour images can be estimated robustly using hard-decision heuristics. <p> In our case this is unnecessary, because the generalized second moments provide this invariance already. These techniques are very storage intensive and for that very slow in recall. More powerful techniques for object classification are multi-layer-perceptrons [22]. <ref> [3] </ref> showed successfully how appearance-based recognition can be done using such techniques. Another version of neural networks are so called Radial-Basis-Networks.
Reference: [4] <author> W. Freeman and E Adelson. </author> <title> The design and use of steerable filters. </title> <journal> IEEE Trans. Pattern Anal. Mach. Intell., </journal> <volume> 13 </volume> <pages> 891-906, </pages> <year> 1991. </year>
Reference-contexts: If more than one orientation is present at a single point (e.g. junctions) there is more than one local maxima across the orientation selective responses. The computation time of such convolutions can be significantly reduced with efficient methods proposed by <ref> [18, 4] </ref>. Instead of convolving the image with a rich family of orientation and scales, a small set of simple X-Y separable, steerable, and scalable basis functions can be found.
Reference: [5] <author> W. Freeman and M. Roth. </author> <title> Orientation histogrmas for hand gesture recognition. </title> <booktitle> In International Workshop on Automatic Face- and Gesture-Recognition, </booktitle> <year> 1995. </year>
Reference-contexts: The disadvantage is that gradients are not very orientation selective and a certain scale has to be selected beforehand. Averaging the gradients washes out the detailed orientation information in complex texture regions. Orientation histograms would avoid this effect <ref> [5] </ref>. Elongated families of oriented and scaled kernels could be used to estimate the orientation at each point.
Reference: [6] <author> J. Garding and T. Lindeberg. </author> <title> Direct computation of shape cues using scale-adapted spatial derivative operators. </title> <note> to appear in Int. J. </note> <institution> of Computer Vision, </institution> <year> 1995. </year>
Reference-contexts: There might be many such interesting points in an image region. It is unclear how to pick the right number of points and how to order them. Another way of representing the texture in a local region is done by <ref> [6] </ref> in calculating a windowed second moment matrix. Instead of finding maximum filter responses, the second moments of brightness gradients in the local neighborhood are weighted and averaged with a 4 selected location. Right image: The angle and scale distribution of the filter response at the selected location. <p> Looking at the weight matrices of the experts trained on simpler second moment matrices we found some interesting constellations. We used just two basis kernels, a vertical and a horizontal first Gaussian derivative, which results in 3 numbers per local tile (similar to <ref> [6] </ref>). This allows us to interpret the learned weights better. Figure 9 shows the weights back-projected into the 10 fi 10 fi 3 grid space. Each of the five rows represents the weights used for each of the five categories.
Reference: [7] <author> D.J. Heeger. </author> <title> Optical flow using spatiotemporal filters. </title> <journal> Int. J. of Computer Vision, </journal> <volume> 1, </volume> <year> 1988. </year>
Reference-contexts: Besides edge information the response values of such filters contain much more general information about the local neighborhood. It is a mature representation used in other early vision tasks like stereopsis [8], motion, <ref> [28, 7, 27] </ref>, and texture discrimination [14]. Although this approach is loosely inspired by the current understanding of processing in the early stages of the primate visual system, the use of spatial filters has many advantages from a pure analytical viewpoint.
Reference: [8] <author> D. Jones and J. Malik. </author> <title> Computational framework for determining stereo correspondence from a set of linear spatial filters. </title> <journal> Image and Vision Computing, </journal> <volume> 10(10), </volume> <year> 1992. </year>
Reference-contexts: Besides edge information the response values of such filters contain much more general information about the local neighborhood. It is a mature representation used in other early vision tasks like stereopsis <ref> [8] </ref>, motion, [28, 7, 27], and texture discrimination [14]. Although this approach is loosely inspired by the current understanding of processing in the early stages of the primate visual system, the use of spatial filters has many advantages from a pure analytical viewpoint.
Reference: [9] <author> M.I. Jordan and R. A. Jacobs. </author> <title> Hierarchical mixtures of experts and the em algorithm. </title> <journal> Neural Computation, </journal> <volume> 6(2), </volume> <month> March </month> <year> 1994. </year> <month> 13 </month>
Reference-contexts: The image features of each local patch are represented using a new texture descriptor that we call Generalized Second Moments. Based on this representation we learn class-based local features and their global relationships using a Hierarchical Mixtures of Experts Architecture (HME) <ref> [9] </ref>. Multiple experts are trained to classify object categories. Each expert is a generalized linear model (GLIM) that maps the grid based feature representation into a class probability vector. Potentially different experts are responsible for different object poses or sub-categories. <p> A gating function or mixture function weights the different experts and builds a combined classification hypothesis. Potentially each expert could be a specialist for a certain object pose or sub-category. 7 Hierarchical Mixtures of Experts (HME <ref> [9] </ref>) are tree-structured mixture models in which both the mixture coefficients and the mixture components are generalized linear models (see below). The mixture components or gating functions divide the feature vector space into a nested set of regions. <p> The final classification result is the weighted average of all local expert classifications y i . Given the training data and output labels, the gating functions and expert functions can be estimated using an iterative version of the EM-algorithm. For more detail see <ref> [9] </ref>. 3.1.1 Linear subspace projection As mentioned earlier our feature representation consists of 3000 dimensional vectors. For a 5 category classification problem this would mean we have to estimate for each expert a 3000 fi 5 dimension matrix and for each gating function a 3000 dimensional vector.
Reference: [10] <author> D. Koller, J. Weber, and J. Malik. </author> <title> Towards realtime visual based tracking in cluttered traffic scenes. </title> <booktitle> In Proceedings of the Intelligent Vehicles Symposium, </booktitle> <address> Paris, </address> <year> 1994. </year>
Reference-contexts: Surveillance cameras are far apart from each other 9 which require one to match cars seen in one segment to cars seen in another segment. We are able to segment each moving object based on motion cues <ref> [10] </ref>. Given the car segmentation 5 broader car categories should be classified: Modern Sedan, Old Sedan, Van with back-doors, Van without back-door, and Volkswagen Bug. The images show the rear of the car across a small set of poses. All images are normalized to 100x100 pixel using bilinear interpolation.
Reference: [11] <author> A. Lanitis, Taylor C.J., Cootes T.F., and Ahmed T. </author> <title> Automatic interpretation of human faces and hand gestures using flexible models. </title> <booktitle> In International Workshop on Automatic Face- and Gesture-Recognition, </booktitle> <year> 1995. </year>
Reference-contexts: Intermediate solutions impose explicit structure to some extent, but allow for data driven estimation of the global structural and local textural features. The domain of face recognition is a popular application for such decompositions <ref> [17, 2, 12, 11] </ref>. We propose a domain independent part decomposition using a 2D grid representation of overlapping local image regions. The image features of each local patch are represented using a new texture descriptor that we call Generalized Second Moments. <p> Object classification should be based on these local part descriptions and the relationship between the parts. The partitioning reduces the complexity greatly and invariance to the precise relation between the parts could be achieved. Examples of learning architectures that use domain specific part decompositions may be found in <ref> [2, 17, 12, 11] </ref> for face recognition. A more general decomposition based on line and circular edge segments is proposed by [21]. For our domain of vehicle classification we don't believe it is appropriate to explicitly code any part decomposition.
Reference: [12] <author> T. Leung, Burl M.C., and Perona P. </author> <title> Finding face in cluttered scenes using random labelled graph matching. </title> <booktitle> In Proc. Int. Conf. Computer Vision, </booktitle> <year> 1995. </year>
Reference-contexts: Intermediate solutions impose explicit structure to some extent, but allow for data driven estimation of the global structural and local textural features. The domain of face recognition is a popular application for such decompositions <ref> [17, 2, 12, 11] </ref>. We propose a domain independent part decomposition using a 2D grid representation of overlapping local image regions. The image features of each local patch are represented using a new texture descriptor that we call Generalized Second Moments. <p> Object classification should be based on these local part descriptions and the relationship between the parts. The partitioning reduces the complexity greatly and invariance to the precise relation between the parts could be achieved. Examples of learning architectures that use domain specific part decompositions may be found in <ref> [2, 17, 12, 11] </ref> for face recognition. A more general decomposition based on line and circular edge segments is proposed by [21]. For our domain of vehicle classification we don't believe it is appropriate to explicitly code any part decomposition. <p> How could a local image region be described with just a few numbers? Representing the region with all filter responses at all locations is not feasible because of the high dimensionality. <ref> [12] </ref> investigated heuristics how to find interesting locations that are representative for the local neighborhood. Locations with local magnitude maxima or high responses across several directions could be interesting points. There might be many such interesting points in an image region.
Reference: [13] <author> J. Malik and P. Perona. </author> <title> Detecting edges composed of steps, peaks and roofs. </title> <booktitle> In Proc. 3 rd Int. Conf. Computer Vision, </booktitle> <year> 1990. </year>
Reference-contexts: This requires hard decision thresholds. We like to avoid such heuristics and we like to capture a much richer set of geometric and non-geometrical information. Convolving image regions with a large number of spatial filters, at various orientations, phases, and scales is the first step of robust edge detection <ref> [13] </ref>. Besides edge information the response values of such filters contain much more general information about the local neighborhood. It is a mature representation used in other early vision tasks like stereopsis [8], motion, [28, 7, 27], and texture discrimination [14].
Reference: [14] <author> J. Malik and P. Perona. </author> <title> Preattentive texture discrimination with early vision mechanisms. </title> <journal> J. Opt. Soc. Am. A, </journal> <volume> 7(5) </volume> <pages> 923-932, </pages> <year> 1990. </year> <note> Also appeared as a chapter in Computer vision: advances and applications, </note> <editor> Ed. R. Kasturi and R. Jain, </editor> <publisher> IEEE Computer Society Press, </publisher> <year> 1991. </year>
Reference-contexts: Besides edge information the response values of such filters contain much more general information about the local neighborhood. It is a mature representation used in other early vision tasks like stereopsis [8], motion, [28, 7, 27], and texture discrimination <ref> [14] </ref>. Although this approach is loosely inspired by the current understanding of processing in the early stages of the primate visual system, the use of spatial filters has many advantages from a pure analytical viewpoint. Usually the filter kernels are highly orientation selective elongated Gaussian derivatives.
Reference: [15] <author> S. Mukherjee and S. K. Nayar. </author> <title> Automatic generation of grbf networks for visual learning. </title> <booktitle> In Proc. Int. Conf. Computer Vision, </booktitle> <year> 1995. </year>
Reference-contexts: More powerful techniques for object classification are multi-layer-perceptrons [22]. [3] showed successfully how appearance-based recognition can be done using such techniques. Another version of neural networks are so called Radial-Basis-Networks. Radial-basis-functions can be circular Gaussian modeling receptive fields. <ref> [1, 15] </ref> demonstrated how such networks can be used for classification and interpolation. 3.1 Mixtures of Experts The idea is the following: Experts are classifiers that are specialized on certain sub-domains. A gating function or mixture function weights the different experts and builds a combined classification hypothesis.
Reference: [16] <author> H. Murase and S.K. Nayar. </author> <title> Learning and recognition of 3-d objects from brightness images. </title> <booktitle> In Proc. AAAI Fall Symposium: Machine Learning in Computer Vision: What, Why, and How?, </booktitle> <year> 1993. </year>
Reference-contexts: The most extreme solutions start with raw unprocessed images and show how task based feature detectors can be learned from a large image database automatically <ref> [26, 16, 20, 3, 25] </ref>. Neglecting any preprocessing is mainly motivated by the concern not to loose any useful information for the final classification. To the other extreme belong approaches that assume that mid-level representations like outlines or contour images can be estimated robustly using hard-decision heuristics. <p> It should capture both local textural and global structural information. This corresponds roughly to the notion in 3D object models of (i) parts (ii) relationship between parts. 2.1 Structural Description Examples of representations that implicitly capture the global and local structure are Eigen-Images [26], and nonlinear subspace-representations <ref> [16] </ref> of graylevel images. To span all object configurations, pose, and lighting conditions, large training image databases are crucial to the success of these representations. Objects usually can be decomposed into parts. A face consists of eyes, nose, and mouth.
Reference: [17] <author> A. Pentland, B. Moghaddam, and T. Starner. </author> <title> View-based and modular eigenspaces for face recognition. </title> <journal> Proc. IEEE Comput. Soc. Conf. Comput. Vision and Pattern Recogn., </journal> <year> 1994. </year>
Reference-contexts: Intermediate solutions impose explicit structure to some extent, but allow for data driven estimation of the global structural and local textural features. The domain of face recognition is a popular application for such decompositions <ref> [17, 2, 12, 11] </ref>. We propose a domain independent part decomposition using a 2D grid representation of overlapping local image regions. The image features of each local patch are represented using a new texture descriptor that we call Generalized Second Moments. <p> Object classification should be based on these local part descriptions and the relationship between the parts. The partitioning reduces the complexity greatly and invariance to the precise relation between the parts could be achieved. Examples of learning architectures that use domain specific part decompositions may be found in <ref> [2, 17, 12, 11] </ref> for face recognition. A more general decomposition based on line and circular edge segments is proposed by [21]. For our domain of vehicle classification we don't believe it is appropriate to explicitly code any part decomposition.
Reference: [18] <author> P. Perona. </author> <title> Deformable kernels for early vision. </title> <journal> Proc. IEEE Comput. Soc. Conf. Comput. Vision and Pattern Recogn., </journal> <pages> pages 222-227, </pages> <address> Maui, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: If more than one orientation is present at a single point (e.g. junctions) there is more than one local maxima across the orientation selective responses. The computation time of such convolutions can be significantly reduced with efficient methods proposed by <ref> [18, 4] </ref>. Instead of convolving the image with a rich family of orientation and scales, a small set of simple X-Y separable, steerable, and scalable basis functions can be found.
Reference: [19] <author> R. W. Picard and T. P. Minka. </author> <title> Vision texture for annotation. </title> <journal> ACM/Springer Journal of Multimedia Systems, </journal> <volume> 3, </volume> <year> 1995. </year>
Reference-contexts: The generic grid representation allows the learning architecture to induce class-based part decomposition, and extract local texture and global shape features. For example the outline of a face could be represented as 1 A similar grid representation is used by <ref> [19] </ref> but only local classification for each tile region is done. 3 certain orientation dominance in the local tiles at positions of the face boundary (Figure 1). The eyes are other characteristic features in the tiles. 2.2 Local Features We like to extract from each local tile characteristic features.
Reference: [20] <author> D. Pomerleau. </author> <title> Neural Network Perception for Mobile Robot Guidance. </title> <publisher> Kluwer Academic Pubulishing, </publisher> <year> 1994. </year>
Reference-contexts: The most extreme solutions start with raw unprocessed images and show how task based feature detectors can be learned from a large image database automatically <ref> [26, 16, 20, 3, 25] </ref>. Neglecting any preprocessing is mainly motivated by the concern not to loose any useful information for the final classification. To the other extreme belong approaches that assume that mid-level representations like outlines or contour images can be estimated robustly using hard-decision heuristics.
Reference: [21] <author> A. Pope and Lowe D. </author> <title> Learning 3d object recognition models from 2d images. </title> <booktitle> In AAAI Fall Workshop on Machine Learning in Computer Vision, </booktitle> <year> 1993. </year>
Reference-contexts: To the other extreme belong approaches that assume that mid-level representations like outlines or contour images can be estimated robustly using hard-decision heuristics. Learning starts at this level and algorithms are proposed that deal with inducing models for geometrical configurations <ref> [21, 23] </ref>. Intermediate solutions impose explicit structure to some extent, but allow for data driven estimation of the global structural and local textural features. The domain of face recognition is a popular application for such decompositions [17, 2, 12, 11]. <p> Examples of learning architectures that use domain specific part decompositions may be found in [2, 17, 12, 11] for face recognition. A more general decomposition based on line and circular edge segments is proposed by <ref> [21] </ref>. For our domain of vehicle classification we don't believe it is appropriate to explicitly code any part decomposition. The kind and number of useful parts might vary across different car makes. The resolution of the images (100x100 pixel) restricts us to a certain degree of granularity. <p> The eyes are other characteristic features in the tiles. 2.2 Local Features We like to extract from each local tile characteristic features. Certainly images of cars contain lines and curves. A representation based on straight and circular edge segments is proposed by <ref> [21] </ref>. This requires hard decision thresholds. We like to avoid such heuristics and we like to capture a much richer set of geometric and non-geometrical information.
Reference: [22] <author> D. E. Rummelhart, G. E. Hinton, and R. J. Williams. </author> <title> Learning Representations by Back-Propagating Errors. </title> <journal> Nature, </journal> <volume> 323(9) </volume> <pages> 533-536, </pages> <month> October </month> <year> 1986. </year>
Reference-contexts: In our case this is unnecessary, because the generalized second moments provide this invariance already. These techniques are very storage intensive and for that very slow in recall. More powerful techniques for object classification are multi-layer-perceptrons <ref> [22] </ref>. [3] showed successfully how appearance-based recognition can be done using such techniques. Another version of neural networks are so called Radial-Basis-Networks.
Reference: [23] <author> S. Sclaroff and A. Pentland. </author> <title> Modal matching for correspondence and recognition. </title> <journal> IEEE Trans. Pattern Anal. Mach. Intell., </journal> <month> June </month> <year> 1995. </year>
Reference-contexts: To the other extreme belong approaches that assume that mid-level representations like outlines or contour images can be estimated robustly using hard-decision heuristics. Learning starts at this level and algorithms are proposed that deal with inducing models for geometrical configurations <ref> [21, 23] </ref>. Intermediate solutions impose explicit structure to some extent, but allow for data driven estimation of the global structural and local textural features. The domain of face recognition is a popular application for such decompositions [17, 2, 12, 11].
Reference: [24] <author> D. Shy and P. Perona. </author> <title> X-y separable steerable filters. Computation and Neural Systems Technical Report 33, </title> <institution> California Institute of Technology, </institution> <month> October </month> <year> 1993. </year>
Reference-contexts: We compute at each point (x; y) the filter response of a finite set of R basis kernels (F 1 (x; y); :::; F R (x; y)). These kernels are generated using the technique of X-Y separable steerable scalable approximations of filter kernels by <ref> [24] </ref>.
Reference: [25] <author> P. Simard, Y. LeCun, and J. Denker. </author> <title> Efficient pattern recognition using a new transformation distance. </title> <booktitle> In Advances in Neural Information Processing Systems, </booktitle> <year> 1993. </year> <month> 14 </month>
Reference-contexts: The most extreme solutions start with raw unprocessed images and show how task based feature detectors can be learned from a large image database automatically <ref> [26, 16, 20, 3, 25] </ref>. Neglecting any preprocessing is mainly motivated by the concern not to loose any useful information for the final classification. To the other extreme belong approaches that assume that mid-level representations like outlines or contour images can be estimated robustly using hard-decision heuristics. <p> An example database of labeled feature vectors is kept in storage. A new test feature vector is classified in finding the closest example vector in the database. Distance metrics could be the Euclidean distance. A more complex distance metric is the tangent-distance <ref> [25] </ref> which is invariant to slight shifting, rotation, and scaling if the feature vectors would be raw pixel images. In our case this is unnecessary, because the generalized second moments provide this invariance already. These techniques are very storage intensive and for that very slow in recall.
Reference: [26] <author> M. Turk and A. Pentland. </author> <title> Eigenfaces for recognition. </title> <journal> Journal of Cognitive Neuroscience, </journal> <volume> 3(1) </volume> <pages> 71-86, </pages> <year> 1991. </year>
Reference-contexts: The most extreme solutions start with raw unprocessed images and show how task based feature detectors can be learned from a large image database automatically <ref> [26, 16, 20, 3, 25] </ref>. Neglecting any preprocessing is mainly motivated by the concern not to loose any useful information for the final classification. To the other extreme belong approaches that assume that mid-level representations like outlines or contour images can be estimated robustly using hard-decision heuristics. <p> It should capture both local textural and global structural information. This corresponds roughly to the notion in 3D object models of (i) parts (ii) relationship between parts. 2.1 Structural Description Examples of representations that implicitly capture the global and local structure are Eigen-Images <ref> [26] </ref>, and nonlinear subspace-representations [16] of graylevel images. To span all object configurations, pose, and lighting conditions, large training image databases are crucial to the success of these representations. Objects usually can be decomposed into parts. A face consists of eyes, nose, and mouth.
Reference: [27] <author> J. Weber and J. Malik. </author> <title> Robust computation of optical flow in a multi-scale differential framework. </title> <journal> International Journal of Computer Vision, </journal> <volume> 14(1), </volume> <year> 1995. </year>
Reference-contexts: Besides edge information the response values of such filters contain much more general information about the local neighborhood. It is a mature representation used in other early vision tasks like stereopsis [8], motion, <ref> [28, 7, 27] </ref>, and texture discrimination [14]. Although this approach is loosely inspired by the current understanding of processing in the early stages of the primate visual system, the use of spatial filters has many advantages from a pure analytical viewpoint.
Reference: [28] <author> Y. Xiong and S. A. Shafer. </author> <title> Hypergeometric filters for optical flow and affine matching. </title> <booktitle> In Proc. Int. Conf. Computer Vision, </booktitle> <year> 1995. </year> <month> 15 </month>
Reference-contexts: Besides edge information the response values of such filters contain much more general information about the local neighborhood. It is a mature representation used in other early vision tasks like stereopsis [8], motion, <ref> [28, 7, 27] </ref>, and texture discrimination [14]. Although this approach is loosely inspired by the current understanding of processing in the early stages of the primate visual system, the use of spatial filters has many advantages from a pure analytical viewpoint.
References-found: 28

