URL: ftp://ftp.cs.cmu.edu/project/chimera/npapas.randa95.ps.gz
Refering-URL: http://www.cs.cmu.edu/~kem/ri/unused_pages/aml-pubs.html
Root-URL: 
Title: Six Degree-of-Freedom Hand/Eye Visual Tracking with Uncertain Parameters  
Author: Nikolaos P. Papanikolopoulos Bradley J. Nelson and Pradeep K. Khosla 
Keyword: Robotic Visual Servoing, Adaptive Control, Image Motion, Calibration.  
Abstract: Algorithms for full 3D robotic visual tracking of moving targets whose motion is 3D and consists of translational and rotational components are presented. The objective of the system is to track selected features on moving objects and to place their projections on the image plane at desired positions by appropriate camera motion. The most important characteristics of the proposed algorithms are the use of a single camera mounted on the end-effector of a robotic manipulator (eye-in-hand configuration), and the fact that these algorithms do not require accurate knowledge of the relative distance of the target object from the camera frame. The detection of motion is based on a cross-correlation technique known as Sum-of-Squares Differences (SSD) algorithm. The camera model used introduces a number of parameters that are estimated on-line, further reducing the algorithms reliance on precise calibration of the system. An adaptive control algorithm compensates for modeling errors, tracking errors, and unavoidable computational delays which result from time-consuming image processing. Experimental results are presented to verify the efficacy of the proposed algorithms and to highlight the limitations of the approach. These experiments were performed using a multi-robotic system consisting of Puma 560 manipulators. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P. Anandan, </author> <title> A Computational Framework and an Algorithm for the Measurement of Visual Motion, </title> <journal> in International Journal of Computer Vision, </journal> <volume> 2(3), </volume> <pages> pp. 283-310, </pages> <year> 1988. </year>
Reference-contexts: We use a single camera mounted on the end-effector of a six degree-of-freedom manipulator in order to demonstrate that relatively unsophisticated off-the-shelf hardware can be used to solve the 3D tracking problem. Visual mea page 3 surements are based on a pyramidal Sum-of-Squares Differences (SSD) algorithm <ref> [1] </ref>. A properly formulated adaptive control algorithm (designed on several simplifying assumptions) uses these measurements to determine the correct input to a cartesian robot controller.
Reference: [2] <author> D.H. Ballard and C.M. Brown, </author> <title> Computer Vision, </title> <publisher> Prentice Hall, Inc., </publisher> <address> Englewood Cliffs, N.J., </address> <year> 1982. </year>
Reference: [3] <author> F. Chaumette, P. Rives, and B. Espiau, </author> <title> Positioning of a Robot with Respect to an Object, Tracking it, and Estimating its Velocity by Visual Servoing, </title> <booktitle> in Proc. of the IEEE Int. Conf. on Robotics and Automation, </booktitle> <pages> pp. 2248-2253, </pages> <month> April, </month> <year> 1991. </year>
Reference: [4] <author> E.D. Dickmanns, B. Mysliwetz, and T. Christians, </author> <title> An Integrated Spatio-Temporal Approach to Automatic Visual Guidance of Autonomous Vehicles, </title> <journal> in IEEE Trans. on Systems, Man, and Cybernetics, </journal> <volume> 20(6), </volume> <pages> pp. 1273-1284, </pages> <year> 1990. </year>
Reference: [5] <author> J.T. Feddema and C.S.G. Lee, </author> <title> Adaptive Image Feature Prediction and Control for Visual Tracking with a Hand-Eye Coordinated Camera, </title> <journal> in IEEE Trans. on Systems, Man, and Cybernetics, </journal> <volume> 20(5), </volume> <pages> pp. </pages> <year> 1172-1183,1990. </year>
Reference-contexts: Thus, we directly control the magnitudes of the control signal and the control signal change. This results in a control law that is more robust and feasible than the one proposed in <ref> [5] </ref>. It should be noted that the term Du (k)L d Du (k) in the cost function (23) introduces an integral term into the control law. This term is desirable since our mathematical model (21) has a deterministic disturbance component. <p> This estimation scheme requires the use of one parameter per feature point making it computa tionally realistic for real-time control. Some researchers, for example <ref> [5] </ref>, propose the use of an adaptive scheme which estimates all of the elements of the matrix B (k) on-line. As reported in [5], z o z o 2 + j ( ) k 1-( ) + j ( ) k 2-( ) + j ( ) k 1-( ) f <p> This estimation scheme requires the use of one parameter per feature point making it computa tionally realistic for real-time control. Some researchers, for example <ref> [5] </ref>, propose the use of an adaptive scheme which estimates all of the elements of the matrix B (k) on-line. As reported in [5], z o z o 2 + j ( ) k 1-( ) + j ( ) k 2-( ) + j ( ) k 1-( ) f + j ( ) + j ( ) = (42) + j ( ) j ( ) j ( ) + j (
Reference: [6] <author> J.T. Feddema, C.S.G. Lee, and O.R. Mitchell, </author> <title> Weighted Selection of Image Features for Resolved Rate Visual Feedback Control, </title> <journal> in IEEE Trans. on Robotics and Automation, </journal> <volume> 7(1), </volume> <pages> pp. 31-47, </pages> <year> 1991. </year>
Reference: [7] <author> D. Forsyth, J.L. Mundy, A. Zisserman, C. Coelho, A. Heller, and C. Rothwell, </author> <title> Invariant Descriptors for 3-D Object Recognition and Pose, </title> <journal> in IEEE Trans. on Pattern Analysis and Machine Intelligence, </journal> <volume> 13(10), </volume> <pages> pp. 971-991. </pages>
Reference: [8] <author> G.C. Goodwin and K.S. </author> <title> Sin, Information and Systems Science SeriesVolume 1: Adaptive Filtering, Prediction and Control, </title> <publisher> Prentice-Hall, Inc., </publisher> <address> Englewood Cliffs, N.J., </address> <year> 1984. </year>
Reference-contexts: These techniques use the estimated values of the unknown parameters in order to compute the control signal. This approach is called certainty equivalence adaptive control <ref> [8] </ref>. A variety of tracking algorithms can be created depending on the parameter estimation schemes and control laws chosen. The rest of this section is devoted to a description of the control and estimation schemes, and highlights the differences from the techniques reported in [16]. 3.1. <p> The new con trol law is (based on the certainty equivalence principle <ref> [8] </ref>) where is the estimated value of the matrix B (k). The matrix is dependent on the esti mated values of the features depth (j -1,2,...,M-) and the coordinates of the features image projections.
Reference: [9] <author> R.M. Haralick, C. Lee, K. Ottenberg, and M. Nolle, </author> <title> Analysis and Solutions of the Three Point Perspective Pose Estimation Problem, </title> <booktitle> in Proc. IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pp. 592-598, </pages> <year> 1991. </year>
Reference: [10] <author> A.J. Koivo and N. Houshangi, </author> <title> Real-Time Vision Feedback for Servoing of a Robotic Manipulator with Self-Tuning Controller, </title> <journal> in IEEE Trans. on Systems, Man, and Cybernetics, </journal> <volume> 21(1), </volume> <pages> pp. </pages> <year> 134-142,1991. </year>
Reference: [11] <author> R. Krishmam, H.J. Sommer III, and P.D. Spidaliere, </author> <title> Monocular Pose of a Rigid Body Using Point Landmarks, </title> <booktitle> in CVGIP: Image Understanding, </booktitle> <volume> 55(2), </volume> <pages> pp. 307-316, </pages> <year> 1992. </year>
Reference: [12] <author> F.L. Lewis, </author> <title> Optimal Control, </title> <publisher> John Wiley and Sons, </publisher> <address> New York, </address> <year> 1986. </year>
Reference-contexts: Finally, several researchers [7][9][11][18] in computer vision have studied this problem from the pose estimation perspective. Unfortunately, no standard procedure exists for choosing the individual elements of L, L d , and Q. A common technique to employ is the optimization technique <ref> [12] </ref>.
Reference: [13] <author> P.S. Maybeck, </author> <title> Stochastic Processes, Estimation, and Control, </title> <publisher> Academic Press, </publisher> <address> London, </address> <year> 1979. </year>
Reference-contexts: The term is a covariance scalar which corresponds to the white noise that characterizes the transition between states and is assumed con stant. N (j) (k) is the constant predefined covariance matrix of the gaussian noise vector . The recursive equations are given by <ref> [13] </ref> The depth related parameter is time-varying since the target and the camera move in 3D. The estimation scheme described by equations (44)-(48) can compensate for the time-varying nature of , because the scheme was designed under the assumption that the estimated vari able undergoes a random change.
Reference: [14] <author> N.P. Papanikolopoulos, </author> <title> Controlled Active Vision, </title> <type> Ph.D. Thesis, </type> <institution> Department of Electrical and Computer Engineering, Carnegie Mellon University, </institution> <month> August, </month> <year> 1992. </year>
Reference-contexts: 2 k ( )s y + x k ( )y k ( )s x - s y = (15) y F k ( ) C F x F k ( ) w F k ( )+= (16) page 6 y F (k) is computed using the SSD algorithm described in <ref> [14] </ref>. In addition, a method for automatic selection of features and on-line evaluation of visual measurements (useful in cases of sudden occlusion of features) is presented in [14]. <p> F k ( ) w F k ( )+= (16) page 6 y F (k) is computed using the SSD algorithm described in <ref> [14] </ref>. In addition, a method for automatic selection of features and on-line evaluation of visual measurements (useful in cases of sudden occlusion of features) is presented in [14]. In order to solve for the manipulator control input, it can be shown that at least three feature points which are not collinear are needed [17]. In other words, less than three feature points do not provide enough measurements in order to reliably compute the manipulator control input. <p> The matrix B (k) loses rank when the M feature points are collinear [5]<ref> [14] </ref>. An extensive study of other conditions which cause a loss of rank in B (k) can be found in [14]. Finally, several researchers [7][9][11][18] in computer vision have studied this problem from the pose estimation perspective. Unfortunately, no standard procedure exists for choosing the individual elements of L, L d , and Q. A common technique to employ is the optimization technique [12]. <p> Estimation of Depth Related Parameters There are several methods which can be used to estimate the depth related parameters that appear in . In this section, we describe one technique which we have successfully implemented, and in <ref> [14] </ref> we describe two other techniques which are related to the following scheme. The estimation scheme that is described is simpler and more effective than the one that we reported in [16]. <p> The schemes presented in <ref> [14] </ref> make this assumption, however, a more accurate form for the updated parameter equation (36) can be obtained. <p> Our proposed approach alleviates these computational problems. 4. Experiments The ability of the eye-in-hand system to successfully track objects whose motion is fully three dimensional using the vision, control, and estimation algorithms presented in this paper has been experimentally verified. These experiments are extensively described in <ref> [14] </ref>. The results of one of these experiments are presented in this section. <p> The delay factor d is 2. The vector of the desired coordinates of the features on the image plane, y D (k), is constant and is set to y D (k)=y (0). The initial values for the depth related parameters and their associated covariance scalars can be found in <ref> [14] </ref>. In particular, the initial values for the depth related parameters are different from the actual values by a factor of 4. <p> The four features (one in each image quadrant) on the object being tracked are selected by the user with a mouse, and the tracking quality of the features are then evaluated on-line based on the confidence measures described in <ref> [14] </ref>. In our experiment, the features are the four corners of the target. If a feature does not satisfy a confidence threshold, the user is asked to select a replacement object feature. In addition, the option of invoking an automatic feature selector is available. <p> If a feature does not satisfy a confidence threshold, the user is asked to select a replacement object feature. In addition, the option of invoking an automatic feature selector is available. A scheme for dealing with suddenly partially occluded targets is also presented in <ref> [14] </ref>. Figures 1 through 6 show the results from the experiment. The trajectory of the target is shown in z j ( ) j ( ) z j ( ) page 14 the initial end-effector frame at k=0, versus kT. <p> Deviations from desired X and Y positions never exceed 20 pixels during tracking, with the maximum deviations occurring immediately after the targets direction of motion abruptly changes. The maximum search range of the SSD algorithm presented in <ref> [14] </ref> is 32 pixels, so the errors in pixel position fall well within the tracking capabilities of the vision system. From the graphs, one can observe that the tracking and feature errors reach their maximum values immediately after the target trajectory changes direction to return to its initial pose. <p> The robustness of our algorithms has also been tested by adding artificial noise to the images and the results can be found in <ref> [14] </ref>. Two interesting observations can be made concerning the system based on the experimental results. First, error in the Z direction, along the optical axis, is relatively large when compared to errors along other directions. <p> These results demonstrate the robustness of the system to inaccurate initial estimates of system parameters, as well as the ability of the system to track different types of target trajectories. This work also demonstrates that the Controlled Active Vision paradigm <ref> [14] </ref> can be successfully used to extend the capabilities of eye-in-hand systems where other tracking methods have failed. 6.
Reference: [15] <author> N.P. Papanikolopoulos, P.K. Khosla, and T. Kanade, </author> <title> Vision and Control Techniques for Robotic Visual Tracking, </title> <booktitle> in Proc. of the IEEE Int. Conf. on Robotics and Automation, </booktitle> <pages> pp. 857-864, </pages> <month> April, </month> <year> 1991. </year> <pages> page 17 </pages>
Reference: [16] <author> N.P. Papanikolopoulos and P.K. Khosla, </author> <title> Adaptive Robotic Visual Tracking: Theory and Experiments, </title> <journal> in IEEE Trans. on Automatic Control, </journal> <volume> 38(3), pp.429-445, </volume> <year> 1993. </year>
Reference-contexts: Modeling of the Visual Servoing Problem To model the 3-D visual servoing problem, we first assume a pinhole model for the camera with a frame -C- placed at the focal point of the lens. This formulation was presented in <ref> [16] </ref> and is reviewed here. A feature on an object at P 1 with coordinates (X o ,Y o ,Z o ) in the camera frame 1. <p> A variety of tracking algorithms can be created depending on the parameter estimation schemes and control laws chosen. The rest of this section is devoted to a description of the control and estimation schemes, and highlights the differences from the techniques reported in <ref> [16] </ref>. 3.1. Selection of an Efficient Control Law As stated previously, the control objective is to track the motion of certain features on the target and place the projection of these features at some desired positions on the image plane. <p> In this section, we describe one technique which we have successfully implemented, and in [14] we describe two other techniques which are related to the following scheme. The estimation scheme that is described is simpler and more effective than the one that we reported in <ref> [16] </ref>.
Reference: [17] <author> N.P. Papanikolopoulos and P.K. Khosla, </author> <title> Selection of Features and Evaluation of Visual Measurements for 3-D Robotic Visual Tracking in Proc. </title> <booktitle> of the 1993 IEEE International Symposium on Intelligent Control, </booktitle> <pages> pp. 320-325, </pages> <month> August 25-27, </month> <year> 1993. </year>
Reference-contexts: In order to solve for the manipulator control input, it can be shown that at least three feature points which are not collinear are needed <ref> [17] </ref>. In other words, less than three feature points do not provide enough measurements in order to reliably compute the manipulator control input.
Reference: [18] <author> C.A. Rothwell, A. Zisserman, C.I. Marinos, D.A. Forsyth, and J.L. Mundy, </author> <title> Relative Motion and Pose from Arbitrary Plane Curves, </title> <booktitle> in Image and Vision Computing, </booktitle> <volume> 10(2), </volume> <pages> pp. 250-262, </pages> <year> 1992. </year>
Reference: [19] <author> L.S. Shapiro, H. Wang, and J.M. Brady, </author> <title> A Matching and Tracking Strategy for Independently Moving Objects, </title> <booktitle> in Proc. of the British Machine Vision Conference, </booktitle> <pages> pp. 306-315, </pages> <year> 1992. </year>
Reference: [20] <author> R. Szeliski and S.B. Kang, </author> <title> Recovering 3D Shape and Motion from Image Streams Using Nonlinear Least Squares, in Journal of Visual Communication and Image Representation, </title> <booktitle> 5(1), </booktitle> <pages> pp. 10-28, </pages> <year> 1994. </year>
Reference: [21] <author> L.E. Weiss, A.C. Sanderson, </author> <title> and C.P. Neuman, Dynamic Sensor-Based Control of Robots with Visual Feedback, </title> <journal> in IEEE Journal of Robotics and Automation RA-3(5), </journal> <pages> pp. 404-417, </pages> <month> October, </month> <year> 1987. </year> <note> page 18 initial pose. page 19 page 20 </note>
References-found: 21

