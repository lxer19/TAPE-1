URL: ftp://ftp.cs.toronto.edu/pub/bonner/papers/hypotheticals/pods89.ps
Refering-URL: http://www.cs.toronto.edu/DB/people/bonner/papers.html
Root-URL: 
Email: bonner@db.toronto.edu  
Title: Hypothetical Datalog: Negation and Linear Recursion  characterization of the relational queries in P  
Author: Anthony J. Bonner k 
Note: k Furthermore, these rulebases provide a complete  That is, any query whose graph is in P  
Address: New Brunswick, NJ 08903  
Affiliation: Department of Computer Science Rutgers University  
Abstract: This paper appears in the Proceedings of the ACM Symposium on the Principles of Database Abstract This paper examines an extension of Horn logic in which rules can add entries to a database hypothetically. Several researchers have developed logical systems along these lines, but the complexity and expressibility of such logics is only now being explored. It has been shown, for instance, that the data-complexity of these logics is P SP ACE-complete in the function-free, predicate case. This paper extends this line of research by developing syntactic restrictions with lower complexity. These restrictions are based on two ideas from Horn-clause logic: linear recursion and stratified negation. In particular, a notion of stratification is developed in which negation-as-failure alternates with linear recursion. The complexity of such rulebases depends on the number of layers of stratification. The result is a hierarchy of syntactic classes which corresponds exactly to the polynomial-time hierarchy of complexity classes. In particular, rule-bases with k strata are data-complete for P k can be represented as a set of hypothetical rules with k strata. Unlike other expressibility results in the literature, this result does not require the data domain to be linearly ordered. fl Published in the Proceedings of the Eighth ACM Symposium on Principles of Database Systems (PODS), pages 286-300, Philadelphia, Pennsylvania, March 29-31, 1989. c fl 1989 ACM 1 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> K.R. Apt, H.A. Blair, and A. Walker. </author> <title> Towards a Theory of Declarative Knowledge. </title> <editor> In Jack Minker, editor, </editor> <booktitle> Foundations of Deductive Databases and Logic Programming, chapter 2, </booktitle> <pages> pages 89-148. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1988. </year>
Reference-contexts: As in the Horn-clause case, however, if there is no recursion through negation, then there is no ambiguity. In this paper, therefore, we assume that negation is stratified <ref> [1] </ref>. This paper makes one other simplifying assumption: that only atomic queries are negated. That is, ~ A is allowed as a rule premise, but ~ A [add : B] is not. This restriction is a theoretical convenience but poses no serious limitations in practice. <p> The definitions below define stratification precisely. They are are generalizations of those given in <ref> [1] </ref> and [2]. The essential idea is to partition a rulebase into segments, numbered 1; :::; n. Even segments must contain hypothetical rules with linear recursion, and odd segments must contain Horn rules with stratified negation. <p> Subgoals not involving predicates defined in i are passed to P ROV E i . P ROV E i is a P -machine. Since i is essentially a set of stratified Horn rules, it can answer queries in polynomial time by generating the perfect model in a bottom-up fashion <ref> [1] </ref>. The only ru*e in this approach is that some of the rules in i may contain hypothetical premises A [add : B]. <p> The implementation of P ROV E i is therefore almost identical to the bottom-up method used to perform inference given a set of Horn rules with stratified negation <ref> [1] </ref>. Since negation in i is stratified, i can be partitioned into strata i1 ; :::; im i such that within each stratum, negation occurs only at the base level.
Reference: [2] <author> F. Bancilhon and R. Ramakrishnan. </author> <title> An Amateur's Introduction to Recursive Query Processing Strategies. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 16-52, </pages> <address> Washington, D.C., </address> <month> May 28-30 </month> <year> 1986. </year>
Reference-contexts: A rule is linear if recursion occurs through only one premise. In Horn-clause logic, "linear rules play an important role because, (i) there is a belief that most `real life' recursive rules are linear, and (ii) algorithms have been developed to handle them efficiently" <ref> [2] </ref>. Linearity, however, does not affect the data-complexity of Horn-clause rulebases, even when combined with negation-by-failure. In each case, the data-complexity is simply P . For hypothetical rules, the situation is more interesting. Firstly, linearity reduces their data-complexity from P SP ACE to N P . <p> To reduce complexity, we disallow such rules. We focus instead on rules in which recursion occurs through only one premise. In Horn logic, such rules are said to be linear <ref> [2] </ref>. Example 9. The following rulebase has three strata, the i th stratum defining the predicate A i . <p> The definitions below define stratification precisely. They are are generalizations of those given in [1] and <ref> [2] </ref>. The essential idea is to partition a rulebase into segments, numbered 1; :::; n. Even segments must contain hypothetical rules with linear recursion, and odd segments must contain Horn rules with stratified negation. A stratum is then defined to consist of two adjacent segments, one odd and one even. <p> To guarantee linearity, it is not enough that no rule have the form (1). For instance, each of the following n + 1 rules may appear linear, but taken together, they imply rule (1): A B; D 1 :::D n : Linearity is defined precisely for Horn rules in <ref> [2] </ref>, and is easily extended to include hypothetical rules.
Reference: [3] <author> A.J. Bonner. </author> <title> A Logic for Hypothetical Reasoning. </title> <booktitle> In Proceedings of the Seventh National Conference on Artificial Intelligence, </booktitle> <pages> pages 480-484, </pages> <address> Saint Paul, Minnesota, </address> <month> August 21-26 </month> <year> 1988. </year> <note> Published in expanded form as Technical Report TR-DCS-230, </note> <institution> Department of Computer Science, Rutgers University, </institution> <address> New Brunswick, NJ 08903. </address>
Reference-contexts: Note that the premise of the first rule is a hypothetical query similar to the one in example 2. <ref> [3] </ref> shows that there is a strong sense in which such rules cannot be expressed in Datalog. 3 Hypothetical Inference This section defines a logical inference system for hypothetical rules and queries. 3 It is an extension of Horn logic, both syntactically and proof theoretically, and some of the terminology is <p> In this paper, all formulas are are function-free. 3 See <ref> [3] </ref> for a proof that this inference system has an intuitionistic semantics. 4 Definition 1 A premise (or query) is an expression having one of the following forms: * A where A is an atomic formula. * A [add : B] where A and B are atomic formulas.
Reference: [4] <author> A.J. Bonner. </author> <title> Hypothetical Datalog: Complexity and Expressibility. </title> <booktitle> In Proceedings of the International Conference on Database Theory (ICDT), </booktitle> <pages> pages 144-160. </pages> <publisher> Springer-Verlag, </publisher> <year> 1988. </year> <note> Published as volume 326 of Lecture Notes in Computer Science. 27 </note>
Reference-contexts: McCarty has extended this work to a larger class of formulas and established interesting semantic results [16, 17]. Bonner has shown that query evaluation in such systems is data-complete for P SP ACE in the function-free predicate case (data-complete for EXP T IM E when hypothetical deletions are allowed) <ref> [4] </ref>. This paper extends this line of research by developing syntactic restrictions whose data-complexity is less that P SP ACE. Central to these restrictions is the idea of linearity. A rule is linear if recursion occurs through only one premise. <p> Thus, adding a single non-recursive rule to R has increased its complexity class from N P to N P [ coN P . 4 The proof of this is left as an exercise for the reader. 7 4 Linear Stratification In <ref> [4] </ref> it was shown that the inference system of section 3 is data-complete for P SP ACE. In this section, we develop syntactic restrictions with reduced complexity. Central to these restrictions are the ideas of linear recursion and stratified negation. <p> In particular, a new notion of stratification is developed in which linear recursion alternates with negation-by-failure. For such rulebases, data-complexity depends on the number of layers of stratification. Rulebases with k strata are data-complete for P k . P SP ACE-hardness was established in <ref> [4] </ref> by encoding the computations of alternating Turing machines.
Reference: [5] <author> A.J. Bonner. </author> <title> Hypothetical Datalog: Complexity and Expressibility. </title> <type> Technical Report DCS--TR-231, </type> <institution> Department of Computer Science, Rutgers university, </institution> <address> New Brunswick, NJ 08903, </address> <year> 1988. </year> <note> Also published in volume 76 (1990) of Theoretical Computer Science (TCS), pages 3-51. </note>
Reference-contexts: Since P ROV E i is virtually identical, it runs in polynomial time relative to an oracle for P ROV E i1 . 6 Expressibility In <ref> [5] </ref>, hypothetical rulebases with non-linear recursion were examined. Two results were established: (i) that the graphs of such rulebases are in P SP ACE, and (ii) that such rulebases can represent any typed, generic query whose graph is in P SP ACE. <p> F IRST (x) and LAST (y) are true iff x and y represent the integers 0 and n l 1, respectively. N EXT (x; y) is true iff y represents the integer x + 1. (See <ref> [5] </ref> for details). With this counter, l-tuples can be used to represent n l distinct points in time and n l distinct positions on tape. The composite machine M k ; :::; M 1 can therefore be encoded much as was done in section 5.1. <p> In particular, for each symbol c 2 f0; 1; bg, we can define a predicate IN IT c (j) which is true iff c is the initial value of the tape cell at position j. (See <ref> [5] </ref> for details). <p> This extension is centered on rules of the form A B [add : C], which intuitively means, "infer A if inserting C allows the inference of B." In <ref> [5] </ref> it was shown that such rulebases are data-complete for P SP ACE. The present paper has extended this line of research by developing syntactic restrictions with lower complexity. <p> In this way, the complexity of each stratum is in N P . The direct encoding of Turing machines not only establishes a lower complexity bound, it also helps establish expressibility results. In <ref> [5] </ref>, for instance, the encoding of alternating Turing machines was used to show that any database query computable in P SP ACE could be represented as a set of hypothetical rules.
Reference: [6] <author> A.K. Chandra and D. Harel. </author> <title> Computable Queries for Relational Databases. </title> <journal> Journal of Computer and System Sciences (JCSS), </journal> <volume> 21(2) </volume> <pages> 156-178, </pages> <year> 1980. </year>
Reference-contexts: Linearly-ordered domains are used to simulate counters, which in turn, are used to simulate tape-head movements. Our approach is to start with unordered domains and assert linear orders hypothetically. This technique works for all generic queries, that is, for all queries satisfying the consistency criterion of Chandra and Harel <ref> [6, 7] </ref>. 2 Examples This section gives several examples of hypothetical queries and rules. In each example, tuples are hypothetically inserted into the database before a least-fixpoint query is made. <p> A rulebase can, however, assert all possible linear-orders, one after another, and simulate the oracle machines for each one. This technique works as long as the machine encodings are insensitive to the particular linear-order being used. This is the case for database queries which are generic <ref> [6, 7] </ref>. A query is generic iff it satisfies the following consistency criterion: if the constants in the database are renamed in a consistent way, then the constants in the answer to the query are renamed in the same way. <p> The main results regarding queries are then stated and reduced to a single lemma, which is proved in the next section. The definitions are essentially those of <ref> [6] </ref> and [7]. 20 Definition 12 (Relational Database) Let U be a countable set, called the universal data domain. <p> The approach of this paper has been to start with unordered domains and to assert linear orders hypothetically. This technique works for all generic queries, that is, for all queries satisfying the consistency criterion of Chandra and Harel <ref> [6, 7] </ref>. Acknowledgements The work of Thorne McCarty on the intuitionistic semantics of embedded implications was the original stimulus for this work. Thanks go to Tomasz Imielinski for helpful comments on the paper.
Reference: [7] <author> A.K. Chandra and D. Harel. </author> <title> Structure and Complexity of Relational Queries. </title> <booktitle> In Proceedings of the Symposium on the Foundations of Computer Science (FOCS), </booktitle> <pages> pages 333-347, </pages> <year> 1980. </year>
Reference-contexts: Linearly-ordered domains are used to simulate counters, which in turn, are used to simulate tape-head movements. Our approach is to start with unordered domains and assert linear orders hypothetically. This technique works for all generic queries, that is, for all queries satisfying the consistency criterion of Chandra and Harel <ref> [6, 7] </ref>. 2 Examples This section gives several examples of hypothetical queries and rules. In each example, tuples are hypothetically inserted into the database before a least-fixpoint query is made. <p> The database DB (s) describes the initial tape contents of these machines. Since machines M k1 ; :::; M 1 act as oracles, their work tapes are initially blank. Thus, the following entries are 5 See <ref> [7] </ref> for examples of such languages. 6 Note that each machine can only provide its oracle with a string of polynomial length, so that the oracle runs in polynomial time, both in terms of its own input and the input of the machine which invoked it. 12 placed in DB (s): <p> A rulebase can, however, assert all possible linear-orders, one after another, and simulate the oracle machines for each one. This technique works as long as the machine encodings are insensitive to the particular linear-order being used. This is the case for database queries which are generic <ref> [6, 7] </ref>. A query is generic iff it satisfies the following consistency criterion: if the constants in the database are renamed in a consistent way, then the constants in the answer to the query are renamed in the same way. <p> The main results regarding queries are then stated and reduced to a single lemma, which is proved in the next section. The definitions are essentially those of [6] and <ref> [7] </ref>. 20 Definition 12 (Relational Database) Let U be a countable set, called the universal data domain. <p> The approach of this paper has been to start with unordered domains and to assert linear orders hypothetically. This technique works for all generic queries, that is, for all queries satisfying the consistency criterion of Chandra and Harel <ref> [6, 7] </ref>. Acknowledgements The work of Thorne McCarty on the intuitionistic semantics of embedded implications was the original stimulus for this work. Thanks go to Tomasz Imielinski for helpful comments on the paper.
Reference: [8] <author> D.M. Gabbay. N-Prolog: </author> <title> an Extension of Prolog with Hypothetical Implications. II. Logical Foundations and Negation as Failure. </title> <journal> Journal of Logic Programming (JLP), </journal> <volume> 2(4) </volume> <pages> 251-283, </pages> <year> 1985. </year>
Reference-contexts: In particular, they augment Horn-clause logic with rules of the form A B [add : C] which intuitively means, "infer A if inserting C allows the inference of B." The formal properties of these rules are still being explored. Gabbay has shown that they have an intuitionistic semantics <ref> [8] </ref>, and Miller has developed fixpoint semantics for the predicate case [19]. McCarty has extended this work to a larger class of formulas and established interesting semantic results [16, 17].
Reference: [9] <editor> D.M. Gabbay and U. Reyle. N-Prolog: </editor> <title> an Extension of Prolog with Hypothetical Implications. I. </title> <journal> Journal of Logic Programming (JLP), </journal> <volume> 1(4) </volume> <pages> 319-355, </pages> <year> 1984. </year>
Reference-contexts: Gabbay, for example, has reported a need to augment Prolog with hypothetical rules in order to encode the British Nationality Act. The act contains rules such as, "You are eligible for citizenship if your father would be eligible if he were still alive" <ref> [9] </ref>. In addition, McCarty has developed a wide class of hypothetical rules for the purpose of constructing computer-based legal consultation systems, especially systems for reasoning about contract law and corporate tax law [16, 18].
Reference: [10] <author> M.R. Garey and D.S. Johnson. </author> <title> Computers and Intractability: A Guide to the Theory of NP-Completeness. W.H. </title> <publisher> Freeman, </publisher> <address> New York, </address> <year> 1979. </year>
Reference-contexts: In this example, the data-complexity of the rulebase is N P -hard <ref> [10] </ref>. To find a Hamiltonian path, the rulebase looks for a sequence of edges that contains each node in the graph exactly once. The first rule selects a node x at which this sequence is to begin.
Reference: [11] <author> Ginsberg. </author> <title> Counterfactuals. </title> <journal> Artificial Intelligence, </journal> <volume> 30(1) </volume> <pages> 35-79, </pages> <year> 1986. </year>
Reference-contexts: In addition, McCarty has developed a wide class of hypothetical rules for the purpose of constructing computer-based legal consultation systems, especially systems for reasoning about contract law and corporate tax law [16, 18]. Although hypothetical reasoning is complex in general <ref> [11] </ref>, these systems focus on a form of hypothetical reasoning which appears tractable.
Reference: [12] <author> J.E. Hopcroft and J.D. Ullman. </author> <title> Introduction to Automata Theory, Languages and Computation. </title> <publisher> Addison-Wesley, </publisher> <year> 1979. </year>
Reference-contexts: In particular, rulebases with k strata are data-complete for P k . The polynomial-time hierarchy is a sequence of complexity classes between P and P SP ACE. It 2 is based on the idea of an oracle Turing-machine <ref> [12] </ref> and for our purposes, can be defined recursively as follows: * P * P k = Those languages accepted in non-deterministic polynomial time by an oracle machine whose oracle is a language in P k . k P This paper also addresses the issue of expressibility.
Reference: [13] <author> N. Immerman. </author> <title> Relational Queries Computable in Polynomial Time. </title> <booktitle> In Proceedings of the ACM Symposium on Theory of Computing (STOC), </booktitle> <pages> pages 147-152, </pages> <year> 1982. </year>
Reference-contexts: That is, any relational query whose graph is in P k can be represented as a hypothetical rulebase with at most k strata. The proof relies on a simulation of oracle Turing machines, and in this respect, is similar to other expressibility proofs in the literature <ref> [13, 22] </ref>. One difference, however, is that we do not require the data domain to be linearly ordered. Linearly-ordered domains are used to simulate counters, which in turn, are used to simulate tape-head movements. Our approach is to start with unordered domains and assert linear orders hypothetically. <p> This section shows the converse, that such rulebases can represent any typed, generic query whose graph is in P k . The proof relies on the encodings of oracle Turing-machines developed in the section 5.1. In this respect, it is similar to other expressibility proofs in the literature (e.g., <ref> [13, 22] </ref>). One difference, however, is that we do not assume that the data domain is linearly ordered. Ordered domains are used to simulate counters, which in turn, are used to simulate the movement of Turing-machine tape-heads. <p> For this reason, the assumption of a linearly-ordered domain is common in the literature <ref> [13, 22] </ref>), especially when expressibility results are established in terms of complexity classes, as in lemma 2. For hypothetical logics, however, this assumption is unnecessary, for if a linear order does not exist, then one can be asserted hypothetically. <p> Unlike other expressibility results in the literature, this result does not assume that the data domain is linearly ordered. Linearly ordered domains are typically used to simulate counters, which in turn, are used to simulate tape-head movements <ref> [13, 22] </ref>. The approach of this paper has been to start with unordered domains and to assert linear orders hypothetically. This technique works for all generic queries, that is, for all queries satisfying the consistency criterion of Chandra and Harel [6, 7].
Reference: [14] <author> R. Kowalski. </author> <title> Logic for Problem Solving. </title> <publisher> North-Holland, </publisher> <year> 1979. </year>
Reference-contexts: eng201): In the following examples, each query is described in three ways: (i) informally in English, (ii) formally at the meta-level, and (iii) formally at the object-level with operators of addition. 2 1 Although considered likely, it is an open question as to whether these containments are strict. 2 See <ref> [14] </ref> for a description of meta-level and object-level reasoning. 3 Example 1. <p> The greater part of an id, however, remains unchanged by such transitions. Indeed, except for those cells under the tape heads, the contents of the machine tapes remain unchanged. This is an instance of the frame axiom <ref> [14] </ref>, and we must write rules to encode it. Such rules are necessary only because we are representing time explicitly; i.e., the database represents a sequence of id's, and rules are needed to copy the unchanged portion of an id from one instant of time to the next.
Reference: [15] <author> Sanjay Manchanda. </author> <title> A Dynamic Logic Programming Language for Relational Updates. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, State University of New York at Stony Brook, Stony Brook, </institution> <address> New York, </address> <month> December </month> <year> 1987. </year> <note> Also published as Technical Report TR 88-2, </note> <institution> Department of Computer Science, The University of Arizona, Tuscon, Arizona 85721, </institution> <month> January, </month> <year> 1988. </year>
Reference-contexts: Miller, for instance, has shown how such rules can structure the runtime environment of a logic program [19], and Warren and Manchanda have proposed such logics for reasoning about database updates <ref> [23, 15] </ref>. The legal domain has inspired much work into this kind of hypothetical reasoning. Gabbay, for example, has reported a need to augment Prolog with hypothetical rules in order to encode the British Nationality Act.
Reference: [16] <author> L.T. McCarty. </author> <title> Clausal Intuitionistic Logic. I. Fixed-Point Semantics. </title> <journal> Journal of Logic Programming (JLP), </journal> <volume> 5(1) </volume> <pages> 1-31, </pages> <year> 1988. </year>
Reference-contexts: In addition, McCarty has developed a wide class of hypothetical rules for the purpose of constructing computer-based legal consultation systems, especially systems for reasoning about contract law and corporate tax law <ref> [16, 18] </ref>. Although hypothetical reasoning is complex in general [11], these systems focus on a form of hypothetical reasoning which appears tractable. <p> Gabbay has shown that they have an intuitionistic semantics [8], and Miller has developed fixpoint semantics for the predicate case [19]. McCarty has extended this work to a larger class of formulas and established interesting semantic results <ref> [16, 17] </ref>. Bonner has shown that query evaluation in such systems is data-complete for P SP ACE in the function-free predicate case (data-complete for EXP T IM E when hypothetical deletions are allowed) [4].
Reference: [17] <author> L.T. McCarty. </author> <title> Clausal Intuitionistic Logic. II. Tableau Proof Procedures. </title> <journal> Journal of Logic Programming (JLP), </journal> <volume> 5(2) </volume> <pages> 93-132, </pages> <year> 1988. </year> <month> 28 </month>
Reference-contexts: Gabbay has shown that they have an intuitionistic semantics [8], and Miller has developed fixpoint semantics for the predicate case [19]. McCarty has extended this work to a larger class of formulas and established interesting semantic results <ref> [16, 17] </ref>. Bonner has shown that query evaluation in such systems is data-complete for P SP ACE in the function-free predicate case (data-complete for EXP T IM E when hypothetical deletions are allowed) [4].
Reference: [18] <author> L.T. McCarty and N.S. Sridharan. </author> <title> The Representation of an Evolving System of Legal Con--cepts. II. Prototypes and Deformations. </title> <booktitle> In Proceedings of the Seventh IJCAI, </booktitle> <pages> pages 246-253, </pages> <year> 1981. </year>
Reference-contexts: In addition, McCarty has developed a wide class of hypothetical rules for the purpose of constructing computer-based legal consultation systems, especially systems for reasoning about contract law and corporate tax law <ref> [16, 18] </ref>. Although hypothetical reasoning is complex in general [11], these systems focus on a form of hypothetical reasoning which appears tractable.
Reference: [19] <author> D. Miller. </author> <title> A Logical Analysis of Modules in Logic Programming. </title> <booktitle> In Proceedings of the IEEE Symposium on Logic Programming, </booktitle> <pages> pages 106-114, </pages> <month> Sept </month> <year> 1986. </year>
Reference-contexts: Several researchers in the logic-programming community have pointed out the utility of such rules and have developed systems along these lines. Miller, for instance, has shown how such rules can structure the runtime environment of a logic program <ref> [19] </ref>, and Warren and Manchanda have proposed such logics for reasoning about database updates [23, 15]. The legal domain has inspired much work into this kind of hypothetical reasoning. Gabbay, for example, has reported a need to augment Prolog with hypothetical rules in order to encode the British Nationality Act. <p> Gabbay has shown that they have an intuitionistic semantics [8], and Miller has developed fixpoint semantics for the predicate case <ref> [19] </ref>. McCarty has extended this work to a larger class of formulas and established interesting semantic results [16, 17].
Reference: [20] <author> T. Przymusinski. </author> <title> On the Declarative Semantics of Deductive Databases and Logic Programs. </title> <editor> In Jack Minker, editor, </editor> <booktitle> Foundations of Deductive Databases and Logic Programming, chapter 5, </booktitle> <pages> pages 193-216. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1988. </year>
Reference-contexts: After the rules in im i have been applied, the resulting fixpoint is called the "perfect model" of i and DB <ref> [20] </ref>. The procedures below implement this idea. The first four procedures are exactly as they would be in the case of Horn rules. P ROV E i computes the "perfect model" by successively applying each stratum of i . It then determines whether is true in this model.
Reference: [21] <author> L.J. Stockmeyer. </author> <title> The Polynomial Time Hierarchy. </title> <journal> Theoretical Computer Science (TCS), </journal> <volume> 3(1) </volume> <pages> 1-22, </pages> <year> 1976. </year>
Reference-contexts: To capture this, we develop a new notion of stratification, in which linear recursion alternates with negation-as-failure. The complexity of a hypothetical rulebase then depends on its degree of stratification. As the number of strata increases, the data-complexity climbs the polynomial-time hierarchy <ref> [21] </ref>. In particular, rulebases with k strata are data-complete for P k . The polynomial-time hierarchy is a sequence of complexity classes between P and P SP ACE.
Reference: [22] <author> M. Vardi. </author> <title> The Complexity of Relational Query Languages. </title> <booktitle> In Proceedings of the ACM Symposium on Theory of Computing (STOC), </booktitle> <pages> pages 137-146, </pages> <year> 1982. </year>
Reference-contexts: That is, any relational query whose graph is in P k can be represented as a hypothetical rulebase with at most k strata. The proof relies on a simulation of oracle Turing machines, and in this respect, is similar to other expressibility proofs in the literature <ref> [13, 22] </ref>. One difference, however, is that we do not require the data domain to be linearly ordered. Linearly-ordered domains are used to simulate counters, which in turn, are used to simulate tape-head movements. Our approach is to start with unordered domains and assert linear orders hypothetically. <p> It is defined precisely in terms of the graph of a database query <ref> [22] </ref>. Definition 10 Suppose that is a relational database query. The graph of is the set of ordered pairs (x; DB) where x is an answer to the query when applied to database DB. The data complexity of a set of queries is the complexity of their graphs. <p> This section shows the converse, that such rulebases can represent any typed, generic query whose graph is in P k . The proof relies on the encodings of oracle Turing-machines developed in the section 5.1. In this respect, it is similar to other expressibility proofs in the literature (e.g., <ref> [13, 22] </ref>). One difference, however, is that we do not assume that the data domain is linearly ordered. Ordered domains are used to simulate counters, which in turn, are used to simulate the movement of Turing-machine tape-heads. <p> For this reason, the assumption of a linearly-ordered domain is common in the literature <ref> [13, 22] </ref>), especially when expressibility results are established in terms of complexity classes, as in lemma 2. For hypothetical logics, however, this assumption is unnecessary, for if a linear order does not exist, then one can be asserted hypothetically. <p> Unlike other expressibility results in the literature, this result does not assume that the data domain is linearly ordered. Linearly ordered domains are typically used to simulate counters, which in turn, are used to simulate tape-head movements <ref> [13, 22] </ref>. The approach of this paper has been to start with unordered domains and to assert linear orders hypothetically. This technique works for all generic queries, that is, for all queries satisfying the consistency criterion of Chandra and Harel [6, 7].
Reference: [23] <author> D.S. Warren. </author> <title> Database Updates in Pure Prolog. </title> <booktitle> In Proceedings of the International Conference on Fifth Generation Computer Systems, </booktitle> <pages> pages 244-253, </pages> <year> 1984. </year>
Reference-contexts: Miller, for instance, has shown how such rules can structure the runtime environment of a logic program [19], and Warren and Manchanda have proposed such logics for reasoning about database updates <ref> [23, 15] </ref>. The legal domain has inspired much work into this kind of hypothetical reasoning. Gabbay, for example, has reported a need to augment Prolog with hypothetical rules in order to encode the British Nationality Act.
References-found: 23

