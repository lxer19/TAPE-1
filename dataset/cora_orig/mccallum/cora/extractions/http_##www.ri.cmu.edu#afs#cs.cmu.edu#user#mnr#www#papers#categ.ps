URL: http://www.ri.cmu.edu/afs/cs.cmu.edu/user/mnr/www/papers/categ.ps
Refering-URL: http://www.ri.cmu.edu/afs/cs.cmu.edu/user/mnr/www/index.html
Root-URL: 
Title: A Comparison of Two Learning Algorithms for Text Categorization (Symposium on Document Analysis and IR,
Author: David D. Lewis Marc Ringuette 
Keyword: Function: Learning Domain: Natural Language Text  
Note: Foundation: Statistical  
Date: April, 1994  
Address: Chicago, IL 60637  Pittsburgh, PA 15213  
Affiliation: Ctr. for Info. and Lang. Studies University of Chicago  School of Computer Science Carnegie Mellon University  
Abstract: This paper examines the use of inductive learning to categorize natural language documents into predefined content categories. Categorization of text is of increasing importance in information retrieval and natural language processing systems. Previous research on automated text categorization has mixed machine learning and knowledge engineering methods, making it difficult to draw conclusions about the performance of particular methods. In this paper we present empirical results on the performance of a Bayesian classifier and a decision tree learning algorithm on two text categorization data sets. We find that both algorithms achieve reasonable performance and allow controlled tradeoffs between false positives and false negatives. The stepwise feature selection in the decision tree algorithm is particularly effective in dealing with the large feature sets common in text categorization. However, even this algorithm is aided by an initial prefiltering of features, confirming the results found by Almuallim and Dietterich on artificial data sets. We also demonstrate the impact of the time-varying nature of category definitions. 
Abstract-found: 1
Intro-found: 1
Reference: [AD91] <author> Almuallim, Hussein and Dietterich, Thomas G. </author> <title> Learning with many irrelevant features. </title> <booktitle> AAAI-91, </booktitle> <pages> pages 547-552, </pages> <year> 1991. </year>
Reference-contexts: This is in agreement with Almuallin and Dietterich's results suggesting that the decision tree learning algorithms ID3 and FRINGE are not effective at minimizing number of features used in the face of many irrelevant features 10 <ref> [AD91] </ref>. The success of our relatively simple pre-filtering strategy suggests that more research on feature selection would be profitable, even for relatively well-understood learning algorithms.
Reference: [BT91] <author> Balcom, Laura Blumer and Tong, Richard M. </author> <title> Advanced Decision Systems: Description of the CODEX system as used for MUC-3. </title> <booktitle> In Proceedings of the Third Message Understanding Evaluation and Conference, </booktitle> <address> Los Altos, CA: </address> <publisher> Morgan Kaufmann, </publisher> <month> May </month> <year> 1991. </year>
Reference-contexts: They also can be used to route texts to category-specific processing mechanisms [DeJ82, SS89, JR90], and even to generate fillers for some fields <ref> [BT91, DGCN91, DR91, Lew91a] </ref>. Text categorization systems attempt to reproduce human categorization judgments. One approach to building a text categorization system is to manually assign some set of documents to categories, and then use inductive learning to automatically assign categories to future documents based on, say, the words they contain.
Reference: [BFL + 88] <author> Biebricher, Peter, Fuhr, Norbert, Lustig, Gerhard, Schwantner, Michael, and Knorz, Gerhard. </author> <title> The automatic indexing system AIR/PHYS|from research to application. </title> <booktitle> In Eleventh International Conference on Research & Development in Information Retrieval, </booktitle> <pages> pages 333|342, </pages> <year> 1988. </year>
Reference-contexts: 1 Introduction Text categorization|the automated assigning of natural language texts to predefined categories based on their content|is a task of increasing importance. A primary application of text categorization systems is to assign subject categories to documents to support information retrieval, or to aid human indexers in assigning such categories <ref> [BFL + 88, HW90] </ref>. Text categorization components are also seeing increasing use in natural language processing systems for data extraction. <p> The second strategy is to use existing bodies of manually categorized text in constructing categorizers by inductive learning. A wide variety of learning approaches have been used, including Bayesian classification [Mar61], decision trees [CFAT91], factor analysis [BB63], fuzzy sets [COL83], linear regression <ref> [BFL + 88] </ref>, and memory-based approaches [CMSW91]. Learning-based systems have been found to be cheaper and faster to build, as well as more accurate in some applications [CMSW91]. Text categorization applications nevertheless provide many challenges for machine learning.
Reference: [BB63] <author> Borko, Harold and Bernick, Myrna. </author> <title> Automatic document classification. </title> <journal> Journal of the Association for Computing Machinery, </journal> <pages> pages 151-161, </pages> <year> 1963. </year>
Reference-contexts: The second strategy is to use existing bodies of manually categorized text in constructing categorizers by inductive learning. A wide variety of learning approaches have been used, including Bayesian classification [Mar61], decision trees [CFAT91], factor analysis <ref> [BB63] </ref>, fuzzy sets [COL83], linear regression [BFL + 88], and memory-based approaches [CMSW91]. Learning-based systems have been found to be cheaper and faster to build, as well as more accurate in some applications [CMSW91]. Text categorization applications nevertheless provide many challenges for machine learning.
Reference: [Bun90] <author> Buntine, Wray. </author> <title> A theory of learning classification rules. </title> <type> PhD thesis, </type> <institution> School of Computing Science, University of Technology, </institution> <address> Sydney, </address> <month> February </month> <year> 1990. </year>
Reference-contexts: If X% of the training documents are in category C j , we place the kX% of the test documents with the highest estimates of P (C j = 1jD) in that category. 3.2 DT-min10 Our second approach was a decision tree learning algorithm implemented using the IND package <ref> [Bun90, Bun91] </ref>. A decision tree was constructed for each category using the recursive partitioning algorithm with information gain splitting rule.
Reference: [Bun91] <author> Buntine, Wray. </author> <title> Introduction to IND and recursive partitioning. </title> <type> Technical Report. </type> <institution> RIACS/NASA Ames Research Center, </institution> <month> September </month> <year> 1991. </year>
Reference-contexts: If X% of the training documents are in category C j , we place the kX% of the test documents with the highest estimates of P (C j = 1jD) in that category. 3.2 DT-min10 Our second approach was a decision tree learning algorithm implemented using the IND package <ref> [Bun90, Bun91] </ref>. A decision tree was constructed for each category using the recursive partitioning algorithm with information gain splitting rule.
Reference: [COL83] <author> Cerny, Barbara A., Okseniuk, Anna, and Lawrence, J. Dennis. </author> <title> A fuzzy measure of agreement between machine and manual assignment of documents to subject categories. </title> <booktitle> In Proceedings of the 46th ASIS Annual Meeting, </booktitle> <pages> page 265, </pages> <year> 1983. </year>
Reference-contexts: The second strategy is to use existing bodies of manually categorized text in constructing categorizers by inductive learning. A wide variety of learning approaches have been used, including Bayesian classification [Mar61], decision trees [CFAT91], factor analysis [BB63], fuzzy sets <ref> [COL83] </ref>, linear regression [BFL + 88], and memory-based approaches [CMSW91]. Learning-based systems have been found to be cheaper and faster to build, as well as more accurate in some applications [CMSW91]. Text categorization applications nevertheless provide many challenges for machine learning.
Reference: [Cla85] <author> Clancey, William J. </author> <title> Heuristic classification. </title> <journal> Artificial Intelligence, </journal> <volume> 27 </volume> <pages> 289-350, </pages> <year> 1985. </year>
Reference-contexts: Other systems take advantage of multi-word phrases, positional or linguistic structure, or other information. There have been two main approaches to the construction of text categorization systems. First, a number of systems [VS87, Har88a, HW90] have embodied approaches similar to those used in expert systems for classification or diagnosis <ref> [Cla85] </ref>.
Reference: [Cle91] <author> Cleverdon, Cyril W. </author> <title> The significance of the Cranfield tests of index languages. </title> <booktitle> In Fourteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 3-12, </pages> <year> 1991. </year>
Reference: [CFAT91] <author> Crawford, Stuart L., Fung, Robert M., Appelbaum, Lee A., and Tong, Richard M. </author> <title> Classification trees for information retrieval. </title> <booktitle> In Eighth International Workshop on Machine Learning, </booktitle> <pages> pages 245-249, </pages> <year> 1991. </year>
Reference-contexts: The second strategy is to use existing bodies of manually categorized text in constructing categorizers by inductive learning. A wide variety of learning approaches have been used, including Bayesian classification [Mar61], decision trees <ref> [CFAT91] </ref>, factor analysis [BB63], fuzzy sets [COL83], linear regression [BFL + 88], and memory-based approaches [CMSW91]. Learning-based systems have been found to be cheaper and faster to build, as well as more accurate in some applications [CMSW91]. Text categorization applications nevertheless provide many challenges for machine learning.
Reference: [CMSW91] <author> Creecy, Robert H., Masand, Brij M., Smith, Stephen J., Waltz, David L. </author> <title> Trading MIPS and memory for knowledge engineering: automatic classification of census returns on a massively parallel supercomputer. </title> <type> Technical Report TMC-192, </type> <institution> Thinking Machines Corp., </institution> <address> Cambridge, MA, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: The second strategy is to use existing bodies of manually categorized text in constructing categorizers by inductive learning. A wide variety of learning approaches have been used, including Bayesian classification [Mar61], decision trees [CFAT91], factor analysis [BB63], fuzzy sets [COL83], linear regression [BFL + 88], and memory-based approaches <ref> [CMSW91] </ref>. Learning-based systems have been found to be cheaper and faster to build, as well as more accurate in some applications [CMSW91]. Text categorization applications nevertheless provide many challenges for machine learning. <p> wide variety of learning approaches have been used, including Bayesian classification [Mar61], decision trees [CFAT91], factor analysis [BB63], fuzzy sets [COL83], linear regression [BFL + 88], and memory-based approaches <ref> [CMSW91] </ref>. Learning-based systems have been found to be cheaper and faster to build, as well as more accurate in some applications [CMSW91]. Text categorization applications nevertheless provide many challenges for machine learning. Feature sets are huge|on the order of tens of thousands of features when words are used, or even more if multi-word phrases are allowed.
Reference: [DLW + 91] <author> Dahlgren, Kathleen, Lord, Carol, Wada, Hajime, McDowell, Joyce, and Stabler, Jr., Edward P. </author> <title> ITP Interpretext system: MUC-3 test results and 12 analysis. </title> <booktitle> In Proceedings of the Third Message Understanding Evaluation and Conference, </booktitle> <address> Los Altos, CA: </address> <publisher> Morgan Kaufmann, </publisher> <month> May </month> <year> 1991. </year>
Reference-contexts: Text categorization components are also seeing increasing use in natural language processing systems for data extraction. Categorization may be used to filter out documents or parts of documents that are unlikely to contain extractable data, without incurring the cost of more expensive natural language processing <ref> [DLW + 91, GSM91, Hob91] </ref>. They also can be used to route texts to category-specific processing mechanisms [DeJ82, SS89, JR90], and even to generate fillers for some fields [BT91, DGCN91, DR91, Lew91a]. Text categorization systems attempt to reproduce human categorization judgments.
Reference: [DeJ82] <author> DeJong, Gerald. </author> <title> An overview of the FRUMP system. </title> <editor> In Lehnert, Wendy G. and Ringle, Martin H., editors, </editor> <booktitle> Strategies for Natural Language Processing, </booktitle> <pages> pages 149-176. </pages> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hillsdale, New Jersey, </address> <year> 1982. </year>
Reference-contexts: Categorization may be used to filter out documents or parts of documents that are unlikely to contain extractable data, without incurring the cost of more expensive natural language processing [DLW + 91, GSM91, Hob91]. They also can be used to route texts to category-specific processing mechanisms <ref> [DeJ82, SS89, JR90] </ref>, and even to generate fillers for some fields [BT91, DGCN91, DR91, Lew91a]. Text categorization systems attempt to reproduce human categorization judgments.
Reference: [DGCN91] <author> Dolan, Charles P., Goldman, Seth R., Cuda, Thomas V., and Nakamura, Alan M. </author> <title> Hughes Trainable Text Skimmer: Description of the TTS system as used for MUC-3. </title> <booktitle> In Proceedings of the Third Message Understanding Evaluation and Conference, </booktitle> <address> Los Altos, CA: </address> <publisher> Morgan Kaufmann, </publisher> <month> May </month> <year> 1991. </year>
Reference-contexts: They also can be used to route texts to category-specific processing mechanisms [DeJ82, SS89, JR90], and even to generate fillers for some fields <ref> [BT91, DGCN91, DR91, Lew91a] </ref>. Text categorization systems attempt to reproduce human categorization judgments. One approach to building a text categorization system is to manually assign some set of documents to categories, and then use inductive learning to automatically assign categories to future documents based on, say, the words they contain.
Reference: [DR91] <author> Deogun, Jitender S. and Raghavan, Vijay V. </author> <title> Description of the UNL/USL system used for MUC-3. </title> <booktitle> In Proceedings of the Third Message Understanding Evaluation and Conference, </booktitle> <address> Los Altos, CA: </address> <publisher> Morgan Kaufmann, </publisher> <month> May </month> <year> 1991. </year>
Reference-contexts: They also can be used to route texts to category-specific processing mechanisms [DeJ82, SS89, JR90], and even to generate fillers for some fields <ref> [BT91, DGCN91, DR91, Lew91a] </ref>. Text categorization systems attempt to reproduce human categorization judgments. One approach to building a text categorization system is to manually assign some set of documents to categories, and then use inductive learning to automatically assign categories to future documents based on, say, the words they contain.
Reference: [DH73] <author> Duda, Richard O. and Hart, Peter E. </author> <title> Pattern Classification and Scene Analysis. </title> <publisher> Wiley-Interscience, </publisher> <address> New York, </address> <year> 1973. </year>
Reference-contexts: (5:414 fi stake + 0:826) Given accurate estimates of P (C j = 1jD), the optimal categorization strategy, under the assumption of equal costs for all errors, is to set a threshold p and assign to document D all C j for which P (C j = 1jD) &gt;= p <ref> [DH73] </ref>. This strategy is not necessarily optimal when there are errors in the probability estimates, due to limited samples or the violation of our independence assumptions. We have experimented with a number of alternative thresholding strategies, and found the best to be proportional assignment. <p> With more features performance starts to decline. A primary cause of this phenomenon, refered to as "the curse of dimensionality" <ref> [DH73] </ref>, is overfitting. As an increasing number of parameters are estimated from a fixed amount of data, we induce a model of the noise as well as the true relationships in the training set.
Reference: [Fis87] <author> Fisher, Douglas H. </author> <title> Knowledge acquisition via incremental conceptual clustering. </title> <journal> Machine Learning, </journal> <volume> 2 </volume> <pages> 139-172, </pages> <year> 1987. </year>
Reference-contexts: We plan to investigate making available to our standard learning algorithms features corresponding to time of publication, day, date of the week, month, and so on. More generally, we plan to investigate incremental learning algorithms that are designed to track concept drift <ref> [Fis87] </ref> and to see how the idea of cyclical changes in concept definition might be used. Raw performance is not the only characteristic of interest in a learning algorithm for text categorization. For applications it is likely that manual editing or tuning of induced concept descriptions will be desirable.
Reference: [FHL + 91] <author> Fuhr, Norbert, Hartmann, Stephan, Lustig, Gerhard, Schwantner, Michael, Tzeras, Konstadinos, and Knorz, Gerhard. </author> <title> AIR/X|a rule-based multistage indexing system for large subject fields. </title> <booktitle> In RIAO 91 Conference Proceedings: Intelligent Text and Image Handling, </booktitle> <pages> pages 606-623, </pages> <year> 1991. </year>
Reference-contexts: Indirect comparisons with other text categorization methods indicate that our performance is competitive with that of other approaches to text categorization. For instance, the operational AIR/X system uses both rule-based and statistical techniques to achieve a microaveraged breakeven point of approximately 0:65 in indexing a physics database <ref> [FHL + 91] </ref>. The CONSTRUE rule-based text categorization system achieves a microaveraged breakeven of around 0:90 on a different, and possibly easier, testset drawn from the Reuters data [HW90].
Reference: [GC90] <author> Gale, William A. and Church, Kenneth W. </author> <title> Poor estimates of context are worse than none. </title> <booktitle> In Speech and Natural Language Workshop, </booktitle> <pages> pages 283-287, </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann, </publisher> <month> June </month> <year> 1990. </year>
Reference-contexts: To a certain extent, this problem is inherent in the simplicity of the decision tree model, in which each estimated probability corresponds to a disjoint set 9 of training instances. However, more sophisticated treatment of estimation from small samples might help <ref> [GC90] </ref>. The second thing we notice is that performance seems to approach an asymptote on the Reuters data as the number of features increases. This suggests we have avoided overfitting in the range of feature set sizes tested.
Reference: [GSM91] <author> Grishman, Ralph, Sterling, John, and Macleod, Catherine. </author> <title> New York University description of the PROTEUS system as used for MUC-3. </title> <booktitle> In Proceedings of the Third Message Understanding Evaluation and Conference, </booktitle> <address> Los Altos, CA: </address> <publisher> Morgan Kaufmann, </publisher> <month> May </month> <year> 1991. </year>
Reference-contexts: Text categorization components are also seeing increasing use in natural language processing systems for data extraction. Categorization may be used to filter out documents or parts of documents that are unlikely to contain extractable data, without incurring the cost of more expensive natural language processing <ref> [DLW + 91, GSM91, Hob91] </ref>. They also can be used to route texts to category-specific processing mechanisms [DeJ82, SS89, JR90], and even to generate fillers for some fields [BT91, DGCN91, DR91, Lew91a]. Text categorization systems attempt to reproduce human categorization judgments.
Reference: [Har88a] <author> Hardt, S. L. </author> <title> On recognizing planned deception. </title> <booktitle> In AAAI-88 Workshop on Plan Recognition, </booktitle> <year> 1988. </year>
Reference-contexts: Other systems take advantage of multi-word phrases, positional or linguistic structure, or other information. There have been two main approaches to the construction of text categorization systems. First, a number of systems <ref> [VS87, Har88a, HW90] </ref> have embodied approaches similar to those used in expert systems for classification or diagnosis [Cla85].
Reference: [HW90] <author> Hayes, Philip J. and Weinstein, Steven P. CONSTRUE/TIS: </author> <title> a system for content-based indexing of a database of news stories. </title> <booktitle> In Second Annual Conference on Innovative Applications of Artificial Intelligence, </booktitle> <year> 1990. </year>
Reference-contexts: 1 Introduction Text categorization|the automated assigning of natural language texts to predefined categories based on their content|is a task of increasing importance. A primary application of text categorization systems is to assign subject categories to documents to support information retrieval, or to aid human indexers in assigning such categories <ref> [BFL + 88, HW90] </ref>. Text categorization components are also seeing increasing use in natural language processing systems for data extraction. <p> Other systems take advantage of multi-word phrases, positional or linguistic structure, or other information. There have been two main approaches to the construction of text categorization systems. First, a number of systems <ref> [VS87, Har88a, HW90] </ref> have embodied approaches similar to those used in expert systems for classification or diagnosis [Cla85]. <p> The CONSTRUE rule-based text categorization system achieves a microaveraged breakeven of around 0:90 on a different, and possibly easier, testset drawn from the Reuters data <ref> [HW90] </ref>. This level of performance, the result of a 9.5 person-year effort, is an admirable target for learning based systems to shoot for. Comparison with published results on MUC-3 are difficult, since we simplified the complex MUC-3 task.
Reference: [Hob91] <author> Hobbs, Jerry R. </author> <title> SRI International: Description of the TACITUS system as used for MUC-3. </title> <booktitle> In Proceedings of the Third Message Understanding Evaluation and Conference, </booktitle> <address> Los Altos, CA: </address> <publisher> Morgan Kaufmann, </publisher> <month> May </month> <year> 1991. </year>
Reference-contexts: Text categorization components are also seeing increasing use in natural language processing systems for data extraction. Categorization may be used to filter out documents or parts of documents that are unlikely to contain extractable data, without incurring the cost of more expensive natural language processing <ref> [DLW + 91, GSM91, Hob91] </ref>. They also can be used to route texts to category-specific processing mechanisms [DeJ82, SS89, JR90], and even to generate fillers for some fields [BT91, DGCN91, DR91, Lew91a]. Text categorization systems attempt to reproduce human categorization judgments.
Reference: [JR90] <author> Jacobs, Paul S. and Rau, Lisa F. SCISOR: </author> <title> Extracting information from on-line news. </title> <journal> Communications of the ACM, </journal> <volume> 33(11) </volume> <pages> 88-97, </pages> <month> November </month> <year> 1990. </year>
Reference-contexts: Categorization may be used to filter out documents or parts of documents that are unlikely to contain extractable data, without incurring the cost of more expensive natural language processing [DLW + 91, GSM91, Hob91]. They also can be used to route texts to category-specific processing mechanisms <ref> [DeJ82, SS89, JR90] </ref>, and even to generate fillers for some fields [BT91, DGCN91, DR91, Lew91a]. Text categorization systems attempt to reproduce human categorization judgments.
Reference: [Lew91a] <author> Lewis, David D. </author> <title> Data extraction as text categorization: An experiment with the MUC-3 corpus. </title> <booktitle> In Proceedings of the Third Message Understanding Evaluation and Conference, </booktitle> <address> Los Altos, CA: </address> <publisher> Morgan Kaufmann, </publisher> <month> May </month> <year> 1991. </year>
Reference-contexts: They also can be used to route texts to category-specific processing mechanisms [DeJ82, SS89, JR90], and even to generate fillers for some fields <ref> [BT91, DGCN91, DR91, Lew91a] </ref>. Text categorization systems attempt to reproduce human categorization judgments. One approach to building a text categorization system is to manually assign some set of documents to categories, and then use inductive learning to automatically assign categories to future documents based on, say, the words they contain. <p> We used the other 1,200 MUC-3 training documents (encoded by 16 different MUC-3 sites) as our categorization training documents. It is likely that category assignments on our training set are less consistent than assignments on our test set. Details of the Reuters [Lew92, Lew92b] and MUC-3 <ref> [Lew91a] </ref> datasets are available 6 in other publications. 4.2 Evaluation Measures The performance measures used were recall (number of categories correctly assigned divided by the total number of categories that should be assigned) and precision (number of categories correctly assigned divided by total number of categories assigned) [van79]. <p> Comparison with published results on MUC-3 are difficult, since we simplified the complex MUC-3 task. However, in earlier experiments using the official MUC-3 testset and scoring, PropBayes achieved performance toward but within the low end of official MUC-3 scores <ref> [Lew91a] </ref>. 6 Feature Set Size We experimented with varying the number of features chosen by information gain for each category to study the effect of feature set size on performance. 0 0.4 0.8 1 10 100 1000 Breakeven Feature set size Graph 2a: effect of feature set size, Reuters PropBayes b
Reference: [Lew91b] <author> Lewis, David D. </author> <title> Evaluating text categorization. </title> <booktitle> In Proceedings of Speech and Natural Language Workshop, </booktitle> <pages> pages 312-318, </pages> <month> February, </month> <year> 1991. </year>
Reference-contexts: For a set of k categories and d documents a total of n = kd categorization decisions are made. Given those kd decisions, several ways of computing average performance are available <ref> [Lew91b] </ref>. We used microaveraging, which considers all kd decisions as a single group and computes recall and precision for the group as whole. Both of our categorization algorithms include an adjustable parameter controlling the algorithm's willingness to assign categories to documents.
Reference: [Lew92] <author> Lewis, David D. </author> <title> Representation and learning in information retrieval. </title> <type> PhD thesis, </type> <institution> Computer Science Dept., Univ. of Massachusetts at Amherst, </institution> <month> Febru-ary </month> <year> 1992. </year> <type> Technical Report 91-93. </type>
Reference-contexts: Feature sets are huge|on the order of tens of thousands of features when words are used, or even more if multi-word phrases are allowed. Natural language features exhibit a number of properties, including synonymy, ambiguity, and skewed distributions, that interfere with forming classification functions <ref> [Lew92] </ref>. Proper categorization may depend on subtle distinctions in emphasis. A human indexer assigned the story in Figure 1 to the GOLD and SILVER categories, but not to the DLR or OIL categories, as these concepts were apparently not considered central. <p> This enabled us to explore variations in the size of the feature set given each algorithm, and was also a practical necessity given the size of the full feature sets (see Section 4.1). 3.1 PropBayes We describe PropBayes only briefly, since full details have been presented elsewhere <ref> [Lew92, Lew92b] </ref>. <p> We used the other 1,200 MUC-3 training documents (encoded by 16 different MUC-3 sites) as our categorization training documents. It is likely that category assignments on our training set are less consistent than assignments on our test set. Details of the Reuters <ref> [Lew92, Lew92b] </ref> and MUC-3 [Lew91a] datasets are available 6 in other publications. 4.2 Evaluation Measures The performance measures used were recall (number of categories correctly assigned divided by the total number of categories that should be assigned) and precision (number of categories correctly assigned divided by total number of categories assigned)
Reference: [Lew92b] <author> Lewis, David D. </author> <title> An evaluation of phrasal and clustered representations on a text categorization task. </title> <note> Submitted to ACM SIGIR-92. </note>
Reference-contexts: This enabled us to explore variations in the size of the feature set given each algorithm, and was also a practical necessity given the size of the full feature sets (see Section 4.1). 3.1 PropBayes We describe PropBayes only briefly, since full details have been presented elsewhere <ref> [Lew92, Lew92b] </ref>. <p> We used the other 1,200 MUC-3 training documents (encoded by 16 different MUC-3 sites) as our categorization training documents. It is likely that category assignments on our training set are less consistent than assignments on our test set. Details of the Reuters <ref> [Lew92, Lew92b] </ref> and MUC-3 [Lew91a] datasets are available 6 in other publications. 4.2 Evaluation Measures The performance measures used were recall (number of categories correctly assigned divided by the total number of categories that should be assigned) and precision (number of categories correctly assigned divided by total number of categories assigned)
Reference: [Mar61] <author> Maron, M. E. </author> <title> Automatic indexing: An experimental inquiry. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 8 </volume> <pages> 404-417, </pages> <year> 1961. </year>
Reference-contexts: The second strategy is to use existing bodies of manually categorized text in constructing categorizers by inductive learning. A wide variety of learning approaches have been used, including Bayesian classification <ref> [Mar61] </ref>, decision trees [CFAT91], factor analysis [BB63], fuzzy sets [COL83], linear regression [BFL + 88], and memory-based approaches [CMSW91]. Learning-based systems have been found to be cheaper and faster to build, as well as more accurate in some applications [CMSW91]. Text categorization applications nevertheless provide many challenges for machine learning.
Reference: [Qui86a] <author> Quinlan, J. R. </author> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1 </volume> <pages> 81-106, </pages> <year> 1986. </year>
Reference-contexts: Before either algorithm was used, a preliminary filtering of the features for each data set was done. All features were ranked for each category using the information gain measure <ref> [Qui86a] </ref> and the top features were given to each algorithm.
Reference: [Utg86] <author> Utgoff, Paul E. </author> <title> Shift of bias for inductive concept learning. </title> <editor> In Michalski, Ryszard S., Carbonell, Jaime G., and Mitchell, Tom M., editors, </editor> <booktitle> Machine Learning. An Artificial Intelligence Approach. </booktitle> <volume> Volume II, </volume> <pages> pages 107-148. </pages> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos, CA, </address> <year> 1986. </year> <editor> [van79] van Rijsbergen, C. J. </editor> <booktitle> Information Retrieval. </booktitle> <publisher> Butterworths, </publisher> <address> London, </address> <note> second edition, </note> <year> 1979. </year>
Reference-contexts: It also means that DT-min10 that can induce any discrete probability distribution over the feature space, and unlike PropBayes will converge to the optimal categorizer (for a given feature set) in the limit of an infinite well-distributed training set. If we consider the tendencies or bias <ref> [Utg86] </ref> of the algorithms instead of asymptotic behavior, we see that DT-min10 most succintly represents distributions where conditional probabilities are uniform except as specifiable by conjunctions of a small number of features.
Reference: [VS87] <author> Vleduts-Stokolov, Natasha. </author> <title> Concept recognition in an automatic text-processing system for the life sciences. </title> <journal> Journal of the American Society for Information Science, </journal> <volume> 38 </volume> <pages> 269-287, </pages> <year> 1987. </year>
Reference-contexts: Other systems take advantage of multi-word phrases, positional or linguistic structure, or other information. There have been two main approaches to the construction of text categorization systems. First, a number of systems <ref> [VS87, Har88a, HW90] </ref> have embodied approaches similar to those used in expert systems for classification or diagnosis [Cla85].
Reference: [SS89] <author> Sahin, Kenan and Sawyer, Keith. </author> <title> The Intelligent Banking System: natural language processing for financial communications. </title> <editor> In Schorr, Herbert and Rappaport, Alain, editors, </editor> <booktitle> Innovative Applications of Artificial Intelligence, </booktitle> <pages> pages 43-50. </pages> <publisher> AAAI Press, </publisher> <address> Menlo Park, CA, </address> <year> 1989. </year> <month> 14 </month>
Reference-contexts: Categorization may be used to filter out documents or parts of documents that are unlikely to contain extractable data, without incurring the cost of more expensive natural language processing [DLW + 91, GSM91, Hob91]. They also can be used to route texts to category-specific processing mechanisms <ref> [DeJ82, SS89, JR90] </ref>, and even to generate fillers for some fields [BT91, DGCN91, DR91, Lew91a]. Text categorization systems attempt to reproduce human categorization judgments.
References-found: 33

