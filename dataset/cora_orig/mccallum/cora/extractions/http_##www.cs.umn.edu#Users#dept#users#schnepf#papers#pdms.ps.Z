URL: http://www.cs.umn.edu/Users/dept/users/schnepf/papers/pdms.ps.Z
Refering-URL: http://www.cs.umn.edu/Users/dept/users/schnepf/papers/
Root-URL: http://www.cs.umn.edu
Email: schnepf@csbsju.edu, fylee,du,kang,laig@cs.umn.edu  
Title: Building A Framework for FLexible Interactive Presentations dia segment. The implementation is modular and allows
Author: James A. Schnepf Yen-Jen Lee, David H.C. Du, Lan Lai Liang-Wei Kang 
Note: Authors' e-mail addresses are:  Support provided by US WEST, Honeywell, IVI Publishing, Computing Devices International, and Network Systems; and also a gift from IBM This work was conducted while the author was an MS student in  
Address: Collegeville, Minnesota, USA  Minneapolis, Minnesota, USA  Hsinchu, Taiwan, ROC  
Affiliation: Computer Science Department College of St. Benedict/St. John's University  Distributed Multimedia Research Center Department of Computer Science University of Minnesota  Computer Communication Research Laboratories Industrial Technology Research Institute  Department of Computer Science, University of Min-nesota, Minneapolis, Minnesota, USA  
Abstract: As presentation technology advances, it is possible to incorporate a wider range of media including variable duration media such as simulations and animations. At the same time, users are able to take more control over presentations by controlling the rate and selection of media being played. To make full use of these advances, multimedia systems must support flexible presentations that incorporate many variations in the way they are played. As a result of content-based searches and other methods of selections such as a selection from an index of slides, viewers may skip to different parts of a presentation or start viewing a presentation in the middle. These presentations must remain semantically coherent in the face of these interactions. This paper presents the work we have done to design and implement a framework to support the inclusion of diverse media displayers into a presentation and to support user interaction. The implementation maintains a consistent and coherent presentation in the face of user interactions such as skipping forward and backward to different points within the presentation or modifying the speed of a single me fl This work was conducted while the author was a PhD candidate in Department of Computer Science, University of Min-nesota, Minneapolis, Minnesota, USA
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Schnepf, V. Mashayekhi, J. Riedl, and D. Du. </author> <title> Closing the gap in distance learning: Computer-supported, </title> <journal> participative, media-rich education. ED-TECH Review, </journal> <month> fall/winter </month> <year> 1994. </year>
Reference: [2] <author> J. Schnepf, J. Konstan, and D. Du. </author> <title> Doing FLIPS: FLexible Interactive Presentation Synchronization. </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <month> January </month> <year> 1996. </year>
Reference-contexts: Our implementation provides the ability to view and interact with a flexible presentation that can incorporate standard media displayers as well as many nonstandard displayers such as simulations and visualizations. Our framework supports an event-based model, FLexible Interactive Presentation Synchronization (FLIPS) <ref> [2] </ref>, that can handle the synchronization of variable duration objects and a wider range of specifications than the typical binary equality relation of many models. This model, together with the enforcement mechanism, provides a richer presentation environment that supports user interaction in a multimedia presentation. <p> The entire specification is in effect a network of media objects connected by enabler and barrier links to the begin and end events of the objects. A detailed description is beyond the scope of this paper and can be found in <ref> [2] </ref>. A possible specification for the architecture example is shown in Figure 1. Enablers are represented as A ! B and barriers are shown as A a B. 4 Systems Design The system design has a modular architecture built around a few simple data structures. <p> The presentation coordinator maintains the status of each object in the presentation. It maintains a valid global state in response to each event by propagating changes in the network of objects until a consistent state is reached (the algorithm is described in <ref> [2] </ref>). The presentation coordinator is event driven. When an event occurs, the presentation coordinator determines a valid global state and sends messages to the appropriate media displayers to achieve that state. <p> When a change occurs in one of the displayers or the user interface, the appropriate module sends a message (DONE or JUMP) to the coordinator notifying it of that change. When a message arrives, the coordinator navigates the presentation graph, updating each node according to the synchronization algorithm <ref> [2] </ref>. When a valid global state is achieved, it generates and sends STOP and START messages to the appropriate media displayers to achieve that state. This can be better understood by viewing an example. <p> The presentation specification generated through the authoring tool then uses that object name for the presentation interface. The Media Specific check box in the parameter window implements Alternative Actions defined in the FLIPS model <ref> [2] </ref>. The user can define the duration of display and the action taken after the display comes to an end but must wait for barriers to be removed. Common alter-native actions for a media object include holding the display until the barrier is satisfied or looping through the object again. <p> These abstractions are covered in more detail in <ref> [2] </ref>. The authoring tool maintains the consistency between objects and their relations with other objects. icons to create relationship between media objects.
Reference: [3] <author> L.A. Rowe and B.C. Smith. </author> <title> A continuous media player. </title> <booktitle> In Proceedings Third International Workshop on Network and Operating Systems Support for Digital Audio and Video, </booktitle> <pages> pages 237-249, </pages> <month> November </month> <year> 1992. </year>
Reference-contexts: Fine-grain synchronization (e.g. lip-synching) is not handled directly, but is integrated by incorporating composite objects representing fine grain synchronization along with an appropriate displayer such as the Berkeley CM Player <ref> [3] </ref>. The organization of the paper is as follows. Section 2 relates our design to other work. In section 3, we provide an example of a flexible presentation and the basic constructs used in the FLIPS model. <p> The same media objects could be used to define a different presentation by specifying different synchronizations. as is used in the CM Player <ref> [3] </ref>, where any shift in the presentation affects all the corresponding objects. In addition, each displayer could have its own user interface that allowed the viewer to control and interact with the individual object. The FLIPS model supports the specification of flexible presentations.
Reference: [4] <author> T.D.C. Little and A. Ghafoor. </author> <title> Spatial-temporal composition of distributed multimedia objects for value-added networks. </title> <booktitle> IEEE Computer, </booktitle> <month> October </month> <year> 1991. </year>
Reference: [5] <author> B. Prabhakaran and S.V. Raghavan. </author> <title> Synchronization models for presentation with user participation. </title> <booktitle> In Proceedings of ACM Multimedia 93, </booktitle> <pages> pages 157-165. </pages> <publisher> ACM, </publisher> <year> 1993. </year>
Reference: [6] <author> L. Hardman, G. vanRossum, and D. Bulterman. </author> <title> Structured multimedia authoring. </title> <booktitle> In Proceedings of ACM Multimedia 93, </booktitle> <pages> pages 283-289. </pages> <publisher> ACM, </publisher> <year> 1993. </year>
Reference: [7] <author> A. Poggio. CCWS: </author> <title> A computer-based multimedia information system. </title> <booktitle> IEEE Computer, </booktitle> <month> Oct </month> <year> 1985. </year>
Reference: [8] <author> L. Li, A. Karmouch, </author> <title> and N.D. Georganas. Multimedia teleorchestra with independent sources: Part 1 temporal modeling of collaborative multimedia scenarios. </title> <journal> ACM Multimedia Systems, </journal> <volume> 1(1) </volume> <pages> 143-153, </pages> <year> 1994. </year>
Reference: [9] <author> G. Blakowski et al. </author> <title> Tool support for the synchronization and presentation of distributed multimedia. </title> <journal> Computer Communications, </journal> <volume> 15(10) </volume> <pages> 611-618, </pages> <month> December </month> <year> 1992. </year>
Reference-contexts: Section 7 summarizes the results and describes the direction we are proceeding. 2 Comparison with Related Work Implementations for coarse grain synchronization have been built by several research groups including the MODE project <ref> [9] </ref>, Firefly [10], CMIFed [11], Maestro [12], Xavier [13], and Eventor [14]. [9, 11, 13, 14] all provide media displayers built into the presentation system. While this supports efficient implementations, it does not allow for quick and easy incorporation of new and varied media types. <p> Section 7 summarizes the results and describes the direction we are proceeding. 2 Comparison with Related Work Implementations for coarse grain synchronization have been built by several research groups including the MODE project [9], Firefly [10], CMIFed [11], Maestro [12], Xavier [13], and Eventor [14]. <ref> [9, 11, 13, 14] </ref> all provide media displayers built into the presentation system. While this supports efficient implementations, it does not allow for quick and easy incorporation of new and varied media types.
Reference: [10] <author> M. C. Buchanan and P. T. Zellweger. </author> <title> Scheduling multimedia documents using temporal constraints. </title> <booktitle> In Proceedings Third International Workshop on Network and Operating Systems Support for Digital Audio and Video, </booktitle> <pages> pages 237-249, </pages> <month> November </month> <year> 1992. </year>
Reference-contexts: Section 7 summarizes the results and describes the direction we are proceeding. 2 Comparison with Related Work Implementations for coarse grain synchronization have been built by several research groups including the MODE project [9], Firefly <ref> [10] </ref>, CMIFed [11], Maestro [12], Xavier [13], and Eventor [14]. [9, 11, 13, 14] all provide media displayers built into the presentation system. While this supports efficient implementations, it does not allow for quick and easy incorporation of new and varied media types.
Reference: [11] <author> G. van Rossum, J. Jansen, K. Mullender, and D. Bulterman. CMIFed: </author> <title> A presentation system for portable hypermedia documents. </title> <booktitle> In Proceedings of ACM Multimedia 93, </booktitle> <pages> pages 183-188. </pages> <publisher> ACM, </publisher> <year> 1993. </year>
Reference-contexts: Section 7 summarizes the results and describes the direction we are proceeding. 2 Comparison with Related Work Implementations for coarse grain synchronization have been built by several research groups including the MODE project [9], Firefly [10], CMIFed <ref> [11] </ref>, Maestro [12], Xavier [13], and Eventor [14]. [9, 11, 13, 14] all provide media displayers built into the presentation system. While this supports efficient implementations, it does not allow for quick and easy incorporation of new and varied media types. <p> Section 7 summarizes the results and describes the direction we are proceeding. 2 Comparison with Related Work Implementations for coarse grain synchronization have been built by several research groups including the MODE project [9], Firefly [10], CMIFed [11], Maestro [12], Xavier [13], and Eventor [14]. <ref> [9, 11, 13, 14] </ref> all provide media displayers built into the presentation system. While this supports efficient implementations, it does not allow for quick and easy incorporation of new and varied media types.
Reference: [12] <author> G. Drapeau. </author> <title> Synchronization in the maestro multimedia authoring environment. </title> <booktitle> In Proceedings of ACM Multimedia 93, </booktitle> <pages> pages 331-339. </pages> <publisher> ACM, </publisher> <year> 1993. </year>
Reference-contexts: Section 7 summarizes the results and describes the direction we are proceeding. 2 Comparison with Related Work Implementations for coarse grain synchronization have been built by several research groups including the MODE project [9], Firefly [10], CMIFed [11], Maestro <ref> [12] </ref>, Xavier [13], and Eventor [14]. [9, 11, 13, 14] all provide media displayers built into the presentation system. While this supports efficient implementations, it does not allow for quick and easy incorporation of new and varied media types. <p> While this supports efficient implementations, it does not allow for quick and easy incorporation of new and varied media types. As in the models discussed above, the support of user interaction and skips presume that all concurrent media are affected by a jump. Drapeau in <ref> [12] </ref> allows for varied media displayers to be incorporated, but these applications must be modified to work with the Maestro system. 3 Flexible Presentations and the FLIPS Model An example illustrates the flexibility that can be part of the playout of a presentation. 2 An architecture presentation describes the transition of
Reference: [13] <author> R. Hamakawa and J. Rekimoto. </author> <title> Object composition and playback models for handling multimedia data. </title> <journal> ACM Multimedia Systems, </journal> <volume> 2(1) </volume> <pages> 26-35, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: Section 7 summarizes the results and describes the direction we are proceeding. 2 Comparison with Related Work Implementations for coarse grain synchronization have been built by several research groups including the MODE project [9], Firefly [10], CMIFed [11], Maestro [12], Xavier <ref> [13] </ref>, and Eventor [14]. [9, 11, 13, 14] all provide media displayers built into the presentation system. While this supports efficient implementations, it does not allow for quick and easy incorporation of new and varied media types. <p> Section 7 summarizes the results and describes the direction we are proceeding. 2 Comparison with Related Work Implementations for coarse grain synchronization have been built by several research groups including the MODE project [9], Firefly [10], CMIFed [11], Maestro [12], Xavier [13], and Eventor [14]. <ref> [9, 11, 13, 14] </ref> all provide media displayers built into the presentation system. While this supports efficient implementations, it does not allow for quick and easy incorporation of new and varied media types.
Reference: [14] <author> S.Eun, E.S. No, H.C. Kim, H. Yoon, and S. R. Maeng. Eventor: </author> <title> an authoring system for interactive multimedia applications. </title> <journal> ACM Multimedia Systems, </journal> <volume> 2(3) </volume> <pages> 129-140, </pages> <month> September </month> <year> 1994. </year>
Reference-contexts: Section 7 summarizes the results and describes the direction we are proceeding. 2 Comparison with Related Work Implementations for coarse grain synchronization have been built by several research groups including the MODE project [9], Firefly [10], CMIFed [11], Maestro [12], Xavier [13], and Eventor <ref> [14] </ref>. [9, 11, 13, 14] all provide media displayers built into the presentation system. While this supports efficient implementations, it does not allow for quick and easy incorporation of new and varied media types. <p> Section 7 summarizes the results and describes the direction we are proceeding. 2 Comparison with Related Work Implementations for coarse grain synchronization have been built by several research groups including the MODE project [9], Firefly [10], CMIFed [11], Maestro [12], Xavier [13], and Eventor [14]. <ref> [9, 11, 13, 14] </ref> all provide media displayers built into the presentation system. While this supports efficient implementations, it does not allow for quick and easy incorporation of new and varied media types.
Reference: [15] <author> Little T.D.C. etal. </author> <title> A digital on-demand video service supporting content-based queries. </title> <booktitle> In Proceedings of ACM Multimedia 93, </booktitle> <pages> pages 427-436. </pages> <publisher> ACM, </publisher> <year> 1993. </year>
Reference-contexts: An area where the application has great potential is to integrate this presentation application with content-based search tools. Researchers have been developing schemes for content-based searches. Recent work on searches on video databases using metabases include the work of Little et al. <ref> [15] </ref> and Rowe et al. [16]. Rowe et al. have defined query interfaces that provide relational, hierarchical browsing, and keyword search operations to the metadata indices.
Reference: [16] <author> L.A. Rowe, J. S. Boreczky, and C. A. Eads. </author> <title> Indexes for user access to large video databases. In Proceedings of Storage and Retrieval for Image and Video Databases II, </title> <booktitle> IS&T/SPIE Symposium on Elec. </booktitle> <institution> Imaging Sci. & Tech., </institution> <month> February </month> <year> 1994. </year>
Reference-contexts: An area where the application has great potential is to integrate this presentation application with content-based search tools. Researchers have been developing schemes for content-based searches. Recent work on searches on video databases using metabases include the work of Little et al. [15] and Rowe et al. <ref> [16] </ref>. Rowe et al. have defined query interfaces that provide relational, hierarchical browsing, and keyword search operations to the metadata indices. But un-til now, there was not a reasonable way to jump into the middle of a presentation of multiple media streams based on these searches.
References-found: 16

