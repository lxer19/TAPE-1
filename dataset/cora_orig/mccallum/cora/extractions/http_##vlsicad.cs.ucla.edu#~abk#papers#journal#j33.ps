URL: http://vlsicad.cs.ucla.edu/~abk/papers/journal/j33.ps
Refering-URL: http://vlsicad.cs.ucla.edu/~abk/publications.html
Root-URL: http://www.cs.ucla.edu
Title: Spectral Partitioning: The More Eigenvectors, The Better  
Author: Charles J. Alpert, Andrew B. Kahng and So-Zen Yao 
Address: Los Angeles, CA 90095-1596  San Jose, CA 94135  
Affiliation: UCLA Computer Science Department,  Cadence Design Systems,  
Abstract: The graph partitioning problem is to divide the vertices of a graph into disjoint clusters to minimize the total cost of the edges cut by the clusters. A spectral partitioning heuristic uses the graph's eigenvectors to construct a geometric representation of the graph (e.g., linear orderings) which are subsequently partitioned. Our main result shows that when all the eigenvectors are used, graph partitioning reduces to a new vector partitioning problem. This result implies that as many eigenvectors as are practically possible should be used to construct a solution. This philosophy is in contrast to that of the widely-used spectral bipartitioning (SB) heuristic (which uses a single eigenvector to construct a 2-way partitioning) and several previous multi-way partitioning heuristics [7] [10] [16] [26] [37] (which use k eigenvectors to construct a k-way partitioning). Our result motivates a simple ordering heuristic that is a multiple-eigenvector extension of SB. This heuristic not only significantly outperforms SB, but can also yield excellent multi-way VLSI circuit partitionings as compared to [1] [10]. Our experiments suggest that the vector partitioning perspective opens the door to new and effective heuristics. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> C. J. Alpert and A. B. Kahng, </author> <title> Multi-way partitioning via spacefilling curves and dynamic programming, </title> <booktitle> in: Proceedings of the ACM/IEEE Design Automation Conference (1994) 652-657. </booktitle> <pages> 18 </pages>
Reference-contexts: Alpert and Kahng <ref> [1] </ref> extended this idea to higher dimensions, i.e., the i th entries of d eigenvectors yield the coordinates of v i in d-space. They used a spacefilling curve to induce a linear ordering of the embedded vertices, and then split the ordering into a multi-way partitioning via dynamic programming. <p> Instead of explicitly solving the vector partitioning problem, we construct a linear ordering of the vectors, which corresponds to a linear ordering of the graph vertices. Previous work <ref> [1] </ref> [25] [38] has shown the utility of ordering-based partitionings for VLSI applications. In addition, the idea of constructing an ordering and splitting it into a partitioning is at the heart of spectral bipartitioning (SB) [7] [36]. <p> infeasible. 12 5 Experimental Results In this section, we present four sets of experiments that we performed with MELO: * Comparisons of the weighting schemes proposed in the previous section, * Comparisons with different values of d, * Multi-way partitioning comparisons with recursive spectral bipartitioning (RSB), KP [10], and SFC <ref> [1] </ref> algorithms, * Balanced 2-way partitioning comparisons with SB [25] and PARABOLI [38]. Our experiments use the set of ACM/SIGDA benchmarks listed in Table 1 (available via the World Wide Web at http://ballade.cs.ucla.edu/~cheese). <p> To generate multi-way partitionings from MELO orderings, we apply the "DP-RP" algorithm of <ref> [1] </ref>. DP-RP accepts a vertex ordering and returns a restricted partitioning, i.e., a k-way partitioning such that each cluster is a contiguous subset of the ordering. <p> Table 4 reports results for our third set of experiments, which compare MELO to the multi-way parti tioning algorithms RSB (recursive spectral bipartitioning) [25], KP [10], and SFC <ref> [1] </ref>. <p> Note that for MELO, only experiments 16 all splits of the Fiedler vector, and the algorithm is iteratively applied to the largest remaining cluster. The SFC and DP-RP codes were acquired from their authors <ref> [1] </ref>; experiments for SFC were done using the partitioning-specific net model. The results for all four algorithms are given in Table 4. MELO averaged 10.6%, 15.8% and 13.2% improvement over RSB, KP, and SFC respectively.
Reference: [2] <author> C. J. Alpert and A. B. Kahng, </author> <title> Multi-way partitioning via geometric embeddings, orderings, and dynamic programming, </title> <journal> IEEE Trans. </journal> <note> on CAD 14 (1995) 1342-1358. </note>
Reference-contexts: It remains open as to which model is best for a given application. For VLSI netlist partitioning, Alpert and Kahng <ref> [2] </ref> empirically showed that the Frankle and partitioning-specific models are comparable, and that both are better suited than the standard model for multi-way partitioning. <p> Min-cut graph partitioning is known to be NP-complete, and many heuristic methods have been proposed (see [4] for a survey). Spectral methods are well-established [7] [16] [18] [27] [36] and have also been the subject of extensive study in recent years <ref> [2] </ref> [5] [6] [10] [19] [23] [25] [29] [37] [40]. These methods use eigenvectors of the Laplacian or adjacency matrix to construct various types of geometric representations of the graph. <p> They prove a strong approximation bound on the expected performance of their heuristic. * Vectors in d-space: Chan et al. [10] use the same embedded vertices as in <ref> [2] </ref> [27], but view each embedded vertex as a vector rather than as a point. Their KP algorithm constructs partitioning solutions using the directional cosine between two vectors as a similarity measure between vertices. <p> Table 5 also reports the runtimes required for MELO to construct and split orderings using two and ten eigenvectors, after the eigenvectors have been computed. Despite MELO's O (dn 2 ) complexity, the runtimes are quite reasonable because the algorithm is so simple (see <ref> [2] </ref> for detailed runtimes for eigenvector computations). The results from Table 5 do not immediately imply that MELO is a superior bipartitioner; rather, the results show that multiple-eigenvector based orderings can be used to yield high-quality balanced bipartitionings.
Reference: [3] <author> C. J. Alpert and A. B. Kahng, </author> <title> A general framework for vertex orderings, with applications to netlist clustering, </title> <booktitle> in: IEEE International Conference on Computer-Aided Design (1994) 63-67. </booktitle>
Reference-contexts: Label v i as vertex j in the ordering. The idea of iteratively constructing a cluster (i.e., subset of vectors) seems to be the most direct method for constructing a linear ordering. MELO may not seem much different from a graph traversal (cf. <ref> [3] </ref>), e.g., choose some vertex to be in its own cluster and iteratively add vertices to the cluster to minimize the cluster degree. However, with our approach each vector contains global partitioning information; the set of edges connected to any vertex in the original graph representation comprises strictly local information.
Reference: [4] <author> C. J. Alpert and A. B. Kahng, </author> <title> Recent developments in netlist partitioning: a survey, Integration: </title> <note> the VLSI Journal 19 (1995) 1-81. </note>
Reference-contexts: 1 Introduction Automatic circuit partitioning has become an essential tool for such important VLSI CAD applications such as top-down hierarchical cell placement, simulation and emulation <ref> [4] </ref>. Systems with several million transistors entail problem complexities that are unmanageable for existing logic- and physical-level design tools. Thus, partitioning is used to divide the system into smaller, more manageable components, with the traditional goal being to minimize the number of signals which pass between the components. <p> We write each edge e 2 E as a pair of vertices. Many hypergraph-to-graph transformations have been proposed (see <ref> [4] </ref> for a detailed survey) including (i) creating a dummy vertex v 0 for each hyperedge e 2 E H , and inserting edges (v; v 0 ) in E for each v 2 v 0 [30]; (ii) mapping each hyperedge to a vertex in G and constructing an edge 1 <p> Notice that f counts the cost of each cut edge twice. Min-cut graph partitioning is known to be NP-complete, and many heuristic methods have been proposed (see <ref> [4] </ref> for a survey). Spectral methods are well-established [7] [16] [18] [27] [36] and have also been the subject of extensive study in recent years [2] [5] [6] [10] [19] [23] [25] [29] [37] [40].
Reference: [5] <author> K. S. Arun and V. B. Rao, </author> <title> New heuristics and lower bounds for graph partitioning, </title> <booktitle> in: Proceedings of the IEEE International Symposium on Circuits and Systems (1991) 1172-1175. </booktitle>
Reference-contexts: Min-cut graph partitioning is known to be NP-complete, and many heuristic methods have been proposed (see [4] for a survey). Spectral methods are well-established [7] [16] [18] [27] [36] and have also been the subject of extensive study in recent years [2] <ref> [5] </ref> [6] [10] [19] [23] [25] [29] [37] [40]. These methods use eigenvectors of the Laplacian or adjacency matrix to construct various types of geometric representations of the graph. <p> Hendrickson and Leland [29] have also used this embedding; they use d eigenvectors to construct a partitioning with 2 d clusters. Arun and Rao <ref> [5] </ref> propose a bipartitioning heuristic that constructs a 2-dimensional embedding, then partitions to minimize the distance between the centroids of the two clusters. * Probe vectors: Frankle and Karp [19] proposed an algorithm that searches for a good solution by defining probe vectors in the d-space spanned by the d best <p> Corollary 5 Min-cut graph partitioning reduces to min-sum vector partitioning, hence min-sum vector partitioning is NP-hard. It is not hard to show that min-sum vector partitioning is actually NP-complete, although optimum bipartitioning solutions have been found with time complexity polynomial in d [19] <ref> [5] </ref>. Corollary 6 jj~y n i jj 2 = deg (v i ). This result directly follows from jj ~ Y n h jj 2 = E h Corollary 6 helps in understanding why the graph parti tioning and vector partitioning formulations are equivalent.
Reference: [6] <author> S. T. Barnard and H. D. Simon, </author> <title> A fast multilevel implementation of recursive spectral bisection for partitioning unstructured problems, </title> <journal> Concurrency: </journal> <note> Practice and Experience 6 (1994) 101-117. </note>
Reference-contexts: Min-cut graph partitioning is known to be NP-complete, and many heuristic methods have been proposed (see [4] for a survey). Spectral methods are well-established [7] [16] [18] [27] [36] and have also been the subject of extensive study in recent years [2] [5] <ref> [6] </ref> [10] [19] [23] [25] [29] [37] [40]. These methods use eigenvectors of the Laplacian or adjacency matrix to construct various types of geometric representations of the graph. <p> SB takes the linear ordering induced by the second eigenvector of the Laplacian (also called the Fiedler vector) and splits it to yield a 2-way partitioning. Subsequent works have proposed variations of this algorithm <ref> [6] </ref> [36] [25] and [23] [40] analyzed its performance. * Multiple linear orderings: Barnes [7] proposed a multiple-eigenvector extension to spectral bi-partitioning. Barnes tries to map each cluster in a k-way partitioning to one of k eigenvectors while minimizing the rounding error according to a transportation formulation.
Reference: [7] <author> E. R. Barnes, </author> <title> An algorithm for partitioning the nodes of a graph, </title> <note> Siam J. Alg. Disc. Methods 3 (1982) 541-549. </note>
Reference-contexts: Notice that f counts the cost of each cut edge twice. Min-cut graph partitioning is known to be NP-complete, and many heuristic methods have been proposed (see [4] for a survey). Spectral methods are well-established <ref> [7] </ref> [16] [18] [27] [36] and have also been the subject of extensive study in recent years [2] [5] [6] [10] [19] [23] [25] [29] [37] [40]. These methods use eigenvectors of the Laplacian or adjacency matrix to construct various types of geometric representations of the graph. <p> SB takes the linear ordering induced by the second eigenvector of the Laplacian (also called the Fiedler vector) and splits it to yield a 2-way partitioning. Subsequent works have proposed variations of this algorithm [6] [36] [25] and [23] [40] analyzed its performance. * Multiple linear orderings: Barnes <ref> [7] </ref> proposed a multiple-eigenvector extension to spectral bi-partitioning. Barnes tries to map each cluster in a k-way partitioning to one of k eigenvectors while minimizing the rounding error according to a transportation formulation. <p> The magnitude of the projection of ~ X h onto ~ j is given by ff jh . 1 The first two properties also hold for the eigenvectors of the adjacency matrix A. Some early spectral partitioning works used the spectra of A (e.g., <ref> [7] </ref> [16]); however, the last two properties of the Laplacian make Q more convenient and hence preferable. All the results of this work can be equivalently established with A instead of Q (except Corollary 4 which follows from the third property). <p> Previous work [1] [25] [38] has shown the utility of ordering-based partitionings for VLSI applications. In addition, the idea of constructing an ordering and splitting it into a partitioning is at the heart of spectral bipartitioning (SB) <ref> [7] </ref> [36]. Our construction seeks to combine d distinct eigenvectors (where d is as large as practically possible) into a single vertex ordering that utilizes all of the eigenvector information.
Reference: [8] <author> E. R. Barnes, A. Vannelli, and J. Q. Walker, </author> <title> An new heuristic for partitioning the nodes of a graph, </title> <note> Siam J. Dicrete Mathematics 3 (1988) 299-305. </note>
Reference-contexts: Cullum et al. [12] showed how to find a diagonal matrix D that minimizes the sum of the first d eigenvalues of A + D. Another possibility is to use the algorithm of Carter [9] to construct D such that trace (D) is minimized. Many researchers, e.g., <ref> [8] </ref> [16] [37] [17], have applied various types of diagonal optimization both to improve the quality of lower bounds on the cost of a solution and to enhance the performance of their spectral partitioning heuristics.
Reference: [9] <author> M. Carter, </author> <title> The indefinite zero-one quadratic problem, </title> <note> Discrete Applied Mathematics 7 (1984) 23-44. </note>
Reference-contexts: Cullum et al. [12] showed how to find a diagonal matrix D that minimizes the sum of the first d eigenvalues of A + D. Another possibility is to use the algorithm of Carter <ref> [9] </ref> to construct D such that trace (D) is minimized. Many researchers, e.g., [8] [16] [37] [17], have applied various types of diagonal optimization both to improve the quality of lower bounds on the cost of a solution and to enhance the performance of their spectral partitioning heuristics.
Reference: [10] <author> P. K. Chan, M. D. F. Schlag and J. Zien, </author> <title> Spectral k-way ratio cut partitioning and clustering, </title> <journal> IEEE Trans. </journal> <note> on CAD (1994) 1088-1096. </note>
Reference-contexts: This model has been utilized in the partitioning heuristic of <ref> [10] </ref>. * Costs of 2 jej [28], ( 2 jej 2 jej [15] have also been proposed for the clique edges. It remains open as to which model is best for a given application. <p> Min-cut graph partitioning is known to be NP-complete, and many heuristic methods have been proposed (see [4] for a survey). Spectral methods are well-established [7] [16] [18] [27] [36] and have also been the subject of extensive study in recent years [2] [5] [6] <ref> [10] </ref> [19] [23] [25] [29] [37] [40]. These methods use eigenvectors of the Laplacian or adjacency matrix to construct various types of geometric representations of the graph. <p> They prove a strong approximation bound on the expected performance of their heuristic. * Vectors in d-space: Chan et al. <ref> [10] </ref> use the same embedded vertices as in [2] [27], but view each embedded vertex as a vector rather than as a point. Their KP algorithm constructs partitioning solutions using the directional cosine between two vectors as a similarity measure between vertices. <p> In our work, we propose a new geometric representation that is based on a reduction from the graph partitioning problem to a vector partitioning problem. This representation is similar to that used by Chan et al. <ref> [10] </ref>, but the coordinates are scaled by a function of the eigenvalue. The resulting vectors comprise a vector partitioning instance; the bijection between graph vertices and vectors permits us to develop a correspondence between graph and vector partitioning solutions. <p> The objective can be either to minimize or maximize the sum of the squared magnitudes of the subset vectors. Unlike the directional cosines-based approach of <ref> [10] </ref>, our objective captures both vector magnitude and direction. We show that when all n eigenvectors are used, graph partitioning reduces to vector partitioning. * This result motivates the use of as many eigenvectors as are practically possible. <p> Our experimental results show that the information contained in additional eigenvectors of the graph's Laplacian yields significant improvements over both SB and its recursive implementation. * We show that our heuristic also outperforms the multi-way partitioning heuristic of Chan et al. <ref> [10] </ref> which uses k eigenvectors to construct a k-way partitioning. Hence, we provide theoretical and empirical evidence that as many eigenvectors as practically possible should be used. Our experimental results suggest that more sophisticated vector partitioning heuristics hold much promise for graph and circuit partitioning applications. <p> Each row of X has sum one, and column h has sum jC h j. A well-known result is that the min-cut objective f can be directly expressed in terms of the Laplacian and assignment matrices (see e.g., <ref> [10] </ref> [37]). Theorem 1 f (P k ) = trace (X T QX). The trace of a matrix is the sum of its diagonal entries, e.g., trace (A) = P n i=1 a ii . <p> When the weight of vertex v i is extended to be the weight of ~y d i , the vector partitioning constraints are simply L h w (S h ) W h , for 1 h k. 9 Minimum Scaled Cost: Chan et al. <ref> [10] </ref> proposed to minimize the Scaled Cost objective f (P k ) = 1 P k E h jC h j with no cluster size constraints; this objective reduces to the ratio cut objective f (P 2 ) = E 1 jC 1 jjC 2 j for k = 2. <p> make possible speedups infeasible. 12 5 Experimental Results In this section, we present four sets of experiments that we performed with MELO: * Comparisons of the weighting schemes proposed in the previous section, * Comparisons with different values of d, * Multi-way partitioning comparisons with recursive spectral bipartitioning (RSB), KP <ref> [10] </ref>, and SFC [1] algorithms, * Balanced 2-way partitioning comparisons with SB [25] and PARABOLI [38]. Our experiments use the set of ACM/SIGDA benchmarks listed in Table 1 (available via the World Wide Web at http://ballade.cs.ucla.edu/~cheese). <p> Our experiments use the set of ACM/SIGDA benchmarks listed in Table 1 (available via the World Wide Web at http://ballade.cs.ucla.edu/~cheese). The eigenvector computations were performed using LASO2 code [39], with a driver provided by the authors of <ref> [10] </ref>. Before the eigenvectors were computed, each netlist was transformed into a graph using the partitioning-specific clique model. We also discuss use of the standard and Frankle clique models. <p> Table 4 reports results for our third set of experiments, which compare MELO to the multi-way parti tioning algorithms RSB (recursive spectral bipartitioning) [25], KP <ref> [10] </ref>, and SFC [1]. <p> Pak Chan; however, the results reported in Table 4 are considerably better than the values reported in <ref> [10] </ref>. 3 RSB constructs ratio cut bipartitionings by choosing the best of 3 For the experiments performed in [10], nets with more than 99 pins were removed before the eigenvectors were computed using the Frankle clique model. <p> Pak Chan; however, the results reported in Table 4 are considerably better than the values reported in <ref> [10] </ref>. 3 RSB constructs ratio cut bipartitionings by choosing the best of 3 For the experiments performed in [10], nets with more than 99 pins were removed before the eigenvectors were computed using the Frankle clique model. For some of the circuit netlists (test03, test04, and test06), removing large nets disconnected the graph, forcing 2 = 0. <p> In addition, results for KP also suffered. Hence, we ran both RSB and KP using the Frankle and partitioning-specific net models for the seven benchmarks used in <ref> [10] </ref> (prim1-2, test02-6). We observed that: (i) for RSB, the partitioning-specific net model averaged 0.19% and 11.1% respective improvement over the Frankle net model and the results from [10]; (ii) for KP, the Frankle model averaged 2.97% and 2.96% respective improvement over the partitioning-specific model and the results from [10]. <p> Hence, we ran both RSB and KP using the Frankle and partitioning-specific net models for the seven benchmarks used in <ref> [10] </ref> (prim1-2, test02-6). We observed that: (i) for RSB, the partitioning-specific net model averaged 0.19% and 11.1% respective improvement over the Frankle net model and the results from [10]; (ii) for KP, the Frankle model averaged 2.97% and 2.96% respective improvement over the partitioning-specific model and the results from [10]. Hence, in Table 4 results are given for the partitioning-specific model for RSB and the Frankle model for KP. <p> in <ref> [10] </ref> (prim1-2, test02-6). We observed that: (i) for RSB, the partitioning-specific net model averaged 0.19% and 11.1% respective improvement over the Frankle net model and the results from [10]; (ii) for KP, the Frankle model averaged 2.97% and 2.96% respective improvement over the partitioning-specific model and the results from [10]. Hence, in Table 4 results are given for the partitioning-specific model for RSB and the Frankle model for KP. Note that for MELO, only experiments 16 all splits of the Fiedler vector, and the algorithm is iteratively applied to the largest remaining cluster.
Reference: [11] <author> H. R. Charney and D. L. Plato, </author> <title> Efficient partitioning of components, </title> <booktitle> in: Proceedings of the Fifth Design Automation Workshop (1968) 16-0 - 16-21. </booktitle>
Reference-contexts: Hence, many different cost functions have been proposed for the clique model: * The "standard" clique model [32] assigns cost 1 jej1 to each clique edge; it is motivated by the linear placement into fixed locations at unit separation <ref> [11] </ref>. * The "partitioning-specific" model assigns cost 4 jej (jej1) 2 jej 2 2 jej to each clique edge so that the expected cost of each cut hyperedge is one. * The "Frankle" model [19] proposed assigning cost ( 2 jej ) 3=2 to each clique edge to address linear place
Reference: [12] <author> J. Cullum, W. E. Donath and P. Wolfe, </author> <title> The minimization of certain nondifferentiable sums of eigenval-ues of symmetric matrices, Mathematical Programming Study 3 (North-Holland, </title> <address> Amsterdam, </address> <year> 1975) </year> <month> 35-55. </month>
Reference-contexts: Thus, it should be possible to identify such subsets of vectors and thereby construct high-quality clusterings. * Perform diagonal optimization. Cullum et al. <ref> [12] </ref> showed how to find a diagonal matrix D that minimizes the sum of the first d eigenvalues of A + D. Another possibility is to use the algorithm of Carter [9] to construct D such that trace (D) is minimized.
Reference: [13] <author> C. Delorme and S. Poljak, </author> <title> The performance of an eigenvalue bound on the max-cut problem in some classes of graphs, </title> <note> Discrete Mathematics 111 (1991) 145-156. </note>
Reference-contexts: The corresponding partitioning objective is to maximize g (S k ) = min 1hk jjY n h jj 2 . Max Cut: Another problem which has received much attention in the recent literature is the max-cut problem <ref> [13] </ref> [14] [35]: Maximize: f (P k ) = k X jE (C h )j: The same mapping of ~y n i to row i of 2 U that was used to reduce min-cut graph partitioning to min-sum vector partitioning can be used to reduce the max-cut problem to max-sum vector
Reference: [14] <author> C. Delorme and S. Poljak, </author> <title> Laplacian eigenvalues and the maximum cut problem, </title> <note> Mathematical Programming 62 (1993) 557-574. </note>
Reference-contexts: The corresponding partitioning objective is to maximize g (S k ) = min 1hk jjY n h jj 2 . Max Cut: Another problem which has received much attention in the recent literature is the max-cut problem [13] <ref> [14] </ref> [35]: Maximize: f (P k ) = k X jE (C h )j: The same mapping of ~y n i to row i of 2 U that was used to reduce min-cut graph partitioning to min-sum vector partitioning can be used to reduce the max-cut problem to max-sum vector partitioning.
Reference: [15] <author> W. E. Donath, </author> <title> Logic partitioning, </title> <booktitle> in: Physical Design Automation of VLSI Systems (Ben-jamin/Cummings 1988) 65-86. </booktitle>
Reference-contexts: This model has been utilized in the partitioning heuristic of [10]. * Costs of 2 jej [28], ( 2 jej 2 jej <ref> [15] </ref> have also been proposed for the clique edges. It remains open as to which model is best for a given application.
Reference: [16] <author> W. E. Donath and A. J. Hoffman, </author> <title> Lower bounds for the partitioning of graphs, </title> <journal> IBM Journal of Research and Development 17 (1973) 420-425. </journal>
Reference-contexts: Notice that f counts the cost of each cut edge twice. Min-cut graph partitioning is known to be NP-complete, and many heuristic methods have been proposed (see [4] for a survey). Spectral methods are well-established [7] <ref> [16] </ref> [18] [27] [36] and have also been the subject of extensive study in recent years [2] [5] [6] [10] [19] [23] [25] [29] [37] [40]. These methods use eigenvectors of the Laplacian or adjacency matrix to construct various types of geometric representations of the graph. <p> Barnes tries to map each cluster in a k-way partitioning to one of k eigenvectors while minimizing the rounding error according to a transportation formulation. If there is zero rounding error, the optimum cut value equal to a weighted sum of the largest k eigenvalues (of the adjacency matrix) <ref> [16] </ref> is obtained. <p> The magnitude of the projection of ~ X h onto ~ j is given by ff jh . 1 The first two properties also hold for the eigenvectors of the adjacency matrix A. Some early spectral partitioning works used the spectra of A (e.g., [7] <ref> [16] </ref>); however, the last two properties of the Laplacian make Q more convenient and hence preferable. All the results of this work can be equivalently established with A instead of Q (except Corollary 4 which follows from the third property). <p> Cullum et al. [12] showed how to find a diagonal matrix D that minimizes the sum of the first d eigenvalues of A + D. Another possibility is to use the algorithm of Carter [9] to construct D such that trace (D) is minimized. Many researchers, e.g., [8] <ref> [16] </ref> [37] [17], have applied various types of diagonal optimization both to improve the quality of lower bounds on the cost of a solution and to enhance the performance of their spectral partitioning heuristics.
Reference: [17] <author> J. Falkner, F. Rendl, and H. Wolkowicz, </author> <title> A computational study of graph partitioning, </title> <note> Mathematical Programming 66 (1994) 211-239. 19 </note>
Reference-contexts: Another possibility is to use the algorithm of Carter [9] to construct D such that trace (D) is minimized. Many researchers, e.g., [8] [16] [37] <ref> [17] </ref>, have applied various types of diagonal optimization both to improve the quality of lower bounds on the cost of a solution and to enhance the performance of their spectral partitioning heuristics.
Reference: [18] <author> M. Fiedler, </author> <title> Algebraic connectivity of graphs, </title> <note> Czechoslovak Mathematical Journal 23 (1973) 298-305. </note>
Reference-contexts: Notice that f counts the cost of each cut edge twice. Min-cut graph partitioning is known to be NP-complete, and many heuristic methods have been proposed (see [4] for a survey). Spectral methods are well-established [7] [16] <ref> [18] </ref> [27] [36] and have also been the subject of extensive study in recent years [2] [5] [6] [10] [19] [23] [25] [29] [37] [40]. These methods use eigenvectors of the Laplacian or adjacency matrix to construct various types of geometric representations of the graph. <p> These methods use eigenvectors of the Laplacian or adjacency matrix to construct various types of geometric representations of the graph. We loosely categorize previous methods according to five basic representations: * Linear orderings (spectral bipartitioning): The classic works of Hall [27] and Fiedler <ref> [18] </ref> gave theoretical motivation to the spectral bipartitioning (SB) heuristic, which is widely used in both the VLSI and scientific computing communities. SB takes the linear ordering induced by the second eigenvector of the Laplacian (also called the Fiedler vector) and splits it to yield a 2-way partitioning.
Reference: [19] <author> J. Frankle and R. M. Karp, </author> <title> Circuit placements and cost bounds by eigenvector decomposition, </title> <booktitle> in: Proceedings of the IEEE International Conference on Computer-Aided Design (1986) 414-417. </booktitle>
Reference-contexts: each clique edge; it is motivated by the linear placement into fixed locations at unit separation [11]. * The "partitioning-specific" model assigns cost 4 jej (jej1) 2 jej 2 2 jej to each clique edge so that the expected cost of each cut hyperedge is one. * The "Frankle" model <ref> [19] </ref> proposed assigning cost ( 2 jej ) 3=2 to each clique edge to address linear place ment with a quadratic optimization objective. <p> Min-cut graph partitioning is known to be NP-complete, and many heuristic methods have been proposed (see [4] for a survey). Spectral methods are well-established [7] [16] [18] [27] [36] and have also been the subject of extensive study in recent years [2] [5] [6] [10] <ref> [19] </ref> [23] [25] [29] [37] [40]. These methods use eigenvectors of the Laplacian or adjacency matrix to construct various types of geometric representations of the graph. <p> Arun and Rao [5] propose a bipartitioning heuristic that constructs a 2-dimensional embedding, then partitions to minimize the distance between the centroids of the two clusters. * Probe vectors: Frankle and Karp <ref> [19] </ref> proposed an algorithm that searches for a good solution by defining probe vectors in the d-space spanned by the d best eigenvectors of Q. For each probe, they find the binary vector that maximally projects onto the probe in O (n log n) time. <p> This corollary is a multi-way extension of the bipartitioning result <ref> [19] </ref>: E 1 = ~ X T 1 Q ~ X 1 = j=1 ff 2 Using indicator vectors to represent partitioning solutions allows us to express the cost of a solution in terms of the projections of indicator vectors onto eigenvectors. <p> Corollary 5 Min-cut graph partitioning reduces to min-sum vector partitioning, hence min-sum vector partitioning is NP-hard. It is not hard to show that min-sum vector partitioning is actually NP-complete, although optimum bipartitioning solutions have been found with time complexity polynomial in d <ref> [19] </ref> [5]. Corollary 6 jj~y n i jj 2 = deg (v i ). This result directly follows from jj ~ Y n h jj 2 = E h Corollary 6 helps in understanding why the graph parti tioning and vector partitioning formulations are equivalent. <p> To establish a reduction between min-cut graph partitioning and max-sum vector partitioning, we reformulate the min-cut objective as the maximization objective nH f (P k ) (following <ref> [19] </ref>), where H is some constant greater than or equal to n (for now, the choice of H is inconsequential). <p> To minimize the error of this approximation, we require that the sum of the "contributions" of the unused nd eigenvectors is zero, i.e., P n j1 (H j ) = 0. This occurs when <ref> [19] </ref> H = P d j1 j P d j1 Thus, after Step 6 in Figure 2, H is recomputed using C 1 as the set of vertices corresponding to vectors in S, and the coordinates of the vectors in Y and S are then readjusted.
Reference: [20] <author> A. Frieze and M. Jerrum, </author> <title> Improved approximation algorithms for max k-cut and max bisection, </title> <booktitle> in: Proceedings of the 4th International IPCO Conference 920 (1995) 1-13. </booktitle>
Reference-contexts: Their KP algorithm constructs partitioning solutions using the directional cosine between two vectors as a similarity measure between vertices. Each cluster is constructed to minimize the directional cosine between vectors of the cluster and the "cluster center prototype" vector for that cluster. For the Max-Cut problem, Frieze and Jerrum <ref> [20] </ref> apply a simpler version of KP to vectors obtained from solving a relaxation of the Max-Cut objective. In our work, we propose a new geometric representation that is based on a reduction from the graph partitioning problem to a vector partitioning problem.
Reference: [21] <author> J. Garbers, H. J. Promel and A. Steger, </author> <title> Finding clusters in VLSI circuits, </title> <booktitle> in: Proceedings of the IEEE International Conference on Computer-Aided Design (1990) 520-523. </booktitle>
Reference-contexts: Graph partitioning has no analogous natural similarity measure between vertices (cf. the many ad hoc means in the literature, such as all-pairs shortest paths, k l connectivity <ref> [21] </ref>, degree=separation [24], etc.).
Reference: [22] <author> M. X. Goemans and D. P. Williamson, </author> <title> Improved approximation algorithms for maximum cut and satisfiability problems using semidefinite programming, </title> <note> Journal of the ACM 42 (1995) 1115-1145. </note>
Reference-contexts: For each probe, they find the binary vector that maximally projects onto the probe in O (n log n) time. This vector corresponds to a bipartitioning solution. For the Max-Cut problem (in which the objective f is maximized), Goemans and Williamson <ref> [22] </ref> construct a set of d-dimensional vectors that correspond to the vertices. They choose a random probe vector and assign vectors with positive projection onto 3 the probe into one cluster, and those with negative projection onto the probe into the other cluster.
Reference: [23] <author> S. Guattery and G. L. Miller, </author> <title> On the performance of spectral graph partitioning methods, </title> <booktitle> in: Proceedings of the ACM/SIAM Symposium on Discrete Algorithms (1995) 233-242. </booktitle>
Reference-contexts: Min-cut graph partitioning is known to be NP-complete, and many heuristic methods have been proposed (see [4] for a survey). Spectral methods are well-established [7] [16] [18] [27] [36] and have also been the subject of extensive study in recent years [2] [5] [6] [10] [19] <ref> [23] </ref> [25] [29] [37] [40]. These methods use eigenvectors of the Laplacian or adjacency matrix to construct various types of geometric representations of the graph. <p> SB takes the linear ordering induced by the second eigenvector of the Laplacian (also called the Fiedler vector) and splits it to yield a 2-way partitioning. Subsequent works have proposed variations of this algorithm [6] [36] [25] and <ref> [23] </ref> [40] analyzed its performance. * Multiple linear orderings: Barnes [7] proposed a multiple-eigenvector extension to spectral bi-partitioning. Barnes tries to map each cluster in a k-way partitioning to one of k eigenvectors while minimizing the rounding error according to a transportation formulation.
Reference: [24] <author> L. Hagen and A. B. Kahng, </author> <title> A new approach to effective circuit clustering, </title> <booktitle> in: Proceedings of the IEEE International Conference on Computer-Aided Design (1992) 422-427. </booktitle>
Reference-contexts: Graph partitioning has no analogous natural similarity measure between vertices (cf. the many ad hoc means in the literature, such as all-pairs shortest paths, k l connectivity [21], degree=separation <ref> [24] </ref>, etc.). To establish a reduction between min-cut graph partitioning and max-sum vector partitioning, we reformulate the min-cut objective as the maximization objective nH f (P k ) (following [19]), where H is some constant greater than or equal to n (for now, the choice of H is inconsequential).
Reference: [25] <author> L. Hagen and A. B. Kahng, </author> <title> New spectral methods for ratio cut partitioning and clustering, </title> <journal> IEEE Trans. </journal> <note> on CAD 11 (1992) 1074-1085. </note>
Reference-contexts: Min-cut graph partitioning is known to be NP-complete, and many heuristic methods have been proposed (see [4] for a survey). Spectral methods are well-established [7] [16] [18] [27] [36] and have also been the subject of extensive study in recent years [2] [5] [6] [10] [19] [23] <ref> [25] </ref> [29] [37] [40]. These methods use eigenvectors of the Laplacian or adjacency matrix to construct various types of geometric representations of the graph. <p> SB takes the linear ordering induced by the second eigenvector of the Laplacian (also called the Fiedler vector) and splits it to yield a 2-way partitioning. Subsequent works have proposed variations of this algorithm [6] [36] <ref> [25] </ref> and [23] [40] analyzed its performance. * Multiple linear orderings: Barnes [7] proposed a multiple-eigenvector extension to spectral bi-partitioning. Barnes tries to map each cluster in a k-way partitioning to one of k eigenvectors while minimizing the rounding error according to a transportation formulation. <p> Instead of explicitly solving the vector partitioning problem, we construct a linear ordering of the vectors, which corresponds to a linear ordering of the graph vertices. Previous work [1] <ref> [25] </ref> [38] has shown the utility of ordering-based partitionings for VLSI applications. In addition, the idea of constructing an ordering and splitting it into a partitioning is at the heart of spectral bipartitioning (SB) [7] [36]. <p> present four sets of experiments that we performed with MELO: * Comparisons of the weighting schemes proposed in the previous section, * Comparisons with different values of d, * Multi-way partitioning comparisons with recursive spectral bipartitioning (RSB), KP [10], and SFC [1] algorithms, * Balanced 2-way partitioning comparisons with SB <ref> [25] </ref> and PARABOLI [38]. Our experiments use the set of ACM/SIGDA benchmarks listed in Table 1 (available via the World Wide Web at http://ballade.cs.ucla.edu/~cheese). The eigenvector computations were performed using LASO2 code [39], with a driver provided by the authors of [10]. <p> Table 4 reports results for our third set of experiments, which compare MELO to the multi-way parti tioning algorithms RSB (recursive spectral bipartitioning) <ref> [25] </ref>, KP [10], and SFC [1].
Reference: [26] <author> S. W. Hadley, B. L. Mark, and A. Vannelli, </author> <title> An efficient eigenvector approach for finding netlist partitions, </title> <journal> IEEE Trans. </journal> <note> on CAD 11 (1992) 885-892. </note>
Reference-contexts: An extension of Barnes' approach has been given by Rendl and Wolkowicz [37], and iterative improvement post-processing was proposed by Hadley et al. <ref> [26] </ref>. * Points in d-dimensional space: Hall [27] proposed using the coordinates of the second and third eigenvectors of the Laplacian to construct a 2-dimensional placement.
Reference: [27] <author> K. M. Hall, </author> <title> An r-dimensional quadratic placement algorithm, </title> <institution> Manag. Sci. </institution> <month> 17 </month> <year> (1970) </year> <month> 219-229. </month>
Reference-contexts: Notice that f counts the cost of each cut edge twice. Min-cut graph partitioning is known to be NP-complete, and many heuristic methods have been proposed (see [4] for a survey). Spectral methods are well-established [7] [16] [18] <ref> [27] </ref> [36] and have also been the subject of extensive study in recent years [2] [5] [6] [10] [19] [23] [25] [29] [37] [40]. These methods use eigenvectors of the Laplacian or adjacency matrix to construct various types of geometric representations of the graph. <p> These methods use eigenvectors of the Laplacian or adjacency matrix to construct various types of geometric representations of the graph. We loosely categorize previous methods according to five basic representations: * Linear orderings (spectral bipartitioning): The classic works of Hall <ref> [27] </ref> and Fiedler [18] gave theoretical motivation to the spectral bipartitioning (SB) heuristic, which is widely used in both the VLSI and scientific computing communities. <p> An extension of Barnes' approach has been given by Rendl and Wolkowicz [37], and iterative improvement post-processing was proposed by Hadley et al. [26]. * Points in d-dimensional space: Hall <ref> [27] </ref> proposed using the coordinates of the second and third eigenvectors of the Laplacian to construct a 2-dimensional placement. Alpert and Kahng [1] extended this idea to higher dimensions, i.e., the i th entries of d eigenvectors yield the coordinates of v i in d-space. <p> They prove a strong approximation bound on the expected performance of their heuristic. * Vectors in d-space: Chan et al. [10] use the same embedded vertices as in [2] <ref> [27] </ref>, but view each embedded vertex as a vector rather than as a point. Their KP algorithm constructs partitioning solutions using the directional cosine between two vectors as a similarity measure between vertices. <p> Theorem 1 f (P k ) = trace (X T QX). The trace of a matrix is the sum of its diagonal entries, e.g., trace (A) = P n i=1 a ii . Theorem 1 directly follows from the result of Hall <ref> [27] </ref> that E h = ~ X T h Q ~ X h . Definition: An n-vector ~ is an eigenvector of Q with eigenvalue if and only if Q~ = ~.
Reference: [28] <author> M. Hanan, P. K. Wolff, and B. J. Agule, </author> <title> A study of placement techniques, </title> <journal> Journal of Design Automation and Fault-Tolerant Computing 2 (1978) 28-61. </journal>
Reference-contexts: This model has been utilized in the partitioning heuristic of [10]. * Costs of 2 jej <ref> [28] </ref>, ( 2 jej 2 jej [15] have also been proposed for the clique edges. It remains open as to which model is best for a given application.
Reference: [29] <author> B. Hendrickson and R. Leland, </author> <title> An improved spectral graph partitioning algorithm for mapping parallel computations, </title> <note> SIAM Journal on Scientific Computing 16 (1995) 452-69. </note>
Reference-contexts: Min-cut graph partitioning is known to be NP-complete, and many heuristic methods have been proposed (see [4] for a survey). Spectral methods are well-established [7] [16] [18] [27] [36] and have also been the subject of extensive study in recent years [2] [5] [6] [10] [19] [23] [25] <ref> [29] </ref> [37] [40]. These methods use eigenvectors of the Laplacian or adjacency matrix to construct various types of geometric representations of the graph. <p> They used a spacefilling curve to induce a linear ordering of the embedded vertices, and then split the ordering into a multi-way partitioning via dynamic programming. Hendrickson and Leland <ref> [29] </ref> have also used this embedding; they use d eigenvectors to construct a partitioning with 2 d clusters.
Reference: [30] <author> T. C. Hu and K. Moerder, </author> <title> Multiterminal flows in a hypergraph, in: VLSI Circuit Layout: </title> <journal> Theory and Design (IEEE Press, </journal> <year> 1985) </year> <month> 87-93. </month>
Reference-contexts: Many hypergraph-to-graph transformations have been proposed (see [4] for a detailed survey) including (i) creating a dummy vertex v 0 for each hyperedge e 2 E H , and inserting edges (v; v 0 ) in E for each v 2 v 0 <ref> [30] </ref>; (ii) mapping each hyperedge to a vertex in G and constructing an edge 1 between two vertices if their corresponding hyperedges are incident to a common vertex [34]; and (iii) for each hyperedge e, constructing an edge (v; w) for every pair of vertices v; w 2 e.
Reference: [31] <author> E. Ihler, D. Wagner, and F. Wagner, </author> <title> Modeling hypergraphs by graphs with the same mincut properties, </title> <note> Information Processing Letters 45 (1993) 171-175. </note>
Reference-contexts: The problem remains as to how to assign costs to edges in G. Ideally, the total cost of the cut edges should be one, corresponding to the cut of a single hyperedge, no matter how the vertices of that hyperedge's clique are partitioned. However, Ihler et al. <ref> [31] </ref> prove that such a "perfect" clique model is impossible, and Lengauer [32] shows that for any cost function there is some partitioning solution with ( p jej) deviation from the desired unit cost of cutting the hyperedge e.
Reference: [32] <author> T. Lengauer, </author> <title> Combinatorial algorithms for integrated circuit layout, </title> <address> (Wiley-Teubner, </address> <year> 1990). </year>
Reference-contexts: Ideally, the total cost of the cut edges should be one, corresponding to the cut of a single hyperedge, no matter how the vertices of that hyperedge's clique are partitioned. However, Ihler et al. [31] prove that such a "perfect" clique model is impossible, and Lengauer <ref> [32] </ref> shows that for any cost function there is some partitioning solution with ( p jej) deviation from the desired unit cost of cutting the hyperedge e. Hence, many different cost functions have been proposed for the clique model: * The "standard" clique model [32] assigns cost 1 jej1 to each <p> clique model is impossible, and Lengauer <ref> [32] </ref> shows that for any cost function there is some partitioning solution with ( p jej) deviation from the desired unit cost of cutting the hyperedge e. Hence, many different cost functions have been proposed for the clique model: * The "standard" clique model [32] assigns cost 1 jej1 to each clique edge; it is motivated by the linear placement into fixed locations at unit separation [11]. * The "partitioning-specific" model assigns cost 4 jej (jej1) 2 jej 2 2 jej to each clique edge so that the expected cost of each cut hyperedge is
Reference: [33] <author> B. Mohar, </author> <title> The Laplacian spectrum of graphs, </title> <booktitle> in: Proceedings of the 6th Quadrennial International Conference on the Theory and Applications of Graphs (1988) 871-898. </booktitle>
Reference-contexts: We assume that the eigenvectors are normalized, i.e., for 1 j n, ~ T j ~ j = jj~ j jj 2 = 1. The eigenvectors of Q have many interesting properties, including the following <ref> [33] </ref> 1 : 1. The eigenvectors are all mutually orthogonal, hence they form a basis in n-dimensional space. 2. Each eigenvalue j of Q is real. 3.
Reference: [34] <author> L. T. Pillage and R. A. Rohrer, </author> <title> A quadratic metric with a simple solution scheme for initial placement, </title> <booktitle> in: Proceedings of the ACM/IEEE Design Automation Conference (1988) 324-329. </booktitle> <pages> 20 </pages>
Reference-contexts: each hyperedge e 2 E H , and inserting edges (v; v 0 ) in E for each v 2 v 0 [30]; (ii) mapping each hyperedge to a vertex in G and constructing an edge 1 between two vertices if their corresponding hyperedges are incident to a common vertex <ref> [34] </ref>; and (iii) for each hyperedge e, constructing an edge (v; w) for every pair of vertices v; w 2 e.
Reference: [35] <author> S. Poljak and F. Rendl, </author> <title> Solving the max-cut problem using eigenvalues, </title> <note> Discrete Applied Mathematics 62 (1995) 249-278. </note>
Reference-contexts: The corresponding partitioning objective is to maximize g (S k ) = min 1hk jjY n h jj 2 . Max Cut: Another problem which has received much attention in the recent literature is the max-cut problem [13] [14] <ref> [35] </ref>: Maximize: f (P k ) = k X jE (C h )j: The same mapping of ~y n i to row i of 2 U that was used to reduce min-cut graph partitioning to min-sum vector partitioning can be used to reduce the max-cut problem to max-sum vector partitioning. 4
Reference: [36] <author> A. Pothen, H. D. Simon, and K. P. Liou, </author> <title> Partitioning sparse matrices with eigenvectors of graphs, </title> <note> SIAM Journal of Matrix Analysis and its Applications 11 (1990) 430-452. </note>
Reference-contexts: Notice that f counts the cost of each cut edge twice. Min-cut graph partitioning is known to be NP-complete, and many heuristic methods have been proposed (see [4] for a survey). Spectral methods are well-established [7] [16] [18] [27] <ref> [36] </ref> and have also been the subject of extensive study in recent years [2] [5] [6] [10] [19] [23] [25] [29] [37] [40]. These methods use eigenvectors of the Laplacian or adjacency matrix to construct various types of geometric representations of the graph. <p> SB takes the linear ordering induced by the second eigenvector of the Laplacian (also called the Fiedler vector) and splits it to yield a 2-way partitioning. Subsequent works have proposed variations of this algorithm [6] <ref> [36] </ref> [25] and [23] [40] analyzed its performance. * Multiple linear orderings: Barnes [7] proposed a multiple-eigenvector extension to spectral bi-partitioning. Barnes tries to map each cluster in a k-way partitioning to one of k eigenvectors while minimizing the rounding error according to a transportation formulation. <p> Previous work [1] [25] [38] has shown the utility of ordering-based partitionings for VLSI applications. In addition, the idea of constructing an ordering and splitting it into a partitioning is at the heart of spectral bipartitioning (SB) [7] <ref> [36] </ref>. Our construction seeks to combine d distinct eigenvectors (where d is as large as practically possible) into a single vertex ordering that utilizes all of the eigenvector information.
Reference: [37] <author> F. Rendl and H. Wolkowicz, </author> <title> A projection technique for partitioning the nodes of a graph, </title> <note> Annals of Operations Research 58 (1995) 155-179. </note>
Reference-contexts: Min-cut graph partitioning is known to be NP-complete, and many heuristic methods have been proposed (see [4] for a survey). Spectral methods are well-established [7] [16] [18] [27] [36] and have also been the subject of extensive study in recent years [2] [5] [6] [10] [19] [23] [25] [29] <ref> [37] </ref> [40]. These methods use eigenvectors of the Laplacian or adjacency matrix to construct various types of geometric representations of the graph. <p> If there is zero rounding error, the optimum cut value equal to a weighted sum of the largest k eigenvalues (of the adjacency matrix) [16] is obtained. An extension of Barnes' approach has been given by Rendl and Wolkowicz <ref> [37] </ref>, and iterative improvement post-processing was proposed by Hadley et al. [26]. * Points in d-dimensional space: Hall [27] proposed using the coordinates of the second and third eigenvectors of the Laplacian to construct a 2-dimensional placement. <p> Each row of X has sum one, and column h has sum jC h j. A well-known result is that the min-cut objective f can be directly expressed in terms of the Laplacian and assignment matrices (see e.g., [10] <ref> [37] </ref>). Theorem 1 f (P k ) = trace (X T QX). The trace of a matrix is the sum of its diagonal entries, e.g., trace (A) = P n i=1 a ii . <p> Cullum et al. [12] showed how to find a diagonal matrix D that minimizes the sum of the first d eigenvalues of A + D. Another possibility is to use the algorithm of Carter [9] to construct D such that trace (D) is minimized. Many researchers, e.g., [8] [16] <ref> [37] </ref> [17], have applied various types of diagonal optimization both to improve the quality of lower bounds on the cost of a solution and to enhance the performance of their spectral partitioning heuristics.
Reference: [38] <author> B. M. Riess, K. Doll, and F. M. Johannes, </author> <title> Partitioning very large circuits using analytical placement techniques, </title> <booktitle> in: Proceedings of the ACM/IEEE Design Automation Conference (1994) 646-651. </booktitle>
Reference-contexts: Instead of explicitly solving the vector partitioning problem, we construct a linear ordering of the vectors, which corresponds to a linear ordering of the graph vertices. Previous work [1] [25] <ref> [38] </ref> has shown the utility of ordering-based partitionings for VLSI applications. In addition, the idea of constructing an ordering and splitting it into a partitioning is at the heart of spectral bipartitioning (SB) [7] [36]. <p> of experiments that we performed with MELO: * Comparisons of the weighting schemes proposed in the previous section, * Comparisons with different values of d, * Multi-way partitioning comparisons with recursive spectral bipartitioning (RSB), KP [10], and SFC [1] algorithms, * Balanced 2-way partitioning comparisons with SB [25] and PARABOLI <ref> [38] </ref>. Our experiments use the set of ACM/SIGDA benchmarks listed in Table 1 (available via the World Wide Web at http://ballade.cs.ucla.edu/~cheese). The eigenvector computations were performed using LASO2 code [39], with a driver provided by the authors of [10]. <p> Our final set of experiments used MELO orderings to construct bipartitionings by choosing the one with lowest ratio cut from all possible splits of the ordering, while ensuring that each cluster contains at least 45% of the modules. We quote the PARABOLI results of <ref> [38] </ref> as a source of comparison, and additionally compare against SB. 4 The MELO results reported are the best observed from splitting each of the ten orderings constructed for schemes #2, #3, and #4; we use three schemes since the best scheme for this application remains unclear (in fact, frequently one <p> Thus, the SB results differ from those reported in <ref> [38] </ref> for this reason and also because of net model differences. 17 ranked vector not in S or T is added to T . The remaining vectors are re-ranked periodically (e.g., every 100 iterations) and T is updated.
Reference: [39] <author> D. S. Scott, </author> <title> LASO2 documentation, </title> <type> Technical Report, </type> <institution> University of Texas, Austin, </institution> <address> TX (1980). </address>
Reference-contexts: terms in this summation; however, we can approximate it by using the first d terms (since these are the most dominant terms), i.e., H 2 d X ff 2 Assuming that this approximation is reasonable (which we observed in practice by the distribution of 2 We use the Lanczos algorithm <ref> [39] </ref> to compute the Laplacian eigenvectors. When computing the eigenvectors with the smallest corresponding eigenvalues, ~ i will always converge faster than ~ j if i &lt; j, e.g., it will never be the case that say the ~ 20 is known but ~ 10 is not. <p> Our experiments use the set of ACM/SIGDA benchmarks listed in Table 1 (available via the World Wide Web at http://ballade.cs.ucla.edu/~cheese). The eigenvector computations were performed using LASO2 code <ref> [39] </ref>, with a driver provided by the authors of [10]. Before the eigenvectors were computed, each netlist was transformed into a graph using the partitioning-specific clique model. We also discuss use of the standard and Frankle clique models.
Reference: [40] <author> D. A. Spielman and S.-H. Teng, </author> <title> Spectral partitioning works: planar graphs and finite element meshes, </title> <type> Manuscript (1996). </type>
Reference-contexts: Spectral methods are well-established [7] [16] [18] [27] [36] and have also been the subject of extensive study in recent years [2] [5] [6] [10] [19] [23] [25] [29] [37] <ref> [40] </ref>. These methods use eigenvectors of the Laplacian or adjacency matrix to construct various types of geometric representations of the graph. <p> SB takes the linear ordering induced by the second eigenvector of the Laplacian (also called the Fiedler vector) and splits it to yield a 2-way partitioning. Subsequent works have proposed variations of this algorithm [6] [36] [25] and [23] <ref> [40] </ref> analyzed its performance. * Multiple linear orderings: Barnes [7] proposed a multiple-eigenvector extension to spectral bi-partitioning. Barnes tries to map each cluster in a k-way partitioning to one of k eigenvectors while minimizing the rounding error according to a transportation formulation.

References-found: 40

