URL: http://www.iro.umontreal.ca/~lecuyer/myftp/papers/lrsrec.ps
Refering-URL: http://www.iro.umontreal.ca/~lecuyer/papers.html
Root-URL: http://www.iro.umontreal.ca
Title: LIKELIHOOD RATIO GRADIENT ESTIMATION FOR STOCHASTIC RECURSIONS  
Author: Peter W. Glynn Pierre L'Ecuyer 
Keyword: Harris recurrent Markov chain, likelihood ratio, gradient estimation, regeneration.  
Address: Stanford, CA 94305-4022  C.P. 6128, Succ. A, Montreal, H3C 3J7, CANADA  
Affiliation: Department of Operations Research, Stanford University  Departement d'IRO, Universite de Montreal  
Date: June 5, 1995  
Note: To appear in Advances in Applied Probability, 1995 Version:  
Abstract: In this paper, we develop mathematical machinery for verifying that a broad class of general state space Markov chains reacts smoothly to certain types of perturbations in the underlying transition structure. Our main result provides conditions under which the stationary probability measure of an ergodic Harris recurrent Markov chain is differentiable in a certain strong sense. The approach is based on likelihood ratio "change-of-measure" arguments, and leads directly to a "likelihood ratio gradient estimator" that can be computed numerically. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Asmussen, S. </author> <year> (1987). </year> <title> Applied Probability and Queues, </title> <publisher> Wiley. </publisher> <pages> 36 </pages>
Reference-contexts: More precisely, for each 2 fl, we assume that there exists a family of functions (r n () : n 0) such that for each n 0, r n () : S n+1 1 ! <ref> [0; 1] </ref> is measurable, and such that P [T = n j X] = r n (; X 0 ; : : : ; X n ): Demanding this is equivalent to require that T be a randomized stopping time with respect to (oe (X 0 ; : : : ; <p> To simplify our notation, let P () and E () = E 0 (). A "prime" will denote the derivative with respect to . We shall assume that: (A2) (i) There exists * &gt; 0 such that for each 2 fl * , P <ref> [T &lt; 1] </ref> = 1; (ii) There exists * &gt; 0 such that for each x 2 S 1 and z 2 S 2 , u (; x) and k (; z) are continuously differentiable on fl * ; (iii) There exists a random variable ae 0 ( 0 ) such <p> To be more precise, suppose that there is a specific state x fl 2 S 1 that is hit in finite time with probability one from any other state; that is, P ;x <ref> [T &lt; 1] </ref> = 1 for all x 2 S 1 and 2 fl * , where T = inffn &gt; 0 : X n = x fl g. Define A = fx fl g and '(dy) = I [x fl 2 dy].
Reference: [2] <author> Athreya, K. B. and P. </author> <title> Ney (1978). A new approach to the limit theory of recurrent Markov Chains. </title> <journal> Trans. Amer. Math. Soc. </journal> <volume> 245, </volume> <pages> 493-501. </pages>
Reference: [3] <author> Billingsley, P. </author> <year> (1968). </year> <title> Convergence of Probability Measures, </title> <publisher> John Wiley, </publisher> <address> New York. </address>
Reference: [4] <author> Chung, K. L. </author> <year> (1974). </year> <title> A Course in Probability Theory, </title> <publisher> Academic Press, </publisher> <address> New York. </address>
Reference: [5] <author> Fox, B. L. and P. W. </author> <title> Glynn (1986). Discrete-time conversion for simulating semi-Markov processes. </title> <journal> Operations Research Letters 5, </journal> <pages> 191-196. </pages>
Reference: [6] <author> Glasserman, P. </author> <year> (1991). </year> <title> Gradient Estimation via Perturbation Analysis. </title> <publisher> Kluwer Academic Publishers, Norwell, </publisher> <address> MA. </address>
Reference: [7] <author> Glynn, P. W. </author> <year> (1989). </year> <title> A GSMP formalism for discrete event systems. </title> <booktitle> Proc. IEEE 77, </booktitle> <pages> 14-23. </pages>
Reference: [8] <author> Glynn, P.W. </author> <year> (1986). </year> <title> Optimization of stochastic systems. </title> <booktitle> Proc. of the 1986 Winter Simulation Conference, </booktitle> <pages> 52-59. </pages>
Reference: [9] <author> Glynn, P. W. </author> <year> (1992). </year> <title> Pathwise convexity and its relation to convergence of time-average derivatives. </title> <booktitle> Management Science 38, </booktitle> <volume> 9, </volume> <pages> 1360-1366. </pages>
Reference: [10] <author> Glynn, P. W. and L'Ecuyer, P. </author> <year> (1994). </year> <title> Likelihood Ratio Gradient Estimation for Stochastic Recursions. </title> <note> Research report No. </note> <institution> G-94-xx, GERAD, University of Montreal. </institution>
Reference: [11] <author> Glynn, P. W., L'Ecuyer, P., and Ades, M. </author> <year> (1991). </year> <title> Gradient Estimation for Ratios. </title> <booktitle> Proceedings of the 1991 Winter Simulation Conference, </booktitle> <publisher> IEEE Press, </publisher> <pages> 986-993. </pages>
Reference: [12] <author> Golub, G. H. and Meyer, C. D. </author> <year> (1986). </year> <title> Using the QR Factorization and group Inversion to Compute, Differentiate, and Estimate the Sensitivity of Stationary Probabilities for Markov Chains. </title> <journal> SIAM J. Alg. and Dis. </journal> <volume> Methods 7, </volume> <pages> 273-281. </pages>
Reference: [13] <author> Kennedy, D.P. </author> <year> (1972). </year> <title> The Continuity of the Single-Server Queue. </title> <journal> J. Appl. </journal> <volume> Probability 9, </volume> <pages> 370-381. </pages>
Reference: [14] <author> Konig, D., K. Mathes and K. </author> <month> Nawrotzki </month> <year> (1967). </year> <editor> Verallgemeinerungen der Erlangschen und Engsetschen Formeln. </editor> <publisher> Akademie-Verlag, </publisher> <address> Berlin. </address>
Reference: [15] <author> L'Ecuyer, P. and P. W. </author> <title> Glynn (1994). Stochastic Optimization by Simulation: Convergence Proofs for GI/G/1 Queues in Steady-State. </title> <institution> Management Science, </institution> <note> to appear. 37 </note>
Reference: [16] <author> Meyn, S. P. and R. L. </author> <month> Tweedie </month> <year> (1993). </year> <title> Markov Chains and Stochastic Stability. </title> <publisher> Springer--Verlag, </publisher> <address> New York. </address>
Reference: [17] <author> Nummelin, E. </author> <year> (1978). </year> <title> A splitting technique for Harris recurrent Markov chains. </title> <journal> Z. </journal> <volume> Wahrschein-lichkeitstheorie 43, </volume> <pages> 309-318. </pages>
Reference: [18] <author> Nummelin, E. </author> <year> (1984). </year> <title> General Irreducible Markov Chains and Non-negative Operators, </title> <publisher> Cam-bridge University Press, </publisher> <address> New York. </address>
Reference: [19] <author> Rubinstein, R. Y. and Shapiro, A. </author> <year> (1993). </year> <title> Discrete Event Systems: Sensitivity Analysis and Stochastic Optimization by the Score Function Method , John Wiley, </title> <address> New York. </address>
Reference: [20] <author> Schweitzer, P. J. </author> <year> (1968). </year> <title> Perturbation Theory and Finite Markov Chains. </title> <journal> J. Appl. Prob. </journal> <volume> 5, </volume> <pages> 401-413. </pages>
Reference: [21] <author> Tweedie, R. L. </author> <year> (1983). </year> <title> The existence of moments for stationary Markov chains. </title> <journal> J. Appl. Prob. </journal> <volume> 20, </volume> <pages> 191-196. </pages>
Reference: [22] <author> Vasquez-Abad, F. and H. </author> <title> Kushner (1992). Estimation of the derivative of a stationary measure with respect to a control parameter. </title> <journal> J. Appl. Prob. </journal> <volume> 29, </volume> <pages> 343-352. </pages>
Reference: [23] <author> Whitt, W. </author> <year> (1980). </year> <title> Continuity of Generalized Semi-Markov Processes. </title> <journal> Mathematics of Operations Research 5, </journal> <pages> 494-501. </pages>
Reference: [24] <author> Whitt, W. </author> <year> (1974). </year> <title> The Continuity of Queues. </title> <booktitle> Advances in Appl. Probability 6, </booktitle> <pages> 175-183. 38 </pages>
References-found: 24

