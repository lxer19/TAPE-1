URL: ftp://theory.lcs.mit.edu/pub/classes/6.858/lecture21.ps
Refering-URL: http://theory.lcs.mit.edu/~mona/lectures.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Outline Learning decision trees with Fourier theory  of random examples. 4. The algorithm uses membership queries.  
Author: Lecturer: Ron Rivest Scribe: Andreas Argiriou 
Date: 21 November 28, 1994  
Note: 6.858/18.428 Machine Learning Lecture  21.1 Introduction 3. There is no source  2 f0; 1g 7! (1)  
Abstract: In this lecture we see how we can apply Fourier techniques to learn decision trees, as described by Kushilevitz and Mansour in [1]. Such techniques have also been used in other problems, like DNF formulas. The type of learning game we need to consider now is special in the following ways: 2. We want to learn decision trees. In the model of membership queries, the learner makes up the questions so that it may ask for the label of an example. With equivalence queries, on the other hand, the learner presents a hypothesis h and asks if h is the same as the target concept f . If h 6= f , the learner receives a counterexample as an answer. In this problem we essentially need statistical queries, but we can use membership queries to get information of the type a statistical query would give. We will consider boolean functions with a slight modification: a boolean function now maps f0; 1g n to f1g instead of f0; 1g in the following way 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Eyal Kushilevitz and Yishay Mansour. </author> <title> Learning Decision Trees using the Fourier Spectrum. </title> <booktitle> In Proceedings of the 23rd Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 455-464, </pages> <year> 1991. </year>
References-found: 1

