URL: http://www.cs.dartmouth.edu/~jasonliu/courses/sim188/biblio/whal92.ps.gz
Refering-URL: http://www.cs.dartmouth.edu/~jasonliu/courses/sim188/notes-08.html
Root-URL: http://www.cs.dartmouth.edu
Email: SUMMARY  
Title: Fast Instruction Cache Performance Evaluation Using Compile-Time Analysis  
Author: DAVID B. WHALLEY 
Keyword: KEY WORDS: Instruction Cache Cache Simulation Trace Generation Trace Analysis  
Address: FL 32306, U.S.A.  
Affiliation: Department of Computer Science, Florida State University, Tallahassee,  
Abstract: Cache performance has become a very crucial factor in the overall system performance of machines. Effective analysis of a cache design requires the evaluation of the performance of the cache for typical programs that are to be executed on the machine. Recent attempts to reduce the time required for such evaluations either result in a loss of accuracy or require an initial pass by a filter to reduce the length of the trace. This paper describes techniques that overcome these problems for instruction cache performance evaluation. Information calculated during the compilation is used to reduce the number of references in the trace. Thus, in effect references are stripped before the initial trace is generated. These techniques are shown to significantly reduce the time required for evaluating instruction caches with no loss of accuracy. 
Abstract-found: 1
Intro-found: 1
Reference: [ASH86] <author> A. Agarwal, R. L. Sites, and M. Horowitz, ATUM: </author> <title> A New Technique for Capturing Address Traces Using Microcode, </title> <booktitle> Proceedings of the 13th Annual Symposium on Computer Architecture, </booktitle> <pages> pp. </pages> <month> 119-127 (June </month> <year> 1986). </year>
Reference-contexts: One faster trace generation method is to modify the microcode of a microprogrammed machine. Relative to techniques using traps or simulated program execution, this method does not impose a large run-time penalty <ref> [ASH86] </ref>. The microcode of a machine, however, is o ften not accessible to the typical user. Even when it is accessible, it often requires great expertise to modify without adversely affecting the operation of the machine.
Reference: [BeD88] <author> M. E. Benitez and J. W. Davidson, </author> <title> A Portable Global Optimizer and Linker, </title> <booktitle> Proceedings of the SIGPLAN '88 Symposium on Programming Language Design and Implementation, p p. </booktitle> <month> 329-338 (June </month> <year> 1988). </year>
Reference-contexts: A C compiler for the Motorola 68020/68881 was implemented within the ease environment [DaW90], which consists of a compiler generation system called vpo <ref> [BeD88] </ref> and measurement tools. The compiler was modified to implement each of the seven techniques described in the previous section. Cache performance measurements were obtained for each program within the test set using each of the techniques.
Reference: [BKW90] <author> A. Borg, R. E. Kessler, and D. W. Wall, </author> <title> Generation and Analysis of Very Long Address Traces, Proceedings of the 17th Annual 7 Some approaches have dedicated a set of registers to be used exclusively for tracing and/or require special operating system support [BKW90, </title> <booktitle> EKK90, ASH86, Wie82]. -9 International Symposium on Computer Archi--tecture, </booktitle> <pages> pp. </pages> <month> 270-279 (May </month> <year> 1990). </year>
Reference-contexts: Since realistic program traces can be quite lengthy, a trace is often only collected from a portion of the program's execution. However, it h as been shown that the cache performance can vary greatly in different portions of a program's execution <ref> [BKW90] </ref>. Cache performance measurements obtained when unrealistic input data is used to shorten the length of the trace would also be of questionable value. <p> Trace data is typically stored in secondary storage and then later read by a cache simulator that will perform the analysis of the data. Realistic trace data, however, requires at least several million references which may make infeasible the use of disk as the storage media <ref> [BKW90] </ref>. Therefore, there has been much work on the problem of reducing the space and time requirements for trace-driven simulation. One faster trace generation method is to modify the microcode of a microprogrammed machine. <p> Also, modification of microcode would not be applicable for machines which are not microprogrammed (e.g. many RISCs). Program instrumentation, or inline tracing, is a technique that requires little overhead for generating a trace of addresses <ref> [HLT87, BKW90, EKK90] </ref>. Instructions are inserted to record addresses during the program's execution and must not change the normal execution behavior of the program. Therefore, the values in data registers or the condition codes may have to be sav ed and restored. <p> Even after tuning a cache simulator for a specific cache configuration, a cache simulator can still require an order of magnitude more time than generating the trace itself <ref> [BKW90] </ref>. Therefore, there has been much attention given to reducing the number of references that need to be traced. There have been several methods proposed to improve cache simulation times by reducing the number of references in the trace. <p> On-the-y analysis is a technique that avoids the I/O associated with storing the generated trace and retrieving the trace for input to the cache simulator. In this approach either the cache simulator is a separate process that reads a trace buffer containing the trace <ref> [BKW90] </ref> or the cache simulator is linked directly to the program and trace information is received as arguments via function calls [StF89]. Even though the space and I/O requirements are diminished, the trace analysis can still be quite time-consuming since the entire trace is being processed. <p> Though only the number of instruction references to be processed can be reduced, the techniques can also be used when evaluating split instruction and data caches. There still should be a measurable improvement in this situation since typically the majority of address references being processed are instructions <ref> [BKW90] </ref>. The effective evaluation of large second-level c aches may require billions of references to be traced. When positioned behind a split first-level cache, the techniques presented in this paper would be very useful.
Reference: [DaW90] <author> J. W. Davidson and D. B. Whalley, </author> <title> Ease: An Environment for Architecture Study and Experimentation, </title> <booktitle> Proceedings SIGMETRICS '90 Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pp. </pages> <month> 259-260 (May </month> <year> 1990). </year>
Reference-contexts: Unfortunately, this would complicate implementation of the techniques since portability would be decreased and the control-ow and data-ow information already available in a compiler would have to be recalculated. A C compiler for the Motorola 68020/68881 was implemented within the ease environment <ref> [DaW90] </ref>, which consists of a compiler generation system called vpo [BeD88] and measurement tools. The compiler was modified to implement each of the seven techniques described in the previous section. Cache performance measurements were obtained for each program within the test set using each of the techniques.
Reference: [EKK90] <author> S. J. Eggers, D. R. Keppel, E. J. Koldinger, and H. M. Levy, </author> <title> Techniques for Efficient Inline Tracing on a Shared-Memory Multiprocessor, </title> <booktitle> Proceedings SIGMETRICS '90 Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pp. </pages> <month> 37-47 (May </month> <year> 1990). </year>
Reference-contexts: Also, modification of microcode would not be applicable for machines which are not microprogrammed (e.g. many RISCs). Program instrumentation, or inline tracing, is a technique that requires little overhead for generating a trace of addresses <ref> [HLT87, BKW90, EKK90] </ref>. Instructions are inserted to record addresses during the program's execution and must not change the normal execution behavior of the program. Therefore, the values in data registers or the condition codes may have to be sav ed and restored. <p> Each technique builds upon the previously presented techniques. Technique A is a straight-forward approach. Techniques B and C recognize spatial locality to reduce the length of the trace and methods similar to these have been used in previous studies <ref> [MiF88, EKK90] </ref>. Techniques D-G use cache configuration information and the control ow of the program to avoid processing additional references due to both spatial and temporal locality. Technique A For Technique A, a call to a trace routine is inserted before each basic block in the program. <p> Instead of invoking the simulator once for an entire basic block, the technique invokes the simulator once for each sequence of executed blocks that are physically contiguous. The basic block number of the beginning of a sequence of blocks, also described as a superblock <ref> [EKK90] </ref>, is saved. A call instruction to the trace routine is inserted before any unconditional jump, call, or return instructions. Handling conditional transfers of control is a little more complicated. The trace routine should only be invoked when the conditional branch is taken.
Reference: [HeP90] <author> J. Hennessy and D. Patterson, </author> <title> Computer Architecture: A Quantitative Approach, </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA (1990). </address>
Reference-contexts: Non-usaged based algorithms, such as first-in-first-out (FIFO) or random, are not affected by the reuse of a line. The most common usage-based replacement algorithm for set-associative caches is least-recently-used (LRU) <ref> [HeP90] </ref>. If the current cache line being referenced is also the last line that was referenced within the set, then LRU information need not be updated.
Reference: [HiS89] <author> M. D. Hill and A. J. Smith, </author> <title> Evaluating Associativity in CPU Caches, </title> <journal> IEEE Transactions on Computers 38(12) pp. </journal> <month> 1612-1630 (Decem-ber </month> <year> 1989). </year>
Reference-contexts: Furthermore, the reduced trace may still be quite lengthy, which can result in large files and slow s imu-lations. There have also been several methods that allow different cache configurations to be evaluated during a single simulation <ref> [WaB90, HiS89] </ref>. Another method to avoid processing the entire trace of references is to instead use several discrete samples of traces from the program execution to predict cache performance measures [LPI88].
Reference: [HLT87] <author> M. Huguet, T. Lang, and Y. Tamir, </author> <title> A Block-and-Actions Generator as an Alternative to a Simulator for Collecting Architecture Measurements, </title> <booktitle> Proceedings of the SIGPLAN '87 Symposium on Interpreters and Interpretive Techniques, </booktitle> <pages> pp. </pages> <month> 14-25 (June </month> <year> 1987). </year>
Reference-contexts: Two common methods used for generating trace data are forcing a program to trap after the execution of each instruction or to record references while simulating the execution of each instruction. Each of these methods can result in a program executing a 1000 times slower than normal execution <ref> [PeS77, Wie82, HLT87] </ref>. Trace data is typically stored in secondary storage and then later read by a cache simulator that will perform the analysis of the data. Realistic trace data, however, requires at least several million references which may make infeasible the use of disk as the storage media [BKW90]. <p> Also, modification of microcode would not be applicable for machines which are not microprogrammed (e.g. many RISCs). Program instrumentation, or inline tracing, is a technique that requires little overhead for generating a trace of addresses <ref> [HLT87, BKW90, EKK90] </ref>. Instructions are inserted to record addresses during the program's execution and must not change the normal execution behavior of the program. Therefore, the values in data registers or the condition codes may have to be sav ed and restored.
Reference: [HwC89] <author> W. W. Hwu and P. P. Chang, </author> <title> Achieving High Instruction Cache Performance with an Optimizing Compiler, </title> <booktitle> Proceedings of the 16th Annual Symposium on Computer Architecture, </booktitle> <pages> pp. </pages> <month> 242-250 (May </month> <year> 1989). </year>
Reference-contexts: Thus, the bandwidth between cache memory and the CPU can be improved. Since instruction caches have become more common, there has been much recent work that attempts to reorganize the code of programs to improve the instruction cache performance <ref> [HwC89, McF89, PeH90] </ref>. In fact, most compiler optimizations can affect instruction cache performance since the optimizations can change the order and number of instructions that are executed by a program.
Reference: [LPI88] <author> S. Laha, J. H. Patel, and R. K. Iyer, </author> <title> Accurate Low-Cost Methods for Performance Evaluation of Cache Memory Systems, </title> <journal> IEEE Transactions on Computers 37(11) pp. </journal> <month> 1325-1336 (November </month> <year> 1988). </year>
Reference-contexts: There have also been several methods that allow different cache configurations to be evaluated during a single simulation [WaB90, HiS89]. Another method to avoid processing the entire trace of references is to instead use several discrete samples of traces from the program execution to predict cache performance measures <ref> [LPI88] </ref>. While a significant loss of accuracy may not occur, the method may not have the desirable accuracy for measuring the effect of a new compiler optimization or reorganization technique.
Reference: [McF89] <author> S. McFarling, </author> <title> Program Optimization for Instruction Caches, </title> <booktitle> Proceedings of the Third International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pp. </pages> <month> 183-191 (April </month> <year> 1989). </year>
Reference-contexts: Thus, the bandwidth between cache memory and the CPU can be improved. Since instruction caches have become more common, there has been much recent work that attempts to reorganize the code of programs to improve the instruction cache performance <ref> [HwC89, McF89, PeH90] </ref>. In fact, most compiler optimizations can affect instruction cache performance since the optimizations can change the order and number of instructions that are executed by a program.
Reference: [MiF88] <author> C. L. Mitchell and M. J. Flynn, </author> <title> A Workbench for Computer Architects, </title> <journal> IEEE Design & Test of Computers 5(1) pp. </journal> <month> 19-29 (February </month> <year> 1988). </year>
Reference-contexts: Each technique builds upon the previously presented techniques. Technique A is a straight-forward approach. Techniques B and C recognize spatial locality to reduce the length of the trace and methods similar to these have been used in previous studies <ref> [MiF88, EKK90] </ref>. Techniques D-G use cache configuration information and the control ow of the program to avoid processing additional references due to both spatial and temporal locality. Technique A For Technique A, a call to a trace routine is inserted before each basic block in the program.
Reference: [PeH90] <author> K. Pettis and R. Hansen, </author> <title> Profile Guided Code Positioning, </title> <booktitle> Proceedings of the SIGPLAN '90 Conference on Programming Language Design and Implementation, </booktitle> <pages> pp. </pages> <month> 16-27 (June </month> <year> 1990). </year>
Reference-contexts: Thus, the bandwidth between cache memory and the CPU can be improved. Since instruction caches have become more common, there has been much recent work that attempts to reorganize the code of programs to improve the instruction cache performance <ref> [HwC89, McF89, PeH90] </ref>. In fact, most compiler optimizations can affect instruction cache performance since the optimizations can change the order and number of instructions that are executed by a program.
Reference: [PeS77] <author> B. L. Peuto and L. J. Shustek, </author> <title> An Instruction Timing Model of CPU Performance, </title> <booktitle> Proceedings of the 4th Annual Symposium on Computer Architecture, </booktitle> <pages> pp. </pages> <month> 165-178 (March </month> <year> 1977). </year>
Reference-contexts: Two common methods used for generating trace data are forcing a program to trap after the execution of each instruction or to record references while simulating the execution of each instruction. Each of these methods can result in a program executing a 1000 times slower than normal execution <ref> [PeS77, Wie82, HLT87] </ref>. Trace data is typically stored in secondary storage and then later read by a cache simulator that will perform the analysis of the data. Realistic trace data, however, requires at least several million references which may make infeasible the use of disk as the storage media [BKW90].
Reference: [Puz85] <author> T. R. Puzak, </author> <title> Analysis of Cache Replacement Algorithms, </title> <type> PhD Dissertation, </type> <institution> University of Massachusetts, </institution> <address> Amherst, MA (February 1985). </address>
Reference-contexts: There have been several methods proposed to improve cache simulation times by reducing the number of references in the trace. One method for reducing the length of the trace data is called trace stripping <ref> [Puz85] </ref>. This approach first simulates a direct-mapped cache and records only the references that are misses since hits do not result in changes to the cache state. <p> As in Puzak's trace stripping method <ref> [Puz85] </ref>, if the number of sets is not decreased and the line size remains the same, then the program need not be recompiled.
Reference: [Smi77] <author> A. J. Smith, </author> <title> Two Methods for the Efficient Analysis of Memory Address Trace Data, </title> <journal> IEEE Transactions on Software Engineering 3(1) pp. </journal> <month> 94-101 (January </month> <year> 1977). </year>
Reference-contexts: INTRODUCTION The time required to generate and analyze trace data is proportional to the number of references in the trace <ref> [Smi77] </ref>. Since realistic program traces can be quite lengthy, a trace is often only collected from a portion of the program's execution. However, it h as been shown that the cache performance can vary greatly in different portions of a program's execution [BKW90].
Reference: [Smi82] <author> A. J. Smith, </author> <title> Cache Memories, </title> <journal> Computing Surveys 14(3) pp. </journal> <month> 473-530 (September </month> <year> 1982). </year>
Reference-contexts: The replacement algorithm for determining which cache line to replace within the set can be usage or non-usage based <ref> [Smi82] </ref>. Non-usaged based algorithms, such as first-in-first-out (FIFO) or random, are not affected by the reuse of a line. The most common usage-based replacement algorithm for set-associative caches is least-recently-used (LRU) [HeP90]. <p> A cache hit was assumed to require one work unit while a cache miss was assumed to require ten. The context switch interval and estimated time units required for a hit versus a miss are the same as those used in Smith's cache studies <ref> [Smi82] </ref>. Though the experiments in this paper simulated context switching based on estimated cache work to check that identical measurements were obtained with the different techniques, other methods to determine context switch points could also be used.
Reference: [StF89] <author> C. Stunkel and W. Fuchs, TRAPEDS: </author> <title> Producing Traces for Multicomputers Via Execution Driven Simulation, </title> <booktitle> Proceedings of the International Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pp. </pages> <month> 70-78 (May </month> <year> 1989). </year>
Reference-contexts: In this approach either the cache simulator is a separate process that reads a trace buffer containing the trace [BKW90] or the cache simulator is linked directly to the program and trace information is received as arguments via function calls <ref> [StF89] </ref>. Even though the space and I/O requirements are diminished, the trace analysis can still be quite time-consuming since the entire trace is being processed. TECHNIQUES FOR REDUCING INSTRUCTION CACHE EVALUATION TIMES An optimizer of a compiler system was modified to be able to generate and analyze trace data. <p> Therefore, only the execution time ratios for Techniques E, F, and G are presented in Table VI. 6 Smaller ratios to execution times without tracing were reported for a method similar to Technique B in the trapeds system <ref> [StF89] </ref> This discrepancy was probably due to their choice to simulate more oating-point intensive programs, to not introduce or check for pending context switches, and the use of a cache simulator tuned for specific cache configurations. -8 Cache Ratio to Execution Time without Tracing E F G Size Program compact 25.58
Reference: [WaB90] <author> W. Wang and J. Baer, </author> <title> Efficient Trace-Driven Simulation Methods for Cache Performance Analysis, </title> <booktitle> Proceedings SIGMETRICS '90 Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pp. </pages> <month> 27-36 (May </month> <year> 1990). </year>
Reference-contexts: Furthermore, the reduced trace may still be quite lengthy, which can result in large files and slow s imu-lations. There have also been several methods that allow different cache configurations to be evaluated during a single simulation <ref> [WaB90, HiS89] </ref>. Another method to avoid processing the entire trace of references is to instead use several discrete samples of traces from the program execution to predict cache performance measures [LPI88].
Reference: [Wie82] <author> C. A. Wiecek, </author> <title> A Case Study of VAX-11 Instruction Set Usage for Compiler Execution, </title> <booktitle> Proceedings of the Symposium on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pp. </pages> <month> 177-184 (March, </month> <year> 1982). </year>
Reference-contexts: Two common methods used for generating trace data are forcing a program to trap after the execution of each instruction or to record references while simulating the execution of each instruction. Each of these methods can result in a program executing a 1000 times slower than normal execution <ref> [PeS77, Wie82, HLT87] </ref>. Trace data is typically stored in secondary storage and then later read by a cache simulator that will perform the analysis of the data. Realistic trace data, however, requires at least several million references which may make infeasible the use of disk as the storage media [BKW90].
References-found: 20

