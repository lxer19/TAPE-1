URL: http://www.cs.rice.edu/~willy/papers/ppopp97a.ps.gz
Refering-URL: http://www.cs.rice.edu/~willy/TreadMarks/papers.html
Root-URL: 
Email: willyg@cs.rice.edu  sandhya@cs.rochester.edu  
Title: Compiler and Software Distributed Shared Memory Support for Irregular Applications  
Author: Honghui Lu Alan L. Cox Sandhya Dwarkadas Ramakrishnan Rajamony and Willy Zwaenepoel zy 
Address: fhhl, alc, rrk,  Rochester  
Affiliation: Department of Electrical and Computer Engg Department of Computer Science Rice University  Department of Computer Science University of  
Abstract: We investigate the use of a software distributed shared memory (DSM) layer to support irregular computations on distributed memory machines. Software DSM supports irregular computation through demand fetching of data in response to memory access faults. With the addition of a very limited form of compiler support, namely the identification of the section of the indirection array accessed by each processor, many of these on-demand page fetches can be aggregated into a single message, and prefetched prior to the access fault. We have measured the performance of this approach for two irregular applications, moldyn and nbf, using the Tread-Marks DSM system on an 8-processor IBM SP2. We find that it has similar performance to the inspector-executor method supported by the CHAOS run-time library, while requiring much simpler compile-time support. For moldyn, it is up to 23% faster than CHAOS, depending on the input problem's characteristics; and for nbf, it is no worse than 14% slower. If we include the execution time of the inspector, the software DSM-based approach is always faster than CHAOS. The advantage of this approach increases as the frequency of changes to the indirection array increases. The disadvantage of this approach is the potential for false sharing overhead when the data set is small or has poor spatial locality. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> G. Agarwal and J. Saltz. </author> <title> Interprocedural compilation of irregular applications for distributed memory machines. </title> <booktitle> In Proceedings of Supercomputing '95, </booktitle> <month> December </month> <year> 1995. </year>
Reference-contexts: It has been argued that part or all of the above procedure can be automated by a compiler [21]. The compiler analysis involved can, however, be quite complicated <ref> [1, 6, 20] </ref>. In this paper we propose an alternative approach. We use a software distributed shared memory (DSM) layer that provides a shared memory interface on top of the message layer [13]. In its simplest form, the DSM layer supports irregular computations by demand-driven fetching of data. <p> This is usually a regular section [4]. In contrast, the inspector-executor approach requires complex analysis to determine whether the inspector loop can be hoisted out of the main loop <ref> [1, 20] </ref>. This paper presents our approach in detail. In order to gather experimental results, we use a modified version of TreadMarks [2] that supports prefetching and aggregation in the manner described above. Furthermore, we have augmented the Parascope parallel programming environment [12] to carry out the required compiler analysis.
Reference: [2] <author> C. Amza, A.L. Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu, and W. Zwaenepoel. </author> <title> Tread-Marks: Shared memory computing on networks of workstations. </title> <journal> IEEE Computer, </journal> <volume> 29(2) </volume> <pages> 18-28, </pages> <month> February </month> <year> 1996. </year>
Reference-contexts: In contrast, the inspector-executor approach requires complex analysis to determine whether the inspector loop can be hoisted out of the main loop [1, 20]. This paper presents our approach in detail. In order to gather experimental results, we use a modified version of TreadMarks <ref> [2] </ref> that supports prefetching and aggregation in the manner described above. Furthermore, we have augmented the Parascope parallel programming environment [12] to carry out the required compiler analysis. We present performance results for two irregular applications, moldyn and nbf. <p> Section 5 presents the results of our evaluation of the shared memory run-time support, and compares the results to those from CHAOS. Section 6 provides a summary of related work. Finally, we conclude in Section 7. 2 Background - TreadMarks TreadMarks <ref> [2] </ref> is a software DSM system built at Rice University. It is an efficient user-level DSM system that runs on commonly available Unix systems. We use TreadMarks version 1.0.1 as the base shared memory run-time system in our experiments. <p> A barrier stalls the calling processor until all processors in the system have arrived at the same barrier. Locks are used to control access to critical sections. No processor can acquire a lock if another processor is holding it. TreadMarks uses a lazy invalidate <ref> [2] </ref> version of release consistency (RC) [9] and a multiple-writer protocol [5] to reduce the overhead involved in implementing the shared memory abstraction. RC is a relaxed memory consistency model. <p> The merge is accomplished through the use of diffs. A diff is a run-length encoding of the modifications made to a page, generated by comparing the page to a copy saved prior to the modifications (called a twin). TreadMarks implements a lazy invalidate version of RC <ref> [2] </ref>. A lazy implementation delays the propagation of consistency information until the time of an acquire. Furthermore, the releaser notifies the acquirer of which pages have been modified, causing the acquirer to invalidate its local copies of these pages.
Reference: [3] <author> B.R. Brooks, R.E. Bruccoleri, B.D. Olafson, D.J. States, S. Swaminathan, and M. Karplus. Charmm: </author> <title> A program for macromolecular energy, minimization, and dynamics calculations. </title> <journal> Journal of Computational Chemistry, </journal> <volume> 4:187, </volume> <year> 1983. </year>
Reference-contexts: If no memory protection violation occurs for these pages, then the same set of pages are requested in the next iteration. Otherwise, the indirection array has been changed, and the set needs to be recomputed. 3.1 Example We first illustrate our approach with an example using the moldyn program <ref> [3] </ref> (see also Section 5). Figure 1 illustrates the program structure of moldyn, and the force computation subroutine in which the indirect accesses occur. Each molecule i has two attributes: its position, x (i), and the force, forces (i), acting on it. the force computation subroutine. <p> Tables 1 and 2 present the execution times, speedups, number of messages and the amount of data communicated at 8 processors for the two applications discussed in this paper. 5.1 Moldyn Moldyn is a molecular dynamics simulation. Its computational structure resembles the non-bonded force calculation in CHARMM <ref> [3] </ref>, which is a well-known molecular dynamics code used at NIH to model macromolecular systems. Nonbonded forces are long-range interactions existing between each pair of molecules. CHARMM approximates the nonbonded calculation by ignoring all pairs which are beyond a certain cutoff radius.
Reference: [4] <author> D. Callahan and K. Kennedy. </author> <title> Analysis of interprocedu-ral side effects in a parallel programming environment. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 5 </volume> <pages> 517-550, </pages> <year> 1988. </year>
Reference-contexts: The compiler support required for our approach is very simple: it suffices to determine the indirection array, and the part of the indirection array being accessed by each processor. This is usually a regular section <ref> [4] </ref>. In contrast, the inspector-executor approach requires complex analysis to determine whether the inspector loop can be hoisted out of the main loop [1, 20]. This paper presents our approach in detail. <p> This avoids the memory protection violation to create the twin. 3.3 Compiler Analysis The compiler support required for our approach involves determining the indirection array used to access shared data, and the part of the indirection array being accessed. This is usually a regular section <ref> [4] </ref>, and hence can be handled by the existing compiler framework for regular accesses. Our approach also naturally extends to multiple levels of the indirection in the access pattern without additional mechanisms. In contrast, the inspector-executor approach requires several inspector loops to be generated for such access patterns [6].
Reference: [5] <author> J.B. Carter, J.K. Bennett, and W. Zwaenepoel. </author> <title> Techniques for reducing consistency-related information in distributed shared memory systems. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 13(3) </volume> <pages> 205-243, </pages> <month> August </month> <year> 1995. </year>
Reference-contexts: Locks are used to control access to critical sections. No processor can acquire a lock if another processor is holding it. TreadMarks uses a lazy invalidate [2] version of release consistency (RC) [9] and a multiple-writer protocol <ref> [5] </ref> to reduce the overhead involved in implementing the shared memory abstraction. RC is a relaxed memory consistency model. In RC, ordinary shared memory accesses are distinguished from synchronization accesses, with the latter category divided into acquire and release accesses.
Reference: [6] <author> R. Das, P. Havlak, J. Saltz, and K. Kennedy. </author> <title> Index array flattening through program transformation. </title> <booktitle> In Proceedings of Supercomputing '95, </booktitle> <month> December </month> <year> 1995. </year>
Reference-contexts: It has been argued that part or all of the above procedure can be automated by a compiler [21]. The compiler analysis involved can, however, be quite complicated <ref> [1, 6, 20] </ref>. In this paper we propose an alternative approach. We use a software distributed shared memory (DSM) layer that provides a shared memory interface on top of the message layer [13]. In its simplest form, the DSM layer supports irregular computations by demand-driven fetching of data. <p> Our approach also naturally extends to multiple levels of the indirection in the access pattern without additional mechanisms. In contrast, the inspector-executor approach requires several inspector loops to be generated for such access patterns <ref> [6] </ref>. Furthermore, the inspector-executor approach also requires sophisticated compiler analysis to pull the inspector as far forward as possible in the program. We concentrate here on the additions to the analysis necessary for handling indirect accesses (see [8] for details on how regular accesses are handled).
Reference: [7] <author> R. Das, M. Uysal, J. Saltz, and Y.-S. Hwang. </author> <title> Communication optimizations for irregular scientific computations on distributed memory architectures. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 22(3) </volume> <pages> 462-479, </pages> <month> September </month> <year> 1994. </year>
Reference-contexts: We present performance results for two irregular applications, moldyn and nbf. The results were obtained on an 8-processor IBM SP2 using base TreadMarks and TreadMarks with aggregation support. We compare these results to measurements of hand-coded inspector-executor versions of the same applications that use the CHAOS run-time library <ref> [7] </ref>. We find that TreadMarks augmented with compiler support for communication aggregation in irregular programs has similar performance to the inspector-executor method supported by the CHAOS run-time library.
Reference: [8] <author> S. Dwarkadas, A.L. Cox, and W. Zwaenepoel. </author> <title> An integrated compile-time/run-time software distributed shared memory system. </title> <booktitle> In Proceedings of the 7th Symposium on Architectural Support for Programming Languages and Operating Systems, </booktitle> <month> October </month> <year> 1996. </year>
Reference-contexts: This can result in extra messages due to the fact that data is brought in at a page granularity, and additional run-time overheads in terms of page faults and interrupts in order to trigger the communication <ref> [8, 14] </ref>. This section describes the enhancements to the TreadMarks run-time system as well as the compiler analysis necessary in order to optimize performance for programs with irregular access patterns. Our approach involves a simple compiler front-end that identifies the indirection array (s) to the run-time system. <p> We concentrate here on the support for communication aggregation for irregular accesses. Support for regular accesses and other optimizations was described in earlier work <ref> [8] </ref>. <p> Furthermore, the inspector-executor approach also requires sophisticated compiler analysis to pull the inspector as far forward as possible in the program. We concentrate here on the additions to the analysis necessary for handling indirect accesses (see <ref> [8] </ref> for details on how regular accesses are handled). Let V be the set of shared variables, let S be the set of all synchronization operations in the program, and let F be the set of "possible fetch points", the locations in the program where a Validate may be inserted. <p> As indicated in our study, the compiler analysis necessary is relatively straightforward. Our study is also related to the many papers on prefetch-ing and aggregation. In particular, Mowry et al. [15] use a somewhat similar strategy to prefetch and aggregate disk requests for sequential programs, and Dwarkadas et al. <ref> [8] </ref> study prefetching and aggregation for regular applications in software distributed shared memory systems. 7 Conclusions We have described an integrated compile-time/run-time approach for executing irregular computations on distributed memory machines. This approach is based on a modified software distributed shared memory layer, and fairly simple compile-time support.
Reference: [9] <author> K. Gharachorloo, D. Lenoski, J. Laudon, P. Gibbons, A. Gupta, and J. Hennessy. </author> <title> Memory consistency and event ordering in scalable shared-memory multiprocessors. </title> <booktitle> In Proceedings of the 17th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 15-26, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: Locks are used to control access to critical sections. No processor can acquire a lock if another processor is holding it. TreadMarks uses a lazy invalidate [2] version of release consistency (RC) <ref> [9] </ref> and a multiple-writer protocol [5] to reduce the overhead involved in implementing the shared memory abstraction. RC is a relaxed memory consistency model. In RC, ordinary shared memory accesses are distinguished from synchronization accesses, with the latter category divided into acquire and release accesses.
Reference: [10] <author> W.F. van Gunsteren and H.J.C. Berendsen. GROMOS: </author> <title> GROningen MOlecular Simulation software. </title> <type> Technical report, </type> <institution> Laboratory of Physical Chemistry, University of Groningen, </institution> <year> 1988. </year>
Reference-contexts: As a result, the optimized TreadMarks program is 23% faster than CHAOS. 5.2 NBF NBF is the kernel of a molecular dynamics simulation. It is taken from the GROMOS benchmark <ref> [10] </ref>. It was previously used as an example to demonstrate compiler generated message passing programs [22]. Instead of keeping a list of pairs of interacting molecules like moldyn, nbf keeps a list of interacting partners for each molecule.
Reference: [11] <author> P. Havlak and K. Kennedy. </author> <title> An implementation of interprocedural bounded regular section analysis. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 2(3) </volume> <pages> 350-360, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: Access analysis generates a summary of shared data accesses associated with each element of F , and the type of such accesses. Our main tool is regular section analysis <ref> [11] </ref>. Regular section descriptors (RSDs) are used to concisely characterize the array accesses in a loop nest. RSDs represent the accessed data as linear expressions of the upper and lower loop bounds along each dimension, and include stride information.
Reference: [12] <author> K. Kennedy, K. S. McKinley, and C. Tseng. </author> <title> Analysis and transformation in an interactive parallel programming tool. </title> <journal> Concurrency: Practice and Experience, </journal> <volume> 5(7), </volume> <month> October </month> <year> 1993. </year>
Reference-contexts: This paper presents our approach in detail. In order to gather experimental results, we use a modified version of TreadMarks [2] that supports prefetching and aggregation in the manner described above. Furthermore, we have augmented the Parascope parallel programming environment <ref> [12] </ref> to carry out the required compiler analysis. We present performance results for two irregular applications, moldyn and nbf. The results were obtained on an 8-processor IBM SP2 using base TreadMarks and TreadMarks with aggregation support.
Reference: [13] <author> K. Li and P. Hudak. </author> <title> Memory coherence in shared virtual memory systems. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 7(4) </volume> <pages> 321-359, </pages> <month> November </month> <year> 1989. </year>
Reference-contexts: The compiler analysis involved can, however, be quite complicated [1, 6, 20]. In this paper we propose an alternative approach. We use a software distributed shared memory (DSM) layer that provides a shared memory interface on top of the message layer <ref> [13] </ref>. In its simplest form, the DSM layer supports irregular computations by demand-driven fetching of data.
Reference: [14] <author> H. Lu, S. Dwarkadas, A.L. Cox, and W. Zwaenepoel. </author> <title> Message passing versus distributed shared memory on networks of workstations. </title> <booktitle> In Proceedings SuperComputing '95, </booktitle> <month> December </month> <year> 1995. </year>
Reference-contexts: This can result in extra messages due to the fact that data is brought in at a page granularity, and additional run-time overheads in terms of page faults and interrupts in order to trigger the communication <ref> [8, 14] </ref>. This section describes the enhancements to the TreadMarks run-time system as well as the compiler analysis necessary in order to optimize performance for programs with irregular access patterns. Our approach involves a simple compiler front-end that identifies the indirection array (s) to the run-time system.
Reference: [15] <author> T.C. Mowry, A.K. Demke, and O. Krieger. </author> <title> Automatic compiler-inserted i/o prefetching for out-of-core applications. </title> <booktitle> In Proceedings of the Second USENIX Symposium on Operating System Design and Implementation, </booktitle> <pages> pages 3-17, </pages> <month> November </month> <year> 1996. </year>
Reference-contexts: Second, we use a compiler to optimize the shared memory programs, rather than relying on handcoded special-purpose protocols. As indicated in our study, the compiler analysis necessary is relatively straightforward. Our study is also related to the many papers on prefetch-ing and aggregation. In particular, Mowry et al. <ref> [15] </ref> use a somewhat similar strategy to prefetch and aggregate disk requests for sequential programs, and Dwarkadas et al. [8] study prefetching and aggregation for regular applications in software distributed shared memory systems. 7 Conclusions We have described an integrated compile-time/run-time approach for executing irregular computations on distributed memory machines.
Reference: [16] <author> S.S. Mukherjee, S.D. Sharma, M.D. Hill, J.R. Larus, A. Rogers, and J. Saltz. </author> <title> Efficient support for irregular applications on distributed memory machines. </title> <booktitle> In Proceedings of the 5th Symposium on the Principles and Practice of Parallel Programming, </booktitle> <month> July </month> <year> 1995. </year>
Reference-contexts: Mukher-jee et al. <ref> [16] </ref> compare the CHAOS inspector-executor system to the TSM (transparent shared memory) and the XSM (extendible shared memory) systems, both implemented on the Tempest interface [17]. Three applications are used: moldyn, unstructured, and DSMC, and the comparison is done on a 32-processor CM-5.
Reference: [17] <author> Steven K. Reinhardt, James R. Larus, and David A. Wood. Tempest and Typhoon: </author> <title> User-level shared memory. </title> <booktitle> In Proceedings of the 21th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 325-337, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: Mukher-jee et al. [16] compare the CHAOS inspector-executor system to the TSM (transparent shared memory) and the XSM (extendible shared memory) systems, both implemented on the Tempest interface <ref> [17] </ref>. Three applications are used: moldyn, unstructured, and DSMC, and the comparison is done on a 32-processor CM-5. They conclude that TSM is not competitive with CHAOS, while XSM achieves performance comparable to CHAOS after introducing several special-purpose protocols. Our study differs from the cited paper in several aspects.
Reference: [18] <author> J. Saltz, H. Berryman, and J. Wu. </author> <title> Multiprocessors and run-time compilation. </title> <journal> Concurrency:Practice and Experience, </journal> <volume> 3(6) </volume> <pages> 573-592, </pages> <month> December </month> <year> 1991. </year>
Reference-contexts: 1 Introduction Inspector-executor methods have been proposed as a way to efficiently execute irregular computations on distributed memory machines <ref> [18] </ref>. A separate loop, the inspector, precedes the actual computational loop (called the executor). The inspector loop determines the data read and written by the individual processors executing the computational loop.
Reference: [19] <author> S. Sharma, R. Ponnusamy, B. Moon, Y. Hwang, R. Das, and J. Saltz. </author> <title> Interprocedural compilation of irregular applications for distributed memory machines. </title> <booktitle> In Proceedings SuperComputing '95, </booktitle> <month> dec </month> <year> 1995. </year>
Reference-contexts: The handler for this memory protection violation sets a flag. During the next execution of Validate, if the flag is set, modified clears the flag and returns true, and Validate recomputes the set of pages that must be fetched. 4 CHAOS CHAOS <ref> [19] </ref> is a run-time library designed to handle irregular applications on distributed memory machines. There are three steps in solving irregular problems in CHAOS, namely, data and iteration partitioning, the inspector, and the executor.
Reference: [20] <author> R. von Hanxleden and K. Kennedy. </author> <title> Give-N-Take a balanced code placement framework. </title> <booktitle> In Proceedings of the ACM SIGPLAN 91 Conference on Programming Language Design and Implementation, </booktitle> <month> June </month> <year> 1994. </year>
Reference-contexts: It has been argued that part or all of the above procedure can be automated by a compiler [21]. The compiler analysis involved can, however, be quite complicated <ref> [1, 6, 20] </ref>. In this paper we propose an alternative approach. We use a software distributed shared memory (DSM) layer that provides a shared memory interface on top of the message layer [13]. In its simplest form, the DSM layer supports irregular computations by demand-driven fetching of data. <p> This is usually a regular section [4]. In contrast, the inspector-executor approach requires complex analysis to determine whether the inspector loop can be hoisted out of the main loop <ref> [1, 20] </ref>. This paper presents our approach in detail. In order to gather experimental results, we use a modified version of TreadMarks [2] that supports prefetching and aggregation in the manner described above. Furthermore, we have augmented the Parascope parallel programming environment [12] to carry out the required compiler analysis.
Reference: [21] <author> R. von Hanxleden, K. Kennedy, C. Koelbel, R. Das, and J. Saltz. </author> <title> Compiler analysis for irregular problems in Fortran D. </title> <booktitle> In Proceedings of the 5th Workshop on Languages and Compilers for Parallel Computing, </booktitle> <month> August </month> <year> 1992. </year>
Reference-contexts: In order to further reduce over head, an attempt is made to execute the inspector loop only once for a large number of iterations of the executor loop. It has been argued that part or all of the above procedure can be automated by a compiler <ref> [21] </ref>. The compiler analysis involved can, however, be quite complicated [1, 6, 20]. In this paper we propose an alternative approach. We use a software distributed shared memory (DSM) layer that provides a shared memory interface on top of the message layer [13].
Reference: [22] <author> Reinhard von Hanxleden. </author> <title> Handling irregular problems with Fortran D a preliminary report. </title> <booktitle> In Proceedings of the Fourth Workshop on Compilers for Parallel Computers, </booktitle> <month> December </month> <year> 1993. </year>
Reference-contexts: As a result, the optimized TreadMarks program is 23% faster than CHAOS. 5.2 NBF NBF is the kernel of a molecular dynamics simulation. It is taken from the GROMOS benchmark [10]. It was previously used as an example to demonstrate compiler generated message passing programs <ref> [22] </ref>. Instead of keeping a list of pairs of interacting molecules like moldyn, nbf keeps a list of interacting partners for each molecule. The lists of partners are concatenated together, with a per molecule list pointing to the end of each molecule's partners in the partner list.
References-found: 22

