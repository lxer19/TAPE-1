URL: ftp://ftp.cnl.salk.edu/pub/marni/cns95.ta.ps.gz
Refering-URL: http://www.cnl.salk.edu/cgi-bin/pub-search/
Root-URL: 
Email: marni@salk.edu, terry@salk.edu  
Title: UNSUPERVISED LEARNING OF INVARIANT REPRESENTATIONS OF FACES THROUGH TEMPORAL ASSOCIATION  
Author: Marian Stewart Bartlett Terrence J. Sejnowski 
Address: La Jolla, CA, 92037  
Affiliation: Departments of Cognitive Science and Psychology, UCSD Howard Hughes Medical Institute The Salk Institute,  
Note: In press: The Neurobiology of Computation: Proceedings of the Annual Compu--tational Neuroscience Meeting. J.M. Bower, ed. Kluwer Academic Publishers, Boston.  
Abstract: The appearance of an object or a face changes continuously as the observer moves through the environment or as a face changes expression or pose. Recognizing an object or a face despite these image changes is a challenging problem for computer vision systems, yet we perform the task quickly and easily. This simulation investigates the ability of an unsupervised learning mechanism to acquire representations that are tolerant to such changes in the image. The learning mechanism finds these representations by capturing temporal relationships between 2-D patterns. Previous models of temporal association learning have used idealized input representations. The input to this model consists of graylevel images of faces. A two-layer network learned face representations that incorporated changes of pose up to 30 ffi . A second network learned representations that were independent of facial expression. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Stryker, M. </author> <year> 1991. </year> <title> Temporal Associations. </title> <journal> Nature: </journal> <volume> 354(14) </volume> <pages> 108-109. </pages>
Reference-contexts: Unsupervised learning can find invariant representations by capitalizing on this dynamic information. Capturing the temporal relationships among patterns is a way to automatically associate different views of an object without requiring complex geometrical transformations or three dimensional structural descriptions <ref> [1] </ref>. Temporal association may be a fundamental component of visual processing in the temporal lobe. Cells in the anterior inferior temporal lobe will adjust their receptive fields so that they respond to temporally contiguous inputs [2].
Reference: 2. <author> Miyashita, Y. </author> <year> 1988. </year> <title> Neuronal correlate of visual associative long-term memory in the primate temporal cortex. </title> <journal> Nature: </journal> <volume> 335(27) </volume> <pages> 817-820. </pages>
Reference-contexts: Temporal association may be a fundamental component of visual processing in the temporal lobe. Cells in the anterior inferior temporal lobe will adjust their receptive fields so that they respond to temporally contiguous inputs <ref> [2] </ref>. A temporal window for Hebbian learning could be provided by the long open-time of the NMDA channel [3], a hysteresis in neural activity caused by reciprocal con-nections between cortical regions [4], or the release of a chemical signal following activity such as nitric oxide [5].
Reference: 3. <author> Rhodes, P. </author> <year> 1992. </year> <title> The long open time of the NMDA channel facilitates the self-organization of invariant object responses in cortex. </title> <journal> Society for Neuroscience Abstracts 18:740. </journal>
Reference-contexts: Cells in the anterior inferior temporal lobe will adjust their receptive fields so that they respond to temporally contiguous inputs [2]. A temporal window for Hebbian learning could be provided by the long open-time of the NMDA channel <ref> [3] </ref>, a hysteresis in neural activity caused by reciprocal con-nections between cortical regions [4], or the release of a chemical signal following activity such as nitric oxide [5]. This simulation investigates the capability of such Hebbian learning mechanisms to acquire transformation invariant representations of complex objects such as faces.
Reference: 4. <author> O'Reilly, R. & Johnson, M. </author> <year> 1994. </year> <title> Object recognition and sensitive periods: A computational analysis of visual imprinting. </title> <booktitle> Neural Computation 6 </booktitle> <pages> 357-389. </pages>
Reference-contexts: A temporal window for Hebbian learning could be provided by the long open-time of the NMDA channel [3], a hysteresis in neural activity caused by reciprocal con-nections between cortical regions <ref> [4] </ref>, or the release of a chemical signal following activity such as nitric oxide [5]. This simulation investigates the capability of such Hebbian learning mechanisms to acquire transformation invariant representations of complex objects such as faces. <p> This simulation investigates the capability of such Hebbian learning mechanisms to acquire transformation invariant representations of complex objects such as faces. These mechanisms have been previously tested with idealized input representations with little or no crosstalk on the connections <ref> [6, 7, 4] </ref>. In order to understand the capabilities of temporal association learning, it is important to evaluate it using complex, realistic stimuli. Network Architecture We tested the temporal association learning mechanism on a very simple architecture (Figure 1). We used a feed-forward network with two layers of units.
Reference: 5. <author> Montague, R., Gally, J., & Edelman, G., </author> <year> 1991. </year> <title> Spatial signaling in the development and function of neural connections. </title> <journal> Cerebral Cortex: </journal> <volume> 1 </volume> <pages> 199-220. </pages>
Reference-contexts: A temporal window for Hebbian learning could be provided by the long open-time of the NMDA channel [3], a hysteresis in neural activity caused by reciprocal con-nections between cortical regions [4], or the release of a chemical signal following activity such as nitric oxide <ref> [5] </ref>. This simulation investigates the capability of such Hebbian learning mechanisms to acquire transformation invariant representations of complex objects such as faces. These mechanisms have been previously tested with idealized input representations with little or no crosstalk on the connections [6, 7, 4].
Reference: 6. <author> Foldiak, P. </author> <year> 1991. </year> <title> Learning invariance from transformation sequences. </title> <journal> Neural Computation: </journal> <volume> 3 </volume> <pages> 194-200. </pages>
Reference-contexts: This simulation investigates the capability of such Hebbian learning mechanisms to acquire transformation invariant representations of complex objects such as faces. These mechanisms have been previously tested with idealized input representations with little or no crosstalk on the connections <ref> [6, 7, 4] </ref>. In order to understand the capabilities of temporal association learning, it is important to evaluate it using complex, realistic stimuli. Network Architecture We tested the temporal association learning mechanism on a very simple architecture (Figure 1). We used a feed-forward network with two layers of units. <p> Let y j be the activation of output j, computed by a weighted sum of the inputs. After Foldiak <ref> [6] </ref>, the winning unit i at time t is determined by the trace of the activation: 1 winner = max j [y t j ] j = (1 )y t1 The Competitive Learning Rule alone, without the temporal manipulation, will partition the set of inputs into roughly equal groups by spatial
Reference: 7. <author> Weinshall, D., Edelman, S., & Bulthoff, H. </author> <title> A self-organizing multiple view representation of 3D objects in Advances in Neural Information Processing Systems No. 2, </title> <editor> D. Touretzky, ed. </editor> <address> Cambridge MA: </address> <publisher> MIT Press, </publisher> <year> 1990: </year> <pages> 274-281. </pages>
Reference-contexts: This simulation investigates the capability of such Hebbian learning mechanisms to acquire transformation invariant representations of complex objects such as faces. These mechanisms have been previously tested with idealized input representations with little or no crosstalk on the connections <ref> [6, 7, 4] </ref>. In order to understand the capabilities of temporal association learning, it is important to evaluate it using complex, realistic stimuli. Network Architecture We tested the temporal association learning mechanism on a very simple architecture (Figure 1). We used a feed-forward network with two layers of units. <p> Figure 3a compares invariance to pose 1 Representation units that failed to win for two iterations were given a competitive advantage by increasing slightly the value of y t j . This adjustment is equivalent to enlarging the receptive field of that unit <ref> [7] </ref>. after temporal association learning (dashed line) to baseline performance (solid line), in which the network was trained on the frontal views only. Mean correct classification at each pose is shown, collapsed over the ten subjects in the data set.
Reference: 8. <author> Rumelhart, D. & Zipser, D. </author> <year> 1985. </year> <title> Feature discovery by competitive learning. </title> <journal> Cognitive Science: </journal> <volume> 9 </volume> <pages> 75-112. </pages>
Reference-contexts: At each time step t, the network took one 20 x 20 graylevel image as input. Temporal Association Learning The weight update rule is based on the Competitive Learning Rule <ref> [8, 9] </ref>. Let ff be the learning rate, x ik be the value of input unit i for pattern k, and t k be the total amount of input activation for pattern k. <p> The resulting weights to each output unit are proportional to the probability that a given input unit is active when that unit wins <ref> [8] </ref>. The temporal manipulation allows temporal association to influence these partitions. The winning unit in the current time step has a competitive advantage for recruiting the pattern in the next time step.
Reference: 9. <author> Grossberg, S. </author> <year> 1976. </year> <title> Adaptive pattern classification and universal recoding: Part 1. Parallel development and coding of neural feature detectors. </title> <journal> Biological Cybernetics: </journal> <volume> 23 </volume> <pages> 121-134. </pages>
Reference-contexts: At each time step t, the network took one 20 x 20 graylevel image as input. Temporal Association Learning The weight update rule is based on the Competitive Learning Rule <ref> [8, 9] </ref>. Let ff be the learning rate, x ik be the value of input unit i for pattern k, and t k be the total amount of input activation for pattern k.
Reference: 10. <author> Beymer, D. </author> <title> Face recognition under varying pose. </title> <booktitle> In Proceedings of the 1994 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. </booktitle> <address> Los Alamitos, CA: </address> <publisher> IEEE Comput. Soc. Press, </publisher> <year> 1994: </year> <pages> 756-61. </pages>
Reference-contexts: Simulation 1: Learning Invariance to Changes in Pose We first tested the ability of this learning algorithm to develop representations of faces that were independent of pose. The inputs were graylevel face images provided by David Beymer at the MIT Media Lab <ref> [10] </ref>. We used images of ten individuals at each of five different angles of view (0 ffi ,15 ffi , and 30 ffi ), for a total of fifty stimuli (Figure 2).
Reference: 11. <author> Field, D. </author> <year> 1994. </year> <title> What is the goal of sensory coding? Neural Computation: </title> <booktitle> 6(4) </booktitle> <pages> 559-601. </pages>
Reference-contexts: Interpolation and Extrapolation. redundancy in the input, then there is no limit to the amount of invariance that this system can learn. This points to the importance of intermediate representations with reduced input redundancy, such as principal components or sparse distributed representations <ref> [11] </ref>. Larger invariances can also be obtained in a hierarchical system that learns new invariances at each level of the hierarchy. Acknowledgments This research was supported by Lawrence Livermore National Laboratory, Intra-University Agreement B291436, and Howard Hughes Medical Institute.
References-found: 11

