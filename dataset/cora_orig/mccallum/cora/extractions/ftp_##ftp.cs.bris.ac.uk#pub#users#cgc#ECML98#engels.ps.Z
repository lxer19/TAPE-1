URL: ftp://ftp.cs.bris.ac.uk/pub/users/cgc/ECML98/engels.ps.Z
Refering-URL: http://www.cs.bris.ac.uk/~cgc/ECML98-WS/Summary.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: Email: fengels, chthg@aifb.uni-karlsruhe.de  
Title: Support for data transformation in machine learning applications  
Author: Robert Engels and Christiane Theusinger 
Note: (UGM) for user support.  
Address: D-76128, Karlsruhe, Germany  
Affiliation: Institute AIFB, University of Karlsruhe  
Abstract: This paper describes research that is performed in the course of a project where a methodology for providing user support plays a central role. Although methodologically we aim at supporting the whole process of applying inductive learning techniques, the current paper focussus on support of the data preprocessing phase and getting insight in the data. One of our experiences is that preprocessing of data possibly is the most time consuming part of machine learning applications. We will rudimentary describe the metadata we calculate from a dataset as part of the method for user support and focus on how metadata can be used to guide preprocessing in combination with a top down approach. Some examples are given that resulted from running the UGM/DCT (User Guidance Module/ Data Characterisation Tool) on example data. Finally we consider the improvements we made w.r.t. other approaches as well as what we gained using this extension to our User Guidance Module 
Abstract-found: 1
Intro-found: 1
Reference: [BCK95] <author> I. Bratko, B. Cestnik, and I. Kononenko. </author> <title> Attribute based learning. </title> <booktitle> MLnet Newsletter, </booktitle> <month> September </month> <year> 1995. </year>
Reference-contexts: For example, algorithms that are based on greedy search heuristics such as information gain, gain ratio, Gini Index and distance measures pose this restriction on data <ref> [BCK95] </ref>. The knowledge about correlated attributes is used in accordance to the eventual selection of a specific algorithm.
Reference: [Con93] <author> MLT Consortium. </author> <title> Final public report. </title> <type> Technical report, </type> <year> 1993. </year> <title> Esprit II Project 2154. </title>
Reference-contexts: Such an approach can also be found in statistics, as described in [Han94b] and [Han94a] and projects 43 like the StatLOG project [MST94] or the MLT-approach <ref> [Con93] </ref> where the CONSUL--TANT [CSG + 92] played an advisory role. A very important contribution of that research is that it notifies the importance for a support in defining application processes where statistical and inductive techniques are involved. <p> Beginning with ideas from the knowledge acquisition field and statistical principles and guided by projects as MLT <ref> [Con93] </ref> and StatLOG [MST94] we finally came up with a framework for User Guidance Modelling ([Eng96], [ELS97b]) that recollects a top down (problem definition etc.) and bottom up (data characteristics) process.
Reference: [CSG + 92] <author> S. Craw, D. Sleeman, N. Granger, M. Rissakis, and S. Sharma. </author> <title> Consultant: Providing advice for the machine learning toolbox. In M.A. </title> <editor> Bramer and R.W. Milne, editors, </editor> <booktitle> Research and Development in Expert Systems, </booktitle> <pages> pages 5-23, </pages> <year> 1992. </year>
Reference-contexts: Such an approach can also be found in statistics, as described in [Han94b] and [Han94a] and projects 43 like the StatLOG project [MST94] or the MLT-approach [Con93] where the CONSUL--TANT <ref> [CSG + 92] </ref> played an advisory role. A very important contribution of that research is that it notifies the importance for a support in defining application processes where statistical and inductive techniques are involved.
Reference: [EEHV97] <author> R. Engels, B. Evans, J. Herrmann, and F. Verdenius, </author> <title> editors. Workshop on Machine Learning Application in the real world; Methodological Aspects and Implications (at the ICML-97), Nashville, </title> <booktitle> TN, July 12th, 1997. at: 14th International Conference on Machine Learning. </booktitle>
Reference-contexts: The more such applications were discussed the more it became clear that applying inductive algorithms is not as trivial as it sometimes might look. The setting in which algorithms are immediately tested on (clean) datasets clearly is too academic and not realistic in real world applications (see e.g. <ref> [EEHV97] </ref>, [Ver97]). Several experiences show that up to three quarters of the time might be used for transforming the data at hand in a format appropriate for learning and that this process has significant influence on the final generated models ([PSBK + 96]).
Reference: [ELS97a] <author> R. Engels, G. Lindner, and R. </author> <title> Studer. </title> <editor> Benutzerunterstutzung fur wissensent-deckung in datanbanken. In Ch. Nakhaeizadeh, editor, </editor> <title> Data Mining: Theo-retische Aspekte und Anwendungen. </title> <publisher> Springer Verlag, </publisher> <year> 1997. </year>
Reference-contexts: We will provide some short examples that illustrate the kind of insights one can gather, after which we discuss possible further implications of our UGM/DCT approach. 2 User support; the UGM Although the UGM approach to user guidance is described in previous papers ([Eng96], [ELS97b] and <ref> [ELS97a] </ref>), we will shortly repeat the main ideas in order to put the following discussion in the right context.
Reference: [ELS97b] <author> R. Engels, G. Lindner, and R. Studer. </author> <title> A guided tour through the data mining jungle. </title> <editor> In D.Pregibon D. Heckerman, H.Manilla, editor, </editor> <booktitle> Proceedings of the 3rd International Conference on Knowledge Discovery and Data Mining, </booktitle> <address> Newport Beach, CA, August 14 -17, 1997. </address> <publisher> AAAI Press, </publisher> <address> Menlo Park, CA. </address>
Reference-contexts: What became clear to us is that selection of a group of applicable algorithms, as we do in a top down manner in our UGM approach (User Guidance Module <ref> [ELS97b] </ref>), forms an important first step after having analysed the problem and data that are available. <p> But at the same time we noticed that selecting a final appropriate algorithm for the problem at hand depends more on the effort one wants to put in preprocessing the data more than anything else. In our approach to user support ([Eng96], <ref> [ELS97b] </ref>, [ES96]) we describe how we aim at helping a user define a KDD-process. We provide user support in a two-way process as described in [ELS97b], where problem analysis and task decomposition is performed top-down in combination with a bottom-up selection of suitable Reusable Process Units (RPU's) or techniques (being inductive <p> In our approach to user support ([Eng96], <ref> [ELS97b] </ref>, [ES96]) we describe how we aim at helping a user define a KDD-process. We provide user support in a two-way process as described in [ELS97b], where problem analysis and task decomposition is performed top-down in combination with a bottom-up selection of suitable Reusable Process Units (RPU's) or techniques (being inductive or inference based) that can perform a certain task. <p> We will provide some short examples that illustrate the kind of insights one can gather, after which we discuss possible further implications of our UGM/DCT approach. 2 User support; the UGM Although the UGM approach to user guidance is described in previous papers ([Eng96], <ref> [ELS97b] </ref> and [ELS97a]), we will shortly repeat the main ideas in order to put the following discussion in the right context. <p> These nets often provide the possibility to measure importance of inputvectors w.r.t. their influence (measured through their weights) on the classification. 6 Conclusions The work described in this paper proposes a way to support user guidance as described in ([Eng96], <ref> [ELS97b] </ref>). Beginning with ideas from the knowledge acquisition field and statistical principles and guided by projects as MLT [Con93] and StatLOG [MST94] we finally came up with a framework for User Guidance Modelling ([Eng96], [ELS97b]) that recollects a top down (problem definition etc.) and bottom up (data characteristics) process. <p> work described in this paper proposes a way to support user guidance as described in ([Eng96], <ref> [ELS97b] </ref>). Beginning with ideas from the knowledge acquisition field and statistical principles and guided by projects as MLT [Con93] and StatLOG [MST94] we finally came up with a framework for User Guidance Modelling ([Eng96], [ELS97b]) that recollects a top down (problem definition etc.) and bottom up (data characteristics) process. <p> For the UGM framework described in ([Eng96], <ref> [ELS97b] </ref>) this also means that we will use DCT as supporting tool for instantiation of repository components that are selected for reuse and parameter initialisation. Other research at our institute aims at using DCT for algorithm selection and will be integrated in the UGM framework.
Reference: [Eng96] <author> R. Engels. </author> <title> Planning tasks for knowledge discovery in databases; performing task-oriented user-guidance. </title> <editor> In E. Simounis, J. Han, and U. Fayyad, editors, </editor> <booktitle> Proceedings of the 2nd Int. Conference on Knowledge Discovery and Data Mining, </booktitle> <pages> pages 170-175, </pages> <address> Portland, Oregon, </address> <month> August 2-4, </month> <year> 1996. </year> <month> AAAI-Press. </month>
Reference: [ES96] <author> R. Engels and R. Studer. </author> <title> User guidance for clementine; towards implementation of a user guidance module. </title> <type> Technical report, </type> <institution> Angewandte Informatik und Formale Beschreibungsverfahren (AIFB), </institution> <address> Englerstr. 11 D-76128 Karl-sruhe, Germany., </address> <year> 1996. </year>
Reference-contexts: But at the same time we noticed that selecting a final appropriate algorithm for the problem at hand depends more on the effort one wants to put in preprocessing the data more than anything else. In our approach to user support ([Eng96], [ELS97b], <ref> [ES96] </ref>) we describe how we aim at helping a user define a KDD-process.
Reference: [Fis36] <author> R. A. Fisher. </author> <title> The use of multiple measurements in taxonomic problems. </title> <journal> Annals of Eugenics, </journal> <volume> 7:179 - 188, </volume> <year> 1936. </year>
Reference-contexts: The aim is to get insight in the complexity that might be involved in a certain classification task. An appropriate technique for prediction of complexity of a domain and relevance of dependent variables is discriminant analysis (see e.g. <ref> [Fis36] </ref> or [Kle80]). Where approaches like PCA aim at estimating the number of attributes that are minimally needed for description of the data, the discriminant analysis approach describes the minimal number of significant discriminant functions needed to divide the dataspace w.r.t. the classification problem.
Reference: [Han94a] <author> D.J. </author> <title> Hand. Deconstructing statistical questions. </title> <journal> Journal of the Royal Statistical Society, </journal> <pages> pages 317-356, </pages> <year> 1994. </year>
Reference-contexts: Such an approach can also be found in statistics, as described in [Han94b] and <ref> [Han94a] </ref> and projects 43 like the StatLOG project [MST94] or the MLT-approach [Con93] where the CONSUL--TANT [CSG + 92] played an advisory role. A very important contribution of that research is that it notifies the importance for a support in defining application processes where statistical and inductive techniques are involved.
Reference: [Han94b] <author> D.J. </author> <title> Hand. Statistical strategy: step 1. </title> <editor> In P. Cheeseman and R. W. Oldford, editors, </editor> <title> Selecting Models from Data: </title> <journal> Artificial Intelligence and Statistics IV, </journal> <volume> volume 89, </volume> <pages> pages 3-9. </pages> <booktitle> Lecture Notes in Statistics, </booktitle> <publisher> Springer Verlag, </publisher> <address> Berlin, </address> <year> 1994. </year>
Reference-contexts: Such an approach can also be found in statistics, as described in <ref> [Han94b] </ref> and [Han94a] and projects 43 like the StatLOG project [MST94] or the MLT-approach [Con93] where the CONSUL--TANT [CSG + 92] played an advisory role.
Reference: [HW97] <author> N. Henze and Th. Wagner. </author> <title> A new approach to the bhep tests for multivariate normality. </title> <journal> Journal of Multivariate Analysis, </journal> <volume> 62(1), </volume> <year> 1997. </year>
Reference-contexts: measures based on statistical theory given in figure 1 are calculated and include: Standard statistics (the number of examples, classes (if known), distribution among those classes, the dimensionality of the data and the datatypes that the several dimensions are represented in) Multiple correlation coefficients. - BHEP-statistic with its critical value <ref> [HW97] </ref> as test on multivariate normal distribution. - Boxian M-statistic for testing the hypothesis that all classes have equal covariance structure. - Eigenvalues of W 1 B and their significance. - Wilks fl which gives an interpretation of possible disctinction between groups. <p> Data transformations can bring solutions within reach or just further away. Two main tasks concerning preprocessing are currently supported by DCT: * Defining which kind of sampling or balancing of the dataset makes sense, this includes providing parameter settings for the proposed techniques. 2 See <ref> [HW97] </ref> for a thorough description of the BHEP-test. 48 Dataset C4.5 OC1 N.
Reference: [Kle80] <author> W.R. Klecka. </author> <title> Discriminant analysis. </title> <booktitle> Sage University Paper Series on Quan-titive Applications in the Social Sciences, </booktitle> <pages> 07-019, </pages> <year> 1980. </year> <title> Beverly Hills and London: </title> <journal> Sage Pubns. </journal> <volume> 52 </volume>
Reference-contexts: The aim is to get insight in the complexity that might be involved in a certain classification task. An appropriate technique for prediction of complexity of a domain and relevance of dependent variables is discriminant analysis (see e.g. [Fis36] or <ref> [Kle80] </ref>). Where approaches like PCA aim at estimating the number of attributes that are minimally needed for description of the data, the discriminant analysis approach describes the minimal number of significant discriminant functions needed to divide the dataspace w.r.t. the classification problem.
Reference: [MST94] <editor> D. Michie, D.J. Spiegelhalter, and C.C. Taylor. </editor> <title> Machine Learning, Neural and Statistical Classification. </title> <publisher> Ellis Horwood, </publisher> <year> 1994. </year>
Reference-contexts: Such an approach can also be found in statistics, as described in [Han94b] and [Han94a] and projects 43 like the StatLOG project <ref> [MST94] </ref> or the MLT-approach [Con93] where the CONSUL--TANT [CSG + 92] played an advisory role. A very important contribution of that research is that it notifies the importance for a support in defining application processes where statistical and inductive techniques are involved. <p> Beginning with ideas from the knowledge acquisition field and statistical principles and guided by projects as MLT [Con93] and StatLOG <ref> [MST94] </ref> we finally came up with a framework for User Guidance Modelling ([Eng96], [ELS97b]) that recollects a top down (problem definition etc.) and bottom up (data characteristics) process.
Reference: [Mui82] <author> R.J. Muirhead. </author> <title> Aspects of Multivariate Statistical Theory. </title> <editor> J. </editor> <publisher> Wiley and Sons, </publisher> <address> New York, </address> <year> 1982. </year>
Reference-contexts: They are in principle calculated as part of the dependency scheme of figure 1. This is backed up by a multiple correlation coefficient approach <ref> [Mui82] </ref>. Dependencies among discrete variables is calculated using association rule approaches that are limited to learn rules of the form: X ) Y Such rules provide a convenient insight in correlations among discrete variable.
Reference: [PSBK + 96] <author> G. Piatetsky-Shapiro, R. Brachman, T. Khabaza, W. Kloesgen, and E. Simoudis. </author> <title> An overview of issues in developing industrial data mining and knowledge discovery applications. </title> <editor> In E. Simoudis, J. Han, and U. Fayyad, editors, </editor> <booktitle> Proceedings of the 2nd Int. Conference on Knowledge Discovery in Databases, </booktitle> <pages> pages 89-95, </pages> <address> Portland, Oregon, 1996. </address> <publisher> AAAI press. </publisher>
Reference: [Ver97] <author> F. Verdenius. </author> <title> Applications of inductive learning techniques: A survey in the netherlands. </title> <journal> AI communications, </journal> <volume> 10(1), </volume> <year> 1997. </year> <month> 53 </month>
Reference-contexts: The more such applications were discussed the more it became clear that applying inductive algorithms is not as trivial as it sometimes might look. The setting in which algorithms are immediately tested on (clean) datasets clearly is too academic and not realistic in real world applications (see e.g. [EEHV97], <ref> [Ver97] </ref>). Several experiences show that up to three quarters of the time might be used for transforming the data at hand in a format appropriate for learning and that this process has significant influence on the final generated models ([PSBK + 96]).
References-found: 17

