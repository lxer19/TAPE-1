URL: http://www.sls.lcs.mit.edu/nikko/publications/asru97/asru97.ps
Refering-URL: http://www.sls.lcs.mit.edu/nikko/publications/index.html
Root-URL: 
Title: A Tonotopic Artificial Neural Network Architecture For Phoneme Probability Estimation  
Author: Nikko Strm 
Address: Stockholm, Sweden  
Affiliation: Department of Speech, Music and Hearing, Centre for Speech Technology, KTH (Royal Institute of Technology),  
Abstract: A novel sparse ANN connection scheme is proposed. It is inspired by the so called tonotopic organization of the auditory nerve, and allows a more detailed representation of the speech spectrum to be input to an ANN than is commonly used. A consequence of the new connection scheme is that more resources are allocated to analysis within narrow frequency sub-bands a concept that has recently been investigated by others with so called sub-band ASR. ANNs with the proposed architecture have been evaluated on the TIMIT database for phoneme recognition, and are found to give better phoneme recognition performance than ANNs based on standard mel frequency cepstrum input. The lowest achieved phone error-rate, 26.7%, is very close to the lowest published result for the core test set of the TIMIT database. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Bourlard & Wellekens (1988): </author> <title> Links between Markov Models and Multilayer Perceptrons, </title> <journal> IEEE Trans. on PAMI , 12 (12), </journal> <pages> pp. 1167-1178. </pages>
Reference-contexts: 1. Introduction In the most widespread type of hybrid HMM/ANN ASR systems, an artificial neural network (ANN) is utilized to compute the observation likelihoods of a hidden Markov model, (e.g., <ref> [ 1 ] </ref>). The input to the ANN is normally a standard speech feature vector, e.g., the mel frequency cepstrum coefficients. After a training process, the output units approximate a posteriori probabilities for phonemes given the input feature vector.
Reference: [2] <author> Strm N. </author> <year> (1997): </year> <title> Sparse Connection and Pruning in Large Dynamic Artificial Neural Networks, </title> <booktitle> Proc. </booktitle> <pages> EUROSPEECH 97 . pp. 2807-2810. </pages>
Reference: [3] <author> Strm N. </author> <year> (1997): </year> <title> Phoneme Probability Estimation with Dynamic Sparsely Connected Artificial Neural Networks, </title> <note> The Free Speech Journal , Vol 1, Issue #5. </note>
Reference-contexts: Recently, it has been shown that sparsely connected ANN architectures can be used to promote the training of networks with a large number of hidden units. The results of <ref> [ 2 , 3 ] </ref> indicate that increasing the number of hidden units is more important for the networks performance than to fully connect between the layers. In this paper we turn to the input units. <p> Except for the tonotopic connection scheme between input units and hidden units, the ANN architecture is the same as in [ 2,3]. The temporal features of the speech are modeled by timedelayed connections. This is described in detail in <ref> [3] </ref> and can only be briefly summarized here. Higher layers have access to the activities within a timedelay window of units in lower layers. <p> Except for the new tonotopic connection scheme, the training and testing conditions are identical to that of [2,3], and a more detailed description can be found in <ref> [3] </ref>. Three ANNs with tonotopic connection, and different hidden layer sizes were trained and evaluated. Only the number of hidden units was varied, and the fixed connectivity parameters were: s input = 15, s recurrent = 25, and f output = 0.10.
Reference: [4] <author> Kiang N. Y-S, Watanabe T., Thomas E. C., and Clarke L. F. </author> <year> (1965): </year> <title> Discharge Patterns of Single Fibers in the Cats Auditory Nerve , MIT Press, </title> <address> Cambridge, Mass. </address>
Reference-contexts: Although ANNs are very different from biological neural systems, human perception can be an important source of inspiration for innovations in ANN technology. It has been found that in the auditory nerve, neurones are organized in an orderly manner depending on their characteristic frequency <ref> [ 4 ] </ref>. Neurones responding to high frequencies are located in the periphery of the nerve, and those responding to low frequencies are found in the center (see Figure 1). This structure of the auditory nerve is called tonotopic organization.
Reference: [5] <author> Lee K-F & Hon H-W (1989): </author> <title> Speaker-independent Phone Recognition using Hidden Markov Models, </title> <booktitle> IEEE Trans. On Acoustics, Speech, and Signal Processing , 37 (11), </booktitle> <pages> pp. 1641-1648. </pages>
Reference-contexts: All training utterances, except the so called sa-sentences, were used for training, and the official core test set was used for evaluation. In the phone error evaluation, the 61 symbols of the database were collapsed into the 39 phoneme set defined in <ref> [ 5 ] </ref> that have evolved into an unofficial standard for phoneme recognition experiments. Except for the new tonotopic connection scheme, the training and testing conditions are identical to that of [2,3], and a more detailed description can be found in [3].
Reference: [6] <author> Robinson A.J. </author> <year> (1994): </year> <title> An application of Recurrent Nets to Phone Probability Estimation, </title> <journal> IEEE Trans. On Neural Networks , 5 (2), </journal> <pages> pp. 298 305. </pages>
Reference-contexts: The lowest phone error-rate of this study, 26.7%, is very close to the (to our knowledge) lowest published rate, 26.1%, reached by another ANN based system <ref> [ 6 ] </ref>.
Reference: [7] <author> Chang J. & Glass J. </author> <year> (1997): </year> <title> Segmentation and Modeling in Segment based Recognition, </title> <booktitle> Proc. </booktitle> <pages> EUROSPEECH 97 , pp. 1199-1202. </pages>
Reference-contexts: The lowest phone error-rate of this study, 26.7%, is very close to the (to our knowledge) lowest published rate, 26.1%, reached by another ANN based system [ 6 ]. Results reported for other methods are slightly higher, e.g., 26.6% <ref> [ 7 ] </ref> using a segment based approach and 27.7% [ 8 ] with a CDHHM recognizer (the latter was achieved for the full test set a slightly easier task). 1000 100000 15% 20% 25% 30% 35% 40% Phone error-rate N m e f c o n c t i o
Reference: [8] <author> Young S. J. & Woodland P. C. </author> <year> (1994): </year> <title> State clustering in hidden Markov model-based continuous speech recognition , Computer Speech and Language 8 (4), </title> <journal> pp. </journal> <pages> 369-383. </pages>
Reference-contexts: The lowest phone error-rate of this study, 26.7%, is very close to the (to our knowledge) lowest published rate, 26.1%, reached by another ANN based system [ 6 ]. Results reported for other methods are slightly higher, e.g., 26.6% [ 7 ] using a segment based approach and 27.7% <ref> [ 8 ] </ref> with a CDHHM recognizer (the latter was achieved for the full test set a slightly easier task). 1000 100000 15% 20% 25% 30% 35% 40% Phone error-rate N m e f c o n c t i o s core test set train set 700 300 500 each
Reference: [9] <author> Bourlard H. and Dupont S. </author> <year> (1996): </year> <title> A new ASR approach based on independent processing and recombination of partial frequency bands, </title> <booktitle> Proc. </booktitle> <pages> ICSLP 96 , pp. 426429. </pages>
Reference: [10] <author> Hermansky H., Tibrewala S. and Pavel M. </author> <year> (1996): </year> <title> Towards ASR on partially corrupted speech, </title> <booktitle> Proc. </booktitle> <pages> ICSLP 96 , pp. 462465. </pages>
Reference-contexts: Evidence from the different frequency bands in the hidden units are then combined in the output layer where the phoneme probabilities are formed. Recently, a method that processes sub-bands individually, and recombines the recognition based on the sub-bands at a higher level of the recognizer, have been proposed <ref> [ 9 , 10 ] </ref>. The method has similarities with our approach, but sub-band recognition has not so far been used with the high resolution of the input representation that is utilized in the tonotopic ANN.
References-found: 10

