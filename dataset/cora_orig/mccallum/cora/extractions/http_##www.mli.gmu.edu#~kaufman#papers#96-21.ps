URL: http://www.mli.gmu.edu/~kaufman/papers/96-21.ps
Refering-URL: http://www.mli.gmu.edu/kpubs.html
Root-URL: 
Email: -kaufman, michalsk-@aic.gmu.edu  
Title: A Method for Reasoning with Structured and Continuous Attributes in the INLEN-2 Multistrategy Knowledge Discovery
Author: Kenneth A. Kaufman and Ryszard S. Michalski* George Mason 
Address: Fairfax, Virginia, 22030, USA  
Affiliation: University,  Also GMU Departments of Computer Science and Systems Engineering and the Institute of Computer Science, Polish Academy of Sciences  
Note: Proceedings of the Second International Conference on Knowledge Discovery and Data Mining (KDD-96), Portland OR, August 2-4, 1996, pp. 232-237  
Abstract: Structured attributes have domains (value sets) that are partially ordered sets, typically hierarchies. Such attributes allow knowledge discovery programs t o incorporate background knowledge about hierarchical relationships among attribute values. Inductive generalization rules for structured attributes have been developed that take into consideration the type of nodes in the domain hierarchy (anchor or non-anchor) and the type of decision rules to be generated (characteristic, discriminant or minimum complexity). These generalization rules enhance the ability of knowledge discovery system INLEN-2 to exploit the semantic content of the domain knowledge in the process of generating hypotheses. If the dependent attribute (e.g., a decision attribute) is structured, the system generates a system of hierarchically organized rules representing relationships between the values of this attribute and independent attributes. Such a situation often occurs i n practice when the decision to be assigned to a situation can be at different levels of abstraction (e.g., this is a liver disease, or this is a liver cancer). Continuous attributes (e.g., physical measurements) are quantized into a hierarchy of values (ranges of values arranged into different levels). These methods are illustrated by an example concerning the discovery of patterns in world economics and demographics. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Fisher, D. </author> <year> 1987. </year> <title> Knowledge Acquisition via Incremental Conceptual Clustering. </title> <journal> Machine Learning, </journal> <volume> 2 </volume> <pages> 139-172. </pages>
Reference: <author> Fisher, D. </author> <year> 1995. </year> <title> Optimization and Simplification of Hierarchical Clusterings. </title> <booktitle> Proceedings of the First International Conference on Knowledge Discovery and Data Mining (KDD-95), </booktitle> <address> Montreal, PQ, </address> <pages> 118-123. </pages>
Reference-contexts: The structure of the domain can be modified to suit a specific class of problems <ref> (e.g., Fisher 1995) </ref>. Structured attributes can be used as independent (input) variables (Michalski 1980), as well as dependent (output) variables (e.g., Reinke 1984). The roles of structured variables in these two cases differ.
Reference: <author> Karni, R. and Loksh, S. </author> <year> 1996. </year> <title> Generalization Trees as Discovered Knowledge for Manufacturing Management. </title> <publisher> Forthcoming. </publisher>
Reference-contexts: introduction of structured attributes (Michalski 1980). The domain of a structured attribute is a partially ordered set, typically a hierarchy. Domains of structured variables can be generated by a domain expert <ref> (e.g., Karni & Loksh 1996) </ref>, or by an automatic process using a numerical or conceptual clustering method (e.g., Sokal & Sneath 1973; Michalski & Stepp 1983; Fisher 1987). The structure of the domain can be modified to suit a specific class of problems (e.g., Fisher 1995). <p> Even when numeric values have been quantized into ranges by a domain expert, the expert-generated abstraction schema may not be optimal for the learning task <ref> (e.g., Karni & Loksh 1996) </ref>. Furthermore, a particular set of ranges may be useful for one learning task, but irrelevant to another. The implemented methodology performs automatic discretization of numeric data using the ChiMerge algorithm (Kerber 1992).
Reference: <author> Kaufman, K., Michalski, R.S. and Kerschberg, L. </author> <year> 1991. </year> <title> Mining For Knowledge in Data: Goals and General Description of the INLEN System. </title> <editor> In Piatetsky-Shapiro, G. and Frawley, W.J. (Eds.), </editor> <booktitle> Knowledge Discovery in Databases, </booktitle> <address> Menlo Park, CA: </address> <publisher> AAAI Press, </publisher> <pages> 449-462. </pages>
Reference: <author> Kerber, R. </author> <year> 1992. </year> <title> ChiMerge: Discretization of Numeric Attributes. </title> <booktitle> Proceedings of the Tenth National Conference on Artificial Intelligence (AAAI-92), </booktitle> <address> San Jose, CA, </address> <pages> 123-127. </pages>
Reference-contexts: Furthermore, a particular set of ranges may be useful for one learning task, but irrelevant to another. The implemented methodology performs automatic discretization of numeric data using the ChiMerge algorithm <ref> (Kerber 1992) </ref>. With this method, neighboring distinct values of the attribute found in the data are merged into single ranges based on a c 2 analysis of the classification of the values.
Reference: <author> Klimesch, W. </author> <year> 1988. </year> <title> Struktur und Aktivierung des Gedaechtnisses. Das Vernetzungsmodell: Grundlagen und Elemente einer uebergreifenden Theorie. Bern: </title> <publisher> Verlag Hans Huber. </publisher>
Reference: <author> Kubat, M., Bratko, I. and Michalski, R.S. </author> <year> 1996. </year> <title> A Review of Machine Learning Techniques. Chapter in Methods and Applications of Machine Learning and Discovery (forthcoming). </title>
Reference: <author> Michalski, R.S. and McCormick, B.H. </author> <year> 1971. </year> <title> Interval Generalization of Switching Theory. </title> <booktitle> Proceedings of the 3rd Annual Houston Conference on Computer and System Science, </booktitle> <address> Houston, TX. </address>
Reference: <author> Michalski, R.S. </author> <year> 1980. </year> <title> Inductive Learning as Rule-Guided Generalization and Conceptual Simplification of Symbolic Descriptions: Unifying Principles and a Methodology. </title> <booktitle> Workshop on Current Developments in Machine Learning, </booktitle> <institution> Carnegie Mellon University, </institution> <address> Pittsburgh, PA. </address>
Reference-contexts: introduction of structured attributes <ref> (Michalski 1980) </ref>. The domain of a structured attribute is a partially ordered set, typically a hierarchy. <p> The structure of the domain can be modified to suit a specific class of problems (e.g., Fisher 1995). Structured attributes can be used as independent (input) variables <ref> (Michalski 1980) </ref>, as well as dependent (output) variables (e.g., Reinke 1984). The roles of structured variables in these two cases differ. This paper discusses methods for reasoning with structured attributes in the process of data analysis and knowledge discovery.
Reference: <author> Michalski, R.S. </author> <year> 1983. </year> <title> A Theory and Methodology of Inductive Learning. </title> <editor> Chapter in Michalski, R.S., Carbonell, J. and Mitchell, T. (Eds.), </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach, </booktitle> <address> Palo Alto: </address> <publisher> Tioga Publishing, Co., </publisher> <pages> 83-134. </pages>
Reference: <author> Michalski, R.S. </author> <year> 1994. </year> <title> Inferential Theory of Learning: Developing Foundations for Multistrategy Learning. Chapter in Machine Learning: A Multistrategy Approach, </title> <editor> Michalski, R.S. and Tecuci, G. (Eds.), </editor> <address> San Francisco: </address> <publisher> Morgan Kaufmann, </publisher> <pages> 3-61. </pages>
Reference-contexts: This paper discusses methods for reasoning with structured attributes in the process of data analysis and knowledge discovery. Many of the presented ideas have been adapted for knowledge discovery from the Inferential Theory of Learning, which provides a unifying framework for characterizing learning and discovery processes <ref> (Michalski, 1994) </ref>. Among the novel ideas are the use of anchor nodes to guide the inductive generalization process, the use of nonhierarchical attribute domains, and the introduction of different kinds of generalization rules for structured attributes.
Reference: <author> Michalski, R.S., Kerschberg, L., Kaufman, K. and Ribeiro, J. </author> <year> 1992. </year> <title> Mining for Knowledge in Databases: The INLEN Architecture, Initial Implementation and First Results. </title> <journal> Journal of Intelligent Information Systems: Integrating AI and Database Technologies, </journal> <volume> 1(1): </volume> <pages> 85-113. </pages>
Reference: <author> Michalski, R.S., Mozetic, I., Hong, J. and Lavrac, N. </author> <year> 1986. </year> <title> The AQ15 Inductive Learning System: An Overview and Experiments. </title> <type> Report No. </type> <institution> UIUCDCS-R-86-1260, Department of Computer Science, University of Illinois, Urbana, IL. </institution>
Reference-contexts: Another important concept that needs to be explained before introducing the central ideas of this paper is the type of description, as defined in the AQ rule learning methodology <ref> (Michalski et al. 1986) </ref>. By applying the extension-against operator in different ways, one can generate a range of descriptions with different degrees of generality.
Reference: <author> Michalski, R.S. and Stepp, R.E. </author> <year> 1983. </year> <title> Automated Construction of Classifications: Conceptual Clustering versus Numerical Taxonomy. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 5(4): </volume> <pages> 396-410. </pages>
Reference: <author> Reinke, R.E. </author> <year> 1984. </year> <title> Knowledge Acquisition and Refinement Tools for the Advise Meta-Expert System. </title> <type> Masters Thesis, </type> <institution> University of Illinois at Urbana-Champaign. </institution>
Reference-contexts: The structure of the domain can be modified to suit a specific class of problems (e.g., Fisher 1995). Structured attributes can be used as independent (input) variables (Michalski 1980), as well as dependent (output) variables <ref> (e.g., Reinke 1984) </ref>. The roles of structured variables in these two cases differ. This paper discusses methods for reasoning with structured attributes in the process of data analysis and knowledge discovery.
Reference: <author> Rosch, E., Mervis, C., Gray, W., Johnson, D. and Boyes-Braem, P. </author> <year> 1976. </year> <title> Basic Objects in Natural Categories, </title> <journal> Cognitive Psychology, </journal> <volume> 8 </volume> <pages> 382-439. </pages>
Reference: <author> Sokal, R.R. and Sneath, P.H. </author> <year> 1973. </year> <title> Principles of Numerical Taxonomy. </title> <address> San Francisco: </address> <publisher> W.H. Freeman. </publisher>
References-found: 17

