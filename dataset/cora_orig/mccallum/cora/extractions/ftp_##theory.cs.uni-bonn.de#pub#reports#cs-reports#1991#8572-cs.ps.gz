URL: ftp://theory.cs.uni-bonn.de/pub/reports/cs-reports/1991/8572-cs.ps.gz
Refering-URL: http://cs.uni-bonn.de/info5/publications/CS-1991-en.html
Root-URL: http://cs.uni-bonn.de
Title: Probabilistic Recurrence Relations for Parallel Divide-and-Conquer Algorithms  
Author: Marek Karpinski Wolf Zimmermann 
Note: submitted to STOC 92 Supported in part by the DFG Grant KA 673/4-1 and the SERC Grant GR-E 68297  
Address: Berkeley, California.  Berkeley, California.  
Affiliation: Dept. of Computer Science University of Bonn and International Computer Science Institute,  Dept. of Computer Science University of Karlsruhe and International Computer Science Institute,  
Abstract: We study two probabilistic recurrence relations that arise frequently in the analysis of parallel and sequential divide-and-conquer algorithms (cf. [Ka 91]). Suppose a problem of size x has to be solved. In order to solve it we divide it into subproblems of size h 1 (x); : : : ; h k (x) and these subproblems are solved recursively. We assume that size(h i (z)) are random variables. This occurs if either the break up step is randomized or the instances to be solved are drawn from a probability distribution. The running time T (z) of a parallel algorithm is therefore determined by the maximum of the running times T (h i (z)) of the subproblems while the sequential algorithm is determined by the sum of the running times of the subproblems. We give a method for estimating (tight) upper bounds on the probability distribution of T (x) for these two kinds of recurrence relations, answering the open questions of Karp in [Ka 91]. 
Abstract-found: 1
Intro-found: 1
Reference: [ASU 86] <author> Aho, A.V., Sethi, R., and Ullman, J.D. </author> <booktitle> Compilers: Principles, Techniques, and Tools Addison-Wesley 1986 </booktitle>
Reference-contexts: The application of Theorem 1 yields Pr [S (z) w + log 2 n] 1 n 2 For the definition see,e.g., the section on runtime environments in <ref> [ASU 86] </ref> 9 and by corollary 2 E [S (z)] (1= log 2 1) log n 1 In general if E [h 1 (z)] = n=c for a c &gt; 1, it can be concluded from Theorem 1 that E [S (z)] = O (log n). 4.3 Average Running Time for
Reference: [Ak 89] <author> Akl, S. </author> <booktitle> The Design and Analysis of Parallel Algorithms Prentice-Hall 1989 </booktitle>
Reference-contexts: to a probabilistic recurrence relation of the form T (z) = a (x) + max (T (h 1 (x)); T (h 2 (x))) + max (T (h 3 (x)); T (h 4 (x))) These kind of recurrences occur for example in the analysis of a convex hull algorithm (cf., e.g. <ref> [Ak 89] </ref>). These recurrences require a combination of Theorems 1 and 5. Acknowledgements. We thank Peter Burgisser, Gerhard Goos, Dick Karp, and Raimund Seidel for a number of interesting discussions.
Reference: [FSZ 88] <author> Flajolet, P., Salvy, B., and Zimmermann, P. </author> <title> Lambda Upsilon Omega: An Assistant Algorithms Analyzer, </title> <booktitle> in: The Proceedings of 6th International Conference on Ap 11 plied Algebra, Algebraic Algorithms and Error Correcting Codes, </booktitle> <volume> LNCS 357, </volume> <pages> pp 201-212, </pages> <year> 1988 </year>
Reference-contexts: The work of Martinez [Ma 91] shows that this bound is tight. Here a probability distribution is given where the average complexity is fi (log n). 4.4 Automatic Complexity Analysis In recent years automatic complexity analysis systems are developed. The most important of these methods and systems are in <ref> [FSZ 88, HC 88, Me 75, FSZ 91, Zi 90] </ref>. In [FSZ 88, FSZ 91] only uniform input distributions are considered. The method of Flajolet [FSZ 88, FSZ 91] is 10 unable to deal with function composition because the output distribution of a function (or procedure) is usually non-uniform. <p> Here a probability distribution is given where the average complexity is fi (log n). 4.4 Automatic Complexity Analysis In recent years automatic complexity analysis systems are developed. The most important of these methods and systems are in [FSZ 88, HC 88, Me 75, FSZ 91, Zi 90]. In <ref> [FSZ 88, FSZ 91] </ref> only uniform input distributions are considered. The method of Flajolet [FSZ 88, FSZ 91] is 10 unable to deal with function composition because the output distribution of a function (or procedure) is usually non-uniform. <p> The most important of these methods and systems are in [FSZ 88, HC 88, Me 75, FSZ 91, Zi 90]. In <ref> [FSZ 88, FSZ 91] </ref> only uniform input distributions are considered. The method of Flajolet [FSZ 88, FSZ 91] is 10 unable to deal with function composition because the output distribution of a function (or procedure) is usually non-uniform.
Reference: [FSZ 91] <author> Flajolet, P., Salvy, B. and Zimmermann, P. </author> <title> Average Case Analysis of Algorithms, </title> <booktitle> Theoretical Computer Science (79)1, </booktitle> <pages> pp. 37 - 110, </pages> <year> 1991 </year>
Reference-contexts: The work of Martinez [Ma 91] shows that this bound is tight. Here a probability distribution is given where the average complexity is fi (log n). 4.4 Automatic Complexity Analysis In recent years automatic complexity analysis systems are developed. The most important of these methods and systems are in <ref> [FSZ 88, HC 88, Me 75, FSZ 91, Zi 90] </ref>. In [FSZ 88, FSZ 91] only uniform input distributions are considered. The method of Flajolet [FSZ 88, FSZ 91] is 10 unable to deal with function composition because the output distribution of a function (or procedure) is usually non-uniform. <p> Here a probability distribution is given where the average complexity is fi (log n). 4.4 Automatic Complexity Analysis In recent years automatic complexity analysis systems are developed. The most important of these methods and systems are in [FSZ 88, HC 88, Me 75, FSZ 91, Zi 90]. In <ref> [FSZ 88, FSZ 91] </ref> only uniform input distributions are considered. The method of Flajolet [FSZ 88, FSZ 91] is 10 unable to deal with function composition because the output distribution of a function (or procedure) is usually non-uniform. <p> The most important of these methods and systems are in [FSZ 88, HC 88, Me 75, FSZ 91, Zi 90]. In <ref> [FSZ 88, FSZ 91] </ref> only uniform input distributions are considered. The method of Flajolet [FSZ 88, FSZ 91] is 10 unable to deal with function composition because the output distribution of a function (or procedure) is usually non-uniform.
Reference: [HC 88] <author> Hickey, T. and Cohen, J. </author> <title> Automating Program Analysis Journal of the ACM (35)1, </title> <journal> pp. </journal> <volume> 185 - 220, </volume> <year> 1988 </year>
Reference-contexts: The work of Martinez [Ma 91] shows that this bound is tight. Here a probability distribution is given where the average complexity is fi (log n). 4.4 Automatic Complexity Analysis In recent years automatic complexity analysis systems are developed. The most important of these methods and systems are in <ref> [FSZ 88, HC 88, Me 75, FSZ 91, Zi 90] </ref>. In [FSZ 88, FSZ 91] only uniform input distributions are considered. The method of Flajolet [FSZ 88, FSZ 91] is 10 unable to deal with function composition because the output distribution of a function (or procedure) is usually non-uniform.
Reference: [Ka 91] <author> Karp, R. M., </author> <title> Probabilistic Recurrence Relations, </title> <booktitle> Proc. 23 rd ACM STOC (1991), </booktitle> <pages> pp. 191-197. </pages>
Reference-contexts: 1 Introduction Two classes of probabilistic recurrence relations occur frequently in the analysis of divide-and-conquer algorithms cf. <ref> [Ka 91] </ref>. A problem instance z of size x is divided into subproblems h 1 (z); : : : ; h k (z). On a sequential computer the subproblems has to be solved one after another. <p> In this case the running time T (z) is also a random variable, and we estimate bounds on its probability distribution for both cases, (1) and (2). This work is an extension of Karp's results <ref> [Ka 91] </ref> and solves the open questions of [Ka 91]. Throughout the paper we use the following notations and assumptions: * a (z) is a function on the size of z and does not depend on the distribution of z. <p> In this case the running time T (z) is also a random variable, and we estimate bounds on its probability distribution for both cases, (1) and (2). This work is an extension of Karp's results <ref> [Ka 91] </ref> and solves the open questions of [Ka 91]. Throughout the paper we use the following notations and assumptions: * a (z) is a function on the size of z and does not depend on the distribution of z. <p> These weak assumptions make our results practical, because the distribution of (h 1 (x); : : : ; h k (x)) is usually unknown. In section 2 we consider probabilistic recurrences of type (2), and in section 3, probabilistic recurrences of type (1). This paper has similar aims as <ref> [Ka 91] </ref>. Among others, we provide a cook book methodology for analyzing divide-and-conquer algorithms in some general situations. <p> 2 E (T (z)) u (x) log (m 1 (x) + + m k (x)) + log (x) Proof: Use the formula E [Y ] = R 1 0 Pr [Y y]dy for non-negative random variables Y . 2 The proof of Theorem 1 follows a similar line as in <ref> [Ka 91] </ref>. We shall also use the following Lemma: Lemma 3 (R. Karp [Ka 91]) Let X be a random variable with range [0; x] for some x. <p> k (x)) + log (x) Proof: Use the formula E [Y ] = R 1 0 Pr [Y y]dy for non-negative random variables Y . 2 The proof of Theorem 1 follows a similar line as in <ref> [Ka 91] </ref>. We shall also use the following Lemma: Lemma 3 (R. Karp [Ka 91]) Let X be a random variable with range [0; x] for some x. <p> Define a function d r (x) as follows: d r (x) = &lt; i x a (x) e x 1 otherwise Then s r (z) d r (size (z)). Proof: The outline of this proof is similar to that of Theorem 7 in <ref> [Ka 91] </ref>. The proof is by induction using as hypothesis the claim in 5. In order to prove the induction step, we apply another induction. <p> We assume that k 2. For k = 1 the results of <ref> [Ka 91] </ref> can be applied. This kind of recurrence relations occurs for example in the analysis of sequential divide-and-conquer algorithms. <p> These results also enable the extension of the above methods to analyze automatically the expected worst case of randomized algorithms. 5 Summary and Further Research It would be interesting to improve the above results (and the results of <ref> [Ka 91] </ref>) in the case the upper bounds of the higher moments are known. Currently, we are able to give estimates for the probability distribution of the running time of parallel divide-and-conquer algorithms.
Reference: [Ma 91] <author> Martinez, C. </author> <title> Average Case Analysis of Equality of Binary Trees Under the BST Probability Model in: </title> <booktitle> Proceedings of the 8th International Conference on Fundamentals of Computation Theory, </booktitle> <volume> LNCS 529, </volume> <pages> pp. 350 - 359, </pages> <publisher> Springer 1991 </publisher>
Reference-contexts: The work of Martinez <ref> [Ma 91] </ref> shows that this bound is tight. Here a probability distribution is given where the average complexity is fi (log n). 4.4 Automatic Complexity Analysis In recent years automatic complexity analysis systems are developed.
Reference: [Me 75] <author> LeMetayer D. </author> <title> ACE: </title> <booktitle> An Automatic Complexity Evaluator ACM Transactions on Programming Languages and Systems (10)2, </booktitle> <pages> pp. 248-266, </pages> <year> 1988 </year>
Reference-contexts: The work of Martinez [Ma 91] shows that this bound is tight. Here a probability distribution is given where the average complexity is fi (log n). 4.4 Automatic Complexity Analysis In recent years automatic complexity analysis systems are developed. The most important of these methods and systems are in <ref> [FSZ 88, HC 88, Me 75, FSZ 91, Zi 90] </ref>. In [FSZ 88, FSZ 91] only uniform input distributions are considered. The method of Flajolet [FSZ 88, FSZ 91] is 10 unable to deal with function composition because the output distribution of a function (or procedure) is usually non-uniform.
Reference: [We 75] <author> Wegbreit, B., </author> <title> Mechanical Program Analysis, </title> <journal> Communications of the ACM (18)9, </journal> <pages> pp. 528-539, </pages> <year> 1975. </year>
Reference: [ZZ 91] <author> Zimmermann, P. and Zimmermann W. </author> <title> The Automatic Complexity Analysis of Divide-and-Conquer Algorithms in: </title> <booktitle> The Proceedings of the 6th International Symposium on Computing and Information Sciences, </booktitle> <year> 1991 </year>
Reference: [Zi 90] <author> Zimmermann, W. </author> <note> Automatische Komplexitatsanalyse funktionaler Programme, In-formatik Fachberichte 261, Springer 1990 12 </note>
Reference-contexts: The work of Martinez [Ma 91] shows that this bound is tight. Here a probability distribution is given where the average complexity is fi (log n). 4.4 Automatic Complexity Analysis In recent years automatic complexity analysis systems are developed. The most important of these methods and systems are in <ref> [FSZ 88, HC 88, Me 75, FSZ 91, Zi 90] </ref>. In [FSZ 88, FSZ 91] only uniform input distributions are considered. The method of Flajolet [FSZ 88, FSZ 91] is 10 unable to deal with function composition because the output distribution of a function (or procedure) is usually non-uniform. <p> However an application of Theorems 1 and 5 would allow to estimate the output distribution because of the very general assumptions in the preconditions of these Theorems. In <ref> [Zi 90] </ref> it is shown how (deterministic and probabilistic) recurrence relations can be obtained automatically from a program, but they are solved only under very specific assumptions.
References-found: 11

