URL: http://www.eecs.umich.edu/~qstout/pap/JAlg97.ps.Z
Refering-URL: http://www.eecs.umich.edu/~qstout/abs/JAlg97.html
Root-URL: http://www.eecs.umich.edu
Title: Ultra-Fast Expected Time Parallel Algorithms  
Author: Philip D. MacKenzie Quentin F. Stout 
Address: 83725  Ann Arbor, MI 48109-2122  
Affiliation: Department of Mathematics and Computer Science Boise State University Boise, ID  Department of Electrical Engineering and Computer Science The University of Michigan  
Note: In Journal of Algorithms 26 (1998), pp. 1-33.  
Abstract: It has been shown previously that sorting n items into n locations with a polynomial number of processors requires (log n= log log n) time. We sidestep this lower bound with the idea of Padded Sorting, or sorting n items into n+o(n) locations. Since many problems do not rely on the exact rank of sorted items, a Padded Sort is often just as useful as an unpadded sort. Our algorithm for Padded Sort runs on the Tolerant CRCW PRAM and takes fi(log log n= log log log n) expected time using n log log log n= log log n processors, assuming the items are taken from a uniform distribution. Using similar techniques we solve some computational geometry problems, including Voronoi Diagram, with the same processor and time bounds, assuming points are taken from a uniform distribution in the unit square. Further, we present an Arbitrary CRCW PRAM algorithm to solve the Closest Pair problem in constant expected time with n processors regardless of the distribution of points. All of these algorithms achieve linear speedup in expected time over their optimal serial counterparts. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Aggarwal, B. Chazelle, L. Guibas, C. O'Dunlaing, and C. Yap. </author> <title> Parallel computational geometry. </title> <journal> Algorithmica, </journal> <volume> 3 </volume> <pages> 293-327, </pages> <year> 1988. </year>
Reference-contexts: Padded Sort Given n values taken from a uniform distribution over the unit interval <ref> [0; 1] </ref>, arrange them in sorted order in an array of size n+o (n), with the value NULL in all unfilled locations. <p> Cole and Goodrich [14] and Willard and Wee [37] both present PT-optimal n processor, fi (log n) worst case time algorithms for solving the All Nearest Neighbor and Closest Pair problems. Aggarwal et al. <ref> [1] </ref> present an n processor, fi (log 2 n) worst case time algorithm for finding the Voronoi Diagram. <p> Distribution dependent parallel sorting has been worked on by Chlebus [12]. He obtains a fi (log n) expected time, n= log n processor algorithm to sort n random integers in the range <ref> [1; n] </ref>. Following the work in this paper, MacKenzie [27] has proven a lower bound of (log fl n) expected time for Padded Sort and Hagerup and Raman [21] have shown that this is optimal by giving an O (log fl n) expected time algorithm for Padded Sort. <p> We note that although the size of the output is only n + o (n), we actually use superlinear (n polylog (n)) space during the Padded Sort algorithm. 4 Applications of Padded Sort By having each processor choose a random number uniformly from <ref> [0; 1] </ref> and performing a Padded Sort, we will obviously be left with the processors in random order.
Reference: [2] <author> M. Ajtai and M. Ben-Or. </author> <title> A theorem on probabilistic constant depth computations. </title> <booktitle> In Proc. 16th ACM Symp. on Theory of Computing, </booktitle> <pages> pages 471-474, </pages> <year> 1984. </year>
Reference-contexts: From Ajtai and Ben-Or <ref> [2] </ref> and Chandra, Stockmeyer, and Vishkin [11], we can see that this lower bound applies even when randomization is allowed and/or the bits are chosen at random.
Reference: [3] <author> M. Ajtai, J. Komlos, and E. Szemeredi. </author> <title> An O(n log n) sorting network. </title> <journal> Combinatorica, </journal> <volume> 3 </volume> <pages> 1-19, </pages> <year> 1983. </year>
Reference-contexts: When the processor time product of an algorithm is O (n), the PT-optimality is obvious, and we will sometimes omit this indication. Leighton's [25] modification to the AKS sorting network <ref> [3] </ref>, and Cole's parallel merge sort [13] both use n processors and achieve fi (log n) worst case time for sorting, which is PT-optimal. We note that any PT-optimal algorithm for sorting must use at least log n time [4]. <p> Merge Two lists of size n can be merged in fi (log log n) time using n= log log n processors [24]. Sort A list of n items can be sorted in fi (log n) time using n processors <ref> [3, 13] </ref>. With n 2 processors, the items can be sorted in fi (log n= log log n) time, by finding the position of each item using separate prefix operations.
Reference: [4] <author> N. Alon and Y. Azar. </author> <title> The average complexity of deterministic and randomized parallel comparison sorting algorithms. </title> <journal> SIAM J. Comput., </journal> <volume> 17(6) </volume> <pages> 1178-1192, </pages> <month> December </month> <year> 1988. </year>
Reference-contexts: Leighton's [25] modification to the AKS sorting network [3], and Cole's parallel merge sort [13] both use n processors and achieve fi (log n) worst case time for sorting, which is PT-optimal. We note that any PT-optimal algorithm for sorting must use at least log n time <ref> [4] </ref>. Reischuk [33] gives a PT-optimal randomized n processor, fi (log n) time algorithm for sorting.
Reference: [5] <author> D. Angluin and L. G. Valiant. </author> <title> Fast probabilistic algorithms for Hamiltonian circuits and matchings. </title> <journal> J. Comput. System Sci., </journal> <volume> 18 </volume> <pages> 155-193, </pages> <year> 1979. </year>
Reference-contexts: For a binomial random varible Z B (n; p), where Z is the sum of n independent Bernoulli trials with probability of success p, Angluin and Valiant <ref> [5] </ref> show that for 0 &lt; fi &lt; 1, one can obtain the bounds P (Z (1 + fi)np) e fi 2 np=3 ; P (Z (1 fi)np) e fi 2 np=2 : From this we obtain the bound P (Z 2np) 2 4np=9 : Also, for k 3 we obtain
Reference: [6] <author> P. Beame and J. Hastad. </author> <title> Optimal bounds for decision problems on the CRCW PRAM. </title> <journal> J. Assoc. Comput. Mach., </journal> <volume> 36(3) </volume> <pages> 643-670, </pages> <month> July </month> <year> 1989. </year>
Reference-contexts: this by the number of superblocks. 2 Lemma 2.5 For k 16, k 2 k 2 nk Proof: For k 16, k 2 k 2 nk k 2 k k 2 k k 2 k (log klog 2e) e (k log k)=4 : 6 3 Padded Sort Beame and Hastad <ref> [6] </ref> have shown that finding the parity of n bits in any PRAM model requires (log n= log log n) time using any polynomial number of processors.
Reference: [7] <author> J. L. Bentley, B. W. Weide, and A. C. Yao. </author> <title> Optimal expected-time algorithms for closest point problems. </title> <journal> ACM Trans. Math. Software, </journal> <volume> 6(4) </volume> <pages> 563-580, </pages> <month> December </month> <year> 1980. </year>
Reference-contexts: All of the problems above have trivial linear lower bounds on the expected times of their solutions, and serial algorithms have been developed for all of them which attain this lower bound. The solution for sorting is well known. Bentley, Weide, and Yao <ref> [7] </ref> exhibit linear expected time algorithms for All Nearest Neighbors and Voronoi Diagram, and linear expected time Delaunay Triangulation and Largest Empty Circle algorithms follow immediately. Katajainen, Nevalainen, and Teuhola [22] exhibit a linear expected time algorithm for the Relative Neighborhood Graph. <p> To do this, we follow the technique of Bentley, Weide, and Yao <ref> [7] </ref> and divide the square into n equal subsquares in a p p n grid. The points can be placed into bins corresponding to these subsquares just as in the Padded Sort algorithm. <p> The probability of a search taking more than Ki steps has been shown to be e i , for some K <ref> [7] </ref>. <p> The procedure for constructing the Voronoi Diagram inside the unit square will be very similar to the one given above for solving All Nearest Neighbors. We refer the reader to Bentley, Weide, and Yao <ref> [7] </ref> for the details of the transformation.
Reference: [8] <author> O. Berkman, D. Breslauer, Z. Galil, B. Schieber, and U. Vishkin. </author> <title> Highly parallelizable problems. </title> <booktitle> In Proc. 21st ACM Symp. on Theory of Computing, </booktitle> <pages> pages 309-319, </pages> <year> 1989. </year>
Reference-contexts: We note that the Largest Empty Circle can be found in fi (log n) worst case time with n processors given the Voronoi Diagram, so the time and processor bounds above also apply to finding the Largest Empty Circle. Berkman et al. <ref> [8] </ref> give n= log log n processor, fi (log log n) worst case time algorithms for some other geometric problems, but these problems are highly constrained.
Reference: [9] <author> O. Berkman, B. Schieber, and U. Vishkin. </author> <title> Some doubly logarithmic parallel algorithms based on finding all nearest smaller values. </title> <type> Technical Report UMIACS-TR-88-79, </type> <institution> University of Maryland Institute for Advanced Computer Studies, </institution> <year> 1988. </year>
Reference-contexts: We will call this a marked compression. When is maximum or minimum, the prefix operation can be performed in fi (log log n) time using n= log log n processors <ref> [9, 34] </ref>. This obviously implies that the maximum or minimum of n elements can be found in fi (log log n) 4 time with n= log log n processors [36].
Reference: [10] <author> O. Berkman and U. Vishkin. </author> <title> Recursive *-tree parallel data-structure. </title> <booktitle> In Proc. 30th Symp. on Found. of Comp. Sci., </booktitle> <pages> pages 196-202, </pages> <year> 1989. </year>
Reference-contexts: We can easily obtain a random cycle of the processors from this using an algorithm for chaining <ref> [10] </ref>, and we can obtain a random permutation of the processors by compressing the padded list using a prefix sum operation. (In a random cycle of processors, each processor contains a link to another processor, the links form a simple cycle, and each possible cycle is equally likely.) Thus, by using
Reference: [11] <author> A. K. Chandra, L. J. Stockmeyer, and U. Vishkin. </author> <title> A complexity theory for unbounded fan-in parallelism. </title> <booktitle> In Proc. 23th Symp. on Found. of Comp. Sci., </booktitle> <pages> pages 1-13, </pages> <year> 1982. </year>
Reference-contexts: From Ajtai and Ben-Or [2] and Chandra, Stockmeyer, and Vishkin <ref> [11] </ref>, we can see that this lower bound applies even when randomization is allowed and/or the bits are chosen at random.
Reference: [12] <author> B. S. Chlebus. </author> <title> Parallel iterated bucket sort. </title> <journal> Inform. Process. Lett., </journal> <volume> 31(4) </volume> <pages> 181-183, </pages> <month> May </month> <year> 1989. </year>
Reference-contexts: Katajainen, Nevalainen, and Teuhola [22] show that the Relative Neighborhood graph of n points taken from a uniform distribution over the unit square can also be constructed in fi (log n) expected time with n= log n processors. Distribution dependent parallel sorting has been worked on by Chlebus <ref> [12] </ref>. He obtains a fi (log n) expected time, n= log n processor algorithm to sort n random integers in the range [1; n].
Reference: [13] <author> R. Cole. </author> <title> Parallel merge sort. </title> <booktitle> In Proc. 27th Symp. on Found. of Comp. Sci., </booktitle> <pages> pages 511-516, </pages> <year> 1986. </year>
Reference-contexts: When the processor time product of an algorithm is O (n), the PT-optimality is obvious, and we will sometimes omit this indication. Leighton's [25] modification to the AKS sorting network [3], and Cole's parallel merge sort <ref> [13] </ref> both use n processors and achieve fi (log n) worst case time for sorting, which is PT-optimal. We note that any PT-optimal algorithm for sorting must use at least log n time [4]. Reischuk [33] gives a PT-optimal randomized n processor, fi (log n) time algorithm for sorting. <p> Merge Two lists of size n can be merged in fi (log log n) time using n= log log n processors [24]. Sort A list of n items can be sorted in fi (log n) time using n processors <ref> [3, 13] </ref>. With n 2 processors, the items can be sorted in fi (log n= log log n) time, by finding the position of each item using separate prefix operations.
Reference: [14] <author> R. Cole and M. T. Goodrich. </author> <title> Optimal parallel algorithms for polygon and point-set problems. </title> <booktitle> In Proc. 4th ACM Symp. on Comp. Geom., </booktitle> <pages> pages 205-214, </pages> <year> 1988. </year>
Reference-contexts: Cole and Goodrich <ref> [14] </ref> and Willard and Wee [37] both present PT-optimal n processor, fi (log n) worst case time algorithms for solving the All Nearest Neighbor and Closest Pair problems. Aggarwal et al. [1] present an n processor, fi (log 2 n) worst case time algorithm for finding the Voronoi Diagram.
Reference: [15] <author> R. Cole, M. T. Goodrich, and C. O'Dunlaing. </author> <title> Merging free trees in parallel for efficient voronoi diagram construction. </title> <booktitle> In Proc. 17th Intl. Coll. on Automata, Languages, and Programming, </booktitle> <pages> pages 432-445, </pages> <year> 1990. </year>
Reference-contexts: Aggarwal et al. [1] present an n processor, fi (log 2 n) worst case time algorithm for finding the Voronoi Diagram. Cole, Goodrich, and O'Dunlaing <ref> [15] </ref> give algorithms for finding the Voronoi Diagram in fi (log 2 n) worst case time with n= log n processors, and in fi (log n log log n) worst case time with n log n= log log n processors.
Reference: [16] <author> R. Cole and U. Vishkin. </author> <title> Approximate and exact parallel scheduling with applications to list, tree, and graph problems. </title> <booktitle> In 27th IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 478-491, </pages> <year> 1986. </year>
Reference-contexts: When is addition, and the input array consists of n numbers, each of O (log n) bits, the prefix operation can be performed in fi (log n= log log n) time with n log log n= log n processors on a CRCW PRAM <ref> [16] </ref>. Compression, in which m marked records out of a total of n records must be compressed to the front of the output array, can easily be reduced to prefix addition, and thus can be performed in the same time bounds.
Reference: [17] <author> J. Gil, Y. Matias, and U. Vishkin. </author> <title> Towards a theory of nearly constant time parallel algorithms. </title> <booktitle> In Proc. 32nd Symp. on Found. of Comp. Sci., </booktitle> <pages> pages 698-710, </pages> <year> 1991. </year> <month> 25 </month>
Reference-contexts: This result is not optimal, as shown by Gil, Matias, and Vishkin <ref> [17] </ref>, who give an algorithm to construct a random permutation in fi (log fl n) expected time using n= log fl n processors, where log (1) n j log n, log (i) n j log (log (i1) n) for i &gt; 1, and log fl n j minfi : log (i)
Reference: [18] <author> J. Gil and L. Rudolph. </author> <title> Counting and packing in parallel. </title> <booktitle> In Proc. 15th Intl. Conf. on Parallel Processing, </booktitle> <pages> pages 1000-1002, </pages> <year> 1986. </year>
Reference-contexts: Using only the processors assigned to the marked records, those marked records can be compressed in fi (log n) time <ref> [18] </ref>. We will call this a marked compression. When is maximum or minimum, the prefix operation can be performed in fi (log log n) time using n= log log n processors [9, 34].
Reference: [19] <author> G. H. Gonnet. </author> <title> Expected length of the longest probe sequence in hash code searching. </title> <journal> J. Assoc. Comput. Mach., </journal> <volume> 28 </volume> <pages> 289-304, </pages> <year> 1981. </year>
Reference-contexts: Unfortunately, a straightforward parallelization of the above technique does not lead to an efficient algorithm. The first problem is placing items in bins. The expected maximum number of items in a bin is fi (log n= log log n) <ref> [19] </ref>, and thus it would take that many naive attempts before all items were placed in bins. The other problem is that assuming each processor took one bin to sort, the expected maximum time would be (log n= log log n).
Reference: [20] <author> T. Hagerup and T. Radzik. </author> <title> Every robust CRCW PRAM can efficiently simulate a Priority PRAM. </title> <booktitle> In Proc. 2nd ACM Symp. on Para. Alg. and Arch., </booktitle> <pages> pages 117-124, </pages> <year> 1990. </year>
Reference-contexts: An algorithm for the Tolerant CRCW PRAM implies algorithms with the same time and processor bounds on stronger models, such as the Collision and Arbitrary models (see, for example, Hagerup and Radzik <ref> [20] </ref>). For the Closest Pair algorithm we will be using the Arbitrary CRCW PRAM model. In this model, if two or more processors write to a cell simultaneously, the one which succeeds in writing is chosen arbitrarily.
Reference: [21] <author> T. Hagerup and R. Raman. </author> <title> Waste makes haste: Tight bounds for loose parallel sorting. </title> <booktitle> In Proc. 33rd IEEE Symp. on Found. of Comp. Sci., </booktitle> <pages> pages 628-637, </pages> <year> 1992. </year>
Reference-contexts: He obtains a fi (log n) expected time, n= log n processor algorithm to sort n random integers in the range [1; n]. Following the work in this paper, MacKenzie [27] has proven a lower bound of (log fl n) expected time for Padded Sort and Hagerup and Raman <ref> [21] </ref> have shown that this is optimal by giving an O (log fl n) expected time algorithm for Padded Sort.
Reference: [22] <author> J. Katajainen, O. Nevalainen, and J. Teuhola. </author> <title> A linear expected-time algorithm for computing planar relative neighbourhood graphs. </title> <journal> Inform. Process. Lett., </journal> <volume> 25(2) </volume> <pages> 77-86, </pages> <month> May </month> <year> 1987. </year>
Reference-contexts: The solution for sorting is well known. Bentley, Weide, and Yao [7] exhibit linear expected time algorithms for All Nearest Neighbors and Voronoi Diagram, and linear expected time Delaunay Triangulation and Largest Empty Circle algorithms follow immediately. Katajainen, Nevalainen, and Teuhola <ref> [22] </ref> exhibit a linear expected time algorithm for the Relative Neighborhood Graph. Rabin [29] has given a randomized linear expected time algorithm for Closest Pair which is distribution independent. There has been a great amount of work on parallel algorithms for distribution independent versions of the problems above. <p> Levcopoulos, Katajainen, and Lingas [26] show that the Voronoi Diagram of n points taken from a uniform distribution over the unit square can be constructed in fi (log n) expected time with n= log n processors. Katajainen, Nevalainen, and Teuhola <ref> [22] </ref> show that the Relative Neighborhood graph of n points taken from a uniform distribution over the unit square can also be constructed in fi (log n) expected time with n= log n processors. Distribution dependent parallel sorting has been worked on by Chlebus [12]. <p> The details here are not complicated and are left to the reader. 4.2 Relative Neighborhood Graph The procedure for constructing the Relative Neighborhood Graph is very similar to the one for solving All Nearest Neighbors. We refer the reader to Katajainen, Nevalainen, and Teuhola <ref> [22] </ref> for the details of the differences. 4.3 Voronoi Diagram We construct the Voronoi Diagram with two separate procedures, one which constructs the part inside the unit square, and one which constructs the part outside the unit square.
Reference: [23] <author> D. E. Knuth. </author> <booktitle> The Art of Computer Programming, </booktitle> <volume> volume 1. </volume> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1973. </year>
Reference-contexts: The number of maximal positions is then equal to the number of maximal points. The analysis of the number of maximal positions is given in Knuth <ref> [23] </ref>. The average is less than log n and the standard deviation is less than p log n. <p> Taken from Knuth <ref> [23] </ref>, e 2x x! x x p One use of Stirling's Approximation is to obtain the bound k (n k) nk k k ne k 24
Reference: [24] <author> C. P. Kruskal. </author> <title> Searching, merging, and sorting. </title> <journal> IEEE Trans. Comput., </journal> <volume> 32(10) </volume> <pages> 942-947, </pages> <month> Octo-ber </month> <year> 1983. </year>
Reference-contexts: Some examples of problems with known ultra-fast parallel algorithms include merging two lists of size n <ref> [24] </ref> and finding the maximum of n numbers [36]. We also define an ultra-fast expected time parallel algorithm as one which uses at most a linear number of processors and runs in O ((log log n) O (1) ) expected time. <p> A segmented prefix operation can be performed in the same time bounds as a normal prefix operation. Merge Two lists of size n can be merged in fi (log log n) time using n= log log n processors <ref> [24] </ref>. Sort A list of n items can be sorted in fi (log n) time using n processors [3, 13]. With n 2 processors, the items can be sorted in fi (log n= log log n) time, by finding the position of each item using separate prefix operations.
Reference: [25] <author> T. Leighton. </author> <title> Tight bounds on the complexity of parallel sorting. </title> <journal> IEEE Trans. Comput., </journal> <volume> 34(4) </volume> <pages> 344-354, </pages> <month> April </month> <year> 1985. </year>
Reference-contexts: When the processor time product of an algorithm is O (n), the PT-optimality is obvious, and we will sometimes omit this indication. Leighton's <ref> [25] </ref> modification to the AKS sorting network [3], and Cole's parallel merge sort [13] both use n processors and achieve fi (log n) worst case time for sorting, which is PT-optimal. We note that any PT-optimal algorithm for sorting must use at least log n time [4].
Reference: [26] <author> C. Levcopoulos, J. Katajainen, and A. Lingas. </author> <title> An optimal expected-time parallel algorithm for Voronoi diagrams. </title> <booktitle> In Scandenavian Conf. on Theoretical Comp. Sci., </booktitle> <year> 1988. </year>
Reference-contexts: These results can also be extended to more general regions. Levcopoulos, Katajainen, and Lingas <ref> [26] </ref> show that the Voronoi Diagram of n points taken from a uniform distribution over the unit square can be constructed in fi (log n) expected time with n= log n processors.
Reference: [27] <author> P. D. MacKenzie. </author> <title> Load balancing requires (log fl n) expected time. </title> <booktitle> In 3rd ACM-SIAM Symp. on Disc. Alg., </booktitle> <pages> pages 94-99, </pages> <year> 1992. </year>
Reference-contexts: Distribution dependent parallel sorting has been worked on by Chlebus [12]. He obtains a fi (log n) expected time, n= log n processor algorithm to sort n random integers in the range [1; n]. Following the work in this paper, MacKenzie <ref> [27] </ref> has proven a lower bound of (log fl n) expected time for Padded Sort and Hagerup and Raman [21] have shown that this is optimal by giving an O (log fl n) expected time algorithm for Padded Sort.
Reference: [28] <author> F. P. Preparata and M. I. Shamos. </author> <title> Computational Geometry: An Introduction. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1985. </year>
Reference-contexts: Since S contains O (n 0:3 ) points, all the Outer Voronoi Cells can be found simultaneously, and this completes the construction of the Voronoi Diagram. 4.4 Delaunay Triangulation From Preparata and Shamos <ref> [28] </ref>, we know that the Delaunay Triangulation is simply the straight line dual of the Voronoi Diagram. Thus we can find the Voronoi Diagram as above, and easily construct the dual in fi (log log n= log log log n) time. 4.5 Largest Empty Circle From Preparata and Shamos [28], we <p> Shamos <ref> [28] </ref>, we know that the Delaunay Triangulation is simply the straight line dual of the Voronoi Diagram. Thus we can find the Voronoi Diagram as above, and easily construct the dual in fi (log log n= log log log n) time. 4.5 Largest Empty Circle From Preparata and Shamos [28], we know that the midpoint of the Largest Empty Circle must be on a vertex of the Voronoi Diagram, or on the intersection of a line segment from the Voronoi Diagram and the Convex Hull. We find the Voronoi Diagram as above.
Reference: [29] <author> M. O. Rabin. </author> <title> Probabilistic algorithms. </title> <editor> In J. F. Traub, editor, </editor> <booktitle> Algorithms and Complexity, </booktitle> <pages> pages 21-39. </pages> <publisher> Academic Press, Inc., </publisher> <address> New York, New York, </address> <year> 1976. </year>
Reference-contexts: Bentley, Weide, and Yao [7] exhibit linear expected time algorithms for All Nearest Neighbors and Voronoi Diagram, and linear expected time Delaunay Triangulation and Largest Empty Circle algorithms follow immediately. Katajainen, Nevalainen, and Teuhola [22] exhibit a linear expected time algorithm for the Relative Neighborhood Graph. Rabin <ref> [29] </ref> has given a randomized linear expected time algorithm for Closest Pair which is distribution independent. There has been a great amount of work on parallel algorithms for distribution independent versions of the problems above. <p> n) expected time and using n log log log n= log log n processors, we can 1. solve the All Nearest Neighbors problem, 2. construct the Relative Neighborhood Graph, 3. construct the Voronoi Diagram, 4. construct the Delaunay Triangulation, and 5. find the Largest Empty Circle. 5 Closest Pair Rabin <ref> [29] </ref> suggests the following algorithm for finding the closest pair of n points in linear time. Take a random sample of n 2=3 points and find the closest pair of this sample recursively. <p> This will not add more than a constant to our expected time. 2 We now return to the description of a parallel closest pair algorithm. We begin by defining the notation used in Rabin <ref> [29] </ref>. Let S = fx 1 ; : : : ; x n g be a set of points in the plane.
Reference: [30] <author> S. Rajasekaran and J. H. Reif. </author> <title> Optimal and sublogarithmic time randomized parallel sorting algorithms. </title> <journal> SIAM J. Comput., </journal> <volume> 18(3) </volume> <pages> 594-607, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: We note that any PT-optimal algorithm for sorting must use at least log n time [4]. Reischuk [33] gives a PT-optimal randomized n processor, fi (log n) time algorithm for sorting. Rajasekaran and Reif <ref> [30] </ref> give a randomized algorithm for general sorting which achieves fi (log n= log log n) time with n log * n processors for any * &gt; 0, which is optimal, a randomized algorithm for integer sorting which achieves fi (log n= log log n) time with n (log log n)
Reference: [31] <author> S. Rajasekaran and S. Sen. </author> <title> Random sampling techniques and parallel algorithm design. </title> <editor> In J. Reif, editor, </editor> <booktitle> Synthesis of Parallel Algorithms, </booktitle> <pages> pages 411-451. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference-contexts: Proof: Use a Chernoff bound to place an upper bound on the probability that 4 log n items fall into any block and multiply this by the number of blocks. 2 The ideas in the following lemma were previously used in Stout [35] and Rajasekaran and Sen <ref> [31] </ref> Lemma 2.3 For any b &gt; 0, n processors can each be allocated a position in an array of n 1+b positions in constant time (which depends on b) with probability of failure less than 1=n in the CRCW PRAM model. (We assume that each processor has a unique identification
Reference: [32] <author> J. H. Reif and S. Sen. </author> <title> Polling: A new randomized sampling technique for computational geometry. </title> <booktitle> In Proc. 21st ACM Symp. on Theory of Computing, </booktitle> <year> 1989. </year>
Reference-contexts: Cole, Goodrich, and O'Dunlaing [15] give algorithms for finding the Voronoi Diagram in fi (log 2 n) worst case time with n= log n processors, and in fi (log n log log n) worst case time with n log n= log log n processors. Reif and Sen <ref> [32] </ref> have recently given PT-optimal n processor, fi (log n) expected time randomized algorithms for constructing the Voronoi Diagram and finding All Nearest Neighbors.
Reference: [33] <author> R. Reischuk. </author> <title> Probabilistic parallel algorithms for sorting and selection. </title> <journal> SIAM J. Comput., </journal> <volume> 14(2) </volume> <pages> 396-409, </pages> <month> May </month> <year> 1985. </year>
Reference-contexts: Leighton's [25] modification to the AKS sorting network [3], and Cole's parallel merge sort [13] both use n processors and achieve fi (log n) worst case time for sorting, which is PT-optimal. We note that any PT-optimal algorithm for sorting must use at least log n time [4]. Reischuk <ref> [33] </ref> gives a PT-optimal randomized n processor, fi (log n) time algorithm for sorting.
Reference: [34] <author> B. Schieber. </author> <title> Design and analysis of some parallel algorithms. </title> <type> PhD thesis, </type> <institution> Tel Aviv University, </institution> <year> 1987. </year>
Reference-contexts: We will call this a marked compression. When is maximum or minimum, the prefix operation can be performed in fi (log log n) time using n= log log n processors <ref> [9, 34] </ref>. This obviously implies that the maximum or minimum of n elements can be found in fi (log log n) 4 time with n= log log n processors [36].
Reference: [35] <author> Q. F. Stout. </author> <title> Constant-time geometry on PRAMs. </title> <booktitle> In Proc. Intl. Conf. on Parallel Processing, </booktitle> <pages> pages 104-107, </pages> <year> 1988. </year> <month> 26 </month>
Reference-contexts: On the other hand, we solve 3 much more general problems and use randomness and a knowledge of input distribution to obtain linear speedup and o (log log n) expected time solutions. Two groups have previously done work on parallel distribution dependent expected-time geometry. Stout <ref> [35] </ref> shows that given n points taken from a uniform distribution over the unit square, the maximal points, extreme points, diameter, smallest enclosing rectangle, smallest enclosing circle, and closest pair can all be found in constant expected time with n processors. <p> Proof: Use a Chernoff bound to place an upper bound on the probability that 4 log n items fall into any block and multiply this by the number of blocks. 2 The ideas in the following lemma were previously used in Stout <ref> [35] </ref> and Rajasekaran and Sen [31] Lemma 2.3 For any b &gt; 0, n processors can each be allocated a position in an array of n 1+b positions in constant time (which depends on b) with probability of failure less than 1=n in the CRCW PRAM model. (We assume that each <p> We find the Voronoi Diagram as above. To find the Convex Hull, first we find the extreme points (i.e. those points which are corners of the Convex Hull) in fi (log log n= log log log n) time, using the constant time algorithm given in Stout <ref> [35] </ref>, but simulating log log n= log log log n processors with 1 processor. Then we use the following lemma.
Reference: [36] <author> L. G. Valiant. </author> <title> Parallelism in comparison problems. </title> <journal> SIAM J. Comput., </journal> <volume> 4 </volume> <pages> 348-355, </pages> <year> 1975. </year>
Reference-contexts: Some examples of problems with known ultra-fast parallel algorithms include merging two lists of size n [24] and finding the maximum of n numbers <ref> [36] </ref>. We also define an ultra-fast expected time parallel algorithm as one which uses at most a linear number of processors and runs in O ((log log n) O (1) ) expected time. In this paper, we will develop ultra-fast expected time parallel algorithms for sorting and many geometric problems. <p> This obviously implies that the maximum or minimum of n elements can be found in fi (log log n) 4 time with n= log log n processors <ref> [36] </ref>. However, if we can use n 1+b processors, for any b &gt; 0, the maximum of n elements can be found in constant time [36]. <p> implies that the maximum or minimum of n elements can be found in fi (log log n) 4 time with n= log log n processors <ref> [36] </ref>. However, if we can use n 1+b processors, for any b &gt; 0, the maximum of n elements can be found in constant time [36]. A special type of prefix operation is the segmented prefix operation in which the input array is divided into contiguous groups and a prefix operation is performed within each group in parallel. A segmented prefix operation can be performed in the same time bounds as a normal prefix operation.
Reference: [37] <author> D. E. Willard and Y. C. Wee. </author> <title> Quasi-valid range querying and its implications for nearest neighbor problems. </title> <booktitle> In Proc. 4th ACM Symp. on Comp. Geom., </booktitle> <pages> pages 34-43, </pages> <year> 1988. </year> <month> 27 </month>
Reference-contexts: Cole and Goodrich [14] and Willard and Wee <ref> [37] </ref> both present PT-optimal n processor, fi (log n) worst case time algorithms for solving the All Nearest Neighbor and Closest Pair problems. Aggarwal et al. [1] present an n processor, fi (log 2 n) worst case time algorithm for finding the Voronoi Diagram.
References-found: 37

