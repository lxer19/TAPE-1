URL: ftp://ftp.ai.mit.edu/pub/users/gideon/papers/motionStereo-ver4.ps.gz
Refering-URL: http://www.ai.mit.edu/people/gideon/gideon.html
Root-URL: 
Email: gideon@ai.mit.edu  
Title: Direct Estimation of Motion and Extended Scene Structure from a Moving Stereo Rig  
Author: Gideon P. Stein Amnon Shashua 
Web: http://www.cs.huji.ac.il/~ shashua/  
Address: Cambridge, MA 02139 Jerusalem 91904, Israel  
Affiliation: Artificial Intelligence Laboratory Institute of Computer Science MIT Hebrew University of Jerusalem  
Abstract: We investigate the relationship between the kinematics (infinitesimal motion model) of a calibrated Stereo Rig and point and line image feature measurements seen at two time instances of the rig's motion (four images in all). In particular, we are interested in the byproduct of this analysis providing a direct connection between the spatio-temporal derivatives of the images at two time instances and kinematics of the 3D motion of the Rig. We establish a fundamental result showing that 3 quadruples of point-line-line-line matches (i.e., point in the reference image and lines coincident with the corresponding points in the remaining three images) are sufficient for a unique linear solution for the kinematics of the rig. In other words, the projected instantaneous motion of "one and a half " 3D lines is sufficient for recovering the kinematics of the moving rig. In particular, spatio-temporal derivatives across 3 points are sufficient for a direct estimation of the rig's motion. Consequently, we describe a new direct estimation method for motion estimation and 3D reconstruction from stereo image sequences obtained by a stereo rig moving through a rigid world. Correspondences (optic flow) are not required as spatio-temporal derivative are used instead. One can then use the images from both pairs combined, to compute a dense depth map. Finally, since the basic equations are linear, we combine the contribution coming from all pixels in the image using a Least Squares approach. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. R. Bergen, P. Anandan, K. J. Hanna, and R. Hingo-rani. </author> <title> Hierarchical model-based motion estimation. </title> <booktitle> In Proceedings of the European Conference on Computer Vision, </booktitle> <address> Santa Margherita Ligure, Italy, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: This stabilizes regions where there is no image gradient. 3.3 Coarse to fine processing and itera tive refinement In order to deal with image motions larger than 1 pixel we use a Gaussian pyramid for coarse to fine processing <ref> [1, 2] </ref>. For a 640 fi 480 image we used a 5 level pyramid. The linear solution can be thought of as a single iteration of Newton's method applied to the problem. At each level of the pyramid we iterate as follows: 1.
Reference: [2] <author> P. J. Burt and E. H. Adelson. </author> <title> The laplacian pyramid as a compact image code. </title> <journal> IEEE Transactions on Communications, </journal> <volume> 31 </volume> <pages> 532-540, </pages> <year> 1983. </year>
Reference-contexts: This stabilizes regions where there is no image gradient. 3.3 Coarse to fine processing and itera tive refinement In order to deal with image motions larger than 1 pixel we use a Gaussian pyramid for coarse to fine processing <ref> [1, 2] </ref>. For a 640 fi 480 image we used a 5 level pyramid. The linear solution can be thought of as a single iteration of Newton's method applied to the problem. At each level of the pyramid we iterate as follows: 1.
Reference: [3] <author> P. Fua. </author> <title> Reconstructing complex surfaces from multiple stereo views. </title> <booktitle> In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 1078-1085. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> June </month> <year> 1995. </year>
Reference-contexts: We have also not dealt with the issue of how to represent the final 3D reconstruction. At this point we draw multiple 2 1 2 D surfaces. Better methods are described in <ref> [3] </ref>. We have focused on direct methods but multiview geometric constraints can also be applied to merge 3D reconstructions from a stereo sequence using feature correspondences.
Reference: [4] <author> K. J. Hanna and N. E. Okamoto. </author> <title> Combining stereo and motion analysis for direct estimation of scene structure. </title> <booktitle> In Proceedings of the International Conference on Computer Vision, </booktitle> <address> Berlin, Germany, </address> <month> May </month> <year> 1993. </year> <title> scene created by aligning four separate reconstructions into one coordinate system using the recovered camera motion. The small spheres show the camera path. The large spheres show the camera positions of the four Eu clidean reconstructions. </title>
Reference-contexts: The goal is to recover the motion (kinematics) of the rig and, by combining the stream of image pairs, to obtain a 3D reconstruction of the scene depicted by the image stream. Details on various approaches for stereo-motion cooperation can be found in <ref> [7, 4, 15, 8] </ref>. We first investigate the theoretical lower bound on the amount of image measurements required for recovering the kinematics of the rig.
Reference: [5] <author> B. K. P. Horn and B. G. Schunk. </author> <title> Determining optical flow. </title> <journal> Artificial Intelligence, </journal> <volume> 17 </volume> <pages> 185-203, </pages> <year> 1981. </year>
Reference-contexts: However, there still remains the problem of finding those correspondences. This is addressed in the next section in which we introduce the photometric constraint. 2.1 Photometric Constraints A first order approximation of the constant brightness constraint leads to the optical flow constraint equation <ref> [5] </ref>: u 0 I x + v 0 I y + I 0 where (u 0 ; v 0 ) are the optical flow values at (x; y) between image 1 and image 2 (i.e. u 0 = x 0 x and v 0 = y 0 y). (I x ;
Reference: [6] <author> M. Irani, B. Rousso, and S. Peleg. </author> <title> Recovery of ego-motion using image stabilization'. </title> <booktitle> In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 454-460, </pages> <address> Seattle, Washington, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: Calibration of the stereo pair is performed in two stages. First we take an image of a distant scene (the plane at infinity) and find the homography between image 2 and image 1 using the method described in <ref> [6] </ref>. Since the rotation angle is small we can assume an affine model rather than a full planar projective transformation. This stage takes into account both the rotation between the two cameras and also the variation in internal camera parameters.
Reference: [7] <author> Y. C. Kim and J. K. Aggarwal. </author> <title> Determining object motion in a sequence of stereo images. </title> <journal> IEEE Journal of Robotics and Automation, </journal> <volume> 3(6) </volume> <pages> 599-614, </pages> <month> December </month> <year> 1987. </year>
Reference-contexts: The goal is to recover the motion (kinematics) of the rig and, by combining the stream of image pairs, to obtain a 3D reconstruction of the scene depicted by the image stream. Details on various approaches for stereo-motion cooperation can be found in <ref> [7, 4, 15, 8] </ref>. We first investigate the theoretical lower bound on the amount of image measurements required for recovering the kinematics of the rig.
Reference: [8] <author> R. Koch. </author> <title> 3-d surface reconstruction from stereoscopic image sequences. </title> <booktitle> In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 109-114. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> June </month> <year> 1995. </year>
Reference-contexts: The goal is to recover the motion (kinematics) of the rig and, by combining the stream of image pairs, to obtain a 3D reconstruction of the scene depicted by the image stream. Details on various approaches for stereo-motion cooperation can be found in <ref> [7, 4, 15, 8] </ref>. We first investigate the theoretical lower bound on the amount of image measurements required for recovering the kinematics of the rig.
Reference: [9] <author> N. Navab, R. Deriche, and O. D. Faugeras. </author> <title> Recovering 3d motion and structure from stereo and 2d token tracking cooperation. </title> <booktitle> In Proceedings of the International Conference on Computer Vision, </booktitle> <pages> pages 513-516, </pages> <address> Osaka, Japan, </address> <month> December </month> <year> 1990. </year>
Reference-contexts: Details on various approaches for stereo-motion cooperation can be found in [7, 4, 15, 8]. We first investigate the theoretical lower bound on the amount of image measurements required for recovering the kinematics of the rig. This problem was studied in the past by <ref> [9] </ref> who showed that the projections of a pair of 3D lines are sufficient for a Linear solution for the rig's kinematics, i.e., two matching lines across two image-pairs (four images in all) are sufficient for recovering the parameters of the continuous 3D motion of the rig between the two time
Reference: [10] <author> A. Shashua and K. J. Hanna. </author> <title> The tensor brightness constraints: Direct estimation of motion revisited. </title> <type> Technical report, </type> <institution> Technion, Haifa, Israel, </institution> <month> November </month> <year> 1995. </year>
Reference-contexts: In the case of three views, the combination of camera motion and spatio-temporal derivatives gives rise to a model-based brightness constraint known as the "tensor brightness constraint" <ref> [10, 14, 13] </ref>.
Reference: [11] <author> G. P. Stein. </author> <title> Accurate internal camera calibration using rotation, with analysis of sources of error. </title> <booktitle> In Proceedings of the International Conference on Computer Vision, </booktitle> <pages> pages 230-236. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> June </month> <year> 1995. </year>
Reference-contexts: Consequently, motion 1 ! 2 is also assumed to be small, thus a coarse-to-fine framework is required for the implementation stage. 3 Implementation Details 3.1 Calibration We assume the internal parameters of the first camera are known. These can be found using methods described in <ref> [11] </ref>. For true Euclidean reconstruction an accurate estimate of the focal length is required but the whole process degrades gracefully when only approximate values are provided. Calibration of the stereo pair is performed in two stages.
Reference: [12] <author> G. P. Stein. </author> <title> Lens distortion calibration using point correspondences. </title> <booktitle> In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <address> Puerto Rico, </address> <month> June </month> <year> 1997. </year>
Reference-contexts: This does not affect 4 the stability of the method but the accuracy of the motion estimates is reduced and the 3D reconstruction suffers non-projective distortion. Flat surfaces and straight line appear slightly curved. A variety of methods to compute lens distortion appear in the literature (see <ref> [12] </ref>). 3.2 Computing Depth To compute the depth at every point we use equations 4,(5 and 7.
Reference: [13] <author> G. P. Stein. </author> <title> Geometric and Photometric Constraints: Motion and Structure from Three Views. </title> <type> PhD thesis, </type> <institution> M.I.T Artificial Intelligence Laboratory, </institution> <month> February </month> <year> 1998. </year>
Reference-contexts: In the case of three views, the combination of camera motion and spatio-temporal derivatives gives rise to a model-based brightness constraint known as the "tensor brightness constraint" <ref> [10, 14, 13] </ref>.
Reference: [14] <author> G. P. Stein and A. Shashua. </author> <title> Model based brightness constraints: On direct estimation of structure and motion. </title> <booktitle> In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <address> Puerto Rico, </address> <month> June </month> <year> 1997. </year>
Reference-contexts: In the case of three views, the combination of camera motion and spatio-temporal derivatives gives rise to a model-based brightness constraint known as the "tensor brightness constraint" <ref> [10, 14, 13] </ref>. <p> The second stage is to find the translation between the two cameras. We move the whole stereo rig in pure translation. Under the assumption of pure translation we can rewrite equation 19 as: I 00 t s 00&gt; t 00 = 0: (21) This equation, which appeared in <ref> [14] </ref>, can be used to accurately compute both the translation of the rig t 00 and the displacement between the two cameras t 0 (up to an unknown scale factor). 3.1.1 Lens Distortion Since we us are using a wide field-of-view (FOV) lens there is noticeable lens distortion. <p> Compute a new motion and depth estimate. One cannot simply compute the incremental model from the previous iteration because as the iterations proceed the system of equations of the incremental model will become badly conditioned. We followed the procedure in <ref> [14] </ref>. At the finest level (640 fi 480) we performed 2 iterations and we recursively doubled the number of iterations at the coarser levels. We can afford to do this because the number of computations per iteration at each levels drops by a factor of 4.
Reference: [15] <author> Z. Zhang and O. D. Faugeras. </author> <title> Three dimensional motion computation and segementation in a long sequnce of stereo frames. </title> <journal> International Journal of Computer Vision, </journal> <volume> 7(3) </volume> <pages> 211-241, </pages> <year> 1992. </year> <month> 8 </month>
Reference-contexts: The goal is to recover the motion (kinematics) of the rig and, by combining the stream of image pairs, to obtain a 3D reconstruction of the scene depicted by the image stream. Details on various approaches for stereo-motion cooperation can be found in <ref> [7, 4, 15, 8] </ref>. We first investigate the theoretical lower bound on the amount of image measurements required for recovering the kinematics of the rig.
References-found: 15

