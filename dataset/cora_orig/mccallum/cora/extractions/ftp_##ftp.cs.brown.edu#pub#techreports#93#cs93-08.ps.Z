URL: ftp://ftp.cs.brown.edu/pub/techreports/93/cs93-08.ps.Z
Refering-URL: http://www.cs.brown.edu/publications/techreports/reports/CS-93-08.html
Root-URL: http://www.cs.brown.edu/
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> A. Aggarwal, B. Alpern, A. Chandra, and M. Snir, </author> <title> "A Model for Hierarchical Memory," Procs. </title> <booktitle> 21st Annual ACM Symposium on Theory of Computing (May 15-17, </booktitle> <year> 1989), </year> <pages> 305-314. </pages>
Reference-contexts: They obtained tight bounds for sorting-related problems, including sorting, FFT, permutation networks, and matrix transposition. They did not handle the I/O-limited case or multiple levels. Aggarwal, Alpern, Chandra and Snir <ref> [1] </ref> introduced the hierarchy memory model (HMM), which treats memory as a linear array with cost f (x) to access location x in the array, and obtained tight bounds for a number of problems. They examined cost functions dlog xe, x, and x ff for ff 0.
Reference: [2] <author> A. Aggarwal, A. Chandra, and M. Snir, </author> <title> "Hierarchical Memory with Block Transfer," </title> <booktitle> Proc. 28th Annl. Symp. on Foundations of Computer Science (October 1987), </booktitle> <pages> 204-216. </pages>
Reference-contexts: They examined cost functions dlog xe, x, and x ff for ff 0. They don't handle blocks, show optimal algorithms for an arbitrary spectrum of memory sizes, nor handle the I/O-limited 4 case or large discontinuities in the storage access time between levels. Aggarwal, Chandra and Snir <ref> [2] </ref> introduced the BT model, an extension of the HMM model supporting block transfers. A block of size b ending at location x is allowed to move in time f (x) + b.
Reference: [3] <author> A. Aggarwal and J. S. Vitter, </author> <title> "The Input/Output Complexity of Sorting and Related Problems," </title> <booktitle> Communications of the ACM 31 (September 1988), </booktitle> <pages> 1116-1127. </pages>
Reference-contexts: Aggarwal and Vitter <ref> [3] </ref> examined a two-level memory in which P blocks of contiguous items can be transferred in each step. They obtained tight bounds for sorting-related problems, including sorting, FFT, permutation networks, and matrix transposition. They did not handle the I/O-limited case or multiple levels. <p> A bound on the S-span for the FFT is implicit in the work of Hong and Kung [11] and explicit in the work of Aggarwal and Vitter <ref> [3] </ref>. We state the bound and for completeness give a variant of the latter's proof. Lemma 4.4 The S-span of the FFT graph F (d) on n = 2 d inputs satisfies (S; G) 2S log S when S n.
Reference: [4] <author> B. Alpern, L. Carter, and E. Feig, </author> <title> "Uniform Memory Hierarchies," </title> <booktitle> Proc. 31st Annual Symposium on Foundations of Computer Science (October 22-24, </booktitle> <year> 1990), </year> <pages> 600-608. </pages>
Reference-contexts: They allow blocks to be arbitrarily large and problem dependent but do not handle the I/O-limited case nor large discontinuities in access time. Alpern, Carter and Feig <ref> [4] </ref> introduced the uniform memory hierarchy (UMH). The uth memory has capacity ff 2u , block size u , and time u =fi (u) to move a block between levels; fi (u) is a bandwidth function.
Reference: [5] <author> D. A. Carlson, </author> <title> "Time-Space Tradeoffs for Back-to-Back FFT Algorithms," </title> <journal> IEEE Trans. Computing C-32 (1983), </journal> <pages> 585-589. </pages>
Reference: [6] <author> D. A. Carlson, </author> <title> "Using Local Memory to Boost the Performance of FFT Algorithms on the CRAY-2 Supercomputer ," The Journal of Supercomputing 4 (1990), </title> <type> 345-356. </type>
Reference: [7] <author> D. A. Carlson, </author> <title> "Ultrahigh-Performance FFTs for the CRAY-2 and CRAY Y-MP Supercomputers," </title> <booktitle> The Journal of Supercomputing 6 (1992), </booktitle> <pages> 107-116. </pages>
Reference: [8] <author> J. J. Dongarra, J. D. Croz, S. Hammarling, and I. Duff, </author> <title> "A Set of Level 3 Basic Linear Algebra Subprograms," </title> <journal> ACM Trans. on Math. Soft. </journal> <month> 16 (March, </month> <year> 1990), </year> <pages> 1-17. </pages>
Reference-contexts: These problems are at the heart of scientific computation. Carlson has designed very fast two-level FFT algorithms for CRAY supercomputers [6,7] and Dongarra etal. <ref> [8] </ref> cite algorithms for memory hierarchies designed for linear algebra problems. 4.1 Matrix Multiplication We now derive a bound on the S-span of "butterfly-based level graphs," the FFT and related graphs on 2 d inputs, such as permutation networks based on three back-to-back FFT graphs P (d) [21], bitonic sorting networks
Reference: [9] <author> S. Even and A. Litman, </author> <title> "Layered Cross Product ATechnique to Construct Interconnection Networks," </title> <booktitle> Proc. 4th Ann. ACM Symp. on Parallel Algorithms and Architectures (June 29 - July 1, </booktitle> <year> 1992), </year> <pages> 60-69. </pages>
Reference-contexts: It is immediate from the layered cross-product representation of FFT graphs <ref> [9] </ref> that BS (d) is isomorphic to the FFT graph. Thus, the bounds for the FFT apply directly to BS (d) . From Lemma 3.2 it follows that lower bounds for the FFT apply to P (d) because P (d) reduces to F (d) .
Reference: [10] <author> D. Y. Grigoryev, </author> <title> "An Application of Separability and Independence Notions for Proving Lower Bounds of Circuit Complexity," Notes of Scientific Seminars, </title> <institution> Steklov Math. Inst. </institution> <month> 60 </month> <year> (1976), </year> <pages> 35-48. </pages>
Reference-contexts: It is O (n 2 ) for j &gt; k. 2 We close this section with a lower bound for the I/O-limited version of the game. It is based on the following lower bound due to Grigoryev <ref> [10] </ref> on the number of times that pebbles are placed on input vertices in the Red Pebble Game. (See Savage and Swamy [15] for a translation of Grigoryev's proof.) As explained in Section 2, the Red Pebble Game is generally viewed as a one-level game but is actually a two-level game
Reference: [11] <author> J. -W. Hong and H. T. Kung, </author> <title> "I/O Complexity: The Red-Blue Pebble Game," </title> <booktitle> Proc. 13th Ann. ACM Symp. on Theory of Computing (May 11-13, </booktitle> <year> 1981), </year> <pages> 326-333. </pages>
Reference-contexts: Not only are many important computational science algorithms described by dags, efficient prefetching in large memory hierarchies may require that all large computations be straight-line. The MHG generalizes to L levels the two-level game introduced by Hong and Kung <ref> [11] </ref>. The rules of the MHG assume that the values of input vertices of a dag G = (V; E) are kept in the level-L archival memory unit. <p> Each application of Rules 4, 5, and 6 is called an I/O operation. Applications of Rule 2 are not counted. Two restrictions of this game have been studied previously. The Red-Blue Pebble Game <ref> [11] </ref> is the standard MHG on two levels. It is used to investigate the number of I/O operations needed when the number of storage locations in the first-level memory is small. <p> to level L, we have the following simple facts. 7 Lemma 3.1 The following inequalities hold for any minimal MHG on G = (V; E) for 2 l L: (L) l (p; G) jIn (G)j + jOut (G)j; T (L) The following definition abstracts ideas used by Hong and Kung <ref> [11] </ref>. <p> For example, (S; G) 2S 3=2 for n fi n multiplication when S n 2 . The following theorem generalizes Hong-Kung <ref> [11] </ref> lower bound on I/O time for the two-level MHG. Our proof is new and far simpler. Theorem 3.1 Consider a minimal pebbling of the dag G = (V; E) in the standard MHG with resource vector p using s l pebbles at level j, 1 j l. <p> It follows that at most (2s l1 ; G) computation steps can be done on G in C t with level-1 pebbles. This completes the proof of this theorem. 2 9 Hong and Kung <ref> [11] </ref> derive their lower bound on the number of I/O operations in the Red-Blue Game by showing that at least S [P (2S) 1] I/O operations are necessary to pebble a graph with S red pebbles when P (S) is the minimum number of vertex sets in any "S-partition" of the <p> Developing good upper bounds under the I/O limitation is related to the challenging problem of deriving fast algorithms for matrix multiplication. We begin by deriving an upper bound on the S-span of G, (S; G), for matrix multiplication. We simplify the proof given by Hong and Kung <ref> [11] </ref> and illustrate how such bounds are derived. 12 Lemma 4.1 The S-span of any graph G associated with the classical algorithm to multiply two n fi n matrices with the binary operations of addition and multiplication of component values satisfies (S; G) 2S 3=2 for S n 2 . <p> A bound on the S-span for the FFT is implicit in the work of Hong and Kung <ref> [11] </ref> and explicit in the work of Aggarwal and Vitter [3]. We state the bound and for completeness give a variant of the latter's proof. Lemma 4.4 The S-span of the FFT graph F (d) on n = 2 d inputs satisfies (S; G) 2S log S when S n.
Reference: [12] <author> F. T. Leighton, </author> <title> in Introduction to Parallel Algorithms and Architectures, </title> <publisher> Mor-gan Kaufmann Publishers, Inc., </publisher> <address> San Mateo, CA, </address> <year> 1992. </year> <month> 27 </month>
Reference-contexts: for linear algebra problems. 4.1 Matrix Multiplication We now derive a bound on the S-span of "butterfly-based level graphs," the FFT and related graphs on 2 d inputs, such as permutation networks based on three back-to-back FFT graphs P (d) [21], bitonic sorting networks BS (d) for merging sorted lists <ref> [12, pp. 632] </ref>, and sorting networks S (d) based on bitonic sorting [12, pp. 633]. Consider a matrix multiplication algorithm conforming to the classical algorithm. All products of pairs of entries in the two matrices A and B are formed and combined in independent binary addition trees. <p> on the S-span of "butterfly-based level graphs," the FFT and related graphs on 2 d inputs, such as permutation networks based on three back-to-back FFT graphs P (d) [21], bitonic sorting networks BS (d) for merging sorted lists [12, pp. 632], and sorting networks S (d) based on bitonic sorting <ref> [12, pp. 633] </ref>. Consider a matrix multiplication algorithm conforming to the classical algorithm. All products of pairs of entries in the two matrices A and B are formed and combined in independent binary addition trees. <p> q &lt; 2 q + d q S &lt; 2 q+1 + d q 1 42 q when q + 1 log d (this is implied by S 2d), from which the result follows.2 4.3 Permutation and Merging Networks Consider next merging networks BS (d) based on bitonic sorting networks <ref> [12, pp. 632] </ref> and permutation networks P (d) based on three back-to-back FFT graphs [21]. 24 Replacing comparators in BS (d) with two-input butterfly graphs produces an FFT with edge directions reversed.
Reference: [13] <author> M. H. Nodine and J. S. Vitter, </author> <title> "Large-Scale Sorting in Parallel Memories (Ex--tended Abstract)," Procs. </title> <booktitle> 3rd Annual ACM Symposium on Parallel Algorithms and Architectures (July 21-24, </booktitle> <year> 1991), </year> <pages> 29-39. </pages>
Reference-contexts: Vitter and Shriver [20] examine three parallel memory systems in which the memories are disks with block transfer, of the HMM type, or of the BT type. They present a randomized version of distribution sort that meets the lower bounds for these models of computation. Nodine and Vitter <ref> [13] </ref> give an optimal deterministic sorting algorithm for these memory models.
Reference: [14] <author> M. S. Paterson and C. E. Hewitt, </author> <title> "Comparative Schematology," </title> <booktitle> Proc. Proj. MAC Conf. on Concurrent Systems and Parallel Computation (June 1970), </booktitle> <pages> 119-127. </pages>
Reference-contexts: The two-level I/O limited game is actually the Paterson-Hewitt <ref> [14] </ref> one-color pebble game while the two-level standard game is the Hong-Kung Red-Blue pebble game. Thus, the MHG combines elements of both games and generalizes them to multiple levels. <p> They allow I/O overlap between levels and determine conditions under which matrix transposition, matrix multiplication and Fourier transforms can and cannot be done efficiently. Savage and Vitter [17] extended the one-level Paterson-Hewitt model <ref> [14] </ref> to support parallel pebbling and the Hong-Kung model to support contiguous block I/O. Vitter and Shriver [20] examine three parallel memory systems in which the memories are disks with block transfer, of the HMM type, or of the BT type. <p> Two restrictions of this game have been studied previously. The Red-Blue Pebble Game [11] is the standard MHG on two levels. It is used to investigate the number of I/O operations needed when the number of storage locations in the first-level memory is small. The Red Pebble Game <ref> [14] </ref> is the two-level I/O-limited MHG game. (Rule 5 does not apply.) It is generally viewed as a one-level game because second-level pebbles can be placed only on input and output vertices.
Reference: [15] <author> J. E. Savage and S. Swamy, </author> <title> "Space-Time Tradeoffs for Oblivious Integer Multiplication," </title> <booktitle> in Lecture Notes in Computer Science, </booktitle> <editor> H. A. Maurer, ed., </editor> <publisher> Springer-Verlag, </publisher> <address> Berlin, Heidelberg, New York, </address> <month> July, </month> <year> 1979, </year> <pages> 498-504. </pages>
Reference-contexts: It is based on the following lower bound due to Grigoryev [10] on the number of times that pebbles are placed on input vertices in the Red Pebble Game. (See Savage and Swamy <ref> [15] </ref> for a translation of Grigoryev's proof.) As explained in Section 2, the Red Pebble Game is generally viewed as a one-level game but is actually a two-level game with the I/O limitation.
Reference: [16] <author> J. E. Savage and S. Swamy, </author> <title> "Space-Time Tradeoffs on the FFT Algorithm," </title> <journal> IEEE Trans. on Info. Th. </journal> <note> IT-24 (Sept. </note> <year> 1978), </year> <pages> 563-568. </pages>
Reference-contexts: We now show that these lower bounds can be achieved simultaneously on F (d) for 1 l L when the I/O limitation applies. Recall that the two-level MHG under the I/O limitation is exactly the Red Pebble Game. We begin by describing the construction given in <ref> [16] </ref> for this game and use it as a basis for constructing a pebbling in the MHG. Consider the decomposition of F (d) of Lemma 4.3 illustrated in Figure 2. In the Red Pebble Game, level-2 pebbles reside initially on input vertices.
Reference: [17] <author> J. E. Savage and J. S. Vitter, </author> <title> "Parallelism in Space-Time Tradeoffs," </title> <booktitle> in Advances in Computing Research, </booktitle> <editor> F. P. Preparata, ed., </editor> <year> 1987, </year> <pages> 117-146. </pages>
Reference-contexts: They allow I/O overlap between levels and determine conditions under which matrix transposition, matrix multiplication and Fourier transforms can and cannot be done efficiently. Savage and Vitter <ref> [17] </ref> extended the one-level Paterson-Hewitt model [14] to support parallel pebbling and the Hong-Kung model to support contiguous block I/O. Vitter and Shriver [20] examine three parallel memory systems in which the memories are disks with block transfer, of the HMM type, or of the BT type.
Reference: [18] <author> M. Tompa, </author> <title> "Time-Space Tradeoffs for Computing Functions, Using Connectivity Properties of Their Circuits," </title> <booktitle> JCSS 20 (1980), </booktitle> <pages> 118-132. </pages>
Reference: [19] <author> M. Tompa, </author> <title> "Corrigendum: Time-Space Tradeoffs for Computing Functions, Using Connectivity Properties of Their Circuits," </title> <journal> JCSS 23 (1981), </journal> <volume> 106. </volume>
Reference: [20] <author> J. S. Vitter and E. A. M. Shriver, </author> <title> "Optimal Disk I/O with Parallel Block Transfer," Procs. </title> <booktitle> 22nd Annual ACM Symposium on Theory of Computing (May 1990), </booktitle> <pages> 159-169. </pages>
Reference-contexts: Savage and Vitter [17] extended the one-level Paterson-Hewitt model [14] to support parallel pebbling and the Hong-Kung model to support contiguous block I/O. Vitter and Shriver <ref> [20] </ref> examine three parallel memory systems in which the memories are disks with block transfer, of the HMM type, or of the BT type. They present a randomized version of distribution sort that meets the lower bounds for these models of computation.
Reference: [21] <author> C. L. Wu and T. Y. Feng, </author> <title> "The Universality of the Shu*e-Exchange Network," </title> <journal> IEEE Trans. </journal> <note> Computing C-30 (May 1981), 324-332. 28 </note>
Reference-contexts: and Dongarra etal. [8] cite algorithms for memory hierarchies designed for linear algebra problems. 4.1 Matrix Multiplication We now derive a bound on the S-span of "butterfly-based level graphs," the FFT and related graphs on 2 d inputs, such as permutation networks based on three back-to-back FFT graphs P (d) <ref> [21] </ref>, bitonic sorting networks BS (d) for merging sorted lists [12, pp. 632], and sorting networks S (d) based on bitonic sorting [12, pp. 633]. Consider a matrix multiplication algorithm conforming to the classical algorithm. <p> 1 42 q when q + 1 log d (this is implied by S 2d), from which the result follows.2 4.3 Permutation and Merging Networks Consider next merging networks BS (d) based on bitonic sorting networks [12, pp. 632] and permutation networks P (d) based on three back-to-back FFT graphs <ref> [21] </ref>. 24 Replacing comparators in BS (d) with two-input butterfly graphs produces an FFT with edge directions reversed. It is immediate from the layered cross-product representation of FFT graphs [9] that BS (d) is isomorphic to the FFT graph.
References-found: 21

