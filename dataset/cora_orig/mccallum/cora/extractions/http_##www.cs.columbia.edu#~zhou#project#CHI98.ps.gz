URL: http://www.cs.columbia.edu/~zhou/project/CHI98.ps.gz
Refering-URL: http://www.cs.columbia.edu/~zhou/project/CHI98Title.html
Root-URL: http://www.cs.columbia.edu
Title: ABSTRACT  
Keyword: Automated design of graphics, visual discourse, visual task characterization.  
Abstract: To develop a comprehensive and systematic approach to the automated design of visual discourse, we introduce a visual task taxonomy that interfaces high-level presentation intents with low-level visual techniques. In our approach, visual tasks describe presentation intents through their visual accomplishments, and suggest desired visual techniques through their visual implications. Therefore, we can characterize visual tasks by their visual accomplishments and implications. Through this characterization, visual tasks can guide the visual discourse synthesis process by specifying what presentation intents can be achieved and how to achieve them. Keywords 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E. Andre and T. Rist. </author> <title> The design of illustrated documents as a planning task. </title> <editor> In M. Maybury, editor, </editor> <booktitle> Intelligent Multimedia Interfaces, chapter 4, </booktitle> <pages> pages 94116. </pages> <publisher> AAAI Press/The MIT Press, </publisher> <address> Menlo Park, CA, </address> <year> 1993. </year>
Reference-contexts: Of these researchers, only Sutcliffe et al. [24] briey mention four specific visual tasks (e.g., Highlight and Classify). For the purpose of automated visual discourse synthesis, researchers have classified various user information-seeking goals (e.g., [3, 21, 8]) or communicative acts (e.g., <ref> [1, 17, 23] </ref>). Although information-seeking goals or communicative acts serve different design purposes [20], they are similar in the sense that they both specify high-level presentation intents. To bridge the gap between high-level presentation intents and low-level visual techniques, a set of intermediate specifications is usually constructed. <p> Whereas perceptual operators are usually employed sequentially, visual tasks can be specified in parallel to achieve multiple visual effects simultaneously. Closest to our visual task specifications are visual acts, such as style strategies in [23], visual operators in <ref> [1] </ref>, and graphic acts in [17]. Like visual tasks, visual acts directly specify the visual effects. By our definition, however, visual acts such as Highlight, Zoom, and Include are more like low-level visual techniques than abstracted visual tasks. <p> Moreover, since systems that use visual acts deal mainly with real-world objects (e.g., <ref> [1, 23] </ref>) or existing presentations (e.g., a database of maps in [17]), they focus on visual manipulation instead of visual creation. Therefore, they rarely include or describe visual acts that can be used to create visual presentations from scratch (e.g., visual symbol encoding acts in graph creation).
Reference: [2] <institution> J. Bertin. Semiology of Graphics. Univ. of Wisconsin Press, Madison, WI, </institution> <year> 1983. </year> <note> (trans. by W.J. Berg). </note>
Reference-contexts: Visual accomplishments describe the type of presentation intents that a visual task might help to achieve, while visual implications specify a particular type of visual action that a visual task may carry out. Visual Accomplishments Informational visual presentations are usually charged with one of two intents <ref> [2, 20] </ref>: the presentation is intended either to simply convey a presenters message to a user or to help the user accomplish certain perceptual tasks such as search or verify. <p> In addition, Symbolize could be further refined to Quantify or Iconify an object, depending on what visual variable is involved. For example, Quantify implies that the object may be encoded effectively using the visual variable size, but not by shape or color <ref> [2, 4] </ref>, while Iconify implies that the object may be encoded by shape or color [14]. Visual Transformation To ensure visual discourse coherence, visual transformation cannot be ignored [32].
Reference: [3] <author> S. Casner. </author> <title> A task-analytic approach to the automated design of graphic presentations. </title> <journal> ACM Trans. on Graphics, </journal> <volume> 10(2):111151, </volume> <year> 1991. </year>
Reference-contexts: If an approach is to create effective presentations, it must accomplish a set of presentation intents associated with the discourse <ref> [3, 21, 23, 8] </ref>; for example, it may inform a user about some fact x or enable a user to search for information y, which we will notate as Inform&lt;?x&gt; or Search&lt;?y&gt;. <p> Of these researchers, only Sutcliffe et al. [24] briey mention four specific visual tasks (e.g., Highlight and Classify). For the purpose of automated visual discourse synthesis, researchers have classified various user information-seeking goals (e.g., <ref> [3, 21, 8] </ref>) or communicative acts (e.g., [1, 17, 23]). Although information-seeking goals or communicative acts serve different design purposes [20], they are similar in the sense that they both specify high-level presentation intents. <p> To bridge the gap between high-level presentation intents and low-level visual techniques, a set of intermediate specifications is usually constructed. One type of specification, known as perceptual operators (e.g., <ref> [3, 8] </ref>), indicates the perceptual tasks to be performed by the user in a visual environment. There are significant differences between a perceptual operator and a visual task.
Reference: [4] <author> W. Cleveland and R. McGill. </author> <title> Graphical perception: Theory, experimentation, and application to the development of graphical methods. </title> <journal> Journal of the American Statistical Association, </journal> <volume> 79:531554, </volume> <year> 1984. </year>
Reference-contexts: In addition, Symbolize could be further refined to Quantify or Iconify an object, depending on what visual variable is involved. For example, Quantify implies that the object may be encoded effectively using the visual variable size, but not by shape or color <ref> [2, 4] </ref>, while Iconify implies that the object may be encoded by shape or color [14]. Visual Transformation To ensure visual discourse coherence, visual transformation cannot be ignored [32].
Reference: [5] <author> M. Dalal, S. Feiner, K. McKeown, D. Jordan, B. Allen, and Y. alSafadi. </author> <title> MAGIC: An experimental system for generating multimedia briefings about post-bypass patient status. </title> <booktitle> In Proc. 1996 AMIA Annual Fall Symp, </booktitle> <pages> pages 684688, </pages> <address> Washington, DC, </address> <month> October 26-30 </month> <year> 1996. </year>
Reference-contexts: Present Patient Information to a Nurse As shown in Figure 8, the first task formulated by IMPROVISE is to Structure all patient information together, since our informal design studies <ref> [5] </ref> indicated that nurses prefer all relevant information be placed near a patients physical body and displayed at once (rather than successively revealed).
Reference: [6] <author> E. Goldsmith. </author> <title> Research Into Illustration: An Approach and A Review. </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge, </address> <year> 1984. </year>
Reference-contexts: Next we introduce a finer-grained categorization of visual tasks by their visual implications. Visual Implications Cognitive psychologists have conducted extensive studies to understand human visual perceptual behavior and reveal how visual cues can affect or direct perception (e.g., <ref> [25, 6, 12] </ref>). Based on these studies, a set of principles for visual perception and cognition has been formulated. From the standpoint of visual discourse synthesis, we have summarized three types of visual perception and cognition principles: visual organization, visual signaling, and visual transformation. <p> From the standpoint of visual discourse synthesis, we have summarized three types of visual perception and cognition principles: visual organization, visual signaling, and visual transformation. The visual organization principle suggests how people visually organize the world and perceive it as a coherent whole (e.g., <ref> [25, 6, 12] </ref>). The visual signaling principle explains how people tend to interpret visual cues and infer their meanings (e.g., [6]). The visual transformation principle explains how people switch attention and adapt to visual changes (e.g., [31]). <p> The visual organization principle suggests how people visually organize the world and perceive it as a coherent whole (e.g., [25, 6, 12]). The visual signaling principle explains how people tend to interpret visual cues and infer their meanings (e.g., <ref> [6] </ref>). The visual transformation principle explains how people switch attention and adapt to visual changes (e.g., [31]). Directed by these principles, we could categorize various visual tasks by their visual implications: whether they imply certain types of visual organization, certain ways of visual signaling, or certain paths of visual transformation. <p> However, since the definition of good form may depend on factors such as the viewers visual literacy, we do not discuss it here. Visual Attention. Cognitive psychology studies have shown that people are usually drawn to special visual features when they gaze at visual presentations (e.g., <ref> [25, 6] </ref>). As the process of recognizing these features does not require conscious attention [25], it is important to know what types of visual tasks imply such preattentive features. <p> Using this knowledge, presentation systems could employ these visual tasks to achieve related presentation intents, and use appropriate visual techniques to accomplish these tasks. Since we focus only on visual features independent of their semantics, our visual tasks are concerned only with syntactic emphasis as defined by Goldsmith <ref> [6] </ref>. Goldsmith summarizes eight important visual factors that help syntactic emphasis: color, position, size, isolation, complexity, tonal contrast, directionality, and implied motion. We examine whether a visual task implies exploiting any of these eight factors to attract or direct attention. <p> Spatial sequence indicates how people are intended to successively scan a presentation based on its elements positions, whereas perceptual sequence indicates how people order patterns or features by their visual appearance. Winn and Holliday [30] have summarized desired visual sequences used in charts, graphs and diagrams. Goldsmiths experiments <ref> [6] </ref> have also indicated how certain visual patterns guide ordered perception. Based on their results, we recognize a set of visual tasks that imply certain visual sequences in presentations.
Reference: [7] <author> B. Hunter, A. Crismore, and P. Pearson. </author> <title> Visual displays in basal readers and social studies textbooks. </title> <editor> In D. Willows and H. Houghton, editors, </editor> <booktitle> The Psychology of Illustration: Instructional Issues, </booktitle> <volume> volume 2, chapter 5, </volume> <pages> pages 116158. </pages> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1987. </year>
Reference-contexts: Finally, we present our conclusions and suggest future research directions. RELATED WORK To characterize different visual presentations and capture the relationships between presentation intents and visual cues, researchers have developed various taxonomies (e.g., <ref> [7, 13, 24, 29, 10] </ref>). Unlike our visual task taxonomy, previous taxonomies either broadly categorize the functions of pictures without examining their specific visual organizations (e.g., [7, 13]), or only describe conceptual relationships between information-seeking goals and various visual techniques (e.g., [29, 10]). <p> RELATED WORK To characterize different visual presentations and capture the relationships between presentation intents and visual cues, researchers have developed various taxonomies (e.g., [7, 13, 24, 29, 10]). Unlike our visual task taxonomy, previous taxonomies either broadly categorize the functions of pictures without examining their specific visual organizations (e.g., <ref> [7, 13] </ref>), or only describe conceptual relationships between information-seeking goals and various visual techniques (e.g., [29, 10]). Of these researchers, only Sutcliffe et al. [24] briey mention four specific visual tasks (e.g., Highlight and Classify). <p> Based on the level of detail, we divide visual signaling into two types: visual structuring and visual encoding. Visual structuring specifies the type of display <ref> [7, 14] </ref>, while visual encoding emphasizes visual symbol encoding, such as using visual variables (e.g., color, size, and shape) to encode an object or its attributes. Visual Structuring. We have combined several visual display taxonomies [7, 30, 11, 14] to categorize the displays in which we are interested. <p> Visual structuring specifies the type of display [7, 14], while visual encoding emphasizes visual symbol encoding, such as using visual variables (e.g., color, size, and shape) to encode an object or its attributes. Visual Structuring. We have combined several visual display taxonomies <ref> [7, 30, 11, 14] </ref> to categorize the displays in which we are interested. Based on this display categorization, we recognize five types of visual tasks: Tabulate, Plot, Structure, Trace, and Map. They imply five types of visual display: Visual Encoding.
Reference: [8] <author> E. Ignatius, H. Senay, and J. Favre. </author> <title> An intelligent system for task-specific visualization assistance. </title> <journal> J. of Visual Lang. and Computing, </journal> <volume> 5:321338, </volume> <year> 1994. </year>
Reference-contexts: If an approach is to create effective presentations, it must accomplish a set of presentation intents associated with the discourse <ref> [3, 21, 23, 8] </ref>; for example, it may inform a user about some fact x or enable a user to search for information y, which we will notate as Inform&lt;?x&gt; or Search&lt;?y&gt;. <p> Of these researchers, only Sutcliffe et al. [24] briey mention four specific visual tasks (e.g., Highlight and Classify). For the purpose of automated visual discourse synthesis, researchers have classified various user information-seeking goals (e.g., <ref> [3, 21, 8] </ref>) or communicative acts (e.g., [1, 17, 23]). Although information-seeking goals or communicative acts serve different design purposes [20], they are similar in the sense that they both specify high-level presentation intents. <p> To bridge the gap between high-level presentation intents and low-level visual techniques, a set of intermediate specifications is usually constructed. One type of specification, known as perceptual operators (e.g., <ref> [3, 8] </ref>), indicates the perceptual tasks to be performed by the user in a visual environment. There are significant differences between a perceptual operator and a visual task.
Reference: [9] <author> P. Johnson, H. Johnson, R. Waddington, and A. Shouls. </author> <title> Task-related knowledge structures: Analysis, modelling, and application. </title> <editor> In D. Jones and R. Winder, editors, </editor> <booktitle> People and Computers IV, Proc. of British SIGHCI, </booktitle> <pages> pages 3561. </pages> <publisher> Cambridge University Press, </publisher> <year> 1988. </year>
Reference-contexts: To decide which visual tasks may be used to achieve what presentation intent, we pair presentation intents and corresponding information categories together <ref> [9] </ref> (e.g., Verify&lt;object-composition&gt;). Then we infer how the specific presentation intent could be accomplished visually, based on both rhetorical and visual design principles [22, 18, 15, 26, 27, 19, 28]. For example, Verify&lt;object-composition&gt; requires displaying an object and its components. Thus, the visual task Reveal&lt;?x&gt; could facilitate perceptual verification.
Reference: [10] <author> P. R. Keller and M. M. Keller. </author> <title> Visual Cues: Practical Data Visualization. </title> <publisher> IEEE Computer Society Press and IEEE Press, </publisher> <year> 1993. </year>
Reference-contexts: However, it is difficult to formulate general rules that can directly relate high level presentation intents, such as Inform&lt;?x&gt;, to low-level visual techniques, such as Highlight&lt;?x&gt;. Based on a variety of visual presentations from different sources (e.g., <ref> [22, 26, 27, 10, 28] </ref>), and our own work on visual discourse synthesis [32], we believe that there is a level of abstraction midway between presentation intents and low-level visual techniques. We refer to this level of abstraction as a visual task taxonomy. <p> Finally, we present our conclusions and suggest future research directions. RELATED WORK To characterize different visual presentations and capture the relationships between presentation intents and visual cues, researchers have developed various taxonomies (e.g., <ref> [7, 13, 24, 29, 10] </ref>). Unlike our visual task taxonomy, previous taxonomies either broadly categorize the functions of pictures without examining their specific visual organizations (e.g., [7, 13]), or only describe conceptual relationships between information-seeking goals and various visual techniques (e.g., [29, 10]). <p> Unlike our visual task taxonomy, previous taxonomies either broadly categorize the functions of pictures without examining their specific visual organizations (e.g., [7, 13]), or only describe conceptual relationships between information-seeking goals and various visual techniques (e.g., <ref> [29, 10] </ref>). Of these researchers, only Sutcliffe et al. [24] briey mention four specific visual tasks (e.g., Highlight and Classify). For the purpose of automated visual discourse synthesis, researchers have classified various user information-seeking goals (e.g., [3, 21, 8]) or communicative acts (e.g., [1, 17, 23]). <p> In contrast, our visual task taxonomy covers both high-level visual organization and low-level visual symbol encoding tasks. VISUAL TASK CHARACTERIZATION Building on previous work <ref> [29, 10, 17, 24] </ref>, we have derived a taxonomy of visual tasks, shown in Figure 1. Like a visual act, each visual task is described by two parts: an act and a set of arguments to act on. <p> Position&lt;devices, patient-body&gt; 4. Itemize&lt;demographics&gt; 5. Name&lt;demographics, name&gt; 6. Symbolize&lt;lines&gt; 7. Name (lines, line-name&gt; 8. Associate&lt;lines, contents&gt; 9. Symbolize&lt;other-devices&gt; 10. Name&lt;other-devices, device-name&gt; 11. Associate&lt;other-devices, parameters&gt; DesignVisRep&lt;demographics, ?title&gt; DesignVisRep&lt;devices, ?elements&gt; DesignVisRep&lt;patient, ?body&gt; DesignTable&lt;demographics, ?table&gt; DesignVisRep&lt;name, ?table-title&gt; DesignVisRep&lt;lines, ?line&gt; DesignVisRep&lt;line-name,?line-label&gt; DesignVisRep&lt;content, ?content-label&gt; DesignVisRep&lt;other-devices, ?device&gt; DesignVisRep&lt;device-name,?device-label&gt; DesignVisRep&lt;content, ?content-label&gt; of visual presentations (e.g, <ref> [26, 27, 10, 28] </ref>) and integration of both rhetorical and visual design theories (e.g., [22, 18, 30, 15, 11, 19]). Moreover, these task specifications are being used in our experimental visual discourse synthesis system IMPROVISE to test their practical value.
Reference: [11] <author> S. Kosslyn. </author> <title> Understanding charts and graphs. </title> <journal> Applied Cognitive Psychology, </journal> <volume> 3:185226, </volume> <year> 1989. </year>
Reference-contexts: Visual Organization Visual organization could be described from several aspects such as overall pattern or sequence of the organization (e.g., [30]), preattentive features of the organization (e.g, [25]), and various visual relationships among visual elements (e.g., <ref> [11, 12] </ref>). Generalizing from this previous work, we have compiled a comprehensive set of features to describe various aspects of visual organization: visual grouping, visual attention, visual sequence, and visual composition. Visual grouping is concerned with how visual patterns could be grouped together so people can perceive them as groups. <p> Other visual tasks suggesting closure are: Besides proximity, similarity, continuity, and closure, symmetry groups objects by a sense of good form <ref> [11] </ref>. However, since the definition of good form may depend on factors such as the viewers visual literacy, we do not discuss it here. Visual Attention. Cognitive psychology studies have shown that people are usually drawn to special visual features when they gaze at visual presentations (e.g., [25, 6]). <p> Visual structuring specifies the type of display [7, 14], while visual encoding emphasizes visual symbol encoding, such as using visual variables (e.g., color, size, and shape) to encode an object or its attributes. Visual Structuring. We have combined several visual display taxonomies <ref> [7, 30, 11, 14] </ref> to categorize the displays in which we are interested. Based on this display categorization, we recognize five types of visual tasks: Tabulate, Plot, Structure, Trace, and Map. They imply five types of visual display: Visual Encoding. <p> Associate&lt;lines, contents&gt; 9. Symbolize&lt;other-devices&gt; 10. Name&lt;other-devices, device-name&gt; 11. Associate&lt;other-devices, parameters&gt; DesignVisRep&lt;demographics, ?title&gt; DesignVisRep&lt;devices, ?elements&gt; DesignVisRep&lt;patient, ?body&gt; DesignTable&lt;demographics, ?table&gt; DesignVisRep&lt;name, ?table-title&gt; DesignVisRep&lt;lines, ?line&gt; DesignVisRep&lt;line-name,?line-label&gt; DesignVisRep&lt;content, ?content-label&gt; DesignVisRep&lt;other-devices, ?device&gt; DesignVisRep&lt;device-name,?device-label&gt; DesignVisRep&lt;content, ?content-label&gt; of visual presentations (e.g, [26, 27, 10, 28]) and integration of both rhetorical and visual design theories (e.g., <ref> [22, 18, 30, 15, 11, 19] </ref>). Moreover, these task specifications are being used in our experimental visual discourse synthesis system IMPROVISE to test their practical value. To use visual task specifications in automated visual discourse synthesis, we have characterized them by their visual accomplishments and implications.
Reference: [12] <author> W. Levie. </author> <title> Research on pictures: a guide to the literature. </title> <editor> In D. Willows and H. Houghton, editors, </editor> <title> The Psychology of Illustration: </title> <journal> Basic Research, </journal> <volume> volume 1, chapter 2, </volume> <pages> pages 150. </pages> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1987. </year>
Reference-contexts: Next we introduce a finer-grained categorization of visual tasks by their visual implications. Visual Implications Cognitive psychologists have conducted extensive studies to understand human visual perceptual behavior and reveal how visual cues can affect or direct perception (e.g., <ref> [25, 6, 12] </ref>). Based on these studies, a set of principles for visual perception and cognition has been formulated. From the standpoint of visual discourse synthesis, we have summarized three types of visual perception and cognition principles: visual organization, visual signaling, and visual transformation. <p> From the standpoint of visual discourse synthesis, we have summarized three types of visual perception and cognition principles: visual organization, visual signaling, and visual transformation. The visual organization principle suggests how people visually organize the world and perceive it as a coherent whole (e.g., <ref> [25, 6, 12] </ref>). The visual signaling principle explains how people tend to interpret visual cues and infer their meanings (e.g., [6]). The visual transformation principle explains how people switch attention and adapt to visual changes (e.g., [31]). <p> Visual Organization Visual organization could be described from several aspects such as overall pattern or sequence of the organization (e.g., [30]), preattentive features of the organization (e.g, [25]), and various visual relationships among visual elements (e.g., <ref> [11, 12] </ref>). Generalizing from this previous work, we have compiled a comprehensive set of features to describe various aspects of visual organization: visual grouping, visual attention, visual sequence, and visual composition. Visual grouping is concerned with how visual patterns could be grouped together so people can perceive them as groups.
Reference: [13] <author> J. Levin, G. Anglin, and R. Carney. </author> <title> On empirically validating functions of pictures in prose. </title> <editor> In D. Willows and H. Houghton, editors, </editor> <title> The Psychology of Illustration: </title> <journal> Basic Research, </journal> <volume> volume 1, chapter 2, </volume> <pages> pages 5186. </pages> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1987. </year>
Reference-contexts: Finally, we present our conclusions and suggest future research directions. RELATED WORK To characterize different visual presentations and capture the relationships between presentation intents and visual cues, researchers have developed various taxonomies (e.g., <ref> [7, 13, 24, 29, 10] </ref>). Unlike our visual task taxonomy, previous taxonomies either broadly categorize the functions of pictures without examining their specific visual organizations (e.g., [7, 13]), or only describe conceptual relationships between information-seeking goals and various visual techniques (e.g., [29, 10]). <p> RELATED WORK To characterize different visual presentations and capture the relationships between presentation intents and visual cues, researchers have developed various taxonomies (e.g., [7, 13, 24, 29, 10]). Unlike our visual task taxonomy, previous taxonomies either broadly categorize the functions of pictures without examining their specific visual organizations (e.g., <ref> [7, 13] </ref>), or only describe conceptual relationships between information-seeking goals and various visual techniques (e.g., [29, 10]). Of these researchers, only Sutcliffe et al. [24] briey mention four specific visual tasks (e.g., Highlight and Classify). <p> As listed in Figure 2, many visual tasks could help to achieve different presentation intents at once in different ways <ref> [13] </ref>. For example, the visual task Compare&lt;?x, ?y&gt; could aid in accomplishing the intent Inform&lt;?x&gt; by indicating the similarity between ?x and ?y (Intersect&lt;?x, ?y&gt;), and could also help to achieve the intent Verify&lt;?x&gt; by showing a difference (Differentiate&lt;?x, ?y&gt;).
Reference: [14] <author> G. Lohse, K. Biolsi, and H. Rueter. </author> <title> A classification of visual representations. </title> <journal> Communications of the ACM, </journal> <volume> 37(12):3649, </volume> <year> 1994. </year>
Reference-contexts: Based on the level of detail, we divide visual signaling into two types: visual structuring and visual encoding. Visual structuring specifies the type of display <ref> [7, 14] </ref>, while visual encoding emphasizes visual symbol encoding, such as using visual variables (e.g., color, size, and shape) to encode an object or its attributes. Visual Structuring. We have combined several visual display taxonomies [7, 30, 11, 14] to categorize the displays in which we are interested. <p> Visual structuring specifies the type of display [7, 14], while visual encoding emphasizes visual symbol encoding, such as using visual variables (e.g., color, size, and shape) to encode an object or its attributes. Visual Structuring. We have combined several visual display taxonomies <ref> [7, 30, 11, 14] </ref> to categorize the displays in which we are interested. Based on this display categorization, we recognize five types of visual tasks: Tabulate, Plot, Structure, Trace, and Map. They imply five types of visual display: Visual Encoding. <p> For example, Quantify implies that the object may be encoded effectively using the visual variable size, but not by shape or color [2, 4], while Iconify implies that the object may be encoded by shape or color <ref> [14] </ref>. Visual Transformation To ensure visual discourse coherence, visual transformation cannot be ignored [32]. Visual transformation can help integrate new information into the current display to achieve unity; or gradually transform the current display into a new one to achieve continuity. <p> As mentioned in the last section, Structure implies constructing a structure diagram (DesignStructureDiagram in Figure 8), which is capable of conveying a physical structure (e.g., the patient body) and expressing the spatial coordinates for related objects (e.g., medical devices) <ref> [30, 14] </ref>. DesignStructureDia-gram produces an empty structure diagram, and other visual tasks help refine it.
Reference: [15] <author> W. Mann and S. Thompson. </author> <title> Rhetorical structure theory: Towards a functional theory of text organization. </title> <booktitle> In TEXT, </booktitle> <volume> volume 2, </volume> <pages> pages 243 281. </pages> <publisher> Springer, </publisher> <year> 1988. </year>
Reference-contexts: To decide which visual tasks may be used to achieve what presentation intent, we pair presentation intents and corresponding information categories together [9] (e.g., Verify&lt;object-composition&gt;). Then we infer how the specific presentation intent could be accomplished visually, based on both rhetorical and visual design principles <ref> [22, 18, 15, 26, 27, 19, 28] </ref>. For example, Verify&lt;object-composition&gt; requires displaying an object and its components. Thus, the visual task Reveal&lt;?x&gt; could facilitate perceptual verification. <p> Associate&lt;lines, contents&gt; 9. Symbolize&lt;other-devices&gt; 10. Name&lt;other-devices, device-name&gt; 11. Associate&lt;other-devices, parameters&gt; DesignVisRep&lt;demographics, ?title&gt; DesignVisRep&lt;devices, ?elements&gt; DesignVisRep&lt;patient, ?body&gt; DesignTable&lt;demographics, ?table&gt; DesignVisRep&lt;name, ?table-title&gt; DesignVisRep&lt;lines, ?line&gt; DesignVisRep&lt;line-name,?line-label&gt; DesignVisRep&lt;content, ?content-label&gt; DesignVisRep&lt;other-devices, ?device&gt; DesignVisRep&lt;device-name,?device-label&gt; DesignVisRep&lt;content, ?content-label&gt; of visual presentations (e.g, [26, 27, 10, 28]) and integration of both rhetorical and visual design theories (e.g., <ref> [22, 18, 30, 15, 11, 19] </ref>). Moreover, these task specifications are being used in our experimental visual discourse synthesis system IMPROVISE to test their practical value. To use visual task specifications in automated visual discourse synthesis, we have characterized them by their visual accomplishments and implications.
Reference: [16] <author> J. Marks. </author> <title> A formal specification scheme for network diagrams that facilitates automated design. </title> <editor> J. </editor> <booktitle> of Visual Languages and Computing, </booktitle> <address> 2(4):395414, </address> <year> 1991. </year>
Reference-contexts: In comparison, our visual task taxonomy presents an abstraction above low-level visual techniques and addresses both visual creation and manipulation. It is also worth noting that the pragmatic directives proposed by Marks <ref> [16] </ref> are different from any of the taxonomies mentioned above. They more or less directly imply the underlying visual organization or layout (e.g., a particular network path or a hub), but do not imply or suggest any of the low-level attribute encodings.
Reference: [17] <author> M. </author> <title> Maybury. Planning multimedia explanations using communicative acts. </title> <editor> In M. Maybury, editor, </editor> <booktitle> Intelligent Multimedia Interfaces, chapter 2, </booktitle> <pages> pages 6074. </pages> <publisher> AAAI Press/The MIT Press, </publisher> <address> Menlo Park, CA, </address> <year> 1993. </year>
Reference-contexts: Of these researchers, only Sutcliffe et al. [24] briey mention four specific visual tasks (e.g., Highlight and Classify). For the purpose of automated visual discourse synthesis, researchers have classified various user information-seeking goals (e.g., [3, 21, 8]) or communicative acts (e.g., <ref> [1, 17, 23] </ref>). Although information-seeking goals or communicative acts serve different design purposes [20], they are similar in the sense that they both specify high-level presentation intents. To bridge the gap between high-level presentation intents and low-level visual techniques, a set of intermediate specifications is usually constructed. <p> Whereas perceptual operators are usually employed sequentially, visual tasks can be specified in parallel to achieve multiple visual effects simultaneously. Closest to our visual task specifications are visual acts, such as style strategies in [23], visual operators in [1], and graphic acts in <ref> [17] </ref>. Like visual tasks, visual acts directly specify the visual effects. By our definition, however, visual acts such as Highlight, Zoom, and Include are more like low-level visual techniques than abstracted visual tasks. <p> Moreover, since systems that use visual acts deal mainly with real-world objects (e.g., [1, 23]) or existing presentations (e.g., a database of maps in <ref> [17] </ref>), they focus on visual manipulation instead of visual creation. Therefore, they rarely include or describe visual acts that can be used to create visual presentations from scratch (e.g., visual symbol encoding acts in graph creation). <p> In contrast, our visual task taxonomy covers both high-level visual organization and low-level visual symbol encoding tasks. VISUAL TASK CHARACTERIZATION Building on previous work <ref> [29, 10, 17, 24] </ref>, we have derived a taxonomy of visual tasks, shown in Figure 1. Like a visual act, each visual task is described by two parts: an act and a set of arguments to act on.
Reference: [18] <author> K. McKeown. </author> <title> Text Generation. </title> <publisher> Cambridge University Press, </publisher> <address> London, </address> <year> 1985. </year>
Reference-contexts: To decide which visual tasks may be used to achieve what presentation intent, we pair presentation intents and corresponding information categories together [9] (e.g., Verify&lt;object-composition&gt;). Then we infer how the specific presentation intent could be accomplished visually, based on both rhetorical and visual design principles <ref> [22, 18, 15, 26, 27, 19, 28] </ref>. For example, Verify&lt;object-composition&gt; requires displaying an object and its components. Thus, the visual task Reveal&lt;?x&gt; could facilitate perceptual verification. <p> Associate&lt;lines, contents&gt; 9. Symbolize&lt;other-devices&gt; 10. Name&lt;other-devices, device-name&gt; 11. Associate&lt;other-devices, parameters&gt; DesignVisRep&lt;demographics, ?title&gt; DesignVisRep&lt;devices, ?elements&gt; DesignVisRep&lt;patient, ?body&gt; DesignTable&lt;demographics, ?table&gt; DesignVisRep&lt;name, ?table-title&gt; DesignVisRep&lt;lines, ?line&gt; DesignVisRep&lt;line-name,?line-label&gt; DesignVisRep&lt;content, ?content-label&gt; DesignVisRep&lt;other-devices, ?device&gt; DesignVisRep&lt;device-name,?device-label&gt; DesignVisRep&lt;content, ?content-label&gt; of visual presentations (e.g, [26, 27, 10, 28]) and integration of both rhetorical and visual design theories (e.g., <ref> [22, 18, 30, 15, 11, 19] </ref>). Moreover, these task specifications are being used in our experimental visual discourse synthesis system IMPROVISE to test their practical value. To use visual task specifications in automated visual discourse synthesis, we have characterized them by their visual accomplishments and implications.
Reference: [19] <author> K. Mullet and D. Sano. </author> <title> Designing Visual Interfaces. </title> <publisher> SunSoft Press, </publisher> <address> Mountain View, CA, </address> <year> 1995. </year>
Reference-contexts: To decide which visual tasks may be used to achieve what presentation intent, we pair presentation intents and corresponding information categories together [9] (e.g., Verify&lt;object-composition&gt;). Then we infer how the specific presentation intent could be accomplished visually, based on both rhetorical and visual design principles <ref> [22, 18, 15, 26, 27, 19, 28] </ref>. For example, Verify&lt;object-composition&gt; requires displaying an object and its components. Thus, the visual task Reveal&lt;?x&gt; could facilitate perceptual verification. <p> Next, we describe how various visual tasks are characterized by these four aspects. Visual Grouping. According to gestalt psychology, people group different visual elements together by certain patterns: proximity, similarity, continuity, and closure <ref> [19] </ref>. Proximity states that objects that are spatially close will be perceived as being together. For example, Figure 3 presents information about a car to a customer. <p> Associate&lt;lines, contents&gt; 9. Symbolize&lt;other-devices&gt; 10. Name&lt;other-devices, device-name&gt; 11. Associate&lt;other-devices, parameters&gt; DesignVisRep&lt;demographics, ?title&gt; DesignVisRep&lt;devices, ?elements&gt; DesignVisRep&lt;patient, ?body&gt; DesignTable&lt;demographics, ?table&gt; DesignVisRep&lt;name, ?table-title&gt; DesignVisRep&lt;lines, ?line&gt; DesignVisRep&lt;line-name,?line-label&gt; DesignVisRep&lt;content, ?content-label&gt; DesignVisRep&lt;other-devices, ?device&gt; DesignVisRep&lt;device-name,?device-label&gt; DesignVisRep&lt;content, ?content-label&gt; of visual presentations (e.g, [26, 27, 10, 28]) and integration of both rhetorical and visual design theories (e.g., <ref> [22, 18, 30, 15, 11, 19] </ref>). Moreover, these task specifications are being used in our experimental visual discourse synthesis system IMPROVISE to test their practical value. To use visual task specifications in automated visual discourse synthesis, we have characterized them by their visual accomplishments and implications.
Reference: [20] <author> S. Roth and W. Hefley. </author> <title> Intelligent multimedia presentation systems: Research and principles. </title> <editor> In M. Maybury, editor, </editor> <booktitle> Intelligent Multimedia Interfaces, chapter 1, </booktitle> <pages> pages 1358. </pages> <publisher> AAAI Press/The MIT Press, </publisher> <address> Menlo Park, CA, </address> <year> 1993. </year>
Reference-contexts: For the purpose of automated visual discourse synthesis, researchers have classified various user information-seeking goals (e.g., [3, 21, 8]) or communicative acts (e.g., [1, 17, 23]). Although information-seeking goals or communicative acts serve different design purposes <ref> [20] </ref>, they are similar in the sense that they both specify high-level presentation intents. To bridge the gap between high-level presentation intents and low-level visual techniques, a set of intermediate specifications is usually constructed. <p> Visual accomplishments describe the type of presentation intents that a visual task might help to achieve, while visual implications specify a particular type of visual action that a visual task may carry out. Visual Accomplishments Informational visual presentations are usually charged with one of two intents <ref> [2, 20] </ref>: the presentation is intended either to simply convey a presenters message to a user or to help the user accomplish certain perceptual tasks such as search or verify. <p> Two different examples generated by IMPROVISE illustrate the visual-task-oriented synthesis process. To construct a complete visual discourse synthesis system, visual task characterization must be combined with other areas of research, such as data characterization and visual principle modeling <ref> [20] </ref>. Formal user studies will also be essential to provide a more comprehensive and accurate evaluation of the current set of visual tasks. For example, we would like to determine how well users can employ the visual task descriptions to describe visual presentations, and the range of presentations they can describe.
Reference: [21] <author> S. F. Roth and J. Mattis. </author> <title> Automating the presentation of information. </title> <booktitle> In Proc. IEEE Conf. on AI Applications, </booktitle> <pages> pages 9097, </pages> <year> 1991. </year>
Reference-contexts: If an approach is to create effective presentations, it must accomplish a set of presentation intents associated with the discourse <ref> [3, 21, 23, 8] </ref>; for example, it may inform a user about some fact x or enable a user to search for information y, which we will notate as Inform&lt;?x&gt; or Search&lt;?y&gt;. <p> Of these researchers, only Sutcliffe et al. [24] briey mention four specific visual tasks (e.g., Highlight and Classify). For the purpose of automated visual discourse synthesis, researchers have classified various user information-seeking goals (e.g., <ref> [3, 21, 8] </ref>) or communicative acts (e.g., [1, 17, 23]). Although information-seeking goals or communicative acts serve different design purposes [20], they are similar in the sense that they both specify high-level presentation intents.
Reference: [22] <author> C. Schmid. </author> <title> Handbook of graphic presentation. </title> <publisher> The Ronald Press, </publisher> <address> New York, </address> <year> 1954. </year>
Reference-contexts: However, it is difficult to formulate general rules that can directly relate high level presentation intents, such as Inform&lt;?x&gt;, to low-level visual techniques, such as Highlight&lt;?x&gt;. Based on a variety of visual presentations from different sources (e.g., <ref> [22, 26, 27, 10, 28] </ref>), and our own work on visual discourse synthesis [32], we believe that there is a level of abstraction midway between presentation intents and low-level visual techniques. We refer to this level of abstraction as a visual task taxonomy. <p> To decide which visual tasks may be used to achieve what presentation intent, we pair presentation intents and corresponding information categories together [9] (e.g., Verify&lt;object-composition&gt;). Then we infer how the specific presentation intent could be accomplished visually, based on both rhetorical and visual design principles <ref> [22, 18, 15, 26, 27, 19, 28] </ref>. For example, Verify&lt;object-composition&gt; requires displaying an object and its components. Thus, the visual task Reveal&lt;?x&gt; could facilitate perceptual verification. <p> Associate&lt;lines, contents&gt; 9. Symbolize&lt;other-devices&gt; 10. Name&lt;other-devices, device-name&gt; 11. Associate&lt;other-devices, parameters&gt; DesignVisRep&lt;demographics, ?title&gt; DesignVisRep&lt;devices, ?elements&gt; DesignVisRep&lt;patient, ?body&gt; DesignTable&lt;demographics, ?table&gt; DesignVisRep&lt;name, ?table-title&gt; DesignVisRep&lt;lines, ?line&gt; DesignVisRep&lt;line-name,?line-label&gt; DesignVisRep&lt;content, ?content-label&gt; DesignVisRep&lt;other-devices, ?device&gt; DesignVisRep&lt;device-name,?device-label&gt; DesignVisRep&lt;content, ?content-label&gt; of visual presentations (e.g, [26, 27, 10, 28]) and integration of both rhetorical and visual design theories (e.g., <ref> [22, 18, 30, 15, 11, 19] </ref>). Moreover, these task specifications are being used in our experimental visual discourse synthesis system IMPROVISE to test their practical value. To use visual task specifications in automated visual discourse synthesis, we have characterized them by their visual accomplishments and implications.
Reference: [23] <author> D. Seligmann. </author> <title> A Visual Language for Automated 3D Graphics Generation. </title> <type> PhD thesis, </type> <institution> Columbia University, </institution> <address> New York, NY, </address> <year> 1993. </year>
Reference-contexts: If an approach is to create effective presentations, it must accomplish a set of presentation intents associated with the discourse <ref> [3, 21, 23, 8] </ref>; for example, it may inform a user about some fact x or enable a user to search for information y, which we will notate as Inform&lt;?x&gt; or Search&lt;?y&gt;. <p> Of these researchers, only Sutcliffe et al. [24] briey mention four specific visual tasks (e.g., Highlight and Classify). For the purpose of automated visual discourse synthesis, researchers have classified various user information-seeking goals (e.g., [3, 21, 8]) or communicative acts (e.g., <ref> [1, 17, 23] </ref>). Although information-seeking goals or communicative acts serve different design purposes [20], they are similar in the sense that they both specify high-level presentation intents. To bridge the gap between high-level presentation intents and low-level visual techniques, a set of intermediate specifications is usually constructed. <p> Whereas perceptual operators are usually employed sequentially, visual tasks can be specified in parallel to achieve multiple visual effects simultaneously. Closest to our visual task specifications are visual acts, such as style strategies in <ref> [23] </ref>, visual operators in [1], and graphic acts in [17]. Like visual tasks, visual acts directly specify the visual effects. By our definition, however, visual acts such as Highlight, Zoom, and Include are more like low-level visual techniques than abstracted visual tasks. <p> Moreover, since systems that use visual acts deal mainly with real-world objects (e.g., <ref> [1, 23] </ref>) or existing presentations (e.g., a database of maps in [17]), they focus on visual manipulation instead of visual creation. Therefore, they rarely include or describe visual acts that can be used to create visual presentations from scratch (e.g., visual symbol encoding acts in graph creation).
Reference: [24] <author> A. Sutcliffe and J. Darzentas. </author> <title> Use of visual media in explanation. </title> <editor> In M. Tauber, D. Mahling, and F. Arefi, editors, </editor> <booktitle> Cognitive Aspects of Visual Languages and Visual Interfaces, chapter 2, </booktitle> <pages> pages 105132. </pages> <publisher> Elsevier Science B.V., </publisher> <address> Amsterdam, </address> <year> 1994. </year>
Reference-contexts: Finally, we present our conclusions and suggest future research directions. RELATED WORK To characterize different visual presentations and capture the relationships between presentation intents and visual cues, researchers have developed various taxonomies (e.g., <ref> [7, 13, 24, 29, 10] </ref>). Unlike our visual task taxonomy, previous taxonomies either broadly categorize the functions of pictures without examining their specific visual organizations (e.g., [7, 13]), or only describe conceptual relationships between information-seeking goals and various visual techniques (e.g., [29, 10]). <p> Unlike our visual task taxonomy, previous taxonomies either broadly categorize the functions of pictures without examining their specific visual organizations (e.g., [7, 13]), or only describe conceptual relationships between information-seeking goals and various visual techniques (e.g., [29, 10]). Of these researchers, only Sutcliffe et al. <ref> [24] </ref> briey mention four specific visual tasks (e.g., Highlight and Classify). For the purpose of automated visual discourse synthesis, researchers have classified various user information-seeking goals (e.g., [3, 21, 8]) or communicative acts (e.g., [1, 17, 23]). <p> In contrast, our visual task taxonomy covers both high-level visual organization and low-level visual symbol encoding tasks. VISUAL TASK CHARACTERIZATION Building on previous work <ref> [29, 10, 17, 24] </ref>, we have derived a taxonomy of visual tasks, shown in Figure 1. Like a visual act, each visual task is described by two parts: an act and a set of arguments to act on.
Reference: [25] <author> A. Treisman. </author> <title> Perceptual grouping and attention in visual search for features and for objects. J. of Experimental Psychology: Human Perception and Performance, </title> <address> 8(2):194214, </address> <year> 1982. </year>
Reference-contexts: Next we introduce a finer-grained categorization of visual tasks by their visual implications. Visual Implications Cognitive psychologists have conducted extensive studies to understand human visual perceptual behavior and reveal how visual cues can affect or direct perception (e.g., <ref> [25, 6, 12] </ref>). Based on these studies, a set of principles for visual perception and cognition has been formulated. From the standpoint of visual discourse synthesis, we have summarized three types of visual perception and cognition principles: visual organization, visual signaling, and visual transformation. <p> From the standpoint of visual discourse synthesis, we have summarized three types of visual perception and cognition principles: visual organization, visual signaling, and visual transformation. The visual organization principle suggests how people visually organize the world and perceive it as a coherent whole (e.g., <ref> [25, 6, 12] </ref>). The visual signaling principle explains how people tend to interpret visual cues and infer their meanings (e.g., [6]). The visual transformation principle explains how people switch attention and adapt to visual changes (e.g., [31]). <p> Visual Organization Visual organization could be described from several aspects such as overall pattern or sequence of the organization (e.g., [30]), preattentive features of the organization (e.g, <ref> [25] </ref>), and various visual relationships among visual elements (e.g., [11, 12]). Generalizing from this previous work, we have compiled a comprehensive set of features to describe various aspects of visual organization: visual grouping, visual attention, visual sequence, and visual composition. <p> However, since the definition of good form may depend on factors such as the viewers visual literacy, we do not discuss it here. Visual Attention. Cognitive psychology studies have shown that people are usually drawn to special visual features when they gaze at visual presentations (e.g., <ref> [25, 6] </ref>). As the process of recognizing these features does not require conscious attention [25], it is important to know what types of visual tasks imply such preattentive features. <p> Visual Attention. Cognitive psychology studies have shown that people are usually drawn to special visual features when they gaze at visual presentations (e.g., [25, 6]). As the process of recognizing these features does not require conscious attention <ref> [25] </ref>, it is important to know what types of visual tasks imply such preattentive features. Using this knowledge, presentation systems could employ these visual tasks to achieve related presentation intents, and use appropriate visual techniques to accomplish these tasks. <p> In other words, the visual task Reinforce implies attracting and directing attention. The visual tasks related to visual attention are: Visual Sequence. Although people can perceive multiple visual features simultaneously, cognitive studies assert that some pattern recognition and interpretation still requires successive processing <ref> [25] </ref>. Visual sequence therefore becomes another important factor in visual organization. In other words, if visual elements are organized in the right sequence, the resulting presentation will guide a viewer to process information efficiently. In contrast, poorly organized presentations will greatly impair a viewers performance [30].
Reference: [26] <author> E. R. Tufte. </author> <title> The Visual Display of Quantitative Information. </title> <publisher> Graphics Press, </publisher> <address> Cheshire, CT, </address> <year> 1983. </year>
Reference-contexts: However, it is difficult to formulate general rules that can directly relate high level presentation intents, such as Inform&lt;?x&gt;, to low-level visual techniques, such as Highlight&lt;?x&gt;. Based on a variety of visual presentations from different sources (e.g., <ref> [22, 26, 27, 10, 28] </ref>), and our own work on visual discourse synthesis [32], we believe that there is a level of abstraction midway between presentation intents and low-level visual techniques. We refer to this level of abstraction as a visual task taxonomy. <p> To decide which visual tasks may be used to achieve what presentation intent, we pair presentation intents and corresponding information categories together [9] (e.g., Verify&lt;object-composition&gt;). Then we infer how the specific presentation intent could be accomplished visually, based on both rhetorical and visual design principles <ref> [22, 18, 15, 26, 27, 19, 28] </ref>. For example, Verify&lt;object-composition&gt; requires displaying an object and its components. Thus, the visual task Reveal&lt;?x&gt; could facilitate perceptual verification. <p> Position&lt;devices, patient-body&gt; 4. Itemize&lt;demographics&gt; 5. Name&lt;demographics, name&gt; 6. Symbolize&lt;lines&gt; 7. Name (lines, line-name&gt; 8. Associate&lt;lines, contents&gt; 9. Symbolize&lt;other-devices&gt; 10. Name&lt;other-devices, device-name&gt; 11. Associate&lt;other-devices, parameters&gt; DesignVisRep&lt;demographics, ?title&gt; DesignVisRep&lt;devices, ?elements&gt; DesignVisRep&lt;patient, ?body&gt; DesignTable&lt;demographics, ?table&gt; DesignVisRep&lt;name, ?table-title&gt; DesignVisRep&lt;lines, ?line&gt; DesignVisRep&lt;line-name,?line-label&gt; DesignVisRep&lt;content, ?content-label&gt; DesignVisRep&lt;other-devices, ?device&gt; DesignVisRep&lt;device-name,?device-label&gt; DesignVisRep&lt;content, ?content-label&gt; of visual presentations (e.g, <ref> [26, 27, 10, 28] </ref>) and integration of both rhetorical and visual design theories (e.g., [22, 18, 30, 15, 11, 19]). Moreover, these task specifications are being used in our experimental visual discourse synthesis system IMPROVISE to test their practical value.
Reference: [27] <author> E. R. Tufte. </author> <title> Envisioning Information. </title> <publisher> Graphics Press, </publisher> <address> Cheshire, CT, </address> <year> 1990. </year>
Reference-contexts: However, it is difficult to formulate general rules that can directly relate high level presentation intents, such as Inform&lt;?x&gt;, to low-level visual techniques, such as Highlight&lt;?x&gt;. Based on a variety of visual presentations from different sources (e.g., <ref> [22, 26, 27, 10, 28] </ref>), and our own work on visual discourse synthesis [32], we believe that there is a level of abstraction midway between presentation intents and low-level visual techniques. We refer to this level of abstraction as a visual task taxonomy. <p> To decide which visual tasks may be used to achieve what presentation intent, we pair presentation intents and corresponding information categories together [9] (e.g., Verify&lt;object-composition&gt;). Then we infer how the specific presentation intent could be accomplished visually, based on both rhetorical and visual design principles <ref> [22, 18, 15, 26, 27, 19, 28] </ref>. For example, Verify&lt;object-composition&gt; requires displaying an object and its components. Thus, the visual task Reveal&lt;?x&gt; could facilitate perceptual verification. <p> Position&lt;devices, patient-body&gt; 4. Itemize&lt;demographics&gt; 5. Name&lt;demographics, name&gt; 6. Symbolize&lt;lines&gt; 7. Name (lines, line-name&gt; 8. Associate&lt;lines, contents&gt; 9. Symbolize&lt;other-devices&gt; 10. Name&lt;other-devices, device-name&gt; 11. Associate&lt;other-devices, parameters&gt; DesignVisRep&lt;demographics, ?title&gt; DesignVisRep&lt;devices, ?elements&gt; DesignVisRep&lt;patient, ?body&gt; DesignTable&lt;demographics, ?table&gt; DesignVisRep&lt;name, ?table-title&gt; DesignVisRep&lt;lines, ?line&gt; DesignVisRep&lt;line-name,?line-label&gt; DesignVisRep&lt;content, ?content-label&gt; DesignVisRep&lt;other-devices, ?device&gt; DesignVisRep&lt;device-name,?device-label&gt; DesignVisRep&lt;content, ?content-label&gt; of visual presentations (e.g, <ref> [26, 27, 10, 28] </ref>) and integration of both rhetorical and visual design theories (e.g., [22, 18, 30, 15, 11, 19]). Moreover, these task specifications are being used in our experimental visual discourse synthesis system IMPROVISE to test their practical value.
Reference: [28] <author> E. R. Tufte. </author> <title> Visual Explanations: Images and Quantities, Evidence and Narrative. </title> <publisher> Graphics Press, </publisher> <address> Cheshire, CT, </address> <year> 1997. </year>
Reference-contexts: However, it is difficult to formulate general rules that can directly relate high level presentation intents, such as Inform&lt;?x&gt;, to low-level visual techniques, such as Highlight&lt;?x&gt;. Based on a variety of visual presentations from different sources (e.g., <ref> [22, 26, 27, 10, 28] </ref>), and our own work on visual discourse synthesis [32], we believe that there is a level of abstraction midway between presentation intents and low-level visual techniques. We refer to this level of abstraction as a visual task taxonomy. <p> To decide which visual tasks may be used to achieve what presentation intent, we pair presentation intents and corresponding information categories together [9] (e.g., Verify&lt;object-composition&gt;). Then we infer how the specific presentation intent could be accomplished visually, based on both rhetorical and visual design principles <ref> [22, 18, 15, 26, 27, 19, 28] </ref>. For example, Verify&lt;object-composition&gt; requires displaying an object and its components. Thus, the visual task Reveal&lt;?x&gt; could facilitate perceptual verification. <p> Position&lt;devices, patient-body&gt; 4. Itemize&lt;demographics&gt; 5. Name&lt;demographics, name&gt; 6. Symbolize&lt;lines&gt; 7. Name (lines, line-name&gt; 8. Associate&lt;lines, contents&gt; 9. Symbolize&lt;other-devices&gt; 10. Name&lt;other-devices, device-name&gt; 11. Associate&lt;other-devices, parameters&gt; DesignVisRep&lt;demographics, ?title&gt; DesignVisRep&lt;devices, ?elements&gt; DesignVisRep&lt;patient, ?body&gt; DesignTable&lt;demographics, ?table&gt; DesignVisRep&lt;name, ?table-title&gt; DesignVisRep&lt;lines, ?line&gt; DesignVisRep&lt;line-name,?line-label&gt; DesignVisRep&lt;content, ?content-label&gt; DesignVisRep&lt;other-devices, ?device&gt; DesignVisRep&lt;device-name,?device-label&gt; DesignVisRep&lt;content, ?content-label&gt; of visual presentations (e.g, <ref> [26, 27, 10, 28] </ref>) and integration of both rhetorical and visual design theories (e.g., [22, 18, 30, 15, 11, 19]). Moreover, these task specifications are being used in our experimental visual discourse synthesis system IMPROVISE to test their practical value.
Reference: [29] <author> R. Wehrend and C. Lewis. </author> <title> A problem-oriented classification of visualization techniques. </title> <booktitle> In Proceedings of the First IEEE Conference on Visualization: Visualization 90, </booktitle> <pages> pages 139143. </pages> <publisher> IEEE, Los Alamitos, </publisher> <address> CA, </address> <month> October </month> <year> 1990. </year>
Reference-contexts: Finally, we present our conclusions and suggest future research directions. RELATED WORK To characterize different visual presentations and capture the relationships between presentation intents and visual cues, researchers have developed various taxonomies (e.g., <ref> [7, 13, 24, 29, 10] </ref>). Unlike our visual task taxonomy, previous taxonomies either broadly categorize the functions of pictures without examining their specific visual organizations (e.g., [7, 13]), or only describe conceptual relationships between information-seeking goals and various visual techniques (e.g., [29, 10]). <p> Unlike our visual task taxonomy, previous taxonomies either broadly categorize the functions of pictures without examining their specific visual organizations (e.g., [7, 13]), or only describe conceptual relationships between information-seeking goals and various visual techniques (e.g., <ref> [29, 10] </ref>). Of these researchers, only Sutcliffe et al. [24] briey mention four specific visual tasks (e.g., Highlight and Classify). For the purpose of automated visual discourse synthesis, researchers have classified various user information-seeking goals (e.g., [3, 21, 8]) or communicative acts (e.g., [1, 17, 23]). <p> In contrast, our visual task taxonomy covers both high-level visual organization and low-level visual symbol encoding tasks. VISUAL TASK CHARACTERIZATION Building on previous work <ref> [29, 10, 17, 24] </ref>, we have derived a taxonomy of visual tasks, shown in Figure 1. Like a visual act, each visual task is described by two parts: an act and a set of arguments to act on.
Reference: [30] <author> W. Winn and W. Holliday. </author> <title> Design principles for diagrams and charts. </title> <editor> In D. Jonassen, editor, </editor> <booktitle> The Technology of Text, </booktitle> <volume> volume 1, </volume> <pages> pages 277 299. </pages> <publisher> Educational Technology Publications, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1982. </year>
Reference-contexts: Visual Organization Visual organization could be described from several aspects such as overall pattern or sequence of the organization (e.g., <ref> [30] </ref>), preattentive features of the organization (e.g, [25]), and various visual relationships among visual elements (e.g., [11, 12]). Generalizing from this previous work, we have compiled a comprehensive set of features to describe various aspects of visual organization: visual grouping, visual attention, visual sequence, and visual composition. <p> Visual sequence therefore becomes another important factor in visual organization. In other words, if visual elements are organized in the right sequence, the resulting presentation will guide a viewer to process information efficiently. In contrast, poorly organized presentations will greatly impair a viewers performance <ref> [30] </ref>. There are two types of visual sequence, depending on what visual features produce the order: spatial sequence and perceptual sequence. <p> Spatial sequence indicates how people are intended to successively scan a presentation based on its elements positions, whereas perceptual sequence indicates how people order patterns or features by their visual appearance. Winn and Holliday <ref> [30] </ref> have summarized desired visual sequences used in charts, graphs and diagrams. Goldsmiths experiments [6] have also indicated how certain visual patterns guide ordered perception. Based on their results, we recognize a set of visual tasks that imply certain visual sequences in presentations. <p> Visual structuring specifies the type of display [7, 14], while visual encoding emphasizes visual symbol encoding, such as using visual variables (e.g., color, size, and shape) to encode an object or its attributes. Visual Structuring. We have combined several visual display taxonomies <ref> [7, 30, 11, 14] </ref> to categorize the displays in which we are interested. Based on this display categorization, we recognize five types of visual tasks: Tabulate, Plot, Structure, Trace, and Map. They imply five types of visual display: Visual Encoding. <p> As mentioned in the last section, Structure implies constructing a structure diagram (DesignStructureDiagram in Figure 8), which is capable of conveying a physical structure (e.g., the patient body) and expressing the spatial coordinates for related objects (e.g., medical devices) <ref> [30, 14] </ref>. DesignStructureDia-gram produces an empty structure diagram, and other visual tasks help refine it. <p> Associate&lt;lines, contents&gt; 9. Symbolize&lt;other-devices&gt; 10. Name&lt;other-devices, device-name&gt; 11. Associate&lt;other-devices, parameters&gt; DesignVisRep&lt;demographics, ?title&gt; DesignVisRep&lt;devices, ?elements&gt; DesignVisRep&lt;patient, ?body&gt; DesignTable&lt;demographics, ?table&gt; DesignVisRep&lt;name, ?table-title&gt; DesignVisRep&lt;lines, ?line&gt; DesignVisRep&lt;line-name,?line-label&gt; DesignVisRep&lt;content, ?content-label&gt; DesignVisRep&lt;other-devices, ?device&gt; DesignVisRep&lt;device-name,?device-label&gt; DesignVisRep&lt;content, ?content-label&gt; of visual presentations (e.g, [26, 27, 10, 28]) and integration of both rhetorical and visual design theories (e.g., <ref> [22, 18, 30, 15, 11, 19] </ref>). Moreover, these task specifications are being used in our experimental visual discourse synthesis system IMPROVISE to test their practical value. To use visual task specifications in automated visual discourse synthesis, we have characterized them by their visual accomplishments and implications.
Reference: [31] <author> H. Zettl. </author> <title> Sight Sound Motion: Applied Media Aesthetics. </title> <publisher> Wadsworth Publishing Company, </publisher> <address> Belmont, CA, </address> <note> second edition, </note> <year> 1990. </year>
Reference-contexts: The visual signaling principle explains how people tend to interpret visual cues and infer their meanings (e.g., [6]). The visual transformation principle explains how people switch attention and adapt to visual changes (e.g., <ref> [31] </ref>). Directed by these principles, we could categorize various visual tasks by their visual implications: whether they imply certain types of visual organization, certain ways of visual signaling, or certain paths of visual transformation. <p> We recognize two types of visual transformation: visual modification and visual transition. Visual modification asserts that the current display has been modified either to achieve a new task or accommodate a new piece of information. Visual transition, on the other hand, indicates visual effects <ref> [31] </ref> that bridge a gap between two completely different presentations (e.g., a cross-fade). Examining our visual tasks, we are able to determine that some imply visual modification, and others visual transition.
Reference: [32] <author> M. Zhou and S. Feiner. </author> <title> Top-down hierarchical planning of coherent visual discourse. </title> <booktitle> In Proc. IUI97, </booktitle> <pages> pages 129136, </pages> <address> Orlando, FL, </address> <month> Janu-ary </month> <year> 1997. </year>
Reference-contexts: Therefore, researchers are developing computational approaches to automating the design process. The work described here addresses the general task of designing visual discourse, a series of connected visual displays <ref> [32] </ref>, of which a single display or a series of static displays may be considered special cases. <p> Based on a variety of visual presentations from different sources (e.g., [22, 26, 27, 10, 28]), and our own work on visual discourse synthesis <ref> [32] </ref>, we believe that there is a level of abstraction midway between presentation intents and low-level visual techniques. We refer to this level of abstraction as a visual task taxonomy. Unlike presentation intents, visual tasks directly indicate the desired visual effects. <p> CHI 98, Los Angeles, CA, April 1823, 1998 edge-based visual presentation system called IMPROVISE (Illustrative Metaphor Production in Reactive Object-oriented VISual Environments). IMPROVISE uses a hierarchical planning approach <ref> [32] </ref> to automatically generate coherent visual discourse in two application domains: computer network management and hospital patient record summarization. Finally, we present our conclusions and suggest future research directions. <p> Search Verify Sum Differentiate Background Categorize Cluster Compare Correlate Distinguish Generalize Identify Locate Rank Emphasize Associate Reveal Categorize Cluster Compare Correlate Distinguish Emphasize Identify Locate Rank Reveal Correlate Locate Rank Categorize Compare Correlate Distinguish Identify Locate Rank Reveal Correlate Locate Rank each type of visual task, using lower-level visual techniques <ref> [32] </ref>. For example, if we know that the visual task Focus implies attracting attention, and that visual techniques such as Highlight or Enlarge attract visual attention, then these techniques could become different subplans to achieve Focus. <p> Visual Transformation To ensure visual discourse coherence, visual transformation cannot be ignored <ref> [32] </ref>. Visual transformation can help integrate new information into the current display to achieve unity; or gradually transform the current display into a new one to achieve continuity. We need to identify which visual tasks imply visual transformation, and subsequently, determine how to achieve these transformations. <p> Map: implies organizing information by geographic location Emphasize: may imply transformation by modifying emphasized objects Generalize: implies transformation by merging components Reveal: implies transformation by adding new information Switch: implies transition by switching from one scene to another previous work <ref> [32] </ref>.
References-found: 32

