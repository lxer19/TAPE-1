URL: ftp://ftp.cs.cornell.edu/pub/chandra/failure.detectors.weakest.ps.Z
Refering-URL: http://www.cs.cornell.edu/Info/People/chandra/WeakestFD.html
Root-URL: 
Title: The Weakest Failure Detector for Solving Consensus  asynchronous systems with a majority of correct processes.  
Author: Tushar Deepak Chandra yx Vassos Hadzilacos Sam Toueg 
Note: Consensus in  
Date: May 9, 1994  
Abstract: We determine what information about failures is necessary and sufficient to solve Consensus in asynchronous distributed systems subject to crash failures. In [CT91], we proved that 3W, a failure detector that provides surprisingly little information about which processes have crashed, is sufficient to solve Consensus in asynchronous systems with a majority of correct processes. In this paper, we prove that to solve Consensus, any failure detector has to provide at least as much information as 3W. Thus, 3W is indeed the weakest failure detector for solving 
Abstract-found: 1
Intro-found: 1
Reference: [ABD + 87] <author> Hagit Attiya, Amotz Bar-Noy, Danny Dolev, Daphne Koller, David Peleg, and Rudiger Reischuk. </author> <title> Achievable cases in an asynchronous environment. </title> <booktitle> In Proceedings of the Twenty-Eighth Symposium on Foundations of Computer Science, </booktitle> <pages> pages 337-346. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> October </month> <year> 1987. </year>
Reference-contexts: Essentially, these impossibility results stem from the inherent difficulty of determining whether a process has actually crashed or is only "very slow". To circumvent these impossibility results, previous research focused on the use of randomization techniques [CD89], the definition of some weaker problems and their solutions <ref> [DLP + 86, ABD + 87, BW87, BMZ88] </ref>, or the study of several models of partial synchrony [DDS87, DLS88].
Reference: [BMZ88] <author> Ofer Biran, Shlomo Moran, and Shmuel Zaks. </author> <title> A combinatorial characterization of the distributed tasks that are solvable in the presence of one faulty processor. </title> <booktitle> In Proceedings of the Seventh ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 263-275. </pages> <publisher> ACM Press, </publisher> <month> August </month> <year> 1988. </year>
Reference-contexts: Essentially, these impossibility results stem from the inherent difficulty of determining whether a process has actually crashed or is only "very slow". To circumvent these impossibility results, previous research focused on the use of randomization techniques [CD89], the definition of some weaker problems and their solutions <ref> [DLP + 86, ABD + 87, BW87, BMZ88] </ref>, or the study of several models of partial synchrony [DDS87, DLS88].
Reference: [BW87] <author> Michael Bridgland and Ronald Watro. </author> <title> Fault-tolerant decision making in totally asynchronous distributed systems. </title> <booktitle> In Proceedings of the Sixth ACM 42 Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 52-63. </pages> <publisher> ACM Press, </publisher> <month> August </month> <year> 1987. </year>
Reference-contexts: Essentially, these impossibility results stem from the inherent difficulty of determining whether a process has actually crashed or is only "very slow". To circumvent these impossibility results, previous research focused on the use of randomization techniques [CD89], the definition of some weaker problems and their solutions <ref> [DLP + 86, ABD + 87, BW87, BMZ88] </ref>, or the study of several models of partial synchrony [DDS87, DLS88].
Reference: [CD89] <author> Benny Chor and Cynthia Dwork. </author> <title> Randomization in byzantine agreement. </title> <booktitle> Advances in Computer Research, </booktitle> <volume> 5 </volume> <pages> 443-497, </pages> <year> 1989. </year>
Reference-contexts: Essentially, these impossibility results stem from the inherent difficulty of determining whether a process has actually crashed or is only "very slow". To circumvent these impossibility results, previous research focused on the use of randomization techniques <ref> [CD89] </ref>, the definition of some weaker problems and their solutions [DLP + 86, ABD + 87, BW87, BMZ88], or the study of several models of partial synchrony [DDS87, DLS88].
Reference: [CT91] <author> Tushar D. Chandra and Sam Toueg. </author> <title> Unreliable failure detectors for asynchronous systems. </title> <type> Technical Report 91-1225, </type> <institution> Department of Computer Science, Cornell University, </institution> <month> August </month> <year> 1991. </year> <note> Available by anonymous ftp from ftp.cs.cornell.edu in pub/chandra/failure.detectors.algorithms.dvi.Z. A preliminary version appeared in the Proceedings of the Tenth ACM Symposium on Principles of Distributed Computing, pages 325-340. ACM Press, </note> <month> August </month> <year> 1991. </year>
Reference-contexts: The Atomic Broadcast algorithm must still ensure that p delivers the same set of messages, in the same order, as all the other correct processes. Furthermore, if p broadcasts a message m, all correct processes must deliver m. 1 In <ref> [CT91] </ref>, we showed that a surprisingly weak failure detector is sufficient to solve Consensus and Atomic Broadcast in asynchronous systems with a majority of correct processes. <p> For instance, in practice the algorithm of <ref> [CT91] </ref> that solves Consensus using W only needs the two properties of W to hold for a relatively short period of time. 3 However, in an asynchronous system it is not possible to quantify "sufficiently long", since even a single process step or a single message transmission is allowed to take <p> Is it possible to solve Consensus using A? Indeed what is the weakest failure detector sufficient to solve Consensus in asynchronous systems? In trying to answer this fundamental question we run into a problem. Consider failure detector B that satisfies the following two properties: 2 In <ref> [CT91] </ref>, this was denoted 3W. 3 In that algorithm processes are cyclically elected as "coordinators". Consensus is achieved as soon as a correct coordinator is reached, and no process suspects it to have crashed while this coordinator is trying to enforce consensus. 4 1. <p> Since T B!W is able to transform B into W in an asynchronous system, B must provide at least as much information about process failures as W does. Intuitively, B is at least as strong as W. 1.3 The result In <ref> [CT91] </ref>, we showed that W is sufficient to solve Consensus in asynchronous systems if and only if n &gt; 2f (where n is the total number of processes, and f is the maximum number of processes that may crash). <p> Formally: 8p 2 correct (F ); 8C = (s; M ) of (S; I) : m = (q; data; p) 2 M ) (9i : S [i] is of the type (p; m; ; A)) In <ref> [CT91] </ref>, we proved that any algorithm that uses W to solve Consensus requires n &gt; 2f . With other failure detectors the requirements may be different. <p> Note that, in general, T D!D 0 need not emulate all the failure detector histories of D 0 (in environment E ); what we do require is that all the failure detector histories it emulates be histories of D 0 (in that environment). 5 An outline of the result In <ref> [CT91] </ref> we showed that W can be used to solve Consensus in any environment in which n &gt; 2f . We now show that W is weaker than any failure detector that can be used to solve Consensus. This result holds for any environment E . Together with [CT91], this implies <p> result In <ref> [CT91] </ref> we showed that W can be used to solve Consensus in any environment in which n &gt; 2f . We now show that W is weaker than any failure detector that can be used to solve Consensus. This result holds for any environment E . Together with [CT91], this implies that W is indeed the weakest failure detector that can be used to solve Consensus in any environment in which n &gt; 2f . 11 To prove our result, we first define a new failure detector, denoted , that is at least as strong as W. <p> Proof: If D can be used to solve Consensus in E , then, by Theorem 2, D -E . From Theorem 1, -E W. By transitivity, D -E W. 2 In <ref> [CT91] </ref> we proved that, for all environments E in which n &gt; 2f , W can be used to solve Consensus. <p> Finally, no two steps can occur at the same time. 10 These assumptions are convenient because they make the formal model simpler to describe. Also, they are consistent with those made in the model of [FLP85] that provided the impetus for this work. On the other hand, in <ref> [CT91] </ref> a model with weaker properties is used. There, the three phases of a step need not occur indivisibly, and may occur at different times. Even within the send phase, the messages sent to the different processes may be sent at different times. <p> Also, actions of different processes may take place simultaneously, subject to the restriction that a message can only be received strictly after it was sent. Since <ref> [CT91] </ref> is mainly concerned with showing how to use various types of failure detectors to achieve Consensus, the use of a weaker model strengthens the results. (In fact, the negative results of [CT91] hold even in the model of this paper, with the stronger atomicity assumptions.) The question naturally arises whether <p> Since <ref> [CT91] </ref> is mainly concerned with showing how to use various types of failure detectors to achieve Consensus, the use of a weaker model strengthens the results. (In fact, the negative results of [CT91] hold even in the model of this paper, with the stronger atomicity assumptions.) The question naturally arises whether our result also applies to this weaker model. <p> Thus the ability to solve Consensus in a given system is intimately related to the failure detection capabilities of that system. This realization led to the extension of the asynchronous model of computation with failure detectors in <ref> [CT91] </ref>. In that paper Consensus is shown to be solvable even with very weak failure detectors that could make an infinite number of "mistakes". A different tack on circumventing the unsolvability of Consensus is pursued in [DDS87] and [DLS88]. <p> By definition, k is a critical index. 2 The rest of the proof remains unchanged. 7.4 Failure detectors with infinite range of output values The failure detectors in <ref> [RB91, CT91] </ref> only output lists of processes suspected to have crashed. Since the set of processes is finite, the range of possible output values of these failure detectors is also finite.
Reference: [DDS87] <author> Danny Dolev, Cynthia Dwork, and Larry Stockmeyer. </author> <title> On the minimal synchronism needed for distributed consensus. </title> <journal> Journal of the ACM, </journal> <volume> 34(1) </volume> <pages> 77-97, </pages> <month> January </month> <year> 1987. </year>
Reference-contexts: In particular, it is well-known that Consensus, and several forms of reliable broadcast, including Atomic Broadcast, cannot be solved deterministically in an asynchronous system that is subject to even a single crash failure <ref> [FLP85, DDS87] </ref>. Essentially, these impossibility results stem from the inherent difficulty of determining whether a process has actually crashed or is only "very slow". <p> To circumvent these impossibility results, previous research focused on the use of randomization techniques [CD89], the definition of some weaker problems and their solutions [DLP + 86, ABD + 87, BW87, BMZ88], or the study of several models of partial synchrony <ref> [DDS87, DLS88] </ref>. However, the impossibility of deterministic solutions to many agreement problems (such as Consensus and Atomic Broadcast) remains a major obstacle to the use of the asynchronous model of computation for fault-tolerant distributed computing. <p> In that paper Consensus is shown to be solvable even with very weak failure detectors that could make an infinite number of "mistakes". A different tack on circumventing the unsolvability of Consensus is pursued in <ref> [DDS87] </ref> and [DLS88]. The approach of those papers is based on the observation that between the completely synchronous and completely asynchronous models of distributed systems there lie a variety of intermediate "partially synchronous" models. <p> In yet another variation, the eventual maximum message delay is known, but during some initial period of finite but unknown duration some messages may experience longer delays. These and many other models of partial synchrony are studied in <ref> [DDS87] </ref> and [DLS88], and the question of solvability of Consensus in each of them is answered either positively or negatively. 11 Another problem that must be confronted is that in the proofs of Lemmata 23 and 24 we often refer to the "first graph" in which a vertex or edge is <p> The fact that a message can be received only after it was sent is needed here. 34 In particular, <ref> [DDS87] </ref> defines a space of 32 models by considering five key parameters, each of which admits a "favorable" and an "unfavorable" setting. For instance, one of the parameters is whether the maximum message delay is known (favorable setting) or not (unfavorable setting). <p> For instance, one of the parameters is whether the maximum message delay is known (favorable setting) or not (unfavorable setting). Each of the 32 models corresponds to a particular setting of the 5 parameters. <ref> [DDS87] </ref> identifies four "minimal" models in which Consensus is solvable. These are minimal in the sense that the weakening of any parameter from favorable to unfavorable would yield a model of partial synchrony where Consensus is unsolvable. Thus, within the space of the models considered, [DDS87] and [DLS88] delineate precisely the <p> setting of the 5 parameters. <ref> [DDS87] </ref> identifies four "minimal" models in which Consensus is solvable. These are minimal in the sense that the weakening of any parameter from favorable to unfavorable would yield a model of partial synchrony where Consensus is unsolvable. Thus, within the space of the models considered, [DDS87] and [DLS88] delineate precisely the boundary between solvability and unsolvability of Consensus, and provide an answer to the question "What is the least amount of synchrony sufficient to solve Consensus?". <p> Failure detectors can be viewed as a more abstract and modular way of incorporating partial synchrony assumptions into the model of computation. Instead of focusing on the operational features of partial synchrony (such as the five parameters considered in <ref> [DDS87] </ref>), we can consider the axiomatic properties that failure detectors must have in order to solve Consensus. The problem of implementing a given failure detector in a specific model of partial synchrony becomes a separate issue; this separation affords greater modularity. <p> In contrast to <ref> [DDS87] </ref>, which identified a set of minimal models of partial synchrony in which Consensus is solvable, we are able to exhibit a single minimum failure detector that can be used to solve Consensus. The technical device that made this possible is the notion of reduction between failure detectors.
Reference: [DLP + 86] <author> Danny Dolev, Nancy A. Lynch, Shlomit S. Pinter, Eugene W. Stark, and William E. Weihl. </author> <title> Reaching approximate agreement in the presence of faults. </title> <journal> Journal of the ACM, </journal> <volume> 33(3) </volume> <pages> 499-516, </pages> <month> July </month> <year> 1986. </year>
Reference-contexts: Essentially, these impossibility results stem from the inherent difficulty of determining whether a process has actually crashed or is only "very slow". To circumvent these impossibility results, previous research focused on the use of randomization techniques [CD89], the definition of some weaker problems and their solutions <ref> [DLP + 86, ABD + 87, BW87, BMZ88] </ref>, or the study of several models of partial synchrony [DDS87, DLS88].
Reference: [DLS88] <author> Cynthia Dwork, Nancy A. Lynch, and Larry Stockmeyer. </author> <title> Consensus in the presence of partial synchrony. </title> <journal> Journal of the ACM, </journal> <volume> 35(2) </volume> <pages> 288-323, </pages> <month> April </month> <year> 1988. </year>
Reference-contexts: To circumvent these impossibility results, previous research focused on the use of randomization techniques [CD89], the definition of some weaker problems and their solutions [DLP + 86, ABD + 87, BW87, BMZ88], or the study of several models of partial synchrony <ref> [DDS87, DLS88] </ref>. However, the impossibility of deterministic solutions to many agreement problems (such as Consensus and Atomic Broadcast) remains a major obstacle to the use of the asynchronous model of computation for fault-tolerant distributed computing. <p> In that paper Consensus is shown to be solvable even with very weak failure detectors that could make an infinite number of "mistakes". A different tack on circumventing the unsolvability of Consensus is pursued in [DDS87] and <ref> [DLS88] </ref>. The approach of those papers is based on the observation that between the completely synchronous and completely asynchronous models of distributed systems there lie a variety of intermediate "partially synchronous" models. <p> In yet another variation, the eventual maximum message delay is known, but during some initial period of finite but unknown duration some messages may experience longer delays. These and many other models of partial synchrony are studied in [DDS87] and <ref> [DLS88] </ref>, and the question of solvability of Consensus in each of them is answered either positively or negatively. 11 Another problem that must be confronted is that in the proofs of Lemmata 23 and 24 we often refer to the "first graph" in which a vertex or edge is present. <p> These are minimal in the sense that the weakening of any parameter from favorable to unfavorable would yield a model of partial synchrony where Consensus is unsolvable. Thus, within the space of the models considered, [DDS87] and <ref> [DLS88] </ref> delineate precisely the boundary between solvability and unsolvability of Consensus, and provide an answer to the question "What is the least amount of synchrony sufficient to solve Consensus?".
Reference: [FLP85] <author> Michael J. Fischer, Nancy A. Lynch, and Michael S. Paterson. </author> <title> Impossibility of distributed consensus with one faulty process. </title> <journal> Journal of the ACM, </journal> <volume> 32(2) </volume> <pages> 374-382, </pages> <month> April </month> <year> 1985. </year>
Reference-contexts: In particular, it is well-known that Consensus, and several forms of reliable broadcast, including Atomic Broadcast, cannot be solved deterministically in an asynchronous system that is subject to even a single crash failure <ref> [FLP85, DDS87] </ref>. Essentially, these impossibility results stem from the inherent difficulty of determining whether a process has actually crashed or is only "very slow". <p> Our model of asynchronous computation with failure detection is patterned after the one in <ref> [FLP85] </ref>. The system consists of a set of n processes, = fp 1 ; p 2 ; : : : ; p n g. Every pair of processes is connected by a reliable communication channel. <p> As was shown in <ref> [FLP85] </ref>, the ability to do so is not sufficient for solving Consensus. An alternative formulation of a step could restrict a process to sending a message to a single process in the send phase. <p> Finally, no two steps can occur at the same time. 10 These assumptions are convenient because they make the formal model simpler to describe. Also, they are consistent with those made in the model of <ref> [FLP85] </ref> that provided the impetus for this work. On the other hand, in [CT91] a model with weaker properties is used. There, the three phases of a step need not occur indivisibly, and may occur at different times. <p> To see the connection between partial synchrony and failure detectors, it is useful to examine how one might go about implementing a failure detector. By the impossibility result of <ref> [FLP85] </ref>, a failure detector that can be used to solve Consensus cannot be implemented in a completely asynchronous system. Now consider partially synchronous systems in which correct processes have accurate timers (i.e., they can measure elapsed time). <p> although they are comparable as far as failure detection is concerned | which is all that matters for solving Consensus! In this connection, it is useful to recall our earlier observation, that the same failure detector can be implemented in different (indeed, incomparable) models of partial synchrony. 7.3 Weak Consensus <ref> [FLP85] </ref> actually showed that even the Weak Consensus problem cannot be solved (deterministically) in an asynchronous system.
Reference: [RB91] <author> Aleta Ricciardi and Kenneth P. Birman. </author> <title> Using process groups to implement failure detection in asynchronous environments. </title> <booktitle> In Proceedings of the Tenth ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 341-351. </pages> <publisher> ACM Press, </publisher> <month> August </month> <year> 1991. </year>
Reference-contexts: This failure detector, called the eventually weak failure detector and denoted 1 A different approach was taken in <ref> [RB91] </ref>: a correct process that is wrongly suspected to have crashed, voluntarily leaves the system. It may later rejoin the system by assuming a new identity. 3 W here, satisfies only the following two properties: 2 1. <p> By definition, k is a critical index. 2 The rest of the proof remains unchanged. 7.4 Failure detectors with infinite range of output values The failure detectors in <ref> [RB91, CT91] </ref> only output lists of processes suspected to have crashed. Since the set of processes is finite, the range of possible output values of these failure detectors is also finite.
References-found: 10

