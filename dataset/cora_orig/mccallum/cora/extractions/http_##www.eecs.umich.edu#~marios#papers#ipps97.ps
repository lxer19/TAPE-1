URL: http://www.eecs.umich.edu/~marios/papers/ipps97.ps
Refering-URL: http://www.eecs.umich.edu/~marios/pubs.html
Root-URL: http://www.cs.umich.edu
Phone: 2  3  
Title: Performance Evaluation of Gang Scheduling for Parallel and Distributed Multiprogramming  
Author: Fang Wang Marios Papaefthymiou Mark Squillante 
Address: New Haven CT 06520, USA  Ann Arbor MI 48109, USA  Yorktown Heights NY 10598, USA  
Affiliation: 1 Yale University,  University of Michigan,  IBM Research Division,  
Abstract: In this paper we explore the performance of various aspects of gang scheduling designs. We developed an event-driven simulator of a vanilla gang scheduler that relies on the Distributed Hierarchical Control (DHC) structure. We also developed three variations of the vanilla gang scheduler that rely on a push-down heuristic and on two job-migration schemes to decrease response times by reducing processor idle time. We evaluated the gang schedulers on a compiled, one-month long history of jobs from the Cornell Theory Center that was scheduled by EASY-LL, a particular version of LoadLeveler with backfilling. Our results demonstrate the significant performance improvements that can be achieved with gang scheduling. They also show the performance impact of various aspects in the design of gang schedulers. We identify and discuss the potential benefits of several approaches for addressing a number of gang scheduling issues that, under certain workload conditions, become important in practice. Our techniques include heuristics for mapping jobs to processors and for choosing time quanta, block paging for reducing memory overheads, and the allocation of multiple time-slices to smaller jobs per timeplexing cycle.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> T. Beretvas and W. H. Tetzlaff. </author> <title> Paging enhancements in VM/SP HPO 3.4. </title> <type> Technical Report TB GG22-9467, </type> <institution> IBM Washington Syst. Center, </institution> <month> May </month> <year> 1984. </year>
Reference-contexts: We now discuss a particular strategy to significantly reduce and effectively eliminate these overheads for a general class of large-scale parallel applications. Our approach is based in part on the concept of block paging, which was introduced in the VM/SP HPO operating system <ref> [1, 25, 26] </ref> and extended in the VM/ESA operating system [23, 24]. A few other systems have since adopted some of these concepts, and related forms of prefetching have recently appeared in the research literature [15, 17]. <p> A few other systems have since adopted some of these concepts, and related forms of prefetching have recently appeared in the research literature [15, 17]. We first provide a brief overview of the block paging mechanisms used in VM; the interested reader is referred to <ref> [1, 23, 24, 25, 26, 27, 28] </ref> for additional technical details. We then discuss our approach for addressing memory and paging overheads in large-scale parallel time-sharing systems, which is based on the VM mechanisms and extensions tailored to the parallel computing environments of interest.
Reference: 2. <author> D. L. Eager, J. Zahorjan, and E. D. Lazowska. </author> <title> Speedup versus efficiency in parallel systems. </title> <journal> IEEE Trans. Comp., </journal> <volume> 38 </volume> <pages> 408-423, </pages> <month> March </month> <year> 1989. </year>
Reference-contexts: A job may not require the attention of the entire system, however. Moreover, abundant empirical evidence indicates that program dependencies and communication costs may limit the degree of achievable parallelism (e.g., <ref> [2, 16] </ref>). In these situations, space-sharing can increase throughput by partitioning resources and reducing the underutilization of system partitions.
Reference: 3. <author> D. G. Feitelson. </author> <title> Packing schemes for gang scheduling. In Job Sched. Strategies for Parallel Processing, </title> <editor> D. G. Feitelson and L. </editor> <booktitle> Rudolph (eds.), </booktitle> <pages> pages 89-110. </pages> <publisher> Springer-Verlag, </publisher> <year> 1996. </year> <note> LNCS Vol. 1162. </note>
Reference-contexts: The performance of gang scheduling schemes that use distributed hierarchical control has been analyzed from a queueing-theoretic perspective [21, 22]. Moreover, the performance of several gang scheduling algorithms has been studied by simulation on synthetically generated workloads <ref> [3, 7] </ref>. In this paper we present an empirical evaluation of various gang scheduling policies and design alternatives based on an actual parallel workload. <p> We have been working on a tree-packing scheme that exploits parasite allocations (somewhat similar to the alternative scheduling in <ref> [3] </ref>) by assigning jobs to partitions in the tree that maximize the number of processors kept busy throughout the timeplexing cycle. Much like the migration scheme, this approach uses a priority-based mechanism for choosing among multiple assignments that are equal with respect to keeping processors busy.
Reference: 4. <author> D. G. Feitelson and L. Rudolph. </author> <title> Distributed hierarchical control for parallel processing. </title> <booktitle> Computer, </booktitle> <pages> pages 65-77, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: Gang scheduling encompasses a very broad range of schedulers depending on the particular schemes used for partitioning resources and for sharing resources within each partition. One particular approach is based on the distributed hierarchical control structure <ref> [4, 5, 6] </ref>. <p> A somewhat different approach, which can be conceptually viewed as a generalization of Ousterhout's original global scheduling matrix, has also been considered [13, 14]. Due to its promising characteristics, gang scheduling has attracted considerable attention in recent years. Gang schedulers based on the distributed hierarchical control structure <ref> [4, 5, 6] </ref> have been implemented for the IBM RS/6000 SP2 [8, 30] and for clusters of workstations [9, 29]. Similarly, another form of gang scheduling has been implemented on both the IBM SP2 and a cluster of workstations [13, 14]. <p> Our focus is on the distributed hierarchical control approach to gang scheduling, although many of the principles and trends observed in this study are relevant to other forms of gang scheduling. Our study includes an examination of a vanilla gang scheduling scheme <ref> [4, 21] </ref> and two variations of this scheme that use pushdown and job-migration heuristics to increase system throughput and decrease response times by minimizing idle partitions.
Reference: 5. <author> D. G. Feitelson and L. Rudolph. </author> <title> Mapping and scheduling in a shared parallel environment using distributed hierarchical control. </title> <booktitle> In Proc. International Conf. Parallel Processing, </booktitle> <volume> volume I, </volume> <pages> pages 1-8, </pages> <month> August </month> <year> 1990. </year>
Reference-contexts: Gang scheduling encompasses a very broad range of schedulers depending on the particular schemes used for partitioning resources and for sharing resources within each partition. One particular approach is based on the distributed hierarchical control structure <ref> [4, 5, 6] </ref>. <p> A somewhat different approach, which can be conceptually viewed as a generalization of Ousterhout's original global scheduling matrix, has also been considered [13, 14]. Due to its promising characteristics, gang scheduling has attracted considerable attention in recent years. Gang schedulers based on the distributed hierarchical control structure <ref> [4, 5, 6] </ref> have been implemented for the IBM RS/6000 SP2 [8, 30] and for clusters of workstations [9, 29]. Similarly, another form of gang scheduling has been implemented on both the IBM SP2 and a cluster of workstations [13, 14].
Reference: 6. <author> D. G. Feitelson and L. Rudolph. </author> <title> Gang scheduling performance benefits for fine-grain synchronization. </title> <journal> J. Parallel and Distr. Comp., </journal> <volume> 16(4) </volume> <pages> 306-318, </pages> <month> December </month> <year> 1992. </year>
Reference-contexts: Gang scheduling encompasses a very broad range of schedulers depending on the particular schemes used for partitioning resources and for sharing resources within each partition. One particular approach is based on the distributed hierarchical control structure <ref> [4, 5, 6] </ref>. <p> A somewhat different approach, which can be conceptually viewed as a generalization of Ousterhout's original global scheduling matrix, has also been considered [13, 14]. Due to its promising characteristics, gang scheduling has attracted considerable attention in recent years. Gang schedulers based on the distributed hierarchical control structure <ref> [4, 5, 6] </ref> have been implemented for the IBM RS/6000 SP2 [8, 30] and for clusters of workstations [9, 29]. Similarly, another form of gang scheduling has been implemented on both the IBM SP2 and a cluster of workstations [13, 14].
Reference: 7. <author> D. G. Feitelson and L. Rudolph. </author> <title> Evaluation of design choices for gang scheduling using distributed hierarchical control. </title> <journal> J. Parallel and Distr. Comp., </journal> <volume> 35 </volume> <pages> 18-34, </pages> <year> 1996. </year>
Reference-contexts: The performance of gang scheduling schemes that use distributed hierarchical control has been analyzed from a queueing-theoretic perspective [21, 22]. Moreover, the performance of several gang scheduling algorithms has been studied by simulation on synthetically generated workloads <ref> [3, 7] </ref>. In this paper we present an empirical evaluation of various gang scheduling policies and design alternatives based on an actual parallel workload.
Reference: 8. <author> H. Franke, P. Pattnaik, and L. Rudolph. </author> <title> Gang scheduling for highly efficient distributed multiprocessor systems. </title> <booktitle> In Proc. </booktitle> <address> Frontiers'96, </address> <year> 1996. </year>
Reference-contexts: Due to its promising characteristics, gang scheduling has attracted considerable attention in recent years. Gang schedulers based on the distributed hierarchical control structure [4, 5, 6] have been implemented for the IBM RS/6000 SP2 <ref> [8, 30] </ref> and for clusters of workstations [9, 29]. Similarly, another form of gang scheduling has been implemented on both the IBM SP2 and a cluster of workstations [13, 14]. The performance of gang scheduling schemes that use distributed hierarchical control has been analyzed from a queueing-theoretic perspective [21, 22].
Reference: 9. <author> A. Hori, H. Tezuka, Y. Ishikawa, N. Soda, H. Konaka, and M. Maeda. </author> <title> Implementation of gang-scheduling on workstation cluster. In Job Sched. Strategies for Parallel Processing, </title> <editor> D. G. Feitelson and L. </editor> <booktitle> Rudolph (eds.), </booktitle> <pages> pages 126-139. </pages> <publisher> Springer-Verlag, </publisher> <year> 1996. </year> <note> LNCS Vol. 1162. </note>
Reference-contexts: Due to its promising characteristics, gang scheduling has attracted considerable attention in recent years. Gang schedulers based on the distributed hierarchical control structure [4, 5, 6] have been implemented for the IBM RS/6000 SP2 [8, 30] and for clusters of workstations <ref> [9, 29] </ref>. Similarly, another form of gang scheduling has been implemented on both the IBM SP2 and a cluster of workstations [13, 14]. The performance of gang scheduling schemes that use distributed hierarchical control has been analyzed from a queueing-theoretic perspective [21, 22].
Reference: 10. <author> S. G. Hotovy. </author> <title> Workload evolution on the Cornell Theory Center IBM SP2. In Job Sched. Strategies for Parallel Processing, </title> <editor> D. G. Feitelson and L. </editor> <booktitle> Rudolph (eds.), </booktitle> <pages> pages 27-40. </pages> <publisher> Springer-Verlag, </publisher> <year> 1996. </year> <note> LNCS Vol. 1162. </note>
Reference-contexts: These scheduling strategies are sim-ulated under a workload that we obtained by post-processing a trace of the workload characteristics for one month at the Cornell Theory Center <ref> [10, 11, 12] </ref>. The original workload was scheduled on 320 processors of the IBM SP2 at Cornell's Theory Center using EASY-LL, an enhanced version of the basic LoadLeveler scheduler that uses backfilling to reduce the response times of jobs with small resource requirements [20].
Reference: 11. <author> S. G. Hotovy. </author> <type> Personal communication. </type> <year> 1997. </year>
Reference-contexts: These scheduling strategies are sim-ulated under a workload that we obtained by post-processing a trace of the workload characteristics for one month at the Cornell Theory Center <ref> [10, 11, 12] </ref>. The original workload was scheduled on 320 processors of the IBM SP2 at Cornell's Theory Center using EASY-LL, an enhanced version of the basic LoadLeveler scheduler that uses backfilling to reduce the response times of jobs with small resource requirements [20]. <p> The timeplexing cycle, which is given on the x-axis, is divided uniformly among the system's ten classes. We arrived at the worst-case context-switch cost of 16 seconds by assuming that the jobs have a 64MB working set on each processor <ref> [11] </ref> which must be loaded in its entirety at the rate of 1 page/millisecond for a page size of 4KB, given the characteristics of many parallel scientific applications [19] and the (potentially) large degree of multiprogramming with ten classes.
Reference: 12. <author> S. G. Hotovy, D. J. Schneider, and T. O'Donnell. </author> <title> Analysis of the early workload on the Cornell Theory Center IBM SP2. </title> <booktitle> In Proc. ACM SIGMETRICS Conf. Measurement and Modeling of Comp. Syst., </booktitle> <pages> pages 272-273, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: These scheduling strategies are sim-ulated under a workload that we obtained by post-processing a trace of the workload characteristics for one month at the Cornell Theory Center <ref> [10, 11, 12] </ref>. The original workload was scheduled on 320 processors of the IBM SP2 at Cornell's Theory Center using EASY-LL, an enhanced version of the basic LoadLeveler scheduler that uses backfilling to reduce the response times of jobs with small resource requirements [20].
Reference: 13. <author> N. Islam, A. Prodromidis, M. S. Squillante, L. L. Fong, and A. S. Gopal. </author> <title> Extensi--ble resource mangement for cluster computing. </title> <booktitle> In Proc. International Conf. Distr. Comp. Syst., </booktitle> <month> May </month> <year> 1997. </year>
Reference-contexts: A somewhat different approach, which can be conceptually viewed as a generalization of Ousterhout's original global scheduling matrix, has also been considered <ref> [13, 14] </ref>. Due to its promising characteristics, gang scheduling has attracted considerable attention in recent years. Gang schedulers based on the distributed hierarchical control structure [4, 5, 6] have been implemented for the IBM RS/6000 SP2 [8, 30] and for clusters of workstations [9, 29]. <p> Gang schedulers based on the distributed hierarchical control structure [4, 5, 6] have been implemented for the IBM RS/6000 SP2 [8, 30] and for clusters of workstations [9, 29]. Similarly, another form of gang scheduling has been implemented on both the IBM SP2 and a cluster of workstations <ref> [13, 14] </ref>. The performance of gang scheduling schemes that use distributed hierarchical control has been analyzed from a queueing-theoretic perspective [21, 22]. Moreover, the performance of several gang scheduling algorithms has been studied by simulation on synthetically generated workloads [3, 7].
Reference: 14. <author> N. Islam, A. Prodromidis, M. S. Squillante, A. S. Gopal, and L. L. Fong. </author> <title> Extensible resource scheduling for parallel scientific applications. </title> <booktitle> In Proc. Eighth SIAM Conf. Parallel Processing for Scientific Comp., </booktitle> <month> March </month> <year> 1997. </year>
Reference-contexts: A somewhat different approach, which can be conceptually viewed as a generalization of Ousterhout's original global scheduling matrix, has also been considered <ref> [13, 14] </ref>. Due to its promising characteristics, gang scheduling has attracted considerable attention in recent years. Gang schedulers based on the distributed hierarchical control structure [4, 5, 6] have been implemented for the IBM RS/6000 SP2 [8, 30] and for clusters of workstations [9, 29]. <p> Gang schedulers based on the distributed hierarchical control structure [4, 5, 6] have been implemented for the IBM RS/6000 SP2 [8, 30] and for clusters of workstations [9, 29]. Similarly, another form of gang scheduling has been implemented on both the IBM SP2 and a cluster of workstations <ref> [13, 14] </ref>. The performance of gang scheduling schemes that use distributed hierarchical control has been analyzed from a queueing-theoretic perspective [21, 22]. Moreover, the performance of several gang scheduling algorithms has been studied by simulation on synthetically generated workloads [3, 7].
Reference: 15. <author> T. Kimbrel, A. Tomkins, R. H. Patterson, B. Bershad, P. Cao, E. W. Felten, G. A. Gibson, A. R. Karlin, and K. Li. </author> <title> A trace-driven comparison of algorithms for parallel prefetching and caching. </title> <booktitle> In Proc. USENIX Symp. Operating Syst. Design and Implementation (OSDI), </booktitle> <pages> pages 19-34, </pages> <month> October </month> <year> 1996. </year>
Reference-contexts: A few other systems have since adopted some of these concepts, and related forms of prefetching have recently appeared in the research literature <ref> [15, 17] </ref>. We first provide a brief overview of the block paging mechanisms used in VM; the interested reader is referred to [1, 23, 24, 25, 26, 27, 28] for additional technical details.
Reference: 16. <author> V. M. Lo. </author> <title> Heuristic algorithms for task assignment in distributed systems. </title> <journal> IEEE Trans. Comp., </journal> <volume> 37(11) </volume> <pages> 1384-1397, </pages> <month> November </month> <year> 1988. </year>
Reference-contexts: A job may not require the attention of the entire system, however. Moreover, abundant empirical evidence indicates that program dependencies and communication costs may limit the degree of achievable parallelism (e.g., <ref> [2, 16] </ref>). In these situations, space-sharing can increase throughput by partitioning resources and reducing the underutilization of system partitions.
Reference: 17. <author> T. C. Mowry, A. K. Demke, and O. Krieger. </author> <title> Automatic compiler-inserted I/O prefetching for out-of-core applications. </title> <booktitle> In Proc. USENIX Symp. Operating Syst. Design and Implem. (OSDI), </booktitle> <pages> pages 3-17, </pages> <month> October </month> <year> 1996. </year>
Reference-contexts: A few other systems have since adopted some of these concepts, and related forms of prefetching have recently appeared in the research literature <ref> [15, 17] </ref>. We first provide a brief overview of the block paging mechanisms used in VM; the interested reader is referred to [1, 23, 24, 25, 26, 27, 28] for additional technical details.
Reference: 18. <author> J. K. Ousterhout. </author> <title> Scheduling techniques for concurrent syst.. </title> <booktitle> In Proc. Third International Conf. Distr. Comp. Syst., </booktitle> <pages> pages 22-30, </pages> <month> October </month> <year> 1982. </year>
Reference-contexts: Gang scheduling is a flexible scheduling scheme that combines time-sharing and space-sharing with the goal of providing the advantages of both approaches, including high system throughput and low response times for short-running jobs. The roots of gang scheduling can be traced back to the coscheduling concept described in <ref> [18] </ref>. This two-dimensional division (in time and space) of resources among jobs can be easily viewed as having the resource allocations governed by a scheduling matrix, where each column represents a specific processor and each row represents a particular time-slice, or quantum.
Reference: 19. <author> V. G. Peris, M. S. Squillante, and V. K. Naik. </author> <title> Analysis of the impact of memory in distributed parallel processing systems. </title> <booktitle> In Proc. ACM SIGMETRICS Conf. Measurement and Modeling of Comp. Syst., </booktitle> <pages> pages 5-18, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: arrived at the worst-case context-switch cost of 16 seconds by assuming that the jobs have a 64MB working set on each processor [11] which must be loaded in its entirety at the rate of 1 page/millisecond for a page size of 4KB, given the characteristics of many parallel scientific applications <ref> [19] </ref> and the (potentially) large degree of multiprogramming with ten classes. Note that EASY-LL is not affected by the context-switch overheads of gang scheduling, and the corresponding curves in Figs. 4 - 7 represent the last column in the table of Fig. 3. <p> There are two basic approaches to address the performance issues related to the memory management component of large-scale parallel environments in general <ref> [19] </ref>, and especially in systems that time-share their resources. One approach consists of allocating jobs to partitions such that the memory requirements of all jobs on each node of the partition fit within the memory available on that node, thus avoiding the memory overhead problem. <p> As soon as the page is brought into memory, the system returns to the execution of this job and the remaining pages of the block are brought into memory in parallel with the execution of the job. Given the memory reference characteristics of many scientific applications <ref> [19] </ref>, the operating system can continue to bring into memory a number of page blocks that are chained to the faulting page block based on time (and space) affinity.
Reference: 20. <author> J. Skovira, W. Chan, H. Zhou, and D. Lifka. </author> <title> The EASY-LoadLeveler API project. In Job Sched. Strategies for Parallel Processing, </title> <editor> D. G. Feitelson and L. </editor> <booktitle> Rudolph (eds.), </booktitle> <pages> pages 41-47. </pages> <publisher> Springer-Verlag, </publisher> <year> 1996. </year> <note> LNCS Vol. 1162. </note>
Reference-contexts: The original workload was scheduled on 320 processors of the IBM SP2 at Cornell's Theory Center using EASY-LL, an enhanced version of the basic LoadLeveler scheduler that uses backfilling to reduce the response times of jobs with small resource requirements <ref> [20] </ref>. The objectives of our evaluation study were to assess the effectiveness of different aspects of gang scheduling designs under a variety of heuristics for assigning jobs to processors and across a range of memory overheads.
Reference: 21. <author> M. S. Squillante, F. Wang, and M. Papaefthymiou. </author> <title> An analysis of gang scheduling for multiprogrammed parallel computing environments. </title> <booktitle> In Proc. Annual ACM Symp. Parallel Algorithms and Architectures (SPAA), </booktitle> <pages> pages 89-98, </pages> <month> June </month> <year> 1996. </year>
Reference-contexts: Similarly, another form of gang scheduling has been implemented on both the IBM SP2 and a cluster of workstations [13, 14]. The performance of gang scheduling schemes that use distributed hierarchical control has been analyzed from a queueing-theoretic perspective <ref> [21, 22] </ref>. Moreover, the performance of several gang scheduling algorithms has been studied by simulation on synthetically generated workloads [3, 7]. In this paper we present an empirical evaluation of various gang scheduling policies and design alternatives based on an actual parallel workload. <p> Our focus is on the distributed hierarchical control approach to gang scheduling, although many of the principles and trends observed in this study are relevant to other forms of gang scheduling. Our study includes an examination of a vanilla gang scheduling scheme <ref> [4, 21] </ref> and two variations of this scheme that use pushdown and job-migration heuristics to increase system throughput and decrease response times by minimizing idle partitions. <p> We have used, and continue to use, an analytic approach <ref> [21, 22] </ref> to gain insights into this problem with which heuristics can be developed for practical gang scheduling policies. <p> We are currently studying such approaches in more detail. Another important aspect of quanta allocation was also observed based upon our queueing-theoretic gang scheduling analysis <ref> [21, 22] </ref>. In particular, the setting of these policy parameters in gang scheduling systems must address the complex tradeoff between providing preferential treatment to short-running jobs via small quanta lengths at the expense of larger delays for long-running jobs.
Reference: 22. <author> M. S. Squillante, F. Wang, and M. Papaefthymiou. </author> <title> Stochastic analysis of gang scheduling in parallel and distributed syst.. </title> <booktitle> Perf. Eval., </booktitle> 27&28:273-296, 1996. 
Reference-contexts: Similarly, another form of gang scheduling has been implemented on both the IBM SP2 and a cluster of workstations [13, 14]. The performance of gang scheduling schemes that use distributed hierarchical control has been analyzed from a queueing-theoretic perspective <ref> [21, 22] </ref>. Moreover, the performance of several gang scheduling algorithms has been studied by simulation on synthetically generated workloads [3, 7]. In this paper we present an empirical evaluation of various gang scheduling policies and design alternatives based on an actual parallel workload. <p> We have used, and continue to use, an analytic approach <ref> [21, 22] </ref> to gain insights into this problem with which heuristics can be developed for practical gang scheduling policies. <p> We are currently studying such approaches in more detail. Another important aspect of quanta allocation was also observed based upon our queueing-theoretic gang scheduling analysis <ref> [21, 22] </ref>. In particular, the setting of these policy parameters in gang scheduling systems must address the complex tradeoff between providing preferential treatment to short-running jobs via small quanta lengths at the expense of larger delays for long-running jobs.
Reference: 23. <author> W. H. Tetzlaff. </author> <title> Paging in the VM/XA system product. </title> <journal> CMG Trans., </journal> <volume> 66 </volume> <pages> 55-64, </pages> <year> 1989. </year>
Reference-contexts: Our approach is based in part on the concept of block paging, which was introduced in the VM/SP HPO operating system [1, 25, 26] and extended in the VM/ESA operating system <ref> [23, 24] </ref>. A few other systems have since adopted some of these concepts, and related forms of prefetching have recently appeared in the research literature [15, 17]. <p> A few other systems have since adopted some of these concepts, and related forms of prefetching have recently appeared in the research literature [15, 17]. We first provide a brief overview of the block paging mechanisms used in VM; the interested reader is referred to <ref> [1, 23, 24, 25, 26, 27, 28] </ref> for additional technical details. We then discuss our approach for addressing memory and paging overheads in large-scale parallel time-sharing systems, which is based on the VM mechanisms and extensions tailored to the parallel computing environments of interest. <p> For example, it is shown in <ref> [23, 24] </ref> that the delay to fetch a single page from a particular IBM 3380 disk configuration is 29ms, whereas the delay to fetch 10 pages from a simpler 3380 configuration is 48ms. <p> As a specific example, the average block size on VM systems is between 9 and 12 pages with a range of 2 to 20 pages <ref> [23, 24] </ref>. When a page is fetched from disk as part of a block and is never referenced during the block's residence in memory, then the VM algorithms subsequently eliminate the page from the block. In certain cases, the system also chains together related page blocks for additional optimizations.
Reference: 24. <author> W. H. Tetzlaff. </author> <title> Paging in VM/ESA. </title> <booktitle> In Proc. CMG'91 Conf., </booktitle> <pages> pages 723-734, </pages> <year> 1991. </year>
Reference-contexts: Our approach is based in part on the concept of block paging, which was introduced in the VM/SP HPO operating system [1, 25, 26] and extended in the VM/ESA operating system <ref> [23, 24] </ref>. A few other systems have since adopted some of these concepts, and related forms of prefetching have recently appeared in the research literature [15, 17]. <p> A few other systems have since adopted some of these concepts, and related forms of prefetching have recently appeared in the research literature [15, 17]. We first provide a brief overview of the block paging mechanisms used in VM; the interested reader is referred to <ref> [1, 23, 24, 25, 26, 27, 28] </ref> for additional technical details. We then discuss our approach for addressing memory and paging overheads in large-scale parallel time-sharing systems, which is based on the VM mechanisms and extensions tailored to the parallel computing environments of interest. <p> For example, it is shown in <ref> [23, 24] </ref> that the delay to fetch a single page from a particular IBM 3380 disk configuration is 29ms, whereas the delay to fetch 10 pages from a simpler 3380 configuration is 48ms. <p> As a specific example, the average block size on VM systems is between 9 and 12 pages with a range of 2 to 20 pages <ref> [23, 24] </ref>. When a page is fetched from disk as part of a block and is never referenced during the block's residence in memory, then the VM algorithms subsequently eliminate the page from the block. In certain cases, the system also chains together related page blocks for additional optimizations.
Reference: 25. <author> W. H. Tetzlaff and T. Beretvas. </author> <title> Paging in VM/370 operating systems. </title> <journal> CMG Trans., </journal> <volume> 53 </volume> <pages> 65-76, </pages> <year> 1986. </year>
Reference-contexts: We now discuss a particular strategy to significantly reduce and effectively eliminate these overheads for a general class of large-scale parallel applications. Our approach is based in part on the concept of block paging, which was introduced in the VM/SP HPO operating system <ref> [1, 25, 26] </ref> and extended in the VM/ESA operating system [23, 24]. A few other systems have since adopted some of these concepts, and related forms of prefetching have recently appeared in the research literature [15, 17]. <p> A few other systems have since adopted some of these concepts, and related forms of prefetching have recently appeared in the research literature [15, 17]. We first provide a brief overview of the block paging mechanisms used in VM; the interested reader is referred to <ref> [1, 23, 24, 25, 26, 27, 28] </ref> for additional technical details. We then discuss our approach for addressing memory and paging overheads in large-scale parallel time-sharing systems, which is based on the VM mechanisms and extensions tailored to the parallel computing environments of interest.
Reference: 26. <author> W. H. Tetzlaff, T. Beretvas, W. M. Buco, J. Greenberg, D. R. Patterson, and G. A. Spivak. </author> <title> A page-swapping prototype for VM/HPO. </title> <journal> IBM Syst. J., </journal> <volume> 26 </volume> <pages> 215-230, </pages> <year> 1987. </year>
Reference-contexts: We now discuss a particular strategy to significantly reduce and effectively eliminate these overheads for a general class of large-scale parallel applications. Our approach is based in part on the concept of block paging, which was introduced in the VM/SP HPO operating system <ref> [1, 25, 26] </ref> and extended in the VM/ESA operating system [23, 24]. A few other systems have since adopted some of these concepts, and related forms of prefetching have recently appeared in the research literature [15, 17]. <p> A few other systems have since adopted some of these concepts, and related forms of prefetching have recently appeared in the research literature [15, 17]. We first provide a brief overview of the block paging mechanisms used in VM; the interested reader is referred to <ref> [1, 23, 24, 25, 26, 27, 28] </ref> for additional technical details. We then discuss our approach for addressing memory and paging overheads in large-scale parallel time-sharing systems, which is based on the VM mechanisms and extensions tailored to the parallel computing environments of interest.
Reference: 27. <author> W. H. Tetzlaff and R. Flynn. </author> <title> A comparison of page replacement algorithms. </title> <booktitle> In Proc. CMG'92 Conf., </booktitle> <pages> pages 1136-1143, </pages> <year> 1992. </year>
Reference-contexts: A few other systems have since adopted some of these concepts, and related forms of prefetching have recently appeared in the research literature [15, 17]. We first provide a brief overview of the block paging mechanisms used in VM; the interested reader is referred to <ref> [1, 23, 24, 25, 26, 27, 28] </ref> for additional technical details. We then discuss our approach for addressing memory and paging overheads in large-scale parallel time-sharing systems, which is based on the VM mechanisms and extensions tailored to the parallel computing environments of interest.
Reference: 28. <author> W. H. Tetzlaff, M. G. Kienzle, and J. A. Garay. </author> <title> Analysis of block-paging strategies. </title> <journal> IBM J. Res. and Devel., </journal> <volume> 33(1) </volume> <pages> 51-59, </pages> <month> January </month> <year> 1989. </year>
Reference-contexts: A few other systems have since adopted some of these concepts, and related forms of prefetching have recently appeared in the research literature [15, 17]. We first provide a brief overview of the block paging mechanisms used in VM; the interested reader is referred to <ref> [1, 23, 24, 25, 26, 27, 28] </ref> for additional technical details. We then discuss our approach for addressing memory and paging overheads in large-scale parallel time-sharing systems, which is based on the VM mechanisms and extensions tailored to the parallel computing environments of interest. <p> This page status information together with other temporal (and address) affinity information are used to minimize failures in accurately predicting future page co-reference and to dynamically maintain page blocks. The analysis in <ref> [28] </ref> shows that the VM paging algorithms are very effective in maintaining appropriate page blocks (e.g., a page is incorrectly placed in a block in the sense that it is brought in as part of the block but never referenced less than 13% of the time in practice) and extremely effective
Reference: 29. <author> F. Wang. </author> <title> Multiprogramming for parallel and distributed systems. </title> <type> PhD thesis, </type> <institution> Computer Science Department, Yale University, </institution> <year> 1997. </year>
Reference-contexts: Due to its promising characteristics, gang scheduling has attracted considerable attention in recent years. Gang schedulers based on the distributed hierarchical control structure [4, 5, 6] have been implemented for the IBM RS/6000 SP2 [8, 30] and for clusters of workstations <ref> [9, 29] </ref>. Similarly, another form of gang scheduling has been implemented on both the IBM SP2 and a cluster of workstations [13, 14]. The performance of gang scheduling schemes that use distributed hierarchical control has been analyzed from a queueing-theoretic perspective [21, 22].
Reference: 30. <author> F. Wang, H. Franke, M. Papaefthymiou, P. Pattnaik, L. Rudolph, and M. S. Squil-lante. </author> <title> A gang scheduling design for multiprogrammed parallel computing environments. In Job Sched. Strategies for Parallel Processing, </title> <editor> D. G. Feitelson and L. </editor> <booktitle> Rudolph (eds.), </booktitle> <pages> pages 111-125. </pages> <publisher> Springer-Verlag, </publisher> <year> 1996. </year> <note> LNCS Vol. </note> <month> 1162. </month> <title> This article was processed using the L A T E X macro package with LLNCS style </title>
Reference-contexts: Due to its promising characteristics, gang scheduling has attracted considerable attention in recent years. Gang schedulers based on the distributed hierarchical control structure [4, 5, 6] have been implemented for the IBM RS/6000 SP2 <ref> [8, 30] </ref> and for clusters of workstations [9, 29]. Similarly, another form of gang scheduling has been implemented on both the IBM SP2 and a cluster of workstations [13, 14]. The performance of gang scheduling schemes that use distributed hierarchical control has been analyzed from a queueing-theoretic perspective [21, 22].
References-found: 30

