URL: http://www.ri.cmu.edu/afs/cs.cmu.edu/project/fox/mosaic/papers/mleone-pldi96.ps
Refering-URL: http://www.ri.cmu.edu/afs/cs.cmu.edu/project/fox/mosaic/papers.html
Root-URL: 
Email: petel@cs.cmu.edu mleone@cs.cmu.edu  
Title: Optimizing ML with Run-Time Code Generation  
Author: Peter Lee Mark Leone 
Address: Pittsburgh, Pennsylvania 15213-3891  
Affiliation: School of Computer Science Carnegie Mellon University  
Abstract: We describe the design and implementation of a compiler that automatically translates ordinary programs written in a subset of ML into code that generates native code at run time. Run-time code generation can make use of values and invariants that cannot be exploited at compile time, yielding code that is often superior to statically optimal code. But the cost of optimizing and generating code at run time can be prohibitive. We demonstrate how compile-time specialization can reduce the cost of run-time code generation by an order of magnitude without greatly affecting code quality. Several benchmark programs are examined, which exhibit an average cost of only six cycles per instruction generated at run time. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Agesen, O., and H olzle, U. </author> <title> Type feedback vs. concrete type inference: A comparison of optimization techniques for object-oriented languages. </title> <booktitle> In OOP-SLA'95 Conference on Object-Oriented Programming Systems, Languages, and Applications (October 1995). </booktitle>
Reference-contexts: This program was both general (because it accepted any regular expression) and fast (because it generated special-purpose code quickly). Run-time code generation also led to notable performance improvements in the areas of operating systems [4, 8, 26, 33, 36], method dispatch in object-oriented systems <ref> [1, 9, 13, 20] </ref>, instruction-set simulation [10], graphics [14, 31], and many other applications. With the emergence of highly distributed and Web computing, more applications demand software that is general-purpose, safe, and highly compos-able. <p> The early instructions are simply executed, but the late instructions are emitted into a dynamic code segment, as explained below. For example, when supplied with the vector v1 = <ref> [1, 2, 3] </ref>, the following dot-product function is dynamically created: lw $x2, 0 ($v2) mult $prod, 1, $x2 add $sum, $sum, $prod lw $x2, 4 ($v2) mult $prod, 2, $x2 add $sum, $sum, $prod lw $x2, 8 ($v2) mult $prod, 3, $x2 add $sum, $sum, $prod move $result, $sum Even though
Reference: [2] <author> Appel, A. W. </author> <title> Compiling with Continuations. </title> <publisher> Cam-bridge University Press, </publisher> <address> New York, </address> <year> 1992. </year>
Reference-contexts: The early instructions are simply executed, but the late instructions are emitted into a dynamic code segment, as explained below. For example, when supplied with the vector v1 = <ref> [1, 2, 3] </ref>, the following dot-product function is dynamically created: lw $x2, 0 ($v2) mult $prod, 1, $x2 add $sum, $sum, $prod lw $x2, 4 ($v2) mult $prod, 2, $x2 add $sum, $sum, $prod lw $x2, 8 ($v2) mult $prod, 3, $x2 add $sum, $sum, $prod move $result, $sum Even though <p> Figure 5 (d) demonstrates the effect of run-time code generation on a simple curried membership function written in ML, and Figure 5 (e) shows the performance improvement observed in a commonly used ML benchmark, Conway's game of life (adapted from <ref> [2] </ref>), which uses a set to record the locations of living cells. Run-time code generation does not always improve performance, of course.
Reference: [3] <author> Appel, A. W., and MacQueen, D. B. </author> <title> Separate compilation for Standard ML. </title> <booktitle> In PLDI'94 Conference on Programming Language Design and Implementation (June 1994), </booktitle> <pages> pp. 13-23. </pages>
Reference-contexts: The advantage of S-expressions is that the programmer can specify the construction of Lisp terms at the source level, rather than as intermediate code trees. A similar features has also been implemented as an extension of Standard ML <ref> [3] </ref>. Recently, Engler and colleagues added support for this style of run-time code generation on top of DCG, in a system called `C [16], with good results. An even better approach is to design a programming language so that run-time code generation can be performed without programmer assistance. <p> The early instructions are simply executed, but the late instructions are emitted into a dynamic code segment, as explained below. For example, when supplied with the vector v1 = <ref> [1, 2, 3] </ref>, the following dot-product function is dynamically created: lw $x2, 0 ($v2) mult $prod, 1, $x2 add $sum, $sum, $prod lw $x2, 4 ($v2) mult $prod, 2, $x2 add $sum, $sum, $prod lw $x2, 8 ($v2) mult $prod, 3, $x2 add $sum, $sum, $prod move $result, $sum Even though
Reference: [4] <author> Auslander, J., Philipose, M., Chambers, C., Eg-gers, S. J., and Bershad, B. N. </author> <title> Fast, effective dynamic compilation. </title> <booktitle> In PLDI'96 Conference on Programming Language Design and Implementation (May 1996). </booktitle>
Reference-contexts: This program was both general (because it accepted any regular expression) and fast (because it generated special-purpose code quickly). Run-time code generation also led to notable performance improvements in the areas of operating systems <ref> [4, 8, 26, 33, 36] </ref>, method dispatch in object-oriented systems [1, 9, 13, 20], instruction-set simulation [10], graphics [14, 31], and many other applications. With the emergence of highly distributed and Web computing, more applications demand software that is general-purpose, safe, and highly compos-able. <p> Chambers and colleagues adopt a similar approach, using the Multiflow compiler to generate templates for programmer-delimited dynamic regions in Modula-3 programs <ref> [4, 8] </ref>. A major drawback of templates is that they severely limit the range of optimizations that may be applied at run time. A template fixes a particular instruction schedule and chooses fixed encodings for instructions, which precludes optimizations such as run-time code motion and instruction selection.
Reference: [5] <author> Bershad, B., Savage, S., Pardyak, P., Sirer, E. G., Becker, D., Fiuczynski, M., Chambers, C., and Eggers, S. </author> <title> Extensibility, safety and performance in the SPIN operating system. </title> <booktitle> In Symposium on Operating System Principles (December 1995), </booktitle> <pages> pp. 267-284. </pages>
Reference-contexts: With the emergence of highly distributed and Web computing, more applications demand software that is general-purpose, safe, and highly compos-able. This trend has prompted increased interest in run-time (and link-time) optimization and code generation as a way to regain the performance advantage enjoyed by special-purpose, monolithic systems <ref> [5] </ref>. Additional arguments for run-time code generation have been well-summarized by Kep-pel and colleagues [23, 24] 2.1 General-Purpose Dynamic Compilation Despite the increasing attention, researchers have done relatively little to automate and optimize the process of run-time optimization and compilation. <p> Run-time code generation can eliminate the overhead of interpretation by compiling a selection predicate into trusted native code. More generally, run-time code generation can allow a kernel to efficiently execute "agents" supplied by user-level processes while avoiding context switches. Such an approach has also been investigated by others <ref> [5, 18] </ref>. To investigate the feasibility of this idea, we implemented the BSD packet filter language [29] using Fabius and compared its performance to BPF, a kernel-resident interpreter implemented in C [28].
Reference: [6] <author> Biagioni, E., Harper, R., and Lee, P. </author> <title> Signatures for a protocol stack: A systems application of Standard ML. </title> <booktitle> In Conference on Lisp and Functional Programming (June 1994). </booktitle>
Reference-contexts: Fabius compiles a pure, first-order subset of ML with integers, reals, vectors, and user-defined datatypes. We chose this language primarily for two reasons. First, we are involved in a more general project to investigate the practicality of ML for systems programming (specifically, network protocols) <ref> [6] </ref>. Thus, we have a special interest in the optimization of ML programs. Second, ML provides good support for expressing staged computations in a way that might be usefully exploited by run-time code generation.
Reference: [7] <author> Bondorf, A., and Danvy, O. </author> <title> Automatic autopro-jection of recursive equations with global variables and abstract data types. </title> <institution> Sci. Comput. </institution> <note> Programming 16, </note> <month> 2 (September </month> <year> 1991), </year> <pages> 151-195. </pages>
Reference-contexts: These include memoization of specialization, unfolding of static conditionals, and the residualization of static values in dynamic contexts <ref> [7] </ref>. 3 The Fabius Compiler We have previously given a high-level overview of our approach, which we call deferred compilation [25].
Reference: [8] <author> Chambers, C., Eggers, S. J., Auslander, J., Phili-pose, M., Mock, M., and Pardyak, P. </author> <title> Automatic dynamic compilation support for event dispatching in extensible systems. </title> <booktitle> In WCSSS'96 Workshop on Compiler Support for System Software (February 1996). </booktitle>
Reference-contexts: This program was both general (because it accepted any regular expression) and fast (because it generated special-purpose code quickly). Run-time code generation also led to notable performance improvements in the areas of operating systems <ref> [4, 8, 26, 33, 36] </ref>, method dispatch in object-oriented systems [1, 9, 13, 20], instruction-set simulation [10], graphics [14, 31], and many other applications. With the emergence of highly distributed and Web computing, more applications demand software that is general-purpose, safe, and highly compos-able. <p> Chambers and colleagues adopt a similar approach, using the Multiflow compiler to generate templates for programmer-delimited dynamic regions in Modula-3 programs <ref> [4, 8] </ref>. A major drawback of templates is that they severely limit the range of optimizations that may be applied at run time. A template fixes a particular instruction schedule and chooses fixed encodings for instructions, which precludes optimizations such as run-time code motion and instruction selection.
Reference: [9] <author> Chambers, C., and Ungar, D. </author> <title> Customization: Optimizing compiler technology for SELF, a dynamically-typed object-oriented programming language. </title> <booktitle> In PLDI'89 Conference on Programming Language Design and Implementation (June 1989), </booktitle> <pages> pp. 146-160. </pages>
Reference-contexts: This program was both general (because it accepted any regular expression) and fast (because it generated special-purpose code quickly). Run-time code generation also led to notable performance improvements in the areas of operating systems [4, 8, 26, 33, 36], method dispatch in object-oriented systems <ref> [1, 9, 13, 20] </ref>, instruction-set simulation [10], graphics [14, 31], and many other applications. With the emergence of highly distributed and Web computing, more applications demand software that is general-purpose, safe, and highly compos-able. <p> An even better approach is to design a programming language so that run-time code generation can be performed without programmer assistance. For example, in an implementation of SELF <ref> [9] </ref>, the system provides run-time compilation of type-specialized versions of methods by simply postponing most aspects of optimization and compilation until run time.
Reference: [10] <author> Cmelik, R. F., and Keppel, D. Shade: </author> <title> A fast instruction-set simulator for execution profiling. </title> <type> Tech. Rep. </type> <institution> 93-06-06, Department of Computer Science and Engineering, University of Washington, </institution> <month> June </month> <year> 1993. </year>
Reference-contexts: Run-time code generation also led to notable performance improvements in the areas of operating systems [4, 8, 26, 33, 36], method dispatch in object-oriented systems [1, 9, 13, 20], instruction-set simulation <ref> [10] </ref>, graphics [14, 31], and many other applications. With the emergence of highly distributed and Web computing, more applications demand software that is general-purpose, safe, and highly compos-able.
Reference: [11] <author> Consel, C., and No el, F. </author> <title> A general approach to run-time specialization and its application to C. </title> <booktitle> In POPL '96 Symposium on Principles of Programming Languages (January 1996), </booktitle> <pages> pp. 145-156. </pages>
Reference-contexts: Templates and the code that instantiates them are typically constructed manually, which is non-portable and error prone. Recent work has explored the automatic derivation of templates from programs written in higher-level languages. For example, the Tempo system <ref> [11, 36] </ref> uses gcc to create machine code templates corresponding to portions of ordinary C programs that are classified as dynamic by a binding-time analysis. Chambers and colleagues adopt a similar approach, using the Multiflow compiler to generate templates for programmer-delimited dynamic regions in Modula-3 programs [4, 8].
Reference: [12] <author> Davies, R., and Pfenning, F. </author> <title> A modal analysis of staged computation. </title> <booktitle> In POPL '96 Symposium on Principles of Programming Languages (January 1996), </booktitle> <pages> pp. 258-270. </pages>
Reference-contexts: Memoization can be expensive and is sometimes ineffective, and the heuristic we employ to control run-time inlining occasionally leads to over-specialization or under-specialization. Recent advances in type theory have suggested a mechanism for providing better feedback to programmers <ref> [12] </ref>. Ultimately, the feasibility of deferred compilation will have to be demonstrated on larger, more realistic programs. It is encouraging to see that a prototype such as Fabius can already achieve good results.
Reference: [13] <author> Deutsch, L., and Schiffman, A. M. </author> <title> Efficient implementation of the Smalltalk-80 system. </title> <booktitle> In POPL'84 Symposium on Principles of Programming Languages, </booktitle> <address> Salt Lake City (January 1984), </address> <pages> pp. 297-302. </pages>
Reference-contexts: This program was both general (because it accepted any regular expression) and fast (because it generated special-purpose code quickly). Run-time code generation also led to notable performance improvements in the areas of operating systems [4, 8, 26, 33, 36], method dispatch in object-oriented systems <ref> [1, 9, 13, 20] </ref>, instruction-set simulation [10], graphics [14, 31], and many other applications. With the emergence of highly distributed and Web computing, more applications demand software that is general-purpose, safe, and highly compos-able.
Reference: [14] <author> Draves, S. </author> <title> Compiler generation for interactive graphics. </title> <booktitle> In Dagstuhl Seminar on Partial Evaluation (Febru-ary 1996). </booktitle>
Reference-contexts: Run-time code generation also led to notable performance improvements in the areas of operating systems [4, 8, 26, 33, 36], method dispatch in object-oriented systems [1, 9, 13, 20], instruction-set simulation [10], graphics <ref> [14, 31] </ref>, and many other applications. With the emergence of highly distributed and Web computing, more applications demand software that is general-purpose, safe, and highly compos-able.
Reference: [15] <author> Engler, D. R. </author> <title> vcode: A retargetable, extensible, very fast dynamic code generation system. </title> <booktitle> In PLDI'96 Conference on Programming Language Design and Implementation (May 1996). </booktitle>
Reference-contexts: The Fabius compiler is not a partial evaluator, but it does create specialized run-time code generators (as generating extensions) that do not manipulate templates nor any 2 other intermediate representation of code at run time. A similar approach has also been employed recently by the tcc compiler for `C <ref> [15, 32] </ref>. In contrast to tcc, Fabius achieves run-time code generation from completely ordinary ML programs (rather than depending on language extensions), and is more systematic in its use of well-known techniques and heuristics from partial evaluation.
Reference: [16] <author> Engler, D. R., Hsieh, W. C., and Kaashoek, M. F. </author> <title> `C: A language for high-level, efficient, and machine-independent dynamic code generation. </title> <booktitle> In POPL '96 Symposium on Principles of Programming Languages (January 1996), </booktitle> <pages> pp. 131-144. </pages>
Reference-contexts: A similar features has also been implemented as an extension of Standard ML [3]. Recently, Engler and colleagues added support for this style of run-time code generation on top of DCG, in a system called `C <ref> [16] </ref>, with good results. An even better approach is to design a programming language so that run-time code generation can be performed without programmer assistance.
Reference: [17] <author> Engler, D. R., and Proebsting, T. A. </author> <title> DCG: An efficient, retargetable dynamic code generation system. </title> <booktitle> In Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS VI) (October 1994), </booktitle> <publisher> ACM Press, </publisher> <pages> pp. 263-272. </pages>
Reference-contexts: A standard approach is to provide programming support for constructing representations of programs at run time, and for invoking an optimizing compiler to transform such representations into native code. This approach is relatively easy to implement, and systems such as DCG <ref> [17] </ref> based on this approach have been shown to be useful in interesting applications. Using DCG, a C programmer can write a program that constructs intermediate code trees and then invokes a compiler back-end to translate them into optimized native code that can be dynamically linked and executed. <p> For example, DCG's reported overhead of generating an instruction at run time is about 350 instructions per instruction generated <ref> [17] </ref>. 2.2 Templates It is possible to reduce the cost of run-time code generation by "pre-compiling" (as much as possible) the code that will be generated at run time. <p> For comparison purposes, we also evaluated the performance of two matrix multiplication algorithms implemented in C. One was a conventional triply nested loop (in row-major order) and the other was a special-purpose algorithm based on indirection vectors <ref> [17] </ref>, which is well-suited to sparse matrices that lack predictable characteristics. The ML implementation was purely functional and used dynamically dimensioned arrays, which were implemented using immutable one-dimensional vectors; each subscript operation included two bounds checks.
Reference: [18] <author> Engler, D. R., Wallach, D., and Kaashoek, M. F. </author> <title> Efficient, safe, application-specific message processing. </title> <type> Technical Memorandum MIT/LCS/TM533, </type> <institution> MIT Laboratory for Computer Science, </institution> <month> March </month> <year> 1995. </year> <month> 11 </month>
Reference-contexts: Run-time code generation can eliminate the overhead of interpretation by compiling a selection predicate into trusted native code. More generally, run-time code generation can allow a kernel to efficiently execute "agents" supplied by user-level processes while avoiding context switches. Such an approach has also been investigated by others <ref> [5, 18] </ref>. To investigate the feasibility of this idea, we implemented the BSD packet filter language [29] using Fabius and compared its performance to BPF, a kernel-resident interpreter implemented in C [28].
Reference: [19] <author> Feeley, M., Turcotte, M., and Lapalme, G. </author> <title> Us--ing Multilisp for solving constraint satisfaction problems: An application to nucleic acid 3D structure determination. </title> <booktitle> Lisp and Symbolic Computation 7 (1994), </booktitle> <pages> 231-247. </pages>
Reference-contexts: In practice, most lexical comparisons do not examine more than two or three characters of each string, so the time spent generating code for the remaining characters is wasted. We also experimented with the Pseudoknot benchmark <ref> [19] </ref>, which is a floating-point intensive program that attempts to determine the three-dimensional structure of portions of RNA molecules using constraint satisfaction and backtracking search.
Reference: [20] <author> H olzle, U., and Ungar, D. </author> <title> Optimizing dynamically-dispatched calls with run-time type feedback. </title> <booktitle> In PLDI'94 Conference on Programming Language Design and Implementation (June 1994). </booktitle>
Reference-contexts: This program was both general (because it accepted any regular expression) and fast (because it generated special-purpose code quickly). Run-time code generation also led to notable performance improvements in the areas of operating systems [4, 8, 26, 33, 36], method dispatch in object-oriented systems <ref> [1, 9, 13, 20] </ref>, instruction-set simulation [10], graphics [14, 31], and many other applications. With the emergence of highly distributed and Web computing, more applications demand software that is general-purpose, safe, and highly compos-able.
Reference: [21] <author> Jones, N. D., Gomard, C. K., and Sestoft, P. </author> <title> Partial Evaluation and Automatic Program Generation. </title> <publisher> Prentice-Hall, </publisher> <year> 1993. </year>
Reference-contexts: As we shall demonstrate, this interpretive overhead can be largely eliminated. 2.3 Specialized Code Generators We advocate a more general approach to reducing the cost of run-time code generation that is based on ideas from the literature on partial evaluation <ref> [21] </ref>.
Reference: [22] <author> Keppel, D. </author> <title> A portable interface for on-the-fly instruction space modification. </title> <booktitle> In Conference on Architectural Support for Programming Languages and Operating Systems (April 1991), </booktitle> <pages> pp. 86-95. </pages>
Reference-contexts: Thus, invalidating or updating the instruction cache is necessary to ensure that it remains coherent with memory. Coherency mechanisms vary, but portability does not appear to be a major concern <ref> [22] </ref>. The cost of instruction-cache invalidation varies widely, however. On the DEC-station 5000/200, flushing the instruction cache requires a kernel trap plus approximately 0.8 nanoseconds per byte flushed [22]. Fortunately, it is relatively easy to amortize this cost. <p> Coherency mechanisms vary, but portability does not appear to be a major concern <ref> [22] </ref>. The cost of instruction-cache invalidation varies widely, however. On the DEC-station 5000/200, flushing the instruction cache requires a kernel trap plus approximately 0.8 nanoseconds per byte flushed [22]. Fortunately, it is relatively easy to amortize this cost. Because Fabius-generated code generators do not modify existing code, it is not necessary to flush individual words from the instruction cache as new instructions are written.
Reference: [23] <author> Keppel, D., Eggers, S. J., and Henry, R. R. </author> <title> A case for runtime code generation. </title> <type> Tech. Rep. </type> <institution> 91-11-04, Department of Computer Science and Engineering, University of Washington, </institution> <month> November </month> <year> 1991. </year>
Reference-contexts: This trend has prompted increased interest in run-time (and link-time) optimization and code generation as a way to regain the performance advantage enjoyed by special-purpose, monolithic systems [5]. Additional arguments for run-time code generation have been well-summarized by Kep-pel and colleagues <ref> [23, 24] </ref> 2.1 General-Purpose Dynamic Compilation Despite the increasing attention, researchers have done relatively little to automate and optimize the process of run-time optimization and compilation. Indeed, existing approaches, although quite effective for some applications, are themselves rather specialized and require significant effort on the part of the programmer.
Reference: [24] <author> Keppel, D., Eggers, S. J., and Henry, R. R. </author> <title> Evaluating runtime-compiled value-specific optimizations. </title> <type> Tech. Rep. </type> <institution> 93-11-02, Department of Computer Science and Engineering, University of Washington, </institution> <month> November </month> <year> 1993. </year>
Reference-contexts: This trend has prompted increased interest in run-time (and link-time) optimization and code generation as a way to regain the performance advantage enjoyed by special-purpose, monolithic systems [5]. Additional arguments for run-time code generation have been well-summarized by Kep-pel and colleagues <ref> [23, 24] </ref> 2.1 General-Purpose Dynamic Compilation Despite the increasing attention, researchers have done relatively little to automate and optimize the process of run-time optimization and compilation. Indeed, existing approaches, although quite effective for some applications, are themselves rather specialized and require significant effort on the part of the programmer.
Reference: [25] <author> Leone, M., and Lee, P. </author> <title> Lightweight run-time code generation. In PEPM 94 Workshop on Partial Evaluation and Semantics-Based Program Manipulation (June 1994), </title> <type> Technical Report 94/9, </type> <institution> Department of Computer Science, University of Melbourne, </institution> <note> pp. 97-106. </note>
Reference-contexts: These include memoization of specialization, unfolding of static conditionals, and the residualization of static values in dynamic contexts [7]. 3 The Fabius Compiler We have previously given a high-level overview of our approach, which we call deferred compilation <ref> [25] </ref>. The main goals of deferred compilation are to minimize the costs of run-time code generation while allowing a wide range of optimizations in both the statically and dynamically generated code. <p> Function applications have also been given early annotations, which is taken as an indication that they should be inlined at run time. Determining the treatment of function calls is actually a rather subtle problem, which we do not discuss here. (See <ref> [25] </ref> for details.) 2 In particular, this staging analysis is more difficult than binding-time analysis because an initial division of program inputs is not supplied by the programmer [25]. 3 After annotating the program, Fabius compiles it into a register-transfer language, also containing early and late annotations, which in turn is <p> Determining the treatment of function calls is actually a rather subtle problem, which we do not discuss here. (See <ref> [25] </ref> for details.) 2 In particular, this staging analysis is more difficult than binding-time analysis because an initial division of program inputs is not supplied by the programmer [25]. 3 After annotating the program, Fabius compiles it into a register-transfer language, also containing early and late annotations, which in turn is translated into a representation of annotated MIPS assembly code. <p> Fabius is forced to insert spill code around inlined code in several of the benchmarks we have examined. We propose an efficient solution to this problem in <ref> [25] </ref>. 4 Preliminary Results To evaluate the performance of Fabius, we have experimented with a number of small and medium-sized benchmark programs.
Reference: [26] <author> Massalin, H. </author> <title> Synthesis: An Efficient Implementation of Fundamental Operating System Services. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, Columbia University, </institution> <year> 1992. </year>
Reference-contexts: This program was both general (because it accepted any regular expression) and fast (because it generated special-purpose code quickly). Run-time code generation also led to notable performance improvements in the areas of operating systems <ref> [4, 8, 26, 33, 36] </ref>, method dispatch in object-oriented systems [1, 9, 13, 20], instruction-set simulation [10], graphics [14, 31], and many other applications. With the emergence of highly distributed and Web computing, more applications demand software that is general-purpose, safe, and highly compos-able. <p> Figure 5 (c) demonstrates that run-time code generation can amortize this overhead when multiple lookups are performed on the same association list. Fabius automatically compiles a curried lookup function into a code generator that, in essence, creates executable data structures <ref> [26] </ref> that require no memory accesses; a sample of the lookup code generated at run time is contained in Figure 6. The task of determining set membership is also well suited to run-time code generation, because repeated membership tests on the same set require duplicate effort that can be amortized.
Reference: [27] <author> Massalin, H., and Pu, C. </author> <title> Threads and input/output in the Synthesis kernel. </title> <booktitle> In ACM Symposium on Operating Systems Principles (1989), </booktitle> <pages> pp. 191-201. </pages>
Reference-contexts: Several systems have used this approach with great success, such as Pike, Locanthi, and Reiser's bitblt compiler [31] and in Massalin and Pu's Synthesis kernel <ref> [27] </ref>. Until very recently, the use of templates has imposed a significant burden on programmers. Templates and the code that instantiates them are typically constructed manually, which is non-portable and error prone. Recent work has explored the automatic derivation of templates from programs written in higher-level languages.
Reference: [28] <author> McCanne, S. </author> <title> The Berkeley Packet Filter man page. </title> <note> BPF distribution available at ftp://ftp.ee.lbl.gov. </note>
Reference-contexts: Such an approach has also been investigated by others [5, 18]. To investigate the feasibility of this idea, we implemented the BSD packet filter language [29] using Fabius and compared its performance to BPF, a kernel-resident interpreter implemented in C <ref> [28] </ref>. The interpreter shown in Figure 3 is a simple ML function, called eval, that is parameterized by the filter program, a network packet, and variables that encode the machine state.
Reference: [29] <author> McCanne, S., and Jacobson, V. </author> <title> The BSD packet filter: A new architecture for user-level packet capture. </title> <booktitle> In Winter 1993 USENIX Conference (January 1993), USENIX Association, </booktitle> <pages> pp. 259-269. </pages>
Reference-contexts: For example, the BSD packet filter interpreter, which the BSD operating-system kernel uses for fast selection of network packets on behalf of user processes <ref> [29] </ref>, runs nearly 40% faster on typical inputs when translated from C to ML and compiled by Fabius. This paper describes our early experience with the Fabius compiler, with a particular emphasis on low-level optimization and code-generation issues. <p> Many useless packets may be delivered as a result, with a consequent degradation of performance. A commonly adopted solution to this problem is to parameterize a packet filter by a selection predicate that is dynamically constructed by a user-level process <ref> [30, 29] </ref>. A selection predicate is expressed in the abstract syntax of a "safe" or easily verified programming language, so that it 6 can be trusted by the kernel. But this approach has sub-stantial overhead: the selection predicate is reinterpreted every time a packet is received. <p> More generally, run-time code generation can allow a kernel to efficiently execute "agents" supplied by user-level processes while avoiding context switches. Such an approach has also been investigated by others [5, 18]. To investigate the feasibility of this idea, we implemented the BSD packet filter language <ref> [29] </ref> using Fabius and compared its performance to BPF, a kernel-resident interpreter implemented in C [28]. The interpreter shown in Figure 3 is a simple ML function, called eval, that is parameterized by the filter program, a network packet, and variables that encode the machine state.
Reference: [30] <author> Mogul, J. C., Rashid, R. F., and Accetta, M. J. </author> <title> The packet filter: An efficient mechanism for user-level network code. </title> <booktitle> In ACM Symposium on Operating Systems Principles (November 1987), </booktitle> <publisher> ACM Press, </publisher> <pages> pp. 39-51. </pages> <note> An updated version is available as DEC WRL Research Report 87/2. </note>
Reference-contexts: Many useless packets may be delivered as a result, with a consequent degradation of performance. A commonly adopted solution to this problem is to parameterize a packet filter by a selection predicate that is dynamically constructed by a user-level process <ref> [30, 29] </ref>. A selection predicate is expressed in the abstract syntax of a "safe" or easily verified programming language, so that it 6 can be trusted by the kernel. But this approach has sub-stantial overhead: the selection predicate is reinterpreted every time a packet is received.
Reference: [31] <author> Pike, R., Locanthi, B., and Reiser, J. </author> <title> Hardware/software trade-offs for bitmap graphics on the Blit. </title> <journal> Software | Practice and Experience 15, </journal> <volume> 2 (Febru-ary 1985), </volume> <pages> 131-151. </pages>
Reference-contexts: Run-time code generation also led to notable performance improvements in the areas of operating systems [4, 8, 26, 33, 36], method dispatch in object-oriented systems [1, 9, 13, 20], instruction-set simulation [10], graphics <ref> [14, 31] </ref>, and many other applications. With the emergence of highly distributed and Web computing, more applications demand software that is general-purpose, safe, and highly compos-able. <p> Code is generated simply by copying templates and instantiating holes with values computed at run time; templates may also be concatenated to effect loop unrolling and function inlin-ing. Several systems have used this approach with great success, such as Pike, Locanthi, and Reiser's bitblt compiler <ref> [31] </ref> and in Massalin and Pu's Synthesis kernel [27]. Until very recently, the use of templates has imposed a significant burden on programmers. Templates and the code that instantiates them are typically constructed manually, which is non-portable and error prone.
Reference: [32] <author> Poletto, M., Engler, D. R., and Kaashoek, M. F. tcc: </author> <title> A template-based compiler for `C. </title> <booktitle> In WCSSS'96 Workshop on Compiler Support for System Software (February 1996), </booktitle> <pages> pp. 1-7. </pages>
Reference-contexts: The Fabius compiler is not a partial evaluator, but it does create specialized run-time code generators (as generating extensions) that do not manipulate templates nor any 2 other intermediate representation of code at run time. A similar approach has also been employed recently by the tcc compiler for `C <ref> [15, 32] </ref>. In contrast to tcc, Fabius achieves run-time code generation from completely ordinary ML programs (rather than depending on language extensions), and is more systematic in its use of well-known techniques and heuristics from partial evaluation.
Reference: [33] <author> Pu, C., Autrey, T., Black, A., Consel, C., Cowan, C., Inouye, J., Kethana, L., Walpole, J., and Zhang, K. </author> <title> Optimistic incremental specialization: Streamlining a commercial operating system. </title> <booktitle> In Symposium on Operating Systems Principles (Decem-ber 1995). </booktitle>
Reference-contexts: This program was both general (because it accepted any regular expression) and fast (because it generated special-purpose code quickly). Run-time code generation also led to notable performance improvements in the areas of operating systems <ref> [4, 8, 26, 33, 36] </ref>, method dispatch in object-oriented systems [1, 9, 13, 20], instruction-set simulation [10], graphics [14, 31], and many other applications. With the emergence of highly distributed and Web computing, more applications demand software that is general-purpose, safe, and highly compos-able.
Reference: [34] <author> Tarditi, D., Morrisett, J. G., Cheng, P., Stone, C., Harper, R., and Lee, P. </author> <title> TIL: A type-directed optimizing compiler for ML. </title> <booktitle> In PLDI'96 Conference on Programming Language Design and Implementation (May 1996). </booktitle>
Reference-contexts: Existing ML compilers commonly use tags to distinguish between integers and pointers to support efficient garbage collection, but this approach has undesirable side effects: integers are restricted to 31 bits and numerous tagging and untagging operations are involved in arithmetic operations. The TIL compiler project <ref> [34] </ref> has shown that a principled use of types at compile time and run time permits most ML code to be compiled into tag-free, monomorphic code. Hence, we have focused on efficiently compiling such code and have ignored the problem of tagging.
Reference: [35] <author> Thompson, K. </author> <title> Regular expression search algorithm. </title> <journal> Communications of the Association for Computing Machinery 11, </journal> <month> 6 (June </month> <year> 1968), </year> <pages> 419-422. </pages>
Reference-contexts: For example, in 1968 Ken Thompson implemented a search algorithm that compiled a user-supplied regular expression into an executable finite-state machine in the form of native code for the IBM 7094 <ref> [35] </ref>. This program was both general (because it accepted any regular expression) and fast (because it generated special-purpose code quickly). <p> Because the cost of run-time code generation was low, performance on smaller systems of equations was also superior to the statically optimized code. regular-expression matching algorithm using run-time code generation. Unlike Thompson's compiler for regular expressions <ref> [35] </ref>, our program is a simple backtracking interpreter. Fabius compiled it into a code generator that, given a regular expression, creates a finite state machine (in native MIPS code).
Reference: [36] <author> Volanschi, E.-N., Muller, G., and Consel, C. </author> <title> Safe operating system specialization: the RPC case study. </title> <booktitle> In WCSSS'96 Workshop on Compiler Support for System Software (February 1996). </booktitle>
Reference-contexts: This program was both general (because it accepted any regular expression) and fast (because it generated special-purpose code quickly). Run-time code generation also led to notable performance improvements in the areas of operating systems <ref> [4, 8, 26, 33, 36] </ref>, method dispatch in object-oriented systems [1, 9, 13, 20], instruction-set simulation [10], graphics [14, 31], and many other applications. With the emergence of highly distributed and Web computing, more applications demand software that is general-purpose, safe, and highly compos-able. <p> Templates and the code that instantiates them are typically constructed manually, which is non-portable and error prone. Recent work has explored the automatic derivation of templates from programs written in higher-level languages. For example, the Tempo system <ref> [11, 36] </ref> uses gcc to create machine code templates corresponding to portions of ordinary C programs that are classified as dynamic by a binding-time analysis. Chambers and colleagues adopt a similar approach, using the Multiflow compiler to generate templates for programmer-delimited dynamic regions in Modula-3 programs [4, 8].
Reference: [37] <author> Wainwright, R. L., and Sexton, M. E. </author> <title> A study of sparse matrix representations for solving linear systems in a functional language. </title> <journal> Journal of Functional Programming 2, </journal> <month> 1 (January </month> <year> 1992), </year> <pages> 61-72. 12 </pages>
Reference-contexts: The total cost of run-time code generation varied from one benchmark to the next, but its relative cost was low, averaging roughly six cycles per generated instruction. The first benchmark (Figure 5a) is an iterative solver for sparse linear systems of equations, adapted from <ref> [37] </ref>. It is based on the conjugate gradient method, which finds solutions to systems of equations of the form Ax = b, where A is a square, symmetric, positive-definite matrix of double-floating-point values.
References-found: 37

