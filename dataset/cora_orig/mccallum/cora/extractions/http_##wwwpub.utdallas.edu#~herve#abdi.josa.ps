URL: http://wwwpub.utdallas.edu/~herve/abdi.josa.ps
Refering-URL: http://www.cnl.salk.edu/~wiskott/Bibliographies/FaceProcessing.html
Root-URL: http://www.cnl.salk.edu/~wiskott/Bibliographies/FaceProcessing.html
Title: Can a Linear Autoassociator Recognize Faces From New Orientations?  
Author: Dominique Valentin and Herve Abdi 
Date: Received: February 1995, accepted: June 1995, revised version received: October 1995  
Address: Dallas, Richardson, TX 75083-0688, and Universite de Bourgogne  21004 France.  
Affiliation: School of Human Development, The University of Texas at  
Note: Vol.13 #/Month 1996/ J. Opt. Soc. Am. A.  a Dijon, Dijon  
Abstract: An often noted limitation of computational models of faces operating on 2D pixel intensity representations is that they cannot handle changes in orientation. We show that this limitation can be overcome by using multiple views of a given face instead of a single view to represent the face. Specifically, we show that a linear autoassociator trained to reconstruct multiple views of a set of faces is able to recognize the faces from new view angles. An analysis of the internal representation of the memory (i.e., eigenvectors of the between unit connection weight matrix) shows a dissociation between two kinds of perceptual information: orientation versus identity information. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <editor> H. Abdi, and D. Valentin, "Modeles neuronaux, connex-ionistes et numeriques pour la memoire des visages", Psy-chologie Francaise, </editor> <volume> Vol. 39, </volume> <pages> pp. 375-391, </pages> <year> 1994. </year>
Reference-contexts: These models have been successfully applied to a wide range of tasks such as image compression, face detection, categorization, recognition, and identification, as well as feature detection and selection (see <ref> [1, 2] </ref> for reviews). Much of the effort going into these recent models has been concentrated on the processing of single frontal (or nearly frontal) two-dimensional (or 2D, in brief) pixel-based representations of faces. <p> In particular, if j is properly chosen ([25]), [n] converges toward the unity matrix, and W [n] from Eq. (6) converges towards W <ref> [1] </ref> = UU T (8) which is equivalent to saying that the weight matrix is sphericized [24] (i.e., all its eigenvalues are equal to one). Along the same lines, retrieval of a given face by the memory can be expressed as a weighted linear combination of the eigenvectors of W.
Reference: [2] <author> D. Valentin, H. Abdi, A.J. O'Toole, and G.W. Cottrell, </author> <title> "Connectionist models of face processing: A survey", </title> <journal> Pattern Recognition, </journal> <volume> Vol. 27, </volume> <pages> pp. 1209-1230, </pages> <year> 1994. </year>
Reference-contexts: These models have been successfully applied to a wide range of tasks such as image compression, face detection, categorization, recognition, and identification, as well as feature detection and selection (see <ref> [1, 2] </ref> for reviews). Much of the effort going into these recent models has been concentrated on the processing of single frontal (or nearly frontal) two-dimensional (or 2D, in brief) pixel-based representations of faces.
Reference: [3] <author> M. Turk, and A. Pentland, </author> <title> "Eigenfaces for recognition", </title> <journal> J. Cognitive Neurosci., </journal> <volume> Vol. 3, </volume> <pages> pp. 71-86, </pages> <year> 1991. </year>
Reference-contexts: To avoid these problems, a preprocessing of the faces is necessary. However, this can be done in a relatively straightforward manner by using automatic algorithms for locating the faces in the images and normalizing them for size, lighting and position (e.g., <ref> [3] </ref>). Most models in the literature assume that the preprocessing step has already been implemented and focus on the problem of face recognition per se. <p> Because of these properties, autoassociative memories are also a useful tool for compressing <ref> [19, 3] </ref> and analyzing [20] the perceptual information in faces. In the framework of image compression, the principal components analysis (pca) technique (or Kar-hunen@-Loeve transform or singular value decomposition, cf. [21]) amounts to computing the eigenvec-tors of the pixel-covariance matrix of a set of images represented as gray-level vectors. <p> using this type of analysis showed that: * The eigenvectors of a face autoassociative memory are face-like and can be interpreted as some kinds of macrofeatures or building blocks from which the faces are made [15, 19]. * A face can be approximated using a small num ber of eigenvectors <ref> [19, 3] </ref>. * Different ranges of eigenvectors convey different types of information. Specifically, eigenvectors with large eigenvalues convey mostly information useful for categorizing the faces along general semantic dimensions such as sex or race. Conversely, eigenvectors with low eigenvalues convey information useful for identifying specific faces [21, 20].
Reference: [4] <author> W.D. Dukes, and W. Bevan, </author> <title> "Stimulus variation and repetition in the acquisition of naming responses", </title> <journal> J. Exper. Psychol., </journal> <volume> Vol. 74, </volume> <pages> pp. 178-181, </pages> <year> 1967. </year>
Reference-contexts: The methodology of this study is based on empirical evidence suggesting that human subjects trained with multiple 2D views of unfamiliar faces handle depth rotation better than human subjects trained with single views of the same faces <ref> [4, 5] </ref>. This could be due to several reasons. First, subjects could elaborate a 3D invariant representation of the faces, such as the object-centered structural description described by Marr and Nishihara [6] for object recognition.
Reference: [5] <author> J.C. Bartlett, and J.E. Leslie, </author> <title> "Aging and memory for faces versus single views of faces", </title> <journal> Memory and Cognition, </journal> <volume> Vol. 14, </volume> <pages> pp, 371-381, </pages> <year> 1986. </year>
Reference-contexts: The methodology of this study is based on empirical evidence suggesting that human subjects trained with multiple 2D views of unfamiliar faces handle depth rotation better than human subjects trained with single views of the same faces <ref> [4, 5] </ref>. This could be due to several reasons. First, subjects could elaborate a 3D invariant representation of the faces, such as the object-centered structural description described by Marr and Nishihara [6] for object recognition.
Reference: [6] <author> D. Marr, and H.K. Nishihara, </author> " <title> Representation and recognition of the spatial organization of three dimensional shape", </title> <journal> Proc. Royal Soc. of London, B, </journal> <volume> Vol. 200, </volume> <pages> pp. 269-294, </pages> <year> 1978. </year>
Reference-contexts: This could be due to several reasons. First, subjects could elaborate a 3D invariant representation of the faces, such as the object-centered structural description described by Marr and Nishihara <ref> [6] </ref> for object recognition. However, although the object-centered approach seems relevant for the general domain of object recognition, its extension to the specific case of face recognition is problematic.
Reference: [7] <author> E. Rosch, </author> <title> "Principle of categorization". </title> <editor> In E. Rosch and B. Lloyd (Eds.), </editor> <title> Cognition and categorization, </title> <publisher> Hillsdalle Erlbaum, </publisher> <pages> pp. 27-48, </pages> <year> 1978. </year>
Reference-contexts: While object recognition requires stimuli to be assigned to broad categories that maximize the physical similarities between exemplars (i.e., the "basic level categories" as defined by Rosch <ref> [7] </ref>), face recognition requires the discrimination of stimuli within the basic level category "face." Object-centered models seem more appropriate for assigning objects to basic level categories than for discriminating instances within basic level categories.
Reference: [8] <author> S. Edelman, and H. Bulthoff, </author> <title> "Orientation dependence in the recognition of familiar and novel views of three dimensional objects", </title> <journal> Vision Research, </journal> <volume> Vol. 32, </volume> <pages> pp. 2385-2400, </pages> <year> 1992. </year>
Reference-contexts: Some recent studies in computational theory of 3D object recognition suggest that, for basic level categories, objects might be more efficiently represented using a set of viewer-centered representations 1 2 D. Valentin & H. Abdi Vol.13 #/Month 1996/ J. Opt. Soc. Am. A. than a single object-centered representation <ref> [8, 9, 10] </ref>. These representations depend on the position of the viewer relative to the object to be recognized, and therefore are specific to the particular viewpoint from which the object is perceived.
Reference: [9] <author> D.G. Lowe, </author> <title> "Three-dimensional object recognition from single two-dimensional images", </title> <journal> Artificial Intelligence, </journal> <volume> Vol. 31, </volume> <pages> pp. 355-395, </pages> <year> 1987. </year> <editor> D. Valentin & H. Abdi Vol.13 #/Month 1996/ J. </editor> <publisher> Opt. Soc. </publisher> <address> Am. </address> <publisher> A. </publisher> <pages> 11 </pages>
Reference-contexts: Some recent studies in computational theory of 3D object recognition suggest that, for basic level categories, objects might be more efficiently represented using a set of viewer-centered representations 1 2 D. Valentin & H. Abdi Vol.13 #/Month 1996/ J. Opt. Soc. Am. A. than a single object-centered representation <ref> [8, 9, 10] </ref>. These representations depend on the position of the viewer relative to the object to be recognized, and therefore are specific to the particular viewpoint from which the object is perceived.
Reference: [10] <author> S. Ullman, </author> <title> "Aligning pictorial descriptions: An approach to object recognition", </title> <journal> Cognition, </journal> <volume> Vol. 32, </volume> <pages> pp. 97-136, </pages> <year> 1989. </year>
Reference-contexts: Some recent studies in computational theory of 3D object recognition suggest that, for basic level categories, objects might be more efficiently represented using a set of viewer-centered representations 1 2 D. Valentin & H. Abdi Vol.13 #/Month 1996/ J. Opt. Soc. Am. A. than a single object-centered representation <ref> [8, 9, 10] </ref>. These representations depend on the position of the viewer relative to the object to be recognized, and therefore are specific to the particular viewpoint from which the object is perceived.
Reference: [11] <author> M.J. Tarr, and S. Pinker, </author> <title> "Mental rotation and orientation dependence in shape recognition", </title> <journal> Cognitive Psy-chol., </journal> <volume> Vol. 21, </volume> <pages> pp. 233-282, </pages> <year> 1990. </year>
Reference-contexts: Applied to the problem of face recognition, a face could be represented in memory by a limited set of 2D view-dependent descriptions that correspond to its familiar orientations. Recognition could be achieved by transforming an input representation of a face to the orientation of the nearest stored representation <ref> [11] </ref>, or, if the faces are represented by a series of views that are close enough to each other, by interpolating among those views [12, 13, 14].
Reference: [12] <author> S. Edelman, and D. Weinshall, </author> <title> "A self-organizing multiple-view representation of 3-D objects", </title> <journal> Biol. Cy-bern., </journal> <volume> Vol. 64, </volume> <pages> pp. 209-219, </pages> <year> 1991. </year>
Reference-contexts: Recognition could be achieved by transforming an input representation of a face to the orientation of the nearest stored representation [11], or, if the faces are represented by a series of views that are close enough to each other, by interpolating among those views <ref> [12, 13, 14] </ref>. In the series of simulations we report here, we trained an autoassociative memory by using multiple views of a set of faces, and we tested its ability to generalize to new views of the learned faces.
Reference: [13] <author> H. Bulthoff, and S. </author> <title> Edelman (1992), "Psychological support for a two dimensional view interpolation theory of object recognition", </title> <journal> Proc. National Academy of Sci., </journal> <volume> Vol. 89, </volume> <pages> pp. 60-64, </pages> <year> 1992. </year>
Reference-contexts: Recognition could be achieved by transforming an input representation of a face to the orientation of the nearest stored representation [11], or, if the faces are represented by a series of views that are close enough to each other, by interpolating among those views <ref> [12, 13, 14] </ref>. In the series of simulations we report here, we trained an autoassociative memory by using multiple views of a set of faces, and we tested its ability to generalize to new views of the learned faces.
Reference: [14] <author> T. Poggio, and S. Edelman, </author> <title> "A network that learns to recognize three-dimensional objects", </title> <journal> Nature, </journal> <volume> Vol. 343, </volume> <pages> pp. 263-266, </pages> <year> 1990. </year>
Reference-contexts: Recognition could be achieved by transforming an input representation of a face to the orientation of the nearest stored representation [11], or, if the faces are represented by a series of views that are close enough to each other, by interpolating among those views <ref> [12, 13, 14] </ref>. In the series of simulations we report here, we trained an autoassociative memory by using multiple views of a set of faces, and we tested its ability to generalize to new views of the learned faces.
Reference: [15] <author> A. Abdi, </author> <title> "A generalized approach for connectionist auto-associative memories: interpretation, implications and illustration for face processing", </title> <editor> In J. Demongeot (Ed.) </editor> <booktitle> Artificial Intelligence and Cognitive Sciences, </booktitle> <publisher> Manchester University Press, </publisher> <year> 1988. </year>
Reference-contexts: Au-toassociative memories are a powerful tool for storing, recognizing, and categorizing faces represented as pixel-intensity images <ref> [15, 16, 17, 18] </ref>. Their power stems mainly from the fact that they 1) use extremely efficient and well explored computational algorithms (i.e., eigenvalue and singular value decomposition) and 2) are easily analyzable in terms of traditional mathematical concepts and statistical techniques (i.e., least-squares estimation and principal components analysis). <p> here is somewhat similar to the approach of both Murase and Nayar [22] and Pentland et al. [23] in that using an autoassociative memory to store and retrieve faces is equivalent to computing the eigendecomposition of the set of faces and representing the faces as a weighted sum of eigenvectors <ref> [15] </ref>. Specifically, since the autoassociative memory is trained with multiple views of a set of faces, it is equivalent to the universal eigenspace representation proposed by Murase and Nayar, with the exception that in our application, all the eigenvectors of the set of faces are kept. <p> Previous studies using this type of analysis showed that: * The eigenvectors of a face autoassociative memory are face-like and can be interpreted as some kinds of macrofeatures or building blocks from which the faces are made <ref> [15, 19] </ref>. * A face can be approximated using a small num ber of eigenvectors [19, 3]. * Different ranges of eigenvectors convey different types of information. Specifically, eigenvectors with large eigenvalues convey mostly information useful for categorizing the faces along general semantic dimensions such as sex or race.
Reference: [16] <author> T. Kohonen, </author> <title> Associative Memory: A System Theoretic Approach, </title> <publisher> Springer-Verlag, </publisher> <year> 1977. </year>
Reference-contexts: Au-toassociative memories are a powerful tool for storing, recognizing, and categorizing faces represented as pixel-intensity images <ref> [15, 16, 17, 18] </ref>. Their power stems mainly from the fact that they 1) use extremely efficient and well explored computational algorithms (i.e., eigenvalue and singular value decomposition) and 2) are easily analyzable in terms of traditional mathematical concepts and statistical techniques (i.e., least-squares estimation and principal components analysis). <p> Eigenvector Representation. One advantage of using an autoassociative memory to store faces is that, since the weight matrix W is a cross-product matrix (and therefore is positive semi-definite), it can be analyzed in terms of its eigendecomposition <ref> [28, 16] </ref> as W = XX T = UflU T with U T U = I (5) where U is the matrix of eigenvectors of W, and fl is the diagonal matrix of eigenvalues. The eigende-composition of W can be used also to analyze the 8 D. Valentin & H.
Reference: [17] <author> A.J. O'Toole, R.B. Millward, and J.A. Anderson, </author> <title> "A physical system approach to recognition memory for spatially transformed faces", </title> <journal> Neural Network, </journal> <volume> Vol. 1, </volume> <pages> pp. 179-199, </pages> <year> 1988. </year>
Reference-contexts: Au-toassociative memories are a powerful tool for storing, recognizing, and categorizing faces represented as pixel-intensity images <ref> [15, 16, 17, 18] </ref>. Their power stems mainly from the fact that they 1) use extremely efficient and well explored computational algorithms (i.e., eigenvalue and singular value decomposition) and 2) are easily analyzable in terms of traditional mathematical concepts and statistical techniques (i.e., least-squares estimation and principal components analysis).
Reference: [18] <author> A.J. O'Toole, H. Abdi, K.A. Deffenbacher, and J.C. Bartlett, </author> <title> "Classifying faces by race and sex using an au-toassociative memory trained for recognition", </title> <editor> In K.J. Hammomd and D. Gentner (Eds.) </editor> <booktitle> Proc. 13th Annu. Conf. Cognitive Sci. </booktitle> <publisher> Soc., Hillsdale Erlbaum, </publisher> <year> 1991. </year>
Reference-contexts: Au-toassociative memories are a powerful tool for storing, recognizing, and categorizing faces represented as pixel-intensity images <ref> [15, 16, 17, 18] </ref>. Their power stems mainly from the fact that they 1) use extremely efficient and well explored computational algorithms (i.e., eigenvalue and singular value decomposition) and 2) are easily analyzable in terms of traditional mathematical concepts and statistical techniques (i.e., least-squares estimation and principal components analysis).
Reference: [19] <author> L. Sirovich, and M. Kirby, </author> <title> "Low-dimensional procedure for the characterization of human faces", </title> <journal> J. Opt. Soc. Am. A, </journal> <volume> Vol. 4, </volume> <pages> pp. 519-554, </pages> <year> 1987. </year>
Reference-contexts: Because of these properties, autoassociative memories are also a useful tool for compressing <ref> [19, 3] </ref> and analyzing [20] the perceptual information in faces. In the framework of image compression, the principal components analysis (pca) technique (or Kar-hunen@-Loeve transform or singular value decomposition, cf. [21]) amounts to computing the eigenvec-tors of the pixel-covariance matrix of a set of images represented as gray-level vectors. <p> Previous studies using this type of analysis showed that: * The eigenvectors of a face autoassociative memory are face-like and can be interpreted as some kinds of macrofeatures or building blocks from which the faces are made <ref> [15, 19] </ref>. * A face can be approximated using a small num ber of eigenvectors [19, 3]. * Different ranges of eigenvectors convey different types of information. Specifically, eigenvectors with large eigenvalues convey mostly information useful for categorizing the faces along general semantic dimensions such as sex or race. <p> using this type of analysis showed that: * The eigenvectors of a face autoassociative memory are face-like and can be interpreted as some kinds of macrofeatures or building blocks from which the faces are made [15, 19]. * A face can be approximated using a small num ber of eigenvectors <ref> [19, 3] </ref>. * Different ranges of eigenvectors convey different types of information. Specifically, eigenvectors with large eigenvalues convey mostly information useful for categorizing the faces along general semantic dimensions such as sex or race. Conversely, eigenvectors with low eigenvalues convey information useful for identifying specific faces [21, 20].
Reference: [20] <author> A.J. O'Toole, H. Abdi, K.A. Deffenbacher, and D. Valentin, </author> <title> "A low-dimensional representation of faces in higher dimensions of the space", </title> <journal> J. Opt. Soc. Am. A, </journal> <volume> Vol. 10, </volume> <pages> pp. 405-411, </pages> <year> 1993. </year>
Reference-contexts: Because of these properties, autoassociative memories are also a useful tool for compressing [19, 3] and analyzing <ref> [20] </ref> the perceptual information in faces. In the framework of image compression, the principal components analysis (pca) technique (or Kar-hunen@-Loeve transform or singular value decomposition, cf. [21]) amounts to computing the eigenvec-tors of the pixel-covariance matrix of a set of images represented as gray-level vectors. <p> Specifically, eigenvectors with large eigenvalues convey mostly information useful for categorizing the faces along general semantic dimensions such as sex or race. Conversely, eigenvectors with low eigenvalues convey information useful for identifying specific faces <ref> [21, 20] </ref>. Using this eigendecomposition technique, we examined the perceptual information conveyed by different ranges of eigenvectors extracted from a cross-product face matrix built from 5 views of 30 female faces. <p> This dissociation is reminiscent of previous dissociations found between semantic components (e.g., gender, race) of face and identity (cf. <ref> [20] </ref>). The method of displaying eigenvectors and combining them, as shown in this paper, can, in principle, be applied to any eigenvector based methods, and to materials other than faces.
Reference: [21] <author> H. Abdi, D. Valentin, B. Edelman, and A.J. O'Toole, </author> <title> "More about the difference between men and women: Evidence from linear neural networks and the principal component approach", </title> <journal> Perception, </journal> <volume> Vol. 24, </volume> <pages> pp, 539-562, </pages> <year> 1995. </year>
Reference-contexts: Because of these properties, autoassociative memories are also a useful tool for compressing [19, 3] and analyzing [20] the perceptual information in faces. In the framework of image compression, the principal components analysis (pca) technique (or Kar-hunen@-Loeve transform or singular value decomposition, cf. <ref> [21] </ref>) amounts to computing the eigenvec-tors of the pixel-covariance matrix of a set of images represented as gray-level vectors. The eigenvec-tors constitute an orthogonal basis for representing (i.e., in the eigenspace) the images. <p> Specifically, eigenvectors with large eigenvalues convey mostly information useful for categorizing the faces along general semantic dimensions such as sex or race. Conversely, eigenvectors with low eigenvalues convey information useful for identifying specific faces <ref> [21, 20] </ref>. Using this eigendecomposition technique, we examined the perceptual information conveyed by different ranges of eigenvectors extracted from a cross-product face matrix built from 5 views of 30 female faces.
Reference: [22] <author> H. Murase, and S.K. Nayar, </author> <title> "Learning and recognition of 3D objects from appearance", </title> <booktitle> IEEE 2nd Qualitative Vision Workshop, </booktitle> <year> 1993. </year>
Reference-contexts: This approach as been applied recently to the problems of 3D object recognition by Murase and Nayar <ref> [22] </ref> and 3D face recognition by Pentland, Moghaddam, and Starner [23]. Murase and Nayar represented a set of objects using two different types of eigenspaces. A universal eigenspace, and an object eigenspace. The universal eigenspace is used to identify the object presented as prompt. <p> The projection coefficients of the face onto the closest eigenspace are then used to "identify" the face using a nearest-neighbor algorithm. The autoassociative model we present here is somewhat similar to the approach of both Murase and Nayar <ref> [22] </ref> and Pentland et al. [23] in that using an autoassociative memory to store and retrieve faces is equivalent to computing the eigendecomposition of the set of faces and representing the faces as a weighted sum of eigenvectors [15].
Reference: [23] <author> A. Pentland, B. Moghaddam, and T. Starner, </author> <title> "View-based and modular eigenspaces for face recognition" Proc. </title> <journal> IEEE Conf. Comput. Vision and Pattern Recognition, </journal> <year> 1994. </year>
Reference-contexts: This approach as been applied recently to the problems of 3D object recognition by Murase and Nayar [22] and 3D face recognition by Pentland, Moghaddam, and Starner <ref> [23] </ref>. Murase and Nayar represented a set of objects using two different types of eigenspaces. A universal eigenspace, and an object eigenspace. The universal eigenspace is used to identify the object presented as prompt. <p> The universal eigenspace is used to identify the object presented as prompt. Once the object is identified as a particular object, it is projected onto the appropriate object eigenspace and its orientation is determined. A somewhat different approach was used by Pent-land et al. <ref> [23] </ref>. Instead of the universal and object eigenspaces proposed by Murase and Nayar, they used a multiple set of view-based eigenspaces. Each eigenspace is obtained by computing the eigenvectors of an image set of different individuals in a common orientation. <p> The projection coefficients of the face onto the closest eigenspace are then used to "identify" the face using a nearest-neighbor algorithm. The autoassociative model we present here is somewhat similar to the approach of both Murase and Nayar [22] and Pentland et al. <ref> [23] </ref> in that using an autoassociative memory to store and retrieve faces is equivalent to computing the eigendecomposition of the set of faces and representing the faces as a weighted sum of eigenvectors [15]. <p> In contrast, in the 9-view condition, the memory is clearly able to discriminate between learned and new faces (area under roc =.79). This performance is somewhat poorer than the performance reported in previous work by Pentland et al. <ref> [23] </ref>. Using a set of nine "view-based" eigenspaces to estimate first the orientation of the face, and then recognize it, they obtained an average performance of 86% correct recognition. The model proposed by Pentland et al. differs in two ways from the autoas-sociative model described here.
Reference: [24] <author> A. Abdi, Les reseaux de neurones, </author> <title> Grenoble: </title> <institution> Presses Uni-versitaires de Grenoble, </institution> <year> 1994. </year>
Reference-contexts: D. Valentin & H. Abdi Vol.13 #/Month 1996/ J. Opt. Soc. Am. A. 5 simply by using the eigendecomposition of W <ref> [24, 25] </ref>. After complete Widrow-Hoff learning, all the faces in the training set are perfectly reconstructed, and if new faces are used as memory cues, they are distorted as an inverse function of their similarity with the training faces (cf. Figure 2, bottom row). <p> The dotted lines represent the 1-view condition, the dashed lines the 4-view condition, and the solid lines the 9-view condition. Widrow-Hoff learning rule. Specifically, Equation 4 can be rewritten as (cf. <ref> [24] </ref>) W [n+1] = U [n] U T (6) with [n] = I (I jfl) n (7) which shows that Widrow-Hoff learning affects only the eigenvalues of W. <p> In particular, if j is properly chosen ([25]), [n] converges toward the unity matrix, and W [n] from Eq. (6) converges towards W [1] = UU T (8) which is equivalent to saying that the weight matrix is sphericized <ref> [24] </ref> (i.e., all its eigenvalues are equal to one). Along the same lines, retrieval of a given face by the memory can be expressed as a weighted linear combination of the eigenvectors of W.
Reference: [25] <author> A. Abdi, </author> <title> "A neural network primer", </title> <journal> J. Biol. Syst., </journal> <volume> Vol. 2, </volume> <pages> pp. 247-281, </pages> <year> 1994. </year>
Reference-contexts: D. Valentin & H. Abdi Vol.13 #/Month 1996/ J. Opt. Soc. Am. A. 5 simply by using the eigendecomposition of W <ref> [24, 25] </ref>. After complete Widrow-Hoff learning, all the faces in the training set are perfectly reconstructed, and if new faces are used as memory cues, they are distorted as an inverse function of their similarity with the training faces (cf. Figure 2, bottom row).
Reference: [26] <author> D. Valentin, H. Abdi, A.J. O'Toole, </author> <title> "Categorization and identification of human face images by neural networks: A review of the linear autoassociative and principal component approaches", </title> <journal> J. Biol. Syst., </journal> <volume> Vol. 2, </volume> <pages> pp. 413-429, </pages> <year> 1994. </year>
Reference-contexts: After complete Widrow-Hoff learning, all the faces in the training set are perfectly reconstructed, and if new faces are used as memory cues, they are distorted as an inverse function of their similarity with the training faces (cf. Figure 2, bottom row). Previous studies (see <ref> [26] </ref> for a review) showed that autoassociative memories constitute a useful tool for recognizing and categorizing faces. Yet, the problem with these previous studies is that, because they used single views of the faces (generally a frontal view) as training sets, memory performance was very sensitive to depth rotation.
Reference: [27] <author> D.M. Green, and J.A. Swets, </author> <title> Signal Detection Theory and Psychophysics, </title> <address> New York: </address> <publisher> Wiley, Reprinted by Krieger, </publisher> <address> Huntington: NY, </address> <year> 1966. </year>
Reference-contexts: Different values of the cosine were used as the criterion to generate a receiver operating characteristic (roc, cf. <ref> [27] </ref>) for each view of the faces. This procedure was repeated until each view of the target faces was used, in turn, as the "new" view during testing. <p> This is the signal-detection measure used to assess the discriminability of the new stimuli. The area under the curve provides an unbiased estimate of the proportion of correct classification where chance performance is .50 <ref> [27] </ref>. rate for all values of the criterion, and therefore the memory is not able to "recognize" the faces on which it has been trained when those faces are presented in novel orientations (area under roc=.51).
Reference: [28] <author> J.A. Anderson, J.W. Silverstein, S.A. Ritz, and R.S. Jones, </author> <title> "Distinctive features, categorical perception, and probability learning: Some applications of a neural model", </title> <journal> Psychol. Rev., </journal> <volume> Vol. 84, </volume> <pages> pp. 413-451, </pages> <year> 1977. </year>
Reference-contexts: Eigenvector Representation. One advantage of using an autoassociative memory to store faces is that, since the weight matrix W is a cross-product matrix (and therefore is positive semi-definite), it can be analyzed in terms of its eigendecomposition <ref> [28, 16] </ref> as W = XX T = UflU T with U T U = I (5) where U is the matrix of eigenvectors of W, and fl is the diagonal matrix of eigenvalues. The eigende-composition of W can be used also to analyze the 8 D. Valentin & H.
References-found: 28

