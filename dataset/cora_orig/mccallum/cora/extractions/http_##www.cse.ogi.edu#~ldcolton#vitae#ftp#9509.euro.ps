URL: http://www.cse.ogi.edu/~ldcolton/vitae/ftp/9509.euro.ps
Refering-URL: http://www.cse.ogi.edu/~ldcolton/vitae/vitae.html
Root-URL: http://www.cse.ogi.edu
Email: email: Don Colton@cse.ogi.edu  
Title: UTTERANCE VERIFICATION IMPROVES CLOSED-SET RECOGNITION AND OUT-OF-VOCABULARY REJECTION  
Author: Don Colton Mark Fanty Ron Cole P. O. 
Address: Box 91000, Portland, Oregon 97291-1000 USA  
Affiliation: Oregon Graduate Institute  
Note: Center for Spoken Language Understanding,  
Web: http://www.cse.ogi.edu/CSLU/  
Abstract: We report on utterance verification of putative recognitions in both open-set and closed-set recognition tasks using telephone speech. For open-set recognition, we report on rejection of out-of-vocabulary utterances. In a two-keyword task ("male" and "female") using 50% out-of-vocabulary utterances, utterance verification reduced errors by 60%, from 12% to 4.8% compared to our baseline rejection strategy. For closed-set recognition, we report on re-ordering the N-best hypotheses. In a 58-phrase task, utterance verification reduced closed-set recognition errors by 30%, from 6.5% to 4.5%. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Mark Fanty, Ronald A. Cole, and Krist Ro-ginski. </author> <title> English alphabet recognition with telephone speech. </title> <editor> In D. S. Touretzky, editor, </editor> <booktitle> Advances in Neural Information Processing Systems 4, </booktitle> <address> Denver, 1992. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: We can also reject out-of-vocabulary utterances by rejecting the entire set of top-scoring matches from the N-best list. This paper extends prior work at the Center for Spoken Language Understanding (CSLU) on two-pass Alphabet recognition <ref> [1] </ref>. In the alphabet system, the frame-based first pass provides letter and broad-phonetic boundaries. The second pass uses an extensive set of knowledge-based features specifically designed for the alphabet.
Reference: [2] <author> Luc Mathan and Laurent Miclet. </author> <title> Rejection of extraneous input in speech recognition applications, using multi-layer perceptrons and the trace of HMMs. </title> <booktitle> In Proceedings of the 1991 International Conference on Acoustics, Speech, and Signal Processing (ICASSP-91), </booktitle> <pages> pages 93-96, </pages> <address> Toronto, </address> <month> May </month> <year> 1991. </year>
Reference-contexts: This contrasts with having the whole vocabulary in a single network. Also, the feature set is generic and not based on careful study of the vocabulary. Our work also extends that of Mathan and Miclet <ref> [2] </ref>. They used word-specific neural networks to reclassify putative hits in an isolated word recognizer. Their feature vector included duration, average energy and the average first Mel frequency coefficient for each segment in the trace of the first-pass recognition as input features.
Reference: [3] <author> Hynek Hermansky. </author> <title> Perceptual linear predictive (PLP) analysis of speech. </title> <journal> Journal of the Acoustical Society of America, </journal> <volume> 87(4) </volume> <pages> 1738-1752, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: THE FRAME-BASED CLASSIFIER For both experiments, the first pass is a frame-based classifier which uses a neural network to estimate phoneme probabilities. Speech analysis is seventh order Perceptual Linear Prediction (PLP) analysis <ref> [3] </ref>, which yields eight coefficients per frame including energy. The analysis window is 10 msec and the frame increment is 6 msec. The inputs to the neural network are 56 PLP coefficients from a 160msec window around the frame to be classified.
Reference: [4] <author> Etienne Barnard, Ronald A. Cole, Mark Fanty, and Pieter Vermeulen. </author> <title> Real-world speech recognition with neural networks. </title> <booktitle> In Applications and Science of artificial neural networks, </booktitle> <volume> volume 2492, </volume> <pages> pages 524-537. SPIE, </pages> <month> April </month> <year> 1995. </year>
Reference-contexts: The outputs of the network correspond to the phonetic units of the task. For the male/female task the net has only six outputs. For the 58-word task, we used a context-dependent net with sub-phoneme units <ref> [4] </ref> and there were several hundred outputs. The best alignment of a vocabulary word with the neural network probability estimates is found using a Viterbi search. Background sounds are modeled with a simple garbage model [5] which increases robustness and provides some wordspotting ability.
Reference: [5] <author> Jean-Marc Boite, Herve Bourlard, Bart D'hoore, and Marc Haesen. </author> <title> New approach towards keyword spotting. </title> <booktitle> In Proceedings of the Third European Conference on Speech Communication and Technology (EUROSPEECH-93), </booktitle> <pages> pages 1273-1276, </pages> <address> Berlin, </address> <month> September </month> <year> 1993. </year>
Reference-contexts: For the 58-word task, we used a context-dependent net with sub-phoneme units [4] and there were several hundred outputs. The best alignment of a vocabulary word with the neural network probability estimates is found using a Viterbi search. Background sounds are modeled with a simple garbage model <ref> [5] </ref> which increases robustness and provides some wordspotting ability. This makes out-of-vocabulary rejection more difficult, as the vocabulary word need only align with part of the extraneous speech. 3. OUT-OF-VOCABULARY REJECTION Our first experiment sought to identify and reject out-of-vocabulary utterances using a second-pass, whole-word classifier.
Reference: [6] <author> Ronald Cole, Mark Fanty, Mike Noel, and Terri Lander. </author> <title> Telephone speech corpus development at CSLU. </title> <booktitle> In Proceedings of the 1994 International Conference on Spoken Language Processing (ICSLP-94), </booktitle> <address> Yoko-hama, Japan, </address> <month> September </month> <year> 1994. </year>
Reference-contexts: All speech data in this experiment are from the OGI Census corpus <ref> [6] </ref>. We used gender utterances and last name utterances.
Reference: [7] <author> Ronald Cole, David G. Novick, Mark Fanty, Pieter Vermeulen, Stephen Sutton, Dan Bur-nett, and Johan Schalkwyk. </author> <title> A prototype voice-response questionnaire for the U.S. census. </title> <booktitle> In Proceedings of the 1994 International Conference on Spoken Language Processing (ICSLP-94), </booktitle> <address> Yokohama, Japan, </address> <month> September </month> <year> 1994. </year>
Reference-contexts: Baseline System The baseline system was a frame-based neural network recognizer for the two words "male" and "female." This recognizer was developed for and used in the OGI Census system <ref> [7] </ref>. When in-vocabulary utterances are used, the baseline system's accuracy is 99.5%. To detect low-confidence recognitions, the baseline system takes the ratio of the top two recognizer scores, and compares this to an optimized threshold. 3.2.
References-found: 7

