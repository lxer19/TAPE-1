URL: http://www.mli.gmu.edu/papers/mli98-6.ps
Refering-URL: http://www.mli.gmu.edu/kpubs.html
Root-URL: 
Title: 10 Learning Patterns in Images concentrated on neural network applications for example, road navigation [Pom91]
Author: Ryszard Michalski, Azriel Rosenfeld, Zoran Duric, Marcus Maloof, Qi Zhang 
Note: 10.1 INTRODUCTION Much of the current research on learning in vision systems has  etc.) [FeB96, RBP96, RBK96]. Advantages of these methods include their generality and their ability to  
Abstract: This chapter concerns problems of learning patterns in images and image sequences, and using them for interpreting new images. The chapter concentrates on three problem areas: (i) semantic interpretation of color images of outdoor scenes, (ii) detection of blasting caps in x-ray images of luggage, and (iii) recognizing actions in video image sequences. It discusses the image formation processes in these problem areas, and the choices of representation spaces used in our approaches to solving these problems. The results presented indicate the The underlying motivation of this research is that vision systems need learning capabilities for handling problems for which algorithmic solutions are unknown or difficult to obtain. Learning capabilities can also make vision systems more easily adaptable to different vision problems, and more flexible and robust in handling variable perceptual conditions [MRA94]. advantages of applying machine learning to vision.
Abstract-found: 1
Intro-found: 1
Reference: [BMP94] <author> Bala, J.W., Michalski, </author> <title> R.S., and Pachowicz, P.W., "Progress on vision through learning at George Mason University", </title> <booktitle> in Proc. ARPA Image Understanding Workshop, </booktitle> <pages> 191-207, </pages> <year> 1994. </year>
Reference-contexts: One particular multistrategy system combines neural network and symbolic learning. This method induces rules which are used to structure a neural network architecture. A secondary learning step refines the network's weights. This method provides generality and very fast recognition rates <ref> [BMP94, MZMB96] </ref>. One can also use neural networks for lower-level vision processes and symbolic methods for higher-level visual processes. These methods are potentially very powerful and promising directions of research. <p> MIST has been applied to a variety of problems including natural scene segmentation [MZMB96] and identification of blasting caps in x-ray images [MDMR96]. For classifying natural scenes, three learning techniques were compared: AQ15c [WKBM95], a backpropagation neural network [Zur92], and AQ-NN <ref> [BMP94] </ref>. AQ-NN is a multistrategy learning technique in that it uses two different representations and two different learning strategies. Specifically, the AQ learning algorithm is used to learn attributional decision rules from training examples. These decision rules are then used to structure a neural network architecture. <p> with the ASI pixels denoting a given class. 8 Michalski et al. 10.3.2 Implementation and Experimental Results The current MIST methodology has been implemented with the following learning systems: * Symbolic rule learning program AQ15c [MMHL86, WKBM95]. * Multistrategy learning system AQ-NN combining decision rule learning with neural network learning <ref> [BMP94] </ref>. * Multistrategy learning system AQ-GA that combines decision rule learning with a genetic algorithm [MBP93]. * Class similarity-based learning for building descriptions of large numbers of classes (PRAX) [BMW92, BMW93]. An earlier version of MIST has been applied to learning descriptions of classes of surfaces [MBP93].
Reference: [BMW92] <author> Bala, J., Michalski, R.S., and Wnek, J., </author> <title> "The principal axes method for constructive induction", </title> <booktitle> in Proc. International Conference on Machine Learning, </booktitle> <editor> D. Sleeman and P. Edwards (Eds.), Aberdeen, </editor> <address> Scotland, </address> <year> 1992. </year>
Reference-contexts: These techniques included optimizing learned symbolic descriptions by truncating rules [MMHL86], as well as removing training examples covered by weak rules and re-learning. The PRAX method for learning a large number of classes was introduced by Bala, Michalski, and Wnek <ref> [BMW92, BMW93] </ref>. Segen [Seg94] used a hybrid shape representation consisting of a hierarchical graph that takes into account local features of high curvature, and the angles and distances between these local features. This representation is invariant to both planar rotation and translation. Shapes were silhouettes of hand gestures. <p> * Symbolic rule learning program AQ15c [MMHL86, WKBM95]. * Multistrategy learning system AQ-NN combining decision rule learning with neural network learning [BMP94]. * Multistrategy learning system AQ-GA that combines decision rule learning with a genetic algorithm [MBP93]. * Class similarity-based learning for building descriptions of large numbers of classes (PRAX) <ref> [BMW92, BMW93] </ref>. An earlier version of MIST has been applied to learning descriptions of classes of surfaces [MBP93].
Reference: [BMW93] <author> Bala, J., Michalski, R.S., and Wnek, J., </author> <title> "The PRAX approach to learning a large number of texture concepts", </title> <booktitle> in Proc. Machine Learning in Computer Vision: What, Why and How?, AAAI Fall Symposium on Machine Learning in Computer Vision, </booktitle> <year> 1993. </year>
Reference-contexts: These techniques included optimizing learned symbolic descriptions by truncating rules [MMHL86], as well as removing training examples covered by weak rules and re-learning. The PRAX method for learning a large number of classes was introduced by Bala, Michalski, and Wnek <ref> [BMW92, BMW93] </ref>. Segen [Seg94] used a hybrid shape representation consisting of a hierarchical graph that takes into account local features of high curvature, and the angles and distances between these local features. This representation is invariant to both planar rotation and translation. Shapes were silhouettes of hand gestures. <p> * Symbolic rule learning program AQ15c [MMHL86, WKBM95]. * Multistrategy learning system AQ-NN combining decision rule learning with neural network learning [BMP94]. * Multistrategy learning system AQ-GA that combines decision rule learning with a genetic algorithm [MBP93]. * Class similarity-based learning for building descriptions of large numbers of classes (PRAX) <ref> [BMW92, BMW93] </ref>. An earlier version of MIST has been applied to learning descriptions of classes of surfaces [MBP93].
Reference: [Bie85] <author> Biederman, I., </author> <title> "Human image understanding: Recent research and a theory", Computer Vision, </title> <journal> Graphics and Image Processing, </journal> <volume> 32 </volume> <pages> 29-73, </pages> <year> 1985. </year>
Reference-contexts: Since many objects can display similar motion characteristics an object model is necessary to determine the functions of objects from their motion characteristics. Our work is based on segmenting the object into primitive parts and analyzing their motions. 10.5.1 Function from Motion 10.5.1.1 PRIMITIVE SHAPES AND PRIMITIVE MOTIONS Following <ref> [Bie85, RRP93, RDR95] </ref> we regard objects as composed of primitive parts. On the coarsest level we consider four types of primitive parts: sticks, strips, plates, and blobs, which differ in the values of their relative dimensions.
Reference: [BWMK93] <author> Bloedorn, E., Wnek, J., Michalski, R.S., and Kaufman, K., </author> <title> "AQ17 | A multi-strategy learning system: The method and user's guide", Reports of the Machine Learning and Inference Laboratory, </title> <type> MLI 93-12, </type> <institution> George Mason University, Fairfax, VA, </institution> <year> 1993. </year>
Reference-contexts: In this experiment, AQ-NN produced a slightly smaller neural network and the interpretation time was about 50% shorter than with the NN method. We also tested the data-driven constructive induction method (AQ17-DCI) in this experiment; this resulted in some new attributes, but it gave comparable results <ref> [BWMK93] </ref>. 10.4 DETECTION OF BLASTING CAPS IN X-RAY IMAGES OF LUGGAGE This section presents work on an approach to the problem of recognizing blasting caps in x-ray images.
Reference: [BoB94] <editor> Bogoni, L. and Bajcsy, R., </editor> <title> "Active investigation of functionality", </title> <booktitle> in Proc. CVPR Workshop on Visual Behaviors, </booktitle> <month> June </month> <year> 1994. </year>
Reference-contexts: The functionality of an object can be defined as the usability of the object for a particular purpose <ref> [BoB94] </ref>. There has been considerable recent research on the problem of recognizing object functionality; for a short survey see [BoB94]. Early work on functional recognition can be found in [FrN71, SoB83, WBKL83]. <p> The functionality of an object can be defined as the usability of the object for a particular purpose <ref> [BoB94] </ref>. There has been considerable recent research on the problem of recognizing object functionality; for a short survey see [BoB94]. Early work on functional recognition can be found in [FrN71, SoB83, WBKL83]. The goal of this research has been to determine functional capabilities of an object based on characteristics such as shape, physics and causation.
Reference: [BABC84] <author> Brady, M., Agre, P.E., Braunegg, D.J., and Connell, J., </author> <title> II, </title> <booktitle> "The mechanic's mate" in Proc. European Conference on Artificial Intelligence, </booktitle> <pages> 79-94, </pages> <year> 1984. </year>
Reference: [Cha89] <author> Channic, T., "TEXPERT: </author> <title> An application of machine learning to texture recognition", Reports of the Machine Learning and Inference Laboratory, </title> <type> MLI 89-27, </type> <institution> George Mason University, Fairfax, VA, </institution> <year> 1989. </year>
Reference-contexts: Comparisons of classification accuracy were made between decision tree, k-nearest neighbor (k-nn), and minimum distance classifiers. Experimental results for these classifiers were similar, with the minimum distance classifier producing the highest accuracy, 82%. Channic <ref> [Cha89] </ref> extended the MLT methodology [Mic72, Mic73] by using convolution operators in conjunction with the original set of windowing operators for feature extraction. Using the AQ learning system, Channic investigated incremental learning and iterative learning from sequences of images using ultrasound images of laminated objects. <p> They reported that their method achieved 72% on testing data, but no comparisons were made to other learning methods. Pachowicz and Bala [PaB91] also used the MLT methodology, following Michal-ski [Mic72, Mic73] and Channic <ref> [Cha89] </ref>, but added a modified set of Laws' masks for texture feature extraction. They also applied techniques for handling noise in symbolic data. These techniques included optimizing learned symbolic descriptions by truncating rules [MMHL86], as well as removing training examples covered by weak rules and re-learning.
Reference: [ChD94] <author> Cho, K. and Dunn, </author> <title> S.M., "Learning shape classes", </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 16 </volume> <pages> 882-888, </pages> <year> 1994. </year>
Reference-contexts: Shapes were silhouettes of hand gestures. Segen's system runs in real time and has been applied to airplane simulator control as well as to control of a graphics editor program. Error rates were between 5% and 10%, but most errors were unknowns rather than misclassifications. Cho and Dunn <ref> [ChD94] </ref> described a new learning algorithm for learning shape. This algorithm memorizes property lists and updates associated weights as training proceeds. Forgetting mechanisms remove useless property lists. Shapes are modeled by a series of line segments.
Reference: [CrK91] <author> Cromwell, </author> <title> R.L. and Kak, A.C., "Automatic generation of object class descriptions using symbolic learning techniques", </title> <booktitle> in Proc. National Conference on Artificial Intelligence, </booktitle> <pages> 710-717, </pages> <year> 1991. </year>
Reference-contexts: A learning system, which was a modified version of Winston's [Win84] ANALOGY program, learned by generalizing the training examples. The learning system was extended to learn disjunctive concepts and to learn from only positive examples. These generalized representations were used to classify unknown objects. Cromwell and Kak <ref> [CrK91] </ref> proceeded as Shepherd did, using feature vectors to characterize shapes. Electrical component shapes were learned using a symbolic induction methodology based on that developed by Michalski [Mic80]. They reported that their method achieved 72% on testing data, but no comparisons were made to other learning methods.
Reference: [CoB87] <author> Connell, J.H. and Brady, M., </author> <title> "Generating and generalizing models of visual objects", </title> <journal> Artificial Intelligence, </journal> <volume> 34 </volume> <pages> 159-183, </pages> <year> 1987. </year>
Reference-contexts: Using the AQ learning system, Channic investigated incremental learning and iterative learning from sequences of images using ultrasound images of laminated objects. Instead of representing examples using feature vectors, Connell and Brady <ref> [CoB87] </ref> learned generalized semantic networks from images of classes of hammers and of overhead views of commercial aircraft. Training examples were generated by a vision system that took gray scale images as input and produced semantic networks for the objects.
Reference: [Dan88] <author> Dance, </author> <title> D.R, "Diagnostic radiology with x-rays", in The Physics of Medical Imaging, </title> <editor> S. Webb (Ed.), </editor> <address> 20-73, </address> <publisher> IOP Publishing, </publisher> <address> Philadelphia, PA, </address> <year> 1988. </year> <title> Learning Patterns in Images 27 </title>
Reference-contexts: A typical x-ray imaging system consists of an x-ray tube (photon source), an anti-scatter device, and a receptor (photon detector) <ref> [Dan88] </ref>. The photons emitted by the x-ray tube enter the objects, where they may be scattered, absorbed or transmitted without interaction. The primary photons recorded by the image receptor form the image, but the scattered photons create a background signal (i.e., noise) that degrades contrast.
Reference: [DFR96] <author> Duric, Z., Fayman, E., and Rivlin, E., </author> <title> "Function from motion", </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <pages> 579-591, </pages> <year> 1996. </year>
Reference-contexts: In Section 10.4 we address the problem of detecting blasting caps in x-ray images of luggage; the details can be found in [MaM96, MDMR96]. Finally, in Section 10.5 we address the problem of recognizing a function of an object from its motion; the technical details can be found in <ref> [DFR96, DRR96] </ref>. 10.2 PREVIOUS WORK ON MACHINE LEARNING IN COMPUTER VISION Michalski [Mic72, Mic73] examined how symbolic AQ rule learning could be used for discrimination between textures or between simple structures. <p> In this case we choose the axis of minimal moment of inertia to be orthogonal to the plane of the motion. 10.5.2.2 COMPUTING PRIMITIVE MOTIONS We now briefly review our method of computing primitive motions of sticks and strips. A complete description of the method can be found in <ref> [DRR96, DFR96] </ref>. We associate two rectangular coordinate frames with a rigidly moving body B, one (Oxyz) fixed in space (the camera frame), the other (Cx 1 y 1 z 1 ) fixed in the body B and moving with it (the object frame). <p> The weak perspective projection of the scene point (X; Y; Z) onto the image point (x; y) is given by x = Z c Y f: For the instantaneous velocity of the image point (x; y) under weak perspective pro jection we have <ref> [DFR96] </ref> _x = Z c y =N z ]; V f yW + C 1 (x x c )N z + C 1 [(x x c )N 2 where (x c ; y c ) is the image of (X c ; Y c ) and ~ N = (N x <p> Hence _ ~r n ~u n when krIk is large. Expression for the normal flow thus provides an approximate relationship between the 3-D motion and the image derivatives. In <ref> [DFR96, DRR96] </ref> the normal flow (an observable quantity) was used as an approximation of the projected motion field. The method of least squares estimation was used to obtain the estimates of C 1 , U=Z c , V =Z c , and W=Z c . <p> Several image sequences were used to demonstrate our approach. In the three sequences shown in Section 10.5, motion was used to discriminate between three cutting actions: stabbing, chopping, and slicing. In other sequences, not shown here <ref> [DFR96] </ref>, we used motion information to differentiate between two different functionalities of the same object: scooping and hitting with a shovel, and hammering and tightening with a wrench. Natural extensions of this work include the analysis of more complex objects.
Reference: [DRR96] <author> Duric, Z., Rivlin, E., and Rosenfeld, A., </author> <title> "Learning an object's function by observing the object in action", </title> <booktitle> in Proc. ARPA Image Understanding Workshop, </booktitle> <pages> 1437-1445, </pages> <year> 1996. </year>
Reference-contexts: In Section 10.4 we address the problem of detecting blasting caps in x-ray images of luggage; the details can be found in [MaM96, MDMR96]. Finally, in Section 10.5 we address the problem of recognizing a function of an object from its motion; the technical details can be found in <ref> [DFR96, DRR96] </ref>. 10.2 PREVIOUS WORK ON MACHINE LEARNING IN COMPUTER VISION Michalski [Mic72, Mic73] examined how symbolic AQ rule learning could be used for discrimination between textures or between simple structures. <p> In this case we choose the axis of minimal moment of inertia to be orthogonal to the plane of the motion. 10.5.2.2 COMPUTING PRIMITIVE MOTIONS We now briefly review our method of computing primitive motions of sticks and strips. A complete description of the method can be found in <ref> [DRR96, DFR96] </ref>. We associate two rectangular coordinate frames with a rigidly moving body B, one (Oxyz) fixed in space (the camera frame), the other (Cx 1 y 1 z 1 ) fixed in the body B and moving with it (the object frame). <p> Hence _ ~r n ~u n when krIk is large. Expression for the normal flow thus provides an approximate relationship between the 3-D motion and the image derivatives. In <ref> [DFR96, DRR96] </ref> the normal flow (an observable quantity) was used as an approximation of the projected motion field. The method of least squares estimation was used to obtain the estimates of C 1 , U=Z c , V =Z c , and W=Z c .
Reference: [DuB94] <author> Dutta, R. and Bhanu, B., </author> <title> "A learning system for consolidated recognition and motion analysis", </title> <booktitle> in Proc. ARPA Image Understanding Workshop, </booktitle> <pages> 773-776, </pages> <year> 1994. </year>
Reference-contexts: Using the orientations of these segments, local spatial measures are computed and form a property list for a shape. The system was used to 4 Michalski et al. classify tools and hand gestures and achieved predictive accuracies of 92% and 96% on these problems. Dutta and Bhanu <ref> [DuB94] </ref> presented a 3D CAD-based recognition system in which genetic algorithms are used to optimize segmentation parameters. Qualitative experimental results were presented for indoor and outdoor motion sequences in which the system recognized images of wedges (traffic cones) and cans from gray scale and depth map images.
Reference: [Fah88] <author> Fahlman, </author> <title> S.E., "An empirical study of learning speed in back-propagation networks", </title> <type> Report CMU-CS-88-182, </type> <institution> Carnegie-Mellon University, </institution> <address> Pittsburgh, PA, </address> <year> 1988. </year>
Reference: [FeB96] <author> Ferryman, A. and Bhanu, B., </author> <title> "A Bayesian approach for the segmentation of SAR images using dynamically selected neigborhoods", </title> <booktitle> in Proc. ARPA Image Understanding Workshop, </booktitle> <pages> 891-895, </pages> <year> 1996. </year>
Reference-contexts: Much of the current research on learning in vision systems has concentrated on neural network applications | for example, road navigation [Pom91] and object detection and recognition in various types of images (visible, SAR, etc.) <ref> [FeB96, RBP96, RBK96] </ref>. Advantages of these methods include their generality and their ability to 2 Michalski et al. learn continuous transformations.
Reference: [FiS88] <author> Fischler, M.A. and Strat, </author> <title> T.M., "Recognizing trees, bushes, rocks and rivers", </title> <booktitle> in Proc. AAAI Spring Symposium Series: Physical and Biological Approaches to Computational Vision, </booktitle> <pages> 62-64, </pages> <year> 1988. </year>
Reference-contexts: Overall, the experiments indicate that the multistrategy learning program AQ-NN appears to be the most promising approach. This section briefly describes the MIST methodology and illustrates it by an application to natural scene interpretation. As pointed out in <ref> [FiS88, StF91] </ref>, the semantic interpretion of natural scenes and recognition of natural objects is one of the most challenging open vision problems. The MIST methodology offers a new approach to these problems. 10.3.1 The MIST Methodology The MIST methodology works in two basic modes: Learning mode and Interpretation mode.
Reference: [FrN71] <author> Freeman, P. and Newell, A., </author> <title> "A model for functional reasoning in design", </title> <booktitle> in Proc. International Joint Conference on Artificial Intelligence, </booktitle> <pages> 621-640, </pages> <year> 1971. </year>
Reference-contexts: Unfortunately, the fact that the objects are known is often of little or no help. If there is little standardization of the class of known objects, it becomes impractical to attempt to model the objects geometrically. What often constrains a class of objects is functionality <ref> [FrN71, StB91a, RDR95] </ref>. Learning can be useful for acquiring the relationship between image characteristics and object functionality [WCHBS95]. Our primary focus is on investigating how vision and learning can be combined to find blasting caps, as well as objects that could occlude blasting caps, in x-ray images. <p> The functionality of an object can be defined as the usability of the object for a particular purpose [BoB94]. There has been considerable recent research on the problem of recognizing object functionality; for a short survey see [BoB94]. Early work on functional recognition can be found in <ref> [FrN71, SoB83, WBKL83] </ref>. The goal of this research has been to determine functional capabilities of an object based on characteristics such as shape, physics and causation.
Reference: [GESB94] <author> Green, K., Eggert, D., Stark, L., and Bowyer, K., </author> <title> "Generic recognition of articulated objects by reasoning about functionality", </title> <booktitle> in Proc. AAAI Workshop on Repres-ening and Reasoning about Device Function, </booktitle> <pages> 56-64, </pages> <year> 1994. </year>
Reference-contexts: More recently, Stark and Bowyer [StB91a, StB91b, SHGB93] used this approach to solve some of the problems presented by more traditional model-based methods of object recognition. This work has dealt only with stationary objects; no motion is involved. In more recent work Green et al. <ref> [GESB94] </ref> discuss the recognition of articulated objects, using motion to determine whether the object possesses the appropriate functional properties. Little attention has been given to the problem of determining or learning the functionality of an object from its motion. In fact, however, motion provides a strong indication of function.
Reference: [GrP96] <author> Grimson, W.E.L. and Poggio, T., </author> <title> "Progress in image understanding at MIT", </title> <booktitle> in Proc. ARPA Image Understanding Workshop, </booktitle> <pages> 65-74, </pages> <year> 1996. </year>
Reference-contexts: vision, they may be particularly useful for new feature generation, learning visual surface descriptions like textures, learning complex shape descriptions, acquisition of structural or relational models of objects, construction and updating of model databases, scene segmentation, learning the "context" in which an algorithm can be successfully applied, and so forth <ref> [GrP96, MDMR96, MRADMZ96, StF95] </ref>. Applications of symbolic approaches to vision problems remain an insufficiently explored but potentially fruitful domain of research. Multistrategy learning systems combine different representations and/or different learning algorithms. One particular multistrategy system combines neural network and symbolic learning.
Reference: [HoB94] <author> Howard, C.G. and Bock, P., </author> <title> "Using a hierarchical approach to avoid over-fitting in early vision", </title> <booktitle> in Proc. International Conference on Pattern Recognition, </booktitle> <pages> 826-829, </pages> <year> 1994. </year>
Reference-contexts: to annotations (text containing additional information about the classes, such as degree of certainty 6 Michalski et al. of recognition, properties of the class, relations to other classes, etc.). (Although developed independently, MIST's concept of an ASI is similar to the concept of a class map in the ALISA system <ref> [HoB94] </ref>.) The following paragraphs describe the two modes in greater detail. 10.3.1.1 TRAINING MODE This mode (see Figure 10.1) is executed in four phases: LP1|description space generation and background knowledge formulation; LP2|event generation; LP3|learning or refinement; and LP4|image interpretation and evaluation.
Reference: [MDMR96] <author> Maloof, M.A., Duric, Z., Michalski, R.S., and Rosenfeld, A., </author> <title> "Recognizing blasting caps in x-ray images", </title> <booktitle> in Proc. ARPA Image Understandning Workshop, </booktitle> <pages> 1257-1261, </pages> <year> 1996. </year>
Reference-contexts: vision, they may be particularly useful for new feature generation, learning visual surface descriptions like textures, learning complex shape descriptions, acquisition of structural or relational models of objects, construction and updating of model databases, scene segmentation, learning the "context" in which an algorithm can be successfully applied, and so forth <ref> [GrP96, MDMR96, MRADMZ96, StF95] </ref>. Applications of symbolic approaches to vision problems remain an insufficiently explored but potentially fruitful domain of research. Multistrategy learning systems combine different representations and/or different learning algorithms. One particular multistrategy system combines neural network and symbolic learning. <p> For this purpose we use the Multi-level Image Sampling and Transformation (MIST) methodology; a detailed description of this methodology can be found in [MZMB96]. In Section 10.4 we address the problem of detecting blasting caps in x-ray images of luggage; the details can be found in <ref> [MaM96, MDMR96] </ref>. <p> The MLT methodology [Mic72, Mic73] has recently been extended into the MultiLevel Image Sampling and Transformation (MIST) methodology. MIST has been applied to a variety of problems including natural scene segmentation [MZMB96] and identification of blasting caps in x-ray images <ref> [MDMR96] </ref>. For classifying natural scenes, three learning techniques were compared: AQ15c [WKBM95], a backpropagation neural network [Zur92], and AQ-NN [BMP94]. AQ-NN is a multistrategy learning technique in that it uses two different representations and two different learning strategies.
Reference: [MaM94] <author> Maloof, M.A. and Michalski, </author> <title> R.S., "Learning descriptions of 2D blob-like shapes for object recognition in x-ray images: An initial study", Reports of the Machine Learning and Inference Laboratory, </title> <type> MLI 94-4, </type> <institution> George Mason University, Fairfax, VA, </institution> <year> 1994. </year>
Reference-contexts: Learning can be useful for acquiring the relationship between image characteristics and object functionality [WCHBS95]. Our primary focus is on investigating how vision and learning can be combined to find blasting caps, as well as objects that could occlude blasting caps, in x-ray images. In a previous study <ref> [MaM94, MaM96] </ref>, learning was used to acquire descriptions of blasting caps. Simple segmentation techniques were used to isolate objects from their background; they were then represented using intensity and geometric features.
Reference: [MaM96] <author> Maloof, M.A. and Michalski, </author> <title> R.S, "Learning descriptions of shape for object recognition in x-ray images", Expert Systems with Applications, </title> <publisher> in press, </publisher> <year> 1996. </year>
Reference-contexts: For this purpose we use the Multi-level Image Sampling and Transformation (MIST) methodology; a detailed description of this methodology can be found in [MZMB96]. In Section 10.4 we address the problem of detecting blasting caps in x-ray images of luggage; the details can be found in <ref> [MaM96, MDMR96] </ref>. <p> Learning can be useful for acquiring the relationship between image characteristics and object functionality [WCHBS95]. Our primary focus is on investigating how vision and learning can be combined to find blasting caps, as well as objects that could occlude blasting caps, in x-ray images. In a previous study <ref> [MaM94, MaM96] </ref>, learning was used to acquire descriptions of blasting caps. Simple segmentation techniques were used to isolate objects from their background; they were then represented using intensity and geometric features.
Reference: [Mic72] <author> Michalski, </author> <title> R.S., "A variable-valued logic system as applied to picture description and recognition", </title> <editor> in F. Nake and A. Rosenfeld (Eds.), </editor> <booktitle> Graphic Languages, </booktitle> <publisher> North-Holland, Amsterdam, </publisher> <pages> 21-47, </pages> <year> 1972. </year>
Reference-contexts: Finally, in Section 10.5 we address the problem of recognizing a function of an object from its motion; the technical details can be found in [DFR96, DRR96]. 10.2 PREVIOUS WORK ON MACHINE LEARNING IN COMPUTER VISION Michalski <ref> [Mic72, Mic73] </ref> examined how symbolic AQ rule learning could be used for discrimination between textures or between simple structures. These seminal papers presented the Multi-Level Logical Template (MLT) methodology in which windowing operators scanned an image and extracted local features. <p> Comparisons of classification accuracy were made between decision tree, k-nearest neighbor (k-nn), and minimum distance classifiers. Experimental results for these classifiers were similar, with the minimum distance classifier producing the highest accuracy, 82%. Channic [Cha89] extended the MLT methodology <ref> [Mic72, Mic73] </ref> by using convolution operators in conjunction with the original set of windowing operators for feature extraction. Using the AQ learning system, Channic investigated incremental learning and iterative learning from sequences of images using ultrasound images of laminated objects. <p> Electrical component shapes were learned using a symbolic induction methodology based on that developed by Michalski [Mic80]. They reported that their method achieved 72% on testing data, but no comparisons were made to other learning methods. Pachowicz and Bala [PaB91] also used the MLT methodology, following Michal-ski <ref> [Mic72, Mic73] </ref> and Channic [Cha89], but added a modified set of Laws' masks for texture feature extraction. They also applied techniques for handling noise in symbolic data. These techniques included optimizing learned symbolic descriptions by truncating rules [MMHL86], as well as removing training examples covered by weak rules and re-learning. <p> The technique has been integrated into a screen locking application which permits access to workstations by performing face verification in lieu of password authentication. The MLT methodology <ref> [Mic72, Mic73] </ref> has recently been extended into the MultiLevel Image Sampling and Transformation (MIST) methodology. MIST has been applied to a variety of problems including natural scene segmentation [MZMB96] and identification of blasting caps in x-ray images [MDMR96]. <p> We see that as was expected, the values of ff are very close to =2, fi is close to 0, and is close to 0. A V L 1 rule (Michalski <ref> [Mic72] </ref>) describing stabbing would be &lt; stabbing &gt; &lt;:: [ff = 1:55 :: 1:35] & [fi = 1 :: 0:2] & [ = 0:2 :: 0]: 10.5.3.2 CHOPPING Chopping is defined as the cutting motion of a knife in which ff (the angle between the projection of l c onto the
Reference: [Mic73] <author> Michalski, </author> <title> R.S., "AQVAL/1: Computer implementation of a variable-valued logic system VL 1 and examples of its application to pattern recognition", </title> <booktitle> in Proc. International Joint Conference on Pattern Recognition, </booktitle> <pages> 3-17, </pages> <year> 1973. </year>
Reference-contexts: Finally, in Section 10.5 we address the problem of recognizing a function of an object from its motion; the technical details can be found in [DFR96, DRR96]. 10.2 PREVIOUS WORK ON MACHINE LEARNING IN COMPUTER VISION Michalski <ref> [Mic72, Mic73] </ref> examined how symbolic AQ rule learning could be used for discrimination between textures or between simple structures. These seminal papers presented the Multi-Level Logical Template (MLT) methodology in which windowing operators scanned an image and extracted local features. <p> Comparisons of classification accuracy were made between decision tree, k-nearest neighbor (k-nn), and minimum distance classifiers. Experimental results for these classifiers were similar, with the minimum distance classifier producing the highest accuracy, 82%. Channic [Cha89] extended the MLT methodology <ref> [Mic72, Mic73] </ref> by using convolution operators in conjunction with the original set of windowing operators for feature extraction. Using the AQ learning system, Channic investigated incremental learning and iterative learning from sequences of images using ultrasound images of laminated objects. <p> Electrical component shapes were learned using a symbolic induction methodology based on that developed by Michalski [Mic80]. They reported that their method achieved 72% on testing data, but no comparisons were made to other learning methods. Pachowicz and Bala [PaB91] also used the MLT methodology, following Michal-ski <ref> [Mic72, Mic73] </ref> and Channic [Cha89], but added a modified set of Laws' masks for texture feature extraction. They also applied techniques for handling noise in symbolic data. These techniques included optimizing learned symbolic descriptions by truncating rules [MMHL86], as well as removing training examples covered by weak rules and re-learning. <p> The technique has been integrated into a screen locking application which permits access to workstations by performing face verification in lieu of password authentication. The MLT methodology <ref> [Mic72, Mic73] </ref> has recently been extended into the MultiLevel Image Sampling and Transformation (MIST) methodology. MIST has been applied to a variety of problems including natural scene segmentation [MZMB96] and identification of blasting caps in x-ray images [MDMR96]. <p> The core part of the descriptions was in the form of decision rules, which were determined by the inductive learning program AQ15 [MMHL86] and represented in the VL 1 logic-style language (Variable-Valued Logic System 1) <ref> [Mic73] </ref>. Such decision rules can be applied to an image in parallel or sequentially. A simple version of the MIST methodology was applied to problems of semantically interpreting outdoor scenes using several learning methods.
Reference: [Mic80] <author> Michalski, </author> <title> R.S., "Pattern recognition as rule-guided inductive inference", </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 2 </volume> <pages> 349-361, </pages> <year> 1980. </year>
Reference-contexts: These generalized representations were used to classify unknown objects. Cromwell and Kak [CrK91] proceeded as Shepherd did, using feature vectors to characterize shapes. Electrical component shapes were learned using a symbolic induction methodology based on that developed by Michalski <ref> [Mic80] </ref>. They reported that their method achieved 72% on testing data, but no comparisons were made to other learning methods. Pachowicz and Bala [PaB91] also used the MLT methodology, following Michal-ski [Mic72, Mic73] and Channic [Cha89], but added a modified set of Laws' masks for texture feature extraction.
Reference: [MBP93] <author> Michalski, R.S., Bala, J.W, and Pachowicz, P.W., </author> <title> "Progress on vision through learning at George Mason University", </title> <booktitle> in Proc. ARPA Image Understanding Workshop, </booktitle> <pages> 191-207, </pages> <year> 1993. </year>
Reference-contexts: Experimental Results The current MIST methodology has been implemented with the following learning systems: * Symbolic rule learning program AQ15c [MMHL86, WKBM95]. * Multistrategy learning system AQ-NN combining decision rule learning with neural network learning [BMP94]. * Multistrategy learning system AQ-GA that combines decision rule learning with a genetic algorithm <ref> [MBP93] </ref>. * Class similarity-based learning for building descriptions of large numbers of classes (PRAX) [BMW92, BMW93]. An earlier version of MIST has been applied to learning descriptions of classes of surfaces [MBP93]. <p> with neural network learning [BMP94]. * Multistrategy learning system AQ-GA that combines decision rule learning with a genetic algorithm <ref> [MBP93] </ref>. * Class similarity-based learning for building descriptions of large numbers of classes (PRAX) [BMW92, BMW93]. An earlier version of MIST has been applied to learning descriptions of classes of surfaces [MBP93]. The core part of the descriptions was in the form of decision rules, which were determined by the inductive learning program AQ15 [MMHL86] and represented in the VL 1 logic-style language (Variable-Valued Logic System 1) [Mic73]. Such decision rules can be applied to an image in parallel or sequentially.
Reference: [MMHL86] <author> Michalski, R.S., Mozetic, I., Hong, J., and Lavrac, N., </author> <title> "The multipurpose incremental learning system AQ15 and its testing application to three medical domains", </title> <booktitle> in Proc. National Conference on Artificial Intelligence, </booktitle> <pages> 1041-1045, </pages> <year> 1986. </year>
Reference-contexts: Pachowicz and Bala [PaB91] also used the MLT methodology, following Michal-ski [Mic72, Mic73] and Channic [Cha89], but added a modified set of Laws' masks for texture feature extraction. They also applied techniques for handling noise in symbolic data. These techniques included optimizing learned symbolic descriptions by truncating rules <ref> [MMHL86] </ref>, as well as removing training examples covered by weak rules and re-learning. The PRAX method for learning a large number of classes was introduced by Bala, Michalski, and Wnek [BMW92, BMW93]. <p> The simplest form of annotation used in the ASI is to associate degrees of confidence with the ASI pixels denoting a given class. 8 Michalski et al. 10.3.2 Implementation and Experimental Results The current MIST methodology has been implemented with the following learning systems: * Symbolic rule learning program AQ15c <ref> [MMHL86, WKBM95] </ref>. * Multistrategy learning system AQ-NN combining decision rule learning with neural network learning [BMP94]. * Multistrategy learning system AQ-GA that combines decision rule learning with a genetic algorithm [MBP93]. * Class similarity-based learning for building descriptions of large numbers of classes (PRAX) [BMW92, BMW93]. <p> An earlier version of MIST has been applied to learning descriptions of classes of surfaces [MBP93]. The core part of the descriptions was in the form of decision rules, which were determined by the inductive learning program AQ15 <ref> [MMHL86] </ref> and represented in the VL 1 logic-style language (Variable-Valued Logic System 1) [Mic73]. Such decision rules can be applied to an image in parallel or sequentially. A simple version of the MIST methodology was applied to problems of semantically interpreting outdoor scenes using several learning methods.
Reference: [MRA94] <editor> Michalski, R.S., Rosenfeld, A., and Aloimonos, Y., </editor> <booktitle> "Machine vision and learning: Research issues and directions | A report on the NSF/ARPA Workshop on Learning and Vision, </booktitle> <address> Harpers Ferry, WV, </address> <month> October 15-17, </month> <year> 1992", </year> <title> Reports of the Machine Learning and Inference Laboratory, </title> <type> MLI 94-6, </type> <institution> George Mason University, Fairfax, VA, </institution> <year> 1994. </year>
Reference-contexts: Learning capabilities can also make vision systems more easily adaptable to different vision problems, and more flexible and robust in handling variable perceptual conditions <ref> [MRA94] </ref>. Much of the current research on learning in vision systems has concentrated on neural network applications | for example, road navigation [Pom91] and object detection and recognition in various types of images (visible, SAR, etc.) [FeB96, RBP96, RBK96]. <p> Advantages of these methods include their generality and their ability to 2 Michalski et al. learn continuous transformations. Disadvantages include the difficulty of incorporating prior knowledge (especially relational knowledge), the difficulty of learning complex structural knowledge, slow learning rates, and lack of comprehensibility of the learned knowledge <ref> [MRA94] </ref>. While symbolic learning methods suffer much less from these problems, they have been applied mostly in areas other than computer vision. <p> Experimental results demonstrate the ability of the inductive learning system to acquire the relationship between image characteristics and object functionality. This research provides an opportunity to study the interplay between vision and learning processes <ref> [MRA94] </ref>, especially as it relates to learning object functionality.
Reference: [MRADMZ96] <author> Michalski, R.S., Rosenfeld, A., Aloimonos, Y., Duric, Z., Maloof, M.A., and Zhang, Q., </author> <title> "Progress on vision through learning: A collaborative effort of George Mason University and the University of Maryland", </title> <booktitle> in Proc. ARPA Image Understandning Workshop, </booktitle> <pages> 177-187, </pages> <year> 1996. </year>
Reference-contexts: vision, they may be particularly useful for new feature generation, learning visual surface descriptions like textures, learning complex shape descriptions, acquisition of structural or relational models of objects, construction and updating of model databases, scene segmentation, learning the "context" in which an algorithm can be successfully applied, and so forth <ref> [GrP96, MDMR96, MRADMZ96, StF95] </ref>. Applications of symbolic approaches to vision problems remain an insufficiently explored but potentially fruitful domain of research. Multistrategy learning systems combine different representations and/or different learning algorithms. One particular multistrategy system combines neural network and symbolic learning. <p> The following sections summarize specific results obtained on a project on "Computer vision through learning" being conducted jointly by George Mason University and the University of Maryland <ref> [MRADMZ96] </ref>. In Section 10.2 we review previous work on machine learning in computer vision. In Section 10.3 we address the problem of conceptually segmenting color images of outdoor scenes.
Reference: [MZMB96] <author> Michalski, R.S., Zhang, Q., Maloof, M.A., and Bloedorn, E., </author> <title> "The multi-level 28 Michalski et al. image sampling and transformation methodology and its application to natural scene interpretation", </title> <booktitle> in Proc. ARPA Image Understandning Workshop, </booktitle> <pages> 1473-1479, </pages> <year> 1996. </year>
Reference-contexts: One particular multistrategy system combines neural network and symbolic learning. This method induces rules which are used to structure a neural network architecture. A secondary learning step refines the network's weights. This method provides generality and very fast recognition rates <ref> [BMP94, MZMB96] </ref>. One can also use neural networks for lower-level vision processes and symbolic methods for higher-level visual processes. These methods are potentially very powerful and promising directions of research. <p> In Section 10.3 we address the problem of conceptually segmenting color images of outdoor scenes. For this purpose we use the Multi-level Image Sampling and Transformation (MIST) methodology; a detailed description of this methodology can be found in <ref> [MZMB96] </ref>. In Section 10.4 we address the problem of detecting blasting caps in x-ray images of luggage; the details can be found in [MaM96, MDMR96]. <p> The MLT methodology [Mic72, Mic73] has recently been extended into the MultiLevel Image Sampling and Transformation (MIST) methodology. MIST has been applied to a variety of problems including natural scene segmentation <ref> [MZMB96] </ref> and identification of blasting caps in x-ray images [MDMR96]. For classifying natural scenes, three learning techniques were compared: AQ15c [WKBM95], a backpropagation neural network [Zur92], and AQ-NN [BMP94]. AQ-NN is a multistrategy learning technique in that it uses two different representations and two different learning strategies.
Reference: [PaB91] <author> Pachowicz, P.W. and Bala, J.W., </author> <title> "Texture recognition through machine learning and concept optimization", Reports of the Machine Learning and Inference Laboratory, </title> <type> MLI 95-4, </type> <institution> George Mason University, Fairfax, VA, </institution> <year> 1991. </year>
Reference-contexts: Electrical component shapes were learned using a symbolic induction methodology based on that developed by Michalski [Mic80]. They reported that their method achieved 72% on testing data, but no comparisons were made to other learning methods. Pachowicz and Bala <ref> [PaB91] </ref> also used the MLT methodology, following Michal-ski [Mic72, Mic73] and Channic [Cha89], but added a modified set of Laws' masks for texture feature extraction. They also applied techniques for handling noise in symbolic data.
Reference: [Pom91] <author> Pomerleau, D.A., </author> <title> "Efficient training of artificial neural networks for autonomous navigation", </title> <journal> Neural Computation, </journal> <volume> 3 </volume> <pages> 88-97, </pages> <year> 1991. </year>
Reference-contexts: Learning capabilities can also make vision systems more easily adaptable to different vision problems, and more flexible and robust in handling variable perceptual conditions [MRA94]. Much of the current research on learning in vision systems has concentrated on neural network applications | for example, road navigation <ref> [Pom91] </ref> and object detection and recognition in various types of images (visible, SAR, etc.) [FeB96, RBP96, RBK96]. Advantages of these methods include their generality and their ability to 2 Michalski et al. learn continuous transformations.
Reference: [RDR95] <author> Rivlin, E., Dickinson, S.J., and Rosenfeld, A., </author> <title> "Recognition by functional parts", </title> <booktitle> Computer Vision and Image Understanding, </booktitle> <volume> 62 </volume> <pages> 164-176, </pages> <year> 1995. </year>
Reference-contexts: Unfortunately, the fact that the objects are known is often of little or no help. If there is little standardization of the class of known objects, it becomes impractical to attempt to model the objects geometrically. What often constrains a class of objects is functionality <ref> [FrN71, StB91a, RDR95] </ref>. Learning can be useful for acquiring the relationship between image characteristics and object functionality [WCHBS95]. Our primary focus is on investigating how vision and learning can be combined to find blasting caps, as well as objects that could occlude blasting caps, in x-ray images. <p> Since many objects can display similar motion characteristics an object model is necessary to determine the functions of objects from their motion characteristics. Our work is based on segmenting the object into primitive parts and analyzing their motions. 10.5.1 Function from Motion 10.5.1.1 PRIMITIVE SHAPES AND PRIMITIVE MOTIONS Following <ref> [Bie85, RRP93, RDR95] </ref> we regard objects as composed of primitive parts. On the coarsest level we consider four types of primitive parts: sticks, strips, plates, and blobs, which differ in the values of their relative dimensions. <p> On the coarsest level we consider four types of primitive parts: sticks, strips, plates, and blobs, which differ in the values of their relative dimensions. As in <ref> [RDR95] </ref> we let a 1 , a 2 , and a 3 represent the length, width, and height of a volumetric part. <p> When no two dimensions are about the same we have a strip. For example, a knife blade is a strip, because no two of its dimensions are similar. Primitives can be combined to create compound objects. In <ref> [RDR95] </ref> the different qualitative ways in which primitives can be combined were described|for example, end to end, end to side, end to edge, etc. <p> The object is given as a collection of primitives. For example, a knife can be described as consisting of two primitives: a handle (a stick) and a blade (a strip). Given this model, the system estimates the pose of the object (as in <ref> [RDR95] </ref>) and passes this information to the motion estimation module. The model and the results of the motion estimation enable the system to infer the function that is being performed by the object.
Reference: [RRP93] <author> Rivlin, E., Rosenfeld, A., and Perlis, D., </author> <title> "Recognition of object functionality in goal-directed robotics", </title> <booktitle> in Proc. AAAI Workshop on Reasoning about Function, </booktitle> <pages> 126-130, </pages> <year> 1993. </year>
Reference-contexts: Since many objects can display similar motion characteristics an object model is necessary to determine the functions of objects from their motion characteristics. Our work is based on segmenting the object into primitive parts and analyzing their motions. 10.5.1 Function from Motion 10.5.1.1 PRIMITIVE SHAPES AND PRIMITIVE MOTIONS Following <ref> [Bie85, RRP93, RDR95] </ref> we regard objects as composed of primitive parts. On the coarsest level we consider four types of primitive parts: sticks, strips, plates, and blobs, which differ in the values of their relative dimensions.
Reference: [RBP96] <author> Romano, R., Beymer, D., and Poggio, T., </author> <title> "Face verification for real-time applications", </title> <booktitle> in Proc. ARPA Image Understanding Workshop, </booktitle> <pages> 747-756, </pages> <year> 1996. </year>
Reference-contexts: Much of the current research on learning in vision systems has concentrated on neural network applications | for example, road navigation [Pom91] and object detection and recognition in various types of images (visible, SAR, etc.) <ref> [FeB96, RBP96, RBK96] </ref>. Advantages of these methods include their generality and their ability to 2 Michalski et al. learn continuous transformations. <p> A bootstrap algorithm was implemented during training so as to add false detection into the training set and as a consequence, eliminate the difficult task of manually selecting non-face training examples. Experimental results showed better performance in terms of detection and false-positive rates. Romano et al. <ref> [RBP96] </ref> built a real-time system for face verification. Experiments showed that simple correlation strategies on template-based models are sufficient for many applications in which the identity of a face in a novel image must be verified quickly and reliably from a single reference image.
Reference: [RBK96] <author> Rowley, H.A., Baluja, S., and Kanade, T., </author> <title> "Neural network-based face detection", </title> <booktitle> in Proc. ARPA Image Understanding Workshop, </booktitle> <pages> 725-735, </pages> <year> 1996. </year>
Reference-contexts: Much of the current research on learning in vision systems has concentrated on neural network applications | for example, road navigation [Pom91] and object detection and recognition in various types of images (visible, SAR, etc.) <ref> [FeB96, RBP96, RBK96] </ref>. Advantages of these methods include their generality and their ability to 2 Michalski et al. learn continuous transformations. <p> Qualitative results were presented in which the adaptive thresholding algorithm was shown to be superior to the classical thresholding algorithm for both SAR and FLIR images. Rowley et al. <ref> [RBK96] </ref> built a neural network-based face detection system by using a retinally connected neural network to examine small windows of an image and decide on the existence of a face.
Reference: [Seg94] <author> Segen, J., "GEST: </author> <title> A learning computer vision system that recognizes hand gestures", in R.S. </title> <editor> Michalski and G. Tecuci, (Eds.), </editor> <title> Machine Learning: A Multistrategy Approach, </title> <booktitle> Vol. IV, </booktitle> <pages> 621-634, </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Francisco, CA, </address> <year> 1994. </year>
Reference-contexts: These techniques included optimizing learned symbolic descriptions by truncating rules [MMHL86], as well as removing training examples covered by weak rules and re-learning. The PRAX method for learning a large number of classes was introduced by Bala, Michalski, and Wnek [BMW92, BMW93]. Segen <ref> [Seg94] </ref> used a hybrid shape representation consisting of a hierarchical graph that takes into account local features of high curvature, and the angles and distances between these local features. This representation is invariant to both planar rotation and translation. Shapes were silhouettes of hand gestures.
Reference: [She83] <author> Shepherd, </author> <title> B.A., "An appraisal of a decision tree approach to image classification", </title> <booktitle> in Proc. International Joint Conference on Artificial Intelligence, </booktitle> <pages> 473-475, </pages> <year> 1983. </year>
Reference-contexts: These features were used Learning Patterns in Images 3 to learn rules describing textures (or simple structures); the rules were then used for texture (or simple structure) recognition. Shepherd <ref> [She83] </ref>, encoding examples as feature vectors, learned decision trees for an industrial inspection task | specifically, classification of the shapes of chocolates. Comparisons of classification accuracy were made between decision tree, k-nearest neighbor (k-nn), and minimum distance classifiers.
Reference: [SoB83] <editor> Solina, S. and Bajcsy, R., </editor> <title> "Shape and function", </title> <booktitle> in Proc. SPIE Conference on Intelligent Robots and Computer Vision, </booktitle> <volume> Vol. 726, </volume> <pages> 284-291, </pages> <year> 1983. </year>
Reference-contexts: The functionality of an object can be defined as the usability of the object for a particular purpose [BoB94]. There has been considerable recent research on the problem of recognizing object functionality; for a short survey see [BoB94]. Early work on functional recognition can be found in <ref> [FrN71, SoB83, WBKL83] </ref>. The goal of this research has been to determine functional capabilities of an object based on characteristics such as shape, physics and causation.
Reference: [StB91a] <author> Stark, L. and Bowyer, K., </author> <title> "Achieving generalized object recognition through reasoning about association of function to structure", </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 13 </volume> <pages> 1097-1104, </pages> <year> 1991. </year>
Reference-contexts: Unfortunately, the fact that the objects are known is often of little or no help. If there is little standardization of the class of known objects, it becomes impractical to attempt to model the objects geometrically. What often constrains a class of objects is functionality <ref> [FrN71, StB91a, RDR95] </ref>. Learning can be useful for acquiring the relationship between image characteristics and object functionality [WCHBS95]. Our primary focus is on investigating how vision and learning can be combined to find blasting caps, as well as objects that could occlude blasting caps, in x-ray images. <p> Early work on functional recognition can be found in [FrN71, SoB83, WBKL83]. The goal of this research has been to determine functional capabilities of an object based on characteristics such as shape, physics and causation. More recently, Stark and Bowyer <ref> [StB91a, StB91b, SHGB93] </ref> used this approach to solve some of the problems presented by more traditional model-based methods of object recognition. This work has dealt only with stationary objects; no motion is involved.
Reference: [StB91b] <author> Stark, L. and Bowyer, K., </author> <title> "Generic recognition through qualitative reasoning about 3-D shape and object function", </title> <booktitle> in Proc. IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> 251-256, </pages> <year> 1991. </year>
Reference-contexts: Early work on functional recognition can be found in [FrN71, SoB83, WBKL83]. The goal of this research has been to determine functional capabilities of an object based on characteristics such as shape, physics and causation. More recently, Stark and Bowyer <ref> [StB91a, StB91b, SHGB93] </ref> used this approach to solve some of the problems presented by more traditional model-based methods of object recognition. This work has dealt only with stationary objects; no motion is involved.
Reference: [StB92] <author> Stark, L. and Bowyer, K., </author> <title> "Indexing function-based categories for generic recognition", </title> <booktitle> in Proc. IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> 795-797, </pages> <year> 1992. </year>
Reference: [SHGB93] <author> Stark, L., Hoover, A., Goldgof, D., and Bowyer, K., </author> <title> "Function-based recognition from incomplete knowledge of shape", </title> <booktitle> in Proc. IEEE Workshop on Qualitative Vision, </booktitle> <pages> 11-22, </pages> <year> 1993. </year>
Reference-contexts: Early work on functional recognition can be found in [FrN71, SoB83, WBKL83]. The goal of this research has been to determine functional capabilities of an object based on characteristics such as shape, physics and causation. More recently, Stark and Bowyer <ref> [StB91a, StB91b, SHGB93] </ref> used this approach to solve some of the problems presented by more traditional model-based methods of object recognition. This work has dealt only with stationary objects; no motion is involved.
Reference: [StF91] <author> Strat, T. and Fischler, M., </author> <title> "Natural object recognition: A theoretical framework and its implementation", </title> <booktitle> in Proc. International Joint Conference on Artificial Intelligence, </booktitle> <year> 1991. </year>
Reference-contexts: Overall, the experiments indicate that the multistrategy learning program AQ-NN appears to be the most promising approach. This section briefly describes the MIST methodology and illustrates it by an application to natural scene interpretation. As pointed out in <ref> [FiS88, StF91] </ref>, the semantic interpretion of natural scenes and recognition of natural objects is one of the most challenging open vision problems. The MIST methodology offers a new approach to these problems. 10.3.1 The MIST Methodology The MIST methodology works in two basic modes: Learning mode and Interpretation mode.
Reference: [StF95] <author> Strat, T. and Fischler, M., </author> <title> "The role of context in computer vision", </title> <booktitle> in Proc. ICCV Workshop on Context-Based Vision, </booktitle> <year> 1995. </year>
Reference-contexts: vision, they may be particularly useful for new feature generation, learning visual surface descriptions like textures, learning complex shape descriptions, acquisition of structural or relational models of objects, construction and updating of model databases, scene segmentation, learning the "context" in which an algorithm can be successfully applied, and so forth <ref> [GrP96, MDMR96, MRADMZ96, StF95] </ref>. Applications of symbolic approaches to vision problems remain an insufficiently explored but potentially fruitful domain of research. Multistrategy learning systems combine different representations and/or different learning algorithms. One particular multistrategy system combines neural network and symbolic learning.
Reference: [SuP94] <author> Sung, K. and Poggio, T., </author> <title> "Example-based learning for view-based human face detection", </title> <booktitle> in Proc. ARPA Image Understanding Workshop, </booktitle> <pages> 747-756, </pages> <year> 1994. </year>
Reference-contexts: Qualitative experimental results were presented for indoor and outdoor motion sequences in which the system recognized images of wedges (traffic cones) and cans from gray scale and depth map images. Sung and Poggio <ref> [SuP94] </ref> worked on automatic human face detection. An example-based learning approach was tested for locating unoccluded frontal views of human faces in complex scenes. The space of human faces was represented by a few "face" and "non-face" pattern prototypes.
Reference: [WeK92] <author> Weiss, </author> <title> S.M., and Kulikowski, C.A., Computer Systems that Learn: Classification and Prediction Methods from Statistics, Neural Nets, Machine Learning and Expert Systems, </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1992. </year>
Reference-contexts: The validation methodology used here was a hold-out method in which a random selection of 60% of the samples from the training area were used for training, while the remaining 40% were used for testing <ref> [WeK92] </ref>. Table 10.1 gives results from an experiment involving only one level of image transformation using different learning programs. In this experiment, the training area for each class was only 10 fi 10 pixels.
Reference: [Win84] <author> Winston, P.H., </author> <booktitle> Artificial Intelligence, 2nd ed., </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1984. </year>
Reference-contexts: Training examples were generated by a vision system that took gray scale images as input and produced semantic networks for the objects. A learning system, which was a modified version of Winston's <ref> [Win84] </ref> ANALOGY program, learned by generalizing the training examples. The learning system was extended to learn disjunctive concepts and to learn from only positive examples. These generalized representations were used to classify unknown objects. Cromwell and Kak [CrK91] proceeded as Shepherd did, using feature vectors to characterize shapes.
Reference: [WBKL83] <author> Winston, P.H., Binford, T.O., Katz, B., and Lowry, M., </author> <title> "Learning physical descriptions from functional descriptions, examples, and precedents", </title> <booktitle> in Proc. National Conference on Artificial Intelligence, </booktitle> <pages> 433-439, </pages> <year> 1983. </year>
Reference-contexts: The functionality of an object can be defined as the usability of the object for a particular purpose [BoB94]. There has been considerable recent research on the problem of recognizing object functionality; for a short survey see [BoB94]. Early work on functional recognition can be found in <ref> [FrN71, SoB83, WBKL83] </ref>. The goal of this research has been to determine functional capabilities of an object based on characteristics such as shape, physics and causation.
Reference: [WKBM95] <author> Wnek, J., Kaufman, K., Bloedorn, E., and Michalski, </author> <title> R.S., "Inductive learning system AQ15c: The method and user's guide", Reports of the Machine Learning and Inference Laboratory, </title> <type> MLI 95-4, </type> <institution> George Mason University, Fairfax, VA, </institution> <year> 1995. </year>
Reference-contexts: MIST has been applied to a variety of problems including natural scene segmentation [MZMB96] and identification of blasting caps in x-ray images [MDMR96]. For classifying natural scenes, three learning techniques were compared: AQ15c <ref> [WKBM95] </ref>, a backpropagation neural network [Zur92], and AQ-NN [BMP94]. AQ-NN is a multistrategy learning technique in that it uses two different representations and two different learning strategies. Specifically, the AQ learning algorithm is used to learn attributional decision rules from training examples. <p> The simplest form of annotation used in the ASI is to associate degrees of confidence with the ASI pixels denoting a given class. 8 Michalski et al. 10.3.2 Implementation and Experimental Results The current MIST methodology has been implemented with the following learning systems: * Symbolic rule learning program AQ15c <ref> [MMHL86, WKBM95] </ref>. * Multistrategy learning system AQ-NN combining decision rule learning with neural network learning [BMP94]. * Multistrategy learning system AQ-GA that combines decision rule learning with a genetic algorithm [MBP93]. * Class similarity-based learning for building descriptions of large numbers of classes (PRAX) [BMW92, BMW93]. <p> From each of the 64 selected regions, 27 geometric (e.g., compactness and proximity measures) and intensity-based (e.g., minimum, maximum, and average) features were computed, resulting in 28 blasting cap and 38 non-blasting cap objects. The AQ15c <ref> [WKBM95] </ref> inductive learning system was used to learn descriptions of blasting caps and non-blasting caps. Induced descriptions from AQ15c were validated using 100 iterations of two-fold cross-validation. This validation method involves 100 learning and recognition runs.
Reference: [WCHBS95] <author> Woods, K., Cook, D., Hall, L., Bowyer, K., and Stark, </author> <title> L, "Learning membership functions in a function-based object recognition system", </title> <journal> Journal of Artificial Learning Patterns in Images 29 Intelligence Research, </journal> <volume> 3 </volume> <pages> 187-222, </pages> <year> 1995. </year>
Reference-contexts: If there is little standardization of the class of known objects, it becomes impractical to attempt to model the objects geometrically. What often constrains a class of objects is functionality [FrN71, StB91a, RDR95]. Learning can be useful for acquiring the relationship between image characteristics and object functionality <ref> [WCHBS95] </ref>. Our primary focus is on investigating how vision and learning can be combined to find blasting caps, as well as objects that could occlude blasting caps, in x-ray images. In a previous study [MaM94, MaM96], learning was used to acquire descriptions of blasting caps.
Reference: [ZhB96] <author> Zheng, Y. and Bhanu, B., </author> <title> "Performance improvement by input adaptation using modified Hebbian learning", </title> <booktitle> in Proc. ARPA Image Understanding Workshop, </booktitle> <pages> 1381-1387, </pages> <year> 1996. </year>
Reference-contexts: At each image location, a two-valued distance measure was computed between the local image pattern and each prototype. A trained classifier was used to determine whether a human face is present. The authors showed that their distance metric is critical for the success of their system. Zheng and Bhanu <ref> [ZhB96] </ref> examined how Hebbian learning mechanisms could be used to improve the performance of an image thresholding algorithm for automatic target detection and recognition. Qualitative results were presented in which the adaptive thresholding algorithm was shown to be superior to the classical thresholding algorithm for both SAR and FLIR images.
Reference: [Zur92] <author> Zurada, J.M., </author> <title> Introduction to Artificial Neural Systems, </title> <publisher> West Publishing, </publisher> <address> St. Paul, MN, </address> <year> 1992. </year>
Reference-contexts: MIST has been applied to a variety of problems including natural scene segmentation [MZMB96] and identification of blasting caps in x-ray images [MDMR96]. For classifying natural scenes, three learning techniques were compared: AQ15c [WKBM95], a backpropagation neural network <ref> [Zur92] </ref>, and AQ-NN [BMP94]. AQ-NN is a multistrategy learning technique in that it uses two different representations and two different learning strategies. Specifically, the AQ learning algorithm is used to learn attributional decision rules from training examples. These decision rules are then used to structure a neural network architecture.
References-found: 56

