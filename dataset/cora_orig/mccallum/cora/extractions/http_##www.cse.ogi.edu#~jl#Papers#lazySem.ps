URL: http://www.cse.ogi.edu/~jl/Papers/lazySem.ps
Refering-URL: http://www.cse.ogi.edu/~jl/biblio-functional.html
Root-URL: http://www.cse.ogi.edu
Email: jl@dcs.glasgow.ac.uk  
Title: A Natural Semantics for Lazy Evaluation  
Author: John Launchbury 
Address: Glasgow University  
Affiliation: Computing Science Department  
Abstract: We define an operational semantics for lazy evaluation which provides an accurate model for sharing. The only computational structure we introduce is a set of bindings which corresponds closely to a heap. The semantics is set at a considerably higher level of abstraction than operational semantics for particular abstract machines, so is more suitable for a variety of proofs. Furthermore, because a heap is explicitly modelled, the semantics provides a suitable framework for studies about space be-haviour of terms under lazy evaluation. 
Abstract-found: 1
Intro-found: 1
Reference: [Abr90] <author> S.Abramsky, </author> <title> The Lazy Lambda Calculus, </title> <editor> in D.Turner ed., </editor> <booktitle> Declarative Programming, </booktitle> <publisher> Addison-Wesley, </publisher> <year> 1990. </year>
Reference-contexts: The paper concludes with ap-plications and extensions. 2 Related Work There have already been a number of attempts to provide semantics for laziness. Perhaps the best known is due to Abramsky and Ong <ref> [Abr90, Ong88] </ref> where they explore the theoretical consequences of treating -terms in weak head normal form as values. <p> For the rest of the paper a statement like : e + : z carries the assumption that : e is distinctly named. 5.2 Relating to Denotational Semantics 5.2.1 Semantics of Terms Following Abramsky and Ong <ref> [Abr90] </ref>, the denotational semantics models functions by a lifted function space, so it distinguishes between a term (a non-terminating computation) and x : . This distinction in the model reflects the fact that reduction ceases at whnf rather than head normal form (hnf).
Reference: [AA91] <author> Z.Ariola and Arvind, </author> <title> A Syntactic Approach to Program Transformations, </title> <booktitle> in Proc. SIGPLAN PEPM 91, </booktitle> <address> New Haven, </address> <pages> pp 116-129, </pages> <year> 1991. </year>
Reference-contexts: By defining a particular reduction order and extending their rules to discard unneeded redexes, laziness can be modelled. A further point of contact is that, when providing a semantics for the kernel of Id, Ariola and Arvind use a similar technique to ours for making closures explicit <ref> [AA91] </ref>. 3 Modelling Laziness The semantics we present is an intermediate-level operational semantics, lying midway between a straightforward denotational semantics (or, equivalently, the operational semantics of Abramsky and Ong) and a full operational semantics of an abstract machine.
Reference: [ANP89] <author> Arvind, R.Nikhil and K.Pingali, I-Structures: </author> <title> Data Structures for Parallel Computing, </title> <note> in TOPLAS (11) 4 pp 598-632, </note> <month> Oct </month> <year> 1989. </year>
Reference-contexts: The resulting semantics for laziness is significantly more complex than that presented here (having been developed with different goals in mind), and also omits recursive lets which are a vital part of modern lazy functional languages. The semantics for Id also deserve a mention at this point <ref> [ANP89] </ref>. While not lazy, Id has a non-strict semantics with sharing defined by a small-step semantics of a core of the Id language. Many rules may apply at any one time, but as the system is confluent the result is deterministic.
Reference: [FW87] <author> J.Fairbairn and S.Wray, </author> <title> A Simple Lazy Abstract-Machine to Execute Supercombina-tors , in Proc. </title> <booktitle> FPCA, Portland, </booktitle> <pages> pp 34-45, </pages> <address> S-V, </address> <year> 1987. </year>
Reference-contexts: Abramsky and Ong's semantics are defined at a high level of abstraction. At the other end of the scale is the operational semantics given to define the behaviour of abstract machines. Examples of this are the G-machine [Jon84], the STG-machine [Pey92], the TIM <ref> [FW87] </ref> and TIGRE [KL89]. At the level of these machines we have to deal with code pointers, stacks, indirection nodes, and the like. These operational semantics capture laziness completely, but contain so much extra detail as to make reasoning or proofs nigh on impossible.
Reference: [Jon84] <author> T.Johnsson, </author> <title> Efficient Compilation of Lazy Evaluation, </title> <booktitle> in Proc. SIGPLAN Symp. on Compiler Construction, </booktitle> <pages> SIGPLAN Notices 19 pp 58-59, </pages> <year> 1984. </year>
Reference-contexts: Thus they omits precisely the aspect of laziness we wish to study. Abramsky and Ong's semantics are defined at a high level of abstraction. At the other end of the scale is the operational semantics given to define the behaviour of abstract machines. Examples of this are the G-machine <ref> [Jon84] </ref>, the STG-machine [Pey92], the TIM [FW87] and TIGRE [KL89]. At the level of these machines we have to deal with code pointers, stacks, indirection nodes, and the like. These operational semantics capture laziness completely, but contain so much extra detail as to make reasoning or proofs nigh on impossible.
Reference: [Jos89] <author> M.Josephs, </author> <title> The Semantics of Lazy Functional Languages, </title> <booktitle> in TCS 68, </booktitle> <pages> pp 105-111, </pages> <year> 1989. </year>
Reference-contexts: To be able to study sharing, therefore, we need a semantics containing more detail than Abramsky and Ong's, but less than provided by particular abstract machines. The earliest intermediate level semantics seems to have been Josephs' <ref> [Jos89] </ref>. This denotational semantics is continuation-based, and manipulates both an environment and a store. Sharing is successfully mod-elled, including the sharing that occurs in implementing fixed points.
Reference: [KL89] <author> P.Koopman and P.Lee, </author> <title> A Fresh Look at Com-binator Graph Reduction, </title> <booktitle> in SIGPLAN PLDI 89, Portland, </booktitle> <pages> pp 110-119, </pages> <year> 1989. </year>
Reference-contexts: Abramsky and Ong's semantics are defined at a high level of abstraction. At the other end of the scale is the operational semantics given to define the behaviour of abstract machines. Examples of this are the G-machine [Jon84], the STG-machine [Pey92], the TIM [FW87] and TIGRE <ref> [KL89] </ref>. At the level of these machines we have to deal with code pointers, stacks, indirection nodes, and the like. These operational semantics capture laziness completely, but contain so much extra detail as to make reasoning or proofs nigh on impossible.
Reference: [Lau92] <author> J.Launchbury, A.Gill, J.Hughes, S.Marlow, S.Peyton Jones and P.Wadler, </author> <title> Avoiding Unnecessary Updates, </title> <booktitle> Glasgow Functional Programming Workshop, Ayr, (draft proceedings), </booktitle> <year> 1992. </year>
Reference-contexts: This may prove to be a useful route for formalising the notion of cost centres [SP92], and is the topic of current work. 6.4 Abstractions and Analyses One motivation for this work was a desire to avoid unnecessary updates <ref> [Lau92] </ref>. Previously we had no good semantics against which to prove our analysis correct.
Reference: [Lev80] <author> J.-J.Levy, </author> <title> Optimal Reductions in the Lambda Calculus, </title> <editor> in Seldin and Hindley eds., </editor> <booktitle> To H.B.Curry: Essays in Combinatory Logic, Lambda Calculus and Formalism, </booktitle> <pages> pp 159-191, </pages> <publisher> Academic Press, </publisher> <year> 1980. </year>
Reference-contexts: Similarly, a semantics for laziness is vital precursor to being precise about the difference between laziness and optimal reduction strategies <ref> [Lev80] </ref>. The semantics for laziness presented in this paper are simpler than any previously published. The key reason is that we separate the semantics into two parts. The first stage is a static conversion of the -calculus into a form where the creation and sharing of closures is explicit.
Reference: [Mar91] <author> L.Maranget, </author> <title> Optimal Derivations in Weak Lambda-calculi and in Orthogonal Term Rewriting Systems, </title> <booktitle> in Proc SIGPLAN POPL 91, Orlando, </booktitle> <pages> pp 255-269, </pages> <year> 1991. </year>
Reference-contexts: Sharing has been lost. Much work has been done on making substitution explicit, the most relevant for our purposes being that by Maranget <ref> [Mar91] </ref>, where he develops a framework of Labelled-Terms Rewriting Systems. Using these he studies the weak -calculi and shows the lazy strategy to be optimal.
Reference: [Ong88] <author> C.-H.L.Ong, </author> <title> The Lazy Lambda Calculus: An Investigation in the Foundations of Functional Programming, </title> <type> PhD Thesis, </type> <institution> Imperial College, </institution> <address> London, </address> <year> 1988. </year>
Reference-contexts: The paper concludes with ap-plications and extensions. 2 Related Work There have already been a number of attempts to provide semantics for laziness. Perhaps the best known is due to Abramsky and Ong <ref> [Abr90, Ong88] </ref> where they explore the theoretical consequences of treating -terms in weak head normal form as values.
Reference: [Pey92] <author> S.Peyton Jones, </author> <title> Implementing Lazy Functional Languages on Stock Hardware: </title> <journal> the Spineless Tagless G-Machine, Journal of Functional Programming, </journal> <note> CUP, 1992, to appear. </note>
Reference-contexts: Abramsky and Ong's semantics are defined at a high level of abstraction. At the other end of the scale is the operational semantics given to define the behaviour of abstract machines. Examples of this are the G-machine [Jon84], the STG-machine <ref> [Pey92] </ref>, the TIM [FW87] and TIGRE [KL89]. At the level of these machines we have to deal with code pointers, stacks, indirection nodes, and the like. These operational semantics capture laziness completely, but contain so much extra detail as to make reasoning or proofs nigh on impossible. <p> This process of normalisation borrows heavily from the STG language <ref> [Pey92] </ref>, which has an even more restricted form of application. The value of the STG language is its direct operational reading (though far less abstract than appearing here). 3.2 Dynamic Semantics The rules are presented in Figure 1.
Reference: [PL91] <author> S.Peyton Jones and D.Lester, </author> <title> A Fully-Lazy Lambda-Lifter in Haskell, </title> <journal> Software Practice and Experience, </journal> <volume> 21 (5), </volume> <pages> pp 479-506, </pages> <year> 1991. </year>
Reference-contexts: Showing why this happens is exactly what the semantics is for. In particular, this work was motivated by a need to be precise about when closures where built, how often computations were performed, how often closures were accessed, and the operational implications of lambda lifting and full laziness <ref> [PL91] </ref>. Similarly, a semantics for laziness is vital precursor to being precise about the difference between laziness and optimal reduction strategies [Lev80]. The semantics for laziness presented in this paper are simpler than any previously published. The key reason is that we separate the semantics into two parts.
Reference: [PS92] <author> S.Purushothaman and J.Seaman, </author> <title> An Adequate Operational Semantics of Sharing in Lazy Evaluation, </title> <booktitle> in Proc ESOP 92, Rennes, </booktitle> <address> S-V, </address> <year> 1992. </year>
Reference-contexts: Furthermore, because the semantics was denotational, Josephs had to introduce a forcing function (corresponding to the print-demand) for controlling the extent of evaluation required at any point. An operational alternative was adopted by Pu-rushothaman and Seaman <ref> [PS92] </ref>. The authors present an operational semantics for Lazy PCF which they prove equivalent to a standard denotational semantics (observations at higher types are treated specially because of this).
Reference: [SP92] <author> P.Sansom and S.Peyton Jones, </author> <title> Profiling Lazy Functional Languages, </title> <booktitle> Glasgow Functional Programming Workshop, </booktitle> <address> Ayr, </address> <note> (draft proceedings),1992. </note>
Reference-contexts: For example, the Application rule might become, : e + p : y:e 0 : e 0 [x=y] + q fi : z Now the subscripts indicate how many reduction steps were performed. This may prove to be a useful route for formalising the notion of cost centres <ref> [SP92] </ref>, and is the topic of current work. 6.4 Abstractions and Analyses One motivation for this work was a desire to avoid unnecessary updates [Lau92]. Previously we had no good semantics against which to prove our analysis correct.
References-found: 15

