URL: http://www.cs.pitt.edu/~moir/Papers/menke-moir-ramamurthy-podc98.ps
Refering-URL: http://www.cs.pitt.edu/~moir/papers.html
Root-URL: http://www.cs.pitt.edu
Title: Synchronization Mechanisms for SCRAMNet+ Systems  
Author: Stephen Menke Mark Moir Srikanth Ramamurthy 
Address: 200 Beta Drive Pittsburgh, PA 15238  Pittsburgh Pittsburgh, PA 15260  707 Grant Street Pittsburgh, PA 15219  
Affiliation: Westinghouse Co.  Department of Computer Science The University of  Transarc Corporation  
Abstract: SCRAMNet network cards provide a replicated shared memory via a high-speed, fiber-optic ring. Such systems combine the advantages of conventional shared-memory multiprocessors and message-passing networks by allowing a collection of different computers to access a shared memory with low latency. This paper presents several synchronization mechanisms | both blocking and non-blocking | for SCRAMNet systems. It is well known that, for general non-blocking synchronization, strong synchronization primitives such as compare-and-swap (CAS) or load-linked/store-conditional (LL/SC) are needed. SCRAMNet cards do not provide such primitives. However, we show that strong synchronization primitives can be implemented in software by exploiting certain features of SCRAMNet cards. In particular, we show that wait-free consensus can be solved in SCRAMNet systems, and we present a simple and efficient wait-free implementation of CAS. We also present new mutual exclusion and renaming algorithms for SCRAMNet systems. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Anderson and M. Moir, </author> <title> "Universal Constructions for Multi-Object Operations", </title> <booktitle> Proceedings of the 14th Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <year> 1995, </year> <pages> pp. 184-194. </pages>
Reference: [2] <author> J. Anderson and M. Moir, </author> <title> "Universal Constructions for Large Objects", </title> <booktitle> Proceedings of the Ninth International Workshop on Distributed Algorithms, </booktitle> <year> 1995, </year> <pages> pp. 168-182. </pages>
Reference-contexts: We believe (although we have not verified this) that the universal constructions for large objects designed by Anderson and Moir <ref> [2] </ref> will work directly in SCRAMNet systems because, roughly speaking, whenever they are writing shared memory locations other than synchronization variables, these memory locations are "owned" by the writing process and are not accessed by other processes concurrently.
Reference: [3] <author> J. Anderson and M. Moir, </author> <title> "Fast Algorithms for k-Exclusion", </title> <note> to appear in Distributed Computing. A preliminary version appeared in Proceedings of the 13th Annual ACM Symposium on Principles of Distributed Computing, </note> <year> 1994, </year> <pages> pp. 141-150. </pages>
Reference-contexts: Therefore, in order to apply our implementation, we must first assign new identifiers to the processes. This problem is known as renaming and has been studied extensively for both message passing and shared-memory systems [5, 11, 12]. In some settings, processes need to repeatedly acquire and release names <ref> [3] </ref>. This problem is known as long-lived renaming [11]. In this problem, there are N processes in the system, and at most k N processes concurrently hold or request names. <p> In other applications of renaming (see <ref> [3] </ref>, for example), the size of the name space achieved affects the time complexity of a computation performed by the renamed processes. In shared-memory systems that do not support any strong synchronization primitives (such as CAS), it is impossible to rename k processes to fewer than 2k 1 names [10].
Reference: [4] <author> J. Anderson, S. Ramamurthy, and K. Jeffay, </author> <title> "Real-Time Computing with Lock-Free Shared Objects", </title> <booktitle> Proceedings of the 16th IEEE Real-Time Systems Symposium, </booktitle> <year> 1995, </year> <pages> pp. 28-37. </pages>
Reference-contexts: We explore how these features can be exploited in order to provide the foundations for non-blocking synchronization. In particular, we show how CAS can be efficiently implemented in SCRAMNet systems. Anderson et al. recognized the utility of non-blocking shared object implementations in real-time systems <ref> [4] </ref> and implemented universal primitives for such systems [14]. These results exploit the characteristics of common real-time schedulers. In contrast, the results presented here do not rely on any scheduling assumptions; instead we exploit features of the underlying hardware.
Reference: [5] <author> H. Attiya, A. Bar-Noy, D. Dolev, D. Koller, D. Peleg, and R. Reischuk, </author> <title> "Achievable Cases in an Asynchronous Environment", </title> <booktitle> Proceedings of the 28th Annual IEEE Symposium on Foundations of Computer Science, </booktitle> <year> 1987, </year> <pages> pp. 337-346. </pages>
Reference-contexts: However, in practice, this is unlikely to be the case. Therefore, in order to apply our implementation, we must first assign new identifiers to the processes. This problem is known as renaming and has been studied extensively for both message passing and shared-memory systems <ref> [5, 11, 12] </ref>. In some settings, processes need to repeatedly acquire and release names [3]. This problem is known as long-lived renaming [11]. In this problem, there are N processes in the system, and at most k N processes concurrently hold or request names.
Reference: [6] <author> T. Bowman, </author> <title> "Shared-Memory Computing Architectures for Real-Time Simulation | Simplicity and Elegance", </title> <note> Systran technical paper available from http://www.systran.com/scramnet.htm, January 1998. </note>
Reference-contexts: For example, in a network with 10 nodes, all nodes will be updated within less than 9s of a write <ref> [6] </ref>. Thus, SCRAMNet systems have the advantages of shared memory, namely ease of programming, fast communication, and little or no software overhead for communication [6]. SCRAMNet systems also have the advantages of message-passing systems. <p> For example, in a network with 10 nodes, all nodes will be updated within less than 9s of a write <ref> [6] </ref>. Thus, SCRAMNet systems have the advantages of shared memory, namely ease of programming, fast communication, and little or no software overhead for communication [6]. SCRAMNet systems also have the advantages of message-passing systems. First, processors on a SCRAMNet network may be from different vendors, and may even be running different operating systems. <p> This might be an advantage, for example, if a specialized graphics processor is used to display the results of a computation carried out by general purpose computers. Also, in SCRAMNet systems, processors can be connected at distances of hundreds or even thousands of meters <ref> [6] </ref>. In contrast, processors in conventional shared-memory systems must usually be identical and located very close to each other geographically. In many applications, it is necessary for processes to share data. In this case, some form of synchronization must be employed in order to ensure the consistency of the data.
Reference: [7] <author> M. Greenwald and D. Cheriton, </author> <title> "The Synergy Between Non-Blocking Synchronization and Operating System Structure", </title> <booktitle> Proceedings of the Second Symposium on Operating System Design and Implementation, </booktitle> <year> 1996, </year> <pages> pp. 123-136. </pages>
Reference-contexts: While locking is simple and widely used, it also causes a number of problems, especially in real-time settings. These problems include convoying, deadlock, priority inversion, complicated scheduling, contention, and susceptibility to process delays and failures. Locking can also complicate system design <ref> [7] </ref>. There has been significant research interest recently in non-blocking synchronization as an alternative to locking. A particular focus of this research has been lock-free and wait-free implementations of shared objects. A shared object is a data structure and associated operations.
Reference: [8] <author> M. Herlihy, </author> <title> "Wait-Free Synchronization", </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 13(1), </volume> <year> 1991, </year> <pages> pp. 124-149. </pages>
Reference-contexts: It is clearly not reasonable to expect programmers to make such an undertaking each time a new object is needed. To relieve programmers of this burden, Herlihy suggested the use of universal constructions <ref> [8] </ref>. A universal construction takes sequential code for an object and automatically produces a lock-free or wait-free implementation of that object. Herlihy also showed that universal constructions are necessarily based on so-called universal primitives. Such primitives include the compare-and-swap (CAS) instruction and the load-linked/store-conditional (LL/SC) instruction pair. <p> This algorithm demonstrates the key idea used in our later results, and also establishes that, at least in principle, general non-blocking synchronization is possible in SCRAMNet systems. (Herlihy showed that the ability to solve wait-free consensus is necessary and sufficient for implementing any lock-free or wait-free shared object <ref> [8] </ref>.) Next, we present the simple mutual exclusion algorithm mentioned above; this algorithm employs a technique similar to the one used in our consensus algorithm. <p> However, universal constructions that are based directly on consensus have very high space and time overhead, and are therefore impractical (e.g., <ref> [8] </ref>). More practical universal constructions are based on synchronization primitives such as CAS and LL/SC. In Section 5, we show that CAS can be implemented in a wait free manner in SCRAMNet systems.
Reference: [9] <author> M. Herlihy, </author> <title> "A Methodology for Implementing Highly Concurrent Data Objects", </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 15(5), </volume> <year> 1993, </year> <pages> pp. 745-770. </pages>
Reference: [10] <author> M. Herlihy and N. Shavit, </author> <title> "The Topological Structure of Asynchronous Computability", </title> <type> Technical Report CS-96-03, </type> <institution> Brown University, </institution> <year> 1996. </year>
Reference-contexts: In shared-memory systems that do not support any strong synchronization primitives (such as CAS), it is impossible to rename k processes to fewer than 2k 1 names <ref> [10] </ref>. Furthermore, the best known long-lived algorithms for such systems that do achieve this bound have high space and time complexity [12]. This situation may seem discouraging for the problem at hand. However, below we present two solutions for long-lived renaming in SCRAMNet systems.
Reference: [11] <author> M. Moir and J. Anderson, </author> <title> "Wait-Free Algorithms for Fast, Long-Lived Renaming", </title> <booktitle> Science of Computer Programming 25 (1995), </booktitle> <pages> pp. 1-39. </pages> <note> A preliminary version appeared in Proceedings of the 8th International Workshop on Distributed Algorithms, </note> <year> 1994, </year> <pages> pp. 141-155. </pages>
Reference-contexts: However, in practice, this is unlikely to be the case. Therefore, in order to apply our implementation, we must first assign new identifiers to the processes. This problem is known as renaming and has been studied extensively for both message passing and shared-memory systems <ref> [5, 11, 12] </ref>. In some settings, processes need to repeatedly acquire and release names [3]. This problem is known as long-lived renaming [11]. In this problem, there are N processes in the system, and at most k N processes concurrently hold or request names. <p> This problem is known as renaming and has been studied extensively for both message passing and shared-memory systems [5, 11, 12]. In some settings, processes need to repeatedly acquire and release names [3]. This problem is known as long-lived renaming <ref> [11] </ref>. In this problem, there are N processes in the system, and at most k N processes concurrently hold or request names. <p> The first step in acquiring a name using our first algorithm is to acquire a name that is distinct among processes on the same processor. This can be achieved using a known simple and efficient renaming algorithm that can rename k processes to k names <ref> [11] </ref>. This algorithm is based on test-and-set (TAS). Most modern processors provide hardware instructions that easily implement TAS. <p> We therefore present a long-lived renaming algorithm below that does not depend on this assumption. Our second long-lived renaming algorithm draws on the techniques used in our SCRAMNet consensus algo rithm and the overall structure of the TAS renaming al-gorithm presented in <ref> [11] </ref>. In the algorithm of [11], there are k bits, which are initially false. A process acquires a name by performing a TAS on each bit in order until it succeeds in setting one of them. The process acquires the name associated with the bit that it sets. <p> We therefore present a long-lived renaming algorithm below that does not depend on this assumption. Our second long-lived renaming algorithm draws on the techniques used in our SCRAMNet consensus algo rithm and the overall structure of the TAS renaming al-gorithm presented in <ref> [11] </ref>. In the algorithm of [11], there are k bits, which are initially false. A process acquires a name by performing a TAS on each bit in order until it succeeds in setting one of them. The process acquires the name associated with the bit that it sets. <p> This identifier is assumed to be acquired using a renaming algorithm like the one in <ref> [11] </ref> before AcquireName is called. old is assumed to hold its value between calls to AcquireName and ReleaseName. processes from overwriting the value proposed by a pro-cess in the current round. For this reason, AcquireName repeatedly writes WAKEUP while waiting for DEC to change.
Reference: [12] <author> M. Moir, </author> <title> "Fast, Long-Lived Renaming Improved and Simplified", </title> <note> to appear in Science of Computer Programming. A preliminary version appeared in the proceedings of the 10th International Workshop of Distributed Algorithms, </note> <year> 1996, </year> <pages> pp. 287-303. </pages>
Reference-contexts: However, in practice, this is unlikely to be the case. Therefore, in order to apply our implementation, we must first assign new identifiers to the processes. This problem is known as renaming and has been studied extensively for both message passing and shared-memory systems <ref> [5, 11, 12] </ref>. In some settings, processes need to repeatedly acquire and release names [3]. This problem is known as long-lived renaming [11]. In this problem, there are N processes in the system, and at most k N processes concurrently hold or request names. <p> In shared-memory systems that do not support any strong synchronization primitives (such as CAS), it is impossible to rename k processes to fewer than 2k 1 names [10]. Furthermore, the best known long-lived algorithms for such systems that do achieve this bound have high space and time complexity <ref> [12] </ref>. This situation may seem discouraging for the problem at hand. However, below we present two solutions for long-lived renaming in SCRAMNet systems. Like our consensus and CAS implementations, these algorithms exploit the interrupt features of SCRAMNet to circumvent the lower bound mentioned above.
Reference: [13] <author> M. Moir, </author> <title> "Transparent Support for Wait-Free Transactions", </title> <booktitle> Proceedings of the 11th Annual International Workshop on Distributed Algorithms, </booktitle> <year> 1997, </year> <pages> pp. 305-319. </pages>
Reference-contexts: However, this approach would preclude some of the advantages offered by recent non-blocking constructions (e.g. <ref> [13] </ref>). <p> On the other hand, other universal constructions | such as Moir's constructions for supporting lock-free and wait-free parallel transactions <ref> [13] </ref> | do not have this property, and will therefore need to be modified in order to work in SCRAMNet systems. All of our synchronization techniques involve an ISR on one processor that coordinates concurrent operations.
Reference: [14] <author> S. Ramamurthy, M. Moir, and J. Anderson, </author> <title> "Real-Time Object Sharing with Minimal System Support", </title> <booktitle> Proceedings of the 15th Annual ACM Symposium on the Principles of Distributed Computing, </booktitle> <year> 1996, </year> <pages> pp. 233-242. </pages> <note> [15] "SCRAMNet VME Hardware Reference", Copyright 1994, Systran Corp., pp. F1-F2. </note>
Reference-contexts: In particular, we show how CAS can be efficiently implemented in SCRAMNet systems. Anderson et al. recognized the utility of non-blocking shared object implementations in real-time systems [4] and implemented universal primitives for such systems <ref> [14] </ref>. These results exploit the characteristics of common real-time schedulers. In contrast, the results presented here do not rely on any scheduling assumptions; instead we exploit features of the underlying hardware.
Reference: [16] <institution> Systran Corp. </institution> <note> World Wide Web Page. http://www.systran.com/scramnet.htm, January, </note> <year> 1998. </year>
Reference-contexts: Work supported in part by an NSF CAREER Award, CCR 9702767 and by an Oak Ridge Associated Universities Junior Faculty Development Award. latency communication between processors. Such applications include aircraft simulators, telemetry, robotics, data acquisition, instrumentation and control, and virtual reality <ref> [16] </ref>. A SCRAMNet system consists of a collection of computers, each of which contains a SCRAMNet network card. 1 These cards are connected together by a single fiber-optic ring.
References-found: 15

