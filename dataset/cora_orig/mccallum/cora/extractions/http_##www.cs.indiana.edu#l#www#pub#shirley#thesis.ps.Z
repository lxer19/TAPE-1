URL: http://www.cs.indiana.edu/l/www/pub/shirley/thesis.ps.Z
Refering-URL: http://www.cs.indiana.edu/l/www/pub/shirley/
Root-URL: http://www.cs.indiana.edu
Title: The Direct Lighting Computation in Global Illumination Methods  
Author: Changyaw Wang 
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> A.H.Stroud. </author> <title> Approximate Calculation of Multiple Integrals. </title> <publisher> Prentice-Hall, </publisher> <year> 1971. </year>
Reference-contexts: However it is currently difficult to predict the behavior of quasi-random samples. Although mathematicians have studied quasi-random samples and related them to equidistribution and its measure <ref> [1, 28, 71, 83, 50, 4] </ref> the application of these mathematical results in computer graphics is still limited. In this chapter, we also generalize the idea of equidistribution and propose a new multi-jittered sampling method [7], whose samples are equidistributed in any sub-domain. <p> In one dimension, suppose that P (x) is the probability distribution function of p (x), i.e. P (x) = a p (x)dx, then x i = P 1 (~) where ~ is a random number in <ref> [0; 1] </ref>. When the analytical form of P 1 (x) does not exist, numerical inversion should be used. If p (x) is 18 non-uniform, then the sampling strategy of finding x i is called importance sampling. The main drawback of Monte Carlo methods is slow convergence. <p> Jittering is an example of stratified samples as discussed in Section 5.2.2. 59 4.3 Linear Method To minimize the noise caused by a bad choice of p i , we can consult each luminaire to get a good estimate of L [i] direct for all i 2 <ref> [1; N ] </ref>. We call this the linear method since its execution time is linearly proportional to the number of luminaires. This method of setting p i was first used in [61], and was first theoretically justified in [65]. <p> Otherwise, the samples are not equidistributed. On the unit square, two widely used definitions of discrepancy [71, 19] are: 1. L 1 -discrepancy D N = maximum of j n xyj for 8 (x; y) 2 <ref> [0; 1] </ref> 2 2. L 2 -discrepancy T N = s 0 0 n xyj 2 dxdy for 8 (x; y) 2 [0; 1] 2 where N is the total number of samples and n is the number of samples inside the region [0; x] fi [0; y]. <p> L 1 -discrepancy D N = maximum of j n xyj for 8 (x; y) 2 <ref> [0; 1] </ref> 2 2. L 2 -discrepancy T N = s 0 0 n xyj 2 dxdy for 8 (x; y) 2 [0; 1] 2 where N is the total number of samples and n is the number of samples inside the region [0; x] fi [0; y]. The term j n xyj is called the local discrepancy at (x; y). The discrepancy, which is within [0; 1], becomes smaller as the samples <p> dxdy for 8 (x; y) 2 <ref> [0; 1] </ref> 2 where N is the total number of samples and n is the number of samples inside the region [0; x] fi [0; y]. The term j n xyj is called the local discrepancy at (x; y). The discrepancy, which is within [0; 1], becomes smaller as the samples are more equidistributed. The axis-aligned rectangle in local discrepancy test has been extended to disks [46] and random-edges [19] in an effort to make discrepancy more valuable for graphics application. <p> The estimation error from a set of samples has been shown to be bounded by a linear combination of the discrepancy and the variation (defined below) of the estimated function <ref> [17, 71, 1] </ref>. This suggests that discrepancy might be used to rate the quality of sample sets. <p> This gives motivation for Mitchell's introduction of edge based discrepancy [46]. 5.2 Sampling Methods A sampling method should generate samples that estimate an integral with as small an error as possible. Sampling methods from integration theory have developed different numerical rules to generate sample sets of extremely low discrepancy <ref> [83, 89, 1] </ref>, but these rules create deterministic sample sets which are prone to aliasing artifacts when used in image synthesis, because each pixel is sampled using the same pattern. On the other hand, methods from computer graphics generate stochastic samples with higher discrepancy. <p> The kth sample over the hypercube 0 x i 1, for all i 2 <ref> [1; d] </ref> is (x 1 ; ; x d ) = (fk 1 g; ; fk d g) Zaremba-Hammersley sequence. 1 = 2 and 2 = 3 are one possible choice in a square domain. <p> Zaremba-Hammersley sequence : The kth sample over the hypercube 0 x i 1, for all i 2 <ref> [1; d] </ref> is k 1 ; P 1 (k 1); ; P d1 (k 1)) where P i is the ith prime, e.g. P 1 = 2 and P 2 = 3. <p> 0 where a n 6= 0, then r (m) = (a 0 mod r) r 1 1 The numerical experiments have shown that the Zaremba-Hammersley sequence has the lowest L 2 -discrepancy T N among many commonly suggested methods from integration theory, including the other two methods in this Section <ref> [83, 89, 1] </ref>. The sample patterns with 9 samples from each of these sampling methods are in Figure 5.1. <p> Assign a unique bin to the samples with the same Z cell. The result in Table 5.5 shows that multi-jittered still has the lowest average 3D L 2 discrep ancy, where T N = s 0 0 0 n xyzj 2 dxdydz for 8 (x; y; z) 2 <ref> [0; 1] </ref> 3 . The N-rooks oriented approach can also be used to generate 3D multi-jittered samples. Suppose N samples are needed. <p> K () is commonly expressed as a product of maximum lumi nous efficacy K m ( = 683 lumen watt ), and spectral luminous efficiency function V (), which is normalized in <ref> [0; 1] </ref>. K () basically corresponds to photopic vision, mediated by the cones and similarly there is a relationship for scotopic vision or rod vision, i.e. K 0 () = K 0 m V 0 (). <p> L direct = L <ref> [1] </ref> direct + + L [i] direct + + L [N] direct = 0 [1] direct dt + + Z i L direct dt + + Z N L direct dt = 0 [1] direct u 1 (t )dt + + Z N L direct u i (t )dt + + <p> L direct = L <ref> [1] </ref> direct + + L [i] direct + + L [N] direct = 0 [1] direct dt + + Z i L direct dt + + Z N L direct dt = 0 [1] direct u 1 (t )dt + + Z N L direct u i (t )dt + + Z N L direct u N (t )dt = 0 [1] direct u 1 <p> L direct = L <ref> [1] </ref> direct + + L [i] direct + + L [N] direct = 0 [1] direct dt + + Z i L direct dt + + Z N L direct dt = 0 [1] direct u 1 (t )dt + + Z N L direct u i (t )dt + + Z N L direct u N (t )dt = 0 [1] direct u 1 (t ) + + L [N] direct u N (t )dt where u i (t ) = 1 when <p> direct = 0 <ref> [1] </ref> direct dt + + Z i L direct dt + + Z N L direct dt = 0 [1] direct u 1 (t )dt + + Z N L direct u i (t )dt + + Z N L direct u N (t )dt = 0 [1] direct u 1 (t ) + + L [N] direct u N (t )dt where u i (t ) = 1 when i 1 &lt; t i and u i (t ) = 0 otherwise. <p> L direct L direct u 1 ( _t ) + + L [N] direct u N ( _t ) p ( _t ) L direct p ( _t ) The ceiling function dt e = i when i 1 &lt; t i. The integrand L <ref> [1] </ref> direct u 1 (t ) + + L direct u N (t ) is a step function and thus it is reasonable to have the discrete probability 111 density function p (t ) equal to p (dt e) for all t , and L direct L direct p (d _t <p> L direct = Z Z f (; -)dd Z Z f (; -) p -(-)dd 1 Z f (; _-)d = p -( _-) p (j _-) p -( _-)p ( _j _-) f ( _; _-) If given two random numbers ~ 1 and ~ 2 in <ref> [0; 1] </ref>, then _ and _- can be derived by inverting the following two equations. ~ 1 = min Z _ Z p (; -)dd- (C.1) Z _ ( _-) p (j _-)d = min ( _-) p (; _-)d p (; _-)d In order to implement this inversion, the antiderivative
Reference: [2] <author> Larry Aupperle and Pat Hanrahan. </author> <title> A hierarchical illumination algorithm for surfaces with glossy reflection. </title> <journal> Computer Graphics, </journal> <volume> 6(1) </volume> <pages> 155-162, </pages> <month> August </month> <year> 1993. </year> <booktitle> ACM Siggraph '93 Conference Proceedings. </booktitle>
Reference-contexts: For example, the hierarchy suggested for a TV screen or the sky in Section 3.1.7. In zonal methods, combining (energy-receiving) elments and (energy-releasing) patches is a typical example of two-level representation [13, 12] while the hierarchical algorithm is an example of multiple resolution <ref> [29, 26, 2] </ref>. To compute the color change due to an imposter at a point or in a pixel is difficult since it involves the computation of the difference between two high dimensional integrals with different domains (the shape of the luminaire) and integrands (the luminous intensity of the luminaire).
Reference: [3] <author> Daniel R. Baum, Holly E. Rushmeier, and James M. Winget. </author> <title> Improving radiosity solutions through the use of analytically determined form-factors. </title> <journal> Computer Graphics, </journal> <volume> 23(3) </volume> <pages> 325-334, </pages> <month> July </month> <year> 1989. </year> <booktitle> ACM Siggraph '89 Conference Proceedings. </booktitle>
Reference-contexts: Case 4 : p 4 (x 0 ) = cos cos 0 p total p total is the sum of the p total from T 1 ,: : :,T n as discussed in Section 3.1.3. A better way to compute p total is in <ref> [51, 3] </ref>.
Reference: [4] <author> Jozsef Beck and William W.L. Chen. </author> <title> Irregularities of distribution. </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge, </address> <year> 1987. </year>
Reference-contexts: However it is currently difficult to predict the behavior of quasi-random samples. Although mathematicians have studied quasi-random samples and related them to equidistribution and its measure <ref> [1, 28, 71, 83, 50, 4] </ref> the application of these mathematical results in computer graphics is still limited. In this chapter, we also generalize the idea of equidistribution and propose a new multi-jittered sampling method [7], whose samples are equidistributed in any sub-domain.
Reference: [5] <author> Richard L. Burden, J. Douglas Faires, and Albert C. Reynolds. </author> <title> Numerical Analysis. </title> <editor> Prindle, Weber & Schmidt, </editor> <address> Boston, Massachusetts, </address> <year> 1978. </year> <month> 115 </month>
Reference-contexts: Images using ambient light usually look somewhat flat, so there is some indication that the indirect lighting should be computed, but not with an extreme accuracy. 2.2 Numerical Integration over A Finite Interval L direct and L (i; j) can be approximated by many numerical methods <ref> [5, 17] </ref>, which fall into four categories: traditional quadrature, Monte Carlo methods [37, 9, 57], weighted Monte Carlo methods [24], and quasi-Monte Carlo methods [71, 62, 19].
Reference: [6] <author> Shenchang Eric Chen, Holly Rushmeier, Gavin Miller, and Douglass Turner. </author> <title> A pro-gressive multi-pass method for global illumination. </title> <journal> Computer Graphics, </journal> <volume> 25(4) </volume> <pages> 165-174, </pages> <month> July </month> <year> 1991. </year> <booktitle> ACM Siggraph '91 Conference Proceedings. </booktitle>
Reference-contexts: The indirect lighting in a diffuse environment produces smooth shading variation due to multiple and recursive interactions among objects, and is commonly solved by zonal methods with a discretized environment <ref> [25, 63, 29, 6, 72] </ref> or ray tracing with cached indirect lighting [82] as discussed in Chapter 2. In a scene with specular or transparent objects, the situation gets complicated because indirect lighting can also produce rapid shading variation [31, 6]. <p> In a scene with specular or transparent objects, the situation gets complicated because indirect lighting can also produce rapid shading variation <ref> [31, 6] </ref>. It is also possible to solve direct and indirect lighting all at once [69]. In a natural scene, it is estimated that 80 million polygons are required to give a realistic look [74]. <p> In these methods objects are tessellated into elements or patches. Each element of the tessellation is assumed small enough that it can be characterized by one bidirectional reflectance-distribution function f r (x; ; 0 ) <ref> [63, 6, 29, 69, 72] </ref>. Then energy is transported among elements and patches. In the shooting approach, a patch distributes its energy to the visible elements while in the gathering approach, an element collects its energy from all the other patches and elements. <p> No matter how many patches define a light bulb surface, it will receive only one shadow ray. The objects which have strong reflected light are suggested to be incorporated with luminaires into direct lighting computation because they can also cause sharp radiance change on other objects <ref> [39, 6] </ref>. The implementation is generally achieved by first categorizing bright emitting luminaires and reflected objects as light sources, after the zonal methods has computed indirect lighting. Then in the viewing phase, the direct lighting from the 71 light sources are computed.
Reference: [7] <author> K. Chiu, M. Herf, P. Shirley, S. Swamy, C. Wang, and K. Zimmerman. </author> <title> Spatially nonuniform scaling functions for high contrast images. Graphics Interface, </title> <year> 1993. </year>
Reference-contexts: Although mathematicians have studied quasi-random samples and related them to equidistribution and its measure [1, 28, 71, 83, 50, 4] the application of these mathematical results in computer graphics is still limited. In this chapter, we also generalize the idea of equidistribution and propose a new multi-jittered sampling method <ref> [7] </ref>, whose samples are equidistributed in any sub-domain. <p> One reason is that a fast but coarse approximation can produce an image without a significant degradation of quality [58]. The other reasons relate to the non-linear transformation of a real-world image to a screen image which only allows a small intensity range <ref> [73, 7] </ref>. The non-linear transformation of Tumblin and Rushmeier suggests that the full intensity range of the screen image should be a nonlinear function to the actual intensity range of the real-world image, i.e. a real-world image is mapped only to a portion of the intensity range on the screen. <p> However, this transformation further limits the intensity resolution. The other non-linear transformation by Chiu et al. <ref> [7] </ref> suggests that a real-world radiance can be mapped to a range of screen intensities instead of a single intensity as long as the relative contrast is maintained. <p> Yet, to decide the accuracy of an imposter is more complicated than computing the color difference, because human visual system does not see the absolute radiance <ref> [40, 7] </ref>. Furthermore, since images are not compared side-by-side, the "accuracy" of an imposter depends on how humans interpret the visual cues to verify the validity of an image. <p> We set the radiance threshold to be some fraction of L white 2 . Because our display device has eight bits per channel, we usually make 2 L white should be chosen according to a perceptual viewer model, such as the model implemented by Tum-blin and Rushmeier <ref> [73, 7] </ref>. Such models will become increasingly important as physically based rendering 64 the threshold a few percent of L white . Such a threshold will ensure that any luminaire that can change the pixel color more than a few intensity steps will be included in important group. <p> Render the initial image with n initial samples. 96 3. Transform the initial image into the displayable image for the media of choice. If the media is a CRT, then a good transformation would be an extension combining Tumblin [73] and Chiu <ref> [7] </ref>. 4. Decide the accuracy function S (x; y), where S (i; j) is the accuracy requirement at pixel (i; j). <p> Experiments show that to achieve 93% or 99% successful rate, we need at least 9 multi-jittered samples or 16 multi-jittered samples, respectively. 2. Render the initial image with 16 initial samples. 3. Transform the initial image by Chiu's method <ref> [7] </ref>. 4. Set * to be the maximum of jL neighbor Lj L neighbor + L , where neighbor means an adjacent pixel and L is the radiance at the pixel of interest. 5.
Reference: [8] <author> Ken Chiu, Peter Shirley, and Changyaw Wang. </author> <title> Multi-jittered sampling methods. </title> <editor> In Paul S. Heckbert, editor, </editor> <title> Graphics Gems 4. </title> <publisher> Academic Press, </publisher> <address> New York, NY, </address> <year> 1993. </year> <note> (to appear). </note>
Reference-contexts: This step creates an image on the CRT which gives an impression similar to the rendered image displayed on an ideal CRT with an infinite dynamic range 1 . This document focuses on the rendering process. Specifically it covers new sample point generation methods <ref> [8] </ref>, new warping schemes that transform samples to various two dimensional luminaire domains [77], and a complete supersampling framework. Given an accurate scene database, lighting is the key issue in realistic rendering. <p> which have low discrepancy values, but to arrange these patterns in order to decrease the number of patterns required rely on further research. 5.2.2 Previous Methods in Rectangular Domains Sampling methods for square or rectangular domains, e.g. a pixel or a rectangular luminaire, have been heavily studied in computer graphics <ref> [15, 44, 60, 8] </ref>. The most widely used strategies are random sampling, regular sampling, jittered sampling, Poisson disk sampling and N-rooks sampling as illustrated in Figure 5.2. 81 N-rooks samples with 4 samples. The random sampling method randomly chooses a sample within the domain. <p> A faster way to generate multi-jittered samples is to first permute bins in each cell, and then for the (i; j) cell, we put the sample at the jth permuted bin inside the ith cell on X, and the ith permuted bin inside the jth cell on Y <ref> [8] </ref>. 5.2.3.2 N-rooks Oriented Method. To generate N N-rooks samples, we divide the domain into N by N cells. Then we independently permute the list (1; 2; ; N ) twice into L 1 and L 2 .
Reference: [9] <author> William Gemmell Cochran. </author> <title> Sampling Techniques. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1977. </year>
Reference-contexts: so there is some indication that the indirect lighting should be computed, but not with an extreme accuracy. 2.2 Numerical Integration over A Finite Interval L direct and L (i; j) can be approximated by many numerical methods [5, 17], which fall into four categories: traditional quadrature, Monte Carlo methods <ref> [37, 9, 57] </ref>, weighted Monte Carlo methods [24], and quasi-Monte Carlo methods [71, 62, 19].
Reference: [10] <author> Michael F. Cohen, Shenchang Eric Chen, John R. Wallace, and Donald P. Greenberg. </author> <title> A progressive refinement approach to fast radiosity image generation. </title> <journal> Computer Graphics, </journal> <volume> 22(4) </volume> <pages> 75-84, </pages> <month> August </month> <year> 1988. </year> <booktitle> ACM Siggraph '88 Conference Proceedings. </booktitle>
Reference-contexts: Both transformations decrease the accuracy of the real-world image and can make the smooth transition of radiance from 15 L indirect even less noticeable. If the full solution for indirect lighting is not necessary, the ambient light 2 might be sufficient to give a reasonable approximation <ref> [10, 60] </ref>. To make the ambient light a good approximation of indirect lighting, we still need to consult the lighting condition and the environment.
Reference: [11] <author> Michael F. Cohen and Donald P. Greenberg. </author> <title> The hemi-cube: a radiosity solution for complex environments. </title> <journal> Computer Graphics, </journal> <volume> 19(3) </volume> <pages> 31-40, </pages> <month> July </month> <year> 1985. </year> <booktitle> ACM Siggraph '85 Conference Proceedings. </booktitle>
Reference-contexts: Z f (x)dx 0 f (x). A special subdivision scheme to transform the curved surface of solid angle into planes is the hemicube <ref> [11] </ref>, i.e. replacing a unit sphere by a unit box. An element in a hemicube is the smallest unit in approximation; if the projected luminaire covers the center of a element, the whole element is assumed to be covered; otherwise, the element is assumed to be totally uncovered. <p> In this subdivision, the projected solid angle Z cos d! of a luminaire is approximated by the product of the number of elements and , where N is the total number of elements. A different subdivision scheme for cos d! is to apply Nusselt analogy <ref> [68, 11] </ref>, i.e. cos d! equals the projected area of d! on the plane P perpendicular to the normal vector 53 at the illuminated point as shown in Figure 3.13. Note the projected area can never exceed the unit circle.
Reference: [12] <author> Michael F. Cohen and John R. Wallace. </author> <title> Radiosity and Realistic Image Synthesis. </title> <publisher> Academic Press, </publisher> <year> 1993. </year>
Reference-contexts: This method can be generalized to incorporate multiple representation for an object. For example, the hierarchy suggested for a TV screen or the sky in Section 3.1.7. In zonal methods, combining (energy-receiving) elments and (energy-releasing) patches is a typical example of two-level representation <ref> [13, 12] </ref> while the hierarchical algorithm is an example of multiple resolution [29, 26, 2].
Reference: [13] <author> Micheal F. Cohen, Donald P. Greenberg, David S. Immel, and Philip J. Brock. </author> <title> An efficient radioisty approach for realistic image synthesis. </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> 6(2) </volume> <pages> 26-35, </pages> <year> 1986. </year> <month> 116 </month>
Reference-contexts: This method can be generalized to incorporate multiple representation for an object. For example, the hierarchy suggested for a TV screen or the sky in Section 3.1.7. In zonal methods, combining (energy-receiving) elments and (energy-releasing) patches is a typical example of two-level representation <ref> [13, 12] </ref> while the hierarchical algorithm is an example of multiple resolution [29, 26, 2].
Reference: [14] <author> Robert L. Cook. </author> <title> Stochastic sampling and distributed ray tracing. </title> <editor> In Andrew S. Glass--ner, editor, </editor> <title> An Introduction to Ray Tracing. </title> <publisher> Academic Press, </publisher> <address> San Diego, CA, </address> <year> 1989. </year>
Reference-contexts: The other new p.d.f. has the samples evenly distributed within the solid angle 4 covered by the luminaire [76]. The direct lighting from more than one luminaire is the sum of the combined direct lighting. The straightforward summation gives a valid result <ref> [15, 14] </ref>, but it requires consulting all luminaires, including those dim and far away. It can be time consuming when the number of luminaires is over a few tens. Culling methods [39, 78, 81], consult all luminaires, although they calculate contributions only from dominant luminaires. <p> Sample point generation is a key issue in Monte Carlo methods, and is addressed in Chapter 5. Traditional Monte Carlo methods with random samples are inefficient because the samples are not evenly distributed 5 within the domain. Quasi-Monte Carlo methods with quasi-random samples are usually used <ref> [15, 14, 62, 60, 44] </ref>. Commonly used quasi-random samples include jittered samples, Poisson disk samples, and N-rooks samples. <p> Unlike some traditional quadrature methods, the number of samples is not propor- tional to 2 d for d-dimensional problems. 2. Their stochastic nature makes the estimation error appear as noise, which is more visually acceptable than aliasing artifacts created by deterministic process <ref> [15, 14] </ref>. 3. <p> The regular sampling method places samples evenly in a regular grid pattern. The regular samples are equidistributed in 2D, but its regularity can cause aliasing artifacts. Jittered sampling divides the domain into a set of equal-size cells, and a point is randomly chosen from each jittered cell <ref> [14] </ref>. The jittered samples are equidistributed in two dimensions. but are not much better than random samples in one dimension projection. 82 The Poisson disk sampling method places samples apart by, at least, a predefined dis-tance r [15, 18]. <p> Whether samples generated directly in the space they will be sampling can improve equidistribution properties is still a research issue. 5.2.5 Methods for Three Dimensional Domains In a 3D domain such as P ixel fi T ime, Cook associates jittered samples on P ixel with jittered/stratified samples on T ime <ref> [14] </ref>. Mitchell uses a jittered pattern on P ixel and 87 then sequentially assign a time sample to each pixel sample such that the new time sample has (nearly) the maximum distance to all the existing time samples [45]. <p> Traditionally, samples in different domains, P ixel, Lens, T ime, and Direction, are chosen independently, but this approach does not guarantee that samples are equidistributed in any lower dimensional projection of the domain <ref> [14, 45] </ref>. boundary perpendicular to X relies on the sample equidistribution on X; case 2 shows that the effectiveness in detecting a feature boundary parallel to X relies on the sample equidistribution on Y ; and case 3 shows that effectiveness in detecting a feature boundary parallel to the diagonal relies
Reference: [15] <author> Robert L. Cook, Thomas Porter, and Loren Carpenter. </author> <title> Distributed ray tracing. </title> <journal> Computer Graphics, </journal> <volume> 18(4) </volume> <pages> 165-174, </pages> <month> July </month> <year> 1984. </year> <booktitle> ACM Siggraph '84 Conference Proceedings. </booktitle>
Reference-contexts: In this document, a luminaire doesn't include the sur rounding fixtures. 2 extremely important visual cue in a realistic image [48]. Global illumination <ref> [84, 15, 25, 51] </ref>, on the other hand, accounts for interreflection among objects. Not surprisingly, global illumination takes much more computation time than local illumination. One major speed up strategy for global illumination is to treat direct lighting and indirect lighting 3 differently [51, 36, 82, 60, 58]. <p> The other new p.d.f. has the samples evenly distributed within the solid angle 4 covered by the luminaire [76]. The direct lighting from more than one luminaire is the sum of the combined direct lighting. The straightforward summation gives a valid result <ref> [15, 14] </ref>, but it requires consulting all luminaires, including those dim and far away. It can be time consuming when the number of luminaires is over a few tens. Culling methods [39, 78, 81], consult all luminaires, although they calculate contributions only from dominant luminaires. <p> Sample point generation is a key issue in Monte Carlo methods, and is addressed in Chapter 5. Traditional Monte Carlo methods with random samples are inefficient because the samples are not evenly distributed 5 within the domain. Quasi-Monte Carlo methods with quasi-random samples are usually used <ref> [15, 14, 62, 60, 44] </ref>. Commonly used quasi-random samples include jittered samples, Poisson disk samples, and N-rooks samples. <p> Unlike some traditional quadrature methods, the number of samples is not propor- tional to 2 d for d-dimensional problems. 2. Their stochastic nature makes the estimation error appear as noise, which is more visually acceptable than aliasing artifacts created by deterministic process <ref> [15, 14] </ref>. 3. <p> L direct = N X L direct . In traditional ray tracing programs the direct lighting computation is carried out by explicit summation <ref> [15] </ref>, which requires one shadow ray for each luminaire. This approach can be computationally expensive because too many shadow rays are sent to unimportant luminaires which have little contribution. <p> The nature of high frequency in image synthesis explains the occurrence of aliasing artifacts, such as jaggies and Moire patterns [21, 23]. Signal processing also predicts that the aliasing can be reduced by pushing the error into high frequencies as being used by stochastic samples <ref> [15] </ref>. <p> which have low discrepancy values, but to arrange these patterns in order to decrease the number of patterns required rely on further research. 5.2.2 Previous Methods in Rectangular Domains Sampling methods for square or rectangular domains, e.g. a pixel or a rectangular luminaire, have been heavily studied in computer graphics <ref> [15, 44, 60, 8] </ref>. The most widely used strategies are random sampling, regular sampling, jittered sampling, Poisson disk sampling and N-rooks sampling as illustrated in Figure 5.2. 81 N-rooks samples with 4 samples. The random sampling method randomly chooses a sample within the domain. <p> The jittered samples are equidistributed in two dimensions. but are not much better than random samples in one dimension projection. 82 The Poisson disk sampling method places samples apart by, at least, a predefined dis-tance r <ref> [15, 18] </ref>. To generate Poisson disk samples, we can sequentially create random samples, and reject a sample if its distance to any previous sample is within r. The Poisson disk samples are designed to avoid clumping, which will improve equidistribution in two dimensions.
Reference: [16] <author> Frank Crow. </author> <title> Summed-area tables for texture mapping. </title> <journal> Computer Graphics, </journal> <volume> 18(4) </volume> <pages> 207-212, </pages> <month> July </month> <year> 1984. </year> <booktitle> ACM Siggraph '84 Conference Proceedings. </booktitle>
Reference-contexts: A better approach is to construct a hierarchy such as a Mip map [85] or a summed-area 46 table <ref> [16] </ref>, and use the coarsest representation whenever possible.
Reference: [17] <author> Philip J. Davis and Philip Rabinowitz. </author> <title> Methods of Numerical Integration. </title> <publisher> Academic Press, </publisher> <address> second edition, </address> <year> 1984. </year>
Reference-contexts: Images using ambient light usually look somewhat flat, so there is some indication that the indirect lighting should be computed, but not with an extreme accuracy. 2.2 Numerical Integration over A Finite Interval L direct and L (i; j) can be approximated by many numerical methods <ref> [5, 17] </ref>, which fall into four categories: traditional quadrature, Monte Carlo methods [37, 9, 57], weighted Monte Carlo methods [24], and quasi-Monte Carlo methods [71, 62, 19]. <p> The process of generating a Voronoi diagram is illustrated in Figure 2.2. Weighted Monte Carlo methods become less attractive as the dimension goes up because of the dimensional effect, where the number of partition cells increases at the same order as the dimension of the domain <ref> [17] </ref>. 19 perpendicular line at the middle of the line segment connecting every pair of samples. <p> The estimation error from a set of samples has been shown to be bounded by a linear combination of the discrepancy and the variation (defined below) of the estimated function <ref> [17, 71, 1] </ref>. This suggests that discrepancy might be used to rate the quality of sample sets.
Reference: [18] <author> Mark Z. Dippe and Erling Henry Wold. </author> <title> Antialiasing through stochastic sampling. </title> <journal> Computer Graphics, </journal> <volume> 19(3) </volume> <pages> 69-78, </pages> <month> July </month> <year> 1985. </year> <booktitle> ACM Siggraph '85 Conference Proceedings. </booktitle>
Reference-contexts: Although adaptive supersampling, which uses more than one sample within a pixel for antialiasing, has often been proposed, the prediction of the number of samples needed is still a challenging topic. Methods based on criteria from statistics [43], signal processing <ref> [18] </ref>, or perceptual models [44] have been suggested, but the justification of the criteria involves the not fully understood relationship between the estimation error of the pixel color, the display algorithm, and the human perceptual system. <p> The jittered samples are equidistributed in two dimensions. but are not much better than random samples in one dimension projection. 82 The Poisson disk sampling method places samples apart by, at least, a predefined dis-tance r <ref> [15, 18] </ref>. To generate Poisson disk samples, we can sequentially create random samples, and reject a sample if its distance to any previous sample is within r. The Poisson disk samples are designed to avoid clumping, which will improve equidistribution in two dimensions. <p> Adaptive supersampling methods can be with subdivision, which places extra samples only in regions with high variance [84, 36, 54, 23, 24], or without subdivision, which evenly distributes extra samples over the pixel <ref> [43, 18, 55, 35, 44, 38] </ref>. In subdivision supersampling, if the variation of the estimates in a region is over a predefined threshold, the region is further sampled. Subdivision supersampling methods are effective if the initial samples can reliably detect regions that require extra sampling. <p> All the existing methods are based on contrast or on the pixel complexity such as variance or the absolute estimation error <ref> [43, 55, 18, 44] </ref>. In this section, we discuss the existing non-adaptive supersampling methods and their weaknesses, and then present a supersampling framework which can take all these factors into account. 5.3.1 Existing Adaptive Supersampling Methods Statistical methods have been used to control adaptive supersampling. <p> Signal processing suggests that jX E [X]j / fi, where fi is the sampling rate, which changes with the number of samples as well as the sampling methods <ref> [18] </ref>.
Reference: [19] <author> David P. Dobkin and Don P. Mitchell. </author> <title> Random-edge discrepancy of supersampling patterns. </title> <booktitle> In Proceedings of Graphics Interface '93, </booktitle> <pages> pages 62-69, </pages> <year> 1993. </year>
Reference-contexts: but not with an extreme accuracy. 2.2 Numerical Integration over A Finite Interval L direct and L (i; j) can be approximated by many numerical methods [5, 17], which fall into four categories: traditional quadrature, Monte Carlo methods [37, 9, 57], weighted Monte Carlo methods [24], and quasi-Monte Carlo methods <ref> [71, 62, 19] </ref>. This classification emphasizes various Monte Carlo methods because their important properties which have made them a practical choice for computer graphics: 2 Ambient light is a simple model which produces constant illumination on all surfaces regardless of their position or orientation. 16 1. <p> However, signal processing does not help us predict the absolute quality of estimation to be expected from a given sampling pattern. 5.1.3 Discrepancy Integration theory suggests that the convergence rate from a set of samples is closely related to the discrepancy <ref> [71, 62, 19] </ref>, which is a measure of equidistribution. Ideal equidis-tribution means that the fraction of the samples in each subdomain is equal to the fractional measure of that subdomain. With a finite number of samples, ideal equidistribution is impossible. <p> If all samples have the same weight, then samples are equidistributed if there exist a subdivision such that all i are compact and close to 1 . Otherwise, the samples are not equidistributed. On the unit square, two widely used definitions of discrepancy <ref> [71, 19] </ref> are: 1. L 1 -discrepancy D N = maximum of j n xyj for 8 (x; y) 2 [0; 1] 2 2. <p> The term j n xyj is called the local discrepancy at (x; y). The discrepancy, which is within [0; 1], becomes smaller as the samples are more equidistributed. The axis-aligned rectangle in local discrepancy test has been extended to disks [46] and random-edges <ref> [19] </ref> in an effort to make discrepancy more valuable for graphics application. The local discrepancy in random-edge discrepancy is the difference between the area of a unit square above a random line and the fraction of sample points above the same line.
Reference: [20] <author> H. Engels. </author> <title> Numerical Quadrature and Cubature. </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1980. </year>
Reference-contexts: There are three common methods used to generate the ! i and x i <ref> [20] </ref>. Gaussian quadrature uses deterministic ! i and x i . Monte Carlo methods and quasi-Monte Carlo methods start with a partition of the domain and the weight of each cell, and then a sample is assigned in each cell.
Reference: [21] <author> James D. Foley, Andries van Dam, Steven K. Feiner, and John F. Hughes. </author> <title> Computer Graphics: </title> <booktitle> Principles and Practice. </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <note> second edition, </note> <year> 1990. </year>
Reference-contexts: Specifically it covers new sample point generation methods [8], new warping schemes that transform samples to various two dimensional luminaire domains [77], and a complete supersampling framework. Given an accurate scene database, lighting is the key issue in realistic rendering. The earliest lighting simulation used local illumination <ref> [21] </ref>, which only considers the luminaire 2 and the object whose color is being calculated. <p> In real examples, Ward used over 3 million surfaces (mostly cones) to generate tens of pine tress over a field of snow [81], and Snyder and Barr used 2 billion objects to generate a scene with hundreds of trees over a grass field <ref> [21] </ref>. <p> bidirectional reflectance-distribution function f r to account for the material property and a cosine term to account for the projected area of the incident light beam, e.g. the projected area is minimal if the light is perpendicular to the surface, and increases as the light goes down to the horizon <ref> [21] </ref>. The complete form is dL out r = f r (in; out r ) cos (N; in)L in , where N is the normal vector at x. <p> Modification schemes similar to luminaire imposters are widely used in image synthesis, 51 for example objects with simplified reflectance functions and objects stored at multiple levels of resolution <ref> [21, 27, 80] </ref>. Another typical imposter example is to change the physical behavior. <p> In computer graphics, edge and texture can make the pixel color a discrete continuous signal with unbounded frequency. The nature of high frequency in image synthesis explains the occurrence of aliasing artifacts, such as jaggies and Moire patterns <ref> [21, 23] </ref>. Signal processing also predicts that the aliasing can be reduced by pushing the error into high frequencies as being used by stochastic samples [15].
Reference: [22] <author> Andrew S. Glassner. </author> <title> Space subdivision for fast ray tracing. </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> 4(10) </volume> <pages> 15-22, </pages> <year> 1984. </year> <month> 117 </month>
Reference-contexts: The stratification of the scene into boxes is arbitrary. An easy way to choose the subdivision cells is simply to use the leaf cells of the conventional subdivision structure (e.g. the octree leaves of a Glassner style octree used for ray intersection acceleration <ref> [22] </ref>), and maintain a separate important group at each leaf. This is a finer than needed subdivision for scenes where the number of objects is much greater than the number of luminaires.
Reference: [23] <author> Andrew S. Glassner, </author> <title> editor. An Introduction to Ray Tracing. </title> <publisher> Academic Press, </publisher> <address> San Diego, CA, </address> <year> 1989. </year>
Reference-contexts: One major speed up strategy for global illumination is to treat direct lighting and indirect lighting 3 differently [51, 36, 82, 60, 58]. In general, the direct lighting can cause rapid shading change and is simulated by ray tracing <ref> [84, 23] </ref>, which starts from the eye or the camera film and reversely traces photons back to the luminaire as shown in Figure 1.2. <p> Theoretically, a continuous signal with band-limited frequency can be properly reconstructed with a sample rate greater than twice the highest frequency component in its spectrum <ref> [23] </ref>. In computer graphics, edge and texture can make the pixel color a discrete continuous signal with unbounded frequency. The nature of high frequency in image synthesis explains the occurrence of aliasing artifacts, such as jaggies and Moire patterns [21, 23]. <p> In computer graphics, edge and texture can make the pixel color a discrete continuous signal with unbounded frequency. The nature of high frequency in image synthesis explains the occurrence of aliasing artifacts, such as jaggies and Moire patterns <ref> [21, 23] </ref>. Signal processing also predicts that the aliasing can be reduced by pushing the error into high frequencies as being used by stochastic samples [15]. <p> Adaptive supersampling methods can be with subdivision, which places extra samples only in regions with high variance <ref> [84, 36, 54, 23, 24] </ref>, or without subdivision, which evenly distributes extra samples over the pixel [43, 18, 55, 35, 44, 38]. In subdivision supersampling, if the variation of the estimates in a region is over a predefined threshold, the region is further sampled. <p> In this framework, there are many missing elements that require further research. We present here a new supersampling method based on our partial understanding of the missing 97 elements. 1. The number of initial samples in existing supersampling methods assume 4 to 9 samples without justification <ref> [43, 36, 44, 23] </ref>. Instead, we assume that the initial samples are expected to detect the case of two features fully occupying a pixel when the projected area of either feature on the pixel is larger than 5% of the pixel size. <p> The surface scatters the incident flux in all directions. A perfectly diffusing surface (Lambertian surface) uniformly scatters such that the radiance is the same in all directions. specular surface or regular surface . The surface reflects the incident flux predominately at the specular angle or angle of reflection <ref> [23] </ref>. reflectance : , none. The reflected flux per incident flux, i.e. = r . bidirectional reflectance-distribution function : f r ( i ; i ; r ; r ), sr 1 .
Reference: [24] <author> Andrew S. Glassner. </author> <title> Dynamic stratification. </title> <booktitle> In Graphics Interface '93, </booktitle> <year> 1993. </year>
Reference-contexts: indirect lighting should be computed, but not with an extreme accuracy. 2.2 Numerical Integration over A Finite Interval L direct and L (i; j) can be approximated by many numerical methods [5, 17], which fall into four categories: traditional quadrature, Monte Carlo methods [37, 9, 57], weighted Monte Carlo methods <ref> [24] </ref>, and quasi-Monte Carlo methods [71, 62, 19]. <p> This requires some knowledge of the function which is possible in many, but not all, instances. In a two dimensional domain, Glassner used the Voronoi diagram as the partition and the area covered by each cell as the weight <ref> [24] </ref>. The Voronoi cell is a good choice because it is compact and has the sample near the center of each cell. The process of generating a Voronoi diagram is illustrated in Figure 2.2. <p> Adaptive supersampling methods can be with subdivision, which places extra samples only in regions with high variance <ref> [84, 36, 54, 23, 24] </ref>, or without subdivision, which evenly distributes extra samples over the pixel [43, 18, 55, 35, 44, 38]. In subdivision supersampling, if the variation of the estimates in a region is over a predefined threshold, the region is further sampled.
Reference: [25] <author> Cindy M. Goral, Kenneth E. Torrance, and Donald P. Greenberg. </author> <title> Modeling the interaction of light between diffuse surfaces. </title> <journal> Computer Graphics, </journal> <volume> 18(4) </volume> <pages> 213-222, </pages> <month> July </month> <year> 1984. </year> <booktitle> ACM Siggraph '84 Conference Proceedings. </booktitle>
Reference-contexts: In this document, a luminaire doesn't include the sur rounding fixtures. 2 extremely important visual cue in a realistic image [48]. Global illumination <ref> [84, 15, 25, 51] </ref>, on the other hand, accounts for interreflection among objects. Not surprisingly, global illumination takes much more computation time than local illumination. One major speed up strategy for global illumination is to treat direct lighting and indirect lighting 3 differently [51, 36, 82, 60, 58]. <p> The indirect lighting in a diffuse environment produces smooth shading variation due to multiple and recursive interactions among objects, and is commonly solved by zonal methods with a discretized environment <ref> [25, 63, 29, 6, 72] </ref> or ray tracing with cached indirect lighting [82] as discussed in Chapter 2. In a scene with specular or transparent objects, the situation gets complicated because indirect lighting can also produce rapid shading variation [31, 6]. <p> It is possible to apply methods other than Monte Carlo methods to estimate L direct . One possible method is to simply combine L direct with L indirect and solve everything via naive zonal methods <ref> [25, 75] </ref>. However, this approach requires an extremely fine mesh size to capture rapid radiance changes caused by shadowing, projected solid angle of the luminaire, the intensity distribution of the luminaire, and reflectivity. <p> Another typical imposter example is to change the physical behavior. For example, non-emitting objects in zonal methods can emit the same amount of light as they would reflect <ref> [25, 63, 29] </ref>. 3.3.2 Imposters with Extra Information In a daytime indoor scene, the dominant luminaire would be the sun (assuming it is visible). Without predetermined knowledge of visibility in the environment, the direct lighting is carried out by sending shadow rays to the sun.
Reference: [26] <author> Steven J. Gortler, Peter Schroder, Michael F. Cohen, and Pat Hanrahan. </author> <title> Wavelet ra-diosity. </title> <journal> Computer Graphics, </journal> <volume> 6(1) </volume> <pages> 221-230, </pages> <month> August </month> <year> 1993. </year> <booktitle> ACM Siggraph '93 Conference Proceedings. </booktitle>
Reference-contexts: For example, the hierarchy suggested for a TV screen or the sky in Section 3.1.7. In zonal methods, combining (energy-receiving) elments and (energy-releasing) patches is a typical example of two-level representation [13, 12] while the hierarchical algorithm is an example of multiple resolution <ref> [29, 26, 2] </ref>. To compute the color change due to an imposter at a point or in a pixel is difficult since it involves the computation of the difference between two high dimensional integrals with different domains (the shape of the luminaire) and integrands (the luminous intensity of the luminaire).
Reference: [27] <author> Roy Hall. </author> <title> Illumination and Color in Computer Generated Imagery. </title> <publisher> Springer-Verlag, </publisher> <address> New York, N.Y., </address> <year> 1988. </year>
Reference-contexts: Modification schemes similar to luminaire imposters are widely used in image synthesis, 51 for example objects with simplified reflectance functions and objects stored at multiple levels of resolution <ref> [21, 27, 80] </ref>. Another typical imposter example is to change the physical behavior.
Reference: [28] <author> John H. Halton. </author> <title> Estimating the accuracy of quasi-monte carlo integration. </title> <editor> In S.K.Zaremba, editor, </editor> <booktitle> Applications of Number Theory to Numerical Analysis, </booktitle> <pages> pages 345-360. </pages> <publisher> Academic Press, </publisher> <year> 1972. </year>
Reference-contexts: However it is currently difficult to predict the behavior of quasi-random samples. Although mathematicians have studied quasi-random samples and related them to equidistribution and its measure <ref> [1, 28, 71, 83, 50, 4] </ref> the application of these mathematical results in computer graphics is still limited. In this chapter, we also generalize the idea of equidistribution and propose a new multi-jittered sampling method [7], whose samples are equidistributed in any sub-domain. <p> (~ i1 ; i1 )j among all possible partitions 0 = ~ 0 &lt; ~ 1 &lt; &lt; ~ N = 1 and 0 = 0 &lt; 1 &lt; &lt; N = 1. 77 Similar formulas for both one dimension and two dimensions can also be established with T N <ref> [28] </ref>. Theorem 2 cannot be directly applied to predict error in image synthesis because the image function in computer graphics contains edges and thus has unbounded variation V X;Y in Equation 5.2. However, the discrepancy might still be helpful in predicting the convergence behavior from a sample pattern [62].
Reference: [29] <author> Pat Hanrahan, David Salzman, and Larry Aupperle. </author> <title> A rapid hierarchical radiosity algorithm. </title> <journal> Computer Graphics, </journal> <volume> 25(4) </volume> <pages> 197-206, </pages> <month> July </month> <year> 1991. </year> <booktitle> ACM Siggraph '91 Conference Proceedings. </booktitle>
Reference-contexts: The indirect lighting in a diffuse environment produces smooth shading variation due to multiple and recursive interactions among objects, and is commonly solved by zonal methods with a discretized environment <ref> [25, 63, 29, 6, 72] </ref> or ray tracing with cached indirect lighting [82] as discussed in Chapter 2. In a scene with specular or transparent objects, the situation gets complicated because indirect lighting can also produce rapid shading variation [31, 6]. <p> In these methods objects are tessellated into elements or patches. Each element of the tessellation is assumed small enough that it can be characterized by one bidirectional reflectance-distribution function f r (x; ; 0 ) <ref> [63, 6, 29, 69, 72] </ref>. Then energy is transported among elements and patches. In the shooting approach, a patch distributes its energy to the visible elements while in the gathering approach, an element collects its energy from all the other patches and elements. <p> For example, the hierarchy suggested for a TV screen or the sky in Section 3.1.7. In zonal methods, combining (energy-receiving) elments and (energy-releasing) patches is a typical example of two-level representation [13, 12] while the hierarchical algorithm is an example of multiple resolution <ref> [29, 26, 2] </ref>. To compute the color change due to an imposter at a point or in a pixel is difficult since it involves the computation of the difference between two high dimensional integrals with different domains (the shape of the luminaire) and integrands (the luminous intensity of the luminaire). <p> Another typical imposter example is to change the physical behavior. For example, non-emitting objects in zonal methods can emit the same amount of light as they would reflect <ref> [25, 63, 29] </ref>. 3.3.2 Imposters with Extra Information In a daytime indoor scene, the dominant luminaire would be the sun (assuming it is visible). Without predetermined knowledge of visibility in the environment, the direct lighting is carried out by sending shadow rays to the sun.
Reference: [30] <author> Eugene Hecht and Alfred Zajac. </author> <title> Optics. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1974. </year>
Reference-contexts: The rendering equation represents only geometric optics and does not consider the light's properties in terms of the electromagnetic waves <ref> [30, 49] </ref>. This simplification ignores the effects of polarization, interference, and diffraction; but this is a minor limitation for most applications since these phenomena are not very noticeable in most scenes. The rendering equations in Equation 2.1 and Equation 2.2 show the radiance toward one direction only. <p> This is not physically correct because the color dispersion 1 <ref> [30, 49] </ref> is not simulated, but this is not a severe limitation for most applications.
Reference: [31] <author> Paul S. Heckbert. </author> <title> Adaptive radiosity textures for bidirectional ray tracing. </title> <journal> Computer Graphics, </journal> <volume> 24(3) </volume> <pages> 145-154, </pages> <month> August </month> <year> 1990. </year> <booktitle> ACM Siggraph '90 Conference Proceedings. </booktitle> <pages> 118 </pages>
Reference-contexts: In a scene with specular or transparent objects, the situation gets complicated because indirect lighting can also produce rapid shading variation <ref> [31, 6] </ref>. It is also possible to solve direct and indirect lighting all at once [69]. In a natural scene, it is estimated that 80 million polygons are required to give a realistic look [74].
Reference: [32] <author> Ronald N. Helms and M. Clay Belcher. </author> <title> lighting for energy-efficienct luminous environ-ments. </title> <publisher> Prentice-Hall, Inc., </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1991. </year>
Reference-contexts: In this section, we present several examples of imposters, paying special attention to imposter objects for luminaires. A luminaire is often specified by its shape and luminous intensity (which defines the luminous flux per unit solid angle as explained in Appendix A) <ref> [52, 35, 32] </ref>. The luminous 48 intensity of a luminaire can be represented as a polar graph (luminous intensity distribution curve), which shows a typical distribution curve of a point on the luminaire at a particular plane, in Figure 3.11.
Reference: [33] <author> Robert V. Hogg and Allen T. Craig. </author> <title> Introduction to Mathematical Statistics. </title> <address> Macmil-lan, New York, </address> <year> 1978. </year>
Reference-contexts: Weighted Monte Carlo methods assign samples before constructing the partition and computing the weights. 17 2.2.2 Monte Carlo Methods Monte Carlo methods represent an integral as a statistical expected value, which is then approximated by an average <ref> [33, 57, 38, 89] </ref>: Z f (x)d (x) = 8x2S p (x) = E [ p (X) N i=1 p (x i ) where X is a random variable having a probability density function p (x) (denoted X ~ p), i.e. p (x) &gt; 0 when f (x) 6= 0, and <p> k is a good approximation of the pixel color, and the standard derivation is a good approximation of the estimation error (X E [X]) if X has a normal distribution, where 2 = 1 n X (x i E [X]) 2 and x i is an estimate of E [X] <ref> [33] </ref>. Let s 2 1 n X (x i L) 2 . Then the Chi-square test [43]: p ( n fi (n 1)) = fi can be used to predict N , the number of samples needed in supersampling, from n initial samples. <p> The first weakness is that the fundamental assumption of a normal distribution of sample values is questionable. For example, if a pixel has only two constant colors, then X has a binomial distribution, which can be very different from normal distribution when n is small, say less than 30 <ref> [33] </ref>. The other weakness is that the quasi-random samples behave differently from random samples [46], and the validity of using the same formulas is questionable.
Reference: [34] <author> David S. Immel, Michael F. Cohen, and Donald P. Greenberg. </author> <title> A radiosity method for non-diffuse environments. </title> <journal> Computer Graphics, </journal> <volume> 20(4) </volume> <pages> 133-142, </pages> <month> August </month> <year> 1986. </year> <booktitle> ACM Siggraph '86 Conference Proceedings. </booktitle>
Reference-contexts: The first one shows that the outgoing radiance toward d! is the sum of the emitted radiance and the reflected radiance coming from every possible direction 0 as in Figure 2.1, and in Equation 2.1 (from Immel) <ref> [34] </ref>: Z f r (x; ; 0 )L (x; 0 ) cos d! 0 (2.1) where E (x; ) is the emitted radiance in direction at x, L (x; 0 ) the radiance from direc tion 0 incident at x, d! 0 is the differential solid angle subtended by 0 .
Reference: [35] <institution> American National Standard Institude. Nomenclature and definitions for illuminating engineering. </institution> <note> ANSI Report, 1986. ANSI/IES RP-16-1986. </note>
Reference-contexts: In this section, we present several examples of imposters, paying special attention to imposter objects for luminaires. A luminaire is often specified by its shape and luminous intensity (which defines the luminous flux per unit solid angle as explained in Appendix A) <ref> [52, 35, 32] </ref>. The luminous 48 intensity of a luminaire can be represented as a polar graph (luminous intensity distribution curve), which shows a typical distribution curve of a point on the luminaire at a particular plane, in Figure 3.11. <p> Adaptive supersampling methods can be with subdivision, which places extra samples only in regions with high variance [84, 36, 54, 23, 24], or without subdivision, which evenly distributes extra samples over the pixel <ref> [43, 18, 55, 35, 44, 38] </ref>. In subdivision supersampling, if the variation of the estimates in a region is over a predefined threshold, the region is further sampled. Subdivision supersampling methods are effective if the initial samples can reliably detect regions that require extra sampling. <p> Contrast is closely related to human perception and is the fundamental measure that other other visual behaviors are derived from. One common form of luminance contrast, L max L min , where L max and L min are the maximum and minimum radiance respectively <ref> [35] </ref>, is suggested to predict the number of samples, i.e. the number of samples taken is proportional to the contrast [44]. This method is plausible because it considers the nonlinear response of human perception; but it still has some weaknesses. <p> To avoid unnecessary confusion, we will follow the definition from American National Standard and Illuminating Engineering Society <ref> [35] </ref> as shown in Figure A.1, along with some supplementary information from Wyszecki and Stiles [88]. A quantity with a subscript means a spectral concentration, i.e. a quantity corresponding to a narrow wavelength interval. A quantity with a in parentheses means a function of wavelength.
Reference: [36] <author> James T. Kajiya. </author> <title> The rendering equation. </title> <journal> Computer Graphics, </journal> <volume> 20(4) </volume> <pages> 143-150, </pages> <month> August </month> <year> 1986. </year> <booktitle> ACM Siggraph '86 Conference Proceedings. </booktitle>
Reference-contexts: Global illumination [84, 15, 25, 51], on the other hand, accounts for interreflection among objects. Not surprisingly, global illumination takes much more computation time than local illumination. One major speed up strategy for global illumination is to treat direct lighting and indirect lighting 3 differently <ref> [51, 36, 82, 60, 58] </ref>. In general, the direct lighting can cause rapid shading change and is simulated by ray tracing [84, 23], which starts from the eye or the camera film and reversely traces photons back to the luminaire as shown in Figure 1.2. <p> The second form of the rendering equation shows that the outgoing radiance is the sum of the emitted radiance and the radiance from all visible surfaces, which is an integral over 10 all surfaces (as used by Kajiya <ref> [36] </ref>): L (x; ) = E (x; ) + 8x 0 2 x 0 dA 0 cos 0 where g (x; x 0 ) is the geometry term, which is zero if there is an obstruction between x and x 0 , and one otherwise. <p> However, finding a p ~ f r (x; ; 0 )E (x 0 ; 0 ) cos for general environment is very difficult and remains a research topic. In path tracing <ref> [36] </ref>, a viewing ray generates one shadow ray for direct lighting and one reflected/transmitted ray for indirect lighting. <p> This is very similar in concept to Kajiya's argument that we should not expend much work for deep parts of the ray tree <ref> [36] </ref>. It is not always true that one shadow ray per viewing ray is optimal. For example, the 100 luminaire case, one shadow ray is better than 100 shadow rays, but two or three might be better still. This issue requires further investigation. <p> Adaptive supersampling methods can be with subdivision, which places extra samples only in regions with high variance <ref> [84, 36, 54, 23, 24] </ref>, or without subdivision, which evenly distributes extra samples over the pixel [43, 18, 55, 35, 44, 38]. In subdivision supersampling, if the variation of the estimates in a region is over a predefined threshold, the region is further sampled. <p> In this framework, there are many missing elements that require further research. We present here a new supersampling method based on our partial understanding of the missing 97 elements. 1. The number of initial samples in existing supersampling methods assume 4 to 9 samples without justification <ref> [43, 36, 44, 23] </ref>. Instead, we assume that the initial samples are expected to detect the case of two features fully occupying a pixel when the projected area of either feature on the pixel is larger than 5% of the pixel size.
Reference: [37] <author> Malvin H. Kalos and Paula A. Whitlock. </author> <title> Monte Carlo Methods. </title> <publisher> John Wiley and Sons, </publisher> <address> New York, N.Y., </address> <year> 1986. </year>
Reference-contexts: so there is some indication that the indirect lighting should be computed, but not with an extreme accuracy. 2.2 Numerical Integration over A Finite Interval L direct and L (i; j) can be approximated by many numerical methods [5, 17], which fall into four categories: traditional quadrature, Monte Carlo methods <ref> [37, 9, 57] </ref>, weighted Monte Carlo methods [24], and quasi-Monte Carlo methods [71, 62, 19].
Reference: [38] <author> David Kirk and James Arvo. </author> <title> Unbiased sampling techniques for image sysnthesis. </title> <journal> Computer Graphics, </journal> <volume> 25(4) </volume> <pages> 153-156, </pages> <month> July </month> <year> 1991. </year> <booktitle> ACM Siggraph '91 Conference Proceedings. </booktitle>
Reference-contexts: Weighted Monte Carlo methods assign samples before constructing the partition and computing the weights. 17 2.2.2 Monte Carlo Methods Monte Carlo methods represent an integral as a statistical expected value, which is then approximated by an average <ref> [33, 57, 38, 89] </ref>: Z f (x)d (x) = 8x2S p (x) = E [ p (X) N i=1 p (x i ) where X is a random variable having a probability density function p (x) (denoted X ~ p), i.e. p (x) &gt; 0 when f (x) 6= 0, and <p> Adaptive supersampling methods can be with subdivision, which places extra samples only in regions with high variance [84, 36, 54, 23, 24], or without subdivision, which evenly distributes extra samples over the pixel <ref> [43, 18, 55, 35, 44, 38] </ref>. In subdivision supersampling, if the variation of the estimates in a region is over a predefined threshold, the region is further sampled. Subdivision supersampling methods are effective if the initial samples can reliably detect regions that require extra sampling.
Reference: [39] <author> A. Kok and F. Jansen. </author> <title> Source selection for the direct lighting calculation in global illumination. </title> <booktitle> In Proceedings of the Second Eurographics Workshop on Rendering, </booktitle> <year> 1991. </year>
Reference-contexts: The straightforward summation gives a valid result [15, 14], but it requires consulting all luminaires, including those dim and far away. It can be time consuming when the number of luminaires is over a few tens. Culling methods <ref> [39, 78, 81] </ref>, consult all luminaires, although they calculate contributions only from dominant luminaires. Unlike culling methods, the Monte Carlo methods in Chapter 4 will give an unbiased estimate and has a lower time complexity than current culling methods [65, 60, 61]. <p> Predicting the importance of a luminaire in a non--diffuse environment can be complicated because it should account for the luminaire intensity, reflectance of the illuminated surface, solid angle of the luminaire, and the visibility <ref> [39] </ref>. In this chapter we formalize an approach of designating important/unimportant luminaires, and present three specific methods that follow this approach [65, 66, 77]. <p> Coarse estimation of the less important group is sufficient because this group has little to contribute and the estimation error it can introduce is limited. 62 To decide which luminaires are important for a particular x is a difficult task. As pointed out by Kok and Jansen <ref> [39] </ref>, a luminaire that is more important to the color of x than most other luminaires is likely to be more important to the neighboring points of x. <p> No matter how many patches define a light bulb surface, it will receive only one shadow ray. The objects which have strong reflected light are suggested to be incorporated with luminaires into direct lighting computation because they can also cause sharp radiance change on other objects <ref> [39, 6] </ref>. The implementation is generally achieved by first categorizing bright emitting luminaires and reflected objects as light sources, after the zonal methods has computed indirect lighting. Then in the viewing phase, the direct lighting from the 71 light sources are computed.
Reference: [40] <author> Edwin H. Land. </author> <title> The retinex theory of color vision. </title> <journal> (The) Scientific American, </journal> (12):108-128, December 1977. <volume> 119 </volume>
Reference-contexts: Yet, to decide the accuracy of an imposter is more complicated than computing the color difference, because human visual system does not see the absolute radiance <ref> [40, 7] </ref>. Furthermore, since images are not compared side-by-side, the "accuracy" of an imposter depends on how humans interpret the visual cues to verify the validity of an image.
Reference: [41] <author> Brigitta Lange. </author> <title> The simulation of radiant light transfer with stochastic ray-tracing. </title> <booktitle> In Proceedings of the Second Eurographics Workshop on Rendering, </booktitle> <year> 1991. </year>
Reference-contexts: direct lighting from each Mip map cell for a TV screen. 3.2 Sampling Strategies for Non-diffuse Environments If f r (x; ; 0 ) is the only dominant term in f r (x; ; 0 )E (x 0 ; 0 ) cos and it is represented by a Phong BRDF <ref> [41, 66] </ref> or a Gaussian Model [78], then an effective p ( 0 ) ~ f r (x; ; 0 ) can be derived. If only one term dominates each time, the weighted quasi-Monte Carlo methods in Section 2.2.3 can choose samples from each term in its local coordinate system. <p> In the remaining sections, we examine three different strategies for constructing a p.d.f. 4.2 Constant Method The simplest p.d.f. is the constant one, with p i = 1 for all i 2 [0; N ] <ref> [41] </ref>. Since this method is both simple and fast, it is useful for debugging and testing, but its high variance requires too many samples for rendering a realistic scene.
Reference: [42] <author> Eric Languenou and Pierre Tellier. </author> <title> Including physical light sources and daylight in a global illumination model. </title> <journal> Computer Graphics Forum, </journal> <note> 1992. Eurographics '92. </note>
Reference-contexts: However, this approach requires an extremely fine mesh size to capture rapid radiance changes caused by shadowing, projected solid angle of the luminaire, the intensity distribution of the luminaire, and reflectivity. The second method discretizes the luminaire into point luminaires at specific positions <ref> [42] </ref>, but unfortunately the regularity of luminaire positions might cause aliasing artifacts. The third method first calculates the visible boundary and then uses the exact formula of L direct from a perfectly 22 diffuse polygonal luminaire [51].
Reference: [43] <author> Mark E. Lee, Richard A. Redner, and Samuel P. Uselton. </author> <title> Statistically optimized sampling for distributed ray tracing. </title> <journal> Computer Graphics, </journal> <volume> 19(3) </volume> <pages> 61-68, </pages> <month> July </month> <year> 1985. </year> <booktitle> ACM Siggraph '85 Conference Proceedings. </booktitle>
Reference-contexts: Although adaptive supersampling, which uses more than one sample within a pixel for antialiasing, has often been proposed, the prediction of the number of samples needed is still a challenging topic. Methods based on criteria from statistics <ref> [43] </ref>, signal processing [18], or perceptual models [44] have been suggested, but the justification of the criteria involves the not fully understood relationship between the estimation error of the pixel color, the display algorithm, and the human perceptual system. <p> Adaptive supersampling methods can be with subdivision, which places extra samples only in regions with high variance [84, 36, 54, 23, 24], or without subdivision, which evenly distributes extra samples over the pixel <ref> [43, 18, 55, 35, 44, 38] </ref>. In subdivision supersampling, if the variation of the estimates in a region is over a predefined threshold, the region is further sampled. Subdivision supersampling methods are effective if the initial samples can reliably detect regions that require extra sampling. <p> All the existing methods are based on contrast or on the pixel complexity such as variance or the absolute estimation error <ref> [43, 55, 18, 44] </ref>. In this section, we discuss the existing non-adaptive supersampling methods and their weaknesses, and then present a supersampling framework which can take all these factors into account. 5.3.1 Existing Adaptive Supersampling Methods Statistical methods have been used to control adaptive supersampling. <p> Let s 2 1 n X (x i L) 2 . Then the Chi-square test <ref> [43] </ref>: p ( n fi (n 1)) = fi can be used to predict N , the number of samples needed in supersampling, from n initial samples. Similarly, the t-test [55] is suggested to compute N . However, applying these statistical tests to supersampling has two weaknesses. <p> In this framework, there are many missing elements that require further research. We present here a new supersampling method based on our partial understanding of the missing 97 elements. 1. The number of initial samples in existing supersampling methods assume 4 to 9 samples without justification <ref> [43, 36, 44, 23] </ref>. Instead, we assume that the initial samples are expected to detect the case of two features fully occupying a pixel when the projected area of either feature on the pixel is larger than 5% of the pixel size.
Reference: [44] <author> Don P. Mitchell. </author> <title> Generating antialiased images at low sampling densities. </title> <journal> Computer Graphics, </journal> <volume> 21(4) </volume> <pages> 65-72, </pages> <month> July </month> <year> 1987. </year> <booktitle> ACM Siggraph '87 Conference Proceedings. </booktitle>
Reference-contexts: Sample point generation is a key issue in Monte Carlo methods, and is addressed in Chapter 5. Traditional Monte Carlo methods with random samples are inefficient because the samples are not evenly distributed 5 within the domain. Quasi-Monte Carlo methods with quasi-random samples are usually used <ref> [15, 14, 62, 60, 44] </ref>. Commonly used quasi-random samples include jittered samples, Poisson disk samples, and N-rooks samples. <p> Although adaptive supersampling, which uses more than one sample within a pixel for antialiasing, has often been proposed, the prediction of the number of samples needed is still a challenging topic. Methods based on criteria from statistics [43], signal processing [18], or perceptual models <ref> [44] </ref> have been suggested, but the justification of the criteria involves the not fully understood relationship between the estimation error of the pixel color, the display algorithm, and the human perceptual system. Without incorporating this missing information, all the proposed methods are limited in one way or the other. <p> Right: defining each Voronoi cell by the perpendicular lines related to the sample. 2.2.4 Quasi-Monte Carlo Methods Quasi-Monte Carlo methods are Monte Carlo methods with quasi-random samples, which have some, but not all, properties of random samples <ref> [62, 44, 47, 45] </ref>. Number theory has been used to study quasi-Monte Carlo methods for many years, and has yielded some interesting results. <p> which have low discrepancy values, but to arrange these patterns in order to decrease the number of patterns required rely on further research. 5.2.2 Previous Methods in Rectangular Domains Sampling methods for square or rectangular domains, e.g. a pixel or a rectangular luminaire, have been heavily studied in computer graphics <ref> [15, 44, 60, 8] </ref>. The most widely used strategies are random sampling, regular sampling, jittered sampling, Poisson disk sampling and N-rooks sampling as illustrated in Figure 5.2. 81 N-rooks samples with 4 samples. The random sampling method randomly chooses a sample within the domain. <p> Adaptive supersampling methods can be with subdivision, which places extra samples only in regions with high variance [84, 36, 54, 23, 24], or without subdivision, which evenly distributes extra samples over the pixel <ref> [43, 18, 55, 35, 44, 38] </ref>. In subdivision supersampling, if the variation of the estimates in a region is over a predefined threshold, the region is further sampled. Subdivision supersampling methods are effective if the initial samples can reliably detect regions that require extra sampling. <p> All the existing methods are based on contrast or on the pixel complexity such as variance or the absolute estimation error <ref> [43, 55, 18, 44] </ref>. In this section, we discuss the existing non-adaptive supersampling methods and their weaknesses, and then present a supersampling framework which can take all these factors into account. 5.3.1 Existing Adaptive Supersampling Methods Statistical methods have been used to control adaptive supersampling. <p> One common form of luminance contrast, L max L min , where L max and L min are the maximum and minimum radiance respectively [35], is suggested to predict the number of samples, i.e. the number of samples taken is proportional to the contrast <ref> [44] </ref>. This method is plausible because it considers the nonlinear response of human perception; but it still has some weaknesses. <p> In this framework, there are many missing elements that require further research. We present here a new supersampling method based on our partial understanding of the missing 97 elements. 1. The number of initial samples in existing supersampling methods assume 4 to 9 samples without justification <ref> [43, 36, 44, 23] </ref>. Instead, we assume that the initial samples are expected to detect the case of two features fully occupying a pixel when the projected area of either feature on the pixel is larger than 5% of the pixel size.
Reference: [45] <author> Don P. Mitchell. </author> <title> Spectrally optimal sampling for distribution ray tracing. </title> <journal> Computer Graphics, </journal> <volume> 25(4), </volume> <month> July </month> <year> 1991. </year> <booktitle> ACM Siggraph '91 Conference Proceedings. </booktitle>
Reference-contexts: Right: defining each Voronoi cell by the perpendicular lines related to the sample. 2.2.4 Quasi-Monte Carlo Methods Quasi-Monte Carlo methods are Monte Carlo methods with quasi-random samples, which have some, but not all, properties of random samples <ref> [62, 44, 47, 45] </ref>. Number theory has been used to study quasi-Monte Carlo methods for many years, and has yielded some interesting results. <p> Mitchell uses a jittered pattern on P ixel and 87 then sequentially assign a time sample to each pixel sample such that the new time sample has (nearly) the maximum distance to all the existing time samples <ref> [45] </ref>. Note these two methods only guarantee equidistribution on P ixel and on T ime. In 3D, full multi-jittered samples would be jittered in 3D and projections in XY , Y Z, XZ, X, Y , Z would also be jittered. <p> Traditionally, samples in different domains, P ixel, Lens, T ime, and Direction, are chosen independently, but this approach does not guarantee that samples are equidistributed in any lower dimensional projection of the domain <ref> [14, 45] </ref>. boundary perpendicular to X relies on the sample equidistribution on X; case 2 shows that the effectiveness in detecting a feature boundary parallel to X relies on the sample equidistribution on Y ; and case 3 shows that effectiveness in detecting a feature boundary parallel to the diagonal relies
Reference: [46] <author> Don P. Mitchell. </author> <title> Ray tracing and irregularities of distribution. </title> <booktitle> In Proceedings of Third Eurographics Workshop on Rendering, </booktitle> <pages> pages 61-69, </pages> <year> 1992. </year>
Reference-contexts: The term j n xyj is called the local discrepancy at (x; y). The discrepancy, which is within [0; 1], becomes smaller as the samples are more equidistributed. The axis-aligned rectangle in local discrepancy test has been extended to disks <ref> [46] </ref> and random-edges [19] in an effort to make discrepancy more valuable for graphics application. The local discrepancy in random-edge discrepancy is the difference between the area of a unit square above a random line and the fraction of sample points above the same line. <p> However, the discrepancy might still be helpful in predicting the convergence behavior from a sample pattern [62]. Discrepancy gives an objective measure of the ability of a sample set to calculate images with features similar to rectangles. This gives motivation for Mitchell's introduction of edge based discrepancy <ref> [46] </ref>. 5.2 Sampling Methods A sampling method should generate samples that estimate an integral with as small an error as possible. <p> For example, if a pixel has only two constant colors, then X has a binomial distribution, which can be very different from normal distribution when n is small, say less than 30 [33]. The other weakness is that the quasi-random samples behave differently from random samples <ref> [46] </ref>, and the validity of using the same formulas is questionable. Signal processing suggests that jX E [X]j / fi, where fi is the sampling rate, which changes with the number of samples as well as the sampling methods [18]. <p> If the boundary is an edge, then to successfully detect both features means the samples must fall on both sides of an random edge. This can be done by slightly modifying Mitchell's method for random edge discrepancy <ref> [46] </ref>. Instead of counting the number of samples below a line, we examine if all samples are below a line. Experiments show that to achieve 93% or 99% successful rate, we need at least 9 multi-jittered samples or 16 multi-jittered samples, respectively. 2. <p> If the sampling strategy has O (N d ) accuracy, then N = n ( n ) d . Random sampling has O (N 1 2 ) <ref> [46] </ref>; other quasi-random samples which converge faster are likely to have d smaller than 0:5. 5.4 Summary In this chapter, we emphasize the importance of equidistribution across projections of subdomain and derived new multi-jittered sampling methods which have the lowest discrepancy and the highest stability among the commonly used stochastic sampling <p> One of the major purposes of initial samples is feature detection. In this document we assume that pixel has two features and the features are divided by a random edge. With slight modification of Mitchell's method for computing random edge discrepancy <ref> [46] </ref>, we are able to numerically justify that approximately 10 multi-jittered samples are sufficient to detect both features if their projected areas are not smaller than 5% of the pixel area.
Reference: [47] <author> Don P. Mitchell and Arun N. Netravali. </author> <title> Reconstruction filters in computer graphics. </title> <journal> Computer Graphics, </journal> <volume> 22(4) </volume> <pages> 221-228, </pages> <month> August </month> <year> 1988. </year> <booktitle> ACM Siggraph '88 Conference Proceedings. </booktitle>
Reference-contexts: Right: defining each Voronoi cell by the perpendicular lines related to the sample. 2.2.4 Quasi-Monte Carlo Methods Quasi-Monte Carlo methods are Monte Carlo methods with quasi-random samples, which have some, but not all, properties of random samples <ref> [62, 44, 47, 45] </ref>. Number theory has been used to study quasi-Monte Carlo methods for many years, and has yielded some interesting results.
Reference: [48] <author> Earl N. Mitchell. </author> <title> Photographic Science. </title> <publisher> John Wiley and Sons, </publisher> <year> 1984. </year>
Reference-contexts: In this document, a luminaire doesn't include the sur rounding fixtures. 2 extremely important visual cue in a realistic image <ref> [48] </ref>. Global illumination [84, 15, 25, 51], on the other hand, accounts for interreflection among objects. Not surprisingly, global illumination takes much more computation time than local illumination.
Reference: [49] <author> Karl Dieter Moller. </author> <title> Optics. </title> <publisher> University Science Books, </publisher> <address> Mill Valley, Calif, </address> <year> 1988. </year> <month> 120 </month>
Reference-contexts: The rendering equation represents only geometric optics and does not consider the light's properties in terms of the electromagnetic waves <ref> [30, 49] </ref>. This simplification ignores the effects of polarization, interference, and diffraction; but this is a minor limitation for most applications since these phenomena are not very noticeable in most scenes. The rendering equations in Equation 2.1 and Equation 2.2 show the radiance toward one direction only. <p> This is not physically correct because the color dispersion 1 <ref> [30, 49] </ref> is not simulated, but this is not a severe limitation for most applications.
Reference: [50] <author> Harald Niederreiter. </author> <title> Quasi-monte carlo methods and pseudo-random numbers. </title> <journal> Bulletin of the American Mathematical Society, </journal> <volume> 84(4) </volume> <pages> 957-1029, </pages> <month> November </month> <year> 1978. </year>
Reference-contexts: However it is currently difficult to predict the behavior of quasi-random samples. Although mathematicians have studied quasi-random samples and related them to equidistribution and its measure <ref> [1, 28, 71, 83, 50, 4] </ref> the application of these mathematical results in computer graphics is still limited. In this chapter, we also generalize the idea of equidistribution and propose a new multi-jittered sampling method [7], whose samples are equidistributed in any sub-domain.
Reference: [51] <author> Tomoyuki Nishita and Eihachiro Nakamae. </author> <title> Continuous tone representation of three-dimensional objects taking account of shadows and interreflection. </title> <journal> Computer Graphics, </journal> <volume> 19(3) </volume> <pages> 23-30, </pages> <month> July </month> <year> 1985. </year> <booktitle> ACM Siggraph '85 Conference Proceedings. </booktitle>
Reference-contexts: In this document, a luminaire doesn't include the sur rounding fixtures. 2 extremely important visual cue in a realistic image [48]. Global illumination <ref> [84, 15, 25, 51] </ref>, on the other hand, accounts for interreflection among objects. Not surprisingly, global illumination takes much more computation time than local illumination. One major speed up strategy for global illumination is to treat direct lighting and indirect lighting 3 differently [51, 36, 82, 60, 58]. <p> Global illumination [84, 15, 25, 51], on the other hand, accounts for interreflection among objects. Not surprisingly, global illumination takes much more computation time than local illumination. One major speed up strategy for global illumination is to treat direct lighting and indirect lighting 3 differently <ref> [51, 36, 82, 60, 58] </ref>. In general, the direct lighting can cause rapid shading change and is simulated by ray tracing [84, 23], which starts from the eye or the camera film and reversely traces photons back to the luminaire as shown in Figure 1.2. <p> The second method discretizes the luminaire into point luminaires at specific positions [42], but unfortunately the regularity of luminaire positions might cause aliasing artifacts. The third method first calculates the visible boundary and then uses the exact formula of L direct from a perfectly 22 diffuse polygonal luminaire <ref> [51] </ref>. The limitation of this method is that only polygonal or polyhedral objects are allowed in the environment. The fourth method is to divide the (rectangular) luminaire into quadtree cells of various sizes, and estimate L direct from each piece of the luminaire by Monte Carlo methods [81]. <p> Case 4 : p 4 (x 0 ) = cos cos 0 p total p total is the sum of the p total from T 1 ,: : :,T n as discussed in Section 3.1.3. A better way to compute p total is in <ref> [51, 3] </ref>.
Reference: [52] <author> James L. Nuckolls. </author> <title> Interior Lighting for Environmental Designers. </title> <publisher> Wiley-interscience, </publisher> <address> New York, </address> <note> second edition, </note> <year> 1983. </year>
Reference-contexts: In this section, we present several examples of imposters, paying special attention to imposter objects for luminaires. A luminaire is often specified by its shape and luminous intensity (which defines the luminous flux per unit solid angle as explained in Appendix A) <ref> [52, 35, 32] </ref>. The luminous 48 intensity of a luminaire can be represented as a polar graph (luminous intensity distribution curve), which shows a typical distribution curve of a point on the luminaire at a particular plane, in Figure 3.11.
Reference: [53] <editor> Commission Internationale De L'Eclairage International Commission on Illumination Internationale Beleuchtungskommission. </editor> <title> Standardization of luminance distribution on clear skies, 1973. </title> <journal> C.I.E. </journal> <volume> No, 22 (TC-4.2.). </volume>
Reference-contexts: Similarly, a clear sky dome, with maximum radiance contrast over 30 <ref> [53] </ref>, should not be simulated as a luminaire with constant radiance.
Reference: [54] <author> James Painter and Kenneth Sloan. </author> <title> Antialiased ray tracing by adaptive progressive refinement. </title> <journal> Computer Graphics, </journal> <volume> 23(3) </volume> <pages> 281-288, </pages> <month> July </month> <year> 1989. </year> <booktitle> ACM Siggraph '89 Conference Proceedings. </booktitle>
Reference-contexts: Adaptive supersampling methods can be with subdivision, which places extra samples only in regions with high variance <ref> [84, 36, 54, 23, 24] </ref>, or without subdivision, which evenly distributes extra samples over the pixel [43, 18, 55, 35, 44, 38]. In subdivision supersampling, if the variation of the estimates in a region is over a predefined threshold, the region is further sampled.
Reference: [55] <author> Werner Purgathofer. </author> <title> A statistical method for adaptive stochastic sampling. </title> <journal> Computer Graphics forum, </journal> <note> 1986. Eurographics '92, Also appears in Computers & Graphics, </note> <year> 1987, </year> <journal> Vol.11, </journal> <volume> Number 2, </volume> <pages> 157-162. </pages>
Reference-contexts: Adaptive supersampling methods can be with subdivision, which places extra samples only in regions with high variance [84, 36, 54, 23, 24], or without subdivision, which evenly distributes extra samples over the pixel <ref> [43, 18, 55, 35, 44, 38] </ref>. In subdivision supersampling, if the variation of the estimates in a region is over a predefined threshold, the region is further sampled. Subdivision supersampling methods are effective if the initial samples can reliably detect regions that require extra sampling. <p> All the existing methods are based on contrast or on the pixel complexity such as variance or the absolute estimation error <ref> [43, 55, 18, 44] </ref>. In this section, we discuss the existing non-adaptive supersampling methods and their weaknesses, and then present a supersampling framework which can take all these factors into account. 5.3.1 Existing Adaptive Supersampling Methods Statistical methods have been used to control adaptive supersampling. <p> Let s 2 1 n X (x i L) 2 . Then the Chi-square test [43]: p ( n fi (n 1)) = fi can be used to predict N , the number of samples needed in supersampling, from n initial samples. Similarly, the t-test <ref> [55] </ref> is suggested to compute N . However, applying these statistical tests to supersampling has two weaknesses. The first weakness is that the fundamental assumption of a normal distribution of sample values is questionable.
Reference: [56] <author> Jon Rokne. </author> <title> The area of a simple polygon. </title> <editor> In James Arvo, editor, </editor> <title> Graphics Gems 2. </title> <publisher> Academic Press, </publisher> <address> New York, NY, </address> <year> 1991. </year>
Reference-contexts: projected onto XY plane, then A 0 = 2 n X x i y (i+1 mod i) i=1 y i x (i+1 mod i) ), where (x i ; y i ), i + 1; : : : ; n is the counter clockwise enumeration of the vertices of P <ref> [56] </ref>.
Reference: [57] <author> Reuven Y. Rubinstein. </author> <title> Simulation and the Monte Carlo method. </title> <publisher> New York : Wiley, </publisher> <year> 1981. </year>
Reference-contexts: so there is some indication that the indirect lighting should be computed, but not with an extreme accuracy. 2.2 Numerical Integration over A Finite Interval L direct and L (i; j) can be approximated by many numerical methods [5, 17], which fall into four categories: traditional quadrature, Monte Carlo methods <ref> [37, 9, 57] </ref>, weighted Monte Carlo methods [24], and quasi-Monte Carlo methods [71, 62, 19]. <p> Weighted Monte Carlo methods assign samples before constructing the partition and computing the weights. 17 2.2.2 Monte Carlo Methods Monte Carlo methods represent an integral as a statistical expected value, which is then approximated by an average <ref> [33, 57, 38, 89] </ref>: Z f (x)d (x) = 8x2S p (x) = E [ p (X) N i=1 p (x i ) where X is a random variable having a probability density function p (x) (denoted X ~ p), i.e. p (x) &gt; 0 when f (x) 6= 0, and <p> Monte Carlo methods involve two steps <ref> [57] </ref>. The first step is the choice of a valid p (x). In general, the more similar p (x) is to f (x), the smaller the error is [60].
Reference: [58] <author> Holly Rushmeimer, Charles Patterson, and Aravindan Veerasamy. </author> <title> Geometric simplifi-cation for indirect illumination calculations. Graphics Interface, </title> <year> 1993. </year>
Reference-contexts: Global illumination [84, 15, 25, 51], on the other hand, accounts for interreflection among objects. Not surprisingly, global illumination takes much more computation time than local illumination. One major speed up strategy for global illumination is to treat direct lighting and indirect lighting 3 differently <ref> [51, 36, 82, 60, 58] </ref>. In general, the direct lighting can cause rapid shading change and is simulated by ray tracing [84, 23], which starts from the eye or the camera film and reversely traces photons back to the luminaire as shown in Figure 1.2. <p> In our implementation, distribution ray tracing is used for the direct lighting computation and the geometric simplification method of Rushmeier et al. <ref> [58] </ref> is used for the indirect lighting computation. Rushmeier's method is a modified zonal method which stores the radiant intensity at a resolution lower than the resolution of the objects/surfaces. This reduces the memory requirements as well as the calculation time for energy exchange. <p> Common zonal methods require storage of the energy information on each element. This is overkill in a complex environment because most objects have little contribution to the image and do not need high accuracy. In our implementation, the indirect lighting is computed by geometry simplification <ref> [58] </ref>, where the energy is distributed over a coarsely tessellated environment. After the reflected energy of every element is calculated in the zonal phase, we treat the tessellated environment as luminaires with zero reflectivity. <p> Although having the full solution for indirect lighting is commonly thought of as the ultimate goal, there are reasons to believe that full solution might be an overkill. One reason is that a fast but coarse approximation can produce an image without a significant degradation of quality <ref> [58] </ref>. The other reasons relate to the non-linear transformation of a real-world image to a screen image which only allows a small intensity range [73, 7]. <p> Figure 3.12 replaces a luminaire with two emitting cylinders and fixtures by a rectangular luminaire imposter in the lighting computation. In the geometry simplification method suggested by Rushmeimer et al. <ref> [58] </ref>, groups of objects are replaced by a box. The luminaire imposter helps speed up the lighting calculation, but the luminaire displayed in the image must be in its original representation. <p> To fix this, we ask the shadow ray to see the true luminaire when an object is close to the luminaire. This is similar to Rushmeier's strategy of not using the simple environment inside a threshold radius <ref> [58] </ref>. This method can be generalized to incorporate multiple representation for an object. For example, the hierarchy suggested for a TV screen or the sky in Section 3.1.7.
Reference: [59] <author> Peter Shirley. </author> <type> Personal Communication. </type>
Reference-contexts: A similar example is a luminaire imposter for a lamp with built-in knowledge of its surrounding lamp shade as in <ref> [59] </ref>.
Reference: [60] <author> Peter Shirley. </author> <title> Physically Based Lighting Calculations for Computer Graphics. </title> <type> PhD thesis, </type> <institution> University of Illinois at Urbana-Champaign, </institution> <month> November </month> <year> 1990. </year>
Reference-contexts: Global illumination [84, 15, 25, 51], on the other hand, accounts for interreflection among objects. Not surprisingly, global illumination takes much more computation time than local illumination. One major speed up strategy for global illumination is to treat direct lighting and indirect lighting 3 differently <ref> [51, 36, 82, 60, 58] </ref>. In general, the direct lighting can cause rapid shading change and is simulated by ray tracing [84, 23], which starts from the eye or the camera film and reversely traces photons back to the luminaire as shown in Figure 1.2. <p> Culling methods [39, 78, 81], consult all luminaires, although they calculate contributions only from dominant luminaires. Unlike culling methods, the Monte Carlo methods in Chapter 4 will give an unbiased estimate and has a lower time complexity than current culling methods <ref> [65, 60, 61] </ref>. Sample point generation is a key issue in Monte Carlo methods, and is addressed in Chapter 5. Traditional Monte Carlo methods with random samples are inefficient because the samples are not evenly distributed 5 within the domain. <p> Sample point generation is a key issue in Monte Carlo methods, and is addressed in Chapter 5. Traditional Monte Carlo methods with random samples are inefficient because the samples are not evenly distributed 5 within the domain. Quasi-Monte Carlo methods with quasi-random samples are usually used <ref> [15, 14, 62, 60, 44] </ref>. Commonly used quasi-random samples include jittered samples, Poisson disk samples, and N-rooks samples. <p> Both transformations decrease the accuracy of the real-world image and can make the smooth transition of radiance from 15 L indirect even less noticeable. If the full solution for indirect lighting is not necessary, the ambient light 2 might be sufficient to give a reasonable approximation <ref> [10, 60] </ref>. To make the ambient light a good approximation of indirect lighting, we still need to consult the lighting condition and the environment. <p> Monte Carlo methods involve two steps [57]. The first step is the choice of a valid p (x). In general, the more similar p (x) is to f (x), the smaller the error is <ref> [60] </ref>. If p (x) / f (x), then Z f (x)d (x) = p (x i ) for any x i such that f (x i ) &gt; 0. <p> which have low discrepancy values, but to arrange these patterns in order to decrease the number of patterns required rely on further research. 5.2.2 Previous Methods in Rectangular Domains Sampling methods for square or rectangular domains, e.g. a pixel or a rectangular luminaire, have been heavily studied in computer graphics <ref> [15, 44, 60, 8] </ref>. The most widely used strategies are random sampling, regular sampling, jittered sampling, Poisson disk sampling and N-rooks sampling as illustrated in Figure 5.2. 81 N-rooks samples with 4 samples. The random sampling method randomly chooses a sample within the domain.
Reference: [61] <author> Peter Shirley. </author> <title> A ray tracing algorithm for global illumination. </title> <booktitle> Graphics Interface '90, </booktitle> <pages> pages 205-212, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: Culling methods [39, 78, 81], consult all luminaires, although they calculate contributions only from dominant luminaires. Unlike culling methods, the Monte Carlo methods in Chapter 4 will give an unbiased estimate and has a lower time complexity than current culling methods <ref> [65, 60, 61] </ref>. Sample point generation is a key issue in Monte Carlo methods, and is addressed in Chapter 5. Traditional Monte Carlo methods with random samples are inefficient because the samples are not evenly distributed 5 within the domain. <p> We call this the linear method since its execution time is linearly proportional to the number of luminaires. This method of setting p i was first used in <ref> [61] </ref>, and was first theoretically justified in [65]. In a diffuse environment, we can estimate L [i] direct by assuming the entire luminaire is visible. <p> This will make p i take the one value that is not allowed: zero. Such a bug will become obvious in pictures of spheres illuminated by luminaires that subtend large solid angles as in Figure 4.2, but in many scenes such errors are not noticeable (the figures in <ref> [61] </ref> had this bug, but it was not noticeable). 61 wrong image with discontinuous shading transition due to p i = 0 when L [i] direct &gt; 0. 4.4 Spatial Subdivision Method In the linear method, choosing a p.d.f. based on estimated contribution requires querying every luminaire in the scene.
Reference: [62] <author> Peter Shirley. </author> <title> Discrepancy as a quality measure for sampling distributions. </title> <booktitle> In Euro-graphics '91, </booktitle> <pages> pages 183-193, </pages> <month> September </month> <year> 1991. </year>
Reference-contexts: Sample point generation is a key issue in Monte Carlo methods, and is addressed in Chapter 5. Traditional Monte Carlo methods with random samples are inefficient because the samples are not evenly distributed 5 within the domain. Quasi-Monte Carlo methods with quasi-random samples are usually used <ref> [15, 14, 62, 60, 44] </ref>. Commonly used quasi-random samples include jittered samples, Poisson disk samples, and N-rooks samples. <p> but not with an extreme accuracy. 2.2 Numerical Integration over A Finite Interval L direct and L (i; j) can be approximated by many numerical methods [5, 17], which fall into four categories: traditional quadrature, Monte Carlo methods [37, 9, 57], weighted Monte Carlo methods [24], and quasi-Monte Carlo methods <ref> [71, 62, 19] </ref>. This classification emphasizes various Monte Carlo methods because their important properties which have made them a practical choice for computer graphics: 2 Ambient light is a simple model which produces constant illumination on all surfaces regardless of their position or orientation. 16 1. <p> Right: defining each Voronoi cell by the perpendicular lines related to the sample. 2.2.4 Quasi-Monte Carlo Methods Quasi-Monte Carlo methods are Monte Carlo methods with quasi-random samples, which have some, but not all, properties of random samples <ref> [62, 44, 47, 45] </ref>. Number theory has been used to study quasi-Monte Carlo methods for many years, and has yielded some interesting results. <p> However, signal processing does not help us predict the absolute quality of estimation to be expected from a given sampling pattern. 5.1.3 Discrepancy Integration theory suggests that the convergence rate from a set of samples is closely related to the discrepancy <ref> [71, 62, 19] </ref>, which is a measure of equidistribution. Ideal equidis-tribution means that the fraction of the samples in each subdomain is equal to the fractional measure of that subdomain. With a finite number of samples, ideal equidistribution is impossible. <p> Theorem 2 cannot be directly applied to predict error in image synthesis because the image function in computer graphics contains edges and thus has unbounded variation V X;Y in Equation 5.2. However, the discrepancy might still be helpful in predicting the convergence behavior from a sample pattern <ref> [62] </ref>. Discrepancy gives an objective measure of the ability of a sample set to calculate images with features similar to rectangles. <p> The Poisson disk samples are designed to avoid clumping, which will improve equidistribution in two dimensions. The N-rooks sampling method randomly associates rows and columns such that each row and each column have exactly one sample <ref> [62] </ref>. The N-rooks samples are evenly distributed in both single dimensions separately. 5.2.3 Multi-jittered Sampling Methods in Rectangular Domains Multi-jittered sampling methods attempt to minimize the discrepancy in every subdo-main.
Reference: [63] <author> Peter Shirley. </author> <title> Radiosity via ray tracing. </title> <editor> In James Arvo, editor, </editor> <title> Graphics Gems 2. </title> <publisher> Academic Press, </publisher> <address> New York, NY, </address> <year> 1991. </year>
Reference-contexts: The indirect lighting in a diffuse environment produces smooth shading variation due to multiple and recursive interactions among objects, and is commonly solved by zonal methods with a discretized environment <ref> [25, 63, 29, 6, 72] </ref> or ray tracing with cached indirect lighting [82] as discussed in Chapter 2. In a scene with specular or transparent objects, the situation gets complicated because indirect lighting can also produce rapid shading variation [31, 6]. <p> In these methods objects are tessellated into elements or patches. Each element of the tessellation is assumed small enough that it can be characterized by one bidirectional reflectance-distribution function f r (x; ; 0 ) <ref> [63, 6, 29, 69, 72] </ref>. Then energy is transported among elements and patches. In the shooting approach, a patch distributes its energy to the visible elements while in the gathering approach, an element collects its energy from all the other patches and elements. <p> Another typical imposter example is to change the physical behavior. For example, non-emitting objects in zonal methods can emit the same amount of light as they would reflect <ref> [25, 63, 29] </ref>. 3.3.2 Imposters with Extra Information In a daytime indoor scene, the dominant luminaire would be the sun (assuming it is visible). Without predetermined knowledge of visibility in the environment, the direct lighting is carried out by sending shadow rays to the sun.
Reference: [64] <author> Peter Shirley. </author> <title> Warping transformations for sampling. </title> <editor> In David Kirk, editor, </editor> <title> Graphics Gems 3. </title> <publisher> Academic Press, </publisher> <address> New York, NY, </address> <year> 1992. </year>
Reference-contexts: An alternative method is to generate equidistributed samples on a unit square, and then stretch the unit square to the desired shape/domain. This is sometimes called warping <ref> [86, 64] </ref> and does not have the drawback of the rejection method. However, a compact cell in the unit square might become a strip and the degree of equidistribution might not be conserved after warping, although new samples may still be uniform.
Reference: [65] <author> Peter Shirley and Changyaw Wang. </author> <title> Direct lighting by monte carlo integration. </title> <booktitle> In Proceedings of the Second Eurographics Workshop on Rendering, </booktitle> <year> 1991. </year>
Reference-contexts: Culling methods [39, 78, 81], consult all luminaires, although they calculate contributions only from dominant luminaires. Unlike culling methods, the Monte Carlo methods in Chapter 4 will give an unbiased estimate and has a lower time complexity than current culling methods <ref> [65, 60, 61] </ref>. Sample point generation is a key issue in Monte Carlo methods, and is addressed in Chapter 5. Traditional Monte Carlo methods with random samples are inefficient because the samples are not evenly distributed 5 within the domain. <p> In this chapter we formalize an approach of designating important/unimportant luminaires, and present three specific methods that follow this approach <ref> [65, 66, 77] </ref>. These methods are aimed not only at efficiently classifying luminaires, but also at efficiently calculating the contribution from each luminaire. 4.1 Monte Carlo Methods for Multiple Luminaires The direct lighting from multiple luminaires is the sum of the direct lighting from each luminaire as in Equation 4.1. <p> We call this the linear method since its execution time is linearly proportional to the number of luminaires. This method of setting p i was first used in [61], and was first theoretically justified in <ref> [65] </ref>. In a diffuse environment, we can estimate L [i] direct by assuming the entire luminaire is visible.
Reference: [66] <author> Peter Shirley and Changyaw Wang. </author> <title> Distribution ray tracing theory and practice. </title> <journal> Computer Graphics forum, 1992. </journal> <volume> Eurographics '92. </volume> <pages> 122 </pages>
Reference-contexts: If an object is perfectly specular like a mirror, one reflected ray is all we need to compute the direct lighting and indirect lighting, and calculating L direct independently is unnecessary. If a surface is not perfectly specular, it is unclear which calculation method converges more rapidly <ref> [66] </ref>. 3.1 Luminaire Sampling Strategies for Diffuse Environment The full integral of L direct can be written in two forms. <p> direct lighting from each Mip map cell for a TV screen. 3.2 Sampling Strategies for Non-diffuse Environments If f r (x; ; 0 ) is the only dominant term in f r (x; ; 0 )E (x 0 ; 0 ) cos and it is represented by a Phong BRDF <ref> [41, 66] </ref> or a Gaussian Model [78], then an effective p ( 0 ) ~ f r (x; ; 0 ) can be derived. If only one term dominates each time, the weighted quasi-Monte Carlo methods in Section 2.2.3 can choose samples from each term in its local coordinate system. <p> However, generally in a non-diffuse environment choosing a p ( 0 ) with fast convergence rate is very difficult because the different local coordinate systems make the combined behavior of f r (x; ; 0 )E (x 0 ; 0 ) cos d! 0 hard to predict <ref> [66] </ref>. 47 3.3 Luminaires and Imposters Due to complexity and efficiency considerations, objects are sometimes modified and often simplified. The simplified object can be thought of as an "imposter". <p> In this chapter we formalize an approach of designating important/unimportant luminaires, and present three specific methods that follow this approach <ref> [65, 66, 77] </ref>. These methods are aimed not only at efficiently classifying luminaires, but also at efficiently calculating the contribution from each luminaire. 4.1 Monte Carlo Methods for Multiple Luminaires The direct lighting from multiple luminaires is the sum of the direct lighting from each luminaire as in Equation 4.1. <p> In a non-diffuse environment, f max is the maximum f r whose direct lighting is computed separatly from indirect lighting <ref> [66] </ref>. of 7381 spheres. In the three images with 7381 luminaires, the light octree was used. As expected, the one sample case has a large variance, and the forty sample case is fairly smooth. Notice that both of the 10 sample cases (with 1 and 7381 luminaires) have visible noise.
Reference: [67] <author> Peter Shirley and Changyaw Wang. </author> <title> Luminaire sampling in distribution ray tracing. </title> <type> Technical Report 343, </type> <institution> Department of Computer Science,Indiana University, </institution> <month> January </month> <year> 1992. </year>
Reference-contexts: The simplified object can be thought of as an "imposter". An example of an imposter is an object with zero reflectivity that is shaped like the original object and emits light in exactly the same distribution and intensity as is reflected from the original non-emitting object <ref> [67] </ref>. This light emitting imposter would be indistinguishable from the original light reflecting object. The application of imposter objects appears frequently in computer graphics as special cases but the use of imposters have not been formally justified.
Reference: [68] <author> Robert Siegel and John R. Howell. </author> <title> Thermal Radiation Heat Transfer. </title> <publisher> McGraw-Hill, </publisher> <address> New York, N.Y., </address> <year> 1981. </year>
Reference-contexts: One way to characterize energy transport is to relate the incident radiance and the outgoing radiance change at a point x on a surface, i.e. dL out / L in , as in radiative heat transfer <ref> [68] </ref>. <p> In this subdivision, the projected solid angle Z cos d! of a luminaire is approximated by the product of the number of elements and , where N is the total number of elements. A different subdivision scheme for cos d! is to apply Nusselt analogy <ref> [68, 11] </ref>, i.e. cos d! equals the projected area of d! on the plane P perpendicular to the normal vector 53 at the illuminated point as shown in Figure 3.13. Note the projected area can never exceed the unit circle.
Reference: [69] <author> Francois Sillion, James Arvo, Stephen Westin, and Donald Greenberg. </author> <title> A global illumination algorithm for general reflection distributions. </title> <journal> Computer Graphics, </journal> <volume> 25(4) </volume> <pages> 187-196, </pages> <month> July </month> <year> 1991. </year> <booktitle> ACM Siggraph '91 Conference Proceedings. </booktitle>
Reference-contexts: In a scene with specular or transparent objects, the situation gets complicated because indirect lighting can also produce rapid shading variation [31, 6]. It is also possible to solve direct and indirect lighting all at once <ref> [69] </ref>. In a natural scene, it is estimated that 80 million polygons are required to give a realistic look [74]. <p> In these methods objects are tessellated into elements or patches. Each element of the tessellation is assumed small enough that it can be characterized by one bidirectional reflectance-distribution function f r (x; ; 0 ) <ref> [63, 6, 29, 69, 72] </ref>. Then energy is transported among elements and patches. In the shooting approach, a patch distributes its energy to the visible elements while in the gathering approach, an element collects its energy from all the other patches and elements. <p> Such scenes are becoming increasingly important. In outdoor scenes, especially in urban settings, scenes with thousands and even hundreds of thousands of luminaires are commonplace. In opera and theater applications, hundreds or thousands of luminaires are typical <ref> [69] </ref>. In infrared scenes, almost all surfaces are luminaires, so something such as the light octree is crucial. These methods also make it easy to use luminaires defined by many polygons or parametric patches.
Reference: [70] <author> Francois Sillion and Claude Puech. </author> <title> A general two-pass method integrating specular and diffuse reflection. </title> <journal> Computer Graphics, </journal> <volume> 23(3) </volume> <pages> 335-344, </pages> <month> July </month> <year> 1989. </year> <booktitle> ACM Siggraph '89 Conference Proceedings. </booktitle>
Reference-contexts: The third integration domain in lighting computation is integrated over cos d!. One special subdivision scheme which can transform this non-intuitive integration domain into a plane is the rectangular grid suggested by Sillion <ref> [70] </ref>. In this subdivision, the projected solid angle Z cos d! of a luminaire is approximated by the product of the number of elements and , where N is the total number of elements.
Reference: [71] <author> S.K.Zaremba, </author> <title> editor. Applications of Number Theory to Numerical Analysis. </title> <publisher> Academic Press, </publisher> <address> New York and London, </address> <year> 1972. </year>
Reference-contexts: However it is currently difficult to predict the behavior of quasi-random samples. Although mathematicians have studied quasi-random samples and related them to equidistribution and its measure <ref> [1, 28, 71, 83, 50, 4] </ref> the application of these mathematical results in computer graphics is still limited. In this chapter, we also generalize the idea of equidistribution and propose a new multi-jittered sampling method [7], whose samples are equidistributed in any sub-domain. <p> but not with an extreme accuracy. 2.2 Numerical Integration over A Finite Interval L direct and L (i; j) can be approximated by many numerical methods [5, 17], which fall into four categories: traditional quadrature, Monte Carlo methods [37, 9, 57], weighted Monte Carlo methods [24], and quasi-Monte Carlo methods <ref> [71, 62, 19] </ref>. This classification emphasizes various Monte Carlo methods because their important properties which have made them a practical choice for computer graphics: 2 Ambient light is a simple model which produces constant illumination on all surfaces regardless of their position or orientation. 16 1. <p> However, signal processing does not help us predict the absolute quality of estimation to be expected from a given sampling pattern. 5.1.3 Discrepancy Integration theory suggests that the convergence rate from a set of samples is closely related to the discrepancy <ref> [71, 62, 19] </ref>, which is a measure of equidistribution. Ideal equidis-tribution means that the fraction of the samples in each subdomain is equal to the fractional measure of that subdomain. With a finite number of samples, ideal equidistribution is impossible. <p> If all samples have the same weight, then samples are equidistributed if there exist a subdivision such that all i are compact and close to 1 . Otherwise, the samples are not equidistributed. On the unit square, two widely used definitions of discrepancy <ref> [71, 19] </ref> are: 1. L 1 -discrepancy D N = maximum of j n xyj for 8 (x; y) 2 [0; 1] 2 2. <p> The estimation error from a set of samples has been shown to be bounded by a linear combination of the discrepancy and the variation (defined below) of the estimated function <ref> [17, 71, 1] </ref>. This suggests that discrepancy might be used to rate the quality of sample sets.
Reference: [72] <author> Brian E. Smits, James R. Arvo, and David H. Salesin. </author> <title> An importance-driven radiosity algorithm. </title> <journal> Computer Graphics, </journal> <volume> 26(2) </volume> <pages> 273-282, </pages> <month> July </month> <year> 1992. </year> <booktitle> ACM Siggraph '92 Conference Proceedings. </booktitle>
Reference-contexts: The indirect lighting in a diffuse environment produces smooth shading variation due to multiple and recursive interactions among objects, and is commonly solved by zonal methods with a discretized environment <ref> [25, 63, 29, 6, 72] </ref> or ray tracing with cached indirect lighting [82] as discussed in Chapter 2. In a scene with specular or transparent objects, the situation gets complicated because indirect lighting can also produce rapid shading variation [31, 6]. <p> In these methods objects are tessellated into elements or patches. Each element of the tessellation is assumed small enough that it can be characterized by one bidirectional reflectance-distribution function f r (x; ; 0 ) <ref> [63, 6, 29, 69, 72] </ref>. Then energy is transported among elements and patches. In the shooting approach, a patch distributes its energy to the visible elements while in the gathering approach, an element collects its energy from all the other patches and elements.
Reference: [73] <author> Jack Tumblin and Holly Rushmeier. </author> <title> Tone reproduction for realistic computer generated images. </title> <journal> IEEE Computer Graphics and Applications, </journal> <month> November </month> <year> 1993. </year>
Reference-contexts: One reason is that a fast but coarse approximation can produce an image without a significant degradation of quality [58]. The other reasons relate to the non-linear transformation of a real-world image to a screen image which only allows a small intensity range <ref> [73, 7] </ref>. The non-linear transformation of Tumblin and Rushmeier suggests that the full intensity range of the screen image should be a nonlinear function to the actual intensity range of the real-world image, i.e. a real-world image is mapped only to a portion of the intensity range on the screen. <p> We set the radiance threshold to be some fraction of L white 2 . Because our display device has eight bits per channel, we usually make 2 L white should be chosen according to a perceptual viewer model, such as the model implemented by Tum-blin and Rushmeier <ref> [73, 7] </ref>. Such models will become increasingly important as physically based rendering 64 the threshold a few percent of L white . Such a threshold will ensure that any luminaire that can change the pixel color more than a few intensity steps will be included in important group. <p> Render the initial image with n initial samples. 96 3. Transform the initial image into the displayable image for the media of choice. If the media is a CRT, then a good transformation would be an extension combining Tumblin <ref> [73] </ref> and Chiu [7]. 4. Decide the accuracy function S (x; y), where S (i; j) is the accuracy requirement at pixel (i; j).
Reference: [74] <author> Steve Upstill. </author> <title> The RenderMan Companion. </title> <publisher> Addison-Wesley Publishing Company, </publisher> <year> 1990. </year>
Reference-contexts: It is also possible to solve direct and indirect lighting all at once [69]. In a natural scene, it is estimated that 80 million polygons are required to give a realistic look <ref> [74] </ref>. In real examples, Ward used over 3 million surfaces (mostly cones) to generate tens of pine tress over a field of snow [81], and Snyder and Barr used 2 billion objects to generate a scene with hundreds of trees over a grass field [21].
Reference: [75] <author> John R. Wallace, Kells A. Elmquist, and Eric A. Haines. </author> <title> A ray tracing algorithm for progressive radiosity. </title> <journal> Computer Graphics, </journal> <volume> 23(3) </volume> <pages> 335-344, </pages> <month> July </month> <year> 1989. </year> <booktitle> ACM Siggraph '89 Conference Proceedings. </booktitle>
Reference-contexts: It is possible to apply methods other than Monte Carlo methods to estimate L direct . One possible method is to simply combine L direct with L indirect and solve everything via naive zonal methods <ref> [25, 75] </ref>. However, this approach requires an extremely fine mesh size to capture rapid radiance changes caused by shadowing, projected solid angle of the luminaire, the intensity distribution of the luminaire, and reflectivity.
Reference: [76] <author> Changyaw Wang. </author> <title> Physically correct direct lighting for distribution ray tracing. </title> <editor> In David Kirk, editor, </editor> <title> Graphics Gems 3. </title> <publisher> Academic Press, </publisher> <address> New York, NY, </address> <year> 1992. </year>
Reference-contexts: When the luminaire is blocked, it can generate stochastic samples according to the direct lighting contribution from an non-occluded luminaire. The other new p.d.f. has the samples evenly distributed within the solid angle 4 covered by the luminaire <ref> [76] </ref>. The direct lighting from more than one luminaire is the sum of the combined direct lighting. The straightforward summation gives a valid result [15, 14], but it requires consulting all luminaires, including those dim and far away. <p> 3 ( 0 ) = 1 1 p d ) _ is a unit vector from the origin to (1; _ ; _ ) in spherical coordinates. _ = arccos (1 ~ 1 + ~ 1 d 2 r 2 d ) and _ = 2~ 2 as derived in <ref> [76] </ref>. Case 4 : p 4 ( 0 ) = cos p total , where p total = Z cos d! 0 = 0 0 = 0 0 = 0 = N w sin 2 max where max = arcsin r . <p> 36 We have not been able to compute case 3 exactly, so instead the solid angle covered by the triangle luminaire, it is approximated by a triangle whose vertices are the intersections of the unit sphere centered at x and the three lines connecting x and the actual luminaire vertices <ref> [76] </ref>.
Reference: [77] <author> Changyaw Wang and Peter Shirley. </author> <title> Monte carlo techniques for the direct lighting calculation. </title> <journal> ACM Transaction on Computer Graphics, </journal> <note> 1993. (submitted), Also appears in ACM Siggraph '93 Course Notes, Global Illumination. </note>
Reference-contexts: This document focuses on the rendering process. Specifically it covers new sample point generation methods [8], new warping schemes that transform samples to various two dimensional luminaire domains <ref> [77] </ref>, and a complete supersampling framework. Given an accurate scene database, lighting is the key issue in realistic rendering. The earliest lighting simulation used local illumination [21], which only considers the luminaire 2 and the object whose color is being calculated. <p> We will apply four different p.d.f.s to various 4 luminaire geometries. One of the newly proposed p.d.f.s can give the optimal sampling distribution in a diffuse environment if the whole luminaire is unblocked <ref> [77] </ref>. This method gives the analytical solution when the whole luminaire is visible. When the luminaire is blocked, it can generate stochastic samples according to the direct lighting contribution from an non-occluded luminaire. <p> theory and computer graphics may be useful in speeding up the calculation of this approximation. 21 3 Direct Lighting from One Luminaire In this chapter we present four sampling methods which can be used with quasi-Monte Carlo methods to compute direct lighting, L direct in Equation 2.5 or Equation 2.6 <ref> [77] </ref>. It is possible to apply methods other than Monte Carlo methods to estimate L direct . One possible method is to simply combine L direct with L indirect and solve everything via naive zonal methods [25, 75]. <p> In this chapter we formalize an approach of designating important/unimportant luminaires, and present three specific methods that follow this approach <ref> [65, 66, 77] </ref>. These methods are aimed not only at efficiently classifying luminaires, but also at efficiently calculating the contribution from each luminaire. 4.1 Monte Carlo Methods for Multiple Luminaires The direct lighting from multiple luminaires is the sum of the direct lighting from each luminaire as in Equation 4.1.
Reference: [78] <author> Greg Ward. </author> <title> Adaptive shadow testing for ray tracing. </title> <booktitle> In Proceedings of the Second Eurographics Workshop on Rendering, </booktitle> <year> 1991. </year>
Reference-contexts: The straightforward summation gives a valid result [15, 14], but it requires consulting all luminaires, including those dim and far away. It can be time consuming when the number of luminaires is over a few tens. Culling methods <ref> [39, 78, 81] </ref>, consult all luminaires, although they calculate contributions only from dominant luminaires. Unlike culling methods, the Monte Carlo methods in Chapter 4 will give an unbiased estimate and has a lower time complexity than current culling methods [65, 60, 61]. <p> cell for a TV screen. 3.2 Sampling Strategies for Non-diffuse Environments If f r (x; ; 0 ) is the only dominant term in f r (x; ; 0 )E (x 0 ; 0 ) cos and it is represented by a Phong BRDF [41, 66] or a Gaussian Model <ref> [78] </ref>, then an effective p ( 0 ) ~ f r (x; ; 0 ) can be derived. If only one term dominates each time, the weighted quasi-Monte Carlo methods in Section 2.2.3 can choose samples from each term in its local coordinate system. <p> One possible improvement over the straightforward summation is to predict the contribution from each luminaire, then send shadow rays to the dominant luminaires, and finally add together the direct lighting from the dominant luminaires and a guessed direct lighting 57 from the unimportant luminaires <ref> [78] </ref>. Predicting the importance of a luminaire in a non--diffuse environment can be complicated because it should account for the luminaire intensity, reflectance of the illuminated surface, solid angle of the luminaire, and the visibility [39]. <p> If L a L b , luminaire a is much more likely to be chosen. The linear method is similar to a generalized form of Ward's method <ref> [78] </ref>.
Reference: [79] <author> Gregory J. Ward. </author> <type> Personal communication. </type>
Reference-contexts: In an object-oriented design, this is achieved by associating two intersection tests with a luminaire, one for the viewing ray and the other for the shadow ray <ref> [79] </ref>. However, the shading on the fixtures in this approach would be wrong because the imposter can result in noticeable shading difference on nearby objects. To fix this, we ask the shadow ray to see the true luminaire when an object is close to the luminaire.
Reference: [80] <author> Gregory J. Ward. </author> <title> Measuring and modeling anisotropic reflection. </title> <journal> Computer Graphics, </journal> <volume> 26(2) </volume> <pages> 265-272, </pages> <month> July </month> <year> 1992. </year> <booktitle> ACM Siggraph '92 Conference Proceedings. </booktitle>
Reference-contexts: Modification schemes similar to luminaire imposters are widely used in image synthesis, 51 for example objects with simplified reflectance functions and objects stored at multiple levels of resolution <ref> [21, 27, 80] </ref>. Another typical imposter example is to change the physical behavior.
Reference: [81] <author> Gregory J. Ward. </author> <title> The radiance lighting simulation system. </title> <booktitle> Global Illumination, </booktitle> <pages> pages 1-16, </pages> <year> 1992. </year> <note> ACM Siggraph '92 Course Notes. </note>
Reference-contexts: In a natural scene, it is estimated that 80 million polygons are required to give a realistic look [74]. In real examples, Ward used over 3 million surfaces (mostly cones) to generate tens of pine tress over a field of snow <ref> [81] </ref>, and Snyder and Barr used 2 billion objects to generate a scene with hundreds of trees over a grass field [21]. <p> The straightforward summation gives a valid result [15, 14], but it requires consulting all luminaires, including those dim and far away. It can be time consuming when the number of luminaires is over a few tens. Culling methods <ref> [39, 78, 81] </ref>, consult all luminaires, although they calculate contributions only from dominant luminaires. Unlike culling methods, the Monte Carlo methods in Chapter 4 will give an unbiased estimate and has a lower time complexity than current culling methods [65, 60, 61]. <p> The limitation of this method is that only polygonal or polyhedral objects are allowed in the environment. The fourth method is to divide the (rectangular) luminaire into quadtree cells of various sizes, and estimate L direct from each piece of the luminaire by Monte Carlo methods <ref> [81] </ref>. The problem with this approach is that the artificial division may result in more samples than actually needed.
Reference: [82] <author> Gregory J. Ward, Francis M. Rubinstein, and Robert D. </author> <title> Clear. A ray tracing solution for diffuse interreflection. </title> <journal> Computer Graphics, </journal> <volume> 22(4) </volume> <pages> 85-92, </pages> <month> August </month> <year> 1988. </year> <booktitle> ACM Siggraph '88 Conference Proceedings. </booktitle>
Reference-contexts: Global illumination [84, 15, 25, 51], on the other hand, accounts for interreflection among objects. Not surprisingly, global illumination takes much more computation time than local illumination. One major speed up strategy for global illumination is to treat direct lighting and indirect lighting 3 differently <ref> [51, 36, 82, 60, 58] </ref>. In general, the direct lighting can cause rapid shading change and is simulated by ray tracing [84, 23], which starts from the eye or the camera film and reversely traces photons back to the luminaire as shown in Figure 1.2. <p> The indirect lighting in a diffuse environment produces smooth shading variation due to multiple and recursive interactions among objects, and is commonly solved by zonal methods with a discretized environment [25, 63, 29, 6, 72] or ray tracing with cached indirect lighting <ref> [82] </ref> as discussed in Chapter 2. In a scene with specular or transparent objects, the situation gets complicated because indirect lighting can also produce rapid shading variation [31, 6]. It is also possible to solve direct and indirect lighting all at once [69]. <p> If the reflected ray hits an object very close by, the ray is further reflected to avoid error amplification due to the large solid angle covered by the nearby object. Indirect lighting can also be solved by ray tracing as is done by Ward <ref> [82] </ref>, where the radiance values at points in three dimensional space is stored instead of on objects. Existing information is reused if the radiance at a nearby point with similar normal vector is already 14 stored.
Reference: [83] <author> Tony T. Warnock. </author> <title> Low-discrepancy point sets. In S.K.Zaremba, editor, Applications of Number Theory to Numerical Analysis. </title> <publisher> Academic Press, </publisher> <address> New York, NY, </address> <year> 1972. </year> <month> 124 </month>
Reference-contexts: However it is currently difficult to predict the behavior of quasi-random samples. Although mathematicians have studied quasi-random samples and related them to equidistribution and its measure <ref> [1, 28, 71, 83, 50, 4] </ref> the application of these mathematical results in computer graphics is still limited. In this chapter, we also generalize the idea of equidistribution and propose a new multi-jittered sampling method [7], whose samples are equidistributed in any sub-domain. <p> This gives motivation for Mitchell's introduction of edge based discrepancy [46]. 5.2 Sampling Methods A sampling method should generate samples that estimate an integral with as small an error as possible. Sampling methods from integration theory have developed different numerical rules to generate sample sets of extremely low discrepancy <ref> [83, 89, 1] </ref>, but these rules create deterministic sample sets which are prone to aliasing artifacts when used in image synthesis, because each pixel is sampled using the same pattern. On the other hand, methods from computer graphics generate stochastic samples with higher discrepancy. <p> 0 where a n 6= 0, then r (m) = (a 0 mod r) r 1 1 The numerical experiments have shown that the Zaremba-Hammersley sequence has the lowest L 2 -discrepancy T N among many commonly suggested methods from integration theory, including the other two methods in this Section <ref> [83, 89, 1] </ref>. The sample patterns with 9 samples from each of these sampling methods are in Figure 5.1.
Reference: [84] <author> Turner Whitted. </author> <title> An improved illumination model for shaded display. </title> <journal> Communications of the ACM, </journal> <volume> 23(6) </volume> <pages> 343-349, </pages> <month> June </month> <year> 1980. </year>
Reference-contexts: In this document, a luminaire doesn't include the sur rounding fixtures. 2 extremely important visual cue in a realistic image [48]. Global illumination <ref> [84, 15, 25, 51] </ref>, on the other hand, accounts for interreflection among objects. Not surprisingly, global illumination takes much more computation time than local illumination. One major speed up strategy for global illumination is to treat direct lighting and indirect lighting 3 differently [51, 36, 82, 60, 58]. <p> One major speed up strategy for global illumination is to treat direct lighting and indirect lighting 3 differently [51, 36, 82, 60, 58]. In general, the direct lighting can cause rapid shading change and is simulated by ray tracing <ref> [84, 23] </ref>, which starts from the eye or the camera film and reversely traces photons back to the luminaire as shown in Figure 1.2. <p> Adaptive supersampling methods can be with subdivision, which places extra samples only in regions with high variance <ref> [84, 36, 54, 23, 24] </ref>, or without subdivision, which evenly distributes extra samples over the pixel [43, 18, 55, 35, 44, 38]. In subdivision supersampling, if the variation of the estimates in a region is over a predefined threshold, the region is further sampled.
Reference: [85] <author> Lance Willams. </author> <title> Pyramidal parametrics. </title> <journal> Computer Graphics, </journal> <volume> 17(3), </volume> <month> July </month> <year> 1983. </year> <booktitle> ACM Siggraph '83 Conference Proceedings. </booktitle>
Reference-contexts: A better approach is to construct a hierarchy such as a Mip map <ref> [85] </ref> or a summed-area 46 table [16], and use the coarsest representation whenever possible.
Reference: [86] <author> Grorge Wolberg. </author> <title> Digital image warping. </title> <publisher> IEEE Computer Society Press, </publisher> <year> 1990. </year>
Reference-contexts: An alternative method is to generate equidistributed samples on a unit square, and then stretch the unit square to the desired shape/domain. This is sometimes called warping <ref> [86, 64] </ref> and does not have the drawback of the rejection method. However, a compact cell in the unit square might become a strip and the degree of equidistribution might not be conserved after warping, although new samples may still be uniform.
Reference: [87] <author> Stephen Wolfram. </author> <title> Mathematica. </title> <publisher> Addison-Wesley Publishing Company, Inc., </publisher> <year> 1991. </year>
Reference-contexts: So, it is plausible to accelerate the direct lighting computation by replacing the real luminaires by simplified ones (imposters). Note that the viewing ray should still see the complicated luminaire. The most complicated integrals in Section 3.1.2 and Section 3.1.3 were solved using the symbolic algebra package Mathematica <ref> [87] </ref>. We also tried to apply the same sampling strategy in case 3 and case 4 to other types of luminaires, but the integrals were too difficult for Mathematica, so we have chosen approximation schemes.
Reference: [88] <author> Gunter Wyszecki and W.S. Stiles. </author> <title> Color Science : Concepts and Methods, Quantitative Data and Formulae. </title> <publisher> John Wiley and Sons, </publisher> <address> second edition, </address> <year> 1982. </year>
Reference-contexts: To avoid unnecessary confusion, we will follow the definition from American National Standard and Illuminating Engineering Society [35] as shown in Figure A.1, along with some supplementary information from Wyszecki and Stiles <ref> [88] </ref>. A quantity with a subscript means a spectral concentration, i.e. a quantity corresponding to a narrow wavelength interval. A quantity with a in parentheses means a function of wavelength. The symbols for photometric quantities are the same as those for the corresponding radiometric quantities.
Reference: [89] <author> Daniel Zwillinger. </author> <title> Handbook of Integration. </title> <publisher> Jones and Bartlett, </publisher> <address> Boston, </address> <year> 1992. </year> <month> 125 </month>
Reference-contexts: Weighted Monte Carlo methods assign samples before constructing the partition and computing the weights. 17 2.2.2 Monte Carlo Methods Monte Carlo methods represent an integral as a statistical expected value, which is then approximated by an average <ref> [33, 57, 38, 89] </ref>: Z f (x)d (x) = 8x2S p (x) = E [ p (X) N i=1 p (x i ) where X is a random variable having a probability density function p (x) (denoted X ~ p), i.e. p (x) &gt; 0 when f (x) 6= 0, and <p> This gives motivation for Mitchell's introduction of edge based discrepancy [46]. 5.2 Sampling Methods A sampling method should generate samples that estimate an integral with as small an error as possible. Sampling methods from integration theory have developed different numerical rules to generate sample sets of extremely low discrepancy <ref> [83, 89, 1] </ref>, but these rules create deterministic sample sets which are prone to aliasing artifacts when used in image synthesis, because each pixel is sampled using the same pattern. On the other hand, methods from computer graphics generate stochastic samples with higher discrepancy. <p> 0 where a n 6= 0, then r (m) = (a 0 mod r) r 1 1 The numerical experiments have shown that the Zaremba-Hammersley sequence has the lowest L 2 -discrepancy T N among many commonly suggested methods from integration theory, including the other two methods in this Section <ref> [83, 89, 1] </ref>. The sample patterns with 9 samples from each of these sampling methods are in Figure 5.1.
References-found: 89

