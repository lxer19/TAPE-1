URL: http://www.cs.columbia.edu/~kar/pubsk/mfcubeedbt.ps
Refering-URL: http://www.cs.columbia.edu/~kar/pubsk/pubsk.html
Root-URL: http://www.cs.columbia.edu
Phone: 3  
Title: Complex Aggregation at Multiple Granularities  
Author: Kenneth A. Ross Divesh Srivastava Damianos Chatziantoniou 
Note: 2 AT&T Labs-Research, Florham  
Address: New York, NY 10027, USA  Park, NJ 07932, USA  NJ 07030, USA  
Affiliation: 1 Columbia University,  Stevens Institute of Technology, Hoboken,  
Abstract: Datacube queries compute simple aggregates at multiple gran-ularities. In this paper we examine the more general and useful problem of computing a complex subquery involving multiple dependent aggregates at multiple granularities. We call such queries "multi-feature cubes." An example is "Broken down by all combinations of month and customer, find the fraction of the total sales in 1996 of a particular item due to suppliers supplying within 10% of the minimum price (within the group), showing all subtotals across each dimension." We classify multi-feature cubes based on the extent to which fine granularity results can be used to compute coarse granularity results; this classification includes distributive, algebraic and holistic multi-feature cubes. We provide syntactic sufficient conditions to determine when a multi-feature cube is either distributive or algebraic. This distinction is important because, as we show, existing datacube evaluation algorithms can be used to compute multi-feature cubes that are distributive or algebraic, without any increase in I/O complexity. We evaluate the CPU performance of computing multi-feature cubes using the datacube evaluation algorithm of Ross and Srivastava. Using a variety of synthetic, benchmark and real-world data sets, we demonstrate that the CPU cost of evaluating distributive multi-feature cubes is comparable to that of evaluating simple datacubes. We also show that a variety of holistic multi-feature cubes can be evaluated with a manageable overhead compared to the distributive case.
Abstract-found: 1
Intro-found: 1
Reference: [AAD + 96] <author> S. Agarwal, R. Agrawal, P. M. Deshpande, A. Gupta, J. F. Naughton, R. Ramakrishnan, and S. Sarawagi. </author> <title> On the computation of multidimensional aggregates. </title> <booktitle> In Proceedings of VLDB, </booktitle> <pages> pages 506-521, </pages> <year> 1996. </year>
Reference-contexts: A datacube could be computed by separately computing the aggregate at each granularity. However, it is also possible to compute aggregates at several coarser levels of granularity at the same time as computing aggregates at finer levels of granularity. Such algorithms are presented in <ref> [GBLP96, AAD + 96, ZDN97, RS97] </ref>. A different kind of decision support query has been considered in [CR96], involving aggregation queries in which multiple dependent aggregates are computed within each group. <p> is applicable whenever the conditions of Theorem 5.1 are satisfied has to deal with many grouping variables and tree-structured multi-feature cube graphs, and is given as Incremental-Eval in the full version of the paper [RSC97]. 6.2 Algorithms for Distributive Multi-Feature Cubes Several algorithms have been proposed for computing the datacube <ref> [GBLP96, AAD + 96, ZDN97, RS97] </ref>. The details of these algorithms are not important here. All of these algorithms attempt to compute the datacube by utilizing the lattice structure of the various granularities. Finer granularity results are combined to give results at the next coarser granularity. <p> Since F may be harder to compute than a simple aggregate like SUM, there might be an increase in the CPU cost. We address this concern in detail in Section 7. 6.3 The Holistic Case The algorithms that have been proposed for computing the datacube <ref> [GBLP96, AAD + 96, ZDN97, RS97] </ref> can be divided into two approaches: Algorithms that use main memory essentially for storing the input relation, typically in a partitioned and/or sorted fashion [AAD + 96, RS97]. Datacube tuples are computed, and immediately flushed to output buffers. <p> concern in detail in Section 7. 6.3 The Holistic Case The algorithms that have been proposed for computing the datacube [GBLP96, AAD + 96, ZDN97, RS97] can be divided into two approaches: Algorithms that use main memory essentially for storing the input relation, typically in a partitioned and/or sorted fashion <ref> [AAD + 96, RS97] </ref>. Datacube tuples are computed, and immediately flushed to output buffers. Algorithms that use main memory essentially for storing the (partially com puted) output, typically as a k-dimensional array [GBLP96, ZDN97]. Of these, the algorithms in the first approach are better suited to computing holistic multi-feature cubes.
Reference: [AGS97] <author> R. Agrawal, A. Gupta, and S. Sarawagi. </author> <title> Modeling multidimensional databases. </title> <booktitle> In Proceedings of IEEE ICDE, </booktitle> <year> 1997. </year>
Reference-contexts: This is an important subclass of multi-feature cube queries that is no more difficult to compute than datacube queries, and which includes many sophisticated queries not easily expressed as datacube queries. Other authors have introduced new algebraic operators and/or syntaxes for multidimensional data analysis <ref> [AGS97, LW96] </ref>. However, none of these proposals considers the issue of multiple dependent aggregates within a group. As a result, the specification of most of the examples presented in this paper using their approaches would require multiple views or subqueries, leading to the problems outlined in [CR96].
Reference: [CR96] <author> D. Chatziantoniou and K. A. Ross. </author> <title> Querying multiple features of groups in relational databases. </title> <booktitle> In Proceedings of VLDB, </booktitle> <pages> pages 295-306, </pages> <year> 1996. </year>
Reference-contexts: However, it is also possible to compute aggregates at several coarser levels of granularity at the same time as computing aggregates at finer levels of granularity. Such algorithms are presented in [GBLP96, AAD + 96, ZDN97, RS97]. A different kind of decision support query has been considered in <ref> [CR96] </ref>, involving aggregation queries in which multiple dependent aggregates are computed within each group. An example of such a query is the following: Q0: For each item, find its minimum price in 1996, and the total sales among all minimum price tuples. [CR96] presented an extended SQL syntax that allows a <p> of decision support query has been considered in <ref> [CR96] </ref>, involving aggregation queries in which multiple dependent aggregates are computed within each group. An example of such a query is the following: Q0: For each item, find its minimum price in 1996, and the total sales among all minimum price tuples. [CR96] presented an extended SQL syntax that allows a succinct representation of such queries. An experimental study demonstrated that such queries can be efficiently evaluated. <p> follows: for each subset ~ B of the CUBE BY attributes, the CUBE BY clause is replaced by GROUP BY ~ B, and any attribute in the SELECT clause not in ~ B is replaced by the special constant value ALL. 4 2 2.2 Querying Multiple Features of Groups In <ref> [CR96] </ref>, Chatziantoniou and Ross present an extension of SQL that allows one to query multiple features of groups in relational databases. We refer the reader to [CR96] for the syntax and semantics of such queries, and present an example below to aid intuition. 4 Recall that in standard SQL only attributes <p> the SELECT clause not in ~ B is replaced by the special constant value ALL. 4 2 2.2 Querying Multiple Features of Groups In <ref> [CR96] </ref>, Chatziantoniou and Ross present an extension of SQL that allows one to query multiple features of groups in relational databases. We refer the reader to [CR96] for the syntax and semantics of such queries, and present an example below to aid intuition. 4 Recall that in standard SQL only attributes in the GROUP BY clause, aggregates and constant values can appear in the SELECT clause. <p> Example 2.2: Suppose that we want to ask the following query: for each cus-tomer, for each item, and for each month in 1996, find the total sales among all minimum price suppliers of that item for that month. In the SQL extension of <ref> [CR96] </ref>, one could write this query as: SELECT Customer, Item, Month, SUM (R.Sales) FROM SUPPLIES WHERE Year = 1996 GROUP BY Customer, Item, Month : R SUCH THAT R.Price = MIN (Price) The meaning of this query can be understood as follows. <p> Syntax for Multi-Feature Cube Queries Just as the multi-feature queries of <ref> [CR96] </ref> can be expressed using standard features of SQL such as views and/or subqueries, multi-feature cubes can also be expressed using the datacube and views/subqueries. However, as argued in [CR96], the resulting expressions are both complex and repetitious, leading to queries that are difficult to understand, maintain, and optimize, Thus, we <p> Syntax for Multi-Feature Cube Queries Just as the multi-feature queries of <ref> [CR96] </ref> can be expressed using standard features of SQL such as views and/or subqueries, multi-feature cubes can also be expressed using the datacube and views/subqueries. However, as argued in [CR96], the resulting expressions are both complex and repetitious, leading to queries that are difficult to understand, maintain, and optimize, Thus, we prefer to extend the succinct syntax of [CR96] with the CUBE BY clause of [GBLP96]. 3.1 A Combined Syntax for Multi-Feature Cubes A multi-feature cube query Q has the <p> However, as argued in <ref> [CR96] </ref>, the resulting expressions are both complex and repetitious, leading to queries that are difficult to understand, maintain, and optimize, Thus, we prefer to extend the succinct syntax of [CR96] with the CUBE BY clause of [GBLP96]. 3.1 A Combined Syntax for Multi-Feature Cubes A multi-feature cube query Q has the syntax described in Figure 1. The FROM and the WHERE clauses in the multi-feature cube are identical to the corresponding clauses in the syntactic extensions of [CR96] and [GBLP96], <p> syntax of <ref> [CR96] </ref> with the CUBE BY clause of [GBLP96]. 3.1 A Combined Syntax for Multi-Feature Cubes A multi-feature cube query Q has the syntax described in Figure 1. The FROM and the WHERE clauses in the multi-feature cube are identical to the corresponding clauses in the syntactic extensions of [CR96] and [GBLP96], which are unchanged from standard SQL. The CUBE BY clause in the multi-feature cube combines the CUBE BY clause from [GBLP96] with the specification of grouping variables R 1 ; : : : ; R m of the GROUP BY clause from [CR96]. <p> in the syntactic extensions of <ref> [CR96] </ref> and [GBLP96], which are unchanged from standard SQL. The CUBE BY clause in the multi-feature cube combines the CUBE BY clause from [GBLP96] with the specification of grouping variables R 1 ; : : : ; R m of the GROUP BY clause from [CR96]. The SELECT and the SUCH THAT clauses in the multi-feature cube are identical to the corresponding clauses in the syntactic extension of [CR96]. <p> the CUBE BY clause from [GBLP96] with the specification of grouping variables R 1 ; : : : ; R m of the GROUP BY clause from <ref> [CR96] </ref>. The SELECT and the SUCH THAT clauses in the multi-feature cube are identical to the corresponding clauses in the syntactic extension of [CR96]. <p> This computation can be performed using the techniques suggested in <ref> [CR96] </ref>. <p> However, none of these proposals considers the issue of multiple dependent aggregates within a group. As a result, the specification of most of the examples presented in this paper using their approaches would require multiple views or subqueries, leading to the problems outlined in <ref> [CR96] </ref>. Acknowledgements We would like to thank Ted Johnson for his comments on this paper. The research of Kenneth A.
Reference: [GBLP96] <author> J. Gray, A. Bosworth, A. Layman, and H. Pirahesh. </author> <title> Datacube : A relational aggregation operator generalizing group-by, </title> <booktitle> cross-tab, and sub-totals. In Proceedings of IEEE ICDE, </booktitle> <pages> pages 152-159, </pages> <year> 1996. </year> <note> Also available as Microsoft Technical Report MSR-TR-95-22. </note>
Reference-contexts: Broken down by hospital, diagnosis and treatment, find the average life expectancy, including all subtotals across each dimension. The electronic mail addresses of the authors are kar@cs.columbia.edu, divesh@research.att.com and damianos@cs.stevens-tech.edu. Each of these queries is an example of a datacube query <ref> [GBLP96] </ref>. Datacube queries allow one to compute aggregates of the data at a variety of granularities. <p> A datacube could be computed by separately computing the aggregate at each granularity. However, it is also possible to compute aggregates at several coarser levels of granularity at the same time as computing aggregates at finer levels of granularity. Such algorithms are presented in <ref> [GBLP96, AAD + 96, ZDN97, RS97] </ref>. A different kind of decision support query has been considered in [CR96], involving aggregation queries in which multiple dependent aggregates are computed within each group. <p> The main contributions of this paper are the following. Classification (Section 4) We classify multi-feature cubes based on their degree of incrementality. We extend the notions of distributive, algebraic, and holistic aggregates from <ref> [GBLP96] </ref> to our more general context. Identification (Section 5) We provide syntactic sufficient conditions on multi-feature cube queries to determine when they are distributive or algebraic. The evaluation of such queries can be performed particularly efficiently, so it is important to be able to identify them syntactically. <p> The unit price and sales (in dollars) of items ordered by the customer from the supplier on the given date are stored in Price and Sales. Orders placed on that date are delivered after Delay days. 2 Background 2.1 The Datacube: Aggregation at Multiple Granularities In <ref> [GBLP96] </ref>, Gray et al. present the datacube, which allows the computation of aggregates of the data at multiple granularities. We refer the reader to [GBLP96] for the syntax and semantics of such queries in general, and present an example below to aid intuition. <p> Orders placed on that date are delivered after Delay days. 2 Background 2.1 The Datacube: Aggregation at Multiple Granularities In <ref> [GBLP96] </ref>, Gray et al. present the datacube, which allows the computation of aggregates of the data at multiple granularities. We refer the reader to [GBLP96] for the syntax and semantics of such queries in general, and present an example below to aid intuition. Example 2.1: Suppose that we want to ask the following datacube query: grouping by all subsets of fSupplier, Customer, Item, Monthg, find the total sales among all tuples from 1996. <p> However, as argued in [CR96], the resulting expressions are both complex and repetitious, leading to queries that are difficult to understand, maintain, and optimize, Thus, we prefer to extend the succinct syntax of [CR96] with the CUBE BY clause of <ref> [GBLP96] </ref>. 3.1 A Combined Syntax for Multi-Feature Cubes A multi-feature cube query Q has the syntax described in Figure 1. The FROM and the WHERE clauses in the multi-feature cube are identical to the corresponding clauses in the syntactic extensions of [CR96] and [GBLP96], which are unchanged from standard SQL. <p> [CR96] with the CUBE BY clause of <ref> [GBLP96] </ref>. 3.1 A Combined Syntax for Multi-Feature Cubes A multi-feature cube query Q has the syntax described in Figure 1. The FROM and the WHERE clauses in the multi-feature cube are identical to the corresponding clauses in the syntactic extensions of [CR96] and [GBLP96], which are unchanged from standard SQL. The CUBE BY clause in the multi-feature cube combines the CUBE BY clause from [GBLP96] with the specification of grouping variables R 1 ; : : : ; R m of the GROUP BY clause from [CR96]. <p> The FROM and the WHERE clauses in the multi-feature cube are identical to the corresponding clauses in the syntactic extensions of [CR96] and <ref> [GBLP96] </ref>, which are unchanged from standard SQL. The CUBE BY clause in the multi-feature cube combines the CUBE BY clause from [GBLP96] with the specification of grouping variables R 1 ; : : : ; R m of the GROUP BY clause from [CR96]. The SELECT and the SUCH THAT clauses in the multi-feature cube are identical to the corresponding clauses in the syntactic extension of [CR96]. <p> While such an evaluation technique may be required in general, a large number of datacubes (those using distributive aggregate functions, in the terminology of <ref> [GBLP96] </ref>) can be evaluated much more efficiently, by incrementally computing the output of the datacube at a coarser granularity using only the output of the datacube at a finer granularity. We capture this property in our definition of distributive multi-feature cubes. <p> Example Multi-Feature Cube Graphs As a final step before identifying conditions for distributivity of multi-feature cubes, we define what it means for a set of aggregate functions of attributes to be distributive. This generalizes the characterization, from <ref> [GBLP96] </ref>, of a single distributive aggregate function. <p> is applicable whenever the conditions of Theorem 5.1 are satisfied has to deal with many grouping variables and tree-structured multi-feature cube graphs, and is given as Incremental-Eval in the full version of the paper [RSC97]. 6.2 Algorithms for Distributive Multi-Feature Cubes Several algorithms have been proposed for computing the datacube <ref> [GBLP96, AAD + 96, ZDN97, RS97] </ref>. The details of these algorithms are not important here. All of these algorithms attempt to compute the datacube by utilizing the lattice structure of the various granularities. Finer granularity results are combined to give results at the next coarser granularity. <p> Since F may be harder to compute than a simple aggregate like SUM, there might be an increase in the CPU cost. We address this concern in detail in Section 7. 6.3 The Holistic Case The algorithms that have been proposed for computing the datacube <ref> [GBLP96, AAD + 96, ZDN97, RS97] </ref> can be divided into two approaches: Algorithms that use main memory essentially for storing the input relation, typically in a partitioned and/or sorted fashion [AAD + 96, RS97]. Datacube tuples are computed, and immediately flushed to output buffers. <p> Datacube tuples are computed, and immediately flushed to output buffers. Algorithms that use main memory essentially for storing the (partially com puted) output, typically as a k-dimensional array <ref> [GBLP96, ZDN97] </ref>. Of these, the algorithms in the first approach are better suited to computing holistic multi-feature cubes.
Reference: [HWL94] <author> C. J. Hahn, S. G. Warren, and J. </author> <title> London. Edited synoptic cloud reports from ships and land stations over the globe, </title> <type> 1982-1991. </type> <note> Available from http://cdiac.esd.ornl.gov/cdiac/ndps/ndp026b.html, 1994. </note>
Reference-contexts: We used three different data sources for the input: (a) a uniform, randomly generated data set, (b) data generated according to the TPC-D benchmark [Tra95], and (c) data from real-world measurements of cloud coverage over the globe for a period of one month <ref> [HWL94] </ref>. The meaning of each attribute is given below.
Reference: [LW96] <author> C. Li and X. S. Wang. </author> <title> A data model for supporting on-line analytical processing. </title> <booktitle> In Proceedings of CIKM, </booktitle> <pages> pages 81-88, </pages> <year> 1996. </year>
Reference-contexts: This is an important subclass of multi-feature cube queries that is no more difficult to compute than datacube queries, and which includes many sophisticated queries not easily expressed as datacube queries. Other authors have introduced new algebraic operators and/or syntaxes for multidimensional data analysis <ref> [AGS97, LW96] </ref>. However, none of these proposals considers the issue of multiple dependent aggregates within a group. As a result, the specification of most of the examples presented in this paper using their approaches would require multiple views or subqueries, leading to the problems outlined in [CR96].
Reference: [RS97] <author> K. A. Ross and D. Srivastava. </author> <title> Fast computation of sparse datacubes. </title> <booktitle> In Proceedings of VLDB, </booktitle> <pages> pages 116-125, </pages> <year> 1997. </year>
Reference-contexts: A datacube could be computed by separately computing the aggregate at each granularity. However, it is also possible to compute aggregates at several coarser levels of granularity at the same time as computing aggregates at finer levels of granularity. Such algorithms are presented in <ref> [GBLP96, AAD + 96, ZDN97, RS97] </ref>. A different kind of decision support query has been considered in [CR96], involving aggregation queries in which multiple dependent aggregates are computed within each group. <p> We also discuss the suitability of previously proposed datacube evaluation techniques for efficiently evaluating holistic multi-feature cubes. Performance (Section 7) We evaluate the CPU performance of computing multi-feature cubes using the datacube evaluation algorithm of Ross and Srivastava <ref> [RS97] </ref>. Using a variety of synthetic, benchmark and real-world data sets, we demonstrate that the CPU cost of evaluating distributive multi-feature cubes is comparable to that of evaluating simple datacubes. <p> is applicable whenever the conditions of Theorem 5.1 are satisfied has to deal with many grouping variables and tree-structured multi-feature cube graphs, and is given as Incremental-Eval in the full version of the paper [RSC97]. 6.2 Algorithms for Distributive Multi-Feature Cubes Several algorithms have been proposed for computing the datacube <ref> [GBLP96, AAD + 96, ZDN97, RS97] </ref>. The details of these algorithms are not important here. All of these algorithms attempt to compute the datacube by utilizing the lattice structure of the various granularities. Finer granularity results are combined to give results at the next coarser granularity. <p> Since F may be harder to compute than a simple aggregate like SUM, there might be an increase in the CPU cost. We address this concern in detail in Section 7. 6.3 The Holistic Case The algorithms that have been proposed for computing the datacube <ref> [GBLP96, AAD + 96, ZDN97, RS97] </ref> can be divided into two approaches: Algorithms that use main memory essentially for storing the input relation, typically in a partitioned and/or sorted fashion [AAD + 96, RS97]. Datacube tuples are computed, and immediately flushed to output buffers. <p> concern in detail in Section 7. 6.3 The Holistic Case The algorithms that have been proposed for computing the datacube [GBLP96, AAD + 96, ZDN97, RS97] can be divided into two approaches: Algorithms that use main memory essentially for storing the input relation, typically in a partitioned and/or sorted fashion <ref> [AAD + 96, RS97] </ref>. Datacube tuples are computed, and immediately flushed to output buffers. Algorithms that use main memory essentially for storing the (partially com puted) output, typically as a k-dimensional array [GBLP96, ZDN97]. Of these, the algorithms in the first approach are better suited to computing holistic multi-feature cubes. <p> The second approach, on the other hand, maintains partially computed aggregates, obtained by scanning the input relation; such incremental computation cannot be performed for holistic multi-feature cubes. 7 Experimental Evaluation We used the techniques proposed by Ross and Srivastava <ref> [RS97] </ref> to implement a variety of multi-feature cube queries. The software used is extensible with respect to the aggregate functions used; arbitrary distributive or non-distributive aggregate functions can be written and linked to the cube-computation code. <p> For distributive aggregates, the software works as follows: First, combine all tuples that share all CUBE BY attributes into a single tuple using the combination function F (which exists for distributive aggregates). After doing so, multiple sorting and scanning steps compute the cube result, as described in <ref> [RS97] </ref>. For holistic aggregates, there is no initial combining step. Multiple sorting and scanning steps compute the cube result. Unlike the case for distributive cubes, fine granularity results are not used to compute coarse granularity results; the aggregates are computed separately at each granularity. <p> The machine used had 128MB of RAM, and in all cases, the input relations used were able to fit in RAM. We would expect analogous results for larger tables using the divide and conquer approach of <ref> [RS97] </ref>. The reported time is the CPU time reported by the operating system, which was always very close to the elapsed time. CPU time measurement commenced after the input was read, and the writing of the output result was suppressed in order to avoid introducing I/O cost.
Reference: [RSC97] <author> K. A. Ross, D. Srivastava and D. Chatziantoniou. </author> <title> Complex aggregation at multiple granularities. </title> <type> AT&T Technical Report, </type> <year> 1997. </year>
Reference-contexts: The first and third queries satisfy the conditions of Theorem 5.1, but the conditions in the SUCH THAT clause of the second query violate Condition C3. 2 The conditions of Theorem 5.1 can be easily modified to identify algebraic multi-feature cubes, as shown in the full version of the paper <ref> [RSC97] </ref>. 6 Evaluating Multi-Feature Cubes When considering the evaluation of multi-feature cube queries, we consider only distributive queries which (in a sense) represent the "fully incremental" queries, and holistic queries which represent the non-incremental queries. <p> A general algorithm that is applicable whenever the conditions of Theorem 5.1 are satisfied has to deal with many grouping variables and tree-structured multi-feature cube graphs, and is given as Incremental-Eval in the full version of the paper <ref> [RSC97] </ref>. 6.2 Algorithms for Distributive Multi-Feature Cubes Several algorithms have been proposed for computing the datacube [GBLP96, AAD + 96, ZDN97, RS97]. The details of these algorithms are not important here. All of these algorithms attempt to compute the datacube by utilizing the lattice structure of the various granularities.
Reference: [Tra95] <institution> Transaction Processing Performance Council (TPC), </institution> <address> 777 N. First Street, Suite 600, San Jose, CA 95112, USA. </address> <booktitle> TPC Benchmark D (Decision Support), </booktitle> <month> May </month> <year> 1995. </year>
Reference-contexts: All queries were run over an input with seven attributes, including four CUBE BY attributes (G1-G4) and three aggregated attributes (A1-A3). We used three different data sources for the input: (a) a uniform, randomly generated data set, (b) data generated according to the TPC-D benchmark <ref> [Tra95] </ref>, and (c) data from real-world measurements of cloud coverage over the globe for a period of one month [HWL94]. The meaning of each attribute is given below.
Reference: [ZDN97] <author> Y. Zhao, P. M. Deshpande, and J. F. Naughton. </author> <title> An array-based algorithm for simultaneous multidimensional aggregates. </title> <booktitle> In Proceedings of ACM SIGMOD, </booktitle> <pages> pages 159-170, </pages> <year> 1997. </year> <title> This article was processed using the L A T E X macro package with LLNCS style </title>
Reference-contexts: A datacube could be computed by separately computing the aggregate at each granularity. However, it is also possible to compute aggregates at several coarser levels of granularity at the same time as computing aggregates at finer levels of granularity. Such algorithms are presented in <ref> [GBLP96, AAD + 96, ZDN97, RS97] </ref>. A different kind of decision support query has been considered in [CR96], involving aggregation queries in which multiple dependent aggregates are computed within each group. <p> is applicable whenever the conditions of Theorem 5.1 are satisfied has to deal with many grouping variables and tree-structured multi-feature cube graphs, and is given as Incremental-Eval in the full version of the paper [RSC97]. 6.2 Algorithms for Distributive Multi-Feature Cubes Several algorithms have been proposed for computing the datacube <ref> [GBLP96, AAD + 96, ZDN97, RS97] </ref>. The details of these algorithms are not important here. All of these algorithms attempt to compute the datacube by utilizing the lattice structure of the various granularities. Finer granularity results are combined to give results at the next coarser granularity. <p> Since F may be harder to compute than a simple aggregate like SUM, there might be an increase in the CPU cost. We address this concern in detail in Section 7. 6.3 The Holistic Case The algorithms that have been proposed for computing the datacube <ref> [GBLP96, AAD + 96, ZDN97, RS97] </ref> can be divided into two approaches: Algorithms that use main memory essentially for storing the input relation, typically in a partitioned and/or sorted fashion [AAD + 96, RS97]. Datacube tuples are computed, and immediately flushed to output buffers. <p> Datacube tuples are computed, and immediately flushed to output buffers. Algorithms that use main memory essentially for storing the (partially com puted) output, typically as a k-dimensional array <ref> [GBLP96, ZDN97] </ref>. Of these, the algorithms in the first approach are better suited to computing holistic multi-feature cubes.
References-found: 10

