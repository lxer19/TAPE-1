URL: http://www.ri.cmu.edu/afs/cs/project/prodigy-1/eugene/Public/Papers/primary-effects.ps
Refering-URL: http://www.ri.cmu.edu/afs/cs.cmu.edu/user/eugene/Public/Www/Research/Papers/prim.html
Root-URL: 
Email: eugene@cs.cmu.edu  qyang@cs.sfu.ca  
Title: Automatically Selecting and Using Primary Effects in Planning: Theory and Experiments  
Author: Eugene Fink Qiang Yang 
Note: Eugene Fink is supported by Wright Laboratory, Aeronautical Systems Center, Air Force Materiel Command, USAF, and the Advanced Research Projects Agency (ARPA) under grant number F33615-93-1-1330. Qiang Yang is supported by Natural Sciences and Engineering Research Council of Canada (NSERC) under grant number OGP0184883.  
Web: http://www.cs.cmu.edu/~eugene  http://fas.sfu.ca/cs/people/Faculty/Yang  
Address: Pittsburgh, PA 15213, USA  Burnaby, BC V5A1S6, Canada  
Affiliation: School of Computer Science Carnegie Mellon University  School of Computing Science Simon Fraser University  
Abstract: The use of primary effects of operators is an effective approach to improving the efficiency of planning. The characterization of "good" primary effects, however, has remained at an informal level and there have been no algorithms for selecting primary effects of operators. We formalize the use of primary effects in planning and present a criterion for selecting useful primary effects, which guarantees efficiency and completeness. We analyze the efficiency of planning with primary effects and the quality of the resulting plans. We then describe a learning algorithm that automatically selects primary effects and demonstrate, both analytically and empirically, that the use of this algorithm significantly reduces planning time and does not compromise completeness. 
Abstract-found: 1
Intro-found: 1
Reference: [ Barrett and Weld, 1994 ] <author> Anthony Barrett and Dan Weld. </author> <title> Partial order planning: Evaluat ing possible efficiency gains. </title> <journal> Aritificial Intelligence, </journal> <volume> 67(1) </volume> <pages> 71-112, </pages> <year> 1994. </year>
Reference-contexts: planning domains (Sections 7.1 and 7.2), with an extended version of the robot domain (Section 7.3), and with a manufacturing domain (Section 7.4). 7.1 Artificial Planning Domains We consider a family of artificial domains, similar to the domains used by Barrett and Weld for evaluating the efficiency of partial-order planning <ref> [ Barrett and Weld, 1994 ] </ref> . We can independently vary different features of these domains, which enables us to perform controlled experiments.
Reference: [ Blumer et al., 1987 ] <author> Anselm Blumer, Andrzej Ehrenfeucht, David Haussler, and Manfred K. Warmuth. </author> <title> Occam's razor. </title> <journal> Information Processing Letters, </journal> <volume> 24 </volume> <pages> 377-380, </pages> <year> 1987. </year>
Reference-contexts: For a hypothesis space with at most (E + 1) hypotheses, the probability of learning a hypothesis that is not approximately correct is no larger than the following expression <ref> [ Blumer et al., 1987 ] </ref> : The learning algorithm is probably approximately correct if this probability is no larger than a certain small positive value, ffi ff : (E + 1) (1 * ff ) m ffi ff : It is a classical PAC-learning inequality, used for determining the required <p> The inequality holds if m satisfies the following condition <ref> [ Blumer et al., 1987; Russell and Norvig, 1995 ] </ref> : m * ff E + 1 : (7) We assume that the selected values of * ff are the same for all operators in the planning domain and that the values of ffi ff are also the same for all
Reference: [ Chapman, 1987 ] <author> David Chapman. </author> <title> Planning for conjunctive goals. </title> <journal> Artificial Intelligence, </journal> <volume> 32 </volume> <pages> 333-377, </pages> <year> 1987. </year>
Reference-contexts: We estimate the planning time by the number of nodes in the planner's search space and the solution quality by the sum of the costs of operators in the solution plan. We then experimentally confirm the analytical predictions using an advanced version of the tweak planner <ref> [ Chapman, 1987 ] </ref> , called abtweak [ Yang and Tenenberg, 1990 ] . We can readily generalize the techniques for learning primary effects to other backward-chaining planners, such as prodigy [ Veloso et al., 1995 ] and ucpop [ Penberthy and Weld, 1992 ] . <p> We discuss some extensions to the learning algorithm in Section 8. Finally, we conclude in Section 9, with a summary of the results. 3 2 Using Primary Effects in Planning We discuss the use of primary effects in planning and describe the Prim-tweak planner, a version of tweak <ref> [ Chapman, 1987 ] </ref> that uses primary effects. We first describe the representation of planning domains in the tweak system (Section 2.1). <p> The implementation of Prim-tweak uses Chapman's codesignation technique to generate plans with variables. The search for unsatisfied preconditions at Steps 1 and 2 of Prim-tweak is based on Chapman's Modal Truth Criterion <ref> [ Chapman, 1987 ] </ref> . This search is performed by a very fast algorithm. <p> We use this condition in Section 5 to design an algorithm for learning primary effects. 3.1 Completeness A planner is complete if it can find a solution plan for every solvable problem. The unrestricted tweak planner is complete <ref> [ Chapman, 1987 ] </ref> . The use of primary effects, however, may compromise completeness of tweak. For example, consider the robot domain with the primary effects given in Example 5. Suppose that the initial state is as shown in Figure 2 and the robot must move out of room 1. <p> Theorem 1 If Prim-tweak searches the space of plans in the best-first order of plan costs, then it will solve every problem that has a primary-effect justified solution. The proof of this theorem is similar to the completeness proof for the unrestricted tweak planner, presented elsewhere <ref> [ Chapman, 1987; Yang and Murray, 1994 ] </ref> . Thus, to guarantee completeness of Prim-tweak, we have to ensure that every solvable problem has a primary-effect justified solution.
Reference: [ Cohen et al., 1994 ] <author> William W. Cohen, Russ Greiner, and Dale Schuurmans. </author> <title> Probabilistic hill-climbing. </title> <editor> In S.J. Hanson, T. Petsche, M. Kearns, and R.L. Rivest, editors, </editor> <booktitle> Computational Learning Theory and Natural Learning Systems, </booktitle> <pages> pages 171-181. </pages> <publisher> MIT Press, </publisher> <address> Boston, MA, </address> <year> 1994. </year>
Reference-contexts: We determine the required value of m, using the theory of probably approximately correct (PAC) learning [ Valiant, 1984 ] . Researchers have investigated various ways of applying this theory in designing learning and search algorithms <ref> [ Cohen et al., 1994 ] </ref> . The dependency between m and the values of * u and ffi u is called the sample complexity of the learning algorithm.
Reference: [ Fikes and Nilsson, 1971 ] <author> Richard E. Fikes and Nils J. Nilsson. </author> <title> strips: A new approach to the application of theorem proving to problem solving. </title> <journal> Artificial Intelligence, </journal> <volume> 2 </volume> <pages> 189-208, </pages> <year> 1971. </year>
Reference-contexts: A primary-effect restricted planner never inserts an operator into a plan for achieving its side effects. AI researchers have long recognized the advantages of using primary effects. For example, Fikes and Nilsson used primary effects to improve the quality of solutions generated by the strips planner <ref> [ Fikes and Nilsson, 1971 ] </ref> . The authors of sipe [ Wilkins, 1988 ] distinguished between the main effects and side effects of operators and used this distinction to simplify the conflict resolution. <p> Warming the room, on the other hand, is a primary effect of using the fireplace. Example 2 We describe a version of the robot world <ref> [ Fikes and Nilsson, 1971 ] </ref> , which includes a robot and four rooms (see Figure 1a). The robot can go between two rooms connected by a door and break through a wall to create a new doorway (see Figure 1b).
Reference: [ Fink and Veloso, 1996 ] <author> Eugene Fink and Manuela M. Veloso. </author> <title> Formalizing the prodigy planning algorithm. </title> <editor> In M. Ghallab and A. Milani, editors, </editor> <booktitle> New Directions in AI Planning, </booktitle> <pages> pages 261-271. </pages> <publisher> IOS Press, </publisher> <address> Amsterdam, Netherlands, </address> <year> 1996. </year>
Reference-contexts: The authors of sipe [ Wilkins, 1988 ] distinguished between the main effects and side effects of operators and used this distinction to simplify the conflict resolution. The prodigy system <ref> [ Veloso et al., 1995; Fink and Veloso, 1996 ] </ref> allows the user to specify primary effects of operators in the form of control rules. The abtweak planner [ Yang et al., 1996 ] also enables the user to specify primary effects.
Reference: [ Fink and Yang, 1992a ] <author> Eugene Fink and Qiang Yang. </author> <title> Automatically abstracting effects of operators. </title> <booktitle> In Proceedings of the First International Conference on AI Planning Systems, </booktitle> <pages> pages 243-251, </pages> <year> 1992. </year>
Reference-contexts: We may use the relationship between primary effects and abstraction in selecting primary effects [ Fink and Yang, 1994 ] . We implemented an algorithm that selects primary effects in such a way as to maximize the number of levels in the abstraction hierarchy generated by alpine <ref> [ Fink and Yang, 1992a ] </ref> . Experiments show that this selection heuristic helps to avoid redundant primary effects and choose primary effects that correspond to the human intuition.
Reference: [ Fink and Yang, 1992b ] <author> Eugene Fink and Qiang Yang. </author> <title> Formalizing plan justifications. </title> <booktitle> In Proceedings of the Ninth Conference of the Canadian Society for Computational Studies of Intelligence, </booktitle> <pages> pages 9-14, </pages> <year> 1992. </year>
Reference-contexts: A plan is primary-effect justified if every operator has a justified primary effect. Intuitively, primary-effect justification means that no operator is used for the sake of its side effects. We presented a general discussion of justified plans in our previous research on improving the plan quality <ref> [ Fink and Yang, 1992b ] </ref> . For example, consider the robot domain of Example 4 and suppose that the predicate robot-in (x; y) is a primary effect of go (x; y) and a side effect of break (x; y).
Reference: [ Fink and Yang, 1994 ] <author> Eugene Fink and Qiang Yang. </author> <title> Search reduction in planning with primary effects. </title> <booktitle> In Proceedings of the Workshop on Theory Reformulation and Abstraction, </booktitle> <pages> pages 39-55, </pages> <year> 1994. </year>
Reference-contexts: In particular, the alpine abstraction-generating algorithm may use the knowledge of primary effects of operators in constructing an abstraction hierarchy [ Knoblock, 1994 ] . We may use the relationship between primary effects and abstraction in selecting primary effects <ref> [ Fink and Yang, 1994 ] </ref> . We implemented an algorithm that selects primary effects in such a way as to maximize the number of levels in the abstraction hierarchy generated by alpine [ Fink and Yang, 1992a ] .
Reference: [ Fink and Yang, 1995 ] <author> Eugene Fink and Qiang Yang. </author> <title> Planning with primary effects: Ex periments and analysis. </title> <booktitle> In Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 1606-1611, </pages> <year> 1995. </year>
Reference-contexts: Redundant primary effect A primary effect that can be demoted to a side effect without affecting completeness or increasing solution costs. 4 Analysis of the Search Reduction We analyzed the search space of backward-chaining planners and identified the factors that determine the efficiency of planning with primary effects <ref> [ Fink and Yang, 1995 ] </ref> . The analysis is an approximation based on several simplifying assumptions about properties of planning domains. We present here an analytical comparison of planning efficiency with and without primary effects. <p> The value of r decreases with B p ; however, r increases with C. To minimize r, we have to strike the right balance between B p and C <ref> [ Fink and Yang, 1995 ] </ref> . Second, we conclude from Equality 5 that we should always avoid redundant primary effects. Recall that a primary effect is redundant if we can make it a side effect without increasing solution costs.
Reference: [ Fink, 1995 ] <author> Eugene Fink. </author> <title> Systematic approach to the design of representation-changing algorithms. </title> <booktitle> In Proceedings of the Symposium on Abstraction, Reformulation, and Approximation, </booktitle> <pages> pages 54-61, </pages> <year> 1995. </year>
Reference-contexts: If we encounter only a subclass of possible goals, then we may select fewer primary effects without compromising completeness. When goals are limited to a certain subclass, we may be able to remove some operators from the domain and solve all goals of the subclass with the remaining operators <ref> [ Fink, 1995 ] </ref> . We can disregard the predicates that are not in the preconditions of any of the remaining operators. We thus obtain a new planning domain, with a reduced set of operators and predicates.
Reference: [ Gil, 1991 ] <author> Yolanda Gil. </author> <title> A specification of process planning for prodigy. </title> <type> Technical Report CMU-CS-91-179, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <year> 1991. </year>
Reference-contexts: This manufacturing domain is a simplified version of the prodigy process-planning domain <ref> [ Gil, 1991 ] </ref> . In Table 5, we give the operators of the manufacturing domain and their effects. We ran the learning algorithm with C u = 5 and * u = ffi u = 0:1. The algorithm selected the primary effects shown in Table 5.
Reference: [ Knoblock and Yang, 1994 ] <author> Craig A. Knoblock and Qiang Yang. </author> <title> Evaluating the trade-offs in partial-order planning algorithms. </title> <booktitle> In Proceedings of the Tenth Conference of the Canadian Society for Computational Studies of Intelligence, </booktitle> <pages> pages 279-286, </pages> <year> 1994. </year>
Reference-contexts: We note that the search depth of most planners is proportional to the size of the solution plan. In particular, we demonstrated this proportion, both analytically and experimentally, for the tweak planner <ref> [ Knoblock and Yang, 1994 ] </ref> . We give here an informal justification for the linear relationship between search depth and solution size. The tweak planner has to achieve every precondition of every operator in the plan, either by inserting a new operator or by adding an ordering constraint.
Reference: [ Knoblock, 1994 ] <author> Craig A. Knoblock. </author> <title> Automatically generating abstractions for planning. </title> <journal> Artificial Intelligence, </journal> <volume> 68 </volume> <pages> 243-302, </pages> <year> 1994. </year>
Reference-contexts: In particular, the alpine abstraction-generating algorithm may use the knowledge of primary effects of operators in constructing an abstraction hierarchy <ref> [ Knoblock, 1994 ] </ref> . We may use the relationship between primary effects and abstraction in selecting primary effects [ Fink and Yang, 1994 ] .
Reference: [ Penberthy and Weld, 1992 ] <author> J. Scott Penberthy and Daniel S. Weld. ucpop: </author> <title> A sound, com plete, partial-order planner for ADL. </title> <booktitle> In Proceedings of the Third International Conference on Knowledge Representation in Reasoning, </booktitle> <pages> pages 103-114, </pages> <year> 1992. </year>
Reference-contexts: We can readily generalize the techniques for learning primary effects to other backward-chaining planners, such as prodigy [ Veloso et al., 1995 ] and ucpop <ref> [ Penberthy and Weld, 1992 ] </ref> . Some researchers have used primary effects to improve the solution quality of depth-first search planners, by directing search to branches with low-cost operators. In particular, this approach was taken in the strips planner and in a depth-first version of prodigy.
Reference: [ Russell and Norvig, 1995 ] <author> Stuart Russell and Peter Norvig. </author> <title> Artificial Intelligence: A Mod ern Approach. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1995. </year>
Reference-contexts: The inequality holds if m satisfies the following condition <ref> [ Blumer et al., 1987; Russell and Norvig, 1995 ] </ref> : m * ff E + 1 : (7) We assume that the selected values of * ff are the same for all operators in the planning domain and that the values of ffi ff are also the same for all
Reference: [ Smith and Peot, 1992 ] <author> David E. Smith and Mark A. Peot. </author> <title> A critical look at Knoblock's hierarchy mechanism. </title> <booktitle> In Proceedings of the First International Conference on AI Planning Systems, </booktitle> <pages> pages 307-308, </pages> <year> 1992. </year> <month> 30 </month>
Reference-contexts: The use of primary effects considerably reduced planning time. 7.4 Experiments in a Manufacturing Domain We next describe the use of primary effects in a manufacturing domain, similar to the domain used by Smith and Peot in their analysis of abstraction planning <ref> [ Smith and Peot, 1992 ] </ref> . This manufacturing domain is a simplified version of the prodigy process-planning domain [ Gil, 1991 ] . In Table 5, we give the operators of the manufacturing domain and their effects.
Reference: [ Valiant, 1984 ] <author> Leslie G. Valiant. </author> <title> A theory of the learnable. </title> <journal> Communications of the ACM, </journal> <volume> 27 </volume> <pages> 1134-1142, </pages> <year> 1984. </year>
Reference-contexts: The first value, C u , is the maximal cost increase allowed by the user. The other two values is the probability requirements for the success of the inductive learning. They are the standard parameters of the probably approximately correct (PAC) learning <ref> [ Valiant, 1984 ] </ref> . We now briefly describe the meaning of these two values. In Section 6, we present the detailed explanation of their use. The * u value determines the required probability of completeness and limited cost increase. <p> The value of m depends on the success-probability parameters * u and ffi u , specified by the user. We determine the required value of m, using the theory of probably approximately correct (PAC) learning <ref> [ Valiant, 1984 ] </ref> . Researchers have investigated various ways of applying this theory in designing learning and search algorithms [ Cohen et al., 1994 ] . The dependency between m and the values of * u and ffi u is called the sample complexity of the learning algorithm.
Reference: [ Veloso et al., 1995 ] <author> Manuela M. Veloso, Jaime G. Carbonell, M. Alicia Perez, Daniel Bor rajo, Eugene Fink, and Jim Blythe. </author> <title> Integrating planning and learning: The prodigy architecture. </title> <journal> Journal of Experimental and Theoretical Artificial Intelligence, </journal> <volume> 7(1) </volume> <pages> 81-120, </pages> <year> 1995. </year>
Reference-contexts: The authors of sipe [ Wilkins, 1988 ] distinguished between the main effects and side effects of operators and used this distinction to simplify the conflict resolution. The prodigy system <ref> [ Veloso et al., 1995; Fink and Veloso, 1996 ] </ref> allows the user to specify primary effects of operators in the form of control rules. The abtweak planner [ Yang et al., 1996 ] also enables the user to specify primary effects. <p> We then experimentally confirm the analytical predictions using an advanced version of the tweak planner [ Chapman, 1987 ] , called abtweak [ Yang and Tenenberg, 1990 ] . We can readily generalize the techniques for learning primary effects to other backward-chaining planners, such as prodigy <ref> [ Veloso et al., 1995 ] </ref> and ucpop [ Penberthy and Weld, 1992 ] . Some researchers have used primary effects to improve the solution quality of depth-first search planners, by directing search to branches with low-cost operators.
Reference: [ Wilkins, 1988 ] <author> David E. Wilkins. </author> <title> Practical Planning: Extending the Classical AI Planning Paradigm. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1988. </year>
Reference-contexts: AI researchers have long recognized the advantages of using primary effects. For example, Fikes and Nilsson used primary effects to improve the quality of solutions generated by the strips planner [ Fikes and Nilsson, 1971 ] . The authors of sipe <ref> [ Wilkins, 1988 ] </ref> distinguished between the main effects and side effects of operators and used this distinction to simplify the conflict resolution.
Reference: [ Yang and Murray, 1994 ] <author> Qiang Yang and Cheryl Murray. </author> <title> An evaluation of the temporal coherence heuristic in partial-order planning. </title> <journal> Computational Intelligence, </journal> <volume> 10(3) </volume> <pages> 245-267, </pages> <year> 1994. </year>
Reference-contexts: Theorem 1 If Prim-tweak searches the space of plans in the best-first order of plan costs, then it will solve every problem that has a primary-effect justified solution. The proof of this theorem is similar to the completeness proof for the unrestricted tweak planner, presented elsewhere <ref> [ Chapman, 1987; Yang and Murray, 1994 ] </ref> . Thus, to guarantee completeness of Prim-tweak, we have to ensure that every solvable problem has a primary-effect justified solution.
Reference: [ Yang and Tenenberg, 1990 ] <author> Qiang Yang and Josh Tenenberg. abtweak: </author> <title> Abstracting a non-linear, least-commitment planner. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pages 204-209, </pages> <address> Boston, MA, </address> <year> 1990. </year>
Reference-contexts: We then experimentally confirm the analytical predictions using an advanced version of the tweak planner [ Chapman, 1987 ] , called abtweak <ref> [ Yang and Tenenberg, 1990 ] </ref> . We can readily generalize the techniques for learning primary effects to other backward-chaining planners, such as prodigy [ Veloso et al., 1995 ] and ucpop [ Penberthy and Weld, 1992 ] . <p> For example, 5 we may view the predicate door (x; y) as a primary effect of the operator break (x; y), and robot-in (y) as its side effect. To formalize the use of primary effects in planning, we use the notion of primary-effect justified plans <ref> [ Yang and Tenenberg, 1990 ] </ref> . We begin by defining useful, or justified, effects of operators in a plan. Definition 2 Let l be a primary effect of an operator ff 1 in some plan.
Reference: [ Yang et al., 1996 ] <author> Qiang Yang, Josh Tenenberg, and Steve Woods. </author> <title> On the implementation and evaluation of abtweak. </title> <journal> Computational Intelligence, </journal> <volume> 12(2) </volume> <pages> 295-318, </pages> <year> 1996. </year> <month> 31 </month>
Reference-contexts: The prodigy system [ Veloso et al., 1995; Fink and Veloso, 1996 ] allows the user to specify primary effects of operators in the form of control rules. The abtweak planner <ref> [ Yang et al., 1996 ] </ref> also enables the user to specify primary effects. Despite the importance of primary effects, the characterization of "good" primary effects has remained at an informal level and the task of choosing primary effects has been left to the human user.
References-found: 23

