URL: ftp://ftp.cs.indiana.edu/pub/techreports/TR457.ps.Z
Refering-URL: http://www.cs.indiana.edu/trindex.html
Root-URL: 
Title: Sequential-System Factorization  
Degree: by Kamlesh Rath Submitted to the faculty of the University Graduate School in partial fulfillment of the requirements for the degree Doctor of Philosophy in the  
Affiliation: Department of Computer Science Indiana University  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> T. K. Lee D. Borkovic A. J. Martin, S. M. Burns and P. J. Hazewindus. </author> <title> The design of an asynchronous microprocessor. </title> <booktitle> In Proc. Decennetial Caltech Conference on VLSI. </booktitle> <institution> CS Dept, California Institute of Technology, Pasadena, </institution> <address> CA, </address> <publisher> MIT Press, </publisher> <month> March </month> <year> 1989. </year>
Reference-contexts: The problem of arbitration in asynchronous circuits was first addressed by Muller [61]. 12 CHAPTER 2. RELATED RESEARCH Ebergen has also studied the use of arbiters in the decomposition of asynchronous circuits [26]. Martin was the first to use formal design methods to synthesize a working asynchronous microprocessor <ref> [1] </ref>. His design method for designing self-timed circuits [51] is based on Hoare's CSP [33]. Burns has developed an automatic synthesis method for self-timed circuits based on Martin's work [10]. Dill has also used trace theory in his dissertation to verify asynchronous designs [21].
Reference: [2] <author> Venkatesh Akella. hopCP: </author> <title> A new paradigm for VLSI programming. VLSI Systems Research Group, Note VLSI-89-002, </title> <institution> University of Utah, Department of Computer Science, </institution> <month> August </month> <year> 1989. </year>
Reference-contexts: Dill et. al have also verified invariant conditions and deadlock avoidance in asynchronous circuits in large systems by down-scaling in the Mur' language [22, 64]. Gopalakrishnan's hopCP is an extension of HOP for formal verification of asynchronous circuits <ref> [2, 29, 28] </ref>. HOP and hopCP specifications consist of separate protocol and behavior sections representing two orthogonal facets of a process. Similarly, Interface specification language (ISL), developed in this dissertation, is used to specify only the interactions of a machine with its environment.
Reference: [3] <author> W. R. Bevier and W. D. Young. </author> <title> The proof of correctness of a fault-tolerant circuit design. </title> <booktitle> In Proceedings of International Conference on Dependable Computing for Critical Applications, </booktitle> <pages> pages 107-114, </pages> <month> February </month> <year> 1991. </year>
Reference-contexts: The interaction protocols between components are added to 10 CHAPTER 2. RELATED RESEARCH the system description in decomposition steps. 2.1.2 Deductive Verification Theorem provers provide a versatile framework for verification and have been used extensively to verify many different kinds of systems, from microprocessors [8] to fault-tolerant systems <ref> [3] </ref>. Hunt has used the Boyer-Moore Nqthm theorem prover to verify the correctness of the layout of the FM9001 microprocessor against its high-level specification [37, 8]. His earlier verification exercises included the verification of the FM8501 microprocessor [36].
Reference: [4] <author> G. Borriello. </author> <title> Specification and synthesis of interface logic. </title> <booktitle> High-Level VLSI Synthesis, </booktitle> <pages> pages 153-176, </pages> <year> 1991. </year>
Reference-contexts: In a related discussion of interface specification, Boriello points out that, "the interface component has received limited attention even though it is crucial to integrating the circuit into an environment that will put it to use" <ref> [4] </ref>. However, while Boriello 3 develops external interface specifications as a means to guide synthesis, our goal is to use them to guide design decomposition. Both sides of the protocol are involved in factoring nontrivial sequential components. <p> It is typical that an area of verification research would have this orientation, and also that the top-down view would be better represented in synthesis research. In addition to Boriello's work <ref> [4] </ref>, approaches to scheduling by Ku, Micheli [47] and Nestor et.al [62] have considered protocol-like constraints. 2.1. FORMAL METHODS 9 Kurshan uses L-automata with language and process homomorphism [49] to verify reactive systems by stepwise reduction and refinement.
Reference: [5] <author> Bhaskar Bose. </author> <title> DDD A Transformation system for Digital Design Derivation. </title> <type> Technical Report 331, </type> <institution> Department of Computer Science, Indiana University, </institution> <month> May </month> <year> 1991. </year>
Reference-contexts: In this example, the heap is further decomposed into an allocator process and a garbage collector process. Chapter 2 Related Research The research reported in this thesis grew out of earlier work by Johnson [39, 40], Bose [6] and Zhu [79, 78] on transformational methodology for VLSI design. DDD <ref> [5, 41] </ref> is a transformation system based on Johnson's design derivation algebra. The limitations of the functional transformation framework in dealing with factorizations of sequential components with non-trivial protocols provided the motivation for this work.
Reference: [6] <author> Bhaskar Bose and Steven D. Johnson. DDD-FM9001: </author> <title> Derivation of a verified microprocessor. an exercise in integrating verification with formal derivation. </title> <booktitle> In Proceedings of IFIP Conference on Correct Hardware Design and Verification Methods. </booktitle> <publisher> Springer, </publisher> <year> 1993. </year>
Reference-contexts: In this example, the heap is further decomposed into an allocator process and a garbage collector process. Chapter 2 Related Research The research reported in this thesis grew out of earlier work by Johnson [39, 40], Bose <ref> [6] </ref> and Zhu [79, 78] on transformational methodology for VLSI design. DDD [5, 41] is a transformation system based on Johnson's design derivation algebra. The limitations of the functional transformation framework in dealing with factorizations of sequential components with non-trivial protocols provided the motivation for this work. <p> DDD has been used in conjunction with other formal verification tools to verify parts of designs that could not be derived using existing transformations <ref> [7, 6] </ref>. Sheeran has also used a transformational approach to verification in the Ruby relational algebra [71, 70]. T-Ruby [69] have developed a rewriting tool based on the Ruby algebra for VLSI design derivation. 2.1. <p> The third example describes the application of sequential decomposition to derive a dynamic memory interface for a formally derived realization of the Nqthm FM9001 57 58 CHAPTER 6. EXAMPLES microprocessor specification [37], called DDD-FM9001 <ref> [6] </ref>. Sequential decomposition of the DRAM memory interface entails extraction of a DRAM memory object from a system description that incorporates the read/write protocol and accounts for refresh cycles. The current realization of the DDD-FM9001 processor [6] does not support a DRAM interface because of the limitations in deriving an interface <p> EXAMPLES microprocessor specification [37], called DDD-FM9001 <ref> [6] </ref>. Sequential decomposition of the DRAM memory interface entails extraction of a DRAM memory object from a system description that incorporates the read/write protocol and accounts for refresh cycles. The current realization of the DDD-FM9001 processor [6] does not support a DRAM interface because of the limitations in deriving an interface with non-trivial protocols. <p> Embedding an implementation of a component into another introduces control synchronization and data communication mechanism between the components for correct interactions between them. The decomposed components can now be synthesized independently. 6.3 DDD-FM9001 Decomposition A realization of the Nqthm FM9001 [37] specification, called DDD-FM9001 <ref> [6] </ref>, was derived using the DDD [42] derivation system. DDD is a set of mechanized transformation tools to derive boolean descriptions from iterative functional specifications. 6.3. <p> The DDD-FM9001 is a general purpose microprocessor realized in FPGAs, mechanically derived from Hunt's Nqthm FM9001 specification [37]. The FM9001 is a 32-bit microprocessor mechanically verified in the Nqthm theorem prover and implemented in LSI Logic's gate array technology. Details of the derivation of the DDD-FM9001 are reported in <ref> [6] </ref>. Starting with specifications for DRAM and DDD-FM9001, let us derive the system organization shown in Figure 6.8. The state machine denoted by the DRAM specification is shown in Figure 4.7. The read, write and refresh cycles are represented as three paths from the reset state to the final state.
Reference: [7] <author> Bhaskar Bose, Steven D. Johnson, and Shyam Pullela. </author> <title> Integrating boolean verification with formal derivation. </title> <editor> In D. Agnew, L. Claesen, and R. Camposano, </editor> <title> 77 78 BIBLIOGRAPHY editors, </title> <booktitle> Proceedings of IFIP Conference on Hardware Description Languages and their Applications, </booktitle> <pages> pages 127-134. </pages> <publisher> Elsevier, </publisher> <month> April </month> <year> 1993. </year>
Reference-contexts: DDD has been used in conjunction with other formal verification tools to verify parts of designs that could not be derived using existing transformations <ref> [7, 6] </ref>. Sheeran has also used a transformational approach to verification in the Ruby relational algebra [71, 70]. T-Ruby [69] have developed a rewriting tool based on the Ruby algebra for VLSI design derivation. 2.1.
Reference: [8] <author> Bishop Brock and Warren A. Hunt. </author> <title> The FM9001 proof script. </title> <type> Technical report, </type> <institution> Computational Logic Incorporated, </institution> <year> 1993. </year>
Reference-contexts: The interaction protocols between components are added to 10 CHAPTER 2. RELATED RESEARCH the system description in decomposition steps. 2.1.2 Deductive Verification Theorem provers provide a versatile framework for verification and have been used extensively to verify many different kinds of systems, from microprocessors <ref> [8] </ref> to fault-tolerant systems [3]. Hunt has used the Boyer-Moore Nqthm theorem prover to verify the correctness of the layout of the FM9001 microprocessor against its high-level specification [37, 8]. His earlier verification exercises included the verification of the FM8501 microprocessor [36]. <p> Hunt has used the Boyer-Moore Nqthm theorem prover to verify the correctness of the layout of the FM9001 microprocessor against its high-level specification <ref> [37, 8] </ref>. His earlier verification exercises included the verification of the FM8501 microprocessor [36]. In a similar exercise, the Tamarack microprocessor was also verified by Joyce using HOL [44].
Reference: [9] <author> R.E. Bryant. </author> <title> A switch level model and simulator for MOS digital circuits. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-33(2):160-177, </volume> <month> February </month> <year> 1984. </year> <note> COSMOS paper. </note>
Reference-contexts: Binary decision diagrams have emerged as a popular modeling paradigm for digital systems <ref> [9] </ref>. Although model checking has now been used to verify temporal properties of some very large systems [13], it can not be used to verify many other properties that a designer might be interested in.
Reference: [10] <author> S.M. Burns. </author> <title> Automated compilation of concurrent programs into self-timed circuits. </title> <type> Technical Report Caltech-CS-TR-88-2, </type> <institution> California Institute of Technology, Computer Sc Dept, Caltech, Pasadena, </institution> <address> CA, </address> <month> December </month> <year> 1987. </year>
Reference-contexts: Martin was the first to use formal design methods to synthesize a working asynchronous microprocessor [1]. His design method for designing self-timed circuits [51] is based on Hoare's CSP [33]. Burns has developed an automatic synthesis method for self-timed circuits based on Martin's work <ref> [10] </ref>. Dill has also used trace theory in his dissertation to verify asynchronous designs [21]. Nowick and Dill have used petri-nets for verification of asynchronous circutis [24].
Reference: [11] <author> Tam Anh Chu. </author> <title> Synthesis of self timed VLSI circuits from graph theoritic specifications. </title> <booktitle> In Intl. Workshop on Petri Nets and Performance Models, </booktitle> <month> August </month> <year> 1987. </year>
Reference-contexts: Most formal treatments of system decomposition are bottom-up in the sense that they are oriented toward post-design verification. This would include most of the recent research in finite-state machine verification [12]; extensions of FSM models (e.g. [76, 72]) and Petri net theories (e.g. <ref> [11] </ref>); and model-theoretic work involving process formalisms (e.g. [54, 30]). It is typical that an area of verification research would have this orientation, and also that the top-down view would be better represented in synthesis research.
Reference: [12] <author> Ed Clarke, D. Dill, J. Burch, K. L. McMillan, and L. J. Hwang. </author> <title> Symbolic model checking: 10**20 states and beyond. </title> <booktitle> In International Workshop on Formal Methods in VLSI Design. </booktitle> <address> ACM-SIGDA, </address> <month> January </month> <year> 1991. </year>
Reference-contexts: Although model checking has now been used to verify temporal properties of some very large systems [13], it can not be used to verify many other properties that a designer might be interested in. Clarke et.al <ref> [14, 12] </ref> have used a compositional finite state machine model to verify temporal properties of systems using computational tree logic and binary decision diagram based methods. Most formal treatments of system decomposition are bottom-up in the sense that they are oriented toward post-design verification. <p> Most formal treatments of system decomposition are bottom-up in the sense that they are oriented toward post-design verification. This would include most of the recent research in finite-state machine verification <ref> [12] </ref>; extensions of FSM models (e.g. [76, 72]) and Petri net theories (e.g. [11]); and model-theoretic work involving process formalisms (e.g. [54, 30]). It is typical that an area of verification research would have this orientation, and also that the top-down view would be better represented in synthesis research.
Reference: [13] <author> Edmund M. Clarke, Orna Grumberg, Hiromi Hiraishi, Somesh Jha, David E. Long, and Linda A. Ness. </author> <title> Verification of the futurebus+ cache coherence protocol. </title> <booktitle> In Proceedings of IFIP Conference on Hardware Description Languages and their Applications (CHDL), </booktitle> <year> 1993. </year>
Reference-contexts: Binary decision diagrams have emerged as a popular modeling paradigm for digital systems [9]. Although model checking has now been used to verify temporal properties of some very large systems <ref> [13] </ref>, it can not be used to verify many other properties that a designer might be interested in. Clarke et.al [14, 12] have used a compositional finite state machine model to verify temporal properties of systems using computational tree logic and binary decision diagram based methods.
Reference: [14] <author> E.M. Clarke, D.E. Long, and K.L. McMillan. </author> <title> A language for compositional specification and verification of finite state hardware controllers. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 79, </volume> <month> September </month> <year> 1991. </year>
Reference-contexts: Although model checking has now been used to verify temporal properties of some very large systems [13], it can not be used to verify many other properties that a designer might be interested in. Clarke et.al <ref> [14, 12] </ref> have used a compositional finite state machine model to verify temporal properties of systems using computational tree logic and binary decision diagram based methods. Most formal treatments of system decomposition are bottom-up in the sense that they are oriented toward post-design verification.
Reference: [15] <author> Rance Cleaveland and Matthew Hennessy. </author> <title> Testing equivalence as a bisimulation equivalence. In Sifakis, editor, Automatic Verification Methods for Finite State Systems, </title> <address> pages 11-23. </address> <publisher> Springer Verlag, </publisher> <year> 1990. </year> <note> LNCS 407. BIBLIOGRAPHY 79 </note>
Reference-contexts: These process calculi have been enhanced by many researchers for applications in VLSI design verification. Milne's CIRCAL [55] is one such compositional process algebra with modeling support for buses and clocks. Other bottom-up formal verification methods based on process algebras include <ref> [63, 15, 16] </ref>. Davie [17] takes a top-down approach to design using verification between specification and implementation steps in CIRCAL. The description of components are composed together for verification with respect to the specification.
Reference: [16] <author> Rance Cleaveland, Joachim Parrow, and Bernhard Steffen. </author> <title> The concurrency workbench. In Sifakis, editor, Automatic Verification Methods for Finite State Systems, </title> <address> pages 24-37. </address> <publisher> Springer Verlag, </publisher> <year> 1990. </year> <note> LNCS 407. </note>
Reference-contexts: These process calculi have been enhanced by many researchers for applications in VLSI design verification. Milne's CIRCAL [55] is one such compositional process algebra with modeling support for buses and clocks. Other bottom-up formal verification methods based on process algebras include <ref> [63, 15, 16] </ref>. Davie [17] takes a top-down approach to design using verification between specification and implementation steps in CIRCAL. The description of components are composed together for verification with respect to the specification.
Reference: [17] <author> Bruce S. Davie. </author> <title> A Formal, Hierarchical Design and Validation Methodology for VLSI. </title> <type> PhD thesis, </type> <institution> University of Edinburgh, </institution> <year> 1988. </year>
Reference-contexts: These process calculi have been enhanced by many researchers for applications in VLSI design verification. Milne's CIRCAL [55] is one such compositional process algebra with modeling support for buses and clocks. Other bottom-up formal verification methods based on process algebras include [63, 15, 16]. Davie <ref> [17] </ref> takes a top-down approach to design using verification between specification and implementation steps in CIRCAL. The description of components are composed together for verification with respect to the specification. Contextual constraints, restrictions imposed by a device on its environment are introduced to write partial specifications of a component's environment.
Reference: [18] <author> Bruce S. Davie and George J. Milne. </author> <title> Contextual constraints for design and verification. </title> <editor> In Birtwistle and Subramanyam, editors, </editor> <booktitle> VLSI Specification, Verification and Synthesis, </booktitle> <pages> pages 257-265. </pages> <publisher> Kluwer, </publisher> <year> 1988. </year>
Reference-contexts: Contextual constraints, restrictions imposed by a device on its environment are introduced to write partial specifications of a component's environment. The constraints are also used to restrict the target architecture to reduce the complexity of verification <ref> [18] </ref>. A CIR-CAL based transformation to partition a design is mentioned. The designer specifies a component and an algorithm is used to generate the specification of the other component (s) in the design. Davie suggests that this transformation is of "limited usefulness" due to restrictions on it in their formalism.
Reference: [19] <author> S. Devadas and K. Keutzer. </author> <title> An Automata-Theoretic Approach to Behavioral Equivalence. </title> <booktitle> In Proceedings of the International Conference on Computer-Aided Design, </booktitle> <pages> pages 30-33, </pages> <month> November </month> <year> 1990. </year>
Reference-contexts: For simple expressions this is done by textual comparison. In general this involves verification of equivalence of logical and arithmetic expressions, and is a heuristic task <ref> [19] </ref>. Let ^u, ^v be the values in registers u, v before the procedures u = u1 and v = uflv in the original fac.
Reference: [20] <author> Srinivas Devadas and A. Richard Newton. </author> <title> Decomposition and factorization of sequential finite state machines. </title> <journal> Transactions on Computer-Aided Design 1989, </journal> <volume> 8(11) </volume> <pages> 1206-1217, </pages> <month> November </month> <year> 1989. </year>
Reference-contexts: This is different from classical FSM decomposition <ref> [20] </ref>, which assumes tightly 2.2. SYSTEM SYNTHESIS 13 coupled sub-machines that can share state and input information. Kuehlmann and Bergamaschi have considered system specifications at different levels of abstraction and partitioning of control and data flow graphs to obtain smaller layouts [48].
Reference: [21] <author> David L. Dill. </author> <title> Trace Theory for Automatic Hierarchical Verification of Speed-Independent Circuits. </title> <publisher> MIT Press, </publisher> <year> 1988. </year>
Reference-contexts: His design method for designing self-timed circuits [51] is based on Hoare's CSP [33]. Burns has developed an automatic synthesis method for self-timed circuits based on Martin's work [10]. Dill has also used trace theory in his dissertation to verify asynchronous designs <ref> [21] </ref>. Nowick and Dill have used petri-nets for verification of asynchronous circutis [24]. Dill et. al have also verified invariant conditions and deadlock avoidance in asynchronous circuits in large systems by down-scaling in the Mur' language [22, 64]. <p> The theory developed in this dissertation provides a model and decomposition method for globally synchronous systems. It has many similarities with formal design methods for asynchronous circuits. The notion of "complement of a machine" described here is similar to Dill's description of an "environment" in trace theory <ref> [21] </ref>. Also, the composition operation described here is similar to Gopalakrishnan's PARCOMP [31]. 2.2 System Synthesis The methodology described in this dissertation explores how a system description can be decomposed into interacting components using a protocol specification with non-trivial control synchronization and data transfer interactions between components.
Reference: [22] <author> David L. Dill, Andreas J. Drexler, Alan J. Hu, and C. Han Yang. </author> <title> Protocol verification as a hardware design aid. </title> <booktitle> In Proceedings of International Conference on Computer Design: VLSI in Computers & Processors, </booktitle> <pages> pages 522-525. </pages> <publisher> IEEE, </publisher> <year> 1992. </year>
Reference-contexts: Dill has also used trace theory in his dissertation to verify asynchronous designs [21]. Nowick and Dill have used petri-nets for verification of asynchronous circutis [24]. Dill et. al have also verified invariant conditions and deadlock avoidance in asynchronous circuits in large systems by down-scaling in the Mur' language <ref> [22, 64] </ref>. Gopalakrishnan's hopCP is an extension of HOP for formal verification of asynchronous circuits [2, 29, 28]. HOP and hopCP specifications consist of separate protocol and behavior sections representing two orthogonal facets of a process.
Reference: [23] <author> David L. Dill, Alan J. Hu, and Howard Wong-Toi. </author> <title> Checking for language inclusion using simulation preorders. </title> <editor> In Larsen and Skou, editors, </editor> <booktitle> Proceedings of Computer Aided Verification, </booktitle> <pages> pages 255-265. </pages> <publisher> Springer, </publisher> <month> July </month> <year> 1991. </year> <note> LNCS 575. </note>
Reference-contexts: As an alternative to bottom-up verification techniques, the methodology described in this dissertation facilitates top-down design by factoring sequential components from designs using transformations. Dill et.al have used a Buchi automata based model to verify safety and liveness properties using language containment <ref> [23] </ref>. McMillan and Dill have also modelled timing constraints as min/max constraints and used a generalized branch and bound algorithm to verify the timing specification of connected components [53]. Drusinsky and Harel have used state-charts for hierarchical description of hardware and synthesis of component machines [25].
Reference: [24] <author> David L. Dill, Steven M. Novick, and Robert F. Sproull. </author> <title> Automatic verification of speed-independent circuits with petri net specification. </title> <booktitle> In IEEE International 80 BIBLIOGRAPHY Conference on Computer Design, </booktitle> <pages> pages 212-216. </pages> <publisher> Stanford Univ., IEEE Press, </publisher> <year> 1989. </year>
Reference-contexts: Burns has developed an automatic synthesis method for self-timed circuits based on Martin's work [10]. Dill has also used trace theory in his dissertation to verify asynchronous designs [21]. Nowick and Dill have used petri-nets for verification of asynchronous circutis <ref> [24] </ref>. Dill et. al have also verified invariant conditions and deadlock avoidance in asynchronous circuits in large systems by down-scaling in the Mur' language [22, 64]. Gopalakrishnan's hopCP is an extension of HOP for formal verification of asynchronous circuits [2, 29, 28].
Reference: [25] <author> Doron Drusinsky and David Harel. </author> <title> Using statecharts for hardware description and synthesis. </title> <journal> Transactions on CAD, </journal> <volume> 8(7) </volume> <pages> 798-807, </pages> <month> July </month> <year> 1989. </year>
Reference-contexts: McMillan and Dill have also modelled timing constraints as min/max constraints and used a generalized branch and bound algorithm to verify the timing specification of connected components [53]. Drusinsky and Harel have used state-charts for hierarchical description of hardware and synthesis of component machines <ref> [25] </ref>. Holzmann formulated search heuristics to reduce the search space and time for validation of communication protocols [34]. State space explosion is often a problem in bottom-up verification methods using finite state machine models. This occurs in the construction of the product machine.
Reference: [26] <author> J. C. Ebergen. Arbiters: </author> <title> An exercise in specifying and decomposing asynchronously communicating components. </title> <institution> CS Dept, University of Waterloo. </institution>
Reference-contexts: The problem of arbitration in asynchronous circuits was first addressed by Muller [61]. 12 CHAPTER 2. RELATED RESEARCH Ebergen has also studied the use of arbiters in the decomposition of asynchronous circuits <ref> [26] </ref>. Martin was the first to use formal design methods to synthesize a working asynchronous microprocessor [1]. His design method for designing self-timed circuits [51] is based on Hoare's CSP [33]. Burns has developed an automatic synthesis method for self-timed circuits based on Martin's work [10].
Reference: [27] <author> Daniel D. Gajski. </author> <title> High-Level VLSI Synthesis, chapter Essential Issues and Possible Solutions in High-Level Synthesis, </title> <address> pages 1-26. </address> <publisher> Kluwer, </publisher> <year> 1991. </year>
Reference-contexts: The system partitioning method described in this dissertation supports both design approaches and does not restrict a designer to any one of them. 4 CHAPTER 1. INTRODUCTION 1.1 Sequential Decomposition Decomposition of system specifications for computer-aided system design is an active topic in system synthesis research. As Gajski <ref> [27] </ref> points out, system synthesis by design partitioning and interface synthesis must be explored to make synthesis viable for large designs. Synthesis of systems with complex control structures into designs with "monolithic" control units can result in unwieldy circuits.
Reference: [28] <author> Ganesh Gopalakrishnan and Prabhat Jain. </author> <title> Some recent asynchronous system design methodologies. </title> <type> Technical Report UU-CS-TR-90-016, </type> <institution> Dept. of Computer Sc, University of Utah, </institution> <address> Salt Lake City, Utah 84112, </address> <month> October </month> <year> 1990. </year>
Reference-contexts: Dill et. al have also verified invariant conditions and deadlock avoidance in asynchronous circuits in large systems by down-scaling in the Mur' language [22, 64]. Gopalakrishnan's hopCP is an extension of HOP for formal verification of asynchronous circuits <ref> [2, 29, 28] </ref>. HOP and hopCP specifications consist of separate protocol and behavior sections representing two orthogonal facets of a process. Similarly, Interface specification language (ISL), developed in this dissertation, is used to specify only the interactions of a machine with its environment.
Reference: [29] <author> Ganesh C. Gopalakrishnan. </author> <title> Specification and verification of pipelined hardware in HOP. </title> <editor> In J.A.Darringer and F.J.Rammig, editors, </editor> <booktitle> Computer Hardware Description Languages, </booktitle> <pages> pages 117-131. </pages> <publisher> ELSEVIER, </publisher> <year> 1989. </year>
Reference-contexts: Dill et. al have also verified invariant conditions and deadlock avoidance in asynchronous circuits in large systems by down-scaling in the Mur' language [22, 64]. Gopalakrishnan's hopCP is an extension of HOP for formal verification of asynchronous circuits <ref> [2, 29, 28] </ref>. HOP and hopCP specifications consist of separate protocol and behavior sections representing two orthogonal facets of a process. Similarly, Interface specification language (ISL), developed in this dissertation, is used to specify only the interactions of a machine with its environment.
Reference: [30] <author> Ganesh C. Gopalakrishnan, Richard M. Fujimoto, Venkatesh Akella, and Narayana S. Mani. HOP: </author> <title> A process model for synchronous hardware; semantics and experiments in process composition. Integration, </title> <journal> the VLSI journal, </journal> <volume> 8 </volume> <pages> 209-247, </pages> <year> 1989. </year>
Reference-contexts: This would include most of the recent research in finite-state machine verification [12]; extensions of FSM models (e.g. [76, 72]) and Petri net theories (e.g. [11]); and model-theoretic work involving process formalisms (e.g. <ref> [54, 30] </ref>). It is typical that an area of verification research would have this orientation, and also that the top-down view would be better represented in synthesis research. In addition to Boriello's work [4], approaches to scheduling by Ku, Micheli [47] and Nestor et.al [62] have considered protocol-like constraints. 2.1. <p> The bottom-up approach models lowest levels of design as processes and composes them for higher levels of description. Each process is modeled as a state machine and composition creates a product machine of the constituent parts. Gopalakrishnan's HOP is a typical example <ref> [30] </ref>. HOP models processes as state machines with internal behavior and external protocol specifications. HOP specifications are composed using PARCOMP for system level specifications [30]. One problem encountered with this approach is state-space explosion during composition, especially for nondeterministic processes. <p> Each process is modeled as a state machine and composition creates a product machine of the constituent parts. Gopalakrishnan's HOP is a typical example <ref> [30] </ref>. HOP models processes as state machines with internal behavior and external protocol specifications. HOP specifications are composed using PARCOMP for system level specifications [30]. One problem encountered with this approach is state-space explosion during composition, especially for nondeterministic processes. PARCOMP addresses this problem by pruning extraneous paths in the product machine during construction. <p> The protocol specification of a process has two components, data and control interaction. Communication between machines is modeled as values over connected ports. Other forms of communication, such as using buffers or shared storage must be modeled explicitly. Gopalakrishnan's HOP <ref> [30] </ref> and Zhu's formalism [81] also use a similar convention of defining protocol over separate control and data ports. We begin with an informal discussion of the syntax and give an interpretation of the language in Chapter 4. 15 16 CHAPTER 3. <p> The composition operation on machines with respect to a particular connection of their ports is used to construct a machine that behaves as the constituent machines executing synchronously. The construction of the composed machine is similar to "lock-step cartesian product" in HOP <ref> [30] </ref>. Composition only creates reachable states and transitions, starting inductively from the start state. In each inductive step, the transitions in each machine that can "occur synchronously" are used to form a transition in the composed machine. <p> The restriction operation requires a set of ports to be hidden (P h ) and the composition operation requires a net-list of connected ports (N ). The operational semantic rules are defined over the abstract syntax as in <ref> [65, 56, 30] </ref>. We consider machine transitions at a time step (t) and define the relation given below by structural induction.
Reference: [31] <author> Ganesh C. Gopalakrishnan, Narayana S. Mani, and Venkatesh Akella. </author> <title> Parallel composition of lockstep synchronous processes for hardware validation: divide-and-conquer composition. </title> <editor> In A. Pneuli, J. Sifakis, and E. Clarke, editors, </editor> <title> Automatic Verification Methods for Finite State Systems, </title> <booktitle> Springer Lecture Notes in Computer Science. </booktitle> <publisher> Springer, </publisher> <address> Berlin, </address> <year> 1990. </year> <booktitle> Proceedings of the 1989 C-cube workshop, </booktitle> <address> Grenoble, </address> <note> in press. BIBLIOGRAPHY 81 </note>
Reference-contexts: It has many similarities with formal design methods for asynchronous circuits. The notion of "complement of a machine" described here is similar to Dill's description of an "environment" in trace theory [21]. Also, the composition operation described here is similar to Gopalakrishnan's PARCOMP <ref> [31] </ref>. 2.2 System Synthesis The methodology described in this dissertation explores how a system description can be decomposed into interacting components using a protocol specification with non-trivial control synchronization and data transfer interactions between components. This is different from classical FSM decomposition [20], which assumes tightly 2.2.
Reference: [32] <author> Matthew Hennessy. </author> <title> Algebraic Theory of Processes. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1988. </year>
Reference-contexts: Milner's CCS [56, 57] and Pi-calculus [58, 59] have had a great influence on the work in this dissertation. The idea of simulation in this thesis is inspired by the bisimulation relation among processes in CCS and Pi-calculus. Hen-nessy's work on process algebra <ref> [32] </ref> and Hoare's CSP [33] have also given me valuable insights into the theoritical aspects of this thesis. These process calculi have been enhanced by many researchers for applications in VLSI design verification. Milne's CIRCAL [55] is one such compositional process algebra with modeling support for buses and clocks.
Reference: [33] <author> C.A.R. Hoare. </author> <title> Communicating Sequential Processes. </title> <publisher> Prentice Hall, </publisher> <year> 1985. </year>
Reference-contexts: Milner's CCS [56, 57] and Pi-calculus [58, 59] have had a great influence on the work in this dissertation. The idea of simulation in this thesis is inspired by the bisimulation relation among processes in CCS and Pi-calculus. Hen-nessy's work on process algebra [32] and Hoare's CSP <ref> [33] </ref> have also given me valuable insights into the theoritical aspects of this thesis. These process calculi have been enhanced by many researchers for applications in VLSI design verification. Milne's CIRCAL [55] is one such compositional process algebra with modeling support for buses and clocks. <p> RELATED RESEARCH Ebergen has also studied the use of arbiters in the decomposition of asynchronous circuits [26]. Martin was the first to use formal design methods to synthesize a working asynchronous microprocessor [1]. His design method for designing self-timed circuits [51] is based on Hoare's CSP <ref> [33] </ref>. Burns has developed an automatic synthesis method for self-timed circuits based on Martin's work [10]. Dill has also used trace theory in his dissertation to verify asynchronous designs [21]. Nowick and Dill have used petri-nets for verification of asynchronous circutis [24].
Reference: [34] <author> Gerard J. Holzmann. </author> <title> Tracing protocols. </title> <editor> In Yemini, editor, </editor> <booktitle> Current Advances in Distributed Computing and Communications, </booktitle> <pages> pages 189-207. </pages> <publisher> Computer Science Press Inc, </publisher> <year> 1987. </year>
Reference-contexts: Drusinsky and Harel have used state-charts for hierarchical description of hardware and synthesis of component machines [25]. Holzmann formulated search heuristics to reduce the search space and time for validation of communication protocols <ref> [34] </ref>. State space explosion is often a problem in bottom-up verification methods using finite state machine models. This occurs in the construction of the product machine. These techniques require the designer to model a system as a network of processes with predefined interactions.
Reference: [35] <author> J.E. Hopcroft and J.D. Ullman. </author> <title> Introduction to Automata Theory, Languages and Computation. </title> <publisher> Addison Wesley, </publisher> <year> 1979. </year>
Reference-contexts: state machine is preserved. [E 1 X E 2 ] [ E 1 ] fi [ E 2 ] where [E 1 ] fi [E 2 ] denotes the product machine of [E 1 ]; [E 2 ] The construction of the product machine is similar to the description in <ref> [35] </ref>. The start state in the product machine corresponds to the product state formed by the start states of both machines.
Reference: [36] <author> Warren A. Hunt. </author> <title> Microprocessor design verification. </title> <journal> Journal of Automated Reasoning, </journal> <volume> 5 </volume> <pages> 429-460, </pages> <year> 1989. </year>
Reference-contexts: Hunt has used the Boyer-Moore Nqthm theorem prover to verify the correctness of the layout of the FM9001 microprocessor against its high-level specification [37, 8]. His earlier verification exercises included the verification of the FM8501 microprocessor <ref> [36] </ref>. In a similar exercise, the Tamarack microprocessor was also verified by Joyce using HOL [44]. More recently there have been attempts to integrate these different verification methods, using theorem prover based verification for ingenious aspects of system verification and automatic BDD based methods for other verification tasks [67, 68].
Reference: [37] <author> Warren A. Hunt. </author> <title> A formal HDL and its use in the FM9001 verification. In C.A.R. </title> <editor> Hoare and M.J. Gordon, editors, </editor> <title> Mechanized Reasoning in Hardware Design. </title> <publisher> Prentice-Hall, </publisher> <year> 1992. </year>
Reference-contexts: Hunt has used the Boyer-Moore Nqthm theorem prover to verify the correctness of the layout of the FM9001 microprocessor against its high-level specification <ref> [37, 8] </ref>. His earlier verification exercises included the verification of the FM8501 microprocessor [36]. In a similar exercise, the Tamarack microprocessor was also verified by Joyce using HOL [44]. <p> The third example describes the application of sequential decomposition to derive a dynamic memory interface for a formally derived realization of the Nqthm FM9001 57 58 CHAPTER 6. EXAMPLES microprocessor specification <ref> [37] </ref>, called DDD-FM9001 [6]. Sequential decomposition of the DRAM memory interface entails extraction of a DRAM memory object from a system description that incorporates the read/write protocol and accounts for refresh cycles. <p> Embedding an implementation of a component into another introduces control synchronization and data communication mechanism between the components for correct interactions between them. The decomposed components can now be synthesized independently. 6.3 DDD-FM9001 Decomposition A realization of the Nqthm FM9001 <ref> [37] </ref> specification, called DDD-FM9001 [6], was derived using the DDD [42] derivation system. DDD is a set of mechanized transformation tools to derive boolean descriptions from iterative functional specifications. 6.3. <p> We now look at this example in the context of sequential decomposition to realize a memory interface for dynamic RAM. The DDD-FM9001 is a general purpose microprocessor realized in FPGAs, mechanically derived from Hunt's Nqthm FM9001 specification <ref> [37] </ref>. The FM9001 is a 32-bit microprocessor mechanically verified in the Nqthm theorem prover and implemented in LSI Logic's gate array technology. Details of the derivation of the DDD-FM9001 are reported in [6]. Starting with specifications for DRAM and DDD-FM9001, let us derive the system organization shown in Figure 6.8.
Reference: [38] <author> Steven D. Johnson. </author> <title> Applicative programming and digital design. </title> <booktitle> In Proceedings of 11th Annual SIGACT-SIGPLAN Symposium on Principles of Programming Languages, </booktitle> <pages> pages 218-227, </pages> <year> 1984. </year>
Reference-contexts: With the advent of automatic verification methods there is renewed interest in the industry towards verification to gain a measure of confidence in their designs. Our approach to design, called derivation is a branch of formal verification that deals with correct-by-construction reasoning <ref> [38, 40, 42, 39] </ref>. A system of equivalence preserving transformations are used to derive an implementation from a specification. We can view such a derivation as a formal proof reflecting a top-down reasoning style.
Reference: [39] <author> Steven D. Johnson. </author> <title> Synthesis of Digital Designs from Recursion Equations. </title> <publisher> MIT Press, </publisher> <address> Cambridge, </address> <year> 1984. </year> <note> ACM Distinguished Dissertation 1984. </note>
Reference-contexts: With the advent of automatic verification methods there is renewed interest in the industry towards verification to gain a measure of confidence in their designs. Our approach to design, called derivation is a branch of formal verification that deals with correct-by-construction reasoning <ref> [38, 40, 42, 39] </ref>. A system of equivalence preserving transformations are used to derive an implementation from a specification. We can view such a derivation as a formal proof reflecting a top-down reasoning style. <p> In this example, the heap is further decomposed into an allocator process and a garbage collector process. Chapter 2 Related Research The research reported in this thesis grew out of earlier work by Johnson <ref> [39, 40] </ref>, Bose [6] and Zhu [79, 78] on transformational methodology for VLSI design. DDD [5, 41] is a transformation system based on Johnson's design derivation algebra. The limitations of the functional transformation framework in dealing with factorizations of sequential components with non-trivial protocols provided the motivation for this work.
Reference: [40] <author> Steven D. Johnson. </author> <title> Manipulating logical organization with system factorizations. </title> <editor> In Leeser and Brown, editors, </editor> <title> Hardware Specification, Verification and Synthesis: </title> <booktitle> Mathematical Aspects, volume 408 of LNCS, </booktitle> <pages> pages 260-281. </pages> <publisher> Springer, </publisher> <month> July </month> <year> 1989. </year> <booktitle> Proceedings of Mathematical Sciences Institute Workshop, </booktitle> <institution> Cornell University, </institution> <year> 1989. </year> <note> 82 BIBLIOGRAPHY </note>
Reference-contexts: With the advent of automatic verification methods there is renewed interest in the industry towards verification to gain a measure of confidence in their designs. Our approach to design, called derivation is a branch of formal verification that deals with correct-by-construction reasoning <ref> [38, 40, 42, 39] </ref>. A system of equivalence preserving transformations are used to derive an implementation from a specification. We can view such a derivation as a formal proof reflecting a top-down reasoning style. <p> INTRODUCTION A specification can have many implementations and a particular derivation chooses one. Hence, the transformations themselves add information to the (accumulating) implementation. Data abstraction in high-level structural descriptions is achieved using transformations based on functional algebra. A transformation called system factorization <ref> [40] </ref> is applied to encapsulate abstract values and operations as simple sequential processes with trivial protocols. A key aspect of derivation is to impose architectural structure on a behavioral specification. Let us consider the specification of a machine with a number of different arithmetic and logical operations. <p> But, alternatively, a dynamic RAM (DRAM) would require local protocols to be followed to integrate the memory as a process. System factorization transformations are strong enough to replace abstract memory values in a design, with black-box SRAMs, for example <ref> [40] </ref>, but they need to be further generalized to replace memories with DRAMs. Such a transformation would have to incorporate the read/write protocol and account for refresh cycles. <p> In this example, the heap is further decomposed into an allocator process and a garbage collector process. Chapter 2 Related Research The research reported in this thesis grew out of earlier work by Johnson <ref> [39, 40] </ref>, Bose [6] and Zhu [79, 78] on transformational methodology for VLSI design. DDD [5, 41] is a transformation system based on Johnson's design derivation algebra. The limitations of the functional transformation framework in dealing with factorizations of sequential components with non-trivial protocols provided the motivation for this work. <p> We described a method for the decomposition of system specifications into interacting components with the interface between them derived from the protocol specifications of the components. This is an extension of the system factorization <ref> [40] </ref> transformation which is used to encapsulate abstract values and operations as simple sequential processes with trivial protocols. Sequential decomposition includes support for arbitrary interaction protocols between components in a system.
Reference: [41] <author> Steven D. Johnson and B. Bose. </author> <title> A system of digital design derivation. </title> <type> Technical Report 289, </type> <institution> Indiana University, Computer Science Department, Indiana University, </institution> <month> August </month> <year> 1989. </year>
Reference-contexts: In this example, the heap is further decomposed into an allocator process and a garbage collector process. Chapter 2 Related Research The research reported in this thesis grew out of earlier work by Johnson [39, 40], Bose [6] and Zhu [79, 78] on transformational methodology for VLSI design. DDD <ref> [5, 41] </ref> is a transformation system based on Johnson's design derivation algebra. The limitations of the functional transformation framework in dealing with factorizations of sequential components with non-trivial protocols provided the motivation for this work. <p> The limitations of the functional transformation framework in dealing with factorizations of sequential components with non-trivial protocols provided the motivation for this work. In previous derivation exercises, system factorization transformations were used to encapsulate parts of a system into abstract objects <ref> [41] </ref>. These transformations were adequate to factor objects with trivial protocols such as static RAMs, but could not be used for components with non-trivial protocols, e.g. dynamic RAMs.
Reference: [42] <author> Steven D. Johnson and Bhaskar Bose. </author> <title> A system for mechanized digital design derivation. </title> <editor> In Subramanyam, editor, </editor> <booktitle> Proceedings of ACM International Workshop on Formal Methods in VLSI Design, </booktitle> <month> January </month> <year> 1991. </year>
Reference-contexts: With the advent of automatic verification methods there is renewed interest in the industry towards verification to gain a measure of confidence in their designs. Our approach to design, called derivation is a branch of formal verification that deals with correct-by-construction reasoning <ref> [38, 40, 42, 39] </ref>. A system of equivalence preserving transformations are used to derive an implementation from a specification. We can view such a derivation as a formal proof reflecting a top-down reasoning style. <p> The decomposed components can now be synthesized independently. 6.3 DDD-FM9001 Decomposition A realization of the Nqthm FM9001 [37] specification, called DDD-FM9001 [6], was derived using the DDD <ref> [42] </ref> derivation system. DDD is a set of mechanized transformation tools to derive boolean descriptions from iterative functional specifications. 6.3. DDD-FM9001 DECOMPOSITION 65 The tool set includes a transformation called system factorization that is used to factor parts of a system specification into functional objects with trivial interactions between them. <p> Also, the semantic model of the language will have to be modified for asynchronous system design. The general methodology of decomposition will probably be applicable for asynchronous designs. The system decomposition method described here can be of use if it is included in the DDD design derivation tool set <ref> [42] </ref>. An integrated design environment based on behavior tables with transformations for different design facets must be implemented for a designer to make use of all the ideas described in this dissertation.
Reference: [43] <author> Steven D. Johnson, R.M. Wehrmeister, and B. Bose. </author> <title> On the interplay of synthesis and verification: Experiments with the FM8501 processor description. </title> <editor> In Claesen, editor, </editor> <booktitle> Applied Formal Methods for Correct VLSI Design, </booktitle> <pages> pages 385-404. </pages> <publisher> Elsevier, </publisher> <year> 1989. </year> <month> IMEC </month> <year> 1989. </year>
Reference-contexts: We can view such a derivation as a formal proof reflecting a top-down reasoning style. In this respect it should not be viewed as an alternative for deductive (i.e., conventional theorem-prover based) verification but as an alternate mode of reasoning in design <ref> [43, 80] </ref>. We can also view derivation as a formalization of synthesis, but as a formalization it is more centrally concerned with correctness in reasoning than with automated design. 1 2 CHAPTER 1. INTRODUCTION A specification can have many implementations and a particular derivation chooses one. <p> Such a transformation would have to incorporate the read/write protocol and account for refresh cycles. Another example of the problem is described in <ref> [43] </ref>, where the derivation of a microprocessor implementation required moving a naive functional model of memory to a process model with indefinite wait states. This is also one of the key problems in raising synthesis to the system level. <p> These transformations were adequate to factor objects with trivial protocols such as static RAMs, but could not be used for components with non-trivial protocols, e.g. dynamic RAMs. In the derivation of Hunt's FM8501 microprocessor using DDD, Bose derived the entire architecture of the original microprocessor except the memory interface <ref> [43] </ref>. The memory interface of the FM8501 was injected into Hunt's proof using a "oracle" object that contained a definition of the memory protocol. This could not be incorporated into the description derived by DDD because there was no mechanism to introduce the oracle into the derivation. <p> Each transformation sequence can be considered a proof script. There are limitations to the domain of designs that can be derived using this approach and that can be circumvented by integrating with verification tools <ref> [43] </ref>. DDD has been used in conjunction with other formal verification tools to verify parts of designs that could not be derived using existing transformations [7, 6]. Sheeran has also used a transformational approach to verification in the Ruby relational algebra [71, 70].
Reference: [44] <author> Jeffrey J. Joyce. </author> <title> Formal verification and implementation of a microprocessor. </title> <editor> In C. Birtwhistle and P.A Subrahmanyam, editors, </editor> <title> VLSI Specification, Verification, and Synthesis. </title> <publisher> Academic Press, </publisher> <year> 1988. </year>
Reference-contexts: His earlier verification exercises included the verification of the FM8501 microprocessor [36]. In a similar exercise, the Tamarack microprocessor was also verified by Joyce using HOL <ref> [44] </ref>. More recently there have been attempts to integrate these different verification methods, using theorem prover based verification for ingenious aspects of system verification and automatic BDD based methods for other verification tasks [67, 68].
Reference: [45] <author> L. Jozwiak and J. Kolsteren. </author> <title> An efficient method for the sequential general decomposition of sequential machines. </title> <journal> Microprocessing and Microprogramming, </journal> <volume> 31 </volume> <pages> 657-664, </pages> <year> 1991. </year>
Reference-contexts: Jozwiak et.al have developed heuristic methods for simultaneous decompositions of sequential machines into component machines by partitioning the state space, inputs and outputs <ref> [46, 45] </ref>. The inter-connections between the components are also determined heuristically by analyzing the machine structure. This method can be used to decompose a machine into sub-machines based on various area and speed constraints, but it does not take into account timing and protocol constraints in a design.
Reference: [46] <author> Lech Jozwiak. </author> <title> Simultaneous decompositions of sequential machines. </title> <journal> Micropro-cessing and Microprogramming, </journal> <volume> 30 </volume> <pages> 305-312, </pages> <year> 1990. </year>
Reference-contexts: Jozwiak et.al have developed heuristic methods for simultaneous decompositions of sequential machines into component machines by partitioning the state space, inputs and outputs <ref> [46, 45] </ref>. The inter-connections between the components are also determined heuristically by analyzing the machine structure. This method can be used to decompose a machine into sub-machines based on various area and speed constraints, but it does not take into account timing and protocol constraints in a design.
Reference: [47] <author> David Ku and Giovanni De Micheli. </author> <title> Relative scheduling under timing constraints. </title> <booktitle> In Proceedings of ACM/IEEE Design Automation Conference, </booktitle> <month> June </month> <year> 1990. </year>
Reference-contexts: It is typical that an area of verification research would have this orientation, and also that the top-down view would be better represented in synthesis research. In addition to Boriello's work [4], approaches to scheduling by Ku, Micheli <ref> [47] </ref> and Nestor et.al [62] have considered protocol-like constraints. 2.1. FORMAL METHODS 9 Kurshan uses L-automata with language and process homomorphism [49] to verify reactive systems by stepwise reduction and refinement.
Reference: [48] <author> Andreas Kuehlmann and Reinaldo A. Bergamaschi. </author> <title> High-level state machine specification and synthesis. </title> <booktitle> In Proceedings of International Conference on Computer Design: VLSI in Computers & Processors, </booktitle> <pages> pages 536-539. </pages> <publisher> IEEE, </publisher> <year> 1992. </year> <note> BIBLIOGRAPHY 83 </note>
Reference-contexts: This is different from classical FSM decomposition [20], which assumes tightly 2.2. SYSTEM SYNTHESIS 13 coupled sub-machines that can share state and input information. Kuehlmann and Bergamaschi have considered system specifications at different levels of abstraction and partitioning of control and data flow graphs to obtain smaller layouts <ref> [48] </ref>. Ya-jnik and Ciesielski perform top-down machine decomposition by partitioning outputs and states in state graphs with the objective of performance and area optimization in synthesized PLA circuits [77].
Reference: [49] <author> R. P. Kurshan. </author> <title> Analysis of discrete event simulation. </title> <editor> In Bakker, Roever, and Rozenberg, editors, </editor> <booktitle> Stepwise Refinement of Distributed Systems, </booktitle> <pages> pages 414-453. </pages> <publisher> Springer-Verlag, </publisher> <month> July </month> <year> 1989. </year> <note> LNCS 430. </note>
Reference-contexts: In addition to Boriello's work [4], approaches to scheduling by Ku, Micheli [47] and Nestor et.al [62] have considered protocol-like constraints. 2.1. FORMAL METHODS 9 Kurshan uses L-automata with language and process homomorphism <ref> [49] </ref> to verify reactive systems by stepwise reduction and refinement. He uses a bottom-up model with registers and controllers as processes at the lowest level and constructs complex systems by composing them. The bottom-up approach models lowest levels of design as processes and composes them for higher levels of description.
Reference: [50] <author> I.S. Levin. </author> <title> A hierarchical model of the interaction of micropragrammed automata. </title> <journal> Avtomatika i Vychislitelnaya Technika, </journal> <volume> 21(3) </volume> <pages> 77-83, </pages> <year> 1987. </year> <note> Translation from Russian by Allerton Press. </note>
Reference-contexts: The decomposition method described here can be used to correctly partition a design based on protocol specifications of its components. Levin describes another synthesis method in which he uses a hierarchical automata model for system specification targeted towards a network of PLAs with memory <ref> [50] </ref>. This method only supports naive interactions between constituent automata where one of the automata is in "operation" and all the others are "waiting for its response". System-level synthesis in the System Architect's Workbench is accomplished by behavioral transformations [75]. Walker and Thomas show transformations on the controller and selector.
Reference: [51] <author> A. J. Martin. </author> <title> A synthesis method for self-timed VLSI circuits. </title> <booktitle> In ICCD87: 1987 IEEE International Conference on Computer Design, </booktitle> <pages> pages 224-229. </pages> <institution> CS Dept, California Institute of Technology, Pasadena, </institution> <address> CA, </address> <publisher> IEEE Computer Society Press, </publisher> <year> 1987. </year>
Reference-contexts: RELATED RESEARCH Ebergen has also studied the use of arbiters in the decomposition of asynchronous circuits [26]. Martin was the first to use formal design methods to synthesize a working asynchronous microprocessor [1]. His design method for designing self-timed circuits <ref> [51] </ref> is based on Hoare's CSP [33]. Burns has developed an automatic synthesis method for self-timed circuits based on Martin's work [10]. Dill has also used trace theory in his dissertation to verify asynchronous designs [21]. Nowick and Dill have used petri-nets for verification of asynchronous circutis [24].
Reference: [52] <author> Kayhan Ku~cuk~cakar and Alice C. Parker. CHOP: </author> <title> A constraint-driven system-level partitioner. </title> <booktitle> In Proceedings of the 28th ACM/IEEE Design Automation Conference, </booktitle> <pages> pages 514-519, </pages> <year> 1991. </year>
Reference-contexts: Their approach can not synthesize components using complex protocols for data transfers and synchronization, e.g. a 4-cycle handshake protocol. SpecPart [74] partitions algorithm/process grained computations from the Spec-Chart behavioral specifications. Default protocols are used for interaction between components. The CHOP system-level design partitioner <ref> [52] </ref> uses task graphs to specify the protocol between every partition. Special purpose hardware units called data-transfer modules are used on both sides of each interaction.
Reference: [53] <author> Kenneth L. McMillan and David L. Dill. </author> <title> Algorithms for interface timing verification. </title> <booktitle> In Proceedings of IEEE International Conference on Computer Design, </booktitle> <pages> pages 48-51. </pages> <publisher> IEEE Computer Society, </publisher> <month> November </month> <year> 1992. </year>
Reference-contexts: Dill et.al have used a Buchi automata based model to verify safety and liveness properties using language containment [23]. McMillan and Dill have also modelled timing constraints as min/max constraints and used a generalized branch and bound algorithm to verify the timing specification of connected components <ref> [53] </ref>. Drusinsky and Harel have used state-charts for hierarchical description of hardware and synthesis of component machines [25]. Holzmann formulated search heuristics to reduce the search space and time for validation of communication protocols [34].
Reference: [54] <author> George J. Milne. CIRCAL: </author> <title> A calculus for circuit description. </title> <journal> Integration, </journal> <volume> 1 </volume> <pages> 121-160, </pages> <year> 1983. </year>
Reference-contexts: This would include most of the recent research in finite-state machine verification [12]; extensions of FSM models (e.g. [76, 72]) and Petri net theories (e.g. [11]); and model-theoretic work involving process formalisms (e.g. <ref> [54, 30] </ref>). It is typical that an area of verification research would have this orientation, and also that the top-down view would be better represented in synthesis research. In addition to Boriello's work [4], approaches to scheduling by Ku, Micheli [47] and Nestor et.al [62] have considered protocol-like constraints. 2.1.
Reference: [55] <author> George J. Milne. </author> <title> Design for verifiability. </title> <editor> In Leeser and Brown, editors, </editor> <title> Hardware Specification, Verification and Synthesis: </title> <journal> Mathematical Aspects, </journal> <pages> pages 1-13. </pages> <publisher> Springer, </publisher> <month> July </month> <year> 1989. </year> <note> LNCS 408. </note>
Reference-contexts: Hen-nessy's work on process algebra [32] and Hoare's CSP [33] have also given me valuable insights into the theoritical aspects of this thesis. These process calculi have been enhanced by many researchers for applications in VLSI design verification. Milne's CIRCAL <ref> [55] </ref> is one such compositional process algebra with modeling support for buses and clocks. Other bottom-up formal verification methods based on process algebras include [63, 15, 16]. Davie [17] takes a top-down approach to design using verification between specification and implementation steps in CIRCAL.
Reference: [56] <author> Robin Milner. </author> <title> Calculi for synchrony and asynchrony. </title> <journal> Theoretical Computer Science, </journal> <volume> 25 </volume> <pages> 267-310, </pages> <year> 1983. </year>
Reference-contexts: T-Ruby [69] have developed a rewriting tool based on the Ruby algebra for VLSI design derivation. 2.1. FORMAL METHODS 11 2.1.3 Process Calculi Process calculi provide an elegant formal basis for reasoning about interacting sequential systems. Milner's CCS <ref> [56, 57] </ref> and Pi-calculus [58, 59] have had a great influence on the work in this dissertation. The idea of simulation in this thesis is inspired by the bisimulation relation among processes in CCS and Pi-calculus. <p> The restriction operation requires a set of ports to be hidden (P h ) and the composition operation requires a net-list of connected ports (N ). The operational semantic rules are defined over the abstract syntax as in <ref> [65, 56, 30] </ref>. We consider machine transitions at a time step (t) and define the relation given below by structural induction.
Reference: [57] <author> Robin Milner. </author> <title> Communication and Concurrency. </title> <publisher> Prentice Hall, </publisher> <year> 1989. </year> <note> 84 BIBLIOGRAPHY </note>
Reference-contexts: T-Ruby [69] have developed a rewriting tool based on the Ruby algebra for VLSI design derivation. 2.1. FORMAL METHODS 11 2.1.3 Process Calculi Process calculi provide an elegant formal basis for reasoning about interacting sequential systems. Milner's CCS <ref> [56, 57] </ref> and Pi-calculus [58, 59] have had a great influence on the work in this dissertation. The idea of simulation in this thesis is inspired by the bisimulation relation among processes in CCS and Pi-calculus.
Reference: [58] <author> Robin Milner. </author> <title> Elements of interaction. </title> <journal> Communications of the ACM, </journal> <volume> 36(1) </volume> <pages> 78-89, </pages> <month> January </month> <year> 1993. </year> <note> Turing award lecture. </note>
Reference-contexts: T-Ruby [69] have developed a rewriting tool based on the Ruby algebra for VLSI design derivation. 2.1. FORMAL METHODS 11 2.1.3 Process Calculi Process calculi provide an elegant formal basis for reasoning about interacting sequential systems. Milner's CCS [56, 57] and Pi-calculus <ref> [58, 59] </ref> have had a great influence on the work in this dissertation. The idea of simulation in this thesis is inspired by the bisimulation relation among processes in CCS and Pi-calculus.
Reference: [59] <author> Robin Milner, Joachim Parrow, and David Walker. </author> <title> A calculus of mobile processes i and ii. </title> <journal> Information and Computation, </journal> <volume> 100(1) 1-40,41-77, </volume> <month> September </month> <year> 1992. </year>
Reference-contexts: T-Ruby [69] have developed a rewriting tool based on the Ruby algebra for VLSI design derivation. 2.1. FORMAL METHODS 11 2.1.3 Process Calculi Process calculi provide an elegant formal basis for reasoning about interacting sequential systems. Milner's CCS [56, 57] and Pi-calculus <ref> [58, 59] </ref> have had a great influence on the work in this dissertation. The idea of simulation in this thesis is inspired by the bisimulation relation among processes in CCS and Pi-calculus.
Reference: [60] <author> Paul Miner. </author> <title> Verification of fault-tolerant clock synchronization systems. </title> <type> Technical Report 3349, </type> <institution> National Aeronautics and Space Administration, Hampton, VA, </institution> <month> November </month> <year> 1993. </year>
Reference-contexts: collect to be asserted and then after a finite interval asserts gc-active. gc (collect,gc-active)(M ) 4 [; await collect=T ; compute gc-active=F; fM = garbage-collect (M )g] fl 3.2.4 Clock Synchronizer In this section we develop a protocol specification for a fault-tolerant clock synchronizer from formal and informal descriptions in <ref> [60] </ref>. Four or more such clock synchronizer elements periodically synchronizing their individual clocks using a voting 24 CHAPTER 3. A LANGUAGE FOR PROTOCOL SPECIFICATION scheme can provide a fault tolerant clock.
Reference: [61] <author> David E. Muller and W. S. Bartky. </author> <title> A theory of asynchronous circuits. </title> <journal> The Annals of the Computation Laboratory of Harvard University, </journal> <volume> 29 </volume> <pages> 204-243, </pages> <month> April </month> <year> 1959. </year>
Reference-contexts: It has no restrictions and is central to the decomposition exercise. 2.1.4 Asynchronous Design Methods Formal methods have been used by many researchers for asynchronous circuit design. The problem of arbitration in asynchronous circuits was first addressed by Muller <ref> [61] </ref>. 12 CHAPTER 2. RELATED RESEARCH Ebergen has also studied the use of arbiters in the decomposition of asynchronous circuits [26]. Martin was the first to use formal design methods to synthesize a working asynchronous microprocessor [1].
Reference: [62] <author> J. A. Nestor and D. Thomas. </author> <title> Behavioral synthesis with interfaces. </title> <booktitle> In Proceedings of ICCAD, </booktitle> <month> November </month> <year> 1986. </year>
Reference-contexts: It is typical that an area of verification research would have this orientation, and also that the top-down view would be better represented in synthesis research. In addition to Boriello's work [4], approaches to scheduling by Ku, Micheli [47] and Nestor et.al <ref> [62] </ref> have considered protocol-like constraints. 2.1. FORMAL METHODS 9 Kurshan uses L-automata with language and process homomorphism [49] to verify reactive systems by stepwise reduction and refinement. He uses a bottom-up model with registers and controllers as processes at the lowest level and constructs complex systems by composing them.
Reference: [63] <author> Xavier Nicollin and Joseph Sifakis. </author> <title> An overview and synthesis on timed process algebras. </title> <editor> In Larsen and Skou, editors, </editor> <booktitle> Proceedings of International Conference on Computer Aided Verification, </booktitle> <pages> pages 376-398. </pages> <publisher> Springer, </publisher> <month> July </month> <year> 1991. </year> <note> LNCS 575. </note>
Reference-contexts: These process calculi have been enhanced by many researchers for applications in VLSI design verification. Milne's CIRCAL [55] is one such compositional process algebra with modeling support for buses and clocks. Other bottom-up formal verification methods based on process algebras include <ref> [63, 15, 16] </ref>. Davie [17] takes a top-down approach to design using verification between specification and implementation steps in CIRCAL. The description of components are composed together for verification with respect to the specification.
Reference: [64] <author> Steven M. Nowick, Kenneth Y. Yun, and David L. Dill. </author> <title> Practical asynchronous controller design. </title> <booktitle> In Proceedings of International Conference on Computer Design, </booktitle> <pages> pages 341-345. </pages> <publisher> IEEE, </publisher> <year> 1992. </year>
Reference-contexts: Dill has also used trace theory in his dissertation to verify asynchronous designs [21]. Nowick and Dill have used petri-nets for verification of asynchronous circutis [24]. Dill et. al have also verified invariant conditions and deadlock avoidance in asynchronous circuits in large systems by down-scaling in the Mur' language <ref> [22, 64] </ref>. Gopalakrishnan's hopCP is an extension of HOP for formal verification of asynchronous circuits [2, 29, 28]. HOP and hopCP specifications consist of separate protocol and behavior sections representing two orthogonal facets of a process.
Reference: [65] <author> G.D. Plotkin. </author> <title> A structural approach to operational semantics. </title> <type> Technical Report DAIMI FN-19, </type> <institution> Aarhus University, Denmark, </institution> <year> 1981. </year>
Reference-contexts: The restriction operation requires a set of ports to be hidden (P h ) and the composition operation requires a net-list of connected ports (N ). The operational semantic rules are defined over the abstract syntax as in <ref> [65, 56, 30] </ref>. We consider machine transitions at a time step (t) and define the relation given below by structural induction.
Reference: [66] <author> Kamlesh Rath, M. Esen Tuna, and Steven D. Johnson. </author> <title> Behavior tables: A basis for system representation and transformational system synthesis. </title> <booktitle> In Proceedings of the International Conference on Computer Aided Design (ICCAD). IEEE, </booktitle> <month> November </month> <year> 1993. </year> <note> BIBLIOGRAPHY 85 </note>
Reference-contexts: Similarly, Interface specification language (ISL), developed in this dissertation, is used to specify only the interactions of a machine with its environment. Other facets of a system specification can be expressed in other forms, e.g. behavior tables <ref> [66] </ref>. The theory developed in this dissertation provides a model and decomposition method for globally synchronous systems. It has many similarities with formal design methods for asynchronous circuits. The notion of "complement of a machine" described here is similar to Dill's description of an "environment" in trace theory [21]. <p> Behavior tables are an extension of register-transfer tables and provide a unified basis for system representation for reasoning about all facets of system design <ref> [66] </ref>. Starting from a specification with symbolic data values, transformations can be used by a designer to direct the design towards an implementation of interacting behavior tables with boolean data representation and appropriate control and datapath abstractions.
Reference: [67] <author> Klaus Schneider, Ramayya Kumar, and Thomas Kropf. </author> <title> Hardware verification using first order BDDs. </title> <booktitle> In Proceedings of IFIP Conference on Hardware Description Languages and their Applications (CHDL), </booktitle> <year> 1993. </year>
Reference-contexts: In a similar exercise, the Tamarack microprocessor was also verified by Joyce using HOL [44]. More recently there have been attempts to integrate these different verification methods, using theorem prover based verification for ingenious aspects of system verification and automatic BDD based methods for other verification tasks <ref> [67, 68] </ref>. The transformational approach to system design is an alternate form of deductive verification where an implementation is derived from a specification using correctness preserving transformations. Since the transformations assure the integrity of the resulting system it obviates the need to verify each implementation against its specification.
Reference: [68] <author> Carl-Johan Seger and Jeffrey J. Joyce. </author> <title> A two-level formal verification methodology using HOL and COSMOS. </title> <booktitle> In Proceedings of Computer Aided Verification Conference, </booktitle> <pages> pages 299-309. </pages> <publisher> Springer, </publisher> <month> July </month> <year> 1991. </year> <note> LNCS 575. </note>
Reference-contexts: In a similar exercise, the Tamarack microprocessor was also verified by Joyce using HOL [44]. More recently there have been attempts to integrate these different verification methods, using theorem prover based verification for ingenious aspects of system verification and automatic BDD based methods for other verification tasks <ref> [67, 68] </ref>. The transformational approach to system design is an alternate form of deductive verification where an implementation is derived from a specification using correctness preserving transformations. Since the transformations assure the integrity of the resulting system it obviates the need to verify each implementation against its specification.
Reference: [69] <author> Robin Sharp and Ole Rasmussen. </author> <title> Rewriting and constraints in t-ruby. </title> <editor> In Milne and Pierre, editors, </editor> <booktitle> IFIP Conference on Correct Hardware Design and Verification Methods, </booktitle> <pages> pages 226-241. </pages> <publisher> Springer, </publisher> <month> May </month> <year> 1993. </year> <note> LNCS 683. </note>
Reference-contexts: DDD has been used in conjunction with other formal verification tools to verify parts of designs that could not be derived using existing transformations [7, 6]. Sheeran has also used a transformational approach to verification in the Ruby relational algebra [71, 70]. T-Ruby <ref> [69] </ref> have developed a rewriting tool based on the Ruby algebra for VLSI design derivation. 2.1. FORMAL METHODS 11 2.1.3 Process Calculi Process calculi provide an elegant formal basis for reasoning about interacting sequential systems.
Reference: [70] <author> Mary Sheeran. muFP, </author> <title> An algebraic VLSI design language. </title> <booktitle> In ACM Symposium on LISP and Functional Programming, </booktitle> <pages> pages 104-112, </pages> <year> 1984. </year>
Reference-contexts: DDD has been used in conjunction with other formal verification tools to verify parts of designs that could not be derived using existing transformations [7, 6]. Sheeran has also used a transformational approach to verification in the Ruby relational algebra <ref> [71, 70] </ref>. T-Ruby [69] have developed a rewriting tool based on the Ruby algebra for VLSI design derivation. 2.1. FORMAL METHODS 11 2.1.3 Process Calculi Process calculi provide an elegant formal basis for reasoning about interacting sequential systems.
Reference: [71] <editor> Mary Sheeran. Retiming and slowdown in ruby. In Milne, editor, </editor> <booktitle> The fusion of hardware design and verification, </booktitle> <pages> pages 285-308. </pages> <publisher> IFIP, North-Holland, </publisher> <year> 1988. </year>
Reference-contexts: DDD has been used in conjunction with other formal verification tools to verify parts of designs that could not be derived using existing transformations [7, 6]. Sheeran has also used a transformational approach to verification in the Ruby relational algebra <ref> [71, 70] </ref>. T-Ruby [69] have developed a rewriting tool based on the Ruby algebra for VLSI design derivation. 2.1. FORMAL METHODS 11 2.1.3 Process Calculi Process calculi provide an elegant formal basis for reasoning about interacting sequential systems.
Reference: [72] <author> Andres R. Takach and Wayne Wolf. </author> <title> Behavior FSMs for high-level synthesis and verification. </title> <type> Technical Report CE-W91-13, </type> <institution> Dept. of Electrical Engineering, Princeton University, </institution> <month> July </month> <year> 1991. </year>
Reference-contexts: Most formal treatments of system decomposition are bottom-up in the sense that they are oriented toward post-design verification. This would include most of the recent research in finite-state machine verification [12]; extensions of FSM models (e.g. <ref> [76, 72] </ref>) and Petri net theories (e.g. [11]); and model-theoretic work involving process formalisms (e.g. [54, 30]). It is typical that an area of verification research would have this orientation, and also that the top-down view would be better represented in synthesis research.
Reference: [73] <author> Texas Instruments. </author> <title> MOS Memory Data Book, </title> <year> 1989. </year>
Reference-contexts: To keep the specification brief, we consider the normal modes of operation of the DRAM chip TI-TMS4256. A timing diagram of the read and CAS-before-RAS refresh cycle, in the normal modes of operation, adapted from the TI-TMS4256 data sheets <ref> [73] </ref> is shown in Figures 3.4 and 3.5. The write cycle is similar to the read cycle.
Reference: [74] <author> Frank Vahid and Daniel D. Gajski. </author> <title> Specification partitioning for system design. </title> <booktitle> In Proceedings of the 29th ACM/IEEE Design Automation Conference, </booktitle> <pages> pages 219-224, </pages> <year> 1992. </year>
Reference-contexts: RELATED RESEARCH shown. The processes created using their method have a very simple interaction scheme to transfer data values and control signals using message passing. Their approach can not synthesize components using complex protocols for data transfers and synchronization, e.g. a 4-cycle handshake protocol. SpecPart <ref> [74] </ref> partitions algorithm/process grained computations from the Spec-Chart behavioral specifications. Default protocols are used for interaction between components. The CHOP system-level design partitioner [52] uses task graphs to specify the protocol between every partition. Special purpose hardware units called data-transfer modules are used on both sides of each interaction.
Reference: [75] <author> Robert A. Walker and Donald E. Thomas. </author> <title> Behavioral transformation for algorithmic level IC design. </title> <journal> IEEE Transactions on Computer-Aided Design, </journal> <volume> 8(10) </volume> <pages> 1115-1128, </pages> <year> 1989. </year>
Reference-contexts: This method only supports naive interactions between constituent automata where one of the automata is in "operation" and all the others are "waiting for its response". System-level synthesis in the System Architect's Workbench is accomplished by behavioral transformations <ref> [75] </ref>. Walker and Thomas show transformations on the controller and selector. Transformations to partition a design into processes are also 14 CHAPTER 2. RELATED RESEARCH shown. The processes created using their method have a very simple interaction scheme to transfer data values and control signals using message passing.
Reference: [76] <author> Wayne Wolf, Andres Takach, and Tien-Chien Lee. </author> <title> Architectural optimization methods for control-dominated machines. </title> <booktitle> High-Level VLSI Synthesis, </booktitle> <pages> pages 231-254, </pages> <year> 1991. </year>
Reference-contexts: Most formal treatments of system decomposition are bottom-up in the sense that they are oriented toward post-design verification. This would include most of the recent research in finite-state machine verification [12]; extensions of FSM models (e.g. <ref> [76, 72] </ref>) and Petri net theories (e.g. [11]); and model-theoretic work involving process formalisms (e.g. [54, 30]). It is typical that an area of verification research would have this orientation, and also that the top-down view would be better represented in synthesis research.
Reference: [77] <author> Maya K. Yajnik and Maciej J. Ciesielski. </author> <title> Finite state machine decomposition using multi-way partitioning. </title> <booktitle> In Proceedings of International Conference on Computer Design: VLSI in Computers & Processors, </booktitle> <pages> pages 320-323. </pages> <publisher> IEEE, </publisher> <year> 1992. </year>
Reference-contexts: Ya-jnik and Ciesielski perform top-down machine decomposition by partitioning outputs and states in state graphs with the objective of performance and area optimization in synthesized PLA circuits <ref> [77] </ref>. Jozwiak et.al have developed heuristic methods for simultaneous decompositions of sequential machines into component machines by partitioning the state space, inputs and outputs [46, 45]. The inter-connections between the components are also determined heuristically by analyzing the machine structure.
Reference: [78] <author> Zheng Zhu. </author> <title> Structured Hardware Design Transformations. </title> <type> PhD thesis, </type> <institution> Computer Science Department, Indiana University, USA, </institution> <year> 1992. </year>
Reference-contexts: In this example, the heap is further decomposed into an allocator process and a garbage collector process. Chapter 2 Related Research The research reported in this thesis grew out of earlier work by Johnson [39, 40], Bose [6] and Zhu <ref> [79, 78] </ref> on transformational methodology for VLSI design. DDD [5, 41] is a transformation system based on Johnson's design derivation algebra. The limitations of the functional transformation framework in dealing with factorizations of sequential components with non-trivial protocols provided the motivation for this work. <p> Zhu developed a method to automatically synthesize the interface between two interacting sequential systems by solving the timing constraint equations for the dif 7 8 CHAPTER 2. RELATED RESEARCH ferent ports of the systems <ref> [81, 78] </ref>. His method performs adequately for simple protocols, but can not compose systems with complex interactions like a 4-cycle handshake.
Reference: [79] <author> Zheng Zhu. </author> <title> Automatic synthesis of sequential synchronizations. </title> <editor> In D. Ag-new, L. Claesen, and R. Camposano, editors, </editor> <booktitle> Proceedings of IFIP Conference on Hardware Description Languages and their Applications, </booktitle> <pages> pages 285-301. </pages> <address> El-sevier, </address> <month> April </month> <year> 1993. </year>
Reference-contexts: In this example, the heap is further decomposed into an allocator process and a garbage collector process. Chapter 2 Related Research The research reported in this thesis grew out of earlier work by Johnson [39, 40], Bose [6] and Zhu <ref> [79, 78] </ref> on transformational methodology for VLSI design. DDD [5, 41] is a transformation system based on Johnson's design derivation algebra. The limitations of the functional transformation framework in dealing with factorizations of sequential components with non-trivial protocols provided the motivation for this work.
Reference: [80] <author> Zheng Zhu and Steven D. Johnson. </author> <title> An example of digital design transformation in an algebraic framework. </title> <editor> In Subramanyam, editor, </editor> <booktitle> Proceedings of ACM International Workshop on Formal Methods in VLSI Design, </booktitle> <month> January </month> <year> 1991. </year>
Reference-contexts: We can view such a derivation as a formal proof reflecting a top-down reasoning style. In this respect it should not be viewed as an alternative for deductive (i.e., conventional theorem-prover based) verification but as an alternate mode of reasoning in design <ref> [43, 80] </ref>. We can also view derivation as a formalization of synthesis, but as a formalization it is more centrally concerned with correctness in reasoning than with automated design. 1 2 CHAPTER 1. INTRODUCTION A specification can have many implementations and a particular derivation chooses one.
Reference: [81] <author> Zheng Zhu and Steven D. Johnson. </author> <title> Automatic synthesis of sequential synchronizations. </title> <editor> In D. Agnew, L. Claesen, and R. Camposano, editors, </editor> <booktitle> Proceedings of IFIP Conference on Hardware Description Languages and their Applications, </booktitle> <pages> pages 285-301. </pages> <publisher> Elsevier, </publisher> <month> April </month> <year> 1993. </year> <note> Also published as Technical Report No. 373, </note> <institution> Dept. of Computer Science, Indiana University. </institution>
Reference-contexts: Zhu developed a method to automatically synthesize the interface between two interacting sequential systems by solving the timing constraint equations for the dif 7 8 CHAPTER 2. RELATED RESEARCH ferent ports of the systems <ref> [81, 78] </ref>. His method performs adequately for simple protocols, but can not compose systems with complex interactions like a 4-cycle handshake. <p> The protocol specification of a process has two components, data and control interaction. Communication between machines is modeled as values over connected ports. Other forms of communication, such as using buffers or shared storage must be modeled explicitly. Gopalakrishnan's HOP [30] and Zhu's formalism <ref> [81] </ref> also use a similar convention of defining protocol over separate control and data ports. We begin with an informal discussion of the syntax and give an interpretation of the language in Chapter 4. 15 16 CHAPTER 3.
Reference: [82] <author> Zheng Zhu and Steven D. Johnson. </author> <title> Capturing synchronization specifications for sequential compositions. </title> <booktitle> In Proceedings of the 1994 IEEE International Conference on Computer Design (ICCD 94), </booktitle> <pages> pages 117-121. </pages> <publisher> IEEE, </publisher> <month> October </month> <year> 1994. </year> <month> 86 </month>
Reference-contexts: The transition path in the component with the matching term forms the basis for choosing the path implementation of its complement that is grafted into the original specification. The criteria described above can not deal with factoring sub-terms from specifications. Zhu describes an algebra in <ref> [82] </ref> can be used in a more general treatment of functional correctness. The decomposition technique described here was developed for designing systems with globally synchronous communications and a common synchronizing reference. Many of the concepts presented here are similar to asynchronous self-timed design methods.
References-found: 82

