URL: http://www.iscs.nus.sg/~plong/papers/output.ps
Refering-URL: 
Root-URL: 
Title: The Composition of Messages in Speech-Graphics Interactive Systems  
Author: Alan W. Biermann Philip M. Long 
Address: P.O. Box 90129 Durham, NC 27708 USA  Singapore 119260, Republic of Singapore  
Affiliation: Department of Computer Science Duke University,  ISCS Department National University of Singapore  
Abstract: We consider the problem of multimodal message generation. The main ideas of this paper are to unify the treatment of speech, text and graphics using a single grammar, and to adapt an evaluation function used to estimate the subjective quality of proposed messages by observing the time it takes the user to respond to them. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A.W. Biermann, C.I. Guinn, M. Fulkerson, G. Keim, Z. Liang, D. Melamed, and K. Rajagopalan. </author> <title> Goal-oriented multimedia dialogue with variable initiative, </title> <note> 1996. Submitted. </note>
Reference-contexts: 1 Introduction The work described in this paper is part of a larger ongoing effort by the Duke Voice and Natural Language Lab to develop speech-graphics interactive dialogue systems <ref> [2, 7, 1] </ref> built around a theorem proving mechanism. The system attempts to prove that some global goal is achievable, and if it is successful, no significant dialogue takes place. <p> The main idea is to unify the treatment of speech, text and graphics, in contrast with the usual practice in multimodal message generation (see [8, 9, 3, 5]). 1 Our implementation is part of a Pascal tutor being developed by members of the Duke Voice and Natural Language Lab (see <ref> [1] </ref>).
Reference: [2] <author> A.W. Biermann, C.I. Guinn, D.R. Hipp, and R.W. Smith. </author> <title> Efficient collaborative discourse: A theory and its implementation. </title> <booktitle> Proceedings of the ARPA Human Language Technology Workshop, </booktitle> <year> 1993. </year>
Reference-contexts: 1 Introduction The work described in this paper is part of a larger ongoing effort by the Duke Voice and Natural Language Lab to develop speech-graphics interactive dialogue systems <ref> [2, 7, 1] </ref> built around a theorem proving mechanism. The system attempts to prove that some global goal is achievable, and if it is successful, no significant dialogue takes place.
Reference: [3] <author> S.K. Feiner and K.R. McKeown. </author> <title> Automating the generation of coordinated multimedia explanations, </title> <address> pages 113-134. </address> <publisher> AAAI/MIT Press, </publisher> <year> 1993. </year> <title> In Intelligent Multimedia Interfaces, M.T. </title> <publisher> Maybury (ed.). </publisher>
Reference-contexts: The main idea is to unify the treatment of speech, text and graphics, in contrast with the usual practice in multimodal message generation (see <ref> [8, 9, 3, 5] </ref>). 1 Our implementation is part of a Pascal tutor being developed by members of the Duke Voice and Natural Language Lab (see [1]).
Reference: [4] <author> P.M. </author> <title> Long. On-line evaluation and prediction using linear functions, </title> <note> 1996. Submitted. </note>
Reference-contexts: Our solution to this problem is to build a selection function into the generator system that evaluates the quality of semantically equivalent messages and then chooses which one to actually pass to the user. We show how to apply theoretical work about learning linear evaluation functions <ref> [4] </ref> to enable this selection function to adapt to users' preferences on line and thus self-modify to become maximally habitable. <p> and the algorithm searches the space of lists of strings by applying the operators, keeping track at any time of the least cost solution found so far and the running cost of the current partial solution, and pruning as described above. 3 Adaptive message evaluation Motivated by this problem, Long <ref> [4] </ref> has proposed a theoretical model for situations where an algorithm needs to make a sequence of choices to minimize an evaluation function, but where the evaluation function must be learned on-line as it is being used. <p> The algorithm's choices may be randomized. Long <ref> [4] </ref> also analyzed several algorithms for learning linear evaluation functions in the above model, in the case in which X = R d , that is, where associated with each message was a fixed set of numerical features, and where the function from the features to the algorithm's estimate of the <p> Our initial implementation uses the very crude measure of the total time between when a message was sent, and when the user next queries the tutor as reinforcement for the learning algorithm. Since the algorithms of <ref> [4] </ref> are highly robust with respect to noisy data, they have potential to be useful with such noisy feedback, and our initial experience using the system suggests that it indeed learns to output subjectively good messages using such crude, however objective and passively obtained, feedback. 3.2 Features To illustrate how we <p> This implies that a linear function of these features is an appropriate cost model, and therefore that the analysis of the learning algorithm from <ref> [4] </ref> is relevant to this setting. 3.3 Pruning The algorithms analyzed in [4] had a nonzero probability of picking any message. Due to the large number of possible messages, it is difficult to sample from all of them according to the distributions described in [4]. <p> This implies that a linear function of these features is an appropriate cost model, and therefore that the analysis of the learning algorithm from <ref> [4] </ref> is relevant to this setting. 3.3 Pruning The algorithms analyzed in [4] had a nonzero probability of picking any message. Due to the large number of possible messages, it is difficult to sample from all of them according to the distributions described in [4]. <p> analysis of the learning algorithm from <ref> [4] </ref> is relevant to this setting. 3.3 Pruning The algorithms analyzed in [4] had a nonzero probability of picking any message. Due to the large number of possible messages, it is difficult to sample from all of them according to the distributions described in [4]. Instead, in our implementation, the output system first generates a list of the lowest cost alternatives (according to the current cost function), and this is in turn passed to the learning algorithm. <p> Setting the threshold in terms of cost relative to the lowest cost alternative, rather than to have a fixed number of lowest cost alternatives, facilitates pruning and therefore efficient implementation. This results in a nonconstant number of alternatives being presented at each "trial", but the algorithms of <ref> [4] </ref> are easily modified to cope with this. 4 Conclusion We have implemented this system and integrated it into a Pascal tutor being developed with other members of the Duke Voice and Natural Language Lab. <p> Our immediate plans for extending this research involve evaluating the message generation system of this paper experimentally using human subjects. Possible experiments include the comparing the performance of the system in adaptive vs. nonadaptive mode, and comparing the performance of the adaptation algorithm based on <ref> [4] </ref> vs. an analogous system in which the currently least cost solution is always chosen, i.e. one that ignores the "exploration/exploitation" tradeoff.
Reference: [5] <editor> M.T. Maybury, editor. </editor> <title> Intelligent Multimedia Interfaces. </title> <publisher> AAAI/MIT Press, </publisher> <year> 1993. </year>
Reference-contexts: The main idea is to unify the treatment of speech, text and graphics, in contrast with the usual practice in multimodal message generation (see <ref> [8, 9, 3, 5] </ref>). 1 Our implementation is part of a Pascal tutor being developed by members of the Duke Voice and Natural Language Lab (see [1]).
Reference: [6] <author> J.G. Neal and S.C. Shapiro. </author> <booktitle> Intelligent multi-media interface technology, </booktitle> <pages> pages 11-43. </pages> <publisher> ACM press, </publisher> <year> 1991. </year> <title> In Intelligent User Interfaces, J.W. Sullivan and S.W. </title> <type> Tyler (eds.). </type>
Reference-contexts: An example of a noun operator is the LINE operator. A precondition for the application of the LINE operator is that the 1 Neal and Shapiro <ref> [6] </ref> alluded to the use of a unified grammar for parsing multimodal input. set of strings currently referred to consists of a single string. Applying the LINE operator results in this string being broken into several strings, one for each line in the original string.
Reference: [7] <author> R.W. Smith and D.R. </author> <title> Hipp. Spoken Natural Language Dialogue Systems. </title> <publisher> Oxford Press, </publisher> <year> 1994. </year>
Reference-contexts: 1 Introduction The work described in this paper is part of a larger ongoing effort by the Duke Voice and Natural Language Lab to develop speech-graphics interactive dialogue systems <ref> [2, 7, 1] </ref> built around a theorem proving mechanism. The system attempts to prove that some global goal is achievable, and if it is successful, no significant dialogue takes place.
Reference: [8] <editor> J.W. Sullivan and S.W. Tyler, editors. </editor> <title> Intelligent User Interfaces. </title> <publisher> ACM press, </publisher> <year> 1991. </year>
Reference-contexts: The main idea is to unify the treatment of speech, text and graphics, in contrast with the usual practice in multimodal message generation (see <ref> [8, 9, 3, 5] </ref>). 1 Our implementation is part of a Pascal tutor being developed by members of the Duke Voice and Natural Language Lab (see [1]).
Reference: [9] <author> W. Wahlster. </author> <title> User and Discourse Models for Multimodal Communication, </title> <address> pages 45-67. </address> <publisher> ACM press, </publisher> <year> 1991. </year> <title> In Intelligent User Interfaces, J.W. Sullivan and S.W. </title> <type> Tyler (eds.). </type>
Reference-contexts: The main idea is to unify the treatment of speech, text and graphics, in contrast with the usual practice in multimodal message generation (see <ref> [8, 9, 3, 5] </ref>). 1 Our implementation is part of a Pascal tutor being developed by members of the Duke Voice and Natural Language Lab (see [1]).
References-found: 9

