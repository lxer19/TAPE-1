URL: http://www.cs.berkeley.edu/~alanm/CP/edwards.sigcomm.94.ps
Refering-URL: http://www.cs.berkeley.edu/~alanm/CP/bib.html
Root-URL: 
Title: Abstract Two important questions in high-speed networking are firstly, how to provide Gbit/s networking at
Abstract: We describe some work that addresses both of these questions. The Jetstream Gbit/s LAN is an experimental, low-cost network interface that provides the services required by delay-sensitive traffic as well as meeting the performance needs of current applications. Jetstream is a combination of traditional shared-medium LAN technology and more recent ATM cell- and switch-based technology. Jetstream frames contain a channel identifier so that the network driver can immediately associate an incoming frame with its application. We have developed such a driver that enables applications to control how their data should be managed without the need to first move the data into the applications address space. Consequently, applications can elect to read just a part of a frame and then instruct the driver to move the remainder directly to its destination. Individual channels can elect to receive frames that have failed their CRC, while applications can specify frame-drop policies on a per-channel basis. Measured results show that both kernel and user-space protocols can achieve very good throughput: applications using both TCP and our own reliable byte-stream protocol have demonstrated throughputs in excess of 200 Mbit/s. The benefits of running protocols in user-space are well known - the drawback has often been a severe penalty in the performance achieved. In this paper we show that it is possible to have the best of both worlds. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> G. Watson, D. Banks, C. Calamvokis, C. Dalton, A. Edwards and J. Lumley, </author> <title> AAL5 at a Gigabit for a Kilobuck, to appear in Journal of High Speed Networks. </title>
Reference-contexts: Section 5 presents the measured performance of the system. 2 The Jetstream LAN This section describes the main characteristics of the Jet-stream LAN and explains the reasoning behind the most important decisions. More detail is presented in <ref> [1] </ref>. 2.1 Ring Topology A Jetstream LAN interconnects up to 64 computers in a ring topology to provide a shared bandwidth of 800 Mbit/s. It is designed to interconnect a workgroup consisting of typically 10 to 30 computers and rarely more than 50.
Reference: [2] <author> CCITT, </author> <title> AAL Type 5, Draft Recommendation text for section 6 of I.363. CCITT Study Group XVIII/8-5, Report of Rapporteurs Meeting on AAL type 5, </title> <type> Annex 2, </type> <institution> Copenhagen, </institution> <month> 19-21 October, </month> <year> 1992. </year>
Reference-contexts: First, it is important that Jetstream can handle ATM AAL5 frames without the need for segmentation and reassembly, AAL5 being the ATM Forums adaptation layer of choice for data and thus likely to be an important frame format in the future <ref> [2] </ref>.
Reference: [3] <author> D.L. Tennenhouse, </author> <title> Layered multiplexing considered harmful, </title> <booktitle> In Proceedings of the 1st International Workshop on High-Speed Networks, </booktitle> <pages> pp. 143-148, </pages> <month> November </month> <year> 1989. </year>
Reference-contexts: This is exactly what is necessary to address the second issue described in the introduction. By demultiplexing at the driver an incoming video stream could be processed differently to a file transfer stream or even another video stream using a different cod ing. Tennenhouse <ref> [3] </ref> provides other reasons why it is best to demultiplex only at a single point. <p> Despite this, adequate performance can be achieved, as shown in section 5. 4.2 Single-copy kernel client In section 4.1, the pools were known only to the driver. If higher layers are also aware of pools, then PDUs can be demultiplexed directly to the end-consumer <ref> [3] </ref>. For instance, when a TCP connection is established, dedicated pools and VCIs could be allocated allowing incoming PDUs to be directly demultiplexed to the appropriate TCP control block and socket buffer. This of course would require changes to TCP code in the kernel.
Reference: [4] <author> K.C. Sevcik and M.J. Johnson, </author> <title> Cycle-Time Properties of the FDDI Token Ring Protocol, </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> Vol. SE-13, No. 3, </volume> <pages> pp. 376-385, </pages> <month> March </month> <year> 1987. </year>
Reference-contexts: Only one source is transmitting data at any one time and frames are removed by their source. A bit in each frame is used to detect frames that circulate the ring more than once. A concern with using the timed token protocol <ref> [4] </ref> is the worst case access delay that synchronous traffic might encounter. This protocol uses a target token rotation time (TTRT) to bound the delay encountered by any station. The maximum delay encountered by synchronous traffic will not exceed twice the TTRT.
Reference: [5] <author> CCITT, </author> <title> Blue Book, Vol. 3, F3.1, Recommendation G.114, Mean one-way propagation time. </title>
Reference-contexts: It is not clear whether a two millisecond worst case access delay is acceptable or not, but if humans can tolerate delays of the order of 100 milliseconds <ref> [5] </ref> for audio/visual information then Jetstream can provide the services for many new applications. 2.5 The prototype LAN We have designed and built a small number of Jetstream interfaces for use in our HP Series 700 workstations.
Reference: [6] <author> R.C. Walker, T. Hornak, C.-S. Yen, J. Doernberg and K.H. Springer, </author> <title> A 1.5 Gbit/s Link Interface Chipset for Computer Data Transmission, </title> <journal> IEEE J. Select. Areas in Comms, </journal> <volume> Vol. 9, No. 5, </volume> <pages> pp. </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: Coaxial cable has been used as the physical layer interconnect for distances up to about 50 meters, driven by HPs HDMP-1000 serial transceiver <ref> [6] </ref> chipset, which employ a 16B/ 20B coding scheme and can drive the cable directly at rates beyond 1 Gbit/s. FIGURE 2. The prototype Jetstream interface (left) with Afterburner card The Jetstream interface has been designed for use with the Afterburner network card [7].
Reference: [7] <author> C. Dalton, G. Watson, D. Banks, C. Calamvokis, A. Edwards and J. Lumley, </author> <title> Afterburner, </title> <journal> IEEE Network Mag., </journal> <volume> Vol. 7, No. 4, </volume> <pages> pp. 36-43, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: FIGURE 2. The prototype Jetstream interface (left) with Afterburner card The Jetstream interface has been designed for use with the Afterburner network card <ref> [7] </ref>. Figure 2 shows both cards, which connect to form a single board that plugs into the graphics bus of the workstation. Throughout this work we have aimed to produce a network interface that offers high performance at low cost and modest size. <p> Other comparable network interfaces include Orbit [8], the iWarp/Nectar CAB [9] and Davies 622 Mbit/s ATM interface [10]. At 20cm by 12cm we believe that Jetstream is substantially smaller and cheaper than these. 2.6 Afterburner The Afterburner <ref> [7] </ref> card is simply some multi-ported buffer memory together with some checksum calculation logic. It is designed to be used with a network card such as Jet-stream. It is based on the ideas in Jacobsons WITLESS proposal [11] and our experience with the Medusa [12] FDDI card. <p> This of course would require changes to TCP code in the kernel. Whilst we believe that this is the correct approach, it does entail substantial modifications to protocol code, so instead, as an intermediate step, we extended some earlier work <ref> [7] </ref> to accommodate the pool model. Thus, we retain a single IP pool but make some of the IP pool operations visible to socket layer code. In this way we support what we call single-copy operation [7][8] for TCP and UDP.
Reference: [8] <author> I. Cidon, I. Gopal, P.M. Gopal, J. Janniello and M. Kaplan, </author> <title> The plaNET/ORBIT High-Speed Network, </title> <institution> IBM Research Report 92A005472, </institution> <month> August </month> <year> 1992. </year>
Reference-contexts: A product could be made simpler and cheaper. The design uses a minimal amount of memory, so we could compress much of the random logic into a single ASIC and reduce the total cost to approximately $500. Other comparable network interfaces include Orbit <ref> [8] </ref>, the iWarp/Nectar CAB [9] and Davies 622 Mbit/s ATM interface [10]. At 20cm by 12cm we believe that Jetstream is substantially smaller and cheaper than these. 2.6 Afterburner The Afterburner [7] card is simply some multi-ported buffer memory together with some checksum calculation logic.
Reference: [9] <author> P.A. Steenkiste, B.D. Zill, H.T. Kung, S.J. Schlick, J. Hughes, R. Kowalski and J. Mullaney, </author> <title> A Host Interface Architecture for High-Speed Networks, </title> <booktitle> In Proceedings of 4th IFIP Conference on High Performance Networking, </booktitle> <editor> A. Danthine and O. Spaniol (Eds.), pp. A3-1 - A3-16, </editor> <month> December </month> <year> 1992. </year>
Reference-contexts: A product could be made simpler and cheaper. The design uses a minimal amount of memory, so we could compress much of the random logic into a single ASIC and reduce the total cost to approximately $500. Other comparable network interfaces include Orbit [8], the iWarp/Nectar CAB <ref> [9] </ref> and Davies 622 Mbit/s ATM interface [10]. At 20cm by 12cm we believe that Jetstream is substantially smaller and cheaper than these. 2.6 Afterburner The Afterburner [7] card is simply some multi-ported buffer memory together with some checksum calculation logic.
Reference: [10] <author> B.S. Davie, </author> <title> A Host-Network Interface Architecture for ATM, </title> <booktitle> in Proceedings SIGCOMM 1991, </booktitle> <address> Zurich, Switzerland, </address> <pages> pp. 307-315, </pages> <month> September, </month> <year> 1991. </year>
Reference-contexts: The design uses a minimal amount of memory, so we could compress much of the random logic into a single ASIC and reduce the total cost to approximately $500. Other comparable network interfaces include Orbit [8], the iWarp/Nectar CAB [9] and Davies 622 Mbit/s ATM interface <ref> [10] </ref>. At 20cm by 12cm we believe that Jetstream is substantially smaller and cheaper than these. 2.6 Afterburner The Afterburner [7] card is simply some multi-ported buffer memory together with some checksum calculation logic. It is designed to be used with a network card such as Jet-stream.
Reference: [11] <author> Van Jacobson, </author> <title> Efficient Protocol Implementation, </title> <booktitle> ACM SIGCOMM 90 Tutorial, </booktitle> <month> September </month> <year> 1990. </year>
Reference-contexts: It is designed to be used with a network card such as Jet-stream. It is based on the ideas in Jacobsons WITLESS proposal <ref> [11] </ref> and our experience with the Medusa [12] FDDI card. With the WITLESS model, data is only copied once and the IP checksum is calculated during that one copy operation. Clark [13] and Partridge [14] describe these issues in much more detail.
Reference: [12] <author> D.M. Banks and M.J. Prudence, </author> <title> A High Performance Network Architecture for a PA-RISC Workstation, </title> <journal> IEEE J. Select Areas in Comms., </journal> <volume> Vol. 11, No. 2, </volume> <month> Feb-ruary </month> <year> 1993. </year>
Reference-contexts: It is designed to be used with a network card such as Jet-stream. It is based on the ideas in Jacobsons WITLESS proposal [11] and our experience with the Medusa <ref> [12] </ref> FDDI card. With the WITLESS model, data is only copied once and the IP checksum is calculated during that one copy operation. Clark [13] and Partridge [14] describe these issues in much more detail.
Reference: [13] <author> D.D. Clark, Van Jacobson, J. Romkey and H. Salwen, </author> <title> An Analysis of TCP Processing Overhead, </title> <journal> IEEE Commun. Mag., </journal> <pages> pp. 23-29, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: It is based on the ideas in Jacobsons WITLESS proposal [11] and our experience with the Medusa [12] FDDI card. With the WITLESS model, data is only copied once and the IP checksum is calculated during that one copy operation. Clark <ref> [13] </ref> and Partridge [14] describe these issues in much more detail. Afterburner provides one Mbyte of buffer memory as well as IP checksum support for outbound data. The buffer memory can be organised as 512 2-Kbyte blocks, 256 4-Kbyte blocks, etc.
Reference: [14] <author> C. Partridge, </author> <title> Gigabit Networking, Chapter 9, </title> <publisher> Addi-son-Wesley Publ., </publisher> <year> 1993. </year>
Reference-contexts: It is based on the ideas in Jacobsons WITLESS proposal [11] and our experience with the Medusa [12] FDDI card. With the WITLESS model, data is only copied once and the IP checksum is calculated during that one copy operation. Clark [13] and Partridge <ref> [14] </ref> describe these issues in much more detail. Afterburner provides one Mbyte of buffer memory as well as IP checksum support for outbound data. The buffer memory can be organised as 512 2-Kbyte blocks, 256 4-Kbyte blocks, etc.
Reference: [15] <author> Jeffrey C. Mogul, Richard F. Rashid and Michael J. Accetta. </author> <title> The Packet Filter: An efficient mechanism for user-level network code, </title> <booktitle> in Proceedings of the 11th ACM Symposium on Operating System Principles, </booktitle> <pages> pp. 39-51, </pages> <month> November </month> <year> 1987. </year>
Reference-contexts: If the application is to provide enough information to allow the driver to demultiplex packets to the appropriate pool the driver either needs to have detailed knowledge of all possible higher layer protocols, or needs to understand some general filter specification <ref> [15] </ref>. Pool-specific policies for error handling are useful because particular data streams may have different requirements in case of error [16] or overow. For instance, a file transfer application will drop PDUs with an incorrect link CRC and drop newly-arrived PDUs in preference to ones already received.
Reference: [16] <author> O. Hagsand and S. Pink, </author> <title> ATM as a link in an ST-2 Internet, </title> <booktitle> in Proceedings of the 4th International Workshop on Network and Operating Systems Support for Digital Audio and Video, </booktitle> <pages> pp. 189-198, </pages> <address> Lan-caster, </address> <month> November </month> <year> 1993. </year>
Reference-contexts: Pool-specific policies for error handling are useful because particular data streams may have different requirements in case of error <ref> [16] </ref> or overow. For instance, a file transfer application will drop PDUs with an incorrect link CRC and drop newly-arrived PDUs in preference to ones already received.
Reference: [17] <author> C.B.S. Traw and J.M. Smith, </author> <title> Hardware/Software Organization of a High-Performance ATM Host Interface, </title> <journal> IEEE J. Select Areas in Comms., </journal> <volume> Vol. 11, No. 2, </volume> <month> Feb. </month> <year> 1993. </year>
Reference-contexts: A video application might accept PDUs containing errors, and drop old PDUs in preference to new ones, in order to keep the display up-to-date. A number of other approaches allow a similar sort of low-level access. Traw <ref> [17] </ref> and Druschel [18] are excellent examples. These schemes perform demultiplexing in hardware whereas our scheme does it in software. A more fundamental difference is that in these schemes data is available for consumption by an application immediately after it has arrived off the network.
Reference: [18] <author> P. Druschel, L.L. Peterson, B.S. Davie, </author> <title> Experiences with a High-Speed Network Adaptor: A Software Perspective, </title> <booktitle> in Proceedings SIGCOMM 1994, </booktitle> <address> Lon-don, </address> <month> September, </month> <year> 1994. </year>
Reference-contexts: A video application might accept PDUs containing errors, and drop old PDUs in preference to new ones, in order to keep the display up-to-date. A number of other approaches allow a similar sort of low-level access. Traw [17] and Druschel <ref> [18] </ref> are excellent examples. These schemes perform demultiplexing in hardware whereas our scheme does it in software. A more fundamental difference is that in these schemes data is available for consumption by an application immediately after it has arrived off the network.
Reference: [19] <author> Chandramohan A. Thekkath, Thu D. Nguyen, Evelyn Moy and Edward D. Lazowska, </author> <title> Implementing Network Protocols at User Level, </title> <booktitle> in Proceedings SIG-COMM 1993, </booktitle> <address> San Francisco, </address> <pages> pp. 64-73, </pages> <month> September, </month> <year> 1993. </year>
Reference-contexts: The impact of system calls TCP and substantially better then the two-copy TCP. We note that our stream library was coded and debugged in about four weeks and is still being tuned, so better results may be forthcoming. User-space protocol implementations have a number of well-known advantages <ref> [19] </ref>. For example, they ease the prototyping and debugging of new protocols, and allow application specific knowledge to be exploited to allow performance improvements to be made.
Reference: [20] <editor> Rick A. Jones, netperf: </editor> <title> A Network Performance Benchmark, Revision 1. Information Networks Division, </title> <institution> Hewlett-Packard Co., </institution> <month> March </month> <year> 1993. </year> <note> The netperf utility can be obtained via anonymous ftp from ftp.csc.liv.ac.uk in /hpux8/Networking </note>
Reference-contexts: We then present application-to-application throughput measured over Jetstream using TCP (single- and double-copy) and our own reliable byte-stream protocol. The measurements reported here were collected from two HP 9000/735 workstations running HP-UX 9.01 and using the netperf <ref> [20] </ref> utility. TCP window scaling [21] is used with socket buffers of 245760 bytes. Both workstations are connected to the site Ethernet and have the usual background processes.
Reference: [21] <author> V. Jacobson, R. Braden, D. </author> <title> Borman, RFC 1323, TCP Extensions for High Performance. </title> <month> May </month> <year> 1992. </year>
Reference-contexts: We then present application-to-application throughput measured over Jetstream using TCP (single- and double-copy) and our own reliable byte-stream protocol. The measurements reported here were collected from two HP 9000/735 workstations running HP-UX 9.01 and using the netperf [20] utility. TCP window scaling <ref> [21] </ref> is used with socket buffers of 245760 bytes. Both workstations are connected to the site Ethernet and have the usual background processes.
References-found: 21

