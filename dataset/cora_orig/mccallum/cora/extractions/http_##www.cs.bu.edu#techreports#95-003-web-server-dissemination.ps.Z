URL: http://www.cs.bu.edu/techreports/95-003-web-server-dissemination.ps.Z
Refering-URL: http://cs-www.bu.edu/techreports/Home.html
Root-URL: 
Email: (best@cs.bu.edu)  
Title: Demand-based Document Dissemination for the World-Wide Web  
Author: Azer Bestavros 
Date: February 7, 1995  
Address: Boston, MA 02215  
Affiliation: Computer Science Department Boston University  
Abstract: We analyzed the logs of our departmental HTTP server http://cs-www.bu.edu as well as the logs of the more popular Rolling Stones HTTP server http://www.stones.com. These servers have very different purposes; the former caters primarily to local clients, whereas the latter caters exclusively to remote clients all over the world. In both cases, our analysis showed that remote HTTP accesses were confined to a very small subset of documents. Using a validated analytical model of server popularity and file access profiles, we show that by disseminating the most popular documents on servers (proxies) closer to the clients, network traffic could be reduced considerably, while server loads are balanced. We argue that this process could be generalized so as to provide for an automated demand-based duplication of documents. We believe that such server-based information dissemination protocols will be more effective at reducing both network bandwidth and document retrieval times than client-based caching protocols [2]. fl This work has been partially supported by NSF (grant CCR-9308344).
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Swarup Acharya and Stanley B. Zdonik. </author> <title> An efficient scheme for dynamic data replication. </title> <type> Technical Report CS-93-43, </type> <institution> Brown University, </institution> <address> Providence, Rhode Island 02912, </address> <month> September </month> <year> 1993. </year>
Reference-contexts: In this study, a hierarchical caching system that caches files at Core Nodal Switching Subsystems is shown to reduce the NSFNET backbone traffic by 21%. The effect of data placement and replication on network traffic was also studied in <ref> [1] </ref>, where file access patterns are used to suggest a distributed dynamic replication scheme. A more static solution based on fixed network and storage costs for the delivery of multimedia home entertainment was suggested in [13].
Reference: [2] <author> Azer Bestavros, Robert Carter, Mark Crovella, Carlos Cunha, Abdelsalam Heddaya, and Suli-man Mirdad. </author> <title> Application level document caching in the internet. </title> <type> Technical Report TR-95-002, </type> <institution> Boston University, CS Dept, </institution> <address> Boston, MA 02215, </address> <month> January </month> <year> 1995. </year> <note> (submitted for publication). </note>
Reference-contexts: Let Freq (S i , f) 4 Notice that our protocol does not preclude the EffectiveURL from pointing to the local cache of the client itself (whether at the session, machine, or LAN levels <ref> [2] </ref>).
Reference: [3] <author> Azer Bestavros and Mark Crovella. </author> <type> Personal communication, </type> <month> January </month> <year> 1995. </year>
Reference-contexts: Such a naming protocol should not be dependent on (say) a particular dissemination/replication protocol, like the one presented in this paper. Other orthogonal problems include that of clustering (grouping servers/clients into dynamic clusters to reduce traffic) and resource discovery (locating nearby copies of replicated resources) <ref> [3, 8] </ref>. Much work needs to be done to identify and tackle such orthogonal problems and then compose their solutions.
Reference: [4] <author> Matthew Addison Blaze. </author> <title> Caching in Large Scale Distributed File Systems. </title> <type> PhD thesis, </type> <institution> Prince-ton University, </institution> <month> January </month> <year> 1993. </year> <month> 21 </month>
Reference-contexts: A more static solution based on fixed network and storage costs for the delivery of multimedia home entertainment was suggested in [13]. Multi-level caching was studied in [12], where simulations of a two-level caching system is shown to reduce both network and server loads. In <ref> [4] </ref>, a dynamic hierarchical file system, which supports demand-driven replication is proposed, whereby clients are allowed to service requests issued by other clients from the local disk cache. A similar cooperative caching idea was suggested in [5].
Reference: [5] <author> Michael D. Dahlin, Randolph Y. Wang, Thomas E. Anderson, and Dacid A. Patterson. </author> <title> Co--operative caching: Using remote client memory to improve file system performance. </title> <booktitle> In First Symposium on Operating systems Design and Implementation (OSDI), </booktitle> <pages> pages 267-280, </pages> <year> 1994. </year>
Reference-contexts: In [4], a dynamic hierarchical file system, which supports demand-driven replication is proposed, whereby clients are allowed to service requests issued by other clients from the local disk cache. A similar cooperative caching idea was suggested in <ref> [5] </ref>. The proposed research work of Gwertzman and Seltzer sketched in [9] is the closest to ours. In particular, they propose the implementation of what they termed as geographical push-cashing, which allows servers to decide when and where to cache information.
Reference: [6] <author> Peter Danzig, Richard Hall, and Michael Schwartz. </author> <title> A case for cashing file objects inside internetworks. </title> <type> Technical Report CU-CS-642-93, </type> <institution> University of Colorado at Boulder, Boulder, Colorado 80309-430, </institution> <month> March </month> <year> 1993. </year>
Reference-contexts: Recently, there have been some attempts at extending caching and replication to distributed information systems (e.g. FTP and HTTP). Caching to reduce the bandwidth requirements for the FTP protocol on the NSFNET has been studied in <ref> [6] </ref>. In this study, a hierarchical caching system that caches files at Core Nodal Switching Subsystems is shown to reduce the NSFNET backbone traffic by 21%. <p> First, we believe that adding servers (i.e. proxies) to the internet is much cheaper than adding (upgrading) internet links <ref> [6] </ref>.
Reference: [7] <author> Michael Foster and Robert Jump. </author> <title> NSF Solicitation 94-75. </title> <booktitle> STIS database, </booktitle> <month> May </month> <year> 1994. </year>
Reference-contexts: Perhaps the best "living" proof of the seriousness of this problem is the fate of many information servers on the Internet: they are unreacheable as soon as they become popular. In a recent solicitation <ref> [7] </ref> from the National Science Foundation's ES and MSA programs, the following research topics were deemed critical for projected applications of the National Information Infrastructure (NII): * New techniques for organizing cache memories and other buffering schemes to alleviate mem ory and network latency and increase bandwidth. * Partitioning and distribution
Reference: [8] <author> James Guyton and Michael Schwartz. </author> <title> Locating nearby copies of replicated internet servers. </title> <type> Technical Report CU-CS-762-95, </type> <institution> University of Colorado at Boulder, Boulder, Colorado 80309-430, </institution> <month> February </month> <year> 1995. </year>
Reference-contexts: Such a naming protocol should not be dependent on (say) a particular dissemination/replication protocol, like the one presented in this paper. Other orthogonal problems include that of clustering (grouping servers/clients into dynamic clusters to reduce traffic) and resource discovery (locating nearby copies of replicated resources) <ref> [3, 8] </ref>. Much work needs to be done to identify and tackle such orthogonal problems and then compose their solutions.
Reference: [9] <author> James Gwertzman and Margo Seltzer. </author> <title> The case for geographical push-caching. </title> <type> Technical Report HU TR-34-94 (excerpt), </type> <institution> Harvard University, DAS, </institution> <address> Cambridge, MA 02138, </address> <year> 1994. </year>
Reference-contexts: In [4], a dynamic hierarchical file system, which supports demand-driven replication is proposed, whereby clients are allowed to service requests issued by other clients from the local disk cache. A similar cooperative caching idea was suggested in [5]. The proposed research work of Gwertzman and Seltzer sketched in <ref> [9] </ref> is the closest to ours. In particular, they propose the implementation of what they termed as geographical push-cashing, which allows servers to decide when and where to cache information. Their work provides no information about resource allocation strategies and seems to be static and flat (not hierarchical).
Reference: [10] <author> John H. Howard, Michael L. Kazar, Sherri G. Menees, David A. Nichols, M. Satyanarayanan, Robert N. Sidebotham, and Michael J. West. </author> <title> Scale and performance in a distributed file system. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 6(1) </volume> <pages> 51-81, </pages> <month> February </month> <year> 1988. </year>
Reference-contexts: There has been quite a bit of research on caching and replication to improve the availability and performance of scalable distributed file systems <ref> [10] </ref>. Example systems include the Sun NFS 2 [14], the Andrew File System [11], and the Coda system [15]. Recently, there have been some attempts at extending caching and replication to distributed information systems (e.g. FTP and HTTP).
Reference: [11] <author> J.H. Morris, M. Satyanarayanan, M.H. Conner, J.H. Howard, D.S.H. Rosenthal, and F.D. Smith. Andrew: </author> <title> a distributed personal computing environment. </title> <journal> Comm. ACM, </journal> <volume> 29(3) </volume> <pages> 184-201, </pages> <month> Mar. </month> <year> 1986. </year>
Reference-contexts: There has been quite a bit of research on caching and replication to improve the availability and performance of scalable distributed file systems [10]. Example systems include the Sun NFS 2 [14], the Andrew File System <ref> [11] </ref>, and the Coda system [15]. Recently, there have been some attempts at extending caching and replication to distributed information systems (e.g. FTP and HTTP). Caching to reduce the bandwidth requirements for the FTP protocol on the NSFNET has been studied in [6].
Reference: [12] <author> D. Muntz and P. Honeyman. </author> <title> Multi-level caching in distributed file systems or your cache ain't nuthing but trash. </title> <booktitle> In Proceedings of the Winter 1992 USENIX, </booktitle> <pages> pages 305-313, </pages> <month> January </month> <year> 1992. </year>
Reference-contexts: A more static solution based on fixed network and storage costs for the delivery of multimedia home entertainment was suggested in [13]. Multi-level caching was studied in <ref> [12] </ref>, where simulations of a two-level caching system is shown to reduce both network and server loads. In [4], a dynamic hierarchical file system, which supports demand-driven replication is proposed, whereby clients are allowed to service requests issued by other clients from the local disk cache.
Reference: [13] <author> Christos H. Papadimitriou, Srinivas Ramanathan, and P. Venkat Rangan. </author> <title> Information caching for delivery of personalized video programs on home entertainment channels. </title> <booktitle> In Proceedings of the International Confrence on Multimedia Computing and Systems, </booktitle> <pages> pages 214-223, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: The effect of data placement and replication on network traffic was also studied in [1], where file access patterns are used to suggest a distributed dynamic replication scheme. A more static solution based on fixed network and storage costs for the delivery of multimedia home entertainment was suggested in <ref> [13] </ref>. Multi-level caching was studied in [12], where simulations of a two-level caching system is shown to reduce both network and server loads.
Reference: [14] <author> R. Sandber, D. Goldberg, S. Kleiman, D. Walsh, and B. Lyon. </author> <title> Design and implementation of the sun network file system. </title> <booktitle> In Proceedings of USENIX Summer Conference, </booktitle> <year> 1985. </year>
Reference-contexts: There has been quite a bit of research on caching and replication to improve the availability and performance of scalable distributed file systems [10]. Example systems include the Sun NFS 2 <ref> [14] </ref>, the Andrew File System [11], and the Coda system [15]. Recently, there have been some attempts at extending caching and replication to distributed information systems (e.g. FTP and HTTP). Caching to reduce the bandwidth requirements for the FTP protocol on the NSFNET has been studied in [6].
Reference: [15] <author> M. Satyanarayanan, J. Kistler, P. Kumar, M. Okasaki, E. Siegel, and D. Streere. Coda: </author> <title> A highly available file system for distributed workstation environments. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 39(4), </volume> <month> April </month> <year> 1990. </year> <month> 22 </month>
Reference-contexts: There has been quite a bit of research on caching and replication to improve the availability and performance of scalable distributed file systems [10]. Example systems include the Sun NFS 2 [14], the Andrew File System [11], and the Coda system <ref> [15] </ref>. Recently, there have been some attempts at extending caching and replication to distributed information systems (e.g. FTP and HTTP). Caching to reduce the bandwidth requirements for the FTP protocol on the NSFNET has been studied in [6].
References-found: 15

