URL: http://www.neci.nj.nec.com/homepages/oliensis/finjnt3.ps
Refering-URL: http://www.neci.nj.nec.com/homepages/oliensis/
Root-URL: 
Title: Structure from Linear or Planar Motions  
Author: J Oliensis 
Address: Princeton, NJ 08540  
Affiliation: NEC Research Institute  
Abstract: We recently demonstrated a new approach to mul-tiframe structure from motion from point features which, in the appropriate domain, provably reconstructs structure and motion correctly. The algorithm works for general motion and large perspective effects. In this paper, we describe how to adapt our approach to translational motion lying along a line or in a plane, with arbitrary rotations. An analysis of the bas-relief effect for multiple-motion sequences is also presented. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Dutta, R. Manmatha, </author> <title> L.R. Williams, and E.M. Riseman, "A data set for quantitative motion analysis," </title> <booktitle> CVPR, </booktitle> <pages> 159-164, </pages> <year> 1989. </year>
Reference-contexts: Since our error anal ysis implies that these values are accurate and since we adhere otherwise to a MLE, the third stage should give a better estimate of "f1g" than does the second stage. 3 Experiments: rocket sequence We tested our linear motion algorithm on the Martin-Marietta Rocket sequence <ref> [1] </ref> (Figure 1). The motion is primarily forward with maximum displacement of about 7.4' and small rotations of less than 4 ffi . Since the rotations were small, we applied our algorithms directly without compensating for them. 22 points were tracked over 9 frames.
Reference: [2] <author> G. Golub and C. F. Van Loan, </author> <title> Matrix Computations, </title> <publisher> John Hopkins, </publisher> <address> Baltimore 1983. </address>
Reference: [3] <author> D.J. Heeger and A.D. Jepson, </author> <title> "Subspace methods for recovering rigid motion I: Algorithm and implementation," </title> <booktitle> IJCV 7, </booktitle> <pages> 95-117, </pages> <year> 1992. </year>
Reference: [4] <author> A.D. </author> <title> Jepson and D.J. Heeger, "Linear subspace methods for recovering translational direction," </title> <type> U. </type> <institution> of Toronto TR RBCV-TR-92-40,1992, </institution> <address> p. </address> <month> 19. </month>
Reference-contexts: To further reduce the effects of rotation errors and diminish the influence of outlier images, we eliminate the first order effect of the residual rotations using a technique similar to <ref> [4, 5] </ref>. Rewrite the displacements as an (N 1) fi 2M matrix D by putting all the x and then the y coordinates for a given image on a single row. <p> The (2M 3) fi 2M matrix H V can be computed quickly using Householder matrices [14, 11]. [5] first proposed the linear elimination of rotations in the different context of optical flow, but their technique did not extend simply to annihilating general vectors or to sparse flows <ref> [4] </ref> as ours does. Note that, unlike [5], we lose no useful information in multiplying by H V . As described in [11], to make our algorithm correspond better to a MLE we left-multiply D H by a known matrix C 1=2 H .

Reference: [6] <author> A.D. </author> <title> Jepson and D.J. Heeger, "Subspace methods for recovering rigid motion II: Theory," </title> <type> U. </type> <institution> of Toronto TR RBCV-TR-90-36, </institution> <year> 1990. </year>
Reference-contexts: Each A a corresponds to some linear combination of the H V S 1;2;3 |effectively, to the image displacements for an appropriately chosen "translation" (as multiplied by H V ). Our modi fied algorithm directly computes the appropriate linear combinations by techniques similar to those of <ref> [6] </ref> 5 Explicitly, A a H V S ; for some T (a) ; with S T (a) ; f~g T z fx~g T x f~g (a) (a) ! S T (a) ; f~g has the form of a translational flow with a "translation" T (a) (T (a) (a) (a) z <p> i : Define fW g; T (a) @ (a) (a) fW T z x T x g A : 5 This is worse than our previous algorithm since it treats each singular vector A 1;2;3 separately and since for a linear estimate we must neglect 3 of the available constraints <ref> [6] </ref>. The constrained algorithm should not be used for general motion. so that t S = 0 independent of fW g: Then t H t A a t V Ra . <p> T z y ^ T y g t : For known ^ T; this gives 2M 3 linear constraints determining the M unknowns ~ i : The translation magnitudes h are determined straightforwardly from the leading left singular vector. 2.2.2 Error analysis For ^ T recovery, the error analysis in <ref> [6, 9] </ref> for the optical flow case applies here as well. For structure, the error (given ^ T) can be estimated and bounded by a perturbation analysis of the SVD, yielding results similar to those of [6] for optical flow 7 . <p> For structure, the error (given ^ T) can be estimated and bounded by a perturbation analysis of the SVD, yielding results similar to those of <ref> [6] </ref> for optical flow 7 . Essentially, we obtain the bas-relief effect, with the 3 ~-components linear in the image coordinates relatively more sensitive to error than the rest. <p> Previously, this effect has been analyzed just for the optical flow (constant motion) case, <ref> [6, 9] </ref>, where it implies that the three linear ~-components are much more noise-sensitive than the others. Here, in analyzing the errors of our planar motion algorithm, we show how the bas-relief effect works for multiple, nonconstant motions.
Reference: [7] <author> R. Kumar and A.R. Hanson, </author> <title> "Sensitivity of the Pose Refinement Problem to Accurate Estimation of Camera Parameters," </title> <booktitle> ICCV, </booktitle> <pages> 365-369, </pages> <year> 1990. </year>
Reference-contexts: Similar results were obtained when we started by compensating the rotations initially. Our results improve on previous ones obtained via Kalman filtering [19, 20]. 3.1 Experiments: T z = 0 We applied our planar motion algorithm to part of the PUMA image sequence <ref> [7] </ref> (Figure 3). 32 points were automatically tracked over 16 image frames. A camera attached to one end of a PUMA arm was rotated in a plane about its other end. The offset of the camera optical axis from the rotation axis was about 6 ffi .
Reference: [8] <author> H. C. Longuet-Higgins, </author> <title> "A computer algorithm for reconstructing a scene from two projections," </title> <journal> Nature, </journal> <volume> 293 </volume> <pages> 133-135, </pages> <year> 1981. </year>
Reference-contexts: Algorithms already exist that cope well with large translations <ref> [21, 8] </ref>, but there was no previous algorithm well adapted for both small translations and large perspective effects. Our approach complements previous algorithms [8, 21] and together with them should suffice for most domains. <p> Algorithms already exist that cope well with large translations [21, 8], but there was no previous algorithm well adapted for both small translations and large perspective effects. Our approach complements previous algorithms <ref> [8, 21] </ref> and together with them should suffice for most domains. We have argued previously [11, 14] that it is best to design specialized rather than general SFM algorithms.
Reference: [9] <author> S. Maybank, </author> <title> Theory of Reconstruction from Image Motion, </title> <publisher> Springer, </publisher> <address> Berlin, </address> <year> 1992. </year>
Reference-contexts: T z y ^ T y g t : For known ^ T; this gives 2M 3 linear constraints determining the M unknowns ~ i : The translation magnitudes h are determined straightforwardly from the leading left singular vector. 2.2.2 Error analysis For ^ T recovery, the error analysis in <ref> [6, 9] </ref> for the optical flow case applies here as well. For structure, the error (given ^ T) can be estimated and bounded by a perturbation analysis of the SVD, yielding results similar to those of [6] for optical flow 7 . <p> Previously, this effect has been analyzed just for the optical flow (constant motion) case, <ref> [6, 9] </ref>, where it implies that the three linear ~-components are much more noise-sensitive than the others. Here, in analyzing the errors of our planar motion algorithm, we show how the bas-relief effect works for multiple, nonconstant motions.
Reference: [10] <author> J. Oliensis, </author> <note> in preparation. </note>
Reference-contexts: The convergence of the iteration can be established (under reasonable conditions) by the same perturbation methods used to bound the initial estimate's error <ref> [10] </ref>. <p> the rotational terms and are suppressed for small residual rotations. 9 The bias occurs only through errors in H V ; which lead to small errors in D of order the residual rotation times the noise. the reconstruction errors can be derived using bounds on the perturbations of singular vectors <ref> [18, 10] </ref>. Starting from the solution of (7) we can get an improved structure estimate that gives a better approximation to the exact MLE [10]. From first order perturbation theory for singular vectors [18], the covari-ance of the recovered A 1;2 can be estimated. <p> Starting from the solution of (7) we can get an improved structure estimate that gives a better approximation to the exact MLE <ref> [10] </ref>. From first order perturbation theory for singular vectors [18], the covari-ance of the recovered A 1;2 can be estimated. <p> Essentially, this is because only this component is noise-sensitive for all the allowed translation directions 12 . For these estimates, we use a modified version of the second stage of our algorithm (7), but our qualitative conclusions can be shown to be general <ref> [10] </ref>. Consider recovering f~g from the two leading singular vectors 12 For general motion, typically no structure component is noise-sensitive for all translation directions; therefore all can typically be recovered accurately [10]. <p> version of the second stage of our algorithm (7), but our qualitative conclusions can be shown to be general <ref> [10] </ref>. Consider recovering f~g from the two leading singular vectors 12 For general motion, typically no structure component is noise-sensitive for all translation directions; therefore all can typically be recovered accurately [10]. A 1;2 by solving 13 0 = P A H V f~g f0g where P A 1 A 1 A 2 1 2 is a projection. Like (7), (10) implements the requirement that both of S Hx;y are approximately contained in the subspace generated by the A 1;2 . <p> Solving (10) is equivalent to finding the least eigenvector of K A H t V1 + H t V2 ; where the H V 1;2 are (2M 3) fi M matrices defined by H V = H V 1 H V 2 . We have shown <ref> [10] </ref> that the only noise-sensitive ~-components are those corresponding to K A -eigenvalues i with i t 1. In general only one k i t 1, corresponding approximately to the constant component 14 . All other ~-components should be reasonably noise-insensitive 15 .
Reference: [11] <author> J. Oliensis, </author> <title> "Multiframe Structure from Motion in Perspective," </title> <booktitle> Workshop on the Representations of Visual Scenes, </booktitle> <pages> 77-84, </pages> <month> June </month> <year> 1995. </year> <title> [12] "Provably Correct Algorithms for Multiframe Structure from Motion: The Case of Constant Translation Direction," </title> <type> NEC TR, </type> <month> Dec. </month> <year> 1994. </year> <note> [13] http://www.neci.nj.nec.com/ homepages/oliensis.html. </note>
Reference-contexts: 1 Introduction We recently demonstrated in <ref> [14, 11] </ref> a new algorithm for multiframe structure from motion (MFSFM) from point features. In the appropriate domain, the algorithm provably reconstructs the true structure and motion from exact data; with sufficiently small (and reasonable) noise it provably reconstructs with small errors. <p> Algorithms already exist that cope well with large translations [21, 8], but there was no previous algorithm well adapted for both small translations and large perspective effects. Our approach complements previous algorithms [8, 21] and together with them should suffice for most domains. We have argued previously <ref> [11, 14] </ref> that it is best to design specialized rather than general SFM algorithms. Take e.g. the maximum likelihood least square estimate (MLE) as the "optimal estimate." Its dependence on the observed image points is highly nonlinear. <p> The small translation assumption is actually not crucial, since typically the rotations can also be recovered accurately for large translations 2 [15]. For our general motion algorithm <ref> [11] </ref>, the next step is to apply the small translation assumption by approximating the denominator in (1) by a constant. (This approximation will be corrected later by iterating and can also be avoided to some extent for the special-case algorithms presented here.) With this approximation and since the residual rotations are <p> The (2M 3) fi 2M matrix H V can be computed quickly using Householder matrices <ref> [14, 11] </ref>. [5] first proposed the linear elimination of rotations in the different context of optical flow, but their technique did not extend simply to annihilating general vectors or to sparse flows [4] as ours does. <p> Note that, unlike [5], we lose no useful information in multiplying by H V . As described in <ref> [11] </ref>, to make our algorithm correspond better to a MLE we left-multiply D H by a known matrix C 1=2 H . This partially removes the bias due to singling out the zeroth image for special treatment. The general motion algorithm described in [11] goes on to compute the three leading <p> As described in <ref> [11] </ref>, to make our algorithm correspond better to a MLE we left-multiply D H by a known matrix C 1=2 H . This partially removes the bias due to singling out the zeroth image for special treatment. The general motion algorithm described in [11] goes on to compute the three leading right singular vectors A 1;2;3 of D CH C 1=2 H D H and then recovers the structure from these vectors by least squares using the fact that the S Hx;y;z lie approximately in the subspace generated by the A 1;2;3 . <p> One possibility is to proceed as in the general algorithm <ref> [11] </ref>. Let A 1;2 be the 2 leading right singular vectors of D H . The S Hi must be approximately contained in the subspace generated by the A i .
Reference: [14] <author> J. Oliensis, </author> <title> "A Linear Solution for Multiframe Structure from Motion," </title> <booktitle> IUW, </booktitle> <pages> 1225-1231. </pages> <year> 1994. </year>
Reference-contexts: 1 Introduction We recently demonstrated in <ref> [14, 11] </ref> a new algorithm for multiframe structure from motion (MFSFM) from point features. In the appropriate domain, the algorithm provably reconstructs the true structure and motion from exact data; with sufficiently small (and reasonable) noise it provably reconstructs with small errors. <p> Algorithms already exist that cope well with large translations [21, 8], but there was no previous algorithm well adapted for both small translations and large perspective effects. Our approach complements previous algorithms [8, 21] and together with them should suffice for most domains. We have argued previously <ref> [11, 14] </ref> that it is best to design specialized rather than general SFM algorithms. Take e.g. the maximum likelihood least square estimate (MLE) as the "optimal estimate." Its dependence on the observed image points is highly nonlinear. <p> Our experiments indicate that the projective approach does little (if any) better than a Euclidean estimate based on a wrong calibration, even for the projective structure, and may be less stable. Our algorithms were described initially in <ref> [14, 12] </ref>. 2 Algorithms: general motion Choose the zeroth image as a base image. <p> The (2M 3) fi 2M matrix H V can be computed quickly using Householder matrices <ref> [14, 11] </ref>. [5] first proposed the linear elimination of rotations in the different context of optical flow, but their technique did not extend simply to annihilating general vectors or to sparse flows [4] as ours does. <p> Accurate structure recovery depends critically on determining the translation direction accurately. To minimize the bias in its estimate, we use standard Levenberg-Marquardt (LM) to find the MLE of the translation direction (consistent with our approximations) starting from the linear solution <ref> [14] </ref>. This is a relatively simple minimization in two unknowns. Since the linear solution already produces an excellent starting guess for ^ T, few iterations are required. 2.2.1 Depth reconstruction Our algorithm just reconstructs depth, the most diffi cult structure component.
Reference: [15] <author> J. Oliensis, </author> <title> "Rigorous Bounds for Two-Frame Structure from Motion," </title> <note> ECCV 1996 and NECI TR, October 1995 (expanded version). </note>
Reference-contexts: Assuming moderate translation, we recover the rotations separately between the base frame and each subsequent frame via a standard technique assuming that the translations are zero. This may seem a strong assumption, but we have proven rigorously that the resulting rotation errors are small when the translations are moderate <ref> [15] </ref>. The small translation assumption is actually not crucial, since typically the rotations can also be recovered accurately for large translations 2 [15]. <p> This may seem a strong assumption, but we have proven rigorously that the resulting rotation errors are small when the translations are moderate <ref> [15] </ref>. The small translation assumption is actually not crucial, since typically the rotations can also be recovered accurately for large translations 2 [15]. <p> M 5 components are robustly recoverable, and the 5 remaining "difficult" components are in the subspace generated by f1 + x 2 g, f1 + y 2 g, fxg, fyg, fxyg. 10 When the translations are large the bas-relief effect typi cally is unimportant <ref> [15] </ref>. 11 This is for general motion: S z would be excluded for T z = 0.
Reference: [16] <author> J. Oliensis and Venu Govindu, </author> <title> "Experimental Evaluation of Projective Reconstruction in Structure from Motion," </title> <note> NECI TR October 1995. </note>
Reference-contexts: Our approach assumes known camera calibration. We have studied the sensitivity of our approach to calibration errors both experimentally and theoretically and have found that it is relatively insensitive. We have also conducted a general study <ref> [16] </ref> comparing Euclidean to projective reconstruction. Our experiments indicate that the projective approach does little (if any) better than a Euclidean estimate based on a wrong calibration, even for the projective structure, and may be less stable.
Reference: [17] <author> H-Y Shum et al., </author> <title> "Principal Component Analysis with Missing Data and Its Application to Object Modeling," </title> <booktitle> CVPR 1994, </booktitle> <pages> 560-565. </pages>
Reference-contexts: When there is occlusion, we can derive a good initial guess for this row vector e.g. by determining rows that are at relatively small angles with respect to each other and averaging them. This estimate can then be iteratively improved for instance as in <ref> [17] </ref>. For simplicity, we assume no occlusion. Let A 1 be the leading right singular vector of D CH .
Reference: [18] <author> G.W. Stewart, J. G. Sun, </author> <title> Matrix Perturbation Theory, </title> <publisher> Academic Press, </publisher> <address> Boston, </address> <year> 1990. </year>
Reference-contexts: the rotational terms and are suppressed for small residual rotations. 9 The bias occurs only through errors in H V ; which lead to small errors in D of order the residual rotation times the noise. the reconstruction errors can be derived using bounds on the perturbations of singular vectors <ref> [18, 10] </ref>. Starting from the solution of (7) we can get an improved structure estimate that gives a better approximation to the exact MLE [10]. From first order perturbation theory for singular vectors [18], the covari-ance of the recovered A 1;2 can be estimated. <p> Starting from the solution of (7) we can get an improved structure estimate that gives a better approximation to the exact MLE [10]. From first order perturbation theory for singular vectors <ref> [18] </ref>, the covari-ance of the recovered A 1;2 can be estimated.
Reference: [19] <author> J. Inigo Thomas, A. Hanson, and J. Olien-sis, </author> <title> "Refining 3D reconstructions: A theoretical and experimental study of the effect of cross-correlations", </title> <journal> CVGIP:IU, </journal> <volume> Vol. 60, </volume> <pages> 359-370, </pages> <year> 1994. </year>
Reference-contexts: Similar results were obtained when we started by compensating the rotations initially. Our results improve on previous ones obtained via Kalman filtering <ref> [19, 20] </ref>. 3.1 Experiments: T z = 0 We applied our planar motion algorithm to part of the PUMA image sequence [7] (Figure 3). 32 points were automatically tracked over 16 image frames.
Reference: [20] <author> J. Inigo Thomas and J. Oliensis, </author> <title> "Isolation and Correction of Noise in Multi-Frame Structure from Motion," </title> <type> U. </type> <institution> of Massachusetts, </institution> <month> Oct </month> <year> 1994. </year>
Reference-contexts: Similar results were obtained when we started by compensating the rotations initially. Our results improve on previous ones obtained via Kalman filtering <ref> [19, 20] </ref>. 3.1 Experiments: T z = 0 We applied our planar motion algorithm to part of the PUMA image sequence [7] (Figure 3). 32 points were automatically tracked over 16 image frames.
Reference: [21] <author> C. Tomasi and T. Kanade, </author> <title> "Shape and motion from image streams under orthography: A factorization method," </title> <booktitle> IJCV 9, </booktitle> <pages> 137-154, </pages> <year> 1992. </year>
Reference-contexts: Algorithms already exist that cope well with large translations <ref> [21, 8] </ref>, but there was no previous algorithm well adapted for both small translations and large perspective effects. Our approach complements previous algorithms [8, 21] and together with them should suffice for most domains. <p> Algorithms already exist that cope well with large translations [21, 8], but there was no previous algorithm well adapted for both small translations and large perspective effects. Our approach complements previous algorithms <ref> [8, 21] </ref> and together with them should suffice for most domains. We have argued previously [11, 14] that it is best to design specialized rather than general SFM algorithms. <p> Like the algorithm of <ref> [21] </ref>, it operates in two stages. But with the translational motion confined to a plane or a line, the three translational vectors T x;y;z will be linearly dependent, D CH will have rank less than 3, and the general algorithm needs to be modified. <p> We now extract the row vector that best corresponds to its rows; it will be approximately proportional to S t V which contains all the structure information in D CH . With no occlusion, this can be done via the SVD as in <ref> [21] </ref>. When there is occlusion, we can derive a good initial guess for this row vector e.g. by determining rows that are at relatively small angles with respect to each other and averaging them. This estimate can then be iteratively improved for instance as in [17]. <p> is approximately rank 1: by extracting the leading right singular vector of D E (or rather of C 1=2 H D E ) we can compute almost the exact MLE estimate of the f~ E g components in a single stage, eliminating the bias of our previous two stage technique <ref> [21] </ref>. For an 11 image sequence with 256 2 images, using dense correspondences given at all 256 2 image points, this computation takes seconds on an Indigo II. <p> The offset of the camera optical axis from the rotation axis was about 6 ffi . The maximum displacement of the camera was 1.5 feet, and the 3D depths varied from 13.5 to 31.8 feet. The FOV was about 40 ffi . The algorithm of <ref> [21] </ref> failed to produce a reconstruction on this sequence. Two frame algorithms also produce poor reconstruction. Our initial computation of the rotations used the knowledge that they were primarily around the z-axis.
References-found: 18

