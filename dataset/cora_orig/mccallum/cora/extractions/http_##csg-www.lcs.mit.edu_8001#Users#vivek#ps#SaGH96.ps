URL: http://csg-www.lcs.mit.edu:8001/Users/vivek/ps/SaGH96.ps
Refering-URL: http://csg-www.lcs.mit.edu:8001/Users/vivek/sark_pub.html
Root-URL: 
Title: Locality Analysis for Distributed Shared-Memory Multiprocessors  
Author: Vivek Sarkar Guang R. Gao Shaohua Han 
Abstract: This paper studies the locality analysis problem for shared-memory multiprocessors, a class of parallel machines that has experienced steady and rapid growth in the past few years. The focus of this work is on estimation of the memory performance of a loop nest for a given set of computation and data distributions. We assume a distributed shared-memory multiprocessor model. We discuss how to estimate the total number of cache misses (compulsory misses, conflict misses, capacity misses), and also the fractions of these cache misses that result in local vs. remote memory accesses. The goal of our work is to use this performance estimation to guide automatic and semi-automatic selection of data distributions and loop transformations in programs written for future shared-memory multiprocessors. This paper also includes sim ulation results as validation of our analysis method. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Anant Agarwal, David Krantz, and Venkat Natarajan. </author> <title> Automatic Partitioning of Parallel Loops and Data Arrays for Distributed Shared Memory Multiprocessors. </title> <booktitle> International Conference on Parallel Computing, </booktitle> <year> 1993. </year>
Reference-contexts: Restructuring can reduce false sharing, but it may also have a negative impact on spatial locality. Thus it is hard to estimate how much pay-off restructuring can get. Agarwal, Krantz and Nararajan <ref> [1] </ref> present a theoretical framework for automatically partitioning parallel loops to minimize cache coherency traffic on shared-memory multiprocessors. They derive an optimal hyperparallelpiped tiling of iteration space for minimal communication for loops with general affine index expressions in multiprocessors with caches.
Reference: 2. <author> S. Amarasinghe and M. Lam. </author> <title> Generating efficient communication for distributed memory machines. </title> <booktitle> In Proceedings of ACM SIGPLAN'93 Conference on Programming Language Design and Implementation, </booktitle> <month> June </month> <year> 1993. </year>
Reference-contexts: Email: vivek@lcs.mit.edu. ?? Dept. of Electrical Engineering, University of Delaware, Newark 19711. Email: ggao@eecis.udel.edu. ??? School of Computer Science, McGill University, Montreal, Canada H3A 2A7. Email: shaohua@cs.mcgill.ca. mappings may be derived automatically by a compiler with (or without) guid-ance from user annotations and directives <ref> [2, 3, 15] </ref>. We assume a distributed shared memory model with caching. The program model considered in this work is a perfect loop nest, where array references contain affine subscript expressions.
Reference: 3. <author> J. M. Anderson and M. S. Lam. </author> <title> Global optimizations for parallelism and locality on scalable parallel machines. </title> <booktitle> ACM SIGPLAN '93 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 112-125, </pages> <address> June 1993. Albuquerque, NM. </address>
Reference-contexts: Email: vivek@lcs.mit.edu. ?? Dept. of Electrical Engineering, University of Delaware, Newark 19711. Email: ggao@eecis.udel.edu. ??? School of Computer Science, McGill University, Montreal, Canada H3A 2A7. Email: shaohua@cs.mcgill.ca. mappings may be derived automatically by a compiler with (or without) guid-ance from user annotations and directives <ref> [2, 3, 15] </ref>. We assume a distributed shared memory model with caching. The program model considered in this work is a perfect loop nest, where array references contain affine subscript expressions. <p> Both C and D have the form (d 1 ; : : : ; d m ), where m is the number of iteration/array dimensions, and each d j is one of block, cyclic, cyclic (n), or fl. Similar formulations of these mappings have been used elsewhere <ref> [11, 3, 7] </ref>. In this paper, we assume that the mapping of global data addresses to local memories stays fixed during program execution. In the rest of our discussion, we assume that a loop is sequential if its computation mapping is fl and is parallel (i.e. a doall loop) otherwise.
Reference: 4. <author> David F. Bacon, Jyh-Herng Chow, Dz ching R. Ju, K. Muthukumar, and Vivek Sarkar. </author> <title> A Compiler Framework for Restructuring Data Declarations to Enhance Cache and TLB Effectiveness. </title> <booktitle> CASCON '94 conference, </booktitle> <month> November </month> <year> 1994. </year>
Reference-contexts: Since the effective locality group has 2 fi 200 = 400 iterations, this amounts to an average of 603=400 = 1:51 misses/iteration. For the entire local iteration space, this estimation results in 1:51 fi 5; 000 ' 7; 538 cache misses. Program transformations such as array dimension padding <ref> [4] </ref> and array copying [14] can be used to improve the cache utilization efficiency. In this paper, our focus is on analysis of locality costs. <p> Using cache efficiency, the compiler can detect unfavorable strides and automatically adjust array dimensions through padding techniques. However, this work does not address the overall problem of locality analysis (estimating the number of misses) for array references in a loop nest. Bacon et al <ref> [4] </ref> focus on techniques for improving uniprocessor data locality by restructuring data declarations, as opposed to restructuring the computation without changing the data layout. They provide a padding algorithm for selecting appropriate padding amounts, which takes into account various cache and translation lookaside buffer effects collectively within a single framework.
Reference: 5. <author> David H. Bailey. </author> <title> Unfavorable Strides in Cache Memory Systems. </title> <journal> Scientific Programming, </journal> <volume> 4 </volume> <pages> 53-58, </pages> <year> 1995. </year> <note> RNR Technical Report RNR-92-015, </note> <institution> NASA Ames Research Center. </institution>
Reference-contexts: Unlike our approach of locality analysis by estimating a count of the number of cache misses, they measure the locality of a transformed code by intersecting the reuse vector space with the localized vector space. In <ref> [5] </ref>, Bailey presents a thorough analysis of the behavior of a direct-mapped cache with strided data access, and gives a formula for estimating cache efficiency. Using cache efficiency, the compiler can detect unfavorable strides and automatically adjust array dimensions through padding techniques.
Reference: 6. <author> Utpal Banerjee. </author> <title> Dependence Analysis for Supercomputing. </title> <publisher> Kluwer Academic Publishers, Norwell, </publisher> <address> Massachusetts, </address> <year> 1988. </year>
Reference-contexts: Our analysis is applicable to array references with affine subscript expressions. In this paper, we assume that all loop bounds expressions are invariant (rectangular), though the extension to trapezoidal loop bounds is straightforward using techniques such as those presented in <ref> [6] </ref>. We assume that a computation mapping C is given (either by a compiler or a user) which specifies partitioning of iterations onto processors, and a data mapping D is given which specifies partitioning of array elements onto processor local memories.
Reference: 7. <author> R. Berrendorf, M. Gerndt, and M. Mairandres. </author> <booktitle> Programming Shared Virtual Memory on the Intel Paragon Supercomputer . Proceedings of Fifth Workshop on Compilers for Parallel Computers, </booktitle> <year> 1995. </year> <type> Internal Report KFA-ZAM-IB-9509, </type> <institution> Research Centre Juelich, </institution> <note> Germany (also http://www.kfa-juelich.de/zam/ZAMPeople/gerndt.html). </note>
Reference-contexts: Both C and D have the form (d 1 ; : : : ; d m ), where m is the number of iteration/array dimensions, and each d j is one of block, cyclic, cyclic (n), or fl. Similar formulations of these mappings have been used elsewhere <ref> [11, 3, 7] </ref>. In this paper, we assume that the mapping of global data addresses to local memories stays fixed during program execution. In the rest of our discussion, we assume that a loop is sequential if its computation mapping is fl and is parallel (i.e. a doall loop) otherwise.
Reference: 8. <author> Jeanne Ferrante, Vivek Sarkar, and Wendy Thrash. </author> <title> On Estimating and Enhancing Cache Effectiveness. </title> <booktitle> Lecture Notes in Computer Science, </booktitle> (589):328-343, 1991. Proceedings of the Fourth International Workshop on Languages and Compilers for Parallel Computing, Santa Clara, California, USA, August 1991. 
Reference-contexts: The major results of this paper are twofold: We extend the method of estimating uniprocessor cache misses in <ref> [8] </ref> to estimate the number of non-local (remote) misses for different cache organizations (e.g. fully associative, direct-mapped and set-associative) under our program and machine models (Section 4 and 5). Our estimation methods are simple and efficient. Simulation results are presented to validate these methods. <p> Furthermore, in cases where an array dimension only involves two or fewer index variables | a frequent case in real programs | we provide an alternative proof based on the concept of reuse vectors and reuse spaces for the exact solution presented in <ref> [8] </ref>. The rest of the paper is organized as follows. Section 2 describes the machine model and program model assumed in our work. Section 3 states the locality analysis problem that is addressed by this paper. <p> For each array variable, X, estimate the number of distinct accesses (DA) for X's array reference in the local iteration space, I C (i), which equals the number of total (compulsory) misses incurred by processor i for accesses to X. We can use the heuristic bound method from <ref> [8] </ref> for this estimation, or the exact methods for special cases discussed later in section 6. <p> It is clear that this reference exhibits temporal locality e.g. B (1+2) and B (2+1) access the same array element. We estimate the total number of misses due to B (i1+i2) as the number of distinct accesses to B, DA B by using the method from <ref> [8] </ref> as follows (f lo and f hi are the low and high bounds of the expression i1+i2 in the local iteration space): f lo = (25i + 1) + 1 DA B = (25 (i + 1) + 200) (25i + 1 + 1) + 1 = 224 The array <p> Estimate the number of distinct accesses in the local array region consisting of the intersection of lower and upper bounds from step 2 and 3. We can use the heuristic bound method from <ref> [8] </ref> outlined in section 4.1 to do the counting, or the exact methods for special cases discussed later in section 6. Let us use the example in Figure 2 to illustrate the steps outlined above. We will estimate the number of local misses on processor 0 for array B. <p> The estimation techniques used in prior sections were based on upper bounds presented in <ref> [8] </ref>. [8] also contained a closed-form exact formula for a single array reference in a two-dimensional loop nest. In section 6.1, we study the case of three-dimensional loop nest, and state conditions under which the bounds introduced from [8] are provably exact. <p> The estimation techniques used in prior sections were based on upper bounds presented in <ref> [8] </ref>. [8] also contained a closed-form exact formula for a single array reference in a two-dimensional loop nest. In section 6.1, we study the case of three-dimensional loop nest, and state conditions under which the bounds introduced from [8] are provably exact. <p> techniques used in prior sections were based on upper bounds presented in <ref> [8] </ref>. [8] also contained a closed-form exact formula for a single array reference in a two-dimensional loop nest. In section 6.1, we study the case of three-dimensional loop nest, and state conditions under which the bounds introduced from [8] are provably exact. In section 6.2, we introduce the concepts of reuse vectors and reuse spaces, and demonstrate how to use these concepts to prove the correctness of the exact formula for two variables. <p> in one dimension of array A in a perfect nest of three loops 1 i n i , 1 j n j , 1 k n k , such that 1. 0 &lt; a b c, If a = 1, and n i max (b; c) then the bounds from <ref> [8] </ref> are exact. Proof. (Sketch) Note that f lo = 1 + b + c, and f hi = n i + bn j + cn k when a = 1. <p> Theorem 2. Consider subscript expression f = ai + bj + ck as in Theorem 1. If g = gcd (a; b; c) &gt; 1, and one of (a=g; b=g; c=g) equals 1, then the bounds from <ref> [8] </ref> are exact. Proof. (Sketch) Let f 0 = a 0 i + b 0 j + c 0 k, such that (a 0 ; b 0 ; c 0 ) = (a=g; b=g; c=g), and f = gf 0 . <p> Therefore, we can simply extend the solutions for estimating the number of distinct accesses (DA) to the number of distinct lines (DL) based on the solution outlined in <ref> [8] </ref>. In section 5.2, we outlined a method to estimate (T ) for a direct-mapped cache with S lines/sets. It needs to be extended for the L &gt; 1 case as discussed in [8]. <p> of distinct accesses (DA) to the number of distinct lines (DL) based on the solution outlined in <ref> [8] </ref>. In section 5.2, we outlined a method to estimate (T ) for a direct-mapped cache with S lines/sets. It needs to be extended for the L &gt; 1 case as discussed in [8]. More precise estimates of (T ) are possible when cache block alignment offset, number of loop iterations, and degree of cache associativity are also taken into account. Estimating Number of Misses for Read/Write Variables (False Sharing) We make a conservative estimate of false sharing overhead. <p> We refer the readers to <ref> [8] </ref> for a brief discussion on how to do the estimation in this case. 8.3 Set-associative Caches We considered locality analysis for a fully associative cache in section 5.1 and for a direct-mapped cache in section 5.2. A set-associative cache is a hybrid of these two cases. <p> Most of the references cited below perform locality analysis in the context of uniprocessor execution, and do not deal with identifying local vs. remote misses. Ferrante, Sarkar and Thrash <ref> [8] </ref> provide simple closed-form formulae that bound the number of distinct accesses (DA) and distinct lines (DL) for a single array reference in a given sequential loop nest. They show how to extend these bounds for multiple references to the same array variable.
Reference: 9. <author> D. Gannon, , W. Jalby, and K. Gallivan. </author> <title> Strategies for cache and local memory management by global program transformation. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 5 </volume> <pages> 587-616, </pages> <year> 1988. </year>
Reference-contexts: Consider the following example and its local iteration space for processor i do 10 i1 = i*100/4 + 1, (i+1)*100/4 The three references to array A, A (i1 1), A (i1) and A (i1 + 1), are said to be uniformly generated <ref> [9] </ref>. It is easy to see that the overwhelming majority of the three references overlap with each other.
Reference: 10. <author> Shaohua Han. </author> <title> Cache Misses Prediction for Array References in Loop Nest. </title> <type> Technical report, </type> <institution> School of Computer Science, McGill University, </institution> <year> 1996. </year> <type> Master's thesis in progress. </type>
Reference-contexts: Without loss of generality, we assume both a 1 and a 2 are positive. A closed-form solution for RV min is obtained as follows (see <ref> [10] </ref> for details): RV min = (a 1 =gcd (a 1 ; a 2 ); a 2 =gcd (a 1 ; a 2 )): (2) The above expression for RV min can be used to show that jRSj = (B 1 a 2 =gcd (a 1 ; a 2 ))(B 2
Reference: 11. <author> High Performance Fortran Forum. </author> <title> High Performance Fortran. Language Specification Version 0.4, </title> <month> December </month> <year> 1992. </year>
Reference-contexts: Both C and D have the form (d 1 ; : : : ; d m ), where m is the number of iteration/array dimensions, and each d j is one of block, cyclic, cyclic (n), or fl. Similar formulations of these mappings have been used elsewhere <ref> [11, 3, 7] </ref>. In this paper, we assume that the mapping of global data addresses to local memories stays fixed during program execution. In the rest of our discussion, we assume that a loop is sequential if its computation mapping is fl and is parallel (i.e. a doall loop) otherwise.
Reference: 12. <author> M. D. Hill. </author> <title> Aspects of Cache Memories and Instruction Buffer Performance. </title> <type> PhD thesis, </type> <institution> Univ. of California at Berkeley, </institution> <month> November </month> <year> 1987. </year> <type> Tech. Rep. </type> <note> UCB/CSD 87/381. </note>
Reference-contexts: When we deal with real caches with finite capacity and a limited degree of set-associativity, it is not sufficient to estimate the number of compulsory misses; we also need to estimate the number of local and remote capacity and collision misses <ref> [12] </ref>. In section 5.1, we address the problem of counting capacity misses by estimating the number of total misses for a fully associative cache with S lines. In section 5.2, we estimate the number of total misses for direct-mapped cache with S sets/lines of unit size.
Reference: 13. <author> Tor E. Jeremiassen and Susan J. Eggers. </author> <title> Reducing False Sharing on Shared Memory Multiprocessors through Compile Time Data Transformations. </title> <booktitle> The fifth Symposium on Principles and Practice of Parallel Programming, </booktitle> <month> July </month> <year> 1995. </year>
Reference-contexts: They provide a padding algorithm for selecting appropriate padding amounts, which takes into account various cache and translation lookaside buffer effects collectively within a single framework. Jeremiassen and Eggers <ref> [13] </ref> develop compiler algorithms that analyze parallel programs and restructure their shared data to reduce the number of false sharing misses. The algorithms analyze per-process shared data accesses, pinpoint the data structures that are susceptible to false sharing and choose an appropriate transformation to reduce it.
Reference: 14. <author> Monica S. Lam, Edward E. Rothberg, and Michael E. Wolf. </author> <title> The Cache Performance and Optimization of Blocked Algorithms. </title> <booktitle> Proceedings of the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <month> April </month> <year> 1991. </year>
Reference-contexts: For the entire local iteration space, this estimation results in 1:51 fi 5; 000 ' 7; 538 cache misses. Program transformations such as array dimension padding [4] and array copying <ref> [14] </ref> can be used to improve the cache utilization efficiency. In this paper, our focus is on analysis of locality costs.
Reference: 15. <author> Qi Ning, Van Dongen Vincent, and Guang R. Gao. </author> <title> Automatic Decomposition in EPPP Compiler. </title> <booktitle> CASCON '94 conference, </booktitle> <pages> pages 283-291, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: Email: vivek@lcs.mit.edu. ?? Dept. of Electrical Engineering, University of Delaware, Newark 19711. Email: ggao@eecis.udel.edu. ??? School of Computer Science, McGill University, Montreal, Canada H3A 2A7. Email: shaohua@cs.mcgill.ca. mappings may be derived automatically by a compiler with (or without) guid-ance from user annotations and directives <ref> [2, 3, 15] </ref>. We assume a distributed shared memory model with caching. The program model considered in this work is a perfect loop nest, where array references contain affine subscript expressions.
Reference: 16. <author> M. J. Serrano. </author> <title> Performance Tradeoffs in Multistreamed Superscalar Architectures. </title> <type> PhD thesis, </type> <institution> University of California at Santa Barbara, </institution> <month> March </month> <year> 1994. </year>
Reference-contexts: The simulation results were obtained using the Powersim <ref> [16] </ref> tool, with an extension to cause the entire cache to be flushed after each locality group instance.
Reference: 17. <author> Ben Verghese, Scott Devine, Anoop Gupta, and Mendel Rosenblum. </author> <booktitle> Operating System Support for Improving Data Locality on CC-NUMA Computer Servers . The seventh International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <month> October </month> <year> 1996. </year>
Reference-contexts: Their solution addresses a limited problem statement that of partitioning a loop nest with perfect load balance. They restrict their analysis to the case of a unit line size and do not take cache size considerations into account. Verghese et al <ref> [17] </ref> study the performance improvements provided by OS supported dynamic page migration replication on CC-NUMA (cache-coherent non-uniform memory access) machine. The operating system can improve data locality by migrating and replicating pages.
Reference: 18. <author> Michael E. Wolf and Monica S. Lam. </author> <title> A Data Locality Optimization Algorithm. </title> <booktitle> Proceedings of the ACM SIGPLAN Symposium on Programming Language Design and Implementation, </booktitle> <pages> pages 30-44, </pages> <month> June </month> <year> 1991. </year> <title> This article was processed using the L a T E X macro package with LLNCS style </title>
Reference-contexts: These bounds provide an estimate of the number of cache misses incurred by a given loop nest. They also showed how to analyze set conflicts in the case of direct mapped and set associative caches with non-unit line sizes. Wolf and Lam <ref> [18] </ref> propose an algorithm that improves the locality of a loop nest by transforming the code via interchange, reversal, skewing and tiling based on a mathematical formulation of reuse and locality, and a loop transformation theory that unifies the various transforms as unimodular transformations.
References-found: 18

