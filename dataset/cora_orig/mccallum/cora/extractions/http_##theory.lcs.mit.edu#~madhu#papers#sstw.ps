URL: http://theory.lcs.mit.edu/~madhu/papers/sstw.ps
Refering-URL: http://theory.lcs.mit.edu/~madhu/papers.html
Root-URL: 
Title: Gadgets, Approximation, and Linear Programming [Extended Abstract]  
Author: Luca Trevisan Gregory B. Sorkin Madhu Sudan David P. Williamson 
Note: From: Proceedings of the 37th Annual IEEE Symposium on Foundations of Computer Science, October 1996. Please note final page, an errata sheet distributed at FOCS.  
Abstract: We present a linear-programming based method for finding "gadgets", i.e., combinatorial structures reducing constraints of one optimization problems to constraints of another. A key step in this method is a simple observation which limits the search space to a finite one. Using this new method we present a number of new, computer-constructed gadgets for several different reductions. This method also answers a question posed by [1] on how to prove the optimality of gadgets | we show how LP duality gives such proofs. The new gadgets improve hardness results for MAX CUT and MAX DICUT, showing that approximating these problems to within factors of 60=61 and 44=45 respectively is NP-hard (improving upon the previous hardness of 71=72 for both problems [1]). We also use the gadgets to obtain an improved approximation algorithm for MAX 3SAT which guarantees an approximation ratio of :801. This improves upon the previous best bound (implicit in [6, 3]) of :7704. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Bellare, O. Goldreich, and M. Sudan. </author> <title> Free bits, PCPs and non-approximability towards tight results (version 3). Technical Report TR95-024, </title> <booktitle> Electronic Colloquium on Computational Complexity, </booktitle> <month> Jan. </month> <year> 1996. </year> <note> See http://www.eccc .uni-trier.de/eccc/. </note>
Reference-contexts: Despite their importance, the construction of gadgets has always been a "black art", with no known uniform methods. In fact, until recently no one had even proposed a concrete definition of a gadget; Bellare, Goldreich and Sudan <ref> [1] </ref> finally did so, with a view to quantifying the role of gadgets in non-approximability results. Their definition is accompanied by a seemingly natural "cost" measure for a gadget. The more "costly" the gadget, the weaker the reduction. <p> (and with a bit of luck) we can often get the bounds to match, thereby producing optimal gadgets with even greater efficiency! Armed with this tool for finding gadgets (and an RS/6000, OSL, and often APL2 1 ), we examine some of the known gadgets and construct many new ones. <ref> [1] </ref> presented gadgets reducing the computation of a verifier to several problems, including MAX 3SAT, MAX 2SAT, and MAX CUT. We examine these in turn and show that the gadgets in [1] for MAX 3SAT and MAX 2SAT were optimal, but their MAX CUT gadget was not. <p> RS/6000, OSL, and often APL2 1 ), we examine some of the known gadgets and construct many new ones. <ref> [1] </ref> presented gadgets reducing the computation of a verifier to several problems, including MAX 3SAT, MAX 2SAT, and MAX CUT. We examine these in turn and show that the gadgets in [1] for MAX 3SAT and MAX 2SAT were optimal, but their MAX CUT gadget was not. We improve on the efficiency of the last, thereby improving on the factor to which approximating MAX CUT can be shown to be NP-hard. <p> We also construct a new gadget for the MAX DICUT problem, thereby strengthening its hardness. Our final result, obtained by plugging our gadget into the proof of <ref> [1] </ref>, shows that approximating MAX CUT to within a factor of 60=61 is NP-hard, as is approximating MAX DICUT to within a factor of 44=45. (For both problems, the previous best hardness factor was 71=72 [1].) 2 1 respectively, an IBM RiscSystem/6000 workstation, the IBM Optimization Subroutine Library, which includes a <p> Our final result, obtained by plugging our gadget into the proof of <ref> [1] </ref>, shows that approximating MAX CUT to within a factor of 60=61 is NP-hard, as is approximating MAX DICUT to within a factor of 44=45. (For both problems, the previous best hardness factor was 71=72 [1].) 2 1 respectively, an IBM RiscSystem/6000 workstation, the IBM Optimization Subroutine Library, which includes a linear programming package, and (not that we're partisan) IBM's APL2 programming language 2 Note that approximation ratios in this paper for maximiza Obtaining better reductions between problems can also yield improved approximation algorithms for some <p> We show: first, that there exist constants c and s, c=s &gt; 34=33, such that NP PCP c;s [log; 2]; and second, for all c; s with c=s &gt; 2:7214, PCP c;s [log; 3] P. The best previously known bounds for these results were 74/73 <ref> [1] </ref> and 4 [9] respectively. All the gadgets we use are computer constructed. <p> This is the reciprocal of the factors mentioned in <ref> [1] </ref> and exactly the factors as stated in [10, 5, 6, 3]. 2 Definitions We begin with some definitions we will need before giving the definition of a gadget from [1]. Definition 2.1 A (k-ary) constraint function is a boolean function f : f0; 1g k ! f0; 1g. <p> This is the reciprocal of the factors mentioned in <ref> [1] </ref> and exactly the factors as stated in [10, 5, 6, 3]. 2 Definitions We begin with some definitions we will need before giving the definition of a gadget from [1]. Definition 2.1 A (k-ary) constraint function is a boolean function f : f0; 1g k ! f0; 1g. <p> We can now formally define a gadget. Definition 2.4 [Gadget <ref> [1] </ref>] For ff 2 R + , a constraint function f : f0; 1g k ! f0; 1g, and a constraint family F: an ff-gadget (or "gadget with performance ff") reducing f to F is a finite collection of real weights w j 0, and associated constraints C j from F <p> The gadget reduces a function f (called source) to a family F (called target). The above list of constraint families includes both sources and targets of reductions. Our interest in the function families PC and RMBC comes from the following theorem of <ref> [1] </ref>. Theorem 2.7 [1] For any family F , if there exists an ff 1 -gadget reducing every function in PC to F and an ff 2 -gadget reducing every function in RMBC to F , then for any fl &gt; 0, MAX F is hard to approximate to within 1 <p> The gadget reduces a function f (called source) to a family F (called target). The above list of constraint families includes both sources and targets of reductions. Our interest in the function families PC and RMBC comes from the following theorem of <ref> [1] </ref>. Theorem 2.7 [1] For any family F , if there exists an ff 1 -gadget reducing every function in PC to F and an ff 2 -gadget reducing every function in RMBC to F , then for any fl &gt; 0, MAX F is hard to approximate to within 1 :15 Thus using <p> The sole exception (y) is the best possible strict gadget; there is a non-strict 3-gadget. All previous results quoted are interpretations of the results in <ref> [1] </ref>, except the gadget reducing 3SAT to 2SAT, which is due to [4], and the gadget reducing PC to 3SAT, which is folklore. The gadgets marked with (z) are not strictly reductions to CUT; see Section 4.1. 0 satisfies (4)). <p> A gadget over 7 variables can thus be identified with the vector (w 1 ; : : : ; w 98 ) of the weights of the constraints. Since in <ref> [1] </ref> it is shown that an 11-gadget exists reducing PC 0 to 2SAT, it follows that in an optimum gadget no constraint will have a weight larger than 11. <p> An optimal LP solution yields an optimal ff-gadget (one where ff is as small as possible). In particular, (LP1) has optimal solution ff = 11, proving the optimality of the <ref> [1] </ref> gadget. In the remaining sections we give applications of some gadgets and then report their best possible gad gets. All gadgets are computer-constructed unless otherwise noted. <p> Following <ref> [1] </ref>, we generalize the definition: Definition 4.1 A gadget with auxiliary constant 0 is a gadget as previously defined, except that (1-4) are only required to hold when Y 1 = 0. <p> To get a hardness result for MAX CUT, we first need the following lemma, which is a very minor modifica tion of a lemma in <ref> [1] </ref>. 6 has weight .5. The auxiliary variable which is always 0 is labelled 0. Lemma 4.2 [1] For the constraint family CUT, if there exists an ff 1 -gadget with constant 0 reducing every function in PC to CUT and an ff 2 -gadget with constant 0 reducing every function <p> To get a hardness result for MAX CUT, we first need the following lemma, which is a very minor modifica tion of a lemma in <ref> [1] </ref>. 6 has weight .5. The auxiliary variable which is always 0 is labelled 0. Lemma 4.2 [1] For the constraint family CUT, if there exists an ff 1 -gadget with constant 0 reducing every function in PC to CUT and an ff 2 -gadget with constant 0 reducing every function in RMBC to CUT, then for any fl &gt; 0, MAX CUT is NP-hard to approximate to <p> Using the well-known reduction from constraint satisfaction problems to probabilistically checkable proofs, Theorem 4.11 implies that constants c and s exist such that NP PCP c;s [log; 2] and c=s &gt; 34=33. The previously known gap between the completeness and soundness achievable reading two bits was 74=73 <ref> [1] </ref>. 5 Interlude: Methodology Despite the seeming variety, all gadgets in this paper were computed by a single APL2 program (calling OSL to solve the constructed LP). The source function f is specified explicitly, by a small program.
Reference: [2] <author> P. Crescenzi, R. Silvestri, and L. Trevisan. </author> <title> To weight or not to weight: Where is the question? In Proc. </title> <booktitle> of the Fourth Israel Symposium on Theory of Computing and Systems, </booktitle> <pages> pages 68-77, </pages> <year> 1996. </year>
Reference-contexts: This seemingly helps only in showing hardness of weighted optimization problems, but a new result due to Crescenzi, Silvestri and Trevisan <ref> [2] </ref> shows that for a large class of optimization problems (including all the ones considered in this paper), the weighted versions are exactly as hard with respect to approximation as the unweighted ones. Therefore, working with the weighted version is as good as working with the unweighted one. <p> We show: first, that there exist constants c and s, c=s &gt; 34=33, such that NP PCP c;s <ref> [log; 2] </ref>; and second, for all c; s with c=s &gt; 2:7214, PCP c;s [log; 3] P. The best previously known bounds for these results were 74/73 [1] and 4 [9] respectively. All the gadgets we use are computer constructed. <p> MAX 2CSP can be approximated within .859 [3]. The above theorem has implications for probabilistically checkable proofs. Using the well-known reduction from constraint satisfaction problems to probabilistically checkable proofs, Theorem 4.11 implies that constants c and s exist such that NP PCP c;s <ref> [log; 2] </ref> and c=s &gt; 34=33. The previously known gap between the completeness and soundness achievable reading two bits was 74=73 [1]. 5 Interlude: Methodology Despite the seeming variety, all gadgets in this paper were computed by a single APL2 program (calling OSL to solve the constructed LP).
Reference: [3] <author> U. Feige and M. X. Goemans. </author> <title> Approximating the value of two prover proof systems, with applications to MAX 2SAT and MAX DICUT. </title> <booktitle> In Proc. of the Third Israel Symposium on Theory of Computing and Systems, </booktitle> <pages> pages 182-189, </pages> <year> 1995. </year>
Reference-contexts: We illustrate the point by constructing a gadget reducing MAX 3SAT to MAX 2SAT. Using this new reduction in combination with a technique of Goemans and Williamson [5, 6] and the state-of-the-art :931-approximation algorithm for MAX 2SAT due to Feige and Goemans <ref> [3] </ref> (which improves upon the previous (famous) :878-approximation algorithm of [6]), we obtain a :801-approximation algorithm for MAX 3SAT. The best result that could be obtained previously, by combining the technique of [5, 6] and the bound of [3], was :7704. (This is not mentioned explicitly anywhere but why would we <p> the state-of-the-art :931-approximation algorithm for MAX 2SAT due to Feige and Goemans <ref> [3] </ref> (which improves upon the previous (famous) :878-approximation algorithm of [6]), we obtain a :801-approximation algorithm for MAX 3SAT. The best result that could be obtained previously, by combining the technique of [5, 6] and the bound of [3], was :7704. (This is not mentioned explicitly anywhere but why would we lie. See also the :769-approximation algorithm in the paper of Ono, Hirata, and Asano [8].) Finally, our reductions have implications for probabilistically checkable proof systems. <p> We show: first, that there exist constants c and s, c=s &gt; 34=33, such that NP PCP c;s [log; 2]; and second, for all c; s with c=s &gt; 2:7214, PCP c;s <ref> [log; 3] </ref> P. The best previously known bounds for these results were 74/73 [1] and 4 [9] respectively. All the gadgets we use are computer constructed. <p> This is the reciprocal of the factors mentioned in [1] and exactly the factors as stated in <ref> [10, 5, 6, 3] </ref>. 2 Definitions We begin with some definitions we will need before giving the definition of a gadget from [1]. Definition 2.1 A (k-ary) constraint function is a boolean function f : f0; 1g k ! f0; 1g. <p> We also use 2SAT as a target to obtain new approximation algorithms for the source (by a reduction to MAX 2SAT and using the algorithm of <ref> [3] </ref> to approxi mate this problem). The two families reduced to 2SAT in this way are 3SAT and 3ConjSAT. 3 The Basic Procedure In this section we shall illustrate our technique by constructing a gadget reducing PC 0 to 2SAT. <p> All are optimal and strict. Theorem 4.11 For every fl &gt; 0, MAX 2CSP is hard to approximate to within :97 + fl. In particular, MAX 2CSP is hard to approximate to within 33=34. MAX 2CSP can be approximated within .859 <ref> [3] </ref>. The above theorem has implications for probabilistically checkable proofs. Using the well-known reduction from constraint satisfaction problems to probabilistically checkable proofs, Theorem 4.11 implies that constants c and s exist such that NP PCP c;s [log; 2] and c=s &gt; 34=33. <p> Lemma 6.2 <ref> [3] </ref> There exists a polynomial-time (:976; :931) approximation algorithm for MAX 2SAT. 6.1 MAX 3SAT In this section we show how to derive an improved approximation algorithm for MAX 3SAT. <p> By restricting techniques in [6] from MAX SAT to MAX 3SAT and using a :931-approximation algorithm for MAX 2SAT due to Feige and Goemans <ref> [3] </ref>, one can obtain a :7704-approximation algorithm for MAX 3SAT. The basic idea of [6] is to reduce each clause of length 3 to the three possible subclauses of length 2, give each new length-2 clause one-third the original weight, and then apply an approximation algorithm for MAX 2SAT. <p> The gadget is composed of one length-1 clause and three length-2 clauses. Theorem 6.8 MAX 3ConjSAT has a polynomial-time .367-approximation algorithm. It is shown by Trevisan [9] that the above theorem has consequences for PCP c;s <ref> [log; 3] </ref>. This is because the computation of the verifier in such a proof system can be described by a decision tree of depth 3, for every choice of random string. <p> Further, there is a 1-gadget reducing every function which can be computed by a decision tree of depth k to kConjSAT. Thus we get the following corollary for PCP systems using 3 bits of queries. Corollary 6.9 PCP c;s <ref> [log; 3] </ref> P provided that c=s &gt; 2:7214.
Reference: [4] <author> M. Garey, D. Johnson, and L. Stockmeyer. </author> <title> Some simplified NP-complete graph problems. </title> <journal> Theoretical Comput. Sci., </journal> <volume> 1 </volume> <pages> 237-267, </pages> <year> 1976. </year>
Reference-contexts: 1 Introduction A "gadget" is a finite combinatorial structure which translates constraints of one optimization problem into a set of constraints of a second optimization problem. A typical example is in the reduction from 3SAT to MAX 2SAT <ref> [4] </ref> in which a clause C k = X 1 _ X 2 _ X 3 is replaced by ten clauses X 1 ; X 2 ; X 3 ; :X 1 _ :X 2 ; :X 2 _ :X 3 ; :X 3 _ :X 1 ; fl Dipartimento di <p> The sole exception (y) is the best possible strict gadget; there is a non-strict 3-gadget. All previous results quoted are interpretations of the results in [1], except the gadget reducing 3SAT to 2SAT, which is due to <ref> [4] </ref>, and the gadget reducing PC to 3SAT, which is folklore. The gadgets marked with (z) are not strictly reductions to CUT; see Section 4.1. 0 satisfies (4)).
Reference: [5] <author> M. X. Goemans and D. P. Williamson. </author> <title> New 3/4-approximation algorithms for the maximum sat-isfiability problem. </title> <journal> SIAM Journal on Discrete Mathematics, </journal> <volume> 7 </volume> <pages> 656-666, </pages> <year> 1994. </year>
Reference-contexts: We illustrate the point by constructing a gadget reducing MAX 3SAT to MAX 2SAT. Using this new reduction in combination with a technique of Goemans and Williamson <ref> [5, 6] </ref> and the state-of-the-art :931-approximation algorithm for MAX 2SAT due to Feige and Goemans [3] (which improves upon the previous (famous) :878-approximation algorithm of [6]), we obtain a :801-approximation algorithm for MAX 3SAT. The best result that could be obtained previously, by combining the technique of [5, 6] and the <p> Goemans and Williamson <ref> [5, 6] </ref> and the state-of-the-art :931-approximation algorithm for MAX 2SAT due to Feige and Goemans [3] (which improves upon the previous (famous) :878-approximation algorithm of [6]), we obtain a :801-approximation algorithm for MAX 3SAT. The best result that could be obtained previously, by combining the technique of [5, 6] and the bound of [3], was :7704. (This is not mentioned explicitly anywhere but why would we lie. See also the :769-approximation algorithm in the paper of Ono, Hirata, and Asano [8].) Finally, our reductions have implications for probabilistically checkable proof systems. <p> This is the reciprocal of the factors mentioned in [1] and exactly the factors as stated in <ref> [10, 5, 6, 3] </ref>. 2 Definitions We begin with some definitions we will need before giving the definition of a gadget from [1]. Definition 2.1 A (k-ary) constraint function is a boolean function f : f0; 1g k ! f0; 1g.
Reference: [6] <author> M. X. Goemans and D. P. Williamson. </author> <title> Improved approximation algorithms for maximum cut and satisfiability problems using semidefinite programming. </title> <journal> Journal of the ACM, </journal> <volume> 42 </volume> <pages> 1115-1145, </pages> <year> 1995. </year>
Reference-contexts: We illustrate the point by constructing a gadget reducing MAX 3SAT to MAX 2SAT. Using this new reduction in combination with a technique of Goemans and Williamson <ref> [5, 6] </ref> and the state-of-the-art :931-approximation algorithm for MAX 2SAT due to Feige and Goemans [3] (which improves upon the previous (famous) :878-approximation algorithm of [6]), we obtain a :801-approximation algorithm for MAX 3SAT. The best result that could be obtained previously, by combining the technique of [5, 6] and the <p> Using this new reduction in combination with a technique of Goemans and Williamson [5, 6] and the state-of-the-art :931-approximation algorithm for MAX 2SAT due to Feige and Goemans [3] (which improves upon the previous (famous) :878-approximation algorithm of <ref> [6] </ref>), we obtain a :801-approximation algorithm for MAX 3SAT. The best result that could be obtained previously, by combining the technique of [5, 6] and the bound of [3], was :7704. (This is not mentioned explicitly anywhere but why would we lie. <p> Goemans and Williamson <ref> [5, 6] </ref> and the state-of-the-art :931-approximation algorithm for MAX 2SAT due to Feige and Goemans [3] (which improves upon the previous (famous) :878-approximation algorithm of [6]), we obtain a :801-approximation algorithm for MAX 3SAT. The best result that could be obtained previously, by combining the technique of [5, 6] and the bound of [3], was :7704. (This is not mentioned explicitly anywhere but why would we lie. See also the :769-approximation algorithm in the paper of Ono, Hirata, and Asano [8].) Finally, our reductions have implications for probabilistically checkable proof systems. <p> This is the reciprocal of the factors mentioned in [1] and exactly the factors as stated in <ref> [10, 5, 6, 3] </ref>. 2 Definitions We begin with some definitions we will need before giving the definition of a gadget from [1]. Definition 2.1 A (k-ary) constraint function is a boolean function f : f0; 1g k ! f0; 1g. <p> Lemma 6.2 [3] There exists a polynomial-time (:976; :931) approximation algorithm for MAX 2SAT. 6.1 MAX 3SAT In this section we show how to derive an improved approximation algorithm for MAX 3SAT. By restricting techniques in <ref> [6] </ref> from MAX SAT to MAX 3SAT and using a :931-approximation algorithm for MAX 2SAT due to Feige and Goemans [3], one can obtain a :7704-approximation algorithm for MAX 3SAT. The basic idea of [6] is to reduce each clause of length 3 to the three possible subclauses of length 2, <p> By restricting techniques in <ref> [6] </ref> from MAX SAT to MAX 3SAT and using a :931-approximation algorithm for MAX 2SAT due to Feige and Goemans [3], one can obtain a :7704-approximation algorithm for MAX 3SAT. The basic idea of [6] is to reduce each clause of length 3 to the three possible subclauses of length 2, give each new length-2 clause one-third the original weight, and then apply an approximation algorithm for MAX 2SAT.
Reference: [7] <author> J. H-astad. </author> <type> Unpublished manuscript, </type> <year> 1996. </year>
Reference-contexts: It is possible to show that this is a feasible solution for (DUAL2) and it is immediate to verify that its cost is 4. 2 Note: In a recent breakthrough result, Hastad <ref> [7] </ref> has shown that MAX PC is hard to approximate to within 1=2 + fl, for any fl &gt; 0. The results translate to a surprising threshold of 7=8 + fl for the approximability of MAX E3SAT.
Reference: [8] <author> T. Ono, T. Hirata, and T. Asano. </author> <title> An approximation algorithm for MAX 3SAT. </title> <note> To appear in Scan-dinavian Workshop on Algorithm Theory., </note> <year> 1996. </year>
Reference-contexts: The best result that could be obtained previously, by combining the technique of [5, 6] and the bound of [3], was :7704. (This is not mentioned explicitly anywhere but why would we lie. See also the :769-approximation algorithm in the paper of Ono, Hirata, and Asano <ref> [8] </ref>.) Finally, our reductions have implications for probabilistically checkable proof systems.
Reference: [9] <author> L. Trevisan. </author> <title> Positive linear programming, parallel approximation, </title> <journal> and PCPs. </journal> <note> To appear in European Symposium on Algorithms, </note> <year> 1996. </year>
Reference-contexts: We show: first, that there exist constants c and s, c=s &gt; 34=33, such that NP PCP c;s [log; 2]; and second, for all c; s with c=s &gt; 2:7214, PCP c;s [log; 3] P. The best previously known bounds for these results were 74/73 [1] and 4 <ref> [9] </ref> respectively. All the gadgets we use are computer constructed. <p> Lemma 6.7 For any f 2 3ConjSAT there exists a strict (and optimal) 4-gadget reducing f to 2SAT. The gadget is composed of one length-1 clause and three length-2 clauses. Theorem 6.8 MAX 3ConjSAT has a polynomial-time .367-approximation algorithm. It is shown by Trevisan <ref> [9] </ref> that the above theorem has consequences for PCP c;s [log; 3]. This is because the computation of the verifier in such a proof system can be described by a decision tree of depth 3, for every choice of random string. <p> Thus we get the following corollary for PCP systems using 3 bits of queries. Corollary 6.9 PCP c;s [log; 3] P provided that c=s &gt; 2:7214. The previous best trade-off between completeness and soundness for polynomial-time PCP classes was c=s &gt; 4 <ref> [9] </ref>. 7 A Lower Bound from Duality All the computer-constructed gadgets referred to in the preceding sections come with automatic proofs of optimality: the LP formulation guarantees optimality mathematically, and the equality of the objective values computed for the LP and its dual assures optimality in practice.

Reference: [1] <author> H. Karloff and U. </author> <title> Zwick. </title> <type> Personal communication. </type> <month> September </month> <year> 1996. </year>
Reference-contexts: Despite their importance, the construction of gadgets has always been a "black art", with no known uniform methods. In fact, until recently no one had even proposed a concrete definition of a gadget; Bellare, Goldreich and Sudan <ref> [1] </ref> finally did so, with a view to quantifying the role of gadgets in non-approximability results. Their definition is accompanied by a seemingly natural "cost" measure for a gadget. The more "costly" the gadget, the weaker the reduction. <p> (and with a bit of luck) we can often get the bounds to match, thereby producing optimal gadgets with even greater efficiency! Armed with this tool for finding gadgets (and an RS/6000, OSL, and often APL2 1 ), we examine some of the known gadgets and construct many new ones. <ref> [1] </ref> presented gadgets reducing the computation of a verifier to several problems, including MAX 3SAT, MAX 2SAT, and MAX CUT. We examine these in turn and show that the gadgets in [1] for MAX 3SAT and MAX 2SAT were optimal, but their MAX CUT gadget was not. <p> RS/6000, OSL, and often APL2 1 ), we examine some of the known gadgets and construct many new ones. <ref> [1] </ref> presented gadgets reducing the computation of a verifier to several problems, including MAX 3SAT, MAX 2SAT, and MAX CUT. We examine these in turn and show that the gadgets in [1] for MAX 3SAT and MAX 2SAT were optimal, but their MAX CUT gadget was not. We improve on the efficiency of the last, thereby improving on the factor to which approximating MAX CUT can be shown to be NP-hard. <p> We also construct a new gadget for the MAX DICUT problem, thereby strengthening its hardness. Our final result, obtained by plugging our gadget into the proof of <ref> [1] </ref>, shows that approximating MAX CUT to within a factor of 60=61 is NP-hard, as is approximating MAX DICUT to within a factor of 44=45. (For both problems, the previous best hardness factor was 71=72 [1].) 2 1 respectively, an IBM RiscSystem/6000 workstation, the IBM Optimization Subroutine Library, which includes a <p> Our final result, obtained by plugging our gadget into the proof of <ref> [1] </ref>, shows that approximating MAX CUT to within a factor of 60=61 is NP-hard, as is approximating MAX DICUT to within a factor of 44=45. (For both problems, the previous best hardness factor was 71=72 [1].) 2 1 respectively, an IBM RiscSystem/6000 workstation, the IBM Optimization Subroutine Library, which includes a linear programming package, and (not that we're partisan) IBM's APL2 programming language 2 Note that approximation ratios in this paper for maximiza Obtaining better reductions between problems can also yield improved approximation algorithms for some <p> We show: first, that there exist constants c and s, c=s &gt; 34=33, such that NP PCP c;s [log; 2]; and second, for all c; s with c=s &gt; 2:7214, PCP c;s [log; 3] P. The best previously known bounds for these results were 74/73 <ref> [1] </ref> and 4 [9] respectively. All the gadgets we use are computer constructed. <p> This is the reciprocal of the factors mentioned in <ref> [1] </ref> and exactly the factors as stated in [10, 5, 6, 3]. 2 Definitions We begin with some definitions we will need before giving the definition of a gadget from [1]. Definition 2.1 A (k-ary) constraint function is a boolean function f : f0; 1g k ! f0; 1g. <p> This is the reciprocal of the factors mentioned in <ref> [1] </ref> and exactly the factors as stated in [10, 5, 6, 3]. 2 Definitions We begin with some definitions we will need before giving the definition of a gadget from [1]. Definition 2.1 A (k-ary) constraint function is a boolean function f : f0; 1g k ! f0; 1g. <p> We can now formally define a gadget. Definition 2.4 [Gadget <ref> [1] </ref>] For ff 2 R + , a constraint function f : f0; 1g k ! f0; 1g, and a constraint family F: an ff-gadget (or "gadget with performance ff") reducing f to F is a finite collection of real weights w j 0, and associated constraints C j from F <p> The gadget reduces a function f (called source) to a family F (called target). The above list of constraint families includes both sources and targets of reductions. Our interest in the function families PC and RMBC comes from the following theorem of <ref> [1] </ref>. Theorem 2.7 [1] For any family F , if there exists an ff 1 -gadget reducing every function in PC to F and an ff 2 -gadget reducing every function in RMBC to F , then for any fl &gt; 0, MAX F is hard to approximate to within 1 <p> The gadget reduces a function f (called source) to a family F (called target). The above list of constraint families includes both sources and targets of reductions. Our interest in the function families PC and RMBC comes from the following theorem of <ref> [1] </ref>. Theorem 2.7 [1] For any family F , if there exists an ff 1 -gadget reducing every function in PC to F and an ff 2 -gadget reducing every function in RMBC to F , then for any fl &gt; 0, MAX F is hard to approximate to within 1 :15 Thus using <p> The sole exception (y) is the best possible strict gadget; there is a non-strict 3-gadget. All previous results quoted are interpretations of the results in <ref> [1] </ref>, except the gadget reducing 3SAT to 2SAT, which is due to [4], and the gadget reducing PC to 3SAT, which is folklore. The gadgets marked with (z) are not strictly reductions to CUT; see Section 4.1. 0 satisfies (4)). <p> A gadget over 7 variables can thus be identified with the vector (w 1 ; : : : ; w 98 ) of the weights of the constraints. Since in <ref> [1] </ref> it is shown that an 11-gadget exists reducing PC 0 to 2SAT, it follows that in an optimum gadget no constraint will have a weight larger than 11. <p> An optimal LP solution yields an optimal ff-gadget (one where ff is as small as possible). In particular, (LP1) has optimal solution ff = 11, proving the optimality of the <ref> [1] </ref> gadget. In the remaining sections we give applications of some gadgets and then report their best possible gad gets. All gadgets are computer-constructed unless otherwise noted. <p> Following <ref> [1] </ref>, we generalize the definition: Definition 4.1 A gadget with auxiliary constant 0 is a gadget as previously defined, except that (1-4) are only required to hold when Y 1 = 0. <p> To get a hardness result for MAX CUT, we first need the following lemma, which is a very minor modifica tion of a lemma in <ref> [1] </ref>. 6 has weight .5. The auxiliary variable which is always 0 is labelled 0. Lemma 4.2 [1] For the constraint family CUT, if there exists an ff 1 -gadget with constant 0 reducing every function in PC to CUT and an ff 2 -gadget with constant 0 reducing every function <p> To get a hardness result for MAX CUT, we first need the following lemma, which is a very minor modifica tion of a lemma in <ref> [1] </ref>. 6 has weight .5. The auxiliary variable which is always 0 is labelled 0. Lemma 4.2 [1] For the constraint family CUT, if there exists an ff 1 -gadget with constant 0 reducing every function in PC to CUT and an ff 2 -gadget with constant 0 reducing every function in RMBC to CUT, then for any fl &gt; 0, MAX CUT is NP-hard to approximate to <p> Using the well-known reduction from constraint satisfaction problems to probabilistically checkable proofs, Theorem 4.11 implies that constants c and s exist such that NP PCP c;s [log; 2] and c=s &gt; 34=33. The previously known gap between the completeness and soundness achievable reading two bits was 74=73 <ref> [1] </ref>. 5 Interlude: Methodology Despite the seeming variety, all gadgets in this paper were computed by a single APL2 program (calling OSL to solve the constructed LP). The source function f is specified explicitly, by a small program.
Reference: [2] <author> L. Trevisan, G.B. Sorkin, M. Sudan, and D.P. Williamson. Gadgets, </author> <title> approximation and linear programming. </title> <booktitle> In Proc. of the 37th Annual IEEE Symposium on Foundations of Computer Science, </booktitle> <year> 1996. </year>
Reference-contexts: This seemingly helps only in showing hardness of weighted optimization problems, but a new result due to Crescenzi, Silvestri and Trevisan <ref> [2] </ref> shows that for a large class of optimization problems (including all the ones considered in this paper), the weighted versions are exactly as hard with respect to approximation as the unweighted ones. Therefore, working with the weighted version is as good as working with the unweighted one. <p> We show: first, that there exist constants c and s, c=s &gt; 34=33, such that NP PCP c;s <ref> [log; 2] </ref>; and second, for all c; s with c=s &gt; 2:7214, PCP c;s [log; 3] P. The best previously known bounds for these results were 74/73 [1] and 4 [9] respectively. All the gadgets we use are computer constructed. <p> MAX 2CSP can be approximated within .859 [3]. The above theorem has implications for probabilistically checkable proofs. Using the well-known reduction from constraint satisfaction problems to probabilistically checkable proofs, Theorem 4.11 implies that constants c and s exist such that NP PCP c;s <ref> [log; 2] </ref> and c=s &gt; 34=33. The previously known gap between the completeness and soundness achievable reading two bits was 74=73 [1]. 5 Interlude: Methodology Despite the seeming variety, all gadgets in this paper were computed by a single APL2 program (calling OSL to solve the constructed LP).
References-found: 11

