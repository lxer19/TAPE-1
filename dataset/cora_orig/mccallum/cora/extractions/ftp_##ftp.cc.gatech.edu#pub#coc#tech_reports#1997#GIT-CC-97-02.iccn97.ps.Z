URL: ftp://ftp.cc.gatech.edu/pub/coc/tech_reports/1997/GIT-CC-97-02.iccn97.ps.Z
Refering-URL: http://www.cs.gatech.edu/tech_reports/index.97.html
Root-URL: 
Email: -jdixon, calvert-@cc.gatech.edu  
Title: Effective Search Strategies for Application-Independent Speedup in UDP  
Author: Demultiplexing Joseph T. Dixon and Kenneth L. Calvert 
Address: Atlanta, GA 30332-0280  
Affiliation: Networking and Telecommunications Group, College of Computing Georgia Institute of Technology,  
Abstract: We present UDP datagram demultiplexing techniques that can yield potentially substantial application-independent performance gains over BSD-derived UDP implementations. Our demultiplexing strategies exploit local host and UDP implementation features - (1) how UDP processes connection-less datagrams, (2) local host application as client or server, and (3) local host application density - resulting in straightforward hash-based search strategies that caused demultiplexing speedups as high as 24-to-1 over BSDs one-behind cache. Furthermore, while past researchers have shown that cache-based schemes yield little performance benefit for UDP, we show that cache-based implementations can actually degrade demultiplexing performance. Finally, we recommend simple, non-protocol altering local host modifications for existing and future UDP implementations. We used four server traffic traces and eight algorithms in our tracedriven simulations, and executed more than 60 simulations to obtain our results. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Girish P. Chandranmenon and George Varghese, </author> <title> Trading Packet Headers for Packet Processing, </title> <type> SIGCOMM 95, </type> <year> 1995. </year>
Reference-contexts: When a packet arrives, it is routed to a hash chain via a hash function. The packet is then assigned to its pcb via a cached pcb comparison or linear hash chain search if the cache comparison fails. H ash C hain <ref> [ 1 ] </ref> C ache [ 1 ] &lt;I 1 ,P 1 &gt; &lt;I 2 ,P 2 &gt; H ash C hain [ R ] C ache [ R ] &lt;I 3 ,P 3 &gt; &lt;I 4 ,P 4 &gt; R 0 H ashed Pointers ( N o o n e <p> When a packet arrives, it is routed to a hash chain via a hash function. The packet is then assigned to its pcb via a cached pcb comparison or linear hash chain search if the cache comparison fails. H ash C hain <ref> [ 1 ] </ref> C ache [ 1 ] &lt;I 1 ,P 1 &gt; &lt;I 2 ,P 2 &gt; H ash C hain [ R ] C ache [ R ] &lt;I 3 ,P 3 &gt; &lt;I 4 ,P 4 &gt; R 0 H ashed Pointers ( N o o n e behind c a c h <p> Such approaches include passing 32-bit pcb identification parameters as a TCP connect-time option [6]; source hashing , a protocol altering technique that allows direct access to various information associated with general packet processing <ref> [1] </ref>; Mentat, Inc.s streams-implemented TCP/IP, which demultiplexes incoming packets in IP rather than TCP or UDP [9]; and our own multiple hash chain recommendations [4, 5].
Reference: [2] <author> David D. Clark, Van Jacobson, John Romkey, and Howard Salwen, </author> <title> An Analysis of TCP Processing Overhead, </title> <journal> IEEE Communications Magazine, </journal> <month> June, </month> <year> 1989. </year>
Reference-contexts: 1. Introduction 1.1 Background The recent Internet explosion has placed greater demand on TCP/IPs performance. As a result, several works have presented implementations that can yield significant TCP/IP performance gains over BSD-derived implementations. <ref> [2, 4, 11] </ref> A common strategy is to speed up specific processing steps that are potential performance bottlenecks. In this paper, we show how unicast datagram demultiplexing - the successful delivery of a datagram to its intended communication endpoint/process - can be improved so that overall packet processing improves. <p> Changes are isolated to individual hosts. Impact on system resources is not altered significantly. Code changes are straightforward and sparse. 1.4 Previous Work Several researchers have investigated TCP demultiplexing efficiency. <ref> [2, 4, 5, 8] </ref> UDP, however, has been investigated less frequently: Mogul, interested in persistence and temporal locality at the process level, suggested that a lastsent pcb cache might result in UDP demultiplexing speedup [10]; Partridge and Pink observed that the one-behind cache yielded little UDP performance benefit and also tested
Reference: [3] <author> Douglas E. Comer and David L. Stevens, </author> <title> Internetworking with TCP/IP Volume II: Design, Implementation, and Internals, </title> <publisher> Prentice Hall, Inc., </publisher> <year> 1991. </year>
Reference-contexts: UDP performance gains are of particular interest because UDPs transport services are utilized by some of the Internets most heavily used applications. <ref> [3, 13] </ref> We describe UDPs unicast datagram demultiplexing using the destination host model shown in Figure 1. ... Arriving Datagram Stream Kernel Space User Space User Processes Communication Endpoint Store UDP/IP demultiplexing. Our model assumes the following: UDP/IP performs UDP datagram demultiplexing and is implemented in the operating system kernel. <p> single datagram is delivered to a client application, its pcb is removed from the pcb list) or how bindings are managed (e. g., each local host application binds to an existing wildcard pcb when it sends a datagram.) All assumptions follow directly from various well-documented discussions concerning BSD-derived TCP/IP implementations. <ref> [3, 12, 13] </ref> 3. Results 3.1 Caching can add cost to demultiplexing. Our simulations show that caching can actually add cost to demultiplexing because we consider assembly language instructions executed rather than cache hit/miss rates.
Reference: [4] <author> Joseph T. Dixon and Kenneth L. Calvert, </author> <title> Increasing Demultiplexing Efficiency in TCP/IP Network Servers, </title> <booktitle> International Conference on Computer Communications and Networks, </booktitle> <month> October, </month> <year> 1996. </year>
Reference-contexts: 1. Introduction 1.1 Background The recent Internet explosion has placed greater demand on TCP/IPs performance. As a result, several works have presented implementations that can yield significant TCP/IP performance gains over BSD-derived implementations. <ref> [2, 4, 11] </ref> A common strategy is to speed up specific processing steps that are potential performance bottlenecks. In this paper, we show how unicast datagram demultiplexing - the successful delivery of a datagram to its intended communication endpoint/process - can be improved so that overall packet processing improves. <p> Changes are isolated to individual hosts. Impact on system resources is not altered significantly. Code changes are straightforward and sparse. 1.4 Previous Work Several researchers have investigated TCP demultiplexing efficiency. <ref> [2, 4, 5, 8] </ref> UDP, however, has been investigated less frequently: Mogul, interested in persistence and temporal locality at the process level, suggested that a lastsent pcb cache might result in UDP demultiplexing speedup [10]; Partridge and Pink observed that the one-behind cache yielded little UDP performance benefit and also tested <p> parameters as a TCP connect-time option [6]; source hashing , a protocol altering technique that allows direct access to various information associated with general packet processing [1]; Mentat, Inc.s streams-implemented TCP/IP, which demultiplexes incoming packets in IP rather than TCP or UDP [9]; and our own multiple hash chain recommendations <ref> [4, 5] </ref>. We know of little else done recently to address UDP demultiplexing efficiency since Partridge and Pinks effort.[11] In this work, we corroborated past findings when we showed that conventional UDP demultiplexing can be notoriously inefficient, even with the one-behind cache strategy.
Reference: [5] <author> Joseph T. Dixon and Kenneth L. Calvert, </author> <title> Increasing Demultiplexing Efficiency in TCP/IP Network Servers, </title> <type> Technical Report #: GIT-CC-96-08, </type> <institution> Georgia Institute of Technology, </institution> <year> 1996. </year>
Reference-contexts: Changes are isolated to individual hosts. Impact on system resources is not altered significantly. Code changes are straightforward and sparse. 1.4 Previous Work Several researchers have investigated TCP demultiplexing efficiency. <ref> [2, 4, 5, 8] </ref> UDP, however, has been investigated less frequently: Mogul, interested in persistence and temporal locality at the process level, suggested that a lastsent pcb cache might result in UDP demultiplexing speedup [10]; Partridge and Pink observed that the one-behind cache yielded little UDP performance benefit and also tested <p> [ R ]; If !(cache hit)- inp = in_pcblookup (f_chain [ R ], ...); If (inp == NULL) inp = in_pcblookup (w_chain [ R ], ...);- else f_cache [ R ] = inp; Return inp as the destination PCB; Our multiple hash chain algorithms are consistent with our TCP recommendations <ref> [5] </ref>: we use a small number of hash chains (64) because additional performance speedup (using more chains) may not justify system resource costs; we use a straightforward, low-cost hash function (local hosts service port modulo-64). 2.3 Metrics We measure performance in terms of assembly language instructions required per lookup. <p> parameters as a TCP connect-time option [6]; source hashing , a protocol altering technique that allows direct access to various information associated with general packet processing [1]; Mentat, Inc.s streams-implemented TCP/IP, which demultiplexes incoming packets in IP rather than TCP or UDP [9]; and our own multiple hash chain recommendations <ref> [4, 5] </ref>. We know of little else done recently to address UDP demultiplexing efficiency since Partridge and Pinks effort.[11] In this work, we corroborated past findings when we showed that conventional UDP demultiplexing can be notoriously inefficient, even with the one-behind cache strategy.
Reference: [6] <author> Christian Huitema, </author> <type> Multi-homed TCP - IETF Draft, </type> <institution> Network Working Group, </institution> <month> May, </month> <year> 1995. </year> <note> This is a work in progress. </note>
Reference-contexts: Conclusions Recent proposals (including our own past work) have focused almost exclusively on TCP demultiplexing speed up. Such approaches include passing 32-bit pcb identification parameters as a TCP connect-time option <ref> [6] </ref>; source hashing , a protocol altering technique that allows direct access to various information associated with general packet processing [1]; Mentat, Inc.s streams-implemented TCP/IP, which demultiplexes incoming packets in IP rather than TCP or UDP [9]; and our own multiple hash chain recommendations [4, 5].
Reference: [7] <author> John L. Hennessy and David A. Patterson, </author> <title> Computer Architecture A Quantitative Approach 2nd Edition, </title> <publisher> Morgan Kaufman Publishers, </publisher> <year> 1996. </year>
Reference-contexts: We report UDP demultiplexing speedup for each algorithm relative to the original in_pcblookup using the simple ratio <ref> [7] </ref>: Speedup Avg InstructionCost LinearSearch Avg InstructionCost NewAlgorithm = ( ) 2.4 Assumptions We made several assumptions so our simulation results would be as realistic as possible.
Reference: [8] <author> Paul E. McKenney and Ken F. Dove, </author> <title> Efficient Demultiplexing of Incoming TCP Packets, </title> <booktitle> ACM SIGCOMM 92, </booktitle> <month> August, </month> <year> 1992. </year>
Reference-contexts: Changes are isolated to individual hosts. Impact on system resources is not altered significantly. Code changes are straightforward and sparse. 1.4 Previous Work Several researchers have investigated TCP demultiplexing efficiency. <ref> [2, 4, 5, 8] </ref> UDP, however, has been investigated less frequently: Mogul, interested in persistence and temporal locality at the process level, suggested that a lastsent pcb cache might result in UDP demultiplexing speedup [10]; Partridge and Pink observed that the one-behind cache yielded little UDP performance benefit and also tested
Reference: [9] <institution> Mentat TCP/IP Design Overview (extracted from Mentat TCP/IP Internals Manual), Mentat, Inc., </institution> <address> Los Angeles, CA., </address> <month> July, </month> <year> 1993. </year>
Reference-contexts: Such approaches include passing 32-bit pcb identification parameters as a TCP connect-time option [6]; source hashing , a protocol altering technique that allows direct access to various information associated with general packet processing [1]; Mentat, Inc.s streams-implemented TCP/IP, which demultiplexes incoming packets in IP rather than TCP or UDP <ref> [9] </ref>; and our own multiple hash chain recommendations [4, 5].
Reference: [10] <author> Jeffrey C. Mogul, </author> <title> Network Locality at the Scale of Processes, </title> <journal> ACM Transactions on Computer Systems, </journal> <month> May, </month> <year> 1992. </year>
Reference-contexts: Code changes are straightforward and sparse. 1.4 Previous Work Several researchers have investigated TCP demultiplexing efficiency. [2, 4, 5, 8] UDP, however, has been investigated less frequently: Mogul, interested in persistence and temporal locality at the process level, suggested that a lastsent pcb cache might result in UDP demultiplexing speedup <ref> [10] </ref>; Partridge and Pink observed that the one-behind cache yielded little UDP performance benefit and also tested a last-received and lastsent pcb and showed that substantial cache hit rates could be achieved.[11] Our UDP research differs from past investigations because we investigate local host and UDP implementation characteristics rather than pcb
Reference: [11] <author> Craig Partridge and Stephen Pink, </author> <title> A Faster UDP, </title> <journal> IEEE/ACM Transactions on Networking, </journal> <month> August, </month> <year> 1993. </year>
Reference-contexts: 1. Introduction 1.1 Background The recent Internet explosion has placed greater demand on TCP/IPs performance. As a result, several works have presented implementations that can yield significant TCP/IP performance gains over BSD-derived implementations. <ref> [2, 4, 11] </ref> A common strategy is to speed up specific processing steps that are potential performance bottlenecks. In this paper, we show how unicast datagram demultiplexing - the successful delivery of a datagram to its intended communication endpoint/process - can be improved so that overall packet processing improves. <p> While informal, this approach puts demultiplexing speedup in the overall packet processing context. Partridge and Pink showed that the checksum calculation ( in_cksum in Net/3) accounted for 8.4% of total IP and UDP packet processing time for a 512-byte UDP datagram. <ref> [11] </ref> This includes four in_cksum invocations (for the IP header and the entire datagram on send and receive.) Our experiments show that, when optimally compiled on a SPARC architecture, the four in_cksum invocations require 1680 assembly language instructions to process a 512-byte UDP datagram. 5 Therefore, if we assume the fraction
Reference: [12] <author> W. Richard Stevens, </author> <title> UNIX Network Programming, </title> <publisher> Prentice Hall, Inc., </publisher> <year> 1990. </year>
Reference-contexts: single datagram is delivered to a client application, its pcb is removed from the pcb list) or how bindings are managed (e. g., each local host application binds to an existing wildcard pcb when it sends a datagram.) All assumptions follow directly from various well-documented discussions concerning BSD-derived TCP/IP implementations. <ref> [3, 12, 13] </ref> 3. Results 3.1 Caching can add cost to demultiplexing. Our simulations show that caching can actually add cost to demultiplexing because we consider assembly language instructions executed rather than cache hit/miss rates.
Reference: [13] <author> Gary R. Wright and W. Richard Stevens, </author> <title> TCP/IP Illustrated, </title> <booktitle> Volume 2: The Implementation, </booktitle> <publisher> Addison-Wesley Publishing Company, </publisher> <year> 1995. </year>
Reference-contexts: UDP performance gains are of particular interest because UDPs transport services are utilized by some of the Internets most heavily used applications. <ref> [3, 13] </ref> We describe UDPs unicast datagram demultiplexing using the destination host model shown in Figure 1. ... Arriving Datagram Stream Kernel Space User Space User Processes Communication Endpoint Store UDP/IP demultiplexing. Our model assumes the following: UDP/IP performs UDP datagram demultiplexing and is implemented in the operating system kernel. <p> associated user process. (We assume that all other typical UDP/IP datagram processing also takes place.) 1.2 BSDs UDP and Pcb Implementations BSD-derived UDP implementations use protocol control blocks (pcbs) as communication endpoints and manage the pcbs using a circular linked list store combined with a one-behind cached pcb pointer. 2 <ref> [13] </ref> Traditionally, in_pcblookup is the kernel function that performs the pcb list search. <p> In practice, UDP clients that utilize an actual connection (via connect) are optional; such UDP server implementations are rare. <ref> [13] </ref> 1.3 Solution Requirements We propose a pcb search strategy that significantly speeds up UDP packet demultiplexing over the implementation described in section 1.2. <p> single datagram is delivered to a client application, its pcb is removed from the pcb list) or how bindings are managed (e. g., each local host application binds to an existing wildcard pcb when it sends a datagram.) All assumptions follow directly from various well-documented discussions concerning BSD-derived TCP/IP implementations. <ref> [3, 12, 13] </ref> 3. Results 3.1 Caching can add cost to demultiplexing. Our simulations show that caching can actually add cost to demultiplexing because we consider assembly language instructions executed rather than cache hit/miss rates.
References-found: 13

