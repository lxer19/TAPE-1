URL: http://www.umiacs.umd.edu/users/sarit/Articles/14.ps
Refering-URL: http://www.umiacs.umd.edu/users/sarit/articles.html
Root-URL: 
Title: Foundations of Secure Deductive Databases  
Author: Piero Bonatti Sarit Kraus V.S. Subrahmanian 
Date: 7(3):406-422, 1995.  
Note: Note: This article appears in IEEE Transaction on Knowledge and Data Engineering,  
Abstract: In this paper, we develop a formal logical foundation for secure deductive databases. This logical foundation is based on an extended logic involving several modal operators. We develop two models of interaction between the user and the database called "yes-no" dialogs, and "yes-no-don't know" dialogs. Both dialog frameworks allow the database to lie to the user. We develop an algorithm for answering queries using yes-no dialogs and prove that secure query processing using yes-no dialogs is NP-complete. Consequently, the degree of computational intractability of query processing with yes-no dialogs is no worse than for ordinary databases. Furthermore, the algorithm is maximally cooperative to user in the sense that lying is resorted to only when absolutely necessary. For Horn databases, we show that secure query processing can be achieved in linear time hence, this is no more intractable than the situation in ordinary databases. Finally, we identify necessary and sufficient conditions for the database to be able to preserve security. Similar results are also obtained for yes-no-don't know dialogs.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> N.R. Adam and J. C. Wortmann. </author> <title> (1989) Security-Control Methods for Statistical Databases: A Comparative Study, </title> <journal> ACM Computing Surveys, </journal> <volume> 21, 4, </volume> <pages> pps 515-556. </pages>
Reference-contexts: In addition to the modal logic formalizations of secure databases discussed above, there has also been a good deal of formal work in the area of statistical databases and statistical methods for preserving secrets <ref> [1] </ref>. In the statistical approach, the users of a database DB, are allowed to inspect functions of DB rather than DB itself; typical functions are COUNT, SUM, PERCENTILE, etc. <p> There are two classes of approaches to security in statistical databases (SDB's for short), based on query restrictions or data perturbation. Adam and Wortmann <ref> [1] </ref> conclude that the latter is generally more effective for SDB's. The two classes of approaches correspond to refuse-to-answers and lies, respectively. After perturbing data, some queries may change their value; the error introduced by the perturbation is called "bias".
Reference: [2] <author> F. Bancilhon and N. Spyratos. </author> <title> (1977) Protection of Information in Relational Data Bases, </title> <booktitle> Proc. Intl. Symp. on Very Large Data Bases, </booktitle> <address> Tokyo, Japan, pps 494-500. </address>
Reference-contexts: In multi-user databases, where different users are allowed to access different pieces of data, mechanisms must be in place where all users can access data that they are allowed to access, unless doing so would violate security in one way or the other. In previous work, Bancilhon and Spyratos <ref> [2] </ref> raised four important questions that need to be addressed when developing a foundation for database security: (Q1) What do we protect ? (Q2) Against whom do we protect ? (Q3) How do we protect ? (Q4) What does "protect" mean ? fl This work was supported by the Army Research <p> A large part of this research has dealt with multilevel security where, intuitively, different parts of the database are assigned security "level" and each user is allowed access to certain levels only. Work on developing a formal theoretical foundation for secure databases has developed more slowly. Bancilhon and Spyratos <ref> [2] </ref> wrote an important paper identifying the key questions that must be asked when attempting to develop a foundation for secure databases. These questions are broad enough to cover not only the traditional relational databases, but also deductive Horn databases, as well as more general models. <p> Sicherman et. al. [26] subsequently extended the work of Bancilhon and Spyratos. Recently, several formalizations of security, based on modal logics, have been explored [5, 10, 16]. The key differences between our work and <ref> [2, 26, 5, 10, 16] </ref> is that: * In our framework, we never refuse to answer queries. <p> In other words, our work deals with the user's beliefs, rather than with his knowledge (as in <ref> [2, 26, 5, 10, 16] </ref>). The reason is that we do not wish the user to uncover a secret by using his/her incorrect beliefs. <p> A number of the ideas explored in this paper have been suggested, but not explored, in <ref> [2, 26] </ref>. These include the possibility of lying, and also the concept of meta-security which is called a "secrecy" in [26].
Reference: [3] <author> F. Bancilhon, D. Maier, Y. Sagiv, and J.D. Ullman. </author> <title> (1986) Magic Sets and Other Strange Ways to Implement Logic Programs, </title> <booktitle> Proc. 1986 ACM Symp. on Principles of Database Systems, </booktitle> <address> pps 1-15. </address>
Reference-contexts: There are a variety of methods to perform these tests for different kinds of databases (cf. magic sets <ref> [3] </ref>, resolution [21], counting methods [24], to name a few). In a joint project between Cornell University and University of Maryland [4, 23], various implementations of monotonic and non-monotonic deductive databases have been developed.
Reference: [4] <author> C. Bell, A. Nerode, R. Ng and V.S. Subrahmanian. </author> <title> (1992) Implementing Deductive Databases by Linear Programming, </title> <booktitle> Proc. 1992 ACM Symp. on Principles of Database Systems. </booktitle>
Reference-contexts: There are a variety of methods to perform these tests for different kinds of databases (cf. magic sets [3], resolution [21], counting methods [24], to name a few). In a joint project between Cornell University and University of Maryland <ref> [4, 23] </ref>, various implementations of monotonic and non-monotonic deductive databases have been developed. These implementations are based on incremental mixed integer linear programming techniques 7 : at any given point in time, an optimized linear programming tableau corresponding to the database is maintained. <p> Query processing corresponds to adding a new linear constraint to the the tableau and re-optimizing an objective function. Experimental results reported in <ref> [4, 23] </ref> indicate that such reoptimizations make effective use of previous computations (captured by the previously optimized simplex tableau) and are very efficient in practice. <p> A linear program is usually represented as a special kind of table called a tableau [17]. Bell et. al. <ref> [4] </ref> show how deductive databases can be represented as linear programs, and how queries (and their negations) can be represented as additional constraints. <p> Bell et. al. [4] show how deductive databases can be represented as linear programs, and how queries (and their negations) can be represented as additional constraints. The reader interested in the technical details of this technique is referred to <ref> [4, 23] </ref> it is beyond the scope of this paper. 19 Definition 5.1 (World) A world w is a propositional interpretation, i.e. w is a set of propositional symbols. If F 2 L, we use the notation w j= F to denote the statement "w satisfies formula F " (cf.
Reference: [5] <author> P. Bieber and F. Cuppens. </author> <title> (1991) A Definition of Secure Dependencies using the Logic of Security, </title> <booktitle> Proc. of the Computer Security Foundations Workshop IV, </booktitle> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: There are several other formalizations of security based on modal logics. In <ref> [5] </ref>, a modal logic of security is defined, based on a modal knowledge operator, K A , and a modal operator R A , that captures what the user is allowed to know. <p> For example, R A satisfies both axiom T and the schema R A ' ^ R A ! R A (' ^ ) while All satisfies none of them. In [10], the logical framework introduced in <ref> [5] </ref> is adapted to analyze aggregation problems. To solve this class of problems, the above schema should be invalidated, and hence, the author gives a "diamond"-like definition of R A . <p> These questions are broad enough to cover not only the traditional relational databases, but also deductive Horn databases, as well as more general models. Sicherman et. al. [26] subsequently extended the work of Bancilhon and Spyratos. Recently, several formalizations of security, based on modal logics, have been explored <ref> [5, 10, 16] </ref>. The key differences between our work and [2, 26, 5, 10, 16] is that: * In our framework, we never refuse to answer queries. <p> Sicherman et. al. [26] subsequently extended the work of Bancilhon and Spyratos. Recently, several formalizations of security, based on modal logics, have been explored [5, 10, 16]. The key differences between our work and <ref> [2, 26, 5, 10, 16] </ref> is that: * In our framework, we never refuse to answer queries. <p> In other words, our work deals with the user's beliefs, rather than with his knowledge (as in <ref> [2, 26, 5, 10, 16] </ref>). The reason is that we do not wish the user to uncover a secret by using his/her incorrect beliefs.
Reference: [6] <author> J. Biskup and H. H. Bruggemann. </author> <title> (1988) The Personal Model of Data: Towards a Privacy-Oriented Information System, </title> <journal> Computers and Security, </journal> <volume> 7, </volume> <pages> pps 575-597. </pages>
Reference-contexts: they can be given partial protection, e.g. it is possible to make the jobs of some individuals available, while "hiding" the job of some other individuals at the same time. 34 8 Conclusions During recent years, a great deal of work has been done on enforcing security in traditional databases <ref> [13, 12, 6, 7, 18, 30, 29] </ref>. A large part of this research has dealt with multilevel security where, intuitively, different parts of the database are assigned security "level" and each user is allowed access to certain levels only.
Reference: [7] <author> J. Biskup and H.-W. Graf. </author> <title> (1988) Analysis of the Privacy Model for the Information System Doris, </title> <booktitle> Proc. Workshop on Database Security, </booktitle> <address> Ontario, Canada. </address>
Reference-contexts: they can be given partial protection, e.g. it is possible to make the jobs of some individuals available, while "hiding" the job of some other individuals at the same time. 34 8 Conclusions During recent years, a great deal of work has been done on enforcing security in traditional databases <ref> [13, 12, 6, 7, 18, 30, 29] </ref>. A large part of this research has dealt with multilevel security where, intuitively, different parts of the database are assigned security "level" and each user is allowed access to certain levels only.
Reference: [8] <author> P. Bonatti, S Kraus and V.S. Subrahmanian, </author> <year> (1992). </year> <title> Declarative Foundations of Secure Deductive Databases, </title> <institution> University of Maryland Tech. </institution> <type> Report, UMIACS TR 92-73 CS TR 2922. </type>
Reference-contexts: If BCCI allowed b to be known, then, through the equivalence a $ b, the user could deduce a. Therefore, if a is a secret, b should also be kept secret. 3 Proofs of results are can be found in <ref> [8] </ref> unless those proofs are essential to the ongoing discussion in the paper. 8 The more general question arising out of the previous proposition, is: Question 3.1 Shouldn't we then consider B U (a $ b) ! (Sa $ Sb) to be true even if the database does not consider a
Reference: [9] <author> B. F. Chellas. </author> <title> (1980) Modal Logic: an introduction, </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge. </address>
Reference-contexts: If F = a _ b then w j= a _ b iff w j= a or w j= b. 4. If F = a ^ b then w j= a ^ b iff w j= a and w j= b. As is common in modal logics <ref> [9] </ref>, we use the notion of a world as the basis for defining interpretations of our modal language for yn-dialogs. These interpretations characterize the possible changes in the beliefs of the user/database as an interaction between the user and the database proceeds. <p> The semantics of R A and K A are similar; both of them satisfy all the axioms of modal logic S5 (i.e. axioms K, T, 4, 5 , see <ref> [9] </ref>.) 33 Although R A and K A intuitively correspond to our operators All and B U , respectively, there are important differences.
Reference: [10] <author> F. Cuppens. </author> <title> (1992) A Modal Logic Framework to Solve Aggregation Problems, </title> <editor> S. Jajodia and C. Landwehr (eds.) </editor> <title> Database Security, 5: Status and Prospects. </title> <publisher> North Holland. </publisher>
Reference-contexts: For example, R A satisfies both axiom T and the schema R A ' ^ R A ! R A (' ^ ) while All satisfies none of them. In <ref> [10] </ref>, the logical framework introduced in [5] is adapted to analyze aggregation problems. To solve this class of problems, the above schema should be invalidated, and hence, the author gives a "diamond"-like definition of R A . <p> These questions are broad enough to cover not only the traditional relational databases, but also deductive Horn databases, as well as more general models. Sicherman et. al. [26] subsequently extended the work of Bancilhon and Spyratos. Recently, several formalizations of security, based on modal logics, have been explored <ref> [5, 10, 16] </ref>. The key differences between our work and [2, 26, 5, 10, 16] is that: * In our framework, we never refuse to answer queries. <p> Sicherman et. al. [26] subsequently extended the work of Bancilhon and Spyratos. Recently, several formalizations of security, based on modal logics, have been explored [5, 10, 16]. The key differences between our work and <ref> [2, 26, 5, 10, 16] </ref> is that: * In our framework, we never refuse to answer queries. <p> In other words, our work deals with the user's beliefs, rather than with his knowledge (as in <ref> [2, 26, 5, 10, 16] </ref>). The reason is that we do not wish the user to uncover a secret by using his/her incorrect beliefs.
Reference: [11] <author> D.E. Denning. </author> <title> (1982) Cryptography and Data Security, </title> <publisher> Addison-Wesley. </publisher>
Reference-contexts: For example, in the Secret Service DB example above, the DB may refuse to answer any query related to the job description <ref> [11, chap. 6] </ref> or arbitrarily refuse to answer some of these queries (in addition to those queries that may directly reveal secrets) [26]. Lying may sometimes be a dangerous approach since the user may act upon the wrong information.
Reference: [12] <author> D.E. Denning and M. Morgenstern. </author> <title> (1986) Military Database Technology Study: AI Techniques for Security and Reliability, </title> <type> SRI International Tech. Report Project 1644. </type>
Reference-contexts: they can be given partial protection, e.g. it is possible to make the jobs of some individuals available, while "hiding" the job of some other individuals at the same time. 34 8 Conclusions During recent years, a great deal of work has been done on enforcing security in traditional databases <ref> [13, 12, 6, 7, 18, 30, 29] </ref>. A large part of this research has dealt with multilevel security where, intuitively, different parts of the database are assigned security "level" and each user is allowed access to certain levels only.
Reference: [13] <author> D. Denning, T.F. Lunt, R.R. Schell, M. Heckman and W. Shockley. </author> <title> (1987) A Multilevel Relational Data Model, </title> <booktitle> Proc. IEEE Symp. on Security and Privacy, </booktitle> <address> Oakland, CA, pps 46-56. </address>
Reference-contexts: they can be given partial protection, e.g. it is possible to make the jobs of some individuals available, while "hiding" the job of some other individuals at the same time. 34 8 Conclusions During recent years, a great deal of work has been done on enforcing security in traditional databases <ref> [13, 12, 6, 7, 18, 30, 29] </ref>. A large part of this research has dealt with multilevel security where, intuitively, different parts of the database are assigned security "level" and each user is allowed access to certain levels only.
Reference: [14] <author> W.F. Dowling and J. Gallier. </author> <title> (1984) Linear-Time Algorithms for Testing the Satisfiability of Propositional Horn Formulae, </title> <journal> J. of Logic Programming, </journal> <volume> 1, 3, </volume> <pages> pps 267-284. </pages>
Reference-contexts: The same reasoning applies to condition (2). Dowling and Gallier <ref> [14] </ref> (see also Vardi [28]) have given an algorithm that would check, in linear-time, if DB j= q i+1 .
Reference: [15] <author> M.R. Garey and D.S. Johnson. </author> <title> (1979) Computers and Intractability: A Guide to the Theory of NP-Completeness. </title> <editor> W. H. </editor> <publisher> Freeman and Company, </publisher> <year> 1979. </year>
Reference-contexts: Then, given as input, a query Q i+1 = Ask q i+1 , the problem of answering query Q i+1 so that the user is not led to believe any secret, is NP-complete. Proof. NP-Hardness The proof is by a reduction to SAT <ref> [15] </ref>. Suppose C = fc 1 ; : : : ; c n g, is a set of propositional clauses (We assume n 2. This assumption leads to no loss of generality as a set consisting of a single clause is always satisfiable).
Reference: [16] <author> J. Gray and P. Syverson. </author> <title> A Logical Approach to Multilevel Security of Probabilistic Systems, </title> <booktitle> Proc. of the IEEE Computer Society Symposium on Research in Security and Privacy, </booktitle> <address> Oakland, CA, </address> <month> May </month> <year> 1992. </year>
Reference-contexts: However, since the user is allowed to have only correct beliefs, R A still satisfies the modal axiom T , and so it is different from All . In <ref> [16] </ref>, a second order modal logic is adopted, that embodies a probabilistic treatment of possible worlds. Furthermore, in this logic, R A satisfies all the axioms of S5. Su and Ozsoyoglu [27] study how to control inferences that may be drawn by users in multilevel relational DBMSs with integrity constraints. <p> These questions are broad enough to cover not only the traditional relational databases, but also deductive Horn databases, as well as more general models. Sicherman et. al. [26] subsequently extended the work of Bancilhon and Spyratos. Recently, several formalizations of security, based on modal logics, have been explored <ref> [5, 10, 16] </ref>. The key differences between our work and [2, 26, 5, 10, 16] is that: * In our framework, we never refuse to answer queries. <p> Sicherman et. al. [26] subsequently extended the work of Bancilhon and Spyratos. Recently, several formalizations of security, based on modal logics, have been explored [5, 10, 16]. The key differences between our work and <ref> [2, 26, 5, 10, 16] </ref> is that: * In our framework, we never refuse to answer queries. <p> In other words, our work deals with the user's beliefs, rather than with his knowledge (as in <ref> [2, 26, 5, 10, 16] </ref>). The reason is that we do not wish the user to uncover a secret by using his/her incorrect beliefs.
Reference: [17] <author> F. Hillier and G. Lieberman. </author> <note> (1974) Operations Research, Holden-Day. </note>
Reference-contexts: security. 7 A linear constraint is a relation of the form a 1 x 1 + + a n x n &lt;b, where &lt; is one of ; =; and the a i 's, 1 i n are integers, and the x i 's, 1 i n, are integer variables <ref> [17] </ref>. An integer linear program consists of a set of linear constraints together with an objective function that reflects a quantity to be minimized or maximized. <p> An objective function minimizes or maximizes an expression of the form a 1 x 1 + + a n x n where the a i s and x i 's are as before. A linear program is usually represented as a special kind of table called a tableau <ref> [17] </ref>. Bell et. al. [4] show how deductive databases can be represented as linear programs, and how queries (and their negations) can be represented as additional constraints.
Reference: [18] <author> S. Jajodia and R. Sandhu. </author> <booktitle> (1990) Polyinstantiation Integrity in Multilevel Relations Proc. IEEE Symp. on Research in Security and Privacy, </booktitle> <address> Oakland, CA, pps 104-115. </address>
Reference-contexts: they can be given partial protection, e.g. it is possible to make the jobs of some individuals available, while "hiding" the job of some other individuals at the same time. 34 8 Conclusions During recent years, a great deal of work has been done on enforcing security in traditional databases <ref> [13, 12, 6, 7, 18, 30, 29] </ref>. A large part of this research has dealt with multilevel security where, intuitively, different parts of the database are assigned security "level" and each user is allowed access to certain levels only.
Reference: [19] <author> S. Kraus, D. Lehmann. </author> <title> (1988) Knowledge, Belief and Time, </title> <journal> Theoretical Computer Science, </journal> <volume> 58, </volume> <pages> pps 155-174. </pages>
Reference: [20] <author> S. Kraus, D. Lehmann, M. Magidor. </author> <title> (1990) Nonmonotonic Reasoning, Preferential Models and Cumulative Logics, </title> <journal> Artificial Intelligence, </journal> <volume> 44, </volume> <pages> pps 167-207. </pages>
Reference-contexts: Intuitively, an epistemic world E contains information about the objective, modality-free formulas (the W part) together with some information about the beliefs held by the database (the B part) <ref> [20] </ref>. Note that there may be propositional formulas such that neither B D nor B D : is in an epistemic world E.
Reference: [21] <author> J.W. Lloyd. </author> <booktitle> (1987) Foundations of Logic Programming, </booktitle> <publisher> Springer. </publisher>
Reference-contexts: There are a variety of methods to perform these tests for different kinds of databases (cf. magic sets [3], resolution <ref> [21] </ref>, counting methods [24], to name a few). In a joint project between Cornell University and University of Maryland [4, 23], various implementations of monotonic and non-monotonic deductive databases have been developed. <p> As CW T (DB) is simply a set of propositional formulas, we may consider CW T (DB) to be a database. It is well-known <ref> [21] </ref> that the set CW T (DB) is a complete database whenever DB is Horn and only atoms (and conjunctions of atoms) are considered. Corollary 5.2 (Complexity of (Atomic) Secure Query-Answering in Horn Databases) Suppose DB is a Horn database augmented with the Closed World Assumption [21] (i.e. the theory being <p> It is well-known <ref> [21] </ref> that the set CW T (DB) is a complete database whenever DB is Horn and only atoms (and conjunctions of atoms) are considered. Corollary 5.2 (Complexity of (Atomic) Secure Query-Answering in Horn Databases) Suppose DB is a Horn database augmented with the Closed World Assumption [21] (i.e. the theory being considered is CW T (DB)), and KER SEC (u) is a finite set of conjunctive atomic secrets (i.e. each secret is a conjunction of atoms). <p> The same reasoning applies to condition (2). Dowling and Gallier [14] (see also Vardi [28]) have given an algorithm that would check, in linear-time, if DB j= q i+1 . Under the conditions specified, it is well-known <ref> [21] </ref>, that for all positive atoms A: * DB j= a iff CW T (DB) j= a and Consequently, if the Dowling-Gallier algorithm answered "yes", we would know that CW T (DB) j= q i+1 ; if "no", we would know that CW T (DB) j= :q i+1 .
Reference: [22] <editor> A. Nerode, W. Marek and V.S. Subrahmanian. </editor> <booktitle> (1991) Logic Programming and Non-Monotonic Reasoning: Proceedings of the First International Workshop, </booktitle> <publisher> MIT Press. </publisher> <pages> 36 </pages>
Reference-contexts: A Horn Database is a finite set of clauses of the form a 1 ^ : : : ^ a n ! b where a 1 ; : : : ; a n ; b are all atoms. It is well-known <ref> [22] </ref> that if DB is a Horn database, then DB entails no negative atom, i.e. there does not exist an atom c such that DB j= :c.
Reference: [23] <author> A. Nerode, R. Ng and V.S. Subrahmanian. </author> <note> (1992) Computing Circumscriptive Databases, to appear in: Information and Computation. </note>
Reference-contexts: There are a variety of methods to perform these tests for different kinds of databases (cf. magic sets [3], resolution [21], counting methods [24], to name a few). In a joint project between Cornell University and University of Maryland <ref> [4, 23] </ref>, various implementations of monotonic and non-monotonic deductive databases have been developed. These implementations are based on incremental mixed integer linear programming techniques 7 : at any given point in time, an optimized linear programming tableau corresponding to the database is maintained. <p> Query processing corresponds to adding a new linear constraint to the the tableau and re-optimizing an objective function. Experimental results reported in <ref> [4, 23] </ref> indicate that such reoptimizations make effective use of previous computations (captured by the previously optimized simplex tableau) and are very efficient in practice. <p> Bell et. al. [4] show how deductive databases can be represented as linear programs, and how queries (and their negations) can be represented as additional constraints. The reader interested in the technical details of this technique is referred to <ref> [4, 23] </ref> it is beyond the scope of this paper. 19 Definition 5.1 (World) A world w is a propositional interpretation, i.e. w is a set of propositional symbols. If F 2 L, we use the notation w j= F to denote the statement "w satisfies formula F " (cf.
Reference: [24] <author> D. Sacca and C. Zaniolo. </author> <title> (1986) On the Implementation of a Simple Class of Logic Queries for Databases, </title> <booktitle> Proc. 1986 ACM Symp. on Principles of Database Systems, </booktitle> <address> pps 16-23. </address>
Reference-contexts: There are a variety of methods to perform these tests for different kinds of databases (cf. magic sets [3], resolution [21], counting methods <ref> [24] </ref>, to name a few). In a joint project between Cornell University and University of Maryland [4, 23], various implementations of monotonic and non-monotonic deductive databases have been developed.
Reference: [25] <author> J. Shoenfield. </author> <title> (1967) Mathematical Logic, </title> <publisher> Addison Wesley. </publisher>
Reference-contexts: wffs of L S , then (a ^ b), (a _ b), :a, (a ! b) are wffs of L S . (Other connectives can be defined in terms of these connectives in the usual way.) We assume that all the classical axioms and inference rules of propositional logic (cf. <ref> [25] </ref>) also hold in the extended logic. Furthermore, we provide new logical axioms that our secrecy and allowed-ness modalities are expected to satisfy. Thus, we are now in a position to formally state what constitutes a secret. <p> If F 2 L, we use the notation w j= F to denote the statement "w satisfies formula F " (cf. Shoenfield <ref> [25] </ref>), and define it in the usual way as follows: 1. If F is a propositional symbol, (i.e., F 2 L 0 ) then w j= F iff F 2 w. 2. If F = :a then w j= :a iff w 6j= a. 3.
Reference: [26] <author> G. Sicherman, W. de Jonge and R.P. van de Riet. </author> <title> (1983) Answering Queries without Revealing Secrets, </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 8, 1, </volume> <pages> pps 41-49. </pages>
Reference-contexts: Therefore, the only way to preserve security in this instance, and to provide information whenever it doesn't violate security, is for the database to answer "no", which shows that sometimes lying is the only way to protect a secret. The strategy of lying, has been suggested, in passing, in <ref> [26, 31] </ref>, and will be discussed later. More importantly, if the initial beliefs of the user are wrong, the system should take that into account. This is not considered in [31, 26]. <p> The strategy of lying, has been suggested, in passing, in [26, 31], and will be discussed later. More importantly, if the initial beliefs of the user are wrong, the system should take that into account. This is not considered in <ref> [31, 26] </ref>. Our logic encompasses this possibility because secrets are defined in terms of the user's beliefs rather than what is true. <p> For example, in the Secret Service DB example above, the DB may refuse to answer any query related to the job description [11, chap. 6] or arbitrarily refuse to answer some of these queries (in addition to those queries that may directly reveal secrets) <ref> [26] </ref>. Lying may sometimes be a dangerous approach since the user may act upon the wrong information. However, not providing information that does not directly violate security may also be dangerous. <p> Then: a completely honest, ynd-dialog based query answering strategy cannot preserve security. It may be suggested that the database be occasionally dishonest, i.e. on random occasions, it may say "I don't know" even if it does indeed know the answer to the query <ref> [26] </ref>. <p> There, the response "I refuse to answer" is inadequate, because the user may use the database's refusal to respond to infer that a piece of information is secret. This case is explicitly excluded in <ref> [26] </ref>; hence, their theorems and techniques do not apply to our example. More specifically, they prove that there exist two systems that give the same answers: one where "X is an assassin" is a secret, and one where "X is not an assassin" is a secret. <p> More specifically, they prove that there exist two systems that give the same answers: one where "X is an assassin" is a secret, and one where "X is not an assassin" is a secret. However, when the framework of <ref> [26] </ref> is applied to Example 1.2, the user can violate the secret because s/he can infer that the latter system should be excluded. 32 Our result on yes/no dialogs is easily comparable with the results of [26]. <p> However, when the framework of <ref> [26] </ref> is applied to Example 1.2, the user can violate the secret because s/he can infer that the latter system should be excluded. 32 Our result on yes/no dialogs is easily comparable with the results of [26]. We both prove that, under suitable assumptions, the system can always answer the user's queries without violating any secret. The assumptions we make are complementary to theirs: they restrict the user's reasoning about query rejections, while we impose slightly stronger constraints on the user's initial knowledge about secret facts. <p> We believe our approach is reasonable because we assume that the user is as smart as possible ("perfect reasoner axioms" and "non-forgetfulness"). This seems more reasonable in real life than making assumptions that limit the intelligence of the user. As we have already pointed out, <ref> [26] </ref> suggests that the system might arbitrarily withhold answers, in order to prevent the user to make inferences like: If Q was not a secret, then the system would have answered. <p> These questions are broad enough to cover not only the traditional relational databases, but also deductive Horn databases, as well as more general models. Sicherman et. al. <ref> [26] </ref> subsequently extended the work of Bancilhon and Spyratos. Recently, several formalizations of security, based on modal logics, have been explored [5, 10, 16]. The key differences between our work and [2, 26, 5, 10, 16] is that: * In our framework, we never refuse to answer queries. <p> Sicherman et. al. [26] subsequently extended the work of Bancilhon and Spyratos. Recently, several formalizations of security, based on modal logics, have been explored [5, 10, 16]. The key differences between our work and <ref> [2, 26, 5, 10, 16] </ref> is that: * In our framework, we never refuse to answer queries. <p> In other words, our work deals with the user's beliefs, rather than with his knowledge (as in <ref> [2, 26, 5, 10, 16] </ref>). The reason is that we do not wish the user to uncover a secret by using his/her incorrect beliefs. <p> A number of the ideas explored in this paper have been suggested, but not explored, in <ref> [2, 26] </ref>. These include the possibility of lying, and also the concept of meta-security which is called a "secrecy" in [26]. <p> A number of the ideas explored in this paper have been suggested, but not explored, in [2, 26]. These include the possibility of lying, and also the concept of meta-security which is called a "secrecy" in <ref> [26] </ref>.
Reference: [27] <author> T.-A. Su and G. Ozsoyoglu. </author> <title> (1991) Controlling FD and MVD Inferences in Multilevel Relational Database Systems, </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 3, 4, </volume> <pages> pps 474-485. </pages>
Reference-contexts: We are grateful to Sushil Jajodia and Moshe Vardi for useful discussions. In particular, Sushil Jajodia drew our attention to <ref> [27] </ref> and Moshe Vardi to [31]. Address correspondence to V. S. Subrahmanian. y Dip. di Informatica, Universita' di Pisa, Corso Italia 40, 56100 Pisa, Italy. E-Mail: bonatti@di.unipi.it. <p> In [16], a second order modal logic is adopted, that embodies a probabilistic treatment of possible worlds. Furthermore, in this logic, R A satisfies all the axioms of S5. Su and Ozsoyoglu <ref> [27] </ref> study how to control inferences that may be drawn by users in multilevel relational DBMSs with integrity constraints. They develop a method to assign security levels to prevent inferences that lead to security violations.
Reference: [28] <author> M. Vardi. </author> <title> The Complexity of Relational Query Languages, </title> <booktitle> Proc. 14th ACM Symp. on Theory of Computing, </booktitle> <address> San Francisco, </address> <year> 1982, </year> <pages> pp. 137-146. </pages>
Reference-contexts: The same reasoning applies to condition (2). Dowling and Gallier [14] (see also Vardi <ref> [28] </ref>) have given an algorithm that would check, in linear-time, if DB j= q i+1 .
Reference: [29] <author> I. Wilson. </author> <title> (1988) Views as Security Objects in Multilevel Secure Relational DBMS Proc. </title> <booktitle> IEEE Symp. on Security and Privacy, </booktitle> <address> Oakland, CA, pps 70-84. </address>
Reference-contexts: they can be given partial protection, e.g. it is possible to make the jobs of some individuals available, while "hiding" the job of some other individuals at the same time. 34 8 Conclusions During recent years, a great deal of work has been done on enforcing security in traditional databases <ref> [13, 12, 6, 7, 18, 30, 29] </ref>. A large part of this research has dealt with multilevel security where, intuitively, different parts of the database are assigned security "level" and each user is allowed access to certain levels only.
Reference: [30] <author> S. R. Wiseman. </author> <title> (1990) Control of Confidentiality in Databases, </title> <journal> Computers and Security Journal, </journal> <volume> 9, 6, </volume> <pages> pps 529-537. </pages>
Reference-contexts: they can be given partial protection, e.g. it is possible to make the jobs of some individuals available, while "hiding" the job of some other individuals at the same time. 34 8 Conclusions During recent years, a great deal of work has been done on enforcing security in traditional databases <ref> [13, 12, 6, 7, 18, 30, 29] </ref>. A large part of this research has dealt with multilevel security where, intuitively, different parts of the database are assigned security "level" and each user is allowed access to certain levels only.
Reference: [31] <author> S. Wiseman. </author> <title> (1991) Lies, Dammed Lies and Database, Royal Signals and Radar Establishment, </title> <type> memo 4503, </type> <address> England. </address> <month> 37 </month>
Reference-contexts: We are grateful to Sushil Jajodia and Moshe Vardi for useful discussions. In particular, Sushil Jajodia drew our attention to [27] and Moshe Vardi to <ref> [31] </ref>. Address correspondence to V. S. Subrahmanian. y Dip. di Informatica, Universita' di Pisa, Corso Italia 40, 56100 Pisa, Italy. E-Mail: bonatti@di.unipi.it. This work was done while the author was visiting the University of Maryland Institute for Advanced Computer Studies. z Department of Computer Science Bar-Ilan University Ramat Gan, Israel. <p> Therefore, the only way to preserve security in this instance, and to provide information whenever it doesn't violate security, is for the database to answer "no", which shows that sometimes lying is the only way to protect a secret. The strategy of lying, has been suggested, in passing, in <ref> [26, 31] </ref>, and will be discussed later. More importantly, if the initial beliefs of the user are wrong, the system should take that into account. This is not considered in [31, 26]. <p> The strategy of lying, has been suggested, in passing, in [26, 31], and will be discussed later. More importantly, if the initial beliefs of the user are wrong, the system should take that into account. This is not considered in <ref> [31, 26] </ref>. Our logic encompasses this possibility because secrets are defined in terms of the user's beliefs rather than what is true. <p> If the user doesn't know "too much", the system is very cooperative. Therefore, lying is a promising technique when the set of correct answers has to be maximized. Furthermore, there are some applications that require the database to deceive some users by supplying incorrect answers (see <ref> [31] </ref> for a discussion of the effectiveness of existing database security techniques for handling such situations.) In such cases, we gives a theoretical foundation for lying, and our approach can be used to preserve the integrity of the lies and provide the database with an algorithm for lying consistently.
References-found: 31

