URL: ftp://ftp.cse.ucsc.edu/pub/tr/ucsc-crl-92-21.ps.Z
Refering-URL: ftp://ftp.cse.ucsc.edu/pub/tr/README.html
Root-URL: http://www.cse.ucsc.edu
Title: Automatic Process Selection for Load Balancing  
Author: Prof. Darrell D. E. Long Prof. Kimberly E. Taylor Prof. Charles McDowell Dean 
Degree: A thesis submitted in partial satisfaction of the requirements for the degree of MASTER OF SCIENCE in COMPUTER ENGINEERING by William Osser  The thesis of William Osser is approved:  
Date: June 1992  
Affiliation: UNIVERSITY OF CALIFORNIA SANTA CRUZ  of Graduate Studies and Research  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> J. K. Ousterhout et al., </author> <title> The Sprite network operating system, </title> <journal> IEEE Computer, </journal> <volume> vol. 21, </volume> <pages> pp. 23-36, </pages> <month> February </month> <year> 1988. </year>
Reference-contexts: The load from one workstation can be transferred to a lightly loaded workstation through two different methods. One method is to start a process remotely and 2 wait for it to terminate, using tools such as rsh [5]. Another method uses a mechanism called process migration <ref> [1] </ref>. Process migration in the Sprite distributed operating system [1] is defined as being able to halt a process during its execution, freeze its current state, move it to a different host, and then resume execution [2]. <p> One method is to start a process remotely and 2 wait for it to terminate, using tools such as rsh [5]. Another method uses a mechanism called process migration <ref> [1] </ref>. Process migration in the Sprite distributed operating system [1] is defined as being able to halt a process during its execution, freeze its current state, move it to a different host, and then resume execution [2]. <p> This information is useful for determining whether a process may be executed remotely. The operating system that we have chosen to use is the Sprite operating system developed at University of California, Berkeley <ref> [1] </ref>. Sprite is a distributed operating system that provides a UNIX compatible interface. The name space is 6 transparent to all of the clients [6], so all files are accessed uniformly throughout the system. <p> In this way, processes can be moved from any site so that the load can be maintained in a balanced state. Distributing the load using process migration is called load balancing. Examples of operating systems that provide process migration include Charlotte [12], V [13], Accent [14], and Sprite <ref> [1] </ref>. Several load sharing algorithms have been developed. Most of these algorithms can be implemented as load balancing algorithms, if the targeted operating system is one that supports process migration. Load sharing is simpler, but load balancing provides more benefits.
Reference: [2] <author> F. Douglis and J. Ousterhout, </author> <title> Transparent process migration for personal workstations, </title> <type> Tech. Rep. </type> <institution> UCB/CSD 89/540, University of California Berkeley, California, </institution> <month> November </month> <year> 1989. </year>
Reference-contexts: One solution to this problem is to distribute some of the tasks to an idle workstation. Studies have shown that over 65% of workstations are idle at any given time <ref> [2, 3] </ref>. Distributing processes over all of the workstations in the network balances the load at each machine so the overall time needed to complete tasks is reduced. Automatic load balancing is a system process that distributes tasks from heavily loaded workstations to idle workstations without user intervention. <p> Another method uses a mechanism called process migration [1]. Process migration in the Sprite distributed operating system [1] is defined as being able to halt a process during its execution, freeze its current state, move it to a different host, and then resume execution <ref> [2] </ref>. One of the advantages of process migration is that it can be used to distribute the load from heavily loaded workstations to idle ones during process execution. If an idle workstation becomes active again, any migrated processes can be sent back to their original locations. <p> Sprite is a distributed operating system that provides a UNIX compatible interface. The name space is 6 transparent to all of the clients [6], so all files are accessed uniformly throughout the system. Sprite provides process migration, which supports moving processes to any homogeneous machine before or during execution <ref> [2] </ref>. Sprite includes a migration daemon [7] which locates a site for remote execution and migrates a process to that site. Processes only migrate to workstations that have received no user input from the mouse or keyboard in the last thirty seconds. <p> Sprite's process migration is transparent to the user. When a process is migrated, all dirty pages are flushed to backing files. The state information of the process is then transferred to the target machine and needed pages are loaded from the backing files <ref> [2] </ref>. A process control block is kept on the machine that invokes that process for every process executed, including processes that have been migrated. This supports a mechanism whereby calls to the process can be forwarded to the machine where the process is executing. <p> In the current Sprite implementation, some of these statistics are simply returned as zero. However, with a small number of modifications, the needed values can be obtained. Two programs that use the migration daemon to distribute work load are Pmake and mig <ref> [2] </ref>. The former program does a parallel compilation, separating each makefile command into a different process and migrating that process to an idle host [2]. The mig command migrates a user-specified process to an idle host. <p> Two programs that use the migration daemon to distribute work load are Pmake and mig <ref> [2] </ref>. The former program does a parallel compilation, separating each makefile command into a different process and migrating that process to an idle host [2]. The mig command migrates a user-specified process to an idle host. A recent modification to the command interpreter (shell) migrates specific 8 processes using the migration daemon [10]. These processes must be specified by the user. <p> The file was locked by the client until it was finished making changes to avoid concurrent access problems. When a source client wished 15 to find a target client, it accessed the file, found an idle site, and migrated a process to that site <ref> [2] </ref>. This was inefficient as the file system had to be invoked each time the file was accessed. For consistency reasons, no process could retain the file in the cache of the local workstation. <p> Although not user-transparent, this does allow users aware of the migration tool to execute processes on foreign hosts. 2.2.3 Choosing an Algorithm Studies on Sprite and other distributed environments of differing sizes have shown idle hosts are plentiful, 65-85% in a network of over 60 workstation <ref> [2] </ref>, and greater than 70% in a Michigan State University study with 17 workstations [3]. If this is the case, then the system load is never high enough to merit a Receiver-Initiated or Symmetric algorithm. <p> Therefore, there are no file dependencies to affect process migration. However, processes on Sprite that access physical devices may not be migratable, or they may experience performance degradation if migrated to a different site. Douglis and Ousterhout <ref> [2] </ref> pose the question: Which processes should be migrated? Should all processes be con sidered candidates for migration, or only a few particularly CPU intensive processes? How are CPU-intensive processes to be identi fied? While they provide the question, the issue is left open. <p> Therefore, the memory allocation mechanism might invoke a daemon to migrate any process being swapped out. Most processes in Sprite that are migrated complete their execution on their foreign site <ref> [2] </ref>. Therefore, under normal circumstances, it is only long-lived processes that will be swapped out. Large batch jobs of low priority may be identified if a majority of their pages in virtual memory are swapped out.
Reference: [3] <author> M. </author> <title> Mutka, Estimating capacity for sharing in a privately owned workstation environment, </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> vol. 18, </volume> <pages> pp. 319-328, </pages> <month> April </month> <year> 1992. </year>
Reference-contexts: One solution to this problem is to distribute some of the tasks to an idle workstation. Studies have shown that over 65% of workstations are idle at any given time <ref> [2, 3] </ref>. Distributing processes over all of the workstations in the network balances the load at each machine so the overall time needed to complete tasks is reduced. Automatic load balancing is a system process that distributes tasks from heavily loaded workstations to idle workstations without user intervention. <p> migration tool to execute processes on foreign hosts. 2.2.3 Choosing an Algorithm Studies on Sprite and other distributed environments of differing sizes have shown idle hosts are plentiful, 65-85% in a network of over 60 workstation [2], and greater than 70% in a Michigan State University study with 17 workstations <ref> [3] </ref>. If this is the case, then the system load is never high enough to merit a Receiver-Initiated or Symmetric algorithm.
Reference: [4] <author> H. S. Stone, </author> <title> Multiprocessor scheduling with the aid of network flow algorithms, </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> vol. 32, </volume> <pages> pp. 85-93, </pages> <month> January </month> <year> 1977. </year>
Reference-contexts: Automatic load balancing is a system process that distributes tasks from heavily loaded workstations to idle workstations without user intervention. This user-transparent process provides a greater amount of processing power to all users of the system. Early studies showed that automatic load balancing can be achieved in multiprocessing systems <ref> [4] </ref> (before distributed systems were commonly available). Since then, several different algorithms have been presented for load balancing of multiprocessing and distributed system. The load from one workstation can be transferred to a lightly loaded workstation through two different methods.
Reference: [5] <author> S. J. Leffler, M. K. McKusick, M. J. Karels, and J. S. Quarterman, </author> <title> The Design and Implementation of the 4.3BSD UNIX Operating System. </title> <publisher> Addison-Wesley Publishing Company, </publisher> <year> 1989. </year>
Reference-contexts: The load from one workstation can be transferred to a lightly loaded workstation through two different methods. One method is to start a process remotely and 2 wait for it to terminate, using tools such as rsh <ref> [5] </ref>. Another method uses a mechanism called process migration [1]. Process migration in the Sprite distributed operating system [1] is defined as being able to halt a process during its execution, freeze its current state, move it to a different host, and then resume execution [2].
Reference: [6] <author> B. B. Welch and J. K. Ousterhout, </author> <title> Prefix tables: A simple mechanism for locating files in a distributed file system, </title> <booktitle> in Proc. of the 6 th International Conference on Distributed Computing Systems, </booktitle> <pages> pp. 184-189, </pages> <month> May </month> <year> 1986. </year>
Reference-contexts: The operating system that we have chosen to use is the Sprite operating system developed at University of California, Berkeley [1]. Sprite is a distributed operating system that provides a UNIX compatible interface. The name space is 6 transparent to all of the clients <ref> [6] </ref>, so all files are accessed uniformly throughout the system. Sprite provides process migration, which supports moving processes to any homogeneous machine before or during execution [2]. Sprite includes a migration daemon [7] which locates a site for remote execution and migrates a process to that site. <p> In the UNIX operating system, a process that relies on a device that is not accessible to all clients cannot be remotely executed on those sites. In Sprite, there is a transparent name space enabling access of all files to all clients <ref> [6] </ref>. Therefore, there are no file dependencies to affect process migration. However, processes on Sprite that access physical devices may not be migratable, or they may experience performance degradation if migrated to a different site. <p> Modifying the file system so that it keeps track of every single device accessed by a process would give a clearer indication of the optimum site of remote execution. Because Sprite's file system is distributed over the network <ref> [6] </ref>, migrating a process to the file server of the needed file domain could provide better execution time. We could determine which file server received the greatest number of accesses and, therefore, which client would be the best site for remote execution.
Reference: [7] <author> F. Douglis and J. Ousterhout, </author> <title> Transparent process migration: Design alternatives and the Sprite implementation, </title> <journal> Software-Practice & Experience, </journal> <volume> vol. 21, </volume> <pages> pp. 757-785, </pages> <month> Aug. </month> <year> 1991. </year>
Reference-contexts: The name space is 6 transparent to all of the clients [6], so all files are accessed uniformly throughout the system. Sprite provides process migration, which supports moving processes to any homogeneous machine before or during execution [2]. Sprite includes a migration daemon <ref> [7] </ref> which locates a site for remote execution and migrates a process to that site. Processes only migrate to workstations that have received no user input from the mouse or keyboard in the last thirty seconds. <p> For consistency reasons, no process could retain the file in the cache of the local workstation. This method was seen as more costly than a centralized program that kept track of the load average of each workstation <ref> [7] </ref>. A different method that uses a shared file is a modification of the Distributed Drafting algorithm [25]. This algorithm is a Receiver-Initiated algorithm that employs lightly loaded sites in finding heavily loaded sites. <p> These values are translated into vectors that are used to determine the most likely candidate to receive a process. Sprite is currently using a centralized algorithm for load balancing <ref> [7] </ref>. Instead of a shared file, a global load average daemon maintains each client's load in its own virtual memory. This avoids the multiple accesses to the file system that were incurred in the previous version.
Reference: [8] <author> B. B. Welch and J. K. Ousterhout, Pseudo-devices: </author> <title> User-level extensions to the Sprite file system, </title> <booktitle> in Proc. of the 1988 Summer USENIX Conf., </booktitle> <pages> pp. 184-189, </pages> <month> June </month> <year> 1988. </year>
Reference-contexts: There are local devices that can be accessed remotely, as well as user and server processes that have been made available through the file system as pseudo-devices <ref> [8] </ref>. A pseudo-device is a process or device whose driver is a user process, instead of part of the kernel. This allows extensions to the file system without modifying the kernel. Pseudo-devices give system access to those objects for which the operating system handles I/O functions.
Reference: [9] <author> B. B. Welch and J. K. Ousterhout, Pseudo-file-systems, </author> <type> Tech. Rep. </type> <institution> UCB/CSD 89/499, Univ. California Berkeley, </institution> <month> April </month> <year> 1989. </year>
Reference-contexts: Any access to a local device, local pipe, or a local pseudo device can be executed on a remote machine. Some of these devices are the keyboard, the tty, and the TCP and UDP servers, which supports access to NFS files instead of Sprite's own LFS file system <ref> [9] </ref>. Sprite satisfies the uniform name space requirement, as well as providing an inexpensive remote execution facility. It also provides performance and resource usage information. <p> The first is comprised of any call to the file system which accesses a device or service local to the source client. These devices and services are accessible through the file system using the pseudo-file mechanism in Sprite <ref> [9] </ref>. Any device mounted as a pseudo-file can be accessed as a file, with normal read and write operations. <p> A pseudo-device is an extension to the file system that allows user processes and services to be accessed remotely as it were a device <ref> [9] </ref>. These system calls must be trapped by the file system. This allows processes to access them as if they were streams, using normal read and write operations.
Reference: [10] <author> A. Ho and F. Meyer, </author> <title> A migration shell for Sprite. </title> <institution> Submitted for CS 262 at University of California, Berkeley, </institution> <month> May </month> <year> 1990. </year>
Reference-contexts: The mig command migrates a user-specified process to an idle host. A recent modification to the command interpreter (shell) migrates specific 8 processes using the migration daemon <ref> [10] </ref>. These processes must be specified by the user. A problem with the existing method is that it only migrates processes to idle clients. <p> When a process is invoked, the user's list is consulted to determine whether the process should be migrated. Two systems have been implemented using this method. One is Utopia [11], which runs on several operating systems, including UNIX and VMS, and the other is msh <ref> [10] </ref>, which runs on Sprite. Utopia distributes the load of each machine within a cluster. This cluster is defined by the system administrator depending upon their needs and network organization. Clusters have a centralized cluster server that directs process placement within the cluster. <p> We have modified both the kernel and the user shell in order to implement such a system. 1 Several modifications to the shell were required. We modified msh <ref> [10] </ref> so that it maintains a database of the past performance of processes based on data that is returned to the shell from the kernel. <p> The only responsibility of the kernel is to make this information available to the shell. We let the shell take care of the entire decision making process. 1 All changes were made according to the Sprite Engineering Manual [34]. 29 3.1 Modifying the Shell Since msh <ref> [10] </ref> was available to us and included several of the functions that were needed, we started with this version of the shell as our foundation.
Reference: [11] <author> S. Zhou, X. Zheng, J. Wang, and P. Delisle, </author> <title> Utopia: A load sharing system 54 for large, heterogeneous distributed computer systems, </title> <type> Tech. Rep. </type> <institution> CSRI-257, University of Toronto, </institution> <month> November </month> <year> 1991. </year>
Reference-contexts: Under this policy, the load cannot be fully balanced, since long-lived processes are bound to the site at 9 which they begin execution. Distributing the load using an initial placement policy is called load sharing. An example of such a system is Utopia <ref> [11] </ref>. The latter policy, process migration, allows processes to be moved to a different site during execution. In this way, processes can be moved from any site so that the load can be maintained in a balanced state. Distributing the load using process migration is called load balancing. <p> When a process is invoked, the user's list is consulted to determine whether the process should be migrated. Two systems have been implemented using this method. One is Utopia <ref> [11] </ref>, which runs on several operating systems, including UNIX and VMS, and the other is msh [10], which runs on Sprite. Utopia distributes the load of each machine within a cluster. This cluster is defined by the system administrator depending upon their needs and network organization.
Reference: [12] <author> Y. Artsy and R. Finkel, </author> <title> Designing a process migration facility: The charlotte experience, </title> <journal> IEEE Computers, </journal> <volume> vol. 22, </volume> <pages> pp. 47-56, </pages> <month> September </month> <year> 1989. </year>
Reference-contexts: In this way, processes can be moved from any site so that the load can be maintained in a balanced state. Distributing the load using process migration is called load balancing. Examples of operating systems that provide process migration include Charlotte <ref> [12] </ref>, V [13], Accent [14], and Sprite [1]. Several load sharing algorithms have been developed. Most of these algorithms can be implemented as load balancing algorithms, if the targeted operating system is one that supports process migration. Load sharing is simpler, but load balancing provides more benefits.
Reference: [13] <author> D. R. Cheriton, </author> <title> The V distributed system, </title> <journal> Communications of the ACM, </journal> <volume> vol. 31, </volume> <pages> pp. 314-333, </pages> <month> March </month> <year> 1988. </year>
Reference-contexts: In this way, processes can be moved from any site so that the load can be maintained in a balanced state. Distributing the load using process migration is called load balancing. Examples of operating systems that provide process migration include Charlotte [12], V <ref> [13] </ref>, Accent [14], and Sprite [1]. Several load sharing algorithms have been developed. Most of these algorithms can be implemented as load balancing algorithms, if the targeted operating system is one that supports process migration. Load sharing is simpler, but load balancing provides more benefits.
Reference: [14] <author> E. Zayas, </author> <title> Attacking the process migration bottleneck, </title> <booktitle> in Proc. of the 1986 fall joint computer conference, </booktitle> <pages> pp. 1-23, </pages> <publisher> IEEE, </publisher> <month> May </month> <year> 1986. </year>
Reference-contexts: In this way, processes can be moved from any site so that the load can be maintained in a balanced state. Distributing the load using process migration is called load balancing. Examples of operating systems that provide process migration include Charlotte [12], V [13], Accent <ref> [14] </ref>, and Sprite [1]. Several load sharing algorithms have been developed. Most of these algorithms can be implemented as load balancing algorithms, if the targeted operating system is one that supports process migration. Load sharing is simpler, but load balancing provides more benefits.
Reference: [15] <author> G. Cybenko, </author> <title> Dynamic load balancing for distributed memory multiprocessors, </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> vol. 8, </volume> <pages> pp. 279-301, </pages> <month> July </month> <year> 1989. </year>
Reference-contexts: The status of each client can be kept in a shared file, or can be broadcast by each client to all other pertinent clients. Since Sprite has no concept of topographic structure, network algorithms that rely on topology, as presented in <ref> [15, 16, 17, 18, 19] </ref>, will not be discussed. The algorithms presented are required to provide clients access to every site involved in process migration. Sender-Initiated A Sender-Initiated algorithm [20] is one where an overloaded source client attempts to execute a local process on a remote target client.
Reference: [16] <author> F. C. H. Lin and R. M. Keller, </author> <title> The gradient model load balancing method, </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> vol. SE-11, </volume> <pages> pp. 32-38, </pages> <month> Jan-uary </month> <year> 1987. </year>
Reference-contexts: The status of each client can be kept in a shared file, or can be broadcast by each client to all other pertinent clients. Since Sprite has no concept of topographic structure, network algorithms that rely on topology, as presented in <ref> [15, 16, 17, 18, 19] </ref>, will not be discussed. The algorithms presented are required to provide clients access to every site involved in process migration. Sender-Initiated A Sender-Initiated algorithm [20] is one where an overloaded source client attempts to execute a local process on a remote target client.
Reference: [17] <author> T. L. Casavant and J. G. Kuhl, </author> <title> Analysis of three dynamic distributed load balancing strategies with varying global information requirements, </title> <booktitle> Proc. of the 7th International Conference on Distributed Computing Systems, </booktitle> <pages> pp. 185-192, </pages> <month> August </month> <year> 1987. </year>
Reference-contexts: The status of each client can be kept in a shared file, or can be broadcast by each client to all other pertinent clients. Since Sprite has no concept of topographic structure, network algorithms that rely on topology, as presented in <ref> [15, 16, 17, 18, 19] </ref>, will not be discussed. The algorithms presented are required to provide clients access to every site involved in process migration. Sender-Initiated A Sender-Initiated algorithm [20] is one where an overloaded source client attempts to execute a local process on a remote target client.
Reference: [18] <author> S. H. Bokhari, </author> <title> A shortest tree algorithm for optimal assignments across space and time in a distributed processor system, </title> <journal> IEEE Transactions On Software Engineering, </journal> <volume> vol. SE-7, </volume> <pages> pp. 583-589, </pages> <month> November </month> <year> 1981. </year>
Reference-contexts: The status of each client can be kept in a shared file, or can be broadcast by each client to all other pertinent clients. Since Sprite has no concept of topographic structure, network algorithms that rely on topology, as presented in <ref> [15, 16, 17, 18, 19] </ref>, will not be discussed. The algorithms presented are required to provide clients access to every site involved in process migration. Sender-Initiated A Sender-Initiated algorithm [20] is one where an overloaded source client attempts to execute a local process on a remote target client.
Reference: [19] <author> S. Hosseini, B. Litow, M. Malkawi, J. McPherson, and K. Vairavan, </author> <title> Analysis of a graph coloring based distributed load balancing algorithm, </title> <journal> Journal of Parallel and Distributed Computng, </journal> <pages> pp. 160-166, </pages> <month> October </month> <year> 1990. </year>
Reference-contexts: The status of each client can be kept in a shared file, or can be broadcast by each client to all other pertinent clients. Since Sprite has no concept of topographic structure, network algorithms that rely on topology, as presented in <ref> [15, 16, 17, 18, 19] </ref>, will not be discussed. The algorithms presented are required to provide clients access to every site involved in process migration. Sender-Initiated A Sender-Initiated algorithm [20] is one where an overloaded source client attempts to execute a local process on a remote target client.
Reference: [20] <author> D. Eager, E. D. Lazowska, and J. Zahorjan, </author> <title> A comparison of receiver-initiated and sender-initiated adaptive load sharing, </title> <journal> Performance Evaluation, </journal> <volume> vol. 6, </volume> <pages> pp. 53-68, </pages> <month> March </month> <year> 1986. </year>
Reference-contexts: Since Sprite has no concept of topographic structure, network algorithms that rely on topology, as presented in [15, 16, 17, 18, 19], will not be discussed. The algorithms presented are required to provide clients access to every site involved in process migration. Sender-Initiated A Sender-Initiated algorithm <ref> [20] </ref> is one where an overloaded source client attempts to execute a local process on a remote target client. If a shared file exists, or load information is broadcast, the source client can choose a candidate based on this information. <p> This algorithm differs from Shortest Queue in that different criteria can be used to determine the best target client. It remains to be seen if this more specific algorithm would provide better results than Threshold. Receiver-Initiated A Receiver-Initiated algorithm <ref> [20] </ref> starts at an underloaded client. When the load of a client is below the minimum threshold level, it requests processes from a heavily loaded client. The methods used for obtaining processes are similar to those used to off load processes in Sender-Initiated algorithms. <p> However, these algorithms require process migration policies to be implemented, since it is not likely that an idle processor will locate a heavily loaded client immediately preceding process execution. There are some differences in the benefits of Sender-Initiated and Receiver-Initiated algorithms <ref> [20] </ref>. The former produces better response times overall when the system load is low, and the latter when the load is high. <p> These estimates are made with the assumption that network delay is the largest factor, and not CPU bundling <ref> [20] </ref>. With a small network delay, there is no significant difference between Sender-Initiated and Symmetric at low system loads. A larger network delay resulted in no significant difference until the system load was greater than 80%.
Reference: [21] <author> D. L. Eager, E. D. Lazowska, and J. Zahorjan, </author> <title> Adaptive load sharing in homogeneous distributed systems, </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> vol. SE-12, </volume> <pages> pp. 662-675, </pages> <month> May </month> <year> 1986. </year>
Reference-contexts: The load balancing mechanism attempts to find another site to execute the process. The first three methods are described by Eager et al. <ref> [21] </ref>. In Random, a target client is chosen at random and the new process is migrated to that client. There is no state information passed between the clients, so the source client has no knowledge concerning the load of the target client. <p> If not, the source client must keep the process. The source client can make several attempts to find an eligible target client. Simulations show that large number of attempts (e.g., 20) provide no significant improvement over a small number (e.g., 3 or 5) <ref> [21] </ref>. In Shortest Queue, also known as Lightest Load, several foreign sites are 12 polled to determine their load. The site with the load farthest below the threshold, if there is one, is selected from this set to be the target client. <p> Simulations performed using these algorithms assume that the largest amount of overhead is the CPU bundling. Results show that even a simple algorithm, such as Random, is a significant improvement over no load balancing <ref> [21] </ref>. Threshold gives even better results than Random. However, Shortest Queue provides very little improvement over Threshold, and costs the system more overhead time to poll potential target clients. Thus, more complex algorithms will not provide any significant performance benefits. <p> A larger network delay resulted in no significant difference until the system load was greater than 80%. Depending on the number of clients that are polled to find a target client, network traffic may be a factor <ref> [21] </ref>. For a Sender-Initiated algorithm, a smaller number of queries is more beneficial in a lightly loaded system. In a heavily loaded system a greater number of queries are necessary.
Reference: [22] <author> C.-K. Chang, </author> <title> Bidding against competitors, </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> vol. 16, </volume> <pages> pp. 100-104, </pages> <month> January </month> <year> 1990. </year>
Reference-contexts: Target clients that respond bid for the extra process, and the best bid receives the process. This bidding scheme can take a number of different forms, such as those explained by Chang <ref> [22] </ref> and Ramamitham et al. [23]. A simple bidding scheme is to grant the process to the first site that responds, limiting responses to those clients with a load small enough to accept additional processes.
Reference: [23] <author> K. Ramamritham, J. A. Stankovic, and W. Zhao, </author> <title> Distributed scheduling of tasks with deadlines and resource requirements, </title> <journal> IEEE Transactions on Computers, </journal> <volume> vol. 38, </volume> <pages> pp. 1110-1123, </pages> <month> August </month> <year> 1989. </year>
Reference-contexts: Target clients that respond bid for the extra process, and the best bid receives the process. This bidding scheme can take a number of different forms, such as those explained by Chang [22] and Ramamitham et al. <ref> [23] </ref>. A simple bidding scheme is to grant the process to the first site that responds, limiting responses to those clients with a load small enough to accept additional processes.
Reference: [24] <author> R. Mirchandaney, D. Towsley, and J. A. Stankovic, </author> <title> Analysis of the effects of delays on load sharing, </title> <journal> IEEE Transactions on Computers, </journal> <volume> vol. 38, </volume> <pages> 55 pp. 1513-1525, </pages> <month> November </month> <year> 1989. </year>
Reference-contexts: heavily loaded system, several heavily loaded clients searching for a few lightly loaded hosts will be more inefficient than a few lightly loaded clients requesting processes from heavily loaded clients. 14 Symmetric Simulations have shown that the combination of the Sender-Initiated and Receiver-Initiated algorithms performs better than either single algorithm <ref> [24] </ref>. These estimates are made with the assumption that network delay is the largest factor, and not CPU bundling [20]. With a small network delay, there is no significant difference between Sender-Initiated and Symmetric at low system loads.
Reference: [25] <author> L. M. Ni, C.-W. Xu, and T. B. Gendreau, </author> <title> A distributed drafting algorithm for load balancing, </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> vol. SE-11, </volume> <pages> pp. 1153-1161, </pages> <month> October </month> <year> 1985. </year>
Reference-contexts: This method was seen as more costly than a centralized program that kept track of the load average of each workstation [7]. A different method that uses a shared file is a modification of the Distributed Drafting algorithm <ref> [25] </ref>. This algorithm is a Receiver-Initiated algorithm that employs lightly loaded sites in finding heavily loaded sites. When a heavily loaded site is found, the idle sites draft some of the processes and execute them locally.
Reference: [26] <author> F. Bonomi and A. Kumar, </author> <title> Adaptive optimal load balancing in a nonhomogeneous multiserversystem with a central job scheduler, </title> <journal> IEEE Transactions On Computers, </journal> <volume> vol. 39, </volume> <pages> pp. 1232-1250, </pages> <month> October </month> <year> 1990. </year>
Reference-contexts: This method avoids numerous messages being sent to the server when a client is continuously switching between the middle state and one of the two extreme states. 2.2.2 Centralized Algorithms Centralized algorithms use a process scheduler that makes decisions concerning where a process should migrate. In many cases <ref> [26, 27] </ref>, process sched-ulers take all incoming processes and place them at a lightly loaded client. Workload and client characteristics can be used to determine the overall system load [28].
Reference: [27] <author> A. Thomasian, </author> <title> A performance study of dynamic load balancing in distributed systems, </title> <journal> IEEE, </journal> <pages> pp. 178-184, </pages> <month> August </month> <year> 1987. </year>
Reference-contexts: This method avoids numerous messages being sent to the server when a client is continuously switching between the middle state and one of the two extreme states. 2.2.2 Centralized Algorithms Centralized algorithms use a process scheduler that makes decisions concerning where a process should migrate. In many cases <ref> [26, 27] </ref>, process sched-ulers take all incoming processes and place them at a lightly loaded client. Workload and client characteristics can be used to determine the overall system load [28].
Reference: [28] <author> A. Ha c and T. J. Johnson, </author> <title> Sensitivity study of the load balancing algorithm in a distributed system, </title> <journal> Journal of Parallel and Distributed Computing, </journal> <pages> pp. 85-89, </pages> <month> October </month> <year> 1990. </year>
Reference-contexts: In many cases [26, 27], process sched-ulers take all incoming processes and place them at a lightly loaded client. Workload and client characteristics can be used to determine the overall system load <ref> [28] </ref>. These characteristics include the number of processes waiting in the CPU queue, CPU utilization, and number of jobs active at the client. These values are translated into vectors that are used to determine the most likely candidate to receive a process.
Reference: [29] <author> A. Ha c and X. Jin, </author> <title> Dynamic load balancing in a distributed system using a sender-initiated algorithm, </title> <booktitle> in Proc. of the 7th International Conference on Distributed Computing Systems, </booktitle> <pages> pp. 170-177, </pages> <month> September </month> <year> 1987. </year>
Reference-contexts: We must find some means to determine which processes are the best candidates for remote execution. First, we must define which processes are eligible for migration. Ha c and Jin <ref> [29] </ref> state: If, in the system not loaded by any additional processes, the mean response time of a process executed locally is greater than the mean response time caused by migration of this process and relative files, then this process is called migratable in the sense of load balancing.
Reference: [30] <author> J. Gait, </author> <title> Scheduling and process migration in partitioned multiprocessors, </title> <journal> Journal of Parallel and Distributed Computing, </journal> <pages> pp. 274-279, </pages> <month> August </month> <year> 1990. </year>
Reference-contexts: There are, however, certain indications that can be noted both during and after process execution which determine whether a process is migratable. In a study on multiprocessor systems <ref> [30] </ref>, Gait states that during execution, a process may be rescheduled on another processor if: * The local resident time slice becomes exhausted; * An idle processor intervenes to globally schedule a low priority process waiting at a processor currently executing a high-priority process; (Receiver-Initiated load balancing) or * The process
Reference: [31] <author> M. J. Litzkow, M. Livny, and M. W. </author> <title> Mutka, Condor a hunter of idle workstations, </title> <booktitle> in Proceedings of ACM Computer Network Performance Symposium, </booktitle> <pages> pp. 104-111, </pages> <month> June </month> <year> 1988. </year>
Reference-contexts: Processes are executed remotely via a remote shell process (rsh) on the target machine. Some UNIX based operating systems allow a remotely executed process to be evicted during its execution and continued on another machine. An example of this is Condor <ref> [31] </ref>, which creates a shadow process on the source client to keep track of process state during remote execution. At certain checkpoints, the state of a process is sent back to the source client. <p> The additional information that is required to make a decision is the number of system calls that must be handled on the source client, and the number of accesses to devices local to the source client. For example, in Condor <ref> [31] </ref>, the number of checkpoints that need to be sent to the home machine is used as a measurement to determine whether a process should be executed remotely. This information can be obtained by tracking the number of times these specific calls are made. <p> System calls that must be handled by the source client can limit the benefits of remote execution. If a large number of calls must be sent to the source client, the CPU time must be proportionately larger to offset the time needed for these remote procedure calls. Condor <ref> [31] </ref> uses a similar measurement to determine the benefits of remote execution. For any process, they compare the amount of CPU time with the number of checkpoints that are sent to the source client. The result is the leverage of the process.
Reference: [32] <author> A. Svensson, </author> <title> History, an intelligent load sharing filter, </title> <booktitle> in Proc. of the 10 th International Conference on Distributed Computing Systems, </booktitle> <pages> pp. 546-553, </pages> <year> 1990. </year>
Reference-contexts: There are two problems that must be considered when using past performance as a guide to the migratability of a process. What characteristics should a process exhibit to be eligible for remote execution, and what data is available from previous executions of the process? In History, proposed by Svennson <ref> [32] </ref>, the amount of CPU time necessary to complete execution is used to determine whether a process should execute remotely. <p> The metric used to prevent short-lived processes from migrating is Min Time. Any process that has an average execution time greater than the Min Time threshold is eligible for remote execution. This last metric is similar to the method used in History <ref> [32] </ref>. The difference is that History only migrates the top percentage of processes, whereas our system migrates all processes that execute longer than the specified threshold.
Reference: [33] <author> F. Douglis, </author> <title> Transparent Process Migration in the Sprite Operating System. </title> <type> PhD dissertation, </type> <institution> University of California Berkeley, California, </institution> <month> September </month> <year> 1990. </year>
Reference-contexts: By using an initial placement policy we lose some of the advantages of load balancing but we decrease the overhead of process migration. The minimum amount of time necessary to migrate a null process on a SPARCStation 1 (4/60) running Sprite is 76 milliseconds <ref> [33] </ref>. This cost increases for each page and file block that must be written back to the file system, as well as for all open file descriptors that must be migrated with the process [33]. By migrating processes only upon invocation, we limit the cost of migration to a minimum. <p> necessary to migrate a null process on a SPARCStation 1 (4/60) running Sprite is 76 milliseconds <ref> [33] </ref>. This cost increases for each page and file block that must be written back to the file system, as well as for all open file descriptors that must be migrated with the process [33]. By migrating processes only upon invocation, we limit the cost of migration to a minimum. We discuss extending this work to include process migration in x5.3.
Reference: [34] <author> J. K. Ousterhout, </author> <title> Sprite engineering manual. Programming and documentation conventions for the Sprite Operating System. </title>
Reference-contexts: The only responsibility of the kernel is to make this information available to the shell. We let the shell take care of the entire decision making process. 1 All changes were made according to the Sprite Engineering Manual <ref> [34] </ref>. 29 3.1 Modifying the Shell Since msh [10] was available to us and included several of the functions that were needed, we started with this version of the shell as our foundation.
Reference: [35] <author> D. A. Berry and B. Fristedt, </author> <title> Bandit Problems Sequential Allocation of Experiments. </title> <publisher> Chapman and Hall, </publisher> <year> 1985. </year>
Reference-contexts: When this policy is used, a process is eligible for remote execution if the ratio of the average number of accesses to local devices to the average CPU time is 2 This problem can be translated into the Two-Armed Bandit Problem <ref> [35, 36] </ref>, where one arm has a positive or negative value based on the gain or loss from remote execution, and the other arm has a value of zero. 37 less than the Dev Ratio threshold.
Reference: [36] <author> J. C. Gittins, </author> <title> Multi-Armed Bandit Allocation Indices. </title> <publisher> John Wiley & Sons, </publisher> <year> 1989. </year>
Reference-contexts: When this policy is used, a process is eligible for remote execution if the ratio of the average number of accesses to local devices to the average CPU time is 2 This problem can be translated into the Two-Armed Bandit Problem <ref> [35, 36] </ref>, where one arm has a positive or negative value based on the gain or loss from remote execution, and the other arm has a value of zero. 37 less than the Dev Ratio threshold.
Reference: [37] <author> J. Glen G. Langdon, </author> <title> An introduction to arithmetic coding, </title> <journal> IBM Journal of Research and Development, </journal> <volume> vol. 28, </volume> <pages> pp. 135-149, </pages> <month> Mar. </month> <year> 1984. </year>
Reference-contexts: Processes that with a large negative speed up should never be migrated. The file that was compiled by L A T E Xwas small (30 Kbyte). The programs compression and decode are arithmetic encoding algorithms. The former took a 16 Kbyte file and compressed it using Laplacian Estimation <ref> [37] </ref>. The latter used the compressed file and generated the original file from it. The program consw uses a large number of reads and writes to local devices to determine the context switch time (given in Appendix B.1), and ls and cat are the standard UNIX utilities.
Reference: [38] <author> F. Douglis and J. Ousterhout, </author> <title> Beating the I/O bottleneck: A case for log-structured files systems, </title> <type> Tech. Rep. </type> <institution> UCB/CSD 88/467, Univ. California Berkeley, </institution> <month> October </month> <year> 1988. </year> <month> 56 </month>
Reference-contexts: One problem that has plagued development of this project from the start is the unreliability of the Sprite log file system (LFS) <ref> [38] </ref>. When we started our final series of tests, we began to experience failures in the file system. The source code for the kernel was not always available because of the file system failures, and therefore, recompilations took an excessive amount of time.
Reference: [39] <author> D. L. Eager, E. D. Lazowska, and J. Zahorjan, </author> <title> The limited performance benefits of migrating active processes for load sharing, </title> <booktitle> in Proc. of ACM SIGMETRICS 1988, </booktitle> <month> May </month> <year> 1988. </year> <month> 57 </month>
Reference-contexts: A true load balancer cannot be implemented until we add an additional program which selects processes to migrate during their execution. The benefits of such an implementation remain to be seen, though Eager et al. present evidence that the benefits of process migration are small under normal circumstances <ref> [39] </ref>. Our system as it is can be used on distributed operating systems that do not have process migration, and only assumes that any process can be executed remotely.
References-found: 39

