URL: ftp://ftp.cs.berkeley.edu/ucb/sprite/papers/jaquith.ps.Z
Refering-URL: http://www.cs.berkeley.edu/projects/sprite/sprite.papers.html
Root-URL: http://www.cs.berkeley.edu
Title: The Jaquith Archive Server  
Author: James W. Mott-Smith 
Abstract: Advances in robotic devices and storage media now make it possible to design near-line automated storage systems. These systems aim to provide responsive performance to users of tertiary storage devices. The Jaquith system is a prototype archive server that lets network users archive their own files using automated storage. It provides semi-interactive file access to its clients by combining a high-density robotic tape system with disk-based indexing. Jaquith presents an FTP interface whereby whole files are moved between the client and its storage archive. Each client's archive is separately governed to provide independent namespaces, added security, and parallel operation. A wildcard query mechanism lets users manipulate arbitrary subsets of their files. Two important aspects of the query system are abstracts, text tags that can be associated with files, and versions, date-stamps that are applied to archived files. Jaquith throughput is about 135 KB/second when archiving small (10 KB) user files to disk buffers. The use of synchronous disk writes by the server to ensure durability of each user file degrades throughput to 40 KB/second. The performance when writing disk buffers to Exabyte or Metrum tape is severely limited by the time to write a hardware filemark. Consequently, it is important to write several megabytes of data between filemarks for good performance. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <editor> UNIX Programmer's Supplementary Documents, </editor> <volume> vol. 1, </volume> <pages> 4.3BSD. </pages> <institution> Computer Systems Research Group, Berkeley, </institution> <address> CA, </address> <month> June </month> <year> 1987. </year>
Reference-contexts: From right to left, the three main divisions are: the client programs, the Jaquith server, and the jukebox manager. The three parts communicate using the Unix socket mechanism <ref> [1] </ref>. at their workstations. The server spawns processes to handle client requests which perform indexing and buffering. The Jukebox manager is responsible for physical device allocation. Users at workstations on the network run the client programs jget, jput, and jls.
Reference: [2] <institution> IEEE Standard Portable Operating System Interface for Computer Environments. Institute of Electrical and Electronics Engineers, 345 E. </institution> <address> 47th St., New York, NY, </address> <year> 1988. </year>
Reference-contexts: A first decision was that the tape layout should adhere to some Unix system standards so that tapes can be exchanged between sites and read with standard Unix tools, when necessary. Consequently, all Jaquith data is written to tape in POSIX tar (Tape ARchive) format <ref> [2] </ref>. The tar format has a 512 byte overhead per file but this is balanced by its convenience and portability. More serious is its limit of 255 characters for full file pathnames and its 100 character limit for link pathnames.
Reference: [3] <institution> METRUM Information Storage RSS-600 Technical Manual. METRUM Information Storage, </institution> <address> Denver, CO, </address> <month> Nov </month> <year> 1990. </year>
Reference-contexts: Near the end of the development cycle a Metrum robot was acquired. It stores about nine terabytes of data with VHS cartridges placed around two rotating cylinders. Table 1 gives various specifications for both robots and tape readers. See <ref> [5, 4, 3, 6] </ref> for more information. While the two systems differ in detail, they have the following important 3 characteristics in common: * The combined latency to load a tape volume into a reader, seek to the proper location, and read a file is measured in minutes.
Reference: [4] <institution> Exabyte-120 Cartridge Hbandling Subsystem User's Manual. Exabyte Corporation, Boulder, CO, </institution> <year> 1991. </year>
Reference-contexts: Near the end of the development cycle a Metrum robot was acquired. It stores about nine terabytes of data with VHS cartridges placed around two rotating cylinders. Table 1 gives various specifications for both robots and tape readers. See <ref> [5, 4, 3, 6] </ref> for more information. While the two systems differ in detail, they have the following important 3 characteristics in common: * The combined latency to load a tape volume into a reader, seek to the proper location, and read a file is measured in minutes.
Reference: [5] <institution> Exabyte-8500 8mm Cartridge Tape Subsystem User's Manual. Exabyte Corporation, Boulder, CO, </institution> <year> 1991. </year>
Reference-contexts: Near the end of the development cycle a Metrum robot was acquired. It stores about nine terabytes of data with VHS cartridges placed around two rotating cylinders. Table 1 gives various specifications for both robots and tape readers. See <ref> [5, 4, 3, 6] </ref> for more information. While the two systems differ in detail, they have the following important 3 characteristics in common: * The combined latency to load a tape volume into a reader, seek to the proper location, and read a file is measured in minutes. <p> Filemarks on older Exabyte 8200 drives are even worse - 2.2 MB each <ref> [5] </ref>. 2 Reducing the number of filemarks also saves write time since writing a single filemark takes about two seconds on the Exabyte 8500 and eight seconds on Metrum RSP-2150. Interleaving data buffers and metadata headers is superior to placing all the metadata at the end of the tape.
Reference: [6] <editor> METRUM Information Storage RSP-2150 Operation Guide. </editor> <booktitle> METRUM Information Storage, </booktitle> <address> Denver, CO, </address> <month> July </month> <year> 1991. </year>
Reference-contexts: Near the end of the development cycle a Metrum robot was acquired. It stores about nine terabytes of data with VHS cartridges placed around two rotating cylinders. Table 1 gives various specifications for both robots and tape readers. See <ref> [5, 4, 3, 6] </ref> for more information. While the two systems differ in detail, they have the following important 3 characteristics in common: * The combined latency to load a tape volume into a reader, seek to the proper location, and read a file is measured in minutes.
Reference: [7] <author> Mary G. Baker et al. </author> <title> Measurements of a Distributed File System. </title> <booktitle> In Proceedings of the 13th ACM Symposium on Operating System Principles, </booktitle> <pages> pages 198-212, </pages> <month> Oct </month> <year> 1991. </year>
Reference-contexts: Table 1 shows the large time penalties for performing tape seek and load operations. Furthermore, Unix file access patterns are well suited to a get/put scheme. Measurements have shown that Unix files often have sequential access patterns, and are frequently read in their entirety <ref> [7, 19] </ref>. These patterns suggest that our simple whole-file access model will work well in this environment. While a whole-file interface is natural at the tape level, it is not the only possibility at the user level.
Reference: [8] <author> Sam Coleman and Steve Miller (eds.). </author> <title> Mass storage system reference model: Version 4. </title> <booktitle> IEEE Technical Committee on Mass Storage Systems and Technology, </booktitle> <month> May </month> <year> 1990. </year>
Reference-contexts: Standard deviations are in parentheses. 6 Related Work This section describes several recent projects in automated storage systems, highlighting some of the differences between their goals and those of Jaquith. 6.1 Mass Storage System Reference Model The Mass Storage System Reference Model <ref> [8] </ref> is a high-level specification for data storage, movement and access. The specification evolved from the mainframe environment so its main goals are: Interface Support for common interfaces: NFS and FTP. Integration Merging of second and third level store with automatic file migration.
Reference: [9] <author> James da Silva, Olafur Gu omondsson, and Daniel Moss e. </author> <title> Performance of a Parallel Network Backup Manager. </title> <booktitle> In 1992 Summer Usenix Conference Proceedings, </booktitle> <pages> pages 217-225, </pages> <year> 1992. </year>
Reference-contexts: Jaquith hides the database from the user. The File Motel does not have Jaquith's buffering or query features. Finally, A special network backup system called Amanda was built at the University of Maryland <ref> [9] </ref>. Amanda's goal is performance through parallelism. Amanda is an automated backup program built on top of the Unix dump utility that dumps filesystems over the network to multiple disk buffers simultaneously, Jaquith can support multiple concurrent I/O streams provided that they are directed to distinct logical archives.
Reference: [10] <author> Ann Chervenak Drapeau. </author> <title> U.C. </title> <type> Berkeley Technical report. </type> <note> To appear. </note>
Reference-contexts: The drawback of these tape systems is their low transfer rate and long load delays (the time to mount the volume and locate the beginning of tape). Long term reliability is also an open issue, see <ref> [10] </ref>. Ampex D-2 tape systems combine high-density storage with very high throughput rates, but carry very high prices that make them more suitable for specialized purposes.
Reference: [11] <author> Joel Fine et al. </author> <title> Abstracts: A Latency-Hiding Technique for High-Capacity Mass-Storage Systems. </title> <note> Technical Report UCB/CSD 99/11 June 1992, </note> <institution> University of California, Berkeley, </institution> <month> June </month> <year> 1992. </year>
Reference-contexts: Jaquith's whole-file interface provides multiple file versions and consistent performance. Additionally, an NFS interface with a successful migration policy should do intelligent prefetching, construct file summaries for quick browsing, and be integrated with the kernel. The first two item are research topics beyond Jaquith's scope (see for example <ref> [11] </ref>), and the last requires system dependencies (mostly in the file descriptor to know whether a file is on disk or not) that we wanted to avoid. 3.3 Wildcard Queries Two utility programs, jput and jget, are used to move files between the archive and the disk.
Reference: [12] <author> Andrew Hume. </author> <title> The File Motel. </title> <booktitle> In 1988 Summer Usenix Conference Proceedings, </booktitle> <pages> pages 61-72, </pages> <year> 1988. </year>
Reference-contexts: Normal shell syntax is extended with an '@' symbol to provide command-line access to the file versions. Jaquith relies on the shell-like jls, which is more complex, but offers more features. 28 Andrew Hume presented an automated backup system called the File Motel in 1987 <ref> [12] </ref> which was notable for being able to perform incremental dumps. A background process quietly archives files that have been changed without user intervention. Jaquith's jput can also archive files incrementally. Nightly backups can be automated with a cron script.
Reference: [13] <author> Randy H. Katz, Garth A. Gibson, and David A. Patterson. </author> <title> Disk system architectures for high performance computing. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 77(12) </volume> <pages> 1842-1858, </pages> <month> December </month> <year> 1989. </year>
Reference-contexts: In a different environment where the average file size is many megabytes or gigabytes (for example satellite data), tape throughput becomes a problem. One solution to the bandwidth problem is to apply disk RAID <ref> [13] </ref> ideas to tape systems. The main idea is to write a large file out across several tapes in parallel, with parity written to an additional tape for recovery purposes.
Reference: [14] <author> Fred McClain. DataTree and UniTree: </author> <title> Software for file and storage management. </title> <booktitle> In Digest of Papers, </booktitle> <pages> pages 126-128. </pages> <booktitle> Tenth IEEE Symposium on Mass Storage Systems, </booktitle> <month> May </month> <year> 1990. </year>
Reference-contexts: They include the Common File System (originally from Los Alamos National Labs, now sold as DataTree by General Atomics), Unitree (originally from Livermore National Labs now sold by General Atomics), MSS-II at the National Center for Atmospheric Research, and NASA Ames <ref> [28, 15, 20, 14, 21] </ref>. The supercomputer centers running MSS-style code are primarily concerned with moving huge files though several levels of storage automatically. Therefore they provide file migration where Jaquith does not.
Reference: [15] <author> Marc Nelson, David L. Kitts, John H. Merrill, and Gene Harano. </author> <title> The NCAR mass storage system. </title> <booktitle> In Digest of Papers. Eighth IEEE Symposium on Mass Storage Systems, </booktitle> <month> November </month> <year> 1987. </year>
Reference-contexts: They include the Common File System (originally from Los Alamos National Labs, now sold as DataTree by General Atomics), Unitree (originally from Livermore National Labs now sold by General Atomics), MSS-II at the National Center for Atmospheric Research, and NASA Ames <ref> [28, 15, 20, 14, 21] </ref>. The supercomputer centers running MSS-style code are primarily concerned with moving huge files though several levels of storage automatically. Therefore they provide file migration where Jaquith does not.
Reference: [16] <author> Michael Olson. </author> <type> Personal communication. </type>
Reference-contexts: We considered using the Postgres RDBMS [26, 25] for the initial testbed, but its size and complexity did not seem to warrant its use. For example, Postgres version 4.0 has a storage overhead of 50-60 bytes/tuple <ref> [16] </ref>, which would almost double the size of a standard index entry. Requiring the installation of a full DBMS would make Jaquith much less portable. 4.5 Synchronization Parallelism is achieved by the use of multiple reader and writer processes.
Reference: [17] <author> J. K. Ousterhout. </author> <title> Tcl: An Embeddable Command Language. </title> <booktitle> In 1990 Winter Usenix Conference Proceedings, </booktitle> <pages> pages 133-146. </pages> <publisher> USENIX, </publisher> <month> Jan </month> <year> 1990. </year> <month> 34 </month>
Reference-contexts: The motivations for a second interface are to expand Jaquith's appeal and to experiment with the Tcl/Tk <ref> [17, 18] </ref> interface-building tools. The jget, jput, jls programs described in the previous section, along with the status utility jstat comprise Jaquith's command line interface.
Reference: [18] <author> J. K. Ousterhout. </author> <title> An X11 toolkit based on the Tcl language. </title> <booktitle> In 1991 Winter Usenix Conference Proceedings. USENIX, </booktitle> <month> Jan </month> <year> 1991. </year>
Reference-contexts: The motivations for a second interface are to expand Jaquith's appeal and to experiment with the Tcl/Tk <ref> [17, 18] </ref> interface-building tools. The jget, jput, jls programs described in the previous section, along with the status utility jstat comprise Jaquith's command line interface.
Reference: [19] <author> J. K. Ousterhout et al. </author> <title> A Trace-Driven analysis of the UNIX 4.2 BSD File System. </title> <booktitle> In Proceedings of the 10th ACM Symposium on Operating System Principles, </booktitle> <pages> pages 15-24, </pages> <month> Dec </month> <year> 1985. </year>
Reference-contexts: Table 1 shows the large time penalties for performing tape seek and load operations. Furthermore, Unix file access patterns are well suited to a get/put scheme. Measurements have shown that Unix files often have sequential access patterns, and are frequently read in their entirety <ref> [7, 19] </ref>. These patterns suggest that our simple whole-file access model will work well in this environment. While a whole-file interface is natural at the tape level, it is not the only possibility at the user level.
Reference: [20] <author> Anthony L. Peterson. </author> <title> E-Systems Modular Automated Storage System (EMASS) software functionality. </title> <booktitle> In Digest of Papers, </booktitle> <pages> pages 73-76. </pages> <booktitle> Eleventh IEEE Symposium on Mass Storage Systems, </booktitle> <month> October </month> <year> 1991. </year>
Reference-contexts: They include the Common File System (originally from Los Alamos National Labs, now sold as DataTree by General Atomics), Unitree (originally from Livermore National Labs now sold by General Atomics), MSS-II at the National Center for Atmospheric Research, and NASA Ames <ref> [28, 15, 20, 14, 21] </ref>. The supercomputer centers running MSS-style code are primarily concerned with moving huge files though several levels of storage automatically. Therefore they provide file migration where Jaquith does not.
Reference: [21] <author> Dennis F. Reed and Gary A. Mueller. </author> <title> Automated cartidge system library server. </title> <booktitle> In Digest of Papers, </booktitle> <pages> pages 105-110. </pages> <booktitle> Tenth IEEE Symposium on Mass Storage Systems, </booktitle> <year> 1990. </year>
Reference-contexts: They include the Common File System (originally from Los Alamos National Labs, now sold as DataTree by General Atomics), Unitree (originally from Livermore National Labs now sold by General Atomics), MSS-II at the National Center for Atmospheric Research, and NASA Ames <ref> [28, 15, 20, 14, 21] </ref>. The supercomputer centers running MSS-style code are primarily concerned with moving huge files though several levels of storage automatically. Therefore they provide file migration where Jaquith does not.
Reference: [22] <author> W. D. Roome. 3DFS: </author> <title> A time-oriented file server. </title> <booktitle> In 1992 Winter Usenix Conference Proceedings, </booktitle> <pages> pages 405-418. </pages> <publisher> Usenix, </publisher> <month> Jan </month> <year> 1992. </year>
Reference-contexts: The Renaissance package has a built-in migration policy. Jaquith does not have a migration policy. A form of Jaquith's versioning feature is found in the 3D filesystem from AT&T Bell Labs <ref> [22] </ref>. Roome's system retrieves old versions of files using data from incremental backups. It is therefore a read-only system. Like Jaquith it trades space for speed by storing complete versions of files, rather than rebuilding them on the fly.
Reference: [23] <author> Stuart Sechrest. </author> <title> Atrribute-Based Naming of Files. </title> <type> Technical Report CSE-TR-78-91, </type> <institution> University of Michigan, </institution> <month> January </month> <year> 1991. </year>
Reference-contexts: One way to add multiple access methods is to use a relational database system (RDBMS) to do all the indexing. Using a full RDBMS with a query language would make it possible to research various indexing techniques (for example <ref> [23] </ref>), but wouldn't contribute to Jaquith's immediate goals. We considered using the Postgres RDBMS [26, 25] for the initial testbed, but its size and complexity did not seem to warrant its use.
Reference: [24] <author> Jennifer G. Steiner, Clifford Neuman, and Jeffrey I. Schiller. </author> <title> Kerberos: An Authentication Service for Open Network Systems. </title> <booktitle> In 1988 Winter Usenix Conference Proceedings, </booktitle> <pages> pages 191-202. </pages> <publisher> USENIX, </publisher> <month> Jan </month> <year> 1988. </year>
Reference-contexts: The server trusts all callers who use a privileged port to be who they claim to be, using their hostname and username to do validation. The MIT Kerberos project has solved the authentication problems in a networked environment <ref> [24] </ref> and Jaquith should be kerberized for better security. 5 Performance Jaquith's performance has two distinct parts: (1) packaging user files into disk buffers with associated index information and (2) writing full buffers to tertiary storage.
Reference: [25] <author> Michael Stonebraker et al. </author> <title> The Implementation of POSTGRES. </title> <journal> In IEEE Transactions on Knowledge and Data Engineering, </journal> <month> Mar </month> <year> 1990. </year>
Reference-contexts: Using a full RDBMS with a query language would make it possible to research various indexing techniques (for example [23]), but wouldn't contribute to Jaquith's immediate goals. We considered using the Postgres RDBMS <ref> [26, 25] </ref> for the initial testbed, but its size and complexity did not seem to warrant its use. For example, Postgres version 4.0 has a storage overhead of 50-60 bytes/tuple [16], which would almost double the size of a standard index entry.
Reference: [26] <author> Michael Stonebraker and Larry Rowe. </author> <title> The Design of POSTGRES. </title> <booktitle> In Proceedings of ACM-SIGMOD Conference on Management of Data, </booktitle> <year> 1986. </year>
Reference-contexts: Using a full RDBMS with a query language would make it possible to research various indexing techniques (for example [23]), but wouldn't contribute to Jaquith's immediate goals. We considered using the Postgres RDBMS <ref> [26, 25] </ref> for the initial testbed, but its size and complexity did not seem to warrant its use. For example, Postgres version 4.0 has a storage overhead of 50-60 bytes/tuple [16], which would almost double the size of a standard index entry.
Reference: [27] <author> Eng Tan and Bert Vermeulen. </author> <title> Digital audio tape for data storage. </title> <journal> IEEE Spectrum, </journal> <month> October </month> <year> 1989. </year>
Reference-contexts: The tape medium is a sequential access medium and does not support update-in-place 13 operations. (Some 4mm DAT tapes can be pre-formatted to allow update-in-place operations but performance and capacity are sacrificed, see <ref> [27] </ref>. This dataDat mode has not caught on and neither 8mm nor VHS tape supports it.) The design of the tape layout cannot include rewritable index blocks, or updatable data. Hardware filemarks are the universal file separator for tape systems.
Reference: [28] <author> David Tweten. </author> <title> Hiding mass storage under UNIX: </title> <booktitle> NASA's MSS-II architecture. In Digest of Papers, </booktitle> <pages> pages 140-145. </pages> <booktitle> Tenth IEEE Symposium on Mass Storage Systems, </booktitle> <month> May </month> <year> 1990. </year>
Reference-contexts: They include the Common File System (originally from Los Alamos National Labs, now sold as DataTree by General Atomics), Unitree (originally from Livermore National Labs now sold by General Atomics), MSS-II at the National Center for Atmospheric Research, and NASA Ames <ref> [28, 15, 20, 14, 21] </ref>. The supercomputer centers running MSS-style code are primarily concerned with moving huge files though several levels of storage automatically. Therefore they provide file migration where Jaquith does not.
References-found: 28

