URL: http://www.cis.udel.edu/~decker/courses/889b/buridan-aaai94.ps
Refering-URL: http://www.cis.udel.edu/~decker/courses/889b.html
Root-URL: http://www.cis.udel.edu
Email: weldg@cs.washington.edu  
Title: An Algorithm for Probabilistic Least-Commitment Planning less than a user-supplied probability threshold. The algorithm is
Author: Nicholas Kushmerick Steve Hanks Daniel Weld fnick, hanks, 
Address: Seattle, WA 98195  
Affiliation: Department of Computer Science and Engineering, FR-35 University of Washington  
Note: To appear, AAAI-94  with probability no  
Abstract: We define the probabilistic planning problem in terms of a probability distribution over initial world states, a boolean combination of goal propositions, a probability threshold, and actions whose effects depend on the execution-time state of the world and on random chance. Adopting a probabilistic model complicates the definition of plan success: instead of demanding a plan that provably achieves the goal, we seek plans whose probability of success exceeds the threshold. This paper describes a probabilistic semantics for planning under uncertainty, and presents a fully implemented algorithm that generates plans that succeed 
Abstract-found: 1
Intro-found: 1
Reference: <author> Breese, J. </author> <year> 1992. </year> <title> Construction of belief and decision networks. </title> <booktitle> Computational Intelligence 8(4). </booktitle>
Reference-contexts: Work in decision science has dealt with planning problems (see (Dean & Wellman 1991, Chap. 7) for an introduction), but it has focused on solving a given probabilistic model whereas our algorithm interleaves the process of constructing and evaluating solutions. But see <ref> (Breese 1992) </ref> for recent work on model-building issues. (Haddawy & Hanks 1992; 1993) motivate building a planner like buridan, exploring the connection between building plans that probably satisfy goals and plans that are optimal in the sense of maximizing expected utility.
Reference: <author> Chapman, D. </author> <year> 1987. </year> <title> Planning for conjunctive goals. </title> <booktitle> Artificial Intelligence 32(3) </booktitle> <pages> 333-377. </pages>
Reference: <author> Collins, G., and Pryor, L. </author> <year> 1992. </year> <title> Achieving the functionality of filter conditions in a partial order planner. </title> <booktitle> In Proc. 10th Nat. Conf. on A.I. </booktitle>
Reference: <author> Cooper, G. </author> <year> 1990. </year> <title> The computational complexity of probabilistic inference using bayesian belief networks. </title> <booktitle> Artificial Intelligence 42. </booktitle>
Reference: <author> Dean, T., and Wellman, M. </author> <year> 1991. </year> <title> Planning and Control. </title> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Work in decision science has dealt with planning problems (see <ref> (Dean & Wellman 1991, Chap. 7) </ref> for an introduction), but it has focused on solving a given probabilistic model whereas our algorithm interleaves the process of constructing and evaluating solutions.
Reference: <author> Dean, T., Kaelbling, L., Kirman, J., and Nicholson, A. </author> <year> 1993. </year> <title> Planning with deadlines in stochastic domains. </title> <booktitle> In Proc. 11th Nat. Conf. on A.I. </booktitle>
Reference-contexts: Related Work and Conclusions (Mansell 1993) and (Goldman & Boddy 1994) offer alternative approaches to applying classical planning algorithms to probabilistic action and state models. <ref> (Dean et al. 1993) </ref>, (Farley 1983), and (Koenig 1992) use fully observable Markov processes to model the planning problem.
Reference: <author> Draper, D., Hanks, S., and Weld, D. </author> <year> 1994a. </year> <title> A probabilistic model of action for least-commitment planning with information gathering. </title> <booktitle> In Proc., Uncertainty in AI. Submitted. </booktitle>
Reference: <author> Draper, D., Hanks, S., and Weld, D. </author> <year> 1994b. </year> <title> Probabilistic planning with information gathering and contingent execution. </title> <booktitle> In Proc. 2nd Int. Conf. on A.I. Planning Systems. </booktitle>
Reference: <author> Farley, A. </author> <year> 1983. </year> <title> A Probabilistic Model for Uncertain Problem Solving. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics 13(4). </journal>
Reference-contexts: Related Work and Conclusions (Mansell 1993) and (Goldman & Boddy 1994) offer alternative approaches to applying classical planning algorithms to probabilistic action and state models. (Dean et al. 1993), <ref> (Farley 1983) </ref>, and (Koenig 1992) use fully observable Markov processes to model the planning problem.
Reference: <author> Goldman, R. P., and Boddy, M. S. </author> <year> 1994. </year> <note> Epsilon-safe planning. forthcoming. </note>
Reference-contexts: The longer version of this paper describes these algorithms in detail. Analysis of these algorithms shows no clear winner: in each case we can construct domains and problems in which one algorithm consistently outperforms the other. Related Work and Conclusions (Mansell 1993) and <ref> (Goldman & Boddy 1994) </ref> offer alternative approaches to applying classical planning algorithms to probabilistic action and state models. (Dean et al. 1993), (Farley 1983), and (Koenig 1992) use fully observable Markov processes to model the planning problem.
Reference: <author> Haddawy, P., and Hanks, S. </author> <year> 1992. </year> <title> Representations for Decision-Theoretic Planning: Utility Functions for Dealine Goals. </title> <booktitle> In Proc. 3rd Int. Conf. on Principles of Knowledge Representation and Reasoning. </booktitle>
Reference: <author> Haddawy, P., and Hanks, S. </author> <year> 1993. </year> <title> Utility Models for Goal-Directed Decision-Theoretic Planners. </title> <type> Technical Report 93-06-04, </type> <institution> Univ. of Washington, Dept. of Computer Science and Engineering. </institution> <note> Submitted to Artificial Intelligence. Available via FTP from pub/ai/ at cs.washington.edu. </note>
Reference: <author> Hanks, S. </author> <year> 1990. </year> <title> Practical temporal projection. </title> <booktitle> In Proc. 8th Nat. Conf. on A.I., </booktitle> <pages> 158-163. </pages>
Reference: <author> Hanks, S. </author> <year> 1993. </year> <title> Modeling a Dynamic and Uncertain World II: Action Representation and Plan Evaluation. </title> <type> Technical report, </type> <institution> Univ. of Washington, Dept. of Computer Science and Engineering. </institution>
Reference-contexts: Second, we describe an implemented algorithm for probabilistic planning. Third, we briefly describe our investigation of alternative plan assessment strategies. The paper concludes with a discussion of related work. This research is described in detail in the long version of this paper <ref> (Kushmerick, Hanks, & Weld 1993) </ref>. Example. The following example will be developed throughout the paper. Suppose a robot is given the goal of holding a block (HB), making sure it is painted (BP), and simultaneously keeping its gripper clean (GC).
Reference: <author> Koenig, S. </author> <year> 1992. </year> <title> Optimal probabilistic and decision-theoretic planning using markovian decision theory. </title> <address> UCB/CSD 92/685, Berkeley. </address>
Reference-contexts: Related Work and Conclusions (Mansell 1993) and (Goldman & Boddy 1994) offer alternative approaches to applying classical planning algorithms to probabilistic action and state models. (Dean et al. 1993), (Farley 1983), and <ref> (Koenig 1992) </ref> use fully observable Markov processes to model the planning problem.
Reference: <author> Kushmerick, N., Hanks, S., and Weld, D. </author> <year> 1993. </year> <title> An Algorithm for Probabilistic Planning. </title> <type> Technical Report 93-06-03, </type> <institution> Univ. of Washington, Dept. of Computer Science and Engineering. </institution> <note> To appear in Artificial Intelligence. Available via FTP from pub/ai/ at cs.washington.edu. </note>
Reference-contexts: Second, we describe an implemented algorithm for probabilistic planning. Third, we briefly describe our investigation of alternative plan assessment strategies. The paper concludes with a discussion of related work. This research is described in detail in the long version of this paper <ref> (Kushmerick, Hanks, & Weld 1993) </ref>. Example. The following example will be developed throughout the paper. Suppose a robot is given the goal of holding a block (HB), making sure it is painted (BP), and simultaneously keeping its gripper clean (GC).
Reference: <author> Mansell, T. </author> <year> 1993. </year> <title> A method for planning given uncertain and incomplete information. </title> <booktitle> In Proc. 9th Conf. on Uncertainty in Artifical Intelligence. </booktitle>
Reference-contexts: The longer version of this paper describes these algorithms in detail. Analysis of these algorithms shows no clear winner: in each case we can construct domains and problems in which one algorithm consistently outperforms the other. Related Work and Conclusions <ref> (Mansell 1993) </ref> and (Goldman & Boddy 1994) offer alternative approaches to applying classical planning algorithms to probabilistic action and state models. (Dean et al. 1993), (Farley 1983), and (Koenig 1992) use fully observable Markov processes to model the planning problem.
Reference: <author> McAllester, D., and Rosenblitt, D. </author> <year> 1991. </year> <title> Systematic nonlinear planning. </title> <booktitle> In Proc. 9th Nat. Conf. on A.I., </booktitle> <pages> 634-639. </pages>
Reference-contexts: As we'll see, hdry; paint; pickupi is a solution to the example problem. The buridan Algorithm We now describe buridan, an algorithm that generates solutions to planning problems. buridan, like snlp <ref> (McAllester & Rosenblitt 1991) </ref>, searches a space of partial plans.
Reference: <author> Penberthy, J., and Weld, D. </author> <year> 1992. </year> <title> UCPOP: A sound, complete, partial order planner for ADL. </title> <booktitle> In Proc. 3rd Int. Conf. on Principles of Knowledge Representation and Reasoning, </booktitle> <pages> 103-114. </pages> <note> Available via FTP from pub/ai/ at cs.washington.edu. </note>
Reference-contexts: Although planning with conditional effects is not the primary focus of our work, buridan also generalizes work on planning with deterministic conditional effects, e.g. in (Collins & Pryor 1992; Penberthy & Weld 1992). A deterministic form of confrontation is used in ucpop <ref> (Penberthy & Weld 1992) </ref>. The buridan planner integrates a probabilistic semantics for action with classical least-commitment planning techniques. buridan accepts probabilistic information about the problem's initial state, and manipulates actions with conditional and probabilistic effects.
References-found: 19

