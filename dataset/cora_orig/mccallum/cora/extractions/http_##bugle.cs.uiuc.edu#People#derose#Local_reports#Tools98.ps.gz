URL: http://bugle.cs.uiuc.edu/People/derose/Local_reports/Tools98.ps.gz
Refering-URL: http://bugle.cs.uiuc.edu/People/derose/pablo_publications.html
Root-URL: http://www.cs.uiuc.edu
Email: fderose,zhang8,reedg@cs.uiuc.edu  
Title: SvPablo: A Multi-Language Performance Analysis System  
Author: Luiz De Rose Ying Zhang Daniel A. Reed 
Note: Origin 2000.  
Address: Urbana, Illinois 61801 USA  
Affiliation: Department of Computer Science University of Illinois  
Abstract: In this paper we present the design of SvPablo, a language independent performance analysis and visualization system that can be easily extended to new contexts with minimal changes to the software infrastructure. At present, SvPablo supports analysis of applications written in C, Fortran, and HPF on a variety of sequential and parallel systems. In addition to capturing application data via software instrumentation, SvPablo also exploits hardware performance counters to capture the interaction of software and hardware. Both hardware and software performance data are summarized during program execution, enabling measurement of programs that execute for hours or days on hundreds of processors. This performance data is stored in a format designed to be language transparent and portable. We demonstrate the usefulness of SvPablo for tuning application programs with a series of case studies running on an SGI 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Adve, V., Mellor-Crummey, J., Wang, J.-C., and Reed, D. </author> <title> Integrating Compilation and Performance Analysis for Data-Parallel Programs. </title> <booktitle> In Proceedings of Supercomputing'95 (November 1995). </booktitle>
Reference-contexts: Without such ties, application developers must deduce the effects of compiler transformations on source code and the interactions of compiled code with architectural features and runtime systems. This is especially difficult when data parallel source code is aggressively transformed to message passing or shared memory compiled code <ref> [1] </ref>. <p> As described below, these choices were driven by experience with earlier generations of instrumentation systems <ref> [14, 1] </ref> and analysis of common compiler transformations on current parallel systems. 2.1 Automatic Instrumentation To support analysis of codes written in data parallel High-Performance Fortran, SvPablo is integrated with the commercial HPF compiler [13] from the Portland Group (PGI). <p> In addition, as described in x3, the library can also capture hardware performance events via the MIPS R10000 performance counters. 1 The desire to capture performance data for data parallel code via compiler-synthesized instrumentation is based on the results of our collaboration with the Rice Fortran D project <ref> [1, 2] </ref>. The D system, a precursor to current HPF compilers, supports a large set of aggressive optimizations, including procedure inlining, loop distribution software pipelining, and global code motion. Collectively, these optimizations result in executable code that differs markedly from the original source.
Reference: [2] <author> Adve, V. S., Mellor-Crummey, J., Anderson, M., Kennedy, K., Wang, J., and Reed, D. A. </author> <title> Integrating Compilation and Performance Analysis for Data-Parallel Programs. In Proceedings of the Workshop on Debugging and Performance Tuning for Parallel Computing Systems, </title> <editor> M. L. Simmons, A. H. Hayes, D. A. Reed, and J. Brown, Eds. </editor> <publisher> IEEE Computer Society Press, </publisher> <year> 1994. </year>
Reference-contexts: In addition, as described in x3, the library can also capture hardware performance events via the MIPS R10000 performance counters. 1 The desire to capture performance data for data parallel code via compiler-synthesized instrumentation is based on the results of our collaboration with the Rice Fortran D project <ref> [1, 2] </ref>. The D system, a precursor to current HPF compilers, supports a large set of aggressive optimizations, including procedure inlining, loop distribution software pipelining, and global code motion. Collectively, these optimizations result in executable code that differs markedly from the original source.
Reference: [3] <author> Aydt, R. </author> <title> The Pablo Self-Defining Data Format. </title> <type> Tech. rep., </type> <institution> Department of Computer Science at the University of Illinois at Urbana-Champaign, </institution> <month> April </month> <year> 1994. </year>
Reference-contexts: Following execution, performance data from each processor is integrated, additional statistics are computed, and the resulting metrics are correlated with application source code, creating a performance file that is represented via the Pablo self-describing data format (SDDF) <ref> [3] </ref>. This performance file is the specification used by the SvPablo browser to display application source code and correlated performance metrics. Use of the Pablo SDDF metaformat has enabled us to develop a user interface that is both portable and language independent.
Reference: [4] <author> Balsara, D. </author> <title> Riemann Solver for Relativistic Hydrodynamics. </title> <journal> Journal of Computational Physics 114, </journal> <month> 2 (October </month> <year> 1994), </year> <month> 284. </month>
Reference-contexts: Moreover, the mean MFLOPS rate for each processor increased by four orders of magnitude. 6.2 Detecting Unnecessary Communication Our second case study explored the behavior of a Riemann solver for relativistic hydrodynamics <ref> [4] </ref>, a portion of a cosmology code that contained approximately 35,000 lines of HPF code. Even before analyzing the program with SvPablo, we observed that it exhibited poor scalability on the SGI Origin. Indeed, parallel execution was substantially shower than the serial execution.
Reference: [5] <author> Fahringer, T. </author> <title> Estimating and Optimizing Performance for Parallel programs. </title> <booktitle> IEEE Computer 28, </booktitle> <month> 11 (November </month> <year> 1995), </year> <pages> 47-56. </pages>
Reference-contexts: Notable example include P 3 T <ref> [5] </ref> for performance prediction, and Pablo [14], Paradyn [8] and AIMS [19] for performance measurement. The majority of these tools focus on particular programming models (e.g., message passing or data parallel) or specific hardware/software platforms.
Reference: [6] <author> Lee, B. D., and Wilhelmson, R. B. </author> <title> The Numerical Simulation of Non-Supercell Tornado-genesis. </title> <booktitle> In 18th Conference on Severe Local Storms (February 1996). </booktitle>
Reference-contexts: Based on this experience, we present three case studies on the SGI Origin 2000 that demonstrate SvPablo's effectiveness when analyzing performance and tuning codes. 6.1 Overlapping Computations and Communications The first of our three studies explores the performance of a numerical model to simulate cloud and density current dynamics <ref> [6] </ref>. The code is a three-dimensional, non-hydrostatic, finite difference, convective cloud model that utilizes a quasi-compressible version of the Navier-Stokes equations. Originally written in CM Fortran for the CM5, the code was later translated to High-Performance Fortran, yielding approximately 9000 lines of HPF code.
Reference: [7] <author> Meadows, L. </author> <type> Personal communication, </type> <year> 1997. </year> <title> The Portland Group, </title> <publisher> Inc. </publisher>
Reference-contexts: The HPF compiler should redistribute the arrays across subroutine boundaries, eliminating communication inside each subroutine However, measurements with SvPablo showed many messages, each four bytes long, sent and received for array assignments inside the inner loop of each subroutine. Further analysis of the code <ref> [7] </ref> showed that these messages were generated due to a scalar passed to a "pure" subroutine with status intent ( inout ). This required the compiler to force dissemination of the scalar to all processors to ensure consistency.
Reference: [8] <author> Miller, B. P., Callaghan, M. D., Cargille, J. M., Hollingsworth, J. K., Irvin, R. B., Karavanic, K. L., Kunchithapadam, K., and Newhall, T. </author> <title> The Paradyn Parallel Performance Measurement Tools. </title> <booktitle> IEEE Computer 28, </booktitle> <month> 11 (November </month> <year> 1995), </year> <pages> 37-46. </pages>
Reference-contexts: Notable example include P 3 T [5] for performance prediction, and Pablo [14], Paradyn <ref> [8] </ref> and AIMS [19] for performance measurement. The majority of these tools focus on particular programming models (e.g., message passing or data parallel) or specific hardware/software platforms.
Reference: [9] <institution> MIPS Technologies Inc. Definition of MIPS R10000 Performance Counters, </institution> <year> 1996. </year> <note> http://www.sgi.com/MIPS/products/r10k/Perf Cnt/R10K PF Count.doc.html. </note>
Reference-contexts: SvPablo supports performance data capture, analysis, and presentation for applications written in a variety of languages and executing on both sequential and parallel systems. In addition, SvPablo exploits support for hardware performance counters <ref> [9, 20] </ref> on the MIPS R10000 [11] and SGI Origin 2000. During execution of instrumented code, the SvPablo library captures data and computes performance metrics on the execution dynamics of each instrumented construct on each processor.
Reference: [10] <author> MIPS Technologies Inc. </author> <title> MIPS R10000 Microprocessor User's Manual, </title> <editor> 2.0 ed., </editor> <year> 1996. </year>
Reference-contexts: Examination of data from the hardware counters showed that the performance degradation when using the cyclic distribution was mainly due to secondary cache misses. The MIPS R10000 processor on the Origin 2000 has a two-level cache composed of separate primary instruction and data caches and a shared secondary cache <ref> [10] </ref>. Each cache is two-way set associative using a write back protocol, with cross-processor cache coherence maintained via a write-invalidate protocol in a directory-based scheme [17]. On the Origin 2000, cache coherence is maintained with two types of actions: external interventions and external invalidations.
Reference: [11] <institution> MIPS Technologies Inc. </institution> <note> R10000 Microprocessor User's Manual, version 2.0 ed. </note> <institution> 2011 N Shoreline Blvd; PO Box 7311; Mountain View, </institution> <address> CA 94039-7311, </address> <month> October </month> <year> 1996. </year> <note> http://www.sgi.com/MIPS/products/r10k/UMan V2.0/R10K UM.cv.html. </note>
Reference-contexts: SvPablo supports performance data capture, analysis, and presentation for applications written in a variety of languages and executing on both sequential and parallel systems. In addition, SvPablo exploits support for hardware performance counters [9, 20] on the MIPS R10000 <ref> [11] </ref> and SGI Origin 2000. During execution of instrumented code, the SvPablo library captures data and computes performance metrics on the execution dynamics of each instrumented construct on each processor.
Reference: [12] <author> Pancake, C. M., Simmons, M. L., and Yan, J. C. </author> <title> Performance Evaluation Tools for Parallel and Distributed Systems. </title> <booktitle> IEEE Computer 28, </booktitle> <month> 11 (November </month> <year> 1995), </year> <pages> 16-19. </pages>
Reference-contexts: Correlating data parallel source code with dynamic performance data from both software and hardware measurement, while still providing a portable, intuitive, and easily used interface, is a challenging task <ref> [12] </ref>. However, without such tools, use of high-performance parallel systems will remain limited to a small cadre of application developers willing to master the arcane details of processor architecture, system software, and compilation systems.
Reference: [13] <institution> The Portland Group, Inc. </institution> <note> PGHPF User's Guide, </note> <year> 1994. </year>
Reference-contexts: As described below, these choices were driven by experience with earlier generations of instrumentation systems [14, 1] and analysis of common compiler transformations on current parallel systems. 2.1 Automatic Instrumentation To support analysis of codes written in data parallel High-Performance Fortran, SvPablo is integrated with the commercial HPF compiler <ref> [13] </ref> from the Portland Group (PGI). The PGI HPF compiler emits message passing code with embedded calls to the SvPablo data capture library. This instrumentation captures data for each executable line in the original HPF source code.
Reference: [14] <author> Reed, D. A., Aydt, R. A., Noe, R. J., Roth, P. C., Shields, K. A., Schwartz, B., and Tavera, L. F. </author> <title> Scalable Performance Analysis: The Pablo Performance Analysis Environment. </title> <booktitle> In Proceedings of the Scalable Parallel Libraries Conference (1993), </booktitle> <editor> A. Skjellum, Ed., </editor> <publisher> IEEE Computer Society. </publisher> <pages> 17 </pages>
Reference-contexts: As described below, these choices were driven by experience with earlier generations of instrumentation systems <ref> [14, 1] </ref> and analysis of common compiler transformations on current parallel systems. 2.1 Automatic Instrumentation To support analysis of codes written in data parallel High-Performance Fortran, SvPablo is integrated with the commercial HPF compiler [13] from the Portland Group (PGI). <p> For each source file the user wishes to instrument, SvPablo parses the file and marks all instru-mentable constructs. In a compromise between instrumentation detail and perturbation, SvPablo restricts these constructs to outer loops and procedure calls. This restriction draws on our earlier experience with the Pablo interactive instrumentation interface <ref> [14] </ref>. We observed that naive users tended to instrument everything, resulting in prodigious volumes of performance data, high perturbations, and little insight. The SvPablo user interface, shown in Figure 1, presents the parser's list of instrumentable constructs as a scrollable list. <p> Only with this separation can one readily add new metrics and support new languages, compilers, and architectures without requiring extensive modifications to the user interface code. In SvPablo, the Pablo self-defining data format (SDDF) <ref> [14, 15] </ref> provides this separation. SDDF defines data streams that consist of a group of record descriptors and record instances. Much as structure declarations in the C programming language specify templates for storage allocation, 7 8 9 SDDF descriptors define the structure for record instances. <p> Notable example include P 3 T [5] for performance prediction, and Pablo <ref> [14] </ref>, Paradyn [8] and AIMS [19] for performance measurement. The majority of these tools focus on particular programming models (e.g., message passing or data parallel) or specific hardware/software platforms.
Reference: [15] <author> Reed, D. A., Elford, C. L., Madhyastha, T., Scullin, W. H., Aydt, R. A., and Smirni, E. </author> <title> I/O, Performance Analysis, and Performance Data Immersion. </title> <booktitle> In Proceedings of MASCOTS '96 (Feb. </booktitle> <year> 1996), </year> <pages> pp. 1-12. </pages>
Reference-contexts: Only with this separation can one readily add new metrics and support new languages, compilers, and architectures without requiring extensive modifications to the user interface code. In SvPablo, the Pablo self-defining data format (SDDF) <ref> [14, 15] </ref> provides this separation. SDDF defines data streams that consist of a group of record descriptors and record instances. Much as structure declarations in the C programming language specify templates for storage allocation, 7 8 9 SDDF descriptors define the structure for record instances.
Reference: [16] <author> Sadourny, R. </author> <title> The Dynamics of Finite-Difference Model of the Shallow-Water Equations. </title> <journal> Journal of Atmospheric Sciences 32, </journal> <month> 4 (April </month> <year> 1975). </year>
Reference-contexts: substitution eliminated the communication and improved the performance of the array assignments in the inner loops by four orders of magnitude. 14 . 6.3 Analyzing Effects of Cache Coherence As a final study, we explored the behavior of a two-dimensional simulation model of the finite difference shallow water wave equations <ref> [16] </ref>. This program was originally written in Fortran 77 at the National Center for Atmospheric Research (NCAR).
Reference: [17] <author> Stenstrom, P. </author> <title> A Survey of Cache Coherence Schemes for Multiprocessors. </title> <booktitle> IEEE Computer (June 1990), </booktitle> <pages> 12-20. </pages>
Reference-contexts: Each cache is two-way set associative using a write back protocol, with cross-processor cache coherence maintained via a write-invalidate protocol in a directory-based scheme <ref> [17] </ref>. On the Origin 2000, cache coherence is maintained with two types of actions: external interventions and external invalidations. External interventions occur when one processor must retrieve a cache line that has been written by another processor.
Reference: [18] <author> Torrellas, J., Lam, M., and Hennessy, J. L. </author> <title> False Sharing and Spatial Locality in Multiprocessor Caches. </title> <journal> IEEE Transactions on Computers (June 1994). </journal>
Reference-contexts: In addition, the numbers of interventions and invalidations were an order of magnitude higher than for the block distribution. These trends suggest either frequent data sharing or a possible cache coherence problem due to false sharing <ref> [18] </ref>. 15 Time Interventions Invalidations D2 Misses Line 42 (CYCLIC,*) 4.66 209,064 421,452 850,304 (*, BLOCK) 0.72 6,510 18,798 133,541 Line 46 (CYCLIC,*) 4.71 202,702 401,880 783,113 (*, BLOCK) 0.77 12,772 14,496 133,541 Line 606 (CYCLIC,*) 6.66 170,582 433,680 700,141 (*, BLOCK) 0.63 8,054 21,752 66,668 Table 5: Performance Metrics (1024fi1024
Reference: [19] <author> Yan, J. C., Sarukkai, S. R., and Mehra, P. </author> <title> Performance Measurement, Visualization and Modeling of Parallel and Distributed Programs using the AIMS Toolkit. </title> <journal> Software Practice & Experience 25, </journal> <month> 4 (April </month> <year> 1995), </year> <pages> 429-461. </pages>
Reference-contexts: Notable example include P 3 T [5] for performance prediction, and Pablo [14], Paradyn [8] and AIMS <ref> [19] </ref> for performance measurement. The majority of these tools focus on particular programming models (e.g., message passing or data parallel) or specific hardware/software platforms.
Reference: [20] <author> Zagha, M., Larson, B., Turner, S., and Itzkowitz, M. </author> <title> Performance Analysis Using the MIPS R10000 Performance Counters. </title> <booktitle> In Proceedings of Supercomputing'96 (November 1996). </booktitle>
Reference-contexts: SvPablo supports performance data capture, analysis, and presentation for applications written in a variety of languages and executing on both sequential and parallel systems. In addition, SvPablo exploits support for hardware performance counters <ref> [9, 20] </ref> on the MIPS R10000 [11] and SGI Origin 2000. During execution of instrumented code, the SvPablo library captures data and computes performance metrics on the execution dynamics of each instrumented construct on each processor.
References-found: 20

