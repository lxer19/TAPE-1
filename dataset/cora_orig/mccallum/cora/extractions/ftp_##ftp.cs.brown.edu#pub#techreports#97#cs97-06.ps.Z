URL: ftp://ftp.cs.brown.edu/pub/techreports/97/cs97-06.ps.Z
Refering-URL: http://www.cs.brown.edu/publications/techreports/reports/CS-97-06.html
Root-URL: http://www.cs.brown.edu/
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> V. R. Algazi, Y. Kato, M. Miyahara, and K. Kotani. </author> <title> Comparison of image coding techniques with a picture quality scale. </title> <booktitle> In Proceedings of SPIE, Applications of Digital Image Processing XV, </booktitle> <pages> pages 396-405, </pages> <address> San Diego, CA, </address> <month> July </month> <year> 1992. </year>
Reference-contexts: After the first frame is coded, the buffer is reset to be half full. The quantization scale Q s is determined from the buffer fullness B f using the formula: Q s = min (b32B f c + 1; 31); where Q s has a integral range of <ref> [1; 31] </ref>, and B f is normalized to have a real-valued range of [0; 1]. This feedback function is plotted in Figure 3.21. <p> The quantization scale Q s is determined from the buffer fullness B f using the formula: Q s = min (b32B f c + 1; 31); where Q s has a integral range of [1; 31], and B f is normalized to have a real-valued range of <ref> [0; 1] </ref>. This feedback function is plotted in Figure 3.21. <p> Both of these factors depend upon the scene content as well. Studies into human visual perception suggest that perceptual distortion is correlated to certain spatial (and temporal) properties of an image (video sequence) <ref> [78, 1] </ref>. These studies lead to various techniques, called perceptual quantization or adaptive perceptual quantization, that take into account properties of the Human Visual System (HVS) in determining the quantization scale [104, 86, 52, 16, 60, 108, 18]. <p> For a sequence of N pictures, we define N corresponding bit-production models ff 1 ; f 2 ; : : : ; f N g that map nominal quantization scale to bits: b i = f i (q i ), where f i : <ref> [0; 1] </ref> 7! [l i ; u i ], with 0 l i &lt; u i . (We number pictures in encoding order and not temporal display order. <p> From these conditions, it follows that f i is invertible with q i = g i (b i ), where g i = f 1 i and g i : [l i ; u i ] 7! <ref> [0; 1] </ref>. We note that g i is also continuous and monotonically decreasing. Although monotonicity does not always hold in practice, it is a generally accepted assumption.
Reference: [2] <author> T. C. Bell, J. G. Cleary, and I. H. Witten. </author> <title> Text Compression. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1990. </year>
Reference: [3] <author> T. C. Bell and I. H. Witten. </author> <title> Relationship between greedy parsing and symbolwise text compression. </title> <journal> Journal of the ACM, </journal> <volume> 41(4) </volume> <pages> 708-724, </pages> <month> July </month> <year> 1994. </year>
Reference: [4] <author> V. Bhaskaran and K. Konstantinides. </author> <title> Image and Video Compression Standards. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, MA, </address> <year> 1995. </year>
Reference-contexts: Next, we describe existing international standards for video coding and present an overview of the fundamentals of these standards. This chapter is by no means intended to be comprehensive; for an in-depth introduction to video coding fundamentals, the reader is referred to <ref> [4, 34, 71, 76] </ref>. 3.1 Digital Video Representation For compression to be meaningful, a standard representation should be defined for the data to be compressed.
Reference: [5] <author> M. Bierling. </author> <title> Displacement estimation by hierarchical blockmatching. </title> <booktitle> SPIE Vol. 1001 Visual Communications and Image Processing, </booktitle> <pages> pages 942-951, </pages> <year> 1988. </year>
Reference-contexts: Potentially better results can be achieved by directly exploiting the two-dimensional correlation of motion vectors. A quadtree data structure can be used for this purpose by representing the motion field hierarchically in two dimensions <ref> [87, 5, 9, 24] </ref>. The quadtree approach works by identifying variable-sized regions of uniform motion and providing an efficient encoding of the motion field. <p> Bierling <ref> [5] </ref> described a hierarchical 89 algorithm for choosing motion vectors in which initially motion vectors are chosen for large blocks (64 fi 64) by minimizing the prediction error. 1 Then for each large block B, motion vectors are chosen for subblocks of B again by minimizing prediction error, except looking only
Reference: [6] <institution> CCIR Recommendation 601. Encoding parameters of digital television for studios, </institution> <year> 1982. </year>
Reference-contexts: the more popular standard representations. 1 This definition is intended also to encompass mappings from a discrete domain to a discrete range. 2 Further quantization of digitized data may use a number of quantization levels that is not a power of 2 and employ variable-length entropy coding. 37 The CCIR-601 <ref> [6] </ref> format for video frames specifies spatial sampling of 720 fi 480 and temporal sampling at 30 frames/sec for NTSC (U.S. and Japan) television systems and 720 fi 576 at 25 frames/sec for PAL (Europe) television systems.
Reference: [7] <author> CCITT. </author> <title> Description of reference model 8 (RM8), </title> <month> June </month> <year> 1989. </year> <title> Study Group XV|Document 525. </title>
Reference-contexts: However, to aid in the evaluation of different coding techniques, the CCITT provides an encoder simulation model called Reference Model 8 (RM8) <ref> [7] </ref>. Motion estimation is performed to minimize the mean absolute difference (MAD) of the prediction errors. A fast three-step search, instead of an exhaustive full search, is used for motion estimation. RM8 specifies several heuristics used to make the coding decisions. <p> If the zero motion vector is chosen, this is indicated by a special coding mode and no motion vector is sent. The decision diagram, as recommended in <ref> [7] </ref>, are shown in Figure 3.19 (b). The loop filter is enabled if a non-zero motion vector is used. The decision of whether to transmit the block-transform coefficients is made individually for each block in a macroblock by considering the values of the quantized transform coefficients. <p> Only the luminance blocks are compared to the determine the best match, with the mean absolute difference (MAD) being used as the measure of prediction error. Decisions on how to code individual blocks are made according to Reference Model 8 <ref> [7] </ref>, as described in Section 3.6.3. 4.3 Explicit Minimization Algorithms In the PVRG coder, motion estimation is performed to minimize the MAD of the prediction error.
Reference: [8] <author> CCITT. </author> <title> Video codec for audiovisual services at p fi 64 kbit/s, </title> <month> August </month> <year> 1990. </year> <title> Study Group XV|Report R 37. </title>
Reference-contexts: its simplicity, block-matching is commonly used with current video coding standards. 3.6 H.261 Standard In 1990, the International Telegraph and Telephone Consultative Committee (CCITT) 5 approved an international standard for video coding at bit rates of p fi 64 kbits/sec, where p is an integer between 1 and 30, inclusive <ref> [8, 65] </ref>. Officially known as CCITT Recommendation H.261, it is informally called the pfi64 standard and is intended for low-bit-rate applications such as videophone and videoconferencing. <p> not for VBR. 63 64 Chapter 4 Motion Estimation for Low-Bit-Rate Video Coding 4.1 Introduction As described in the previous chapter, hybrid video coding that combines block-matching motion compensation (BMMC) with transform coding of the residual is a popular scheme for video compression, adopted by international standards such as H.261 <ref> [8, 65] </ref> and the MPEG standards [47, 49, 57].
Reference: [9] <author> M. H. Chan, Y. B. Yu, and A. G. Constantinides. </author> <title> Variable size block matching motion compensation with applications to video coding. </title> <booktitle> IEE proceedings, </booktitle> <volume> 137(4) </volume> <pages> 205-212, </pages> <year> 1990. </year>
Reference-contexts: Potentially better results can be achieved by directly exploiting the two-dimensional correlation of motion vectors. A quadtree data structure can be used for this purpose by representing the motion field hierarchically in two dimensions <ref> [87, 5, 9, 24] </ref>. The quadtree approach works by identifying variable-sized regions of uniform motion and providing an efficient encoding of the motion field. <p> While Bierling did not discuss how to code motion vectors obtained through by his method, Chan, Yu, and Constantinides <ref> [9] </ref> described a method where motion vectors are again chosen in a top-down fashion, starting with large blocks and refining with smaller blocks.
Reference: [10] <author> J.-J. Chen and H.-M. Hang. </author> <title> A transform video coder source model and its application. </title> <booktitle> In Proceedings ICIP'94, </booktitle> <volume> volume 2, </volume> <pages> pages 967-971, </pages> <year> 1994. </year>
Reference-contexts: Short-term rate control is applied when the upper bound on encoder rate needs to be enforced. Several methods are proposed for performing short-term rate control. In <ref> [10] </ref>, a model relating bits, distortion, and quantization scale is derived for block-transform video coders. Assuming a stationary Gaussian process, the authors derive a bit-production model containing transcendental functions. The model is applied to control the frame rate of motion-JPEG and H.261 video coders. <p> The authors also describe the heuristic of recomputing a allocation only when the buffer reaches predefined threshold levels. In this chapter, we have considered a simple hyperbolic model and a linear-spline model of bit production. In <ref> [10] </ref>, a bit-production model is derived for block-transform coders based on rate-distortion theory and assuming a stationary Gaussian process. The model is applied for VBR coding with motion JPEG and H.261 coders.
Reference: [11] <author> M. C. Chen and Jr. A. N. Willson. </author> <title> Rate-distortion optimal motion estimation algorithm for video coding. </title> <booktitle> In Proceedings 1996 International Conference on Acoustics, Speech and Signal Processing, </booktitle> <volume> volume 4, </volume> <pages> pages 2096-2099, </pages> <address> Atlanta, GA, </address> <month> May </month> <year> 1996. </year>
Reference-contexts: For each block, a Lagrangian cost function is used to select between intraframe and interframe modes and to select between a small number of candidate motion vectors, which are coded with a lossy two-dimensional vector quantizer. Independent of our work, rate-distortion optimization for motion estimation has been reported in <ref> [11] </ref>. The authors consider operational rate-distortion optimization in a dependent-coding environment where motion vectors are coded using DPCM techniques. <p> In comparison, our adaptive heuristic cost function requires minimal overhead over block matching. In another independent work [95], the authors also apply operational rate-distortion optimization to motion estimation in a dependent-coding environment. Similar to <ref> [11] </ref>, they cast motion estimation as a budget-constrained bit allocation problem and solve it using a combination of Lagrange minimization and dynamic programming. The authors also consider joint optimization of motion estimation and quantization using the same framework.
Reference: [12] <author> J.-B. Cheng and H.-M. Hang. </author> <title> Adaptive piecewise linear bits estimation model for MPEG based video coding. </title> <booktitle> In Proceedings ICIP'95, </booktitle> <volume> volume 2, </volume> <pages> pages 551-554, </pages> <year> 1995. </year> <month> 157 </month>
Reference-contexts: In [10], a bit-production model is derived for block-transform coders based on rate-distortion theory and assuming a stationary Gaussian process. The model is applied for VBR coding with motion JPEG and H.261 coders. In <ref> [12] </ref>, an adaptive tree-structured piecewise linear bit-production model is proposed and applied to MPEG video coding using a one-pass encoding strategy. A cubic-spline model of rate and distortion is proposed in [64, 63] for use with a gradient-based rate-control algorithm [61, 62] that attempts to minimize MSE.
Reference: [13] <author> J. Choi and D. Park. </author> <title> A stable feedback control of the buffer state using the controlled lagrange multiplier method. </title> <journal> IEEE Transactions on Image Processing, </journal> <volume> 3(5) </volume> <pages> 546-557, </pages> <month> September </month> <year> 1994. </year>
Reference-contexts: Thus, it seems that fixing is safe in practice. Still, since influences rate to some extent, it can be used in conjunction with the quantization step size in performing rate control. Automatic control of based upon buffer feedback as described in <ref> [13] </ref> is a possibility. Although the methods presented here have been implemented within the H.261 standard, it should be generally applicable to any video coder that employs motion compensation in a low bit rate setting. <p> In related work, a buffered rate control scheme for multiplexing VBR sources onto a CBR channel is described in [81]. This work is based on the rate-distortion framework of [80] and <ref> [13] </ref> and uses a multiplexing model very similar to the one we are about to present. As described in the paper, the basic allocation unit is taken to be a GOP. 10.2.2 Multiplexing Model We first elaborate a model for multiplexing multiple VBR bitstreams onto a CBR channel.
Reference: [14] <author> P. A. Chou, T. Lookabaugh, and R. M. Gray. </author> <title> Entropy-constrained vector quantization. </title> <journal> IEEE Transactions on Signal Processing, </journal> <volume> 37(1) </volume> <pages> 31-42, </pages> <month> January </month> <year> 1989. </year>
Reference-contexts: Even though not directly computable, the existence of a hypothetical rate-distortion function for a given type of information source allows a comparison to be made between competing encoding systems and algorithms. 40 A more practical approach is taken in <ref> [14, 98] </ref>. By measuring actual rates and distortion achieved by the coder under study, an operational rate-distortion plot similar to Figure 3.6 can be constructed. It is sometimes useful to show the convex hull of the data points to fill in the gap between points.
Reference: [15] <author> K. W. Chun, K. W. Lim, H.D. Cho, and J. B. Ra. </author> <title> An adaptive perceptual quantization algorithm for video coding. </title> <journal> IEEE Transactions on Consumer Electronics, </journal> <volume> 39(3) </volume> <pages> 555-558, </pages> <month> August </month> <year> 1993. </year>
Reference-contexts: In this regards, ff I can be viewed as a perceptual weighting factor. Our bit rate allocation, however, works with any perceptual quantization function. The problem of determining P (I; Q) has been studied elsewhere <ref> [104, 15] </ref> and is not considered in this thesis. Here, we address the assignment of Q to each picture to give constant or near-constant quality among pictures while satisfying rate constraints imposed by the channel and decoder.
Reference: [16] <author> T.-Y. Chung, K.-H. Jung, Y.-N. Oh, and D.-H. Shin. </author> <title> Quantization control for improvement of image quality compatible with MPEG2. </title> <journal> IEEE Transactions on Consumer Electronics, </journal> <volume> 40(4) </volume> <pages> 821-825, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: These studies lead to various techniques, called perceptual quantization or adaptive perceptual quantization, that take into account properties of the Human Visual System (HVS) in determining the quantization scale <ref> [104, 86, 52, 16, 60, 108, 18] </ref>.
Reference: [17] <author> W. C. Chung, F. Kossentini, and M. J. T. Smith. </author> <title> A new approach to scalable video coding. </title> <booktitle> In Proceedings 1995 Data Compression Conference, </booktitle> <pages> pages 381-390, </pages> <address> Snowbird, UT, March 1995. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: Only the magnitude of the motion vectors are shown. 80 (a) Carphone (b) Claire (c) Foreman (d) Grandma (e) Miss America (f) Mother and Daughter (g) Suzie (h) Trevor 81 (a) H1 Coder (b) H2 Coder 82 4.5 Related Work In related work, Chung, Kossentini and Smith <ref> [17] </ref> consider rate-distortion optimizations for motion estimation in a hybrid video coder based upon subband coding and block-matching motion compensation. The input frames are first decomposed into subbands, which are divided into uniform rectangular blocks.
Reference: [18] <author> G. Cicalini, L Favalli, and A. Mecocci. </author> <title> Dynamic psychovisual bit allocation for improved quality bit rate in MPEG-2 transmission over ATM links. </title> <journal> Electronic Letters, </journal> <volume> 32(4) </volume> <pages> 370-371, </pages> <month> February </month> <year> 1996. </year>
Reference-contexts: These studies lead to various techniques, called perceptual quantization or adaptive perceptual quantization, that take into account properties of the Human Visual System (HVS) in determining the quantization scale <ref> [104, 86, 52, 16, 60, 108, 18] </ref>.
Reference: [19] <author> J. G. Cleary and I. H. Witten. </author> <title> A comparison of enumerative and adaptive codes. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> IT-30(2):306-315, </volume> <month> March </month> <year> 1984. </year>
Reference: [20] <author> J. G. Cleary and I. H. Witten. </author> <title> Data compression using adaptive coding and partial string matching. </title> <journal> IEEE Transactions on Communication, </journal> <volume> COMM-32(4):396-402, </volume> <month> April </month> <year> 1984. </year>
Reference: [21] <author> T. M. Cover and J. A. Thomas. </author> <title> Elements of Information Theory. </title> <publisher> Wiley-Interscience, </publisher> <address> New York, </address> <year> 1991. </year>
Reference-contexts: In cases where the distortion is bounded above by D max , then R (D max ) = 0. Furthermore, it can be shown that R (D) is a non-increasing convex function of D (see, e.g., <ref> [21] </ref>). For some specific information sources and distortion measures, closed form expressions for the rate-distortion function have been determined.
Reference: [22] <author> W. Ding. </author> <title> Joint encoder and channel rate control of VBR video over ATM networks, </title> <month> April </month> <year> 1996. </year> <type> preprint. </type>
Reference-contexts: In the construction of the trellis used by the Viterbi algorithm, states that violate the various constraints are discarded. Unlike our framework, there is no explicit constraint on the total number of bits used. Joint control of encoder and channel rate is also considered in <ref> [22] </ref>. Instead of considering global optimality, this work focuses on real-time control algorithms. An algorithm is proposed that separates rate control into a "short-term" process and a "long-term" process.
Reference: [23] <author> W. Ding and B. Liu. </author> <title> Rate control of MPEG video coding and recording by rate-quantization modeling. </title> <journal> IEEE Transactions on Circuits and Systems for Video Technology, </journal> <volume> 6(1) </volume> <pages> 12-20, </pages> <month> February </month> <year> 1996. </year>
Reference-contexts: We need a single model whose parameters are independent of Q. The curve fitting results from the pretraining trials show a strong correlation between the model parameters and Q 1 . This agrees well with previous work on rate-quantization modeling <ref> [23] </ref>. Therefore we propose the following form for the cost function: H (~; Q) = c 1 Q This can be simplified as H ( ) = c 1 + c 2 ; (4.8) where ~=Q. <p> This results in a time complexity of O (N 2 ) for both optimal CBR and VBR allocation. In related work, Ding and Liu <ref> [23] </ref> propose the following more general class of bit-production models and describe its use in rate control: f i (q) = q fl i 1 Our framework only assumes monotonicity and not concavity. 130 The extra parameter fl i is dependent on the picture type (I, P, or B) and is
Reference: [24] <author> F. Dufaux and M. Kunt. </author> <title> Multigrid block matching motion estimation with an adaptive local mesh refinement. </title> <booktitle> SPIE Vol. 1818 Visual Communications and Image Processing, </booktitle> <pages> pages 97-109, </pages> <year> 1992. </year>
Reference-contexts: Potentially better results can be achieved by directly exploiting the two-dimensional correlation of motion vectors. A quadtree data structure can be used for this purpose by representing the motion field hierarchically in two dimensions <ref> [87, 5, 9, 24] </ref>. The quadtree approach works by identifying variable-sized regions of uniform motion and providing an efficient encoding of the motion field. <p> Methods for taking a tree structure like the above (except expanded completely) and then "smoothing" the motion vectors by making children tend to be like their parents and vice-versa, were discussed by Dufaux and Kunt <ref> [24] </ref>. Zhang, Cavenor, and Arnold [112] considered various ways of using quadtrees to code the prediction error. 5.5 Discussion In this chapter, we have presented a non-standard hybrid block-matching DCT video coder that further optimizes the coding of motion vectors by representing the motion field using a quadtree decomposition.
Reference: [25] <author> H. Everett. </author> <title> Generalized langrange multiplier method for solving problems of optimum allocation of resources. </title> <journal> Operation Research, </journal> <volume> 11 </volume> <pages> 399-417, </pages> <year> 1963. </year>
Reference-contexts: There could potentially be an exponential number of states generated, on the order of M N . In [98], Shoham and Gersho give an efficient bit allocation algorithm based on the Lagrange-multiplier method <ref> [25] </ref>. In this method, Problem 3.1, a constrained optimization problem, is transformed to the following unconstrained optimization problem. 43 a state that exceeds the bit budget B and can be pruned. An optimal path is shown with thick edges. <p> Note that there may be more than one solution with a given . It can be shown that a solution to Problem 3.2 is also a solution to Problem 3.1 when R fl () = B. This is proved in <ref> [25] </ref>, and we reproduce the theorem and proof as presented in [98]. Theorem 3.1 For any 0, a solution Q fl () to Problem 3.2 is also a solution to Problem 3.1 with the constraint R (Q) B, where B = R fl ().
Reference: [26] <author> R. M. Fano. </author> <title> The transmission of information. </title> <type> Technical Report 65, </type> <institution> Research Laboratory of Electronics, </institution> <year> 1949. </year> <month> 158 </month>
Reference: [27] <author> E. R. Fiala and D. H. Greene. </author> <title> Data compression with finite windows. </title> <journal> Communications of the ACM, </journal> <volume> 32(4) </volume> <pages> 490-505, </pages> <month> April </month> <year> 1989. </year>
Reference: [28] <author> G. D. Forney. </author> <title> The viterbi algorithm. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 61 </volume> <pages> 268-278, </pages> <month> March </month> <year> 1973. </year>
Reference-contexts: hQ 1 ; Q 2 ; : : : ; Q N i to each block that minimizes a distortion measure D (Q) and uses R (Q) B bits. 3.3.3a Viterbi Algorithm Problem 3.1 can be solved using a dynamic programming algorithm commonly referred to as the Viterbi algorithm (VA) <ref> [28, 105] </ref>. Assuming that quantization always produces an integral number of bits, the Viterbi algorithm works by first constructing a trellis of nodes and then finding a shortest path through the trellis. Each node represents a state and each edge a transition between states. <p> A bit allocation algorithm based upon Lagrangian minimization is presented as a more efficient alternative to the well-known dynamic programming solution based upon the Viterbi algorithm <ref> [105, 28] </ref>. This work lays the foundation for much of the ensuing work on optimal bit allocation. Optimal budget-constrained bit allocation in a dependent, predictive coding setting is examined in [103]. A parametric rate-distortion model is proposed for intraframe coding and forward predictive coding.
Reference: [29] <author> J. E. Fowler and S. C. Ahalt. </author> <title> Differential vector quantization of real-time video. </title> <booktitle> In Proceedings 1994 Data Compression Conference, </booktitle> <pages> pages 205-214, </pages> <address> Snowbird, UT, March 1994. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: Usually, the same codebook is used by the encoder and the decoder. The codebook generation process is itself computationally demanding. As with lossless dictionary coding, a VQ codebook can be constructed statically, semi-adaptively, or adaptively. Some applications of VQ in video compression can be found in <ref> [29, 106] </ref>. 46 3.4.2 Block Transform In block-transform coding, an image is divided into blocks, as with vector quantization. Each block is mathematically transformed into a different representation, which is then quantized and coded.
Reference: [30] <author> A. Gersho and R. M. Gray. </author> <title> Vector Quantization and Signal Compression. </title> <publisher> Kluwer Academic Press, </publisher> <year> 1992. </year>
Reference-contexts: Reducing spatial redundancy has been the focus of many image compression algorithms. Since video is just a sequence of images, image compression techniques are directly applicable to video frames. Here, we outline some popular image coding techniques applicable to lossy video coding. 3.4.1 Vector Quantization In vector quantization (VQ) <ref> [30] </ref>, an image is segmented into same-sized blocks of pixel values. The blocks are represented by a fixed number of vectors called codewords. The codewords are chosen from a finite set called a codebook.
Reference: [31] <author> J. B. Ghosh. </author> <title> Siting facilities along a line when equity of service is desirable. </title> <journal> Journal of Operation Research Society, </journal> <volume> 47(3) </volume> <pages> 435-445, </pages> <month> March </month> <year> 1996. </year>
Reference-contexts: After the first frame is coded, the buffer is reset to be half full. The quantization scale Q s is determined from the buffer fullness B f using the formula: Q s = min (b32B f c + 1; 31); where Q s has a integral range of <ref> [1; 31] </ref>, and B f is normalized to have a real-valued range of [0; 1]. This feedback function is plotted in Figure 3.21. <p> Assuming a stationary Gaussian process, the authors derive a bit-production model containing transcendental functions. The model is applied to control the frame rate of motion-JPEG and H.261 video coders. In the operations research literature, lexicographic optimality has been applied to such problems as resource location and allocation (e.g., <ref> [31, 53, 66, 68, 77, 85] </ref>) and is sometimes referred to as lexicographic minimax , since it can be viewed as a refinement of minimax theory. 6.8 Discussion As described above, much of the previous work on optimal rate control for video coding use the conventional rate-distortion approach of minimizing a
Reference: [32] <author> P. C. Gutmann and T. C. Bell. </author> <title> A hybrid approach to data compression. </title> <booktitle> In Proceedings 1994 Data Compression Conference, </booktitle> <pages> pages 225-233, </pages> <address> Snowbird, UT, March 1994. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference: [33] <author> A. Hartman and M. Rodeh. </author> <title> Optimal parsing of strings. </title> <editor> In A. Apostolico and Z. Galil, editors, </editor> <booktitle> Combinatorial Algorithms on Words, </booktitle> <pages> pages 155-167. </pages> <publisher> Springer-Verlag, </publisher> <year> 1985. </year>
Reference: [34] <author> B. G. Haskell, A. Puri, and A. N. Netravali. </author> <title> Digital Video: An Introduction to MPEG-2. </title> <publisher> Chapman & Hall, </publisher> <address> New York, NY, </address> <year> 1997. </year>
Reference-contexts: Next, we describe existing international standards for video coding and present an overview of the fundamentals of these standards. This chapter is by no means intended to be comprehensive; for an in-depth introduction to video coding fundamentals, the reader is referred to <ref> [4, 34, 71, 76] </ref>. 3.1 Digital Video Representation For compression to be meaningful, a standard representation should be defined for the data to be compressed.
Reference: [35] <author> B. G. Haskell and A. R. Reibman. </author> <title> Multiplexing of variable rate encoded streams. </title> <journal> IEEE Transactions on Circuits and Systems for Video Technology, </journal> <volume> 4(4) </volume> <pages> 417-424, </pages> <month> August </month> <year> 1994. </year>
Reference-contexts: This is especially critical in storage applications, where the storage capacity, and not the transfer rate, is the limiting factor. Another important application of VBR video coding is for multiplexing multiple video bitstreams over a CBR channel <ref> [35] </ref>. In this application, statistical properties of the multiple video sequences allow more VBR bitstreams with a given peak rate R max to be multiplexed onto the channel than CBR bitstreams coded at a constant rate of R max . <p> In the figure, M video sources enter a encoder/multiplexer that produces a single multiplexed stream for transport over a CBR channel. On the receiving end, a demultiplexer/decoder performs demultiplexing and decoding to reproduce the M video sequences. This multiplexing model is similar to that proposed in <ref> [35] </ref>. This model is applicable to applications such as a video server where the video sequences to be multiplexed are known in advance. An especially noteworthy case is that of near-video-on-demand (NVOD), where a single sequence is to be transmitted simultaneously with different starting times.
Reference: [36] <author> J. Hertz, A. Krogh, and R. G. Palmer. </author> <title> Introduction to the Theory of Neural Computation. </title> <publisher> Addison-Wesley, </publisher> <address> Redwood City, CA, </address> <year> 1991. </year>
Reference-contexts: This is a tedious and time-consuming operation. Instead, we can use an adaptive on-line technique, such as the Widrow-Hoff learning rule <ref> [109, 36] </ref>, to train the model parameters. The training examples could be generated each time we encode a macroblock using motion compensation mode. However, we cannot possibly hope to train one model for each value of Q simply because there would not be enough training examples.
Reference: [37] <author> D. T. Hoang, P. M. Long, and J. S. Vitter. </author> <title> Explicit bit-minimization for motion-compensated video coding. </title> <booktitle> In Proceedings 1994 Data Compression Conference, </booktitle> <pages> pages 175-184, </pages> <address> Snowbird, UT, March 1994. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: These heuristic coders give compression performance comparable to the explicit minimization coders while running much faster. Experimental results are presented in Sections 4.3.4 and 4.4.2. Preliminary descriptions of this work can be found in <ref> [37, 38, 39, 40] </ref>. 4.2 PVRG Implementation of H.261 As a basis for comparing the different motion estimation schemes proposed in this chapter, we use the p fi 64 coder supplied by the Portable Video Research Group (PVRG) [45]. <p> In this chapter, we consider the instantiation of the bit-minimization principle in a video coder that uses a quadtree to code motion vectors, thereby departing from the p fi 64 standard. The contents of this chapter were originally presented in <ref> [37] </ref>. 5.1 Quadtree Data Structure Often used as a representation for bi-level images, the quadtree can also be used to code motion vectors.
Reference: [38] <author> D. T. Hoang, P. M. Long, and J. S. Vitter. </author> <title> Rate-distortion optimizations for motion estimation in low-bitrate video coding. </title> <type> Technical Report CS-1995-16, </type> <institution> Duke University, Dept. of Computer Science, </institution> <year> 1995. </year>
Reference-contexts: These heuristic coders give compression performance comparable to the explicit minimization coders while running much faster. Experimental results are presented in Sections 4.3.4 and 4.4.2. Preliminary descriptions of this work can be found in <ref> [37, 38, 39, 40] </ref>. 4.2 PVRG Implementation of H.261 As a basis for comparing the different motion estimation schemes proposed in this chapter, we use the p fi 64 coder supplied by the Portable Video Research Group (PVRG) [45].
Reference: [39] <author> D. T. Hoang, P. M. Long, and J. S. Vitter. </author> <title> Efficient cost measures for motion compensation at low bit rates. </title> <booktitle> In Proceedings 1996 Data Compression Conference, </booktitle> <pages> pages 102-111, </pages> <address> Snowbird, Utah, </address> <month> March </month> <year> 1996. </year>
Reference-contexts: These heuristic coders give compression performance comparable to the explicit minimization coders while running much faster. Experimental results are presented in Sections 4.3.4 and 4.4.2. Preliminary descriptions of this work can be found in <ref> [37, 38, 39, 40] </ref>. 4.2 PVRG Implementation of H.261 As a basis for comparing the different motion estimation schemes proposed in this chapter, we use the p fi 64 coder supplied by the Portable Video Research Group (PVRG) [45].
Reference: [40] <author> D. T. Hoang, P. M. Long, and J. S. Vitter. </author> <title> Rate-distortion optimizations for motion estimation in low-bit-rate video coding. </title> <editor> In V. Bhaskaran, F. Sijstermans, and S. Panchanathan, editors, </editor> <title> Digital Video Compression: </title> <booktitle> Algorithms and Technologies 1996, </booktitle> <pages> pages 18-27, </pages> <year> 1996. </year> <booktitle> Proc. SPIE 2668. </booktitle> <pages> 159 </pages>
Reference-contexts: These heuristic coders give compression performance comparable to the explicit minimization coders while running much faster. Experimental results are presented in Sections 4.3.4 and 4.4.2. Preliminary descriptions of this work can be found in <ref> [37, 38, 39, 40] </ref>. 4.2 PVRG Implementation of H.261 As a basis for comparing the different motion estimation schemes proposed in this chapter, we use the p fi 64 coder supplied by the Portable Video Research Group (PVRG) [45].
Reference: [41] <author> P. G. Howard and J. S. Vitter. </author> <title> Practical implementations of arithmetic coding. </title> <editor> In J. A. Storer, editor, </editor> <booktitle> Images and Text Compression, </booktitle> <pages> pages 85-112. </pages> <publisher> Kluwer Academic Publishers, Norwell, </publisher> <address> MA, </address> <year> 1992. </year>
Reference: [42] <author> P. G. Howard and J. S. Vitter. </author> <title> Design and analysis of fast text compression based on quasi-arithmetic coding. </title> <journal> Journal of Information Processing and Management, </journal> <volume> 30(6) </volume> <pages> 777-790, </pages> <year> 1994. </year> <note> A shortened earlier version appears in Proceedings 1993 Data Compression Conference, Snowbird, UT, </note> <month> April </month> <year> 1993. </year>
Reference: [43] <author> C.-Y. Hsu, A. Ortega, and A. R. Reibman. </author> <title> Joint selection of source and channel rate for VBR video transmission under ATM policing constraints. </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <note> 1997. To appear. </note>
Reference-contexts: A heuristic pruning technique is proposed to reduce the number of states considered. However, the effectiveness of the heuristic depends upon the rate-distortion characteristics of the source. In <ref> [43] </ref>, the work of [79] is further extended to include transmission over a variable-bit-rate channel with delay constraints. Besides buffer and delay constraints, the authors also consider constraints imposed by several policing mechanisms proposed for ATM networks.
Reference: [44] <author> D. A. Huffman. </author> <title> A method for the construction of minimum redundancy codes. </title> <booktitle> Proceedings of the Institute of Radio Engineers, </booktitle> <volume> 40 </volume> <pages> 1098-1101, </pages> <year> 1952. </year>
Reference: [45] <author> A. C. Hung. PVRG-p64 codec 1.1, </author> <year> 1993. </year> <note> URL: ftp://havefun.stanford.edu/pub/p64. </note>
Reference-contexts: Preliminary descriptions of this work can be found in [37, 38, 39, 40]. 4.2 PVRG Implementation of H.261 As a basis for comparing the different motion estimation schemes proposed in this chapter, we use the p fi 64 coder supplied by the Portable Video Research Group (PVRG) <ref> [45] </ref>. The block diagram for a basic p fi 64 coder is shown in Figure 3.18. In the base PVRG implementation, a motion vector ~v is determined for each macroblock M using standard full-search block-matching.
Reference: [46] <author> T. Ibaraki and N. Katoh. </author> <title> Resource Allocation Problems. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1988. </year>
Reference-contexts: Instead, we would like to minimize the maximum Q i . Additionally, given that the maximum Q i is minimized, we want the second largest Q i to be as small as possible, and so on. This is referred to as lexicographic optimality in the literature (e.g., <ref> [46] </ref>). We define a sorted permutation DEC on Q s such that for DEC (Q s ) = hq j 1 ; q j 2 ; : : : ; q j N i, we have q j 1 q j 2 q j N .
Reference: [47] <author> ISO. Cd11172-2: </author> <title> Coding of moving pictures and associated audio for digital storage media at up to about 1.5 mbits/s, </title> <month> November </month> <year> 1991. </year>
Reference-contexts: In 1991, the MPEG committee completed its first international standard, MPEG-1 <ref> [47, 57] </ref>, formally ISO 11172. 56 As a generic video coding specification, MPEG-1 supports multiple image formats, including, CIF, SIF, and QCIF. Image sizes up to 4; 095 fi 4; 095 are supported. However, only progressive scan and 4:2:0 color subsampling are supported. <p> 4 Motion Estimation for Low-Bit-Rate Video Coding 4.1 Introduction As described in the previous chapter, hybrid video coding that combines block-matching motion compensation (BMMC) with transform coding of the residual is a popular scheme for video compression, adopted by international standards such as H.261 [8, 65] and the MPEG standards <ref> [47, 49, 57] </ref>. Motion compensation is a technique that exploits the typically strong correlation between successive frames of a video sequence by coding motion vectors that tell the decoder where to look on the previous frame for predictions of the intensity of each pixel in the current frame.
Reference: [48] <author> ISO-IEC/JTC1/SC29/WG11/N0400. </author> <title> Test model 5, </title> <month> April </month> <year> 1993. </year> <note> Document AVC-491b, Version 2. </note>
Reference-contexts: To allow for testing and experimentation using a common set of encoder routines, MPEG created a series of test models. Here, we describe the rate control strategy outlined in the MPEG-2 Test Model 5 (TM5) <ref> [48] </ref>. In TM5, rate control is broken down into three steps: 1. Target bit allocation. In this step, the complexity of the current picture is estimated based on the encoding of previous pictures to allocate a number of bits to code the picture. 2. Rate control. <p> We propose to compute Q at the picture level; that is, we compute one Q for each picture to be coded. Besides decreasing the computation over computing different Q for each block, this method 1 The MPEG-2 Test Model 5 <ref> [48] </ref> also uses a multiplicative formulation while an additive formulation is proposed in [84]. results in constant perceptual quality within each picture given that perceptual quantization is employed at the block level.
Reference: [49] <author> ISO-IEC/JTC1/SC29/WG11/N0802. </author> <title> Generic coding of moving pictures and associated audio information: Video, </title> <month> November </month> <year> 1994. </year> <note> MPEG Draft Recommendation ITU-T H.262, ISO/IEC 13818-2. </note>
Reference-contexts: However, only progressive scan and 4:2:0 color subsampling are supported. While MPEG-1 proved successful for the computer entertainment industry, its lack of support for interlaced scan prevented its use in digital television. In 1990, the MPEG committee started work on MPEG-2 <ref> [49] </ref>, formally ISO 13818. MPEG-2 is an extension of MPEG-1 that remedies several major shortcomings of MPEG-1 by adding support for interlaced video, more color subsampling formats, and other advanced coding features. To leverage existing MPEG-1 titles and to promote its adoption, MPEG-2 retains backward compatibility with MPEG-1. <p> 4 Motion Estimation for Low-Bit-Rate Video Coding 4.1 Introduction As described in the previous chapter, hybrid video coding that combines block-matching motion compensation (BMMC) with transform coding of the residual is a popular scheme for video compression, adopted by international standards such as H.261 [8, 65] and the MPEG standards <ref> [47, 49, 57] </ref>. Motion compensation is a technique that exploits the typically strong correlation between successive frames of a video sequence by coding motion vectors that tell the decoder where to look on the previous frame for predictions of the intensity of each pixel in the current frame.
Reference: [50] <author> J. R. Jain and A. K. Jain. </author> <title> Displacement measurement and its application in interframe coding. </title> <journal> IEEE Transactions on Communications, </journal> <volume> COM-29(12):1799-1808, </volume> <year> 1981. </year>
Reference-contexts: In the final step, indicated in Figure 3.13, the prediction error that results from motion compensation is coded with an intraframe coder, for instance, one of the techniques mentioned in Section 3.4. 3.5.3 Block-Matching A motion model that is commonly used is the block-translation model developed by Jain and Jain <ref> [50] </ref>. In this model, an image is divided into non-overlapping rectangular blocks. Each block in the predicted image is formed by a translation of a similarly shaped source region from the reference frame. The source region needs not coincide with the block boundaries. <p> In previous work on BMMC, motion vectors are typically chosen to minimize prediction error, and much of the emphasis has been on speeding up the motion search <ref> [50, 55, 88, 100] </ref>. However, for low bit-rate applications, the coding of motion vectors takes up a significant portion of the bandwidth, as evidenced with a coding experiment summarized in Table 4.1 and Figure 4.1. This observation has previously been made in [58]. <p> Preliminary experimental results suggest that a quadtree-based technique may be suitable for video coding at rates below that achievable by the p fi 64 standard. 1 In fact, a heuristic search <ref> [50, 55] </ref> was used to only approximately minimize the error. 90 While only the bit-minimization strategy has been examined for the quadtree-based coder, the heuristic cost function of Chapter 4 can certainly be used to speed up the operation of the coder. 91 92 Chapter 6 Lexicographically Optimal Bit Allocation In
Reference: [51] <author> D. Jamison and K. Jamison. </author> <title> A note on the entropy of partially-known languages. </title> <journal> Information and Control, </journal> <volume> 12 </volume> <pages> 164-167, </pages> <year> 1968. </year>
Reference: [52] <author> N. S. Jayant, J. Johnson, and R. Safranek. </author> <title> Signal compression based on models of human perception. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 81 </volume> <pages> 1385-1422, </pages> <month> October </month> <year> 1993. </year>
Reference-contexts: These studies lead to various techniques, called perceptual quantization or adaptive perceptual quantization, that take into account properties of the Human Visual System (HVS) in determining the quantization scale <ref> [104, 86, 52, 16, 60, 108, 18] </ref>.
Reference: [53] <author> R. S. Klein, H. Luss, and D. R. Smith. </author> <title> Lexicographic minimax algorithm for multiperiod resource allocation. </title> <journal> Mathematical Programming, </journal> <volume> 55(2) </volume> <pages> 213-234, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: Assuming a stationary Gaussian process, the authors derive a bit-production model containing transcendental functions. The model is applied to control the frame rate of motion-JPEG and H.261 video coders. In the operations research literature, lexicographic optimality has been applied to such problems as resource location and allocation (e.g., <ref> [31, 53, 66, 68, 77, 85] </ref>) and is sometimes referred to as lexicographic minimax , since it can be viewed as a refinement of minimax theory. 6.8 Discussion As described above, much of the previous work on optimal rate control for video coding use the conventional rate-distortion approach of minimizing a
Reference: [54] <author> D. Knuth. </author> <title> The Art of Computer Programming, Volume 3: Sorting and Searching. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1973. </year>
Reference: [55] <author> T. Koga, K. Iinuma, A. Hirano, Y. Iijima, and T. Ishiguro. </author> <title> Motion-compensated interframe coding for video conferencing. </title> <booktitle> In Proceedings IEEE National Telecommunication Conference, </booktitle> <volume> volume 4, </volume> <pages> pages G5.3.1-G5.3.5, </pages> <month> November </month> <year> 1981. </year> <month> 160 </month>
Reference-contexts: In previous work on BMMC, motion vectors are typically chosen to minimize prediction error, and much of the emphasis has been on speeding up the motion search <ref> [50, 55, 88, 100] </ref>. However, for low bit-rate applications, the coding of motion vectors takes up a significant portion of the bandwidth, as evidenced with a coding experiment summarized in Table 4.1 and Figure 4.1. This observation has previously been made in [58]. <p> Preliminary experimental results suggest that a quadtree-based technique may be suitable for video coding at rates below that achievable by the p fi 64 standard. 1 In fact, a heuristic search <ref> [50, 55] </ref> was used to only approximately minimize the error. 90 While only the bit-minimization strategy has been examined for the quadtree-based coder, the heuristic cost function of Chapter 4 can certainly be used to speed up the operation of the coder. 91 92 Chapter 6 Lexicographically Optimal Bit Allocation In
Reference: [56] <author> G. G. Langdon. </author> <title> A note on the ziv-lempel model for compressing individual sequences. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> IT-29:284-287, </volume> <month> March </month> <year> 1983. </year>
Reference: [57] <author> D. J. LeGall. </author> <title> MPEG: A video compression standard for multimedia applications. </title> <journal> Communications of the ACM, </journal> <volume> 34(4) </volume> <pages> 46-58, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: In 1991, the MPEG committee completed its first international standard, MPEG-1 <ref> [47, 57] </ref>, formally ISO 11172. 56 As a generic video coding specification, MPEG-1 supports multiple image formats, including, CIF, SIF, and QCIF. Image sizes up to 4; 095 fi 4; 095 are supported. However, only progressive scan and 4:2:0 color subsampling are supported. <p> 4 Motion Estimation for Low-Bit-Rate Video Coding 4.1 Introduction As described in the previous chapter, hybrid video coding that combines block-matching motion compensation (BMMC) with transform coding of the residual is a popular scheme for video compression, adopted by international standards such as H.261 [8, 65] and the MPEG standards <ref> [47, 49, 57] </ref>. Motion compensation is a technique that exploits the typically strong correlation between successive frames of a video sequence by coding motion vectors that tell the decoder where to look on the previous frame for predictions of the intensity of each pixel in the current frame.
Reference: [58] <author> H. Li, A. Lundmark, and R. Forchheimer. </author> <title> Image sequence coding at very low bitrates: A review. </title> <journal> IEEE Transactions on Image Processing, </journal> <volume> 3(5) </volume> <pages> 589-609, </pages> <month> September </month> <year> 1994. </year>
Reference-contexts: However, for low bit-rate applications, the coding of motion vectors takes up a significant portion of the bandwidth, as evidenced with a coding experiment summarized in Table 4.1 and Figure 4.1. This observation has previously been made in <ref> [58] </ref>. In this chapter, we investigate the use of cost measures that take into account the effects of the choice of motion vector on rate and distortion. We first develop and present computationally intensive coders that attempt explicitly to optimize for rate and distortion.
Reference: [59] <author> D. W. Lin and J.-J. Chen. </author> <title> Efficient bit allocation under multiple constraints on cumulated rates for delayed video coding. </title> <editor> In J. Biemond and E. J. Delp, editors, </editor> <booktitle> Visual Communications and Image Processing '97, </booktitle> <pages> pages 1370-1381, </pages> <month> February </month> <year> 1997. </year> <booktitle> Proc. SPIE 3024. </booktitle>
Reference-contexts: If we store pointers for tracing the optimal sequence of concatenations, the algorithm requires O (N ) space. 7.3 Related Work Conditions similar to the switching conditions of Theorem 7.1 have been described in <ref> [59] </ref> for optimal buffered bit allocation under a minimum sum-distortion criterion and assuming independent convex rate-distortion functions. In this work, the Lagrange multiplier method is used to find a bit allocation that is optimal within a convex-hull approximation.
Reference: [60] <author> F.-H. Lin and R. M. Mersereau. </author> <title> An optimization of MPEG to maximize subjective quality. </title> <booktitle> In Proceedings ICIP'95, </booktitle> <volume> volume 2, </volume> <pages> pages 547-550, </pages> <year> 1995. </year>
Reference-contexts: These studies lead to various techniques, called perceptual quantization or adaptive perceptual quantization, that take into account properties of the Human Visual System (HVS) in determining the quantization scale <ref> [104, 86, 52, 16, 60, 108, 18] </ref>.
Reference: [61] <author> L.-J. Lin, A. Ortega, and C.-C. J. Kuo. </author> <title> Gradient-based buffer control techniques for MPEG. </title> <booktitle> In Proceedings VCIP'95, </booktitle> <address> Taipei, Taiwan, </address> <month> May </month> <year> 1995. </year>
Reference-contexts: Lin, Ortega, and Kuo [64, 63] propose using cubic-spline interpolation models of rate and distortion in conjunction with a gradient-based rate control algorithm <ref> [61, 62] </ref>. The spline models are computed by first encoding each picture several times using a select set of M quantization scales, fx 1 , x 2 , : : :, x M g with x 1 &lt; x 2 &lt; &lt; x M , and measuring the actual rate. <p> For picture i, the function between two consecutive control points (x k ; y i;k ) and (x k+1 ; y i;k+1 ) has the form f k As in <ref> [61, 62] </ref>, we choose the control quantization scales to be f1, 2, 3, 5, 8, 13, 21, 31g to exploit the exponential-decay property of rate-distortion functions. In case the control points themselves do not exhibit monotonicity, we enforce monotonicity by skipping those control points where the monotonicity property is violated. <p> In [12], an adaptive tree-structured piecewise linear bit-production model is proposed and applied to MPEG video coding using a one-pass encoding strategy. A cubic-spline model of rate and distortion is proposed in [64, 63] for use with a gradient-based rate-control algorithm <ref> [61, 62] </ref> that attempts to minimize MSE. The model takes into account the temporal dependencies introduced by predictive coding. 147 9.8 Discussion In this chapter, we have described an implementation of the bit allocation algorithms of Chapters 7 and 8 within an MPEG-2 software encoder.
Reference: [62] <author> L.-J. Lin, A. Ortega, and C.-C. J. Kuo. </author> <title> A gradient-based rate control algorithm with applications to MPEG video. </title> <booktitle> In Proceedings ICIP'95, </booktitle> <address> Washington, D.C., </address> <month> October </month> <year> 1995. </year>
Reference-contexts: Lin, Ortega, and Kuo [64, 63] propose using cubic-spline interpolation models of rate and distortion in conjunction with a gradient-based rate control algorithm <ref> [61, 62] </ref>. The spline models are computed by first encoding each picture several times using a select set of M quantization scales, fx 1 , x 2 , : : :, x M g with x 1 &lt; x 2 &lt; &lt; x M , and measuring the actual rate. <p> For picture i, the function between two consecutive control points (x k ; y i;k ) and (x k+1 ; y i;k+1 ) has the form f k As in <ref> [61, 62] </ref>, we choose the control quantization scales to be f1, 2, 3, 5, 8, 13, 21, 31g to exploit the exponential-decay property of rate-distortion functions. In case the control points themselves do not exhibit monotonicity, we enforce monotonicity by skipping those control points where the monotonicity property is violated. <p> In [12], an adaptive tree-structured piecewise linear bit-production model is proposed and applied to MPEG video coding using a one-pass encoding strategy. A cubic-spline model of rate and distortion is proposed in [64, 63] for use with a gradient-based rate-control algorithm <ref> [61, 62] </ref> that attempts to minimize MSE. The model takes into account the temporal dependencies introduced by predictive coding. 147 9.8 Discussion In this chapter, we have described an implementation of the bit allocation algorithms of Chapters 7 and 8 within an MPEG-2 software encoder.
Reference: [63] <author> L.-J. Lin, A. Ortega, and C.-C. J. Kuo. </author> <title> Cubic spline approximation of rate and distortion functions for MPEG video. </title> <editor> In V. Bhaskaran, F. Sijstermans, and S. Panchanathan, editors, </editor> <title> Digital Video Compression: </title> <booktitle> Algorithms and Technologies 1996, </booktitle> <pages> pages 169-180, </pages> <year> 1996. </year> <booktitle> Proc. SPIE 2668. </booktitle>
Reference-contexts: We now consider a different approach where more effort is expended to construct more accurate bit models that are then used to encode the video sequence in a single pass. Lin, Ortega, and Kuo <ref> [64, 63] </ref> propose using cubic-spline interpolation models of rate and distortion in conjunction with a gradient-based rate control algorithm [61, 62]. <p> Since there are a fixed number of control points, we can compute G i;j in constant time with linear-time preprocessing. As with the hyperbolic model, we can compute optimal CBR and VBR allocations in quadratic time. The cubic-spline model of <ref> [64, 63] </ref> is used in a dependent-coding framework, where the effects of coding previous pictures are taken into account in the modeling. Our framework assumes 132 independent coding and does not take these effects into account. <p> The model is applied for VBR coding with motion JPEG and H.261 coders. In [12], an adaptive tree-structured piecewise linear bit-production model is proposed and applied to MPEG video coding using a one-pass encoding strategy. A cubic-spline model of rate and distortion is proposed in <ref> [64, 63] </ref> for use with a gradient-based rate-control algorithm [61, 62] that attempts to minimize MSE.
Reference: [64] <author> L.-J. Lin, A. Ortega, and C.-C. J. Kuo. </author> <title> Rate control using spline-interpolated R-D characteristics. </title> <booktitle> In Proceedings VCIP'96, </booktitle> <year> 1996. </year>
Reference-contexts: We now consider a different approach where more effort is expended to construct more accurate bit models that are then used to encode the video sequence in a single pass. Lin, Ortega, and Kuo <ref> [64, 63] </ref> propose using cubic-spline interpolation models of rate and distortion in conjunction with a gradient-based rate control algorithm [61, 62]. <p> Since there are a fixed number of control points, we can compute G i;j in constant time with linear-time preprocessing. As with the hyperbolic model, we can compute optimal CBR and VBR allocations in quadratic time. The cubic-spline model of <ref> [64, 63] </ref> is used in a dependent-coding framework, where the effects of coding previous pictures are taken into account in the modeling. Our framework assumes 132 independent coding and does not take these effects into account. <p> The model is applied for VBR coding with motion JPEG and H.261 coders. In [12], an adaptive tree-structured piecewise linear bit-production model is proposed and applied to MPEG video coding using a one-pass encoding strategy. A cubic-spline model of rate and distortion is proposed in <ref> [64, 63] </ref> for use with a gradient-based rate-control algorithm [61, 62] that attempts to minimize MSE.
Reference: [65] <author> M. Liou. </author> <title> Overview of the p fi 64 kbit/s video coding standard. </title> <journal> Communications of the ACM, </journal> <volume> 34(4) </volume> <pages> 60-63, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: its simplicity, block-matching is commonly used with current video coding standards. 3.6 H.261 Standard In 1990, the International Telegraph and Telephone Consultative Committee (CCITT) 5 approved an international standard for video coding at bit rates of p fi 64 kbits/sec, where p is an integer between 1 and 30, inclusive <ref> [8, 65] </ref>. Officially known as CCITT Recommendation H.261, it is informally called the pfi64 standard and is intended for low-bit-rate applications such as videophone and videoconferencing. <p> not for VBR. 63 64 Chapter 4 Motion Estimation for Low-Bit-Rate Video Coding 4.1 Introduction As described in the previous chapter, hybrid video coding that combines block-matching motion compensation (BMMC) with transform coding of the residual is a popular scheme for video compression, adopted by international standards such as H.261 <ref> [8, 65] </ref> and the MPEG standards [47, 49, 57].
Reference: [66] <author> M. Luptacik and F. Turnovec. </author> <title> Lexicographic geometric programming. </title> <journal> European Journal of Operational Research, </journal> <volume> 51(2) </volume> <pages> 259-269, </pages> <month> March </month> <year> 1991. </year>
Reference-contexts: Assuming a stationary Gaussian process, the authors derive a bit-production model containing transcendental functions. The model is applied to control the frame rate of motion-JPEG and H.261 video coders. In the operations research literature, lexicographic optimality has been applied to such problems as resource location and allocation (e.g., <ref> [31, 53, 66, 68, 77, 85] </ref>) and is sometimes referred to as lexicographic minimax , since it can be viewed as a refinement of minimax theory. 6.8 Discussion As described above, much of the previous work on optimal rate control for video coding use the conventional rate-distortion approach of minimizing a
Reference: [67] <author> H. Luss and S. K. Gupta. </author> <title> Allocation of effort resources among competitive activities. </title> <journal> Operations Research, </journal> <volume> 23 </volume> <pages> 360-366, </pages> <year> 1975. </year>
Reference-contexts: Examples of other functional forms for f i with a closed-form solution for G i;j can be found in <ref> [67] </ref>. Of course, we need to insure that the models are monotonically decreasing. Since VBV verification and constant-Q calculation can be done in constant time with linear-time preprocessing, computing Top k and Bot k takes O (k) time.
Reference: [68] <author> E. Marchi and J. A. Oviedo. </author> <title> Lexicographic optimality in the multiple objective linear programming. The nucleolar solution. </title> <journal> European Journal of Operational Research, </journal> <volume> 57(3) </volume> <pages> 355-359, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: Assuming a stationary Gaussian process, the authors derive a bit-production model containing transcendental functions. The model is applied to control the frame rate of motion-JPEG and H.261 video coders. In the operations research literature, lexicographic optimality has been applied to such problems as resource location and allocation (e.g., <ref> [31, 53, 66, 68, 77, 85] </ref>) and is sometimes referred to as lexicographic minimax , since it can be viewed as a refinement of minimax theory. 6.8 Discussion As described above, much of the previous work on optimal rate control for video coding use the conventional rate-distortion approach of minimizing a
Reference: [69] <author> A. W. Marshall and I. Olkin. </author> <title> Inequalities: Theory of Majorization and its Applications. </title> <publisher> Academic Press, </publisher> <year> 1979. </year>
Reference-contexts: In this work, the Lagrange multiplier method is used to find a bit allocation that is optimal within a convex-hull approximation. The optimal vector of Lagrange multipliers consists of constant-valued segments that increase (decrease, respectively) only when the decoder buffer is full (empty). In [94], the theory of majorization <ref> [69] </ref> is applied to reduce the variability in transmission rate for stored video. In this setting, the problem is to determine a feasible transmission schedule by which a pre-compressed video bitstream can be transmitted over a communications channel to the decoder without underflowing or overflowing the decoder buffer.
Reference: [70] <author> J. L. Mitchell and W. B. Pennebaker. </author> <title> Optimal hardware and software arithmetic coding procedures for the Q-Coder. </title> <journal> IBM Journal of Research and Development, </journal> <volume> 32 </volume> <pages> 727-736, </pages> <month> November </month> <year> 1988. </year>
Reference: [71] <author> J. L. Mitchell, W. B. Pennebaker, C. E. Fogg, and D. J. LeGall, </author> <title> editors. MPEG Video Compression Standard. </title> <publisher> Chapman & Hall, </publisher> <address> New York, NY, </address> <year> 1997. </year>
Reference-contexts: Next, we describe existing international standards for video coding and present an overview of the fundamentals of these standards. This chapter is by no means intended to be comprehensive; for an in-depth introduction to video coding fundamentals, the reader is referred to <ref> [4, 34, 71, 76] </ref>. 3.1 Digital Video Representation For compression to be meaningful, a standard representation should be defined for the data to be compressed. <p> It is not clear whether this work can be extended to lossy coding since distortion is not taken into account in the formulation. 83 A linear relationship between MAD and both rate and distortion has been independently ob-served in <ref> [71] </ref>.
Reference: [72] <author> A. M. Moffat. </author> <title> Implementing the ppm data compression scheme. </title> <journal> IEEE Transactions on Communication, </journal> <volume> COMM-38:1917-1921, </volume> <month> November </month> <year> 1990. </year>
Reference: [73] <author> D. R. Morrison. </author> <title> PATRICIA|A practical algorithm to retrieve information coded in alphanumeric. </title> <journal> Journal of the ACM, </journal> <volume> 15 </volume> <pages> 514-534, </pages> <year> 1968. </year>
Reference: [74] <institution> MPEG Software Simulation Group. </institution> <note> MPEG-2 encoder/decoder version 1.1a, July 4, 1994. URL: http://www.mpeg.org/MSSG. </note>
Reference-contexts: sub-optimal, the resulting coder would have complexity comparable to existing CBR coders. 128 Chapter 9 Implementation of Lexicographic Bit Allocation In this chapter, we describe an implementation of rate control using the lexicographically optimal bit allocation algorithms presented in Chapters 7 and 8 within a publicly available software MPEG-2 encoder <ref> [74] </ref>. <p> To simulate scene changes, we concatenated the four short video clips into a 418-picture video sequence in the following order: flower garden, mobile, football, table tennis. We implemented the rate control algorithms within the software encoder provided by the MPEG-2 Simulation Group <ref> [74] </ref>. The coding parameters are listed in Table 9.1. For CBR mode, we specified a peak bit rate of 1.0 Mbits/sec. For VBR, we used an average bit rate of 1.0 Mbits/sec and a peak bit rate of 1.2 Mbits/sec. The VBV buffer size was set to 720,896 bits.
Reference: [75] <author> Y. Nakano, H. Yahagi, Y. Okada, and S. Yoshida. </author> <title> Highly efficient universal coding with classifying to subdictionaries for text compression. </title> <booktitle> In Proceedings 1994 Data Compression Conference, </booktitle> <pages> pages 234-243, </pages> <address> Snowbird, UT, March 1994. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference: [76] <author> A. N. Netravali and B. G. </author> <title> Haskell. Digital Pictures: Representation, Compression, and Standards. </title> <publisher> Plenum Press, </publisher> <address> second edition, </address> <year> 1995. </year>
Reference-contexts: Next, we describe existing international standards for video coding and present an overview of the fundamentals of these standards. This chapter is by no means intended to be comprehensive; for an in-depth introduction to video coding fundamentals, the reader is referred to <ref> [4, 34, 71, 76] </ref>. 3.1 Digital Video Representation For compression to be meaningful, a standard representation should be defined for the data to be compressed. <p> This technique is called frame differencing and is an 48 previously decoded frame which is used to compute a difference frame. extension of the basic differential pulse code modulation (DPCM) coding techniques (see, e.g. <ref> [76] </ref>). A block diagram of an encoder that uses frame differencing is shown in Figure 3.12. If there is little motion between successive frames, frame differencing yields a difference image that is mostly uniform and can be coded efficiently.
Reference: [77] <author> W. Ogryczak. </author> <title> On the lexicographic minimax approach to location-allocation problems. </title> <type> Technical Report IS - MG 94/22, </type> <institution> Universite Libre de Bruxelles, </institution> <month> December </month> <year> 1994. </year>
Reference-contexts: Assuming a stationary Gaussian process, the authors derive a bit-production model containing transcendental functions. The model is applied to control the frame rate of motion-JPEG and H.261 video coders. In the operations research literature, lexicographic optimality has been applied to such problems as resource location and allocation (e.g., <ref> [31, 53, 66, 68, 77, 85] </ref>) and is sometimes referred to as lexicographic minimax , since it can be viewed as a refinement of minimax theory. 6.8 Discussion As described above, much of the previous work on optimal rate control for video coding use the conventional rate-distortion approach of minimizing a
Reference: [78] <author> L. A. Olzak and J. P. Thomas. </author> <title> Seeing spatial patterns. </title> <editor> In K. Boff, L. Kaufman, and J. Thomas, editors, </editor> <booktitle> Handbook of Perception and Human Performance. </booktitle> <publisher> Wiley, </publisher> <year> 1986. </year>
Reference-contexts: Both of these factors depend upon the scene content as well. Studies into human visual perception suggest that perceptual distortion is correlated to certain spatial (and temporal) properties of an image (video sequence) <ref> [78, 1] </ref>. These studies lead to various techniques, called perceptual quantization or adaptive perceptual quantization, that take into account properties of the Human Visual System (HVS) in determining the quantization scale [104, 86, 52, 16, 60, 108, 18].
Reference: [79] <author> A. Ortega, K. Ramchandran, and M. Vetterli. </author> <title> Optimal buffer-constrained source quantization and fast approximations. </title> <booktitle> In Proceedings 1992 International Symposium on Circuits and Systems, </booktitle> <pages> pages 192-195, </pages> <address> San Diego, CA, </address> <month> May </month> <year> 1992. </year>
Reference-contexts: The constraints take into account both the encoder and decoder buffers. The bit-rate constraints are used in an ad-hoc algorithm that jointly selects the channel and encoder rates. The problem of optimal bit allocation in a buffered video coder is considered in <ref> [79] </ref>. The authors consider video coding with CBR buffer constraints and formulate bit allocation as an integer programming problem. They assume a finite set of quantization scales, an integral number of coded bits, and independent coding. <p> The problem is optimally solved using a dynamic programming algorithm based upon the Viterbi algorithm (as described in Section 3.3.3a). Heuristic methods based upon Lagrangian minimization and other ad-hoc techniques are proposed to provide more efficient, but sub-optimal, solutions. The discrete optimization framework of <ref> [79] </ref> is extended in [89] to handle dependent coding. Except for a simple illustrative case, computing an optimal bit allocation under the dependent framework requires time and space exponential in the number of coding units. A heuristic pruning technique is proposed to reduce the number of states considered. <p> A heuristic pruning technique is proposed to reduce the number of states considered. However, the effectiveness of the heuristic depends upon the rate-distortion characteristics of the source. In [43], the work of <ref> [79] </ref> is further extended to include transmission over a variable-bit-rate channel with delay constraints. Besides buffer and delay constraints, the authors also consider constraints imposed by several policing mechanisms proposed for ATM networks. <p> In Chapter 10, we describe some extensions to the lexicographic framework. We show how to apply the framework to allocate bits to multiple VBR streams for transport over a CBR channel. We also show how to adapt the discrete framework of <ref> [79] </ref> to perform lexicographic optimization. 5 This is similar to the nominal quantization scale defined in Section 6.1. 103 104 Chapter 7 Lexicographic Bit Allocation under CBR Constraints In this chapter, we analyze the buffer-constrained bit-allocation problem under constant-bit-rate VBV constraints, as described in Section 6.4.1. <p> As with hybrid rate control, reverse dynamic programming can be used to speed up the reallocation. 146 (a) TM5 CBR (b) Linear-Spline CBR (c) Linear-Spline VBR 9.7 Related Work A suite of heuristic methods is proposed in <ref> [79] </ref> to reduce the complexity as compared to an optimal bit allocation based on the Viterbi algorithm. A Lagrangian optimization technique is applied to recompute an allocation incrementally for each picture, similar to technique described in Section 9.3.2. In addition, the Lagrangian optimization is performed with a finite window size.
Reference: [80] <author> A. Ortega, K. Ramchandran, and M. Vetterli. </author> <title> Optimal trellis-based buffered compression and fast approximations. </title> <journal> IEEE Transactions on Image Processing, </journal> <volume> 3(1) </volume> <pages> 26-40, </pages> <month> January </month> <year> 1994. </year>
Reference-contexts: framework can certainly be generalized to other coding units, and in principle can be applied to code other types of data, such as images and speech. 6.2 Constant Quality Previous approaches in optimal rate control generally seeks to minimize a distortion measure, typically mean-squared error (MSE), averaged over coding blocks <ref> [80, 90] </ref>. While this approach leverages the wealth of tools from optimization theory and operations research, it does not guarantee the constancy of quality that is generally desired from a video coding system. <p> In related work, a buffered rate control scheme for multiplexing VBR sources onto a CBR channel is described in [81]. This work is based on the rate-distortion framework of <ref> [80] </ref> and [13] and uses a multiplexing model very similar to the one we are about to present. As described in the paper, the basic allocation unit is taken to be a GOP. 10.2.2 Multiplexing Model We first elaborate a model for multiplexing multiple VBR bitstreams onto a CBR channel. <p> In most practical coders, however, both the set of available quantizers and the number of bits produced are discrete and finite. The problem of buffer-constrained bit allocation under these conditions have been examined by Ortega, Ramchandran, and Vetterli <ref> [80] </ref>. They provide a dynamic programming algorithm to find a CBR allocation that minimizes a sum-distortion metric. In this section, we briefly describe their algorithm and show how it can be readily extended to perform lexicographic minimization. 10.3.1 Dynamic Programming The dynamic programming algorithm described in [80] is based on the <p> Ortega, Ramchandran, and Vetterli <ref> [80] </ref>. They provide a dynamic programming algorithm to find a CBR allocation that minimizes a sum-distortion metric. In this section, we briefly describe their algorithm and show how it can be readily extended to perform lexicographic minimization. 10.3.1 Dynamic Programming The dynamic programming algorithm described in [80] is based on the Viterbi algorithm outlined in Section 3.3.3a for solving the budget-constrained bit allocation problem. <p> Since an integral number of bits is generated, the maximum number of states that can be generated at each stage is equal to the size of the buffer. Therefore, with M quantizers, N pictures, and a buffer of size B, the dynamic programming algorithm of <ref> [80] </ref> requires O (M BN ) time to compute an optimal bit allocation. 10.3.2 Lexicographic Extension It is straightforward to modify the dynamic programming algorithm of [80] to perform lexicographic minimization. <p> Therefore, with M quantizers, N pictures, and a buffer of size B, the dynamic programming algorithm of <ref> [80] </ref> requires O (M BN ) time to compute an optimal bit allocation. 10.3.2 Lexicographic Extension It is straightforward to modify the dynamic programming algorithm of [80] to perform lexicographic minimization. Instead of keeping track of a minimum sum distortion value, a scalar, we keep track of a lexicographic minimum, a vector.
Reference: [81] <author> D. Park and K. Kim. </author> <title> Buffered rate-distortion control of MPEG compressed video channel for DBS applications. </title> <booktitle> In Proceedings IEEE Internation Conference on Communications, </booktitle> <volume> volume 3, </volume> <pages> pages 1751-1755, </pages> <year> 1995. </year>
Reference-contexts: In related work, a buffered rate control scheme for multiplexing VBR sources onto a CBR channel is described in <ref> [81] </ref>. This work is based on the rate-distortion framework of [80] and [13] and uses a multiplexing model very similar to the one we are about to present.
Reference: [82] <author> W. B. Pennebaker, J. L. Mitchell, G. G. Langdon, and R. B. </author> <title> Arps. An overview of the basic principles of the q-coder adaptive binary arithmetic coder. </title> <journal> IBM Journal of Research and Development, </journal> <volume> 32(6) </volume> <pages> 717-726, </pages> <month> November </month> <year> 1988. </year>
Reference: [83] <author> W.B. Pennebaker and J. L. Mitchell. </author> <title> JPEG|Still Image Data Compression Standard. </title> <publisher> Van Nostrand Reinhold, </publisher> <address> New York, </address> <year> 1993. </year>
Reference-contexts: However, with block transforms, decoding has approximately the same complexity as encoding, which is more complex than decoding with vector quantization. 3.4.3 Discrete Cosine Transform For images, the two-dimensional discrete cosine transform (2D-DCT) is a popular block transform that forms the basis of the lossy JPEG standard <ref> [83] </ref> developed by the Joint Photographic Experts Group. Because of its success within JPEG, the 2D-DCT has been adopted by many video coding standards as well. <p> Obvious examples include lossy image coding (such as specified by the JPEG standard <ref> [83] </ref>), where the coding unit would logically be a block of pixels, and audio coding, where a coding unit might correspond to half a second of sampled sound. 10.2 Multiplexing VBR Streams over a CBR Channel 10.2.1 Introduction There are many scenarios where multiple compressed video streams are to be transmitted
Reference: [84] <author> M. R. Pickering and J. F. Arnold. </author> <title> A perceptually efficient VBR rate control algorithm. </title> <journal> IEEE Transactions on Image Processing, </journal> <volume> 3(5) </volume> <pages> 527-532, </pages> <month> September </month> <year> 1994. </year>
Reference-contexts: Besides decreasing the computation over computing different Q for each block, this method 1 The MPEG-2 Test Model 5 [48] also uses a multiplicative formulation while an additive formulation is proposed in <ref> [84] </ref>. results in constant perceptual quality within each picture given that perceptual quantization is employed at the block level.
Reference: [85] <author> A. Premoli and W. Ukovich. </author> <title> Piecewise lexicographic programming. A new model for practical decision problems. </title> <journal> Journal of Optimization Theory and Applications, </journal> <volume> 72(1) </volume> <pages> 113-142, </pages> <month> January </month> <year> 1992. </year>
Reference-contexts: Assuming a stationary Gaussian process, the authors derive a bit-production model containing transcendental functions. The model is applied to control the frame rate of motion-JPEG and H.261 video coders. In the operations research literature, lexicographic optimality has been applied to such problems as resource location and allocation (e.g., <ref> [31, 53, 66, 68, 77, 85] </ref>) and is sometimes referred to as lexicographic minimax , since it can be viewed as a refinement of minimax theory. 6.8 Discussion As described above, much of the previous work on optimal rate control for video coding use the conventional rate-distortion approach of minimizing a
Reference: [86] <author> A. Puri and R. Aravind. </author> <title> Motion-compensated video coding with adaptive perceptual quan-tization. </title> <journal> IEEE Transactions on Circuits and Systems for Video Technology, </journal> <volume> 1(4) </volume> <pages> 351-361, </pages> <month> December </month> <year> 1991. </year>
Reference-contexts: These studies lead to various techniques, called perceptual quantization or adaptive perceptual quantization, that take into account properties of the Human Visual System (HVS) in determining the quantization scale <ref> [104, 86, 52, 16, 60, 108, 18] </ref>.
Reference: [87] <author> A. Puri and H.-M. Hang. </author> <title> Adaptive schemes for motion-compensated coding. </title> <booktitle> SPIE Vol. 1001 Visual Communications and Image Processing, </booktitle> <pages> pages 925-935, </pages> <year> 1988. </year>
Reference-contexts: Potentially better results can be achieved by directly exploiting the two-dimensional correlation of motion vectors. A quadtree data structure can be used for this purpose by representing the motion field hierarchically in two dimensions <ref> [87, 5, 9, 24] </ref>. The quadtree approach works by identifying variable-sized regions of uniform motion and providing an efficient encoding of the motion field. <p> The quadtree coder gives better rate-distortion performance for rates under about 0.25 bits/pixel. Furthermore, the range of achievable rates is extended to well below the 0.05 bits/pixel achievable with M2, albeit with higher distortion. 5.4 Previous Work Puri and Hang <ref> [87] </ref> considered an algorithm for motion-compensated video coding which, when an 8 fi 8 block B is not coded well (that is, when coding it requires a lot of bits), chooses a separate motion vector for each of B's four 4 fi 4 subblocks.
Reference: [88] <author> A. Puri, H.-M. Hang, and D. L. Schilling. </author> <title> An efficient block-matching algorithm for motion compensated coding. </title> <booktitle> In Proceedings 1987 International Conference on Acoustics, Speech and Signal Processing, </booktitle> <pages> pages 25.4.1-25.4.4, </pages> <year> 1987. </year>
Reference-contexts: In previous work on BMMC, motion vectors are typically chosen to minimize prediction error, and much of the emphasis has been on speeding up the motion search <ref> [50, 55, 88, 100] </ref>. However, for low bit-rate applications, the coding of motion vectors takes up a significant portion of the bandwidth, as evidenced with a coding experiment summarized in Table 4.1 and Figure 4.1. This observation has previously been made in [58].
Reference: [89] <author> K. Ramchandran, A. Ortega, and M. Vetterli. </author> <title> Bit allocation for dependent quantization with applications to MPEG video coders. </title> <booktitle> In Proceedings 1993 International Conference on Acoustics, Speech and Signal Processing, </booktitle> <volume> volume 5, </volume> <pages> pages 381-384, </pages> <year> 1993. </year>
Reference-contexts: The problem is optimally solved using a dynamic programming algorithm based upon the Viterbi algorithm (as described in Section 3.3.3a). Heuristic methods based upon Lagrangian minimization and other ad-hoc techniques are proposed to provide more efficient, but sub-optimal, solutions. The discrete optimization framework of [79] is extended in <ref> [89] </ref> to handle dependent coding. Except for a simple illustrative case, computing an optimal bit allocation under the dependent framework requires time and space exponential in the number of coding units. A heuristic pruning technique is proposed to reduce the number of states considered.
Reference: [90] <author> K. Ramchandran, A. Ortega, and M. Vetterli. </author> <title> Bit allocation for dependent quantization with applications to multiresolution and MPEG video coders. </title> <journal> IEEE Transactions on Image Processing, </journal> <volume> 3(5) </volume> <pages> 533-545, </pages> <month> September </month> <year> 1994. </year>
Reference-contexts: framework can certainly be generalized to other coding units, and in principle can be applied to code other types of data, such as images and speech. 6.2 Constant Quality Previous approaches in optimal rate control generally seeks to minimize a distortion measure, typically mean-squared error (MSE), averaged over coding blocks <ref> [80, 90] </ref>. While this approach leverages the wealth of tools from optimization theory and operations research, it does not guarantee the constancy of quality that is generally desired from a video coding system. <p> Therefore, the bit-production model for picture i would depend causally not only upon the quantization scale used for picture i but also upon the quantization scales used for its reference pictures. The dependent coding problem has been addressed in the traditional distortion-minimization framework in <ref> [90] </ref>. Whether the results of this chapter can be extended to a dependent-coding framework is an open problem.
Reference: [91] <author> A. R. Reibman and B. G. </author> <title> Haskell. Constraints on variable bit-rate video for ATM networks. </title> <journal> IEEE Transactions on Circuits and Systems for Video Technology, </journal> <volume> 2(4) </volume> <pages> 361-372, </pages> <month> December </month> <year> 1992. </year>
Reference-contexts: By assuming a fixed channel delay the encoder buffer fullness can be shown to mirror the decoder buffer fullness, except for an initial startup period. That is, an empty decoder buffer would correspond to a full encoder buffer, and vice versa. The reader is referred to <ref> [91] </ref> for a more complete discussion of buffer constraints in video coder systems. 6.5 Buffer-Constrained Bit-Allocation Problem Using the bit-production model and VBV constraints defined above, we now formalize the buffer-constrained bit-allocation problem. <p> However, the bisection search is not guaranteed to converge in a finite number of iterations. In <ref> [91] </ref>, bit-rate constraints for buffered video coders are derived for a general variable-bit-rate channel, such as that provided by an ATM network. The constraints take into account both the encoder and decoder buffers. The bit-rate constraints are used in an ad-hoc algorithm that jointly selects the channel and encoder rates.
Reference: [92] <author> J. Ribas-Corbera and D. L. Neuhoff. </author> <title> Optimal bit allocations for lossless video coders: Motion vectors vs. difference frames. </title> <booktitle> In Proceedings ICIP'95, </booktitle> <volume> volume 3, </volume> <pages> pages 180-183, </pages> <year> 1995. </year>
Reference-contexts: Even with simplifying assumptions, the rate-distortion optimization is computationally complex and may not be suitable for real-time implementation, as the authors readily admit. Ribas-Corbera and Neuhoff <ref> [92] </ref> describe a procedure for minimizing rate in a lossless motion-compensated video coder. They explore the allocation of bits between the coding of motion vectors and the coding of prediction error.
Reference: [93] <author> J. Rissanen and G. G. Langdon. </author> <title> Universal modeling and coding. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> IT-27:12-23, </volume> <month> January </month> <year> 1981. </year>
Reference: [94] <author> J. D. Salehi, Z.-L. Zhang, J. F. Kurose, and D. Towsley. </author> <title> Supporting stored video: Reducing rate variability and end-to-end resource requirements through optimal smoothing. </title> <booktitle> In Proceedings 1996 ACM International Conference on Measurement and Modeling of Computer Systems (ACM SIGMETRICS), </booktitle> <month> May </month> <year> 1996. </year>
Reference-contexts: In this work, the Lagrange multiplier method is used to find a bit allocation that is optimal within a convex-hull approximation. The optimal vector of Lagrange multipliers consists of constant-valued segments that increase (decrease, respectively) only when the decoder buffer is full (empty). In <ref> [94] </ref>, the theory of majorization [69] is applied to reduce the variability in transmission rate for stored video. <p> As applied to this problem, majorization results in minimizing the peak and variance in transmission rate. The authors provide an optimal smoothing algorithm that runs in time linear in the length of the video sequence. It can be easily shown that the majorization solution to optimal smoothing of <ref> [94] </ref> is in fact equivalent to lexicographic minimization of the transmitted rates, subject to the constraint that the total number of bits transmitted is fixed. The linear running time is possible because the buffering constraints are manifested as fixed upper and lower bounds on the cumulated number of bits transmitted.
Reference: [95] <author> G. M. Schuster and A. K. Katsaggelos. </author> <title> Rate-Distortion Based Video Compression: Optimal Video Frame Compression and Object Boundary Encoding. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, MA, </address> <year> 1997. </year>
Reference-contexts: Even so, this reduced-complexity algorithm has a considerable processing and memory overhead associated with the dynamic programming algorithm, which is performed on top of traditional block matching. In comparison, our adaptive heuristic cost function requires minimal overhead over block matching. In another independent work <ref> [95] </ref>, the authors also apply operational rate-distortion optimization to motion estimation in a dependent-coding environment. Similar to [11], they cast motion estimation as a budget-constrained bit allocation problem and solve it using a combination of Lagrange minimization and dynamic programming. <p> The authors acknowledge that minimizing sum-distortion does not lead to uniform distortion. They reformulate the problem to minimize the maximum (minimax) picture distortion by equating the distortion among pictures. 4 Budget-constrained minimax bit allocation for dependent coding is also considered in <ref> [95] </ref>. The authors provide a minimax solution by first showing how to find a minimum-rate solution given a maximum distortion and then using an bisection search to find the maximum distortion corresponding to the desired rate.
Reference: [96] <author> C. E. Shannon. </author> <title> A mathematical theory of communication. </title> <journal> Bell System Technical Journal, </journal> <volume> 27 </volume> <pages> 379-423, </pages> <month> July </month> <year> 1948. </year>
Reference-contexts: In classical rate-distortion theory, as pioneered by Claude Shannon <ref> [96] </ref>, a rate-distortion function, R (D), is defined to be the theoretical lower bound on the best compression achievable as a function of the desired distortion D for a given information source, by any compressor.
Reference: [97] <author> C. E. Shannon. </author> <title> Prediction and entropy of printed English. </title> <journal> Bell System Technical Journal, </journal> <volume> 30 </volume> <pages> 50-64, </pages> <month> January </month> <year> 1951. </year>
Reference: [98] <author> Y. Shoham and A. Gersho. </author> <title> Efficient bit allocation for an arbitrary set of quantizers. </title> <journal> IEEE Transactions on Acoustics, Speech, and Signal Processing, </journal> <volume> 36(9) </volume> <pages> 1445-1453, </pages> <month> September </month> <year> 1988. </year> <month> 163 </month>
Reference-contexts: Even though not directly computable, the existence of a hypothetical rate-distortion function for a given type of information source allows a comparison to be made between competing encoding systems and algorithms. 40 A more practical approach is taken in <ref> [14, 98] </ref>. By measuring actual rates and distortion achieved by the coder under study, an operational rate-distortion plot similar to Figure 3.6 can be constructed. It is sometimes useful to show the convex hull of the data points to fill in the gap between points. <p> There could potentially be an exponential number of states generated, on the order of M N . In <ref> [98] </ref>, Shoham and Gersho give an efficient bit allocation algorithm based on the Lagrange-multiplier method [25]. In this method, Problem 3.1, a constrained optimization problem, is transformed to the following unconstrained optimization problem. 43 a state that exceeds the bit budget B and can be pruned. <p> It can be shown that a solution to Problem 3.2 is also a solution to Problem 3.1 when R fl () = B. This is proved in [25], and we reproduce the theorem and proof as presented in <ref> [98] </ref>. Theorem 3.1 For any 0, a solution Q fl () to Problem 3.2 is also a solution to Problem 3.1 with the constraint R (Q) B, where B = R fl (). <p> With appropriate initial upper and lower bounds for , a bisection search can be performed to find the proper value for . Details of the search procedure can be found in <ref> [98] </ref>. For an additive distortion measure, the distortion D (Q) can be expressed as D (Q) = i=1 45 where D i (Q i ) is the distortion for block i when using the quantizer specified by Q i . <p> This can be determined, for example, by preprocessing a portion of the input video to estimate the rate-distortion curve. An on-line iterative search method could also be used <ref> [98] </ref>. In our experiments, we code the test sequence several times with different quantizer step sizes to estimate the rate-distortion function, and fix based upon the slope of the function at the desired operating point. <p> Thus s 0 = s. 2 Lemma 6.1 establishes a desirable property of the lexicographic optimality criterion: If a constant-Q allocation is legal, it is the only lexicographically optimal allocation. This meets our objective of obtaining a constant-quality allocation (via perceptual quantization) when feasible. 101 6.7 Related Work In <ref> [98] </ref>, the budget-constrained bit-allocation problem (see Section 3.3.3) is examined in the context of a discrete set of independent quantizers. A bit allocation algorithm based upon Lagrangian minimization is presented as a more efficient alternative to the well-known dynamic programming solution based upon the Viterbi algorithm [105, 28].
Reference: [99] <author> A M. Slyz. </author> <title> Image compression using a ziv-lempel type coder. </title> <type> Master's thesis, </type> <institution> University of Michigan School of Engineering, </institution> <year> 1991. </year>
Reference: [100] <author> R. Srinivasan and K. R. Rao. </author> <title> Predictive coding based on efficient motion estimation. </title> <booktitle> In Proceedings International Conference on Communications, </booktitle> <volume> volume 1, </volume> <pages> pages 521-526, </pages> <year> 1988. </year>
Reference-contexts: In previous work on BMMC, motion vectors are typically chosen to minimize prediction error, and much of the emphasis has been on speeding up the motion search <ref> [50, 55, 88, 100] </ref>. However, for low bit-rate applications, the coding of motion vectors takes up a significant portion of the bandwidth, as evidenced with a coding experiment summarized in Table 4.1 and Figure 4.1. This observation has previously been made in [58].
Reference: [101] <author> J. A. Storer. </author> <title> Data Compression: Methods and Theory. </title> <publisher> Computer Science Press, </publisher> <address> New York, NY, </address> <year> 1988. </year>
Reference: [102] <author> J. A. Storer and T. G. Szymanski. </author> <title> Data compression via textual substitution. </title> <journal> Journal of the ACM, </journal> <volume> 29(4) </volume> <pages> 928-951, </pages> <year> 1982. </year>
Reference: [103] <author> K. M. Uz, J. M. Shapiro, and M. Czigler. </author> <title> Optimal bit allocation in the presence of quantizer feedback. </title> <booktitle> In Proceedings 1993 International Conference on Acoustics, Speech and Signal Processing, </booktitle> <volume> volume 5, </volume> <pages> pages 385-388, </pages> <year> 1993. </year>
Reference-contexts: This work lays the foundation for much of the ensuing work on optimal bit allocation. Optimal budget-constrained bit allocation in a dependent, predictive coding setting is examined in <ref> [103] </ref>. A parametric rate-distortion model is proposed for intraframe coding and forward predictive coding. The model has an exponential form and is motivated by theoretical rate-distortion results for stationary Gaussian sources.
Reference: [104] <author> E. Viscito and C. Gonzales. </author> <title> A video compression algorithm with adaptive bit allocation and quantization. </title> <booktitle> In SPIE Proceedings: Visual Communications and Image Processing, </booktitle> <volume> volume 1605, </volume> <pages> pages 58-72, </pages> <month> November </month> <year> 1991. </year>
Reference-contexts: These studies lead to various techniques, called perceptual quantization or adaptive perceptual quantization, that take into account properties of the Human Visual System (HVS) in determining the quantization scale <ref> [104, 86, 52, 16, 60, 108, 18] </ref>. <p> In this regards, ff I can be viewed as a perceptual weighting factor. Our bit rate allocation, however, works with any perceptual quantization function. The problem of determining P (I; Q) has been studied elsewhere <ref> [104, 15] </ref> and is not considered in this thesis. Here, we address the assignment of Q to each picture to give constant or near-constant quality among pictures while satisfying rate constraints imposed by the channel and decoder. <p> In practice, therefore, the chosen models should admit efficient computation of G i;j . In this section we examine two classes of models for which G i;j can be efficiently computed. 9.2.1 Hyperbolic Model In <ref> [104] </ref>, the following simple "hyperbolic" model forms the basis of an adaptive bit allocation algorithm: f i (q i ) = q i where ff i is associated with the complexity of coding picture i and fi i with the overhead for coding the picture.
Reference: [105] <author> A. J. Viterbi and J. K. Omura. </author> <title> Principles of Digital Communication and Coding. </title> <publisher> McGraw-Hill, </publisher> <year> 1979. </year>
Reference-contexts: hQ 1 ; Q 2 ; : : : ; Q N i to each block that minimizes a distortion measure D (Q) and uses R (Q) B bits. 3.3.3a Viterbi Algorithm Problem 3.1 can be solved using a dynamic programming algorithm commonly referred to as the Viterbi algorithm (VA) <ref> [28, 105] </ref>. Assuming that quantization always produces an integral number of bits, the Viterbi algorithm works by first constructing a trellis of nodes and then finding a shortest path through the trellis. Each node represents a state and each edge a transition between states. <p> A bit allocation algorithm based upon Lagrangian minimization is presented as a more efficient alternative to the well-known dynamic programming solution based upon the Viterbi algorithm <ref> [105, 28] </ref>. This work lays the foundation for much of the ensuing work on optimal bit allocation. Optimal budget-constrained bit allocation in a dependent, predictive coding setting is examined in [103]. A parametric rate-distortion model is proposed for intraframe coding and forward predictive coding.
Reference: [106] <author> X. Wang, S. M. Shende, and K. Sayood. </author> <title> Online compression of video sequences using adaptive vq codebooks. </title> <booktitle> In Proceedings 1994 Data Compression Conference, </booktitle> <pages> pages 185-194, </pages> <address> Snowbird, UT, March 1994. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: Usually, the same codebook is used by the encoder and the decoder. The codebook generation process is itself computationally demanding. As with lossless dictionary coding, a VQ codebook can be constructed statically, semi-adaptively, or adaptively. Some applications of VQ in video compression can be found in <ref> [29, 106] </ref>. 46 3.4.2 Block Transform In block-transform coding, an image is divided into blocks, as with vector quantization. Each block is mathematically transformed into a different representation, which is then quantized and coded.
Reference: [107] <author> T.A. Welch. </author> <title> A technique for high performance data compression. </title> <booktitle> Computer, </booktitle> <pages> pages 8-19, </pages> <year> 1984. </year>
Reference: [108] <author> S. J. P. Westen, R. L. Lagendijk, and J. Biemond. </author> <title> Perceptual optimization of image coding algorithms. </title> <booktitle> In Proceedings ICIP'95, </booktitle> <volume> volume 2, </volume> <pages> pages 69-72, </pages> <year> 1995. </year>
Reference-contexts: These studies lead to various techniques, called perceptual quantization or adaptive perceptual quantization, that take into account properties of the Human Visual System (HVS) in determining the quantization scale <ref> [104, 86, 52, 16, 60, 108, 18] </ref>.
Reference: [109] <author> B. Widrow and M. E. Hoff. </author> <title> Adaptive switching circuits. </title> <booktitle> In 1960 IRE WESCON Convention Record, </booktitle> <volume> volume 4, </volume> <pages> pages 96-104, </pages> <year> 1960. </year>
Reference-contexts: This is a tedious and time-consuming operation. Instead, we can use an adaptive on-line technique, such as the Widrow-Hoff learning rule <ref> [109, 36] </ref>, to train the model parameters. The training examples could be generated each time we encode a macroblock using motion compensation mode. However, we cannot possibly hope to train one model for each value of Q simply because there would not be enough training examples.
Reference: [110] <author> T. Wiegand, M. Lightstone, D. Mukherjee, T. G. Campbell, and S. K. Mitra. </author> <title> Rate-distortion optimized mode selection for very low bit rate video coding and the emerging H.263 standard. </title> <journal> IEEE Transactions on Circuits and Systems for Video Technology, </journal> <volume> 6(2) </volume> <pages> 182-190, </pages> <month> April </month> <year> 1996. </year>
Reference-contexts: The authors also consider joint optimization of motion estimation and quantization using the same framework. Notably, they also provide a solution to both problems that minimizes the maximum (minimax) distortion. In <ref> [110] </ref>, rate-distortion optimization is applied to the selection of coding control for low-bit-rate video coding under the H.263 standard, a newer standard than the H.261 standard that we consider here. A greedy optimization strategy is adopted to avoid the exponential complexity that a global optimization would entail.
Reference: [111] <author> I. H. Witten and T. C. Bell. </author> <title> The zero frequency problem: Estimating the probabilities of novel events in adaptive text compression. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> IT-37:1085-1094, </volume> <month> July </month> <year> 1991. </year>
Reference: [112] <author> X. Zhang, M. C. Cavenor, and J. F. Arnold. </author> <title> Adaptive quadtree coding of motion-compensated image sequences for use on the broadband ISDN. </title> <journal> IEEE Transactions on Circuits and Systems for Video Technology, </journal> <volume> 3(3) </volume> <pages> 222-229, </pages> <year> 1993. </year> <month> 164 </month>
Reference-contexts: Methods for taking a tree structure like the above (except expanded completely) and then "smoothing" the motion vectors by making children tend to be like their parents and vice-versa, were discussed by Dufaux and Kunt [24]. Zhang, Cavenor, and Arnold <ref> [112] </ref> considered various ways of using quadtrees to code the prediction error. 5.5 Discussion In this chapter, we have presented a non-standard hybrid block-matching DCT video coder that further optimizes the coding of motion vectors by representing the motion field using a quadtree decomposition.
Reference: [113] <author> J. Ziv and A. Lempel. </author> <title> A universal algorithm for sequential data compression. </title> <journal> IEEE Trans--actions on Information Theory, </journal> <volume> IT-23(3):337-343, </volume> <year> 1977. </year>
Reference: [114] <author> J. Ziv and A. Lempel. </author> <title> Compression of individual sequences via variable-rate coding. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> IT-24:530-536, </volume> <month> September </month> <year> 1978. </year> <month> 165 </month>
References-found: 114

