URL: http://theory.lcs.mit.edu/~emjordan/thesis.ps
Refering-URL: http://theory.lcs.mit.edu/~emjordan/
Root-URL: 
Title: Programming Models for the Development of Interactive Audio Applications  
Author: by Eric Michael Jordan 
Degree: Submitted to the Department of Electrical Engineering and Computer Science in partial fulfillment of the requirements for the degree of Master of Science at the  All rights reserved. Author  Certified by Tod Machover Associate Professor Thesis Supervisor Accepted by F. R. Morgenthaler Chairman, Departmental Committee on Graduate Students  
Date: 1992  February 1995  November 23, 1994  
Address: Princeton University,  
Affiliation: B.S.E., Computer Science  MASSACHUSETTS INSTITUTE OF TECHNOLOGY  c Massachusetts Institute of Technology 1995.  Department of Electrical Engineering and Computer Science  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Arvind and David E. Culler. </author> <title> Dataflow architectures. LCS 294, </title> <publisher> MIT, </publisher> <year> 1996. </year>
Reference-contexts: However, graphical dataflow machines have traditionally had difficulty describing sophisticated programming constructs, such as control flow, conditionals, and loops ([1] and [39, chapter 7]). Methods have been developed to handle these situations. In particular, an apply node can be used to elegantly provide many of these facilities <ref> [1, 6, 39] </ref>. However, when you add the issues that arise because of the use of audio, such as time delays, user events, side effects (audio output, for example), different rates of execution, and asynchronous interactions, the dataflow assumption breaks down very quickly.
Reference: [2] <author> Kavi Arya. </author> <title> A functional animation starter-kit. </title> <journal> Journal of Functional Programming, </journal> <volume> 4(1) </volume> <pages> 1-18, </pages> <month> January </month> <year> 1994. </year>
Reference-contexts: We note here, however, that specifying interactive temporal behavior and creating a graphical representation of a program written in a functional language are both interesting but open research problems <ref> [2, 36] </ref>. 2.4 The NeXT Music Kit The NeXT Music Kit [22] is an extension to NeXTSTEP that gives the user access to a library of unit generators, and the ability to make patches out of them from within any language that can link to object files, including Objective C and <p> However, because of their ability to handle functions as first class objects, support for lazy evaluation, and ability to dynamically compile down to native assembly code, they have recently received attention by people developing systems that, like swish, have to handle the concept of time in an elegant manner. <ref> [2] </ref> describes a project that uses Haskell for computer animation. [36] is the beginnings of a visual interface on top of Haskell, much in the same way that swish provides a graphical interface to the tasks in swish.
Reference: [3] <author> M. R. Barbacci and J. M. Wing. </author> <title> Specifying functional and timing behavior for real-time applications. </title> <type> Technical Report 177, </type> <institution> Carnegie Mellon University, </institution> <year> 1986. </year>
Reference-contexts: Instead, by implementing it as an extension to swish, it can be used in conjunction with other audio processes, and controlled in real time using an intuitive and flexible graphical interface. Another distinction between traditional systems and swish is that swish uses a task-based programming model <ref> [3, 4] </ref> instead of a dataflow machine. The basic idea behind the task-based model is to divorce the temporal dependencies of the unit generators from their functional dependencies. The user then has the flexibility needed to handle special cases that the traditional "dataflow machine" approach has trouble with. <p> The task model gives the user this flexibility. It was originally introduced in <ref> [3] </ref>, and a description of a language that uses it is found in [4]. We describe our use of it in the next few sections. <p> In other words, we must look at how the tasks are represented in memory. Each task has a list of input and output ports, a "timing" structure that describes when a task executes, and the function that the task executes when it is invoked. Based on figure one of <ref> [3] </ref>, this might look like: task 1 function timing ports task 2 function timing ports ... task n function timing ports [3] proposes that each task specify its temporal behavior through a set of conditions based on the status of its input port. <p> Based on figure one of <ref> [3] </ref>, this might look like: task 1 function timing ports task 2 function timing ports ... task n function timing ports [3] proposes that each task specify its temporal behavior through a set of conditions based on the status of its input port. <p> Although it is natural to specify "task x receives its first input from port y," a similar temporal statement is harder to formulate. Even <ref> [3] </ref> says that "[the timing information] is the behavior of the task seen from the outside." Therefore, we propose that the information about the timing behavior of a task should be removed from the 26 description of the task itself, and that all of this information should be collected into data
Reference: [4] <author> Mario R. Barbacci, Dennis L. Doubleday, Charles B. Weinstock, Steven L. Baur, David C. Bixler, and Michael T. Heins. </author> <title> Command, control, communications, and intelligence node: A Durra application example. </title> <type> SEI 9, </type> <institution> Carnegie Mellon University, </institution> <year> 1989. </year>
Reference-contexts: Instead, by implementing it as an extension to swish, it can be used in conjunction with other audio processes, and controlled in real time using an intuitive and flexible graphical interface. Another distinction between traditional systems and swish is that swish uses a task-based programming model <ref> [3, 4] </ref> instead of a dataflow machine. The basic idea behind the task-based model is to divorce the temporal dependencies of the unit generators from their functional dependencies. The user then has the flexibility needed to handle special cases that the traditional "dataflow machine" approach has trouble with. <p> The task model gives the user this flexibility. It was originally introduced in [3], and a description of a language that uses it is found in <ref> [4] </ref>. We describe our use of it in the next few sections.
Reference: [5] <author> John A. Bate. </author> <title> Unison a real-time interactive system for digital sound synthesis. </title> <booktitle> In Proceedings of the International Computer Music Conference, </booktitle> <year> 1990. </year>
Reference-contexts: We illustrate this point with a prototype system, "swish," that extends the Tcl/Tk scripting language [30] with a framework that supports the patching together of "unit generators" to describe synthesis and analysis algorithms in a manner that is extremely familiar to the computer music community <ref> [5, 28, 29] </ref>. Tcl is a scripting language that meets all of our requirements: it is portable, freely available, high 7 level, extensible, and interpreted. Tk is an extension to Tcl that provides easy access to a widget set. It is common for patch editors to provide graphical interfaces. <p> In chapter five, we will discuss the importance of incremental compilation. Note, for now, however, that generating code to be executed on external hardware is potentially useful independently of the gain in efficiency, simply because it allows us to create our patches on the fly. <ref> [5] </ref> provides a good description of another system that dynamically generates code for a DSP chip based on a graphical patch of unit generators.
Reference: [6] <author> Micah Beck and Kesav Pingali. </author> <title> From control flow to dataflow. </title> <type> Technical Report 1050, </type> <institution> MIT, </institution> <year> 1989. </year>
Reference-contexts: However, graphical dataflow machines have traditionally had difficulty describing sophisticated programming constructs, such as control flow, conditionals, and loops ([1] and [39, chapter 7]). Methods have been developed to handle these situations. In particular, an apply node can be used to elegantly provide many of these facilities <ref> [1, 6, 39] </ref>. However, when you add the issues that arise because of the use of audio, such as time delays, user events, side effects (audio output, for example), different rates of execution, and asynchronous interactions, the dataflow assumption breaks down very quickly.
Reference: [7] <author> A. Biancardi and A. Rubini. </author> <title> Non-string data handling in Tcl/Tk. </title> <booktitle> In Proceedings of the Tcl/Tk Workshop, </booktitle> <pages> pages 171-175, </pages> <year> 1994. </year>
Reference-contexts: They address many of the implementation and scheduling issues facing the developer of an interactive audio package. They include the VuSystem [43], Pacco <ref> [7] </ref>, and Tcl-Me [16]. All of these projects were developed in UNIX, using Tcl.
Reference: [8] <author> Thomas H. Cormen, Charles E. Leiserson, and Ronald L. Rivest. </author> <title> Introduction to Algorithms. </title> <publisher> MIT Press and McGraw-Hill, </publisher> <year> 1991. </year>
Reference-contexts: For example, the "dataflow" task contains a dependency graph. When invoked, it uses a topological sort <ref> [8, pages 485-488] </ref> of the graph to invoke each of the tasks in the graph in an order that respects the dependencies. Since this is precisely the behavior that is desired when describing an expression, the dataflow task is used quite frequently.
Reference: [9] <author> R. B. Dannenberg, C.L. Fraley, and P. Velikonja. </author> <title> A functional language for sound synthesis with behavioral abstraction and lazy evaluation. </title> <editor> In Dennis Baggi, </editor> <booktitle> 59 editor, Readings in Computer-Generated Music, </booktitle> <pages> pages 25-40. </pages> <publisher> IEEE Computer Society Press, </publisher> <year> 1992. </year>
Reference-contexts: Conversely, the graphical interface provides one intuitive and high level way to manipulate MAX code and create patches. However, because MAX insists on isolating itself, it is difficult to create and manipulate patches in any other way. 2.3 Nyquist Nyquist <ref> [11, 9] </ref> is another system that unifies the two tiered approach. That, however, is where the similarity with MAX ends. Nyquist extends xlisp with a set of unit generators. However, instead of describing a patch graphically, it is described textually, using lazy evaluation.
Reference: [10] <author> Roger Dannenberg. </author> <title> Real-time scheduling and computer accompaniment. </title> <editor> In Max V. Mathews and John R. Pierce, editors, </editor> <booktitle> Current Directions in Computer Music Research, </booktitle> <pages> pages 225-261. </pages> <publisher> MIT Press, </publisher> <year> 1989. </year>
Reference-contexts: The problem of handling a set of timed callback requests and dynamically determining which is the next one that is 40 going to occur is exactly the problem that the operating system is supposed to solve with its scheduler. For musical applications, it is addressed in <ref> [10] </ref>. Fortunately, it is also part of the functionality of the Tcl/Tk main loop. For now, we rely on the Tcl/Tk main loop to handle the scheduling.
Reference: [11] <author> Roger B. Dannenberg. </author> <note> Nyquist. WWW URL file://g.gp.cs.cmu.edu/usr/rbd/public/nyquist. </note>
Reference-contexts: These systems include MAX [35] and Nyquist <ref> [11] </ref> (discussed below). MAX is a popular system for specifying note and control level interactions, primarily through MIDI, although signal processing facilities are available on some platforms. It distinguishes itself by using a purely graphical interface. <p> Conversely, the graphical interface provides one intuitive and high level way to manipulate MAX code and create patches. However, because MAX insists on isolating itself, it is difficult to create and manipulate patches in any other way. 2.3 Nyquist Nyquist <ref> [11, 9] </ref> is another system that unifies the two tiered approach. That, however, is where the similarity with MAX ends. Nyquist extends xlisp with a set of unit generators. However, instead of describing a patch graphically, it is described textually, using lazy evaluation. <p> The buffers of long integers provide a representation of floating point numbers that can be manipulated using integer arithmetic. This kind of trick is extremely common in inner loops of sound synthesis programs. Our use of it is loosely modeled after code found in Nyquist <ref> [11] </ref>. Whether or not it is truly necessary anymore, given the improved performance of floating point arithmetic, is an interesting question. Finally, we provide support for instances. <p> A phasor task is at the heart of a signal synthesis system. It adds the notion of time or state to a buffer. The code for the phasor in swish is based on code found in Nyquist <ref> [11] </ref>. <p> Nyquist <ref> [11] </ref> is written in xlisp, and emphasizes the utility of lazy evaluation. Finally, Common Music [42] adds support for objects that represent musical abstractions in CLOS (Common Lisp Object System).
Reference: [12] <author> Roger B. Dannenberg. </author> <title> Music representation issues, techniques, </title> <journal> and systems. Computer Music Journal, </journal> <volume> 17(3) </volume> <pages> 20-30, </pages> <month> Fall </month> <year> 1993. </year>
Reference-contexts: Tags can be associated with instances or buffers, making it possible for a process to set the value of all variables whose tags satisfy some predicate. Tags have already been found to be useful in computer music systems <ref> [12] </ref>. A variable can receive a tag because of its lexical properties (where it lies in the code), or because of its dynamic properties (what caused the variable to be instantiated).
Reference: [13] <author> Roger B. Dannenberg, Dean Rubine, and Tom Neuendorffer. </author> <title> The resource-instance model of music representation. </title> <booktitle> In Proceedings of the International Computer Music Conference, </booktitle> <year> 1991. </year>
Reference-contexts: Out-of-band code, responding to user input or other external events, starts, controls, and destroys these modules. <ref> [13] </ref> discusses similar concepts, using different terminology, from the computer music perspective. <p> An example of an instance is a procedure that plays a MIDI note: it starts up, it executes, and then it goes away, without responding to any events that other procedures might try to give it. <ref> [13] </ref> proposes the use of a hierarchy of modules, each module treating ones below it in the hierarchy as resources, and the one above it as an instance.
Reference: [14] <author> Sven Delmas. Xf: </author> <title> Design and implementation of a programming environment for interactive construction of graphical user interfaces. </title> <address> WWW URL file://harbor.ecn.purdue.edu/pub/code/xf-doc-us.ps.gz. </address>
Reference-contexts: It has already been shown that a simple program, tkInspect [40], written independently of swish, can be used to examine and modify the current configuration of the tasks. Xf <ref> [14] </ref> and hierQuery [37] are two possible candidates for browsing and editing tools that might be extended to support the manipulation of swish types and tasks.
Reference: [15] <author> Edsger W. Dijkstra. </author> <title> A Discipline of Programming. </title> <publisher> Prentice-Hall, </publisher> <year> 1976. </year>
Reference-contexts: We then discuss a few languages that have this capability that may become available in the near future. 5.2 The Generalization Phenomenon In the first chapter of his classic monograph <ref> [15, page 4] </ref>, Dijkstra writes "When asked to produce one or more results, it is usual to generalize the problem and to consider these results as specific instances of a wider class." 44 He goes on to say that the basis for deciding how to generalize a problem should be how
Reference: [16] <author> Patrick Duval and Tie Liao. Tcl-Me, </author> <title> a Tcl Multimedia Extension. </title> <booktitle> In Proceedings of the Tcl/Tk Workshop, </booktitle> <pages> pages 91-96, </pages> <year> 1994. </year>
Reference-contexts: They address many of the implementation and scheduling issues facing the developer of an interactive audio package. They include the VuSystem [43], Pacco [7], and Tcl-Me <ref> [16] </ref>. All of these projects were developed in UNIX, using Tcl.
Reference: [17] <author> John V. Guttag, James J. Horning, et al. </author> <title> Larch: Languages and Tools for Formal Specification. </title> <publisher> Springer-Verlag, </publisher> <year> 1993. </year>
Reference: [18] <author> Michael Halle. </author> <note> Tk userevent 0.95. WWW URL file://harbor.ecn.purdue.edu/pub/extensions/uevent-0.95.tar.gz. </note>
Reference-contexts: A more elegant implementation would raise an event every time a parameter is changed; then, any graphical representation of the task could respond to that event. Since Tcl/Tk does not allow the user to create his own kinds of events, an extension such as userevent <ref> [18] </ref> could be used. Alternatively, a rule-based system, such as that provided by Rush [38], could provide an elegant solution: We could enforce rules that describe how the graphical representation depends on the state of the tasks.
Reference: [19] <author> Goffredo Haus and Alberto Sametti. Scoresynth: </author> <title> A system for the synthesis of music scores based on Petri nets and a music algebra. </title> <editor> In Dennis Baggi, editor, </editor> <booktitle> Readings in Computer-Generated Music, </booktitle> <pages> pages 53-77. </pages> <publisher> IEEE Computer Society Press, </publisher> <year> 1992. </year> <month> 60 </month>
Reference-contexts: It seems that almost every concept studied in computer science, from context free grammars [20], Petri nets <ref> [19] </ref>, and Markov models [29, section 5.5], to expert systems [23], neural networks, and genetic algorithms [21], has been the basis for some algorithmic composition, sound synthesis technique, or musical listening tool. <p> However, other models of temporal behavior could easily be implemented as well. are two graphs, one for temporal dependencies, and one for functional dependencies. For example, a metronome task might invoke an FM task at regular intervals, to update the buffers read by the speakers. Petri nets <ref> [19] </ref> and Markov models [29, section 5.5] have both been found effective for specifying the algorithmic composition of computer music. Higher order tasks are powerful abstractions, partly because they 28 are allowed to depend on delays or on user interaction.
Reference: [20] <author> S. R. Holtzman. </author> <title> Using generative grammars for music composition. </title> <journal> Computer Music Journal, </journal> <volume> 5(1) </volume> <pages> 51-64, </pages> <month> Spring </month> <year> 1981. </year>
Reference-contexts: It seems that almost every concept studied in computer science, from context free grammars <ref> [20] </ref>, Petri nets [19], and Markov models [29, section 5.5], to expert systems [23], neural networks, and genetic algorithms [21], has been the basis for some algorithmic composition, sound synthesis technique, or musical listening tool.
Reference: [21] <author> Andrew Horner, James Beauchamp, and Lippold Haken. </author> <title> Machine tongues XVI: Genetic algorithms and their application to FM matching synthesis. </title> <journal> Computer Music Journal, </journal> <volume> 17(4) </volume> <pages> 17-29, </pages> <month> Winter </month> <year> 1993. </year>
Reference-contexts: It seems that almost every concept studied in computer science, from context free grammars [20], Petri nets [19], and Markov models [29, section 5.5], to expert systems [23], neural networks, and genetic algorithms <ref> [21] </ref>, has been the basis for some algorithmic composition, sound synthesis technique, or musical listening tool.
Reference: [22] <author> David Jaffe and Lee Boynton. </author> <title> An overview of the Sound and Music Kits for the NeXT computer. </title> <editor> In Stephen Travis Pope, editor, </editor> <booktitle> The Well-Tempered Object: Musical Applications of Object-Oriented Software Technology, </booktitle> <pages> pages 107-115. </pages> <publisher> The MIT Press, </publisher> <year> 1991. </year>
Reference-contexts: We note here, however, that specifying interactive temporal behavior and creating a graphical representation of a program written in a functional language are both interesting but open research problems [2, 36]. 2.4 The NeXT Music Kit The NeXT Music Kit <ref> [22] </ref> is an extension to NeXTSTEP that gives the user access to a library of unit generators, and the ability to make patches out of them from within any language that can link to object files, including Objective C and Common Music [42]. <p> But, having an system with three independently written schedulers is clearly inelegant, and will hopefully be addressed by the POSIX standards at some point, through per-thread (and not just per-process) interrupts. 4.3 The Need for Objects Recently, several systems have proposed using object oriented programming models for computer music projects <ref> [22, 33] </ref>. These systems make the point that an object oriented system provides a facility for abstraction that is extremely important in an environment that has to support the dynamic creation and naming of any kind of module.
Reference: [23] <author> Margaret L. Johnson. </author> <title> An expert system for the articulation of Bach fugue melodies. </title> <editor> In Dennis Baggi, editor, </editor> <booktitle> Readings in Computer-Generated Music, </booktitle> <pages> pages 41-51. </pages> <publisher> IEEE Computer Society Press, </publisher> <year> 1992. </year>
Reference-contexts: It seems that almost every concept studied in computer science, from context free grammars [20], Petri nets [19], and Markov models [29, section 5.5], to expert systems <ref> [23] </ref>, neural networks, and genetic algorithms [21], has been the basis for some algorithmic composition, sound synthesis technique, or musical listening tool.
Reference: [24] <author> Brain W. Kernighan and Rob Pike. </author> <title> The UNIX Programming Environment. </title> <publisher> Prentice-Hall, </publisher> <year> 1984. </year>
Reference-contexts: Unfortunately, real-time interrupts and multithreading was not part of the original Unix philosophy. The designers clearly felt that threads were unnecessary, since processes could communicate through files (The first sentence of chapter two of <ref> [24] </ref> proclaims "Everything in the UNIX system is a file."), using pipelines when appropriate, and that the purpose of scheduling was to ensure that system resources were distributed equitably when several users wanted to use the computer at the same time.
Reference: [25] <author> Thomas M. Levergood, Andrew C. Payne, James Gettys, G. Winfield Treese, and Lawrence C. Stewart. AudioFile: </author> <title> A network-transparent system for distributed audio applications. </title> <booktitle> In Proceedings of the USENIX Summer Conference, </booktitle> <month> June </month> <year> 1993. </year>
Reference-contexts: Swish was developed on an DEC 3000 model 400/400S running OSF 2.0, using a 8 J300 Sound and Motion card to provide audio, and a KEY Electronics Midiator-124W box to establish MIDI capabilities through the serial port. AudioFile <ref> [25] </ref>, a transparent, portable audio server written by DEC at Cambridge Research Laboratory, was used to interface with the J300 Sound and Motion card. Ak [32], also written at CRL, serves as the interface between AudioFile and Tcl. <p> It introduces the term "resource" for in-band code, and contrasts it with the concept of an "instance," which is a procedure that is "independent and isolated." An example of a resource is given by the AudioFile server <ref> [25] </ref>, which runs in the background, processing play or record requests.
Reference: [26] <author> Tod Machover. Hyperinstruments: </author> <title> A progress report 1987-1991. </title> <publisher> MIT Media Lab, </publisher> <month> January </month> <year> 1992. </year>
Reference-contexts: Prof. Machover has recently proposed the Virtual Brain Opera, an extensive, networked, musical installation to be made available on the internet [27]. The computer music community already has an extensive history of interest in real-time interaction with audio processes (see, for instance, <ref> [26] </ref>); the transformation of the computer music community from that small group of people with access to the required special purpose hardware to the global community of workstation users connected through the internet will reemphasize the need for environments that are not only capable of performing real-time audio with no special
Reference: [27] <author> Tod Machover. </author> <title> Brain Opera and Virtual Brain Opera. </title> <publisher> MIT Media Lab, </publisher> <month> August </month> <year> 1994. </year>
Reference-contexts: Prof. Machover has recently proposed the Virtual Brain Opera, an extensive, networked, musical installation to be made available on the internet <ref> [27] </ref>.
Reference: [28] <author> Michael Minnick. </author> <title> A graphical editor for building unit generator patches. </title> <booktitle> In Proceedings of the International Computer Music Conference, </booktitle> <year> 1990. </year>
Reference-contexts: We illustrate this point with a prototype system, "swish," that extends the Tcl/Tk scripting language [30] with a framework that supports the patching together of "unit generators" to describe synthesis and analysis algorithms in a manner that is extremely familiar to the computer music community <ref> [5, 28, 29] </ref>. Tcl is a scripting language that meets all of our requirements: it is portable, freely available, high 7 level, extensible, and interpreted. Tk is an extension to Tcl that provides easy access to a widget set. It is common for patch editors to provide graphical interfaces. <p> For example, the application kit gives the programmer access to widgets that can be used to build a graphical user interface. This has been demonstrated by the author's undergraduate research project grasp, the "GRAphical Synth Patch" editor, an implementation of a program proposed in <ref> [28] </ref>. Grasp is a standalone application that provides both a graphical and a textual interface to the patch creation aspect of the Music Kit. Grasp and other Music Kit interfaces demonstrate that the Music Kit is amenable to a graphical representation.
Reference: [29] <author> F. Richard Moore. </author> <title> Elements of Computer Music. </title> <publisher> Prentice-Hall, </publisher> <year> 1990. </year>
Reference-contexts: We illustrate this point with a prototype system, "swish," that extends the Tcl/Tk scripting language [30] with a framework that supports the patching together of "unit generators" to describe synthesis and analysis algorithms in a manner that is extremely familiar to the computer music community <ref> [5, 28, 29] </ref>. Tcl is a scripting language that meets all of our requirements: it is portable, freely available, high 7 level, extensible, and interpreted. Tk is an extension to Tcl that provides easy access to a widget set. It is common for patch editors to provide graphical interfaces. <p> It seems that almost every concept studied in computer science, from context free grammars [20], Petri nets [19], and Markov models <ref> [29, section 5.5] </ref>, to expert systems [23], neural networks, and genetic algorithms [21], has been the basis for some algorithmic composition, sound synthesis technique, or musical listening tool. <p> The structure of the two-tiered approach creates a model of computation that provides the composer with a simulation of the hardware found in a traditional music studio, where MIDI instruments or sequencers send triggers to synthesizers and effects boxes. Csound [44] and cmusic <ref> [29, section 3.2] </ref> are two popular members of the Music-N family. Csound provides the user with a powerful library of audio routines that have been proven to be effective in computer music pieces. <p> It is clear, however, that portability, longevity, and availability are extremely important features of any system that is intended for artistic use. In <ref> [29, page 174] </ref>, Moore writes "Because the computations involved are arbitrarily complicated and therefore arbitrarily time-consuming, programs such as cmusic do not run in real time, which would allow them to be played by live performers like musical instruments." Here, there is an implication that real-time interaction is merely a question <p> For example, a metronome task might invoke an FM task at regular intervals, to update the buffers read by the speakers. Petri nets [19] and Markov models <ref> [29, section 5.5] </ref> have both been found effective for specifying the algorithmic composition of computer music. Higher order tasks are powerful abstractions, partly because they 28 are allowed to depend on delays or on user interaction.
Reference: [30] <author> John K. Ousterhout. </author> <title> Tcl and the Tk Toolkit. </title> <publisher> Addison-Wesley, </publisher> <year> 1994. </year> <month> 61 </month>
Reference-contexts: We illustrate this point with a prototype system, "swish," that extends the Tcl/Tk scripting language <ref> [30] </ref> with a framework that supports the patching together of "unit generators" to describe synthesis and analysis algorithms in a manner that is extremely familiar to the computer music community [5, 28, 29].
Reference: [31] <author> L. C. Paulson. </author> <title> ML for the Working Programmer. </title> <publisher> Cambridge University Press, </publisher> <year> 1991. </year>
Reference-contexts: For example, the "apply" node in a dataflow language takes a function and arguments as input, and invokes them. In non-procedural programming languages like ML, "functionals" take functions as inputs, and compose them both functionally and temporally to produce the result <ref> [31, chapter 5] </ref>. In swish, higher order tasks perform a role similar to both of these, except that they only work in the temporal domain. A similar abstraction is conceivable in the functional domain. In swish, each task keeps track of its own functional connections. <p> All of the examples of generalization that we have given so far take an input parameter, and make the task work when that parameter has a different or more general type. Many languages address this problem. Some, like ML <ref> [31] </ref>, allow operators to be overloaded, so that they work on many different types. They check the type of a variable at runtime every time it is used. Some object oriented systems would let you define a different phasor for every possible combination of input types. <p> At the moment, the only interpreted, free, and portable languages that support dynamic compilation are functional ones created by the programming languages research community, like ML <ref> [31] </ref>, Haskell, or Scheme. It might be possible to add dynamic compilation to the Tcl/Tk environment in a way that maintains portability across architectures, by creating a Tcl interface to the SMLNJ back end.
Reference: [32] <author> Andrew Payne. Ak. </author> <note> WWW URL file://crl.dec.com/pub/misc. </note>
Reference-contexts: AudioFile [25], a transparent, portable audio server written by DEC at Cambridge Research Laboratory, was used to interface with the J300 Sound and Motion card. Ak <ref> [32] </ref>, also written at CRL, serves as the interface between AudioFile and Tcl. Since the Alpha was a relatively new architecture at the time of development, many languages available on other platforms had not been ported yet.
Reference: [33] <author> Stephen Travis Pope. </author> <title> The Interim DynaPiano: An integrated computer tool and instrument for composers. </title> <journal> Computer Music Journal, </journal> <volume> 16(3) </volume> <pages> 1-23, </pages> <month> Fall </month> <year> 1992. </year>
Reference-contexts: Smalltalk is another extensible language that has been extended for use in computer music <ref> [33] </ref>. Smalltalk provides many of the language abstractions that we will discuss as being essential. It is an interpreted, object oriented, multi-threaded lan 17 guage capable of performing incremental compilations, that has been shown to be appropriate for the development of specific musical installations [33, 46]. <p> Smalltalk provides many of the language abstractions that we will discuss as being essential. It is an interpreted, object oriented, multi-threaded lan 17 guage capable of performing incremental compilations, that has been shown to be appropriate for the development of specific musical installations <ref> [33, 46] </ref>. <p> However, because of its large class library, and because it takes over many of the duties of the operating system, implementing the Smalltalk language itself requires too much development time and code to be freely available and portable, particularly on newer, more powerful platforms. <ref> [33] </ref>, for example, describes a system based on Smalltalk that shares many of our goals: "The motivation for the development of IDP is to build a powerful, flexible, and portable computer-based composer's tool and musical instru ment that is affordable by a professional composer (i.e., around the price of a good <p> In particular, complete versions of Smalltalk are not expected to be available on the Alpha for at least another year. Even if a user has access to Smalltalk, an application that relies on this language forces the user to dedicate the whole machine to that environment. <ref> [33] </ref> has achieved the goals it set out for itself, and has proven to be influential within the computer music community. <p> But, having an system with three independently written schedulers is clearly inelegant, and will hopefully be addressed by the POSIX standards at some point, through per-thread (and not just per-process) interrupts. 4.3 The Need for Objects Recently, several systems have proposed using object oriented programming models for computer music projects <ref> [22, 33] </ref>. These systems make the point that an object oriented system provides a facility for abstraction that is extremely important in an environment that has to support the dynamic creation and naming of any kind of module.
Reference: [34] <author> Stephen Travis Pope. </author> <title> Machine tongues XV: Three packages for software sound synthesis. </title> <journal> Computer Music Journal, </journal> <volume> 17(2), </volume> <month> Summer </month> <year> 1993. </year>
Reference-contexts: at the programming model used by these packages, and how they integrate music into the programming system as a whole, rather than, for example, at what they have to say about the nature of musical structure. 2.1 Csound, cmusic, and the Music-N family The Music-N family of computer music systems <ref> [34, 45] </ref> uses a two-tiered approach: One syntax is used to describe how to produce signals or instruments given a set of 11 unit generators, and another is used to describe scores.
Reference: [35] <author> Miller Puckette. </author> <title> Combining event and signal processing in the MAX graphical programming environment. </title> <journal> Computer Music Journal, </journal> <volume> 15(3) </volume> <pages> 68-77, </pages> <month> Fall </month> <year> 1991. </year>
Reference-contexts: These systems include MAX <ref> [35] </ref> and Nyquist [11] (discussed below). MAX is a popular system for specifying note and control level interactions, primarily through MIDI, although signal processing facilities are available on some platforms. It distinguishes itself by using a purely graphical interface. <p> Many systems compensate for this discrepancy by making reasonable assumptions about temporal dependencies based on the existence of functional dependencies. For example, <ref> [35] </ref> describes how MAX uses the convention that one unit generator A will cause another unit generator B to execute (a temporal dependence) if the output of A 24 is connected to the leftmost input of B (a functional dependency).
Reference: [36] <author> H. John Reekie. </author> <title> Visual Haskell: A first attempt. </title> <type> Technical Report 94.5, </type> <institution> University of Technology, Sidney, Key Centre for Advanced Computing Sciences, University of Technology, </institution> <address> Sydney, PO Box 123, Boadway NSW 2007, Australia, </address> <month> August </month> <year> 1994. </year>
Reference-contexts: We note here, however, that specifying interactive temporal behavior and creating a graphical representation of a program written in a functional language are both interesting but open research problems <ref> [2, 36] </ref>. 2.4 The NeXT Music Kit The NeXT Music Kit [22] is an extension to NeXTSTEP that gives the user access to a library of unit generators, and the ability to make patches out of them from within any language that can link to object files, including Objective C and <p> first class objects, support for lazy evaluation, and ability to dynamically compile down to native assembly code, they have recently received attention by people developing systems that, like swish, have to handle the concept of time in an elegant manner. [2] describes a project that uses Haskell for computer animation. <ref> [36] </ref> is the beginnings of a visual interface on top of Haskell, much in the same way that swish provides a graphical interface to the tasks in swish. Nyquist [11] is written in xlisp, and emphasizes the utility of lazy evaluation. <p> This is a principle already used in existing editors/browsers like [37], but it could be done much more elegantly if types were actually built in to Tcl. <ref> [36] </ref> proves this point, and starts raising questions about the right way to represent more complicated types. This is an extremely intriquing area.
Reference: [37] <author> David Richardson. </author> <title> Interactively configuring Tk-based applications. </title> <booktitle> In Proceedings of the Tcl/Tk Workshop, </booktitle> <pages> pages 21-22, </pages> <year> 1994. </year>
Reference-contexts: It has already been shown that a simple program, tkInspect [40], written independently of swish, can be used to examine and modify the current configuration of the tasks. Xf [14] and hierQuery <ref> [37] </ref> are two possible candidates for browsing and editing tools that might be extended to support the manipulation of swish types and tasks. <p> However, if the user decides to look at a dataflow task, then the system would be able to figure out, solely from the typing information, that it should represent this particular task using a dependency graph. This is a principle already used in existing editors/browsers like <ref> [37] </ref>, but it could be done much more elegantly if types were actually built in to Tcl. [36] proves this point, and starts raising questions about the right way to represent more complicated types. This is an extremely intriquing area.
Reference: [38] <author> Adam Sah, Jon Blow, and Brian Dennis. </author> <title> An introduction to the Rush language. </title> <booktitle> In Proceedings of the Tcl/Tk Workshop, </booktitle> <pages> pages 105-116, </pages> <year> 1994. </year>
Reference-contexts: Since Tcl/Tk does not allow the user to create his own kinds of events, an extension such as userevent [18] could be used. Alternatively, a rule-based system, such as that provided by Rush <ref> [38] </ref>, could provide an elegant solution: We could enforce rules that describe how the graphical representation depends on the state of the tasks. Swish's graphical representation is a prototype of a typical Tcl/Tk browsing and 32 editing tool. <p> Before real-time interaction can be specified in a functional language, these issues must be seriously addressed. One final possibility is a dialect of Tcl/Tk currently under development, called Rush <ref> [38] </ref>.
Reference: [39] <author> John A. Sharp. </author> <title> Data Flow Computing. </title> <publisher> Ellis Horwood Limited, </publisher> <year> 1985. </year>
Reference-contexts: If the user is trying to describe the computation of an expression, for example, then the dataflow assumption is generally applicable. However, graphical dataflow machines have traditionally had difficulty describing sophisticated programming constructs, such as control flow, conditionals, and loops ([1] and <ref> [39, chapter 7] </ref>). Methods have been developed to handle these situations. In particular, an apply node can be used to elegantly provide many of these facilities [1, 6, 39]. <p> However, graphical dataflow machines have traditionally had difficulty describing sophisticated programming constructs, such as control flow, conditionals, and loops ([1] and [39, chapter 7]). Methods have been developed to handle these situations. In particular, an apply node can be used to elegantly provide many of these facilities <ref> [1, 6, 39] </ref>. However, when you add the issues that arise because of the use of audio, such as time delays, user events, side effects (audio output, for example), different rates of execution, and asynchronous interactions, the dataflow assumption breaks down very quickly.
Reference: [40] <author> Sam Shen. tkInspect. </author> <note> WWW URL file://harbor.ecn.purdue.edu/pub/code/tkinspect-4d.README. </note>
Reference-contexts: However, it would be worthwhile to investigate incorporating the graphical representations of the tasks and types into a more sophisticated, previously existing browser and editor. It has already been shown that a simple program, tkInspect <ref> [40] </ref>, written independently of swish, can be used to examine and modify the current configuration of the tasks. Xf [14] and hierQuery [37] are two possible candidates for browsing and editing tools that might be extended to support the manipulation of swish types and tasks.
Reference: [41] <author> Donald Sloan. </author> <title> Aspects of music representation in HyTime/SMDL. </title> <journal> Computer Music Journal, </journal> <volume> 17(4) </volume> <pages> 51-59, </pages> <month> Winter </month> <year> 1993. </year>
Reference-contexts: The computer music community is very aware of these developments, and is responding with further research into representations of music appropriate for real-time, net-worked installations [46]. The HyTime/SMDL standards <ref> [41] </ref> being considered by the American National Standards Institute may provide the SGML (standard generalized markup language) that will allow note-level descriptions of music to be passed around on the internet through textual documents. Prof.
Reference: [42] <author> Heinrich Taube. </author> <title> Common Music: A music composition language in Common Lisp and CLOS. </title> <journal> Computer Music Journal, </journal> <volume> 15(2) </volume> <pages> 21-32, </pages> <month> Summer </month> <year> 1991. </year> <month> 62 </month>
Reference-contexts: The NeXT Music Kit The NeXT Music Kit [22] is an extension to NeXTSTEP that gives the user access to a library of unit generators, and the ability to make patches out of them from within any language that can link to object files, including Objective C and Common Music <ref> [42] </ref>. Objective C provides an object oriented environment, so that musical constructs, such as notes or scores, can be described using object classes. <p> Nyquist [11] is written in xlisp, and emphasizes the utility of lazy evaluation. Finally, Common Music <ref> [42] </ref> adds support for objects that represent musical abstractions in CLOS (Common Lisp Object System). However, there are several important mechanisms built into Tcl that simplify applications that use side effects that are not supported by these languages. First, Tcl makes the current state of the interpreter available to scripts.
Reference: [43] <author> D. L. Tennenhouse, J. Adam, D. Carver, H. Houh, M. Ismert, C. Lindblad, W. Stasior, D. Weatherall, D. Bacher, and T. Chang. </author> <title> A software-oriented approach to the design of media processing environments. </title> <booktitle> In Proceedings of the International Conference on Multimedia Computing and Systems, </booktitle> <month> May </month> <year> 1994. </year>
Reference-contexts: They address many of the implementation and scheduling issues facing the developer of an interactive audio package. They include the VuSystem <ref> [43] </ref>, Pacco [7], and Tcl-Me [16]. All of these projects were developed in UNIX, using Tcl.
Reference: [44] <author> Barry Vercoe. Csound: </author> <title> A Manual for the Audio Processing System and Supporting Programs. </title> <publisher> MIT Media Lab, </publisher> <year> 1986. </year>
Reference-contexts: The structure of the two-tiered approach creates a model of computation that provides the composer with a simulation of the hardware found in a traditional music studio, where MIDI instruments or sequencers send triggers to synthesizers and effects boxes. Csound <ref> [44] </ref> and cmusic [29, section 3.2] are two popular members of the Music-N family. Csound provides the user with a powerful library of audio routines that have been proven to be effective in computer music pieces.
Reference: [45] <author> Geraint Wiggins, Eduardo Miranda, Alan Samill, and Mitch Harris. </author> <title> A framework for the evaluation of music representation systems. </title> <journal> Computer Music Journal, </journal> <volume> 17(3) </volume> <pages> 31-42, </pages> <month> Fall </month> <year> 1993. </year>
Reference-contexts: at the programming model used by these packages, and how they integrate music into the programming system as a whole, rather than, for example, at what they have to say about the nature of musical structure. 2.1 Csound, cmusic, and the Music-N family The Music-N family of computer music systems <ref> [34, 45] </ref> uses a two-tiered approach: One syntax is used to describe how to produce signals or instruments given a set of 11 unit generators, and another is used to describe scores.
Reference: [46] <author> Michael Daniel Wu. </author> <title> Responsive sound surfaces. </title> <institution> Master of science in media arts and technology, Massachusetts Institute of Technology, </institution> <month> September </month> <year> 1994. </year> <month> 63 </month>
Reference-contexts: Smalltalk provides many of the language abstractions that we will discuss as being essential. It is an interpreted, object oriented, multi-threaded lan 17 guage capable of performing incremental compilations, that has been shown to be appropriate for the development of specific musical installations <ref> [33, 46] </ref>. <p> The computer music community is very aware of these developments, and is responding with further research into representations of music appropriate for real-time, net-worked installations <ref> [46] </ref>. The HyTime/SMDL standards [41] being considered by the American National Standards Institute may provide the SGML (standard generalized markup language) that will allow note-level descriptions of music to be passed around on the internet through textual documents. Prof.
References-found: 46

