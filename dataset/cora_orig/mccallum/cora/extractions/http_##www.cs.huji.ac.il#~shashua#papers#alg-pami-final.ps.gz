URL: http://www.cs.huji.ac.il/~shashua/papers/alg-pami-final.ps.gz
Refering-URL: http://www.cs.huji.ac.il/labs/vision/research/geometry.html
Root-URL: http://www.cs.huji.ac.il
Title: Algebraic Functions For Recognition  
Author: Amnon Shashua 
Abstract: In the general case, a trilinear relationship between three perspective views is shown to exist. The tri-linearity result is shown to be of much practical use in visual recognition by alignment | yielding a direct reprojection method that cuts through the computations of camera transformation, scene structure and epipolar geometry. Moreover, the direct method is linear and sets a new lower theoretical bound on the minimal number of points that are required for a linear solution for the task of reprojection. The proof of the central result may be of further interest as it demonstrates certain regularities across homographies of the plane and introduces new view invariants. Experiments on simulated and real image data were conducted, including a comparative analysis with epipolar intersection and the linear combination methods, with results indicating a greater degree of robustness in practice and a higher level of performance in re-projection tasks. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E.H. Adelson. </author> <title> Layered representations for image coding. </title> <type> Technical Report 181, </type> <institution> Media Laboratory, Massachusetts Institute of Technology, </institution> <year> 1991. </year>
Reference-contexts: This is clearly a domain where the number of points is not a major concern, whereas simplicity, and robustness (as shown above) due to the short-cut in the computations, is of great importance. Related to image coding, an approach of image decomposition into "layers" was recently proposed by <ref> [1, 2] </ref>. In this approach, a sequence of views is divided up into regions, whose motion of each is described approximately by a 2D affine transformation. The sender sends the first image fol lowed only by the six affine parameters for each region for each subsequent frame.
Reference: [2] <author> E.H. Adelson and J.Y.A. Wang. </author> <title> Layered representation for motion analysis. </title> <booktitle> In Proceedings IEEE Conf. on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 361-366, </pages> <address> New York, NY, </address> <month> June </month> <year> 1993. </year>
Reference-contexts: This is clearly a domain where the number of points is not a major concern, whereas simplicity, and robustness (as shown above) due to the short-cut in the computations, is of great importance. Related to image coding, an approach of image decomposition into "layers" was recently proposed by <ref> [1, 2] </ref>. In this approach, a sequence of views is divided up into regions, whose motion of each is described approximately by a 2D affine transformation. The sender sends the first image fol lowed only by the six affine parameters for each region for each subsequent frame.
Reference: [3] <author> G. Adiv. </author> <title> Inherent ambiguities in recovering 3D motion and structure from a noisy flow field. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> PAMI-11(5):477-489, </volume> <year> 1989. </year>
Reference: [4] <author> P. Anandan. </author> <title> A unified perspective on computational techniques for the measurement of visual motion. </title> <booktitle> In Proceedings Image Understanding Workshop, </booktitle> <pages> pages 219-230, </pages> <address> Los Angeles, CA, Febru-ary 1987. </address> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA. </address>
Reference-contexts: One can readily automate further this process by selecting points in the first frame for which the Hessian matrix of spatial derivatives is well conditioned | similar to the confidence values suggested in the implementations of <ref> [4, 7, 34] </ref> | however, the intention here was not so much as to build a complete system but to test the performance of the trilinear re-projection method and compare it to the performance of epipolar intersection and the linear combination methods.
Reference: [5] <author> I.A. Bachelder and S. Ullman. </author> <title> Contour matching using local affine transformations. </title> <booktitle> In Proceedings Image Understanding Workshop. </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1992. </year>
Reference: [6] <author> E.B. Barrett, M.H. Brill, N.N. Haag, </author> <title> and P.M. Payton. Invariant linear methods in photogrammetry and model-matching. </title> <editor> In J.L. Mundy and A. Zisserman, editors, </editor> <booktitle> Applications of invariances in computer vision. </booktitle> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference: [7] <author> J.R. Bergen and R. Hingorani. </author> <title> Hierarchical motion-based frame rate conversion. </title> <type> Technical report, </type> <institution> David Sarnoff Research Center, </institution> <year> 1990. </year>
Reference-contexts: A set of 34 points were manually selected on one of the frames, 1 , and their correspondences were automatically obtained along all other frames used in this experiment. The correspondence process is based on an implementation of a coarse-to-fine optical-flow algorithm described in <ref> [7] </ref>. To achieve accurate correspondences across distant views, intermediate in-between frames were taken and the displacements across consecutive frames were added. The overall displacement field was then used to push ("warp") the first frame towards the target frame and thus create a synthetic image. <p> One can readily automate further this process by selecting points in the first frame for which the Hessian matrix of spatial derivatives is well conditioned | similar to the confidence values suggested in the implementations of <ref> [4, 7, 34] </ref> | however, the intention here was not so much as to build a complete system but to test the performance of the trilinear re-projection method and compare it to the performance of epipolar intersection and the linear combination methods.
Reference: [8] <author> S. Demey, A. Zisserman, and P. Beardsley. </author> <title> Affine and projective structure from motion. </title> <booktitle> In Proceedings of the British Machine Vision Conference, </booktitle> <month> October </month> <year> 1992. </year>
Reference: [9] <author> R. Dutta and M.A. Synder. </author> <title> Robustness of correspondence based structure from motion. </title> <booktitle> In Proceedings of the International Conference on Computer Vision, </booktitle> <pages> pages 106-110, </pages> <address> Osaka, Japan, </address> <month> De-cember </month> <year> 1990. </year>
Reference: [10] <author> O.D. Faugeras. </author> <title> What can be seen in three dimensions with an uncalibrated stereo rig? In Proceedings of the European Conference on Computer Vision, </title> <address> pages 563-578, Santa Margherita Ligure, Italy, </address> <month> June </month> <year> 1992. </year> <month> 10 </month>
Reference-contexts: To get a better idea of these advantages, we consider briefly the process of re-projection using epipolar geometry. The epipo-lar intersection method can be described succinctly (see [11]) as follows. Let F 13 and F 23 be the matrices ("fundamental" matrices in recent terminology <ref> [10] </ref>) that satisfy p 00 F 13 p = 0, and p 00 F 23 p 0 = 0. <p> In general two views admit a "fundamental" matrix (cf. <ref> [10] </ref>) representing the epipolar geometry between the two views, and whose elements are subject to a cubic constraint (rank of the matrix is 2). The trilinearity results (Theorems 1,2) imply, first, that three views admit a "fundamental" tensor with 27 distinct elements.
Reference: [11] <author> O.D. Faugeras and L. Robert. </author> <title> What can two images tell us about a third one? Technical Report INRIA, </title> <address> France, </address> <year> 1993. </year>
Reference-contexts: Moving away from the need to recover the epipolar geometry carries distinct and significant advantages. To get a better idea of these advantages, we consider briefly the process of re-projection using epipolar geometry. The epipo-lar intersection method can be described succinctly (see <ref> [11] </ref>) as follows. Let F 13 and F 23 be the matrices ("fundamental" matrices in recent terminology [10]) that satisfy p 00 F 13 p = 0, and p 00 F 23 p 0 = 0.
Reference: [12] <author> W.E.L. </author> <title> Grimson. Why stereo vision is not always about 3D reconstruction. </title> <journal> A.I. </journal> <volume> Memo No. </volume> <pages> 1435, </pages> <institution> Artificial Intelligence Laboratory, Massachusetts Institute of Technology, </institution> <month> July </month> <year> 1993. </year>
Reference: [13] <author> R. Hartley, R. Gupta, and T. Chang. </author> <title> Stereo from uncalibrated cameras. </title> <booktitle> In Proceedings IEEE Conf. on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 761-764, </pages> <address> Champaign, IL., </address> <month> June </month> <year> 1992. </year>
Reference: [14] <author> B.K.P. Horn. </author> <title> Relative orientation. </title> <journal> International Journal of Computer Vision, </journal> <volume> 4 </volume> <pages> 59-78, </pages> <year> 1990. </year>
Reference-contexts: The matter of singular surfaces has been studied for the eight-point case necessary for recovering the epipolar geometry <ref> [19, 14, 22] </ref>. The same matter concerning the results presented in this paper is an open problem. Moving away from the need to recover the epipolar geometry carries distinct and significant advantages. To get a better idea of these advantages, we consider briefly the process of re-projection using epipolar geometry.
Reference: [15] <author> B.K.P. Horn. </author> <title> Relative orientation revisited. </title> <journal> Journal of the Optical Society of America, </journal> <volume> 8 </volume> <pages> 1630-1638, </pages> <year> 1991. </year>
Reference: [16] <author> D.P. Huttenlocher and S. Ullman. </author> <title> Recognizing solid objects by alignment with an image. </title> <journal> International Journal of Computer Vision, </journal> <volume> 5(2) </volume> <pages> 195-212, </pages> <year> 1990. </year>
Reference: [17] <author> J.J. Koenderink and A.J. Van Doorn. </author> <title> Affine structure from motion. </title> <journal> Journal of the Optical Society of America, </journal> <volume> 8 </volume> <pages> 377-385, </pages> <year> 1991. </year>
Reference: [18] <author> H.C. Longuet-Higgins. </author> <title> A computer algorithm for reconstructing a scene from two projections. </title> <journal> Nature, </journal> <volume> 293 </volume> <pages> 133-135, </pages> <year> 1981. </year>
Reference: [19] <author> H.C. Longuet-Higgins. </author> <title> the reconstruction of a scene from two projections configurations that defeat the 8-point algorithm. </title> <booktitle> In Proc. of the 1st Conf. AI applications, </booktitle> <pages> pages 395-397, </pages> <address> Den-ver, </address> <month> December </month> <year> 1984. </year>
Reference-contexts: The matter of singular surfaces has been studied for the eight-point case necessary for recovering the epipolar geometry <ref> [19, 14, 22] </ref>. The same matter concerning the results presented in this paper is an open problem. Moving away from the need to recover the epipolar geometry carries distinct and significant advantages. To get a better idea of these advantages, we consider briefly the process of re-projection using epipolar geometry.
Reference: [20] <author> Q.T. Luong, R. Deriche, O.D. Faugeras, and T. Papadopoulo. </author> <title> On determining the fundamental matrix: Analysis of different methods and experimental results. </title> <type> Technical Report INRIA, </type> <institution> France, </institution> <year> 1993. </year>
Reference-contexts: Since linear least squares methods are still sensitive to image noise, we used the implementation of a non-linear method described in <ref> [20] </ref> which was kindly provided by T. Luong and L. Quan (these were two implementations of the method proposed in [20] | in each case, the implementation that provided the better results was adopted). <p> Since linear least squares methods are still sensitive to image noise, we used the implementation of a non-linear method described in <ref> [20] </ref> which was kindly provided by T. Luong and L. Quan (these were two implementations of the method proposed in [20] | in each case, the implementation that provided the better results was adopted). The first experiment is with simulation data showing that even when the epipolar geometry is recovered accurately, it is still significantly better to use the trilinear result which avoids the process of line intersection. <p> Fig. 4. Results of re-projection using intersection of epipolar lines. In the lefthand display the ground plane points were used for recovering the fundamental matrix (see text), and in the righthand display the fundamental matrices were recovered from the implementation of <ref> [20] </ref> using all 34 points across the three views. Maximum displacement error in the lefthand display is 25.7 pixels and average error is 7.7 pixels. Maximal error in the righthand display is 43.4 pixels and average error is 9.58 pixels. <p> Next the epipolar intersection method was applied. We used two methods for recovering the fundamental matrices. One method is by using the implementation of <ref> [20] </ref>, and the other is by taking advantage that four of the corresponding points are coming from a plane (the ground plane). In the former case, much more than eight points were required in order to achieve reasonable results. <p> However, in the presence of errors, the linear solution does not guarantee that the point in P 9 (representing the solution) will lie on the hypersurface, hence a non-admissible solution is obtained. The non-linear solutions proposed by <ref> [20] </ref>, do not address this problem directly, but in practice yield better behaved solutions than the linear ones. Since the trilinear case yields good performance in practice using linear methods, we arrive to the conjecture above.
Reference: [21] <author> Q.T. Luong and T. Vieville. </author> <title> Canonical representations for the geometries of multiple projective views. </title> <type> Technical Report IN-RIA, </type> <institution> France, </institution> <month> fall </month> <year> 1993. </year>
Reference-contexts: In the latter case, we recovered first the homography B due to the ground plane and then the epipole v 00 using two additional points (those on the film cartridges). It is then known (see <ref> [28, 21, 32] </ref>) that F 13 = [v 00 ]B, where [v 00 ] is the anti-symmetric matrix of v 00 . A similar procedure was used to recover F 23 . Therefore, only six points were used for re-projection, 8 Fig. 5.
Reference: [22] <author> S.J. Maybank. </author> <title> The projective geometry of ambiguous surfaces. </title> <journal> Proceedings of the Royal Society of London, </journal> <volume> 332 </volume> <pages> 1-47, </pages> <year> 1990. </year>
Reference-contexts: The matter of singular surfaces has been studied for the eight-point case necessary for recovering the epipolar geometry <ref> [19, 14, 22] </ref>. The same matter concerning the results presented in this paper is an open problem. Moving away from the need to recover the epipolar geometry carries distinct and significant advantages. To get a better idea of these advantages, we consider briefly the process of re-projection using epipolar geometry.
Reference: [23] <author> J. Mundy and A. Zisserman. </author> <title> Appendix | projective geometry for machine vision. </title> <editor> In J. Mundy and A. Zisserman, editors, </editor> <booktitle> Geometric invariances in computer vision. </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, </address> <year> 1992. </year>
Reference: [24] <author> J.L. Mundy, R.P. Welty, M.H. Brill, P.M. Payton, and E.B. Bar-rett. </author> <title> 3-D model alignment without computing pose. </title> <booktitle> In Proceedings Image Understanding Workshop, </booktitle> <pages> pages 727-735. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <month> January </month> <year> 1992. </year>
Reference: [25] <author> A. Shashua. </author> <title> Correspondence and affine shape from two orthographic views: Motion and Recognition. </title> <journal> A.I. </journal> <volume> Memo No. </volume> <pages> 1327, </pages> <institution> Artificial Intelligence Laboratory, Massachusetts Institute of Technology, </institution> <month> December </month> <year> 1991. </year>
Reference: [26] <author> A. Shashua. </author> <title> Geometry and Photometry in 3D visual recognition. </title> <type> PhD thesis, </type> <institution> M.I.T Artificial Intelligence Laboratory, AI-TR-1401, </institution> <month> November </month> <year> 1992. </year>
Reference: [27] <author> A. Shashua. </author> <title> Illumination and view position in 3D visual recognition. </title> <editor> In S.J. Hanson J.E. Moody and R.P. Lippmann, editors, </editor> <booktitle> Advances in Neural Information Processing Systems 4, </booktitle> <pages> pages 404-411. </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann Publishers, </publisher> <year> 1992. </year> <booktitle> Proceedings of the fourth annual conference NIPS, </booktitle> <address> Dec. 1991, Denver, </address> <publisher> CO. </publisher>
Reference: [28] <author> A. Shashua. </author> <title> On geometric and algebraic aspects of 3D affine and projective structures from perspective 2D views. </title> <booktitle> In The 2nd Eu-ropean Workshop on Invariants, </booktitle> <address> Ponta Delagada, Azores, </address> <month> Oc-tober </month> <year> 1993. </year> <note> Also in MIT AI memo No. 1405, </note> <month> July </month> <year> 1993. </year>
Reference-contexts: In the latter case, we recovered first the homography B due to the ground plane and then the epipole v 00 using two additional points (those on the film cartridges). It is then known (see <ref> [28, 21, 32] </ref>) that F 13 = [v 00 ]B, where [v 00 ] is the anti-symmetric matrix of v 00 . A similar procedure was used to recover F 23 . Therefore, only six points were used for re-projection, 8 Fig. 5.
Reference: [29] <author> A. Shashua. </author> <title> Projective depth: A geometric invariant for 3D reconstruction from two perspective/orthographic views and for visual recognition. </title> <booktitle> In Proceedings of the International Conference on Computer Vision, </booktitle> <pages> pages 583-590, </pages> <address> Berlin, Germany, </address> <month> May </month> <year> 1993. </year>
Reference: [30] <author> A. Shashua. </author> <title> Projective structure from uncalibrated images: structure from motion and recognition. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <note> 1994. in press. </note>
Reference: [31] <author> A. Shashua. </author> <title> Trilinearity in visual recognition by alignment. </title> <booktitle> In Proceedings of the European Conference on Computer Vision, </booktitle> <address> Stockholm, Sweden, </address> <month> May </month> <year> 1994. </year>
Reference: [32] <author> A. Shashua and N. Navab. </author> <title> Relative affine structure: Theory and application to 3d reconstruction from perspective views. </title> <booktitle> In Proceedings IEEE Conf. on Computer Vision and Pattern Recognition, </booktitle> <address> Seattle, Washington, </address> <year> 1994. </year>
Reference-contexts: In the latter case, we recovered first the homography B due to the ground plane and then the epipole v 00 using two additional points (those on the film cartridges). It is then known (see <ref> [28, 21, 32] </ref>) that F 13 = [v 00 ]B, where [v 00 ] is the anti-symmetric matrix of v 00 . A similar procedure was used to recover F 23 . Therefore, only six points were used for re-projection, 8 Fig. 5.
Reference: [33] <author> A. Shashua and S. Toelg. </author> <title> The quadric reference surface: Applications in registering views of complex 3d objects. </title> <booktitle> In Proceedings of the European Conference on Computer Vision, </booktitle> <address> Stock-holm, Sweden, </address> <month> May </month> <year> 1994. </year>
Reference: [34] <author> C. Tomasi and T. Kanade. </author> <title> Factoring image sequences into shape and motion. </title> <booktitle> In IEEE Workshop on Visual Motion, </booktitle> <pages> pages 21-29, </pages> <address> Princeton, NJ, </address> <month> September </month> <year> 1991. </year>
Reference-contexts: One can readily automate further this process by selecting points in the first frame for which the Hessian matrix of spatial derivatives is well conditioned | similar to the confidence values suggested in the implementations of <ref> [4, 7, 34] </ref> | however, the intention here was not so much as to build a complete system but to test the performance of the trilinear re-projection method and compare it to the performance of epipolar intersection and the linear combination methods.
Reference: [35] <author> R.Y. Tsai and T.S. Huang. </author> <title> Uniqueness and estimation of three-dimensional motion parameters of rigid objects with curved surface. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> PAMI-6:13-26, </volume> <year> 1984. </year>
Reference: [36] <author> S. Ullman. </author> <title> The Interpretation of Visual Motion. </title> <publisher> MIT Press, </publisher> <address> Cambridge and London, </address> <year> 1979. </year>
Reference: [37] <author> S. Ullman. </author> <title> Aligning pictorial descriptions: an approach to object recognition. </title> <journal> Cognition, </journal> <volume> 32 </volume> <pages> 193-254, </pages> <year> 1989. </year> <note> Also: in MIT AI Memo 931, </note> <month> Dec. </month> <year> 1986. </year>
Reference: [38] <author> S. Ullman and R. Basri. </author> <title> Recognition by linear combination of models. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <note> PAMI-13:992|1006, 1991. Also in M.I.T AI Memo 1052, </note> <year> 1989. </year>
Reference-contexts: The connection between the general result of trilinear functions of views and the "linear combination of views" result <ref> [38] </ref> for orthographic views, can easily be seen by setting A and B to be affine in P 2 , and v 0 3 = v 00 example, (3) reduces to v 0 1 x 0 + (v 00 1 b 1 ) T p = 0; which is of the <p> Thus, in the case where all three views are orthographic, x 00 (y 00 ) is ex pressed as a linear combination of image coordinates of the two other views | as discovered by <ref> [38] </ref>. IV. The Bilinear Form Consider the case for which the two reference (model) views of an object are taken orthographically (using a tele lens would provide a reasonable approximation), but during recognition any perspective view of the object is al lowed. <p> V. Experimental Data The experiments described in this section were done in order to evaluate the practical aspect of using the trilinear result for re-projection compared to using epipolar intersection and the linear combination result of <ref> [38] </ref> (the latter we have shown is simply a limiting case of the trilinear result). The epipolar intersection method was implemented as described in Section III by recovering first the fundamental matrices. <p> A similar procedure was used to recover F 23 . Therefore, only six points were used for re-projection, 8 Fig. 5. Results of re-projection using the linear combination of views method proposed by <ref> [38] </ref> (applicable to parallel projection). Top Row: In the lefthand display the linear coefficients were recovered from four corresponding points; maximal error is 56.7 pixels and average error is 20.3 pixels.
Reference: [39] <author> D. Weinshall. </author> <title> Model based invariants for 3-D vision. </title> <journal> International Journal of Computer Vision, </journal> <volume> 10(1) </volume> <pages> 27-42, </pages> <year> 1993. </year> <title> Amnon Shashua received the B.Sc. degree in Mathematics and Computer Science from Tel-Aviv University, Tel-Aviv, </title> <booktitle> Israel, in 1986; the M.Sc. degree in Mathematics and Computer Science from the Weizmann Institute of Science, Rehovot, Israel, in 1989; and the Ph.D. degree in Computational Neuroscience, working at the Artificial Intelligence Laboratory, </booktitle> <institution> from the Massachusetts Institute of Technology, </institution> <note> in 1993. In 1993 he received a McDonnell-Pew postdoctoral fellowship and is currently at the Artificial Intelligence Laboratory and at the Center for Biological Computational Learning, MIT. 11 </note>
References-found: 39

