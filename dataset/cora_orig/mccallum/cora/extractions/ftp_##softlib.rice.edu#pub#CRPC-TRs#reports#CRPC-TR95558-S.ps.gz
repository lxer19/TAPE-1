URL: ftp://softlib.rice.edu/pub/CRPC-TRs/reports/CRPC-TR95558-S.ps.gz
Refering-URL: http://www.cs.rice.edu:80/~roth/papers.html
Root-URL: 
Title: Optimizing Fortran 90 Shift Operations on Distributed-Memory Multicomputers  
Author: Ken Kennedy, John Mellor-Crummey, and Gerald Roth 
Address: Houston, TX 77005-1892  
Affiliation: Department of Computer Science MS#132, Rice University,  
Abstract: When executing Fortran 90 style data-parallel array operations on distributed-memory multiprocessors, intraprocessor data movement due to shift operations can account for a significant fraction of the execution time. This paper describes a strategy for minimizing data movement caused by Fortran 90 CSHIFT operations and presents a compiler technique that exploits this strategy automatically. The compiler technique is global in scope and can reduce data movement even when a definition of an array and its uses are separated by control flow. This technique supersedes those whose scope is restricted to a single statement. We focus on the application of this strategy on distributed-memory architectures, although it is more broadly applicable.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> J. R. Allen. </author> <title> Dependence Analysis for Subscripted Variables and Its Application to Program Transformations. </title> <type> PhD thesis, </type> <institution> Dept. of Computer Science, Rice University, </institution> <month> April </month> <year> 1983. </year> <month> 1114 </month>
Reference-contexts: Within SSA, modifications and uses of arrays are represented with UPDATE and REFERENCE operators, respectively. Since we are analyzing Fortran 90D programs, we have enhanced these operators to handle array sections by incorporating regular section descriptors (RSDs) <ref> [1] </ref>. In addition to the SSA graph, we generate an interference graph [3]. The interference graph indicates those SSA variables with overlapping live ranges, and is used to check for violations of criteria 1 or 2.
Reference: 2. <author> R. G. Brickner, W. George, S. L. Johnsson, and A. Ruttenberg. </author> <title> A stencil com-piler for the Connection Machine models CM-2/200. </title> <booktitle> In Proceedings of the Fourth Workshop on Compilers for Parallel Computers, </booktitle> <address> Delft, The Netherlands, </address> <month> December </month> <year> 1993. </year>
Reference-contexts: In addition, the checking of interferences is O (i). Here n is the size of the program, e is the number if edges in the SSA graph, and i is the number of edges in the interference graph. 5 Related Work Stencil Compiler: The stencil compiler <ref> [2, 4] </ref> for the CM-2 avoids the memory-to-memory copying for shift operations that occur within specific, stylized, array-assignment statements. These statements, or stencils, must be in the form of a weighted sum of circularly-shifted arrays.
Reference: 3. <author> P. Briggs. </author> <title> Register Allocation via Graph Coloring. </title> <type> PhD thesis, </type> <institution> Dept. of Computer Science, Rice University, </institution> <month> April </month> <year> 1992. </year>
Reference-contexts: Within SSA, modifications and uses of arrays are represented with UPDATE and REFERENCE operators, respectively. Since we are analyzing Fortran 90D programs, we have enhanced these operators to handle array sections by incorporating regular section descriptors (RSDs) [1]. In addition to the SSA graph, we generate an interference graph <ref> [3] </ref>. The interference graph indicates those SSA variables with overlapping live ranges, and is used to check for violations of criteria 1 or 2. The graph is built in the usual manner, but with one exception: all -functions occurring at the same merge point are considered to be executed simultaneously.
Reference: 4. <author> M. Bromley, S. Heller, T. McNerney, and G. Steele, Jr. </author> <title> Fortran at ten gigaflops: The Connection Machine convolution compiler. </title> <booktitle> In Proceedings of the SIGPLAN '91 Conference on Programming Language Design and Implementation, </booktitle> <address> Toronto, Canada, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: In addition, the checking of interferences is O (i). Here n is the size of the program, e is the number if edges in the SSA graph, and i is the number of edges in the interference graph. 5 Related Work Stencil Compiler: The stencil compiler <ref> [2, 4] </ref> for the CM-2 avoids the memory-to-memory copying for shift operations that occur within specific, stylized, array-assignment statements. These statements, or stencils, must be in the form of a weighted sum of circularly-shifted arrays.
Reference: 5. <author> S. Carr. </author> <title> Memory-Hierarchy Management. </title> <type> PhD thesis, </type> <institution> Dept. of Computer Science, Rice University, </institution> <month> September </month> <year> 1992. </year>
Reference-contexts: Finally, to match the performance of the stencil compiler, we would exploit a highly-optimizing node compiler to perform final code generation. Such a compiler would consider the memory hierarchy and attempt to minimize data movement between local memory and registers <ref> [5] </ref>. Scalarizing Compilers: Previous work on Fortran 90D [6], like the stencil compiler, is capable of avoiding some intraprocessor data movement for stylized expressions. In this case, the expressions have to use array syntax. The compiler translates the array syntax expressions into equivalent Fortran 77D code using forall statements.
Reference: 6. <author> A. Choudhary, G. Fox, S. Hiranandani, K. Kennedy, C. Koelbel, S. Ranka, and C.- W. Tseng. </author> <title> Unified compilation of Fortran 77D and 90D. </title> <journal> ACM Letters on Programming Languages and Systems, </journal> <volume> 2(1-4):95-114, </volume> <month> March-December </month> <year> 1993. </year>
Reference-contexts: Finally, to match the performance of the stencil compiler, we would exploit a highly-optimizing node compiler to perform final code generation. Such a compiler would consider the memory hierarchy and attempt to minimize data movement between local memory and registers [5]. Scalarizing Compilers: Previous work on Fortran 90D <ref> [6] </ref>, like the stencil compiler, is capable of avoiding some intraprocessor data movement for stylized expressions. In this case, the expressions have to use array syntax. The compiler translates the array syntax expressions into equivalent Fortran 77D code using forall statements.
Reference: 7. <author> R. Cytron, J. Ferrante, B. Rosen, M. Wegman, and K. Zadeck. </author> <title> Efficiently computing static single assignment form and the control dependence graph. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 13(4) </volume> <pages> 451-490, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: In fact, the CSHIFT operations account for 75% of the total execution time for the largest subgrid. The corresponding number for the OFFSET SHIFT operations is 17%. 4 Offset Array Analysis Our algorithm for determining offset arrays relies upon the static single assignment (SSA) intermediate representation <ref> [7] </ref>. For our purposes, the SSA representation is an analysis framework which is used in conjunction with the control flow graph. Within SSA, modifications and uses of arrays are represented with UPDATE and REFERENCE operators, respectively. <p> The cost of the algorithm is actually dominated by the cost of generating SSA form and building the interference graph, both of which are O (n 2 ) in the worst case (although building SSA is O (n) in practice <ref> [7] </ref>). Once these structures are built, the rest of the algorithm is linear. Finding offsetable arrays is O (n) and their propagation through the program is O (e). In addition, the checking of interferences is O (i).
Reference: 8. <author> R. Fatoohi. </author> <title> Performance analysis of four SIMD machines. </title> <booktitle> In Proceedings of the 1993 ACM International Conference on Supercomputing, </booktitle> <address> Tokyo, Japan, </address> <month> July </month> <year> 1993. </year>
Reference-contexts: The cost of such a shift operation is described by the following model <ref> [8] </ref>: T shift = g (g d) t onpe + C onpe + g d t offpe + C offpe (1) where t onpe and t offpe represent the time to perform an intraprocessor and inter-processor copy respectively, and C onpe and C offpe represent the startup time (or latency) for <p> Table 1 3 presents measured values for each of 3 From Fatoohi <ref> [8] </ref>, c fl1993 ACM. 113 Table 1. Measured cost of communication parameters for a 32-bit word (in sec).
Reference: 9. <author> M. Gerndt. </author> <title> Updating distributed variables in local computations. </title> <journal> Concurrency: Practice and Experience, </journal> <volume> 2(3) </volume> <pages> 171-193, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: In the following subsections, we present criteria for determining when offset arrays are safe and profitable and present the code transformations that avoid intraprocessor copying by exploiting offset arrays. To hold the data that must move between PEs, we use overlap areas <ref> [9] </ref>. Overlap areas are subgrid extensions to hold data received from neighboring PEs. To limit the impact of allocating this permanent storage, we place an upper bound on their size.
Reference: 10. <author> K. Gopinath and J. L. Hennessy. </author> <title> Copy elimination in functional languages. </title> <booktitle> In Proceedings of the Sixteenth Annual ACM Symposium on the Principles of Programming Languages, </booktitle> <address> Austin, TX, </address> <month> January </month> <year> 1989. </year>
Reference-contexts: He then develops a set of value transmission functions that can be used to determine the safety of a destructive use within the language SETL. Gopinath and Hennessy <ref> [10] </ref> address the problem of copy elimination by targeting, or the proper selection of a storage area for evaluating an expression. For the lambda calculus extended with array operation constructs, they develop a set of equations which, when solved iteratively to a fixpoint, specify targets for array parameters and expressions.
Reference: 11. <author> High Performance Fortran Forum. </author> <title> High Performance Fortran language specification. </title> <booktitle> Scientific Programming, </booktitle> <address> 2(1-2):1-170, </address> <year> 1993. </year>
Reference: 12. <author> S. L. Johnsson. </author> <title> Language and compiler issues in scalable high performance scientific libraries. </title> <booktitle> In Proceedings of the Third Workshop on Compilers for Parallel Computers, </booktitle> <address> Vienna, Austria, </address> <month> July </month> <year> 1992. </year>
Reference-contexts: Johnsson previously has noted that "eliminating the local data motion by separating the set of data that must move between nodes from the data that stays within local memory may yield a significant performance improvement" <ref> [12] </ref>. The cost of local data movement becomes more important for distributed arrays as the partition size per processor increases. In this paper, we focus on the problem of minimizing the amount of intra-processor data movement when computing Fortran 90 array operations.
Reference: 13. <author> K. Kennedy and G. Roth. </author> <title> Context optimization for SIMD execution. </title> <booktitle> In Proceedings of the 1994 Scalable High Performance Computing Conference, </booktitle> <address> Knoxville, TN, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: Currently we do not plan to exploit multidimensional and bidirectional communication, since they are exclusive to the CM-2's slicewise model. Although, it would not be difficult to scan adjacent communication operations looking for opportunities. Our context partitioning optimization <ref> [13] </ref> groups together as many such operations as possible, thus maximizing the possibilities of finding such opportunities. Finally, to match the performance of the stencil compiler, we would exploit a highly-optimizing node compiler to perform final code generation.
Reference: 14. <author> K. Knobe, J. Lukas, and M. Weiss. </author> <title> Optimization techniques for SIMD Fortran compilers. </title> <journal> Concurrency: Practice and Experience, </journal> <volume> 5(7) </volume> <pages> 527-552, </pages> <month> October </month> <year> 1993. </year>
Reference-contexts: Besides CSHIFT operations written by users, compilers for distributed-memory machines commonly insert them to perform data movement needed for operations on array sections that have different processor mappings <ref> [14, 15] </ref>.
Reference: 15. <author> G. Sabot. </author> <title> A compiler for a massively parallel distributed memory MIMD computer. </title> <booktitle> In Frontiers '92: The 4th Symposium on the Frontiers of Massively Parallel Computation, </booktitle> <address> McLean, VA, </address> <month> October </month> <year> 1992. </year>
Reference-contexts: Besides CSHIFT operations written by users, compilers for distributed-memory machines commonly insert them to perform data movement needed for operations on array sections that have different processor mappings <ref> [14, 15] </ref>.
Reference: 16. <author> P. Schnorf, M. Ganapathi, and J. Hennessy. </author> <title> Compile-time copy elimination. </title> <journal> Software|Practice and Experience, </journal> <volume> 23(11) </volume> <pages> 1175-1200, </pages> <month> November </month> <year> 1993. </year>
Reference-contexts: For the lambda calculus extended with array operation constructs, they develop a set of equations which, when solved iteratively to a fixpoint, specify targets for array parameters and expressions. Unfortunately, solving their equations to a fixpoint is at least exponential in time. Schnorf et al. <ref> [16] </ref> describe their efforts to eliminate aggregate copies in the single-assignment language SISAL. Their work analyzes edges in a data flow graph and attempts to determine when edges, representing values, may share storage.
Reference: 17. <author> J. T. Schwartz. </author> <title> Optimization of very high level languages I. Value transmission and its corollaries. </title> <journal> Computer Languages, </journal> <volume> 1(2) </volume> <pages> 161-194, </pages> <year> 1975. </year> <title> This article was processed using the L a T E X macro package with LLNCS style 1115 </title>
Reference-contexts: Any full modification of DST which kills the whole array does not require the copy of SRC and thus DST may still be treated as an offset array up to the point of the killing definition. 114 From the work on copy elimination in functional and higher-order program-ming languages <ref> [17] </ref>, we know that the above two criteria are necessary and sufficient conditions for when the two objects can share the same storage. However, the sharing of storage may not always be profitable. To insure profitability, we add the following efficiency criteria: 3. <p> Naive compilation of such languages causes the insertion of many copy operations of aggregate objects to maintain program semantics. It is imperative that compilers for such languages eliminate a majority of the unnecessary copies if they hope to generate efficient code. This task is known as copy optimization. Schwartz <ref> [17] </ref> characterizes the task of copy optimization as the destructive use (reuse) of an object v at a point P in the program where it can be shown that all other objects that may contain v are dead at P .
References-found: 17

