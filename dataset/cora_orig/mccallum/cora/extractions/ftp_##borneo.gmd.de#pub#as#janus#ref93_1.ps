URL: ftp://borneo.gmd.de/pub/as/janus/ref93_1.ps
Refering-URL: http://borneo.gmd.de/AS/janus/publi/publi.html
Root-URL: 
Title: Learning from Examples, Agent Teams and the Concept of Reflection  
Author: Uwe Beyer Frank Smieja 
Note: Report number: 1993/1  
Abstract: In International Journal of Pattern Recognition and AI, 10(3):251-272, 1996 Also available as GMD report #766 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> U. Beyer and F. J. Smieja. </author> <title> Quantitative aspects of data-driven information processing. </title> <type> Technical Report 732, </type> <institution> GMD German National Research Center for Information Technology, </institution> <address> Sankt Augustin, Germany, </address> <month> March </month> <year> 1993. </year>
Reference-contexts: 1 Introduction "Learning from examples" is the construction of a model of a process using information obtained from observed instances of the process <ref> [6, 1] </ref>. There are various types of learning from examples, depending on what is to be modeled, the information that is available and the modeling assumptions that are made. <p> assumed that the confidence-like principle on which the method must operate obeys to a greater or lesser extent the condition expressed below: A ff (M 0 ) A ff (M); (13) where M 0 = f (x; y) j c ff (x) &gt; ; (x; y) 2 Mg; where 2 <ref> [0; 1] </ref> is an arbitrarily chosen threshold value. In other words, the accuracy based on the test set defined by those patterns not rejected should be significantly higher than that based on the test set including all patterns. (The confidence reliability used = 0:5).
Reference: [2] <author> Belur V. Dasarathy. </author> <title> Nearest Neighbor (NN) Norms: NN Pattern Classification Techni Teams and Reflection 17 ques. </title> <publisher> IEEE Computer Society Press, </publisher> <address> Los Alamos, </address> <year> 1986. </year>
Reference-contexts: However, here the information is only used to provide a global confidence in an estimation process, and not an individual confidence for every subsequent estimate produced by the process. 4.3 Construction of learn confidence functions 4.3.1 Example 1: Geometrical reasoning Consider an agent using the k-nearest neighbor (kNN) <ref> [2] </ref> method to form a discrete function discriminating m classes. The confidence can be produced by geometric reasoning [15] in the following way. An input question x is compared with the fx i g stored during the learning process.
Reference: [3] <author> A. P. Dempster. </author> <title> Upper and lower probabilities induced by a multivalued mapping. </title> <journal> Annals of Mathematical Statistics, </journal> <volume> 38 </volume> <pages> 325-339, </pages> <year> 1967. </year>
Reference-contexts: Sets of classifiers can be combined using such probabilities [12, 5], but generally in a nonadaptive way. The parameters needed to be de termined for the combination are fixed statistically or by using evidence <ref> [3] </ref> or belief [20]. In order that a team work, its constituting members should possess a minimum level of confidence reliability.
Reference: [4] <author> B. Efron. </author> <title> Bootstrap methods: Another look at the jackknife. </title> <journal> The Annals of Statistics, </journal> <volume> 7(1) </volume> <pages> 1-26, </pages> <year> 1979. </year>
Reference-contexts: It is an expensive and non-dynamic way of generating a confidence function. The idea itself is in a similar vogue to "bootstrap" methods used by statisticians <ref> [4] </ref> for Teams and Reflection 7 estimating sampling distributions.
Reference: [5] <author> J. Franke and E. Mandler. </author> <title> A comparison of two approaches for combining the votes of cooperating classifiers. </title> <booktitle> In Proceedings of the 11th IAPR, </booktitle> <pages> pages 611-614, </pages> <address> Den Haag, Netherlands, </address> <year> 1992. </year>
Reference-contexts: Here the agents produce real decision values of whether an input x represents a class k, which are transformed into a posteriori probabilities p (kjx) that the class is k. Sets of classifiers can be combined using such probabilities <ref> [12, 5] </ref>, but generally in a nonadaptive way. The parameters needed to be de termined for the combination are fixed statistically or by using evidence [3] or belief [20]. In order that a team work, its constituting members should possess a minimum level of confidence reliability.
Reference: [6] <author> S. Geman, E. Bienenstock, and R. Doursat. </author> <title> Neural networks and the bias/variance dilemma. </title> <journal> Neural Computation, </journal> <volume> 4 </volume> <pages> 1-58, </pages> <year> 1992. </year>
Reference-contexts: 1 Introduction "Learning from examples" is the construction of a model of a process using information obtained from observed instances of the process <ref> [6, 1] </ref>. There are various types of learning from examples, depending on what is to be modeled, the information that is available and the modeling assumptions that are made.
Reference: [7] <author> J. B. Hampshire and B. A. Pearlmutter. </author> <title> Equivalence proofs for multi-layer perceptron classifiers and the bayesian discriminant function. </title> <editor> In Touretzky, Elman, Se-jnowski, and Hinton, editors, </editor> <booktitle> Proceedings of the 1990 Connectionist Models Summer School, </booktitle> <address> San Mateo, CA, 1990. </address> <publisher> Morgan Kauf-mann. </publisher>
Reference-contexts: The subscript on the patterns in the picture indicates the class they represent. 8 Beyer and Smieja 4.3.2 Example 2: Feed-forward neural network A feed-forward neural network with real output nodes naturally produces confidences for a classification task <ref> [7, 16] </ref>. The confidence is simply formed by extending the discrete class answer to a set of relative probabilities between classes.
Reference: [8] <author> S. Hubrig-Schaumburg. </author> <title> Handwritten character recognition using a reflective modular neural network system, </title> <month> November </month> <year> 1992. </year>
Reference-contexts: Confined to the domain of the single reagent, confidence serves to increase the reliability of the approximator <ref> [8, 17] </ref>. Overall accuracy is, however, not increased in the reflection process. The question remaining is how to increase the overall accuracy of a model. As mentioned in section 3, we see two ways: either brute-force learning or a modular architecture.
Reference: [9] <author> R. A. Jacobs and M. I. Jordan. </author> <title> Adaptive mixtures of local experts. </title> <journal> Neural Computation, </journal> <volume> 3(1), </volume> <year> 1991. </year>
Reference-contexts: There exist in the literature various team architectures employing non-reflective agents <ref> [9, 18, 10, 28, 27] </ref>. Some are built during the construc 10 Beyer and Smieja tion of the individual agent models themselves, thus involving two levels of model (agent and team) being simultaneously optimized.
Reference: [10] <author> K. Joe, Y. Mori, and S. Miyake. </author> <title> Construction of a large-scale neural network: simulation of handwritten Japanese character recognition on NCUBE. </title> <journal> Concurrency, Practice and Experience, </journal> <volume> 2(2) </volume> <pages> 79-107, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: There exist in the literature various team architectures employing non-reflective agents <ref> [9, 18, 10, 28, 27] </ref>. Some are built during the construc 10 Beyer and Smieja tion of the individual agent models themselves, thus involving two levels of model (agent and team) being simultaneously optimized.
Reference: [11] <author> A. Linden and F. Weber. </author> <title> Implementing inner drive by competence reflection. </title> <booktitle> In Proceedings of the 2nd International Conference on Simulation of Adaptive Behavior, Hawaii, </booktitle> <year> 1992. </year>
Reference-contexts: When the tuples (x; y) are chosen by the agent itself (and not, for example, by a teacher) the process is called exploration <ref> [29, 11] </ref>. The following quantities can be defined for an agent. Model accuracy. An agent is graded by the accuracy of its predictions. This may be estimated statistically by comparing a set of its predictions with events in the real world.
Reference: [12] <author> E. Mandler and J. Schurmann. </author> <title> Combining the classification results of independent classifiers based on the Dempster-Schafer theory of evidence. </title> <editor> In E. S. Gelsema and L. N. Kanal, editors, </editor> <booktitle> Pattern Recognition and artificial intelligence, </booktitle> <pages> pages 381-394. </pages> <publisher> Elsevier Science Publishers B. V. (North-Holland), </publisher> <address> Amsterdam, </address> <year> 1988. </year>
Reference-contexts: Here the agents produce real decision values of whether an input x represents a class k, which are transformed into a posteriori probabilities p (kjx) that the class is k. Sets of classifiers can be combined using such probabilities <ref> [12, 5] </ref>, but generally in a nonadaptive way. The parameters needed to be de termined for the combination are fixed statistically or by using evidence [3] or belief [20]. In order that a team work, its constituting members should possess a minimum level of confidence reliability.
Reference: [13] <author> H. Muhlenbein and D. Schlierkamp-Voosen. </author> <title> Predictive models for the breeder genetic algorithm: Continuous parameter optimization. </title> <journal> Evolutionary Computation, </journal> <volume> 1, </volume> <year> 1993. </year>
Reference-contexts: This represents the fifth consideration in the modeling process, the approximation or optimization process O (this includes the initialization of the free parameters). There are a range of methods that may be used for this optimization process, including simulated annealing, genetic algorithms <ref> [13] </ref> and neural networks. Neural networks normally represent methods employing harmonic or hyperbolic basis functions (a sigmoid is a hyperbolic construct), and generally combinations. The parameters to optimize are the "weights", or f i g above. The learning procedure is the method used to adjust these tunable parameters.
Reference: [14] <institution> National Institute of Standards and Technology. OCR-system conference. </institution> <type> Technical Report NISTIR 4912, NIST, </type> <address> Gaithersburg MD, </address> <month> August </month> <year> 1992. </year>
Reference-contexts: The exemplars were obtained from the National Institute of Science and Technology (NIST) database <ref> [14] </ref>. The scanned images were transformed to 16x16 dimensional gray-scale x values with 26 dimensional N-class output coding for the associated y values. This determined the distillation D for all agents. The learn set L consisted of 4616 tuples randomly chosen from the database.
Reference: [15] <author> Stephen Omohundro. </author> <title> Geometric learning algorithms. </title> <type> Technical Report TR-89-041, </type> <institution> Berkeley, </institution> <year> 1989. </year>
Reference-contexts: The confidence can be produced by geometric reasoning <ref> [15] </ref> in the following way. An input question x is compared with the fx i g stored during the learning process. Each exemplar i has associated with it an output y i . In a classification process there are a finite number of different outputs.
Reference: [16] <author> N. Otsu. </author> <title> Nonlinear discriminant analysis as a natural extension of the linear case. </title> <journal> Be-haviormetrika, </journal> (2):24-59, 1975. 
Reference-contexts: The subscript on the patterns in the picture indicates the class they represent. 8 Beyer and Smieja 4.3.2 Example 2: Feed-forward neural network A feed-forward neural network with real output nodes naturally produces confidences for a classification task <ref> [7, 16] </ref>. The confidence is simply formed by extending the discrete class answer to a set of relative probabilities between classes.
Reference: [17] <author> T. L. D. Regulinski. </author> <title> On reliability of expert systems. </title> <journal> IEEE Transactions on Reliability, </journal> <note> 40(4):401, 1991. Editorial. </note>
Reference-contexts: Confined to the domain of the single reagent, confidence serves to increase the reliability of the approximator <ref> [8, 17] </ref>. Overall accuracy is, however, not increased in the reflection process. The question remaining is how to increase the overall accuracy of a model. As mentioned in section 3, we see two ways: either brute-force learning or a modular architecture.
Reference: [18] <author> D. L. Reilly, C. Scofield, C. Elbaum, and L. N. Cooper. </author> <title> Learning system archictectu-res composed of multiple learning modules. </title> <booktitle> In IEEE First International Conference on Neural Networks, </booktitle> <pages> pages 495-503, </pages> <year> 1987. </year>
Reference-contexts: There exist in the literature various team architectures employing non-reflective agents <ref> [9, 18, 10, 28, 27] </ref>. Some are built during the construc 10 Beyer and Smieja tion of the individual agent models themselves, thus involving two levels of model (agent and team) being simultaneously optimized.
Reference: [19] <author> D. E. Rumelhart, G. E. Hinton, and R. J. Williams. </author> <title> Learning internal representations by error propagation. </title> <journal> Nature, </journal> <volume> 323(533), </volume> <year> 1986. </year>
Reference-contexts: The parameters to optimize are the "weights", or f i g above. The learning procedure is the method used to adjust these tunable parameters. The typical example is back propagation <ref> [19] </ref>, although other methods are frequently employed, such as conjugate gradient, Newton-Raphson and second order gradient descent. The difficulty of the approximation task is dependent not only on the complexity of G, but also on the R; B; C and O used in the model. <p> Figure 3a shows this effect for an upper-case letter recognition agent. The agent employed pixel coding (16 fi 16 input patterns) with a sigmoid-based feed-forward neural network, and the approximation was carried out using the back-propagation procedure <ref> [19] </ref>. The test set used to measure the accuracy was held constant, and was disjunct from all the learn sets. The curve shows the best accuracy achieved as a function of the number of exemplars used in the approximation.
Reference: [20] <editor> P. Smets, E. Mamdani, D. Dubois, and H. Prade, editors. </editor> <booktitle> Non-standard Logics for Automated Reasoning, chapter Belief Functions, </booktitle> <pages> pages 253-286. </pages> <publisher> Academic Press, </publisher> <year> 1988. </year>
Reference-contexts: We will show in section 5 how such a continuous-valued rejection function such as confidence provides extra information about the agent's model, which can be used to compare and combine a number of agents. One may alternatively interpret confidence as an indication as to the amount of "belief" <ref> [20] </ref> that should be placed in the current approximation. Eqn. (6) states that reflection is the generation of an inner model of the reliability of the modeling process itself. <p> Sets of classifiers can be combined using such probabilities [12, 5], but generally in a nonadaptive way. The parameters needed to be de termined for the combination are fixed statistically or by using evidence [3] or belief <ref> [20] </ref>. In order that a team work, its constituting members should possess a minimum level of confidence reliability. Otherwise the areas where the answer from one agent should better be used than that of another will only rarely be found, and the desired synergy will not be attained.
Reference: [21] <author> F. J. Smieja. </author> <title> Multiple network systems (MI-NOS) modules: Task division and module discrimination. </title> <booktitle> In Proceedings of the 8th AISB conference on Artificial Intelligence, 18 Beyer and Smieja Leeds, </booktitle> <month> 16-19 April, </month> <year> 1991, 1991. </year> <note> Also available as GMD technical report 638. </note>
Reference-contexts: s (x) (see Figure 6), the confidence c k (x) for the class k is given by: c k (x) = P (12) For a non-classification task, there is no obvious way in which confidence may be derived from a feed-forward network. 4.3.3 Example 3: MINOS reagent A MINOS reagent <ref> [21, 25] </ref> is constructed from two agent modules, called Worker and Monitor (see Figure 7). The Worker learns the mapping f ff (x) and the Monitor learns the confidence c ff (x). The Worker is generally taken to be a feed-forward neural network.
Reference: [22] <author> F. J. Smieja. </author> <title> Neural network constructive algorithms: Trading generalization for learning efficiency? Circuits, </title> <journal> Systems and Signal Processing, </journal> <volume> 12(2) </volume> <pages> 331-374, </pages> <year> 1993. </year>
Reference-contexts: Additionally, the nature of the approximation iteration, O, will lead to characteristic forms of solution. (As an example, neural network construction algorithms might be expected to produce solutions with more "exceptions" than the standard back-propagation algorithm <ref> [22] </ref>). For these reasons, one might envisage a combination of agents with different models to allow better modeling of the process than a single agent. In order to enable such a process, one must decide on the way in which the predictions from the various agents are to be combined.
Reference: [23] <author> F. J. Smieja. </author> <title> Rejection of incorrect answers from a neural net classifier. </title> <editor> In J. Mira, J. Cabestany, and A. Prieto, editors, </editor> <booktitle> New Trends in Neural Computation (Proceedings of the IWANN 93). </booktitle> <publisher> Springer Verlag, </publisher> <year> 1993. </year> <note> Lecture Notes in Computer Science 686. </note>
Reference-contexts: The function is adaptable and is fitted to the learn set data L. The confidence can be seen as a generalization of a rejection function <ref> [23] </ref>, which could be constructed from confidence by introducing a threshold confidence value above which the agent's prediciton is accepted and below which it is rejected. <p> Rejec Teams and Reflection 9 tion methods <ref> [23] </ref> are widely used in all serious pattern recognition applications, and it is implicitly assumed that the confidence-like principle on which the method must operate obeys to a greater or lesser extent the condition expressed below: A ff (M 0 ) A ff (M); (13) where M 0 = f (x;
Reference: [24] <author> F. J. Smieja. </author> <title> The Pandemonium system of reflective agents. </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> 7(1) </volume> <pages> 97-106, </pages> <year> 1996. </year>
Reference-contexts: If it is a feed-forward neural network, the Monitor learns incrementally to map an x to f0; 1g, depending on whether or not the tuple (x; y) is being learned by the Worker. Thus as each new (x; y) tuple is seen, the confidence is adapted. See <ref> [24] </ref> for further information about how the Pandemonium system performs on particular problem domains.
Reference: [25] <author> F. J. Smieja and H. Muhlenbein. </author> <title> Reflective modular neural network systems. </title> <type> Technical Report 633, </type> <institution> GMD German National Research Center for Information Technology, </institution> <address> Sankt Augustin, Germany, </address> <month> February </month> <year> 1992. </year>
Reference-contexts: s (x) (see Figure 6), the confidence c k (x) for the class k is given by: c k (x) = P (12) For a non-classification task, there is no obvious way in which confidence may be derived from a feed-forward network. 4.3.3 Example 3: MINOS reagent A MINOS reagent <ref> [21, 25] </ref> is constructed from two agent modules, called Worker and Monitor (see Figure 7). The Worker learns the mapping f ff (x) and the Monitor learns the confidence c ff (x). The Worker is generally taken to be a feed-forward neural network.
Reference: [26] <author> G. Wahba, C. Gu, Y. Wang, and R. Chap-pell. </author> <title> Soft classification, a.k.a. risk estimation, via penalized log likelihood and smoothing spline analysis of variance. </title> <type> Technical Report 899, </type> <institution> University of Wisconsin, </institution> <month> Janu-ary </month> <year> 1993. </year>
Reference-contexts: The instrumentation B describes the basis functions that are to be employed to fit the model to the observed data, and how they are to be combined. The possible functions can be neatly classified into five broad groups: polynomial, harmonic, hyperbolic, probabilistic <ref> [26] </ref> and rule-based (Table 1). The process B generates a number of free parameters f i g (general examples of which are indicated in the table). The combination C represents the way in which the basis functions are combined to form the model's function f .
Reference: [27] <author> A. Waibel. </author> <title> Modular construction of time-delay neural networks for speech recognition. </title> <journal> Neural Computation, </journal> <volume> 1, </volume> <year> 1989. </year>
Reference-contexts: There exist in the literature various team architectures employing non-reflective agents <ref> [9, 18, 10, 28, 27] </ref>. Some are built during the construc 10 Beyer and Smieja tion of the individual agent models themselves, thus involving two levels of model (agent and team) being simultaneously optimized. <p> This may lead to quicker solutions for certain problems, but is not so promising for performance on the test set (what is to be done at the boundaries between agents?). Waibel <ref> [27] </ref> deals with this problem by cementing the cracks with a "connectionist glue", whereby the whole system is further adapted at the team level after the agents have been combined.
Reference: [28] <author> D. H. Wolpert. </author> <title> Stacked generalization. </title> <type> Technical Report LA-UR-90-3460, </type> <address> LANL, Los Alamos, NM, </address> <year> 1990. </year>
Reference-contexts: There exist in the literature various team architectures employing non-reflective agents <ref> [9, 18, 10, 28, 27] </ref>. Some are built during the construc 10 Beyer and Smieja tion of the individual agent models themselves, thus involving two levels of model (agent and team) being simultaneously optimized. <p> Waibel [27] deals with this problem by cementing the cracks with a "connectionist glue", whereby the whole system is further adapted at the team level after the agents have been combined. This is similar to the general "stacked generalization" strategy <ref> [28] </ref> of second stage adaptation at the team level, except in the latter the constituting agents are not adapted further. The Waibel method is only then feasible when the constituting agents are all of the same type (e.g. neural networks). Table 2 summarizes the basic team strategies. <p> Class of team Non-adaptive Adaptive Non-reflective Majority vote Simultaneous agent and team optimization Static modularization of input space Stacked Generalization Reflective Winner-takes-all Stacked Generalization Table 2: Types of team architectures. 12 Beyer and Smieja Stacked generalization <ref> [28] </ref> is in general the method of second phase learning. The agents used in the team are held fixed, and a further agent learns to associate their collected answers with the actual answer, using a further learn set C, known as the calibration set. Another model is the majority vote.
Reference: [29] <author> Byoung-Tak Zhang and Gerd Veenker. </author> <title> Neural networks that teach themselves through genetic discovery of novel examples. </title> <booktitle> In International Joint Conference on Neural Networks (IJCNN-91), </booktitle> <volume> Vol 1, </volume> <pages> pages 690-695. </pages> <publisher> IEEE and INNS, </publisher> <year> 1991. </year>
Reference-contexts: When the tuples (x; y) are chosen by the agent itself (and not, for example, by a teacher) the process is called exploration <ref> [29, 11] </ref>. The following quantities can be defined for an agent. Model accuracy. An agent is graded by the accuracy of its predictions. This may be estimated statistically by comparing a set of its predictions with events in the real world.
References-found: 29

