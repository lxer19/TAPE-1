URL: http://www.cl.cam.ac.uk:80/ftp/papers/reports/TR326-sll-network.storage.architecture.ps.gz
Refering-URL: http://www.cl.cam.ac.uk:80/ftp/papers/reports/
Root-URL: 
Abstract-found: 0
Intro-found: 1
Reference: [AOG92] <author> David P. Anderson, Yoshitomo Osawa, and Ramesh Govindan. </author> <title> A file system for continuous media. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 10(4) </volume> <pages> 311-337, </pages> <month> November </month> <year> 1992. </year> <note> (cited on pages 99, 120) </note>
Reference-contexts: THE PERFORMANCE OF THE BSC 8 Rate-Based Sessions: Concept & Interface 8.1 Introduction In this chapter, the storage of continuous-medium data is considered. Early work in this area [Cal87] [TS87] only deals with voice storage. The bandwidth requirement of this medium type is low. Recent work [RV91] <ref> [AOG92] </ref> [GC92] [LS93] that deals with high bandwidth media, such as video, concentrates mainly on the hard real-time scheduling of disk transfers. Little attention has been given to the issue of system integration. <p> Given a method to estimate the service time, it is possible to derive algorithms to schedule read-ahead actions for simultaneous sessions. Indeed, research work (e.g. [RV91] <ref> [AOG92] </ref> [GC92] [LS93]) has been done in this area and scheduling algorithms have been derived. The research projects take into account of (1) and (2) listed above but none of them considers the effect of (3).
Reference: [ASTvR86] <author> S. J. Mullender A. S. Tanenbaum and R. van Renesse. </author> <title> Using sparse capabilities in a distributed operating system. </title> <booktitle> In Proceeding of the 6th International Conference on Distributed Computing Systems, </booktitle> <pages> pages 558-563. </pages> <publisher> IEEE, </publisher> <month> May </month> <year> 1986. </year> <note> (cited on page 43) </note>
Reference-contexts: The signature 4.3. AUTHENTICATION 43 is generated by passing the other contents of the capability and a secret number held by the server through a one-way function. Any tampered-with or forged capabilities would have wrong signatures. Amoeba <ref> [ASTvR86] </ref> is an example that uses this form of capabilities. In a distributed environment, servers cannot control where capabilities are stored and how and to whom they are copied. A malicious intruder can intercept all the data packets on an Ethernet and copy capabilities from these packets.
Reference: [Bac86] <author> Maurice J. Bach. </author> <title> The Design of the UNIX Operating System. </title> <booktitle> Prentice-Hall International, </booktitle> <year> 1986. </year> <note> ISBN 0-13-201757-1 025. (cited on page 6) </note>
Reference-contexts: Transaction support was considered a useful mechanism to prevent inconsistencies arising from machine and communication failures or concurrent access to files by other clients. Felix [FO81], XDFS [SMI80], Alpine [BKT85], Swallow [Svo81] are examples of such systems. Since then, the UNIX-style byte stream file model <ref> [Bac86] </ref> [MJLF84] [POS90] has been adopted by most distributed file systems. None of these provides direct transaction support. As the systems are mainly used for program development and engineering applications, this is considered a reasonable tradeoff between high performance and the possible danger of having occasional data inconsistency.
Reference: [BAD + 92] <author> Mary Baker, Satoshi Asami, Etienne Deprit, John Ousterhout, and Margo Seltzer. </author> <title> Non-volatile memory for fast, reliable file systems. </title> <booktitle> In Proceedings of the fifth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 10-22, </pages> <month> October </month> <year> 1992. </year> <note> (cited on page 96) </note>
Reference-contexts: The implementation is simple and the recovery process can be completed in a very short time (section 7.1.3). 96 7. THE PERFORMANCE OF THE BSC 7.2.2 Performance Studies This work has not studied empirically the performance benefit of NVRAM caching with real workloads. However, other work [RW93] <ref> [BAD + 92] </ref> has used data collected on working systems to analyse the effect of NVRAM caching. Their results show that even a small NVRAM cache can bring about significant performance improvement. Ruemmler and Wilkes [RW93] use trace-driven simulations to analyse the effect of write caching at the disk level. <p> They also determine what percentage of writes could be absorbed for a given amount of NVRAM. In 30 second intervals, 95% absorption is reached at 700 Kbytes (workstation), 1 Mbytes (server) and 4 Mbytes (timesharing system). Baker et al. <ref> [BAD + 92] </ref> study the use of NVRAM as file caches on client workstations and on file servers. They use traces obtained from a Sprite distributed file system to drive their simulations.
Reference: [BBLP86] <author> Jean-Pierre Ban atre, Michel Ban atre, Guy Lapalme, and Flo-rimond Ployette. </author> <title> The design and building of enchere, a distributed electronic marketing system. </title> <journal> Communications of the ACM, </journal> <volume> 29(1) </volume> <pages> 19-29, </pages> <month> January </month> <year> 1986. </year> <note> (cited on page 74) 137 138 . BIBLIOGRAPHY </note>
Reference-contexts: With the advent of new microprocessors [Sit92] [KH92] that support 64-bit virtual address space, the sparseness of the address space may be sufficient to catch any run-away software errors. Other solutions [HCHJ91] <ref> [BBLP86] </ref> have been reported in the literature. This work does not investigate NVRAM protection. However, the design would still be valid with any NVRAM protection scheme as long as the NVRAM remains byte addressable. 6.4 Metadata This section describes the organisation of the BSC's metadata on disk.
Reference: [BFH + 67] <author> D. W. Barron, A. G. Fraser, D. F. Hartley, B. Landy, and R. M. Needham. </author> <title> File handling at cambridge university. </title> <booktitle> In Proceedings of AFIPS Spring Joint Computer Conference, </booktitle> <pages> pages 163-167. </pages> <booktitle> The American Federation of Information Processing Societies, </booktitle> <month> May </month> <year> 1967. </year> <note> (cited on page 46) </note>
Reference-contexts: Instead, MSSA uses negative rights included in ACLs to indicate the denial of the specific rights. Negative rights take precedence over positive rights. Titan <ref> [BFH + 67] </ref> allows a file owner to deny a particular principal the access right while permitting other principals to access the file.
Reference: [Bhu71] <author> A K Bhushan. </author> <title> File Transfer Protocol. Request for comments 114, </title> <booktitle> National Information Center, </booktitle> <month> April </month> <year> 1971. </year> <note> Not online. Updated by RFC 141, RFC 172, RFC 171. (cited on page 5) </note>
Reference-contexts: Users were fully aware of the distinction between local and remote files, both in naming convention and permitted operations. Today, this approach is no longer regarded as a distributed file system. Nevertheless, file transfer programs such as FTP <ref> [Bhu71] </ref> and FTAM [fta85] are still used to share files, especially over national or global networks. 5 6 2. BACKGROUND The ability to perform the same set of operations on both local and remote files was soon recognised as an important property of distributed file systems.
Reference: [BKT85] <author> Mark Brown, Karen Kolling, and Edward Taft. </author> <title> The Alpine File System. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 3(4) </volume> <pages> 261-293, </pages> <month> November </month> <year> 1985. </year> <note> (cited on pages 6, 67) </note>
Reference-contexts: In the early 80s, there was considerable interest in providing atomic transactions and concurrency control in distributed file systems. Transaction support was considered a useful mechanism to prevent inconsistencies arising from machine and communication failures or concurrent access to files by other clients. Felix [FO81], XDFS [SMI80], Alpine <ref> [BKT85] </ref>, Swallow [Svo81] are examples of such systems. Since then, the UNIX-style byte stream file model [Bac86] [MJLF84] [POS90] has been adopted by most distributed file systems. None of these provides direct transaction support. <p> Conversely, other custodes that interact with the BSC do not need to take any actions other than to invoke the interrupted operations again. 6.2.3 NVRAM and Atomic Updates The performance cost of atomic updates can be high. Early work [Dio80] [FO81] <ref> [BKT85] </ref> [SMI80] that investigates transaction support in network file systems all extract a high performance cost in exchange for atomicity. In contrast, this design has the potential to achieve high performance because it has made several design trade-offs. These trade-offs are discussed below.
Reference: [BMTW91] <author> Jean Bacon, Ken Moody, Sue Thomson, and Tim Wilson. </author> <title> A multi-service storage architecture. </title> <journal> ACM Operating Systems Review, </journal> <volume> 25(4) </volume> <pages> 47-65, </pages> <month> October </month> <year> 1991. </year> <note> (cited on page 64) </note>
Reference-contexts: The custode may not be accessible at that moment. The issue of existence control will not be addressed in this dissertation. Current work in the Computer Laboratory includes an investigation to solve this problem based on periodic refreshing <ref> [BMTW91] </ref>. 5.4 Summary This chapter gave the reasons for choosing identifiers, instead of textual names, to name files. Identifiers are generated in a uniform way. They are fixed-length, location independent and suitable for embedding in composite objects. Resolving names in multiple layers is a problem specific to MSSA.
Reference: [BRAC91] <author> A. Lester Buck and Jr. Robert A. Coyne. </author> <title> Dynamic hierarchies and optimization in distributed storage systems. </title> <booktitle> In The 11th IEEE Mass Storage Symposium, </booktitle> <pages> pages 85-91, </pages> <year> 1991. </year> <note> (cited on page 16) </note>
Reference-contexts: Wilkes and State [WS91] propose a similar conceptual framework to allow users to specify data availability requirements in a device and location independent way. The storage systems are responsible for matching the requirements with the appropriate storage strategy. Buck and Coyne <ref> [BRAC91] </ref> propose a distributed storage system that supports transparent data migration in a storage hierarchy consisting of disk, robotic tape (or WORM jukeboxes) and human operated tape vaults. The work emphasizes dynamic specification of file migration paths.
Reference: [Bur88] <author> Michael Burrows. </author> <title> Efficient data sharing. </title> <type> Technical Report 153, </type> <institution> University of Cambridge Computer Laboratory, </institution> <month> December </month> <year> 1988. </year> <booktitle> The author's PhD thesis. (cited on pages 6, </booktitle> <pages> 8) </pages>
Reference-contexts: In most NFS implementations, data are used directly from the cache if it has been validated within some time period, usually a few seconds. Andrew [HKM + 88], MFS <ref> [Bur88] </ref> and Sprite [NWO88], developed around the same time, adopt different write-sharing models and assume a different granularity of sharing. Hence the cache consistency protocols of the three designs are quite different. A comparison of the relative merits of the various cache consistency protocols is contained in [Bur88]. <p> + 88], MFS <ref> [Bur88] </ref> and Sprite [NWO88], developed around the same time, adopt different write-sharing models and assume a different granularity of sharing. Hence the cache consistency protocols of the three designs are quite different. A comparison of the relative merits of the various cache consistency protocols is contained in [Bur88]. The availability of distributed file systems has been a concern of researchers for many years. LOCUS [WPE + 83] is an early example which 1 This refers to workstations which have local disks set up as virtual memory paging store and/or temporary file systems only. 2.3. <p> BACKGROUND because these were thought to be the common characteristics of data sharing in a DCE. Although the derivative of AFS OSF DEcorum [KLA + 91] and other caching file systems <ref> [Bur88] </ref> [NWO88] support strict single-system semantics, these systems are likely to operate efficiently only if the degree of concurrent sharing is low. Some research work on improving the performance of file systems relies heavily on the observed access patterns to make the design tradeoffs.
Reference: [CAK + 92] <author> Sailesh Chutani, Owen T. Anderson, Michael L. Kazar, Bruce W. Leverett, W. Anothony Mason, and Robert N. Sidebotham. </author> <title> The episode file system. </title> <booktitle> In Proceedings of USENIX Winter Conference, </booktitle> <pages> pages 43-60. </pages> <publisher> USENIX, </publisher> <month> January </month> <year> 1992. </year> <note> (cited on pages 66, 95) </note>
Reference-contexts: Moreover, a system that recovers by rolling back to a previous consistent state may do so by undoing some operations that have been completed and positively acknowledged. File systems, such as the (re-implemented) Cedar [Hag87] file system, Episode <ref> [CAK + 92] </ref>, JFS [CMR + 90] and Sprite LFS [RO91], that use the logging [Gra79] technique to maintain consistency, are examples that exhibit this kind of behaviour. <p> In the BSD file system, all directories and inodes (file metadata) have to be scanned to detect and repair any inconsistencies. The cost of these scans is already high (tens of minutes in typical configurations), and it is getting higher as storage systems expand. Other file systems [Hag87] <ref> [CAK + 92] </ref> [CMR + 90], which use logs to record metadata updates, can recover in a much shorter time. However, they are likely to be somewhat more complicated than the BSD file system. In contrast, the BSC only needs to scan the NVRAM buffer on recovery.
Reference: [Cal87] <author> R. S. Calnan. </author> <title> Island: A distributed multimedia system. </title> <booktitle> In Proceedings of IEEE Globecom'87, </booktitle> <pages> pages 744-748, </pages> <address> Tokyo, </address> <month> November </month> <year> 1987. </year> <booktitle> (cited on pages 6, </booktitle> <volume> 99, </volume> <pages> 101) </pages>
Reference-contexts: The CFS was used to support two file systems (Tripos [RN83] and the CAP filing system [Del80]), an object-based file store [Cra86] and a digital voice store <ref> [Cal87] </ref>. Since the mid-80s, researchers have explored the use of data caching on diskless or dataless 1 workstations to improve the performance of remote file serving. The cache consistency problem is addressed in different ways depending on the models of data sharing adopted by the different designs. <p> THE PERFORMANCE OF THE BSC 8 Rate-Based Sessions: Concept & Interface 8.1 Introduction In this chapter, the storage of continuous-medium data is considered. Early work in this area <ref> [Cal87] </ref> [TS87] only deals with voice storage. The bandwidth requirement of this medium type is low. Recent work [RV91] [AOG92] [GC92] [LS93] that deals with high bandwidth media, such as video, concentrates mainly on the hard real-time scheduling of disk transfers. <p> If the problems with protection and security can be solved, users may even be able to download their own translators. This opens up new possibilities to extend the functions of the storage service. The idea of customising a generic storage service with translators has its precedent. Roger Calnan <ref> [Cal87] </ref> implements a voice storage service over a general purpose filing system. He also calls this voice service a translator and proposes that a video translator could be built for storing video data.
Reference: [CH91] <author> Greg Cockroft and Leo Howritz. Nextstep: </author> <title> Putting JPEG to multiple users. </title> <journal> Communications of the ACM, </journal> <volume> 34(4):45, </volume> <month> April </month> <year> 1991. </year> <note> (cited on page 10) 139 </note>
Reference-contexts: The proliferation of digital video standards presents another problem to continuous-medium data storage. As Liebhold [LH91] points out, there are a number of digital video standards, some for full-bandwidth video and some for compressed representations (CD-I [Inc89], DVI [Lut91], JPEG [Wal91] <ref> [CH91] </ref>, MPEG [Gal91], px64 [Lio91]). The variety of formats means that the timing information necessary for the timely delivery of data is encoded in different ways. It is a challenge to design a storage service that can cope 2.5. SUPPORT OF STRUCTURED DATA 11 with this diversity.
Reference: [CKKS89] <author> George Copeland, Tom Keller, Ravi Krishnamurthy, and Marc Smith. </author> <title> The case for safe ram. </title> <booktitle> In Proceedings of the Fifteenth International Conference on Very Large Data Bases, </booktitle> <year> 1989. </year> <note> (cited on page 67) </note>
Reference: [CMR + 90] <author> A. Chang, M. F. Mergen, R. K. Rader, J. A. Roberts, and S. L. Porter. </author> <title> Evolution of storage facilities in AIX version 3 for RISC System/6000 processors. </title> <journal> IBM Journal of Research and Development, </journal> <volume> 34(1) </volume> <pages> 103-105, </pages> <month> January </month> <year> 1990. </year> <note> (cited on pages 66, 95) </note>
Reference-contexts: Moreover, a system that recovers by rolling back to a previous consistent state may do so by undoing some operations that have been completed and positively acknowledged. File systems, such as the (re-implemented) Cedar [Hag87] file system, Episode [CAK + 92], JFS <ref> [CMR + 90] </ref> and Sprite LFS [RO91], that use the logging [Gra79] technique to maintain consistency, are examples that exhibit this kind of behaviour. This is because the tail of the logs in these systems are kept in volatile memory and are lost when the systems fail. <p> The cost of these scans is already high (tens of minutes in typical configurations), and it is getting higher as storage systems expand. Other file systems [Hag87] [CAK + 92] <ref> [CMR + 90] </ref>, which use logs to record metadata updates, can recover in a much shorter time. However, they are likely to be somewhat more complicated than the BSD file system. In contrast, the BSC only needs to scan the NVRAM buffer on recovery.
Reference: [Cra86] <author> Stephen Christopher Crawley. </author> <title> The Entity system: An object-based filing system. </title> <type> Technical Report 86, </type> <institution> University of Cam-bridge, </institution> <month> April </month> <year> 1986. </year> <type> The author's Phd thesis. </type> <note> (cited on page 6) </note>
Reference-contexts: The CFS was used to support two file systems (Tripos [RN83] and the CAP filing system [Del80]), an object-based file store <ref> [Cra86] </ref> and a digital voice store [Cal87]. Since the mid-80s, researchers have explored the use of data caching on diskless or dataless 1 workstations to improve the performance of remote file serving.
Reference: [CS92] <author> Scott Carson and Sanjeev Setia. </author> <title> Optimal write batch size in log-structured file systems. </title> <booktitle> In Proceedings of USENIX File Systems Workshop, </booktitle> <pages> pages 79-91. </pages> <publisher> USENIX, </publisher> <month> May </month> <year> 1992. </year> <note> (cited on page 93) </note>
Reference-contexts: Even if there is no hardware restrictions on the I/O size, extremely large disk writes can cause potentially unacceptable delay to any (synchronous) disk reads that queue up behind them. Carson and Setia <ref> [CS92] </ref> analytically derive the optimal write size that minimises read response time.
Reference: [Del80] <author> Carl Dellar. </author> <title> Removing backing store administration from the CAP operating system. </title> <journal> ACM Operating Systems Review, </journal> <volume> 14(4) </volume> <pages> 41-49, </pages> <month> October </month> <year> 1980. </year> <note> (cited on page 6) </note>
Reference-contexts: The Cambridge design is a capability-based virtual disc system augmented with a naming substrate which provides the desired coherency without committing the clients to any specific directory structures or textual name conventions. The CFS was used to support two file systems (Tripos [RN83] and the CAP filing system <ref> [Del80] </ref>), an object-based file store [Cra86] and a digital voice store [Cal87]. Since the mid-80s, researchers have explored the use of data caching on diskless or dataless 1 workstations to improve the performance of remote file serving.
Reference: [DH66] <author> J. B. Dennis and E. C. Van Horn. </author> <title> Programming semantics for multiprogrammed computations. </title> <journal> Comunications of the ACM, </journal> <volume> 9(3) </volume> <pages> 143-155, </pages> <month> March </month> <year> 1966. </year> <note> (cited on page 42) </note>
Reference-contexts: Propagating access rights from one subject to another can be difficult to express. Capabilities An alternative way to represent the access matrix is to have each principal associated with a list of objects it has rights to access. Each element in the list is a capability <ref> [DH66] </ref>. When an access is requested by a principal, the capability is presented to verify that the access right does exist. Capabilities are like tickets in real life. A theatre ticket alone is a sufficient proof of the right to watch a performance.
Reference: [Dio80] <author> Jeremy Dion. </author> <title> The Cambridge File Server. </title> <journal> ACM Operating Systems Review, </journal> <volume> 14(4) </volume> <pages> 26-35, </pages> <month> October </month> <year> 1980. </year> <booktitle> (cited on pages 6, </booktitle> <volume> 42, 56, </volume> <pages> 67) </pages>
Reference-contexts: None of these provides direct transaction support. As the systems are mainly used for program development and engineering applications, this is considered a reasonable tradeoff between high performance and the possible danger of having occasional data inconsistency. The Cambridge File Server (CFS) <ref> [Dio80] </ref>, developed in the early 80s, differed from other designs in the same period in one significant respect. The Cambridge design is a capability-based virtual disc system augmented with a naming substrate which provides the desired coherency without committing the clients to any specific directory structures or textual name conventions. <p> Capabilities must be unforgeable. If object identifiers are chosen from a very large set of numbers and there is no practical way to deduce an identifier by guessing or by testing with randomly generated patterns, these identifiers may be used as capabilities. The Cambridge file server <ref> [Dio80] </ref> use this form of identifier as file capabilities. However, the access right associated with such an identifier cannot be further restricted. Hence, it is not suitable for passing on to other principals if the principal holding the capability wants to limit their individual rights. <p> The task of providing a directory tree is left to some MSSA client. These clients are likely to be servers themselves. Using identifiers to name stored objects is not new, for instance, the Cambridge File Server (CFS) <ref> [Dio80] </ref> uses 64-bit UIDs to name files. Nevertheless, there are several considerations that support this choice and not all of them are relevant to previous work: Service extensibility Firstly, the immediate clients of the storage service may not be tools directed by users, as in conventional file systems. <p> Conversely, other custodes that interact with the BSC do not need to take any actions other than to invoke the interrupted operations again. 6.2.3 NVRAM and Atomic Updates The performance cost of atomic updates can be high. Early work <ref> [Dio80] </ref> [FO81] [BKT85] [SMI80] that investigates transaction support in network file systems all extract a high performance cost in exchange for atomicity. In contrast, this design has the potential to achieve high performance because it has made several design trade-offs. These trade-offs are discussed below.
Reference: [Dix91] <author> Micheal Joseph Dixon. </author> <title> System support for multi-service traffic. </title> <type> Technical Report 245, </type> <institution> Computer Laboratory, University of Cambridge, </institution> <month> September </month> <year> 1991. </year> <type> The author's Phd thesis. </type> <note> (cited on page 85) </note>
Reference-contexts: Once a command is started, the main processor is relieved of any further action 86 6. THE DESIGN OF A BYTE SEGMENT CUSTODE until the command is completed. The prototype runs as a user-space process on top of the WANDA kernel <ref> [Dix91] </ref>. The kernel supports multiple pre-emptive threads per process. The IPC mechanism is designed to minimise the cost of data copying. A set of physically contiguous buffers are mapped into the user address space. Data are transferred between the network interface and the buffers directly.
Reference: [EGLT76] <author> K.P. Eswaran, J.N. Gray, R.A. Lorie, </author> <title> and I.L. Traiger. The notions of consistency and predicate locks in a database system. </title> <journal> Communications of the ACM, </journal> 19(11) 624-633, November 1976. (cited on page <volume> 68) </volume> 140 . BIBLIOGRAPHY 
Reference-contexts: These transactions are called NVRAM transactions because they are performed using a NVRAM buffer. Eswaran et al. <ref> [EGLT76] </ref>, define a transaction as a sequence of actions which, when executed, transform a system from a consistent state into a new consistent state.
Reference: [ES92] <author> Robert M. English and Alexander A. Stepanov. Loge: </author> <title> a self-organizing disk controller. </title> <booktitle> In Proceedings of USENIX Winter Conference, </booktitle> <pages> pages 237-241. </pages> <publisher> USENIX, </publisher> <month> January </month> <year> 1992. </year> <note> (cited on page 94) </note>
Reference-contexts: Perhaps in the long term, disks should be made more intelligent to handle the scheduling and even data organisation decisions, like the self organising disk proposed by <ref> [ES92] </ref>. Nowadays, capable microprocessors are cheap enough to be put to control disk drives. It will be interesting to see whether these devices can perform the data placement and scheduling functions better than the high-level software. This section has presented some preliminary measurements of the BSC performance.
Reference: [FO81] <author> Marek Fridrich and W. </author> <title> Older. The FELIX File Server. </title> <booktitle> In The Eighth Symposium on Operating Systems Principles, </booktitle> <pages> pages 37-44. </pages> <publisher> ACM, </publisher> <month> December </month> <year> 1981. </year> <note> (cited on pages 6, 67) </note>
Reference-contexts: In the early 80s, there was considerable interest in providing atomic transactions and concurrency control in distributed file systems. Transaction support was considered a useful mechanism to prevent inconsistencies arising from machine and communication failures or concurrent access to files by other clients. Felix <ref> [FO81] </ref>, XDFS [SMI80], Alpine [BKT85], Swallow [Svo81] are examples of such systems. Since then, the UNIX-style byte stream file model [Bac86] [MJLF84] [POS90] has been adopted by most distributed file systems. None of these provides direct transaction support. <p> Conversely, other custodes that interact with the BSC do not need to take any actions other than to invoke the interrupted operations again. 6.2.3 NVRAM and Atomic Updates The performance cost of atomic updates can be high. Early work [Dio80] <ref> [FO81] </ref> [BKT85] [SMI80] that investigates transaction support in network file systems all extract a high performance cost in exchange for atomicity. In contrast, this design has the potential to achieve high performance because it has made several design trade-offs. These trade-offs are discussed below.
Reference: [fta85] <author> Open systems interconnection: </author> <title> File transfer, access and management iso/dis/8571. </title> <publisher> British Standards Institution DD113, </publisher> <year> 1985. </year> <note> (cited on page 5) </note>
Reference-contexts: Users were fully aware of the distinction between local and remote files, both in naming convention and permitted operations. Today, this approach is no longer regarded as a distributed file system. Nevertheless, file transfer programs such as FTP [Bhu71] and FTAM <ref> [fta85] </ref> are still used to share files, especially over national or global networks. 5 6 2. BACKGROUND The ability to perform the same set of operations on both local and remote files was soon recognised as an important property of distributed file systems.
Reference: [Gal91] <author> Didier Le Gall. </author> <title> MPEG: A video compression standard for multimedia applications. </title> <journal> Communications of the ACM, </journal> <volume> 34(4) </volume> <pages> 46-58, </pages> <month> April </month> <year> 1991. </year> <note> (cited on page 10) </note>
Reference-contexts: The proliferation of digital video standards presents another problem to continuous-medium data storage. As Liebhold [LH91] points out, there are a number of digital video standards, some for full-bandwidth video and some for compressed representations (CD-I [Inc89], DVI [Lut91], JPEG [Wal91] [CH91], MPEG <ref> [Gal91] </ref>, px64 [Lio91]). The variety of formats means that the timing information necessary for the timely delivery of data is encoded in different ways. It is a challenge to design a storage service that can cope 2.5. SUPPORT OF STRUCTURED DATA 11 with this diversity.
Reference: [GC92] <author> J. Gemmell and S. Christodoulakis. </author> <title> Principles of delay-sensitive multimedia data storage and retrieval. </title> <journal> ACM Transaction on Information System, </journal> <volume> 10(1) </volume> <pages> 51-90, </pages> <month> January </month> <year> 1992. </year> <note> (cited on pages 99, 120) </note>
Reference-contexts: THE PERFORMANCE OF THE BSC 8 Rate-Based Sessions: Concept & Interface 8.1 Introduction In this chapter, the storage of continuous-medium data is considered. Early work in this area [Cal87] [TS87] only deals with voice storage. The bandwidth requirement of this medium type is low. Recent work [RV91] [AOG92] <ref> [GC92] </ref> [LS93] that deals with high bandwidth media, such as video, concentrates mainly on the hard real-time scheduling of disk transfers. Little attention has been given to the issue of system integration. <p> Given a method to estimate the service time, it is possible to derive algorithms to schedule read-ahead actions for simultaneous sessions. Indeed, research work (e.g. [RV91] [AOG92] <ref> [GC92] </ref> [LS93]) has been done in this area and scheduling algorithms have been derived. The research projects take into account of (1) and (2) listed above but none of them considers the effect of (3).
Reference: [Gel89] <author> J. P. Gelb. </author> <title> System-managed storage. </title> <journal> IBM Systems Journal, </journal> <volume> 28(1) </volume> <pages> 77-103, </pages> <month> January </month> <year> 1989. </year> <note> (cited on page 15) </note>
Reference-contexts: The user level names are overloaded with the data placement function. This could be in direct conflict with the users' logical views of data organisation. Also, this rules out any storage resource optimisation that could be done by the storage systems. This is what Gelb <ref> [Gel89] </ref> characterises as user-managed storage, i.e. users 16 2. BACKGROUND server functions independently. The logical names of files are often statically mapped to physical storage devices. have too little information and too much control. Gelb advocates another mode of storage management which he calls system-managed storage.
Reference: [GJSJ91] <author> David K. Gifford, Pierre Jouvelot, Mark A. Sheldon, and James W. O'Toole Jr. </author> <title> Semantic file systems. </title> <booktitle> In Proceedings of 13th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 16-25. </pages> <institution> Association for Computing Machinery SIGOPS, </institution> <month> October </month> <year> 1991. </year> <note> (cited on page 12) </note>
Reference-contexts: In relation to this problem, some researchers [Sal91] [Sat91] have suggested that it will be very useful to extend the file system by adding associative search or indexing functions. An interesting piece of work in this area is the semantic file system by Gif-ford et al. <ref> [GJSJ91] </ref>, which provides associative access to attributes extracted from the contents of files. Many tools exist for associative search and indexing. A simple example is the UNIX command grep which searches for the occurrence of some regular expression in some files.
Reference: [Gon89] <author> Li Gong. </author> <title> A secure identity-based capability system. </title> <booktitle> In Proceeding of the 1989 Symposium on Security and Privacy, </booktitle> <pages> pages 56-63. </pages> <publisher> IEEE, </publisher> <month> May </month> <year> 1989. </year> <note> (cited on pages 43, 51) </note>
Reference-contexts: A malicious intruder can intercept all the data packets on an Ethernet and copy capabilities from these packets. In other words, the propagation of capabilities can neither be controlled nor traced by the servers. Gong <ref> [Gon89] </ref> proposes the identity-based capability scheme which allows servers to limit the propagation of capabilities. The identity of the principal that can use a capability is embedded in the capability. The capability is made unforgeable in a similar way as the Amoeba scheme. <p> Similarly, changing the container secret number would revoke all the (per-container and per-file) capabilities associated with the container. Undoubtedly, the revocation mechanism is rather draconic. It is not possible to revoke capabilities for a file immediately and selectively. However, capability revocation is known to be a difficult problem. Gong <ref> [Gon89] </ref> proposes a revocation mechanism that requires an exception list be associated with an object. Revoked capabilities for an object are stored in the exception list. In an access, both the validity of the capability and the exception list are checked to prevent the use of revoked capabilities.
Reference: [Gra79] <editor> J.N. Gray. </editor> <booktitle> Notes on database operating systems. In Operating Systems: An Advanced Course, volume 80 of Lecture Notes in Computer Science, </booktitle> <pages> pages 393-481. </pages> <publisher> Springer-Verlag, </publisher> <year> 1979. </year> <booktitle> (cited on pages 66, </booktitle> <volume> 68) 141 </volume>
Reference-contexts: File systems, such as the (re-implemented) Cedar [Hag87] file system, Episode [CAK + 92], JFS [CMR + 90] and Sprite LFS [RO91], that use the logging <ref> [Gra79] </ref> technique to maintain consistency, are examples that exhibit this kind of behaviour. This is because the tail of the logs in these systems are kept in volatile memory and are lost when the systems fail. <p> This is usually called the atomic property of transactions. A common technique to implement the all-or-nothing property of transactions is called the two-phase commit <ref> [Gra79] </ref>. The central idea behind any two-phase commit algorithm is that a transaction is made atomic by 6.3. NVRAM TRANSACTIONS 69 performing it in two phases.
Reference: [Hag87] <author> Robert Hagmann. </author> <title> Reimplementing the Cedar file system using logging and group commit. </title> <booktitle> In Proceedings of the 11th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 155-162, </pages> <address> Austin TX (USA), </address> <month> November </month> <year> 1987. </year> <booktitle> ACM. (cited on pages 66, </booktitle> <pages> 95) </pages>
Reference-contexts: Moreover, a system that recovers by rolling back to a previous consistent state may do so by undoing some operations that have been completed and positively acknowledged. File systems, such as the (re-implemented) Cedar <ref> [Hag87] </ref> file system, Episode [CAK + 92], JFS [CMR + 90] and Sprite LFS [RO91], that use the logging [Gra79] technique to maintain consistency, are examples that exhibit this kind of behaviour. <p> In the BSD file system, all directories and inodes (file metadata) have to be scanned to detect and repair any inconsistencies. The cost of these scans is already high (tens of minutes in typical configurations), and it is getting higher as storage systems expand. Other file systems <ref> [Hag87] </ref> [CAK + 92] [CMR + 90], which use logs to record metadata updates, can recover in a much shorter time. However, they are likely to be somewhat more complicated than the BSD file system. In contrast, the BSC only needs to scan the NVRAM buffer on recovery.
Reference: [HBM + 89] <author> Andy Hisgen, Andrew Birrell, Timothy Mann, Michael Schroeder, and Garret Swart. </author> <title> Availability and Consistency Tradeoffs in the Echo Distributed File System. </title> <booktitle> In The 2nd Workshop of Workstation Operating Systems, </booktitle> <pages> pages 49-54, </pages> <address> Pacific Grove, CA, </address> <month> September </month> <year> 1989. </year> <note> IEEE. (cited on page 7) </note>
Reference-contexts: LIMITATIONS OF TODAY'S DISTRIBUTED FILE SYSTEMS 7 combined replication and an algorithm to detect inconsistency to achieve high availability. In the past few years, there has been considerable interest in using file replication to achieve high availability. Echo <ref> [HBM + 89] </ref>, Coda [SKK + 90], Harp [LGG + 91] and Deceit [SBM89] are examples of highly available distributed file systems. The systems differ from earlier designs in that they are all Unix-style file systems and have combined client caching with server replication.
Reference: [HCHJ91] <author> Chris Horn, Brian Coghan, Neville Harris, and Jeremy Jones. </author> <title> Stable memory another look. </title> <editor> In A. Karshmer and J. Nehmer, editors, </editor> <booktitle> International Workshop on Operating Systems of the 90s and Beyond, number 563 in Lecture Notes in Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1991. </year> <note> (cited on page 74) </note>
Reference-contexts: With the advent of new microprocessors [Sit92] [KH92] that support 64-bit virtual address space, the sparseness of the address space may be sufficient to catch any run-away software errors. Other solutions <ref> [HCHJ91] </ref> [BBLP86] have been reported in the literature. This work does not investigate NVRAM protection. However, the design would still be valid with any NVRAM protection scheme as long as the NVRAM remains byte addressable. 6.4 Metadata This section describes the organisation of the BSC's metadata on disk.
Reference: [HKM + 88] <author> John H. Howard, Michael L. Kazar, Sherri G. Menees, David A. Nichols, M. Satyanarayanan, Robert N. Sidebotham, and Michael J. West. </author> <title> Scale and performance in a distributed file system. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 6(1) </volume> <pages> 51-81, </pages> <note> Febru-ary 1988. (cited on pages 6, 7) </note>
Reference-contexts: Sun's Network File System (NFS) [Sun89] does not define clearly what guarantees the system makes about the consistency of the client caches. In most NFS implementations, data are used directly from the cache if it has been validated within some time period, usually a few seconds. Andrew <ref> [HKM + 88] </ref>, MFS [Bur88] and Sprite [NWO88], developed around the same time, adopt different write-sharing models and assume a different granularity of sharing. Hence the cache consistency protocols of the three designs are quite different. <p> The implicit assumption is that the client access pattern exhibits good locality of reference and client caches are large enough to achieve a high hit rate. Also, the cache consistency protocols assume low levels of concurrent write-sharing. For instance, the early version of AFS <ref> [HKM + 88] </ref> only supports whole file caching and sequential write sharing 8 2. BACKGROUND because these were thought to be the common characteristics of data sharing in a DCE.
Reference: [Hop90] <author> Andy Hopper. </author> <title> An experimental system for multimedia applications. </title> <journal> ACM Operating Systems Review, </journal> <volume> 24(2), </volume> <month> April </month> <year> 1990. </year> <note> (cited on page 99) </note>
Reference-contexts: The bandwidth requirement of this medium type is low. Recent work [RV91] [AOG92] [GC92] [LS93] that deals with high bandwidth media, such as video, concentrates mainly on the hard real-time scheduling of disk transfers. Little attention has been given to the issue of system integration. Working systems <ref> [Hop90] </ref> or prototypes [Jar92] are mostly designed to serve in a specific environment and lack the flexibility to offer a general purpose service. In contrast, this work looks at the storage issue from a different angle.
Reference: [Inc89] <author> Philips International Inc. </author> <title> Compact Disc- Interactive. </title> <publisher> McGraw-Hill Book Company, </publisher> <year> 1989. </year> <note> (cited on page 10) </note>
Reference-contexts: The proliferation of digital video standards presents another problem to continuous-medium data storage. As Liebhold [LH91] points out, there are a number of digital video standards, some for full-bandwidth video and some for compressed representations (CD-I <ref> [Inc89] </ref>, DVI [Lut91], JPEG [Wal91] [CH91], MPEG [Gal91], px64 [Lio91]). The variety of formats means that the timing information necessary for the timely delivery of data is encoded in different ways. It is a challenge to design a storage service that can cope 2.5.
Reference: [Jar92] <author> Paul W. Jardetzky. </author> <title> Network file server design for continuous media. </title> <type> Technical Report 268, </type> <institution> Computer Laboratory, University of Cambridge, </institution> <month> October </month> <year> 1992. </year> <booktitle> The author's PhD thesis. (cited on pages 99, </booktitle> <pages> 103) </pages>
Reference-contexts: Recent work [RV91] [AOG92] [GC92] [LS93] that deals with high bandwidth media, such as video, concentrates mainly on the hard real-time scheduling of disk transfers. Little attention has been given to the issue of system integration. Working systems [Hop90] or prototypes <ref> [Jar92] </ref> are mostly designed to serve in a specific environment and lack the flexibility to offer a general purpose service. In contrast, this work looks at the storage issue from a different angle. <p> This approach ensures better synchronisation because local delay and jitter can be determined and controlled more accurately. It might be beneficial to reduce the skew between two synchronised streams by coordinating their starting time. For this purpose, a group operation <ref> [Jar92] </ref> could be added to the translator to start multiple streams simultaneously. The above discussion has established the context in which rate-based sessions are used.
Reference: [JW91] <author> David M. Jacobson and John Wikes. </author> <title> Disk scheduling algorithms based on rotational position. </title> <type> Technical Report HPL-CSP-91-7, </type> <institution> Hewlett-Packard Laboratories, </institution> <month> February </month> <year> 1991. </year> <note> (cited on page 94) 142 . BIBLIOGRAPHY </note>
Reference-contexts: It seems that a SATF scheduling algorithm that takes both seek and rotation position into account could do a better job (SATF stands for shortest access time first <ref> [JW91] </ref>). However, such an algorithm cannot be used in the high-level software because low-level device details, such as the position of the disk head, are simply not available.
Reference: [KH92] <author> Gerry Kane and Joe Heinrich. </author> <title> MIPS Risc architecture. </title> <publisher> Prentice-Hall, Inc, </publisher> <year> 1992. </year> <note> ISBN 0-13-590472-2. (cited on page 74) </note>
Reference-contexts: METADATA 75 hardware/software faults. However, the result is not conclusive and does not show any apparent reduction in the corruption rate when the protection scheme is enabled. With the advent of new microprocessors [Sit92] <ref> [KH92] </ref> that support 64-bit virtual address space, the sparseness of the address space may be sufficient to catch any run-away software errors. Other solutions [HCHJ91] [BBLP86] have been reported in the literature. This work does not investigate NVRAM protection.
Reference: [KLA + 91] <author> Michael L Kazar, Bruce W Leverett, Owen T Anderson, Vasilis Apostolides, Beth A Bottos, Sailesh Chutani, Craig F Everhart, W Anthony Mason, Shu-Tsui Tu, and Edward R Zayas. </author> <title> DEcorum file system architectural overview. </title> <booktitle> In Summer 1991 USENIX Conference. USENIX Association, </booktitle> <year> 1991. </year> <note> (cited on page 7) </note>
Reference-contexts: For instance, the early version of AFS [HKM + 88] only supports whole file caching and sequential write sharing 8 2. BACKGROUND because these were thought to be the common characteristics of data sharing in a DCE. Although the derivative of AFS OSF DEcorum <ref> [KLA + 91] </ref> and other caching file systems [Bur88] [NWO88] support strict single-system semantics, these systems are likely to operate efficiently only if the degree of concurrent sharing is low.
Reference: [Knu73] <author> Donald E. Knuth. </author> <booktitle> The Art of Computer Programming, </booktitle> <volume> volume 1. </volume> <publisher> Addison-Wesley, </publisher> <address> 2 edition, </address> <year> 1973. </year> <note> (cited on page 85) </note>
Reference-contexts: Hence, the I/O queues are implemented as leftist trees which is an efficient way to represent priority queues in the form of linked binary trees (due to C. A. Crane and detailed in <ref> [Knu73] </ref>). The insertion time is only of order log 2 N. The best case occurs when the tree is linear, and the worst case occurs when the tree is perfectly balanced. This property matches the insertion pattern of an I/O queue, especially when the I/O operations are highly sequential.
Reference: [KS91] <author> James J. Kistler and M. Satyanarayanan. </author> <title> Disconnected operation in the Coda file system. </title> <booktitle> In Proceedings of 13th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 213-25. </pages> <institution> Association for Computing Machinery SIGOPS, </institution> <month> October </month> <year> 1991. </year> <note> (cited on page 7) </note>
Reference-contexts: Disconnected operation forms a new strand of work in distributed file system research. This line of work recognises the importance of mobile computing and the need to support automatic data consolidation when a portable computer is reconnected to a distributed computing environment (DCE). Coda <ref> [KS91] </ref> is the first system to support this mode of computing. Distributed file system has been an active area of research for nearly two decades. It is not possible to cover, in this limited discussion, all the significant work. More detailed accounts can be found in [Svo84] [LS90].
Reference: [Lam74] <author> B. W. Lampson. </author> <title> Protection. </title> <journal> ACM Operating Systems Review, </journal> <volume> 8(1), </volume> <month> January </month> <year> 1974. </year> <note> (cited on page 41) </note>
Reference-contexts: Conceptually, this information can be represented by an access matrix <ref> [Lam74] </ref>. In the matrix, the rows represent the subjects and the columns represent the objects. The access rights that a subject holds for an object can be found at the intersection of the corresponding row and column. In this discussion, the files are the objects to which access is controlled.
Reference: [LGG + 91] <author> Barbara Liskov, Sanjay Ghemawat, Robert Gruber, Paul John-son, Liuba Shrira, and Michael Williams. </author> <title> Replication in the Harp file system. </title> <booktitle> In Proceedings of 13th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 226-38. </pages> <institution> Association for Computing Machinery SIGOPS, </institution> <month> October </month> <year> 1991. </year> <note> (cited on page 7) </note>
Reference-contexts: LIMITATIONS OF TODAY'S DISTRIBUTED FILE SYSTEMS 7 combined replication and an algorithm to detect inconsistency to achieve high availability. In the past few years, there has been considerable interest in using file replication to achieve high availability. Echo [HBM + 89], Coda [SKK + 90], Harp <ref> [LGG + 91] </ref> and Deceit [SBM89] are examples of highly available distributed file systems. The systems differ from earlier designs in that they are all Unix-style file systems and have combined client caching with server replication. Disconnected operation forms a new strand of work in distributed file system research.
Reference: [LH91] <author> Michael Liebhold and Eric M. Hoffert. </author> <title> Toward an open environment for digital video. </title> <journal> Communications of the ACM, </journal> <volume> 34(4) </volume> <pages> 103-112, </pages> <month> April </month> <year> 1991. </year> <note> (cited on page 10) </note>
Reference-contexts: Therefore, a level of indirection between the media data and the user-level abstraction, like the rope, seems an appropriate way to minimise copying. The proliferation of digital video standards presents another problem to continuous-medium data storage. As Liebhold <ref> [LH91] </ref> points out, there are a number of digital video standards, some for full-bandwidth video and some for compressed representations (CD-I [Inc89], DVI [Lut91], JPEG [Wal91] [CH91], MPEG [Gal91], px64 [Lio91]).
Reference: [Lio91] <author> Ming Lion. </author> <title> Overview of the px64 kbits/s video coding standard. </title> <journal> Communications of the ACM, </journal> <volume> 34(4) </volume> <pages> 60-63, </pages> <month> April </month> <year> 1991. </year> <note> (cited on page 10) </note>
Reference-contexts: The proliferation of digital video standards presents another problem to continuous-medium data storage. As Liebhold [LH91] points out, there are a number of digital video standards, some for full-bandwidth video and some for compressed representations (CD-I [Inc89], DVI [Lut91], JPEG [Wal91] [CH91], MPEG [Gal91], px64 <ref> [Lio91] </ref>). The variety of formats means that the timing information necessary for the timely delivery of data is encoded in different ways. It is a challenge to design a storage service that can cope 2.5. SUPPORT OF STRUCTURED DATA 11 with this diversity.
Reference: [LS90] <author> Eliezer Levy and Abraham Silberschatz. </author> <title> Distributed file systems: Concepts and examples. </title> <journal> Computing Surveys, </journal> <volume> 22(4) </volume> <pages> 321-374, </pages> <month> December </month> <year> 1990. </year> <booktitle> (cited on pages 7, </booktitle> <volume> 15) 143 </volume>
Reference-contexts: Coda [KS91] is the first system to support this mode of computing. Distributed file system has been an active area of research for nearly two decades. It is not possible to cover, in this limited discussion, all the significant work. More detailed accounts can be found in [Svo84] <ref> [LS90] </ref>. However, it is clear from the discussion above that distributed file systems have been designed to fulfill four requirements: efficiency, transparency, reliability and security. <p> The name of a file in these systems does not reveal where it is stored. In practice, most of the systems provide location transparency by a static mapping from user-level names to server and device locations. However, these systems do not support location independence (figure 2.4). Location independence <ref> [LS90] </ref> is a stronger transparency requirement the name of a file does not change if it is moved from one location to another. This property is essential if the applications are not to be affected by server directed file movement.
Reference: [LS93] <author> P. Lougher and D. Shepherd. </author> <title> The design of a storage server for continuous media. </title> <journal> The Computer Journal, </journal> <volume> 36(1) </volume> <pages> 32-42, </pages> <month> January </month> <year> 1993. </year> <note> (cited on pages 99, 120) </note>
Reference-contexts: THE PERFORMANCE OF THE BSC 8 Rate-Based Sessions: Concept & Interface 8.1 Introduction In this chapter, the storage of continuous-medium data is considered. Early work in this area [Cal87] [TS87] only deals with voice storage. The bandwidth requirement of this medium type is low. Recent work [RV91] [AOG92] [GC92] <ref> [LS93] </ref> that deals with high bandwidth media, such as video, concentrates mainly on the hard real-time scheduling of disk transfers. Little attention has been given to the issue of system integration. <p> Given a method to estimate the service time, it is possible to derive algorithms to schedule read-ahead actions for simultaneous sessions. Indeed, research work (e.g. [RV91] [AOG92] [GC92] <ref> [LS93] </ref>) has been done in this area and scheduling algorithms have been derived. The research projects take into account of (1) and (2) listed above but none of them considers the effect of (3).
Reference: [Lut91] <author> Arch C. </author> <title> Luther. Digital Video In the PC Environment. </title> <publisher> McGraw-Hill Book Company, </publisher> <year> 1991. </year> <note> ISBN 0-07-039177-7. (cited on page 10) </note>
Reference-contexts: The proliferation of digital video standards presents another problem to continuous-medium data storage. As Liebhold [LH91] points out, there are a number of digital video standards, some for full-bandwidth video and some for compressed representations (CD-I [Inc89], DVI <ref> [Lut91] </ref>, JPEG [Wal91] [CH91], MPEG [Gal91], px64 [Lio91]). The variety of formats means that the timing information necessary for the timely delivery of data is encoded in different ways. It is a challenge to design a storage service that can cope 2.5. SUPPORT OF STRUCTURED DATA 11 with this diversity.
Reference: [MA69] <author> S. E. Madnick and J. W. Alsop. </author> <title> A modular approach to file system design. </title> <booktitle> In Proceedings of AFIPS Spring Joint Computer Conference, </booktitle> <pages> pages 184-189. </pages> <booktitle> The American Federation of Information Processing Societies, </booktitle> <month> May </month> <year> 1969. </year> <note> (cited on page 36) </note>
Reference-contexts: ARCHITECTURAL FRAMEWORK 3.9.1 Modular File System Design The idea of building sophisticated file systems in multiple layers of abstraction is not new. Madnick and Alsop <ref> [MA69] </ref> defines a generalised file system model with six hierarchical layers shown (in simplified form) in figure 3.5. It is a framework for describing the structure of file systems. In the middle of the hierarchy is the basic file system. This provides a sequence of blocks abstraction.
Reference: [McA90] <author> D R McAuley. </author> <title> Protocol design for high speed networks. </title> <type> Technical Report 186, </type> <institution> Computer Laboratory, University of Cambridge, </institution> <month> January </month> <year> 1990. </year> <type> The author's Phd thesis. </type> <note> (cited on page 86) </note>
Reference-contexts: This table is passed to the kernel driver and data are transferred directly between the buffer blocks and the disks. The prototype exports a remote procedure call (RPC) interface. The RPC system is called MSRPC. The system uses MSNL <ref> [McA90] </ref>, which is a light weight virtual circuit protocol, as the transport.
Reference: [MH88] <author> J. Menon and M. Hartung. </author> <title> The IBM 3990 disk cache. </title> <booktitle> In Proceedings of COMPCON 1988, </booktitle> <pages> pages 146-151, </pages> <month> June </month> <year> 1988. </year> <note> (cited on pages 67, 94) </note>
Reference-contexts: In contrast, this design has the potential to achieve high performance because it has made several design trade-offs. These trade-offs are discussed below. Use of NVRAM NVRAM has been used as fast write back buffers for some time. For instance, the IBM 3990 disk controller <ref> [MH88] </ref> has NVRAM built-in; NFS accelerators, such as Prestoserve [MSC + 90], use NVRAM to buffer synchronous NFS write operations. In these examples, NVRAM is put behind the disk driver interface. <p> IBM uses four megabytes of NVRAM on the 3990-3 disk controller <ref> [MH88] </ref>. Disk writes go to this non-volatile speed matching buffer to reduce latency. The buffered 7.2. RELATED WORK 95 blocks are sorted in order to reduce the disk head movement in writing these blocks back to disk.
Reference: [Mil90] <author> D. L. Mills. </author> <title> On the accuracy and stablity of clocks synchro-nised by the network time protocol in the internet system. </title> <journal> ACM Computer Communication Review, </journal> <volume> 20(1) </volume> <pages> 65-75, </pages> <month> January </month> <year> 1990. </year> <note> (cited on page 48) </note>
Reference-contexts: This is a reasonable assumption in today's networking environment where clock synchronisation protocols, such as the Network Time Protocol, can maintain the accuracy of system clocks to a few tens of milliseconds over a wide area <ref> [Mil90] </ref>. 4.6. THE USE OF CAPABILITIES IN MSSA 49 is generated by passing the rest of the capability and the secret number (s) held by the file custode through a one-way function.
Reference: [MJLF84] <author> Marshall K. Mckusick, William N. Joy, Samuel J. Leffler, and Robert S. Fabry. </author> <title> A fast file system for UNIX. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 2(3) </volume> <pages> 181-197, </pages> <month> August </month> <year> 1984. </year> <booktitle> (cited on pages 6, </booktitle> <volume> 8, </volume> <pages> 95) </pages>
Reference-contexts: Transaction support was considered a useful mechanism to prevent inconsistencies arising from machine and communication failures or concurrent access to files by other clients. Felix [FO81], XDFS [SMI80], Alpine [BKT85], Swallow [Svo81] are examples of such systems. Since then, the UNIX-style byte stream file model [Bac86] <ref> [MJLF84] </ref> [POS90] has been adopted by most distributed file systems. None of these provides direct transaction support. As the systems are mainly used for program development and engineering applications, this is considered a reasonable tradeoff between high performance and the possible danger of having occasional data inconsistency. <p> However the design has a major potential drawback in that its functionality and performance would be degraded far more severely than more conventional file system designs, such as the Unix FFS <ref> [MJLF84] </ref>, when the data properties are not what the designers expect. For instance, the strict immutability of files requires new copies be created for every update and the extra overhead of copying old data would become intolerable for frequent, and perhaps small step, updates. <p> Legato's Prestoserve [MSC + 90] is an add-on product to improve the write performance of NFS servers. It uses a NVRAM buffer to cache disk writes. The cached disk blocks are written out asynchronously. Prestoserve is designed to work with the BSD FFS <ref> [MJLF84] </ref> as the underlying file system. No change to the file system code or the on-disk data structures is required. The NVRAM cache is accessed via the block device interface, which is the same interface used by the file system to access the disk hardware.
Reference: [MSC + 90] <author> J. Moran, R. Sandberg, D. Coleman, J. Kepecs, and B. Lyon. </author> <title> Breaking through the nfs performance barrier. </title> <booktitle> In Proceedings of EUUG Spring 1990, </booktitle> <pages> pages 199-206, </pages> <month> April </month> <year> 1990. </year> <note> (cited on pages 67, 95) </note>
Reference-contexts: These trade-offs are discussed below. Use of NVRAM NVRAM has been used as fast write back buffers for some time. For instance, the IBM 3990 disk controller [MH88] has NVRAM built-in; NFS accelerators, such as Prestoserve <ref> [MSC + 90] </ref>, use NVRAM to buffer synchronous NFS write operations. In these examples, NVRAM is put behind the disk driver interface. This ensures that the devices are compatible with existing file systems and minimum modification is needed to harness the performance advantage of non-volatile memory. <p> The protocol specification [Sun89] is publicly available and is widely supported by vendors of UNIX machines. NFS servers are stateless, i.e. each operation is independent and must be completed before returning. This property implies that all disk writes performed in an operation must be synchronous. Legato's Prestoserve <ref> [MSC + 90] </ref> is an add-on product to improve the write performance of NFS servers. It uses a NVRAM buffer to cache disk writes. The cached disk blocks are written out asynchronously. Prestoserve is designed to work with the BSD FFS [MJLF84] as the underlying file system.
Reference: [Nee93] <author> Roger M. Needham. </author> <title> An Advanced Course in Distributed Computing, chapter 12. </title> <publisher> Addison-Wesley Publishing Co., </publisher> <address> 2nd edition, </address> <year> 1993. </year> <note> Sape Mullender, Editor. (cited on page 58) </note>
Reference-contexts: This is because a container and the objects it collects must be of the same type. Furthermore, if a container identifier contains location information, an object identifier can just be a pure name <ref> [Nee93] </ref>. A pure name is nothing but a bit-pattern and does not yield any information by examining the name itself. Hence, the only use of an object identifier is for comparing with other bit-patterns for identity. Multi-layer characteristic The multi-layer characteristic of MSSA is another consideration.
Reference: [NHM86] <author> R M Needham, A J Herbert, and J G Mitchell. </author> <title> How to connect stable storage to a computer. Operating Systems Review, </title> <address> 17(1):16, </address> <month> November </month> <year> 1986. </year> <note> (cited on page 74) 144 . BIBLIOGRAPHY </note>
Reference-contexts: In other words, the chance of NVRAM corruption when a system fails is as unlikely (or likely) as disk corruption. There is no clear evidence to show that this is the case. On the contrary, Needham et al. <ref> [NHM86] </ref> point out that NVRAM could be more vulnerable than disks. A misbehaving CPU or a software bug could cause incorrect data to be written anywhere in the processor's address space. If NVRAM is handled like ordinary memory, it is vulnerable to corruption by these faults.
Reference: [NS78] <author> R. M. Needham and M. D. Schroeder. </author> <title> Using encryption for authentication in large networks of computers. </title> <journal> Communications of the ACM, </journal> <volume> 21(12) </volume> <pages> 993-999, </pages> <month> December </month> <year> 1978. </year> <note> (cited on page 43) </note>
Reference-contexts: The principal on whose behalf a client works for must be known for an ACL check. An identity-based capability must be checked against the principal a client speaks for. Authentication in distributed systems is accomplished using encryption-based protocols, such as those described by Needham and Schroeder <ref> [NS78] </ref> or implemented in Kerberos [SNS88]. The following discussion assumes that an authentication mechanism is available for file custodes to authenticate clients.
Reference: [NWO88] <author> M. N. Nelson, B. B. Welch, and J. K. Ousterhout. </author> <title> Caching in the sprite network file system. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 6(1), </volume> <month> February </month> <year> 1988. </year> <note> (cited on pages 6, 8) </note>
Reference-contexts: In most NFS implementations, data are used directly from the cache if it has been validated within some time period, usually a few seconds. Andrew [HKM + 88], MFS [Bur88] and Sprite <ref> [NWO88] </ref>, developed around the same time, adopt different write-sharing models and assume a different granularity of sharing. Hence the cache consistency protocols of the three designs are quite different. A comparison of the relative merits of the various cache consistency protocols is contained in [Bur88]. <p> BACKGROUND because these were thought to be the common characteristics of data sharing in a DCE. Although the derivative of AFS OSF DEcorum [KLA + 91] and other caching file systems [Bur88] <ref> [NWO88] </ref> support strict single-system semantics, these systems are likely to operate efficiently only if the degree of concurrent sharing is low. Some research work on improving the performance of file systems relies heavily on the observed access patterns to make the design tradeoffs.
Reference: [POS90] <author> Portable operating system interface (POSIX)- part i: </author> <title> System application programming interface (API). </title> <journal> IEEE Std. </journal> <note> 1003.1-1990 Standard for Information Technology, 1990. (cited on page 6) </note>
Reference-contexts: Transaction support was considered a useful mechanism to prevent inconsistencies arising from machine and communication failures or concurrent access to files by other clients. Felix [FO81], XDFS [SMI80], Alpine [BKT85], Swallow [Svo81] are examples of such systems. Since then, the UNIX-style byte stream file model [Bac86] [MJLF84] <ref> [POS90] </ref> has been adopted by most distributed file systems. None of these provides direct transaction support. As the systems are mainly used for program development and engineering applications, this is considered a reasonable tradeoff between high performance and the possible danger of having occasional data inconsistency.
Reference: [PPTT90] <author> Rob Pike, Dave Presotto, Ken Thompson, and Howard Trickey. </author> <title> Plan 9 from bell labs. </title> <booktitle> In Proceedings of the summer 1990 UKUUG Conference, </booktitle> <pages> pages 1-9, </pages> <month> July </month> <year> 1990. </year> <note> (cited on page 55) </note>
Reference-contexts: This chapter looks at how these problems can be minimised. 5.1 Textual Names vs Identifiers Files in conventional file systems are often given textual names and organ-ised into hierarchical directories. Some operating systems, such as Plan 9 <ref> [PPTT90] </ref>, go a step further and name all devices and other non-file entities just like real files. The main appeal of this everything has a path name approach is simplicity. Users only have to deal with a single naming concept.
Reference: [RN83] <author> M F Richardson and R M Needham. </author> <title> The TRIPOS Filing Machine, a front end to a file server. </title> <journal> ACM Operating Systems Review, </journal> <volume> 17(5) </volume> <pages> 120-128, </pages> <year> 1983. </year> <note> (cited on page 6) </note>
Reference-contexts: The Cambridge design is a capability-based virtual disc system augmented with a naming substrate which provides the desired coherency without committing the clients to any specific directory structures or textual name conventions. The CFS was used to support two file systems (Tripos <ref> [RN83] </ref> and the CAP filing system [Del80]), an object-based file store [Cra86] and a digital voice store [Cal87]. Since the mid-80s, researchers have explored the use of data caching on diskless or dataless 1 workstations to improve the performance of remote file serving.
Reference: [RO91] <author> Mendel Rosenblum and John K. Ousterhout. </author> <title> The design and implementation of a log-structured file system. </title> <booktitle> In Proceedings of 13th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 1-15, </pages> <month> October </month> <year> 1991. </year> <booktitle> (cited on pages 8, </booktitle> <volume> 66, </volume> <pages> 96) </pages>
Reference-contexts: For instance, the strict immutability of files requires new copies be created for every update and the extra overhead of copying old data would become intolerable for frequent, and perhaps small step, updates. Similarly, log-structured file systems, such as Sprite LFS <ref> [RO91] </ref>, are designed with the assumption that large client caches will have the effect of shifting the server work load towards being write-dominated. <p> Moreover, a system that recovers by rolling back to a previous consistent state may do so by undoing some operations that have been completed and positively acknowledged. File systems, such as the (re-implemented) Cedar [Hag87] file system, Episode [CAK + 92], JFS [CMR + 90] and Sprite LFS <ref> [RO91] </ref>, that use the logging [Gra79] technique to maintain consistency, are examples that exhibit this kind of behaviour. This is because the tail of the logs in these systems are kept in volatile memory and are lost when the systems fail. <p> Their measurements show that a one-half megabyte NVRAM buffer on the server would reduce the number of disk writes for most file systems measured by about 20% and by 90% on one heavily used file system. Notice that the file systems measured are log-structured file systems (LFS) <ref> [RO91] </ref>. The file server has already been optimised to perform fewer disk writes than traditional file servers (at the expense of being less reliable). LFS batches together many small writes and transfers them to disk in one operation.
Reference: [RV91] <author> P. Venkat Rangan and Harrick M. Vin. </author> <title> Designing file systems for digital video and audio. </title> <journal> ACM Operating Systems Review, </journal> <volume> 25(5) </volume> <pages> 81-94, </pages> <month> October </month> <year> 1991. </year> <note> (cited on pages 99, 120) </note>
Reference-contexts: THE PERFORMANCE OF THE BSC 8 Rate-Based Sessions: Concept & Interface 8.1 Introduction In this chapter, the storage of continuous-medium data is considered. Early work in this area [Cal87] [TS87] only deals with voice storage. The bandwidth requirement of this medium type is low. Recent work <ref> [RV91] </ref> [AOG92] [GC92] [LS93] that deals with high bandwidth media, such as video, concentrates mainly on the hard real-time scheduling of disk transfers. Little attention has been given to the issue of system integration. <p> Given a method to estimate the service time, it is possible to derive algorithms to schedule read-ahead actions for simultaneous sessions. Indeed, research work (e.g. <ref> [RV91] </ref> [AOG92] [GC92] [LS93]) has been done in this area and scheduling algorithms have been derived. The research projects take into account of (1) and (2) listed above but none of them considers the effect of (3).
Reference: [RW93] <author> Chris Ruemmler and John Wilkes. </author> <title> Unix disk access patterns. </title> <booktitle> In USENIX Winter 1993 Conference Proceedings, </booktitle> <month> January </month> <year> 1993. </year> <note> (cited on pages 93, 96) </note>
Reference-contexts: The same argument can be applied to any disk block that is modified repeatedly. If these blocks can be identified, which requires more work with normal data, the I/O bandwidth can be better utilised by deferring the write-back of these blocks. Empirical data <ref> [RW93] </ref> from working systems show that a large number of disk writes are directed at a small number of blocks within a short duration. This observation suggests that delaying the write-back of only a small number of repeatedly accessed blocks can significantly reduce the number of disk writes. <p> The implementation is simple and the recovery process can be completed in a very short time (section 7.1.3). 96 7. THE PERFORMANCE OF THE BSC 7.2.2 Performance Studies This work has not studied empirically the performance benefit of NVRAM caching with real workloads. However, other work <ref> [RW93] </ref> [BAD + 92] has used data collected on working systems to analyse the effect of NVRAM caching. Their results show that even a small NVRAM cache can bring about significant performance improvement. Ruemmler and Wilkes [RW93] use trace-driven simulations to analyse the effect of write caching at the disk level. <p> However, other work <ref> [RW93] </ref> [BAD + 92] has used data collected on working systems to analyse the effect of NVRAM caching. Their results show that even a small NVRAM cache can bring about significant performance improvement. Ruemmler and Wilkes [RW93] use trace-driven simulations to analyse the effect of write caching at the disk level. The traces were obtained from three systems over a two month period. The three systems studied are: a timesharing system, a file server and a personal workstation.
Reference: [Sal73] <author> J. H. Saltzer. </author> <title> Operating Systems an Advanced Course. </title> <publisher> Springer Verlag, </publisher> <year> 1973. </year> <title> On the Naming and Binding of Objects. </title> <note> (cited on page 64) </note>
Reference-contexts: A file is unreachable if no reference to the file exists in the client domains. In a system with an integrated directory, the task of detecting unreachable files might be difficult, especially with a freely connected directory graph <ref> [Sal73] </ref>. Nevertheless, the existence of a file can be clearly defined by a system predicate, i.e. a file can be removed if it does not appear in any directory entry. As a research goal, MSSA must support composite objects which contain references to other objects.
Reference: [Sal91] <author> Jerome H. Saltzer. </author> <title> File system indexing, </title> <editor> and backup. In A. Karshmer and J. Nehmer, editors, </editor> <booktitle> International Workshop on 145 Operating Systems of the 90s and Beyond, number 563 in Lecture Notes in Computer Science, </booktitle> <pages> pages 13-19. </pages> <publisher> Springer-Verlag, </publisher> <year> 1991. </year> <note> (cited on page 12) </note>
Reference-contexts: This section discusses two examples of enhancing this primary function by value-adding clients. 2.6.1 File Indexing As the volume of data stored in a file system increases, it becomes increasingly difficult to locate the data item one wants. In relation to this problem, some researchers <ref> [Sal91] </ref> [Sat91] have suggested that it will be very useful to extend the file system by adding associative search or indexing functions.
Reference: [Sat91] <author> M. Satyanarayanan. </author> <title> An agenda for research in large-scale distributed data repositories. </title> <editor> In A. Karshmer and J. Nehmer, editors, </editor> <booktitle> International Workshop on Operating Systems of the 90s and Beyond, number 563 in Lecture Notes in Computer Science, </booktitle> <pages> pages 2-12. </pages> <publisher> Springer-Verlag, </publisher> <year> 1991. </year> <note> (cited on page 12) </note>
Reference-contexts: This section discusses two examples of enhancing this primary function by value-adding clients. 2.6.1 File Indexing As the volume of data stored in a file system increases, it becomes increasingly difficult to locate the data item one wants. In relation to this problem, some researchers [Sal91] <ref> [Sat91] </ref> have suggested that it will be very useful to extend the file system by adding associative search or indexing functions.
Reference: [SBM89] <author> Alex Siegel, Kenneth Birman, and Keith Marzullo. Deceit: </author> <title> A flexible distributed file system. </title> <type> Technical Report TR 89-1042, </type> <institution> Dept. of Computer Science, Cornell University, </institution> <address> Ithaca, NY (USA), </address> <month> November </month> <year> 1989. </year> <note> (cited on page 7) </note>
Reference-contexts: In the past few years, there has been considerable interest in using file replication to achieve high availability. Echo [HBM + 89], Coda [SKK + 90], Harp [LGG + 91] and Deceit <ref> [SBM89] </ref> are examples of highly available distributed file systems. The systems differ from earlier designs in that they are all Unix-style file systems and have combined client caching with server replication. Disconnected operation forms a new strand of work in distributed file system research.
Reference: [SGK + 85] <author> Russel Sandberg, David Goldberg, Steve Kleiman, Dan Walsh, and Bob Lyon. </author> <title> Design and implementation of the Sun Network Filesystem. </title> <booktitle> In Proc. Summer 1985 USENIX Conf., </booktitle> <pages> pages 119-130, </pages> <address> Portland OR (USA), </address> <month> June </month> <year> 1985. </year> <note> USENIX. (cited on page 95) </note>
Reference-contexts: The buffered 7.2. RELATED WORK 95 blocks are sorted in order to reduce the disk head movement in writing these blocks back to disk. Similarly, traditional distributed file systems, such as NFS, also use NVRAM to reduce disk traffic. Sun NFS and Legato Prestoserve Sun's Network File System (NFS) <ref> [SGK + 85] </ref> is currently the de facto standard distributed file system for workstations. The protocol specification [Sun89] is publicly available and is widely supported by vendors of UNIX machines. NFS servers are stateless, i.e. each operation is independent and must be completed before returning.
Reference: [SGN85] <author> Michael D. Schroeder, David K. Gifford, and Roger M. Need-ham. </author> <title> A caching file system for a programmer's workstation. </title> <booktitle> In Proceedings of the 10th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 25-34, </pages> <month> December </month> <year> 1985. </year> <note> (cited on page 6) </note>
Reference-contexts: The cache consistency problem is addressed in different ways depending on the models of data sharing adopted by the different designs. The Cedar File System <ref> [SGN85] </ref>, which was the first caching file system, eliminates the cache consistency problem by forcing all files to be immutable. Sun's Network File System (NFS) [Sun89] does not define clearly what guarantees the system makes about the consistency of the client caches.
Reference: [SHN + 85] <author> M. Satyanarayanan, John H. Howard, David A. Nicols, Robert N. Sidebotham, Alfred Z. Spector, and Michael J. West. </author> <title> The ITC distributed file system: </title> <booktitle> Principles and design. In Proceedings of the 10th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 35-50. </pages> <publisher> ACM, </publisher> <month> December </month> <year> 1985. </year> <note> (cited on page 46) </note>
Reference-contexts: Negative rights take precedence over positive rights. Titan [BFH + 67] allows a file owner to deny a particular principal the access right while permitting other principals to access the file. The same idea has been used in Andrew <ref> [SHN + 85] </ref> to provide a rapid way to deny a principal the access rights to a large set of files. This is necessary in a large distributed system, such as Andrew, because revocation information, such as the removal of a principal from a group, may take time to propagate.
Reference: [Sit92] <author> Richard Sites, </author> <title> editor. Alpha architecture reference manual. </title> <publisher> Digital Press, </publisher> <address> Burlington MA, </address> <year> 1992. </year> <note> (cited on page 74) </note>
Reference-contexts: METADATA 75 hardware/software faults. However, the result is not conclusive and does not show any apparent reduction in the corruption rate when the protection scheme is enabled. With the advent of new microprocessors <ref> [Sit92] </ref> [KH92] that support 64-bit virtual address space, the sparseness of the address space may be sufficient to catch any run-away software errors. Other solutions [HCHJ91] [BBLP86] have been reported in the literature. This work does not investigate NVRAM protection.
Reference: [SKK + 90] <author> M. Satyanarayanan, James J. Kistler, P. Kumar, M. E. Okasaki, and D. C. Steere E.H. Siegel. Coda: </author> <title> A highly available file system for a distributed workstation environment. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 39(4), </volume> <month> April </month> <year> 1990. </year> <note> (cited on page 7) 146 . BIBLIOGRAPHY </note>
Reference-contexts: LIMITATIONS OF TODAY'S DISTRIBUTED FILE SYSTEMS 7 combined replication and an algorithm to detect inconsistency to achieve high availability. In the past few years, there has been considerable interest in using file replication to achieve high availability. Echo [HBM + 89], Coda <ref> [SKK + 90] </ref>, Harp [LGG + 91] and Deceit [SBM89] are examples of highly available distributed file systems. The systems differ from earlier designs in that they are all Unix-style file systems and have combined client caching with server replication.
Reference: [SMI80] <author> Howard Sturgis, James Mitchell, and J. Israel. </author> <title> Issues in the Design and Use of a Distributed File System. </title> <journal> Operating Systems Review, </journal> <volume> 14(3) </volume> <pages> 55-69, </pages> <month> July </month> <year> 1980. </year> <note> (cited on pages 6, 67) </note>
Reference-contexts: In the early 80s, there was considerable interest in providing atomic transactions and concurrency control in distributed file systems. Transaction support was considered a useful mechanism to prevent inconsistencies arising from machine and communication failures or concurrent access to files by other clients. Felix [FO81], XDFS <ref> [SMI80] </ref>, Alpine [BKT85], Swallow [Svo81] are examples of such systems. Since then, the UNIX-style byte stream file model [Bac86] [MJLF84] [POS90] has been adopted by most distributed file systems. None of these provides direct transaction support. <p> Conversely, other custodes that interact with the BSC do not need to take any actions other than to invoke the interrupted operations again. 6.2.3 NVRAM and Atomic Updates The performance cost of atomic updates can be high. Early work [Dio80] [FO81] [BKT85] <ref> [SMI80] </ref> that investigates transaction support in network file systems all extract a high performance cost in exchange for atomicity. In contrast, this design has the potential to achieve high performance because it has made several design trade-offs. These trade-offs are discussed below.
Reference: [SNS88] <author> J. G. Steiner, C. Neuman, and J. I. Schiller. </author> <title> Kerberos: An authentication service for open network systems. </title> <booktitle> In Proceedings of the USENIX Winter Conference, </booktitle> <pages> pages 191-202, </pages> <month> February </month> <year> 1988. </year> <note> (cited on page 43) </note>
Reference-contexts: An identity-based capability must be checked against the principal a client speaks for. Authentication in distributed systems is accomplished using encryption-based protocols, such as those described by Needham and Schroeder [NS78] or implemented in Kerberos <ref> [SNS88] </ref>. The following discussion assumes that an authentication mechanism is available for file custodes to authenticate clients.
Reference: [Sre92] <author> Cormac J. Sreenan. </author> <title> Synchronisation services for digitial continuous media. </title> <type> Technical Report 292, </type> <institution> Computer Laboratory, University of Cambridge, </institution> <month> October </month> <year> 1992. </year> <type> The author's PhD thesis. </type> <note> (cited on page 103) </note>
Reference-contexts: A common example is lip-synching between a video and an audio stream. This work assumes that multi-stream synchronisation is done by some agent outside the storage service. This agent can be a synchronisation service, such as the one described in <ref> [Sre92] </ref>. Sreenan proposes that synchronisation is better performed at the presentation node or close to it. This approach ensures better synchronisation because local delay and jitter can be determined and controlled more accurately. It might be beneficial to reduce the skew between two synchronised streams by coordinating their starting time.
Reference: [SS75] <author> J. H. Saltzer and M. D. Schroeder. </author> <title> The protection of information in computer systems. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 63(9) </volume> <pages> 1278-1308, </pages> <month> September </month> <year> 1975. </year> <note> (cited on page 40) </note>
Reference-contexts: Equally, a service provider, such as a value-adding client or a network service, should be restricted to have access only to the data that are needed to perform the service and only for the duration of the service. This requirement, commonly referred to as the least privilege principle <ref> [SS75] </ref>, is essential in limiting the amount of damage a faulty service provider (or one which has been compromised in security) can cause. Normally, end-clients which access files indirectly through value-adding clients should not be allowed to by-pass the value-adding clients.
Reference: [Sun89] <author> Sun Microsystems, Inc. NFS: </author> <title> Network file system protocol specification. </title> <type> RFC 1094, </type> <institution> Network Information Center, SRI International, </institution> <month> March </month> <year> 1989. </year> <note> (cited on pages 6, 95) </note>
Reference-contexts: The Cedar File System [SGN85], which was the first caching file system, eliminates the cache consistency problem by forcing all files to be immutable. Sun's Network File System (NFS) <ref> [Sun89] </ref> does not define clearly what guarantees the system makes about the consistency of the client caches. In most NFS implementations, data are used directly from the cache if it has been validated within some time period, usually a few seconds. <p> Similarly, traditional distributed file systems, such as NFS, also use NVRAM to reduce disk traffic. Sun NFS and Legato Prestoserve Sun's Network File System (NFS) [SGK + 85] is currently the de facto standard distributed file system for workstations. The protocol specification <ref> [Sun89] </ref> is publicly available and is widely supported by vendors of UNIX machines. NFS servers are stateless, i.e. each operation is independent and must be completed before returning. This property implies that all disk writes performed in an operation must be synchronous.
Reference: [Svo81] <author> Liba Svobodova. </author> <title> A Reliable Object-Oriented Data Repository for a Distributed Computer System. </title> <booktitle> In The Eighth Symposium on Operating Systems Principles, </booktitle> <pages> pages 47-58. </pages> <publisher> ACM, </publisher> <month> December </month> <year> 1981. </year> <note> (cited on page 6) </note>
Reference-contexts: Transaction support was considered a useful mechanism to prevent inconsistencies arising from machine and communication failures or concurrent access to files by other clients. Felix [FO81], XDFS [SMI80], Alpine [BKT85], Swallow <ref> [Svo81] </ref> are examples of such systems. Since then, the UNIX-style byte stream file model [Bac86] [MJLF84] [POS90] has been adopted by most distributed file systems. None of these provides direct transaction support.
Reference: [Svo84] <author> Liba Svobodova. </author> <title> File servers for network-based distributed systems. </title> <journal> Computing Surveys, </journal> <volume> 16(4) </volume> <pages> 353-398, </pages> <month> December </month> <year> 1984. </year> <note> (cited on page 7) </note>
Reference-contexts: Coda [KS91] is the first system to support this mode of computing. Distributed file system has been an active area of research for nearly two decades. It is not possible to cover, in this limited discussion, all the significant work. More detailed accounts can be found in <ref> [Svo84] </ref> [LS90]. However, it is clear from the discussion above that distributed file systems have been designed to fulfill four requirements: efficiency, transparency, reliability and security.
Reference: [Tho90] <author> Susan E. Thomson. </author> <title> A Storage Service For Structured Data. </title> <type> PhD thesis, </type> <institution> Computer Laboratory, University of Cambridge, </institution> <month> Novem-ber </month> <year> 1990. </year> <booktitle> (cited on pages 12, </booktitle> <volume> 14, </volume> <pages> 37) </pages>
Reference-contexts: The storage service may take advantage of knowledge about the struc ture of data to improve performance. 4. The storage service can keep track of object references inside structured objects, and detect and remove unreachable objects. Sue Thomson's work <ref> [Tho90] </ref> on structured data storage is directly related to this dissertation. She proposes a High Level Storage Service (HLSS) to store structured data. HLSS has two primitive types (byte sequence and object identifier) and a small set of constructors (sequence, record and union). <p> This idea is appealing because the attribute extraction process is transparent and unobtrusive, and many applications can easily benefit without any changes to their code. 2.6.2 Persistent Programming Languages PC++ [ZMB93] is a persistent programming language developed to work with HLSS <ref> [Tho90] </ref>. It uses HLSS for storing both data and metadata. Also it supports the HLSS object identifier as a special type and persistent class declarations can include HLSS object identifiers. Therefore the application programmer may construct and manipulate object data structures whose components are separately stored objects. <p> RELATED WORK 37 systems and cannot describe the distribution of functional entities. 3.9.2 HLSS and LLSS The High Level Storage Service (HLSS) and the Low Level Storage Service (LLSS) are results of the Ph.D. work done in the Computer Laboratory by Sue Thomson <ref> [Tho90] </ref> and Tim Wilson [Wil92b] respectively. HLSS has been briefly described in section 2.5. It is a general purpose storage service for storing structured data. The service was designed to work on top of LLSS. LLSS is a general purpose flat file server.
Reference: [TS87] <author> D. B. Terry and D. C. Swinehart. </author> <title> Managing stored voice in the etherphone system. </title> <journal> ACM Operating Systems Review, </journal> <volume> 21(5) </volume> <pages> 48-61, </pages> <month> November </month> <year> 1987. </year> <booktitle> (cited on pages 10, </booktitle> <volume> 99) 147 </volume>
Reference-contexts: The allocation of (disk) bandwidth to match the bursty nature of compressed video is a problem. Editing of continuous-medium data may need extra storage service support. For instance, voice data are stored as ropes in the voice storage server of the Etherphone System <ref> [TS87] </ref>. Each rope is implemented internally as lists of pointers to immutable voice recordings. The server supports editing operations, such as cut and paste, on ropes by manipulating the pointers. The purpose is to minimise the amount of copying involved in editing. <p> THE PERFORMANCE OF THE BSC 8 Rate-Based Sessions: Concept & Interface 8.1 Introduction In this chapter, the storage of continuous-medium data is considered. Early work in this area [Cal87] <ref> [TS87] </ref> only deals with voice storage. The bandwidth requirement of this medium type is low. Recent work [RV91] [AOG92] [GC92] [LS93] that deals with high bandwidth media, such as video, concentrates mainly on the hard real-time scheduling of disk transfers.
Reference: [vRST88] <author> Robert van Renesse, Hans Van Straveren, and Andrew S. Tanen-baum. </author> <title> Performance of the world's fastest distributed operating system. </title> <journal> Operating Systems Review, </journal> <volume> 22(4) </volume> <pages> 25-34, </pages> <month> October </month> <year> 1988. </year> <note> (cited on page 8) </note>
Reference-contexts: Files are cached in their entirety in RAM on the server. When compared with the SUN NFS using simple tests <ref> [vRST88] </ref>, the designers claim that their server performs favourably and is 3 to 6 times faster on reads.
Reference: [vRTW89] <author> R. van Renesse, A. S. Tanenbaum, and A. Wilschut. </author> <title> The design of a high-performance file server. </title> <booktitle> In Proceedings of the 9th Int. Conf. on Distributed Computing Systems, </booktitle> <pages> pages 22-27. </pages> <publisher> IEEE, </publisher> <month> June </month> <year> 1989. </year> <note> (cited on page 8) </note>
Reference-contexts: Some research work on improving the performance of file systems relies heavily on the observed access patterns to make the design tradeoffs. The Bullet file server <ref> [vRTW89] </ref> is one example. The designers observed that most files in the file system they had studied were small in size and were usually accessed in their entirety.
Reference: [Wal91] <author> Gregory K. Wallace. </author> <title> The JPEG still picture compression standard. </title> <journal> Communications of the ACM, </journal> <volume> 34(4) </volume> <pages> 31-44, </pages> <month> April </month> <year> 1991. </year> <note> (cited on page 10) </note>
Reference-contexts: The proliferation of digital video standards presents another problem to continuous-medium data storage. As Liebhold [LH91] points out, there are a number of digital video standards, some for full-bandwidth video and some for compressed representations (CD-I [Inc89], DVI [Lut91], JPEG <ref> [Wal91] </ref> [CH91], MPEG [Gal91], px64 [Lio91]). The variety of formats means that the timing information necessary for the timely delivery of data is encoded in different ways. It is a challenge to design a storage service that can cope 2.5. SUPPORT OF STRUCTURED DATA 11 with this diversity.
Reference: [Wil89] <author> John Wilkes. </author> <title> DataMesh- scope and objective, a commentary. </title> <type> Technical Report HPL-DSD-89-44, </type> <institution> Hewlett-Packard Laboratories, </institution> <month> July </month> <year> 1989. </year> <note> (cited on page 37) </note>
Reference-contexts: MSSA also addresses other architectural issues such as naming, object location and protection in a broader context than HLSS and LLSS. The use of non-volatile RAM in storage services is also considered in the design of a BSC which will be discussed in chapter 6. 3.9.3 DataMesh DataMesh <ref> [Wil89] </ref> [Wil92a] is a research project on network storage service. The target hardware is an array of processing nodes interconnected by a fast, reliable, small area network. The nodes serve different functions.
Reference: [Wil92a] <author> John Wilkes. </author> <title> DataMesh research project, phase 1. </title> <booktitle> In Proceedings of the USENIX File System Workshop, </booktitle> <pages> pages 63-70, </pages> <month> May </month> <year> 1992. </year> <note> (cited on page 37) </note>
Reference-contexts: MSSA also addresses other architectural issues such as naming, object location and protection in a broader context than HLSS and LLSS. The use of non-volatile RAM in storage services is also considered in the design of a BSC which will be discussed in chapter 6. 3.9.3 DataMesh DataMesh [Wil89] <ref> [Wil92a] </ref> is a research project on network storage service. The target hardware is an array of processing nodes interconnected by a fast, reliable, small area network. The nodes serve different functions.
Reference: [Wil92b] <author> Tim D. Wilson. </author> <title> Increasing the performance of storage services for local area networks. </title> <type> PhD thesis, </type> <institution> Computer Laboratory, University of Cambridge, </institution> <month> February </month> <year> 1992. </year> <booktitle> (cited on pages 37, </booktitle> <volume> 74, </volume> <pages> 97) </pages>
Reference-contexts: RELATED WORK 37 systems and cannot describe the distribution of functional entities. 3.9.2 HLSS and LLSS The High Level Storage Service (HLSS) and the Low Level Storage Service (LLSS) are results of the Ph.D. work done in the Computer Laboratory by Sue Thomson [Tho90] and Tim Wilson <ref> [Wil92b] </ref> respectively. HLSS has been briefly described in section 2.5. It is a general purpose storage service for storing structured data. The service was designed to work on top of LLSS. LLSS is a general purpose flat file server. It was designed to exploit nonvolatile RAM to permit faster writing. <p> Needham et al. propose that a simple hardware enforced barrier (embedded in the micro-code of the processor) between the NVRAM and the CPU should greatly increase the robustness of the NVRAM against this kind of corruption. Tim Wilson <ref> [Wil92b] </ref> performs some experiments on NVRAM protection using the protection facility provided by a processor's memory management unit. He tests the strength of the scheme by modifying the content of the processor's registers and some memory locations in order to simulate 6.4. METADATA 75 hardware/software faults. <p> SUMMARY 97 the client caches to the file server's disks immediately and synchronously using fsync calls. They find that most of the write traffic is caused by the 30 second limit or fsync calls and is not due to insufficient cache size. 7.2.3 LLSS LLSS <ref> [Wil92b] </ref> is a research prototype designed by Tim Wilson, as part of his Phd research to increase the performance of network storage services (see also section 3.9.2). Like the BSC, the design has an integrated NVRAM buffer. However, LLSS uses the NVRAM buffer simply as a write-back cache.
Reference: [WPE + 83] <author> Bruce Walker, Gerald Popek, Robert English, Charles Kline, and Greg Thiel. </author> <title> The LOCUS Distributed Operating System. </title> <booktitle> In Proceedings of the Ninth ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 49-70. </pages> <publisher> ACM, </publisher> <month> October </month> <year> 1983. </year> <note> (cited on page 6) </note>
Reference-contexts: Hence the cache consistency protocols of the three designs are quite different. A comparison of the relative merits of the various cache consistency protocols is contained in [Bur88]. The availability of distributed file systems has been a concern of researchers for many years. LOCUS <ref> [WPE + 83] </ref> is an early example which 1 This refers to workstations which have local disks set up as virtual memory paging store and/or temporary file systems only. 2.3. LIMITATIONS OF TODAY'S DISTRIBUTED FILE SYSTEMS 7 combined replication and an algorithm to detect inconsistency to achieve high availability.
Reference: [WS91] <author> John Wilkes and Raymie State. </author> <title> Specifying data availability in multi-device file systems. </title> <journal> ACM Operating System Review, </journal> <volume> 25(1) </volume> <pages> 56-59, </pages> <month> January </month> <year> 1991. </year> <note> (cited on page 16) </note>
Reference-contexts: The logical domain pertains to the management of data and concerns the characteristics that are intrinsic to the data. The physical domain concerns the utilisation of storage devices. Wilkes and State <ref> [WS91] </ref> propose a similar conceptual framework to allow users to specify data availability requirements in a device and location independent way. The storage systems are responsible for matching the requirements with the appropriate storage strategy.
Reference: [ZMB93] <author> Wu Zhixue, Ken Moody, and Jean Bacon. </author> <title> A persistent programming language for multimedia databases. </title> <type> Technical Report TR 296, </type> <institution> Computer Laboratory, </institution> <year> 1993. </year> <note> (cited on page 14) </note>
Reference-contexts: The semantic file system work points to the idea of extracting file content attributes behind a file interface. This idea is appealing because the attribute extraction process is transparent and unobtrusive, and many applications can easily benefit without any changes to their code. 2.6.2 Persistent Programming Languages PC++ <ref> [ZMB93] </ref> is a persistent programming language developed to work with HLSS [Tho90]. It uses HLSS for storing both data and metadata. Also it supports the HLSS object identifier as a special type and persistent class declarations can include HLSS object identifiers.
References-found: 94

