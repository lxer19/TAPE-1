URL: http://ftp.cs.indiana.edu/pub/stoller/communication-software.ps.gz
Refering-URL: http://www.cs.indiana.edu/hyplan/stoller.html
Root-URL: http://www.cs.indiana.edu
Title: Computer Communications Software  
Author: Scott D. Stoller 
Date: July 29, 1998  
Affiliation: Indiana University  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> H. Zimmerman. </author> <title> OSI reference model|The ISO model of architecture for open systems interconnection. </title> <journal> IEEE Trans. Commun., </journal> <volume> COM-28(4), </volume> <month> April </month> <year> 1980. </year>
Reference-contexts: A protocol architecture is a collection of protocols designed to be used together. The International Organization for Standardization (ISO) issued a standard for an influential|though not widely used|protocol architecture, called the Open Systems Interconnection (OSI) Reference Model <ref> [1] </ref>. The Internet Activities Board issues standards for the protocols used on the Internet; collectively, these form the Internet Architecture or TCP/IP Architecture. Both of the standards just mentioned (and most other protocol standards) incorporate a classic design technique: layering.
Reference: [2] <author> D. E. Comer. </author> <title> Computer Networks and Internets. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1997. </year>
Reference-contexts: Figure 1 illustrates layered structure. A collection of layers is called a protocol stack (or stack, for short). The basic principle is that a message m i sent by layer i in the sender's stack is delivered to layer i in the receiver's stack <ref> [2] </ref>. A layer may modify the body of the message; for example, layer i in the sender's stack encrypts the body for secrecy, and layer i in the receiver's stack decrypts it. <p> Typically, the routing table indicates a default router, to which messages are sent when there is no explicit entry for the prefix of the destination address. For modularity, the lowest layer that introduces protocol addresses should completely hide hardware addresses from higher layers, making those layers more hardware-independent <ref> [2, Section 15.15] </ref>. In the Internet Architecture, IP addresses are introduced by the layer immediately below the IP layer; that layer is called the network access layer, network interface layer, or host-to-network layer. Domain names are a higher-level kind of protocol address in the Internet Architecture.
Reference: [3] <author> A. S. Tanenbaum. </author> <title> Distributed Operating Systems. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1995. </year>
Reference-contexts: This approach can be used to construct asynchronous versions of most synchronous services. The choice between the synchronous and asynchronous versions is typically based on performance and ease of programming <ref> [3, Chapter 2] </ref>. The synchronous version avoids the overhead of creating a thread for the up-call but may require more threads in the application to achieve the same degree of concurrency as the asynchronous version. Reliability. <p> The Internet Architecture does not directly support machine-independent addresses, though some experimental architectures, such as Amoeba, do <ref> [3] </ref>. Consequently, the (machine-dependent) address for a service can be constructed simply by concatenating the domain name (or IP address) of a machine with an identifier|called a port|that identifies that service on that machine. <p> The behavior of a centralized memory is characterized by strict consistency: any read to a memory location a returns the value stored by the most recent write to a <ref> [3, Chapter 6] </ref>. Implementing strict consistency in a distributed system is prohibitively expensive. <p> Implementing sequential consistency can incur significant overhead, so a multitude of weaker models have been proposed; Tanenbaum provides a good overview <ref> [3, Chapter 6] </ref>. Weaker models incur less overhead but are harder for application programmers to use, because weaker models are farther from providing the illusion of a centralized shared memory. The unit of sharing specifies the chunks of data that are necessarily stored and transmitted together. <p> Similarly, receiving a message might involve copying the message from a buffer on the network interface into a kernel buffer and then into the address space of the user process. Copies between kernel buffers and user space can be eliminated by exploiting hardware support for page-based virtual memory <ref> [3, Chapter 2] </ref>. By manipulating the page table (or a corresponding data structure, depending on the system), a page|and hence the data on that page|can be moved between address spaces.
Reference: [4] <author> V. Jacobson. </author> <title> Congestion avoidance and control. </title> <booktitle> In Proc. SIGCOMM '88. </booktitle> <publisher> ACM Press, </publisher> <year> 1988. </year>
Reference-contexts: To allow the time-out value to adapt quickly to changes in the round-trip delay, the sender can also maintain an estimate of the variance in the round-trip time and compute the retransmission time-out as a linear combination of the weighted average and the estimated variance <ref> [4] </ref>. This approach is used in most implementations of TCP. Retransmission is effective against transient problems, but additional mechanisms are needed to cope with longer-term network problems or computer crashes.
Reference: [5] <author> J. H. Saltzer, D. P. Reed, and D. D. Clark. </author> <title> End-to-end arguments in system design. </title> <journal> ACM Trans. Computer Systems, </journal> <volume> 2(4) </volume> <pages> 277-288, </pages> <month> November </month> <year> 1984. </year> <month> 22 </month>
Reference-contexts: This is a classic example of an end-to-end argument <ref> [5] </ref>. Now consider EDCs. An end-to-end argument implies that EDCs should be used above the routing layer. This indeed provides the desired reliability. However, in many systems, it is desirable to use EDCs on a hop-by-hop basis as well, to improve performance.
Reference: [6] <author> A. S. Tanenbaum. </author> <title> Computer Networks. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, third edition, </address> <year> 1988. </year>
Reference-contexts: The likelihood of congestion can be reduced by careful design of the entire protocol architecture, including retransmission time-outs, window size, routing algorithm, etc. Limiting the rate at which packets are injected into the network can also help prevent congestion. Two techniques for this are admission control and traffic shaping <ref> [6, Section 5.3] </ref>. Admission control is used with connection-oriented communication; if the network is heavily loaded, the admission control mechanism will refuse requests to establish new connections.
Reference: [7] <author> W. Stallings. </author> <title> Data and Computer Communications. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, fifth edition, </address> <year> 1997. </year>
Reference-contexts: If the layer responsible for connection management is above layers that provide reliable FIFO delivery, then the protocols are reasonably straightforward; otherwise, the connection management protocol will itself need to implement time-outs and retransmission to cope with message loss <ref> [7, Section 17.2] </ref>. Managing connections used for multicasts among groups of arbitrary size is part of group management, which is discussed below. Configuration and Initialization Communication software must be configured (initialized) before it can be used.
Reference: [8] <author> Kenneth P. Birman. </author> <title> The process group approach to reliable distributed computing. </title> <journal> Communications of the ACM, </journal> <volume> 36(12), </volume> <month> December </month> <year> 1993. </year>
Reference-contexts: The basic functions of a group communication system are group management and multicast. Group management supports addition and removal of members, allowing a group's membership to change dynamically. Multicast sends a message to all members of a group. Group communication is especially useful for constructing fault-tolerant systems <ref> [8] </ref>. Support for fault-tolerance can be integrated into group management and multicast. This greatly reduces the burden on the application programmer. In such systems, group management includes a mechanism that monitors all members of a group and automatically removes members that are crashed or unreachable. <p> The use of group names as addresses is a useful abstraction in many settings. This is the basis of a second class of applications of group communication, namely, those involving publication/subscription communication <ref> [8] </ref>. In this style of communication, some processes "publish" information associated with some topic, and all processes that have "subscribed" to that topic receive that information. In group-communication terms, a group is formed for each topic, and information is published by multicasting it to the group.
Reference: [9] <author> Flaviu Cristian. </author> <title> Reaching agreement on processor group membership in synchronous distributed systems. </title> <journal> Distributed Computing, </journal> <volume> 4(4), </volume> <year> 1991. </year>
Reference-contexts: Atomicity guarantees that if any member of the target group receives the message, then all members that do not crash also receive the message. A variety of distributed algorithms have been developed to enforce these guarantees <ref> [9, 10, 11] </ref>. To illustrate the benefits of group communication, consider a group of servers that provide a directory service. Each server maintains a copy of the directory; this allows concurrent processing of read-only operations and keeps the directory available even if some servers fail.
Reference: [10] <author> Aleta Ricciardi. </author> <title> Consistent process membership in asynchronous environments. </title> <editor> In K. P. Birman and R. van Renesse, editors, </editor> <title> Reliable Distributed Computing with the Isis Toolkit, chapter 13. </title> <publisher> IEEE Computer Society Press, Los Alamitos, </publisher> <address> CA, </address> <year> 1993. </year>
Reference-contexts: Atomicity guarantees that if any member of the target group receives the message, then all members that do not crash also receive the message. A variety of distributed algorithms have been developed to enforce these guarantees <ref> [9, 10, 11] </ref>. To illustrate the benefits of group communication, consider a group of servers that provide a directory service. Each server maintains a copy of the directory; this allows concurrent processing of read-only operations and keeps the directory available even if some servers fail.
Reference: [11] <author> Danny Dolev and Dalia Malki. </author> <title> The transis approach to high availability cluster communication. </title> <journal> Communications of the ACM, </journal> <volume> 39(4) </volume> <pages> 87-92, </pages> <month> April </month> <year> 1996. </year>
Reference-contexts: Atomicity guarantees that if any member of the target group receives the message, then all members that do not crash also receive the message. A variety of distributed algorithms have been developed to enforce these guarantees <ref> [9, 10, 11] </ref>. To illustrate the benefits of group communication, consider a group of servers that provide a directory service. Each server maintains a copy of the directory; this allows concurrent processing of read-only operations and keeps the directory available even if some servers fail.
Reference: [12] <author> A. D. Birrell and B. J. Nelson. </author> <title> Implementing remote procedure calls. </title> <journal> ACM Trans. Computer Systems, </journal> <volume> 2 </volume> <pages> 39-59, </pages> <month> February </month> <year> 1984. </year>
Reference-contexts: Remote Procedure Call A remote procedure call (RPC) mechanism allows a process to call a procedure that gets executed on a different computer <ref> [12, 13] </ref>.
Reference: [13] <author> B. H. Tay and A. L. Ananda. </author> <title> A survey of remote procedure calls. </title> <journal> Operating Systems Review, </journal> <volume> 24 </volume> <pages> 68-79, </pages> <month> July </month> <year> 1990. </year>
Reference-contexts: Remote Procedure Call A remote procedure call (RPC) mechanism allows a process to call a procedure that gets executed on a different computer <ref> [12, 13] </ref>.
Reference: [14] <author> R. Srinivasan. </author> <title> RPC: Remote Procedure Call specification version 2. Request for Comments 1831, </title> <institution> Internet Engineering Task Force, </institution> <month> August </month> <year> 1995. </year>
Reference-contexts: The most widely-used RPC standard is Open Network Computing RPC <ref> [14] </ref>, which is based on Sun RPC. The remote method invocation (RMI) facility of the Java programming language [15] is a form of RPC with some extensions. RPC is especially well-suited to client-server communication. For example, communication in the Sun Network File System (NFS) [16] is done by RPC.
Reference: [15] <author> K. Arnold and J. Gosling. </author> <title> The Java Programming Language. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, 2nd edition, </address> <year> 1998. </year>
Reference-contexts: The most widely-used RPC standard is Open Network Computing RPC [14], which is based on Sun RPC. The remote method invocation (RMI) facility of the Java programming language <ref> [15] </ref> is a form of RPC with some extensions. RPC is especially well-suited to client-server communication. For example, communication in the Sun Network File System (NFS) [16] is done by RPC. This, the caller and the remote computer are sometimes referred to as the client and the server, respectively.
Reference: [16] <author> R. Sandberg. </author> <title> The Sun Network File System: Design, Implementation, and Experience. Sun Microsystems, </title> <publisher> Inc., </publisher> <address> Mountain View, CA, </address> <year> 1987. </year>
Reference-contexts: The remote method invocation (RMI) facility of the Java programming language [15] is a form of RPC with some extensions. RPC is especially well-suited to client-server communication. For example, communication in the Sun Network File System (NFS) <ref> [16] </ref> is done by RPC. This, the caller and the remote computer are sometimes referred to as the client and the server, respectively. RPC hides the tasks of marshalling and unmarshalling from the application programmer.
Reference: [17] <author> M. Satyanarayanan. </author> <title> Scalable, secure, and highly available distributed file access. </title> <journal> IEEE Computer, </journal> <volume> 23 </volume> <pages> 9-21, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: UDP has less overhead, because it does not provide reliability, flow control, or congestion control. The primary benefit of using UDP is the decreased overhead|in particular, the decreased load on the server, because in many client-server systems, servers are more heavily loaded than clients <ref> [17] </ref>. For a server with hundreds or thousands of frequent or infrequent clients, the costs of establishing, maintaining, and terminating connections could cause the server to become a bottleneck.
Reference: [18] <author> K. Li and P. Hudak. </author> <title> Memory coherence in shared virtual memory systems. </title> <journal> ACM Trans. Computer Systems, </journal> <volume> 7 </volume> <pages> 321-359, </pages> <month> November </month> <year> 1989. </year>
Reference-contexts: A mechanism is needed to report such errors to the caller, e.g., by introducing new exceptions. Distributed Shared Memory RPC takes a specific program construct|namely, procedure call|and extends it to operate remotely. Distributed Shared Memory (DSM) <ref> [18] </ref> takes two program constructs|namely, memory read and memory write|and extends them to operate remotely. <p> DSM can be viewed as an extension to a traditional virtual-memory system, in which invalid pages are fetched from other computers instead of from disk. From this perspective, it is natural to use a page of memory as the unit of sharing, as in <ref> [18] </ref>. This allows the DSM implementation to exploit hardware and operating-system support for virtual memory. When a shared page is not available locally, it is marked as invalid in the process's page table, so an access to that page causes a page fault.
Reference: [19] <author> L. Lamport. </author> <title> How to make a multiprocessor computer that correctly executes multiprocess programs. </title> <journal> IEEE Trans. Comput., </journal> <volume> C-28:690-691, </volume> <month> September </month> <year> 1979. </year>
Reference-contexts: A slightly weaker model is sequential consistency: the result of any execution is the same as if the operations of all processors were executed in some sequential order, and the operations of each individual processor appears in this sequence in the order specified by its program <ref> [19] </ref>. Intuitively, sequential consistency differs from strict consistency by allowing a read to return an "old" value if there is no way for any process to determine that the returned value is old.
Reference: [20] <author> H. E. Bal, M. F. Kaashoek, and A. S. Tanenbaum. Orca: </author> <title> A language for parallel programming of distributed systems. </title> <journal> IEEE Trans. Softw. Eng., </journal> <volume> 18 </volume> <pages> 190-205, </pages> <year> 1992. </year>
Reference-contexts: The latter is called remote method invocation (RMI). Shared objects can be implemented by combining implementation techniques for RPC and DSM. This approach underlies the shared objects provided by the Orca programming language <ref> [20] </ref>. Most current implementations of distributed object systems are simpler (hence, for some access patterns, slightly more efficient, but for some access patterns, much less efficient) than the DSM-like shared objects described above.
Reference: [21] <author> Cay S. Horstmann and Gary Cornell. </author> <title> Core Java 1.1, Volume II Advanced Features. </title> <publisher> Prentice-Hall, </publisher> <year> 1998. </year>
Reference-contexts: Consequently, all invocations of the methods of a particular object are executed on the same computer, regardless of which computer invoked them. For example, this is the case for distributed objects in version 1.1 of the Java programming language <ref> [21] </ref>. (Objects are sometimes copied, but this is fundamentally different than replication: an update to a copy of an object has no effect on the original or other copies.) However, it is expected that future implementations will support replication.
Reference: [22] <author> Thorsten von Eicken, Anindya Basu, Vineet Buch, and Werner Vogels. U-net: </author> <title> A user-level network interface for parallel and distributed computing. </title> <booktitle> In Proc. 15th ACM Symposium on Operating System Principles, </booktitle> <pages> pages 40-53. </pages> <publisher> ACM Press, </publisher> <year> 1995. </year> <month> 23 </month>
Reference-contexts: For short messages, the benefit is negligible; for large messages, the benefit can be significant. Some experimental systems achieve "zero-copy" communication by reprogramming the network interface to directly access buffers in user address spaces <ref> [22] </ref>; an additional benefit of this design is that messages can be sent and received without the participation of the kernel. Integrated layer processing (ILP) reduces the overhead from modular (layered) implementation of communication software [23, 24].
Reference: [23] <author> D. Clark and D. Tennenhouse. </author> <title> Architectural considerations for a new generation of protocols. </title> <booktitle> In Proc. ACM SIGCOMM '90, </booktitle> <pages> pages 201-208. </pages> <publisher> ACM Press, </publisher> <month> September </month> <year> 1990. </year>
Reference-contexts: Integrated layer processing (ILP) reduces the overhead from modular (layered) implementation of communication software <ref> [23, 24] </ref>. Consider a protocol stack containing two or more layers that each access every byte of a message (e.g., layers that compute a checksum or put the data into a standard format for transmission).
Reference: [24] <author> M. Abbott and L. Peterson. </author> <title> Increasing network throughput by integrating protocol layers. </title> <journal> IEEE/ACM Trans. on Networking, </journal> <volume> 1(5) </volume> <pages> 600-610, </pages> <month> October </month> <year> 1993. </year>
Reference-contexts: Integrated layer processing (ILP) reduces the overhead from modular (layered) implementation of communication software <ref> [23, 24] </ref>. Consider a protocol stack containing two or more layers that each access every byte of a message (e.g., layers that compute a checksum or put the data into a standard format for transmission).
Reference: [25] <author> T. Proebsting and S. Watterson. </author> <title> Filter fusion. </title> <booktitle> In Proc. Twenty-third ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 119-130. </pages> <publisher> ACM Press, </publisher> <year> 1996. </year> <month> 24 </month>
Reference-contexts: Having the programmer combine the loops manually is tedious and destroys modularity. A more promising approach is to have an program transformation system that automatically integrates the loops <ref> [25] </ref>. Cross-references. Communication Protocols.
References-found: 25

