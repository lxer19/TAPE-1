URL: ftp://ftp.cs.umass.edu/pub/techrept/techreport/1994/UM-CS-1994-061.ps
Refering-URL: 
Root-URL: 
Email: brodley@cs.umass.edu  
Title: Recursive Automatic Algorithm Selection for Inductive Learning  
Author: Carla E. Brodley 
Address: Amherst, Massachusetts 01003 USA  
Affiliation: Department of Computer Science University of Massachusetts  
Abstract: COINS Technical Report 94-61 August 1994 
Abstract-found: 1
Intro-found: 1
Reference: <author> Aha, D. W., & Kibler, D. </author> <year> (1989). </year> <title> Noise-tolerant instance-based learning algorithms. </title> <booktitle> Proceedings of the Eleventh International Joint Conference on Artificial Intelligence (pp. </booktitle> <pages> 794-799). </pages> <address> Detroit, Michigan: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Aha, David W. </author> <year> (1990). </year> <title> A study of instance-based algorithms for supervised learning tasks: Mathematical, empirical, and psychological evaluations. </title> <institution> Doctoral disserta-tion, Department of Information and Computer Science, University of California, </institution> <address> Irvine, CA. </address>
Reference: <author> Aha, D. W. </author> <year> (1991a). </year> <title> Incremental constructive induction: An instance-based ap-proach. </title> <booktitle> Machine Learning: Proceedings of the Eighth International Workshop (pp. </booktitle> <pages> 117-121). </pages> <address> Evanston, IL: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Aha, D. W., Kibler, D., & Albert, M. </author> <year> (1991b). </year> <title> Instance-based learning algorithms. </title> <journal> Machine Learning, </journal> <volume> 6, </volume> <pages> 37-66. </pages>
Reference: <author> Aha, D. W. </author> <year> (1992). </year> <title> Generalizing from case studies: A case study. </title> <booktitle> Machine Learning: Proceedings of the Ninth International Conference (pp. </booktitle> <pages> 1-10). </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Ash, T. </author> <year> (1989). </year> <title> Dynamic node creation in backpropagation networks, </title> <type> (ICS Report 8901), </type> <address> San Diego, CA: </address> <institution> University of California, Institute for Cognitive Science. </institution>
Reference: <author> Breiman, L., Friedman, J. H., Olshen, R. A., & Stone, C. J. </author> <year> (1984). </year> <title> Classification and regression trees. </title> <address> Belmont, CA: </address> <publisher> Wadsworth International Group. </publisher>
Reference: <author> Breiman, L. </author> <year> (1992). </year> <title> Stacked regressions, </title> <type> (Technical Report No. 367), </type> <institution> University of California, Berkeley. </institution>
Reference: <author> Brodley, C. E., & Utgoff, P. E. </author> <year> (1992). </year> <title> Multivariate versus univariate decision trees, </title> <type> (Coins Technical Report 92-8), </type> <institution> Amherst, MA: University of Massachusetts, Department of Computer and Information Science. </institution>
Reference: <author> Brodley, C. E., & Utgoff, P. E. </author> <title> (in press). Multivariate decision trees. </title> <booktitle> Machine Learning. </booktitle>
Reference: <author> Brodley, C. E. </author> <year> (1993). </year> <title> Addressing the selective superiority problem: Automatic algorithm/model class selection. </title> <booktitle> Machine Learning: Proceedings of the Tenth International Conference (pp. </booktitle> <pages> 17-24). </pages> <address> Amherst, MA: </address> <publisher> Morgan Kaufmann. </publisher> <address> 105 Cardie, C. </address> <year> (1993). </year> <title> Using decision trees to improve case-based learning. </title> <booktitle> Machine Learning: Proceedings of the Tenth International Conference (pp. </booktitle> <pages> 25-32). </pages> <address> Amherst, MA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Chatterjee, S., & Price, B. </author> <year> (1977). </year> <title> Regression analysis by example. </title> <address> New York: </address> <publisher> John Wiley and Sons. </publisher>
Reference: <author> Clark, P., & Niblett, T. </author> <year> (1989). </year> <title> The CN2 induction algorithm. </title> <journal> Machine Learning, </journal> <volume> 3, </volume> <pages> 261-283. </pages>
Reference: <author> Cover, T. M. </author> <year> (1973). </year> <title> Enumerative source coding. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> IT-19, </volume> <pages> 73-77. </pages>
Reference: <author> Detrano, R., Janosi, A., Steinbrunn, W., Pfisterer, M., Schmid, J., Sandhu, S., Guppy, K., Lee, S., & Froelicher, V. </author> <year> (1989). </year> <title> International application of a new probability algorithm for the diagnosis of coronary artery disese. </title> <journal> American Journal of Cardiology, </journal> <volume> 64, </volume> <pages> 304-310. </pages>
Reference: <author> Dietterich, T. G. </author> <year> (1990). </year> <title> Machine learning. </title> <booktitle> Annual Review of Computer Science, </booktitle> <pages> 4. </pages>
Reference: <author> Draper, N. R., & Smith, H. </author> <year> (1981). </year> <title> Applied regression analysis. </title> <address> New York: </address> <publisher> John Wiley and Sons. </publisher>
Reference: <author> Drucker, H., Schapire, R., & Simard, P. </author> <year> (1993). </year> <title> Improving the performance in neural networks using a boosting algorithm. </title> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> 5, </volume> <pages> 42-49. </pages>
Reference: <author> Duda, R. O., & Hart, P. E. </author> <year> (1973). </year> <title> Pattern classification and scene analysis. </title> <address> New York: </address> <publisher> Wiley & Sons. </publisher>
Reference: <author> Elias, P. </author> <year> (1975). </year> <title> Universal codeword sets and representations of the integers. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> IT-21, </volume> <pages> 194-203. </pages>
Reference: <author> Fahlman, S. E., & Lebiere, C. </author> <year> (1990). </year> <title> The cascade correlation architecture. </title> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> 2, </volume> <pages> 524-532. </pages>
Reference: <author> Falkenhainer, B. C., & Michalski, R. S. </author> <year> (1986). </year> <title> Integrating quantitative and qualitative discovery: The ABACUS system. </title> <journal> Machine Learning, </journal> <volume> 1, </volume> <pages> 367-401. </pages>
Reference: <author> Fayyad, U. M., & Irani, K. B. </author> <year> (1992). </year> <title> On the handling of continuous-valued attributes in decision tree generation. </title> <journal> Machine Learning, </journal> <volume> 8, </volume> <pages> 87-102. </pages>
Reference: <author> Feng, C., Sutherland, A., King, R., Muggleton, S., & Henry, R. </author> <year> (1993). </year> <title> Comparison of machine learning classifiers to statistics and neural networks. </title> <booktitle> Preliminary Papers of the Fourth International Workshop on Artificial Intelligence and Statistics (pp. </booktitle> <pages> 41-52). </pages>
Reference-contexts: The knowledge resulting from such efforts can be used to form a heuristic search procedure for automatic algorithm selection. In the STATLOG project, sixteen algorithms were compared across twelve data sets <ref> (Feng, et al. 1993) </ref>. One of the goals of the project was to discern what characteristics of data sets suit particular algorithms. Twelve statistical characteristics were uncovered that they think will be useful for predicting which of the algorithms will perform the best for a given task. <p> A direction in which to extend MCS is to incorporate the results of efforts such as the STATLOG project <ref> (Feng, et al. 1993) </ref> in order to reduce the amount of search required. One of the results of the STATLOG project is a study that relates statistical measures of a data set to the performance of different algorithms.
Reference: <author> Fisher, R. A. </author> <year> (1936). </year> <title> Multiple measures in taxonomic problems. </title> <journal> Annals of Eugen-ics, </journal> <volume> 7, </volume> <pages> 179-188. </pages>
Reference: <author> Frean, M. </author> <year> (1990a). </year> <title> Small nets and short paths: Optimising neural computation. </title> <type> Doctoral dissertation, </type> <institution> Center for Cognitive Science, University of Edinburgh. </institution>
Reference: <author> Frean, M. </author> <year> (1990b). </year> <title> The upstart algorithm: A method for constructing and training feedforward neural networks. </title> <journal> Neural Computation, </journal> <volume> 2, </volume> <pages> 198-209. </pages>
Reference: <author> Gallant, S. I. </author> <year> (1986). </year> <title> Optimal linear discriminants. </title> <booktitle> Proceedings of the International Conference on Pattern Recognition (pp. </booktitle> <pages> 849-852). </pages> <publisher> IEEE Computer Society Press. </publisher>
Reference: <author> Hampson, S. E., & Volper, D. J. </author> <year> (1986). </year> <title> Linear function neurons: Structure and training. </title> <journal> Biological Cybernetics, </journal> <volume> 53, </volume> <pages> 203-217. </pages>
Reference: <author> Hanson, S. J., & Pratt, L. Y. </author> <year> (1989). </year> <title> Comparing biases for minimal network construction with backpropagation. </title> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> 1, </volume> <pages> 177-185. </pages>
Reference: <author> Hocking, R. R. </author> <year> (1986). </year> <title> The analysis and selection of variables in linear regression. </title> <journal> Biometrics, </journal> <volume> 32, </volume> <pages> 1-49. </pages>
Reference: <author> Honavar, V., & Uhr, L. </author> <year> (1988). </year> <title> A network of neuron-like units that learn to perceive by generation as well as reweighting of its links. </title> <booktitle> Proc. of the 1988 Connectionist Summer School. </booktitle>
Reference: <author> Jacobs, R. A., Jordan, M. I., Nowlan, S. J., & Hinton, G. E. </author> <year> (1991). </year> <title> Adaptive mixtures of local experts. </title> <journal> Neural Computation, </journal> <volume> 3, </volume> <pages> 79-87. </pages>
Reference: <author> Karnin, E. D. </author> <year> (1990). </year> <title> A simple procedure for pruning back-propagation trained neural networks. </title> <journal> IEEE Trans. on Neural Networks, </journal> <volume> 1, </volume> <pages> 239-242. </pages>
Reference: <author> Kittler, J. </author> <year> (1986). </year> <title> Feature selection and extraction. </title> <editor> In Young & Fu (Eds.), </editor> <booktitle> Handbook of pattern recognition and image processing. </booktitle> <address> New York: </address> <publisher> Academic Press. </publisher>
Reference: <author> Kokar, M. M. </author> <year> (1986). </year> <title> Determining arguments of invariant functional descriptions. </title> <journal> Machine Learning, </journal> <volume> 1, </volume> <pages> 403-422. </pages>
Reference: <author> Langley, P. </author> <year> (1986). </year> <title> Machine learning and discovery. </title> <journal> Machine Learning, </journal> <volume> 1, </volume> <pages> 363-366. </pages>
Reference: <author> Le Cun, Y., Denker, J. S., & Solla, S. A. </author> <year> (1990). </year> <title> Optimal brain damage. </title> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> 2, </volume> <pages> 598-605. </pages>
Reference: <author> Lesser, V., Nawab, S. H., & Klassner, F. </author> <note> (to appear March 1995). </note> <author> IPUS: </author> <title> An architecture for the integrated processing and understanding of signals. </title> <journal> Artificial Intelligence. </journal>
Reference: <author> Linhart, H., & Zucchini, W. </author> <year> (1986). </year> <title> Model selection. </title> <address> NY: </address> <note> Wiley. 107 Mangasarian, </note> <author> O. L. , & Wolberg, W. H. </author> <year> (1990). </year> <title> Cancer diagnosis via linear programming. </title> <journal> SIAM News, </journal> <pages> 23 , 1-18. </pages>
Reference: <author> Matheus, C. J. </author> <year> (1990). </year> <title> Feature construction: An analytic framework and an appli-cation to decision trees. </title> <type> Doctoral dissertation, </type> <institution> Department of Computer Science, University of Illinois, Urbana-Champaign, IL. </institution>
Reference: <author> Michalski, R. S., & Chilausky, R. L. </author> <year> (1980). </year> <title> Learning by being told and learning from examples: An experimental comparison of the two methods of knowledge acquisition in the context of developing an expert system for soybean disease diagnosis. </title> <journal> Policy Analysis and Information Systems, </journal> <volume> 4, </volume> <pages> 125-160. </pages>
Reference: <author> Michalski, R. S. </author> <year> (1983). </year> <title> A theory and methodology of inductive learning. </title> <editor> In Michalski, Carbonell & Mitchell (Eds.), </editor> <booktitle> Machine learning: An artificial intelligence approach. </booktitle> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Moret, B. M. E. </author> <year> (1982). </year> <title> Decision trees and diagrams. </title> <journal> Computing Surveys, </journal> <volume> 14, </volume> <pages> 593-623. </pages>
Reference: <author> Mozer, M. C., & Smolensky, P. </author> <year> (1989). </year> <title> Skeletonization: A technique for trimming the fat from a network via relevance assessment. </title> <journal> Connection Science, </journal> <volume> 1, </volume> <pages> 3-26. </pages>
Reference: <author> Nilsson, N. J. </author> <year> (1965). </year> <title> Learning machines. </title> <address> New York: </address> <publisher> McGraw-Hill. </publisher>
Reference: <author> Pagallo, G., & Haussler, D. </author> <year> (1990). </year> <title> Boolean feature discovery in empirical learning. </title> <booktitle> Machine Learning, </booktitle> <pages> 71-99. </pages>
Reference: <author> Pagallo, G. M. </author> <year> (1990). </year> <title> Adaptive decision tree algorithms for learning from examples. </title> <type> Doctoral dissertation, </type> <institution> University of California at Santa Cruz. </institution>
Reference: <author> Provost, F. J., & Buchanan, B. G. </author> <year> (1994). </year> <title> Inductive policy: The pragmatics of bias selection , (Technical Report ISL-94-4), </title> <institution> University of Pittsburgh, Intelligent Systems Laboratory, Department of Computer Science. </institution>
Reference: <author> Provost, F. J., & Buchanan, B. G. </author> <year> (1992). </year> <title> Inductive policy. </title> <booktitle> Proceedings of the Tenth National Conference on Artificial Intelligence (pp. </booktitle> <pages> 255-261). </pages> <address> San Jose, CA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Quinlan, J. R. </author> <year> (1986). </year> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1, </volume> <pages> 81-106. </pages>
Reference: <author> Quinlan, J. R. </author> <year> (1987). </year> <title> Simplifying decision trees. </title> <journal> International Journal of Manmachine Studies, </journal> <volume> 27, </volume> <pages> 221-234. </pages>
Reference: <author> Quinlan, J. R. </author> <year> (1989). </year> <title> Unknown attribute values in induction. </title> <booktitle> Proceedings of the Sixth International Workshop on Machine Learning (pp. </booktitle> <pages> 164-168). </pages> <address> Ithaca, NY: </address> <publisher> Morgan Kaufmann. 108 Quinlan, </publisher> <editor> J. R. </editor> <year> (1993). </year> <title> Combining instance-based and model-based learning. </title> <booktitle> Ma-chine Learning: Proceedings of the Tenth International Conference (pp. </booktitle> <pages> 236-243). </pages> <address> Amherst, MA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Rendell, L., Seshu, R., & Tcheng, D. </author> <year> (1987). </year> <title> Layered concept learning and dynamically variable bias management. </title> <booktitle> Proceedings of the Tenth International Joint Conference on Artificial Intelligence (pp. </booktitle> <pages> 308-314). </pages> <address> Milan, Italy: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Rendell, L., & Cho, H. </author> <year> (1990). </year> <title> Empirical learning as a function of concept character. </title> <journal> Machine Learning, </journal> <volume> 5, </volume> <pages> 267-298. </pages>
Reference: <author> Rissanen, J. </author> <year> (1989). </year> <title> Stochastic complexity in statistical inquiry. </title> <address> New Jersey: </address> <publisher> World Scientific. </publisher>
Reference: <author> Salzberg, S. </author> <year> (1991). </year> <title> A nearest hyperrectangular learning method. </title> <journal> Machine Learning, </journal> <volume> 6, </volume> <pages> 251-276. </pages>
Reference: <author> Saxena, S. </author> <year> (1991a). </year> <title> Predicting the effect of instance representations on inductive learning. </title> <type> Doctoral dissertation, </type> <institution> Department of Computer Science, University of Massachusetts, </institution> <address> Amherst, MA. </address>
Reference: <author> Saxena, S. </author> <year> (1991b). </year> <title> An algorithm to evaluate instance representations, </title> <address> (TR-91-21), Amherst, MA: </address> <institution> University of Massachusetts, Computer and Information Science Department. </institution>
Reference: <author> Schaffer, C. </author> <year> (1990). </year> <title> A proven domain-independent scientific function-finding al-gorithm. </title> <booktitle> Proceedings of Eighth National Conference on Artificial Intelligence (pp. </booktitle> <pages> 828-833). </pages> <publisher> MIT Press. </publisher>
Reference: <author> Schaffer, C. </author> <year> (1993). </year> <title> Selecting a classification method by cross-validation. </title> <booktitle> Preliminary Papers of the Fourth International Workshop on Artificial Intelligence and Statistics (pp. </booktitle> <pages> 15-25). </pages>
Reference: <author> Schapire, R. E. </author> <year> (1990). </year> <title> The strength of weak learnability. </title> <journal> Machine Learning, </journal> <volume> 5, </volume> <pages> 197-227. </pages>
Reference: <author> Schlimmer, J. C., & Granger, R. H., Jr. </author> <year> (1986). </year> <title> Incremental learning from noisy data. </title> <journal> Machine Learning, </journal> <volume> 1, </volume> <pages> 317-354. </pages>
Reference: <author> Schlimmer, J. C. </author> <year> (1987). </year> <title> Concept acquisition through representational adjustment. </title> <type> Doctoral dissertation, </type> <institution> University of California, Irvine. </institution>
Reference: <author> Shavlik, J. W., Mooney, R. J., & Towell, G. G. </author> <year> (1991). </year> <title> Symbolic and neural learning algorithms: An experimental comparison. </title> <journal> Machine Learning, </journal> <volume> 6, </volume> <pages> 111-144. </pages> <note> 109 Sutton, </note> <author> R. S. </author> <year> (1988). </year> <title> NADALINE: A normalized adaptive linear element that learns efficiently, </title> <institution> (GTE TR88-509.4), GTE Laboratories Incorporated. </institution>
Reference: <author> Sutton, R. S., & Matheus, C. J. </author> <year> (1991). </year> <title> Learning polynomial functions by feature construction. </title> <booktitle> Machine Learning: Proceedings of the Eighth International Workshop (pp. </booktitle> <pages> 208-212). </pages> <address> Evanston, IL: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Tcheng, D., Lambert, B., C-Y Lu, S., & Rendell, </author> <title> L (1989). Building robust learning systems by computing induction and optimization. </title> <booktitle> Proceedings of the Eleventh International Joint Conference on Artificial Intelligence (pp. </booktitle> <pages> 806-812). </pages> <address> Detroit, Michigan: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Towell, G., Craven, M., & Shavlik, J. </author> <year> (1991). </year> <title> Constructive induction in knowledgebased neural networks. </title> <booktitle> Machine Learning: Proceedings of the Eighth International Workshop (pp. </booktitle> <pages> 213-217). </pages> <address> Evanston, IL: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Utgoff, P. E. </author> <year> (1989). </year> <title> Perceptron trees: A case study in hybrid concept representa-tions. </title> <journal> Connection Science, </journal> <volume> 1, </volume> <pages> 377-391. </pages>
Reference: <author> Utgoff, P. E., & Brodley, C. E. </author> <year> (1990). </year> <title> An incremental method for finding multivariate splits for decision trees. </title> <booktitle> Proceedings of the Seventh International Conference on Machine Learning (pp. </booktitle> <pages> 58-65). </pages> <address> Austin, TX: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Utgoff, P. E., & Brodley, C. E. </author> <year> (1991). </year> <title> Linear machine decision trees, </title> <type> (COINS Technical Report 91-10), </type> <institution> Amherst, MA: University of Massachusetts, Department of Computer and Information Science. </institution>
Reference: <author> Weiss, S. M., & Kulikowski, C. S. </author> <year> (1991). </year> <title> Computer systems that learn. </title> <address> Palo Alto: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Weiss, S. M., & Kapouleas, I. </author> <year> (1989). </year> <title> An empirical comparision of pattern recogni-tion, neural nets, and machine learning classification methods. </title> <booktitle> Proceedings of the Eleventh International Joint Conference on Artificial Intelligence (pp. </booktitle> <pages> 781-787). </pages> <address> Detroit, Michigan: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Wolpert, D. H. </author> <year> (1992). </year> <title> Stacked generalization. </title> <booktitle> Neural Networks, </booktitle> <volume> 5, </volume> <pages> 241-259. </pages>
Reference: <author> Yang, D. S., Rendell, L., & Blix, G. </author> <year> (1991). </year> <title> Fringe-like feature construction a comparitive study and a unifying scheme. </title> <booktitle> Machine Learning: Proceedings of the Eighth International Workshop. </booktitle> <address> Evanston, IL: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Yerramareddy, S., Tcheng, D. K., Lu, S. , & Assanis, D. N. </author> <year> (1992). </year> <title> Creating and using models for engineering design. </title> <journal> IEEE Expert, </journal> <volume> 3, </volume> <pages> 52-59. </pages>
Reference: <author> Zhang, X., Mesirov, J. P., & Waltz, D. L. </author> <year> (1992). </year> <title> Hybrid system for protein secondary structure prediction. </title> <journal> Journal of Molecular Biology, </journal> <volume> 225, </volume> <pages> 1049-1063. 110 </pages>
References-found: 77

