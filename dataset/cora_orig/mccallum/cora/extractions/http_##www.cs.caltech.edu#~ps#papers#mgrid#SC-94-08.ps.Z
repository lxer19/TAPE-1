URL: http://www.cs.caltech.edu/~ps/papers/mgrid/SC-94-08.ps.Z
Refering-URL: http://www.cs.caltech.edu/~ps/papers/mgrid/
Root-URL: http://www.cs.caltech.edu
Title: Folkmar A. Bornemann On the Convergence of Cascadic Iterations for Elliptic Problems  
Author: SC 
Date: 94-8 (Marz 1994)  
Abstract-found: 0
Intro-found: 0
Reference: [1] <author> R. E. Bank and T. F. Dupont. </author> <title> An optimal order process for solving elliptic finite element equations. </title> <journal> Math. Comp. </journal> <volume> 36, </volume> <month> 967-975 </month> <year> (1981). </year>
Reference-contexts: A smoother in the sense of (4) fulfills kS j;m j v j k a c j fffl j Proof. This can be shown be an usual interpolation argument using discrete Sobolev norms like those introduced in <ref> [1] </ref> and their equivalence to the fractional Sobolev norms. We are now able to state and prove the main convergence estimate for the cascadic iteration (1). Theorem 1.2.
Reference: [2] <author> F. A. Bornemann, B. Erdmann, and R. Kornhuber. </author> <title> A posteriori error estimates for elliptic problems in two and three space dimensions. </title> <note> SIAM J. Numer. Anal. (submitted). </note>
Reference-contexts: ! (d+1)=2 The actual approximation error ku u j k a is also not known, so we replace this expression by ku u j k a * j1 n j1 ! 1=d 11 for some estimate * j1 of the previous approximation error ku u j1 k a , cf. <ref> [2] </ref>. This algorithm is nearest to the a priori choice of the parameters m j . In practice, the basic iteration can be accurate enough much earlier than stated in theory.
Reference: [3] <author> P. Deuflhard. </author> <title> Cascadic conjugate gradient methods for elliptic partial differential equations. Algorithm and numerical results. </title> <editor> In D. Keyes and J. Xu, editors, </editor> <volume> 13 Fig. </volume> <month> 2. </month> <title> Number of iterations vs. </title> <booktitle> number of unknowns "Proceedings of the 7th International Conference on Domain Decomposition Methods 1993". AMS, </booktitle> <address> Providence (1994). </address>
Reference-contexts: This method was named and invented by Deuflhard, Leinen and Yserentant [4]. * CCG-iteration: the basic iteration is a plain cg-method, the m j are chosen a posteriori. CCG stands for cascadic conjugate gradient method and was introduced by Deuflhard <ref> [3] </ref>. <p> The optimality of the nested iteration and of Cascade are well known [5, 4], at least for certain situations. The optimality of the CCG method has been demonstrated by several numerical examples <ref> [3] </ref>. This has been considered as rather astonishing, since only a plain basic iteration is used. Shaidurov [10] has recently shown for H 2 -regular problems and quasi-uniform triangulations in two dimension, that the CCG method is optimal for a certain choice of the parameters m j . <p> Property (4 (ii)) was already stated in Theorem 2.2. With the help of this majorizing smoother it is immediately clear, that Theorem 1.2, Lemma 1.3, Lemma 1.4 and Lemma 1.5 remain valid for the cascadic iteration with the cg-method as basic iteration, short the CCG-method of Deuflhard <ref> [3] </ref>. In particular the CCG method is optimal for d = 2; 3. 3. Adaptive control of the CCG-method. <p> Despite the fact, that our termination criterion is different from the original one of Deuflhard <ref> [3] </ref> we get comparable numerical results for the CCG method. They share the essential feature that the iteration has to be more accurate on coarser triangulations. However, the basis for (10) seems to be a sound combination of theory and heuristics. Example. <p> We compared three different implementations: * CCG1 : the CCG method with termination criterion (10). 12 Fig. 1. Typical adaptive triangulation with isolines of solution * CCG2 : the CCG method with Deuflhard's termination criterion <ref> [3] </ref>. * CSGS : an adaptive cascadic iteration using symmetric Gauss-Seidel as basic iteration. We implemented the termination criterion (10) in this case also. We observe that the CCG1 and CCG2 implementations are comparable, the CCG1 needs one adaptive step less in order to achieve the tolerance TOL.
Reference: [4] <author> P. Deuflhard, P. Leinen, and H. Yserentant. </author> <title> Concepts of an adaptive hierarchical finite element code. IMPACT Compt. </title> <journal> Sci. Engrg. </journal> <volume> 1, </volume> <month> 3-35 </month> <year> (1989). </year>
Reference-contexts: Hackbusch [5]. * Cascade: the basic iteration is a multilevel preconditioned cg-method, the m j are chosen a posteriori due to certain termination criteria. This method was named and invented by Deuflhard, Leinen and Yserentant <ref> [4] </ref>. * CCG-iteration: the basic iteration is a plain cg-method, the m j are chosen a posteriori. CCG stands for cascadic conjugate gradient method and was introduced by Deuflhard [3]. <p> The optimality of the nested iteration and of Cascade are well known <ref> [5, 4] </ref>, at least for certain situations. The optimality of the CCG method has been demonstrated by several numerical examples [3]. This has been considered as rather astonishing, since only a plain basic iteration is used.
Reference: [5] <author> W. Hackbusch. </author> <title> "Multi-Grid Methods and Applications". </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, Heidelberg, New York (1985). </address>
Reference-contexts: Hackbusch <ref> [5] </ref>. * Cascade: the basic iteration is a multilevel preconditioned cg-method, the m j are chosen a posteriori due to certain termination criteria. <p> The optimality of the nested iteration and of Cascade are well known <ref> [5, 4] </ref>, at least for certain situations. The optimality of the CCG method has been demonstrated by several numerical examples [3]. This has been considered as rather astonishing, since only a plain basic iteration is used. <p> We call the basic iteration a smoother, if it obeys the smoothing property (i) kS j;m j v j k a c j fl kv j k L 2 8v j 2 X j ;(4) with a parameter 0 &lt; fl 1. As is shown in <ref> [5] </ref> the symmetric Gau-Seidel-, the SSOR- and the damped Jacobi-iteration are smoothers in the sense of (4) with parameter fl = 1=2: Lemma 1.1. A smoother in the sense of (4) fulfills kS j;m j v j k a c j fffl j Proof.
Reference: [6] <author> W. Hackbusch. </author> <title> "Theory and Numerical Treatment of Elliptic Differential Equations". </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, Heidelberg, New York (1992). </address>
Reference-contexts: problem will be H 1+ff -regularity for some 0 &lt; ff 1, i.e., kuk H 1+ff c kf k H ff1 8f 2 H ff1 (): The approximation error of the finite element method is then given in energy norm as ku u j k a c h ff cf. <ref> [6, Lemma 8.4.9] </ref>. By the well-known Aubin-Nitsche lemma and an interpolation argument one gets the approximation property ku j u j1 k H 1ff c h ff cf. [6, Theorem 8.4.14]. <p> By the well-known Aubin-Nitsche lemma and an interpolation argument one gets the approximation property ku j u j1 k H 1ff c h ff cf. <ref> [6, Theorem 8.4.14] </ref>. <p> Proof. The usual inverse inequality shows that the maximum eigenvalue of the stiffness matrix can be estimated by j ch d2 cf. <ref> [6, Theorem 8.8.6] </ref>. The euclidean norm with respect to the nodal basis is related to the L 2 -norm by 1 h d L 2 ch d cf. [6, Theorem 8.8.1]. <p> The usual inverse inequality shows that the maximum eigenvalue of the stiffness matrix can be estimated by j ch d2 cf. [6, Theorem 8.8.6]. The euclidean norm with respect to the nodal basis is related to the L 2 -norm by 1 h d L 2 ch d cf. <ref> [6, Theorem 8.8.1] </ref>. Thus Theorem 2.2 gives kS j;m j v j k a c (d2)=2 2m j + 1 h 1 2m j + 1 i.e., (4 (i)) with fl = 1. Property (4 (ii)) was already stated in Theorem 2.2.
Reference: [7] <author> V. P. Il'in. </author> <title> Some estimates for conjugate gradient methods. </title> <journal> USSR Comput. Math. and Math. Phys. </journal> <volume> 16, </volume> <month> 22-30 </month> <year> (1976). </year>
Reference-contexts: Thus, it seems that our frame up to now does not cover the cg-method. However, there is a remedy which uses results on the cg-method well known in the Russian literature <ref> [7, 9] </ref>. We have to fix some notation.
Reference: [8] <author> P. Oswald. </author> <title> On function spaces related to finite element approximation theory. </title> <journal> Z. Anal. Anwend. </journal> <volume> 9, </volume> <month> 43-64 </month> <year> (1990). </year>
Reference-contexts: Thus it is a statement of the efficiency of a triangulation. Note that quasi-uniform triangulations do not accomplish assumption (ii) for problems which are not H 2 -regular. The second assumption is a statement of optimal accuracy, which is justified by results of nonlinear approximation theory like <ref> [8] </ref>. The same proof as for Theorem 1.2 gives the following 10 Lemma 3.1.
Reference: [9] <author> V. V. Shaidurov. </author> <title> "Multigrid Methods for Finite Elements". </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Dordrecht, Boston, London (1994). </address>
Reference-contexts: Thus, it seems that our frame up to now does not cover the cg-method. However, there is a remedy which uses results on the cg-method well known in the Russian literature <ref> [7, 9] </ref>. We have to fix some notation. <p> The minimal value is given by max j x ;m (x)j = : Moreover we have max j ;m (x)j = 1: A proof may be found in the book of Shaidurov <ref> [9] </ref>. However, Shaidurov represents ;m by the expression ;m (x) = k=1 As a fairly easy consequence Shaidurov [10] proves the following Theorem 2.2.
Reference: [10] <author> V. V. Shaidurov. </author> <title> "Some estimates of the rate of convergence for the cascadic conjugate-gradient method". Otto-von-Guericke-Universitat, Magdeburg (1994). </title> <type> Preprint. </type>
Reference-contexts: The optimality of the nested iteration and of Cascade are well known [5, 4], at least for certain situations. The optimality of the CCG method has been demonstrated by several numerical examples [3]. This has been considered as rather astonishing, since only a plain basic iteration is used. Shaidurov <ref> [10] </ref> has recently shown for H 2 -regular problems and quasi-uniform triangulations in two dimension, that the CCG method is optimal for a certain choice of the parameters m j . <p> However, Shaidurov represents ;m by the expression ;m (x) = k=1 As a fairly easy consequence Shaidurov <ref> [10] </ref> proves the following Theorem 2.2.
Reference: [11] <author> J. Xu. </author> <title> "Theory of Multilevel Methods". </title> <institution> Department of Mathematics, Pennsylvania State University, University Park (1989). </institution> <note> Report No. AM 48. 14 </note>
Reference-contexts: Xu <ref> [11] </ref> has shown the equivalence of norms 1 jv j j 2 T 2T j T kv j k 2 L 2 (T ) c jv j j 2 ; h T = diam T; and the bound j = max (A j ) c for the maximum eigenvalue of A
References-found: 11

