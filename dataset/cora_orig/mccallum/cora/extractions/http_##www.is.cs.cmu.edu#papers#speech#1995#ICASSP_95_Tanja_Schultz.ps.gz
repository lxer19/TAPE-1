URL: http://www.is.cs.cmu.edu/papers/speech/1995/ICASSP_95_Tanja_Schultz.ps.gz
Refering-URL: http://www.is.cs.cmu.edu/ISL.speech.publications.html
Root-URL: 
Email: ftanja,roginag@ira.uka.de  
Title: ACOUSTIC AND LANGUAGE MODELING OF HUMAN AND NONHUMAN NOISES FOR HUMAN-TO-HUMAN SPONTANEOUS SPEECH RECOGNITION  
Author: T.Schultz and I.Rogina 
Address: (USA)  
Affiliation: Interactive Systems Laboratories University of Karlsruhe (Germany), Carnegie Mellon University  
Abstract: In this paper several improvements of our speech-to-speech translation system JANUS on spontaneous human-to-human dialogs are presented. Common phenomena in spontaneous speech are described, followed by a classification of different types of noises. To handle the variety of spontaneous effects in human-to-human dialogs, special noise models are introduced representing both human and nonhuman noises, as well as word fragments. It will be shown that both the acoustic and the language modeling of these noises increase the recognition performance significantly. In the experiments, a clustering of the noise classes is performed and the resulting cluster variants are compared, thus allowing to determine the best tradeoff between sensitivity and trainability of the models. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Butzberger, H. Murveit, E. Shriberg, P. Price: </author> <title> Modeling Spontaneous Speech Effects In Large Vocabulary Speech Recognition Applications. SRI, Speech Research and Technology Program. </title>
Reference-contexts: A superposition of noises and speech is not considered in this paper. Bootstrapping our JANUS-2 speech recognizer towards spontaneous speech, the recognition performance dropped significantly compared to read speech. <ref> [1] </ref> showed that 20% of the errors between the alignment of the phonetical reference transcription and the phonetically recognized hypothesis, were due to unmodeled pause fillers and noises in the ATIS task. This suggest that the modeling of spontaneous speech events should significantly reduce the error rate. <p> But the main objective, if noises are stripped out from the hypotheses, is the substitution error between noise models and word models. The table shows that this kind of substitution error is only a relatively small portion of the total error. Contrary to common belief (e.g. <ref> [1] </ref>) we found, that noise models are not highly confusable with short function words. 5. CLUSTER EXPERIMENTS 5.1. Clustering the classes of noises Although approximately 20% of all words are noises, the lack of training data remains the main problem of acoustic noise modeling.
Reference: [2] <author> W. Ward: </author> <title> Modelling Non-verbal Sounds for Speech Recognition. </title> <booktitle> Proceedings of the DARPA Speech and Natural Language Workshop 1989, </booktitle> <pages> pp. 137-141. </pages>
Reference-contexts: This suggest that the modeling of spontaneous speech events should significantly reduce the error rate. The explicit modeling of 14 human and nonhuman noises decreased the word error rate of the PHOENIX system on the Spreadsheet-Task dramatically <ref> [2] </ref>. Compared to human-to-machine tasks, e.g. ATIS, human-to-human dialogs contain a greater variety of human and nonhuman noises. Modeling these effects is extremely important for human-to-human speech recognition tasks. 2. JANUS-2 WITH A NEW DATABASE JANUS-2 is the spontaneous speech-to-speech translation system of Carnegie Mellon and Karlsruhe University [3, 4]. <p> Figure 1 illustrates the balanced occurence of the different noises in our training and test set. In contrary the transcribed utterances of the ATIS trainingset contain not nearly enough noise words to train our noise models. 4. LANGUAGE MODELING Different types of language modeling were evaluated. In <ref> [2] </ref> noises are allowed to follow all words without language model penalties. So noise words are treated like silences. But statistics on occurrence of noise events showed, that noise some words are more probable than others at distinct locations in the utterance.
Reference: [3] <author> M. Woszczyna, N. Aoki-Waibel, F.D. But, N. Coc-caro, K. Horiguchi, T. Kemp, A. Lavie, A. McNair, T. Polzin, I. Rogina, C.P. Rose, T. Schultz, B. Suhm, M. Tomita, A. Waibel: </author> <title> JANUS 93: Towards Spontaneous Speech Translation. </title> <booktitle> Proceedings of the ICASSP 1994, </booktitle> <volume> volume 1, </volume> <pages> pp 345-348. </pages>
Reference-contexts: Compared to human-to-machine tasks, e.g. ATIS, human-to-human dialogs contain a greater variety of human and nonhuman noises. Modeling these effects is extremely important for human-to-human speech recognition tasks. 2. JANUS-2 WITH A NEW DATABASE JANUS-2 is the spontaneous speech-to-speech translation system of Carnegie Mellon and Karlsruhe University <ref> [3, 4] </ref>. It was designed as a modular system containing a speaker independent recognizer for utterances spoken in English, Spanish, and German, and a parser which analyzes the hypotheses and translates them into an Interlingua representation. <p> German, English or Japanese text can be generated from the Interlingua representation and synthesized by a commercially available speech output device. Several algorithms are available for acoustic modeling, i.e. TDNNs, MS-TDNNs, HMM, MLP and LVQ. JANUS-2 was extended towards spontaneous spoken human-to-human dialogs on a new database <ref> [3] </ref>. This Appointment Scheduling database is being collected in a similiar fashion in German, English, and Spanish. In each session, two persons are asked to schedule a fictitious meeting with their human dialog partner. The data used in the following ex periments consists of 63 English dialogs.
Reference: [4] <author> L. Osterholtz, A. McNair, I. Rogina, H. Saito, T. Slo-boda, J. Tebelskis, A. Waibel, and M. Woszczyna: </author> <title> Testing Generality in JANUS: A Multi-lingual Speech to Speech Translation System. </title> <booktitle> Proceedings of the ICASSP 1992, </booktitle> <volume> volume 1, </volume> <pages> pp 209-212. </pages>
Reference-contexts: Compared to human-to-machine tasks, e.g. ATIS, human-to-human dialogs contain a greater variety of human and nonhuman noises. Modeling these effects is extremely important for human-to-human speech recognition tasks. 2. JANUS-2 WITH A NEW DATABASE JANUS-2 is the spontaneous speech-to-speech translation system of Carnegie Mellon and Karlsruhe University <ref> [3, 4] </ref>. It was designed as a modular system containing a speaker independent recognizer for utterances spoken in English, Spanish, and German, and a parser which analyzes the hypotheses and translates them into an Interlingua representation.
Reference: [5] <author> I. Rogina and A. Waibel: </author> <title> Learning State-Dependent Stream Weights for Multi-Codebook HMM Speech Recognition Systems. </title> <booktitle> Proceedings of the ICASSP 1994, </booktitle> <volume> volume 1, </volume> <pages> pp 217-220. </pages>
Reference-contexts: ACOUSTIC MODELING For acoustic modeling a phonetically tied SCHMM trained for speaker independent recognition was used <ref> [5] </ref>. In order to generate acoustic models for the human and the nonhuman noises, new dedicated phonemes were added to the existing set of 46 context independent phonemes. To guarantee a minimum amount of training input per model, classes of noises have to be created.
Reference: [6] <author> Kai-Fu Lee: </author> <title> Context-Dependent Phonetic Hidden Markov Models for Speaker-Independent Continuous Speech. </title> <journal> IEEE Transactions on Acoustics, Speech, and Signal Processing (ASSP), </journal> <month> April </month> <year> 1990. </year>
Reference-contexts: An agglomerative clustering algorithm was used, based on the acoustic information loss after merging two clusters of noise models. Information loss is given by the difference of entropy between the original models and the merged model, weighted by their frequencies <ref> [6] </ref>. This algorithm used a heuristic optimization, which allowed elements to be moved from one cluster to another. The cluster variants are labeled by the number of noise classes they contain.
Reference: [7] <author> T. Kemp: </author> <title> Data-Driven Codebook Adaption in Phonetically Tied SCHMMS. </title> <booktitle> Proceedings of the ICASSP 1995. </booktitle>
Reference-contexts: By today, the performance of the system was improved by context-dependend phonemes, data-driven codebook adaption <ref> [7] </ref>, dictionary learning [8], and using morphology for language modeling [9].
Reference: [8] <author> T. Sloboda: </author> <title> Dictionary Learning: Performance through Consistency. </title> <booktitle> Proceedings of the ICASSP 1995. </booktitle>
Reference-contexts: By today, the performance of the system was improved by context-dependend phonemes, data-driven codebook adaption [7], dictionary learning <ref> [8] </ref>, and using morphology for language modeling [9].
Reference: [9] <author> P. Geutner: </author> <title> Using Morphology Towards Better Large-Vocabulary Speech Recognition Systems. </title> <booktitle> Proceedings of the ICASSP 1995. </booktitle>
Reference-contexts: By today, the performance of the system was improved by context-dependend phonemes, data-driven codebook adaption [7], dictionary learning [8], and using morphology for language modeling <ref> [9] </ref>.
Reference: [10] <institution> J. Bortz: Statistik fur Sozialwissenschaftler. </institution> <address> Springer Berlin, Heidelberg, </address> <year> 1993. </year>
Reference-contexts: Statistical Relevance For indicating the statistical relevance of the results we used an empirical test. For each cluster variant we used the number of misrecognized words per sentence on the test set after the 23rd iteration and performed a t-test for pairs <ref> [10] </ref> to see the significance of the differences of the mean values between the best (Cluster 6) and the other variants.
References-found: 10

