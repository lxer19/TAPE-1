URL: http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume3/bengio95a.ps.Z
Refering-URL: http://www.cs.washington.edu/research/jair/abstracts/bengio95a.html
Root-URL: 
Email: bengioy@iro.umontreal.ca  paolo@mcculloch.ing.unifi.it  
Title: Diffusion of Context and Credit Information in Markovian Models  
Author: Yoshua Bengio Paolo Frasconi 
Address: Montreal, Qc, Canada H3C-3J7  Via di Santa Marta 3 50139 Firenze (Italy)  
Affiliation: Dept. I.R.O., Universite de Montreal,  Dip. di Sistemi e Informatica, Universita di Firenze  
Note: Journal of Artificial Intelligence Research 3 (1995) 249-270 Submitted 6/95; published 10/95  
Abstract: This paper studies the problem of ergodicity of transition probability matrices in Marko-vian models, such as hidden Markov models (HMMs), and how it makes very difficult the task of learning to represent long-term context for sequential data. This phenomenon hurts the forward propagation of long-term context information, as well as learning a hidden state representation to represent long-term context, which depends on propagating credit information backwards in time. Using results from Markov chain theory, we show that this problem of diffusion of context and credit is reduced when the transition probabilities approach 0 or 1, i.e., the transition probability matrices are sparse and the model essentially deterministic. The results found in this paper apply to learning approaches based on continuous optimization, such as gradient descent and the Baum-Welch algorithm.
Abstract-found: 1
Intro-found: 1
Reference: <author> Bahl, L. R., de Souza, P. V., & Mercer, R. L. </author> <year> (1986). </year> <title> Maximun mutual information esti mation of hidden Markov model parameters for speech recognition. </title> <booktitle> In ICASSP, </booktitle> <pages> pp. </pages> <address> 49-52 Tokyo. </address>
Reference: <author> Baum, L. E., Petrie, T., Soules, G., & Weiss, N. </author> <year> (1970). </year> <title> A maximization technique occuring in the statistical analysis of probabilistic functions of Markov chains. </title> <journal> Ann. Math. Statistic., </journal> <volume> 41, </volume> <pages> 164-171. </pages>
Reference: <author> Bellman, R. </author> <year> (1974). </year> <title> Introduction to Matrix Analysis, 2nd edition. </title> <publisher> McGraw-Hill, </publisher> <address> New York. </address>
Reference-contexts: Note that an irreducible matrix is either periodic or primitive (i.e., of period 1), and that a primitive stochastic matrix is necessarily allowable. 2.3 The Perron-Frobenius Theorem Right eigenvectors v of a matrix A and their corresponding eigenvalues have the following properties <ref> (see Bellman, 1974, for more on eigenvalues and eigenvectors) </ref>: determinant (A I) = 0: where I is the identity matrix, and Av = v j Note that for a stochastic matrix A the largest eigenvalue has norm 1, which can be shown as follows.
Reference: <author> Bengio, Y., De Mori, R., Flammia, G., & Kompe, R. </author> <year> (1992). </year> <title> Global optimization of a neural network-hidden Markov model hybrid. </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> 3 (2), </volume> <pages> 252-259. </pages>
Reference: <author> Bengio, Y., & Frasconi, P. </author> <year> (1994). </year> <title> Credit assignment through time: Alternatives to back propagation. </title> <editor> In Cowan, J. D., Tesauro, G., & Alspector, J. (Eds.), </editor> <booktitle> Advances in Neural Information Processing Systems 6. </booktitle> <publisher> Morgan Kaufmann. </publisher> <editor> 268 Diffusion in Markovian Models Bengio, Y., & Frasconi, P. </editor> <year> (1995a). </year> <title> Diffusion of credit in Markovian models. </title> <editor> In Tesauro, G., Touretzky, D. S., & Alspector, J. (Eds.), </editor> <booktitle> Advances in Neural Information Processing Systems 7. </booktitle> <publisher> MIT Press. </publisher>
Reference-contexts: These plateaus can become a very serious problem when their slope approaches numerical precision or their length becomes unacceptable. 6. Conclusion and Future Work In previous work on recurrent networks <ref> (Bengio et al., 1994) </ref> we had found that, for these nonlinear dynamical parameterized systems, propagating credit over the long term was incompatible with storing information for the long term. Basically, with enough non-linearity (larger weights) to store long-term context robustly, gradients back-propagated through time vanish rapidly. <p> These arguments were also supported by experiments on artificial data, studying the phenomenon of diffusion of credit and the corresponding difficulty in training HMMs to learn long-term dependencies. IOHMMs <ref> (Bengio & Frasconi, 1994, 1995b) </ref> and POMDPs (Sondik, 1973, 1978; Chris-man, 1992) are non-homogeneous variants of HMMs, i.e., the transition probabilities are function of the input (for IOHMMs) or the action (for POMDPs) at each time t.
Reference: <author> Bengio, Y., & Frasconi, P. </author> <year> (1995b). </year> <title> An input/output HMM architecture. </title> <editor> In Tesauro, G., Touretzky, D. S., & Alspector, J. (Eds.), </editor> <booktitle> Advances in Neural Information Processing Systems 7. </booktitle> <publisher> MIT Press. </publisher>
Reference-contexts: The main contribution of this paper is therefore an extension of the negative results found by Bengio et al. (1994) to the case of Markovian models, which include standard HMMs (Baum et al., 1970; Levinson et al., 1983) as well as variations of HMMs such as Input/Output HMMs (IOHMMs) <ref> (Bengio & Frasconi, 1995b) </ref>, and Partially Observable Markov Decision Processes (POMDPs) (Sondik, 1973, 1978; Chrisman, 1992). <p> In the non-homogeneous case, transition and output distributions are conditional on an input sequence, allowing to model relationships between input and output sequences. In the case of IOHMMs <ref> (Bengio & Frasconi, 1995b) </ref>, one thus learns a model P (y T 1 ju T 1 ) of the conditional distribution of an output sequence y T 1 when an input sequence u T 1 is given. <p> This can be accomplished with an EM algorithm when the form of the output and transition probability models are simple enough, e.g. in the case of HMMs (Baum et al., 1970; Levinson et al., 1983; Rabiner, 1989) or IOHMMs <ref> (Bengio & Frasconi, 1995b) </ref>. <p> In practice, this means that the underlying dynamics of state evolution to be modeled should be deterministic. For example, a deterministic IOHMM can recognize strings from a deterministic grammar, taking into account long-term dependencies <ref> (Bengio & Frasconi, 1995b) </ref>. For HMMs this constraint restricts the model to simple cycles, which are not very interesting. Our analysis and numerical experiments also suggest that using many more hidden states than necessary, with a sparse connectivity, reduces the diffusion problem.
Reference: <author> Bengio, Y., Simard, P., & Frasconi, P. </author> <year> (1994). </year> <title> Learning long-term dependencies with gradient descent is difficult. </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> 5 (2), </volume> <pages> 157-166. </pages>
Reference-contexts: These plateaus can become a very serious problem when their slope approaches numerical precision or their length becomes unacceptable. 6. Conclusion and Future Work In previous work on recurrent networks <ref> (Bengio et al., 1994) </ref> we had found that, for these nonlinear dynamical parameterized systems, propagating credit over the long term was incompatible with storing information for the long term. Basically, with enough non-linearity (larger weights) to store long-term context robustly, gradients back-propagated through time vanish rapidly. <p> These arguments were also supported by experiments on artificial data, studying the phenomenon of diffusion of credit and the corresponding difficulty in training HMMs to learn long-term dependencies. IOHMMs <ref> (Bengio & Frasconi, 1994, 1995b) </ref> and POMDPs (Sondik, 1973, 1978; Chris-man, 1992) are non-homogeneous variants of HMMs, i.e., the transition probabilities are function of the input (for IOHMMs) or the action (for POMDPs) at each time t.
Reference: <author> Bridle, J. </author> <year> (1990). </year> <title> Alphanets: a recurrent `neural' network architecture with a hidden Markov model interpretation. </title> <journal> Speech Communication, </journal> <volume> 9 (1), </volume> <pages> 83-92. </pages>
Reference: <author> Chauvin, Y., & Baldi, P. </author> <year> (1995). </year> <title> Hidden Markov models of the g-protein-coupled receptor family. </title> <journal> Journal of Computational Biology, </journal> <note> to appear. </note>
Reference-contexts: Unfortunately, this generally supposes prior knowledge of an appropriate connectivity graph. In practical applications of HMMs, for example to speech recognition (Lee, 1989; Rabiner, 1989) or protein secondary structure modeling <ref> (Chauvin & Baldi, 1995) </ref>, prior knowledge is heavily used in setting up the connectivity graph. As illustrated in Figure 4, in speech recognition systems the meaning of individual states is usually fixed a-priori except within phoneme models. The representation of long-term context is therefore not learned by the HMM.
Reference: <author> Chrisman, L. </author> <year> (1992). </year> <title> Reinforcement learning with perceptual aliasing: The perceptual distinctions approach. </title> <booktitle> In Proceedings of the 12th National Conference on Artificial Intelligence, </booktitle> <pages> pp. 183-188. </pages>
Reference: <author> Dempster, A. P., Laird, N. M., & Rubin, D. B. </author> <year> (1977). </year> <title> Maximum-likelihood from incomplete data via the EM algorithm. </title> <journal> Journal of Royal Statistical Society B, </journal> <volume> 39, </volume> <pages> 1-38. </pages>
Reference-contexts: In the following, we shall use the same symbol u T 1 to denote the sequence that controls transition probabilities, i.e. inputs for IOHMMs and actions for POMDPs. The negative results presented in this paper are directly applicable to learning algorithms such as the EM algorithm <ref> (Dempster, Laird, & Rubin, 1977) </ref> or other gradient-based optimization algorithms, which rely on gradually and iteratively modifying continuous-valued parameters (such as transition probabilities, or parameters of a function computing these probabilities) in order to optimize a learning criterion. 2.
Reference: <author> Frasconi, P., Gori, M., Maggini, M., & Soda, G. </author> <year> (1994). </year> <title> Unified integration of explicit rules and learning by example in recurrent networks. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 7 (2), </volume> <pages> 340-346. </pages>
Reference-contexts: These arguments were also supported by experiments on artificial data, studying the phenomenon of diffusion of credit and the corresponding difficulty in training HMMs to learn long-term dependencies. IOHMMs <ref> (Bengio & Frasconi, 1994, 1995b) </ref> and POMDPs (Sondik, 1973, 1978; Chris-man, 1992) are non-homogeneous variants of HMMs, i.e., the transition probabilities are function of the input (for IOHMMs) or the action (for POMDPs) at each time t.
Reference: <author> Lari, K., & Young, S. </author> <year> (1990). </year> <title> The estimation of stochastic context-free grammars using the inside-outside algorithm. </title> <booktitle> Computer Speech and Language, </booktitle> <volume> 4, </volume> <pages> 35-56. </pages>
Reference: <author> Lee, K.-F. </author> <year> (1989). </year> <title> Automatic Speech Recognition: the development of the SPHINX system. </title> <publisher> Kluwer Academic Publ. </publisher>
Reference: <author> Levinson, S. E., Rabiner, L. R., & Sondhi, M. M. </author> <year> (1983). </year> <title> An introduction to the applica tion of the theory of probabilistic functions of a Markov process to automatic speech recognition. </title> <journal> Bell System Technical Journal, </journal> <volume> 64 (4), </volume> <pages> 1035-1074. </pages>
Reference: <author> Mozer, M. C. </author> <year> (1992). </year> <title> The induction of multiscale temporal structure. </title> <editor> In Moody, J., Hanson, S., & Lipmann, R. (Eds.), </editor> <booktitle> Advances in Neural Information Processing Systems 4, </booktitle> <pages> pp. </pages> <address> 275-282 San Mateo, CA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Rabiner, L. R. </author> <year> (1989). </year> <title> A tutorial on hidden Markov models and selected applications in speech recognition. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 77 (2), </volume> <pages> 257-286. </pages>
Reference-contexts: We will write A ij for the element (i; j) of a matrix A, A n = AA : : : A for the n th power of A, and (A n ) ij for the element (i; j) of A n . See <ref> (Rabiner, 1989) </ref> for an introduction to HMMs, and (Seneta, 1981) for a basic reference on positive matrices.
Reference: <author> Rohwer, R. </author> <year> (1994). </year> <title> The time dimension of neural network models. </title> <journal> ACM Sigart Bulleting, </journal> <volume> 5 (3), </volume> <pages> 36-44. </pages>
Reference: <author> Ron, D., Singer, Y., & Tishby, N. </author> <year> (1994). </year> <title> The power of amnesia. </title> <editor> In Cowan, J. D., Tesauro, G., & Alspector, J. (Eds.), </editor> <booktitle> Advances in Neural Information Processing Systems 6, </booktitle> <pages> pp. </pages> <address> 176-183 San Mateo, CA. </address> <publisher> Morgan Kaufmann. </publisher> <editor> 269 Bengio & Frasconi Rumelhart, D., Hinton, G., & Williams, R. </editor> <year> (1986). </year> <title> Learning internal representations by error propagation. </title> <editor> In Rumelhart, D., & McClelland, J. (Eds.), </editor> <booktitle> Parallel Distributed Processing, </booktitle> <volume> Vol. 1, chap. 8, </volume> <pages> pp. 318-362. </pages> <publisher> MIT Press, </publisher> <address> Cambridge. </address>
Reference-contexts: On the basis of the results of this paper, however, we believe that in order to successfully learn long-term dependencies, such algorithms should look for very sparse topologies (or very deterministic models). Note that some of the already proposed approaches <ref> (Ron et al., 1994) </ref> are limited in the type of context that can be represented (e.g., no loops in the graph and the constraint that all intermediate observations between times t 0 and t must be represented by the state variable in order to model the influence of y t 0
Reference: <author> Seneta, E. </author> <year> (1981). </year> <title> Nonnegative Matrices and Markov Chains. </title> <publisher> Springer, </publisher> <address> New York. </address>
Reference-contexts: See (Rabiner, 1989) for an introduction to HMMs, and <ref> (Seneta, 1981) </ref> for a basic reference on positive matrices. The Markovian independence assumption implies that the state variable x t summarizes the past of the sequence: P (x t jx 1 ; x 2 ; : : : ; x t1 ) = P (x t jx t1 ). <p> First, we introduce the projective distance between vectors v and w: d (v 0 ; w 0 ) = max ln ( v j w i Note that some form of contraction takes place when d (v 0 A; w 0 A) d (v 0 ; w 0 ) <ref> (Seneta, 1981) </ref>, i.e., applying the linear operator A to the vectors v 0 and w 0 brings them "closer" (according to the above projective distance). <p> The coefficients of ergodicity quantify the ergodicity of a matrix, i.e., at what rate a power of the matrix converges to rank 1. Furthermore, t (A 1 A 2 ) t (A 1 )t (A 2 ) <ref> (Seneta, 1981) </ref>. <p> If such a limit exists and it is a matrix with all rows equal, then the product is said to be strongly ergodic. 3.4 Canonical Decomposition and Periodic Graphs Any non-negative matrix A can be rewritten by relabeling its indices in the following canonical decomposition <ref> (Seneta, 1981) </ref>, with diagonal blocks B i , C i and Q: A = B B B B B B B 1 0 0 0 . . . . . . . . . . . . <p> Transitions among states in each subgroup are depicted inside the large circles. G 1 G 2 258 Diffusion in Markovian Models period of the i th periodic block C i . It can be shown <ref> (Seneta, 1981) </ref> that taking d products of periodic matrices with the same incidence matrix and period d yields a block-diagonal matrix whose d blocks are primitive. Thus a product C (t 0 ;t) retains information about the initial block in which x t 0 was.
Reference: <author> Sondik, E. </author> <year> (1973). </year> <title> The optimal control of partially observable Markov processes over the finite horizon. </title> <journal> Operations Research, </journal> <volume> 11, </volume> <pages> 1071-1088. </pages>
Reference: <author> Sondik, E. </author> <year> (1978). </year> <title> The optimal control of partially observable Markov processes over the infinite horizon: discounted case. </title> <journal> Operations Research, </journal> <volume> 26, </volume> <pages> 282-304. </pages>
Reference: <author> Stolcke, A., & Omohundro, S. </author> <year> (1993). </year> <title> Hidden Markov model induction by Bayesian model merging. </title> <editor> In Hanson, S. J., Cowan, J. D., & Giles, C. L. (Eds.), </editor> <booktitle> Advances in Neural Information Processing Systems 5, </booktitle> <pages> pp. </pages> <address> 11-18 San Mateo, CA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Williams, R., & Zipser, D. </author> <year> (1989). </year> <title> A learning algorithm for continually running fully recurrent neural networks. </title> <journal> Neural Computation, </journal> <volume> 1, </volume> <pages> 270-280. 270 </pages>
References-found: 24

