URL: http://robotics.stanford.edu/~latombe/papers/kuffner/captech98.ps.gz
Refering-URL: http://robotics.stanford.edu/~latombe/projects/
Root-URL: http://www.robotics.stanford.edu
Email: kuffner@stanford.edu,  
Title: Goal-Directed Navigation for Animated Characters Using Real-Time Path Planning and Control  
Author: James J. Kuffner, Jr 
Date: NOVEMBER 1998  
Note: TO APPEAR IN THE PROCEEDINGS OF CAPTECH'98,  
Web: http://robotics.stanford.edu/~kuffner/  
Address: Stanford, CA 94305-9010, USA,  
Affiliation: Computer Science Robotics Lab, Stanford University  
Abstract: This paper presents a new technique for computing collision-free navigation motions from task-level commands for animated human characters in interactive virtual environments. The algorithm implementation utilizes the hardware rendering pipeline commonly found on graphics accelerator cards to perform fast 2D motion planning. Given a 3D geometric description of an animated character and a level-terrain environment, collision-free navigation paths can be computed between initial and goal locations at interactive rates. Speed is gained by leveraging the graphics hardware to quickly project the obstacle geometry into a 2D bitmap for planning. The bitmap may be searched by any number of standard dynamic programming techniques to produce a final path. Cyclic motion capture data is used along with a simple proportional derivative controller to animate the character as it follows the computed path. The technique has been implemented on an SGI Indigo2 workstation and runs at interactive rates. It allows for real-time modification of the goal locations and obstacle positions for multiple characters in complex environments composed of more than 15,000 triangles.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. J. Kuffner Jr., </author> <title> An Architecture for the Design of Intelligent Animated Characters, </title> <type> Ph.D. thesis, </type> <institution> Stanford University (in preparation). </institution>
Reference-contexts: The resulting animation can be generated at interactive rates and looks fairly realistic. This work is part of a larger project to build autonomous animated characters equipped with motion planning capabilities and simulated sensing <ref> [1] </ref>. The ultimate goal of this research is to create animated agents able to respond to task-level commands and behave naturally within changing virtual environments. A prolific area of research in the robotics literature has been the design and implementation of task-level motion planning algorithms for real-world robotic systems [2]. <p> Knowing these optimal gains might also facilitate the calculation of conservative error-bounds on the performance of the path following controller. Efforts to incorporate active perception based on simulated vision into the planning process are currently underway <ref> [1] </ref>. In addition, some simple velocity prediction to take into account the estimated motion of other characters and obstacles during planning is also being investigated. Clearly, many challenging research issues must be faced before more interesting motions and intelligent behaviors for autonomous animated characters can be realized.
Reference: [2] <author> J. C. Latombe, </author> <title> Robot Motion Planning, </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, MA, </address> <year> 1991. </year>
Reference-contexts: The ultimate goal of this research is to create animated agents able to respond to task-level commands and behave naturally within changing virtual environments. A prolific area of research in the robotics literature has been the design and implementation of task-level motion planning algorithms for real-world robotic systems <ref> [2] </ref>. The inspiration for the fundamental ideas in this paper arises from this research. Section 2 provides a background and motivation for task-level control in the context of animation. Related work in building autonomous agents for the purposes of graphic animation is summarized in Section 3. <p> If no path exists, an appropriate stopping motion or waiting behavior is performed. 6 Path Planning The theory and analysis of motion planning algorithms is fairly well-developed in the robotics literature, and is not discussed in detail here. For a broad background in motion planning, readers are referred to <ref> [2] </ref>. For any motion planning, it is important to minimize the number of degrees of freedom (DOFs), since the time complexity of known algorithms grows exponentially with the number of DOFs [28]. <p> The character's joint hierarchy is shown, along with the number of DOF for each joint. The path planning approach adopted in this paper is one instance of an approximate cell decomposition method <ref> [2] </ref>. The search space (in this case, the walking surface) is discretized into a fine regular grid of cells. All obstacles are projected onto the grid and "grown" as detailed in Section 6.1. <p> Otherwise, the controller is notified that no path exists. The planner is resolution-complete, meaning that it is guaranteed to find a collision-free path from S to G if one exists at the current grid resolution, and otherwise report failure <ref> [2] </ref>. The running time of the obstacle projection step is proportional to the number and geometric complexity of the obstacles. Searching for a path in the bitmap using Dijkstra's algorithm runs in quadratic time with respect to the number of free cells in the grid.
Reference: [3] <author> A. Witkin and Z. Popovic, </author> <title> "Motion warping," </title> <booktitle> in Proc. SIGGRAPH '95, </booktitle> <year> 1995. </year>
Reference-contexts: Unfortunately, both keyframed-motion and motion capture data alone are inflexible in the sense that the motion is often only valid for a limited set of situations. Frequently, such motions must be redesigned if the locations of other objects or starting conditions change even slightly. Motion warping or blending algorithms <ref> [3, 4] </ref> offer some added flexibility, but usually can only be applied to a limited set of situations involving minor changes to the environment or starting conditions. Significant changes typically result in unrealistic motions.
Reference: [4] <author> A. Bruderlin and L. Williams, </author> <title> "Motion signal processing," </title> <booktitle> in Proc. SIGGRAPH '95, </booktitle> <editor> Robert Cook, Ed. </editor> <booktitle> ACM SIGGRAPH, Aug. 1995, Annual Conference Series, </booktitle> <pages> pp. 97-104, </pages> <publisher> Addison Wesley, </publisher> <address> held in Los Angeles, California, </address> <month> 06-11 August </month> <year> 1995. </year>
Reference-contexts: Unfortunately, both keyframed-motion and motion capture data alone are inflexible in the sense that the motion is often only valid for a limited set of situations. Frequently, such motions must be redesigned if the locations of other objects or starting conditions change even slightly. Motion warping or blending algorithms <ref> [3, 4] </ref> offer some added flexibility, but usually can only be applied to a limited set of situations involving minor changes to the environment or starting conditions. Significant changes typically result in unrealistic motions.
Reference: [5] <author> D. Baraff, </author> <title> "Analytical methods for dynamic simulation of non-penetrating rigid bodies," </title> <booktitle> in Proc. SIGGRAPH '89, </booktitle> <year> 1989, </year> <pages> pp. 223-231. </pages>
Reference-contexts: Significant changes typically result in unrealistic motions. Dynamic simulation and physically-based modeling techniques nicely handle the problems of physical validity and applicability to arbitrary situations. Given initial positions, velocities, forces, and dynamic properties, an object's motion is simulated according to natural physical laws <ref> [5, 6] </ref>. However, aside from specifying initial conditions, the user has no control over both the resulting motion and the final resting position of the object. Spacetime constraints provide a more general mathematical framework for addressing this problem of control [7, 8, 9].
Reference: [6] <author> B. Mirtich, </author> <title> Impulse-Based Dynamic Simulation of Rigid Body Systems, </title> <type> Ph.D. thesis, </type> <institution> University of California, Berkeley, </institution> <address> CA, </address> <year> 1996. </year>
Reference-contexts: Significant changes typically result in unrealistic motions. Dynamic simulation and physically-based modeling techniques nicely handle the problems of physical validity and applicability to arbitrary situations. Given initial positions, velocities, forces, and dynamic properties, an object's motion is simulated according to natural physical laws <ref> [5, 6] </ref>. However, aside from specifying initial conditions, the user has no control over both the resulting motion and the final resting position of the object. Spacetime constraints provide a more general mathematical framework for addressing this problem of control [7, 8, 9].
Reference: [7] <author> A. Witkin and Kass M., </author> <title> "Spacetime constraints," </title> <booktitle> in Proc. SIGGRAPH '88, </booktitle> <year> 1988, </year> <pages> pp. 159-168. </pages>
Reference-contexts: However, aside from specifying initial conditions, the user has no control over both the resulting motion and the final resting position of the object. Spacetime constraints provide a more general mathematical framework for addressing this problem of control <ref> [7, 8, 9] </ref>. Constraint equations imposed by the initial and final conditions, obstacle boundaries, and other desired properties of the motion are solved numerically. Unfortunately, the large number of constraints imposed by complex obstacle-cluttered environments can severely degrade the performance of such methods.
Reference: [8] <author> J. T. Ngo and J. Marks, </author> <title> "Spacetime constraints revisited," </title> <booktitle> in Proc. SIGGRAPH '93, </booktitle> <year> 1993, </year> <pages> pp. 343-350. </pages>
Reference-contexts: However, aside from specifying initial conditions, the user has no control over both the resulting motion and the final resting position of the object. Spacetime constraints provide a more general mathematical framework for addressing this problem of control <ref> [7, 8, 9] </ref>. Constraint equations imposed by the initial and final conditions, obstacle boundaries, and other desired properties of the motion are solved numerically. Unfortunately, the large number of constraints imposed by complex obstacle-cluttered environments can severely degrade the performance of such methods.
Reference: [9] <author> Z. Liu, S. J. Gortler, and F. C. Cohen, </author> <title> "Hierachical spacetime control," </title> <booktitle> in Proc. SIGGRAPH '94, </booktitle> <year> 1994, </year> <pages> pp. 35-42. </pages>
Reference-contexts: However, aside from specifying initial conditions, the user has no control over both the resulting motion and the final resting position of the object. Spacetime constraints provide a more general mathematical framework for addressing this problem of control <ref> [7, 8, 9] </ref>. Constraint equations imposed by the initial and final conditions, obstacle boundaries, and other desired properties of the motion are solved numerically. Unfortunately, the large number of constraints imposed by complex obstacle-cluttered environments can severely degrade the performance of such methods.
Reference: [10] <author> R. A. Brooks, </author> <title> "A layered intelligent control system for a mobile robot," </title> <booktitle> in Robotics Research The Third International Symposium. </booktitle> <year> 1985, </year> <pages> pp. 365-372, </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference-contexts: However, as processor speeds continue to increase, algorithms originally intended for off-line animations will gradually become feasible in real-time virtual environments. Much research effort in robotics has been focused on designing control architectures for autonomous agents that operate in the real world <ref> [10, 11] </ref>. Using rasterizing computer graphics hardware to assist robot motion planning algorithms was previously investigated by Lengyel, et al [12]. Recently, motion planning tools and algorithms have been applied to character animation.
Reference: [11] <author> R. C. Arkin, </author> <title> "Cooperation without communication: Multiagent schema based robot navigation," </title> <journal> Journal of Robotic Systems, </journal> <pages> pp. 351-364, </pages> <year> 1992. </year>
Reference-contexts: However, as processor speeds continue to increase, algorithms originally intended for off-line animations will gradually become feasible in real-time virtual environments. Much research effort in robotics has been focused on designing control architectures for autonomous agents that operate in the real world <ref> [10, 11] </ref>. Using rasterizing computer graphics hardware to assist robot motion planning algorithms was previously investigated by Lengyel, et al [12]. Recently, motion planning tools and algorithms have been applied to character animation.
Reference: [12] <author> J. Lengyel, M. Reichert, B. R. Donald, and D. P. Greenberg, </author> <title> "Real-time robot motion planning using rasterizing computer graphics hardware," </title> <booktitle> in Proc. </booktitle> <volume> SIG-GRAPH '90, </volume> <year> 1990. </year>
Reference-contexts: Much research effort in robotics has been focused on designing control architectures for autonomous agents that operate in the real world [10, 11]. Using rasterizing computer graphics hardware to assist robot motion planning algorithms was previously investigated by Lengyel, et al <ref> [12] </ref>. Recently, motion planning tools and algorithms have been applied to character animation. Koga et al. combined motion planning and human arm inverse kinematics algorithms for automatically generating animation for human arm manipulation tasks [13].
Reference: [13] <author> Y. Koga, K. Kondo, J. Kuffner, and J.-C. Latombe, </author> <title> "Planning motions with intentions," </title> <booktitle> in Proc. SIGGRAPH '94, </booktitle> <year> 1994, </year> <pages> pp. 395-408. </pages>
Reference-contexts: Recently, motion planning tools and algorithms have been applied to character animation. Koga et al. combined motion planning and human arm inverse kinematics algorithms for automatically generating animation for human arm manipulation tasks <ref> [13] </ref>. Hsu and Cohen combined path planning with motion capture data to animate a human figure navigating on uneven terrain [14].
Reference: [14] <author> D. Hsu and M. Cohen, </author> <title> "Task-level motion control for human figure animation," </title> <type> Unpublished Manuscript, </type> <year> 1997. </year>
Reference-contexts: Koga et al. combined motion planning and human arm inverse kinematics algorithms for automatically generating animation for human arm manipulation tasks [13]. Hsu and Cohen combined path planning with motion capture data to animate a human figure navigating on uneven terrain <ref> [14] </ref>. Researchers at the University of Pennsylvania have been exploring the use of motion planning to achieve postural goals using their Jack human character model [15, 16], incorporating body dynamics [17], and high-level scripting [18]. Research in designing fully-autonomous, interactive, artificial agents has also been on the rise. <p> The most severe limitation of the planner is the level-terrain requirement. Extending the algorithm to handle uneven-terrain is possible, but it would involve redesigning the geometry clipping and projection operations. Perhaps the approach taken by Hsu and Cohen would be more appropriate in this situation <ref> [14] </ref>. Possible extensions to the basic algorithm, include incorporating into the planning process the ability to step over low obstacles, or duck under overhangs. One idea might be to utilize the depth information information that is generated, but is currently being ignored during the projection process.
Reference: [15] <author> M. R. Jung, N. Badler, and T. Noma, </author> <title> "Animated human agents with motion planning capability for 3D-space postural goals," </title> <journal> The Journal of Visualization and Computer Animation, </journal> <volume> vol. 5, no. 4, </volume> <pages> pp. 225-246, </pages> <month> October </month> <year> 1994. </year>
Reference-contexts: Hsu and Cohen combined path planning with motion capture data to animate a human figure navigating on uneven terrain [14]. Researchers at the University of Pennsylvania have been exploring the use of motion planning to achieve postural goals using their Jack human character model <ref> [15, 16] </ref>, incorporating body dynamics [17], and high-level scripting [18]. Research in designing fully-autonomous, interactive, artificial agents has also been on the rise. Tu and Terzopoulos implemented a realistic simulation of autonomous artificial fishes, complete with integrated simple behaviors, physically-based motion generation, and simulated perception [19].
Reference: [16] <author> J. P. Granieri, W. Becket, B. D. Reich, J. Crabtree, and N. L. Badler, </author> <title> "Behavioral control for real-time simulated human agents," in 1995 Symposium on Interactive 3D Graphics, </title> <editor> Pat Hanrahan and Jim Winget, Eds. </editor> <booktitle> ACM SIGGRAPH, </booktitle> <month> Apr. </month> <year> 1995, </year> <pages> pp. 173-180, </pages> <note> ISBN 0-89791-736-7. </note>
Reference-contexts: Hsu and Cohen combined path planning with motion capture data to animate a human figure navigating on uneven terrain [14]. Researchers at the University of Pennsylvania have been exploring the use of motion planning to achieve postural goals using their Jack human character model <ref> [15, 16] </ref>, incorporating body dynamics [17], and high-level scripting [18]. Research in designing fully-autonomous, interactive, artificial agents has also been on the rise. Tu and Terzopoulos implemented a realistic simulation of autonomous artificial fishes, complete with integrated simple behaviors, physically-based motion generation, and simulated perception [19].
Reference: [17] <author> E. Kokkevis, D. Metaxas, and N. I. Badler, </author> <title> "Autonomous animation and control of four-legged animals," in Graphics Interface '95, </title> <editor> Wayne A. Davis and Przemyslaw Prusinkiewicz, Eds. </editor> <booktitle> Canadian Information Processing Society, </booktitle> <month> May </month> <year> 1995, </year> <pages> pp. </pages> <month> 10-17, </month> <journal> Canadian Human-Computer Communications Society, </journal> <note> ISBN 0-9695338-4-5. </note>
Reference-contexts: Hsu and Cohen combined path planning with motion capture data to animate a human figure navigating on uneven terrain [14]. Researchers at the University of Pennsylvania have been exploring the use of motion planning to achieve postural goals using their Jack human character model [15, 16], incorporating body dynamics <ref> [17] </ref>, and high-level scripting [18]. Research in designing fully-autonomous, interactive, artificial agents has also been on the rise. Tu and Terzopoulos implemented a realistic simulation of autonomous artificial fishes, complete with integrated simple behaviors, physically-based motion generation, and simulated perception [19].
Reference: [18] <author> N. Badler, </author> <title> "Real-time virtual humans," </title> <journal> Pacific Graphics, </journal> <year> 1997. </year>
Reference-contexts: Researchers at the University of Pennsylvania have been exploring the use of motion planning to achieve postural goals using their Jack human character model [15, 16], incorporating body dynamics [17], and high-level scripting <ref> [18] </ref>. Research in designing fully-autonomous, interactive, artificial agents has also been on the rise. Tu and Terzopoulos implemented a realistic simulation of autonomous artificial fishes, complete with integrated simple behaviors, physically-based motion generation, and simulated perception [19].
Reference: [19] <author> X. Tu and D. Terzopoulos, </author> <title> "Artificial fishes: Physics, locomotion, perception, behavior," </title> <booktitle> in Proc. SIGGRAPH '94, </booktitle> <editor> Andrew Glassner, Ed. </editor> <booktitle> ACM SIGGRAPH, </booktitle> <month> July </month> <year> 1994, </year> <booktitle> Computer Graphics Proceedings, Annual Conference Series, </booktitle> <pages> pp. 43-50, </pages> <publisher> ACM Press, </publisher> <address> ISBN 0-89791-667-0. </address>
Reference-contexts: Research in designing fully-autonomous, interactive, artificial agents has also been on the rise. Tu and Terzopoulos implemented a realistic simulation of autonomous artificial fishes, complete with integrated simple behaviors, physically-based motion generation, and simulated perception <ref> [19] </ref>. Noser, et al. proposed a navigation system for animated characters based on synthetic vision, memory and learning [20].
Reference: [20] <author> H. Noser, O. Renault, D. Thalmann, and N. Magnenat Thalmann, </author> <title> "Navigation for digital actors based on synthetic vision, memory and learning," </title> <journal> Comput. Graphics, </journal> <volume> vol. 19, </volume> <pages> pp. 7-19, </pages> <year> 1995. </year>
Reference-contexts: Tu and Terzopoulos implemented a realistic simulation of autonomous artificial fishes, complete with integrated simple behaviors, physically-based motion generation, and simulated perception [19]. Noser, et al. proposed a navigation system for animated characters based on synthetic vision, memory and learning <ref> [20] </ref>. Other systems include Perlin and Goldberg's Improv software for interactive agents [21, 22], the ALIVE project at MIT [23, 24], Johnson's WavesWorld, and perhaps one of the earliest attempts at creating an agent architecture for the purposes of graphic animation: the Oz project at CMU [25].
Reference: [21] <author> K. Perlin and A. Goldberg, "IMPROV: </author> <title> A system for scripting interactive actors in virtual worlds," </title> <booktitle> in Proc. SIGGRAPH '96, </booktitle> <editor> Holly Rushmeier, Ed. </editor> <booktitle> ACM SIGGRAPH, 1996, Annual Conference Series, </booktitle> <pages> pp. 205-216, </pages> <publisher> Addison Wesley. </publisher>
Reference-contexts: Noser, et al. proposed a navigation system for animated characters based on synthetic vision, memory and learning [20]. Other systems include Perlin and Goldberg's Improv software for interactive agents <ref> [21, 22] </ref>, the ALIVE project at MIT [23, 24], Johnson's WavesWorld, and perhaps one of the earliest attempts at creating an agent architecture for the purposes of graphic animation: the Oz project at CMU [25].
Reference: [22] <author> K. Perlin, </author> <title> "Real time responsive animation with personality," </title> <journal> IEEE Transactions on Visualization and Computer Graphics, </journal> <volume> vol. 1, no. 1, </volume> <pages> pp. 5-15, </pages> <month> March </month> <year> 1995, </year> <pages> ISSN 1077-2626. </pages>
Reference-contexts: Noser, et al. proposed a navigation system for animated characters based on synthetic vision, memory and learning [20]. Other systems include Perlin and Goldberg's Improv software for interactive agents <ref> [21, 22] </ref>, the ALIVE project at MIT [23, 24], Johnson's WavesWorld, and perhaps one of the earliest attempts at creating an agent architecture for the purposes of graphic animation: the Oz project at CMU [25].
Reference: [23] <author> B. M. Blumberg and T. A. Galyean, </author> <title> "Multi-level direction of autonomous creatures for real-time virtual environments," </title> <booktitle> in Proc. SIGGRAPH '95, </booktitle> <editor> Robert Cook, Ed. </editor> <booktitle> ACM SIGGRAPH, Aug. 1995, Annual Conference Series, </booktitle> <pages> pp. 47-54, </pages> <publisher> Addison Wesley, </publisher> <address> held in Los Angeles, California, </address> <month> 06-11 August </month> <year> 1995. </year>
Reference-contexts: Noser, et al. proposed a navigation system for animated characters based on synthetic vision, memory and learning [20]. Other systems include Perlin and Goldberg's Improv software for interactive agents [21, 22], the ALIVE project at MIT <ref> [23, 24] </ref>, Johnson's WavesWorld, and perhaps one of the earliest attempts at creating an agent architecture for the purposes of graphic animation: the Oz project at CMU [25].
Reference: [24] <author> P. Maes, D. Trevor, B. Blumberg, and A. Pentland, </author> <title> "The ALIVE system full-body interaction with autonomous agents," </title> <booktitle> in Computer Animation '95, </booktitle> <month> Apr. </month> <year> 1995. </year>
Reference-contexts: Noser, et al. proposed a navigation system for animated characters based on synthetic vision, memory and learning [20]. Other systems include Perlin and Goldberg's Improv software for interactive agents [21, 22], the ALIVE project at MIT <ref> [23, 24] </ref>, Johnson's WavesWorld, and perhaps one of the earliest attempts at creating an agent architecture for the purposes of graphic animation: the Oz project at CMU [25].
Reference: [25] <author> J. Bates, A. B. Loyall, and W. S. Reilly, </author> <title> "An architecture for action, emotion, and social behavior," </title> <booktitle> in Artificial Social Systems : Proc of 4th European Wkshp on Modeling Autonomous Agents in a Multi-Agent World. 1994, </booktitle> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Other systems include Perlin and Goldberg's Improv software for interactive agents [21, 22], the ALIVE project at MIT [23, 24], Johnson's WavesWorld, and perhaps one of the earliest attempts at creating an agent architecture for the purposes of graphic animation: the Oz project at CMU <ref> [25] </ref>. The goals of the Oz project were to create agents with "broad" but "shallow" capabilities, rather than "deep" capabilities in a narrow area. Researchers at Georgia Tech have combined physically-based simulation with group behaviors for simulating human athletics [26].
Reference: [26] <author> D. C. Brogan and J. K. Hodgins, </author> <title> "Group behaviors with significant dynamics," </title> <booktitle> in Proc. IEEE/RSJ International Conference on Intelligent Robots and Systems, </booktitle> <year> 1995. </year>
Reference-contexts: The goals of the Oz project were to create agents with "broad" but "shallow" capabilities, rather than "deep" capabilities in a narrow area. Researchers at Georgia Tech have combined physically-based simulation with group behaviors for simulating human athletics <ref> [26] </ref>. They have also designed a controller for human running in 3D [27].
Reference: [27] <author> J. K. Hodgins, </author> <title> "Three-dimensional human running," </title> <booktitle> in Proc. IEEE Int. Conf. on Robotics and Automation, </booktitle> <year> 1996. </year>
Reference-contexts: Researchers at Georgia Tech have combined physically-based simulation with group behaviors for simulating human athletics [26]. They have also designed a controller for human running in 3D <ref> [27] </ref>. Despite these achievements, building autonomous agents that respond intelligently to task-level commands remains an elusive goal, particularly in real-time applications. 4 Goal-Directed Navigation Consider the case of an animated human character given the task of moving from one location to another in a flat-terrain virtual environment. <p> So-called "footstep"-driven animation systems could be applied to place the feet at points nearby the computed path, along with real-time inverse kinematics (IK) to hold them in place. As computer processing power increases, physically-based models of the character dynamics along with complex controllers such as the one presented in <ref> [27] </ref> could also potentially be used to simulate locomotion gaits along the path. For the purposes of these experiments, applying cyclic motion capture data proved to be a fast and simple method of obtaining satisfactory motion.
Reference: [28] <author> J. H. Reif, </author> <title> "Complexity of the mover's problem and generalizations," </title> <booktitle> in Proc. 20th IEEE Symp. on Foundations of Computer Science (FOCS), </booktitle> <year> 1979, </year> <pages> pp. 421-427. </pages>
Reference-contexts: For a broad background in motion planning, readers are referred to [2]. For any motion planning, it is important to minimize the number of degrees of freedom (DOFs), since the time complexity of known algorithms grows exponentially with the number of DOFs <ref> [28] </ref>. For character navigation on level-terrain, the important DOFs are the position and orientation (x; y; ) of the base of the character on the walking surface. As detailed in Section 7, the orientation (forward-facing direction) of the character is computed by the controller during the path following phase.
References-found: 28

