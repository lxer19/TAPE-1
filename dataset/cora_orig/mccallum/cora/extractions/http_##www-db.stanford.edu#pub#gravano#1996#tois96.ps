URL: http://www-db.stanford.edu/pub/gravano/1996/tois96.ps
Refering-URL: http://www.public.iastate.edu/~CYBERSTACKS/Aristotle.htm
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Data Structures for Efficient Broker Implementation  
Author: Anthony Tomasic Luis Gravano Calvin Lue Peter Schwarz Laura Haas 
Affiliation: INRIA  Stanford University  IBM Almaden  IBM Almaden  IBM Almaden  
Date: 1996  
Note: To Appear, ACM Transactions on Information Systems,  
Abstract: With the profusion of text databases on the Internet, it is becoming increasingly hard to find the most useful databases for a given query. To attack this problem, several existing and proposed systems employ brokers to direct user queries, using a local database of summary information about the available databases. This summary information must effectively distinguish relevant databases, and must be compact while allowing efficient access. We offer evidence that one broker, GlOSS, can be effective at locating databases of interest even in a system of hundreds of databases, and examine the performance of accessing the GlOSS summaries for two promising storage methods: the grid file and partitioned hashing. We show that both methods can be tuned to provide good performance for a particular workload (within a broad range of workloads), and discuss the tradeoffs between the two data structures. As a side effect of our work, we show that grid files are more broadly applicable than previously thought; in particular, we show that by varying the policies used to construct the grid file we can provide good performance for a wide range of workloads even when storing highly skewed data.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Alfred V. Aho and Jeffrey D. Ullman. </author> <title> Optimal partial-match retrieval when fields are independently specified. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 4(2) </volume> <pages> 168-179, </pages> <month> June </month> <year> 1979. </year>
Reference-contexts: words. 8 7 Comparing Grid Files to Partitioned Hashing for Storing Sum maries A comparison of Tables 8 and 9 with Tables 10 and 11 shows that with an ideal choice of parameters for either structure, partitioned hashing and the grid file are competitive data structures for storing 8 References <ref> [1] </ref> and [25] study how to analytically derive the values of b w and b db that would minimize the number of buckets accessed for a given query distribution. 19 0 100 200 300 b w Average Word Access Cost 3 3 3 3 3 3 3 3 Average Trace Word
Reference: [2] <author> Daniel Barbara and Chris Clifton. </author> <title> Information Brokers: Sharing knowledge in a heterogeneous distributed system. </title> <type> Technical Report MITL-TR-31-92, </type> <institution> Matsushita Information Technology Laboratory, </institution> <month> October </month> <year> 1992. </year> <month> 24 </month>
Reference-contexts: The meta-information typically provides some summary of the contents of each database; thus, these systems fit our generic concept of a broker. Of course, different systems use different types of summaries, and their implementation varies substantially (e.g., [23], [10], [38], <ref> [2] </ref>, [30], [37, 11], and [29, 35]). Some systems provide manual mechanisms to specify meta-information (e.g., WAIS [23], Yahoo 9 , and ALIWEB 10 ) and attach human-generated text summaries to data sources. Given a query, these systems search for matching text summaries and return the attached data sources.
Reference: [3] <author> Ludger Becker, Klaus Hinrichs, and Ulrich Finke. </author> <title> A new algorithm for computing joins with grid files. </title> <booktitle> In Proceedings of the 9 th International Conference on Data Engineering, </booktitle> <pages> pages 190-197, </pages> <year> 1993. </year>
Reference-contexts: These alternative organizations include the region-representation directory and the BR 2 directory <ref> [3] </ref>. The 2-level directory organization [22] shows how to implement the directory on disk. We have not yet explored how these techniques would work in our environment. 8 1. Compute region and block for record 2. If Record fits in block 3. Insert record 4. Else 5. <p> There is more work to be done on the storage of these summaries as well. An unfortunate aspect of the grid files is their need for a relatively large directory. Techniques have been reported for controlling directory size <ref> [3] </ref>; we must examine whether those techniques are applicable to the highly-skewed grid files generated by the GlOSS summaries. Compression techniques [47] would have a significant impact on the performance figures reported here.
Reference: [4] <author> Tim Berners-Lee, Robert Cailliau, Jean-F. Groff, and Bernd Pollermann. </author> <title> World-Wide Web: The Information Universe. </title> <journal> Electronic Networking: Research, Applications and Policy, </journal> <volume> 1(2), </volume> <year> 1992. </year>
Reference-contexts: These fall into two groups: distributed browsing systems and query systems. In distributed browsing systems (e.g., <ref> [4] </ref>, [27]), users follow pre-defined links between data items. While a wealth of information is accessible this way, links must be maintained by hand, and are therefore frequently out of date (or non-existent). Finding information can be frustrating to say the least.
Reference: [5] <author> C. Mic Bowman, Peter B. Danzig, Darren R. Hardy, Udi Manber, and Michael F. Schwartz. Harvest: </author> <title> A scalable, customizable discovery and access system. </title> <type> Technical Report CU-CS-732-94, </type> <institution> Department of Computer Science, University of Colorado-Boulder, </institution> <month> August </month> <year> 1994. </year>
Reference-contexts: In principle, we can achieve greater effectiveness by creating brokers that specialize in a certain topic. Scalability comes from removing the central server bottleneck. In Indie (shorthand for "Distributed Indexing") [10, 9] and Harvest <ref> [5] </ref>, each broker knows about some subset of the data sources, with a special broker that keeps information about all other brokers. Reference [34] and WHOIS++ [45] allow brokers (index-servers in WHOIS++) to exchange information about sources they index, and to forward queries they receive to other knowledgeable brokers.
Reference: [6] <author> Eric W. Brown, James P. Callan, and W. Bruce Croft. </author> <title> Fast incremental indexing for full-text information retrieval. </title> <booktitle> In Proceedings of the 20 th International Conference on Very Large Data Bases, </booktitle> <pages> pages 192-202, </pages> <year> 1994. </year>
Reference-contexts: To implement GlOSS using this approach, we could adapt any of the techniques for building inverted files for documents (e.g.,[8], [47], [40], <ref> [6] </ref>). However, this approach does not support fast access by database, for updating summaries or exchanging them with other brokers. To access all the words for a database, the entire directory tree must be searched. Organizations for "spatial" data provide a variety of techniques that we can apply for GlOSS.
Reference: [7] <author> James P. Callan, Zhihong Lu, and W. Bruce Croft. </author> <title> Searching distributed collections with inference networks. </title> <booktitle> In Proceedings of the 18 th Annual SIGIR Conference, </booktitle> <year> 1995. </year> <note> To appear. </note>
Reference-contexts: Other metrics will be included. For example, a metric that revealed whether the matching documents were scattered thinly across many databases or concentrated in a few large clumps would allow us to measure the corresponding impact on effectiveness. Effectiveness can also be measured using information retrieval metrics <ref> [7] </ref>. <p> As an example, a GlOSS-based meta-information query facility has been implemented for WAIS servers. 14 Recently, reference <ref> [7] </ref> describes the application of inference networks (from traditional information retrieval) to the text database discovery problem. Their approach summarizes databases using document frequency information for each term (the same type of information that GlOSS keeps about the databases), together with the "inverse collection frequency" of the different terms. <p> Reference [34] includes a simulation study of the effectiveness of having brokers exchange content summaries, but is not concerned with what these content summaries are, nor with the costs of storing and exchanging them. Reference <ref> [7] </ref> studies the inference network approach experimentally. Likewise, [16, 17, 15] examine the effectiveness and storage efficiency of GlOSS without worrying about costs of access and update. On a related topic, the fusion track of the TREC conference [20, 21] has produced papers on the "collection fusion" problem [44, 43]. <p> These papers study how to merge query results from multiple data sources into a single query result so as to maximize the number of relevant documents that users get from the distributed search. Reference <ref> [7] </ref> also studies this problem. The representation of summary information for distributed text databases is clearly important for a broad range of query systems.
Reference: [8] <author> Doug Cutting and Jan Pedersen. </author> <title> Optimizations for dynamic inverted index maintenance. </title> <booktitle> In Proceedings of the 13 th International Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 405-411, </pages> <year> 1990. </year>
Reference: [9] <author> Peter B. Danzig, Jongsuk Ahn, John Noll, and Katia Obraczka. </author> <title> Distributed indexing: a scalable mechanism for distributed information retrieval. </title> <booktitle> In Proceedings of the 14 th Annual SIGIR Conference, </booktitle> <month> October </month> <year> 1991. </year>
Reference-contexts: Another approach to solving the effectiveness and performance problems is to design a more sophisticated broker architecture. In principle, we can achieve greater effectiveness by creating brokers that specialize in a certain topic. Scalability comes from removing the central server bottleneck. In Indie (shorthand for "Distributed Indexing") <ref> [10, 9] </ref> and Harvest [5], each broker knows about some subset of the data sources, with a special broker that keeps information about all other brokers.
Reference: [10] <author> Peter B. Danzig, Shih-Hao Li, and Katia Obraczka. </author> <title> Distributed indexing of autonomous Internet services. </title> <journal> Computer Systems, </journal> <volume> 5(4), </volume> <year> 1992. </year>
Reference-contexts: The meta-information typically provides some summary of the contents of each database; thus, these systems fit our generic concept of a broker. Of course, different systems use different types of summaries, and their implementation varies substantially (e.g., [23], <ref> [10] </ref>, [38], [2], [30], [37, 11], and [29, 35]). Some systems provide manual mechanisms to specify meta-information (e.g., WAIS [23], Yahoo 9 , and ALIWEB 10 ) and attach human-generated text summaries to data sources. <p> Another approach to solving the effectiveness and performance problems is to design a more sophisticated broker architecture. In principle, we can achieve greater effectiveness by creating brokers that specialize in a certain topic. Scalability comes from removing the central server bottleneck. In Indie (shorthand for "Distributed Indexing") <ref> [10, 9] </ref> and Harvest [5], each broker knows about some subset of the data sources, with a special broker that keeps information about all other brokers.
Reference: [11] <author> Andrzej Duda and Mark A. Sheldon. </author> <title> Content routing in a network of WAIS servers. </title> <booktitle> In 14th IEEE International Conference on Distributed Computing Systems, </booktitle> <year> 1994. </year>
Reference-contexts: The meta-information typically provides some summary of the contents of each database; thus, these systems fit our generic concept of a broker. Of course, different systems use different types of summaries, and their implementation varies substantially (e.g., [23], [10], [38], [2], [30], <ref> [37, 11] </ref>, and [29, 35]). Some systems provide manual mechanisms to specify meta-information (e.g., WAIS [23], Yahoo 9 , and ALIWEB 10 ) and attach human-generated text summaries to data sources. Given a query, these systems search for matching text summaries and return the attached data sources.
Reference: [12] <author> Christos Faloutsos. </author> <title> Multiattribute hashing using Gray codes. </title> <booktitle> In Proceedings of the 1986 ACM SIGMOD Conference, </booktitle> <pages> pages 227-238, </pages> <year> 1986. </year>
Reference-contexts: we need to access every block in every bucket of the hash table, resulting in an expansion factor for databases of around 773.28. 7 In contrast, when b w = 7 and b db = 6 we access, 6 An improvement over this scheme is to apply the methodology of <ref> [12] </ref> and use Gray codes to achieve better performance of partial-match queries. 7 Smarter bucket organizations can help alleviate this situation by sorting the records by database inside each bucket, for example.
Reference: [13] <author> David W. Flater and Yelena Yesha. </author> <title> An information retrieval system for network resources. </title> <booktitle> In Proceedings of the International Workshop on Next Generation Information Technologies and Systems, </booktitle> <month> June </month> <year> 1993. </year>
Reference-contexts: Reference [34] and WHOIS++ [45] allow brokers (index-servers in WHOIS++) to exchange information about sources they index, and to forward queries they receive to other knowledgeable brokers. Reference <ref> [13] </ref> describes a system that allows sites to forward queries to likely sources (based, in this case, on what information has been received from that source in the past).
Reference: [14] <author> Michael Freeston. </author> <title> A general solution of the n-dimensional b-tree problem. </title> <booktitle> In Proceedings of the 1995 ACM SIGMOD Conference, </booktitle> <pages> pages 80-91, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: 5) Data BlockData Block (buffalo, db2, 2) (llama, db5, 5) (llama, db5, 5) a m (ostrich, db3, 2) Data Block (zebra, db1, 2) proaches that index multiple dimensions using a tree-based directory, including quad trees, k-d trees, K-D-B trees [42], R trees [18], R + trees [36], and BV trees <ref> [14] </ref>, are not well suited for this type of access. To answer a partial-match query, typically a significant portion of the directory tree must be searched. A similar problem arises with techniques like the ones based on the "z order" [31].
Reference: [15] <author> Luis Gravano and Hector Garca-Molina. </author> <title> Generalizing GlOSS for vector-space databases and broker hierarchies. </title> <booktitle> In Proceedings of the 21st International Conference on Very Large Data Bases (VLDB'95), </booktitle> <pages> pages 78-89, </pages> <month> September </month> <year> 1995. </year>
Reference-contexts: Reference [34] includes a simulation study of the effectiveness of having brokers exchange content summaries, but is not concerned with what these content summaries are, nor with the costs of storing and exchanging them. Reference [7] studies the inference network approach experimentally. Likewise, <ref> [16, 17, 15] </ref> examine the effectiveness and storage efficiency of GlOSS without worrying about costs of access and update. On a related topic, the fusion track of the TREC conference [20, 21] has produced papers on the "collection fusion" problem [44, 43]. <p> On a broader front, many other issues remain to be studied. The vastly expanding number and scope of online information sources make it clear that a centralized solution to the database discovery problem will never be satisfactory, showing the need to further explore architectures based on hierarchies <ref> [15] </ref> or networks of brokers.
Reference: [16] <author> Luis Gravano, Hector Garca-Molina, and Anthony Tomasic. </author> <title> The effectiveness of GlOSS for the text-database discovery problem. </title> <booktitle> In Proceedings of the 1994 ACM SIGMOD Conference, </booktitle> <month> May </month> <year> 1994. </year> <note> Also available as ftp://db.stanford.edu/pub/gravano/1994/- stan.cs.tn.93.002.sigmod94.ps. 25 </note>
Reference-contexts: E-mail: Anthony.Tomasic@inria.fr z Computer Science Department, Stanford University, Stanford, CA 94305-9040, USA. E-mail: gravano@cs.stanford.edu x Current address: Trident Systems, Sunnyvale, CA, USA. E-mail: clue@tridmicr.com Department K55/801, IBM Almaden Research Center, 650 Harry Road, San Jose, CA 95120-6099, USA. E-mail: schwarz@almaden.ibm.com, laura@almaden.ibm.com 1 GlOSS (Glossary-Of-Servers Server) <ref> [16, 17] </ref> is one broker that keeps database summaries to choose the most promising databases for a given query. Initial studies of GlOSS are encouraging. <p> The information used by GlOSS to produce this ranking consists of a vector that indicates how many documents in the database contain each word in the database vocabulary, and a count of the total number of documents in the database <ref> [16] </ref>. This summary information is much smaller than the complete contents of the database, so this approach scales well as the number of available databases increases. Table 1 shows a portion of the GlOSS summaries for two databases. Each row corresponds to a word and each column to a database. <p> The rest of the article is devoted to computational performance. 3 Effectiveness of GlOSS Given a set of candidate databases and a set of queries, we explored the ability of GlOSS to suggest appropriate databases for each query. The original GlOSS studies <ref> [16, 17] </ref> tested GlOSS's ability to select among six databases. To be sure that GlOSS would be useful as a large scale broker, we scaled up the number of databases by about two orders of magnitude. <p> A simple data organization for GlOSS is to cluster the records according to their associated word, and to build a tree based directory on the words (e.g., a sparse B + tree), to provide efficient access by word <ref> [16] </ref>, thus yielding fast query processing. To implement GlOSS using this approach, we could adapt any of the techniques for building inverted files for documents (e.g.,[8], [47], [40], [6]). However, this approach does not support fast access by database, for updating summaries or exchanging them with other brokers. <p> Reference [34] includes a simulation study of the effectiveness of having brokers exchange content summaries, but is not concerned with what these content summaries are, nor with the costs of storing and exchanging them. Reference [7] studies the inference network approach experimentally. Likewise, <ref> [16, 17, 15] </ref> examine the effectiveness and storage efficiency of GlOSS without worrying about costs of access and update. On a related topic, the fusion track of the TREC conference [20, 21] has produced papers on the "collection fusion" problem [44, 43].
Reference: [17] <author> Luis Gravano, Hector Garca-Molina, and Anthony Tomasic. </author> <title> Precision and recall of GlOSS estimators for database discovery. </title> <booktitle> In Proceedings of the 3rd International Conference on Parallel and Distributed Information Systems (PDIS'94), </booktitle> <month> September </month> <year> 1994. </year> <note> Also available as ftp://db.stanford.edu/pub/gravano/1994/stan.cs.tn.94.010.pdis94.ps. </note>
Reference-contexts: E-mail: Anthony.Tomasic@inria.fr z Computer Science Department, Stanford University, Stanford, CA 94305-9040, USA. E-mail: gravano@cs.stanford.edu x Current address: Trident Systems, Sunnyvale, CA, USA. E-mail: clue@tridmicr.com Department K55/801, IBM Almaden Research Center, 650 Harry Road, San Jose, CA 95120-6099, USA. E-mail: schwarz@almaden.ibm.com, laura@almaden.ibm.com 1 GlOSS (Glossary-Of-Servers Server) <ref> [16, 17] </ref> is one broker that keeps database summaries to choose the most promising databases for a given query. Initial studies of GlOSS are encouraging. <p> Several other estimation functions are given in <ref> [17] </ref>. As mentioned in the introduction, GlOSS can be measured with respect to its effectiveness in locating the best databases for a given query, and it can be measured in terms of its computational performance. In the next section we study the effectiveness of GlOSS. <p> The rest of the article is devoted to computational performance. 3 Effectiveness of GlOSS Given a set of candidate databases and a set of queries, we explored the ability of GlOSS to suggest appropriate databases for each query. The original GlOSS studies <ref> [16, 17] </ref> tested GlOSS's ability to select among six databases. To be sure that GlOSS would be useful as a large scale broker, we scaled up the number of databases by about two orders of magnitude. <p> Reference [34] includes a simulation study of the effectiveness of having brokers exchange content summaries, but is not concerned with what these content summaries are, nor with the costs of storing and exchanging them. Reference [7] studies the inference network approach experimentally. Likewise, <ref> [16, 17, 15] </ref> examine the effectiveness and storage efficiency of GlOSS without worrying about costs of access and update. On a related topic, the fusion track of the TREC conference [20, 21] has produced papers on the "collection fusion" problem [44, 43].
Reference: [18] <author> Antonin Guttman. R-trees: </author> <title> A dynamic index structure for spatial searching. </title> <booktitle> In Proceedings of the 1984 ACM SIGMOD Conference, </booktitle> <pages> pages 47-57, </pages> <month> June </month> <year> 1984. </year>
Reference-contexts: (zebra, db1, 2) z z (3) (llama, db5, 5) Data BlockData Block (buffalo, db2, 2) (llama, db5, 5) (llama, db5, 5) a m (ostrich, db3, 2) Data Block (zebra, db1, 2) proaches that index multiple dimensions using a tree-based directory, including quad trees, k-d trees, K-D-B trees [42], R trees <ref> [18] </ref>, R + trees [36], and BV trees [14], are not well suited for this type of access. To answer a partial-match query, typically a significant portion of the directory tree must be searched. A similar problem arises with techniques like the ones based on the "z order" [31].
Reference: [19] <author> D. K. Harman, </author> <title> editor. Overview of the Third Text REtrieval Conference (TREC-3). </title> <type> U.S. </type> <institution> Department of Commerce, Technology Administration, National Institute of Standards and Technology (NIST), </institution> <year> 1995. </year> <note> NIST Special Publication 500-225, Coden: NSPUE2. </note>
Reference-contexts: Effectiveness can also be measured using information retrieval metrics [7]. In this case, GlOSS would be measured in terms of its effectiveness in retrieving relevant documents, irrespective of the document location in one database or another <ref> [19] </ref>. 4 4 Alternative Data Structures for GlOSS Summaries The choice of a good data structure to store the GlOSS summaries depends on the type and frequency of operations at the GlOSS servers. A GlOSS server needs to support two types of operations efficiently: query processing and summary updates.
Reference: [20] <author> Donna Harman, </author> <title> editor. </title> <booktitle> Proceedings of the Third Text Retrieval Conference (TREC-3). </booktitle> <institution> National Institute of Standards and Technology, </institution> <note> Special Publication 500-225, </note> <year> 1995. </year>
Reference-contexts: Reference [7] studies the inference network approach experimentally. Likewise, [16, 17, 15] examine the effectiveness and storage efficiency of GlOSS without worrying about costs of access and update. On a related topic, the fusion track of the TREC conference <ref> [20, 21] </ref> has produced papers on the "collection fusion" problem [44, 43]. These papers study how to merge query results from multiple data sources into a single query result so as to maximize the number of relevant documents that users get from the distributed search.
Reference: [21] <author> Donna Harman, </author> <title> editor. </title> <booktitle> Proceedings of the Fourth Text Retrieval Conference (TREC-4). </booktitle> <institution> National Institute of Standards and Technology, </institution> <year> 1996. </year>
Reference-contexts: Reference [7] studies the inference network approach experimentally. Likewise, [16, 17, 15] examine the effectiveness and storage efficiency of GlOSS without worrying about costs of access and update. On a related topic, the fusion track of the TREC conference <ref> [20, 21] </ref> has produced papers on the "collection fusion" problem [44, 43]. These papers study how to merge query results from multiple data sources into a single query result so as to maximize the number of relevant documents that users get from the distributed search.
Reference: [22] <author> Klaus Hinrichs. </author> <title> Implementation of the grid file: design concepts and experience. </title> <journal> BIT, </journal> <volume> 25 </volume> <pages> 569-592, </pages> <year> 1985. </year>
Reference-contexts: These alternative organizations include the region-representation directory and the BR 2 directory [3]. The 2-level directory organization <ref> [22] </ref> shows how to implement the directory on disk. We have not yet explored how these techniques would work in our environment. 8 1. Compute region and block for record 2. If Record fits in block 3. Insert record 4. Else 5. If Usable partitions in database scale 6.
Reference: [23] <author> Brewster Kahle and Art Medlar. </author> <title> An information system for corporate users: Wide Area Information Servers. </title> <type> Technical Report TMC199, </type> <institution> Thinking Machines Corporation, </institution> <month> April </month> <year> 1991. </year>
Reference-contexts: The meta-information typically provides some summary of the contents of each database; thus, these systems fit our generic concept of a broker. Of course, different systems use different types of summaries, and their implementation varies substantially (e.g., <ref> [23] </ref>, [10], [38], [2], [30], [37, 11], and [29, 35]). Some systems provide manual mechanisms to specify meta-information (e.g., WAIS [23], Yahoo 9 , and ALIWEB 10 ) and attach human-generated text summaries to data sources. <p> Of course, different systems use different types of summaries, and their implementation varies substantially (e.g., <ref> [23] </ref>, [10], [38], [2], [30], [37, 11], and [29, 35]). Some systems provide manual mechanisms to specify meta-information (e.g., WAIS [23], Yahoo 9 , and ALIWEB 10 ) and attach human-generated text summaries to data sources. Given a query, these systems search for matching text summaries and return the attached data sources. Unfortunately, human-generated summaries are often out of date.
Reference: [24] <author> Donald E. Knuth. </author> <title> The art of computer programming: Volume 3/Sorting and searching. </title> <publisher> Addison-Wesley, </publisher> <year> 1973. </year>
Reference-contexts: To answer a partial-match query, typically a significant portion of the directory tree must be searched. A similar problem arises with techniques like the ones based on the "z order" [31]. In contrast, the directory structure of grid files [28] and the addressing scheme for partitioned or multi-attribute hashing <ref> [24] </ref> make them well suited for answering partial-match queries. 5 Using Grid Files for GlOSS In this section we describe how grid files [28] can be used to store the GlOSS summaries, and describe a series of experiments that explore their performance. <p> Details can be found in [41]. The results were generally acceptable and did not serve to differentiate the various policies, hence they are not repeated here. 6 Using Partitioned Hashing for GlOSS In this section we analyze partitioned (or multi-attribute) hashing <ref> [24] </ref> as an alternative technique for GlOSS to access its records efficiently both by word and by database. <p> a n : : : a 0 , h w does this mapping by first translating word w into integer i w = P n i=0 lettervalue (a i ) fi 36 i [46], and then taking b (i w A mod 1)2 b w c, where A = 0:6180339887 <ref> [24] </ref>. Similarly, the h db hash function maps database numbers into integers between 0 and 2 b db 1. Given a database number i db , h db maps it into integer b (i db A mod 1)2 b db c. We initially assign one disk block per hash-table bucket.
Reference: [25] <author> John W. Lloyd. </author> <title> Optimal partial-match retrieval. </title> <journal> BIT, </journal> <volume> 20 </volume> <pages> 406-413, </pages> <year> 1980. </year>
Reference-contexts: 7 Comparing Grid Files to Partitioned Hashing for Storing Sum maries A comparison of Tables 8 and 9 with Tables 10 and 11 shows that with an ideal choice of parameters for either structure, partitioned hashing and the grid file are competitive data structures for storing 8 References [1] and <ref> [25] </ref> study how to analytically derive the values of b w and b db that would minimize the number of buckets accessed for a given query distribution. 19 0 100 200 300 b w Average Word Access Cost 3 3 3 3 3 3 3 3 Average Trace Word Access Cost
Reference: [26] <author> John W. Lloyd and K. Ramamohanarao. </author> <title> Partial-match retrieval for dynamic files. </title> <journal> BIT, </journal> <volume> 22 </volume> <pages> 150-168, </pages> <year> 1982. </year>
Reference-contexts: Since we expect databases to grow over time, even an initially optimal choice will degrade as database size increases. By contrast, the grid file grows gracefully. Dynamic versions of multi-attribute hashing like the ones in <ref> [26] </ref> solve this problem at the expense of more complicated algorithms, resulting in techniques that are closely related to the grid files. Secondly, with partitioned hashing, the tradeoff between word and database access cost is fixed for all time once a division of hash-value bits has been made.
Reference: [27] <author> B. Clifford Neuman. </author> <title> The Prospero File System: A global file system based on the Virtual System model. </title> <journal> Computer Systems, </journal> <volume> 5(4), </volume> <year> 1992. </year>
Reference-contexts: These fall into two groups: distributed browsing systems and query systems. In distributed browsing systems (e.g., [4], <ref> [27] </ref>), users follow pre-defined links between data items. While a wealth of information is accessible this way, links must be maintained by hand, and are therefore frequently out of date (or non-existent). Finding information can be frustrating to say the least.
Reference: [28] <author> J. Nievergelt, H. Hinterberger, and K. C. Sevcik. </author> <title> The grid file: An adaptable, symmetric multikey file structure. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 9(1) </volume> <pages> 38-71, </pages> <month> March </month> <year> 1984. </year>
Reference-contexts: To answer a partial-match query, typically a significant portion of the directory tree must be searched. A similar problem arises with techniques like the ones based on the "z order" [31]. In contrast, the directory structure of grid files <ref> [28] </ref> and the addressing scheme for partitioned or multi-attribute hashing [24] make them well suited for answering partial-match queries. 5 Using Grid Files for GlOSS In this section we describe how grid files [28] can be used to store the GlOSS summaries, and describe a series of experiments that explore their <p> In contrast, the directory structure of grid files <ref> [28] </ref> and the addressing scheme for partitioned or multi-attribute hashing [24] make them well suited for answering partial-match queries. 5 Using Grid Files for GlOSS In this section we describe how grid files [28] can be used to store the GlOSS summaries, and describe a series of experiments that explore their performance.
Reference: [29] <author> Katia Obraczka, Peter B. Danzig, and Shih-Hao Li. </author> <title> Internet resource discovery services. </title> <booktitle> IEEE Computer, </booktitle> <month> September </month> <year> 1993. </year>
Reference-contexts: The meta-information typically provides some summary of the contents of each database; thus, these systems fit our generic concept of a broker. Of course, different systems use different types of summaries, and their implementation varies substantially (e.g., [23], [10], [38], [2], [30], [37, 11], and <ref> [29, 35] </ref>). Some systems provide manual mechanisms to specify meta-information (e.g., WAIS [23], Yahoo 9 , and ALIWEB 10 ) and attach human-generated text summaries to data sources. Given a query, these systems search for matching text summaries and return the attached data sources.
Reference: [30] <author> Joann J. Ordille and Barton P. Miller. </author> <title> Distributed active catalogs and meta-data caching in descriptive name services. </title> <type> Technical Report #1118, </type> <institution> University of Wisconsin-Madison, </institution> <month> November </month> <year> 1992. </year>
Reference-contexts: The meta-information typically provides some summary of the contents of each database; thus, these systems fit our generic concept of a broker. Of course, different systems use different types of summaries, and their implementation varies substantially (e.g., [23], [10], [38], [2], <ref> [30] </ref>, [37, 11], and [29, 35]). Some systems provide manual mechanisms to specify meta-information (e.g., WAIS [23], Yahoo 9 , and ALIWEB 10 ) and attach human-generated text summaries to data sources. Given a query, these systems search for matching text summaries and return the attached data sources.
Reference: [31] <author> J. A. Orenstein and T. H. Merrett. </author> <title> A class of data structures for associative searching. </title> <booktitle> In 3rd ACM Symposium on Principles of Database Systems, </booktitle> <pages> pages 181-190, </pages> <month> April </month> <year> 1984. </year>
Reference-contexts: To answer a partial-match query, typically a significant portion of the directory tree must be searched. A similar problem arises with techniques like the ones based on the "z order" <ref> [31] </ref>.
Reference: [32] <author> Sergio Pissanetzky. </author> <title> Sparse matrix technology. </title> <publisher> Academic Press, </publisher> <year> 1984. </year>
Reference-contexts: If multiple partitions exist in a single dimension, we choose the one that splits the block most nearly in half. (See Section 5.4 for a variation of this 2 We can compress the contents of each block of the grid file by applying methods used for storing sparse matrices efficiently <ref> [32] </ref>, or by using the methods in [47] for compressing inverted files, for example.
Reference: [33] <author> Gerard Salton and Michael J. McGill. </author> <title> Introduction to modern information retrieval. </title> <publisher> McGraw-Hill, </publisher> <year> 1983. </year> <month> 26 </month>
Reference-contexts: When new or updated summaries arrive, GlOSS has to update its data structure, operating on the frequencies associated with a single database. Efficient access by database might also be needed if different brokers exchange database summaries to develop "expertise" [34], or if we allow users to do relevance feedback <ref> [33] </ref> and ask for databases "similar" to some given database. The two types of operations pose conflicting requirements on the GlOSS data structure: to process queries, GlOSS needs fast access to the table by word, whereas to handle frequency updates, GlOSS needs fast access to the table by database.
Reference: [34] <author> Michael F. Schwartz. </author> <title> A scalable, non-hierarchical resource discovery mechanism based on probabilistic protocols. </title> <type> Technical Report CU-CS-474-90, </type> <institution> Dept. of Computer Science, University of Colorado at Boulder, </institution> <month> June </month> <year> 1990. </year>
Reference-contexts: When new or updated summaries arrive, GlOSS has to update its data structure, operating on the frequencies associated with a single database. Efficient access by database might also be needed if different brokers exchange database summaries to develop "expertise" <ref> [34] </ref>, or if we allow users to do relevance feedback [33] and ask for databases "similar" to some given database. <p> Scalability comes from removing the central server bottleneck. In Indie (shorthand for "Distributed Indexing") [10, 9] and Harvest [5], each broker knows about some subset of the data sources, with a special broker that keeps information about all other brokers. Reference <ref> [34] </ref> and WHOIS++ [45] allow brokers (index-servers in WHOIS++) to exchange information about sources they index, and to forward queries they receive to other knowledgeable brokers. <p> While there have been many proposals for how to summarize database contents and how to use the summaries to answer queries, there have been very few performance studies in this area. Reference <ref> [34] </ref> includes a simulation study of the effectiveness of having brokers exchange content summaries, but is not concerned with what these content summaries are, nor with the costs of storing and exchanging them. Reference [7] studies the inference network approach experimentally.
Reference: [35] <author> Michael F. Schwartz, Alan Emtage, Brewster Kahle, and B. Clifford Neuman. </author> <title> A comparison of Internet resource discovery approaches. </title> <journal> Computer Systems, </journal> <volume> 5(4), </volume> <year> 1992. </year>
Reference-contexts: The meta-information typically provides some summary of the contents of each database; thus, these systems fit our generic concept of a broker. Of course, different systems use different types of summaries, and their implementation varies substantially (e.g., [23], [10], [38], [2], [30], [37, 11], and <ref> [29, 35] </ref>). Some systems provide manual mechanisms to specify meta-information (e.g., WAIS [23], Yahoo 9 , and ALIWEB 10 ) and attach human-generated text summaries to data sources. Given a query, these systems search for matching text summaries and return the attached data sources.
Reference: [36] <author> Timos Sellis, Nick Roussopoulos, and Christos Faloutsos. </author> <title> The R+-tree: A dynamic index for multi-dimensional objects. </title> <booktitle> In Proceedings of the 13th Conference on Very Large Databases, </booktitle> <pages> pages 507-518, </pages> <month> September </month> <year> 1987. </year>
Reference-contexts: z (3) (llama, db5, 5) Data BlockData Block (buffalo, db2, 2) (llama, db5, 5) (llama, db5, 5) a m (ostrich, db3, 2) Data Block (zebra, db1, 2) proaches that index multiple dimensions using a tree-based directory, including quad trees, k-d trees, K-D-B trees [42], R trees [18], R + trees <ref> [36] </ref>, and BV trees [14], are not well suited for this type of access. To answer a partial-match query, typically a significant portion of the directory tree must be searched. A similar problem arises with techniques like the ones based on the "z order" [31].
Reference: [37] <author> Mark A. Sheldon, Andrzej Duda, Ron Weiss, James W. O'Toole, and David K. Gifford. </author> <title> A content routing system for distributed information servers. </title> <booktitle> In Proceedings Fourth International Conference on Extending Database Technology, </booktitle> <year> 1994. </year>
Reference-contexts: The meta-information typically provides some summary of the contents of each database; thus, these systems fit our generic concept of a broker. Of course, different systems use different types of summaries, and their implementation varies substantially (e.g., [23], [10], [38], [2], [30], <ref> [37, 11] </ref>, and [29, 35]). Some systems provide manual mechanisms to specify meta-information (e.g., WAIS [23], Yahoo 9 , and ALIWEB 10 ) and attach human-generated text summaries to data sources. Given a query, these systems search for matching text summaries and return the attached data sources.
Reference: [38] <author> Patricia Simpson and Rafael Alonso. </author> <title> Querying a network of autonomous databases. </title> <type> Technical Report CS-TR-202-89, </type> <institution> Dept. of Computer Science, Princeton University, </institution> <month> January </month> <year> 1989. </year>
Reference-contexts: The meta-information typically provides some summary of the contents of each database; thus, these systems fit our generic concept of a broker. Of course, different systems use different types of summaries, and their implementation varies substantially (e.g., [23], [10], <ref> [38] </ref>, [2], [30], [37, 11], and [29, 35]). Some systems provide manual mechanisms to specify meta-information (e.g., WAIS [23], Yahoo 9 , and ALIWEB 10 ) and attach human-generated text summaries to data sources. Given a query, these systems search for matching text summaries and return the attached data sources.
Reference: [39] <author> Anthony Tomasic and Hector Garcia-Molina. </author> <title> Performance issues in distributed shared-nothing information retrieval systems. </title> <booktitle> Information Processing and Management, </booktitle> <year> 1996. </year> <note> To Appear. </note>
Reference-contexts: Each query is a boolean conjunction of one or more words, e.g., 1 For more information on the query traces, see reference <ref> [39] </ref>, which provides detailed statistics for similar traces from the same system. 3 N Mean Std.
Reference: [40] <author> Anthony Tomasic, Hector Garca-Molina, and Kurt Shoens. </author> <title> Incremental updates of inverted lists for text document retrieval. </title> <booktitle> In Proceedings of the 1994 ACM SIGMOD Conference, </booktitle> <pages> pages 289-300, </pages> <year> 1994. </year>
Reference-contexts: To implement GlOSS using this approach, we could adapt any of the techniques for building inverted files for documents (e.g.,[8], [47], <ref> [40] </ref>, [6]). However, this approach does not support fast access by database, for updating summaries or exchanging them with other brokers. To access all the words for a database, the entire directory tree must be searched.
Reference: [41] <author> Anthony Tomasic, Luis Gravano, Calvin Lue, Peter Schwarz, and Laura Haas. </author> <title> Data structures for efficient broker implementation. </title> <type> Technical report, </type> <institution> IBM Almaden Research Center, </institution> <month> June </month> <year> 1995. </year> <note> Also available as ftp://db.stanford.edu/pub/gravano/1995/ibm rj.ps. </note>
Reference-contexts: In particular, since we must be able to maintain (update) the summaries efficiently, we tested each of the policies under simulated updates. We also ran our experiments with a smaller block size to see how that affected our results. Details can be found in <ref> [41] </ref>.
Reference: [42] <author> Jeffrey D. Ullman. </author> <title> Principles of database and knowledge-base systems, volume I. </title> <publisher> Computer Science Press, </publisher> <year> 1988. </year>
Reference-contexts: Block Data Block (zebra, db1, 2) z z (3) (llama, db5, 5) Data BlockData Block (buffalo, db2, 2) (llama, db5, 5) (llama, db5, 5) a m (ostrich, db3, 2) Data Block (zebra, db1, 2) proaches that index multiple dimensions using a tree-based directory, including quad trees, k-d trees, K-D-B trees <ref> [42] </ref>, R trees [18], R + trees [36], and BV trees [14], are not well suited for this type of access. To answer a partial-match query, typically a significant portion of the directory tree must be searched.
Reference: [43] <author> Ellen M. Voorhees. </author> <title> Siemens TREC-4 report: Further experiments with database merging. </title> <booktitle> In Proceedings of the 4 th Text Retrieval Conference (TREC-4), </booktitle> <year> 1996. </year>
Reference-contexts: Reference [7] studies the inference network approach experimentally. Likewise, [16, 17, 15] examine the effectiveness and storage efficiency of GlOSS without worrying about costs of access and update. On a related topic, the fusion track of the TREC conference [20, 21] has produced papers on the "collection fusion" problem <ref> [44, 43] </ref>. These papers study how to merge query results from multiple data sources into a single query result so as to maximize the number of relevant documents that users get from the distributed search. Reference [7] also studies this problem.
Reference: [44] <author> Ellen M. Voorhees, Narendra K. Gupta, and Ben Johnson-Laird. </author> <title> The collection fusion problem. </title> <booktitle> In Proceedings of the 3 rd Text Retrieval Conference (TREC-3), </booktitle> <year> 1995. </year>
Reference-contexts: Reference [7] studies the inference network approach experimentally. Likewise, [16, 17, 15] examine the effectiveness and storage efficiency of GlOSS without worrying about costs of access and update. On a related topic, the fusion track of the TREC conference [20, 21] has produced papers on the "collection fusion" problem <ref> [44, 43] </ref>. These papers study how to merge query results from multiple data sources into a single query result so as to maximize the number of relevant documents that users get from the distributed search. Reference [7] also studies this problem.
Reference: [45] <author> Chris Weider and Simon Spero. </author> <title> Architecture of the WHOIS++ Index Service, </title> <month> October </month> <year> 1993. </year> <note> Working draft. </note>
Reference-contexts: Scalability comes from removing the central server bottleneck. In Indie (shorthand for "Distributed Indexing") [10, 9] and Harvest [5], each broker knows about some subset of the data sources, with a special broker that keeps information about all other brokers. Reference [34] and WHOIS++ <ref> [45] </ref> allow brokers (index-servers in WHOIS++) to exchange information about sources they index, and to forward queries they receive to other knowledgeable brokers.
Reference: [46] <author> Gio Wiederhold. </author> <title> File organization for database design. </title> <publisher> McGraw-Hill, </publisher> <year> 1987. </year>
Reference-contexts: Given a word w = a n : : : a 0 , h w does this mapping by first translating word w into integer i w = P n i=0 lettervalue (a i ) fi 36 i <ref> [46] </ref>, and then taking b (i w A mod 1)2 b w c, where A = 0:6180339887 [24]. Similarly, the h db hash function maps database numbers into integers between 0 and 2 b db 1.
Reference: [47] <author> Justin Zobel, Alistair Moffat, and Ron Sacks-Davis. </author> <title> An efficient indexing technique for full-text database systems. </title> <booktitle> In Proceedings of the 18 th International Conference on Very Large Data Bases, </booktitle> <pages> pages 352-362, </pages> <year> 1992. </year> <month> 27 </month>
Reference-contexts: To implement GlOSS using this approach, we could adapt any of the techniques for building inverted files for documents (e.g.,[8], <ref> [47] </ref>, [40], [6]). However, this approach does not support fast access by database, for updating summaries or exchanging them with other brokers. To access all the words for a database, the entire directory tree must be searched. <p> dimension, we choose the one that splits the block most nearly in half. (See Section 5.4 for a variation of this 2 We can compress the contents of each block of the grid file by applying methods used for storing sparse matrices efficiently [32], or by using the methods in <ref> [47] </ref> for compressing inverted files, for example. <p> An unfortunate aspect of the grid files is their need for a relatively large directory. Techniques have been reported for controlling directory size [3]; we must examine whether those techniques are applicable to the highly-skewed grid files generated by the GlOSS summaries. Compression techniques <ref> [47] </ref> would have a significant impact on the performance figures reported here. Finally, building an operational GlOSS server for a large number of real databases is the only way to truly determine the right ratio between word and database access costs.
References-found: 47

