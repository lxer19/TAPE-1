URL: http://www.cs.colorado.edu/~carlosm/sigmetrics.ps.gz
Refering-URL: http://www.cs.colorado.edu/~carlosm/mypapers.html
Root-URL: http://www.cs.colorado.edu
Email: carlosm@cs.colorado.edu, kjr@pa.dec.com  grunwald@cs.colorado.edu  
Title: Performance Issues of Enterprise Level Web Proxies  
Author: Carlos Maltzahn and Kathy J. Richardson Dirk Grunwald 
Address: Palo Alto, CA  Boulder, CO  
Affiliation: Digital Equipment Corporation Network Systems Laboratory  University of Colorado Department of Computer Science  
Abstract: Enterprise level web proxies relay world-wide web traffic between private networks and the Internet. They improve security, save network bandwidth, and reduce network latency. While the performance of web proxies has been analyzed based on synthetic workloads, little is known about their performance on real work-loads. In this paper we present a study of two web proxies (CERN and Squid) executing real workloads on Digital's Palo Alto Gateway. We demonstrate that the simple CERN proxy architecture outperforms all but the latest version of Squid and continues to outperform cacheless configurations. For the measured load levels the Squid proxy used at least as many CPU, memory, and disk resources as CERN, in some configurations significantly more resources. At higher load levels the resource utilization requirements will cross and Squid will be the one using fewer resources. Lastly we found that cache hit rates of around 30% had very little effect on the requests service time. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Jussara Almeida, Virgilio Almeida, and David Yates. </author> <title> Measuring the Behavior of a World-Wide Web Server. </title> <type> Technical Report CS 96-025, </type> <institution> Boston University, </institution> <month> October 29 </month> <year> 1996. </year>
Reference-contexts: The uncertainty and variance of Internet services impact web servers and proxies in different ways. While web servers only accept connections from clients, proxies additionally generate connections to a multitude of web servers with varying service times and often over slow or poor connections. In <ref> [1] </ref> the authors perform application and system level measurements of web server performance. Their measurements are based on sampling and event-driven techniques that resulted in less than 3% overhead. They use a synthetic workload generated according to the WebStone benchmark. <p> Prior to the final DCPI run, many other samples were taken; the cycles/request varied somewhat but the conclusions were consistent reguardless of load or time of day. Furthermore, these results are consistent with the measurements shown in Figures 2 and 3 and with the related work in <ref> [1] </ref>. The latter demonstrates that a vast majority of the CPU time is spent in kernel routines and implies that a proxy's major function is to manage network connections and pass data.
Reference: [2] <author> Virgilio Almeida, Azer Bestavros, Mark Crovella, , and Adri-ana de Oliveira. </author> <title> Characterizing Reference Locality in the WWW. In IEEE PDIS'96: </title> <booktitle> The International Conference in Parallel and Distributed Information Systems, </booktitle> <address> Miami Beach, Florida, </address> <month> December </month> <year> 1996. </year> <note> IEEE. </note>
Reference-contexts: Their measurements indicate that Harvest is orders of magnitude faster than CERN. We will complement that paper with measurements on a much higher and non-simulated load. There have been a number of web traffic characterization <ref> [2, 3, 9, 16, 15] </ref>. However, all of them focus on web server traces and often at a much lower load level than the workloads we studied. The uncertainty and variance of Internet services impact web servers and proxies in different ways.
Reference: [3] <author> Martin F. Arlitt and Carey L. Williamson. </author> <title> Web Server Workload Characterization: The Search for Invariants. </title> <booktitle> In ACM Sigmetrics '96, </booktitle> <pages> pages 126-137, </pages> <address> Philadelphia, PA, </address> <month> May 23-26 </month> <year> 1996. </year> <booktitle> ACM Sigmetrics, ACM. </booktitle>
Reference-contexts: Their measurements indicate that Harvest is orders of magnitude faster than CERN. We will complement that paper with measurements on a much higher and non-simulated load. There have been a number of web traffic characterization <ref> [2, 3, 9, 16, 15] </ref>. However, all of them focus on web server traces and often at a much lower load level than the workloads we studied. The uncertainty and variance of Internet services impact web servers and proxies in different ways.
Reference: [4] <author> Lance Berc, Sanjay Ghemawat, Monika Henzinger, Shun-Tak Leung, Mitch Lichtenberg, Dick Sites, Mark Vandevoorde, Carl Waldspurger, and Bill Weihl. </author> <title> DIGITAL Continuous Profiling Infrastructure. </title> <note> Available on the World Wide Web at http://www.research.digital.com/SRC/dcpi/papers/osdi96-wip.html, October 1996. </note>
Reference-contexts: This results in additional CPU cycles to manage all the network connections in a single process, to process much more state for network system calls, and to manage the in-memory meta-data. With the Digital Continuous Profiling Infrastructure (DCPI 2 ) <ref> [4] </ref> we compared the CPU usage profile of CERN and Squid 2 DCPI: The Digital Continuous Profiling Infrastructurefor Digital Alpha platforms permits continuouslow-overheadprofiling of entire systems, including the kernel, user programs, drivers, and shared libraries.
Reference: [5] <author> C. Mic Bowman, Peter B. Danzig, Darren R. Hardy, Udi Man ber, Michael F. Schwartz, and Duane P. Wessels. Harvest: </author> <title> A scalable, customizable discovery and access system. </title> <type> Technical Report CU-CS-732-94, </type> <institution> Department of Computer Science, University of Colorado, Boulder , CO, </institution> <month> August </month> <year> 1994 </year> <month> (revised March </month> <year> 1995) 1994. </year>
Reference-contexts: Processes are created to serve a single request after which they terminate. Objects are removed from the cache by a separate garbage collection process that checks for expired objects and deletes them. Squid The Squid proxy is the public domain network object cache portion [6] of the Harvest system <ref> [5] </ref>: tools to gather, extract, organize, search, cache, and replicate relevant information across the Internets.
Reference: [6] <author> Anawat Chankhunthod, Peter B. Danzig, Chuck Neerdaels, Michael F. Schwartz, and Kurt J. Worrell. </author> <title> A Hierarchical Internet Object Cache. </title> <booktitle> In 1996 USENIX Technical Conference, </booktitle> <address> San Diego, CA, </address> <month> January </month> <year> 1996. </year> <booktitle> USENIX. </booktitle>
Reference-contexts: These web proxies are the web server httpd developed at CERN [12], which can also be run as a proxy, and the public domain successor of the Harvest Object Cache <ref> [6, 7] </ref> called Squid [22]. Two versions of Squid are evaluated: Squid 1.0.beta17 and Squid 1.1.5. For the rest of the paper we will refer to the CERN proxy server as CERN and to the two Squid proxy versions as Squid 1.0 and Squid 1.1. <p> Resource utilization is also influenced by the hit rate of a caching proxy, and other environmental factors which increase the network latency. The most related work is the paper about the design of the Harvest Object Cache <ref> [6] </ref>. The authors present a performance analysis based on a simulated load of 10 local clients each requesting in parallel 200 unique objects in random order. Their measurements indicate that Harvest is orders of magnitude faster than CERN. <p> Processes are created to serve a single request after which they terminate. Objects are removed from the cache by a separate garbage collection process that checks for expired objects and deletes them. Squid The Squid proxy is the public domain network object cache portion <ref> [6] </ref> of the Harvest system [5]: tools to gather, extract, organize, search, cache, and replicate relevant information across the Internets. <p> For efficiency and portability across UNIX-like platforms, the cache implements its own non-blocking disk and network I/O abstractions directly atop a BSD select loop (section 2.8 in <ref> [6] </ref>). In managing its own resources, Squid attempts to isolate itself from the operating system. Squid keeps meta-data about the cache contents in main memory. This enables Squid to determine whether it can serve a given request from its cache without accessing the disk. <p> Squid and its predecessor, the Harvest Object Cache are perceived as at least an order of magnitude faster than CERN <ref> [6, 23] </ref>. We found that the service times of CERN and Squid are about the same. The load used in the performance analysis of the Harvest Object Cache [6] is very small compared to our load. <p> Squid and its predecessor, the Harvest Object Cache are perceived as at least an order of magnitude faster than CERN [6, 23]. We found that the service times of CERN and Squid are about the same. The load used in the performance analysis of the Harvest Object Cache <ref> [6] </ref> is very small compared to our load. The Harvest Object Cache's architecture addresses performance issues that are visible at low load, such as the elimination of context switches and the introduction of the DNS cache. These features should also significantly improve performance under high load.
Reference: [7] <author> Anawat Chankhunthod, Peter B. Danzig, Chuck Neerdaels, Duane Wessels, Mike F. Schwartz, and Erhyuan Tsai. </author> <note> The Harvest Cache and Httpd-Accelerator. Available on the World Wide Web at http://excalibur.usc.edu/, July 1995. </note>
Reference-contexts: These web proxies are the web server httpd developed at CERN [12], which can also be run as a proxy, and the public domain successor of the Harvest Object Cache <ref> [6, 7] </ref> called Squid [22]. Two versions of Squid are evaluated: Squid 1.0.beta17 and Squid 1.1.5. For the rest of the paper we will refer to the CERN proxy server as CERN and to the two Squid proxy versions as Squid 1.0 and Squid 1.1.
Reference: [8] <author> Dan Connolly and Tim Berners-Lee. </author> <title> Names and Addresses, </title> <journal> URIs, </journal> <note> URLs, URNs, URCs. Available on the World Wide Web at http://www.w3.org/pub/WWW/Addressing/, December 1990. </note>
Reference: [9] <author> M. Crovella and A. Bestavros. </author> <title> Self-similarity in World-Wide Web Traffic: Evidence and Possible Causes. </title> <booktitle> In Proc. of the 1996 SIGMETRICS Conference on Measurement and Modeling of Computer Systems, </booktitle> <year> 1996, </year> <month> May </month> <year> 1996. </year> <journal> ACM. </journal> <volume> 9 </volume>
Reference-contexts: Their measurements indicate that Harvest is orders of magnitude faster than CERN. We will complement that paper with measurements on a much higher and non-simulated load. There have been a number of web traffic characterization <ref> [2, 3, 9, 16, 15] </ref>. However, all of them focus on web server traces and often at a much lower load level than the workloads we studied. The uncertainty and variance of Internet services impact web servers and proxies in different ways.
Reference: [10] <author> Peter Druschel and Gaurav Banga. </author> <title> Lazy Reiceiver Processing (LRP): A Network Subsystem Architecture for Server Systems. </title> <booktitle> In Second Symposium on Operating System Design and Implementation (OSDI 96), </booktitle> <address> Seattle, WA, </address> <month> October </month> <year> 1996. </year>
Reference-contexts: We suspect that many of Squid's sophisticated architectural features were designed prior to the work on operating system behavior and implementation effects on high Internet server performance <ref> [15, 16, 17, 10] </ref>. Common web server and web proxy benchmarks do not include realistic network latency profiles [18, 19]. As we will show in this paper, network latency can have a significant impact on a proxy's resource utilization and therefore its performance.
Reference: [11] <author> Thomas Kroeger and Jeffrey Mogul. </author> <title> Digital's Web Proxy Traces. Available on the World Wide Web at ftp://ftp.digital.com/pub/DEC/traces/proxy/webtraces.html, </title> <month> October </month> <year> 1996. </year>
Reference-contexts: Occasionally, the DNS degenerates, which increases proxy service time and skews our measurements. 1 Colleagues have collected proxy request traces that are now available for public use <ref> [11] </ref>. The current traces contain data taken between 29 August 1996 and 22 September 1996. This is a total of 24,477,674 references. Selecting workloads based on the above criteria results in a selection which represents best cases instead of average cases.
Reference: [12] <author> Ari Luotonen, Henrik Frystyk Nielsen, and Tim Berners-Lee. </author> <note> CERN httpd 3.0A. Available on the World Wide Web at http://www.w3.org/pub/WWW/Daemon/, July 15 1996. </note>
Reference-contexts: In this paper we present the performance of two widely used public domain web proxies under real workload conditions for both caching and cacheless configurations. These web proxies are the web server httpd developed at CERN <ref> [12] </ref>, which can also be run as a proxy, and the public domain successor of the Harvest Object Cache [6, 7] called Squid [22]. Two versions of Squid are evaluated: Squid 1.0.beta17 and Squid 1.1.5.
Reference: [13] <author> P. Mockapetris. </author> <title> Domain Names Concepts and Facilities. Available on the World Wide Web at ftp://ftp.internic.net/rfc/rfc1034.txt, </title> <month> November </month> <year> 1987. </year>
Reference-contexts: When the request is relayed to a server, the proxy translates the server name contained in the URL into an IP address in order to establish a connection. This usually requires a query to the Domain Name Service (DNS) <ref> [13, 14] </ref>, which is typically implemented on a separate host on the same network as the proxy to service all external host name to IP address mappings for the enterprise. CERN The CERN proxy forks a new process to handle each request.
Reference: [14] <author> P. Mockapetris. </author> <title> Domain Names Implementation and Specification. Available on the World Wide Web at ftp://ftp.internic.net/rfc/rfc1035.txt, </title> <month> November </month> <year> 1987. </year>
Reference-contexts: When the request is relayed to a server, the proxy translates the server name contained in the URL into an IP address in order to establish a connection. This usually requires a query to the Domain Name Service (DNS) <ref> [13, 14] </ref>, which is typically implemented on a separate host on the same network as the proxy to service all external host name to IP address mappings for the enterprise. CERN The CERN proxy forks a new process to handle each request.
Reference: [15] <author> Jeffrey C. Mogul. </author> <title> Network behavior of a busy web server and its clients. </title> <type> Technical Report 95/5, </type> <institution> DEC Western Research Laboratory, </institution> <address> Palo Alto, CA, </address> <month> October </month> <year> 1995. </year>
Reference-contexts: We suspect that many of Squid's sophisticated architectural features were designed prior to the work on operating system behavior and implementation effects on high Internet server performance <ref> [15, 16, 17, 10] </ref>. Common web server and web proxy benchmarks do not include realistic network latency profiles [18, 19]. As we will show in this paper, network latency can have a significant impact on a proxy's resource utilization and therefore its performance. <p> Their measurements indicate that Harvest is orders of magnitude faster than CERN. We will complement that paper with measurements on a much higher and non-simulated load. There have been a number of web traffic characterization <ref> [2, 3, 9, 16, 15] </ref>. However, all of them focus on web server traces and often at a much lower load level than the workloads we studied. The uncertainty and variance of Internet services impact web servers and proxies in different ways.
Reference: [16] <author> Jeffrey C. Mogul. </author> <title> Operating Systems Support for Busy Internet Servers. </title> <booktitle> In Fifth Workshop on Hot Topics in Operating Systems (HotOS-V), page addendum, </booktitle> <address> Orcas Island, Washing-ton, </address> <month> May </month> <year> 1995. </year>
Reference-contexts: We suspect that many of Squid's sophisticated architectural features were designed prior to the work on operating system behavior and implementation effects on high Internet server performance <ref> [15, 16, 17, 10] </ref>. Common web server and web proxy benchmarks do not include realistic network latency profiles [18, 19]. As we will show in this paper, network latency can have a significant impact on a proxy's resource utilization and therefore its performance. <p> Their measurements indicate that Harvest is orders of magnitude faster than CERN. We will complement that paper with measurements on a much higher and non-simulated load. There have been a number of web traffic characterization <ref> [2, 3, 9, 16, 15] </ref>. However, all of them focus on web server traces and often at a much lower load level than the workloads we studied. The uncertainty and variance of Internet services impact web servers and proxies in different ways.
Reference: [17] <author> Jeffrey C. Mogul and K. K. Ramakrishnan. </author> <title> Eliminating receive livelock in an interrupt-driven kernel. </title> <booktitle> In 1996 Usenix Technical Conference, </booktitle> <pages> pages 99-111, </pages> <address> San Diego, CA, </address> <month> January </month> <year> 1996. </year>
Reference-contexts: We suspect that many of Squid's sophisticated architectural features were designed prior to the work on operating system behavior and implementation effects on high Internet server performance <ref> [15, 16, 17, 10] </ref>. Common web server and web proxy benchmarks do not include realistic network latency profiles [18, 19]. As we will show in this paper, network latency can have a significant impact on a proxy's resource utilization and therefore its performance.
Reference: [18] <institution> Standard Performance Evaluation Corp. (SPEC). </institution> <note> SPECweb96 Benchmark. Available on the World Wide Web at http://www.specbench.org/osg/web96/, July 1996. </note>
Reference-contexts: We suspect that many of Squid's sophisticated architectural features were designed prior to the work on operating system behavior and implementation effects on high Internet server performance [15, 16, 17, 10]. Common web server and web proxy benchmarks do not include realistic network latency profiles <ref> [18, 19] </ref>. As we will show in this paper, network latency can have a significant impact on a proxy's resource utilization and therefore its performance. Resource utilization is also influenced by the hit rate of a caching proxy, and other environmental factors which increase the network latency. <p> They use a synthetic workload generated according to the WebStone benchmark. Results show that a server saturated by requests spends over 90% of the time in system calls. We complement these results with our results from real workloads. Recently, SPEC published a standard for web server performance <ref> [18] </ref>. This benchmark acknowledges the fact that it does not simulate network latency. We will show in this paper that network latency is a crucial factor in server and proxy performance. In section 2 we present an overview of CERN and Squid architectures.
Reference: [19] <author> Gene Trent and Mark Sake. WebSTONE: </author> <title> The First Generation in HTTP Server Benchmarking. </title> <note> Available on the World Wide Web at http://www.sgi.com/Products/WebFORCE/WebStone/, February 1995. </note>
Reference-contexts: We suspect that many of Squid's sophisticated architectural features were designed prior to the work on operating system behavior and implementation effects on high Internet server performance [15, 16, 17, 10]. Common web server and web proxy benchmarks do not include realistic network latency profiles <ref> [18, 19] </ref>. As we will show in this paper, network latency can have a significant impact on a proxy's resource utilization and therefore its performance. Resource utilization is also influenced by the hit rate of a caching proxy, and other environmental factors which increase the network latency.
Reference: [20] <author> Neal R. Wagner. </author> <title> Fingerprinting. </title> <booktitle> In Symposium on Security and Privacy, </booktitle> <pages> pages 18-22, </pages> <address> Oakland, CA, 1983. </address> <publisher> IEEE. </publisher>
Reference-contexts: Squid keeps meta-data about the cache contents in main memory. This enables Squid to determine whether it can serve a given request from its cache without accessing the disk. Squid maps URLs to cache object names using fingerprinting <ref> [20] </ref>. The cache has a LRU expiration policy which is activated once the cache size reaches a configurable high mark, and deactivated once the cache size falls below a configurable low mark.
Reference: [21] <author> Duane Wessels. </author> <title> Personal communication. during which became clear that Squid 1.0.beta17 has a memory management bug, </title> <month> August </month> <year> 1996. </year>
Reference-contexts: With a cache, Squid 1.0 uses only slightly more memory than the cacheless configuration. This is probably due to a bug in its memory management <ref> [21] </ref>. The CERN proxy memory usage is entirely load dependent. Other system components, such as the operating system still require independent memory. Each CERN process uses 280K Bytes. Higher loads result in a larger number of simultaneous processes, which require more memory.
Reference: [22] <author> Duane Wessels. </author> <title> Squid Internet Object Cache. </title> <note> Available on the World Wide Web at http://squid.nlanr.net/Squid/, May 1996. </note>
Reference-contexts: These web proxies are the web server httpd developed at CERN [12], which can also be run as a proxy, and the public domain successor of the Harvest Object Cache [6, 7] called Squid <ref> [22] </ref>. Two versions of Squid are evaluated: Squid 1.0.beta17 and Squid 1.1.5. For the rest of the paper we will refer to the CERN proxy server as CERN and to the two Squid proxy versions as Squid 1.0 and Squid 1.1.
Reference: [23] <author> Duane Wessels. </author> <title> SQUID Frequently Asked Questions. </title> <note> Available on the World Wide Web at http://squid.nlanr.net/Squid/FAQ.html, January 1997. 10 </note>
Reference-contexts: Squid and its predecessor, the Harvest Object Cache are perceived as at least an order of magnitude faster than CERN <ref> [6, 23] </ref>. We found that the service times of CERN and Squid are about the same. The load used in the performance analysis of the Harvest Object Cache [6] is very small compared to our load.
References-found: 23

