URL: http://www.cs.unc.edu/~anderson/papers/wdag95.ps.Z
Refering-URL: http://www.cs.unc.edu/~anderson/papers.html
Root-URL: http://www.cs.unc.edu
Title: Universal Constructions for Large Objects  
Author: James H. Anderson and Mark Moir 
Address: Chapel Hill  
Affiliation: Dept. of Computer Science, University of North Carolina at  
Abstract: We present lock-free and wait-free universal constructions for implementing large shared objects. Most previous universal constructions require processes to copy the entire object state, which is impractical for large objects. Previous attempts to address this problem require programmers to explicitly fragment large objects into smaller, more manageable pieces, paying particular attention to how such pieces are copied. In contrast, our constructions are designed to largely shield programmers from this fragmentation. Furthermore, for many objects, our constructions result in lower copying overhead than previous ones. Fragmentation is achieved in our constructions through the use of load-linked, store-conditional, and validate operations on a "large" multi-word shared variable. Before presenting our constructions, we show that these operations can be efficiently implemented from similar one-word primitives.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Anderson and M. Moir, </author> <title> "Universal Constructions for Multi-Object Operations", </title> <booktitle> to appear in the Proceedings of the 14th Annual ACM Symposium on Principles of Distributed Computing , 1995. </booktitle>
Reference-contexts: Thus, they are not the same as the multi-word operations considered in <ref> [1, 2, 5, 6] </ref>, which access multiple variables, each stored in a separate word. The multi-word operations we consider admit simpler and more efficient implementations than those considered in [1, 2, 5, 6]. shared var X: record pid: 0::N 1; tag: 0::1 end; BUF : array [0::N 1; 0::1] of array <p> Thus, they are not the same as the multi-word operations considered in <ref> [1, 2, 5, 6] </ref>, which access multiple variables, each stored in a separate word. The multi-word operations we consider admit simpler and more efficient implementations than those considered in [1, 2, 5, 6]. shared var X: record pid: 0::N 1; tag: 0::1 end; BUF : array [0::N 1; 0::1] of array [0::W 1] of wordtype initially X = (0; 0) ^ BUF [0; 0] = initial value of the implemented variable V private var curr: record pid: 0::N 1; tag: <p> Values of V are stored in "buffers", and a shared variable X indicates which buffer contains the "current" value of V. The current value is the value written 2 We assume that the SC operation does not fail spuriously. As shown in <ref> [1] </ref>, a SC operation that does not fail spuriously can be efficiently implemented using LL and a SC operation that might fail spuriously. 3 Private variables in all figures are assumed to retain their values between procedure calls. to V by the most recent successful SC operation, or the initial value <p> To ensure that a SC operation does not overwrite the contents of the current buffer, the SC operations of each process p alternate between two buffers, BUF [p; 0] and BUF <ref> [p; 1] </ref>. <p> This work is performed by special Read and Write procedures, which are called by the sequential operation in order to read or write the MEM array. As a result, our constructions are not completely transparent to the sequential object designer. For example, instead of writing "MEM <ref> [1] </ref> := MEM [10]", the designer would write "Write (1; Read (10))". However, as discussed in Section 4, a preprocessor could be used to provide complete transparency. We now turn our attention to the code of Figure 5. <p> We would like to extend our constructions to allow such parallel execution where possible. For example, in our shared queue implementations, an enqueue operation might unnecessarily interfere with a dequeue operation. In <ref> [1] </ref>, we addressed similar concerns when implementing wait-free operations on multiple objects. Acknowledgement: We would like to thank Lars Nyland for his help with the performance studies in Section 3.3.
Reference: [2] <author> G. Barnes, </author> <title> "A Method for Implementing Lock-Free Shared Data Structures", </title> <booktitle> Proceedings of the Fifth Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <year> 1993, </year> <pages> pp. 261-270. </pages>
Reference-contexts: Thus, they are not the same as the multi-word operations considered in <ref> [1, 2, 5, 6] </ref>, which access multiple variables, each stored in a separate word. The multi-word operations we consider admit simpler and more efficient implementations than those considered in [1, 2, 5, 6]. shared var X: record pid: 0::N 1; tag: 0::1 end; BUF : array [0::N 1; 0::1] of array <p> Thus, they are not the same as the multi-word operations considered in <ref> [1, 2, 5, 6] </ref>, which access multiple variables, each stored in a separate word. The multi-word operations we consider admit simpler and more efficient implementations than those considered in [1, 2, 5, 6]. shared var X: record pid: 0::N 1; tag: 0::1 end; BUF : array [0::N 1; 0::1] of array [0::W 1] of wordtype initially X = (0; 0) ^ BUF [0; 0] = initial value of the implemented variable V private var curr: record pid: 0::N 1; tag:
Reference: [3] <author> M. Herlihy, </author> <title> "Wait-Free Synchronization", </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> Vol. 13, No. 1, </volume> <year> 1991, </year> <pages> pp. 124-149. </pages>
Reference-contexts: 1 Introduction This paper extends recent research on universal lock-free and wait-free constructions of shared objects <ref> [3, 4] </ref>. Such constructions can be used to implement any object in a lock-free or a wait-free manner, and thus can be used as the basis for a general methodology for constructing highly-concurrent objects. <p> To see why two bits are needed to detect whether q's operation is complete, consider the scenario in Figure 7. In this figure, process p performs two operations. In the first, p's SC is successful, and p replaces RET [5] with RET <ref> [3] </ref> as the current return block at line 26. During p's first operation, q starts an operation. However, q starts this operation too late to be helped by p.
Reference: [4] <author> M. Herlihy, </author> <title> "A Methodology for Implementing Highly Concurrent Data Objects", </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> Vol. 15, No. 5, </volume> <year> 1993, </year> <pages> pp. 745-770. </pages>
Reference-contexts: 1 Introduction This paper extends recent research on universal lock-free and wait-free constructions of shared objects <ref> [3, 4] </ref>. Such constructions can be used to implement any object in a lock-free or a wait-free manner, and thus can be used as the basis for a general methodology for constructing highly-concurrent objects. <p> In this paper, we address this shortcoming by presenting universal constructions that can be used to implement large objects with low space overhead. We take as our starting point the lock-free and wait-free universal constructions presented by Herlihy in <ref> [4] </ref>. In these constructions, operations are implemented using "retry loops". <p> We begin with a brief overview of previous constructions due to Herlihy <ref> [4] </ref>. Herlihy presented lock-free and wait-free universal constructions for "small" objects as well as a lock-free construction for "large" objects [4]. As described in Section 1, an operation in Herlihy's small-object constructions copies the entire object, which can be a severe disadvantage for large objects. <p> We begin with a brief overview of previous constructions due to Herlihy <ref> [4] </ref>. Herlihy presented lock-free and wait-free universal constructions for "small" objects as well as a lock-free construction for "large" objects [4]. As described in Section 1, an operation in Herlihy's small-object constructions copies the entire object, which can be a severe disadvantage for large objects. In Herlihy's large-object construction, the implemented object is fragmented into blocks, which are linked by pointers.
Reference: [5] <author> A. Israeli and L. Rappoport, </author> <title> "Disjoint-Access-Parallel Implementations of Strong Shared Memory Primitives", </title> <booktitle> Proceedings of the 13th Annual ACM Symposium on Principles of Distributed Computing, ACM, </booktitle> <address> New York, </address> <month> August </month> <year> 1994, </year> <pages> pp. 151-160. </pages>
Reference-contexts: Thus, they are not the same as the multi-word operations considered in <ref> [1, 2, 5, 6] </ref>, which access multiple variables, each stored in a separate word. The multi-word operations we consider admit simpler and more efficient implementations than those considered in [1, 2, 5, 6]. shared var X: record pid: 0::N 1; tag: 0::1 end; BUF : array [0::N 1; 0::1] of array <p> Thus, they are not the same as the multi-word operations considered in <ref> [1, 2, 5, 6] </ref>, which access multiple variables, each stored in a separate word. The multi-word operations we consider admit simpler and more efficient implementations than those considered in [1, 2, 5, 6]. shared var X: record pid: 0::N 1; tag: 0::1 end; BUF : array [0::N 1; 0::1] of array [0::W 1] of wordtype initially X = (0; 0) ^ BUF [0; 0] = initial value of the implemented variable V private var curr: record pid: 0::N 1; tag: <p> To see why two bits are needed to detect whether q's operation is complete, consider the scenario in Figure 7. In this figure, process p performs two operations. In the first, p's SC is successful, and p replaces RET <ref> [5] </ref> with RET [3] as the current return block at line 26. During p's first operation, q starts an operation. However, q starts this operation too late to be helped by p. Before p's execution of line 26, q reads BANK in line 7 and determines that RET [5] is the <p> replaces RET <ref> [5] </ref> with RET [3] as the current return block at line 26. During p's first operation, q starts an operation. However, q starts this operation too late to be helped by p. Before p's execution of line 26, q reads BANK in line 7 and determines that RET [5] is the current return block. Now, p starts a second operation. Because p previously replaced RET [5] as the current return block, RET [5] is now p's private copy, so p's second operation uses RET [5] to record the operations it helps. <p> However, q starts this operation too late to be helped by p. Before p's execution of line 26, q reads BANK in line 7 and determines that RET <ref> [5] </ref> is the current return block. Now, p starts a second operation. Because p previously replaced RET [5] as the current return block, RET [5] is now p's private copy, so p's second operation uses RET [5] to record the operations it helps. When p executes line 6, it changes q's applied bit to indicate that it has applied q's operation. <p> Before p's execution of line 26, q reads BANK in line 7 and determines that RET <ref> [5] </ref> is the current return block. Now, p starts a second operation. Because p previously replaced RET [5] as the current return block, RET [5] is now p's private copy, so p's second operation uses RET [5] to record the operations it helps. When p executes line 6, it changes q's applied bit to indicate that it has applied q's operation. <p> execution of line 26, q reads BANK in line 7 and determines that RET <ref> [5] </ref> is the current return block. Now, p starts a second operation. Because p previously replaced RET [5] as the current return block, RET [5] is now p's private copy, so p's second operation uses RET [5] to record the operations it helps. When p executes line 6, it changes q's applied bit to indicate that it has applied q's operation. Note that, at this stage, q's operation has only been applied to p's private object copy, and p has not yet performed its SC. <p> Note that, at this stage, q's operation has only been applied to p's private object copy, and p has not yet performed its SC. However, if q reads the applied bit of RET <ref> [5] </ref> (which it previously determined to be the current RET block) at line 13, then q incorrectly concludes that its operation has been applied to the object, and terminates prematurely.
Reference: [6] <author> N. Shavit and D. Touitou, </author> <title> "Software Transactional Memory", </title> <booktitle> to appear in the Proceedings of the 14th Annual ACM Symposium on Principles of Distributed Computing , 1995. </booktitle>
Reference-contexts: Thus, they are not the same as the multi-word operations considered in <ref> [1, 2, 5, 6] </ref>, which access multiple variables, each stored in a separate word. The multi-word operations we consider admit simpler and more efficient implementations than those considered in [1, 2, 5, 6]. shared var X: record pid: 0::N 1; tag: 0::1 end; BUF : array [0::N 1; 0::1] of array <p> Thus, they are not the same as the multi-word operations considered in <ref> [1, 2, 5, 6] </ref>, which access multiple variables, each stored in a separate word. The multi-word operations we consider admit simpler and more efficient implementations than those considered in [1, 2, 5, 6]. shared var X: record pid: 0::N 1; tag: 0::1 end; BUF : array [0::N 1; 0::1] of array [0::W 1] of wordtype initially X = (0; 0) ^ BUF [0; 0] = initial value of the implemented variable V private var curr: record pid: 0::N 1; tag:
References-found: 6

