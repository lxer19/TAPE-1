URL: ftp://ftp.stat.duke.edu/pub/WorkingPapers/95-20.ps
Refering-URL: http://www.isds.duke.edu/~mw/papers.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: BAYESIAN TIME SERIES: Models and Computations for the Analysis of Time Series in the Physical Sciences  
Author: MIKE WEST 
Keyword: Key words: Dynamic linear models, Markov chain Monte Carlo, Mixture models, Non-linear auto-regression, State-space models, Stochastic time defor mations, Time series decomposition, Timing errors  
Address: Durham, NC 27708-0251  
Affiliation: Institute of Statistics Decision Sciences Duke University,  
Abstract: This articles discusses developments in Bayesian time series mod-elling and analysis relevant in studies of time series in the physical and engineering sciences. With illustrations and references, we discuss: Bayesian inference and computation in various state-space models, with examples in analysing quasi-periodic series; isolation and modelling of various components of error in time series; decompositions of time series into significant latent subseries; nonlinear time series models based on mixtures of auto-regressions; problems with errors and uncertainties in the timing of observations; and the development of non-linear models based on stochastic deformations of time scales. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> M. West and P. Harrison, </author> <title> Bayesian Forecasting and Dynamic Models, </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1989. </year>
Reference-contexts: implied by the basic normal distributions of the ! t terms (<ref> [1] </ref> chapters 11 and, particularly, 12). In fact, the early developments of Bayesian forecasting using DLMs were largely predicated on applied problems in commercial forecasting that led to the development of mixture errors models and multi-process DLMs ([12] and [1] chapter 12).
Reference: 2. <author> A. Pole, M. West, and P. Harrison, </author> <title> Applied Bayesian Forecasting and Time Series Analysis, </title> <address> Chapman-Hall, New York, </address> <year> 1994. </year>
Reference: 3. <author> M. West, </author> <title> "Bayesian inference in cyclical component dynamic linear models," </title> <journal> J. Amer. Statist. Assoc., </journal> <note> 92, 1995 (to appear). </note>
Reference-contexts: Note that t could be replaced by other DLM forms, such as more complex trends and/or regression terms, with direct extension, using the notion of model superposition ([1]). Another class of auto-regressive component DLMs is developed in <ref> [3] </ref> and applied in various geological time series analyses in [4]. Such models combine two or more distinct AR (2) components, each exhibiting time-varying periodic structure, but now with persistent, i.e. unit root components.
Reference: 4. <author> M. West, </author> <title> "Some statistical issues in Paloclimatology (with discussion)," in Bayesian Statistics 5, </title> <editor> J. Berger, J. Bernardo, A. Dawid, and A. Smith, eds., </editor> <publisher> Oxford University Press, Oxford, 1995 (in press). </publisher>
Reference-contexts: Note that t could be replaced by other DLM forms, such as more complex trends and/or regression terms, with direct extension, using the notion of model superposition ([1]). Another class of auto-regressive component DLMs is developed in [3] and applied in various geological time series analyses in <ref> [4] </ref>. Such models combine two or more distinct AR (2) components, each exhibiting time-varying periodic structure, but now with persistent, i.e. unit root components. This provides an approach to Bayesian spectral analysis in which several sustained sinusoids of distinct periods are subject to stochastic changes in amplitudes and phased. <p> Random Observation Times: Timing Errors and Uncertainties Many application areas suffer from problems of errors and uncertainties in the timing of time series observations. In <ref> [4] </ref>, for example, the x t series is a geochemical quantity, from deep lake sediment, that is a proxy indicator of local climatic conditions of interest in studying climatic change over time. <p> By detailing and modelling this calibration process, a rather elaborate model for the true but uncertain times of observations is constructed, and this provides a class of prior distributions for the times. Analyses then incorporate the uncertain times along with the model parameters and state variables. The study in <ref> [4] </ref> describes this, and focuses particularly on how limited the data is as a result of realistic measures of the timing uncertainties. Simple measurement errors, and truncation or rounding errors in timing, may be subject to assessment using similar approaches. <p> Then 10 MIKE WEST MCMC analysis proceeds by iteratively resampling these two conditional posteriors in the usual manner. Some specific models p (X n jT n ; fi) and priors p (T n ) are studied in <ref> [4] </ref>, where various Gibbs and Metropolis-Hastings algorithms for these sampling exercises are developed and applied. One issue to note is that these problems require time series models for arbitrary spacings between observations.
Reference: 5. <author> M. West, </author> <title> "Time series decomposition and analysis in a study of oxygen isotope records," </title> <type> ISDS Discussion Paper 95-18, </type> <institution> Duke University, </institution> <year> 1995. </year>
Reference-contexts: This is based on recent developments in <ref> [5] </ref>, and is closely linked to the developments of similar and canonical models in the DLM framework ([1], chapter 5). In this special model, the eigenvalues of G are the reciprocal roots of the auto-regressive characteristic polynomial. <p> subset of these quantities, write for all remaining parameters and variables; e.g. = fZ n ; v; u; w; H n g: Various Gibbs sampling algorithms may be constructed to iteratively sample from conditional distributions p (jX n ; ) for appropriate choices of ; one such algorithm, detailed in <ref> [5] </ref>, has the following basic structure. (a) Sampling (Z n jX n ; Z n ) Fixing model parameters and variance components in Z n ; standard normal DLM theory applies and delivers useful normal distributions. <p> Sample the remaining two elements ( t ; y tp+1 ) from the resulting bivariate normal distribution, namely N ( t ; y tp+1 jX t ; z t+1 ; Z n ); this may be done efficiently, the precise algorithmic details are laid out in appendix in <ref> [5] </ref>.
Reference: 6. <author> M. West, </author> <title> "Modelling and robustness issues in Bayesian time series analysis (with discussion)," in Bayesian Robustness 2, </title> <editor> J. Berger, F. Ruggeri, and L. Wasserman, eds., </editor> <address> IMS Monographs, </address> <note> 1995 (to appear). </note>
Reference-contexts: Various classes of priors, including non-parametric models, are being explored for time deformation functions. Applications include modelling irregular waveform patterns of long series of EEG recordings, in collaboration with Duke psychiatrists, and will be reported elsewhere; some very preliminary discussion appears in <ref> [6] </ref>. 10. Mixture Models and Non-Linear Auto-Regression A rather different but, in some sense, more traditional approach to non-linear time series modelling is initiated in [19].
Reference: 7. <author> B. Kleiner, R. Martin, and D. Thompson, </author> <title> "Robust estimation of power spectra (with discussion)," </title> <journal> J. Roy. Statist. Soc. (Ser. B), </journal> <volume> 41, </volume> <pages> pp. 313-351, </pages> <year> 1979. </year>
Reference: 8. <author> M. West, </author> <title> "Robust sequential approximate Bayesian estimation," </title> <journal> J. Roy. Statist. Soc., (Ser. B), </journal> <volume> 43, </volume> <pages> pp. 157-166, </pages> <year> 1981. </year>
Reference: 9. <institution> Statistical Sciences, </institution> <note> S-PLUS Guide to Statistical and Mathematical Analysis (Version 3.2), </note> <institution> StatSci, a division of MathSoft, Inc., </institution> <address> Seattle, </address> <year> 1993. </year>
Reference-contexts: normal mixture distribution -t ~ (1 )N (-t j0; v) + N (-t j0; k 2 v): This admits a background level of routine measurement error, with variance v; together with occasional extremes, or outliers, via the inflated variance component with k &gt; 1 with some (small) probability ([8,6,1] and <ref> [9] </ref> section 16.7). The background variation, measured by v; may be small, even negligible, in some applications ([6]); indeed, a degenerate mixture -t ~ (1 )ffi 0 (-t ) + N (-t j0; q) is the default additive outlier model in the "robust" time series fitting functions in S-Plus ([9]).
Reference: 10. <author> S. Fruhwirth-Schnatter, </author> <title> "Data augmentation and dynamic linear models," </title> <journal> J. Time Series Analysis, </journal> <volume> 15, </volume> <pages> pp. 183-102, </pages> <year> 1994. </year>
Reference-contexts: In particular, following <ref> [10] </ref> and [11], most efficient algorithms are based on reverse sampling through the sequence: p (z n jX n ; Z n ) followed by, for each t = n 1; n 2; : : : ; 1; 0 in turn, p (z t jX n ; Z n ; z <p> Issues of establishing con vergence results for MCMC schemes, especially in connection with mixture error models, are discussed in <ref> [10] </ref> and [11], for example. 7. An Illustration An analysis of an oxygen isotope record is briefly summarised as an illustration of state-space analysis with latent auto-regression and a mixture error model, implemented via simulation analysis as just summarised.
Reference: 11. <author> C. K. Carter and R. Kohn, </author> <title> "On Gibbs sampling for state space models," </title> <journal> Biometrika, </journal> <volume> 81, </volume> <pages> pp. 541-553, </pages> <year> 1994. </year>
Reference-contexts: In particular, following [10] and <ref> [11] </ref>, most efficient algorithms are based on reverse sampling through the sequence: p (z n jX n ; Z n ) followed by, for each t = n 1; n 2; : : : ; 1; 0 in turn, p (z t jX n ; Z n ; z t+1 ) <p> Issues of establishing con vergence results for MCMC schemes, especially in connection with mixture error models, are discussed in [10] and <ref> [11] </ref>, for example. 7. An Illustration An analysis of an oxygen isotope record is briefly summarised as an illustration of state-space analysis with latent auto-regression and a mixture error model, implemented via simulation analysis as just summarised.
Reference: 12. <author> P. Harrison and C. Stevens, </author> <title> "Bayesian forecasting (with discussion)," </title> <journal> J. Roy. Statist. Soc., (Ser. B), </journal> <volume> 38, </volume> <pages> pp. 205-247, </pages> <year> 1976. </year>
Reference: 13. <author> C. M. Scipione and L. M. Berliner, </author> <title> "Bayesian statistical inference in nonlinear dynamical systems," </title> <booktitle> in Proceedings of the Bayesian Statistical Science Section, American Statistical Association, </booktitle> <address> Washington, DC, </address> <year> 1993. </year>
Reference: 14. <author> B. P. Carlin, N. G. Polson, and D. S. Stoffer, </author> <title> "A Monte Carlo approach to nonnormal and nonlinear state-space modelling," </title> <journal> J. Amer. Statist. Ass., </journal> <volume> 87, </volume> <pages> pp. 493-50, </pages> <year> 1992. </year>
Reference: 15. <author> R. McCulloch and R. Tsay, </author> <title> "Bayesian analysis of autoregressive time series via the Gibbs sampler," </title> <journal> J. Time Series Analysis, </journal> <volume> 15, </volume> <pages> pp. 235-250, </pages> <year> 1994. </year>
Reference-contexts: Posterior Computations for Bayesian Time Series Analysis Following early work in [13,14,10,11], the development of MCMC simulation methods in state space frameworks is growing rapidly. Note that there are ranges of related developments outside the state-space framework, typified by <ref> [15] </ref>, for example; more references appear in the review of [16]. MCMC methods now permit Monte Carlo inference in the kinds of models exemplified above using variants of basic Gibbs and more general Metropolis-Hastings algorithms to generate approximate posterior samples of collections of state vectors and DLM parameters.
Reference: 16. <author> M. West, </author> <title> "Bayesian Forecasting," in Encyclopedia of Statistical Sciences, </title> <editor> S. Kotz, C. Read, and D. Banks, eds., </editor> <publisher> Wiley, </publisher> <address> New York, </address> <note> 1995 (in press). </note>
Reference-contexts: Posterior Computations for Bayesian Time Series Analysis Following early work in [13,14,10,11], the development of MCMC simulation methods in state space frameworks is growing rapidly. Note that there are ranges of related developments outside the state-space framework, typified by [15], for example; more references appear in the review of <ref> [16] </ref>. MCMC methods now permit Monte Carlo inference in the kinds of models exemplified above using variants of basic Gibbs and more general Metropolis-Hastings algorithms to generate approximate posterior samples of collections of state vectors and DLM parameters.
Reference: 17. <author> J. Park and K. Maasch, </author> <title> "Plio-Pleistocene time evolution of the 100-kyr cycle in marine paleoclimate records," </title> <journal> J. Geophys. Res., </journal> <volume> 98, </volume> <pages> pp. 447-461, </pages> <year> 1993. </year>
Reference-contexts: In [4,5] I discuss data and modelling questions arising in studies of the forms of quasi-periodic components of recorded geological time series in connection with investigating patterns of historical climate change. The latter reference discusses one deep-ocean oxygen isotope series used in previous analyses (e.g. <ref> [17] </ref>). A further such series is explored here; the upper frame in Figure 1 plots the data, which is representative of several oxygen isotope series from cores from various geographical locations, and measures relative abundance of ffi 18 O timed on an approximately equally spaced 3kyr scale. <p> The so-called 100kyr "ice-age cycle" is of major current geological interest in connection with debates over its genesis, roughly 1Myrs ago, and, particularly, to questions of whether or not the onset was gradual and inherent or the result of a significant structural climatic change. (e.g. <ref> [17] </ref> and references therein).
Reference: 18. <author> J. H. </author> <title> Stock, "Estimating continuous-time processes subject to time deformation: An application to postwar U.S. </title> <journal> GNP," J. Amer. Statist. Ass., </journal> <volume> 83, </volume> <pages> pp. 77-85, </pages> <year> 1986. </year>
Reference-contexts: time model (<ref> [18] </ref>); work is in progress to develop Bayesian analyses in various such contexts. 9. Random Observation Times: Time Deformation Models The conceptual and technical developments of dealing with uncertain observation times are opening a novel area involving inference on stochastic time deformations. This builds on basic ideas in [18]. which demonstrates that, under certain deterministic deformations, traditional linear models can be mapped into models with characteristics similar to some common non-linear models, such as ARCH models and threshold AR models.
Reference: 19. <author> P. Muller, M. West, and S. MacEachern, </author> <title> "Bayesian models for non-linear auto-regressions," </title> <type> ISDS Discussion Paper 94-30, </type> <institution> Duke University, </institution> <year> 1995. </year>
Reference-contexts: Mixture Models and Non-Linear Auto-Regression A rather different but, in some sense, more traditional approach to non-linear time series modelling is initiated in <ref> [19] </ref>. The interest here is in identifying and inferring departures from linearity in an auto-regressive context; though not yet developed in a state-space framework, the practical issues of dealing with observational errors will lead to such extensions. The basic idea is simple. <p> Building on flexible classes of Dirichlet mixture models developed for semi-parametric Bayesian density estimation, <ref> [19] </ref> develops models in which these defining conditionals are themselves flexible mixtures; BAYESIAN TIME SERIES 11 specifically, mixtures of normal distributions p (x t jx t1 ; : : : ; x tp ; fi) = j=1 where, for suitable k; the regression functions b j are each linear in x <p> not depend on conditioning past x tj values; and w j is a multivariate kernel factor, implying higher conditional weight on mixture components that best "support" the current conditioning values of the "state variables" x t1 ; : : : ; x tp : Our approach to inference, described in <ref> [19] </ref>, is largely predictive. Posterior computations deliver approximate posteriors for model parameters (k; fi) and then the model is interpreted predictively, exploring features of the resulting sets of conditional predictive distributions for future data just averages of mixtures (5) with respect to the posterior. <p> Examples in <ref> [19] </ref> include cases where conditional distributions in some regions of x t1 ; : : : ; x tp space are unimodal, but in other regions are clearly bi-or multi-modal. <p> Modelling entire distributions also allows for adaptation to changing patterns of variation in spread and other features of conditional predictive distributions as the series evolves. Some example in <ref> [19] </ref> illustrate these features.
Reference: 20. <author> M. West, P. Muller, and M. Escobar, </author> <title> "Hierarchical priors and mixture models, with application in regression and density estimation," in Aspects of Uncertainty: </title> <editor> A tribute to D. V. Lindley, A. Smith and P. Freeman, eds., </editor> <publisher> Wiley, </publisher> <address> New-York, </address> <year> 1994. </year>
Reference: 21. <author> H. Tong, </author> <title> Non-Linear Time Series, </title> <publisher> Oxford University Press, Oxford, </publisher> <address> England, </address> <year> 1990. </year>
Reference-contexts: In this sense, the models are capable of capturing both abrupt threshold effects (as in TAR models, <ref> [21] </ref>, chapter 3), and smooth transitions (as in STAR models, [21], section 3.3.3), as well as ranges of other non-linearities. Modelling entire distributions also allows for adaptation to changing patterns of variation in spread and other features of conditional predictive distributions as the series evolves. <p> In this sense, the models are capable of capturing both abrupt threshold effects (as in TAR models, <ref> [21] </ref>, chapter 3), and smooth transitions (as in STAR models, [21], section 3.3.3), as well as ranges of other non-linearities. Modelling entire distributions also allows for adaptation to changing patterns of variation in spread and other features of conditional predictive distributions as the series evolves. Some example in [19] illustrate these features.
References-found: 21

