URL: http://www-csag.cs.uiuc.edu/papers/clone-lcpc95.ps
Refering-URL: http://www-csag.cs.uiuc.edu/projects/concert/implementation.html
Root-URL: http://www.cs.uiuc.edu
Title: Type Directed Cloning for Object-Oriented Programs  
Author: John Plevyak and Andrew A. Chien 
Affiliation: University of Illinois at Urbana-Champaign  
Abstract: Object-oriented programming encourages the use of small functions, dynamic dispatch (virtual functions), and inheritance for code reuse. As a result, such programs typically suffer from inferior performance. The problem is that polymorphic functions do not know the exact types of the data they operate on, and hence must use indirection to operate on them. However, most polymorphism is parametric (e.g. templates in C++) which is amenable to elimination through code replication. We present a cloning algorithm which eliminates parametric polymorphism while minimizing code duplication. The effectiveness of this algorithm is demonstrated on a number of concurrent object-oriented programs. Finally, since functions and data structures can be parameterized over properties other than type, this algorithm is applicable to general for ward data flow problems.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> O. Agesen, J. Palsberg, and M. Schwartzbach. </author> <title> Type inference of Self: Analysis of objects with dynamic and multiple inheritance. </title> <booktitle> In Proceedings of ECOOP '93, </booktitle> <year> 1993. </year>
Reference-contexts: The key to eliminating the overhead of dynamic calls is concrete type information, knowledge of the implementation types that actually occur at function call sites. Such information can be obtained through global flow analysis <ref> [27, 26, 1, 28, 25] </ref> (across function boundaries and even across compilation units). These algorithms infer flow sensitive parameterizations for functions and data in the form of concrete type information. <p> Global analysis recovers this concrete type information, linking the caller and callee and breaking through abstraction boundaries to enable optimization. Recently, global program analysis frameworks have been developed for object-oriented languages which can efficiently derive global control flow and concrete type information <ref> [27, 26, 1, 28] </ref>. These algorithms simultaneously infer the interwoven global control and data flow of object-oriented programs. They do so by a combination of flow analysis and abstract interpretation and by modeling the different environment in which a function is invoked by a set of "contours" [31]. <p> However, the analysis may distinguish method contours by any aspect of the calling environment including the contours from which they were invoked [26], the types of all the arguments <ref> [1] </ref> as well as other criteria [25]. <p> In theory, flow analyses produce O (N ), O (N 2 ), O (N 6 ) or more contours for a program of size N <ref> [27, 26, 1, 25] </ref>. The number of contours seen in practice can require large amounts of space [2]. The particular analysis we use is an iterative algorithm which creates 37.9 contours in response to imprecisions discovered in previous iterations [28].
Reference: 2. <author> Ole Agesen and Urs Holzle. </author> <title> Type feedback vs. concrete type analysis: A comparison of optimization techniques for object-oriented languages. </title> <type> Technical Report TRCS 95-04, </type> <institution> Computer Science Department, University of California, Santa Barbara, </institution> <year> 1995. </year>
Reference-contexts: In theory, flow analyses produce O (N ), O (N 2 ), O (N 6 ) or more contours for a program of size N [27, 26, 1, 25]. The number of contours seen in practice can require large amounts of space <ref> [2] </ref>. The particular analysis we use is an iterative algorithm which creates 37.9 contours in response to imprecisions discovered in previous iterations [28]. As a result, it is much more conservative in the number of contours it creates than other analyses. <p> While this can remove dynamic dispatches across method invocations, it does not handle polymorphic instance variables. Finally, Agesen and Holzle have recently used the results of global analysis in the Self compiler <ref> [2] </ref>. However, the information for all the contours for each customized method is combined before being used by the optimizer. The cloning algorithm we have presented is general enough to enable optimization based on any data flow information provided by global flow analysis.
Reference: 3. <institution> Apple Computer, Inc., Cupertino, California. </institution> <note> Object Pascal User's Manual, </note> <year> 1988. </year>
Reference-contexts: Customization [6] is a simple form of cloning whereby a method is cloned for each subclass which inherits it. This enables invocations on self (or this in C++ terminology) to be statically bound. Another simple approach is to statically bind calls when there is only one possible method <ref> [3] </ref>. This idea was extended by Calder and Grunwald [4] through `if conversion', essentially a static version of polymorphic inline caches [23]. Our work also shares some similarities with that done for the Self [33] and Cecil [9] languages.
Reference: 4. <author> Brad Calder and Dirk Grunwald. </author> <title> Reducing indirect function call overhead in C++ programs. </title> <booktitle> In Twenty-first Symposium on Principles of Programming Languages, </booktitle> <pages> pages 397-408. </pages> <booktitle> ACM SIGPLAN, </booktitle> <year> 1994. </year>
Reference-contexts: This enables invocations on self (or this in C++ terminology) to be statically bound. Another simple approach is to statically bind calls when there is only one possible method [3]. This idea was extended by Calder and Grunwald <ref> [4] </ref> through `if conversion', essentially a static version of polymorphic inline caches [23]. Our work also shares some similarities with that done for the Self [33] and Cecil [9] languages. Chambers and Ungar [7], used splitting, essentially an intraprocedural cloning of basic blocks, to preserve type information within a function.
Reference: 5. <author> Brad Calder, Dirk Grunwald, and Benjamin Zorn. </author> <title> Quantifying differences between C and C++ programs. </title> <type> Technical Report CU-CS-698-94, </type> <institution> University of Colorado, Boulder, </institution> <month> January </month> <year> 1994. </year>
Reference-contexts: Likewise, concurrent object-oriented programming enables programmers to abstract and encapsulate consistency mechanisms, parallelization and 37.2 data layout decisions. This, in turn, makes the programs easier to understand and modify. Object-oriented programs differ greatly in structure from procedural code <ref> [5] </ref>, and there is every indication that these differences increase as programmers develop an "object-oriented" programming style. Though they have desirable software engineering advantages, OOP and COOP typically have an adverse impact on performance.
Reference: 6. <author> C. Chambers and D. Ungar. </author> <title> Customization: Optimizing compiler technology for Self, a dynamically-typed object-oriented programming language. </title> <booktitle> In Proceedings of SIGPLAN Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 146-60, </pages> <year> 1989. </year>
Reference-contexts: We three different runs of our compiler. The base case baseline copies out inheritance (customization <ref> [6] </ref>) but does no cloning and inlines only accessors and operations on primitive types (like integers and floats). This corresponds roughly to the optimization level for a hybrid language like C++. The optimized version includes global flow analysis and inlining and the cloning version includes the analysis, cloning and inlining. <p> We handle forward flow problems in a similar manner, but rely on global propagation to determine the final clones for recursive functions. Several different approaches have been used to reduce the overhead of object-orientation. Customization <ref> [6] </ref> is a simple form of cloning whereby a method is cloned for each subclass which inherits it. This enables invocations on self (or this in C++ terminology) to be statically bound. Another simple approach is to statically bind calls when there is only one possible method [3].
Reference: 7. <author> C. Chambers and D. Ungar. </author> <title> Iterative type analysis and extended message splitting. </title> <booktitle> In Proceedings of the SIGPLAN Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 150-60, </pages> <year> 1990. </year> <month> 37.14 </month>
Reference-contexts: This idea was extended by Calder and Grunwald [4] through `if conversion', essentially a static version of polymorphic inline caches [23]. Our work also shares some similarities with that done for the Self [33] and Cecil [9] languages. Chambers and Ungar <ref> [7] </ref>, used splitting, essentially an intraprocedural cloning of basic blocks, to preserve type information within a function. Early work on Smalltalk used inline caches [17] to exploit type locality. Holzle and Ungar [24] have shown the information obtained by polymorphic inline caches can be used to speculatively inline methods.
Reference: 8. <author> Craig Chambers. </author> <title> The Design and Implementation of the Self Compiler, an Optimizing Com--piler for Object-Oriented Programming Languages. </title> <type> PhD thesis, </type> <institution> Stanford University, Stanford, </institution> <address> CA, </address> <month> March </month> <year> 1992. </year>
Reference-contexts: The tsp program solves the traveling salesman problem. richards is an operating system simulator used to benchmark the Self system <ref> [8, 24] </ref>. The last three programs are kernels representing uses of polymorphic libraries. mmult multiplies integer and floating point matrices, poly evaluates integer and floating point polynomials and test is a synthetic code which uses multi-level polymorphic data structure.
Reference: 9. <author> Craig Chambers. </author> <title> The Cecil language: Specification and rationale. </title> <type> Technical Report TR 93-03-05, </type> <institution> Department of Computer Science and Engineering, University of Washington, </institution> <address> Seattle, Washington, </address> <month> March </month> <year> 1993. </year>
Reference-contexts: This idea was extended by Calder and Grunwald [4] through `if conversion', essentially a static version of polymorphic inline caches [23]. Our work also shares some similarities with that done for the Self [33] and Cecil <ref> [9] </ref> languages. Chambers and Ungar [7], used splitting, essentially an intraprocedural cloning of basic blocks, to preserve type information within a function. Early work on Smalltalk used inline caches [17] to exploit type locality.
Reference: 10. <author> Andrew A. Chien. </author> <title> Concurrent Aggregates: Supporting Modularity in Massively-Parallel Programs. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1993. </year>
Reference-contexts: The Concert system supports a concurrent object-oriented programming model and includes a globally optimizing compiler, efficient runtime, symbolic debugger, and an emulator for program development. This system compiles ICC++ [18], a parallel C++ dialect, and Concurrent Aggregates <ref> [11, 10] </ref> for execution on the Cray T3D [15] and Thinking Machines CM-5 [32] as well as uniprocessor workstations. <p> these sites, an entry is made into the dispatch table mapping the &lt; call site; selector; concrete type &gt; to the appropriate clone. 4 Experimental Results We have implemented these cloning techniques in the Illinois Concert compiler and tested them on tens of thousands of lines of Concurrent Aggregates programs <ref> [10] </ref>. In this section we present results from a representative sample of those programs. These test programs are concurrent object-oriented codes written by a variety of authors of differing levels of experience with object-oriented programming. They range in size from kernels to small applications.
Reference: 11. <author> Andrew A. Chien, Vijay Karamcheti, John Plevyak, and Xingbin Zhang. </author> <title> Concurrent aggregates language report 2.0. </title> <note> Available via anonymous ftp from cs.uiuc.edu in /pub/csag or from http://www-csag.cs.uiuc.edu/, September 1993. </note>
Reference-contexts: The Concert system supports a concurrent object-oriented programming model and includes a globally optimizing compiler, efficient runtime, symbolic debugger, and an emulator for program development. This system compiles ICC++ [18], a parallel C++ dialect, and Concurrent Aggregates <ref> [11, 10] </ref> for execution on the Cray T3D [15] and Thinking Machines CM-5 [32] as well as uniprocessor workstations.
Reference: 12. <author> K. Cooper, K. Kennedy, and L. Torczon. </author> <title> The impact of interprocedural analysis and optimization in the R n environment. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 8(4) </volume> <pages> 491-523, </pages> <month> October </month> <year> 1986. </year>
Reference-contexts: Total Number of Calls combined with the greater number of statically bound methods in the cloning version will enable us to reduce the number of calls even further. 5 Related Work and Discussion Cooper <ref> [12] </ref> presents general interprocedural analysis and optimization techniques. Whole program (global) analysis is used to construct the call graph and solve a number of data flow problems. Transformation techniques are described to increase the availability of this information through linkage optimization including cloning.
Reference: 13. <author> K. D. Cooper, M. W. Hall, and K. Kennedy. </author> <title> Procedure cloning. </title> <booktitle> In Proceedings of the IEEE Computer Society 1992 International Conference on Computer Languages, </booktitle> <pages> pages 96-105, </pages> <month> April </month> <year> 1992. </year>
Reference-contexts: Whole program (global) analysis is used to construct the call graph and solve a number of data flow problems. Transformation techniques are described to increase the availability of this information through linkage optimization including cloning. However, this work does not address clone minimization. Cooper and Hall <ref> [19, 21, 13, 14, 20, 22] </ref> present comprehensive interprocedural compilation techniques and cloning for FORTRAN. This work is general over forward data flow problems, and presents mechanisms for preserving information across clones and minimizing their number. However, concrete types are not a forward data flow problem.
Reference: 14. <author> K. D. Cooper, M. W. Hall, and K. Kennedy. </author> <title> A methodology for procedure cloning. </title> <journal> Computer Languages, </journal> <volume> 19(2) </volume> <pages> 105-118, </pages> <month> April </month> <year> 1993. </year>
Reference-contexts: Whole program (global) analysis is used to construct the call graph and solve a number of data flow problems. Transformation techniques are described to increase the availability of this information through linkage optimization including cloning. However, this work does not address clone minimization. Cooper and Hall <ref> [19, 21, 13, 14, 20, 22] </ref> present comprehensive interprocedural compilation techniques and cloning for FORTRAN. This work is general over forward data flow problems, and presents mechanisms for preserving information across clones and minimizing their number. However, concrete types are not a forward data flow problem.
Reference: 15. <institution> Cray Research, Inc., Eagan, Minnesota 55121. CRAY T3D Software Overview Technical Note, </institution> <year> 1992. </year>
Reference-contexts: The Concert system supports a concurrent object-oriented programming model and includes a globally optimizing compiler, efficient runtime, symbolic debugger, and an emulator for program development. This system compiles ICC++ [18], a parallel C++ dialect, and Concurrent Aggregates [11, 10] for execution on the Cray T3D <ref> [15] </ref> and Thinking Machines CM-5 [32] as well as uniprocessor workstations.
Reference: 16. <author> Jeffrey Dean, Craig Chambers, and David Grove. </author> <title> Identifying profitable specialization in object-oriented languages. </title> <type> Technical Report TR 94-02-05, </type> <institution> Department of Computer Science and Engineering, University of Washington, </institution> <address> Seattle, Washington, </address> <month> February </month> <year> 1994. </year>
Reference-contexts: While run time tests are still required, various techniques are presented to preserve the resulting type information. None of these approaches uses globally 37.13 analyzes and transformation to eliminate the run time checks nor to preserve gen-eral global data flow information. More recently, Dean, Chambers, and Grove <ref> [16] </ref> have used information collected at run time to specialize methods with respect to argument types. While this can remove dynamic dispatches across method invocations, it does not handle polymorphic instance variables. Finally, Agesen and Holzle have recently used the results of global analysis in the Self compiler [2].
Reference: 17. <author> L. Peter Deutsch and Allan M. Schiffman. </author> <title> Efficient implementation of the smalltalk-80 system. </title> <booktitle> In Eleventh Symposium on Principles of Programming Languages, </booktitle> <pages> pages 297-302. </pages> <publisher> ACM, </publisher> <year> 1984. </year>
Reference-contexts: Our work also shares some similarities with that done for the Self [33] and Cecil [9] languages. Chambers and Ungar [7], used splitting, essentially an intraprocedural cloning of basic blocks, to preserve type information within a function. Early work on Smalltalk used inline caches <ref> [17] </ref> to exploit type locality. Holzle and Ungar [24] have shown the information obtained by polymorphic inline caches can be used to speculatively inline methods. While run time tests are still required, various techniques are presented to preserve the resulting type information.
Reference: 18. <institution> The Concurrent Systems Architecture Group. </institution> <note> The ICC++ reference manual, version 1.0. Technical report, </note> <institution> University of Illinois, Department of Computer Science, 1304 W. Springfield Avenue, Urbana, Illinois, </institution> <year> 1995. </year> <note> Also available from http://www-csag.cs.uiuc.edu/. </note>
Reference-contexts: The Concert system supports a concurrent object-oriented programming model and includes a globally optimizing compiler, efficient runtime, symbolic debugger, and an emulator for program development. This system compiles ICC++ <ref> [18] </ref>, a parallel C++ dialect, and Concurrent Aggregates [11, 10] for execution on the Cray T3D [15] and Thinking Machines CM-5 [32] as well as uniprocessor workstations.
Reference: 19. <author> M. W. Hall. </author> <title> Managing Interprocedural Optimization. </title> <type> PhD thesis, </type> <institution> Rice University, </institution> <year> 1991. </year>
Reference-contexts: Since object-oriented programs tend to have very small functions, inlining is required to enable these optimizations. Unfortunately, dynamic dispatch confounds control flow, seriously complicating or preventing inlining. Likewise, parallelization, data layout, blocking and other high level transformation rely on interprocedural control flow information <ref> [19] </ref>. To inline functions a compiler for object-oriented languages must know the exact type of an object (as opposed to the declared type of which it may be a subclass). This concrete type information is precisely the detail the programmer wishes to hide, via encapsulation and code reuse. <p> Whole program (global) analysis is used to construct the call graph and solve a number of data flow problems. Transformation techniques are described to increase the availability of this information through linkage optimization including cloning. However, this work does not address clone minimization. Cooper and Hall <ref> [19, 21, 13, 14, 20, 22] </ref> present comprehensive interprocedural compilation techniques and cloning for FORTRAN. This work is general over forward data flow problems, and presents mechanisms for preserving information across clones and minimizing their number. However, concrete types are not a forward data flow problem. <p> We have used optimization criteria for increasing the availability of interprocedural constants successfully with our cloning algorithm. However, efficient cloning for such information requires estimating its potential use for optimization which we have not yet implemented. Interested readers are referred to <ref> [19] </ref> for a discussion of the issues. 6 Summary and Future Work Object-oriented programming is rapidly becoming a standard in program development. Traditional optimization techniques are severely hampered by the small methods and data dependent control flow of object-oriented programs.
Reference: 20. <author> M. W. Hall, S. Hiranandani, and K. Kennedy. </author> <title> Interprocedural compilation of Fortran D for MIMD distributed memory machines. </title> <booktitle> In Supercomputing '92, </booktitle> <pages> pages 522-535, </pages> <year> 1992. </year>
Reference-contexts: Whole program (global) analysis is used to construct the call graph and solve a number of data flow problems. Transformation techniques are described to increase the availability of this information through linkage optimization including cloning. However, this work does not address clone minimization. Cooper and Hall <ref> [19, 21, 13, 14, 20, 22] </ref> present comprehensive interprocedural compilation techniques and cloning for FORTRAN. This work is general over forward data flow problems, and presents mechanisms for preserving information across clones and minimizing their number. However, concrete types are not a forward data flow problem.
Reference: 21. <author> Mary W. Hall, Ken Kennedy, and Kathryn S. McKinley. </author> <title> Interprocedural transformations for parallel code generation. </title> <booktitle> In Proceedings of the 4 th Annual Conference on High-Performance Computing (Supercomputing '91), </booktitle> <pages> pages 424-434, </pages> <month> November </month> <year> 1991. </year>
Reference-contexts: Whole program (global) analysis is used to construct the call graph and solve a number of data flow problems. Transformation techniques are described to increase the availability of this information through linkage optimization including cloning. However, this work does not address clone minimization. Cooper and Hall <ref> [19, 21, 13, 14, 20, 22] </ref> present comprehensive interprocedural compilation techniques and cloning for FORTRAN. This work is general over forward data flow problems, and presents mechanisms for preserving information across clones and minimizing their number. However, concrete types are not a forward data flow problem.
Reference: 22. <author> Mary W. Hall, John M. Mellor-Crummey, Alan Clarle, and Rene G. Rodr iguez. FIAT: </author> <title> A framework for interprocedural analysis and transformation. </title> <booktitle> In Proceedings of the Sixth Workshop for Languages and Compilers for Parallel Machines, </booktitle> <pages> pages 522-545, </pages> <month> August </month> <year> 1993. </year>
Reference-contexts: Whole program (global) analysis is used to construct the call graph and solve a number of data flow problems. Transformation techniques are described to increase the availability of this information through linkage optimization including cloning. However, this work does not address clone minimization. Cooper and Hall <ref> [19, 21, 13, 14, 20, 22] </ref> present comprehensive interprocedural compilation techniques and cloning for FORTRAN. This work is general over forward data flow problems, and presents mechanisms for preserving information across clones and minimizing their number. However, concrete types are not a forward data flow problem.
Reference: 23. <author> Urs Holzle, Craig Charmbers, and David Ungar. </author> <title> Optimizing dynamically-typed object-oriented languages iwth polymorphic inline caches. </title> <booktitle> In ECOOP'91 Conference Proceedings. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1991. </year> <note> Lecture Notes in Computer Science 512. </note>
Reference-contexts: Another simple approach is to statically bind calls when there is only one possible method [3]. This idea was extended by Calder and Grunwald [4] through `if conversion', essentially a static version of polymorphic inline caches <ref> [23] </ref>. Our work also shares some similarities with that done for the Self [33] and Cecil [9] languages. Chambers and Ungar [7], used splitting, essentially an intraprocedural cloning of basic blocks, to preserve type information within a function. Early work on Smalltalk used inline caches [17] to exploit type locality.
Reference: 24. <author> Urs Holzle and David Ungar. </author> <title> Optimizing dynamically-dispatched calls with run-time type feedback. </title> <booktitle> In Proceedings of the 1994 ACM SIGPLAN Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 326-336, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: The tsp program solves the traveling salesman problem. richards is an operating system simulator used to benchmark the Self system <ref> [8, 24] </ref>. The last three programs are kernels representing uses of polymorphic libraries. mmult multiplies integer and floating point matrices, poly evaluates integer and floating point polynomials and test is a synthetic code which uses multi-level polymorphic data structure. <p> Chambers and Ungar [7], used splitting, essentially an intraprocedural cloning of basic blocks, to preserve type information within a function. Early work on Smalltalk used inline caches [17] to exploit type locality. Holzle and Ungar <ref> [24] </ref> have shown the information obtained by polymorphic inline caches can be used to speculatively inline methods. While run time tests are still required, various techniques are presented to preserve the resulting type information.
Reference: 25. <author> Suresh Jagannathan and Stephen Weeks. </author> <title> A unified treatment of flow analysis in higher-order languages. </title> <booktitle> In Twenty-second Symposium on Principles of Programming Languages, </booktitle> <pages> pages 393-407. </pages> <booktitle> ACM SIGPLAN, </booktitle> <year> 1995. </year>
Reference-contexts: The key to eliminating the overhead of dynamic calls is concrete type information, knowledge of the implementation types that actually occur at function call sites. Such information can be obtained through global flow analysis <ref> [27, 26, 1, 28, 25] </ref> (across function boundaries and even across compilation units). These algorithms infer flow sensitive parameterizations for functions and data in the form of concrete type information. <p> However, the analysis may distinguish method contours by any aspect of the calling environment including the contours from which they were invoked [26], the types of all the arguments [1] as well as other criteria <ref> [25] </ref>. Thus, a call graph on the contours cannot, in general, be realized by the standard dispatch mechanism. 3.2 Modified Dynamic Dispatch Mechanism Cloning modifies the call graph by replicating subgraphs the methods of which are then called by only a subset of the previous callers. <p> In theory, flow analyses produce O (N ), O (N 2 ), O (N 6 ) or more contours for a program of size N <ref> [27, 26, 1, 25] </ref>. The number of contours seen in practice can require large amounts of space [2]. The particular analysis we use is an iterative algorithm which creates 37.9 contours in response to imprecisions discovered in previous iterations [28].
Reference: 26. <author> N. Oxhtj, J. Palsberg, and M. Schwartzbach. </author> <title> Making type inference practical. </title> <booktitle> In Proceedings of OOPSLA '92, </booktitle> <year> 1992. </year>
Reference-contexts: The key to eliminating the overhead of dynamic calls is concrete type information, knowledge of the implementation types that actually occur at function call sites. Such information can be obtained through global flow analysis <ref> [27, 26, 1, 28, 25] </ref> (across function boundaries and even across compilation units). These algorithms infer flow sensitive parameterizations for functions and data in the form of concrete type information. <p> Global analysis recovers this concrete type information, linking the caller and callee and breaking through abstraction boundaries to enable optimization. Recently, global program analysis frameworks have been developed for object-oriented languages which can efficiently derive global control flow and concrete type information <ref> [27, 26, 1, 28] </ref>. These algorithms simultaneously infer the interwoven global control and data flow of object-oriented programs. They do so by a combination of flow analysis and abstract interpretation and by modeling the different environment in which a function is invoked by a set of "contours" [31]. <p> call graph including the dispatch tables. 3.1 Contours and Clones Flow analysis of object-oriented programs produces information about data flow values for methods based on the contours (calling environments) in which they 37.4 are invoked and for instance variables based on the statement and contour at which they were created <ref> [26, 28] </ref>. <p> However, the analysis may distinguish method contours by any aspect of the calling environment including the contours from which they were invoked <ref> [26] </ref>, the types of all the arguments [1] as well as other criteria [25]. <p> In theory, flow analyses produce O (N ), O (N 2 ), O (N 6 ) or more contours for a program of size N <ref> [27, 26, 1, 25] </ref>. The number of contours seen in practice can require large amounts of space [2]. The particular analysis we use is an iterative algorithm which creates 37.9 contours in response to imprecisions discovered in previous iterations [28].
Reference: 27. <author> J. Palsberg and M. Schwartzbach. </author> <title> Object-oriented type inference. </title> <booktitle> In Proceedings of OOPSLA '91, </booktitle> <pages> pages 146-61, </pages> <year> 1991. </year>
Reference-contexts: The key to eliminating the overhead of dynamic calls is concrete type information, knowledge of the implementation types that actually occur at function call sites. Such information can be obtained through global flow analysis <ref> [27, 26, 1, 28, 25] </ref> (across function boundaries and even across compilation units). These algorithms infer flow sensitive parameterizations for functions and data in the form of concrete type information. <p> Global analysis recovers this concrete type information, linking the caller and callee and breaking through abstraction boundaries to enable optimization. Recently, global program analysis frameworks have been developed for object-oriented languages which can efficiently derive global control flow and concrete type information <ref> [27, 26, 1, 28] </ref>. These algorithms simultaneously infer the interwoven global control and data flow of object-oriented programs. They do so by a combination of flow analysis and abstract interpretation and by modeling the different environment in which a function is invoked by a set of "contours" [31]. <p> In theory, flow analyses produce O (N ), O (N 2 ), O (N 6 ) or more contours for a program of size N <ref> [27, 26, 1, 25] </ref>. The number of contours seen in practice can require large amounts of space [2]. The particular analysis we use is an iterative algorithm which creates 37.9 contours in response to imprecisions discovered in previous iterations [28].
Reference: 28. <author> John Plevyak and Andrew A. Chien. </author> <title> Precise concrete type inference of object-oriented programs. </title> <booktitle> In Proceedings of OOPSLA, </booktitle> <year> 1994. </year>
Reference-contexts: The key to eliminating the overhead of dynamic calls is concrete type information, knowledge of the implementation types that actually occur at function call sites. Such information can be obtained through global flow analysis <ref> [27, 26, 1, 28, 25] </ref> (across function boundaries and even across compilation units). These algorithms infer flow sensitive parameterizations for functions and data in the form of concrete type information. <p> Global analysis recovers this concrete type information, linking the caller and callee and breaking through abstraction boundaries to enable optimization. Recently, global program analysis frameworks have been developed for object-oriented languages which can efficiently derive global control flow and concrete type information <ref> [27, 26, 1, 28] </ref>. These algorithms simultaneously infer the interwoven global control and data flow of object-oriented programs. They do so by a combination of flow analysis and abstract interpretation and by modeling the different environment in which a function is invoked by a set of "contours" [31]. <p> call graph including the dispatch tables. 3.1 Contours and Clones Flow analysis of object-oriented programs produces information about data flow values for methods based on the contours (calling environments) in which they 37.4 are invoked and for instance variables based on the statement and contour at which they were created <ref> [26, 28] </ref>. <p> In our example, the call site information would allow us to select the version of print for Circle at the first call site and that for Square at the second. 2 Method contours and class contours correspond to entry sets and creation sets in <ref> [28] </ref>. Since only a single dimension is added, this mechanism is the smallest extension sufficient to select the correct clone, and, unlike multiple-dispatch, is independent of the number of arguments. Cloning partitions the objects in user defined classes into concrete types which have more precise type signatures. <p> The number of contours seen in practice can require large amounts of space [2]. The particular analysis we use is an iterative algorithm which creates 37.9 contours in response to imprecisions discovered in previous iterations <ref> [28] </ref>. As a result, it is much more conservative in the number of contours it creates than other analyses.
Reference: 29. <author> John Plevyak, Vijay Karamcheti, Xingbin Zhang, and Andrew Chien. </author> <title> A hybrid execution model for fine-grained languages on distributed memory multicomputers. </title> <booktitle> In Proceedings of Supercomputing '95, </booktitle> <year> 1995. </year>
Reference-contexts: On parallel machines, the more precise control flow information has enabled us to specialize the calling conventions in our hybrid execution model <ref> [29] </ref>.
Reference: 30. <author> John Plevyak, Xingbin Zhang, and Andrew A. Chien. </author> <title> Obtaining sequential efficiency in concurrent object-oriented programs. </title> <booktitle> In Proceedings of the ACM Symposium on the Principles of Programming Languages, </booktitle> <pages> pages 311-321, </pages> <month> January </month> <year> 1995. </year>
Reference-contexts: Object-oriented programs make frequent calls which, in addition to their own cost, disrupt instruction scheduling and register usage. To make matters worse, such programs allow the target of function calls to be data dependent, making inlining difficult or impossible 1 and compicating parallelization and concurrency optimization <ref> [30] </ref>. The key to eliminating the overhead of dynamic calls is concrete type information, knowledge of the implementation types that actually occur at function call sites. Such information can be obtained through global flow analysis [27, 26, 1, 28, 25] (across function boundaries and even across compilation units). <p> Cloning is used in our system to enable unboxing and register allocation of integer and floating point numbers, unboxing of integer and floating point arrays, and inlining and static binding of functions, enabling us to obtain sequential efficiency comparable to C <ref> [30] </ref>. On parallel machines, the more precise control flow information has enabled us to specialize the calling conventions in our hybrid execution model [29].
Reference: 31. <author> Olin Shivers. </author> <title> Topics in Advanced Language Implementation, chapter Data-Flow Analysis and Type Recovery in Scheme, </title> <address> pages 47-88. </address> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1991. </year>
Reference-contexts: The code operating on such instances could be optimized for the type of contents. Unfortunately, flow analysis results cannot be used directly for cloning, because the natural candidates for replication, contours <ref> [31] </ref>, are too numerous and because standard dispatch mechanisms cannot select between them at runtime. We present a cloning algorithm which minimizes the number of clones by replicating functions based on optimization criteria such as minimization of dynamic dispatch, unboxing opportunities and data layout. <p> These algorithms simultaneously infer the interwoven global control and data flow of object-oriented programs. They do so by a combination of flow analysis and abstract interpretation and by modeling the different environment in which a function is invoked by a set of "contours" <ref> [31] </ref>. Typical analyses create for each function a number of contours polynomial in the size of the program.
Reference: 32. <institution> Thinking Machines Corporation, </institution> <address> 245 First Street, Cambridge, MA 02154-1264. </address> <booktitle> The Connection Machine CM-5 Technical Summary, </booktitle> <month> October </month> <year> 1991. </year>
Reference-contexts: This system compiles ICC++ [18], a parallel C++ dialect, and Concurrent Aggregates [11, 10] for execution on the Cray T3D [15] and Thinking Machines CM-5 <ref> [32] </ref> as well as uniprocessor workstations. Cloning is used in our system to enable unboxing and register allocation of integer and floating point numbers, unboxing of integer and floating point arrays, and inlining and static binding of functions, enabling us to obtain sequential efficiency comparable to C [30].
Reference: 33. <author> David Ungar and Randall B. Smith. </author> <title> Self: The power of simplicity. </title> <booktitle> In Proceedings of OOPSLA '87, </booktitle> <pages> pages 227-41. </pages> <booktitle> ACM SIGPLAN, </booktitle> <publisher> ACM Press, </publisher> <year> 1987. </year>
Reference-contexts: Another simple approach is to statically bind calls when there is only one possible method [3]. This idea was extended by Calder and Grunwald [4] through `if conversion', essentially a static version of polymorphic inline caches [23]. Our work also shares some similarities with that done for the Self <ref> [33] </ref> and Cecil [9] languages. Chambers and Ungar [7], used splitting, essentially an intraprocedural cloning of basic blocks, to preserve type information within a function. Early work on Smalltalk used inline caches [17] to exploit type locality.
Reference: 34. <author> Tim A. Wagner, Vance Maverick, Susan L. Graham, and Michael A. Harrison. </author> <title> Accurate static estimators for program optimization. </title> <booktitle> In Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 85-96, </pages> <address> Orlando, Florida USA, </address> <month> June </month> <year> 1994. </year> <title> This article was processed using the L A T E X macro package with LLNCS style 37.15 </title>
Reference-contexts: The code to check these optimization criteria appears in Figure 3 under the comments: optimization criteria. Standard techniques for profiling or frequency estim ation <ref> [34] </ref> can be used to maximize the benefits of optimization while limiting code expansion. To ensure that the call graph is realizable by the modified dispatch mech anism, further refinement of the partitions may be required. This affects both method and class partitions.
References-found: 34

