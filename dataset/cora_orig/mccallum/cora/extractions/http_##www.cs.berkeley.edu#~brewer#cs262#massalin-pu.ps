URL: http://www.cs.berkeley.edu/~brewer/cs262/massalin-pu.ps
Refering-URL: http://www.cs.berkeley.edu/~brewer/cs262.html
Root-URL: 
Email: calton@cs.columbia.edu  
Title: Threads and Input/Output in the Synthesis Kernel  
Author: Henry Massalin Calton Pu 
Date: November 3, 1995  
Address: New York, NY 10027  
Affiliation: Department of Computer Science Columbia University,  
Abstract: The Synthesis operating system kernel combines several techniques to provide high performance, including kernel code synthesis, fine-grain scheduling, and optimistic synchronization. Kernel code synthesis reduces the execution path for frequently used kernel calls. Optimistic synchronization increases concurrency within the kernel. Their combination results in significant performance improvement over traditional operating system implementations. Using hardware and software emulating a SUN 3/160 running SUNOS, Synthesis achieves several times to several dozen times speedup for Unix kernel calls and context switch times of 21 mi croseconds or faster.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Anonymous et al. </author> <title> SUNOS release 3.5 source code. SUN Microsystems Source License, </title> <year> 1988. </year>
Reference-contexts: are expensive in traditional systems like Unix because they always do the work of a complete switch: save the registers in a system area, setup the C run-time stack, find the current proc-table and copy the registers into proc-table, start the next process, among other complications (summarized from source code <ref> [1] </ref>). A Synthesis context-switch is shorter for two reasons. First, we switch only the part of the context being used, not all of it. Second, we use executable data structures to minimize the critical path.
Reference: [2] <author> Douglas Hofstadter. </author> <title> Godel, Escher, Bach: an eternal golden braid. </title> <publisher> Basic Books, </publisher> <year> 1979. </year>
Reference-contexts: The executable a.out was timed on the SUN, then brought over to the Quamachine and executed under the Unix emulator. To validate our emulation, the first benchmark program is a compute-bound test of similarity between the two machines. This test program implements a function producing a chaotic sequence <ref> [2] </ref>. It touches a large array at non-contiguous points, which ensures that we are not just measuring the "in-the-cache" perfor 16 mance. 6.2 Comparing Synthesis with SUNOS The purpose of making the Synthesis hardware and software emulate the SUN 3/160 is to compare Synthesis with SUNOS kernel calls.
Reference: [3] <author> H. Massalin and C. Pu. </author> <title> Fine-grain scheduling. </title> <booktitle> In Proceedings of the Workshop on Experience in Building Distributed Systems, Asilomar, </booktitle> <address> Calilfornia, </address> <month> October </month> <year> 1989. </year> <month> 21 </month>
Reference-contexts: Instead of priorities, Synthesis uses fine-grain scheduling, which assigns larger or smaller quanta to threads based on a "need to execute" criterion. A detailed explanation on fine-grain scheduling is beyond the scope of this paper; the idea and its implementation in Synthesis are described in detail in another paper <ref> [3] </ref>. Here, we only give a brief informal summary. In our directed graph model of computation (Section 2.1), a thread's "need to execute" is determined by the rate at which I/O data flows into and out of its quaspace.
Reference: [4] <author> C. Pu and H. Massalin. </author> <title> Model of computation in Synthesis. </title> <type> Technical Report CUCS-383-88, </type> <institution> Department of Computer Science, Columbia University, </institution> <note> In preparation. </note>
Reference-contexts: To support parallel and distributed computing, the threads of execution form a directed graph, in which the nodes are threads and the arcs are data flow channels. This graph model and other support for parallel and distributed computation will be described in more detail in another paper <ref> [4] </ref>. 3 Synthesis threads are threads of execution, like Unix processes. Some threads never execute user-level code, but run entirely within the kernel to provide additional concurrency for some kernel operations. Threads execute programs in a quaspace (quasi address space), which also store data. <p> I/O includes all data flow among hardware devices and quaspaces. Data move along logical channels we call streams, which connect the source and the destination of data flow. The details of the stream model of I/O will be described in a separate paper <ref> [4] </ref>. Here we describe how the streams are implemented using the building blocks described in Section 2.3. 12 5.1 I/O Device Servers Physical I/O devices are encapsulated in quajects called device servers. Typically, the device server interface supports the usual I/O operations such as read and write.
Reference: [5] <author> C. Pu, H. Massalin, and J. Ioannidis. </author> <title> The Synthesis kernel. </title> <journal> Computing Systems, </journal> <volume> 1(1) </volume> <pages> 11-32, </pages> <month> Winter </month> <year> 1988. </year>
Reference-contexts: To achieve very high performance, we combine kernel code synthesis <ref> [5] </ref>, which decreases kernel call overhead through specialization, and reduced synchronization, which decreases kernel thread synchronization overhead. 2 We have introduced the principles of code synthesis [5], which makes the Synthesis kernel fast for several reasons. <p> To achieve very high performance, we combine kernel code synthesis <ref> [5] </ref>, which decreases kernel call overhead through specialization, and reduced synchronization, which decreases kernel thread synchronization overhead. 2 We have introduced the principles of code synthesis [5], which makes the Synthesis kernel fast for several reasons. First, frequently executed Synthesis kernel calls are "compiled" and optimized at run-time using ideas similar to currying and constant folding. <p> The current implementation of the kernel does not support virtual memory. 2.2 Kernel Code Synthesis The idea of kernel code synthesis has been introduced in a previous paper <ref> [5] </ref>. In Synthesis, we have a code synthesizer in the kernel to generate specialized (thus short and fast) kernel routines for specific situations. We have three methods to synthesize code. The Factoring Invariants method bypasses redundant computations, much like constant folding. <p> With unrolled loops this achieves the data transfer rate of about 8MB per second. Program 5 reads and writes a file (cached in main memory) in chunks of 1K bytes. This is the same program used in an earlier measurement of Synthesis <ref> [5] </ref> and shows some improvement in the current implementation of Synthesis. We include the programs 6 and 7, which open/close /dev/null and /dev/tty, to show that Synthesis kernel code generation is very efficient.
Reference: [6] <author> C.J. Stephenson. </author> <title> Fast fits. </title> <booktitle> In Proceedings of the Ninth ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 30-32, </pages> <month> October </month> <year> 1983. </year>
Reference-contexts: For example, naive implementations of memory allocation, block copy, and string comparison would have slowed down our system considerably. In Synthesis, the memory allocation routine is an executable data structure implementing a fast-fit heap <ref> [6] </ref> with randomized traversal added. The block copy as used in read has been outlined in Section 6.2.
Reference: [7] <author> W.A. Wulf, E. Cohen, W. Corwin, A. Jones, R. Levin, C. Pierson, and F. Pollack. Hydra: </author> <title> The kernel of a multiprocessing operating system. </title> <journal> Communications of ACM, </journal> <volume> 17(6) </volume> <pages> 337-345, </pages> <month> June </month> <year> 1974. </year> <month> 22 </month>
Reference-contexts: The Synthesis kernel can be divided into a number of collections of procedures and data. We call these collections of procedures quajects that encapsulate hardware resources, like Hydra objects <ref> [7] </ref>. For this paper the most important quajects are threads and I/O device servers. Threads are an abstraction of the CPU. The device servers are abstractions of I/O devices. Except for the threads, quajects consist only of procedures and data.
References-found: 7

