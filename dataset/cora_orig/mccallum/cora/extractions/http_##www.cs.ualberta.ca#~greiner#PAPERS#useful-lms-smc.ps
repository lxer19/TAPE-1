URL: http://www.cs.ualberta.ca/~greiner/PAPERS/useful-lms-smc.ps
Refering-URL: http://www.cs.ualberta.ca/~greiner/PAPERS/
Root-URL: 
Title: Learning to Select Useful Landmarks  
Author: Russell Greiner and Ramana Isukapalli 
Keyword: autonomous navigation, probably-approximately-correct learning, position estimation, landmark selection  
Abstract: To navigate effectively, an autonomous agent must be able to quickly and accurately determine its current location. Given an initial estimate of its position (perhaps based on dead-reckoning) and an image taken of a known environment, our agent first attempts to locate a set of landmarks (real-world objects at known locations), then uses their angular separation to obtain an improved estimate of its current position. Unfortunately, some landmarks may not be visible, or worse, may be confused with other landmarks, resulting in both time wasted in searching for undetected landmarks, and in further errors in the agent's estimate of its position. To address these problems, we propose a method that uses previous experiences to learn a selection function that, given the set of landmarks that might be visible, returns the subset that can be used to reliably provide an accurate registration of the agent's position. We use statistical techniques to prove that the learned selection function is, with high probability, effectively at a local optimum in the space of such functions. This report also presents empirical evidence, using real-world data, that demonstrate the effectiveness of our approach. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Betke and L. Gurvits, </author> <title> "Mobile robot localization using landmarks," </title> <booktitle> Proceedings of the IEEE/RSJ/GI International Conference on Intelligent Robots and Systems, IEEE, </booktitle> <month> Sept. </month> <year> 1994. </year>
Reference-contexts: algorithm will not match ` i to an edge that is counter-clockwise from an edge it matched to ` j . (Notice that some of the landmarks sought may not be found, and that some of the edges may be unmatched.) Given this edge-to-landmark mapping, Locate uses the Betke/Gurvits algorithm <ref> [1] </ref> to efficiently produce an estimate of the agent's position and uncertainty. 8 We gathered 270 such "pictures" at known locations within three halls of our building.
Reference: [2] <author> P. J. Bickel and K. A. Doksum, </author> <title> Mathematical Statistics: Basic Ideas and Selected Topics. </title> <publisher> Holden-Day, Inc., </publisher> <address> Oakland, </address> <year> 1977. </year>
Reference-contexts: m Norm ( ff; fi ) = ff z 1 (1 2 ) ff Norm (m; fi ) = q m t 1 (3) where z (p) = 1 p 2 1 e x 2 2 dx computes the p th quantile of the standard normal distribution N (0; 1) <ref> [2] </ref>; 1 2 m X Err ( Sel; u ` ) 2 m `=1 ! 2 5 is an unbiased estimator of the variance of the Err ( Sel; u ` ) variables after m samples; and t m (p) is the p th quantile of the Student's T distribution with
Reference: [3] <author> L. Breiman, J. Friedman, J. Olshen, and C. Stone, </author> <title> Classification and Regression Trees. </title> <publisher> Wadsworth and Brooks, </publisher> <address> Monterey, CA, </address> <year> 1984. </year>
Reference-contexts: error is minimal). (This learning/performance dichotomy appears in [30], and the view that learning corresponds to improving the performance of a performance system on its performance task, discussed in [28] and elsewhere, is the basis for learning systems that range from standard decision tree learners like c4.5 [26] and cart <ref> [3] </ref> that seek the decision tree whose expected accuracy is maximal, through speed-up learning systems [25], [21] that seek a set of macros that yield an optimally efficient program, to neural net learners [27], [24], [14] that seek a setting of the weights that produces an optimal classifier, etc.) Moreover, LearnSF
Reference: [4] <author> R. Caruana and D. Freitag, </author> <title> "Greedy attribute selection," </title> <booktitle> Proceedings of the Eleventh International Machine Learning Workshop, </booktitle> <pages> pp. 28-36, </pages> <address> N.J., </address> <publisher> Morgan Kaufmann, </publisher> <year> 1994. </year>
Reference-contexts: accuracy is maximal, through speed-up learning systems [25], [21] that seek a set of macros that yield an optimally efficient program, to neural net learners [27], [24], [14] that seek a setting of the weights that produces an optimal classifier, etc.) Moreover, LearnSF qualifies as a "wrapper learning system" [17], <ref> [4] </ref>, as it views its "performance elements" (the individual selection functions) as black boxes, whose behavior can be sampled, but whose internals are unavailable. Notice this makes it fairly easy to adapt the LearnSF system to work with other types of performance elements, in other contexts; see Section IV-A. II.
Reference: [5] <author> M. </author> <title> Case, "Single landmark navigation by mobile robots," </title> <booktitle> Proceedings of the SPIE, Conference on "Mobile Robots", </booktitle> <volume> vol. 727, </volume> <pages> pp. 231-238. </pages> <booktitle> SPIE | The International Society for Optical Engineering, </booktitle> <month> Oct. </month> <year> 1986. </year>
Reference: [6] <author> I. Cox and G. Wilfong, eds., </author> <title> Autonomous Robot Vehicles. </title> <publisher> Springer-Verlag, </publisher> <year> 1990. </year>
Reference: [7] <author> T. Dean, K. Basye, and L. Kaelbling, </author> <title> "Uncertainty in graph-based map learning," in Robot Learning (J. </title> <editor> Connel and S. Ma-hadevan, </editor> <booktitle> eds.), </booktitle> <pages> pp. 171-192, </pages> <publisher> Kluwer Academic Publishers, </publisher> <year> 1994. </year>
Reference: [8] <author> R. O. Duda and P. E. Hart, </author> <title> Pattern Classification and Scene Analysis. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1973. </year> <month> 19 </month>
Reference-contexts: Alternatively, if these errors are completely uncorrelated with the landmarks, the best strategy is simply to ignore this factor and select the landmark set leading to the best empirical score <ref> [8] </ref>; notice again that this is precisely what LearnSF will do. III. Empirical Results The arguments above suggest that a good selection function should help an autonomous agent to register its position efficiently and accurately, and also that LearnSF should help find such a good selection function.
Reference: [9] <author> S. P. Engelson, </author> <title> "Active place recognition using image signatures," </title> <booktitle> SPIE Symposium on Intelligent Robotic Systems, Sensor Fusion V, </booktitle> <pages> pp. 393-404. </pages> <booktitle> SPIE | The International Society for Optical Engineering, </booktitle> <year> 1992. </year>
Reference: [10] <author> C. Fennema, A. Hanson, E. Riseman, J. Beveridge, and R. Kumar, </author> <title> "Model-directed mobile robot navigation," </title> <journal> IEEE Transactions on Systems, Man and Cybernetics, </journal> <volume> vol. 20, no. 6, </volume> <pages> pp. 1352-1369, </pages> <year> 1990. </year>
Reference: [11] <author> R. Greiner, </author> <title> "Probabilistic hill-climbing: Theory and applications," </title> <booktitle> Proceedings of CSCSI-92, </booktitle> <pages> pp. 60-67, </pages> <address> Vancouver, June 1992, </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Finally, our overall LearnSF system is an instance of the very general "probabilistic hill-climbing" learning algorithm <ref> [11] </ref>, as it uses a set of "experiences" (each an image labeled with actual agent position, etc.) to climb in a discrete space of "performance elements" (here, the space of individual selection functions) seeking one whose expected "utility" is optimal (here, whose expected error is minimal). (This learning/performance dichotomy appears in <p> Finally, note that our basic "probabilistic hill-climbing" LearnSF algorithm can be applied, mutatis mutandis, to any other task that requires searching through a discrete space of "performance elements" (such as the above space of selection functions) seeking an element whose average performance is optimal; see <ref> [11] </ref>.
Reference: [12] <author> R. Greiner, </author> <title> "PALO: A probabilistic hill-climbing algorithm," </title> <type> Technical report, </type> <institution> Siemens Corporate Research, </institution> <year> 1995. </year>
Reference-contexts: Otherwise, the implicit assumption that the sum of the random variables is normal, is likely to be violated, which could cause the system to take an inappropriate action. 6 The proof of this theorem is isomorphic to the proof that appears in <ref> [12] </ref>. 8 Algorithm LearnSF ( Sel (0) : selection function; * : &lt; + ; ffi : &lt; + ) : selection function For j = 0::1 do Letffi j ffi 6 (j+1) 2 2 , % T ( Sel (j) ) are Sel (j) 's neighbors L j m (
Reference: [13] <author> T. Hancock and S. Judd, "Ratbot: </author> <title> Robot navigation using simple visual algorithms," </title> <booktitle> 1993 IEEE Regional Conference on Control Systems (T. Chang, </booktitle> <publisher> ed.), </publisher> <pages> pp. 181-184, </pages> <address> NJIT, </address> <month> Aug. </month> <year> 1993. </year>
Reference-contexts: Notice this makes it fairly easy to adapt the LearnSF system to work with other types of performance elements, in other contexts; see Section IV-A. II. Function for Selecting Good Landmarks A. Performance Task: Position Estimation The current RatBOT system <ref> [13] </ref> maintains estimates ^x (^) of its current position x (uncertainty, ). It uses two algorithms when computing these values: * LMs ( x ), which specifies the subset of the landmarks that may be visible from each position x. <p> Locate then uses geometric reasoning to obtain 4 Fig. 2. Representation of Landmarks (viewing part of Hallway-A, from above) a new estimate of RatBOT's position and uncertainty, which are then returned. (Section III-A provides more details about the low-level vision parts of this algorithm; and <ref> [13] </ref> describes the overall RatBOT system.) As our goal is an efficient way of locating the agent's position, our implementation uses an inexpensive way of finding the set of landmarks based on simple tests on the visual image. <p> To test these theoretical claims, we implemented various selection functions and the LearnSF learning algorithm, and incorporated them within an implemented autonomous agent, the RatBOT system described in <ref> [13] </ref>. This section describes our empirical results. A. <p> First, we see that selection functions are useful; notice in particular that the landmarks they returned enabled R to obtain fairly good positional estimates (within a few tenths of a meter, which was sufficient for our purposes of identifying offices, etc. <ref> [13] </ref>). 17 TABLE V Varying Landmark-to-Error Ratio (using Sel (A) , * = 0:1 m, ffi = 0:05, = 0:3 m) Ratio Err Sel (A:1) /Err Sel (A:2) /Err Sel (A:3) /Err Sel (A:4) /Err Sel (A:5) /Err Sel (A:6) /Err 0 346 2022/ 280 5 606 64/ 467 149 /
Reference: [14] <author> G. Hinton, </author> <title> "Connectionist learning procedures," </title> <journal> Artificial Intelligence, </journal> <volume> vol. 40, no. </volume> <pages> 1-3, pp. 185-234, </pages> <year> 1989. </year>
Reference-contexts: for learning systems that range from standard decision tree learners like c4.5 [26] and cart [3] that seek the decision tree whose expected accuracy is maximal, through speed-up learning systems [25], [21] that seek a set of macros that yield an optimally efficient program, to neural net learners [27], [24], <ref> [14] </ref> that seek a setting of the weights that produces an optimal classifier, etc.) Moreover, LearnSF qualifies as a "wrapper learning system" [17], [4], as it views its "performance elements" (the individual selection functions) as black boxes, whose behavior can be sampled, but whose internals are unavailable.
Reference: [15] <author> W. Hoeffding, </author> <title> "Probability inequalities for sums of bounded random variables," </title> <journal> Journal of the American Statistical Association, </journal> <volume> vol. 58, no. 301, </volume> <pages> pp. 13-30, </pages> <year> 1963. </year>
Reference-contexts: different types: Miscellaneous, BlackStrip, ConcaveCorner, ConvexCorner, DarkColored Door, LightColoredDoor, Picture, FireExtinguisher and SupportBetweenWindows. 4 That is, we assume there is no explicit correlation between the errors encountered from one instance to the next, which is a very reasonable, and standard, assumption. 7 For general distributions, we can use Hoeffding's inequality <ref> [15] </ref> to obtain m HI ( ff; fi ) = 1 ff ln 2 ff HI (m; fi ) = fl 1 fi where here fl = max Sel;u f Err ( Sel; u ) g is the largest value of Err ( Sel; u ) for any selection function Sel
Reference: [16] <author> P. Huber, </author> <title> Robust Statistics. </title> <publisher> Wiley, </publisher> <address> NY, </address> <year> 1981. </year>
Reference-contexts: Notice also that our task, of identifying a good subset of landmarks, has some similarities to the techniques of robust analysis and outlier removal <ref> [16] </ref>. Such techniques, however, first accumulate all of the possible information, and then remove or de-emphasize certain individual components.
Reference: [17] <author> G. H. John, R. Kohavi, and K. Pfleger, </author> <title> "Irrelevant features and the subset selection problem," </title> <booktitle> Proceedings of the Eleventh International Machine Learning Workshop, </booktitle> <pages> pp. 121-129, </pages> <address> N.J., 1994, </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: expected accuracy is maximal, through speed-up learning systems [25], [21] that seek a set of macros that yield an optimally efficient program, to neural net learners [27], [24], [14] that seek a setting of the weights that produces an optimal classifier, etc.) Moreover, LearnSF qualifies as a "wrapper learning system" <ref> [17] </ref>, [4], as it views its "performance elements" (the individual selection functions) as black boxes, whose behavior can be sampled, but whose internals are unavailable. Notice this makes it fairly easy to adapt the LearnSF system to work with other types of performance elements, in other contexts; see Section IV-A.
Reference: [18] <author> A. Kosaka and A. C. Kak, </author> <title> "Fast vision-guided mobile robot navigation using model-based reasoning and prediction of uncertainties," Computer Vision, Graphics, </title> <booktitle> and Image Processing-Image Understanding, </booktitle> <volume> vol. 56, no. 3, </volume> <pages> pp. 271-329, </pages> <year> 1992. </year>
Reference: [19] <author> B. J. Kuipers and Y.-T. Byun, </author> <title> "A robust, qualitative method for robot spatial learning," </title> <booktitle> Proceedings of the Seventh National Conference on Artificial Intelligence, </booktitle> <pages> pp. 774-779, </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1988. </year>
Reference: [20] <author> B. J. Kuipers and T. S. Levitt, </author> <title> "Navigation and mapping in large-scale space," </title> <journal> AI Magazine, </journal> <volume> vol. 9, no. 2, </volume> <pages> pp. 25-43, </pages> <year> 1988. </year>
Reference: [21] <author> J. E. Laird, P. S. Rosenbloom, and A. Newell, </author> <title> Universal Subgoaling and Chunking: The Automatic Generation and Learning of Goal Hierarchies. </title> <publisher> Kluwer Academic Press, </publisher> <address> Hingham, MA, </address> <year> 1986. </year>
Reference-contexts: improving the performance of a performance system on its performance task, discussed in [28] and elsewhere, is the basis for learning systems that range from standard decision tree learners like c4.5 [26] and cart [3] that seek the decision tree whose expected accuracy is maximal, through speed-up learning systems [25], <ref> [21] </ref> that seek a set of macros that yield an optimally efficient program, to neural net learners [27], [24], [14] that seek a setting of the weights that produces an optimal classifier, etc.) Moreover, LearnSF qualifies as a "wrapper learning system" [17], [4], as it views its "performance elements" (the individual
Reference: [22] <author> T. S. Levitt and D. T. Lawton, </author> <title> "Qualitative navigation for mobile robots," </title> <journal> Artificial Intelligence, </journal> <volume> vol. 44, </volume> <pages> pp. 305-360, </pages> <year> 1990. </year>
Reference: [23] <author> M. Mataric, </author> <title> "Navigation with a rat brain: A neurobiologically-inspired model for robot spatial representation," </title> <booktitle> Proceedings of the First International Conference on Simulation of Adaptive Behavior: From Animals to Animats, </booktitle> <pages> pp. 169-175, </pages> <publisher> MIT Press, </publisher> <year> 1991. </year>
Reference-contexts: 1 As one example, Mataric <ref> [23] </ref> presents a model, motivated by the organization and function of the rat hippocampus, that allows a robot, equipped with sonar sensors and a compass, to learn a map by boundary tracing and "landmark" detection.
Reference: [24] <author> J. L. McClelland, D. E. Rumelhart, </author> <title> and the PDP Research Group, </title> <editor> eds., </editor> <booktitle> Parallel Distributed Processing: Explorations in the Microstructure of Cognition, </booktitle> <volume> vol. </volume> <month> 2: </month> <title> Psychological and Biological Models, </title> <publisher> MIT Press, </publisher> <address> Cambridge, </address> <year> 1986. </year>
Reference-contexts: basis for learning systems that range from standard decision tree learners like c4.5 [26] and cart [3] that seek the decision tree whose expected accuracy is maximal, through speed-up learning systems [25], [21] that seek a set of macros that yield an optimally efficient program, to neural net learners [27], <ref> [24] </ref>, [14] that seek a setting of the weights that produces an optimal classifier, etc.) Moreover, LearnSF qualifies as a "wrapper learning system" [17], [4], as it views its "performance elements" (the individual selection functions) as black boxes, whose behavior can be sampled, but whose internals are unavailable.
Reference: [25] <author> T. M. Mitchell, R. M. Keller, and S. T. Kedar-Cabelli, </author> <title> "Example-based generalization: A unifying view," </title> <journal> Machine Learning, </journal> <volume> vol. 1, no. 1, </volume> <pages> pp. 47-80, </pages> <year> 1986. </year>
Reference-contexts: to improving the performance of a performance system on its performance task, discussed in [28] and elsewhere, is the basis for learning systems that range from standard decision tree learners like c4.5 [26] and cart [3] that seek the decision tree whose expected accuracy is maximal, through speed-up learning systems <ref> [25] </ref>, [21] that seek a set of macros that yield an optimally efficient program, to neural net learners [27], [24], [14] that seek a setting of the weights that produces an optimal classifier, etc.) Moreover, LearnSF qualifies as a "wrapper learning system" [17], [4], as it views its "performance elements" (the
Reference: [26] <author> J. R. Quinlan, C4.5: </author> <title> Programs for Machine Learning. </title> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, </address> <year> 1992. </year>
Reference-contexts: (here, whose expected error is minimal). (This learning/performance dichotomy appears in [30], and the view that learning corresponds to improving the performance of a performance system on its performance task, discussed in [28] and elsewhere, is the basis for learning systems that range from standard decision tree learners like c4.5 <ref> [26] </ref> and cart [3] that seek the decision tree whose expected accuracy is maximal, through speed-up learning systems [25], [21] that seek a set of macros that yield an optimally efficient program, to neural net learners [27], [24], [14] that seek a setting of the weights that produces an optimal classifier,
Reference: [27] <author> D. E. Rumelhart, J. L. McClelland, </author> <title> and the PDP Research Group, </title> <editor> eds., </editor> <booktitle> Parallel Distributed Processing: Explorations in the Microstructure of Cognition, </booktitle> <volume> vol. 1: </volume> <booktitle> Foundations, </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, </address> <year> 1986. </year>
Reference-contexts: the basis for learning systems that range from standard decision tree learners like c4.5 [26] and cart [3] that seek the decision tree whose expected accuracy is maximal, through speed-up learning systems [25], [21] that seek a set of macros that yield an optimally efficient program, to neural net learners <ref> [27] </ref>, [24], [14] that seek a setting of the weights that produces an optimal classifier, etc.) Moreover, LearnSF qualifies as a "wrapper learning system" [17], [4], as it views its "performance elements" (the individual selection functions) as black boxes, whose behavior can be sampled, but whose internals are unavailable.
Reference: [28] <author> H. A. Simon, </author> <title> "Why should machines learn?," in Machine Learning: An Artificial Intelligence Approach (R. </title> <editor> S. Michalski, J. G. Carbonell, and T. M. Mitchell, eds.), </editor> <address> Palo Alto, CA, </address> <publisher> Tioga Publishing Company, </publisher> <year> 1983. </year>
Reference-contexts: space of "performance elements" (here, the space of individual selection functions) seeking one whose expected "utility" is optimal (here, whose expected error is minimal). (This learning/performance dichotomy appears in [30], and the view that learning corresponds to improving the performance of a performance system on its performance task, discussed in <ref> [28] </ref> and elsewhere, is the basis for learning systems that range from standard decision tree learners like c4.5 [26] and cart [3] that seek the decision tree whose expected accuracy is maximal, through speed-up learning systems [25], [21] that seek a set of macros that yield an optimally efficient program, to
Reference: [29] <author> R. Smith and P. Cheeseman, </author> <title> "On the representation and estimation of spatial uncertainty," </title> <journal> International Journal of Robotics Research, </journal> <volume> vol. 5, no. 4, </volume> <pages> pp. 56-68, </pages> <year> 1987. </year>
Reference: [30] <author> R. G. Smith, T. M. Mitchell, R. Chestek, and B. G. Buchanan, </author> <title> "A model for learning systems," </title> <booktitle> Proceedings of IJCAI-77, </booktitle> <pages> pp. 338-343, </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1977. </year>
Reference-contexts: as it uses a set of "experiences" (each an image labeled with actual agent position, etc.) to climb in a discrete space of "performance elements" (here, the space of individual selection functions) seeking one whose expected "utility" is optimal (here, whose expected error is minimal). (This learning/performance dichotomy appears in <ref> [30] </ref>, and the view that learning corresponds to improving the performance of a performance system on its performance task, discussed in [28] and elsewhere, is the basis for learning systems that range from standard decision tree learners like c4.5 [26] and cart [3] that seek the decision tree whose expected accuracy
Reference: [31] <author> K. Sugihara, </author> <title> "Location of a robot using sparse visual information," </title> <booktitle> Robotics Research: The Fourth International Symposium (R. Bolles and B. Roth, eds.), </booktitle> <pages> pp. 319-326, </pages> <publisher> MIT Press, </publisher> <year> 1987. </year>
Reference: [32] <author> K. Sugihara, </author> <title> "Some location problems for robot navigation using a single camera," Computer Vision, </title> <journal> Graphics and Image Processing, </journal> <volume> vol. 42, no. 1, </volume> <pages> pp. 112-129, </pages> <year> 1988. </year>
Reference: [33] <author> B. Yamauchi and R. Beer, </author> <title> "Spatial learning for navigation in dynamic environment," </title> <note> this issue. </note>
References-found: 33

