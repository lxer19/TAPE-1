URL: http://simon.cs.cornell.edu/home/selman/papers-ftp/horn-rel.ps
Refering-URL: http://simon.cs.cornell.edu/home/selman/papers-ftp/index.html
Root-URL: 
Email: email: fkautz, mkearns, selmang@research.att.com  
Title: Horn Approximations of Empirical Data  
Author: Henry Kautz, Michael Kearns, and Bart Selman 
Address: Murray Hill, NJ 07974  
Affiliation: AI Principles Research Dept., AT&T Bell Laboratories,  
Abstract: Formal AI systems traditionally represent knowledge using logical formulas. Some- times, however, a model-based representation is more compact and enables faster reasoning than the corresponding formula-based representation. The central idea behind our work is to represent a large set of models by a subset of characteristic models. More specifically, we examine model-based representations of Horn theories, and show that there are large Horn theories that can be exactly represented by an exponentially smaller set of characteristic models. We show that deduction based on a set of characteristic models requires only polynomial time, as it does using Horn theories. More surprisingly, abduction can be performed in polynomial time using a set of characteristic models, whereas abduction using Horn theories is NP-complete. Finally, we discuss algorithms for generating efficient representations of the Horn theory that best approximates a general set of models. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. Angluin, M. Frazier, and L. Pitt, </author> <title> Learning conjunctions of Horn clauses, </title> <booktitle> in: Proceedings 31st Annual Symposium on Foundations of Computer Science, </booktitle> <address> St. Louis, </address> <publisher> MI (IEEE Computer Society Press, </publisher> <address> Los Almamitos, CA, </address> <year> 1990) </year> <month> 186-192. </month>
Reference-contexts: See Fig. 3. Our algorithm is based on an algorithm for learning Horn theories from examples (i.e., models) by Angluin et al. <ref> [1] </ref>. Angluin et al.'s algorithm is quite involved, and we refer the reader to their paper for the details. The algorithm employs a membership oracle and an equivalence oracle to construct a formula that is logically equivalent to the unknown Horn formula that is to be learned.
Reference: [2] <author> C. Beeri, M. Dowd, R. Fagin, and R. Statman, </author> <title> On the structure of Armstrong relations for functional dependencies, </title> <journal> J. </journal> <note> ACM 31(1) (1984) 30-46. </note>
Reference: [3] <author> T. Bylander, D. Allemang, M.C. Tanner, and J.R. Josephson, </author> <title> Some results concerning the computational complexity of abduction, </title> <booktitle> in: Proceedings KR-89 , Toronto, </booktitle> <address> Ontario (1989) 44-54. </address>
Reference: [4] <author> R. Dechter and A. Itai, </author> <title> The complexity of finding all solutions, </title> <type> UCI Technical Report 92-61, </type> <institution> University of California at Irvine, </institution> <address> Irvine, CA (1991). </address>
Reference: [5] <author> R. Dechter and J. Pearl, </author> <title> Structure identification in relational data, </title> <booktitle> Artif. Intell. </booktitle> <month> 58 </month> <year> (1992) </year> <month> 237-270. </month>
Reference-contexts: The final part of this paper examines the problem of converting a set of models into an efficient representation. This general task can be viewed as identifying meaningful, computationally-attractive structures in a set of empirical data, where each model represents a data point <ref> [5] </ref>. As such structure identification is a way of formalizing (some kinds of) scientific discovery, where a representation is judged to be good if it compactly represents the data and can be reasoned with easily. <p> We consider the specific problem of converting a set of models into either a set of characteristic models or a set of Horn clauses. Previously, Dechter and Pearl <ref> [5] </ref> have shown that it is easy to check when an exact translation is possible, and that in that case both kinds of representations can be generated in polynomial time. Some sets of models, however, can only be approximated by such representations. <p> The closure of this set is given by M 0 0 = M 0 [ f [0100]; [0000]g. See Fig. 1. The notion of closure is particularly relevant in the context of Horn theories, 4 due to the following theorem. Theorem 2 (McKinsey 1943 [18], Dechter and Pearl 1992 <ref> [5] </ref>) A theory is equivalent to a Horn theory if and only if models () is closed under intersection. The original proof by McKinsey is for first-order equational theories, and in fact led to the original definition of Horn clauses [9]. A direct proof for the propositional case appears in [5]. <p> <ref> [5] </ref>) A theory is equivalent to a Horn theory if and only if models () is closed under intersection. The original proof by McKinsey is for first-order equational theories, and in fact led to the original definition of Horn clauses [9]. A direct proof for the propositional case appears in [5]. Thus there is a direct correspondence between Horn theories and sets of models that are closed under intersection. For example, consider the closure M 0 0 of the models in set M 0 defined above. <p> Characteristic models are called "extreme" models in <ref> [5] </ref>. The proofs in this paper all depend upon the assumption that we are dealing with finite sets of models: certain infinite sets of models (over an infinite number of variables) may have no characteristic elements. <p> Ob- viously, it is as least as large as the set of characteristic models, and often much larger. Furthermore, every Horn theory with K models over n variables can be represented using at most Kn 2 Horn clauses <ref> [5] </ref>. Thus up to a small polynomial factor, the complete set of models is also always at least as large as the clausal representation. Neither of the other two representations strictly dominates the other. <p> The characteristic models in a closed set can be efficiently found by selecting each model which is not equal to the intersection of any two models in the set. The clausal theory can be found using the algorithms described in <ref> [5] </ref> and [11]. We will return to the problem of generating efficient representations in Section 6 below. 4 Deduction using Characteristic Models One of the most appealing features of Horn theories is that they allow for fast inference. In the propositional case, queries can be answered in polynomial time [6]. <p> The complexity of this procedure is O ((njM j) 2 ). More interestingly, Dechter and Pearl <ref> [5] </ref> show that if a set of input models M does correspond to a Horn theory, then this theory can be represented using at most n 2 jM j clauses, and the clauses can be generated in polynomial time. <p> Therefore let us consider the problem of generating a clausal representation of the Horn approximation of a set of models. It follows from Theorem 6 that the clausal representation of the Horn approximation of M can be exponentially large. Dechter and Pearl <ref> [5] </ref> therefore investigated k-Horn approximations. The maximum size of a k-Horn approximation is given by the maximum number of distinct Horn clauses with at most k literals, which is polynomial in n. Dechter and Pearl give a polynomial time algorithm for generating such k-Horn approximation. <p> There is a randomized algorithm that takes as input both M and small real numbers * and ffi (where 0 &lt; *; ffi 1), and outputs a Horn theory ^ such that with probability 1 ffi, closure (M ) = models () models ( ^ ) 4 Dechter and Pearl <ref> [5] </ref> observe that when the closure of the input set M is reasonably small (jclosure (M )j=jM j is bounded by some constant), general Horn approximations can also be computed by simply generating the complete closure and then directly applying the algorithm for the exact case.
Reference: [6] <author> W.F. Dowling and J.H. Gallier, </author> <title> Linear time algorithms for testing the satisfiability of propositional Horn formula, </title> <note> Journal of Logic Programming 3 (1984) 267-284. </note>
Reference-contexts: Both the characteristic model and clausal representations are strictly better than a simple enumeration of all models. 2 Next, we consider the complexity of reasoning with sets of characteristic models. Deduction based on a set of characteristic models takes only polynomial time, as it does using Horn theories <ref> [6] </ref>. More surprisingly, abduction can be performed in polynomial time using a set of characteristic models, whereas abduction using Horn theories is NP-complete [23]. This result is particularly interesting because very few other tractable classes of abduction problems are known [3,8,24]. <p> We will return to the problem of generating efficient representations in Section 6 below. 4 Deduction using Characteristic Models One of the most appealing features of Horn theories is that they allow for fast inference. In the propositional case, queries can be answered in polynomial time <ref> [6] </ref>. However, there is no a priori reason why a representation based on characteristic models would also enable fast inference. Nevertheless, in this section, we show that there is indeed a polynomial-time algorithm for deduction using characteristic models.
Reference: [7] <author> T. Eiter and G. Gottlob, </author> <title> Identifying the minimal traversals of hypergraph and related problems, </title> <note> preprint (1991). </note>
Reference-contexts: Unfortunately, as of yet, no efficient algorithm for generating characteristic models has been found. Kavvadias et al. [10] have recently shown that the problem is at least as hard as the so-called hypergraph enumeration problem, which is a well-known open problem <ref> [7] </ref>. We will therefore use a random sampling strategy to search for a possible counterexample for the overgeneralization 0 .
Reference: [8] <author> K. Eshghi, </author> <title> A tractable class of abduction problems, </title> <booktitle> in: Proceedings IJCAI-93 , Chambery, </booktitle> <address> France (1993) 3-8. </address>
Reference: [9] <author> A. Horn, </author> <title> On sentences which are true of direct unions of algebras, </title> <note> Journal of Symbolic Logic 16 (1951) 14-21. </note>
Reference-contexts: Theorem 2 (McKinsey 1943 [18], Dechter and Pearl 1992 [5]) A theory is equivalent to a Horn theory if and only if models () is closed under intersection. The original proof by McKinsey is for first-order equational theories, and in fact led to the original definition of Horn clauses <ref> [9] </ref>. A direct proof for the propositional case appears in [5]. Thus there is a direct correspondence between Horn theories and sets of models that are closed under intersection. For example, consider the closure M 0 0 of the models in set M 0 defined above.
Reference: [10] <author> D. Kavvadias, C. Papadimitriou, and M. Sideri, </author> <title> On Horn envelopes and hypergraph traversals, </title> <booktitle> Proceedings Fourth Annual International Symposium on Algorithms and Computation (ISAAC-93), </booktitle> <address> Hong Kong (1993). </address>
Reference-contexts: The set M of characteristic models of this theory contains all the models where each of the variables in each consecutive pair, such as (a; b), (c; d), (e; f ), etc., are assigned opposite truth values (i.e., either [01] or <ref> [10] </ref>). So, we get the models [010101 : : :], [100101 : : :], [011001 : : :], : : :, [101010 : : :]. There are 2 (n=2) of such such models, where n is the number of variables. <p> As soon as we encounter characteristic model that is not in M , we know that 0 contains strictly more models than closure (M ). Unfortunately, as of yet, no efficient algorithm for generating characteristic models has been found. Kavvadias et al. <ref> [10] </ref> have recently shown that the problem is at least as hard as the so-called hypergraph enumeration problem, which is a well-known open problem [7]. We will therefore use a random sampling strategy to search for a possible counterexample for the overgeneralization 0 .
Reference: [11] <author> H. Kautz, M. Kearns, and B. Selman, </author> <title> Reasoning with characteristic models, </title> <booktitle> Proceedings AAAI-93 , Washington, </booktitle> <address> DC (1993) 34-39. </address>
Reference-contexts: The characteristic models in a closed set can be efficiently found by selecting each model which is not equal to the intersection of any two models in the set. The clausal theory can be found using the algorithms described in [5] and <ref> [11] </ref>. We will return to the problem of generating efficient representations in Section 6 below. 4 Deduction using Characteristic Models One of the most appealing features of Horn theories is that they allow for fast inference. In the propositional case, queries can be answered in polynomial time [6].
Reference: [12] <author> R. Khardon and D. Roth, </author> <title> Reasoning with models, </title> <type> Tech. Report TR-1-94, </type> <institution> Center for Research in Computing Technologies, Harvard University, </institution> <address> Boston, MA (1994). </address> <note> A short version appears in: Proceedings AAAI-94, </note> <institution> Seattle, </institution> <address> WA (1994) 1148-1153. </address>
Reference-contexts: Specifically, the number of characteristic models of a Horn theory is bounded by the size of the minimal DNF representation times the number of variables; on the other hand, the minimal DNF may be exponentially larger than the number of characteristic models <ref> [12] </ref>. 7 ff in 0 , it is the case that j= ff. Because no clauses in resolve, this means that there exists an ff 0 in such that ff 0 subsumes ff. That is, every clause in 0 is subsumed by some clause in . <p> We showed that for Horn theories neither the formula nor the model-based representation dominates the other in terms of size, and that sometimes one other can offer an exponential savings over the other. Recently, Khardon and Roth <ref> [12] </ref> have introduced an interesting generalization of our model-based representation, and have shown a clear computational advantage of the use of their model-based representation by combining various learning and reasoning tasks in a single framework [13].
Reference: [13] <author> R. Khardon and D. Roth, </author> <title> Learning to reason, </title> <booktitle> in: Proceedings AAAI-94 , Seattle, </booktitle> <address> WA (1994) 682-687. </address>
Reference-contexts: Recently, Khardon and Roth [12] have introduced an interesting generalization of our model-based representation, and have shown a clear computational advantage of the use of their model-based representation by combining various learning and reasoning tasks in a single framework <ref> [13] </ref>. We also showed that the characteristic model representation of Horn theories has very good computational properties, in that both deduction and abduction can be performed in polynomial time. On the other hand, all known and foreseeable algorithms for abduction with Horn clauses are of worst-case exponential complexity.
Reference: [14] <author> J.L. </author> <title> Kolodner, </title> <publisher> Case-Based Reasoning (Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1993). </year>
Reference-contexts: An example of the reaction against the traditional approach is the growing body of research and applications using case-based reasoning (CBR) <ref> [14] </ref>.
Reference: [15] <author> R.C.T. Lee, </author> <title> A completeness theorem and a computer program for finding theorems derivable from given axioms, </title> <type> PhD thesis, </type> <institution> University of California at Berkeley, Berkeley, </institution> <address> CA (1967). </address> <month> 20 </month>
Reference-contexts: Lemma 9 Let H be a Horn theory and C a clause that is not a tautology. If H j= C then there is a clause C H that is a Horn-strengthening of C such that H j= C H . 2 Proof. By the subsumption theorem <ref> [15] </ref>, there is a clause C 0 that follows from H by resolution such that C 0 subsumes C. Because the resolvent of Horn clauses is Horn, C 0 is Horn.
Reference: [16] <author> H. Manilla and K.J. and Raiha, </author> <title> Design of Relational Databases (Addison-Wesley, </title> <address> Reading, MA, </address> <year> 1992). </year>
Reference: [17] <author> J. McCarthy and P.J. Hayes, </author> <title> Some philosophical problems from the standpoint of artificial intelligence, </title> <editor> in: D. Michie, ed., </editor> <booktitle> Machine Intelligence 4 (Ellis Horwood, </booktitle> <address> Chichester, England 1969) 463-502. </address>
Reference-contexts: 1 Introduction Logical formulas are the traditional means of representing knowledge in formal AI systems <ref> [17] </ref>. The information implicit in a set of logical formulas can also be captured by expliciting recording the set of models (truth assignments) that satisfy the formulas.
Reference: [18] <author> J.C.C. McKinsey, </author> <title> The decision problem for some classes of sentences without quantifiers, </title> <note> Journal of Symbolic Logic 8 (3) (1943) 61-77. </note>
Reference-contexts: The closure of this set is given by M 0 0 = M 0 [ f [0100]; [0000]g. See Fig. 1. The notion of closure is particularly relevant in the context of Horn theories, 4 due to the following theorem. Theorem 2 (McKinsey 1943 <ref> [18] </ref>, Dechter and Pearl 1992 [5]) A theory is equivalent to a Horn theory if and only if models () is closed under intersection. The original proof by McKinsey is for first-order equational theories, and in fact led to the original definition of Horn clauses [9].
Reference: [19] <institution> C.S. Peirce, Collected Papers of Charles Sanders Peirce (Harvard University Press, </institution> <address> Cambridge, MA 1958). </address>
Reference-contexts: It is possible to determine if j= ff in time O (njM jjffj 2 ), where n is number of variables. 5 Abduction using Characteristic Models Another central reasoning task for intelligent systems is abduction, or inference to the best explanation <ref> [19] </ref>. In an abduction problem, one tries to explain an observation by selecting a set of assumptions that, together with other background knowledge, logically entails the observation. This kind of reasoning is central to many systems that perform diagnosis or interpretation, such as the ATMS.
Reference: [20] <author> R. Reiter and J. de Kleer, </author> <title> Foundations of assumption based truth maintenance systems: preliminary report, </title> <booktitle> in: Proceedings AAAI-87 , Seattle, </booktitle> <address> WA (1987) 183188. </address>
Reference-contexts: This kind of reasoning is central to many systems that perform diagnosis or interpretation, such as the ATMS. The notion of an explanation can be formally defined as follows <ref> [20] </ref>: Definition 12 [Explanation] Given a set of clauses , called the background theory, a subset A of the propositional letters, called the assumption set, and a query letter q, an explanation E for q is a minimal subset of unit clauses with letters from among A such that 1. [
Reference: [21] <author> B. Selman and H. Kautz, </author> <title> Knowledge compilation using Horn approximations, </title> <booktitle> in: Proceedings AAAI-91, </booktitle> <address> Anaheim, CA (1991) 904-909. </address>
Reference: [22] <author> B. Selman and H. Kautz, </author> <title> Knowledge compilation and theory approximation J. </title> <publisher> ACM , in press. </publisher>
Reference: [23] <author> B. Selman and H.J. Levesque, </author> <title> Abductive and default reasoning: a computational core, </title> <booktitle> in: Proceedings AAAI-90 , Boston, </booktitle> <address> MA (1990) 343-348. </address>
Reference-contexts: Deduction based on a set of characteristic models takes only polynomial time, as it does using Horn theories [6]. More surprisingly, abduction can be performed in polynomial time using a set of characteristic models, whereas abduction using Horn theories is NP-complete <ref> [23] </ref>. This result is particularly interesting because very few other tractable classes of abduction problems are known [3,8,24]. The final part of this paper examines the problem of converting a set of models into an efficient representation. <p> However, abduction can remain hard even when the background theory is restricted to languages in which both tests can be performed in polynomial time. Selman and Levesque <ref> [23] </ref> show that computing such an explanation is NP-complete even when the background theory contains only Horn clauses, despite the fact that the tests take only linear time for such theories.
Reference: [24] <author> B. Selman and H.J. Levesque, </author> <title> Support set selection for abductive and default reasoning, </title> <booktitle> Artif. Intell., </booktitle> <publisher> in press. </publisher> <pages> 21 </pages>
References-found: 24

