URL: http://www.cs.unc.edu/Research/mi/ftp/tutorial.ps
Refering-URL: http://www.cs.unc.edu/Research/mi/mi-publications.html
Root-URL: http://www.cs.unc.edu
Email: e-mail: plaisted@cs.unc.edu  
Title: The Use of Semantics in Instance-Based Proof Procedures  
Author: David A. Plaisted and 
Address: Chapel Hill, NC 27599-3175  Im Stadtwald  675 Kaiserslautern  
Affiliation: Department of Computer Science University of North Carolina at Chapel Hill  MPI fuer Informatik  and Universitaet Kaiserslautern Fachbereich Informatik  
Pubnum: D-66123 Saarbruecken  
Abstract: We survey our past work in theorem proving, leading up to the semantic hyper-linking method, and clause linking with semantics. We highlight some basic problems in automated deduction, and show that significant progress has been made. We present our belief that these problems are about to be solved completely. We present some strategies that we believe will accomplish this. 
Abstract-found: 1
Intro-found: 1
Reference: [AP92] <author> G. Alexander and D. Plaisted. </author> <title> Proving equality theorems with hyper-linking. </title> <booktitle> In Proceedings of the 11th International Conference on Automated Deduction, </booktitle> <pages> pages 706-710, </pages> <year> 1992. </year> <title> system abstract. </title>
Reference-contexts: Then the time bound is increased, and all the problems are tried again. Whenever a problem is proved, it is removed from further testing. 3.5 Equality We tried to incorporate equality, using something like Brand's modification method [Bra75] and term-rewriting together. A brief description is in <ref> [AP92] </ref>. However, we had trouble getting a good equality implementation. This could be because hyper-linking corresponds to performing several paramodulations at once, which may be too large a granularity. <p> However, this approach also has an overhead, since paramodulation is simulated by unification. In addition, some method of term-rewriting still needs to be added, for efficiency. This approach was implemented in clause linking <ref> [AP92] </ref>, but the results were somewhat weak. Possibly the reason is that hyper-linking essentially simulates several paramodulations at once (since several unifications are done at once) and this is too big an inference step for paramodulation. Also, the fact that CLIN performs breadth first search may handicap its performance.
Reference: [BGLS91] <author> L. Bachmair, H. Ganzinger, C. Lynch, and W. Snyder. </author> <title> Basic paramodula-tion and basic strict superposition. </title> <note> submitted, </note> <year> 1991. </year>
Reference-contexts: Such a transformation is given in [Bra75], for example. This method is simple and effective and eliminates some of the redundancies in paramodulation-based methods; in some ways it yields some of the advantages of basic paramodulation <ref> [BGLS91] </ref>. However, this approach also has an overhead, since paramodulation is simulated by unification. In addition, some method of term-rewriting still needs to be added, for efficiency. This approach was implemented in clause linking [AP92], but the results were somewhat weak.
Reference: [Bra75] <author> D. Brand. </author> <title> Proving theorems with the modification method. </title> <journal> SIAM J. Com-put., </journal> <volume> 4 </volume> <pages> 412-430, </pages> <year> 1975. </year>
Reference-contexts: However, we found that this prover had trouble with some problems that should have been simple, and I felt that a better way to do back chaining was needed. As for other issues, equality was handled using an equality reprsentation much like that of Brand <ref> [Bra75] </ref>, together with some ideas inspired by term-rewriting based theorem provers. However, the prover was not designed primarily to be fast on pure equality problems. This prover also had (syntactic) abstraction [Pla81, GW92] built into it. It even had a search strategy based on a sequence of abstractions. <p> Then the time bound is increased, and all the problems are tried again. Whenever a problem is proved, it is removed from further testing. 3.5 Equality We tried to incorporate equality, using something like Brand's modification method <ref> [Bra75] </ref> and term-rewriting together. A brief description is in [AP92]. However, we had trouble getting a good equality implementation. This could be because hyper-linking corresponds to performing several paramodulations at once, which may be too large a granularity. <p> One technique that we often employed was to transform the clauses in such a way that all the equality axioms except for fx = xg and possibly the symmetry axiom, can be dispensed with. Such a transformation is given in <ref> [Bra75] </ref>, for example. This method is simple and effective and eliminates some of the redundancies in paramodulation-based methods; in some ways it yields some of the advantages of basic paramodulation [BGLS91]. However, this approach also has an overhead, since paramodulation is simulated by unification.
Reference: [CP94] <author> Heng Chu and D. Plaisted. </author> <title> Semantically guided first-order theorem proving using hyper-linking. </title> <booktitle> In Proceedings of the Twelfth International Conference on Automated Deduction, </booktitle> <pages> pages 192-206, </pages> <year> 1994. </year> <booktitle> Lecture Notes in Artificial Intelligence 814. </booktitle>
Reference-contexts: We feel in general that such issues as these are not as well appreciated by the general theorem proving community as they should be, but that they must be dealt with if we are to obtain more powerful provers. 5 Clause Linking with Semantics Clause linking with semantics <ref> [CP94] </ref> is an attempt to combine the philosophy of clause linking with the idea of a persistent search for a counterexample. In clause linking, it is the ground instantiation part of the method which is in control. After each phase of instantiation, a propositional satisfiability procedure is applied. <p> The prover is complete regardless of the initial semantics given to it, but it can be more powerful with a careful choice of semantics, as we showed in <ref> [CP94] </ref>. <p> Furthermore, the definition of rough resolution seems somewhat arbitrary, although it works well in practice. A good description of the working of this prover is found in <ref> [CP94] </ref>, as well as a comparison with some other provers on some hard problems. <p> We note that some of these complexity issues were addressed already in [Pla82]. A further evidence for the search inefficiencies of resolution and other common strategies is the superior performance of CLIN-S on some problems, as mentioned in <ref> [CP94] </ref> and confirmed by our tests of this prover on other examples as well. We note that term-rewriting based theorem provers also have severe combinatorial inefficiencies in general, as shown in [Pla94c]. Term-rewriting techniques correspond to A-resolution, in their extension to first-order theorem proving methods.
Reference: [DP60] <author> M. Davis and H. Putnam. </author> <title> A computing procedure for quantification theory. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 7 </volume> <pages> 201-215, </pages> <year> 1960. </year>
Reference-contexts: This led to a change back to the relevance prover philosophy of instantiating the input clauses and then applying an efficient propositional decision procedure such as Davis and Putnam's method <ref> [DP60] </ref>. Note that the modified problem reduction format and the simplified problem reduction format are the same on pure Horn clauses. The modified problem reduction format prover "sprfn" had a combination of forward and backward chaining that considerably augmented its power. <p> In this way we obtain a sequence S, HL (S), HL (HL (S)) : : : of instances of sets of clauses; a propositional satisfiability test similar to Davis and Putnam's method <ref> [DP60] </ref> is applied to each such set of instances. Let Gr (S) be the set S of clauses with all variables replaced by the same constant symbol. Note that distinct variables are replaced by the same constant symbol.
Reference: [GHL63] <author> H. Gelernter, J.R. Hansen, and D.W. Loveland. </author> <title> Empirical explorations of the geometry theorem proving machine. </title> <editor> In E. Feigenbaum and J. Feldman, editors, </editor> <booktitle> Computers and Thought, </booktitle> <pages> pages 153-167. </pages> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <year> 1963. </year>
Reference-contexts: This "sprf" strategy can be extended to include some notion of semantics deletion, although we did not do this. By semantics deletion we mean the recognition that subgoals that are false in a certain interpretation cannot succeed, somewhat in the spirit of the geometry theorem prover of <ref> [GHL63] </ref>. The simplified problem reduction format prover applies also to non-Horn clauses, but its search mechanism for non-Horn clauses is not well controlled because of a case-analysis rule that is hard to control. We did implement this prover, but did not obtain good results for some reason.
Reference: [GW92] <author> F. Giunchiglia and T. Walsh. </author> <title> A theory of abstraction. </title> <journal> Artificial Intelligence, </journal> <note> 1992. to appear. </note>
Reference-contexts: As for other issues, equality was handled using an equality reprsentation much like that of Brand [Bra75], together with some ideas inspired by term-rewriting based theorem provers. However, the prover was not designed primarily to be fast on pure equality problems. This prover also had (syntactic) abstraction <ref> [Pla81, GW92] </ref> built into it. It even had a search strategy based on a sequence of abstractions.
Reference: [JP84] <author> S. Jefferson and D. Plaisted. </author> <title> Implementation of an improved relevance criterion. </title> <booktitle> In First Conference on Artificial Intelligence Applications, </booktitle> <pages> pages 476-482, </pages> <year> 1984. </year>
Reference-contexts: In such a case, we want to avoid just combining axioms. One of the precursors of the Herbrand-based provers discussed in the CADE tutorial was the relevance prover implemented by Stanley Jefferson <ref> [JP84] </ref>. This was based on an earlier article about the same idea [Pla80].
Reference: [KN92] <author> D. Kapur and P. Narendran. </author> <title> Double-exponential complexity of computing a complete set of ac-unifiers. </title> <booktitle> In Proceedings 7th IEEE Symposium on Logic in Computer Science, </booktitle> <pages> pages 11-21, </pages> <address> Santa Cruz, California, </address> <year> 1992. </year>
Reference-contexts: However, perhaps there are more efficient implementation techniques that could solve this problem. Possibly the polynomial constraint methods of [Pla93] would help. Of course, specialized unification algorithms for specific equational theoris are another possibility, too, although this can lead to a large number of unifiers as for AC-unification <ref> [KN92] </ref>. 8 Basic Problems in the Field As the reader can see, we have developed quite a sequence of provers (7 or 8 in all), and they have become successively more powerful, in general.
Reference: [LP92] <author> S.-J. Lee and D. Plaisted. </author> <title> Eliminating duplication with the hyper-linking strategy. </title> <journal> Journal of Automated Reasoning, </journal> <volume> 9(1) </volume> <pages> 25-42, </pages> <year> 1992. </year>
Reference-contexts: This prover is quite compact in Prolog and in its initial implementation only about 36,000 bytes long. It had some mechanism for equality and term-rewriting, but this equality mechanism was fairly weak. 3 Clause Linking The clause linking prover CLIN implemented by Shie-Jue Lee <ref> [LP92] </ref> was an attempt to remove the propositional inefficiencies from resolution. As noted above, I had decided that Horn clause subgoaling was not essential to general theorem proving, and that propositional efficiency was a more important issue in general. <p> Also, we assume that this constant symbol does not occur in S. For example, Gr (ff:(Q (x; y)); P (x; y)g; fQ (a; z)gg) is ff:(Q (c; c)); P (c; c)g; fQ (a; c)gg if this global constant is c. We can then show <ref> [LP92] </ref> that S is unsatisfiable iff for some i, Gr (HL i (S)) is propositionally unsatisfiable. Thus we have completeness of the method. This strategy works fairly well. <p> We feel that this strategy has considerable potential, especially if it is implemented well in some language like C with good data structures. (The current implementation is in Prolog.) In <ref> [LP92] </ref> we showed that on near-propositional, highly non-Horn problems, clause linking has a distinct advantage over resolution-based approaches. The CLIN prover has a number of support strategies, simulating forward reasoning, backward reasoning, UR-resolution, and set-of-support, the latter giving it goal-sensitivity. <p> We base this thesis on a number of evidences. One of these evidences is the results from <ref> [LP92] </ref> showing the superiority of clause linking to resolution on certain problems. It appears that resolution has such severe inefficiencies on highly non-Horn problems as to severely limit its effectiveness there. Of course, Davis and Putnam's method can be implemented much better than we did in [LP92], but even our implementation <p> is the results from <ref> [LP92] </ref> showing the superiority of clause linking to resolution on certain problems. It appears that resolution has such severe inefficiencies on highly non-Horn problems as to severely limit its effectiveness there. Of course, Davis and Putnam's method can be implemented much better than we did in [LP92], but even our implementation shows a great advantage over resolution. We compared clause linking to Otter and other provers; Otter has been significantly improved since then, using ordered hyper-linking for example, and possibly in other ways as well. But clause linking can still solve more of the problems. <p> The completeness proof is along the lines of the proofs of completeness of forward, backward, and user support in <ref> [LP92] </ref>. We now comment on the complexity of this procedure. If S is unsatisfiable, then there is an unsatisfiable set S 0 of ground instances of clauses in S, by Herbrand's theorem. Let n be the maximum of jjCjj for any clause C in S 0 . <p> Therefore all clauses in T are I-relevant in T . If all the needed clauses in S are I-relevant, then there is a hyper-link operation that makes progress towards the proof, along the lines of the completeness proof in <ref> [LP92] </ref>. Otherwise, there must be some clause C in S that is needed for the proof such that C is not I-relevant, but one of its ground instances D is I-relevant in T . <p> Therefore, we will eventually obtain a set S such that Gr (S) is unsatisfiable. The remaining details of this argument can be filled in along the lines of the completeness proof in <ref> [LP92] </ref>. We now give a second refinement to hyper-linking. Define a partial interpretation to be a partial assignment of truth values to atoms. Then I j= L iff I assigns true to L, and I j= :L iff I assigns false to L. <p> This restriction of hyper-linking is also complete, as can be seen by examining the completeness proof in <ref> [LP92] </ref>. However, at present we do not have much of an intuition for the usefulness of this restriction. 9.3 Ordered Clause Linking with Semantics We also plan to extend CLIN-S to make it more consistent.
Reference: [LP94] <author> S.-J. Lee and D. Plaisted. </author> <title> Use of replace rules in theorem proving. </title> <booktitle> Methods of Logic in Computer Science, </booktitle> <volume> 1 </volume> <pages> 217-240, </pages> <year> 1994. </year>
Reference-contexts: That paper examined the technique of replacing predicates by their definitions. Next, in the paper [PP91], we applied them to some problems in set theory in the modified problem reduction format, obtaining proofs with very little guidance. We also did some work with replacement rules in CLIN <ref> [LP94] </ref>, obtaining proofs in set theory and temporal logic. Replacement rules were also incorporated in CLIN-S, but in a way that requires less user guidance than previously. All the previous realizations required some user guidance, but that in CLIN-S is completely automatic.
Reference: [McC89] <author> W. W. McCune. </author> <title> Otter 1.0 Users' Guide. </title> <institution> Mathematics and Computer Science Division, Aggonne National Laboratory, Argonne, Illinois, </institution> <month> January </month> <year> 1989. </year>
Reference-contexts: This gives better control of the search than the method of always picking the smallest clause and resolving it with everything else, which is used by Otter <ref> [McC89] </ref>. But there is a cost in the size of the data structure. This prover was able to prove the so-called Schubert Steamroller problem, which is not really very hard, quite fast. It was also good on a wide variety of problems with little guidance.
Reference: [PACL92] <author> D. Plaisted, G. Alexander, Heng Chu, and S.-J. Lee. </author> <title> Conditional term rewriting and first-order theorem proving. </title> <booktitle> In Proceedings of the Third International Workshop on Conditional Term-Rewriting Systems, </booktitle> <pages> pages 257-271, </pages> <month> July 8 - 10 </month> <year> 1992. </year> <type> Invited talk. </type>
Reference-contexts: One of the best general descriptions of this prover and the techniques used is in the article [PL90], from which some material here is drawn. Another useful general discussion is in the talk <ref> [PACL92] </ref>. 3.1 Saving Instances One drawback of the clause linking strategy is that it is necessary to save instances of other clauses that are saved. Thus one cannot do subsumption deletion, which is a common feature in resolution theorem provers. <p> These ground instances are then accumulated and tested for satisfiability. Thus the search for a model becomes more explicit in this prover. A proof of completeness is given in <ref> [PACL92] </ref>. This completeness proof requires that some complexity ordering on ground instances be used, and that the instances D chosen in the following algorithm be minimal in this ordering. <p> It should avoid the (propositional) search inefficiencies of resolution and similar strategies 2. It should be goal-sensitive. 3. It should incorporate unification 4. It should permit the use of meaningful (natural) semantics These criteria (except for 3.) were also mentioned in the paper <ref> [PACL92] </ref>. First we discuss the search efficiency issue. We feel that the inefficiencies of resolution and other similar strategies are severely retarding the progress of theorem proving, in the sense of unguided search, and are partly responsible for the switch to systems featuring intensive user-interaction.
Reference: [PG86] <author> D. Plaisted and S. Greenbaum. </author> <title> A structure-preserving clause form translation. </title> <journal> Journal of Symbolic Computation, </journal> <volume> 2 </volume> <pages> 293-304, </pages> <year> 1986. </year>
Reference-contexts: This has the advantage that it avoids the issue of whether formulae should be replaced by their definitions or not. In some cases, just replacing A by B can make the proof much harder to obtain. Replacement rules have a substantial history in our work, beginning with the paper <ref> [PG86] </ref> concerning set theory and resolution. That paper examined the technique of replacing predicates by their definitions. Next, in the paper [PP91], we applied them to some problems in set theory in the modified problem reduction format, obtaining proofs with very little guidance.
Reference: [PL90] <author> D. Plaisted and S.-J. Lee. </author> <title> Inference by clause matching. </title> <editor> In Z. Ras and M. Zemankova, editors, </editor> <booktitle> Intelligent Systems: State of the Art and Future Directions, </booktitle> <pages> pages 200-235. </pages> <publisher> Ellis Horwood, </publisher> <address> West Sussex, </address> <year> 1990. </year>
Reference-contexts: The combination of support strategies, hyper-linking (linking all literals at once), and special rules for unit clauses seems to have made the difference. One of the best general descriptions of this prover and the techniques used is in the article <ref> [PL90] </ref>, from which some material here is drawn. Another useful general discussion is in the talk [PACL92]. 3.1 Saving Instances One drawback of the clause linking strategy is that it is necessary to save instances of other clauses that are saved. <p> There are a number of efficiencies that can be built into the search for small proofs, such as noting when certain literals are ground literals so that backtracking can be avoided. For some more details, see <ref> [PL90] </ref>. 3.4 Top-Level Supervisor The prover CLIN also has a supervisor available that permits it to be used without any guidance. This supervisor tries a number of strategies in a reasonable sequence, and is also somewhat dependent on the form of the input.
Reference: [Pla76] <author> D. Plaisted. </author> <title> Theorem Proving and Semantic Trees. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <year> 1976. </year>
Reference: [Pla80] <author> D. Plaisted. </author> <title> An efficient relevance criterion for mechanical theorem proving. </title> <booktitle> In Proceedings of the First Annual National Conference on Artificial Intelligence, </booktitle> <pages> pages 79-83, </pages> <year> 1980. </year>
Reference-contexts: In such a case, we want to avoid just combining axioms. One of the precursors of the Herbrand-based provers discussed in the CADE tutorial was the relevance prover implemented by Stanley Jefferson [JP84]. This was based on an earlier article about the same idea <ref> [Pla80] </ref>. The idea was to consider connections between clauses as analogous to associations between facts in human thought, and to find a set of clauses that are highly connected in a certain way; then one can use these connections to instantiate the clauses, and then apply a propositional decision procedure.
Reference: [Pla81] <author> D. Plaisted. </author> <title> Theorem proving with abstraction. </title> <journal> Artificial Intelligence, </journal> <volume> 16 </volume> <pages> 47-108, </pages> <year> 1981. </year>
Reference-contexts: As for other issues, equality was handled using an equality reprsentation much like that of Brand [Bra75], together with some ideas inspired by term-rewriting based theorem provers. However, the prover was not designed primarily to be fast on pure equality problems. This prover also had (syntactic) abstraction <ref> [Pla81, GW92] </ref> built into it. It even had a search strategy based on a sequence of abstractions.
Reference: [Pla82] <author> D. Plaisted. </author> <title> A simplified problem reduction format. </title> <journal> Artificial Intelligence, </journal> <volume> 18 </volume> <pages> 227-261, </pages> <year> 1982. </year>
Reference-contexts: I then wanted to develop this into a general first-order theorem prover based on unification, but this was not to be until Shie-Jue's clause linking theorem prover implementation. The simplified problem reduction format of <ref> [Pla82] </ref> was an attempt to improve on the SL-resolution idea by performing back chaining in a more efficient manner, and was seen as an extension of Prolog's search strategy to full-first order logic, with caching incorporated. It is a goal-oriented strategy that avoids repeated work for Horn clauses. <p> There, we show that only a small number of strategies are both goal-sensitive and propositionally efficient. We note that some of these complexity issues were addressed already in <ref> [Pla82] </ref>. A further evidence for the search inefficiencies of resolution and other common strategies is the superior performance of CLIN-S on some problems, as mentioned in [CP94] and confirmed by our tests of this prover on other examples as well.
Reference: [Pla88] <author> D. Plaisted. </author> <title> Non-Horn clause logic programming without contrapositives. </title> <journal> Journal of Automated Reasoning, </journal> <volume> 4 </volume> <pages> 287-325, </pages> <year> 1988. </year>
Reference-contexts: We did implement this prover, but did not obtain good results for some reason. Still, such a prover can be quite efficient for Horn clause problems. The modified problem reduction format <ref> [Pla88] </ref> continued with the philosophy that the important issue in theorem proving is subgoaling. This strategy is similar to the simplified problem reduction format, but has a better control mechanism for case analysis.
Reference: [Pla90] <author> D. Plaisted. </author> <title> A sequent style model elimination strategy and a positive refinement. </title> <journal> Journal of Automated Reasoning, </journal> <volume> 6(4):389 - 402, </volume> <year> 1990. </year>
Reference-contexts: Also, adjacent connections do not use the same literal. We say that two clauses C and D are connected in S if there is an alternating path in S mentioning both C and D. Such paths were mentioned in <ref> [Pla90] </ref>. One can show ([Pla76]) that if S is a minimal unsatisfi-able set of ground clauses, then every pair of clauses in S is connected in S.
Reference: [Pla93] <author> D. Plaisted. </author> <title> Polynomial time termination and constraint satisfaction tests. </title> <editor> In Claude Kirchner, editor, </editor> <booktitle> Fifth International Conference on Rewriting Techniques and Applications, </booktitle> <pages> pages 405-420, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: When there are many rewrites, this seems to lead to too many cases. However, perhaps there are more efficient implementation techniques that could solve this problem. Possibly the polynomial constraint methods of <ref> [Pla93] </ref> would help.
Reference: [Pla94a] <author> D. Plaisted. </author> <title> Ordered semantic hyper-linking. </title> <type> Technical Report MPI-I-94-235, </type> <institution> Max-Planck Institut fuer Informatik, Saarbruecken, Germany, </institution> <year> 1994. </year>
Reference-contexts: Our proposed strategy builds orderings into clause linking, too, as an attempt to reconcile clause linking with ordering techniques such as those com-monly used in term-rewriting systems. A sketch of this proposed "ordered clause linking with semantics" approach is given in <ref> [Pla94a] </ref>. This approach has the disadvantage that the A-ordering part of the prover still uses resolution, and therefore has the combinatorial inefficiencies of resolution to contend with. On the other hand, resolution has the advantage of faster transmission of information between literals, as noted above.
Reference: [Pla94b] <author> D. Plaisted. </author> <title> The search efficiency of theorem proving strategies. </title> <booktitle> In Proceedings of the Twelfth International Conference on Automated Deduction, </booktitle> <pages> pages 57-71, </pages> <year> 1994. </year> <booktitle> Lecture Notes in Artificial Intelligence 814. </booktitle>
Reference-contexts: Efficiencies of languages and data structures have been secondary, although emphasized at times. I apologize for failing to mention many other interesting approaches to automated deduction. Some of these are covered in the search complexity analyses of <ref> [Pla94b] </ref> and [Pla94c]. 1.1 Goal-Sensitivity We should clarify at the start what we mean by goal-sensitivity, since we mention it a number of times. <p> We compared clause linking to Otter and other provers; Otter has been significantly improved since then, using ordered hyper-linking for example, and possibly in other ways as well. But clause linking can still solve more of the problems. Another evidence is the search complexity analyses of <ref> [Pla94b] </ref> and [Pla94c], which give sets of clauses on which well-known strategies perform asymptotically very bad. There, we show that only a small number of strategies are both goal-sensitive and propositionally efficient. We note that some of these complexity issues were addressed already in [Pla82].
Reference: [Pla94c] <author> D. Plaisted. </author> <title> The search efficiency of theorem proving strategies: an analytical comparison. </title> <type> Technical Report MPI-I-94-233, </type> <institution> Max-Planck Institut fuer Informatik, Saarbruecken, Germany, </institution> <year> 1994. </year>
Reference-contexts: Efficiencies of languages and data structures have been secondary, although emphasized at times. I apologize for failing to mention many other interesting approaches to automated deduction. Some of these are covered in the search complexity analyses of [Pla94b] and <ref> [Pla94c] </ref>. 1.1 Goal-Sensitivity We should clarify at the start what we mean by goal-sensitivity, since we mention it a number of times. <p> We compared clause linking to Otter and other provers; Otter has been significantly improved since then, using ordered hyper-linking for example, and possibly in other ways as well. But clause linking can still solve more of the problems. Another evidence is the search complexity analyses of [Pla94b] and <ref> [Pla94c] </ref>, which give sets of clauses on which well-known strategies perform asymptotically very bad. There, we show that only a small number of strategies are both goal-sensitive and propositionally efficient. We note that some of these complexity issues were addressed already in [Pla82]. <p> We note that term-rewriting based theorem provers also have severe combinatorial inefficiencies in general, as shown in <ref> [Pla94c] </ref>. Term-rewriting techniques correspond to A-resolution, in their extension to first-order theorem proving methods. In [Pla94c], we give satisfiable sets of propositional Horn clauses for which the A-ordering strategy generates an exponential number of resolvents, regardless of the ordering chosen. <p> We note that term-rewriting based theorem provers also have severe combinatorial inefficiencies in general, as shown in <ref> [Pla94c] </ref>. Term-rewriting techniques correspond to A-resolution, in their extension to first-order theorem proving methods. In [Pla94c], we give satisfiable sets of propositional Horn clauses for which the A-ordering strategy generates an exponential number of resolvents, regardless of the ordering chosen. This seems to indicate that additional techniques are needed in order to combine rewrite-based methods with first-order theorem provers.
Reference: [PP91] <author> D. Plaisted and R Potter. </author> <title> Term rewriting: Some experimental results. </title> <journal> Journal of Symbolic Computation, </journal> <volume> 11:149 - 180, </volume> <year> 1991. </year>
Reference-contexts: Replacement rules have a substantial history in our work, beginning with the paper [PG86] concerning set theory and resolution. That paper examined the technique of replacing predicates by their definitions. Next, in the paper <ref> [PP91] </ref>, we applied them to some problems in set theory in the modified problem reduction format, obtaining proofs with very little guidance. We also did some work with replacement rules in CLIN [LP94], obtaining proofs in set theory and temporal logic.
Reference: [Sla67] <author> J.R. Slagle. </author> <title> Automatic theorem proving with renameable and semantic resolution. </title> <journal> J. ACM, </journal> <volume> 14 </volume> <pages> 687-697, </pages> <year> 1967. </year> <title> This article was processed using the L a T E X macro package with LLNCS style </title>
Reference-contexts: We note that the natural semantics corresponds much more closely to the kind of structure that a human would use in proving a theorem. The semantic resolution strategy of <ref> [Sla67] </ref> is one of the early attempts to incorporate arbitrary semantics into a theorem prover; we feel that the idea is good, but that the search inefficiencies of resolution largely negate its value.
References-found: 27

