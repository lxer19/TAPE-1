URL: http://www.eecs.umich.edu/PPP/ICPP93.ps
Refering-URL: http://www.eecs.umich.edu/PPP/karen.html
Root-URL: http://www.cs.umich.edu
Email: email: karent@eecs.umich.edu  
Title: Iteration Partitioning for Resolving Stride Conflicts on Cache-Coherent Multiprocessors  
Author: Karen A. Tomko and Santosh G. Abraham 
Address: Ann Arbor, MI 48109-2122  
Affiliation: Department of Electrical Engineering and Computer Science University of Michigan  
Abstract: We develop compile-time iteration partitioning techniques for private-cache shared-memory multiprocessors. Our techniques assign loop iterations to a set of processors so that cache coherency traffic due to interprocessor communication is minimized and load balance is maintained. In contrast to most previous research that has examined uniformly-generated dependences, we develop methods for non-uniform dependences that are generated by stride conflicts. Furthermore, we consider the effects of a long cache line size and minimize false coherency traffic. Our methods can handle conflicts between any two integer strides. We have conducted experiments on a 32-processor KSR-1 from Kendall Square Research which show 2x performance improvement using our partitioning algorithm over standard contiguous partitioning techniques. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Santosh G. Abraham and David E. Hudak. </author> <title> Compile-time partitioning of iterative parallel loops to reduce cache coherence traffic. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 2(3) </volume> <pages> 318-328, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: Several researchers have developed methods for determining communication free partitions of index sets for subscript expressions having uniform dependencies [12], [11], [2]. Our work presents methods for communication free partitions of index sets with non-uniform dependencies. Abraham and Hudak <ref> [1] </ref> have developed automatic partitioning techniques for regular data-parallel loops with array accesses that have unit-coefficient linear subscripts. In contrast, this paper discusses automatic partitioning techniques for loops with stride conflicts. In [1], they develop iteration space partitions that satisfy load-balancing constraints and optimize cache-coherency traffic whereas we develop partitions that <p> Our work presents methods for communication free partitions of index sets with non-uniform dependencies. Abraham and Hudak <ref> [1] </ref> have developed automatic partitioning techniques for regular data-parallel loops with array accesses that have unit-coefficient linear subscripts. In contrast, this paper discusses automatic partitioning techniques for loops with stride conflicts. In [1], they develop iteration space partitions that satisfy load-balancing constraints and optimize cache-coherency traffic whereas we develop partitions that satisfy a zero communication constraint and minimize load imbalance. Fang and Lu [3] develop a scheduling scheme that exploits reuse due to non-uniformly generated dependences. <p> Reference set partitioning also assumes, for convergence, that jk 1 j 6= jk 2 j. If k 1 = k 2 then the dependence distance between the data accesses is constant (or uniform). Several researchers have provided partitioning algorithms which handle this case [12], [11], [2] and <ref> [1] </ref>. If k 1 = k 2 the dependencies are not uniform and are thus not addressed in the papers mentioned above. There is however a simple solution for this case. In Figure 5 we give an example diagram for k 1 = k 2 .
Reference: [2] <author> E. H. D'Hollander. </author> <title> Partitioning and labeling of index sets in do loops with constant dependence vectors. </title> <booktitle> In Proceedings of the International Conference on Parallel Processing, </booktitle> <pages> pages 139-144, </pages> <year> 1989. </year>
Reference-contexts: Additionally, our work is useful in reducing cache coherency traffic in a parallel program as well as capacity misses in a sequential program. Several researchers have developed methods for determining communication free partitions of index sets for subscript expressions having uniform dependencies [12], [11], <ref> [2] </ref>. Our work presents methods for communication free partitions of index sets with non-uniform dependencies. Abraham and Hudak [1] have developed automatic partitioning techniques for regular data-parallel loops with array accesses that have unit-coefficient linear subscripts. In contrast, this paper discusses automatic partitioning techniques for loops with stride conflicts. <p> Reference set partitioning also assumes, for convergence, that jk 1 j 6= jk 2 j. If k 1 = k 2 then the dependence distance between the data accesses is constant (or uniform). Several researchers have provided partitioning algorithms which handle this case [12], [11], <ref> [2] </ref> and [1]. If k 1 = k 2 the dependencies are not uniform and are thus not addressed in the papers mentioned above. There is however a simple solution for this case. In Figure 5 we give an example diagram for k 1 = k 2 .
Reference: [3] <author> Jesse Fang and Mi Lu. </author> <title> An iteration partition approach for cache or local memory thrashing on parallel processing. </title> <booktitle> In Proceedings of the 4th Workshop on Languages and Compilers for Parallel Computing, </booktitle> <pages> pages 313-327, </pages> <year> 1991. </year>
Reference-contexts: In an empirical study [13], 15% of three-dimensional array references had subscript expressions with loop index coefficients greater than 1. Stride conflicts can be found in diverse applications such as mechanical CAE and computational chemistry <ref> [3] </ref>. Standard parallelization schemes such as contiguous or cyclic partitioning of the iteration space of parallel loops will generate cache coherency traffic in the presence of stride conflicts. <p> In contrast, this paper discusses automatic partitioning techniques for loops with stride conflicts. In [1], they develop iteration space partitions that satisfy load-balancing constraints and optimize cache-coherency traffic whereas we develop partitions that satisfy a zero communication constraint and minimize load imbalance. Fang and Lu <ref> [3] </ref> develop a scheduling scheme that exploits reuse due to non-uniformly generated dependences. Neither our model or Fang and Lu's model is subsumed by the other. Our approach is similar to theirs in that we partition the iteration space into equivalence classes which access common array elements.
Reference: [4] <author> Dennis Gannon, William Jalby, and Kyle Gallivan. </author> <title> Strategies for cache and local memory management by global program transformation. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 5(5) </volume> <pages> 587-616, </pages> <month> October </month> <year> 1988. </year>
Reference-contexts: Offset conflicts arising from uniformly-generated dependences have been investigated both in the context of improving locality in sequential programs and in the context of reducing interprocessor communication in parallel programs. Gannon, Jalby and Gallivan <ref> [4] </ref> and Wolf and Lam [14] describe methods for improving data locality using program transformations. In contrast to our work, both analyses are restricted to uniformly generated dependences and cannot handle stride conflicts.
Reference: [5] <author> Dennis Gannon, Jenq Kuen Lee, Bruce Shei, Sekhar Sarukkai, Srivinas Narayana, Neelakantan Sundaresan, Daya Atapattu, and Francois Bodin. </author> <title> SIGMA II: A tool kit for building parallelizing compilers and performance analysis systems. </title> <note> To appear in Elsevier, </note> <year> 1992. </year>
Reference-contexts: We are integrating these software tools into the ASCOT (Architecture-Specific Compile-time Optimization Tool), a source to source re-structurer being developed at the University of Michigan and built upon SIGMA II and the SIGMA Toolbox developed by Gannon et. al. <ref> [5] </ref>. The main limitation of our method is that it does not easily extend to more than two data access functions. If we increase the number of data access functions to just three the complexity increases dramatically.
Reference: [6] <author> Manish Gupta and Prithviraj Banerjee. </author> <title> Demonstration of automatic data partitioning techniques for parallelizing compilers on multicomputers. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 3(2) </volume> <pages> 179-193, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: Our objective is to partition scientific programs containing loop-level parallelism for current shared-memory parallel systems. We meet the conflicting allocation requirements by reducing the parallelism without incurring any communication costs. Various heuristics to resolve conflicts have been developed. Gupta and Banerjee <ref> [6] </ref> have developed methods for automatic data partitioning for distributed memory MIMD multiprocessors. Kennedy and McKinley [8] use memory access cost estimates to guide transformations to increase data locality for parallel processors.
Reference: [7] <institution> Kendall Square Research Corporation, </institution> <address> 170 Tracer Lane, Waltham, MA, </address> <month> 02154-1379. </month> <title> KSR1 Principles of Operation, </title> <year> 1991. </year>
Reference-contexts: 1 Introduction In todays high performance multiprocessor systems, the remote memory latencies are over a hundred times greater than the cycle time of the processors <ref> [7] </ref>. Complex memory hierarchies have been developed to hide latency and provide data at sufficient rates to keep the processors busy. However, the memory hierarchy alone does not guarantee good performance.
Reference: [8] <author> Ken Kennedy and Kathryn S. McKinley. </author> <title> Optimizing for parallelism and data locality. </title> <institution> Technical Report Rice COMP TR92-175, Rice University, Department of Computer Science, </institution> <year> 1992. </year>
Reference-contexts: We meet the conflicting allocation requirements by reducing the parallelism without incurring any communication costs. Various heuristics to resolve conflicts have been developed. Gupta and Banerjee [6] have developed methods for automatic data partitioning for distributed memory MIMD multiprocessors. Kennedy and McKinley <ref> [8] </ref> use memory access cost estimates to guide transformations to increase data locality for parallel processors. Offset conflicts arising from uniformly-generated dependences have been investigated both in the context of improving locality in sequential programs and in the context of reducing interprocessor communication in parallel programs.
Reference: [9] <author> Kathleen Knobe, Joan D. Lukas, and Guy L. Steele, Jr. </author> <title> Data optimization: Allocation of arrays to reduce communication on SIMD machines. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 8 </volume> <pages> 102-118, </pages> <year> 1990. </year>
Reference-contexts: Knobe, Lukas and Steele <ref> [9] </ref> present an algorithm for automatic allocation of array elements to processors for SIMD machines, based on array usage. They identify four types of conflicts that prevent communication-free parallelism-preserving data assignments to processors: stride, offset, scalar and cell conflicts. We assume techniques such as described in [9] can be used to <p> Knobe, Lukas and Steele <ref> [9] </ref> present an algorithm for automatic allocation of array elements to processors for SIMD machines, based on array usage. They identify four types of conflicts that prevent communication-free parallelism-preserving data assignments to processors: stride, offset, scalar and cell conflicts. We assume techniques such as described in [9] can be used to identify stride conflicts and concentrate on resolution techniques. Knobe and Natarajan [10] present an algorithm to minimize the interprocessor communication resulting from conflicts by dividing source programs into regions based on control flow and dependence information.
Reference: [10] <author> Kathleen Knobe and Venkataraman Natarajan. </author> <title> Data optimization: Minimizing residual interprocessor data motion on SIMD machines. </title> <booktitle> In Proceedings of the Third Symposium on the Frontiers of Massively Parallel Computation, </booktitle> <pages> pages 416-423, </pages> <year> 1990. </year>
Reference-contexts: They identify four types of conflicts that prevent communication-free parallelism-preserving data assignments to processors: stride, offset, scalar and cell conflicts. We assume techniques such as described in [9] can be used to identify stride conflicts and concentrate on resolution techniques. Knobe and Natarajan <ref> [10] </ref> present an algorithm to minimize the interprocessor communication resulting from conflicts by dividing source programs into regions based on control flow and dependence information. Allocation requirements within a region are met and communication occurs between regions.
Reference: [11] <author> Jih-Kwon Peir and Ron Cytron. </author> <title> Minimum distance: A method for partitioning recurrences for multiprocessors. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 38(8) </volume> <pages> 1203-1211, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: Additionally, our work is useful in reducing cache coherency traffic in a parallel program as well as capacity misses in a sequential program. Several researchers have developed methods for determining communication free partitions of index sets for subscript expressions having uniform dependencies [12], <ref> [11] </ref>, [2]. Our work presents methods for communication free partitions of index sets with non-uniform dependencies. Abraham and Hudak [1] have developed automatic partitioning techniques for regular data-parallel loops with array accesses that have unit-coefficient linear subscripts. In contrast, this paper discusses automatic partitioning techniques for loops with stride conflicts. <p> Reference set partitioning also assumes, for convergence, that jk 1 j 6= jk 2 j. If k 1 = k 2 then the dependence distance between the data accesses is constant (or uniform). Several researchers have provided partitioning algorithms which handle this case [12], <ref> [11] </ref>, [2] and [1]. If k 1 = k 2 the dependencies are not uniform and are thus not addressed in the papers mentioned above. There is however a simple solution for this case. In Figure 5 we give an example diagram for k 1 = k 2 .
Reference: [12] <author> Weijia Shang and Jose A. B. Fortes. </author> <title> Independent partitioning of algorithms with uniform dependencies. </title> <booktitle> In Proceedings of the International Conference on Parallel Processing, </booktitle> <pages> pages 26-33, </pages> <year> 1987. </year>
Reference-contexts: Additionally, our work is useful in reducing cache coherency traffic in a parallel program as well as capacity misses in a sequential program. Several researchers have developed methods for determining communication free partitions of index sets for subscript expressions having uniform dependencies <ref> [12] </ref>, [11], [2]. Our work presents methods for communication free partitions of index sets with non-uniform dependencies. Abraham and Hudak [1] have developed automatic partitioning techniques for regular data-parallel loops with array accesses that have unit-coefficient linear subscripts. <p> Reference set partitioning also assumes, for convergence, that jk 1 j 6= jk 2 j. If k 1 = k 2 then the dependence distance between the data accesses is constant (or uniform). Several researchers have provided partitioning algorithms which handle this case <ref> [12] </ref>, [11], [2] and [1]. If k 1 = k 2 the dependencies are not uniform and are thus not addressed in the papers mentioned above. There is however a simple solution for this case. In Figure 5 we give an example diagram for k 1 = k 2 .
Reference: [13] <author> Zhiyu Shen, Zhiyuan Li, and Pen-Chung Yew. </author> <title> An empirical study of fortran programs for parallelizing compilers. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 1(3) </volume> <pages> 356-364, </pages> <year> 1990. </year>
Reference-contexts: Stride conflicts occur when array subscript expressions contain index coefficients (strides) greater than one or when an array is accessed by the same index variable in more than one dimension. In an empirical study <ref> [13] </ref>, 15% of three-dimensional array references had subscript expressions with loop index coefficients greater than 1. Stride conflicts can be found in diverse applications such as mechanical CAE and computational chemistry [3].
Reference: [14] <author> Michael E. Wolf and Monica S. Lam. </author> <title> A data locality optimizing algorithm. </title> <booktitle> In Proceedings of the ACM SIGPLAN'91 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 30-44, </pages> <year> 1991. </year>
Reference-contexts: Offset conflicts arising from uniformly-generated dependences have been investigated both in the context of improving locality in sequential programs and in the context of reducing interprocessor communication in parallel programs. Gannon, Jalby and Gallivan [4] and Wolf and Lam <ref> [14] </ref> describe methods for improving data locality using program transformations. In contrast to our work, both analyses are restricted to uniformly generated dependences and cannot handle stride conflicts.
References-found: 14

