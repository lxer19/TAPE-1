URL: http://www.media.mit.edu/~moux/papers/jaamas98.ps
Refering-URL: http://www.media.mit.edu/~moux/research.html
Root-URL: http://www.media.mit.edu
Email: moux/pattie@media.mit.edu  
Title: Amalthaea: An Evolving Multi-Agent Information Filtering and Discovery System for the WWW  
Author: Alexandros Moukas and Pattie Maes 
Keyword: Agents, Evolution, Information Filtering, WorldWide-Web  
Address: E15-305C, 20 Ames Street, Cambridge, MA 02139, USA  
Affiliation: Software Agents Group MIT Media Laboratory  
Abstract: Amalthaea is an evolving, multiagent ecosystem for personalized filtering, discovery and monitoring of information sites. Amalthaea's primary application domain is the WorldWide-Web and its main purpose is to assist its users in finding interesting information. Two different categories of agents are introduced in the system: filtering agents that model and monitor the interests of the user and discovery agents that model the information sources. A market-like ecosystem where the agents evolve, compete and collaborate is presented: agents that are useful to the user or other agents reproduce while low-performing agents are destroyed. Results from various experiments with different system configurations and varying ratios of user interests versus agents in the system are presented. Finally issues like fine-tuning the initial parameters of the system and establishing and maintaining equilibria in the ecosystem are discussed. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Baclace, P. </author> <year> (1992). </year> <title> Competitive agents for information filtering. </title> <journal> Comm. of the ACM, </journal> <volume> 35 (12):50. </volume>
Reference-contexts: In order to accelerate the destruction of noncompetent agents and the evolution of new ones we introduced a linear decay function which can be seen as a type of rent <ref> (Baclace, 1992) </ref>. In order for the agents to inhabit the ecosystem they have to pay something. If the credits they gain fall short this rent they are removed from the system.
Reference: <author> Balabanovic, M. and Shoham, Y. </author> <year> (1995). </year> <title> Learning information retrieval agents: Experiments with automated web browsing. </title> <note> In AAAI Tech. Report SS-95-08, Proc. of the 1995 AAAI SSS. </note>
Reference-contexts: These agents are designed to assist the user and provide personalization, while the user browses the WWW. They perform a breadth-first search on the links ahead and provide navigation recommendations. More similar to our work in terms of application domain and representation is the system built at Stanford <ref> (Balabanovic and Shoham, 1995) </ref>. They introduced a system for WWW document filtering which also utilized the weighted keyword vector representation.
Reference: <author> Belew, R. </author> <year> (1989). </year> <title> Evolution Learning and Culture: Computational metaphors for adaptive algorithms. </title> <institution> UC at San Diego Technical Report CS89-156. </institution>
Reference: <author> Belkin, N. and Croft, B. </author> <year> (1992). </year> <title> Information filtering and informatiuon retrieval. </title> <journal> Comm. of the ACM, </journal> <volume> 35, No. </volume> <month> 12:2937. </month>
Reference-contexts: The system continues to explore the search space for better solutions using evolution techniques such as mutation and crossover for refreshing and specializing the agents population. Our approach to creating an ecosystem is influenced by Belkin and Croft's <ref> (Belkin and Croft, 1992) </ref> approach to information filtering and information retrieval: filtering and retrieval are in fact two sides of the same coin. Significant work has been done on applying artificial intelligence techniques to information filtering.
Reference: <author> Best, M. </author> <year> (1997). </year> <title> Corporal ecologies and population fitness on the net. Submitted to Journal of Artificial Life, </title> <publisher> MIT Press Clearwater, </publisher> <editor> S. </editor> <year> (1996). </year> <title> A comparative-developmental approach to understanding imitation. </title> <editor> In Clearwater, S., editor, </editor> <title> Market Based Control: a paradigm for distributed resource allocation. </title>
Reference-contexts: Finally analysis of text fitness in the internet in an ecological framework was done at the MIT Media Lab using LSI techniques <ref> (Best, 1997) </ref> 6 Conclusions and Future Work This paper discussed the idea of using evolving populations of agents for personalized information filtering and discovery. In particular, we introduced the idea of integrating two different populations of agents, Information Filtering Agents and Information Discovery Agents into an ecosystem.
Reference: <author> Decker, K. and Lesser, V. </author> <year> (1995). </year> <title> Macron: An architecture for multi-agent cooperative information gathering. </title> <booktitle> In CIKM Conference, Workshop on Intelligent Information Agents. </booktitle>
Reference-contexts: Webcompass is a WWW product by Quarterdeck. Webcompass is directed towards offline search and indexing. It enables the user to generate queries that will search the WWW offline and presents the results at a later time. The MACRON multiagent system <ref> (Decker and Lesser, 1995) </ref> developed at UMass/Amherst, is built on top of the CIG searchbots and uses a centralized planner to generate subgoals that are pursued by a group of cooperating agents, using KQML (Labrou and Finin, 1994), a standardized language for inter-agent communication and negotiation.
Reference: <author> Decker, K., Pannu, A., Sycara, K., and Williamson, M. </author> <year> (1997). </year> <title> Designing behaviors for information agents. </title> <booktitle> In Proceedings of the First International Conference on Autonomous Agents, </booktitle> <address> Los Angeles, 1997. References 34 Moukas/Maes - AAMAS Submission Etzioni, O. </address> <year> (1995). </year> <title> Results from using the metacrawler. </title> <editor> In Varela, F. and Bourgine, P., editors, </editor> <booktitle> Proceedings of the Fourth WWW Conference. </booktitle> <publisher> MIT Press. </publisher>
Reference: <author> Etzioni, O. </author> <year> (1996). </year> <title> Moving up the information food chain: </title> <booktitle> deploying softbots on the www. In Proceedings of the AAAI-96. </booktitle> <publisher> AAAI Press. </publisher>
Reference-contexts: Etzioni is referring to that as the information food chain and is advocating that Metacrawler is an information carnivore high up the information food source <ref> (Etzioni, 1996) </ref>. Webcompass is a WWW product by Quarterdeck. Webcompass is directed towards offline search and indexing. It enables the user to generate queries that will search the WWW offline and presents the results at a later time.
Reference: <author> Grosof, B. </author> <year> (1995). </year> <title> Reusable architecture for embedding rule-based intelligence. </title> <booktitle> In CIKM Conference, Workshop on Intelligent Information Agents. </booktitle>
Reference-contexts: A comparable system is RAISE <ref> (Grosof, 1995) </ref>, developed by IBM. RAISE is a rule-based system that provides a framework for knowledge reuse in different domains (like electronic mail, newsgroups e.t.c.) INFOrmer (Riordan and Sorensen, 1995), developed at University of Cork introduces the idea of using associative networks instead of keywords for information retrieval.
Reference: <author> Hill, W., Stead, L., Resenstein, R., and Furnas, G. </author> <year> (1995). </year> <title> Recommending and evaluating choices in a virtual community of use. </title> <booktitle> In Proceedings of CHI 95, </booktitle> <address> Denver, </address> <publisher> CO. </publisher>
Reference-contexts: The smaller the standard deviation, the better the algorithm. The standard deviation of the error is defined as: (5) Correlation Coefficient. The higher the correlation of the agents confidence to the user rating, the better the algorithm according to <ref> (Hill et al., 1995) </ref>. (6) Extreme Values. (Lashkari, 1995) and (Shardanand and Maes, 1995) assert that the confidence of the agents for extreme values (that is weighted values above six or below two) indicate very strong user preferences and are probably more important than other values (i.e. the users care about
Reference: <author> Kohonen, T. </author> <year> (1989). </year> <title> Self-Organization and Associative Memory. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin. </address>
Reference: <author> Labrou, Y. and Finin, T. </author> <year> (1994). </year> <title> A semantics approach for kqml - a general purpose communication language for software agents. </title> <booktitle> In Proceedings of Conference on Information and Knowledge Management 1994. </booktitle> <publisher> ACM Press. </publisher>
Reference-contexts: The MACRON multiagent system (Decker and Lesser, 1995) developed at UMass/Amherst, is built on top of the CIG searchbots and uses a centralized planner to generate subgoals that are pursued by a group of cooperating agents, using KQML <ref> (Labrou and Finin, 1994) </ref>, a standardized language for inter-agent communication and negotiation. A comparable system is RAISE (Grosof, 1995), developed by IBM.
Reference: <author> Lang, K. </author> <year> (1995). </year> <title> Newsweeder. </title> <booktitle> In Proceedings of the 12th Int l Conference on Machine Learning. </booktitle>
Reference: <author> Lashkari, Y. </author> <year> (1995). </year> <title> Webhound. </title> <type> Masters thesis, </type> <institution> MIT Media Laboratory. </institution>
Reference-contexts: mutation rates, crossover rates, cloning rates, Testing and Evaluation Moukas/Maes - AAMAS Submission 25 etc.) all the tests were conducted using a fixed set of parameters (due to time and com putational resource limitations.) 4.2.1 Evaluation Criteria The evaluation criteria for the first set of the experiments are similar to <ref> (Lashkari, 1995) </ref>. <p> The smaller the standard deviation, the better the algorithm. The standard deviation of the error is defined as: (5) Correlation Coefficient. The higher the correlation of the agents confidence to the user rating, the better the algorithm according to (Hill et al., 1995). (6) Extreme Values. <ref> (Lashkari, 1995) </ref> and (Shardanand and Maes, 1995) assert that the confidence of the agents for extreme values (that is weighted values above six or below two) indicate very strong user preferences and are probably more important than other values (i.e. the users care about the system being right about high and
Reference: <author> Lieberman, H. </author> <year> (1995). </year> <title> Letizia, an agent that assists web browsing. </title> <booktitle> In Proceedings of IJCAI-95. </booktitle> <publisher> AAAI Press. </publisher>
Reference-contexts: Pleiades introduces taskspe-cific and informationspecific agents deployed in different levels that can collaborate with one another to provide the information requested by the user. Another category of WWW agents includes Carnegie Mellons University Webwatcher (Armstrong et al., 1995) and MIT Media Laboratory's Letizia <ref> (Lieberman, 1995) </ref>. These agents are designed to assist the user and provide personalization, while the user browses the WWW. They perform a breadth-first search on the links ahead and provide navigation recommendations.
Reference: <author> Menczer, F., Belew, R., and Willuhn, W. </author> <year> (1995). </year> <title> Artificial life applied to adaptive information agents. </title> <booktitle> In Working Notes of the AAAI Symposium on Information Gathering from Distributed, Heterogeneous Databases. </booktitle> <publisher> AAAI Press. </publisher>
Reference-contexts: The main difference between NewT and Amalthaea (apart from the application domain) is that NewT employed only one kind of agents, namely specialized information filters, while the system presented here introduces different types of agents which base their relationships on a simple market-based model. The Infospiders or ARACHNID project <ref> (Menczer et al., 1995) </ref> at the University of California at San Diego combine evolutionary techniques with the idea of endogenous fitness to create a scalable distributed information retrieval system.
Reference: <author> Mitchell, M. </author> <year> (1996). </year> <title> An Introduction to Genetic Algorithms. </title> <publisher> MIT Press. </publisher>
Reference-contexts: If the overall fitness is increasing the evolution is kept at a lower rate to allow the system to slowly explore the search space for better solutions. New agents are created by copying (or cloning), crossover or mutation <ref> (see Mitchell, 1996) </ref>. All operators are applied to the evolvable part of the agents, the genotype. The other part of the agents, the phenotype contains information that should not be evolved, usually instructions on how to handle the evolvable part.
Reference: <author> Moukas, A. </author> <year> (1997). </year> <title> Amalthaea: Information discovery and filtering using a multiagent evolving ecosystem. </title> <journal> In Journal of Applied Artificial Intelligence, </journal> <volume> 11(5) </volume> <year> 437-457,1997. </year>
Reference-contexts: For those experiments we used the notion of virtual users, profiles created by real user interests that automatically tested the system. The virtual users Testing and Evaluation Moukas/Maes - AAMAS Submission 19 enabled us to perform big scale lenghty experiments without the use of people <ref> (the complete results can be found in Moukas, 1997) </ref>. The second axis which we worked along is that of testing the performance of the whole system with real users. We tested if the system could actually find useful information on the WWW and present it to its users.
Reference: <author> Porter, M. </author> <year> (1980). </year> <title> An algorithm for suffix stripping. Program, </title> <journal> 14(3):130138, </journal> <note> 1980 Resnik, </note> <author> P., Iacovou, N., Sushak, M., Bergstrom, P., and Riedl, J. </author> <year> (1994). </year> <title> Grouplens: An open architecture for collaborative filtering of netnews. </title> <booktitle> In Proceedings of CSCW94. </booktitle>
Reference: <author> Riordan, A. O. and Sorensen, H. </author> <year> (1995). </year> <title> An intelligent agent for high-precision information filtering. </title> <booktitle> In Proceedings of the CIKM-95 Conference. </booktitle>
Reference-contexts: A comparable system is RAISE (Grosof, 1995), developed by IBM. RAISE is a rule-based system that provides a framework for knowledge reuse in different domains (like electronic mail, newsgroups e.t.c.) INFOrmer <ref> (Riordan and Sorensen, 1995) </ref>, developed at University of Cork introduces the idea of using associative networks instead of keywords for information retrieval. CMUs RETSINA project (Sycara et al., 1996, Sycara and D., 1996, Decker et al., 1997) defines a framework for distributed intelligent agents.
Reference: <author> Salton, G. and Buckley, C. </author> <year> (1987). </year> <title> Text Weighting Approaches in Automatic Text Retrieval. </title> <type> Cornell University Technical Report 87-881. </type>
Reference-contexts: Finally the database is used for keeping track of the URLs already included in previous digests to prevent presentation of duplicate information to the user. Amalthaea's internal representation of documents is based on a standard information retrieval technique called weighted vector representation <ref> (Salton and Buckley, 1987) </ref>. The basic representation for the Information Filtering Agents as well as for the parsed HTML files is the weighted keyword vector.
Reference: <author> Shardanand, U. and Maes, P. </author> <year> (1995). </year> <title> Social information filtering: Algorithms for automating word of mouth. </title> <booktitle> In Proceedings of the CHI-95 Conference, </booktitle> <address> Dencer, </address> <publisher> CO. ACM Press. </publisher>
Reference-contexts: The smaller the standard deviation, the better the algorithm. The standard deviation of the error is defined as: (5) Correlation Coefficient. The higher the correlation of the agents confidence to the user rating, the better the algorithm according to (Hill et al., 1995). (6) Extreme Values. (Lashkari, 1995) and <ref> (Shardanand and Maes, 1995) </ref> assert that the confidence of the agents for extreme values (that is weighted values above six or below two) indicate very strong user preferences and are probably more important than other values (i.e. the users care about the system being right about high and low ratings, but
Reference: <author> Sheth, B. and Maes, P. </author> <year> (1993). </year> <title> Evolving agents for personalized information filtering. </title> <booktitle> In Proceedings of the Ninth Conference on Artificial Intelligence for Applications. </booktitle> <publisher> IEEE Computer Press. </publisher>
Reference-contexts: Our experimentation methods closely follow those introduced by the NewT and Webhound research projects <ref> (Sheth and Maes, 1993 and Lashkari, 1995) </ref>. One of the goals of this research project was to produce a useful system, utilized frequently by internet users. Experiments to assess the positive or negative feedback of the users were an important part of the evaluation process. <p> More similar to our work in terms of application domain and representation is the system built at Stanford (Balabanovic and Shoham, 1995). They introduced a system for WWW document filtering which also utilized the weighted keyword vector representation. In terms of evolutionary filtering systems, NewT <ref> (Sheth and Maes, 1993) </ref> developed at the Media Lab, is a multiagent system that uses evolution and relevance feedback for Conclusions and Future Work 32 Moukas/Maes - AAMAS Submission information filtering.
Reference: <author> Sycara, K. and D., Z. </author> <year> (1996). </year> <title> Coordination of multiple intelligent software agents. </title> <journal> International journal of Intelligent and Cooperative Information Systems, </journal> <volume> 5(2-3):181211, </volume> <year> 1996. </year>
Reference: <author> Sycara, K., Decker, K., Pannu, A., Williamson, M., and D., Z. </author> <year> (1996). </year> <title> Distributed intelligent agents. </title> <journal> IEEE Expert, </journal> <volume> 11(6), </volume> <year> 1996. </year>
References-found: 25

