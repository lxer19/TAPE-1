URL: http://www.cs.columbia.edu/~hgs/papers/Schu9107_Distribution.ps.Z
Refering-URL: http://www.cs.columbia.edu/~hgs/research/loss/
Root-URL: http://www.cs.columbia.edu
Title: Distribution of the Loss Period for Some Queues in Continuous and Discrete Time  
Author: Henning Schulzrinne James F. Kurose and Donald Towsley 
Address: Amherst, MA 01003  
Affiliation: Dept. of Electrical and Computer Engineering Dept. of Computer and Information Science University of Massachusetts  
Note: (presented in part at IEEE Infocom,  Contents  
Pubnum: COINS Technical Report TR91-3  
Email: hgschulz,kurose,towsley@cs.umass.edu  
Date: April 1991)  July 17, 1991  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> H. Schulzrinne, J. F. Kurose, and D. Towsley, </author> <title> "Congestion control for real-time traffic in high-speed networks," </title> <type> Tech. Rep. </type> <institution> TR89-92, Department of Computer and Information Science, University of Massachusetts, </institution> <address> Amherst, MA, </address> <year> 1989. </year>
Reference-contexts: Defining C C and C B as the number of consecutively lost customers and the number of customers in a busy period, respectively, we have P [C C = n] = P <ref> [C B &gt; 1] </ref> where P [C B &gt; 1] is the probability that the busy period contains more than one customer. Let us apply these results to the M=M=1 queue. <p> Defining C C and C B as the number of consecutively lost customers and the number of customers in a busy period, respectively, we have P [C C = n] = P <ref> [C B &gt; 1] </ref> where P [C B &gt; 1] is the probability that the busy period contains more than one customer. Let us apply these results to the M=M=1 queue. <p> where P <ref> [C B &gt; 1] </ref> is the probability that the busy period contains more than one customer. Let us apply these results to the M=M=1 queue. With P [C B = n] given by [24, Eq. (5.157)] P [C B = n] = n 2n 2 we compute P [C B &gt; 1] = 1 P [C B = 1] = 1 1 + : Thus, P [C C = n] = n + 1 2n ! (1 + ) 2n ; n &gt; 0: Note that this result differs markedly from the geometric distribution postulated by Ferrandiz [15, Corollary <p> Since the average number of customers per busy period is 1=(1), we have that for the M=M=1 queue the average number of consecutive customers lost is E [C C ] = P <ref> [C B &gt; 1] </ref> 1 1 = 1 This result differs markedly from that obtained under the assumption that losses occur independently as Bernoulli events with the time-average loss probability ff. <p> This model is used to represent the output queue of a fast packet switch, for example [48]. The waiting time and loss probability for this model have been analyzed by a number of authors <ref> [49, 47, 36, 48, 50, 51, 1] </ref>. For Poisson-distributed batches, Birdsall et al. [49, p. 392] computes the conditional probability of a run of exactly n slots in which one or more arrivals are rejected given that an arrival was rejected in the preceding slot. <p> We focus on one batch and construct a discrete-time chain with the state (i; j) = (left in buffer; consecutive losses in batch) i 2 <ref> [1; K 1] </ref>; j 2 [0; 1) The initial state, that is, the state immediately after the arrival of the batch of interest, is determined by the batch size and the system state and should be computable. The states (0; j) are absorbing.
Reference: [2] <author> H. Schulzrinne, J. F. Kurose, and D. Towsley, </author> <title> "Congestion control for real-time traffic in high-speed networks," </title> <booktitle> in Proceedings of the Conference on Computer Communications (IEEE Infocom), </booktitle> <address> (San Francisco, CA), </address> <pages> pp. 543-550, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: The loss as defined here differs from that studied in our earlier work <ref> [2] </ref>, where excessively delayed customers depart before occupying the server. A loss period (LP) is an uninterrupted interval during which all arriving customers would experience a waiting time exceeding h. <p> In this section, we consider the case when excessively delayed customers are dropped by the server. The queueing model with Poisson arrivals and exponential service was considered in [43] (called FIFO-TO there) and <ref> [2] </ref> (labelled FIFO-BW).
Reference: [3] <author> C. G. Cassandras, M. H. Kallmes, and D. Towsley, </author> <title> "Optimal routing and flow control in networks with real-time traffic," </title> <booktitle> in Proceedings of the Conference on Computer Communications (IEEE Infocom), </booktitle> <address> (Ottawa, Canada), </address> <pages> pp. 784-791, </pages> <publisher> IEEE, </publisher> <month> Apr. </month> <year> 1989. </year>
Reference: [4] <author> M. H. Kallmes, D. Towsley, and C. G. Cassandras, </author> <title> "Optimality of the last-in-first-out (LIFO) service discipline in queueing systems with real-time constraints," </title> <booktitle> in Proceedings of the 28th Conference on Decision and Control (CDC), </booktitle> <address> (Tampa, FL), </address> <pages> pp. 1073-1074, </pages> <publisher> IEEE, </publisher> <year> 1989. </year>
Reference: [5] <author> A. W. Berger, </author> <title> "Overload control in star networks: Comparison of percent blocking throttle and LIFO queue discipline." submitted to Performance Evaluation, </title> <year> 1989. </year>
Reference: [6] <author> L. J. Forys, </author> <title> "Performance analysis of a new overload strategy," </title> <booktitle> in Proceedings of the Tenth International Teletraffic Congress (ITC-10), </booktitle> <address> (Montreal), p. 5.24, IAC, </address> <publisher> North Holland, </publisher> <month> June </month> <year> 1983. </year>
Reference: [7] <author> J. G. Gruber and N. H. Le, </author> <title> "Performance requirements for integrated voice/data networks," </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> vol. SAC-1, </volume> <pages> pp. 981-1005, </pages> <month> Dec. </month> <year> 1983. </year>
Reference-contexts: The importance of accounting for correlated losses has long been recognized in specifiying acceptable performance of data circuits. "An errored second is declared when one or more bits in that second is found in error." <ref> [7] </ref> This leads to the metric of the percentage of error-free seconds (EFS). Papers on packet voice reconstruction typically assume random, uncorrelated occurrence of packet loss [8, 9]; as we will show, this assumption might be overly optimistic. The work by Shacham and Kenney [10, 11] provides another example.
Reference: [8] <author> N. S. Jayant, </author> <title> "Effects of packet losses in waveform-coded speech," </title> <booktitle> in International Conference on Computers and Communications, (Atlanta, Georgia), </booktitle> <pages> pp. 275-280, </pages> <publisher> IEEE, </publisher> <month> Oct. </month> <year> 1980. </year>
Reference-contexts: Papers on packet voice reconstruction typically assume random, uncorrelated occurrence of packet loss <ref> [8, 9] </ref>; as we will show, this assumption might be overly optimistic. The work by Shacham and Kenney [10, 11] provides another example.
Reference: [9] <author> L. A. DaSilva, D. W. Petr, and V. S. Frost, </author> <title> "A class-oriented replacement technique for lost speech packets," </title> <booktitle> in Proceedings of the Conference on Computer Communications (IEEE Infocom), </booktitle> <address> (Ottawa, Canada), </address> <pages> pp. 1098-1105, </pages> <publisher> IEEE, </publisher> <month> Apr. </month> <year> 1989. </year>
Reference-contexts: Papers on packet voice reconstruction typically assume random, uncorrelated occurrence of packet loss <ref> [8, 9] </ref>; as we will show, this assumption might be overly optimistic. The work by Shacham and Kenney [10, 11] provides another example.
Reference: [10] <author> N. Shacham, </author> <title> "Packet resequencing under reliable transport protocols," </title> <booktitle> in Hawaii International Conference on System Sciences, </booktitle> <volume> vol. 3, </volume> <pages> (Kailua-Kona, </pages> <address> HI), </address> <pages> pp. 716-723, </pages> <month> Jan. </month> <year> 1989. </year>
Reference-contexts: Papers on packet voice reconstruction typically assume random, uncorrelated occurrence of packet loss [8, 9]; as we will show, this assumption might be overly optimistic. The work by Shacham and Kenney <ref> [10, 11] </ref> provides another example. They observed that loss correlation in a finite-buffer system could completely eliminate the advantage of three orders of magnitude predicted for forward-error correction under the assumption of independent (Bernoulli) losses.
Reference: [11] <author> N. Shacham and P. McKenney, </author> <title> "Packet recovery in high-speed networks using coding and buffer management," </title> <booktitle> in Proceedings of the Conference on Computer Communications (IEEE Infocom), </booktitle> <address> (San Francisco, CA), </address> <pages> pp. 124-131, </pages> <publisher> IEEE, </publisher> <month> June </month> <year> 1990. </year>
Reference-contexts: Papers on packet voice reconstruction typically assume random, uncorrelated occurrence of packet loss [8, 9]; as we will show, this assumption might be overly optimistic. The work by Shacham and Kenney <ref> [10, 11] </ref> provides another example. They observed that loss correlation in a finite-buffer system could completely eliminate the advantage of three orders of magnitude predicted for forward-error correction under the assumption of independent (Bernoulli) losses. <p> Van Doorn [16] and Meier-Hellstern [17,18] characterize the overflow process from a finite Markovian queueing system. As pointed out earlier, <ref> [11] </ref> underlines the importance of taking loss correlations into account, but investigates their effect on forward-error correction only through simulation. A large body of literature analyzes the overflow process of blocked-calls-cleared systems, but the results do not seem directly applicable to our problem. The report is organized as follows.
Reference: [12] <author> T. Kamitake and T. Suda, </author> <title> "Evaluation of an admission control scheme for an ATM network considering fluctuations in cell loss rate," </title> <booktitle> in Proceedings of the Conference on Global Communications (GLOBECOM), </booktitle> <address> (Dallas, Texas), </address> <pages> pp. 1774-1780, </pages> <publisher> IEEE, </publisher> <month> Nov. </month> <year> 1989. </year>
Reference-contexts: We also derive measures of the time between loss periods. Throughout the paper, emphasis is placed on providing results that can be readily numerically evaluated. A number of authors have investigated related aspects of the problem. Kamitake and Suda <ref> [12] </ref> consider a discrete-time queue in which traffic is generated by a changing number of active callers, with each active caller generating a packet in a slot according to a Bernoulli process. <p> Our work differs from <ref> [12] </ref> in that we directly characterize those periods of time in which arriving customers are lost, rather than characterizing loss as being "quasi-stationary" during periods of times during which the number of active sources remains constant.
Reference: [13] <author> W. E. Leland, </author> <title> "Window-based congestion management in broadband ATM networks: the performance of three access-control policies," </title> <booktitle> in Proceedings of the Conference on Global Communications (GLOBECOM), </booktitle> <address> (Dallas, Texas), </address> <pages> pp. 1794-1800, </pages> <publisher> IEEE, </publisher> <month> Nov. </month> <year> 1989. </year>
Reference-contexts: Our work differs from [12] in that we directly characterize those periods of time in which arriving customers are lost, rather than characterizing loss as being "quasi-stationary" during periods of times during which the number of active sources remains constant. Leland <ref> [13] </ref> mentions, but does not elaborate on measuring consecutive losses per connection in an ATM simulation experiment. Woodruff and Kositpaiboon [14] mention the desirability of specifying the probability and duration of periods of high cell loss rates.
Reference: [14] <author> G. M. Woodruff and R. Kositpaiboon, </author> <title> "Multimedia traffic management principles for guaranteed ATM network performance," </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> vol. 8, </volume> <pages> pp. 437-446, </pages> <month> Apr. </month> <year> 1990. </year> <month> 42 </month>
Reference-contexts: Leland [13] mentions, but does not elaborate on measuring consecutive losses per connection in an ATM simulation experiment. Woodruff and Kositpaiboon <ref> [14] </ref> mention the desirability of specifying the probability and duration of periods of high cell loss rates.
Reference: [15] <author> J. M. Ferrandiz and A. A. Lazar, </author> <title> "Consecutive packet loss in real-time packet traffic," </title> <booktitle> in Proceedings of the Fourth International Conference on Data Communication Systems, (Barce-lona), </booktitle> <pages> pp. 306-324, </pages> <publisher> IFIP TC6, </publisher> <month> June </month> <year> 1990. </year>
Reference-contexts: Leland [13] mentions, but does not elaborate on measuring consecutive losses per connection in an ATM simulation experiment. Woodruff and Kositpaiboon [14] mention the desirability of specifying the probability and duration of periods of high cell loss rates. Ferrandiz and Lazar <ref> [15] </ref> investigate the distribution of gaps, that is, consecutive losses, due to blocking and clipping (see 1 The terms "customer" and "packet" will be used interchangeably. 3 below) in a multiclass G=G=m=B queueing system; we discuss similarities and differences between our work and [15] in the following sections. <p> Ferrandiz and Lazar <ref> [15] </ref> investigate the distribution of gaps, that is, consecutive losses, due to blocking and clipping (see 1 The terms "customer" and "packet" will be used interchangeably. 3 below) in a multiclass G=G=m=B queueing system; we discuss similarities and differences between our work and [15] in the following sections. Van Doorn [16] and Meier-Hellstern [17,18] characterize the overflow process from a finite Markovian queueing system. As pointed out earlier, [11] underlines the importance of taking loss correlations into account, but investigates their effect on forward-error correction only through simulation. <p> Customers that spend more than a deterministic, fixed amount of time h waiting for service are tagged as lost on leaving the queue, but are still served. (Ferrandiz and Lazar <ref> [15] </ref> refer to this as clipping loss.) This definition of loss is motivated by considerations of traffic with soft real-time constraints, where packets that are excessively delayed are worthless to the receiver. <p> The M=M=1=1 system was also investigated by Ferrandiz and Lazar <ref> [15] </ref> as a special case of their G=G=m=B analysis. Their analysis seems considerably more involved, does not readily yield numerical results and does not make use of the simple connection to the busy period pointed out here. <p> P [C B &gt; 1] = 1 P [C B = 1] = 1 1 + : Thus, P [C C = n] = n + 1 2n ! (1 + ) 2n ; n &gt; 0: Note that this result differs markedly from the geometric distribution postulated by Ferrandiz <ref> [15, Corollary 5.3] </ref>. <p> An additional characterization of loss periods is provided by the conditional probability of packet loss given that the previous packet was lost, denoted here by r. It is directly related to the average loss run length, E [C C ], through <ref> [15, eq. (5.1)] </ref> E [C C ] = 1 r r = 1 E [C C ] For the M=M=1 case, r = 1 + The clustering of losses in a queueing system is naturally also reflected in this measure.
Reference: [16] <author> E. A. van Doorn, </author> <title> "On the overflow process from a finite Markovian queue," </title> <journal> Performance Evaluation, </journal> <volume> vol. 4, </volume> <pages> pp. 233-240, </pages> <month> Nov. </month> <year> 1984. </year>
Reference-contexts: Van Doorn <ref> [16] </ref> and Meier-Hellstern [17,18] characterize the overflow process from a finite Markovian queueing system. As pointed out earlier, [11] underlines the importance of taking loss correlations into account, but investigates their effect on forward-error correction only through simulation.
Reference: [17] <author> K. S. Meier-Hellstern, </author> <title> "Parcel overflows in queues with multiple inputs," </title> <booktitle> in Proceedings of the 12th International Teletraffic Congress (ITC) (M. </booktitle> <editor> Bonatti, ed.), </editor> <address> (Torino, Italy), </address> <pages> pp. 1359-1366, </pages> <publisher> North-Holland, </publisher> <month> June </month> <year> 1988. </year>
Reference: [18] <author> K. S. Meier-Hellstern, </author> <title> "The analysis of a queue arising in overflow models," </title> <journal> IEEE Transactions on Communications, </journal> <volume> vol. 37, </volume> <pages> pp. 367-372, </pages> <month> Apr. </month> <year> 1989. </year>
Reference: [19] <author> S. Li, </author> <title> "Study of information loss in packet voice systems," </title> <journal> IEEE Transactions on Communications, </journal> <volume> vol. 37, </volume> <pages> pp. 1192-1202, </pages> <month> Nov. </month> <year> 1989. </year>
Reference-contexts: For an individual source, the probability of consecutive losses depends on its position within the bulk, which might be fixed, uniformly distributed or a time-varying stochastic process, depending on the buffer management policy. This system was treated extensively by Li <ref> [19] </ref>. Li defines as blocking those states where the buffer is full prior to service completion. We may also look at loss-correlation through a frequency-domain perspective. As an example, the first-order autocorrelation coefficient of intervals between losses was measured experimentally for a five-stage virtual circuit model with bounded waiting times. <p> For G=G=1 queues, a loss period is stochastically identical to a busy period with special first service. Busy periods with special (or exceptional) first service are covered by Wolff [23, p. 392-394]. The independence of the loss behavior from the threshold recalls a similar observation made by Li <ref> [19] </ref> regarding the buffer overflow process in a packet voice system. There, the time spent in the overload state was found to be independent of the buffer size. Let the random variable L denote the time duration of a loss period. <p> It seems natural to extend these results to finite queues in order to analyze periods of buffer overflow, as was done in <ref> [19] </ref> for a packet voice arrival process. For G=M=1 and D [Geo] =D=1 queues, a busy period can be regarded as a special case of a loss period. Thus, computation of the distribution of busy periods is of particular interest in studying loss phenomena.
Reference: [20] <author> J. P. C. Kleijnen, </author> <title> Statistical Tools for Simulation Practitioners. </title> <address> New York, NY: </address> <publisher> Marcel Dekker, </publisher> <year> 1987. </year>
Reference-contexts: We may also look at loss-correlation through a frequency-domain perspective. As an example, the first-order autocorrelation coefficient of intervals between losses was measured experimentally for a five-stage virtual circuit model with bounded waiting times. Using the von-Neumann statistic <ref> [20] </ref> as a robust estimator, it was found that the intervals between losses were essentially uncorrelated. Autocorrelation information might be useful in comparing different buffer management schemes or service disciplines, but cannot readily be used to predict the performance of packet reconstruction algorithms.
Reference: [21] <author> I. Cidon and I. S. Gopal, "PARIS: </author> <title> An approach to integrated high-speed private networks," </title> <journal> International Journal of Digital and Analog Cabled Networks, </journal> <volume> vol. 1, </volume> <pages> pp. 77-85, </pages> <month> April-June </month> <year> 1988. </year>
Reference-contexts: Their analysis seems considerably more involved, does not readily yield numerical results and does not make use of the simple connection to the busy period pointed out here. The model is applicable, if only in approximation, to systems with variable packet sizes, for example the PARIS network <ref> [21] </ref> or a variation of the Knockout switch [22].
Reference: [22] <author> K. Y. Eng, M. G. Hluchyj, and Y. S. Yeh, </author> <title> "A knockout switch for variable-length packets," </title> <booktitle> in Conference Record of the International Conference on Communications (ICC), </booktitle> <address> (Seattle, WA), </address> <pages> pp. 794-799, </pages> <publisher> IEEE, </publisher> <month> June </month> <year> 1987. </year>
Reference-contexts: The model is applicable, if only in approximation, to systems with variable packet sizes, for example the PARIS network [21] or a variation of the Knockout switch <ref> [22] </ref>.
Reference: [23] <author> R. W. Wolff, </author> <title> Stochastic Modeling and the Theory of Queues. </title> <address> Englewood Cliffs, NJ: </address> <publisher> Prentice Hall, </publisher> <year> 1989. </year>
Reference-contexts: The loss period distribution is independent of the threshold h. For G=G=1 queues, a loss period is stochastically identical to a busy period with special first service. Busy periods with special (or exceptional) first service are covered by Wolff <ref> [23, p. 392-394] </ref>. The independence of the loss behavior from the threshold recalls a similar observation made by Li [19] regarding the buffer overflow process in a packet voice system. There, the time spent in the overload state was found to be independent of the buffer size. <p> The pmf of the number of arrivals with interarrival density a (t) in an interval (0; t), given that an arrival occurred at 0 , is labeled P [C L = njt] and computed from standard renewal theory <ref> [23, p. 57] </ref> P [C L njt] = L 1 1 [A fl (s)] n = 0 where A fl (s) is the Laplace transform of the interarrival density a (t) and L 1 fg denotes the inverse Laplace transform.
Reference: [24] <author> L. </author> <title> Kleinrock, </title> <journal> Queueing Systems | Theory, </journal> <volume> vol. </volume> <pages> 1. </pages> <address> New York, NY: </address> <publisher> Wiley-Interscience, </publisher> <year> 1975. </year>
Reference-contexts: There, the time spent in the overload state was found to be independent of the buffer size. Let the random variable L denote the time duration of a loss period. Then, given Theorem 1, busy and loss periods for the M=M=1 queue have the density <ref> [24, p. 215] </ref> f L (y) = y p and mean E [L] = 1 1 ; where I 1 (y) is the modified Bessel function of the first kind of order one. The distribution is best computed by numerical integration. <p> Let us apply these results to the M=M=1 queue. With P [C B = n] given by <ref> [24, Eq. (5.157)] </ref> P [C B = n] = n 2n 2 we compute P [C B &gt; 1] = 1 P [C B = 1] = 1 1 + : Thus, P [C C = n] = n + 1 2n ! (1 + ) 2n ; n &gt; 0: <p> Because each customer occupies the server for one slot, duration and number of customers served are equal in the discrete-time case. For geometric batches 3 , we can compute the number of customers in a busy period by making use of Takacs combinatorial arguments [39, p. 102f], <ref> [24, p. 225f] </ref>. <p> The distribution of this "shortened" batch has the same distribution as a regular batch only if batches are geometrically distributed. For other batch distributions, the following calculations can serve as an approximation. 17 The probability mass function of the number served in a busy period is given by <ref> [24, Eq. (5.166)] </ref> P [B = n] = n For the case of deterministic service and batch size distribution a n , the probability on the right-hand side can be readily derived: P [ ~ A n = n 1] = P [n 1 arrivals in n slots] = a nfl <p> We recognize the last expression as the distribution of the number of customers served in an M=M=1 busy period <ref> [24, p. 218] </ref>. The z-transform of the number served in a busy period, B (z), follows from the M=M=1-derivation [24, p. 218]: B (z) = 2 1 1 (1 + ) 2 = p 2q The expected number served (and arriving) in a busy period can be computed by evaluating an <p> We recognize the last expression as the distribution of the number of customers served in an M=M=1 busy period <ref> [24, p. 218] </ref>. The z-transform of the number served in a busy period, B (z), follows from the M=M=1-derivation [24, p. 218]: B (z) = 2 1 1 (1 + ) 2 = p 2q The expected number served (and arriving) in a busy period can be computed by evaluating an infinite series using Eq. (11) or directly copying the M=M=1 result: E [B] = n=1 p 1 4pq 1 <p> The results for the loss period also follow naturally from the well-known relation <ref> [24] </ref> V (z) = B fl ( z), where V (z) is the z-transform of the probability distribution of the number of Poisson arrivals with rate during a time interval with Laplace transform B fl (). Also note the geometric form of the loss run distributions. <p> For the multi-server case where K &gt; c, P K;K is given by [44, p. 313] <ref> [24, p. 246] </ref>. Eq. (6.12) in [24] shows that the conditional loss probability r = fi 0 = 0 where fi n is the probability of serving n customers during an interarrival time given that all c servers remain busy during this interval. <p> For the multi-server case where K &gt; c, P K;K is given by [44, p. 313] [24, p. 246]. Eq. (6.12) in <ref> [24] </ref> shows that the conditional loss probability r = fi 0 = 0 where fi n is the probability of serving n customers during an interarrival time given that all c servers remain busy during this interval.
Reference: [25] <author> S. M. Ross, </author> <title> Stochastic Processes. </title> <address> New York, NY: </address> <publisher> John Wiley and Sons, </publisher> <year> 1983. </year>
Reference-contexts: Proof We prove the first, non-parenthesized part; the other proceeds similarly. Let the random variables X and Y denote a regular service time and an initial jump, respectively. From the coupling theorem (see <ref> [25, Proposition 8.2.2] </ref>), we know that if Y st X , then there exist random variables ~ X and ~ Y , with the same distributions as X and Y , such that ~ Y ~ X, i. e., P ( ~ Y ~ X) = 1. <p> Finally, we uncondition to make the result apply to any busy and loss period. Alternatively, we can argue by using <ref> [25, Example 8.2 (a)] </ref>, where it is shown that f (Y 1 ; : : : ; Y n ) st f (X 1 ; : : : ; X n ) for any increasing function f if Y i st X i and given that X 1 ; : : <p> Theorem 2 If the service time has decreasing failure rate (DFR), the loss period is stochastically longer than a busy period. Conversely, for service times with inreasing failure rate (IFR), the loss period is stochastically shorter than a busy period. Proof In <ref> [25, Proposition 8.1.3] </ref>, it is shown that iff X is DFR, then X t st X and iff X is IFR, then X t st X. This is true for any value of t.
Reference: [26] <author> L. </author> <title> Kleinrock, </title> <journal> Queueing Systems | Computer Applications, </journal> <volume> vol. </volume> <pages> 2. </pages> <address> New York, NY: </address> <publisher> Wiley-Interscience, </publisher> <year> 1976. </year>
Reference-contexts: It is conjectured that this property holds for general queueing systems. A possible justification can be sought in the exponential form of Kingman's approximation for the tail of the waiting time distribution <ref> [26, p. 45] </ref>. h initial jump loss period 0.0 1.000 5.00 0.5 0.588 2.93 2.0 0.483 2.39 5.0 0.465 2.31 Table 1: 2.3 Consecutive Customers Lost While the duration of a loss period is distributed like the duration of a busy period, we recall from Section 2.1 that the number of
Reference: [27] <author> N. U. Prabhu, </author> <title> Stochastic Storage Processes | Queues, Insurance Risk, </title> <booktitle> and Dams. Applications of Mathematics, </booktitle> <address> New York, NY: </address> <publisher> Springer-Verlag, </publisher> <year> 1980. </year>
Reference-contexts: Thus, the computation of this section will be limited to the M=G=1 model. Aspects of this problem or approximations of it appear in a number of applied stochastic models <ref> [27] </ref>. In collective risk theory [28] the insurance company starts out with some fixed capital, increasing through premiums at a constant rate and decreased (or increased) by claims occurring at Poisson instants. Of interest is the time until the capital reaches zero, that is, the company is ruined.
Reference: [28] <author> J. H. B. Kemperman, </author> <title> The Passage Problem for a Stationary Markov Chain. </title> <publisher> Chicago: University of Chicago Press, </publisher> <year> 1961. </year>
Reference-contexts: Thus, the computation of this section will be limited to the M=G=1 model. Aspects of this problem or approximations of it appear in a number of applied stochastic models [27]. In collective risk theory <ref> [28] </ref> the insurance company starts out with some fixed capital, increasing through premiums at a constant rate and decreased (or increased) by claims occurring at Poisson instants. Of interest is the time until the capital reaches zero, that is, the company is ruined.
Reference: [29] <author> P. A. P. Moran, </author> <title> "A probability theory of a dam with a continuous release," </title> <journal> The Quarterly Journal of Mathematics Oxford Second Series, </journal> <volume> vol. 7, </volume> <pages> pp. 130-137, </pages> <month> June </month> <year> 1956. </year>
Reference-contexts: It would give exact results, however, for t &lt; h since the system cannot have reached h by that time. We select a model involving an approximation that is based on the so-called Moran dam model <ref> [29, 30] </ref> [31, p. 336f] [32, p. 200]. In this model, the water content of a dam or reservoir is represented by a continuous or discrete-state, discrete-time homogeneous Markov process. For reasons of computability, we choose a discrete-state representation, yielding a discrete-time Markov chain (DTMC).
Reference: [30] <author> P. A. P. Moran, </author> <title> The Theory of Storage. </title> <booktitle> Methuen's Monographs on Applied Probability and Statistics, </booktitle> <address> London/New York, NY: Methuen/Wiley, </address> <year> 1959. </year>
Reference-contexts: It would give exact results, however, for t &lt; h since the system cannot have reached h by that time. We select a model involving an approximation that is based on the so-called Moran dam model <ref> [29, 30] </ref> [31, p. 336f] [32, p. 200]. In this model, the water content of a dam or reservoir is represented by a continuous or discrete-state, discrete-time homogeneous Markov process. For reasons of computability, we choose a discrete-state representation, yielding a discrete-time Markov chain (DTMC).
Reference: [31] <author> T. L. Saaty, </author> <title> Elements of Queueing Theory. </title> <address> New York, NY: </address> <publisher> Dover Publications (originally published by McGraw-Hill), 1983/1961. </publisher> <pages> 43 </pages>
Reference-contexts: It would give exact results, however, for t &lt; h since the system cannot have reached h by that time. We select a model involving an approximation that is based on the so-called Moran dam model [29, 30] <ref> [31, p. 336f] </ref> [32, p. 200]. In this model, the water content of a dam or reservoir is represented by a continuous or discrete-state, discrete-time homogeneous Markov process. For reasons of computability, we choose a discrete-state representation, yielding a discrete-time Markov chain (DTMC).
Reference: [32] <author> N. U. Prabhu, </author> <title> Queues and Inventories | A Study of Their Basic Stochastic Processes. </title> <address> New York, NY: </address> <publisher> John Wiley, </publisher> <year> 1965. </year>
Reference-contexts: It would give exact results, however, for t &lt; h since the system cannot have reached h by that time. We select a model involving an approximation that is based on the so-called Moran dam model [29, 30] [31, p. 336f] <ref> [32, p. 200] </ref>. In this model, the water content of a dam or reservoir is represented by a continuous or discrete-state, discrete-time homogeneous Markov process. For reasons of computability, we choose a discrete-state representation, yielding a discrete-time Markov chain (DTMC).
Reference: [33] <author> L. Takacs, </author> <title> Stochastic Processes | Problems and Solutions. </title> <address> London/New York, NY: Me-thuen/Wiley, </address> <year> 1960. </year>
Reference-contexts: can be evaluated as a special case of the general relationship for any functional f of a matrix, given by f (P) = Vf (fl)V 1 , where V is the matrix of eigenvectors of P and the function f is applied element-by-element to the diagonal matrix of eigenvalues fl <ref> [33, p. 8] </ref>. The eigenvalue approach may be more accurate for large values of n. The other alternative defines f (n) il as the probability that the system first enters state l after n steps, given the initial state is i.
Reference: [34] <author> S. Karlin and H. M. Taylor, </author> <title> A First Course in Stochastic Processes. </title> <address> San Diego, CA: </address> <publisher> Academic Press, </publisher> <editor> 2nd ed., </editor> <year> 1975. </year>
Reference-contexts: The transition probability matrix of the return process is derived from P by replacing the last row with all zeros, except for a one in column k 2. This relationship is derived in <ref> [34, p. 112, Problem 3] </ref> for the case of two absorbing states, but the result generalizes readily to any number of absorbing states (see also [35, p. 103]). For our example, the exact value of E [N ] is 6.388.
Reference: [35] <author> U. N. Bhat, </author> <title> Elements of Applied Stochastic Processes. </title> <address> New York, NY: </address> <publisher> John Wiley, </publisher> <editor> 2nd ed., </editor> <year> 1984. </year>
Reference-contexts: This relationship is derived in [34, p. 112, Problem 3] for the case of two absorbing states, but the result generalizes readily to any number of absorbing states (see also <ref> [35, p. 103] </ref>). For our example, the exact value of E [N ] is 6.388.
Reference: [36] <author> M. J. Karol, M. G. Hluchyj, and S. P. Morgan, </author> <title> "Input versus output queueing on a space-division packet switch," </title> <journal> IEEE Transactions on Communications, </journal> <volume> vol. COM-35, </volume> <pages> pp. 1347-1356, </pages> <month> Dec. </month> <year> 1987. </year>
Reference-contexts: 0.8170: : :0.8195 0.8162 14 0.8562: : :0.8659 0.8503: : :0.8556 0.8466: : :0.8488 0.8443 Table 4: Approximation of distribution of noloss period 15 16 3 Clip Loss in Discrete-time Systems We now turn our attention to a queueing model that is commonly used for packet switches and ATM-type networks <ref> [36, 37] </ref>. In this model, time is discretized, with deterministic service (of duration t = 1) and batch arrivals, which, in many instances, allow somewhat simpler solutions than their continuous-time counterparts. <p> This model is used to represent the output queue of a fast packet switch, for example [48]. The waiting time and loss probability for this model have been analyzed by a number of authors <ref> [49, 47, 36, 48, 50, 51, 1] </ref>. For Poisson-distributed batches, Birdsall et al. [49, p. 392] computes the conditional probability of a run of exactly n slots in which one or more arrivals are rejected given that an arrival was rejected in the preceding slot.
Reference: [37] <author> Y.-S. Yeh, M. G. Hluchyj, and A. S. Acampora, </author> <title> "The knockout switch: A simple, modular architecture for high-performance packet switching," </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> vol. SAC-5, </volume> <pages> pp. 1274-1282, </pages> <month> Oct. </month> <year> 1987. </year>
Reference-contexts: 0.8170: : :0.8195 0.8162 14 0.8562: : :0.8659 0.8503: : :0.8556 0.8466: : :0.8488 0.8443 Table 4: Approximation of distribution of noloss period 15 16 3 Clip Loss in Discrete-time Systems We now turn our attention to a queueing model that is commonly used for packet switches and ATM-type networks <ref> [36, 37] </ref>. In this model, time is discretized, with deterministic service (of duration t = 1) and batch arrivals, which, in many instances, allow somewhat simpler solutions than their continuous-time counterparts.
Reference: [38] <author> J. J. Hunter, </author> <title> Mathematical Techniques of Applied Probability Discrete Time Models: </title> <journal> Techniques and Applications, </journal> <volume> vol. </volume> <pages> 2. </pages> <address> New York, NY: </address> <publisher> Academic Press, </publisher> <year> 1983. </year>
Reference-contexts: Batches arrive at the beginning of a slot of unit width, while at most one customer departs at the end of a slot. (Hunter <ref> [38, p. 193] </ref> refers to this as an early arrival system.) We allow the batch size, A, to have a general distribution, but require the batch sizes to be independent from slot to slot and independent of the state of the queue itself. <p> This buffer policy will be referred to as rear dropping in section 6.2. Arbitrarily, arrivals are fixed to occur at the beginning of a time slot and departures at the end, creating, in Hunter's terminology <ref> [38] </ref>, an early arrival system. This model is used to represent the output queue of a fast packet switch, for example [48]. The waiting time and loss probability for this model have been analyzed by a number of authors [49, 47, 36, 48, 50, 51, 1]. <p> Note that q n , n = 1; 2; : : :, depends only through the factor q 0 on the buffer size, i.e., q n =q 0 is independent of the buffer size <ref> [38, p. 236] </ref>. For later use, let us compute the probability P [S] that one or more losses occurs during a randomly selected time slot. <p> We first need to establish the pmf of the system occupancy at batch arrival instants, V . A simple partial fraction expansion of the generating function V (z) (see <ref> [38, p. 278] </ref>), using A (z) = p=(1 qz), V (z) = A (z) z (1 ) ; yields the pmf P [V = v] = (1 )[ffi (v) + v+1 ]; where ffi () denotes the Kronecker delta.
Reference: [39] <author> L. Takacs, </author> <title> Combinatorial Methods in the Theory of Stochastic Processes. </title> <address> New York, NY: </address> <publisher> John Wiley, </publisher> <year> 1967. </year>
Reference-contexts: Because each customer occupies the server for one slot, duration and number of customers served are equal in the discrete-time case. For geometric batches 3 , we can compute the number of customers in a busy period by making use of Takacs combinatorial arguments <ref> [39, p. 102f] </ref>, [24, p. 225f].
Reference: [40] <author> P. A. P. Moran, </author> <title> An Introduction to Probability Theory. </title> <publisher> Oxford, </publisher> <address> Great Britain: </address> <publisher> Clarendon Press, </publisher> <year> 1968. </year>
Reference-contexts: to the one used to approximate the noloss period for the continuous-time case, Eq. (3), but since there are no departures when the system is empty, 5 For the tail of the loss-period, this random walk with drift and one absorbing barrier may be represented by the corresponding Brownian motion <ref> [40, p. 437] </ref>. 22 the first and second row are identical.
Reference: [41] <author> W. Feller, </author> <title> An Introduction to Probability Theory and Its Applications, </title> <booktitle> vol. 1. </booktitle> <address> New York, NY: </address> <publisher> John Wiley and Sons, </publisher> <editor> third ed., </editor> <year> 1968. </year>
Reference-contexts: However, an alternative approach exists <ref> [41, p. 425] </ref>. Let d j be the expected time to absorption into state 0, starting at state j.
Reference: [42] <author> H. Schulzrinne and J. F. Kurose, </author> <title> "Distribution of the loss period for some queues in continuous and discrete time," </title> <booktitle> in Proceedings of the Conference on Computer Communications (IEEE Infocom), </booktitle> <address> (Bal Harbour, FL), </address> <pages> pp. </pages> <address> 1446-1455 (12C.1), </address> <month> Apr. </month> <year> 1991. </year>
Reference: [43] <author> B. T. Doshi and H. Heffes, </author> <title> "Overload performance of several processor queueing disciplines for the M/M/1 queue," </title> <journal> IEEE Transactions on Communications, </journal> <volume> vol. COM-34, </volume> <pages> pp. 538-546, </pages> <month> June </month> <year> 1986. </year>
Reference-contexts: In this section, we consider the case when excessively delayed customers are dropped by the server. The queueing model with Poisson arrivals and exponential service was considered in <ref> [43] </ref> (called FIFO-TO there) and [2] (labelled FIFO-BW). <p> i.e., r = 1: P [W &lt; h] = 1 2 e -h c = 1 + c P [C L = n] = + c n c + c E [C L ] = r = 1 E [C C ] = + Note that the loss probability result <ref> [43] </ref> is only valid for the single-server case.
Reference: [44] <author> D. Gross and C. M. Harris, </author> <title> Fundamentals of Queueing Theory. </title> <address> New York, NY: </address> <publisher> John Wiley, </publisher> <editor> 2nd ed., </editor> <year> 1985. </year>
Reference-contexts: The conditional loss probability r can be read directly from the transition probability matrix P as r = P K;K : For the G=M=1=K queue, P is of dimension K + 1 by K + 1 <ref> [44, p. 305] </ref>: P = 6 6 6 6 4 1 i=0 b i b 1 b 0 : : : 0 P 2 : : : P K1 1 i=0 b i b K1 b K2 : : : b 0 7 7 7 7 5 Note that the two <p> For the multi-server case where K &gt; c, P K;K is given by <ref> [44, p. 313] </ref> [24, p. 246]. Eq. (6.12) in [24] shows that the conditional loss probability r = fi 0 = 0 where fi n is the probability of serving n customers during an interarrival time given that all c servers remain busy during this interval.
Reference: [45] <author> D. M. Lucantoni and S. P. Parekh, </author> <title> "Selective cell discard mechanisms for a B-ISDN congestion control architecture," </title> <booktitle> in International Teletraffic Congress, Seventh Specialist Seminar, </booktitle> <address> (Morristown, NJ), p. 10.3, ITC, </address> <month> Oct. </month> <year> 1990. </year>
Reference-contexts: that the distribution is in general not geometrically distributed as assumed in the Gilbert error model. 32 5.1 Effect of Service Order and Buffer Management on Buffer Loss Correlation The effect of buffer management on loss probabilities on delay and blocking probability of marked and unmarked traffic was considered by <ref> [45, 46] </ref>. Both papers hint at the issue of loss correlation, but do not elaborate further.
Reference: [46] <author> N. Yin and M. G. Hluchyj, </author> <title> "Implication of dropping packets from the front of a queue," </title> <booktitle> in International Teletraffic Congress, Seventh Specialist Seminar, </booktitle> <address> (Morristown, NJ), p. 10.4, ITC, </address> <month> Oct. </month> <year> 1990. </year>
Reference-contexts: that the distribution is in general not geometrically distributed as assumed in the Gilbert error model. 32 5.1 Effect of Service Order and Buffer Management on Buffer Loss Correlation The effect of buffer management on loss probabilities on delay and blocking probability of marked and unmarked traffic was considered by <ref> [45, 46] </ref>. Both papers hint at the issue of loss correlation, but do not elaborate further. <p> A loss run never straddles batch boundaries. For all four systems, indeed over all work-conserving disciplines, the queue state distribution (and, thus, the loss probability) are the same <ref> [52, 53, 46] </ref>. The mean waiting time results favoring front dropping agree with those of [46] for general queueing systems. Clare and Rubin [53] show that the minimum mean waiting time for non-lost packets is obtained using LCFS with front dropping (referred to as preemptive buffering in [53]). <p> A loss run never straddles batch boundaries. For all four systems, indeed over all work-conserving disciplines, the queue state distribution (and, thus, the loss probability) are the same [52, 53, 46]. The mean waiting time results favoring front dropping agree with those of <ref> [46] </ref> for general queueing systems. Clare and Rubin [53] show that the minimum mean waiting time for non-lost packets is obtained using LCFS with front dropping (referred to as preemptive buffering in [53]). For all systems, a batch arrival causes the same number of lost packets.
Reference: [47] <author> N. M. Dor, </author> <title> "Guide to the length of buffer storage required for random (Poisson) input and constant output rates," </title> <journal> IEEE Transactions on Electronic Computers, </journal> <volume> vol. EC-16, </volume> <pages> pp. 683-684, </pages> <month> Oct. </month> <year> 1967. </year> <month> 44 </month>
Reference-contexts: As our queueing model, we consider a FIFO single-server discrete-time queue where arrivals occur in i.i.d. batches of general distribution with mean batch size . Each arrival requires exactly one unit of service. For short, we will refer to this system as D [G] =D=1=K <ref> [47] </ref>. Let K denote the system size, that is, the buffer capacity plus one. Arrivals that do not find space are rejected, but once a customer enters the system, it will be served. This buffer policy will be referred to as rear dropping in section 6.2. <p> This model is used to represent the output queue of a fast packet switch, for example [48]. The waiting time and loss probability for this model have been analyzed by a number of authors <ref> [49, 47, 36, 48, 50, 51, 1] </ref>. For Poisson-distributed batches, Birdsall et al. [49, p. 392] computes the conditional probability of a run of exactly n slots in which one or more arrivals are rejected given that an arrival was rejected in the preceding slot.
Reference: [48] <author> M. G. Hluchyj and M. J. Karol, </author> <title> "Queueing in high-performance packet switching," </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> vol. SAC-6, </volume> <pages> pp. 1587-1597, </pages> <month> Dec. </month> <year> 1988. </year>
Reference-contexts: Arbitrarily, arrivals are fixed to occur at the beginning of a time slot and departures at the end, creating, in Hunter's terminology [38], an early arrival system. This model is used to represent the output queue of a fast packet switch, for example <ref> [48] </ref>. The waiting time and loss probability for this model have been analyzed by a number of authors [49, 47, 36, 48, 50, 51, 1]. <p> This model is used to represent the output queue of a fast packet switch, for example [48]. The waiting time and loss probability for this model have been analyzed by a number of authors <ref> [49, 47, 36, 48, 50, 51, 1] </ref>. For Poisson-distributed batches, Birdsall et al. [49, p. 392] computes the conditional probability of a run of exactly n slots in which one or more arrivals are rejected given that an arrival was rejected in the preceding slot. <p> For general batch size probability mass function (pmf) a k , the q k 's are described by the following recursive equations <ref> [48] </ref>: q 1 = a 0 q n = a 0 q n1 k=1 # q 0 = 1 n=1 " K1 X q n =q 0 The probability that a packet joins the queue, P [J], is given by P [J] = since 1 a 0 q 0 is the
Reference: [49] <author> T. G. Birdsall, M. P. Ristenbatt, and S. B. Weinstein, </author> <title> "Analysis of asynchronous time multiplexing of speech sources," </title> <journal> IRE Transactions on Communication Systems, </journal> <volume> vol. CS-10, </volume> <pages> pp. 390-397, </pages> <month> Dec. </month> <year> 1962. </year>
Reference-contexts: This model is used to represent the output queue of a fast packet switch, for example [48]. The waiting time and loss probability for this model have been analyzed by a number of authors <ref> [49, 47, 36, 48, 50, 51, 1] </ref>. For Poisson-distributed batches, Birdsall et al. [49, p. 392] computes the conditional probability of a run of exactly n slots in which one or more arrivals are rejected given that an arrival was rejected in the preceding slot. <p> This model is used to represent the output queue of a fast packet switch, for example [48]. The waiting time and loss probability for this model have been analyzed by a number of authors [49, 47, 36, 48, 50, 51, 1]. For Poisson-distributed batches, Birdsall et al. <ref> [49, p. 392] </ref> computes the conditional probability of a run of exactly n slots in which one or more arrivals are rejected given that an arrival was rejected in the preceding slot. We will call it P [C R = n]. <p> P [C R = n] = e (1 + ) 1 (1 + )e : Birdsall et al. <ref> [49, Eq. (11)] </ref> also compute the probability that exactly d arrivals are rejected in the next slot, provided that one or more was rejected in the previous slot. Their result is related to a relation we will derive later (Eq. (18)).
Reference: [50] <author> P. Tran-Gia and H. Ahmadi, </author> <title> "Analysis of a discrete-time G [X] =D=1 S queueing system with applications in packet-switching systems," </title> <booktitle> in Proceedings of the Conference on Computer Communications (IEEE Infocom), </booktitle> <address> (New Orleans), </address> <pages> pp. </pages> <address> 861-870 (9A.1), </address> <publisher> IEEE, </publisher> <month> Mar. </month> <year> 1988. </year>
Reference-contexts: This model is used to represent the output queue of a fast packet switch, for example [48]. The waiting time and loss probability for this model have been analyzed by a number of authors <ref> [49, 47, 36, 48, 50, 51, 1] </ref>. For Poisson-distributed batches, Birdsall et al. [49, p. 392] computes the conditional probability of a run of exactly n slots in which one or more arrivals are rejected given that an arrival was rejected in the preceding slot.
Reference: [51] <author> A. Y. M. Lin and J. A. Silvester, </author> <title> "Queueing analysis of an ATM switch with multichannel transmission groups," </title> <type> Tech. Rep. </type> <institution> CRI 89-25, Computer Engineering Division, Electrical Engineering-Systems Department, University of Southern California, </institution> <address> Los Angeles, CA, </address> <year> 1989. </year>
Reference-contexts: This model is used to represent the output queue of a fast packet switch, for example [48]. The waiting time and loss probability for this model have been analyzed by a number of authors <ref> [49, 47, 36, 48, 50, 51, 1] </ref>. For Poisson-distributed batches, Birdsall et al. [49, p. 392] computes the conditional probability of a run of exactly n slots in which one or more arrivals are rejected given that an arrival was rejected in the preceding slot.
Reference: [52] <author> L. P. Clare and I. Rubin, </author> <title> "On the design of prioritized multiplexing systems," </title> <booktitle> in Conference Record of the International Conference on Communications (ICC), </booktitle> <address> (Boston, MA), </address> <pages> pp. </pages> <address> 1344-1348 (E5.3), </address> <publisher> IEEE, </publisher> <month> June </month> <year> 1983. </year>
Reference-contexts: A loss run never straddles batch boundaries. For all four systems, indeed over all work-conserving disciplines, the queue state distribution (and, thus, the loss probability) are the same <ref> [52, 53, 46] </ref>. The mean waiting time results favoring front dropping agree with those of [46] for general queueing systems. Clare and Rubin [53] show that the minimum mean waiting time for non-lost packets is obtained using LCFS with front dropping (referred to as preemptive buffering in [53]).
Reference: [53] <author> L. P. Clare and I. Rubin, </author> <title> "Preemptive buffering disciplines for time-critical sensor communications," </title> <booktitle> in Conference Record of the International Conference on Communications (ICC), </booktitle> <address> (Toronto, Canada), </address> <pages> pp. 904-909, </pages> <publisher> IEEE, </publisher> <month> June </month> <year> 1986. </year> <month> 45 </month>
Reference-contexts: A loss run never straddles batch boundaries. For all four systems, indeed over all work-conserving disciplines, the queue state distribution (and, thus, the loss probability) are the same <ref> [52, 53, 46] </ref>. The mean waiting time results favoring front dropping agree with those of [46] for general queueing systems. Clare and Rubin [53] show that the minimum mean waiting time for non-lost packets is obtained using LCFS with front dropping (referred to as preemptive buffering in [53]). <p> For all four systems, indeed over all work-conserving disciplines, the queue state distribution (and, thus, the loss probability) are the same [52, 53, 46]. The mean waiting time results favoring front dropping agree with those of [46] for general queueing systems. Clare and Rubin <ref> [53] </ref> show that the minimum mean waiting time for non-lost packets is obtained using LCFS with front dropping (referred to as preemptive buffering in [53]). For all systems, a batch arrival causes the same number of lost packets. <p> The mean waiting time results favoring front dropping agree with those of [46] for general queueing systems. Clare and Rubin <ref> [53] </ref> show that the minimum mean waiting time for non-lost packets is obtained using LCFS with front dropping (referred to as preemptive buffering in [53]). For all systems, a batch arrival causes the same number of lost packets. If there are q packets in the buffer (0 q &lt; K) and a arrive in a batch, [(q + a) K] + will be lost.
References-found: 53

