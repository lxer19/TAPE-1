URL: http://www.cam.sri.com/people/milward/milcooperc94.ps.gz
Refering-URL: http://www.cam.sri.com/people/milward/
Root-URL: 
Email: davidm@cogsci.ed.ac.uk  
Title: INCREMENTAL INTERPRETATION: APPLICATIONS, THEORY, AND RELATIONSHIP TO DYNAMIC SEMANTICS semantic interpretation in human sentence processing
Author: David Milward Robin Cooper 
Address: 2, Buccleuch Place, Edinburgh, EH8 9LW, Scotland,  
Affiliation: Centre for Cognitive Science, University of Edinburgh  
Note: In Proceedings of the 15th International Conference on Computational Linguistics, Coling 94, Kyoto, Japan, pages 748-754.  APPLICATIONS Following the work of, for example, Marslen-Wilson (1973), Just and Carpenter (1980) and Altmann and Steedman (1988), it has become widely accepted that  are rejected, thereby pre This research was supported by the UK Science and Engineering Research Council, Research Grant RR30718.  Although the  
Abstract: Why should computers interpret language incrementally? In recent years psycholinguistic evidence for incremental interpretation has become more and more compelling, suggesting that humans perform semantic interpretation before constituent boundaries, possibly word by word. However, possible computational applications have received less attention. In this paper we consider various potential applications, in particular graphical interaction and dialogue. We then review the theoretical and computational tools available for mapping from fragments of sentences to fully scoped semantic representations. Finally, we tease apart the relationship between dynamic semantics and incremental interpretation. However, on-line semantic filtering for sentence processing does have drawbacks. Firstly, for sentence processing using a serial architecture (rather than one in which syntactic and semantic processing is performed in parallel), the savings in computation obtained from on-line filtering have to be balanced against the additional costs of performing semantic computations for parses of fragments which would eventually be ruled out anyway from purely syntactic considerations. Moreover, there are now relatively sophisticated ways of packing ambiguities during parsing (e.g. by the use of graph-structured stacks and packed parse forests (Tomita 1985)). Secondly, the task of judging plausibility or anomaly according to context and real world knowledge is a difficult problem, except in some very limited domains. In contrast, statistical techniques using lexeme co-occurrence provide a relatively simple mechanism which can imitate semantic filtering in many cases. For example, instead of judging bank as a financial institution as more plausible than bank as a riverbank in the noun phrase the rich bank, we can compare the number of co-occurrences of the lexemes rich and bank 1 (= riverbank) versus rich and bank 2 (= financial institution) in a semantically analysed corpus. Cases where statistical techniques seem less appropriate are where plausibility is affected by local context. For example, consider the ambiguous sentence, The decorators painted a wall with cracks in the two contexts The room was supposed to look run-down vs. The clients couldn't afford wallpaper. Such cases involve reasoning with an interpretation in its immediate context, as opposed to purely judging the likelihood of a particular linguistic expression in a given application domain (see e.g. Cooper 1993 for discussion). The concentration in early literature on using incremental interpretation for semantic filtering has perhaps distracted from some other applications which provide less controversial applications. We will con 
Abstract-found: 1
Intro-found: 1
Reference: <author> Alshawi, H. </author> <year> (1990). </year> <title> Resolving Quasi Logical Forms. </title> <journal> Computational Linguistics, </journal> <volume> 16, </volume> <month> p.133-144. </month>
Reference-contexts: Again the problem can be avoided by a form of packing. A particularly simple way of doing this is to use unscoped logical forms where quantifiers are left in situ (similar to the representations used by Hobbs and Shieber (1987), or to Quasi Logical Form <ref> (Alshawi 1990) </ref>). For example, the fragment Every man gives a book can be given the following representation: 11) z.gives (&lt; 8,x,man (x)&gt;,&lt; 9,y,book (y)&gt;,z) Each quantified term consists of a quantifier, a variable and a restrictor, but no body.
Reference: <author> Altmann, G.T.M. and M.J. </author> <title> Steedman (1988). Interaction with Context during Human Speech Comprehension. </title> <journal> Cognition, </journal> <volume> 30, </volume> <month> p.191-238. </month>
Reference: <author> Barwise, J. </author> <year> (1987). </year> <title> Noun Phrases, Generalized Quantifiers and Anaphors. </title> <editor> In P. Gardenfors, Ed., </editor> <title> Generalized Quantifiers, </title> <publisher> p.1-29, Dordrecht: Reidel. </publisher>
Reference-contexts: This intuitive evidence can be backed up by considering garden path effects with quantifier scope ambiguities <ref> (called jungle paths by Barwise 1987) </ref>. The original examples, such as the following, 9) Statistics show that every 11 seconds a man is mugged here in New York city. We are here today to interview him showed that preferences for a particular scope are established and are overturned.
Reference: <author> Carletta, J., R. Caley and S. </author> <title> Isard (1993). A Collection of Self-repairs from the Map Task Corpus. </title> <type> Research Report, </type> <institution> HCRC/TR-47, University of Edinburgh. </institution>
Reference: <author> Chater, N., M.J. Pickering and D.R. </author> <title> Milward (1994). What is Incremental Interpretation? ms. </title> <note> To appear in Edinburgh Working Papers in Cognitive Science. </note>
Reference: <author> Cooper, R. </author> <year> (1993). </year> <title> A Note on the Relationship between Linguistic Theory and Linguistic Engineering. </title> <type> Research Report, </type> <institution> HCRC/RP-42, University of Edinburgh. </institution>
Reference-contexts: The clients couldn't afford wallpaper. Such cases involve reasoning with an interpretation in its immediate context, as opposed to purely judging the likelihood of a particular linguistic expression in a given application domain <ref> (see e.g. Cooper 1993 for discussion) </ref>. Although the usefulness of on-line semantic filtering during the processing of complete sentences is debatable, filtering has a more plausible role to play in interactive, real-time environments, such as interactive spell checkers (see e.g. Wiren (1990) for arguments for incremental parsing in such environments).
Reference: <author> Frazier, L. </author> <year> (1979). </year> <title> On Comprehending Sentences: Syntactic Parsing Strategies. </title> <type> Ph.D. Thesis, </type> <institution> University of Connecticut. </institution> <note> Published by Indiana University Linguistics Club. </note>
Reference-contexts: Although some of the parses can be ruled out using structural preferences during parsing (such as Late Closure or Minimal Attachment <ref> (Frazier 1979) </ref>), extraction of the correct set of plausible readings requires use of real world knowledge.
Reference: <author> Groenendijk, J. and M. </author> <title> Stokhof (1991). Dynamic Predicate Logic. </title> <journal> Linguistics and Philosophy, </journal> <volume> 14, </volume> <month> p.39-100. </month>
Reference-contexts: DYNAMIC SEMANTICS Dynamic semantics adopts the view that "the meaning of a sentence does not lie in its truth conditions, but rather in the way in which it changes (the representation of) the information of the interpreter" <ref> (Groenendijk and Stokhof, 1991) </ref>. At first glance such a view seems ideally suited to incremental interpretation. <p> In contrast, in dynamic semantics, the order in which states are updated is determined by semantic structure, not by left-to-right order (see e.g. Lewin, 1992 for discussion). For example, in Dynamic Predicate Logic <ref> (Groenendijk & Stokhof, 1991) </ref>, states are threaded from the antecedent of a conditional into the consequent, and from a restrictor of a quantifier into the body.
Reference: <author> Gross, D., J. Allen and D. </author> <title> Traum (1993). The TRAINS 91 Dialogues. </title> <type> TRAINS Technical Note 92-1, </type> <institution> Computer Science Dept., University of Rochester. </institution>
Reference-contexts: A more compelling argument for incremental interpretation is provided by considering dialogues involving interruptions. Consider the following dialogue from the TRAINS corpus <ref> (Gross et al., 1993) </ref>: 5) A: so we should move the engine at Avon, engine E, to ... B: engine E1 A: E1 B: okay A: engine E1, to Bath ...
Reference: <author> Haddock, N.J. </author> <year> (1987). </year> <title> Incremental semantic interpretation and incremental syntactic analysis. </title> <type> Ph.D. Thesis, </type> <institution> University of Edinburgh. </institution>
Reference: <author> Haddock, N.J. </author> <year> (1989). </year> <title> Computational Models of Incremental Semantic Interpretation. </title> <booktitle> Language and Cognitive Processes, </booktitle> <volume> 4, </volume> <pages> (3/4), </pages> <note> Special Issue, p.337-368. </note>
Reference: <author> Hobbs, J.R. </author> <title> and S.M. Shieber (1987). An Algorithm for Generating Quantifier Scoping. </title> <journal> Computational Linguistics, </journal> <volume> 3, </volume> <month> p47-63. </month>
Reference-contexts: In this case we obtain: 12) gives (&lt; 8,x,man (x)&gt;,&lt; 9,y,book (y)&gt;,&lt; 9,z,T&gt;) Scoped propositions can then be obtained by using an outside-in quantifier scoping algorithm (Lewin, 1990), or an inside-out algorithm with a free variable constraint <ref> (Hobbs and Shieber, 1987) </ref>. The propositions formed can then be judged for plausibility. To imitate jungle path phenomena, these plausibility judgements need to feed back into the scoping procedure for the next fragment.
Reference: <author> Joshi, A.K. </author> <year> (1987). </year> <title> An Introduction to Tree Adjoining Grammars. </title> <editor> In Manaster-Ramer, Ed., </editor> <booktitle> Mathematics of Language, </booktitle> <address> Amsterdam: </address> <publisher> John Benjamins. </publisher>
Reference-contexts: A second possibility is to factor out recursive structures from a grammar. Thompson et al. (1991) show how this can be done for a phrase structure grammar (creating an equivalent Tree Adjoining Grammar <ref> (Joshi 1987) </ref>). The parser for the resulting grammar allows linear parsing for an (infinitely) parallel system, with the absorption of each word performed in constant time.
Reference: <author> Just, M. and P. </author> <title> Carpenter (1980). A Theory of Reading from Eye Fixations to Comprehension. </title> <journal> Psychological Review, </journal> <volume> 87, </volume> <month> p.329-354. </month>
Reference: <author> Kurtzman, H.S. and M.C. </author> <title> MacDonald (1993). Resolution of Quantifier Scope Ambiguities. </title> <journal> Cognition, </journal> <volume> 48(3), </volume> <month> p.243-279. </month>
Reference: <author> Lewin, I. </author> <year> (1990). </year> <title> A Quantifier Scoping Algorithm without a Free Variable Constraint. </title> <booktitle> In Proceedings of COLING 90, Helsinki, </booktitle> <volume> vol 3, </volume> <month> p.190-194. </month>
Reference-contexts: To convert lambda expressions to unscoped propositions, we replace an occurrence of each argument with an empty existen tial quantifier term. In this case we obtain: 12) gives (&lt; 8,x,man (x)&gt;,&lt; 9,y,book (y)&gt;,&lt; 9,z,T&gt;) Scoped propositions can then be obtained by using an outside-in quantifier scoping algorithm <ref> (Lewin, 1990) </ref>, or an inside-out algorithm with a free variable constraint (Hobbs and Shieber, 1987). The propositions formed can then be judged for plausibility. To imitate jungle path phenomena, these plausibility judgements need to feed back into the scoping procedure for the next fragment.
Reference: <author> Lewin, I. </author> <year> (1992). </year> <title> Dynamic Quantification in Logic and Computational Semantics. </title> <type> Research report, </type> <institution> Centre for Cognitive Science, University of Edinburgh. </institution>
Reference-contexts: In an incremental semantics, we would expect the information state of an interpreter to be updated word by word. In contrast, in dynamic semantics, the order in which states are updated is determined by semantic structure, not by left-to-right order <ref> (see e.g. Lewin, 1992 for discussion) </ref>. For example, in Dynamic Predicate Logic (Groenendijk & Stokhof, 1991), states are threaded from the antecedent of a conditional into the consequent, and from a restrictor of a quantifier into the body.
Reference: <author> Levelt, W.J.M. </author> <year> (1983). </year> <title> Modelling and Self-Repair in Speech. </title> <journal> Cognition, </journal> <volume> 14, </volume> <month> p.41-104. </month>
Reference-contexts: For example, if sets of possible referents for a definite noun phrase are highlighted during word by word processing then the user knows how much or how little information is required for successful reference. 2 Human dialogue, in particular, task oriented dialogue is characterised by a large numbers of self-repairs <ref> (Levelt 1983, Carletta et al. 1993) </ref>, such as hesitations, insertions, and replacements. It is also common to find interruptions requesting extra clarification, or disagreements before the end of a sentence. It is even possible for sentences started by one dialogue participant to be finished by another.
Reference: <author> Marcus, M., D. Hindle, and M. </author> <title> Fleck (1983). D-Theory: Talking about Talking about Trees. </title> <booktitle> In Proceedings of the 21st ACL, </booktitle> <address> Cambridge, Mass. p.129-136. </address>
Reference-contexts: There are several possibilities. The first is to use a language describing trees where we can express the fact that John is dominated by the s node, but do not have to specify what it is immediately dominated by <ref> (e.g. D-Theory, Marcus et al. 1983) </ref>. Semantic representations could be formed word by word by extracting `default' syntax trees (by strengthening dominance links into immediated dominance links wherever possible). A second possibility is to factor out recursive structures from a grammar.
Reference: <author> Marslen-Wilson, W. </author> <year> (1973). </year> <title> Linguistic Structure and Speech Shadowing at Very Short Latencies. </title> <journal> Nature, </journal> <volume> 244, </volume> <month> p.522-523. </month>
Reference: <author> Mellish, C.S. </author> <year> (1985). </year> <title> Computer Interpretation of Natural Language Descriptions. </title> <address> Chichester: </address> <publisher> Ellis Horwood. </publisher>
Reference: <author> Milward, D.R. </author> <year> (1991). </year> <title> Axiomatic Grammar, Non-Constituent Coordination, and Incremental Interpretation. </title> <type> Ph.D. Thesis, </type> <institution> University of Cambridge. </institution>
Reference: <author> Milward, D.R. </author> <year> (1992). </year> <title> Dynamics, Dependency Grammar and Incremental Interpretation. </title> <booktitle> In Proceedings of COL-ING 92, Nantes, </booktitle> <volume> vol 4, </volume> <month> p.1095-1099. </month>
Reference-contexts: Every parent shows it ... We assume that the first sentence has been processed, and concentrate on processing the fragment. The implementation consists of five modules: 1. A word-by-word incremental parser for a lex-icalised version of dependency grammar <ref> (Milward, 1992) </ref>. This takes fragments of sentences and maps them to unscoped logical forms. INPUT: Every parent shows it OUTPUT: z.show (&lt; 8,x,parent (x)&gt;,&lt;pronoun,y&gt;,z) 2. A module which replaces lambda abstracted variables with existential quantifiers in situ. INPUT: Output from 1. OUTPUT: show (&lt; 8,x,parent (x)&gt;,&lt;pronoun,y&gt;,&lt; 9,z,T&gt;) 3.
Reference: <author> Moortgat, M. </author> <year> (1988). </year> <title> Categorial Investigations: Logical and Linguistic Aspects of the Lambek Calculus, </title> <publisher> Dordrecht: Foris. </publisher>
Reference: <author> Pulman, S.G. </author> <year> (1986). </year> <title> Grammars, Parsers, and Memory Limitations. </title> <booktitle> Language and Cognitive Processes, </booktitle> <volume> 1(3), </volume> <month> p.197-225. </month>
Reference: <author> Resnik, P. </author> <year> (1992). </year> <title> Left-corner Parsing and Psychological Plausibility. </title> <booktitle> In Proceedings of COLING 92, Nantes, </booktitle> <volume> vol 1, </volume> <month> p.191-197. </month>
Reference-contexts: A complete incremental parser, which is not fully word by word, was proposed by Pulman (1986). This is based on arc-eager left-corner parsing <ref> (see e.g. Resnik 1992) </ref>. To enable complete, fully word by word parsing requires a way of encoding an infinite number of partial trees. There are several possibilities.
Reference: <author> Shieber, S.M. and M. </author> <title> Johnson (1993). Variations on Incremental Interpretation. </title> <journal> Journal of Psycholinguistic Research, </journal> <volume> 22(2), </volume> <month> p.287-318. </month>
Reference: <author> Shieber, S.M. and Y. </author> <month> Schabes </month> <year> (1990). </year> <title> Synchronous Tree-Adjoining Grammars. </title> <booktitle> In Proceedings of COLING 90, Helsinki, </booktitle> <volume> vol 3, </volume> <month> p.253-258. </month>
Reference-contexts: John could also be embedded within a sentence which has a sentence modifier requiring its own s node e.g. Mary thinks John will go home probably 5 , and this can be further embedded 4 The downarrow notation for missing constituents is adopted from Synchronous Tree Adjoining Grammar <ref> (Shieber & Schabes 1990) </ref>. 5 The treatment of probably as a modifier of a sentence is perhaps controversial. However, treatment of it as a verb phrase modifier would merely shift the potential left recursion e.g. Mary thinks John will go home probably because he is tired.
Reference: <author> Stabler, E.P. </author> <year> (1991). </year> <title> Avoid the pedestrian's paradox. </title> <editor> In R. Berwick, S. Abney, and C. Tenny, Eds., </editor> <title> Principle-Based Parsing: Computation and Psycholinguistics. </title> <publisher> Kluwer. </publisher>
Reference: <author> Steedman, M. </author> <year> (1988). </year> <title> Combinators and Grammars. </title> <editor> In R. Oehrle et al., Eds., </editor> <title> Categorial Grammars and Natural Language Structures, </title> <publisher> p.417-442. </publisher>
Reference: <author> Thompson, H., M. Dixon, and J. </author> <title> Lamping (1991). </title> <booktitle> Compose-Reduce Parsing. In Proceedings of the 29th ACL, </booktitle> <address> p.87-97. </address>
Reference: <author> Tomita, M. </author> <year> (1985). </year> <title> Efficient Parsing for Natural Language. </title> <publisher> Kluwer. </publisher>
Reference-contexts: Moreover, there are now relatively sophisticated ways of packing ambiguities during parsing (e.g. by the use of graph-structured stacks and packed parse forests <ref> (Tomita 1985) </ref>). Secondly, the task of judging plausibility or anomaly according to context and real world knowledge is a difficult problem, except in some very limited domains. In contrast, statistical techniques using lexeme co-occurrence provide a relatively simple mechanism which can imitate semantic filtering in many cases.
Reference: <author> Veltman F. </author> <year> (1990). </year> <title> Defaults in Update Semantics. </title> <editor> In H. Kamp, Ed., </editor> <title> Conditionals, Defaults and Belief Revision, </title> <type> DYANA Report 2.5.A, </type> <institution> Centre for Cognitive Science, University of Edinburgh. </institution>
Reference-contexts: For exam ple, if (17) is converted into the `donkey' sentence: 18) Every man who loves a woman who lives with him appreciates her When we consider threading of possible worlds, as in Update Semantics <ref> (Veltman 1990) </ref>, the need to distinguish between the order of evaluation and the order of presentation becomes more clear cut. Consider trying to perform threading in left-to-right order during interpretation of the sentence, John left if Mary left.
Reference: <author> Wiren, M. </author> <year> (1990). </year> <title> Incremental Parsing and Reason Maintenance. </title> <booktitle> In Proceedings of COLING 90, Helsinki, </booktitle> <volume> vol 3, </volume> <month> p.287-292. </month>
Reference: <author> Zeevat, H. </author> <year> (1990). </year> <title> Static Semantics. </title> <editor> In J. van Benthem, Ed., </editor> <title> Partial and Dynamic Semantics I, </title> <type> DYANA Report 2.1.A, </type> <institution> Centre for Cognitive Science, University of Edinburgh. </institution> <month> 7 </month>
References-found: 35

