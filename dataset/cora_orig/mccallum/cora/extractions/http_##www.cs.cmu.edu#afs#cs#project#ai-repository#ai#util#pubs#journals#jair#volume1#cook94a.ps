URL: http://www.cs.cmu.edu/afs/cs/project/ai-repository/ai/util/pubs/journals/jair/volume1/cook94a.ps
Refering-URL: http://www.cs.cmu.edu/afs/cs/project/ai-repository/ai/util/pubs/journals/jair/volume1/
Root-URL: http://www.cs.cmu.edu
Email: cook@cse.uta.edu  holder@cse.uta.edu  
Title: Substructure Discovery Using Minimum Description Length and Background Knowledge  
Author: Diane J. Cook Lawrence B. Holder 
Address: Box 19015  Arlington, TX 76019 USA  
Affiliation: Department of Computer Science Engineering  University of Texas at Arlington  
Note: Journal of Artificial Intelligence Research 1 (1994) 231-255 Submitted 12/93; published 2/94  
Abstract: The ability to identify interesting and repetitive substructures is an essential component to discovering knowledge in structural data. We describe a new version of our Subdue substructure discovery system based on the minimum description length principle. The Subdue system discovers substructures that compress the original data and represent structural concepts in the data. By replacing previously-discovered substructures in the data, multiple passes of Subdue produce a hierarchical description of the structural regularities in the data. Subdue uses a computationally-bounded inexact graph match that identifies similar, but not identical, instances of a substructure and finds an approximate measure of closeness of two substructures when under computational constraints. In addition to the minimum description length principle, other background knowledge can be used by Subdue to guide the search towards more appropriate substructures. Experiments in a variety of domains demonstrate Subdue's ability to find substructures capable of com pressing the original data and to discover structural concepts important to the domain.
Abstract-found: 1
Intro-found: 1
Reference: <author> Bunke, H., & Allermann, G. </author> <year> (1983). </year> <title> Inexact graph matching for structural pattern recognition. </title> <journal> Pattern Recognition Letters, </journal> <volume> 1 (4), </volume> <pages> 245-253. </pages>
Reference-contexts: Furthermore, we want to associate a distance measure between a pair of graphs consisting of a given substructure and a subgraph of the input graph. We adopt the approach to inexact graph match given by Bunke and Allermann <ref> (Bunke & Allermann, 1983) </ref>. 238 Substructure Discovery In this inexact match approach, each distortion of a graph is assigned a cost. A distortion is described in terms of basic transformations such as deletion, insertion, and substitution of vertices and edges.
Reference: <author> Cheeseman, P., Kelly, J., Self, M., Stutz, J., Taylor, W., & Freeman, D. </author> <year> (1988). </year> <title> Autoclass: A bayesian classification system. </title> <booktitle> In Proceedings of the Fifth International Workshop on Machine Learning, </booktitle> <pages> pp. 54-64. </pages>
Reference-contexts: Once a substructure is discovered, instances of the substructure can be replaced by the concept definition, affording compression of the data description and providing a basis for discovering hierarchically-defined structures. Future work will combine structural discovery with discovery of concepts using a linear-based representation such as AutoClass <ref> (Cheeseman, Kelly, Self, Stutz, Taylor, & Freeman, 1988) </ref>. In particular, we will use Subdue to compress the data fed to AutoClass, and let Subdue evaluate the interesting structures in the classes generated by AutoClass.
Reference: <author> Conklin, D., & Glasgow, J. </author> <year> (1992). </year> <title> Spatial analogy and subsumption. </title> <booktitle> In Proceedings of the Ninth International Machine Learning Workshop, </booktitle> <pages> pp. 111-116. </pages>
Reference-contexts: The upper-level components of the structured-object hierarchy produced by Labyrinth represent substructures common to the examples. Therefore, although not the primary focus, Labyrinth is discovering substructure, but in a more constrained context than the general graph representation used by Subdue. Conklin et al. <ref> (Conklin & Glasgow, 1992) </ref> have developed the i-mem system for constructing an image hierarchy, similar to that of Labyrinth, used for discovering common substructures in a set of images and for efficient retrieval of images similar to a given image. <p> This same view can be constructed by Subdue using multiple passes over the graph after replacing portions of the input graph with substructures discovered during previous passes. i-mem has performed well in a simple chess domain and molecular chemistry domains <ref> (Conklin & Glasgow, 1992) </ref>. However, i-mem requires domain-specific relations for expressing images in order for the hierarchy to find relevant substructures and for image matching to be efficient.
Reference: <author> Derthick, M. </author> <year> (1991). </year> <title> A minimal encoding approach to feature discovery. </title> <booktitle> In Proceedings of the Ninth National Conference on Artificial Intelligence, </booktitle> <pages> pp. 565-571. </pages>
Reference-contexts: The MDL principle has been used for decision tree induction (Quinlan & Rivest, 1989), image processing (Pednault, 1989; Pentland, 1989; Leclerc, 1989), concept learning from relational data <ref> (Derthick, 1991) </ref>, and learning models of non-homogeneous engineering domains (Rao & Lu, 1992). We demonstrate how the minimum description length principle can be used to discover substructures in complex data.
Reference: <author> Fisher, D. H. </author> <year> (1987). </year> <title> Knowledge acquisition via incremental conceptual clustering. </title> <journal> Machine Learning, </journal> <volume> 2 (2), </volume> <pages> 139-172. </pages>
Reference-contexts: As with Levin-son's approach, graphs are processed incrementally, and substructure is found across several graphs, not within a single graph as in Subdue. The Labyrinth system (Thompson & Langley, 1991) extends the Cobweb incremental conceptual clustering system <ref> (Fisher, 1987) </ref> to handle structured objects. Labyrinth uses Cobweb to form hierarchical concepts of the individual objects in the domain based on their primitive attributes. Concepts of structured objects are formed in a similar manner using the individual objects as attributes.
Reference: <author> Fu, K. S. </author> <year> (1982). </year> <title> Syntactic Pattern Recognition and Applications. </title> <publisher> Prentice-Hall. </publisher>
Reference: <author> Holder, L. B., Cook, D. J., & Bunke, H. </author> <year> (1992). </year> <title> Fuzzy substructure discovery. </title> <booktitle> In Proceedings of the Ninth International Machine Learning Conference, </booktitle> <pages> pp. 218-223. </pages> <note> 253 Cook & Holder Holder, </note> <author> L. B., & Cook, D. J. </author> <year> (1993). </year> <title> Discovery of inexact concepts from structural data. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 5 (6), </volume> <pages> 992-994. </pages>
Reference: <author> Jeltsch, E., & Kreowski, H. J. </author> <year> (1991). </year> <title> Grammatical inference based on hyperedge replacement. </title> <booktitle> In Fourth International Workshop on Graph Grammars and Their Application to Computer Science, </booktitle> <pages> pp. 461-474. </pages>
Reference-contexts: The approach begins with a set of sample graphs and produces a generalized graph grammar capable of deriving the original sample graphs and many others. The production rules of this general grammar capture regularities (substructures) in the sample graphs. Jeltsch and Kreowski <ref> (Jeltsch & Kreowski, 1991) </ref> describe an approach that begins with a maximally-specific grammar and iteratively identifies common subgraphs in the right-hand sides of the production rules. These common subgraphs are used to form 235 Cook & Holder new, more general production rules.
Reference: <author> Leclerc, Y. G. </author> <year> (1989). </year> <title> Constructing simple stable descriptions for image partitioning. </title> <journal> International journal of Computer Vision, </journal> <volume> 3 (1), </volume> <pages> 73-102. </pages>
Reference: <author> Levinson, R. </author> <year> (1984). </year> <title> A self-organizing retrieval system for graphs. </title> <booktitle> In Proceedings of the Second National Conference on Artificial Intelligence, </booktitle> <pages> pp. 203-206. </pages>
Reference-contexts: For instance, the sequence discovery method looks for supported-by and in-front-of relations only. Subdue's substructure discovery method is domain independent, although the inclusion of domain-specific knowledge would improve Subdue's performance. Motivated by the need to construct a knowledge base of chemical structures, Levinson <ref> (Levinson, 1984) </ref> developed a system for storing labeled graphs in which individual graphs 233 Cook & Holder are represented by the set of vertices in a universal graph.
Reference: <author> Michalski, R. S., & Stepp, R. E. </author> <year> (1983). </year> <title> Learning from observation: Conceptual clustering. </title>
Reference-contexts: The coverage rule is motivated from research in inductive learning and provides that concept descriptions describing more input examples are considered better <ref> (Michalski & Stepp, 1983) </ref>. Although MDL measures the amount of structure, the coverage rule includes the relevance of this savings with respect to the size of the entire input graph.
Reference: <editor> In Michalski, R. S., Carbonell, J. G., & Mitchell, T. M. (Eds.), </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach, </booktitle> <volume> Vol. I, </volume> <pages> pp. 331-363. </pages> <publisher> Tioga Publishing Company. </publisher>
Reference: <author> Miclet, L. </author> <year> (1986). </year> <title> Structural Methods in Pattern Recognition. </title> <publisher> Chapman and Hall. </publisher>
Reference: <author> Pednault, E. P. D. </author> <year> (1989). </year> <title> Some experiments in applying inductive inference principles to surfa ce reconstruction. </title> <booktitle> In Proceedings of the International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. 1603-1609. </pages>
Reference: <author> Pentland, A. </author> <year> (1989). </year> <title> Part segmentation for object recognition. </title> <journal> Neural Computation, </journal> <volume> 1, </volume> <pages> 82-91. </pages>
Reference: <author> Prather, R. </author> <year> (1976). </year> <title> Discrete Mathemetical Structures for Computer Science. </title> <publisher> Houghton Miffin Company. </publisher>
Reference-contexts: The first rule, compactness, is a generalization of Wertheimer's Factor of Closure, which states that human attention is drawn to closed structures (Wertheimer, 1939). A closed substructure has at least as many edges as vertices, whereas a non-closed substructure has fewer edges than vertices <ref> (Prather, 1976) </ref>. Thus, closed substructures have a higher compactness value.
Reference: <author> Quinlan, J. R., & Rivest, R. L. </author> <year> (1989). </year> <title> Inferring decision trees using the minimum description length principle. </title> <journal> Information and Computation, </journal> <volume> 80, </volume> <pages> 227-248. </pages>
Reference-contexts: The MDL principle has been used for decision tree induction <ref> (Quinlan & Rivest, 1989) </ref>, image processing (Pednault, 1989; Pentland, 1989; Leclerc, 1989), concept learning from relational data (Derthick, 1991), and learning models of non-homogeneous engineering domains (Rao & Lu, 1992). We demonstrate how the minimum description length principle can be used to discover substructures in complex data. <p> Therefore, a typical row in the adjacency matrix will have much fewer than v 1s, where v is the total number of vertices in the graph. We apply a variant of the coding scheme used by <ref> (Quinlan & Rivest, 1989) </ref> to encode bit strings with length n consisting of k 1s and (n k) 0s, where k t (n k). In our case, row i (1 i v) can be represented as a bit string of length v containing k i 1s.
Reference: <author> Rao, R. B., & Lu, S. C. </author> <year> (1992). </year> <title> Learning engineering models with the minimum description length principle. </title> <booktitle> In Proceedings of the Tenth National Conference on Artificial Intelligence, </booktitle> <pages> pp. 717-722. </pages>
Reference-contexts: The MDL principle has been used for decision tree induction (Quinlan & Rivest, 1989), image processing (Pednault, 1989; Pentland, 1989; Leclerc, 1989), concept learning from relational data (Derthick, 1991), and learning models of non-homogeneous engineering domains <ref> (Rao & Lu, 1992) </ref>. We demonstrate how the minimum description length principle can be used to discover substructures in complex data. In particular, a substructure is evaluated based on how well it can compress the entire dataset using the minimum description length.
Reference: <author> Rissanen, J. </author> <year> (1989). </year> <title> Stochastic Complexity in Statistical Inquiry. </title> <publisher> World Scientific Publishing Company. </publisher>
Reference-contexts: Furthermore, the graph grammar production-rule may provide a suitable representation for background knowledge during the substructure discovery process. 4. Minimum Description Length Encoding of Graphs The minimum description length principle (MDLP) introduced by Rissanen <ref> (Rissanen, 1989) </ref> states that the best theory to describe a set of data is that theory which minimizes the description length of the entire data set.
Reference: <author> Schalkoff, R. J. </author> <year> (1992). </year> <title> Pattern Recognition: Statistical, Structural and Neural Approaches. </title> <publisher> John Wiley & Sons. </publisher>
Reference-contexts: These differences in CLiP suggest possible enhancements to Subdue. Research in pattern recognition has begun to investigate the use of graphs and graph grammars as an underlying representation for structural problems <ref> (Schalkoff, 1992) </ref>. Many results in grammatical inference are applicable to constrained classes of graphs (e.g., trees) (Fu, 1982; Miclet, 1986). The approach begins with a set of sample graphs and produces a generalized graph grammar capable of deriving the original sample graphs and many others.
Reference: <author> Segen, J. </author> <year> (1990). </year> <title> Graph clustering and model learning by data compression. </title> <booktitle> In Proceedings of the Seventh International Machine Learning Workshop, </booktitle> <pages> pp. 93-101. </pages>
Reference-contexts: Finally, the subgraph-of partial ordering used by Levinson's system is not included in Subdue, but maintaining this partial ordering would improve the performance of the graph matching procedure by pruning the number of possible matching graphs. Segen <ref> (Segen, 1990) </ref> describes a system for storing graphs using a probabilistic graph model to represent subsets of the graph. Alternative models are evaluated based on a minimum description length measure of the information needed to represent the stored graphs using the model.
Reference: <author> Thompson, K., & Langley, P. </author> <year> (1991). </year> <title> Concept formation in structured domains. </title> <editor> In Fisher, D. H., & Pazzani, M. (Eds.), </editor> <title> Concept Formation: Knowledge and Experience in Unsupervised Learning, </title> <journal> chap. </journal> <volume> 5. </volume> <publisher> Morgan Kaufmann Publishers, Inc. </publisher>
Reference-contexts: As with Levin-son's approach, graphs are processed incrementally, and substructure is found across several graphs, not within a single graph as in Subdue. The Labyrinth system <ref> (Thompson & Langley, 1991) </ref> extends the Cobweb incremental conceptual clustering system (Fisher, 1987) to handle structured objects. Labyrinth uses Cobweb to form hierarchical concepts of the individual objects in the domain based on their primitive attributes.
Reference: <author> Waltz, D. </author> <year> (1975). </year> <title> Understanding line drawings of scenes with shadows. </title> <editor> In Winston, P. H. (Ed.), </editor> <booktitle> The Psychology of Computer Vision. </booktitle> <address> McGraw-Hill. </address> <note> 254 Substructure Discovery Wertheimer, </note> <author> M. </author> <year> (1939). </year> <title> Laws of organization in perceptual forms. </title> <editor> In Ellis, W. D. (Ed.), </editor> <booktitle> A Sourcebook of Gestalt Psychology, </booktitle> <pages> pp. 331-363. </pages> <publisher> Harcourt, Brace and Company. </publisher>
Reference-contexts: The graph representation consists of eight types of vertices and two types of arcs (edge and space). The vertex labels (f , a, l, t, k, x, p, and m) follow the Waltz labelings <ref> (Waltz, 1975) </ref> of junctions of edges in the image and represent the types of vertices shown in Figure 10. An edge arc represents the edge of an object in the image, and a space arc links non-connecting objects together.
Reference: <author> Winston, P. H. </author> <year> (1975). </year> <title> Learning structural descriptions from examples. </title> <editor> In Winston, P. H. (Ed.), </editor> <booktitle> The Psychology of Computer Vision, </booktitle> <pages> pp. 157-210. </pages> <publisher> McGraw-Hill. </publisher>
Reference-contexts: As a result, Subdue makes use of an optional pruning mechanism that eliminates substructure expansions from consideration when the description lengths for these expansions increases. 3. Related Work Several approaches to substructure discovery have been developed. Winston's Arch program <ref> (Winston, 1975) </ref> discovers substructures in order to deepen the hierarchical description of a scene and to group objects into more general concepts. The Arch program searches for two types of substructure in the blocks-world domain. The first type involves a sequence of objects connected by a chain of similar relations.
Reference: <author> Yoshida, K., Motoda, H., & Indurkhya, N. </author> <year> (1993). </year> <title> Unifying learning methods by colored digraphs. </title> <booktitle> In Proceedings of the Learning and Knowledge Acquisition Workshop at IJCAI-93. </booktitle>
Reference-contexts: Again, maintaining the concepts (images, graphs) in a partially-ordered hierarchy improves the efficiency of matching and retrieval, and suggests a possible improvement to Subdue. The CLiP system <ref> (Yoshida, Motoda, & Indurkhya, 1993) </ref> for graph-based induction is more similar to Subdue than the previous systems. CLiP iteratively discovers patterns in graphs by expanding and combining patterns discovered in previous iterations. Patterns are grouped into views based on their collective ability to compress the original input graph.
Reference: <author> Zahn, C. T. </author> <year> (1971). </year> <title> Graph-theoretical methods for detecting and describing gestalt clusters. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 20 (1), </volume> <pages> 68-86. 255 </pages>
Reference-contexts: The connectivity rule is a variant of Wertheimer's Factor of Proximity (Wertheimer, 1939), and is related to earlier numerical clustering techniques <ref> (Zahn, 1971) </ref>. These works demonstrate the human preference for "isolated" substructures, that is, substructures that are minimally related to adjoining structure.
References-found: 26

