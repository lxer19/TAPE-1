URL: ftp://ftp.cs.utexas.edu/pub/mooney/papers/banner-proposal-95.ps.Z
Refering-URL: http://www.cs.utexas.edu/users/ml/abstracts.html
Root-URL: 
Title: Refinement of Bayesian Networks by Combining Connectionist and Symbolic Techniques  
Author: Sowmya Ramachandran, Supervising Professor: Dr. Raymond J. Mooney 
Date: October 20, 1995  
Address: Austin, TX 78712  
Affiliation: Department of Computer Sciences, University of Texas,  
Abstract-found: 0
Intro-found: 1
Reference: <author> Beinlich, I., Suermondt, H., Chavez, R., and Cooper, G. </author> <year> (1989). </year> <title> The alarm monitoring system: A case study with two probabilistic inference techniques for belief networks. </title> <booktitle> In Proceedings of the Second European Conference on Artificial Intelligence in Medicine, </booktitle> <pages> 247-256. </pages> <address> London, England. </address>
Reference: <author> Buchanan, G., and Shortliffe, E., </author> <title> editors (1984). Rule-Based Expert Systems:The MYCIN Experiments of the Stanford Heuristic Programming Project. </title> <address> Reading, MA: </address> <publisher> Addison-Wesley Publishing Co. </publisher>
Reference: <author> Buntine, W. </author> <year> (1991). </year> <title> Theory refinement on Bayesian networks. </title> <booktitle> In Proceedings of the Conference on Uncertainty in Artificial Intelligence, </booktitle> <pages> 52-60. </pages>
Reference: <author> Buntine, W. L. </author> <year> (1994). </year> <title> Operations for learning graphical models. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 2 </volume> <pages> 159-225. </pages>
Reference: <author> Buntine, W. L., and Weigend, A. S. </author> <year> (1991). </year> <title> Bayesian back-propagation. </title> <journal> Complex Systems, </journal> <volume> 5(6) </volume> <pages> 603-643. </pages>
Reference: <author> Burnell, L., and Horovitz, E. </author> <year> (1995). </year> <title> Structure and chance: Melding logic and probability for software debugging. </title> <journal> Communications of the Association for Computing Machinery, </journal> <volume> 38(3) </volume> <pages> 31-41. </pages>
Reference: <author> Cohen, W. </author> <year> (1992). </year> <title> Compiling prior knowledge into an explicit bias. </title> <booktitle> In Proceedings of the Ninth International Conference on Machine Learning, </booktitle> <pages> 102-110. </pages> <address> Aberdeen, Scotland. </address>
Reference: <author> Connolly, D. </author> <year> (1993). </year> <title> Constructing hidden variables in Bayesian networks via conceptual clustering. </title> <booktitle> In Proceedings of the Tenth International Conference on Machine Learning, </booktitle> <pages> 65-72. </pages> <address> Amherst, MA. </address>
Reference: <author> Cooper, G. </author> <year> (1990). </year> <title> Computational complexity of probabilistic inference using Bayesian belief networks (research note). </title> <journal> Artificial Intelligence, </journal> <volume> 42 </volume> <pages> 393-405. </pages>
Reference-contexts: For a network that is a polytree, i.e. in which each pair of variables is connected by at most one undirected path, the inference procedure is linear in the size of the network. For networks with undirected loops, however, the inference is NP-hard <ref> (Cooper, 1990) </ref>. The specification of a general Bayesian network is combinatorial in the fan-in of the nodes. It requires the specification, for each variable, of the conditional probabilities of the variable given all possible combinations of values of its parents.
Reference: <author> Cooper, G. G., and Herskovits, E. </author> <year> (1992). </year> <title> A Bayesian method for the induction of probabilistic networks from data. </title> <journal> Machine Learning, </journal> <volume> 9 </volume> <pages> 309-347. </pages>
Reference-contexts: Lam and Bacchus (1994) have a technique for incrementally refining a Bayesian network using the Minimum Description Length principle (Rissanen, 1978). Buntine (1991) has proposed a technique for revising a Bayesian network efficiently, using scoring metrics similar to that proposed by <ref> (Cooper and Herskovits, 1992) </ref>. However, neither of these techniques can revise networks with hidden variables. Mahoney and Mooney (1993a) have a system for revising probabilistic knowledge bases, but expressed in the form of certainty factors. <p> For this purpose, we will try to find some real-world applications of Bayesian networks which could be used for evaluation. We will also compare the performance of our system with other systems, such as K2 <ref> (Cooper and Herskovits, 1992) </ref>, that learn Bayesian networks, We discuss this in greater detail in Section 6.1. 6 Research Plan As discussed in previous chapters, we have already implemented our technique for revising the conditional probabilities for predictive inference. <p> Both these systems only learn the parameters of the network and cannot revise the structure. Therefore, we will also compare the performance of our system with systems like K2 <ref> (Cooper and Herskovits, 1992) </ref> which use induction to learn the structure of a network. <p> While the problem of inducing Bayesian networks from data has been explored deeply, the problem revising a Bayesian network has received very little attention. Buntine (1991) has proposed a technique for revising a Bayesian network efficiently, using scoring metrics similar to that proposed by <ref> (Cooper and Herskovits, 1992) </ref>. However, he does not specify any method for recognising when the network needs to be revised. Nor does he discuss ways of focusing on the portions of the network that should be modified.
Reference: <author> Dempster, A., Laird, N., and Rubin, D. </author> <year> (1977). </year> <title> Maximum likelihood from incomplete data via the EM algorithm. </title> <journal> Journal of the Royal Statistical Society B, </journal> <volume> 39 </volume> <pages> 1-38. </pages> <note> 31 Fahlman, </note> <editor> S., and Lebiere, C. </editor> <booktitle> (1989). The cascade-correlation learning architecture. In Advances in Neural Information Processing Systems, </booktitle> <volume> Vol. 2, </volume> <pages> 524-532. </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Fisher, D. H. </author> <year> (1987). </year> <title> Knowledge acquisition via incremental conceptual clustering. </title> <journal> Machine Learning, </journal> <volume> 2 </volume> <pages> 139-172. </pages>
Reference-contexts: Most of the above techniques could be adapted to discover hidden variables, but at a great cost involving brute force search. Connolly (1993) has proposed using clustering techniques <ref> (Fisher, 1987) </ref> to discover hidden variables. However, this technique can only learn tree structured networks. Thus, while researchers have a grasp on some aspects of learning Bayesian networks, the problem of learning Bayesian networks with unknown structures and hidden variables still poses a tough challenge. <p> This would increase the search space considerably. Connolly (1993) proposes a technique for discovering hidden variables with an unknown number of values using a clustering algorithm similar to Cobweb <ref> (Fisher, 1987) </ref>. However, their approach can only learn tree-structured networks with all the observable variables at the bottom-most level. We will consider adapting such algorithms to our learning problem. 7 Related Work The problem of learning Bayesian networks from data has received considerable attention in recent years.
Reference: <author> Frean, M. </author> <year> (1990). </year> <title> The Upstart algorithm: A method for constructing and training feedfor-ward neural networks. </title> <journal> Neural Computation, </journal> <volume> 2 </volume> <pages> 198-209. </pages>
Reference: <author> Fung, R., and Del Favero, B. </author> <year> (1995). </year> <title> Applying Bayesian networks to information retrieval. </title> <journal> Communications of the Association for Computing Machinery, </journal> <volume> 38(3) </volume> <pages> 42-48. </pages>
Reference: <author> Geman, S., and Geman, D. </author> <year> (1984). </year> <title> Stochastic relaxation, Gibbs distributions and the Bayesian restoration of images. </title> <journal> IEEE transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 6 </volume> <pages> 721-742. </pages>
Reference-contexts: The problem of learning the parameters for a network with a known structure, in the presence of hidden variables, has also received some attention. Many statistical techniques like Gibbs sampling <ref> (Geman and Geman, 1984) </ref> and EM (Dempster et al., 1977; Lauritzen, 3 1995) can be used in the context of Bayesian networks. Russell et al. (1995) have proposed an approach that optimises the probability of the data given the network using a gradient descent algorithm. <p> In the case of data that is missing some values, approximation methods like Gibbs Sampling <ref> (Geman and Geman, 1984) </ref> and EM (Dempster et al., 1977; Lauritzen, 1995) have been proposed. Both these methods require some initialisation of the parameters and data for the missing variables. The complete data is then sampled to compute new values for the parameters.
Reference: <author> Glymour, C., and Spirtes, P. </author> <year> (1988). </year> <title> Latent variables, causal models and overidentifying constraints. </title> <journal> Journal of Econometrics, </journal> <volume> 39 </volume> <pages> 175-198. </pages>
Reference: <author> Heckerman, D. </author> <year> (1995). </year> <title> A tutorial on learning Bayesian networks. </title> <type> Technical Report MSR-TR-95-06, </type> <institution> Microsoft Research, Advanced Technology Division, Microsoft Corporation, One Microsoft Way, </institution> <address> Redmond, WA 98052. </address>
Reference-contexts: will also evaluate the advantage of using the theory-revision approach to learning as opposed to a purely inductive approach. 26 A standard practice in the field of learning Bayesian networks is to the evaluate a learn-ing algorithm by comparing the learned network with the original network, called the gold standard <ref> (Heckerman, 1995) </ref>. This assumes that the target network is known ahead of time. Given the target network, the practice is to generate data from the network, learn a Bayesian network from the generated data, and compare the learned network with the original.
Reference: <author> Heckerman, D., Geiger, D., and Chikering, D. M. </author> <year> (1994). </year> <title> Learning Bayesian networks: The combination of knowledge and statistical data. </title> <booktitle> In Proceedings of the Tenth Conference on Uncertainty in Artificial Intelligence, </booktitle> <pages> 293-301. </pages> <address> Seattle, WA. </address>
Reference-contexts: One way of comparing the original and the learned networks is to compute the cross-entropy, which measures how close the learned distribution is to the target distribution <ref> (Heckerman et al., 1994) </ref>. Another measure is the structural-difference measure, which computes how similar the structures of the two networks are.
Reference: <author> Hertz, J., Krogh, A., and Palmer, R. G. </author> <year> (1991). </year> <title> Introduction to the Theory of Neural Computation. </title> <publisher> Addison Wesley. </publisher>
Reference-contexts: Our experiments with learning parameters for the general case (McQuesten, 1995) suggest that non-gradient techniques using simulated annealing <ref> (Hertz et al., 1991) </ref> are more effective than backpropagation. We also propose to compare the non-gradient training regimes with backpropagation for the predictive case. One limitation with the current approach is that it cannot be used with networks that have undirected loops. <p> Our backpropagation algorithm succeeded only twice out of 60 trials with a limit if 2000 epochs. There were no successes in 28 runs to 5000 epochs, nor in 3 runs to 10,000 epochs. We also ran some experiments where we used simulated annealing <ref> (Hertz et al., 1991) </ref>, instead of backpropagation, to train the network. This training regime does not require the gradient of the error function in order to modify the weights. Instead, it makes random perturbations to the weights of the network and picks the best network in each iteration. <p> We will also analyse the causes that lead to poor convergence. Such an analysis may suggest some improvements that can be made to the training algorithm. Finally, we will also investigate the faster training algorithms such as the conjugate gradient <ref> (Hertz et al., 1991) </ref> approach. 20 4.2.2 Future Work Our experiments, indicating the success of simulated annealing techniques in learning the parameter, is especially interesting since this training regime does not require gradients and hence does not depend on the computations involved in the propagation of activations over the network.
Reference: <author> Lam, W., and Bacchus, F. </author> <year> (1994). </year> <title> Using new data to refine a Bayesian network. </title> <booktitle> In Proceedings of the Conference on Uncertainty in Artificial Intelligence, </booktitle> <pages> 383-390. </pages>
Reference: <author> Lauritzen, S. L. </author> <year> (1995). </year> <title> The EM algorithm for graphical association models with missing data. </title> <journal> Computational Statistics and Data Analysis, </journal> <volume> 19 </volume> <pages> 191-201. </pages>
Reference: <author> Mahoney, J. J., and Mooney, R. J. </author> <year> (1993a). </year> <title> Combining connectionist and symbolic learning to refine certainty-factor rule-bases. </title> <journal> Connection Science, </journal> <volume> 5 </volume> <pages> 339-364. </pages>
Reference: <author> Mahoney, J. J., and Mooney, R. J. </author> <year> (1993b). </year> <title> Combining neural and symbolic learning to revise probabilistic rule bases. </title> <editor> In Hanson, S., Cowan, J., and Giles, C., editors, </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> Vol. 5, </volume> <pages> 107-114. </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufman. </publisher>
Reference-contexts: We also compare the performance of Banner with the performances of other learning systems like Kbann, Id3, Either, Rapture and Backprop. Id3 (Quinlan, 1986) is a system for inducing decision trees. Either (Ourston and Mooney, 1994) learns and revises propositional Horn-clause theories. Rapture <ref> (Mahoney and Mooney, 1993b) </ref> is a system for revising certainty-factor rule bases using neural networks. Kbann (Towell et al., 1990; Noordewier et al., 1991) revises a logical theory using a hybrid of symbolic and connectionist learning methods. Backprop is the standard backpropagation approach using a three-layer feedforward neural network.
Reference: <author> Mahoney, J. J., and Mooney, R. J. </author> <year> (1994). </year> <title> Comparing methods for refining certainty-factor rule bases. </title> <booktitle> In Proceedings of the Eleventh International Conference on Machine Learning, </booktitle> <pages> 173-180. </pages> <address> New Brunswick, NJ. </address> <note> 32 Marshall R. </note> <author> Mayberry, I. </author> <year> (1995). </year> <title> A Bayesian approach to translating Japanese verb aspect to english. Report for a class project. </title> <institution> The University of Texas at Austin. </institution>
Reference: <author> McClelland, J. L., and Rumelhart, D. E. </author> <year> (1988). </year> <title> Explorations in Parallel Distributed Processing: A Handbook of Models, Programs, and Exercises. </title> <address> Cambridge, MA: </address> <publisher> The MIT Press. </publisher>
Reference-contexts: Schwalb (1993) addresses the problem of learning the parameters of a given Bayesian network by mapping it onto a neural network with SIGMA-PI nodes and learning the conditional probabilities associated with the network (represented by link weights in the corresponding neural network) using standard backpropagation techniques <ref> (McClelland and Rumelhart, 1988) </ref>. This has the advantage that it is able to learn the conditional probabilities even in the presence of hidden variables.
Reference: <author> McQuesten, P. </author> <year> (1995). </year> <title> Abductive Banner. Report for a class project. </title> <institution> The University of Texas at Austin. </institution>
Reference-contexts: Our experiments with learning parameters for the general case <ref> (McQuesten, 1995) </ref> suggest that non-gradient techniques using simulated annealing (Hertz et al., 1991) are more effective than backpropagation. We also propose to compare the non-gradient training regimes with backpropagation for the predictive case. <p> The errors and the errors are computed as derivatives of the belief propagation functions. These gradients and the learning rules for modifying the weights based on the errors are presented in <ref> (McQuesten, 1995) </ref>. 4.2.1 Experimental Evaluation McQuesten (1995) also reports on experiments conducted to evaluate this approach. We picked a small network for our preliminary experiments designed to give us a quick evaluation of our approach. We used the network shown in Figure 1 as our test bed.
Reference: <author> Mezard, M., and Nadal, J. </author> <year> (1989). </year> <title> Learning in feedforward layered networks: The tiling algorithm. </title> <journal> Journal of Physics, A22(12):2191-2203. </journal>
Reference: <author> Mozer, M. C., and Smolensky, P. </author> <year> (1989). </year> <title> Skeletonization: A technique for trimming the fat from a network via relevance assessment. </title> <editor> In Touretzky, D. S., editor, </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> Vol. 1, </volume> <pages> 107-115. </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Musick, R. C. </author> <year> (1994). </year> <title> Belief Network Induction. </title> <type> PhD thesis, </type> <institution> University of California at Berkeley. </institution>
Reference-contexts: Russell et al. (1995) evaluate their system on data generated from a network for car insurance risk estimation <ref> (Musick, 1994) </ref>. We will evaluate our system on both these data sets. We will also test our system on a database of cases generated from a Bayesian network for a medical knowledge-base which is used in evaluating the ability medical students to treat patients (Pradhan et al., 1994).
Reference: <author> Neal, R. M. </author> <year> (1992). </year> <title> Connectionist learning of belief networks. </title> <journal> Artificial Intelligence, </journal> <volume> 56 </volume> <pages> 71-113. </pages>
Reference: <author> Noordewier, M. O., Towell, G. G., and Shavlik, J. W. </author> <year> (1991). </year> <title> Training knowledge-based neural networks to recognize genes in DNA sequences. </title> <booktitle> In Advances in Neural Information Processing Systems, </booktitle> <volume> vol. </volume> <pages> 3. </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufman. </publisher>
Reference-contexts: Once the network has been trained to a desired accuracy following the procedure de scribed in Section 2.2, it can be mapped back into a Bayesian network. 4.1.3 Experimental Evaluation We have evaluated Banner on two classification problems: DNA promoter recognition (No-ordewier et al., 1991) and DNA Splice Junction recognition <ref> (Noordewier et al., 1991) </ref>. Each 13 of these has associated with it an initial domain theory that does not have a good prediction accuracy on the data and therefore has to be revised. For each problem, we created several random splits of the data into training and test sets. <p> Its ultimate performance is comparable to both Rapture and Kbann, although its learning curve is not as steep. DNA Splice Junction: We have also evaluated Banner on the task of learning to recog-nise the splice junctions in a given DNA sequence <ref> (Noordewier et al., 1991) </ref>. Human DNA sequences consist of two regions: extron regions encoding information that is used for protein synthesis, interspersed with intron regions which are "garbage". The junctions between these regions are called splice junctions.
Reference: <author> Opitz, D. W., and Shavlik, J. W. </author> <year> (1993). </year> <title> Heuristically expanding knowledge-based neural networks. </title> <booktitle> In Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> 512-517. </pages> <address> Chamberry, France. </address>
Reference-contexts: A number of important issues have yet to be addressed, and the details of each step in the algorithm have to fleshed out. The approach outlined here is similar to the one used by <ref> (Opitz and Shavlik, 1993) </ref> to revise knowledge-based neural networks. Their experiments revealed that adding links and new 25 nodes is more crucial for their system than deleting links and nodes.
Reference: <author> Ourston, D., and Mooney, R. </author> <year> (1990). </year> <title> Changing the rules: A comprehensive approach to theory refinement. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> 815-820. </pages> <address> Detroit, MI. </address>
Reference: <author> Ourston, D., and Mooney, R. J. </author> <year> (1994). </year> <title> Theory refinement combining analytical and empirical methods. </title> <journal> Artificial Intelligence, </journal> <volume> 66 </volume> <pages> 311-344. </pages>
Reference-contexts: Thus, theory revisions systems assume that the learner has an initial imperfect knowledge base (usually obtained from a domain expert) which is then inductively revised to fit the data. Many techniques have been developed for revising knowledge bases represented in various languages such as propositional Horn-clause logic <ref> (Ourston and Mooney, 1994) </ref> and relational Horn-clause logic (Cohen, 1992; Pazzani and Kibler, 1992; Richards and Mooney, 1995). Even in the connectionist framework, theory revision has received a fair amount of attention. <p> Here, we present the results of our experiments. We also compare the performance of Banner with the performances of other learning systems like Kbann, Id3, Either, Rapture and Backprop. Id3 (Quinlan, 1986) is a system for inducing decision trees. Either <ref> (Ourston and Mooney, 1994) </ref> learns and revises propositional Horn-clause theories. Rapture (Mahoney and Mooney, 1993b) is a system for revising certainty-factor rule bases using neural networks. Kbann (Towell et al., 1990; Noordewier et al., 1991) revises a logical theory using a hybrid of symbolic and connectionist learning methods.
Reference: <author> Pazzani, M., and Kibler, D. </author> <year> (1992). </year> <title> The utility of background knowledge in inductive learning. </title> <journal> Machine Learning, </journal> <volume> 9 </volume> <pages> 57-94. </pages>
Reference: <author> Pearl, J. </author> <year> (1988). </year> <title> Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. </title> <address> San Mateo,CA: </address> <publisher> Morgan Kaufmann, Inc. </publisher>
Reference-contexts: Although they have been successfully applied in a number of domains, the rules for combining certainty factors are ad hoc and provide no mathematical guarantees, unless unrealistic independence assumptions are made. Bayesian networks <ref> (Pearl, 1988) </ref>, on the other hand, represent uncertainties as proba 2 bilities of events in the world. They provide ways for representing dependencies between variables explicitly. They also provide theoretically sound mechanisms for combining probabilities, and for accounting for dependencies. <p> Next, we will present our approach to the problem of revising Bayesian networks. We will also present the results from our preliminary experiments with Banner. We will conclude with a discussion of our proposed future research. 2 Background 2.1 Bayesian Networks: An Overview Bayesian networks <ref> (Pearl, 1988) </ref> provide a formalism for representing probabilistic knowledge. In general, a Bayesian network is a directed acyclic graph whose nodes correspond to random variables. These variables can take on many values. <p> Thus, for a network 6 where all variables are binary-valued, a variable with n parents would require 2 n conditional probabilities to be specified. The noisy-or and the noisy-and models of Bayesian networks <ref> (Pearl, 1988) </ref> avoid this problem by providing a way to compute the conditional probability of a variable given a combination of values of its parents from just the conditional probabilities of the variable given the value of each of its parents in isolation. <p> However, the presence of loops increases the complexity of inference significantly. The derivation of the propagation rules for polytrees exploit the fact that the network is singly connected. These rules cannot be used in the presence of loops. Several algorithms have been proposed for handling loops <ref> (Pearl, 1988) </ref>. Clustering is a technique where the variables forming a loop are clustered into one node, which results in a polytree. Inference is done using the polytree algorithm on the clustered network.
Reference: <author> Pearl, J., and Verma, T. </author> <year> (1991). </year> <title> A theory of inferred causation. </title> <booktitle> In Proceedings of the Second International Conference on Principles of Knowledge Representation and Reasoning, </booktitle> <pages> 441-452. </pages>
Reference: <author> Pradhan, M., Provan, G., Middleton, B., and Henrion, M. </author> <year> (1994). </year> <title> Knowledge engineering for large belief networks. </title> <booktitle> In Proceedings of the Conference on Uncertainty in Artificial Intelligence, </booktitle> <pages> 484-490. </pages> <address> Seattle, WA. </address>
Reference-contexts: We will evaluate our system on both these data sets. We will also test our system on a database of cases generated from a Bayesian network for a medical knowledge-base which is used in evaluating the ability medical students to treat patients <ref> (Pradhan et al., 1994) </ref>. Real world learning problems, however, seldom provide gold standards. While we will certainly evaluate our algorithm using the methodology described above, we also propose to evaluate it using real-world data for which approximate theories are available but not the target networks. <p> The 27 notion of noisy-or gates has been extended to handle multi-valued variables <ref> (Pradhan et al., 1994) </ref>. Noisy-and gates can be similarly extended. We believe that the parameter revision component can be extended to this case easily. Extending the theory revision algorithm poses a challenge, since we now have to search for hidden variables with an unknown number of values.
Reference: <author> Provan, G. M., and Singh, M. </author> <year> (1994). </year> <title> Learning Bayesian networks using feature selection. </title> <booktitle> In Proceedings of the Workshop on Artificial Intelligence and Statistics. </booktitle>
Reference: <author> Quinlan, J. R. </author> <year> (1986). </year> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1(1) </volume> <pages> 81-106. </pages>
Reference-contexts: The networks for the remaining splits were trained for the same number of epochs as the first one. Here, we present the results of our experiments. We also compare the performance of Banner with the performances of other learning systems like Kbann, Id3, Either, Rapture and Backprop. Id3 <ref> (Quinlan, 1986) </ref> is a system for inducing decision trees. Either (Ourston and Mooney, 1994) learns and revises propositional Horn-clause theories. Rapture (Mahoney and Mooney, 1993b) is a system for revising certainty-factor rule bases using neural networks.
Reference: <author> Richards, B. L., and Mooney, R. J. </author> <year> (1995). </year> <title> Automated refinement of first-order Horn-clause domain theories. </title> <journal> Machine Learning, </journal> <volume> 19(2) </volume> <pages> 95-131. </pages>
Reference: <author> Rissanen, J. </author> <year> (1978). </year> <title> Modeling by shortest data description. </title> <journal> Automatica, </journal> <volume> 14 </volume> <pages> 465-471. </pages>
Reference-contexts: We had mentioned earlier that there has been very little research into using theory revision techniques to learn Bayesian networks. Lam and Bacchus (1994) have a technique for incrementally refining a Bayesian network using the Minimum Description Length principle <ref> (Rissanen, 1978) </ref>. Buntine (1991) has proposed a technique for revising a Bayesian network efficiently, using scoring metrics similar to that proposed by (Cooper and Herskovits, 1992). However, neither of these techniques can revise networks with hidden variables. <p> As such, his approach involves extensive search and therefore is inefficient, especially in the presence of hidden variables. Lam and Bacchus (1994) have a technique for incrementally refining a Bayesian network using the Minimum Description Length <ref> (Rissanen, 1978) </ref> principle. Their approach, however, can only modify those portions of the network whose variables are observable. Thus, it cannot modify nor invent a hidden variable.
Reference: <author> Russell, S., Binder, J., Koller, D., and Kanazawa, K. </author> <year> (1995). </year> <title> Local learning in probabilistic networks with hidden variables. </title> <booktitle> In Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> 1146-1152. </pages> <address> Montreal, Canada. </address>
Reference-contexts: Although its learning rate is slower, Banner eventually performs comparably with other inductive learning systems. We would like to run similar experiments to compare the performance of our system with other systems that learn Bayesian networks with hidden variables, such as the Adaptive Probabilistic Networks <ref> (Russell et al., 1995) </ref> approach and the EM (Demp-ster et al., 1977; Lauritzen, 1995) algorithm. Our experiments with learning parameters for the general case (McQuesten, 1995) suggest that non-gradient techniques using simulated annealing (Hertz et al., 1991) are more effective than backpropagation. <p> In particular, we would like to empirically prove the hypothesis that it is better to train a network to optimise it for its intended task rather than optimise the probability of the network given the data. For this, we will compare the performance of our system with the APN <ref> (Russell et al., 1995) </ref> approach as well as the EM algorithm. Both these systems only learn the parameters of the network and cannot revise the structure. <p> These steps are repeated until some convergence criteria is met. While the above methods are efficient when the parameters have certain kinds of distributions, gradient descent approaches have been suggested for general distributions. One example is the idea of Adaptive Probabilistic Networks (APNs) <ref> (Russell et al., 1995) </ref>, which uses a gradient descent algorithm to find the parameters that maximise the probability of the data given the network. This is different from our approach, which tries to find parameters that will maximise the predictive accuracy of the network.
Reference: <author> Schwalb, E. </author> <year> (1993). </year> <title> Compiling Bayesian networks into neural networks. </title> <booktitle> In Proceedings of the Tenth International Conference on Machine Learning, </booktitle> <pages> 291-297. </pages> <address> Amherst, MA. </address>
Reference: <author> Shortliffe, E., and Buchanan, B. </author> <year> (1975). </year> <title> A model of inexact reasoning in medicine. </title> <journal> Mathematical Biosciences, </journal> <volume> 23 </volume> <pages> 351-379. </pages>
Reference: <author> Spiegelhalter, D. J., and Lauritzen, S. L. </author> <year> (1990). </year> <title> Sequential updating of conditional probabilities on directed graphical structures. </title> <journal> Networks, </journal> <volume> 20 </volume> <pages> 579-605. </pages>
Reference-contexts: The first of these is fairly straightforward. A common approach is to use the maximum likelihood estimates for the parameters, which in the case of no hidden variables, reduces to a function of the relative frequencies of occurrences of the values of the variable <ref> (Spiegelhalter and Lauritzen, 1990) </ref>. The problem of learning the parameters for a network with a known structure, in the presence of hidden variables, has also received some attention.
Reference: <author> Srinivas, S., and Breese, J. </author> <year> (1993). </year> <title> Ideal: Influence diagram evaluation and analysis in lisp: Documentation and users' guide. </title> <type> Technical Report Technical Memorandum No. 23, </type> <institution> Rockwell International Science Center, Palo Alto: Rockwell. </institution>
Reference-contexts: We picked a small network for our preliminary experiments designed to give us a quick evaluation of our approach. We used the network shown in Figure 1 as our test bed. We used IDEAL <ref> (Srinivas and Breese, 1993) </ref>, a system for reasoning with Bayesian networks, to simulate the network and generate data. This data was then given to our system, along with the structure of the network, to learn the parameters.
Reference: <author> Thompson, K., Langley, P., and Iba, W. </author> <year> (1991). </year> <title> Using background knowledge in concept formation. </title> <booktitle> In Proceedings of the Eighth International Workshop on Machine Learning, </booktitle> <pages> 554-558. </pages> <address> Evanston, IL. </address>
Reference: <author> Towell, G. G., and Shavlik, J. W. </author> <year> (1994). </year> <title> Knowledge-based artificial neural networks. </title> <journal> Artificial Intelligence, </journal> <volume> 70 </volume> <pages> 119-165. </pages>
Reference: <author> Towell, G. G., Shavlik, J. W., and Noordewier, M. O. </author> <year> (1990). </year> <title> Refinement of approximate domain theories by knowledge-based artificial neural networks. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> 861-866. </pages> <address> Boston, MA. </address>
Reference: <author> Wellman, M. P. </author> <year> (1990). </year> <title> Fundamental concepts of qualitative probabilistic networks. </title> <journal> Artificial Intelligence, </journal> <volume> 44 </volume> <pages> 257-303. 34 </pages>
Reference-contexts: This restricts the search space considerably. If, instead of viewing a Bayesian network as a quantitative model, we could look at it as a specification of qualitative relationship among variables <ref> (Wellman, 1990) </ref>, we would be able to apply symbolic theory revision techniques to revise the Bayesian network locally. The idea is to reduce the search space of possible revisions by focusing attention on a subset of variables that can be held responsible for an erroneous prediction by the network. <p> The second component is concerned with modifying the structure of the network. To do this, we approximate the Bayesian network by a Qualitative Probability Network (QPN) <ref> (Wellman, 1990) </ref>. Given a set of data which are predicted incorrectly by the network, we use qualitative analysis to determine the portion of the network that needs to be revised. affecting the entire system. <p> We use the ideas of Qualitative Probability Networks (QPN), presented in Wellman (1990) in our analyses. We first describe QPNs and then give an outline of our structure revision algorithm. 5.1 Qualitative Probability Networks Qualitative Probability Networks <ref> (Wellman, 1990) </ref> are an abstraction of graphical representations of probability distributions such as Bayesian networks. They represent the dependencies between variables in terms of qualitative relationships rather than numerically.
References-found: 51

