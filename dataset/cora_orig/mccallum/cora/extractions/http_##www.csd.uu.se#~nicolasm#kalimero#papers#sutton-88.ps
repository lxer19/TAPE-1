URL: http://www.csd.uu.se/~nicolasm/kalimero/papers/sutton-88.ps
Refering-URL: http://www.csd.uu.se/~nicolasm/kalimero/papers/index.html
Root-URL: 
Email: (RICH@GTE.COM)  
Title: Machine Learning Learning to Predict by the Methods of Temporal Differences Keywords: Incremental learning, prediction,
Author: RICHARD S. SUTTON 
Address: 40 Sylvan Road, Waltham, MA 02254, U.S.A.  
Affiliation: GTE Laboratories Incorporated,  
Note: c 1988 Kluwer Academic Publishers, Boston Manufactured in The Netherlands  
Date: 9-44, 1988  (Received: April 22, 1987) (Revised: February 4, 1988)  
Pubnum: 3:  
Abstract: This article introduces a class of incremental learning procedures specialized for prediction|that is, for using past experience with an incompletely known system to predict its future behavior. Whereas conventional prediction-learning methods assign credit by means of the difference between predicted and actual outcomes, the new methods assign credit by means of the difference between temporally successive predictions. Although such temporal-difference methods have been used in Samuel's checker player, Holland's bucket brigade, and the author's Adaptive Heuristic Critic, they have remained poorly understood. Here we prove their convergence and optimality for special cases and relate them to supervised-learning methods. For most real-world prediction problems, temporal-difference methods require less memory and less peak computation than conventional methods; and they produce more accurate predictions. We argue that most problems to which supervised learning is currently applied are really prediction problems of the sort to which temporal-difference methods can be applied to advantage. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Ackley, D. H., Hinton, G. H., & Sejnowski, T. J. </author> <year> (1985). </year> <title> A learning algorithm for Boltzmann machines. </title> <journal> Cognitive Science, </journal> <volume> 9, </volume> <pages> 147-169. </pages>
Reference: <author> Anderson, C. W. </author> <year> (1986). </year> <title> Learning and problem solving with multilayer connectionist systems. </title> <type> Doctoral dissertation, </type> <institution> Department of Computer and Information Science, University of Massachusetts, Amherst. </institution>
Reference: <author> Anderson, C. W. </author> <year> (1987). </year> <title> Strategy learning with multilayer connectionist representations. </title> <booktitle> Proceedings of the Fourth International Workshop on Machine Learning (pp. </booktitle> <pages> 103-114). </pages> <address> Irvine, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Barto, A. G. </author> <year> (1985). </year> <title> Learning by statistical cooperation of self-interested neuron-like computing elements. </title> <journal> Human Neurobiology, </journal> <volume> 4, </volume> <pages> 229-256. </pages>
Reference: <author> Barto, A. G., Sutton R. S., & Anderson, C. W. </author> <year> (1983). </year> <title> Neuronlike elements that can solve difficult learning control problems. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> 13, </volume> <pages> 834-846. </pages>
Reference: <author> Booker, L. B. </author> <year> (1982). </year> <title> Intelligent behavior as an adaptation to the task environment. </title> <type> Doctoral dissertation, </type> <institution> Department of Computer and Communication Sciences, University of Michigan, </institution> <address> Ann Arbor. </address>
Reference: <author> Christensen, J. </author> <year> (1986). </year> <title> Learning static evaluation functions by linear regression. </title>
Reference: <editor> In T. M. Mitchell, J. G. Carbonell, & R. S. Michalski (Eds.), </editor> <title> Machine learning: A guide to current research. </title> <address> Boston: </address> <publisher> Kluwer Academic. </publisher>
Reference: <author> Denardo, E. V. </author> <year> (1982). </year> <title> Dynamic programming: Models and applications. </title> <address> Engle-wood Cliffs, NJ: </address> <note> Prentice-Hall. 42 R. </note> <author> S. SUTTON Dietterich, T. G., & Michalski, R. S. </author> <year> (1986). </year> <title> Learning to predict sequences. </title> <editor> In R. S. Michalski, J. G. Carbonell & T. M. Mitchell (Eds.), </editor> <booktitle> Machine learning: An artificial intelligence approach, Volume II, </booktitle> <address> Los Altos, Ca: </address> <publisher> Morgan-Kaufmann. </publisher>
Reference-contexts: Third, construct an update rule that uses the mismatch in the recursive equations to drive weight changes towards a better match. These three steps are very similar to those taken in formulating a dynamic programming problem <ref> (e.g., Denardo, 1982) </ref>. 6. Related Research Although temporal-difference methods have never previously been identified or studied on their own, we can view some previous machine learning research as having used them.
Reference: <author> Gelperin, A., Hopfield, J. J., Tank, D. W. </author> <year> (1985). </year> <title> The logic of Limax learning. </title> <editor> In A. Selverston (Ed.), </editor> <title> Model neural networks and behavior. </title> <address> New York: </address> <publisher> Plenum Press. </publisher>
Reference: <author> Hampson, S. E. </author> <year> (1983). </year> <title> A neural model of adaptive behavior. </title> <type> Doctoral dissertation, </type> <institution> Department of Information and Computer Science, University of California, Irvine. </institution>
Reference: <author> Hampson, S. E., & Volper, D. J. </author> <year> (1987). </year> <title> Disjunctive models of boolean category learning. </title> <journal> Biological Cybernetics, </journal> <volume> 56, </volume> <pages> 121-137. </pages>
Reference: <author> Holland, J. H. </author> <year> (1986). </year> <title> Escaping brittleness: The possibilities of general-purpose learning algorithms applied to parallel rule-based systems. </title> <editor> In R. S. Michalski, J. G. Carbonell & T. M. Mitchell (Eds.), </editor> <booktitle> Machine learning: An artificial intelligence approach, Volume II, </booktitle> <address> Los Altos, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Kehoe, E. J., Schreurs, B. G., & Graham, P. </author> <year> (1987). </year> <title> Temporal primacy overrides prior training in serial compound conditioning of the rabbit's nictitating membrane response. Animal Learning and Behavior, </title> <booktitle> 15, </booktitle> <pages> 455-464. </pages>
Reference: <author> Kemeny, J. G., & Snell, J. L. </author> <year> (1976). </year> <title> Finite markov chains. </title> <address> New York: </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: For an absorbing Markov chain <ref> (e.g., see Kemeny & Snell, 1976, p. 46) </ref>: d T = T (I Q) 1 ; (7) where [d] i = d i and [] i = i , i 2 N .
Reference: <author> Klopf, A. H. </author> <year> (1987). </year> <title> A neuronal model of classical conditioning (Air Force Wright Aeronautical Laboratories Technical Report 87-1139). </title> <institution> Wright-Patterson AFB, OH. </institution>
Reference: <author> Moore, J. W., Desmond, J. E., Berthier, N. E., Blazis, D. E. J., Sutton, R. S., Barto, A. G. </author> <year> (1986). </year> <title> Simulation of the classically conditioned nictitating membrane response by a neuron-like adaptive element: Response topography, neuronal firing and interstimulus intervals. </title> <journal> Behavioral Brain Research, </journal> <volume> 21, </volume> <pages> 143-154. </pages>
Reference: <author> Rumelhart, D. E., Hinton, G. E., & Williams, R. J. </author> <year> (1985). </year> <title> Learning internal representations by error propagation (Institute for Cognitive Science Technical Report 8506). </title> <institution> La Jolla, Ca: University of California, </institution> <address> San Diego. </address> <note> Also in D. </note> <editor> E. Rumehart, & J. L. McClelland (Eds.), </editor> <booktitle> Parallel distributed processing: Explorations in the microstructure of cognition, Volume 1: Foundations. </booktitle> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Samuel, A. L. </author> <year> (1959). </year> <title> Some studies in machine learning using the game of checkers. </title> <journal> IBM Journal on Research and Development, </journal> <volume> 3, </volume> <pages> 210-229. </pages> <note> Reprinted in E. </note> <editor> A. Feigenbaum, & J. Feldman (Eds.), </editor> <booktitle> Computers and thought. </booktitle> <address> New York: </address> <publisher> McGraw-Hill. </publisher>
Reference: <author> Sutton, R. S. </author> <year> (1984). </year> <title> Temporal credit assignment in reinforcement learning. </title> <type> Doctoral dissertation, </type> <institution> Department of Computer and Information Science, University of Massachusetts, Amherst. </institution>
Reference-contexts: only changes in prediction due to x are effective in causing weight alterations: w t+1 = w t + ff P (x t+1 ; w t ) P (x t ; w t ) k=1 This refinement is used in Samuel's (1959) checker player and in the Adaptive Heuristic Critic <ref> (Sutton, 1984) </ref>, but not in Holland's (1986) bucket brigade or in the system described by Barto, Sutton, and Anderson (1983). 5.3 Prediction by a fixed interval Finally, consider the problem of making a prediction for a particular fixed amount of time later.
Reference: <author> Sutton, R. S., & Barto, A. G. </author> <year> (1981a). </year> <title> Toward a modern theory of adaptive networks: Expectation and prediction. </title> <journal> Psychological Review, </journal> <volume> 88, </volume> <pages> 135-171. </pages> <note> TEMPORAL-DIFFERENCE LEARNING 43 Sutton, </note> <author> R. S., & Barto, A. G. </author> <year> (1981b). </year> <title> An adaptive network that constructs and uses an internal model of its environment. </title> <journal> Cognition and Brain Theory Quarterly, </journal> <volume> 4, </volume> <pages> 217-246. </pages>
Reference: <author> Sutton, R. S., & Barto, A. G. </author> <year> (1987). </year> <title> A temporal-difference model of classical conditioning. </title> <booktitle> Proceedings of the Ninth Annual Conference of the Cognitive Science Society (pp. </booktitle> <pages> 355-378). </pages> <address> Seattle, WA: </address> <publisher> Lawrence Erlbaum. </publisher>
Reference: <author> Sutton, R. S., & Pinette, B. </author> <year> (1985). </year> <title> The learning of world models by connectionist networks. </title> <booktitle> Proceedings of the Seventh Annual Conference of the Cognitive Science Society (pp. </booktitle> <pages> 54-64). </pages> <address> Irvine, CA: </address> <publisher> Lawrence Erlbaum. </publisher>
Reference: <author> Varga, R. S. </author> <year> (1962). </year> <title> Matrix iterative analysis. </title> <address> Englewood Cliffs, NJ: </address> <publisher> Prentice-Hall. </publisher>
Reference-contexts: TEMPORAL-DIFFERENCE LEARNING 27 We show that D (I Q) is positive definite 6 by applying the following lemma <ref> (see Varga, 1962, p. 23, for a proof.) </ref>: Lemma If A is a real, symmetric, and strictly diagonally dominant matrix with positive diagonal entries, then A is positive definite. We cannot apply this lemma directly to D (I Q) because it is not symmetric. <p> Then, for any positive ff &lt; * , all eigenvalues 1 ff of I ffXD (I Q)X T are less than 1 in modulus. And this immediately implies <ref> (e.g., see Varga, 1962, p. 13) </ref> that lim n!1 (I ffXD (I Q)X T ) n = 0 , completing the proof.
Reference: <author> Widrow B., & Hoff, M. E. </author> <year> (1960). </year> <title> Adaptive switching circuits. </title> <booktitle> 1960 WESCON Convention Record Part IV (pp. </booktitle> <pages> 96-104). </pages>
Reference-contexts: S. SUTTON the i th components of w and x t respectively. 2 In this case we have r w P t = x t , and (2) reduces to the well known Widrow-Hoff rule <ref> (Widrow & Hoff, 1960) </ref>: w t = ff (z w T x t )x t : This linear learning method is also know as the "delta rule", the ADALINE, and the LMS filter. It is widely used in connectionism, pattern recognition, signal processing, and adaptive control.
Reference: <author> Widrow, B., & Stearns, S. D. </author> <year> (1985). </year> <title> Adaptive signal processing. </title> <address> Englewood Cliffs, NJ: </address> <publisher> Prentice-Hall. </publisher>
Reference-contexts: The Widrow-Hoff rule is simple, effective, and robust. Its theory is also better developed than that of any other learning method <ref> (e.g., see Widrow and Stearns, 1985) </ref>. Another instance of the prototypical supervised-learning procedure is the "generalized delta rule," or backpropagation procedure, of Rumelhart, Hinton and Williams (1985). In this case, P t is computed by a multi-layer connectionist network and is a nonlinear function of x t and w . <p> It is well known that, under repeated presentations, the Widrow-Hoff procedure minimizes the RMS error between its predictions and the actual outcomes in the training set <ref> (Widrow & Stearns, 1985) </ref>. How can it be that this optimal method performed worse than all the TD methods for &lt; 1 ? The answer is that the Widrow-Hoff procedure only minimizes error on the training set; it does not necessarily minimize error for future experience. <p> If the set of observation vectors f x i j i 2 N g is linearly independent, and if ff is chosen small enough, then it is known that the predictions of the Widrow-Hoff rule converge in expected value to the ideal predictions <ref> (e.g., see Widrow and Stearns, 1985) </ref>. <p> This does not change any of the conclusions of the analysis. TEMPORAL-DIFFERENCE LEARNING 31 converges so as to minimize the RMS error between its predictions and the actual outcomes in the training set <ref> (Widrow & Stearns, 1985) </ref>. As illustrated earlier in the random-walk example, linear TD (0) converges to a different set of predictions. We now show that those predictions are in fact the optimal predictions in the maximum-likelihood sense discussed above.
Reference: <author> Williams, R. J. </author> <year> (1986). </year> <title> Reinforcement learning in connectionist networks: </title> <institution> A mathematical analysis (Institute for Cognitive Science Technical Report 8605). La Jolla, Ca: University of California, </institution> <address> San Diego. </address>
Reference: <author> Witten, I. H. </author> <year> (1977). </year> <title> An adaptive optimal controller for discrete-time markov environments. </title> <journal> Information and Control, </journal> <volume> 34, </volume> <pages> 286-295. </pages> <note> 44 R. </note> <editor> S. </editor> <publisher> SUTTON </publisher>
References-found: 28

