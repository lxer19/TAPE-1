URL: ftp://whitechapel.media.mit.edu/pub/tech-reports/TR-365.ps.Z
Refering-URL: http://www-white.media.mit.edu/cgi-bin/tr_pagemaker/
Root-URL: http://www.media.mit.edu
Email: tpminka@media.mit.edu  
Title: Image Database Browser that Learns From User Interaction  
Author: Thomas Minka 
Address: 20 Ames Street; Cambridge, MA 02139  
Affiliation: Vision and Modeling Group MIT Media Laboratory  
Note: An  This work was supported in part by BT, HP, and IBM.  
Abstract: MIT Media Laboratory Technical Report 365 Also appears as MIT thesis for the degree of Master of Engineering in Electrical Engineering and Computer Science Supervised by Rosalind W. Picard Abstract Digital libraries of images and video are rapidly growing in size and availability. To avoid the expense and limitations of text, there is considerable interest in navigation by perceptual and other automatically extractable attributes. Unfortunately, the relevance of an attribute for a query is not always obvious. Queries which go beyond explicit color, shape, and positional cues must incorporate multiple features in complex ways. This dissertation uses machine learning to automatically select and combine features to satisfy a query, based on positive and negative examples from the user. The learning algorithm does not just learn during the course of one session: it learns continuously, across sessions. The learner improves its learning ability by dynamically modifying its inductive bias, based on experience over multiple sessions. Experiments demonstrate the ability to assist image classification, segmentation, and annotation (labeling of image regions). The common theme of this work, applied to computer vision, database retrieval, and machine learning, is building in enough flexibility to allow adaptation to changing goals. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> B. Allen and I. Munro. </author> <title> Self-organizing search trees. </title> <journal> Journal ACM, </journal> <volume> 25 </volume> <pages> 526-535, </pages> <year> 1978. </year>
Reference-contexts: The self-organization principle is also used in searchable data structures, to dynamically optimize them according to the distribution of queries. For example, the "move to front rule" is used for sequential lists [48] and the "move to root rule" is used for binary trees <ref> [1] </ref>. Of course, if the query distribution is fixed and known beforehand, a static Huffman tree is optimal; this is the usual tradeoff between off-line and on-line solutions. Unfortunately, a continuous learner has neither of these two luxuries for determining its bias.
Reference: [2] <author> Bir Bhanu and Sungkee Lee. </author> <title> Genetic learning for adaptive image segmentation. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1994. </year>
Reference-contexts: Unfortunately, optimization-based algorithms like region competition bury their parameters in split/merge/smoothing thresholds, which together conspire to alter the resulting segmentation. Even the designer of such an algorithm would be hard pressed to transform a segmentation task into a suitable set of parameters. For example, <ref> [2] </ref> applies a sophisticated optimization algorithm simply to find the right parameters of the Phoenix segmentation algorithm for images taken under different conditions. Phoenix uses histogram splitting to do top-down segmentation, where each split is chosen to optimize a fitness function.
Reference: [3] <author> A. Bookstein. </author> <title> The generalized retrieval problem. </title> <editor> In C. J. Crouch, editor, </editor> <booktitle> Proc. 4th Int'l Conf on Info. Stor. and Retr., </booktitle> <volume> volume 16, </volume> <pages> pages 4-14. ACM-SIGIR, </pages> <month> Summer </month> <year> 1981. </year>
Reference-contexts: In the presence of relevance feedback, the dual view is instrumental in allowing attribute selection and combination to be handled by rule-induction methods used in machine learning. 2.1 A dual view of retrieval 2.1.1 Document retrieval In the generalized retrieval problem discussed in <ref> [3] </ref>, the user wants to find a document containing certain terms. A term might be a single word like "rocket" or multiple words like "rocket fuel" or "National Aeronautics and Space Administration." The terms to use for indexing are decided upon when the database is populated.
Reference: [4] <author> L. Breiman, J. H. Freidman, R. A. Olshen, and C. J. Stone. </author> <title> Classification and Regression Trees. </title> <publisher> Wadsworth & Brooks/Cole Advanced Books & Software, </publisher> <year> 1984. </year>
Reference-contexts: By viewing this problem as concept induction in the AI sense, we can apply standard machine learning algorithms, but in terms of set-based attributes. Three adapted algorithms: set covering [28] [14], decision list [47], and decision tree [15] [45] <ref> [4] </ref>, are described here. This chapter drives home the point that learning performance hinges on the bias of the learner. Hence a robust solution is to make the choice as flexible as possible and then adapt it at runtime. This extension is explored in chapter 4. <p> A further relaxation of constraints allows the learner to choose a decision which simply makes the best division of the examples into two parts, each of which may require further division. This yields a greedy algorithm which builds decision trees [15] [45] <ref> [4] </ref> (see figure 3.4). Unlike the methods in [45] and [4], we're going to use no stopping or pruning criterion to halt tree growth, because in an interactive setting the learner is expected to classify all training points correctly. <p> This yields a greedy algorithm which builds decision trees [15] [45] <ref> [4] </ref> (see figure 3.4). Unlike the methods in [45] and [4], we're going to use no stopping or pruning criterion to halt tree growth, because in an interactive setting the learner is expected to classify all training points correctly. Another difference is that DT uses set membership to make decisions, not raw attribute values. <p> Consider the examples as data points of value one or zero, for positive and negative, respectively. Two useful definitions of impurity are then the sample variance and the sample entropy under an independence assumption (these are the splitting rules suggested in <ref> [4] </ref>): * p I = the fraction of I c which are positive examples * p O = the fraction of O c which are positive examples * V (x) = 4x (1 x) * sample variance = V (p I ) fl jI c j + V (p O ) <p> Recurse separately on the examples in the sets I c and O c . This will yield the two subtrees of T c . No difference was found in the following experiments between the use of variance or entropy, so the simpler variance rule was chosen (as in <ref> [4] </ref>). DL is the special case of DT where impurity is either zero, meaning pure, or one, meaning some mixture of positive and negative. Therefore DT is the most general of the three learning schemes.
Reference: [5] <author> P. Brodatz. </author> <title> Textures: A Photographic Album for Artists and Designers. </title> <publisher> Dover, </publisher> <address> New York, </address> <year> 1966. </year>
Reference-contexts: But both of these tasks are plagued with difficulties. Research does not yet have the capability to mimic human perception in general contexts. Computational models which isolate one perceptual component, e.g. texture, have succeeded in benchmarks like the Brodatz <ref> [5] </ref> collection [43] [24], but have yet to prove themselves on naturally-occurring imagery in which textures may be occluded, in perspective, warped around a surface, at different scales, in different colors and contrast, or have different lighting. Consequently, perceptual models are highly data-dependent; see figure 1.1 for an example. <p> This stability is largely due to the on-line example selection. Hence the results for only one run is shown, rather than an average which would suppress the variation in error throughout a run. 3.3.1 Brodatz collection The first data set consisted of images digitized from the monochrome Brodatz <ref> [5] </ref> texture album. Each of the 112 textures in the album was equally divided into 9 128 fi 128 non-overlapping images. The desired classification corresponded to two disjoint groups each containing 56 of the 112 original texture classes.
Reference: [6] <author> G. Carpenter and S. Grossberg. ART2: </author> <title> Self-organization of stable category recognition codes for analog input patterns. </title> <journal> Applied Optics, </journal> <volume> 26(23) </volume> <pages> 4919-4946, </pages> <year> 1987. </year>
Reference-contexts: Our eyes may "learn" the right focus or light setting, while our minds learn occlusion and grouping. * Evolution. Each creature perceives and reasons while also participating in a common learning process. An advantage of a multi-scale learning architecture is that it avoids the stability-plasticity tradeoff <ref> [6] </ref> faced by using a single layer. That is, a layer which learns fast also forgets fast, because it cannot take into account all that it has seen.
Reference: [7] <author> T. Chang and C. C. J. Kuo. </author> <title> Texture analysis and classification with tree-structured wavelet transform. </title> <type> Technical Report USC-SIPI198, </type> <institution> University of Southern California, </institution> <address> Los Angeles, CA, </address> <month> February </month> <year> 1992. </year>
Reference-contexts: MRSAR) over others was obvious in the previous four experiments, but it need not be so in general. The next set of experiments attempted to achieve synergy with two roughly equally good measures, a Euclidean gray-level histogram distance and the tree-structured wavelet (TSW) transform <ref> [7] </ref>. The histogram distance is the squared error between all 256 pixel-value bins, accumulated over an entire image. The learning time for the three algorithms, using the hierarchies alone and together, is shown in figure 3.9. Using either hierarchy alone, the order from best to worst was: DT, DL, SC.
Reference: [8] <author> Allen Cypher, </author> <title> editor. Watch what I do: programming by demonstration. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1993. </year>
Reference-contexts: Third, training is accumulated across sessions with the user, so that the system improves over time and can solve similar problems better, i.e. learn faster, the next time. 1.3 Applications 1.3.1 Example-based User Interfaces FourEyes can be viewed as a user interface agent <ref> [8] </ref>. Agents automate repetitive tasks and fill a niche missed by macros and scripting, by learning from examples. In FourEyes, the repetitive task is grouping pixels into objects and objects into classes. Conventional programs support this but with considerable user effort.
Reference: [9] <author> Jon Doyle. </author> <title> A model for deliberation, action, and introspection. </title> <type> PhD thesis, </type> <institution> Massachusetts Institute of Technology, </institution> <year> 1980. </year> <note> Also MIT Artificial Intelligence Laboratory Memo AIM-TR-581. </note>
Reference-contexts: Thus the discovery of not just new learning algorithms, but malleable learning algorithms, is an important research topic. An extreme form of malleability would be a learner capable of reflecting on itself, i.e. a learner with complete access to, and control over, its own learning mechanisms <ref> [9] </ref>, e.g. rewriting its own program. In this sense, a reflective learner would be self-aware: it is not only conscious of its situation, but also conscious of itself in that situation. These correspond to understanding the attributes of the target concepts and how inductive bias exploits those, respectively.
Reference: [10] <author> R. O. Duda and P. E. Hart. </author> <title> Pattern Classification and Scene Analysis. </title> <publisher> Wiley-Interscience, </publisher> <year> 1973. </year>
Reference-contexts: Single-link clustering also tends to group areas of similar density, as opposed to complete-link methods which will make seemingly arbitrary cuts through regions of constant density. These advantages of single-link clustering, which seem most appropriate for perceptual problems, have been demonstrated in the literature; see e.g. [16], <ref> [10] </ref> (section 6.10.2). If this heuristic is in doubt, one can always add additional quantizations, as mentioned earlier. The metric interpretation of the resulting hierarchy yields a distance function similar to that provided by the original vector space. However, many of the unnecessary distinctions between images have been removed.
Reference: [11] <author> Michael R. Garey and David S. Johnson. </author> <title> Computers and Intractability: A Guide to the Theory of NP-Completeness. </title> <editor> W. H. </editor> <publisher> Freeman, </publisher> <year> 1979. </year>
Reference-contexts: Given an assortment C of sets to choose from, the algorithm's job is to find the smallest union of sets which covers (includes) all of the positive examples and none of the negative examples. This problem is NP-complete <ref> [11] </ref>, but there are a variety of greedy methods which get close to the optimum covering [28] [14]. For example, algorithm SC: 1. Choose the set c from C which covers the most positive examples and no negative examples. Resolve ties with a coin toss. 2.
Reference: [12] <author> D. L. Hall. </author> <title> Mathematical Techniques in Multi-Sensor Data Fusion. </title> <publisher> Artech House, </publisher> <year> 1992. </year>
Reference-contexts: Multiple similarity measures, which individually specialize on an image domain, must cooperate to simply provide good color-based or texture-based navigation. In short, human desires rarely map onto a single extractable visual attribute. The basic issue in combining multiple measures (also known as data fusion <ref> [12] </ref>) is the comparison of incommensurates. When two measures have a linear tradeoff, they can simply be combined into one composite vector. In fact, this constitutes one definition of a feature vector: a collection of dimensions with known exchange rates.
Reference: [13] <editor> C. J. Harris, editor. </editor> <booktitle> Advances in Intelligent Control. </booktitle> <publisher> Taylor & Francis, </publisher> <year> 1994. </year>
Reference: [14] <author> D. Haussler. </author> <title> Quantifying inductive bias: AI learning algorithms and Valiant's learning framework. </title> <journal> Artificial Intelligence, </journal> <volume> 36 </volume> <pages> 177-221, </pages> <year> 1988. </year>
Reference-contexts: By viewing this problem as concept induction in the AI sense, we can apply standard machine learning algorithms, but in terms of set-based attributes. Three adapted algorithms: set covering [28] <ref> [14] </ref>, decision list [47], and decision tree [15] [45] [4], are described here. This chapter drives home the point that learning performance hinges on the bias of the learner. Hence a robust solution is to make the choice as flexible as possible and then adapt it at runtime. <p> With a suitable vocabulary (described below), each of the three grammars is sufficient to encode all concepts. Thus the number of candidate concepts, for any set of examples, is the same for all three grammars. Traditional analysis methods are unable to distinguish these grammars, since their VC dimension <ref> [14] </ref> is infinite and they are all accurate [58]. However, it will be shown that they have significant performance differences. <p> This problem is NP-complete [11], but there are a variety of greedy methods which get close to the optimum covering [28] <ref> [14] </ref>. For example, algorithm SC: 1. Choose the set c from C which covers the most positive examples and no negative examples. Resolve ties with a coin toss. 2. Remove all positive examples covered by c from consideration. 3. If positive examples remain, go back to step one.
Reference: [15] <author> Earl B. Hunt, Janet Marin, and Philip J. Stone. </author> <title> Experiments in Induction. </title> <publisher> Academic Press, </publisher> <year> 1966. </year>
Reference-contexts: By viewing this problem as concept induction in the AI sense, we can apply standard machine learning algorithms, but in terms of set-based attributes. Three adapted algorithms: set covering [28] [14], decision list [47], and decision tree <ref> [15] </ref> [45] [4], are described here. This chapter drives home the point that learning performance hinges on the bias of the learner. Hence a robust solution is to make the choice as flexible as possible and then adapt it at runtime. This extension is explored in chapter 4. <p> A further relaxation of constraints allows the learner to choose a decision which simply makes the best division of the examples into two parts, each of which may require further division. This yields a greedy algorithm which builds decision trees <ref> [15] </ref> [45] [4] (see figure 3.4). Unlike the methods in [45] and [4], we're going to use no stopping or pruning criterion to halt tree growth, because in an interactive setting the learner is expected to classify all training points correctly. <p> When a bias is strong but inaccurate, then a weak bias may do better. But while bias strength can be derived from the algorithm, bias accuracy cannot. Hence choosing the bias strength of a learner is somewhat of a gamble. As observed in <ref> [15] </ref> with respect to a decision tree algorithm (CLS): This faces the potential user of a CLS program with something of a paradox. Depending on the type of problem, he should use a particular program.
Reference: [16] <author> A. K. Jain and R. C. Dubes. </author> <title> Algorithms for Clustering Data. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1988. </year>
Reference-contexts: This always defines a hierarchy because (1) all points are distinct when k = 0, (2) all points merge for sufficiently large k, and (3) if x = y in P (k; c) then x = y in P (k + 1; c). This algorithm is a single-link method <ref> [16] </ref> because two clusters merge in the hierarchy as soon as two of their members get close enough. This is opposed to complete-link methods which merge two clusters only when all of their members are close enough. <p> This is opposed to complete-link methods which merge two clusters only when all of their members are close enough. Complete-link clustering is similar to minimizing mean squared error, such as in the popular k-means algorithm <ref> [16] </ref>. Hence it would be expected to give the best preservation of the distances in the original vector space. However, there is no reason to believe that the desired perceptual groupings occur as equal-sized spheres in attribute space. <p> Single-link clustering also tends to group areas of similar density, as opposed to complete-link methods which will make seemingly arbitrary cuts through regions of constant density. These advantages of single-link clustering, which seem most appropriate for perceptual problems, have been demonstrated in the literature; see e.g. <ref> [16] </ref>, [10] (section 6.10.2). If this heuristic is in doubt, one can always add additional quantizations, as mentioned earlier. The metric interpretation of the resulting hierarchy yields a distance function similar to that provided by the original vector space. However, many of the unnecessary distinctions between images have been removed.
Reference: [17] <author> R. A. Jarvis and E. A. Patrick. </author> <title> Clustering using a similarity measure based on shared near neighbors. </title> <editor> IEEE T. </editor> <booktitle> Comp., </booktitle> <pages> pages 1025-1034, </pages> <month> Nov. </month> <year> 1973. </year> <month> 52 </month>
Reference-contexts: However, the second representation has the benefit of speeding database access, raising recall rates, automatically introducing a "visual vocabulary," and providing a basis for the fusion of diverse similarity measures. Hierarchical clustering is obtained in FourEyes by the shared-neighbor algorithm in <ref> [17] </ref>. Define x to be a k-nearest neighbor of y when x is one of the k nearest data points to y in the vector space.
Reference: [18] <author> K. Sparck Jones. </author> <title> A statistical interpretation of term specificity and its application in retrieval. </title> <journal> Journal of Documentation, </journal> <volume> 28 </volume> <pages> 11-21, </pages> <year> 1972. </year>
Reference-contexts: There are several methods explored in document retrieval to alleviate this burden. First, a thesaurus can be used to add new terms to the query (query expansion). Second, terms which rarely occur in documents can be automatically increased in importance <ref> [18] </ref>. Third, the user can indicate which documents are relevant and which are not (relevance feedback: [52], section 7-4), allowing term weights to be automatically modified. Such methods are conspicuously rare in visual retrieval, for no apparent reason.
Reference: [19] <author> Pentti Kanerva. </author> <title> Sparse distributed memory. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1988. </year>
Reference-contexts: Network weights will arrange themselves to approximate the desired input-output mapping. Perceptron modifies the normal of the linear discriminant to point closer to a positive example or farther from a negative example. The effect is to find a boundary between the classes. Sparse distributed memory <ref> [19] </ref> maintains a randomly distributed set of fixed location memory cells. To write a value into an arbitrary location, average the value with the contents of the D nearest cells. To read a value from an arbitrary location, take the average of the D nearest cells.
Reference: [20] <author> T. Kohonen. </author> <title> Self-Organization and Associative Memory. </title> <publisher> Springer, </publisher> <address> Berlin, Heidelberg, </address> <year> 1984. </year> <note> 3rd ed. </note> <year> 1989. </year>
Reference-contexts: For example, these "neural" algorithms all follow the self-organization principle (though they are not continuous learners), where each "problem" is a single input point: Kohonen map <ref> [20] </ref> maintains a set of cluster centers. Given a point to approximate, the map outputs the nearest cluster center. Then it moves that center (and possibly others) slightly closer to the input point. The idea is that the approximation will be better for that point again.
Reference: [21] <author> P. Langley. </author> <title> Rediscovering physics with Bacon. </title> <booktitle> In Proc. Fifth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 505-507, </pages> <year> 1977. </year>
Reference-contexts: Since accuracy can only be determined empirically, it is important to be able to change it to track the problem domain. 33 Two provocative early AI experiments, which had good biases but did not modify them, were BACON <ref> [21] </ref> and AM [22]. BACON's task was to discover simple mathematical equations to explain a data set, such as a table of planetary revolution times versus their orbital distance.
Reference: [22] <author> D. B. Lenat. </author> <title> AM: Discovery in mathematics as heuristic search. </title> <editor> In R. Davis and D. B. Lenat, editors, </editor> <booktitle> Knowledge-Based Systems in Artificial Intelligence, </booktitle> <pages> pages 3-228. </pages> <publisher> McGraw-Hill, </publisher> <year> 1980. </year>
Reference-contexts: Since accuracy can only be determined empirically, it is important to be able to change it to track the problem domain. 33 Two provocative early AI experiments, which had good biases but did not modify them, were BACON [21] and AM <ref> [22] </ref>. BACON's task was to discover simple mathematical equations to explain a data set, such as a table of planetary revolution times versus their orbital distance. The program was able to discover Kepler's law and several others, by exploring and refining hypotheses which were arithmetic combinations of attributes.
Reference: [23] <author> D. B. Lenat, F. Hayes-Roth, and P. </author> <title> Klahr. </title> <journal> Cognitive economy in artificial intelligence systems. IJCAI, </journal> <volume> 6 </volume> <pages> 531-536, </pages> <year> 1979. </year>
Reference-contexts: If each of these layers can learn, then the higher layers effectively provide the bias for the lower layers, which report on their performance so that the higher layers can adapt. This "multi-scale learning" architecture, used in FourEyes, has numerous parallels: * The "data reductions" of <ref> [23] </ref>: induction, deduction, calculation, and access. Each reduction produces a simpler computational task.
Reference: [24] <author> F. Liu and R. W. </author> <title> Picard. Periodicity, directionality, and randomness: Wold features for image modeling and retrieval. </title> <journal> IEEE T. Patt. Analy. and Mach. Intell., </journal> <note> To appear. Also MIT Media Laboratory Perceptual Computing TR#320. </note>
Reference-contexts: But both of these tasks are plagued with difficulties. Research does not yet have the capability to mimic human perception in general contexts. Computational models which isolate one perceptual component, e.g. texture, have succeeded in benchmarks like the Brodatz [5] collection [43] <ref> [24] </ref>, but have yet to prove themselves on naturally-occurring imagery in which textures may be occluded, in perspective, warped around a surface, at different scales, in different colors and contrast, or have different lighting. Consequently, perceptual models are highly data-dependent; see figure 1.1 for an example. <p> Consequently, perceptual models are highly data-dependent; see figure 1.1 for an example. Unfortunately, the nature of the specialization is rarely clear from the definition of the model. (But see <ref> [24] </ref> for one attempt at this.) There is no clear separation between perception and semantics in image similarity. The right notion of similarity changes depending on context: the particular image, the particular database, the particular user, or their particular task; see figure 1.2 for an example. <p> In document retrieval, this has been shown to give substantially better results than using either measure alone. A similar, but more adaptive, method has achieved synergy between texture models <ref> [24] </ref>. In that work, the ranks are combined with unequal weight, determined from a measure of the periodicity of the texture. The weights can be determined a-priori because of careful selection of the models to be combined. Hierarchical clustering allows FourEyes to take a different approach.
Reference: [25] <author> D. J. C. MacKay. </author> <title> Bayesian interpolation. </title> <journal> Neural Computation, </journal> <volume> 4(3) </volume> <pages> 415-447, </pages> <year> 1992. </year>
Reference-contexts: Context is the provider of inductive bias, which is the reason we choose one candidate concept over another [33]. The classical algorithm for concept learning is this: choose the candidate concept most favored by the bias. This methodology is analogous to Bayesian inference <ref> [25] </ref>, where the likelihood function serves to isolate candidates and the prior provides the bias. Two important axes along which biases vary are strength (or precision) and accuracy (or correctness) [58]. Strong biases focus the learner on a relatively small number of concepts. <p> This methodology is analogous to expressing Bayesian inference in terms of minimum description length <ref> [25] </ref>, by inventing a suitable notion of "description." The concept vocabulary available to the algorithms is the same: groupings derived from hierarchical clustering (chapter 2). With a suitable vocabulary (described below), each of the three grammars is sufficient to encode all concepts.
Reference: [26] <author> R. Maclin and J. W. Shavlik. </author> <title> Refining alogrithms with knowledge-based neural networks: Improving the Chou-Fasman algorithm for protein folding. </title> <journal> Machine Learning, </journal> <volume> 11 </volume> <pages> 195-215, </pages> <year> 1993. </year>
Reference-contexts: Thus we see attempts to reduce the burden of setting these control knobs. One approach is transfer of training from old to new problems. For example, backpropagation training of artificial neural networks can be biased by the initial connection weights. In [44] and <ref> [26] </ref> this property was exploited by incorporating pretrained networks as parts of a new, larger network which was then retrained on a new problem and required fewer examples and/or was more accurate.
Reference: [27] <author> J. Mao and A. K. Jain. </author> <title> Texture classification and segmentation using multiresolution simultaneous autoregressive models. </title> <booktitle> Patt. Rec., </booktitle> <volume> 25(2) </volume> <pages> 173-188, </pages> <year> 1992. </year>
Reference-contexts: seems to require a close coupling between perceptual modeling, semantic modeling, and domain knowledge, gleaned from sources as diverse as computed attributes, text annotations, usage patterns, and subjective opinions. 3 retrieved based on their similarity to the pattern on the left, given the particular model space EV [43] or MRSAR <ref> [27] </ref>. The multi-resolution simultaneous auto-regressive (MRSAR) model, because it attempts to model fixed-size neighborhoods, misses the high-level structure that the shift-invariant eigenvector (EV) model does not. However, on other images the MRSAR does substantially better than EV [43]. brick straw matting oriental rattan brick visual context, or user preference. <p> For example, figure 2.4 shows how some textures are clustered by FourEyes on the basis of the MRSAR texture model <ref> [27] </ref>. Like the document-term matrix, the output of hierarchical clustering can be interpreted in two ways: 1. A new metric over the images, where distance between two images corresponds to the height of the lowest common ancestor ([10], section 6.10.4). 2.
Reference: [28] <author> R. S. Michalski. </author> <title> A theory and methodology of inductive learning. </title> <journal> Artificial Intelligence, </journal> <volume> 20(2) </volume> <pages> 111-161, </pages> <year> 1983. </year>
Reference-contexts: By viewing this problem as concept induction in the AI sense, we can apply standard machine learning algorithms, but in terms of set-based attributes. Three adapted algorithms: set covering <ref> [28] </ref> [14], decision list [47], and decision tree [15] [45] [4], are described here. This chapter drives home the point that learning performance hinges on the bias of the learner. Hence a robust solution is to make the choice as flexible as possible and then adapt it at runtime. <p> This problem is NP-complete [11], but there are a variety of greedy methods which get close to the optimum covering <ref> [28] </ref> [14]. For example, algorithm SC: 1. Choose the set c from C which covers the most positive examples and no negative examples. Resolve ties with a coin toss. 2. Remove all positive examples covered by c from consideration. 3. If positive examples remain, go back to step one.
Reference: [29] <author> R. S. Michalski. </author> <title> Inferential theory of learning as a conceptual basis for multistrategy learning. </title> <journal> Machine Learning, </journal> <volume> 11 </volume> <pages> 111-151, </pages> <year> 1993. </year>
Reference-contexts: However, it was limited to only weakening its bias, which will eventually degrade overall performance, without a corresponding strengthening operation. Multistrategy or task-adaptive learners <ref> [29] </ref> choose from a fixed set of biases in a problem-dependent manner. For example, [38] used a chain of learners, from explanation-based (strongly biased) to theory-driven (less biased) to similarity-based (weakly biased), which were applied in turn until one produced a consistent concept.
Reference: [30] <editor> R. S. Michalski, editor. </editor> <booktitle> Multistrategy Learning. </booktitle> <publisher> Kluwer Academic Publishers, </publisher> <year> 1993. </year>
Reference-contexts: The task of learning how to learn has cropped up repeatedly in the machine learning and artificial intelligence literature, culminating recently in the topic of multistrategy learning <ref> [30] </ref>, where the learner is given multiple biases to choose from. The fundamental adversary being fought is the generality/efficiency tradeoff: when a learner weakens its inductive bias and allows a greater variety of concepts to be learned, then it takes more examples, on average, to learn any particular concept.
Reference: [31] <author> R. S. Michalski and R. E. Stepp. </author> <title> Automated construction of classifications: Conceptual clustering versus numerical taxonomy. </title> <editor> IEEE T. Patt. Analy. </editor> <booktitle> and Mach. Intell., </booktitle> <address> PAMI-5(4):396-409, </address> <month> July </month> <year> 1983. </year>
Reference-contexts: Bias is crucial to any problem for which many possible answers may be valid, i.e. problems which are ill-defined such as representation, extrapolation, segmentation and clustering. Recognizing this, subsequent learners added control knobs for their bias. For example, the clustering program in <ref> [31] </ref> provided the user detailed control of its cluster evaluation function (its bias), in terms of simplicity, commonality, fit, discrimination, and so on. However, if the underlying attributes are nonintuitive, such controls will not make the clustering process intuitive again.
Reference: [32] <author> T. P. Minka and R. W. </author> <title> Picard. Interactive learning using a `society of models'. </title> <note> Submitted for Publication, 1995. Also appears as MIT Media Lab Perceptual Computing TR#349. </note>
Reference-contexts: This allows the learner to encode the plausibility of a grouping. An experiment was made to learn the best weight function over groupings, using a kind of Sparse Distributed Memory; this yielded a significant decrease in the learning time of SC <ref> [32] </ref>.
Reference: [33] <author> T. M. Mitchell. </author> <title> The need for biases in learning generalizations. </title> <type> Technical Report CBM-TR-117, </type> <institution> Rutgers University, </institution> <month> May </month> <year> 1980. </year>
Reference-contexts: Unfortunately, this is exactly what happens when we present our learning problems to a computer. So the issue is not the ill-posedness; it is the lack of context. Context is the provider of inductive bias, which is the reason we choose one candidate concept over another <ref> [33] </ref>. The classical algorithm for concept learning is this: choose the candidate concept most favored by the bias. This methodology is analogous to Bayesian inference [25], where the likelihood function serves to isolate candidates and the prior provides the bias. <p> Indeed, it was this notion of heuristics which prune the search through concept space that gave rise to the term inductive bias: "any basis for choosing one generalization over another, other than strict consistency with the observed training examples" <ref> [33] </ref>. Bias is crucial to any problem for which many possible answers may be valid, i.e. problems which are ill-defined such as representation, extrapolation, segmentation and clustering. Recognizing this, subsequent learners added control knobs for their bias. <p> This dissertation introduced malleability as a general criterion for evaluating concept learners. This is more practical than Mitchell's proposition that inductive bias be used as the criterion for comparing and evaluating concept learners <ref> [33] </ref>, because the quality of an inductive bias varies with the problem domain. Malleability, instead, is the ability of a learner to adapt its bias to the problem domain. A malleable learner allows direct translation of domain characteristics into learning parameters.
Reference: [34] <author> W. Niblack, R. Barber, W. Equitz, M. Flickner, E. Glasman, D. Petkovic, P. Yanker, and C. Faloutsos. </author> <title> The QBIC project: Querying images by content using color, texture, and shape. </title> <editor> In W. Niblack, editor, </editor> <title> IS & T Storage and Retrieval for Image and Video Databases, </title> <booktitle> volume 1908, </booktitle> <month> Feb. </month> <year> 1993. </year> <institution> IBM TechReport RJ9203 (815111), </institution> <month> Feb. </month> <year> 1993. </year>
Reference-contexts: The prototype datum may be selected from the database or provided by the user, e.g. with a sketchpad. Some examples of this approach are QBIC <ref> [34] </ref>, SWIM [62], CORE [61], and Photobook [39] (figure 1.3). Unfortunately, this approach does not scale to arbitrary content, because it relies crucially on the similarity measure and the user's ability to choose it. Designing the measures is extremely hard, since each of the difficulties identified above apply.
Reference: [35] <author> Y-I Ohta, T. Kanade, and T. Sakai. </author> <title> Color information for region segmentation. Comp. Graph. </title> <journal> and Img. Proc., </journal> <volume> 13 </volume> <pages> 222-241, </pages> <year> 1980. </year>
Reference-contexts: The color space was the Ohta principal components of the RGB cube <ref> [35] </ref>. The "VisTex" hierarchy contains the 167 four-image groupings defined by the cropping process. The DT algorithm does best, but as before it exhibits diminishing returns with more hierarchies, while the SC does not.
Reference: [36] <author> G. Pagallo and D. Haussler. </author> <title> Boolean feature discovery in empirical learning. </title> <journal> Machine Learning, </journal> <volume> 5 </volume> <pages> 71-99, </pages> <year> 1990. </year>
Reference-contexts: This general scheme carries over to learning problems with linear or continuous attributes, given suitable transformation operators and definition of dispersion. More research needs to be done in finding and validating instantiations of this scheme. An attribute construction heuristic for decision trees was proposed in <ref> [36] </ref>. It was inspired by the observation that decision trees cannot explicitly represent branching on conjunctions of decisions. When a concept requires a conjunction of decisions, two identical subtrees are created; they call this the replication problem.
Reference: [37] <author> M. Pavel, M. A. Gluck, and V. Henkle. </author> <title> Constraints on adaptive networks for modeling human generalization. </title> <editor> In D. S. Touretzky, editor, </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> volume 1, </volume> <pages> pages 2-10, </pages> <year> 1988. </year>
Reference-contexts: 1 1 0 4 1 0 1 0 0 1 0 1 0 1 0 1 0 1 0 1 Category A A A A B B B B ? ? ? ? ? ? ? ? Take a moment to consider the classification problem in figure 3.1 (taken from <ref> [37] </ref>).
Reference: [38] <author> M. J. Pazzani. </author> <title> Learning causal patterns: Making a transition from data-driven to theory-driven learning. </title> <journal> Machine Learning, </journal> <volume> 11 </volume> <pages> 173-194, </pages> <year> 1993. </year>
Reference-contexts: However, it was limited to only weakening its bias, which will eventually degrade overall performance, without a corresponding strengthening operation. Multistrategy or task-adaptive learners [29] choose from a fixed set of biases in a problem-dependent manner. For example, <ref> [38] </ref> used a chain of learners, from explanation-based (strongly biased) to theory-driven (less biased) to similarity-based (weakly biased), which were applied in turn until one produced a consistent concept.
Reference: [39] <author> A. Pentland, R. W. Picard, and S. Sclaroff. Photobook: </author> <title> Tools for content-based manipulation of image databases. </title> <booktitle> In SPIE Storage and Retrieval of Image & Video Databases II, </booktitle> <pages> pages 34-47, </pages> <address> San Jose, CA, </address> <month> Feb. </month> <year> 1994. </year>
Reference-contexts: The prototype datum may be selected from the database or provided by the user, e.g. with a sketchpad. Some examples of this approach are QBIC [34], SWIM [62], CORE [61], and Photobook <ref> [39] </ref> (figure 1.3). Unfortunately, this approach does not scale to arbitrary content, because it relies crucially on the similarity measure and the user's ability to choose it. Designing the measures is extremely hard, since each of the difficulties identified above apply.
Reference: [40] <author> R. W. </author> <title> Picard. Toward a visual thesaurus. </title> <note> In Springer-Verlag Workshops in Computing, 1995. To appear; Also appears as MIT Media Lab Perceptual Computing TR #358. </note>
Reference-contexts: However, there are numerous obstacles to achieving this kind of efficiency with multimedia. First, there are far more levels of abstraction at which the data can be perceived. 9 arc. This makes the notion of "misspelling," "synonym," or "same" much harder to quantify. (See <ref> [40] </ref> for an example.) Second, automatic modeling of human perception is unsolved, requiring some degree of user guidance. (If we raise our standards for text manipulation, for example to the domain of meaning, we can find the same difficulties.) FourEyes presents an approach to seemless interaction between multiple levels of abstraction
Reference: [41] <author> R. W. </author> <title> Picard. </title> <journal> Computer learning of subjectivity. ACM Computing Surveys, </journal> <note> 1996. To appear; Also appears as MIT Media Lab Perceptual Computing TR #359. </note>
Reference-contexts: Since the later stages of the system only see groupings, not feature values, it is not necessary for continuous similarity spaces to be used. For example, this is advantageous for incorporating subjective associations among content <ref> [41] </ref>. For humans, it is often easier to specify groupings of image regions than to attach meaningful and consistent attributes to them. 20 Chapter 3 Learning image annotations Chapter 2 showed how different similarity measures can be placed into a common vocabulary of groupings.
Reference: [42] <author> R. W. Picard and T. Kabir. </author> <title> Finding similar patterns in large image databases. </title> <booktitle> In Proc. IEEE Conf. on Acoustics, Speech, and Signal Proc., pages V-161-V-164, </booktitle> <address> Minneapolis, MN, </address> <year> 1993. </year>
Reference-contexts: These had a total of 700 groupings (excluding singleton groupings). Given this feeble knowledge, SC required 0:98N examples to reach zero error (call this the learning time). The second experiment used a hierarchy generated by clustering the images by EV features <ref> [42] </ref> (the hierarchy contained 427 groupings). This knowledge reduced the learning time to 0:59N examples. The third experiment used a hierarchy generated by clustering the images with MRSAR (the hierarchy contained 255 groupings).
Reference: [43] <author> R. W. Picard, T. Kabir, and F. Liu. </author> <title> Real-time recognition with the entire Brodatz texture database. </title> <booktitle> In Proc. IEEE Conf. on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 638-639, </pages> <address> New York, </address> <month> June </month> <year> 1993. </year>
Reference-contexts: But both of these tasks are plagued with difficulties. Research does not yet have the capability to mimic human perception in general contexts. Computational models which isolate one perceptual component, e.g. texture, have succeeded in benchmarks like the Brodatz [5] collection <ref> [43] </ref> [24], but have yet to prove themselves on naturally-occurring imagery in which textures may be occluded, in perspective, warped around a surface, at different scales, in different colors and contrast, or have different lighting. Consequently, perceptual models are highly data-dependent; see figure 1.1 for an example. <p> Fielding such requests seems to require a close coupling between perceptual modeling, semantic modeling, and domain knowledge, gleaned from sources as diverse as computed attributes, text annotations, usage patterns, and subjective opinions. 3 retrieved based on their similarity to the pattern on the left, given the particular model space EV <ref> [43] </ref> or MRSAR [27]. The multi-resolution simultaneous auto-regressive (MRSAR) model, because it attempts to model fixed-size neighborhoods, misses the high-level structure that the shift-invariant eigenvector (EV) model does not. However, on other images the MRSAR does substantially better than EV [43]. brick straw matting oriental rattan brick visual context, or user <p> pattern on the left, given the particular model space EV <ref> [43] </ref> or MRSAR [27]. The multi-resolution simultaneous auto-regressive (MRSAR) model, because it attempts to model fixed-size neighborhoods, misses the high-level structure that the shift-invariant eigenvector (EV) model does not. However, on other images the MRSAR does substantially better than EV [43]. brick straw matting oriental rattan brick visual context, or user preference. Most computational models notice that all of these have similar horizontal/vertical structure. However, one model may decide that the two brick images are most similar, and another model may decide that the top two images are most similar. <p> This knowledge reduced the learning time to 0:59N examples. The third experiment used a hierarchy generated by clustering the images with MRSAR (the hierarchy contained 255 groupings). The MRSAR has demonstrated excellent matching performance on this database in earlier experiments <ref> [43] </ref>, so we would expect learning to proceed even faster. This was indeed the case; the learning time was 0:4N examples. The fourth experiment used a hierarchy ("Brodatz") which explicitly contained the 112 textures as groupings (148 groupings total).
Reference: [44] <author> L. Y. Pratt. </author> <title> Experiments on the transfer of knowledge between neural networks. </title> <editor> In S. J. Hanson, G. A. Drastal, and R. L. Rivest, editors, </editor> <booktitle> Computational Learning Theory and Natural Learning Systems, </booktitle> <volume> volume 1, </volume> <pages> pages 523-560. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1994. </year>
Reference-contexts: Thus we see attempts to reduce the burden of setting these control knobs. One approach is transfer of training from old to new problems. For example, backpropagation training of artificial neural networks can be biased by the initial connection weights. In <ref> [44] </ref> and [26] this property was exploited by incorporating pretrained networks as parts of a new, larger network which was then retrained on a new problem and required fewer examples and/or was more accurate.
Reference: [45] <author> J. R. Quinlan. </author> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1 </volume> <pages> 81-106, </pages> <year> 1986. </year>
Reference-contexts: By viewing this problem as concept induction in the AI sense, we can apply standard machine learning algorithms, but in terms of set-based attributes. Three adapted algorithms: set covering [28] [14], decision list [47], and decision tree [15] <ref> [45] </ref> [4], are described here. This chapter drives home the point that learning performance hinges on the bias of the learner. Hence a robust solution is to make the choice as flexible as possible and then adapt it at runtime. This extension is explored in chapter 4. <p> A further relaxation of constraints allows the learner to choose a decision which simply makes the best division of the examples into two parts, each of which may require further division. This yields a greedy algorithm which builds decision trees [15] <ref> [45] </ref> [4] (see figure 3.4). Unlike the methods in [45] and [4], we're going to use no stopping or pruning criterion to halt tree growth, because in an interactive setting the learner is expected to classify all training points correctly. <p> This yields a greedy algorithm which builds decision trees [15] <ref> [45] </ref> [4] (see figure 3.4). Unlike the methods in [45] and [4], we're going to use no stopping or pruning criterion to halt tree growth, because in an interactive setting the learner is expected to classify all training points correctly. Another difference is that DT uses set membership to make decisions, not raw attribute values.
Reference: [46] <author> L. Rendell and R. Seshu. </author> <title> Learning hard concepts through constructive induction: Framework and rationale. </title> <editor> In S. J. Hanson, G. A. Drastal, and R. L. Rivest, editors, </editor> <booktitle> Computational Learning Theory and Natural Learning Systems, </booktitle> <volume> volume 1, </volume> <pages> pages 83-142. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1994. </year>
Reference-contexts: Its power came from a constrained search through the concept space, which trimmed down the choices available to the learner and thus reduced the apparent complexity of the problem, as described in <ref> [46] </ref>. AM also used heuristics for mathematical discovery, this time to optimize a notion of "interestingness." Starting with set theory and some general heuristics, the program could synthesize concepts ranging from natural numbers to the fundamental theorem of arithmetic. <p> First pass 2 2 2 2 2 2 2 2 2 2 2 Second pass fi fi fi fi fi fi fi (Cf. figure 4.11.) The ideal times are again on the bottom on the graph. 4.4.3 Related work Improving the vocabulary available to a learner is also investigated in <ref> [46] </ref>. That work was inspired by the observation that large decision trees are produced by concepts having many separate peaks in attribute space with many attributes defining each peak.
Reference: [47] <author> R. Rivest. </author> <title> Learning decision lists. </title> <journal> Machine Learning, </journal> <volume> 2 </volume> <pages> 229-246, </pages> <year> 1987. </year>
Reference-contexts: By viewing this problem as concept induction in the AI sense, we can apply standard machine learning algorithms, but in terms of set-based attributes. Three adapted algorithms: set covering [28] [14], decision list <ref> [47] </ref>, and decision tree [15] [45] [4], are described here. This chapter drives home the point that learning performance hinges on the bias of the learner. Hence a robust solution is to make the choice as flexible as possible and then adapt it at runtime. <p> The fact that the algorithm is an approximation also adds bias, although in this case we know the approximation error is not great. 3.2.2 Decision list The requirement of SC that at each step we cover no negative examples seems somewhat harsh and asymmetric. The decision list <ref> [47] </ref> algorithm instead chooses sets which either (1) include positive but no negative examples or (2) include negative but no positive examples. The complements of sets from C may also be used, even though they are not explicitly contained in C.
Reference: [48] <author> R. L. Rivest. </author> <title> On self-organizing sequential search heuristics. </title> <journal> Comm. ACM, </journal> <volume> 19 </volume> <pages> 63-67, </pages> <year> 1976. </year>
Reference-contexts: To read a value from an arbitrary location, take the average of the D nearest cells. The self-organization principle is also used in searchable data structures, to dynamically optimize them according to the distribution of queries. For example, the "move to front rule" is used for sequential lists <ref> [48] </ref> and the "move to root rule" is used for binary trees [1]. Of course, if the query distribution is fixed and known beforehand, a static Huffman tree is optimal; this is the usual tradeoff between off-line and on-line solutions.
Reference: [49] <author> D. Romer. </author> <title> The Kodak picture exchange, </title> <month> April </month> <year> 1995. </year> <institution> seminar at MIT Media Lab. </institution>
Reference-contexts: For example, a stock photography agency may get a request for "a dry, open shot, at a weird angle," "a threatening forest, with a repeating pattern," or "a group of people reflecting in rippled water" <ref> [49] </ref>. It is an unsolved problem to derive such annotations automatically, or even to offer database navigation with these kinds of abstractions. <p> The document-term matrix should be generalized to a document-attribute matrix, where attributes might be "about NASA rocketry," "something Joe liked," or "well-written, with lots of pictures." The same applies to images; users may want "dry, open shots" or "powerful lines" <ref> [49] </ref>. While arbitrary attributes like these can significantly improve perceived performance on some queries and for some users, they may just as likely be irrelevant.
Reference: [50] <author> D. E. Rumelhart, G. E. Hinton, and R. J. Williams. </author> <title> Learning representations by back-propagating errors. </title> <journal> Nature, </journal> <volume> 323(9) </volume> <pages> 533-536, </pages> <month> October </month> <year> 1986. </year>
Reference-contexts: The idea is that the approximation will be better for that point again. The result of this simple algorithm is that cluster centers will arrange themselves to match the distribution of the input, so that the mean squared error of the approximation is minimized. Backpropagation <ref> [50] </ref> modifies connection weights to minimize the difference between the last output and the desired output. Network weights will arrange themselves to approximate the desired input-output mapping. Perceptron modifies the normal of the linear discriminant to point closer to a positive example or farther from a negative example.
Reference: [51] <author> E. Saber, A. M. Tekalp, R. Eschbach, and K. Knox. </author> <title> Annotation of natural scenes using adaptive color segmentation. IS&T/SPIE Electronic Imaging, </title> <address> Feb. 1995. San Jose, CA. </address>
Reference-contexts: For example, if a within-image grouping utilizes face detection to produce segments containing faces, the across-image grouping can use a face classifier. The advantage of incorporating within-image relationships for across-image annotation is described in <ref> [51] </ref>. For color-based annotation of image regions, that work demonstrated a clear qual 19 which contains c; e.g. they might be house, door of the house, window on the door. When projected into feature space, they are considered individually, and look different. <p> FourEyes approximates this behavior by forming its across-image groupings from within-image groupings. Moreover, the shared neighbor clustering algorithm used by FourEyes behaves similarly to the histogram splitting used in <ref> [51] </ref>, so the within-image groupings generated by both methods similarly preserve class-likelihood continuity. All of these within-image and across-image groupings are computed off-line, before the user begins interaction with the system.
Reference: [52] <author> G. Salton. </author> <title> Automatic Information Organization and Retrieval. </title> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <year> 1968. </year>
Reference-contexts: The selection and combination process is furthermore controlled by learning from positive and negative examples from the user. For example, "these objects are cars, those are telephones," or "these are the kind of images I'm looking for; those aren't." The latter kind of interaction, known as relevance feedback <ref> [52] </ref>, is common in document retrieval. FourEyes puts much more emphasis on learning how to select and combine similarity measures than designing and understanding them. Besides making user interaction easier, this approach eases development of browsers, since newly discovered measures can be added invisibly to the user. <p> This might be 1 if the document has the term, 0 otherwise, or perhaps the normalized frequency of occurrence of the term in the document. These vectors can be interpreted as rows of a document-term connection matrix (figure 2.2; see also <ref> [52] </ref>, section 2-5). The system then assigns each document a relevance score according to the similarity of its terms with the query and the connection strength of those terms to the document as a whole. <p> Boolean queries now correspond to fuzzy set operations on columns and do not require scanning every document's entire term vector, as in the first approach. Instead of clustering documents, this representation allows us to cluster terms, e.g. for automatic thesaurus generation <ref> [52] </ref>. The membership values in each term column define a similarity measure over documents. For example, according to "rocket", document 1 is similar to 4 but not to 2. <p> The groupings thus form FourEyes' vocabulary about images. This is similar to the process of automatic thesaurus construction for document databases <ref> [52] </ref>. However, it is unclear how this new "visual vocabulary" could be used for manually formulating queries. It seems that a more automatic approach to formulation is needed. <p> First, a thesaurus can be used to add new terms to the query (query expansion). Second, terms which rarely occur in documents can be automatically increased in importance [18]. Third, the user can indicate which documents are relevant and which are not (relevance feedback: <ref> [52] </ref>, section 7-4), allowing term weights to be automatically modified. Such methods are conspicuously rare in visual retrieval, for no apparent reason. Perhaps the belief remains that computed visual attributes like the MRSAR or EV are sufficiently intuitive.
Reference: [53] <author> E. Saund and T. P. Moran. </author> <title> Perceptual organization in an interactive sketch editing application. </title> <booktitle> In Proc. Fifth International Conference on Computer Vision, </booktitle> <pages> pages 597-604, </pages> <address> Cambridge, MA, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: The paradigm is similar to that of the perceptually organized editing program PerSketch <ref> [53] </ref>. Under this paradigm, the single object hierarchy of conventional paint programs is traded for multiple, possibly conflicting organizations. The amount of structure imposed by the system is mediated by an example-based interaction with the user. <p> Upon termination, the blackboard 11 contains all segmentations suggested by the agents which are consistent with the domain knowledge. This provides the desired retainment of ambiguity. A program employing a similar approach, but geared toward interactive applications, is PerSketch <ref> [53] </ref>, a perceptually-organized graphical editor. Here agents also propose segmentations, but instead of using rules to eliminate hypotheses, the hypotheses are all made available to the user.
Reference: [54] <author> T. M. Strat and M. A. Fischler. </author> <title> Context-based vision: Recognizing objects using information from both 2-d and 3-d imagery. </title> <journal> IEEE T. Patt. Analy. and Mach. Intell., </journal> <volume> 13(10) </volume> <pages> 1050-1065, </pages> <month> Oct. </month> <year> 1991. </year>
Reference-contexts: Thus it is important in a database application that the machine decompose an image in multiple ways, ordered according to their probable utility to a user. An approach which addresses both of these complaints is context-based vision, as practiced by CONDOR <ref> [54] </ref>. CONDOR works by updating a blackboard of segmentation/classification hypotheses, using explicit rules for creating and removing hypotheses. The rules specify which of a variety of specialized algorithms, or agents, should be consulted to produce a hypothesis.
Reference: [55] <author> Richard S. Sutton, </author> <title> editor. Reinforcement learning. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1992. </year> <note> Reprinted from Machine Learning vol. 8, nos. 3-4. 54 </note>
Reference-contexts: Unfortunately, the paper does not give a proof of convergence nor demonstrate the transfer of this training to new problems. The constructed attributes may not form a hierarchical structure, making the algorithm difficult to implement efficiently. Continuous learning shares qualities with reinforcement learning <ref> [55] </ref>, because it involves simultaneous modeling of the world and acting upon that model. But while reinforcement learning, e.g. Q-learning [60], learns observation-action rules for direct interaction with the world, continuous learning is indirect: it provides a bias for a general-purpose learner which then does the interaction.
Reference: [56] <author> C. W. Therrien. </author> <title> Decision Estimation and Classification. </title> <publisher> John Wiley and Sons, Inc., </publisher> <address> New York, </address> <year> 1989. </year>
Reference-contexts: The example-based learning, supported by continuous self-improvement, allows rapid and natural specification of the level of abstraction. 1.3.2 Attribute Selection for Pattern Recognition Solutions to pattern recognition problems can generally be described by a two-stage process (figure 1.7, see also <ref> [56] </ref>, section 1.3). First the raw input data is projected into a suitable attribute space, then decision rules are applied to the attribute values. For example, a rule might be "anything which is red is an apple," where color is the representation of the input.
Reference: [57] <author> M. A. Turk and A. P. Pentland. </author> <title> Face recognition using eigenfaces. </title> <booktitle> In Proc. IEEE Conf. on Computer Vision and Pattern Recognition, </booktitle> <address> Maui, HI, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: The amount of structure imposed by the system is mediated by an example-based interaction with the user. This makes image organization more like a process of discovery, for both the system and user. In PerSketch, 5 the upper left, using an eigenpicture space <ref> [57] </ref>. The ordering is one-dimensional, but displayed in raster scans. 6 recovering useful within-image or across-image groupings.
Reference: [58] <author> P. Utgoff. </author> <title> Machine Learning of Inductive Bias. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, MA, </address> <year> 1986. </year>
Reference-contexts: This methodology is analogous to Bayesian inference [25], where the likelihood function serves to isolate candidates and the prior provides the bias. Two important axes along which biases vary are strength (or precision) and accuracy (or correctness) <ref> [58] </ref>. Strong biases focus the learner on a relatively small number of concepts. Assigning equal probability to all candidate concepts is the weakest possible bias. (Hence the weakness of a bias is analogous to the entropy of the prior probability distribution. <p> Thus the number of candidate concepts, for any set of examples, is the same for all three grammars. Traditional analysis methods are unable to distinguish these grammars, since their VC dimension [14] is infinite and they are all accurate <ref> [58] </ref>. However, it will be shown that they have significant performance differences. <p> This has a direct effect on their precision, as we shall see, because the rules denoting the same concept may have different sizes. The effect on accuracy is more problematic. Since the target concept is always a candidate, some authors would say that all three biases are accurate <ref> [58] </ref>, however this is not very informative. A better definition would include the preference assigned to the target concept, e.g. the average size of the rules which can represent it. This is left as a research exercise. 3.2.1 Set covering The set covering algorithm represents concepts via set union. <p> DT suffered from this problem in section 3.3.1. A more automatic approach is for the learner itself to modify its bias at runtime, e.g. by changing the set of available concepts. Utgoff <ref> [58] </ref> showed a learner which could automatically enlarge its concept language when the current one was unable to express the target (i.e. all concepts were inconsistent with the examples). However, it was limited to only weakening its bias, which will eventually degrade overall performance, without a corresponding strengthening operation.
Reference: [59] <author> V. Vapnik. </author> <title> Principles of risk minimization for learning theory. </title> <editor> In J. E. Moody, S. J. Hanson, and R. P. Lippmann, editors, </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> volume 4, </volume> <pages> pages 831-838, </pages> <year> 1992. </year>
Reference-contexts: Since speed is coupled with scale, we can also call this method "multi-speed learning." Multi-speed learning can be viewed as an on-line version of structural risk minimization <ref> [59] </ref>. Structural risk minimization arises from the observation that a learner's bias makes it suitable only for certain numbers of examples. For example, the number of parameters in a function approximator 46 determines both how many examples it needs and how many it can understand.
Reference: [60] <author> C. J. C. H. Watkins and P. Dayan. </author> <note> Technical note: Q-learning. Machine Learning, 8(3-4):279-292, </note> <year> 1991. </year>
Reference-contexts: The constructed attributes may not form a hierarchical structure, making the algorithm difficult to implement efficiently. Continuous learning shares qualities with reinforcement learning [55], because it involves simultaneous modeling of the world and acting upon that model. But while reinforcement learning, e.g. Q-learning <ref> [60] </ref>, learns observation-action rules for direct interaction with the world, continuous learning is indirect: it provides a bias for a general-purpose learner which then does the interaction. However, continuous learning can be applied to any learning problem, including reinforcement learning. <p> However, continuous learning can be applied to any learning problem, including reinforcement learning. For example, most reinforcement learners do not use a look-up table to store Q-values, as Watkins suggests <ref> [60] </ref>, but rather a generalizer such as a neural network. Such generalizers can benefit from continuous learning to adapt their bias. Neural networks and genetic algorithms have a number of parameters to their bias, yet these are notoriously difficult to adjust without brute-force search.
Reference: [61] <author> J. K. Wu, A. D. Narasimhalu, B. M. Mehtre, C. P. Lam, and Y. J. Gao. </author> <title> CORE: a content-based retrieval engine for multimedia information systems. </title> <journal> Multimedia Systems, </journal> <volume> 2 </volume> <pages> 25-41, </pages> <month> Feb. </month> <year> 1995. </year>
Reference-contexts: The prototype datum may be selected from the database or provided by the user, e.g. with a sketchpad. Some examples of this approach are QBIC [34], SWIM [62], CORE <ref> [61] </ref>, and Photobook [39] (figure 1.3). Unfortunately, this approach does not scale to arbitrary content, because it relies crucially on the similarity measure and the user's ability to choose it. Designing the measures is extremely hard, since each of the difficulties identified above apply.
Reference: [62] <author> H.-J. Zhang and S. W. Smoliar. </author> <title> Developing power tools for video indexing and retrieval. </title> <editor> In W. Niblack and R. C. Jain, editors, </editor> <booktitle> Proceedings SPIE Storage and Retrieval for Image and Video Databases II, </booktitle> <pages> pages 140-149, </pages> <address> San Jose, CA, </address> <month> Feb. </month> <year> 1994. </year> <booktitle> SPIE. </booktitle> <volume> Vol. </volume> <pages> 2185. </pages>
Reference-contexts: The prototype datum may be selected from the database or provided by the user, e.g. with a sketchpad. Some examples of this approach are QBIC [34], SWIM <ref> [62] </ref>, CORE [61], and Photobook [39] (figure 1.3). Unfortunately, this approach does not scale to arbitrary content, because it relies crucially on the similarity measure and the user's ability to choose it. Designing the measures is extremely hard, since each of the difficulties identified above apply.
Reference: [63] <author> S. C. Zhu, T. S. Lee, and A. L. Yuille. </author> <title> Region competition: Unifying snakes, region growing, energy/Bayes/MDL for multi-band image segmentation. </title> <booktitle> In Int. Conf. on Computer Vision, </booktitle> <pages> pages 416-423, </pages> <address> Boston, MA, </address> <year> 1995. </year> <month> 55 </month>
Reference-contexts: This progression, moving from optimization to blackboards to user-guidance, is marked by an increasing utilization of domain knowledge or context and retaining of the ambiguity in the image. A segmentation approach which capstones much of the existing research is region competition <ref> [63] </ref>, which attempts to optimize a general-purpose fitness function over region interiors and region boundaries. The algorithm strives for the "simplest" segmentation, i.e. the one with smoothest interiors and smoothest boundaries. This intractable optimization problem must always be solved by an approximate method; in [63] this is region growing. <p> the existing research is region competition <ref> [63] </ref>, which attempts to optimize a general-purpose fitness function over region interiors and region boundaries. The algorithm strives for the "simplest" segmentation, i.e. the one with smoothest interiors and smoothest boundaries. This intractable optimization problem must always be solved by an approximate method; in [63] this is region growing. The algorithm thus scatters seed regions randomly across the image and then iteratively grows them in a way that incrementally produces the greatest increase in the fitness function.
References-found: 63

