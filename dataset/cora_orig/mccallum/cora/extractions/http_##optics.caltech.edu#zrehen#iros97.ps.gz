URL: http://optics.caltech.edu/zrehen/iros97.ps.gz
Refering-URL: http://optics.caltech.edu/zrehen/sz_publis.html
Root-URL: http://www.cs.caltech.edu
Email: e-mail:  joulain@ensea.fr  
Title: Visual Navigation in an open environment without map  
Author: P. Gaussier, C. Joulain, S. Zrehen, J.P. Banquet A. Revel ENSEA ETIS, Av du Ponceau, 
Note: gaussier or  
Address: 95014 Cergy Pontoise Cedex, France CREARE Universite Paris VI, France  
Abstract: In this paper we describe how a mobile robot controled only by visual information can retrieve a particular goal location in an open environment. Our model does not need a precise map nor to learn all the possible positions in the environment. The system is a neural architecture inspired from neurobiological studies using the recognition of visual patterns called landmarks. The robot merges those visual information and their azimuth to build a plastic representation of its location. This representation is used to learn the best movement to reach the goal. A simple and fast on line learning of a few places located near the goal allows the robot to reach the goal from anywhere in its neighborhood. The system uses only egocentric representation of the robot environment and presents very high generalization capabilities. We describe an efficient implementation tested on our robot in two real indoor environments. We show the limitations of the model and its possible extensions to create autononous robots only guided by visual information. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R.C. Arkin. </author> <title> Motor schema-based mobile robot navigation. </title> <journal> International Journal of Robotics Research, </journal> <pages> pages 92-112, </pages> <year> 1987. </year>
Reference-contexts: In a less structured environment, when the robot does not move in corridors but must evoluate in a room or in any other "open" environment, potential field techniques <ref> [1] </ref> can be used. For each location the strenght of the attraction of the goal on the robot is computed. It implies at least to store the goal location and the robot location in a cartesian referential frame (need to compute precise trigonometrical computations).
Reference: [2] <author> J.P. Banquet, J.L. Contreras-Vidal, P. Gaussier, and Y. Burnod. </author> <title> Fundamentals of neural network modelling for neuropsychologists, chapter The cortical-hippocampal system as a multirange temporal processor: A neural model. </title> <publisher> MIT Press, </publisher> <address> Boston, </address> <year> 1997. </year>
Reference-contexts: This "plastic" merging by opposition to the static recognition of a multisensor configuration seems to be performed by a brain region called the hippocam-pus and involved in the memorization and navigation processes (processes that we study in the frame of a neurobiological project <ref> [2] </ref>). Direction of movement are WTA. Landmarks azimuths emphasizes merging of visual and motor flow. The place representation (Landmarks Azimuths) is learned by the Place Cells group of neurons.
Reference: [3] <author> G. Bugmann. </author> <title> Spatial memory and planning for mobile robot navigation: A connectionist approach. </title> <type> Technical report, </type> <year> 1997. </year>
Reference-contexts: In the case of real autonomous navigation, if the robot forgets to learn a place or learns several times the same physical place, it becomes unable to navigate correctly (cut or infinite loop in the graph of its cognitive map - <ref> [3] </ref>). In a less structured environment, when the robot does not move in corridors but must evoluate in a room or in any other "open" environment, potential field techniques [1] can be used. For each location the strenght of the attraction of the goal on the robot is computed.
Reference: [4] <author> B.A. Cartwright and T.S. Collett. </author> <title> Landmark learning in bees. </title> <journal> Journal Comp. Physiology, </journal> <volume> 151 </volume> <pages> 521-543, </pages> <year> 1983. </year>
Reference-contexts: Finally, we discuss experimental results and propose different improvements of this first implementation. 1 2 Landmark-based navigation More and more systems take into account the fact that animals mainly use landmark information and navigate directly from 2D perceived images <ref> [4] </ref>. This approach reduces their algorithmic complexity and increases their robustness (qualitative navigation [12], visual homing [13]). The PerAc architecture is a neural computation architecture proposed to solve a wide variety of control problems requiring learning capabilities (by opposition to adaptation 1 capabilities).
Reference: [5] <author> R. Chatila. </author> <title> Control architecture for autonomous mobile robots. </title> <editor> In P. Gaussier and J.D. Nicoud, editors, </editor> <booktitle> Proc. of Perception to Action, </booktitle> <pages> pages 254-265, </pages> <address> Lausanne, 1994. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: Unfortunately, odometry currently used to measure distances is not precise in a long run and must be recalibrated by other sources of information such as particular visual patterns called landmarks <ref> [5] </ref>. Thus in both structured and "open" environments, the actual main problem in realizing really autonomous mobile robots is linked to the problem of finding learning criteria such as how to choose the learned positions and how to regulate the learning level [6].
Reference: [6] <author> M.J. Denham and S.L. McCabe. </author> <title> Biological temporal sequence processing and its application in robot control. </title> <booktitle> In Control96, </booktitle> <pages> pages 1266-1271, </pages> <year> 1996. </year>
Reference-contexts: Thus in both structured and "open" environments, the actual main problem in realizing really autonomous mobile robots is linked to the problem of finding learning criteria such as how to choose the learned positions and how to regulate the learning level <ref> [6] </ref>. The way information is represented seems to be crucial to reduce the algorithm complexity. Indeed, if the robot had to learn each position in the environment before being able to navigate correctly, the learning time would be huge. Moreover, the robot would be unable to perform topological generalization.
Reference: [7] <author> P. Gaussier, A. Revel, C. Joulain, and S. Zrehen. </author> <title> Living in a partially structured environment: How to bypass the limitation of classical reinforcement techniques. </title> <booktitle> to appear in Robotics and Autonomous Systems, </booktitle> <year> 1997. </year>
Reference-contexts: The robot would then find a movement that allows it to go in a direction associated to a global increase of the goal recognition (an efficient reinforcement learning rule is described in <ref> [7] </ref>). Our future work will consist in testing for real a planification level allowing the robot to pass from one subgoal to another in order to reach a particular goal.
Reference: [8] <author> P. Gaussier and S. Zrehen. </author> <title> Avoiding the world model trap: an acting robot does not need to be so smart! Robotics and Computer-Integrated Manufacturing, </title> <booktitle> 11 </booktitle> <pages> 279-286, </pages> <year> 1994. </year>
Reference-contexts: So the robot knows that its movement was wrong. Obviously more efficient trajectories could be obtained if the movements are performed randomly according to their associated neuron activity rather than according to a deterministic WTA mechanism <ref> [8] </ref>. Moreover, our N.N. can also be used to avoid particular zones or to introduce other goals [9]. 5 Conclusion Our algorithm works correctly even in difficult situations. It supports a lack of landmarks or a misinterpretation of a few of the landmarks.
Reference: [9] <author> P. Gaussier and S. Zrehen. </author> <title> Navigating with an animal brain : a neural network for landmark identification and navigation. </title> <booktitle> In Proceedings of Intelligent Vehicles, </booktitle> <pages> pages 399-404, </pages> <address> Paris, </address> <year> 1994. </year>
Reference-contexts: Obviously more efficient trajectories could be obtained if the movements are performed randomly according to their associated neuron activity rather than according to a deterministic WTA mechanism [8]. Moreover, our N.N. can also be used to avoid particular zones or to introduce other goals <ref> [9] </ref>. 5 Conclusion Our algorithm works correctly even in difficult situations. It supports a lack of landmarks or a misinterpretation of a few of the landmarks. There is no need of a particular number of landmarks (more than 2). <p> It is easy to build a learning rule that is triggered when the sum of the place cells response decreases <ref> [9] </ref>. The robot would then find a movement that allows it to go in a direction associated to a global increase of the goal recognition (an efficient reinforcement learning rule is described in [7]).
Reference: [10] <author> P. Gaussier and S. Zrehen. Perac: </author> <title> A neural architecture to control artificial animals. </title> <booktitle> Robotics and Autonomous Systems, </booktitle> <address> 16(2-4):291-320, </address> <year> 1995. </year>
Reference-contexts: Moreover, the robot would be unable to perform topological generalization. In this paper, we show experimental results of a navigation model proposed in a previous paper <ref> [10] </ref>. It is a neural architecture named PerAc (Perception Action) based on animals and humans navigation models which do not require a precise map of the environment to navigate. This model has been implemented on a mobile robot named Prometheus. <p> Thus at each step, the distance to the target is reduced (Fig. 1) and the robot returns inevitably to the learned position. A complete description of a neural implementation of the learning process can be found in <ref> [10] </ref>. The PerAc architecture for place learning realizes an approximation of a potential field function without the cost of learning what to do from each position in the environment. <p> Moreover, it has been mathematically proved that there was no local minimum induced by the competition between the action neurons within the domain bounded by the set of landmarks <ref> [10] </ref>. a) b) a) Each black circle represent a landmark which present 6 dif-ferents aspects according to the observer point of view.
Reference: [11] <author> C. Joulain, P. Gaussier, A. Revel, and B. </author> <title> Gas. Learning to build visual categories from sensori-motor associations. </title> <note> In submitted to IROS'97, </note> <year> 1997. </year>
Reference-contexts: When the goal is in sight (goal recognition), a neuron corresponding to its angular position relative to the robot's facing position is activated in the Target Azimuth group (we suppose that the robot has previously learned what the goal looks like <ref> [11] </ref>). A shifting mechanism activates a neuron in the Direction of Movement Proposal (DMP) group by adding an angle corresponding to the angle between the robot and the north direction. The inverse shifting mechanism is applied to the output of the Direction of Movement group, by substracting the same angle.
Reference: [12] <author> T. Levitt, D. Lawton, D. Chelberg, K. Koitzsch, and J.W. Dye. </author> <title> Qualitative navigation 2. </title> <booktitle> In Proc. DARPA Image Understand Workshop, </booktitle> <pages> pages 319-326, </pages> <address> Los Altos, </address> <year> 1988. </year>
Reference-contexts: This approach reduces their algorithmic complexity and increases their robustness (qualitative navigation <ref> [12] </ref>, visual homing [13]). The PerAc architecture is a neural computation architecture proposed to solve a wide variety of control problems requiring learning capabilities (by opposition to adaptation 1 capabilities).
Reference: [13] <author> R.C. Nelson. </author> <title> Visual homing using an associative memory. </title> <journal> Biological cybernetics, </journal> <volume> 65 </volume> <pages> 281-291, </pages> <year> 1991. </year>
Reference-contexts: This approach reduces their algorithmic complexity and increases their robustness (qualitative navigation [12], visual homing <ref> [13] </ref>). The PerAc architecture is a neural computation architecture proposed to solve a wide variety of control problems requiring learning capabilities (by opposition to adaptation 1 capabilities).
Reference: [14] <author> S. Zrehen. </author> <title> Elements of Brain Design for Autonomous Agents. </title> <type> PhD thesis, </type> <institution> EPFL, </institution> <year> 1995. </year> <month> 6 </month>
Reference-contexts: a landmark is missing (for instance if the fridge is removed), because the "image" of the scene (Landmarks Azimuths) is noisy, the other landmarks can allow a good recognition (we have shown that several landmarks can be removed, hidden or displaced 2 without disturbing the global recognition of the scene <ref> [14] </ref>). This "plastic" merging by opposition to the static recognition of a multisensor configuration seems to be performed by a brain region called the hippocam-pus and involved in the memorization and navigation processes (processes that we study in the frame of a neurobiological project [2]). Direction of movement are WTA.
References-found: 14

