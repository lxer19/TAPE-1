URL: ftp://softlib.rice.edu/pub/CRPC-TRs/reports/CRPC-TR97722.ps.gz
Refering-URL: http://www.crpc.rice.edu/CRPC/softlib/TRs_online.html
Root-URL: 
Email: Scotland/UK  
Title: High-Performance Fortran for SPMD programming: An Applications Overview  
Author: Sanjay Ranka Kenneth A Hawick Geoffrey C Fox 
Date: June 3, 1997  
Address: Gainesville, FL 32611-6120 USA  Edinburgh EH9-3JZ  Adelaide South Australia 5005 Australia  Syracuse, NY 13244-4100 USA  
Affiliation: Computer and Information Science and Engineering Department University of Florida  Edinburgh Parallel Computing Centre University of Edinburgh  Department of Computer Science The University of  Northeast Parallel Architectures Center Syracuse University  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Adams, J., Brainerd, W., Martin, J., Smith, B., and Wagener, J., </author> <title> Fortran 90 Handbook: Complete ANSI/ISO Reference, </title> <publisher> McGraw-Hill, </publisher> <year> 1991. </year>
Reference-contexts: The HPF language specification is based in part on experience gained with the research languages such as Fortran D [21, 22, 10] and Vienna Fortran [5]. HPF is based on 4 Fortran 90 <ref> [1, 33] </ref>, an extension of Fortran 77 that allows new features to be integrated into existing code in a controlled, evolutionary manner.
Reference: [2] <author> Bailey, D., Barton, J., Lasinski, T. and Simon, H., </author> <title> Editors, "The NAS Parallel Benchmarks", NASA Ames, </title> <type> NASA Technical Memorandum 103863, </type> <month> July </month> <year> 1993. </year>
Reference-contexts: A simple approach is to generate a larger (say twice) the number of potential deviates as are requested by the caller. Since, the Box-Muller algorithm has an intrinsic efficiency of about 2:0=1:27, this would typically be large enough for a large set. The NAS EP (`Embarrassingly Parallel') benchmark <ref> [2] </ref> in appendix A.1 follows the Box-Muller approach, converting vectors of uniform-deviate random numbers into vectors with a Gaussian distribution. However, because the benchmark specifies how these numbers are generated, the system-dependent random number generator has to be replaced with a portable implementation.
Reference: [3] <author> Ballard, D., and Brown, C., </author> <title> Computer Vision, </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ 1982. </address>
Reference-contexts: The code in appendix A.2 illustrates how this might be achieved compactly in HPF. The input to this program is and edge image (a pixel is `1' if it is and edge pixel). This is typically derived by using simple template matching algorithms <ref> [3] </ref>. The first phase of the code packs all the edge pixels in a compact array. This removes a conditional check which will otherwise be required to determine whether this pixel can vote for the resultant Hough array. Edge pixels are non-uniformly distributed in the edge array.
Reference: [4] <author> Bozkus, Z., Choudhary, A., Fox, G., Haupt, T., and Ranka, S., </author> <title> "Fortran 90D/HPF compiler for distributed-memory MIMD computers: design, implementation, and performance results," </title> <booktitle> Proceedings of Supercomputing '93, </booktitle> <address> Portland, OR, </address> <year> 1993, </year> <month> p.351. </month>
Reference-contexts: This section is limited to parallelization of explicit parallelism available for which we have had extensive experience <ref> [4] </ref> and is the main focus of this paper. It is a very brief and simplistic overview of an HPF compiler. <p> The costs of collective 12 communication routines can be determined more precisely than generating point to point communication for each pair of communicating processors, thereby enabling the compiler to generate better distributions. A list of important communication primitives required are as follows <ref> [4] </ref>. * Transfer: Single source sends data to a single destination. * Broadcast: One processor (source node) sends data (scalar variable or multi-dimension array) to all processors or a subset of processors (destination nodes). * Reduction: It is the inverse of a broadcast.
Reference: [5] <author> Chapman, B., Mehrotra, P., Mortisch, H., and Zima, H., </author> <title> "Dynamic data distributions in Vienna Fortran," </title> <booktitle> Proceedings of Supercomputing '93, </booktitle> <address> Portland, OR, </address> <year> 1993, </year> <month> p.284. </month>
Reference-contexts: To address some of the above issues, a specification for a language called High-Performance Fortran (HPF) was adopted in 1993 [18]. The HPF language specification is based in part on experience gained with the research languages such as Fortran D [21, 22, 10] and Vienna Fortran <ref> [5] </ref>. HPF is based on 4 Fortran 90 [1, 33], an extension of Fortran 77 that allows new features to be integrated into existing code in a controlled, evolutionary manner.
Reference: [6] <author> T. H. Cormen, C. L. Leiserson and R. L. Rivest, </author> <title> "Introduction to Algorithms", </title> <publisher> MIT Press/McGray Hill, </publisher> <year> 1991. </year>
Reference-contexts: An algorithm for calculating the minimum spanning assumes that set S initially contains an arbitrary vertex r <ref> [6, 27] </ref>. The initial weight of the remaining vertices is given by the cost of the edge (if any) to the vertex r. <p> The single source shortest path algorithm for dense graphs is a variant of of the minimum spanning tree algorithm described above <ref> [6] </ref>. The parallelization requirements are also similar [27]. 6.12 Summary of Synchronous Applications Computational problems where the algorithm is synchronous, i.e., data parallelism with regular data and identical operations on all data points, are easily expressable in a parallel manner with High Performance Fortran.
Reference: [7] <author> Dincer, K., Fox, </author> <title> G.C., Hawick, K.A., "High Performance Fortran and Possible Extensions to support Conjugate Gradient Algorithms", </title> <booktitle> proceedings of the 5th IEEE Int.Sym. on High Performance Distributed Computing, </booktitle> <month> August 6-9 </month> <year> 1997, </year> <institution> Syracuse NY, pp69-77. </institution>
Reference-contexts: The former contain few or no zero entries. The latter class deals with matrices where a majority of elements are zero. This sparsity can be exploited to achieve better algorithms such as the conjugate gradient method; the suitability of the current HPF-1.1 standard for which have been examined <ref> [7] </ref>. The shortcomings for sparse matrix problems are largely to do with load distribution for solving matrices with arbitrarily sparse structures (see the discussion on regular and irregular problems in x1), and have better addressed with the approved extensions in HPF-2.0 (see x3.5).
Reference: [8] <author> Duff, </author> <title> I.S., Erisman, A.M., and Reid, J.K., "Direct Methods for Sparse Matrices", </title> <publisher> Clarendon Press, Oxford, </publisher> <year> 1985. </year> <month> 83 </month>
Reference-contexts: Furthermore, in the case of an irregular mesh, where each element may be topologically variant, the matrix will also have an arbitrary sparse structure (see <ref> [8] </ref> for a more detailed discussion on sparse matrix problems). Such irregular meshes also require a more complicated data structure (since determining neighbouring nodes is non-trivial) involving indirect addressing with gather/scatter operations (see x6.3), with the distinct possibility of load imbalances from the varying sized elements.
Reference: [9] <author> Finucane, T., </author> <title> "Binomial Approximation of American Call Option Prices with Stochastic Volatilities", </title> <journal> Journal of Finance, </journal> <year> 1992. </year>
Reference: [10] <author> Fox, G.C., Hiranadani, S., Kennedy, K., Koelbel, C., Kremmer, U., Tseng, C.W., and Wu, M., </author> <title> "Fortran D language specification," </title> <type> Technical Report, </type> <institution> Rice and Syracuse Universities, </institution> <year> 1992. </year>
Reference-contexts: To address some of the above issues, a specification for a language called High-Performance Fortran (HPF) was adopted in 1993 [18]. The HPF language specification is based in part on experience gained with the research languages such as Fortran D <ref> [21, 22, 10] </ref> and Vienna Fortran [5]. HPF is based on 4 Fortran 90 [1, 33], an extension of Fortran 77 that allows new features to be integrated into existing code in a controlled, evolutionary manner.
Reference: [11] <author> Fox, </author> <title> G.C., </title> <type> Technical Report SCCS-717, </type> <institution> Northeast Parallel Architectures Center, </institution> <note> http://www.npac.syr.edu/techreports/, June 1995. </note>
Reference-contexts: For example, there is now the extrinsic library `FORTRAN LOCAL' to support interactions between Fortran 77 and HPF subprograms. 16 4 Application Classification It is convenient to use the classification of problems into embarrassingly parallel, synchronous, loosely synchronous, asynchronous, and metaproblems <ref> [11, 13] </ref>. 1. The class of embarrassingly parallel problems require little communication or synchron ization and can be parallelized using straightforward approaches. 2.
Reference: [12] <author> Fox, G.C., Hawick, K.A., Haupt, T., Bogucz, E. and Roe, K., </author> <title> "Application of High Performance Fortran", </title> <type> NPAC Technical Report, </type> <note> SCCS-727, http://www.npac.syr.edu/techreports/, July 1995. </note>
Reference-contexts: Hence it is almost inevitable that the HPF language should be explored for its relevance in this arena. The following x6.6.1| x6.6.2 examines the use of HPF for two techniques in the CFD field. Other work has been done in evaluating HPF <ref> [12, 39] </ref>, particularly for where the computational mesh is regular with elements of equal topologies.
Reference: [13] <author> Fox, G.C., Williams, R.D., and Messina, </author> <title> P.C., Parallel Computing Works!, </title> <publisher> Morgan Kaufmann, </publisher> <address> San Francisco, </address> <year> 1994. </year>
Reference-contexts: For example, there is now the extrinsic library `FORTRAN LOCAL' to support interactions between Fortran 77 and HPF subprograms. 16 4 Application Classification It is convenient to use the classification of problems into embarrassingly parallel, synchronous, loosely synchronous, asynchronous, and metaproblems <ref> [11, 13] </ref>. 1. The class of embarrassingly parallel problems require little communication or synchron ization and can be parallelized using straightforward approaches. 2.
Reference: [14] <author> Hawick, K.A., Yau, H.W., and Fox, </author> <title> G.C., "Exploiting High Performance Fortran for Computational Fluid Dynamics," </title> <booktitle> Proceedings of High-Performance Computing and Networking, </booktitle> <month> May </month> <year> 1995, </year> <institution> Milan Italy. </institution>
Reference-contexts: A common approach to this problem is to use a split operator technique such as the Altern ating Direction Implicit (ADI) method <ref> [14] </ref>. This technique assumes that the five star stencil operator L for the finite difference scheme can be split into two line operators: 31 L x = i+1;j + 2 i;j i1;j (9) which are invoked alternatively at each half-time step.
Reference: [15] <author> Hawick, K.A., Bell, R.S., Dickinson, A., Surry, P.D., Wylie, B.J.N., </author> <title> "Parallelisation of the Unified Model Data Assimilation Scheme", Invited paper, </title> <booktitle> Proceedings of the Fifth ECMWF Workshop on the Use of Parallel Processors in Meteorology. </booktitle>
Reference-contexts: The full code for this algorithm can be found in appendix A.7. 6.6 Computational Fluid Dynamics The solution of Computational Fluid Dynamics (CFD) simulations has traditionally been a major user of high performance computing technologies, from weather predictions <ref> [15] </ref>, flow behaviour around aircrafts [38], to blood flow in a human heart [35]. Hence it is almost inevitable that the HPF language should be explored for its relevance in this arena. The following x6.6.1| x6.6.2 examines the use of HPF for two techniques in the CFD field.
Reference: [16] <author> Hawick, K.A., and Wallace, </author> <title> D.J., "High Performance Computing for Numerical Applications", Keynote address, </title> <booktitle> Proceedings of Workshop on Computational Mechanics in UK, Association for Computational Mechanics in Engineering, </booktitle> <address> Swansea, </address> <month> January </month> <year> 1993. </year>
Reference-contexts: It is important to observe that real industrial applications codes involve more than one basic algorithm to be applied to the problem data. Depending on the data access patterns, the layout of data required for one phase may be different than the other <ref> [16] </ref>. For this reason the data remapping features of HPF are particularly important |although these are not in the subset HPF standard [18] nor in the core HPF-2.0 specifications (see x3.5).
Reference: [17] <author> Hebb, </author> <title> D.O., "The Organisation of Behavior" New York: </title> <publisher> Wiley, </publisher> <year> 1949. </year>
Reference: [18] <author> High Performance Fortran Forum (HPFF), </author> <title> "High Performance Fortran Language Specification," </title> <booktitle> Scientific Programming, vol.2 no.1, </booktitle> <month> July </month> <year> 1993. </year> <note> Also available on the World Wide Web via: http://www.crpc.rice.edu/HPFF/home.html. </note>
Reference-contexts: As a result, efficient use of distributed memory systems requires either the use of message-passing programming or the development of new languages. To address some of the above issues, a specification for a language called High-Performance Fortran (HPF) was adopted in 1993 <ref> [18] </ref>. The HPF language specification is based in part on experience gained with the research languages such as Fortran D [21, 22, 10] and Vienna Fortran [5]. <p> A new round of discussions concerning a second HPF specification (`HPF-2.0') have just been completed <ref> [18] </ref>, and one of the key areas of discussion concerns better support for irregular mesh codes (see [19] for the motivating applications, and x3.5 for a discussion of these new features). It is our belief that HPF will complement |not replace| programming using message-passing libraries. <p> This section includes a brief overview of Fortran 90 and the major extensions to Fortran 90 contained in the HPF specification. Complete details concerning HPF may be found in references <ref> [18, 25] </ref>. 3.1 Fortran 90 Features Although Fortran 90 includes major extensions to Fortran 77 in a broad range of areas, the principal features of interest in the present paper involve array processing. In this area, notable extensions include: * Processing of arrays as individual data objects. <p> Objects (typically arrays) are first aligned relative to one another, and then groups of aligned objects are distributed onto a programmer-defined rectilinear arrangement of abstract processors (using the 1 HPF also restricts sequence and storage association available in Fortran 90 due to incompatibility with the data distribution directives (see <ref> [18] </ref> for further details). 8 `PROCESSORS' directive). The final mapping of abstract to physical processors is not specified by HPF and is implementation dependent. The `ALIGN' directive can be used to enforce the co-locality of different arrays. <p> Depending on the data access patterns, the layout of data required for one phase may be different than the other [16]. For this reason the data remapping features of HPF are particularly important |although these are not in the subset HPF standard <ref> [18] </ref> nor in the core HPF-2.0 specifications (see x3.5). In HPF this is done directly with the `REDISTRIBUTE' and the `REALIGN' mapping directives; upon the arrays being re-mapped first begin given the HPF `DYNAMIC' attribute.
Reference: [19] <author> High Performance Fortran Forum (HPFF), </author> <title> "HPF-2 Scope of Activities and Motivating Applications," available on the World Wide Web via: </title> <booktitle> ftp://hpsl.cs.umd.edu/pub/hpf bench/hpf2/hpf2.htm, 13th of November 1994. </booktitle>
Reference-contexts: A new round of discussions concerning a second HPF specification (`HPF-2.0') have just been completed [18], and one of the key areas of discussion concerns better support for irregular mesh codes (see <ref> [19] </ref> for the motivating applications, and x3.5 for a discussion of these new features). It is our belief that HPF will complement |not replace| programming using message-passing libraries. For many applications, HPF is expected to provide convenient, compact and relatively-simple programs without recourse to explicit message-passing instructions. <p> The need for more general task-parallelism constructs and irregular mapping of data has been addressed in the HPF 2.0 standard [20], following feedback from the initial HPF-1.0 process <ref> [19] </ref>.
Reference: [20] <author> High Performance Fortran Forum (HPFF), </author> <title> "High Performance Fortran v2.0fi Language Specification," available on the World Wide Web via: </title> <note> http://www.crpc.rice.edu/HPFF/hpf2/index.html, 17th of August 1996. 84 </note>
Reference-contexts: This subsection discusses the improvements made, based upon the document (version 2.0.fi) released in mid-November, 1996 <ref> [20] </ref> The round of meetings for HPF-2.0 was motivated by three needs: to make corrections and clarifications to the original definition, to provide any new features requested by the HPF community, and to recognise that compiler vendors have to provide efficient implementations of 14 the full language specification. <p> The need for more general task-parallelism constructs and irregular mapping of data has been addressed in the HPF 2.0 standard <ref> [20] </ref>, following feedback from the initial HPF-1.0 process [19]. <p> High energy physics applications require such analyses over a very large number of events. These applications can make use of the HPF features: 1. `INDEPENDENT' 18 2. Reducing intrinsics such as `SUM', and `SCATTER/GATHER' for histogramming. In addition, the HPF-2.0 <ref> [20] </ref> specifications have added the `REDUCTION' clause has been added to the `INDEPENDENT' directive to allow more generic reduction operations to be written (see x3.5). <p> Unfortunately this is only defined for rank-2 matrices, but a generalization for other larger ranks have been proposed for the HPF 2.0 standard <ref> [20] </ref>. 6.1 Full Matrix Algorithms Algorithms involving matrices and vectors are applied in several scientific and non-scientific applications. Matrices can generally be classified into dense or sparse matrices. The former contain few or no zero entries. The latter class deals with matrices where a majority of elements are zero.
Reference: [21] <author> Hiranandani, S., Kennedy, K., and Tseng, C.W., </author> <title> "Compiler support for machine-independent parallel programming in FortranD," in Compiler and Runtime Software for Scalable Multiprocessors, </title> <year> 1991. </year>
Reference-contexts: To address some of the above issues, a specification for a language called High-Performance Fortran (HPF) was adopted in 1993 [18]. The HPF language specification is based in part on experience gained with the research languages such as Fortran D <ref> [21, 22, 10] </ref> and Vienna Fortran [5]. HPF is based on 4 Fortran 90 [1, 33], an extension of Fortran 77 that allows new features to be integrated into existing code in a controlled, evolutionary manner.
Reference: [22] <author> Hiranandani, S., Kennedy, K., and Tseng, C.W., </author> <title> "Preliminary experiences with the FortranD compiler," </title> <booktitle> Proceedings of Supercomputing '93, </booktitle> <address> Portland, OR, </address> <year> 1993, </year> <note> p. 338. </note>
Reference-contexts: To address some of the above issues, a specification for a language called High-Performance Fortran (HPF) was adopted in 1993 [18]. The HPF language specification is based in part on experience gained with the research languages such as Fortran D <ref> [21, 22, 10] </ref> and Vienna Fortran [5]. HPF is based on 4 Fortran 90 [1, 33], an extension of Fortran 77 that allows new features to be integrated into existing code in a controlled, evolutionary manner.
Reference: [23] <author> Hopfield, J.J., </author> <title> "Neural Networks and Physical Systems with Emergent Collective Computational Abilities," </title> <booktitle> in Proceedings of the National Academy of Sciences, </booktitle> <address> USA, 79, pp2554-2558, </address> <year> 1982. </year>
Reference: [24] <author> Klasky, S., Haupt, T., Fox, </author> <title> G.C., "Role of Message Passing HPF and DAGH in Black Hole Grand Challenge", </title> <note> presented to SIAM Workshop Minneapolis `Is Message Passing Obsolete', http://www.npac.syr.edu/users/gcf/bbhdaghhpfmar97/ 16th of March 1997. </note>
Reference-contexts: The need for more general task-parallelism constructs and irregular mapping of data has been addressed in the HPF 2.0 standard [20], following feedback from the initial HPF-1.0 process [19]. These shortcomings in HPF-1.1 have impacted work in General Relativity simulations <ref> [24] </ref>, where the problem mesh is irregular, and where the simulation's adaptive mesh refinement algorithm causes load imbalances. 5 Embarrassingly Parallel Applications This class of applications require execution of several independent instances of the problems and can be parallelized relatively easily.
Reference: [25] <author> Koelbel, C.H., Loveman, D.B., Schreiber, R.S., Steele, G.L., Zosel, </author> <title> M.E., "The High Performance Fortran Handbook", </title> <publisher> MIT Press 1994. </publisher>
Reference-contexts: This section includes a brief overview of Fortran 90 and the major extensions to Fortran 90 contained in the HPF specification. Complete details concerning HPF may be found in references <ref> [18, 25] </ref>. 3.1 Fortran 90 Features Although Fortran 90 includes major extensions to Fortran 77 in a broad range of areas, the principal features of interest in the present paper involve array processing. In this area, notable extensions include: * Processing of arrays as individual data objects.
Reference: [26] <author> Kohonen, T., </author> <title> "Self-Organization and Associative Memory (3rd Edition)," </title> <publisher> Berlin: Springer-Verlag 1989. </publisher>
Reference: [27] <author> Kumar, V., Grama, A., Gupta, A., and Karypis, G., </author> <title> "Introduction to Parallel Computing: Design and Analysis of Algorithms", </title> <publisher> The Benjamin/Cummings Publishing Company, Inc, </publisher> <year> 1994. </year>
Reference-contexts: It requires changing the view from `BLOCK' to `CYCLIC' distribution 36 locally and can only be achieved by an explicit reordering by data copying in the current HPF standard. Another way to implement the 1-D FFT is a direct parallelization of radix 2 FFT algorithm <ref> [27] </ref>. A representative code is given in appendix A.12. Most of the communication is generated in the last phase of the program. It can be shown that the scalability of this algorithm is than the transpose based FFT due to asymptotically larger amount of communication required [27]. <p> radix 2 FFT algorithm <ref> [27] </ref>. A representative code is given in appendix A.12. Most of the communication is generated in the last phase of the program. It can be shown that the scalability of this algorithm is than the transpose based FFT due to asymptotically larger amount of communication required [27]. The FFT algorithm can be used to compute 2-D convolution (appendix A.13). Let two equal-sized images `A' and `B' are represented in a (complex) matrix of square dimension `NN'. The convolution of these images are stored in the matrix `C', and is calculated by the steps: 1. <p> An algorithm for calculating the minimum spanning assumes that set S initially contains an arbitrary vertex r <ref> [6, 27] </ref>. The initial weight of the remaining vertices is given by the cost of the edge (if any) to the vertex r. <p> The single source shortest path algorithm for dense graphs is a variant of of the minimum spanning tree algorithm described above [6]. The parallelization requirements are also similar <ref> [27] </ref>. 6.12 Summary of Synchronous Applications Computational problems where the algorithm is synchronous, i.e., data parallelism with regular data and identical operations on all data points, are easily expressable in a parallel manner with High Performance Fortran.
Reference: [28] <author> Liao, W. K., and Ranka, S., </author> " <title> Scalable Parallelization of the Hough Transform", </title> <note> in preparation. </note>
Reference-contexts: This array is used to determine the resultant Hough array by using a `COUNT SCATTER ()' intrinsic. 19 Also, for realistic images suitable runtime support and redistribution of edge pixels can be used to reduce the communication overhead generated by the `COUNT SCATTER ()' <ref> [28] </ref>. The `COUNT SCATTER ()' may generate hot spots if most of the votes are for a few bins in the Hough array. 5.3 Unindexed Search Several application require searching of a specific pattern in a database.
Reference: [29] <author> McCracken, N., </author> <title> "NPAC Educational Materials for High Performance Fortran (HPF)", </title> <note> http://www.npac.syr.edu/projects/cpsedu/hpfe/, January 1996. </note>
Reference-contexts: When the pairwise interactions are commutative, for example as would be found in classical molecular dynamics and Newtonian gravitational interactions, the total amount of computation can be reduced in half by calculating the interaction only once and using Newton's third law of motion to automatically determine the other half <ref> [29] </ref>. This requires a simple modification of the N-Body code, with the main complication being an explicit check on whether an even or an odd number of particles are being considered. The code in appendix A.9 is such an example of a commutative N-Body direct simulation.
Reference: [30] <author> McMahon, M., </author> <title> "Benchmarking NPAC High Performance Fortran Application Kernels", </title> <address> http://web.syr.edu/ mtmcmaho/, </address> <month> April </month> <year> 1997. </year>
Reference-contexts: Although HPF and, to a slightly lesser extent Fortran 90, are comparatively new languages, it is encouraging to see that many vendors either support, or is highly interested in supporting HPF, as is seen in documented reports <ref> [36, 30, 43] </ref> comparing some of these products. This reinforces the wish to have a language portable across a variety of platforms and compilers. In particular [43] has observed scalability up to 8 processors on simple application codes, with modest overheads when running from Fortran 90 to HPF.
Reference: [31] <author> Makivic, M. S., </author> <title> "Path Integral Monte Carlo Method for Valuation of Derivative Securities: Algorithms and Parallel Implementation", </title> <type> NPAC Technical Report SCCS 650, </type> <month> February </month> <year> 1995. </year>
Reference-contexts: Using a block distribution would ensure that no communication is generated. The program fragment which uses the above strategy is given in appendix A.3. Another approach relies on the direct stochastic integration of the Langevin equation for the security price process <ref> [31] </ref>. It generates the probability distribution of security prices using a Metropolis algorithm. Similar Monte Carlo methods have been successfully used in many financial modeling applications and are notoriously computationally intensive. The basic computational structure requires calculating the probability of transition from one path to another.
Reference: [32] <author> Mehrotra, K. G., Mohan., C. K., and Ranka, S., </author> <title> Elements of Artificial Neural Networks, </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <month> September </month> <year> 1996. </year>
Reference-contexts: The winner is moved either towards or away from the pattern depending on whether C (i) = C (jfl). 38 The algorithm is presented in figure 5 <ref> [32] </ref>. The learning rate (t) is a decreasing function of time t, such as (t) = 0 t A or (t) = 0 [1 At] where 0 and A are positive constants.
Reference: [33] <author> Metcalf, M., Reid, J., </author> <title> "Fortran 90 Explained", </title> <publisher> Oxford, </publisher> <year> 1990. </year> <month> 85 </month>
Reference-contexts: The HPF language specification is based in part on experience gained with the research languages such as Fortran D [21, 22, 10] and Vienna Fortran [5]. HPF is based on 4 Fortran 90 <ref> [1, 33] </ref>, an extension of Fortran 77 that allows new features to be integrated into existing code in a controlled, evolutionary manner.
Reference: [34] <author> MPI Forum. </author> <title> "The Message-Passing Interface Standard," </title> <institution> Mississippi State University http://www.erc.msstate.edu/mpi/resources.html, 1995. </institution>
Reference-contexts: Furthermore, portability of the code can be a problem when libraries unique to a particular hardware vendor are used. The acceptance of the machine-independent message passing interface `MPI' <ref> [34] </ref> has largely relieved the problem of portability for most message passing codes, but message-passing software development tools are still strangely lacking. An alternative to hand-coded message-passing is to develop compilers capable of generating automatically the message-passing instructions required. <p> These routines pack data into a contiguous block before passing it to communication network, and unpack data and place it to the right location upon its arrival of destination processor. The Message Passing Interface (MPI) standard <ref> [34] </ref> addresses many of the above issues. Parallelization of the independent statements may require careful mapping of the iterations to minimize computations as well as load balance.
Reference: [35] <author> Peskin, C. and McQueen, D., </author> <title> "Heart Throb: Modelling Cardiac Fluid Dynamics", </title> <institution> Pittsburgh Supercomputing Center, </institution> <note> http://pscinfo.psc.edu/publications/publications.html, 1994. </note>
Reference-contexts: full code for this algorithm can be found in appendix A.7. 6.6 Computational Fluid Dynamics The solution of Computational Fluid Dynamics (CFD) simulations has traditionally been a major user of high performance computing technologies, from weather predictions [15], flow behaviour around aircrafts [38], to blood flow in a human heart <ref> [35] </ref>. Hence it is almost inevitable that the HPF language should be explored for its relevance in this arena. The following x6.6.1| x6.6.2 examines the use of HPF for two techniques in the CFD field.
Reference: [36] <author> Presberg, </author> <title> D.L., "Comparisons of 3 HPF Compilers", </title> <note> NHSE Review http://nhse.cs.rice.edu/NHSEreview/HPF/, September 1996. </note>
Reference-contexts: Although HPF and, to a slightly lesser extent Fortran 90, are comparatively new languages, it is encouraging to see that many vendors either support, or is highly interested in supporting HPF, as is seen in documented reports <ref> [36, 30, 43] </ref> comparing some of these products. This reinforces the wish to have a language portable across a variety of platforms and compilers. In particular [43] has observed scalability up to 8 processors on simple application codes, with modest overheads when running from Fortran 90 to HPF.
Reference: [37] <author> R. Ponnusamy, J. Saltz, A. Choudhary, Yuan-Shin Hwang, and G. Fox, </author> <title> "Supporting Irregular Data Distributions in FORTRAN 90D/HPF Compilers," </title> <booktitle> IEEE Parallel and Distributed Technology, </booktitle> <month> Spring </month> <year> 1995. </year>
Reference-contexts: The cost of the communication will be low if the nodes are reordered such that most of these accesses are local. This reordering can be potentially achieved in HPF 1.1 by use of extrinsic functions to perform graph partitioning using the edge array <ref> [37] </ref>.
Reference: [38] <author> Raj, P., and Siclari, M., </author> <title> "Toward certifying CFD codes using wing C and M100 wing-body configurations," </title> <booktitle> Paper AIAA-94-2241 presented at 25th AIAA Fluid Dynamics Conference, </booktitle> <address> Colorado Springs, CO, </address> <month> 20-23 June </month> <year> 1994. </year>
Reference-contexts: The full code for this algorithm can be found in appendix A.7. 6.6 Computational Fluid Dynamics The solution of Computational Fluid Dynamics (CFD) simulations has traditionally been a major user of high performance computing technologies, from weather predictions [15], flow behaviour around aircrafts <ref> [38] </ref>, to blood flow in a human heart [35]. Hence it is almost inevitable that the HPF language should be explored for its relevance in this arena. The following x6.6.1| x6.6.2 examines the use of HPF for two techniques in the CFD field.
Reference: [39] <author> Roe, K.P., Mehrotra, P., </author> <title> "Implementation of a Total Variation Diminishing Scheme for the Shock Tube Problem in High Performance Fortran", </title> <booktitle> presented at the Eighth SIAM Conference on Parallel Processing for Scientific Computing, </booktitle> <month> March 14 </month> <year> 1997. </year>
Reference-contexts: Hence it is almost inevitable that the HPF language should be explored for its relevance in this arena. The following x6.6.1| x6.6.2 examines the use of HPF for two techniques in the CFD field. Other work has been done in evaluating HPF <ref> [12, 39] </ref>, particularly for where the computational mesh is regular with elements of equal topologies.
Reference: [40] <author> Sorevik, T., </author> <title> "Ocean Modelling code benefits from High Performance Fortran", HPCwire article number 10539, </title> <booktitle> hpcwirenewsmaster.tgc.com, December 13th 1996. </booktitle>
Reference-contexts: In these cases, it is difficult to envisage a hand-tuned message passing code providing appreciably better performances. For real-world applications in the commercial world, success has also been reported for a large ocean modelling code <ref> [40] </ref>, where HPF was used in the parallelisation of a multiple tridiagonal matrix solver. This paper provides a brief overview of High Performance Fortran, general principles of its compilation and runtime support for scalable code generation for coarse grained machines. <p> Other work has been done in evaluating HPF [12, 39], particularly for where the computational mesh is regular with elements of equal topologies. Moreover, HPF has also recently been used for the large, real-world CFD problem of modelling ocean currents <ref> [40] </ref>, and it is not too unrealistic for the language to replace hand-written message passing codes for parallel CFD applications on regular mesh topologies. 6.6.1 Poisson Equation using ADI The time dependent Navier-Stokes equation can be written in terms of the vorticity () and stream ( ) functions by the coupled
Reference: [41] <author> Trew, A. and Wilson, G. (eds.), </author> <title> "Past Present, Parallel: A Survey of Available Parallel Computing Systems", </title> <publisher> Springer-Verlag 1991. </publisher>
Reference-contexts: 1 Introduction From the early 1980's to the mid 1990's, parallel computer architectures went through a proliferation in designs, as manufacturers competed to meet the promise of high performance and/or low hardware costs <ref> [41] </ref>. The machine from that era typically boasted esoteric hardware features with which to distinguish themselves from the existing vector-parallel supercomputers and other traditional mainframes.
Reference: [42] <author> Yau, H.W., and Wallace, </author> <title> D.J., "Enlarging the Attractor Basins of Neural Networks with Noisy External Fields", </title> <journal> Journal of Physics:A Maths and General, </journal> <volume> 24 </volume> <pages> 5639-5650, </pages> <year> 1991. </year>
Reference: [43] <author> Yau, H.W., Fox, G.C., and Hawick, K.A., </author> <title> "Evaluation of High Performance Fortran through Application Kernels", </title> <booktitle> Proceeedings of High Performance Computing and Networking 1997, </booktitle> <address> Vienna, Austria, 28-30th of April, </address> <year> 1997. </year> <month> 86 </month>
Reference-contexts: Although HPF and, to a slightly lesser extent Fortran 90, are comparatively new languages, it is encouraging to see that many vendors either support, or is highly interested in supporting HPF, as is seen in documented reports <ref> [36, 30, 43] </ref> comparing some of these products. This reinforces the wish to have a language portable across a variety of platforms and compilers. In particular [43] has observed scalability up to 8 processors on simple application codes, with modest overheads when running from Fortran 90 to HPF. <p> This reinforces the wish to have a language portable across a variety of platforms and compilers. In particular <ref> [43] </ref> has observed scalability up to 8 processors on simple application codes, with modest overheads when running from Fortran 90 to HPF. In these cases, it is difficult to envisage a hand-tuned message passing code providing appreciably better performances. <p> The efficient implementation of these features can probably be regarded as a minimum requirement for those wishing to express their synchronous application in HPF. Our experience <ref> [43] </ref> is that these requirements are being seriously addressed with today's available compilers. 42 Application HPF Features Gaussian Elimination (A.4) `CYCLIC' distribution, `FORALL', `MAXLOC ()' 2-D Potts model (A.6) `CSHIFT ()', `MERGE ()', `WHERE' 2-D Cahn-Hilliard (A.7) `CSHIFT ()' Poisson solution by ADI (A.8) Descriptive interface, `TRANSPOSE ()' Direct N-body (A.9)
References-found: 43

