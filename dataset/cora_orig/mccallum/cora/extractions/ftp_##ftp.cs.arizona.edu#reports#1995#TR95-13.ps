URL: ftp://ftp.cs.arizona.edu/reports/1995/TR95-13.ps
Refering-URL: http://www.cs.arizona.edu/research/reports.html
Root-URL: http://www.cs.arizona.edu
Title: Adaptive Data Placement for Distributed-Memory Machines  
Author: David K. Lowenthal Gregory R. Andrews 
Abstract-found: 0
Intro-found: 1
Reference: [AL93] <author> J. Anderson and M. Lam. </author> <title> Global optimizations for parallelism and locality on scalable parallel machines. </title> <booktitle> In Proceedings of the SIGPLAN '93 Conference on Program Language Design and Implementation, </booktitle> <pages> pages 112-125, </pages> <year> 1993. </year>
Reference-contexts: Most current approaches determine data placements statically. They can generally be divided into two categories: using language primitives, such as the ones in HPF [HPF93], or compiler analysis, such as the work reported in <ref> [AL93] </ref>, [GB93], and [KK94]. Language primitives involve the programmer in the choice of data placement; unfortunately, the best placement may be difficult or impossible for the programmer to determine. <p> Whether a remapping or a combination placement is best requires the programmer not only to have extensive understanding of the application, but also of the underlying hardware [KK94]. With the compiler-based method, determining whether to remap requires extensive analysis. (Some work has been done in this area, such as <ref> [AL93] </ref> and [KK94].) Furthermore, larger programs are more likely to contain procedures and aliases, hindering a compiler's effort. Adapt works on some of these types of "multi-kernel" applications.
Reference: [BFKK91] <author> V. Balasundaram, G. Fox, K. Kennedy, and U. Kremer. </author> <title> An static performance estimator to guide data partitioning decisions. </title> <booktitle> In Proceedings of the Third ACM SIGPLAN Symposium on Principles and Practices of Parallel Programming, </booktitle> <pages> pages 213-223, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: With a compiler-based approach, the compiler infers a placement for each array in the source code by inspecting loops and array accesses (e.g. <ref> [GB93, LC90, BFKK91, HA90, LC91, KLS90, Soc91] </ref>). Hence, the programmer need not be involved in placing data. On the other hand, a compiler may not be able to infer the best placement, and compiler approach increases its complexity greatly.
Reference: [CMZ92] <author> B. Chapman, P. Mehrotra, and H. Zima. </author> <title> Programming in Vienna Fortran. </title> <journal> Scientific Programming, </journal> <volume> 1(1) </volume> <pages> 31-50, </pages> <year> 1992. </year> <month> 13 </month>
Reference-contexts: With language primitives, the programmer annotates each array with a placement (e.g. <ref> [HPF93, HKK + 91, RSW91, ZBG88, CMZ92, TCF94] </ref>). The advantage of using language primitives is that the programmer has full control over the program.
Reference: [FLA94] <author> Vincent W. Freeh, David K. Lowenthal, and Gregory R. Andrews. </author> <title> Distributed Fila--ments: Efficient fine-grain parallelism on a cluster of workstations. </title> <booktitle> In First Symposium on Operating Systems Design and Implementation, </booktitle> <pages> pages 201-212, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: Below we discuss how Adapt monitors the computation (Section 3.1), determines a placement (Section 3.2), and effects and continues to monitor this placement (Section 3.3). The current implementation of Adapt is implemented in concert with the Distributed Filaments (DF) software kernel <ref> [FLA94] </ref>. It supports multi-dimensional arrays and distributes only the first dimension (rows). It relies on instrumenting a distributed shared memory (DSM) (for monitoring) and requires that code segments in loops have the same communication pattern. <p> In addition, some of the delay can be eliminated by overlapping communication and computation, as is done for example in <ref> [vCGS92, FLA94] </ref>. 6 with node 0 the owner. 3.1.2 Computation Monitoring Adapt instruments the code to obtain the time a node spends computing the data elements it owns. <p> When a node accesses data it does not own, page faults result; the underlying DSM then implicitly moves the data. The Filaments package provides a simple and efficient mechanism for generating a new code parameterization (see <ref> [FLA94] </ref> for details); however, any generation method will do. After a placement has been changed, Adapt continues to monitor the application to detect when a different placement might be better. (This can happen when characteristics change in the middle of a loop, as described in Section 4). <p> Particle simulation, on the other hand, requires run-time support both to determine a good placement and possibly to change the placement during the computation. For each application we developed a program using Adapt. For an accurate comparison, we also developed a Distributed Filaments (DF) <ref> [FLA94] </ref> program without the Adapt subsystem. The DF program uses a statically determined data placement. For each application we present the results of the DF program with the best statically determined data placement and compare it to the Adapt program.
Reference: [GB93] <author> M. Gupta and P. Banerjee. </author> <title> PARADIGM: A compiler for automated data distribution on multicomputers. </title> <booktitle> In Proceedings of the 1993 ACM International Conference on Supercomputing, </booktitle> <pages> pages 357-367, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: Most current approaches determine data placements statically. They can generally be divided into two categories: using language primitives, such as the ones in HPF [HPF93], or compiler analysis, such as the work reported in [AL93], <ref> [GB93] </ref>, and [KK94]. Language primitives involve the programmer in the choice of data placement; unfortunately, the best placement may be difficult or impossible for the programmer to determine. <p> With a compiler-based approach, the compiler infers a placement for each array in the source code by inspecting loops and array accesses (e.g. <ref> [GB93, LC90, BFKK91, HA90, LC91, KLS90, Soc91] </ref>). Hence, the programmer need not be involved in placing data. On the other hand, a compiler may not be able to infer the best placement, and compiler approach increases its complexity greatly.
Reference: [HA90] <author> David E. Hudak and Santosh G. Abraham. </author> <title> Compiler techniques for data partitioning of sequentially iterated parallel loops. </title> <booktitle> In Proceedings 1990 International Conference on Supercomputing, ACM SIGARCH Computer Architecture News, </booktitle> <pages> pages 187-200, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: With a compiler-based approach, the compiler infers a placement for each array in the source code by inspecting loops and array accesses (e.g. <ref> [GB93, LC90, BFKK91, HA90, LC91, KLS90, Soc91] </ref>). Hence, the programmer need not be involved in placing data. On the other hand, a compiler may not be able to infer the best placement, and compiler approach increases its complexity greatly.
Reference: [Har64] <author> Francis H. Harlow. </author> <title> The particle-in-cell computing method for fluid dynamics. </title> <editor> In Bernie Alder, editor, </editor> <booktitle> Methods in Computational Physics, </booktitle> <pages> pages 319-343. </pages> <publisher> Academic Press, Inc., </publisher> <year> 1964. </year>
Reference-contexts: Some applications that have locality and a regular "nearest neighbor" communication pattern do not have a balanced workload, such as particle-in-cell codes <ref> [Har64] </ref>. It is still usually best to use a contiguous mapping for such applications, but the mapping may need to assign each node a different number of elements in order to balance the workload. In particular, the number of elements per node should match the distribution of particles. <p> However, the programmer might not know the best placement; even if the programmer does, the best placement might change 7 The clustering of particles is not contrived; this kind of clustering can occur in practice <ref> [Har64] </ref>. 8 The execution times using very small blocks can cause so many messages that the network bandwidth is exceeded, slowing the program down even more than expected. 11 when executing the program on a new architecture.
Reference: [HKK + 91] <author> Seema Hiranandani, Ken Kennedy, Charles Koelbel, Ulrich Kremer, and Chau-Wen Tseng. </author> <title> An overview of the Fortran-D programming system. </title> <type> Report TR91121, CRPC, </type> <month> March </month> <year> 1991. </year>
Reference-contexts: With language primitives, the programmer annotates each array with a placement (e.g. <ref> [HPF93, HKK + 91, RSW91, ZBG88, CMZ92, TCF94] </ref>). The advantage of using language primitives is that the programmer has full control over the program.
Reference: [HKT92] <author> S. Hiranandani, K. Kennedy, and C.W. Tseng. </author> <title> Compiling Fortran D for MIMD distributed-memory machines. </title> <journal> Communications of the ACM, </journal> <volume> 35(8) </volume> <pages> 66-80, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: This section first describes our models of computation and communication and how a data placement affects computation time, communication overhead, and delays. Then we discuss the range of data placements and their relation to representative applications. Our computational model is Single Program Multiple Data (SPMD) <ref> [HKT92] </ref>, in which each process executes the same code but references a different subset of the data elements We also require iterative computations, because placing data dynamically depends on having computations that exhibit repeated access patterns, giving a run-time data placement method the opportunity to detect these patterns and use them <p> Data placement remappings are made only at the last barrier point in a loop, because that is the one point at which information exists about every code segment in the loop. We assume that any node can reference any data element. We also assume the owner-computes <ref> [HKT92] </ref> rule, which means each data element has an "owner" node and that is the only node that will update the element; however, other nodes may reference the element. The data placement affects both computation time and communication overhead.
Reference: [HPF93] <institution> High Performance Fortran language specification. </institution> <month> October </month> <year> 1993. </year>
Reference-contexts: The goal of this work is to determine data placements dynamically rather than requiring programmers or compilers to make such decisions. Most current approaches determine data placements statically. They can generally be divided into two categories: using language primitives, such as the ones in HPF <ref> [HPF93] </ref>, or compiler analysis, such as the work reported in [AL93], [GB93], and [KK94]. Language primitives involve the programmer in the choice of data placement; unfortunately, the best placement may be difficult or impossible for the programmer to determine. <p> With language primitives, the programmer annotates each array with a placement (e.g. <ref> [HPF93, HKK + 91, RSW91, ZBG88, CMZ92, TCF94] </ref>). The advantage of using language primitives is that the programmer has full control over the program.
Reference: [KK94] <author> Ken Kennedy and Ulrich Kremer. </author> <title> Automatic data layout for High Performance Fortran. </title> <type> Technical Report CRPC-TR94498-S, </type> <institution> Rice University, </institution> <month> December </month> <year> 1994. </year>
Reference-contexts: Most current approaches determine data placements statically. They can generally be divided into two categories: using language primitives, such as the ones in HPF [HPF93], or compiler analysis, such as the work reported in [AL93], [GB93], and <ref> [KK94] </ref>. Language primitives involve the programmer in the choice of data placement; unfortunately, the best placement may be difficult or impossible for the programmer to determine. <p> Whether a remapping or a combination placement is best requires the programmer not only to have extensive understanding of the application, but also of the underlying hardware <ref> [KK94] </ref>. With the compiler-based method, determining whether to remap requires extensive analysis. (Some work has been done in this area, such as [AL93] and [KK94].) Furthermore, larger programs are more likely to contain procedures and aliases, hindering a compiler's effort. Adapt works on some of these types of "multi-kernel" applications. <p> a remapping or a combination placement is best requires the programmer not only to have extensive understanding of the application, but also of the underlying hardware <ref> [KK94] </ref>. With the compiler-based method, determining whether to remap requires extensive analysis. (Some work has been done in this area, such as [AL93] and [KK94].) Furthermore, larger programs are more likely to contain procedures and aliases, hindering a compiler's effort. Adapt works on some of these types of "multi-kernel" applications. <p> Adapt works on some of these types of "multi-kernel" applications. Currently it can remap data between loops, but not within loops containing code segments with different communication patterns. (These can be handled by the approach used in <ref> [KK94] </ref>.) If extended, Adapt could find data placements for some of these applications, but certain types of remappings, such as transpose, would pose a problem.
Reference: [KLS90] <author> K. Knobe, J. Lukas, and G. Steele Jr. </author> <title> Data optimization: Allocation of arrays to reduce communication on SIMD machines. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 8(2) </volume> <pages> 102-118, </pages> <month> February </month> <year> 1990. </year>
Reference-contexts: With a compiler-based approach, the compiler infers a placement for each array in the source code by inspecting loops and array accesses (e.g. <ref> [GB93, LC90, BFKK91, HA90, LC91, KLS90, Soc91] </ref>). Hence, the programmer need not be involved in placing data. On the other hand, a compiler may not be able to infer the best placement, and compiler approach increases its complexity greatly.
Reference: [LC90] <author> J. Li and M. Chen. </author> <title> Index domain alignment: Minimizing cost of cross-referencing between distributed arrays. </title> <booktitle> In Frontiers90: The 3rd Symposium on the Frontiers of Massively Parallel Computation, </booktitle> <pages> pages 424-432, </pages> <month> October </month> <year> 1990. </year>
Reference-contexts: With a compiler-based approach, the compiler infers a placement for each array in the source code by inspecting loops and array accesses (e.g. <ref> [GB93, LC90, BFKK91, HA90, LC91, KLS90, Soc91] </ref>). Hence, the programmer need not be involved in placing data. On the other hand, a compiler may not be able to infer the best placement, and compiler approach increases its complexity greatly.
Reference: [LC91] <author> J. Li and M. Chen. </author> <title> The data alignment phase in compiling programs for distributed-memory machines. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 13(4) </volume> <pages> 213-221, </pages> <month> August </month> <year> 1991. </year>
Reference-contexts: With a compiler-based approach, the compiler infers a placement for each array in the source code by inspecting loops and array accesses (e.g. <ref> [GB93, LC90, BFKK91, HA90, LC91, KLS90, Soc91] </ref>). Hence, the programmer need not be involved in placing data. On the other hand, a compiler may not be able to infer the best placement, and compiler approach increases its complexity greatly.
Reference: [McD88] <author> Jeffrey D. McDonald. </author> <title> A direct particle simulation method for hypersonic rarified flow. </title> <type> Technical Report 411, </type> <institution> Stanford University, </institution> <month> March </month> <year> 1988. </year>
Reference-contexts: (Our experimental cluster of workstations could not handle a larger matrix due to its limited memory.) However, we expect the performance of Adapt relative to the DF CYCLIC program to be about the same on eight node tests. 4.3 Particle Simulation Our particle simulation program models the behavior of MP3D <ref> [McD88] </ref>. (The following explanation is paraphrased from [PWG91].) MP3D solves rarefied fluid flow problems, studying the flow of molecules through a rectangular tunnel. Molecules move through the tunnel and at times collide with other molecules | the program computes their new locations using statistically determined probabilities.
Reference: [McM86] <author> F. McMahon. </author> <title> The Livermore Fortran Kernels: A computer test of the numerical performance range. </title> <type> Technical Report UCRL-53745, </type> <institution> Lawrence Livermore National Laboratory, </institution> <year> 1986. </year>
Reference-contexts: In such applications, such as the second sweep in Alternate Direction Integration <ref> [McM86] </ref>, a node must wait for data from other nodes before starting to perform computation. Contiguous placements would exacerbate this delay, and a fully striped placement would cause excess communication.
Reference: [MSH + 95] <author> Shubendu S. Mukherjee, Shamik D. Sharma, Mark D. Hill, James R. Larus, Anne Rogers, and Joel Saltz. </author> <title> Efficient support for irregular applications on distributed-memory machines. </title> <booktitle> In Fifth ACM SIGPLAN Symposium on Principles and Practices of Parallel Programming, </booktitle> <pages> pages 68-79, </pages> <month> July </month> <year> 1995. </year> <month> 14 </month>
Reference-contexts: DF Time, BLOCKCYCLIC (N=4P ) (sec) 69.1 48.5 34.2 26.2 DF Time, BLOCKCYCLIC (N=8P ) (sec) 69.1 46.5 39.3 42.6 Nodes 1 2 4 8 Adapt Time (sec) 69.4 39.4 24.3 16.3 DF Time, BLOCK (sec) 69.1 38.7 22.1 14.6 We distribute the space array to the nodes as in <ref> [MSH + 95] </ref> (as opposed to distributing the particles to the nodes). Each space cell contains a pointer to a list of particles contained in the cell. In each time step, the program updates the positions of each particle and collides particles that reside in the same grid cell.
Reference: [PAM94] <author> Dantosh S. Pande, Dharma P. Agrawal, and Jon Mauney. </author> <title> Compiling functional par-allelism on distributed-memory systems. </title> <journal> IEEE Parallel and Distributed Technology, </journal> <volume> 1(1) </volume> <pages> 64-76, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: Adapt continues to monitor the program, and if the characteristics of the application change, it changes the placement again. The ability to change placements during execution is especially important for problems|such as particle-in-cell codes [Har64]|for which the best data placement can vary over the course of the application <ref> [PAM94] </ref>. Adapt is currently implemented on a cluster of Sparc-1s and supports iterative scientific applications, which comprise a large subset of computational science applications.
Reference: [PWG91] <author> Jaswinder Pal Singh, Wolf-Dietrich Weber, and Anoop Gupta. </author> <title> SPLASH: Stanford Parallel Applications for Shared-Memory. </title> <type> Technical Report CSL-TR-91-469, </type> <institution> Department of Electrical Engineering and Computer Science, Stanford University, </institution> <month> April </month> <year> 1991. </year>
Reference-contexts: handle a larger matrix due to its limited memory.) However, we expect the performance of Adapt relative to the DF CYCLIC program to be about the same on eight node tests. 4.3 Particle Simulation Our particle simulation program models the behavior of MP3D [McD88]. (The following explanation is paraphrased from <ref> [PWG91] </ref>.) MP3D solves rarefied fluid flow problems, studying the flow of molecules through a rectangular tunnel. Molecules move through the tunnel and at times collide with other molecules | the program computes their new locations using statistically determined probabilities. When exiting the tunnel, the molecules re-enter at the opposite end.
Reference: [RSW91] <author> Matthew Rosing, Robert Schnabel, and Robert Weaver. </author> <title> The Dino parallel programming language. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 13(1) </volume> <pages> 30-42, </pages> <month> September </month> <year> 1991. </year>
Reference-contexts: With language primitives, the programmer annotates each array with a placement (e.g. <ref> [HPF93, HKK + 91, RSW91, ZBG88, CMZ92, TCF94] </ref>). The advantage of using language primitives is that the programmer has full control over the program.
Reference: [SMC91] <author> Joel H. Saltz, Ravi Mirchandaney, and Kay Crowley. </author> <title> Run-time parallelization and scheduling of loops. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 40(5) </volume> <pages> 603-612, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: Hence, the programmer need not be involved in placing data. On the other hand, a compiler may not be able to infer the best placement, and compiler approach increases its complexity greatly. With a run-time system approach, such as Adapt ALEXI [Who91], and the inspector/executor <ref> [SMC91] </ref> 9 , data-placement decisions are made during execution. This approach can produce good placements for a larger class of applications because of the increased information available at run time, but it incurs additional overhead to do so.
Reference: [Soc91] <author> David Grimes Socha. </author> <title> Supporting fine-grain computation on distributed memory parallel computers. </title> <type> PhD thesis, </type> <institution> University of Washington, </institution> <address> Seattle, WA 98195, </address> <month> July </month> <year> 1991. </year>
Reference-contexts: With a compiler-based approach, the compiler infers a placement for each array in the source code by inspecting loops and array accesses (e.g. <ref> [GB93, LC90, BFKK91, HA90, LC91, KLS90, Soc91] </ref>). Hence, the programmer need not be involved in placing data. On the other hand, a compiler may not be able to infer the best placement, and compiler approach increases its complexity greatly.
Reference: [TCF94] <author> Rajeev Thakur, Alok Choudhary, and Geoffrey Fox. </author> <title> Runtime array redistribution in HPF programs. </title> <booktitle> In Proceedings of Scalable High Performance Computing Conference 94, </booktitle> <pages> pages 309-316, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: With language primitives, the programmer annotates each array with a placement (e.g. <ref> [HPF93, HKK + 91, RSW91, ZBG88, CMZ92, TCF94] </ref>). The advantage of using language primitives is that the programmer has full control over the program.
Reference: [vCGS92] <author> Thorsten von Eicken, David E. Culler, Seth Copen Goldstein, and Klaus Eric Schauser. </author> <title> Active Messages: a mechanism for intergrated communication and computation. </title> <booktitle> In Proceedings of the 19th International Symposium on Computer Architecture, </booktitle> <pages> pages 256-266, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: In addition, some of the delay can be eliminated by overlapping communication and computation, as is done for example in <ref> [vCGS92, FLA94] </ref>. 6 with node 0 the owner. 3.1.2 Computation Monitoring Adapt instruments the code to obtain the time a node spends computing the data elements it owns.
Reference: [Who91] <author> Skef Wholey. </author> <title> Automatic Data Mapping for Distributed-Memory Parallel Computers. </title> <type> PhD thesis, </type> <institution> Carnegie Mellon University, </institution> <address> Pittsburgh, PA 15213, </address> <month> May </month> <year> 1991. </year>
Reference-contexts: Hence, the programmer need not be involved in placing data. On the other hand, a compiler may not be able to infer the best placement, and compiler approach increases its complexity greatly. With a run-time system approach, such as Adapt ALEXI <ref> [Who91] </ref>, and the inspector/executor [SMC91] 9 , data-placement decisions are made during execution. This approach can produce good placements for a larger class of applications because of the increased information available at run time, but it incurs additional overhead to do so. <p> However, it is concerned with optimizing communication, whereas the goal of Adapt is to determine data placements. 12 varies with the specific application; all three approaches have both advantages and drawbacks. Adapt monitors and remaps data at run time. A related approach is ALEXI <ref> [Who91] </ref>, which employs a static cost model for language primitives|based on the cost of machine primitives|and then uses a hill-climbing heuristic executed at run time to determine a good data placement. ALEXI does not allow data placements to change over the course of the application.
Reference: [ZBG88] <author> H.P. Zima, H.J. Bast, and M. Gerndt. </author> <title> SUPERB: A tool for semi-automatic MIMD/SIMD parallelization. </title> <journal> Parallel Computing, </journal> <volume> 6(6) </volume> <pages> 1-18, </pages> <month> January </month> <year> 1988. </year> <month> 15 </month>
Reference-contexts: With language primitives, the programmer annotates each array with a placement (e.g. <ref> [HPF93, HKK + 91, RSW91, ZBG88, CMZ92, TCF94] </ref>). The advantage of using language primitives is that the programmer has full control over the program.
References-found: 26

