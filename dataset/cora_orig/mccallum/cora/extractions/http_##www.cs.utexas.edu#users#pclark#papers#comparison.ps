URL: http://www.cs.utexas.edu/users/pclark/papers/comparison.ps
Refering-URL: http://www.cs.utexas.edu/users/pclark/papers/comparison.abs.html
Root-URL: 
Title: In: Machine Learning, Meta-reasoning and Logics, pp159-186,  A Comparison of Rule and Exemplar-Based Learning Systems  
Author: Eds: P. B. Brazdil and K. Konolige, Peter Clark 
Keyword: bias, exemplar-based, case-based, concept, rule learning, resources.  
Address: 36 N.Hanover St Glasgow, UK  
Affiliation: The Turing Institute  
Note: (1990), Boston: Kluwer.  
Email: (pete@turing.ac.uk)  
Web: http://www.cs.utexas.edu/users/pclark/papers/comparison.ps  
Date: 1990  
Abstract: Recently, there has been renewed interest in the use of exemplar-based schemes for concept representation and learning. In this paper, we compare systems learning concepts represented in this form with those which learn concepts represented by decision rules, such as the ID3 and AQ11 rule induction systems. We aim to clarify the distinction between the two representational schemes, and compare how systems based on the different schemes address the problem of learning within finite resources. Our conclusions are that the schemes differ in two important ways: in the different `biases' with which they select between alternative concepts during search, and in the different computational approaches of generalising before or during a run-time task. We also show that in addressing the problem of finite resources important commonalities between implementations based on both representational schemes arise, and by highlighting them aim to help enable the transfer of techniques between the two paradigms. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> B. Arbab and D. Michie. </author> <title> Generating rules from examples. </title> <booktitle> In IJCAI-85, </booktitle> <pages> pages 631-633, </pages> <year> 1985. </year>
Reference-contexts: In order to overcome this, one approach has been to allow the user to structure the task manually into a hierarchy of problems and sub-problems [43, 38], and another, in the case of the learned rule being a decision tree, to constrain the tree to be linear 2 <ref> [1] </ref>. 3.2.2 Exemplar-Based Systems One of the notable consequences of the exemplar model is that, in assessing concept membership, there is in general a single previously encountered example which best matches a new case 3 .
Reference: [2] <author> W. M. Bain. </author> <title> A case-based reasoning system for subjective assessment. </title> <booktitle> In AAAI-86, </booktitle> <pages> pages 523-527, </pages> <year> 1986. </year>
Reference-contexts: Weighting features: One method for representing important commonalities is by weighting some features as more important than others. In some exemplar-based systems the weights are found by applying statistical methods to the previously observed examples. In others, such as the case-based systems Chef [13] and Judge <ref> [2] </ref> the weights of importance are user-supplied. In the exemplar-based system Protos, they are found by analysis of the user's explanation of the relevance of an exemplar's feature to its category. 2.
Reference: [3] <author> E. R. Bareiss and B. W. Porter. </author> <title> A survey of psychological models of concept representation. </title> <type> Technical Report AI86-50, </type> <institution> The University of Texas at Austin, Computer Sciences Department, Austin, TX, </institution> <year> 1987. </year>
Reference-contexts: This is the problem of `category cohesiveness' discussed by Bareiss and Porter <ref> [3] </ref>. In order to represent and use such commonalities, various methods are used in exemplar- based systems. Some such methods are: 1. Weighting features: One method for representing important commonalities is by weighting some features as more important than others.
Reference: [4] <author> E. R. Bareiss, B. W. Porter, and C. C. Wier. PROTOS: </author> <title> an exemplar-based learning apprentice. </title> <editor> In P. Langley, editor, </editor> <booktitle> Proc. 4th International Workshop on Machine Learning, </booktitle> <publisher> Kaufmann, </publisher> <address> Ca, </address> <year> 1987. </year>
Reference-contexts: 1 Introduction Recently, there has been renewed interest in the use of exemplar-based schemes for concept representation (e.g. <ref> [4, 6, 16] </ref>), marking a notable shift in parts of the machine learning community [21]. Exemplar systems are based on a representation in which selected examples (termed exemplars) are stored and a matching algorithm retrieves that which best matches a new case. <p> The other extreme, where a single exemplar represents a concept, is sometimes referred to as a `prototype-based' representation (e.g. Taxman- II [22], and by Sowa [46]). Other examples of exemplar-based systems between these extremes include Protos <ref> [4, 33] </ref> Nexus [6] and those studied by Kibler and Aha [16]. Although matching algorithms vary from system to system, some general statement can be made about the models of the concept they assume. <p> The question of which those domains are, however, still evokes considerable debate. It has been claimed that most natural domains are best modelled by exemplar-based approaches (e.g. <ref> [45, 4] </ref>), although there has been little research conducted into ascertaining the appropriate learning `bias' by analysis of the domain itself (though see [40] for work in this area). 6.2 Concept Polymorphy and Volatility In section 4 the merits of pre-compiling generalisations (rule learning systems) compared with those of generating them
Reference: [5] <author> R. A. Boswell. </author> <title> An analytic survey of analytic concept-learning programs. </title> <type> Working Paper 181, </type> <institution> Dept. of AI, Edinburgh Univ., UK, </institution> <year> 1985. </year>
Reference-contexts: Examples in the AQ family are AQ11 [28], Gem [39] and AQ15 [24], and in the ID3 family are Assistant-86 [8] and C4 [37]. In addition, there has been work on the analytic learning of rules <ref> [5] </ref> sometimes referred to `explanation-based learning'. Examples include Strips [11], Lex-2 [31] and Soar [20]. As for exemplar-based representations, such systems make assumptions about the world which they observe, the validity of which will affect the performance of the systems.
Reference: [6] <author> G. Bradshaw. </author> <title> Learning about speech sounds: the nexus project. </title> <editor> In P. Langley, editor, </editor> <booktitle> Proc. 4th International Workshop on Machine Learning, </booktitle> <pages> pages 1-11, </pages> <publisher> Kaufmann, </publisher> <address> Ca, </address> <year> 1987. </year>
Reference-contexts: 1 Introduction Recently, there has been renewed interest in the use of exemplar-based schemes for concept representation (e.g. <ref> [4, 6, 16] </ref>), marking a notable shift in parts of the machine learning community [21]. Exemplar systems are based on a representation in which selected examples (termed exemplars) are stored and a matching algorithm retrieves that which best matches a new case. <p> The other extreme, where a single exemplar represents a concept, is sometimes referred to as a `prototype-based' representation (e.g. Taxman- II [22], and by Sowa [46]). Other examples of exemplar-based systems between these extremes include Protos [4, 33] Nexus <ref> [6] </ref> and those studied by Kibler and Aha [16]. Although matching algorithms vary from system to system, some general statement can be made about the models of the concept they assume. <p> More sophisticated systems will incorporate information about examples before they are discarded, for example by updating weights on features in the best-matching exemplar's description or updating parameters in the matching algorithm. This incremental method is used in Protos and Nexus <ref> [6] </ref>. 4 The authors of Protos refer the reader to [41] for the definition of prototypicality used 9 In storing only selected exemplars, some systems adopt a means of annotating the exemplar with extra information to summarise those examples which the exemplar represents (e.g. measures of how representative each exemplar feature
Reference: [7] <author> J. G. Carbonell. </author> <title> Learning by analogy : formulating and generalizing plans from past experience. </title> <editor> In J. G. Carbonell, R. S. Michalski, and T. M. Mitchell, editors, </editor> <booktitle> Machine Learning, </booktitle> <volume> vol. 1, </volume> <publisher> Tioga, </publisher> <address> Palo Alto, Ca, </address> <year> 1983. </year>
Reference-contexts: With careful control of search, an exemplar system may never need to fully explore all generalisations which would have been formed by a rule learning system. This is especially true in case-based planning systems such as Chef [13] and by Carbonell <ref> [7] </ref>. Given an example plan, these systems could form all the (potentially 7 numerous) generalised variants of it, then select and instantiate one when a new problem is encountered.
Reference: [8] <author> B. Cestnik, I. Kononenko, and I. Bratko. </author> <title> Assistant 86: a knowledge-elicitation tool for sophisticated users. </title> <editor> In I. Bratko and N. Lavrac, editors, </editor> <booktitle> Progress in Machine Learning (proceedings of the 2nd European Working Session on Learning), </booktitle> <pages> pages 31-45, </pages> <address> Sigma, Wilmslow, UK, </address> <year> 1987. </year>
Reference-contexts: Examples in the AQ family are AQ11 [28], Gem [39] and AQ15 [24], and in the ID3 family are Assistant-86 <ref> [8] </ref> and C4 [37]. In addition, there has been work on the analytic learning of rules [5] sometimes referred to `explanation-based learning'. Examples include Strips [11], Lex-2 [31] and Soar [20].
Reference: [9] <author> T. G. Dietterich and R. S. Michalski. </author> <title> A comparative review of selected methods for learning from examples. </title> <editor> In J. G. Carbonell, R. S. Michalski, and T. M. Mitchell, editors, </editor> <booktitle> Machine Learning, </booktitle> <volume> vol. 1, </volume> <pages> pages 41-81, </pages> <publisher> Tioga, </publisher> <address> Palo Alto, Ca, </address> <year> 1983. </year>
Reference-contexts: A simple interpreter deems a new example to be a member of the concept if the general description holds true for it. Much work has been devoted to the empirical learning of such statements from examples <ref> [9] </ref> and two families of rule induction system, based on the AQ [27] and ID3 [36] algorithms, have been particularly successful. Examples in the AQ family are AQ11 [28], Gem [39] and AQ15 [24], and in the ID3 family are Assistant-86 [8] and C4 [37].
Reference: [10] <author> W. Emde. </author> <title> Big flood in the blocks world; or non-cumulative learning. </title> <booktitle> In ECAI-86, </booktitle> <pages> pages 569-575, </pages> <year> 1986. </year>
Reference-contexts: one hand it can be argued it gives the rule-base the undesirable property of `brittleness' [14], on the other hand it enables the occasional major re-organisation of knowledge to occur allowing the system to escape from some local but not global optimum of organisation, enabling it to make `paradigm shifts' <ref> [10] </ref> as well as small refinements to knowledge. 5.3 Summary In order to meet the computational requirement of limited memory usage and the ability to learn incrementally, both representational schemes have converged to a degree on the mechanisms involved.
Reference: [11] <author> R. Fikes, P. Hart, and N. Nilsson. </author> <title> Learning and executing generalized robot plans. </title> <editor> In B. Webber and N. Nilsson, editors, </editor> <booktitle> Readings in AI, </booktitle> <pages> pages 231-249, </pages> <publisher> Tioga, </publisher> <address> Palo Alto, CA, </address> <year> 1981. </year>
Reference-contexts: Examples in the AQ family are AQ11 [28], Gem [39] and AQ15 [24], and in the ID3 family are Assistant-86 [8] and C4 [37]. In addition, there has been work on the analytic learning of rules [5] sometimes referred to `explanation-based learning'. Examples include Strips <ref> [11] </ref>, Lex-2 [31] and Soar [20]. As for exemplar-based representations, such systems make assumptions about the world which they observe, the validity of which will affect the performance of the systems.
Reference: [12] <author> R. Hall. </author> <title> Learning by Failing to Explain. </title> <type> Technical Report 906 (AI-TR-906), </type> <institution> MIT AI Laboratory, </institution> <year> 1986. </year>
Reference-contexts: system is able to recog- nise near matches (i.e. `near misses' [49]) as well as when an example matches an exemplar/generalisation perfectly, then this can act as a source of new domain knowledge by inferring the `missing inference links' and selecting the appropriate interpretation required to make the match perfect <ref> [48, 12] </ref>. 5 In summary, the representational requirement of providing a degree of concept mem-bership is often important in many applications.
Reference: [13] <author> K. Hammond. CHEF: </author> <title> a model of case-based planning. </title> <booktitle> In AAAI-86, </booktitle> <year> 1986. </year>
Reference-contexts: With careful control of search, an exemplar system may never need to fully explore all generalisations which would have been formed by a rule learning system. This is especially true in case-based planning systems such as Chef <ref> [13] </ref> and by Carbonell [7]. Given an example plan, these systems could form all the (potentially 7 numerous) generalised variants of it, then select and instantiate one when a new problem is encountered. <p> Some such methods are: 1. Weighting features: One method for representing important commonalities is by weighting some features as more important than others. In some exemplar-based systems the weights are found by applying statistical methods to the previously observed examples. In others, such as the case-based systems Chef <ref> [13] </ref> and Judge [2] the weights of importance are user-supplied. In the exemplar-based system Protos, they are found by analysis of the user's explanation of the relevance of an exemplar's feature to its category. 2.
Reference: [14] <author> J. Holland. </author> <title> Escaping brittleness. </title> <editor> In J. G. Carbonell, R. S. Michalski, and T. M. Mitchell, editors, </editor> <booktitle> Machine Learning, </booktitle> <volume> vol. 2, </volume> <publisher> Tioga, Tioga, </publisher> <year> 1986. </year>
Reference-contexts: However, sometimes the addition of a single new example can cause a large change in the rule-base. Whether this is a good or a bad property is debatable on one hand it can be argued it gives the rule-base the undesirable property of `brittleness' <ref> [14] </ref>, on the other hand it enables the occasional major re-organisation of knowledge to occur allowing the system to escape from some local but not global optimum of organisation, enabling it to make `paradigm shifts' [10] as well as small refinements to knowledge. 5.3 Summary In order to meet the computational
Reference: [15] <author> R. Holte and R. Zimmer. </author> <title> Estimating the cost effectiveness of macro-operators. 1987. </title> <institution> Brunel Univ., </institution> <note> UK (to be published). 13 </note>
Reference-contexts: However, there are three counter-efficiency effects which pre-compilation causes and must be born in mind: * The system can be swamped with generalisations if it is not selective about which to store. This issue has been examined by workers in explanation-based learning (see <ref> [30, 29, 15] </ref>). * There is a computational overhead in forming the generalisations in the first place it may be that there are many valid generalisations which can be formed, and to form them all beforehand is wasteful.
Reference: [16] <author> D. Kibler and D. W. Aha. </author> <title> Learning representative exemplars of concepts: an initial case study. </title> <editor> In P. Langley, editor, </editor> <booktitle> Proc. 4th International Workshop on Machine Learning, </booktitle> <publisher> Kaufmann, </publisher> <address> Ca, </address> <year> 1987. </year>
Reference-contexts: 1 Introduction Recently, there has been renewed interest in the use of exemplar-based schemes for concept representation (e.g. <ref> [4, 6, 16] </ref>), marking a notable shift in parts of the machine learning community [21]. Exemplar systems are based on a representation in which selected examples (termed exemplars) are stored and a matching algorithm retrieves that which best matches a new case. <p> The other extreme, where a single exemplar represents a concept, is sometimes referred to as a `prototype-based' representation (e.g. Taxman- II [22], and by Sowa [46]). Other examples of exemplar-based systems between these extremes include Protos [4, 33] Nexus [6] and those studied by Kibler and Aha <ref> [16] </ref>. Although matching algorithms vary from system to system, some general statement can be made about the models of the concept they assume. <p> Incremental learning in exemplar systems typically occurs by variations on the `additive algorithm', described in its simplest form in <ref> [16] </ref>. If a new example matches an exemplar well and the example is a member of the exemplar's category, the new example is discarded. Otherwise, the example forms a new exemplar on its own.
Reference: [17] <author> J. J. Kolodner. </author> <title> Extending problem solver capabilities through case-based inference. In Ca, editor, </title> <booktitle> Proc. 4th International Workshop on Machine Learning, </booktitle> <pages> pages 167-178, </pages> <publisher> Kaufmann, </publisher> <address> Ca, </address> <year> 1987. </year>
Reference-contexts: This method sometimes referred to as the `nearest neighbour' classification algorithm. The one extreme of exemplar representation where all examples are stored as exemplars (e.g. Cyrus [18] and Julia <ref> [17] </ref>) is sometimes referred to as an `instance-based' or `case-based' representation. The other extreme, where a single exemplar represents a concept, is sometimes referred to as a `prototype-based' representation (e.g. Taxman- II [22], and by Sowa [46]).
Reference: [18] <author> J. J. Kolodner. </author> <title> Maintaining organization in a dynamic long-term memory. </title> <booktitle> Cognitive Science, </booktitle> <address> 7:281328, </address> <year> 1983. </year>
Reference-contexts: This method sometimes referred to as the `nearest neighbour' classification algorithm. The one extreme of exemplar representation where all examples are stored as exemplars (e.g. Cyrus <ref> [18] </ref> and Julia [17]) is sometimes referred to as an `instance-based' or `case-based' representation. The other extreme, where a single exemplar represents a concept, is sometimes referred to as a `prototype-based' representation (e.g. Taxman- II [22], and by Sowa [46]).
Reference: [19] <author> J. L. Kolodner, R. L. Simpson, and K. Sycara-Cyranski. </author> <title> A process model of case-based reasoning in problem solving. </title> <booktitle> In IJCAI-85, </booktitle> <year> 1985. </year>
Reference-contexts: Location of a best matching case involves two processes firstly descending the hierarchy to locate previous cases and secondly applying a matching process to select among those cases encountered (as performed by Mediator <ref> [19] </ref>). This has the effect of considering some (possibly 8 generalised) features as essential prerequisites for selecting an old case, and others as optional. 3. Prototypicality: In addition to exemplars, the exemplar-based system Protos contains a representation of the categories exemplars belong to.
Reference: [20] <author> J. E. Laird, P. S. Rosenbloom, and A. Newell. </author> <title> Chunking in soar: the anatomy of a general learning mechanism. </title> <journal> Machine Learning, </journal> <volume> 1(1) </volume> <pages> 11-46, </pages> <year> 1986. </year>
Reference-contexts: In addition, there has been work on the analytic learning of rules [5] sometimes referred to `explanation-based learning'. Examples include Strips [11], Lex-2 [31] and Soar <ref> [20] </ref>. As for exemplar-based representations, such systems make assumptions about the world which they observe, the validity of which will affect the performance of the systems.
Reference: [21] <author> P. Langley. </author> <title> The emerging science of machine learning. </title> <editor> In P. Langley, editor, </editor> <booktitle> Proc. 4th International Workshop on Machine Learning, pages v-vi, </booktitle> <publisher> Kaufmann, </publisher> <address> Ca, </address> <year> 1987. </year> <note> (Preface to Proceedings). </note>
Reference-contexts: 1 Introduction Recently, there has been renewed interest in the use of exemplar-based schemes for concept representation (e.g. [4, 6, 16]), marking a notable shift in parts of the machine learning community <ref> [21] </ref>. Exemplar systems are based on a representation in which selected examples (termed exemplars) are stored and a matching algorithm retrieves that which best matches a new case.
Reference: [22] <author> L. T. McCarty and N. S. Sridharan. </author> <title> A Computational Theory of Legal Argument. </title> <type> Technical Report LRP-TR-13, </type> <institution> Rutgers Univ., Lab. for C.S. Research, NJ, </institution> <year> 1982. </year>
Reference-contexts: Cyrus [18] and Julia [17]) is sometimes referred to as an `instance-based' or `case-based' representation. The other extreme, where a single exemplar represents a concept, is sometimes referred to as a `prototype-based' representation (e.g. Taxman- II <ref> [22] </ref>, and by Sowa [46]). Other examples of exemplar-based systems between these extremes include Protos [4, 33] Nexus [6] and those studied by Kibler and Aha [16]. Although matching algorithms vary from system to system, some general statement can be made about the models of the concept they assume.
Reference: [23] <author> J. McDermott. </author> <title> R1: a rule-based configurer of computer systems. </title> <journal> Artificial Intelligence, </journal> <volume> 19(1) </volume> <pages> 39-88, </pages> <year> 1982. </year>
Reference-contexts: However, other methods of concept representation, in particular the production rule paradigm of expert systems, have already proved successful in many applications (e.g. Mycin [44], R1 <ref> [23] </ref>) and much work in machine learning has been devoted to the automatic formation of generalised statements from examples (e.g. AQ11 [28], C4 [37], Lex-2 [31]). This paper compares and contrasts learning systems based on exemplar representations with such rule learning systems.
Reference: [24] <author> R. Michalski, I. Mozetic, J. Hong, and N. Lavrac. </author> <title> The multi-purpose incremental learning system aq15 and its testing application to three medical domains. </title> <booktitle> In AAAI-86, </booktitle> <pages> pages 1041-1045, </pages> <publisher> Kaufmann, </publisher> <address> Ca, </address> <year> 1986. </year>
Reference-contexts: Much work has been devoted to the empirical learning of such statements from examples [9] and two families of rule induction system, based on the AQ [27] and ID3 [36] algorithms, have been particularly successful. Examples in the AQ family are AQ11 [28], Gem [39] and AQ15 <ref> [24] </ref>, and in the ID3 family are Assistant-86 [8] and C4 [37]. In addition, there has been work on the analytic learning of rules [5] sometimes referred to `explanation-based learning'. Examples include Strips [11], Lex-2 [31] and Soar [20]. <p> With this, an incremental learning algorithm can be applied to cope with new training examples [26], as has been applied in AQ15 <ref> [24] </ref> and the system by Mozetic [32]. Here 1. rules contradicted by a new example are either specialised to exclude it (as in AQ15) or simply discarded (as in Mozetic's system) and 2. new rules are induced for any examples now without rules `covering' them.
Reference: [25] <author> R. S. Michalski. </author> <title> How to learn imprecise concepts: a method for employing a two-tiered knowledge representation in learning. </title> <editor> In P. Langley, editor, </editor> <booktitle> Proc. 4th International Workshop on Machine Learning, </booktitle> <publisher> Kaufmann, </publisher> <address> Ca, </address> <year> 1987. </year>
Reference-contexts: In AQ15, the degree to which the `base concept representation' of rules can be mixed with matching procedures can be varied <ref> [25] </ref>. Quinlan recently proposed an adaptation of the decision tree interpreter to introduce a measure of probability of class membership [34]. A final point is that using matching processes can act as a useful source of domain knowledge, and can be used to resolve ambiguities in data.
Reference: [26] <author> R. S. Michalski. </author> <title> Knowledge repair mechanisms: evolution vs. revolution. </title> <type> ISG 85-15, </type> <institution> Univ. of Illinois at Urbana-Champaign, Dept. of Computer Science, Urbana, </institution> <year> 1985. </year>
Reference-contexts: With this, an incremental learning algorithm can be applied to cope with new training examples <ref> [26] </ref>, as has been applied in AQ15 [24] and the system by Mozetic [32].
Reference: [27] <author> R. S. Michalski. </author> <title> On the quasi-minimal solution of the general covering problem. </title> <booktitle> In Proceedings of the 5th international symposium on Information Processing (FCIP 69), Vol. A3 (Switching circuits), Bled, Yugoslavia, </booktitle> <pages> pages 125-128, </pages> <year> 1969. </year>
Reference-contexts: A simple interpreter deems a new example to be a member of the concept if the general description holds true for it. Much work has been devoted to the empirical learning of such statements from examples [9] and two families of rule induction system, based on the AQ <ref> [27] </ref> and ID3 [36] algorithms, have been particularly successful. Examples in the AQ family are AQ11 [28], Gem [39] and AQ15 [24], and in the ID3 family are Assistant-86 [8] and C4 [37].
Reference: [28] <author> R. S. Michalski and J. Larson. </author> <title> Incremental Generation of VL 1 Hypotheses: the underlying Methodology and the Description of Program AQ11. </title> <type> ISG 83-5, </type> <institution> Dept. of Computer Science, Univ. of Illinois at Urbana-Champaign, Urbana, </institution> <year> 1983. </year>
Reference-contexts: However, other methods of concept representation, in particular the production rule paradigm of expert systems, have already proved successful in many applications (e.g. Mycin [44], R1 [23]) and much work in machine learning has been devoted to the automatic formation of generalised statements from examples (e.g. AQ11 <ref> [28] </ref>, C4 [37], Lex-2 [31]). This paper compares and contrasts learning systems based on exemplar representations with such rule learning systems. <p> Much work has been devoted to the empirical learning of such statements from examples [9] and two families of rule induction system, based on the AQ [27] and ID3 [36] algorithms, have been particularly successful. Examples in the AQ family are AQ11 <ref> [28] </ref>, Gem [39] and AQ15 [24], and in the ID3 family are Assistant-86 [8] and C4 [37]. In addition, there has been work on the analytic learning of rules [5] sometimes referred to `explanation-based learning'. Examples include Strips [11], Lex-2 [31] and Soar [20]. <p> In order to resolve such conflicts, matching procedures are used to assess which rule the example matches `best' (e.g. AQ11 <ref> [28] </ref>). Recently, the use of matching to augment logical instantiation in rule application has become emphasised as a way in which the notion of degree of match can be introduced in rule application.
Reference: [29] <author> S. Minton. </author> <title> Quantitative results concerning the utility of explanation-based learning. </title> <booktitle> In AAAI-88, </booktitle> <pages> pages 564-569, </pages> <publisher> Kaufman, </publisher> <address> Ca, </address> <month> August </month> <year> 1988. </year>
Reference-contexts: However, there are three counter-efficiency effects which pre-compilation causes and must be born in mind: * The system can be swamped with generalisations if it is not selective about which to store. This issue has been examined by workers in explanation-based learning (see <ref> [30, 29, 15] </ref>). * There is a computational overhead in forming the generalisations in the first place it may be that there are many valid generalisations which can be formed, and to form them all beforehand is wasteful.
Reference: [30] <author> S. Minton. </author> <title> Selectively generalizing plans for problem-solving. </title> <booktitle> In IJCAI-85, </booktitle> <pages> pages 596-599, </pages> <year> 1985. </year>
Reference-contexts: However, there are three counter-efficiency effects which pre-compilation causes and must be born in mind: * The system can be swamped with generalisations if it is not selective about which to store. This issue has been examined by workers in explanation-based learning (see <ref> [30, 29, 15] </ref>). * There is a computational overhead in forming the generalisations in the first place it may be that there are many valid generalisations which can be formed, and to form them all beforehand is wasteful.
Reference: [31] <author> T. M. Mitchell. </author> <title> Towards Combining Empirical and Analytic Methods for inferring Heuristics. </title> <type> Technical Report LCSR-TR-27, </type> <institution> Rutgers Univ., Lab. for Computer Science, </institution> <year> 1982. </year>
Reference-contexts: Mycin [44], R1 [23]) and much work in machine learning has been devoted to the automatic formation of generalised statements from examples (e.g. AQ11 [28], C4 [37], Lex-2 <ref> [31] </ref>). This paper compares and contrasts learning systems based on exemplar representations with such rule learning systems. Any concept learning system must address the problem of how to transfer knowledge from previously observed to new examples within limited resources, the two most important of which are speed and memory usage. <p> Examples in the AQ family are AQ11 [28], Gem [39] and AQ15 [24], and in the ID3 family are Assistant-86 [8] and C4 [37]. In addition, there has been work on the analytic learning of rules [5] sometimes referred to `explanation-based learning'. Examples include Strips [11], Lex-2 <ref> [31] </ref> and Soar [20]. As for exemplar-based representations, such systems make assumptions about the world which they observe, the validity of which will affect the performance of the systems.
Reference: [32] <author> I. Mozetic. </author> <title> The role of abstractions in learning qualitative models. </title> <editor> In P. Langley, editor, </editor> <booktitle> Proc. 4th International Workshop on Machine Learning, </booktitle> <publisher> Kaufmann, </publisher> <address> Ca, </address> <year> 1987. </year>
Reference-contexts: With this, an incremental learning algorithm can be applied to cope with new training examples [26], as has been applied in AQ15 [24] and the system by Mozetic <ref> [32] </ref>. Here 1. rules contradicted by a new example are either specialised to exclude it (as in AQ15) or simply discarded (as in Mozetic's system) and 2. new rules are induced for any examples now without rules `covering' them. Similar mechanisms have been applied to incrementally forming decision trees (eg.
Reference: [33] <author> B. W. Porter and R. E. Bareiss. PROTOS: </author> <title> an experiment in knowledge acquisition for heuristic classification tasks. </title> <booktitle> In Proceedings of IMAL 1986, </booktitle> <institution> Universite de Paris-Sud, Orsay, France, </institution> <year> 1986. </year>
Reference-contexts: The other extreme, where a single exemplar represents a concept, is sometimes referred to as a `prototype-based' representation (e.g. Taxman- II [22], and by Sowa [46]). Other examples of exemplar-based systems between these extremes include Protos <ref> [4, 33] </ref> Nexus [6] and those studied by Kibler and Aha [16]. Although matching algorithms vary from system to system, some general statement can be made about the models of the concept they assume.
Reference: [34] <author> J. R. Quinlan. </author> <title> Decision trees as probabilistic classifiers. </title> <editor> In P. Langley, editor, </editor> <booktitle> Proc. 4th International Workshop on Machine Learning, </booktitle> <publisher> Kaufmann, </publisher> <address> Ca, </address> <year> 1987. </year>
Reference-contexts: In AQ15, the degree to which the `base concept representation' of rules can be mixed with matching procedures can be varied [25]. Quinlan recently proposed an adaptation of the decision tree interpreter to introduce a measure of probability of class membership <ref> [34] </ref>. A final point is that using matching processes can act as a useful source of domain knowledge, and can be used to resolve ambiguities in data.
Reference: [35] <author> J. R. Quinlan. </author> <title> Discovering rules by induction from large collections of examples. </title> <editor> In D. Michie, editor, </editor> <booktitle> Expert Systems in the Micro-Electronic Age, </booktitle> <pages> pages 168-201, </pages> <publisher> Edinburgh Univ. Press, </publisher> <address> UK, </address> <year> 1979. </year>
Reference-contexts: Similar mechanisms have been applied to incrementally forming decision trees (eg. ID5 [47]). An alternative to using `full memory' is simply to retain a set or `window' of most representative training examples, as performed by various implementations of the ID3 induction system <ref> [35] </ref>. If any new examples arrive which are incorrectly classified, they are added to the window and other examples removed. Following this, the decision tree is re-induced from scratch.
Reference: [36] <author> J. R. Quinlan. </author> <title> Learning efficient classification procedures and their application to chess endgames. </title> <editor> In J. G. Carbonell, R. S. Michalski, and T. M. Mitchell, editors, </editor> <booktitle> Machine Learning, </booktitle> <volume> vol. 1, </volume> <publisher> Tioga, </publisher> <address> Palo Alto, Ca, </address> <year> 1983. </year>
Reference-contexts: Much work has been devoted to the empirical learning of such statements from examples [9] and two families of rule induction system, based on the AQ [27] and ID3 <ref> [36] </ref> algorithms, have been particularly successful. Examples in the AQ family are AQ11 [28], Gem [39] and AQ15 [24], and in the ID3 family are Assistant-86 [8] and C4 [37]. In addition, there has been work on the analytic learning of rules [5] sometimes referred to `explanation-based learning'.
Reference: [37] <author> J. R. Quinlan, P. J. Compton, K. A. Horn, and L. Lazarus. </author> <title> Inductive knowledge acquisition: a case study. </title> <booktitle> In Applications of Expert Systems, </booktitle> <pages> pages 157-173, </pages> <publisher> Addison-Wesley, </publisher> <address> Wokingham, UK, </address> <year> 1987. </year>
Reference-contexts: However, other methods of concept representation, in particular the production rule paradigm of expert systems, have already proved successful in many applications (e.g. Mycin [44], R1 [23]) and much work in machine learning has been devoted to the automatic formation of generalised statements from examples (e.g. AQ11 [28], C4 <ref> [37] </ref>, Lex-2 [31]). This paper compares and contrasts learning systems based on exemplar representations with such rule learning systems. <p> Examples in the AQ family are AQ11 [28], Gem [39] and AQ15 [24], and in the ID3 family are Assistant-86 [8] and C4 <ref> [37] </ref>. In addition, there has been work on the analytic learning of rules [5] sometimes referred to `explanation-based learning'. Examples include Strips [11], Lex-2 [31] and Soar [20].
Reference: [38] <author> A. Razzak, D. Michie, T. Hansan, and A. Ahmad. </author> <title> Case studies of building expert systems using extran. </title> <booktitle> In Artificial Intelligence and Advanced Computer Technology, </booktitle> <year> 1986. </year>
Reference-contexts: In order to overcome this, one approach has been to allow the user to structure the task manually into a hierarchy of problems and sub-problems <ref> [43, 38] </ref>, and another, in the case of the learned rule being a decision tree, to constrain the tree to be linear 2 [1]. 3.2.2 Exemplar-Based Systems One of the notable consequences of the exemplar model is that, in assessing concept membership, there is in general a single previously encountered example
Reference: [39] <author> R. E. Reinke. </author> <title> Knowledge acquisition and refinement tools for the ADVISE META-EXPERT sys-tem. M. S. </title> <type> Thesis ISG 84-4, </type> <institution> UIUCDCS-F-84-921, Univ. of Illinois at Urbana-Champaign, Dept. of Computer Science, Urbana, </institution> <year> 1984. </year> <month> 14 </month>
Reference-contexts: Much work has been devoted to the empirical learning of such statements from examples [9] and two families of rule induction system, based on the AQ [27] and ID3 [36] algorithms, have been particularly successful. Examples in the AQ family are AQ11 [28], Gem <ref> [39] </ref> and AQ15 [24], and in the ID3 family are Assistant-86 [8] and C4 [37]. In addition, there has been work on the analytic learning of rules [5] sometimes referred to `explanation-based learning'. Examples include Strips [11], Lex-2 [31] and Soar [20].
Reference: [40] <author> L. Rendell, R. Seshu, and D. Tcheng. </author> <title> More robust concept learning using dynamically-variable bias. </title> <editor> In P. Langley, editor, </editor> <booktitle> Proc. 4th International Workshop on Machine Learning, </booktitle> <pages> pages 66-78, </pages> <publisher> Kaufmann, </publisher> <address> Ca, </address> <year> 1987. </year>
Reference-contexts: It has been claimed that most natural domains are best modelled by exemplar-based approaches (e.g. [45, 4]), although there has been little research conducted into ascertaining the appropriate learning `bias' by analysis of the domain itself (though see <ref> [40] </ref> for work in this area). 6.2 Concept Polymorphy and Volatility In section 4 the merits of pre-compiling generalisations (rule learning systems) compared with those of generating them at run-time only as needed (exemplar-based systems) were compared. The appropriateness of these approaches again depends on the domain of application.
Reference: [41] <author> E. Rosch and C. B. Mervis. </author> <title> Family resemblance studies in the internal structure of categories. </title> <journal> Cognitive Psychology, </journal> <volume> 7 </volume> <pages> 573-605, </pages> <year> 1975. </year>
Reference-contexts: This incremental method is used in Protos and Nexus [6]. 4 The authors of Protos refer the reader to <ref> [41] </ref> for the definition of prototypicality used 9 In storing only selected exemplars, some systems adopt a means of annotating the exemplar with extra information to summarise those examples which the exemplar represents (e.g. measures of how representative each exemplar feature is of the discarded examples, how many examples were discarded).
Reference: [42] <author> R. Schank. </author> <title> Dynamic Memory. </title> <publisher> Cambridge Univ. Press, </publisher> <year> 1982. </year>
Reference-contexts: In the exemplar-based system Protos, they are found by analysis of the user's explanation of the relevance of an exemplar's feature to its category. 2. Use of Generalised Structures: Another method for representing important commonalities is through the use of additional generalised structures to organise memory <ref> [42] </ref> typically organised hierarchically. Location of a best matching case involves two processes firstly descending the hierarchy to locate previous cases and secondly applying a matching process to select among those cases encountered (as performed by Mediator [19]).
Reference: [43] <author> A. D. Shapiro. </author> <title> Structured Induction in Expert Systems. </title> <publisher> Turing Inst. Press, in association with Addison-Wesley, </publisher> <address> Wokingham, UK, </address> <year> 1987. </year>
Reference-contexts: In order to overcome this, one approach has been to allow the user to structure the task manually into a hierarchy of problems and sub-problems <ref> [43, 38] </ref>, and another, in the case of the learned rule being a decision tree, to constrain the tree to be linear 2 [1]. 3.2.2 Exemplar-Based Systems One of the notable consequences of the exemplar model is that, in assessing concept membership, there is in general a single previously encountered example
Reference: [44] <author> E. H. Shortliffe. </author> <title> Computer-Based Medical Consultations: MYCIN. </title> <publisher> American Elsevier, </publisher> <address> NY, </address> <year> 1976. </year>
Reference-contexts: However, other methods of concept representation, in particular the production rule paradigm of expert systems, have already proved successful in many applications (e.g. Mycin <ref> [44] </ref>, R1 [23]) and much work in machine learning has been devoted to the automatic formation of generalised statements from examples (e.g. AQ11 [28], C4 [37], Lex-2 [31]). This paper compares and contrasts learning systems based on exemplar representations with such rule learning systems.
Reference: [45] <author> E. E. Smith and D. L. Medin. </author> <title> Categories and Concepts. </title> <publisher> Harvard Univ., </publisher> <address> Cambridge, Ma, </address> <year> 1981. </year>
Reference-contexts: The question of which those domains are, however, still evokes considerable debate. It has been claimed that most natural domains are best modelled by exemplar-based approaches (e.g. <ref> [45, 4] </ref>), although there has been little research conducted into ascertaining the appropriate learning `bias' by analysis of the domain itself (though see [40] for work in this area). 6.2 Concept Polymorphy and Volatility In section 4 the merits of pre-compiling generalisations (rule learning systems) compared with those of generating them
Reference: [46] <author> J. F. Sowa. </author> <title> Conceptual structures : Information processing in mind and machine. </title> <publisher> Addison Wesley, </publisher> <year> 1984. </year>
Reference-contexts: Cyrus [18] and Julia [17]) is sometimes referred to as an `instance-based' or `case-based' representation. The other extreme, where a single exemplar represents a concept, is sometimes referred to as a `prototype-based' representation (e.g. Taxman- II [22], and by Sowa <ref> [46] </ref>). Other examples of exemplar-based systems between these extremes include Protos [4, 33] Nexus [6] and those studied by Kibler and Aha [16]. Although matching algorithms vary from system to system, some general statement can be made about the models of the concept they assume.
Reference: [47] <author> P. E. Utgoff. Id5: </author> <title> an incremental id3. </title> <editor> In J. Laird, editor, </editor> <booktitle> Proc. 5th Int. Conf. on Machine Learning, </booktitle> <pages> pages 107-120, </pages> <publisher> Kaufmann, </publisher> <address> Ca, </address> <month> June </month> <year> 1988. </year>
Reference-contexts: Similar mechanisms have been applied to incrementally forming decision trees (eg. ID5 <ref> [47] </ref>). An alternative to using `full memory' is simply to retain a set or `window' of most representative training examples, as performed by various implementations of the ID3 induction system [35]. If any new examples arrive which are incorrectly classified, they are added to the window and other examples removed.
Reference: [48] <author> K. VanLehn. </author> <title> Learning a domain theory by completing explanations. </title> <editor> In T. M. Mitchell, J. G. Carbonell, and R. S. Michalski, editors, </editor> <title> Machine Learning: A Guide to Current Research, </title> <publisher> Kluwer, </publisher> <address> Lancaster, UK, </address> <year> 1986. </year>
Reference-contexts: system is able to recog- nise near matches (i.e. `near misses' [49]) as well as when an example matches an exemplar/generalisation perfectly, then this can act as a source of new domain knowledge by inferring the `missing inference links' and selecting the appropriate interpretation required to make the match perfect <ref> [48, 12] </ref>. 5 In summary, the representational requirement of providing a degree of concept mem-bership is often important in many applications.
Reference: [49] <author> P. H. Winston. </author> <title> Learning structural descriptions from examples. </title> <editor> In P. H. Winston, editor, </editor> <booktitle> The Psychology of Computer Vision, </booktitle> <publisher> McGraw-Hill, </publisher> <address> NY, </address> <year> 1975. </year> <month> 15 </month>
Reference-contexts: A final point is that using matching processes can act as a useful source of domain knowledge, and can be used to resolve ambiguities in data. If a system is able to recog- nise near matches (i.e. `near misses' <ref> [49] </ref>) as well as when an example matches an exemplar/generalisation perfectly, then this can act as a source of new domain knowledge by inferring the `missing inference links' and selecting the appropriate interpretation required to make the match perfect [48, 12]. 5 In summary, the representational requirement of providing a degree
References-found: 49

