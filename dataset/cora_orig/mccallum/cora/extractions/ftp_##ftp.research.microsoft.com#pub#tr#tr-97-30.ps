URL: ftp://ftp.research.microsoft.com/pub/tr/tr-97-30.ps
Refering-URL: http://www.research.microsoft.com/~meek/meek.htm
Root-URL: http://www.research.microsoft.com
Email: fthiesson,meek,dmax,heckermag@microsoft.com  
Title: Learning Mixtures of DAG Models  
Author: Bo Thiesson Christopher Meek David Maxwell Chickering David Heckerman 
Date: December 1997 (Revised May 1998)  
Address: Redmond, WA 98052  One Microsoft Way Redmond, WA 98052  
Affiliation: Microsoft Research  Microsoft Research Advanced Technology Division Microsoft Corporation  
Abstract: Technical Report MSR-TR-97-30 
Abstract-found: 1
Intro-found: 1
Reference: [Banfield and Raftery, 1993] <author> Banfield, J. and Raftery, A. </author> <year> (1993). </year> <title> Model-based Gaussian and non-Gaussian clustering. </title> <journal> Biometrics, </journal> <volume> 49 </volume> <pages> 803-821. </pages>
Reference: [Bernardo and Smith, 1994] <author> Bernardo, J. and Smith, A. </author> <year> (1994). </year> <title> Bayesian Theory. </title> <publisher> John Wiley and Sons, </publisher> <address> New York. </address>
Reference: [Buntine, 1994] <author> Buntine, W. </author> <year> (1994). </year> <title> Operations for learning with graphical models. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 2 </volume> <pages> 159-225. </pages>
Reference: [Celeux and Govaert, 1995] <author> Celeux, G. and Govaert, G. </author> <year> (1995). </year> <title> Gaussian parsimonious clustering models. </title> <journal> Pattern Recognition, </journal> <volume> Vol. 28, No. 5, </volume> <pages> pages 781-793. </pages>
Reference: [Cheeseman and Stutz, 1995] <author> Cheeseman, P. and Stutz, J. </author> <year> (1995). </year> <title> Bayesian classification (AutoClass): Theory and results. </title> <editor> In Fayyad, U., Piatesky-Shapiro, G., Smyth, P., and Uthurusamy, R., editors, </editor> <booktitle> Advances in Knowledge Discovery and Data Mining, </booktitle> <pages> pages 153-180. </pages> <publisher> AAAI Press, </publisher> <address> Menlo Park, CA. </address>
Reference: [Chickering, 1996] <author> Chickering, D. </author> <year> (1996). </year> <title> Learning Bayesian networks is NP-complete. </title> <editor> In Fisher, D. and Lenz, H., editors, </editor> <booktitle> Learning from Data, </booktitle> <pages> pages 121-130. </pages> <publisher> Springer-Verlag. </publisher>
Reference: [Chickering and Heckerman, 1996] <author> Chickering, D. and Heckerman, D. </author> <year> (1996). </year> <title> Efficient approximations for the marginal likelihood of incomplete data given a Bayesian network. </title> <booktitle> In Proceedings of Twelfth Conference on Uncertainty in Artificial Intelligence, </booktitle> <address> Portland, OR, </address> <pages> pages 158-168. </pages> <publisher> Morgan Kaufmann. </publisher> <pages> 26 </pages>
Reference: [Chickering and Heckerman, 1997] <author> Chickering, D. and Heckerman, D. </author> <year> (1997). </year> <title> Efficient approximations for the marginal likelihood of Bayesian networks with hidden variables. </title> <journal> Machine Learning, </journal> <volume> 29 </volume> <pages> 181-212. </pages>
Reference: [Clogg, 1995] <author> Clogg, C. </author> <year> (1995). </year> <title> Latent class models. </title> <booktitle> In Handbook of statistical modeling for the social and behavioral sciences, </booktitle> <pages> pages 311-359. </pages> <publisher> Plenum Press, </publisher> <address> New York. </address>
Reference: [Cooper and Herskovits, 1992] <author> Cooper, G. and Herskovits, E. </author> <year> (1992). </year> <title> A Bayesian method for the induction of probabilistic networks from data. </title> <journal> Machine Learning, </journal> <volume> 9 </volume> <pages> 309-347. </pages>
Reference: [DeGroot, 1970] <author> DeGroot, M. </author> <year> (1970). </year> <title> Optimal Statistical Decisions. </title> <publisher> McGraw-Hill, </publisher> <address> New York. </address>
Reference: [Dempster et al., 1977] <author> Dempster, A., Laird, N., and Rubin, D. </author> <year> (1977). </year> <title> Maximum likelihood from incomplete data via the EM algorithm. </title> <journal> Journal of the Royal Statistical Society, </journal> <volume> B 39 </volume> <pages> 1-38. </pages>
Reference: [DiCiccio et al., 1995] <author> DiCiccio, T., Kass, R., Raftery, A., and Wasserman, L. </author> <month> (July, </month> <year> 1995). </year> <title> Computing Bayes factors by combining simulation and asymptotic approximations. </title> <type> Technical Report 630, </type> <institution> Department of Statistics, Carnegie Mellon University, </institution> <address> PA. </address>
Reference: [Friedman, 1997] <author> Friedman, N. </author> <year> (1997). </year> <title> Learning belief networks in the presence of missing values and hidden variables. </title> <booktitle> In Proceedings of the Fourteenth International Conference on Machine Learning. </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA. </address>
Reference: [Friedman, 1998] <author> Friedman, N. </author> <year> (1998). </year> <title> The Bayesian structural EM algorithm. </title> <booktitle> In Proceedings of the Fourteenth Conference on Uncertainty in Artificial Intelligence Learning. </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA. </address> <note> To appear. </note>
Reference: [Geiger and Heckerman, 1996] <author> Geiger, D. and Heckerman, D. </author> <year> (1996). </year> <title> Beyond Bayesian networks: Similarity networks and Bayesian multinets. </title> <journal> Artificial Intelligence, </journal> <volume> 82 </volume> <pages> 45-74. </pages>
Reference: [Geiger et al., 1996] <author> Geiger, D., Heckerman, D., and Meek, C. </author> <year> (1996). </year> <title> Asymptotic model selection for directed networks with hidden variables. </title> <booktitle> In Proceedings of Twelfth Conference on Uncertainty in Artificial Intelligence, </booktitle> <address> Portland, OR, </address> <pages> pages 283-290. </pages> <publisher> Morgan Kaufmann. </publisher>
Reference: [Good, 1952] <author> Good, I. </author> <year> (1952). </year> <title> Rational decisions. </title> <journal> J. R. Statist. Soc. B, </journal> <volume> 14 </volume> <pages> 107-114. </pages>
Reference: [Heckerman and Geiger, 1995] <author> Heckerman, D. and Geiger, D. </author> <year> (1995). </year> <title> Likelihoods and priors for Bayesian networks. </title> <type> Technical Report MSR-TR-95-54, </type> <institution> Microsoft Research, </institution> <address> Redmond, WA. </address>
Reference: [Heckerman et al., 1995] <author> Heckerman, D., Geiger, D., and Chickering, D. </author> <year> (1995). </year> <title> Learning Bayesian networks: The combination of knowledge and statistical data. </title> <journal> Machine Learning, </journal> <volume> 20 </volume> <pages> 197-243. </pages>
Reference: [Heckerman and Wellman, 1995] <author> Heckerman, D. and Wellman, M. </author> <year> (1995). </year> <title> Bayesian networks. </title> <journal> Communications of the ACM, </journal> <volume> 38 </volume> <pages> 27-30. </pages>
Reference: [Hinton et al., 1997] <author> Hinton, G., Dayan, P., and Revow, M. </author> <year> (1997). </year> <title> Modeling the manifolds of images of handwritten digits. </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> 8 </volume> <pages> 65-74. </pages>
Reference: [Howard and Matheson, 1981] <author> Howard, R. and Matheson, J. </author> <year> (1981). </year> <title> Influence diagrams. </title> <editor> In Howard, R. and Matheson, J., editors, </editor> <booktitle> Readings on the Principles and Applications of Decision Analysis, </booktitle> <volume> volume II, </volume> <pages> pages 721-762. </pages> <institution> Strategic Decisions Group, </institution> <address> Menlo Park, CA. </address>
Reference: [Hull, 1994] <author> Hull, J. </author> <year> (1994). </year> <title> A database for handwritten text recognition research. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 16 </volume> <pages> 550-554. </pages>
Reference: [Lauritzen, 1992] <author> Lauritzen, S. </author> <year> (1992). </year> <title> Propagation of probabilities, means, and variances in mixed graphical association models. </title> <journal> Journal of the American Statistical Association, </journal> <volume> 87 </volume> <pages> 1098-1108. 27 </pages>
Reference: [Meila et al., 1997] <author> Meila, M., Jordan, M., and Morris, Q. </author> <year> (1997). </year> <title> Estimating dependency structure as a hidden variable. </title> <type> Technical Report 1611, </type> <institution> Massachusetts Institute of Technology, Artificial Intelligence Laboratory. </institution>
Reference: [Pearl, 1982] <author> Pearl, J. </author> <year> (1982). </year> <title> Reverend Bayes on inference engines: A distributed hierarchical approach. </title> <booktitle> In Proceedings AAAI-82 Second National Conference on Artificial Intelligence, </booktitle> <address> Pittsburgh, PA, </address> <pages> pages 133-136. </pages> <publisher> AAAI Press, </publisher> <address> Menlo Park, CA. </address>
Reference: [Pearl and Verma, 1991] <author> Pearl, J. and Verma, T. </author> <year> (1991). </year> <title> A theory of inferred causation. </title> <editor> In Allen, J., Fikes, R., and Sandewall, E., editors, </editor> <booktitle> Proceedings of Second International Conference on Principles of Knowledge Representation and Reasoning, </booktitle> <pages> pages 441-452. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA. </address>
Reference: [Shachter and Kenley, 1989] <author> Shachter, R. and Kenley, C. </author> <year> (1989). </year> <title> Gaussian influence diagrams. </title> <journal> Management Science, </journal> <volume> 35 </volume> <pages> 527-550. </pages>
Reference: [Siebert, 1987] <author> Siebert, J. </author> <year> (1987). </year> <title> Vehicle recognition using rule-based methods. </title> <type> Technical Report TIRM-87-018, </type> <institution> Turing Institute. </institution>
Reference: [Singh, 1997] <author> Singh, M. </author> <year> (1997). </year> <title> Learning Bayesian networks from incomplete data. </title> <booktitle> In Proceedings AAAI-97 Fourteenth National Conference on Artificial Intelligence, </booktitle> <address> Providence, </address> <publisher> RI, </publisher> <pages> pages 534-539. </pages> <publisher> AAAI Press, </publisher> <address> Menlo Park, CA. </address>
Reference: [Spiegelhalter et al., 1993] <author> Spiegelhalter, D., Dawid, A., Lauritzen, S., and Cowell, R. </author> <year> (1993). </year> <title> Bayesian analysis in expert systems. </title> <journal> Statistical Science, </journal> <volume> 8 </volume> <pages> 219-282. </pages>
Reference: [Spirtes et al., 1993] <author> Spirtes, P., Glymour, C., and Scheines, R. </author> <year> (1993). </year> <title> Causation, Prediction, and Search. </title> <publisher> Springer-Verlag, </publisher> <address> New York. </address>
Reference: [Tierney and Kadane, 1986] <author> Tierney, L. and Kadane, J. </author> <year> (1986). </year> <title> Accurate approximations for posterior moments and marginal densities. </title> <journal> Journal of the American Statistical Association, </journal> <volume> 81 </volume> <pages> 82-86. </pages>
Reference: [Tipping and Bishop, 1997] <author> Tipping, M. and Bishop, C. </author> <year> (1997). </year> <title> Mixtures of probabilistic principle component analysers. </title> <type> Technical Report NCRG-97-003, </type> <institution> Neural Computing Research Group. </institution> <month> 28 </month>
References-found: 35

