URL: http://www.umiacs.umd.edu/users/westling/Papers/icpr96.ps.gz
Refering-URL: http://www.umiacs.umd.edu/users/westling/
Root-URL: 
Email: lsd@umiacs.umd.edu  
Title: Object Recognition by Fast Hypothesis Generation and Reasoning about Object Interactions  
Author: Mark Westling Larry S. Davis 
Address: 7525 Colshire Drive  McLean, Virginia 22102 USA  westling@concept5.com College Park, Maryland 20742 USA  
Affiliation: Concept Five Technologies, Inc. Computer Vision Laboratory  Center for Automation Research  University of Maryland  
Abstract: We present a novel, twostep approach for recognizing multiple 3-D objects in single 2-D images. In the first step, hypotheses of object instances are generated using a memory-based technique. This technique relies on an array, which is computed offline, that associates a large number of object poses with corresponding image features. During actual recognition, the array serves as a discrete approximation of the inverse projection function, and each image feature returns a set of poses that are accumulated by a Generalized Hough Transform. In the second step, the configuration of hypotheses that best interprets the image is calculated using a Bayesian network. The network represents both visual effects, such as the creation and occlusion of image features, and physical constraints, such as object interference. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> T. M. Breuel. </author> <title> View-based recognition. </title> <booktitle> IAPR Workshop on Machine Vision Applications, </booktitle> <year> 1992. </year>
Reference-contexts: Instead of using 3-D object models, view-based methods typically use appearance models that represent expected visible image features over a range of views. There are many strong arguments for the view-based approach, including ease of representing and acquiring complex models <ref> [1] </ref> and evidence that humans employ some kind of view-based approach [11]. Unlike the GHT, all matching is done in feature space, between the set of image features and 2-D transformations of each model view.
Reference: [2] <author> T. M. Breuel. </author> <title> Higher-order statistics in object recognition. </title> <booktitle> Proc. IEEE Conf. Computer Vision and Pattern Recognition, </booktitle> <year> 1993. </year>
Reference-contexts: This captures the notion that single, large occlusions are more likely to be found than many small, scattered occlusions <ref> [2] </ref>. <p> Object recognition programs typically define best in terms of degree of match, perhaps as a percentage of matched object features, although work has been done in considering spatial distribution of matches <ref> [2] </ref>. Thus, verification is performed in feature space. Transformation space, however, also provides much information that can be applied to verification, in terms of physical constraints. Here, the term physical constraint means a property of objects that must be maintained in any physically realizable scene.
Reference: [3] <author> T. A. Cass. </author> <title> Polynomial-time object recognition in the presence of clutter, occlusion, and uncertainty. </title> <booktitle> Proc. Image Understanding Workshop, </booktitle> <year> 1992. </year>
Reference-contexts: For an alternative approach to the tessellation problem, see <ref> [3] </ref>.) For this reason, the GHT is often used to generate only initial hypotheses as a first stage in an object recognition system. The second stage might be either verification and refinement, or a new search using the limited transformation space [4].
Reference: [4] <author> W. E. L. </author> <title> Grimson. Object Recognition by Computer: The Role of Geometric Constraints. </title> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: The second stage might be either verification and refinement, or a new search using the limited transformation space <ref> [4] </ref>. Alternative approaches to object recognition are view-based methods, which entail a search in feature space. Instead of using 3-D object models, view-based methods typically use appearance models that represent expected visible image features over a range of views. <p> An extra source of false positives is that for speed, the GHT is applied only once: the more traditional method for recognizing objects in cluttered environments is to apply the GHT once, find the best hypothesis, remove the matching features, apply the GHT again, and so on <ref> [4] </ref>. The goal of the second part of the system is to eliminate these false positives and return the set of hypotheses that best interprets the scene.
Reference: [5] <author> V. F. Leavers. </author> <title> Which Hough transform? CVGIP: </title> <booktitle> Image Understanding 58(2), </booktitle> <year> 1993. </year>
Reference-contexts: Intuitively, if the pose of an object falls between adjacent sampled poses, then the buckets corresponding to the poses will have values roughly proportional to the distance from the true pose. (A survey of approaches to this problem can be found in <ref> [5] </ref>.) Since improvements in pose estimation accuracy are tightly coupled with resolution of transformation and feature spaces, a simple method has been adopted for interpolating pose parameters in the neighborhood of a peak. Each parameter is treated independently and is assumed to be symmetric around the peak.
Reference: [6] <author> W. B. Mann and T. O. Binford. </author> <title> An example of 3d interpretation of images using Bayesian networks. </title> <booktitle> Proc. Image Understanding Workshop, </booktitle> <year> 1992. </year>
Reference-contexts: To handle constraint uncertainty, a Bayesian network is constructed to represent physical relationships between hypotheses. (For another example of the use of Bayesian networks in object recognition, see <ref> [6] </ref>.) The Bayesian network also provides a framework for representing visual interactions between objects. Not only can it capture the direct causality between object features and image features, but it can also explain features that are incomplete and missing due to partial occlusion.
Reference: [7] <author> R. C. Nelson. </author> <title> 3-D recognition via 2-stage associative memory. </title> <institution> TR-565, Dept. of Computer Science, University of Rochester, </institution> <year> 1995. </year>
Reference-contexts: By limiting the degrees of freedom, and by approximating the locations and properties of image features to some resolution, the entire range of views can be stored effectively. (Other examples of such a memory-based approach to 3-D object recognition are described in <ref> [7] </ref> and [10].) These two approaches to 3-D object recognitionthe generalized Hough transform and view-based recogni-tioncan be combined to produce a system that quickly recognizes complex configurations of objects in many practical environments.
Reference: [8] <author> J. Pearl. </author> <title> Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1988. </year>
Reference-contexts: The next step is to created other nodes that represent physical and visual constraints, and to link these nodes together. One can represent physical constraints between a pair of hypotheses in a Bayesian network in two ways <ref> [8] </ref>. One way is to create a single node that represents combinations of both hypotheses, and simply not allow it to have the a value representing the presence of both hypotheses.
Reference: [9] <author> T. Poggio and D. Beymer. </author> <title> Learning networks for face analysis and synthesis. </title> <booktitle> Proc. International Workshop on Automatic Face and Gesture Recognition, </booktitle> <address> Zurich, </address> <month> June, </month> <year> 1995. </year>
Reference-contexts: To build an FP map, synthetic images are generated for each pose in the transformation space by a ray tracer or some other rendering program. A similar strategy is used in <ref> [9] </ref>, where virtual examples are synthesized to enrich a training set. Since each input image has an associated precise pose, and the number of images for a single model numbers in the tens of thousands, acquisition using real images is impractical.
Reference: [10] <author> T. Poggio and A. Hurlbert. </author> <title> Observations on cortical mechanisms for object recognition and learning. </title> <journal> A.I. </journal> <volume> Memo No. 1404, </volume> <publisher> MIT, </publisher> <year> 1993. </year>
Reference-contexts: By limiting the degrees of freedom, and by approximating the locations and properties of image features to some resolution, the entire range of views can be stored effectively. (Other examples of such a memory-based approach to 3-D object recognition are described in [7] and <ref> [10] </ref>.) These two approaches to 3-D object recognitionthe generalized Hough transform and view-based recogni-tioncan be combined to produce a system that quickly recognizes complex configurations of objects in many practical environments.
Reference: [11] <author> S. Ullman. </author> <title> Aligning pictorial descriptions: an approach to object recognition. </title> <journal> Cognition 32, </journal> <year> 1989. </year>
Reference-contexts: There are many strong arguments for the view-based approach, including ease of representing and acquiring complex models [1] and evidence that humans employ some kind of view-based approach <ref> [11] </ref>. Unlike the GHT, all matching is done in feature space, between the set of image features and 2-D transformations of each model view. Basic problems are determining how many views should be stored for each object model and the cost of matching each view to the image.
References-found: 11

