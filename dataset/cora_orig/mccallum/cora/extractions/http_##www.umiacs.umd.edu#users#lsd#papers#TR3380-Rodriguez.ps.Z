URL: http://www.umiacs.umd.edu/users/lsd/papers/TR3380-Rodriguez.ps.Z
Refering-URL: http://www.umiacs.umd.edu/users/lsd/pubs.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: An Appearance-Based Approach to Object Recognition in Aerial Images  
Author: Claudia E. Rodriguez David Harwood Larry S. Davis 
Address: College Park, MD 20742-3275  
Affiliation: Computer Vision Laboratory Center for Automation Research University of Maryland  
Date: December 1994  
Pubnum: CAR-TR-746 DACA76-92-C-0024  
Abstract: This report explores the design of "appearance-based" object recognition systems and their application to the analysis of aerial imagery. Our system, in contrast with the more prevalent model-based vision systems, in which explicit three dimensional models of objects and physics-based reasoning about the image formation process are combined, models objects in terms of how they appear to a computer vision system (i.e., what their structure is in possible segmentations of images) and identifies objects using combinatorial search constrained by the system's knowledge of and experience with finding the objects in previous supervised and unsupervised situations. As in other recognition systems, the "appearance-based" object recognition system that we have designed includes a low-level vision element, in which the image is preprocessed and segmented into components. The segmentation produced is a hierarchical one, with the hierarchy based on border contrast. The high-level vision phase uses the hierarchy and the "appearance-based" models of objects to heuristically combine components from various levels of the hierarchy into possible instances of objects. These are further analyzed by shape delineation processes and a final verification The support of the Advanced Research Projects Agency (ARPA Order No. 8979) and the U.S. Army Topographic Engineering Center under Contract DACA76-92-C-0024 is gratefully acknowledged, as is the help of Sandy German in preparing this paper. selects the combinations that correspond to locally best instances of objects.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> N. Ayache and O. Faugeras, </author> <title> "HYPER: A New Approach for the Recognition and Positioning of Two-Dimensional Objects," </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> Vol. PAMI-8, </volume> <pages> pp. 44-54, </pages> <month> January </month> <year> 1986. </year>
Reference-contexts: Object instances are searched for in the hierarchy under the control of a logic program. The representational primitives in recognition systems are not restricted to regions. The use of edges is also common. Ayache and Faugeras <ref> [1] </ref> present a hypothesis-prediction-verification approach. They incorporate bottom-up (scene-driven) and top-down (model-driven) approaches to take advantage of the system's knowledge of the objects. Shapes of 2D objects are represented by polygonal approximation of their borders. The model description includes a number of privileged segments.
Reference: [2] <author> C. Brice and C. Fennema, </author> <title> "Scene Analysis Using Regions," </title> <journal> Artificial Intelligence, </journal> <volume> Vol. 1, </volume> <pages> pp. 205-226, </pages> <year> 1970. </year>
Reference-contexts: For example, in Brice and Fennema <ref> [2] </ref>, the image is initially partitioned into homogeneous connected components. New partitions of the image are obtained through contrast-based heuristics that guide the merging of regions. The partition obtained after exhaustively applying the heuristics is used for scene analysis. Their object recognition procedure is based on lines.
Reference: [3] <author> J. Burns and L. Kitchen, </author> <title> "Rapid Object Recognition from a Large Model Base Using Prediction Hierarchies," </title> <booktitle> in Proceedings of the DARPA Image Understanding Workshop, </booktitle> <pages> pp. 711-719, </pages> <year> 1988. </year> <title> (a) Results of the combinatorial search and polygonal approximation (b) Results of the second search (c) Final result 51 (a) Rejected tank 1 (b) Shape approximation result Second search result (d) Rejected tank 2 (e) Rejected tank 3 52 </title>
Reference-contexts: The best hypotheses are evaluated and the hypothesis with the highest quality score is reexamined before being validated or rejected. Burns and Kitchen <ref> [3] </ref> address the problem of large model bases in a system designed for polyhedral objects. They precompute descriptions of objects as predictions of how the objects will look, so that 3D recognition is reduced to 2D "appearance" matching. <p> The hierarchy also results in economy in matching. Projections with similarities explicitly share the representation of their common aspects. Matching takes place from most general predictions (shared by many objects) to object view specific predictions. The matching procedure was still under development at the time of publication of <ref> [3] </ref>. Jain and Hoffman [14] define an evidence-based recognition technique which identifies 3D objects by searching for notable features of objects. Their system consists of five stages: acquisition, preprocessing, segmentation, classification and merging.
Reference: [4] <author> R.C.L.D.C.L. Lin, Q. Zheng and X. Zhang, </author> <title> "Site Model Supported Monitoring of Aerial Images," </title> <booktitle> in Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pp. 694-699, </pages> <year> 1994. </year>
Reference: [5] <author> D. Clemens, </author> <title> Region-Based Feature Interpretation for Recognizing 3D Models in 2D Images, </title> <type> Ph.D. dissertation, </type> <institution> Massachusetts Institute of Technology, </institution> <year> 1991. </year>
Reference-contexts: The complexity of doing search in this space is exponential <ref> [5] </ref>. Search does not have to be conducted in a blind way. There are various ways to constrain the search, and thereby generate only those matches with greater potential for being acceptable. The goal of much model-based vision research has been to explore ways of constraining the match search. <p> Clemens <ref> [5] </ref> demonstrates the general utility of match-independent constraints. These constraints come from general knowledge about the kinds of objects in the world. One module is a region-based grouping mechanism that reduces the combinatorics of choosing 10 subsets of features.
Reference: [6] <author> E.C. Freuder, </author> <title> "Affinity: A Relative Approach to Region Finding," </title> <journal> Computer Graphics and Image Processing, </journal> <volume> Vol. 5, </volume> <pages> pp. 254-264, </pages> <month> June </month> <year> 1976. </year>
Reference-contexts: New partitions of the image are obtained through contrast-based heuristics that guide the merging of regions. The partition obtained after exhaustively applying the heuristics is used for scene analysis. Their object recognition procedure is based on lines. Little knowledge about the scene is included. Freuder <ref> [6] </ref> describes a region growing process in which region segments are repeatedly merged with their most similar neighbors. The result is a tree of regions which provides regions of interest for further higher level, semantic or global use. The criteria is to merge a region with its most similar neighbor.
Reference: [7] <author> W. </author> <title> Grimson, "The Combinatorics of Object Recognition in Cluttered Environments Using Constrained Search," </title> <booktitle> in International Conference on Computer Vision, </booktitle> <pages> pp. 218-227, </pages> <year> 1988. </year>
Reference-contexts: They analyze both the case of isolated objects and that of cluttered scenes, for which they use clustering techniques to isolate likely subspaces of the search space. The objects are modeled as polygons, and each feature is a linear segment Grimson <ref> [7] </ref> also indicates the importance of constrained search in object recognition and suggests the importance of grouping, since by identifying groups of sensory fragments that are likely to have come from a single object, without the exponential cost of identifying such groups, it is likely that the expected cost of the
Reference: [8] <author> W. Grimson and T. Lozano-Perez, </author> <title> "Model-based Recognition and Localization from Sparse Range or Tactile Data," </title> <journal> International Journal of Robotics Research, </journal> <volume> Vol. 3, No. 3, </volume> <pages> pp. 3-35, </pages> <year> 1984. </year>
Reference-contexts: There are various ways to constrain the search, and thereby generate only those matches with greater potential for being acceptable. The goal of much model-based vision research has been to explore ways of constraining the match search. Grimson and Lozano-Perez <ref> [8, 9] </ref> were among the first to propose a constrained search scheme. In their system, the objects are modeled as polygons, and each feature is a linear segment.
Reference: [9] <author> W. Grimson and T. Lozano-Perez, </author> <title> "Localizing Overlapping Parts by Searching the Interpretation Tree," </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> Vol. PAMI-9, </volume> <pages> pp. 469-482, </pages> <month> July </month> <year> 1987. </year>
Reference-contexts: There are various ways to constrain the search, and thereby generate only those matches with greater potential for being acceptable. The goal of much model-based vision research has been to explore ways of constraining the match search. Grimson and Lozano-Perez <ref> [8, 9] </ref> were among the first to propose a constrained search scheme. In their system, the objects are modeled as polygons, and each feature is a linear segment.
Reference: [10] <author> D. Harwood, R. Prasannappa, and L. Davis, </author> <title> "Preliminary Design of a Programmed Picture Logic," </title> <booktitle> in Proceedings of the DARPA Image Understanding Workshop, </booktitle> <pages> pp. 745-755, </pages> <year> 1989. </year>
Reference-contexts: He utilizes a hierarchical representation of the objects. An expert exists for each model object and is responsible for the instantiation of its object type and sub-components through a cycle of hypothesis generation, evaluation and refinement. Model matching and quadtree split-and-merge are alternated. Harwood et al. <ref> [10] </ref> describe a modular logic-programming system called Programmed Picture Logic (PPL) for two-dimensional interpretation of images. From an initial set of regions, they construct a hierarchy of regions, but as opposed to ours, it is restricted to few levels.
Reference: [11] <author> A. Huertas, C. Lin, and R. Nevatia, </author> <title> "Detection of Buildings From Monocular Views of Aerial Scenes Using Perceptual Grouping and Shadows," </title> <booktitle> in Proceedings of the DARPA Image Understanding Worklshop, </booktitle> <pages> pp. 253-260, </pages> <year> 1993. </year>
Reference-contexts: Difficulties arise from high fragmentation of detected line segments. The authors utilize the knowledge of the expected building shapes and use shadows to confirm hypotheses, but they have difficulties with poor contrast, small buildings, and dense clusters of buildings which cast shadows on each other. Huertas and Nevatia <ref> [11] </ref> introduce the concept of perceptual grouping in monocular images. The idea is to collect fragments obtained from the low-level segmentation processes and discard those that come from other sources.
Reference: [12] <author> A. Huertas and R. Nevatia, </author> <title> "Detecting Buildings in Aerial Images," Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> Vol. 41, </volume> <pages> pp. 131-152, </pages> <year> 1988. </year>
Reference-contexts: The model parameters are ranges of values and object attributes are compared with each model attribute to classify regions into goal objects. Huertas and Nevatia <ref> [12] </ref> use generic models of the shapes of the structures of interest, together with shadows, to confirm their presence and estimate their heights. They use line segments as image primitives. A building is modeled as the union of one or more rectangular parallelepipeds in 3D.
Reference: [13] <author> R. Irvin and D. McKeown, </author> <title> "Methods for Exploiting the Relationship Between Buildings and Their Shadows in Aerial Imagery," </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> Vol. 19, </volume> <pages> pp. 1564-1575, </pages> <month> November </month> <year> 1989. </year> <month> 53 </month>
Reference-contexts: This approach leads to fewer hypotheses compared to the use of contour tracing. After all reasonable rectangles are formed, a selection process is applied to choose rectangles having strong evidence of support and minimum conflict. Local and global selection criteria are used. Irvin and McKeown <ref> [13] </ref> describe a set of techniques for performing shadow analysis on high resolution aerial imagery. Each technique exploits the relationship between manmade structures and cast shadows to perform structure shape prediction, structure grouping, structure verification, and height estimation.
Reference: [14] <author> A. Jain and R. Hoffman, </author> <title> "Evidence-Based Recognition of 3-D Objects," </title> <journal> IEEE Trans--actions on Pattern Analysis and Machine Intelligence, </journal> <volume> Vol. 10, </volume> <pages> pp. 783-802, </pages> <month> November </month> <year> 1988. </year>
Reference-contexts: Projections with similarities explicitly share the representation of their common aspects. Matching takes place from most general predictions (shared by many objects) to object view specific predictions. The matching procedure was still under development at the time of publication of [3]. Jain and Hoffman <ref> [14] </ref> define an evidence-based recognition technique which identifies 3D objects by searching for notable features of objects. Their system consists of five stages: acquisition, preprocessing, segmentation, classification and merging. The image features are surface patches which ideally correspond to natural object faces; they are classified as planar, convex or concave.
Reference: [15] <author> N. Khan and R. Ramesh, </author> <title> "Matching an Imprecise Object Description with Models in a Knowledge Base," </title> <booktitle> in Proceedings of the International Conference on Pattern Recognition, </booktitle> <pages> pp. 1131-1134, </pages> <year> 1984. </year>
Reference-contexts: Three different sources of interpretations were considered: manual interaction, geometric models, and relational constraints. Considering the constraints, regions are selected to be merged with adjacent regions in the order of lowest average absolute contrast along their common boundary. Khan and Ramesh <ref> [15] </ref> consider a matching scheme in their approach to object recognition using multiple knowledge sources. They assume that the image has been segmented into 5 regions, based on domain-specific and domain-independent properties (geometric structure, spectral properties of surfaces, motion, functionality, etc.).
Reference: [16] <author> Y. Kuno, Y. Okamoto, and S. Okada, </author> <title> "Object Recognition Using a Feature Search Strategy Generated from a 3-D Model," </title> <booktitle> in Proceedings of the International Conference on Computer Vision, </booktitle> <pages> pp. 626-635, </pages> <year> 1990. </year>
Reference-contexts: A different representation is suggested by Whitten [24], who introduces the concept of vertex space. He proposes the use of vertices as primitives to characterize polyhedral 7 structures. Kuno et al. <ref> [16] </ref> describe a vision system which automatically generates an object recognition strategy from a 3D model and recognizes the object using this strategy. The appearances of an object are described with visible 2D features. The system ranks them according to the number of viewpoints from which they are visible.
Reference: [17] <author> A. Rosenfeld and A. Kak, </author> <title> Digital Picture Processing, </title> <address> New York: </address> <publisher> Academic Press, </publisher> <year> 1982. </year>
Reference-contexts: Let i and j be two adjacent regions. The crack-border between i and j is the set of pairs of pixels (P; Q) such that P is in i, Q is in j and P ,Q are 4-adjacent. The pair (P; Q) is called a crack <ref> [17] </ref>. The data structure to represent it is called a boundary unit and consists of the coordinates of P and Q. A list of boundary units forms the boundary. A juncture is the point at which at least three contours intersect.
Reference: [18] <author> J. Shufelt and D. McKeown, </author> <title> "Fusion of Monocular Cues to Detect Man-Made Structures in Aerial Imagery," Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> Vol. 57, </volume> <pages> pp. 307-330, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: Irvin and McKeown [13] describe a set of techniques for performing shadow analysis on high resolution aerial imagery. Each technique exploits the relationship between manmade structures and cast shadows to perform structure shape prediction, structure grouping, structure verification, and height estimation. Shufelt and McKeown <ref> [18] </ref> report a rather simple and effective method for fusing sets of monocular building hypotheses in aerial imagery. They apply the fusion technique to the symbolic data generated by four monocular building extraction systems in monocular and stereo image data sets.
Reference: [19] <author> C. Smyrniotis and K. Dutta, </author> <title> "A Knowledge-Based System for Recognizing Man-Made Objects in Aerial Images," </title> <booktitle> in Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pp. 111-117, </pages> <year> 1988. </year>
Reference-contexts: At later stages, it assigns priorities to features depending on their relations to the analyized ones. 2.2 Aerial image analysis In the aerial imagery domain, several systems have been developed to extract man-made features and objects, such as buildings and transportation networks. In this area, Smyrniotis and Dutta <ref> [19] </ref> describe a knowledge-based vision system for recognizing and classifying man-made objects in aerial images. It is a goal driven approach to image interpretation: analyze the image with the purpose of identifying requested object types.
Reference: [20] <author> J. Tenenbaum and H. Barrow, </author> <title> "Experiments on Interpretation-Guided Segmentation," </title> <journal> Artificial Intelligence, </journal> <volume> Vol. 8, </volume> <pages> pp. 241-274, </pages> <year> 1977. </year>
Reference-contexts: The neighbor with the minimum value gets merged first; the last term favors the merging of the smallest neighbors first. Our hierarchy of regions uses a different type of function in the merging decision and it only merges the regions with the minimum function value. Tenenbaum and Barrow <ref> [20] </ref> integrate knowledge from a variety of sources to make inferences about the interpretation of regions. An initial partition is formed by grouping adjacent pixels of identical brightness. Three different sources of interpretations were considered: manual interaction, geometric models, and relational constraints.
Reference: [21] <author> L. Tucker, </author> <title> "Model-Guided Segmentation Using Quadtrees," </title> <booktitle> in Proceedings of the International Conference on Pattern Recognition, </booktitle> <pages> pp. 216-219, </pages> <year> 1984. </year>
Reference-contexts: Every possible combination between input components and components in the knowledge base is attempted. The best match is validated at a later stage. Later representation strategies are more involved. For example, Tucker <ref> [21] </ref> presents a hierarchical search strategy to perform image segmentation by successive refinement of a quadtree. He utilizes a hierarchical representation of the objects.
Reference: [22] <author> V. Venkateswar and R. Chellappa, </author> <title> "A Hierarchical Approach to Detection of Buildings in Aerial Images," </title> <type> Technical Report CAR-TR-567, </type> <institution> Center for Automation Research, University of Maryland, </institution> <month> August </month> <year> 1991. </year>
Reference-contexts: They apply the fusion technique to the symbolic data generated by four monocular building extraction systems in monocular and stereo image data sets. Analysis of the fusion results reveals shortcomings in each of the building detection systems. Venkateswar and Chellappa <ref> [22] </ref> use a hierarchical approach to building detection which involves grouping pairs of line segments to form vertices which are grouped to form edges which in turn are composed into edge-rings.
Reference: [23] <author> T.L.T. Westman, D. Harwood and M. Pietikaiinen, </author> <title> "Color Segmentation by Hierarchical Connected Components Analysis with Image Enhancement by Symmetric Neighborhood Filters," </title> <booktitle> in Proceedings of the International Conference on Pattern Recognition, </booktitle> <pages> pp. 796-802, </pages> <year> 1990. </year>
Reference-contexts: The diagram in Figure 4 shows the main components of our system. 11 3.1 Segmentation The gray level input image is preprocessed using a recursive enhancement operator called the Symmetric Neighborhood Filter (SNF) <ref> [23] </ref>, which consists of local averaging filters that preserve edges. The resulting image is segmented by our hierarchical connected component algorithm based on boundary intensity contrast. The coarseness of the segmentation is established through an intensity contrast threshold, ".
Reference: [24] <author> G. Whitten, </author> <title> "Vertex Analysis and Its Application to Model Based Object Recognition," </title> <booktitle> in Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pp. 847-857, </pages> <year> 1988. </year> <month> 55 </month>
Reference-contexts: Finally, they extend the work with a technique for automatically creating the evidence rulebase form training images of objects. A different representation is suggested by Whitten <ref> [24] </ref>, who introduces the concept of vertex space. He proposes the use of vertices as primitives to characterize polyhedral 7 structures. Kuno et al. [16] describe a vision system which automatically generates an object recognition strategy from a 3D model and recognizes the object using this strategy.
References-found: 24

