URL: ftp://ftp.cse.ucsc.edu/pub/tr/ucsc-crl-95-06.ps.Z
Refering-URL: http://www.ai.univie.ac.at/~juffi/lig/lig-bib.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: General Game-Playing and Reinforcement Learning  
Author: Robert Levinson 
Keyword: games, mathematical structure, heuristic search, machine learning, hypergraphs, neural networks, analogical reasoning, RETE, relational patterns, hierarchical reinforcement learning  
Address: Santa Cruz, CA 95060  
Affiliation: Department of Computer Science, University of California,  
Note: supersedes UCSC-CRL-93-38 and UCSC-CRL-94-32 partially supported by NSF Grant IRI-9112862  
Pubnum: UCSC-CRL-95-06  
Email: E-mail:levinson@cse.ucsc.edu  
Phone: Phone: 408-459-2087  
Date: May 5, 1995  
Abstract: This paper gives a blueprint for the development of a fully domain-independent single-agent and multi-agent heuristic search system. It gives a graph-theoretic representation of search problems based on conceptual graphs, and outlines two different learning systems. One, an "informed learner," makes use of the the graph-theoretic definition of a search problem or game in playing and adapting to a game in the given environment. The other, a "blind learner," is not given access to the rules of a domain, but must discover and then exploit the underlying mathematical structure of a given domain. Relevant work of others is referenced within the context of the blueprint. To illustrate further how one might go about creating general game-playing agents, we show how we can generalize the understanding obtained with the Morph chess system to all games involving the interactions of abstract mathematical relations. An example of a monitor for such domains is presented, along with an implementation of a blind and informed learning system known as MorphII. Performance results with MorphII are preliminary but encouraging and provide a few more data points with which to understand and evaluate the blueprint. 
Abstract-found: 1
Intro-found: 1
Reference: <institution> References </institution>
Reference: [All92] <editor> V. Allis. Qubic solved again. In J.V.D. Herik and L.V. Allis, editors, </editor> <booktitle> Heuristic Programming in Artificial Intelligence 3, </booktitle> <pages> pages 192-204. </pages> <publisher> Ellis Horwood, </publisher> <year> 1992. </year>
Reference-contexts: But some researchers expect that to change once the mathematics behind planning is understood and a wider variety of games such as those with imperfect information are considered [SN93]. A number of individual games have succumbed to mathematical and computer-aided analysis <ref> [BCG82, All92, Vaj92] </ref>. We believe that through a general graph-theoretic approach this type of analysis can be extended to much wider classes of games and problems. For example, mathematical techniques have recently been applied successfully to previously considered intractable Go endgames [BW94]. <p> If the object is to use as few moves as possible, a primitive condition is set that is unaltered by the rules and decrements the player's score by 1 (through the reward operators) each time it occurs. * Tic-tac-toe-like games (such as Qubic <ref> [All92] </ref>, Renju and GoMoku) in which objects are placed and never moved, have operators with one pre-condition, one post-condition and all terminal hyperedges also produce positive rewards. * Hex is a game played on a grid of hexagons. <p> For example, 3x3 tic-tac-toe has a graph of nine nodes and 8 hyperedges. 3x3x3 has 27 nodes and 48 hyperedges. 4x4x4x4 (Qubic) has 64 nodes and 84 hyperedges. The discussion here builds directly on previous work on forks [Eps90], GoMoku and Qubic <ref> [All92] </ref>, hopefully putting that work in proper perspective. The hypergraph representation makes symmetries fully realizable through graph iso-morphism. This mathematical representation also lends itself to reasonable heuristics.
Reference: [Bau93] <author> E.B. Baum. </author> <title> How a bayesian approaches games like chess. In Games: Planning and Learning, </title> <booktitle> Proceedings of the AAAI Fall Symposium, </booktitle> <address> Menlo Park, CA, </address> <month> October </month> <year> 1993. </year> <note> AAAI Press. </note>
Reference-contexts: Percentage of wins is shown. 10 Conclusion Eric Baum recently pointed out <ref> [Bau93] </ref> the inherent potential in of information (math ematical structure) inherent in a declaration of the rules of a given domain: The computer science approach has since Shannon basically regarded a game as defined by its game tree.
Reference: [BCG82] <author> E.R. Berlekamp, J.H. Conway, and R.K. Guy. </author> <title> Winning Ways for Your Mathematical Plays. </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1982. </year>
Reference-contexts: But some researchers expect that to change once the mathematics behind planning is understood and a wider variety of games such as those with imperfect information are considered [SN93]. A number of individual games have succumbed to mathematical and computer-aided analysis <ref> [BCG82, All92, Vaj92] </ref>. We believe that through a general graph-theoretic approach this type of analysis can be extended to much wider classes of games and problems. For example, mathematical techniques have recently been applied successfully to previously considered intractable Go endgames [BW94].
Reference: [Bea80] <author> D.F. Beal. </author> <title> An analysis of minimax. </title> <editor> In M.R.B. Clarke, editor, </editor> <booktitle> Advances in Computer Chess 2, </booktitle> <pages> pages 103-109. </pages> <publisher> Edinburgh University Press, Edinburgh, </publisher> <address> Scotland, </address> <year> 1980. </year>
Reference: [Ber79] <author> Hans Berliner. </author> <title> The B* tree search algorithm: A best first proof procedure. </title> <journal> Artificial Intelligence, </journal> <volume> 12(1) </volume> <pages> 23-40, </pages> <year> 1979. </year>
Reference: [Bet81] <author> A. D. Bethke. </author> <title> Genetic Algorithms as Function Optimizers. </title> <type> PhD thesis, </type> <institution> University of Michigan, DAI 41(9), 3503B, </institution> <year> 1981. </year>
Reference-contexts: Reinforcement learning in general is becoming increasingly popular [Sut91] because it can minimize the need for human assistance. Neural networks [RM86] and genetic algorithms <ref> [Bet81, BGH89, Gol89, Hol75] </ref> can be viewed as blind-learners. These systems attempt to learn functions given pre-classified input-output pairs. To the extent that the supplied classifications can also be generated automatically (with temporal-difference learning [Sut88], for example) the learned functions coupled with search would produce a general game-playing system.
Reference: [BGH89] <author> L.B. Booker, D.E. Goldberg, and J.H. Holland. </author> <title> Classifier systems and genetic algorithms. </title> <journal> Artificial Intelligence, </journal> <volume> 40 </volume> <pages> 235-282, </pages> <year> 1989. </year>
Reference-contexts: Reinforcement learning in general is becoming increasingly popular [Sut91] because it can minimize the need for human assistance. Neural networks [RM86] and genetic algorithms <ref> [Bet81, BGH89, Gol89, Hol75] </ref> can be viewed as blind-learners. These systems attempt to learn functions given pre-classified input-output pairs. To the extent that the supplied classifications can also be generated automatically (with temporal-difference learning [Sut88], for example) the learned functions coupled with search would produce a general game-playing system.
Reference: [BS94] <author> D. Beal and M. C. Smith. </author> <title> Random evaluations in chess. </title> <journal> International Computer Chess Association Journal, </journal> <volume> 17(1) </volume> <pages> 3-9, </pages> <month> March </month> <year> 1994. </year>
Reference-contexts: In this case statistical and mathematical models of the game and the opponent increase in importance. Recently, Beal <ref> [BS94] </ref> showed experimentally the interesting result that for certain games such as chess, even random evaluations when coupled with minimax can lead to improved play with increasing search-depth, because maximizing and minimizing favors nodes with large branching factors and hence roughly corresponds to a mobility coefficient.
Reference: [BW94] <author> E. Berlekamp and D. Wolfe. </author> <title> Mathematical GO Endgames: Nightmares for the Professional Go Player. A.K. </title> <type> Peters, Wellesley, </type> <institution> Massachusetts, </institution> <year> 1994. </year>
Reference-contexts: We believe that through a general graph-theoretic approach this type of analysis can be extended to much wider classes of games and problems. For example, mathematical techniques have recently been applied successfully to previously considered intractable Go endgames <ref> [BW94] </ref>. Reinforcement learning has already proved to be highly successful in learning the evaluation functions for specific games such as checkers [Sam59], Othello [LM88] and backgammon [TS89]. The latter two programs developed to world-class players in their respective domains.
Reference: [EL92] <author> Gerard Ellis and Robert Levinson, </author> <title> editors. </title> <booktitle> Proceedings of the First International Workshop on PEIRCE: A Conceptual Graphs Workbench. </booktitle> <institution> Department of Computer Science, The University of Queensland, </institution> <year> 1992. </year>
Reference-contexts: Such a facility is available in conceptual graph theory and will be available shortly in the Peirce conceptual graphs workbench <ref> [EL92, Gai93] </ref> in which our learning system is implemented. An important step in showing the generality of the graph-theoretic representation is to show that games generated from the MetaGame generator can fit this structure. <p> the rules, would find it virtually impossible to recognize the interaction, unless it were inferable indirectly from other patterns. 9 MorphII: Domain-Independent Games Environment in C++ The blind and informed learning testbeds described above are available as part of the public domain software known as the Peirce Conceptual Graphs Workbench <ref> [EL92] </ref>. The learning system in Peirce, known as MorphII, accepts the rules of a single-agent or a multi-agent state-space search domain, translates them into conceptual graphs, and then monitors 9.
Reference: [EN69] <author> G. W. Ernst and A. Newell. </author> <title> GPS: A Case Study in Generality and Problem-Solving. </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1969. </year>
Reference-contexts: Single-agent problems have, of course, also been approached through search with such algorithms as A* [Nil80], best-first-search [RK91], and means-ends-analysis <ref> [EN69] </ref>. To discuss single agent search in depth is beyond the scope of this paper.
Reference: [Eps90] <author> S.L. Epstein. </author> <title> Learning plans for competitive domains. </title> <booktitle> In Proceedings of the 7th International Conference on Machine Learning, </booktitle> <pages> pages 190-197, </pages> <address> Austin, TX., 1990. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: For example, 3x3 tic-tac-toe has a graph of nine nodes and 8 hyperedges. 3x3x3 has 27 nodes and 48 hyperedges. 4x4x4x4 (Qubic) has 64 nodes and 84 hyperedges. The discussion here builds directly on previous work on forks <ref> [Eps90] </ref>, GoMoku and Qubic [All92], hopefully putting that work in proper perspective. The hypergraph representation makes symmetries fully realizable through graph iso-morphism. This mathematical representation also lends itself to reasonable heuristics. <p> For example, the quality of a node choice is proportional to the number of "live edges" it is involved in and inversely proportional to the number of nodes remaining in each of those edges. Through the use of subgraph analysis more precise heuristics can be developed <ref> [Eps90] </ref>. 4.1 Reductions in the Basic Tic-tac-toe Hypergraph Game It is useful to become familiar with reductions that preserve game-theoretic value in basic hypergraph games, since such reductions may very well not have been apparent from the traditional state representation.
Reference: [Eps92] <author> S.L. Epstein. </author> <title> Prior knowledge strengthens learning to control search in weak theory domains. </title> <journal> International Journal of Intelligent Systems, </journal> <volume> 7 </volume> <pages> 547-586, </pages> <year> 1992. </year>
Reference-contexts: These heuristics are, however, confined to these chess-like games and do not generally deal with the mathematics of state-space search itself, although it would seem that generalizing them to this larger class of games is possible. Hoyle <ref> [Eps92] </ref> is another domain-independent game-playing and learning system that deals at the abstract operator level. It carries with it a rich set of advisors that embody human-supplied heuristics.
Reference: [FD89] <author> N. S. Flann and T. G. Dietterich. </author> <title> A study of explanation-based methods for inductive learning. </title> <journal> Machine Learning, </journal> <volume> 4 </volume> <pages> 187-226, </pages> <year> 1989. </year>
Reference-contexts: The limitations of the search approaches have suggested the use of abstract and hierarchical planning algorithms that attempt to view a game state as a collection of subproblems to be solved <ref> [Wil80, Pit76, Min84, LNR87, FD89] </ref>. To date, these approaches have not proved powerful or general enough to be serious practical competitors to brute-force search. <p> Many other learning approaches may prove equally viable such as: neural networks [RM86], genetic algorithms [Hol75], constraint satisfaction [RK91], inductive logic programming, and explanation-based generalization <ref> [FD89, KM90, RN94] </ref>. Most of these methods, however, must be extended to the general case of all single and double-agent search problems, just as MorphII generalizes Morph. 5 Review of Original Morph Model Morph is an application of our APS (Adaptive-Predictive Search) method for improving search with experience.
Reference: [For82] <author> C.L. Forgy. </author> <title> Rete: A fast algorithm for the many pattern/many object patern match problem. </title> <journal> Artificial Intelligence, </journal> <volume> 19(1) </volume> <pages> 17-37, </pages> <year> 1982. </year>
Reference-contexts: The "Universal" in UDS refers to an effective monitor and executor of the specifications for any given state space search domain. Due to the relation-based perspective of UDS, the following ideas from the RETE algorithm <ref> [For82, Mir87] </ref> can be exploited with little adjustment to the relational hierarchy defined above. * The firing of an individual operator does not affect the current state radically. * If an operator did not match in the previous cycle, it most likely will not match in the current cycle either. *
Reference: [Gai93] <author> B. R. Gaines. </author> <title> Representation, discourse, logic and truth: Situated knowledge technology. In Conceptual Graphs for Knowledge Representation, </title> <booktitle> number 699 in Lecture Notes in Computer Science, </booktitle> <pages> pages 36-63. </pages> <publisher> Springer-Verlag, </publisher> <year> 1993. </year>
Reference-contexts: Such a facility is available in conceptual graph theory and will be available shortly in the Peirce conceptual graphs workbench <ref> [EL92, Gai93] </ref> in which our learning system is implemented. An important step in showing the generality of the graph-theoretic representation is to show that games generated from the MetaGame generator can fit this structure.
Reference: [GJ79] <author> M.R. Garey and D.S. Johnson. </author> <title> Computers and Intractability: A Guide to the Theory of NP-Completeness. </title> <publisher> Freeman, </publisher> <address> Murray-Hill, </address> <year> 1979. </year>
Reference-contexts: been shown to be PSPACE-hard (for arbitrarily large boards) and are PSPACE-complete if restricted to polynomial length games. ...the fact that a problem is PSPACE-complete is even stronger indication that it is intractable than if it were NP-Complete; we could have P=NP even if P is not equal to P-Space <ref> [GJ79] </ref>. * Chess-like games, such as those defined in MetaGame [Pel92], have primitive operators that are more complicated than those in Hex. Further, conditions once true may become false. <p> Most nim games are played on hypergraphs in which all edges are disjoint. In these disconnected versions a simple winning strategy based on binary arithmetic exists. Does this strategy extend to connected hypergraphs as well? In addition to these games, many NP-complete problems <ref> [GJ79] </ref> such as "set covering" can be formulated to take place on basic hypergraphs.
Reference: [GL94] <author> J. Gould and R. Levinson. </author> <title> Experience-based adaptive search. </title> <editor> In R. Michalski and G. Tecuci, editors, </editor> <booktitle> Machine Learning:A Multi-Strategy Approach, </booktitle> <volume> volume 4, </volume> <pages> pages 579-604. </pages> <publisher> Morgan Kauffman, </publisher> <year> 1994. </year> <note> References 29 </note>
Reference: [Gol89] <author> D. E. Goldberg. </author> <title> Genetic Algorithms in Search, Optimization and Machine Learning. </title> <address> Addison-Welsley, Reading, MA, </address> <year> 1989. </year>
Reference-contexts: Reinforcement learning in general is becoming increasingly popular [Sut91] because it can minimize the need for human assistance. Neural networks [RM86] and genetic algorithms <ref> [Bet81, BGH89, Gol89, Hol75] </ref> can be viewed as blind-learners. These systems attempt to learn functions given pre-classified input-output pairs. To the extent that the supplied classifications can also be generated automatically (with temporal-difference learning [Sut88], for example) the learned functions coupled with search would produce a general game-playing system.
Reference: [Ham72] <author> P. C. Hammer. </author> <title> Mathematics and systems theory. </title> <editor> In G. Klir, editor, </editor> <booktitle> Trends in General Systems Theory, </booktitle> <pages> pages 408-433. </pages> <publisher> Wiley and Sons, </publisher> <address> New York, </address> <year> 1972. </year>
Reference-contexts: It continues to be one of the most pervasive problem 2 Even precisely defined and well-accepted mathematical concepts are not always as general and as appropriate as they could be, and thus may obscure deeper relationships <ref> [Ham72] </ref>. 3 Once this is done conceptually the names may be retained as mnemonic aids for humans, but recognized as arbitrary by the machine. 3.
Reference: [Hol75] <author> J. H. Holland. </author> <title> Adaptation in Natural and Artificial Systems. </title> <publisher> The University of Michigan Press, </publisher> <address> Ann Arbor, </address> <year> 1975. </year>
Reference-contexts: Reinforcement learning in general is becoming increasingly popular [Sut91] because it can minimize the need for human assistance. Neural networks [RM86] and genetic algorithms <ref> [Bet81, BGH89, Gol89, Hol75] </ref> can be viewed as blind-learners. These systems attempt to learn functions given pre-classified input-output pairs. To the extent that the supplied classifications can also be generated automatically (with temporal-difference learning [Sut88], for example) the learned functions coupled with search would produce a general game-playing system. <p> Review of Original Morph Model In the following sections we discuss our group's approach to blind and informed learning with graph analysis and reinforcement learning. Many other learning approaches may prove equally viable such as: neural networks [RM86], genetic algorithms <ref> [Hol75] </ref>, constraint satisfaction [RK91], inductive logic programming, and explanation-based generalization [FD89, KM90, RN94].
Reference: [Hun94] <author> L. Hunter. </author> <title> Disjunctive concept learning. </title> <month> December </month> <year> 1994. </year> <title> A communication in the moderated electronic Machine Learning List. </title>
Reference-contexts: Most systems do not exploit graph-isomorphism and higher-order morphisms between structures despite the fact that such relationships are at the core of the structure of those domains. For example, many implemented learners have difficulty even learning the simple concept "any three consecutive bits are 1" <ref> [Hun94] </ref>, apparently because the simple adjacency relationship between bits is not being exploited or ternary relations are not considered. Our goal is to build a blind learner that constructs and exploits a reinforcement hierarchy, just as in informed learning.
Reference: [Jan90] <author> P. Jansen. </author> <title> Problematic positions and speculative play. </title> <editor> In T. A. Marsland and J. Schaeffer, editors, </editor> <title> Computer, </title> <journal> Chess and Cognition, </journal> <volume> chapter 10, </volume> <pages> pages 169-181. </pages> <publisher> Springer-Verlag, </publisher> <year> 1990. </year>
Reference-contexts: A number of important research issues remain in which this assumption has been relaxed (e.g., trying to play into positions in which the opponent is likely to not find the winning line <ref> [Jan90] </ref>). In this case statistical and mathematical models of the game and the opponent increase in importance.
Reference: [Kai90] <author> H. Kaindl. </author> <title> Tree searching algorithms. In A.T. </title> <editor> Marsland and J. Schaeffer, editors, </editor> <title> Computers, </title> <journal> Chess and Cognition, </journal> <pages> pages 133-158. </pages> <publisher> Springer-Verlag, </publisher> <year> 1990. </year>
Reference: [Kli85] <author> G. J. Klir. </author> <title> Architecture of Systems Problem-Solving. </title> <publisher> Plenum Publishing, </publisher> <address> New York, </address> <year> 1985. </year>
Reference-contexts: Conceptually, any function learning method will do. We focus on the identification of the subsystems themselves and towards their interaction. The notion of a hierarchy of control modules is consistent with the hierarchical general systems theory of Mesarovic <ref> [MMT70, Kli85] </ref>.
Reference: [KM75] <author> D. E. Knuth and R.W. Moore. </author> <title> An analysis of alpha-beta pruning. </title> <journal> Artificial Intelligence, </journal> <volume> 6(4) </volume> <pages> 293-326, </pages> <year> 191975. </year>
Reference: [KM90] <editor> Yves Kodratoff and Ryszard Michalski. </editor> <booktitle> Machine Learning An Artificial Intelligence Approach, </booktitle> <volume> volume 3, chapter 1, </volume> <pages> pages 13-16. </pages> <publisher> Morgan Kaufman, </publisher> <year> 1990. </year> <title> See the bibliography of this book for extensive references to recent work in constructive induction. </title>
Reference-contexts: Many other learning approaches may prove equally viable such as: neural networks [RM86], genetic algorithms [Hol75], constraint satisfaction [RK91], inductive logic programming, and explanation-based generalization <ref> [FD89, KM90, RN94] </ref>. Most of these methods, however, must be extended to the general case of all single and double-agent search problems, just as MorphII generalizes Morph. 5 Review of Original Morph Model Morph is an application of our APS (Adaptive-Predictive Search) method for improving search with experience.
Reference: [Kor87] <author> R. E. Korf. </author> <title> Planning as search. </title> <journal> Artificial Intelligence, </journal> <year> 1987. </year>
Reference-contexts: Generic Games with Abstract Operators 7 solving models used in AI research. 4 We now show how all state space search problems as they are normally formalized <ref> [Kor87] </ref> can be viewed as relation-based transformations over hypergraphs, (which are a special case of conceptual graphs). Relations (in the form of predicates and functions) are also the basis for formal first-order logic, the foundation of many of the declarative representations traditionally used in symbolic AI.
Reference: [Kor88] <author> R. E. Korf. </author> <title> Optimal path-finding algorithms. </title> <editor> In L. Kanal and V. Kumar, editors, </editor> <booktitle> Search in Artificial Intelligence, </booktitle> <pages> pages 223-267. </pages> <publisher> Springer-Verlag, </publisher> <year> 1988. </year>
Reference-contexts: Finally, the hierarchy over problems by easier-than is 10 4. Extending Tic-tac-toe and Other Games to All Hypergraphs. in conformance with the hierarchies generated dynamically during abstract planning <ref> [Kor88, Sac74] </ref>. 4 Extending Tic-tac-toe and Other Games to All Hypergraphs. To further illustrate the unifying power of studying games based on their mathematical structure let's take a closer look at the tic-tac-toe-like games.
Reference: [Lev94] <author> R. A. Levinson. Uds: </author> <title> A universal data structure. </title> <editor> In W.M. Tepfenhart, J.P. Dick, and J.F. Sowa, editors, </editor> <booktitle> Conceptual Structures: Theory and Practice, number 835 in Lecture Notes in AI, </booktitle> <pages> pages 230-250. </pages> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1994. </year>
Reference-contexts: We call the relational hierarchy and the algorithms that operate over it UDS, for "Universal Data Structure" <ref> [Lev94] </ref>. The "Universal" in UDS refers to an effective monitor and executor of the specifications for any given state space search domain. <p> Thus, in our example, the firing of Move (D1,P1,D3) removes (D1,P1,P2) and (D1,P1,D3) from the Move table and adds (D1,P2,P1) and (D2,P1,P3) to the Move table. 9. MorphII: Domain-Independent Games Environment in C++ 21 Further details on the implementation, including how join and merge work, can be found in <ref> [Lev94] </ref>. 9.3 Performance Results With this scheme, we have been able to monitor a variety of domains including tic-tac-toe, Towers of Hanoi, 8-puzzle, and Hexpawn 12 at a level of efficiency that is faster (in some cases up to 10 times) than previous programs of ours that had been written specifically
Reference: [LF4a] <author> Robert Levinson and Gil Fuchs. </author> <title> A pattern-weight formulation of search knowledge. </title> <type> Technical Report UCSC-CRL-91-15, </type> <institution> University of California Santa Cruz, </institution> <year> 1994a. </year> <note> Revision to appear in Computational Intelligence. </note>
Reference-contexts: In APS, knowledge is stored as pattern-weight pairs (pws) <ref> [LF4a] </ref>, where patterns represented by conceptual graphs are boolean predicates over states, and weights are estimates of the expected distance of states satisfying the pattern from a goal state.
Reference: [LK93] <author> R. Levinson and K. Karplus. </author> <title> Graph-isomorphism and experience-based planning. </title> <editor> In D. Subramaniam, editor, </editor> <booktitle> Proceedings of Workshop on Knowledge Compilation and Speed-Up Learning, </booktitle> <address> Amherst, MA., </address> <month> June </month> <year> 1993. </year>
Reference-contexts: bindings, but retain the "label-free" framework by omitting the arbitrary names assigned to objects, conditions and operators. 3 The framework, incorporating state space search, is inspired by Peirce's existential graphs [Rob92] and the more modern version "conceptual graphs" developed by John Sowa [Sow83] and our own work in experience-based planning <ref> [LK93] </ref>. The state space search paradigm breaks problems down into initial conditions, terminal conditions (goals) and operators. <p> The conclusion is significant, however, in that it suggests the potential for graph-theoretic analysis of the rules of a domain and ensuing experience for uncovering powerful heuristics and decision-making strategies <ref> [LK93, LS93] </ref>. It also suggests that state-space search can be monitored in a uniform manner; this topic is discussed in Section 7. 3.1 Evaluation of the Graph-theoretic Representation Scheme The hypergraph representation scheme presented above does not include facilities for inference over static and dynamic relations. <p> With such a domain-independent graph-theoretic representation we have been able to show that the entire TWEAK planning system can be reduced to 5 abstract operators and a simple control structure, and that Roach's robot problem and Sussman's anomaly can be solved using the same database of domain-abstracted operators as macros <ref> [LK93] </ref>. Using the variable-free, graph-theoretic definition of problems it is also possible to define a hierarchy of single-agent problems by "easier than" using sub-hypergraph-isomorphism.
Reference: [LM88] <author> K. F. Lee and S. Mahajan. </author> <title> A pattern classification approach to evaluation function learning. </title> <journal> Artificial Intelligence, </journal> <volume> 36 </volume> <pages> 1-25, </pages> <year> 1988. </year>
Reference-contexts: For example, mathematical techniques have recently been applied successfully to previously considered intractable Go endgames [BW94]. Reinforcement learning has already proved to be highly successful in learning the evaluation functions for specific games such as checkers [Sam59], Othello <ref> [LM88] </ref> and backgammon [TS89]. The latter two programs developed to world-class players in their respective domains.
Reference: [LNR87] <author> J. Laird, A. Newell, and P. Rosenbloom. </author> <title> Soar: An architecture for general intelligence. </title> <journal> Artificial Intelligence, </journal> <volume> 33 </volume> <pages> 1-64, </pages> <year> 1987. </year>
Reference-contexts: The limitations of the search approaches have suggested the use of abstract and hierarchical planning algorithms that attempt to view a game state as a collection of subproblems to be solved <ref> [Wil80, Pit76, Min84, LNR87, FD89] </ref>. To date, these approaches have not proved powerful or general enough to be serious practical competitors to brute-force search.
Reference: [LS91] <author> R. Levinson and R. Snyder. </author> <title> Adaptive pattern oriented chess. </title> <booktitle> In Proceedings of AAAI-91, </booktitle> <pages> pages 601-605. </pages> <address> Morgan-Kaufman, </address> <year> 1991. </year>
Reference: [LS93] <author> R. Levinson and R. Snyder. </author> <title> Distance: Towards the unification of chess knowledge. </title> <journal> International Computer Chess Association Journal, </journal> <volume> 16(3) </volume> <pages> 315-337, </pages> <month> September </month> <year> 1993. </year>
Reference-contexts: The conclusion is significant, however, in that it suggests the potential for graph-theoretic analysis of the rules of a domain and ensuing experience for uncovering powerful heuristics and decision-making strategies <ref> [LK93, LS93] </ref>. It also suggests that state-space search can be monitored in a uniform manner; this topic is discussed in Section 7. 3.1 Evaluation of the Graph-theoretic Representation Scheme The hypergraph representation scheme presented above does not include facilities for inference over static and dynamic relations.
Reference: [McC98] <author> D. A. McCallester. </author> <title> Conspiracy numbers for minmax search. </title> <journal> Artificial Intelligence, </journal> <volume> 35(3) </volume> <pages> 287-310, </pages> <year> 1998. </year> <note> 30 References </note>
Reference: [Mic83] <author> R. S. Michalski. </author> <title> A theory and methodology of inductive learning. </title> <editor> In R. S. Michalski, J. G. Carbonell, and T. M. Mitchell, editors, </editor> <booktitle> Machine learning: An Artificial Intelligence Approach. </booktitle> <publisher> Tioga Press, </publisher> <year> 1983. </year>
Reference-contexts: To date, most such systems only perform well in domains for which their application was anticipated and for which they were tuned. Inductive learning algorithms <ref> [Qui86, Mic83] </ref> have tended to suffer from similar limitations, despite showing strength in well-controlled settings. Recent developments in inductive logic programming [Mor94] may eventually make inductive learning more generally applicable.
Reference: [Min84] <author> S. Minton. </author> <title> Constraint based generalization- learning game playing plans from single examples. </title> <booktitle> In Proceedings of AAAI-84, </booktitle> <pages> pages 251-254. </pages> <publisher> AAAI, AAAI Press, </publisher> <year> 1984. </year>
Reference-contexts: The limitations of the search approaches have suggested the use of abstract and hierarchical planning algorithms that attempt to view a game state as a collection of subproblems to be solved <ref> [Wil80, Pit76, Min84, LNR87, FD89] </ref>. To date, these approaches have not proved powerful or general enough to be serious practical competitors to brute-force search.
Reference: [Mir87] <author> D. P. Miranker. </author> <title> Treat: A better match algorithm for ai production systems. </title> <booktitle> In Proceedings of AAAI-87, </booktitle> <pages> pages 42-47. </pages> <publisher> AAAI Press, </publisher> <year> 1987. </year>
Reference-contexts: The "Universal" in UDS refers to an effective monitor and executor of the specifications for any given state space search domain. Due to the relation-based perspective of UDS, the following ideas from the RETE algorithm <ref> [For82, Mir87] </ref> can be exploited with little adjustment to the relational hierarchy defined above. * The firing of an individual operator does not affect the current state radically. * If an operator did not match in the previous cycle, it most likely will not match in the current cycle either. *
Reference: [MMT70] <author> M.D. Mesarovic, D. Macko, and Y. Takahara. </author> <title> Theory of Hierarchical, Multi-Level Systems. </title> <publisher> Academic Press, </publisher> <address> Massachusetts, </address> <year> 1970. </year>
Reference-contexts: Conceptually, any function learning method will do. We focus on the identification of the subsystems themselves and towards their interaction. The notion of a hierarchy of control modules is consistent with the hierarchical general systems theory of Mesarovic <ref> [MMT70, Kli85] </ref>.
Reference: [Mor94] <author> E. Morales. </author> <title> Learning patterns for playing strategies. </title> <journal> International Computer Chess Association Journal, </journal> <volume> 17(1) </volume> <pages> 15-26, </pages> <month> March </month> <year> 1994. </year>
Reference-contexts: To date, most such systems only perform well in domains for which their application was anticipated and for which they were tuned. Inductive learning algorithms [Qui86, Mic83] have tended to suffer from similar limitations, despite showing strength in well-controlled settings. Recent developments in inductive logic programming <ref> [Mor94] </ref> may eventually make inductive learning more generally applicable. To achieve the goal of the informed learning project, the structure of the learner itself may need to be dynamically adjusted by the system in a way that is specifically suited to the problem in question.
Reference: [Nau80] <author> D.S. Nau. </author> <title> Pathology on game-trees: A summary of results. </title> <booktitle> In Proceedings of the First National Conference on Artificial Intelligence (AAAI-80), </booktitle> <pages> pages 102-104, </pages> <address> Stanford, Calif., 1980. </address> <publisher> AAAI Press. </publisher>
Reference: [Nil80] <author> N. J. Nilsson. </author> <booktitle> Principles of Artificial Intelligence. </booktitle> <publisher> Morgan Kaufmann Publishers, </publisher> <year> 1980. </year>
Reference-contexts: Single-agent problems have, of course, also been approached through search with such algorithms as A* <ref> [Nil80] </ref>, best-first-search [RK91], and means-ends-analysis [EN69]. To discuss single agent search in depth is beyond the scope of this paper. <p> Towers of Hanoi we have the following MOVE operator: MOVE (d1:disk,p1:peg,p2:peg) = pre: ON (d1,p1) AND ~(p1=p2) AND ~((ON (d2,p2) OR ON (d2,p1)) AND SMALLER_THAN (d2,d1)). add: ON (d1, p2) As a further example, the SWAP operator which switches a bottom block for a top block in the blocks world <ref> [Nil80] </ref> and vice versa in a tower of three blocks has this representation: SWAP (block:x, block:y, block:z)= pre: ON (x,y) AND ON (y,z) AND CLEAR (X) add: ON (z,y) CLEAR (z) del: ON (x,y) CLEAR (x) This representation has an equivalent operator graph involving three variable nodes and six dynamic relation <p> Likewise the length of a solution path in A becomes a lower bound on the length of an optimal solution path in B and thus conforms to the traditional notion of admissible heuristic <ref> [Nil80] </ref>. Finally, the hierarchy over problems by easier-than is 10 4. Extending Tic-tac-toe and Other Games to All Hypergraphs. in conformance with the hierarchies generated dynamically during abstract planning [Kor88, Sac74]. 4 Extending Tic-tac-toe and Other Games to All Hypergraphs.
Reference: [Pea82] <author> J. Pearl. </author> <title> The solution for the branching factor of the alpha-beta pruning alghorithm and its optimality. </title> <journal> Communications of the ACM, </journal> <volume> 25(8) </volume> <pages> 559-564, </pages> <year> 1982. </year>
Reference: [Pel92] <author> Barney Pell. METAGAME: </author> <title> A new challenge for games and learning. </title> <editor> In H. J. van den Herik and L. V. Allis, editors, </editor> <booktitle> Programming in Artificial Intellegence: The Third Computer Olympiad. </booktitle> <publisher> Ellis Horwood, </publisher> <year> 1992. </year>
Reference-contexts: are PSPACE-complete if restricted to polynomial length games. ...the fact that a problem is PSPACE-complete is even stronger indication that it is intractable than if it were NP-Complete; we could have P=NP even if P is not equal to P-Space [GJ79]. * Chess-like games, such as those defined in MetaGame <ref> [Pel92] </ref>, have primitive operators that are more complicated than those in Hex. Further, conditions once true may become false.
Reference: [Pit76] <author> J. Pitrat. </author> <title> A program for learning to play chess. </title> <booktitle> In Pattern Recognition and Artificial Intelligence. </booktitle> <publisher> Academic Press, </publisher> <year> 1976. </year>
Reference-contexts: The limitations of the search approaches have suggested the use of abstract and hierarchical planning algorithms that attempt to view a game state as a collection of subproblems to be solved <ref> [Wil80, Pit76, Min84, LNR87, FD89] </ref>. To date, these approaches have not proved powerful or general enough to be serious practical competitors to brute-force search.
Reference: [Qui86] <author> J. R. Quinlan. </author> <title> Induction on decision trees. </title> <journal> Machine Learning, </journal> <volume> 1 </volume> <pages> 81-106, </pages> <year> 1986. </year>
Reference-contexts: To date, most such systems only perform well in domains for which their application was anticipated and for which they were tuned. Inductive learning algorithms <ref> [Qui86, Mic83] </ref> have tended to suffer from similar limitations, despite showing strength in well-controlled settings. Recent developments in inductive logic programming [Mor94] may eventually make inductive learning more generally applicable.
Reference: [RK91] <author> E. Rich and K. Knight. </author> <booktitle> Artificial Intelligence. </booktitle> <publisher> McGraw-Hill, </publisher> <year> 1991. </year>
Reference-contexts: Single-agent problems have, of course, also been approached through search with such algorithms as A* [Nil80], best-first-search <ref> [RK91] </ref>, and means-ends-analysis [EN69]. To discuss single agent search in depth is beyond the scope of this paper. <p> Review of Original Morph Model In the following sections we discuss our group's approach to blind and informed learning with graph analysis and reinforcement learning. Many other learning approaches may prove equally viable such as: neural networks [RM86], genetic algorithms [Hol75], constraint satisfaction <ref> [RK91] </ref>, inductive logic programming, and explanation-based generalization [FD89, KM90, RN94].
Reference: [RM86] <editor> E. D. Rumelhart and J. L. McClelland. </editor> <booktitle> Parallel Distributed Processing, </booktitle> <volume> volume 1-2. </volume> <publisher> MIT Press, </publisher> <year> 1986. </year>
Reference-contexts: Reinforcement learning in general is becoming increasingly popular [Sut91] because it can minimize the need for human assistance. Neural networks <ref> [RM86] </ref> and genetic algorithms [Bet81, BGH89, Gol89, Hol75] can be viewed as blind-learners. These systems attempt to learn functions given pre-classified input-output pairs. <p> Review of Original Morph Model In the following sections we discuss our group's approach to blind and informed learning with graph analysis and reinforcement learning. Many other learning approaches may prove equally viable such as: neural networks <ref> [RM86] </ref>, genetic algorithms [Hol75], constraint satisfaction [RK91], inductive logic programming, and explanation-based generalization [FD89, KM90, RN94].
Reference: [RN94] <author> S. Russell and P. Norvig. </author> <title> Artificial Intelligence: A Modern Approach. </title> <publisher> Prentice-Hall, </publisher> <address> Massachusetts, </address> <year> 1994. </year>
Reference-contexts: Many other learning approaches may prove equally viable such as: neural networks [RM86], genetic algorithms [Hol75], constraint satisfaction [RK91], inductive logic programming, and explanation-based generalization <ref> [FD89, KM90, RN94] </ref>. Most of these methods, however, must be extended to the general case of all single and double-agent search problems, just as MorphII generalizes Morph. 5 Review of Original Morph Model Morph is an application of our APS (Adaptive-Predictive Search) method for improving search with experience.
Reference: [Rob92] <author> D.D. Roberts. </author> <title> The existential graphs. </title> <booktitle> In Semantic Networks in Artificial Intelligence, </booktitle> <pages> pages 639-664. Roberts, </pages> <year> 1992. </year>
Reference-contexts: a more natural definition of generic games we add the notions of domain objects, static relations, dynamic relations, variables and bindings, but retain the "label-free" framework by omitting the arbitrary names assigned to objects, conditions and operators. 3 The framework, incorporating state space search, is inspired by Peirce's existential graphs <ref> [Rob92] </ref> and the more modern version "conceptual graphs" developed by John Sowa [Sow83] and our own work in experience-based planning [LK93]. The state space search paradigm breaks problems down into initial conditions, terminal conditions (goals) and operators.
Reference: [Sac74] <author> E.D. Sacerdoti. </author> <title> Planning in a hierarchy of abstraction spaces. </title> <journal> Artificial Intelligence, </journal> <volume> 5(2) </volume> <pages> 115-135, </pages> <year> 1974. </year>
Reference-contexts: Finally, the hierarchy over problems by easier-than is 10 4. Extending Tic-tac-toe and Other Games to All Hypergraphs. in conformance with the hierarchies generated dynamically during abstract planning <ref> [Kor88, Sac74] </ref>. 4 Extending Tic-tac-toe and Other Games to All Hypergraphs. To further illustrate the unifying power of studying games based on their mathematical structure let's take a closer look at the tic-tac-toe-like games.
Reference: [Sam59] <author> A. L. Samuel. </author> <title> Some studies in machine learning using the game of checkers. </title> <journal> IBM Journal of Research and Development, </journal> <volume> 3(3) </volume> <pages> 211-229, </pages> <year> 1959. </year>
Reference-contexts: For example, mathematical techniques have recently been applied successfully to previously considered intractable Go endgames [BW94]. Reinforcement learning has already proved to be highly successful in learning the evaluation functions for specific games such as checkers <ref> [Sam59] </ref>, Othello [LM88] and backgammon [TS89]. The latter two programs developed to world-class players in their respective domains.
Reference: [SN93] <author> S.J. Smith and D.S. Nau. </author> <title> Strategic planning for imperfect information games. </title> <booktitle> In Proceedings of 1993 AAAI Fall Symposium on Games: Planning and Learning, </booktitle> <address> Menlo Park., 1993. </address> <publisher> AAAI Press. </publisher>
Reference-contexts: To date, these approaches have not proved powerful or general enough to be serious practical competitors to brute-force search. But some researchers expect that to change once the mathematics behind planning is understood and a wider variety of games such as those with imperfect information are considered <ref> [SN93] </ref>. A number of individual games have succumbed to mathematical and computer-aided analysis [BCG82, All92, Vaj92]. We believe that through a general graph-theoretic approach this type of analysis can be extended to much wider classes of games and problems.
Reference: [Sow83] <author> J. F. Sowa. </author> <title> Conceptual Structures. </title> <publisher> Addison-Wesley, </publisher> <year> 1983. </year>
Reference-contexts: domain objects, static relations, dynamic relations, variables and bindings, but retain the "label-free" framework by omitting the arbitrary names assigned to objects, conditions and operators. 3 The framework, incorporating state space search, is inspired by Peirce's existential graphs [Rob92] and the more modern version "conceptual graphs" developed by John Sowa <ref> [Sow83] </ref> and our own work in experience-based planning [LK93]. The state space search paradigm breaks problems down into initial conditions, terminal conditions (goals) and operators.
Reference: [Sto79] <author> G. Stockman. </author> <title> A minimax algorithm better than alpha-beta. </title> <journal> Artificial Intelligence, </journal> <volume> 12(2) </volume> <pages> 179-196, </pages> <year> 1979. </year>
Reference: [Sut88] <author> R. S. Sutton. </author> <title> Learning to predict by the methods of temporal differences. </title> <journal> Machine Learning, </journal> <volume> 3(1) </volume> <pages> 9-44, </pages> <month> August </month> <year> 1988. </year> <note> References 31 </note>
Reference-contexts: Neural networks [RM86] and genetic algorithms [Bet81, BGH89, Gol89, Hol75] can be viewed as blind-learners. These systems attempt to learn functions given pre-classified input-output pairs. To the extent that the supplied classifications can also be generated automatically (with temporal-difference learning <ref> [Sut88] </ref>, for example) the learned functions coupled with search would produce a general game-playing system. However, these systems 4 2. Generic Representation of Games and Search Problems do not yet incorporate a thorough graph-theoretic understanding of machine learning domains in their structure. <p> The individual learning modules form a partially-ordered hierarchy based on the "subsystem" relation. The top level modules of the hierarchy receive feedback for individual states in a state sequence using the same temporal difference (TD) learning <ref> [Sut88] </ref> mechanism as in Morph. 9 These modules in turn send feedback to their subsystems and so on, bottoming out in primitive GLMs. During play, higher-level systems compose their predictions by combining the recommendations of lower-level systems.
Reference: [Sut91] <author> R.S. Sutton. </author> <title> Special issue on reinforcement learning. </title> <booktitle> Machine Learning, </booktitle> <year> 1991. </year>
Reference-contexts: Such successes provide important datapoints in pursuing the blueprint; these systems used only a moderate amount of human assistance (in defining their feature and training sets) and thus were not too far from the ideal of full domain-independence. Reinforcement learning in general is becoming increasingly popular <ref> [Sut91] </ref> because it can minimize the need for human assistance. Neural networks [RM86] and genetic algorithms [Bet81, BGH89, Gol89, Hol75] can be viewed as blind-learners. These systems attempt to learn functions given pre-classified input-output pairs.
Reference: [Tar56] <author> A. Tarski. </author> <title> Logic, Semantics, Metamathematics: Papers from 1923 to 1938. </title> <publisher> Oxford University Press, Oxford, </publisher> <year> 1956. </year>
Reference-contexts: It is our thesis that logic, graph theory and state-space representation should be tied tightly together. In particular, the notion of static and dynamic relations presented below is original and adds a temporal dimension to traditional model theory <ref> [Tar56] </ref> by relating logic and search. The following is a description of the components of a search problem, with running examples taken from tic-tac-toe 5 and Towers of Hanoi on three disks: 6 * Each domain has a finite set of domain objects.
Reference: [TS89] <author> G. Tesauro and T. J. Sejnowski. </author> <title> A parallel network that learns to play backgammon. </title> <journal> Artificial Intelligence, </journal> <volume> 39 </volume> <pages> 357-390, </pages> <year> 1989. </year>
Reference-contexts: For example, mathematical techniques have recently been applied successfully to previously considered intractable Go endgames [BW94]. Reinforcement learning has already proved to be highly successful in learning the evaluation functions for specific games such as checkers [Sam59], Othello [LM88] and backgammon <ref> [TS89] </ref>. The latter two programs developed to world-class players in their respective domains.
Reference: [Vaj92] <author> S. Vajda. </author> <title> Mathematical Games and How to Play Them. </title> <publisher> Ellis Horwood Ltd., </publisher> <address> Great Britain, </address> <year> 1992. </year>
Reference-contexts: But some researchers expect that to change once the mathematics behind planning is understood and a wider variety of games such as those with imperfect information are considered [SN93]. A number of individual games have succumbed to mathematical and computer-aided analysis <ref> [BCG82, All92, Vaj92] </ref>. We believe that through a general graph-theoretic approach this type of analysis can be extended to much wider classes of games and problems. For example, mathematical techniques have recently been applied successfully to previously considered intractable Go endgames [BW94]. <p> Extending Tic-tac-toe and Other Games to All Hypergraphs. 11 The birthday table or round table game <ref> [Vaj92] </ref> is described as follows: We will assume two players, let us call them Left and Right. Left will seat all the boys and Right will seat all the girls around a circular table with 15 seats. <p> If the number of seats is odd, the first player wins by moving anywhere and then invoking the even number of seats strategy, as if the first player went second. Another popular single-agent game is known as Merlin's magic square <ref> [Vaj92] </ref>. This solitaire game, often played on a 3x3 grid can be be generalized to any hypergraph. All nodes start with parity 0. Each move changes the parity of all nodes in a given hyperedge, i.e., 0 becomes 1 and 1 becomes 0. <p> It is interesting to contrast the Merlin games to other search problems, where move order does matter and applying linear programming then becomes very expensive or impossible. Finally, Nim <ref> [Vaj92] </ref> can also be extended for play on any hypergraph. Players alternate taking sets of nodes from the hypergraph, but such that each set is contained within a given hyperedge. The player who takes the last node wins.
Reference: [Wat85] <author> S. Watanabe. </author> <title> Pattern Recognition:Human and Mechanical. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1985. </year>
Reference-contexts: These sets of bits give topological information about the structure of the search space. Currently, the system uses fuzzy graph matching and clustering <ref> [Wat85] </ref> to form higher-level relations and the associated GLMs. For example, two variables whose bit pairs (one bit from each variable) have similar combining rules are then combined to form a new binary relation.
Reference: [Wil80] <author> D. Wilkins. </author> <title> Using patterns and plans in chess. </title> <journal> Artificial Intelligence, </journal> <volume> 14(2) </volume> <pages> 165-203, </pages> <year> 1980. </year>
Reference-contexts: The limitations of the search approaches have suggested the use of abstract and hierarchical planning algorithms that attempt to view a game state as a collection of subproblems to be solved <ref> [Wil80, Pit76, Min84, LNR87, FD89] </ref>. To date, these approaches have not proved powerful or general enough to be serious practical competitors to brute-force search.
References-found: 65

