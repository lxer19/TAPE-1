URL: http://c.gp.cs.cmu.edu:5103/afs/cs.cmu.edu/user/fp/www/papers/strict98.ps.gz
Refering-URL: http://c.gp.cs.cmu.edu:5103/afs/cs.cmu.edu/user/fp/www/homepage.html
Root-URL: http://www.cs.cmu.edu
Email: ffpjcarsteng@cs.cmu.edu  
Title: Algorithms for Equality and Unification in the Presence of Notational Definitions  
Author: Frank Pfenning and Carsten Schurmann 
Date: May 20, 1998  
Affiliation: Carnegie Mellon University School of Computer Science  
Abstract-found: 0
Intro-found: 1
Reference: [B + 98] <editor> Bruno Barras et al. </editor> <title> The Coq Proof Assistant, Reference Manual, </title> <type> Version 6.2. </type> <institution> INRIA, CNRS, France, </institution> <year> 1998. </year>
Reference-contexts: 1 Introduction Notational definitions are pervasive in mathematical practice and are therefore supported in most automated theorem proving systems such as Coq <ref> [B + 98] </ref>, PVS [ORS92], Lego [LP92], or Isabelle [Pau98]. Semantically, notational definitions are transparent, that is, one obtains the meaning of an expression by interpreting the result of expanding all definitions.
Reference: [CP97] <author> Iliano Cervesato and Frank Pfenning. </author> <title> A linear spine calculus. </title> <type> Technical Report CMU-CS-97-125, CMU, </type> <year> 1997. </year>
Reference-contexts: We assess our results in Section 5 and conclude and describe future work in Section 6. 2 Language The type theory underlying the logical framework LF [HHP93] is divided into three levels: objects, types, and kinds. We deviate from standard formulations by adopting a spine notation for application <ref> [CP97] </ref> and by adding definitions. The spine notation contributes significantly to the concise presentation of the theory in Section 4 and corresponds closely to the implementation in Twelf. <p> The LF type theory is defined by a number of mutually dependent judgments which define valid objects, types, kinds, contexts, and signatures, and, in our case, also heads and spines. We 2 will not reiterate the rules here (see <ref> [HHP93, CP97] </ref>).
Reference: [DHKP96] <author> Gilles Dowek, Therese Hardin, Claude Kirchner, and Frank Pfenning. </author> <title> Unification via explicit substitutions: The case of higher-order patterns. </title> <booktitle> In Joint International Conference and Symposium on Logic Programming (JICSLP'96), </booktitle> <address> Bonn, Germany, </address> <year> 1996. </year>
Reference-contexts: But obviously the problem has a solution X = true. Most unification algorithm decompose a unification problem of the form 0 ` d S 1 d S 2 (4) into 0 ` S 1 S 2 (5) and so does the unification algorithm for the higher-order pattern fragment <ref> [DHKP96] </ref> which is employed in Twelf.
Reference: [Geu92] <author> Herman Geuvers. </author> <title> The Church-Rosser property for fi-reduction in typed -calculi. </title> <editor> In A. Sce-drov, editor, </editor> <booktitle> Seventh Annual IEEE Symposium on Logic in Computer Science, </booktitle> <pages> pages 453-460, </pages> <address> Santa Cruz, California, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: Canonical forms are commonly characterized by three mutual dependent judgments, among them the judgment for weak-head reduction M whr ! M 0 which applies local fi- or ffi-reductions. The theory developed, for example, in <ref> [Geu92] </ref> still applies since definitions are transparent. We write ` M 1 M 2 to express that two definition-free and well-typed objects M 1 and M 2 are equivalent modulo fiffi-conversion. Similarly, for spines, we write ` S 1 S 2 .
Reference: [Gri88] <author> Timothy G. Griffin. </author> <title> Notational definition | a formal account. </title> <booktitle> In Third Annual Symposium on Logic in Computer Science, </booktitle> <address> Edinburgh, Scotland, </address> <pages> pages 372-383. </pages> <publisher> IEEE, </publisher> <month> July </month> <year> 1988. </year>
Reference-contexts: Fortunately, most notational definitions are strict in the sense we define. We do not deal with recursive definitions which require different considerations and have been treated in the literature on functional logic programming [Han94]. Other aspects of notational definitions in mathematical practice have been studied by Griffin <ref> [Gri88] </ref>. We have implemented a strictness checker and unification algorithm in Twelf [SP98], an implementation of the logical framework LF which supports type reconstruction, logic programming, and theorem proving. It has been applied on a variety of examples from the area of logics and programming languages.
Reference: [Han94] <author> M. Hanus. </author> <title> The integration of functions into logic programming: From theory to practice. </title> <journal> Journal of Logic Programming, </journal> 19&20:583-628, 1994. 
Reference-contexts: It also solves a related problem with the completeness of the so-called occurs-check during unification. Fortunately, most notational definitions are strict in the sense we define. We do not deal with recursive definitions which require different considerations and have been treated in the literature on functional logic programming <ref> [Han94] </ref>. Other aspects of notational definitions in mathematical practice have been studied by Griffin [Gri88]. We have implemented a strictness checker and unification algorithm in Twelf [SP98], an implementation of the logical framework LF which supports type reconstruction, logic programming, and theorem proving.
Reference: [HHP93] <author> Robert Harper, Furio Honsell, and Gordon Plotkin. </author> <title> A framework for defining logics. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 40(1) </volume> <pages> 143-184, </pages> <month> January </month> <year> 1993. </year>
Reference-contexts: In this paper we investigate the interaction of notational definitions with algorithms for testing equality and unification. We propose a syntactic criterion on definitions which avoids their expansion in many cases without losing soundness or completeness with respect to fiffi-conversion. Our setting is the dependently typed -calculus <ref> [HHP93] </ref>, but, with minor modifications, our results should apply to richer type theories and logics. The question when definitions need to be expanded is surprisingly subtle and of great practical importance. <p> In Section 4 we describe the strictness algorithm and show its correctness. We assess our results in Section 5 and conclude and describe future work in Section 6. 2 Language The type theory underlying the logical framework LF <ref> [HHP93] </ref> is divided into three levels: objects, types, and kinds. We deviate from standard formulations by adopting a spine notation for application [CP97] and by adding definitions. The spine notation contributes significantly to the concise presentation of the theory in Section 4 and corresponds closely to the implementation in Twelf. <p> The LF type theory is defined by a number of mutually dependent judgments which define valid objects, types, kinds, contexts, and signatures, and, in our case, also heads and spines. We 2 will not reiterate the rules here (see <ref> [HHP93, CP97] </ref>). <p> A definition d : A = M is well-formed in a signature if ` M : A. We generally assume that signature is valid and fixed and therefore omit it from the typing and other related judgments introduced later on. In a slight departure from <ref> [HHP93] </ref> we take fiffi-conversion as our notion of definitional equality since this guarantees that every well-typed object has an equivalent canonical form, that is, a long fiffi-normal form. <p> We call x 1 ; : : : ; x n the argument parameters, and all other parameters in the body H S local parameters. 3 Example To illustrate our algorithms we use the encoding of a small fragment of first-order intuitionistic logic in LF <ref> [HHP93] </ref>. <p> false) = pA ?q not : o ! o = A : o: imp (A; false) We write ` A to express that the formula A has a natural deduction, using the following four rules: &gt;I `? ` C ` A ` B ` A B E As shown in <ref> [HHP93] </ref>, there is an adequate encoding of this calculus in LF: The judgment ` A is represented as dependent type family, and the four rules as object constants. nd : o ! type truei : nd true falsee : C : o: nd false ! nd C impi : A :
Reference: [HM94] <author> Chris Hankin and Daniel Le Metayer. </author> <title> Deriving algorithms from type inference systems: Application to strictness analysis. </title> <booktitle> In Proceedings of the Twenty-First Annual ACM Symposium on Principles of Programming Languages, Portland, </booktitle> <pages> pages 202-212. </pages> <publisher> ACM, </publisher> <month> January </month> <year> 1994. </year>
Reference-contexts: Consequently, they cannot be strict according to our definition. A more accurate extension would have to analyze the structure of functional arguments to higher-order definitions, as in the case of strictness analysis for functional programming languages (see, for example, <ref> [HM94] </ref>). However, we suspect one quickly reaches the point of diminishing returns for this kind of complex analysis. 5 Results for Unification So far we have shown how algorithms for testing equality (that is, fiffi-convertibility) can be improved by using strictness.
Reference: [HP] <author> Robert Harper and Frank Pfenning. </author> <title> A module system for a programming language based on the LF logical framework. </title> <journal> Journal of Logic and Computation. </journal> <note> To appear. A preliminary version is available as Technical Report CMU-CS-92-191, </note> <month> September </month> <year> 1992. </year>
Reference-contexts: They are convenient in many situations and are therefore supported in most automated theorem proving systems. We do not 4 explicitly treat other forms of definitions, such as recursive definitions, but our techniques are applicable in more general circumstances. For example, in MLF <ref> [HP] </ref> | an implementation of LF extended with a module system | definitions are used to express logical interpretations. Semantically, definitions are transparent, that is, the meaning of any term can be determined by expanding all definitions.
Reference: [Hue75] <author> Gerard Huet. </author> <title> A unification algorithm for typed -calculus. </title> <journal> Theoretical Computer Science, </journal> <volume> 1 </volume> <pages> 27-57, </pages> <year> 1975. </year>
Reference-contexts: Since injectivity is a semantic criterion, we have developed a syntactic criterion called strictness which guarantees injectivity and which can be easily checked. Informally, a notational definition is said to be strict, if each argument parameter occurs at least once in a rigid position <ref> [Hue75] </ref>, applied only to pairwise distinct local parameters. If there are no defined constants, the rigid positions in a fi-normal form are those resulting from erasing the spines following argument parameters.
Reference: [LP92] <author> Zhaohui Luo and Robert Pollack. </author> <title> The LEGO proof development system: A user's manual. </title> <type> Technical Report ECS-LFCS-92-211, </type> <institution> University of Edinburgh, </institution> <month> May </month> <year> 1992. </year>
Reference-contexts: 1 Introduction Notational definitions are pervasive in mathematical practice and are therefore supported in most automated theorem proving systems such as Coq [B + 98], PVS [ORS92], Lego <ref> [LP92] </ref>, or Isabelle [Pau98]. Semantically, notational definitions are transparent, that is, one obtains the meaning of an expression by interpreting the result of expanding all definitions. Pragmatically, however, expanding all definitions as they are encountered is unsatisfactory, since it can be computationally expensive and complicate the user interface.
Reference: [Mil91] <author> Dale Miller. </author> <title> A logic programming language with lambda-abstraction, function variables, and simple unification. </title> <journal> Journal of Logic and Computation, </journal> <volume> 1(4) </volume> <pages> 497-536, </pages> <year> 1991. </year> <month> 10 </month>
Reference-contexts: Hence the definition is not injective. 6 The first part in the definition of strictness formalizes the requirement that arguments to rigid occurrences of argument parameters must be pairwise distinct local parameters. This is exactly the requirement imposed on higher-order patterns by Miller <ref> [Mil91] </ref>. In the judgments below we generally use for a context consisting of argument parameters to a definition, and consisting of local parameters. Definition 7 (Pattern spine) Let be a context, S be a spine.
Reference: [ORS92] <author> S. Owre, J. M. Rushby, and N. Shankar. PVS: </author> <title> A prototype verification system. </title> <editor> In Deepak Kapur, editor, </editor> <booktitle> 11th International Conference on Automated Deduction (CADE), volume 607 of Lecture Notes in Artificial Intelligence, </booktitle> <pages> pages 748-752, </pages> <address> Saratoga, NY, June 1992. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: 1 Introduction Notational definitions are pervasive in mathematical practice and are therefore supported in most automated theorem proving systems such as Coq [B + 98], PVS <ref> [ORS92] </ref>, Lego [LP92], or Isabelle [Pau98]. Semantically, notational definitions are transparent, that is, one obtains the meaning of an expression by interpreting the result of expanding all definitions. Pragmatically, however, expanding all definitions as they are encountered is unsatisfactory, since it can be computationally expensive and complicate the user interface.
Reference: [Pau98] <author> Lawrence C. Paulson. </author> <title> Introduction to Isabelle, </title> <year> 1998. </year>
Reference-contexts: 1 Introduction Notational definitions are pervasive in mathematical practice and are therefore supported in most automated theorem proving systems such as Coq [B + 98], PVS [ORS92], Lego [LP92], or Isabelle <ref> [Pau98] </ref>. Semantically, notational definitions are transparent, that is, one obtains the meaning of an expression by interpreting the result of expanding all definitions. Pragmatically, however, expanding all definitions as they are encountered is unsatisfactory, since it can be computationally expensive and complicate the user interface.
Reference: [SP98] <author> Carsten Schurmann and Frank Pfenning. </author> <title> Automated theorem proving in a simple meta-logic for LF. </title> <booktitle> In Proceedings of the Fifteenth International Conference on Automated Deduction, </booktitle> <pages> pages 269-283, </pages> <address> Lindau, Germany, </address> <year> 1998. </year> <note> too appear. 11 </note>
Reference-contexts: We do not deal with recursive definitions which require different considerations and have been treated in the literature on functional logic programming [Han94]. Other aspects of notational definitions in mathematical practice have been studied by Griffin [Gri88]. We have implemented a strictness checker and unification algorithm in Twelf <ref> [SP98] </ref>, an implementation of the logical framework LF which supports type reconstruction, logic programming, and theorem proving. It has been applied on a variety of examples from the area of logics and programming languages. This paper is organized as follows. <p> In an implementation of this algorithm, one would annotate each definition with strictness information, and hence no redundant computation is necessary for ls d and rs d. This algorithm has been implemented in the Twelf system <ref> [SP98] </ref>. It is easy to verify that all definitions from Section 3 satisfy the strictness condition. Definitions at base type are always strict.
References-found: 15

