URL: http://www.cs.ucsb.edu/~rugina/papers/ipps98.ps
Refering-URL: http://www.cs.ucsb.edu/~rugina/
Root-URL: http://www.cs.ucsb.edu
Email: frugina, schauserg@cs.ucsb.edu  
Title: Predicting the Running Times of Parallel Programs by Simulation  
Author: Radu Rugina and Klaus Erik Schauser 
Address: Santa Barbara, CA 93106  
Affiliation: Department of Computer Science University of California, Santa Barbara  
Abstract: Predicting the running time of a parallel program is useful for determining the optimal values for the parameters of the implementation and the optimal mapping of data on processors. However, deriving an explicit formula for the running time of a certain parallel program is a difficult task. We present a new method for the analysis of parallel programs: simulating the execution of parallel programs by following their control flow and by determining, for each processor, the sequence of send and receive operations according to the LogGP model. We developed two algorithms to simulate the LogGP communication between processors and we tested them on the blocked parallel version of the Gaussian Elimination algorithm on the Meiko CS-2 parallel machine. Our implementation showed that the LogGP simulation is able to detect the nonlinear behavior of the program running times, to indicate the differences in running times for different data layouts and to find the local optimal value of the block size with acceptable precision. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> V. D. Agrawal and S. T. Chakradhar. </author> <title> Performance estimation in a massively parallel system. </title> <booktitle> In Proceedings of Supercomputing, </booktitle> <pages> pages 306313, </pages> <year> 1990. </year>
Reference-contexts: Other analytical models use parameterized functions to express the characteristics of parallel systems [8], [3] or use statistical modeling <ref> [1] </ref>, [7]. The main disadvantage of functional and statistical models over the scalar parameter models is their high complexity which increases the computational costs of the prediction. The analytical models can be extended by decomposing the parallel systems into several aspects and modeling each aspect separately [15], [17].
Reference: [2] <author> A. Alexandrov, M. Ionescu, K. E. Schauser, and C. Scheiman. LogGP: </author> <title> Incorporating long messages into the LogP model one step closer towards a realistic model for parallel computation. </title> <booktitle> In Proceedings of the 7th Annual Symposium on Parallel Algorithms and Architectures, </booktitle> <address> Santa Bar-bara, CA, </address> <month> July </month> <year> 1995. </year>
Reference-contexts: The model parameters are the number of time units of local computation at each step (L), and the communication bandwidth of the machine (g). The LogP model [6] and its successor, the LogGP model <ref> [2] </ref>, extend BSP by taking into account the number of processors (P) and various communication costs: the latency (L), the overhead (o) and the gap (g) between consecutive messages, leading to more realistic predictions. <p> Previous work on performance prediction used the LogGP model only to analyze regular communication patterns, where each processor executes repeatedly a small communication pat-tern. The program running time was expressed using explicit formulas [9], <ref> [2] </ref> or was only given lower or upper bounds [16], [13]. Even for regular data layouts where all the processors got equal shares of data, and for the best-case algorithms, the resulting formulas were rather complicated.
Reference: [3] <author> E. A. Brewer. </author> <title> High-level optimization via automated statistical modeling. </title> <booktitle> In Proceedings of the 5th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <address> Santa Barbara, CA, </address> <month> July </month> <year> 1995. </year>
Reference-contexts: Other analytical models use parameterized functions to express the characteristics of parallel systems [8], <ref> [3] </ref> or use statistical modeling [1], [7]. The main disadvantage of functional and statistical models over the scalar parameter models is their high complexity which increases the computational costs of the prediction. <p> The basic operations used for Gaussian Elimination exhibit this type of behavior. 3 The LogGP model This model of parallel computation presented in <ref> [3] </ref> abstracts the communication of arbitrary sized messages through the use of five parameters: L: an upper bound to the latency of sending a message; o: the overhead, defined as the length of time a processor is engaged in the transmission or reception of each mes sage; g: the gap between
Reference: [4] <author> M. E. Crovella and T. J. LeBlanc. </author> <title> Parallel performance prediction using lost cycles analysis. </title> <booktitle> In Proceedings of Supercomputing, </booktitle> <address> Washington, D.C., </address> <month> November </month> <year> 1994. </year>
Reference-contexts: Other approaches that use decomposition of parallel systems address both the communication and the memory hierarchy models via the LogP-HMM [11] or aim at decomposing the execution overheads due to par-allelization [12], <ref> [4] </ref>. The work we present in this paper falls in this wide class of modeling by decomposition.
Reference: [5] <author> D. E. Culler, A. Dusseau, S. Goldstein, A. Krishnamurthy, S. Lumetta, T. von Eicken, and K. Yelick. </author> <title> Parallel programming in Split-C. </title> <booktitle> In Proceedings of Supercomputing, </booktitle> <pages> pages 262273, </pages> <month> November </month> <year> 1993. </year>
Reference-contexts: This supplementary assumption was introduced because our test case of the parallel Gaussian elimination was implemented in Split-C <ref> [5] </ref>, whose active messages mechanism gives priority to receive operations.
Reference: [6] <author> D. E. Culler, R. M. Karpand, D. A. Patterson, A. Sahay, K. E. Schauser, E. Santos, R. Subramonian, and T. von Eicken. </author> <title> LogP: Towards a realistic model of parallel computation. </title> <booktitle> In Proceedings of the 4th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <address> San Diego, CA, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: In the bulk-synchronous parallel (BSP) model [18] applications are expressed as sequences of computation steps separated by global synchronization. The model parameters are the number of time units of local computation at each step (L), and the communication bandwidth of the machine (g). The LogP model <ref> [6] </ref> and its successor, the LogGP model [2], extend BSP by taking into account the number of processors (P) and various communication costs: the latency (L), the overhead (o) and the gap (g) between consecutive messages, leading to more realistic predictions.
Reference: [7] <author> R. T. Dimpsey and R. K. Iyer. </author> <title> A measurement-based model to predict the performance impact of system modifications: A case study. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 6(1):2840, </volume> <year> 1995. </year>
Reference-contexts: Other analytical models use parameterized functions to express the characteristics of parallel systems [8], [3] or use statistical modeling [1], <ref> [7] </ref>. The main disadvantage of functional and statistical models over the scalar parameter models is their high complexity which increases the computational costs of the prediction. The analytical models can be extended by decomposing the parallel systems into several aspects and modeling each aspect separately [15], [17].
Reference: [8] <author> M. A. Driscoll and W. R. Daasch. </author> <title> Accurate predictions of parallel program execution time. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 25:1630, </volume> <year> 1995. </year>
Reference-contexts: Other analytical models use parameterized functions to express the characteristics of parallel systems <ref> [8] </ref>, [3] or use statistical modeling [1], [7]. The main disadvantage of functional and statistical models over the scalar parameter models is their high complexity which increases the computational costs of the prediction.
Reference: [9] <author> M. Karp, A. Sahay, E. Santos, and K. E. Schauser. </author> <title> Optimal broadcast and summation in the LogP model. </title> <booktitle> In Proceedings of the 5th Symposium on Parallel Algorithms and Architectures, </booktitle> <month> June </month> <year> 1993. </year>
Reference-contexts: Previous work on performance prediction used the LogGP model only to analyze regular communication patterns, where each processor executes repeatedly a small communication pat-tern. The program running time was expressed using explicit formulas <ref> [9] </ref>, [2] or was only given lower or upper bounds [16], [13]. Even for regular data layouts where all the processors got equal shares of data, and for the best-case algorithms, the resulting formulas were rather complicated.
Reference: [10] <author> Kumar, A. Grama, A. Gupta, and G. Karypis. </author> <title> Introduction to Parallel Computing: Design and Analysis of Algorithms. </title> <publisher> The Benjamin/Cummings Publishing Company, Inc., </publisher> <address> Redwood City, CA, </address> <year> 1994. </year>
Reference-contexts: Therefore, in such cases, the algorithm performs randomly some message transmissions in order to break the deadlock. 5 The parallel Gaussian Elimination algo rithm For testing our performance prediction approach, we used the Gaussian Elimination algorithm without pivoting. The parallel version of the algorithm is presented in <ref> [10] </ref>, and is based on the observation that each iteration of the sequential algorithm can be regarded as a diagonal wave traversing the matrix from the upper left corner to the lower right corner.
Reference: [11] <author> Z. Li, P. H. Mills, and J. H. Reif. </author> <title> Models and resource met-rics for parallel and distributed computation. </title> <booktitle> In Proceedings of the 28th Annual Hawaii International Conference on System Sciences, </booktitle> <address> Maui, Hawaii, </address> <year> 1995. </year>
Reference-contexts: Program information includes flow of control, loop iteration, branching and synchronization, while architecture information comprises message transmission time, message startup overhead and instruction cycle time. Other approaches that use decomposition of parallel systems address both the communication and the memory hierarchy models via the LogP-HMM <ref> [11] </ref> or aim at decomposing the execution overheads due to par-allelization [12], [4]. The work we present in this paper falls in this wide class of modeling by decomposition.
Reference: [12] <author> D. R. Liang and S. K. Tripathi. </author> <title> Performance prediction of parallel computation. </title> <booktitle> In Proceedings of the 8th International Parallel Processing Symposium, </booktitle> <pages> pages 625629, </pages> <year> 1994. </year>
Reference-contexts: Other approaches that use decomposition of parallel systems address both the communication and the memory hierarchy models via the LogP-HMM [11] or aim at decomposing the execution overheads due to par-allelization <ref> [12] </ref>, [4]. The work we present in this paper falls in this wide class of modeling by decomposition.
Reference: [13] <author> W. Lowe and W. Zimmermann. </author> <title> Upper time bounds for executing PRAM-programs on the LogP-machine. </title> <booktitle> In Proceedings of Supercomputing, </booktitle> <pages> pages 4150, </pages> <year> 1995. </year>
Reference-contexts: Previous work on performance prediction used the LogGP model only to analyze regular communication patterns, where each processor executes repeatedly a small communication pat-tern. The program running time was expressed using explicit formulas [9], [2] or was only given lower or upper bounds [16], <ref> [13] </ref>. Even for regular data layouts where all the processors got equal shares of data, and for the best-case algorithms, the resulting formulas were rather complicated. Our simulation algorithm is designed to deal with both irregular communication and irregular mapping patterns.
Reference: [14] <author> W. Meira. </author> <title> Modeling performance of parallel programs. </title> <type> In Technical Report 589, </type> <institution> Rochester University, </institution> <year> 1995. </year>
Reference-contexts: Most of the previous work in modeling performance of parallel programs is based on analytical modeling techniques that abstract the features of parallel systems as a set of scalar parameters or parameterized functions. A survey of the current approaches to modeling is given in <ref> [14] </ref>. In the bulk-synchronous parallel (BSP) model [18] applications are expressed as sequences of computation steps separated by global synchronization. The model parameters are the number of time units of local computation at each step (L), and the communication bandwidth of the machine (g).
Reference: [15] <author> G. R. Nudd, E. Papaefstathiou, Y. Papay, T. J. Atherton, C. T. Clarke, D. J. Kerbyson, A. F. Stratton, R. Ziani, and M. J. Zemerly. </author> <title> A layered approach to characterization of parallel systems for performance prediction. In Performance Evaluation of Parallel Systems, </title> <editor> U. Warwick, </editor> <address> U.K., </address> <year> 1993. </year>
Reference-contexts: The main disadvantage of functional and statistical models over the scalar parameter models is their high complexity which increases the computational costs of the prediction. The analytical models can be extended by decomposing the parallel systems into several aspects and modeling each aspect separately <ref> [15] </ref>, [17]. The Retargetable Program-Sensitive (RPS) model proposed by Stramm and Berman [17] uses mapping, program and architecture information to predict the running time. Program information includes flow of control, loop iteration, branching and synchronization, while architecture information comprises message transmission time, message startup overhead and instruction cycle time.
Reference: [16] <author> E. Santos. </author> <title> Solving triangular linear systems in parallel using substitution. </title> <booktitle> In Proceedings of the 7th IEEE Symposium on Parallel and Distributed Processing, </booktitle> <year> 1995. </year>
Reference-contexts: Previous work on performance prediction used the LogGP model only to analyze regular communication patterns, where each processor executes repeatedly a small communication pat-tern. The program running time was expressed using explicit formulas [9], [2] or was only given lower or upper bounds <ref> [16] </ref>, [13]. Even for regular data layouts where all the processors got equal shares of data, and for the best-case algorithms, the resulting formulas were rather complicated. Our simulation algorithm is designed to deal with both irregular communication and irregular mapping patterns.
Reference: [17] <author> B. Stramm and F. Berman. </author> <title> Predicting the performance of large programs on scalable computers. </title> <booktitle> In Proceedings of the Scalable High Performance Computing Conference, </booktitle> <pages> pages 2229, </pages> <year> 1992. </year>
Reference-contexts: The main disadvantage of functional and statistical models over the scalar parameter models is their high complexity which increases the computational costs of the prediction. The analytical models can be extended by decomposing the parallel systems into several aspects and modeling each aspect separately [15], <ref> [17] </ref>. The Retargetable Program-Sensitive (RPS) model proposed by Stramm and Berman [17] uses mapping, program and architecture information to predict the running time. Program information includes flow of control, loop iteration, branching and synchronization, while architecture information comprises message transmission time, message startup overhead and instruction cycle time. <p> The analytical models can be extended by decomposing the parallel systems into several aspects and modeling each aspect separately [15], <ref> [17] </ref>. The Retargetable Program-Sensitive (RPS) model proposed by Stramm and Berman [17] uses mapping, program and architecture information to predict the running time. Program information includes flow of control, loop iteration, branching and synchronization, while architecture information comprises message transmission time, message startup overhead and instruction cycle time.
Reference: [18] <author> L. G. Valiant. </author> <title> A bridging model for parallel computation. </title> <journal> Communications of the ACM, </journal> <volume> 33(8):103111, </volume> <year> 1990. </year> <month> 7 </month>
Reference-contexts: A survey of the current approaches to modeling is given in [14]. In the bulk-synchronous parallel (BSP) model <ref> [18] </ref> applications are expressed as sequences of computation steps separated by global synchronization. The model parameters are the number of time units of local computation at each step (L), and the communication bandwidth of the machine (g).
References-found: 18

