URL: http://http.cs.berkeley.edu/~halw/poly.ps
Refering-URL: http://http.cs.berkeley.edu/~halw/
Root-URL: 
Title: Reconstructing Randomly Sampled Multivariate Polynomials From Highly Noisy Data  
Author: Hal Wasserman 
Abstract: Sudan and others have considered the problem of reconstructing a bounded-degree polynomial f : F k ! F from n data-points, only t of which are guaranteed to be consistent with f. For t t n=2, the solution may not be unique; but it may be possible to find a small set of candidates for f . Here we extend this work, proving results including the following: Pick ~x (1) ; : : : ; ~x (n) 2 u F k . Generate data-points (~x (1) ; f (~x (1) )); : : : ; (~x (n) ; f (~x (n) )), and allow an adversary to corrupt any n t of them. We require t to be greater than a bound on the order of n k k+1 ; we also require a lower-bound on jF j. Then, with high probability, we may reconstruct from the corrupted data a small set of candidates for f . Our results improve on past research in several respects. First, our bound on t is lower. Second, we allow for weaker restrictions on the distribution of ~x (1) ; : : : ; ~x (n) : in particular, as in the previous paragraph, we allow for the familiar case of learning a polynomial from its values at random locations. Third, we go on to prove that, if noise is assumed to be random in a specified sense, then a polynomial may be uniquely reconstructed from highly noisy data.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Ar, R. Lipton, R. Rubinfeld, and M. Sudan, </author> <title> Reconstructing algebraic functions from mixed data, </title> <booktitle> Proc. 33rd IEEE FOCS, </booktitle> <pages> pp. 503-512, </pages> <year> 1992. </year>
Reference-contexts: While the solution may not be unique, it may be possible to determine a small set of candidates for f . Ar, Lipton, et al. <ref> [1] </ref> give a solution to a high-noise problem, but one which requires an artificial restriction on the data. <p> Goldreich, Rubinfeld, et al. [4], using quite different methods, derive strong reconstruction results which, however, work only if the data is presented as an oracle which one can query at whatever locations one pleases. Finally Sudan [7, 8] was able to enhance the methods of <ref> [1] </ref>, removing the artificial restriction. For the case of univariate polynomials, Su-dan gives a surprisingly strong result [7, Theorem 5]: from an arbitrary collection of n distinct data-points, he efficiently reconstructs all degree-( d) polynomials that are consistent with d 2 (n + 1)=d bd=2c of the data-points. <p> Are there alternative algorithms which work in cases for which Theorem 4.1 fails? 6.2 The Small-jF j Case. Our methods require lower-bounds on jF j. This is not surprising, as related papers (such as <ref> [3, 1, 7] </ref>) also require such bounds. Moreover, our bounds are not unreasonable: they are only polynomial in n, while jF j could quite naturally be even exponentially large. However, it would be desirable to have methods which work over arbitrarily small fields.
Reference: [2] <author> E. Berlekamp and L. Welch, </author> <title> Error correction of algebraic block codes, </title> <type> US Patent #4633470, </type> <year> 1986. </year>
Reference-contexts: 1 Introduction. The reconstruction of polynomials from noisy data was first considered by Berlekamp and Welch (see <ref> [2] </ref> or [3, xA]). They prove that if n+d+1 2 of n data-points are consistent with degree-( d) polynomial f : F ! F (where F is a field), then f may be uniquely and efficiently reconstructed from this data. <p> With high probability, this leaves us with (in the worst case) ~n = t+2 dn +3 dn =2d data-points, of which t are correct. We may now use a conventional decoding algorithm (see <ref> [2] </ref> or [3, xA]) to uniquely reconstruct f from the filtered data, as long as t ~n+d+1 2 .
Reference: [3] <author> P. Gemmell and M. Sudan, </author> <title> Highly resilient correctors for polynomials, </title> <journal> Inform. Processing Letters, </journal> <volume> 43 (1992), </volume> <pages> pp. 169-174. </pages>
Reference-contexts: 1 Introduction. The reconstruction of polynomials from noisy data was first considered by Berlekamp and Welch (see [2] or <ref> [3, xA] </ref>). They prove that if n+d+1 2 of n data-points are consistent with degree-( d) polynomial f : F ! F (where F is a field), then f may be uniquely and efficiently reconstructed from this data. <p> They prove that if n+d+1 2 of n data-points are consistent with degree-( d) polynomial f : F ! F (where F is a field), then f may be uniquely and efficiently reconstructed from this data. Gemmell and Sudan <ref> [3] </ref> subsequently derived related results on correcting programs which compute multivariate polynomials. Such results require a portion of correct data which is scarcely larger than the bound at which the solution would cease to be unique. It was later fl Computer Science Division, University of California, Berke-ley, halw@cs.berkeley.edu. <p> With high probability, this leaves us with (in the worst case) ~n = t+2 dn +3 dn =2d data-points, of which t are correct. We may now use a conventional decoding algorithm (see [2] or <ref> [3, xA] </ref>) to uniquely reconstruct f from the filtered data, as long as t ~n+d+1 2 . <p> Are there alternative algorithms which work in cases for which Theorem 4.1 fails? 6.2 The Small-jF j Case. Our methods require lower-bounds on jF j. This is not surprising, as related papers (such as <ref> [3, 1, 7] </ref>) also require such bounds. Moreover, our bounds are not unreasonable: they are only polynomial in n, while jF j could quite naturally be even exponentially large. However, it would be desirable to have methods which work over arbitrarily small fields.
Reference: [4] <author> O. Goldreich, R. Rubinfeld, and M. Sudan, </author> <title> Learning polynomials with queries: the highly noisy case, </title> <booktitle> Proc. 36th IEEE FOCS, </booktitle> <pages> pp. 294-303, </pages> <year> 1995. </year>
Reference-contexts: While the solution may not be unique, it may be possible to determine a small set of candidates for f . Ar, Lipton, et al. [1] give a solution to a high-noise problem, but one which requires an artificial restriction on the data. Goldreich, Rubinfeld, et al. <ref> [4] </ref>, using quite different methods, derive strong reconstruction results which, however, work only if the data is presented as an oracle which one can query at whatever locations one pleases. Finally Sudan [7, 8] was able to enhance the methods of [1], removing the artificial restriction. <p> hf (x (1) ); : : : ; f (x (n) )i, and allow an adversary to randomize up to n t of this codeword's letters. 3 The existence of a unique solution in the presence of this type of random noise has been demonstrated for a related problem in <ref> [4, x6] </ref>. 7 Assume t 4 l p m . Then, with high probability, from corrupted codeword hy (1) ; : : : ; y (n) i we can uniquely reconstruct f . Proof. We will specify an algorithm which carries out the desired reconstruction. <p> However, when k is large and d is constant, the number of coefficients is polynomial, while our method (like related methods such as that of [7]) still requires an exponential number of data-points. (One might then prefer the method of <ref> [4] </ref>, which takes time exponential in d but polynomial in k. However, this method works only in the context of learning from an oracle which one can query at whatever locations one pleases.) Different methods are thus needed for the large-k case.
Reference: [5] <author> E. Kaltofen, </author> <title> Polynomial factorization 1987-1991, </title> <booktitle> LATIN '92, </booktitle> <publisher> Springer LNCS, </publisher> <month> 583 </month> <year> (1992), </year> <pages> pp. 294-313. </pages>
Reference-contexts: But then Obs. 3.3 (d,c) tell us that Q fl as specified must exist and is efficiently findable. Efficient (randomized) algorithms also exist for factoring polynomials over finite fields <ref> [5] </ref>. Hence Algorithm 2.1 can indeed be implemented in time poly (n). It remains only to prove that y f (x 1 ; : : : ; x k ) must (with high probability) be a factor of Q fl . <p> Note that we have generalized from finite fields to any field over which one can efficiently factor polynomials. This class includes finite fields, the rational numbers, the real numbers, and the complex numbers <ref> [5] </ref>. Theorem 4.1.
Reference: [6] <author> M. A. Shokrollahi and H. Wasserman, </author> <title> Decoding algebraic-geometric codes beyond the error-correction bound, </title> <booktitle> to be presented at 35th Allerton Conf. Communication, Control, and Computing, 1997, and Int'l IEEE Inform. Theory Workshop, </booktitle> <year> 1998. </year> <note> Available at: http.cs.berkeley.edu/~halw/ goppa.ps </note>
Reference-contexts: Algebraic-geometric codes, which may be regarded as a generalization of Reed-Solomon codes, allow for arbitrarily long codes over a fixed field F which have excellent parametric performance. Can one then generalize high-noise reconstruction methods to the case of algebraic-geometric codes? <ref> [6] </ref> carries out such a generalization. 6.4 The Large-k Case. The lower-bound on t in Corollary 4.1 may be loosely upper-bounded by 2e 1+ k k k+1 . Let " denote the portion of correct data-points (" = t=n).
Reference: [7] <author> M. Sudan, </author> <title> Maximum likelihood decoding of Reed Solomon codes, </title> <booktitle> Proc. 37th IEEE FOCS, </booktitle> <pages> pp. 164-172, </pages> <year> 1996. </year>
Reference-contexts: Goldreich, Rubinfeld, et al. [4], using quite different methods, derive strong reconstruction results which, however, work only if the data is presented as an oracle which one can query at whatever locations one pleases. Finally Sudan <ref> [7, 8] </ref> was able to enhance the methods of [1], removing the artificial restriction. <p> Finally Sudan [7, 8] was able to enhance the methods of [1], removing the artificial restriction. For the case of univariate polynomials, Su-dan gives a surprisingly strong result <ref> [7, Theorem 5] </ref>: from an arbitrary collection of n distinct data-points, he efficiently reconstructs all degree-( d) polynomials that are consistent with d 2 (n + 1)=d bd=2c of the data-points. <p> He then turns to the case of multivariate polynomials and derives the following result (where our language is somewhat different from Sudan's): Problem 1.1. <ref> [7, Problem 2] </ref> We are given data-points (~x (1) ; y (1) ); : : : ;(~x (n) ; y (n) ) 2 F k fi F , where F is a field. <p> The problem is to find all polynomials f : F k ! F of total degree d that are consistent with t of the data-points. Theorem 1.1. <ref> [7, Theorem 10] </ref> If t &gt; (k + 1)(d + 1) k+1 n k (k+1) , then Problem 1.1 may be solved in time poly (n). A limitation of this result (particularly from a learning-theory perspective) is the condition here set in boldface type. <p> Sudan indeed notes that "the [multivariate] reconstruction problem is not fully solved," and also that the bound on t in Theorem 1.1 seems too large <ref> [7, p. 171] </ref>. Hence the current paper reformulates the problem so as to replace this restriction with a more natural "random sampling" requirement. <p> Our bound on t, regarded as a function of n, is O (n k+1 ). For k 2, this is superior to 3 1 1 k (k+1) ) bound of Theorem 1.1. We also require a lower-bound on jF j (as do <ref> [7] </ref> and related papers). This bound will be further discussed in x6.2. Algorithm 2.1 is essentially the same as Su-dan's Multivariate Algorithm [7, p. 169]. We observe that the algorithm's solution-set will contain at most L=d k+1 e q n=d k polynomials, so is suitably small. <p> For k 2, this is superior to 3 1 1 k (k+1) ) bound of Theorem 1.1. We also require a lower-bound on jF j (as do [7] and related papers). This bound will be further discussed in x6.2. Algorithm 2.1 is essentially the same as Su-dan's Multivariate Algorithm <ref> [7, p. 169] </ref>. We observe that the algorithm's solution-set will contain at most L=d k+1 e q n=d k polynomials, so is suitably small. The algorithm's efficiency and correctness will be proved in the following section. 3 Main Proof. 3.1 Preliminaries. <p> Note also that any equation which is linearly dependent on the others may be discarded as redundant. 2 Obs. 3.3 (a,b) then follow. A fundamental technique of <ref> [7] </ref> and related papers is that such homogeneous linear systems can be used to find bounded-degree polynomials having specified roots. <p> Are there alternative algorithms which work in cases for which Theorem 4.1 fails? 6.2 The Small-jF j Case. Our methods require lower-bounds on jF j. This is not surprising, as related papers (such as <ref> [3, 1, 7] </ref>) also require such bounds. Moreover, our bounds are not unreasonable: they are only polynomial in n, while jF j could quite naturally be even exponentially large. However, it would be desirable to have methods which work over arbitrarily small fields. <p> In 8 future research it may prove of interest to study what happens as jF j grows small, and if possible to develop alternative algorithms for this case. 6.3 Coding-Theory Applications. As discussed in <ref> [7] </ref>, univariate polynomial reconstruction methods may also be viewed as algorithms for decoding Reed-Solomon codes. <p> However, while such results might be of theoretical interest, the corresponding codes generally do not have good parametric performance. Moreover, the lower-bounds on jF j for the multivariate reconstruction results of <ref> [7] </ref> and the current paper would still prohibit jF j from remaining constant as n ! 1. Algebraic-geometric codes, which may be regarded as a generalization of Reed-Solomon codes, allow for arbitrarily long codes over a fixed field F which have excellent parametric performance. <p> However, when k is large and d is constant, the number of coefficients is polynomial, while our method (like related methods such as that of <ref> [7] </ref>) still requires an exponential number of data-points. (One might then prefer the method of [4], which takes time exponential in d but polynomial in k.
Reference: [8] <author> M. Sudan, </author> <title> Decoding of Reed Solomon codes beyond the error-correction bound, </title> <journal> J. Compl., </journal> <volume> 13 (1997), </volume> <pages> pp. 180-193. </pages>
Reference-contexts: Goldreich, Rubinfeld, et al. [4], using quite different methods, derive strong reconstruction results which, however, work only if the data is presented as an oracle which one can query at whatever locations one pleases. Finally Sudan <ref> [7, 8] </ref> was able to enhance the methods of [1], removing the artificial restriction.
References-found: 8

