URL: ftp://ftp.cs.uoregon.edu/pub/lo/metrics.ps.gz
Refering-URL: http://www.cs.uoregon.edu/research/DistributedComputing/archive.html
Root-URL: http://www.cs.uoregon.edu
Title: METRICS: A Tool for the Display and Analysis of Mappings in Message-passing Multicomputers  
Author: Virginia M. Lo Kurt Windisch and Rajen Datta 
Address: 97403-1202  
Affiliation: Dept. of Computer and Information Science University of Oregon Eugene, Oregon  
Note: Appears in Proceedings of the 6th Distributed Memory Computing Conference,  
Email: lo@cs.uoregon.edu  
Phone: 503-686-4408,  
Date: April 1991.  
Abstract: METRICS is designed to display the mapping in a clear, logical, and intuitive format so that the user can evaluate it quantitatively (through well-known empirical performance metrics) as well as visually (through the use of colors and spatial layout, particularly when the computation graph exhibits regularity). The contributions of METRICS include its rich underlying formalism, the Temporal Communication Graph, a hybrid between the static task graph and the DAG; its mechanisms for handling massive parallelism using subviews, scrolling, and hierarchical grouping; and the broad spectrum of mapping metrics used in the analysis of each mapping. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. A. Bailey and J. E. Cuny. </author> <title> Visual extensions to parallel programming languages. </title> <booktitle> In Languages and Compilers for Parallel Computing, </booktitle> <pages> pages 17-36, </pages> <month> August </month> <year> 1989. </year>
Reference-contexts: Parallel programming languages that provide this abstraction include OCCAM, Data Par--allel C, C and Fortran with communication extensions, and Dino. Programming environments in this domain include Prep-P [2], ORCA [5] , the Parallel Programming Environments Project <ref> [1] </ref>, and TIPS [12]. For these systems, the static task graph of Stone can be used to model the parallel computation. This is in contrast to systems for the parallelization of sequential code in which the computation is viewed as a DAG such as [3],[4],[10].
Reference: [2] <author> F. Berman and B. Stramm. Prep-p: </author> <title> Evolution and overview. </title> <type> Technical Report CS89-158, </type> <institution> Dept. of Computer Science, University of California at San Diego, </institution> <year> 1989. </year>
Reference-contexts: Parallel programming languages that provide this abstraction include OCCAM, Data Par--allel C, C and Fortran with communication extensions, and Dino. Programming environments in this domain include Prep-P <ref> [2] </ref>, ORCA [5] , the Parallel Programming Environments Project [1], and TIPS [12]. For these systems, the static task graph of Stone can be used to model the parallel computation.
Reference: [3] <author> J.C. Browne. </author> <title> Code: A unified approach to parallel programming. </title> <journal> IEEE Software, </journal> <volume> 6(4) </volume> <pages> 10-19, </pages> <month> July </month> <year> 1989. </year>
Reference: [4] <author> H. El-Rewini and T.G. Lewis. </author> <title> Scheduling parallel program tasks onto arbitrary target machines. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 9 </volume> <pages> 138-153, </pages> <year> 1990. </year>
Reference: [5] <author> W. G. Griswold, G. A. Harrison, D. Notkin, and L. Sny-der. </author> <title> Port ensembles: a communication abstraction for nonshared memory parallel programming. </title> <type> Technical report, </type> <institution> Dept. of Computer Science, University of Washing-ton, </institution> <year> 1989. </year>
Reference-contexts: Parallel programming languages that provide this abstraction include OCCAM, Data Par--allel C, C and Fortran with communication extensions, and Dino. Programming environments in this domain include Prep-P [2], ORCA <ref> [5] </ref> , the Parallel Programming Environments Project [1], and TIPS [12]. For these systems, the static task graph of Stone can be used to model the parallel computation.
Reference: [6] <author> D.D. Kandlur and K.G. Shin. </author> <title> Traffic routing for multi-computer networks with virtual cut-through capability,. </title> <booktitle> In Preceedings of the 10th International Conference on Distributed Computer Systems,, </booktitle> <pages> pages 398-405, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: Note that we measure load as the volume of data transferred or the number of messages. Total IPC : The sum of all interprocessor communication costs. Intraprocessor communication costs are assumed to be negligible. Kandlur/Shin metric <ref> [6] </ref>: T (R) = e2E ( m2M;e2R (m) W (m)) 2 where, T (R) is the cost of the routing function R, E is the set of links in the architecture, M is the set of messages, and W (x) is the weight of a message x, R (x) represents the
Reference: [7] <author> L. Lamport. </author> <title> Time, clocks, and the ordering of events in a distributed system. </title> <journal> Communications of the ACM, </journal> <volume> 21(7) </volume> <pages> 558-565, </pages> <month> July </month> <year> 1978. </year>
Reference-contexts: The contributions of METRICS include * The flexibility and power of its underlying formalism, the Temporal Communication Graph (TCG) [8], a hybrid between the static task graph of [11], the precedence-contrained DAG model, and Lam port's process-time graphs <ref> [7] </ref>. * Its mechanisms for handling massive parallelism: subviews, scrolling, and hierarchical grouping. * Its capacity to be used in two arenas: within parallel programming environments as a tool to aid the applications programmer and within the research community for the testing and analysis of mapping algorithms. * The broad spectrum
Reference: [8] <author> V. M. Lo. </author> <title> Temporal communication graphs: A new graph theoretic model for mapping and scheduling in distributed memory systems. </title> <booktitle> In Proceedings 6th Distributed Memory Computing Conference, </booktitle> <month> April </month> <year> 1991. </year>
Reference-contexts: The contributions of METRICS include * The flexibility and power of its underlying formalism, the Temporal Communication Graph (TCG) <ref> [8] </ref>, a hybrid between the static task graph of [11], the precedence-contrained DAG model, and Lam port's process-time graphs [7]. * Its mechanisms for handling massive parallelism: subviews, scrolling, and hierarchical grouping. * Its capacity to be used in two arenas: within parallel programming environments as a tool to aid the
Reference: [9] <author> V. M. Lo, S. Rajopadhye, S. Gupta, D. Keldsen, M. A. Mo-hamed, and J. Telle. OREGAMI: </author> <title> Software tools for mapping parallel algorithms to parallel architectures. </title> <booktitle> In Proceedings 1990 International Conference on Parallel Processing, </booktitle> <pages> pages II:88-92, </pages> <month> August </month> <year> 1990. </year>
Reference-contexts: of performance criteria, and allows the user to interactively inspect and modify the mapping. fl This research is sponsored by NSF grant MIP-9108528 and the Oregon Advanced Computing Institute y Partially supported by NSF grant CCR-8808532 z Partially supported by NSF REU grant METRICS is one component of the OREGAMI <ref> [9] </ref> tools for mapping parallel computations to parallel architectures. OREGAMI addresses the mapping problem by exploiting regularity and by allowing the user to guide and evaluate mapping decisions made by its efficient combinatorial algorithms.
Reference: [10] <author> V. Sakar. </author> <title> Partitioning and scheduling parallel programs for execution on multiprocessors. </title> <type> Technical report, Ph.d. Thesis, </type> <institution> Dept. of Computer Science, Stanford University, </institution> <year> 1987. </year>
Reference: [11] <author> H. S. Stone. </author> <title> Multiprocessor scheduling with the aid of network flow algorithms. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-3(1):85-93, </volume> <month> January </month> <year> 1977. </year>
Reference-contexts: The contributions of METRICS include * The flexibility and power of its underlying formalism, the Temporal Communication Graph (TCG) [8], a hybrid between the static task graph of <ref> [11] </ref>, the precedence-contrained DAG model, and Lam port's process-time graphs [7]. * Its mechanisms for handling massive parallelism: subviews, scrolling, and hierarchical grouping. * Its capacity to be used in two arenas: within parallel programming environments as a tool to aid the applications programmer and within the research community for the
Reference: [12] <author> A. Wagner, S. Chanson, N. Goldstein, J. Jiang, H. Larsen, and H. Sreekantaswamy. </author> <title> Tips: Transputer-based interactive parallelizing system. </title> <type> Technical report, </type> <institution> Dept. of Computer Science, University of British Columbia, </institution> <year> 1990. </year> <title> and metrics phases) mapped to the 3-dim hypercube </title>
Reference-contexts: Parallel programming languages that provide this abstraction include OCCAM, Data Par--allel C, C and Fortran with communication extensions, and Dino. Programming environments in this domain include Prep-P [2], ORCA [5] , the Parallel Programming Environments Project [1], and TIPS <ref> [12] </ref>. For these systems, the static task graph of Stone can be used to model the parallel computation. This is in contrast to systems for the parallelization of sequential code in which the computation is viewed as a DAG such as [3],[4],[10].
References-found: 12

