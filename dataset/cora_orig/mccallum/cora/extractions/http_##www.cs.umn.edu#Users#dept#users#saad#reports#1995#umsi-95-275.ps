URL: http://www.cs.umn.edu/Users/dept/users/saad/reports/1995/umsi-95-275.ps
Refering-URL: http://www.cs.umn.edu/Users/dept/users/saad/reports/1995/
Root-URL: http://www.cs.umn.edu
Title: Solution of Large Eigenvalue Problems in Electronic Structure Calculations  
Author: Y. Saad, A. Stathopoulos, J. Chelikowsky, K. Wu, and S. Ogut 
Note: Parallel implementations are also discussed.  
Date: December 1995  
Abstract: Predicting the structural and electronic properties of complex systems is one of the outstanding problems in condensed matter physics. Central to most methods used in molecular dynamics is the repeated solution of large eigenvalue problems. This paper reviews the source of these eigenvalue problems, describes some techniques for solving them, and addresses the difficulties and challenges which are faced. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Baroni and P. Giannozzi, </author> <title> Towards very large-scale electronic-structure calculations, </title> <journal> Europhys. Lett. </journal> <volume> 17, </volume> <month> 547 </month> <year> (1992). </year>
Reference-contexts: A number of techniques have been developed based on using this observation <ref> [1, 18, 26] </ref>. In the following we will only sketch the main ideas for the purpose of illustrating possible new linear algebra problems of interest. In the so-called Order-n methods, an approximation to the projector P in (10) is constructed without knowledge of eigenvectors.
Reference: [2] <author> J. R. Chelikowsky, N. Troullier, and Y. Saad. </author> <title> Finite-difference-pseudopotential method: electronic structure calculations without a basis. </title> <journal> Phys. Rev. Lett., </journal> <volume> 72 </volume> <pages> 1240-3, </pages> <year> 1994. </year>
Reference-contexts: Besides these physical problems, the eigenvalue problem can be expensive to solve mainly because the matrix is dense. Although this dense matrix is not explicitly formed, two FFTs must be carried out at each step of the iteration procedure. This can be costly, especially in high performance environments <ref> [2] </ref>. In recent years, finite difference techniques have started to challenge planewave techniques. Surprisingly, these methods have only appeared sparingly in the area the last half century [15, 10]. Our approach combines finite differences with a high-order expansion of the derivatives [2, 11, 4]. <p> In recent years, finite difference techniques have started to challenge planewave techniques. Surprisingly, these methods have only appeared sparingly in the area the last half century [15, 10]. Our approach combines finite differences with a high-order expansion of the derivatives <ref> [2, 11, 4] </ref>. Since the pseudo-wavefunctions for isolated atoms are smooth, the wave-functions can be expanded locally in Taylor series and a good approximation is expected as with plane-waves.
Reference: [3] <author> J.R. Chelikowsky and M. L. Cohen, </author> <title> Handbook on Semiconductors, edited by P. </title> <editor> T. </editor> <publisher> Landsberg (Elsevier, </publisher> <address> Amsterdam, </address> <year> 1992), </year> <note> Vol. 1, </note> <editor> p. </editor> <volume> 59. </volume> <pages> 14 </pages>
Reference-contexts: An approximation to (H I) 1 can be easily built this way. However, there are several disadvantages to this approach. In case of non-periodic systems such as clusters, liquids or glasses, the plane-wave basis can only be applied if 4 a supercell method <ref> [3] </ref> is employed. This is very similar to the situation with spectral methods. Spectral methods are excellent at solving problems with rectangular geometries which have periodic boundary conditions. The supercell technique artificially repeats the localized configuration to impose periodicity on the system.
Reference: [4] <author> D. T. Colbert and W. H. Miller. </author> <title> A novel discrete variable representation for quantum mechanical reactive scattering via the S-matrix Kohn method. </title> <journal> J. Comput. Phys., </journal> <volume> 96 </volume> <pages> 1982-1991, </pages> <year> 1992. </year>
Reference-contexts: In recent years, finite difference techniques have started to challenge planewave techniques. Surprisingly, these methods have only appeared sparingly in the area the last half century [15, 10]. Our approach combines finite differences with a high-order expansion of the derivatives <ref> [2, 11, 4] </ref>. Since the pseudo-wavefunctions for isolated atoms are smooth, the wave-functions can be expanded locally in Taylor series and a good approximation is expected as with plane-waves.
Reference: [5] <author> J.R. Chelikowsky, N. Troullier, K. Wu, and Y. Saad, </author> <title> Higher Order Finite Difference Pseudopotential Method: An Application to Diatomic Molecules, </title> <journal> Phys. Rev. </journal> <volume> B 50 </volume> <month> 11355-64 </month> <year> (1994). </year>
Reference-contexts: The matrix is not formed explicitly, but matrix-vector product operations are performed with the help of FFT transforms. An alternative to this approach based on high-order finite difference schemes has recently been advocated. For localized systems, it has proved to be as accurate and more efficient than plane-wave techniques <ref> [5, 6, 14, 13, 6] </ref>. The matrices resulting from both finite difference methods and plane-wave techniques are large, and the number of eigenvalues and eigenvectors required fl Work supported by NSF grant DMR-9217287 and by the Minnesota Supercomputer Institute 1 is proportional to the number of atoms in the system.
Reference: [6] <author> J. R. Chelikowsky, N. R. Troullier, X. Jing, D. Dean, N. Binggeli, K. Wu, and Y. Saad. </author> <title> Algorithms for the structural properties of clusters. </title> <journal> Computer Physics Communications, </journal> <volume> 85 </volume> <pages> 325-335, </pages> <year> 1995. </year>
Reference-contexts: The matrix is not formed explicitly, but matrix-vector product operations are performed with the help of FFT transforms. An alternative to this approach based on high-order finite difference schemes has recently been advocated. For localized systems, it has proved to be as accurate and more efficient than plane-wave techniques <ref> [5, 6, 14, 13, 6] </ref>. The matrices resulting from both finite difference methods and plane-wave techniques are large, and the number of eigenvalues and eigenvectors required fl Work supported by NSF grant DMR-9217287 and by the Minnesota Supercomputer Institute 1 is proportional to the number of atoms in the system. <p> Both potentials V H and V xc have a local character and are represented by diagonal matrices in the discrete form of the problem. The ionic potential is more complex, consisting of both a local and a non-local term <ref> [6] </ref>: V ion = a X V l (r a ) lm &gt; Z where &lt; V a lm &gt; is the normalization factor, &lt; V a Z Here, the superscript a denotes an atom in position R a , r a = r R a , and the functions u <p> This is done by solving an artificial time-dependent problem of the form <ref> [6] </ref>, m dt In the above equation, v is the velocity of the given particle, F is the force acting on it, and fl is some damping (viscosity) coefficient.
Reference: [7] <author> J. Daniel, W. B. Gragg, L. Kaufman, and G. W. Stewart, </author> <title> Reorthogonalization and stable algorithms for updating the Gram-Schmidt QR factorization, </title> <journal> Math. Comput. </journal> , <volume> 30, </volume> <month> 772 </month> <year> (1976). </year>
Reference-contexts: Nonetheless, it is a crucial one. Solutions cannot be obtained if the basis vectors loose their mutual orthogonality. For that purpose, a reorthogonaliza-tion procedure has been employed similar to the one proposed in <ref> [7] </ref>. Whenever the norm of a vector is reduced below a threshold during the orthogonalization, the procedure is repeated. The procedure is cheaper than full reorthogonalization, yet provides adequate accuracy.
Reference: [8] <author> E.R. Davidson, </author> <title> The iterative calculation of a few of the lowest eigenvalues and corresponding eigenvectors of large real-symmetric matrices, </title> <journal> J. Comput. Phys. </journal> <volume> 17, </volume> <month> 87 </month> <year> (1975). </year>
Reference-contexts: In this paper, some of the efforts for meeting these demands are described. We present an eigenvalue solver based on the preconditioned Lanczos (generalized Davidson) method <ref> [8, 9, 20] </ref> which can tackle hundreds of eigenpairs. We also address several issues such as efficient preconditioning, matrix-vector multiplication, orthogonalization, as well as robustness. <p> Second, the separation of the eigenvalues which determines the rate of convergence of iterative solvers becomes increasingly poor as the matrix size increases. Preconditioning techniques attempt to alleviate this problem. The Davidson method is a popular preconditioning variant of the Lanczos iteration 5 <ref> [8, 21] </ref>. In its original form it used only diagonal (Jacobi) preconditioning, and some general purpose Davidson codes are available [24]. In this application, a code based on the preconditioned Lanczos (generalized Davidson [20]) has been developed. This code addresses also the problems mentioned above.
Reference: [9] <author> Ernest R. Davidson. </author> <title> Super-matrix methods. </title> <journal> Computer Physics Communications, </journal> <volume> 53 </volume> <pages> 49-60, </pages> <year> 1989. </year>
Reference-contexts: In this paper, some of the efforts for meeting these demands are described. We present an eigenvalue solver based on the preconditioned Lanczos (generalized Davidson) method <ref> [8, 9, 20] </ref> which can tackle hundreds of eigenpairs. We also address several issues such as efficient preconditioning, matrix-vector multiplication, orthogonalization, as well as robustness.
Reference: [10] <author> D. E. Ellis and G. S. </author> <title> Painter, </title> <journal> Phys. Rev. B, </journal> <volume> 2 2887 (1970). </volume>
Reference-contexts: This can be costly, especially in high performance environments [2]. In recent years, finite difference techniques have started to challenge planewave techniques. Surprisingly, these methods have only appeared sparingly in the area the last half century <ref> [15, 10] </ref>. Our approach combines finite differences with a high-order expansion of the derivatives [2, 11, 4]. Since the pseudo-wavefunctions for isolated atoms are smooth, the wave-functions can be expanded locally in Taylor series and a good approximation is expected as with plane-waves.
Reference: [11] <author> B. Fornberg and D. M. Sloan. </author> <title> A review of pseudospectral methods for solving partial differential equations. </title> <journal> Acta Numerica, </journal> <pages> 203-267, </pages> <year> 1994. </year>
Reference-contexts: In recent years, finite difference techniques have started to challenge planewave techniques. Surprisingly, these methods have only appeared sparingly in the area the last half century [15, 10]. Our approach combines finite differences with a high-order expansion of the derivatives <ref> [2, 11, 4] </ref>. Since the pseudo-wavefunctions for isolated atoms are smooth, the wave-functions can be expanded locally in Taylor series and a good approximation is expected as with plane-waves.
Reference: [12] <author> A. Geist, A. Beguelin, J. Dongarra, W. Jiang, R. Manchek and V. Sunderam, </author> <title> PVM3 Users's Guide and Reference Manual, ORNL, </title> <publisher> TM-12187. </publisher>
Reference-contexts: These improvements must be realized with parallel computing in mind. There are few limits in the gains that can be achieved through parallel processing, safe for the need to use appropriate algorithms. 4.1 Parallel environment and models The parallel implementation of the current application uses the PVM communication library <ref> [12, 25] </ref>. The parallel environment used for the development is a cluster of four Silicon Graphics Power Challenge workstations, each with four processing elements, interconnected through HiPPI and Fiber channels. A cluster of eight IBM 590 workstations, interconnected through an A.T.M.
Reference: [13] <author> X. Jing, N. R. Troullier, J. R. Chelikowsky, K. Wu, and Y. Saad. </author> <title> Vibrational modes of silicon nanostructures. Solid State Communication, </title> <address> 96(4):231, </address> <year> 1995. </year>
Reference-contexts: The matrix is not formed explicitly, but matrix-vector product operations are performed with the help of FFT transforms. An alternative to this approach based on high-order finite difference schemes has recently been advocated. For localized systems, it has proved to be as accurate and more efficient than plane-wave techniques <ref> [5, 6, 14, 13, 6] </ref>. The matrices resulting from both finite difference methods and plane-wave techniques are large, and the number of eigenvalues and eigenvectors required fl Work supported by NSF grant DMR-9217287 and by the Minnesota Supercomputer Institute 1 is proportional to the number of atoms in the system.
Reference: [14] <author> X. Jing, N. R. Troullier, D. Dean, N. Binggeli, J. R. Chelikowsky, K. Wu, and Y. Saad. </author> <title> Ab initio molecular dynamics simulations of Si clusters using the higher-order finite-difference-pseudopotential method. </title> <journal> Phys. Rev. B, </journal> <volume> 50 </volume> <pages> 12234-7, </pages> <year> 1994. </year>
Reference-contexts: The matrix is not formed explicitly, but matrix-vector product operations are performed with the help of FFT transforms. An alternative to this approach based on high-order finite difference schemes has recently been advocated. For localized systems, it has proved to be as accurate and more efficient than plane-wave techniques <ref> [5, 6, 14, 13, 6] </ref>. The matrices resulting from both finite difference methods and plane-wave techniques are large, and the number of eigenvalues and eigenvectors required fl Work supported by NSF grant DMR-9217287 and by the Minnesota Supercomputer Institute 1 is proportional to the number of atoms in the system.
Reference: [15] <author> G. E. Kimball and G. H. </author> <title> Shortley, </title> <journal> Phys. Rev., </journal> <volume> 45, </volume> <month> 815 </month> <year> (1934). </year>
Reference-contexts: This can be costly, especially in high performance environments [2]. In recent years, finite difference techniques have started to challenge planewave techniques. Surprisingly, these methods have only appeared sparingly in the area the last half century <ref> [15, 10] </ref>. Our approach combines finite differences with a high-order expansion of the derivatives [2, 11, 4]. Since the pseudo-wavefunctions for isolated atoms are smooth, the wave-functions can be expanded locally in Taylor series and a good approximation is expected as with plane-waves.
Reference: [16] <author> C. M. Kirkpatrick and D. S. Marynick. </author> <title> Localized molecular orbital studies of transition metal complexes. II. simple -accepting ligands. </title> <journal> Journal of Computational Chemistry, </journal> <volume> 6 </volume> <pages> 142-147. </pages>
Reference-contexts: What is sought is the ground state corresponding to the minimum energy level, among all possible topological structures of the cluster. The typical approach in this context uses simulated annealing <ref> [16] </ref>. The goal is to find a `steady-state' distribution, meaning, for p particles, find locations R 1 ; : : : ; R p to minimize the total energy E (R 1 ; R 2 ; : : : ; R p ) of the system.
Reference: [17] <author> W. Kohn and L. J. </author> <title> Sham, </title> <journal> Phys. Rev., </journal> <volume> 140, </volume> <month> A:1133 </month> <year> (1965). </year>
Reference-contexts: In its original form the operator H is very complex, involving sums over all electrons and nuclei, Lapla-cian related to each nucleus, etc. However, most theories of condensed matter systems make two fundamental approximations which make the problem more tractable. These are the Born-Oppenheimer approximation and the one-electron approximation <ref> [17] </ref>. <p> The above problem can be viewed as a nonlinear eigenvalue problem because of the nonlinear dependence of the operator on the left-hand side on the eigenfunctions. 2 With the local density approximation theory <ref> [17] </ref>, and the use of Pseudo-potentials, the potential V tot is simplified to a summation of three distinct terms, specifically, V tot = V ion + V H + V xc (4) where V ion is the ionic potential, V H is the Hartree potential, and V xc is the exchange-correlation
Reference: [18] <author> X.-P. Li, R. W. Nunes, and D. </author> <title> Vanderbilt, Density-matrix electronic-structure method with linear system-size scaling, </title> <journal> Phys. Rev. </journal> <volume> B 47, </volume> <month> 10891 </month> <year> (1993). </year> <month> 15 </month>
Reference-contexts: A number of techniques have been developed based on using this observation <ref> [1, 18, 26] </ref>. In the following we will only sketch the main ideas for the purpose of illustrating possible new linear algebra problems of interest. In the so-called Order-n methods, an approximation to the projector P in (10) is constructed without knowledge of eigenvectors. <p> The missing constraint is to force 13 P to be a projector. As it turns out, this can be achieved by forcing its eigenvalues to be between zero and one <ref> [18] </ref>. The minimization will yield a matrix P which has eigenvalues equal to either one or zero, thus satisfying the desired idempotent constraint automatically. One strategy that has been used in [18] for this purpose is to seek P in the form P = 3S 2 2S 3 If the eigenvalues <p> As it turns out, this can be achieved by forcing its eigenvalues to be between zero and one <ref> [18] </ref>. The minimization will yield a matrix P which has eigenvalues equal to either one or zero, thus satisfying the desired idempotent constraint automatically. One strategy that has been used in [18] for this purpose is to seek P in the form P = 3S 2 2S 3 If the eigenvalues of S are in the range [0:5; 1:5] this transformation will map them into [0,1].
Reference: [19] <author> B. Liu, </author> <title> in: Numerical Algorithms in Chemistry: Algebraic Methods, </title> <editor> eds. C. Moler and I. </editor> <address> Shavitt, </address> <institution> LBL-8158 Lawrence Berkeley Laboratory (1978). </institution>
Reference-contexts: The issue of targeting is handled by the use of a window of possible targets from the set of basis vectors. The window size is p &lt; m, and depending on a user option, up to p eigenvectors can be targeted simultaneously (block Davidson <ref> [19] </ref>). The robustness of the code is enhanced by carefully selecting and locking the converged eigenpairs from the targeted ones. This scheme significantly reduces the possibility of "missing" an eigenpair. Finally, orthogonalization is a very expensive part of the code since it involves all converged and basis vectors.
Reference: [20] <author> R.B. Morgan and D.S. Scott, </author> <title> Generalizations of Davidson's Method for Computing Eigenvalues of Sparse Symmetric Matrices, </title> <journal> SIAM J. Sci. Stat. Comput. </journal> <volume> 7, </volume> <month> 817 </month> <year> (1986). </year>
Reference-contexts: In this paper, some of the efforts for meeting these demands are described. We present an eigenvalue solver based on the preconditioned Lanczos (generalized Davidson) method <ref> [8, 9, 20] </ref> which can tackle hundreds of eigenpairs. We also address several issues such as efficient preconditioning, matrix-vector multiplication, orthogonalization, as well as robustness. <p> The Davidson method is a popular preconditioning variant of the Lanczos iteration 5 [8, 21]. In its original form it used only diagonal (Jacobi) preconditioning, and some general purpose Davidson codes are available [24]. In this application, a code based on the preconditioned Lanczos (generalized Davidson <ref> [20] </ref>) has been developed. This code addresses also the problems mentioned above. The algorithm is sketched below for the case where the smallest eigenvalue is being computed. Algorithm 3.1 Preconditioned Lanczos 0. Choose an initial unit vector v 1 . 1. Until convergence Do: 2.
Reference: [21] <author> Y. Saad, </author> <title> Numerical Methods for Large Eigenvalue Problems (Manchester Univ. </title> <publisher> Press, </publisher> <address> Manchester, </address> <year> 1992). </year>
Reference-contexts: Second, the separation of the eigenvalues which determines the rate of convergence of iterative solvers becomes increasingly poor as the matrix size increases. Preconditioning techniques attempt to alleviate this problem. The Davidson method is a popular preconditioning variant of the Lanczos iteration 5 <ref> [8, 21] </ref>. In its original form it used only diagonal (Jacobi) preconditioning, and some general purpose Davidson codes are available [24]. In this application, a code based on the preconditioned Lanczos (generalized Davidson [20]) has been developed. This code addresses also the problems mentioned above.
Reference: [22] <author> Y. Saad and A. V. Malevsky, P-SPARSLIB: </author> <title> A Portable Library of Distributed Memory Sparse Iterative Solvers, </title> <institution> University of Minnesota Supercomputer Institute, </institution> <note> Research Report 95/180, </note> <month> September </month> <year> 1995. </year>
Reference-contexts: However, some of the neighbors of the local subdomain may reside on different processors, and communication is necessary. For this reason, a special preprocessing phase has been implemented, which is a special case of the PSPARSLIB library <ref> [22] </ref>. During the setup of the non-local information by the master, the slaves locate which of their rows are needed in the stencils of other processors. Data structures are built for all the information that needs to be communicated among the appropriate processors.
Reference: [23] <author> Y. Saad and K. Wu. </author> <title> Design of an iterative solution module for a parallel matrix library (P SPARSLIB). </title> <editor> In W. Schonauer, editor, </editor> <booktitle> Proceedings of IMACS conference, </booktitle> <address> Georgia, </address> <year> 1994, 1995. </year> <type> Was TR 94-59, </type> <institution> Department of Computer Science, University of Minnesota. </institution>
Reference: [24] <author> A. Stathopoulos and C. F. Fischer, </author> <title> A Davidson program for finding a few selected extreme eigenpairs of a large, sparse, real, symmetric matrix, </title> <journal> Comput. Phys. Commun. </journal> <volume> 79, </volume> <month> 268 </month> <year> (1994). </year>
Reference-contexts: Preconditioning techniques attempt to alleviate this problem. The Davidson method is a popular preconditioning variant of the Lanczos iteration 5 [8, 21]. In its original form it used only diagonal (Jacobi) preconditioning, and some general purpose Davidson codes are available <ref> [24] </ref>. In this application, a code based on the preconditioned Lanczos (generalized Davidson [20]) has been developed. This code addresses also the problems mentioned above. The algorithm is sketched below for the case where the smallest eigenvalue is being computed. Algorithm 3.1 Preconditioned Lanczos 0.
Reference: [25] <author> A. Stathopoulos and A. Ynnerman and C. F. Fischer, </author> <title> A PVM implementation of the MCHF atomic structure package, The International Journal of Supercomputer Applications and High Performance Computing, in print. </title>
Reference-contexts: These improvements must be realized with parallel computing in mind. There are few limits in the gains that can be achieved through parallel processing, safe for the need to use appropriate algorithms. 4.1 Parallel environment and models The parallel implementation of the current application uses the PVM communication library <ref> [12, 25] </ref>. The parallel environment used for the development is a cluster of four Silicon Graphics Power Challenge workstations, each with four processing elements, interconnected through HiPPI and Fiber channels. A cluster of eight IBM 590 workstations, interconnected through an A.T.M.
Reference: [26] <author> A. P. Seitsonen, M. J. Puska, and R. M. Nieminen, </author> <title> Real-space electronic-structure calculations: Combination of the finite-difference and conjugate-gradient methods, </title> <journal> Phys. Rev. </journal> <volume> B , 51, </volume> <month> 14057 </month> <year> (1995). </year>
Reference-contexts: A number of techniques have been developed based on using this observation <ref> [1, 18, 26] </ref>. In the following we will only sketch the main ideas for the purpose of illustrating possible new linear algebra problems of interest. In the so-called Order-n methods, an approximation to the projector P in (10) is constructed without knowledge of eigenvectors.
Reference: [27] <author> C. H. Tong, T. F. Chan, and C. C. J. Kuo. </author> <title> Multilevel filtering preconditioners: extensions to more general elliptic problems. </title> <journal> SIAM J. Sci. Stat. Comput., </journal> <volume> 13 </volume> <pages> 227-242, </pages> <year> 1992. </year>
Reference-contexts: Also, FFT transforms of two vectors are needed at each step adding on the expense of the preconditioned Lanczos. One preconditioner used in our approach is based on a filtering idea and the fact that the Laplacian is an elliptic operator <ref> [27] </ref>. The eigenvectors corresponding to the few lowest eigenvalues of r 2 are smooth functions. Physically, the wavefunctions corresponding to the lowest occupied states are smoothly varying functions.
Reference: [28] <author> N. R Troullier and J. L. Martins, </author> <title> Efficient pseudopotentials for plan-wave calculations. </title> <journal> Phys. Rev. </journal> <volume> B 43 </volume> <pages> 1993-1997, </pages> <year> 1991. </year> <month> 16 </month>
Reference-contexts: Second, it is easy to precondition the resulting matrix in Fourier space by exploiting the fact that a smaller subset of planewaves gives a good approximation to the large matrix. One technique that has been used with success <ref> [28] </ref> is to approximate the desired eigenvalues by using a smaller planewave basis, and the larger ones by using the eigenvalues of the Laplacian ignoring the potential terms. An approximation to (H I) 1 can be easily built this way. However, there are several disadvantages to this approach. <p> One strategy is to focus on this part of the Hamiltonian. In the earlier plane-wave version of the code, subspace iteration with Jacobi preconditioning was used <ref> [28] </ref>. This worked well because of the diagonal form of the Laplacian in Fourier space. In real space, the Laplacian consists of a number of diagonals and Jacobi preconditioning is not effective. An idea would be to solve only the Laplacian in Fourier space.
References-found: 28

