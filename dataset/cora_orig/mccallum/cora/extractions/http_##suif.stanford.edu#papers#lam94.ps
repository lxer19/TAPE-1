URL: http://suif.stanford.edu/papers/lam94.ps
Refering-URL: http://suif.stanford.edu/papers/papers.html
Root-URL: 
Title: Locality Optimizations for Parallel Machines  
Author: Monica S. Lam 
Address: CA 94305  
Affiliation: Computer Systems Laboratory Stanford University,  
Abstract: This paper focuses on the problem of locality optimizations for high-performance uniprocessor and multiprocessor systems. It shows that the problems of minimizing interprocessor communication and optimizing cache locality can be formulated in a similar manner. It outlines the algorithms to optimize for the various levels of the memory hierarchy simultaneously.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> S. P. Amarasinghe and M. S. Lam. </author> <title> Communication optimization and code generation for distributed memory machines. </title> <booktitle> In Proceedings of the SIGPLAN '93 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 126-138, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: This paper focuses on the central problem of how to optimize the locality and parallelism in a program for high-performance systems. In this paper, we will focus mainly on the rationale behind the design of the algorithms; details on the algorithms can be found in other papers <ref> [1, 3, 8, 10, 11] </ref>. This paper offers a unified view of locality optimization at various levels of the memory hierarchy. Our treatment of the problem of minimizing interprocessor communication is similar to that of minimizing cache misses. <p> Code Generation. Finally, the compiler generates the SPMD (Single Program Multiple Data) program to be run on each processor. It involves generating the appropriate computation and communication code for each processor, translating global addresses to local or restructured data addresses, and managing the communicated data. Our code generation techniques <ref> [1] </ref> are based on Ancourt and Irigion's polyhedron-scanning techniques [2]. We use sets of inequalities to represent computation to be executed in each processor, mappings from the data and computation to the processors, as well as necessary communication. <p> The various code generation problems are solved by projecting various polyhedra represented by the system of inequalities onto lower-dimensional spaces in different orders <ref> [1] </ref>. 3 Optimizations at the Multiprocessor Level Our compiler optimizations are targeted at the domain of dense matrix computations.
Reference: 2. <author> C. Ancourt and F. Irigoin. </author> <title> Scanning polyhedra with DO loops. </title> <booktitle> In Proceedings of the Third ACM/SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <pages> pages 39-50, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: It involves generating the appropriate computation and communication code for each processor, translating global addresses to local or restructured data addresses, and managing the communicated data. Our code generation techniques [1] are based on Ancourt and Irigion's polyhedron-scanning techniques <ref> [2] </ref>. We use sets of inequalities to represent computation to be executed in each processor, mappings from the data and computation to the processors, as well as necessary communication.
Reference: 3. <author> J. M. Anderson and M. S. Lam. </author> <title> Global optimizations for parallelism and locality on scalable parallel machines. </title> <booktitle> In Proceedings of the SIGPLAN '93 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 112-125, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: This paper focuses on the central problem of how to optimize the locality and parallelism in a program for high-performance systems. In this paper, we will focus mainly on the rationale behind the design of the algorithms; details on the algorithms can be found in other papers <ref> [1, 3, 8, 10, 11] </ref>. This paper offers a unified view of locality optimization at various levels of the memory hierarchy. Our treatment of the problem of minimizing interprocessor communication is similar to that of minimizing cache misses. <p> Our ap Fig. 1. Memory layout of (a) a two-dimensional array and (b) a blocked two-dimensional array proach is to use a greedy algorithm that starts by optimizing the most frequently executed parts of the code first <ref> [3] </ref>. It tries to find a mapping that incurs no communication at all and introduces communication only when necessary. In this way, the communication is placed away from the inner loops.
Reference: 4. <author> J. H. Hennessy and D. A. Patterson. </author> <title> Computer Architecture: A Quantitative Approach. </title> <publisher> Morgan Kaufmann Publishers, </publisher> <year> 1990. </year>
Reference-contexts: Memory performance is an issue not just for large-scale parallel systems but also for uniprocessors. In the last decade, microprocessor speeds have been improving at a phenomenal rate of 50% to 100% every year <ref> [4] </ref>. While the capacity of memory tracks the improvement of processors by quadrupling every three years, the decrease of 7% per year in memory access time is insufficient to keep up with the growth in processor performance [4]. <p> have been improving at a phenomenal rate of 50% to 100% every year <ref> [4] </ref>. While the capacity of memory tracks the improvement of processors by quadrupling every three years, the decrease of 7% per year in memory access time is insufficient to keep up with the growth in processor performance [4]. This gap between processor and memory speeds is often bridged by not just one, but two levels of caches, with typical access ratios of 1:10:50 between the first-level cache, second-level cache and local memory. This processor-memory gap is expected to widen further in the future.
Reference: 5. <author> High Performance Fortran Forum. </author> <title> High Performance Fortran Language Specification, </title> <month> January </month> <year> 1993. </year> <note> Draft Version 1.0. </note>
Reference-contexts: Our compiler uses two basic kinds of mapping functions: affine transformations and blocking. These two mapping techniques together cover many of the common mappings used in practice. For example, those supported by High-Performance FORTRAN (HPF) language <ref> [5] </ref> are a subset of the mappings in our domain. Affine mappings are specified by a linear transformation and a constant vector. The blocking technique groups contiguous iterations or array elements along one or more dimensions together into a larger unit. Blocking creates a hierarchy in the domain.
Reference: 6. <author> D. Lenoski, K. Gharachorloo, J. Laudon, A. Gupta, J. Hennessy, M. Horowitz, and M. Lam. </author> <title> The Stanford DASH Multiprocessor. </title> <journal> IEEE Computer, </journal> <volume> 25(3) </volume> <pages> 63-79, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: Machines such as the Kendall Square KSR-1 or the Stanford DASH multiprocessors <ref> [6] </ref> allow software to access remote data directly via normal load and store operations and the hardware automatically caches the data locally. Systems such as the Intel Paragon and the Thinking Machines' CM-5 require the software to issue communication operations and manage the hierarchy explicitly.
Reference: 7. <author> E. E. Rothberg M. S. Lam and M. E. Wolf. </author> <title> The cache performance and optimizations of blocked algorithms. </title> <booktitle> In Fourth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS IV), </booktitle> <pages> pages 63-74, </pages> <month> Apr. </month> <year> 1991. </year>
Reference-contexts: Practically all caches are either direct-mapped or have a small set-associativity. Set-associativity is particularly troublesome for numerical applications because regularly strided accesses often cause recurring conflict misses. For example, the performance of blocked algorithms can be very erratic and are highly dependent on the particular matrix sizes <ref> [7] </ref>. One simple way to minimize cache conflicts is to place the data used by the same processor, and in the same localized iteration space, in contiguous memory locations.
Reference: 8. <author> T. C. Mowry, M. S. Lam, and A. Gupta. </author> <title> Design and evaluation of a compiler algorithm for prefetching. </title> <booktitle> In Proceedings of the Fifth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 62-73, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: In a study based on a simulation of programs from standard numerical benchmark suites on a typical uniprocessor architecture, we found that it is not uncommon for processors to spend over half of their time stalled for memory accesses <ref> [8] </ref>. While previous generations of software tend to ignore the presence of caches, optimizing the cache performance is likely to pay off for today's high-performance machines. Improving a program's locality of reference is even more important for multiprocessors. <p> This paper focuses on the central problem of how to optimize the locality and parallelism in a program for high-performance systems. In this paper, we will focus mainly on the rationale behind the design of the algorithms; details on the algorithms can be found in other papers <ref> [1, 3, 8, 10, 11] </ref>. This paper offers a unified view of locality optimization at various levels of the memory hierarchy. Our treatment of the problem of minimizing interprocessor communication is similar to that of minimizing cache misses. <p> Evaluation of our prefetch algorithm on a set of programs from standard benchmark set suggests that it is possible to take advantage of prefetch instructions effectively on many numerical applications <ref> [8] </ref>. 4. Code Generation. Finally, the compiler generates the SPMD (Single Program Multiple Data) program to be run on each processor. It involves generating the appropriate computation and communication code for each processor, translating global addresses to local or restructured data addresses, and managing the communicated data.
Reference: 9. <author> M. E. Wolf. </author> <title> Improving Locality and Parallelism in Nested Loops. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <month> August </month> <year> 1992. </year> <note> Published as CSL-TR-92-538. </note>
Reference-contexts: Details on this topic are the subject of the rest of the paper. All the algorithms described in the paper have been implemented in SUIF. Evaluation of our cache locality optimizations has been completed <ref> [9] </ref>, and we are currently experimenting with our multiprocessor optimizations. 3. Optimizing Data Accesses. After improving a program's locality of reference, our compiler then tries to optimize the remaining memory accesses by hiding the latency of communication with computation.
Reference: 10. <author> M. E. Wolf and M. S. Lam. </author> <title> A data locality optimizing algorithm. </title> <booktitle> In Proceedings of the SIGPLAN '91 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 30-44, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: This paper focuses on the central problem of how to optimize the locality and parallelism in a program for high-performance systems. In this paper, we will focus mainly on the rationale behind the design of the algorithms; details on the algorithms can be found in other papers <ref> [1, 3, 8, 10, 11] </ref>. This paper offers a unified view of locality optimization at various levels of the memory hierarchy. Our treatment of the problem of minimizing interprocessor communication is similar to that of minimizing cache misses. <p> If N is large compared to the cache size, then neither the reuse of Y or Z is soon enough. We define the localized iteration space to denote the set of iterations that can successfully exploit locality between their reuse <ref> [10] </ref>. In this case, we say that the loop's localized iteration space consists of only the innermost loop. In general, a localized iteration space consists of all the iterations in the inner loops up to, and including, the first loop with a large or unknown iteration count.
Reference: 11. <author> M. E. Wolf and M. S. Lam. </author> <title> A loop transformation theory and an algorithm to maximize parallelism. </title> <journal> Transactions on Parallel and Distributed Systems, </journal> <volume> 2(4) </volume> <pages> 452-470, </pages> <month> October </month> <year> 1991. </year> <title> This article was processed using the L a T E X macro package with LLNCS style </title>
Reference-contexts: This paper focuses on the central problem of how to optimize the locality and parallelism in a program for high-performance systems. In this paper, we will focus mainly on the rationale behind the design of the algorithms; details on the algorithms can be found in other papers <ref> [1, 3, 8, 10, 11] </ref>. This paper offers a unified view of locality optimization at various levels of the memory hierarchy. Our treatment of the problem of minimizing interprocessor communication is similar to that of minimizing cache misses.
References-found: 11

