URL: http://cg.ams.sunysb.edu/~csilva/papers/terrain95.ps
Refering-URL: 
Root-URL: 
Title: Automatic Generation of Triangular Irregular Networks using Greedy Cuts  
Author: Claudio T. Silva* Joseph S. B. Mitchellz Arie E. Kaufman* 
Address: NY 11794  
Affiliation: *Department of Computer Science Department of Applied Mathematics Statistics State University of New York at Stony Brook Stony Brook,  
Abstract: We propose a new approach to the automatic generation of triangular irregular networks from dense terrain models. We have developed and implemented an algorithm based on the greedy principle used to compute minimum-link paths in polygons. Our algorithm works by taking greedy cuts ("bites") out of a simple closed polygon that bounds the yet-to-be triangulated region. The algorithm starts with a large polygon, bounding the whole extent of the terrain to be triangulated, and works its way inward, performing at each step one of three basic operations: ear cutting, greedy biting, and edge splitting. We give experimental evidence that our method is competitive with current algorithms and has the potential to be faster and to generate many fewer triangles. Also, it is able to keep the structural terrain fidelity at almost no extra cost in running time and it requires very little memory beyond that for the input height array. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P. K. Agarwal and S. Suri. </author> <title> Surface approximation and geometric partitions. </title> <booktitle> In Proc. Fifth Annual ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <pages> pages 34-43, </pages> <year> 1994. </year>
Reference-contexts: From an algorithmic point of view, terrain simplification is hard (NP-hard) [5, 4], but some polynomial-time algorithms are known for computing a nearly-optimal (i.e., nearly minimum-facet) approximating surface, guaranteed to be within a factor O (log n) of optimal (see <ref> [1, 3, 15, 17] </ref>), or within a constant factor of optimal, if the surface is convex (see [2]). Unfortunately, the polynomial-time bounds for these theoretically good approaches is rather high (at least cubic).
Reference: [2] <author> H. Bronnimann and M. T. Goodrich. </author> <title> Almost optimal set covers in finite VC-dimension. </title> <booktitle> In Proc. 10th Annu. ACM Sympos. Comput. Geom., </booktitle> <pages> pages 293-302, </pages> <year> 1994. </year>
Reference-contexts: simplification is hard (NP-hard) [5, 4], but some polynomial-time algorithms are known for computing a nearly-optimal (i.e., nearly minimum-facet) approximating surface, guaranteed to be within a factor O (log n) of optimal (see [1, 3, 15, 17]), or within a constant factor of optimal, if the surface is convex (see <ref> [2] </ref>). Unfortunately, the polynomial-time bounds for these theoretically good approaches is rather high (at least cubic). <p> Conceptually, there are no changes needed to the algorithm. A somewhat less trivial modification will be to generalize the algorithm to approximate arbitrary (non-terrain) polyhedral surfaces and to find approximations to a minimum-facet separating surface (as done in <ref> [2, 3, 17] </ref>, in the convex case). Another straightforward extension of our method allows one to use it to build hierarchical representations of terrain.
Reference: [3] <author> K. L. Clarkson. </author> <title> Algorithms for polytope covering and approximation. </title> <booktitle> In Proc. 3rd Workshop Algorithms Data Struct., volume 709 of Lecture Notes in Computer Science, </booktitle> <pages> pages 246-252, </pages> <year> 1993. </year>
Reference-contexts: From an algorithmic point of view, terrain simplification is hard (NP-hard) [5, 4], but some polynomial-time algorithms are known for computing a nearly-optimal (i.e., nearly minimum-facet) approximating surface, guaranteed to be within a factor O (log n) of optimal (see <ref> [1, 3, 15, 17] </ref>), or within a constant factor of optimal, if the surface is convex (see [2]). Unfortunately, the polynomial-time bounds for these theoretically good approaches is rather high (at least cubic). <p> The principle that drives our method (and is related to that of <ref> [3, 17, 25] </ref>) is the same greedy principle that is used to compute minimum-link paths in simple polygons. This problem is well studied in computational geometry [12, 16, 24] and can be used to find an optimal piecewise-linear approximation to a function of a single variable (see [10]). <p> Conceptually, there are no changes needed to the algorithm. A somewhat less trivial modification will be to generalize the algorithm to approximate arbitrary (non-terrain) polyhedral surfaces and to find approximations to a minimum-facet separating surface (as done in <ref> [2, 3, 17] </ref>, in the convex case). Another straightforward extension of our method allows one to use it to build hierarchical representations of terrain.
Reference: [4] <author> G. Das and D. Joseph. </author> <title> Minimum vertex hulls for polyhedral domains. </title> <journal> Theoret. Comput. Sci., </journal> <volume> 103 </volume> <pages> 107-135, </pages> <year> 1992. </year>
Reference-contexts: From an algorithmic point of view, terrain simplification is hard (NP-hard) <ref> [5, 4] </ref>, but some polynomial-time algorithms are known for computing a nearly-optimal (i.e., nearly minimum-facet) approximating surface, guaranteed to be within a factor O (log n) of optimal (see [1, 3, 15, 17]), or within a constant factor of optimal, if the surface is convex (see [2]).
Reference: [5] <author> Gautam Das and Michael T. Goodrich. </author> <title> On the complexity of approximating and illuminating three-dimensional convex polyhedra. </title> <booktitle> In Proc. 4th Workshop Algorithms Data Struct., Lecture Notes in Computer Science. To appear. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference-contexts: From an algorithmic point of view, terrain simplification is hard (NP-hard) <ref> [5, 4] </ref>, but some polynomial-time algorithms are known for computing a nearly-optimal (i.e., nearly minimum-facet) approximating surface, guaranteed to be within a factor O (log n) of optimal (see [1, 3, 15, 17]), or within a constant factor of optimal, if the surface is convex (see [2]).
Reference: [6] <author> M. de Berg and K. Dobrindt. </author> <title> On levels of detail in terrains. </title> <booktitle> In Proc. 11th Annu. ACM Sympos. Comput. Geom., pages C26-C27, v 1995. </booktitle>
Reference-contexts: Scarlatos' dissertation [19] is a good survey of terrain modeling and representation. A very recent approach to building hierarchical models of terrains is given by de Berg and Dobrindt <ref> [6] </ref>, who apply a hierarchical refinement of the Delaunay triangulation to represent terrain TINs at many levels of detail. See also [13, 14] for an approach called the "drop heuristic" and its comparison with other methods. <p> In top-down algorithms, such requirements can be incorporated using constraints; for example, line segments can be preserved using con strained Delaunay triangulation (e.g., <ref> [6] </ref>).
Reference: [7] <author> L. De Floriani. </author> <title> A pyramidal data structure for triangle-based surface representation. </title> <journal> IEEE Comput. Graph. Appl., </journal> <volume> 9 </volume> <pages> 67-78, </pages> <month> March </month> <year> 1989. </year>
Reference-contexts: A new version of his code is publically available, and we used it for comparison with our method. A detailed description of his algorithm and code is given in Section 4. Recently, substantial research has been conducted on creating hierarchical structures on top of TINs <ref> [7, 21] </ref>, and on techniques to improve the quality of TIN meshes [22]. Scarlatos' dissertation [19] is a good survey of terrain modeling and representation.
Reference: [8] <author> R. J. Fowler and J. J. Little. </author> <title> Automatic extraction of irregular network digital terrain models. </title> <journal> Computer Graphics, </journal> <volume> 13(2) </volume> <pages> 199-207, </pages> <month> August </month> <year> 1979. </year>
Reference-contexts: TINs stand out as being one of the most convenient to use for rendering and other geometric manipulation operations. A TIN is a set of contiguous non-overlapping triangles whose vertices are placed adaptively over the DEM domain <ref> [8] </ref>. The automatic generation of TIN models from DEM models is an important area of research and is the main topic of this article. <p> Fowler and Little <ref> [8] </ref> have introduced one of the first (and still very popular) methods to address the problem of automatic generation of TINs directly from DEMs. Their method is very simple. First, they classify the points by automatically choosing some "important" features of the terrain, such as ridges and peaks.
Reference: [9] <author> W. R. Franklin. </author> <title> Triangulated irregular network to approximate digital terrain, Section 2.3, Research Interests. </title> <type> Technical report, </type> <institution> Electrical, Computer, and Systems Engineering Dept., Rensselaer Polytechnic Institute, </institution> <address> Troy, NY, </address> <year> 1994. </year> <note> Manuscript and code available on ftp://ftp.cs.rpi.edu/pub/franklin/. </note>
Reference-contexts: At each step, a new point is added to the triangulation until no points are farther from the original surface than a certain predefined threshold. This phase is designed to preserve the "statistical fidelity" (i.e, to make it fit the specified error bound). Franklin <ref> [9] </ref> has proposed a similar approach back in 1973. It appears that his method had no notion of structural fidelity, and he did not use the Delaunay triangulation as the basis for his method. <p> We ran both algorithms on the following types of input: real terrain datasets, artificially generated terrains arising from performing cuts to generate faults, and artificially generated terrains arising from lifting triangulations. Franklin's algorithm Franklin's algorithm is described in <ref> [9] </ref>, and is a nice and efficient example of a top-down triangulation method. Initially, the algorithm approximates the DEM by 2 triangles.
Reference: [10] <author> M. T. Goodrich. </author> <title> Efficient piecewise-linear function approximation using the uniform metric. </title> <booktitle> In Proc. 10th Annu. ACM Sympos. Comput. Geom., </booktitle> <pages> pages 322-331, </pages> <year> 1994. </year>
Reference-contexts: This problem is well studied in computational geometry [12, 16, 24] and can be used to find an optimal piecewise-linear approximation to a function of a single variable (see <ref> [10] </ref>). Our problem is of one higher dimension.
Reference: [11] <author> M. T. Goodrich and R. Tamassia. </author> <title> Dynamic ray shooting and shortest paths via balanced geodesic triangulations. </title> <booktitle> In Proc. 9th Annu. ACM Sympos. Comput. Geom., </booktitle> <pages> pages 318-327, </pages> <year> 1993. </year>
Reference-contexts: Using a dynamic triangulation of P , and performing "ray shooting queries", one can actually check in time O (log k) if (v i ; v i+2 ) is an ear of a simple k-gon <ref> [11] </ref>, but the simple linear--time method is likely to be more practical (since k is typically small) and is what we currently have implemented. Each cut we perform lowers the complexity (number of edges) of polygon P by one, thus taking the algorithm closer to completion.
Reference: [12] <author> L. J. Guibas, J. E. Hershberger, J. S. B. Mitchell, and J. S. Snoeyink. </author> <title> Approximating polygons and subdivisions with minimum link paths. </title> <journal> Internat. J. Comput. Geom. Appl., </journal> <volume> 3(4) </volume> <pages> 383-415, </pages> <month> Decem-ber </month> <year> 1993. </year>
Reference-contexts: The principle that drives our method (and is related to that of [3, 17, 25]) is the same greedy principle that is used to compute minimum-link paths in simple polygons. This problem is well studied in computational geometry <ref> [12, 16, 24] </ref> and can be used to find an optimal piecewise-linear approximation to a function of a single variable (see [10]). Our problem is of one higher dimension.
Reference: [13] <author> J. Lee. </author> <title> A drop heuristic conversion method for extracting irregular network for digital elevation models. </title> <booktitle> In GIS/LIS '89 Proc., </booktitle> <volume> volume 1, </volume> <pages> pages 30-39. </pages> <booktitle> American Congress on Surveying and Mapping, </booktitle> <month> Nov. </month> <year> 1989. </year>
Reference-contexts: A very recent approach to building hierarchical models of terrains is given by de Berg and Dobrindt [6], who apply a hierarchical refinement of the Delaunay triangulation to represent terrain TINs at many levels of detail. See also <ref> [13, 14] </ref> for an approach called the "drop heuristic" and its comparison with other methods. Common to all these previous methods is the necessity to have a complete starting triangulation that is either refined by adding new points, or decimated [23] by removing redundant points.
Reference: [14] <author> J. Lee. </author> <title> Comparison of existing methods for building triangular irregular network models of terrain from grid digital elevation models. </title> <journal> Intl. J. of Geographical Information Systems, </journal> <volume> 5(3) </volume> <pages> 267-285, </pages> <month> July-Sept. </month> <year> 1991. </year>
Reference-contexts: A very recent approach to building hierarchical models of terrains is given by de Berg and Dobrindt [6], who apply a hierarchical refinement of the Delaunay triangulation to represent terrain TINs at many levels of detail. See also <ref> [13, 14] </ref> for an approach called the "drop heuristic" and its comparison with other methods. Common to all these previous methods is the necessity to have a complete starting triangulation that is either refined by adding new points, or decimated [23] by removing redundant points.
Reference: [15] <author> J. S. B. Mitchell. </author> <title> Approximation algorithms for geometric separation problems. </title> <type> Technical report, </type> <institution> Dept, of Applied Math, University at Stony Brook, Stony Brook, </institution> <address> NY, </address> <month> July, </month> <year> 1993. </year>
Reference-contexts: From an algorithmic point of view, terrain simplification is hard (NP-hard) [5, 4], but some polynomial-time algorithms are known for computing a nearly-optimal (i.e., nearly minimum-facet) approximating surface, guaranteed to be within a factor O (log n) of optimal (see <ref> [1, 3, 15, 17] </ref>), or within a constant factor of optimal, if the surface is convex (see [2]). Unfortunately, the polynomial-time bounds for these theoretically good approaches is rather high (at least cubic).
Reference: [16] <author> J. S. B. Mitchell, G. Rote, and G. Woegin-ger. </author> <title> Minimum-link paths among obstacles in the plane. </title> <journal> Algorithmica, </journal> <volume> 8 </volume> <pages> 431-459, </pages> <year> 1992. </year>
Reference-contexts: The principle that drives our method (and is related to that of [3, 17, 25]) is the same greedy principle that is used to compute minimum-link paths in simple polygons. This problem is well studied in computational geometry <ref> [12, 16, 24] </ref> and can be used to find an optimal piecewise-linear approximation to a function of a single variable (see [10]). Our problem is of one higher dimension.
Reference: [17] <author> J. S. B. Mitchell and S. Suri. </author> <title> Separation and approximation of polyhedral surfaces. </title> <booktitle> In Proc. 3rd ACM-SIAM Sympos. Discrete Algorithms, </booktitle> <pages> pages 296-306, </pages> <year> 1992. </year>
Reference-contexts: The need for global information impacts the running time and memory requirements of these algorithms. Our work is based on an entirely different approach for the triangulation and simplification of the data. It is based on an idea in the method developed by Mitchell and Suri <ref> [17] </ref>, where a greedy set cover approach has been developed for approximating convex surfaces, and used recently by Varshney [25] in heuristics for simplifying CAD models. We can consider the input DEM to be an instance of a TIN with very high resolution. <p> From an algorithmic point of view, terrain simplification is hard (NP-hard) [5, 4], but some polynomial-time algorithms are known for computing a nearly-optimal (i.e., nearly minimum-facet) approximating surface, guaranteed to be within a factor O (log n) of optimal (see <ref> [1, 3, 15, 17] </ref>), or within a constant factor of optimal, if the surface is convex (see [2]). Unfortunately, the polynomial-time bounds for these theoretically good approaches is rather high (at least cubic). <p> The principle that drives our method (and is related to that of <ref> [3, 17, 25] </ref>) is the same greedy principle that is used to compute minimum-link paths in simple polygons. This problem is well studied in computational geometry [12, 16, 24] and can be used to find an optimal piecewise-linear approximation to a function of a single variable (see [10]). <p> The use of greedy algorithms is known to give provably good approximation results in many combinatorial optimization problems, for example, the set cover problem is approximated within a log factor of optimal by a natural greedy algorithm, and this fact leads <ref> [17] </ref> to a provably good approximation algorithm for the convex case of our problem. We have not yet been able to prove that our algorithm has a guaranteed effectiveness with respect to optimal, but we are hopeful that interesting properties can be proved about its performance. <p> Conceptually, there are no changes needed to the algorithm. A somewhat less trivial modification will be to generalize the algorithm to approximate arbitrary (non-terrain) polyhedral surfaces and to find approximations to a minimum-facet separating surface (as done in <ref> [2, 3, 17] </ref>, in the convex case). Another straightforward extension of our method allows one to use it to build hierarchical representations of terrain.
Reference: [18] <author> J. O'Rourke. </author> <title> Computational Geometry in C. </title> <publisher> Cambridge University Press, </publisher> <year> 1994. </year> <note> C code and errata available by anonymous ftp from gren-del.csc.smith.edu (131.229.64.23), in the directory /pub/compgeom. </note>
Reference-contexts: As a proof, consider a polygon P 2 P. If P has no grid points, then any ear of P is feasible. (Any simple polygon with at least 4 vertices has at least two ears, by the "Two Ear Theorem" <ref> [18] </ref>.) If P has grid points in its interior, then there must exist a triangulation of these points within P (since any polygonal domain can be triangulated). All triangles in this triangulation must obey weak feasibility. <p> Our C implementation has only about 4,000 lines of code. The code uses several computational geometry primitives, many of which come from O'Rourke <ref> [18] </ref>, including segment intersection testing, diagonal classification, point classification (point location with respect to a simple polygon).
Reference: [19] <author> L. Scarlatos. </author> <title> Spatial data representations for rapid visualization and analysis. </title> <type> Ph.D. thesis, </type> <institution> Department of Computer Science, State University of New York at Stony Brook, Stony Brook, </institution> <address> NY 11794-4400, </address> <year> 1993. </year>
Reference-contexts: The automatic generation of TIN models from DEM models is an important area of research and is the main topic of this article. Several factors are important in judging the quality of the TIN representation of a given DEM (list partially adapted from <ref> [19, 20] </ref>): * Numerical accuracy measured as maximum, mean, or standard deviation error; * Visual accuracy usually assessed by inspection and by number of "slivery" triangles; * Size of the model measured as the number of output triangles; * Algorithm complexity measured in terms of the time to generate the TIN <p> A detailed description of his algorithm and code is given in Section 4. Recently, substantial research has been conducted on creating hierarchical structures on top of TINs [7, 21], and on techniques to improve the quality of TIN meshes [22]. Scarlatos' dissertation <ref> [19] </ref> is a good survey of terrain modeling and representation. A very recent approach to building hierarchical models of terrains is given by de Berg and Dobrindt [6], who apply a hierarchical refinement of the Delaunay triangulation to represent terrain TINs at many levels of detail.
Reference: [20] <author> L. Scarlatos and T. Pavlidis. </author> <title> Hierarchical triangulation using terrain features. </title> <booktitle> In Proc. of the IEEE Conference on Visualization Visualization '90, </booktitle> <pages> pages 168-175. </pages> <publisher> IEEE, </publisher> <year> 1990. </year>
Reference-contexts: The automatic generation of TIN models from DEM models is an important area of research and is the main topic of this article. Several factors are important in judging the quality of the TIN representation of a given DEM (list partially adapted from <ref> [19, 20] </ref>): * Numerical accuracy measured as maximum, mean, or standard deviation error; * Visual accuracy usually assessed by inspection and by number of "slivery" triangles; * Size of the model measured as the number of output triangles; * Algorithm complexity measured in terms of the time to generate the TIN
Reference: [21] <author> L. Scarlatos and T. Pavlidis. </author> <title> Hierarchical triangulation using cartographics coherence. CVGIP: Graph. Models Image Process., </title> <booktitle> 54(2) </booktitle> <pages> 147-161, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: A new version of his code is publically available, and we used it for comparison with our method. A detailed description of his algorithm and code is given in Section 4. Recently, substantial research has been conducted on creating hierarchical structures on top of TINs <ref> [7, 21] </ref>, and on techniques to improve the quality of TIN meshes [22]. Scarlatos' dissertation [19] is a good survey of terrain modeling and representation.
Reference: [22] <author> L. Scarlatos and T. Pavlidis. </author> <title> Optimizing triangulation by curvature equalization. </title> <booktitle> In Proc. of the IEEE Conference on Visualization Visualization '92, </booktitle> <pages> pages 333-339. </pages> <publisher> IEEE, </publisher> <year> 1992. </year>
Reference-contexts: A detailed description of his algorithm and code is given in Section 4. Recently, substantial research has been conducted on creating hierarchical structures on top of TINs [7, 21], and on techniques to improve the quality of TIN meshes <ref> [22] </ref>. Scarlatos' dissertation [19] is a good survey of terrain modeling and representation. A very recent approach to building hierarchical models of terrains is given by de Berg and Dobrindt [6], who apply a hierarchical refinement of the Delaunay triangulation to represent terrain TINs at many levels of detail.
Reference: [23] <author> W. J. Schroeder, J. A. Zarge, and W. E. Lorensen. </author> <title> Decimation of triangle meshes. </title> <booktitle> In SIGGRAPH '92, </booktitle> <volume> volume 26, </volume> <pages> pages 65-70, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: See also [13, 14] for an approach called the "drop heuristic" and its comparison with other methods. Common to all these previous methods is the necessity to have a complete starting triangulation that is either refined by adding new points, or decimated <ref> [23] </ref> by removing redundant points. These approaches require that the algorithm maintain in memory a complete triangulation representation of the input, extended with various pieces of global information (e.g., most deviant point per triangle). The need for global information impacts the running time and memory requirements of these algorithms.
Reference: [24] <author> S. Suri. </author> <title> On some link distance problems in a simple polygon. </title> <journal> IEEE Trans. Robot. Autom., </journal> <volume> 6 </volume> <pages> 108-113, </pages> <year> 1990. </year>
Reference-contexts: The principle that drives our method (and is related to that of [3, 17, 25]) is the same greedy principle that is used to compute minimum-link paths in simple polygons. This problem is well studied in computational geometry <ref> [12, 16, 24] </ref> and can be used to find an optimal piecewise-linear approximation to a function of a single variable (see [10]). Our problem is of one higher dimension. <p> The algorithm can be considered to be a simplified version of the standard min-link path method of Suri <ref> [24] </ref>, applied to the discrete data points between the offset curves obtained by shifting the terrain surface up/down by *. See Figure 2. Main Algorithm The algorithm simply applies the above three operations, one at a time, giving priority (in order) to ear cutting, greedy biting, and then edge splitting.
Reference: [25] <author> A. Varshney. </author> <title> Hierarchical Geometric Approximations. </title> <type> Ph.D. thesis, </type> <institution> Department of Computer Science, University of North Carolina, </institution> <address> Chapel Hill, NC 27599-3175, </address> <year> 1994. </year> <title> TR-050-1994. Color plate 1: Buffalo terrain triangulated with (a) Franklin's algorithm, (b) our algorithm (strong-feasibility). Color plate 2: Jackson terrain triangulated with (a) Franklin's algorithm, (b) our algorithm (strong-feasibility). </title>
Reference-contexts: It is based on an idea in the method developed by Mitchell and Suri [17], where a greedy set cover approach has been developed for approximating convex surfaces, and used recently by Varshney <ref> [25] </ref> in heuristics for simplifying CAD models. We can consider the input DEM to be an instance of a TIN with very high resolution. <p> The principle that drives our method (and is related to that of <ref> [3, 17, 25] </ref>) is the same greedy principle that is used to compute minimum-link paths in simple polygons. This problem is well studied in computational geometry [12, 16, 24] and can be used to find an optimal piecewise-linear approximation to a function of a single variable (see [10]).
References-found: 25

