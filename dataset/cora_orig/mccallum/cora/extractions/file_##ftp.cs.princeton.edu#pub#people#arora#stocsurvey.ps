URL: file://ftp.cs.princeton.edu/pub/people/arora/stocsurvey.ps
Refering-URL: http://www.cs.princeton.edu/~arora/publist.html
Root-URL: http://www.cs.princeton.edu
Title: The Approximability of NP-hard Problems  
Author: Sanjeev Arora 
Affiliation: Princeton University  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> M. Ajtai. </author> <title> Generating hard instances of lattice problems. </title> <booktitle> Proceedings of the Twenty Eighth Annual Symposium on the Theory of Computing, ACM, </booktitle> <year> 1996. </year>
Reference-contexts: We currently know neither an algorithm that achieves an approximation ratio better than around n 1=2 , nor an inap-proximability result of any sort. Recently, Ajtai <ref> [1] </ref> and Ajtai and Dwork [2] have shown deep connections between (conjectured) in-approximability and cryptography by constructing cryptographic primitives whose security is based upon the inapproximability of certain lattice problems (such as SHORTEST VECTOR and NEAREST VECTOR).
Reference: [2] <author> M. Ajtai and C. Dwork. </author> <title> A public-key cryp-tosystem with worst-case/average-case equivalence. </title> <booktitle> Proceedings of the Twenty Eighth Annual Symposium on the Theory of Computing, ACM, </booktitle> <year> 1997 </year>
Reference-contexts: We currently know neither an algorithm that achieves an approximation ratio better than around n 1=2 , nor an inap-proximability result of any sort. Recently, Ajtai [1] and Ajtai and Dwork <ref> [2] </ref> have shown deep connections between (conjectured) in-approximability and cryptography by constructing cryptographic primitives whose security is based upon the inapproximability of certain lattice problems (such as SHORTEST VECTOR and NEAREST VECTOR).
Reference: [3] <author> S. Arora. </author> <title> Probabilistic Checking of Proofs and Hardness of Approximation Problems. </title> <type> PhD thesis, </type> <institution> U.C. Berkeley, </institution> <year> 1994. </year> <note> Available from http://www.cs.princeton.edu/~arora </note> . 
Reference-contexts: See <ref> [3] </ref> for a survey.
Reference: [4] <author> S. Arora. </author> <title> Polynomial-time approximation schemes for Euclidean TSP and other geometric problems. </title> <booktitle> Proceedings of 37th IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pp 2-12, </pages> <year> 1996. </year>
Reference-contexts: I tried unsuccessfully to prove inapproximability in the geometric case, and then became convinced that no such result was provable. This led me to try to design a PTAS, at which I succeeded <ref> [4] </ref>.
Reference: [5] <author> S. Arora. </author> <title> Nearly linear time approximation schemes for Euclidean TSP and other geometric problems. </title> <booktitle> Proceedings of 38th IEEE Symp. on Foundations of Computer Science, </booktitle> <year> 1997. </year>
Reference: [6] <author> S. Arora, L. Babai, J. Stern, and Z. Sweedyk. </author> <title> The hardness of approximate optima in lattices, codes, and systems of linear equations. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 54(2) </volume> <pages> 317-331, </pages> <year> 1997. </year>
Reference-contexts: Other papers have tried to prove inapproximabil-ity results for problems that were not already known to be inapproximable. In the two years after the discovery of the PCP Theorem, many new results were discovered by Lund and Yannakakis [108, 107], Arora, Babai, Stern, and Sweedyk <ref> [6] </ref>, Bellare [24], Bellare and Rogaway [28], Zuckerman [128], etc.. Since then, there has been essentially no progress except for a few MAX-SNP-hardness results.
Reference: [7] <author> S. Arora, A. Frieze, and H. Kaplan. </author> <title> New Rounding Procedure for the Assignment Problem with Applications to Dense Graph Arrangement Problems. </title> <booktitle> Proceedings of the Thirty Seventh Annual Symposium on the Foundations of Computer Science, IEEE, </booktitle> <year> 1996, </year> <pages> pages 21-30. </pages>
Reference-contexts: The work on dense graphs has recently been extended in <ref> [7, 55, 66] </ref>. The last two papers make the PTAS's extremely efficient. 6 Future Directions Simplifying the proofs of the results on PCP's is an extremely important task. Current proofs fill several dozen pages each.
Reference: [8] <author> S. Arora, D. Karger, and M. Karpinski. </author> <title> Polynomial Time Approximation Schemes for Dense Instances of N P-Hard Problems. </title> <booktitle> Proceedings of the Twenty Seventh Annual Symposium on the Theory of Computing, ACM, </booktitle> <year> 1995. </year>
Reference: [9] <author> S. Arora and C. Lund. </author> <title> Hardness of approximations. </title> <booktitle> In [75]. </booktitle>
Reference-contexts: The connection finally became undeniable after Lund and Yan-nakis [108, 107] used PCP constructions to prove the inapproximability of SETCOVER, CHROMATIC-NUMBER, and many MAX--SUBGRAPH problems. Since then many other inapproximability results have been discovered as described in <ref> [9, 43] </ref>. As pointed out in [9], just as 3SAT is the "canonical" problem in the theory of NP-completeness, MAX-3SAT is the "canonical" problem in the theory of inapproximability. <p> The connection finally became undeniable after Lund and Yan-nakis [108, 107] used PCP constructions to prove the inapproximability of SETCOVER, CHROMATIC-NUMBER, and many MAX--SUBGRAPH problems. Since then many other inapproximability results have been discovered as described in [9, 43]. As pointed out in <ref> [9] </ref>, just as 3SAT is the "canonical" problem in the theory of NP-completeness, MAX-3SAT is the "canonical" problem in the theory of inapproximability. Once we prove the in-approximability of MAX-3SAT, we can prove most other inapproximability results, though not always in the strongest possible form. <p> Of course, repeating the verification O (1=*) times makes the rejection probability 1=2. The "only if" part (NP PCP (log n; 1) implies the existence of the above-mentioned reduction) is only a little more difficult. It involves replacing a verifier's actions by an equivalent 3CNF formula (see <ref> [9] </ref>). 3.1.1 Other inapproximability results In the past few years, two types of research has been done on inapproximability. One tries to improve the inapproximability results that are already known. Usually this involves improving the parameters of some known verifier. <p> Having outlined some of the difficulties, I now trace the progress made on the above program. 4.1 Empirical Classification of Known Inapproximability Results In a survey article, Arora and Lund <ref> [9] </ref> briefly describe how to prove most known inapproximabil-ity results. They list at least two dozen important problems for which inapproximability was proved using PCP-based techniques.
Reference: [10] <author> S. Arora, C. Lund, R. Motwani, M. Sudan, and M. Szegedy. </author> <title> Proof verification and intractability of approximation problems. </title> <booktitle> In Proc. 33rd IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 13-22, </pages> <year> 1992. </year>
Reference-contexts: Soon, Arora, Lund, Motwani, Sudan, and Szegedy <ref> [10] </ref> proved the PCP Theorem (see below) and showed that MAX-SNP-hard problems do not have a PTAS if P 6= NP. Many sources attribute the PCP theorem jointly to [12, 10]. For brief surveys of all the above developments see [18, 64, 80]. <p> Soon, Arora, Lund, Motwani, Sudan, and Szegedy [10] proved the PCP Theorem (see below) and showed that MAX-SNP-hard problems do not have a PTAS if P 6= NP. Many sources attribute the PCP theorem jointly to <ref> [12, 10] </ref>. For brief surveys of all the above developments see [18, 64, 80]. In the years since the discovery of the PCP Theorem, other variants of PCP have been studied and used in inap-proximability results. Now we define the class PCP. <p> The verifier uses certain algorithms that, given a function specified by value, can check that it satisfies the desired properties. Two of those algorithms are Sum Check [106] and Low Degree Test (invented in [19] and improved in <ref> [20, 49, 116, 12, 10, 114, 13] </ref>). An important technique introduced in [12] and used in all subsequent papers is verifier composition, which composes two verifiers to give a new verifier some of whose parameters are lower than those in either verifier. <p> Verifier composition relies on the notion of a probabilistically checkable encoding, a notion to which Arora and Safra were led by results in [20]. (Later, in the proof of the PCP Theorem <ref> [10] </ref>, Hadamard codes were used to implement such encodings.) Another result that plays a crucial role in recent works on PCP is Raz's parallel repetition theorem [113]. Finally, the work of H-astad [73, 74] uses encodings based upon the so-called Long Code [26]. <p> connection somewhat earlier; but she worked with a different notion of proof verification and a less natural optimization problem.) For a while, this connection was viewed as "just" coincidental, and this viewpoint began to change only after the PCP theorem was shown to be equivalent to the in-approximability of MAX-SNP <ref> [11, 10] </ref>. The connection finally became undeniable after Lund and Yan-nakis [108, 107] used PCP constructions to prove the inapproximability of SETCOVER, CHROMATIC-NUMBER, and many MAX--SUBGRAPH problems. Since then many other inapproximability results have been discovered as described in [9, 43].
Reference: [11] <author> S. Arora, R. Motwani, S. Safra, M. Sudan, and M. Szegedy. </author> <title> PCP and approximation problems. Unpublished note, </title> <year> 1992. </year>
Reference-contexts: connection somewhat earlier; but she worked with a different notion of proof verification and a less natural optimization problem.) For a while, this connection was viewed as "just" coincidental, and this viewpoint began to change only after the PCP theorem was shown to be equivalent to the in-approximability of MAX-SNP <ref> [11, 10] </ref>. The connection finally became undeniable after Lund and Yan-nakis [108, 107] used PCP constructions to prove the inapproximability of SETCOVER, CHROMATIC-NUMBER, and many MAX--SUBGRAPH problems. Since then many other inapproximability results have been discovered as described in [9, 43].
Reference: [12] <author> S. Arora and S. Safra. </author> <title> Probabilistic checking of proofs: a new characterization of NP. </title> <booktitle> To appear Journal of the ACM. Preliminary version in Proceedings of the Thirty Third Annual Symposium on the Foundations of Computer Science, IEEE, </booktitle> <year> 1992. </year>
Reference-contexts: This important result drew everybody's attention to the (as yet unnamed) area of probabilistically checkable proofs. A year later, Arora and Safra <ref> [12] </ref> formalized and named the class PCP and used it to give a new probabilistic definition of NP. (The works of Babai et al. and Feige et al. were precursors of this new definition.) They also showed that approximating MAX-CLIQUE is NP-hard. <p> Soon, Arora, Lund, Motwani, Sudan, and Szegedy [10] proved the PCP Theorem (see below) and showed that MAX-SNP-hard problems do not have a PTAS if P 6= NP. Many sources attribute the PCP theorem jointly to <ref> [12, 10] </ref>. For brief surveys of all the above developments see [18, 64, 80]. In the years since the discovery of the PCP Theorem, other variants of PCP have been studied and used in inap-proximability results. Now we define the class PCP. <p> The verifier uses certain algorithms that, given a function specified by value, can check that it satisfies the desired properties. Two of those algorithms are Sum Check [106] and Low Degree Test (invented in [19] and improved in <ref> [20, 49, 116, 12, 10, 114, 13] </ref>). An important technique introduced in [12] and used in all subsequent papers is verifier composition, which composes two verifiers to give a new verifier some of whose parameters are lower than those in either verifier. <p> Two of those algorithms are Sum Check [106] and Low Degree Test (invented in [19] and improved in [20, 49, 116, 12, 10, 114, 13]). An important technique introduced in <ref> [12] </ref> and used in all subsequent papers is verifier composition, which composes two verifiers to give a new verifier some of whose parameters are lower than those in either verifier.
Reference: [13] <author> S. Arora and M. Sudan. </author> <title> Improved low degree testing and its applications. </title> <booktitle> Proceedings of the Twenty Eighth Annual Symposium on the Theory of Computing, ACM, </booktitle> <year> 1997 </year>
Reference-contexts: The verifier uses certain algorithms that, given a function specified by value, can check that it satisfies the desired properties. Two of those algorithms are Sum Check [106] and Low Degree Test (invented in [19] and improved in <ref> [20, 49, 116, 12, 10, 114, 13] </ref>). An important technique introduced in [12] and used in all subsequent papers is verifier composition, which composes two verifiers to give a new verifier some of whose parameters are lower than those in either verifier. <p> The first paper in this area was Bellare, Goldwasser, Lund, and Russell [27]; others are Feige and Kilian [50, 51]; Bellare and Sudan [29]; Bellare, Goldreich, and Su-dan [26]; Furer [56], H-astad [73, 74]; Feige [47]; Raz and Safra [114]; and Arora and Sudan <ref> [13] </ref>. Thanks to this work, we now know of tight results for the four problems mentioned above: in other words, the inapproximability results for these problems almost match the performance of the best algorithms.
Reference: [14] <author> G. Ausiello, A. D'Atri, and M. Protasi. </author> <title> On the structure of combinatorial problems and structure preserving reductions. </title> <booktitle> In Proc. 4th Intl. Coll. on Automata, Languages and Programming, </booktitle> <year> 1977. </year>
Reference-contexts: Garey and Johnson identified the notion of strong NP-completeness [59] and showed that most NP-hard problems of interest do not have FPTAS's if P 6= NP. Some preliminary work was also done on classifying problems according to approximability <ref> [14, 15, 16] </ref>.
Reference: [15] <author> G. Ausiello, A. D'Atri, and M. Protasi. </author> <title> Structure preserving reductions among convex optimization problems. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 21 </volume> <pages> 136-153, </pages> <year> 1980. </year>
Reference-contexts: Garey and Johnson identified the notion of strong NP-completeness [59] and showed that most NP-hard problems of interest do not have FPTAS's if P 6= NP. Some preliminary work was also done on classifying problems according to approximability <ref> [14, 15, 16] </ref>.
Reference: [16] <author> G. Ausiello, A. Marchetti-Spaccamela, and M. Protasi. </author> <title> Toward a unified approach for the classification of NP-complete optimization problems. </title> <journal> Theoretical Computer Science, </journal> <volume> 12 </volume> <pages> 83-96, </pages> <year> 1980. </year>
Reference-contexts: Garey and Johnson identified the notion of strong NP-completeness [59] and showed that most NP-hard problems of interest do not have FPTAS's if P 6= NP. Some preliminary work was also done on classifying problems according to approximability <ref> [14, 15, 16] </ref>.
Reference: [17] <author> L. Babai. </author> <title> Trading group theory for randomness. </title> <booktitle> In Proc. 17th ACM Symp. on Theory of Computing, </booktitle> <pages> pages 421-429, </pages> <year> 1985. </year>
Reference-contexts: Luckily, more robust representations of computational histories were around the corner, thanks to work on interactive proofs and program checking. 3 Probabilistically Checkable Proofs The concept of PCPs evolved out of interactive proofs, which were defined in the mid 1980s by Goldwasser, Micali, and Rackoff [67] and Babai <ref> [17] </ref> as a probabilistic extension of the nondeterminism used in NP. Interactive proofs found many applications in cryptography and complexity theory (see Goldreich's article [64]), one of which involved an early version of probabilistically checkable proof systems (Fortnow, Rompel, and Sipser [54]).
Reference: [18] <author> L. Babai. </author> <title> Transparent proofs and limits to approximations. </title> <booktitle> In Proceedings of the First Eu-ropean Congress of Mathematicians. </booktitle> <publisher> Birkhauser, </publisher> <year> 1994. </year>
Reference-contexts: Soon, Arora, Lund, Motwani, Sudan, and Szegedy [10] proved the PCP Theorem (see below) and showed that MAX-SNP-hard problems do not have a PTAS if P 6= NP. Many sources attribute the PCP theorem jointly to [12, 10]. For brief surveys of all the above developments see <ref> [18, 64, 80] </ref>. In the years since the discovery of the PCP Theorem, other variants of PCP have been studied and used in inap-proximability results. Now we define the class PCP.
Reference: [19] <author> L. Babai, L. Fortnow, and C. Lund. </author> <title> Nondeterministic exponential time has two-prover interactive protocols. </title> <journal> Computational Complexity, </journal> <volume> 1 </volume> <pages> 3-40, </pages> <year> 1991. </year>
Reference-contexts: In restrospect, this algebraization can also be seen as a "robust" representation of computation (cf. Section 2). The inspiration to use polynomials came from works on pro gram checking [34] (see also [101, 23, 35]). Babai, Fortnow, and Lund <ref> [19] </ref> used similar methods to give a new probabilistic definition of NEXPTIME, the exponential analogue of NP. <p> The verifier expects the membership proof to contain this polynomial presented by value. The verifier uses certain algorithms that, given a function specified by value, can check that it satisfies the desired properties. Two of those algorithms are Sum Check [106] and Low Degree Test (invented in <ref> [19] </ref> and improved in [20, 49, 116, 12, 10, 114, 13]). An important technique introduced in [12] and used in all subsequent papers is verifier composition, which composes two verifiers to give a new verifier some of whose parameters are lower than those in either verifier.
Reference: [20] <author> L. Babai, L. Fortnow, L. Levin, and M. Szegedy. </author> <title> Checking computations in polylogarithmic time. </title> <booktitle> In Proc. 23rd ACM Symp. on Theory of Computing, </booktitle> <pages> pages 21-31, </pages> <year> 1991. </year>
Reference-contexts: Babai, Fortnow, and Lund [19] used similar methods to give a new probabilistic definition of NEXPTIME, the exponential analogue of NP. To extend this result to NP, Babai, Fortnow, Levin, and Szegedy <ref> [20] </ref> and Feige, Goldwasser, Lovasz, Safra, and Szegedy [49] studied variants of what we now call probabilistically checkable proof systems (Babai et al. called their systems holographic proofs). Feige et al. also proved the first inapproximability result to come out of the PCP area. <p> The verifier uses certain algorithms that, given a function specified by value, can check that it satisfies the desired properties. Two of those algorithms are Sum Check [106] and Low Degree Test (invented in [19] and improved in <ref> [20, 49, 116, 12, 10, 114, 13] </ref>). An important technique introduced in [12] and used in all subsequent papers is verifier composition, which composes two verifiers to give a new verifier some of whose parameters are lower than those in either verifier. <p> Verifier composition relies on the notion of a probabilistically checkable encoding, a notion to which Arora and Safra were led by results in <ref> [20] </ref>. (Later, in the proof of the PCP Theorem [10], Hadamard codes were used to implement such encodings.) Another result that plays a crucial role in recent works on PCP is Raz's parallel repetition theorem [113]. <p> See [3] for a survey. One interesting application first observed by Babai et al. <ref> [20] </ref> (and given prominence in the New York Times [94] article on the PCP Theorem) is that the PCP Theorem implies that formal mathematical proofs can be rewritten |with at most a polynomial blowup in size| such that a probabilistic checker can verify their correctness by examining only a constant number
Reference: [21] <author> L. Babai and S. Moran. </author> <title> Arthur-Merlin games: a randomized proof system, and a hierarchy of complexity classes. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 36 </volume> <pages> 254-276, </pages> <year> 1988. </year>
Reference: [22] <author> B. S. Baker. </author> <title> Approximation algorithms for NP-complete problems on planar graphs. </title> <journal> JACM 41(1) </journal> <pages> 153-180, </pages> <year> 1994. </year> <title> Prelim. </title> <booktitle> version in Proceedings of the Twenty Third Annual Symposium on the Foundations of Computer Science, IEEE, </booktitle> <year> 1982. </year>
Reference-contexts: further success in design of algorithms, including Fernandez de la Vega and Lueker's PTAS [53] and Karmarkar and Karp's FP-TAS [84] for BIN-PACKING 1 , PTAS's for some geometric packing and covering problems (see the chapter by Hochbaum in [75] for a survey), and for various problems on planar graphs <ref> [102, 22] </ref>. (Planar graphs are easier to treat because they have small separators.) Wigderson showed how to color 1 The approximation ratio of these BIN-PACKING algorithms approaches 1 only if the value of the optimum approaches 1. 3-colorable graphs with O ( p n) colors [124].
Reference: [23] <author> D. Beaver and J. Feigenbaum. </author> <title> Hiding instances in multioracle queries. </title> <booktitle> Proceedings of the Seventh Annual Symposium on Theoretical Aspects of Computer Science, Lecture Notes in Computer Science Vol. </booktitle> <volume> 415, </volume> <publisher> Springer Verlag, </publisher> <year> 1990. </year>
Reference-contexts: They introduced a revolutionary algebraic way of looking at boolean formulae. In restrospect, this algebraization can also be seen as a "robust" representation of computation (cf. Section 2). The inspiration to use polynomials came from works on pro gram checking [34] (see also <ref> [101, 23, 35] </ref>). Babai, Fortnow, and Lund [19] used similar methods to give a new probabilistic definition of NEXPTIME, the exponential analogue of NP.
Reference: [24] <author> M. Bellare. </author> <title> Interactive Proofs and approximation: Reductions from two provers in one round. </title> <booktitle> In Proceedings of the 2nd Israel Symposium on Theory and Computing Systems. </booktitle> <publisher> IEEE Computer Press, </publisher> <year> 1993. </year> <note> Preliminary version: IBM Research Report RC 17969 (May 1992). </note>
Reference-contexts: Other papers have tried to prove inapproximabil-ity results for problems that were not already known to be inapproximable. In the two years after the discovery of the PCP Theorem, many new results were discovered by Lund and Yannakakis [108, 107], Arora, Babai, Stern, and Sweedyk [6], Bellare <ref> [24] </ref>, Bellare and Rogaway [28], Zuckerman [128], etc.. Since then, there has been essentially no progress except for a few MAX-SNP-hardness results.
Reference: [25] <author> M. Bellare, D. Coppersmith, J. H-astad, M. Kiwi and M. Sudan. </author> <title> Linearity testing in characteristic two. </title> <journal> IEEE Transactions on Information Theory 42(6) </journal> <pages> 1781-1795, </pages> <month> November </month> <year> 1996. </year>
Reference: [26] <author> M. Bellare, O. Goldreich, and M. Sudan. </author> <title> Free bits and non-approximability- towards tight results. </title> <booktitle> In Proc. 36th IEEE Symp. on Foundations of Computer Science, </booktitle> <year> 1995. </year> <note> Full version available from ECCC. </note>
Reference-contexts: Finally, the work of H-astad [73, 74] uses encodings based upon the so-called Long Code <ref> [26] </ref>. A striking feature of the PCP area is that each advance has built upon previous papers, often using them in a "black-box" fashion. <p> MAX-3SAT, MAX-CLIQUE, SET-COVER, and CHROMATIC NUMBER are the main problems for which such improved results have been obtained. The first paper in this area was Bellare, Goldwasser, Lund, and Russell [27]; others are Feige and Kilian [50, 51]; Bellare and Sudan [29]; Bellare, Goldreich, and Su-dan <ref> [26] </ref>; Furer [56], H-astad [73, 74]; Feige [47]; Raz and Safra [114]; and Arora and Sudan [13]. Thanks to this work, we now know of tight results for the four problems mentioned above: in other words, the inapproximability results for these problems almost match the performance of the best algorithms.
Reference: [27] <author> M. Bellare, S. Goldwasser, C. Lund, and A. Rus-sell. </author> <title> Efficient multi-prover interactive proofs with applications to approximation problems. </title> <booktitle> In Proc. 25th ACM Symp. on Theory of Computing, </booktitle> <pages> pages 113-131, </pages> <year> 1993. </year>
Reference-contexts: The verifier is only allowed to query 1 letter from each array. Since each letter of is represented by dlog jje bits, the number of bits queried may be viewed as p dlog jje. Constructions of such proof systems for NP appeared in <ref> [30, 96, 52, 27, 50, 113] </ref>. Lund and Yannakakis [108] used these proof systems to prove inapproxima-bility results for SETCOVER and many subgraph maximization problems. The best construction of such proof systems is due to Raz and Safra [114]. <p> Usually this involves improving the parameters of some known verifier. MAX-3SAT, MAX-CLIQUE, SET-COVER, and CHROMATIC NUMBER are the main problems for which such improved results have been obtained. The first paper in this area was Bellare, Goldwasser, Lund, and Russell <ref> [27] </ref>; others are Feige and Kilian [50, 51]; Bellare and Sudan [29]; Bellare, Goldreich, and Su-dan [26]; Furer [56], H-astad [73, 74]; Feige [47]; Raz and Safra [114]; and Arora and Sudan [13].
Reference: [28] <author> M. Bellare and P. Rogaway. </author> <title> The complexity of approximating a nonlinear program. </title> <journal> Journal of Mathematical Programming B, </journal> <volume> 69(3) </volume> <pages> 429-441, </pages> <year> 1995. </year> <note> Also in Complexity of Numerical Optimization, </note> <editor> Ed. P. M. Pardalos, </editor> <publisher> World Scientific, </publisher> <year> 1993. </year>
Reference-contexts: In the two years after the discovery of the PCP Theorem, many new results were discovered by Lund and Yannakakis [108, 107], Arora, Babai, Stern, and Sweedyk [6], Bellare [24], Bellare and Rogaway <ref> [28] </ref>, Zuckerman [128], etc.. Since then, there has been essentially no progress except for a few MAX-SNP-hardness results.
Reference: [29] <author> M. Bellare and M. Sudan. </author> <title> Improved non-approximability results. </title> <booktitle> In Proc. 26th ACM Symp. on Theory of Computing, </booktitle> <pages> pages 184-193, </pages> <year> 1994. </year>
Reference-contexts: He uses this to show the inapproximability of MAX-3SAT upto a factor 8=7 *. 4. The free bit parameter may be used instead of query bits <ref> [50, 29] </ref>. This parameter is defined as follows. Suppose the query bit parameter is q. After the verifier has picked its random string, and picked a sequence of q addresses, there are 2 q possible sequences of bits that could be contained in those addresses. <p> If the verifier accepts for only t of those sequences, then we say that the free bit parameter is log t (note that this number need not be an integer). 5. Amortized free bits may be used <ref> [29] </ref>. This parameter is defined as lim s!0 f s = log (1=s), where f s is the number of free bits needed by the veri-fier to make soundness &lt; s. <p> MAX-3SAT, MAX-CLIQUE, SET-COVER, and CHROMATIC NUMBER are the main problems for which such improved results have been obtained. The first paper in this area was Bellare, Goldwasser, Lund, and Russell [27]; others are Feige and Kilian [50, 51]; Bellare and Sudan <ref> [29] </ref>; Bellare, Goldreich, and Su-dan [26]; Furer [56], H-astad [73, 74]; Feige [47]; Raz and Safra [114]; and Arora and Sudan [13].
Reference: [30] <author> M. Ben-or, S. Goldwasser, J. Kilian, and A. Wigderson. </author> <title> Multi prover interactive proofs: How to remove intractability assumptions. </title> <booktitle> In Proc. 20th ACM Symp. on Theory of Computing, </booktitle> <pages> pages 113-121, </pages> <year> 1988. </year>
Reference-contexts: The verifier is only allowed to query 1 letter from each array. Since each letter of is represented by dlog jje bits, the number of bits queried may be viewed as p dlog jje. Constructions of such proof systems for NP appeared in <ref> [30, 96, 52, 27, 50, 113] </ref>. Lund and Yannakakis [108] used these proof systems to prove inapproxima-bility results for SETCOVER and many subgraph maximization problems. The best construction of such proof systems is due to Raz and Safra [114].
Reference: [31] <author> P. Berman and G. Schnitger. </author> <title> On the complexity of approximating the independent set problem. </title> <journal> Information and Computation, </journal> <volume> 96(1) </volume> <pages> 77-94, </pages> <year> 1992. </year>
Reference: [32] <author> M. Bern and P. Plassmann. </author> <title> The Steiner problem with edge lengths 1 and 2. </title> <journal> Information Processing Letters, </journal> <volume> 32 </volume> <pages> 171-176, </pages> <year> 1989. </year>
Reference-contexts: The more general case where the points lie in a metric space was known to be MAX-SNP-hard <ref> [32] </ref>. I tried unsuccessfully to prove inapproximability in the geometric case, and then became convinced that no such result was provable. This led me to try to design a PTAS, at which I succeeded [4].
Reference: [33] <author> A. Blum, G. Konjevod, R. Ravi, and S. Vempala. </author> <title> Semi-definite relaxations for minimum bandwidth and other problems These proceedings. </title>
Reference-contexts: result, since H-astad had already shown that achieving an approximation ratio 8=7 * is hard. (Thus Karloff and Zwick knew the "correct" approximation ratio to shoot for, which must have helped.) Semidefi-nite programming has also been used in better algorithms for coloring 3-colorable graphs [82] and for the MIN-BANDWIDTH problem <ref> [33] </ref> (a stronger version of the latter result was independently obtained by Feige using geometric embeddings [48]). 5.2 Geometric Network Design Problems The status of geometric problems such as Euclidean TSP or Steiner tree was a major open question in the post-PCP years.
Reference: [34] <author> M. Blum and S. Kannan. </author> <title> Designing programs that check their work. </title> <booktitle> In Proc. 21st ACM Symp. on Theory of Computing, </booktitle> <pages> pages 86-97, </pages> <year> 1989. </year>
Reference-contexts: They introduced a revolutionary algebraic way of looking at boolean formulae. In restrospect, this algebraization can also be seen as a "robust" representation of computation (cf. Section 2). The inspiration to use polynomials came from works on pro gram checking <ref> [34] </ref> (see also [101, 23, 35]). Babai, Fortnow, and Lund [19] used similar methods to give a new probabilistic definition of NEXPTIME, the exponential analogue of NP.
Reference: [35] <author> M. Blum, M. Luby, and R. Rubinfeld. </author> <title> Self-Testing/Correcting with Applications to Numerical Problems. </title> <journal> JCSS 47(3) </journal> <pages> 549-595, </pages> <year> 1993. </year> <title> Prelim. </title> <booktitle> Version in Proceedings of the Twenty Second Annual Symposium on the Theory of Computing, ACM, </booktitle> <year> 1990. </year>
Reference-contexts: They introduced a revolutionary algebraic way of looking at boolean formulae. In restrospect, this algebraization can also be seen as a "robust" representation of computation (cf. Section 2). The inspiration to use polynomials came from works on pro gram checking [34] (see also <ref> [101, 23, 35] </ref>). Babai, Fortnow, and Lund [19] used similar methods to give a new probabilistic definition of NEXPTIME, the exponential analogue of NP.
Reference: [36] <author> R. B. Boppana and M. M. Halldorsson. </author> <title> Approximating maximum independent sets by excluding subgraphs. </title> <journal> BIT, </journal> <volume> 32(2) </volume> <pages> 180-196, </pages> <month> June </month> <year> 1992. </year>
Reference: [37] <author> N. Christofides. </author> <title> Worst-case analysis of a new heuristic for the traveling salesman problem. </title> <editor> In J.F. Traub, editor, </editor> <title> Symposium on new directions and recent results in algorithms and complexity, page 441. </title> <publisher> Academic Press, </publisher> <address> NY, </address> <year> 1976. </year>
Reference-contexts: Sahni and Gozalez [118] showed that achieving any constant approximation ratio for the TSP is NP-hard. Notable approximation algorithms were discovered, including Sahni's PTAS [117] for KNAPSACK, Ibarra and Kim's improvement of this algorithm to an FP-TAS [78], and Christofides's algorithm for metric TSP with approximation ratio 1:5 <ref> [37] </ref>. Garey and Johnson identified the notion of strong NP-completeness [59] and showed that most NP-hard problems of interest do not have FPTAS's if P 6= NP. Some preliminary work was also done on classifying problems according to approximability [14, 15, 16].
Reference: [38] <author> A. Condon. </author> <title> The complexity of the max-word problem and the power of one-way interactive proof systems. </title> <journal> Computational Complexity, </journal> <volume> 3 </volume> <pages> 292-305, </pages> <year> 1993. </year>
Reference-contexts: Consequently, a proof of H-astad's MAX-CLIQUE result from first principles would fill well over 100 pages! 3.1 Connection to Inapproximability The connection between PCPs and inapproximabil-ity was first established by the result of Feige et al. [49] on MAX-CLIQUE. (Condon <ref> [38] </ref> had discovered a connection somewhat earlier; but she worked with a different notion of proof verification and a less natural optimization problem.) For a while, this connection was viewed as "just" coincidental, and this viewpoint began to change only after the PCP theorem was shown to be equivalent to the
Reference: [39] <author> A. Condon, J. Feigenbaum, C. Lund and P. Shor. </author> <title> Probabilistically Checkable Debate Systems and Approximation Algorithms for PSPACE-Hard Functions. </title> <booktitle> Proceedings of the Twenty Fifth Annual Symposium on the Theory of Computing, ACM, </booktitle> <year> 1993. </year>
Reference: [40] <author> A. Condon, J. Feigenbaum, C. Lund and P. Shor. </author> <title> Random debaters and the hardness of approximating stochastic functions. </title> <journal> SIAM Journal on Computing, </journal> <volume> 26(2) </volume> <pages> 369-400, </pages> <month> April </month> <year> 1997. </year>
Reference-contexts: Crescenzi and Kann [43] maintain a compendium that lists the current approximation status of important optimization problems. 3.2 Other applications of PCP Techniques The PCP Theorem and related techniques have found many other theoretical applications in complexity theory and cryptography, including new definitions of PSPACE <ref> [40] </ref> and PH [92], probabilistically checkable codes, zero-knowledge proofs, checkable VLSI computations, etc. See [3] for a survey.
Reference: [41] <author> S. Cook. </author> <title> The complexity of theorem-proving procedures. </title> <booktitle> In Proc. 3rd ACM Symp. on Theory of Computing, </booktitle> <pages> pages 151-158, </pages> <year> 1971. </year>
Reference-contexts: This showed that an inapproximability result for MAX-3SAT would generalize to a large class of problems, which motivated the discovery of the PCP Theorem a few years later. Papadimitriou and Yannakakis also noted that the classical style of reduction (Cook-Levin-Karp <ref> [41, 99, 85] </ref>) relies on representing a computational history by a combinatorial problem. A computational history is a very non-robust object, since even changing a bit in it can affect its correctness. This nonro-bustness lay at the root of the difficulty in proving inapproximability results.
Reference: [42] <author> N. Creignou. </author> <title> A dichotomy theorem for maximum generalized satisfiability problems. </title> <journal> JCSS 51(3) </journal> <pages> 511-522, </pages> <year> 1995. </year>
Reference-contexts: testing ground for the hypothesis that approximability properties divide all interesting optimization problems into a small number of classes. (A simple greedy algorithm achieves a constant approximation ratio for every MAX-CSP problem, so this class does not contain the rich diversity of approximation ratios found in the real world.) Creignou <ref> [42] </ref> and Khanna, Sudan, and Williamson [91] show that, indeed, there are only two types of MAX-CSP problems: those that can be optimally solved in polynomial time, and those that are MAX-SNP-hard. (Which case holds depends upon certain syntactic properties of the constraint functions.) More recently Khanna, Sudan, and Trevisan [90]
Reference: [43] <author> P. Crescenzi and V. Kann. </author> <title> A compendium of NP optimization problems. </title> <note> Available from ftp://www.nada.kth.se/Theory/Viggo-Kann/compendium.ps.Z </note>
Reference-contexts: The connection finally became undeniable after Lund and Yan-nakis [108, 107] used PCP constructions to prove the inapproximability of SETCOVER, CHROMATIC-NUMBER, and many MAX--SUBGRAPH problems. Since then many other inapproximability results have been discovered as described in <ref> [9, 43] </ref>. As pointed out in [9], just as 3SAT is the "canonical" problem in the theory of NP-completeness, MAX-3SAT is the "canonical" problem in the theory of inapproximability. <p> Since then, there has been essentially no progress except for a few MAX-SNP-hardness results. Crescenzi and Kann <ref> [43] </ref> maintain a compendium that lists the current approximation status of important optimization problems. 3.2 Other applications of PCP Techniques The PCP Theorem and related techniques have found many other theoretical applications in complexity theory and cryptography, including new definitions of PSPACE [40] and PH [92], probabilistically checkable codes, zero-knowledge proofs,
Reference: [44] <author> P. Crescenzi, V. Kann, R. Silvestri, and L. Tre-visan. </author> <title> Structure in aproximation classes. </title> <booktitle> Proc. 1st Combinatorics and Computing conference, </booktitle> <pages> pages 539-548. </pages> <publisher> LNCS 959, Springer Verlag, </publisher> <year> 1995. </year>
Reference-contexts: After several competing definitions the consensus choices these days are the A-reduction [45] and the AP-reduction <ref> [44] </ref>. An A-reduction is defined such that if a problem is A-reducible to problem and is approximable upto a factor ff, then we can conclude that is approximable upto a factor O (ff).
Reference: [45] <author> P. Crescenzi and A. Panconesi. </author> <title> Completeness in approximation classes. </title> <journal> Information and Computation, </journal> <volume> 93 </volume> <pages> 241-262, </pages> <year> 1991. </year>
Reference-contexts: After several competing definitions the consensus choices these days are the A-reduction <ref> [45] </ref> and the AP-reduction [44]. An A-reduction is defined such that if a problem is A-reducible to problem and is approximable upto a factor ff, then we can conclude that is approximable upto a factor O (ff).
Reference: [46] <author> R. Fagin. </author> <title> Generalized first-order spectra and polynomial-time recognizable sets. </title> <editor> In R. Karp, editor, </editor> <booktitle> Complexity of Computer Computations, </booktitle> <pages> pages 43-73. </pages> <publisher> AMS, </publisher> <year> 1974. </year>
Reference-contexts: The goal is to satisfy as many constraints as possible. The concept of "local" constraints is formalized using logic: constraints are local iff they are definable using a quantifier-free propositional formula. The inspiration to use this definition came from Fagin's characterization of NP using 2nd order logic <ref> [46] </ref> A maximization problem is in MAX-SNP if there is a sequence of relation symbols G 1 ; : : : ; G m , a relation symbol S, and a quantifier-free formula (G 1 ; : : : ; G m ; S; x 1 ; : : : ;
Reference: [47] <author> U. Feige. </author> <title> A threshold of ln n for approximating set cover. </title> <booktitle> Proceedings of the Twenty Eighth Annual Symposium on the Theory of Computing, ACM, </booktitle> <year> 1996, </year> <pages> pages 314-318. </pages>
Reference-contexts: The first paper in this area was Bellare, Goldwasser, Lund, and Russell [27]; others are Feige and Kilian [50, 51]; Bellare and Sudan [29]; Bellare, Goldreich, and Su-dan [26]; Furer [56], H-astad [73, 74]; Feige <ref> [47] </ref>; Raz and Safra [114]; and Arora and Sudan [13]. Thanks to this work, we now know of tight results for the four problems mentioned above: in other words, the inapproximability results for these problems almost match the performance of the best algorithms. <p> The tight approximation ratios for the various problems are: 8=7 * for MAX-3SAT [74], n 1* for MAX-CLIQUE [73], n 1* for CHROMATIC NUMBER [51] and (1 *) ln n for SET-COVER <ref> [47] </ref>. Other papers have tried to prove inapproximabil-ity results for problems that were not already known to be inapproximable.
Reference: [48] <author> U. Feige. </author> <title> Approximating the bandwidth via volume respecting embeddings. </title> <booktitle> These proceedings. </booktitle>
Reference-contexts: Karloff and Zwick knew the "correct" approximation ratio to shoot for, which must have helped.) Semidefi-nite programming has also been used in better algorithms for coloring 3-colorable graphs [82] and for the MIN-BANDWIDTH problem [33] (a stronger version of the latter result was independently obtained by Feige using geometric embeddings <ref> [48] </ref>). 5.2 Geometric Network Design Problems The status of geometric problems such as Euclidean TSP or Steiner tree was a major open question in the post-PCP years. The more general case where the points lie in a metric space was known to be MAX-SNP-hard [32].
Reference: [49] <author> U. Feige, S. Goldwasser, L. Lovasz, S. Safra, and M. Szegedy. </author> <title> Interactive proofs and the hardness of approximating cliques Journal of the ACM, </title> <booktitle> 43(2) </booktitle> <pages> 268-292, </pages> <year> 1996. </year> <title> Preliminary version: Approximating clique is almost NP-complete, </title> <booktitle> Proceedings of the Thirty Second Annual Symposium on the Foundations of Computer Science, IEEE, </booktitle> <year> 1991. </year>
Reference-contexts: Babai, Fortnow, and Lund [19] used similar methods to give a new probabilistic definition of NEXPTIME, the exponential analogue of NP. To extend this result to NP, Babai, Fortnow, Levin, and Szegedy [20] and Feige, Goldwasser, Lovasz, Safra, and Szegedy <ref> [49] </ref> studied variants of what we now call probabilistically checkable proof systems (Babai et al. called their systems holographic proofs). Feige et al. also proved the first inapproximability result to come out of the PCP area. <p> Amortized free bits may be used [29]. This parameter is defined as lim s!0 f s = log (1=s), where f s is the number of free bits needed by the veri-fier to make soundness &lt; s. Bellare and Sudan show (modifying a reduction from <ref> [49] </ref>) that if every NP language has a verifier that uses O (log n) random bits and F amortized free bits then MAX-CLIQUE is inapproximable upto a factor n 1=(1+F +ffi) for each ffi &gt; 0. <p> The verifier uses certain algorithms that, given a function specified by value, can check that it satisfies the desired properties. Two of those algorithms are Sum Check [106] and Low Degree Test (invented in [19] and improved in <ref> [20, 49, 116, 12, 10, 114, 13] </ref>). An important technique introduced in [12] and used in all subsequent papers is verifier composition, which composes two verifiers to give a new verifier some of whose parameters are lower than those in either verifier. <p> Consequently, a proof of H-astad's MAX-CLIQUE result from first principles would fill well over 100 pages! 3.1 Connection to Inapproximability The connection between PCPs and inapproximabil-ity was first established by the result of Feige et al. <ref> [49] </ref> on MAX-CLIQUE. (Condon [38] had discovered a connection somewhat earlier; but she worked with a different notion of proof verification and a less natural optimization problem.) For a while, this connection was viewed as "just" coincidental, and this viewpoint began to change only after the PCP theorem was shown to
Reference: [50] <author> U. Feige and J. Kilian. </author> <title> Two prover protocols-low error at affordable rates. </title> <booktitle> In Proc. 26th ACM Symp. on Theory of Computing, </booktitle> <pages> pages 172-183, </pages> <year> 1994. </year>
Reference-contexts: He uses this to show the inapproximability of MAX-3SAT upto a factor 8=7 *. 4. The free bit parameter may be used instead of query bits <ref> [50, 29] </ref>. This parameter is defined as follows. Suppose the query bit parameter is q. After the verifier has picked its random string, and picked a sequence of q addresses, there are 2 q possible sequences of bits that could be contained in those addresses. <p> The verifier is only allowed to query 1 letter from each array. Since each letter of is represented by dlog jje bits, the number of bits queried may be viewed as p dlog jje. Constructions of such proof systems for NP appeared in <ref> [30, 96, 52, 27, 50, 113] </ref>. Lund and Yannakakis [108] used these proof systems to prove inapproxima-bility results for SETCOVER and many subgraph maximization problems. The best construction of such proof systems is due to Raz and Safra [114]. <p> Usually this involves improving the parameters of some known verifier. MAX-3SAT, MAX-CLIQUE, SET-COVER, and CHROMATIC NUMBER are the main problems for which such improved results have been obtained. The first paper in this area was Bellare, Goldwasser, Lund, and Russell [27]; others are Feige and Kilian <ref> [50, 51] </ref>; Bellare and Sudan [29]; Bellare, Goldreich, and Su-dan [26]; Furer [56], H-astad [73, 74]; Feige [47]; Raz and Safra [114]; and Arora and Sudan [13].
Reference: [51] <author> U. Feige and J. Kilian. </author> <title> Zero Knowledge and the Chromatic Number (Preliminary Version). </title> <booktitle> Proceedings of the Eleventh Annual Conference on Complexity Theory, IEEE, </booktitle> <year> 1996. </year>
Reference-contexts: Usually this involves improving the parameters of some known verifier. MAX-3SAT, MAX-CLIQUE, SET-COVER, and CHROMATIC NUMBER are the main problems for which such improved results have been obtained. The first paper in this area was Bellare, Goldwasser, Lund, and Russell [27]; others are Feige and Kilian <ref> [50, 51] </ref>; Bellare and Sudan [29]; Bellare, Goldreich, and Su-dan [26]; Furer [56], H-astad [73, 74]; Feige [47]; Raz and Safra [114]; and Arora and Sudan [13]. <p> The tight approximation ratios for the various problems are: 8=7 * for MAX-3SAT [74], n 1* for MAX-CLIQUE [73], n 1* for CHROMATIC NUMBER <ref> [51] </ref> and (1 *) ln n for SET-COVER [47]. Other papers have tried to prove inapproximabil-ity results for problems that were not already known to be inapproximable. <p> Whatever the definition of an approximation-preserving reduction, coming up with reductions between concrete problems is definitely not easy. Even seemingly related problems such as MAX-CLIQUE and CHROMATIC NUMBER (both of which were recently proven to be inapproximable upto a factor n 1* <ref> [73, 51] </ref>) are not known to be interreducible. Of course, once a class of interreducible problems has been identified, we still have to find the "right" approximation ratio to associate with it.
Reference: [52] <author> U. Feige and L. Lovasz. </author> <title> Two-prover one-round proof systems: Their power and their problems. </title> <booktitle> In Proc. 24th ACM Symp. on Theory of Computing, </booktitle> <pages> pages 733-741, </pages> <year> 1992. </year>
Reference-contexts: The verifier is only allowed to query 1 letter from each array. Since each letter of is represented by dlog jje bits, the number of bits queried may be viewed as p dlog jje. Constructions of such proof systems for NP appeared in <ref> [30, 96, 52, 27, 50, 113] </ref>. Lund and Yannakakis [108] used these proof systems to prove inapproxima-bility results for SETCOVER and many subgraph maximization problems. The best construction of such proof systems is due to Raz and Safra [114].
Reference: [dlV94] <author> W. Fernandez de la Vega. </author> <title> MAXCUT has a randomized approximation scheme in dense graphs. Random Structures & Algorithms, </title> <journal> vol. </journal> <volume> 8, </volume> <year> 1996. </year> <title> Prelim. </title> <type> manuscript, </type> <month> October </month> <year> 1994. </year>
Reference-contexts: how to apply PCP techniques to prove an inapproxima-bility result for them. 5.3 Problems on Dense Graphs and Hypergraphs Recent work shows that dense instances of problems such as MAX-CUT, MAX-ACYCLIC SUBGRAPH, MAX-k-SAT, MIN-BISECTION etc., have PTAS's ([8]; some of these results were independently obtained by Fernandez de la Vega <ref> [dlV94] </ref>). (A dense graph is one in which each vertex has degree fi (n); denseness for formulae is defined analogously.) We were led to this PTAS when we were investigating whether MAX-SNP problems are in-approximable on dense instances, and we could not come up with an inapproximability result.
Reference: [53] <author> W. Fernandez de la Vega and G. S. Lueker. </author> <title> Bin packing can be solved within 1+* in linear time. </title> <booktitle> Combinatorica:1(4), </booktitle> <pages> 349-355, </pages> <year> 1981. </year>
Reference-contexts: Some preliminary work was also done on classifying problems according to approximability [14, 15, 16]. The early 1980s saw further success in design of algorithms, including Fernandez de la Vega and Lueker's PTAS <ref> [53] </ref> and Karmarkar and Karp's FP-TAS [84] for BIN-PACKING 1 , PTAS's for some geometric packing and covering problems (see the chapter by Hochbaum in [75] for a survey), and for various problems on planar graphs [102, 22]. (Planar graphs are easier to treat because they have small separators.) Wigderson showed
Reference: [54] <author> L. Fortnow, J. Rompel, and M. Sipser. </author> <title> On the power of multi-prover interactive protocols. </title> <booktitle> In Proceedings of the 3rd Conference on Structure in Complexity Theory, </booktitle> <pages> pages 156-161, </pages> <year> 1988. </year>
Reference-contexts: Interactive proofs found many applications in cryptography and complexity theory (see Goldreich's article [64]), one of which involved an early version of probabilistically checkable proof systems (Fortnow, Rompel, and Sipser <ref> [54] </ref>). In 1990, Lund, Fortnow, Karloff and Nisan [106] and Shamir [120] showed IP=PSPACE, thus giving a new probabilistic definition of PSPACE in terms of interactive proofs. They introduced a revolutionary algebraic way of looking at boolean formulae.
Reference: [55] <author> A. Frieze and R. Kannan. </author> <title> The Regularity Lemma and Approximation Schemes for Dense Problems. </title> <booktitle> Proceedings of the Thirty Seventh Annual Symposium on the Foundations of Computer Science, IEEE, </booktitle> <year> 1996, </year> <pages> pages 12-20. </pages>
Reference-contexts: The work on dense graphs has recently been extended in <ref> [7, 55, 66] </ref>. The last two papers make the PTAS's extremely efficient. 6 Future Directions Simplifying the proofs of the results on PCP's is an extremely important task. Current proofs fill several dozen pages each.
Reference: [56] <author> M. Furer. </author> <title> Improved hardness results for approximating the chromatic number. </title> <booktitle> In Proc. 36th IEEE Symp. on Foundations of Computer Science, </booktitle> <year> 1995. </year>
Reference-contexts: MAX-3SAT, MAX-CLIQUE, SET-COVER, and CHROMATIC NUMBER are the main problems for which such improved results have been obtained. The first paper in this area was Bellare, Goldwasser, Lund, and Russell [27]; others are Feige and Kilian [50, 51]; Bellare and Sudan [29]; Bellare, Goldreich, and Su-dan [26]; Furer <ref> [56] </ref>, H-astad [73, 74]; Feige [47]; Raz and Safra [114]; and Arora and Sudan [13]. Thanks to this work, we now know of tight results for the four problems mentioned above: in other words, the inapproximability results for these problems almost match the performance of the best algorithms.
Reference: [57] <author> M. R. Garey, R. L. Graham, and J. D. Ullman. </author> <title> Worst case analysis of memory allocation algorithms. </title> <booktitle> In Proceedings of the Fourth Annual Symposium on the Theory of Computing, ACM, </booktitle> <year> 1972, </year> <pages> pages 143-150. </pages>
Reference-contexts: The running time could be exponential (or worse) in 1=* (for example, jxj 1=* Some approximation algorithms were discovered before NP-completeness, most notably Graham's algorithm for scheduling to minimize makespan [69], which achieves an approximation ratio 2. After the discovery of NP-completeness, Garey, Graham, and Ullman <ref> [57] </ref> and then Johnson [79] formalized the notion of an approximation algorithm. Johnson also described simple approximation algorithms for MAX-CUT, MAX-SAT, and SET-COVER (Lovasz [104] gave a similar algorithm for SET-COVER). Sahni and Gozalez [118] showed that achieving any constant approximation ratio for the TSP is NP-hard.
Reference: [58] <author> M. R. Garey and D. S. Johnson. </author> <title> The complexity of near-optimal graph coloring. </title> <journal> Journal of the ACM, </journal> <volume> 23 </volume> <pages> 43-49, </pages> <year> 1976. </year>
Reference: [59] <author> M. Garey and D. Johnson. </author> <title> "Strong" NP-completeness results: motivation, examples and implications. </title> <journal> Journal of the ACM, </journal> <volume> 25 </volume> <pages> 499-508, </pages> <year> 1978. </year>
Reference-contexts: Notable approximation algorithms were discovered, including Sahni's PTAS [117] for KNAPSACK, Ibarra and Kim's improvement of this algorithm to an FP-TAS [78], and Christofides's algorithm for metric TSP with approximation ratio 1:5 [37]. Garey and Johnson identified the notion of strong NP-completeness <ref> [59] </ref> and showed that most NP-hard problems of interest do not have FPTAS's if P 6= NP. Some preliminary work was also done on classifying problems according to approximability [14, 15, 16].
Reference: [60] <author> M. R. Garey and D. S. Johnson. </author> <title> Computers and Intractability: a guide to the theory of NP-completeness. </title> <editor> W. H. </editor> <publisher> Freeman, </publisher> <year> 1979. </year>
Reference-contexts: 1 Introduction Many problems in combinatorial optimization are NP-hard (see <ref> [60] </ref>). This has forced researchers to explore techniques for dealing with NP-completeness. Some have considered algorithms that solve "typical" or "average" instances instead of worst-case instances [86, 100]. In practice, however, identifying "typical" instances is not easy. Other researchers have tried to design approximation algorithms.
Reference: [61] <author> N. Garg, V.V. Vazirani, and M. Yannakakis. </author> <title> Approximate max-flow min-(multi)-cut theorems and their applications. </title> <booktitle> In Proc. 25th ACM Symp. on Theory of Computing, </booktitle> <pages> pages 698 -707, </pages> <year> 1993. </year>
Reference: [62] <author> M. Goemans and D. Williamson. </author> <title> A 0.878 approximation algorithm for MAX-2SAT and MAX-CUT. </title> <booktitle> In Proc. 26th ACM Symp. on Theory of Computing, </booktitle> <pages> pages 422-431, </pages> <year> 1994. </year>
Reference: [63] <author> M. Goemans and D. Williamson. </author> <title> The primal-dual method for approximation algorithms and its applications to network design problems. </title> <booktitle> In [75]. </booktitle>
Reference-contexts: See, for example, Goemans and Williamson's primal-dual technique for network design <ref> [63] </ref>; Linial, London, and Rabinovich's discovery of geometric embeddings of graphs [103] and their use in algorithms (see Shmoy's chapter [121]); and the use of linear programming techniques in scheduling problems (see Hall's chapter [71]).
Reference: [64] <author> O. Goldreich. </author> <title> Probabilistic proof systems. </title> <type> Technical Report RS-94-28, </type> <institution> Basic Research in Computer Science, Center of the Danish National Research Foundation, </institution> <month> September </month> <year> 1994. </year> <booktitle> Proceedings of the International Congress of Mathematicians, </booktitle> <publisher> Birkhauser Verlag 1994. </publisher>
Reference-contexts: Interactive proofs found many applications in cryptography and complexity theory (see Goldreich's article <ref> [64] </ref>), one of which involved an early version of probabilistically checkable proof systems (Fortnow, Rompel, and Sipser [54]). In 1990, Lund, Fortnow, Karloff and Nisan [106] and Shamir [120] showed IP=PSPACE, thus giving a new probabilistic definition of PSPACE in terms of interactive proofs. <p> Soon, Arora, Lund, Motwani, Sudan, and Szegedy [10] proved the PCP Theorem (see below) and showed that MAX-SNP-hard problems do not have a PTAS if P 6= NP. Many sources attribute the PCP theorem jointly to [12, 10]. For brief surveys of all the above developments see <ref> [18, 64, 80] </ref>. In the years since the discovery of the PCP Theorem, other variants of PCP have been studied and used in inap-proximability results. Now we define the class PCP.
Reference: [65] <author> O. Goldreich. </author> <title> A Taxonomy of Proof Systems. In Complexity Theory Retrospective II, L.A. </title> <editor> Hemas-paandra and A. Selman (eds.), </editor> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1997. </year>
Reference: [66] <author> O. Goldreich, S. Goldwasser and D. Ron. </author> <title> Property Testing and its Connection to Learning and Approximation. </title> <booktitle> Proceedings of the Thirty Seventh Annual Symposium on the Foundations of Computer Science, IEEE, </booktitle> <year> 1996, </year> <pages> pages 339-348. </pages>
Reference-contexts: The work on dense graphs has recently been extended in <ref> [7, 55, 66] </ref>. The last two papers make the PTAS's extremely efficient. 6 Future Directions Simplifying the proofs of the results on PCP's is an extremely important task. Current proofs fill several dozen pages each.
Reference: [67] <author> S. Goldwasser, S. Micali, and C. Rackoff. </author> <title> The knowledge complexity of interactive proofs. </title> <journal> SIAM J. on Computing, </journal> <volume> 18 </volume> <pages> 186-208, </pages> <year> 1989. </year>
Reference-contexts: Luckily, more robust representations of computational histories were around the corner, thanks to work on interactive proofs and program checking. 3 Probabilistically Checkable Proofs The concept of PCPs evolved out of interactive proofs, which were defined in the mid 1980s by Goldwasser, Micali, and Rackoff <ref> [67] </ref> and Babai [17] as a probabilistic extension of the nondeterminism used in NP. Interactive proofs found many applications in cryptography and complexity theory (see Goldreich's article [64]), one of which involved an early version of probabilistically checkable proof systems (Fortnow, Rompel, and Sipser [54]).
Reference: [68] <author> O. Goldreich, S. Micali, and A. Wigderson. </author> <title> How to play any mental game or a completeness theorem for protocols with honest majority. </title> <booktitle> In Proc. 19th ACM Symp. on Theory of Computing, </booktitle> <pages> pages 218-229, </pages> <year> 1987. </year>
Reference: [69] <author> R. L. Graham. </author> <title> Bounds for certain multiprocessing anomalies. </title> <journal> Bell System Technical Journal, </journal> <volume> 45 </volume> <pages> 1563-1581, </pages> <year> 1966. </year>
Reference-contexts: The running time could be exponential (or worse) in 1=* (for example, jxj 1=* Some approximation algorithms were discovered before NP-completeness, most notably Graham's algorithm for scheduling to minimize makespan <ref> [69] </ref>, which achieves an approximation ratio 2. After the discovery of NP-completeness, Garey, Graham, and Ullman [57] and then Johnson [79] formalized the notion of an approximation algorithm. Johnson also described simple approximation algorithms for MAX-CUT, MAX-SAT, and SET-COVER (Lovasz [104] gave a similar algorithm for SET-COVER).
Reference: [70] <author> M. Grotschel, L. Lovasz, and A. Schrijver. </author> <title> Geometric Algorithms and Combinatorial Optimization. </title> <publisher> Springer Verlag, </publisher> <address> Berlin. </address> <year> 1988. </year>
Reference-contexts: The best algorithms before that point could only achieve approximation ratios 2 and 1:33 respectively. Their chief tool, semidefinite programming <ref> [70] </ref>, has since been applied to other constraint satisfaction problems. Karloff and Zwick [83] have used it to achieve an approximation ratio 8=7, for MAX-3SAT.
Reference: [71] <author> L. Hall. </author> <title> Approximation algorithms for scheduling. </title> <booktitle> In [75]. </booktitle>
Reference-contexts: See, for example, Goemans and Williamson's primal-dual technique for network design [63]; Linial, London, and Rabinovich's discovery of geometric embeddings of graphs [103] and their use in algorithms (see Shmoy's chapter [121]); and the use of linear programming techniques in scheduling problems (see Hall's chapter <ref> [71] </ref>). Below I focus only on some algorithms whose discovery appears to have been stimulated by the issues raised by inapproximability results.
Reference: [72] <author> M. Halldorsson. </author> <title> A still better performance guarantee for approximate graph coloring. </title> <journal> Information Processing Letters, </journal> <volume> 45 </volume> <pages> 19-23, </pages> <year> 1993. </year>
Reference: [73] <author> J. H-astad. </author> <title> Clique is Hard to Approximate within n 1* . Proceedings of the Thirty Seventh Annual Symposium on the Foundations of Computer Science, </title> <publisher> IEEE, </publisher> <year> 1996, </year> <pages> pages 627-636. </pages>
Reference-contexts: H-astad has shown that for each * &gt; 0, every NP language has a verifier that uses O (log n) random bits and * amortized free bits <ref> [73] </ref>. This implies that MAX-CLIQUE is inapproximable upto a factor n 1* . 6. The proof may contain not bits but letters from a larger alphabet . The verifier's soundness may then depend upon . <p> Finally, the work of H-astad <ref> [73, 74] </ref> uses encodings based upon the so-called Long Code [26]. A striking feature of the PCP area is that each advance has built upon previous papers, often using them in a "black-box" fashion. <p> The first paper in this area was Bellare, Goldwasser, Lund, and Russell [27]; others are Feige and Kilian [50, 51]; Bellare and Sudan [29]; Bellare, Goldreich, and Su-dan [26]; Furer [56], H-astad <ref> [73, 74] </ref>; Feige [47]; Raz and Safra [114]; and Arora and Sudan [13]. Thanks to this work, we now know of tight results for the four problems mentioned above: in other words, the inapproximability results for these problems almost match the performance of the best algorithms. <p> The tight approximation ratios for the various problems are: 8=7 * for MAX-3SAT [74], n 1* for MAX-CLIQUE <ref> [73] </ref>, n 1* for CHROMATIC NUMBER [51] and (1 *) ln n for SET-COVER [47]. Other papers have tried to prove inapproximabil-ity results for problems that were not already known to be inapproximable. <p> Whatever the definition of an approximation-preserving reduction, coming up with reductions between concrete problems is definitely not easy. Even seemingly related problems such as MAX-CLIQUE and CHROMATIC NUMBER (both of which were recently proven to be inapproximable upto a factor n 1* <ref> [73, 51] </ref>) are not known to be interreducible. Of course, once a class of interreducible problems has been identified, we still have to find the "right" approximation ratio to associate with it.
Reference: [74] <author> J. H-astad. </author> <title> Some optimal inapproximability results. </title> <booktitle> Proceedings of the Twenty Eighth Annual Symposium on the Theory of Computing, ACM, </booktitle> <year> 1997, </year> <pages> pages 1-10. </pages>
Reference-contexts: The number of query bits, which was O (q (n)) above, may be specified more precisely together with the leading constant. The constant is important for many inapproximability results. Building upon past results on PCPs and using fourier analysis, H-astad <ref> [74] </ref> recently proved that for each * &gt; 0, every NP language has a verifier with completeness 1 *, soundness 1=2 and only 3 query bits. He uses this to show the inapproximability of MAX-3SAT upto a factor 8=7 *. 4. <p> Finally, the work of H-astad <ref> [73, 74] </ref> uses encodings based upon the so-called Long Code [26]. A striking feature of the PCP area is that each advance has built upon previous papers, often using them in a "black-box" fashion. <p> The first paper in this area was Bellare, Goldwasser, Lund, and Russell [27]; others are Feige and Kilian [50, 51]; Bellare and Sudan [29]; Bellare, Goldreich, and Su-dan [26]; Furer [56], H-astad <ref> [73, 74] </ref>; Feige [47]; Raz and Safra [114]; and Arora and Sudan [13]. Thanks to this work, we now know of tight results for the four problems mentioned above: in other words, the inapproximability results for these problems almost match the performance of the best algorithms. <p> Thanks to this work, we now know of tight results for the four problems mentioned above: in other words, the inapproximability results for these problems almost match the performance of the best algorithms. The tight approximation ratios for the various problems are: 8=7 * for MAX-3SAT <ref> [74] </ref>, n 1* for MAX-CLIQUE [73], n 1* for CHROMATIC NUMBER [51] and (1 *) ln n for SET-COVER [47]. Other papers have tried to prove inapproximabil-ity results for problems that were not already known to be inapproximable.
Reference: [75] <author> D. Hochbaum, ed. </author> <title> Approximation Algorithms for NP-hard problems. </title> <publisher> PWS Publishing, </publisher> <address> Boston, </address> <year> 1996. </year>
Reference-contexts: After twenty-five years of research, approximation algorithms is a major research area with deep techniques (see <ref> [75] </ref> for a detailed survey). Nevertheless, researchers have failed to design good approximation algorithms for a wide variety of NP-hard optimization problems. <p> The early 1980s saw further success in design of algorithms, including Fernandez de la Vega and Lueker's PTAS [53] and Karmarkar and Karp's FP-TAS [84] for BIN-PACKING 1 , PTAS's for some geometric packing and covering problems (see the chapter by Hochbaum in <ref> [75] </ref> for a survey), and for various problems on planar graphs [102, 22]. (Planar graphs are easier to treat because they have small separators.) Wigderson showed how to color 1 The approximation ratio of these BIN-PACKING algorithms approaches 1 only if the value of the optimum approaches 1. 3-colorable graphs with <p> The above research touches a good number of problems, and seems to provide clues to what a more comprehensive theory might look like. 5 Good Upperbounds: New Algorithms Approximation algorithms is a big area and some of its high points of the past few years are surveyed in chapters of <ref> [75] </ref>. See, for example, Goemans and Williamson's primal-dual technique for network design [63]; Linial, London, and Rabinovich's discovery of geometric embeddings of graphs [103] and their use in algorithms (see Shmoy's chapter [121]); and the use of linear programming techniques in scheduling problems (see Hall's chapter [71]).
Reference: [76] <author> D. Hochbaum and D. Shmoys. </author> <title> Using dual approximation algorithms for scheduling problems: practical and theoretical results. </title> <journal> Journal of the ACM 34(1) </journal> <pages> 144-162, </pages> <year> 1987. </year>
Reference-contexts: Hochbaum and Shmoys <ref> [76] </ref> designed a PTAS for MIN-MAKESPAN. In another work [77] they proved a tight result for the k-CENTER problem: they showed how to achieve an approximation ratio 2 and proved that achieving a ratio 2 * is NP-hard. In the late 1980s two important developments occurred.
Reference: [77] <author> D. Hochbaum and D. Shmoys. </author> <title> A best-possible heuristic for the k-center problem. </title> <journal> Math. of Op. Res. </journal> <volume> 10(2) </volume> <pages> 180-184, </pages> <year> 1985. </year>
Reference-contexts: Hochbaum and Shmoys [76] designed a PTAS for MIN-MAKESPAN. In another work <ref> [77] </ref> they proved a tight result for the k-CENTER problem: they showed how to achieve an approximation ratio 2 and proved that achieving a ratio 2 * is NP-hard. In the late 1980s two important developments occurred.
Reference: [78] <author> O. H. Ibarra and C. E. Kim. </author> <title> Fast approximation algorithms for the knapsack and sum of subsets problems. </title> <journal> JACM, </journal> <volume> 22(4) </volume> <pages> 463-468, </pages> <year> 1975. </year>
Reference-contexts: Sahni and Gozalez [118] showed that achieving any constant approximation ratio for the TSP is NP-hard. Notable approximation algorithms were discovered, including Sahni's PTAS [117] for KNAPSACK, Ibarra and Kim's improvement of this algorithm to an FP-TAS <ref> [78] </ref>, and Christofides's algorithm for metric TSP with approximation ratio 1:5 [37]. Garey and Johnson identified the notion of strong NP-completeness [59] and showed that most NP-hard problems of interest do not have FPTAS's if P 6= NP.
Reference: [79] <author> D. S. Johnson. </author> <title> Approximation algorithms for combinatorial problems. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 9 </volume> <pages> 256-278, </pages> <year> 1974. </year>
Reference-contexts: After the discovery of NP-completeness, Garey, Graham, and Ullman [57] and then Johnson <ref> [79] </ref> formalized the notion of an approximation algorithm. Johnson also described simple approximation algorithms for MAX-CUT, MAX-SAT, and SET-COVER (Lovasz [104] gave a similar algorithm for SET-COVER). Sahni and Gozalez [118] showed that achieving any constant approximation ratio for the TSP is NP-hard.
Reference: [80] <author> D. S. Johnson. </author> <title> The NP-completeness column: an ongoing guide. </title> <journal> Journal of Algorithms, </journal> <volume> 13 </volume> <pages> 502-524, </pages> <year> 1992. </year>
Reference-contexts: Soon, Arora, Lund, Motwani, Sudan, and Szegedy [10] proved the PCP Theorem (see below) and showed that MAX-SNP-hard problems do not have a PTAS if P 6= NP. Many sources attribute the PCP theorem jointly to [12, 10]. For brief surveys of all the above developments see <ref> [18, 64, 80] </ref>. In the years since the discovery of the PCP Theorem, other variants of PCP have been studied and used in inap-proximability results. Now we define the class PCP.
Reference: [81] <author> V. Kann. </author> <title> On the approximability of NP-complete optimization problems. </title> <type> PhD thesis, </type> <institution> Royal Institute of Technology, Stockholm, Sweden, </institution> <year> 1992. </year>
Reference: [82] <author> D. Karger, R. Motwani, and M. Sudan. </author> <title> Approximate graph coloring by semidefinite programming. </title> <booktitle> Proceedings of the Thirty Fifth Annual Symposium on the Foundations of Computer Science, IEEE, </booktitle> <year> 1994, </year> <pages> pages 2-13. </pages>
Reference-contexts: is an example of a tight result, since H-astad had already shown that achieving an approximation ratio 8=7 * is hard. (Thus Karloff and Zwick knew the "correct" approximation ratio to shoot for, which must have helped.) Semidefi-nite programming has also been used in better algorithms for coloring 3-colorable graphs <ref> [82] </ref> and for the MIN-BANDWIDTH problem [33] (a stronger version of the latter result was independently obtained by Feige using geometric embeddings [48]). 5.2 Geometric Network Design Problems The status of geometric problems such as Euclidean TSP or Steiner tree was a major open question in the post-PCP years.
Reference: [83] <author> H. Karloff and U. </author> <title> Zwick. </title> <booktitle> A 7/8-Approximation Algorithm for MAX 3SAT? Proceedings of the Thirty Eigth Annual Symposium on the Foundations of Computer Science, IEEE, </booktitle> <year> 1997 </year> . 
Reference-contexts: The best algorithms before that point could only achieve approximation ratios 2 and 1:33 respectively. Their chief tool, semidefinite programming [70], has since been applied to other constraint satisfaction problems. Karloff and Zwick <ref> [83] </ref> have used it to achieve an approximation ratio 8=7, for MAX-3SAT.
Reference: [84] <author> N. Karmarkar and R.M. Karp. </author> <title> An efficient approximation scheme for the one-dimensional bin-packing problem. </title> <booktitle> In Proc. 23 rd IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pp 312-320, </pages> <year> 1982. </year>
Reference-contexts: Some preliminary work was also done on classifying problems according to approximability [14, 15, 16]. The early 1980s saw further success in design of algorithms, including Fernandez de la Vega and Lueker's PTAS [53] and Karmarkar and Karp's FP-TAS <ref> [84] </ref> for BIN-PACKING 1 , PTAS's for some geometric packing and covering problems (see the chapter by Hochbaum in [75] for a survey), and for various problems on planar graphs [102, 22]. (Planar graphs are easier to treat because they have small separators.) Wigderson showed how to color 1 The approximation
Reference: [85] <author> R. M. Karp. </author> <title> Reducibility among combinatorial problems. </title> <editor> In Miller and Thatcher, editors, </editor> <booktitle> Complexity of Computer Computations, </booktitle> <pages> pages 85-103. </pages> <publisher> Plenum Press, </publisher> <year> 1972. </year>
Reference-contexts: This showed that an inapproximability result for MAX-3SAT would generalize to a large class of problems, which motivated the discovery of the PCP Theorem a few years later. Papadimitriou and Yannakakis also noted that the classical style of reduction (Cook-Levin-Karp <ref> [41, 99, 85] </ref>) relies on representing a computational history by a combinatorial problem. A computational history is a very non-robust object, since even changing a bit in it can affect its correctness. This nonro-bustness lay at the root of the difficulty in proving inapproximability results.
Reference: [86] <author> R. M. Karp. </author> <title> Probabilistic analysis of partitioning algorithms for the TSP in the plane. </title> <journal> Math. Oper. Res. </journal> <volume> 2 (1977), </volume> <pages> 209-224. </pages>
Reference-contexts: 1 Introduction Many problems in combinatorial optimization are NP-hard (see [60]). This has forced researchers to explore techniques for dealing with NP-completeness. Some have considered algorithms that solve "typical" or "average" instances instead of worst-case instances <ref> [86, 100] </ref>. In practice, however, identifying "typical" instances is not easy. Other researchers have tried to design approximation algorithms.
Reference: [87] <author> D. Karger, R. Motwani, and G.D.S. Ramkumar. </author> <title> On approximating the longest path in a graph. </title> <booktitle> In Proceedings of Workshop on Algorithms and Data Structures, </booktitle> <pages> pages 421-430. </pages> <publisher> LNCS (Springer-Verlag), v. </publisher> <address> 709, </address> <year> 1993. </year>
Reference: [88] <author> S. Khanna, N. Linial, and S. Safra. </author> <title> On the hardness of approximating the chromatic number. </title> <booktitle> In Proceedings of the 2nd Israel Symposium on Theory and Computing Systems, ISTCS, </booktitle> <pages> pages 250-260. </pages> <publisher> IEEE Computer Society Press, </publisher> <year> 1993. </year>
Reference: [89] <author> S. Khanna, R. Motwani, M. Sudan, and U. Vazi-rani. </author> <title> On syntactic versus computational views of approximability. </title> <booktitle> Proceedings of the Thirty Fifth Annual Symposium on the Foundations of Computer Science, IEEE, </booktitle> <year> 1994, </year> <pages> pages 819-836. </pages>
Reference-contexts: Thus these problems are MAX-SNP-hard. MAX-CUT and MAX-3SAT are also in MAX-SNP, so they are MAX-SNP-complete. Khanna, Motwani, Sudan and Vazirani <ref> [89] </ref> have shown an interesting structural fact about MAX-SNP: every NP-optimization problem that is ap proximable within a constant factor is AP-reducible to MAX-3SAT.
Reference: [90] <author> S. Khanna, M. Sudan, L. Trevisan. </author> <title> Constraint satisfaction: the approximability of minimization problems. </title> <booktitle> Proceedings of the Twelfth Annual Conference on Complexity Theory, IEEE, </booktitle> <year> 1997, </year> <pages> pages 282-296. </pages>
Reference-contexts: [42] and Khanna, Sudan, and Williamson [91] show that, indeed, there are only two types of MAX-CSP problems: those that can be optimally solved in polynomial time, and those that are MAX-SNP-hard. (Which case holds depends upon certain syntactic properties of the constraint functions.) More recently Khanna, Sudan, and Trevisan <ref> [90] </ref> have studied minimization problems connected with constraint satisfaction. These classes contain familiar problems such as s-t min-cut, vertex cover, hitting set with bounded size sets, integer programs with two variables per inequality, deleting the minimum number of edges to make a graph bipartite, and the nearest codeword problem.
Reference: [91] <author> S. Khanna, M. Sudan, and D. Williamson. </author> <title> A complete classification of the approximability of maximization problems derived from Boolean constraint satisfaction. </title> <booktitle> Proceedings of the Twenty Eighth Annual Symposium on the Theory of Computing, ACM, </booktitle> <year> 1997, </year> <pages> pages 11-20. </pages>
Reference-contexts: approximability properties divide all interesting optimization problems into a small number of classes. (A simple greedy algorithm achieves a constant approximation ratio for every MAX-CSP problem, so this class does not contain the rich diversity of approximation ratios found in the real world.) Creignou [42] and Khanna, Sudan, and Williamson <ref> [91] </ref> show that, indeed, there are only two types of MAX-CSP problems: those that can be optimally solved in polynomial time, and those that are MAX-SNP-hard. (Which case holds depends upon certain syntactic properties of the constraint functions.) More recently Khanna, Sudan, and Trevisan [90] have studied minimization problems connected with
Reference: [92] <author> M. Kiwi, C. Lund, A. Russell, D. Spielman, and R. </author> <title> Sundaram Alternation in interaction. </title> <booktitle> Proceedings of the Ninth Annual Conference on Structure in Complexity Theory, IEEE, </booktitle> <year> 1994, </year> <pages> pages 294-303. </pages>
Reference-contexts: Crescenzi and Kann [43] maintain a compendium that lists the current approximation status of important optimization problems. 3.2 Other applications of PCP Techniques The PCP Theorem and related techniques have found many other theoretical applications in complexity theory and cryptography, including new definitions of PSPACE [40] and PH <ref> [92] </ref>, probabilistically checkable codes, zero-knowledge proofs, checkable VLSI computations, etc. See [3] for a survey.
Reference: [93] <author> P. G. Kolaitis and M. N. Thakur. </author> <title> Approximation properties of NP minimization classes. </title> <booktitle> In Proc. of the 6th Conference on Structure in Complexity Theory, </booktitle> <pages> pages 353-366, </pages> <year> 1991. </year>
Reference: [94] <author> G. Kolata. </author> <title> New shortcut found for long math proofs. </title> <address> New York Times, </address> <month> April 7, </month> <year> 1992. </year>
Reference-contexts: See [3] for a survey. One interesting application first observed by Babai et al. [20] (and given prominence in the New York Times <ref> [94] </ref> article on the PCP Theorem) is that the PCP Theorem implies that formal mathematical proofs can be rewritten |with at most a polynomial blowup in size| such that a probabilistic checker can verify their correctness by examining only a constant number of bits in them. (The constant does not depend
Reference: [95] <author> R. Ladner. </author> <title> On the Structure of Polynomial Time Reductibility. </title> <journal> JACM, </journal> <volume> 22(1) </volume> <pages> 155-171, </pages> <year> 1975. </year>
Reference-contexts: Of course, the above program is too ambitious in general because the number of equivalence classes may not be small and may even be infinite. (For example a classical result of Ladner <ref> [95] </ref> says that there are infinitely many equivalence classes in NP for the usual polynomial-time reducibility.) Nevertheless, we could conceivably declare such a program a success if all interesting problems could be shown to fall into a small number of classes. (For example, Ladner's result notwithstanding, in practice most decision problems <p> MAX-CUT, MAX-2SAT, and MAX-3SAT lie in MAX-CSP. A classical result of Schaefer [119] shows that each constraint satisfaction problem is either in P or NP-complete. (In other words, the infinitely many levels in NP exhibited by Ladner's theorem <ref> [95] </ref> are absent among constraint satisfaction problems.) Schaefer also gives simple properties of the constraint functions which determine whether the problem is NP-complete.
Reference: [96] <author> D. Lapidot and A. Shamir. </author> <title> Fully parallelized multi prover protocols for NEXPTIME. </title> <booktitle> In Proc. 32nd IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 13-18, </pages> <year> 1991. </year>
Reference-contexts: The verifier is only allowed to query 1 letter from each array. Since each letter of is represented by dlog jje bits, the number of bits queried may be viewed as p dlog jje. Constructions of such proof systems for NP appeared in <ref> [30, 96, 52, 27, 50, 113] </ref>. Lund and Yannakakis [108] used these proof systems to prove inapproxima-bility results for SETCOVER and many subgraph maximization problems. The best construction of such proof systems is due to Raz and Safra [114].
Reference: [97] <author> E. L. Lawler, J. K. Lenstra, A. H. G. Rinnooy Kan, D. B. Shmoys. </author> <title> The traveling salesman problem. </title> <publisher> John Wiley, </publisher> <year> 1985 </year>
Reference: [98] <author> T. Leighton and S. Rao. </author> <title> An approximate max-flow min-cut theorem for uniform multicommod-ity flow problems with applications to approximation algorithms. </title> <booktitle> In Proc. 29th IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 422-431, </pages> <year> 1988. </year>
Reference-contexts: In another work [77] they proved a tight result for the k-CENTER problem: they showed how to achieve an approximation ratio 2 and proved that achieving a ratio 2 * is NP-hard. In the late 1980s two important developments occurred. Leighton and Rao <ref> [98] </ref> used a powerful method based upon linear programming duality to design algorithms that achieve approximation ratio O (log n) or O (log 2 n) for a variety of graph separation and layout problems. The influence of this work can be seen in many approximation algorithms today.
Reference: [99] <author> L. Levin. </author> <title> Universal'nye perebornye zadachi (universal search problems : in Russian). </title> <journal> Problemy Peredachi Informatsii, </journal> <volume> 9(3) </volume> <pages> 265-266, </pages> <year> 1973. </year>
Reference-contexts: This showed that an inapproximability result for MAX-3SAT would generalize to a large class of problems, which motivated the discovery of the PCP Theorem a few years later. Papadimitriou and Yannakakis also noted that the classical style of reduction (Cook-Levin-Karp <ref> [41, 99, 85] </ref>) relies on representing a computational history by a combinatorial problem. A computational history is a very non-robust object, since even changing a bit in it can affect its correctness. This nonro-bustness lay at the root of the difficulty in proving inapproximability results.
Reference: [100] <author> L. Levin. </author> <title> Average case complete problems. </title> <journal> SIAM Jour. of Computing, 1986, </journal> <volume> Vol. 15, </volume> <pages> pp. 285-286. </pages> <note> Extended abstract appeared in Proc. 16th ACM Symp. on Theory of Computing, </note> <year> 1984. </year>
Reference-contexts: 1 Introduction Many problems in combinatorial optimization are NP-hard (see [60]). This has forced researchers to explore techniques for dealing with NP-completeness. Some have considered algorithms that solve "typical" or "average" instances instead of worst-case instances <ref> [86, 100] </ref>. In practice, however, identifying "typical" instances is not easy. Other researchers have tried to design approximation algorithms.
Reference: [101] <author> R. Lipton. </author> <title> New directions in testing. In Distributed Computing and Cryptography, </title> <editor> J. Feigen-baum and M. Merritt, editors. </editor> <booktitle> Dimacs Series in Discrete Mathematics and Theoretical Computer Science, 2. AMS 1991. </booktitle>
Reference-contexts: They introduced a revolutionary algebraic way of looking at boolean formulae. In restrospect, this algebraization can also be seen as a "robust" representation of computation (cf. Section 2). The inspiration to use polynomials came from works on pro gram checking [34] (see also <ref> [101, 23, 35] </ref>). Babai, Fortnow, and Lund [19] used similar methods to give a new probabilistic definition of NEXPTIME, the exponential analogue of NP.
Reference: [102] <author> R. Lipton and R. Tarjan. </author> <title> Applications of a planar separator theorem. </title> <journal> SIAM J. Computing, </journal> <volume> 9(3) </volume> <pages> 615-627, </pages> <year> 1980. </year>
Reference-contexts: further success in design of algorithms, including Fernandez de la Vega and Lueker's PTAS [53] and Karmarkar and Karp's FP-TAS [84] for BIN-PACKING 1 , PTAS's for some geometric packing and covering problems (see the chapter by Hochbaum in [75] for a survey), and for various problems on planar graphs <ref> [102, 22] </ref>. (Planar graphs are easier to treat because they have small separators.) Wigderson showed how to color 1 The approximation ratio of these BIN-PACKING algorithms approaches 1 only if the value of the optimum approaches 1. 3-colorable graphs with O ( p n) colors [124].
Reference: [103] <author> N. Linial, E. London, and Y. Rabinovich. </author> <title> The Geometry of Graphs and Some of its Algorithmic Applications. </title> <journal> Combinatorica, </journal> <year> 1995. </year>
Reference-contexts: See, for example, Goemans and Williamson's primal-dual technique for network design [63]; Linial, London, and Rabinovich's discovery of geometric embeddings of graphs <ref> [103] </ref> and their use in algorithms (see Shmoy's chapter [121]); and the use of linear programming techniques in scheduling problems (see Hall's chapter [71]). Below I focus only on some algorithms whose discovery appears to have been stimulated by the issues raised by inapproximability results.
Reference: [104] <author> L. Lovasz. </author> <title> On the ratio of optimal integral and fractional covers. </title> <journal> Discrete Mathematics, </journal> <volume> 13 </volume> <pages> 383-390, </pages> <year> 1975. </year>
Reference-contexts: After the discovery of NP-completeness, Garey, Graham, and Ullman [57] and then Johnson [79] formalized the notion of an approximation algorithm. Johnson also described simple approximation algorithms for MAX-CUT, MAX-SAT, and SET-COVER (Lovasz <ref> [104] </ref> gave a similar algorithm for SET-COVER). Sahni and Gozalez [118] showed that achieving any constant approximation ratio for the TSP is NP-hard.
Reference: [105] <author> C. Lund. </author> <title> The Power of Interaction. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Mass., </address> <year> 1992. </year>
Reference: [106] <author> C. Lund, L. Fortnow, H. Karloff, and N. Nisan. </author> <title> Algebraic methods for interactive proof systems. </title> <journal> J. of the ACM, </journal> <volume> 39(4) </volume> <pages> 859-868, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: Interactive proofs found many applications in cryptography and complexity theory (see Goldreich's article [64]), one of which involved an early version of probabilistically checkable proof systems (Fortnow, Rompel, and Sipser [54]). In 1990, Lund, Fortnow, Karloff and Nisan <ref> [106] </ref> and Shamir [120] showed IP=PSPACE, thus giving a new probabilistic definition of PSPACE in terms of interactive proofs. They introduced a revolutionary algebraic way of looking at boolean formulae. In restrospect, this algebraization can also be seen as a "robust" representation of computation (cf. Section 2). <p> The verifier expects the membership proof to contain this polynomial presented by value. The verifier uses certain algorithms that, given a function specified by value, can check that it satisfies the desired properties. Two of those algorithms are Sum Check <ref> [106] </ref> and Low Degree Test (invented in [19] and improved in [20, 49, 116, 12, 10, 114, 13]).
Reference: [107] <author> C. Lund and M. Yannakakis. </author> <title> The approximation of maximum subgraph problems. </title> <booktitle> In Proceedings of International Colloquium on Automata, Languages and Programming, ICALP, </booktitle> <pages> pages 40-51, </pages> <year> 1993. </year>
Reference-contexts: The connection finally became undeniable after Lund and Yan-nakis <ref> [108, 107] </ref> used PCP constructions to prove the inapproximability of SETCOVER, CHROMATIC-NUMBER, and many MAX--SUBGRAPH problems. Since then many other inapproximability results have been discovered as described in [9, 43]. <p> Other papers have tried to prove inapproximabil-ity results for problems that were not already known to be inapproximable. In the two years after the discovery of the PCP Theorem, many new results were discovered by Lund and Yannakakis <ref> [108, 107] </ref>, Arora, Babai, Stern, and Sweedyk [6], Bellare [24], Bellare and Rogaway [28], Zuckerman [128], etc.. Since then, there has been essentially no progress except for a few MAX-SNP-hardness results.
Reference: [108] <author> C. Lund and M. Yannakakis. </author> <title> On the hardness of approximating minimization problems. </title> <journal> Journal of the ACM, </journal> <volume> 41(5) </volume> <pages> 960-981, </pages> <year> 1994. </year>
Reference-contexts: Since each letter of is represented by dlog jje bits, the number of bits queried may be viewed as p dlog jje. Constructions of such proof systems for NP appeared in [30, 96, 52, 27, 50, 113]. Lund and Yannakakis <ref> [108] </ref> used these proof systems to prove inapproxima-bility results for SETCOVER and many subgraph maximization problems. The best construction of such proof systems is due to Raz and Safra [114]. <p> The connection finally became undeniable after Lund and Yan-nakis <ref> [108, 107] </ref> used PCP constructions to prove the inapproximability of SETCOVER, CHROMATIC-NUMBER, and many MAX--SUBGRAPH problems. Since then many other inapproximability results have been discovered as described in [9, 43]. <p> Other papers have tried to prove inapproximabil-ity results for problems that were not already known to be inapproximable. In the two years after the discovery of the PCP Theorem, many new results were discovered by Lund and Yannakakis <ref> [108, 107] </ref>, Arora, Babai, Stern, and Sweedyk [6], Bellare [24], Bellare and Rogaway [28], Zuckerman [128], etc.. Since then, there has been essentially no progress except for a few MAX-SNP-hardness results.
Reference: [109] <author> J. Mitchell. </author> <title> Guillotine subdivisions approximate polygonal subdivisions: Part II- A simple PTAS for geometric k-MST, TSP, and related problems. </title> <type> Preliminary manuscript, </type> <month> April 30, </month> <year> 1996. </year> <note> To appear in SIAM J. Computing. </note>
Reference-contexts: This led me to try to design a PTAS, at which I succeeded [4]. Insights gained from my failed attempt to prove inapproximability were invaluable. (Note, however, that Mitchell independently arrived at a similar PTAS a few months later, while working from a different angle <ref> [109] </ref>.) For similar reasons, I suspect that graph bisection and layout problems may also have good approximation algorithms; I do not currently see how to apply PCP techniques to prove an inapproxima-bility result for them. 5.3 Problems on Dense Graphs and Hypergraphs Recent work shows that dense instances of problems such
Reference: [110] <author> A. Panconesi and D. Ranjan. </author> <title> Quantifiers and approximation. </title> <booktitle> In Proc. of the 22nd ACM Symp. on the Theory of Computing, </booktitle> <pages> pages 446-456, </pages> <year> 1990. </year>
Reference: [111] <author> C. Papadimitriou and M. Yannakakis. </author> <title> Optimization, approximation and complexity classes. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 43 </volume> <pages> 425-440, </pages> <year> 1991. </year> <note> Prelim. version in Proc. ACM STOC 1988. </note>
Reference-contexts: The influence of this work can be seen in many approximation algorithms today. Around the same time, Papadimitriou and Yannakakis <ref> [111] </ref> sought to lay the study of approx-imability on a sound footing and made a start by defining a class of optimization problems they called MAX-SNP. Using a certain approximability preserving reduction they defined completeness for MAX-SNP and showed that MAX-3SAT is MAX-SNP-complete (see Section 4.2). <p> The inapproxima-bility of the canonical problems can be proved using MAX-3SAT. The authors pose an open question whether or not these empirically observed classes can be derived from some deeper theory. (Only Class I seems to have an explanation, using MAX-SNP.) 4.2 MAX-SNP Papadimitriou and Yannakakis <ref> [111] </ref> were interested in determining which problems have a PTAS and which don't. They defined a class of optimization problems, MAX-SNP, as well as a notion of completeness for this class.
Reference: [112] <author> C. Papadimitriou and M. Yannakakis. </author> <title> The traveling salesman problem with distances one and two. </title> <journal> Mathematics of Operations Research, </journal> <volume> 18(1) </volume> <pages> 1-11, </pages> <year> 1993. </year>
Reference: [113] <author> R. Raz. </author> <title> A parallel repetition theorem. </title> <booktitle> Proceedings of the Twenty Seventh Annual Symposium on the Theory of Computing, ACM, </booktitle> <year> 1995. </year>
Reference-contexts: The verifier is only allowed to query 1 letter from each array. Since each letter of is represented by dlog jje bits, the number of bits queried may be viewed as p dlog jje. Constructions of such proof systems for NP appeared in <ref> [30, 96, 52, 27, 50, 113] </ref>. Lund and Yannakakis [108] used these proof systems to prove inapproxima-bility results for SETCOVER and many subgraph maximization problems. The best construction of such proof systems is due to Raz and Safra [114]. <p> probabilistically checkable encoding, a notion to which Arora and Safra were led by results in [20]. (Later, in the proof of the PCP Theorem [10], Hadamard codes were used to implement such encodings.) Another result that plays a crucial role in recent works on PCP is Raz's parallel repetition theorem <ref> [113] </ref>. Finally, the work of H-astad [73, 74] uses encodings based upon the so-called Long Code [26]. A striking feature of the PCP area is that each advance has built upon previous papers, often using them in a "black-box" fashion.
Reference: [114] <author> R. Raz and S. Safra. </author> <title> A sub-constant error-probability low-degree test, and a sub-constant error-probability PCP characterization of NP. </title> <booktitle> Proceedings of the Twenty Eighth Annual Symposium on the Theory of Computing, ACM, </booktitle> <year> 1997. </year>
Reference-contexts: Constructions of such proof systems for NP appeared in [30, 96, 52, 27, 50, 113]. Lund and Yannakakis [108] used these proof systems to prove inapproxima-bility results for SETCOVER and many subgraph maximization problems. The best construction of such proof systems is due to Raz and Safra <ref> [114] </ref>. They show that for each k p log n, every NP language has a verifier that uses O (log n) random bits, has log jj = O (k) and soundness 2 k . The parameter p is O (1). <p> The verifier uses certain algorithms that, given a function specified by value, can check that it satisfies the desired properties. Two of those algorithms are Sum Check [106] and Low Degree Test (invented in [19] and improved in <ref> [20, 49, 116, 12, 10, 114, 13] </ref>). An important technique introduced in [12] and used in all subsequent papers is verifier composition, which composes two verifiers to give a new verifier some of whose parameters are lower than those in either verifier. <p> The first paper in this area was Bellare, Goldwasser, Lund, and Russell [27]; others are Feige and Kilian [50, 51]; Bellare and Sudan [29]; Bellare, Goldreich, and Su-dan [26]; Furer [56], H-astad [73, 74]; Feige [47]; Raz and Safra <ref> [114] </ref>; and Arora and Sudan [13]. Thanks to this work, we now know of tight results for the four problems mentioned above: in other words, the inapproximability results for these problems almost match the performance of the best algorithms.
Reference: [115] <author> R. Rubinfeld. </author> <title> A Mathematical Theory of Self-Checking, Self-Testing and Self-Correcting Programs. </title> <type> Ph.D. thesis, </type> <institution> U.C. Berkeley, </institution> <year> 1990. </year>
Reference: [116] <author> R. Rubinfeld and M. Sudan. </author> <title> Testing polynomial functions efficiently and over rational domains. </title> <booktitle> In Proc. 3rd Annual ACM-SIAM Symp. on Discrete Algorithms, </booktitle> <pages> pages 23-32, </pages> <year> 1992. </year>
Reference-contexts: The verifier uses certain algorithms that, given a function specified by value, can check that it satisfies the desired properties. Two of those algorithms are Sum Check [106] and Low Degree Test (invented in [19] and improved in <ref> [20, 49, 116, 12, 10, 114, 13] </ref>). An important technique introduced in [12] and used in all subsequent papers is verifier composition, which composes two verifiers to give a new verifier some of whose parameters are lower than those in either verifier.
Reference: [117] <author> S. Sahni. </author> <title> Approximate algorithms for the 0/1 knapsack problem. </title> <journal> Journal of the ACM, </journal> <volume> 22(1) </volume> <pages> 115-124, </pages> <year> 1975. </year>
Reference-contexts: Johnson also described simple approximation algorithms for MAX-CUT, MAX-SAT, and SET-COVER (Lovasz [104] gave a similar algorithm for SET-COVER). Sahni and Gozalez [118] showed that achieving any constant approximation ratio for the TSP is NP-hard. Notable approximation algorithms were discovered, including Sahni's PTAS <ref> [117] </ref> for KNAPSACK, Ibarra and Kim's improvement of this algorithm to an FP-TAS [78], and Christofides's algorithm for metric TSP with approximation ratio 1:5 [37].
Reference: [118] <author> S. Sahni and T. Gonzalez. </author> <title> P-complete approximation problems. </title> <journal> Journal of the ACM, </journal> <volume> 23 </volume> <pages> 555-565, </pages> <year> 1976. </year>
Reference-contexts: After the discovery of NP-completeness, Garey, Graham, and Ullman [57] and then Johnson [79] formalized the notion of an approximation algorithm. Johnson also described simple approximation algorithms for MAX-CUT, MAX-SAT, and SET-COVER (Lovasz [104] gave a similar algorithm for SET-COVER). Sahni and Gozalez <ref> [118] </ref> showed that achieving any constant approximation ratio for the TSP is NP-hard. Notable approximation algorithms were discovered, including Sahni's PTAS [117] for KNAPSACK, Ibarra and Kim's improvement of this algorithm to an FP-TAS [78], and Christofides's algorithm for metric TSP with approximation ratio 1:5 [37].
Reference: [119] <author> T. J. Schaefer. </author> <title> The Complexity of Satisfiability Problems. </title> <booktitle> In Proc. 10th ACM STOC, </booktitle> <pages> pp 216-226, </pages> <year> 1978. </year>
Reference-contexts: MAX-CSP problems are defined similarly, except the goal is to maximize the number of functions set to 1. MAX-CUT, MAX-2SAT, and MAX-3SAT lie in MAX-CSP. A classical result of Schaefer <ref> [119] </ref> shows that each constraint satisfaction problem is either in P or NP-complete. (In other words, the infinitely many levels in NP exhibited by Ladner's theorem [95] are absent among constraint satisfaction problems.) Schaefer also gives simple properties of the constraint functions which determine whether the problem is NP-complete.
Reference: [120] <author> A. Shamir. </author> <title> IP = PSPACE. </title> <journal> J. of the ACM, </journal> <volume> 39(4) </volume> <pages> 869-877, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: Interactive proofs found many applications in cryptography and complexity theory (see Goldreich's article [64]), one of which involved an early version of probabilistically checkable proof systems (Fortnow, Rompel, and Sipser [54]). In 1990, Lund, Fortnow, Karloff and Nisan [106] and Shamir <ref> [120] </ref> showed IP=PSPACE, thus giving a new probabilistic definition of PSPACE in terms of interactive proofs. They introduced a revolutionary algebraic way of looking at boolean formulae. In restrospect, this algebraization can also be seen as a "robust" representation of computation (cf. Section 2).
Reference: [121] <author> D. Shmoys. </author> <title> Cut problems and their application to divide-and-conquer. </title> <booktitle> In [75]. </booktitle>
Reference-contexts: See, for example, Goemans and Williamson's primal-dual technique for network design [63]; Linial, London, and Rabinovich's discovery of geometric embeddings of graphs [103] and their use in algorithms (see Shmoy's chapter <ref> [121] </ref>); and the use of linear programming techniques in scheduling problems (see Hall's chapter [71]). Below I focus only on some algorithms whose discovery appears to have been stimulated by the issues raised by inapproximability results. <p> This result (either an algorithm or an inapproxima-bility result) could come from the field of graph separation and layout problems, which have been intensively studied <ref> [121] </ref>. The MIN-BISECTION problem (divide a graph into two equal halves so as to minimize the number of edges crossing between them) is particularly intriguing. We currently know neither an algorithm that achieves an approximation ratio better than around n 1=2 , nor an inap-proximability result of any sort.
Reference: [122] <author> H. U. Simon. </author> <title> On approximate solutions for combinatorial optimization problems. </title> <journal> SIAM J. Algebraic Discrete Methods, </journal> <volume> 3 </volume> <pages> 294-310, </pages> <year> 1990. </year>
Reference: [123] <author> M. Sudan. </author> <title> Efficient checking of polynomials and proofs and the hardness of approximation problems. </title> <type> PhD thesis, </type> <institution> U.C. Berkeley, </institution> <year> 1992. </year>
Reference: [124] <author> A. Wigderson. </author> <title> Improving the Performance Guar--antee for Approximate Graph Coloring. </title> <journal> JACM 30(4) </journal> <pages> 729-735, </pages> <year> 1983. </year>
Reference-contexts: various problems on planar graphs [102, 22]. (Planar graphs are easier to treat because they have small separators.) Wigderson showed how to color 1 The approximation ratio of these BIN-PACKING algorithms approaches 1 only if the value of the optimum approaches 1. 3-colorable graphs with O ( p n) colors <ref> [124] </ref>. Hochbaum and Shmoys [76] designed a PTAS for MIN-MAKESPAN. In another work [77] they proved a tight result for the k-CENTER problem: they showed how to achieve an approximation ratio 2 and proved that achieving a ratio 2 * is NP-hard. In the late 1980s two important developments occurred.
Reference: [125] <author> M. Yannakakis. </author> <title> The effect of a connectivity requirement on the complexity of of maximum subgraph problems. </title> <journal> Journal of the ACM, </journal> <volume> 26 </volume> <pages> 618-630, </pages> <year> 1979. </year>
Reference: [126] <author> M. Yannakakis. </author> <title> Edge deletion problems. </title> <journal> SIAM Journal of Computing, </journal> <volume> 10 </volume> <pages> 77-89, </pages> <year> 1981. </year>
Reference: [127] <author> M. Yannakakis. </author> <title> On the approximation of maximum satisfiability. </title> <booktitle> In Proceedings of 3rd Annual ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <pages> pages 1-9, </pages> <year> 1992. </year>
Reference: [128] <author> D. Zuckerman. </author> <title> NP-complete problems have a version that's hard to approximate. </title> <booktitle> In 8th Structure in Complexity Theory Conf., </booktitle> <pages> pages 305-312, </pages> <year> 1993. </year>
Reference-contexts: In the two years after the discovery of the PCP Theorem, many new results were discovered by Lund and Yannakakis [108, 107], Arora, Babai, Stern, and Sweedyk [6], Bellare [24], Bellare and Rogaway [28], Zuckerman <ref> [128] </ref>, etc.. Since then, there has been essentially no progress except for a few MAX-SNP-hardness results.
References-found: 129

