URL: http://http.cs.berkeley.edu/~bregler/bregler_malik_nips97.ps.gz
Refering-URL: http://http.cs.berkeley.edu/~bregler/pubs.html
Root-URL: 
Email: email: bregler@cs.berkeley.edu, malik@cs.berkeley.edu  
Title: Learning Appearance Based Models: Mixtures of Second Moment Experts  
Author: Christoph Bregler and Jitendra Malik 
Address: Berkeley, CA 94720  
Affiliation: Computer Science Division University of California at Berkeley  
Date: 1997  
Note: To Appear in Advances in Neural Information Processing Systems  
Abstract: This paper describes a new technique for object recognition based on learning appearance models. The image is decomposed into local regions which are described by a new texture representation called Generalized Second Moments that are derived from the output of multiscale, multiorientation filter banks. Class-characteristic local texture features and their global composition is learned by a hierarchical mixture of experts architecture (Jordan & Jacobs). The technique is applied to a vehicle database consisting of 5 general car categories (Sedan, Van with back-doors, Van without back-doors, old Sedan, and Volkswagen Bug). This is a difficult problem with considerable in-class variation. The new technique has a 6:5% misclassification rate, compared to eigen-images which give 17:4% misclassification rate, and nearest neighbors which give 15:7% misclassification rate.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. Beymer, A. Shashua, and T. Poggio. </author> <title> Example based image analysis and synthesis. M.I.T. </title> <journal> A.I. </journal> <volume> Memo No. 1431, </volume> <month> Nov </month> <year> 1993. </year>
Reference-contexts: Appearance-based schemes rely on collections of images of the object. A principal advantage is that they implicitly capture both shape and photometric information (e.g. surface reflectance variation). They have been most sucessfully applied in the domain of human faces <ref> [15, 11, 1, 14] </ref> though other 3d objects under fixed lighting have also been considered [13]. View-based representations lend themselves very naturally to learning from examples- principal component analysis [15, 13] and radial basis functions [1] have been used. <p> They have been most sucessfully applied in the domain of human faces [15, 11, 1, 14] though other 3d objects under fixed lighting have also been considered [13]. View-based representations lend themselves very naturally to learning from examples- principal component analysis [15, 13] and radial basis functions <ref> [1] </ref> have been used. Approaches such as principal component analysis (or eigen-images) use global representations at the image level.
Reference: [2] <author> C. Bregler and J. Malik. </author> <title> Learning Appearance Based Models: Hierarchical Mixtures of Experts Approach based on Generalized Second Moments. </title> <type> Technical Report UCB//CSD-96-897, </type> <institution> Comp. Sci. Dep., U.C. Berkeley, </institution> <address> http://www.cs/ bregler/soft.html, </address> <year> 1996. </year>
Reference-contexts: We compute for each pixel in the image patch the R basis kernel responses (using X-Y separable steerable scalable approximations of a rich filter family). Given a spatial weighting function of the patch (e.g. Gaussian), we compute the covariance matrix of the weighted set of R dimensional vectors. In <ref> [2] </ref> we show that this covariance matrix can be used to reconstruct for any desired oriented and scaled version of the filter family the weighted sum of all filter response energies: E (; ) = x;y Using elongated kernels produces orientation/scale peaks, therefore the sum of all orientation/scale responses doesn't wash <p> Little noisy orientations have no high energy responses in the sum. E (; ) is somehow a soft orientation/scale histogram of the local image patch. Figure 2 shows an example of such a scale/orientation reconstruction based on the covariance matrix (see <ref> [2] </ref> for details). Three peaks are seen, representing the edge lines along three directions and scales in the local image patch. This representation greatly reduces the dimensionality without being domain specific or applying any hard decisions.
Reference: [3] <author> Y. Le Cun, B. Boser, J.S. Denker, S. Solla, R. Howard, and L. Jackel. </author> <title> Back-propagation applied to handwritten zipcode recognition. </title> <journal> Neural Computation, </journal> <volume> 1(4), </volume> <year> 1990. </year>
Reference-contexts: Interestingly the choices of these filter kernels can also be motivated in a learning paradigm as they provide very useful intermediate layer units in convolutional neural networks <ref> [3] </ref>. The straightforward approach would then be to characterize each image pixel by such a vector of feature responses. However note that there is considerable redundancy in the filter responses-particularly at coarse scales, the responses of filters at neighboring pixels are strongly correlated.
Reference: [4] <author> W. Freeman and M. Roth. </author> <title> Orientation histograms for hand gesture recognition. </title> <booktitle> In International Workshop on Automatic Face- and Gesture-Recognition, </booktitle> <year> 1995. </year>
Reference-contexts: The disadvantage is that gradients are not very orientation selective and a certain scale has to be selected beforehand. Averaging the gradients washes out the detailed orientation information in complex texture regions. Orientation histograms would avoid this effect and have been applied successfully for classification <ref> [4] </ref>. Elongated families of oriented and scaled kernels could be used to estimate the orientation at each point. But as pointed out already, there might be more than one orientation at each point, and significant information is lost. reconstructed scale and rotation distribution of the Generalized Second Moments.
Reference: [5] <author> J. Garding and T. Lindeberg. </author> <title> Direct computation of shape cues using scale-adapted spatial derivative operators. </title> <journal> Int. J. of Computer Vision, </journal> <volume> 17, </volume> <month> February </month> <year> 1996. </year>
Reference-contexts: Leaving this issue of compressing the filter response representation aside for the moment, let us study other possible representations of low level image data. One way of representing the texture in a local region is to calculate a windowed second moment matrix <ref> [5] </ref>. Instead of finding maxima of filter responses, the second moments of brightness gradients in the local neighborhood are weighted and averaged with a circular Gaussian window. The gradient is a special case of Gaussian oriented filter banks.
Reference: [6] <author> D.J. Heeger. </author> <title> Optical flow using spatiotemporal filters. </title> <journal> Int. J. of Computer Vision, </journal> <volume> 1, </volume> <year> 1988. </year>
Reference-contexts: The response values of such filters contain much more general information about the local neighborhood, a fact that has now been recognized and exploited in a number of early vision tasks like stereopsis, motion and texture analysis <ref> [16, 9, 6, 12, 7] </ref>. Although this approach is loosely inspired by the current understanding of processing in the early stages of the primate visual system, the use of spatial filters has many advantages from a pure analytical viewpoint [9, 7].
Reference: [7] <author> D. Jones and J. Malik. </author> <title> Computational framework for determining stereo correspondence from a set of linear spatial filters. </title> <journal> Image and Vision Computing, </journal> <volume> 10(10), </volume> <year> 1992. </year>
Reference-contexts: The response values of such filters contain much more general information about the local neighborhood, a fact that has now been recognized and exploited in a number of early vision tasks like stereopsis, motion and texture analysis <ref> [16, 9, 6, 12, 7] </ref>. Although this approach is loosely inspired by the current understanding of processing in the early stages of the primate visual system, the use of spatial filters has many advantages from a pure analytical viewpoint [9, 7]. <p> Although this approach is loosely inspired by the current understanding of processing in the early stages of the primate visual system, the use of spatial filters has many advantages from a pure analytical viewpoint <ref> [9, 7] </ref>. We use as filter kernels, orientation selective elongated Gaussian derivatives. This enables one to gain the power of orientation specific features, such as edges, without the disadvantage of non-robustness due to hard thresholds.
Reference: [8] <author> M.I. Jordan and R. A. Jacobs. </author> <title> Hierarchical mixtures of experts and the em algorithm. </title> <journal> Neural Computation, </journal> <volume> 6(2), </volume> <month> March </month> <year> 1994. </year>
Reference-contexts: Related representations have already been successfully applied to other early-vision tasks like stereopsis, motion, and texture discrimination. Class-based local texture features and their global relationships are induced using the Hierarchical Mixtures of Experts Architecture (HME) <ref> [8] </ref>. We apply this technique to the domain of vehicle classification. The vehicles are seen from behind by a camera mounted above a freeway (Figure 1). We urge the reader to examine Figure 3 to see examples of the in class variations in the 5 different categories. <p> We used generalized linear models (GLIM). Given the training data and output labels, the gating functions and expert functions can be estimated using an iterative version of the EM-algorithm. For more detail see <ref> [8] </ref>. In order to reduce training time and storage requirements, we trained such nonlinear decision surfaces embedded in one global linear subspace.
Reference: [9] <author> J.J. Koenderink. </author> <title> Operational significance of receptive field assemblies. </title> <journal> Biol. Cybern., </journal> <volume> 58 </volume> <pages> 163-171, </pages> <year> 1988. </year>
Reference-contexts: The response values of such filters contain much more general information about the local neighborhood, a fact that has now been recognized and exploited in a number of early vision tasks like stereopsis, motion and texture analysis <ref> [16, 9, 6, 12, 7] </ref>. Although this approach is loosely inspired by the current understanding of processing in the early stages of the primate visual system, the use of spatial filters has many advantages from a pure analytical viewpoint [9, 7]. <p> Although this approach is loosely inspired by the current understanding of processing in the early stages of the primate visual system, the use of spatial filters has many advantages from a pure analytical viewpoint <ref> [9, 7] </ref>. We use as filter kernels, orientation selective elongated Gaussian derivatives. This enables one to gain the power of orientation specific features, such as edges, without the disadvantage of non-robustness due to hard thresholds.
Reference: [10] <author> D. Koller, J. Weber, and J. Malik. </author> <title> Robust multiple car tracking with occlusion reasoning. </title> <booktitle> In Proc. Third European Conference on Computer Vision, </booktitle> <pages> pages 189-196, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: The goal is to classify different types of vehicles. We are able to segment each moving object based on motion cues <ref> [10] </ref>. We chose the following 5 vehicle classes: Modern Sedan, Old Sedan, Van with back-doors, Van without back-door, and Volkswagen Bug. The images show the rear of the car across a small set of poses (Figure 3). All images are normalized to 100x100 pixel using bilinear interpolation.
Reference: [11] <author> M. Lades, J.C. Vorbrueggen, J. Buhmann, J. Lange, C. von der Malsburg, and R.P. Wuertz. </author> <title> Distortion invariant object recognition in the dynamic link architecure. </title> <journal> In IEEE Transactions on Computers, </journal> <volume> volume 42, </volume> <year> 1993. </year>
Reference-contexts: Appearance-based schemes rely on collections of images of the object. A principal advantage is that they implicitly capture both shape and photometric information (e.g. surface reflectance variation). They have been most sucessfully applied in the domain of human faces <ref> [15, 11, 1, 14] </ref> though other 3d objects under fixed lighting have also been considered [13]. View-based representations lend themselves very naturally to learning from examples- principal component analysis [15, 13] and radial basis functions [1] have been used.
Reference: [12] <author> J. Malik and P. Perona. </author> <title> Preattentive texture discrimination with early vision mechanisms. </title> <journal> J. Opt. Soc. Am. A, </journal> <volume> 7(5) </volume> <pages> 923-932, </pages> <year> 1990. </year>
Reference-contexts: The response values of such filters contain much more general information about the local neighborhood, a fact that has now been recognized and exploited in a number of early vision tasks like stereopsis, motion and texture analysis <ref> [16, 9, 6, 12, 7] </ref>. Although this approach is loosely inspired by the current understanding of processing in the early stages of the primate visual system, the use of spatial filters has many advantages from a pure analytical viewpoint [9, 7].
Reference: [13] <author> H. Murase and S.K. Nayar. </author> <title> Visual learning and recognition of 3-d objects from appearance. </title> <journal> Int. J. Computer Vision, </journal> <volume> 14(1) </volume> <pages> 5-24, </pages> <month> January </month> <year> 1995. </year>
Reference-contexts: A principal advantage is that they implicitly capture both shape and photometric information (e.g. surface reflectance variation). They have been most sucessfully applied in the domain of human faces [15, 11, 1, 14] though other 3d objects under fixed lighting have also been considered <ref> [13] </ref>. View-based representations lend themselves very naturally to learning from examples- principal component analysis [15, 13] and radial basis functions [1] have been used. Approaches such as principal component analysis (or eigen-images) use global representations at the image level. <p> They have been most sucessfully applied in the domain of human faces [15, 11, 1, 14] though other 3d objects under fixed lighting have also been considered [13]. View-based representations lend themselves very naturally to learning from examples- principal component analysis <ref> [15, 13] </ref> and radial basis functions [1] have been used. Approaches such as principal component analysis (or eigen-images) use global representations at the image level.
Reference: [14] <author> H.A. Rowley, S. Baluja, and T. Kanade. </author> <title> Human face detection in visual scenes. </title> <booktitle> In NIPS, </booktitle> <volume> volume 8, </volume> <year> 1996. </year>
Reference-contexts: Appearance-based schemes rely on collections of images of the object. A principal advantage is that they implicitly capture both shape and photometric information (e.g. surface reflectance variation). They have been most sucessfully applied in the domain of human faces <ref> [15, 11, 1, 14] </ref> though other 3d objects under fixed lighting have also been considered [13]. View-based representations lend themselves very naturally to learning from examples- principal component analysis [15, 13] and radial basis functions [1] have been used.
Reference: [15] <author> M. Turk and A. Pentland. </author> <title> Eigenfaces for recognition. </title> <journal> Journal of Cognitive Neuroscience, </journal> <volume> 3(1) </volume> <pages> 71-86, </pages> <year> 1991. </year>
Reference-contexts: Appearance-based schemes rely on collections of images of the object. A principal advantage is that they implicitly capture both shape and photometric information (e.g. surface reflectance variation). They have been most sucessfully applied in the domain of human faces <ref> [15, 11, 1, 14] </ref> though other 3d objects under fixed lighting have also been considered [13]. View-based representations lend themselves very naturally to learning from examples- principal component analysis [15, 13] and radial basis functions [1] have been used. <p> They have been most sucessfully applied in the domain of human faces [15, 11, 1, 14] though other 3d objects under fixed lighting have also been considered [13]. View-based representations lend themselves very naturally to learning from examples- principal component analysis <ref> [15, 13] </ref> and radial basis functions [1] have been used. Approaches such as principal component analysis (or eigen-images) use global representations at the image level.
Reference: [16] <author> R.A. Young. </author> <title> The gaussian derivative theory of spatial vision: Analysis of cortical cell receptive field line-weighting profiles. </title> <type> Technical Report GMR-4920, </type> <institution> General Motors Research, </institution> <year> 1985. </year>
Reference-contexts: The response values of such filters contain much more general information about the local neighborhood, a fact that has now been recognized and exploited in a number of early vision tasks like stereopsis, motion and texture analysis <ref> [16, 9, 6, 12, 7] </ref>. Although this approach is loosely inspired by the current understanding of processing in the early stages of the primate visual system, the use of spatial filters has many advantages from a pure analytical viewpoint [9, 7].
References-found: 16

