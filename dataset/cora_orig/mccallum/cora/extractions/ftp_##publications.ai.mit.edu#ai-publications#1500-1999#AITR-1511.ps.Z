URL: ftp://publications.ai.mit.edu/ai-publications/1500-1999/AITR-1511.ps.Z
Refering-URL: http://www.ils.nwu.edu/~ian/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Specialization of Perceptual Processes  
Author: Ian D. Horswill 
Date: December 6, 1994  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Philip Agre and Ian Horswill. </author> <title> Cultural support for improvisation. </title> <booktitle> In Tenth National Conference on Artificial Intelligence, </booktitle> <address> Cambridge, MA, </address> <year> 1992. </year> <booktitle> American Assoiciation for Artificial Intelligence, </booktitle> <publisher> MIT Press. </publisher>
Reference-contexts: Bartenders use the position of a glass on the bar to encode what type of drink they intend to mix and how far they are into the mixing (see Beach [14]). For an example of a program that uses external state, see Agre and Horswill <ref> [1] </ref>. 7.3 Progress functions A progress function is a measure of distance to a goal.
Reference: [2] <author> Philip E. Agre. </author> <title> The dynamic structure of everyday life. </title> <type> Technical Report 1085, </type> <institution> Massachusetts Institute of Technology, Artificial Intelligence Lab, </institution> <month> Octo-ber </month> <year> 1988. </year>
Reference-contexts: The key question is: what is it about the instances we encounter regularly in our lives that makes them easy to solve? A number of overlapping answers have been proposed. Both Schank [90] and Agre <ref> [2] </ref> have argued at length that we tend to solve similar or even identical instances over and over, so we can keep recycling old solutions with minor modifications. <p> A number of authors have stressed the importance of environmental dynamics in explaining intelligent activity. Some authors stress that the world is much simpler than the most general imaginable case (see, for example, Agre <ref> [2] </ref>). Other authors stress the complexity of the environment, arguing that the complexity of the environment allows agents to be simpler (see, for example, Simon [92]). These are not 49 incompatible statements. <p> If we treat problems as task/environment pairs, then we can also taxonomize environments in terms of their relative difficulty for specific tasks. In recent years, many researchers have tried to build the minimal mechanisms for specific task/environment pairs (see, for example, Agre <ref> [2] </ref>, Brooks [20], Chapman [25], Connell [28], and Rosenschein and Kaelbling [88]). Some researchers, such as Connell, use minimalism as an engineering methodology. Agre, on the other hand, treats it largely as a psychological or anthropological methodology. I will focus principally on engineering issues. <p> Like this work, Dixon's work attempts to formally model the assumptions a system makes about its environment. Dixon's interest however, is on what an individual program means rather than on comparing competing programs. Several researchers have discussed how time-extended patterns of interaction with the environment (called "dynamics" by Agre <ref> [2] </ref>) can be used to reduce the computational burden on an agent. Lyons and Hendricks have discussed how to derive and exploit useful dynamics from a formal specification of the environment [67]. They use a uniform formalization of both agent and environment based on process algebra.
Reference: [3] <author> Philip E. Agre and David Chapman. Pengi: </author> <title> An implementation of a theory of activity. </title> <booktitle> In Proceedings of the Sixth National Conference on Artificial Intelligence, </booktitle> <pages> pages 268-272, </pages> <year> 1987. </year>
Reference: [4] <author> John Aloimonos. </author> <title> Purposive and qualitative active vision. </title> <booktitle> In DARPA Image Understanding Workshop, </booktitle> <year> 1990. </year>
Reference: [5] <editor> Yiannis Aloimonos and Azriel Rosenfeld. </editor> <booktitle> Computer vision. Science, </booktitle> <volume> 253 </volume> <pages> 1249-1254, </pages> <month> September </month> <year> 1991. </year>
Reference-contexts: Introduction to part II 4.1 Background In the last decade AI has seen a surprising number of negative theoretical results. Formal planning has been shown to be computationally intractable, or even undecidable (see Chapman [23]). Many perception problems have been shown to be highly numerically unstable (see Aloimonos and Rosenfeld <ref> [5] </ref>). In general, most AI problems amount to search of large spaces, be they discrete spaces, as in the case of reasoning, or continuous spaces, as in the problems of inverse optics. Unfortunately, search is fundamentally hard.
Reference: [6] <author> Ronald C. Arkin. </author> <title> Motor schema based navigation for a mobile robot. </title> <booktitle> In 1987 IEEE Internation Conference on Robotics and Automation, </booktitle> <pages> pages 264-271. </pages> <publisher> IEEE, </publisher> <month> March 87. </month>
Reference: [7] <author> N. Ayache and O. D. Faugeras. </author> <title> Maintaining representations of the environment of a mobile robot. </title> <journal> IEEE Transactions on Robotics and Automation, </journal> <volume> 5(6) </volume> <pages> 804-819, </pages> <year> 1989. </year>
Reference: [8] <editor> Ruzena Bajcsy. </editor> <title> Active perception vs. passive perception. </title> <booktitle> In Proc. Third IEEE Workshop on Computer Vision: Representation and Control, </booktitle> <pages> pages 55-59. </pages> <publisher> IEEE, </publisher> <month> October </month> <year> 1985. </year>
Reference: [9] <author> Dana H. Ballard. </author> <title> Animate vision. </title> <journal> Artificial Intelligence, </journal> <volume> 48(1) </volume> <pages> 57-86, </pages> <year> 1991. </year>
Reference: [10] <author> A. Bandopadhay, B. Chandra, and D.H. Ballard. </author> <title> Egomotion using active vision. </title> <booktitle> In Proceedings, CVPR '86 (IEEE Computer Society Conference on Computer 184 Vision and Pattern Recognition, </booktitle> <address> Miami Beach, FL, </address> <month> June 22-26, </month> <year> 1986), </year> <journal> IEEE Publ.86CH2290-5, </journal> <pages> pages 498-503. </pages> <publisher> IEEE, </publisher> <year> 1986. </year>
Reference: [11] <author> Stephen T. Barnard and Martin A. Fischler. </author> <title> Computational and biological models of stereo vision. </title> <booktitle> In Proc. DARPA Image Understanding Workshop, </booktitle> <month> September </month> <year> 1990. </year>
Reference: [12] <author> Avron Barr and Edward A. Feigenbaum. </author> <booktitle> The Handbook of Artificial Intelligence. </booktitle> <publisher> William Kaufmann, Inc., </publisher> <year> 1981. </year>
Reference-contexts: The term "progress function" is taken from the program verification literature, where it refers to functions over the internal state of the program that are used to prove termination of loops. Progress functions are also similar to Liapunov functions (see Luenberger [65]), admissible heuristics (see Barr and Feigenbaum <ref> [12] </ref>, volume 1, chapter II), and artificial potential fields (see Khatib [54] or Latombe [62]).
Reference: [13] <author> Fred Bauer and John A. Nohel. </author> <title> Ordinary Differential Equations: a First Course. </title> <editor> W. A. </editor> <publisher> Benjamin, Inc., </publisher> <address> New York, </address> <year> 1967. </year>
Reference-contexts: Proof: Without loss of generality, we will assume that x set = 0. We want to show that lim t!1 x (t) = 0. This equation must have a unique, continuous solution for a given initial value (see Brauer and Nohel <ref> [13] </ref>, theorem 1.1). Note that x and its derivative must always have opposite sign, except when one is zero, in which case the other must also be zero.
Reference: [14] <author> King Beach. </author> <title> Becoming a bartender: The role of external memory cues in a work-directed educational activity. </title> <journal> Journal of Applied Cognitive Psychology, </journal> <year> 1992. </year>
Reference-contexts: Bartenders use the position of a glass on the bar to encode what type of drink they intend to mix and how far they are into the mixing (see Beach <ref> [14] </ref>). For an example of a program that uses external state, see Agre and Horswill [1]. 7.3 Progress functions A progress function is a measure of distance to a goal.
Reference: [15] <author> Randall Beer. </author> <title> A dynamical systems perspective on autonomous agents. </title> <type> CES 92-11, </type> <institution> Case Western Reserve University, Cleveland, Ohio, </institution> <year> 1992. </year>
Reference-contexts: First, we will add actions (state transitions) to the environment, making it a full state-machine. We will then model both deliberative planning systems and reactive systems as variants of the control policies of classical control theory (see Luenberger [65] or Beer <ref> [15] </ref>). This gives us a uniform vocabulary for expressing both types of systems.
Reference: [16] <author> P. Bellutta, G. Collini, A. Verri, and V. Torre. </author> <title> Navigation by tracking vanishing points. </title> <booktitle> In AAAI Spring Symposium on Robot Navigation, </booktitle> <pages> pages 6-10, </pages> <institution> Stanford University, </institution> <month> March </month> <year> 1989. </year> <note> AAAI. </note>
Reference-contexts: We can make this knowledge explicit by deriving Polly's vanishing point computation from a more general computation. I will start from the system of Bellutta et al. <ref> [16] </ref>, which extracts vanishing points by running an edge finder, extracting straight line segments, and performing 2D clustering on the pairwise intersections of the edge segments.
Reference: [17] <author> Andrew Blake and Alan Yuille, </author> <title> editors. Active Vision. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1992. </year>
Reference: [18] <author> David J. Braunegg. Marvel: </author> <title> A system for recognizing world locations with stereo vision. </title> <type> Technical report, </type> <institution> MIT Artificial Intelligence Laboratory, </institution> <year> 1990. </year>
Reference: [19] <author> J. Bresina and M. Drummond. </author> <title> Integrating planning and reaction. </title> <editor> In J. Hendler, editor, </editor> <booktitle> AAAI Spring Symposium on Planning in Uncertain, Unpredictable or Changing Environments. AAAI, </booktitle> <month> March </month> <year> 1990. </year>
Reference-contexts: The result would then be a hybrid system with planning on top and reacting on the bottom (see Spector and Hendler [93], Lyons and Hendriks [67], Bresina and Drummond <ref> [19] </ref>, or Gat [40] for other examples). On the other hand, one could imagine an environment where the individual corridors were cluttered but were connected in a grid.
Reference: [20] <author> Rodney A. Brooks. </author> <title> A robust layered control system for a mobile robot. </title> <journal> IEEE Journal of Robotics and Automoation, </journal> <volume> 2(1) </volume> <pages> 14-23, </pages> <month> March </month> <year> 1986. </year>
Reference-contexts: If we treat problems as task/environment pairs, then we can also taxonomize environments in terms of their relative difficulty for specific tasks. In recent years, many researchers have tried to build the minimal mechanisms for specific task/environment pairs (see, for example, Agre [2], Brooks <ref> [20] </ref>, Chapman [25], Connell [28], and Rosenschein and Kaelbling [88]). Some researchers, such as Connell, use minimalism as an engineering methodology. Agre, on the other hand, treats it largely as a psychological or anthropological methodology. I will focus principally on engineering issues. <p> If both are implemented using planners, then the resulting system is effectively a hierarchical planner (see Sacerdoti [89] or Knoblock et al. [55]). Polly's environment happens to allow the use of simple reactive policies for both, so it is a layered reactive system (Brooks <ref> [20] </ref>). In an environment with a more complicated graph topology, one could reverse the second optimization and use a deliberative planner, leaving the first optimization intact.
Reference: [21] <author> Rodney A. Brooks. </author> <title> The behavior language; user's guide. AI Lab Memo 1227, </title> <address> MITAI, </address> <month> Apr </month> <year> 1990. </year>
Reference: [22] <author> Christopher Brown, David Coombs, and John Soong. </author> <title> Real-time smooth pursuit tracking. </title> <booktitle> In Blake and Yuille [17], </booktitle> <pages> pages 126-136. </pages>
Reference: [23] <author> David Chapman. </author> <title> Planning for conjunctive goals. </title> <journal> Artificial Intelligence, </journal> <volume> 32 </volume> <pages> 333-377, </pages> <year> 1987. </year>
Reference-contexts: Introduction to part II 4.1 Background In the last decade AI has seen a surprising number of negative theoretical results. Formal planning has been shown to be computationally intractable, or even undecidable (see Chapman <ref> [23] </ref>). Many perception problems have been shown to be highly numerically unstable (see Aloimonos and Rosenfeld [5]). In general, most AI problems amount to search of large spaces, be they discrete spaces, as in the case of reasoning, or continuous spaces, as in the problems of inverse optics.
Reference: [24] <author> David Chapman. </author> <title> Intermediate vision: Architecture, implementation, and use. </title> <type> TR 90-06, </type> <institution> Teleos Research, </institution> <year> 1990. </year>
Reference: [25] <author> David Chapman. </author> <title> Vision, instruction, and action. </title> <type> Technical Report 1204, </type> <institution> Mas-sachusetts Institute of Technology, Artificial Intelligence Lab, </institution> <month> April </month> <year> 1990. </year>
Reference-contexts: If we treat problems as task/environment pairs, then we can also taxonomize environments in terms of their relative difficulty for specific tasks. In recent years, many researchers have tried to build the minimal mechanisms for specific task/environment pairs (see, for example, Agre [2], Brooks [20], Chapman <ref> [25] </ref>, Connell [28], and Rosenschein and Kaelbling [88]). Some researchers, such as Connell, use minimalism as an engineering methodology. Agre, on the other hand, treats it largely as a psychological or anthropological methodology. I will focus principally on engineering issues.
Reference: [26] <author> David Chapman. </author> <title> Vision, Instruction, and Action. </title> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference: [27] <author> Noam Chomsky. </author> <title> Aspects of the Theory of Syntax. </title> <publisher> MIT Pres, </publisher> <address> Cambridge, MA, </address> <year> 1965. </year>
Reference: [28] <author> Jonathan H. Connell. </author> <title> Minimalist Mobile Robotics. </title> <publisher> Academic Press, </publisher> <year> 1990. </year>
Reference-contexts: If we treat problems as task/environment pairs, then we can also taxonomize environments in terms of their relative difficulty for specific tasks. In recent years, many researchers have tried to build the minimal mechanisms for specific task/environment pairs (see, for example, Agre [2], Brooks [20], Chapman [25], Connell <ref> [28] </ref>, and Rosenschein and Kaelbling [88]). Some researchers, such as Connell, use minimalism as an engineering methodology. Agre, on the other hand, treats it largely as a psychological or anthropological methodology. I will focus principally on engineering issues.
Reference: [29] <author> David Coombs and Karen Roberts. "bee-bot": </author> <title> using peripheral optical flow to avoid obstacles. </title> <booktitle> In Proc. of the SPIE Conf. on Intelligent Robots and Computer Vision XI: Algorithms, Techniques, and Active Vision, </booktitle> <address> (Boston, MA, </address> <month> November 15-20, </month> <year> 1992), 1992. </year>
Reference: [30] <author> Jill D. Crisman. </author> <title> Color region tracking for vehicle guidance. </title> <note> In Blake and Yuille [17], chapter 7. </note>
Reference-contexts: An information type is a salience function if it is conditionally equivalent to F G O given some constraint (a "salience constraint"). The use of such simple, easily computed functions to find particular classes of objects is common both in AI (see Swain [96], Turk et al. [105], <ref> [30] </ref>, Horswill and Brooks [51], Woodfill and Zabih [115]) and in the biological world (see Roitblat [85] for a good introduction). 64 The coloring algorithm uses the texture detector as a salience function. We want to determine what salience constraint is required for a given texture detector.
Reference: [31] <author> James E. </author> <title> Cutting. Perception with an Eye for Motion. </title> <publisher> MIT Press, </publisher> <year> 1986. </year>
Reference: [32] <author> DARPA SISTO. </author> <booktitle> Proceedings of the 1993 DARPA Image Understanding Workshop, </booktitle> <address> Washington, D.C., 1993. </address> <publisher> Morgan Kaufman. </publisher>
Reference: [33] <author> D. DeMenthon. </author> <title> A zero-bank algorithm for inverse perspective of a road from a single image. </title> <booktitle> In 1987 IEEE Internation Conference on Robotics and Automation, </booktitle> <pages> pages 258-263. </pages> <publisher> IEEE, </publisher> <month> March </month> <year> 1987. </year>
Reference: [34] <author> Ernst D. Dickmanns. </author> <title> Expectation-based dynamic scene understanding. </title> <note> In Blake and Yuille [17], chapter 18. </note>
Reference: [35] <author> Michael Dixon. </author> <title> Embedded computation and the semantics of programs. </title> <type> TR SSL-91-1, </type> <institution> Xerox Palo Alto Research Center, </institution> <address> Palo Alto, CA, </address> <month> September </month> <year> 1991. </year>
Reference-contexts: An alternative to the state-machine formalism can be found in the work of Dixon <ref> [35] </ref>. Dixon derives his semantics from first order logic, in which the world comes individuated into objects and relations, rather than on the state-space methods used here. Dixon's "open" approach also avoids the need to define the environment as a single mathematical structure.
Reference: [36] <author> Bruce Randall Donald and James Jennings. </author> <title> Constructive recognizability for task-directed robot programming. </title> <booktitle> Robotics and Autonomous Systems, </booktitle> <volume> 9 </volume> <pages> 41-74, </pages> <year> 1992. </year>
Reference-contexts: Later, Rosenschein developed a method for synthesizing automata whose internal states had provable correlations to the state of the environment given a set of temporal logic assertions about the dynamics of the environment. Donald and Jennings <ref> [36] </ref> use a geometric, but similar, approach for constructing virtual sensors. Wilson [113] has specifically proposed the classification of simulated environments based on the types of mechanisms which can operate successfully within them. Wilson also used a finite state formalization of the environment. <p> The notation is needed to establish a framework within which to apply the transformations. The notation used here is largely equivalent to those used by Rosenschein and Kaelbling [88], and by Donald and Jennings <ref> [36] </ref>. It was chosen for largely for compactness of presentation. The formal trick of externalizing the agent's internal state also turns out to be useful. 7.1 Environments We will now allow different environments to have different state spaces and will treat actions as mappings from states to states.
Reference: [37] <author> Sean P. Engelson and Drew McDermott. </author> <title> Image signatures for place recognition and map construction. </title> <booktitle> In Proceedings SPIE Symposium on Intelligent Robotic Systems, Sensor Fusion IV, </booktitle> <month> November </month> <year> 1991. </year> <month> 186 </month>
Reference: [38] <author> Jerome A. Feldman. </author> <title> Four frames suffice: A provisionary model of vision and space. </title> <type> TR 99, </type> <institution> Computer Science Department, University of Rochester, Rochester, </institution> <address> NY 14627, </address> <month> September </month> <year> 1982. </year>
Reference: [39] <author> Margaret M. Fleck. </author> <title> Boundaries and topological algorithms. </title> <type> TR 1065, </type> <institution> MIT Artificial Intelligence Laboratory, </institution> <address> Cambridge, MA, </address> <year> 1988. </year>
Reference-contexts: Given GP C, we can use least y coordinate as a measure of the depth of the closest object. Let Body-Depth O be the information type that gives the correct body 1 Formalizing the notion of contact can be difficult (see for example Fleck <ref> [39] </ref>, chapter 8), but we will treat the notion as primitive, since the particular formalization is unimportant for our purposes. 67 depth for pixels generated by one of the objects O, or 1 for pixels generated by the background. Lemma 4 Let R be a region of the image.
Reference: [40] <author> Erann Gat. </author> <title> Integrating planning and reacting in a heterogeneous asynchronous architecture for controlling real-world mobile robots. </title> <booktitle> In Proceedings, AAAI-92, </booktitle> <year> 1992. </year>
Reference-contexts: The result would then be a hybrid system with planning on top and reacting on the bottom (see Spector and Hendler [93], Lyons and Hendriks [67], Bresina and Drummond [19], or Gat <ref> [40] </ref> for other examples). On the other hand, one could imagine an environment where the individual corridors were cluttered but were connected in a grid.
Reference: [41] <author> J. J. Gibson. </author> <title> The Senses Considered as Perceptual Systems. </title> <address> Houghton-Mi*in, Boston, </address> <year> 1966. </year>
Reference: [42] <author> J. J. Gibson. </author> <title> The Ecological Approach to Perception. </title> <address> Houghton-Mi*in, Boston, </address> <year> 1979. </year>
Reference: [43] <author> Richard W. </author> <title> Hamming. Coding and Information Theory. </title> <publisher> Prentice Hall, </publisher> <address> Engle-wood Cliffs, N.J. 07632, </address> <year> 1980. </year>
Reference-contexts: An information type is finite if its range is finite. Note that information types should not be confused with the concept of information as inverse probability used in classical information theory (see Hamming <ref> [43] </ref>).
Reference: [44] <author> Kristian J. Hammond and Timothy M. </author> <title> Converse. Stabilizing environments to facilitate planning and activity: An engineering argument. </title> <booktitle> In Ninth National Conference on Artificial Intelligence, </booktitle> <pages> pages 787-793, </pages> <address> Menlo Park, CA, </address> <month> July </month> <year> 1991. </year> <booktitle> American Association for Artificial Intelligence, </booktitle> <publisher> AAAI Press. </publisher>
Reference-contexts: Using temporal logic, they are able to identify useful dynamics and design reactive behaviors to exploit them. Hammond, Converse, and Grass discuss how new dynamics can be designed into an agent to improve the stability of the agent/environment system <ref> [44] </ref>. 4.5 How to read part II The top-level claims of this report are that (1) the use of task and environment in the design of special purpose vision systems can lead to dramatically simpler and more robust systems and (2) those systems can be analyzed and understood in a principled
Reference: [45] <author> John E. Hopcroft and Jeffrey D. Ullman. </author> <title> Introduction to Automata Theory, Languages, and Computation. </title> <publisher> Addison Wesley, </publisher> <year> 1979. </year>
Reference-contexts: Unfortunately, search is fundamentally hard. It is widely believed that no search problem which is at least as difficult as boolean satisfiability can be solved in polynomial time (Cook's NP-completeness result; see Hopcroft and Ullman <ref> [45] </ref> for an introduction). This is a problem. If search is formally intractable, then either AI is impossible, as Penrose argues [79], or there must be a loophole somewhere. There are two candidate loopholes.
Reference: [46] <author> B. K. P. Horn. </author> <title> Robot Vision. </title> <publisher> MIT Press, </publisher> <year> 1986. </year>
Reference: [47] <author> Ian Horswill. </author> <title> The senselisp programmer's manual. </title> <type> Unpublished technical note, </type> <institution> MIT Artificial Intelligence Laboratory, </institution> <year> 1989. </year>
Reference: [48] <author> Ian Horswill. </author> <title> How to hack yourself senselisp. </title> <type> Unpublished technical note, </type> <institution> MIT Artificial Intelligence Laboratory, </institution> <month> March </month> <year> 1990. </year>
Reference: [49] <author> Ian Horswill. </author> <title> Proximity detection using a spatial filter tuned in three-space. </title> <booktitle> In Proceedings of the 1991 AAAI Fall Symposium on Sensory Aspects of Robotic Intelligence, </booktitle> <year> 1991. </year>
Reference: [50] <author> Ian Horswill. </author> <title> Specialization of perceptual processes. </title> <type> PhD thesis, </type> <institution> Massachusetts Institute of Technology, </institution> <address> Cambridge, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: north of goal and at turn to north turn-south if south of goal and at turn to south ::: turn-north if south of goal and pointed south turn-south if north of goal and pointed north ::: f ollow-corridor otherwise The details of the perception and control systems are given in <ref> [50] </ref>. 10.0.1 Derivation from a geometric path planner Geometric path planning is a common technique for solving this type of problem.
Reference: [51] <author> Ian Horswill and Rodney Brooks. </author> <title> Situated vision in a dynamic environment: Chasing objects. </title> <booktitle> In Proceedings of the Seventh National Conference on Artificial Intelligence, </booktitle> <month> August </month> <year> 1988. </year> <month> 187 </month>
Reference-contexts: The use of such simple, easily computed functions to find particular classes of objects is common both in AI (see Swain [96], Turk et al. [105], [30], Horswill and Brooks <ref> [51] </ref>, Woodfill and Zabih [115]) and in the biological world (see Roitblat [85] for a good introduction). 64 The coloring algorithm uses the texture detector as a salience function. We want to determine what salience constraint is required for a given texture detector. <p> Many researchers I have talked to have taken it for granted that images below 128 fi 128 are mostly useless, whereas Polly uses resolutions as low at 16 fi 12. Polly demonstrates that surprisingly good results can be obtained with surprisingly low resolutions (see Horswill and Brooks <ref> [51] </ref> and Pomerleau [81] for other examples). Obviously, some tasks and environments require higher resolution, but many do not. Nor does a system need to sample everything at the same resolution.
Reference: [52] <author> Ian D. Horswill. </author> <title> Reactive navigation for mobile robots. </title> <type> Master's thesis, </type> <institution> Mas--sachusetts Institute of Technology, </institution> <month> June </month> <year> 1988. </year>
Reference: [53] <author> Katsushi Ikeuchi and Martial Herbert. </author> <title> Task oriented vision. </title> <booktitle> In DARPA Image Understanding Workshop, </booktitle> <year> 1990. </year>
Reference: [54] <author> O. Khatib. </author> <title> Real-time obstacle avoidance for manipulators and mobile robots. </title> <journal> International Journal of Robotics Research, </journal> <volume> 5(1) </volume> <pages> 90-98, </pages> <year> 1986. </year>
Reference-contexts: Progress functions are also similar to Liapunov functions (see Luenberger [65]), admissible heuristics (see Barr and Feigenbaum [12], volume 1, chapter II), and artificial potential fields (see Khatib <ref> [54] </ref> or Latombe [62]). We will say that a policy p honors a non-negative function , if steadily decreases it until it reaches zero, i.e. for all states s and some * &gt; 0, either ((p (s))(s)) &lt; (s) * or else (s) = ((p (s))(s)) = 0. <p> However, if an obstacle is in the way, it will be the nearest thing on one or the other side and the robot will avoid it. This is a local navigation strategy equivalent to the method of artificial potential fields (see Khatib <ref> [54] </ref>). It has the advantage of being fast and easy to compute and the disadvantage that the left and right distances can sometimes balance exactly, even when then robot is blocked by an obstacle.
Reference: [55] <author> Craig A. Knoblock, Josh D. Tenenberg, and Qiang Yang. </author> <title> A spectrum of abstraction hierarchies for planning. </title> <booktitle> In Proceedings of AAAI-90, </booktitle> <year> 1990. </year>
Reference-contexts: If both are implemented using planners, then the resulting system is effectively a hierarchical planner (see Sacerdoti [89] or Knoblock et al. <ref> [55] </ref>). Polly's environment happens to allow the use of simple reactive policies for both, so it is a layered reactive system (Brooks [20]). In an environment with a more complicated graph topology, one could reverse the second optimization and use a deliberative planner, leaving the first optimization intact.
Reference: [56] <author> David Kortencamp. </author> <title> Applying computational theories of cognitive mapping to mobile robots. </title> <editor> In Marc Slack and Erann Gat, editors, </editor> <booktitle> Working notes of the AAAI Spring Symposium on Control of Selective Perception, </booktitle> <pages> pages 83-89. </pages> <publisher> AAAI, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1992. </year>
Reference: [57] <author> A. Kosaka and A. C. Kak. </author> <title> Fast vision-guided mobile robot navigation using model-based reasoning and prediction of uncertainties. Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> 56(3), </volume> <month> September </month> <year> 1992. </year>
Reference: [58] <author> Jana Kosecka. </author> <title> Control of discrete event systems. </title> <type> GRASP LAB report 313, </type> <institution> University of Pennsylvania Computer and Information Science Department, </institution> <address> Philadelphia, PA, </address> <month> April </month> <year> 1992. </year>
Reference-contexts: See Marr [68]. 53 the minimal parameters that still allowed an optimal control policy to be learned. There is also an extensive literature on discrete-event dynamic systems (see Kosecka <ref> [58] </ref> for a readable introduction), which also model the environment as a finite state machine, but which assume that transition information (rather than state information) is visible to the agents. An alternative to the state-machine formalism can be found in the work of Dixon [35].
Reference: [59] <author> David J. Kriegman and Ernst Triendl. </author> <title> Stereo vision and navigation within buildings. </title> <booktitle> In 1987 IEEE Internation Conference on Robotics and Automation, </booktitle> <pages> pages 402-408. </pages> <publisher> IEEE, </publisher> <month> March 87. </month>
Reference: [60] <author> David J. Kriegman, Ernst Triendl, and Tomas O. Binford. </author> <title> A mobile robot: Sensing, planning and locomotion. </title> <booktitle> In 1987 IEEE Internation Conference on Robotics and Automation, </booktitle> <pages> pages 402-408. </pages> <publisher> IEEE, </publisher> <month> March 87. </month>
Reference: [61] <author> Benjamin J. Kuipers and Yung-Tai Byun. </author> <title> A robust, qualitative approach to a spatial learning mobile robot. </title> <booktitle> In SPIE Advances in Intelligent Robotics Systems, </booktitle> <month> November </month> <year> 1988. </year>
Reference: [62] <author> Jean-Claude Latombe. </author> <title> Robot Motion Planning. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, </address> <year> 1991. </year>
Reference-contexts: Progress functions are also similar to Liapunov functions (see Luenberger [65]), admissible heuristics (see Barr and Feigenbaum [12], volume 1, chapter II), and artificial potential fields (see Khatib [54] or Latombe <ref> [62] </ref>). We will say that a policy p honors a non-negative function , if steadily decreases it until it reaches zero, i.e. for all states s and some * &gt; 0, either ((p (s))(s)) &lt; (s) * or else (s) = ((p (s))(s)) = 0. <p> Given a detailed description of the environment, a start position, and a goal position, a path planner computes a safe path through the environment from start to goal (see Latombe <ref> [62] </ref>). Once the path has been planned, a separate system follows the path. Geometric planning is versatile and can produce very efficient paths, but is not computationally efficient. It also requires detailed knowledge of the environment which the perceptual system may be unable to deliver.
Reference: [63] <author> Hector J. Levesque and Ronald J. Brachman. </author> <title> A fundamental tradeoff in knowledge representation and reasoning (revised edition). </title> <editor> In Ronald J. Brachman and Hector J. Levesque, editors, </editor> <booktitle> Readings in Knowledge Representation, </booktitle> <pages> pages 42-70. </pages> <publisher> Morgan Kaufman, </publisher> <address> Los Altos, CA, </address> <year> 1985. </year> <month> 188 </month>
Reference: [64] <author> Michael L. Littman. </author> <title> An optimization-based categorization of reinforcement learning environments. </title> <booktitle> In Meyer and Wilson [73], </booktitle> <pages> pages 262-270. </pages>
Reference-contexts: Wilson also used a finite state formalization of the environment. He divided environments into three classes based on properties such as determinacy. Todd and Wilson [102] used finite state machines to taxonomize grid worlds for a class of artificial agents created by a genetic algorithm. Littman <ref> [64] </ref> used FSM models to classify environments for reinforcement learning algorithms. Littman parameterized the complexity of RL agents in terms of the amount of local storage they use and how far into the future the RL algorithm looks.
Reference: [65] <author> David G. Luenberger. </author> <title> Introduction to Dynamic Systems: Theory, Models, and Applications. </title> <publisher> John Wiley and Sons, </publisher> <year> 1979. </year>
Reference-contexts: First, we will add actions (state transitions) to the environment, making it a full state-machine. We will then model both deliberative planning systems and reactive systems as variants of the control policies of classical control theory (see Luenberger <ref> [65] </ref> or Beer [15]). This gives us a uniform vocabulary for expressing both types of systems. <p> The term "progress function" is taken from the program verification literature, where it refers to functions over the internal state of the program that are used to prove termination of loops. Progress functions are also similar to Liapunov functions (see Luenberger <ref> [65] </ref>), admissible heuristics (see Barr and Feigenbaum [12], volume 1, chapter II), and artificial potential fields (see Khatib [54] or Latombe [62]).
Reference: [66] <author> Kevin Lynch. </author> <title> The Image of the City. </title> <publisher> MIT Press, </publisher> <year> 1960. </year>
Reference-contexts: Polly can also recognize large-scale "districts" and correct its position estimate even if it cannot determine exactly where it is. There is evidence that humans use such information (see Lynch <ref> [66] </ref>). The robot presently recognizes the two long east/west corridors as districts. For example, when the robot sees a left turn while driving west, it must be in the southern east/west corridor, so its y coordinate must be 10 regardless of its x coordinate.
Reference: [67] <author> D. M. Lyons and A. J. Hendriks. </author> <title> Exploiting patterns of interaction to achieve reactive behavior. </title> <booktitle> in submission, </booktitle> <year> 1993. </year>
Reference-contexts: Several researchers have discussed how time-extended patterns of interaction with the environment (called "dynamics" by Agre [2]) can be used to reduce the computational burden on an agent. Lyons and Hendricks have discussed how to derive and exploit useful dynamics from a formal specification of the environment <ref> [67] </ref>. They use a uniform formalization of both agent and environment based on process algebra. Using temporal logic, they are able to identify useful dynamics and design reactive behaviors to exploit them. <p> The result would then be a hybrid system with planning on top and reacting on the bottom (see Spector and Hendler [93], Lyons and Hendriks <ref> [67] </ref>, Bresina and Drummond [19], or Gat [40] for other examples). On the other hand, one could imagine an environment where the individual corridors were cluttered but were connected in a grid.
Reference: [68] <author> David Marr. </author> <title> Vision. </title> <editor> W. H. </editor> <publisher> Freeman and Co., </publisher> <year> 1982. </year>
Reference-contexts: Gibson 52 argued that the structure of the environment determines a set of invariants in the energy flowing through the environment and that these invariants can be directly picked up by the perceptual apparatus of the organism via a process akin to resonance. Marr <ref> [68] </ref> argued that in order to properly understand the operation of a perceptual system (or more generally, of any intelligent system), we must understand the problem it solves at the level of a computational theory. 2 The computational theory defines the desired input-output behavior of the perceptual system, along with a <p> He then empirically classified environments by the 2 Marr's actual story is more complicated than this, and used three levels of explanation, not two. See Marr <ref> [68] </ref>. 53 the minimal parameters that still allowed an optimal control policy to be learned.
Reference: [69] <editor> Maja J. Mataric. </editor> <title> Minimizing complexity in controlling a collection of mobile robots. </title> <booktitle> In IEEE International Conference on Robotics and Automation, </booktitle> <pages> pages 830-835, </pages> <address> Nice, France, </address> <month> May </month> <year> 1992. </year>
Reference: [70] <author> David McFarland. </author> <title> What it means for robot behavior to be adaptive. </title> <booktitle> In Meyer and Wilson [72], </booktitle> <pages> pages 22-28. </pages>
Reference-contexts: Cybernetics, the progenitor of artificial intelligence, also focused on agent/environment interactions, although not necessarily on the properties of specific, complex environments [112]. Ideas from these areas are now being applied to artificial intelligence and robotics (see McFarland <ref> [70] </ref>, Paton et al. [78]. Meyer and Guillot [71]). In perceptual psychology, Gibson proposed an "ecological" theory of perception that stressed the role of the environment in forming an agent's perceptions.
Reference: [71] <editor> Jean-Arcady Meyer and Agnes Guillot. </editor> <booktitle> Simulation of adaptive behavior in animats: Review and prospect. In Meyer and Wilson [72], </booktitle> <pages> pages 2-14. </pages>
Reference-contexts: Cybernetics, the progenitor of artificial intelligence, also focused on agent/environment interactions, although not necessarily on the properties of specific, complex environments [112]. Ideas from these areas are now being applied to artificial intelligence and robotics (see McFarland [70], Paton et al. [78]. Meyer and Guillot <ref> [71] </ref>). In perceptual psychology, Gibson proposed an "ecological" theory of perception that stressed the role of the environment in forming an agent's perceptions.
Reference: [72] <editor> Jean-Arcady Meyer and Stewart W. Wilson, editors. </editor> <booktitle> From Animals to Animats: Proceedings of the First International Conference on Simulation of Adaptive Behavior. </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1991. </year>
Reference: [73] <editor> Jean-Arcady Meyer and Stewart W. Wilson, editors. </editor> <booktitle> From Animals to Animats: The Second International Conference on Simulation of Adaptive Behavior. </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1993. </year>
Reference: [74] <author> Hans P. Moravec. </author> <title> The stanford cart and cmu rover. </title> <type> Technical report, </type> <institution> Robotics Institute, Carnegie-Mellon University, </institution> <month> February </month> <year> 1983. </year>
Reference: [75] <author> Randal C. Nelson. </author> <title> Visual homing using an associative memory. </title> <booktitle> In Proceedings of the DARPA Image Understanding Workshop, </booktitle> <pages> pages 245-262, </pages> <year> 1989. </year> <note> [76] ed. </note> <author> Nils J. Nilsson. </author> <title> Shakey the robot. </title> <type> Technical Report 323, </type> <institution> SRI International, </institution> <month> April </month> <year> 1984. </year>
Reference: [77] <author> H. Keith Nishihara. </author> <title> Minimal meaningful measurement tools. </title> <type> TR 91-01, </type> <institution> Teleos Research, </institution> <year> 1991. </year>
Reference: [78] <author> R. C. Patton, H. S. Nwana, M. J. R. Shave, and T. J. M. Bench-Capon. </author> <title> Computing at the tissue/organ level (with particular reference to the liver). </title> <booktitle> In Varela and Bourgine [107], </booktitle> <pages> pages 411-420. 189 </pages>
Reference-contexts: Cybernetics, the progenitor of artificial intelligence, also focused on agent/environment interactions, although not necessarily on the properties of specific, complex environments [112]. Ideas from these areas are now being applied to artificial intelligence and robotics (see McFarland [70], Paton et al. <ref> [78] </ref>. Meyer and Guillot [71]). In perceptual psychology, Gibson proposed an "ecological" theory of perception that stressed the role of the environment in forming an agent's perceptions.
Reference: [79] <author> Roger Penrose. </author> <title> The Emperor's New Mind. </title> <publisher> Oxford University Press, </publisher> <year> 1989. </year>
Reference-contexts: This is a problem. If search is formally intractable, then either AI is impossible, as Penrose argues <ref> [79] </ref>, or there must be a loophole somewhere. There are two candidate loopholes. There could be a loophole in search: there might be polynomial-time algorithms for solving search problems in the average case.
Reference: [80] <author> T. Poggio and V. Torre. </author> <title> Ill-posed problems and regularization analysis in early vision. </title> <editor> In Lee S. Baumann, editor, </editor> <booktitle> Image Understanding Workshop (New Or-leans, </booktitle> <address> LA, </address> <month> October 3-4, </month> <year> 1984), </year> <pages> pages 257-263. </pages> <institution> Defense Advanced Research Projects Agency, Science Applications International Corp., </institution> <year> 1984. </year>
Reference: [81] <author> Dean A. Pomerleau. </author> <title> Efficient training of artificial neural networks for autonomous navigation. </title> <journal> Neural Computation, </journal> <volume> 3(1), </volume> <year> 1991. </year>
Reference-contexts: Polly demonstrates that surprisingly good results can be obtained with surprisingly low resolutions (see Horswill and Brooks [51] and Pomerleau <ref> [81] </ref> for other examples). Obviously, some tasks and environments require higher resolution, but many do not. Nor does a system need to sample everything at the same resolution.
Reference: [82] <author> Louise Pryor and Gregg Collins. </author> <title> Planning to perceive: a utilitarian approach. </title> <booktitle> In Simmons [91], </booktitle> <pages> pages 113-122. </pages>
Reference: [83] <author> Douglas A. Reece and Steven Shafer. </author> <title> Active vision at the system level for robot driving. </title> <booktitle> In Simmons [91], </booktitle> <pages> pages 70-77. </pages>
Reference: [84] <author> Daniel Reisfeld, Haim Wolfson, and Yehezkel Yeshurun. </author> <title> Detection of interest points using symmetry. </title> <booktitle> In Proceedings of the Third International Conference on Computer Vision, </booktitle> <pages> pages 62-65, </pages> <address> Osaka, Japan, </address> <month> December </month> <year> 1990. </year> <journal> IEEE Computer Society. </journal>
Reference-contexts: Then, it tests the most symmetric region to see if it is a distinct object. 8.4.1 Symmetry detection This is performed by the Scheme procedure find-symmetric. It is a simplified version of the technique used by Reisfeld et al. <ref> [84] </ref>. The simplest measure of symmetry about the vertical axis at a point (x; y) is: 0 @x @I (x r; y)dr where l is the width of the region being searched for symmetry. <p> This can be alleviated by adding a compressive nonlinearity to the integrand. Reisfeld et al. <ref> [84] </ref> used a log function for the nonlinearity. Polly uses a max because it is somewhat faster to compute: 0 @I (x + r; y) @x !! Here ff is the maximal symmetry value which the system will give to a single pixel pair.
Reference: [85] <author> Herbert L. </author> <title> Roitblat. Introduction to Comparitive Cognition. </title> <editor> W. H. </editor> <publisher> Freeman and Company, </publisher> <year> 1987. </year>
Reference-contexts: The use of such simple, easily computed functions to find particular classes of objects is common both in AI (see Swain [96], Turk et al. [105], [30], Horswill and Brooks [51], Woodfill and Zabih [115]) and in the biological world (see Roitblat <ref> [85] </ref> for a good introduction). 64 The coloring algorithm uses the texture detector as a salience function. We want to determine what salience constraint is required for a given texture detector. For simplicity, we will restrict ourselves to Fourier-based measures of texture.
Reference: [86] <author> Stanley J. Rosenschein. </author> <title> Formal theories of knowledge in ai and robotics. report CSLI-87-84, Center for the Study of Language and Information, </title> <publisher> Stanford, </publisher> <address> CA, </address> <year> 1987. </year>
Reference: [87] <author> Stanley J. Rosenschein. </author> <title> Synthesizing information-tracking automata from environment descriptions. </title> <editor> In Ronald J. Brachman, Hector J. Levesque, and Raymond Reiter, editors, </editor> <booktitle> Proceedings of the First International Conference on Principles of Knowledge Representation and Reasoning, </booktitle> <pages> pages 386-393, </pages> <month> May </month> <year> 1989. </year>
Reference: [88] <author> Stanley J. Rosenschein and Leslie Pack Kaelbling. </author> <title> The synthesis of machines with provable epistemic properties. </title> <editor> In Joseph Halpern, editor, </editor> <booktitle> Proc. Conf. on Theoretical Aspects of Reasoning about Knowledge, </booktitle> <pages> pages 83-98. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1986. </year>
Reference-contexts: In recent years, many researchers have tried to build the minimal mechanisms for specific task/environment pairs (see, for example, Agre [2], Brooks [20], Chapman [25], Connell [28], and Rosenschein and Kaelbling <ref> [88] </ref>). Some researchers, such as Connell, use minimalism as an engineering methodology. Agre, on the other hand, treats it largely as a psychological or anthropological methodology. I will focus principally on engineering issues. <p> This work extends Marr's ideas by using constraints to explain optimizations at the implementation level. Most formal models of environments use state-space descriptions of the environment, usually finite-state machines. Rosenschein and Kaelbling used finite state machines to represent both agent and environment (see Rosenschein [86][87], and Rosenschein and Kaelbling <ref> [88] </ref>). Their formalization allowed specialized mechanisms to be directly synthesized from descriptions of desired behavior and a formalization of the behavior of the environment. The formalization was powerful enough to form the basis of a programming language used to program a real robot. <p> The notation is needed to establish a framework within which to apply the transformations. The notation used here is largely equivalent to those used by Rosenschein and Kaelbling <ref> [88] </ref>, and by Donald and Jennings [36]. It was chosen for largely for compactness of presentation.
Reference: [89] <author> Earl D. Sacerdoti. </author> <title> Planning in a hierarchy of abstraction spaces. </title> <journal> Artificial Intelligence, </journal> <volume> 5(2), </volume> <year> 1974. </year>
Reference-contexts: It is important to note that either, both, or neither of the subproblems (the abstracted environment and corridor following) could be solved using deliberative planning; the two decisions are orthogonal. If both are implemented using planners, then the resulting system is effectively a hierarchical planner (see Sacerdoti <ref> [89] </ref> or Knoblock et al. [55]). Polly's environment happens to allow the use of simple reactive policies for both, so it is a layered reactive system (Brooks [20]).
Reference: [90] <author> Roger C. Schank. </author> <title> Tell Me a Story. </title> <publisher> Charles Scribner's Sons, </publisher> <year> 1990. </year> <month> 190 </month>
Reference-contexts: The key question is: what is it about the instances we encounter regularly in our lives that makes them easy to solve? A number of overlapping answers have been proposed. Both Schank <ref> [90] </ref> and Agre [2] have argued at length that we tend to solve similar or even identical instances over and over, so we can keep recycling old solutions with minor modifications.
Reference: [91] <author> Reid Simmons, </author> <title> editor. </title> <booktitle> Working notes of the AAAI Spring Symposium on Con--trol of Selective Perception, </booktitle> <address> Stanford, California, </address> <year> 1992. </year> <journal> American Association for Artificial Intelligence. </journal>
Reference: [92] <author> Herbert A. Simon. </author> <booktitle> Sciences of the Artificial. </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, Mas-sachusetts, </address> <year> 1970. </year>
Reference-contexts: Some authors stress that the world is much simpler than the most general imaginable case (see, for example, Agre [2]). Other authors stress the complexity of the environment, arguing that the complexity of the environment allows agents to be simpler (see, for example, Simon <ref> [92] </ref>). These are not 49 incompatible statements. The former is a statement about which of the imaginable possible worlds an agent must actually live in, whereas the latter is a statement about the presence of simplifying structures within the environment.
Reference: [93] <author> Lee Spector and James Hendler. </author> <title> The supervenience architecture. </title> <editor> In Avi Kak, editor, </editor> <booktitle> Working notes of the AAAI Fall Symposium on Sensory Aspects of Robotic Intelligence, </booktitle> <pages> pages 93-100. </pages> <publisher> AAAI Press, </publisher> <address> Asilomar, California, </address> <year> 1991. </year>
Reference-contexts: In an environment with a more complicated graph topology, one could reverse the second optimization and use a deliberative planner, leaving the first optimization intact. The result would then be a hybrid system with planning on top and reacting on the bottom (see Spector and Hendler <ref> [93] </ref>, Lyons and Hendriks [67], Bresina and Drummond [19], or Gat [40] for other examples). On the other hand, one could imagine an environment where the individual corridors were cluttered but were connected in a grid.
Reference: [94] <author> Anselm Spoerri. </author> <title> The early detection of motion boundaries. </title> <type> Technical Report 1275, </type> <institution> MIT Artificial Intelligence Laboratory, </institution> <year> 1991. </year>
Reference: [95] <author> K. Storjohann, T. Zeilke, H. A. Mallot, and W. von Seelen. </author> <title> Visual obstacle detection for automatically guided vehicles. </title> <booktitle> In Proceedings of the IEEE International Conference on Robotics and Automation, </booktitle> <pages> pages 761-766, </pages> <month> May </month> <year> 1990. </year>
Reference: [96] <author> Michael J. Swain. </author> <title> Color indexing. </title> <type> Technical Report 390, </type> <institution> University of Rochester Computer Science Department, </institution> <month> November </month> <year> 1990. </year>
Reference-contexts: An information type is a salience function if it is conditionally equivalent to F G O given some constraint (a "salience constraint"). The use of such simple, easily computed functions to find particular classes of objects is common both in AI (see Swain <ref> [96] </ref>, Turk et al. [105], [30], Horswill and Brooks [51], Woodfill and Zabih [115]) and in the biological world (see Roitblat [85] for a good introduction). 64 The coloring algorithm uses the texture detector as a salience function. <p> For example, if the background has a distinctive color or set of colors, we can use a color system such as Swain's color histogram method <ref> [96] </ref> to find the carpet: ) color ! column heights ! If we wanted to build a system that worked in both domains, we could implement both the color system and the edge detector and switch between them opportunistically, provided there was sufficient information to determine which one to use.
Reference: [97] <author> Michael J. Swain. </author> <title> Active visual routines. </title> <booktitle> In Simmons [91], </booktitle> <pages> pages 147-149. </pages>
Reference: [98] <author> W.B. Thompson and J.K. Kearney. </author> <title> Inexact vision. </title> <booktitle> In Workshop on Motion: Representation and Analysis, </booktitle> <year> 1986. </year>
Reference: [99] <author> W.B. Thompson, K.M. Mutch, and V.A. Berzins. </author> <title> Dynamic occlusion analysis in optical flow fields. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 7 </volume> <pages> 374-383, </pages> <year> 1985. </year>
Reference: [100] <author> C. E. Thorpe. </author> <title> FIDO: Vision and Navigation for a Robot Rover. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, Carnegie-Mellon University, </institution> <month> December </month> <year> 1984. </year>
Reference: [101] <editor> Where to Look Next Using a Bayes Net: </editor> <title> The TEA-1 System and Future Directions. </title> <editor> Raymond d. rimey. </editor> <booktitle> In Simmons [91], </booktitle> <pages> pages 118-122. </pages>
Reference: [102] <author> Peter M. Todd and Stewart W. Wilson. </author> <title> Environment structure and adaptive behavior from the ground up. </title> <booktitle> In Meyer and Wilson [73], </booktitle> <pages> pages 11-20. </pages>
Reference-contexts: Wilson [113] has specifically proposed the classification of simulated environments based on the types of mechanisms which can operate successfully within them. Wilson also used a finite state formalization of the environment. He divided environments into three classes based on properties such as determinacy. Todd and Wilson <ref> [102] </ref> used finite state machines to taxonomize grid worlds for a class of artificial agents created by a genetic algorithm. Littman [64] used FSM models to classify environments for reinforcement learning algorithms.
Reference: [103] <author> Peng-Seng Toh and Andrew K. Forrest. </author> <title> Occlusion detection in early vision. </title> <booktitle> In Proceedings of the International Conference on Computer Vision, </booktitle> <year> 1990. </year>
Reference: [104] <author> John K. Tsotsos. </author> <title> Analyzing vision at the complexity level. </title> <journal> Behavioral and Brain Sciences, </journal> <volume> 13(3) </volume> <pages> 423-469, </pages> <year> 1990. </year> <month> 191 </month>
Reference: [105] <author> Matthew A. Turk, David G. Morgenthaler, Keith Gremban, and Martin Marra. </author> <title> Video road following for the autonomous land vehicle. </title> <booktitle> In 1987 IEEE Internation Conference on Robotics and Automation, </booktitle> <pages> pages 273-280. </pages> <publisher> IEEE, </publisher> <month> March </month> <year> 1987. </year>
Reference-contexts: An information type is a salience function if it is conditionally equivalent to F G O given some constraint (a "salience constraint"). The use of such simple, easily computed functions to find particular classes of objects is common both in AI (see Swain [96], Turk et al. <ref> [105] </ref>, [30], Horswill and Brooks [51], Woodfill and Zabih [115]) and in the biological world (see Roitblat [85] for a good introduction). 64 The coloring algorithm uses the texture detector as a salience function. We want to determine what salience constraint is required for a given texture detector.
Reference: [106] <author> Shimon Ullman. </author> <title> Visual routines. </title> <journal> Cognition, </journal> <volume> 18 </volume> <pages> 97-159, </pages> <year> 1984. </year>
Reference: [107] <editor> F. J. Varela and P. Bourgine, editors. </editor> <booktitle> Toward a Practice of Autonomous Systems: the Proceedings of the First European Conference on Artificial Life. </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1992. </year>
Reference: [108] <author> R. Wallace. </author> <title> Robot road following by adaptive color classification and shape tracking. </title> <booktitle> In 1987 IEEE Internation Conference on Robotics and Automation, </booktitle> <pages> pages 258-263. </pages> <publisher> IEEE, </publisher> <month> March </month> <year> 1987. </year>
Reference: [109] <author> R. Wallace, K. Matsuzaki, Y. Goto, J. Crisman, J. Webb, and T. Kanade. </author> <title> Progress in robot road-following. </title> <booktitle> In 1986 IEEE Internation Conference on Robotics and Automation, </booktitle> <pages> pages 1615-1621, </pages> <month> April </month> <year> 1986. </year>
Reference: [110] <author> R. Wallace, A. Stenz, C. Thorpe, H. Moravec, W. Whittaker, and T. Kanade. </author> <title> First results in robot road-following. </title> <booktitle> In IJCAI-85, </booktitle> <year> 1985. </year>
Reference: [111] <author> A. M. Waxman, J. LeMoinge, and B. Srinivasan. </author> <title> Visual navigation of roadways. </title> <booktitle> In 1985 IEEE Internation Conference on Robotics and Automation, </booktitle> <month> April </month> <year> 1985. </year>
Reference: [112] <author> Norbert Wiener. </author> <title> Cybernetics. </title> <publisher> MIT Press, </publisher> <address> Cambridge, </address> <year> 1961. </year>
Reference-contexts: In biology, a great deal of attention has been given to the specialization of complete agents to their environments. Cybernetics, the progenitor of artificial intelligence, also focused on agent/environment interactions, although not necessarily on the properties of specific, complex environments <ref> [112] </ref>. Ideas from these areas are now being applied to artificial intelligence and robotics (see McFarland [70], Paton et al. [78]. Meyer and Guillot [71]). In perceptual psychology, Gibson proposed an "ecological" theory of perception that stressed the role of the environment in forming an agent's perceptions.
Reference: [113] <author> Stewart W. Wilson. </author> <title> The animat path to ai. </title> <booktitle> In Meyer and Wilson [72], </booktitle> <pages> pages 15-21. </pages>
Reference-contexts: Later, Rosenschein developed a method for synthesizing automata whose internal states had provable correlations to the state of the environment given a set of temporal logic assertions about the dynamics of the environment. Donald and Jennings [36] use a geometric, but similar, approach for constructing virtual sensors. Wilson <ref> [113] </ref> has specifically proposed the classification of simulated environments based on the types of mechanisms which can operate successfully within them. Wilson also used a finite state formalization of the environment. He divided environments into three classes based on properties such as determinacy.
Reference: [114] <author> Lambert E. Wixson. </author> <title> Detecting occluding edges without computing dense correspondence. </title> <booktitle> In IU93 [32], </booktitle> <pages> pages 933-938. </pages>
Reference: [115] <author> John Woodfill and Ramin Zabih. </author> <title> Using motion vision for a simple robotic task. </title> <booktitle> In AAAI Fall Symposium on Sensory Aspects of Robotic Intelligence, </booktitle> <year> 1991. </year> <month> 192 </month>
Reference-contexts: The use of such simple, easily computed functions to find particular classes of objects is common both in AI (see Swain [96], Turk et al. [105], [30], Horswill and Brooks [51], Woodfill and Zabih <ref> [115] </ref>) and in the biological world (see Roitblat [85] for a good introduction). 64 The coloring algorithm uses the texture detector as a salience function. We want to determine what salience constraint is required for a given texture detector. For simplicity, we will restrict ourselves to Fourier-based measures of texture.
References-found: 114

