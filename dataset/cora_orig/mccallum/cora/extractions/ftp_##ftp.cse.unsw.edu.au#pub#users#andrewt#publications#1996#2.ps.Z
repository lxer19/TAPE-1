URL: ftp://ftp.cse.unsw.edu.au/pub/users/andrewt/publications/1996/2.ps.Z
Refering-URL: http://www.cse.unsw.edu.au/school/publications/1996/SCSE_publications.html
Root-URL: 
Email: Email: fbjtong,jas,anneg@cse.unsw.edu.au  
Title: Query Classification in Multidatabase Systems  
Author: Banchong Harangsri John Shepherd Anne Ngu 
Keyword: Cost function derivation, Classification, Query optimisation, Multidatabase systems  
Address: Sydney 2052, AUSTRALIA.  
Affiliation: School of Computer Science and Engineering, The University of New South Wales,  
Abstract: Query optimisation is a significant unsolved problem in the development of multidatabase systems. The main reason for this is that the query cost functions for the component database systems may not be known to the global query optimiser. In this paper, we describe a method, based on a classical clustering algorithm, for classifying queries which allows us to derive accurate approximations of these query cost functions. The experimental results show that the cost functions derived by the clustering algorithm yield a lower average error as compared to the error produced by a manual classification. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M.R. Anderberg. </author> <title> Cluster Analysis for Applica tions. </title> <publisher> Academic Press, </publisher> <year> 1973. </year>
Reference-contexts: It may yield suboptimal solutions, but its great advantage is that it has polynomial running time. In any hierarchical clustering algorithm, one is required to define a matrix of similarity values <ref> [4, 1] </ref>. Based on such values, two clusters of "entities" which have a highest similarity are grouped together into a new cluster. The semantics of similarity are problem-dependent: it could be Euclidean distance, correlation, and so on [1]. <p> Based on such values, two clusters of "entities" which have a highest similarity are grouped together into a new cluster. The semantics of similarity are problem-dependent: it could be Euclidean distance, correlation, and so on <ref> [1] </ref>. In this case, it is the average error value of root mean squared errors (RMS) of each cost function.
Reference: [2] <author> W. Du, R. Krishnamurthy and M.C. Shan. </author> <title> Query Optimization in Heterogeneous DBMS. </title> <booktitle> In Proceedings of the 18th VLDB Conference, </booktitle> <pages> pages 277-291, </pages> <year> 1992. </year>
Reference-contexts: Clearly, before effective query optimisation is possible in such a system, some means must be found of estimating query costs in the component (or local) database systems. Du et al. <ref> [2] </ref> were the first to address this problem. They identified three types of component database systems: proprietary databases, for which cost functions and database statistics are known; conforming databases, which can provide database statistics but not cost functions; non-conforming databases, for which neither cost functions nor database statistics are available. <p> apart from knowing the relational schema, which makes it more widely applicable than the ZL method (which requires us to know the access methods used in the local database). 1 In this paper, we use the elapsed running time of queries as a cost metric which is the same as <ref> [8, 2] </ref> The rest of the paper is organised as follows: Section 2 describes the model of queries that we use in optimisation and the cost functions on which the global query optimiser is based.
Reference: [3] <author> J.A. Hartigan. </author> <title> Clustering Algorithms. </title> <publisher> John Wiley & Sons, </publisher> <year> 1975. </year>
Reference-contexts: Thus, non-linear regression techniques could be better in finding best-fit cost functions. * Compare the HCA algorithm with other clas sification algorithms such as the partitioning algorithm in <ref> [3] </ref> or the algorithms used in machine learning. * Investigate how many queries to be sampled are "sufficient" for each query class. * Investigate how the cost functions of multiple query classes derived by HCA affect the choice of query execution plans as compared to the (a) clustered index class (b)
Reference: [4] <author> S.C. Johnson. </author> <title> Hierarchical clustering schemes. </title> <journal> Psychometrika, </journal> <volume> Volume 32, Number 3, </volume> <pages> pages 241-254, </pages> <month> September </month> <year> 1967. </year>
Reference-contexts: Whenever the required number of query classes is less than the maximum, the query classification problem can be formulated as a clustering problem in a large search space. Here, we propose to use a hierarchical clustering algorithm (HCA) <ref> [4] </ref> to perform classification. <p> It may yield suboptimal solutions, but its great advantage is that it has polynomial running time. In any hierarchical clustering algorithm, one is required to define a matrix of similarity values <ref> [4, 1] </ref>. Based on such values, two clusters of "entities" which have a highest similarity are grouped together into a new cluster. The semantics of similarity are problem-dependent: it could be Euclidean distance, correlation, and so on [1].
Reference: [5] <author> H. Lu, B.C. Ooi and C.H. Goh. </author> <title> Multidatabase Query Optimization: Issues and Solutions. </title> <booktitle> In Proceedings of Third International Workshop on Research Issues in Data Engineering: Interoperability in Multidatabase Systems, </booktitle> <pages> pages 137-143, </pages> <year> 1993. </year>
Reference-contexts: 1 Introduction Query optimisation in multidatabase systems is fundamentally different from distributed query optimisation, for three major reasons <ref> [5] </ref>: site autonomy, system heterogeneity and semantic heterogeneity. Site autonomy means that the essential information for optimisation, namely cost functions and database statistics, may not be available to the global query optimiser to assist in choosing query execution plans.
Reference: [6] <author> D.E. Shasha. </author> <title> Database Tuning: A Principled Approach, </title> <booktitle> Chapter 3, </booktitle> <pages> pages 53-88. </pages> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, New Jersy, </address> <year> 1992. </year>
Reference-contexts: be used with local databases which: 1. can provide some priori knowledge 2. cannot provide any knowledge For the former, we can use knowledge gained from the applications at hand such as database schema, key information, query type information (for instance, point query, multipoint query, range query, prefix match query <ref> [6] </ref>) etc. to roughly classify all given queries into top-level classes.
Reference: [7] <author> S.K. Thomson. </author> <title> Sampling. </title> <publisher> John Wiley & Sons, Inc., </publisher> <year> 1992. </year> <title> Basic and Advanced Sampling Methods. </title>
Reference-contexts: situations (either starting from Q or Q 1 ; Q 2 and Q 3 ), based on the number of queries given, the HCA algorithm works out query subclasses with their cost functions having a low average error. 4 Query Sampling Query sampling we use here is simple random sampling <ref> [7] </ref> which is the same as the one in [8]. For the purpose of describing a number of parameters, we will explain the sampling method based on the ZL knowledge-based classification.

References-found: 7

