URL: http://www.cs.wisc.edu/~solodov/iusol97newt.ps.Z
Refering-URL: http://www.cs.wisc.edu/~solodov/solodov.html
Root-URL: http://www.cs.wisc.edu
Title: NEWTON-TYPE METHODS WITH GENERALIZED DISTANCES FOR CONSTRAINED OPTIMIZATION  
Author: Alfredo N. Iusem and Michael V. Solodov 
Keyword: Key words. proximal point methods, Newton method, generalized distances, constrained optimization  
Note: Optimization, 1997, Vol.41, pp. 257-278. c fl1997 OPA (Overseas Publishers Association) license by Gordon and Breach Science Publishers  AMS subject classifications. 90C25, 90C30  
Abstract: We consider a class of interior point algorithms for minimizing a twice continuously differentiable function over a closed convex set with nonempty interior. On one hand, our algorithms can be viewed as an approximate version of the generalized proximal point methods and, on the other hand, as an extension of unconstrained Newton-type methods to the constrained case. Each step consists of solving a strongly convex unconstrained program followed by a one-dimensional search along either a line or a curve segment in the interior of the feasible set. The information about the feasible set is contained in the generalized distance function whose gradient diverges on the boundary of this set. When the feasible set is the whole space, the standard regularized Newton method is a particular case in our framework. We show, under standard assumptions, that every accumulation point of the sequence of iterates satisfies a first order necessary optimality condition for the problem and solves the problem if the objective function is convex. Some computational results are also reported. fl Research of the first author is partially supported by CNPq grant 301280/86; the second author is supported in part by CNPq grant 300734/95-6. y Instituto de Matematica Pura e Aplicada, Estrada Dona Castorina 110, Jardim Bot^anico, Rio de Janeiro, RJ, CEP 22460-320, Brazil. Email : iusp@impa.br and solodov@impa.br 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> L. Armijo. </author> <title> Minimization of functions having Lipschitz continuous first partial derivatives. </title> <journal> Pacific Journal of Mathematics, </journal> <volume> 16 </volume> <pages> 1-3, </pages> <year> 1966. </year>
Reference-contexts: Or, alternatively, a one-dimensional search along the generated direction can be employed to enforce the decrease of the objective function. In this paper, we consider two algorithms. In the first one, i is fixed for the given iteration. Once the subproblem (1.5) is solved, an inexact Armijo-type search <ref> [1] </ref> is performed along the generated direction. In the second algorithm, i is treated as a variable and a one-dimensional curvilinear search with respect to i is done for the regularized objective function f () + i D g (x i ; ), where i &gt; 0 is a parameter. <p> We first consider the case of Algorithm 3.1. Because fx i g D and D is bounded, rf () is Lipschitz continuous on D with some constant L &gt; 0. Denote d i := h (x i ; i; i ) x i . For any 2 <ref> [0; 1] </ref> we have f (x i + d i ) f (x i ) = 0 = hrf (x i ); d i i + 0 hrf (x i ); d i i + L 0 = hrf (x i ); d i i + 2 ! where the inequality
Reference: [2] <author> L.M. Bregman. </author> <title> The relaxation method of finding the common points of convex sets and its application to the solution of problems in convex programming. </title> <journal> USSR Computational Mathematics and Mathematical Physics, </journal> <volume> 7(3) </volume> <pages> 200-217, </pages> <year> 1967. </year>
Reference-contexts: The set C 0 is called the zone of g (). These definitions originate in the results of <ref> [2] </ref>. It is easy to check that D g (x; y) 0 for all x 2 C, y 2 C 0 and D g (x; y) = 0 if and only if x = y.
Reference: [3] <author> R.S. </author> <title> Burachik and A.N. Iusem. A generalized proximal point algorithm for the variational inequality problem in a Hilbert space. </title> <type> Technical Report MAT-07/95, </type> <institution> Pontificia Universidade Catolica, Rio de Janeiro, Brazil, </institution> <year> 1995. </year> <note> SIAM J. on Optimization, accepted for publication. </note>
Reference-contexts: In particular, g () should contain information about C. This is precisely the role of B6 because divergence of rg () on @C makes C univocally defined by g (). We refer the readers to <ref> [4, 3] </ref> for further details on boundary coercive Bregman functions. 4 Example 2.1. C = &lt; n , g (x) = kxk 2 . In this case D g (x; y) = kx yk 2 . Example 2.2.
Reference: [4] <author> Y. Censor, </author> <title> A.N. Iusem, and S.A. Zenios. An interior point method with Bregman functions for the variational inequality problem with paramonotone operators. </title> <type> Technical 19 Report 94-03, </type> <institution> Department of Public and Business Administration, University of Cyprus, Nicosia, Cyprus, </institution> <year> 1994. </year> <note> Mathematical Programming, accepted for publication. </note>
Reference-contexts: In particular, g () should contain information about C. This is precisely the role of B6 because divergence of rg () on @C makes C univocally defined by g (). We refer the readers to <ref> [4, 3] </ref> for further details on boundary coercive Bregman functions. 4 Example 2.1. C = &lt; n , g (x) = kxk 2 . In this case D g (x; y) = kx yk 2 . Example 2.2. <p> Bregman functions based on the x log x entropy function such that D g (x; ) is quasiconvex (and, in fact, convex) can be found in <ref> [4] </ref> for the cases in which C is a box, a polyhedron, or a ball. 5 Computational Results In this section, we report some preliminary computational results. <p> The latter is the case when the feasible set has a simple structure, for instance when it is an orthant, a polyhedron, a box, or a ball (see <ref> [4] </ref>). The resulting algorithms require a line search because otherwise the objective function may not decrease, but they can also handle nonconvex problems. 18 The algorithms considered in this paper use a regularized quadratic approximation of f () at x i . <p> These subproblems cannot be solved explicitly but they are, in general, much simpler than (6.1) because the nonlinearities due to f () have been eliminated. In the cases of nonnegativity or box constraints, g () is typically separable (see <ref> [4] </ref>). In that case, the Jacobian matrix of the left-hand-side of (6.3) is constant except in its diagonal. As in the case of (6.2), line search procedures are necessary to enforce the decrease of the objective function, and the algorithm works also for the nonconvex case.
Reference: [5] <author> Y. Censor and S. Zenios. </author> <title> The proximal minimization algorithm with D-functions. </title> <journal> Journal of Optimization Theory and Applications, </journal> <volume> 73 </volume> <pages> 451-464, </pages> <year> 1992. </year>
Reference-contexts: It is clear that (1.3) is more practical than (1.2) in the sense that a sequence of constrained subproblems is replaced by a sequence of unconstrained ones (the latter, presumably, being easier to solve). We refer the readers to <ref> [11, 5, 6, 10, 14] </ref> for further details on the generalized proximal methods. It should be noted that when f () is nonconvex (1.3) can still be difficult to solve. <p> The first three (respectively, fourth to sixth) test problems were randomly generated with M = !EE T + E E T ; where ! = 0 (respectively, ! = 1) and every entry of the n fi n matrix E was uniformly generated from <ref> [5; 5] </ref>, and with q = M y + z, where each entry of y has equal probability of being 0 or being uniformly generated from [5; 10] and each entry of z is 0 if the corresponding 17 entry of y is not 0 and otherwise has equal probability of <p> T ; where ! = 0 (respectively, ! = 1) and every entry of the n fi n matrix E was uniformly generated from [5; 5], and with q = M y + z, where each entry of y has equal probability of being 0 or being uniformly generated from <ref> [5; 10] </ref> and each entry of z is 0 if the corresponding 17 entry of y is not 0 and otherwise has equal probability of being 0 or being uniformly generated from [5; 10] (so y is a solution). <p> + z, where each entry of y has equal probability of being 0 or being uniformly generated from <ref> [5; 10] </ref> and each entry of z is 0 if the corresponding 17 entry of y is not 0 and otherwise has equal probability of being 0 or being uniformly generated from [5; 10] (so y is a solution). In our implementation of Algorithm 3.1, we chose l = 1; u = 2; fl = 1=2; fi = 1.
Reference: [6] <author> G. Chen and M. Teboulle. </author> <title> Convergence analysis of proximal-like optimization algorithm using Bregman functions. </title> <journal> SIAM Journal on Optimization, </journal> <volume> 3 </volume> <pages> 538-543, </pages> <year> 1993. </year>
Reference-contexts: It is clear that (1.3) is more practical than (1.2) in the sense that a sequence of constrained subproblems is replaced by a sequence of unconstrained ones (the latter, presumably, being easier to solve). We refer the readers to <ref> [11, 5, 6, 10, 14] </ref> for further details on the generalized proximal methods. It should be noted that when f () is nonconvex (1.3) can still be difficult to solve.
Reference: [7] <author> R.W. Cottle, J.-S. Pang, and R.E. Stone. </author> <title> The Linear Complementarity Problem. </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1992. </year>
Reference-contexts: We implemented Algorithm 3.1 in Matlab to solve a minimization reformulation of the the linear complementarity problem <ref> [7] </ref>, which is to find y 2 &lt; n such that y 0; M y + q 0; hy; M y + qi = 0; Problem Name n iter. 1 CPU 2 RanLCP1 10 21 43.0 RanLCP2 100 574 274 RanLCP3 200 2760 3152 RanLCP4 10 18 27 RanLCP5 100 313
Reference: [8] <author> A.R. </author> <title> De Pierro and A.N. Iusem. A relaxed version of Bregman's method for convex programming. </title> <journal> Journal of Optimization Theory and Applications, </journal> <volume> 51 </volume> <pages> 421-440, </pages> <year> 1986. </year>
Reference-contexts: We remark that B4 and B5 hold automatically when x k ; y fl are in C 0 , as a consequence of B1, B2 and B3, and so they need to be checked only at points in the boundary @C of C. It has been proved in <ref> [8] </ref> that when C = &lt; n , a sufficient condition for a convex and differentiable function g to be a Bregman function is (g (x)=kxk) ! 1 as kxk ! 1.
Reference: [9] <author> J.E. Dennis and R.B. Schnabel. </author> <title> Numerical Methods for Unconstrained Optimization and Nonlinear Equations. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, N.J., </address> <year> 1983. </year>
Reference-contexts: The connection to quasi-Newton and trust-region methods <ref> [9] </ref> becomes apparent from the following considerations. <p> Estimation of i can also be done in an efficient way <ref> [9] </ref>. It is clear that in both (1.4) or (1.5) i has to be chosen in a special way to guarantee a decrease of the objective function f (). In particular, i has to be taken sufficiently large so that the step x i+1 x i be sufficiently small. <p> As in the case of (6.2), line search procedures are necessary to enforce the decrease of the objective function, and the algorithm works also for the nonconvex case. Finally, in the case of Newton-type methods with trust regions <ref> [9] </ref>, the subproblems consist of minimizing a quadratic function over a trust region which, in the constrained case, must carry the information about the feasible set. Our algorithm has unconstrained subproblems which are equivalent, in view of (6.3), to minimizing a strongly convex quadratic function plus g (x).
Reference: [10] <author> J. Eckstein. </author> <title> Nonlinear proximal point algorithms using Bregman functions, with applications to convex programming. </title> <journal> Mathematics of Operations Research, </journal> <volume> 18 </volume> <pages> 202-226, </pages> <year> 1993. </year>
Reference-contexts: It is clear that (1.3) is more practical than (1.2) in the sense that a sequence of constrained subproblems is replaced by a sequence of unconstrained ones (the latter, presumably, being easier to solve). We refer the readers to <ref> [11, 5, 6, 10, 14] </ref> for further details on the generalized proximal methods. It should be noted that when f () is nonconvex (1.3) can still be difficult to solve. <p> T ; where ! = 0 (respectively, ! = 1) and every entry of the n fi n matrix E was uniformly generated from [5; 5], and with q = M y + z, where each entry of y has equal probability of being 0 or being uniformly generated from <ref> [5; 10] </ref> and each entry of z is 0 if the corresponding 17 entry of y is not 0 and otherwise has equal probability of being 0 or being uniformly generated from [5; 10] (so y is a solution). <p> + z, where each entry of y has equal probability of being 0 or being uniformly generated from <ref> [5; 10] </ref> and each entry of z is 0 if the corresponding 17 entry of y is not 0 and otherwise has equal probability of being 0 or being uniformly generated from [5; 10] (so y is a solution). In our implementation of Algorithm 3.1, we chose l = 1; u = 2; fl = 1=2; fi = 1.
Reference: [11] <author> P.P.B. Eggermont. </author> <title> Multiplicative iterative algorithms for convex programming. </title> <journal> Linear Algebra and its Applications, </journal> <volume> 130 </volume> <pages> 25-32, </pages> <year> 1990. </year>
Reference-contexts: It is clear that (1.3) is more practical than (1.2) in the sense that a sequence of constrained subproblems is replaced by a sequence of unconstrained ones (the latter, presumably, being easier to solve). We refer the readers to <ref> [11, 5, 6, 10, 14] </ref> for further details on the generalized proximal methods. It should be noted that when f () is nonconvex (1.3) can still be difficult to solve.
Reference: [12] <author> A. Friedlander, J.M. Martnez, and S.A. Santos. </author> <title> Solution of linear complementarity problems using minimization with simple bounds. </title> <journal> Journal of Global Optimization, </journal> <volume> 6 </volume> <pages> 253-267, </pages> <year> 1995. </year>
Reference-contexts: In particular, we use the following bound constrained minimization reformulation (see <ref> [12] </ref>) min f (y; z) := 2 1 (hy; zi) 2 : As the Bregman function, we chose the x log x entropy function from Example 2.2. To solve subproblems (1.5) we used the unconstrained minimization solver fminu.m from the Matlab optimization toolbox.
Reference: [13] <author> A. N. Iusem. </author> <title> Steepest descent methods with generalized distances for constrained optimization, 1994. </title> <journal> Acta Applicandae Mathematicae, </journal> <note> accepted for publication. </note>
Reference-contexts: We refer the readers to [11, 5, 6, 10, 14] for further details on the generalized proximal methods. It should be noted that when f () is nonconvex (1.3) can still be difficult to solve. Thus in <ref> [13] </ref> the following approximate version of the generalized proximal algorithm was proposed: x i+1 = arg min 1 where h; i stands for the usual Euclidean inner product. This algorithm can also be viewed as a steepest descent method with respect to the distance induced by D g (; ). <p> The subproblems (1.4) are particularly easy to solve when the gradient of g () is explicitly invertible on C 0 (see <ref> [13] </ref>). In this paper, we propose a more efficient approximate version of the generalized proximal algorithms which can be viewed as a certain extension of the unconstrained Newton-type methods to constrained problems. <p> This also becomes clear when the properties of our Algorithm 3.1 are compared with that of Algorithm A3 in <ref> [13] </ref>. We note that, with an appropriate choice of i, (1.5) is a strongly convex unconstrained program which can be solved very efficiently by a variety of optimization techniques [17] (for example, the standard Newton method applied to (1.5) is globally quadratically convergent). <p> such that f (x i ) f (x i + fl k (h (x i ; i; i ) x i )) fifl k kh (x i ; i; i ) x i k 2 : (3.4) This algorithm appears to be more practical than a similar Algorithm A3 in <ref> [13] </ref> where exact minimization along the direction generated by (1.4) is required. It is not immediately clear if exact line search can be replaced with an Armijo-type rule in [13]. <p> i ) x i k 2 : (3.4) This algorithm appears to be more practical than a similar Algorithm A3 in <ref> [13] </ref> where exact minimization along the direction generated by (1.4) is required. It is not immediately clear if exact line search can be replaced with an Armijo-type rule in [13]. As we shall see, the direction generated by (1.5) is also "better" in the sense that it provides steeper descent for the objective function. We now state our second algorithm. Algorithm 3.2 Let the following constants be given : u &gt; 0, u l &gt; 0. <p> i := arg min f (h (x i ; i;))+ i D g (x i ; h (x i ; i;)): (3.5) Algorithm 3.2 performs a curvilinear search with the regularized objective function f () + i D g (x i ; ) and is analogous to Algorithm A1 in <ref> [13] </ref>. 7 4 Convergence Analysis From now on, we assume that f () is bounded below on C. <p> In conclusion, we compare the basic structure of the algorithms considered here with the methods in <ref> [13] </ref> and [14] and also with the trust-region Newton-type methods. <p> Furthermore, the system of equations (6.1) can be highly nonlinear due to the presence of the gradient of f () in the left-hand-side. Thus (6.1) can be very difficult to solve. If we approximate f () by a linear model at x i , as is done in <ref> [13] </ref>, the following system has to be solved : rg (x) = rg (x i ) i rf (x i ); (6.2) which can be done explicitly when rg () is invertible on C 0 .
Reference: [14] <author> A. N. Iusem. </author> <title> On some properties of generalized proximal point methods for quadratic and linear programming. </title> <journal> Journal of Optimization Theory and Applications, </journal> <volume> 85 </volume> <pages> 596-612, </pages> <year> 1995. </year>
Reference-contexts: It is clear that (1.3) is more practical than (1.2) in the sense that a sequence of constrained subproblems is replaced by a sequence of unconstrained ones (the latter, presumably, being easier to solve). We refer the readers to <ref> [11, 5, 6, 10, 14] </ref> for further details on the generalized proximal methods. It should be noted that when f () is nonconvex (1.3) can still be difficult to solve. <p> The optimality condition for (3.1) is 0 2 (@ )(h (x; -; )) = @(' + g)(h (x; -; )): It has been proved in <ref> [14, Theorem 4.1] </ref> that @(' + g)(y) = ; for any y 62 C 0 and any convex '() provided g () is boundary coercive with zone C 0 . It follows that h (x; -; ) must belong to C 0 and the claim is established. <p> In conclusion, we compare the basic structure of the algorithms considered here with the methods in [13] and <ref> [14] </ref> and also with the trust-region Newton-type methods. In the case of the exact proximal point methods with Bregman functions (e.g. [14]), the subproblems consist of solving the system of equations i rf (x) + rg (x) = rg (x i ): (6.1) In this case no line search is necessary. <p> In conclusion, we compare the basic structure of the algorithms considered here with the methods in [13] and <ref> [14] </ref> and also with the trust-region Newton-type methods. In the case of the exact proximal point methods with Bregman functions (e.g. [14]), the subproblems consist of solving the system of equations i rf (x) + rg (x) = rg (x i ): (6.1) In this case no line search is necessary. On the other hand, the convexity of f () is required for the existence of solution of (6.1).
Reference: [15] <author> B. Lemaire. </author> <title> The proximal algorithm. </title> <editor> In J.P. Penot, editor, </editor> <booktitle> International Series of Numerical Mathematics, </booktitle> <pages> pages 73-87. </pages> <publisher> Birkhauser, </publisher> <address> Basel, </address> <year> 1989. </year>
Reference-contexts: It was first shown in [18] that in the case when (1.1) is solvable, f () is convex and C = &lt; n , the sequence fx i g converges to a solution of the problem. Proximal point algorithms have been studied very extensively. We refer the readers to <ref> [15] </ref> for a survey. In the general case when C is not the whole space and f () is nonconvex, the proximal algorithm is impractical because the subproblems (1.2) are as hard to solve as the original problem itself.
Reference: [16] <author> O.L. Mangasarian. </author> <title> Nonlinear Programming. </title> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <year> 1969. </year>
Reference-contexts: The proof is complete. Now we consider the case when accumulation points of the sequence of iterates belong to the boundary of the feasible set. Recall that a point x 2 C satisfies the first order necessary optimality condition <ref> [16] </ref> for problem (1.1) if hrf (x); x xi 0 for all x 2 C: If f () is convex, this condition is also sufficient for optimality. <p> For Algorithm 3.1, by quasiconvexity of D g (x; ) and the fact that x i j +1 is on a line between x i j and h (x i j ; i j ; i j ), it follows that (see <ref> [16] </ref>) D g (x; x i j ) &lt; D g (x; x i j +1 ) maxfD g (x; x i j ); D g (h (x i j ; i j ; i j ))g implying that D g (x; x i j ) &lt; D g (h (x
Reference: [17] <author> B.T. Polyak. </author> <title> Introduction to Optimization. Optimization Software, </title> <publisher> Inc., Publications Division, </publisher> <address> New York, </address> <year> 1987. </year>
Reference-contexts: This also becomes clear when the properties of our Algorithm 3.1 are compared with that of Algorithm A3 in [13]. We note that, with an appropriate choice of i, (1.5) is a strongly convex unconstrained program which can be solved very efficiently by a variety of optimization techniques <ref> [17] </ref> (for example, the standard Newton method applied to (1.5) is globally quadratically convergent). Estimation of i can also be done in an efficient way [9]. <p> Now the implicit function theorem <ref> [17, p.57] </ref> ensures continuity of the solution y of the equation (y; x; -; ) = 0 as a function of (x; -; ), which is precisely h (x; -; ). Note that h (x; -; 0) = x. We now state our first algorithm.
Reference: [18] <author> R.T. Rockafellar. </author> <title> Monotone operators and the proximal point algorithm. </title> <journal> SIAM Journal on Control and Optimization, </journal> <volume> 14(5) </volume> <pages> 877-898, </pages> <year> 1976. </year>
Reference-contexts: The classical proximal point method generates a sequence of iterates according to the formula x i+1 2 arg min f (x) + i kx x i k 2 ; (1.2) where i &gt; 0 is a regularization parameter. It was first shown in <ref> [18] </ref> that in the case when (1.1) is solvable, f () is convex and C = &lt; n , the sequence fx i g converges to a solution of the problem. Proximal point algorithms have been studied very extensively. We refer the readers to [15] for a survey.
Reference: [19] <author> M. V. Solodov and P. Tseng. </author> <title> Modified projection-type methods for monotone variational inequalities. </title> <journal> SIAM Journal on Control and Optimization, </journal> <volume> 34 </volume> <pages> 1814-1830, </pages> <year> 1996. </year> <month> 21 </month>
Reference-contexts: To solve subproblems (1.5) we used the unconstrained minimization solver fminu.m from the Matlab optimization toolbox. For test problems, we generated dense monotone linear complementarity problems in a manner similar to <ref> [19] </ref>.
References-found: 19

