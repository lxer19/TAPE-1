URL: ftp://speech.cse.ogi.edu/pub/docs/philipp_formant_95.ps.Z
Refering-URL: http://www.cse.ogi.edu/CSLU/publications/publications.html
Root-URL: http://www.cse.ogi.edu
Title: ROBUST, N-BEST FORMANT TRACKING  for Spoken Language Understanding  
Author: Philipp Schmid Etienne Barnard 
Address: 20000 N.W. Walker Road P.O. Box 91000 Portland, OR 97291-1000, USA  
Affiliation: Center  Oregon Graduate Institute  
Abstract: We describe a robust, N-best formant tracker. The 2 stage algorithm initially finds single formants or parts thereof. In the second stage a robust dynamic programming search with a wild card mechanism is employed to find the N best consistent interpretation of the initial formant information. The selection of the correct formant tracks is delayed until after the phonetic search, thus overcoming the lack of robustness of traditional formant trackers by delaying the final decision until after phonemic classification. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> V. Zue, J. Glass, M. Phillips, and S. Seneff. </author> <title> The MIT SUMMIT speech recognition system: A progress report. </title> <booktitle> In Proceedings of the DARPA Speech and Natural Language Workshop, </booktitle> <pages> pages 1-11, </pages> <month> February </month> <year> 1989. </year>
Reference-contexts: 1. INTRODUCTION We are building a knowledge-based, segmental speech recognition system. Such systems have traditionally used cepstral, spectral or related features as a basis for segmentation and classification <ref> [1, 2] </ref>. However, from our experience with spectrogram reading, we know that formants are the single most important source of evidence for the classification of phonetic segments. Formants (especially their relative positioning) are the primary indicator for the classification of vowels, liquids and glides [3].
Reference: [2] <author> R. Cole, K. Roginsky, and M. Fanty. </author> <title> English alphabet recognition with telephone speech. </title> <booktitle> In Proceedings of EUROSPEECH'91, </booktitle> <pages> pages 479-482, </pages> <address> Genova,Italy, </address> <year> 1991. </year>
Reference-contexts: 1. INTRODUCTION We are building a knowledge-based, segmental speech recognition system. Such systems have traditionally used cepstral, spectral or related features as a basis for segmentation and classification <ref> [1, 2] </ref>. However, from our experience with spectrogram reading, we know that formants are the single most important source of evidence for the classification of phonetic segments. Formants (especially their relative positioning) are the primary indicator for the classification of vowels, liquids and glides [3].
Reference: [3] <author> R. Cole and V. Zue. </author> <title> Speech as eyes see it. </title> <editor> In R. S. Nickerson, editor, </editor> <booktitle> Attention and Performance VIII, </booktitle> <pages> pages 475-494. </pages> <publisher> Lawrence Erlbaum Assoc., </publisher> <address> Hillsdale, NJ, </address> <year> 1980. </year>
Reference-contexts: However, from our experience with spectrogram reading, we know that formants are the single most important source of evidence for the classification of phonetic segments. Formants (especially their relative positioning) are the primary indicator for the classification of vowels, liquids and glides <ref> [3] </ref>. In addition, the formant transitions (where available) out of the preceding vowel or into the following vowel give strong indications as to the place of articulation for the stop and nasal classifications.
Reference: [4] <author> R. Cole, R. Stern, and M. Lasry. </author> <title> Performing fine phonetic distinctions: Templates versus features. </title> <editor> In D. Klatt J.Perkell, editor, </editor> <booktitle> Variability and In-variance in Speech Processes. </booktitle> <publisher> Lawrence Erlbaum Assoc., </publisher> <address> Hillsdale, NJ, </address> <year> 1986. </year>
Reference-contexts: The usefulness of formant information has been recognized in the past and put to use in speech recognition systems, most notably in CMU's FEATURE system <ref> [4] </ref>. However, the accuracy and reliability of the formant trackers turned out to be too low for the demands of speech recognition systems. Hence the current focus on using spectral or cepstral representations in conjunction with mathematical tools such as Hidden Markov Modelling.
Reference: [5] <author> H. Hermansky and L. Cox. </author> <title> Perceptual Linear Predictive (PLP) Analysis-Resynthesis Technique. </title> <booktitle> In Proceedings of the 2nd European Conference in Speech Communication and Technology, </booktitle> <month> September </month> <year> 1991. </year>
Reference-contexts: Hence the current focus on using spectral or cepstral representations in conjunction with mathematical tools such as Hidden Markov Modelling. Estimating the formants based on short term spectral analysis can be done successfully in the case where the local information is pronounced (e.g. <ref> [5] </ref>). However, the more interesting case (in terms of expected improvements over cepstral / spectral signal representations) is when the short time spectrum is relatively flat or ambiguous. In that case the informa tion regarding the location of the formants can only be reconstructed by "tracking" the formants.
Reference: [6] <author> Y. Laprie. </author> <title> Optimum spectral peak track interpretation in term of formants. </title> <booktitle> In Proceedings of ICSLP, </booktitle> <address> Kobe, Japan, </address> <pages> pages 1261-1264, </pages> <year> 1990. </year>
Reference-contexts: We observed that for most sonorant segments, only a few consistent interpretations of formants are possible. This led to the decision to design a formant tracker which finds the N best interpretations rather than the single best as has been done in the past <ref> [6, 7, 8] </ref>. The N best interpretations are fed to a phonetic segment classifier. <p> ELEMENTARY TRACKS The goal of this first processing step is to identify individual formants or parts thereof (elementary tracks). This is similar to the initial processing step as proposed by Laprie <ref> [6] </ref>. There are three basic mechanisms for generating formant candidates for a given sonorant frame: computing the complex roots of a linear predictor polynomial [12], peak picking of a short-time spectral representation [13], or analysis by synthesis [14].
Reference: [7] <author> D. Talkin. </author> <title> Formant trajectory estimation using dynamic programming with modulated transition costs. Transparencies from Presentation. </title> <institution> AT&T Bell Laboratories, </institution> <address> Murray Hill, NY. </address>
Reference-contexts: We observed that for most sonorant segments, only a few consistent interpretations of formants are possible. This led to the decision to design a formant tracker which finds the N best interpretations rather than the single best as has been done in the past <ref> [6, 7, 8] </ref>. The N best interpretations are fed to a phonetic segment classifier.
Reference: [8] <author> D. </author> <type> Talkin. </type> <institution> ESPS. Entropic Research Lab, Inc., </institution> <year> 1993. </year>
Reference-contexts: We observed that for most sonorant segments, only a few consistent interpretations of formants are possible. This led to the decision to design a formant tracker which finds the N best interpretations rather than the single best as has been done in the past <ref> [6, 7, 8] </ref>. The N best interpretations are fed to a phonetic segment classifier.
Reference: [9] <author> J. Allen. </author> <title> How do humans process and recognize speech? IEEE Trans. </title> <booktitle> on Speech and Audio Processing, </booktitle> <volume> 2(4), </volume> <year> 1994. </year>
Reference-contexts: This approach has several potential advantages over more conventional segmental systems. For instance, as has been pointed out by Allen <ref> [9] </ref>, noise in a particular frequency band influences all cepstral or spectral coefficients. On the other hand, a formant representation is more robust to such noise.
Reference: [10] <author> J. Miller. </author> <title> Auditory-perceptual interpretation of the vowel. </title> <journal> J. Acoustical Society of America, </journal> <volume> 85(5) </volume> <pages> 2114-2134, </pages> <year> 1989. </year>
Reference-contexts: The same process will reduce the problems for heavily glottalized speech as well as strong extraneous noise events such as clicks. Similarly, principled speaker normalization should be more feasible when formant frequencies are known explicitly <ref> [10] </ref>. Our current approach assumes that the speech is already pre-segmented into sonorant, obstruent and silence segments, and only tries to find the N consistent formant tracks within the sonorant segments. Hence, we are able to avoid tracking problems across sono-rant / obstruent boundaries as reported by Talkin [11].
Reference: [11] <author> D. Talkin. </author> <title> Speech Formant Trajectory Estimation Using Dynamic Programming with Modulated Transition Costs. </title> <journal> AT&T Internal Memo MH 11222 2924 2D-410, AT&T, </journal> <year> 1987. </year>
Reference-contexts: Our current approach assumes that the speech is already pre-segmented into sonorant, obstruent and silence segments, and only tries to find the N consistent formant tracks within the sonorant segments. Hence, we are able to avoid tracking problems across sono-rant / obstruent boundaries as reported by Talkin <ref> [11] </ref>. We have constructed such a segmenter for earlier purposes, but intend to enhance it in the current context. 2. ELEMENTARY TRACKS The goal of this first processing step is to identify individual formants or parts thereof (elementary tracks). <p> Generally, formant tracking algorithms try to find a good trade-off between maximizing the amount of energy "explained" by a given interpretation and some sort of smoothness constraint (e.g. [16], <ref> [11] </ref>). Our goal is to find consistent interpretations of the formant information as represented by the elementary tracks. Therefore, we "count" the number of consistency violations as well as the number of preferred behaviors of a hypothesis.
Reference: [12] <author> B.S. Atal and S.L. Hanauer. </author> <title> Speech Analysis and Synthesis by Linear Prediction of the Speech Wave. </title> <journal> JASA, </journal> <volume> 50 </volume> <pages> 637-655, </pages> <year> 1971. </year>
Reference-contexts: This is similar to the initial processing step as proposed by Laprie [6]. There are three basic mechanisms for generating formant candidates for a given sonorant frame: computing the complex roots of a linear predictor polynomial <ref> [12] </ref>, peak picking of a short-time spectral representation [13], or analysis by synthesis [14]. In this work we have chosen to pick peaks of a 20-th order LPC spectrum to generate formant candidates for each sonorant frame of speech.
Reference: [13] <author> R.W. Schafer and L.R. Rabiner. </author> <title> System for Automatic Formant Analysis of Voiced Speech. </title> <journal> JASA, </journal> <pages> 57(634-648), </pages> <year> 1970. </year>
Reference-contexts: This is similar to the initial processing step as proposed by Laprie [6]. There are three basic mechanisms for generating formant candidates for a given sonorant frame: computing the complex roots of a linear predictor polynomial [12], peak picking of a short-time spectral representation <ref> [13] </ref>, or analysis by synthesis [14]. In this work we have chosen to pick peaks of a 20-th order LPC spectrum to generate formant candidates for each sonorant frame of speech. The spectrum (0 - 4 kHz) is discretized into 32 frequency bands.
Reference: [14] <author> J. P. Olive. </author> <title> Automatic Formant Tracking by a Newton-Raphson Technique. </title> <journal> JASA, </journal> <volume> 50 </volume> <pages> 661-670, </pages> <year> 1971. </year>
Reference-contexts: This is similar to the initial processing step as proposed by Laprie [6]. There are three basic mechanisms for generating formant candidates for a given sonorant frame: computing the complex roots of a linear predictor polynomial [12], peak picking of a short-time spectral representation [13], or analysis by synthesis <ref> [14] </ref>. In this work we have chosen to pick peaks of a 20-th order LPC spectrum to generate formant candidates for each sonorant frame of speech. The spectrum (0 - 4 kHz) is discretized into 32 frequency bands. Therefore, the formant location is the index of the frequency band.
Reference: [15] <author> G. David Forney. </author> <title> The viterbi algorithm. </title> <booktitle> In Proceedings of the IEEE, </booktitle> <volume> volume 61, </volume> <pages> pages 268-277, </pages> <year> 1973. </year>
Reference-contexts: ROBUST N-BEST SEARCH In this processing step, elementary tracks are combined into consistent hypotheses for locations for the first three formants (F1, F2 and F3). The search is a dynamic programming algorithm similar to the Viterbi search <ref> [15] </ref>. The search nodes contain the current score and pointers to the elementary tracks representing F i (i = 1; 2; 3). The track elements pointed to in turn store information about the trajectory of the track, more precisely the location for the track at each frame of the sub-segment.
Reference: [16] <author> Y. Laprie. </author> <title> A new paradigm for reliable automatic formant tracking. </title> <booktitle> In Proceedings of ICASSP, </booktitle> <address> San Francisco, CA, </address> <pages> pages 201-204, </pages> <year> 1992. </year>
Reference-contexts: If S i is empty, then add a wild card to S i with the default location for F i . Generally, formant tracking algorithms try to find a good trade-off between maximizing the amount of energy "explained" by a given interpretation and some sort of smoothness constraint (e.g. <ref> [16] </ref>, [11]). Our goal is to find consistent interpretations of the formant information as represented by the elementary tracks. Therefore, we "count" the number of consistency violations as well as the number of preferred behaviors of a hypothesis.
References-found: 16

