URL: http://www.cs.huji.ac.il/~rousso/TRs/cvpr98.ps.gz
Refering-URL: http://www.cs.huji.ac.il/~rousso/
Root-URL: http://www.cs.huji.ac.il
Email: frousso,erezsg@cs.huji.ac.il  
Title: Varying Focal Length Self-Calibration and Pose Estimation from Two Images  
Author: Benny Rousso Erez Shilat 
Address: Jeruslem 91904, Israel.  
Affiliation: Institute of Computer Science, The Hebrew University of Jerusalem  
Abstract: This paper presents a self-calibration and pose estimation method that uses two cameras which only differ by focal length. The estimation of the rotation and focal lengths is independent of the translation recovery. Unlike most methods, we do not initialize our recovery with the projective camera. Instead we estimate the ego-motion and calibration from 3 homographies. These homographies can be easily obtained from a fundamental matrix or a trifocal tensor. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Avidan A. Shashua. </author> <title> Unifying two-view and three-view geometry. </title> <booktitle> In ARPA, Image Understanding Workshop, </booktitle> <year> 1997. </year>
Reference-contexts: It extends [9] to the uncalibrated cameras case. Like [9], we use three homographies for reconstruction. Three homographies can be obtained directly from the trifocal tensor [10] or from the fundamental matrix between the 2 images using <ref> [1] </ref>. Note that the fundamental matrix and the trifocal tensor are unrecoverable in the pure rotation case. This paper starts with some general results on ho-mographies (Section 2) that we use to reconstruct the epipole (Section 3), rotation and the 2 cameras' focal lengths (Section 4). <p> Choosing n to be one of <ref> [0; 0; 1] </ref> T , [0; f 1 ; v 1 ] T or [~f 1 ; s; u 1 ] T and substituting in Equation 4 proves that the following are valid homographies: 2 0 0 e x 0 0 e z 5 4 0 e y 0 3 2 <p> E 1 2 + c 3 E 1 E 2 = c 4 E 2 2 + c 6 E 2 From the structure of E (Equation 5), we obtain a lin ear system of 9 equations and 6 unknowns (c 1 c 6 ): c 1 E 1 2 <ref> [n; 1] </ref> + c 3 E 1 c 4 E 2 2 [n; 1] + c 6 E 2 c 1 E 1 2 [n; 2] + c 3 E 1 c 4 E 2 2 [n; 2] + c 6 E 2 for n = 1; 2; 3. <p> 4 E 2 2 + c 6 E 2 From the structure of E (Equation 5), we obtain a lin ear system of 9 equations and 6 unknowns (c 1 c 6 ): c 1 E 1 2 <ref> [n; 1] </ref> + c 3 E 1 c 4 E 2 2 [n; 1] + c 6 E 2 c 1 E 1 2 [n; 2] + c 3 E 1 c 4 E 2 2 [n; 2] + c 6 E 2 for n = 1; 2; 3. The result is a solution up to scale of the epipole.
Reference: [2] <author> O. Faugeras. </author> <title> Three-Dimensional Computer Vision. </title> <publisher> The MIT Press, </publisher> <year> 1993. </year>
Reference-contexts: The matrix M is called the calibration matrix and its elements are the internal parameters of the camera. Classic calibration methods, use different types of knowledge of the 3-D scene for the reconstruction of the internal and external parameters <ref> [2] </ref>. In self-calibration, one finds the internal parameters of the camera without using prior knowledge of the 3-D scene. Finding the relative position of the camera (external parameters) is termed "pose estimation" or "ego motion". Self-calibration methods use more than one image. <p> of E (Equation 5), we obtain a lin ear system of 9 equations and 6 unknowns (c 1 c 6 ): c 1 E 1 2 [n; 1] + c 3 E 1 c 4 E 2 2 [n; 1] + c 6 E 2 c 1 E 1 2 <ref> [n; 2] </ref> + c 3 E 1 c 4 E 2 2 [n; 2] + c 6 E 2 for n = 1; 2; 3. The result is a solution up to scale of the epipole. We solve using Singular Value Decompo sition. <p> equations and 6 unknowns (c 1 c 6 ): c 1 E 1 2 [n; 1] + c 3 E 1 c 4 E 2 2 [n; 1] + c 6 E 2 c 1 E 1 2 <ref> [n; 2] </ref> + c 3 E 1 c 4 E 2 2 [n; 2] + c 6 E 2 for n = 1; 2; 3. The result is a solution up to scale of the epipole. We solve using Singular Value Decompo sition. Similar results can be obtained using any of the other homographies in Equation 5.
Reference: [3] <author> O. Faugeras Q. T. Loung S. J. Maybank. </author> <title> Camera self-calibration: Theory and experiments. </title> <booktitle> In ECCV '92, </booktitle> <pages> pages 321-334, </pages> <year> 1992. </year>
Reference-contexts: Finding the relative position of the camera (external parameters) is termed "pose estimation" or "ego motion". Self-calibration methods use more than one image. We will assume, without loss of generality, that the first camera is M [I; 0]. Most self-calibration papers <ref> [3, 8, 7, 11, 6, 5] </ref> start with the reconstruction of the projective cameras C i that differ by a 3-D projective transformations H i from the true camera.
Reference: [4] <author> R. I. </author> <title> Hartley. Estimation of relative camera position for uncalibrated cameras. </title> <booktitle> In ECCV '92, </booktitle> <pages> pages 579-587, </pages> <year> 1992. </year>
Reference-contexts: They show, using a degrees of freedom consideration, that at least three images are needed to reconstruct a constant calibration matrix and two images are enough when only the focal length is changing. Our work was motivated by the different ap-proaches of Hartley <ref> [4] </ref> and Rousso et al. [9]. Hartley [4], factored the fundamental matrix to solve pose estimation and calibration. The paper assumed a constant, degenerate calibration matrix that contains aspect ratio and focal length. Rousso et al. [9] found the rotation in an image pair using three homographies between the images. <p> Our work was motivated by the different ap-proaches of Hartley <ref> [4] </ref> and Rousso et al. [9]. Hartley [4], factored the fundamental matrix to solve pose estimation and calibration. The paper assumed a constant, degenerate calibration matrix that contains aspect ratio and focal length. Rousso et al. [9] found the rotation in an image pair using three homographies between the images.
Reference: [5] <author> R. I. </author> <title> Hartley. Euclidean reconstruction from uncalibrated views. </title> <editor> In J. L. Mundy A. Zis-serman D. Forsyth, editor, </editor> <booktitle> Applications of In-variance in Computer Vision, Lecture Notes in Computer Science 825, </booktitle> <pages> pages 237-256. </pages> <publisher> Springer-Verlag, </publisher> <year> 1993. </year>
Reference-contexts: Finding the relative position of the camera (external parameters) is termed "pose estimation" or "ego motion". Self-calibration methods use more than one image. We will assume, without loss of generality, that the first camera is M [I; 0]. Most self-calibration papers <ref> [3, 8, 7, 11, 6, 5] </ref> start with the reconstruction of the projective cameras C i that differ by a 3-D projective transformations H i from the true camera. <p> Most of these assumed that the internal parameters remain constant and use at least three images. Hartley <ref> [5] </ref>, solved by minimizing the differences between the internal camera parameters for different views. Most others used, in different ways, the absolute quadratic Q = I 3fi3 0 and its projections to the images: q i ' C i QC T i q i is called the absolute conic.
Reference: [6] <author> A. Heyden K. -Astrom. </author> <title> Euclidean reconstruction from image sequences with varying and unknown focal length and principal point. </title> <booktitle> In CVPR '97, </booktitle> <pages> pages 438-443, </pages> <year> 1997. </year>
Reference-contexts: Finding the relative position of the camera (external parameters) is termed "pose estimation" or "ego motion". Self-calibration methods use more than one image. We will assume, without loss of generality, that the first camera is M [I; 0]. Most self-calibration papers <ref> [3, 8, 7, 11, 6, 5] </ref> start with the reconstruction of the projective cameras C i that differ by a 3-D projective transformations H i from the true camera. <p> The first paper, to our knowledge, that let the internal parameters vary in self calibration was Heyden and -Astrom's paper <ref> [6] </ref>. They assumed a known aspect ratio and skew, but allowed the other parameters to vary along the sequence. They used bundle adjustment on all cameras and the 3-D points simultaneously. Their work was extended by Pollefeys et al. [7] that reconstructed varying internal cameras parameters, assuming zero skew.
Reference: [7] <author> M. Pollefeys R. Koch L. Van Gool. </author> <title> Self calibration and metric reconstruction in spite of varying and unknown internal camera parameters. </title> <note> In ICCV '98, 1998, to appear. </note>
Reference-contexts: Finding the relative position of the camera (external parameters) is termed "pose estimation" or "ego motion". Self-calibration methods use more than one image. We will assume, without loss of generality, that the first camera is M [I; 0]. Most self-calibration papers <ref> [3, 8, 7, 11, 6, 5] </ref> start with the reconstruction of the projective cameras C i that differ by a 3-D projective transformations H i from the true camera. <p> They assumed a known aspect ratio and skew, but allowed the other parameters to vary along the sequence. They used bundle adjustment on all cameras and the 3-D points simultaneously. Their work was extended by Pollefeys et al. <ref> [7] </ref> that reconstructed varying internal cameras parameters, assuming zero skew. They used an initial reconstruction of the projective camera and a nonlinear least squares method to minimize the distance between different definitions of the absolute conic: one containing the projective camera and the other, the calibration matrix.
Reference: [8] <author> M. Pollefeys L. Van Gool. </author> <title> A stratified approach to self-calibration. </title> <booktitle> In CVPR '97, </booktitle> <pages> pages 407-412, </pages> <year> 1997. </year>
Reference-contexts: Finding the relative position of the camera (external parameters) is termed "pose estimation" or "ego motion". Self-calibration methods use more than one image. We will assume, without loss of generality, that the first camera is M [I; 0]. Most self-calibration papers <ref> [3, 8, 7, 11, 6, 5] </ref> start with the reconstruction of the projective cameras C i that differ by a 3-D projective transformations H i from the true camera.
Reference: [9] <author> B. Rousso S. Avidan A. Shashua S. Peleg. </author> <title> Robust recovery of camera rotation from three frames. </title> <booktitle> In CVPR '96, </booktitle> <year> 1996. </year>
Reference-contexts: They show, using a degrees of freedom consideration, that at least three images are needed to reconstruct a constant calibration matrix and two images are enough when only the focal length is changing. Our work was motivated by the different ap-proaches of Hartley [4] and Rousso et al. <ref> [9] </ref>. Hartley [4], factored the fundamental matrix to solve pose estimation and calibration. The paper assumed a constant, degenerate calibration matrix that contains aspect ratio and focal length. Rousso et al. [9] found the rotation in an image pair using three homographies between the images. <p> Our work was motivated by the different ap-proaches of Hartley [4] and Rousso et al. <ref> [9] </ref>. Hartley [4], factored the fundamental matrix to solve pose estimation and calibration. The paper assumed a constant, degenerate calibration matrix that contains aspect ratio and focal length. Rousso et al. [9] found the rotation in an image pair using three homographies between the images. They assumed a small rotation and calibrated cameras. They obtain larger rotations by using an iterative method. <p> They assumed a small rotation and calibrated cameras. They obtain larger rotations by using an iterative method. In this paper we present a method to compute pose estimation and calibration from three homographies between two images, without first computing a projective camera. It extends <ref> [9] </ref> to the uncalibrated cameras case. Like [9], we use three homographies for reconstruction. Three homographies can be obtained directly from the trifocal tensor [10] or from the fundamental matrix between the 2 images using [1]. <p> They obtain larger rotations by using an iterative method. In this paper we present a method to compute pose estimation and calibration from three homographies between two images, without first computing a projective camera. It extends <ref> [9] </ref> to the uncalibrated cameras case. Like [9], we use three homographies for reconstruction. Three homographies can be obtained directly from the trifocal tensor [10] or from the fundamental matrix between the 2 images using [1]. Note that the fundamental matrix and the trifocal tensor are unrecoverable in the pure rotation case. <p> The following lemma was proved in <ref> [9] </ref>: Lemma 1 (Rank 4) The space of all homographies between two cameras is embedded in a 4 dimensional linear subspace of &lt; 9 . <p> inspection that fi 1 H i fl fi 6fik + M 0 T 0 ((M 1 ) T n 1 ) i ((M 1 ) T n k ) i fl = H i M 0 T 0 1 k 2 This is an extension of a similar lemma in <ref> [9] </ref> to the case of uncalibrated cameras. 3 Epipole Estimation In this section we present a method to reconstruct the epipole from three homographies. As mentioned in the introduction, we can obtain three homographies from a fundamental matrix or from a trifocal tensor. <p> In practice, an equivalent and simpler approach is used: Calibrating the homography matrices E j using the estimation of the calibration matrices ~ M and ~ M 0 , and implying the iteration scheme of <ref> [9] </ref> to reconstruct the large rotation for the calibrated cameras case: H new2 ' ~ R T ~ M 0 1 1 T n T )M 1 ~ M 1 T n T ) The convergence of this method can not be guarantied, but for a first iteration in the right
Reference: [10] <author> A. Shashua M. Werman. </author> <title> Fundamental tensor: On the geometry of three perspective views. </title> <booktitle> In ICCV '95, </booktitle> <year> 1995. </year>
Reference-contexts: It extends [9] to the uncalibrated cameras case. Like [9], we use three homographies for reconstruction. Three homographies can be obtained directly from the trifocal tensor <ref> [10] </ref> or from the fundamental matrix between the 2 images using [1]. Note that the fundamental matrix and the trifocal tensor are unrecoverable in the pure rotation case.
Reference: [11] <author> B. Triggs. </author> <title> The absolute quadratic. </title> <booktitle> In CVPR '97, </booktitle> <pages> pages 609-614, </pages> <year> 1997. </year>
Reference-contexts: Finding the relative position of the camera (external parameters) is termed "pose estimation" or "ego motion". Self-calibration methods use more than one image. We will assume, without loss of generality, that the first camera is M [I; 0]. Most self-calibration papers <ref> [3, 8, 7, 11, 6, 5] </ref> start with the reconstruction of the projective cameras C i that differ by a 3-D projective transformations H i from the true camera.
References-found: 11

