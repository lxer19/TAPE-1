URL: http://www-eksl.cs.umass.edu/papers/rosenstein97a.ps
Refering-URL: http://www-eksl.cs.umass.edu/~mtr/papers/nld.html
Root-URL: 
Email: atking@cs.umass.edu  
Title: Action Representation, Prediction and Concepts  
Author: Michael T. Rosenstein, Paul R. Cohen, Matthew D. Schmill, and Marc S. Atkin fmtr, cohen, schmill, 
Address: Box 34610 Amherst, MA 01003-4610  
Affiliation: Computer Science Department, LGRC University of Massachusetts  
Abstract: A conceptual framework is a valuable resource for planning by situated agents. In this paper, we discuss the acquisition of such a framework. We take the position that concepts are abstractions of experience that confer a predictive ability for new situations. We also show specific examples which demonstrate the utility of abstract representations of actions, called activity maps, for reasoning about concepts and their entailments. In fact, we make the case that activity maps are concepts themselves. Where appropriate, we draw analogies with related work in nonlinear dynamics. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Agre, P. E., and Chapman, D. </author> <year> 1990. </year> <title> What are plans for? Robotics and Autonomous Systems 6 </title> <type> 17-34. </type>
Reference-contexts: Introduction Reasoning about one's environment, possible actions, and desired outcomes is the basis for planning | especially interactionist or improvisational planning <ref> (Agre & Chapman 1990) </ref>. Although our current focus is not planning per se, we do address the prerequisite problem of acquiring a conceptual structure for planning. In particular, this research is part of an effort to explain how sensorimotor agents develop symbolic, conceptual thought, as every human child does. <p> Surprisingly, activity maps can recognize what the agents are doing, quite accurately, with very little data. Are activity maps useful for planning? Surely, if activity maps lead to a conceptual structure for reasoning about actions and outcomes. One hint to this possibility comes from Agre and Chapman's <ref> (Agre & Chapman 1990) </ref> plan-as-communication view of plans. In this view, a plan no longer plays a central role in specifying activity, but rather guides an agent in action selection. <p> An integral part of plan-as-communication is a theory of activity which requires "two intercon-straining parts: a theory of cognitive machinery and a theory of the dynamics or regularly occurring patterns of activity. <ref> (Agre & Chapman 1990) </ref>" Activity maps provide both of these things. Are activity maps concepts? If by concept one means an abstraction that identifies a category and is invested with meaning through its predictions, then activity maps probably qualify. This issue is discussed further in a later section. <p> Nevertheless, this work has taken us a step closer to an understanding of "concept." Indeed, we are encouraged by how far we've come with activity maps from such a simple experimental domain. Planning Under Agre and Chapman's <ref> (Agre & Chapman 1990) </ref> plan-as-communication paradigm, one views an agent as a flexible participant in the world. Planning occurs during the course of action and requires the repeated evaluation of the current situation with respect to future outcomes. <p> In the previous example, we say nothing about how an agent actually decides what actions to follow. This problem is beyond the goals of this paper, although we are about to build agents that select actions by visualization <ref> (Agre & Chapman 1990) </ref>, i.e., by imagining the states and trajectories produced by available actions. Behavior maps and interaction maps naturally lend themselves to visual manipulation (e.g., gv, cluster analysis) and are ideal representations for planning by visualization. Acknowledgements We thank T. Oates and D. Westbrook for stimulating discussions.
Reference: <author> Brooks, R. A. </author> <year> 1991. </year> <title> Intelligence without Reasoning. </title> <booktitle> In Proceedings of the Twelth International Joint Conference on Artificial Intelligence, </booktitle> <pages> 569-595. </pages>
Reference-contexts: Although our current focus is not planning per se, we do address the prerequisite problem of acquiring a conceptual structure for planning. In particular, this research is part of an effort to explain how sensorimotor agents develop symbolic, conceptual thought, as every human child does. Like Brooks <ref> (Brooks 1991) </ref> and others, we are trying to "grow" an intelligent agent from minimal beginnings by having it interact with a complex environment (the "Baby Project" (Cohen et al. 1996)). A problem for these projects is the transition from sensorimotor programs to symbolic concepts.
Reference: <author> Cohen, P. R.; Oates, T.; Atkin, M. S.; and Beal, C. R. </author> <year> 1996. </year> <title> Building a baby. </title> <booktitle> In Eighteenth Annual Conference of the Cognitive Science Society, </booktitle> <pages> 518-522. </pages>
Reference-contexts: Like Brooks (Brooks 1991) and others, we are trying to "grow" an intelligent agent from minimal beginnings by having it interact with a complex environment (the "Baby Project" <ref> (Cohen et al. 1996) </ref>). A problem for these projects is the transition from sensorimotor programs to symbolic concepts.
Reference: <author> Gibbs, G. J., and Colston, H. L. </author> <year> 1995. </year> <title> The cognitive psychological reality of image schemas and their transforms. </title> <journal> Cognitive Linguistics 6-4:347-378. </journal>
Reference: <author> Johnson, M. </author> <year> 1987. </year> <title> The Body in the Mind. </title> <publisher> University of Chicago Press. </publisher>
Reference-contexts: This is one interpretation of Mandler's claim (Mandler 1992) that concepts are "minitheories" (i.e., predictive statements) and Lakoff's (Lakoff 1984) and John-son's <ref> (Johnson 1987) </ref> observations that image schemas (abstractions of experience) support entailments (i.e., predictive inferences). On this account, activity maps are concepts and their meanings are the predictions they support.
Reference: <author> Kiss, G. </author> <year> 1991. </year> <title> Autonomous agents, AI and chaos theory. In an S.W. </title> <editor> Wilson, J.-A. M., ed., </editor> <booktitle> From Animals To Animats: Proceedings of the First International Conference On the Simulation of Adaptive Behavior, </booktitle> <pages> 518-524. </pages> <address> Cambridge Massachusetts: </address> <publisher> The MIT Press. </publisher>
Reference-contexts: It's one thing to store a motor scheme for shaking a rattle, quite another to have the symbolic concept rattle, with all its entailments (i.e., plausible inferences), or even an extensional category of rattles. Thelen and Smith (Thelen & Smith 1994), Kiss <ref> (Kiss 1991) </ref>, Smithers (Smithers 1995), and Steels (Steels 1995) suggest that concepts (or categories, it isn't always clear which is intended) might be represented as dynamical systems, but none of these researchers demonstrates how such representations might be learned and used, or what their properties are.
Reference: <author> Lakoff, G. </author> <year> 1984. </year> <title> Women, Fire, and Dangerous Things. </title> <publisher> University of Chicago Press. </publisher>
Reference-contexts: In fact, predictiveness underlies our entire approach to concept acquisition: Concepts are abstractions selected for their ability to differentiate and predict, and their meanings are just their predictions. This is one interpretation of Mandler's claim (Mandler 1992) that concepts are "minitheories" (i.e., predictive statements) and Lakoff's <ref> (Lakoff 1984) </ref> and John-son's (Johnson 1987) observations that image schemas (abstractions of experience) support entailments (i.e., predictive inferences). On this account, activity maps are concepts and their meanings are the predictions they support.
Reference: <author> Mandler, J. M. </author> <year> 1992. </year> <title> How to build a baby: II. Conceptual primitives. </title> <journal> Psychological Review 99(4) </journal> <pages> 587-604. </pages>
Reference-contexts: In fact, predictiveness underlies our entire approach to concept acquisition: Concepts are abstractions selected for their ability to differentiate and predict, and their meanings are just their predictions. This is one interpretation of Mandler's claim <ref> (Mandler 1992) </ref> that concepts are "minitheories" (i.e., predictive statements) and Lakoff's (Lakoff 1984) and John-son's (Johnson 1987) observations that image schemas (abstractions of experience) support entailments (i.e., predictive inferences). On this account, activity maps are concepts and their meanings are the predictions they support.
Reference: <author> Rosch, E., and Lloyd, B. B. </author> <year> 1978. </year> <title> Cognition and Categorization. </title> <address> Hillsdale, NJ: </address> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference-contexts: Let us comment on some other aspects of concepts and categories and how they correspond to aspects of activity maps. Some instances of concepts are judged by humans to be "better examples" than others; Rosch discovered that robins, for example, are good prototypes for birds whereas turkeys are not <ref> (Rosch & Lloyd 1978) </ref>. A corresponding notion is that some trajectories through activity maps occur more often than others. Perhaps such a trajectory would be judged a prototypical crash, say.
Reference: <author> Rosenstein, M. T.; Collins, J. J.; and De Luca, C. J. </author> <year> 1994. </year> <title> Reconstruction expansion as a geometry-based framework for choosing proper delay times. </title> <journal> Physica D 73 </journal> <pages> 82-98. </pages>
Reference-contexts: Essentially, this is the purpose of attractor reconstruction methods which take time series and produce a topologically equivalent spatial representation of the underlying dynamical system. (See <ref> (Rosenstein, Collins, & De Luca 1994) </ref> and references therein.) The remainder of this section describes the construction of such representations, which we call behavior maps. One could certainly devise a number of visualization techniques (e.g., vector fields, 3D surface plots) for creating activity maps|behavior maps in particular.
Reference: <author> Smithers, T. </author> <year> 1995. </year> <title> Are autonomous agents information processing systems? In Steels, </title> <editor> L., and Brooks, R., eds., </editor> <title> The Artificial Life Route To Artificial Intelligence: Building Embodied, Situated Agents. </title> <publisher> Lawrence Erlbaum Associates. </publisher> <pages> 123-162. </pages>
Reference-contexts: It's one thing to store a motor scheme for shaking a rattle, quite another to have the symbolic concept rattle, with all its entailments (i.e., plausible inferences), or even an extensional category of rattles. Thelen and Smith (Thelen & Smith 1994), Kiss (Kiss 1991), Smithers <ref> (Smithers 1995) </ref>, and Steels (Steels 1995) suggest that concepts (or categories, it isn't always clear which is intended) might be represented as dynamical systems, but none of these researchers demonstrates how such representations might be learned and used, or what their properties are.
Reference: <author> Steels, L. </author> <year> 1995. </year> <title> Intelligence dynamics and representations. </title> <editor> In Steels, L., ed., </editor> <booktitle> The Biology and Technology of Intelligent Autonomous Agents. </booktitle> <address> Berlin: </address> <publisher> Springer Verlag. </publisher>
Reference-contexts: It's one thing to store a motor scheme for shaking a rattle, quite another to have the symbolic concept rattle, with all its entailments (i.e., plausible inferences), or even an extensional category of rattles. Thelen and Smith (Thelen & Smith 1994), Kiss (Kiss 1991), Smithers (Smithers 1995), and Steels <ref> (Steels 1995) </ref> suggest that concepts (or categories, it isn't always clear which is intended) might be represented as dynamical systems, but none of these researchers demonstrates how such representations might be learned and used, or what their properties are.
Reference: <author> Thelen, E., and Smith, L. </author> <year> 1994. </year> <title> A Dynamic Systems Approach to the Development of Cognition and Action. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher> <pages> 7 </pages>
Reference-contexts: It's one thing to store a motor scheme for shaking a rattle, quite another to have the symbolic concept rattle, with all its entailments (i.e., plausible inferences), or even an extensional category of rattles. Thelen and Smith <ref> (Thelen & Smith 1994) </ref>, Kiss (Kiss 1991), Smithers (Smithers 1995), and Steels (Steels 1995) suggest that concepts (or categories, it isn't always clear which is intended) might be represented as dynamical systems, but none of these researchers demonstrates how such representations might be learned and used, or what their properties are.
References-found: 13

