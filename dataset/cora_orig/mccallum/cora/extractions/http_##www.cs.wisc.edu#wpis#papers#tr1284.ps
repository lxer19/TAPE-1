URL: http://www.cs.wisc.edu/wpis/papers/tr1284.ps
Refering-URL: http://www.cs.wisc.edu/wpis/papers/
Root-URL: 
Email: horwitzg@cs.wisc.edu  
Title: Precise Interprocedural Dataflow Analysis with Applications to Constant Propagation 1  
Author: Mooly Sagiv, Thomas Reps, and Susan Horwitz 
Note: Electronic mail: fsagiv, reps,  
Address: 1210 West Dayton Street, Madison, WI 53706 USA  
Affiliation: Computer Sciences Department, University of Wisconsin-Madison  
Abstract: This paper concerns interprocedural dataflow-analysis problems in which the dataflow information at a program point is represented by an environment (i.e., a mapping from symbols to values), and the effect of a program operation is represented by a distributive environment transformer. We present two efficient algorithms that produce precise solutions: an exhaustive algorithm that finds values for all symbols at all program points, and a demand algorithm that finds the value for an individual symbol at a particular program point. Two interesting problems that can be handled by our algorithms are (decidable) variants of the interprocedural constant-propagation problem: copy-constant propagation and linear-constant propagation. The former interprets program statements of the form x := 7 and x := y. The latter also interprets statements of the form x := 5 fl y + 17. Experimental results on C programs have shown that * Although solving constant-propagation problems precisely (i.e., finding the meet-over-all-valid -paths solution, rather than the meet-over-all -paths solution) resulted in a slowdown by a factor ranging from 2:2 to 4:5, the precise algorithm found additional constants in 7 of 38 test programs. * In contrast to previous results for numeric Fortran programs, linear-constant propagation found more constants than copy-constant propagation in 6 of 38 test programs. * The demand algorithm, when used to demand values for all uses of scalar integer variables, was faster than the exhaustive algorithm by a factor ranging from 1:14 to about 6.
Abstract-found: 1
Intro-found: 1
Reference: [AHU74] <author> A.V. Aho, J.E. Hopcroft, and J.D. Ullman. </author> <title> The Design and Analysis of Computer Algorithms. </title> <publisher> Addison-Wesley, </publisher> <year> 1974. </year>
Reference-contexts: with a pure reachability problem, but with values obtained by applying functions along (realizable) paths. (The relationship between transformed IFDS problems and transformed IDE problems is similar to the relationship between ordinary graph-reachability problems and generalized problems that compute summaries over paths, such as shortest-path problems, closed-semiring path problems, etc. <ref> [AHU74, CLR90] </ref>.) * The algorithm's efficiency depends on the use of compact representations of the functions that label edges in (the transformed) IDE problems.
Reference: [BMSU86] <author> F. Bancilhon, D. Maier, Y. Sagiv, and J. Ullman. </author> <title> Magic sets and other strange ways to implement logic programs. </title> <booktitle> In Proceedings of the Fifth ACM Symposium on Principles of Database Systems, </booktitle> <year> 1986. </year>
Reference-contexts: way in which algorithms that solve demand versions of interprocedural analysis problems can be obtained automatically from their exhaustive counterparts (expressed as logic programs) by making use of the "magic-sets transformation", a general transformation developed in the logic-programming and deductive-database communities for creating efficient demand versions of (bottom-up) logic programs <ref> [RLK86, BMSU86, BR87, Ull89] </ref>. Reps illustrated this approach by showing how to obtain a demand algorithm for the interprocedural locally separable problems.
Reference: [BR87] <author> C. Beeri and R. Ramakrishnan. </author> <title> On the power of magic. </title> <booktitle> In Proceedings of the Sixth ACM Symposium on Principles of Database Systems, </booktitle> <pages> pages 269-293, </pages> <address> San Diego, CA, </address> <month> March </month> <year> 1987. </year> <month> 32 </month>
Reference-contexts: way in which algorithms that solve demand versions of interprocedural analysis problems can be obtained automatically from their exhaustive counterparts (expressed as logic programs) by making use of the "magic-sets transformation", a general transformation developed in the logic-programming and deductive-database communities for creating efficient demand versions of (bottom-up) logic programs <ref> [RLK86, BMSU86, BR87, Ull89] </ref>. Reps illustrated this approach by showing how to obtain a demand algorithm for the interprocedural locally separable problems.
Reference: [Cal88] <author> D. Callahan. </author> <title> The program summary graph and flow-sensitive interprocedural data flow analysis. </title> <booktitle> In SIGPLAN Conference on Programming Languages Design and Implementation, </booktitle> <pages> pages 47-56, </pages> <year> 1988. </year>
Reference-contexts: In contrast with intraprocedural dataflow analysis, where "precise" means "meet-over-all-paths" [Kil73], a precise inter procedural dataflow-analysis algorithm must provide the "meet-over-all-valid-paths" solution. (A path is valid if it respects the fact that when a procedure finishes it returns to the site of the most recent call <ref> [SP81, Cal88, LR91, KS92, Rep94b, RSH94, RHS95, DGS95, HRS95] </ref>.) In this paper, we show how to find the meet-over-all-valid-paths solution for a certain class of dataflow problems in which the dataflow facts are maps ("environments") from some finite set of symbols D to some (possibly infinite) set of values L (i.e.,
Reference: [CC78] <author> P. Cousot and R. Cousot. </author> <title> Static determination of dynamic properties of recursive procedures. </title> <editor> In E.J. Neuhold, editor, </editor> <title> Formal Descriptions of Programming Concepts, </title> <booktitle> (IFIP WG 2.2, </booktitle> <address> St. Andrews, Canada, </address> <month> August </month> <year> 1977), </year> <pages> pages 237-277. </pages> <publisher> North-Holland, </publisher> <year> 1978. </year>
Reference-contexts: functions that arise in the linear-constant-propagation problem can be represented very simply using triples of integers. 30 The IDE (and IFDS) problems can be solved by a number of previous algorithms, including the "elimination", "iterative", and "call-strings" algorithms given by Sharir and Pnueli and the algorithm of Cousot and Cousot <ref> [CC78] </ref>. However, for general IFDS and IDE problems, both the iterative and call-strings algorithms can take exponential time in the worst case. Knoop and Steffen give an algorithm similar to Sharir and Pnueli's "elimination" algorithm [KS92].
Reference: [CCKT86] <author> D. Callahan, K.D. Cooper, K. Kennedy, and L. Torczon. </author> <title> Interprocedural constant propagation. </title> <booktitle> In SIGPLAN Symposium on Compiler Construction, </booktitle> <pages> pages 152-161, </pages> <year> 1986. </year>
Reference-contexts: The algorithms obtained in this way improve on the well-known constant-propagation work from Rice <ref> [CCKT86, GT93] </ref> in two ways: 1. The Rice algorithm is not precise for recursive programs. (In fact, it may fall into an infinite loop when applied to recursive programs). 2. <p> For both copy-constant propagation and linear-constant propagation, there are several antecedents. A version of interprocedural copy-constant propagation was developed at Rice and has been in use for many years. The algorithm is described in <ref> [CCKT86] </ref>, and studies of how the algorithm performs in practice on Fortran programs were carried out by Grove and Torczon [GT93].
Reference: [CH95] <author> P. Carini and M. Hind. </author> <title> Flow-sensitive interprocedural constant propagation. </title> <booktitle> In SIGPLAN Conference on Programming Languages Design and Implementation, </booktitle> <pages> pages 23-31, </pages> <year> 1995. </year>
Reference-contexts: We have also shown in this paper how to solve linear-constant-propagation problems, which in general find a superset of the instances of constant variables found by copy-constant propagation. Several others have also examined classes of constant-propagation problems more general than copy-constant propagation <ref> [Kar76, SK91, GT93, MS93, CH95] </ref>. * Karr used linear algebra to define a safe algorithm for (intraprocedural) affine problems (i.e., problems in which relationships of the form x := a 1 y 1 + ::: + a k y k + c are tracked) [Kar76]. * Steffen and Knoop address the <p> + c] is not distributive.) However, their algorithm is imprecise; it does not find the "meet-over-all-valid-paths" solution. * Carini and Hind defined an algorithm for interprocedural constant propagation (extending the work of Wegman and Zadeck [WZ85]) that can handle non-distributive dataflow functions (and thus is more general than our algorithm) <ref> [CH95] </ref>. However, since they do not propagate values from called functions back to calling functions, their results are even less precise than our Naive Exhaustive algorithm. Wegman and Zadeck [WZ85], building on earlier work by Wegbreit [Weg75], examined the interaction between constant propagation and dead-code elimination.
Reference: [CLR90] <author> T.H. Cormen, C.E. Leiserson, and R.L. Rivest. </author> <title> Introduction to Algorithms. </title> <publisher> M.I.T. Press, </publisher> <year> 1990. </year>
Reference-contexts: with a pure reachability problem, but with values obtained by applying functions along (realizable) paths. (The relationship between transformed IFDS problems and transformed IDE problems is similar to the relationship between ordinary graph-reachability problems and generalized problems that compute summaries over paths, such as shortest-path problems, closed-semiring path problems, etc. <ref> [AHU74, CLR90] </ref>.) * The algorithm's efficiency depends on the use of compact representations of the functions that label edges in (the transformed) IDE problems.
Reference: [DGS95] <author> E. Duesterwald, R. Gupta, </author> <title> and M.L. Soffa. Demand-driven computation of interprocedural data flow. </title> <booktitle> In ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 37-48, </pages> <year> 1995. </year>
Reference-contexts: In contrast with intraprocedural dataflow analysis, where "precise" means "meet-over-all-paths" [Kil73], a precise inter procedural dataflow-analysis algorithm must provide the "meet-over-all-valid-paths" solution. (A path is valid if it respects the fact that when a procedure finishes it returns to the site of the most recent call <ref> [SP81, Cal88, LR91, KS92, Rep94b, RSH94, RHS95, DGS95, HRS95] </ref>.) In this paper, we show how to find the meet-over-all-valid-paths solution for a certain class of dataflow problems in which the dataflow facts are maps ("environments") from some finite set of symbols D to some (possibly infinite) set of values L (i.e., <p> In contrast, our algorithm yields precise results, for both recursive and non-recursive programs. * In Section 6 we present a demand dataflow-analysis algorithm for the class of IDE problems. This demand algorithm is more general than both the demand algorithm of Duesterwald, Gupta, and Soffa <ref> [DGS95] </ref> and the demand algorithm of Horwitz, Reps, and Sagiv [HRS95]. For example, it can handle linear-constant-propagation problems, which neither of the above algorithms can handle. * Our dataflow-analysis algorithms have been implemented and used to analyze C programs. <p> Demand algorithms can then be obtained by applying the magic-sets transformation.) A different approach to obtaining demand versions of interprocedural dataflow-analysis algorithms has been investigated by Duesterwald, Gupta, and Soffa <ref> [DGS95] </ref>. In their approach, for each query a set of dataflow equations is set up on the flow graph (but as if all edges were reversed). The flow functions on the reverse graph are the (approximate) inverses of the forward flow functions.
Reference: [FL88] <author> C.N. Fischer and R.J. LeBlanc. </author> <title> Crafting a Compiler. </title> <publisher> Benjamin/Cummings Publishing Company, Inc., </publisher> <address> Menlo Park, CA, </address> <year> 1988. </year>
Reference-contexts: in Software Engineering, (Aarhus, Denmark, May 22-26, 1995) [SRH95]. 2 On leave from IBM Scientific Center, Haifa, Israel. 1 the number of edges in the program's control-flow graph and D is the number of symbols in an environment. * We study two natural variants of the constant-propagation problem: copy-constant propagation <ref> [FL88] </ref> and linear-constant propagation, which extends copy-constant propagation by interpreting statements of the form x = a fl y + b, where a and b are literals or user-defined constants. <p> The IFDS problems include all locally separable problems | the interprocedural versions of classical "bit-vector" or "gen-kill" problems (e.g., reaching definitions, available expressions, and live variables) | as well as non-locally-separable problems such as truly-live variables [GMW81], copy-constant propagation <ref> [FL88, page 660] </ref>, and possibly-uninitialized variables [RSH94, RHS95, HRS95].
Reference: [GMW81] <author> R. Giegerich, U. Moncke, and R. Wilhelm. </author> <title> Invariance of approximative semantics with respect to program transformation. </title> <booktitle> In GI 81 11th GI Annual Conference, </booktitle> <volume> Informatik-Fachberichte 50, </volume> <pages> pages 1-10, </pages> <address> New York, NY, 1981. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: The IFDS problems include all locally separable problems | the interprocedural versions of classical "bit-vector" or "gen-kill" problems (e.g., reaching definitions, available expressions, and live variables) | as well as non-locally-separable problems such as truly-live variables <ref> [GMW81] </ref>, copy-constant propagation [FL88, page 660], and possibly-uninitialized variables [RSH94, RHS95, HRS95].
Reference: [GT93] <author> D. Grove and L. Torczon. </author> <title> A study of jump function implementations. </title> <booktitle> In SIGPLAN Conference on Programming Languages Design and Implementation, </booktitle> <pages> pages 90-99, </pages> <year> 1993. </year>
Reference-contexts: The algorithms obtained in this way improve on the well-known constant-propagation work from Rice <ref> [CCKT86, GT93] </ref> in two ways: 1. The Rice algorithm is not precise for recursive programs. (In fact, it may fall into an infinite loop when applied to recursive programs). 2. <p> Our experimental results have shown that * Although solving constant-propagation problems precisely resulted in a slowdown by a factor ranging from 2:2 to 4:5, the precise algorithm found additional constants in 7 of 38 test programs. * In contrast to previous results for numeric Fortran programs <ref> [GT93] </ref>, linear-constant prop agation found more constants than copy-constant propagation in 6 of 38 test programs. * The demand algorithm, when used to demand values for all uses of scalar integer variables, was faster than the exhaustive algorithm by a factor ranging from 1:14 to about 6. <p> Furthermore, in 7 out of the 38 test programs, linear-constant propagation via the Precise Exhaustive algorithm found more constants than copy-constant propagation via the Naive Exhaustive algorithm. These results are in contrast to previous results reported by Grove and Tor-czon for numeric Fortran programs <ref> [GT93] </ref>, in which no differences in accuracy were found between "pass-through parameter" constant propagation (which is even weaker than copy-constant propagation) and "polynomial parameter" constant propagation (which is stronger than linear-constant propagation). 9 9 The algorithm used by Grove and Torczon in their study did not necessarily determine precise interprocedural information <p> A version of interprocedural copy-constant propagation was developed at Rice and has been in use for many years. The algorithm is described in [CCKT86], and studies of how the algorithm performs in practice on Fortran programs were carried out by Grove and Torczon <ref> [GT93] </ref>. <p> We have also shown in this paper how to solve linear-constant-propagation problems, which in general find a superset of the instances of constant variables found by copy-constant propagation. Several others have also examined classes of constant-propagation problems more general than copy-constant propagation <ref> [Kar76, SK91, GT93, MS93, CH95] </ref>. * Karr used linear algebra to define a safe algorithm for (intraprocedural) affine problems (i.e., problems in which relationships of the form x := a 1 y 1 + ::: + a k y k + c are tracked) [Kar76]. * Steffen and Knoop address the <p> They define a decidable version of the problem and give an algorithm for the intraprocedural setting. In the case of loop-free code, the algorithm is optimal. * Grove and Torczon defined a class of polynomial jump functions <ref> [GT93] </ref>, which are more general than the linear jump functions used in our work; however, because of limitations in the way they define "return jump functions", their algorithm does not necessarily find precise interprocedural information. * An algorithm given by Metzger and Stroud can handle statements of the form x :=
Reference: [HRS95] <author> S. Horwitz, T. Reps, and M. Sagiv. </author> <title> Demand interprocedural dataflow analysis. </title> <booktitle> In Proceedings of the Third ACM SIGSOFT Symposium on the Foundations of Software Engineering, </booktitle> <year> 1995. </year>
Reference-contexts: In contrast with intraprocedural dataflow analysis, where "precise" means "meet-over-all-paths" [Kil73], a precise inter procedural dataflow-analysis algorithm must provide the "meet-over-all-valid-paths" solution. (A path is valid if it respects the fact that when a procedure finishes it returns to the site of the most recent call <ref> [SP81, Cal88, LR91, KS92, Rep94b, RSH94, RHS95, DGS95, HRS95] </ref>.) In this paper, we show how to find the meet-over-all-valid-paths solution for a certain class of dataflow problems in which the dataflow facts are maps ("environments") from some finite set of symbols D to some (possibly infinite) set of values L (i.e., <p> This demand algorithm is more general than both the demand algorithm of Duesterwald, Gupta, and Soffa [DGS95] and the demand algorithm of Horwitz, Reps, and Sagiv <ref> [HRS95] </ref>. For example, it can handle linear-constant-propagation problems, which neither of the above algorithms can handle. * Our dataflow-analysis algorithms have been implemented and used to analyze C programs. <p> In IFDS problems, the dataflow facts form a finite set U , and the dataflow functions (which are of type 2 U ! 2 U ) distribute over the meet operator (either union or intersection) <ref> [RSH94, RHS95, HRS95] </ref>. The IFDS problems include all locally separable problems | the interprocedural versions of classical "bit-vector" or "gen-kill" problems (e.g., reaching definitions, available expressions, and live variables) | as well as non-locally-separable problems such as truly-live variables [GMW81], copy-constant propagation [FL88, page 660], and possibly-uninitialized variables [RSH94, RHS95, HRS95]. <p> or intersection) <ref> [RSH94, RHS95, HRS95] </ref>. The IFDS problems include all locally separable problems | the interprocedural versions of classical "bit-vector" or "gen-kill" problems (e.g., reaching definitions, available expressions, and live variables) | as well as non-locally-separable problems such as truly-live variables [GMW81], copy-constant propagation [FL88, page 660], and possibly-uninitialized variables [RSH94, RHS95, HRS95]. <p> In this section, we explain how our ideas and results relate to previous work. 8.1 The IDE Framework The IDE framework is based on earlier interprocedural dataflow-analysis frameworks defined by Sharir and Pnueli [SP81] and Knoop and Steffen [KS92], as well as the IFDS framework that we proposed earlier <ref> [RSH94, RHS95, HRS95] </ref>. <p> An algorithm for precise copy-constant propagation (for both recursive and non-recursive programs) was given using the IFDS framework by Reps, Sagiv, and Horwitz <ref> [RSH94, HRS95] </ref>. However, as discussed in Section 8.1, there is a significant drawback to formulating copy-constant propagation as an IFDS problem: The running time and the space used both depend on the quantity "number of literals in the program". <p> The relationship between the demand algorithm of Section 6 and the exhaustive algorithm of Section 5 is similar to the relationship that holds for IFDS problems between the demand algorithm of <ref> [RSH94, HRS95] </ref> and the exhaustive algorithm of [RSH94, RHS95]. One approach to obtaining demand algorithms for interprocedural dataflow-analysis problems was described by Reps [Rep94c, Rep94a].
Reference: [JM86] <author> N.D. Jones and A. Mycroft. </author> <title> Data flow analysis of applicative programs using minimal function graphs. </title> <booktitle> In ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 296-306, </pages> <year> 1986. </year>
Reference-contexts: Figure 6 depicts the configurations that are used by ForwardComputeJumpFunctionsSLRPs to progressively compute better approximations to jump and summary functions for longer and longer same-level realizable paths. To reduce the amount of work performed, ForwardComputeJumpFunctionsSLRPs uses an idea similar to the "minimal-function-graph" approach <ref> [JM86] </ref>: Only after a jump function for a path from a node of the form hs p ; d 1 i to a node of the form hc; d 2 i has been processed, where c is a call on procedure q, will a path from hs q ; d 3
Reference: [Kar76] <author> M. Karr. </author> <title> Affine relationship among variables of a program. </title> <journal> Acta Inf., </journal> <volume> 6 </volume> <pages> 133-151, </pages> <year> 1976. </year>
Reference-contexts: We have also shown in this paper how to solve linear-constant-propagation problems, which in general find a superset of the instances of constant variables found by copy-constant propagation. Several others have also examined classes of constant-propagation problems more general than copy-constant propagation <ref> [Kar76, SK91, GT93, MS93, CH95] </ref>. * Karr used linear algebra to define a safe algorithm for (intraprocedural) affine problems (i.e., problems in which relationships of the form x := a 1 y 1 + ::: + a k y k + c are tracked) [Kar76]. * Steffen and Knoop address the <p> problems more general than copy-constant propagation [Kar76, SK91, GT93, MS93, CH95]. * Karr used linear algebra to define a safe algorithm for (intraprocedural) affine problems (i.e., problems in which relationships of the form x := a 1 y 1 + ::: + a k y k + c are tracked) <ref> [Kar76] </ref>. * Steffen and Knoop address the more general problem of determining whether a subexpression (rather than a variable) has a constant value [SK91]. They define a decidable version of the problem and give an algorithm for the intraprocedural setting.
Reference: [Kil73] <author> G.A. Kildall. </author> <title> A unified approach to global program optimization. </title> <booktitle> In ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 194-206, </pages> <year> 1973. </year>
Reference-contexts: Of the problems to which our techniques apply, several variants of the interprocedural constant-propagation problem stand out as being of particular importance. In contrast with intraprocedural dataflow analysis, where "precise" means "meet-over-all-paths" <ref> [Kil73] </ref>, a precise inter procedural dataflow-analysis algorithm must provide the "meet-over-all-valid-paths" solution. (A path is valid if it respects the fact that when a procedure finishes it returns to the site of the most recent call [SP81, Cal88, LR91, KS92, Rep94b, RSH94, RHS95, DGS95, HRS95].) In this paper, we show how
Reference: [KS92] <author> J. Knoop and B. Steffen. </author> <title> The interprocedural coincidence theorem. </title> <booktitle> In International Conference on Compiler Construction, </booktitle> <pages> pages 125-140, </pages> <year> 1992. </year>
Reference-contexts: In contrast with intraprocedural dataflow analysis, where "precise" means "meet-over-all-paths" [Kil73], a precise inter procedural dataflow-analysis algorithm must provide the "meet-over-all-valid-paths" solution. (A path is valid if it respects the fact that when a procedure finishes it returns to the site of the most recent call <ref> [SP81, Cal88, LR91, KS92, Rep94b, RSH94, RHS95, DGS95, HRS95] </ref>.) In this paper, we show how to find the meet-over-all-valid-paths solution for a certain class of dataflow problems in which the dataflow facts are maps ("environments") from some finite set of symbols D to some (possibly infinite) set of values L (i.e., <p> In this section, we explain how our ideas and results relate to previous work. 8.1 The IDE Framework The IDE framework is based on earlier interprocedural dataflow-analysis frameworks defined by Sharir and Pnueli [SP81] and Knoop and Steffen <ref> [KS92] </ref>, as well as the IFDS framework that we proposed earlier [RSH94, RHS95, HRS95]. <p> Condition (iii), however, generalizes the Sharir-Pnueli framework and permits it to cover programming languages in which recursive procedures have local variables and parameters (which the Sharir-Pnueli framework does not). A different generalization to handle recursive procedures with local variables and parameters was proposed by Knoop and Steffen <ref> [KS92] </ref>. 29 As discussed in Section 5.4.1, the IDE framework is a strict generalization of the IFDS framework. <p> However, for general IFDS and IDE problems, both the iterative and call-strings algorithms can take exponential time in the worst case. Knoop and Steffen give an algorithm similar to Sharir and Pnueli's "elimination" algorithm <ref> [KS92] </ref>. The efficiencies of the Sharir-Pnueli and Knoop-Steffen elimination algorithms depend, among other things, on the way functions are represented. No representations are discussed in [SP81] and [KS92]; however, even if the techniques of the present paper are used, because the Sharir-Pnueli and Knoop-Steffen algorithms manipulate functions as a whole, rather <p> Knoop and Steffen give an algorithm similar to Sharir and Pnueli's "elimination" algorithm <ref> [KS92] </ref>. The efficiencies of the Sharir-Pnueli and Knoop-Steffen elimination algorithms depend, among other things, on the way functions are represented. No representations are discussed in [SP81] and [KS92]; however, even if the techniques of the present paper are used, because the Sharir-Pnueli and Knoop-Steffen algorithms manipulate functions as a whole, rather than pointwise, they are not as efficient as the algorithm presented here. 8.2 Constant-Propagation Algorithms Our algorithms for solving IDE problems can be used to find precise
Reference: [LR91] <author> W. Landi and B.G. Ryder. </author> <title> Pointer induced aliasing: A problem classification. </title> <booktitle> In ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 93-103, </pages> <year> 1991. </year>
Reference-contexts: In contrast with intraprocedural dataflow analysis, where "precise" means "meet-over-all-paths" [Kil73], a precise inter procedural dataflow-analysis algorithm must provide the "meet-over-all-valid-paths" solution. (A path is valid if it respects the fact that when a procedure finishes it returns to the site of the most recent call <ref> [SP81, Cal88, LR91, KS92, Rep94b, RSH94, RHS95, DGS95, HRS95] </ref>.) In this paper, we show how to find the meet-over-all-valid-paths solution for a certain class of dataflow problems in which the dataflow facts are maps ("environments") from some finite set of symbols D to some (possibly infinite) set of values L (i.e.,
Reference: [MS93] <author> R. Metzger and S. Stroud. </author> <title> Interprocedural constant propagation: An empirical study. </title> <journal> ACM Letters on Programming Languages and Systems, </journal> <volume> 2, </volume> <year> 1993. </year>
Reference-contexts: We have also shown in this paper how to solve linear-constant-propagation problems, which in general find a superset of the instances of constant variables found by copy-constant propagation. Several others have also examined classes of constant-propagation problems more general than copy-constant propagation <ref> [Kar76, SK91, GT93, MS93, CH95] </ref>. * Karr used linear algebra to define a safe algorithm for (intraprocedural) affine problems (i.e., problems in which relationships of the form x := a 1 y 1 + ::: + a k y k + c are tracked) [Kar76]. * Steffen and Knoop address the <p> the linear jump functions used in our work; however, because of limitations in the way they define "return jump functions", their algorithm does not necessarily find precise interprocedural information. * An algorithm given by Metzger and Stroud can handle statements of the form x := ay + bz + c <ref> [MS93] </ref>, which is a more general form than can be handled by the IDE framework. (The environment transformer that corresponds to such a statement, env:env [x ! a fl env (y) + 31 b fl env (z) + c] is not distributive.) However, their algorithm is imprecise; it does not find
Reference: [Rep94a] <author> T. Reps. </author> <title> Demand interprocedural program analysis using logic databases. </title> <editor> In R. Ramakrishnan, editor, </editor> <booktitle> Applications of Logic Databases. </booktitle> <publisher> Kluwer Academic Publishers, </publisher> <year> 1994. </year>
Reference-contexts: One approach to obtaining demand algorithms for interprocedural dataflow-analysis problems was described by Reps <ref> [Rep94c, Rep94a] </ref>.
Reference: [Rep94b] <author> T. Reps. </author> <title> Solving demand versions of interprocedural analysis problems. </title> <booktitle> In International Conference on Compiler Construction, </booktitle> <pages> pages 389-403, </pages> <year> 1994. </year>
Reference-contexts: In contrast with intraprocedural dataflow analysis, where "precise" means "meet-over-all-paths" [Kil73], a precise inter procedural dataflow-analysis algorithm must provide the "meet-over-all-valid-paths" solution. (A path is valid if it respects the fact that when a procedure finishes it returns to the site of the most recent call <ref> [SP81, Cal88, LR91, KS92, Rep94b, RSH94, RHS95, DGS95, HRS95] </ref>.) In this paper, we show how to find the meet-over-all-valid-paths solution for a certain class of dataflow problems in which the dataflow facts are maps ("environments") from some finite set of symbols D to some (possibly infinite) set of values L (i.e.,
Reference: [Rep94c] <author> T. Reps. </author> <title> Solving demand versions of interprocedural analysis problems. </title> <booktitle> In Proceedings of the Fifth International Conference on Compiler Construction, </booktitle> <pages> pages 389-403, </pages> <address> Edinburgh, Scotland, </address> <month> April </month> <year> 1994. </year> <note> Appeared as Lecture Notes in Computer Science, Vol. 786, </note> <editor> P. Fritzson (ed.), </editor> <publisher> Springer-Verlag, </publisher> <address> New York, NY, </address> <year> 1994. </year>
Reference-contexts: One approach to obtaining demand algorithms for interprocedural dataflow-analysis problems was described by Reps <ref> [Rep94c, Rep94a] </ref>.
Reference: [RHS95] <author> T. Reps, S. Horwitz, and M. Sagiv. </author> <title> Precise interprocedural dataflow analysis via graph reacha-bility. </title> <booktitle> In ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 49-61, </pages> <year> 1995. </year>
Reference-contexts: In contrast with intraprocedural dataflow analysis, where "precise" means "meet-over-all-paths" [Kil73], a precise inter procedural dataflow-analysis algorithm must provide the "meet-over-all-valid-paths" solution. (A path is valid if it respects the fact that when a procedure finishes it returns to the site of the most recent call <ref> [SP81, Cal88, LR91, KS92, Rep94b, RSH94, RHS95, DGS95, HRS95] </ref>.) In this paper, we show how to find the meet-over-all-valid-paths solution for a certain class of dataflow problems in which the dataflow facts are maps ("environments") from some finite set of symbols D to some (possibly infinite) set of values L (i.e., <p> In IFDS problems, the dataflow facts form a finite set U , and the dataflow functions (which are of type 2 U ! 2 U ) distribute over the meet operator (either union or intersection) <ref> [RSH94, RHS95, HRS95] </ref>. The IFDS problems include all locally separable problems | the interprocedural versions of classical "bit-vector" or "gen-kill" problems (e.g., reaching definitions, available expressions, and live variables) | as well as non-locally-separable problems such as truly-live variables [GMW81], copy-constant propagation [FL88, page 660], and possibly-uninitialized variables [RSH94, RHS95, HRS95]. <p> or intersection) <ref> [RSH94, RHS95, HRS95] </ref>. The IFDS problems include all locally separable problems | the interprocedural versions of classical "bit-vector" or "gen-kill" problems (e.g., reaching definitions, available expressions, and live variables) | as well as non-locally-separable problems such as truly-live variables [GMW81], copy-constant propagation [FL88, page 660], and possibly-uninitialized variables [RSH94, RHS95, HRS95]. <p> In this section, we explain how our ideas and results relate to previous work. 8.1 The IDE Framework The IDE framework is based on earlier interprocedural dataflow-analysis frameworks defined by Sharir and Pnueli [SP81] and Knoop and Steffen [KS92], as well as the IFDS framework that we proposed earlier <ref> [RSH94, RHS95, HRS95] </ref>. <p> The relationship between the demand algorithm of Section 6 and the exhaustive algorithm of Section 5 is similar to the relationship that holds for IFDS problems between the demand algorithm of [RSH94, HRS95] and the exhaustive algorithm of <ref> [RSH94, RHS95] </ref>. One approach to obtaining demand algorithms for interprocedural dataflow-analysis problems was described by Reps [Rep94c, Rep94a]. <p> Reps illustrated this approach by showing how to obtain a demand algorithm for the interprocedural locally separable problems. Subsequent work by Reps, Sagiv, and Horwitz extended the logic-programming approach to the class of IFDS problems <ref> [RSH94, RHS95] </ref>. (The latter papers do not make use of logic-programming terminology; however, the exhaustive algorithms described in the papers have straightforward implementations as logic programs.
Reference: [RLK86] <author> R. Rohmer, R. Lescoeur, and J.-M. Kersit. </author> <title> The Alexander method, a technique for the processing of recursive axioms in deductive databases. </title> <journal> New Generation Computing, </journal> <volume> 4(3) </volume> <pages> 273-285, </pages> <year> 1986. </year>
Reference-contexts: way in which algorithms that solve demand versions of interprocedural analysis problems can be obtained automatically from their exhaustive counterparts (expressed as logic programs) by making use of the "magic-sets transformation", a general transformation developed in the logic-programming and deductive-database communities for creating efficient demand versions of (bottom-up) logic programs <ref> [RLK86, BMSU86, BR87, Ull89] </ref>. Reps illustrated this approach by showing how to obtain a demand algorithm for the interprocedural locally separable problems.
Reference: [RSH94] <author> T. Reps, M. Sagiv, and S. Horwitz. </author> <title> Interprocedural dataflow analysis via graph reachability. </title> <type> Technical Report TR 94-14, </type> <institution> Datalogisk Institut, University of Copenhagen, </institution> <year> 1994. </year>
Reference-contexts: In contrast with intraprocedural dataflow analysis, where "precise" means "meet-over-all-paths" [Kil73], a precise inter procedural dataflow-analysis algorithm must provide the "meet-over-all-valid-paths" solution. (A path is valid if it respects the fact that when a procedure finishes it returns to the site of the most recent call <ref> [SP81, Cal88, LR91, KS92, Rep94b, RSH94, RHS95, DGS95, HRS95] </ref>.) In this paper, we show how to find the meet-over-all-valid-paths solution for a certain class of dataflow problems in which the dataflow facts are maps ("environments") from some finite set of symbols D to some (possibly infinite) set of values L (i.e., <p> In IFDS problems, the dataflow facts form a finite set U , and the dataflow functions (which are of type 2 U ! 2 U ) distribute over the meet operator (either union or intersection) <ref> [RSH94, RHS95, HRS95] </ref>. The IFDS problems include all locally separable problems | the interprocedural versions of classical "bit-vector" or "gen-kill" problems (e.g., reaching definitions, available expressions, and live variables) | as well as non-locally-separable problems such as truly-live variables [GMW81], copy-constant propagation [FL88, page 660], and possibly-uninitialized variables [RSH94, RHS95, HRS95]. <p> or intersection) <ref> [RSH94, RHS95, HRS95] </ref>. The IFDS problems include all locally separable problems | the interprocedural versions of classical "bit-vector" or "gen-kill" problems (e.g., reaching definitions, available expressions, and live variables) | as well as non-locally-separable problems such as truly-live variables [GMW81], copy-constant propagation [FL88, page 660], and possibly-uninitialized variables [RSH94, RHS95, HRS95]. <p> In this section, we explain how our ideas and results relate to previous work. 8.1 The IDE Framework The IDE framework is based on earlier interprocedural dataflow-analysis frameworks defined by Sharir and Pnueli [SP81] and Knoop and Steffen [KS92], as well as the IFDS framework that we proposed earlier <ref> [RSH94, RHS95, HRS95] </ref>. <p> An algorithm for precise copy-constant propagation (for both recursive and non-recursive programs) was given using the IFDS framework by Reps, Sagiv, and Horwitz <ref> [RSH94, HRS95] </ref>. However, as discussed in Section 8.1, there is a significant drawback to formulating copy-constant propagation as an IFDS problem: The running time and the space used both depend on the quantity "number of literals in the program". <p> The relationship between the demand algorithm of Section 6 and the exhaustive algorithm of Section 5 is similar to the relationship that holds for IFDS problems between the demand algorithm of <ref> [RSH94, HRS95] </ref> and the exhaustive algorithm of [RSH94, RHS95]. One approach to obtaining demand algorithms for interprocedural dataflow-analysis problems was described by Reps [Rep94c, Rep94a]. <p> The relationship between the demand algorithm of Section 6 and the exhaustive algorithm of Section 5 is similar to the relationship that holds for IFDS problems between the demand algorithm of [RSH94, HRS95] and the exhaustive algorithm of <ref> [RSH94, RHS95] </ref>. One approach to obtaining demand algorithms for interprocedural dataflow-analysis problems was described by Reps [Rep94c, Rep94a]. <p> Reps illustrated this approach by showing how to obtain a demand algorithm for the interprocedural locally separable problems. Subsequent work by Reps, Sagiv, and Horwitz extended the logic-programming approach to the class of IFDS problems <ref> [RSH94, RHS95] </ref>. (The latter papers do not make use of logic-programming terminology; however, the exhaustive algorithms described in the papers have straightforward implementations as logic programs.
Reference: [SK91] <author> B. Steffen and J. Knoop. </author> <title> Finite constants: Characterizations of a new decidable set of constants. </title> <journal> Theoretical Computer Science, </journal> <volume> 80(2) </volume> <pages> 303-318, </pages> <year> 1991. </year>
Reference-contexts: We have also shown in this paper how to solve linear-constant-propagation problems, which in general find a superset of the instances of constant variables found by copy-constant propagation. Several others have also examined classes of constant-propagation problems more general than copy-constant propagation <ref> [Kar76, SK91, GT93, MS93, CH95] </ref>. * Karr used linear algebra to define a safe algorithm for (intraprocedural) affine problems (i.e., problems in which relationships of the form x := a 1 y 1 + ::: + a k y k + c are tracked) [Kar76]. * Steffen and Knoop address the <p> affine problems (i.e., problems in which relationships of the form x := a 1 y 1 + ::: + a k y k + c are tracked) [Kar76]. * Steffen and Knoop address the more general problem of determining whether a subexpression (rather than a variable) has a constant value <ref> [SK91] </ref>. They define a decidable version of the problem and give an algorithm for the intraprocedural setting.
Reference: [SP81] <author> M. Sharir and A. Pnueli. </author> <title> Two approaches for interprocedural data flow analysis. </title> <editor> In S.S. Muchnick and N.D. Jones, editors, </editor> <title> Program Flow Analysis: </title> <journal> Theory and Applications, </journal> <volume> chapter 7, </volume> <pages> pages 189-234. </pages> <publisher> Prentice-Hall, </publisher> <year> 1981. </year>
Reference-contexts: In contrast with intraprocedural dataflow analysis, where "precise" means "meet-over-all-paths" [Kil73], a precise inter procedural dataflow-analysis algorithm must provide the "meet-over-all-valid-paths" solution. (A path is valid if it respects the fact that when a procedure finishes it returns to the site of the most recent call <ref> [SP81, Cal88, LR91, KS92, Rep94b, RSH94, RHS95, DGS95, HRS95] </ref>.) In this paper, we show how to find the meet-over-all-valid-paths solution for a certain class of dataflow problems in which the dataflow facts are maps ("environments") from some finite set of symbols D to some (possibly infinite) set of values L (i.e., <p> all IDE problems; however, it does terminate for all copy-constant-propagation problems, all linear-constant-propagation problems, and, in general, for all problems for which the space F of micro-functions contains no infinite decreasing chains. (Note that it is possible to construct infinite decreasing chains even in certain distributive variants of constant propagation <ref> [SP81, page 206] </ref>.) The cost of the algorithm is dominated by the cost of Phase I. This phase can be carried out particularly efficiently if there exists a way of representing the micro-functions such that certain operations on micro-functions can be computed in unit-time. <p> We have described an algorithm to solve such problems precisely in polynomial time. In this section, we explain how our ideas and results relate to previous work. 8.1 The IDE Framework The IDE framework is based on earlier interprocedural dataflow-analysis frameworks defined by Sharir and Pnueli <ref> [SP81] </ref> and Knoop and Steffen [KS92], as well as the IFDS framework that we proposed earlier [RSH94, RHS95, HRS95]. <p> Knoop and Steffen give an algorithm similar to Sharir and Pnueli's "elimination" algorithm [KS92]. The efficiencies of the Sharir-Pnueli and Knoop-Steffen elimination algorithms depend, among other things, on the way functions are represented. No representations are discussed in <ref> [SP81] </ref> and [KS92]; however, even if the techniques of the present paper are used, because the Sharir-Pnueli and Knoop-Steffen algorithms manipulate functions as a whole, rather than pointwise, they are not as efficient as the algorithm presented here. 8.2 Constant-Propagation Algorithms Our algorithms for solving IDE problems can be used to
Reference: [SPE92] <institution> SPEC Component CPU Integer Release 2/1992 (Cint92). Standard Performance Evaluation Corporation (SPEC), Fairfax, VA, </institution> <year> 1992. </year>
Reference-contexts: The three algorithms were implemented in C and used with a front end that analyzes a C program and generates the corresponding exploded supergraphs for copy-constant propagation and linear-constant propagation (for scalar integer variables). 8 The study used 38 C programs; some came from the SPEC integer benchmark suite <ref> [SPE92] </ref> and some were standard UNIX utilities. Figure 12 gives information about the characteristics of the test programs. The second column indicates the code size (lines of C source code after the C preprocessor has been applied and blank lines removed).
Reference: [SRH95] <author> M. Sagiv, T. Reps, and S. Horwitz. </author> <title> Precise interprocedural dataflow analysis with applications to constant propagation. </title> <editor> In P.D. Mosses, M. Nielsen, and M.I. Schwartzbach, editors, </editor> <booktitle> Proceedings of FASE 95: Colloquium on Formal Approaches in Software Engineering, volume 915 of Lecture Notes in Computer Science, </booktitle> <pages> pages 651-665, </pages> <address> Aarhus, Denmark, </address> <month> May </month> <year> 1995. </year> <note> Springer-Verlag. 33 </note>
Reference-contexts: Part of this work was done while the authors were visiting the University of Copenhagen. A preliminary version of this paper appeared in Proceedings of FASE 95: Colloquium on Formal Approaches in Software Engineering, (Aarhus, Denmark, May 22-26, 1995) <ref> [SRH95] </ref>. 2 On leave from IBM Scientific Center, Haifa, Israel. 1 the number of edges in the program's control-flow graph and D is the number of symbols in an environment. * We study two natural variants of the constant-propagation problem: copy-constant propagation [FL88] and linear-constant propagation, which extends copy-constant propagation by
Reference: [Ull89] <author> J. D. Ullman. </author> <title> Principles of Database and Knowledge-Base Systems, Volume II: The New Tech--nologies. </title> <publisher> Computer Science Press, </publisher> <address> Rockville, MD, </address> <year> 1989. </year>
Reference-contexts: way in which algorithms that solve demand versions of interprocedural analysis problems can be obtained automatically from their exhaustive counterparts (expressed as logic programs) by making use of the "magic-sets transformation", a general transformation developed in the logic-programming and deductive-database communities for creating efficient demand versions of (bottom-up) logic programs <ref> [RLK86, BMSU86, BR87, Ull89] </ref>. Reps illustrated this approach by showing how to obtain a demand algorithm for the interprocedural locally separable problems.
Reference: [Weg75] <author> B. Wegbreit. </author> <title> Property extraction in well-founded property sets. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 1(3) </volume> <pages> 270-285, </pages> <year> 1975. </year>
Reference-contexts: However, since they do not propagate values from called functions back to calling functions, their results are even less precise than our Naive Exhaustive algorithm. Wegman and Zadeck [WZ85], building on earlier work by Wegbreit <ref> [Weg75] </ref>, examined the interaction between constant propagation and dead-code elimination.
Reference: [WZ85] <author> M.N. Wegman and F.K. Zadeck. </author> <title> Constant propagation with conditional branches. </title> <booktitle> In ACM Symposium on Principles of Programming Languages, </booktitle> <year> 1985. </year> <month> 34 </month>
Reference-contexts: a statement, env:env [x ! a fl env (y) + 31 b fl env (z) + c] is not distributive.) However, their algorithm is imprecise; it does not find the "meet-over-all-valid-paths" solution. * Carini and Hind defined an algorithm for interprocedural constant propagation (extending the work of Wegman and Zadeck <ref> [WZ85] </ref>) that can handle non-distributive dataflow functions (and thus is more general than our algorithm) [CH95]. However, since they do not propagate values from called functions back to calling functions, their results are even less precise than our Naive Exhaustive algorithm. Wegman and Zadeck [WZ85], building on earlier work by Wegbreit <p> the work of Wegman and Zadeck <ref> [WZ85] </ref>) that can handle non-distributive dataflow functions (and thus is more general than our algorithm) [CH95]. However, since they do not propagate values from called functions back to calling functions, their results are even less precise than our Naive Exhaustive algorithm. Wegman and Zadeck [WZ85], building on earlier work by Wegbreit [Weg75], examined the interaction between constant propagation and dead-code elimination.
References-found: 32

