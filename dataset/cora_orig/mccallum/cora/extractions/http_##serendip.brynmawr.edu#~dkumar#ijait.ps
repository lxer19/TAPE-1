URL: http://serendip.brynmawr.edu/~dkumar/ijait.ps
Refering-URL: http://serendip.brynmawr.edu/~dkumar/
Root-URL: 
Email: dkumar@cc.brynmawr.edu shapiro@cs.buffalo.edu  
Phone: (610) 526-7485 (716) 645-3181  
Title: THE OK BDI ARCHITECTURE  
Author: Deepak Kumar Stuart C. Shapiro 
Keyword: BDI Architectures, Knowledge Representation and Reason ing, Acting, and Planning.  
Address: Bryn Mawr, PA 19010 Buffalo, NY 14260  
Affiliation: Department of Mathematics Department of Computer Science Bryn Mawr College State University of New York at Buffalo  
Abstract: The design of a belief-desire-intention (BDI) architecture is presented. The architecture is defined using a unified object-based knowledge representation formalism, called the OK formalism, and a unified reasoning and acting module, called the OK rational engine. Together they form the OK BDI architecture for modeling rational agents endowed with beliefs, desires, and intentions. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> James Allen. </author> <title> The RHET System. </title> <editor> In Charles Rich (Guest Editor), </editor> <title> editor, </title> <journal> SIGART BULLETIN Special Issue on Implemented KRR Systems, </journal> <pages> pages 1-7, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: Thus, most "good" planning/acting systems are "bad" knowledge representation and reasoning (KRR) systems and vice versa. For example, in a recent symposium on "Implemented KRR Systems" [24] out of a total of 22 KRR systems presented only four systems had capabilities for representation and reasoning about actions/plans (RHET <ref> [1] </ref>, CYC [17], fl From IJAIT, International Journal of Artificial Intelligence Tools, Volume 3 Number 3 (1994) 349-366, World Scientific Publishing CAKE [23] and SNePS [27]).
Reference: [2] <author> Michael E. Bratman, David J. Israel, and Martha E. Pollack. </author> <title> Plans and Resource-Bounded Practical Reasoning. </title> <journal> Computational Intelligence, </journal> <volume> 4(4), </volume> <year> 1988. </year>
Reference-contexts: There has been work describing formal BDI models [3, 21]. There are also architectures that have been proposed that address various issues relating to rational agency. For instance <ref> [2, 20] </ref> describe a high-level BDI architecture that specifically focuses on issues relating to resource bound-edness of rational agent behavior. Their work explores the hypothesis that plans, once committed, in addition to guiding the agent's actions, also constrain the agent's reasoning behavior.
Reference: [3] <author> P. R. Cohen and H. J. Levesque. </author> <title> Intention is choice with commitment. </title> <journal> Artificial Intelligence, </journal> <volume> 42(3), </volume> <year> 1990. </year>
Reference-contexts: There has been work describing formal BDI models <ref> [3, 21] </ref>. There are also architectures that have been proposed that address various issues relating to rational agency. For instance [2, 20] describe a high-level BDI architecture that specifically focuses on issues relating to resource bound-edness of rational agent behavior.
Reference: [4] <author> Mark E. Drummond. </author> <title> A representation of action and belief for automatic planning systems. </title> <editor> In Michael P. Georgeff and Amy L. Lansky, editors, </editor> <booktitle> Reasoning about Actions and Plans Proceedings of the 1986 Workshop, </booktitle> <pages> pages 189-212, </pages> <address> Los Altos, CA, 1987. </address> <publisher> AAAI and CSLI, Morgan Kauffmann. </publisher>
Reference-contexts: At the same time, it can facilitate easy incorporation of their ideas by virtue of the extendibility of the design. We have taken a unified approach to representations. Drummond expresses the need for a single unified formalism for representing beliefs, acts, and plans <ref> [4] </ref>. This facilitates a single reasoning module to be able to reason about beliefs, acts, and plans.
Reference: [5] <author> M. P. Georgeff, A. Lansky, and P. Bessiere. </author> <title> A procedural logic. </title> <booktitle> In Proceedings of the 9th IJCAI, </booktitle> <year> 1985. </year>
Reference-contexts: The architecture reported in [22] provides a very simplistic representation of beliefs (thus suffering from some of the concerns mentioned in Section 1) together with a transition network-like formalism for plans. It is a (limited, though successful) attempt towards bridging the their earlier work on PRS <ref> [5, 7] </ref> and their later work on formal foundations of rational agents [21]. The work presented here complements these models. It provides a general representational framework which these models lack. At the same time, it can facilitate easy incorporation of their ideas by virtue of the extendibility of the design.
Reference: [6] <author> Michael P. Georgeff. </author> <title> Planning. </title> <booktitle> In Annual Reviews of Computer Science Volume 2, </booktitle> <pages> pages 359-400. </pages> <publisher> Annual Reviews Inc., </publisher> <address> Palo Alto, CA, </address> <year> 1987. </year>
Reference-contexts: It employs an assumption-based truth maintenance (ATMS) system [18]. Thus, inferences, once drawn, are retained by the agent as long as their underlying support persists. The ATMS is also employed for implementing the extended STRIPS assumption for acting <ref> [6, 15] </ref>. Moreover, as will be evident in the section below, the rational engine is capable of modeling reactive as well as belief acquisition behavior (cases where inference can lead to acting). <p> Notice how, in the above example, a backward chaining query lead the agent to perform an action in order to answer the query. Thus, acting was performed in service of inference. 6 Related Work Our use of the term `BDI Architectures' comes from Georgeff <ref> [6] </ref>, that mentions the challenges of designing rational agents capable of goal-directed as well as reactive behavior based on the attitudes of beliefs, desires, and intentions.
Reference: [7] <author> Michael. P. Georgeff and Amy. Lansky. </author> <title> Procedural knowledge. </title> <type> Technical Note 411, </type> <institution> AI Center, SRI International, </institution> <year> 1987. </year>
Reference-contexts: The architecture reported in [22] provides a very simplistic representation of beliefs (thus suffering from some of the concerns mentioned in Section 1) together with a transition network-like formalism for plans. It is a (limited, though successful) attempt towards bridging the their earlier work on PRS <ref> [5, 7] </ref> and their later work on formal foundations of rational agents [21]. The work presented here complements these models. It provides a general representational framework which these models lack. At the same time, it can facilitate easy incorporation of their ideas by virtue of the extendibility of the design.
Reference: [8] <author> Deepak Kumar. </author> <title> An AI architecture based on message passing. </title> <editor> In James Geller, editor, </editor> <booktitle> Proceedings of The 1993 AAAI Spring Symposium on Innovative Applications of Massively Parallel Architectures, </booktitle> <pages> pages 127-131. </pages> <publisher> AAAI Press, </publisher> <month> March </month> <year> 1993. </year>
Reference-contexts: In this paper we use an object-oriented approach to describe the architecture. The resulting architecture is independent of, yet isomorphic to, the SNePS formalism. The resulting architecture enjoys all the advantages of object-oriented design|the ontology is easily extendible, as is the underlying logic, and amenable to a concurrent implementation <ref> [8, 12] </ref>. 2 Motivation Consider a modeled agent that has the set of beliefs acquired via an understanding of the following sentences about a blocksworld domain: Blocks are supports. Red colored blocks are wooden. Picking up is a primitive action. Putting is a primitive action.
Reference: [9] <author> Deepak Kumar. </author> <title> Rational engines for BDI architectures. </title> <editor> In Amy Lansky, editor, </editor> <booktitle> Proceedings of The 1993 AAAI Spring Symposium on Foundations of Automated Planning, </booktitle> <pages> pages 78-82. </pages> <publisher> AAAI Press, </publisher> <month> March </month> <year> 1993. </year>
Reference-contexts: The resulting unified acting and reasoning engine, which we are calling a rational engine, has to operate on beliefs as well as acts <ref> [9] </ref>.
Reference: [10] <author> Deepak Kumar. </author> <title> A unified model of acting and inference. </title> <booktitle> In Proceedings of the Twenty-Sixth Hawaii International Conference on System Sciences. </booktitle> <publisher> IEEE Computer Society Press, Los Alamitos, </publisher> <address> CA, </address> <year> 1993. </year>
Reference-contexts: In this paper, we describe the architecture that results when one makes the above set of commitments. The work presented here has evolved from research involved in extending a semantic network-based KRR system, SNePS (whose rational engine called SNeRE is described in <ref> [11, 10, 12, 13] </ref>), into a BDI architecture. In this paper we use an object-oriented approach to describe the architecture. The resulting architecture is independent of, yet isomorphic to, the SNePS formalism. <p> Search during reasoning/acting/plan decomposition is focused by means of some KR principles, the Uniqueness Principle being one (there is a one-to-one correspondence between instances and intensional entities) <ref> [10] </ref>. The Uniqueness Principle helps focus the chaining (method/message propagation) through a restricted set of entities. The object-oriented approach provides a promising approach to building BDI architectures.
Reference: [11] <author> Deepak Kumar. </author> <title> From Beliefs and Goals to Intentions and Actions| An Amalgamated Model of Acting and Inference. </title> <type> PhD thesis, </type> <institution> State University of New York at Buffalo, </institution> <year> 1994. </year>
Reference-contexts: In this paper, we describe the architecture that results when one makes the above set of commitments. The work presented here has evolved from research involved in extending a semantic network-based KRR system, SNePS (whose rational engine called SNeRE is described in <ref> [11, 10, 12, 13] </ref>), into a BDI architecture. In this paper we use an object-oriented approach to describe the architecture. The resulting architecture is independent of, yet isomorphic to, the SNePS formalism. <p> Any conceptual entity represented in the system can be the object of a belief, plan, or act. By the same token, it can be reasoned about (or acted upon, as the case may be) and discussed by the agent representing it. The SNePS Rational Engine, called SNeRE <ref> [11, 12] </ref>, is an integrated reasoning and acting module that uses a logic called SWM [18]. It is the module responsible for the agent's reasoning processes. It is also the module responsible for the agent's acting and planning behavior. It employs an assumption-based truth maintenance (ATMS) system [18]. <p> Our repertoire of control acts includes acts for sequencing (linear plans), conditional acts, iterative acts, nondeterministic choice and ordering acts, and qualifier acts |acts whose objects are only described and not yet fully identified (as in requests 6 and 7 in Section 2) (see <ref> [11, 12] </ref>). In addition to standard beliefs that an agent is able to represent, we also define a special class of beliefs called transformers. A transformer is a propositional representation that subsumes various notions of inference and acting. <p> Other quantifiers include the existential, and the numerical quantifiers (see <ref> [26, 11] </ref>). Belief-Act Transformers: These are transformers where hffi is a set of belief (s) and hfii is a set of acts. Used during backward chaining, these can be propositions specifying preconditions of actions, i.e. hffi is a precondition of some act hfii. <p> For example, the same object (say, a belief proposition) can be displayed as a frame, a predicate, a semantic network, or some other communicational entity (ala KIF) (see <ref> [11] </ref>). The next section presents how the example of Section 2 can be solved by such an architecture. 5 Example In order for the failed inference of Section 2 to succeed, the agent only needs to have the following set of beliefs: Looking is a primitive action.
Reference: [12] <author> Deepak Kumar. </author> <title> The SNePS BDI architecture. </title> <journal> Journal of Decision Support Systems|Special Issue on Logic Modeling, </journal> <year> 1994. </year> <month> Forthcoming. </month>
Reference-contexts: In this paper, we describe the architecture that results when one makes the above set of commitments. The work presented here has evolved from research involved in extending a semantic network-based KRR system, SNePS (whose rational engine called SNeRE is described in <ref> [11, 10, 12, 13] </ref>), into a BDI architecture. In this paper we use an object-oriented approach to describe the architecture. The resulting architecture is independent of, yet isomorphic to, the SNePS formalism. <p> In this paper we use an object-oriented approach to describe the architecture. The resulting architecture is independent of, yet isomorphic to, the SNePS formalism. The resulting architecture enjoys all the advantages of object-oriented design|the ontology is easily extendible, as is the underlying logic, and amenable to a concurrent implementation <ref> [8, 12] </ref>. 2 Motivation Consider a modeled agent that has the set of beliefs acquired via an understanding of the following sentences about a blocksworld domain: Blocks are supports. Red colored blocks are wooden. Picking up is a primitive action. Putting is a primitive action. <p> Any conceptual entity represented in the system can be the object of a belief, plan, or act. By the same token, it can be reasoned about (or acted upon, as the case may be) and discussed by the agent representing it. The SNePS Rational Engine, called SNeRE <ref> [11, 12] </ref>, is an integrated reasoning and acting module that uses a logic called SWM [18]. It is the module responsible for the agent's reasoning processes. It is also the module responsible for the agent's acting and planning behavior. It employs an assumption-based truth maintenance (ATMS) system [18]. <p> Our repertoire of control acts includes acts for sequencing (linear plans), conditional acts, iterative acts, nondeterministic choice and ordering acts, and qualifier acts |acts whose objects are only described and not yet fully identified (as in requests 6 and 7 in Section 2) (see <ref> [11, 12] </ref>). In addition to standard beliefs that an agent is able to represent, we also define a special class of beliefs called transformers. A transformer is a propositional representation that subsumes various notions of inference and acting.
Reference: [13] <author> Deepak Kumar, Susan Haller, and Syed S. Ali. </author> <title> Towards a Unified AI Formalism. </title> <booktitle> In Proceedings of the Twenty-Seventh Hawaii International Conference on System Sciences. </booktitle> <publisher> IEEE Computer Society Press, Los Alamitos, </publisher> <address> CA, </address> <year> 1994. </year>
Reference-contexts: In this paper, we describe the architecture that results when one makes the above set of commitments. The work presented here has evolved from research involved in extending a semantic network-based KRR system, SNePS (whose rational engine called SNeRE is described in <ref> [11, 10, 12, 13] </ref>), into a BDI architecture. In this paper we use an object-oriented approach to describe the architecture. The resulting architecture is independent of, yet isomorphic to, the SNePS formalism.
Reference: [14] <author> Deepak Kumar and Stuart C. Shapiro. </author> <title> Architecture of an intelligent agent in SNePS. </title> <journal> SIGART Bulletin, </journal> <volume> 2(4) </volume> <pages> 89-92, </pages> <month> August </month> <year> 1991. </year>
Reference-contexts: piling involves creating a pile of two blocks on a table), piling is a complex act and the plan that decomposes it is expressed in the proposition PlanAct (SEQUENCE (PUT (B; TABLE); PUT (A; B)); PILE (A; B)) Our present model of acting is based upon a state-change model (see <ref> [14] </ref>). We identify three types of states|external world states, mental states (belief space), and intentional states (agent's current intentions). Accordingly, we identify three classes of actions|physical actions, mental actions, and control actions that bring about changes in their respective states.
Reference: [15] <author> Deepak Kumar and Stuart C. Shapiro. </author> <title> Deductive efficiency, belief revision and acting. </title> <journal> Journal of Experimental and Theoretical Artificial Intelligence (JETAI), </journal> <volume> 5(2), </volume> <year> 1993. </year>
Reference-contexts: It employs an assumption-based truth maintenance (ATMS) system [18]. Thus, inferences, once drawn, are retained by the agent as long as their underlying support persists. The ATMS is also employed for implementing the extended STRIPS assumption for acting <ref> [6, 15] </ref>. Moreover, as will be evident in the section below, the rational engine is capable of modeling reactive as well as belief acquisition behavior (cases where inference can lead to acting). <p> The effectory procedures for BELIEVE and DISBELIEVE are implemented as belief revision procedures. We have found that such an integrated TMS facility simplifies several action and plan representations (see <ref> [15] </ref> for details). The Intend method is used to specify the fulfillment of agent's intentions by performing acts. All these methods can be specified (and specialized) for the hierarchy as well as inherited. <p> In our formalism, act representations are different from standard operator-based representations of classical planning/acting systems. Elsewhere <ref> [15] </ref>, we have also shown how even simple act representations can benefit from an integrated TMS. In the presence of a TMS even the simplest acting model (that of adding and deleting the act's effects) implements the extended STRIPS assumption. As a result, ours is a deductive approach to acting.
Reference: [16] <author> Deepak Kumar and Stuart C. Shapiro. </author> <title> Acting in Service of Inference (and vice versa). </title> <editor> In Douglas D. Dankel II, editor, </editor> <booktitle> Proceedings of The Seventh Florida AI Research Symposium (FLAIRS 93). The Florida AI Research Society, </booktitle> <month> May </month> <year> 1994. </year>
Reference-contexts: We have taken this approach a step further by explicitly identifying the semantic relationship between inference and acting so that a single module, a rational engine, in addition to reasoning, is also responsible for carrying out physical acts and plans (see <ref> [16] </ref> for examples). In our formalism, act representations are different from standard operator-based representations of classical planning/acting systems. Elsewhere [15], we have also shown how even simple act representations can benefit from an integrated TMS.
Reference: [17] <author> Douglas B. Lenat and Ramanathan V. Guha. </author> <title> The Evolution of CYCL, The CYC Representation Language. </title> <editor> In Charles Rich (Guest Editor), </editor> <title> editor, </title> <journal> SIGART BULLETIN Special Issue on Implemented KRR Systems, </journal> <pages> pages 84-87, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: For example, in a recent symposium on "Implemented KRR Systems" [24] out of a total of 22 KRR systems presented only four systems had capabilities for representation and reasoning about actions/plans (RHET [1], CYC <ref> [17] </ref>, fl From IJAIT, International Journal of Artificial Intelligence Tools, Volume 3 Number 3 (1994) 349-366, World Scientific Publishing CAKE [23] and SNePS [27]).
Reference: [18] <author> J. P. Martins and S. C. Shapiro. </author> <title> A model for belief revision. </title> <journal> Artificial Intelligence, </journal> <volume> 35(1) </volume> <pages> 25-79, </pages> <year> 1988. </year>
Reference-contexts: By the same token, it can be reasoned about (or acted upon, as the case may be) and discussed by the agent representing it. The SNePS Rational Engine, called SNeRE [11, 12], is an integrated reasoning and acting module that uses a logic called SWM <ref> [18] </ref>. It is the module responsible for the agent's reasoning processes. It is also the module responsible for the agent's acting and planning behavior. It employs an assumption-based truth maintenance (ATMS) system [18]. Thus, inferences, once drawn, are retained by the agent as long as their underlying support persists. <p> Engine, called SNeRE [11, 12], is an integrated reasoning and acting module that uses a logic called SWM <ref> [18] </ref>. It is the module responsible for the agent's reasoning processes. It is also the module responsible for the agent's acting and planning behavior. It employs an assumption-based truth maintenance (ATMS) system [18]. Thus, inferences, once drawn, are retained by the agent as long as their underlying support persists. The ATMS is also employed for implementing the extended STRIPS assumption for acting [6, 15].
Reference: [19] <author> John McCarthy. </author> <title> Mental situation calculus. </title> <editor> In Joseph Y. Halpern, editor, </editor> <booktitle> Theoretical Aspects of Reasoning about Knowledge|Proceedings of the 1986 Conference, </booktitle> <pages> page 307, </pages> <year> 1986. </year>
Reference-contexts: During backward chaining, the mental acting executive forms the intention of believing the consequents of a rule if its antecedents are satisfied (i.e., preconditions are fulfilled). Similarly for forward chaining. McCarthy has also suggested that inference can be treated as a mental action <ref> [19] </ref>. Alternatively, plans can be viewed as rules for acting. Reasoning rules pass a truth or a belief status from antecedent to consequent, whereas acting rules pass an intention status from earlier acts to later acts.
Reference: [20] <author> Martha E. Pollack. </author> <title> Overloading Intentions for Efficient Practical Reasoning. </title> <address> No^us, XXV(4):513-536, </address> <month> September </month> <year> 1991. </year>
Reference-contexts: There has been work describing formal BDI models [3, 21]. There are also architectures that have been proposed that address various issues relating to rational agency. For instance <ref> [2, 20] </ref> describe a high-level BDI architecture that specifically focuses on issues relating to resource bound-edness of rational agent behavior. Their work explores the hypothesis that plans, once committed, in addition to guiding the agent's actions, also constrain the agent's reasoning behavior.
Reference: [21] <author> Anand S. Rao and Michael P. Georgeff. </author> <title> Modeling Rational Agents within a BDI-Architecture. </title> <booktitle> In Principles of Knowledge Representation and Reasoning| Proceedings of the Second International Conference (KR91), </booktitle> <pages> pages 473-485. </pages> <booktitle> AAAI, IJCAI, CSCSI, </booktitle> <month> April </month> <year> 1991. </year>
Reference-contexts: There has been work describing formal BDI models <ref> [3, 21] </ref>. There are also architectures that have been proposed that address various issues relating to rational agency. For instance [2, 20] describe a high-level BDI architecture that specifically focuses on issues relating to resource bound-edness of rational agent behavior. <p> For instance [2, 20] describe a high-level BDI architecture that specifically focuses on issues relating to resource bound-edness of rational agent behavior. Their work explores the hypothesis that plans, once committed, in addition to guiding the agent's actions, also constrain the agent's reasoning behavior. Rao and Georgeff <ref> [21, 22] </ref> have also studied formally the nature of intention and commitment in the context of rational agent behavior. The architecture reported in [22] provides a very simplistic representation of beliefs (thus suffering from some of the concerns mentioned in Section 1) together with a transition network-like formalism for plans. <p> It is a (limited, though successful) attempt towards bridging the their earlier work on PRS [5, 7] and their later work on formal foundations of rational agents <ref> [21] </ref>. The work presented here complements these models. It provides a general representational framework which these models lack. At the same time, it can facilitate easy incorporation of their ideas by virtue of the extendibility of the design. We have taken a unified approach to representations.
Reference: [22] <author> Anand S. Rao and Michael P. Georgeff. </author> <title> An Abstract Architecture for Rational Agents. </title> <editor> In Bernhard Nebel, Charles Rich, and William Swartout, editors, </editor> <booktitle> Proceedings of the 2nd Conference on Principles of Knowledge Representation and Reasoning, </booktitle> <pages> pages 439-449, </pages> <address> San Mateo, CA, 1992. </address> <publisher> Morgan Kaufmann Publishers. </publisher>
Reference-contexts: For instance [2, 20] describe a high-level BDI architecture that specifically focuses on issues relating to resource bound-edness of rational agent behavior. Their work explores the hypothesis that plans, once committed, in addition to guiding the agent's actions, also constrain the agent's reasoning behavior. Rao and Georgeff <ref> [21, 22] </ref> have also studied formally the nature of intention and commitment in the context of rational agent behavior. The architecture reported in [22] provides a very simplistic representation of beliefs (thus suffering from some of the concerns mentioned in Section 1) together with a transition network-like formalism for plans. <p> Their work explores the hypothesis that plans, once committed, in addition to guiding the agent's actions, also constrain the agent's reasoning behavior. Rao and Georgeff [21, 22] have also studied formally the nature of intention and commitment in the context of rational agent behavior. The architecture reported in <ref> [22] </ref> provides a very simplistic representation of beliefs (thus suffering from some of the concerns mentioned in Section 1) together with a transition network-like formalism for plans.
Reference: [23] <author> Charles Rich. CAKE: </author> <title> An Implemented Hybrid KR and Limited Reasoning System. </title> <editor> In Charles Rich (Guest Editor), </editor> <title> editor, </title> <journal> SIGART BULLETIN Special Issue on Implemented KRR Systems, </journal> <pages> pages 120-127, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: recent symposium on "Implemented KRR Systems" [24] out of a total of 22 KRR systems presented only four systems had capabilities for representation and reasoning about actions/plans (RHET [1], CYC [17], fl From IJAIT, International Journal of Artificial Intelligence Tools, Volume 3 Number 3 (1994) 349-366, World Scientific Publishing CAKE <ref> [23] </ref> and SNePS [27]). The work presented in this paper presents an approach that bridges this "representational/behavioral gap." In traditional planning/acting systems the inference engine is employed in service of planning and acting. In other words, it is the planning and acting processes that invoke the modeled thought (reasoning) processes.
Reference: [24] <author> Charles Rich. </author> <title> Special Issue on Implemented Knowledge Representa--tion and Reasoning Systems|Letter from the Guest Editor. </title> <journal> SIGART Bulletin, </journal> <volume> 2(3), </volume> <month> June </month> <year> 1991. </year>
Reference-contexts: Thus, most "good" planning/acting systems are "bad" knowledge representation and reasoning (KRR) systems and vice versa. For example, in a recent symposium on "Implemented KRR Systems" <ref> [24] </ref> out of a total of 22 KRR systems presented only four systems had capabilities for representation and reasoning about actions/plans (RHET [1], CYC [17], fl From IJAIT, International Journal of Artificial Intelligence Tools, Volume 3 Number 3 (1994) 349-366, World Scientific Publishing CAKE [23] and SNePS [27]).
Reference: [25] <author> Earl D. Sacerdoti. </author> <title> A Structure for Plans and Behavior. </title> <publisher> Elsevier North Holland, </publisher> <address> New York, NY, </address> <year> 1977. </year>
Reference-contexts: Control acts, when performed, change the agent's intentions about carrying out acts. Our repertoire of control actions includes sequencing (for representing linear plans), conditional, iterative, disjunctive (equivalent to the OR-splits of the Procedural Net formalism <ref> [25, 29] </ref>), conjunctive (AND-splits), selective, and achieve acts (for goal-based plan invocation). Sequencing Act: SEQUENCE (a 1 ; a 2 ) The acts a 1 and a 2 are performed in sequence.
Reference: [26] <author> S. C. </author> <title> Shapiro and The SNePS Implementation Group. SNePS-2 User's Manual. </title> <institution> Department of Computer Science, SUNY at Buffalo, </institution> <year> 1989. </year>
Reference-contexts: Other quantifiers include the existential, and the numerical quantifiers (see <ref> [26, 11] </ref>). Belief-Act Transformers: These are transformers where hffi is a set of belief (s) and hfii is a set of acts. Used during backward chaining, these can be propositions specifying preconditions of actions, i.e. hffi is a precondition of some act hfii.
Reference: [27] <author> Stuart C. Shapiro. </author> <title> Case studies of SNePS. </title> <journal> SIGART Bulletin, </journal> <volume> 2(3) </volume> <pages> 128-134, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: "Implemented KRR Systems" [24] out of a total of 22 KRR systems presented only four systems had capabilities for representation and reasoning about actions/plans (RHET [1], CYC [17], fl From IJAIT, International Journal of Artificial Intelligence Tools, Volume 3 Number 3 (1994) 349-366, World Scientific Publishing CAKE [23] and SNePS <ref> [27] </ref>). The work presented in this paper presents an approach that bridges this "representational/behavioral gap." In traditional planning/acting systems the inference engine is employed in service of planning and acting. In other words, it is the planning and acting processes that invoke the modeled thought (reasoning) processes.
Reference: [28] <author> Stuart C. Shapiro and William J. Rapaport. </author> <title> SNePS considered as a fully intensional propositional semantic network. </title> <editor> In Leslie Burkholder, editor, </editor> <booktitle> Philosophy and the Computer, </booktitle> <pages> pages 75-91. </pages> <publisher> Westview Press, </publisher> <address> Boulder, CO, </address> <year> 1992. </year>
Reference-contexts: The SNePS BDI architecture has the following components: SNePS BDI Architecture = SNePS Formalism + SNePS Rational Engine The modeled agent's beliefs, plans, acts, and rules are represented in the SNePS semantic network formalism <ref> [28] </ref>. SNePS is an intentional, propositional semantic network system. Nodes in the semantic network represent conceptual entities|individuals, and structured individuals. Structured individuals can be propositions, which are used to represent beliefs, or acts and plans.
Reference: [29] <author> David E. Wilkins. </author> <title> Practical Planning-Extending the Classical AI Planning Paradigm. </title> <publisher> Morgan Kaufmann, </publisher> <address> Palo Alto, CA, </address> <year> 1988. </year>
Reference-contexts: Control acts, when performed, change the agent's intentions about carrying out acts. Our repertoire of control actions includes sequencing (for representing linear plans), conditional, iterative, disjunctive (equivalent to the OR-splits of the Procedural Net formalism <ref> [25, 29] </ref>), conjunctive (AND-splits), selective, and achieve acts (for goal-based plan invocation). Sequencing Act: SEQUENCE (a 1 ; a 2 ) The acts a 1 and a 2 are performed in sequence.
References-found: 29

