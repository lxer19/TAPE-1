URL: ftp://cl-ftp.dfki.uni-sb.de/pub/papers/local/RR-94-39.ps.Z
Refering-URL: http://cl-www.dfki.uni-sb.de/cl/papers/cl-abstracts.html
Root-URL: 
Phone: Tel.: 49 (631) 205-3211 Stuhlsatzenhausweg 3  Tel.: 49 (681) 302-5252  
Title: Typed Feature Formalisms as a Common Basis for Linguistic Specification  
Author: Hans-Ulrich Krieger f ur K unstliche Intelligenz 
Address: Postfach 20 80 67608 Kaiserslautern, FRG  66123 Saarbrucken, FRG  
Affiliation: GmbH  
Note: Deutsches Forschungszentrum  
Date: November 1994  
Abstract: Deutsches Forschungszentrum f ur K unstliche Intelligenz GmbH Research Report RR-94-39 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Hassan At-Kaci and Roger Nasr. </author> <title> LOGIN: A logic programming language with built-in inheritance. </title> <journal> Journal of Logic Programming, </journal> <volume> 3 </volume> <pages> 185-215, </pages> <year> 1986. </year>
Reference-contexts: But if this is the case, our treatment has nearly the same complexity as in theory: there exist well-known quasi-linear unification algorithms for conjunctive formulae, for instance At-Kaci's unification algorithm employed in LOGIN <ref> [1] </ref>, which is an extension of Huet's method 7 for fixed-arity, first-order terms.
Reference: 2. <author> Hiyan Alshawi, </author> <title> editor. The Core Language Engine. ACL-MIT Press Series in Natural Language Processing. </title> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: semantic content of an utterance as a feature structure, they do not use a parser (or generator) or a uniform deduction component to simplify logical form or to draw domain-specific inferences within the calculus of HPSG in order to derive legal, simpler expressions represented as a feature structure again (cf. <ref> [2] </ref> to get an impression of simplifying/resolving (quasi) logical form within the core language engine of SRI).
Reference: 3. <author> Steven Bird. </author> <title> Finite-state phonology in HPSG. </title> <booktitle> In Proceedings of the 14th International Conference on Computational Linguistics, COLING-92, </booktitle> <pages> pages 74-80, </pages> <year> 1992. </year>
Reference-contexts: They have been employed in the description of morphophonemics <ref> [11, 3] </ref> and in the formulation of word order constraints [26]; moreover, the use of FA allows for the integration of allomorphy and mor-photactics [15, 12].
Reference: 4. <author> Bob Carpenter. </author> <title> The Logic of Typed Feature Structures. </title> <booktitle> Tracts in Theoretical Computer Science. </booktitle> <publisher> Cambridge University Press, </publisher> <address> Cambridge, </address> <year> 1992. </year> <month> 19 </month>
Reference-contexts: Speaking in Carpenter's terms <ref> [4] </ref>, we thus require that q 0 ^ [INPUT w] 5 be totally well-typable, i.e., that there is at least one model that satisfies the input description. 4 The processing of FA within TFF is thus achieved by type expansion of possibly recursive feature types.
Reference: 5. <author> Jochen Dorre and Andreas Eisele. </author> <title> Determining consistency of feature terms with distributed disjunctions. </title> <editor> In Dieter Metzing, editor, </editor> <booktitle> Proceedings of 13th German Workshop on Artificial Intelligence, GWAI-89, </booktitle> <pages> pages 270-279, </pages> <address> Berlin, 1989. </address> <publisher> Springer. </publisher>
Reference-contexts: Note that we make use of distributed disjunctions <ref> [5] </ref> (depicted by the disjunction name $1) in the definition of X to express the covariation between edges and successor states: if a is processed, use type X (and vice versa), if b is processed, use again type X , but if c is chosen, choose type Y .
Reference: 6. <author> John E. Hopcroft and Jeffrey D. Ullman. </author> <title> Introduction to Automata Theory, Languages, and Computation. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1979. </year>
Reference-contexts: These questions and, of course, their solutions will be addressed in this section. 2.1 Preliminaries Assuming a familiarity with the basic inventory of automata theory and formal languages <ref> [6] </ref>, we shall, in the following, formally refer to a deterministic finite automaton (DFA) by a 5-tuple hQ; ; ffi; q 0 ; F i, where Q is a finite set of states, a finite input alphabet , ffi : Qfi 7! Q is the transition function, q 0 2 Q <p> While A 1 A 2 would usually be constructed by introducing an *-move between A 1 and A 2 <ref> [6, p. 31] </ref>, we account for concatenation by connecting every final state f i 2 F 1 with the start state q 0 0 of A 2 ; thus, we have to write (_ i f i ) ^ q 0 0 .
Reference: 7. <author> Mark Johnson. </author> <title> Attribute Value Logic and the Theory of Grammar. CSLI Lecture Notes, Number 16. Center for the Study of Language and Information, </title> <publisher> Stanford, </publisher> <year> 1988. </year>
Reference-contexts: w.r.t. the set of recognized words: given an arbitrary NFA, we can always construct a deterministic one which recognizes the same language (however, in the worst case with exponentially more states). 1 In the following, we will assume a basic familiarity with unification-based grammar theories [23, 25] and their logics <ref> [9, 7, 24] </ref>. 3 Fortunately, our approach is also capable of directly representing and process-ing non-deterministic FA with *-moves, and allows for edges which are multiple-symbol consumers (see next section). It is worth noting that edges may not only be annotated with atomic symbols.
Reference: 8. <author> Ronald M. Kaplan and John T. Maxwell III. </author> <title> An algorithm for functional uncertainty. </title> <booktitle> In Proceedings of the 12th International Conference on Computational Linguistics, COLING-88, </booktitle> <pages> pages 297-302, </pages> <year> 1988. </year>
Reference-contexts: It turns out that the feature logic on which our approach is based together with a weak form of functional uncertainty <ref> [8] </ref> allows for a characterization of these operations [14]. Let A 1 = hQ 1 ; 1 ; ffi 1 ; q 0 ; F 1 i and A 2 = hQ 2 ; 2 ; ffi 2 ; q 0 0 ; F 2 i be two arbitrary FA. <p> There exists a mechanism used primarily in the LFG community which fulfills exactly our needs: functional uncertainty <ref> [8] </ref> (note that Section 2.4 also makes use of this device). Functional uncertainty is a mechanism for dealing elegantly with linguistic phenomena like long distance dependencies or constituent coordination. With functional uncertainty, we can characterize a nested doubly negated formula at an arbitrary depth by the antecedent of (30).
Reference: 9. <author> Robert T. Kasper and William C. </author> <title> Rounds. A logical semantics for feature structures. </title> <booktitle> In Proceedings of the 24th Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pages 257-266, </pages> <year> 1986. </year>
Reference-contexts: w.r.t. the set of recognized words: given an arbitrary NFA, we can always construct a deterministic one which recognizes the same language (however, in the worst case with exponentially more states). 1 In the following, we will assume a basic familiarity with unification-based grammar theories [23, 25] and their logics <ref> [9, 7, 24] </ref>. 3 Fortunately, our approach is also capable of directly representing and process-ing non-deterministic FA with *-moves, and allows for edges which are multiple-symbol consumers (see next section). It is worth noting that edges may not only be annotated with atomic symbols. <p> Because we employ disjunctions to describe the covariation between edges and successor states, one might assume that the complexity of our treatment is already exponential for the DFA case as a result of the fact that the satisfiability problem for disjunctive formulae is NP-complete <ref> [9] </ref>, thus a unification algorithm will have a non-polynomial complexity, assuming that P 6= NP. Recall that we are using unification as a means for testing equality.
Reference: 10. <author> Martin Kay, Jean Mark Gawron, and Peter Norvig. </author> <title> Verbmobil: A Translation System for Face-to-Face Dialog. CSLI Lecture Notes, Number 33. Center for the Study of Language and Information, </title> <publisher> Stanford, </publisher> <year> 1994. </year>
Reference-contexts: In this regard, it is better to construct the composite automaton first by hand| which is fairly straightforward|and then apply the encoding mechanism for non-complex FA. 10 3 Logical Form Simplification Within HPSG Typed feature formalisms in general, and HPSG in particular, serve as a basis for many NLP/MT systems <ref> [27, 28, 10] </ref>.
Reference: 11. <author> Kimmo Koskenniemi. </author> <title> Two-level model for morphological analysis. </title> <booktitle> In Proceedings of the 8th International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 683-685, </pages> <year> 1983. </year>
Reference-contexts: They have been employed in the description of morphophonemics <ref> [11, 3] </ref> and in the formulation of word order constraints [26]; moreover, the use of FA allows for the integration of allomorphy and mor-photactics [15, 12].
Reference: 12. <author> Hans-Ulrich Krieger. </author> <title> Derivation without lexical rules. </title> <editor> In C.J. Rupp, M.A. Ros-ner, and R.L. Johnson, editors, </editor> <booktitle> Constraints, Language and Computation, </booktitle> <pages> pages 277-313. </pages> <publisher> Academic Press, </publisher> <year> 1994. </year> <note> A version of this paper is available as DFKI Research Report RR-93-27. Also published in IDSIA Working Paper No. 5, Lugano, </note> <month> November </month> <year> 1991. </year>
Reference-contexts: They have been employed in the description of morphophonemics [11, 3] and in the formulation of word order constraints [26]; moreover, the use of FA allows for the integration of allomorphy and mor-photactics <ref> [15, 12] </ref>. While it is unsurprising that the languages accepted by FA may also be encoded as typed feature descriptions, it is not clear how FA themselves can be specified as feature structures, how they can be processed, and, furthermore, what closure properties they have within TFF.
Reference: 13. <author> Hans-Ulrich Krieger. </author> <title> Logical form simplification within HPSG. </title> <type> Technical report, </type> <institution> Deutsches Forschungszentrum fur Kunstliche Intelligenz, Saarbrucken, Germany, </institution> <year> 1995. </year> <month> Forthcoming. </month>
Reference-contexts: This can be achieved either by adding new principles for each case or, more generally, by making the improved version of (2Neg) sensitive to these special situations (cf. <ref> [13] </ref> for more details). Our last extension concerns the introduction of set values.
Reference: 14. <author> Hans-Ulrich Krieger. </author> <title> Representing and processing finite automata within typed feature formalisms. </title> <type> Technical report, </type> <institution> Deutsches Forschungszentrum fur Kunstliche Intelligenz, Saarbrucken, Germany, </institution> <year> 1995. </year> <month> Forthcoming. </month>
Reference-contexts: Multiple-symbol 4 Type expansion here is analogous to a top-down parsing method in syntactic analysis, viz., recursive descent parsing. Note that the satisfiability problem for recursive type descriptions is in general undecidable, although this is not the case for our encoding <ref> [14] </ref>. 5 From a processing standpoint, of course, a DFA differs from a NFA in our approach. <p> This problem is inherent and well-known but is no restriction w.r.t. expressivity (see <ref> [14] </ref> for more details and related aspects). 9 2.4 Concatenation and Kleene Closure Let us now focus on the concatenation and Kleene closure of regular expressions/FA. <p> It turns out that the feature logic on which our approach is based together with a weak form of functional uncertainty [8] allows for a characterization of these operations <ref> [14] </ref>. Let A 1 = hQ 1 ; 1 ; ffi 1 ; q 0 ; F 1 i and A 2 = hQ 2 ; 2 ; ffi 2 ; q 0 0 ; F 2 i be two arbitrary FA.
Reference: 15. <author> Hans-Ulrich Krieger and John Nerbonne. </author> <title> Feature-based inheritance networks for computational lexicons. </title> <editor> In Ted Briscoe, Valeria de Paiva, and Ann Copestake, editors, </editor> <title> Inheritance, Defaults, </title> <booktitle> and the Lexicon, </booktitle> <pages> pages 90-136. </pages> <publisher> Cambridge University Press, </publisher> <address> New York, </address> <year> 1993. </year> <note> A version of this paper is available as DFKI Research Report RR-91-31. Also published in Proceedings of the ACQUILEX Workshop on Default Inheritance in the Lexicon, Technical Report No. 238, </note> <institution> University of Cambridge, Computer Laboratory, </institution> <month> October </month> <year> 1991. </year>
Reference-contexts: They have been employed in the description of morphophonemics [11, 3] and in the formulation of word order constraints [26]; moreover, the use of FA allows for the integration of allomorphy and mor-photactics <ref> [15, 12] </ref>. While it is unsurprising that the languages accepted by FA may also be encoded as typed feature descriptions, it is not clear how FA themselves can be specified as feature structures, how they can be processed, and, furthermore, what closure properties they have within TFF.
Reference: 16. <author> Hans-Ulrich Krieger, John Nerbonne, and Hannes Pirker. </author> <title> Feature-based allomor-phy. </title> <booktitle> In Proceedings of the 31st Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pages 140-147, </pages> <year> 1993. </year> <note> A version of this paper is available as DFKI Research Report RR-93-28. </note>
Reference-contexts: It is worth noting that edges may not only be annotated with atomic symbols. They can also be labelled with complex ones, i.e., with possibly underspecified feature structures, where unification is a means for testing equality (for instance, in case of 2-level morphological descriptions; see <ref> [16] </ref> for an example of a paradigm-based inflectional morphology). 2.2 Encoding Finite Automata Within Typed Feature Formalisms To specify an automaton as a typed feature structure, we introduce for every state q 2 Q a possibly recursive feature type with the same name as q. <p> The encoding method assumes that the logic makes recursive type definitions available. Some examples of German inflectional morphology <ref> [16] </ref> have been implemented in the typed feature formalism T DL [17]. The second area addressed in this paper concerns a proposal for logical form simplification within TFF/HPSG. The approach makes strong assumptions about the expressivity of the feature calculus (set values, functional uncertainty/recursive types and monotonic substitution).
Reference: 17. <author> Hans-Ulrich Krieger and Ulrich Schafer. </author> <title> TDL|a type description language for constraint-based grammars. </title> <booktitle> In Proceedings of the 15th International Conference on Computational Linguistics, COLING-94, </booktitle> <address> Kyoto, Japan, </address> <pages> pages 893-899, </pages> <year> 1994. </year> <note> An extended version of this paper is available as DFKI Research Report RR-94-37. </note>
Reference-contexts: (b _ c _ undef ) NEXT $1 (V _ V _ undef ) 3 (11) The intersection of A 1 and A 2 then corresponds to the unification of X and U , which leads to the following structure (assuming that our logic is based on an open-world semantics <ref> [17] </ref>): 2 X EDGE $1 (a _ b _ c) NEXT $1 (X _ X _ Y ) 3 2 U EDGE a NEXT V 3 2 X ^ U EDGE a NEXT X ^ V 3 8 Testing whether a given string w belongs to L (A 1 ) " <p> The encoding method assumes that the logic makes recursive type definitions available. Some examples of German inflectional morphology [16] have been implemented in the typed feature formalism T DL <ref> [17] </ref>. The second area addressed in this paper concerns a proposal for logical form simplification within TFF/HPSG. The approach makes strong assumptions about the expressivity of the feature calculus (set values, functional uncertainty/recursive types and monotonic substitution).
Reference: 18. <author> Joachim Laubsch and John Nerbonne. </author> <title> An overview of NLL. </title> <type> Technical report, </type> <institution> Hewlett-Packard, </institution> <year> 1991. </year> <month> 20 </month>
Reference-contexts: Instead, all systems either translate the semantic representation directly into an application language (e.g., a database language), which means that semantic inferences are not seen as essential in the front-end, or transform feature structures into a term of a semantic representation logic (for instance the language NLL <ref> [18] </ref>), on which a deduction component operates to yield another, denotation-preserving expression.
Reference: 19. <author> John Nerbonne. </author> <title> A feature-based syntax/semantics interface. </title> <editor> In Alexis Manaster--Ramer and Wlodek Zadrozny, editors, </editor> <booktitle> Mathematics of Language, </booktitle> <volume> Vol. 2. </volume> <booktitle> Annals of Artificial Intelligence and Mathematics, </booktitle> <year> 1992. </year> <note> Also available as DFKI Research Report RR-92-42. </note>
Reference-contexts: of an operator like a semantic not :. 6 There's a notable exception to what we said about the lack of semantic inferences in HPSG: most of the effects of fi-reduction, used by many semanticists growing out of the Montagovian tradition, can be easily captured by unification (see for instance <ref> [19] </ref>). In this section, we intend to present the necessary inventory for logical form simplification within HPSG. <p> We, therefore, suggest to replace the keyword approach ARGn by a set-valued treatment as shown in (34). Moreover, this has the advantage of allowing more than two arguments for connectives like ^ or _ (see <ref> [19] </ref> for a similar proposal).
Reference: 20. <author> Carl Pollard and Ivan A. Sag. </author> <title> Information-Based Syntax and Semantics. Vol. I: Fundamentals. CSLI Lecture Notes, Number 13. Center for the Study of Language and Information, </title> <publisher> Stanford, </publisher> <year> 1987. </year>
Reference-contexts: 1 Introduction Pollard&Sag's seminal work on Head-Driven Phrase Structure Grammar has shown that a great deal of syntax and semantics can be neatly encoded within typed feature structures, thus leading for the first time to a highly lexicalized theory of language <ref> [20, 21] </ref>. Moreover, the formalisms underlying these structures can be given a precise set-theoretical semantics along the lines of Smolka and others. 1 However, there are certain areas within computational linguistics, for which, until recently, no satisfactory formulation in a uniform, constraint-based (or more specifically, HPSG-oriented) theory has been provided. <p> This is achieved by enriching the feature logic underlying HPSG|however, without sticking to external relational constraints. 11 3.1 Encoding Logical Form Simplification In the following, we refer to Pollard and Sag's first volume of HPSG <ref> [20] </ref>. <p> SEM is flat , i.e., only consists of top level attributes like OP (operator), SC (scope), CONN (connective), etc., the idea developed here can be easily adapted to more complex forms of HPSG and other constraint-based grammar formalisms which have similar notions of what English (or any natural language) is <ref> [20, p. 147] </ref>: English = P 1 ^ ^ P n+m ^ (L 1 _ _ L p _ R 1 _ _ R q ) (20) In the introductory section, we said that during parsing the primary reason for using feature structures is the need for storing information obtained so
Reference: 21. <author> Carl Pollard and Ivan A. Sag. </author> <title> Head-Driven Phrase Structure Grammar. </title> <booktitle> Studies in Contemporary Linguistics. </booktitle> <publisher> University of Chicago Press, </publisher> <address> Chicago, </address> <year> 1994. </year>
Reference-contexts: 1 Introduction Pollard&Sag's seminal work on Head-Driven Phrase Structure Grammar has shown that a great deal of syntax and semantics can be neatly encoded within typed feature structures, thus leading for the first time to a highly lexicalized theory of language <ref> [20, 21] </ref>. Moreover, the formalisms underlying these structures can be given a precise set-theoretical semantics along the lines of Smolka and others. 1 However, there are certain areas within computational linguistics, for which, until recently, no satisfactory formulation in a uniform, constraint-based (or more specifically, HPSG-oriented) theory has been provided.
Reference: 22. <author> William C. </author> <title> Rounds. Set values for unification-based grammar formalisms and logic programming. </title> <type> Technical Report CSLI-88-129, </type> <institution> Center for the Study of Language and Information, </institution> <year> 1988. </year>
Reference-contexts: a need for specifying commutativity via a principle/schema; instead, commutativity is now handled internally through set unification. 2 conn-args-struct CONN ^ ARGS f; ; : : :g 3 However, the question still remains which form of set values and set unification is really needed in our case (see for instance <ref> [22] </ref>). And perhaps, more important, what is the price we have to pay when using set-values. However, an examination of these aspects would exceed the scope of this paper. 4 Summary and Conclusions In this paper, I have shown how FA can be neatly integrated and processed within TFF.
Reference: 23. <author> Stuart M. Shieber. </author> <title> An Introduction to Unification-Based Approaches to Grammar. CSLI Lecture Notes, Number 4. Center for the Study of Language and Information, </title> <publisher> Stanford, </publisher> <year> 1986. </year>
Reference-contexts: this is not a restriction w.r.t. the set of recognized words: given an arbitrary NFA, we can always construct a deterministic one which recognizes the same language (however, in the worst case with exponentially more states). 1 In the following, we will assume a basic familiarity with unification-based grammar theories <ref> [23, 25] </ref> and their logics [9, 7, 24]. 3 Fortunately, our approach is also capable of directly representing and process-ing non-deterministic FA with *-moves, and allows for edges which are multiple-symbol consumers (see next section). It is worth noting that edges may not only be annotated with atomic symbols.
Reference: 24. <author> Gert Smolka. </author> <title> A feature logic with subsorts. </title> <type> LILOG Report 33, </type> <institution> WT LILOG-IBM Germany, Stuttgart, </institution> <month> May </month> <year> 1988. </year> <note> Also in J. </note> <editor> Wedekind and C. Rohrer (eds.), </editor> <title> Unification in Grammar, </title> <publisher> MIT Press, </publisher> <year> 1991. </year>
Reference-contexts: w.r.t. the set of recognized words: given an arbitrary NFA, we can always construct a deterministic one which recognizes the same language (however, in the worst case with exponentially more states). 1 In the following, we will assume a basic familiarity with unification-based grammar theories [23, 25] and their logics <ref> [9, 7, 24] </ref>. 3 Fortunately, our approach is also capable of directly representing and process-ing non-deterministic FA with *-moves, and allows for edges which are multiple-symbol consumers (see next section). It is worth noting that edges may not only be annotated with atomic symbols. <p> The correspondences can be easily shown when assuming a sorted set-theoretical semantics for feature descriptions <ref> [24] </ref>. Take, for instance, the intersection of two arbitrary FA, A 1 and A 2 . Intersecting A 1 and A 2 means construction of an FA A which recognizes the intersection of L (A 1 ) and L (A 2 ).
Reference: 25. <author> Hans Uszkoreit. </author> <title> From feature bundles to abstract data types: New directions in the representation and processing of linguistic knowledge. </title> <editor> In A. Blaser, editor, </editor> <booktitle> Natural Language at the Computer|Contributions to Syntax and Semantics for Text Processing and Man-Machine Translation, </booktitle> <pages> pages 31-64. </pages> <publisher> Springer, </publisher> <address> Berlin, </address> <year> 1988. </year>
Reference-contexts: this is not a restriction w.r.t. the set of recognized words: given an arbitrary NFA, we can always construct a deterministic one which recognizes the same language (however, in the worst case with exponentially more states). 1 In the following, we will assume a basic familiarity with unification-based grammar theories <ref> [23, 25] </ref> and their logics [9, 7, 24]. 3 Fortunately, our approach is also capable of directly representing and process-ing non-deterministic FA with *-moves, and allows for edges which are multiple-symbol consumers (see next section). It is worth noting that edges may not only be annotated with atomic symbols.
Reference: 26. <author> Hans Uszkoreit. </author> <title> Linear precedence in head domains. </title> <note> Paper presented at the HPSG in German workshop, </note> <year> 1992. </year>
Reference-contexts: They have been employed in the description of morphophonemics [11, 3] and in the formulation of word order constraints <ref> [26] </ref>; moreover, the use of FA allows for the integration of allomorphy and mor-photactics [15, 12].
Reference: 27. <author> Hans Uszkoreit, Rolf Backofen, Stephan Busemann, Abdel Kader Diagne, Eliz-abeth A. Hinkelman, Walter Kasper, Bernd Kiefer, Hans-Ulrich Krieger, Klaus Netter, Gunter Neumann, Stephan Oepen, and Stephen P. Spackman. </author> <title> DISCO| an HPSG-based NLP system and its application for appointment scheduling. </title> <booktitle> In Proceedings of COLING-94, </booktitle> <address> Kyoto, Japan, </address> <year> 1994. </year> <note> A version of this paper is available as DFKI Research Report RR-94-38. </note>
Reference-contexts: In this regard, it is better to construct the composite automaton first by hand| which is fairly straightforward|and then apply the encoding mechanism for non-complex FA. 10 3 Logical Form Simplification Within HPSG Typed feature formalisms in general, and HPSG in particular, serve as a basis for many NLP/MT systems <ref> [27, 28, 10] </ref>.
Reference: 28. <author> Remi Zajac. </author> <title> A transfer model using a typed feature structure rewriting system with inheritance. </title> <booktitle> In Proceedings of the 27th Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pages 1-6, </pages> <year> 1989. </year> <title> This article was processed using the L a T E X macro package with LLNCS style 21 </title>
Reference-contexts: In this regard, it is better to construct the composite automaton first by hand| which is fairly straightforward|and then apply the encoding mechanism for non-complex FA. 10 3 Logical Form Simplification Within HPSG Typed feature formalisms in general, and HPSG in particular, serve as a basis for many NLP/MT systems <ref> [27, 28, 10] </ref>.
References-found: 28

