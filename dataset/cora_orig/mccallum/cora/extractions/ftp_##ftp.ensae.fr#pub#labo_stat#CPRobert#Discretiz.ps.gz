URL: ftp://ftp.ensae.fr/pub/labo_stat/CPRobert/Discretiz.ps.gz
Refering-URL: http://www.stats.bris.ac.uk/MCMC/pages/list.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Discretization of continuous Markov chains and MCMC convergence assessment  
Author: Chantal Guihenneuc-Jouyaux and Christian P. Robert 
Keyword: Divergence; ergodic theorem; finite state space; MCMC algorithm; multiple chains; renewal theory; renewal time; stopping time.  
Note: AMS Subject Classification: 65C05, 65C10, 60J27, 60K20, 62M99.  
Address: Paris  
Affiliation: 1 UA CNRS 1323, Universite Paris 5 and 2 CREST, INSEE,  
Abstract: We show in this paper that continuous state space Markov chains can be rigorously discretized into finite Markov chains. The idea is to subsample the continuous chain at renewal times related to small sets which control the discretization. Once a finite Markov chain is derived from the MCMC output, general convergence properties on finite state spaces can be exploited for convergence assessment in several directions. Our choice is based on a divergence criterion derived from Kemeny and Snell (1960), which is first evaluated on parallel chains with a stopping time, and then implemented, more efficiently, on two parallel chains only, using Birkhoff's pointwise ergodic theorem for stopping rules. The performance of this criterion is illustrated on three standard examples. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Asmussen, S. </author> <title> (1979) Applied Probability and Queues. </title> <editor> J. </editor> <publisher> Wiley, </publisher> <address> New York. </address>
Reference: <author> Battacharya, R.N. and Waymire, </author> <title> E.C. (1990) Stochastic Processes with Applications. </title> <editor> J. </editor> <publisher> Wiley, </publisher> <address> New York. </address>
Reference-contexts: Moreover, the convergence assessment also imposes a different implementation of the MCMC algorithm since this parallel evaluation cannot be operated on-line. We then reduce the number of parallel chains necessary for the implementation of the control method to two chains, by virtue of Birkhoff's pointwise 2 ergodic theorem <ref> (Battacharya and Waymire, 1990) </ref>, with the additional incentive that these two chains do not need to be restarted at all. We thus get as close as possible from a genuine on-line evaluation. <p> We show in this last section how the divergence criterion can be implemented with only two parallel chains, for an arbitrary number of small sets A i . This alternative imple mentation is based on Birkhoff 's pointwise ergodic theorem which we now recall <ref> (see, e.g., Battacharya and Waymire, 1990, pp.223-227, for a proof) </ref>. We denote X = (X (1) ; : : :) a Markov chain and T r X = (X (r+1) ; X (r+2) ; : : :) the shifted version of the chain. Theorem 5.1.
Reference: <author> Chauveau, D. and Diebolt, J. </author> <title> (1997) MCMC Convergence Diagnostic via the Central Limit Theorem. </title> <type> Tech. report, </type> <institution> Universite de Marne-la-Vallee. </institution>
Reference-contexts: Besides its simplicity, it meets the main requirement of convergence control since it compares the 6 behavior of chains with different starting points till independence from the starting posi-tions. Obviously, alternative criteria can be similarly devised based on other convergence results <ref> (see, e.g., Chauveau and Diebolt, 1997) </ref>.
Reference: <author> Diebolt, J. and Robert, </author> <title> C.P. (1993) The duality Principle. </title> <journal> Journal of the Royal Statistical Society (Series B) 55, </journal> <pages> 71-72. </pages>
Reference: <author> Diebolt, J. and Robert, </author> <title> C.P. (1994) Estimation of finite mixture distributions through Bayesian sampling. </title> <journal> Journal of the Royal Statistical Society (Series B) 56, </journal> <pages> 163-175. </pages>
Reference: <author> Feller, W. </author> <title> (1970) An Introduction to Probability Theory and its Applications., </title> <journal> Vol. </journal> <volume> 1. </volume> <editor> J. </editor> <publisher> Wiley, </publisher> <address> New York. </address>
Reference: <author> Gaver, D.P. and O'Muircheartaigh, I.G. </author> <title> (1987) Robust empirical Bayes analysis of event rates. </title> <type> Technometrics 29, </type> <pages> 1-15. </pages>
Reference: <author> Gelfand, A.E. and Smith, A.F.M. </author> <title> (1990) Sampling based approaches to calculating marginal densities. </title> <journal> Journal of the American Statistical Association 85, </journal> <pages> 398-409. </pages>
Reference: <author> Geyer, C.J. </author> <title> (1992) Practical Monte Carlo Markov Chain (with discussion). </title> <booktitle> Statistical Science 7, </booktitle> <pages> 473-511. </pages>
Reference: <author> Gilks, W.R., Roberts, </author> <title> G.O. and Sahu, S.K. (1997) Adaptive Markov chain Monte Carlo through regeneration. </title> <type> Tech. Report, </type> <institution> MRC Biostatistics Unit, </institution> <address> Cambridge. </address>
Reference: <author> Johnson V.E. </author> <title> (1996) Studying convergence of Markov chain Monte Carlo algorithms using coupled sample paths. </title> <journal> Journal of the American Statistical Association 91, </journal> <pages> 154-166. </pages>
Reference-contexts: Note also that coupling between the chains ( (t) be used to reduce N m (i 1 ; i 2 ) and thus to accelerate the estimation of div j (u; v), although coupling is difficult to implement in continuous state space chains <ref> (see Johnson, 1996) </ref>. In fact, two departures from independence between the parallel chains are of interest. First, the same uniform r.v. can be used at each (absolute) time t to decide whether this is a renewal time for every chain entering an arbitrary small set A j .
Reference: <author> Kemeny, J.G. and Snell, </author> <title> S.L. (1960) Finite Markov Chains. </title> <publisher> Van Nostrand, Princeton. </publisher>
Reference-contexts: A drawback of Raftery and Lewis' (1992) approach is that (~ (t) ) is not a Markov chain, unless restrictive conditions hold <ref> (see Kemeny and Snell, 1960) </ref>.
Reference: <author> Meyn, S.P. et Tweedie, </author> <title> R.L. (1993) Markov Chains and Stochastic Stability. </title> <publisher> Springer-Verlag, London. </publisher>
Reference-contexts: We propose in this paper a general and theoretically valid discretization method which is based on subsampling of a discrete sequence derived from ( (t) ), depending on a sequence of renewal times, that is epochs which separate the chain into iid blocks <ref> (Meyn and Tweedie, 1993) </ref>. Once a true finite state space Markov chain is constructed, several convergence assessments can apply for that chain. <p> We first recall some necessary notions on these sets and their connection with renewal theory. 2.1. Small sets and renewal times. A small set A <ref> (see Meyn and Tweedie, 1993, p.106) </ref> satisfies the following property: there exist m 2 IN fl , " &gt; 0 and a probability measure -m such that, when (t) 2 A, P ( (t+m) 2 Bj (t) ) "-m (B) (2:1) for every measurable set B. <p> Theorem 5.1. For an ergodic Markov chain (X (n) ), with stationary distribution 13 , and a functional g of X, the average 1 M X g (T m X) (5:1) converges almost surely to the expectation IE [g (X)]. This result thus extends the standard ergodic theorem <ref> (see Meyn and Tweedie, 1993) </ref> to functionals of the whole chain and thus allow for repeated use of the same chain. <p> In particular, if R is a stopping time, that is a functional such that the event R (X) = n is determined by (X (1) ; : : : ; (X (n) ) only <ref> (see Meyn and Tweedie, 1993, p.71) </ref> and if g satisfies g (X (1) ; : : : ; X (n) ; : : :) = g (X (1) ; : : : ; X (R (X (1) ;:::)) ); the above result applies.
Reference: <author> Mykland, P., Tierney, L. et Yu, B. </author> <title> (1995) Regeneration in Markov chain samplers. </title> <journal> Journal of the American Statistical Association 90, </journal> <pages> 233-241. </pages>
Reference: <author> O Ruanaidh, J.J.K. and Fitzgerald, W.J. </author> <title> (1996) Numerical Bayesian Methods applied to Signal Processing. </title> <publisher> Springer-Verlag, </publisher> <address> New York. </address>
Reference-contexts: Note also that coupling between the chains ( (t) be used to reduce N m (i 1 ; i 2 ) and thus to accelerate the estimation of div j (u; v), although coupling is difficult to implement in continuous state space chains <ref> (see Johnson, 1996) </ref>. In fact, two departures from independence between the parallel chains are of interest. First, the same uniform r.v. can be used at each (absolute) time t to decide whether this is a renewal time for every chain entering an arbitrary small set A j . <p> In order to approximate the ratio "-(fi 0 )=K (fi; fi 0 ) mentioned in Section 2.1, the inte 12 grals in both -(fi 0 ) and K (fi; fi 0 ) are replaced by sums <ref> (see Robert, 1996) </ref>, leading to the approximation "-(fi 0 ) ' s=1 ffi + i=1 s fl+10ff n i=1 s o s=1 ffi + i=1 i exp fi 0 P 10 ~ s o ; where the s i are generated from Exp (t i +fi j ) and the ~
Reference: <author> Propp, J.G. and Wilson, </author> <title> D.B. (1995) Exact sampling with coupled Markov chains and applications to statistical mechanics. </title> <type> Tech. report, </type> <institution> Department of Mathematics, MIT, </institution> <address> Cambridge, Massachussetts. </address>
Reference: <author> Raftery, A. and Lewis, S. </author> <title> (1992) How many iterations in the Gibbs sampler? In Bayesian Statistics 4 (J.M. </title> <editor> Bernardo, J.O. Berger, A.P. Dawid and A.F.M. Smith, eds.). </editor> <publisher> Oxford University Press, </publisher> <pages> 765-776. </pages>
Reference: <author> Raftery, A.E. et Lewis, S. </author> <title> (1996) Implementing MCMC. In Markov chain Monte-Carlo in Practice (W.R. Gilks, S.T. Richardson and D.J. </title> <editor> Spiegelhalter, eds), </editor> <address> 115-130. </address> <publisher> Chapman and Hall, London. </publisher>
Reference: <author> Robert, </author> <title> C.P. (1995) Convergence control techniques for Markov Chain Monte Carlo algorithms. </title> <booktitle> Statistical Science 10(3), </booktitle> <pages> 231-253. </pages>
Reference-contexts: Note that we can estimate in addition the variance of (4.1), since the batches between renewal times are independent <ref> (see Robert, 1995, for the variance estimation) </ref>. <p> x 3 ; 1 ; 2 ; 3 ~ N 1 x 1 + 2 x 2 + 3 x 3 1 The intervals C = [r 1 ; r 2 ] with x 1 &lt; r 1 &lt; x 2 &lt; r 2 &lt; x 3 are small sets <ref> (see Robert, 1995) </ref> for the Markov chain associated with (5.3) and the corresponding kernel satisfies K (; 0 ) 11 12 1 + 2 1 + 2 1 + 2 -( 0 ) = "-( 0 ) ; where is the marginal density (in ) of (; 1 ; 2 ;
Reference: <author> Robert, </author> <title> C.P. (1996) Methodes de Monte Carlo par Cha^nes de Markov. </title> <address> Economica, Paris. </address>
Reference-contexts: In order to approximate the ratio "-(fi 0 )=K (fi; fi 0 ) mentioned in Section 2.1, the inte 12 grals in both -(fi 0 ) and K (fi; fi 0 ) are replaced by sums <ref> (see Robert, 1996) </ref>, leading to the approximation "-(fi 0 ) ' s=1 ffi + i=1 s fl+10ff n i=1 s o s=1 ffi + i=1 i exp fi 0 P 10 ~ s o ; where the s i are generated from Exp (t i +fi j ) and the ~
Reference: <author> Tanner, M. </author> <title> (1991) Tools for Statistical Inference: Observed Data and Data Augmentation Methods. </title> <booktitle> Lecture Notes in Statistics 67, </booktitle> <publisher> Springer-Verlag, </publisher> <address> New York. </address>
Reference: <author> Yu, B. and Mykland, P. </author> <title> (1994) Looking at Markov samplers through cusum path plots: a simple diagnostic idea. </title> <type> Tech. Report No. 413, </type> <institution> Department of Statistics, University of California at Berkeley. </institution> <month> 24 </month>
References-found: 22

