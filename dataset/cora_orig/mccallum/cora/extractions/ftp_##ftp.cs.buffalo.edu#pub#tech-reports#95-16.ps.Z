URL: ftp://ftp.cs.buffalo.edu/pub/tech-reports/95-16.ps.Z
Refering-URL: ftp://ftp.cs.buffalo.edu/pub/tech-reports/README.html
Root-URL: 
Title: Average Time Complexity Classes  
Author: Jin-yi Cai Alan Selman 
Keyword: computational complexity, average time complexity classes, hierarchy, Average-P, logarithmico-exponential ACM Computing Reviews Subject Category: F.1.3  
Date: March 31, 1995  
Address: Buffalo, NY 14260  
Affiliation: Department of Computer Science State University of New York at Buffalo  
Abstract: We extend Levin's theory of average polynomial time to arbitrary time bounds and prove that average time complexity classes form as fine a hierarchy as do deterministic time complexity classes.
Abstract-found: 1
Intro-found: 1
Reference: [BDCGL92] <author> S. Ben-David, B. Chor, O. Goldreich, and M. Luby. </author> <title> On the theory of average case complexity. </title> <journal> J. Computer System Sci., </journal> <volume> 44(2) </volume> <pages> 193-219, </pages> <year> 1992. </year>
Reference-contexts: Many beautiful results fl Research supported in part by NSF grants CCR-9057486 and CCR-9319093, and an Alfred P. Sloan Fellowship y Research supported in part by NSF grants CCR-9400229 1 have been obtained. Levin, for example, has proved the existence of complete prob-lems in DistNP. Ben-David et al. <ref> [BDCGL92] </ref> were the first to suggest a general formulation of average case complexity for time-bounds other than polynomials. We will demonstrate that this formulation is inadequate|there fails to be a fine hierarchy. However, their formulation is satisfactory for time-bounds that are bounded above by some polynomial. <p> number of input words x), then it should follow that (L; ) should not belong to AVTIME (T (n)). (The definition of Ben-David et al. does not satisfy this condition.) Our definition will satisfy these conditions and will essentially agree with the definition of Levin [Lev86] and Ben-David et al. <ref> [BDCGL92] </ref> when we apply polynomial time-bounds. Readers who are familiar with Levin's theory of average polynomial time will recall that a naive, intuitive formulation suffers from serious problems. This issue is discussed in detail by previous authors including, notably, Gurevich [Gur91] and Ben-David et al. [BDCGL92]. <p> [Lev86] and Ben-David et al. <ref> [BDCGL92] </ref> when we apply polynomial time-bounds. Readers who are familiar with Levin's theory of average polynomial time will recall that a naive, intuitive formulation suffers from serious problems. This issue is discussed in detail by previous authors including, notably, Gurevich [Gur91] and Ben-David et al. [BDCGL92]. Similarly, the path to a correct formulation of average case complexity for arbitrary time-bounds is intricate. In Section 3, we will provide as strong a justification for our new definition for arbitrary time-bounds as Levin [Lev86] and Gurevich [Gur91] provided for polynomial time-bounds. <p> that t (an) = a k q (n)n k q (an) &lt; 1; for all n c, and for all a &gt; 1. (Note that c does not depend on a.) This implies that t (an) &lt; a k t (n). 2 3 The first hierarchy theorem Ben-David et al. <ref> [BDCGL92] </ref> propose the following definition. <p> Then according to Levin's definition, the distributional problem (L; ) is in Average-P; indeed it is linear on the -average according to the definition in <ref> [BDCGL92] </ref>, since X 1 2 n 16 However, according to our definition, by Theorem 4.3 the problem (L; ) is not in time 2 n =n 3 on the -average. Thus, the two definitions differ. <p> the context of average case analysis, we still stand by our guiding principle that a language that requires more than polynomial time almost everywhere is not polynomial time on the average for any distribution. 4.3.2 Worst case average case Moving further in our direction, and away from the definition in <ref> [BDCGL92] </ref>, C.
Reference: [CR73] <author> S. Cook and R. Reckow. </author> <title> Time bounded random access machines. </title> <journal> J. Comput. System Sci., </journal> <volume> 7 </volume> <pages> 354-375, </pages> <year> 1973. </year>
Reference-contexts: L that is decided by a random-access machine in time O (T (n)) such that the running time of every random-access machine M 0 that decides L exceeds T 0 (n) almost everywhere. (This result is an almost-everywhere version of a hierarchy theorem of Cook and Reckow for random-access machines <ref> [CR73] </ref>.) Let be any polynomial time computable distribution that satisfies Condition W. It is immediate that the running time of M is O (T (n)) on the -average.
Reference: [GHS87] <author> J. Geske, D. Huynh, and A. Selman. </author> <title> A hierarchy theorem for almost everywhere complex sets with application to polynomial complexity degrees. </title> <booktitle> In STACS 1987, </booktitle> <year> 1987. </year>
Reference: [GHS91] <editor> J. Geske, D. Huynh, and J. Seiferas. </editor> <title> A note on almost-everywhere-complex sets and separating deterministic-time-complexity classes. </title> <journal> Inf. and Comput., </journal> <volume> 92(1) </volume> <pages> 97-104, </pages> <year> 1991. </year>
Reference-contexts: We adhere to the customary convention that T (n) n + 1 (S (x) jxj + 1), for any Turing machine running time T (S, respectively). The following proposition is one of the main theorems of Geske, Huynh, and Seiferas <ref> [GHS91] </ref>. <p> It follows from the result of Geske, Huynh, and Seiferas <ref> [GHS91] </ref>, Proposition 2.1, that there exists a language L 2 DTIME (2 2n ) that cannot be recognized in time 2 n almost everywhere|every Turing machine that accepts L requires more than 2 n steps on all but some finite number of inputs. <p> To illustrate, let's consider a (pathological) example where u n = 1=2 n ; i.e., all strings of length n have total measure 1=2 n . It follows from the theorem of Geske, Huynh, and Seiferas <ref> [GHS91] </ref>, Proposition 2.1, that there is a language L that runs in time 2 n =n, but almost everywhere more than, say, 2 n =n 3 . <p> Proof. It is known <ref> [GHS91] </ref> that there is a language L that is decided by a random-access machine in time O (T (n)) such that the running time of every random-access machine M 0 that decides L exceeds T 0 (n) almost everywhere. (This result is an almost-everywhere version of a hierarchy theorem of Cook
Reference: [Gur91] <author> Y. Gurevich. </author> <title> Average case completeness. </title> <journal> J. Comput. System Sci., </journal> <volume> 42 </volume> <pages> 346-398, </pages> <year> 1991. </year>
Reference-contexts: Readers who are familiar with Levin's theory of average polynomial time will recall that a naive, intuitive formulation suffers from serious problems. This issue is discussed in detail by previous authors including, notably, Gurevich <ref> [Gur91] </ref> and Ben-David et al. [BDCGL92]. Similarly, the path to a correct formulation of average case complexity for arbitrary time-bounds is intricate. In Section 3, we will provide as strong a justification for our new definition for arbitrary time-bounds as Levin [Lev86] and Gurevich [Gur91] provided for polynomial time-bounds. <p> by previous authors including, notably, Gurevich <ref> [Gur91] </ref> and Ben-David et al. [BDCGL92]. Similarly, the path to a correct formulation of average case complexity for arbitrary time-bounds is intricate. In Section 3, we will provide as strong a justification for our new definition for arbitrary time-bounds as Levin [Lev86] and Gurevich [Gur91] provided for polynomial time-bounds. We will present a hierarchy theorem for average-case complexity, for arbitrary time-bounds, that is as tight as the well-known Hartmanis-Stearns [HS65] hierarchy theorem for deterministic complexity. <p> We restrict our attention to distributions that are computable in polynomial time. If the distribution function is computable in polynomial time, then the density function 0 is computable in polynomial time. (The converse is false unless P = NP <ref> [Gur91] </ref>.) Levin [Lev86] defines a function f from fl to nonnegative reals to be linear on -average if X 0 (x) jxj and f is polynomial on -average if f is bounded by a polynomial of a function that is linear on -average.
Reference: [Har24] <author> G. Hardy. </author> <title> Orders of Infinity, </title> <booktitle> The `infinitarcalcul' of Paul du Bois-Reymond, volume 12 of Cambridge Tracts in Mathematics and Mathematical Physics. </booktitle> <publisher> Cambridge University Press, </publisher> <address> London, 2nd edition, </address> <year> 1924. </year>
Reference-contexts: Thus we might as well take the expectation now, after this manipulation, which results in the established definition. (We will discuss this point further in Section 4.) 2.3 Hardy's class of logarithmico-exponential functions We will need the notion of a class of functions L defined by Hardy <ref> [Har24] </ref>, called the logarithmico-exponential functions. Every function in L is a real valued function of one variable that is defined on the real numbers. <p> For example, if t (x) and s (x) are in L, then so are t (x) + s (x), t (x)s (x) and t (x)=s (x). Also, functions such as k q 1 p ln t (x)= ln ln t (x) belong to L. Hardy <ref> [Har24] </ref> proved the following facts regarding the logarithmico-exponential functions. He showed that every function in L is either eventually positive or eventually negative or identically zero.
Reference: [Har11] <author> G. Hardy. </author> <title> Properties of logarithmico-exponential functions. </title> <journal> Proc. Lon--don Math. Soc., </journal> <volume> (2),10:54-90, </volume> <year> 1911. </year>
Reference-contexts: Let f (`) denote the function that iterates ` applications of f. That is, f (1) (x) = f (x) and f (`+1) (x) = f (f (`) )(x), for ` &gt; 1. Hardy proved <ref> [Har11] </ref> that for every function t 2 L, if lim x!1 t (x) = 1, then there is some constant ` so that log (`) (x) = o (t (x)), as well as t (x) = o (exp (`) (x)) |informally, a logarithmico-exponential function that goes to infinity cannot increase more
Reference: [HS65] <author> J. Hartmanis and R. Stearns. </author> <title> On the computational complexity of algorithms. </title> <journal> Trans. Amer. Math. Soc., </journal> <volume> 117 </volume> <pages> 285-306, </pages> <year> 1965. </year>
Reference-contexts: In Section 3, we will provide as strong a justification for our new definition for arbitrary time-bounds as Levin [Lev86] and Gurevich [Gur91] provided for polynomial time-bounds. We will present a hierarchy theorem for average-case complexity, for arbitrary time-bounds, that is as tight as the well-known Hartmanis-Stearns <ref> [HS65] </ref> hierarchy theorem for deterministic complexity. <p> Since T is logarithmico-exponential, either (i) n = o (T (n)), or (ii) for some constant c 1, T (n) cn, for all sufficiently large n. If case (i) holds, then the well-known linear-speedup theorem applies <ref> [HS65] </ref>. In this case L 2 DTIME (T (n)) and the result follows immediately. If case (ii) holds, then L 2 DTIME (cn). Let M be a Turing machine that witnesses L 2 DTIME (cn) and let T M be the running time of M . <p> This result is as strong as the well-known Hartmanis-Stearns hierarchy theorem <ref> [HS65] </ref> for deterministic time. Corollary 4.1 For all c 1 and for all * &gt; 0, AVTIME (n c ) AVTIME (n c+* ). For all c &gt; 1 and for all * &gt; 0, AVTIME (c n ) AVTIME ((c + *) n ).
Reference: [Ko83] <author> K. Ko. </author> <title> On the definition of some complexity classes of real numbers. </title> <journal> Math. Systems Theory, </journal> <volume> 16 </volume> <pages> 95-109, </pages> <year> 1983. </year>
Reference-contexts: That is, 0 n (x) = 0 (x)=u n , if u n &gt; 0, and 0 for x 2 fx j jxj = ng, if u n = 0. A function from fl to [0; 1] is computable in polynomial time <ref> [Ko83] </ref> if there is a polynomial time-bounded transducer T such that for every string x and every positive integer n, j (x) T (x; 1 n )j &lt; 1 2 n . We restrict our attention to distributions that are computable in polynomial time.
Reference: [Lev86] <author> L. Levin. </author> <title> Average case complete problems. </title> <journal> SIAM J. of Comput., </journal> <volume> 15 </volume> <pages> 285-286, </pages> <year> 1986. </year>
Reference-contexts: Here we consider this issue for average case complexity. The average complexity of a problem is, in many cases, a more significant measure than its worst case complexity. This has motivated a rich area in algorithms research, but Levin <ref> [Lev86] </ref> was the first to advocate the general study of average case complexity. An average case complexity class consists of pairs, called distributional problems. Each pair consists of a decision problem and a probability distribution on problem instances. <p> for all but a finite number of input words x), then it should follow that (L; ) should not belong to AVTIME (T (n)). (The definition of Ben-David et al. does not satisfy this condition.) Our definition will satisfy these conditions and will essentially agree with the definition of Levin <ref> [Lev86] </ref> and Ben-David et al. [BDCGL92] when we apply polynomial time-bounds. Readers who are familiar with Levin's theory of average polynomial time will recall that a naive, intuitive formulation suffers from serious problems. <p> Similarly, the path to a correct formulation of average case complexity for arbitrary time-bounds is intricate. In Section 3, we will provide as strong a justification for our new definition for arbitrary time-bounds as Levin <ref> [Lev86] </ref> and Gurevich [Gur91] provided for polynomial time-bounds. We will present a hierarchy theorem for average-case complexity, for arbitrary time-bounds, that is as tight as the well-known Hartmanis-Stearns [HS65] hierarchy theorem for deterministic complexity. <p> We restrict our attention to distributions that are computable in polynomial time. If the distribution function is computable in polynomial time, then the density function 0 is computable in polynomial time. (The converse is false unless P = NP [Gur91].) Levin <ref> [Lev86] </ref> defines a function f from fl to nonnegative reals to be linear on -average if X 0 (x) jxj and f is polynomial on -average if f is bounded by a polynomial of a function that is linear on -average.
Reference: [Rac95] <author> C. Rackoff. </author> <type> Personal communication. 20 </type>
Reference-contexts: Rackoff in discussion of a preliminary draft of this paper <ref> [Rac95] </ref>, suggested the following even more stringent requirement as a possible definition for a distributional problem (L; ) to be T on the -average: There exists a Turing machine M that accepts L such that for all n, the running time T M satisfies X 0 (x) jxj Clearly if T
References-found: 11

