URL: http://www.cs.cmu.edu/~laura/Papers-PS/ACL97-signll-final.ps
Refering-URL: http://www.cs.cmu.edu/afs/cs/user/laura/www/pages/publications.html
Root-URL: 
Email: laura@cs.cmu.edu  kries@ira.uka.de  
Title: What makes a word: Learning base units in Japanese for speech recognition  
Author: Laura Mayfield Tomokiyo Klaus Ries 
Address: 4910 Forbes Avenue Pittsburgh, PA 15213, USA  76128 Karlsruhe, Germany  
Affiliation: Language Technology Institute Carnegie Mellon University  Universitat Karlsruhe Fakultat fur Informatik Interactive Systems Laboratories  
Abstract: We describe an automatic process for learning word units in Japanese. Since the Japanese orthography has no spaces delimiting words, the first step in building a Japanese speech recognition system is to define the units that will be recognized. Our method applies a compound-finding algorithm, previously used to find word sequences in English, to learning syllable sequences in Japanese. We report that we were able not only to extract meaningful units, eliminating the need for possibly inconsistent manual segmentation, but also to decrease perplexity using this automatic procedure, which relies on a statistical, not syntactic, measure of relevance. Our algorithm also uncovers the kinds of environments that help the recognizer predict phonological alternations, which are often hidden by morphologically-motivated tok enization.
Abstract-found: 1
Intro-found: 1
Reference: <author> Sabine Deligne and Frederic Bimbot. </author> <title> Language Modeling by Variable Length Sequences: Theoretical Formulation and Evaluation of Multigram. </title> <booktitle> In ICASSP 1995, </booktitle> <volume> Vol. 1, </volume> <pages> pp. 169-172. </pages>
Reference: <author> Reinhard Kneser and Hermann Ney. </author> <title> Improved Backing-off for M-gram Language Modeling. </title> <booktitle> In ICASSP 1995, </booktitle> <volume> Vol. 1, </volume> <pages> pp. 181-184. </pages>
Reference: <author> Akinori Ito and Masaki Kohda. </author> <title> Language Modeling by String Pattern N-gram for Japanese Speech Recogniton. </title> <booktitle> In ICSLP, </booktitle> <year> 1996. </year>
Reference: <author> Masayuki Kameda. </author> <title> A Portable & Quick Japanese Parser: </title> <booktitle> QJP. In COLING, </booktitle> <address> Copenhagen, </address> <year> 1996. </year>
Reference: <author> Mark Lauer. </author> <title> Corpus Statistics Meet the Noun Compound: Some Empirical Results. </title> <booktitle> In ACL, </booktitle> <year> 1995. </year>
Reference: <author> Hubert Hin-Cheung Law and Chorkin Chan. </author> <title> Ergodic Multigram HMM Integrating Word Segmentation and Class Tagging for Chinese Language Modeling. </title> <booktitle> In ICASSP 1996, Vol.1, </booktitle> <pages> pp. 196-199. </pages>
Reference: <author> David M. Magerman and Mitchell P. Marcus. </author> <title> Dis-tituent Parsing and Grammar Induction. </title> <publisher> pages 122a-122e. </publisher>
Reference: <author> Sven Martin, Joerg Liebermann, and Hermann Ney. </author> <title> Algorithms for Bigram and Trigram Clustering. </title> <booktitle> In Eurospeech, </booktitle> <year> 1995. </year>
Reference: <author> Hirokazu Masataki and Yoshinori Sagisaka. </author> <title> Variable-order N-gram Generationi by Word-class Splitting and Consecutive Word Grouping. </title> <booktitle> In ICASSP 1996, </booktitle> <volume> Vol. 1, </volume> <pages> pp. 188-191. </pages>
Reference: <author> Yo Matsumoto. </author> <title> Constraints on the 'Intransitivizing' Resultatitive -te aru construction in Japanese. </title> <booktitle> In Japanese/Korean Linguistics, </booktitle> <pages> pp. 269-283, </pages> <note> SLA, </note> <author> Stanford, 1990 Michael K McCandless and James R Glass. </author> <title> Empirical Acquisition of Language Models for Speech Recognition. </title> <booktitle> In ICSLP, </booktitle> <address> Yokohama, Japan, </address> <year> 1994. </year>
Reference: <author> Thomas M. Cover and Joy A. </author> <title> Thomas Elements of Information Theory. </title> <publisher> Wiley, </publisher> <year> 1991. </year> <title> Series in Telecommunications. </title>
Reference-contexts: These models are called m-gram models and have proved to be very effective in a large number of applications, even though they are a naive model of language. Information theoretic measures <ref> (Cover and Thomas, 1991) </ref> are frequently used to describe the power of language models. (Cover and Thomas, 1991) shows in chapter 4.2 that the entropy rate of a random process converges, under additional assumptions, to the entropy of the random source. <p> These models are called m-gram models and have proved to be very effective in a large number of applications, even though they are a naive model of language. Information theoretic measures <ref> (Cover and Thomas, 1991) </ref> are frequently used to describe the power of language models. (Cover and Thomas, 1991) shows in chapter 4.2 that the entropy rate of a random process converges, under additional assumptions, to the entropy of the random source.
Reference: <author> Tsuyoshi Morimoto et al. </author> <title> ATR's Speech Translation System: </title> <booktitle> ASURA. In Eurospeech, </booktitle> <year> 1993. </year>
Reference: <editor> Shiho Nobesawa et al. </editor> <title> Segmenting Sentences into Linky Strings using D-bigram statistics. </title> <booktitle> In COL-ING, </booktitle> <address> Copenhagen, </address> <year> 1996. </year>
Reference: <author> Klaus Ries, </author> <title> Finn Dag But, and Alex Waibel Class Phrase Models for Language Modeling. </title> <booktitle> In ICSLP, </booktitle> <year> 1996. </year>
Reference: <author> Klaus Ries, Finn Dag But, and Ye-Yi Wang. </author> <title> Improved Language Modeling by Unsupervised Acquisition of Structure. </title> <booktitle> In ICASSP 1995, </booktitle> <volume> Vol. 1, </volume> <pages> pp. 193-196. </pages>
Reference: <author> Tanja Schultz and Detlef Koll. </author> <title> Spontaneously Spoken Japanese Speech Recognition with Janus-3 To appear in EUROSPEECH, </title> <year> 1997. </year>
Reference: <author> Peter Sells. </author> <title> VP in Japanese: Evidence from -te Complements. </title> <booktitle> In Japanese/Korean Linguistics, </booktitle> <pages> pp. 319-333, </pages> <address> SLA, Stanford, </address> <year> 1990. </year> <title> Masayoshi Shibatani. Japanese. </title> <booktitle> In The World's Major Languages, </booktitle> <pages> pp. 855-880, </pages> <editor> Bernard Comrie, ed., </editor> <publisher> Oxford University Press, </publisher> <year> 1987. </year>
Reference: <author> Koichi Shinoda and Takao Watanabe. </author> <title> Speaker Adaptation with Autonomous Model Complexity Control by MDL Principle. </title> <booktitle> In ICASSP 1996, </booktitle> <volume> Vol. 2, </volume> <pages> pp. 717-720. </pages>
Reference: <author> Bernhard Suhm and Alex Waibel. </author> <title> Towards Better Language Models for Spontaneous Speech. </title> <booktitle> In IC-SLP, </booktitle> <address> Yokohama, Japan, </address> <year> 1994. </year>
Reference: <author> Eiichiro Sumita and Hitoshi Iida. </author> <title> Heterogeneous Computing for Example-based Translation of Spoken Language. </title> <booktitle> In Proceedings of the sixth international conference on theoretical and methodological issues in Machine Translation, </booktitle> <address> Leuven, Bel-gium, </address> <year> 1995. </year>
Reference: <author> B. V. Suhotin. </author> <title> Methode de dechiffrage, outil de recherche en linguistique. </title> <journal> TA Informationes, </journal> <volume> 2 </volume> <pages> 3-43, </pages> <year> 1973. </year>
Reference-contexts: earlier work have been: * mutual information (Magerman and Marcus, ) * frequency * iterative marking frequency (Ries et al., 1995) * backward bigram: p (w 1 jw 2 ) * backward perplexity: p (w 1 ; w 2 ) log (p (w 1 jw 2 )) * Suhotin's measure <ref> (Suhotin, 1973) </ref> 3.1 Statistical language modeling and speech recognition Statistical models of language are, to our knowledge, the type of language model used in all modern speech recognition engines, especially in research systems but also in most commercial large vocabulary systems that can recognize naturally fluent spoken language.
Reference: <author> Virginia Teller and Eleanor Olds Batchelder. </author> <title> A Probabilistic Algorithm for Segmenting Non-Kanji Japanese Strings. </title> <booktitle> In AAAI pp. </booktitle> <pages> 742-747, </pages> <address> Seattle, </address> <year> 1994. </year>
Reference: <author> Kei Yoshimoto and Christine Nanz. </author> <title> A Study in Transfer Japanese-English. </title> <type> Verbmobil report 101 2/96. </type>
References-found: 23

