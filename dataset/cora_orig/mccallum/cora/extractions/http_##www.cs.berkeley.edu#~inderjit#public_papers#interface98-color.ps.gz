URL: http://www.cs.berkeley.edu/~inderjit/public_papers/interface98-color.ps.gz
Refering-URL: http://www.cs.berkeley.edu/~inderjit/
Root-URL: 
Email: Emails: fdhillon,dmodha,spanglesg@almaden.ibm.com  
Title: Visualizing Class Structure of Multidimensional Data  
Author: Inderjit S. Dhillon, Dharmendra S. Modha W. Scott Spangler 
Address: San Jose, CA 95120-6099  
Affiliation: IBM Almaden Research Center  
Abstract: We consider the problem of visualizing multidimensional data that has been categorized into classes. Our goal in visualizing is to quickly absorb inter and intra-class relationships. Towards this end, we introduce class-preserving projections of the multidimensional data onto two-dimensional planes which can then be displayed on a computer screen. These class-preserving projections maintain the high-dimensional class structure, and are closely related to Fisher's linear discriminants. By displaying sequences of such two-dimensional projections and by moving continuously from one projection to the next, we can create illusions of smooth motion through a multidimensional display. Such sequences are termed class tours. We illustrate the proposed ideas by various computer simulations on the classical Iris plant dataset and a text corpus of book reviews. 
Abstract-found: 1
Intro-found: 1
Reference: [Asimov, 1985] <author> Asimov, D. </author> <year> (1985). </year> <title> The grand tour: A tool for viewing multidimensional data. </title> <journal> SIAM J. Sci. Stat. Comput., </journal> <volume> 6(1) </volume> <pages> 128-143. </pages>
Reference-contexts: Ideally, we would like a mechanism for viewing this inter-class differentiating or class-preserving linear subspace. In order to simulate multidimensional displays, <ref> [Asimov, 1985, Asimov and Buja, 1985] </ref> proposed the use of motion graphics. Specifically, they introduced the concept of tours which are sequences of 2-dimensional projections interspersed with a number of intermediate projections. <p> The main question of interest is in the choice of the or-thonormal basis used for viewing so that the motion appears smooth. <ref> [Asimov, 1985, Asimov and Buja, 1985] </ref> have proposed using geodesic interpolation paths between the current and the target planes. These geodesic paths are simply a rotation in the (at most) 4-dimensional linear subspace containing both the current and the target two-planes.
Reference: [Asimov and Buja, 1985] <author> Asimov, D. and Buja, A. </author> <year> (1985). </year> <title> Grand tour methods: an outline. </title> <booktitle> In Proceedings of the 17th Symposium on Interface of Computer Science and Statistics. </booktitle>
Reference-contexts: Ideally, we would like a mechanism for viewing this inter-class differentiating or class-preserving linear subspace. In order to simulate multidimensional displays, <ref> [Asimov, 1985, Asimov and Buja, 1985] </ref> proposed the use of motion graphics. Specifically, they introduced the concept of tours which are sequences of 2-dimensional projections interspersed with a number of intermediate projections. <p> The main question of interest is in the choice of the or-thonormal basis used for viewing so that the motion appears smooth. <ref> [Asimov, 1985, Asimov and Buja, 1985] </ref> have proposed using geodesic interpolation paths between the current and the target planes. These geodesic paths are simply a rotation in the (at most) 4-dimensional linear subspace containing both the current and the target two-planes.
Reference: [Bryan, 1951] <author> Bryan, J. G. </author> <year> (1951). </year> <title> The generalized discriminant function: mathematical foundation and computational routine. Harvard Educ. </title> <journal> Rev., </journal> <volume> 21 </volume> <pages> 90-95. </pages>
Reference-contexts: We have chosen to ignore such within-class scatter for computational reasons as we plan to deal with very large and high-dimensional datasets. For more details on these projection schemes, the reader is referred to <ref> [Fisher, 1936, Duda and Hart, 1973, Bryan, 1951, Kullback, 1959] </ref>. We emphasize that our class-preserving projections preserve distances between the three class-means, i.e., the multidimensional scaling error is zero for these class-means.
Reference: [Buja et al., 1998] <author> Buja, A., Cook, D., Asimov, D., and Hurley, C. </author> <year> (1998). </year> <title> Dynamic projections in high-dimensional visualization: Theory and computational methods. </title> <journal> Journal of Computational and Graphical Statistics. </journal> <note> to appear. </note>
Reference-contexts: These geodesic paths are simply a rotation in the (at most) 4-dimensional linear subspace containing both the current and the target two-planes. Various smoothness properties of such geodesic paths are explored in great detail in <ref> [Buja et al., 1998] </ref>. For a description of various implementation details, see [Hurley and Buja, 1990, section 2.2.1]. 5 Conclusions In this paper, we have proposed the use of class-preserving projections for visual discriminant analysis. These projections satisfy a certain optimality criterion that tries to preserve distances between the class-means.
Reference: [Duda and Hart, 1973] <author> Duda, R. O. and Hart, P. E. </author> <year> (1973). </year> <title> Pattern Classification and Scene Analysis. </title> <publisher> Wi-ley. </publisher>
Reference-contexts: not worry about how the data is classified | the classification may be fl To appear in the Proceedings of the 30th Symposium on the Interface: Computing Science and Statistics done manually as in the Yahoo! hierarchy, or may be obtained by a clustering method such as the k-means algorithm <ref> [Duda and Hart, 1973, Hartigan, 1975] </ref>. We assume that we know the representation of all the data points as vectors in R d , and their respective class labels. <p> We have chosen to ignore such within-class scatter for computational reasons as we plan to deal with very large and high-dimensional datasets. For more details on these projection schemes, the reader is referred to <ref> [Fisher, 1936, Duda and Hart, 1973, Bryan, 1951, Kullback, 1959] </ref>. We emphasize that our class-preserving projections preserve distances between the three class-means, i.e., the multidimensional scaling error is zero for these class-means. <p> We emphasize that our class-preserving projections preserve distances between the three class-means, i.e., the multidimensional scaling error is zero for these class-means. For the more general problem of preserving inter-point distances between all the data points after projection, see <ref> [Kruskal, 1964, Kruskal, 1977, Duda and Hart, 1973] </ref>. 2.1 Discriminating More than 3 Classes In the above discussion, we arrived at a certain 2-dimensional projection that "best" preserves the relationship between 3 classes. But in most practical situations, we will encounter a greater number of classes. <p> This is an inevitable loss of information in projecting high-dimensional data to lower dimensions. To mitigate this information loss, we propose the addition of class-similarity graphs to our 2-dimensional plots. A class-similarity graph is described as follows <ref> [Duda and Hart, 1973, pp. 238] </ref>.
Reference: [Fisher, 1936] <author> Fisher, R. A. </author> <year> (1936). </year> <title> The use of multiple measurements in taxonomic problems. </title> <editor> Ann. Eugenics, 7(Part II):179-188. </editor> <title> also in Contributions to Mathematical Statistics (John Wiley, </title> <address> New York, </address> <year> 1950). </year> <note> [Flickner et al., 1995] Flickner, </note> <author> M., Sawhney, H., Niblack, W., Ashley, J., Huang, Q., Dom, B., Gorkani, M., Hafner, J., Lee, D., Petkovic, D., Steele, D., and Yanker, P. </author> <year> (1995). </year> <title> Query by image and video content: the QBIC system. </title> <journal> IEEE Computer, </journal> <volume> 28(9) </volume> <pages> 23-32. </pages>
Reference-contexts: We have chosen to ignore such within-class scatter for computational reasons as we plan to deal with very large and high-dimensional datasets. For more details on these projection schemes, the reader is referred to <ref> [Fisher, 1936, Duda and Hart, 1973, Bryan, 1951, Kullback, 1959] </ref>. We emphasize that our class-preserving projections preserve distances between the three class-means, i.e., the multidimensional scaling error is zero for these class-means.
Reference: [Hartigan, 1975] <author> Hartigan, J. A. </author> <year> (1975). </year> <title> Clustering Algorithms. </title> <publisher> Wiley. </publisher>
Reference-contexts: not worry about how the data is classified | the classification may be fl To appear in the Proceedings of the 30th Symposium on the Interface: Computing Science and Statistics done manually as in the Yahoo! hierarchy, or may be obtained by a clustering method such as the k-means algorithm <ref> [Duda and Hart, 1973, Hartigan, 1975] </ref>. We assume that we know the representation of all the data points as vectors in R d , and their respective class labels.
Reference: [Hurley and Buja, 1990] <author> Hurley, C. and Buja, A. </author> <year> (1990). </year> <title> Analyzing high-dimensional data with motion graphics. </title> <journal> SIAM J. Sci. Stat. Comput., </journal> <volume> 11(6) </volume> <pages> 1193-1211. </pages>
Reference-contexts: These geodesic paths are simply a rotation in the (at most) 4-dimensional linear subspace containing both the current and the target two-planes. Various smoothness properties of such geodesic paths are explored in great detail in [Buja et al., 1998]. For a description of various implementation details, see <ref> [Hurley and Buja, 1990, section 2.2.1] </ref>. 5 Conclusions In this paper, we have proposed the use of class-preserving projections for visual discriminant analysis. These projections satisfy a certain optimality criterion that tries to preserve distances between the class-means.
Reference: [Kruskal, 1964] <author> Kruskal, J. B. </author> <year> (1964). </year> <title> Nonmetric multidimensional scaling: A numerical method. </title> <journal> Psychome-trika, </journal> <volume> 29 </volume> <pages> 115-129. </pages>
Reference-contexts: We emphasize that our class-preserving projections preserve distances between the three class-means, i.e., the multidimensional scaling error is zero for these class-means. For the more general problem of preserving inter-point distances between all the data points after projection, see <ref> [Kruskal, 1964, Kruskal, 1977, Duda and Hart, 1973] </ref>. 2.1 Discriminating More than 3 Classes In the above discussion, we arrived at a certain 2-dimensional projection that "best" preserves the relationship between 3 classes. But in most practical situations, we will encounter a greater number of classes.
Reference: [Kruskal, 1977] <author> Kruskal, J. B. </author> <year> (1977). </year> <title> Multidimensional scaling and other methods for discovering structure. </title> <editor> In Enslein, K., Ralston, A., and Wilf, H. S., editors, </editor> <booktitle> Statistical Methods for Digital Computers, </booktitle> <pages> pages 296-339. </pages> <publisher> Wiley. </publisher>
Reference-contexts: We emphasize that our class-preserving projections preserve distances between the three class-means, i.e., the multidimensional scaling error is zero for these class-means. For the more general problem of preserving inter-point distances between all the data points after projection, see <ref> [Kruskal, 1964, Kruskal, 1977, Duda and Hart, 1973] </ref>. 2.1 Discriminating More than 3 Classes In the above discussion, we arrived at a certain 2-dimensional projection that "best" preserves the relationship between 3 classes. But in most practical situations, we will encounter a greater number of classes.
Reference: [Kullback, 1959] <author> Kullback, S. </author> <year> (1959). </year> <title> Information Theory and Statistics. </title> <publisher> John Wiley, </publisher> <address> New York. </address>
Reference-contexts: We have chosen to ignore such within-class scatter for computational reasons as we plan to deal with very large and high-dimensional datasets. For more details on these projection schemes, the reader is referred to <ref> [Fisher, 1936, Duda and Hart, 1973, Bryan, 1951, Kullback, 1959] </ref>. We emphasize that our class-preserving projections preserve distances between the three class-means, i.e., the multidimensional scaling error is zero for these class-means.
Reference: [Salton and Buckley, 1988] <author> Salton, G. and Buckley, C. </author> <year> (1988). </year> <title> Term-weighting approaches in automatic text retrieval. </title> <booktitle> Information Processing & Management, </booktitle> <volume> 4(5) </volume> <pages> 513-523. </pages>
Reference-contexts: In addition, we also normalize each document vector to have unit Euclidean norm in order to remove the effects of the length of a document. Many other such scaling strategies have been studied, see <ref> [Salton and McGill, 1983, Salton and Buckley, 1988] </ref>. For this text corpus of book reviews, we used a total of d = 867 words. After forming the vector-space model, we divided the book reviews into seven classes by invoking the k-means algorithm.
Reference: [Salton and McGill, 1983] <author> Salton, G. and McGill, M. J. </author> <year> (1983). </year> <title> Introduction to Modern Retrieval. </title> <publisher> McGraw-Hill Book Company. </publisher>
Reference-contexts: We will assume that the data is embedded in high-dimensional Euclidean space R d . The data may naturally occur in this form, or vector-space models of the underlying data may be formed, e.g., text documents or images may be treated as vectors in a multidimensional feature space, see <ref> [Salton and McGill, 1983] </ref> and [Flickner et al., 1995]. <p> The raw data is in the form of 1412 book reviews, each of which is a short text document containing about 25-100 words. For our treatment, we transform this data into a vector-space model , where each document is expressed as a numerical vector (of words) <ref> [Salton and McGill, 1983] </ref>. <p> In addition, we also normalize each document vector to have unit Euclidean norm in order to remove the effects of the length of a document. Many other such scaling strategies have been studied, see <ref> [Salton and McGill, 1983, Salton and Buckley, 1988] </ref>. For this text corpus of book reviews, we used a total of d = 867 words. After forming the vector-space model, we divided the book reviews into seven classes by invoking the k-means algorithm.
Reference: [Yahoo!, 1998] <institution> Yahoo! (1998). </institution> <note> http://www.yahoo.com. </note>
Reference-contexts: 1 Introduction It is often desirable to classify data into meaningful categories. The Yahoo! hierarchy of the World-Wide Web is a prime example of the value of classification <ref> [Yahoo!, 1998] </ref>. Given such classes, we may want to quickly absorb inter and intra-class relationships. Visualization is an effective tool for this task, and in this paper we propose a scheme for visually understanding the relationships between classes.
References-found: 14

