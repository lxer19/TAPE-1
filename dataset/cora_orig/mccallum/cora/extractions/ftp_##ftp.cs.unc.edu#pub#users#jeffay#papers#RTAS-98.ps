URL: ftp://ftp.cs.unc.edu/pub/users/jeffay/papers/RTAS-98.ps
Refering-URL: http://www.cs.unc.edu/Research/real-time.html
Root-URL: http://www.cs.unc.edu
Email: fgoddard, jeffayg@cs.unc.edu  
Title: Managing Memory Requirements in the Synthesis of Real-Time Systems from Processing Graphs  
Author: Steve Goddard Kevin Jeffay 
Address: Chapel Hill, NC 27599-3175  
Affiliation: Department of Computer Science University of North Carolina at Chapel Hill  
Date: June 1998, pages 59-70.  
Note: In: Proceedings of the Fourth IEEE Real-Time Technology and Applications Symposium, Denver, CO,  
Abstract: We present techniques for managing the memory requirements of signal processing applications in the synthesis of a real-time uniprocessor system from processing graphs. To demonstrate the effectiveness of our memory management techniques, we compare the memory requirements of a statically scheduled implementation of an INMARSAT (International Maritime Satellite) mobile receiver, with our dynamic scheduling techniques. The case study demonstrates that state-of-the-art, static schedulers use over 300% more memory than our simple, preemptive, EDF scheduler for a large class of signal processing applications. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Baruah, S., Goddard, S., Jeffay, K., </author> <title> Feasibility Concerns in PGM Graphs with Bounded Buffers, </title> <booktitle> Proc. of the Third Intl. Conference on Engineering of Complex Computer Systems, </booktitle> <month> Sept., </month> <year> 1997, </year> <pages> pp 130-139. </pages>
Reference-contexts: We have selected PGM as our processing graph model since it is a general and widely used paradigm. Our previous work on the synthesis of real-time uniprocessor systems from PGM was based on simple PGM graphs called chains <ref> [1, 8] </ref>. In this paper, we extend the analyses developed for chains to handle directed acyclic graphs. In addition, we present new methods for deriving the memory needs of a common class of acyclic PGM graphs executed using the same simple, preemptive, earliest deadline first (EDF) scheduler of [8].
Reference: [2] <author> Bhattacharyya, S.S., Murthy, P.K., Lee, </author> <title> E.A., Software Synthesis from Dataflow Graphs, </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1996. </year>
Reference-contexts: The canonical approach to minimiz-ing memory requirements for the graph edges is to use static scheduling. Static node execution schedules are created offline and then executed on a periodic basis. Numerous static scheduling algorithms have been created to minimize memory requirements <ref> [13, 17, 22, 18, 2] </ref>. The primary trade-off made by static schedulers is the storage requirement and execution complexity of the schedule vs. the storage requirement of data in the graph edges. Typically, minimal buffer space requires increased state space for the scheduler. <p> We compare the memory needs of the mobile satellite receiver application executed with our on-line scheduler to the memory needs of the same application executed using state-of-the-art, off-line, static schedulers presented in [18] and <ref> [2] </ref>. From the real-time literature, PGM graphs are most closely related to the Logical Application Stream Model (LASM) [3, 4]. Our work improves on the analysis of LASM graphs by not requiring periodic execution of the nodes in the graph. <p> Our contributions are summarized in x6. 2. Notation and the Processing Graph Method The notation and terminology of this paper, for the most part, is an amalgamation of the notation and terminology used in [6] and <ref> [2] </ref>. A processing graph is formally described as a directed graph (or digraph) G = (V; E; ). <p> Other algorithms save scheduler state space by associating a number of executions with each scheduler entry to reduce state space for multiple executions of the same node. Still other scheduling algorithms produce slightly more complicated schedules by creating scheduling loops encompassing many scheduling entries <ref> [2] </ref>. For example, three different possible schedules for the chain in Figure 1 are: uwuwuww a multiple appearance flat schedule, (3u)(4w) a single appearance flat schedule, and (3uw)w a multiple appearance looped schedule. 1 A single appearance looped schedule is not possible for this graph. <p> The schedules uwuwuww and (3uw)w produce identical execution results. 1 The notation in the looped schedule is such that the 3 applies to all sub sequent nodes until the right parenthesis is reached <ref> [2] </ref>. 6 The buffer space required by static schedulers is depen-dent on the particular scheduling algorithm. For example, assume the input queue to node u in Figure 1 is labeled q 0 and that it is attached to a periodic external device i. <p> Buffer Requirements In this section we present the buffer requirements of each queue in the mobile satellite receiver application and compare the total memory requirements of our synthesis of the application with the bounds reported in <ref> [18, 2] </ref>. We derive the bounds for one queue as an example and refer the reader to Table 2 (and [9]) for the buffer bounds on the remaining queues. The analysis is abstract in that all tokens are assumed to be the same size. <p> The queues attached to input or output devices are omitted from the table since these queues were ignored in the buffer calculations of <ref> [18, 2] </ref>. <p> The minimum buffer requirement possible for the INMARSAT graph is 1,545 tokens (including the graph input and output queues) derived by summing prd (q)cns (q) gcd (prd (q);cns (q)) = max (prd (q); cns (q)) over all queues in the graph <ref> [2] </ref>. <p> For example, once the single appearance looped schedule (24 (11 (4A)B)CGH I (11 (4D)E)F KLM (10N SJ T U P )) QRV (240W ) produced by the off-line Acyclic Pairwise Grouping of Adjacent Nodes (APGAN) scheduling algorithm of <ref> [2] </ref> begins, additional tokens will accumulate on the input queues, which may increase the total buffer space required. Thus, the total buffer space required for the two queues attached to input devices is at least 2,112 tokens for the APGAN schedule.
Reference: [3] <author> Chatterjee, S., Strosnider, J., </author> <title> Distributed Pipeline Scheduling: A Framework for Distributed, Heterogeneous Real-Time System Design, </title> <journal> The Computer Journal (British Computer Society), </journal> <volume> Vol. 38, No. 4, </volume> <year> 1995. </year>
Reference-contexts: For this, we appeal to real-time scheduling theory. Typically a processing graph is mapped to a set of tasks according to a model of real-time execution <ref> [3, 7, 10, 14, 16, 21, 19, 20] </ref>. The schedulability conditions for the model are used to see if the graph fits on the processor i.e., to see if enough processing capacity is available to guarantee real-time execution to all tasks. <p> From the real-time literature, PGM graphs are most closely related to the Logical Application Stream Model (LASM) <ref> [3, 4] </ref>. Our work improves on the analysis of LASM graphs by not requiring periodic execution of the nodes in the graph. Instead, graph execution is modeled with the Rate-Based Execution (RBE) process model [11] (a generalization of the sporadic process model) to more accurately predict processor demand.
Reference: [4] <author> Chatterjee, S., Strosnider, J., </author> <title> A Generalized Admissions Control Strategy for Heterogeneous, Distributed Multimedia Systems, </title> <booktitle> Proc. of ACM Mutlimedia 95, </booktitle> <month> Nov. </month> <year> 1995. </year>
Reference-contexts: From the real-time literature, PGM graphs are most closely related to the Logical Application Stream Model (LASM) <ref> [3, 4] </ref>. Our work improves on the analysis of LASM graphs by not requiring periodic execution of the nodes in the graph. Instead, graph execution is modeled with the Rate-Based Execution (RBE) process model [11] (a generalization of the sporadic process model) to more accurately predict processor demand.
Reference: [5] <author> Berry, G., Cosserat, L., </author> <title> The ESTEREL Synchronous Programming Language and its Mathematical Semantics, </title> <booktitle> Lecture Notes in Computer Science, Vol. 197 Seminar on Con-currency, </booktitle> <publisher> Springer Verlag, </publisher> <address> Berlin, </address> <year> 1985. </year>
Reference-contexts: An affirmative result after testing the scheduling condition means that the processor has enough capacity to execute the graph such that latency and buffer 3 requirements can be guaranteed. (Verifying and managing memory requirements are addressed in x4.) 3.1. Node Execution Rates We assume the strong synchrony hypothesis of <ref> [5] </ref> to introduce the concept of node execution rates. Under the strong synchrony hypothesis, we assume the graph executes on an infinitely fast machine and each node takes no time to execute the system instantly reacts to external stimuli.
Reference: [6] <author> Bondy, J.A., Murty, U.S.R., </author> <title> Graph Theory with Applications, </title> <publisher> North Holland, </publisher> <year> 1976. </year>
Reference-contexts: Our contributions are summarized in x6. 2. Notation and the Processing Graph Method The notation and terminology of this paper, for the most part, is an amalgamation of the notation and terminology used in <ref> [6] </ref> and [2]. A processing graph is formally described as a directed graph (or digraph) G = (V; E; ).
Reference: [7] <author> Gerber, R., Seongsoo, H., Saksena, M., </author> <title> Guaranteeing Real-Time Requirements with Resource-Based Calibration of Periodic Processes, </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 21(7), </volume> <month> July </month> <year> 1995. </year>
Reference-contexts: For this, we appeal to real-time scheduling theory. Typically a processing graph is mapped to a set of tasks according to a model of real-time execution <ref> [3, 7, 10, 14, 16, 21, 19, 20] </ref>. The schedulability conditions for the model are used to see if the graph fits on the processor i.e., to see if enough processing capacity is available to guarantee real-time execution to all tasks.
Reference: [8] <author> Goddard, S., Jeffay, K. </author> <title> Analyzing the Real-Time Properties of a Dataflow Execution Paradigm using a Synthetic Aperture Radar Application, </title> <booktitle> Proc. IEEE Real-Time Technology and Applications Symposium, </booktitle> <month> June </month> <year> 1997, </year> <pages> pp. 60-71. </pages>
Reference-contexts: We have selected PGM as our processing graph model since it is a general and widely used paradigm. Our previous work on the synthesis of real-time uniprocessor systems from PGM was based on simple PGM graphs called chains <ref> [1, 8] </ref>. In this paper, we extend the analyses developed for chains to handle directed acyclic graphs. In addition, we present new methods for deriving the memory needs of a common class of acyclic PGM graphs executed using the same simple, preemptive, earliest deadline first (EDF) scheduler of [8]. <p> In this paper, we extend the analyses developed for chains to handle directed acyclic graphs. In addition, we present new methods for deriving the memory needs of a common class of acyclic PGM graphs executed using the same simple, preemptive, earliest deadline first (EDF) scheduler of <ref> [8] </ref>. To illustrate these concepts and to quantify the memory savings achievable in a real application, we analyze an existing processing graph for a mobile receiver in a commercial satellite-based communication and navigational system known as INMARSAT (International Maritime Satellite). <p> As shown in <ref> [8] </ref>, when the deadline for each node is greater than or equal to its predecessor's deadline, a scheduling technique called release time inheritance can be used to minimize latency. <p> Released tasks are scheduled with the RBE-EDF scheduling algorithm a simple, preemptive, EDF scheduler using deadline assignment function (3.4) with release time inheritance. The feasibility of an RBE task set can be determined with (3.5) <ref> [8] </ref>. Notice that (3.5) reduces to the simple Liu & Lay-land [12] EDF feasibility condition of U 1 when x i = 1 and d i = y i . Lemma 3.4. <p> T will be feasible if and only if 8L &gt; 0; L i=1 y i x i e i (3.5) where f (a) = ( 0 if a &lt; 0 Sufficiency of (3.5) was established in <ref> [8] </ref> by showing that the preemptive EDF scheduling algorithm can schedule releases of the tasks in T without a task missing a deadline if the task set satisfies (3.5). <p> This flexibility in scheduling comes at a price; it makes it difficult to derive tight bounds for the buffer requirements of a queue. In <ref> [8] </ref>, we presented functions to bound the buffer requirements of queues in chains scheduled with variations of the RBE-EDF algorithm. <p> Unfortunately, the execution rules for PGM nodes with multiple input queues are such that one input queue may be over threshold long before another input queue, and the equations derived in <ref> [8] </ref> to bound queue buffers do not apply to general PGM graphs. In the general case, the buffer bounds that we can derive are much too loose to be useful (though they are valid upper bounds).
Reference: [9] <author> Goddard, S., </author> <title> On the Management of Latency and Memory Requirements in the Synthesis of Distributed Real-Time Signal Processing Systems from Processing Graphs, </title> <type> Ph.D. Dissertation, </type> <institution> University of North Carolina at Chapel Hill, </institution> <year> 1998. </year>
Reference-contexts: For signal processing graphs, latency is the time between when a sensor produces a data token and when the graph outputs the processed signal. This paper is part of a larger body of work <ref> [9] </ref> that creates a framework for evaluating and managing processor demand, latency, and memory usage in the synthesis of distributed real-time signal processing systems from the U.S. Navy's coarse-grain Processing Graph Method (PGM) [15]. <p> We start with chains and work up to general acyclic graphs in the derivation of node execution rates. Proofs for the theorems presented in this paper a can be found in <ref> [9] </ref>. Theorem 3.1. Let i ; w be a PGM chain such that i 2 I (the set of input nodes), u; v 2 fi ; wg with (q) = (u; v), and R i = (x i ; y i ). <p> Managing Memory Requirements The three primary uses of memory in an embedded signal processing system are (1) scheduler state space, (2) code space for each node, and (3) buffer space for intermediate results stored on graph edges. In <ref> [9] </ref>, we argue that the memory requirements for (1) and (2) are similar for either statically or dynamically scheduled implementations. Here, we only address buffer space requirements. The canonical approach to managing the memory requirements of the graph edges is to use static scheduling. <p> In contrast to using off-line scheduling algorithms to 2 Due to space limitations, we are unable to present the functions that derive S and s w see <ref> [9] </ref>. manage memory requirements, our approach is to use a simple, dynamic, on-line scheduler for graph execution. One of the advantages of the RBE model over other dynamic scheduling algorithms is that it provides great flexibility in describing when nodes will execute. <p> We derive the bounds for one queue as an example and refer the reader to Table 2 (and <ref> [9] </ref>) for the buffer bounds on the remaining queues. The analysis is abstract in that all tokens are assumed to be the same size. Let a be the label for the queue joining nodes A and B in the application graph of Figure 4 on page 9.
Reference: [10] <author> Jeffay, K., </author> <title> The Real-Time Producer/Consumer Paradigm: A paradigm for the construction of efficient, predictable real-time systems, </title> <booktitle> Proc. of ACM/SIGAPP Symp. on Appl. Computing, </booktitle> <month> Feb. </month> <year> 1993, </year> <pages> pp. 796-804. </pages>
Reference-contexts: For this, we appeal to real-time scheduling theory. Typically a processing graph is mapped to a set of tasks according to a model of real-time execution <ref> [3, 7, 10, 14, 16, 21, 19, 20] </ref>. The schedulability conditions for the model are used to see if the graph fits on the processor i.e., to see if enough processing capacity is available to guarantee real-time execution to all tasks. <p> Forcing periodic execution of all graph nodes adds latency to the processed signal, but simplifies the analysis of memory requirements. Restricted PGM graphs can also be represented by the dataflow graph models used in the Software Automation for Real-Time Operations (SARTOR) project [14] and the Real-Time Producer/Consumer (RTP/C) paradigm <ref> [10] </ref>. Unfortunately, neither of these paradigms correctly model the execution of general PGM graphs. Our goal, as with the SARTOR project, is to demonstrate that we can apply real-time scheduling results to real-life applications.
Reference: [11] <author> Jeffay, K., Bennett, D. </author> <title> A Rate-Based Execution Abstraction For Multimedia Computing, </title> <booktitle> Lecture Notes in Computer Science, </booktitle> <editor> T.D.C. Little and R. Gusella eds., </editor> <volume> Vol. 1018, </volume> <publisher> Springer-Verlag, </publisher> <address> Heidelberg, </address> <year> 1995, </year> <pages> pp 65-75. </pages>
Reference-contexts: Our work improves on the analysis of LASM graphs by not requiring periodic execution of the nodes in the graph. Instead, graph execution is modeled with the Rate-Based Execution (RBE) process model <ref> [11] </ref> (a generalization of the sporadic process model) to more accurately predict processor demand. The RBE process model allows node execution at an average (but deterministic) rate, which provides a more natural representation of node execution for PGM graphs. <p> Synthesis Method Our synthesis method involves 3 steps: i) identifying node execution rates, ii) mapping each node to a task in the Rate-Based Execution (RBE) task model <ref> [11] </ref>, and iii) verifying latency and memory requirements. <p> RBE Task Model Once node execution rates have been established, the nodes of a graph can be mapped to real-time tasks. Unfortunately since nodes are neither periodic nor sporadic, even when the source is periodic, most task models from the literature are inapplicable. The Rate-Based Execution (RBE) paradigm <ref> [11] </ref>, however, does provide a natural description of node executions in an implementation of processing graphs. This section provides a brief overview of the RBE task model. RBE is a general task model consisting of a collection of independent processes specified by four parameters: (x; y; d; e).
Reference: [12] <author> Liu, C., Layland, J., </author> <title> Scheduling Algorithms for multiprogramming in a Hard-Real-Time Environment, </title> <journal> Journal of the ACM, </journal> <volume> Vol 30., </volume> <month> Jan. </month> <year> 1973, </year> <pages> pp. 46-61. </pages>
Reference-contexts: Released tasks are scheduled with the RBE-EDF scheduling algorithm a simple, preemptive, EDF scheduler using deadline assignment function (3.4) with release time inheritance. The feasibility of an RBE task set can be determined with (3.5) [8]. Notice that (3.5) reduces to the simple Liu & Lay-land <ref> [12] </ref> EDF feasibility condition of U 1 when x i = 1 and d i = y i . Lemma 3.4.
Reference: [13] <author> Lee, E.A., Messerschmitt, D.G., </author> <title> Static Scheduling of Synchronous Data Flow Programs for Digital Signal Processing, </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-36(1), </volume> <month> Jan. </month> <year> 1987, </year> <pages> pp. 24-35. </pages>
Reference-contexts: The canonical approach to minimiz-ing memory requirements for the graph edges is to use static scheduling. Static node execution schedules are created offline and then executed on a periodic basis. Numerous static scheduling algorithms have been created to minimize memory requirements <ref> [13, 17, 22, 18, 2] </ref>. The primary trade-off made by static schedulers is the storage requirement and execution complexity of the schedule vs. the storage requirement of data in the graph edges. Typically, minimal buffer space requires increased state space for the scheduler.
Reference: [14] <author> Mok, A.K., Sutanthavibul, S., </author> <title> Modeling and Scheduling of Dataflow Real-Time Systems, </title> <booktitle> Proc. of the IEEE Real-Time Systems Symposium, </booktitle> <month> Dec. </month> <year> 1985, </year> <pages> pp. 178-187. </pages>
Reference-contexts: For this, we appeal to real-time scheduling theory. Typically a processing graph is mapped to a set of tasks according to a model of real-time execution <ref> [3, 7, 10, 14, 16, 21, 19, 20] </ref>. The schedulability conditions for the model are used to see if the graph fits on the processor i.e., to see if enough processing capacity is available to guarantee real-time execution to all tasks. <p> Forcing periodic execution of all graph nodes adds latency to the processed signal, but simplifies the analysis of memory requirements. Restricted PGM graphs can also be represented by the dataflow graph models used in the Software Automation for Real-Time Operations (SARTOR) project <ref> [14] </ref> and the Real-Time Producer/Consumer (RTP/C) paradigm [10]. Unfortunately, neither of these paradigms correctly model the execution of general PGM graphs. Our goal, as with the SARTOR project, is to demonstrate that we can apply real-time scheduling results to real-life applications. Unfortunately, the techniques developed in [14] cannot be applied here <p> Real-Time Operations (SARTOR) project <ref> [14] </ref> and the Real-Time Producer/Consumer (RTP/C) paradigm [10]. Unfortunately, neither of these paradigms correctly model the execution of general PGM graphs. Our goal, as with the SARTOR project, is to demonstrate that we can apply real-time scheduling results to real-life applications. Unfortunately, the techniques developed in [14] cannot be applied here without introducing additional latency since the execution of PGM nodes do not follow the periodic execution model assumed in [14]. Like the RTP/C paradigm, we use the structure of the graph to help specify execution rates of the processes that implement nodes in the graph. <p> Our goal, as with the SARTOR project, is to demonstrate that we can apply real-time scheduling results to real-life applications. Unfortunately, the techniques developed in <ref> [14] </ref> cannot be applied here without introducing additional latency since the execution of PGM nodes do not follow the periodic execution model assumed in [14]. Like the RTP/C paradigm, we use the structure of the graph to help specify execution rates of the processes that implement nodes in the graph. However, PGM graphs are capable of supporting much more sophisticated data flow applications than RTP/C.
Reference: [15] <editor> Processing Graph Method Specification, </editor> <title> prepared by NRL for use by the Navy Standard Signal Processing Program Office (PMS-412), </title> <note> Version 1.0, </note> <month> Dec. </month> <year> 1987. </year>
Reference-contexts: This paper is part of a larger body of work [9] that creates a framework for evaluating and managing processor demand, latency, and memory usage in the synthesis of distributed real-time signal processing systems from the U.S. Navy's coarse-grain Processing Graph Method (PGM) <ref> [15] </ref>. Here, we demonstrate the management of memory requirements in the synthesis of a real-time uniprocessor system from acyclic processing graphs developed with PGM. We show that dynamic, on-line scheduling can achieve near minimal memory requirements.
Reference: [16] <author> Ramamritham, K., </author> <title> Allocation and Scheduling of Precedence-Related Periodic Tasks, </title> <journal> IEEE Trans. on Parallel and Dist. Syst., </journal> <volume> 6(4), </volume> <month> April </month> <year> 1995, </year> <pages> pp 412-420. </pages>
Reference-contexts: For this, we appeal to real-time scheduling theory. Typically a processing graph is mapped to a set of tasks according to a model of real-time execution <ref> [3, 7, 10, 14, 16, 21, 19, 20] </ref>. The schedulability conditions for the model are used to see if the graph fits on the processor i.e., to see if enough processing capacity is available to guarantee real-time execution to all tasks.
Reference: [17] <author> Ritz, S., Meyer, H., </author> <title> Exploring the design space of a DSP-based mobile satellite receiver, </title> <booktitle> Proc. of ICSPAT 94, </booktitle> <address> Dallas, TX, </address> <month> Oct. </month> <year> 1994. </year>
Reference-contexts: The canonical approach to minimiz-ing memory requirements for the graph edges is to use static scheduling. Static node execution schedules are created offline and then executed on a periodic basis. Numerous static scheduling algorithms have been created to minimize memory requirements <ref> [13, 17, 22, 18, 2] </ref>. The primary trade-off made by static schedulers is the storage requirement and execution complexity of the schedule vs. the storage requirement of data in the graph edges. Typically, minimal buffer space requires increased state space for the scheduler.
Reference: [18] <author> Ritz, R., Willems, M., Meyer, H., </author> <title> Scheduling for Optimum Data Memory Compaction in Block Diagram Oriented Software Synthesis, </title> <booktitle> Proc. of ICASSP 95, </booktitle> <address> Detroit, MI, </address> <month> May </month> <year> 1995, </year> <pages> pp. 133-143. </pages>
Reference-contexts: The canonical approach to minimiz-ing memory requirements for the graph edges is to use static scheduling. Static node execution schedules are created offline and then executed on a periodic basis. Numerous static scheduling algorithms have been created to minimize memory requirements <ref> [13, 17, 22, 18, 2] </ref>. The primary trade-off made by static schedulers is the storage requirement and execution complexity of the schedule vs. the storage requirement of data in the graph edges. Typically, minimal buffer space requires increased state space for the scheduler. <p> We compare the memory needs of the mobile satellite receiver application executed with our on-line scheduler to the memory needs of the same application executed using state-of-the-art, off-line, static schedulers presented in <ref> [18] </ref> and [2]. From the real-time literature, PGM graphs are most closely related to the Logical Application Stream Model (LASM) [3, 4]. Our work improves on the analysis of LASM graphs by not requiring periodic execution of the nodes in the graph. <p> Buffer Requirements In this section we present the buffer requirements of each queue in the mobile satellite receiver application and compare the total memory requirements of our synthesis of the application with the bounds reported in <ref> [18, 2] </ref>. We derive the bounds for one queue as an example and refer the reader to Table 2 (and [9]) for the buffer bounds on the remaining queues. The analysis is abstract in that all tokens are assumed to be the same size. <p> The queues attached to input or output devices are omitted from the table since these queues were ignored in the buffer calculations of <ref> [18, 2] </ref>. <p> Thus, the total buffer space required for the two queues attached to input devices is at least 2,112 tokens for the APGAN schedule. The single appearance flat schedule (1056A)(264B)(24C)(24G)(24H )(24I )(240J )(1056D) (240U )V QR (240W ) of <ref> [18] </ref> also requires a delay of 1054 periods of the input devices. For this schedule, however, no more than 1056 tokens will accumulate on an input queue since the execution time of A must be less than the period of the external source for the schedule to be feasible.
Reference: [19] <author> Sun, J., Liu, J., </author> <title> Synchronization Protocols in Distributed Real-Time Systems, </title> <booktitle> Proc Intl. Conference on Dist. Computing Syst., </booktitle> <month> May, </month> <year> 1996. </year>
Reference-contexts: For this, we appeal to real-time scheduling theory. Typically a processing graph is mapped to a set of tasks according to a model of real-time execution <ref> [3, 7, 10, 14, 16, 21, 19, 20] </ref>. The schedulability conditions for the model are used to see if the graph fits on the processor i.e., to see if enough processing capacity is available to guarantee real-time execution to all tasks.
Reference: [20] <author> Sun, J., Liu, J., </author> <title> Bounding Completion Times of Jobs with Arbitrary Release Times and Variable Execution Times, </title> <booktitle> Proc. of the IEEE Real-Time Systems Symposium, </booktitle> <month> Dec. </month> <year> 1996, </year> <pages> pp. 2-12. </pages>
Reference-contexts: For this, we appeal to real-time scheduling theory. Typically a processing graph is mapped to a set of tasks according to a model of real-time execution <ref> [3, 7, 10, 14, 16, 21, 19, 20] </ref>. The schedulability conditions for the model are used to see if the graph fits on the processor i.e., to see if enough processing capacity is available to guarantee real-time execution to all tasks.
Reference: [21] <author> Spuri, M., Stankovic, J.A., </author> <title> How to Integrate Precedence Constraints and Shared Resources in Real-Time Scheduling, </title> <journal> IEEE Transactions on Computers, </journal> <volume> Vol. 43, No. 12, </volume> <month> Dec. </month> <year> 1994, </year> <pages> pp. 1407-1412. </pages>
Reference-contexts: For this, we appeal to real-time scheduling theory. Typically a processing graph is mapped to a set of tasks according to a model of real-time execution <ref> [3, 7, 10, 14, 16, 21, 19, 20] </ref>. The schedulability conditions for the model are used to see if the graph fits on the processor i.e., to see if enough processing capacity is available to guarantee real-time execution to all tasks.
Reference: [22] <author> Zivojnovic, V., Ritz, S., Meyer, H., </author> <title> High Performance DSP Software Using Data-Flow Graph Transformations, </title> <booktitle> Proc. of ASILOMAR 94, </booktitle> <month> Nov. </month> <year> 1994. </year> <month> 12 </month>
Reference-contexts: The canonical approach to minimiz-ing memory requirements for the graph edges is to use static scheduling. Static node execution schedules are created offline and then executed on a periodic basis. Numerous static scheduling algorithms have been created to minimize memory requirements <ref> [13, 17, 22, 18, 2] </ref>. The primary trade-off made by static schedulers is the storage requirement and execution complexity of the schedule vs. the storage requirement of data in the graph edges. Typically, minimal buffer space requires increased state space for the scheduler.
References-found: 22

