URL: ftp://ftp.cs.utexas.edu/pub/boyer/diss/shults.ps.Z
Refering-URL: http://www.cs.utexas.edu/users/boyer/students.html
Root-URL: http://www.cs.utexas.edu
Title: by  
Author: Benjamin Price Shults 
Date: 1997  
Note: Copyright  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> R. Abraham, J. E. Marsden, and T. Ratiu. </author> <title> Manifolds, Tensor Analysis, and Applications. </title> <publisher> Springer-Verlag, </publisher> <address> second edition, </address> <year> 1988. </year>
Reference-contexts: successfully proved this theorem. 1 Among others, Ingo Dahn has tried to prove this example using several resolution and tableau automated theorem proving systems including Otter and Setheo. 2 The theorem can be found, for example, as an exercise in Chapter 1 of Abraham-Marsden-Ratiu's text Manifolds, Tensor Analysis, and Applications <ref> [1] </ref>. We want to prove (8S)(Hausdorff (S) closed-in (top-to-class (diagonal (S fi t S)); S fi t S)) We present here a simple and natural formalization of the needed knowledge. The following eight textbook-level theorems turn into 12 sequents in the knowledge base.
Reference: [2] <author> Peter B. Andrews. </author> <title> An Introduction to Mathematical Logic and Type Theory: To Truth Through Proof. </title> <publisher> Academic Press, </publisher> <year> 1986. </year>
Reference-contexts: However, when the language is extended in this way, reasoning typically becomes much more complex. Several methods have been developed for handling higher-order reasoning. Some have developed provers for full higher-order logic <ref> [2, 4] </ref>. Others have implemented Godel's axioms in order to keep set theory completely within first-order logic [102]. Others have despaired of handling the problem automatically and resorted to proof checkers [96]. <p> If IPR is in 122 Show that if the product of (_X) over the index set (_A) is locally compact then for every _B the _Bth coordinate space is locally compact <ref> [2] </ref> PROMOTE Suppose that the product of (_X) over the index set (_A) is locally compact and show that for every _B the _Bth coordinate space is locally compact [3] CONSIDER Suppose that the product of (_X) over the index set (_A) is locally compact and show that the (_B)th coordinate <p> force an equality substitution is in the case that a term is defined in the knowledge base and the user wants the 124 We have shown if the product of (_X) over the index set (_A) is locally compact then for every _B, the _Bth coordinate space is locally compact <ref> [2] </ref> PROMOTE If we suppose the product of (_X) over the index set (_A) is locally compact then we have shown for every _B, the _Bth coordinate space is locally compact [3] CONSIDER If we suppose the product of (_X) over the index set (_A) is locally compact then we have <p> from A to B 142 We have shown: if X 2 is path connected and x 0 is a member of X 2 and x 1 is a member of X 2 then 1 (X 2 ; x 0 ) and 1 (X 2 ; x 1 ) are isomorphic <ref> [2] </ref> PROMOTE If we suppose all of the following: 1.
Reference: [3] <author> Peter B. Andrews, Matthew Bishop, Sunil Issar, Dan Nesmith, Frank Pfenning, and Hongwei Xi. TPS: </author> <title> A theorem proving system for classical type theory. </title> <type> Technical Report 94-166, </type> <institution> Department of Mathematics, Carnegie Mellon University, </institution> <year> 1994. </year>
Reference-contexts: of (_X) over the index set (_A) is locally compact then for every _B the _Bth coordinate space is locally compact [2] PROMOTE Suppose that the product of (_X) over the index set (_A) is locally compact and show that for every _B the _Bth coordinate space is locally compact <ref> [3] </ref> CONSIDER Suppose that the product of (_X) over the index set (_A) is locally compact and show that the (_B)th coordinate space is locally compact [4] (1) APPLY-THEOREM-SPLIT Suppose that the product of (_X) over the index set (_A) is locally compact and show that one of the following is <p> over the index set (_A) is locally compact then for every _B, the _Bth coordinate space is locally compact [2] PROMOTE If we suppose the product of (_X) over the index set (_A) is locally compact then we have shown for every _B, the _Bth coordinate space is locally compact <ref> [3] </ref> CONSIDER If we suppose the product of (_X) over the index set (_A) is locally compact then we have shown the (_B)th coordinate space is locally compact [4] (1) APPLY-THEOREM-SPLIT We have shown that the (_B)th projection function is an open function from the product of (_X) over the index <p> X 2 is path connected 2. x 1 is a member of X 2 3. x 0 is a member of X 2 then we have shown: 1 (X 2 ; x 0 ) and 1 (X 2 ; x 1 ) are isomorphic <ref> [3] </ref> APPLY-THEOREM If we suppose: for some P , P is a path from x 0 to x 1 in X 2 then we have shown: 1 (X 2 ; x 0 ) and 1 (X 2 ; x 1 ) are isomorphic [4] CONSIDER If we suppose: P 0 is <p> Methods such as higher-order unification used in Andrews' TPS prover <ref> [3] </ref> would need to be incorporated into a prover that we want to discover this kind of proof without help. This is an area where much more work is needed. Finding examples and counter-examples.
Reference: [4] <author> Peter B. Andrews, Dale A. Miller, Eve Longini Cohen, and Frank Pfenning. </author> <title> Automating higher-order logic. </title> <editor> In W. W. Bledsoe and D. W. Loveland, editors, </editor> <title> Automatic Theorem Proving: After 25 Years, </title> <booktitle> volume 29 of Contemporary Mathematics, </booktitle> <pages> pages 169-192. </pages> <publisher> American Mathematical Society, </publisher> <year> 1984. </year>
Reference-contexts: However, when the language is extended in this way, reasoning typically becomes much more complex. Several methods have been developed for handling higher-order reasoning. Some have developed provers for full higher-order logic <ref> [2, 4] </ref>. Others have implemented Godel's axioms in order to keep set theory completely within first-order logic [102]. Others have despaired of handling the problem automatically and resorted to proof checkers [96]. <p> Quaife used the Otter program of Wos and McCune to prove many theorems of set theory based on Godel's first-order axioms [102]. Peter Andrews developed a completely automatic theorem prover for full higher-order logic <ref> [4] </ref>. The fact that his prover, TPS, uses full higher-order logic allows many complex statements about sets and functions to be stated more simply than is possible in the language of first-order logic with set-theory. Human-like techniques. <p> product of (_X) over the index set (_A) is locally compact and show that for every _B the _Bth coordinate space is locally compact [3] CONSIDER Suppose that the product of (_X) over the index set (_A) is locally compact and show that the (_B)th coordinate space is locally compact <ref> [4] </ref> (1) APPLY-THEOREM-SPLIT Suppose that the product of (_X) over the index set (_A) is locally compact and show that one of the following is true: 1. <p> F is an open function from the product of (_X) over the index set (_A) onto the (_B)th coordinate space 2. the (_B)th coordinate space is locally compact <ref> [4] </ref> (2) APPLY-THEOREM-SPLIT Suppose that the product of (_X) over the index set (_A) is locally compact and show that one of the following is true: 1. <p> over the index set (_A) is locally compact then we have shown for every _B, the _Bth coordinate space is locally compact [3] CONSIDER If we suppose the product of (_X) over the index set (_A) is locally compact then we have shown the (_B)th coordinate space is locally compact <ref> [4] </ref> (1) APPLY-THEOREM-SPLIT We have shown that the (_B)th projection function is an open function from the product of (_X) over the index set (_A) onto the (_B)th coordinate space [4] (2) APPLY-THEOREM-SPLIT We have shown that the (_B)th projection function is a continuous function from the product of (_X) over <p> (_X) over the index set (_A) is locally compact then we have shown the (_B)th coordinate space is locally compact <ref> [4] </ref> (1) APPLY-THEOREM-SPLIT We have shown that the (_B)th projection function is an open function from the product of (_X) over the index set (_A) onto the (_B)th coordinate space [4] (2) APPLY-THEOREM-SPLIT We have shown that the (_B)th projection function is a continuous function from the product of (_X) over the index set (_A) onto the (_B)th coordinate space 125 Since we know that the product of (_X) over the index set (_A) is locally compact and we are trying <p> 2 ; x 1 ) are isomorphic [3] APPLY-THEOREM If we suppose: for some P , P is a path from x 0 to x 1 in X 2 then we have shown: 1 (X 2 ; x 0 ) and 1 (X 2 ; x 1 ) are isomorphic <ref> [4] </ref> CONSIDER If we suppose: P 0 is a path from x 0 to x 1 in X 2 then we have shown: 1 (X 2 ; x 0 ) and 1 (X 2 ; x 1 ) are isomorphic [5] APPLY-THEOREM If we suppose: P 0 -hat is an isomorphism
Reference: [5] <author> O. W. Astrachan and M. E. Stickel. </author> <title> Caching and lemmaizing in model elimination theorem provers. </title> <booktitle> In Proc. 11th Conference on Automated Deduction, volume 607 of Lecture Notes in Artificial Intelligence, </booktitle> <pages> pages 224-238. </pages> <publisher> Springer Verlag, </publisher> <year> 1992. </year>
Reference-contexts: and 1 (X 2 ; x 1 ) are isomorphic [4] CONSIDER If we suppose: P 0 is a path from x 0 to x 1 in X 2 then we have shown: 1 (X 2 ; x 0 ) and 1 (X 2 ; x 1 ) are isomorphic <ref> [5] </ref> APPLY-THEOREM If we suppose: P 0 -hat is an isomorphism from 1 (X 2 ; x 0 ) to 1 (X 2 ; x 1 ) then we have shown: 1 (X 2 ; x 0 ) and 1 (X 2 ; x 1 ) are isomorphic 143 The proof <p> In late 1993 and early 1994, I implemented the congruence closure technique [85, 105] into the unifier. It was at that time that the more complex equality problems were solved by the prover. At the same time, I experimented with the sequent calculus and its variations including "lemmaizing" <ref> [5] </ref>, mixed universal and rigid variables [18], various ffi-rules [8], equality methods [18, 85] and unification strategies. In those early days, the prover was tested on Pelletier's problems [97] and was quite successful, although not enough to be competitive with the provers that win the international contests.
Reference: [6] <author> Owen Astrachan. METEOR: </author> <title> Exploring model elimination theorem proving. </title> <journal> Journal of Automated Reasoning, </journal> <volume> 13(3) </volume> <pages> 283-296, </pages> <year> 1994. </year>
Reference-contexts: While higher-order languages are more convenient for expressing mathematical facts, the reasoning in higher-order languages is much less tractable. Many theorem proving programs use tableaux and related methods. PROTEIN [14], 3 T A P [19], lean-T A P [16], SETHEO [82], MGTP and it variants [66, 65], METEOR <ref> [6] </ref>, Parthenon [35] and PTTP [115] are some of the better known systems. Most existing systems and calculi use clausal form for storing the theory. Some save some space by breaking a formula only to negation normal form [63]. This form still has the disadvantages associated with Skolem constants. <p> In this calculus, only the formulas themselves are entered. No indexing or additional information is provided. The "-rule is closely related to various strategies used in clausal tableaux [81]. The "- rule is distinct from existing rules for clausal tableau expansion in various ways. METEOR <ref> [6] </ref>, Parthenon [35], PTTP [115], SETHEO [82] and PROTEIN [14] use calculi closely related to model elimination. Therefore, they obey the connection condition. In a clausal context, the "-rule only uses the weak connection condition (set-of-support) as in Hahnle's ordered 147 tableaux [64].
Reference: [7] <author> Matthias Baaz, Uwe Egly, and Christian G. Fermuller. </author> <title> Lean induction principles for tableaux. </title> <editor> In Didier Galmiche, editor, </editor> <title> Automated Reasoning with Analytic Tableaux and Related Methods, </title> <booktitle> volume 1227 of Lecture Notes in Artificial Intelligence, </booktitle> <pages> pages 62-75. </pages> <publisher> Springer-Verlag, </publisher> <month> May </month> <year> 1997. </year> <pages> 167 168 </pages>
Reference-contexts: Boyer, Moore and Kaufmann have developed a series of provers for this purpose [38]. Alan Bundy's group developed their own "rippling" techniques for proving theorems by induction [41]. Recently, Baaz, et. al. developed the incorporation of induction schemata into the tableau method in a tractable way <ref> [7] </ref>. Rewriting and equality. Particularly in algebraic problems, a lot of the work in proving a statement involves writing terms in a form that is more useful. This kind of reasoning is called rewriting. This is a special area of reasoning in which very successful techniques have been developed. <p> See Example 4.5. Baaz, Egly and Fermuller have illustrated the usefulness of tableaux in the context of applying axiom schemata by applying the idea to induction and similar schemata <ref> [7] </ref>. In their paper, they argue the advantages of analytic or on-the-fly methods such as tableaux over preprocessed normal-form methods such as resolution. The same argument applies here. <p> For information on successful provers in this area, reference the Boyer-Moore provers [36] and the rippling provers [41]. Matthias Baaz et. al. recently demonstrated an excellent way of implementing induction and related inference rules in a tableau based prover <ref> [7] </ref>. Complexity. Finally, there is the simple fact that some proofs are just too long and complex to be handled by existing methods with existing commonly used hardware. Proof planning and analogy could help this problem by keeping the search space smaller.
Reference: [8] <author> Matthias Baaz and Christian G. Fermuller. </author> <title> Non-elementary speedups between different versions of tableaux. </title> <editor> In Peter Baumgartner, Reiner Hahnle, and Joachim Posegga, editors, </editor> <booktitle> Proc. 4th Workshop on Deduction with Tableaux and Related Methods, St. Goar, </booktitle> <address> Germany, </address> <publisher> LNCS 918, </publisher> <pages> pages 217-230. </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference-contexts: It is this procedure that is proved complete and sound elsewhere [113, 54]. This completes the description of the analytic tableau method. The method is complete, i.e., any true sentence can be proved by the method [54], and there are various methods of making it more efficient <ref> [8, 20, 82, 94] </ref>. We emphasize how easy it is to translate proofs in this system into natural, readable proofs. Section 5.2 gives some examples of proofs translated automatically into English by the IPR program. <p> It was at that time that the more complex equality problems were solved by the prover. At the same time, I experimented with the sequent calculus and its variations including "lemmaizing" [5], mixed universal and rigid variables [18], various ffi-rules <ref> [8] </ref>, equality methods [18, 85] and unification strategies. In those early days, the prover was tested on Pelletier's problems [97] and was quite successful, although not enough to be competitive with the provers that win the international contests.
Reference: [9] <author> L. Bachmair and N. Dershowitz. </author> <title> Completion for rewriting modulo a congruence. </title> <journal> Theoretical Computer Science, </journal> <volume> 67(2 </volume> & 3):173-201, 1989. 
Reference-contexts: Supposing that it is known that certain terms are equal, those equalities are automatically used to decide whether some new pair of terms are equal. This technique has been expanded, specialized and generalized by Kapur [76, 124], Bachmair <ref> [9] </ref> and Dershowitz [51]. Larry Wos and his group incorporated their own rewriting techniques into their resolution provers [122]. These methods are called demodulation and paramodulation. Another method for handling equality is called the congruence closure technique [85, 92, 105]. This method is complete for ground equality.
Reference: [10] <author> Sidney C. Bailin and Dave Barker-Plummer. Z-match: </author> <title> An inference rule for incrementally constructing set instantiations. </title> <journal> Journal of Automated Reasoning, </journal> <volume> 11(3) </volume> <pages> 391-428, </pages> <year> 1993. </year>
Reference-contexts: Another approach to this kind of reasoning is to use higher-order logics in which it is easier to express statements about sets of objects. Bledsoe's Set-Var method [30] and Bailin and Barker-Plummer's Z-match method <ref> [10] </ref> both used a slight extension to first-order logic in order to allow sets to be expressed and used more easily. Both of these methods discover sets that have the properties needed to prove many statements in set theory and real analysis. <p> His Set-Var calculus was quite successful on many interesting problems [30]. Set-Var used a rule for constructing sets that was essentially equivalent to circumscription. Many of Bledsoe's collaborators (Plummer, Brown, etc.) also worked on related problems. Bailin and Barker-Plummer's Z-match took a very similar approach to Set-Var <ref> [10] </ref>. The present work does not construct classes in any interesting way as these systems do. Frank Brown also worked on a system that proved theorems in set theory using some special inference rules [39].
Reference: [11] <author> Dave Barker-Plummer. </author> <title> Gazing: An approach to the problem of definition and lemma use. </title> <journal> Journal of Automated Reasoning, </journal> <volume> 8(3) </volume> <pages> 311-344, </pages> <year> 1992. </year>
Reference-contexts: We discussed in Chapter 1 the problems associated with selecting knowledge from a large knowledge base. But let us not give up before we begin. Indeed, computer systems have already been developed that use rather large knowledge bases and make selections automatically <ref> [11, 13, 62, 84, 123] </ref>. These systems show their strength in and, to a large extent, are limited to Horn theories and theories that have the nature of rewrite rules. Other systems exist that apply knowledge based on hints or other information from the user [36, 53, 61, 84]. <p> This actually occurs in ordinary examples such as in the proof that the diagonal of a product of a Hausdorff space with itself is closed. (See Example 6.1.) 4 When IPR applies a theorem, rather than applying some depth-first search of the knowledge base (as in Gazer <ref> [11] </ref>), IPR ranks the various ways all theorems can be applied. 5 This also differs from the usual method in clausal tableaux in which some fair procedure is applied in clause selection. <p> This form still has the disadvantages associated with Skolem constants. The non-clausal format in which knowledge is stored as described in this dissertation appears to be a novelty. The Gazer system stores knowledge in a similar but less general form. Gazer essentially assumes that the input is nearly Horn <ref> [11] </ref>. While clausal form is compatible with the "-rule|indeed clausal form allows the "-rule to be applied with the set-of-support restriction (weak connection condition) without losing completeness|we have stressed the advantages of the non-clausal form in Section 2.3. <p> That is, the existing methods that work well on large knowledge bases do not work well if the knowledge is non-Horn. Among the most closely-related work is that of Dave Barker-Plummer on his Gazing algorithm <ref> [11, 12] </ref>. The formulas entered into Gazer's knowledge base are translated into "rewrite normal form" that is similar to the form knowledge takes in this dissertation although, in Gazer, the formulas are assumed to be nearly Horn. <p> The IPR framework is a step toward solving the fetching problem. IPR is particularly weak when a proof requires a good deal of rewriting. Barker-Plummer's prover, Gazer, implements a fetcher that is stronger on rewriting problems <ref> [11] </ref> but more limited in non-Horn theories. The Gazing algorithm accomplishes this by planning the entire (if linear) proof before applying any theorem. Barker-Plummer's implementation limited the application of theorems to exclude branching altogether and limited the formulas input to the knowledge base to be nearly Horn. <p> It is this kind of decision that we would like to keep away from the non-expert user. There is also the possibility of an extension or generalization of the planning mechanism used in Gazer <ref> [11] </ref>. The techniques used by IPR for knowledge selection are local whereas if the proof is planned, then we have a global view of the proof that should help in the decision making.
Reference: [12] <author> Dave Barker-Plummer and Alex Rothenberg. </author> <title> The Gazer theorem prover. </title> <editor> In D. Kapur, editor, </editor> <booktitle> Proceedings of the Eleventh International Conference on Automated Deduction, volume 607 of Lecture Notes in Computer Science, </booktitle> <pages> pages 726-730. </pages> <publisher> Springer-Verlag, </publisher> <year> 1992. </year>
Reference-contexts: That is, the existing methods that work well on large knowledge bases do not work well if the knowledge is non-Horn. Among the most closely-related work is that of Dave Barker-Plummer on his Gazing algorithm <ref> [11, 12] </ref>. The formulas entered into Gazer's knowledge base are translated into "rewrite normal form" that is similar to the form knowledge takes in this dissertation although, in Gazer, the formulas are assumed to be nearly Horn.
Reference: [13] <author> P. Baumgartner. </author> <title> A model elimination calculus with built-in theories. </title> <editor> In Fronhofer, Hahnle, and Kaufl, editors, </editor> <title> Theorem Proving with Analytic Tableaux and Related Methods, </title> <year> 1992. </year>
Reference-contexts: We discussed in Chapter 1 the problems associated with selecting knowledge from a large knowledge base. But let us not give up before we begin. Indeed, computer systems have already been developed that use rather large knowledge bases and make selections automatically <ref> [11, 13, 62, 84, 123] </ref>. These systems show their strength in and, to a large extent, are limited to Horn theories and theories that have the nature of rewrite rules. Other systems exist that apply knowledge based on hints or other information from the user [36, 53, 61, 84]. <p> Brown's work was very closely related to Bledsoe's IMPLY prover [29] that also used knowledge essentially for rewriting. Baumgartner has worked to allow provers to use certain types of first-order theories by means of theory reasoning <ref> [13] </ref>. A theory reasoning system needs a background reasoner for the theories of interest. They are particularly useful for Horn theories. Boyer and Moore's proof checkers, which are experts at applying induction, use theories extensively.
Reference: [14] <author> P. Baumgartner and U. Furbach. </author> <title> PROTEIN: A PRO ver with a T heory E xtension I nterface. </title> <editor> In A. Bundy, editor, </editor> <booktitle> Automated Deduction - CADE-12, volume 814 of Lecture Notes in Artificial Intelligence, </booktitle> <pages> pages 769-773. </pages> <publisher> Springer, </publisher> <year> 1994. </year> <note> Available in the WWW, URL: http://www.uni-koblenz.de/ag-ki/Systems/PROTEIN/. </note>
Reference-contexts: While higher-order languages are more convenient for expressing mathematical facts, the reasoning in higher-order languages is much less tractable. Many theorem proving programs use tableaux and related methods. PROTEIN <ref> [14] </ref>, 3 T A P [19], lean-T A P [16], SETHEO [82], MGTP and it variants [66, 65], METEOR [6], Parthenon [35] and PTTP [115] are some of the better known systems. Most existing systems and calculi use clausal form for storing the theory. <p> No indexing or additional information is provided. The "-rule is closely related to various strategies used in clausal tableaux [81]. The "- rule is distinct from existing rules for clausal tableau expansion in various ways. METEOR [6], Parthenon [35], PTTP [115], SETHEO [82] and PROTEIN <ref> [14] </ref> use calculi closely related to model elimination. Therefore, they obey the connection condition. In a clausal context, the "-rule only uses the weak connection condition (set-of-support) as in Hahnle's ordered 147 tableaux [64].
Reference: [15] <author> P. Baumgartner, U. Furbach, and I. Niemela. </author> <title> Hyper Tableaux. </title> <booktitle> In JELIA 96. European Workshop on Logic in AI, </booktitle> <publisher> Springer, LNCS, </publisher> <year> 1996. </year>
Reference-contexts: If the "-rule is used in the context of a clausal form knowledge base, then the rule is very similar to other clausal tableau expansion rules but it adds fewer branches to the tableau even in the clausal case. In that sense, S-tableaux (defined below) are similar to hyper-tableaux <ref> [15] </ref> and tableaux constructed by MGTP [66], which are clausal tableaux. However, the present calculus is more symmetric and has other differences discussed in Chapter 7. <p> This makes little difference if a depth-first search is made of a unification, however, in a breadth-first search, the omission of the extra literals cuts the search space tremendously. Baumgartner's hyper-tableaux resemble S-tableaux formed by the "-rule <ref> [15] </ref>. Indeed, in some proofs the tableaux constructed by the two methods are identical.
Reference: [16] <author> B. Beckert and J. Posegga. </author> <title> leanT A P : Lean, tableau-based deduction. </title> <journal> Journal of Automated Reasoning, </journal> <volume> 15(3) </volume> <pages> 339-358, </pages> <year> 1995. </year> <month> 169 </month>
Reference-contexts: While higher-order languages are more convenient for expressing mathematical facts, the reasoning in higher-order languages is much less tractable. Many theorem proving programs use tableaux and related methods. PROTEIN [14], 3 T A P [19], lean-T A P <ref> [16] </ref>, SETHEO [82], MGTP and it variants [66, 65], METEOR [6], Parthenon [35] and PTTP [115] are some of the better known systems. Most existing systems and calculi use clausal form for storing the theory. Some save some space by breaking a formula only to negation normal form [63].
Reference: [17] <author> Bernhard Beckert. </author> <title> Adding equality to semantic tableaux. </title> <editor> In Krysia Broda, Marcello D'Agostino, Rajeev Gore, Rob Johnson, and Steve Reeves, editors, </editor> <booktitle> Proc. 3rd Workshop on Theorem Proving with Analytic Tableaux and Related Methods, </booktitle> <pages> pages 29-42, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: The problem of adding equality inference rules to tableau systems is quite different from that of adding equality to resolution systems <ref> [17, 18, 55] </ref>. Most of the work published in this area has concentrated on complete procedures. In this dissertation, we have looked for some "minimal" set of inference rules for equality that encompass a useful area of mathematical reasoning without becoming intractable.
Reference: [18] <author> Bernhard Beckert. </author> <title> A completion-based method for mixed universal and rigid E-unification. </title> <editor> In Alan Bundy, editor, </editor> <booktitle> Proc. 12th Conference on Automated Deduction CADE, Nancy/France, volume 814 of Lecture Notes in Artificial Intelligence, </booktitle> <pages> pages 678-692. </pages> <publisher> Springer-Verlag, </publisher> <year> 1994. </year>
Reference-contexts: In tableau-based methods, some of these techniques do not work the same way because variables are treated differently in tableaux. Beckert, Gallier, and others have worked on efficient methods for handling equality in tableaux <ref> [18, 55] </ref>. 14 Set theory and higher-order logic. Reasoning in most mathematical theories (or in most other realms of reasoning) involves reasoning about sets of objects. Reasoning about sets of objects in first-order logic is usually done using a well-known yet complex list of axioms called the axioms of set-theory. <p> Section 5.1.1 goes into more detail on the topic of breadth-first unification. 3.2.1 Unification Strategies For each of these strategies, there are certainly refinements that make it more efficient. For example, Beckert's mixed universal and rigid unification <ref> [18] </ref> or Oppacher and Suen's condense algorithm [94] can be incorporated into any of these strategies with some additional bookkeeping. Depth-First Backtracking Unification. In this strategy, we use a limit, q, on the number of times the fl-rule may be applied to a single formula. <p> Then the comprehension schema cannot be applied unless the substitution of fy : Ag for x is made in the second formula. However, implementing a complete procedure that makes substitutions can be very inefficient <ref> [18] </ref>. Therefore, we introduce restricted equality substitution and extensionality rules here that are not terribly expensive to apply in realistic examples and that give more strength to 86 a prover. The idea is to have a set of rules that apply equalities on-the-fly just when they are needed. <p> )(basis-of (E [ F; V ) ^ basis-of (E; W ))) 137 AND-SPLIT If we suppose: (_G1) and (_G2) are disjoint then we have shown: the cartesian product of (_G1) and (_G2) and the class associated with the diagonal of the product topological space of (_S) and (_S) are disjoint <ref> [18] </ref> (1.3) APPLY-THEOREM The following are contradictory: 1 (_G1) and (_G2) are disjoint 2 for some _Y _Y is a member of the cartesian product of (_G1) and (_G2) and _Y is a member of the class associated with the diagonal of the product topological space of (_S) and (_S) [19] <p> The problem of adding equality inference rules to tableau systems is quite different from that of adding equality to resolution systems <ref> [17, 18, 55] </ref>. Most of the work published in this area has concentrated on complete procedures. In this dissertation, we have looked for some "minimal" set of inference rules for equality that encompass a useful area of mathematical reasoning without becoming intractable. <p> It was at that time that the more complex equality problems were solved by the prover. At the same time, I experimented with the sequent calculus and its variations including "lemmaizing" [5], mixed universal and rigid variables <ref> [18] </ref>, various ffi-rules [8], equality methods [18, 85] and unification strategies. In those early days, the prover was tested on Pelletier's problems [97] and was quite successful, although not enough to be competitive with the provers that win the international contests. <p> It was at that time that the more complex equality problems were solved by the prover. At the same time, I experimented with the sequent calculus and its variations including "lemmaizing" [5], mixed universal and rigid variables [18], various ffi-rules [8], equality methods <ref> [18, 85] </ref> and unification strategies. In those early days, the prover was tested on Pelletier's problems [97] and was quite successful, although not enough to be competitive with the provers that win the international contests. In the Spring of 1994, I worked on adding rules for handling set theory.
Reference: [19] <author> Bernhard Beckert, Stefan Gerberding, Reiner Hahnle, and Werner Kernig. </author> <title> The tableau-based theorem prover 3 T A P for multiple-valued logics. </title> <booktitle> In Proceedings, 11th International Conference on Automated Deduction (CADE), </booktitle> <address> Saratoga Springs, NY, </address> <publisher> LNCS 607. Springer, </publisher> <year> 1992. </year>
Reference-contexts: [18] (1.3) APPLY-THEOREM The following are contradictory: 1 (_G1) and (_G2) are disjoint 2 for some _Y _Y is a member of the cartesian product of (_G1) and (_G2) and _Y is a member of the class associated with the diagonal of the product topological space of (_S) and (_S) <ref> [19] </ref> (1.3) CONSIDER The following are contradictory: 1 (_G1) and (_G2) are disjoint 2 (_Y0) is a member of the cartesian product of (_G1) and (_G2) 3 (_Y0) is a member of the class associated with the diagonal of the product topological space of (_S) and (_S) [20] (1.3) APPLY-THEOREM The <p> While higher-order languages are more convenient for expressing mathematical facts, the reasoning in higher-order languages is much less tractable. Many theorem proving programs use tableaux and related methods. PROTEIN [14], 3 T A P <ref> [19] </ref>, lean-T A P [16], SETHEO [82], MGTP and it variants [66, 65], METEOR [6], Parthenon [35] and PTTP [115] are some of the better known systems. Most existing systems and calculi use clausal form for storing the theory.
Reference: [20] <author> Bernhard Beckert, Reiner Hahnle, and Peter H. Schmitt. </author> <title> The even more liberalized ffi-rule in free variable semantic tableaux. </title> <editor> In Georg Gottlob, Alexander Leitsch, and Daniele Mundici, editors, </editor> <booktitle> Proceedings of the third Kurt Godel Colloquium KGC'93, Brno, Czech Republic, volume 713 of Lecture Notes in Computer Science, </booktitle> <pages> pages 108-119. </pages> <publisher> Springer-Verlag, </publisher> <month> August </month> <year> 1993. </year>
Reference-contexts: It is this procedure that is proved complete and sound elsewhere [113, 54]. This completes the description of the analytic tableau method. The method is complete, i.e., any true sentence can be proved by the method [54], and there are various methods of making it more efficient <ref> [8, 20, 82, 94] </ref>. We emphasize how easy it is to translate proofs in this system into natural, readable proofs. Section 5.2 gives some examples of proofs translated automatically into English by the IPR program. <p> Now suppose that every ground instance of T i is true under M. We will show that every ground instance of T i+1 is true under M. The case for the soundness of the ff-, fi-, ffi-, fl- and tableau substitution rules is made elsewhere <ref> [54, 20] </ref>. We will show that this holds in the case that the "-rule was applied. Let be a grounding substitution for T i+1 . We will show that T i+1 is true under M. By induction, any ground instance of T i is true under M. <p> At that point the proof is condensed, using Oppacher and Suen's technique [94], and output in English as described in Section 5.2.4. 4 Beckert, Hahnle and Schmitt's ffi + + -rule could also be used to solve the problem of too many Skolem functions in this particular case <ref> [20] </ref>. 5 This is implemented in a rather efficient way by storing at each formula in the tableau a list of the formulas in the knowledge base with which it has a connection. <p> (_S) and (_S) [19] (1.3) CONSIDER The following are contradictory: 1 (_G1) and (_G2) are disjoint 2 (_Y0) is a member of the cartesian product of (_G1) and (_G2) 3 (_Y0) is a member of the class associated with the diagonal of the product topological space of (_S) and (_S) <ref> [20] </ref> (1.3) APPLY-THEOREM The following are contradictory: 1 (_G1) and (_G2) are disjoint 2 (_Y0) is a member of the cartesian product of (_G1) and (_G2) 3 for some _A _A is a member of the class associated with (_S) and (_Y0) = &lt;_A, _A&gt; CONSIDER The following are contradictory: 1
Reference: [21] <author> Paul Bernays. </author> <title> Axiomatic Set Theory: with a Historical Introduction by Abraham A. </title> <publisher> Fraenkel. Dover Publications, </publisher> <year> 1991. </year> <note> This Dover edition, first published in 1991, is an unabridged and unaltered republication of the second edition (1968) of the work first published by the North-Holland Publishing Company, </note> <editor> Amsterdam, </editor> <booktitle> in 1958 in their series Studies in Logic and The Foundations of Mathematics. </booktitle>
Reference-contexts: Probably the most closely related work to that presented here is the work of Frank Brown [39]. We build a strong but safe comprehension schema into the tableau calculus. The rules developed here are consistent with the comprehension schema of Kelley [77] or Bernays <ref> [21] </ref>. The method is compatible with various axiomatizations of set theory and is also useful in reasoning in more advanced theories in which the particular axiomatization of set theory is unimportant. <p> is the following. t 2 C a-class (C) 1 We often fail to mention the fact that no free variable in t can be bound in A since these problems are easy to handle by variable renaming, by keeping the sets of free and bound variables disjoint (as in Bernays <ref> [21] </ref>) or by some other method (as in Quine [103].) The reader who wants to implement this rule should be warned that this point is necessary for soundness. 81 This rule could also be stated as a branch closure rule. <p> The rules are most useful and easy to use in a set theory like Kelley's [77] or Bernays' <ref> [21] </ref>. The author recommends the use of such a set of axioms for use in problems in low-level set theory. 2 There are other ways of handling the case when the -term is undefined [21]. 3 The "if. . . then. . . else" logical operator can be handled by fi-rules <p> are most useful and easy to use in a set theory like Kelley's [77] or Bernays' <ref> [21] </ref>. The author recommends the use of such a set of axioms for use in problems in low-level set theory. 2 There are other ways of handling the case when the -term is undefined [21]. 3 The "if. . . then. . . else" logical operator can be handled by fi-rules [99]. 84 (an-element (b) ^ a = x (x = b)) a = b an-element (a) x (x = a) = a :an-element (b) s (s = b) = undefined (an-element (c) ^ U <p> The user might assure that all of the formulas used in such a rule are stratified as described by Quine in his "new foundations" [103]. Or the user might be sure that each application of the rule is an instance of Zermelo and Fraenkel's axiom of subsets <ref> [21] </ref>. Of course, it is the duty of the user who puts axioms into the knowledge base to take care of consistency concerns. The symbol, ;, is a special non-logical constant in the language interpreted as the empty set. <p> His rule was more like the one used in Quine's [103] or Zermelo-Fraenkel's <ref> [21] </ref> set theory. Brown, however, went all the way and implemented all of the axioms of Quine's set theory as inference rules. In the present work, we have tried to be a bit more general purpose by implementing only the comprehension schema. <p> Using the comprehension schema is a much stronger and more direct way of proving theorems than using Godel's axioms to deconstruct classes. The rules developed here are consistent with the comprehension schema of Kelley [77] or Bernays <ref> [21] </ref>. The method is compatible with various axiomatizations of set theory and is particularly useful in reasoning in more advanced theories in which the particular axiomatization of set theory is unimportant.
Reference: [22] <editor> E. W. Beth. </editor> <booktitle> The Foundations of Mathematics. </booktitle> <publisher> North Holland, </publisher> <year> 1959. </year>
Reference-contexts: A predicate definition is a sentence that introduces a new predicate to the language, continuous-from-to in this case, as an abbreviation for a formula already in the language. Definitions are axioms that we are allowed to assume to be true without danger of introducing a contradiction into a theory <ref> [22] </ref>. We will learn, in Section 2.3, how such a formula can be stored in a computer knowledge base in a form that is useful and, in Section 3.2, how this knowledge can be used in the process of trying to prove other statements in the theory of topology. <p> IPR uses a non-clausal form for storing knowledge. The novel tableau calculus presented in Section 3.2 can just as well be applied in the context of clausal tableaux. The proof procedure of the analytic tableau was developed by Smullyan [113] based on the work of Beth <ref> [22] </ref> and Hintikka [71]. The method was extended to allow for free variables by Prawitz [100]. See Fitting's book [54] for a formal and rather up-to-date treatment of the procedure. We do not present all of the details here.
Reference: [23] <author> E. W. Beth. </author> <title> On machines which prove theorems. </title> <editor> In Jorg Siekmann and Graham Wrightson, editors, </editor> <booktitle> Automation of Reasoning, </booktitle> <volume> volume 1, </volume> <pages> pages 79-90. </pages> <publisher> Springer-Verlag, </publisher> <year> 1983. </year> <editor> Reprinted from Simon Stevin Wis-en Naturkundig Tijdschrift, </editor> <volume> Vol. 32, </volume> <pages> pages 49-60, </pages> <year> 1958. </year> <month> 170 </month>
Reference-contexts: The use of a tableau calculus (as opposed to a resolution calculus) makes all of these things possible. In fact, the tableau calculus was invented (in its early form by Gentzen and Beth <ref> [57, 23] </ref>) in order to simulate human proofs. <p> Some researchers worked on interactive provers that cooperate with the human. These provers accepted hints or proof sketches from the user and used these to prove the given statement. General-purpose methods. In the 1930s and 1940s, Gentzen [57] and Beth <ref> [23] </ref> worked on complete systematic proof procedures for first-order logic. These methods are referred to as sequent or tableau methods. It is a derivative of these methods that is used in the calculus developed in this dissertation and therefore they will be discussed in detail later.
Reference: [24] <author> Richard L. Bishop and Samuel I. Goldberg. </author> <title> Tensor Analysis on Manifolds. </title> <publisher> Dover Publications, </publisher> <year> 1980. </year> <note> This Dover edition, first published in 1980, is an unabridged and corrected republication of the work originally published by The Macmillan Company in 1968. </note>
Reference-contexts: We give an example below of the English output of IPR. Example 6.2 Here is an example from the theory of vector spaces. It is Proposition 2.4.3 of Bishop and Goldberg's text, Tensor Analysis on Manifolds <ref> [24] </ref>. (8W )(8V )((a-vector-subspace (W; V ) ^ a-vector-space (V )) (9E)(9F )(basis-of (E [ F; V ) ^ basis-of (E; W ))) 137 AND-SPLIT If we suppose: (_G1) and (_G2) are disjoint then we have shown: the cartesian product of (_G1) and (_G2) and the class associated with the diagonal
Reference: [25] <author> W. W. Bledsoe and L. J. Henschen. </author> <title> What is automated theorem proving? Journal of Automated Reasoning, </title> <type> 1(1), </type> <year> 1985. </year>
Reference-contexts: Q.E.D. 3.3 Selection of Knowledge Therefore, one major (THE major) research activity is to devise methods (strategies) for guiding the program so that it makes enough of the right deductions and not too many of the wrong ones. |Bledsoe and Henschen <ref> [25] </ref> 68 In the foregoing sections, we have introduced a method for storing knowledge in a formal language and a method for using this knowledge in the process of establishing the truth of new sentences in the language. <p> and applications|are interconnected, and each plays an indispensable role in automated reasoning. |Larry Wos [119] The main goal of research in automated theorem proving is to build programs that are effective in finding or helping to find proofs of theorems from mathematics and other fields of application. |Bledsoe and Henschen <ref> [25] </ref> IPR is the name of a computer program that uses the calculi described in this dissertation. The interface to IPR has some nice features that have been relatively easy to implement due to the fact that the framework for storing and using knowledge is comprehensible.
Reference: [26] <author> Woodrow W. Bledsoe. </author> <title> Non-resolution theorem proving. </title> <journal> Artificial Intelligence, </journal> <volume> 9 </volume> <pages> 1-35, </pages> <year> 1977. </year>
Reference-contexts: Perhaps the earliest experiment in this direction was conducted by Newell, Simon and Shaw in the late 1950s [93]. 15 Woody Bledsoe, who made substantial contributions to mathematics before dedicating himself to automating reasoning, tried to encode some of his own techniques into his automatic theorem provers <ref> [26] </ref>. Bledsoe and his collaborators also wanted the programs they developed to be very usable so that the user would not have to be an expert at the underlying proof procedure in order to use the programs [28, 29].
Reference: [27] <author> Woodrow W. Bledsoe. </author> <title> I had a dream: </title> <publisher> AAAI Presidential address, </publisher> <month> 19 August </month> <year> 1985. </year> <journal> The AI Magazine, </journal> <pages> pages 57-61, </pages> <year> 1985. </year>
Reference-contexts: He dreamt of a reasoning machine that would help people solve problems from the mundane to the crucial <ref> [27] </ref>. Indeed, in the late 1950s and early 1960s, computer implementations of proof procedures began to be reported. In what follows, we will discuss some of the computer theorem provers that have been developed. <p> Woody Bledsoe, an expert not only in mathematical analysis but in theorem-proving technology, was optimistic. He dreamt of a reasoning machine that would help people solve problems from the mundane to the crucial <ref> [27] </ref>. Larry Wos, another expert with a background in mathematics, is optimistic [121]. The programs developed by his group have already solved problems that confounded some of the greatest mathematicians of this century [89]. While great success has been attained, there has been much frustration and disappointment.
Reference: [28] <author> Woodrow W. Bledsoe. </author> <title> Interactive proof presentation. </title> <editor> In J. L. Sassez and Gordon Plotkin, editors, </editor> <booktitle> Computational Logic, </booktitle> <pages> pages 136-165. </pages> <publisher> MIT Press, </publisher> <year> 1991. </year>
Reference-contexts: Bledsoe and his collaborators also wanted the programs they developed to be very usable so that the user would not have to be an expert at the underlying proof procedure in order to use the programs <ref> [28, 29] </ref>. As a result, the provers needed to be able to communicate with people in a natural way. Interactive provers. Many of the systems mentioned so far were interactive to some extent.
Reference: [29] <author> Woodrow W. Bledsoe and Peter Bruell. </author> <title> A man-machine theorem-proving system. </title> <journal> Artificial Intelligence, </journal> <volume> 5 </volume> <pages> 51-72, </pages> <year> 1974. </year>
Reference-contexts: Bledsoe and his collaborators also wanted the programs they developed to be very usable so that the user would not have to be an expert at the underlying proof procedure in order to use the programs <ref> [28, 29] </ref>. As a result, the provers needed to be able to communicate with people in a natural way. Interactive provers. Many of the systems mentioned so far were interactive to some extent. <p> Frank Brown [39] used what was essentially an incomplete sequent-based prover with free variables to prove theorems in set theory. Brown's system used one particular theory (Quine's set theory [103]) primarily as rewrite rules. Brown's work was very closely related to Bledsoe's IMPLY prover <ref> [29] </ref> that also used knowledge essentially for rewriting. Baumgartner has worked to allow provers to use certain types of first-order theories by means of theory reasoning [13]. A theory reasoning system needs a background reasoner for the theories of interest. They are particularly useful for Horn theories. <p> I was initially influenced by experience with Bledsoe's IMPLY <ref> [29] </ref> and McAllester's Ontic [84].
Reference: [30] <author> Woodrow W. Bledsoe and Guohui Feng. </author> <title> Set-Var. </title> <journal> Journal of Automated Reasoning, </journal> <volume> 11(3) </volume> <pages> 293-314, </pages> <year> 1993. </year>
Reference-contexts: Another approach to this kind of reasoning is to use higher-order logics in which it is easier to express statements about sets of objects. Bledsoe's Set-Var method <ref> [30] </ref> and Bailin and Barker-Plummer's Z-match method [10] both used a slight extension to first-order logic in order to allow sets to be expressed and used more easily. Both of these methods discover sets that have the properties needed to prove many statements in set theory and real analysis. <p> However, the calculus described here does not construct sets well independently of hints from the knowledge base. Woody Bledsoe initiated a tremendous amount of work on the automation of reasoning 149 in set theory. His Set-Var calculus was quite successful on many interesting problems <ref> [30] </ref>. Set-Var used a rule for constructing sets that was essentially equivalent to circumscription. Many of Bledsoe's collaborators (Plummer, Brown, etc.) also worked on related problems. Bailin and Barker-Plummer's Z-match took a very similar approach to Set-Var [10].
Reference: [31] <author> Woodrow W. Bledsoe and Larry M. Hines. </author> <title> Variable elimination and chaining in a resolution-based prover for inequalities. </title> <editor> In W. Bibel and R. Kowalski, editors, </editor> <booktitle> Proceedings of the Fifth Conference on Automated Deduction, volume 87 of Lecture Notes in Computer Science, </booktitle> <pages> pages 70-87. </pages> <publisher> Springer Verlag, </publisher> <year> 1980. </year>
Reference-contexts: Special provers for elementary number theory and inequality problems were developed based on the work of Presberger and others. Martin Davis implemented such a prover 13 in 1957 [49]. Larry Hines incorporated systematic procedures for handling certain kinds of inequality problems in 1980 <ref> [31, 70] </ref>. Various provers were developed for proving theorems by induction. Boyer, Moore and Kaufmann have developed a series of provers for this purpose [38]. Alan Bundy's group developed their own "rippling" techniques for proving theorems by induction [41].
Reference: [32] <author> Woody Bledsoe. </author> <title> Splitting and reduction heuristics in automatic theorem proving. </title> <journal> Artificial Intelligence, </journal> <volume> 2 </volume> <pages> 55-77, </pages> <year> 1971. </year> <booktitle> also in Automation Of Reasoning Classical Papers On Computational Logic, </booktitle> <volume> Vol. II, </volume> <pages> 1967-1970, </pages> <editor> ed. J. Siekmann And G. Wrightson, </editor> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1983, </year> <pages> pp. 508-530. </pages>
Reference-contexts: "without search." 83 A stronger version of the dual is also proved easily using only the comprehension rules. t 2 fa : (8b)(b 2 a b 2 fs : s 2 X ^ s 2 Y gg $ This says that Pow (X " Y ) =Pow (X)"Pow (Y ) <ref> [32] </ref>. This is the only example so far that requires search.
Reference: [33] <author> Woody Bledsoe. </author> <title> Some thoughts on proof discovery. </title> <type> Technical report, </type> <institution> Microelectronics and Computer Technology Corporation, </institution> <month> June </month> <year> 1986. </year> <month> 171 </month>
Reference-contexts: This is detailed in Section 2.3. 2.3 Knowledge in a Theory Central in all of this is knowledge. We see no satisfactory solution to the ATP [Automated Theorem Proving] performance problem without a substantial knowl edge base, which contains much known mathematics. . . |Woody Bledsoe <ref> [33] </ref> The IPR system is designed with a specific application or challenge in mind. That is the n + 1 challenge: enter the first n theorems, definitions and axioms from a textbook and let the system prove the next theorem. <p> Chapter 4 Extensions to First-Order Logic We need also, methods, procedures, and tricks of the trade, which have been used so successfully by the great mathematicians over the years. . . |Woody Bledsoe <ref> [33] </ref> It has been mentioned that first-order logic is an extremely expressive language and essentially all of mathematical or other reasoning can be framed in it. However, this is sometimes very tedious and inconvenient. Therefore, certain shortcuts are frequently used by mathematicians. <p> But alas, it requires more complicated mechanisms to do complicated reasoning; the human prover uses a whole collection of methods of different sorts. |Woody Bledsoe <ref> [33] </ref> 159 To my knowledge, such a project has not been undertaken on a scale large enough to attempt the n +1 problem. However, this idea seems as promising today as it did 37 years ago. 8.4 Imitating Human Techniques.
Reference: [34] <author> George Boole. </author> <title> An Investigation of the Laws of Thought. </title> <publisher> Walton, </publisher> <address> London, 1854. </address> <publisher> Reprinted by Dover Books, </publisher> <address> New York, </address> <year> 1954. </year>
Reference-contexts: His work in this area was left unfinished. In the nineteenth century, George Boole developed the propositional calculus (in his book The Laws of Thought <ref> [34] </ref>) that provided a language and set of inference rules in which much ordinary common-sense reasoning can be expressed. An advantage to his language was that there was a procedure that would determine whether any sentence in the language were true or false in a finite amount of time.
Reference: [35] <author> S. Bose, E. M. Clarke, D. E. Long, and S. Michaylov. Parthenon: </author> <title> a parallel theorem prover for non-horn clauses. </title> <journal> Journal of Automated Reasoning, </journal> <volume> 8 </volume> <pages> 153-181, </pages> <year> 1992. </year>
Reference-contexts: Many theorem proving programs use tableaux and related methods. PROTEIN [14], 3 T A P [19], lean-T A P [16], SETHEO [82], MGTP and it variants [66, 65], METEOR [6], Parthenon <ref> [35] </ref> and PTTP [115] are some of the better known systems. Most existing systems and calculi use clausal form for storing the theory. Some save some space by breaking a formula only to negation normal form [63]. This form still has the disadvantages associated with Skolem constants. <p> In this calculus, only the formulas themselves are entered. No indexing or additional information is provided. The "-rule is closely related to various strategies used in clausal tableaux [81]. The "- rule is distinct from existing rules for clausal tableau expansion in various ways. METEOR [6], Parthenon <ref> [35] </ref>, PTTP [115], SETHEO [82] and PROTEIN [14] use calculi closely related to model elimination. Therefore, they obey the connection condition. In a clausal context, the "-rule only uses the weak connection condition (set-of-support) as in Hahnle's ordered 147 tableaux [64].
Reference: [36] <author> Robert S. Boyer, M. Kaufmann, and J Strother Moore. </author> <title> The Boyer-Moore theorem prover and its interactive enhancement. </title> <journal> Computers and Mathematics with Applications, </journal> <volume> 29(2) </volume> <pages> 27-62, </pages> <year> 1995. </year>
Reference-contexts: These systems show their strength in and, to a large extent, are limited to Horn theories and theories that have the nature of rewrite rules. Other systems exist that apply knowledge based on hints or other information from the user <ref> [36, 53, 61, 84] </ref>. There are also existing systems that use analogy: given a proof that is expected to be similar to the proof of the problem at hand, the prover is able to revise or expand the analogous proof [95]. <p> If we were to choose a number theory text that used a schema for its induction principle then the problem of finding proofs by induction becomes more difficult. For information on successful provers in this area, reference the Boyer-Moore provers <ref> [36] </ref> and the rippling provers [41]. Matthias Baaz et. al. recently demonstrated an excellent way of implementing induction and related inference rules in a tableau based prover [7]. Complexity.
Reference: [37] <author> Robert S. Boyer and J. Strother Moore. </author> <title> A Computational Logic Handbook, </title> <booktitle> volume 23 of Perspectives in Computing. </booktitle> <publisher> Academic Press, </publisher> <year> 1988. </year>
Reference-contexts: Boyer and Moore's proof checkers, which are experts at applying induction, use theories extensively. In this case, the user needs to supply a bit of information along with the statement of the lemma to help the prover know how to use the knowledge <ref> [37] </ref>. Larry Hines' hyper-chaining technique is another example of a system in which the user needs to attach extra information to the knowledge so that the prover will know how to use it [68].
Reference: [38] <author> Robert S. Boyer and J. Strother Moore. </author> <title> A theorem prover for a computational logic. </title> <editor> In M. E. Stickel, editor, </editor> <booktitle> Proceedings of the Tenth International Conference on Automated Deduction, volume 449 of Lecture Notes in Computer Science, </booktitle> <pages> pages 1-15. </pages> <publisher> Springer Verlag, </publisher> <year> 1990. </year>
Reference-contexts: Martin Davis implemented such a prover 13 in 1957 [49]. Larry Hines incorporated systematic procedures for handling certain kinds of inequality problems in 1980 [31, 70]. Various provers were developed for proving theorems by induction. Boyer, Moore and Kaufmann have developed a series of provers for this purpose <ref> [38] </ref>. Alan Bundy's group developed their own "rippling" techniques for proving theorems by induction [41]. Recently, Baaz, et. al. developed the incorporation of induction schemata into the tableau method in a tractable way [7]. Rewriting and equality. <p> In some systems, knowledge is stored with additional information supplied by the user, which instructs the prover how or when to use the knowledge <ref> [38, 68] </ref>. In this calculus, only the formulas themselves are entered. No indexing or additional information is provided. The "-rule is closely related to various strategies used in clausal tableaux [81]. The "- rule is distinct from existing rules for clausal tableau expansion in various ways. <p> With few exceptions [74], automatic systems cannot produce a natural language description of a proof once it is finished. Boyer, Moore and Kaufmann's NQTHM prover communicates with the user largely in English although formulas and terms in the formal language are not translated <ref> [38] </ref>. David McAllester developed a formal language that more closely resembles English [84, 87]. The proof system, Ontic, checks proofs in this language.
Reference: [39] <author> Frank M. Brown. </author> <title> Towards the automation of set theory and its logic. </title> <journal> Artificial Intelligence, </journal> <volume> 10(3) </volume> <pages> 281-316, </pages> <year> 1978. </year>
Reference-contexts: Some have developed provers for full higher-order logic [2, 4]. Others have implemented Godel's axioms in order to keep set theory completely within first-order logic [102]. Others have despaired of handling the problem automatically and resorted to proof checkers [96]. The method used by Frank Brown <ref> [39] </ref> turns out to be rather closely related to the method described in this dissertation. The method used by IPR is essentially the implementation of the axiom schema of comprehension by means of some new tableau branch closure rules and new tableau branch expansion rules. <p> This comment was made by Ulrich Furbach at the most recent TABLEAUX conference. 58 Depth-First Non-Backtracking Unification. Our description will follow Frank Brown's description of the strategy <ref> [39] </ref>. With each fl-formula, we associate a replica instance list, which is the list of instantiations of the variables introduced by the application of a fl-rule to the formula. Each fl-formula is initialized with an empty replica instance list. <p> Therefore, the user can use IPR to prove any theorem in an equality theory. In the remainder of this section, we describe only the equality techniques that IPR applies automatically. 4.1.1 Brown's Rule Brown's Rule is a restricted equality substitution method <ref> [39] </ref>. <p> In proof-checking systems, of course, there is no limit to what a patient person with a great deal of expertise at the system can prove [96]. Probably the most closely related work to that presented here is the work of Frank Brown <ref> [39] </ref>. We build a strong but safe comprehension schema into the tableau calculus. The rules developed here are consistent with the comprehension schema of Kelley [77] or Bernays [21]. <p> The same argument applies here. Using analytic tableau expansion and reduction rules to implement axiom schemata turns out to be very efficient and to have other advantages over methods that use preprocessing techniques such as resolution. Other rules could be wired into a system <ref> [39] </ref> but those given here allow proofs to be found for an important and useful class of theorems. In the case of the comprehension schema, it is easy to see that other rules related to the ones described here may also be useful for some problems. <p> Restricted Paramodulation It appears that some sort of controlled paramodulation (i.e., equality substitution) rule would be very useful in order to trigger the application of comprehension and extensionality. The IPR program uses a very restricted version of paramodulation called Brown's rule <ref> [39, 109] </ref> that only eliminates Skolem terms. A specific liberalization of this rule would be useful. In particular, in addition to Brown's rule, paramodulation should be applied any time its application will allow the application of one of the comprehension or extensionality rules described above. <p> See Example 6.5 for a description of a proof of this theorem that does not use any higher-order logic. 4.2.7 Remarks We first mention that Frank Brown used a very similar rule in his prover for set theory <ref> [39] </ref>. His rule was more like the one used in Quine's [103] or Zermelo-Fraenkel's [21] set theory. Brown, however, went all the way and implemented all of the axioms of Quine's set theory as inference rules. <p> Hahnle, Klingenbeck and Pape's A-ordered tableaux are another restriction to clausal tableaux that reduce the search space tremendously while retaining completeness [64, 62]. This 148 system make gains in efficiency by applying an order on the predicates and terms in the theory. Frank Brown <ref> [39] </ref> used what was essentially an incomplete sequent-based prover with free variables to prove theorems in set theory. Brown's system used one particular theory (Quine's set theory [103]) primarily as rewrite rules. Brown's work was very closely related to Bledsoe's IMPLY prover [29] that also used knowledge essentially for rewriting. <p> Bailin and Barker-Plummer's Z-match took a very similar approach to Set-Var [10]. The present work does not construct classes in any interesting way as these systems do. Frank Brown also worked on a system that proved theorems in set theory using some special inference rules <ref> [39] </ref>. These special inference rules encoded all of the axioms of Quine's set theory into rewrite rules. This method was also quite successful on many interesting problems. The present approach allows any set theory to be used rather than wiring one particular system into the calculus. <p> The earliest implementation of IPR was a sequent-based prover. I read Smullyan's First-Order Logic [113] and followed his directions. Then I began to make improvements, reinventing everything from free-variable semantic tableaux [54] to Brown's depth-first non-backtracking unification strategy <ref> [39] </ref>. I was also experimenting with the interface. I strove to have the prover present proofs in progress in a way that was easy to understand. I implemented the tree navigation code for the interface very early in the process and experimented with various conventions for displaying Skolem terms. <p> Although it takes away from the general-purpose nature of IPR, the method used by Frank Brown for handling set theory seems promising <ref> [39] </ref>. The procedure I envision is to write tableau expansion and branch closure rules for each axiom of, say, Kelley's set theory.
Reference: [40] <author> Bruno Buchberger. </author> <title> Natural language proof in nested cells representation. </title> <editor> In X. Huang, J. Pelletier, F. Pfenning, and J. Siekmann, editors, </editor> <booktitle> First International Workshop on Proof Transformation and Presentation, </booktitle> <month> April </month> <year> 1997. </year>
Reference-contexts: Bruno Buchberger's THEOREMA project intends to develop a system that incorporates various special purpose provers each in its respective area. The combination of these reasoning systems will be unified in a single interface for examining proofs in English <ref> [40] </ref>. Ingo Dahn's ILF project also has similar aims [48]. His system attempts to prove a sentence using a large set of powerful theorem provers and then, upon success, explains the proofs in English. Many other systems share one of the two motivations of the IPR project.
Reference: [41] <author> A. Bundy, A. Stevens, F. van Harmelen, A. Ireland, and A. Smaill. Rippling: </author> <title> A heuristic for guiding inductive proofs. </title> <journal> Artificial Intelligence, </journal> <volume> 62 </volume> <pages> 185-253, </pages> <year> 1993. </year>
Reference-contexts: Various provers were developed for proving theorems by induction. Boyer, Moore and Kaufmann have developed a series of provers for this purpose [38]. Alan Bundy's group developed their own "rippling" techniques for proving theorems by induction <ref> [41] </ref>. Recently, Baaz, et. al. developed the incorporation of induction schemata into the tableau method in a tractable way [7]. Rewriting and equality. Particularly in algebraic problems, a lot of the work in proving a statement involves writing terms in a form that is more useful. <p> If we were to choose a number theory text that used a schema for its induction principle then the problem of finding proofs by induction becomes more difficult. For information on successful provers in this area, reference the Boyer-Moore provers [36] and the rippling provers <ref> [41] </ref>. Matthias Baaz et. al. recently demonstrated an excellent way of implementing induction and related inference rules in a tableau based prover [7]. Complexity. Finally, there is the simple fact that some proofs are just too long and complex to be handled by existing methods with existing commonly used hardware.
Reference: [42] <editor> Alan Bundy. </editor> <booktitle> The Computer Modelling of Mathematical Reasoning. </booktitle> <publisher> Academic Press, </publisher> <year> 1983. </year>
Reference-contexts: Solow [114] and Polya [98] studied general heuristics used by humans in the theorem-proving process. They studied the basic tactics applied by mathematicians in trying to establish a statement as fact. Alan Bundy advocated attempts to encode some of these human techniques into systematic procedures and computer algorithms <ref> [42] </ref>. Perhaps the earliest experiment in this direction was conducted by Newell, Simon and Shaw in the late 1950s [93]. 15 Woody Bledsoe, who made substantial contributions to mathematics before dedicating himself to automating reasoning, tried to encode some of his own techniques into his automatic theorem provers [26]. <p> A formula in Kowalski form is basically a sequent in which all of the formulas in the hypotheses and in the goals are atomic formulas <ref> [42, 45] </ref>. A formula in Kowalski form is usually called a clause and when a formula is translated into a conjunction of clauses, it is said to be in clausal form.
Reference: [43] <author> D. Cantone, A. Ferro, and E. G. Omodeo. </author> <title> Computable Set Theory, volume 1. </title> <publisher> Oxford University Press, </publisher> <year> 1989. </year>
Reference-contexts: Some take a small fragment of set theory and develop decision procedures <ref> [43] </ref>. Others prove theorems using a variant of Godel's axioms of set theory [101]. Some invent special rules for handling properties such as the transitivity of the -relation [69].
Reference: [44] <author> Lewis Carroll. </author> <title> Through the Looking Glass: And What Alice Found There. </title> <address> Puffin Classics. Puffin, </address> <year> 1996. </year> <month> 172 </month>
Reference-contexts: Chapter 2 Formal Reasoning "Contrariwise," continued Tweedledee, "if it was so, it might be; and if it were so, it would be; but as it isn't, it ain't. That's logic." |Lewis Carroll <ref> [44] </ref> As was mentioned in Section 1.3, and indeed was known by Leibniz, in order to automate reasoning we need a language, inference rules, and some sentences in the language that we assume are true. These assumptions are called axioms and definitions and will be stored in the knowledge base.
Reference: [45] <author> Chin-Liang Chang and Richard Char-Tung Lee. </author> <title> Symbolic Logic and Mechanical Theorem Proving. </title> <publisher> Academic Press, </publisher> <address> London, </address> <year> 1973. </year>
Reference-contexts: A formula in Kowalski form is basically a sequent in which all of the formulas in the hypotheses and in the goals are atomic formulas <ref> [42, 45] </ref>. A formula in Kowalski form is usually called a clause and when a formula is translated into a conjunction of clauses, it is said to be in clausal form. <p> Once the negation of a formula is translated into this form, the resolution inference rule is applied in order to find a proof of the original formula <ref> [45] </ref>. We do not give the details of the resolution procedure here. The interested reader should see the apropriate references in the bibliography [45, 122]. <p> We do not give the details of the resolution procedure here. The interested reader should see the apropriate references in the bibliography <ref> [45, 122] </ref>. In Section 2.3.1, we present the procedure for translating a formula into clausal (or Kowal-ski) form. 27 2.2.1 Tableaux Most existing tableau calculi can be divided into two classes: analytic and clausal. <p> A literal is an atom or the negation of an atom. A clause is a disjunction of literals. A clause set is a conjunction of clauses. To prove a formula by the clausal tableau method, the formula is negated and translated into clausal form by Skolemizing <ref> [45] </ref>. (Translating to clausal form is treated in detail in Section 2.3.) A clausal tableau is initialized by placing the formula &gt; at the initial node.
Reference: [46] <author> Shang-Ching Chou. </author> <title> Mechanical Geometry Theorem Proving. </title> <address> D. </address> <publisher> Reidel Publishing, </publisher> <year> 1988. </year>
Reference-contexts: In the late 1950s, H. Gelernter published his work on a theorem prover for statements in geometry [56]. Much later, Shang-Ching Chou wrote a geometry prover that used analytical methods developed by Ritt, Buchberger and Wu <ref> [46] </ref>. Special provers for elementary number theory and inequality problems were developed based on the work of Presberger and others. Martin Davis implemented such a prover 13 in 1957 [49]. Larry Hines incorporated systematic procedures for handling certain kinds of inequality problems in 1980 [31, 70].
Reference: [47] <author> J. M. Crawford and B. J. Kuipers. </author> <title> Algernon a tractable system for knowledge representation. </title> <journal> SIGART Bulletin, </journal> <volume> 2(3) </volume> <pages> 35-44, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: Because of this early association with Kuipers, the early versions of IPR used his Algernon system to store and access the knowledge <ref> [47] </ref>. 156 place at least as early as Hao Wang's work in the late 1950s [116]. This has been called the n + 1 problem or the theorem n + 1 challenge.
Reference: [48] <author> B. I. Dahn, J. Gehne, T. Honigmann, L. Walther, and A. Wolf. </author> <title> Integrating logical functions with ILF. </title> <type> Technical report, </type> <institution> Institut fur Mathematik der Humboldt-Universitat zu Berlin, </institution> <year> 1994. </year>
Reference-contexts: Therefore, some of these features do not work properly in the latest implementation. 116 with similar names. With time, the interface should be written to produce L A T E X [80] output. Ingo Dahn <ref> [48] </ref> has demonstrated the use of ILF technology to translate the output of IPR into L A T E X source and thence into typeset English. In many of the examples shown in this dissertation, we have applied such a transformation to the IPR output. <p> This definition adds an equality to the knowledge base. If the user wants to load the format strings without putting the definitional formula into the knowledge base, that is also possible. Examples are given in the knowledge base that comes with the program. Ingo Dahn <ref> [48] </ref> is able to use his ILF technology to translate the output of IPR as shown above into L A T E X source and thence into typeset English. This sort of technology could be incorporated into the IPR system. <p> Bruno Buchberger's THEOREMA project intends to develop a system that incorporates various special purpose provers each in its respective area. The combination of these reasoning systems will be unified in a single interface for examining proofs in English [40]. Ingo Dahn's ILF project also has similar aims <ref> [48] </ref>. His system attempts to prove a sentence using a large set of powerful theorem provers and then, upon success, explains the proofs in English. Many other systems share one of the two motivations of the IPR project.
Reference: [49] <author> Martin Davis. </author> <title> A computer program for Presburger's algorithm. </title> <booktitle> In Summer Inst. for Symbolic Logic, </booktitle> <pages> pages 215-233. </pages> <publisher> Cornell Press, </publisher> <year> 1957. </year>
Reference-contexts: Much later, Shang-Ching Chou wrote a geometry prover that used analytical methods developed by Ritt, Buchberger and Wu [46]. Special provers for elementary number theory and inequality problems were developed based on the work of Presberger and others. Martin Davis implemented such a prover 13 in 1957 <ref> [49] </ref>. Larry Hines incorporated systematic procedures for handling certain kinds of inequality problems in 1980 [31, 70]. Various provers were developed for proving theorems by induction. Boyer, Moore and Kaufmann have developed a series of provers for this purpose [38].
Reference: [50] <author> Martin Davis. </author> <title> The prehistory and early history of automated deduction. </title> <editor> In Jorg Siekmann and Graham Wrightson, editors, </editor> <booktitle> Automation of Reasoning, </booktitle> <volume> volume 1, </volume> <pages> pages 1-28. </pages> <publisher> Springer-Verlag, </publisher> <year> 1983. </year>
Reference-contexts: For hundreds of years, many great thinkers have envisioned the automation of reasoning and have worked toward the realization of that goal. Most of the historical information in the early part of this section can be found in Martin Davis' survey article <ref> [50] </ref>. The reasoning algorithms invented by Euclid, such as the division algorithm, are early examples of some types of reasoning that were mechanized by the ancients.
Reference: [51] <author> Nachum Dershowitz and Jean-Pierre Jounnaud. </author> <title> Rewrite systems. </title> <editor> In J. van Leeuwen, editor, </editor> <booktitle> Handbook of Theoretical Computer Science, volume B: Formal Models and Semantics, </booktitle> <pages> pages 243-320. </pages> <publisher> Elsevier Science Pub. B. V./MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: Supposing that it is known that certain terms are equal, those equalities are automatically used to decide whether some new pair of terms are equal. This technique has been expanded, specialized and generalized by Kapur [76, 124], Bachmair [9] and Dershowitz <ref> [51] </ref>. Larry Wos and his group incorporated their own rewriting techniques into their resolution provers [122]. These methods are called demodulation and paramodulation. Another method for handling equality is called the congruence closure technique [85, 92, 105]. This method is complete for ground equality. <p> The first method is rarely used since the use of the axioms without special guidance introduces 73 74 tremendous complexity. Therefore, many special inference systems have been developed to handle equality <ref> [51] </ref>. IPR uses a combination of equality inference rules. The combination of the equality techniques used by IPR does not make IPR complete for equality problems. However, the rules presented here have proved to be extremely useful and powerful in practice.
Reference: [52] <author> W. M. Farmer, J. D. Guttman, and F. J. Thayer. IMPS: </author> <title> System description. </title> <editor> In D. Kapur, editor, </editor> <booktitle> Proceedings of the Eleventh International Conference on Automated Deduction, volume 607 of Lecture Notes in Computer Science, </booktitle> <pages> pages 701-705. </pages> <publisher> Springer-Verlag, </publisher> <year> 1992. </year>
Reference-contexts: I implemented the tree navigation code for the interface very early in the process and experimented with various conventions for displaying Skolem terms. In July 1993, I visited McAllester at MIT and Farmer, Guttman and Thayer at the MITRE Corp. Farmer, et. al. had implemented IMPS <ref> [52] </ref>, a sequent based proof checker for higher-order logic. I was very impressed by their interface and began to try to make my system as easy to use. In late 1993 and early 1994, I implemented the congruence closure technique [85, 105] into the unifier.
Reference: [53] <author> William M. Farmer, Joshua D. Guttman, and F. Javier Thayer. IMPS: </author> <title> An interactive mathematical proof system. </title> <journal> Journal of Automated Reasoning, </journal> <volume> 11(2) </volume> <pages> 213-248, </pages> <month> August </month> <year> 1993. </year>
Reference-contexts: These systems show their strength in and, to a large extent, are limited to Horn theories and theories that have the nature of rewrite rules. Other systems exist that apply knowledge based on hints or other information from the user <ref> [36, 53, 61, 84] </ref>. There are also existing systems that use analogy: given a proof that is expected to be similar to the proof of the problem at hand, the prover is able to revise or expand the analogous proof [95]. <p> In order to produce all of its output in natural language, IPR requires format strings to be associated with predicate and term definitions. Any system that translates formulas and terms into natural language must have this information given to it in some form <ref> [53] </ref>. 150 In terms of the interaction, IPR is similar to interactive theorem proving systems [53]. Powerful automatic systems do not offer the non-expert user the opportunity to watch a proof in progress and change its direction. <p> Any system that translates formulas and terms into natural language must have this information given to it in some form <ref> [53] </ref>. 150 In terms of the interaction, IPR is similar to interactive theorem proving systems [53]. Powerful automatic systems do not offer the non-expert user the opportunity to watch a proof in progress and change its direction. With few exceptions [74], automatic systems cannot produce a natural language description of a proof once it is finished.
Reference: [54] <author> Melvin C. </author> <title> Fitting. First-Order Logic and Automated Theorem Proving. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <note> second edition, 1996. 173 </note>
Reference-contexts: A formula with no free variables is called a closed formula or a sentence. There are technical points about renaming bound variables when free variables are replaced by other terms. The concerned reader should refer to a textbook on first-order logic for more rigorous definitions <ref> [113, 54] </ref>. A literal is an atomic formula or the negation of an atomic formula. Thus, a literal can contain no logical connectives other than one occurrence of :. <p> The proof procedure of the analytic tableau was developed by Smullyan [113] based on the work of Beth [22] and Hintikka [71]. The method was extended to allow for free variables by Prawitz [100]. See Fitting's book <ref> [54] </ref> for a formal and rather up-to-date treatment of the procedure. We do not present all of the details here. We present the signed version in a novel way for pedagogical reasons, then we describe how to use the more common unsigned version. <p> That is, we can show A or B. The right branch is similar. Now notice that each branch contains a complementary pair of formulas. Therefore the tableau is closed and we have a proof of the formula we started with. The fact that the tableau procedure is sound <ref> [54] </ref> tells us that that formula must be true. The proofs found by the tableau procedure are intended to be comprehensible. How do we follow this proof? Look at one branch at a time. <p> We must refer the reader elsewhere for the technical details of this definition <ref> [54] </ref>. <p> It is this procedure that is proved complete and sound elsewhere <ref> [113, 54] </ref>. This completes the description of the analytic tableau method. The method is complete, i.e., any true sentence can be proved by the method [54], and there are various methods of making it more efficient [8, 20, 82, 94]. <p> It is this procedure that is proved complete and sound elsewhere [113, 54]. This completes the description of the analytic tableau method. The method is complete, i.e., any true sentence can be proved by the method <ref> [54] </ref>, and there are various methods of making it more efficient [8, 20, 82, 94]. We emphasize how easy it is to translate proofs in this system into natural, readable proofs. Section 5.2 gives some examples of proofs translated automatically into English by the IPR program. <p> In 1968, Raymond Smullyan published a beautiful unification of Gentzen's work with the analytic tableau method [113]. We will use some of Smullyan's notation here. We are also using further extensions to the system that incorporate free variables <ref> [54, 100] </ref>. A sequent consists of two sets of formulas, denoted U ! V , where U and V are sets 34 of formulas. We call U the hypotheses, antecedents or suppositions and we call V the goals, succedents, consequents or conclusions. <p> A formula is proved if there is a tree of sequents built by these rules based at ! such that each leaf is closed. If a formula, , is proved in this way, then the formula is true <ref> [113, 54] </ref>. The relationship between the semantic tableau method and the sequent calculus is close. <p> It is only novel in that it uses sequent notation and retains the ordinary semantics of sequents. When Fitting explains the rules for transforming a formula into clausal form he uses something like a tableau format but he reverses the roles of the ff- and fi-rules <ref> [54] </ref>. Smullyan showed a simple isomorphism between tableaux and trees of sequents [113]. Therefore, in order to make 39 the rules produce output that is easy to explain, we use the sequent form instead of the tableau form. <p> That is, we want to apply a 9 When Fitting <ref> [54] </ref> describes clausifying, he takes the opposite approach so that the original formula is negated, propositional rules are reversed and the quantifier removal rules are left the same. <p> allowed by the depth-first search plus many other strategies, such as easy subgoal selection, dynamic lemma creation, etc. 59 3.2.2 The "-Rule Here we describe the technical details of a general and complete rule for applying sequents from a knowledge base in the context of a free-variable semantic tableau proof <ref> [54, 113] </ref>. We prove soundness and completeness and illustrate the use of the rule by using it to prove the theorem of topology we have been discussing. <p> Now suppose that every ground instance of T i is true under M. We will show that every ground instance of T i+1 is true under M. The case for the soundness of the ff-, fi-, ffi-, fl- and tableau substitution rules is made elsewhere <ref> [54, 20] </ref>. We will show that this holds in the case that the "-rule was applied. Let be a grounding substitution for T i+1 . We will show that T i+1 is true under M. By induction, any ground instance of T i is true under M. <p> The IPR program does not use the procedure given here and, in fact, IPR is incomplete because it insists that " 6= ;. The completeness proof is completely routine and follows the well-known proofs <ref> [54] </ref>. We will outline the ordinary proof using Hintikka's Lemma. The procedure given below is complete regardless of whether clausal or non-clausal form is used. If clausal form is used, then certain restrictions such as set-of-support (Section 3.3) can be applied without losing completeness. <p> with a non-empty set of closed terms) and S is the set of leaves of the finished KB-trees for the sentences in , then every Hintikka set for S (with respect to the language) is satisfiable by some model of S. 67 The ordinary proof of Hintikka's Lemma goes through <ref> [54, 113] </ref>. First build an interpretation which makes the literals in H true, then show that this interpretation makes every other formula true by induction. <p> The earliest implementation of IPR was a sequent-based prover. I read Smullyan's First-Order Logic [113] and followed his directions. Then I began to make improvements, reinventing everything from free-variable semantic tableaux <ref> [54] </ref> to Brown's depth-first non-backtracking unification strategy [39]. I was also experimenting with the interface. I strove to have the prover present proofs in progress in a way that was easy to understand.
Reference: [55] <author> J. Gallier, W. Snyder, P. Narendran, and D. Plaisted. </author> <title> Rigid E-unification is NP-complete. </title> <booktitle> In Proc. Logic in Computer Science LICS, </booktitle> <pages> pages 218-227. </pages> <publisher> IEEE Computer Society Press, </publisher> <year> 1988. </year>
Reference-contexts: In tableau-based methods, some of these techniques do not work the same way because variables are treated differently in tableaux. Beckert, Gallier, and others have worked on efficient methods for handling equality in tableaux <ref> [18, 55] </ref>. 14 Set theory and higher-order logic. Reasoning in most mathematical theories (or in most other realms of reasoning) involves reasoning about sets of objects. Reasoning about sets of objects in first-order logic is usually done using a well-known yet complex list of axioms called the axioms of set-theory. <p> The problem of adding equality inference rules to tableau systems is quite different from that of adding equality to resolution systems <ref> [17, 18, 55] </ref>. Most of the work published in this area has concentrated on complete procedures. In this dissertation, we have looked for some "minimal" set of inference rules for equality that encompass a useful area of mathematical reasoning without becoming intractable.
Reference: [56] <author> H. Gelernter, J. R. Hansen, and D. W. Loveland. </author> <title> Empirical explorations of the geometry-theorem proving machine. </title> <editor> In Jorg Siekmann and Graham Wrightson, editors, </editor> <booktitle> Automation of Reasoning, </booktitle> <volume> volume 1, </volume> <pages> pages 99-122. </pages> <publisher> Springer-Verlag, </publisher> <year> 1983. </year> <booktitle> Reprinted from Proc. West. Joint Comp. Conf., </booktitle> <month> May </month> <year> 1960, </year> <pages> pages 143-147. </pages>
Reference-contexts: The general-purpose provers can prove theorems in these particular fields but it is much more efficient to use the special-purpose shortcuts. In the late 1950s, H. Gelernter published his work on a theorem prover for statements in geometry <ref> [56] </ref>. Much later, Shang-Ching Chou wrote a geometry prover that used analytical methods developed by Ritt, Buchberger and Wu [46]. Special provers for elementary number theory and inequality problems were developed based on the work of Presberger and others. Martin Davis implemented such a prover 13 in 1957 [49].
Reference: [57] <author> Gerhard Gentzen. </author> <title> Investigation into logical deduction. </title> <editor> In M. E. Szabo, editor, </editor> <booktitle> The Collected Papers of Gerhard Gentzen, </booktitle> <pages> pages 68-131. </pages> <publisher> North-Holland Publishing Co., </publisher> <year> 1969. </year>
Reference-contexts: The use of a tableau calculus (as opposed to a resolution calculus) makes all of these things possible. In fact, the tableau calculus was invented (in its early form by Gentzen and Beth <ref> [57, 23] </ref>) in order to simulate human proofs. <p> Some researchers worked on interactive provers that cooperate with the human. These provers accepted hints or proof sketches from the user and used these to prove the given statement. General-purpose methods. In the 1930s and 1940s, Gentzen <ref> [57] </ref> and Beth [23] worked on complete systematic proof procedures for first-order logic. These methods are referred to as sequent or tableau methods. It is a derivative of these methods that is used in the calculus developed in this dissertation and therefore they will be discussed in detail later. <p> The technical details and most examples will be presented in terms of tableaux while the rules for breaking knowledge into the form in which it is stored are given in sequent form. The sequent calculus was developed by Gentzen <ref> [57] </ref> for the purpose of formalizing the proofs that humans write. The system was intended to be very similar to natural deduction. As a result, it is relatively easy to translate proofs from this system into natural language. <p> A tableau is regular if no two nodes on the same branch are labeled with the same formula. 2.2.2 Sequent Calculus The sequent calculus was described in 1935 by Gerhard Gentzen <ref> [57] </ref>. In 1968, Raymond Smullyan published a beautiful unification of Gentzen's work with the analytic tableau method [113]. We will use some of Smullyan's notation here. We are also using further extensions to the system that incorporate free variables [54, 100].
Reference: [58] <author> Robert Givan and David McAllester. </author> <title> New results on local inference relations. </title> <booktitle> In Principles of Knolwedge Representation and Reasoning: Proceedings of the Third International Conference, </booktitle> <pages> pages 403-412. </pages> <publisher> Morgan Kaufman Press, </publisher> <month> October </month> <year> 1992. </year>
Reference-contexts: Propositional logic is another example of a language in which reasoning is very efficient. In propositional logic, there is a decision procedure. But, in propositional logic, it is impossible even to express the notion of "every" or "some" in a general way. David McAllester <ref> [58, 59, 86, 87] </ref> has developed languages that are more expressive than first-order logic and for which the subset of the language for which there is a decision procedure properly contains the subset of first-order logic for which there is a decision procedure. This is a great advantage.
Reference: [59] <author> Robert Givan, David McAllester, and Sameer Shalaby. </author> <title> Natural language based inference procedures applied to Schubert's steamroller. </title> <booktitle> In Proc. 9th National Conf. on Artificial Intelligence (AAAI-91), </booktitle> <pages> pages 915-920. </pages> <publisher> Morgan Kaufmann Publishers, </publisher> <month> July </month> <year> 1991. </year>
Reference-contexts: Propositional logic is another example of a language in which reasoning is very efficient. In propositional logic, there is a decision procedure. But, in propositional logic, it is impossible even to express the notion of "every" or "some" in a general way. David McAllester <ref> [58, 59, 86, 87] </ref> has developed languages that are more expressive than first-order logic and for which the subset of the language for which there is a decision procedure properly contains the subset of first-order logic for which there is a decision procedure. This is a great advantage.
Reference: [60] <author> Kurt Godel. </author> <title> The Consistency of the Axiom of Choice and the Generalized Continuum Hypothesis with the Axioms of Set Theory. </title> <publisher> Princeton University Press, </publisher> <year> 1940. </year>
Reference-contexts: ^ U (a) ^ U (b) ^ a 6= b) r (U (r)) = undefined (an-element (c) ^ U (c) ^ (8r)((an-element (r) ^ U (r)) r = c)) U ( x (U (x))) The comprehension schema bypasses many of Godel's axioms because Godel's set theory is a first-order theory <ref> [60] </ref>. (The idea of bypassing the axioms is suggested by Wos as the better way to solve his eighth research problem [120].) If the user is proving theorems in Godel's theory, then the comprehension schema will never be applied since there is no classifier in Godel's set theory.
Reference: [61] <author> M. Gordon. </author> <title> HOL: A proof generating system for higher-order logic. </title> <editor> In G. Birtwistle and P. A. Subrahmanyam, editors, </editor> <booktitle> Current Trends in Hardware Verification and Automated Theorem Proving, </booktitle> <pages> pages 77-128. </pages> <publisher> Springer-Verlag, </publisher> <year> 1989. </year>
Reference-contexts: These systems show their strength in and, to a large extent, are limited to Horn theories and theories that have the nature of rewrite rules. Other systems exist that apply knowledge based on hints or other information from the user <ref> [36, 53, 61, 84] </ref>. There are also existing systems that use analogy: given a proof that is expected to be similar to the proof of the problem at hand, the prover is able to revise or expand the analogous proof [95].
Reference: [62] <author> Reiner Hahnle and Stefan Klingenbeck. </author> <title> A-ordered tableaux. </title> <journal> Journal of Logic and Computation, </journal> <note> 1996, to appear. Available as Technical Report 26/95 from University of Karlsruhe, Department of Computer Science via anonymous ftp to ftp.ira.uka.de under pub/uni-karlsruhe/papers/techreports/1995/1995-26.ps.gz. 174 </note>
Reference-contexts: We discussed in Chapter 1 the problems associated with selecting knowledge from a large knowledge base. But let us not give up before we begin. Indeed, computer systems have already been developed that use rather large knowledge bases and make selections automatically <ref> [11, 13, 62, 84, 123] </ref>. These systems show their strength in and, to a large extent, are limited to Horn theories and theories that have the nature of rewrite rules. Other systems exist that apply knowledge based on hints or other information from the user [36, 53, 61, 84]. <p> However, in non-Horn theories, something stronger than Gazer is required. Hahnle, Klingenbeck and Pape's A-ordered tableaux are another restriction to clausal tableaux that reduce the search space tremendously while retaining completeness <ref> [64, 62] </ref>. This 148 system make gains in efficiency by applying an order on the predicates and terms in the theory. Frank Brown [39] used what was essentially an incomplete sequent-based prover with free variables to prove theorems in set theory. <p> Other ideas related to the ones explained in Section 3.3 could be implemented and tested on harder problems. Some techniques for selecting input clauses recently developed for clausal tableaux may be compatible with the goals of this project. Hahnle's A-ordered tableau ideas <ref> [62] </ref> may augment IPR's selection criteria well. The problem faced here is that the user (or perhaps the program) needs to decide on a selection function or an ordering on terms and predicates. It is this kind of decision that we would like to keep away from the non-expert user.
Reference: [63] <author> Reiner Hahnle, Neil Murray, and Erik Rosenthal. </author> <title> Completeness for linear regular negation normal form inference systems. </title> <editor> In Zbigniew Ras, editor, </editor> <booktitle> Proc. International Symposium on Methodologies for Intelligent Systems, Charlotte, North Carolina, Lecture Notes in Artificial Intelligence. </booktitle> <publisher> Springer Verlag, </publisher> <year> 1997. </year>
Reference-contexts: Most existing systems and calculi use clausal form for storing the theory. Some save some space by breaking a formula only to negation normal form <ref> [63] </ref>. This form still has the disadvantages associated with Skolem constants. The non-clausal format in which knowledge is stored as described in this dissertation appears to be a novelty. The Gazer system stores knowledge in a similar but less general form.
Reference: [64] <author> Reiner Hahnle and Christian Pape. </author> <title> Ordered tableaux: Extensions and applications. </title> <editor> In Didier Galmiche, editor, </editor> <booktitle> Proc. International Conference on Automated Reasoning with Analytic Tableaux and Related Methods, Pont-a-Mousson, France, volume 1227 of Lecture Notes in Artificial Intelligence, </booktitle> <pages> pages 173-187. </pages> <publisher> Springer-Verlag, </publisher> <year> 1997. </year>
Reference-contexts: The procedure we prove complete here is complete regardless of whether the knowledge base is made of clauses or the non-clausal form described in Section 2.3 <ref> [64] </ref>. <p> to say that some formula from the theorem being applied must be unified with some formula in the tableau. (The handling of equality introduces a possible exception to this rule in IPR and is discussed in Section 4.1.) This restriction is called the weak connection condition in more recent work <ref> [64] </ref>. The set-of-support strategy was apparently first implemented in the context of tableau in the IPR prover and first described in an early technical report [106]. This restriction destroys completeness because of the fact that theorems are not stored in the form of clauses. <p> In addition, the framework facilitates human interaction. It appears to follow from Hahnle's results that the "-rule with this set-of-support restriction is complete in the context of a clausal knowledge base <ref> [64] </ref>. 72 These are the strategies used by IPR in selecting lemmas. <p> METEOR [6], Parthenon [35], PTTP [115], SETHEO [82] and PROTEIN [14] use calculi closely related to model elimination. Therefore, they obey the connection condition. In a clausal context, the "-rule only uses the weak connection condition (set-of-support) as in Hahnle's ordered 147 tableaux <ref> [64] </ref>. The system 3 T A P uses the weak connection condition but considers only one connection at a time. The clausal (and non-clausal) "-rule takes into account any number of connections from a single clause (or, more generally, a single sequent in the knowledge base) into a given branch. <p> The clausal (and non-clausal) "-rule takes into account any number of connections from a single clause (or, more generally, a single sequent in the knowledge base) into a given branch. A second apparent distinction between the "-rule and the A-ordered tableau technique <ref> [64] </ref> used in 3 T A P is that the "-rule does not add the connected literals to the tableau. This makes little difference if a depth-first search is made of a unification, however, in a breadth-first search, the omission of the extra literals cuts the search space tremendously. <p> However, in non-Horn theories, something stronger than Gazer is required. Hahnle, Klingenbeck and Pape's A-ordered tableaux are another restriction to clausal tableaux that reduce the search space tremendously while retaining completeness <ref> [64, 62] </ref>. This 148 system make gains in efficiency by applying an order on the predicates and terms in the theory. Frank Brown [39] used what was essentially an incomplete sequent-based prover with free variables to prove theorems in set theory. <p> In order to keep the complexity down, the plans would be formed in a more intelligent manner using IPR's strategies. Other promising technology exists for helping to solve the fetching problem. For 157 example, Hahnle's A-ordered tableaux make tremendous restrictions to the way knowledge can be applied <ref> [64] </ref>. Rewriting. This problem has been solved to a great extent in many systems. Indeed, even pure mathematicians frequently use softwares, such as Mathematica, that apply rewriting techniques to help them prove theorems.
Reference: [65] <author> R. Hasegawa. </author> <title> MGTP: A model generation theorem prover|its advanced features and applications. </title> <editor> In Didier Galmiche, editor, </editor> <title> Automated Reasoning with Analytic Tableaux and Related Methods, </title> <booktitle> volume 1227 of Lecture Notes in AI, </booktitle> <pages> pages 1-15. </pages> <publisher> Springer-Verlag, </publisher> <month> May </month> <year> 1997. </year>
Reference-contexts: While higher-order languages are more convenient for expressing mathematical facts, the reasoning in higher-order languages is much less tractable. Many theorem proving programs use tableaux and related methods. PROTEIN [14], 3 T A P [19], lean-T A P [16], SETHEO [82], MGTP and it variants <ref> [66, 65] </ref>, METEOR [6], Parthenon [35] and PTTP [115] are some of the better known systems. Most existing systems and calculi use clausal form for storing the theory. Some save some space by breaking a formula only to negation normal form [63].
Reference: [66] <author> R. Hasegawa and Y. Shirai. </author> <title> Constraint propagation of CP and CMGTP: Experiments on quasigroup problems. </title> <booktitle> In Proceedings of the Twelfth International Conference on Automated Deduction, </booktitle> <year> 1994. </year>
Reference-contexts: In that sense, S-tableaux (defined below) are similar to hyper-tableaux [15] and tableaux constructed by MGTP <ref> [66] </ref>, which are clausal tableaux. However, the present calculus is more symmetric and has other differences discussed in Chapter 7. <p> While higher-order languages are more convenient for expressing mathematical facts, the reasoning in higher-order languages is much less tractable. Many theorem proving programs use tableaux and related methods. PROTEIN [14], 3 T A P [19], lean-T A P [16], SETHEO [82], MGTP and it variants <ref> [66, 65] </ref>, METEOR [6], Parthenon [35] and PTTP [115] are some of the better known systems. Most existing systems and calculi use clausal form for storing the theory. Some save some space by breaking a formula only to negation normal form [63].
Reference: [67] <author> D. Hilbert and W. </author> <title> Ackermann. </title> <booktitle> Principles of Mathematical Logic. </booktitle> <publisher> Chelsea, </publisher> <year> 1950. </year> <note> This is a translation of the second edition of Grundzuge der Theoretischen Logik. </note>
Reference-contexts: Introduction The following question now arises as a fundamental problem: Is it possible to determine whether or not a given statement pertaining to a field of knowledge is a consequence of the axioms? . . . [We] are justified in calling it the main problem of mathematical logic. |David Hilbert <ref> [67] </ref> While automatic methods have had great success in many areas of mathematical reasoning, large classes of problems remain out of reach for machines. In particular, the process of establishing the truth of a statement given a large base of knowledge in the theory is very difficult to automate. <p> Modus ponens is an example of an inference rule. Modus ponens allows us to conclude that the sentence "Q" is a consequence of the two sentences "P " and "P implies Q." 10 of the axioms?" (See Sections 11 and 12 of Chapter III of Mathematical Logic <ref> [67] </ref>.) Axioms are simply the most basic assumptions used in a given field of reasoning.
Reference: [68] <author> Larry M. Hines. </author> <title> Hyper-chaining and knowledge-based theorem proving. </title> <editor> In E. Lusk and R. Overbeek, editors, </editor> <booktitle> Proceedings of the Ninth International Conference on Automated Deduction, </booktitle> <pages> pages 469-486. </pages> <address> Spring-Verlag, </address> <year> 1988. </year>
Reference-contexts: In some systems, knowledge is stored with additional information supplied by the user, which instructs the prover how or when to use the knowledge <ref> [38, 68] </ref>. In this calculus, only the formulas themselves are entered. No indexing or additional information is provided. The "-rule is closely related to various strategies used in clausal tableaux [81]. The "- rule is distinct from existing rules for clausal tableau expansion in various ways. <p> Larry Hines' hyper-chaining technique is another example of a system in which the user needs to attach extra information to the knowledge so that the prover will know how to use it <ref> [68] </ref>. The problem of adding equality inference rules to tableau systems is quite different from that of adding equality to resolution systems [17, 18, 55]. Most of the work published in this area has concentrated on complete procedures.
Reference: [69] <author> Larry M. Hines. Str : +ve: </author> <title> The Str : +ve-based subset prover. </title> <editor> In Mark Stickel, editor, </editor> <booktitle> Proceedings of the Tenth International Conference on Automated Deduction, volume 449 of Lecture Notes in Computer Science, </booktitle> <pages> pages 193-206. </pages> <publisher> Springer-Verlag, </publisher> <year> 1990. </year>
Reference-contexts: Both of these methods discover sets that have the properties needed to prove many statements in set theory and real analysis. Larry Hines developed a prover for a part of the theory of sets based on the ideas used in his inequality prover (mentioned above) <ref> [69] </ref>. His techniques handle the transitivity of the subset relation while avoiding the usual complexity that other systematic methods face when using that axiom. <p> Some take a small fragment of set theory and develop decision procedures [43]. Others prove theorems using a variant of Godel's axioms of set theory [101]. Some invent special rules for handling properties such as the transitivity of the -relation <ref> [69] </ref>. In proof-checking systems, of course, there is no limit to what a patient person with a great deal of expertise at the system can prove [96]. Probably the most closely related work to that presented here is the work of Frank Brown [39]. <p> Another commonly used approach is to apply the equality definitions and comprehension schema as a preprocessing step rather than on-the-fly when needed as in the current approach <ref> [69] </ref>. One disadvantage to this approach is that in an interactive prover, the output becomes ugly immediately rather than only becoming ugly when necessary.
Reference: [70] <author> Larry M. Hines. </author> <title> The central variable strategy of Str : +ve. </title> <editor> In D. Kapur, editor, </editor> <booktitle> Proceedings of the Eleventh International Conference on Automated Deduction, volume 607 of Lecture Notes in Computer Science, </booktitle> <pages> pages 35-49. </pages> <publisher> Springer-Verlag, </publisher> <year> 1992. </year> <month> 175 </month>
Reference-contexts: Special provers for elementary number theory and inequality problems were developed based on the work of Presberger and others. Martin Davis implemented such a prover 13 in 1957 [49]. Larry Hines incorporated systematic procedures for handling certain kinds of inequality problems in 1980 <ref> [31, 70] </ref>. Various provers were developed for proving theorems by induction. Boyer, Moore and Kaufmann have developed a series of provers for this purpose [38]. Alan Bundy's group developed their own "rippling" techniques for proving theorems by induction [41].
Reference: [71] <author> Jaakko Hintikka. </author> <title> Form and content in quantification theory. </title> <journal> Acta Philosohica Fennica, </journal> <volume> 8 </volume> <pages> 7-55, </pages> <year> 1955. </year>
Reference-contexts: IPR uses a non-clausal form for storing knowledge. The novel tableau calculus presented in Section 3.2 can just as well be applied in the context of clausal tableaux. The proof procedure of the analytic tableau was developed by Smullyan [113] based on the work of Beth [22] and Hintikka <ref> [71] </ref>. The method was extended to allow for free variables by Prawitz [100]. See Fitting's book [54] for a formal and rather up-to-date treatment of the procedure. We do not present all of the details here.
Reference: [72] <author> Jaakko Hintikka. </author> <title> The Principles of Mathematics Revisited. </title> <publisher> Cambridge University Press, </publisher> <year> 1996. </year>
Reference-contexts: Jaakko Hintikka advocates the use of "independence-friendly" logic since it is more expressive than ordinary first-order logic <ref> [72] </ref>. Naturally, reasoning in this logic is more complex than in ordinary first-order logic. Additionally, Hintikka's independence-friendly logics do not obey the law of the excluded middle. 21 Higher-order languages are much more expressive than first-order logic.
Reference: [73] <author> Xiaorong Huang and Armin Fiedler. </author> <title> Presenting machine-found proofs. </title> <booktitle> In Proceedings of 13th International Conference on Automated Deduction, </booktitle> <year> 1996. </year>
Reference-contexts: There are some recent projects that share very nearly the motivations of this project. The OMEGA project [74], overseen by Jorg Siekmann, incorporates many components that come together as an excellent automatic proof discovery and explanation system. Parts of OMEGA include PROVERB <ref> [73] </ref>, a system that translates resolution proofs into "assertion-level" proofs and explains them in natural language; LEO/HOTEL [79], which incorporates some set theoretic and equality reasoning power; as well as other components.
Reference: [74] <author> Xiaorong Huang, Manfred Kerber, Michael Kohlhase, Erica Melis, Dan Nesmith, Jorn Richts, and Jorg Siekmann. -MKRP: </author> <title> A proof development environment. </title> <editor> In Alan Bundy, editor, </editor> <booktitle> Proceedings of the 12th International Conference on Automated Deduction, volume 814 of Lecture Notes in Artificial Intelligence, </booktitle> <pages> pages 788-792, </pages> <address> Nancy, France, 1994. </address> <publisher> Springer-Verlag, </publisher> <address> Berlin, Germany. </address>
Reference-contexts: Of course, the student would write it in English along with a picture. The proof that IPR writes out in English is long and rather boring in this case. The problem of making long proofs output by the prover read well is difficult <ref> [74, 110] </ref>. We give an example below of the English output of IPR. Example 6.2 Here is an example from the theory of vector spaces. <p> The motivations for the present work|automated reasoning in mathematics together with human understanding|distinguish it from a large amount of the work that has been done by others. There are some recent projects that share very nearly the motivations of this project. The OMEGA project <ref> [74] </ref>, overseen by Jorg Siekmann, incorporates many components that come together as an excellent automatic proof discovery and explanation system. <p> Powerful automatic systems do not offer the non-expert user the opportunity to watch a proof in progress and change its direction. With few exceptions <ref> [74] </ref>, automatic systems cannot produce a natural language description of a proof once it is finished. Boyer, Moore and Kaufmann's NQTHM prover communicates with the user largely in English although formulas and terms in the formal language are not translated [38].
Reference: [75] <author> Ortrun Ibens and Reinholt Letz. </author> <title> Subgoal alternation in model elimination. </title> <editor> In Didier Galmiche, editor, </editor> <title> Automated Reasoning with Analytic Tableaux and Related Methods, </title> <booktitle> volume 1227 of Lecture Notes in AI, </booktitle> <pages> pages 201-215. </pages> <publisher> Springer-Verlag, </publisher> <month> May </month> <year> 1997. </year>
Reference-contexts: Breadth-first unification also allows strategies to be applied that cannot be applied if depth-first unification is used. For example, subgoal (or branch) selection <ref> [75] </ref> becomes a completely different issue. Suppose that for each branch of the tableau, there is a substitution that closes it, however, there is no substitution that closes the entire tableau. <p> One of the most important of these control issues is breadth-first unification. IPR searches for a unification that closes a tableau breadth-first. Breadth-first unification allows several other strategies, such as subgoal (or branch) selection <ref> [75] </ref>, to be applied more easily than in the case of depth-first unification. Also, if it is done as described in Section 5.1.1, breadth-first unification allows theorems to be applied using substitutions that are incompatible with the proof and yet the proof can still be found in a proof-confluent way.
Reference: [76] <author> D. Kapur and N. Narendran. </author> <title> An equational approach to theorem proving in first-order predicate calculus. </title> <booktitle> In Proc. 9th Int. Joint Conf. on Artificial Intelligence (IJCAI-85), </booktitle> <pages> pages 1146-1153, </pages> <year> 1985. </year>
Reference-contexts: Supposing that it is known that certain terms are equal, those equalities are automatically used to decide whether some new pair of terms are equal. This technique has been expanded, specialized and generalized by Kapur <ref> [76, 124] </ref>, Bachmair [9] and Dershowitz [51]. Larry Wos and his group incorporated their own rewriting techniques into their resolution provers [122]. These methods are called demodulation and paramodulation. Another method for handling equality is called the congruence closure technique [85, 92, 105]. This method is complete for ground equality.
Reference: [77] <author> John Kelley. </author> <title> General Topology. </title> <booktitle> The University Series in Higher Mathematics. </booktitle> <address> D. </address> <publisher> Van Nostrand Company, </publisher> <year> 1955. </year>
Reference-contexts: Example 3.1 Let us consider a simple example of the proof of a theorem taken from John Kelley's text, General Topology <ref> [77] </ref>. This is the first part of Theorem 19 in Chapter 5 of that text. Here is what we want to prove to be true assuming that the axioms and theorems given earlier in the text are true. <p> Probably the most closely related work to that presented here is the work of Frank Brown [39]. We build a strong but safe comprehension schema into the tableau calculus. The rules developed here are consistent with the comprehension schema of Kelley <ref> [77] </ref> or Bernays [21]. The method is compatible with various axiomatizations of set theory and is also useful in reasoning in more advanced theories in which the particular axiomatization of set theory is unimportant. <p> Each of these theorems requires the use of the -removal rule. 4.2.3 Axioms of Set Theory Notice that these schemata do not bind the user to a particular choice of axioms of set theory. The rules are most useful and easy to use in a set theory like Kelley's <ref> [77] </ref> or Bernays' [21]. <p> In particular, we build a strong but safe comprehension schema into the tableau calculus. Using the comprehension schema is a much stronger and more direct way of proving theorems than using Godel's axioms to deconstruct classes. The rules developed here are consistent with the comprehension schema of Kelley <ref> [77] </ref> or Bernays [21]. The method is compatible with various axiomatizations of set theory and is particularly useful in reasoning in more advanced theories in which the particular axiomatization of set theory is unimportant. <p> Example 5.1 Here we proceed through the example of the proof of Theorem 5.19 in Kelley's General Topology <ref> [77] </ref>. <p> The example of the continuous function was given in the previous section. Example 5.4 Here we present a simple example of a theorem proved by IPR to give the flavor of the interface and the output. The theorem is taken from John Kelley's General Topology <ref> [77] </ref> (See Example 3.3 in this dissertation.) Theorem: If the product of X over the index set A is locally compact then for every a, X a is locally compact. The three sequents shown in Figure 5.6 are in the knowledge base and are used in the proof. <p> Example 6.4 Here is an example from the appendix on set theory in Kelley's text on topology <ref> [77] </ref>. In this example, all of the previously-occurring theorems and definitions were present in the knowledge base. This came to 59 sequents including 8 term definitions. <p> This has been called the n + 1 problem or the theorem n + 1 challenge. John Kelley's text, General Topology <ref> [77] </ref>, seems to be an excellent target for this test since it is very thorough, includes the axioms of set theory on which the system may be built, is apparently based on a system of axioms including only one proper schema (the easily-implemented comprehension schema) and contains many different types of
Reference: [78] <author> D. E. Knuth and P. B. Bendix. </author> <title> Simple word problems in universal algebras. </title> <editor> In Leech, editor, </editor> <booktitle> Computational Problems in Abstract Algebra, </booktitle> <pages> pages 263-267. </pages> <publisher> Pergamon Press, </publisher> <year> 1970. </year>
Reference-contexts: This kind of reasoning is called rewriting. This is a special area of reasoning in which very successful techniques have been developed. In 1970, Knuth and Bendix wrote a landmark paper describing a method for proving theorems involving equalities <ref> [78] </ref>. Supposing that it is known that certain terms are equal, those equalities are automatically used to decide whether some new pair of terms are equal. This technique has been expanded, specialized and generalized by Kapur [76, 124], Bachmair [9] and Dershowitz [51].
Reference: [79] <author> Michael Kohlhase. </author> <title> Higher-order tableaux. </title> <note> submitted to the Tableau Workshop 1995, Koblenz. </note>
Reference-contexts: The OMEGA project [74], overseen by Jorg Siekmann, incorporates many components that come together as an excellent automatic proof discovery and explanation system. Parts of OMEGA include PROVERB [73], a system that translates resolution proofs into "assertion-level" proofs and explains them in natural language; LEO/HOTEL <ref> [79] </ref>, which incorporates some set theoretic and equality reasoning power; as well as other components. Bruno Buchberger's THEOREMA project intends to develop a system that incorporates various special purpose provers each in its respective area.
Reference: [80] <author> Leslie Lamport. </author> <title> L A T E X: A Document Preparation System. </title> <publisher> Addison-Wesley Publishing Company, </publisher> <address> second edition, </address> <year> 1994. </year> <month> 176 </month>
Reference-contexts: Therefore, some of these features do not work properly in the latest implementation. 116 with similar names. With time, the interface should be written to produce L A T E X <ref> [80] </ref> output. Ingo Dahn [48] has demonstrated the use of ILF technology to translate the output of IPR into L A T E X source and thence into typeset English. In many of the examples shown in this dissertation, we have applied such a transformation to the IPR output.
Reference: [81] <author> R. Letz, K. Mayr, and C. Goller. </author> <title> Controlled integration of the cut rule into connection tableau calculi. </title> <journal> Journal of Automated Reasoning, </journal> <volume> 13(3) </volume> <pages> 297-338, </pages> <month> December </month> <year> 1994. </year>
Reference-contexts: We present the signed version in a novel way for pedagogical reasons, then we describe how to use the more common unsigned version. The model elimination calculus [83] was the first manifestation of a clausal tableau calculus. More recently, the theory of clausal tableaux has been studied more thoroughly <ref> [81] </ref>. The essential difference is that an analytic tableau is built by breaking an initial formula into pieces. <p> Hence 33 forth, we will deal with unsigned tableaux. Furthermore, we will not label edges with inference rules except in the case of the new inference rules introduced later or in cases when there might be confusion. Clausal Tableaux We follow Letz' treatment of clausal tableaux <ref> [81] </ref>. We refer the reader to Letz' work for more details. A literal is an atom or the negation of an atom. A clause is a disjunction of literals. A clause set is a conjunction of clauses. <p> In our current approach, we would apply the extensionality rule from Section 4.2.4 followed by the comprehension schema from Section 4.2.1. (We give detailed examples below.) 4 What we call "lemma generation" is elsewhere called "optimistic folding down" <ref> [81] </ref>. 90 A second approach is to replace the equality definition with an axiom of the following form. (8X)(8Y )(8z)(z 2 P (X; Y ) $ an-element (z) ^ A (z; X; Y )) In order to prove the theorem this way, the axiom of extensionality is also needed. <p> In this calculus, only the formulas themselves are entered. No indexing or additional information is provided. The "-rule is closely related to various strategies used in clausal tableaux <ref> [81] </ref>. The "- rule is distinct from existing rules for clausal tableau expansion in various ways. METEOR [6], Parthenon [35], PTTP [115], SETHEO [82] and PROTEIN [14] use calculi closely related to model elimination. Therefore, they obey the connection condition.
Reference: [82] <author> Reinhold Letz, Johann Schumann, Stephan Bayerl, and Wolfgang Bibel. </author> <title> SETHEO: A high-perfomance theorem prover. </title> <journal> Journal of Automated Reasoning, </journal> <volume> 8(2) </volume> <pages> 183-212, </pages> <year> 1992. </year>
Reference-contexts: It is this procedure that is proved complete and sound elsewhere [113, 54]. This completes the description of the analytic tableau method. The method is complete, i.e., any true sentence can be proved by the method [54], and there are various methods of making it more efficient <ref> [8, 20, 82, 94] </ref>. We emphasize how easy it is to translate proofs in this system into natural, readable proofs. Section 5.2 gives some examples of proofs translated automatically into English by the IPR program. <p> We will discuss below how they need to be restated if breadth-first unification is being used. The first provision is not needed for soundness but it does not take away any first-order completeness and is generally useful. This is what is called the regularity condition <ref> [82] </ref>. The "-rule would be unsound without the second provision. 4 A substitution, , is idempotent if for any formula, F , F = F . 61 If breadth-first unification is being used, then the provisions change. <p> While higher-order languages are more convenient for expressing mathematical facts, the reasoning in higher-order languages is much less tractable. Many theorem proving programs use tableaux and related methods. PROTEIN [14], 3 T A P [19], lean-T A P [16], SETHEO <ref> [82] </ref>, MGTP and it variants [66, 65], METEOR [6], Parthenon [35] and PTTP [115] are some of the better known systems. Most existing systems and calculi use clausal form for storing the theory. Some save some space by breaking a formula only to negation normal form [63]. <p> No indexing or additional information is provided. The "-rule is closely related to various strategies used in clausal tableaux [81]. The "- rule is distinct from existing rules for clausal tableau expansion in various ways. METEOR [6], Parthenon [35], PTTP [115], SETHEO <ref> [82] </ref> and PROTEIN [14] use calculi closely related to model elimination. Therefore, they obey the connection condition. In a clausal context, the "-rule only uses the weak connection condition (set-of-support) as in Hahnle's ordered 147 tableaux [64].
Reference: [83] <author> D.W. Loveland. </author> <title> A simplified format for the model elimination procedure. </title> <journal> Journal of the ACM, </journal> <volume> 16(3) </volume> <pages> 233-248, </pages> <month> July </month> <year> 1969. </year>
Reference-contexts: A method called model-elimination, which is related to tableau methods, was developed by Loveland in the early 1960s <ref> [83] </ref>. Another group of researchers was working on automatic theorem provers based on the work of Herbrand and Skolem. In the early 1960s, J. A. Robinson [104] came up with a new complete procedure for proving theorems in first-order logic called resolution. <p> We do not present all of the details here. We present the signed version in a novel way for pedagogical reasons, then we describe how to use the more common unsigned version. The model elimination calculus <ref> [83] </ref> was the first manifestation of a clausal tableau calculus. More recently, the theory of clausal tableaux has been studied more thoroughly [81]. The essential difference is that an analytic tableau is built by breaking an initial formula into pieces.
Reference: [84] <author> David McAllester. Ontic: </author> <title> A Knowledge Representation Language for Mathematics. </title> <publisher> MIT Press, </publisher> <year> 1989. </year>
Reference-contexts: David McAllester's interactive Ontic prover checks proofs in set theory using a combination of fast procedures and a language that is based on the theory of English grammar <ref> [84] </ref>. Quaife used the Otter program of Wos and McCune to prove many theorems of set theory based on Godel's first-order axioms [102]. Peter Andrews developed a completely automatic theorem prover for full higher-order logic [4]. <p> We discussed in Chapter 1 the problems associated with selecting knowledge from a large knowledge base. But let us not give up before we begin. Indeed, computer systems have already been developed that use rather large knowledge bases and make selections automatically <ref> [11, 13, 62, 84, 123] </ref>. These systems show their strength in and, to a large extent, are limited to Horn theories and theories that have the nature of rewrite rules. Other systems exist that apply knowledge based on hints or other information from the user [36, 53, 61, 84]. <p> These systems show their strength in and, to a large extent, are limited to Horn theories and theories that have the nature of rewrite rules. Other systems exist that apply knowledge based on hints or other information from the user <ref> [36, 53, 61, 84] </ref>. There are also existing systems that use analogy: given a proof that is expected to be similar to the proof of the problem at hand, the prover is able to revise or expand the analogous proof [95]. <p> Boyer, Moore and Kaufmann's NQTHM prover communicates with the user largely in English although formulas and terms in the formal language are not translated [38]. David McAllester developed a formal language that more closely resembles English <ref> [84, 87] </ref>. The proof system, Ontic, checks proofs in this language. <p> I was initially influenced by experience with Bledsoe's IMPLY [29] and McAllester's Ontic <ref> [84] </ref>.
Reference: [85] <author> David McAllester. </author> <title> Grammar rewriting. </title> <editor> In D. Kapur, editor, </editor> <booktitle> Proceedings of the Eleventh International Conference on Automated Deduction, volume 607 of Lecture Notes in Artificial Intelligence, </booktitle> <pages> pages 124-138. </pages> <publisher> Springer-Verlag, </publisher> <month> June </month> <year> 1992. </year>
Reference-contexts: Larry Wos and his group incorporated their own rewriting techniques into their resolution provers [122]. These methods are called demodulation and paramodulation. Another method for handling equality is called the congruence closure technique <ref> [85, 92, 105] </ref>. This method is complete for ground equality. That is to say that for any set of equalities without variables, and for any theorem that follows from those equalities, this method will prove the theorem using the equalities. <p> The method mentioned there has not yet been implemented in IPR but has proved useful in examples proved by hand. 4.1.2 Congruence Closure At an early stage in the development of IPR, it also used an incomplete E-unification algorithm incorporating the ground congruence closure technique <ref> [85, 92, 105] </ref>. This part of the code has not been kept current. 75 To use this technique, a grammar is built from the positive equalities on a branch and the simple equalities in the knowledge base. That grammar is used any time unification is performed between clashing terms. <p> Farmer, et. al. had implemented IMPS [52], a sequent based proof checker for higher-order logic. I was very impressed by their interface and began to try to make my system as easy to use. In late 1993 and early 1994, I implemented the congruence closure technique <ref> [85, 105] </ref> into the unifier. It was at that time that the more complex equality problems were solved by the prover. <p> It was at that time that the more complex equality problems were solved by the prover. At the same time, I experimented with the sequent calculus and its variations including "lemmaizing" [5], mixed universal and rigid variables [18], various ffi-rules [8], equality methods <ref> [18, 85] </ref> and unification strategies. In those early days, the prover was tested on Pelletier's problems [97] and was quite successful, although not enough to be competitive with the provers that win the international contests. In the Spring of 1994, I worked on adding rules for handling set theory.
Reference: [86] <author> David McAllester and Robert Givan. </author> <title> Natural language syntax and first order inference. </title> <journal> Artificial Intelligence, </journal> <volume> 56 </volume> <pages> 1-20, </pages> <year> 1992. </year>
Reference-contexts: Propositional logic is another example of a language in which reasoning is very efficient. In propositional logic, there is a decision procedure. But, in propositional logic, it is impossible even to express the notion of "every" or "some" in a general way. David McAllester <ref> [58, 59, 86, 87] </ref> has developed languages that are more expressive than first-order logic and for which the subset of the language for which there is a decision procedure properly contains the subset of first-order logic for which there is a decision procedure. This is a great advantage.
Reference: [87] <author> David McAllester and Robert Givan. </author> <title> Taxonomic syntax for first order inference. </title> <journal> Journal of the ACM, </journal> <volume> 40(2) </volume> <pages> 246-283, </pages> <month> April </month> <year> 1993. </year>
Reference-contexts: Propositional logic is another example of a language in which reasoning is very efficient. In propositional logic, there is a decision procedure. But, in propositional logic, it is impossible even to express the notion of "every" or "some" in a general way. David McAllester <ref> [58, 59, 86, 87] </ref> has developed languages that are more expressive than first-order logic and for which the subset of the language for which there is a decision procedure properly contains the subset of first-order logic for which there is a decision procedure. This is a great advantage. <p> Boyer, Moore and Kaufmann's NQTHM prover communicates with the user largely in English although formulas and terms in the formal language are not translated [38]. David McAllester developed a formal language that more closely resembles English <ref> [84, 87] </ref>. The proof system, Ontic, checks proofs in this language.
Reference: [88] <author> John McCarthy. </author> <title> Recursive functions of symbolic expressions and their computation by machine (Part I). </title> <journal> Communications of the ACM, </journal> <volume> 3(3) </volume> <pages> 184-195, </pages> <month> April </month> <year> 1960. </year>
Reference-contexts: Formulas in the input language need to be in fully parenthesized prefix notation. This notation is sometimes called "s-expression syntax" <ref> [88] </ref>. Here we describe the syntax of the input language including the handling of the classifier, fx : Ag, and the definite descriptor, x (A). Definition of term and predicate in the input language. The words "term" and "predicate" are defined recursively in terms of each other.
Reference: [89] <author> William McCune. </author> <title> Solution of the Robbins problem. </title> <journal> Journal of Automated Reasoning. </journal> <note> to appear. </note>
Reference-contexts: Some of the techniques mentioned below will be explained in more detail in other parts of this dissertation. In the last forty years tremendous progress has been made and computers have proved several theorems that have been puzzling mathematicians <ref> [89] </ref>. Workers in this field approached the problem of automating mathematical reasoning from many different directions. Some wanted to develop methods for first-order logic in general. <p> Larry Wos, another expert with a background in mathematics, is optimistic [121]. The programs developed by his group have already solved problems that confounded some of the greatest mathematicians of this century <ref> [89] </ref>. While great success has been attained, there has been much frustration and disappointment. The lion's share of the realm of reasoning has not been touched by the computer. 16 One very basic skill that computers have yet to master is that of using successfully an enormous base of knowledge.
Reference: [90] <author> Elliott Mendelson. </author> <title> Introduction of Mathematical Logic. </title> <journal> Mathematics Series. </journal> <note> Wadsworth & Brooks/Cole, 3rd edition, </note> <year> 1987. </year>
Reference-contexts: A disadvantage to higher-order logic is that reasoning is much more complex. In higher-order logics, the branching factor|that is, the number of choices one has in taking the next step in the proof|can be infinite. 2.1.2 First-Order Logic First-order logic is defined in many textbooks <ref> [90, 113] </ref>. In this dissertation we will remain rather informal in the definition of first-order logic, particularly regarding semantics. To see all of the details, one should read the appropriate articles and books mentioned in the bibliography [113].
Reference: [91] <author> James R. Munkres. </author> <title> Topology: A First Course. </title> <publisher> Prentice-Hall, Inc., </publisher> <year> 1975. </year>
Reference-contexts: It is Corollary 2.2 in Chapter 8 of Munkres' Topology: A first course <ref> [91] </ref>.
Reference: [92] <author> G. Nelson and D. Oppen. </author> <title> Fast decision procedures based on congruence closure. </title> <journal> Journal of the ACM, </journal> <volume> 27(2) </volume> <pages> 356-364, </pages> <year> 1980. </year> <month> 177 </month>
Reference-contexts: Larry Wos and his group incorporated their own rewriting techniques into their resolution provers [122]. These methods are called demodulation and paramodulation. Another method for handling equality is called the congruence closure technique <ref> [85, 92, 105] </ref>. This method is complete for ground equality. That is to say that for any set of equalities without variables, and for any theorem that follows from those equalities, this method will prove the theorem using the equalities. <p> The method mentioned there has not yet been implemented in IPR but has proved useful in examples proved by hand. 4.1.2 Congruence Closure At an early stage in the development of IPR, it also used an incomplete E-unification algorithm incorporating the ground congruence closure technique <ref> [85, 92, 105] </ref>. This part of the code has not been kept current. 75 To use this technique, a grammar is built from the positive equalities on a branch and the simple equalities in the knowledge base. That grammar is used any time unification is performed between clashing terms.
Reference: [93] <author> A. Newell, J. C. Shaw, and H. A. Simon. </author> <title> Empirical explorations with the logic theory machine. </title> <booktitle> In Proc. West. Joint Comp. Conf., </booktitle> <pages> pages 218-239, </pages> <year> 1957. </year>
Reference-contexts: Alan Bundy advocated attempts to encode some of these human techniques into systematic procedures and computer algorithms [42]. Perhaps the earliest experiment in this direction was conducted by Newell, Simon and Shaw in the late 1950s <ref> [93] </ref>. 15 Woody Bledsoe, who made substantial contributions to mathematics before dedicating himself to automating reasoning, tried to encode some of his own techniques into his automatic theorem provers [26].
Reference: [94] <author> F. Oppacher and E. Suen. HARP: </author> <title> A tableau-based theorem prover. </title> <journal> Journal of Automated Reasoning, </journal> <volume> 4 </volume> <pages> 69-100, </pages> <year> 1988. </year>
Reference-contexts: It is this procedure that is proved complete and sound elsewhere [113, 54]. This completes the description of the analytic tableau method. The method is complete, i.e., any true sentence can be proved by the method [54], and there are various methods of making it more efficient <ref> [8, 20, 82, 94] </ref>. We emphasize how easy it is to translate proofs in this system into natural, readable proofs. Section 5.2 gives some examples of proofs translated automatically into English by the IPR program. <p> Section 5.1.1 goes into more detail on the topic of breadth-first unification. 3.2.1 Unification Strategies For each of these strategies, there are certainly refinements that make it more efficient. For example, Beckert's mixed universal and rigid unification [18] or Oppacher and Suen's condense algorithm <ref> [94] </ref> can be incorporated into any of these strategies with some additional bookkeeping. Depth-First Backtracking Unification. In this strategy, we use a limit, q, on the number of times the fl-rule may be applied to a single formula. <p> All that is lacking is to give the user easy access to this information. 104 Implementing strategies with breadth-first unification. As an example, we will show how to implement Oppacher and Suen's condense algorithm <ref> [94] </ref> using breadth-first unification. With this understanding, it should be easy to see how other strategies would be implemented. There is definitely room for interesting research in the area of applying strategies in the context of breadth-first unification. <p> At that point the proof is condensed, using Oppacher and Suen's technique <ref> [94] </ref>, and output in English as described in Section 5.2.4. 4 Beckert, Hahnle and Schmitt's ffi + + -rule could also be used to solve the problem of too many Skolem functions in this particular case [20]. 5 This is implemented in a rather efficient way by storing at each formula <p> The user can also select from the various ways of assigning terms to variables. 8 If a proof is finally found, the proof tree is condensed <ref> [94] </ref> to remove all formulas and branches that were not involved in the proof and IPR instantiates the variables in the closing substitution. At this point, the user can continue to navigate the condensed tree. <p> It would be easy 164 to give the user the ability to select from the possible ways a branch can be closed. When the user makes this choice, the prover would apply that substitution across the tree, closing many branches and cutting others off using the condense algorithm <ref> [94] </ref>. It would also be easy to program IPR to show the user all the top-ranked options for applying theorems and allow the user to make a selection. All of the information needed to do this is stored on the tableau.
Reference: [95] <author> S. Owen. </author> <title> Analogy for Automated Reasoning. </title> <publisher> Academic Press, Inc., </publisher> <year> 1990. </year>
Reference-contexts: There are also existing systems that use analogy: given a proof that is expected to be similar to the proof of the problem at hand, the prover is able to revise or expand the analogous proof <ref> [95] </ref>. So a problem that remains largely open is that of automatically discovering a proof in a large non-Horn theory when we have no idea what the proof is supposed to look like.
Reference: [96] <author> Lawrence C. Paulson. </author> <title> Set theory for verification: I. from foundations to functions. </title> <journal> Journal of Automated Reasoning, </journal> <volume> 11 </volume> <pages> 353-389, </pages> <year> 1993. </year>
Reference-contexts: Several methods have been developed for handling higher-order reasoning. Some have developed provers for full higher-order logic [2, 4]. Others have implemented Godel's axioms in order to keep set theory completely within first-order logic [102]. Others have despaired of handling the problem automatically and resorted to proof checkers <ref> [96] </ref>. The method used by Frank Brown [39] turns out to be rather closely related to the method described in this dissertation. <p> Some invent special rules for handling properties such as the transitivity of the -relation [69]. In proof-checking systems, of course, there is no limit to what a patient person with a great deal of expertise at the system can prove <ref> [96] </ref>. Probably the most closely related work to that presented here is the work of Frank Brown [39]. We build a strong but safe comprehension schema into the tableau calculus. The rules developed here are consistent with the comprehension schema of Kelley [77] or Bernays [21]. <p> The following theorem has been used as an example for showing the strength of various systems. (a = c ^ b = d) $ ha; bi = hc; di For example, Paulson uses this example to illustrate his ability to write long and somewhat difficult proofs in the Isabella language <ref> [96] </ref>. <p> No formulas are created that are not needed in the proof. There was no wasted time and no choices needed to be made in this example. Example 4.6 This example is from Paulson's article on the development of set theory in his Isabella prover <ref> [96] </ref>. A " B = B " A Only the definition of intersection is needed in the proof. A " B = fx : x 2 A ^ x 2 Bg The definition of intersection is applied automatically by the restricted paramodulation rule mentioned in Section 4.2.4. <p> Example 6.5 This example is from Paulson's article on the development of set theory in his Isabella prover <ref> [96] </ref>. The following theorem is proved completely automatically by IPR. A " B = B " A Or in the input format: (= (the-intersection-of A B) (the-intersection-of B A)) The formulas in Figure 6.11 are used to form the knowledge base.
Reference: [97] <author> Francis Jeffry Pelletier. </author> <title> Seventy-five problems for testing automatic theorem provers. </title> <journal> Journal of Automated Reasoning, </journal> <volume> 2 </volume> <pages> 191-216, </pages> <year> 1986. </year>
Reference-contexts: At the same time, I experimented with the sequent calculus and its variations including "lemmaizing" [5], mixed universal and rigid variables [18], various ffi-rules [8], equality methods [18, 85] and unification strategies. In those early days, the prover was tested on Pelletier's problems <ref> [97] </ref> and was quite successful, although not enough to be competitive with the provers that win the international contests. In the Spring of 1994, I worked on adding rules for handling set theory.
Reference: [98] <author> G. Polya. </author> <title> Mathematics and Plausible Reasoning. </title> <publisher> Princeton University Press, </publisher> <year> 1954. </year> <title> Two volumes. </title>
Reference-contexts: The fact that his prover, TPS, uses full higher-order logic allows many complex statements about sets and functions to be stated more simply than is possible in the language of first-order logic with set-theory. Human-like techniques. Solow [114] and Polya <ref> [98] </ref> studied general heuristics used by humans in the theorem-proving process. They studied the basic tactics applied by mathematicians in trying to establish a statement as fact. Alan Bundy advocated attempts to encode some of these human techniques into systematic procedures and computer algorithms [42]. <p> Since the application of the "-rule resembles the way a human explains the application of a theorem, it makes it easier (than in the case of resolution, for example) for the programmer to think about human-like strategies for selecting theorems to apply <ref> [98, 114] </ref>. The strategies mentioned in Section 3.3 include the "n + m" strategy that prefers to apply theorems that do not add too much complexity to what remains to the proof after the theorem application.
Reference: [99] <author> Joachim Posegga. </author> <title> Deduction based on Shannon graphs. </title> <booktitle> In Proceedings GWAI-92, </booktitle> <address> Bonn, </address> <publisher> LNCS. Springer-Verlag, </publisher> <year> 1992. </year>
Reference-contexts: The author recommends the use of such a set of axioms for use in problems in low-level set theory. 2 There are other ways of handling the case when the -term is undefined [21]. 3 The "if. . . then. . . else" logical operator can be handled by fi-rules <ref> [99] </ref>. 84 (an-element (b) ^ a = x (x = b)) a = b an-element (a) x (x = a) = a :an-element (b) s (s = b) = undefined (an-element (c) ^ U (c) ^ (8r)(U (r) r = c)) c = r (U (r)) (9r)(an-element (r) ^ U (r)
Reference: [100] <author> Dag Prawitz. </author> <title> An improved proof procedure. </title> <journal> Theoria, </journal> <volume> 26 </volume> <pages> 102-139, </pages> <year> 1960. </year> <booktitle> Reprinted in Automation of Reasoning I edited by Seikmann and Wrightson, </booktitle> <pages> pages 162-199, </pages> <address> 1983, </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: The proof procedure of the analytic tableau was developed by Smullyan [113] based on the work of Beth [22] and Hintikka [71]. The method was extended to allow for free variables by Prawitz <ref> [100] </ref>. See Fitting's book [54] for a formal and rather up-to-date treatment of the procedure. We do not present all of the details here. We present the signed version in a novel way for pedagogical reasons, then we describe how to use the more common unsigned version. <p> In 1968, Raymond Smullyan published a beautiful unification of Gentzen's work with the analytic tableau method [113]. We will use some of Smullyan's notation here. We are also using further extensions to the system that incorporate free variables <ref> [54, 100] </ref>. A sequent consists of two sets of formulas, denoted U ! V , where U and V are sets 34 of formulas. We call U the hypotheses, antecedents or suppositions and we call V the goals, succedents, consequents or conclusions.
Reference: [101] <author> Art Quaife. </author> <title> Automated deduction in von Neumann-Bernays-Godel set theory. </title> <journal> Journal of Automated Reasoning, </journal> <volume> 8(1) </volume> <pages> 91-148, </pages> <month> February </month> <year> 1992. </year>
Reference-contexts: Some take a small fragment of set theory and develop decision procedures [43]. Others prove theorems using a variant of Godel's axioms of set theory <ref> [101] </ref>. Some invent special rules for handling properties such as the transitivity of the -relation [69]. In proof-checking systems, of course, there is no limit to what a patient person with a great deal of expertise at the system can prove [96]. <p> In this work we emphasized the automatic discovery of proofs in set theory. Related to this, there has been less done. Art Quaife used Godel's first-order axioms (or a slight improvement on them which benefits systematization) to prove theorems in set theory <ref> [101] </ref>. The calculus introduced in Section 4.2 bypasses many of Godel's axioms rendering them unneeded for most applications. However, the calculus described here does not construct sets well independently of hints from the knowledge base.
Reference: [102] <author> Art Quaife. </author> <title> Automated Development of Fundamental Mathematical Theories, </title> <booktitle> volume 2 of Automated Reasoning Series. </booktitle> <publisher> Kluwer Academic Publishers, </publisher> <year> 1992. </year>
Reference-contexts: However, when the language is extended in this way, reasoning typically becomes much more complex. Several methods have been developed for handling higher-order reasoning. Some have developed provers for full higher-order logic [2, 4]. Others have implemented Godel's axioms in order to keep set theory completely within first-order logic <ref> [102] </ref>. Others have despaired of handling the problem automatically and resorted to proof checkers [96]. The method used by Frank Brown [39] turns out to be rather closely related to the method described in this dissertation. <p> Quaife used the Otter program of Wos and McCune to prove many theorems of set theory based on Godel's first-order axioms <ref> [102] </ref>. Peter Andrews developed a completely automatic theorem prover for full higher-order logic [4]. The fact that his prover, TPS, uses full higher-order logic allows many complex statements about sets and functions to be stated more simply than is possible in the language of first-order logic with set-theory. Human-like techniques.
Reference: [103] <author> Willard Van Orman Quine. </author> <title> Set Theory and its Logic. </title> <publisher> The Belknap Press of Harvard University Press, </publisher> <address> revised edition, </address> <year> 1969. </year>
Reference-contexts: We often fail to mention the fact that no free variable in t can be bound in A since these problems are easy to handle by variable renaming, by keeping the sets of free and bound variables disjoint (as in Bernays [21]) or by some other method (as in Quine <ref> [103] </ref>.) The reader who wants to implement this rule should be warned that this point is necessary for soundness. 81 This rule could also be stated as a branch closure rule. That is, any branch containing the formulas t 2 C :a-class (C) is closed. <p> In such a case, the user must take precautions about when the comprehension schema is applied. The user might assure that all of the formulas used in such a rule are stratified as described by Quine in his "new foundations" <ref> [103] </ref>. Or the user might be sure that each application of the rule is an instance of Zermelo and Fraenkel's axiom of subsets [21]. Of course, it is the duty of the user who puts axioms into the knowledge base to take care of consistency concerns. <p> See Example 6.5 for a description of a proof of this theorem that does not use any higher-order logic. 4.2.7 Remarks We first mention that Frank Brown used a very similar rule in his prover for set theory [39]. His rule was more like the one used in Quine's <ref> [103] </ref> or Zermelo-Fraenkel's [21] set theory. Brown, however, went all the way and implemented all of the axioms of Quine's set theory as inference rules. In the present work, we have tried to be a bit more general purpose by implementing only the comprehension schema. <p> This 148 system make gains in efficiency by applying an order on the predicates and terms in the theory. Frank Brown [39] used what was essentially an incomplete sequent-based prover with free variables to prove theorems in set theory. Brown's system used one particular theory (Quine's set theory <ref> [103] </ref>) primarily as rewrite rules. Brown's work was very closely related to Bledsoe's IMPLY prover [29] that also used knowledge essentially for rewriting. Baumgartner has worked to allow provers to use certain types of first-order theories by means of theory reasoning [13].
Reference: [104] <author> J. A. Robinson. </author> <title> A machine-oriented logic based on the resolution principle. </title> <journal> Journal of the ACM, </journal> <volume> 1(12) </volume> <pages> 23-41, </pages> <year> 1965. </year> <month> 178 </month>
Reference-contexts: A method called model-elimination, which is related to tableau methods, was developed by Loveland in the early 1960s [83]. Another group of researchers was working on automatic theorem provers based on the work of Herbrand and Skolem. In the early 1960s, J. A. Robinson <ref> [104] </ref> came up with a new complete procedure for proving theorems in first-order logic called resolution. The resolution methods are not so closely related to the way humans present or normally think of proving theorems. Special-purpose provers.
Reference: [105] <author> Robert E. Shostak. </author> <title> An algorithm for reasoning about equality. </title> <journal> Comm. of the ACM, </journal> <volume> 21(2) </volume> <pages> 583-585, </pages> <year> 1978. </year>
Reference-contexts: Larry Wos and his group incorporated their own rewriting techniques into their resolution provers [122]. These methods are called demodulation and paramodulation. Another method for handling equality is called the congruence closure technique <ref> [85, 92, 105] </ref>. This method is complete for ground equality. That is to say that for any set of equalities without variables, and for any theorem that follows from those equalities, this method will prove the theorem using the equalities. <p> The method mentioned there has not yet been implemented in IPR but has proved useful in examples proved by hand. 4.1.2 Congruence Closure At an early stage in the development of IPR, it also used an incomplete E-unification algorithm incorporating the ground congruence closure technique <ref> [85, 92, 105] </ref>. This part of the code has not been kept current. 75 To use this technique, a grammar is built from the positive equalities on a branch and the simple equalities in the knowledge base. That grammar is used any time unification is performed between clashing terms. <p> Farmer, et. al. had implemented IMPS [52], a sequent based proof checker for higher-order logic. I was very impressed by their interface and began to try to make my system as easy to use. In late 1993 and early 1994, I implemented the congruence closure technique <ref> [85, 105] </ref> into the unifier. It was at that time that the more complex equality problems were solved by the prover.
Reference: [106] <author> Benjamin Shults. </author> <title> The creation and use of a knowledge base of mathematical theorems and definitions. </title> <type> Technical Report ATP-127, </type> <institution> The University of Texas at Austin, </institution> <year> 1995. </year>
Reference-contexts: has been relatively easy to implement an unusually informative interface to the prover (Section 5.2.) IPR also explains the proofs it finds completely in English (Section 5.2.4.) All of the novelties mentioned so far were developed by 1994 and published in at least a primitive form in early technical reports <ref> [106, 107] </ref>. Since that time, most of the work has gone into improving the implementation to the point that it could prove theorems that are difficult for other systems. Some examples of theorems proved are detailed in Chapter 6. <p> In that sense, S-tableaux (defined below) are similar to hyper-tableaux [15] and tableaux constructed by MGTP [66], which are clausal tableaux. However, the present calculus is more symmetric and has other differences discussed in Chapter 7. The "-rule was developed in 1994 <ref> [106, 107] </ref>, but since the author was not using clausal form, the relation between this work and the similar work done at that time and since that time in clausal tableaux was not immediately noticed. Further comparison is given in Chapter 7. <p> The set-of-support strategy was apparently first implemented in the context of tableau in the IPR prover and first described in an early technical report <ref> [106] </ref>. This restriction destroys completeness because of the fact that theorems are not stored in the form of clauses. However, examples that demonstrate this incompleteness are generally unnatural syntactic tricks. Example 3.5 Suppose the axiom (9x)(P (x)^Q (x)) is entered into the knowledge base. <p> The comprehension schema is implemented by new tableau reduction and expansion rules. These rules were first described in an early technical report on the IPR prover <ref> [106] </ref> that implements the comprehension schema described here. Using these rules, the IPR system has proved many examples. The use of these rules allows the IPR user to express many commonly-used mathematical constructs much more easily than is possible with first-order logic. <p> The non-clausal form introduced in this work (first described in an early technical report <ref> [106] </ref>) has several advantages in both efficient reasoning and human interface (Section 2.3.) 151 152 The "-rule is a generalized connection method for applying knowledge. It can be applied in both the clausal and non-clausal contexts. In the clausal context, completeness is retained even with the weak connection condition. <p> I worked an unrelated project with Benjamin Kuipers [111]. 1 During that time, the only work I got done related to IPR was light writing and editing of the technical reports describing the non-clausal "-rule, the associated strategies, the comprehension schema, the congruence closure and other basic ideas behind IPR <ref> [106, 107] </ref>. In the Summer of 1996, I began working on the IPR code again in earnest. At this point, I was most interested in its ability to prove theorems in advanced theories using relatively large knowledge bases.
Reference: [107] <author> Benjamin Shults. </author> <title> A framework for the creation and use of a knowledge base of mathematical theorems and definitions. </title> <type> Technical Report ATP-127a, </type> <institution> The University of Texas at Austin, </institution> <year> 1995. </year>
Reference-contexts: has been relatively easy to implement an unusually informative interface to the prover (Section 5.2.) IPR also explains the proofs it finds completely in English (Section 5.2.4.) All of the novelties mentioned so far were developed by 1994 and published in at least a primitive form in early technical reports <ref> [106, 107] </ref>. Since that time, most of the work has gone into improving the implementation to the point that it could prove theorems that are difficult for other systems. Some examples of theorems proved are detailed in Chapter 6. <p> In that sense, S-tableaux (defined below) are similar to hyper-tableaux [15] and tableaux constructed by MGTP [66], which are clausal tableaux. However, the present calculus is more symmetric and has other differences discussed in Chapter 7. The "-rule was developed in 1994 <ref> [106, 107] </ref>, but since the author was not using clausal form, the relation between this work and the similar work done at that time and since that time in clausal tableaux was not immediately noticed. Further comparison is given in Chapter 7. <p> I worked an unrelated project with Benjamin Kuipers [111]. 1 During that time, the only work I got done related to IPR was light writing and editing of the technical reports describing the non-clausal "-rule, the associated strategies, the comprehension schema, the congruence closure and other basic ideas behind IPR <ref> [106, 107] </ref>. In the Summer of 1996, I began working on the IPR code again in earnest. At this point, I was most interested in its ability to prove theorems in advanced theories using relatively large knowledge bases.
Reference: [108] <author> Benjamin Shults. </author> <title> Challenge problems in first-order theories. </title> <journal> Association of Automated Reasoning Newsletter, </journal> (34):5-8, October 1996. 
Reference-contexts: Please see other sections for examples pertaining to specific rules or interface issues as they are dealt with. For example, Section 4.2.6 contains many examples of proofs found automatically in set theory. 127 128 Several of these examples were published previously <ref> [108] </ref>. Example 6.1 The first example we present was one of the main motivating challenges during the recent development of the prover. The proof itself is quite complex and there is some necessary branching involved. Here is the statement in English.
Reference: [109] <author> Benjamin Shults. </author> <title> A framework for using knowledge in tableau proofs. </title> <editor> In Didier Galmiche, editor, </editor> <title> Automated Reasoning with Analytic Tableaux and Related Methods, </title> <booktitle> volume 1227 of Lecture Notes in AI, </booktitle> <pages> pages 328-342. </pages> <publisher> Springer-Verlag, </publisher> <month> May </month> <year> 1997. </year>
Reference-contexts: Neither of the above rules for equality or are currently wired into the IPR program. Currently, IPR handles reasoning about by including the definition of in the knowledge base and fetching it automatically using the "-rule <ref> [109] </ref>. Restricted Paramodulation It appears that some sort of controlled paramodulation (i.e., equality substitution) rule would be very useful in order to trigger the application of comprehension and extensionality. The IPR program uses a very restricted version of paramodulation called Brown's rule [39, 109] that only eliminates Skolem terms. <p> Restricted Paramodulation It appears that some sort of controlled paramodulation (i.e., equality substitution) rule would be very useful in order to trigger the application of comprehension and extensionality. The IPR program uses a very restricted version of paramodulation called Brown's rule <ref> [39, 109] </ref> that only eliminates Skolem terms. A specific liberalization of this rule would be useful. In particular, in addition to Brown's rule, paramodulation should be applied any time its application will allow the application of one of the comprehension or extensionality rules described above. <p> Other appropriate test problems include theorems from elementary group theory, point set topology, and number theory. |Larry Wos [120] If the usual definitions and lemmas pertaining to this theory were present in the knowledge base of a prover using the "-rule <ref> [109] </ref> as well as the rules for set theory presented here and 100 some slightly more sophisticated equality rules, then the prover could find a proof if the set of lemmas included a mention of the function that is needed in the proof. <p> The last two sequents in this proof were formed by the application of the first sequent in the knowledge base. The last two sequents are closed by the application of the last two sequents in the knowledge base with the substitution the Bth coordinate function for the variable F <ref> [109] </ref>. The user who runs the program interactively can decide to apply a certain substitution to the tree, to apply a certain bit of knowledge or logical rule, or simply to watch the decisions made by the prover.
Reference: [110] <author> Benjamin Shults. </author> <title> IPR and English proofs. </title> <editor> In X. Huang, J. Pelletier, F. Pfenning, and J. Siekmann, editors, </editor> <booktitle> First International Workshop on Proof Transformation and Presentation, </booktitle> <month> April </month> <year> 1997. </year>
Reference-contexts: The first novelty is the format in which knowledge is stored (Section 2.3.2.) Knowledge is stored in a sensible and useful non-clausal format that facilitates automatic use and human understanding <ref> [110] </ref>. This is useful in an automated theorem proving context because it allows humans to interact if necessary and to understand the output proof. <p> The present approach is completely automatic and quite successful on many problems that are showcased as challenge problems for provers in set theory. In fact, this 79 procedure finds proofs of several of these examples without search. The method proposed here is also compatible with English explanation <ref> [110] </ref>. We implement the comprehension schema by means of tableau reduction (i.e., branch closure) and expansion rules. We also discuss the implementation of the definite descriptor in tableaux and special rules for handling equality effectively and in a tractable way in set theory. <p> y = a * fc=yg (4) x = fc; dg :an-element (w) fc=wg w = a * fc=wg [x 6= fag] ffag=xg Before we continue to the explanation of Figures 4.5 and 4.6, we want to show how closely this system relates to the way humans write or explain proofs <ref> [110] </ref>. Here we describe We know that ha; bi = hc; di and we want to show that a = c. Since fag 2 ha; bi we know that fag 2 hc; di by extensionality. Therefore, fag = fcg or fag = fc; dg by comprehension. Suppose fag = fcg. <p> With IPR, any selection of set theoretic axioms can be added to the knowledge base and used automatically by the prover. 99 The method proposed here is a completely automatic method that is tractable, strong and compatible with English explanation <ref> [110] </ref>. In particular, we build a strong but safe comprehension schema into the tableau calculus. Using the comprehension schema is a much stronger and more direct way of proving theorems than using Godel's axioms to deconstruct classes. <p> Of course, the student would write it in English along with a picture. The proof that IPR writes out in English is long and rather boring in this case. The problem of making long proofs output by the prover read well is difficult <ref> [74, 110] </ref>. We give an example below of the English output of IPR. Example 6.2 Here is an example from the theory of vector spaces.
Reference: [111] <author> Benjamin Shults and Benjamin Kuipers. </author> <title> Proving properties of continuous systems: qualitative simulation and temporal logic. </title> <journal> Artificial Intelligence, </journal> <volume> 92 </volume> <pages> 91-129, </pages> <year> 1997. </year>
Reference-contexts: Until that point, only the logical operators were in English. The code for producing English proofs was also developed during this time. From August 1994 through May 1996 I worked an unrelated project with Benjamin Kuipers <ref> [111] </ref>. 1 During that time, the only work I got done related to IPR was light writing and editing of the technical reports describing the non-clausal "-rule, the associated strategies, the comprehension schema, the congruence closure and other basic ideas behind IPR [106, 107].
Reference: [112] <author> Donald Simon. </author> <title> Checking natural language proofs. </title> <editor> In E. Lusk and R. Overbeek, editors, </editor> <booktitle> Proceedings of the Ninth International Conference on Automated Deduction, volume 310 of Lecture Notes in Computer Science, </booktitle> <pages> pages 141-150. </pages> <publisher> Springer-Verlag, </publisher> <year> 1988. </year>
Reference-contexts: For 9 Other researchers have worked on the problem of translating English into a formal language for use in automated theorem proving <ref> [112] </ref>. 117 example, (a-member-of (the-ordered-pair x (f x)) S) is a formula in the input language where x and S are variable symbols and the-ordered-pair and f are function symbols. <p> In most systems, one of these properties excludes the other. Some work has been done on the problem of having automated theorem proving systems read natural language <ref> [112] </ref>. However, most systems, even interactive systems, require the user to input the statements in a formal computer-oriented language. IPR is not unusual in this way. In order to produce all of its output in natural language, IPR requires format strings to be associated with predicate and term definitions.
Reference: [113] <author> Raymond M. Smullyan. </author> <title> First-Order Logic. </title> <publisher> Dover Publications, </publisher> <address> New York, </address> <note> second corrected edition, 1995. First published 1968 by Springer-Verlag. </note>
Reference-contexts: A disadvantage to higher-order logic is that reasoning is much more complex. In higher-order logics, the branching factor|that is, the number of choices one has in taking the next step in the proof|can be infinite. 2.1.2 First-Order Logic First-order logic is defined in many textbooks <ref> [90, 113] </ref>. In this dissertation we will remain rather informal in the definition of first-order logic, particularly regarding semantics. To see all of the details, one should read the appropriate articles and books mentioned in the bibliography [113]. <p> In this dissertation we will remain rather informal in the definition of first-order logic, particularly regarding semantics. To see all of the details, one should read the appropriate articles and books mentioned in the bibliography <ref> [113] </ref>. In Section 5.2.1 we give a slightly more formal definition of the syntax for the language that is input to the IPR program. First we will describe terms in the language. Terms are expressions that stand for objects in the universe of discourse. <p> A formula with no free variables is called a closed formula or a sentence. There are technical points about renaming bound variables when free variables are replaced by other terms. The concerned reader should refer to a textbook on first-order logic for more rigorous definitions <ref> [113, 54] </ref>. A literal is an atomic formula or the negation of an atomic formula. Thus, a literal can contain no logical connectives other than one occurrence of :. <p> There are many sets of inference rules that are adequate for this task. The two methods we present, the sequent calculus (Section 2.2.2) and the tableau calculus (Section 2.2.1), are very closely related. In fact, the latter can be thought of as a more efficient version of the former <ref> [113] </ref>. The reason we present both is merely that some issues are easier to explain in terms of the sequent calculus even though it is less efficient to use. <p> IPR uses a non-clausal form for storing knowledge. The novel tableau calculus presented in Section 3.2 can just as well be applied in the context of clausal tableaux. The proof procedure of the analytic tableau was developed by Smullyan <ref> [113] </ref> based on the work of Beth [22] and Hintikka [71]. The method was extended to allow for free variables by Prawitz [100]. See Fitting's book [54] for a formal and rather up-to-date treatment of the procedure. We do not present all of the details here. <p> It is this procedure that is proved complete and sound elsewhere <ref> [113, 54] </ref>. This completes the description of the analytic tableau method. The method is complete, i.e., any true sentence can be proved by the method [54], and there are various methods of making it more efficient [8, 20, 82, 94]. <p> A tableau is regular if no two nodes on the same branch are labeled with the same formula. 2.2.2 Sequent Calculus The sequent calculus was described in 1935 by Gerhard Gentzen [57]. In 1968, Raymond Smullyan published a beautiful unification of Gentzen's work with the analytic tableau method <ref> [113] </ref>. We will use some of Smullyan's notation here. We are also using further extensions to the system that incorporate free variables [54, 100]. A sequent consists of two sets of formulas, denoted U ! V , where U and V are sets 34 of formulas. <p> A formula is proved if there is a tree of sequents built by these rules based at ! such that each leaf is closed. If a formula, , is proved in this way, then the formula is true <ref> [113, 54] </ref>. The relationship between the semantic tableau method and the sequent calculus is close. <p> When Fitting explains the rules for transforming a formula into clausal form he uses something like a tableau format but he reverses the roles of the ff- and fi-rules [54]. Smullyan showed a simple isomorphism between tableaux and trees of sequents <ref> [113] </ref>. Therefore, in order to make 39 the rules produce output that is easy to explain, we use the sequent form instead of the tableau form. Also, instead of reversing the roles of the ff- and fi-rules as Fitting does, we reverse the roles of the ffi- and fl-rules. <p> The reason for this is to maintain the semantics of sequents with which Fitting was not concerned in his presentation. We stick as closely as possible to Smullyan's unified notation. Recall that in Smullyan's notation (see Chapter XI, Section 1 of First-Order Logic <ref> [113] </ref>) formulas in the antecedent of a sequent correspond to positive formulas on a branch of a tableau and formulas in the consequent of a sequent correspond to negative formulas on a branch of a tableau. Therefore, an existentially quantified formula in the consequent of a sequent is a fl-formula. <p> allowed by the depth-first search plus many other strategies, such as easy subgoal selection, dynamic lemma creation, etc. 59 3.2.2 The "-Rule Here we describe the technical details of a general and complete rule for applying sequents from a knowledge base in the context of a free-variable semantic tableau proof <ref> [54, 113] </ref>. We prove soundness and completeness and illustrate the use of the rule by using it to prove the theorem of topology we have been discussing. <p> with a non-empty set of closed terms) and S is the set of leaves of the finished KB-trees for the sentences in , then every Hintikka set for S (with respect to the language) is satisfiable by some model of S. 67 The ordinary proof of Hintikka's Lemma goes through <ref> [54, 113] </ref>. First build an interpretation which makes the literals in H true, then show that this interpretation makes every other formula true by induction. <p> All this is accomplished by translating each branch of the tableau into a sequent as in Smullyan <ref> [113] </ref>. <p> The earliest implementation of IPR was a sequent-based prover. I read Smullyan's First-Order Logic <ref> [113] </ref> and followed his directions. Then I began to make improvements, reinventing everything from free-variable semantic tableaux [54] to Brown's depth-first non-backtracking unification strategy [39]. I was also experimenting with the interface. I strove to have the prover present proofs in progress in a way that was easy to understand.
Reference: [114] <author> Daniel Solow. </author> <title> How to Read and Do Proofs. </title> <publisher> John Wiley & Sons, Inc., </publisher> <year> 1982. </year>
Reference-contexts: Related technology could be used in artificial intelligence programs that are used to do common-sense reasoning in particular. In talking about proving theorems, Solow makes an analogy with solving a maze <ref> [114] </ref>. One can work forward or backward: one can concentrate on the statement being proved and try to decide what would be sufficient, or one can concentrate on the assumptions and try to draw conclusions from them until the goal is reached. <p> As Solow mentions, we usually work 4 forward and backward alternatively. It might be necessary to alternate several times between the forward and backward processes before you succeed, for there are likely to be several false starts and blind alleys. |Daniel Solow <ref> [114] </ref> Consider how complicated this maze is. Suppose that at each step in the proof (maze) there are only 100 different ways of applying the theorems we know. This means that in each step in the maze, there are 100 different possible directions we could go. <p> The fact that his prover, TPS, uses full higher-order logic allows many complex statements about sets and functions to be stated more simply than is possible in the language of first-order logic with set-theory. Human-like techniques. Solow <ref> [114] </ref> and Polya [98] studied general heuristics used by humans in the theorem-proving process. They studied the basic tactics applied by mathematicians in trying to establish a statement as fact. Alan Bundy advocated attempts to encode some of these human techniques into systematic procedures and computer algorithms [42]. <p> Since the application of the "-rule resembles the way a human explains the application of a theorem, it makes it easier (than in the case of resolution, for example) for the programmer to think about human-like strategies for selecting theorems to apply <ref> [98, 114] </ref>. The strategies mentioned in Section 3.3 include the "n + m" strategy that prefers to apply theorems that do not add too much complexity to what remains to the proof after the theorem application.
Reference: [115] <author> Mark E. Stickel. </author> <title> A Prolog technology theorem prover: a new exposition and implementation in prolog. </title> <journal> Theoretical Computer Science, </journal> <volume> 104 </volume> <pages> 109-128, </pages> <year> 1992. </year> <month> 179 </month>
Reference-contexts: Many theorem proving programs use tableaux and related methods. PROTEIN [14], 3 T A P [19], lean-T A P [16], SETHEO [82], MGTP and it variants [66, 65], METEOR [6], Parthenon [35] and PTTP <ref> [115] </ref> are some of the better known systems. Most existing systems and calculi use clausal form for storing the theory. Some save some space by breaking a formula only to negation normal form [63]. This form still has the disadvantages associated with Skolem constants. <p> In this calculus, only the formulas themselves are entered. No indexing or additional information is provided. The "-rule is closely related to various strategies used in clausal tableaux [81]. The "- rule is distinct from existing rules for clausal tableau expansion in various ways. METEOR [6], Parthenon [35], PTTP <ref> [115] </ref>, SETHEO [82] and PROTEIN [14] use calculi closely related to model elimination. Therefore, they obey the connection condition. In a clausal context, the "-rule only uses the weak connection condition (set-of-support) as in Hahnle's ordered 147 tableaux [64].
Reference: [116] <author> Hao Wang. </author> <title> Proving theorems by pattern recognition I. </title> <editor> In Jorg Siekmann and Graham Wrightson, editors, </editor> <booktitle> Automation of Reasoning, </booktitle> <volume> volume 1, </volume> <pages> pages 229-243. </pages> <publisher> Springer-Verlag, </publisher> <year> 1983. </year> <journal> Reprinted from Communications of the Association for Computing Machinery, </journal> <volume> Vol. 3, No. 4, </volume> <month> April </month> <year> 1960. </year>
Reference-contexts: Their methods were related to the way humans present proofs. It is not difficult to translate proofs in their systems into readable natural-language proofs (Section 5.2.) Several of the early (late 1950s and early 1960s) automatic theorem proving programs (such as those of Hao Wang <ref> [116] </ref>) were based on the methods developed by Gentzen and Beth. A method called model-elimination, which is related to tableau methods, was developed by Loveland in the early 1960s [83]. Another group of researchers was working on automatic theorem provers based on the work of Herbrand and Skolem. <p> While this problem of selecting relevant earlier theorems to apply appears unimportant in the domain of logic as dealt with by the method to be described, it has to be faced at some stage, and the writer does not have a ready general solution of it. |Hao Wang <ref> [116] </ref> Mathematicians select and apply lemmas from an enormous knowledge base. <p> David McAllester developed a formal language that more closely resembles English [84, 87]. The proof system, Ontic, checks proofs in this language. Chapter 8 Conclusion . . . one could be too conservative in estimating the potentialities of machines in theorem proving. |Hao Wang. 1960 <ref> [116] </ref> In this chapter, we summarize the new results presented in this dissertation and present a history of the author's development of the ideas behind IPR and behind the IPR program itself. <p> Because of this early association with Kuipers, the early versions of IPR used his Algernon system to store and access the knowledge [47]. 156 place at least as early as Hao Wang's work in the late 1950s <ref> [116] </ref>. This has been called the n + 1 problem or the theorem n + 1 challenge. <p> There is another method, proposed long ago, for handling complex mathematical proofs. That is, in Hao Wang's words, the formation of "interlocked hierarchies of methods, and . . . a complex web of clearly understood, definite and deterministic algorithms. . . " <ref> [116] </ref>. What is intended here is the combination of special methods, many of which will be decision procedures, with a program that assigns each part of the proof to its appropriate method.
Reference: [117] <author> Hao Wang. </author> <title> Toward mechanical mathematics. </title> <editor> In Jorg Siekmann and Graham Wright-son, editors, </editor> <booktitle> Automation of Reasoning, </booktitle> <volume> volume 1, </volume> <pages> pages 244-264. </pages> <publisher> Springer-Verlag, </publisher> <year> 1983. </year> <journal> Reprinted from IBM Journal of Research and Development, </journal> <volume> 4, </volume> <pages> 2-22, </pages> <year> 1960. </year>
Reference-contexts: It seems, therefore, that the general domain of algorithmic analysis can now begin to be enriched by the inclusion of inferential analysis as a younger companion to the fairly well established but still rapidly developing leg of numerical analysis. |Hao Wang <ref> [117] </ref> Woody Bledsoe had a famous dream. He dreamt of a reasoning machine that would help people solve problems from the mundane to the crucial [27]. Indeed, in the late 1950s and early 1960s, computer implementations of proof procedures began to be reported. <p> Hao Wang, a logician who was aware of the theoretical difficulty of the problem of the automation of reasoning, was optimistic. He expected that computers would come into common use as proof assistants for working mathematicians just as they are used today to solve numerical problems <ref> [117] </ref>. Woody Bledsoe, an expert not only in mathematical analysis but in theorem-proving technology, was optimistic. He dreamt of a reasoning machine that would help people solve problems from the mundane to the crucial [27]. Larry Wos, another expert with a background in mathematics, is optimistic [121].
Reference: [118] <author> Stephen Wolfram. </author> <title> The Mathematica Book. </title> <publisher> Cambridge University Press, </publisher> <address> third edition, </address> <year> 1996. </year>
Reference-contexts: The solution to the fetching problem mentioned above would go quite far in the direction of controlling rewriting but some proofs will require some of the more powerful rewriting techniques that are used by other systems <ref> [118, 122, 123] </ref>. This would be even more important for texts in more algebraic fields. The current framework does not control rewriting well at all. There are many existing provers that easily outperform it on problems that are Horn or otherwise related to rewriting.
Reference: [119] <author> Larry Wos. </author> <title> Editorial: A journal is born. </title> <journal> Journal of Automated Reasoning, </journal> <volume> 1(1), </volume> <year> 1985. </year>
Reference-contexts: These proofs remain challenging for this approach, other approaches and humans. Chapter 5 IPR: Control and Interface Excellent software is needed to conduct such experimentation adequately. Indeed, the three|theory, software, and applications|are interconnected, and each plays an indispensable role in automated reasoning. |Larry Wos <ref> [119] </ref> The main goal of research in automated theorem proving is to build programs that are effective in finding or helping to find proofs of theorems from mathematics and other fields of application. |Bledsoe and Henschen [25] IPR is the name of a computer program that uses the calculi described in
Reference: [120] <author> Larry Wos. </author> <title> Automated Reasoning: 33 Basic Research Problems. </title> <publisher> Prentice-Hall, </publisher> <address> Engle-wood Cliffs, </address> <year> 1988. </year>
Reference-contexts: More precisely, just as the employment of paramod-ulation permits one to avoid using any equality axioms other than reflexivity, the sought-after inference rule for set theory would permit one to avoid using a number of the axioms in Godel's approach. |Larry Wos <ref> [120] </ref> Various approaches have been invented for enabling an automated theorem proving program to find proofs in set theory. Some take a small fragment of set theory and develop decision procedures [43]. Others prove theorems using a variant of Godel's axioms of set theory [101]. <p> The calculus described here is a step in an unusual direction toward a solution to Wos' eighth basic research problem|an inference rule for set theory <ref> [120] </ref>. It will be clear that the direction is very promising and that there is plenty of room for more work in this direction. It might be said that the rules here solve the problem in one direction (the easy direction.) That is, classes are easily deconstructed. <p> (8r)((an-element (r) ^ U (r)) r = c)) U ( x (U (x))) The comprehension schema bypasses many of Godel's axioms because Godel's set theory is a first-order theory [60]. (The idea of bypassing the axioms is suggested by Wos as the better way to solve his eighth research problem <ref> [120] </ref>.) If the user is proving theorems in Godel's theory, then the comprehension schema will never be applied since there is no classifier in Godel's set theory. To prove theorems in Godel's theory, an ordinary (or special purpose) first-order logic prover should be used. <p> The fact that this rule only goes in one direction makes it unable to solve some difficult problems in set theory. For example, Wos <ref> [120] </ref> puts forward a challenge for any inference rule claiming to have solved his eighth research problem. This is the proof that G=Ker (f ) ~ = H where f : G ! H is an onto homomorphism. <p> Other appropriate test problems include theorems from elementary group theory, point set topology, and number theory. |Larry Wos <ref> [120] </ref> If the usual definitions and lemmas pertaining to this theory were present in the knowledge base of a prover using the "-rule [109] as well as the rules for set theory presented here and 100 some slightly more sophisticated equality rules, then the prover could find a proof if the <p> specific problem to solve|bearing in mind the tight coupling of representation, inference rule, and strategy|what metarules enable one to simultaneously choose the best representation to use, the most effective inference rule (s) to employ, and the most powerful strategy or strategies to control the chosen inference rule (s)? |Larry Wos <ref> [120] </ref> Until now, we have discussed an abstract logical calculus for first-order logic. The definition of the calculus does not absolutely determine how the rules will be implemented and controlled. <p> The examples in Chapter 6 use newer templates. Chapter 6 Examples Real problems must be used as test problems to evaluate the worth of an idea; syntactic problems can be used as illustrations, and can also be used for experiments that may lead to important discoveries. |Larry Wos <ref> [120] </ref> IPR has independently found the proofs of many theorems in various fields of mathematics in the presence of relatively interesting knowledge bases. By independently, we mean that the user only entered the needed formulas and the formula to be proved. The user provided no guidance during the proof. <p> apparently quite different, no need exists for emulating the reasoning a person might employ, for the objective is to design and implement powerful and effective procedures to be used in a computer program that reasons; a study of how people solve problems, however, might lead to important breakthroughs. |Larry Wos <ref> [120] </ref> The famous quotation attributed to Edsgar Dijkstra is also used: to ask whether a computer can be intelligent is like asking whether a submarine can swim. The point is that computers and humans presumably operate differently. <p> A related problem is to try to have classes be constructed intelligently as is needed for the satisfactory solution of the problem posed by Wos to test a system claiming to solve his eighth research problem <ref> [120] </ref>. Experimentation has convinced me that control issues are an extremely important factor contributing to the success or failure of a program using any given logical calculus.
Reference: [121] <author> Larry Wos. </author> <title> Automated reasoning: It cannot exist. Keynote Address at CADE 92, </title> <address> Saratoga Springs, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: Woody Bledsoe, an expert not only in mathematical analysis but in theorem-proving technology, was optimistic. He dreamt of a reasoning machine that would help people solve problems from the mundane to the crucial [27]. Larry Wos, another expert with a background in mathematics, is optimistic <ref> [121] </ref>. The programs developed by his group have already solved problems that confounded some of the greatest mathematicians of this century [89]. While great success has been attained, there has been much frustration and disappointment.
Reference: [122] <author> Larry Wos, Ross Overbeek, Ewing Lusk, and Jim Boyle. </author> <title> Automated Reasoning: Introduction and Applications. </title> <publisher> McGraw-Hill, Inc., </publisher> <address> second edition, </address> <year> 1992. </year>
Reference-contexts: This technique has been expanded, specialized and generalized by Kapur [76, 124], Bachmair [9] and Dershowitz [51]. Larry Wos and his group incorporated their own rewriting techniques into their resolution provers <ref> [122] </ref>. These methods are called demodulation and paramodulation. Another method for handling equality is called the congruence closure technique [85, 92, 105]. This method is complete for ground equality. <p> We do not give the details of the resolution procedure here. The interested reader should see the apropriate references in the bibliography <ref> [45, 122] </ref>. In Section 2.3.1, we present the procedure for translating a formula into clausal (or Kowal-ski) form. 27 2.2.1 Tableaux Most existing tableau calculi can be divided into two classes: analytic and clausal. <p> The solution to the fetching problem mentioned above would go quite far in the direction of controlling rewriting but some proofs will require some of the more powerful rewriting techniques that are used by other systems <ref> [118, 122, 123] </ref>. This would be even more important for texts in more algebraic fields. The current framework does not control rewriting well at all. There are many existing provers that easily outperform it on problems that are Horn or otherwise related to rewriting.
Reference: [123] <author> Hantao Zhang. Herky: </author> <title> High performance rewriting in RRL. </title> <editor> In D. Kapur, editor, </editor> <booktitle> Proceedings of the Eleventh International Conference on Automated Deduction, volume 607 of Lecture Notes in Computer Science, </booktitle> <pages> pages 696-700. </pages> <publisher> Springer-Verlag, </publisher> <year> 1992. </year>
Reference-contexts: We discussed in Chapter 1 the problems associated with selecting knowledge from a large knowledge base. But let us not give up before we begin. Indeed, computer systems have already been developed that use rather large knowledge bases and make selections automatically <ref> [11, 13, 62, 84, 123] </ref>. These systems show their strength in and, to a large extent, are limited to Horn theories and theories that have the nature of rewrite rules. Other systems exist that apply knowledge based on hints or other information from the user [36, 53, 61, 84]. <p> The solution to the fetching problem mentioned above would go quite far in the direction of controlling rewriting but some proofs will require some of the more powerful rewriting techniques that are used by other systems <ref> [118, 122, 123] </ref>. This would be even more important for texts in more algebraic fields. The current framework does not control rewriting well at all. There are many existing provers that easily outperform it on problems that are Horn or otherwise related to rewriting.
Reference: [124] <author> Hantao Zhang and Deepak Kapur. </author> <title> First-order theorem proving using conditional rewrite rules. </title> <editor> In E. Lusk and R. Overbeek, editors, </editor> <booktitle> Proceedings of the Ninth International Conference on Automated Deduction, volume 310 of Lecture Notes in Computer Science, </booktitle> <pages> pages 1-20. </pages> <publisher> Springer-Verlag, </publisher> <year> 1988. </year>
Reference-contexts: Supposing that it is known that certain terms are equal, those equalities are automatically used to decide whether some new pair of terms are equal. This technique has been expanded, specialized and generalized by Kapur <ref> [76, 124] </ref>, Bachmair [9] and Dershowitz [51]. Larry Wos and his group incorporated their own rewriting techniques into their resolution provers [122]. These methods are called demodulation and paramodulation. Another method for handling equality is called the congruence closure technique [85, 92, 105]. This method is complete for ground equality.
References-found: 124

