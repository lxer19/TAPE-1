URL: http://polaris.cs.uiuc.edu/reports/1042.ps.gz
Refering-URL: http://polaris.cs.uiuc.edu/tech_reports.html
Root-URL: http://www.cs.uiuc.edu
Title: A Control-Flow Normalization Algorithm and Its Complexity  
Author: Zahira Ammarguellat 
Keyword: Index Terms: Continuations, control-flow, elimination algorithms, normalization, program transformations, reducibility, structured programs.  
Date: July 17, 1992  
Address: Urbana, Illinois, 61801  
Affiliation: Center for Supercomputing Research and Development University of Illinois at Urbana-Champaign  
Abstract: We present a simple method for normalizing the control-flow of programs to facilitate program transformations, program analysis, and automatic parallelization. While previous methods result in programs whose control flowgraphs are reducible, programs normalized by this technique satisfy a stronger condition than reducibility and are therefore simpler in their syntax and structure than with previous methods. In particular, all control-flow cycles are normalized into single-entry, single-exit while loops, and all goto's are eliminated. Furthermore, the method avoids problems of code replication that are characteristic of node-splitting techniques. This restructuring obviates the control dependence graph, since afterwards control dependence relations are manifest in the syntax tree of the program. In this paper we present transformations that effect this normalization, and study the complexity of the method. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A.V. Aho, J.E. Hopcroft, and J.D. Ullman. </author> <title> The Design and Analysis of Computer Algorithms. </title> <publisher> Addison-Wesley, </publisher> <year> 1976. </year>
Reference-contexts: The search for common factors in the reduced equations allows a saving in the calculation <ref> [1, 37, 46] </ref>.
Reference: [2] <author> A.V. Aho and J.D. Ullman. </author> <title> The Theory of Parsing, </title> <journal> Translation and Computing, </journal> <volume> Vol. </volume> <booktitle> II: Computing. </booktitle> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1973. </year>
Reference-contexts: In accordance with the resolution order we have chosen, the predecessors of i will be treated before i itself. When we come to substitute i, it will appear in the equation of its nearest dominator h <ref> [2] </ref>. After factorization of h, i will appear only once in h, and will be substituted for only once. Case 2: i is in a loop whose header is h but i and h are distinct. <p> Some syntactic restrictions are imposed upon the input program as well. The algorithm is divided in two steps: locating the loops in the flowgraph and adding branching statements. The first step uses the classical notion of dominators <ref> [2] </ref> after building the depth-first spanning tree of the flowgraph. The second step of the algorithm adds branching statements to the basic form of the program generated in the first step. The algorithm can be extended to handle irreducible graphs.
Reference: [3] <author> F. Allen, M. Burke, P. Charles, R. Cytron, and J. Ferrante. </author> <title> An overview of the ptran analysis system for multiprocessing. </title> <type> Technical Report RC 13115 (#56866), </type> <institution> IBM, New-york, </institution> <year> 1987. </year>
Reference-contexts: The increased complexity of a continuation semantics is translated to increased complexity in any program analysis that models the semantics, e.g., abstract interpretation or dataflow analysis. Third, our technique obviates the control dependence graph. Much effort is spent in traditional parallelizing compilers in the treatment of control dependences <ref> [3] </ref>. We will argue that when the control-flow of a program is properly normalized, control dependence relations are so manifest in the syntax tree of the normalized program that there is no need for a separate representation of such dependences. <p> In a program normalized by our method, control dependences are, in effect, represented directly by the syntax tree since each conditional structure contains all the expressions it controls. Since the analysis of control dependences is central to the work of parallelizing programs <ref> [3] </ref>, this is a significant simplification. This work has been implemented in PAF [44], a parallelizer of Fortran programs written at the University of Paris 6, and in MIPRAC, a multilingual parallelizer of programs at the University of Illinois.
Reference: [4] <author> F.E. Allen and J. Cocke. </author> <title> A program data flow analysis procedure. </title> <journal> CACM, </journal> <volume> 19(3), </volume> <month> March </month> <year> 1977. </year>
Reference-contexts: It does not treat irreducible graphs, but it can be adjusted to handle them. The equations it uses are quite different from ours. They represent the dataflow equations of the program. They describe the reaching definitions of each variable of the program <ref> [4, 38] </ref>. The Allen and Cocke algorithm consists of the iteration of three phases: a partitioning algorithm that finds single entry regions in the dependency graph, elimination of the dataflow equations, and finally propagation. The elimination process turns out to be the application of successive substitution and loop-breaking transformations.
Reference: [5] <author> J.R. Allen, K. Kennedy, C. Porterfield, and J. Warren. </author> <title> Conversion of control dependence to data dependence. </title> <booktitle> POPL, </booktitle> <month> January </month> <year> 1983. </year>
Reference-contexts: If we wish the compiler to work always with a normalized program, we may apply normalization following such transformations. A lot of work has been done in the normalization of the control-flow of programs <ref> [10, 47, 12, 5] </ref>. <p> It appears, however, that the boolean expressions generated by the normalization are small enough that simplification would not be a major expense. 6 Position of Our Work Several techniques exist for structuring flowgraphs <ref> [13, 28, 33, 11, 12, 5] </ref>. Most of these techniques consist of modifications such eliminating goto statements, adding control-flow variables, copying code, creating and calling procedures and adding levels of iteration. <p> None presents a simple comprehensive algorithm for the normalization of all control flowgraphs. We present, below, a limited overview of each of these methods; however, we emphasize Kennedy's method <ref> [5] </ref>, since it is the most recent and the closest to our own method. Bohm and Jacopini [13] present two normalization methods of flow diagrams. They decompose the flow diagrams into base diagrams of three types or two types. <p> Allen and Kennedy's method for converting control dependences to data dependences is called if conversion <ref> [5] </ref>. The primary goal of this transformation is to transform programs for the purpose of vectorization. It takes every do loop of a program and transforms each of its statement into a guarded one. <p> Branch removal eliminates forward branches by attaching guard expressions to targets. If conversion has goals similar to our normalization method. Its shortcomings are presented below along with differences between it and our work. The examples that are used below are taken from Allen and Kennedy's paper <ref> [5] </ref> and are written in a Fortran-like syntax. The normalized forms are also written in this same syntax in order to make the differences more apparent. The first problem with if conversion is that backward branches are improperly identified as those whose targets precede them (lexically). <p> The first problem with if conversion is that backward branches are improperly identified as those whose targets precede them (lexically). Thus the program in figure 26 is treated in the reference paper <ref> [5] </ref> as a cycle; the if conversion algorithm detects GOTO 100 as being a backward branch. But if we follow carefully the control-flow of the code, there is no loop in this program. The program obtained after if conversion is in figure 27. <p> A boolean variable is used to record which branches are taken to reach statements in the loop body. The resulting program contains a goto, and the cycle of control-flow has not been replaced by a structured loop. A subsequent transformation (not described in the reference paper <ref> [5] </ref>) must be used to replace this backward branch by a while loop. By contrast, our method produces the program of figure 31, using a uniform treatment of reducible and irreducible flowgraphs (since the flowgraph is irreducible, there is some code replication). <p> This framework has made it easy for us to prove that our transformations preserve the semantics of programs. It is applicable to a variety of languages and is more powerful than existing methods in several respects. First, in methods based upon node-splitting [12], and if conversion <ref> [5] </ref>, some branching instructions remain after transformations, and code replication may occur even when normalizing programs whose flowgraphs are reducible. Our method eliminates all branching instructions and replicates code only when eliminating irreducibility, a rare condition even in unstructured programs.
Reference: [6] <author> Z. Ammarguellat. </author> <title> Restructuration des Programmes Fortran en Vue de leur Parallelisation. </title> <type> PhD thesis, </type> <institution> Laboratoire MASI, Universite de Pierre et Marie-Curie, </institution> <address> Paris 6, France, </address> <year> 1988. </year>
Reference-contexts: The input language we treat has a Lisp-like syntax and includes branching instructions (goto's) and labels at the top-level of procedures. We applied this method to Fortran 77 and Le-Lisp [16] <ref> [6] </ref>, and are applying it to Common Lisp, and C [25]. <p> For the purpose of simplicity, the grammar includes only scalar variables. The normalization method we are presenting has been applied to Fortran and Lisp programs <ref> [6, 24] </ref>, and is by no means restricted to the treatment of scalar data; nor does it require restrictions upon side effects and aliasing. 2.3 Continuation Equations For a procedure P we may give a syntactic representation to the continuation associated with each program label I i . <p> Second, while previous methods result in programs with reducible flow-graphs, our method yields programs whose control flowgraphs are more highly structured yet; in particular, all control-flow cycles are normalized into single-entry, single-exit while loops. Such loops may be further transformed into conventional do loops by induction variable recognition <ref> [6, 9] </ref>. This makes our method particularly helpful in automatic parallelization, where highly regular loop structures are essential [32], [22]. It simplifies both forward and backward 35 dataflow analyses by transforming a program to one with an obvious, trivial internal structure.
Reference: [7] <author> Z. Ammarguellat. </author> <title> Normalization of program control flow. </title> <type> Technical Report CSRD 885, </type> <institution> Center for Supercomputing Research and Development, University of Illinois at Urbana-Champaign, </institution> <month> May </month> <year> 1989. </year>
Reference-contexts: The result is a new store (state of memory). Usually continuations are associated with each point of a program. In our approach a point will represent a program label. The author provides, for the interested reader, a denotational semantics with continuations for the primitive expressions of our language <ref> [7, 8] </ref>.
Reference: [8] <author> Z. Ammarguellat. </author> <title> A control-flow normalization algorithm and its complexity. </title> <type> Technical report, </type> <institution> Center for Supercomputing Research and Development, University of Illinois at Urbana-Champaign, </institution> <year> 1990. </year>
Reference-contexts: The result is a new store (state of memory). Usually continuations are associated with each point of a program. In our approach a point will represent a program label. The author provides, for the interested reader, a denotational semantics with continuations for the primitive expressions of our language <ref> [7, 8] </ref>.
Reference: [9] <author> Z. Ammarguellat and W.L. Harrison III. </author> <title> Automatic recognition of induction variables and recurrence relations by abstract interpretation corrected version. </title> <booktitle> In Sigplan'90 Conference on Programming Languages Design and Implementation. </booktitle> <publisher> ACM Press, </publisher> <year> 1990. </year>
Reference-contexts: PAF is an experimental Fortran parallelizer developed at the University of Paris 6 (France). In PAF the normalization method has two applications. The first is to convert every cycle (explicit or implicit) into while loops, which are themselves transformed into do loops whenever possible <ref> [9] </ref>, and finally into doall loops when the dependences permit it. In other words, even when a programmer writes loops using goto's, or writes unstructured do loops, they are made eligible for parallelization by normalization. The second purpose is vectorization. <p> Second, while previous methods result in programs with reducible flow-graphs, our method yields programs whose control flowgraphs are more highly structured yet; in particular, all control-flow cycles are normalized into single-entry, single-exit while loops. Such loops may be further transformed into conventional do loops by induction variable recognition <ref> [6, 9] </ref>. This makes our method particularly helpful in automatic parallelization, where highly regular loop structures are essential [32], [22]. It simplifies both forward and backward 35 dataflow analyses by transforming a program to one with an obvious, trivial internal structure.
Reference: [10] <author> E. Ashcroft and Z. Manna. </author> <title> The translation of 'goto' programs to 'while' programs. </title> <booktitle> In Proceedings of IFIP Congress 71. </booktitle> <address> Amsterdam, </address> <year> 1972. </year>
Reference-contexts: If we wish the compiler to work always with a normalized program, we may apply normalization following such transformations. A lot of work has been done in the normalization of the control-flow of programs <ref> [10, 47, 12, 5] </ref>.
Reference: [11] <author> E. Ashcroft and Z. Manna. </author> <title> Translating program schemas to while-schemas. </title> <journal> SIAM Journal of Computing, </journal> <volume> 4(2), </volume> <year> 1975. </year>
Reference-contexts: It appears, however, that the boolean expressions generated by the normalization are small enough that simplification would not be a major expense. 6 Position of Our Work Several techniques exist for structuring flowgraphs <ref> [13, 28, 33, 11, 12, 5] </ref>. Most of these techniques consist of modifications such eliminating goto statements, adding control-flow variables, copying code, creating and calling procedures and adding levels of iteration. <p> The method replicates code in normalizing reducible flowgraphs (no bound is given on the size of the resulting program) and the resulting programs have multiple-exit loops, and branches that exit several nested control structures. Ashcroft and Manna <ref> [11] </ref> introduce two transformations to translate programs with goto's into programs without. The first one adds temporary variables and the second adds logical variables to the program. The first method replicates code in normalizing reducible flowgraphs, and both methods result in loops with multiple exits.
Reference: [12] <author> B. Baker. </author> <title> An algorithm for structuring flowgraphs. </title> <journal> JACM, </journal> <volume> 24(1), </volume> <year> 1977. </year>
Reference-contexts: If we wish the compiler to work always with a normalized program, we may apply normalization following such transformations. A lot of work has been done in the normalization of the control-flow of programs <ref> [10, 47, 12, 5] </ref>. <p> It appears, however, that the boolean expressions generated by the normalization are small enough that simplification would not be a major expense. 6 Position of Our Work Several techniques exist for structuring flowgraphs <ref> [13, 28, 33, 11, 12, 5] </ref>. Most of these techniques consist of modifications such eliminating goto statements, adding control-flow variables, copying code, creating and calling procedures and adding levels of iteration. <p> Ashcroft and Manna [11] introduce two transformations to translate programs with goto's into programs without. The first one adds temporary variables and the second adds logical variables to the program. The first method replicates code in normalizing reducible flowgraphs, and both methods result in loops with multiple exits. Baker <ref> [12] </ref> concentrates on making programs more understandable rather than on eliminating the goto statements entirely. Some goto statements are generated when they give a clearer description of the control-flow. Some syntactic restrictions are imposed upon the input program as well. <p> This framework has made it easy for us to prove that our transformations preserve the semantics of programs. It is applicable to a variety of languages and is more powerful than existing methods in several respects. First, in methods based upon node-splitting <ref> [12] </ref>, and if conversion [5], some branching instructions remain after transformations, and code replication may occur even when normalizing programs whose flowgraphs are reducible. Our method eliminates all branching instructions and replicates code only when eliminating irreducibility, a rare condition even in unstructured programs.
Reference: [13] <author> C. Bohm and G. Jacopini. </author> <title> Flow diagrams, turing machines and languages with only two formation rules. </title> <journal> CACM, </journal> <volume> 9(5), </volume> <year> 1966. </year>
Reference-contexts: Williams and Ossher [47] have proved that such an elimination is necessary and sufficient to obtain a structured form of the program. A theorem of Bohm and Jacopini <ref> [13] </ref> says that we may transform any program into another one where only the following three control structures are used: * Assignment 3 * Conditional * Iteration However, their theorem is not constructive in that it does not give a method for deriving such a program. <p> The only control structures used in these systems are the three proposed by Bohm and Jacopini <ref> [13] </ref>. The solution to this system will represent the normalized form of the procedure. In the next section we will present the method we choose to solve this system. 2.4 Gaussian Elimination-Like Resolution A straightforward Gaussian elimination-like resolution method may be used to solve the system of continuation equations. <p> It appears, however, that the boolean expressions generated by the normalization are small enough that simplification would not be a major expense. 6 Position of Our Work Several techniques exist for structuring flowgraphs <ref> [13, 28, 33, 11, 12, 5] </ref>. Most of these techniques consist of modifications such eliminating goto statements, adding control-flow variables, copying code, creating and calling procedures and adding levels of iteration. <p> None presents a simple comprehensive algorithm for the normalization of all control flowgraphs. We present, below, a limited overview of each of these methods; however, we emphasize Kennedy's method [5], since it is the most recent and the closest to our own method. Bohm and Jacopini <ref> [13] </ref> present two normalization methods of flow diagrams. They decompose the flow diagrams into base diagrams of three types or two types.
Reference: [14] <author> R.A. Brooks, R.P. Gabriel, and G.L. Steele Jr. </author> <title> An optimizing compiler for lexically scoped lisp. </title> <journal> ACM SIGPLAN Notices, </journal> <volume> 17(6), </volume> <month> June </month> <year> 1982. </year> <month> 37 </month>
Reference-contexts: Unnormalized programs may arise in several ways. First, unstructured programs can be written in languages such as Common Lisp, Fortran, Pascal or C. Second, the compiler itself may produce unstructured code when it applies classical program transformations such as tail recursion elimination <ref> [14] </ref>. For an example see figures 1 and 2. Other transformations such as recursion splitting [22] result in even more complex output than the tail recursion elimination. If we wish the compiler to work always with a normalized program, we may apply normalization following such transformations.
Reference: [15] <author> B.A. Carre. </author> <title> An algebra for network routing problems. </title> <journal> J. Inst. Math. Applic., </journal> <volume> 7, </volume> <year> 1971. </year>
Reference-contexts: These include global flow analysis [19, 20], shortest path problems <ref> [15, 18, 26] </ref> and conversion of finite automata to regular expressions [41]. The fundamental framework of these problems is to build a system of equations based on regions of a flowgraph and to solve this system using the Gaussian resolution.
Reference: [16] <author> J. </author> <note> Chailloux. Le-Lisp Version 15. </note> <institution> INRIA, Rocquencourt, France. </institution>
Reference-contexts: The input language we treat has a Lisp-like syntax and includes branching instructions (goto's) and labels at the top-level of procedures. We applied this method to Fortran 77 and Le-Lisp <ref> [16] </ref> [6], and are applying it to Common Lisp, and C [25].
Reference: [17] <author> J. Davies, C. Huson, T. Macke, B. Leasure, and M. Wolfe. </author> <title> The kaps-1: An advanced source-to-source vectorizer for the s-1 mark iia supercomputer. </title> <booktitle> In Proceedings of the 1986 International Conference on Parallel Processing, </booktitle> <year> 1986. </year>
Reference-contexts: The second purpose is vectorization. In order to vectorize statements that are conditionally executed in a loop, one must attach boolean variables (mode vectors) to the statements <ref> [29, 48, 17, 32] </ref>. By control-flow normalization we may accomplish this easily for any program. MIPRAC is a multilingual compiler for shared memory machines being implemented at the University of Illinois. Its applications of the normalization method are much more ambitious.
Reference: [18] <author> R. Floyd. </author> <title> Shortest path. </title> <journal> CACM, </journal> <volume> 5(6), </volume> <year> 1962. </year>
Reference-contexts: These include global flow analysis [19, 20], shortest path problems <ref> [15, 18, 26] </ref> and conversion of finite automata to regular expressions [41]. The fundamental framework of these problems is to build a system of equations based on regions of a flowgraph and to solve this system using the Gaussian resolution.
Reference: [19] <author> S. Graham and M. Wegman. </author> <title> Fast and usually linear algorithm for global flow analysis. </title> <journal> JACM, </journal> <volume> 23(1), </volume> <month> January 76. </month>
Reference-contexts: These include global flow analysis <ref> [19, 20] </ref>, shortest path problems [15, 18, 26] and conversion of finite automata to regular expressions [41]. The fundamental framework of these problems is to build a system of equations based on regions of a flowgraph and to solve this system using the Gaussian resolution. <p> A simpler algorithm that runs in O (n log n) exists [43]. 7.4 Graham and Wegman Method This algorithm is close to Tarjan's interval analysis; but it handles irreducible graphs without the need for eliminating the irreducibility. The notion of intervals is called here S-sets <ref> [19] </ref>. They represent the loops in the flowgraph. The S-sets are defined by a numbering of the nodes of the dependency graph associated with the equations; this numbering is performed using a depth-first order. <p> This is because the backward flowgraph of a normalized program is also normalized, whereas a flowgraph that is merely structured, may be unstructured when its edges are reversed. Finally, even though closures may still be required for loops, especially for non-fast problems <ref> [19, 43] </ref>, these will be simpler than for a non-normalized program. 8 Conclusion In this paper we have presented an algebraic framework for normalization of control-flow. This framework has made it easy for us to prove that our transformations preserve the semantics of programs.
Reference: [20] <author> M.S. Hecht. </author> <title> Flow Analysis of Computer Programs. </title> <publisher> Elsevier North-Holland, </publisher> <address> Amsterdam, </address> <year> 1977. </year>
Reference-contexts: To compare these two methods and to measure their respective cost, we have run an experiment that normalizes the scientific computations of the Perfect Club [34]. See figures 24 and 25 in section 5. 2.5.4 Derecursivation Derecursivation, like T 1 Hecht's transformation <ref> [20] </ref>, consists of making a loop explicit. <p> 2 (begin (set! pred 2 Exp 2 ) (if pred 2 Cmd 3 Cmd 4 ))) (and (not pred 1 ) (not pred 2 )))) (if pred 1 x j (begin (if pred 2 x k )))) 2.5.5 Substitution and Elimination (T 0 2 ) 2 , like T 2 <ref> [20] </ref>, consists of substituting an unknown in the continuations system and of eliminating its equation from this system. However, Hecht [20] performs T 2 on unknowns that have only a single use in the system. <p> ) (not pred 2 )))) (if pred 1 x j (begin (if pred 2 x k )))) 2.5.5 Substitution and Elimination (T 0 2 ) 2 , like T 2 <ref> [20] </ref>, consists of substituting an unknown in the continuations system and of eliminating its equation from this system. However, Hecht [20] performs T 2 on unknowns that have only a single use in the system. The T 0 2 transformation is not constrained by this condition since it replaces an unknown anywhere it appears in the system (i.e., an unknown may be replaced in several different equations). <p> These include global flow analysis <ref> [19, 20] </ref>, shortest path problems [15, 18, 26] and conversion of finite automata to regular expressions [41]. The fundamental framework of these problems is to build a system of equations based on regions of a flowgraph and to solve this system using the Gaussian resolution.
Reference: [21] <author> W.L. Harrison III. </author> <title> Compiling lisp for evaluation on a tightly coupled multiprocessor. </title> <type> Technical report, </type> <institution> Center for Supercomputing Research and Development, University of Illinois at Urbana-Champaign, </institution> <year> 1986. </year>
Reference-contexts: When restructuring an expression, we do not need to be concerned with branches into the middle of, and out from the middle of the expression: control flows into and out of the expression in an orderly way. The reader may look at Harrison's work <ref> [21] </ref> to see the difficulties that we may encounter for program transformations such as exit-loop parallelization and recursion splitting [22], when they are performed on a code that is not so structured.
Reference: [22] <author> W.L. Harrison III. </author> <title> The interprocedural analysis and automatic paralleliza-tion of scheme programs. Lisp and Symbolic Computation: </title> <journal> an International Journal, </journal> <volume> 2(3), </volume> <year> 1989. </year>
Reference-contexts: Second, the compiler itself may produce unstructured code when it applies classical program transformations such as tail recursion elimination [14]. For an example see figures 1 and 2. Other transformations such as recursion splitting <ref> [22] </ref> result in even more complex output than the tail recursion elimination. If we wish the compiler to work always with a normalized program, we may apply normalization following such transformations. A lot of work has been done in the normalization of the control-flow of programs [10, 47, 12, 5]. <p> This makes the analysis simpler to implement and more efficient. The reader may contrast the interprocedural analysis, where continuations are used <ref> [22] </ref>, to that where direct semantics are applied to programs whose procedures bodies are normalized [23]. The third application is to simplify program transformations. <p> The reader may look at Harrison's work [21] to see the difficulties that we may encounter for program transformations such as exit-loop parallelization and recursion splitting <ref> [22] </ref>, when they are performed on a code that is not so structured. By control-flow normalization, we effectively make while- and do- loop transformations applicable to all iterative structures by replacing arbitrary control-flow cycles by single-entry single-exit loops, and by reducing the number of different syntactic structures. <p> Such loops may be further transformed into conventional do loops by induction variable recognition [6, 9]. This makes our method particularly helpful in automatic parallelization, where highly regular loop structures are essential [32], <ref> [22] </ref>. It simplifies both forward and backward 35 dataflow analyses by transforming a program to one with an obvious, trivial internal structure. Third, our method makes the separate representation of control dependences unnecessary.
Reference: [23] <author> W.L. Harrison III. </author> <title> Pointers, procedures and parallelization. </title> <type> Technical report, </type> <institution> Center for Supercomputing Research and Development, University of Illinois at Urbana-Champaign, </institution> <year> 1991. </year>
Reference-contexts: This makes the analysis simpler to implement and more efficient. The reader may contrast the interprocedural analysis, where continuations are used [22], to that where direct semantics are applied to programs whose procedures bodies are normalized <ref> [23] </ref>. The third application is to simplify program transformations. When restructuring an expression, we do not need to be concerned with branches into the middle of, and out from the middle of the expression: control flows into and out of the expression in an orderly way.
Reference: [24] <author> W.L. Harrison III and Z. Ammarguellat. </author> <title> The design of parallelizers for symbolic and numeric programs. </title> <editor> In Takayasu Ito and Robert Halstead, editors, </editor> <booktitle> Proceedings of the 2nd US-Japan Workshop on Parallel Lisp, </booktitle> <month> June </month> <year> 1989. </year>
Reference-contexts: For the purpose of simplicity, the grammar includes only scalar variables. The normalization method we are presenting has been applied to Fortran and Lisp programs <ref> [6, 24] </ref>, and is by no means restricted to the treatment of scalar data; nor does it require restrictions upon side effects and aliasing. 2.3 Continuation Equations For a procedure P we may give a syntactic representation to the continuation associated with each program label I i . <p> equation the unknown for which to substitute, nor in factorization the cost of collecting and simplifying boolean conditions. 5 Application of the Normalization Process The normalization method that we have presented has been put to several uses in projects with which the author has been involved: PAF [44] and MIPRAC <ref> [24] </ref>. PAF is an experimental Fortran parallelizer developed at the University of Paris 6 (France). In PAF the normalization method has two applications.
Reference: [25] <author> W.L. Harrison III and Z. Ammarguellat. Miprac: </author> <title> A compiler for symbolic and numerical programs. </title> <type> Technical report, </type> <institution> Center for Supercomputing Research and Development, University of Illinois at Urbana-Champaign, </institution> <year> 1990. </year>
Reference-contexts: The input language we treat has a Lisp-like syntax and includes branching instructions (goto's) and labels at the top-level of procedures. We applied this method to Fortran 77 and Le-Lisp [16] [6], and are applying it to Common Lisp, and C <ref> [25] </ref>. The output language contains single-entry, single-exit while loops but neither goto's nor labels, and represents the normalized form of the program. 2.1 Denotational Semantics The semantics of a programming language is a precise mathematical specification of the meaning of programs in the language [42, 45, 40].
Reference: [26] <author> D.B. Jonhson. </author> <title> Efficient algorithms for shortest paths in sparse networks. </title> <journal> JACM, </journal> <volume> 24(1), </volume> <year> 1977. </year>
Reference-contexts: These include global flow analysis [19, 20], shortest path problems <ref> [15, 18, 26] </ref> and conversion of finite automata to regular expressions [41]. The fundamental framework of these problems is to build a system of equations based on regions of a flowgraph and to solve this system using the Gaussian resolution.
Reference: [27] <author> D.E. Knuth. </author> <title> Structured programming with goto statements. </title> <journal> ACM Computing Surveys, </journal> <volume> 6(4) </volume> <pages> 261-302, </pages> <year> 1974. </year>
Reference-contexts: Each of them may be appropriate for some cases; however the programs they produce are often less regular than those produced by our method and often contain more replicated code <ref> [27] </ref>. None presents a simple comprehensive algorithm for the normalization of all control flowgraphs. We present, below, a limited overview of each of these methods; however, we emphasize Kennedy's method [5], since it is the most recent and the closest to our own method.
Reference: [28] <author> D.E. Knuth and R.W. Floyd. </author> <title> Notes on avoiding go to statements. </title> <journal> Information Processing Letters, </journal> <volume> 1, </volume> <year> 1971. </year> <month> 38 </month>
Reference-contexts: It appears, however, that the boolean expressions generated by the normalization are small enough that simplification would not be a major expense. 6 Position of Our Work Several techniques exist for structuring flowgraphs <ref> [13, 28, 33, 11, 12, 5] </ref>. Most of these techniques consist of modifications such eliminating goto statements, adding control-flow variables, copying code, creating and calling procedures and adding levels of iteration. <p> Furthermore, the authors do not present a simple algorithm, but rather describe the method by pattern-matching of flowgraphs, which could be complex and costly to implement. Knuth and Floyd <ref> [28] </ref> study program transformations that eliminate goto statements without introducing new variables or modifying the sequence of the program computations.
Reference: [29] <author> David J. Kuck, Robert H. Kuhn, Bruce Leasure, and M. J. Wolfe. </author> <title> The structure of an advanced vectorized for pipelined processors. </title> <booktitle> In Fourth International Computer Software and Applications Conference, </booktitle> <year> 1980. </year>
Reference-contexts: The second purpose is vectorization. In order to vectorize statements that are conditionally executed in a loop, one must attach boolean variables (mode vectors) to the statements <ref> [29, 48, 17, 32] </ref>. By control-flow normalization we may accomplish this easily for any program. MIPRAC is a multilingual compiler for shared memory machines being implemented at the University of Illinois. Its applications of the normalization method are much more ambitious.
Reference: [30] <author> A. Mazurkiewicz. </author> <title> Proving algorithms by tail functions. </title> <journal> Information and Control, </journal> <volume> 18, </volume> <year> 1970. </year>
Reference-contexts: We must then switch from a direct semantics to a semantics with continuations. The theory of continuations was developed by C. Wadsworth and L. Morris independently. This notion originated from the "tail function" of Mazurkiewicz <ref> [30] </ref>. 2.1.1 Continuations Continuations are a powerful tool because they allow us to give a straightforward meaning to branches, exceptions and errors, and because they allow us to regain a degree of the compositionality we lose by having branches.
Reference: [31] <author> P.D. Mosses. </author> <title> The mathematical semantics of algol 60. </title> <type> Technical Monograph, P.R. G 12, </type> <month> January </month> <year> 1974. </year>
Reference-contexts: The idea of this approach is to define functions which map syntactic constructs into algebraic ones. This method is based on Scott and Strachey's work and has been used to define languages like ALGOL 60 <ref> [31] </ref>, PASCAL [45], and CLU [39]. Our input language contains branching instructions. Simple jumps make the semantics of programs more complex because we lose the compositionality of the semantics of commands. We must then switch from a direct semantics to a semantics with continuations.
Reference: [32] <author> D.A. Padua and M.J. Wolfe. </author> <title> Advanced compiler optimizations for supercomputers. </title> <journal> CACM, </journal> <volume> 29(12), </volume> <month> December </month> <year> 1986. </year>
Reference-contexts: The second purpose is vectorization. In order to vectorize statements that are conditionally executed in a loop, one must attach boolean variables (mode vectors) to the statements <ref> [29, 48, 17, 32] </ref>. By control-flow normalization we may accomplish this easily for any program. MIPRAC is a multilingual compiler for shared memory machines being implemented at the University of Illinois. Its applications of the normalization method are much more ambitious. <p> Such loops may be further transformed into conventional do loops by induction variable recognition [6, 9]. This makes our method particularly helpful in automatic parallelization, where highly regular loop structures are essential <ref> [32] </ref>, [22]. It simplifies both forward and backward 35 dataflow analyses by transforming a program to one with an obvious, trivial internal structure. Third, our method makes the separate representation of control dependences unnecessary.
Reference: [33] <author> W.W. Peterson, T. Kasami, and N. Tokura. </author> <title> On the capabilities of while , repeat and exit statements. </title> <journal> CACM, </journal> <volume> 16(8), </volume> <year> 1973. </year>
Reference-contexts: It appears, however, that the boolean expressions generated by the normalization are small enough that simplification would not be a major expense. 6 Position of Our Work Several techniques exist for structuring flowgraphs <ref> [13, 28, 33, 11, 12, 5] </ref>. Most of these techniques consist of modifications such eliminating goto statements, adding control-flow variables, copying code, creating and calling procedures and adding levels of iteration. <p> The second possibility is to write a flowchart according to the BNF they have defined. Both methods replicate code in normalizing reducible flowgraphs. The authors declare that these methods do not suffice to eliminate goto's in all programs. Peterson, Kasami and Tokura <ref> [33] </ref> define a well-formed program as a program in which loops and conditional statements are properly nested and have a single entry. To obtain such a program they use a node splitting transformation that may replicate code, or procedure calls in case the code replication is too big.
Reference: [34] <author> L. </author> <title> Pointer. </title> <type> Perfect club report. Technical Report 896, </type> <institution> Center for Supercomputing Research and Development, University of Illinois at Urbana-Champaign, </institution> <month> July </month> <year> 1989. </year>
Reference-contexts: To compare these two methods and to measure their respective cost, we have run an experiment that normalizes the scientific computations of the Perfect Club <ref> [34] </ref>. See figures 24 and 25 in section 5. 2.5.4 Derecursivation Derecursivation, like T 1 Hecht's transformation [20], consists of making a loop explicit.
Reference: [35] <institution> Proceedings of the IFIP Congress '71. A Basis for Program Optimization. IEEE, </institution> <address> North- Holland, Amsterdam, </address> <year> 1971. </year>
Reference-contexts: used for global dataflow analysis. e represents the number of edges in the flowgraph and is assumed to be in order O (n), where n in the number of nodes of the flowgraph. 7.1 Allen and Cocke Method This method, known as Interval Analysis, was introduced by Allen and Cocke <ref> [35] </ref>. It does not treat irreducible graphs, but it can be adjusted to handle them. The equations it uses are quite different from ours. They represent the dataflow equations of the program. They describe the reaching definitions of each variable of the program [4, 38].
Reference: [36] <author> E.M. Reingold, J. Nievergelt, and N. Deo. </author> <title> Combinatorial Algorithms - Theory and Practice. </title> <publisher> Prentice-Hall, </publisher> <year> 1977. </year>
Reference-contexts: For example, the graph associated with the system of equations in figure 4 is in figure 19. A topological ordering of the nodes of such a graph is a labeling of the nodes with integers 1,2,: : :; n <ref> [36] </ref>. Of course this graph must be acyclic for this ordering to be meaningful. Since, in general, our input graphs contain cycles, we order the nodes by first eliminating the back and cross edges of the graph and sorting the resulting graph in a topological order.
Reference: [37] <author> B.G. Ryder. </author> <title> Incremental data flow analysis based on a unified model of elimination algorithms. </title> <booktitle> In Conference Record of the Ninth Annual ACM Symposium on POPL, </booktitle> <pages> pages 167-176. </pages> <booktitle> ACM SIGPLAN, </booktitle> <year> 1982. </year>
Reference-contexts: The search for common factors in the reduced equations allows a saving in the calculation <ref> [1, 37, 46] </ref>.
Reference: [38] <author> B.G. Ryder and M.C. Paull. </author> <title> Elimination algorithms for data flow analysis. </title> <journal> ACM Computing Surveys, </journal> <volume> 18(3), </volume> <month> September </month> <year> 1986. </year>
Reference-contexts: Similarly, the method makes it unnecessary to perform interval analysis as part of dataflow analysis, because after normalization the internal structure of a program is obvious and trivial. It may therefore be used to simplify the implementation of dataflow analysis since pathological flowgraphs <ref> [38] </ref> will not exist. Unnormalized programs may arise in several ways. First, unstructured programs can be written in languages such as Common Lisp, Fortran, Pascal or C. Second, the compiler itself may produce unstructured code when it applies classical program transformations such as tail recursion elimination [14]. <p> PRED-22) B (I) = X + 10 (2) ENDIF IF (.NOT. ((.NOT. PRED-20) .AND. PRED-22)) A (I) = B (I) + A (I) called elimination algorithms. Ryder and Paull present a comparison of these four algorithms <ref> [38] </ref>. They are, in general, described for a specific implementation, and therefore it is difficult to see their common points and differences. Our goal is to give a presentation of these algorithms describing their complexity and performances. <p> It does not treat irreducible graphs, but it can be adjusted to handle them. The equations it uses are quite different from ours. They represent the dataflow equations of the program. They describe the reaching definitions of each variable of the program <ref> [4, 38] </ref>. The Allen and Cocke algorithm consists of the iteration of three phases: a partitioning algorithm that finds single entry regions in the dependency graph, elimination of the dataflow equations, and finally propagation. The elimination process turns out to be the application of successive substitution and loop-breaking transformations.
Reference: [39] <author> R.W. Scheifler. </author> <title> A denotational Semantics of CLU. </title> <address> U.S.A, </address> <month> May </month> <year> 1978. </year>
Reference-contexts: The idea of this approach is to define functions which map syntactic constructs into algebraic ones. This method is based on Scott and Strachey's work and has been used to define languages like ALGOL 60 [31], PASCAL [45], and CLU <ref> [39] </ref>. Our input language contains branching instructions. Simple jumps make the semantics of programs more complex because we lose the compositionality of the semantics of commands. We must then switch from a direct semantics to a semantics with continuations. The theory of continuations was developed by C. Wadsworth and L.
Reference: [40] <author> D.A. Schmidt. </author> <title> Denotational Semantics. </title> <publisher> Allyn and Bacon, </publisher> <address> Newton, MA, </address> <year> 1986. </year>
Reference-contexts: The output language contains single-entry, single-exit while loops but neither goto's nor labels, and represents the normalized form of the program. 2.1 Denotational Semantics The semantics of a programming language is a precise mathematical specification of the meaning of programs in the language <ref> [42, 45, 40] </ref>. The idea of this approach is to define functions which map syntactic constructs into algebraic ones. This method is based on Scott and Strachey's work and has been used to define languages like ALGOL 60 [31], PASCAL [45], and CLU [39]. Our input language contains branching instructions.
Reference: [41] <author> C. Shannon and J.McCarthy. </author> <title> Representation of events in nerve nets and finite automata. Automata Studies, </title> <year> 1956. </year>
Reference-contexts: These include global flow analysis [19, 20], shortest path problems [15, 18, 26] and conversion of finite automata to regular expressions <ref> [41] </ref>. The fundamental framework of these problems is to build a system of equations based on regions of a flowgraph and to solve this system using the Gaussian resolution.
Reference: [42] <author> J.E. Stoy. </author> <title> Denotational Semantics: The Schott-Strachey Approach to Programming Language Theory. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1977. </year>
Reference-contexts: The output language contains single-entry, single-exit while loops but neither goto's nor labels, and represents the normalized form of the program. 2.1 Denotational Semantics The semantics of a programming language is a precise mathematical specification of the meaning of programs in the language <ref> [42, 45, 40] </ref>. The idea of this approach is to define functions which map syntactic constructs into algebraic ones. This method is based on Scott and Strachey's work and has been used to define languages like ALGOL 60 [31], PASCAL [45], and CLU [39]. Our input language contains branching instructions.
Reference: [43] <author> R.E. Tarjan. </author> <title> Fast algorithms for solving path problems. </title> <journal> JACM, </journal> <volume> 28(3), </volume> <month> July </month> <year> 1981. </year>
Reference-contexts: Again this method is applied to reducible flowgraphs. For such a graph the algorithm requires a time of O (nff (n)) where ff is the inverse of Ackerman's function. A simpler algorithm that runs in O (n log n) exists <ref> [43] </ref>. 7.4 Graham and Wegman Method This algorithm is close to Tarjan's interval analysis; but it handles irreducible graphs without the need for eliminating the irreducibility. The notion of intervals is called here S-sets [19]. They represent the loops in the flowgraph. <p> This is because the backward flowgraph of a normalized program is also normalized, whereas a flowgraph that is merely structured, may be unstructured when its edges are reversed. Finally, even though closures may still be required for loops, especially for non-fast problems <ref> [19, 43] </ref>, these will be simpler than for a non-normalized program. 8 Conclusion In this paper we have presented an algebraic framework for normalization of control-flow. This framework has made it easy for us to prove that our transformations preserve the semantics of programs.
Reference: [44] <author> N. Tawbi, A. Dumay, and P. Feautrier. Paf: </author> <title> un paralleliseur automatique pour fortran. </title> <type> Technical Report 185, </type> <institution> Laboratoire MASI , Universite de Pierre et Marie-Curie, </institution> <address> Paris 6, France, </address> <month> May </month> <year> 1988. </year> <month> 39 </month>
Reference-contexts: find within the equation the unknown for which to substitute, nor in factorization the cost of collecting and simplifying boolean conditions. 5 Application of the Normalization Process The normalization method that we have presented has been put to several uses in projects with which the author has been involved: PAF <ref> [44] </ref> and MIPRAC [24]. PAF is an experimental Fortran parallelizer developed at the University of Paris 6 (France). In PAF the normalization method has two applications. <p> Since the analysis of control dependences is central to the work of parallelizing programs [3], this is a significant simplification. This work has been implemented in PAF <ref> [44] </ref>, a parallelizer of Fortran programs written at the University of Paris 6, and in MIPRAC, a multilingual parallelizer of programs at the University of Illinois.
Reference: [45] <author> R.D. Tennent. </author> <title> The denotational semantics of programming languages. </title> <journal> CACM, </journal> <volume> 19(8), </volume> <year> 1976. </year>
Reference-contexts: The output language contains single-entry, single-exit while loops but neither goto's nor labels, and represents the normalized form of the program. 2.1 Denotational Semantics The semantics of a programming language is a precise mathematical specification of the meaning of programs in the language <ref> [42, 45, 40] </ref>. The idea of this approach is to define functions which map syntactic constructs into algebraic ones. This method is based on Scott and Strachey's work and has been used to define languages like ALGOL 60 [31], PASCAL [45], and CLU [39]. Our input language contains branching instructions. <p> The idea of this approach is to define functions which map syntactic constructs into algebraic ones. This method is based on Scott and Strachey's work and has been used to define languages like ALGOL 60 [31], PASCAL <ref> [45] </ref>, and CLU [39]. Our input language contains branching instructions. Simple jumps make the semantics of programs more complex because we lose the compositionality of the semantics of commands. We must then switch from a direct semantics to a semantics with continuations. The theory of continuations was developed by C.
Reference: [46] <author> J.D. Ullman. </author> <title> Fast algorithms for the elimination of common subexpres-sions. </title> <journal> Acta Informatica, </journal> <volume> 2(3), </volume> <year> 1973. </year>
Reference-contexts: The search for common factors in the reduced equations allows a saving in the calculation <ref> [1, 37, 46] </ref>.
Reference: [47] <author> M.H. Williams and H.L. Ossher. </author> <title> Conversion of unstructured flow diagrams to structured. </title> <journal> The Computer Journal, </journal> <volume> 21(2), </volume> <year> 1975. </year>
Reference-contexts: If we wish the compiler to work always with a normalized program, we may apply normalization following such transformations. A lot of work has been done in the normalization of the control-flow of programs <ref> [10, 47, 12, 5] </ref>. <p> The solution of this system of equations is the normalized form of the program. The effect of this is to detect all of the loops and to eliminate all pathological syntactic constructions that the program contains. Williams and Ossher <ref> [47] </ref> have proved that such an elimination is necessary and sufficient to obtain a structured form of the program.
Reference: [48] <author> M.J. Wolfe. </author> <title> Optimizing Supercompilers for Supercomputers. </title> <type> PhD thesis, </type> <institution> Center for Supercomputing Research and Development, University of Illi-nois at Urbana-Champaign, </institution> <year> 1980. </year> <month> 40 </month>
Reference-contexts: The second purpose is vectorization. In order to vectorize statements that are conditionally executed in a loop, one must attach boolean variables (mode vectors) to the statements <ref> [29, 48, 17, 32] </ref>. By control-flow normalization we may accomplish this easily for any program. MIPRAC is a multilingual compiler for shared memory machines being implemented at the University of Illinois. Its applications of the normalization method are much more ambitious.
References-found: 48

