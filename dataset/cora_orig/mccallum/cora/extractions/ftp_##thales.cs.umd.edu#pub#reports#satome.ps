URL: ftp://thales.cs.umd.edu/pub/reports/satome.ps
Refering-URL: ftp://thales.cs.umd.edu/pub/biographical/xapp.html
Root-URL: 
Title: Stochastic Automata, Tensors Operation, and Matrix Formulas  
Author: G. W. Stewart 
Date: January, 1996  
Affiliation: University of Maryland College Park Institute for Advanced Computer Studies TR-96-11 Department of Computer Science  
Pubnum: TR-3598  
Abstract: This paper concerns two matrix operators and their relation to tensor (Kronecker) products. The object is to present the manipulation of descriptors of stochastic automata networks in a new light. The results suggest new preconditioners for the iterative solution of stochastic automata networks. fl This report is available by anonymous ftp from thales.cs.umd.edu in the directory pub/reports. y Department of Computer Science and Institute for Advanced Computer Studies, University of Maryland, College Park, MD 20742. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E. Anderson, Z. Bai, C. Bischof, J. Demmel, J. Dongarra, J. Du Croz, A. Greenbaum, S. Hammarling, A. McKenney, S. Ostrouchov, and D. Sorensen. </author> <title> LAPACK Users' Guide. </title> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1992. </year>
Reference-contexts: A T X + XB = Y: Suppose we have unitary transformation U and V such that ^ A = U H AU and ^ B = V H BV are upper triangular. (The unitary reduction of A and B to triangular form can be done by the QR algorithm <ref> [1] </ref>.) Set ^ X = U H XV and ^ Y = U H Y V: Stochastic Automata 5 Then the original equation is easily seen to be equivalent to ^ A T ^ X + ^ X ^ B = ^ Y : (2) Let us compute the first column
Reference: [2] <author> R. H. Bartels and G. W. Stewart. </author> <title> Algorithm 432: The solution of the matrix equation AX BX = C. </title> <journal> Communications of the ACM, </journal> <volume> 8 </volume> <pages> 820-826, </pages> <year> 1972. </year>
Reference-contexts: Hence to use a tensor sum as a preconditioner we must be able to solve systems whose matrix is a tensor sum. We will now describe a way to do this. The basic algorithm is due to Bartels and Stewart <ref> [2] </ref>. 16. We will begin with the case of the tensor sum of two matrices.
Reference: [3] <author> P. Fernandes, B. Plateau, and W. J. Stewart. </author> <title> Efficient descriptor-vector multiplications in stochastic automata networks. </title> <type> IMAG Rapport MAI 12, </type> <institution> Centre National de la Recherche Scientifique, Institut National Polytechnique de Grenoble, Universite Joseph Forier Gernoble I, </institution> <year> 1994. </year>
Reference-contexts: Introduction 1. Stochastic automata networks (sams) are discrete state, continuous time Mar-kov chains used to build up models of complex systems <ref> [3, 7, 8, 10] </ref>. They are defined recursively as follows. Let A and B the generators of two sams and let the tensor sum be defined as in (1) below. Then A B is also the generator of a sam.
Reference: [4] <author> R. W. Freund and N. M. Nachtigal. </author> <title> An implementaion of the QMR method based on coupled two-term recurrences. </title> <journal> SIAM Journal on Scientific Computing, </journal> <volume> 15 </volume> <pages> 313-337, </pages> <year> 1994. </year> <title> Stochastic Automata 7 </title>
Reference-contexts: The solution of impure sams cannot be so written, and recourse must be had to iterative methods. Fortunately, with some classes of impure sams, the product of the generator with a vector can be efficiently calculated. This means that Krylov methods such as gmres [9] or qmr <ref> [5, 4] </ref> can be used in solving the systems. 4. The purpose of this paper is twofold. First we will show that the tensor approach to sams can be cast in terms of equivalent matrix-matrix operations not involving tensors. This provides new insight into operations with sams.
Reference: [5] <author> Roland W. Freund and N. M. Nachtigal. </author> <title> QMR: a quasi-minimal residual method for non-Hermitian linear systems. </title> <type> Research Report 91-05, </type> <institution> Interdisciplinary Project Center for Supercomputing, Eidgenossische Technische Hochsulle Zurich, </institution> <year> 1991. </year>
Reference-contexts: The solution of impure sams cannot be so written, and recourse must be had to iterative methods. Fortunately, with some classes of impure sams, the product of the generator with a vector can be efficiently calculated. This means that Krylov methods such as gmres [9] or qmr <ref> [5, 4] </ref> can be used in solving the systems. 4. The purpose of this paper is twofold. First we will show that the tensor approach to sams can be cast in terms of equivalent matrix-matrix operations not involving tensors. This provides new insight into operations with sams.
Reference: [6] <author> G. H. Golub and C. F. Van Loan. </author> <title> Matrix Computations. </title> <publisher> Johns Hopkins University Press, </publisher> <address> Baltimore, Maryland, 2nd edition, </address> <year> 1989. </year>
Reference: [7] <author> B. Plateau and K. Atif. </author> <title> Stochastic automata network for modelling parallel systems. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 17 </volume> <pages> 1093-1108, </pages> <year> 1991. </year>
Reference-contexts: Introduction 1. Stochastic automata networks (sams) are discrete state, continuous time Mar-kov chains used to build up models of complex systems <ref> [3, 7, 8, 10] </ref>. They are defined recursively as follows. Let A and B the generators of two sams and let the tensor sum be defined as in (1) below. Then A B is also the generator of a sam.
Reference: [8] <author> B. Plateau and J.-M. Fourneau. </author> <title> A methodology for solving markov models of parallel systems. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 12 </volume> <pages> 370-387, </pages> <year> 1991. </year>
Reference-contexts: Introduction 1. Stochastic automata networks (sams) are discrete state, continuous time Mar-kov chains used to build up models of complex systems <ref> [3, 7, 8, 10] </ref>. They are defined recursively as follows. Let A and B the generators of two sams and let the tensor sum be defined as in (1) below. Then A B is also the generator of a sam.
Reference: [9] <author> Y. Saad and M. Schultz. </author> <title> GMRES: A generalized minimal residual algorithm for solving nonsymmetric linear systems. </title> <journal> SIAM Journal on Scientific and Statistical Computing, </journal> <volume> 7 </volume> <pages> 856-869, </pages> <year> 1986. </year> <note> Cited in [6]. </note>
Reference-contexts: The solution of impure sams cannot be so written, and recourse must be had to iterative methods. Fortunately, with some classes of impure sams, the product of the generator with a vector can be efficiently calculated. This means that Krylov methods such as gmres <ref> [9] </ref> or qmr [5, 4] can be used in solving the systems. 4. The purpose of this paper is twofold. First we will show that the tensor approach to sams can be cast in terms of equivalent matrix-matrix operations not involving tensors. This provides new insight into operations with sams.
Reference: [10] <author> W. J. Stewart, K. Atif, and B. </author> <title> Plateau. The numerical solution of stochastic automata network. </title> <institution> IMAG Rapport APACHE 6, Centre National de la Recherche Scientifique, Institut National Polytechnique de Grenoble, Univer-site Joseph Forier Gernoble I, </institution> <year> 1993. </year>
Reference-contexts: Introduction 1. Stochastic automata networks (sams) are discrete state, continuous time Mar-kov chains used to build up models of complex systems <ref> [3, 7, 8, 10] </ref>. They are defined recursively as follows. Let A and B the generators of two sams and let the tensor sum be defined as in (1) below. Then A B is also the generator of a sam. <p> Of course the B i themselves could be tensor products, and the second element of the products could have functional dependencies. A recursive application of the procedure sketched above to the products y i B will calculate the products for us. This is the essence of Theorem 5.1 in <ref> [10] </ref>. 14. If instead, we first compute Z = XB, we must then compute A T Z and once again we can allow functional dependencies, but this time in A (not, however, in both A and B). Preconditioning 15.
References-found: 10

