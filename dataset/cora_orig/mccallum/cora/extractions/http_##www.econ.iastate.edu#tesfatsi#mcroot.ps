URL: http://www.econ.iastate.edu/tesfatsi/mcroot.ps
Refering-URL: http://www.econ.iastate.edu/tesfatsi/vita.htm
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: A Multicriteria Approach to Model Specification and Estimation  
Author: Robert Kalaba Leigh Tesfatsion 
Keyword: Model Specification; Set-Valued Estimation; Multicriteria Decision Making; Efficiency; Vector-Valued Optimization; Flexible Least Squares.  
Address: Los Angeles, CA 90089  Ames, IA 50011-1070  
Affiliation: Departments of Electrical and Biomedical Engineering University of Southern California,  Department of Economics and Department of Mathematics Iowa State University,  
Note: Revised:  
Date: 6 January 1995  
Web: http://www.econ.iastate.edu/tesfatsi/  
Abstract: ISU Economic Report No. 28 Abstract: In decision theory, incommensurabilities among conflicting decision criteria are typically handled by multicriteria optimization methods such as Pareto efficiency and mean-variance analysis. In econometrics and statistics, where conflicting model criteria replace conflicting decision criteria, probability assessments are routinely used to transform disparate model discrepancy terms into apparently commensurable quantities. This tactic has both strengths and weaknesses. On the plus side, it permits the construction of a single real-valued measure of theory and data incompatibility in the form of a likelihood function or a posterior probability distribution. On the minus side, the amalgamation of conceptually distinct model discrepancy terms into a single real-valued incompatibility measure can make it difficult to untangle the true source of any diagnosed model specification problem. This paper discusses recent theoretical and empirical work on a multicriteria "flexible least squares" (FLS) approach to model specification and estimation. The basic FLS objective is to determine the "cost-efficient frontier," that is, the set of estimates that are minimally incompatible with a specified set of model criteria. The relation of this work to previous work in econometrics, statistics, and systems science is also clarified. flTo appear in Computational Statistics and Data Analysis 21 (1996). This work was partially supported by NIH Grant No. DK 33729 and has been presented at meetings of the Econometric Society, the Society for Economic Dynamics and Control, the Midwest Econometrics Group, and the IC 2 Institute. A preliminary abridged version of this paper appears in the IC 2 proceedings volume [19]. The authors are grateful to the editor and two anonymous referees for helpful comments. Please address correspondence to L. Tesfatsion (tesfatsi@iastate.edu). 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. D. Banker, A. Charnes, and W. W. Cooper, </author> <title> Some Models for Estimating Technical and Scale Inefficiencies in Data Envelopment Analysis, </title> <booktitle> Management Science 30 (1984) 1078-1092. </booktitle>
Reference-contexts: Also, Charnes and Cooper have developed a "data envelopment analysis" method for the estimation of the Pareto-efficient frontier of an empirically-determined multi-input/multi-output production function. The method has been used to classify organizations using the same kinds of inputs and outputs either as efficient or inefficient; see <ref> [1] </ref>. Other potential applications of this method are discussed in Charnes et al. [4] and Seiford and Thrall [37].
Reference: [2] <author> R. Bellman, H. Kagiwada, R. Kalaba, and R. Sridhar, </author> <title> Invariant Imbedding and Nonlinear Filtering Theory, </title> <note> Journal of the Astronautical Sciences 13 (1966) 110-115. </note>
Reference-contexts: Our work on multicriteria estimation has its roots in "Sridhar filtering." In a series of studies initiated in the mid-nineteen sixties focusing on continuous-time rigid-body dynamics (see, e.g., refs. <ref> [2, 5] </ref>), R. Sridhar and other associates explored the idea of forming a cost-of-estimation function as a weighted sum of squared dynamic and measurement discrepancy terms.
Reference: [3] <author> T. R. Benedict and G. W. Bordner, </author> <title> Synthesis of an Optimal Set of Radar Track-While-Scan Smoothing Equations, </title> <note> IRE Transactions on Automatic Control 7 (1962) 27-32. </note>
Reference-contexts: One also finds instances in which researchers have advocated using multicriteria methods for other types of estimation purposes. For example, in the systems literature, Benedict and Bordner <ref> [3] </ref> proposed a bicriteria estimation algorithm for a class of radar tracking problems.
Reference: [4] <author> A. Charnes, W. W. Cooper, B. Golany, L. Seiford, and J. Stutz, </author> <title> Foundations of Data Envelopment Analysis for Pareto-Koopmans Efficient Empirical Production Functions, </title> <note> Journal of Econometrics 30 (1985) 91-107. </note>
Reference-contexts: The method has been used to classify organizations using the same kinds of inputs and outputs either as efficient or inefficient; see [1]. Other potential applications of this method are discussed in Charnes et al. <ref> [4] </ref> and Seiford and Thrall [37].
Reference: [5] <author> D. Detchmendy and R. Sridhar, </author> <title> Sequential Estimation of States and Parameters in Noisy Nonlinear Dynamical Systems, </title> <note> Journal of Basic Engineering 88 (1966) 362-368. </note>
Reference-contexts: Our work on multicriteria estimation has its roots in "Sridhar filtering." In a series of studies initiated in the mid-nineteen sixties focusing on continuous-time rigid-body dynamics (see, e.g., refs. <ref> [2, 5] </ref>), R. Sridhar and other associates explored the idea of forming a cost-of-estimation function as a weighted sum of squared dynamic and measurement discrepancy terms.
Reference: [6] <author> J. Dorfman and K. Foster, </author> <title> Estimating Productivity Changes with Flexible Coefficients, </title> <note> Western Journal of Agricultural Economics 16 (December 1991) 280-290. </note>
Reference-contexts: A number of other empirical FLS studies have recently appeared that suggest the potential usefulness of FLS as a diagnostic tool. For example, Dorfman and Foster <ref> [6] </ref> use FLS to develop a new measure of productivity change. They assume that measurement errors are independently and identically distributed random variables whereas the coefficients characterizing the production relation evolve slowly over time in an unknown deterministic 15 manner.
Reference: [7] <author> J. S. Dyer, P. C. Fishburn, R. E. Steuer, J. Wallenius, and S. Zionts, </author> <title> Multiple Criteria Decision Making, Multiattribute Utility Theory: The Next Ten Years, </title> <note> Management Science 38 (May 1992) 645-654. </note>
Reference-contexts: See, for example, refs. <ref> [7, 24, 38, 45, 46, 47] </ref>. The duality between decision making (control) and estimation (system identification) for single-criterion optimization problems has been known for over thirty years (Kalman [21, p. 42]). Surprisingly, however, the interconnections between multicriteria decision making and multicriteria estimation have yet to be systematically explored.
Reference: [8] <author> G. D. Forney, Jr., </author> <title> The Viterbi Algorithm, </title> <booktitle> Proceedings of the IEEE (March 1973) 268-278. </booktitle>
Reference-contexts: then given by C F (T ) = vmin [ [ C F (^x T ; T ) ] : (18) Three well-known state estimation algorithms are derived in [18] as single-criterion special cases of the multicriteria recurrence relations (17) and (18): namely, the Kalman filter [21], the Viterbi filter <ref> [8, 41] </ref>, and the Larson-Peschon filter [26] for sequentially generating maximum a posteriori (MAP) probability estimates. In addition, an algorithm for sequentially generating the FLS estimates for the problem discussed in Section 2, above, is derived as a bicriteria special case of (17) and (18).
Reference: [9] <author> I. J. Good and R. A. Gaskins, </author> <title> Density Estimation and Bump-Hunting by the Penal--ized Likelihood Method Exemplified by Scattering and Meteorite Data, </title> <journal> Journal of the American Statistical Association 75 (March 1980) 42-56, </journal> <note> followed by comments, 56-73. </note>
Reference-contexts: See, for example, the discussion of ridge trace procedures in Judge et al. [12, pp. 915-916], the discussion of smoothing splines in Wahba [42], and the discussion in Good and Gaskins <ref> [9] </ref> of penalized likelihood methods for the location and probabilistic evaluation of "bumps" in estimated probability densities. One also finds instances in which researchers have advocated using multicriteria methods for other types of estimation purposes.
Reference: [10] <author> Y. Y. Haimes, L. S. Lasdon, and D. A. Wismer, </author> <title> On a Bicriteria Formulation of the Problems of Integrated system Identification and System Optimization, </title> <journal> IEEE Transactions on Systems, Man, </journal> <note> and Cybernetics 1 (1977) 296-297. </note>
Reference-contexts: See, for example, Haimes et al. <ref> [10] </ref> 21 and Koussoulas [25]. In the MCDM literature, both Narula and Wellington [33] and Zeleny [46, pp. 469-471] have proposed the use of multicriteria methods for linear regression analysis.
Reference: [11] <author> D. F. Hendry and J.-F. Richard, </author> <title> The Econometric Analysis of Economic Time Series, </title> <note> International Statistical Review 51 (1983) 111-164. </note>
Reference-contexts: Nevertheless, rather than considering the sensitivity of inferences to alternative prior probability distributions, the majority of these researchers instead rely on ordinary least squares and maximum likelihood methods for initial estimation purposes, 22 followed by subsequent diagnostic testing to check for model misspecification. Hendry and Richard <ref> [11] </ref> have attempted to systematize the latter model specification procedure. They formulate various model design criteria which they believe to be of particular relevance for econometric modelling.
Reference: [12] <author> G. G. Judge, W. E. Griffiths, R. C. Hill, H. Lutkepohl, and T. C. Lee, </author> <title> The Theory and Practice of Econometrics (New York: </title> <publisher> Wiley, </publisher> <year> 1985). </year>
Reference-contexts: In addition, multicriteria methods have been used to describe the tradeoff between bias and variance (fidelity and smoothness) which some estimation procedures entail. See, for example, the discussion of ridge trace procedures in Judge et al. <ref> [12, pp. 915-916] </ref>, the discussion of smoothing splines in Wahba [42], and the discussion in Good and Gaskins [9] of penalized likelihood methods for the location and probabilistic evaluation of "bumps" in estimated probability densities. <p> Rather, as is standard in the diagnostic testing literature, Hendry and Richard advocate the sequential application of their model design criteria, opening themselves to the usual criticism (see, e.g., Judge et al. <ref> [12, pp. 869-870] </ref>) that the choice of a final model might depend upon the particular order of application. 4 One way to interpret this path-dependence criticism is to note that Hendry and Richard may simply be ending up at one among many possible points on a frontier of models that are
Reference: [13] <author> R. Kalaba and L. Tesfatsion, </author> <title> A Least-Squares Model Specification Test for a Class of Dynamic Nonlinear Economic Models with Systematically Varying Parameters, </title> <note> Journal of Optimization Theory and Applications 32 (1980) 538-567. </note>
Reference-contexts: In summary, the basic FLS objective is to characterize the set of all state sequence estimates that achieve vector-minimal incompatibility between process observations and imperfectly specified theoretical relations, whatever form these theoretical relations might take. Although probability relations can be incorporated along with other types of theoretical relations (see <ref> [13, 18] </ref>), they do not play a distinguished role. Indeed, as illustrated above, they may be absent altogether. <p> Sridhar and other associates explored the idea of forming a cost-of-estimation function as a weighted sum of squared dynamic and measurement discrepancy terms. In refs. <ref> [13, 14] </ref> we extend this previous work by considering a broader class of models and by deriving exact filtering equations for the determination of the cost-minimizing solutions.
Reference: [14] <author> R. Kalaba and L. Tesfatsion, </author> <title> An Exact Sequential Solution Procedure for a Class of Discrete-Time Nonlinear Estimation Problems, </title> <journal> IEEE Transactions on Automatic Control 26 (1981) 1144-1149. </journal>
Reference-contexts: Sridhar and other associates explored the idea of forming a cost-of-estimation function as a weighted sum of squared dynamic and measurement discrepancy terms. In refs. <ref> [13, 14] </ref> we extend this previous work by considering a broader class of models and by deriving exact filtering equations for the determination of the cost-minimizing solutions.
Reference: [15] <author> R. Kalaba and L. Tesfatsion, </author> <title> The Flexible Least Squares Approach to Time-Varying Linear Regression, </title> <journal> Journal of Economic Dynamics and Control 12 (1988) 43-48. </journal>
Reference-contexts: However, as in the earlier Sridhar studies, the cost-of-estimation functions in these studies are still formulated with uniquely specified penalty weights. The basic FLS approach, introduced in <ref> [15] </ref>, instead focuses attention on a cost vector (c D ; c M ) incorporating separate penalty costs for dynamic and measurement discrepancy terms.
Reference: [16] <author> R. Kalaba and L. Tesfatsion, </author> <title> Time-Varying Linear Regression via Flexible Least Squares, </title> <note> Computers and Mathematics with Applications 17 (1989) 1215-1245. </note>
Reference-contexts: Not yet examined, however, is the extent to which the FLS approach permits the recovery of accurate information about process states. The present section briefly reviews a number of simulation and empirical studies that have addressed this issue. Ref. <ref> [16] </ref> undertakes an FLS analysis of a time-varying linear regression problem, a special case of (1) and (2) in which the time t state vector x t denotes the vector of time t regression coefficients and the time t exogenous vector h t denotes the vector of time t regressor variables. <p> The basic estimation objective is to determine whether the regression coefficients have exhibited any systematic time-variation over the course of the observation period. A Fortran program for generating the FLS estimates is provided in ref. <ref> [16] </ref>, together with an explanation of the program logic. 2 Various FLS simulation experiments making use of this program are reported and graphically depicted in [16] and [20]. <p> A Fortran program for generating the FLS estimates is provided in ref. <ref> [16] </ref>, together with an explanation of the program logic. 2 Various FLS simulation experiments making use of this program are reported and graphically depicted in [16] and [20]. These experiments demonstrate the ability of the FLS method to track and recover linear, quadratic, sinusoidal, and elliptical motions in the true underlying regression coefficients, despite noisy observations, and relying only on prior measurement and dynamic relations of the form (1) and (2). <p> He concludes (p. 742) that these FLS findings are consistent with a financial innovations explanation of money demand instability over this period. In a different study, Lutkepohl and Herwartz [31] generalize the FLS time-varying linear regression method developed in <ref> [16, 17] </ref> by allowing for anticipated seasonal periodicities as well as for time trends. They first undertake a study of their generalized FLS algorithm for three artificially generated time series, each having a seasonal pattern, in which a variable is linearly dependent on its value in some past time.
Reference: [17] <author> R. Kalaba and L. Tesfatsion, </author> <title> Flexible Least Squares for Approximately Linear Systems, </title> <journal> IEEE Transactions on Systems, Man, </journal> <note> and Cybernetics 20 (1990) 978-989. </note>
Reference-contexts: See also <ref> [17] </ref> for a more general FLS Fortran program, GFLS, applicable for systems characterized by approximately linear measurement and dynamic relations. 13 regressor vector h 0 t were taken to be deterministic cyclic functions of t and the components of the measurement discrepancy term v t were independently generated from a pseudo-random <p> He concludes (p. 742) that these FLS findings are consistent with a financial innovations explanation of money demand instability over this period. In a different study, Lutkepohl and Herwartz [31] generalize the FLS time-varying linear regression method developed in <ref> [16, 17] </ref> by allowing for anticipated seasonal periodicities as well as for time trends. They first undertake a study of their generalized FLS algorithm for three artificially generated time series, each having a seasonal pattern, in which a variable is linearly dependent on its value in some past time.
Reference: [18] <author> R. Kalaba and L. Tesfatsion, </author> <title> An Organizing Principle for Dynamic Estimation, </title> <note> Journal of Optimization Theory and Applications 64 (1990) 445-470. </note>
Reference-contexts: In summary, the basic FLS objective is to characterize the set of all state sequence estimates that achieve vector-minimal incompatibility between process observations and imperfectly specified theoretical relations, whatever form these theoretical relations might take. Although probability relations can be incorporated along with other types of theoretical relations (see <ref> [13, 18] </ref>), they do not play a distinguished role. Indeed, as illustrated above, they may be absent altogether. <p> Rather, subsequent tests must be conducted to check whether the data appear to be anomalous with respect to the given model specification, or whether other plausible model specifications exist that make the data appear less anomalous. A further difficulty here, as detailed in ref. <ref> [18, section 5.1] </ref>, is that standard diagnostic procedures force all incompatibilities between theory and observations to reveal themselves as incompatibilities between theoretically anticipated probability relations and empirically determined statistical properties. <p> In this section we describe a more general multicriteria approach to estimation developed in <ref> [18] </ref>. We also suggest how the latter approach might be recast in the form of a utility maximization problem subject to a budget constraint. <p> See, for example, ref. [29]. 19 C F (^x t ; t) denote the cost-efficient frontier for C (^x t ; t). Given certain regularity conditions, it is shown in <ref> [18] </ref> that the state-conditional frontier at any intermediate time t is mapped into a state-conditional frontier at time t + 1 in accordance with a vector-valued recurrence relation having the form C F (^x t+1 ; t + 1) = vmin ( [ [C F (^x t ; t) + c <p> The cost-efficient frontier at the final time T is then given by C F (T ) = vmin [ [ C F (^x T ; T ) ] : (18) Three well-known state estimation algorithms are derived in <ref> [18] </ref> as single-criterion special cases of the multicriteria recurrence relations (17) and (18): namely, the Kalman filter [21], the Viterbi filter [8, 41], and the Larson-Peschon filter [26] for sequentially generating maximum a posteriori (MAP) probability estimates.
Reference: [19] <author> R. Kalaba and L. Tesfatsion, </author> <title> A Multicriteria Approach to Dynamic Estimation, pp. </title> <editor> 289-300 in R. H. Day and P. Chen (eds.) </editor> <title> Nonlinear Dynamics and Evolutionary Economics, </title> <publisher> Oxford University Press, </publisher> <address> N.Y., </address> <year> 1993. </year>
Reference: [20] <author> R. Kalaba, N. Rasakhoo, and L. Tesfatsion, </author> <title> A Fortran Program for Time-Varying Linear Regression via Flexible Least Squares, Computational Statistics and Data Analysis 7 (1989) 291-309. </title>
Reference-contexts: A Fortran program for generating the FLS estimates is provided in ref. [16], together with an explanation of the program logic. 2 Various FLS simulation experiments making use of this program are reported and graphically depicted in [16] and <ref> [20] </ref>. These experiments demonstrate the ability of the FLS method to track and recover linear, quadratic, sinusoidal, and elliptical motions in the true underlying regression coefficients, despite noisy observations, and relying only on prior measurement and dynamic relations of the form (1) and (2).
Reference: [21] <author> R. E. </author> <title> Kalman, A New Approach to Linear Filtering and Prediction Problems, </title> <journal> Transactions of the ASME: </journal> <note> Journal of Basic Engineering 82 (1960) 35-45. 26 </note>
Reference-contexts: final time T is then given by C F (T ) = vmin [ [ C F (^x T ; T ) ] : (18) Three well-known state estimation algorithms are derived in [18] as single-criterion special cases of the multicriteria recurrence relations (17) and (18): namely, the Kalman filter <ref> [21] </ref>, the Viterbi filter [8, 41], and the Larson-Peschon filter [26] for sequentially generating maximum a posteriori (MAP) probability estimates. In addition, an algorithm for sequentially generating the FLS estimates for the problem discussed in Section 2, above, is derived as a bicriteria special case of (17) and (18). <p> See, for example, refs. [7, 24, 38, 45, 46, 47]. The duality between decision making (control) and estimation (system identification) for single-criterion optimization problems has been known for over thirty years (Kalman <ref> [21, p. 42] </ref>). Surprisingly, however, the interconnections between multicriteria decision making and multicriteria estimation have yet to be systematically explored. Some use of multicriteria methods has of course occurred in statistical inferential studies. Multicriteria methods have traditionally been used to describe the trade-off between Type I and Type II errors.
Reference: [22] <author> R. Kohn and C. F. Ansley, </author> <title> Equivalence Between Bayesian Smoothness Priors and Opti--mal Smoothing for Function Estimation, pp. </title> <editor> 393-430 in C. Spall (ed.), </editor> <title> Bayesian Analysis of Time Series and Dynamic Models, </title> <publisher> Marcel Dekker, </publisher> <address> N.Y., </address> <year> 1988. </year>
Reference-contexts: In refs. [13, 14] we extend this previous work by considering a broader class of models and by deriving exact filtering equations for the determination of the cost-minimizing solutions. In a related study, Kohn and Ansley <ref> [22] </ref> discuss the relation between the use of Bayesian smoothness priors for state-space smoothing and the use of a Sridhar-type penalized least squares criterion function with quadratically specified dynamic and measurement costs to achieve optimal function smoothing.
Reference: [23] <author> P. Korhonen, H. Moskowitz, and J. Wallenius, </author> <title> Choice Behavior in Interactive Multiple Criteria Decision Making, </title> <note> Annals of Operations Research 23 (1990) 161-179. </note>
Reference-contexts: different idea concerning which model criteria should be included in c, and a different degree of recognition that conflicting model criteria result in set -valued 4 The observation that the "decision path" can affect a final choice is also well known in the MCDM literature; see, e.g., Korhonen et al. <ref> [23] </ref>. 23 inferences in the form of a nondegenerate cost-efficient frontier of alternative models. Our work on multicriteria estimation has its roots in "Sridhar filtering." In a series of studies initiated in the mid-nineteen sixties focusing on continuous-time rigid-body dynamics (see, e.g., refs. [2, 5]), R.
Reference: [24] <author> P. Korhonen, A. Lewandowski, and J. Wallenius (eds.) </author> <title> Multiple Criteria Decision Support , Vol. </title> <booktitle> 356, Lecture Notes in Economics and Mathematical Systems, </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1991. </year>
Reference-contexts: See, for example, refs. <ref> [7, 24, 38, 45, 46, 47] </ref>. The duality between decision making (control) and estimation (system identification) for single-criterion optimization problems has been known for over thirty years (Kalman [21, p. 42]). Surprisingly, however, the interconnections between multicriteria decision making and multicriteria estimation have yet to be systematically explored.
Reference: [25] <author> N. T. Koussoulas, </author> <title> Multiobjective Optimization in Adaptive and Stochastic control, pp. </title> <editor> 55-78 in C. T. Leondes (ed.) </editor> <booktitle> Control and Dynamic Systems Vol. </booktitle> <address> 25 (New York: </address> <publisher> Academic Press, </publisher> <year> 1987). </year>
Reference-contexts: See, for example, Haimes et al. [10] 21 and Koussoulas <ref> [25] </ref>. In the MCDM literature, both Narula and Wellington [33] and Zeleny [46, pp. 469-471] have proposed the use of multicriteria methods for linear regression analysis. Also, Charnes and Cooper have developed a "data envelopment analysis" method for the estimation of the Pareto-efficient frontier of an empirically-determined multi-input/multi-output production function.
Reference: [26] <author> R. E. Larson and J. Peschon, </author> <title> A Dynamic Programming Approach to Trajectory Estimation, </title> <journal> IEEE Transactions on Automatic Control 11 (1966) 537-540. </journal>
Reference-contexts: ) = vmin [ [ C F (^x T ; T ) ] : (18) Three well-known state estimation algorithms are derived in [18] as single-criterion special cases of the multicriteria recurrence relations (17) and (18): namely, the Kalman filter [21], the Viterbi filter [8, 41], and the Larson-Peschon filter <ref> [26] </ref> for sequentially generating maximum a posteriori (MAP) probability estimates. In addition, an algorithm for sequentially generating the FLS estimates for the problem discussed in Section 2, above, is derived as a bicriteria special case of (17) and (18).
Reference: [27] <author> E. Leamer, </author> <title> Specification Searches (New York: </title> <publisher> Wiley, </publisher> <year> 1978). </year>
Reference-contexts: The method has been used to classify organizations using the same kinds of inputs and outputs either as efficient or inefficient; see [1]. Other potential applications of this method are discussed in Charnes et al. [4] and Seiford and Thrall [37]. In the econometrics literature, Leamer <ref> [27, pp. 141-170] </ref> introduces the notion of an "information contract curve" in the space of regression coefficients to discuss regression selection strategies in the case in which only the contours (iso-density surfaces) of the prior probability density function and the likelihood function are known.
Reference: [28] <author> E. Leamer, </author> <title> Sensitivity Analyses Would Help, pp. </title> <editor> 88-96 in C. Granger (ed.) </editor> <booktitle> Modelling Economic Series (Oxford: </booktitle> <publisher> Clarendon Press, </publisher> <year> 1990). </year>
Reference-contexts: In subsequent work (see <ref> [28] </ref>), Leamer proposes a more general "global sensitivity analysis" for investigating the sensitivity of posterior distribution inferences to alternative choices of prior probability distributions.
Reference: [29] <author> D. Li and Y. Y. Haimes, </author> <title> The Envelope Approach for Multiobjective Optimization Problems, </title> <journal> IEEE Transactions on Systems, Man, </journal> <note> and Cybernetics 17 (1987) 1026-1038; for Errata Corrige, see Ibid. 18 (1988) 332. </note>
Reference-contexts: See, for example, ref. <ref> [29] </ref>. 19 C F (^x t ; t) denote the cost-efficient frontier for C (^x t ; t).
Reference: [30] <author> H. Lutkepohl, </author> <title> The Sources of the U.S. Money Demand Instability, Empirical Economics 18 (1993) 729-743. </title>
Reference-contexts: Interestingly, the FLS measure also produces considerably lower estimates of productivity growth than the total factor productivity measure and generally higher estimates of productivity growth than the elasticity measure. In <ref> [30] </ref>, Lutkepohl uses FLS to obtain detailed information on the variability of individual coefficients for a U.S. money demand relation specified in error-correction form.
Reference: [31] <author> H. Lutkepohl and H. Herwartz, </author> <title> Specification of Varying Coefficient Time Series Models via Generalized Flexible Least Squares, </title> <note> Working Paper No. 9311, </note> <institution> Institut fur Statistik & Okonometrie, Humboldt-Universitat zu Berlin, </institution> <month> June </month> <year> 1993, </year> <note> to appear in the Journal of Econometrics. </note>
Reference-contexts: He concludes (p. 742) that these FLS findings are consistent with a financial innovations explanation of money demand instability over this period. In a different study, Lutkepohl and Herwartz <ref> [31] </ref> generalize the FLS time-varying linear regression method developed in [16, 17] by allowing for anticipated seasonal periodicities as well as for time trends.
Reference: [32] <author> D. R. Morrell, </author> <title> Epistemic Utility Estimation, </title> <journal> IEEE Transactions on Systems, Man, </journal> <note> and Cybernetics 23 (1993) 129-140. </note>
Reference-contexts: A related line of work on "set-valued filtering" has been developed in the systems science and statistics literatures; see, for example, Stirling and Morrell [39, Section V.B] and Morrell <ref> [32] </ref>. These studies argue that unique estimates cannot be inferred from data sets when, for whatever reason, a data analyst is unable to use probability assessments to fully scale and weigh disparate sources of information in the form of a uniquely specified posterior probability distribution.
Reference: [33] <author> S. C. Narula and J. F. Wellington, </author> <title> Linear Regression Using Multiple Criteria, pp. </title> <editor> 266-277 in G. Gandel and T. Gal (eds.) </editor> <title> Multiple Criteria Decision Making and Applications (New York: </title> <publisher> Springer-Verlag, </publisher> <year> 1980). </year>
Reference-contexts: See, for example, Haimes et al. [10] 21 and Koussoulas [25]. In the MCDM literature, both Narula and Wellington <ref> [33] </ref> and Zeleny [46, pp. 469-471] have proposed the use of multicriteria methods for linear regression analysis. Also, Charnes and Cooper have developed a "data envelopment analysis" method for the estimation of the Pareto-efficient frontier of an empirically-determined multi-input/multi-output production function.
Reference: [34] <author> C. R. Nelson and C. I. Plosser, </author> <title> Trends and Random Walks in Macroeconomic Time Series: Some Evidence and Implications, </title> <note> Journal of Monetary Economics 10 (1982) 139-162. </note>
Reference-contexts: It is sometimes countered that this distinction is unimportant if the variances of the random walk error terms are anticipated to be small. However, as stressed in recent macroe-conometric work, e.g., Nelson and Plosser <ref> [34] </ref>, the dynamic properties of a time-trend model are altogether different from the dynamic properties of a random walk model, however one models the variances of these error terms. Consequently, "small discrepancy terms" and "small error term variances" are not conceptually interchangeable descriptions.
Reference: [35] <author> E. H. Ruspini, </author> <title> Approximate Reasoning: Past, Present, and Future, </title> <note> Information Sci--ences 57-58 (1991) 297-317. </note>
Reference-contexts: Consequently, "small discrepancy terms" and "small error term variances" are not conceptually interchangeable descriptions. In particular, for initial diagnostic checks of poorly understood structures, the probabilistic assumption of "small variances" can be an overly restrictive concept (cf. Ruspini <ref> [35] </ref>). Another important objection to the standard estimation approach is that the probability relations (9)-(13) imply that w t and v t are governed by a well-defined joint probability distribution and hence are cardinally comparable. For many processes it is hard to maintain this assumption in a publicly credible way.
Reference: [36] <author> W. Schneider, </author> <title> Stability Analysis Using Kalman Filtering, Scoring, EM, and an Adaptive EM Method, </title> <booktitle> Chapter 14, </booktitle> <pages> pp. 191-221, </pages> <editor> in P. Hackl and A. H. Westlund (eds.) </editor> <title> Economic Structural Change: Analysis and Forecasting (New York: </title> <publisher> Springer-Verlag, </publisher> <year> 1991). </year>
Reference-contexts: Finally, Schneider <ref> [36] </ref> carries out an extensive comparative study between maximum likelihood (EM and scoring) and FLS time-varying linear regression methods, where the latter is characterized (p. 192) as a descriptive variant of Kalman filtering that constitutes a "simple but powerful tool of exploratory data analysis." He first applies FLS as a preliminary
Reference: [37] <author> L. M. Seiford and R. M. Thrall, </author> <title> Recent Developments in DEA: The Mathematical Programming Approach to Frontier Analysis, </title> <note> Journal of Econometrics 46 (1990) 7-38. </note>
Reference-contexts: The method has been used to classify organizations using the same kinds of inputs and outputs either as efficient or inefficient; see [1]. Other potential applications of this method are discussed in Charnes et al. [4] and Seiford and Thrall <ref> [37] </ref>. In the econometrics literature, Leamer [27, pp. 141-170] introduces the notion of an "information contract curve" in the space of regression coefficients to discuss regression selection strategies in the case in which only the contours (iso-density surfaces) of the prior probability density function and the likelihood function are known.
Reference: [38] <author> R. E. Steuer, </author> <title> Multiple Criteria Optimization: Theory, Computation, and Application (New York: </title> <publisher> Wiley, </publisher> <year> 1986). </year>
Reference-contexts: See, for example, refs. <ref> [7, 24, 38, 45, 46, 47] </ref>. The duality between decision making (control) and estimation (system identification) for single-criterion optimization problems has been known for over thirty years (Kalman [21, p. 42]). Surprisingly, however, the interconnections between multicriteria decision making and multicriteria estimation have yet to be systematically explored.
Reference: [39] <author> W. C. Stirling and D. R. Morrell, </author> <title> Convex Bayes Decision Theory, </title> <journal> IEEE Transactions on Systems, Man, </journal> <note> and Cybernetics 21 (1991) 173-183. </note>
Reference-contexts: A related line of work on "set-valued filtering" has been developed in the systems science and statistics literatures; see, for example, Stirling and Morrell <ref> [39, Section V.B] </ref> and Morrell [32]. These studies argue that unique estimates cannot be inferred from data sets when, for whatever reason, a data analyst is unable to use probability assessments to fully scale and weigh disparate sources of information in the form of a uniquely specified posterior probability distribution.
Reference: [40] <author> L. Tesfatsion and J. Veitch, </author> <title> U.S. Money Demand Instability: A Flexible Least Squares Approach, </title> <journal> Journal of Economic Dynamics and Control 14 (1990) 151-173. </journal>
Reference-contexts: See ref. <ref> [40, Footnote 3] </ref> 5 of all possible configurations of dynamic and measurement costs attainable at time T , condi-tional on the given observation sequence Y T . <p> This issue arose in the FLS money demand study <ref> [40] </ref>, for the focus of the study concerned possible step-function breaks in money demand regression coefficients. Various simulation experiments were therefore conducted in which the components of the true regression coefficients were shifted idiosyncratically at various points in time. <p> Given the promising nature of these shift simulation results, the FLS method was next used in <ref> [40] </ref> to undertake an empirical money demand investigation. Measurement and dynamic relations analogous to (1) and (2) were used to model U.S. money demand over the volatile period 1959:Q2-1985:Q3. In particular, no prior information regarding possible shift times was used in the FLS estimation procedure. <p> This finding was in accordance with previous ordinary least squares (OLS) studies of U.S. money demand that had investigated the possibility of a 1974 shift in the money demand regression coefficients using variants of the Chow test and recursive least squares. In addition, however, the FLS results in <ref> [40] </ref> also indicated the presence of systematic idiosyncratic time variations in the regression coefficients|e.g., a sharp and steady decline in the coefficient for the inflation rate|which Chow tests and recursive least squares are not designed to detect.
Reference: [41] <author> A. J. </author> <title> Viterbi, Error Bounds of Convolutional Codes and an Asymptotically Optimal Decoding Algorithm, </title> <note> IEEE Transactions on Information Theory 13 (1967) 260-269. </note>
Reference-contexts: then given by C F (T ) = vmin [ [ C F (^x T ; T ) ] : (18) Three well-known state estimation algorithms are derived in [18] as single-criterion special cases of the multicriteria recurrence relations (17) and (18): namely, the Kalman filter [21], the Viterbi filter <ref> [8, 41] </ref>, and the Larson-Peschon filter [26] for sequentially generating maximum a posteriori (MAP) probability estimates. In addition, an algorithm for sequentially generating the FLS estimates for the problem discussed in Section 2, above, is derived as a bicriteria special case of (17) and (18).
Reference: [42] <author> G. Wahba, </author> <title> Spline Models for Observational Data (Philadelphia: </title> <publisher> SIAM, </publisher> <year> 1990). </year>
Reference-contexts: In addition, multicriteria methods have been used to describe the tradeoff between bias and variance (fidelity and smoothness) which some estimation procedures entail. See, for example, the discussion of ridge trace procedures in Judge et al. [12, pp. 915-916], the discussion of smoothing splines in Wahba <ref> [42] </ref>, and the discussion in Good and Gaskins [9] of penalized likelihood methods for the location and probabilistic evaluation of "bumps" in estimated probability densities. One also finds instances in which researchers have advocated using multicriteria methods for other types of estimation purposes.
Reference: [43] <author> M. West and J. Harrison, </author> <title> Bayesian Forecasting and Dynamic Models (New York: </title> <publisher> Springer, </publisher> <year> 1989). </year>
Reference-contexts: As detailed in <ref> [43] </ref>, an objective commonly assumed for estimation problems described by relations of the form (7)-(13) is maximum a posteriori (MAP) estimation, i.e., the determination of the state sequence X T that maximizes the posterior probability density function P (X T j Y T ).
Reference: [44] <author> K. J. White et al., </author> <title> SHAZAM User's Reference Manual (New York: </title> <publisher> McGraw-Hill, </publisher> <year> 1995). </year>
Reference-contexts: Each observation y t was generated in accordance with the linear regression model y t = h 0 t x t + v t , where the components of the 2 This FLS program for time-varying linear regression has recently been incorporated into the statistical package SHAZAM; see <ref> [44] </ref>, or email info@shazam.econ.ubc.ca for information.
Reference: [45] <author> P. L. Yu, </author> <title> Multiple-Criteria Decision Making: Concepts, Techniques, and Extensions (New York: </title> <publisher> Plenum Press, </publisher> <year> 1985). </year>
Reference-contexts: prior beliefs (1) and (2) concerning the measurement and dynamic relations hold true with absolute equality, then selecting the actual state sequence X T as the state sequence estimate would result in zero values for both c M and c D |the "ideal" cost point in the terminology of Yu <ref> [45, p. 67] </ref>. In all other cases, each potential state sequence estimate ^ X T will entail positive measurement and/or dynamic costs. Nevertheless, not all of these state sequence estimates are equally interesting. <p> See, for example, refs. <ref> [7, 24, 38, 45, 46, 47] </ref>. The duality between decision making (control) and estimation (system identification) for single-criterion optimization problems has been known for over thirty years (Kalman [21, p. 42]). Surprisingly, however, the interconnections between multicriteria decision making and multicriteria estimation have yet to be systematically explored.
Reference: [46] <author> M. Zeleny, </author> <title> Multiple Criteria Decision Making (New York: </title> <publisher> McGraw Hill, </publisher> <year> 1982). </year>
Reference-contexts: See, for example, refs. <ref> [7, 24, 38, 45, 46, 47] </ref>. The duality between decision making (control) and estimation (system identification) for single-criterion optimization problems has been known for over thirty years (Kalman [21, p. 42]). Surprisingly, however, the interconnections between multicriteria decision making and multicriteria estimation have yet to be systematically explored. <p> See, for example, Haimes et al. [10] 21 and Koussoulas [25]. In the MCDM literature, both Narula and Wellington [33] and Zeleny <ref> [46, pp. 469-471] </ref> have proposed the use of multicriteria methods for linear regression analysis. Also, Charnes and Cooper have developed a "data envelopment analysis" method for the estimation of the Pareto-efficient frontier of an empirically-determined multi-input/multi-output production function.
Reference: [47] <author> S. Zionts, </author> <title> The State of Multiple Criteria Decision Making: Past, Present, </title> <booktitle> and Future, </booktitle> <pages> pp. </pages> <note> 33-43 in Goicoechea, </note> <author> A., L. Duckstein, and S. Zionts, </author> <title> Multiple Criteria Decision making, </title> <booktitle> Proceedings of the Ninth International Conference: Theory and Applications in Business, Industry, and Government, </booktitle> <address> (New York: </address> <publisher> Springer-Verlag, </publisher> <year> 1992). </year> <title> 28 (a) Cost Possibility Set C(T ) (b) Cost-Efficient Frontier C F (T ) FIGURE 1 Sine Wave Experiment with Parameter Values = 0:05, = 1, and T = 30. </title> <type> FIGURE 2 </type>
Reference-contexts: See, for example, refs. <ref> [7, 24, 38, 45, 46, 47] </ref>. The duality between decision making (control) and estimation (system identification) for single-criterion optimization problems has been known for over thirty years (Kalman [21, p. 42]). Surprisingly, however, the interconnections between multicriteria decision making and multicriteria estimation have yet to be systematically explored.
References-found: 47

