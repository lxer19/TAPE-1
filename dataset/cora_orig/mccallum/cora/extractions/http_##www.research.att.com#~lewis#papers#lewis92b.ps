URL: http://www.research.att.com/~lewis/papers/lewis92b.ps
Refering-URL: http://www.research.att.com/~lewis/chronobib.html
Root-URL: 
Email: lewis@tira.uchicago.edu  
Title: An Evaluation of Phrasal and Clustered Representations on a Text Categorization Task  
Author: David D. Lewis 
Date: 37-50.  
Note: Appeared (with same pagination) in Fifteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, Copenhagen, 1992, pp.  
Address: Chicago; Chicago, IL 60637  
Affiliation: Center for Information and Language Studies University of  
Abstract: Syntactic phrase indexing and term clustering have been widely explored as text representation techniques for text retrieval. In this paper we study the properties of phrasal and clustered indexing languages on a text categorization task, enabling us to study their properties in isolation from query interpretation issues. We show that optimal effectiveness occurs when using only a small proportion of the indexing terms available, and that effectiveness peaks at a higher feature set size and lower effectiveness level for a syntactic phrase indexing than for word-based indexing. We also present results suggesting that traditional term clustering method are unlikely to provide significantly improved text representations. An improved probabilistic text categorization method is also presented. 
Abstract-found: 1
Intro-found: 1
Reference: [BFL + 88] <author> Biebricher, P., Fuhr, N., Lustig, G., Schwantner, M., and Knorz, G. </author> <title> The automatic indexing system AIR/PHYS|from research to application. </title> <booktitle> SIGIR-88, </booktitle> <pages> pp. 333|342, </pages> <year> 1988. </year>
Reference-contexts: Text categorization is also of considerable practical importance. It has been widely investigated for assigning controlled vocabulary categories to documents for text retrieval, or for aiding human indexers in assigning such categories. Some systems of this sort are operational <ref> [BFL + 88, HW90] </ref>. Text categorization is also increasingly used to support category-specific processing in NLP systems [Sun91]. Two broad approaches have been taken to developing text categorization systems. First, a number of systems have been the result of human knowledge engineering of categorization rules and knowledge bases [HW90]. <p> Unfortunately, there have been few studies comparing multiple text categorization techniques, so little is known about the relative merits of different approaches. (An exception is the large body of research which has been conducted using the PHYS database <ref> [BFL + 88, FHL + 91] </ref>.) A lack of agreement on evaluation measures has also hampered comparisons of methods. 3 Problems in Studying Text Representation Text retrieval is currently the most important application for new indexing languages.
Reference: [Chu88] <author> Church, K. </author> <title> A stochastic parts program and noun phrase parser for unrestricted text. </title> <booktitle> In Second Conference on Applied Natural Language Processing, </booktitle> <pages> pp. 136-143, </pages> <year> 1988. </year>
Reference-contexts: Phrases were formed using parts, a stochastic syntactic class tagger and simple noun phrase bracketing program <ref> [Chu88] </ref>. An example of a tagged and bracketed Reuters story is shown in Figure 2. We used the parts segmentation and bracketing of text to define both our word-based and phrasal indexing languages. * WORDS: We started with all words tokenized by parts.
Reference: [Cro83] <author> Croft, W. </author> <title> Experiments with representation in a document retrieval system. </title> <journal> Information Technology: Research and Development, </journal> <volume> 2 </volume> <pages> 1-21, </pages> <year> 1983. </year>
Reference-contexts: In the experiments reported here P (W i = 1jD m ) is always 0 or 1, but nonbinary estimates could be used <ref> [Cro83, Fuh89] </ref>. * All probabilities were estimated from the training corpus using the "add one" adjustment (the Jeffreys prior) [RS76]. the PLATINUM category on our test set ranged from 10 9:96 to 10 3:21 , while the estimates for the SHIP category ranged from 10 2:89 to 10 9:47 .
Reference: [CD90] <author> Croft, W. and Das, R. </author> <title> Experiments with query acquisition and use in document retrieval sytems. </title> <booktitle> SIGIR-90, </booktitle> <pages> pp. 349-365, </pages> <year> 1990. </year>
Reference-contexts: There is considerable debate as to whether all words from user-identified relevant documents should be added to the user query, or whether statistical feature quality measures, user input, and domain knowledge should be used to limit the number of terms added <ref> [SB90, CD90] </ref>. Most studies on relevance feedback have used test collections of short, focused texts, such as titles and abstracts.
Reference: [CTL91] <author> Croft, W., Turtle, H., and Lewis, D. </author> <title> The use of phrases and structured queries in information retrieval. </title> <booktitle> SIGIR-91, </booktitle> <pages> pp. 32-45, </pages> <year> 1991. </year>
Reference-contexts: The phrases to use in a particular query might be found by applying the same tool to a textual user request, but any other method of extracting word pairs from the request could also be used. This flexibility provides opportunities for increased effectiveness <ref> [CTL91] </ref>, but it limits our ability to study indexing language properties in isolation from query analysis. Text categorization avoids the above problems. Large collections of documents manually indexed with controlled vocabulary categories are available.
Reference: [Cro88] <author> Crouch, C. </author> <title> A cluster-based approach to thesaurus construction. </title> <booktitle> SIGIR-88, </booktitle> <pages> pp. 309-320, </pages> <year> 1988. </year>
Reference-contexts: Peat and Willett [PW91] recently showed that clustering using documents as metafeatures tends to group terms that occur in similar numbers of documents, which is not necessarily desirable. Other metafeature definitions are possible. Crouch clustered words using metafeatures corre 38 sponding to automatically formed document clus-ters <ref> [Cro88] </ref>. Our CACM-3204 experiments clustered phrases using metafeatures corresponding to groups of documents defined by manual indexing categories [LC90]. Sparck Jones conducted the most comprehensive study of term clustering [Spa73a].
Reference: [DH73] <author> Duda, R. and Hart, P. </author> <title> Pattern Classification and Scene Analysis. </title> <publisher> Wiley-Interscience, </publisher> <address> New York, </address> <year> 1973. </year>
Reference-contexts: Given accurate estimates of P (C j = 1jD m ), decision theory tells us that the optimal strategy is to set a single threshold p and assign C j to a document exactly when P (C j = 1jD m ) &gt;= p <ref> [DH73] </ref>. We call this strategy probability thresholding. However, as is common in probabilistic models for text classification tasks, the formula in Figure 1 makes assumptions about independence of probabilities which do not actually hold for textual data.
Reference: [Fag87] <author> Fagan, J. </author> <title> Experiments in Automatic Phrase Indexing for Document Retrieval: A Comparison of Syntactic and Non-Syntactic Methods. </title> <type> PhD thesis, </type> <institution> Dept. of Computer Science, Cor-nell University, </institution> <year> 1987. </year>
Reference-contexts: In a direct comparison on two text retrieval test collections, Fagan found phrase formation based on simple cooccurrence of words to produce a more effective set of phrases than requiring particular syntactic relationships to hold <ref> [Fag87] </ref>. Our own experiments using the CACM-3204 text retrieval test collection also found only small effectiveness improvements [LC90]. 2.2 Term Clustering Term clustering is the use of cluster analysis in an attempt to group together semantically related indexing terms.
Reference: [Fie75] <author> Field, B. </author> <title> Towards automatic indexing: Automatic assignment of controlled-language indexing and classification from free indexing. </title> <journal> Journal of Documentation, </journal> <volume> 31(4) </volume> <pages> 246-265, </pages> <month> December </month> <year> 1975. </year>
Reference-contexts: Probability thresholding requires that estimates are comparable across all category/document pairs. If estimates are comparable within documents, but not within categories, then this suggests a k-per-doc strategy, where the top k categories are assigned to each document. This strategy has been used by Field <ref> [Fie75] </ref>. Conversely, estimates might be more comparable within categories than within documents. Assigning each category to the documents with the top k scores on that category would clearly be foolish, since there are huge differences in the frequency of assignment of categories. Instead, we propose a proportional assignment strategy.
Reference: [Fuh89] <author> Fuhr, N. </author> <title> Models for retrieval with probabilistic indexing. </title> <booktitle> Information Processing and Management, </booktitle> <volume> 25(1) </volume> <pages> 55-72, </pages> <year> 1989. </year>
Reference-contexts: We conducted some initial experiments with the model used by Maron [Mar61], but later decided to switch to a model that supported probabilistic indexing for predictor features. The model used in our experiments was proposed by Fuhr <ref> [Fuh89] </ref> for probabilistic text retrieval, but the adaptation to text categorization is straightforward. We present the formula used, with notation slightly changed from Fuhr's, in Figure 1. Note that we probabilities are estimated in a fashion similar to that used for relevance feedback in probabilistic text retrieval. <p> In the experiments reported here P (W i = 1jD m ) is always 0 or 1, but nonbinary estimates could be used <ref> [Cro83, Fuh89] </ref>. * All probabilities were estimated from the training corpus using the "add one" adjustment (the Jeffreys prior) [RS76]. the PLATINUM category on our test set ranged from 10 9:96 to 10 3:21 , while the estimates for the SHIP category ranged from 10 2:89 to 10 9:47 .
Reference: [FB90] <author> Fuhr, N. and Buckley, C. </author> <title> Probabilistic document indexing from relevance feedback data. </title> <booktitle> SIGIR-90, </booktitle> <pages> pp. 45-61, </pages> <year> 1990. </year>
Reference-contexts: Pattern recognition practice suggests 5 to 10 times as many training examples as features are needed to avoid overfitting [JC82], but Fuhr and Knorz (cited in <ref> [FB90] </ref>) have suggested that 50-100 samples per feature may be needed for text classification tasks.
Reference: [FHL + 91] <author> Fuhr, N., Hartmann, S., Lustig, G., Schwantner, M., Tzeras, K., and Knorz, G.. </author> <title> AIR/X|a rule-based multistage indexing system for large subject fields. </title> <booktitle> RIAO 91, </booktitle> <pages> pp. 606-623, </pages> <year> 1991. </year>
Reference-contexts: Unfortunately, there have been few studies comparing multiple text categorization techniques, so little is known about the relative merits of different approaches. (An exception is the large body of research which has been conducted using the PHYS database <ref> [BFL + 88, FHL + 91] </ref>.) A lack of agreement on evaluation measures has also hampered comparisons of methods. 3 Problems in Studying Text Representation Text retrieval is currently the most important application for new indexing languages. <p> We therefore used this strategy in all of our experiments on text representation. Our best breakeven between microaveraged cat-recall and cat-precision was 0:65. This is a level of accuracy that has been found usable in at least one operational system <ref> [FHL + 91] </ref>, and is very close to the effectiveness we found with a more computa-tionally expensive decision tree method [Lew92c]. We conclude that adapting probabilistic text retrieval models to text categorization is a reason able approach. 45 0 .4 .8 0 .2 .4 .6 .8 1 Prec.
Reference: [HZ80] <author> Hamill, K. and Zamora, A. </author> <title> The use of titles for automatic document classification. </title> <booktitle> JASIS, </booktitle> <pages> pp. 396-402, </pages> <month> Nov. </month> <year> 1980. </year>
Reference-contexts: Maron [Mar61] and Hamill and Zamora <ref> [HZ80] </ref> proposed but did not test the use of information theoretic methods to select features. We implemented this approach, choosing for each category the k features with the highest expected mutual information [van77] between the feature and the category.
Reference: [HW90] <author> Hayes, P. and Weinstein, S. CONSTRUE/TIS: </author> <title> a system for content-based indexing of a database of news 49 stories. </title> <booktitle> In Second Annual Conference on Innovative Applications of Artificial Intelligence, </booktitle> <year> 1990. </year>
Reference-contexts: Text categorization is also of considerable practical importance. It has been widely investigated for assigning controlled vocabulary categories to documents for text retrieval, or for aiding human indexers in assigning such categories. Some systems of this sort are operational <ref> [BFL + 88, HW90] </ref>. Text categorization is also increasingly used to support category-specific processing in NLP systems [Sun91]. Two broad approaches have been taken to developing text categorization systems. First, a number of systems have been the result of human knowledge engineering of categorization rules and knowledge bases [HW90]. <p> Text categorization is also increasingly used to support category-specific processing in NLP systems [Sun91]. Two broad approaches have been taken to developing text categorization systems. First, a number of systems have been the result of human knowledge engineering of categorization rules and knowledge bases <ref> [HW90] </ref>. The second approach is to induce the categorization system automatically from manually labeled training data. A range of statistical and machine learning techniques have been tried, including probabilistic models, factor analysis, fuzzy sets, neural nets, regression, and nearest neighbor classification, as well as combinations of these with knowledge engineering. <p> The CONSTRUE rule-based text categorization system exhibited a microaveraged cat-precision and cat-recall (see Section 5.4) near 90% on a test subset of 723 of these stories <ref> [HW90] </ref>. This suggested a high level of consistency in the manual indexing of the collection, which was desirable for our experiments. We chose not to use the original CONSTRUE testset of 723 stories. This test set had been chosen without attention to certain properties of the data.
Reference: [JC82] <author> Jain, A. and Chandrasekaran, B. </author> <title> Dimensionality and sample size considerations in pattern recognition practice. </title> <editor> In Krishnaiah, P. and Kanal, L., eds., </editor> <booktitle> Handbook of Statistics, </booktitle> <volume> Vol. 2, </volume> <pages> pp. 835-855. </pages> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <year> 1982. </year>
Reference-contexts: Pattern recognition practice suggests 5 to 10 times as many training examples as features are needed to avoid overfitting <ref> [JC82] </ref>, but Fuhr and Knorz (cited in [FB90]) have suggested that 50-100 samples per feature may be needed for text classification tasks.
Reference: [Jam85] <author> James, M. </author> <title> Classification Algorithms. </title> <publisher> John Wiley, </publisher> <address> New York, </address> <year> 1985. </year>
Reference: [Lan86] <author> Lancaster, F. </author> <title> Vocabulary Control for Information Retrieval. Information Resources, </title> <address> Arlington, VA, 2nd edition, </address> <year> 1986. </year>
Reference: [LC90] <author> Lewis, D. and Croft, W. </author> <title> Term clustering of syntactic phrases. </title> <booktitle> SIGIR-90, </booktitle> <pages> pp. 385-404, </pages> <year> 1990. </year>
Reference-contexts: Our first test of this approach involved cluster 37 ing of syntactic indexing phrases from the CACM--3204 text retrieval test collection <ref> [LC90] </ref>. Small effectiveness improvements were found, but we found it difficult to draw strong conclusions about the technique. In this paper, we use a text categorization task to again study phrasal and clustered indexing languages, and gain a much clearer insight into their properties. <p> Experiments by Dillon and Gray, Fagan, Smeaton, Sembok, and others have shown only small improvements in text retrieval effectiveness to occur when syntactic indexing phrases are used to supplement a word-based indexing language <ref> [LC90] </ref>. In a direct comparison on two text retrieval test collections, Fagan found phrase formation based on simple cooccurrence of words to produce a more effective set of phrases than requiring particular syntactic relationships to hold [Fag87]. <p> Our own experiments using the CACM-3204 text retrieval test collection also found only small effectiveness improvements <ref> [LC90] </ref>. 2.2 Term Clustering Term clustering is the use of cluster analysis in an attempt to group together semantically related indexing terms. Cluster analysis forms groups of objects which have similar values for some set of features. <p> Other metafeature definitions are possible. Crouch clustered words using metafeatures corre 38 sponding to automatically formed document clus-ters [Cro88]. Our CACM-3204 experiments clustered phrases using metafeatures corresponding to groups of documents defined by manual indexing categories <ref> [LC90] </ref>. Sparck Jones conducted the most comprehensive study of term clustering [Spa73a]. She used documents as metafeatures and found that small clusters of low frequency terms were most effective, regardless of the clustering method used.
Reference: [Lew91] <author> Lewis, D. </author> <title> Evaluating text categorization. </title> <booktitle> In Proceedings of Speech and Natural Language Workshop, </booktitle> <publisher> Morgan Kaufmann: </publisher> <address> San Mateo, CA, </address> <pages> pp. 312-318, </pages> <month> February </month> <year> 1991. </year>
Reference-contexts: 1jD) = 2:187 + log (5:879 fi acquire + 0:840) + log (5:398 fi acquisition + 0:795) + log (2:609 fi shares + 0:715) + log (5:414 fi stake + 0:826) 5.4 Evaluation There has been less standardization in evaluation measures for text categorization than for text re 44 trieval <ref> [Lew91] </ref>. However, the same contingency table model ([van79], ch. 7) which yields the text retrieval effectiveness measures recall and precision can be used analogously in text categorization.
Reference: [Lew92] <author> Lewis, D. </author> <title> Representation and Learning in Information Retrieval. </title> <type> PhD thesis, </type> <institution> Computer Science Dept.; Univ. </institution> <address> of Mass.; Amherst, MA, </address> <year> 1992. </year> <type> Technical Report 91-93. </type>
Reference-contexts: We have proposed a concept learning model of text classification systems, which treats both statistical training and human knowledge engineering (or query formulation) as a search through a space of classification functions <ref> [Lew92] </ref>. This model suggests that the effectiveness of a text retrieval or text categorization system using a particular indexing language will depend on both the semantic and statistical characteristics of the language. <p> number of features used. 39 4 Experimental Hypotheses In comparison with words, an indexing language consisting of syntactic indexing phrases will have more terms, more synonymous or nearly synonymous terms, lower consistency of assignment (since synonymous terms are not assigned to the same documents), and lower document frequency for terms <ref> [Lew92] </ref>. Furthermore, if categorization into relatively broad categories is desired (as in the experiment reported in this paper), the meaning of most phrasal terms will be narrower in scope than the classes which we want to discriminate. All these factors suggested: 1. <p> Hypothesis 3 was tested by 40 comparing the best text categorization effective-ness obtained with each of four representations: words, phrases, word clusters, and phrase clusters. All experiments were conducted using the Max-cat text categorization package <ref> [Lew92] </ref>. Maxcat provides efficient storage of and access to sparse matrices of feature values, and flexibility in defining and evaluating classification procedures. In this section we describe the test collection used in these experiments, the statistical text categorization algorithms and text representation techniques tested, and finally the evaluation measures used. <p> In this section we describe the test collection used in these experiments, the statistical text categorization algorithms and text representation techniques tested, and finally the evaluation measures used. More details on the experiments and on Maxcat can be found elsewhere <ref> [Lew92] </ref>. 5.1 The Test Collection A corpus of 22,173 Reuters full-text newswire stories from 1987 was used for testing. The CONSTRUE rule-based text categorization system exhibited a microaveraged cat-precision and cat-recall (see Section 5.4) near 90% on a test subset of 723 of these stories [HW90].
Reference: [Lew92c] <author> Lewis, D. and Ringuette, M. </author> <title> Text categorization by inductive learning. </title> <type> Manuscript, </type> <month> Jan. </month> <year> 1992. </year>
Reference-contexts: Our best breakeven between microaveraged cat-recall and cat-precision was 0:65. This is a level of accuracy that has been found usable in at least one operational system [FHL + 91], and is very close to the effectiveness we found with a more computa-tionally expensive decision tree method <ref> [Lew92c] </ref>. We conclude that adapting probabilistic text retrieval models to text categorization is a reason able approach. 45 0 .4 .8 0 .2 .4 .6 .8 1 Prec.
Reference: [Mar61] <author> Maron, M. </author> <title> Automatic indexing: An experimental inquiry. </title> <journal> J. ACM, </journal> <volume> 8 </volume> <pages> 404-417, </pages> <year> 1961. </year>
Reference-contexts: We conducted some initial experiments with the model used by Maron <ref> [Mar61] </ref>, but later decided to switch to a model that supported probabilistic indexing for predictor features. The model used in our experiments was proposed by Fuhr [Fuh89] for probabilistic text retrieval, but the adaptation to text categorization is straightforward. <p> Of the 6,746 test documents, 8 were assigned to PLATINUM and 92 to SHIP.) Many studies on probabilistic models for text categorization have made simplifying assumptions to avoid addressing this problem. Maron's classic study <ref> [Mar61] </ref>, for instance, assumed advance knowledge of how many correct categories each test document should get. Other studies have used test sets where each document has exactly one category. Probability thresholding requires that estimates are comparable across all category/document pairs. <p> Maron <ref> [Mar61] </ref> proposed scaling estimates of P (C j = 1jD m ) so that they sum to 1.0 for each document, D m . This normalizes for document length and makes probabilities more comparable across documents. <p> A summary of the four representations reported on in this paper is given in Figure 3. 5.3.3 Feature Selection By feature selection we mean choosing, for each category, a subset of the terms from an indexing language to be used in predicting occurrences of that category. Maron <ref> [Mar61] </ref> and Hamill and Zamora [HZ80] proposed but did not test the use of information theoretic methods to select features. We implemented this approach, choosing for each category the k features with the highest expected mutual information [van77] between the feature and the category.
Reference: [Mur83] <author> Murtagh, F. </author> <title> A survey of recent advances in hierarchical clustering algorithms. </title> <journal> The Computer Journal, </journal> <volume> 26(4) </volume> <pages> 354-359, </pages> <year> 1983. </year>
Reference-contexts: Story belongs to categories GROUND-NUT and OILSEED. 5.3.2 Term Clustering Reciprocal nearest neighbor (RNN) clustering <ref> [Mur83] </ref> was used for clustering terms. An RNN cluster consists of two items, each of which is the nearest neighbor of the other according to the similarity metric in use. Therefore, not all items are clustered.
Reference: [PW91] <author> Peat, H. and Willett, P. </author> <title> The limitations of term co-occurrence data for query expansion in document retrieval systems. </title> <journal> JASIS, </journal> <volume> 42(5) </volume> <pages> 378-383, </pages> <year> 1991. </year>
Reference-contexts: When clustering terms from a 200 document collection, each term would be represented by 200 metafeatures, with each metafeature indicating presence or absence of that term in one of the 200 documents. Clusters formed using these metafea-tures will consist of terms that tend cooccur in documents. Peat and Willett <ref> [PW91] </ref> recently showed that clustering using documents as metafeatures tends to group terms that occur in similar numbers of documents, which is not necessarily desirable. Other metafeature definitions are possible. Crouch clustered words using metafeatures corre 38 sponding to automatically formed document clus-ters [Cro88].
Reference: [RS76] <author> Robertson, S. and Sparck Jones, K. </author> <title> Relevance weighting of search terms. </title> <booktitle> JASIS, </booktitle> <pages> pp. 129-146, </pages> <month> May-June </month> <year> 1976. </year>
Reference-contexts: In the experiments reported here P (W i = 1jD m ) is always 0 or 1, but nonbinary estimates could be used [Cro83, Fuh89]. * All probabilities were estimated from the training corpus using the "add one" adjustment (the Jeffreys prior) <ref> [RS76] </ref>. the PLATINUM category on our test set ranged from 10 9:96 to 10 3:21 , while the estimates for the SHIP category ranged from 10 2:89 to 10 9:47 .
Reference: [SB90] <author> Salton, G. and Buckley, C. </author> <title> Improving retrieval performance by relevance feedback. </title> <journal> JASIS, </journal> <volume> 41(4) </volume> <pages> 288-297, </pages> <year> 1990. </year>
Reference-contexts: There is considerable debate as to whether all words from user-identified relevant documents should be added to the user query, or whether statistical feature quality measures, user input, and domain knowledge should be used to limit the number of terms added <ref> [SB90, CD90] </ref>. Most studies on relevance feedback have used test collections of short, focused texts, such as titles and abstracts.
Reference: [SS91] <author> Smeaton, A. and Sheridan, P. </author> <title> Using morpho-syntactic language analysis in phrase matching. </title> <booktitle> RIAO-91, </booktitle> <pages> pp. 414-429, </pages> <year> 1991. </year>
Reference-contexts: The use of syntactic context in metafeatures, and the pruning of low quality phrases may help [Str92]. Smeaton and Sheridan <ref> [SS91] </ref>, as well as several researchers they cite, have suggested that partial matching on syntactic structures is a more effective approach to text representation than forming indexing phrases.
Reference: [Spa73a] <author> Sparck Jones, K. </author> <title> Collection properties influencing automatic term classification performance. </title> <booktitle> Information Storage and Retrieval, </booktitle> <volume> 9 </volume> <pages> 499-513, </pages> <year> 1973. </year>
Reference-contexts: Other metafeature definitions are possible. Crouch clustered words using metafeatures corre 38 sponding to automatically formed document clus-ters [Cro88]. Our CACM-3204 experiments clustered phrases using metafeatures corresponding to groups of documents defined by manual indexing categories [LC90]. Sparck Jones conducted the most comprehensive study of term clustering <ref> [Spa73a] </ref>. She used documents as metafeatures and found that small clusters of low frequency terms were most effective, regardless of the clustering method used.
Reference: [Str92] <author> Strzalkowski, T. </author> <title> Information retrieval using robust natural language processing. </title> <booktitle> In Proceedings of Speech and Natural Language Workshop, </booktitle> <publisher> Morgan Kaufmann: </publisher> <address> San Mateo, CA, </address> <month> Feb. </month> <year> 1992. </year> <note> To appear. </note>
Reference-contexts: However, it may be necessary to supplement statistical evidence of phrase similarity with evidence from thesauri and other knowledge sources, along with using metafeatures which provide tighter constraints on meaning. The use of syntactic context in metafeatures, and the pruning of low quality phrases may help <ref> [Str92] </ref>. Smeaton and Sheridan [SS91], as well as several researchers they cite, have suggested that partial matching on syntactic structures is a more effective approach to text representation than forming indexing phrases.
Reference: [Sun91] <editor> Sundheim, B., editor. </editor> <booktitle> Proceedings of the Third Message Understanding Evaluation and Conference, </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos, CA, </address> <month> May </month> <year> 1991. </year> <editor> [van77] van Rijsbergen, C. </editor> <title> A theoretical basis for the use of co-occurrence data in information retrieval. </title> <journal> Journal of Documentation, </journal> <volume> 33(2) </volume> <pages> 106-119, </pages> <month> June </month> <year> 1977. </year> <editor> [van79] van Rijsbergen, C. </editor> <booktitle> Information Retrieval. </booktitle> <publisher> Butterworths, </publisher> <address> London, </address> <note> second edition, 1979. </note> <editor> [van81] van Rijsbergen, C. </editor> <title> Retrieval effectiveness. </title> <editor> In Sparck Jones, K., editor, </editor> <booktitle> Information Retrieval Experiment. </booktitle> <address> But-terworths, London, </address> <year> 1981. </year> <month> 50 </month>
Reference-contexts: It has been widely investigated for assigning controlled vocabulary categories to documents for text retrieval, or for aiding human indexers in assigning such categories. Some systems of this sort are operational [BFL + 88, HW90]. Text categorization is also increasingly used to support category-specific processing in NLP systems <ref> [Sun91] </ref>. Two broad approaches have been taken to developing text categorization systems. First, a number of systems have been the result of human knowledge engineering of categorization rules and knowledge bases [HW90]. The second approach is to induce the categorization system automatically from manually labeled training data.
References-found: 30

