URL: ftp://ftp.cs.rochester.edu/pub/papers/ai/95.heeman.IEICE.ps.gz
Refering-URL: http://www.cs.rochester.edu/u/heeman/papers.html
Root-URL: 
Email: fheeman,kyunghog@itl.atr.co.jp  
Title: Using Structural Information to Detect Speech Repairs  
Author: Peter A. Heeman and Kyung-ho Loken-Kim 
Address: 2-2 Hikaridai, Seika-cho, Soraku-gun, Kyoto, 619-02 JAPAN  
Affiliation: ATR Interpreting Telecommunications Research Laboratories  
Abstract: Previous approaches to detecting and correcting speech repairs have for the most part separated these two problems. In this paper, we present a statistical model of speech repairs that uses information about the postulated repair structure (correction) to help decide whether a speech repair actually occurred. By better modeling the interactions between detection and correction, we are able to improve our detection results. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Church, K. </author> <year> 1988. </year> <title> A stochastic parts program and noun phrase parser for unrestricted text. </title> <booktitle> In Proceedings of the 2nd Conference on Applied Natural Language Processing, </booktitle> <pages> pages 136-143, </pages> <month> Febuary. </month>
Reference-contexts: Part-of-speech tagging is the process of assigning to a word the category that is most probable given the sentential context <ref> (Church, 1988) </ref>. The sentential context is typically approximated by only a set number of previous categories, usually one or two. Good part-of-speech results can be obtained using only the preceding category (Weischedel et al., 1993), which is what we will be using.
Reference: <author> Dowding, John, Jean Mark Gawron, Doug Appelt, John Bear, Lynn Cherny, Robert Moore, and Douglas Moran. </author> <year> 1993. </year> <title> Gemini: A natural language system for spoken-language understanding. </title> <booktitle> In Proceedings of the 31 th Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pages 54-61. </pages> <institution> Entropic Research Laboratory, Inc., </institution> <year> 1993. </year> <title> WAVES+ Reference Manual. </title> <note> Version 5.0. </note>
Reference-contexts: For detection, they were able to achieve a recall rate of 76%, and a precision of 62%, and they were able to find the correct repair 57% of the time, leading to an overall correction recall of 43% and correction precision of 50%. In later work <ref> (Dowding et al., 1993) </ref>, they also tried combining syntactic and semantic knowledge in a "parser-first" approach|first try to parse the input and if that fails, invoke repair strategies based on word patterns in the input.
Reference: <author> Heeman, Peter and James Allen. </author> <year> 1994. </year> <title> Detecting and correcting speech repairs. </title> <booktitle> In Proceedings of the 32 th Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pages 295-302, </pages> <address> Las Cruces, New Mexico, </address> <month> June. </month>
Reference-contexts: The only solution is to use information about the likely correction for a potential interruption point as a clue for deciding if it is in fact a repair. In this paper, we will focus on modification repairs and show how our existing statistical model for detecting modification repairs <ref> (Heeman and Allen, 1994) </ref> can be augmented to use information about the proposed correction. 3 We have categorized potential corrections into a set of ten different groups, which differ in terms of how strongly they signal a modification repair.
Reference: <author> Heeman, Peter A. and James Allen. </author> <year> 1995. </year> <title> The Trains 93 dialogues. </title> <type> Trains Technical Note 94-2, </type> <institution> Department of Computer Science, University of Rochester, </institution> <month> March. </month>
Reference-contexts: actually occurs, but simply relies on the yes/no decision of the correction module. 3 The Trains Corpus As part of the Trains project (Allen et al., 1995), which is a long term research project to build a conversationally proficient planning assistant, we have collected a corpus of problem solving dialogs <ref> (Heeman and Allen, 1995) </ref>. The dialogs involve two human participants, one who is playing the role of a user and has a certain task to accomplish, and another who is playing the role of the system by acting as a planning assistant. <p> These dialogs have been segmented into single speaker utterance files and word annotated using the Waves software (Ent, 1993). The corpus is available from the Linguistics Data Consortium on CD-ROM <ref> (Heeman and Allen, 1995) </ref>. The speech repairs in the dialog corpus have been hand-annotated.
Reference: <author> Heeman, Peter A. and James Allen. </author> <year> 1996a. </year> <title> Annotating speech repairs. </title> <type> Unpublished manuscript. </type>
Reference-contexts: The example below illustrates how a repair is annotated in this scheme. engine two from Elmi- or engine three from Elmira m1 r2 m3 m4 et m1 r2 m3 m4 Further details of this scheme can be found in <ref> (Heeman and Allen, 1996a) </ref>. 4 Statistical Model For detecting speech repairs, we use a statistical model based on a part-of-speech tagger.
Reference: <author> Heeman, Peter A. and James Allen. </author> <year> 1996b. </year> <title> Using local context to detect and correct speech repairs. </title> <note> In preparation. </note>
Reference-contexts: So, by giving these distributions to the part-of-speech tagger, the tagger can decide if a transition signals a modification repair or not. In fact, in our general model <ref> (Heeman and Allen, 1996b) </ref>, we feel that these different distributions can be used as the basis for detecting fresh starts and intonational phrase boundaries as well. Part-of-speech tagging is the process of assigning to a word the category that is most probable given the sentential context (Church, 1988).
Reference: <author> Heeman, Peter A. and James F. Allen. </author> <year> 1995. </year> <title> The Trains spoken dialog corpus. CD-ROM, </title> <booktitle> Linguistics Data Consortium, </booktitle> <month> April. </month>
Reference-contexts: actually occurs, but simply relies on the yes/no decision of the correction module. 3 The Trains Corpus As part of the Trains project (Allen et al., 1995), which is a long term research project to build a conversationally proficient planning assistant, we have collected a corpus of problem solving dialogs <ref> (Heeman and Allen, 1995) </ref>. The dialogs involve two human participants, one who is playing the role of a user and has a certain task to accomplish, and another who is playing the role of the system by acting as a planning assistant. <p> These dialogs have been segmented into single speaker utterance files and word annotated using the Waves software (Ent, 1993). The corpus is available from the Linguistics Data Consortium on CD-ROM <ref> (Heeman and Allen, 1995) </ref>. The speech repairs in the dialog corpus have been hand-annotated.
Reference: <author> Hindle, Donald. </author> <year> 1983. </year> <title> Deterministic parsing of syntactic non-fluencies. </title> <booktitle> In Proceedings of the 21 st Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pages 123-128. </pages>
Reference: <author> Katz, Slava M. </author> <year> 1987. </year> <title> Estimation of probabilities from sparse data for the language model component of a speech recognizer. </title> <journal> IEEE Transactions on Acoustics, Speech, and Signal Processing, </journal> <pages> pages 400-401, </pages> <month> March. </month> <note> Kikui, </note> <author> Gen-ichiro and Tsuyoshi Morimoto. </author> <year> 1994. </year> <title> Similarity-based identification of repairs in Japanese spoken language. </title> <booktitle> In Proceedings of the 3rd International Conference on Spoken Language Processing (ICSLP-94), </booktitle> <pages> pages 915-918. </pages>
Reference-contexts: So we combine these two sources of information, using P (T i jS i M i )=P (T i ) as the preference factor. To cope with the limited amount of training data, we use a back-off model <ref> (Katz, 1987) </ref>, which first back-offs on the identify of the matching word, and then on the distance between the word matching. Next we back-off on the structural analysis score, combining categories that make similar predictions about the occurrences of a modification repair.
Reference: <author> Kurohashi, Sadao and Makoto Nagao. </author> <year> 1992. </year> <title> Dynamic programming method for analyzing conjunctive structures in Japanese. </title> <booktitle> In Proceedings of the 14 th International Conference on Computational Linguistics (COLING '92). </booktitle>
Reference-contexts: First, they find all possible onsets for the reparadum that cause the resulting correction to be well-formed, according to an adjacency matrix that lists syntactically well-formed POS transitions. Second, they used a similarity-based analyzer <ref> (Kurohashi and Nagao, 1992) </ref> that finds the best path through all possible repair structures using dynamic programming. Each type of word correspondence has been given a different weight. The best path was then altered to take into account the well-formedness information from the first step.
Reference: <author> Labov, William. </author> <year> 1966. </year> <title> On the grammaticality of everyday speech. </title> <booktitle> Paper presented at the Linguistic Society of America Annual Meeting. </booktitle>
Reference-contexts: For abridged repairs, there is no reparadum, and so simply knowing that it is abridged automatically gives the correction. Previous work in correcting speech repairs (Levelt, 1983; Hindle, 1983; Kikui and Morimoto, 1994) has assumed that speech repairs are accompanied by an acoustic editing signal <ref> (Labov, 1966) </ref>. Given the interruption point, the type of repair, and the syntactic categories of the words involved, correction rates of around 95% can be achieved. However, a reliable accoustic signal has yet to be found (Bear, Dowding, and Shriberg, 1992).
Reference: <author> Levelt, Willem J. M. </author> <year> 1983. </year> <title> Monitoring and self-repair in speech. </title> <journal> Cognition, </journal> <volume> 14 </volume> <pages> 41-104. </pages>
Reference: <author> Lickley, R. J. and E. G. Bard. </author> <year> 1992. </year> <title> Processing disfluent speech: Recognizing disfluency before lexical access. </title> <booktitle> In Proceedings of the 2nd International Conference on Spoken Language Processing (ICSLP-92), </booktitle> <pages> pages 935-938, </pages> <month> Oc-tober. </month>
Reference: <author> Nakatani, Christine and Julia Hirschberg. </author> <year> 1993. </year> <title> A speech-first model for repair detection and correction. </title> <booktitle> In Proceedings of the 31 th Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pages 46-53. </pages>
Reference: <author> Shriberg, Elizabeth Ellen. </author> <year> 1994. </year> <title> Preliminaries to a theory of speech disfluencies. </title> <institution> Doctoral dissertion, University of California at Berkeley. </institution>
Reference: <author> Weischedel, Ralph, Marie Meteer, Richard Schwartz, Lance Ramshaw, and Jeff Palmucci. </author> <year> 1993. </year> <title> Coping with ambiguity and unknown words through probabilistic models. </title> <journal> Computational Linguistics, </journal> <volume> 19(2) </volume> <pages> 359-382. </pages>
Reference-contexts: The sentential context is typically approximated by only a set number of previous categories, usually one or two. Good part-of-speech results can be obtained using only the preceding category <ref> (Weischedel et al., 1993) </ref>, which is what we will be using. In this case, the number of states of the Markov model will be N , where N is the number of tags.
References-found: 16

