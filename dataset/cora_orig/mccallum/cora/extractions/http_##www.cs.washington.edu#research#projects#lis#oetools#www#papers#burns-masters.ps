URL: http://www.cs.washington.edu/research/projects/lis/oetools/www/papers/burns-masters.ps
Refering-URL: http://www.cs.washington.edu/homes/burns/professional/pubs.html
Root-URL: http://www.cs.washington.edu
Title: Automated Compilation of Concurrent Programs into Self-timed Circuits  
Author: Steven M. Burns 
Degree: Thesis by  In Partial Fulfillment of the Requirements for the Degree of Master of Science  
Date: December 1987  
Address: Pasadena, California  
Affiliation: California Institute of Technology  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> M. Annaratone, </author> <title> Digital CMOS Circuit Design, </title> <publisher> Kluwer Academic, </publisher> <address> Boston, </address> <note> pp 134-5 (1986) </note>
Reference-contexts: However, in future technologies, interconnect delays will become more significant and the isochronic fork assumption may be invalid <ref> [1] </ref>. Fortunately, arbitrary-size isochronic forks are not intrinsically necessary for our compilation strategy. We may algorithmically reduce each large isochronic fork into an isochronic fork between two usage points. 4.2 Algorithmic Solution The isochronic forks produced by the compilation methodology are local to a single sequential process.
Reference: [2] <author> E. W. Dijkstra, </author> <title> "Guarded commands, nondeterminacy, and formal derivation of programs", </title> <journal> Comm. </journal> <note> ACM 18, 8, pp 453-457 (August 1975) </note>
Reference: [3] <author> C. A. R. Hoare, </author> <title> "Communicating Sequential Processes", </title> <journal> Comm. </journal> <note> ACM 21, 8, pp 666-677 (August 1978) </note>
Reference-contexts: Our language is based on CSP <ref> [3] </ref> with the probe [8]. A few new constructs have been added to facilitate efficient implementation in VLSI. The new constructs reduce the number of explicit variables needed in some programs by introducing more control structures.
Reference: [4] <author> A. J. Martin, </author> <title> "An Axiomatic Definition of Synchronization Primitives", </title> <journal> Acta Infor-matica, </journal> <volume> 16, </volume> <pages> pp 219-235 (1981) </pages>
Reference-contexts: The integer valued variable cX represents the number of completed communication action through the port X . The boolean qX states whether X is ready but not able to finish a communication action. The standard zero slack axioms apply <ref> [4] </ref>. :qL _ :qR A Hoare triple semantics of the data transmission mechanism is given in Figure 1.4. The communications L and R are performed by separate sequential processes. Information is exchanged during the communication. One of m values is transmitted from port L to port R.
Reference: [5] <author> A. J. Martin, </author> <title> "Compiling Communicating Processes into Delay-Insensitive VLSI Circuits", </title> <journal> Distributed Computing, </journal> <volume> 1, </volume> <pages> pp 226-234 (1986) </pages>
Reference-contexts: In this first transformation step, the designer may apply the tools of concurrent program development and verification. The concurrent program is then transformed into a semantically equivalent self-timed circuit. Alain Martin <ref> [5, 7] </ref> describes a general framework for performing these transformation. In this thesis, we describe a way of automating the compilation procedure. The final task is the realization of the operator sets in a computing medium such as a VLSI chip. <p> Chapter 2 Decomposition Our goal is to produce a translation procedure that transforms an arbitrary program of the language introduced in the last chapter into a self-timed circuit. The method we demonstrate faithfully applies the low level techniques described in <ref> [7, 5] </ref>. However, we choose to do most of the work at a higher level by first decomposing each process into a collection of smaller, more easily compiled processes. We use the syntax of the original program to guide the decomposition. <p> Notice that the abbreviations for infinite repetition, communication, and probes have been expanded to their general forms. 2.2 Decomposition and Sub-Processes When implementing a complex process, one may wish to divide the process code into pieces and compile the pieces separately. Process decomposition <ref> [5] </ref> provides a method of structuring the division of process code. A process may be decomposed by moving a statement or sequence of statements from the original process to a new concurrently executing process. <p> ! D (0)]] kactive D 0 (1; 2) fl [[G ! D 0 : [1 ! H 0 j0 ! G]]] )channel (D 0 ; D) Chapter 3 Compilations We have decomposed the original program into sub-processes which are now small enough to compile easily using the method described in <ref> [5, 7] </ref>. We begin the description of the compilations by a brief review of this method and how it is applied to our problem. 3.1 Synopsis The compilation method consists of a sequence of step-wise refinements. <p> While we can not enforce "true" simultaneity in an asynchronous environment, it is possible define the simultaneous completion of a communication action in a consistent and implementable manner (see <ref> [5] </ref>). Consider the following implementation of a communication from the active port X to the passive port Y . Each port is implemented by an input variable (denoted by xi for the port X) and an output variable (xo). <p> We allow the parameter in parenthesis to be a free running variable in order to concisely specify constructs of arbitrary size. Since there can be no ambiguity between a parameter and a suffix, we may without confusion use i as a free running variable. Using handshaking expansion notation <ref> [5] </ref>, the general passive communication action (see [l (0)i ! l (i)o "; [:l (0)i]; l (i)o #; ff 0 j : : : jl (n 1)i ! l (i)o "; [:l (n 1)i]; l (i)o #; ff n1 ] and the general active communication as r (j)o "; [r (0)i <p> form, we get fl [[di ! x "; [x]; do "; [:di]; do # jf i ! x #; [:x]; f o "; [:f i]; f o #]] The derivation of the resulting production rule set, operator set and resulting circuit shown in figure 3.3 is straight-forward and given in <ref> [5] </ref>.
Reference: [6] <author> A. J. Martin, </author> <note> "A Delay-Insensitive Fair Arbiter", Caltech Computer Science Technical Report 5193:TR:85 (1985) </note>
Reference-contexts: In the first case we use the arbiter from <ref> [6] </ref>. (ui; li)me (u; l) V (l; :si) (to) (ti)w (lo) The me operator is a primitive process which implements the handshaking expansion (ui; vi)me (uo; vo) j fl [[ui ! uo "; [:ui]; uo # []vi ! vo "; [:vi]; vo #]] as long as the four-phase protocol is obeyed
Reference: [7] <author> A. J. Martin, </author> <title> "The Design of a Self-Timed Circuit for Distributed Mutual Exclusion", </title> <booktitle> Proc. 1985 Chapel Hill Conf. VLSI, </booktitle> <editor> ed. </editor> <booktitle> Henry Fuchs, </booktitle> <pages> pp 247-260 (1985) </pages>
Reference-contexts: In this first transformation step, the designer may apply the tools of concurrent program development and verification. The concurrent program is then transformed into a semantically equivalent self-timed circuit. Alain Martin <ref> [5, 7] </ref> describes a general framework for performing these transformation. In this thesis, we describe a way of automating the compilation procedure. The final task is the realization of the operator sets in a computing medium such as a VLSI chip. <p> No variables or ports may be inherited from the surrounding scope when these code segments are instantiated. We illustrate the instantiation mechanism with a complete example (see Figure 1.6), a ring of four processes which insures mutually exclusive access to a single resource <ref> [7] </ref>. The process ring is created by instantiating three priv0 processes and one priv1 process. The L and R ports are connected via channels to form a ring of four elements. <p> Chapter 2 Decomposition Our goal is to produce a translation procedure that transforms an arbitrary program of the language introduced in the last chapter into a self-timed circuit. The method we demonstrate faithfully applies the low level techniques described in <ref> [7, 5] </ref>. However, we choose to do most of the work at a higher level by first decomposing each process into a collection of smaller, more easily compiled processes. We use the syntax of the original program to guide the decomposition. <p> ! D (0)]] kactive D 0 (1; 2) fl [[G ! D 0 : [1 ! H 0 j0 ! G]]] )channel (D 0 ; D) Chapter 3 Compilations We have decomposed the original program into sub-processes which are now small enough to compile easily using the method described in <ref> [5, 7] </ref>. We begin the description of the compilations by a brief review of this method and how it is applied to our problem. 3.1 Synopsis The compilation method consists of a sequence of step-wise refinements.
Reference: [8] <author> A. J. Martin, </author> <title> "The Probe: an Addition to Communication Primitives", </title> <journal> Information Processing Letters, </journal> <volume> 20, </volume> <pages> pp 125-130 (1985) </pages>
Reference-contexts: Our language is based on CSP [3] with the probe <ref> [8] </ref>. A few new constructs have been added to facilitate efficient implementation in VLSI. The new constructs reduce the number of explicit variables needed in some programs by introducing more control structures.
Reference: [9] <author> C. L. Seitz, </author> <title> "System Timing", Chapter 7 in Mead and Conway, Introduction to VLSI Systems, </title> <publisher> Addison-Wesley, </publisher> <address> Reading MA (1980) </address>
Reference: [10] <author> L. Sterling and E. Shapiro, </author> <title> The Art of Prolog, </title> <publisher> The MIT Press, </publisher> <address> Cambridge MA (1986) </address>
Reference-contexts: This compiler closely follows the structure of standard source-to-machine code compilers, in particular the Prolog implementations described in <ref> [10, 11] </ref>. While it is beyond the scope of this thesis to describe the compiler in detail, we will make claims about its performance, and thus make claims about the quality of the circuits produced by the compilation technique as a whole.
Reference: [11] <author> D. Warren, </author> <title> "Logic Programming and Compiler Writing", </title> <journal> Software-Practice and Experience, </journal> <volume> 10, </volume> <month> 2 </month> <year> (1980) </year> <month> 55 </month>
Reference-contexts: This compiler closely follows the structure of standard source-to-machine code compilers, in particular the Prolog implementations described in <ref> [10, 11] </ref>. While it is beyond the scope of this thesis to describe the compiler in detail, we will make claims about its performance, and thus make claims about the quality of the circuits produced by the compilation technique as a whole.
References-found: 11

