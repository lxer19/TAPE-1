URL: http://www.cs.rice.edu:80/~achauhan/work/fall95/comp425/report.ps
Refering-URL: http://www.cs.rice.edu:80/~achauhan/work/courses.html
Root-URL: 
Email: (achauhan@cs.rice.edu)  (henrik@cs.rice.edu)  (shilpa@cs.rice.edu)  
Title: Quantitative Comparison of Set-Associative and Victim Caches  
Author: Arun Chauhan Henrik Weimer Shilpa Lawande 
Date: December 7th, 1995  
Abstract: As processors become faster, memory performance becomes a serious bottleneck. In recent years memory speeds have failed to keep up with processor speeds and the gap has been steadily increasing. Cache performance has become a critical parameter in system performance. Several methods have been proposed to improve cache performances. One such technique that aims at reducing the cache miss rate, without affecting the hit rate is using what are called "victim caches". Victim caches are small fully associative caches placed between a cache and its refill path. Misses served by the victim caches have only a very small miss penalty, typically one cycle, as opposed to several cycles for main memory. A small victim cache along with a direct mapped primary cache is expected to significantly improve the 
Abstract-found: 1
Intro-found: 1
Reference: [AP93] <author> A Agarwal and D Pudar. </author> <title> Column-associative caches: A technique for reducing the miss rate of direct-mapped caches. In Computer Architecture News, </title> <address> San Diego, Cal-ifornia, </address> <month> May </month> <year> 1993. </year> <booktitle> 20th Annual International Symposium on Computer Architecture ISCA '20. </booktitle>
Reference-contexts: At the same time it increases miss penalty. Increasing the cache associativity can reduce conflict misses, but can lead to higher hit times as the hardware complexity increases. Targeting higher clock rates favors a simple cache design with low hit times [Hil88]. Other techniques include column-associative caches <ref> [AP93] </ref>, and compiler-controlled prefetching [MLG92] and optimizations [McF89]. Victim caches were first proposed by Jouppi [Jou90] as a mechanism to improve the hit rate of a primary cache.
Reference: [Com92a] <author> SPEC Steering Committee. </author> <title> Introduction to the SPEC CPU Floating Point Benchmark Suite: </title> <journal> CFP92. </journal> <note> SPEC, release 2/1992 edition, </note> <month> October 19 </month> <year> 1992. </year>
Reference-contexts: We had to extend the capabilities of Dinero to support victim caches at the same time maintaining its original behavior. 4 Experiments We analyzed the behavior of various cache configurations on a subset of the SPEC92 benchmark suite <ref> [Com92b, Com92a] </ref> which has been widely accepted as a measure for performance. The benchmarks used are described in table 4.
Reference: [Com92b] <author> SPEC Steering Committee. </author> <title> Introduction to the SPEC CPU Integer Benchmark Suite: </title> <journal> CINT92. </journal> <note> SPEC, release 2/1992 edition, </note> <month> October 19 </month> <year> 1992. </year>
Reference-contexts: We had to extend the capabilities of Dinero to support victim caches at the same time maintaining its original behavior. 4 Experiments We analyzed the behavior of various cache configurations on a subset of the SPEC92 benchmark suite <ref> [Com92b, Com92a] </ref> which has been widely accepted as a measure for performance. The benchmarks used are described in table 4.
Reference: [Hil87] <author> Mark D. Hill. </author> <title> Aspects of Cache Memory and Instruction Buffer Performance. </title> <type> PhD thesis, </type> <institution> University of California, </institution> <year> 1987. </year> <type> Tech. Rep. </type> <month> UCB/CSD 87/381 (November). </month>
Reference-contexts: Used with a direct-mapped cache, a victim cache serves to increase the cache associativity, in a limited sense. This results in an improved performance of conflict misses, which typically account for 20%-40% <ref> [Hil87] </ref> of all cache misses. One major point of distinction between victim caches and second or higher level caches is that they do not have the inclusion property. Furthermore, the contents of the victim cache and those of it's associated cache are mutually exclusive.
Reference: [Hil88] <author> Mark D. Hill. </author> <title> A case for direct mapped caches. </title> <journal> Computer, </journal> <volume> 21(12) </volume> <pages> 25-40, </pages> <month> December </month> <year> 1988. </year>
Reference-contexts: At the same time it increases miss penalty. Increasing the cache associativity can reduce conflict misses, but can lead to higher hit times as the hardware complexity increases. Targeting higher clock rates favors a simple cache design with low hit times <ref> [Hil88] </ref>. Other techniques include column-associative caches [AP93], and compiler-controlled prefetching [MLG92] and optimizations [McF89]. Victim caches were first proposed by Jouppi [Jou90] as a mechanism to improve the hit rate of a primary cache.
Reference: [Jou90] <author> Norman P Jouppi. </author> <title> Improving direct-mapped cache performance by the addition of a small fully-associative cache and prefetch buffers. </title> <booktitle> In Conference Proceedings - Annual Symposium on Computer Architecture, </booktitle> <address> Los Alamitos, California, Aug 1990. </address> <publisher> IEEE, Computer Society Press. </publisher>
Reference-contexts: A cache miss might result in a heavy penalty in terms of number of instructions which may be even higher for superscalar architectures that issue multiple instructions per cycle. Table 1 lists some cache miss times and the effects of the misses on machine performance <ref> [Jou90] </ref>. All this points to a greater incentive for reducing the cache miss rates. <p> The conventional caching techniques handle this by using a set-associative cache. However this limits the number of sets that could be present in a cache for a fixed cache size. As an alternative, we could use a victim cache <ref> [Jou90] </ref> which is a small fully associative cache placed between a cache and the object it caches (main memory, in our case). It is used to hold the "victims" that are chosen for replacement from the cache. <p> Targeting higher clock rates favors a simple cache design with low hit times [Hil88]. Other techniques include column-associative caches [AP93], and compiler-controlled prefetching [MLG92] and optimizations [McF89]. Victim caches were first proposed by Jouppi <ref> [Jou90] </ref> as a mechanism to improve the hit rate of a primary cache. Victim caches (figure 1) are used to store the data that is discarded from the cache because of a conflict, and hence, reduce the miss penalty due to conflict misses. <p> Jouppi <ref> [Jou90] </ref> mainly focuses on finding the percentage of conflict misses removed from a direct mapped cache by the use of a victim cache while we are interested in a quantitative comparison of direct mapped caches together with a victim cache and set-associative caches.
Reference: [McF89] <author> S. McFarling. </author> <title> Program optimization for instruction caches. </title> <booktitle> In Proc. Third Int'l Conf. on Architectural support for programming languages and operating systems, </booktitle> <pages> pages 183-191, </pages> <address> Boston, </address> <month> April </month> <year> 1989. </year>
Reference-contexts: Increasing the cache associativity can reduce conflict misses, but can lead to higher hit times as the hardware complexity increases. Targeting higher clock rates favors a simple cache design with low hit times [Hil88]. Other techniques include column-associative caches [AP93], and compiler-controlled prefetching [MLG92] and optimizations <ref> [McF89] </ref>. Victim caches were first proposed by Jouppi [Jou90] as a mechanism to improve the hit rate of a primary cache.
Reference: [MLG92] <author> T. C. Mowry, S. Lam, and A. Gupta. </author> <title> Design and evaluation of a compiler algorithm for prefetching. </title> <booktitle> In Fifth Int'l Conf. on Architectural support for Programming languages and operating systems, </booktitle> <pages> pages 62-73, </pages> <address> Boston, </address> <month> October </month> <year> 1992. </year> <journal> SIGPLAN Notices 27:9. </journal>
Reference-contexts: Increasing the cache associativity can reduce conflict misses, but can lead to higher hit times as the hardware complexity increases. Targeting higher clock rates favors a simple cache design with low hit times [Hil88]. Other techniques include column-associative caches [AP93], and compiler-controlled prefetching <ref> [MLG92] </ref> and optimizations [McF89]. Victim caches were first proposed by Jouppi [Jou90] as a mechanism to improve the hit rate of a primary cache.
Reference: [PH96] <author> David A Patterson and John L Hennessey. </author> <title> Computer Architecture A Quantitative Approach. </title> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <address> San Francisco, California, </address> <note> second edition, </note> <year> 1996. </year>
Reference-contexts: There are several techniques for improving each of these <ref> [PH96] </ref>. All cache misses can be categorized into the following types. Compulsory These are first reference misses since a block must be brought into the cache the first time it is accessed. Capacity If the number of active blocks is more than the cache can contain, capacity misses take place. <p> This pure consideration of miss ratios is in fact quite conservative, as this disregards the different average access times for the different systems. If we adopt the assumption that the 2-way set associative cache has a 10% longer cycle time than the direct mapped cache <ref> [PH96] </ref> and we assume that misses in the direct mapped cache which are hits in the victim cache can be handled within two cycles, the direct mapped cache together with the victim cache outperforms the set-associative cache at the break even point.
Reference: [Sti94] <author> Dimitrios Stiliadis. </author> <title> Selective victim caching : A method to improve the performance of direct-mapped caches. </title> <booktitle> In Proceedings of the 27th Hawaii International Conference on System Sciences, </booktitle> <address> Los Alamitos, California, 1994. </address> <publisher> IEEE, Computer Society Press. </publisher>
Reference-contexts: In addition, it serves to increase the associativity of the primary cache in the sense that for a small subset of the cache now behaves like a set associative cache. Selective victim caching was proposed by <ref> [Sti94] </ref> to improve the performance of victim caches. The incoming blocks are selectively placed into the victim or the main cache based on their past history of use. The blocks are also exchanged between the two caches selectively.
References-found: 10

