URL: http://www.research.microsoft.com/~gurevich/Opera/94.ps
Refering-URL: http://www.research.microsoft.com/~gurevich/annotated.html
Root-URL: http://www.research.microsoft.com
Title: Average Case Complexity  
Author: Yuri Gurevich 
Affiliation: University of Michigan.  
Abstract: We attempt to motivate, justify and survey the average case reduction theory. 
Abstract-found: 1
Intro-found: 1
Reference: [BCGL] <author> Shai Ben-David, Benny Chor, Oded Goldreich and Michael Luby, </author> <title> "On the Theory of Average Case Complexity", </title> <booktitle> Symposium on Theory of Computing, ACM, </booktitle> <year> 1989, </year> <pages> 204-216. </pages>
Reference-contexts: The references include three student papers: [Gr], [Kn] and [Sc]. 2. Polynomial on average In the average case approach, a decision or search problem is supposed to be given together with a probability distribution on instances. A problem with a probability distribution on instances is called randomized (or distributional <ref> [BCGL] </ref>). <p> A more extensive discussion of the issue of AP functions can be found in [Gu1] and <ref> [BCGL] </ref>. We will return to that issue in Section 7. 3. A new setting A randomized NP decision or search problem may be specified by a triple (D; W; R) where D, W and R are as above (in Section 1) except that D is a domain now. <p> is played by the class AP of AP-time decidable RNP decision problems. (This is going to be revised.) It is difficult to exhibit an RNP decision problem that is not AP. (Such a problem exists if N T ime (2 O (n) ) 6= DT ime (2 O (n) ) <ref> [BCGL] </ref>.) In particular, the existence of such a problem implies P 6= N P . However the reduction theory allows one to exhibit maximally hard RNP problems. We try to motivate an appropriate reduction notion. <p> Such a reduction can be made deterministic by pretending that all coins come up heads. This may ruin the domination requirement however. Fully correct reductions may be employed to overcome the phenomenon of flatness [Gu1, Gu3]. It is much more fruitful though to allow partially correct reductions <ref> [VL, BCGL, IL] </ref>. <p> Repeating a randomizing reduction k times results in k outputs in the target domain, not one as in the definition of reduction. In other words, such a repetition is a version of Turing (or truth-table) reduction, not a many-one reduction. At this point, we refer the reader to papers <ref> [VL, BCGL, IL] </ref> where partially correct reductions were successfully employed. It is our impression that the notion of reductions of RNP problems requires a little additional cleaning work. <p> This simple reduction does not work for RNP problems; it violates the domination condition. Using substantially more sophisticated randomizing Turing reductions, Ben-David, Chor, Goldreich and Luby were able to prove that every RNP search problem reduces to an appropriate RNP decision problem <ref> [BCGL] </ref>. 6. Revision 2: P-samplable distributions We return to the definition of domains in Section 2 and discuss probability distributions. For simplicity, restrict attention to domains where the universe is the set f0; 1gfl of all binary strings and the size of a string is its length. <p> Even a disinterested party may inadvertently mess things up. Certainly one would expect an adversary to mess things up. The following definition is implicitly in [Le2] and explicitly in <ref> [BCGL] </ref>. Definition 6.1. A distribution is P-samplable if it is generated by a coin-flipping Turing machine M (with no addi 9 tional input) such that the length of every terminating computation of M is bounded by a fixed polynomial of the output. <p> Chor, Goldreich and Luby prove that (i) every P-time distribution is P-samplable, and (ii) if there exists a one-way function (a function which is easy to compute but difficult in some precise technical sense to invert) then there is a P-samplable distribution which is not dominated by any P-time distribution <ref> [BCGL] </ref>. Fortunately, Impagliazzo and Levin were able to prove the following theorem. Theorem 6.1 [IL]. Every NP search problem with a P-samplable distribution reduces to an NP search problem with the uniform distribution.
Reference: [BG] <author> Andreas Blass and Yuri Gure-vich, </author> <title> "On the Reduction Theory for Average-Case Complexity", </title> <booktitle> in Proc. of CSL'90, 4th Workshop on Computer Science Logic (Eds. </booktitle> <editor> E. Borger, H. Kleine Buning and M. Richter), </editor> <publisher> Springer LNCS, </publisher> <year> 1991. </year>
Reference-contexts: In any case, it seems to us that, in many applications where polynomial time is feasible, polynomial on average time is feasible as well. The question arises what does it mean that a function is polynomial (i.e. polynomially bounded) on average. Following <ref> [BG] </ref>, we define a domain to be a set U (the universe) with a function from U to natural numbers (the size function) and a probability distribution on U satisfying the following technical restrictions. <p> Since E (T 0 ) = 1, we have the following special case of (3.2): (3.3) P 1 (f 1 (f x))=P 2 (f x) is AP. Theorem 3.1 <ref> [BG] </ref>. Assume (3.1). Then (3.2) $ (3.3). Say that D 2 dominates D 1 with respect to f if (3.3) holds. This is a slight variation on Levin's original definition of domination. Definition 3.1. <p> Given an instance x of the randomized halting problem, the reducing machine of Venkate-san and Levin flips coins to produce a random graph of an appropriate size. Then it massages this graph to make sure that x can be coded in with a sufficiently high probability. Next, following <ref> [BG] </ref>, we generalize the notion of domain reduction by allowing reductions to flip coins. All reductions as in Section 3 will be called deterministic from now on. Consider a Turing machine M which takes inputs from a domain D and which can flip a fair coin. <p> Call such f a random function on D. (One may object to the term "random function" on the grounds that a random function on A should be a randomly chosen function on A. The term "a random function" is fashioned in <ref> [BG] </ref> after well accepted terms like "a real function". A real function assigns real numbers to elements.
Reference: [GJ] <author> Michael R. Garey and David S. Johnson, </author> <title> "Computers and Intractability: A Guide to the Theory of NP-Completeness", </title> <publisher> Freeman, </publisher> <address> New York, </address> <year> 1979. </year>
Reference-contexts: Address: EECS Dept., University of Michi-gan, 1301 Beal Ave., Ann Arbor, MI 48109-2122. Email: gurevich@eecs.umich.edu to wider classes. NP and the class of NP search problems are sufficiently important. The restriction to the case when instances and witnesses are strings is standard <ref> [GJ] </ref>, even though it means that one may be forced to deal with string encodings of real objects of interest. The reason is that we need a clear computational model. If instances and witnesses are strings, the usual Turing machine model can be used.
Reference: [Go] <author> Oded Goldreich, </author> <title> "Towards a Theory of Average Case Complexity: A survey", </title> <institution> TR-531, Computer Science Dept., Technion, Haifa, Israel, </institution> <month> March </month> <year> 1988. </year>
Reference: [Gr] <author> Per Grape, </author> <title> "Complete Problems with L-Samplable Distributions", </title> <booktitle> 2nd Scandinavian Workshop on Algorithm Theory, Springer Lecture Notes in Computer Science 447, </booktitle> <year> 1990, </year> <pages> 360-367. </pages>
Reference-contexts: Leonid Levin proposed one average case approach in [Le1]. His approach is the topic of this talk. We hope this account is entertaining. It certainly isn't complete. The references include three student papers: <ref> [Gr] </ref>, [Kn] and [Sc]. 2. Polynomial on average In the average case approach, a decision or search problem is supposed to be given together with a probability distribution on instances. A problem with a probability distribution on instances is called randomized (or distributional [BCGL]).
Reference: [Gu1] <author> Yuri Gurevich, </author> <title> "Average Case Complexity", </title> <journal> J. </journal> <note> Computer and System Sciences (a special issue on FOCS'87), to appear. 13 </note>
Reference-contexts: It is not required that the size of a string is necessar ily its length. Third, the probability distribution is polynomial time computable (P-time). The notion of P-time distributions was introduced in [Le1] and analyzed to some extent in <ref> [Gu1] </ref>. The requirement that the distribution is P-time will be discussed and relaxed in Section 6. Meantime, view is as some technical restriction that is often satisfied in practice. Consider a function T from a domain D to the interval [0::1] of the real line extended with 1. <p> The "official" definition requires a slightly weaker condi tion. 3 Definition 2.1. A function T from a do-main D to [0::1] is polynomial on average (in short, AP) if (2.3) (9" &gt; 0) E (T " =jxj) &lt; 1. Theorem 2.1 <ref> [Gu1] </ref>. Conditions (2.2) and (2.3) are equivalent if there exists an integer k such that Pfx : jxj = ng &gt; n k for all sufficiently large n with Pfx : jxj = ng &gt; 0. A more extensive discussion of the issue of AP functions can be found in [Gu1] <p> <ref> [Gu1] </ref>. Conditions (2.2) and (2.3) are equivalent if there exists an integer k such that Pfx : jxj = ng &gt; n k for all sufficiently large n with Pfx : jxj = ng &gt; 0. A more extensive discussion of the issue of AP functions can be found in [Gu1] and [BCGL]. We will return to that issue in Section 7. 3. A new setting A randomized NP decision or search problem may be specified by a triple (D; W; R) where D, W and R are as above (in Section 1) except that D is a domain now. <p> Theorem 4.1 [Gu3]. Matrix Decomposition is RNP complete. The prove of RNP hardness consists of the following steps. First, a randomized version of the (bounded) halting problem is proved complete for RNP. This result is implicit in [Le1] and explicit in <ref> [Gu1] </ref>. Second, the randomized halting problem is reduced to a randomized version of the (bounded) Post Correspondence Problem [Gu1]. Third, the randomized PCP is reduced to Matrix Decomposition [Gu3]. A simpler version of Matrix Decomposition is obtained by making S a sequence of matrices rather than linear operators. <p> First, a randomized version of the (bounded) halting problem is proved complete for RNP. This result is implicit in [Le1] and explicit in <ref> [Gu1] </ref>. Second, the randomized halting problem is reduced to a randomized version of the (bounded) Post Correspondence Problem [Gu1]. Third, the randomized PCP is reduced to Matrix Decomposition [Gu3]. A simpler version of Matrix Decomposition is obtained by making S a sequence of matrices rather than linear operators. The question becomes whether A can be represented as a product of at most n S-matrices. <p> Lemma 5.1 <ref> [Gu1] </ref>. If an RNP decision problem on a flat domain is complete for RNP then deterministic exponential time DTime (exp (n O (1) ) equals nondeterministic exponential time NTime (exp (n O (1) ). Proof Sketch. <p> It may seem that there is no sense in using fully correct randomizing reductions. Such a reduction can be made deterministic by pretending that all coins come up heads. This may ruin the domination requirement however. Fully correct reductions may be employed to overcome the phenomenon of flatness <ref> [Gu1, Gu3] </ref>. It is much more fruitful though to allow partially correct reductions [VL, BCGL, IL].
Reference: [Gu2] <author> Y. Gurevich, </author> <title> "The Challenger--Solver game: Variations on the Theme of P=?NP", </title> <journal> Bulletin of Eu-ropean Assoc. for Theor. Computer Science, </journal> <month> October </month> <year> 1989, </year> <pages> 112-121. </pages>
Reference-contexts: A purer mathematician may be unmoved. The question was asked. The challenge was posed. Now is the time to solve the question rather than to try to get around it. In <ref> [Gu2] </ref>, the P=?NP question was criticized for a bias toward the positive solution and an alternative question RAP=?RNP, the counterpart of the P=?NP question in the average-case approach, was advertized. In that connection, the following game between Challenger and Solver was considered. <p> Furthermore, Challenger's generating process may be altered in such a way that the expectation E (T C ) of Challenger's time for generating one instance is bounded D <ref> [Gu2] </ref>. Then the expected time for generating independently k instances is fi (k) and therefore (recall the remark that M (T ) 2E (T ) in Section 7) the median M (T C ; k) of Challenger's time needed to produce k instances is fi (k).
Reference: [Gu3] <author> Yuri Gurevich, </author> <title> "Matrix Decomposition Problem is Complete for the Average Case", </title> <booktitle> Symposium on Foundations of Computer Science, </booktitle> <publisher> IEEE Computer Society Press, </publisher> <year> 1990, </year> <pages> 802-811. </pages> <note> A full version of this paper, coauthored by Blass and Gurevich, is being prepared for publication. </note>
Reference-contexts: The corresponding question is if there a product P = T 1 fi : : : fi T m of m n linear operators T i 2 S such that A = P (1). Theorem 4.1 <ref> [Gu3] </ref>. Matrix Decomposition is RNP complete. The prove of RNP hardness consists of the following steps. First, a randomized version of the (bounded) halting problem is proved complete for RNP. This result is implicit in [Le1] and explicit in [Gu1]. <p> This result is implicit in [Le1] and explicit in [Gu1]. Second, the randomized halting problem is reduced to a randomized version of the (bounded) Post Correspondence Problem [Gu1]. Third, the randomized PCP is reduced to Matrix Decomposition <ref> [Gu3] </ref>. A simpler version of Matrix Decomposition is obtained by making S a sequence of matrices rather than linear operators. The question becomes whether A can be represented as a product of at most n S-matrices. <p> It may seem that there is no sense in using fully correct randomizing reductions. Such a reduction can be made deterministic by pretending that all coins come up heads. This may ruin the domination requirement however. Fully correct reductions may be employed to overcome the phenomenon of flatness <ref> [Gu1, Gu3] </ref>. It is much more fruitful though to allow partially correct reductions [VL, BCGL, IL].
Reference: [GS] <author> Yuri Gurevich and Saharon Shelah, </author> <title> "Expected computation time for Hamiltonian Path Problem", </title> <journal> SIAM J. on Computing 16:3 (1987), </journal> <pages> 486-502. </pages>
Reference-contexts: There is an algorithm A that solves the hamiltonian search problem with any fixed edge-probability distribution and that has an expected running time linear in the number of vertices <ref> [GS] </ref>. You may want to use that algorithm and open a hamiltonian shop. There may even be several such factories in your area. A customer will bring you a graph G with some number n of vertices.
Reference: [Ha] <author> Johan Hastad, </author> <title> "Pseudo-Random Generators under Uniform Functions", </title> <booktitle> Symposium on Theory of Computing, ACM, </booktitle> <year> 1990, </year> <pages> 395-404. </pages>
Reference-contexts: It is easy to see that RAP6=RNP if there exists a one-way function. It is not known whether the converse is true. The converse fails under some oracle [IR], but the question is open and very exciting. The existence of one-way functions allows cryptography in a meaningful sense <ref> [ILL, Ha] </ref>. If the existence of one-way functions follows from RAP6=RNP then the question RAP=?RNP is beautifully balanced. Either all RNP problems are easy on average or else there are problems that are hard on average but then they can be used to do cryptography. Acknowledgement.
Reference: [IR] <author> Russel Impagliazzo and Stephen Rudich, </author> <title> private communication. </title>
Reference-contexts: It is easy to see that RAP6=RNP if there exists a one-way function. It is not known whether the converse is true. The converse fails under some oracle <ref> [IR] </ref>, but the question is open and very exciting. The existence of one-way functions allows cryptography in a meaningful sense [ILL, Ha]. If the existence of one-way functions follows from RAP6=RNP then the question RAP=?RNP is beautifully balanced.
Reference: [IL] <author> Russel Impagliazzo and Leonid A. Levin, </author> <title> "No Better Ways to Generate Hard NP Instances than Picking Uniformly at Random", </title> <booktitle> Symposium on Foundations of Computer Science, </booktitle> <publisher> IEEE Computer Society Press, </publisher> <year> 1990, </year> <pages> 812-821. </pages>
Reference-contexts: Such a reduction can be made deterministic by pretending that all coins come up heads. This may ruin the domination requirement however. Fully correct reductions may be employed to overcome the phenomenon of flatness [Gu1, Gu3]. It is much more fruitful though to allow partially correct reductions <ref> [VL, BCGL, IL] </ref>. <p> Repeating a randomizing reduction k times results in k outputs in the target domain, not one as in the definition of reduction. In other words, such a repetition is a version of Turing (or truth-table) reduction, not a many-one reduction. At this point, we refer the reader to papers <ref> [VL, BCGL, IL] </ref> where partially correct reductions were successfully employed. It is our impression that the notion of reductions of RNP problems requires a little additional cleaning work. <p> Fortunately, Impagliazzo and Levin were able to prove the following theorem. Theorem 6.1 <ref> [IL] </ref>. Every NP search problem with a P-samplable distribution reduces to an NP search problem with the uniform distribution. Redefine the notion of domains by relaxing the requirement that the probability distribution is P-time and requiring only that it is P-samplable.
Reference: [ILL] <author> Russel Impagliazzo, Leonid A. Levin and Michael Luby, </author> <title> "PseudoRandom Generation from One-Way Functions", </title> <booktitle> 21st Symposium on Theory of Computing, ACM, </booktitle> <address> New York, </address> <year> 1989, </year> <pages> 12-24. </pages>
Reference-contexts: It is easy to see that RAP6=RNP if there exists a one-way function. It is not known whether the converse is true. The converse fails under some oracle [IR], but the question is open and very exciting. The existence of one-way functions allows cryptography in a meaningful sense <ref> [ILL, Ha] </ref>. If the existence of one-way functions follows from RAP6=RNP then the question RAP=?RNP is beautifully balanced. Either all RNP problems are easy on average or else there are problems that are hard on average but then they can be used to do cryptography. Acknowledgement.
Reference: [Jo] <author> David S. Johnson, </author> <title> "The NP-- Completeness Column", </title> <booktitle> Journal of Algorithms 5 (1984), </booktitle> <pages> 284-299. </pages>
Reference: [Kn] <author> P.M.W. Knijnenburg, </author> <title> "On Randomizing Decision Problems: A Survey of the Theory of Randomized NP", </title> <type> Tech. Report RUU-CS-88-15, </type> <address> Rijksuniversitait Utrecht, The Netherlands, </address> <month> March </month> <year> 1988. </year>
Reference-contexts: Leonid Levin proposed one average case approach in [Le1]. His approach is the topic of this talk. We hope this account is entertaining. It certainly isn't complete. The references include three student papers: [Gr], <ref> [Kn] </ref> and [Sc]. 2. Polynomial on average In the average case approach, a decision or search problem is supposed to be given together with a probability distribution on instances. A problem with a probability distribution on instances is called randomized (or distributional [BCGL]).
Reference: [Le1] <author> Leonid A. Levin, </author> <title> "Average Case Complete Problems", </title> <note> STOC 1984, the final version in SIAM Journal of Computing, </note> <year> 1986. </year>
Reference-contexts: In the case of a decision or search problem, one may have a decision or search algorithm that is usually fast or almost always fast or fast on average. Leonid Levin proposed one average case approach in <ref> [Le1] </ref>. His approach is the topic of this talk. We hope this account is entertaining. It certainly isn't complete. The references include three student papers: [Gr], [Kn] and [Sc]. 2. <p> Second, there are only finitely many elements of positive probability and any given size. It is not required that the size of a string is necessar ily its length. Third, the probability distribution is polynomial time computable (P-time). The notion of P-time distributions was introduced in <ref> [Le1] </ref> and analyzed to some extent in [Gu1]. The requirement that the distribution is P-time will be discussed and relaxed in Section 6. Meantime, view is as some technical restriction that is often satisfied in practice. <p> RSP (D 2 ; W; R)) is so. Corollary 3.2 witnesses a certain robustness of the average case approach. Leonid Levin proved that a randomized version of the (bounded) tiling problem is complete for RNP <ref> [Le1] </ref>. Some additional problems complete for RNP with respect to reductions as defined above were given in [Gu1,Gu2]; in the next section, we describe one of them. 4. <p> Theorem 4.1 [Gu3]. Matrix Decomposition is RNP complete. The prove of RNP hardness consists of the following steps. First, a randomized version of the (bounded) halting problem is proved complete for RNP. This result is implicit in <ref> [Le1] </ref> and explicit in [Gu1]. Second, the randomized halting problem is reduced to a randomized version of the (bounded) Post Correspondence Problem [Gu1]. Third, the randomized PCP is reduced to Matrix Decomposition [Gu3]. <p> For example, the uniform distributions is P-time. The restriction to P-time distributions was used by Levin to construct the first RNP complete problem <ref> [Le1] </ref>. This restriction turns out to be too strict. What distributions are likely to come up in applications? It is natural to assume that some randomizing algorithm is used to generate instances of a problem in question.
Reference: [Le2] <author> Leonid A. Levin, </author> <title> "One-Way Functions and Pseudo-Random Generators", </title> <booktitle> Symposium on Theory of Computing, ACM, </booktitle> <year> 1985, </year> <pages> 363-375. </pages>
Reference-contexts: Even a disinterested party may inadvertently mess things up. Certainly one would expect an adversary to mess things up. The following definition is implicitly in <ref> [Le2] </ref> and explicitly in [BCGL]. Definition 6.1. A distribution is P-samplable if it is generated by a coin-flipping Turing machine M (with no addi 9 tional input) such that the length of every terminating computation of M is bounded by a fixed polynomial of the output.
Reference: [LV] <author> Ming Li and Paul M. B. Vi-tani, </author> <title> "Average Case Complexity under the Universal Distribution Equals Worst Case Complexity", </title> <type> Manuscript, </type> <year> 1989. </year>
Reference-contexts: Li and Vitani notice that, in the case of the universal distribution, the average-case time complexity is "of the same order of magnitude as the corresponding worst-case complexity" <ref> [LV] </ref>. The idea is that, in particular, the universal distribution dominates the distribution that concentrates exclusively on the worst-case instances. In practice, of course, the generating algorithms satisfy severe resource bounds and the average-case complexity is often much lower than the worst-case complexity.
Reference: [Sc] <author> Robert E. Schapire, </author> <title> "The Emerging Theory of Average Case Complexity", </title> <type> Tech. Report MIT/LCS/TM-431, </type> <month> June </month> <year> 1990. </year>
Reference-contexts: Leonid Levin proposed one average case approach in [Le1]. His approach is the topic of this talk. We hope this account is entertaining. It certainly isn't complete. The references include three student papers: [Gr], [Kn] and <ref> [Sc] </ref>. 2. Polynomial on average In the average case approach, a decision or search problem is supposed to be given together with a probability distribution on instances. A problem with a probability distribution on instances is called randomized (or distributional [BCGL]).
Reference: [Tr] <author> Boris A. Trakhtenbrot, </author> <title> "A Survey of Russian Approaches to Perebor (Brute-Force Search) Algorithms", </title> <booktitle> Annals of the History of Computing, 6:4 (1984), </booktitle> <pages> 384-400. </pages>
Reference-contexts: The importance of the P=?NP question is related to the thesis identifying feasible and polynomial time computations, thesis (1.0) of Section 1. (There is a beautiful article of Trakhtenbrot on the original motivation for the P=?NP question <ref> [Tr] </ref>.) In this connection, a computer scientist, who isn't convinced that P captures feasibility, may question the centrality of the P=?NP question. A purer mathematician may be unmoved. The question was asked. The challenge was posed.
Reference: [VL] <author> Ramarathnam Venkatesan and Leonid Levin, </author> " <title> Random Instances of a Graph Coloring Problem are Hard", </title> <booktitle> Symposium on Theory of Computing, ACM, </booktitle> <year> 1988, </year> <pages> 217-222. </pages>
Reference-contexts: Using randomizing reductions, Levin and his student Ramarathnam Venkatesan constructed a natural randomized graph-coloring problem complete for RNP <ref> [VL] </ref>. Their paper demonstrates another reason, a very good one, for using randomizing reductions. Randomizing reductions allow us to use the structure of a random instance of the target problem (the one whose completeness one would like to prove). <p> Such a reduction can be made deterministic by pretending that all coins come up heads. This may ruin the domination requirement however. Fully correct reductions may be employed to overcome the phenomenon of flatness [Gu1, Gu3]. It is much more fruitful though to allow partially correct reductions <ref> [VL, BCGL, IL] </ref>. <p> Repeating a randomizing reduction k times results in k outputs in the target domain, not one as in the definition of reduction. In other words, such a repetition is a version of Turing (or truth-table) reduction, not a many-one reduction. At this point, we refer the reader to papers <ref> [VL, BCGL, IL] </ref> where partially correct reductions were successfully employed. It is our impression that the notion of reductions of RNP problems requires a little additional cleaning work.
Reference: [Ve] <author> Ramarathnam Venkatesan, </author> <title> private correspondence. </title>
Reference-contexts: The question becomes whether A can be represented as a product of at most n S-matrices. We doubt that the modified problem is complete for RNP, but the similar problem for larger matrices, like 20 fi 20 is complete <ref> [Ve] </ref>. 5. Revision 1: Randomized reductions The setting of Section 3 turns out to be too restrictive. Call a domain D flat if P (x) is bounded by 2 jxj " for some " &gt; 0. Intuitively, a flat domain is akin to a uniform one.
Reference: [Wi] <author> Herbert S. Wilf, </author> <title> Some Examples of Combinatorial Averaging, </title> <journal> American Math. </journal> <volume> Monthly 92 (1985), </volume> <pages> 250-261. </pages>
Reference-contexts: Consider for example the 3-coloring search problem when all graphs of the same size have the same probability. The usual backtracking solves this randomized search problem in (surprise!) at most 197 steps on average, never mind the size of the given instance <ref> [Wi] </ref>. The reason is that there are very simple and probable witnesses to non-colorability, like a clique of 4. The distribution is greatly biased toward the negative answer. The average time can be further cut down if the algorithm starts with a direct search for such witnesses.
References-found: 23

