URL: http://www-dbv.cs.uni-bonn.de/postscript/puzicha.imacs97.ps.gz
Refering-URL: 
Root-URL: 
Email: http://www-dbv.cs.uni-bonn.de, e-mail:fjan,th,jbg@cs.uni-bonn.de  
Title: Deterministic Annealing: Fast Physical Heuristics for RealTime Optimization of Large Systems  
Author: Jan Puzicha, Thomas Hofmann and Joachim M. Buhmann 
Keyword: Modelling and Applied Mathematics Keywords: Deterministic Annealing, Combinatorial Optimization, Stochastic Optimization  
Note: To appear in: Proceedings of the 15th IMACS World Conference on Scientific Computation,  
Address: Rheinische FriedrichWilhelmsUniversitat Bonn, Germany Romerstrae 164, D-53117 Bonn, Germany  
Affiliation: Institut fur Informatik III,  
Abstract: This paper systematically investigates the heuristical optimization technique known as deterministic annealing. This method is applicable to a large class of assignment and partitioning problems. Moreover, the established theoretical results, as well as the general algorithmic solution scheme, are largely independent of the objective functions under consideration. Deterministic annealing is derived from strict minimization principles, including a rigorous convergence analysis. We stress the close relation to homotopy methods, and discuss some of the most important strengths and weaknesses in this framework. Optimization results for unsupervised texture segmentation are presented for an autonomous robotics application. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E. Allgower and K. Georg. </author> <title> Numerical Continuation Methods, </title> <booktitle> volume 13 of Springer Series in Computational Mathematics. </booktitle> <publisher> Springer Verlag, </publisher> <year> 1990. </year>
Reference-contexts: Global optimality, however, has not been established yet even for carefully annealing. We present a rigorous mathematical analysis of DA, which culminates in establishing a close connection to homotopy and continuation techniques <ref> [1] </ref>. Like other homotopy methods, DA systematically varies the original objective function by introducing a non-negative parameter T , often called the computational temperature. <p> The canonical topologically equivalent probabilistic embedding is the space of factorial distributions Q F = i=1 ( N Y K X M i- q i; q i- 2 <ref> [0; 1] </ref> : (4) Note, that the choice of factorial distributions arises naturally, when considering solely algorithms with first order transitions between states. Q fl = (q fl i ) 2 Q F is called (strictly) onechange optimal w.r.t.
Reference: [2] <author> S. Geman and D. Geman. </author> <title> Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 6(6):721741, </volume> <year> 1984. </year>
Reference-contexts: Denote by M i!e the matrix obtained by replacing the ith row of M with the unit vector e and let g i (M) = H (M i!e - ). An efficient Monte Carlo algorithm is defined by the GibbsSampler <ref> [2] </ref>, which samples from the conditional probability distribution spanned by site x i for fixed assignments of sites x j ; j 6= i: P (M i!e - jM) = T g i P T g i DETERMINISTIC ANNEALING Formally, denote by P M = P the space of probability distri
Reference: [3] <author> S. Gold and A. Rangarajan. </author> <title> A graduated assignment algorithm for graph matching. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 18(4):377388, </volume> <year> 1996. </year>
Reference-contexts: Second, if such a path exists, it is not a priori guaranteed that the minimum reached at T = 0 corresponds to a global minimum of the original cost function. In the past, DA equations have been derived separately for many different cost function (c.f. <ref> [6, 3, 4] </ref> and the references therein). Here, we consider the rather general class of combinatorial optimization problems, where a set of N objects or sites has to be partitioned into K groups.
Reference: [4] <author> T. Hofmann and J. Buhmann. </author> <title> Pairwise data clustering by deterministic annealing. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 19(1), </volume> <year> 1997. </year>
Reference-contexts: DA is applicable to nonlinear cost functions and yields efficient algorithms which possess a favorable scaling behavior in terms of computational complexity. DA has empirically shown to compute optimal or nearoptimal solutions <ref> [6, 4, 7] </ref>, which makes it a promising optimization heuristic for large problem instances. Global optimality, however, has not been established yet even for carefully annealing. We present a rigorous mathematical analysis of DA, which culminates in establishing a close connection to homotopy and continuation techniques [1]. <p> Second, if such a path exists, it is not a priori guaranteed that the minimum reached at T = 0 corresponds to a global minimum of the original cost function. In the past, DA equations have been derived separately for many different cost function (c.f. <ref> [6, 3, 4] </ref> and the references therein). Here, we consider the rather general class of combinatorial optimization problems, where a set of N objects or sites has to be partitioned into K groups.
Reference: [5] <author> T. Hofmann, J. Puzicha, and J. Buhmann. </author> <title> A deterministic annealing framework for textured image segmentation. </title> <type> Technical Report IAI-TR-96-2, </type> <institution> Institut fur Informatik III, Universitat Bonn, </institution> <year> 1996. </year>
Reference-contexts: They correspond to symmetric superpositions of different local minima of H and are avoided by adding noise during the annealing process. Some important properties of factorial distributions are summarized in the following Proposition, the proof of which can be found in <ref> [5] </ref>. Proposition 3 Let H 0 (M) = P N P K -=1 M i-h i- be a linear cost function. Denote by Q H 0 = exp 1 =Z the associated Gibbs distribution. 1. Q H 0 is factorial. <p> UNSUPERVISED TEXTURE SEGMENTATION As an example for optimizing a large system we present results from our recent approach to unsupervised texture segmentation <ref> [5] </ref>. It is based on the modulus applied to a Gabor filter representation. For each site the empirical distribution of coefficients in a surrounding (Gaborchannel specific) window is determined. <p> Note that H (M) defines a nonquadratic graph partitioning problem. The cost function has been motivated by invariance to linear transformation of the dissimilarity matrix and yields superior results compared to the standard quadratic graph partitioning cost function <ref> [5] </ref>. The meanfield equations are obtained starting from h i= hHi Q old hHi Q old (Proposition 3) and exchanging mean and quotient operations. For the details we refer the reader to [5]. <p> transformation of the dissimilarity matrix and yields superior results compared to the standard quadratic graph partitioning cost function <ref> [5] </ref>. The meanfield equations are obtained starting from h i= hHi Q old hHi Q old (Proposition 3) and exchanging mean and quotient operations. For the details we refer the reader to [5]. For the image analysis task the topological structure of the optimization variables is exploited to combine the basic corrector step from Theorem 2 with a multigrid inspired coursetofine technique to achieve highly efficient optimization methods capable of the realtime demands in autonomous robotic applications.
Reference: [6] <author> C. Peterson and B. Soderberg. </author> <title> A new method for mapping optimization problems onto neural networks. </title> <journal> International Journal of Neural Systems, </journal> <volume> 1(1):322, </volume> <year> 1989. </year>
Reference-contexts: DA is applicable to nonlinear cost functions and yields efficient algorithms which possess a favorable scaling behavior in terms of computational complexity. DA has empirically shown to compute optimal or nearoptimal solutions <ref> [6, 4, 7] </ref>, which makes it a promising optimization heuristic for large problem instances. Global optimality, however, has not been established yet even for carefully annealing. We present a rigorous mathematical analysis of DA, which culminates in establishing a close connection to homotopy and continuation techniques [1]. <p> Second, if such a path exists, it is not a priori guaranteed that the minimum reached at T = 0 corresponds to a global minimum of the original cost function. In the past, DA equations have been derived separately for many different cost function (c.f. <ref> [6, 3, 4] </ref> and the references therein). Here, we consider the rather general class of combinatorial optimization problems, where a set of N objects or sites has to be partitioned into K groups.

References-found: 6

