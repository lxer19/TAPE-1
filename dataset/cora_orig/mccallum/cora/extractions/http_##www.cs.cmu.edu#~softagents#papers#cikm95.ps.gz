URL: http://www.cs.cmu.edu/~softagents/papers/cikm95.ps.gz
Refering-URL: http://www.cs.cmu.edu/~softagents/publications_old.html
Root-URL: 
Email: (decker,sycara,zeng+)@cs.cmu.edu  
Title: Designing a Multi-Agent Portfolio Management System  
Author: Keith Decker, Katia Sycara, and Dajun Zeng 
Address: 5000 Forbes Ave, Pittsburgh, PA 15213  
Affiliation: The Robotics Institute, Carnegie Mellon University  
Abstract: The voluminous and readily available information on the Internet has given rise to exploration of Intelligent Agent technology for accessing, filtering, evaluating and integrating information. In contrast to most current research that has investigated single-agent approaches, we are developing a collection of multiple agents that team up on demand, depending on the user, the task and the situation, to access, filter and integrate information in support of user tasks. We are investigating techniques for developing distributed adaptive collections of information agents that coordinate to retrieve, filter and fuse information relevant to the user, task and situation, as well as anticipate user's information needs. Our approach is based on (1) case-based task and situation models, (2) flexible organizational structuring, and (3) reusable agent architecture. We are currently implementing the system in the domain of financial portfolio management. While this paper focuses on the big picture, the final section will describe the current implementation and point to our work on detailed technical solutions. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Arens, Y.; Chee, C. Y.; Hsu, C.-N.; and Knoblock, C. A. </author> <year> 1993. </year> <title> Retrieving and integrating data from multiple infor mation sources. </title> <journal> International Journal of Intelligent and Coop--erative Information Systems 2(2) </journal> <pages> 127-58. </pages>
Reference: <author> Collet, C.; Huhns, M.; and Shen, W. </author> <year> 1991. </year> <title> Resource integration using a large knowledge base in Carnot. </title> <publisher> Computer. </publisher>
Reference: <author> Decker, K. S., and Lesser, V. R. </author> <year> 1995. </year> <title> Designing a family of coordination algorithms. </title> <booktitle> In Proceedings of the First International Conference on Multi-Agent Systems, </booktitle> <pages> 73-80. </pages> <address> San Francisco: </address> <note> AAAI Press. Longer version available as UMass CS-TR 94-14. </note>
Reference-contexts: In the event of a failure, a non specialist would still be able to retrieve useful plans for a task inside its area of expertise, but outside of its specialty. The Portfolio Monitoring Task We can represent the plans that are retrieved using TMS task structures <ref> (Decker 1995) </ref>. TMS task structures are based on abstraction hierarchies, where task plans are elaborated via a subtask relationship into acyclic directed graphs that have actions, called executable methods, at their leaves. <p> This part of the data, if transmitted to the earnings analysis agent, can somewhat speed up (i.e., facilitate) the process of gathering earnings expectations. We have demonstrated the use of general coordination mechanisms, called the GPGP (Generalized Partial Global Planning) approach, that can easily coordinate such task structure interactions <ref> (Decker & Lesser 1995) </ref>. In this instance, the soft-predecessor-coordination-relationship mechanism will cause the analyst tracking agent to commit to the transmission of a completed analyst report form to the earnings analysis agent, which can then easily extract the portion dealing with the updated earnings estimate. <p> The execution monitor takes care of actually executing the next desired action (perhaps including pre-emption of the action in true real-time execution). Previous work has focussed on the design of the coordinator and the local scheduler <ref> (Decker & Lesser 1995) </ref>. Details of the implementation of these components can be found in the cited papers. We have extended this work to include more sophisticated execution monitoring, using such techniques as the TCA (Task Control Architecture) approach (Simmons 1994). <p> Architecturally, we have developed several versions of the basic agent internals described here. Currently, all of our agent classes (information, task, and interface agnets) are based on this shared architecture. Although the local scheduler is considerably simpler than the one described in <ref> (Decker & Lesser 1995) </ref>, the decision-theoretic hierarchical task network planner is more complex and capable (Williamson, Decker, & Sycara 1996).
Reference: <author> Decker, K.; Williamson, M.; and Sycara, K. </author> <year> 1996. </year> <title> Intelligent adaptive information agents. </title> <booktitle> In Proceedings of the AAAI-96 Workshop on Intelligent Adaptive Agents. </booktitle>
Reference-contexts: Information agents are described in more detail in <ref> (Decker, Williamson, & Sycara 1996) </ref>. The Portfolio Management Domain To evaluate our domain independent agent control, organization, coordination and architectural schemes, we have chosen financial portfolio management as a task domain. <p> Such structures are compatible with most planning representations, and provide the necessary information both for scheduling activities that arise from multiple plans, and for coordinating the activities of multiple agents. We have in fact constructed a decision-theoretic hierarchical task network planner using extensions of this representation framework <ref> (Williamson, Decker, & Sycara 1996) </ref>. The extensions include the ability to represent and reason about periodic tasks. <p> Recently we have developed broker-ing agents that act as central points of contact for certain types of services (centralized markets). A hybrid organizational approach allows the use of both subforms, i.e., the use of a matchmaker in order to find an appropriate broker. More details can be found in <ref> (Decker, Williamson, & Sycara 1996) </ref>. Architecturally, we have developed several versions of the basic agent internals described here. Currently, all of our agent classes (information, task, and interface agnets) are based on this shared architecture. <p> Currently, all of our agent classes (information, task, and interface agnets) are based on this shared architecture. Although the local scheduler is considerably simpler than the one described in (Decker & Lesser 1995), the decision-theoretic hierarchical task network planner is more complex and capable <ref> (Williamson, Decker, & Sycara 1996) </ref>.
Reference: <author> Decker, K. S. </author> <year> 1995. </year> <title> Environment Centered Analysis and Design of Coordination Mechanisms. </title> <type> Ph.D. Dissertation, </type> <institution> University of Massachusetts. </institution>
Reference-contexts: In the event of a failure, a non specialist would still be able to retrieve useful plans for a task inside its area of expertise, but outside of its specialty. The Portfolio Monitoring Task We can represent the plans that are retrieved using TMS task structures <ref> (Decker 1995) </ref>. TMS task structures are based on abstraction hierarchies, where task plans are elaborated via a subtask relationship into acyclic directed graphs that have actions, called executable methods, at their leaves. <p> This part of the data, if transmitted to the earnings analysis agent, can somewhat speed up (i.e., facilitate) the process of gathering earnings expectations. We have demonstrated the use of general coordination mechanisms, called the GPGP (Generalized Partial Global Planning) approach, that can easily coordinate such task structure interactions <ref> (Decker & Lesser 1995) </ref>. In this instance, the soft-predecessor-coordination-relationship mechanism will cause the analyst tracking agent to commit to the transmission of a completed analyst report form to the earnings analysis agent, which can then easily extract the portion dealing with the updated earnings estimate. <p> The execution monitor takes care of actually executing the next desired action (perhaps including pre-emption of the action in true real-time execution). Previous work has focussed on the design of the coordinator and the local scheduler <ref> (Decker & Lesser 1995) </ref>. Details of the implementation of these components can be found in the cited papers. We have extended this work to include more sophisticated execution monitoring, using such techniques as the TCA (Task Control Architecture) approach (Simmons 1994). <p> Architecturally, we have developed several versions of the basic agent internals described here. Currently, all of our agent classes (information, task, and interface agnets) are based on this shared architecture. Although the local scheduler is considerably simpler than the one described in <ref> (Decker & Lesser 1995) </ref>, the decision-theoretic hierarchical task network planner is more complex and capable (Williamson, Decker, & Sycara 1996).
Reference: <author> Etzioni, O., and Weld, D. </author> <year> 1994. </year> <title> A softbot-based interface to the internet. </title> <journal> Communications of the ACM 37(7). </journal>
Reference: <author> Joh, G., and Lee, C. </author> <year> 1992. </year> <title> Stock price response to accounting information in oligopoly. </title> <journal> Journal of Business 65(3) </journal> <pages> 451-472. </pages>
Reference-contexts: For example, a change in the portion of earnings attributed to sales is often applicable to all companies in a group, unlike changes to costs (sales minus earnings) <ref> (Joh & Lee 1992) </ref>. The analyst tracking agent gathers, from news and other sources, existing and updated analyst reports on a company, including revised earnings estimates (often part of a larger report).
Reference: <author> Kambhampati, S., and Hendler, J. A. </author> <year> 1992. </year> <title> A validation-structure-based theory of plan modification and reuse. </title> <journal> Artificial Intelligence 55(2-3):193-258. </journal>
Reference: <author> Kuokka, D., and Harada, L. </author> <year> 1995. </year> <title> On using KQML for matchmaking. </title> <booktitle> In Proceedings of the First International Conference on Multi-Agent Systems, </booktitle> <pages> 239-245. </pages> <address> San Francisco: </address> <publisher> AAAI Press. </publisher>
Reference: <author> Maes, P. </author> <year> 1994. </year> <title> Agents that reduce work and information overload. </title> <journal> Communications of the ACM 37(7). </journal>
Reference: <author> Markowitz, H. </author> <year> 1991. </year> <title> Portfolio selection: efficient diversification of investments. </title> <address> Cambridge, MA: </address> <publisher> B. </publisher> <address> Blackwell, </address> <note> second edition edition. </note>
Reference-contexts: The overall task in the portfolio management domain, as stated by modern portfolio theory <ref> (Markowitz 1991) </ref>, is to provide the best possible rate of return for a specified level of risk, or conversely, to achieve a specified rate of return with the lowest possible risk Risk tolerance is one of the features that characterize the user of our system; other features include the user's investment
Reference: <author> Michalski, R., and Tecuci, G. </author> <year> 1994. </year> <title> Machine Learning: A multistrategy Approach, </title> <booktitle> volume IV. </booktitle> <publisher> Morgan Kaufmann Publishers. </publisher>
Reference-contexts: In addition, there are a number of learning-related research issues we want to explore. How do we formulate the learning task in the context of multi agent interactions where procedural and control knowledge must be learned? Concept learning has been the focus of most machine learning research (e.g., <ref> (Michalski & Tecuci 1994) </ref>). Learning of control knowledge has been explored using case-based reasoning (e.g., (Kambhampati & Hendler 1992; Miyashita & Sycara 1995)), and reinforcement type learning techniques (e.g., (Sutton 1988)). This research has been conducted almost exclusively in a single agent setting.
Reference: <author> Miyashita, K., and Sycara, K. </author> <year> 1995. </year> <title> Cabins: A framework of knowledge acquisition and iterative revision for schedule improvement and reactive repair. </title> <journal> Artificial Intelligence 76(1-2). </journal>
Reference-contexts: After each information gathering cycle the case base is updated. Thus, learning is integrated with problem solving and is achieved automatically. This feature makes Case-Based reasoning very preferable in application domains with open and dynamically changing world model <ref> (Sycara, Zeng, & Miyashita 1995) </ref>. Case based reasoning offers three general advantages. First, since it relies on reusing specific experiences rather than reasoning from a general world model, it provides for more efficient planning.
Reference: <author> Oates, T.; Prasad, M. V. N.; Lesser, V. R.; and Decker, K. S. </author> <year> 1995. </year> <title> A distributed problem solving approach to cooperative information gathering. </title> <booktitle> In AAAI Spring Symposium on Information Gathering in Distributed Environments. </booktitle>
Reference-contexts: Agent Architecture The portfolio manager and task assistant agents have an internal agent structure called DECAF (Distributed, Environment-Centered Agent Framework)a general, reusable, core agent control architecture <ref> (Oates et al. 1995) </ref>. The term architecture here refers to the internal control structure of a single agent, as opposed to the term organization that refers to the control and communication structure of a group of agents.
Reference: <author> Simmons, R. </author> <year> 1994. </year> <title> Structured control for autonomous robots. </title> <journal> IEEE Trans. on Robotics and Automation 10(1). </journal>
Reference-contexts: Details of the implementation of these components can be found in the cited papers. We have extended this work to include more sophisticated execution monitoring, using such techniques as the TCA (Task Control Architecture) approach <ref> (Simmons 1994) </ref>. Current Status We have already built a large part of the underlying basic organizations and achitecture as described here.
Reference: <author> Sutton, R. S. </author> <year> 1988. </year> <title> Learning to predict by the methods of temporal differences. </title> <booktitle> Machine Learning 3 </booktitle> <pages> 9-44. </pages>
Reference-contexts: Learning of control knowledge has been explored using case-based reasoning (e.g., (Kambhampati & Hendler 1992; Miyashita & Sycara 1995)), and reinforcement type learning techniques (e.g., <ref> (Sutton 1988) </ref>). This research has been conducted almost exclusively in a single agent setting. We want to explore strategies for multiple agent learning of control knowledge during agent interactions.
Reference: <author> Sycara, K., and Zeng, D. </author> <year> 1995. </year> <title> Task-based multi-agent coordination for information gathering. </title> <editor> In Knoblock, C., and Levy, A., eds., </editor> <booktitle> Working Notes of the AAAI Spring Symposium Series on Information Gathering from Distributed, Heterogeneous Environments. </booktitle> <address> Stanford, CA: </address> <publisher> AAAI. </publisher>
Reference-contexts: They acquire, model, and utilize user preferences to guide system coordination in support of the user's tasks. This work is a continuation of our previous work on multi agent information access, filtering and integration of everyday organizational tasks <ref> (Sycara & Zeng 1995) </ref>. Of the three types of agents, information agents are the most well-defined. <p> After each information gathering cycle the case base is updated. Thus, learning is integrated with problem solving and is achieved automatically. This feature makes Case-Based reasoning very preferable in application domains with open and dynamically changing world model <ref> (Sycara, Zeng, & Miyashita 1995) </ref>. Case based reasoning offers three general advantages. First, since it relies on reusing specific experiences rather than reasoning from a general world model, it provides for more efficient planning. <p> Information that is important for decision-making (and thus might cause an eventual change in organizational structuring) is monitored at the lowest levels of the organization and passed upward when necessary. In this type of organization (see Figure 1), task agents or task assistants <ref> (Sycara & Zeng 1995) </ref> continually interleave planning, scheduling, coordination, and the execution of domain-level problem-solving actions. Task agents interact with one another and with information agents or information assistants that encapsulate network information sources. Task agents retrieve, coordinate, and schedule plans based on local knowledge modulated by situational context.
Reference: <author> Sycara, K.; Zeng, D.; and Miyashita, K. </author> <year> 1995. </year> <title> Using case-based reasoning to acquire user scheduling preferences that change over time. </title> <booktitle> In The Proceedings of the Eleventh IEEE Conference on Artificial Intelligence Applications (CAIA '95). </booktitle> <address> Los Angeles: </address> <publisher> IEEE. </publisher>
Reference-contexts: They acquire, model, and utilize user preferences to guide system coordination in support of the user's tasks. This work is a continuation of our previous work on multi agent information access, filtering and integration of everyday organizational tasks <ref> (Sycara & Zeng 1995) </ref>. Of the three types of agents, information agents are the most well-defined. <p> After each information gathering cycle the case base is updated. Thus, learning is integrated with problem solving and is achieved automatically. This feature makes Case-Based reasoning very preferable in application domains with open and dynamically changing world model <ref> (Sycara, Zeng, & Miyashita 1995) </ref>. Case based reasoning offers three general advantages. First, since it relies on reusing specific experiences rather than reasoning from a general world model, it provides for more efficient planning. <p> Information that is important for decision-making (and thus might cause an eventual change in organizational structuring) is monitored at the lowest levels of the organization and passed upward when necessary. In this type of organization (see Figure 1), task agents or task assistants <ref> (Sycara & Zeng 1995) </ref> continually interleave planning, scheduling, coordination, and the execution of domain-level problem-solving actions. Task agents interact with one another and with information agents or information assistants that encapsulate network information sources. Task agents retrieve, coordinate, and schedule plans based on local knowledge modulated by situational context.
Reference: <author> Sycara, K. </author> <year> 1989. </year> <title> Multi-agent compromise via negotiation. </title>
Reference-contexts: Finally, a multi-agent system provides a natural mapping of multiple types of expertise to be brought to bear during any portfolio management decision-making. Existing DAI techniques for resolving conflicting opinions, negotiation, and argumentation can be brought to bear on these problems <ref> (Sycara 1989) </ref>. The overall portfolio management task has several component tasks. These include eliciting (or learning) user profile information, collecting information on the user's initial portfolio position, and suggesting and monitoring a re-allocation to meet the user's current profile and goals.
Reference: <editor> In Huhns, M., and Gasser, L., eds., </editor> <booktitle> Distributed Artificial Intelligence, </booktitle> <volume> volume Volume 2. </volume> <pages> Pittman. </pages>
Reference: <author> Trippi, R., and Turban, E., eds. </author> <year> 1990. </year> <title> Investment management: decision support and expert systems. </title> <address> New York: </address> <publisher> Van Nostrand Reinhold. </publisher>
Reference-contexts: In current practice, portfolio management is carried out by investment houses that employ teams of specialists for finding, filtering and evaluating relevant information. Current practice as well as software engineering considerations motivate our multi agent system architecture. Previous work in the portfolio management domain (see <ref> (Trippi & Turban 1990) </ref> for one collection) has focused on the portfolio selection process (i.e., stock picking) as opposed to portfolio monitoringthe ongoing, continuous, daily provision of an up-to-date financial picture of an existing portfolio.
Reference: <author> Williamson, M.; Decker, K.; and Sycara, K. </author> <year> 1996. </year> <title> Unified information and control flow in hierarchical task networks. </title> <booktitle> In Proceedings of the AAAI-96 workshop on Theories of Planning, Action, and Control. </booktitle>
Reference-contexts: Information agents are described in more detail in <ref> (Decker, Williamson, & Sycara 1996) </ref>. The Portfolio Management Domain To evaluate our domain independent agent control, organization, coordination and architectural schemes, we have chosen financial portfolio management as a task domain. <p> Such structures are compatible with most planning representations, and provide the necessary information both for scheduling activities that arise from multiple plans, and for coordinating the activities of multiple agents. We have in fact constructed a decision-theoretic hierarchical task network planner using extensions of this representation framework <ref> (Williamson, Decker, & Sycara 1996) </ref>. The extensions include the ability to represent and reason about periodic tasks. <p> Recently we have developed broker-ing agents that act as central points of contact for certain types of services (centralized markets). A hybrid organizational approach allows the use of both subforms, i.e., the use of a matchmaker in order to find an appropriate broker. More details can be found in <ref> (Decker, Williamson, & Sycara 1996) </ref>. Architecturally, we have developed several versions of the basic agent internals described here. Currently, all of our agent classes (information, task, and interface agnets) are based on this shared architecture. <p> Currently, all of our agent classes (information, task, and interface agnets) are based on this shared architecture. Although the local scheduler is considerably simpler than the one described in (Decker & Lesser 1995), the decision-theoretic hierarchical task network planner is more complex and capable <ref> (Williamson, Decker, & Sycara 1996) </ref>.
References-found: 22

