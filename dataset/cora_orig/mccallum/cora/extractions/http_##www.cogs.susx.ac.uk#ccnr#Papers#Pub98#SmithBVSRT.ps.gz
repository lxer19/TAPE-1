URL: http://www.cogs.susx.ac.uk/ccnr/Papers/Pub98/SmithBVSRT.ps.gz
Refering-URL: http://www.cogs.susx.ac.uk/ccnr/Papers/pub98.html
Root-URL: http://www.cogs.susx.ac.uk/ccnr/Papers/pub98.html
Email: toms@cogs.susx.ac.uk  
Title: Blurred Vision: Simulation-Reality Transfer of a Visually Guided Robot people believe football is a matter
Author: Tom MC Smith Bill Shankly 
Note: "Some  
Address: Brighton BN1 9SB, UK  
Affiliation: Centre for Computational Neuroscience and Robotics School of Cognitive and Computing Sciences University of Sussex  
Abstract: This paper investigates the evolution of robot controllers utilising only visual environment input data, capable of performing a hard task, playing football, in the real world. The techniques of minimal simulation, where the robot controller is forced to ignore certain features through making those features unreliable, are used to construct a noisy simulated environment for a robot with an onboard vision system. Robot control structures evolved in this simulation are then transferred on to a real robot, where the behaviours shown in simulation are displayed in the real world. In the experiment presented, finding a tennis ball and pushing it towards a goal, good controllers capable of performing the same behaviours in simulation and in the real world, are evolved only once sufficient unreliability is incorporated into the simulation. The success in evolving in simulation a robot controller incorporating only distal visual environment input data and displaying the same behaviours in both simulation and the real world, goes some way to addressing the argument that evolution is suitable only for toy problems. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> D.T. Cliff, P. Husbands, and I. Harvey. </author> <title> Evolving visually guided robots. </title> <editor> In J.- A. Meyer, H. Roitblat, and S. Wilson, editors, </editor> <booktitle> Proceedings of the Second International Conference on Simulation of Adaptive Behaviour. </booktitle> <publisher> MIT Press/Bradford Books, </publisher> <year> 1993. </year>
Reference-contexts: 1 Introduction To operate well in the real world 1 , embodied agents must utilise long distance sensor information. The incorporation of such distal information, as opposed to local proximity detector information, e.g. infra-red, enables the utilisation of far more sophisticated strategies <ref> [1] </ref>. <p> Cliff et al <ref> [1] </ref> evolve controllers capable of finding the centre of a room in simulation, but again no evaluation of behaviour in the real world is described. Other approaches include the Sussex gantry robot, "partway between a physical mobile robot ... and simulation" [5].
Reference: 2. <author> D. Floreano and F. Mondada. </author> <title> Automatic creation of an autonomous agent: Genetic evolution of a neural-network driven robot. </title> <editor> In D. Cliff, P. Husbands, J. A. Meyer, and S. W. Wilson, editors, </editor> <booktitle> Animals to Animats 3: Proc. 3rd International Conference on Simulation of Adaptive Behaviour. </booktitle> <publisher> MIT Press/Bradford Books, </publisher> <year> 1994. </year>
Reference-contexts: Evolution in the real world suffers from the problem of the inordinate evaluation time required. With a large population evaluated over number of generations, the real time evolution cost can be prohibitively large. Floreano and Mondada <ref> [2] </ref> required 65 hours to evolve efficient collision-avoidance controllers, and ten days to evolve learning controllers to perform the same task [3].
Reference: 3. <author> D. Floreano and F. Mondada. </author> <title> Evolution of plastic neurocontrollers for situated agents. </title> <editor> In P. Maes, M. J. Mataric, J. A. Meyer, J. Pollack, and S. W. Wilson, editors, </editor> <booktitle> From Animals to Animats 4; Proc. 4th International Conference on Simulation of Adaptive Behaviour. </booktitle> <publisher> MIT Press/Bradford Books, </publisher> <year> 1996. </year>
Reference-contexts: With a large population evaluated over number of generations, the real time evolution cost can be prohibitively large. Floreano and Mondada [2] required 65 hours to evolve efficient collision-avoidance controllers, and ten days to evolve learning controllers to perform the same task <ref> [3] </ref>. By contrast, it is argued that simulation cannot realistically model the features required for robust operation in the real world; robots evolved in simulation may completely or partially fail in the real world the so-called "reality gap" [8].
Reference: 4. <author> D. Floreano and S. Nolfi. </author> <title> Adaptive behaviour in competing co-evolving species. </title> <editor> In P. Husbands and I. Harvey, editors, </editor> <booktitle> Fourth European Conference on Artificial Life. </booktitle> <publisher> MIT Press/Bradford Books, </publisher> <year> 1997. </year>
Reference-contexts: Finally, section 8 summarises the experimental results, with discussion in section 9. 2 Evolved Visual Controllers Previous research in evolving visually guided controllers has tended to concentrate on simulation, avoiding the difficulties inherent in using real world vision. Floreano and Mondada <ref> [4] </ref> investigate a predator-prey scenario using a simulation of the same Khepera robots and vision system used in this paper (see section 4 for a description).
Reference: 5. <author> I. Harvey, P. Husbands, D. T. Cliff, A. Thompson, and N. Jakobi. </author> <title> Evolutionary robotics: The Sussex approach. </title> <booktitle> Robotics and Autonomous Systems, </booktitle> <volume> 20 </volume> <pages> 205-224, </pages> <year> 1997. </year>
Reference-contexts: Cliff et al [1] evolve controllers capable of finding the centre of a room in simulation, but again no evaluation of behaviour in the real world is described. Other approaches include the Sussex gantry robot, "partway between a physical mobile robot ... and simulation" <ref> [5] </ref>. Jakobi [6, 7] has extended work by Har-vey et al [5], successfully evolving controllers in a minimal simulation, capable of distinguishing shapes even in "disco" lighting conditions. However, neither the image processing and sensorimotor control are performed onboard the gantry robot. <p> Other approaches include the Sussex gantry robot, "partway between a physical mobile robot ... and simulation" <ref> [5] </ref>. Jakobi [6, 7] has extended work by Har-vey et al [5], successfully evolving controllers in a minimal simulation, capable of distinguishing shapes even in "disco" lighting conditions. However, neither the image processing and sensorimotor control are performed onboard the gantry robot.
Reference: 6. <author> N. Jakobi. </author> <title> Evolutionary robotics and the radical envelope of noise hypothesis. </title> <journal> Journal of Adaptive Behaviour, </journal> <volume> 6, </volume> <year> 1997. </year>
Reference-contexts: The techniques of minimal simulation <ref> [6, 7] </ref> are used to construct a simulation for a robot sensorimotor control system incorporating only visual input data returned by an onboard camera. The experiment, a simplified version of football, requires the robot to find a bright ball in a dark arena and push it towards a striped goal. <p> Cliff et al [1] evolve controllers capable of finding the centre of a room in simulation, but again no evaluation of behaviour in the real world is described. Other approaches include the Sussex gantry robot, "partway between a physical mobile robot ... and simulation" [5]. Jakobi <ref> [6, 7] </ref> has extended work by Har-vey et al [5], successfully evolving controllers in a minimal simulation, capable of distinguishing shapes even in "disco" lighting conditions. However, neither the image processing and sensorimotor control are performed onboard the gantry robot. <p> Attempts to increase the simulation complexity merely result in expenditure of vast amounts of modelling and computing time [9]. Jakobi's Radical Envelope of Noise hypothesis <ref> [6, 7] </ref> outlines a new approach to the problems of evolution in simulation. The contrast is drawn between the base set aspects of the situation, those that may have some bearing on the robot behaviour, and the implementation aspects, those which must not be allowed to affect behaviour.
Reference: 7. <author> N. Jakobi. Half-baked, </author> <title> ad-hoc and noisy: Minimal simulations for evolutionary robotics. </title> <editor> In P. Husbands and I. Harvey, editors, </editor> <booktitle> Fourth European Conference on Artificial Life. </booktitle> <publisher> MIT Press/Bradford Books, </publisher> <year> 1997. </year>
Reference-contexts: The techniques of minimal simulation <ref> [6, 7] </ref> are used to construct a simulation for a robot sensorimotor control system incorporating only visual input data returned by an onboard camera. The experiment, a simplified version of football, requires the robot to find a bright ball in a dark arena and push it towards a striped goal. <p> Cliff et al [1] evolve controllers capable of finding the centre of a room in simulation, but again no evaluation of behaviour in the real world is described. Other approaches include the Sussex gantry robot, "partway between a physical mobile robot ... and simulation" [5]. Jakobi <ref> [6, 7] </ref> has extended work by Har-vey et al [5], successfully evolving controllers in a minimal simulation, capable of distinguishing shapes even in "disco" lighting conditions. However, neither the image processing and sensorimotor control are performed onboard the gantry robot. <p> Attempts to increase the simulation complexity merely result in expenditure of vast amounts of modelling and computing time [9]. Jakobi's Radical Envelope of Noise hypothesis <ref> [6, 7] </ref> outlines a new approach to the problems of evolution in simulation. The contrast is drawn between the base set aspects of the situation, those that may have some bearing on the robot behaviour, and the implementation aspects, those which must not be allowed to affect behaviour.
Reference: 8. <author> N. Jakobi, P. Husbands, and I. Harvey. </author> <title> Noise and the reality gap: The use of simulation in evolutionary robotics. </title> <editor> In F. Moran, A. Moreno, J. Merelo, and P. Chacon, editors, </editor> <booktitle> Advances in Artificial Life: Proc. 3rd European Conference on Artificial Life. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference-contexts: By contrast, it is argued that simulation cannot realistically model the features required for robust operation in the real world; robots evolved in simulation may completely or partially fail in the real world the so-called "reality gap" <ref> [8] </ref>. Attempts to increase the simulation complexity merely result in expenditure of vast amounts of modelling and computing time [9]. Jakobi's Radical Envelope of Noise hypothesis [6, 7] outlines a new approach to the problems of evolution in simulation.
Reference: 9. <author> M. J. Mataric and D. T. Cliff. </author> <title> Challenges in evolving controllers for physical robots. </title> <booktitle> Robotics and Autonomous Systems, </booktitle> <volume> 19(1) </volume> <pages> 67-83, </pages> <year> 1995. </year>
Reference-contexts: Attempts to increase the simulation complexity merely result in expenditure of vast amounts of modelling and computing time <ref> [9] </ref>. Jakobi's Radical Envelope of Noise hypothesis [6, 7] outlines a new approach to the problems of evolution in simulation.
Reference: 10. <author> F. Mondada, E. Franzi, and P. Ienne. </author> <title> Mobile robot miniaturization: A tool for investigation in control algorithms. </title> <booktitle> In ISER '93, </booktitle> <address> Kyoto, Japan, </address> <month> October </month> <year> 1993. </year>
Reference-contexts: Section 4 introduces the robot and vision system. 4 The Robot and Vision System The work described in this paper used the standard research minirobot Khepera <ref> [10] </ref>, equipped with the plug-in K213 vision module. The vision module returns a one-dimensional line-scan of light intensity values across a 36 ffi arc.
Reference: 11. <author> R. J. Schalkoff. </author> <title> Digital Image Processing and Computer Vision. </title> <publisher> John Wiley and Sons, </publisher> <year> 1989. </year>
Reference-contexts: However, the constraint that any image processing must be performed onboard the robot in real time removes the possibility of using such computationally expensive techniques as Laplacian transformation of Gaussian convoluted data <ref> [11] </ref>. Any processing must be `quick and dirty'.
Reference: 12. <author> T.M.C. Smith. </author> <title> Adding vision to Khepera: An autonomous robot footballer. </title> <type> Master's thesis, </type> <institution> School of Cognitive and Computing Sciences, University of Sussex, </institution> <year> 1997. </year>
Reference-contexts: However, the vision system is only used to return the position of the darkest pixel in the field of view, and no evaluation of the controllers in reality is described (for an exploration of transferring controllers utilising this kind of visual input from simulation to reality, see <ref> [12] </ref>). Cliff et al [1] evolve controllers capable of finding the centre of a room in simulation, but again no evaluation of behaviour in the real world is described. Other approaches include the Sussex gantry robot, "partway between a physical mobile robot ... and simulation" [5]. <p> From characterisation of the K213 vision system (described more fully in <ref> [12] </ref>), two implementation aspects were identified: The performance of individual pixels given identical inputs is not reliably the same. This was varied across trials by adding different values to each of the pixel inputs, chosen from either a. nothing, b.
References-found: 12

