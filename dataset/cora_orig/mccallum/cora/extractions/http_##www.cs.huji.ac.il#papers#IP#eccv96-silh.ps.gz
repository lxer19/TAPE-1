URL: http://www.cs.huji.ac.il/papers/IP/eccv96-silh.ps.gz
Refering-URL: http://www.cs.huji.ac.il/papers/IP/index.html
Root-URL: 
Title: Measures for Silhouettes Resemblance and Representative Silhouettes of Curved Objects  
Author: Yoram Gdalyahu and Daphna Weinshall 
Address: 91904 Jerusalem, Israel  
Affiliation: Institute of Computer Science, The Hebrew University,  
Abstract: We claim that the task of object recognition necessitates a measure for image likelihood, that is: a measure for the probability that a given image is obtained from a familiar (pre-investigated) object. Moreover, in a system where objects are represented by 2D images, the best performance is achieved if those images are selected according to a maximum likelihood principle. This is equivalent to maximum stability of the image, or minimal change under a viewpoint perturbation. All of those qualities involve a quantitative comparison of similarity between images. We propose different metric functions which can be imposed on the image space of curved three dimensional objects. We use these metrics to detect the representative views (most stable and most likely views) of three test models. We find the same representative views under all the investigated metrics, suggesting that local maxima of stability and likelihood are metric independent. Our method of image comparison is based solely on the appearance of the occluding contour, hence our method is suitable for object recognition from silhouettes.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> E. M. Arkin, L. P. Chew, D. P. Huttenlocher, K. Kedem, and J. S. B. Mitchell. </author> <title> An efficiently computable metric for comparing polygonal shapes. </title> <booktitle> T-PAMI, </booktitle> <pages> pages 209-216, </pages> <year> 1991. </year>
Reference-contexts: This transform is a representation of the curve by its tangent angle versus its normalized arc length <ref> [12, 1] </ref>. To construct such a representation, we start from an arbitrary point on the curve and follow it in an arbitrary direction, measuring in each point the angle of the curve tangent with respect to some arbitrary reference direction.
Reference: 2. <author> J. Ben-Arie. </author> <title> The probabilistic peaking effect of viewed angles and distances with application to 3-d object recognition. </title> <booktitle> T-PAMI, </booktitle> <pages> pages 760-774, </pages> <year> 1990. </year>
Reference-contexts: In these approaches a novel view of the object is recognized by comparing it to stored views, and storing "good" views is essential for successful performance. If an angle is to be recognized, Ben-Arie <ref> [2] </ref> and Burns et al. [5] already identified the more common views of it (see section 2). A related measure of view genericity, or view likelihood, also underlies the Bayesian decision strategy suggested by Freeman [7] to interpret correctly ambiguous scenes. <p> A second case which was studied is that of a planar angle that can be viewed from an arbitrary direction in space. This case was studied empirically by Ben-Arie <ref> [2] </ref> and Burns et. al [5], who found the "picking effect": the most probable value of an angle to be picked from a random viewing direction is the value of the angle itself.
Reference: 3. <author> A. M. Bruckstein, R. J. Holt, A. N. Netravali, and T. J. Richardson. </author> <title> Invariant signature for planar shape recognition under partial occlusion. CVGIP: </title> <booktitle> Image Understanding, </booktitle> <pages> pages 49-65, </pages> <year> 1993. </year>
Reference-contexts: However, since the curvature function is not invariant with respect to scale, we could rely above only on its extreme points, but not on the function values themselves. More sophisticated signature functions, that remain invariant under similarity, affine and projective transformations, can be found in the literature (see <ref> [3] </ref> and references therein). Some of them suffer from the involvement of high order derivatives, which is clearly an undesired property when using digitized curves.
Reference: 4. <author> A. M. Bruckstein, N. Katzir, M. Lindenbaum, and M. Porat. </author> <title> Similarity invariant recognition of partially occluded planar curves and shapes. </title> <booktitle> IJCV, </booktitle> <pages> pages 271-285, </pages> <year> 1992. </year>
Reference-contexts: Fig. 3. An original curve (left) and the transformed curve (right) obtained with a multiplication factor of 3. To avoid losing intersections due to end effects, the transformed curve is obtained by tracing the original curve twice. Points of unit signature The term "invariant signature" was assigned in <ref> [4] </ref> to functions that can be computed from a given curve, and have an invariance property under a certain transformation group.
Reference: 5. <author> J. B. Burns, R. S. Weiss, and E. M. Riseman. </author> <title> View variation of point set and line segment features. </title> <booktitle> T-PAMI, </booktitle> <pages> pages 51-68, </pages> <year> 1993. </year>
Reference-contexts: In these approaches a novel view of the object is recognized by comparing it to stored views, and storing "good" views is essential for successful performance. If an angle is to be recognized, Ben-Arie [2] and Burns et al. <ref> [5] </ref> already identified the more common views of it (see section 2). A related measure of view genericity, or view likelihood, also underlies the Bayesian decision strategy suggested by Freeman [7] to interpret correctly ambiguous scenes. <p> A second case which was studied is that of a planar angle that can be viewed from an arbitrary direction in space. This case was studied empirically by Ben-Arie [2] and Burns et. al <ref> [5] </ref>, who found the "picking effect": the most probable value of an angle to be picked from a random viewing direction is the value of the angle itself.
Reference: 6. <author> S. Duvdevani-Bar and S. Edelman. </author> <title> On similarity to prototypes in 3d object representation. </title> <type> Technical Report CS-TR 95-11, </type> <institution> Weizmann Institute, </institution> <month> July </month> <year> 1995. </year>
Reference-contexts: Explicit identification of such views requires an explicit quantitative measure of similarity between images. Such a measure converts the image space into a metric space, where the distance between every two images is proportional to their dissimilarity. Finding an appropriate metric is a research subject of its own <ref> [6] </ref>, and for complicated images it is still an open question how to measure their resemblance. It becomes easier to measure image similarity if the family of the objects is constrained. For example, a discrete object which is made of a cloud of points.
Reference: 7. <author> W. T. Freeman. </author> <title> Exploiting the generic view assumption to estimate scene parameters. </title> <booktitle> In proc. of ICCV, </booktitle> <pages> pages 347-356, </pages> <year> 1993. </year>
Reference-contexts: If an angle is to be recognized, Ben-Arie [2] and Burns et al. [5] already identified the more common views of it (see section 2). A related measure of view genericity, or view likelihood, also underlies the Bayesian decision strategy suggested by Freeman <ref> [7] </ref> to interpret correctly ambiguous scenes. Freeman showed how to use measures of view "genericity" in image understanding, but did not propose a general way to compute such measures directly from images and models.
Reference: 8. <author> D. P. Huttenlocher and S. Ullman. </author> <title> Object recognition using alignment. </title> <booktitle> In proc. of ICCV, </booktitle> <pages> pages 102-111, </pages> <year> 1987. </year>
Reference-contexts: Extreme curvature points Points of maximum (and perhaps also minimum) curvature along the curve are probably the most intuitive features that one can think of. However, extreme curvature points are known to be unstable <ref> [8] </ref> and hard to extract, due to their sensitivity to resolution and to the presence of noise. In general, a reliable extraction requires some smoothing mechanism, which enhances the extraction robustness and reduces its locality.
Reference: 9. <author> N. Katzir, M. Lindenbaum, and M. Porat. </author> <title> Planar curve segmentation for recognition of partially occluded shapes. </title> <booktitle> In proc. of ICPR, </booktitle> <year> 1990. </year>
Reference-contexts: Transformed self intersections The occluding contour, which in our view here is the only image content, is a simple closed curve which does not intersect itself. But it was recently shown <ref> [9] </ref> how such a curve can be transformed into another one, which does intersect itself. In this method the tangent angle transform (see above) is multiplied by a constant factor and a new curve, which in general does intersect itself, is reconstructed (figure 3). <p> In this method the tangent angle transform (see above) is multiplied by a constant factor and a new curve, which in general does intersect itself, is reconstructed (figure 3). The exceptional conditions for which self intersections can't be made, or their number becomes infinite, are discussed in <ref> [9] </ref> and are ignored here. The self intersection points can be mapped back to the original image. Note that each intersection is both a starting point and an ending point of a loop on the transformed curve, hence it is mapped back to two points on the original curve.
Reference: 10. <author> D. Keren, D. Cooper, and J. Subrahmonia. </author> <title> Describing complicated objects by implicit polynomials. </title> <booktitle> T-PAMI, </booktitle> <pages> pages 38-53, </pages> <year> 1994. </year>
Reference-contexts: with the method of a whole curve comparison, since for those viewing directions the object appears as a circle. 4.3 Eggplant model The last test object is a model of an eggplant, which is represented by a fourth degree polynomial whose 35 coefficients were fitted experimentally to a real eggplant <ref> [10] </ref>. The eggplant model lacks any kind of symmetry, except the trivial reflection symmetry of silhouettes which is obtained for any two antipode viewing directions. The stability map and the corresponding representative and non representative views are shown in figure 8.
Reference: 11. <author> Y. Lamdan, J. T. Schwartz, and H. J. Wolfson. </author> <title> Affine invariant model based object recognition. </title> <type> T-RA, </type> <pages> pages 578-589, </pages> <year> 1990. </year>
Reference-contexts: The other metric functions can be applied also to non normalized curves, and therefore can deal with occlusions. Another benefit of comparison methods based on feature extraction is the possibility to combine them with database indexing methods <ref> [11] </ref>. The extracted features can serve not only for distance evaluation against stored arrays of feature points in the memory, but their invariant coordinates can also be used to generate pointers into the database, to enhance the search.
Reference: 12. <author> P. J. van Otterloo. </author> <title> A Contour-Oriented Approach to Shape Analysis. </title> <publisher> Prentice Hall Intrernational, </publisher> <year> 1991. </year>
Reference-contexts: This transform is a representation of the curve by its tangent angle versus its normalized arc length <ref> [12, 1] </ref>. To construct such a representation, we start from an arbitrary point on the curve and follow it in an arbitrary direction, measuring in each point the angle of the curve tangent with respect to some arbitrary reference direction.
Reference: 13. <author> D. Weinshall and M. Werman. </author> <title> Disambiguation techniques for recognition in large databases and for under-constrained reconstruction. </title> <booktitle> In proc. of Intr. Symp. on Comp. Vision, </booktitle> <pages> pages 425-430, </pages> <address> Coral Gables, USA, </address> <year> 1995. </year>
Reference-contexts: This leads to the intuitive notions of "canonical", "characteristic" or "generic" views, which frequently appear in the literature. Recently, an objective definition has been given for those notions <ref> [14, 13] </ref>. According to it, a representative view has the properties of maximum likelihood (it is similar, as an image, to a large number of other images), and maximum stability (it doesn't vary a lot when the viewing direction is perturbed). <p> We have already shown that a local maximum of the likelihood function is obtained at the same points (views) for which a local maximum of the stability function is obtained <ref> [13] </ref>. Therefore, the same single view is (locally) both the most likely and the most stable one, and it is naturally proposed as a representative view. Explicit identification of such views requires an explicit quantitative measure of similarity between images. <p> (#; '): l " (#; ') = f (#; ')f ("j#; ') ' f (#; ') 0 2 Z fd (#;';ffi; )"g sin (ffi)dffid We note that it is also possible to define both the stability and the likelihood in the limit of " ! 0, as we do in <ref> [13] </ref>. This means that stability is measured in the limit of a zero perturbation of camera position, and likelihood is measured in the limit of zero image error. 2.2 General results and some special cases It can be shown [13] that if the prior distribution of viewpoints of a given object <p> in the limit of " ! 0, as we do in <ref> [13] </ref>. This means that stability is measured in the limit of a zero perturbation of camera position, and likelihood is measured in the limit of zero image error. 2.2 General results and some special cases It can be shown [13] that if the prior distribution of viewpoints of a given object is uniform, namely all camera positions are equally likely, then the most stable and the most likely views are the same view. <p> In other words, the local maxima of the stability function and of the likelihood function are obtained for the same views. In previous works we applied our definitions to simple objects, for which there is a natural metric function <ref> [13, 14] </ref>. The first case is that of objects represented by feature points in 3D space. A natural measure for the distance between two images is obtained by measuring residual distances between corresponding points, after the two images have been normalized and aligned.
Reference: 14. <author> D. Weinshall, M. Werman, and N. Tishby. </author> <title> Stability and likelihood of views of three dimensional objects. </title> <journal> Computing Suppl., </journal> <volume> 11 </volume> <pages> 237-256, </pages> <year> 1996. </year> <title> This article was processed using the L a T E X macro package with ECCV'96 style </title>
Reference-contexts: This leads to the intuitive notions of "canonical", "characteristic" or "generic" views, which frequently appear in the literature. Recently, an objective definition has been given for those notions <ref> [14, 13] </ref>. According to it, a representative view has the properties of maximum likelihood (it is similar, as an image, to a large number of other images), and maximum stability (it doesn't vary a lot when the viewing direction is perturbed). <p> In <ref> [14] </ref> the "-stability s " (#; ') of a view was defined simply as 1=R " . <p> In other words, the local maxima of the stability function and of the likelihood function are obtained for the same views. In previous works we applied our definitions to simple objects, for which there is a natural metric function <ref> [13, 14] </ref>. The first case is that of objects represented by feature points in 3D space. A natural measure for the distance between two images is obtained by measuring residual distances between corresponding points, after the two images have been normalized and aligned.
References-found: 14

