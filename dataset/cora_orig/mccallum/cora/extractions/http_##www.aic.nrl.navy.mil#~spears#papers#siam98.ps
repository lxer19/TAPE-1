URL: http://www.aic.nrl.navy.mil/~spears/papers/siam98.ps
Refering-URL: http://www.cs.gmu.edu:80/research/gag/pubs.html
Root-URL: 
Title: A COMPRESSION ALGORITHM FOR PROBABILITY TRANSITION MATRICES  
Author: WILLIAM M. SPEARS 
Keyword: Key words. probability transition matrix, transient behavior, compression, lumping, aggrega tion  
Note: AMS subject classifications. 15A51, 15A04  
Abstract: This paper describes a compression algorithm for probability transition matrices. The compressed matrix is itself a probability transition matrix. In general the compression is not error-free, but the error appears to be small even for high levels of compression. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> T. Dayar and W. J. Stewart, Quasi-lumpability, </author> <title> lower bounding coupling matrices, and nearly completely decomposable Markov chains. </title> <journal> SIAM J. Matrix Anal. Appl. v18, </journal> <volume> #2, </volume> <year> (1997). </year>
Reference-contexts: The aggregated matrix can be computed via the method of "stochastic complementation" or via "iterative aggregation/ disaggregation" methods. The former will work on arbitrary matrices but is generally computationally expensive. The latter is most efficient for "nearly completely decomposable" (NCD) matrices (e.g., see <ref> [1] </ref>). However, the emphasis is always on steady-state behavior, and not on transient behavior. This difference in emphasis can been seen by noting the difference in the choice of weights the focus in this paper has been on column mass instead of steady state values.
Reference: [2] <author> K. De Jong, W. Spears, and D. F. Gordon, </author> <title> Using Markov chains to analyze GAFOs. </title> <booktitle> Foundations of GAs Workshop. </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> (1994), </year> <pages> pp. 115 - 137. </pages>
Reference-contexts: The number of states grows extremely fast as the size of the population increases and as the size of individuals increase. The details of the mapping of GAs to Markov chains can be found in [6]. Their use in examining transient behavior can be found in <ref> [2] </ref>. 5 6.1. Accuracy Experiments. The first set of experiments examine the accuracy of the compressed Markov chains by using both Q n u and Q n c to compute the probability distribution p (n) over the states at time n. <p> For N = 969, over 80% of the states have been removed, yielding Q c matrices roughly 3% the size (in terms of memory requirements) of the original Q u matrix. It is also interesting to note that different search spaces are consistently compressed to different 7 See <ref> [2] </ref> for a definition of these search spaces. 14 W. M. SPEARS Table 6.1 The percentage of states removed when * = 0:15. <p> Further investigation into the nature of these search spaces may help characterize when arbitrary Markov chains are hard/easy to compress with this algorithm. 6.2. Timing Experiments. It is now necessary to examine the computational cost of the compression algorithm. Our prior work, <ref> [2] </ref> and [9], focused heavily on the insights gained by actually examining Q n u , which involved computations on the order of N 3 (to multiply Q u repeatedly).
Reference: [3] <author> E. C. Howe and C. R. Johnson, </author> <title> Aggregation of Markov processes: axiomatization. </title> <journal> Journal of Theoretical Probability v2, </journal> <volume> #2, </volume> <year> (1989), </year> <pages> pp. 201 - 208. </pages>
Reference-contexts: Almost all theoretical analyses of aggregation (e.g., "block aggregation" [5]) utilize the same functional form: f (Q u ) = Q c = AQ u B (AB = I) where A and B are matrices that determine the partitioning and the aggregation of the states <ref> [3] </ref> [4]. This functional form must satisfy two axioms: "linearity" and "state 9 It is also important to emphasize that it is very likely that the compression algorithm can be extensively optimized, producing much better timing results. 16 W. M. SPEARS partitioning".
Reference: [4] <author> E. C. Howe and C. R. Johnson, </author> <title> Linear aggregation of input-output models. </title> <journal> SIAM J. Matrix Anal. Appl. v10, </journal> <volume> #1, </volume> <year> (1989), </year> <pages> pp. 65 - 79. </pages>
Reference-contexts: Almost all theoretical analyses of aggregation (e.g., "block aggregation" [5]) utilize the same functional form: f (Q u ) = Q c = AQ u B (AB = I) where A and B are matrices that determine the partitioning and the aggregation of the states [3] <ref> [4] </ref>. This functional form must satisfy two axioms: "linearity" and "state 9 It is also important to emphasize that it is very likely that the compression algorithm can be extensively optimized, producing much better timing results. 16 W. M. SPEARS partitioning".
Reference: [5] <author> J. Kemeny and J. Snell, </author> <title> Finite Markov chains. </title> <address> D. </address> <publisher> Van Nostrand, </publisher> <address> New York, </address> <year> 1960. </year>
Reference-contexts: There is also considerable work in aggregation of DTMCs. Almost all theoretical analyses of aggregation (e.g., "block aggregation" <ref> [5] </ref>) utilize the same functional form: f (Q u ) = Q c = AQ u B (AB = I) where A and B are matrices that determine the partitioning and the aggregation of the states [3] [4].
Reference: [6] <author> A. E. Nix and M. D. Vose, </author> <title> Modelling genetic algorithms with Markov chains. </title> <journal> Annals of Mathematics and Artificial Intelligence #5, </journal> <year> (1992), </year> <pages> pp. 79 - 88. </pages>
Reference-contexts: The number of states grows extremely fast as the size of the population increases and as the size of individuals increase. The details of the mapping of GAs to Markov chains can be found in <ref> [6] </ref>. Their use in examining transient behavior can be found in [2]. 5 6.1. Accuracy Experiments.
Reference: [7] <author> R. Sidje and W. J. Stewart, </author> <title> A survey of methods for computing large sparse matrix expo-nentials arising in Markov chains. </title> <note> Submitted for publication, </note> <year> (1996). </year>
Reference: [8] <author> W. Spears, K. De Jong, T. Baeck, D. Fogel, and H. de Garis, </author> <title> An overview of evolutionary computation. Euro. </title> <booktitle> Conf. on ML, </booktitle> <publisher> Springer Verlag, </publisher> <address> v667, </address> <year> (1993), </year> <pages> pp. 442 - 459. </pages>
Reference-contexts: In a GA a population of individuals evolves generation by generation via Darwinian selection and perturbation operators such as recombination and mutation. Each individual in the population can be considered to be a point in a search space (see <ref> [8] </ref> for an overview of GAs). Each different population of the GA is a state in the Markov chain, and p i;j is the probability that the GA will evolve from one population i to another j, in one generation (time step).
Reference: [9] <author> W. Spears and K. De Jong, </author> <title> Analyzing GAs using Markov models with semantically ordered and lumped states. </title> <booktitle> Foundations of GAs Workshop. </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> (1996), </year> <pages> pp. 85 - 100. </pages>
Reference-contexts: Further investigation into the nature of these search spaces may help characterize when arbitrary Markov chains are hard/easy to compress with this algorithm. 6.2. Timing Experiments. It is now necessary to examine the computational cost of the compression algorithm. Our prior work, [2] and <ref> [9] </ref>, focused heavily on the insights gained by actually examining Q n u , which involved computations on the order of N 3 (to multiply Q u repeatedly). Thus, the primary motivation for producing the compression algorithm was to gain the same insights more efficiently by dramatically reducing N .
Reference: [10] <author> W. J. Stewart, </author> <title> Introduction to the numerical solution of Markov chains. </title> <publisher> Princeton University Press, </publisher> <address> New Jersey, </address> <year> 1994. </year>
Reference-contexts: The second occasion is when it is necessary to compute p (n) for large n (e.g., <ref> [10] </ref> indicates that times on the order of 10 8 are sometimes required). In both of these situations the cost of the compression algorithm is amortized. <p> This section summarizes the work that is most closely related. There is a considerable body of literature concerning the approximation of transient behavior in Markov chains. Techniques include the computation of matrix expo-nentials, the use of ordinary differential equations, and Krylov subspace methods <ref> [10] </ref>. However, all of these techniques are for continuous-time Markov chains (CTMCs), which use an infinitesimal generator matrix instead of a probability transition matrix. <p> It is possible to discretize a CTMC to obtain a DTMC such that the stationary probability vector of the CTMC is identical to that of the DTMC. However, <ref> [10] </ref> notes that the transient solutions of DTMCs are not the same as those of the corresponding CTMCs, indicating that these techniques will be problematic for computing the transient behavior of DTMCs. There is also considerable work in aggregation of DTMCs. <p> The current results indicate that the relevance of both axioms should be re-examined. The aggregation technique most closely related to the work in this paper is described by <ref> [10] </ref>, [11] and [12]. This aggregation technique partitions the set of states S into s non-empty sets S 1 ; :::; S s .
Reference: [11] <author> W. J. Stewart and W. Wu, </author> <title> Numerical experiments with iteration and aggregation for Markov chains. </title> <journal> ORSA Journal on Computing, v4, </journal> <volume> #3, </volume> <year> (1992), </year> <pages> pp. 336 - 350. </pages>
Reference-contexts: The current results indicate that the relevance of both axioms should be re-examined. The aggregation technique most closely related to the work in this paper is described by [10], <ref> [11] </ref> and [12]. This aggregation technique partitions the set of states S into s non-empty sets S 1 ; :::; S s .
Reference: [12] <author> M. Vose, </author> <title> Modeling simple genetic algorithms. </title> <journal> Evol. Comp., v3, </journal> <volume> #4, </volume> <year> (1995), </year> <note> 453 - 472. 18 W. M. SPEARS </note>
Reference-contexts: The current results indicate that the relevance of both axioms should be re-examined. The aggregation technique most closely related to the work in this paper is described by [10], [11] and <ref> [12] </ref>. This aggregation technique partitions the set of states S into s non-empty sets S 1 ; :::; S s .
References-found: 12

