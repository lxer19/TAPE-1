URL: ftp://speech.cse.ogi.edu/pub/docs/icassp97/hosom.ps
Refering-URL: http://www.cse.ogi.edu/CSLU/personnel/bios/cole.html
Root-URL: http://www.cse.ogi.edu
Email: fhosom, coleg@cse.ogi.edu  
Title: A DIPHONE-BASED DIGIT RECOGNITION SYSTEM USING NEURAL NETWORKS  
Author: John-Paul Hosom Ronald A. Cole 
Web: http://www.cse.ogi.edu/CSLU/  
Address: P.O. Box 91000, Portland, Oregon 97291-1000 USA  
Affiliation: Center for Spoken Language Understanding, Oregon Graduate Institute of Science and Technology  
Abstract: In exploring new ways of looking at speech data, we have developed an alternative method of segmentation for training a neural-network-based digit-recognition system. Whereas previous methods segment the data into monophones, biphones, or triphones and train on each sub-phone unit in several broad-category contexts, our new method uses modified diphones to train on the regions of greatest spectral change as well as the regions of greatest stability. Although we account for regions of spectral stability, we do not require their presence in our word models. Empirical evidence for the advantage of this new method is seen by the 13% reduction in word-level error that was achieved on a test set of the OGI Numbers corpus. Comparison was made to a baseline system that used context-independent monophones and context-dependent biphones and triphones. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E. Barnard, R. A. Cole, M. Fanty, and P. Ver-meulen. </author> <title> Real-world speech recognition with neural networks. </title> <booktitle> Applications and Science of Artificial Neural Networks, </booktitle> <pages> pages 524-537, </pages> <month> April </month> <year> 1995. </year>
Reference-contexts: 1. INTRODUCTION Previous methods for training neural-network rec-ognizers divide each phone for training into one, two, or three parts (monophones, biphones, or tri phones). Training is then done on each phone or sub-phone, either as context-independent units, or in various broad-category contexts <ref> [1] </ref>. Context-dependent modeling is done in order to account for the coarticulatory effects of neighboring phones. Context-dependent modeling, however, may not always provide appropriate information for distinguishing variations of a phone in different contexts.
Reference: [2] <author> R. A. Cole, M. Noel, T. Lander, and T. Durham. </author> <title> New telephone speech corpora at cslu. </title> <booktitle> Proceedings of the Fourth European Conference on Speech Communication and Technology, </booktitle> <pages> pages 821-824, </pages> <month> September </month> <year> 1995. </year>
Reference-contexts: For phones that have a great variation in duration, dividing the phone into a fixed number of parts may not always yield satisfactory results. For example, the /I/ in the word "zero" can vary greatly in duration. (In the OGI Numbers cor pus <ref> [2] </ref>, human labelers have found the duration of this phone to range from 20 to 280 msec.) If /I/ is modeled as a biphone, then long instances of /I/ may be poorly recognized during the middle section. <p> TASK For investigating the performance of our diphone-based system, we selected the task of continuous-digit recognition of telephone-band speech. 2.1. Corpus The corpus that we used for training, development, and testing was a subset of the OGI Numbers corpus <ref> [2] </ref> that contains only digits. This digits corpus contains many thousand utterances of digit strings spoken by a large number of people under various conditions. As a result, many aspects of "real-life" speech are present in the data, including noise, widely-varying energy levels, and dialect differences. <p> The training data are searched to find 2000 vectors of each category, if possible. If less than 50 vectors can be found, then additional vectors are taken from training data in the OGI Names corpus <ref> [2] </ref>. The one exception is silence, which is trained using 8000 vectors, all from the OGI Numbers corpus.
Reference: [3] <author> W. M. Fisher and J. G. Fiscus. </author> <title> Better alignment procedures for speech recognition evaluation. </title> <booktitle> International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <address> 2:II59-II62, </address> <year> 1993. </year>
Reference-contexts: We allocated three-fifths of the available data for training, and one-fifth each for development and testing. 2.2. Measurements We measure the performance of both the baseline and the proposed method using the scoring algo rithm developed by NIST <ref> [3] </ref>. We report the over-all accuracy as well as the percentage of substitutions, insertions, and deletions. 3. THE BASELINE RECOGNITION SYSTEM In this section, we describe the method used to construct the baseline system. This system uses a neural network to classify fixed-length frames of speech into context-dependent phone-based categories.
Reference: [4] <author> J. Schalkwyk, D. Colton, and M. Fanty. </author> <title> The cslush toolkit for automatic speech recognition. </title> <type> OGI Technical Report No. </type> <institution> CSLU-011-95, </institution> <month> December </month> <year> 1995. </year>
Reference-contexts: This system uses a neural network to classify fixed-length frames of speech into context-dependent phone-based categories. Construction of both the baseline system and the diphone system was done using the cslush speech-processing software package developed at OGI <ref> [4] </ref>. 3.1. Baseline Segmentation Method The context-dependent categories used in the baseline system are determined from speech data that have been hand-labeled at the phone level. Each phone is assigned a fixed number of parts to be split into, and a broad category of speech to which it belongs.
Reference: [5] <author> H. Hermansky. </author> <title> Perceptual linear predictive (plp) analysis of speech. </title> <journal> Journal of the Acoustical Society of America, </journal> <volume> 87(4) </volume> <pages> 1738-1752, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: Baseline Training Method As a first step in training the neural network, Perceptual Linear Prediction (PLP) <ref> [5] </ref> features (in cluding energy) are computed at non-overlapping 10-msec frames.
Reference: [6] <author> Y. Yan, M. Fanty, and R. A. Cole. </author> <title> Speech recognition using neural networks with forward-backward probability generated targets. </title> <booktitle> Proceedings of the International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <year> 1997. </year> <note> Accepted for publication. </note>
Reference-contexts: These results are encouraging, but the number of diphone categories will increase dramatically for vocabulary-independent systems. A means of reducing the number of categories for such systems must be found. The authors would also like to apply the training technique developed by Yan et al. <ref> [6] </ref> to the diphone system. In conclusion, we feel that the modified-diphone technique described here represents an advancement over current biphone and triphone methods for the continuous-digits task. 7.
References-found: 6

