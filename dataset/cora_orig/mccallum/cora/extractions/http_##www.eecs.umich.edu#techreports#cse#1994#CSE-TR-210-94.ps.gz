URL: http://www.eecs.umich.edu/techreports/cse/1994/CSE-TR-210-94.ps.gz
Refering-URL: http://www.eecs.umich.edu/home/techreports/cse94.html
Root-URL: http://www.eecs.umich.edu
Title: AN OBJECT-ORIENTED REAL-TIME DATABASE SYSTEM FOR MULTIPROCESSORS.  
Author: by Victor Bradley Lortz Chinya V. Ravishankar 
Degree: A dissertation submitted in partial fulfillment of the requirements for the degree of Doctor of Philosophy (Computer Science and Engineering) in The  Doctoral Committee: Professor Kang G. Shin, Chair Professor Toby J. Teorey Assistant Professor Elke A. Rundensteiner Professor Galip Ulsoy  
Note: Associate Research Scientist  
Date: 1994  
Affiliation: University of Michigan  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> R. Abbott and H. Garcia-Molina, </author> <title> "Scheduling real-time transactions," </title> <booktitle> SIGMOD Record, </booktitle> <volume> vol. 17, no. 1, </volume> <pages> pp. 71-81, </pages> <month> March </month> <year> 1988. </year>
Reference-contexts: None of the prior work in RTDBSs considers the possibility of application tasks executing transactions themselves. Transaction and I/O Scheduling Several researchers have investigated transaction and I/O scheduling algorithms that support different real-time needs and priorities <ref> [1, 12, 62, 83, 76] </ref>. Some commercial database systems support priority-based transaction scheduling [25, 64]. By servicing high-priority tasks first, the database can provide faster and more predictable performance for transactions submitted by high-priority tasks. In this case, low-priority tasks experience degraded performance.
Reference: [2] <author> B. Anderson, </author> <title> "Next generation workstation/machine controller (NGC)," </title> <booktitle> in Proc. </booktitle> <volume> IPC '92, </volume> <pages> pp. </pages> <address> xix-xxvi, </address> <month> April </month> <year> 1992. </year>
Reference-contexts: However, as data volume increases and software becomes more complex, ad hoc data management becomes inadequate. The Next Generation Workstation/Machine Controller (NGC) for automated factories is representative of the class of complex, distributed real-time architectures that requires data management services <ref> [2, 51] </ref>. The NGC is a software architecture specification for advanced cell-level machine tool controllers. In this context, cell-level refers to a manufacturing system workcell, which is a factory component that might contain one or more robots, a computer-controlled milling machine, etc. <p> Customized systems are expensive to build and maintain, so efforts are underway to establish standard, open software architectures for advanced manufacturing. The proposed Next Generation Workstation/Machine Controller (NGC) for automated factories <ref> [2, 51] </ref> is representative of the trend toward open software architectures in manufacturing. The NGC is a software architecture specification for advanced cell-level machine tool controllers. The NGC architecture is designed for high-performance real-time computing platforms such as VME-based shared-memory multiprocessors.
Reference: [3] <author> T. E. Anderson, </author> <title> "The performance of spin lock alternatives for shared-memory multiprocessors," </title> <journal> IEEE Trans. Parallel and Distributed Systems, </journal> <volume> vol. 1, no. 1, </volume> <pages> pp. 6-16, </pages> <month> January </month> <year> 1990. </year>
Reference-contexts: LCScount depends on the locking and queueing protocol implemented by the lock and upon the number and distribution of objects sharing it. We have implemented a spinlock queue lock that uses a simple FIFO queueing strategy. The literature contains several examples of implementing such locks on shared-memory multiprocessors, e.g., <ref> [3, 19] </ref>. A transaction requests a lock by invoking the lock's getLock () method. Just before enqueuing a transaction, getLock () disables task preemption. This means that while executing the critical section or while waiting for the lock, the transaction effectively acquires the highest execution priority in the system. <p> These task sets were generated in groups of 50 sets for each combination of <ref> [3, 6, or 10 processors] </ref>, [3, 6 or 10 tasks per processor], [5, 10, or 20 global semaphores], [processor utilizations of 0.6 or 0.7], and [constant or varying critical section times for semaphores]. <p> These task sets were generated in groups of 50 sets for each combination of [3, 6, or 10 processors], <ref> [3, 6 or 10 tasks per processor] </ref>, [5, 10, or 20 global semaphores], [processor utilizations of 0.6 or 0.7], and [constant or varying critical section times for semaphores]. <p> Instead, it is notified by the task immediately ahead of it when its transaction number comes up. The design of these spinlocks is a bit tricky, but several good examples can be found in the literature (for example, <ref> [3, 19, 30] </ref>). This algorithm assumes that no more than MAX NUM MACHINES tasks will attempt to enter the lock. Since we disable task preemptions, this assumption is valid. Since the performance of MDARTS transactions is so dependent on the concurrency control implementation, we experimented with two other spinlock implementations.
Reference: [4] <author> P. M. G. Apers, C. A. van den Berg, J. Flokstra, P. W. P. J. Grefen, M. L. Kersten, and A. N. Wilschut, "Prisma/db: </author> <title> A parallel, main memory relational dbms," </title> <journal> IEEE Trans. Knowledge and Data Engineering, </journal> <volume> vol. 4, no. 6, </volume> <pages> pp. 541-554, </pages> <month> December </month> <year> 1992. </year>
Reference-contexts: Typical average transactions times for simple transactions in main memory databases (600 milliseconds for TPK [45], about 69 milliseconds for the main memory version of Starburst with concurrency control disabled [42], over 100 milliseconds for PRISMA/DB 1 2 <ref> [4] </ref>) are much too slow for high-speed real-time systems. Furthermore, these main memory database systems do not provide worst-case guarantees for their transactions. Hard real-time systems need worst-case guarantees to ensure that all deadlines will be met. <p> Main Memory Databases Some RTDBS researchers propose using main memory databases to eliminate blocking time uncertainties associated with disk I/O during database transactions [71, 80]. There has also been significant interest recently in using main memory databases to increase performance for conventional transaction processing systems <ref> [4, 23, 42, 45] </ref>. Garcia-Molina 5 and Salem present a nice overview of main memory database research in [23].
Reference: [5] <author> A. Attoui and M. Schneider, </author> <title> "An object oriented model for parallel and reactive systems," </title> <booktitle> in Proc. Real-Time Systems Symposium, </booktitle> <pages> pp. 84-93, </pages> <month> December </month> <year> 1991. </year>
Reference-contexts: Note that this overhead does not include the actual transaction processing or concurrency control delays. Therefore, we conclude that neither CHAOS nor ARTS is well-suited to application domains where sub-millisecond transaction times for object methods are required. The MO2 model combines features of database systems and real-time systems <ref> [5] </ref>. MO2 supports distributed active objects with per-object read and write servers that execute client requests at the client priorities. Serializability is provided by executing methods serially in an object's write server process. Unlike CHAOS, MO2 supports inheritance. <p> In our current prototype, this usually corresponds to local transaction execution time since the blocking times are zero. The following example shows how an application would perform a read transaction: Point end effector position = positions <ref> [5] </ref>; Clearly, the syntax for using MDARTS is very convenient compared with application programming interfaces that require preprocessing of embedded query languages. Object-oriented database systems often have convenient application programming interfaces, so MDARTS is not unique in this respect. <p> Sub 47 * Declaration of MDARTS object in sensor task that will be updating it: */ MdartsArray&lt;Point&gt; position_sensors ("position_sensors", "exclusive_update; size = 6; write (element) &lt;= 50usec", CREATE); /* Sensor task updates the data: */ position_sensors <ref> [5] </ref> = Point (1.2, 0.866, 3.4); /*********************************************************** * Corresponding declaration of MDARTS object in control task: */ ReadOnlyMdartsArray&lt;Point&gt; position_sensors ("position_sensors", "read (element) &lt;= 80usec"); /* Control task reads the data: */ int i = position_sensors ("size") - 1; Point end_effector_position = position_sensors [i]; sequent database access using the objects is not <p> These task sets were generated in groups of 50 sets for each combination of [3, 6, or 10 processors], [3, 6 or 10 tasks per processor], <ref> [5, 10, or 20 global semaphores] </ref>, [processor utilizations of 0.6 or 0.7], and [constant or varying critical section times for semaphores]. For our schedulability analysis, we used critical zone analysis rather than Eq. (4.1) because it is a more accurate method for determining schedulability.
Reference: [6] <author> B. R. Badrinath and K. Ramamritham, </author> <title> "Synchronizing transactions on objects," </title> <journal> IEEE Trans. Computers, </journal> <volume> vol. 37, no. 5, </volume> <pages> pp. 541-547, </pages> <month> May </month> <year> 1988. </year>
Reference-contexts: Synchronization delays caused by locking can be reduced if the frequency of locking conflicts is reduced. One approach to reducing locking conflicts is to adjust the lock granularity to lock only data that are affected by each transaction <ref> [6, 66, 79] </ref>. Reducing lock granularity increases space overhead for locking, and it can degrade performance if many locks must be acquired to perform a transaction. Therefore, the locking granularity should be tuned to transaction characteristics. <p> Avoid unnecessary locking. When possible, use data versioning [39, 79] or multiple data copies [90] to permit concurrent read and write operations without locking. Match locking granularity with data semantics. This ensures that locking does not unnecessarily restrict concurrency. Sha et al. [66], Badrinath and Ramamritham <ref> [6] </ref>, and Son [79] all propose locking only the data affected by a transaction. However, identifying affected data and locking only those data are non-trivial problems in conventional database systems, where the data affected by a transaction are determined during query processing at runtime. <p> These task sets were generated in groups of 50 sets for each combination of <ref> [3, 6, or 10 processors] </ref>, [3, 6 or 10 tasks per processor], [5, 10, or 20 global semaphores], [processor utilizations of 0.6 or 0.7], and [constant or varying critical section times for semaphores].
Reference: [7] <author> B. R. Badrinath and K. Ramamritham, </author> <title> "Semantics-based concurrency control: Beyond commutativity," </title> <journal> ACM Trans. Database Systems, </journal> <volume> vol. 17, no. 1, </volume> <pages> pp. 163-199, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: Therefore, the locking granularity should be tuned to transaction characteristics. Semantic and object-based concurrency control protocols extend this idea by characterizing which transactions conflict and thus require serialization <ref> [7, 21, 40] </ref>. Another approach to reducing locking conflicts is to design transaction protocols that use data versioning to avoid locking altogether [79, 86, 90, 91]. MDARTS objects can use similar techniques in providing concurrency control for their transaction methods. <p> By checking requirements during initialization rather than during transac 35 Constraint type access time persistence staleness concurrency Specification "write&lt;=80usec; read<=50usec" "volatile" "stale&lt;=20msec" "exclusive_update" tion execution, problems are detected early, and overhead during transaction processing is reduced. Recent work by Badrinath and Ramamritham <ref> [7] </ref> and DiPippo and Wolfe [21] propose concurrency control techniques that use the semantics of object methods to increase the level of concurrency supported by database objects.
Reference: [8] <author> T. Baker, </author> <title> "A stack-based resource allocation policy for real-time processes," </title> <booktitle> in Proc. Real-Time Systems Symposium, </booktitle> <pages> pp. 191-200, </pages> <month> December </month> <year> 1990. </year>
Reference-contexts: Given such a bound, traditional scheduling strategies such as rate monotonic scheduling or earliest deadline scheduling can be used to guarantee task deadlines <ref> [8, 60] </ref>. The most common approach to bounding semaphore wait times is to use variants of the priority inheritance protocol (e.g., basic priority inheritance, priority ceiling protocol, semaphore control protocol, kernel priority protocol [59]) to limit wait times due to lower-priority tasks [36, 58, 60, 68].
Reference: [9] <author> B. N. Bershad, </author> <title> High Performance Cross-Address Space Communication, </title> <type> PhD thesis, </type> <institution> University of Washington, </institution> <month> June </month> <year> 1990. </year>
Reference-contexts: Local (same machine) RPCs can be made much faster, depending on how they are implemented in the operating system kernel. By carefully minimizing data copying and using shared memory, Bershad was able to reduce worst-case overhead for local RPCs on DEC Firefly multiprocessors to about 150 microseconds <ref> [9] </ref>. Bershad's technique has the advantage of propagating the execution priority of the client to the server (the client task is mapped into the server's address space, and it effectively becomes an instance of the server for the duration of the RPC). <p> On our implementation platform, round-trip RPCs consumed several milliseconds between CPUs on the local multiprocessor (we used Sun RPC). The special techniques for minimizing context switch overhead in RPCs described in <ref> [9, 46] </ref> were not available to us in the commercial real-time operating system we used. Therefore, the theoretical limits of RPC overhead was a moot issue for us. On our platform, RPC was expensive. <p> These overhead numbers are realistic: a typical RPC round trip can take several milliseconds, whereas local procedure calls and memory accesses require only a few microseconds. Some high-speed RPC systems can reduce the overhead of transferring data and control between 21 clients and servers <ref> [9, 46] </ref>, but these systems are not widely available, they rely on processor-specific optimizations and low-level kernel modifications, and they do not eliminate the serial bottlenecks of server processes on multiprocessors. In MDARTS, each object supplies the context and identity of its particular data.
Reference: [10] <author> J. Bloomer, </author> <title> Power Programming with RPC, </title> <publisher> O'Reilly & Associates, Inc., </publisher> <year> 1991. </year>
Reference-contexts: However, most systems require some form of networking to access remote data. One of the difficulties associated with remote data access is that most networking protocols add substantial overhead and do not provide end-to-end response-time guarantees. For example, TCP/IP-based protocols for socket and datagram communications, on which Sun RPC <ref> [10] </ref> and OSF DCE [69] are built, provide no timing guarantees. Clearly, any remote transaction that uses these services cannot provide any absolute timing guarantees. Nevertheless, it can still be very useful to provide remote access even if transaction-time guarantees are not made. <p> The CPU utilization required by the SDM would depend on the arrival rate of remote requests and their worst-case execution times. For remote access to data, our implementation of MDARTS uses remote procedure calls (RPC) <ref> [10] </ref>. Applications that need to access remote objects use proxy objects that generate RPCs to ask the SDM to perform transactions on their behalf. Applications need not know whether the access is local or remote; the MDARTS objects hide the access mechanism. <p> Our first MDARTS implementation used Apollo NCS for its remote procedure calls. NCS is the base technology for OSF DCE remote procedure calls [69]. However, since NCS and DCE are not widely available yet, we modified the RPC functions in MDARTS to use Sun RPC <ref> [10] </ref>. via RPC. The functions get ival () and set ival () (called on lines 5 and 9, respectively) bundle their arguments into the structures used for the Sun RPC client stubs and generate the RPC calls. Manager to service transactions that retrieve integers from MDARTS objects. <p> These task sets were generated in groups of 50 sets for each combination of [3, 6, or 10 processors], [3, 6 or 10 tasks per processor], <ref> [5, 10, or 20 global semaphores] </ref>, [processor utilizations of 0.6 or 0.7], and [constant or varying critical section times for semaphores]. For our schedulability analysis, we used critical zone analysis rather than Eq. (4.1) because it is a more accurate method for determining schedulability.
Reference: [11] <author> G. Booch, </author> <title> Object Oriented Design with Applications, </title> <publisher> The Benjamin/Cummings Publishing Company, Inc., </publisher> <year> 1991. </year>
Reference-contexts: Some objects use remote procedure calls to submit transaction requests to remote MDARTS SDM servers across the network. Other objects could access persistent data in file-based databases (we have not yet implemented persistent objects in MDARTS, but there are many techniques for accessing file-based databases using C++ classes <ref> [11] </ref>). In our current implementation, only shared-memory objects provide guaranteed transaction times. The object-oriented architecture of MDARTS has been crucial to the success of the real-time constraint implementation effort. MDARTS is a relatively complex software system, but the programming interface presented to the user is remarkably simple.
Reference: [12] <author> A. P. Buchmann, D. R. McCarthy, M. Hsu, and U. Dayal, </author> <title> "Time-critical database scheduling: A framework for integrating real-time scheduling and concurrency control," </title> <booktitle> in Proc. IEEE Int'l Conf. on Data Engineering, </booktitle> <pages> pp. 470-480, </pages> <month> February </month> <year> 1989. </year>
Reference-contexts: None of the prior work in RTDBSs considers the possibility of application tasks executing transactions themselves. Transaction and I/O Scheduling Several researchers have investigated transaction and I/O scheduling algorithms that support different real-time needs and priorities <ref> [1, 12, 62, 83, 76] </ref>. Some commercial database systems support priority-based transaction scheduling [25, 64]. By servicing high-priority tasks first, the database can provide faster and more predictable performance for transactions submitted by high-priority tasks. In this case, low-priority tasks experience degraded performance. <p> Priority inheritance protocols can also be used to reflect task priorities in distributed transaction execution [67]. Some researchers suggest that serializability should not be used as the primary correctness criterion for real-time concurrency control <ref> [12, 21, 56] </ref>. Lin [48, 49] suggests that, for real-time applications, data inconsistent with the external world can be worse than internally inconsistent data. <p> This temporary priority boost helps lower-priority tasks complete transactions and release their locks. Since the best approach to real-time concurrency control often depends upon the particular application, some researchers advocate hybrid protocols that borrow features of several earlier strategies to perform acceptably for a wider range of applications <ref> [12, 32, 35, 60, 78] </ref>. For example, Huang et al. [35] advocate a hybrid approach in which tasks inherit higher priorities only if they are close to committing. Otherwise, if higher-priority tasks require locks held by low-priority tasks, the lower priority transactions are aborted. <p> Object-oriented database systems often have convenient application programming interfaces, so MDARTS is not unique in this respect. Prior real-time database systems either make deadline guarantees a priori with offline static analysis of applications [74] or use dynamic transaction scheduling to try to meet deadlines at runtime <ref> [12] </ref>. Off-line static analysis has the advantage of providing early feedback if requirements cannot be met. However, off-line analysis of transactions is not always feasible, especially for complex, distributed applications. Dynamic transaction scheduling is a viable alternative for soft real-time systems. <p> The serializability property has been the focus of recent debate in the real-time database community. Serializability is considered indispensable in the non-real-time database community, and some real-time database researchers concur <ref> [12, 55, 28, 29, 41] </ref>. Other real-time researchers consider full serializability too expensive and possibly unnecessary for real-time databases [48, 71].
Reference: [13] <author> M. J. Carey, R. Jauhari, and M. Livny, </author> <title> "Priority in dbms resource scheduling," </title> <booktitle> in Proc. Int'l Conf. on Very Large Data Bases, </booktitle> <pages> pp. 397-410, </pages> <year> 1989. </year> <pages> 126 127 </pages>
Reference-contexts: Furthermore, these main memory database systems do not provide worst-case guarantees for their transactions. Hard real-time systems need worst-case guarantees to ensure that all deadlines will be met. Of the prior real-time database prototypes reported in <ref> [13, 41, 34, 70, 77, 88] </ref>, none provides hard real-time guarantees, and none has average transaction times of less than 100 milliseconds. Thus, these database systems are not suitable for high-speed hard real-time systems such as machine tool controllers.
Reference: [14] <author> R. N. Chang and C. V. Ravishankar, </author> <title> "A service acquisition mechanism for the client/service model in cygnus," </title> <booktitle> in Proc. Int'l Conf. on Distributed Computing Systems, </booktitle> <pages> pp. 90-97, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: Contracts are evaluated at runtime during server object initialization. Our approach resembles service specification and acquisition in distributed computing systems <ref> [14, 63] </ref>, except our server objects are much lighter-weight and are constructed from local libraries rather than remote server processes. If no server objects in the library can meet the requirements of the contract, then the library can set an error flag or throw an exception. <p> MDARTS allows applications to make their requirements explicit in the contracts processed by the object constructors. Prior work on dynamic server selection through runtime service specification has been at the level of network services rather than local objects within processes <ref> [14] </ref>. By providing a mechanism for customizing object creation according to application needs, MDARTS can enhance performance without requiring application programmers to 123 124 know exactly which database class to use.
Reference: [15] <author> S. C. Cheng and J. A. Stankovic, </author> <title> "Scheduling algorithms for hard real-time systems: A brief survey," in IEEE Tutorial: Hard Real-Time Systems, </title> <editor> J. Stankovic and K. Ra-mamritham, editors, </editor> <publisher> IEEE Computer Society Press, </publisher> <year> 1988. </year>
Reference-contexts: Rate monotonic scheduling is an optimal algorithm for static (pre-assigned) task priorities. Various other dynamic priority scheduling protocols have also been studied (earliest due date, least slack time, etc. <ref> [15] </ref>). Rate monotonic scheduling is the most popular scheduling method for practical real-time systems, since it is easy to analyze and more robust under overload conditions than dynamic scheduling approaches.
Reference: [16] <author> J. O. Coplien, </author> <title> Advanced C++ Programming Styles and Idioms, </title> <publisher> Addison Wesley, </publisher> <year> 1992. </year>
Reference-contexts: While exemplars in Self form the basis of a complete programming paradigm, exemplars can be useful in a class-based object-oriented context as well. Coplien illustrates the use of exemplar-based programming in C++ <ref> [16] </ref>. In our implementation, we combine software contracts with Coplien's autonomous generic exemplar idiom (in which exemplars register themselves with a base class and object construction requests iterate over the exemplars). Exemplars are special, one-per-class objects that are prototype representatives of an entire class. <p> By declaring a static pointer to the exemplar in the server class, C++ static member initialization can be used to automatically construct and register exactly one exemplar per class. This technique is borrowed from Coplien <ref> [16] </ref>. Each server class need only recognize a subset of the constraints defined by the server base class.
Reference: [17] <author> I. J. Cox, </author> <title> "C++ language support for guaranteed initialization, safe termination and error recovery in robotics," </title> <booktitle> in Proc. IEEE Int'l Conf. on Robotics and Automation, </booktitle> <volume> volume 1, </volume> <pages> pp. 641-643, </pages> <year> 1988. </year>
Reference-contexts: We chose C++ because of its wide availability, runtime efficiency, compatibility with C, and object-oriented features. 24 Some advantages of C++ for real-time software are discussed in the literature <ref> [18, 17] </ref>. To enhance the portability of our implementation, we use only standard features of C++ rather than adding language extensions. It is beyond the scope of this dissertation to fully describe the C++ language. It is a very popular language with dozens of excellent reference books available.
Reference: [18] <author> I. J. Cox, D. A. Kapilow, W. J. Kropfl, and J. E. Shopiro, </author> <title> "Real-time software for robotics," </title> <journal> AT&T Technical Journal, </journal> <volume> vol. 67, no. 2, </volume> <pages> pp. 61-71, </pages> <month> March/April </month> <year> 1988. </year>
Reference-contexts: We chose C++ because of its wide availability, runtime efficiency, compatibility with C, and object-oriented features. 24 Some advantages of C++ for real-time software are discussed in the literature <ref> [18, 17] </ref>. To enhance the portability of our implementation, we use only standard features of C++ rather than adding language extensions. It is beyond the scope of this dissertation to fully describe the C++ language. It is a very popular language with dozens of excellent reference books available.
Reference: [19] <author> T. S. Craig, </author> <title> "Queueing spin lock algorithms to support timing predictability," </title> <booktitle> in Proc. Real-Time Systems Symposium, </booktitle> <pages> pp. 148-157, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: LCScount depends on the locking and queueing protocol implemented by the lock and upon the number and distribution of objects sharing it. We have implemented a spinlock queue lock that uses a simple FIFO queueing strategy. The literature contains several examples of implementing such locks on shared-memory multiprocessors, e.g., <ref> [3, 19] </ref>. A transaction requests a lock by invoking the lock's getLock () method. Just before enqueuing a transaction, getLock () disables task preemption. This means that while executing the critical section or while waiting for the lock, the transaction effectively acquires the highest execution priority in the system. <p> Instead, it is notified by the task immediately ahead of it when its transaction number comes up. The design of these spinlocks is a bit tricky, but several good examples can be found in the literature (for example, <ref> [3, 19, 30] </ref>). This algorithm assumes that no more than MAX NUM MACHINES tasks will attempt to enter the lock. Since we disable task preemptions, this assumption is valid. Since the performance of MDARTS transactions is so dependent on the concurrency control implementation, we experimented with two other spinlock implementations.
Reference: [20] <author> D. Detlefs, M. Herlihy, and J. Wing, </author> <title> "Inheritance of synchronization and recovery properties in Avalon/C++," </title> <journal> IEEE Computer, </journal> <volume> vol. 21, no. 12, </volume> <pages> pp. 57-69, </pages> <month> December </month> <year> 1988. </year>
Reference-contexts: It is also possible to implement atomicity in a base class and inherit this property in derived subclasses <ref> [20] </ref>. MDARTS shared-memory objects differ from atomic data types and semantic concurrency control techniques described in the literature in that MDARTS objects are fragmented across multiple separate processes. The shared data structures, including lock information needed to synchronize access, are the only parts of the objects kept in shared memory.
Reference: [21] <author> L. B. C. DiPippo and V. F. Wolfe, </author> <title> "Object-based semantic real-time concurrency control," </title> <booktitle> in Proc. Real-Time Systems Symposium, </booktitle> <pages> pp. 87-96, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: Priority inheritance protocols can also be used to reflect task priorities in distributed transaction execution [67]. Some researchers suggest that serializability should not be used as the primary correctness criterion for real-time concurrency control <ref> [12, 21, 56] </ref>. Lin [48, 49] suggests that, for real-time applications, data inconsistent with the external world can be worse than internally inconsistent data. <p> Therefore, the locking granularity should be tuned to transaction characteristics. Semantic and object-based concurrency control protocols extend this idea by characterizing which transactions conflict and thus require serialization <ref> [7, 21, 40] </ref>. Another approach to reducing locking conflicts is to design transaction protocols that use data versioning to avoid locking altogether [79, 86, 90, 91]. MDARTS objects can use similar techniques in providing concurrency control for their transaction methods. <p> CHAOS and MO2 share this problem. MDARTS has a more flexible approach that provides support for benchmarking execution times and scaling timing estimates to the performance of the execution platform at runtime (see Section 2.7). DiPippo and Wolfe have developed an extensive object-oriented model for real-time databases called RTSORAC <ref> [21] </ref>. Their model includes object-based semantic concurrency control, temporal scopes for object methods (temporal scopes specify very fine-grained timing information about each method), temporal consistency constraints, inter-object transaction constraints, and imprecision constraints. <p> Furthermore, processing deadline information adds additional overhead and complexity to transaction processing. This overhead in turn reduces the performance of the database system. DiP-ippo and Wolfe <ref> [21] </ref> present an object-based RTDB model in which object methods are specified with worst-case execution times and temporal scopes defining the timing behavior of subsequences of statements within the method. <p> By checking requirements during initialization rather than during transac 35 Constraint type access time persistence staleness concurrency Specification "write&lt;=80usec; read<=50usec" "volatile" "stale&lt;=20msec" "exclusive_update" tion execution, problems are detected early, and overhead during transaction processing is reduced. Recent work by Badrinath and Ramamritham [7] and DiPippo and Wolfe <ref> [21] </ref> propose concurrency control techniques that use the semantics of object methods to increase the level of concurrency supported by database objects. The semantic information used by these techniques is limited to the state of the object and knowledge about the compatibility of the object's methods. <p> Therefore, many researchers have investigated alternative concurrency control strategies for RTDBSs. 2.10.1 Design MDARTS can support multiple concurrency control protocols by encapsulating concur-rency control in the implementation of the object methods that perform transactions. This approach, which is similar to that of DiPippo and Wolfe <ref> [21] </ref>, permits each database class to use whatever protocol best fits the semantics of the data it manages. Through exemplar-based object construction, MDARTS can also match application-specified semantics with concurrency control strategies of different database classes. <p> Since the concurrency control can be individually tailored according to the semantics of the class member functions, it is possible to achieve higher levels of concurrency than with traditional read-write locking <ref> [21, 72, 93] </ref>. It is also possible to implement atomicity in a base class and inherit this property in derived subclasses [20]. MDARTS shared-memory objects differ from atomic data types and semantic concurrency control techniques described in the literature in that MDARTS objects are fragmented across multiple separate processes.
Reference: [22] <author> R. Elmasri and S. B. Navathe, </author> <title> Fundamentals of Database Systems, </title> <address> Ben-jamin/Cummings, </address> <year> 1989. </year>
Reference-contexts: According to Elmasri and Navathe, "The execution of a program that accesses or changes the contents of the database is called a transaction" <ref> [22] </ref>. Traditional properties of transactions (the so-called ACID properties) include atomicity, consistency preservation, isolation, and durability. Atomicity means the transaction is either completely performed or not at all. Consistency preservation means the transaction transforms the database from one consistent state to another.
Reference: [23] <author> H. Garcia-Molina and K. Salem, </author> <title> "Main memory database systems: An overview," </title> <journal> IEEE Trans. Knowledge and Data Engineering, </journal> <volume> vol. 4, no. 6, </volume> <pages> pp. 509-516, </pages> <month> December </month> <year> 1992. </year>
Reference-contexts: In the future, we expect conventional database performance to improve, but by then high-speed real-time applications will require even greater performance. It is possible to improve database performance by keeping the database in memory and avoiding disk I/O during transaction processing <ref> [23] </ref>. However, conventional main memory databases are designed to maximize average throughput, not to minimize individual transaction times. <p> Main Memory Databases Some RTDBS researchers propose using main memory databases to eliminate blocking time uncertainties associated with disk I/O during database transactions [71, 80]. There has also been significant interest recently in using main memory databases to increase performance for conventional transaction processing systems <ref> [4, 23, 42, 45] </ref>. Garcia-Molina 5 and Salem present a nice overview of main memory database research in [23]. <p> There has also been significant interest recently in using main memory databases to increase performance for conventional transaction processing systems [4, 23, 42, 45]. Garcia-Molina 5 and Salem present a nice overview of main memory database research in <ref> [23] </ref>. The primary limitation of conventional main memory database systems, from the perspective of hard real-time applications, is that these database systems are designed to maximize average transaction throughput rather than to minimize worst-case individual transaction times. <p> The TPK main memory database system provides serializability without locking by exe 7 cuting transactions serially in a single database server task. In main memory databases, it is common to achieve serializability by simply using serial transaction execution <ref> [23] </ref>. On a multiprocessor, this is usually accomplished with a database server that serially executes client transaction requests. Disk-based databases cannot afford to use serial transaction scheduling since all transactions would be delayed during I/O operations.
Reference: [24] <author> M. R. Garey and D. S. Johnson, </author> <title> Computer and intractability: A guide to the theory of NP-completeness, </title> <publisher> Freeman, </publisher> <address> San Francisco, </address> <year> 1979. </year>
Reference-contexts: Checking whether task deadlines are guaranteed can be performed in polynomial time by calculating the blocking factors for each task o i using fP i;S g, as described in Section 4.3, and applying Eq. (4.1) or critical zone analysis. We now show that SQPA-RMS is NP-hard by reducing PARTITION <ref> [24] </ref> to an instance of SQPA-RMS. Suppose that we have a multiprocessor with 3 processors. Processor -1 will be assigned a task that uses all n global semaphores but has a low utilization so that it can always tolerate the lowest semaphore queue priority (priority 1). <p> In reality, one often needs to solve both problems: first task allocation and then semaphore queue priority assignment. Since the problem of allocating tasks to processors on a multiprocessor is known to be NP-complete <ref> [24] </ref> even when no resource sharing (other than processors) is considered, there is no computationally efficient solution for this problem (unless P=NP). The potential for blocking on semaphore queues adds another level of complexity to an already very difficult problem.
Reference: [25] <author> GDX. </author> <title> sales literature of Firmware Associates, </title> <publisher> Inc., </publisher> <address> West Chester, PA, </address> <year> 1992. </year>
Reference-contexts: None of the prior work in RTDBSs considers the possibility of application tasks executing transactions themselves. Transaction and I/O Scheduling Several researchers have investigated transaction and I/O scheduling algorithms that support different real-time needs and priorities [1, 12, 62, 83, 76]. Some commercial database systems support priority-based transaction scheduling <ref> [25, 64] </ref>. By servicing high-priority tasks first, the database can provide faster and more predictable performance for transactions submitted by high-priority tasks. In this case, low-priority tasks experience degraded performance. File-based databases in particular can benefit from transaction and I/O scheduling according to priorities.
Reference: [26] <author> P. Gopinath and K. Schwan, </author> <title> ""CHAOS:Why One Cannot Have Only an Operating System for Real-Time Applications"," </title> <journal> SIGOPS, </journal> <volume> vol. 23, no. 3, </volume> <pages> pp. 106-125, </pages> <year> 1989. </year>
Reference-contexts: Data and method encapsulation facilitates the mapping of software objects to physical objects and mechanisms that have internal state. By associating a computation with the context of an object's encapsulated state, higher-level application software need not explicitly maintain implementation-specific state information. CHAOS <ref> [26, 27, 65] </ref>, Maruti [44, 54], and ARTS [87] provide support for real-time objects at the kernel level of an operating system. ARTS supports real-time objects with lightweight threads and multiple task scheduling policies. A major emphasis in ARTS is the provision of exception handling if deadlines are violated.
Reference: [27] <author> P. Gopinath, R. Ramnath, and K. Schwan, </author> <title> "Data base design for real-time adaptations," </title> <journal> J. Systems Software, </journal> <volume> vol. 17, no. 1, </volume> <pages> pp. 155-167, </pages> <year> 1992. </year>
Reference-contexts: Data and method encapsulation facilitates the mapping of software objects to physical objects and mechanisms that have internal state. By associating a computation with the context of an object's encapsulated state, higher-level application software need not explicitly maintain implementation-specific state information. CHAOS <ref> [26, 27, 65] </ref>, Maruti [44, 54], and ARTS [87] provide support for real-time objects at the kernel level of an operating system. ARTS supports real-time objects with lightweight threads and multiple task scheduling policies. A major emphasis in ARTS is the provision of exception handling if deadlines are violated.
Reference: [28] <author> M. H. Graham, </author> <title> "Issues in real-time data management," </title> <journal> Journal of Real-Time Systems, </journal> <volume> vol. 4, no. 3, </volume> <pages> pp. 185-202, </pages> <month> September </month> <year> 1992. </year>
Reference-contexts: Epsilon serializability [61] is another alternative to traditional serializability proposed for real-time transactions. The problem with relaxing consistency constraints such as serializability is that it can be more difficult to demonstrate the correctness of transactions. We agree with Graham <ref> [28, 29] </ref>, who argues that serializability is indispensable as a correctness criterion for concurrent transactions. Furthermore, serializability is not necessarily expensive to achieve. In [29], Graham presents some techniques for verifying the serializabil-ity of transactions by analyzing the read and write operations of concurrent transactions. <p> The serializability property has been the focus of recent debate in the real-time database community. Serializability is considered indispensable in the non-real-time database community, and some real-time database researchers concur <ref> [12, 55, 28, 29, 41] </ref>. Other real-time researchers consider full serializability too expensive and possibly unnecessary for real-time databases [48, 71].
Reference: [29] <author> M. H. Graham, </author> <title> "How to get serializability for real-time transactions without having to pay for it," </title> <booktitle> in Proc. Real-Time Systems Symposium, </booktitle> <pages> pp. 56-65, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: Epsilon serializability [61] is another alternative to traditional serializability proposed for real-time transactions. The problem with relaxing consistency constraints such as serializability is that it can be more difficult to demonstrate the correctness of transactions. We agree with Graham <ref> [28, 29] </ref>, who argues that serializability is indispensable as a correctness criterion for concurrent transactions. Furthermore, serializability is not necessarily expensive to achieve. In [29], Graham presents some techniques for verifying the serializabil-ity of transactions by analyzing the read and write operations of concurrent transactions. <p> We agree with Graham [28, 29], who argues that serializability is indispensable as a correctness criterion for concurrent transactions. Furthermore, serializability is not necessarily expensive to achieve. In <ref> [29] </ref>, Graham presents some techniques for verifying the serializabil-ity of transactions by analyzing the read and write operations of concurrent transactions. The TPK main memory database system provides serializability without locking by exe 7 cuting transactions serially in a single database server task. <p> The serializability property has been the focus of recent debate in the real-time database community. Serializability is considered indispensable in the non-real-time database community, and some real-time database researchers concur <ref> [12, 55, 28, 29, 41] </ref>. Other real-time researchers consider full serializability too expensive and possibly unnecessary for real-time databases [48, 71].
Reference: [30] <author> G. Graunke and S. Thakkar, </author> <title> "Synchronization algorthms for shared-memory multiprocessors," </title> <journal> Computer, </journal> <volume> vol. 23, </volume> <pages> pp. 60-69, </pages> <month> June </month> <year> 1990. </year> <month> 128 </month>
Reference-contexts: Instead, it is notified by the task immediately ahead of it when its transaction number comes up. The design of these spinlocks is a bit tricky, but several good examples can be found in the literature (for example, <ref> [3, 19, 30] </ref>). This algorithm assumes that no more than MAX NUM MACHINES tasks will attempt to enter the lock. Since we disable task preemptions, this assumption is valid. Since the performance of MDARTS transactions is so dependent on the concurrency control implementation, we experimented with two other spinlock implementations.
Reference: [31] <author> C.-C. Han and K.-J. Lin, </author> <title> "Scheduling jobs with temporal consistency constraints," </title> <booktitle> in Sixth IEEE Workshop on Real-Time Operating Systems and Software, </booktitle> <pages> pp. 18-23, </pages> <year> 1989. </year>
Reference-contexts: Thus, temporal consistency may be a semantic requirement for a real-time database. Temporal consistency could be achieved by adding constraints to transaction scheduling so that time correlation of data values is maintained <ref> [31, 62] </ref>. No current sched-ulers employ this technique, but Liu and Song [81] use temporal correlation as a criterion to evaluate scheduling algorithms.
Reference: [32] <author> J. R. Haritsa, M. J. Carey, and M. Livny, </author> <title> "Data access scheduling in firm real-time database systems," </title> <journal> Journal of Real-Time Systems, </journal> <volume> vol. 4, no. 3, </volume> <pages> pp. 203-241, </pages> <month> September </month> <year> 1992. </year>
Reference-contexts: Nishio et al. advocate a cautious transaction scheduling approach that checks for non-serializable execution as it executes transactions [56]. This cautious approach performs better than 2PL, and it never aborts or rolls back transactions to achieve concurrency control. Haritsa et al. <ref> [32] </ref> and Lee and Son [41] advocate various optimistic concurrency control protocols which proceed with transactions and only check for serialization problems at commit time. <p> This temporary priority boost helps lower-priority tasks complete transactions and release their locks. Since the best approach to real-time concurrency control often depends upon the particular application, some researchers advocate hybrid protocols that borrow features of several earlier strategies to perform acceptably for a wider range of applications <ref> [12, 32, 35, 60, 78] </ref>. For example, Huang et al. [35] advocate a hybrid approach in which tasks inherit higher priorities only if they are close to committing. Otherwise, if higher-priority tasks require locks held by low-priority tasks, the lower priority transactions are aborted.
Reference: [33] <author> R. Helm and Y. S. Maarek, </author> <title> "Integrating information retrieval and domain specific approaches for browsing and retrieval in object-oriented class libraries," </title> <booktitle> in Proc. of OOPSLA, </booktitle> <pages> pp. 47-61, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: Therefore, the space-time tradeoffs of alternative class implementations are more likely to become critical issues in real-time systems. Class browsing tools are often proposed to assist application writers in selecting classes <ref> [33] </ref>, but these tools still expose the full complexity of the class hierarchy. Applications that use specific subclasses in a customized class hierarchy can become dependent on the internal class structure of the library. <p> Eiffel also supports the related concept of class invariants, which can be considered contracts specifying consistency between base classes and derived classes in an inheritance hierarchy. Helm et al. propose a higher-level use of the contract metaphor in which contracts specify roles and interactions between cooperating objects <ref> [33] </ref>. Applications instantiate contracts at runtime by selecting classes for the various roles. Like the software contracts described by Wirfs-Brock et al. [94] and Meyer [52], our contracts apply constraints to individual objects rather than behavioral compositions as in Helm et al. [33]. <p> contracts specify roles and interactions between cooperating objects <ref> [33] </ref>. Applications instantiate contracts at runtime by selecting classes for the various roles. Like the software contracts described by Wirfs-Brock et al. [94] and Meyer [52], our contracts apply constraints to individual objects rather than behavioral compositions as in Helm et al. [33]. However, since the application does not necessarily specify the exact class to which the contract applies, our contracts are more accurately viewed as being between the application and the software library. Furthermore, we distinguish between explicit software contracts and implied software contracts.
Reference: [34] <author> J. Huang, J. A. Stankovic, K. Ramamritham, and D. Towsley, </author> <title> "Experimental evaluation of real-time optimistic concurrency control schemes," </title> <booktitle> in Proc. Int'l Conf. on Very Large Data Bases, </booktitle> <pages> pp. 35-46, </pages> <month> September </month> <year> 1991. </year>
Reference-contexts: Furthermore, these main memory database systems do not provide worst-case guarantees for their transactions. Hard real-time systems need worst-case guarantees to ensure that all deadlines will be met. Of the prior real-time database prototypes reported in <ref> [13, 41, 34, 70, 77, 88] </ref>, none provides hard real-time guarantees, and none has average transaction times of less than 100 milliseconds. Thus, these database systems are not suitable for high-speed hard real-time systems such as machine tool controllers. <p> Haritsa et al. [32] and Lee and Son [41] advocate various optimistic concurrency control protocols which proceed with transactions and only check for serialization problems at commit time. Huang et al. <ref> [34] </ref>, however, dispute some of the conclusions of Haritsa et al. and observe that overhead associated with implementing optimistic concurrency control can reduce its performance advantages. Some researchers have investigated concurrency control algorithms for distributed real-time databases.
Reference: [35] <author> J. Huang, J. A. Stankovic, K. Ramamritham, D. Towsley, and B. Purimetla, </author> <title> "Priority inheritance in soft real-time databases," </title> <journal> Journal of Real-Time Systems, </journal> <volume> vol. 4, no. 3, </volume> <pages> pp. 243-268, </pages> <month> September </month> <year> 1992. </year>
Reference-contexts: This temporary priority boost helps lower-priority tasks complete transactions and release their locks. Since the best approach to real-time concurrency control often depends upon the particular application, some researchers advocate hybrid protocols that borrow features of several earlier strategies to perform acceptably for a wider range of applications <ref> [12, 32, 35, 60, 78] </ref>. For example, Huang et al. [35] advocate a hybrid approach in which tasks inherit higher priorities only if they are close to committing. Otherwise, if higher-priority tasks require locks held by low-priority tasks, the lower priority transactions are aborted. <p> Since the best approach to real-time concurrency control often depends upon the particular application, some researchers advocate hybrid protocols that borrow features of several earlier strategies to perform acceptably for a wider range of applications [12, 32, 35, 60, 78]. For example, Huang et al. <ref> [35] </ref> advocate a hybrid approach in which tasks inherit higher priorities only if they are close to committing. Otherwise, if higher-priority tasks require locks held by low-priority tasks, the lower priority transactions are aborted. <p> Very few actual real-time database implementations are described in the literature, and most of those are testbeds designed for studying algorithms rather than for supporting realistic real-time applications <ref> [35, 77] </ref>. Furthermore, to our knowledge, none of the RTDBS implementations reported in the literature are intended for hard real-time applications such as machine controllers. <p> Furthermore, if the aborted transaction were close to committing, substantial processing resources could be wasted in forcing the transaction to start over. This issue is considered by Huang et al. in <ref> [35] </ref>. Unconstrained application-defined transactions may or may not be acceptable in the context of soft real-time systems such as considered in [35], but to provide hard real-time guarantees, a database system must tightly control transaction execution. Therefore, MDARTS transactions are modeled as object method invocations (function calls). <p> This issue is considered by Huang et al. in <ref> [35] </ref>. Unconstrained application-defined transactions may or may not be acceptable in the context of soft real-time systems such as considered in [35], but to provide hard real-time guarantees, a database system must tightly control transaction execution. Therefore, MDARTS transactions are modeled as object method invocations (function calls). An application can provide parameters to the transactions, and a transaction can perform relatively complex computations.
Reference: [36] <author> Y. Ishikawa, H. Tokuda, and C. W. Mercer, </author> <title> "An object-oriented real-time programming language," </title> <journal> IEEE Computer, </journal> <volume> vol. 25, no. 10, </volume> <pages> pp. 66-73, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: Clearly, these transactions will not be serialized. Furthermore, if applications share large amounts of data, it is expensive to copy it between the local and 12 global state tables each cycle. Ishikawa et al. <ref> [36] </ref> describe a real-time extension of C++ called RTC++. RTC++ active objects define periodic tasks with multiple threads. Object methods can include declarations of their execution times, and these execution times can be used to perform schedu-lability analysis of task sets. Concurrency control is implemented in the object methods. <p> A similar problem is addressed in the RTC++ language <ref> [36] </ref>. In RTC++, the designer of a real-time class specifies the worst-case execution time bound of each method in the class definition. An example given in [36] is: int m33 (float f) bound (0t30m);. This declaration specifies a 30 millisecond bound for the method m33. <p> A similar problem is addressed in the RTC++ language <ref> [36] </ref>. In RTC++, the designer of a real-time class specifies the worst-case execution time bound of each method in the class definition. An example given in [36] is: int m33 (float f) bound (0t30m);. This declaration specifies a 30 millisecond bound for the method m33. This method of determining performance has three serious limitations. First, it requires the class developer to determine the execution time bound "by hand" using some unspecified method. <p> The most common approach to bounding semaphore wait times is to use variants of the priority inheritance protocol (e.g., basic priority inheritance, priority ceiling protocol, semaphore control protocol, kernel priority protocol [59]) to limit wait times due to lower-priority tasks <ref> [36, 58, 60, 68] </ref>. These protocols temporarily boost the priorities of tasks that are executing critical sections to ensure that they can complete the critical sections within a short, predictable time. This in turn bounds the blocking delays of other tasks that wait for the resources.
Reference: [37] <author> D. Jordan, </author> <title> "Instantiation of C++ objects in shared memory," </title> <journal> Journal of Object-Oriented Programming, </journal> <pages> pp. 21-28, </pages> <month> March/April </month> <year> 1991. </year>
Reference-contexts: In C++, objects usually contain pointers to functions (most often in the form of a pointer to a virtual function table). In general, these functions will be loaded at different addresses in each process, so no single function pointer will be valid for all processes. Jordan <ref> [37] </ref> discusses this problem and presents an approach to instantiating C++ objects in shared memory. Unfortunately, Jordan's methods rely on virtual memory and will not work for real-time operating systems, such as VME-based VxWorks, that do not support virtual memory.
Reference: [38] <author> D. D. Kandlur and K. G. Shin, </author> <title> "Design of a communication subsystem for HARTS," </title> <type> Technical Report CSE-TR-109-91, </type> <institution> CSE Division, Department of EECS, The University of Michigan, </institution> <month> October </month> <year> 1991. </year>
Reference-contexts: This behavior is useful since it prevents unsuspecting applications from performing operations that might cause them to miss their deadlines. If we were using networking protocols that provided end-to-end response time guarantees, MDARTS could be enhanced to also guarantee transaction times for proxy objects <ref> [38] </ref>. However, this would still not be entirely trivial since the scheduling of RPC requests in the SDM would have to be considered. To do this, the SDM would need to have sufficient execution time to service remote requests.
Reference: [39] <author> W. Kim and J. Srivastava, </author> <title> "Enhancing real-time dbms performance with multiversion data and priority based disk scheduling," </title> <booktitle> in Proc. Real-Time Systems Symposium, </booktitle> <pages> pp. 222-231, </pages> <month> December </month> <year> 1991. </year>
Reference-contexts: However, MDARTS currently does not support application-defined transactions that span multiple database operations. We do not believe that such transactions can be supported in hard real-time systems without sacrificing serializability. In the future we may investigate providing limited support for more complex transactions, perhaps using data versioning <ref> [39] </ref>, but we have not yet developed a model of such transactions or tried to implement one within MDARTS. With the current MDARTS transaction model, it is possible to guarantee transaction times while supporting atomicity, consistency, isolation, and serializability. <p> To implement concurrency control in MDARTS we propose the following principles. Our current implementation reflects all of these ideas except data versioning. Avoid unnecessary locking. When possible, use data versioning <ref> [39, 79] </ref> or multiple data copies [90] to permit concurrent read and write operations without locking. Match locking granularity with data semantics. This ensures that locking does not unnecessarily restrict concurrency.
Reference: [40] <author> T.-W. Kuo and A. K. Mok, </author> <title> "Ssp: a semantics-based protocol for real-time data access," </title> <booktitle> in Proc. Real-Time Systems Symposium, </booktitle> <pages> pp. 76-86, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: Lin does not explain how a database system should choose trade-offs between internal and external consistency. Clearly, these trade-offs would depend heavily on the particular application. Kuo and Mok <ref> [40] </ref> introduce a correctness criterion for concurrent transactions which permits unserialized transactions if the data values read and generated by those transactions are sufficiently similar. Epsilon serializability [61] is another alternative to traditional serializability proposed for real-time transactions. <p> Therefore, the locking granularity should be tuned to transaction characteristics. Semantic and object-based concurrency control protocols extend this idea by characterizing which transactions conflict and thus require serialization <ref> [7, 21, 40] </ref>. Another approach to reducing locking conflicts is to design transaction protocols that use data versioning to avoid locking altogether [79, 86, 90, 91]. MDARTS objects can use similar techniques in providing concurrency control for their transaction methods.
Reference: [41] <author> J. Lee and S. H. Son, </author> <title> "Using dynamic adjustment of serialization order for real-time database systems," </title> <booktitle> in Proc. Real-Time Systems Symposium, </booktitle> <pages> pp. 66-75, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: Furthermore, these main memory database systems do not provide worst-case guarantees for their transactions. Hard real-time systems need worst-case guarantees to ensure that all deadlines will be met. Of the prior real-time database prototypes reported in <ref> [13, 41, 34, 70, 77, 88] </ref>, none provides hard real-time guarantees, and none has average transaction times of less than 100 milliseconds. Thus, these database systems are not suitable for high-speed hard real-time systems such as machine tool controllers. <p> Nishio et al. advocate a cautious transaction scheduling approach that checks for non-serializable execution as it executes transactions [56]. This cautious approach performs better than 2PL, and it never aborts or rolls back transactions to achieve concurrency control. Haritsa et al. [32] and Lee and Son <ref> [41] </ref> advocate various optimistic concurrency control protocols which proceed with transactions and only check for serialization problems at commit time. Huang et al. [34], however, dispute some of the conclusions of Haritsa et al. and observe that overhead associated with implementing optimistic concurrency control can reduce its performance advantages. <p> The serializability property has been the focus of recent debate in the real-time database community. Serializability is considered indispensable in the non-real-time database community, and some real-time database researchers concur <ref> [12, 55, 28, 29, 41] </ref>. Other real-time researchers consider full serializability too expensive and possibly unnecessary for real-time databases [48, 71]. <p> Priority-based transaction processing protocols do not guarantee the transaction times. They only guarantee that higher-priority transactions will receive preferential service. Interestingly, in some cases, priority-insensitive optimistic concurrency control algorithms can outperform priority-cognizant transaction scheduling in the sense that fewer deadlines are missed as the transaction load increases <ref> [41] </ref>. Unfortunately, neither priority-based transaction processing nor optimistic concurrency control algorithms are particularly suitable for hard real-time applications. These protocols cannot prevent transaction overload conditions in which more transactions are submitted to the database than can be scheduled without missing deadlines.
Reference: [42] <author> T. J. Lehman, E. J. Shekita, and L.-F. Cabrera, </author> <title> "An evaluation of starburst's memory resident storage component," </title> <journal> IEEE Trans. Knowledge and Data Engineering, </journal> <volume> vol. 4, no. 6, </volume> <pages> pp. 555-565, </pages> <month> December </month> <year> 1992. </year>
Reference-contexts: However, conventional main memory databases are designed to maximize average throughput, not to minimize individual transaction times. Typical average transactions times for simple transactions in main memory databases (600 milliseconds for TPK [45], about 69 milliseconds for the main memory version of Starburst with concurrency control disabled <ref> [42] </ref>, over 100 milliseconds for PRISMA/DB 1 2 [4]) are much too slow for high-speed real-time systems. Furthermore, these main memory database systems do not provide worst-case guarantees for their transactions. Hard real-time systems need worst-case guarantees to ensure that all deadlines will be met. <p> Main Memory Databases Some RTDBS researchers propose using main memory databases to eliminate blocking time uncertainties associated with disk I/O during database transactions [71, 80]. There has also been significant interest recently in using main memory databases to increase performance for conventional transaction processing systems <ref> [4, 23, 42, 45] </ref>. Garcia-Molina 5 and Salem present a nice overview of main memory database research in [23].
Reference: [43] <author> J. P. Lehoczky, L. Sha, and J. K. Strosnider, </author> <title> "Enhanced aperiodic responsiveness in hard real-time environments," </title> <booktitle> in Proc. Real-Time Systems Symposium, </booktitle> <pages> pp. 261-270, </pages> <month> December </month> <year> 1987. </year>
Reference-contexts: A job corresponds to a sequence of instructions that would continuously use the processor until the job finishes if the job were running alone on the processor. Aperiodic tasks can be accommodated within this framework through use of a periodic server <ref> [43] </ref>. In general, deadline-driven scheduling protocols, which determine execution priorities dynamically, can guarantee higher utilizations than rate monotonic scheduling. However, dynamic priority algorithms are more complex to implement and less stable under overload conditions.
Reference: [44] <author> S. T. Levi, S. K. Tripathi, S. D. Carson, and A. K. Agrawala, </author> <title> "The MARUTI hard real-time operating system," </title> <journal> ACM Operating System Review, </journal> <volume> vol. 23, no. 3, </volume> , <month> June </month> <year> 1989. </year>
Reference-contexts: Data and method encapsulation facilitates the mapping of software objects to physical objects and mechanisms that have internal state. By associating a computation with the context of an object's encapsulated state, higher-level application software need not explicitly maintain implementation-specific state information. CHAOS [26, 27, 65], Maruti <ref> [44, 54] </ref>, and ARTS [87] provide support for real-time objects at the kernel level of an operating system. ARTS supports real-time objects with lightweight threads and multiple task scheduling policies. A major emphasis in ARTS is the provision of exception handling if deadlines are violated.
Reference: [45] <author> K. Li and J. F. Naughton, </author> <title> "Multiprocessor main memory transaction processing," </title> <booktitle> in Proc. IEEE Int'l Symp. on Databases in Parallel and Distributed Systems, </booktitle> <pages> pp. 177-187, </pages> <month> December </month> <year> 1988. </year> <month> 129 </month>
Reference-contexts: However, conventional main memory databases are designed to maximize average throughput, not to minimize individual transaction times. Typical average transactions times for simple transactions in main memory databases (600 milliseconds for TPK <ref> [45] </ref>, about 69 milliseconds for the main memory version of Starburst with concurrency control disabled [42], over 100 milliseconds for PRISMA/DB 1 2 [4]) are much too slow for high-speed real-time systems. Furthermore, these main memory database systems do not provide worst-case guarantees for their transactions. <p> Main Memory Databases Some RTDBS researchers propose using main memory databases to eliminate blocking time uncertainties associated with disk I/O during database transactions [71, 80]. There has also been significant interest recently in using main memory databases to increase performance for conventional transaction processing systems <ref> [4, 23, 42, 45] </ref>. Garcia-Molina 5 and Salem present a nice overview of main memory database research in [23]. <p> The primary limitation of conventional main memory database systems, from the perspective of hard real-time applications, is that these database systems are designed to maximize average transaction throughput rather than to minimize worst-case individual transaction times. For example, the TPK multiprocessor main memory database system reported in <ref> [45] </ref> achieves an average throughput of over 1,300 transactions per second on a multiprocessor with five one-MIPS processors. If TPK's 1,300 transactions per second corresponded to a guaranteed transaction time of one millisecond, it would be sufficient for many hard real-time systems (especially since much faster processors are now available).
Reference: [46] <author> J. Liedtke, </author> <title> "Improving ipc by kernel design," </title> <booktitle> in Proc. ACM Symp. on Operating Systems Principles, </booktitle> <pages> pp. 175-188, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: For example, by manipulating the virtual memory hardware of the 486 processor and carefully optimizing interactions with the system scheduler, Liedtke was able to reduce worst-case local RPC overhead for short messages (passed in registers) on a 50 MHz 486 uniprocessor to about twelve microseconds (twenty machine instructions) <ref> [46] </ref>. This represents about an order of magnitude speedup over Mach RPC on the same platform. Although inter-process communication latencies can be reduced through hardware support and clever optimizations, they can never be completely eliminated. <p> On our implementation platform, round-trip RPCs consumed several milliseconds between CPUs on the local multiprocessor (we used Sun RPC). The special techniques for minimizing context switch overhead in RPCs described in <ref> [9, 46] </ref> were not available to us in the commercial real-time operating system we used. Therefore, the theoretical limits of RPC overhead was a moot issue for us. On our platform, RPC was expensive. <p> These overhead numbers are realistic: a typical RPC round trip can take several milliseconds, whereas local procedure calls and memory accesses require only a few microseconds. Some high-speed RPC systems can reduce the overhead of transferring data and control between 21 clients and servers <ref> [9, 46] </ref>, but these systems are not widely available, they rely on processor-specific optimizations and low-level kernel modifications, and they do not eliminate the serial bottlenecks of server processes on multiprocessors. In MDARTS, each object supplies the context and identity of its particular data.
Reference: [47] <author> K.-J. Lin, S. Natarajan, and J. W.-S. Liu, </author> <title> "Imprecise results: Utilizing partial computations in real-time systems," </title> <booktitle> in Proc. Real-Time Systems Symposium, </booktitle> <pages> pp. 210-217, </pages> <month> December </month> <year> 1987. </year>
Reference-contexts: Smith and Liu [75] suggest that real-time databases could return approximate values when precise values cannot be computed before the deadline. 8 This is an application of the imprecise computation idea of Lin et al. <ref> [47] </ref>. MDARTS does not directly address temporal consistency issues, but it is possible to design data management classes within the MDARTS framework that provide temporal consistency. Similarly, imprecise computation techniques can be built into MDARTS objects if necessary for a particular application.
Reference: [48] <author> K.-J. Lin, </author> <title> "Consistency issues in real-time database systems," </title> <booktitle> in 22nd Hawaii Int'l Conf. on System Sciences, </booktitle> <month> January </month> <year> 1989. </year>
Reference-contexts: Priority inheritance protocols can also be used to reflect task priorities in distributed transaction execution [67]. Some researchers suggest that serializability should not be used as the primary correctness criterion for real-time concurrency control [12, 21, 56]. Lin <ref> [48, 49] </ref> suggests that, for real-time applications, data inconsistent with the external world can be worse than internally inconsistent data. <p> The serializability property has been the focus of recent debate in the real-time database community. Serializability is considered indispensable in the non-real-time database community, and some real-time database researchers concur [12, 55, 28, 29, 41]. Other real-time researchers consider full serializability too expensive and possibly unnecessary for real-time databases <ref> [48, 71] </ref>. Since many of the traditional ACID transaction properties may be expensive or infeasible to provide in the context of a real-time database, it may be desirable to limit or trade off various transaction properties.
Reference: [49] <author> K.-J. Lin and M.-J. Lin, </author> <title> "Enhancing availability in distributed real-time databases," </title> <booktitle> SIGMOD Record, </booktitle> <volume> vol. 17, no. 1, </volume> <pages> pp. 34-43, </pages> <month> March </month> <year> 1988. </year>
Reference-contexts: Priority inheritance protocols can also be used to reflect task priorities in distributed transaction execution [67]. Some researchers suggest that serializability should not be used as the primary correctness criterion for real-time concurrency control [12, 21, 56]. Lin <ref> [48, 49] </ref> suggests that, for real-time applications, data inconsistent with the external world can be worse than internally inconsistent data.
Reference: [50] <author> C. L. Liu and J. W. Layland, </author> <title> "Scheduling algorithms for multiprogramming in a hard real-time environment," </title> <journal> Journal of the ACM, </journal> <volume> vol. 20, no. 1, </volume> <pages> pp. 46-61, </pages> <month> January </month> <year> 1973. </year>
Reference-contexts: If tasks are not preemptible, general schedulability analysis is compu-tationally intractable (NP-complete or NP-hard). However, if tasks are preemptible, it is possible to efficiently determine their schedulability by applying rate monotonic scheduling theory <ref> [50, 59] </ref>. Rate monotonic scheduling is an optimal algorithm for static (pre-assigned) task priorities. Various other dynamic priority scheduling protocols have also been studied (earliest due date, least slack time, etc. [15]). <p> From the perspective of a real-time task, the database transaction should be an atomic operation with a bounded, worst-case execution and blocking time. If the database provides this level of predictability, the task scheduler can guarantee higher-level task deadlines through a straightforward application of well-known real-time scheduling theory <ref> [50] </ref>. Guaranteeing each transaction's execution time also helps applications estimate the latency of tasks that perform database operations. This capability can be very important for systems in which the response time to events is critical. Some real-time database researchers emphasize maintaining temporal consistency constraints in the data itself. <p> We also prove that this priority assignment problem is NP-complete and present a heuristic bin packing algorithm that finds a good solution for most task sets. Early work on scheduling hard real-time systems assumed independence between the tasks to be scheduled <ref> [50] </ref>. However, most real-time systems require inter-task data sharing that violates the independence assumption of early scheduling algorithms. Furthermore, Mok [53] showed that if tasks make unrestricted use of binary semaphores to enforce mutually exclusive access to shared resources, the problem of determining their schedulability is NP-complete. <p> The C i =T i components represent the utilization, or fraction of computation time consumed by task o i . The number i (2 1=i 1) represents a bound on the utilization of the processor below which task deadlines are guaranteed <ref> [50] </ref>. As the number of tasks increases, this bound converges to ln 2, or about 70% utilization. This utilization bound provides only a sufficient condition for schedulability; for most task sets, a more complex method called "critical zone analysis" is able to guarantee higher utilizations with rate monotonic scheduling.
Reference: [51] <institution> Next Generation Workstation / Machine Controller Specification for an Open System Architecture Standard, Martin Marietta Astronautics Group, </institution> <address> NGC-0001-13-000-SYS edition, </address> <month> March </month> <year> 1992. </year>
Reference-contexts: However, as data volume increases and software becomes more complex, ad hoc data management becomes inadequate. The Next Generation Workstation/Machine Controller (NGC) for automated factories is representative of the class of complex, distributed real-time architectures that requires data management services <ref> [2, 51] </ref>. The NGC is a software architecture specification for advanced cell-level machine tool controllers. In this context, cell-level refers to a manufacturing system workcell, which is a factory component that might contain one or more robots, a computer-controlled milling machine, etc. <p> Customized systems are expensive to build and maintain, so efforts are underway to establish standard, open software architectures for advanced manufacturing. The proposed Next Generation Workstation/Machine Controller (NGC) for automated factories <ref> [2, 51] </ref> is representative of the trend toward open software architectures in manufacturing. The NGC is a software architecture specification for advanced cell-level machine tool controllers. The NGC architecture is designed for high-performance real-time computing platforms such as VME-based shared-memory multiprocessors.
Reference: [52] <author> B. Meyer, </author> <title> "Applying "design by contract"," </title> <journal> IEEE Computer, </journal> <volume> vol. 25, no. 10, </volume> <pages> pp. 40-51, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: Meyer discusses this problem and shows how software contracts in Eiffel can detect some types of semantic mismatch at runtime <ref> [52] </ref>. Although Eiffel software contracts help check consistency, they do not help select the server object in the first place. Further 53 54 more, the runtime contract checking in Eiffel adds overhead and slows method execution. <p> Wirfs-Brock et al. define contracts to be the set of methods exported by a server object [94, 95]. In this case, the contract is pure metaphor: a useful perspective on existing structure. The Eiffel language provides support for a more tangible form of software contracts <ref> [52] </ref>. Contracts in Eiffel are constraints on the pre- and post- conditions of functions. These constraints are assertions that check at runtime if applications are using functions correctly. <p> Helm et al. propose a higher-level use of the contract metaphor in which contracts specify roles and interactions between cooperating objects [33]. Applications instantiate contracts at runtime by selecting classes for the various roles. Like the software contracts described by Wirfs-Brock et al. [94] and Meyer <ref> [52] </ref>, our contracts apply constraints to individual objects rather than behavioral compositions as in Helm et al. [33]. However, since the application does not necessarily specify the exact class to which the contract applies, our contracts are more accurately viewed as being between the application and the software library. <p> Furthermore, we distinguish between explicit software contracts and implied software contracts. The implied part of a contract corresponds roughly to the contracts in <ref> [52, 94] </ref>; the explicit part is the subject of this chapter. We base our approach to software contracts on the following analogy with contract law. When a legal contract is established between a service provider and a client, there is both an express and an implied contract. <p> For example, a server object that supports concurrent access could use simplified locking protocols if it knew the application would not perform concurrent update operations. This semantic constraint could be supplied by the application in the contract. Wirfs-Brock et al. [94] and Meyer <ref> [52] </ref> focus on contracts defined by server objects. Since the server dictates all the terms, there is no way for applications to add clauses or establish their own contracts.
Reference: [53] <author> A. K. Mok, </author> <title> "Fundamental design problems of distributed systems for the hard real-time environment," </title> <type> Ph.D thesis, </type> <year> 1983. </year>
Reference-contexts: Early work on scheduling hard real-time systems assumed independence between the tasks to be scheduled [50]. However, most real-time systems require inter-task data sharing that violates the independence assumption of early scheduling algorithms. Furthermore, Mok <ref> [53] </ref> showed that if tasks make unrestricted use of binary semaphores to enforce mutually exclusive access to shared resources, the problem of determining their schedulability is NP-complete. This is because unrestricted semaphore use can force a high-priority task to wait while a low-priority task holds the lock on a resource.
Reference: [54] <author> V. M. Nirkhe, S. K. Tripathi, and A. K. Agrawala, </author> <title> "Language support for the maruti real-time system," </title> <booktitle> in Proc. Real-Time Systems Symposium, </booktitle> <pages> pp. 257-266, </pages> <month> December </month> <year> 1990. </year>
Reference-contexts: Data and method encapsulation facilitates the mapping of software objects to physical objects and mechanisms that have internal state. By associating a computation with the context of an object's encapsulated state, higher-level application software need not explicitly maintain implementation-specific state information. CHAOS [26, 27, 65], Maruti <ref> [44, 54] </ref>, and ARTS [87] provide support for real-time objects at the kernel level of an operating system. ARTS supports real-time objects with lightweight threads and multiple task scheduling policies. A major emphasis in ARTS is the provision of exception handling if deadlines are violated.
Reference: [55] <author> S. Nishio, K. F. Li, and E. G. Manning, </author> <title> "A time-out based resilient token transfer algorithm for mutual exclusion in computer networks," </title> <booktitle> in Proc. Int'l Conf. on Distributed Computing Systems, </booktitle> <pages> pp. 386-393. </pages> <publisher> IEEE, </publisher> <month> June </month> <year> 1989. </year>
Reference-contexts: The serializability property has been the focus of recent debate in the real-time database community. Serializability is considered indispensable in the non-real-time database community, and some real-time database researchers concur <ref> [12, 55, 28, 29, 41] </ref>. Other real-time researchers consider full serializability too expensive and possibly unnecessary for real-time databases [48, 71].
Reference: [56] <author> S. Nishio, S. Taniguchi, and T. Ibaraki, </author> <title> "On the efficiency of cautious schedulers for database concurrency control why insist on two-phase locking?," </title> <journal> Journal of Real-Time Systems, </journal> <volume> vol. 1, </volume> <pages> pp. 177-195, </pages> <year> 1989. </year>
Reference-contexts: Therefore, a significant amount of work has been done to evaluate alternative concurrency control strategies for real-time synchronization. Nishio et al. advocate a cautious transaction scheduling approach that checks for non-serializable execution as it executes transactions <ref> [56] </ref>. This cautious approach performs better than 2PL, and it never aborts or rolls back transactions to achieve concurrency control. Haritsa et al. [32] and Lee and Son [41] advocate various optimistic concurrency control protocols which proceed with transactions and only check for serialization problems at commit time. <p> Priority inheritance protocols can also be used to reflect task priorities in distributed transaction execution [67]. Some researchers suggest that serializability should not be used as the primary correctness criterion for real-time concurrency control <ref> [12, 21, 56] </ref>. Lin [48, 49] suggests that, for real-time applications, data inconsistent with the external world can be worse than internally inconsistent data.
Reference: [57] <author> L. L. Peterson, N. C. Hutchinson, S. W. O`Malley, and H. C. Rao, </author> <title> "The x-Kernel: A platform for accessing internet resources," </title> <journal> IEEE Computer, </journal> <volume> vol. 23, no. 5, </volume> <pages> pp. 23-33, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: Far better performance can be achieved if the overhead itself can be reduced or eliminated. Some researchers have investigated ways to reduce RPC (remote procedure call) overhead. The x-kernel is an operating system designed to efficiently support multiple RPC protocols <ref> [57] </ref>. X-kernel RPC overhead is four milliseconds for Sun RPC and 1.7 milliseconds for Sprite RPC on a 2 MIPS processor and a lightly loaded ethernet. Local (same machine) RPCs can be made much faster, depending on how they are implemented in the operating system kernel.
Reference: [58] <author> R. Rajkumar, </author> <title> "Real-time synchronization protocols for shared memory multiprocessors," </title> <booktitle> in Proc. Int'l Conf. on Distributed Computing Systems, </booktitle> <pages> pp. 116-123, </pages> <year> 1990. </year>
Reference-contexts: One approach to priority inversion is to abort lower priority transactions that conflict with higher priority ones. An alternative is to bound priority inversions using various priority inheritance protocols which temporarily boost the priority of tasks holding locks if they conflict with higher priority tasks <ref> [58, 60, 67, 76] </ref>. This temporary priority boost helps lower-priority tasks complete transactions and release their locks. <p> Prior work on real-time multiprocessor synchronization minimizes the global blocking of high-priority tasks at the expense of lower-priority tasks <ref> [58, 60] </ref>. Global blocking in a multiprocessor system is blocking on semaphores that are shared across processor boundaries. In this chapter, we examine the relationship between global semaphore queue wait times and the schedulability of periodic tasks using rate monotonic scheduling on multiprocessors. <p> The most common approach to bounding semaphore wait times is to use variants of the priority inheritance protocol (e.g., basic priority inheritance, priority ceiling protocol, semaphore control protocol, kernel priority protocol [59]) to limit wait times due to lower-priority tasks <ref> [36, 58, 60, 68] </ref>. These protocols temporarily boost the priorities of tasks that are executing critical sections to ensure that they can complete the critical sections within a short, predictable time. This in turn bounds the blocking delays of other tasks that wait for the resources. <p> The priority ceiling protocol and the semaphore control protocol further bound blocking delays and avoid deadlocks by preventing tasks from attempting to acquire semaphores under certain conditions. These "real-time" synchronization protocols were first developed for uniprocessors and then extended to multiprocessors <ref> [58, 60, 68] </ref>. Some uniprocessor protocols, such as the priority ceiling protocol, do not use explicit semaphore queues. However, real-time multiprocessor synchronization requires queues for the global semaphores. In multiprocessors, the blocking delays also depend on the distribution of tasks that share semaphores across processor boundaries. <p> By allocating blocking delays in this way, it is possible to improve the overall schedulability of the system. Now let us consider the RMSS semaphore queue priority assignment proposed in <ref> [58, 60] </ref>. As we have seen, lower-priority tasks can be less tolerant of blocking delays than higher-priority tasks. If task execution priorities are used for semaphore queues, as much blocking as possible is assigned to the lower-priority tasks. <p> If T max is bounded, the algorithm is essentially O (k lg k). Otherwise, it is quadratic in T max . In either case, this is a relatively efficient algorithm. Now, consider the priority assignment method of <ref> [58, 60] </ref>: assign lowest semaphore queue priorities to the lowest-priority tasks. This is a constant time algorithm, but it is essentially a bin packing strategy in which the largest k items are assigned to a predetermined set of bins, which could be the smallest bins. <p> If this priority assignment overflows a bin's capacity, the algorithm returns failure. Clearly, the bin packing algorithm we propose should perform much better than the method used in <ref> [58, 60] </ref>. By performing better, we mean that given some population of task sets, more will be schedulable with our algorithm. To verify this claim, we have implemented our algorithm and conducted extensive experiments comparing our approach with the previous approach and with simple FIFO queues.
Reference: [59] <author> R. Rajkumar, </author> <title> SYNCHRONIZATION IN REAL-TIME SYSTEMS A Priority Inheritance Approach, </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1991. </year>
Reference-contexts: If tasks are not preemptible, general schedulability analysis is compu-tationally intractable (NP-complete or NP-hard). However, if tasks are preemptible, it is possible to efficiently determine their schedulability by applying rate monotonic scheduling theory <ref> [50, 59] </ref>. Rate monotonic scheduling is an optimal algorithm for static (pre-assigned) task priorities. Various other dynamic priority scheduling protocols have also been studied (earliest due date, least slack time, etc. [15]). <p> The most common approach to bounding semaphore wait times is to use variants of the priority inheritance protocol (e.g., basic priority inheritance, priority ceiling protocol, semaphore control protocol, kernel priority protocol <ref> [59] </ref>) to limit wait times due to lower-priority tasks [36, 58, 60, 68]. These protocols temporarily boost the priorities of tasks that are executing critical sections to ensure that they can complete the critical sections within a short, predictable time.
Reference: [60] <author> R. Rajkumar, L. Sha, and J. P. Lehoczky, </author> <title> "Real-time synchronization protocols for multiprocessors," </title> <booktitle> in Proc. Real-Time Systems Symposium, </booktitle> <pages> pp. 259-269, </pages> <month> December </month> <year> 1988. </year>
Reference-contexts: One approach to priority inversion is to abort lower priority transactions that conflict with higher priority ones. An alternative is to bound priority inversions using various priority inheritance protocols which temporarily boost the priority of tasks holding locks if they conflict with higher priority tasks <ref> [58, 60, 67, 76] </ref>. This temporary priority boost helps lower-priority tasks complete transactions and release their locks. <p> This temporary priority boost helps lower-priority tasks complete transactions and release their locks. Since the best approach to real-time concurrency control often depends upon the particular application, some researchers advocate hybrid protocols that borrow features of several earlier strategies to perform acceptably for a wider range of applications <ref> [12, 32, 35, 60, 78] </ref>. For example, Huang et al. [35] advocate a hybrid approach in which tasks inherit higher priorities only if they are close to committing. Otherwise, if higher-priority tasks require locks held by low-priority tasks, the lower priority transactions are aborted. <p> Prior work on real-time multiprocessor synchronization minimizes the global blocking of high-priority tasks at the expense of lower-priority tasks <ref> [58, 60] </ref>. Global blocking in a multiprocessor system is blocking on semaphores that are shared across processor boundaries. In this chapter, we examine the relationship between global semaphore queue wait times and the schedulability of periodic tasks using rate monotonic scheduling on multiprocessors. <p> Given such a bound, traditional scheduling strategies such as rate monotonic scheduling or earliest deadline scheduling can be used to guarantee task deadlines <ref> [8, 60] </ref>. The most common approach to bounding semaphore wait times is to use variants of the priority inheritance protocol (e.g., basic priority inheritance, priority ceiling protocol, semaphore control protocol, kernel priority protocol [59]) to limit wait times due to lower-priority tasks [36, 58, 60, 68]. <p> The most common approach to bounding semaphore wait times is to use variants of the priority inheritance protocol (e.g., basic priority inheritance, priority ceiling protocol, semaphore control protocol, kernel priority protocol [59]) to limit wait times due to lower-priority tasks <ref> [36, 58, 60, 68] </ref>. These protocols temporarily boost the priorities of tasks that are executing critical sections to ensure that they can complete the critical sections within a short, predictable time. This in turn bounds the blocking delays of other tasks that wait for the resources. <p> The priority ceiling protocol and the semaphore control protocol further bound blocking delays and avoid deadlocks by preventing tasks from attempting to acquire semaphores under certain conditions. These "real-time" synchronization protocols were first developed for uniprocessors and then extended to multiprocessors <ref> [58, 60, 68] </ref>. Some uniprocessor protocols, such as the priority ceiling protocol, do not use explicit semaphore queues. However, real-time multiprocessor synchronization requires queues for the global semaphores. In multiprocessors, the blocking delays also depend on the distribution of tasks that share semaphores across processor boundaries. <p> Section 4.7 discusses various implementation issues, and the chapter concludes with Section 4.8. 4.2 Blocking Delays and Schedulability Guarantees Given rate monotonic scheduling of n periodic tasks with blocking for synchronization, Rajkumar et al. <ref> [60] </ref> proved that satisfaction of the following equation on each processor provides sufficient conditions for schedulability: 8i; 1 i n T 1 C 2 + + T i B i i (2 1=i 1) (4.1) In this equation (set of equations, actually), lower-numbered subscripts correspond to higher-priority tasks. <p> In particular, the blocking times of other tasks do not affect the schedulability of a given task. This makes intuitive sense because it is the processor utilizations of other (higher-priority) tasks that reduce the schedulability of a task. Prior work <ref> [60] </ref> on real-time synchronization for multiprocessors states: "Another fundamental goal of our synchronization protocol is that whenever possible, we would let a lower-priority job wait for a higher-priority job". <p> This is accomplished for global semaphores by using priority queues to ensure that the highest-priority blocked job will be granted the semaphore next. The justification given in <ref> [60] </ref> for making lower-priority jobs wait is that the longer periods (T i ) of lower-priority tasks results in less schedulability loss B=T for a given blocking duration B. However, the statement "a given blocking duration B" does not take into account an important characteristic of the problem. <p> Therefore, our goal is to calculate B i;S , the blocking time for job J i associated with waiting for global semaphore S. To simplify the analysis, we assume that global critical sections are non-preemptible, which approximates the behavior of the modified priority ceiling protocol proposed for multiprocessor synchronization <ref> [60] </ref>. We define the following notation. Note that J i might contain multiple critical sections guarded by S. Furthermore, unlike Eq. (4.1), the task numbers in our notation do not correlate with priorities. <p> By allocating blocking delays in this way, it is possible to improve the overall schedulability of the system. Now let us consider the RMSS semaphore queue priority assignment proposed in <ref> [58, 60] </ref>. As we have seen, lower-priority tasks can be less tolerant of blocking delays than higher-priority tasks. If task execution priorities are used for semaphore queues, as much blocking as possible is assigned to the lower-priority tasks. <p> If T max is bounded, the algorithm is essentially O (k lg k). Otherwise, it is quadratic in T max . In either case, this is a relatively efficient algorithm. Now, consider the priority assignment method of <ref> [58, 60] </ref>: assign lowest semaphore queue priorities to the lowest-priority tasks. This is a constant time algorithm, but it is essentially a bin packing strategy in which the largest k items are assigned to a predetermined set of bins, which could be the smallest bins. <p> If this priority assignment overflows a bin's capacity, the algorithm returns failure. Clearly, the bin packing algorithm we propose should perform much better than the method used in <ref> [58, 60] </ref>. By performing better, we mean that given some population of task sets, more will be schedulable with our algorithm. To verify this claim, we have implemented our algorithm and conducted extensive experiments comparing our approach with the previous approach and with simple FIFO queues.
Reference: [61] <author> K. Ramamritham and C. Pu, </author> <title> "A formal characterization of epsilon serializability," </title> <type> Technical Report CUCS-044-91, </type> <institution> Department of Computer Science, Columbia University, </institution> <year> 1991. </year> <month> 130 </month>
Reference-contexts: Clearly, these trade-offs would depend heavily on the particular application. Kuo and Mok [40] introduce a correctness criterion for concurrent transactions which permits unserialized transactions if the data values read and generated by those transactions are sufficiently similar. Epsilon serializability <ref> [61] </ref> is another alternative to traditional serializability proposed for real-time transactions. The problem with relaxing consistency constraints such as serializability is that it can be more difficult to demonstrate the correctness of transactions.
Reference: [62] <author> K. Ramamritham, </author> <title> "Real-time databases," </title> <booktitle> Int'l Journal of Distributed and Parallel Databases, </booktitle> <pages> pp. 199-226, </pages> <month> April </month> <year> 1993. </year>
Reference-contexts: None of the prior work in RTDBSs considers the possibility of application tasks executing transactions themselves. Transaction and I/O Scheduling Several researchers have investigated transaction and I/O scheduling algorithms that support different real-time needs and priorities <ref> [1, 12, 62, 83, 76] </ref>. Some commercial database systems support priority-based transaction scheduling [25, 64]. By servicing high-priority tasks first, the database can provide faster and more predictable performance for transactions submitted by high-priority tasks. In this case, low-priority tasks experience degraded performance. <p> Thus, temporal consistency may be a semantic requirement for a real-time database. Temporal consistency could be achieved by adding constraints to transaction scheduling so that time correlation of data values is maintained <ref> [31, 62] </ref>. No current sched-ulers employ this technique, but Liu and Song [81] use temporal correlation as a criterion to evaluate scheduling algorithms.
Reference: [63] <author> K. Ravindran and K. K. Ramakrishnan, </author> <title> "A model for naming for fine-grained service specification in distributed systems," </title> <booktitle> in Proc. Int'l Conf. on Distributed Computing Systems, </booktitle> <pages> pp. 98-105, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: Contracts are evaluated at runtime during server object initialization. Our approach resembles service specification and acquisition in distributed computing systems <ref> [14, 63] </ref>, except our server objects are much lighter-weight and are constructed from local libraries rather than remote server processes. If no server objects in the library can meet the requirements of the contract, then the library can set an error flag or throw an exception.
Reference: [64] <institution> RTA Introduction & Overview, Real Time Computersoftware Ges.m.b.H., </institution> <year> 1992. </year>
Reference-contexts: None of the prior work in RTDBSs considers the possibility of application tasks executing transactions themselves. Transaction and I/O Scheduling Several researchers have investigated transaction and I/O scheduling algorithms that support different real-time needs and priorities [1, 12, 62, 83, 76]. Some commercial database systems support priority-based transaction scheduling <ref> [25, 64] </ref>. By servicing high-priority tasks first, the database can provide faster and more predictable performance for transactions submitted by high-priority tasks. In this case, low-priority tasks experience degraded performance. File-based databases in particular can benefit from transaction and I/O scheduling according to priorities.
Reference: [65] <author> K. Schwan, P. Gopinath, and W. Bo, </author> <title> "CHAOS-kernel support for objects in the real-time domain," </title> <journal> IEEE Trans. Computers, </journal> <volume> vol. C-36, no. 8, </volume> <pages> pp. 904-916, </pages> <month> August </month> <year> 1987. </year>
Reference-contexts: Data and method encapsulation facilitates the mapping of software objects to physical objects and mechanisms that have internal state. By associating a computation with the context of an object's encapsulated state, higher-level application software need not explicitly maintain implementation-specific state information. CHAOS <ref> [26, 27, 65] </ref>, Maruti [44, 54], and ARTS [87] provide support for real-time objects at the kernel level of an operating system. ARTS supports real-time objects with lightweight threads and multiple task scheduling policies. A major emphasis in ARTS is the provision of exception handling if deadlines are violated. <p> CHAOS, Maruti, and ARTS are all based entirely on the client-server model of object sharing. Therefore, these systems incur communication latencies, queueing delays, and serial bottlenecks in the object servers. Schwan et al. report some performance numbers for a CHAOS implementation in <ref> [65] </ref>. According to [65], the best-case overhead for invoking CHAOS methods on the client side alone ranges from one to five milliseconds, depending on the semantics of the invocation. Presumably, the worst-case overhead is substantially worse (the paper does not quantify the worst case). <p> CHAOS, Maruti, and ARTS are all based entirely on the client-server model of object sharing. Therefore, these systems incur communication latencies, queueing delays, and serial bottlenecks in the object servers. Schwan et al. report some performance numbers for a CHAOS implementation in <ref> [65] </ref>. According to [65], the best-case overhead for invoking CHAOS methods on the client side alone ranges from one to five milliseconds, depending on the semantics of the invocation. Presumably, the worst-case overhead is substantially worse (the paper does not quantify the worst case).
Reference: [66] <author> L. Sha, J. P. Lehoczky, and E. D. Jensen, </author> <title> "Modular concurrency control and failure recovery," </title> <journal> IEEE Trans. Computers, </journal> <volume> vol. 37, no. 2, </volume> <pages> pp. 146-159, </pages> <month> February </month> <year> 1988. </year>
Reference-contexts: Synchronization delays caused by locking can be reduced if the frequency of locking conflicts is reduced. One approach to reducing locking conflicts is to adjust the lock granularity to lock only data that are affected by each transaction <ref> [6, 66, 79] </ref>. Reducing lock granularity increases space overhead for locking, and it can degrade performance if many locks must be acquired to perform a transaction. Therefore, the locking granularity should be tuned to transaction characteristics. <p> Avoid unnecessary locking. When possible, use data versioning [39, 79] or multiple data copies [90] to permit concurrent read and write operations without locking. Match locking granularity with data semantics. This ensures that locking does not unnecessarily restrict concurrency. Sha et al. <ref> [66] </ref>, Badrinath and Ramamritham [6], and Son [79] all propose locking only the data affected by a transaction. However, identifying affected data and locking only those data are non-trivial problems in conventional database systems, where the data affected by a transaction are determined during query processing at runtime.
Reference: [67] <author> L. Sha, R. Rajkumar, and J. P. Lehoczky, </author> <title> "Concurrency control for distributed real-time databases," </title> <booktitle> SIGMOD Record, </booktitle> <volume> vol. 17, no. 1, </volume> <pages> pp. 82-98, </pages> <month> March </month> <year> 1988. </year>
Reference-contexts: Some researchers have investigated concurrency control algorithms for distributed real-time databases. Consistency across replicated data objects can be maintained through transaction timestamps [70, 79] or symmetric updates [71]. Priority inheritance protocols can also be used to reflect task priorities in distributed transaction execution <ref> [67] </ref>. Some researchers suggest that serializability should not be used as the primary correctness criterion for real-time concurrency control [12, 21, 56]. Lin [48, 49] suggests that, for real-time applications, data inconsistent with the external world can be worse than internally inconsistent data. <p> One approach to priority inversion is to abort lower priority transactions that conflict with higher priority ones. An alternative is to bound priority inversions using various priority inheritance protocols which temporarily boost the priority of tasks holding locks if they conflict with higher priority tasks <ref> [58, 60, 67, 76] </ref>. This temporary priority boost helps lower-priority tasks complete transactions and release their locks.
Reference: [68] <author> L. Sha, R. Rajkumar, and J. P. Lehoczky, </author> <title> "Priority inheritance protocols: An approach to real-time synchronization," </title> <journal> IEEE Trans. Computers, </journal> <volume> vol. 39, no. 9, </volume> <pages> pp. 1175-1185, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: The most common approach to bounding semaphore wait times is to use variants of the priority inheritance protocol (e.g., basic priority inheritance, priority ceiling protocol, semaphore control protocol, kernel priority protocol [59]) to limit wait times due to lower-priority tasks <ref> [36, 58, 60, 68] </ref>. These protocols temporarily boost the priorities of tasks that are executing critical sections to ensure that they can complete the critical sections within a short, predictable time. This in turn bounds the blocking delays of other tasks that wait for the resources. <p> The priority ceiling protocol and the semaphore control protocol further bound blocking delays and avoid deadlocks by preventing tasks from attempting to acquire semaphores under certain conditions. These "real-time" synchronization protocols were first developed for uniprocessors and then extended to multiprocessors <ref> [58, 60, 68] </ref>. Some uniprocessor protocols, such as the priority ceiling protocol, do not use explicit semaphore queues. However, real-time multiprocessor synchronization requires queues for the global semaphores. In multiprocessors, the blocking delays also depend on the distribution of tasks that share semaphores across processor boundaries. <p> For the purposes of this chapter, we analyze the blocking associated with waiting on a single global semaphore in a multiprocessor. Our analysis applies only to global semaphores; local semaphores should be managed by one of the near-optimal uniprocessor protocols such as the priority ceiling protocol <ref> [68] </ref>. It is easy to extend our results to derive the total blocking associated with all semaphores. Therefore, our goal is to calculate B i;S , the blocking time for job J i associated with waiting for global semaphore S.
Reference: [69] <author> J. Shirley, </author> <title> Guide to Writing DCE Applications, </title> <publisher> O'Reilly & Associates, Inc., </publisher> <year> 1992. </year>
Reference-contexts: One of the difficulties associated with remote data access is that most networking protocols add substantial overhead and do not provide end-to-end response-time guarantees. For example, TCP/IP-based protocols for socket and datagram communications, on which Sun RPC [10] and OSF DCE <ref> [69] </ref> are built, provide no timing guarantees. Clearly, any remote transaction that uses these services cannot provide any absolute timing guarantees. Nevertheless, it can still be very useful to provide remote access even if transaction-time guarantees are not made. <p> The RPC calls are serviced by MDARTS SDM servers. Each MdartsRemote object contains an RPC handle and the identifier (name) of the remote MDARTS object. Our first MDARTS implementation used Apollo NCS for its remote procedure calls. NCS is the base technology for OSF DCE remote procedure calls <ref> [69] </ref>. However, since NCS and DCE are not widely available yet, we modified the RPC functions in MDARTS to use Sun RPC [10]. via RPC.
Reference: [70] <author> M. Singhal, </author> <title> "A fully-distributed approach to concurrency control in replicated database systems," </title> <booktitle> in IEEE Proc. Int'l. Computer Software and Applications Conference, </booktitle> <pages> pp. 353-360, </pages> <year> 1988. </year>
Reference-contexts: Furthermore, these main memory database systems do not provide worst-case guarantees for their transactions. Hard real-time systems need worst-case guarantees to ensure that all deadlines will be met. Of the prior real-time database prototypes reported in <ref> [13, 41, 34, 70, 77, 88] </ref>, none provides hard real-time guarantees, and none has average transaction times of less than 100 milliseconds. Thus, these database systems are not suitable for high-speed hard real-time systems such as machine tool controllers. <p> Some researchers have investigated concurrency control algorithms for distributed real-time databases. Consistency across replicated data objects can be maintained through transaction timestamps <ref> [70, 79] </ref> or symmetric updates [71]. Priority inheritance protocols can also be used to reflect task priorities in distributed transaction execution [67]. Some researchers suggest that serializability should not be used as the primary correctness criterion for real-time concurrency control [12, 21, 56].
Reference: [71] <author> M. Singhal, </author> <title> "Issues and approaches to design of real-time database systems," </title> <booktitle> SIGMOD Record, </booktitle> <volume> vol. 17, no. 1, </volume> <pages> pp. 19-33, </pages> <month> March </month> <year> 1988. </year>
Reference-contexts: To this list, we add: 4) avoid the overhead associated with a client-server architecture, and 5) make maximum use of parallelism on multiprocessor systems. Main Memory Databases Some RTDBS researchers propose using main memory databases to eliminate blocking time uncertainties associated with disk I/O during database transactions <ref> [71, 80] </ref>. There has also been significant interest recently in using main memory databases to increase performance for conventional transaction processing systems [4, 23, 42, 45]. Garcia-Molina 5 and Salem present a nice overview of main memory database research in [23]. <p> Some researchers have investigated concurrency control algorithms for distributed real-time databases. Consistency across replicated data objects can be maintained through transaction timestamps [70, 79] or symmetric updates <ref> [71] </ref>. Priority inheritance protocols can also be used to reflect task priorities in distributed transaction execution [67]. Some researchers suggest that serializability should not be used as the primary correctness criterion for real-time concurrency control [12, 21, 56]. <p> The serializability property has been the focus of recent debate in the real-time database community. Serializability is considered indispensable in the non-real-time database community, and some real-time database researchers concur [12, 55, 28, 29, 41]. Other real-time researchers consider full serializability too expensive and possibly unnecessary for real-time databases <ref> [48, 71] </ref>. Since many of the traditional ACID transaction properties may be expensive or infeasible to provide in the context of a real-time database, it may be desirable to limit or trade off various transaction properties.
Reference: [72] <author> A. H. Skarra, </author> <title> "Concurrency control for cooperating transactions in an object-oriented database," </title> <journal> SIGPLAN Notices, </journal> <volume> vol. 24, no. 4, </volume> <pages> pp. 145-147, </pages> <month> April </month> <year> 1989. </year>
Reference-contexts: Since the concurrency control can be individually tailored according to the semantics of the class member functions, it is possible to achieve higher levels of concurrency than with traditional read-write locking <ref> [21, 72, 93] </ref>. It is also possible to implement atomicity in a base class and inherit this property in derived subclasses [20]. MDARTS shared-memory objects differ from atomic data types and semantic concurrency control techniques described in the literature in that MDARTS objects are fragmented across multiple separate processes.
Reference: [73] <author> A. H. Skarra and S. B. Zdonik, </author> <title> "Concurrency control and object-oriented databases," in Object-Oriented Concepts, Databases, and Applications, </title> <editor> W. Kim and F. H. Lochovsky, </editor> <booktitle> editors, </booktitle> <pages> pp. 395-421. </pages> <publisher> Addison Wesley, </publisher> <year> 1989. </year>
Reference-contexts: We were primarily motivated to use object-based concurrency control to avoid the over 50 head of client-server communication. Without a database server to manage concurrency, the database objects must supply their own concurrency control. In other words, the database objects should be atomic data types <ref> [92, 73] </ref>. An atomic data type is essentially a class whose methods guarantee serial behavior in the presence of concurrent requests.
Reference: [74] <author> P. Sleat and P. Osmon, </author> <title> "A methodology for real-time database system construction," </title> <booktitle> in Proc. Int. Conf. on Software Engineering for Real Time Systems, </booktitle> <pages> pp. 233-238, </pages> <month> Septem-ber </month> <year> 1991. </year>
Reference-contexts: Object-oriented database systems often have convenient application programming interfaces, so MDARTS is not unique in this respect. Prior real-time database systems either make deadline guarantees a priori with offline static analysis of applications <ref> [74] </ref> or use dynamic transaction scheduling to try to meet deadlines at runtime [12]. Off-line static analysis has the advantage of providing early feedback if requirements cannot be met. However, off-line analysis of transactions is not always feasible, especially for complex, distributed applications.
Reference: [75] <author> K. P. Smith and J. Liu, </author> <title> "Monotonically improving approximate answers to relational algebra queries," </title> <booktitle> in Proceedings of IEEE Compsac, </booktitle> <address> Orlando, Florida, </address> <month> September </month> <year> 1989. </year>
Reference-contexts: Temporal consistency could be achieved by adding constraints to transaction scheduling so that time correlation of data values is maintained [31, 62]. No current sched-ulers employ this technique, but Liu and Song [81] use temporal correlation as a criterion to evaluate scheduling algorithms. Smith and Liu <ref> [75] </ref> suggest that real-time databases could return approximate values when precise values cannot be computed before the deadline. 8 This is an application of the imprecise computation idea of Lin et al. [47].
Reference: [76] <author> S. H. Son, </author> <title> "Scheduling real-time transactions," </title> <booktitle> in Proc. EuroMicro '90 Workshop on Real Time, </booktitle> <pages> pp. 25-32. </pages> <publisher> IEEE, </publisher> <year> 1990. </year>
Reference-contexts: None of the prior work in RTDBSs considers the possibility of application tasks executing transactions themselves. Transaction and I/O Scheduling Several researchers have investigated transaction and I/O scheduling algorithms that support different real-time needs and priorities <ref> [1, 12, 62, 83, 76] </ref>. Some commercial database systems support priority-based transaction scheduling [25, 64]. By servicing high-priority tasks first, the database can provide faster and more predictable performance for transactions submitted by high-priority tasks. In this case, low-priority tasks experience degraded performance. <p> One approach to priority inversion is to abort lower priority transactions that conflict with higher priority ones. An alternative is to bound priority inversions using various priority inheritance protocols which temporarily boost the priority of tasks holding locks if they conflict with higher priority tasks <ref> [58, 60, 67, 76] </ref>. This temporary priority boost helps lower-priority tasks complete transactions and release their locks.
Reference: [77] <author> S. H. Son and Y. Kim, </author> <title> "A software prototyping environment and its use in developing a multiversion distributed database system," </title> <booktitle> International Conference on Parallel Processing, </booktitle> <volume> vol. 2, </volume> <pages> pp. 81-88, </pages> <month> August </month> <year> 1989. </year> <month> 131 </month>
Reference-contexts: Furthermore, these main memory database systems do not provide worst-case guarantees for their transactions. Hard real-time systems need worst-case guarantees to ensure that all deadlines will be met. Of the prior real-time database prototypes reported in <ref> [13, 41, 34, 70, 77, 88] </ref>, none provides hard real-time guarantees, and none has average transaction times of less than 100 milliseconds. Thus, these database systems are not suitable for high-speed hard real-time systems such as machine tool controllers. <p> Very few actual real-time database implementations are described in the literature, and most of those are testbeds designed for studying algorithms rather than for supporting realistic real-time applications <ref> [35, 77] </ref>. Furthermore, to our knowledge, none of the RTDBS implementations reported in the literature are intended for hard real-time applications such as machine controllers.
Reference: [78] <author> S. H. Son, J. Lee, and Y. Lin, </author> <title> "Hybrid protocols using dynamic adjustment of serialization order for real-time concurrency control," </title> <journal> Journal of Real-Time Systems, </journal> <volume> vol. 4, no. 3, </volume> <pages> pp. 269-276, </pages> <month> September </month> <year> 1992. </year>
Reference-contexts: This temporary priority boost helps lower-priority tasks complete transactions and release their locks. Since the best approach to real-time concurrency control often depends upon the particular application, some researchers advocate hybrid protocols that borrow features of several earlier strategies to perform acceptably for a wider range of applications <ref> [12, 32, 35, 60, 78] </ref>. For example, Huang et al. [35] advocate a hybrid approach in which tasks inherit higher priorities only if they are close to committing. Otherwise, if higher-priority tasks require locks held by low-priority tasks, the lower priority transactions are aborted.
Reference: [79] <author> S. H. Son, </author> <title> "Semantic information and consistency in distributed realtime systems," </title> <journal> Information and Software Technology, </journal> <volume> vol. 30, no. 7, </volume> <pages> pp. 443-449, </pages> <month> September </month> <year> 1988. </year>
Reference-contexts: Some researchers have investigated concurrency control algorithms for distributed real-time databases. Consistency across replicated data objects can be maintained through transaction timestamps <ref> [70, 79] </ref> or symmetric updates [71]. Priority inheritance protocols can also be used to reflect task priorities in distributed transaction execution [67]. Some researchers suggest that serializability should not be used as the primary correctness criterion for real-time concurrency control [12, 21, 56]. <p> Synchronization delays caused by locking can be reduced if the frequency of locking conflicts is reduced. One approach to reducing locking conflicts is to adjust the lock granularity to lock only data that are affected by each transaction <ref> [6, 66, 79] </ref>. Reducing lock granularity increases space overhead for locking, and it can degrade performance if many locks must be acquired to perform a transaction. Therefore, the locking granularity should be tuned to transaction characteristics. <p> Semantic and object-based concurrency control protocols extend this idea by characterizing which transactions conflict and thus require serialization [7, 21, 40]. Another approach to reducing locking conflicts is to design transaction protocols that use data versioning to avoid locking altogether <ref> [79, 86, 90, 91] </ref>. MDARTS objects can use similar techniques in providing concurrency control for their transaction methods. MDARTS does not dictate concurrency control policies, but the MDARTS object-oriented approach facilitates the use of semantic and object-based concurrency control. <p> To implement concurrency control in MDARTS we propose the following principles. Our current implementation reflects all of these ideas except data versioning. Avoid unnecessary locking. When possible, use data versioning <ref> [39, 79] </ref> or multiple data copies [90] to permit concurrent read and write operations without locking. Match locking granularity with data semantics. This ensures that locking does not unnecessarily restrict concurrency. <p> Avoid unnecessary locking. When possible, use data versioning [39, 79] or multiple data copies [90] to permit concurrent read and write operations without locking. Match locking granularity with data semantics. This ensures that locking does not unnecessarily restrict concurrency. Sha et al. [66], Badrinath and Ramamritham [6], and Son <ref> [79] </ref> all propose locking only the data affected by a transaction. However, identifying affected data and locking only those data are non-trivial problems in conventional database systems, where the data affected by a transaction are determined during query processing at runtime.
Reference: [80] <author> S. H. Son, </author> <title> "Recovery in main memory database systems for engineering design applications," </title> <journal> Information and Software Technology, </journal> <volume> vol. 31, no. 2, </volume> <pages> pp. 85-90, </pages> <month> March </month> <year> 1989. </year>
Reference-contexts: To this list, we add: 4) avoid the overhead associated with a client-server architecture, and 5) make maximum use of parallelism on multiprocessor systems. Main Memory Databases Some RTDBS researchers propose using main memory databases to eliminate blocking time uncertainties associated with disk I/O during database transactions <ref> [71, 80] </ref>. There has also been significant interest recently in using main memory databases to increase performance for conventional transaction processing systems [4, 23, 42, 45]. Garcia-Molina 5 and Salem present a nice overview of main memory database research in [23]. <p> The last field is the number of critical sections entered by that transaction. while others are in terms of "bms", which is the execution time required to execute a 41 static void MDclass::calibrate () f int j; char buf <ref> [80] </ref>; CALIBRATE START (MDclass) RUN ("read (delay)",j = getIValue (delay f,"",0),"usecs") RUN ("read (name)",getSValue (name f,"",0,0,buf,80),"usecs") RUN ("read (sum)",j = getIValue (sum f,"",0),"bms") DECLARE ("write (start_motors);10msecs + 3bms;2;50usecs;2") RUN ("write (increment)",setValue (increment f,"",0,j),"bms") CALIBRATE END g standard benchmark function. <p> Next, experiment type "i get" was stored in the command field 103 void RunGetCommand (char fls) f static RW Mdarts ex ob ("experiment","type=Experiment"); int count,itag,index; char tag <ref> [80] </ref>; char type; if (sscanf (s,"get %c %d %d %s %d",&type,&count,&itag,tag,&index) != 5) ScanError (s); ex ob ("repeat_count") = count; ex ob ("itag") = itag; ex ob ("tag") = tag; ex ob ("index") = index; switch (type) f case flifl: ex ob ("command") = (int) Experiment::i get; case fldfl: ex ob
Reference: [81] <author> X. Song and J. W. S. Liu, </author> <title> "Performance of multiversion concurrency control algorithms in maintaining temporal consistency," </title> <type> Technical report, </type> <institution> University of Illinois, Urbana-Champaign, </institution> <month> February </month> <year> 1990. </year>
Reference-contexts: Thus, temporal consistency may be a semantic requirement for a real-time database. Temporal consistency could be achieved by adding constraints to transaction scheduling so that time correlation of data values is maintained [31, 62]. No current sched-ulers employ this technique, but Liu and Song <ref> [81] </ref> use temporal correlation as a criterion to evaluate scheduling algorithms. Smith and Liu [75] suggest that real-time databases could return approximate values when precise values cannot be computed before the deadline. 8 This is an application of the imprecise computation idea of Lin et al. [47].
Reference: [82] <author> J. A. Stankovic, </author> <title> "Misconceptions about real-time computing: A serious problem for next-generation systems," </title> <journal> IEEE Computer, </journal> <volume> vol. 21, no. 10, </volume> <pages> pp. 10-19, </pages> <month> October </month> <year> 1988. </year>
Reference-contexts: For example, a manufacturing machine controller may recompute its control signals every 1 or 2 milliseconds. Failure to meet this deadline could cause the machine to become unstable and malfunction, possibly with dire consequences. A common misconception about real-time computing is that it is equivalent to high-speed computing <ref> [82] </ref>. Actually, there are fundamental differences between the two. Whereas high-speed computing refers to average performance levels, real-time computing requires absolute performance levels. To guard against failure, hard real-time systems are typically designed using worst-case assumptions about all operations.
Reference: [83] <author> J. A. Stankovic and W. Zhao, </author> <title> "On real-time transactions," </title> <booktitle> SIGMOD Record, </booktitle> <volume> vol. 17, no. 1, </volume> <pages> pp. 4-18, </pages> <month> March </month> <year> 1988. </year>
Reference-contexts: None of the prior work in RTDBSs considers the possibility of application tasks executing transactions themselves. Transaction and I/O Scheduling Several researchers have investigated transaction and I/O scheduling algorithms that support different real-time needs and priorities <ref> [1, 12, 62, 83, 76] </ref>. Some commercial database systems support priority-based transaction scheduling [25, 64]. By servicing high-priority tasks first, the database can provide faster and more predictable performance for transactions submitted by high-priority tasks. In this case, low-priority tasks experience degraded performance.
Reference: [84] <author> D. B. Stewart, R. A. Volpe, and P. K. Khosla, </author> <title> "Design of dynamically reconfigurable real-time software using port-based objects," </title> <type> Technical Report CMU-RI-TR-93-11, </type> <institution> Carnegie Mellon University, </institution> <month> July </month> <year> 1993. </year>
Reference-contexts: Furthermore, MO2 is also client-server based and thus incurs the overhead associated with that architecture. Stewart et al. describe an object-oriented approach to developing hard real-time applications in <ref> [84] </ref>. The objects, called port-based objects, follow a strict protocol for sharing information across task boundaries. All cooperating tasks share a common global state table, and during each cycle of a control task's execution, a copy of needed global variables is made by each task. <p> Furthermore, to our knowledge, none of the RTDBS implementations reported in the literature are intended for hard real-time applications such as machine controllers. CMU's port-based objects <ref> [84] </ref> include a simple approach to data management for hard real-time applications, but the data management protocol supported by these port-based objects lacks flexibility. It also incurs substantial runtime overhead by periodically copying data between a global state table and local caches.
Reference: [85] <author> B. Stroustrup, </author> <title> The C++ Programming Language Second Edition, </title> <publisher> Addison Wesley, </publisher> <year> 1991. </year>
Reference-contexts: MDARTS is a framework for developing object-oriented data management services suitable for high-speed, hard real-time applications on uniprocessor or multiprocessor computing platforms. Our MDARTS prototype is an extensible library of data management classes written in C++, an object-oriented programming language <ref> [85] </ref>. Applications using MDARTS can specify real-time requirements for transactions in the declarations of their database objects, and they can query database objects to determine real-time characteristics prior to performing transactions. <p> For the same reason, we explicitly avoided reliance on custom hardware support. Our prototype uses strictly off-the-shelf hardware components and operating systems. We implemented our prototype in C++ <ref> [85] </ref>. We chose C++ because of its wide availability, runtime efficiency, compatibility with C, and object-oriented features. <p> Given these worst-case latencies, MDARTS can guarantee its transaction times. 2.3 Object-Oriented Database Service Classes 2.3.1 Implementation Approach We have implemented MDARTS in the C++ language <ref> [85] </ref>. We chose C++ because of its wide availability, runtime efficiency, compatibility with C, and object-oriented features. 24 Some advantages of C++ for real-time software are discussed in the literature [18, 17]. <p> Furthermore, the SDM needs to pass the type of the database service class back to 46 the client task. To perform runtime type comparisons and class lookups, MDARTS includes an implementation of runtime type information for its classes similar to that described by Stroustrup <ref> [85] </ref>. Each MDARTS class registers itself at initialization time with its runtime type information as a key. Two class registries are maintained by MDARTS, one for interface classes and one for database service classes.
Reference: [86] <author> P. Tang, P.-C. Yew, and C.-Q. Zhu, </author> <title> "A parallel linked list for shared-memory multiprocessors," </title> <booktitle> in IEEE Int'l Computer Software & Applications Conf., </booktitle> <pages> pp. 130-135, </pages> <month> September </month> <year> 1989. </year>
Reference-contexts: Semantic and object-based concurrency control protocols extend this idea by characterizing which transactions conflict and thus require serialization [7, 21, 40]. Another approach to reducing locking conflicts is to design transaction protocols that use data versioning to avoid locking altogether <ref> [79, 86, 90, 91] </ref>. MDARTS objects can use similar techniques in providing concurrency control for their transaction methods. MDARTS does not dictate concurrency control policies, but the MDARTS object-oriented approach facilitates the use of semantic and object-based concurrency control.
Reference: [87] <author> H. Tokuda and C. Mercer, </author> <title> "Arts: A distributed real-time kernel," </title> <journal> SIGOPS, </journal> <volume> vol. 23, no. 3, </volume> , <year> 1989. </year>
Reference-contexts: By associating a computation with the context of an object's encapsulated state, higher-level application software need not explicitly maintain implementation-specific state information. CHAOS [26, 27, 65], Maruti [44, 54], and ARTS <ref> [87] </ref> provide support for real-time objects at the kernel level of an operating system. ARTS supports real-time objects with lightweight threads and multiple task scheduling policies. A major emphasis in ARTS is the provision of exception handling if deadlines are violated.
Reference: [88] <author> O. Ulusoy and G. G. Belford, </author> <title> "Real-time lock-based concurrency control in distributed database systems," </title> <booktitle> in Proc. Int. Conf. on Distributed Computer Systems, </booktitle> <pages> pp. 136-143, </pages> <year> 1992. </year>
Reference-contexts: Furthermore, these main memory database systems do not provide worst-case guarantees for their transactions. Hard real-time systems need worst-case guarantees to ensure that all deadlines will be met. Of the prior real-time database prototypes reported in <ref> [13, 41, 34, 70, 77, 88] </ref>, none provides hard real-time guarantees, and none has average transaction times of less than 100 milliseconds. Thus, these database systems are not suitable for high-speed hard real-time systems such as machine tool controllers.
Reference: [89] <author> D. Ungar and R. B. Smith, </author> <title> "Self: The power of simplicity," </title> <booktitle> in Proc. of OOPSLA, </booktitle> <pages> pp. 227-242, </pages> <month> October </month> <year> 1987. </year>
Reference-contexts: The best known example of this approach is Self, a language which uses exemplars and delegation to dispense with classes altogether <ref> [89] </ref>. While exemplars in Self form the basis of a complete programming paradigm, exemplars can be useful in a class-based object-oriented context as well. Coplien illustrates the use of exemplar-based programming in C++ [16].
Reference: [90] <author> K. Vidyasankar, </author> <title> "An elegant 1-writer multireader multivalued atomic register," </title> <journal> Information Processing Letters, </journal> <pages> pp. 221-223, </pages> <month> March </month> <year> 1989. </year>
Reference-contexts: Semantic and object-based concurrency control protocols extend this idea by characterizing which transactions conflict and thus require serialization [7, 21, 40]. Another approach to reducing locking conflicts is to design transaction protocols that use data versioning to avoid locking altogether <ref> [79, 86, 90, 91] </ref>. MDARTS objects can use similar techniques in providing concurrency control for their transaction methods. MDARTS does not dictate concurrency control policies, but the MDARTS object-oriented approach facilitates the use of semantic and object-based concurrency control. <p> For example, a fundamental constraint type is the transaction times for concurrent read or write transactions. There are many algorithms that support concurrent data access. Faster algorithms generally require semantic restrictions such as allowing only a single writer at a given time <ref> [90, 91] </ref>. If multiple concurrent writers are allowed, additional overhead is required to lock and unlock the data and to wait if another task is updating it. The MDARTS library contains data management classes optimized for restricted concurrency semantics as well as classes that support more general semantics. <p> This constraint allows the MdartsArray&lt;T&gt; class to use efficient concurrency control algorithms and provides protection from unauthorized data access. By alternating updates to two copies of the data as described by Vidyasankar <ref> [90] </ref>, MDARTS can perform concurrent read and write transactions without locking the data. This technique relies on the restriction that only one write transaction will be active at a given time. The "exclusive update" constraint guarantees that this will be the case. <p> To implement concurrency control in MDARTS we propose the following principles. Our current implementation reflects all of these ideas except data versioning. Avoid unnecessary locking. When possible, use data versioning [39, 79] or multiple data copies <ref> [90] </ref> to permit concurrent read and write operations without locking. Match locking granularity with data semantics. This ensures that locking does not unnecessarily restrict concurrency. Sha et al. [66], Badrinath and Ramamritham [6], and Son [79] all propose locking only the data affected by a transaction.
Reference: [91] <author> K. Vidyasankar, </author> <title> "Concurrent reading while writing revisited," </title> <booktitle> Distributed Computing, </booktitle> <pages> pp. 81-85, </pages> <year> 1990. </year>
Reference-contexts: Semantic and object-based concurrency control protocols extend this idea by characterizing which transactions conflict and thus require serialization [7, 21, 40]. Another approach to reducing locking conflicts is to design transaction protocols that use data versioning to avoid locking altogether <ref> [79, 86, 90, 91] </ref>. MDARTS objects can use similar techniques in providing concurrency control for their transaction methods. MDARTS does not dictate concurrency control policies, but the MDARTS object-oriented approach facilitates the use of semantic and object-based concurrency control. <p> For example, a fundamental constraint type is the transaction times for concurrent read or write transactions. There are many algorithms that support concurrent data access. Faster algorithms generally require semantic restrictions such as allowing only a single writer at a given time <ref> [90, 91] </ref>. If multiple concurrent writers are allowed, additional overhead is required to lock and unlock the data and to wait if another task is updating it. The MDARTS library contains data management classes optimized for restricted concurrency semantics as well as classes that support more general semantics. <p> By declaring these hints, the application is expressing a willingness to abide by whatever restrictions are implicit in these hints. For example, single-writer concurrency control protocols can reduce locking delays compared to more general concur 58 rency control methods <ref> [91] </ref>. However, a server object cannot control application behavior to ensure that the single-writer restriction is followed. With contracts, a single-writer server class would not be chosen unless the application explicitly indicated in the contract that it would avoid concurrent updates (by specifying a concurrency constraint such as "exclusive update").
Reference: [92] <author> W. Weihl and B. Liskov, </author> <title> "Implementation of resilient, atomic data types," </title> <journal> ACM Trans. Programming Languages and Systems, </journal> <volume> vol. 7, no. 2, </volume> <pages> pp. 245-269, </pages> <month> April </month> <year> 1985. </year>
Reference-contexts: We were primarily motivated to use object-based concurrency control to avoid the over 50 head of client-server communication. Without a database server to manage concurrency, the database objects must supply their own concurrency control. In other words, the database objects should be atomic data types <ref> [92, 73] </ref>. An atomic data type is essentially a class whose methods guarantee serial behavior in the presence of concurrent requests.
Reference: [93] <author> W. E. Weihl, </author> <title> "Commutativity-based concurrency control for abstract data types," </title> <journal> IEEE Trans. Computers, </journal> <volume> vol. 37, no. 12, </volume> <pages> pp. 1488-1505, </pages> <month> December </month> <year> 1988. </year> <month> 132 </month>
Reference-contexts: Since the concurrency control can be individually tailored according to the semantics of the class member functions, it is possible to achieve higher levels of concurrency than with traditional read-write locking <ref> [21, 72, 93] </ref>. It is also possible to implement atomicity in a base class and inherit this property in derived subclasses [20]. MDARTS shared-memory objects differ from atomic data types and semantic concurrency control techniques described in the literature in that MDARTS objects are fragmented across multiple separate processes.
Reference: [94] <author> R. Wirfs-Brock and B. Wilkerson, </author> <title> "Object-oriented design: A responsibility-driven approach," </title> <booktitle> in Proc. of OOPSLA, </booktitle> <pages> pp. 71-75, </pages> <month> October </month> <year> 1989. </year>
Reference-contexts: Although several researchers have used the contract metaphor, there is little consensus on what a software contract should specify or how it should be expressed. Wirfs-Brock et al. define contracts to be the set of methods exported by a server object <ref> [94, 95] </ref>. In this case, the contract is pure metaphor: a useful perspective on existing structure. The Eiffel language provides support for a more tangible form of software contracts [52]. Contracts in Eiffel are constraints on the pre- and post- conditions of functions. <p> Helm et al. propose a higher-level use of the contract metaphor in which contracts specify roles and interactions between cooperating objects [33]. Applications instantiate contracts at runtime by selecting classes for the various roles. Like the software contracts described by Wirfs-Brock et al. <ref> [94] </ref> and Meyer [52], our contracts apply constraints to individual objects rather than behavioral compositions as in Helm et al. [33]. <p> Furthermore, we distinguish between explicit software contracts and implied software contracts. The implied part of a contract corresponds roughly to the contracts in <ref> [52, 94] </ref>; the explicit part is the subject of this chapter. We base our approach to software contracts on the following analogy with contract law. When a legal contract is established between a service provider and a client, there is both an express and an implied contract. <p> For example, a server object that supports concurrent access could use simplified locking protocols if it knew the application would not perform concurrent update operations. This semantic constraint could be supplied by the application in the contract. Wirfs-Brock et al. <ref> [94] </ref> and Meyer [52] focus on contracts defined by server objects. Since the server dictates all the terms, there is no way for applications to add clauses or establish their own contracts.
Reference: [95] <author> R. Wirfs-Brock, B. Wilkerson, and L. Wiener, </author> <title> Designing Object-Oriented Software, </title> <publisher> Prentice-Hall, </publisher> <year> 1990. </year>
Reference-contexts: Although several researchers have used the contract metaphor, there is little consensus on what a software contract should specify or how it should be expressed. Wirfs-Brock et al. define contracts to be the set of methods exported by a server object <ref> [94, 95] </ref>. In this case, the contract is pure metaphor: a useful perspective on existing structure. The Eiffel language provides support for a more tangible form of software contracts [52]. Contracts in Eiffel are constraints on the pre- and post- conditions of functions.
References-found: 95

