URL: http://ftp.cs.yale.edu/pub/technical-reports/tr1062.ps.gz
Refering-URL: http://ftp.cs.yale.edu/pub/technical-reports/
Root-URL: http://www.cs.yale.edu
Title: A graduated assignment algorithm for graph matching  
Author: Steven Gold and Anand Rangarajan 
Affiliation: Department of Computer Science, and Yale Center for Theoretical and Applied Neuroscience (CTAN) Yale University  
Abstract: A graduated assignment algorithm for graph matching is presented which is fast and accurate even in the presence of high noise. By combining graduated non-convexity (deterministic annealing), two-way (assignment) constraints, and sparsity, large improvements in accuracy and speed are achieved. Its low order computational complexity (O(lm), where l and m are the number of links in the two graphs) and robustness in the presence of noise offer advantages over traditional combinatorial approaches. The algorithm, not restricted to any special class of graph, is applied to subgraph isomorphism, weighted graph matching, and attributed relational graph matching. To illustrate the performance of the algorithm, attributed relational graphs derived from objects are matched. Then, results from twenty-five thousand experiments conducted on 100 node random graphs of varying types (graphs with only zero-one links, weighted graphs, and graphs with node attributes) are reported. No comparable results have been reported by any other graph matching algorithm before in the research literature. Twenty-five hundred control experiments are conducted using a standard form of probabilistic relaxation and large improvements in accuracy are demonstrated. Graduated assignment bears a close relationship to methods within statistical physics that are now being applied to neural networks. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Almohamad, H. A. and Duffuaa, S. O. </author> <year> (1993). </year> <title> A linear programming approach for the weighted graph matching problem. </title> <journal> IEEE Trans. Patt. Anal. Mach. Intell., </journal> <volume> 15(5) </volume> <pages> 522-525. </pages>
Reference: <author> Bertsekas, D. P. and Tsitsiklis, J. N. </author> <year> (1989). </year> <title> Parallel and Distributed Computation: Numerical Methods. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ. </address>
Reference-contexts: However, the weighted graph matching problem we are trying to solve is much harder than the assignment problem it is similar to a quadratic 10 assignment problem which is NP-complete (Garey and Johnson, 1979) as opposed to the assignment problem which can be solved in polynomial time <ref> (Bertsekas and Tsitsiklis, 1989) </ref>. Since we have already described a method to solve the assignment problem, we will find an approximate solution to our quadratic assignment problem by using a continuation method to solve a succession of assignment problems.
Reference: <author> Blake, A. and Zisserman, A. </author> <year> (1987). </year> <title> Visual Reconstruction. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference-contexts: The rows and columns of this matrix add up to one, and in the case where the two sets of objects are equal in size the match matrix is a permutation matrix. Graduated-non-convexity <ref> (Blake and Zisserman, 1987) </ref> is used to turn these discrete variables into continuous ones in order to reduce the chances of getting trapped in local minima.
Reference: <author> Bridle, J. S. </author> <year> (1990). </year> <title> Training stochastic model recognition algorithms as networks can lead to maximum mutual information estimation of parameters. </title> <editor> In Touretzky, D. S., editor, </editor> <booktitle> Advances in Neural Information Processing Systems 2, </booktitle> <pages> pages 211-217, </pages> <address> San Mateo, CA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: This discrete problem may now be formulated as a continuous problem by introducing a control parameter fi &gt; 0 and then setting m as follows (Peterson and Soderberg, 1989; Geiger and Yuille, 1991) : m j = P I This is known as softmax <ref> (Bridle, 1990) </ref>. The exponentiation used within softmax has the effect of ensuring that all the elements of fm i g are positive.
Reference: <author> Chen, T.-W. and Lin, W.-C. </author> <year> (1994). </year> <title> A neural network approach to CSG-based 3-D object recognition. </title> <journal> IEEE Trans. Patt. Anal. Mach. Intell., </journal> <volume> 16(7) </volume> <pages> 719-725. </pages>
Reference-contexts: Some of these elements have been explored before in graph matching algorithms. (Li, 1992) briefly mentions trying to use a graduated non-convexity approach within 3 the relaxation labeling framework with some success. However he still uses the stan-dard one-way constraint of relaxation labeling. <ref> (Chen and Lin, 1994) </ref> use a continuation method (deterministic annealing). They also try to enforce two-way constraints, but via a penalty function a method of constraint satisfaction that has met with poor results in related combinatorial optimization problems (Pelillo, 1994; Kamgar-Parsi and Kamgar-Parsi, 1990; Wilson and Pawley, 1988).
Reference: <author> Chvatal, V. </author> <year> (1983). </year> <title> Linear Programming. </title> <editor> W. H. </editor> <publisher> Freeman and Company, </publisher> <address> New York. </address>
Reference-contexts: As we iterate we slowly increase our control parameter fi. One last detail needs to be resolved. The constraints on M are inequality constraints, not equality constraints. Therefore, we transform the inequality constraints into equality constraints by introducing slack variables, a standard technique from 11 linear programming <ref> (Chvatal, 1983) </ref>; 8a i=1 I+1 X M ai = 1 and likewise for our column constraints. An extra row and column are added to the matrix M to hold the slack variables (figure 2).
Reference: <author> Davis, L. S. </author> <year> (1979). </year> <title> Shape matching using relaxation techniques. </title> <journal> IEEE Trans. Patt. Anal. Mach. Intell., </journal> <volume> 1(1) </volume> <pages> 60-72. </pages>
Reference: <author> Elfadel, I. M. and Yuille, A. L. </author> <year> (1993). </year> <title> Mean-field phase transitions and correlation functions for Gibbs random fields. </title> <journal> J. Math. Imaging Vision, </journal> <volume> 3(2) </volume> <pages> 167-186. </pages>
Reference: <author> Eshera, M. A. and Fu, K. S. </author> <year> (1984). </year> <title> A graph distance measure for image analysis. </title> <journal> IEEE Trans. Syst. Man, Cybern., </journal> <volume> 14(3) </volume> <pages> 398-407. </pages>
Reference-contexts: However even under these assumptions, the algorithm typically has a high-order polynomial complexity. For example the method in <ref> (Eshera and Fu, 1984) </ref>, is approximately O (l 3 m 2 ) complexity (where l and m are the number of links in the two graphs), though special instances are faster. The second approach employs nonlinear optimization methods (or heuristic approximations thereof). <p> A state-space search algorithm is described in <ref> (Eshera and Fu, 1984) </ref> with a computational complexity of approximately O (l 3 m 2 ). In one experiment outlined in (Eshera and Fu, 1986), attributed relational graph matching was used to locate an object within a multiobject scene.
Reference: <author> Eshera, M. A. and Fu, K. S. </author> <year> (1986). </year> <title> An image understanding system using attributed symbolic representation and inexact graph-matching. </title> <journal> IEEE Trans. Patt. Anal. Mach. Intell., </journal> <volume> 8(5) </volume> <pages> 604-619. </pages>
Reference-contexts: First, we repeated an experiment with attributed relational graphs first constructed by Eshera and Fu <ref> (Eshera and Fu, 1986) </ref> who used a tree-search method to perform the matching. Second, we hand designed attributed relational graphs from real images and matched them. <p> Finally, we ran probabilistic relaxation as a control for the above experiments on randomly generated graphs. 3.1 Graphs from Images 17 In <ref> (Eshera and Fu, 1986) </ref>, an image understanding system was developed using attributed relational graphs as a way of representing object models or scenes. A state-space search algorithm is described in (Eshera and Fu, 1984) with a computational complexity of approximately O (l 3 m 2 ). <p> A state-space search algorithm is described in (Eshera and Fu, 1984) with a computational complexity of approximately O (l 3 m 2 ). In one experiment outlined in <ref> (Eshera and Fu, 1986) </ref>, attributed relational graph matching was used to locate an object within a multiobject scene. ARGs were produced from real images using a multilayer graph transducer scheme. <p> We ran our graduated assignment algorithm against these two sparse graphs consisting of 7 and 27 nodes respectively, with all the attribute and link values exactly as reported in <ref> (Eshera and Fu, 1986) </ref>, but normalized to one, over the maximum value for each link and attribute type. The algorithm returned a match matrix with the 100% correct assignment between the two graphs using the compatibility functions outlined previously. <p> We have demonstrated that it will work on a problem from the research literature <ref> (Eshera and Fu, 1986) </ref>, applied it to graphs from real images, tested it on a wide variety of graphs under conditions of noise, and benchmarked it against a standard method. The method is universal|it is applicable to any type of graph. It has low order computational complexity (O (lm)).
Reference: <author> Faugeras, O. </author> <year> (1981). </year> <title> Improving consistency and reducing ambiguity in stochastic labeling: an optimization approach. </title> <journal> IEEE Trans. Patt. Anal. Mach. Intell., </journal> <volume> 3(4) </volume> <pages> 412-424. </pages>
Reference: <author> Feldman, J. A., Fanty, M. A., and Goddard, N. H. </author> <year> (1988). </year> <title> Computing with structured neural networks. </title> <journal> IEEE Computer, </journal> <volume> 21(3) </volume> <pages> 91-103. </pages>
Reference: <author> Fu, K. S. </author> <year> (1983). </year> <title> A step towards unification of syntactic and statistical pattern recognition. </title> <journal> IEEE Trans. Patt. Anal. Mach. Intell., </journal> <volume> 5(2) </volume> <pages> 200-205. </pages>
Reference-contexts: One approach has been to represent the images or objects in the form of graphs. A weighted graph may be used to formulate a structural description of an object (Shapiro and Haralick, 1981). Such descriptions can be further enhanced with parametric information and represented by attributed relational graphs (ARGs) <ref> (Fu, 1983) </ref>. Because of the representational power of graphs, much effort has gone into the development of efficient algorithms which can effectively match graphs. Two main approaches have been tried. <p> These algorithms are of exponential time worst-case complexity. However the assumption is made, that with the help of heuristics, the size of each level of the resulting state-space search tree will be reduced to a low order polynomial (as a function of the number of nodes of the graphs) <ref> (Tsai and Fu, 1983) </ref>. However even under these assumptions, the algorithm typically has a high-order polynomial complexity.
Reference: <author> Garey, M. R. and Johnson, D. S. </author> <year> (1979). </year> <title> Computers and intractability: a guide to the theory of NP-completeness. </title> <editor> W. H. </editor> <publisher> Freeman, </publisher> <address> San Francisco, CA. </address>
Reference-contexts: The expected value will be zero, because two points chosen from a uniform distribution in the unit interval will be on average 1 3 units apart. 6 When c is defined in the above manner, the weighted graph matching problem contains the largest common subgraph problem <ref> (Garey and Johnson, 1979) </ref> as a special case. <p> Since the largest common subgraph problem is NP-complete <ref> (Garey and Johnson, 1979) </ref> and it is a special case of our weighted graph matching problem, the weighted graph matching problem is also NP-complete (with the c function defined as above). <p> However, the weighted graph matching problem we are trying to solve is much harder than the assignment problem it is similar to a quadratic 10 assignment problem which is NP-complete <ref> (Garey and Johnson, 1979) </ref> as opposed to the assignment problem which can be solved in polynomial time (Bertsekas and Tsitsiklis, 1989).
Reference: <author> Geiger, D. and Girosi, F. </author> <year> (1991). </year> <title> Parallel and deterministic algorithms from MRFs: Surface reconstruction. </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, </journal> <volume> 13(5) </volume> <pages> 401-412. </pages> <note> 30 Geiger, </note> <author> D. and Yuille, A. L. </author> <year> (1991). </year> <title> A common framework for image segmentation. </title> <journal> Intl. Journal of Computer Vision, </journal> 6(3):227-243. 
Reference: <author> Gold, S., Lu, C. P., Rangarajan, A., Pappu, S., and Mjolsness, E. </author> <year> (1994a). </year> <title> New algorithms for 2-D and 3-D point matching: pose estimation and correspondence. </title> <type> Technical Report YALEU/DCS/RR-1035, </type> <institution> Department of Computer Science, Yale University. </institution> <note> To appear in Advances in Neural Information Processing Systems 7. </note>
Reference: <author> Gold, S., Mjolsness, E., and Rangarajan, A. </author> <year> (1994b). </year> <title> Clustering with a domain specific distance measure. </title> <editor> In Cowan, J., Tesauro, G., and Alspector, J., editors, </editor> <booktitle> Advances in Neural Information Processing Systems 6. </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Francisco, CA. </address>
Reference-contexts: Graduated assignment, through its use of iterative projective scaling, eliminates the need for penalty functions. We took the first steps towards the development of this algorithm by applying the graduated assignment technique to a parametric assignment problem | point-matching (with point sets of equal size) in <ref> (Gold et al., 1994b) </ref>. This was extended to points sets of unequal size in (Gold et al., 1994a; Gold et al., 1994c).
Reference: <author> Gold, S., Rangarajan, A., and Mjolsness, E. </author> <year> (1994c). </year> <title> Learning with preknowledge: clustering with point- and graph-matching distance measures. </title> <type> Technical Report YALEU/DCS/RR-1037, </type> <institution> Department of Computer Science, Yale University. </institution> <note> To appear in Advances in Neural Information Processing Systems 7. </note>
Reference-contexts: This was extended to points sets of unequal size in (Gold et al., 1994a; Gold et al., 1994c). The method was first applied to graph matching (graphs of equal size) in <ref> (Gold et al., 1994c) </ref> and then to graphs of unequal size in (Rangarajan et al., 1994).
Reference: <author> Hummel, R. and Zucker, S. </author> <year> (1983). </year> <title> On the foundations of relaxation labeling processes. </title> <journal> IEEE Trans. Patt. Anal. Mach. Intell., </journal> <volume> 5(3) </volume> <pages> 267-287. </pages>
Reference: <author> Jordan, M. I. and Jacobs, R. A. </author> <year> (1994). </year> <title> Hierarchical mixtures of experts and the EM algorithm. </title> <journal> Neural Computation, </journal> <volume> 6(2) </volume> <pages> 181-214. </pages>
Reference: <author> Kamgar-Parsi, B. and Kamgar-Parsi, B. </author> <year> (1990). </year> <title> On problem solving with Hopfield networks. </title> <journal> Biological Cybernetics, </journal> <volume> 62 </volume> <pages> 415-423. </pages>
Reference: <author> Kittler, J., Christmas, W. J., and Petrou, M. </author> <year> (1993). </year> <title> Probabilistic relaxation for matching problems in computer vision. </title> <booktitle> In Fourth Intl. Conf. on Computer Vision, </booktitle> <pages> pages 666-673. </pages> <publisher> IEEE Press. </publisher>
Reference-contexts: Related results (i.e. the importance of attribute [unary] information) have also been reported within the probabilistic relaxation framework <ref> (Kittler et al., 1993) </ref>. The difference in performance between graduated assignment and probabilistic relaxation is still large (next section). 17600 experiments were run with attributed relational graphs.
Reference: <author> Kosowsky, J. J. and Yuille, A. L. </author> <year> (1994). </year> <title> The invisible hand algorithm: Solving the assignment problem with statistical physics. </title> <booktitle> Neural Networks, </booktitle> <volume> 7(3) </volume> <pages> 477-490. </pages>
Reference-contexts: A control parameter may be adjusted at each step to slowly move the matrix closer to 0-1 values. The method has been applied to assignment <ref> (Kosowsky and Yuille, 1994) </ref>, parametric assignment (Gold et al., 1994b; Gold et al., 1994a), and quadratic assignment (Gold et al., 1994c; Rangarajan et al., 1994) problems. <p> Just such an algorithm was used in <ref> (Kosowsky and Yuille, 1994) </ref> to exactly solve the assignment problem (the global maximum is found). <p> For each assignment the continuation method returns the corresponding globally optimal doubly stochastic matrix for the current value of the control parameter <ref> (Kosowsky and Yuille, 1994) </ref>. Since a doubly stochastic matrix (and not a permutation matrix) is returned for each assignment problem at the current value of the control parameter we term this a softassign.
Reference: <author> Lawler, E. and Wood, D. </author> <year> (1966). </year> <title> Branch and bound methods: A survey. </title> <journal> Operations Research, </journal> <volume> 14(4) </volume> <pages> 699-719. </pages> <note> 31 Lawler, </note> <author> E. L., Lenstra, J. K., Kan, A. H. G. R., and Shmoys, D. B., </author> <title> editors (1985). The Traveling Salesman Problem. </title> <publisher> John Wiley and Sons, </publisher> <address> Chichester. </address>
Reference-contexts: Two main approaches have been tried. One approach involves the construction of a state-space which is then searched with techniques similar to the branch and bound methods employed in operations research <ref> (Lawler and Wood, 1966) </ref>. These algorithms are of exponential time worst-case complexity.
Reference: <author> Leclerc, Y. G. </author> <year> (1989). </year> <title> Constructing simple stable descriptions for image partitioning. </title> <journal> International Journal of Computer Vision, </journal> <volume> 3(1) </volume> <pages> 73-102. </pages>
Reference: <author> Li, S. Z. </author> <year> (1992). </year> <title> Matching: invariant to translations, rotations and scale changes. </title> <journal> Pattern Recognition, </journal> <volume> 25 </volume> <pages> 583-594. </pages>
Reference-contexts: Iterative projective scaling, graduated non-convexity and sparsity form the key components of our new algorithm. Some of these elements have been explored before in graph matching algorithms. <ref> (Li, 1992) </ref> briefly mentions trying to use a graduated non-convexity approach within 3 the relaxation labeling framework with some success. However he still uses the stan-dard one-way constraint of relaxation labeling. (Chen and Lin, 1994) use a continuation method (deterministic annealing). <p> We omit a detailed description of the above objective which can be used to match graphs with multiple link types and multiple attributes. For a fuller exposition of the construction and use of graphs with multiple relations, attributes, and compatibility functions see <ref> (Li, 1992) </ref>. We demonstrate how the algorithm can be applied to more complex graphs with another example. Suppose the weighted graph of the previous section now has a single attribute.
Reference: <author> Luenberger, D. </author> <year> (1984). </year> <title> Linear and Nonlinear Programming. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA. </address>
Reference-contexts: It convexifies the objective, with the parameter fi controlling the degree of convexity. It is different from a barrier function, because it does not favor points in the interior of the feasible set over those near the boundary <ref> (Luenberger, 1984) </ref>. 16 Other smoothing functions may perform just as well, however (5) can be derived using techniques from statistical physics which have been applied to other combinatorial optimization problems (Elfadel and Yuille, 1993; Yuille and Kosowsky, 1994; Van den Bout and Miller III, 1990; Peterson and Soderberg, 1989). (Peterson and
Reference: <author> Mjolsness, E. and Garrett, C. </author> <year> (1990). </year> <title> Algebraic transformations of objective functions. </title> <booktitle> Neural Networks, </booktitle> <volume> 3 </volume> <pages> 651-669. </pages>
Reference: <author> Mjolsness, E., Gindi, G., and Anandan, P. </author> <year> (1989). </year> <title> Optimization in model matching and perceptual organization. </title> <journal> Neural Computation, </journal> <volume> 1 </volume> <pages> 218-229. </pages>
Reference: <author> Papadimitriou, C. and Steiglitz, K. </author> <year> (1982). </year> <title> Combinatorial Optimization. </title> <publisher> Prentice-Hall, Inc., </publisher> <address> Englewood Cliffs, NJ. </address>
Reference-contexts: Our aim is to find the matrix M (a permutation matrix) which maximizes the following: E a (M ) = a=1 i=1 This is known as the assignment problem, a classic problem in combinatorial optimization <ref> (Papadimitriou and Steiglitz, 1982) </ref>.
Reference: <author> Peleg, S. </author> <year> (1980). </year> <title> A new probabilistic relaxation scheme. </title> <journal> IEEE Trans. Patt. Anal. Mach. Intell., </journal> <volume> 2(4) </volume> <pages> 362-369. </pages>
Reference: <author> Pelillo, M. </author> <year> (1994). </year> <title> Learning compatibility coefficients for relaxation labeling processes. </title> <journal> IEEE Trans. Patt. Anal. Mach. Intell., </journal> <volume> 16(9) </volume> <pages> 933-945. </pages>
Reference: <author> Peterson, C. and Soderberg, B. </author> <year> (1989). </year> <title> A new method for mapping optimization problems onto neural networks. </title> <journal> Intl. Journal of Neural Systems, </journal> <volume> 1(1) </volume> <pages> 3-22. </pages>
Reference: <author> Price, K. </author> <year> (1985). </year> <title> Relaxation matching techniques|a comparison. </title> <journal> IEEE Trans. Patt. Anal. Mach. Intell., </journal> <volume> 7(5) </volume> <pages> 617-623. </pages>
Reference-contexts: The benchmark is simpler and clearer; possible variations in implementations of these enhancements can be avoided. More importantly, while the enhancements offer some improvements over the original method these improvements are relatively small <ref> (Price, 1985) </ref> compared to the enormous differences in performance between probabilistic relaxation and graduated assignment as demonstrated by our experiments. We implement the original method exactly as outlined in (Rosenfeld and Kak, 1982). We used compatibility functions identical to those used in the graduated assignment experiments.
Reference: <author> Rangarajan, A., Gold, S., and Mjolsness, E. </author> <year> (1994). </year> <title> A novel optimizing network architecture with applications. </title> <type> Technical Report YALEU/DCS/RR-1036, </type> <institution> Department of Computer Science, Yale University. </institution> <note> 32 Rangarajan, </note> <author> A. and Mjolsness, E. </author> <year> (1994). </year> <title> A Lagrangian relaxation network for graph matching. </title> <booktitle> In IEEE Intl. Conf. on Neural Networks (ICNN), </booktitle> <volume> volume 7, </volume> <pages> pages 4629-4634. </pages> <publisher> IEEE Press. </publisher>
Reference-contexts: Other nonlinear optimization approaches are neural networks, (Mjolsness et al., 1989; Mjolsness and Garrett, 1990; Simic, 1991; Yu and Tsai, 1992; Young et al., 1994; Chen and Lin, 1994), linear programming (Al-mohamad and Duffuaa, 1993), eigendecomposition (Umeyama, 1988) and Lagrangian relaxation <ref> (Rangarajan and Mjolsness, 1994) </ref>. <p> This was extended to points sets of unequal size in (Gold et al., 1994a; Gold et al., 1994c). The method was first applied to graph matching (graphs of equal size) in (Gold et al., 1994c) and then to graphs of unequal size in <ref> (Rangarajan et al., 1994) </ref>. However, because the graph-matching objective used in (Rangarajan et al., 1994) was originally designed for graphs with equal number of nodes (Rangarajan and Mjolsness, 1994) it did not handle as well the much more interesting cases of graphs with missing and extra nodes and missing and extra <p> The method was first applied to graph matching (graphs of equal size) in (Gold et al., 1994c) and then to graphs of unequal size in <ref> (Rangarajan et al., 1994) </ref>. However, because the graph-matching objective used in (Rangarajan et al., 1994) was originally designed for graphs with equal number of nodes (Rangarajan and Mjolsness, 1994) it did not handle as well the much more interesting cases of graphs with missing and extra nodes and missing and extra links. <p> However, because the graph-matching objective used in (Rangarajan et al., 1994) was originally designed for graphs with equal number of nodes <ref> (Rangarajan and Mjolsness, 1994) </ref> it did not handle as well the much more interesting cases of graphs with missing and extra nodes and missing and extra links. Moreover sparsity was not explicitly accounted for in the previous methods. <p> In (Sinkhorn, 1964), it is proven that any square matrix whose elements are all positive will converge to a doubly stochastic matrix just by the iterative process of alternatively normalizing the rows and columns, i.e. by iterative projective scaling <ref> (Rangarajan et al., 1994) </ref>. (A doubly stochastic matrix is a matrix whose elements are all positive and whose rows and columns all add up to one it may roughly be thought of as the continuous analog of a permutation matrix).
Reference: <author> Rosenfeld, A., Hummel, R., and Zucker, S. </author> <year> (1976). </year> <title> Scene labeling by relaxation operations. </title> <journal> IEEE Trans. Syst. Man, Cybern., </journal> <volume> 6(6) </volume> <pages> 420-433. </pages>
Reference: <author> Rosenfeld, A. and Kak, A. </author> <year> (1982). </year> <title> Digital Picture Processing, volume 2. </title> <publisher> Academic Press, Inc., </publisher> <address> Orlando, Fl. </address>
Reference-contexts: These two ideas are combined with a third | sparsity, an old technique that has appeared within the probabilistic relaxation framework <ref> (Rosenfeld and Kak, 1982) </ref> which is explicitly encoded to increase efficiency. Iterative projective scaling, graduated non-convexity and sparsity form the key components of our new algorithm. <p> GA - 700 trials. PR - 70 trials most widely known non-linear method would make it a suitable control.) Additionally, because it is widely known, we choose to contrast our technique with the standard method of probabilistic relaxation <ref> (Rosenfeld and Kak, 1982) </ref> rather then implement some enhancements such as variants of gradient projection or the product combination rule (Peleg, 1980; Faugeras, 1981; Hummel and Zucker, 1983). The benchmark is simpler and clearer; possible variations in implementations of these enhancements can be avoided. <p> More importantly, while the enhancements offer some improvements over the original method these improvements are relatively small (Price, 1985) compared to the enormous differences in performance between probabilistic relaxation and graduated assignment as demonstrated by our experiments. We implement the original method exactly as outlined in <ref> (Rosenfeld and Kak, 1982) </ref>. We used compatibility functions identical to those used in the graduated assignment experiments. All experiments outlined in the above section were repeated in exactly the same manner, except that only 10 trials were run at each data point, instead of 100.
Reference: <author> Shapiro, L. G. and Haralick, R. M. </author> <year> (1981). </year> <title> Structural descriptions and inexact matching. </title> <journal> IEEE Trans. Patt. Anal. Mach. Intell., </journal> <volume> 3(5) </volume> <pages> 504-519. </pages>
Reference-contexts: Many algorithms for matching sets of features, such as points or line segments derived from two images have been explored. One approach has been to represent the images or objects in the form of graphs. A weighted graph may be used to formulate a structural description of an object <ref> (Shapiro and Haralick, 1981) </ref>. Such descriptions can be further enhanced with parametric information and represented by attributed relational graphs (ARGs) (Fu, 1983). Because of the representational power of graphs, much effort has gone into the development of efficient algorithms which can effectively match graphs. Two main approaches have been tried.
Reference: <author> Simic, P. D. </author> <year> (1991). </year> <title> Constrained nets for graph matching and other quadratic assignment problems. </title> <journal> Neural Computation, </journal> <volume> 3 </volume> <pages> 268-281. </pages>
Reference-contexts: These results are extremely good compared to related attempts to handle subgraph isomor-phism with non-linear optimization methods. In addition to probabilistic relaxation which failed completely on this problem (next section) see Simic <ref> (Simic, 1991) </ref> who obtained poorer results using a neural network approach on the much easier problem of graph isomorphism (equal size graphs). We ran 2800 experiments with subgraph isomorphism. The second set of experiments were performed on weighted graphs (Figure 9).
Reference: <author> Sinkhorn, R. </author> <year> (1964). </year> <title> A relationship between arbitrary positive matrices and doubly stochastic matrices. </title> <journal> Ann. Math. Statist., </journal> <volume> 35 </volume> <pages> 876-879. </pages>
Reference-contexts: Our graduated assignment method falls under the rubric of nonlinear optimization. Like probabilistic relaxation, it does not search a state-space and has a low order computational complexity (O (lm)). It differs from probabilistic relaxation in two major ways. Iterative projective scaling, a method discovered by <ref> (Sinkhorn, 1964) </ref> is employed here to satisfy two-way (assignment) constraints. Assignment constraints require the nodes of both graphs to be equally constrained. A node in one graph can match to at most one node in the other graph and vice versa. <p> The technique is an iterative one, where at each step, an estimate is made of the match matrix and then iterative projective scaling (repeated row and column normalizations) <ref> (Sinkhorn, 1964) </ref> is used to ensure that the match matrix 4 remains the continuous analog of a true assignment (all the rows and columns add up to one). A control parameter may be adjusted at each step to slowly move the matrix closer to 0-1 values. <p> Fortunately, these two constraints can be satisfied using a remarkable result due to <ref> (Sinkhorn, 1964) </ref>. In (Sinkhorn, 1964), it is proven that any square matrix whose elements are all positive will converge to a doubly stochastic matrix just by the iterative process of alternatively normalizing the rows and columns, i.e. by iterative projective scaling (Rangarajan et al., 1994). (A doubly stochastic matrix is a <p> Fortunately, these two constraints can be satisfied using a remarkable result due to <ref> (Sinkhorn, 1964) </ref>. In (Sinkhorn, 1964), it is proven that any square matrix whose elements are all positive will converge to a doubly stochastic matrix just by the iterative process of alternatively normalizing the rows and columns, i.e. by iterative projective scaling (Rangarajan et al., 1994). (A doubly stochastic matrix is a matrix whose elements
Reference: <author> Ton, J. and Jain, A. </author> <year> (1989). </year> <title> Registering Landsat images by point matching. </title> <journal> IEEE Trans. Geo. Rem. Sens., </journal> <volume> 27(5) </volume> <pages> 642-651. </pages>
Reference-contexts: Probabilistic relaxation does not search the state-space and generally has a much lower computational complexity (O (lm) or perhaps even lower see <ref> (Ton and Jain, 1989) </ref>) than tree search methods. <p> Assignment constraints require the nodes of both graphs to be equally constrained. A node in one graph can match to at most one node in the other graph and vice versa. Probabilistic relaxation, a tool for classification, only enforces a one-way constraint. <ref> (Ton and Jain, 1989) </ref> use this concept of two-way matching, but their technique is not guaranteed to satisfy the constraints, while iterative projective scaling is (Sinkhorn, 1964; Kosowsky and Yuille, 1994; Rangarajan et al., 1994).
Reference: <author> Tsai, W.-H. and Fu, K.-S. </author> <year> (1983). </year> <title> Subgraph error-correcting isomorphisms for syntactic pattern recognition. </title> <journal> IEEE Trans. Syst. Man, Cybern., </journal> <volume> 13(1) </volume> <pages> 48-62. </pages>
Reference-contexts: These algorithms are of exponential time worst-case complexity. However the assumption is made, that with the help of heuristics, the size of each level of the resulting state-space search tree will be reduced to a low order polynomial (as a function of the number of nodes of the graphs) <ref> (Tsai and Fu, 1983) </ref>. However even under these assumptions, the algorithm typically has a high-order polynomial complexity.
Reference: <author> Umeyama, S. </author> <year> (1988). </year> <title> An eigendecomposition approach to weighted graph matching problems. </title> <journal> IEEE Trans. Patt. Anal. Mach. Intell., </journal> <volume> 10(5) </volume> <pages> 695-703. </pages>
Reference-contexts: Other nonlinear optimization approaches are neural networks, (Mjolsness et al., 1989; Mjolsness and Garrett, 1990; Simic, 1991; Yu and Tsai, 1992; Young et al., 1994; Chen and Lin, 1994), linear programming (Al-mohamad and Duffuaa, 1993), eigendecomposition <ref> (Umeyama, 1988) </ref> and Lagrangian relaxation (Rangarajan and Mjolsness, 1994).
Reference: <author> Van den Bout, D. E. and Miller III, T. K. </author> <year> (1990). </year> <title> Graph partitioning using annealed networks. </title> <journal> IEEE Trans. Neural Networks, </journal> <volume> 1(2) </volume> <pages> 192-203. </pages>
Reference: <author> Wilson, G. and Pawley, G. </author> <year> (1988). </year> <title> On the stability of the traveling salesman problem algorithm of Hopfield and Tank. </title> <journal> Biological Cybernetics, </journal> <volume> 58 </volume> <pages> 63-70. </pages>
Reference: <author> Young, S. S., Scott, P. D., and Nasrabadi, N. M. </author> <year> (1994). </year> <title> Object recognition using multi-layer Hopfield neural network. </title> <booktitle> In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), </booktitle> <pages> pages 417-422. </pages> <note> IEEE Press. 33 Yu, </note> <author> S.-S. and Tsai, W.-H. </author> <year> (1992). </year> <title> Relaxation by the Hopfield neural network. </title> <journal> Pattern Recognition, </journal> <volume> 25(2) </volume> <pages> 197-208. </pages>
Reference: <author> Yuille, A. L. and Kosowsky, J. J. </author> <year> (1994). </year> <title> Statistical physics algorithms that converge. </title> <journal> Neural Computation, </journal> <volume> 6(3) </volume> <pages> 341-356. </pages>
Reference-contexts: A control parameter may be adjusted at each step to slowly move the matrix closer to 0-1 values. The method has been applied to assignment <ref> (Kosowsky and Yuille, 1994) </ref>, parametric assignment (Gold et al., 1994b; Gold et al., 1994a), and quadratic assignment (Gold et al., 1994c; Rangarajan et al., 1994) problems. <p> Just such an algorithm was used in <ref> (Kosowsky and Yuille, 1994) </ref> to exactly solve the assignment problem (the global maximum is found). <p> For each assignment the continuation method returns the corresponding globally optimal doubly stochastic matrix for the current value of the control parameter <ref> (Kosowsky and Yuille, 1994) </ref>. Since a doubly stochastic matrix (and not a permutation matrix) is returned for each assignment problem at the current value of the control parameter we term this a softassign.
Reference: <author> Yuille, A. L., Stolorz, P., and Utans, J. </author> <year> (1994). </year> <title> Statistical physics, mixtures of distributions, and the EM algorithm. </title> <journal> Neural Computation, </journal> <volume> 6(2) </volume> <pages> 334-340. 34 </pages>
Reference-contexts: A control parameter may be adjusted at each step to slowly move the matrix closer to 0-1 values. The method has been applied to assignment <ref> (Kosowsky and Yuille, 1994) </ref>, parametric assignment (Gold et al., 1994b; Gold et al., 1994a), and quadratic assignment (Gold et al., 1994c; Rangarajan et al., 1994) problems. <p> Just such an algorithm was used in <ref> (Kosowsky and Yuille, 1994) </ref> to exactly solve the assignment problem (the global maximum is found). <p> For each assignment the continuation method returns the corresponding globally optimal doubly stochastic matrix for the current value of the control parameter <ref> (Kosowsky and Yuille, 1994) </ref>. Since a doubly stochastic matrix (and not a permutation matrix) is returned for each assignment problem at the current value of the control parameter we term this a softassign.
References-found: 48

