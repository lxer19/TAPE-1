URL: ftp://ftp.icsi.berkeley.edu/pub/techreports/1992/tr-92-025.ps.gz
Refering-URL: http://www.icsi.berkeley.edu/techreports/1992.html
Root-URL: http://www.icsi.berkeley.edu
Title: Tree Matching with Recursive Distributed Representations  
Author: Andreas Stolcke Dekai Wu 
Note: Paper to be presented at the Workshop on Integrating Neural and Symbolic Processes|the Cognitive Dimension at the National Conference on Artificial Intelligence, San Jose, CA,  
Date: April 1992  July 1992.  
Pubnum: TR-92-025  
Abstract: We present an approach to the structure unification problem using distributed representations of hierarchical objects. Binary trees are encoded using the recursive auto-association method (RAAM), and a unification network is trained to perform the tree matching operation on the RAAM representations. It turns out that this restricted form of unification can be learned without hidden layers and producing good generalization if we allow the error signal from the unification task to modify both the unification network and the RAAM representations themselves. y Computer Science Division, University of California at Berkeley, and International Computer Science Institute, 1947 Center St., Berkeley, CA 94704, stolcke@icsi.berkeley.edu. Research supported by an IBM Graduate Fellowship and by the International Computer Science Institute. z Department of Computer Science, University of Toronto, Canada M5S 1A4, dekai@cs.toronto.edu. Beginning Fall 1992: Dept. of Computer Science, Hong Kong University of Science and Technology. This research was done at the Computer Science Division, University of California at Berkeley and the International Computer Science Institute, and was sponsored in part by the Defense Advanced Research Projects Agency (DoD), monitored by the Space and Naval Warfare Systems Command under N00039-88-C-0292, the Office of Naval Research under contract N00014-89-J-3205, and the Sloan Foundation under grant 86-10-3. Preparation of this document was partially supported by the Natural Sciences and Engineering Research Council of Canada. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Blank, D. S., L. A. Meeden, & J. B. </author> <title> Marshall (1992). Exploring the symbolic/subsymbolic continuum: A case study of RAAM. </title> <editor> In J. Dinsmore, editor, </editor> <title> Closing the Gap: Symbolism vs. Connectionism. </title> <publisher> Lawrence Erlbaum Associates. To appear. </publisher>
Reference-contexts: See Fig. 1 for examples. 3 RAAM encoding The method proposed by Pollack to encode arbitrarily deep trees in a fixed-width vector works by recursive compression of representations. Each leaf node has a predetermined 1 Some attempts in this direction have not been convincing (Chalmers 1990); but see <ref> (Blank et al. 1992) </ref> for some very recent work. 1 0 [ 1 = 1 0 1 0 1 [ 0 = 1 it unchanged. A `1' matches only itself. <p> Parallel training allows shifting part of the work of unification from the unification network itself to the representation. This contrasts with other work <ref> (e.g., Blank et al. 1992) </ref> where multi-layer networks are used to process RAAM codes for tasks which appear less demanding than that investigated here. 3 5 Results Prior to studying unification performance, we studied the performance of RAAM alone on trees of up to five terminal nodes, and obtained good results
Reference: <author> Chalmers, D. J. </author> <year> (1990). </year> <title> Transformations on distributed representations. </title> <journal> Connection Science, </journal> <volume> 2. </volume>
Reference-contexts: See Fig. 1 for examples. 3 RAAM encoding The method proposed by Pollack to encode arbitrarily deep trees in a fixed-width vector works by recursive compression of representations. Each leaf node has a predetermined 1 Some attempts in this direction have not been convincing <ref> (Chalmers 1990) </ref>; but see (Blank et al. 1992) for some very recent work. 1 0 [ 1 = 1 0 1 0 1 [ 0 = 1 it unchanged. A `1' matches only itself.
Reference: <author> Elman, J. L. </author> <year> (1991). </year> <title> Incremental learning, or the importance of starting small. </title> <booktitle> In Program of the Thirteenth Annual Conference of the Cognitive Science Society, </booktitle> <pages> pp. 443-448. </pages>
Reference: <author> Pollack, J. B. </author> <year> (1988). </year> <title> Recursive auto-associative memory: Devising compositional distributed representations. </title> <type> Technical Report MCCS-88-124, </type> <institution> Computing Research Laboratory, New Mexico State University, </institution> <address> Las Cruces, New Mexico. </address>
Reference: <author> Pollack, J. B. </author> <year> (1990). </year> <title> Recursive distributed representations. </title> <journal> Artificial Intelligence, </journal> <volume> 46 </volume> <pages> 77-105. </pages>
Reference: <author> Stolcke, A. </author> <year> (1989). </year> <title> Unification as constraint satisfaction in structured connectionist networks. </title> <journal> Neural Computation, </journal> <volume> 1(4) </volume> <pages> 559-567. </pages>
Reference-contexts: The particular task investigated in this study is that of unification, a general function on structures like terms, trees, and graphs that implements a recursive matching and merging operation. One of us <ref> (Stolcke 1989) </ref> has previously proposed a structured (localist) connectionist model for unification and has argued that unification represents an operation that should have a natural connectionist implementation due to the intuitive notions if formalizes (feature integration, pattern matching).
Reference: <author> Wu, D. </author> <year> (1990). </year> <title> Probabilistic unification-based integration of syntactic and semantic preferences for nominal compounds. </title> <editor> In H. Karlgren, editor, </editor> <booktitle> Proceedings of the 13th International Conference on Computational Linguistics, </booktitle> <institution> University of Helsinki, Helsinki, Finland. </institution>
Reference: <author> Wu, D. </author> <year> (1992). </year> <title> Automatic Inference: A Probabilistic Basis for Natural Language Interpretation. </title> <type> PhD thesis, </type> <institution> University of California at Berkeley. </institution> <month> 8 </month>
References-found: 8

