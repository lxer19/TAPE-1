URL: ftp://ftp.cs.rochester.edu/pub/papers/systems/89.TR309.Psyche_Evolution.ps.Z
Refering-URL: http://www.cs.rochester.edu/trs/systems-trs.html
Root-URL: 
Email: scott@cs.rochester.edu leblanc@cs.rochester.edu marsh@cs.rochester.edu  
Title: Evolution of an Operating System for Large-Scale Shared-Memory Multiprocessors  
Author: Michael L. Scott Thomas J. LeBlanc Brian D. Marsh 
Note: This work was supported in part by NSF CER grant number DCR-8320136, Darpa/ETL contract number DACA76-85-C-0001, and an IBM Faculty Development Award.  
Date: March 1989  
Address: Rochester, NY 14627  
Affiliation: University of Rochester Department of Computer Science  
Abstract: Scalable shared-memory multiprocessors (those with non-uniform memory access times) are among the most flexible architectures for high-performance parallel computing, admitting efficient implementations of a wide range of process models, communication mechanisms, and granularities of parallelism. Such machines present opportunities for general-purpose parallel computing that cannot be exploited by existing operating systems, because the traditional approach to operating system design presents a virtual machine in which the definition of processes, communication, and grain size are outside the control of the user. Psyche is an operating system designed to enable the most effective use possible of large-scale shared memory multiprocessors. The Psyche project is characterized by (1) a design that permits the implementation of multiple models of parallelism, both within and among applications, (2) the ability to trade protection for performance, with information sharing as the default, rather than the exception, (3) explicit, user-level control of process structure and scheduling, and (4) a kernel implementation that uses shared memory itself, and that provides users with the illusion of uniform memory access times. hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Bershad, B. N., E. D. Lazowska, H. M. Levy, and D. B. Wagner, </author> <title> ``An Open Environment for Building Parallel Programming Systems,'' </title> <booktitle> Proceedings of the First ACM Conference on Parallel Programming: Experience with Applications, Languages and Systems, </booktitle> <month> 19-21 July </month> <year> 1988, </year> <pages> pp. 1-9. </pages> <booktitle> In ACM SIGPLAN Notices 23:9. </booktitle> <pages> 23 </pages>
Reference-contexts: We therefore distinguish between the distribution of access rights (which must be cheap) and the exercise of those rights. Other researchers have recognized the need for multiple models of parallel computing. Washington's Presto project <ref> [1] </ref>, for example, supports user-definable processes and communication in a modular, customizable, C++ library package. Presto is not an operating system; it is linked into the code for a single application (written in a single language), and provides no protection beyond that which is available from the compiler.
Reference: [2] <author> Bolosky, W. J., R. P. Fitzgerald, and M. L. Scott, </author> <title> ``Simple But Effective Techniques for NUMA Memory Management,'' </title> <booktitle> Proceedings of the Twelfth ACM Symposium on Operating Systems Principles, </booktitle> <month> 3-6 December </month> <year> 1989, </year> <pages> pp. 19-31. </pages> <booktitle> In ACM SIGOPS Operating Systems Review 23:5. </booktitle>
Reference-contexts: Locality of memory references and contention for memory banks are facets of the general memory-management problem for NUMA machines (what we call the ``NUMA problem''). We are investigating strategies to address this problem <ref> [2, 7, 13] </ref>, but they are beyond the scope of this paper. 5 reason. Its single address space allows data items, including pointers to be copied from the local memory of one process to that of another without any intermediate translation.
Reference: [3] <author> Brown, C. M., R. J. Fowler, T. J. LeBlanc, M. L. Scott, M. Srinivas, and others, </author> <title> ``DARPA Parallel Architecture Benchmark Study,'' </title> <type> BPR 13, </type> <institution> Computer Science Department, University of Rochester, </institution> <month> October </month> <year> 1986. </year>
Reference-contexts: Programming Models A major focus of our experimentation with the Butterfly has been the evaluation and comparison of multiple models of parallel computing <ref> [3, 11, 15] </ref>. Our principal conclusion is that while every programming model has applications for which it seems appropriate, no single model is appropriate for every application. <p> Our principal conclusion is that while every programming model has applications for which it seems appropriate, no single model is appropriate for every application. In an intensive benchmark study conducted in 1986 <ref> [3] </ref>, we implemented seven different computer vision applications on the Butterfly over the course of a three-week period. Based on the characteristics of the problems, programmers chose to use four different programming models, provided by four of our systems packages.
Reference: [4] <author> Campbell, R., G. Johnston, and V. Russo, </author> <title> ``Choices (Class Hierarchical Open Interface for Custom Embedded Systems),'' </title> <booktitle> ACM SIGOPS Operating Systems Review 21:3 (July 1987), </booktitle> <pages> pp. 9-17. </pages>
Reference-contexts: Presto is not an operating system; it is linked into the code for a single application (written in a single language), and provides no protection beyond that which is available from the compiler. At the operating system level, the Choices project at Illinois <ref> [4] </ref> allows the kernel itself to be customized through the replacement of C++ abstractions. The University of Arizona's x-Kernel [17] adopts a similar approach in the context of communication protocols for message-based machines.
Reference: [5] <author> Cheriton, D., </author> <title> ``The V Kernel A Software Base for Distributed Systems,'' </title> <booktitle> IEEE Software 1:2 (April 1984), </booktitle> <pages> pp. 19-42. </pages>
Reference-contexts: We decided very early that Psyche would have a low-level kernel interface. In some sense this places us in the tradition of the ``minimal'' kernels for distributed operating systems such as Accent [19], Charlotte [9], and V <ref> [5] </ref>. Our emphasis, however, is different. Message-passing kernels provide a clean and narrow interface at a relatively high level of abstraction. By confining the kernel to lower-level operations, we can cover a much wider spectrum of programming models with an equally clean and narrow interface. (See figure 2).
Reference: [6] <author> Clark, D., </author> <title> ``The Structuring of Systems Using Upcalls,'' </title> <booktitle> Proceedings of the Tenth ACM Symposium on Operating Systems Principles, </booktitle> <month> 1-4 December </month> <year> 1985, </year> <pages> pp. 171-180. </pages> <booktitle> In ACM SIGOPS Operating Systems Review 19:5. </booktitle>
Reference-contexts: It may be possible under certain programming models to provide compiler-enforced protection at a very fine granularity with little or no run-time cost. Others have adopted this approach in the context of ``open'' operating systems <ref> [6, 25] </ref>. For us to count on compiler protection, however, would be inconsistent with the desire to support as many programming models as possible, particularly with multiple users on a single parallel machine.
Reference: [7] <author> Cox, A. L. and R. J. Fowler, </author> <title> ``The Implementation of a Coherent Memory Abstraction on a NUMA Multiprocessor: Experiences with PLATINUM,'' </title> <booktitle> Proceedings of the Twelfth ACM Symposium on Operating Systems Principles, </booktitle> <month> 3-6 December </month> <year> 1989, </year> <pages> pp. 32-44. </pages> <booktitle> In ACM SIGOPS Operating Systems Review 23:5. </booktitle>
Reference-contexts: Locality of memory references and contention for memory banks are facets of the general memory-management problem for NUMA machines (what we call the ``NUMA problem''). We are investigating strategies to address this problem <ref> [2, 7, 13] </ref>, but they are beyond the scope of this paper. 5 reason. Its single address space allows data items, including pointers to be copied from the local memory of one process to that of another without any intermediate translation.
Reference: [8] <author> Crowl, L. A., </author> <title> ``Shared Memory Multiprocessors and Sequential Programming Languages: A Case Study,'' </title> <booktitle> Proceedings of the 21st Annual Hawaii International Conference on System Sciences, </booktitle> <month> January </month> <year> 1988. </year>
Reference-contexts: We have used the BBN Butterfly to experiment with many different programming models. BBN has developed a model based on fine-grain memory sharing [26]. In addition, we have implemented remote procedure calls [14], an object-oriented encapsulation of processes, memory blocks, and messages <ref> [8] </ref>, a message-based library package [12], a shared-memory model with numerous lightweight processes [24], and a message-based programming language [23]. <p> It suffers, unfortunately, from a tendency toward the ``kitchen sink'' syndrome; no small set of models will satisfy all users, and even the smallest deviations from predefined abstractions can be very difficult to obtain (see <ref> [8] </ref> and [22] for examples). A more attractive approach is to implement a set of primitive building blocks on which practically anything can be built. We decided very early that Psyche would have a low-level kernel interface.
Reference: [9] <author> Finkel, R. A., M. L. Scott, Y. Artsy, and H.-Y. Chang, </author> <title> ``Experience with Charlotte: Simplicity and Function in a Distributed Operating System,'' </title> <journal> IEEE Transactions on Software Engineering 15:6 (June 1989), </journal> <pages> pp. 676-685. </pages> <booktitle> Extended abstract presented at the IEEE Workshop on Design Principles for Experimental Distributed Systems, </booktitle> <institution> Purdue University, </institution> <month> 15-17 October </month> <year> 1986. </year>
Reference-contexts: We decided very early that Psyche would have a low-level kernel interface. In some sense this places us in the tradition of the ``minimal'' kernels for distributed operating systems such as Accent [19], Charlotte <ref> [9] </ref>, and V [5]. Our emphasis, however, is different. Message-passing kernels provide a clean and narrow interface at a relatively high level of abstraction.
Reference: [10] <author> Gelernter, D., </author> <title> ``Generative Communication in Linda,'' </title> <journal> ACM Transactions on Programming Languages and Systems 7:1 (January 1985), </journal> <pages> pp. 80-112. </pages>
Reference-contexts: In any environment based on memory sharing, we believe it will be desirable to employ a uniform model of addressing. Even if the programmer must deal explicitly with local caching of data, uniform addressing remains conceptually appealing. It is, for example, the principal attraction of the Linda programming languages <ref> [10] </ref>. The Linda ``tuple space'' is not a conventional shared memory. Its operations are not transparent, nor are they efficient enough to be used for fine-grained sharing. The tuple space does, however, allow processes to name data without worrying about their location.
Reference: [11] <author> LeBlanc, T. J., </author> <title> ``Shared Memory Versus Message-Passing in a Tightly-Coupled Multiprocessor: A Case Study,'' </title> <booktitle> Proceedings of the 1986 International Conference on Parallel Processing, </booktitle> <month> 19-22 August </month> <year> 1986, </year> <pages> pp. 463-466. </pages>
Reference-contexts: Programming Models A major focus of our experimentation with the Butterfly has been the evaluation and comparison of multiple models of parallel computing <ref> [3, 11, 15] </ref>. Our principal conclusion is that while every programming model has applications for which it seems appropriate, no single model is appropriate for every application.
Reference: [12] <author> LeBlanc, T. J., </author> <title> ``Structured Message Passing on a Shared-Memory Multiprocessor,'' </title> <booktitle> Proceedings of the 21st Annual Hawaii International Conference on System Sciences, </booktitle> <month> January </month> <year> 1988, </year> <pages> pp. 188-194. </pages>
Reference-contexts: We have used the BBN Butterfly to experiment with many different programming models. BBN has developed a model based on fine-grain memory sharing [26]. In addition, we have implemented remote procedure calls [14], an object-oriented encapsulation of processes, memory blocks, and messages [8], a message-based library package <ref> [12] </ref>, a shared-memory model with numerous lightweight processes [24], and a message-based programming language [23].
Reference: [13] <author> LeBlanc, T. J., B. D. Marsh, and M. L. Scott, </author> <title> ``Memory Management for Large-Scale NUMA Multiprocessors,'' </title> <type> TR 311, </type> <institution> Computer Science Department, University of Rochester, </institution> <month> March </month> <year> 1989. </year>
Reference-contexts: Locality of memory references and contention for memory banks are facets of the general memory-management problem for NUMA machines (what we call the ``NUMA problem''). We are investigating strategies to address this problem <ref> [2, 7, 13] </ref>, but they are beyond the scope of this paper. 5 reason. Its single address space allows data items, including pointers to be copied from the local memory of one process to that of another without any intermediate translation. <p> In a program that never attempts to circumvent realm protocols, protection levels can be changed without changing the appearance or behavior of the program. hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh 2 The Psyche memory management system is described in a companion paper <ref> [13] </ref>. 11 Avoidance of kernel intervention Lazy evaluation of protection Reads, writes, and calls as fundamental Sharing of data structures between the kernel and the user Psyche places a heavy emphasis on sharing of data structures between the kernel and the user. <p> Spin locks (our most widely-used synchronization mechanism) disable preemption in order to ensure that the operation they protect completes quickly. 5.2. Memory management The largest and most sophisticated portion of the kernel is devoted to memory management <ref> [13] </ref>, comprising four distinct abstraction layers. The lowest (NUMA) layer provides an encapsulation of physical page frames and tables. The second (UMA) layer provides the illusion of uniform memory access times through page replication and migration.
Reference: [14] <author> LeBlanc, T. J., J. M. Mellor-Crummey, N. M. Gafter, L. A. Crowl, and P. C. Dibble, </author> <title> ``The Elmwood Multiprocessor Operating System,'' </title> <journal> Software Practice and Experience 19:11 (November 1989), </journal> <pages> pp. 1029-1056. </pages>
Reference-contexts: Shared-memory multiprocessors can support this fine-grained sharing, and match the speed of multicomputers for message passing, too. We have used the BBN Butterfly to experiment with many different programming models. BBN has developed a model based on fine-grain memory sharing [26]. In addition, we have implemented remote procedure calls <ref> [14] </ref>, an object-oriented encapsulation of processes, memory blocks, and messages [8], a message-based library package [12], a shared-memory model with numerous lightweight processes [24], and a message-based programming language [23].
Reference: [15] <author> LeBlanc, T. J., M. L. Scott, and C. M. Brown, </author> <title> ``Large-Scale Parallel Programming: Experience with the BBN Butterfly Parallel Processor,'' </title> <booktitle> Proceedings of the First ACM Conference on Parallel Programming: Experience with Applications, Languages and Systems, </booktitle> <month> 19-21 July </month> <year> 1988, </year> <pages> pp. 161-172. </pages>
Reference-contexts: In the course of this experimentation we ported three compilers to the Butterfly, developed five major and several minor library packages, built two different operating systems, and implemented dozens of applications. A summary of this work can be found in <ref> [15] </ref>. 2.1. Architecture As we see it, the most significant strength of a shared-memory architecture is its ability to support efficient implementations of many different parallel programming models, encompassing a wide range of grain sizes of process interaction. <p> Programming Models A major focus of our experimentation with the Butterfly has been the evaluation and comparison of multiple models of parallel computing <ref> [3, 11, 15] </ref>. Our principal conclusion is that while every programming model has applications for which it seems appropriate, no single model is appropriate for every application.
Reference: [16] <author> Mullender, S. J. and A. S. Tanenbaum, </author> <title> ``The Design of a Capability-Based Distributed Operating System,'' </title> <journal> The Computer Journal 29:4 (1986), </journal> <pages> pp. 289-299. 24 </pages>
Reference-contexts: Moreover, no kernel is likely to provide the performance of user-level code to create, destroy, block, and unblock threads. Operating systems such as Mach [18] and Amoeba <ref> [16] </ref> have attempted to reduce the cost of process operations by separating the scheduling abstraction from the address-space abstraction, but the result is still significantly less efficient than the typical implementation of user-level threads. 12 With a traditional operating system it is always possible to implement lightweight threads inside a single
Reference: [17] <author> Peterson, L., N. Hutchinson, S. O'Malley, and M. Abbott, </author> <title> ``RPC in the x-Kernel: Evaluating New Design Techniques,'' </title> <booktitle> Proceedings of the Twelfth ACM Symposium on Operating Systems Principles, </booktitle> <month> 3-6 December </month> <year> 1989, </year> <pages> pp. 91-101. </pages> <booktitle> In ACM SIGOPS Operating Systems Review 23:5. </booktitle>
Reference-contexts: At the operating system level, the Choices project at Illinois [4] allows the kernel itself to be customized through the replacement of C++ abstractions. The University of Arizona's x-Kernel <ref> [17] </ref> adopts a similar approach in the context of communication protocols for message-based machines. Both Choices and the x-Kernel are best described as reconfigurable operating systems; they provide a single programming model defined at system generation time, rather than supporting multiple models at run time.
Reference: [18] <author> Rashid, R. F., </author> <title> ``Threads of a New System,'' </title> <booktitle> UNIX Review 4:8 (August 1986), </booktitle> <pages> pp. 37-49. </pages>
Reference-contexts: Moreover, no kernel is likely to provide the performance of user-level code to create, destroy, block, and unblock threads. Operating systems such as Mach <ref> [18] </ref> and Amoeba [16] have attempted to reduce the cost of process operations by separating the scheduling abstraction from the address-space abstraction, but the result is still significantly less efficient than the typical implementation of user-level threads. 12 With a traditional operating system it is always possible to implement lightweight threads
Reference: [19] <author> Rashid, R. F. and G. G. Robertson, </author> <title> ``Accent: A Communication Oriented Network Operating System Kernel,'' </title> <booktitle> Proceedings of the Eighth ACM Symposium on Operating Systems Principles, </booktitle> <month> 14-16 December </month> <year> 1981, </year> <pages> pp. 64-75. </pages> <booktitle> In ACM SIGOPS Operating Systems Review 15:5. </booktitle>
Reference-contexts: We decided very early that Psyche would have a low-level kernel interface. In some sense this places us in the tradition of the ``minimal'' kernels for distributed operating systems such as Accent <ref> [19] </ref>, Charlotte [9], and V [5]. Our emphasis, however, is different. Message-passing kernels provide a clean and narrow interface at a relatively high level of abstraction.
Reference: [20] <author> Redell, D., </author> <title> ``Experience with Topaz TeleDebugging,'' </title> <booktitle> Proceedings, ACM SIGPLAN/SIGOPS Workshop on Parallel and Distributed Debugging, </booktitle> <month> 5-6 May </month> <year> 1988, </year> <pages> pp. 35-44. </pages> <note> In ACM SIG-PLAN Notices 24:1 (January 1989). </note>
Reference-contexts: We have completed the major portions of the kernel and are experimenting with user-level software. To facilitate kernel development we have implemented a remote, source-level debugger in the style of the Topaz TeleDebug facility <ref> [20] </ref>. The front end for the debugger runs on a Sun workstation and communicates via UDP and serial lines with a low-level debugging stub that underlies the Psyche kernel. The low-level debugger was the first piece of the kernel to be written, and has proven extremely valuable.
Reference: [21] <author> Rettberg, R. and R. Thomas, </author> <title> ``Contention is No Obstacle to Shared-Memory Multiprocessing,'' </title> <journal> Communications of the ACM 29:12 (December 1986), </journal> <pages> pp. 1202-1212. </pages>
Reference-contexts: In our own experience, BBN's Uniform System [26] is the most popular programming package on the Butterfly for much the same hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh 1 Contention in the switching network has not proven to be a problem <ref> [21] </ref>. Locality of memory references and contention for memory banks are facets of the general memory-management problem for NUMA machines (what we call the ``NUMA problem''). We are investigating strategies to address this problem [2, 7, 13], but they are beyond the scope of this paper. 5 reason.
Reference: [22] <author> Scott, M. L., </author> <title> ``The Interface Between Distributed Operating System and High-Level Programming Language,'' </title> <booktitle> Proceedings of the 1986 International Conference on Parallel Processing, </booktitle> <month> 19-22 August </month> <year> 1986, </year> <pages> pp. 242-249. </pages>
Reference-contexts: It suffers, unfortunately, from a tendency toward the ``kitchen sink'' syndrome; no small set of models will satisfy all users, and even the smallest deviations from predefined abstractions can be very difficult to obtain (see [8] and <ref> [22] </ref> for examples). A more attractive approach is to implement a set of primitive building blocks on which practically anything can be built. We decided very early that Psyche would have a low-level kernel interface.
Reference: [23] <author> Scott, M. L. and A. L. Cox, </author> <title> ``An Empirical Study of Message-Passing Overhead,'' </title> <booktitle> Proceedings of the Seventh International Conference on Distributed Computing Systems, </booktitle> <month> 21-25 September </month> <year> 1987, </year> <pages> pp. 536-543. </pages>
Reference-contexts: BBN has developed a model based on fine-grain memory sharing [26]. In addition, we have implemented remote procedure calls [14], an object-oriented encapsulation of processes, memory blocks, and messages [8], a message-based library package [12], a shared-memory model with numerous lightweight processes [24], and a message-based programming language <ref> [23] </ref>. Using our systems packages, we have achieved significant speedups (often nearly linear) on over 100 processors with a range of applications that includes various aspects of computer vision, connectionist network simulation, numerical algorithms, computational geometry, graph theory, combinatorial search, and parallel data structure management.
Reference: [24] <author> Scott, M. L. and K. R. Jones, </author> <title> ``Ant Farm: A Lightweight Process Programming Environment,'' </title> <type> BPR 21, </type> <institution> Computer Science Department, University of Rochester, </institution> <month> August </month> <year> 1988. </year>
Reference-contexts: BBN has developed a model based on fine-grain memory sharing [26]. In addition, we have implemented remote procedure calls [14], an object-oriented encapsulation of processes, memory blocks, and messages [8], a message-based library package [12], a shared-memory model with numerous lightweight processes <ref> [24] </ref>, and a message-based programming language [23]. <p> For one of the applications, none of the existing packages provided a reasonable fit, and the awkwardness of the resulting code was a major impetus for the development of yet another package <ref> [24] </ref>. It strikes us as highly unlikely that any predefined set of parallel programming models will be adequate for the needs of all user programs. In any environment based on memory sharing, we believe it will be desirable to employ a uniform model of addressing.
Reference: [25] <author> Swinehart, D., P. Zellweger, R. Beach, and R. Hagmann, </author> <title> ``A Structural View of the Cedar Programming Environment,'' </title> <journal> ACM Transactions on Programming Languages and Systems 8:4 (October 1986), </journal> <pages> pp. 419-490. </pages>
Reference-contexts: It may be possible under certain programming models to provide compiler-enforced protection at a very fine granularity with little or no run-time cost. Others have adopted this approach in the context of ``open'' operating systems <ref> [6, 25] </ref>. For us to count on compiler protection, however, would be inconsistent with the desire to support as many programming models as possible, particularly with multiple users on a single parallel machine.
Reference: [26] <author> Thomas, R. H. and W. Crowther, </author> <title> ``The Uniform System: An Approach to Runtime Support for Large Scale Shared Memory Parallel Processors,'' </title> <booktitle> Proceedings of the 1988 International Conference on Parallel Processing II Software (15-19 August 1988), </booktitle> <pages> pp. 245-254. </pages>
Reference-contexts: Shared-memory multiprocessors can support this fine-grained sharing, and match the speed of multicomputers for message passing, too. We have used the BBN Butterfly to experiment with many different programming models. BBN has developed a model based on fine-grain memory sharing <ref> [26] </ref>. In addition, we have implemented remote procedure calls [14], an object-oriented encapsulation of processes, memory blocks, and messages [8], a message-based library package [12], a shared-memory model with numerous lightweight processes [24], and a message-based programming language [23]. <p> The Linda ``tuple space'' is not a conventional shared memory. Its operations are not transparent, nor are they efficient enough to be used for fine-grained sharing. The tuple space does, however, allow processes to name data without worrying about their location. In our own experience, BBN's Uniform System <ref> [26] </ref> is the most popular programming package on the Butterfly for much the same hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh 1 Contention in the switching network has not proven to be a problem [21].
Reference: [27] <author> Wilson, Jr., A. W., </author> <title> ``Hierarchical Cache/Bus Architecture for Shared Memory Multiprocessors,'' </title> <booktitle> Proceedings of the Fourteenth Annual International Symposium on Computer Architecture, </booktitle> <month> 2-5 June </month> <year> 1987, </year> <pages> pp. 244-252. </pages>
Reference-contexts: A Psyche host machine is assumed to consist of clusters, each of which comprises processors and memories with identical locality characteristics. A Sequent or Encore machine consists of a single cluster. On a Butterfly, each node is a cluster unto itself. The proposed Encore Ultramax <ref> [27] </ref> would consist of several non-trivial clusters. Scheduling and memory-management data structures are allocated in the kernel on a per-cluster basis. For the sake of scalability, each cluster contains a separate copy of the bulk of the kernel code. Kernel functions are performed locally whenever possible.
Reference: [28] <author> Young, M., A. Tevanian, R. Rashid, D. Golub, J. Eppinger, J. Chew, W. Bolosky, D. Black, and R. Baron, </author> <title> ``The Duality of Memory and Communication in the Implementation of a Multiprocessor Operating System,'' </title> <booktitle> Proceedings of the Eleventh ACM Symposium on Operating Systems Principles, </booktitle> <month> 8-11 November </month> <year> 1987, </year> <pages> pp. 63-76. </pages> <booktitle> In ACM SIGOPS Operating Systems Review 21:5. </booktitle>
Reference-contexts: Requires a key conferring revocation rights. A small number of additional calls are provided for I/O, external pagers, ``ownership,'' and ``attachment.'' The external pager mechanism is similar in spirit to that provided in Mach <ref> [28] </ref>, but with an interface based on shared memory instead of message passing. The ownership mechanism allows automatic reclamation of realms that are no longer needed. The ownership graph is a DAG; we destroy any realm whose owners have all been destroyed.
References-found: 28

