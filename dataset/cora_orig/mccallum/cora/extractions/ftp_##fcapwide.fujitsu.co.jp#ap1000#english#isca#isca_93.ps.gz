URL: ftp://fcapwide.fujitsu.co.jp/ap1000/english/isca/isca_93.ps.gz
Refering-URL: 
Root-URL: 
Title: Improving AP1000 Parallel Computer Performance with Message Communication  
Author: Takeshi Horie, Kenichi Hayashi, Toshiyuki Shimizu, and Hiroaki Ishihata 
Address: 1015 Kamikodanaka, Nakahara-ku, Kawasaki 211, Japan  
Affiliation: Fujitsu Laboratories Ltd.  
Abstract: The performance of message-passing applications depends on cpu speed, communication throughput and latency, and message handling overhead. In this paper we investigate the effect of varying these parameters and applying techniques to reduce message handling overhead on the execution efficiency of ten different applications. Using a message level simulator set up for the architecture of the AP1000, we showed that improving communication performance, especially message handling, improves total performance. If a cpu that is 32 times faster is provided, the total performance increases by less than ten times unless message handling overhead is reduced. Overlapping computation with message reception improves performance significantly. We also discuss how to improve the AP1000 architecture. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <institution> nCUBE2 Supercomputers Technical Overview, </institution> <year> 1990. </year>
Reference-contexts: The DMPP system is easily scaled up to large systems and many research groups have been studying parallelizing compilers to simplify the programming of DMPPs. Implementations of the DMPP architecture range from experimental prototype systems to commercial systems from Intel [3], NCUBE <ref> [1] </ref>, Ametek [10], and Connection Machine. Key architecture design issues for DMPPs include the use of high-speed processing elements, low-latency, high-throughput communications in the interconnection network, and message handling mechanism. This paper presents the quantitative performance evaluation of DMPPs using message level simulation. Ten different applications were selected as benchmarks.
Reference: [2] <author> M. Annaratone, C. Pommerell, and Roland Ruhl: </author> <title> "Interprocessor communication speed and performance in distributed-memory parallel processors," </title> <booktitle> In The 16th Annual International Symposium on Computer Architecture, </booktitle> <pages> pp. 315-324, </pages> <month> May </month> <year> 1989. </year>
Reference-contexts: Related work Annaratone simulated several numerical and nonnumerical algorithms on five DMPPs and quantified the effect that interprocessor communication speed and synchronization overhead have on the performance of the DMPPs <ref> [2] </ref>. In his paper, however, only communication between neighboring processors was used and messages were not vectorized to reduce communication overhead. Hsu presented the performance evaluation and trace driven simulation of a hypercube multicomputer running realistic workloads [18].
Reference: [3] <author> R. Arlauskas: </author> <title> "iPSC/2 system: a second generation hypercube," </title> <booktitle> In Third Conference on Hypercube Concurrent Computers and Applications, </booktitle> <pages> pp. 38-42, </pages> <month> Jan. </month> <year> 1988. </year>
Reference-contexts: The DMPP system is easily scaled up to large systems and many research groups have been studying parallelizing compilers to simplify the programming of DMPPs. Implementations of the DMPP architecture range from experimental prototype systems to commercial systems from Intel <ref> [3] </ref>, NCUBE [1], Ametek [10], and Connection Machine. Key architecture design issues for DMPPs include the use of high-speed processing elements, low-latency, high-throughput communications in the interconnection network, and message handling mechanism. This paper presents the quantitative performance evaluation of DMPPs using message level simulation.
Reference: [4] <author> B. Boothe and A. Ranade: </author> <title> "Improved multithread-ing techniques for hiding communication latency in multiprocessors," </title> <booktitle> In The 19th Annual International Symposium on Computer Architecture, </booktitle> <pages> pp. 214-223, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: The multiple context reduces idle time without rewriting application programs. This multiple context approach is different from that for hiding the latency of remote data fetch <ref> [21, 4, 14] </ref>. On message-passing machines, all communications are performed through messages and this method is natural to hide the message waiting time. We are now investigating the effect of the multiple contexts on DMPP performance. Programming paradigm Message passing programming paradigms can not avoid message buffering.
Reference: [5] <author> R. P. Brent: </author> <title> "The LINPACK benchmark on the AP1000," </title> <booktitle> In Fourth Symposium on the Frontiers of Massively Parallel Computation, </booktitle> <month> Oct. </month> <year> 1992. </year>
Reference-contexts: The communication workload ranged from high to heavy. LINPACK solves dense systems of equations by performing block Gaussian elimination. This program was written by Prof. Brent to perform the LINPACK benchmark <ref> [5] </ref>. The matrix to be solved is 1000 fi 1000. SCG solves Poisson's differential equation using the scaled conjugate gradient method in which the coefficient matrix is scaled by diagonal elements. The matrix to be solved is 200 fi 200. MD is a molecular dynamics simulation program [6].
Reference: [6] <author> D. Brown and J. H. R. Clarke: </author> <title> "Parallelization strategies for MD simulations on the AP1000," </title> <booktitle> In Proceedings of the Second Fujitsu-ANU CAP Workshop, </booktitle> <pages> pp. </pages> <address> L-1-10, </address> <month> Nov. </month> <year> 1991. </year>
Reference-contexts: The matrix to be solved is 1000 fi 1000. SCG solves Poisson's differential equation using the scaled conjugate gradient method in which the coefficient matrix is scaled by diagonal elements. The matrix to be solved is 200 fi 200. MD is a molecular dynamics simulation program <ref> [6] </ref>. A domain decomposition method is used for 216000 particles. QCD is a Monte Carlo program for Lattice Quantum Chromo Dynamics (QCD) [13]. The lattice size is 16fi16fi16fi16. OCEAN simulates an ocean circulation model. The model used here has one horizontal dimension and two layers.
Reference: [7] <author> W. J. Dally: </author> <title> "Performance analysis of k-ary n-cube interconnection networks," </title> <journal> IEEE Transactions on Computers, </journal> <volume> 39, 6, </volume> <pages> pp. 775-785, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: A speedup factor of four is the optimal choice for the current cpu power. 3.3 Varying network performance We evaluated the effect of the interconnection network performance. The delay in the interconnection network using wormhole routing is given as the following equation <ref> [7] </ref>: T delay = (T n + T w )D + (L=W )T p where T n is the latency of a node, T w the latency of a wire, T p the pipeline period of a node, D the distance hopped by a message, L the message length in bits,
Reference: [8] <author> W. J. Dally, L. Chao, S. Hassoun, W. Horwat, J. Ka-plan, P. Song, B. Totty, and S. Wills: </author> <title> "Architecture of a message-driven processor," </title> <booktitle> In The 14th Annual International Symposium on Computer Architecture, </booktitle> <pages> pp. 189-196, </pages> <month> May </month> <year> 1987. </year>
Reference-contexts: Message handling consists of two times. One is the fixed overhead time to construct a message and set up the appropriate communication mechanism, and the other is the time proportional to the message length. Several techniques for reducing message handling have been proposed <ref> [8, 21, 23, 17] </ref>. Fixed overhead time can be reduced by using specialized hardware such as a message formatter and message searcher. One way to reduce the overhead proportional to the message length is overlapping communication with computation.
Reference: [9] <author> T. Eicken, D. E. Culler, S. C. Goldstein, and K. E. Schauser: </author> <title> "Active messages: a mechanism for integrated communication and computation," </title> <booktitle> In The 19th Annual International Symposium on Computer Architecture, </booktitle> <pages> pp. 256-266, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: On message-passing machines, all communications are performed through messages and this method is natural to hide the message waiting time. We are now investigating the effect of the multiple contexts on DMPP performance. Programming paradigm Message passing programming paradigms can not avoid message buffering. This is explained by Eicken <ref> [9] </ref>. The AP1000 does not need buffering for sending messages by applying a line-sending mechanism. However, the overhead of buffer management in receiving remains unsolved.
Reference: [10] <editor> C. L. Seitz et al.: </editor> <booktitle> "The architecture and programming of the Ametek Series 2010 multicomputer," In Third Conference on Hypercube Concurrent Computers and Applications, </booktitle> <pages> pp. 33-36, </pages> <month> Jan. </month> <year> 1988. </year>
Reference-contexts: The DMPP system is easily scaled up to large systems and many research groups have been studying parallelizing compilers to simplify the programming of DMPPs. Implementations of the DMPP architecture range from experimental prototype systems to commercial systems from Intel [3], NCUBE [1], Ametek <ref> [10] </ref>, and Connection Machine. Key architecture design issues for DMPPs include the use of high-speed processing elements, low-latency, high-throughput communications in the interconnection network, and message handling mechanism. This paper presents the quantitative performance evaluation of DMPPs using message level simulation. Ten different applications were selected as benchmarks.
Reference: [11] <author> H. Sato et al.: </author> <title> "Parallelization of AMBER molecular dynamics program for the AP1000," </title> <booktitle> In Scalable High Performance Computing Conference 92, </booktitle> <pages> pp. 113-120, </pages> <month> April </month> <year> 1992. </year>
Reference-contexts: A finite difference method solves the problem iteratively with a successive over-relaxation scheme. The results refer to 20 iterations of the SOR algorithm. TSDE was produced by the compiler Oxygen [22]. AMBER is a molecular dynamics simulation program which was parallelized by Sato <ref> [11] </ref>. A particle division method allocates particles randomly to processors. The number of atoms is 2000. SLALOM is a computer benchmark which solves an optical radiosity in the interior of a box [12]. The number of patches is 500.
Reference: [12] <author> J. Gustafson et al.: </author> <title> "Slalom update," </title> <booktitle> Supercomputing Review, </booktitle> <pages> pp. 56-61, </pages> <month> March </month> <year> 1991. </year>
Reference-contexts: AMBER is a molecular dynamics simulation program which was parallelized by Sato [11]. A particle division method allocates particles randomly to processors. The number of atoms is 2000. SLALOM is a computer benchmark which solves an optical radiosity in the interior of a box <ref> [12] </ref>. The number of patches is 500. In each of these applications only the main execution part is measured. The time required for downloading data and uploading results is not included. Table 1 lists the application statistics for MLSim.
Reference: [13] <author> K. Akemi et al.: </author> <title> "QCD on the highly parallel computer AP1000," </title> <journal> Nuclear Physics B, </journal> <volume> 26, </volume> <pages> pp. 644-646, </pages> <year> 1992. </year>
Reference-contexts: The matrix to be solved is 200 fi 200. MD is a molecular dynamics simulation program [6]. A domain decomposition method is used for 216000 particles. QCD is a Monte Carlo program for Lattice Quantum Chromo Dynamics (QCD) <ref> [13] </ref>. The lattice size is 16fi16fi16fi16. OCEAN simulates an ocean circulation model. The model used here has one horizontal dimension and two layers. OCEAN is written in Dataparallel-C [15]. SHALLOW solves a set of shallow-water equations using finite difference approximations on a 64 fi 64 grid through 1200 iterations.
Reference: [14] <author> A. Gupta, J. Hennessy, K. Gharachorloo, T. Mowry, and W. D. Weber: </author> <title> "Comparative evaluation of latency reducing and tolerating techniques," </title> <booktitle> In The 18th Annual International Symposium on Computer Architecture, </booktitle> <pages> pp. 254-263, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: The multiple context reduces idle time without rewriting application programs. This multiple context approach is different from that for hiding the latency of remote data fetch <ref> [21, 4, 14] </ref>. On message-passing machines, all communications are performed through messages and this method is natural to hide the message waiting time. We are now investigating the effect of the multiple contexts on DMPP performance. Programming paradigm Message passing programming paradigms can not avoid message buffering.
Reference: [15] <author> P. J. Hatcher and M. J. Quinn: </author> <title> Data-Parallel Programming on MIMD Computers. </title> <publisher> The MIT Press, </publisher> <year> 1991. </year>
Reference-contexts: MLSim can be used to rapidly investigate the effect of varying communication parameters on the execution efficiency of a wide range of parallel programs. The parallel applications we studied are numerical algorithms which include objects produced from the Dataparallel-C <ref> [15] </ref> and Oxygen [22] parallelizing compilers. Related work Annaratone simulated several numerical and nonnumerical algorithms on five DMPPs and quantified the effect that interprocessor communication speed and synchronization overhead have on the performance of the DMPPs [2]. <p> A domain decomposition method is used for 216000 particles. QCD is a Monte Carlo program for Lattice Quantum Chromo Dynamics (QCD) [13]. The lattice size is 16fi16fi16fi16. OCEAN simulates an ocean circulation model. The model used here has one horizontal dimension and two layers. OCEAN is written in Dataparallel-C <ref> [15] </ref>. SHALLOW solves a set of shallow-water equations using finite difference approximations on a 64 fi 64 grid through 1200 iterations. SHALLOW is written in Dataparallel-C [15]. ORTHES transforms a real square matrix through Householder similarity transformations to an upper Hessenberg matrix. <p> OCEAN simulates an ocean circulation model. The model used here has one horizontal dimension and two layers. OCEAN is written in Dataparallel-C <ref> [15] </ref>. SHALLOW solves a set of shallow-water equations using finite difference approximations on a 64 fi 64 grid through 1200 iterations. SHALLOW is written in Dataparallel-C [15]. ORTHES transforms a real square matrix through Householder similarity transformations to an upper Hessenberg matrix. All eigenvectors and eigenvalues are computed for an unsymmetric matrix. ORTHES was produced by the compiler Oxygen [22].
Reference: [16] <author> T. Horie, H. Ishihata, and M. Ikesaka: </author> <title> "Design and implementation of an interconnection network for the AP1000," </title> <booktitle> In Information Processing 92, </booktitle> <volume> Volume I, </volume> <pages> pp. 555-561, </pages> <year> 1992. </year>
Reference-contexts: how to improve the AP1000 architecture. 2 Model, Simulation, and Applications This section presents the architecture and programming models, the simulation environment, and the benchmark applications. 2.1 Architecture and programming mod els For our study, we have chosen an architecture that resembles the AP1000 which is a large-scale message-passing machine <ref> [19, 24, 16] </ref>. The architecture consists of several processing elements connected through a point-to-point interconnection network and special barrier synchronization network. The point-to-point interconnection network also has a broadcast communication feature such as for columns and rows. 1 The AP1000 supports non-blocking message passing as a basic programming model.
Reference: [17] <author> J. M. Hsu and P. Banerjee: </author> <title> "A message passing coprocessor for distributed memory multicomputers," </title> <booktitle> In Supercomputing 90, </booktitle> <pages> pp. 720-729, </pages> <year> 1990. </year>
Reference-contexts: Message handling consists of two times. One is the fixed overhead time to construct a message and set up the appropriate communication mechanism, and the other is the time proportional to the message length. Several techniques for reducing message handling have been proposed <ref> [8, 21, 23, 17] </ref>. Fixed overhead time can be reduced by using specialized hardware such as a message formatter and message searcher. One way to reduce the overhead proportional to the message length is overlapping communication with computation.
Reference: [18] <author> J. M. Hsu and P. Banerjee: </author> <title> "Performance measurement and trace driven simulation of parallel CAD and numerical applications on a hypercube multi-computer," </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 3, 4, </volume> <pages> pp. 451-464, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: In his paper, however, only communication between neighboring processors was used and messages were not vectorized to reduce communication overhead. Hsu presented the performance evaluation and trace driven simulation of a hypercube multicomputer running realistic workloads <ref> [18] </ref>. In his evaluation, overhead for event tracing was included and results were obtained from less than 16 processors. To reflect current architecture for larger systems and achieve good performance, we must quantify the effect not only of communication latency and throughput, but also communication overlapping with computation.
Reference: [19] <author> H. Ishihata, T. Horie, S. Inano, T. Shimizu, and S. Kato: </author> <title> "An architecture of highly parallel computer AP1000," </title> <booktitle> In IEEE Pacific Rim Conf. on Communications, Computers and Signal processing, </booktitle> <pages> pp. 13-16, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: how to improve the AP1000 architecture. 2 Model, Simulation, and Applications This section presents the architecture and programming models, the simulation environment, and the benchmark applications. 2.1 Architecture and programming mod els For our study, we have chosen an architecture that resembles the AP1000 which is a large-scale message-passing machine <ref> [19, 24, 16] </ref>. The architecture consists of several processing elements connected through a point-to-point interconnection network and special barrier synchronization network. The point-to-point interconnection network also has a broadcast communication feature such as for columns and rows. 1 The AP1000 supports non-blocking message passing as a basic programming model.
Reference: [20] <author> K. L. Johnson: </author> <title> "The impact of communication locality on large-scale multiprocessor performance," </title> <booktitle> In The 19th Annual International Symposium on Computer Architecture, </booktitle> <pages> pp. 392-402, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: Johnson presented a framework for modeling the impact of communication locality on system performance and showed this impact using the modeling framework <ref> [20] </ref>. In his paper, communication transactions are cache coherency transactions and the communication characteristics are quite different from those of message-passing machines.
Reference: [21] <author> R. S. Nikhil, G. M. Papadopoulos, and Arvind: </author> <title> "*T: A multithreaded massively parallel architecture," </title> <booktitle> In The 19th Annual International Symposium on Computer Architecture, </booktitle> <pages> pp. 156-167, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: Message handling consists of two times. One is the fixed overhead time to construct a message and set up the appropriate communication mechanism, and the other is the time proportional to the message length. Several techniques for reducing message handling have been proposed <ref> [8, 21, 23, 17] </ref>. Fixed overhead time can be reduced by using specialized hardware such as a message formatter and message searcher. One way to reduce the overhead proportional to the message length is overlapping communication with computation. <p> The multiple context reduces idle time without rewriting application programs. This multiple context approach is different from that for hiding the latency of remote data fetch <ref> [21, 4, 14] </ref>. On message-passing machines, all communications are performed through messages and this method is natural to hide the message waiting time. We are now investigating the effect of the multiple contexts on DMPP performance. Programming paradigm Message passing programming paradigms can not avoid message buffering.
Reference: [22] <author> R. Ruehl: </author> <title> "Evaluation of compiler generated parallel programs on three multicomputers," </title> <booktitle> In Proc. of the Sixth International Conference on Supercomputing, </booktitle> <month> June </month> <year> 1992. </year>
Reference-contexts: MLSim can be used to rapidly investigate the effect of varying communication parameters on the execution efficiency of a wide range of parallel programs. The parallel applications we studied are numerical algorithms which include objects produced from the Dataparallel-C [15] and Oxygen <ref> [22] </ref> parallelizing compilers. Related work Annaratone simulated several numerical and nonnumerical algorithms on five DMPPs and quantified the effect that interprocessor communication speed and synchronization overhead have on the performance of the DMPPs [2]. <p> SHALLOW is written in Dataparallel-C [15]. ORTHES transforms a real square matrix through Householder similarity transformations to an upper Hessenberg matrix. All eigenvectors and eigenvalues are computed for an unsymmetric matrix. ORTHES was produced by the compiler Oxygen <ref> [22] </ref>. TSDE is used in analyzing the behavior of airfoils in subsonic, transonic, and supersonic regimes by solving a two-dimensional, steady-state transonic small disturbance equation. A finite difference method solves the problem iteratively with a successive over-relaxation scheme. The results refer to 20 iterations of the SOR algorithm. <p> A finite difference method solves the problem iteratively with a successive over-relaxation scheme. The results refer to 20 iterations of the SOR algorithm. TSDE was produced by the compiler Oxygen <ref> [22] </ref>. AMBER is a molecular dynamics simulation program which was parallelized by Sato [11]. A particle division method allocates particles randomly to processors. The number of atoms is 2000. SLALOM is a computer benchmark which solves an optical radiosity in the interior of a box [12].
Reference: [23] <author> S. Sakai, Y. Yamaguchi, K. Hiraki, and T. Yuba: </author> <title> "An architecture of a dataflow single chip processor," </title> <booktitle> In The 16th Annual International Symposium on Computer Architecture, </booktitle> <pages> pp. 46-53, </pages> <month> May </month> <year> 1989. </year>
Reference-contexts: Message handling consists of two times. One is the fixed overhead time to construct a message and set up the appropriate communication mechanism, and the other is the time proportional to the message length. Several techniques for reducing message handling have been proposed <ref> [8, 21, 23, 17] </ref>. Fixed overhead time can be reduced by using specialized hardware such as a message formatter and message searcher. One way to reduce the overhead proportional to the message length is overlapping communication with computation.
Reference: [24] <author> T. Shimizu, T. Horie, and H. Ishihata: </author> <title> "Low-latency message communication support for the AP1000," </title> <booktitle> In The 19th Annual International Symposium on Computer Architecture, </booktitle> <pages> pp. 288-297, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: how to improve the AP1000 architecture. 2 Model, Simulation, and Applications This section presents the architecture and programming models, the simulation environment, and the benchmark applications. 2.1 Architecture and programming mod els For our study, we have chosen an architecture that resembles the AP1000 which is a large-scale message-passing machine <ref> [19, 24, 16] </ref>. The architecture consists of several processing elements connected through a point-to-point interconnection network and special barrier synchronization network. The point-to-point interconnection network also has a broadcast communication feature such as for columns and rows. 1 The AP1000 supports non-blocking message passing as a basic programming model.
References-found: 24

