URL: http://www.cs.rutgers.edu/~uli/cs671/ruttenberg-pldi96.ps
Refering-URL: http://www.cs.rutgers.edu/~uli/cs671/index.html
Root-URL: http://www.cs.rutgers.edu
Title: Abstract  
Abstract: This paper is a scientific comparison of two code generation techniques with identical goals generation of the best possible software pipelined code for computers with instruction level parallelism. Both are variants of modulo scheduling, a framework for generation of software pipelines pioneered by Rau and Glaser [RaGl81], but are otherwise quite dissimilar. One technique was developed at Silicon Graphics and is used in the MIPSpro compiler. This is the production compiler for SGI s systems which are based on the MIPS R8000 processor [Hsu94]. It is essentially a branchandbound enumeration of possible schedules with extensive pruning. This method is heuristic because of the way it prunes and also because of the interaction between register allocation and scheduling. 1 The second technique aims to produce optimal results by formulating the scheduling and register allocation problem as an integrated integer linear programming (ILP 1 ) problem. This idea has received much recent exposure in the literature [AlGoGa95, Feautrier94, GoAlGa94a, GoAlGa94b, Eichenberger95], but to our knowledge all previous implementations have been too preliminary for detailed measurement and evaluation. In particular, we believe this to be the first published measurement of runtime performance for ILP based generation of software pipelines. A particularly valuable result of this study was evaluation of the heuristic pipelining technology in the SGI compiler . One of the motivations behind the McGill research was the hope that optimal software pipelining, while not in itself practical for use in production compilers, would be useful for their evaluation and validation. Our comparison has indeed provided a quantitative validation of the SGI compilers pipeliner, leading us to increased confidence in both techniques. 
Abstract-found: 1
Intro-found: 1
Reference: [AiNi88] <author> A. Aiken and A. Nicolau. </author> <title> Optimal loop paralleliza-tions. </title> <booktitle> In Proc. of the '88 SIGPLAN Conf. on Programming Language Design and Implementation, </booktitle> <pages> pp. 308-317, </pages> <address> Atlanta, Georgia, </address> <month> June </month> <year> 1988. </year>
Reference-contexts: Such a schedule is called rateoptimal. The problem of finding rateoptimal schedules is NPcomplete [GaJo79], a fact that has led to a number of heuristic techniques <ref> [DeTo93, GaSc91, Huff93, MoEb92, Rau94, Warter92, Lam88, AiNi88] </ref> for generation of optimal or near optimal software pipelined code. [RaFi93] contains an introductory survey of these methods. 1.2 The allure of optimal techniques Recently, motivated by the critical role of software pipelining in high performance computing, researchers have become interested in nonheuristic
Reference: [AlKePoWa83] <author> J. R. Allen, K. Kennedy, C. Porterfield, and J. Warren. </author> <title> Conversion of control dependence to data dependence. </title> <booktitle> In Proc. of the 10th Ann. ACM Symp. on Principles of Programming Languages, </booktitle> <pages> pp. 177-189, </pages> <month> January </month> <year> 1983. </year>
Reference-contexts: The key observation is that the problem can be formulated using integer linear programming ( ILP), a well known framework for solving NPcomplete problems <ref> [Altman95, AlKePoWa83] </ref>. Given such a formulation, the problem can be given to one of a number of standard ILP solving packages. Because this framework has been ef fective in solving other com-putationally difficult problems [NeWo88, Nemhauser94, Pugh91,BiKeKr94], it is hoped that it can also be useful for soft ware pipelining. <p> unrolling; 2. classical intermediate code optimizations, such as: a. common subexpression elimination, b. copy propagation, c. constant folding, and d. strength reduction; 3. special inner loop optimizations and analysis in preparation for software pipelining, in particular: a. if-conversion to convert loops with internal branches to a form using conditional moves <ref> [AlKePoWa83, DeTo93] </ref>, b. interleaving of register recurrences such as summation or dot products, c. inter iteration common memory reference elimination, and d. data dependence graph construction. 2.2 Modulo scheduling The framework for the MIPSpro compiler s pipeliner is modulo scheduling, a technique pioneered by Bob Rau and others and very well
Reference: [AlGoGa95] <author> E. R. Altman, R. Givindarajan, and G.R. Gao. </author> <title> Scheduling and mapping: Software pipelining in the presence of structural hazards. </title> <booktitle> In Proc. of '95 SIGPLAN Conf. on Programming Language Design and Implementation, </booktitle> <address> La Jolla, Calif., </address> <month> June </month> <year> 1995. </year>
Reference-contexts: The work was subsequently generalized to more complex architectures <ref> [AlGoGa95] </ref>. By the spring of 1995, this work was implemented at McGill in MOST, the Modulo Scheduling Toolset, which makes use of any one of several external ILP solvers. MOST was not intended as a component of a production compiler, but rather as a standard of comparison. <p> Being able to generate optimal pipelined loops can be useful for evaluating and improving heuristics for production pipeliners (as this study demonstrates). Because the McGill work is well represented in recent publications, we omit the details of the ILP formulation. The interested reader should consult <ref> [AlGoGa95] </ref> and then the other cited publications. 3.2 Integration with the MIPSpro compiler The research at McGill left many open questions. <p> Adjustment of the objective function Often it was not feasible to use the register optimal formulation (involving coloring) reported in <ref> [AlGoGa95] </ref>. Instead, the ILP formulation used minimized the number of buffers in the software pipeline. This objective function directly translates into the reduction of the number of iterations overlapped in the steady state of the pipeline. 1 The ILP solver for this phase was restricted to a fixed time limit.
Reference: [Altman95] <author> E. R. Altman. </author> <title> Optimal Software Pipelining with Functional Unit and Register Constraints. </title> <type> Ph.D. thesis, </type> <institution> McGill University, </institution> <address> Montreal, Quebec, </address> <year> 1995. </year>
Reference-contexts: The key observation is that the problem can be formulated using integer linear programming ( ILP), a well known framework for solving NPcomplete problems <ref> [Altman95, AlKePoWa83] </ref>. Given such a formulation, the problem can be given to one of a number of standard ILP solving packages. Because this framework has been ef fective in solving other com-putationally difficult problems [NeWo88, Nemhauser94, Pugh91,BiKeKr94], it is hoped that it can also be useful for soft ware pipelining.
Reference: [BiKeKr94] <author> R. Bixby, K. Kennedy, and U. Kremer. </author> <title> Automatic data layout using 0-1 integer linear programming. </title> <booktitle> In Proc. of Conf. on Parallel Architectures and Compilation Techniques, </booktitle> <pages> pp. 111-122, </pages> <month> August </month> <year> 1994. </year>
Reference: [BrCoKeTo89] <author> P. Briggs, K.D. Cooper, K. Kennedy, and L. Torczon. </author> <title> Coloring heuristics for register allocation. </title> <booktitle> In Proc. of '89 SIGPLAN Conf. on Programming Language Design and Implementation, </booktitle> <pages> pp. 275-284, </pages> <month> July </month> <year> 1989. </year>
Reference-contexts: The SGI pipeliner borrows this technique. The modulo renamed live ranges so generated serve as input of a standard global register allocator that uses the Chaitin-Briggs algorithm with minor modifications. <ref> [BrCoKeTo89, Briggs92] </ref>. 2.7 Multiple scheduling priorities and their effect on register allocation Early on the SGI team discovered that the ordering of operations on the schedule priority list has a significant impact on whether the schedules found can be register allocated. On ref lection this is not very surprising.
Reference: [Briggs92] <author> P. Briggs. </author> <title> Register Allocation via Graph Coloring. </title> <type> Ph.D. thesis, </type> <institution> Rice University, Houston, Texas, </institution> <month> April </month> <year> 1992. </year>
Reference-contexts: The SGI pipeliner borrows this technique. The modulo renamed live ranges so generated serve as input of a standard global register allocator that uses the Chaitin-Briggs algorithm with minor modifications. <ref> [BrCoKeTo89, Briggs92] </ref>. 2.7 Multiple scheduling priorities and their effect on register allocation Early on the SGI team discovered that the ordering of operations on the schedule priority list has a significant impact on whether the schedules found can be register allocated. On ref lection this is not very surprising.
Reference: [DeTo93] <author> J.C. Dehnert and R.A. Towle. </author> <title> Compiling for Cydra 5. </title> <journal> Journal of Supercomputing, v.7, </journal> <volume> pp.181-227, </volume> <month> May </month> <year> 1993. </year>
Reference-contexts: Such a schedule is called rateoptimal. The problem of finding rateoptimal schedules is NPcomplete [GaJo79], a fact that has led to a number of heuristic techniques <ref> [DeTo93, GaSc91, Huff93, MoEb92, Rau94, Warter92, Lam88, AiNi88] </ref> for generation of optimal or near optimal software pipelined code. [RaFi93] contains an introductory survey of these methods. 1.2 The allure of optimal techniques Recently, motivated by the critical role of software pipelining in high performance computing, researchers have become interested in nonheuristic <p> unrolling; 2. classical intermediate code optimizations, such as: a. common subexpression elimination, b. copy propagation, c. constant folding, and d. strength reduction; 3. special inner loop optimizations and analysis in preparation for software pipelining, in particular: a. if-conversion to convert loops with internal branches to a form using conditional moves <ref> [AlKePoWa83, DeTo93] </ref>, b. interleaving of register recurrences such as summation or dot products, c. inter iteration common memory reference elimination, and d. data dependence graph construction. 2.2 Modulo scheduling The framework for the MIPSpro compiler s pipeliner is modulo scheduling, a technique pioneered by Bob Rau and others and very well
Reference: [Eichenberger95] <author> A. E. Eichenberger, E. S. Davidson, and S. G. Abraham. </author> <title> Optimum modulo schedules for minimum register requirements. </title> <booktitle> In Proc. of '95 Intl. Conf. on Supercomputing, </booktitle> <pages> pp. 31-40, </pages> <address> Barcelona, Spain, </address> <month> July </month> <year> 1995. </year>
Reference: [Feautrier94] <author> P. Feautrier. </author> <title> Fine-grained scheduling under resource constraints. </title> <booktitle> In 7th Ann. Workshop on Languages and Compilers for Parallel Computing, </booktitle> <address> Ithaca, N.Y., </address> <month> August </month> <year> 1994. </year>
Reference: [GaNi91] <author> G. R. Gao and Q. Ning. </author> <title> Loop storage optimization for dataow machines. </title> <booktitle> In Proc. of 4th Ann. Workshop on Languages and Compilers for Parallel Computing, </booktitle> <pages> pp. 359-373, </pages> <month> August </month> <year> 1991. </year>
Reference: [GaJo79] <author> M.R. Garey and D.S. Johnson. </author> <title> Computers and Intractability: A Guideto the Theory of NP-Completeness. W.H. </title> <publisher> Freeman and Co., </publisher> <address> New York, N.Y., </address> <year> 1979. </year>
Reference-contexts: Such a schedule is called rateoptimal. The problem of finding rateoptimal schedules is NPcomplete <ref> [GaJo79] </ref>, a fact that has led to a number of heuristic techniques [DeTo93, GaSc91, Huff93, MoEb92, Rau94, Warter92, Lam88, AiNi88] for generation of optimal or near optimal software pipelined code. [RaFi93] contains an introductory survey of these methods. 1.2 The allure of optimal techniques Recently, motivated by the critical role of
Reference: [GaSc91] <author> F. Gasperoni and U. Schwiegelshohn. </author> <title> Ef ficient algorithms for cyclic scheduling. </title> <institution> Res. Prep. RC 17068, IBM TJ Wat-son Res. Center, </institution> <address> Yorktown Heights, N.Y., </address> <year> 1991. </year>
Reference-contexts: Such a schedule is called rateoptimal. The problem of finding rateoptimal schedules is NPcomplete [GaJo79], a fact that has led to a number of heuristic techniques <ref> [DeTo93, GaSc91, Huff93, MoEb92, Rau94, Warter92, Lam88, AiNi88] </ref> for generation of optimal or near optimal software pipelined code. [RaFi93] contains an introductory survey of these methods. 1.2 The allure of optimal techniques Recently, motivated by the critical role of software pipelining in high performance computing, researchers have become interested in nonheuristic
Reference: [GoAlGa94a] <author> R. Govindarajan, E. R. Altman, and G. R. Gao. </author> <title> A framework for rate-optimal resource-constrained software pipe-lining. </title> <booktitle> In Proc. of CONPAR94-VAPP VI, </booktitle> <volume> no. 854, </volume> <booktitle> Lecture Notes in Computer Science, </booktitle> <pages> pp. 640-651, </pages> <address> Linz, Austria, </address> <month> September </month> <year> 1994. </year>
Reference: [GoAlGa94b] <author> R. Govindarajan, E. R. Altman, and G. R. Gao. </author> <title> Minimizing register requirements under resource-constrained rate-optimal software pipelining. </title> <booktitle> In Proc. of the 27th Ann. Intl. Symp. on Microarchitecture, </booktitle> <pages> pp. 85-94, </pages> <address> San Jose, Calif., </address> <month> No-vember-December </month> <year> 1994. </year>
Reference: [Hsu94] <author> Hsu, P., </author> <title> Designing the TFP Microprocessor, </title> <booktitle> IEEE Micro, </booktitle> <month> April </month> <year> 1994, </year> <pages> pp. 23-33. </pages>
Reference-contexts: in detail, present our experimental results, draw some conclusions from these results, and try to shed some intuitive light on the results. 2.0 The heuristic approach software pipelining at Silicon Graphics 2.1 MIPSpro compiler Starting in 1990, Silicon Graphics designed a new microprocessor aimed at the supercomputing market called R8000 <ref> [HSU94] </ref> and shipped with SGIs Power Challenge and Power Indigo2 computers. It is an inorder 4-issue superscalar RISC processor featuring fully pipelined floating point and memory operations.
Reference: [Huff93] <author> R. A. Huff. </author> <title> Lifetime-sensitive modulo scheduling. </title> <booktitle> In Proc. of the '93 SIGPLAN Conf. on Programming Language Design and Implementation, </booktitle> <pages> pp. 258-267, </pages> <address> Albuquerque, N. Mex., </address> <month> June </month> <year> 1993. </year>
Reference-contexts: Such a schedule is called rateoptimal. The problem of finding rateoptimal schedules is NPcomplete [GaJo79], a fact that has led to a number of heuristic techniques <ref> [DeTo93, GaSc91, Huff93, MoEb92, Rau94, Warter92, Lam88, AiNi88] </ref> for generation of optimal or near optimal software pipelined code. [RaFi93] contains an introductory survey of these methods. 1.2 The allure of optimal techniques Recently, motivated by the critical role of software pipelining in high performance computing, researchers have become interested in nonheuristic
Reference: [Lam88] <author> M. Lam. </author> <title> Software pipelining: An effective scheduling technique for VLIW machines. </title> <booktitle> In Proc. of the ' 88 SIGPLAN Conf. on Programming Lanugage Design and Implementation, </booktitle> <pages> pp. 318-328, </pages> <address> Atlanta, Georgia, </address> <month> June </month> <year> 1988. </year>
Reference-contexts: Such a schedule is called rateoptimal. The problem of finding rateoptimal schedules is NPcomplete [GaJo79], a fact that has led to a number of heuristic techniques <ref> [DeTo93, GaSc91, Huff93, MoEb92, Rau94, Warter92, Lam88, AiNi88] </ref> for generation of optimal or near optimal software pipelined code. [RaFi93] contains an introductory survey of these methods. 1.2 The allure of optimal techniques Recently, motivated by the critical role of software pipelining in high performance computing, researchers have become interested in nonheuristic <p> register recurrences such as summation or dot products, c. inter iteration common memory reference elimination, and d. data dependence graph construction. 2.2 Modulo scheduling The framework for the MIPSpro compiler s pipeliner is modulo scheduling, a technique pioneered by Bob Rau and others and very well described in the literature. <ref> [Lam88, RaFi93, Lam89] </ref>. Modulo schedulers search for possible schedules by f irst fixing a iteration interval (II) and then trying to pack the operation in the loop body into the given number of cycles. <p> Lam pointed out that being able to find a schedule at II does not imply being able to find a schedule at II+1 and used this to explain why her compiler used linear search <ref> [Lam88] </ref>. searching successively: 3 MinII, MinII+1, MinII+2, MinII+4, MinII+8,... until we either find a schedule or exceed MaxII. If a schedule is found with II MinII+2, there are no better IIs left to search and the schedule is accepted.
Reference: [Lam89] <author> M. Lam. </author> <title> A systolic array optimizing compiler. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1989. </year>
Reference-contexts: register recurrences such as summation or dot products, c. inter iteration common memory reference elimination, and d. data dependence graph construction. 2.2 Modulo scheduling The framework for the MIPSpro compiler s pipeliner is modulo scheduling, a technique pioneered by Bob Rau and others and very well described in the literature. <ref> [Lam88, RaFi93, Lam89] </ref>. Modulo schedulers search for possible schedules by f irst fixing a iteration interval (II) and then trying to pack the operation in the loop body into the given number of cycles. <p> The R8000 has no explicit support for software pipelining. In particular , it has only conventionally accessed registers. Lam describes a technique called modulo renaming that allows effective pipelining with conventional architectures by replicating the software pipeline and rewriting the register references in each replicated instance <ref> [Lam89] </ref>. The SGI pipeliner borrows this technique.
Reference: [MoEb92] <author> S. Moon and K. Ebcioglu. </author> <title> An efficient resource-constrained global scheduling technique for superscalar and VLIW processors. </title> <booktitle> In Proc. of the 25th Ann. Intl. Symp. on Microarchi-tecture, </booktitle> <pages> pp. 55-71, </pages> <address> Portland, Ore., </address> <month> December </month> <year> 1992. </year> <month> 11 </month>
Reference-contexts: Such a schedule is called rateoptimal. The problem of finding rateoptimal schedules is NPcomplete [GaJo79], a fact that has led to a number of heuristic techniques <ref> [DeTo93, GaSc91, Huff93, MoEb92, Rau94, Warter92, Lam88, AiNi88] </ref> for generation of optimal or near optimal software pipelined code. [RaFi93] contains an introductory survey of these methods. 1.2 The allure of optimal techniques Recently, motivated by the critical role of software pipelining in high performance computing, researchers have become interested in nonheuristic
Reference: [NeWo88] <author> G. Nemhauser and L. Wolsey. </author> <title> Integer and Combinatorial Optimization. </title> <publisher> John Wiley & Sons, </publisher> <year> 1988. </year>
Reference-contexts: Given such a formulation, the problem can be given to one of a number of standard ILP solving packages. Because this framework has been ef fective in solving other com-putationally difficult problems <ref> [NeWo88, Nemhauser94, Pugh91,BiKeKr94] </ref>, it is hoped that it can also be useful for soft ware pipelining. Software Pipelining Showdown: Optimal vs. Heuristic Methods in a Production Compiler John Ruttenberg*, G.R.Gao, A.Stoutchinin, and W.Lichtenstein* *Silicon Graphics Inc., 2011 N.
Reference: [Nemhauser94] <author> G. Nemhauser. </author> <title> The age of optimization: Solving large-scale real-world problems. </title> <journal> Operations Research, </journal> <volume> 42(1) </volume> <pages> 5-13, </pages> <month> January-February </month> <year> 1994. </year>
Reference-contexts: Given such a formulation, the problem can be given to one of a number of standard ILP solving packages. Because this framework has been ef fective in solving other com-putationally difficult problems <ref> [NeWo88, Nemhauser94, Pugh91,BiKeKr94] </ref>, it is hoped that it can also be useful for soft ware pipelining. Software Pipelining Showdown: Optimal vs. Heuristic Methods in a Production Compiler John Ruttenberg*, G.R.Gao, A.Stoutchinin, and W.Lichtenstein* *Silicon Graphics Inc., 2011 N.
Reference: [NiGa92] <author> Q. Ning and G. Gao. </author> <title> Optimal loop storage allocation for argument-fetching dataow machines. </title> <journal> International Journal of Parallel Programming, v. </journal> <volume> 21, no. 6, </volume> <month> December </month> <year> 1992. </year>
Reference: [NiGa93] <author> Q. Ning and G. Gao. </author> <title> A novel framework of register allocation for software pipelining. </title> <booktitle> In Conf. Rec.of the 20th Ann. ACM SIGPLAN-SIGACT Symp. on Principles of Programming Languages, </booktitle> <pages> pp. 29-42, </pages> <address> Charleston, S. Carolina, </address> <month> January </month> <year> 1993. </year>
Reference-contexts: This formulation was then used to prove an interesting theoretical result: the minimum storage assignment problem for rate-optimal software pipelined schedules can be solved using an efficient polynomial-time method provided the target machine has enough functional units so resource constraints can be ignored <ref> [NiGa93] </ref>. In this framework, FIFO buf fers are used to model register requirements. A graph coloring method can be applied subsequently on the obtained schedule to further decrease the register requirements of the loop.
Reference: [Pugh91] <author> W. Pugh. </author> <title> The Omega test: A fast and practical integer programming algorithm for dependence analysis. </title> <booktitle> In Proc. Supercomputing '91, </booktitle> <pages> pp. 18-22, </pages> <month> November </month> <year> 1991. </year>
Reference: [RaGl81] <author> B. R. Rau and C. D. Glaser. </author> <title> Some scheduling tec-niques and an easily schedulable horizontal architecture for high performance scientific computing. </title> <booktitle> In Proc. of the 14 Ann. Microprogramming Workshop, </booktitle> <pages> pp. 183-198, </pages> <address> Chatham, Mass., </address> <month> Oc-tober </month> <year> 1981. </year>
Reference-contexts: The search is bounded from below by MinII, a loose lower bound based on resources required and any dependence cycles in the loop body <ref> [RaGl81] </ref>. The search is bounded from above by an arbitrary maximum MaxII = 2MinII. We set this maximum as a sort of compile speed circuit breaker under the assumption that software pipelining has little advantage over traditional scheduling once this bound is exceeded.
Reference: [RaFi93] <author> B. R. Rau and J.A. Fisher. </author> <title> Instruction-level parallel processing: History, overview and perspective. </title> <journal> Journal of Supercomputing, v.7, </journal> <volume> pp.:9-50, </volume> <month> May </month> <year> 1993. </year>
Reference-contexts: Such a schedule is called rateoptimal. The problem of finding rateoptimal schedules is NPcomplete [GaJo79], a fact that has led to a number of heuristic techniques [DeTo93, GaSc91, Huff93, MoEb92, Rau94, Warter92, Lam88, AiNi88] for generation of optimal or near optimal software pipelined code. <ref> [RaFi93] </ref> contains an introductory survey of these methods. 1.2 The allure of optimal techniques Recently, motivated by the critical role of software pipelining in high performance computing, researchers have become interested in nonheuristic methods, ones that guarantee the optimality of the solutions they find. <p> register recurrences such as summation or dot products, c. inter iteration common memory reference elimination, and d. data dependence graph construction. 2.2 Modulo scheduling The framework for the MIPSpro compiler s pipeliner is modulo scheduling, a technique pioneered by Bob Rau and others and very well described in the literature. <ref> [Lam88, RaFi93, Lam89] </ref>. Modulo schedulers search for possible schedules by f irst fixing a iteration interval (II) and then trying to pack the operation in the loop body into the given number of cycles.
Reference: [Rau94] <author> B.R. Rau. </author> <title> Iterative modulo scheduling: An algorithm for software pipelining loops. </title> <booktitle> In Proc. of the 27th Ann. Intl. Symp. on Microarchitecture, </booktitle> <pages> pp. 63-74, </pages> <address> San Jose, Calif., </address> <month> No-vember-December </month> <year> 1994. </year>
Reference-contexts: This, along with a vague and unfounded perception that modulo scheduling is computationally expensive as well as difficult to implement, have inhibited its incorporation into product compilers. B. Ramakrishna Rau <ref> [Rau94] </ref> 1.0 Introduction 1.1 Software pipelining Software pipelining is a coding technique that overlaps operations from various loop iterations in order to exploit instruction level parallelism. <p> Such a schedule is called rateoptimal. The problem of finding rateoptimal schedules is NPcomplete [GaJo79], a fact that has led to a number of heuristic techniques <ref> [DeTo93, GaSc91, Huff93, MoEb92, Rau94, Warter92, Lam88, AiNi88] </ref> for generation of optimal or near optimal software pipelined code. [RaFi93] contains an introductory survey of these methods. 1.2 The allure of optimal techniques Recently, motivated by the critical role of software pipelining in high performance computing, researchers have become interested in nonheuristic
Reference: [Tou84] <author> R.F. Touzeau. </author> <title> A FORTRAN compiler for the FPS164 scientific computer. </title> <booktitle> In Proceedings of the SIGPLAN 84 Symposium on Compiler Construction, </booktitle> <pages> pages 4857, </pages> <address> Montreal, Que-bec, </address> <month> June 1722, </month> <year> 1984. </year>
Reference: [Warter92] <author> N.J. Warter, John W. Bockhaus, Grant E. Haab, and K. Supraliminal. </author> <title> Enhanced modulo scheduling for loops with conditional branches. </title> <booktitle> In Proc. of the 25th Ann. Intl. Symp. on Microarchitecture, </booktitle> <pages> pp. 170-179, </pages> <address> Portland, Ore., </address> <month> December </month> <year> 1992. </year>
Reference-contexts: Such a schedule is called rateoptimal. The problem of finding rateoptimal schedules is NPcomplete [GaJo79], a fact that has led to a number of heuristic techniques <ref> [DeTo93, GaSc91, Huff93, MoEb92, Rau94, Warter92, Lam88, AiNi88] </ref> for generation of optimal or near optimal software pipelined code. [RaFi93] contains an introductory survey of these methods. 1.2 The allure of optimal techniques Recently, motivated by the critical role of software pipelining in high performance computing, researchers have become interested in nonheuristic
References-found: 30

