URL: http://www.genetic-programming.com/FOGA90.ps
Refering-URL: http://www.genetic-programming.com/jkpubs72to93.html
Root-URL: http://www.genetic-programming.com/jkpubs72to93.html
Email: Koza@Sunburn.Stanford.Edu  
Title: A Hierarchical Approach to Learning the Boolean Multiplexer Function  
Author: John R. Koza 
Note: 1 Introduction and Overview 2 Background  
Date: 415-941-0336  
Address: Stanford, CA 94305 USA  
Affiliation: Computer Science Department Stanford University  
Abstract: This paper describes the recently developed genetic programming paradigm which genetically breeds populations of computer programs to solve problems. In genetic programming, the individuals in the population are hierarchical compositions of functions and arguments. Each of these individual computer programs is evaluated for its fitness in handling the problem environment. The size and shape of the computer program needed to solve the problem is not predetermined by the user, but instead emerges from the simulated evolutionary process driven by fitness. In this paper, the operation of the genetic programming paradigm is illustrated with the problem of learning the Boolean 11-multiplexer function. We start by reviewing previous work in the field of genetic algorithms and previous work in the field of induction of computer programs. We then describe the recently developed genetic programming paradigm and apply it to the problem of learning the Boolean 11-multiplexer problem. John Holland of the University of Michigan presented the pioneering formulation of genetic algorithms for fixed-length character strings in Adaptation in Natural and Artificial Systems (Holland 1975). The genetic algorithm is a highly parallel mathematical algorithm that transforms a population of individual mathematical objects (typically fixed-length binary character strings) into a new population using operations patterned after natural genetic operations such as sexual recombination (crossover) and fitness proportionate reproduction (Darwinian survival of the fittest). The genetic algorithm begins with an initial population of individuals (typically randomly generated). It then 
Abstract-found: 1
Intro-found: 1
Reference: <author> Barto, A. G., Anandan, P., and Anderson, C. W. </author> <title> Cooperativity in networks of pattern recognizing stochastic learning automata. </title> <booktitle> In Narendra,K.S. Adaptive and Learning Systems. </booktitle> <address> New York: </address> <publisher> Plenum 1985. </publisher>
Reference: <author> Cramer, Nichael Lynn. </author> <title> A representation for the adaptive generation of simple sequential programs. </title> <booktitle> In Proceedings of an International Conference on Genetic Algorithms and Their Applications. </booktitle> <address> Hillsdale, NJ: </address> <publisher> Lawrence Erlbaum Associates l985. </publisher>
Reference: <author> De Jong, Kenneth A. </author> <title> Learning with genetic algorithms: an overview. </title> <journal> Machine Learning, </journal> <volume> 3(2), </volume> <pages> 121-138, </pages> <year> 1988. </year>
Reference-contexts: Fixed length character strings present difficulties in problems where the desired solution is hierarchical and where the size and shape of the solution is unknown in advance. The need for more powerful representations has been long recognized <ref> (De Jong 1988) </ref>. The structure of the individual mathematical objects that are manipulated by a genetic algorithm can be more complex than the fixed length character strings.
Reference: <author> Fujiki, Cory and Dickinson, John. </author> <title> Using the genetic algorithm to generate LISP source code to solve the prisoner's dilemma. </title> <editor> In Grefenstette, John J.(editor). </editor> <booktitle> Genetic Algorithms and Their Applications: Proceedings of the Second International Conference on Genetic Algorithms. </booktitle> <address> Hillsdale, NJ: </address> <publisher> Lawrence Erlbaum Associates l987. </publisher>
Reference: <author> Goldberg, David E., Korb, B., and Deb, K.. </author> <title> Messy genetic algorithms: Motivation, analysis, and first results. </title> <journal> Complex Systems. </journal> <pages> Pages 493-530. </pages> <month> 3(5) October </month> <year> 1989. </year>
Reference: <author> Holland, J. H. </author> <booktitle> Adaptation in Natural and Artificial Systems. </booktitle> <address> Ann Arbor, MI: </address> <publisher> University of Michigan Press 1975. </publisher>
Reference-contexts: We then describe the recently developed genetic programming paradigm and apply it to the problem of learning the Boolean 11-multiplexer problem. 2 . Background John Holland of the University of Michigan presented the pioneering formulation of genetic algorithms for fixed-length character strings in Adaptation in Natural and Artificial Systems <ref> (Holland 1975) </ref>. The genetic algorithm is a highly parallel mathematical algorithm that transforms a population of individual mathematical objects (typically fixed-length binary character strings) into a new population using operations patterned after natural genetic operations such as sexual recombination (crossover) and fitness proportionate reproduction (Darwinian survival of the fittest).
Reference: <author> Holland, John H. </author> <title> Escaping brittleness: The possibilities of general-purpose learning algorithms applied to parallel rule-based systems. </title> <editor> In Michalski, Ryszard S., Carbonell, Jaime G. and Mitchell, Tom M. </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach, Volume II. P. </booktitle> <pages> 593-623. </pages> <address> Los Altos, CA: </address> <publisher> Morgan Kaufmann l986. </publisher>
Reference: <author> Koza, John R. </author> <title> Hierarchical genetic algorithms operating on populations of computer programs. </title> <booktitle> In Proceedings of the 11th International Joint Conference on Artificial Intelligence (IJCAI). </booktitle> <address> San Mateo, </address> <publisher> CA Morgan Kaufmann 1989. </publisher>
Reference: <author> Koza, John R. </author> <title> Genetic Programming: A Paradigm for Genetically Breeding Populations of Computer Programs to Solve Problems. </title> <institution> Stanford University Computer Science Department Technical Report STAN-CS-90-1314. </institution> <month> June </month> <year> 1990. 1990a. </year>
Reference: <author> Koza, John R. </author> <title> Genetically breeding populations of computer programs to solve problems in artificial intelligence. </title> <booktitle> In Proceedings of the Second International Conference on Tools for AI. </booktitle> <address> Washington. </address> <month> November 6-9, </month> <year> 1990. </year> <editor> 1990b Koza, John R. </editor> <title> Genetic evolution and coevolution of computer programs. </title> <editor> In Farmer, Doyne, Langton, Christopher, Rasmussen, S., and Taylor, C. </editor> <booktitle> (editors) Artificial Life II, SFI Studies in the Sciences of Complexity. Volume XI. </booktitle> <publisher> Addison-Wesley, </publisher> <address> Redwood City CA 1991. </address> <year> 1991a. </year>
Reference: <author> Koza, John R. </author> <title> Evolution and coevolution of computer programs to control independent-acting agents. </title> <editor> In Meyer, Jean-Arcady and Wilson, Stewart W. </editor> <booktitle> From Animals to Animats: Proceedings of the First International Conference on Simulation of Adaptive Behavior. </booktitle> <address> Paris. September 24-28, 1990. </address> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1991. 1991b. </year>
Reference: <author> Koza, John R. </author> <title> Concept formation and decision tree induction using the genetic programming paradigm. </title> <editor> In Schwefel, Hans-Paul and Maenner, </editor> <title> Reinhard (editors) Parallel Problem Solving from Nature. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1991. 1991c. </year>
Reference: <author> Koza, John R. </author> <title> A genetic approach to econometric modeling. </title> <editor> In Bourgine, Paul and Walliser, Bernard. </editor> <booktitle> Proceedings of the 2nd International Conference on Economics and Artificial Intelligence. </booktitle> <publisher> Pergamon Press 1991. </publisher> <year> 1991d. </year>
Reference: <author> Koza, John R. </author> <title> Evolving a computer program to generate random numbers using the genetic programming paradigm. </title> <editor> In Belew, Rik and Booker, </editor> <booktitle> Lashon (editors) Proceedings of the Fourth International Conference on Genetic Algorithms. </booktitle> <address> San Mateo, Ca: </address> <publisher> Morgan Kaufmann Publishers Inc. </publisher> <year> 1991. 1991e. </year>
Reference: <editor> Koza, John R. </editor> <booktitle> Genetic Programming. </booktitle> <address> Cambridge, MA: </address> <publisher> MIT Press, </publisher> <year> 1991 </year> <month> (forthcoming). </month> <year> 1991f. </year>
Reference: <author> Koza, John R. and Keane, Martin A. </author> <title> Cart centering and broom balancing by genetically breeding populations of control strategy programs. </title> <booktitle> In Proceedings of International Joint Conference on Neural Networks, </booktitle> <address> Washington, </address> <month> January, </month> <year> 1990. </year> <title> Volume I. </title> <address> Hillsdale, NJ: </address> <publisher> Lawrence Erlbaum 1990. </publisher> <year> 1990a. </year>
Reference: <author> Koza, John R. and Keane, Martin A. </author> <title> Genetic breeding of nonlinear optimal control strategies for broom balancing. </title> <booktitle> In Proceedings of the Ninth International Conference on Analysis and Optimization of Systems. </booktitle> <address> Berlin: </address> <publisher> Springer-Verlag, </publisher> <year> 1990. 1990b. </year>
Reference: <author> Koza, John R. and Rice, James P. </author> <title> Genetic generation of both the weights and architecture for a neural network. </title> <booktitle> In Proceedings of International Joint Conference on Neural Networks, </booktitle> <address> Seattle, </address> <month> July </month> <year> 1991. </year> <note> IEEE Press 1991. 1991a Koza, </note> <author> John R. and Rice, James P. </author> <title> A genetic approach to artificial intelligence. </title> <editor> In C. G. </editor> <booktitle> Langton Artificial Life II Video Proceedings. </booktitle> <publisher> Addison-Wesley 1991. </publisher> <year> 1991b. </year>
Reference: <author> Lenat, Douglas B. </author> <title> AM: An Artificial Intelligence Approach to Discovery in Mathematics as Heuristic Search. </title> <type> PhD Dissertation. </type> <institution> Computer Science Department. Stanford University. </institution> <year> 1976. </year>
Reference: <author> Lenat, Douglas B. </author> <title> The role of heuristics in learning by discovery: Three case studies. </title> <editor> In Michalski, Ryszard S., Carbonell, Jaime G. and Mitchell, Tom M. </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach, Volume I. P. </booktitle> <pages> 243-306. </pages> <address> Los Altos, CA: </address> <publisher> Morgan Kaufman l983. </publisher>
Reference: <author> Lenat, Douglas B. and Brown, John Seely. </author> <title> Why AM and EURISKO appear to work. </title> <journal> Artificial Intelligence. </journal> <volume> 23 (1984). </volume> <pages> 269-294. </pages>
Reference-contexts: In Lenat's mea culpa article "Why AM and EURISKO appear to work" <ref> (Lenat and Brown 1984) </ref>, Lenat recognized that LISP syntax may have overly facilitated discovery of his previously reported results, namely, mathematical laws stated in terms of LISP's list manipulation functions and LISP's primitive object (i.e. the list).
Reference: <author> Quinlan, J. R. </author> <title> Induction of decision trees. </title> <booktitle> Machine Learning 1 (1), </booktitle> <pages> 81-106, </pages> <year> 1986. </year>
Reference-contexts: For example, this same determination of primitive functions occurs in the induction of decision trees using ID3 <ref> (Quinlan 1986, Koza 1991c) </ref> when the user selects the functions that can appear at the internal points of the decision tree. Similarly, this same determination occurs in neural net problems when the user selects the external functions that are to be activated by the output of a neural network.
Reference: <author> Quinlan, J. R. </author> <title> An empirical comparison of genetic and decision-tree classifiers. </title> <booktitle> Proceedings of the Fifth International Conference on Machine Learning. </booktitle> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher> <year> 1988. </year>
Reference: <author> Smith, Steven F. </author> <title> A Learning System Based on Genetic Adaptive Algorithms. </title> <type> PhD dissertation. </type> <institution> Pittsburgh: University of Pittsburgh 1980. </institution>
Reference: <author> Wilson, Stewart. W. </author> <title> Classifier Systems and the animat problem. </title> <journal> Machine Learning, </journal> <volume> 3(2), </volume> <pages> 199-228, </pages> <year> 1987. </year> <note> 1987a Wilson, </note> <author> S. W. </author> <title> Hierarchical credit allocation in a classifier system. </title> <booktitle> Proceedings of the Tenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> 217-220, </pages> <year> 1987. 1987b. </year>
Reference: <author> Wilson, Stewart W. </author> <title> Bid competition and specificity reconsidered. </title> <journal> Journal of Complex Systems. </journal> <volume> 2(6), </volume> <pages> 705-723, </pages> <year> 1988. </year>
References-found: 26

