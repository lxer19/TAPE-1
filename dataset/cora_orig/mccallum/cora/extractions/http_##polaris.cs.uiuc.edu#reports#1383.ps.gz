URL: http://polaris.cs.uiuc.edu/reports/1383.ps.gz
Refering-URL: http://polaris.cs.uiuc.edu/polaris/rep2.html
Root-URL: http://www.cs.uiuc.edu
Title: The Privatizing DOALL Test: A Run-Time Technique for DOALL Loop Identification and Array Privatization yz  
Author: Lawrence Rauchwerger and David Padua 
Keyword: Index Terms Doall, Run-time, Parallel, Privatization, Speculative, Race Detection  
Address: 1308 W. Main St., Urbana, IL 61801  
Affiliation: Center for Supercomputing Research and Development University of Illinois at Urbana-Champaign  
Abstract: Current parallelizing compilers cannot extract a significant fraction of the available parallelism in a loop if it has a complex and/or statically insufficiently defined access pattern. This is an important issue because a large class of complex simulations used in industry today have irregular domains and/or dynamically changing interactions. To handle these types of problems methods capable of automatically extracting parallelism at run-time are needed. For this reason, we have developed the Privatizing DOALL test a technique for identifying fully parallel loops at run-time, and dynamically privatizing scalars and arrays. The test is fully parallel, requires no synchronization, is easily automatable, and can be applied to any loop, regardless of its access pattern. We show that the expected speedup for fully parallel loops is significant, and the cost of a failed test (a not fully parallel loop) is minimal. We present experimental results on loops from the PERFECT Benchmarks which confirm our conclusion that this test can lead to significant speedups. y Research supported in part by Army contract #DABT63-92-C-0033. This work is not necessarily representative of the positions or policies of the Army or the Government. z A preliminary version of this paper [26] was presented at the 8th ACM International Conference on Supercom puting, July 1994, Manchester, England. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Abraham. </author> <title> Private communication, </title> <year> 1994. </year>
Reference-contexts: In the second example, we use the subscript arrays W 0 [1 : 8] and R 0 [1 : 8], and the shadow arrays A 0 w [1 : 12] 1 any returns the "OR" of its vector operand's elements, i.e., any (v [1 : n]) = (v <ref> [1] </ref> _ v [2] _ : : : _ v [n]). 4 S1: DO i = 1, 8 S3: ... = A [R [i]] S4: ENDDO W [1:8] = [ 1 3 2 3 7 5 6 12] W'[1:8] = [ 1 3 2 4 7 5 6 12] Position in <p> Although the standard version of the PD test described in Section 4 does not determine if an element is written more than once in the loop, it can easily be augmented to provide this 2 This fact was noted by Santosh Abraham <ref> [1] </ref>. 10 information. The simplest approach is to use another shadow structure A p mw to flag the array elements which have been written multiple times.
Reference: [2] <author> T. Allen and D. A. Padua. </author> <title> Debugging fortran on a shared-memory machine. </title> <booktitle> In Proceedings of the 1987 International Conference on Parallel Processing, </booktitle> <pages> pages 721-727, </pages> <address> St. Charles, IL, </address> <year> 1987. </year>
Reference-contexts: The DOALL test allocates, and initializes to zero, the write and read shadow arrays, A w [1 : 12] and A r [1 : 12], respectively. After marking and counting, we obtain the results depicted in the table. Because A w <ref> [2] </ref> = A r [2] = 1, we know there exists at least one flow or anti dependence. Since the number marked does not equal the number written, we know that there are output dependences. Therefore, the loop cannot be executed in parallel. <p> The DOALL test allocates, and initializes to zero, the write and read shadow arrays, A w [1 : 12] and A r [1 : 12], respectively. After marking and counting, we obtain the results depicted in the table. Because A w <ref> [2] </ref> = A r [2] = 1, we know there exists at least one flow or anti dependence. Since the number marked does not equal the number written, we know that there are output dependences. Therefore, the loop cannot be executed in parallel. <p> the second example, we use the subscript arrays W 0 [1 : 8] and R 0 [1 : 8], and the shadow arrays A 0 w [1 : 12] 1 any returns the "OR" of its vector operand's elements, i.e., any (v [1 : n]) = (v [1] _ v <ref> [2] </ref> _ : : : _ v [n]). 4 S1: DO i = 1, 8 S3: ... = A [R [i]] S4: ENDDO W [1:8] = [ 1 3 2 3 7 5 6 12] W'[1:8] = [ 1 3 2 4 7 5 6 12] Position in shadow arrays Written <p> Generally, access anomaly detection techniques seek to identify the point in the parallel execution in which the access anomaly occurred. Padua et al. <ref> [2, 14] </ref> discuss methods that statically analyze the source program, and methods that analyze an execution trace of the program.
Reference: [3] <institution> Alliant Computer Systems Corporation, 42 Nagog Park, Acton, Massachusetts 01720. FX/Series Architecture Manual, </institution> <year> 1986. </year> <title> Part Number: </title> <publisher> 300-00001-B. </publisher>
Reference-contexts: not optimally parallelize the inspector (due to the synchronization barriers introduced for each processor), it will produce the same minimum depth schedule as the sequential inspector of Saltz et al. 11 Experimental Results In this section we present experimental results obtained on two modestly parallel machines with 8 (Alliant FX/80 <ref> [3] </ref>) and 14 processors (Alliant FX/2800 [4]) using a Cedar Fortran [15] implementation of the DOALL tests. We considered five loops contained in the PERFECT Benchmarks [6] that could not be parallelized by any compiler available to us. A summary of our results is given in Table 1.
Reference: [4] <institution> Alliant Computers Systems Corporation. Alliant FX/2800 Series System Description, </institution> <year> 1991. </year>
Reference-contexts: We can determine the positions of the privatized elements of A in P A from the prefix sums of A w [1 : 12], e.g., the private version of A [5] is contained in P A <ref> [4] </ref> since the prefix sum value of A w [5] = 4 (see Figure 4). In general, on each access to a shared array element A [k], it must be determined whether or not A [k] has been privatized, e.g., by checking A w [k]. <p> to the synchronization barriers introduced for each processor), it will produce the same minimum depth schedule as the sequential inspector of Saltz et al. 11 Experimental Results In this section we present experimental results obtained on two modestly parallel machines with 8 (Alliant FX/80 [3]) and 14 processors (Alliant FX/2800 <ref> [4] </ref>) using a Cedar Fortran [15] implementation of the DOALL tests. We considered five loops contained in the PERFECT Benchmarks [6] that could not be parallelized by any compiler available to us. A summary of our results is given in Table 1.
Reference: [5] <author> U. Banerjee. </author> <title> Dependence Analysis for Supercomputing. </title> <publisher> Kluwer. </publisher> <address> Boston, MA., </address> <year> 1988. </year>
Reference-contexts: In order to determine whether or not the execution order of the data accesses affects the semantics of the loop, the data dependence relations between the statements in the loop body must be analyzed <ref> [5, 17, 24, 35, 38] </ref>. There are three possible types of dependences between two statements that access the same memory location: flow (read after write), anti (write after read), and output (write after write). <p> We can determine the positions of the privatized elements of A in P A from the prefix sums of A w [1 : 12], e.g., the private version of A <ref> [5] </ref> is contained in P A [4] since the prefix sum value of A w [5] = 4 (see Figure 4). <p> We can determine the positions of the privatized elements of A in P A from the prefix sums of A w [1 : 12], e.g., the private version of A <ref> [5] </ref> is contained in P A [4] since the prefix sum value of A w [5] = 4 (see Figure 4). In general, on each access to a shared array element A [k], it must be determined whether or not A [k] has been privatized, e.g., by checking A w [k].
Reference: [6] <author> M. Berry, D. Chen, P. Koss, D. Kuck, S. Lo, Y. Pang, R. Roloff, A. Sameh, E. Clementi, S. Chin, D. Schneider, G. Fox, P. Messina, D. Walker, C. Hsiung, J. Schwarzmeier, K. Lue, S. Orzag, F. Seidl, O. Johnson, G. Swanson, R. Goodrum, and J. Martin. </author> <title> The PERFECT club benchmarks: Effective performance evaluation of supercomputers. </title> <type> Technical Report CSRD-827, </type> <institution> Center for Supercomputing Research and Development, University of Illinois, Urbana, IL, </institution> <month> May </month> <year> 1989. </year>
Reference-contexts: We considered five loops contained in the PERFECT Benchmarks <ref> [6] </ref> that could not be parallelized by any compiler available to us. A summary of our results is given in Table 1. For each loop, the methods applied and the speedup obtained are reported.
Reference: [7] <author> H. Berryman and J. Saltz. </author> <title> A manual for PARTI runtime primitives. </title> <type> Interim Report 90-13, </type> <institution> ICASE, </institution> <year> 1990. </year>
Reference-contexts: The boolean expression in the if statement typically tests the value of a scalar variable. During the last few years, new techniques have been developed for the run-time analysis and scheduling of loops with cross-iteration dependences <ref> [7, 11, 16, 19, 22, 25, 27, 28, 29, 36, 37] </ref>. The majority of this work has concentrated on developing run-time methods for constructing execution schedules for partially parallel loops, i.e., loops whose parallelization requires synchronization to ensure that the iterations are executed in the correct order. <p> This scheme relies heavily on synchronization, inserts an additional level of indirection into all memory accesses, and calls for dynamic shared memory allocation. The problem of analyzing and scheduling loops at run-time has been studied extensively by Saltz et al. <ref> [7, 27, 28, 29, 36] </ref>. In most of these methods, the original source loop is transformed into an inspector, which performs some run-time data dependence analysis and constructs a (preliminary) schedule, and an executor, which performs the scheduled work. The original source loop is assumed to have no output dependences.
Reference: [8] <author> W. Blume and R. Eigenmann. </author> <title> Performance Analysis of Parallelizing Compilers on the Perfect Benchmarks T M Programs. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 3(6) </volume> <pages> 643-656, </pages> <month> November </month> <year> 1992. </year>
Reference-contexts: Thus, since the available parallelism in theses types of applications cannot be determined statically by present parallelizing compilers <ref> [8, 10, 13] </ref>, it has become clear that compile-time analysis must be complemented by new methods capable of automatically extracting parallelism at run-time in order to realize the potential of parallel computing.
Reference: [9] <author> M. Burke, R. Cytron, J. Ferrante, and W. Hsieh. </author> <title> Automatic generation of nested, fork-join parallelism. </title> <journal> J. </journal> <volume> Supercomput., </volume> <pages> pages 71-88, </pages> <year> 1989. </year>
Reference-contexts: In order to remove certain types of anti and output dependences a transformation called privatization can be applied to the loop. Privatization creates, for each processor cooperating on the execution of the loop, private copies of program variables that give rise to anti or output dependences (see, e.g., <ref> [24, 9, 20, 21, 33, 34] </ref>).
Reference: [10] <author> W. J. Camp, S. J. Plimpton, B. A. Hendrickson, and R. W. Leland. </author> <title> Massively parallel methods for engineering and science problems. </title> <journal> Comm. ACM, </journal> <volume> 37(4) </volume> <pages> 31-41, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: For example, SPICE for circuit simulation, DYNA-3D and PRONTO-3D for structural mechanics modeling, GAUSSIAN and DMOL for quantum mechanical simulation of molecules, CHARMM and DISCOVER for molecular dynamics simulation of organic systems, and FIDAP for modeling complex fluid flows <ref> [10] </ref>. <p> Thus, since the available parallelism in theses types of applications cannot be determined statically by present parallelizing compilers <ref> [8, 10, 13] </ref>, it has become clear that compile-time analysis must be complemented by new methods capable of automatically extracting parallelism at run-time in order to realize the potential of parallel computing.
Reference: [11] <author> D. K. Chen, P. C. Yew, and J. Torrellas. </author> <title> An efficient algorithm for the run-time parallelization of doacross loops. </title> <type> manuscript, </type> <year> 1994. </year>
Reference-contexts: The boolean expression in the if statement typically tests the value of a scalar variable. During the last few years, new techniques have been developed for the run-time analysis and scheduling of loops with cross-iteration dependences <ref> [7, 11, 16, 19, 22, 25, 27, 28, 29, 36, 37] </ref>. The majority of this work has concentrated on developing run-time methods for constructing execution schedules for partially parallel loops, i.e., loops whose parallelization requires synchronization to ensure that the iterations are executed in the correct order. <p> By using separate shadow variables to process the read and write operations, Midkiff and Padua [22] improved this basic method so that concurrent reads from a memory location are allowed in multiple iterations. Recently, Chen, Yew and Torrellas <ref> [11] </ref> proposed another variant of the Zhu and Yew method which improves performance in the presence of hot-spots (i.e., many accesses to the same memory location) by first doing some of the computation in private storage.
Reference: [12] <author> A. Dinning and E. Schonberg. </author> <title> An empirical comparison of monitoring algorithms for access anomaly detection. </title> <booktitle> In Proc. </booktitle> <pages> ACM ???, pages 1-10, </pages> <year> 1990. </year>
Reference-contexts: The techniques presented are also capable of eliminating some memory-related dependences by dynamically privatizing scalars and arrays. Our methods are fully parallel, require no synchronization, and can be applied to any loop. Our methods can also be used for detecting access anomalies <ref> [30, 12] </ref> or race conditions [14] in parallel programs, i.e., when the same memory location is accessed by more than one concurrent thread without synchronization, and it is written in at least one of the threads. <p> Since not all anomalies can be detected statically, and execution traces can require prohibitive amounts of memory, run-time access anomaly detection methods that minimize memory requirements are desirable <ref> [30, 12, 23] </ref>. In fact, a run-time anomaly detection method proposed by Snir, and optimized by Schonberg [30], bears similarities to the version of the DOALL test presented in Section 3 (i.e., the version without the privatization).
Reference: [13] <author> R. Eigenmann, J. Hoeflinger, Z. Li, and D. Padua. </author> <title> Experience in the Automatic Parallelization of Four Perfect-Benchmark Programs. </title> <booktitle> Lecture Notes in Computer Science 589. Proceedings of the Fourth Workshop on Languages and Compilers for Parallel Computing, </booktitle> <address> Santa Clara, CA, </address> <pages> pages 65-83, </pages> <month> August </month> <year> 1991. </year>
Reference-contexts: Thus, since the available parallelism in theses types of applications cannot be determined statically by present parallelizing compilers <ref> [8, 10, 13] </ref>, it has become clear that compile-time analysis must be complemented by new methods capable of automatically extracting parallelism at run-time in order to realize the potential of parallel computing.
Reference: [14] <author> P. A. Emrath, S. Ghosh, and D. A. Padua. </author> <title> Detecting nondeterminacy in parallel programs. </title> <journal> IEEE Soft., </journal> <pages> pages 69-77, </pages> <month> January </month> <year> 1992. </year>
Reference-contexts: The techniques presented are also capable of eliminating some memory-related dependences by dynamically privatizing scalars and arrays. Our methods are fully parallel, require no synchronization, and can be applied to any loop. Our methods can also be used for detecting access anomalies [30, 12] or race conditions <ref> [14] </ref> in parallel programs, i.e., when the same memory location is accessed by more than one concurrent thread without synchronization, and it is written in at least one of the threads. <p> Generally, access anomaly detection techniques seek to identify the point in the parallel execution in which the access anomaly occurred. Padua et al. <ref> [2, 14] </ref> discuss methods that statically analyze the source program, and methods that analyze an execution trace of the program.
Reference: [15] <author> M. Guzzi, D. Padua, J. Hoeflinger, and D. Lawrie. </author> <title> Cedar fortran and other vector and parallel fortran dialects. </title> <journal> J. Supercomput., </journal> <volume> 4(1) </volume> <pages> 37-62, </pages> <month> March </month> <year> 1990. </year> <month> 21 </month>
Reference-contexts: for each processor), it will produce the same minimum depth schedule as the sequential inspector of Saltz et al. 11 Experimental Results In this section we present experimental results obtained on two modestly parallel machines with 8 (Alliant FX/80 [3]) and 14 processors (Alliant FX/2800 [4]) using a Cedar Fortran <ref> [15] </ref> implementation of the DOALL tests. We considered five loops contained in the PERFECT Benchmarks [6] that could not be parallelized by any compiler available to us. A summary of our results is given in Table 1. For each loop, the methods applied and the speedup obtained are reported.
Reference: [16] <author> V. Krothapalli and P. Sadayappan. </author> <title> An approach to synchronization of parallel computing. </title> <booktitle> In Proceedings of the 1988 International Conference on Supercomputing, </booktitle> <pages> pages 573-581, </pages> <month> June </month> <year> 1988. </year>
Reference-contexts: The boolean expression in the if statement typically tests the value of a scalar variable. During the last few years, new techniques have been developed for the run-time analysis and scheduling of loops with cross-iteration dependences <ref> [7, 11, 16, 19, 22, 25, 27, 28, 29, 36, 37] </ref>. The majority of this work has concentrated on developing run-time methods for constructing execution schedules for partially parallel loops, i.e., loops whose parallelization requires synchronization to ensure that the iterations are executed in the correct order. <p> The wavefronts can be constructed sequentially by inspecting all the shared variable accesses, or in parallel with the aid of critical sections. Note that since all computations are performed at run-time, it is important for them to be efficiently parallelizable. Krothapalli and Sadayappan <ref> [16] </ref> proposed a run-time scheme for removing anti (write-after-read) and output (write-after-write) dependences from loops.
Reference: [17] <author> D. J. Kuck, R. H. Kuhn, D. A. Padua, B. Leasure, and M. Wolfe. </author> <title> Dependence graphs and compiler optimizations. </title> <booktitle> In Proceedings of the 8th Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 207-218, </pages> <month> January </month> <year> 1981. </year>
Reference-contexts: In order to determine whether or not the execution order of the data accesses affects the semantics of the loop, the data dependence relations between the statements in the loop body must be analyzed <ref> [5, 17, 24, 35, 38] </ref>. There are three possible types of dependences between two statements that access the same memory location: flow (read after write), anti (write after read), and output (write after write).
Reference: [18] <author> F. T. Leighton. </author> <title> Introduction to Parallel Algorithms and Architectures: Arrays, Trees, Hypercubes. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1992. </year>
Reference-contexts: The counting in Step 2 (a) can be done in parallel by giving each processor s=p values to add within its private memory, and then summing the p resulting values in global storage, which takes O (s=p + log p) time <ref> [18] </ref>. The comparisons in Step 2 (b) (2 (d)) of the A w and A r (A np ) shadow arrays take O (s=p + log p) time. Again, if s na, then the complexity can be reduced to O (na=p + log p) by using hash tables. <p> Since A w and tm (A) are computed during the test itself, the only additional information needed is the prefix sums, which can be computed in time O (s=p+log p) by recursive doubling <ref> [18] </ref>. In fact, the prefix sums can be computed at the same time that tm (A) is accumulated without much extra work. A similar computation can be performed on the array A mw if only the elements that are written more than once are privatized (as discussed in Section 6.2).
Reference: [19] <author> S. Leung and J. Zahorjan. </author> <title> Improving the performance of runtime parallelization. </title> <booktitle> In 4th PPOPP, </booktitle> <pages> pages 83-91, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: More powerful analysis techniques could remove this last limitation when the index arrays are computed using only statically-known values. However, nothing can be done at compile-time when the index arrays are a function of the input data <ref> [19, 29, 37] </ref>. Run-time techniques have been used practically from the beginning of parallel computing. During the 1960s, relatively simple run-time techniques, used to detect parallelism between scalar operations, were implemented in the hardware of the CDC 6600 and the IBM 360/91 [31, 32]. <p> The boolean expression in the if statement typically tests the value of a scalar variable. During the last few years, new techniques have been developed for the run-time analysis and scheduling of loops with cross-iteration dependences <ref> [7, 11, 16, 19, 22, 25, 27, 28, 29, 36, 37] </ref>. The majority of this work has concentrated on developing run-time methods for constructing execution schedules for partially parallel loops, i.e., loops whose parallelization requires synchronization to ensure that the iterations are executed in the correct order. <p> Recently, Leung and Zahorjan <ref> [19] </ref> have proposed some other methods of parallelizing the inspector of Saltz et al. These techniques are also restricted to loops with no output dependences.
Reference: [20] <author> Z. Li. </author> <title> Array privatization for parallel execution of loops. </title> <booktitle> In Proceedings of the 19th International Symposium on Computer Architecture, </booktitle> <pages> pages 313-322, </pages> <year> 1992. </year>
Reference-contexts: In order to remove certain types of anti and output dependences a transformation called privatization can be applied to the loop. Privatization creates, for each processor cooperating on the execution of the loop, private copies of program variables that give rise to anti or output dependences (see, e.g., <ref> [24, 9, 20, 21, 33, 34] </ref>). <p> If only the elements that are written are privatized, it is possible that this technique might yield performance gains over privatizing the whole array (which is the traditional compile time privatization technique <ref> [20, 21, 33, 34] </ref>) for two reasons: First it may save work in the last value assignment step and second, if the data access pattern is sparse enough, the reduction in the size of the working set could improve the cache performance perhaps to the point of superlinear speedups.
Reference: [21] <author> D. E. Maydan, S. P. Amarasinghe, and M. S. Lam. </author> <title> Data dependence and data-flow analysis of arrays. </title> <booktitle> In Proceedings 5th Annual Workshop on Programming Languages and Compilers for Parallel Computing, </booktitle> <month> August </month> <year> 1992. </year>
Reference-contexts: In order to remove certain types of anti and output dependences a transformation called privatization can be applied to the loop. Privatization creates, for each processor cooperating on the execution of the loop, private copies of program variables that give rise to anti or output dependences (see, e.g., <ref> [24, 9, 20, 21, 33, 34] </ref>). <p> If only the elements that are written are privatized, it is possible that this technique might yield performance gains over privatizing the whole array (which is the traditional compile time privatization technique <ref> [20, 21, 33, 34] </ref>) for two reasons: First it may save work in the last value assignment step and second, if the data access pattern is sparse enough, the reduction in the size of the working set could improve the cache performance perhaps to the point of superlinear speedups.
Reference: [22] <author> S. Midkiff and D. Padua. </author> <title> Compiler algorithms for synchronization. </title> <journal> IEEE Trans. Comput., </journal> <volume> C-36(12):1485-1495, </volume> <year> 1987. </year>
Reference-contexts: The boolean expression in the if statement typically tests the value of a scalar variable. During the last few years, new techniques have been developed for the run-time analysis and scheduling of loops with cross-iteration dependences <ref> [7, 11, 16, 19, 22, 25, 27, 28, 29, 36, 37] </ref>. The majority of this work has concentrated on developing run-time methods for constructing execution schedules for partially parallel loops, i.e., loops whose parallelization requires synchronization to ensure that the iterations are executed in the correct order. <p> In each phase, the lowest unassigned iteration to access any variable (e.g., array element) is found using atomic compare-and-swap synchronization primitives to record the minimum such iteration in a shadow version of that variable. By using separate shadow variables to process the read and write operations, Midkiff and Padua <ref> [22] </ref> improved this basic method so that concurrent reads from a memory location are allowed in multiple iterations.
Reference: [23] <author> I. Nudler and L. Rudolph. </author> <title> Tools for the efficient developement of efficient parallel programs. </title> <booktitle> In Proc. 1st Israeli Conference on Computer System Engineering, </booktitle> <year> 1988. </year>
Reference-contexts: Since not all anomalies can be detected statically, and execution traces can require prohibitive amounts of memory, run-time access anomaly detection methods that minimize memory requirements are desirable <ref> [30, 12, 23] </ref>. In fact, a run-time anomaly detection method proposed by Snir, and optimized by Schonberg [30], bears similarities to the version of the DOALL test presented in Section 3 (i.e., the version without the privatization).
Reference: [24] <author> D. A. Padua and M. J. Wolfe. </author> <title> Advanced compiler optimizations for supercomputers. </title> <journal> Comm. ACM, </journal> <volume> 29 </volume> <pages> 1184-1201, </pages> <month> December </month> <year> 1986. </year>
Reference-contexts: Restructuring, or parallelizing, compilers address these problems by detecting and exploiting parallelism in sequential programs written in conventional languages. Although compiler techniques for the automatic detection of parallelism have been studied extensively over the last two decades <ref> [24, 35] </ref>, current parallelizing compilers cannot extract a significant fraction of the available parallelism in a loop if it has a complex and/or statically insufficiently defined access pattern. <p> In order to determine whether or not the execution order of the data accesses affects the semantics of the loop, the data dependence relations between the statements in the loop body must be analyzed <ref> [5, 17, 24, 35, 38] </ref>. There are three possible types of dependences between two statements that access the same memory location: flow (read after write), anti (write after read), and output (write after write). <p> In order to remove certain types of anti and output dependences a transformation called privatization can be applied to the loop. Privatization creates, for each processor cooperating on the execution of the loop, private copies of program variables that give rise to anti or output dependences (see, e.g., <ref> [24, 9, 20, 21, 33, 34] </ref>).
Reference: [25] <author> C. Polychronopoulos. </author> <title> Compiler Optimizations for Enhancing Parallelism and Their Imp act on Architecture Design. </title> <journal> IEEE Trans. Comput., </journal> <volume> C-37(8):991-1004, </volume> <month> August </month> <year> 1988. </year>
Reference-contexts: The boolean expression in the if statement typically tests the value of a scalar variable. During the last few years, new techniques have been developed for the run-time analysis and scheduling of loops with cross-iteration dependences <ref> [7, 11, 16, 19, 22, 25, 27, 28, 29, 36, 37] </ref>. The majority of this work has concentrated on developing run-time methods for constructing execution schedules for partially parallel loops, i.e., loops whose parallelization requires synchronization to ensure that the iterations are executed in the correct order. <p> All of the above mentioned methods construct maximal stages in the sense that each iteration is placed in the earliest possible stage, giving a minimal depth schedule, i.e., a minimal number of stages. Polychronopolous <ref> [25] </ref> gives a method that assigns iterations to stages in a different way: each wavefront consists of a maximal set of contiguous iterations which contain no cross-iteration dependences. It is easy to see that this method may not yield a minimum depth schedule.
Reference: [26] <author> L. Rauchwerger and D. Padua. </author> <title> The privatizing doall test: A run-time technique for doall loop identification and array privatization. </title> <booktitle> In Proceedings of the 1994 International Conference on Supercomputing, </booktitle> <month> pages -, July </month> <year> 1994. </year>
Reference: [27] <author> J. Saltz and R. Mirchandaney. </author> <title> The preprocessed doacross loop. In Dr. </title> <editor> H.D. Schwetman, editor, </editor> <booktitle> Proceedings of the 1991 International Conference on Parallel Processing, </booktitle> <pages> pages 174-178. </pages> <publisher> CRC Press, Inc., </publisher> <year> 1991. </year> <title> Vol. </title> <booktitle> II Software. </booktitle>
Reference-contexts: The boolean expression in the if statement typically tests the value of a scalar variable. During the last few years, new techniques have been developed for the run-time analysis and scheduling of loops with cross-iteration dependences <ref> [7, 11, 16, 19, 22, 25, 27, 28, 29, 36, 37] </ref>. The majority of this work has concentrated on developing run-time methods for constructing execution schedules for partially parallel loops, i.e., loops whose parallelization requires synchronization to ensure that the iterations are executed in the correct order. <p> This scheme relies heavily on synchronization, inserts an additional level of indirection into all memory accesses, and calls for dynamic shared memory allocation. The problem of analyzing and scheduling loops at run-time has been studied extensively by Saltz et al. <ref> [7, 27, 28, 29, 36] </ref>. In most of these methods, the original source loop is transformed into an inspector, which performs some run-time data dependence analysis and constructs a (preliminary) schedule, and an executor, which performs the scheduled work. The original source loop is assumed to have no output dependences. <p> The inspector computation (the topological sort) can be parallelized somewhat using the DOACROSS parallelization technique of Saltz and Mirchandaney <ref> [27] </ref>, in which processors are assigned iterations in a wrapped manner, and busy-waits are used to ensure that values have been produced before they are used (again, this is only possible if the original loop has no output dependences).
Reference: [28] <author> J. Saltz, R. Mirchandaney, and K. Crowley. </author> <title> The doconsider loop. </title> <booktitle> In Proceedings of the 1989 International Conference on Supercomputing, </booktitle> <pages> pages 29-40, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: The boolean expression in the if statement typically tests the value of a scalar variable. During the last few years, new techniques have been developed for the run-time analysis and scheduling of loops with cross-iteration dependences <ref> [7, 11, 16, 19, 22, 25, 27, 28, 29, 36, 37] </ref>. The majority of this work has concentrated on developing run-time methods for constructing execution schedules for partially parallel loops, i.e., loops whose parallelization requires synchronization to ensure that the iterations are executed in the correct order. <p> This scheme relies heavily on synchronization, inserts an additional level of indirection into all memory accesses, and calls for dynamic shared memory allocation. The problem of analyzing and scheduling loops at run-time has been studied extensively by Saltz et al. <ref> [7, 27, 28, 29, 36] </ref>. In most of these methods, the original source loop is transformed into an inspector, which performs some run-time data dependence analysis and constructs a (preliminary) schedule, and an executor, which performs the scheduled work. The original source loop is assumed to have no output dependences.
Reference: [29] <author> J. Saltz, R. Mirchandaney, and K. Crowley. </author> <title> Run-time parallelization and scheduling of loops. </title> <journal> IEEE Trans. Comput., </journal> <volume> 40(5), </volume> <month> May </month> <year> 1991. </year>
Reference-contexts: More powerful analysis techniques could remove this last limitation when the index arrays are computed using only statically-known values. However, nothing can be done at compile-time when the index arrays are a function of the input data <ref> [19, 29, 37] </ref>. Run-time techniques have been used practically from the beginning of parallel computing. During the 1960s, relatively simple run-time techniques, used to detect parallelism between scalar operations, were implemented in the hardware of the CDC 6600 and the IBM 360/91 [31, 32]. <p> The boolean expression in the if statement typically tests the value of a scalar variable. During the last few years, new techniques have been developed for the run-time analysis and scheduling of loops with cross-iteration dependences <ref> [7, 11, 16, 19, 22, 25, 27, 28, 29, 36, 37] </ref>. The majority of this work has concentrated on developing run-time methods for constructing execution schedules for partially parallel loops, i.e., loops whose parallelization requires synchronization to ensure that the iterations are executed in the correct order. <p> This is a simple illustration of the schedule reuse technique, in which a correct execution schedule is determined once, and subsequently reused if all of the defining conditions remain invariant (see, e.g., Saltz et al. <ref> [29] </ref>). If it can be determined at compile time that the data access pattern is invariant across different executions of the same loop, then no additional computation is required. <p> This scheme relies heavily on synchronization, inserts an additional level of indirection into all memory accesses, and calls for dynamic shared memory allocation. The problem of analyzing and scheduling loops at run-time has been studied extensively by Saltz et al. <ref> [7, 27, 28, 29, 36] </ref>. In most of these methods, the original source loop is transformed into an inspector, which performs some run-time data dependence analysis and constructs a (preliminary) schedule, and an executor, which performs the scheduled work. The original source loop is assumed to have no output dependences. <p> In most of these methods, the original source loop is transformed into an inspector, which performs some run-time data dependence analysis and constructs a (preliminary) schedule, and an executor, which performs the scheduled work. The original source loop is assumed to have no output dependences. In <ref> [29] </ref>, the inspector constructs stages that respect the flow dependences by performing a sequential topological sort of the accesses in the loop. The executer enforces any anti dependences by using old and new versions of each variable.
Reference: [30] <author> E. Schonberg. </author> <title> On-the-fly detection of access anomalies. </title> <booktitle> In Proceedings of the SIGPLAN 1989 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 285-297, </pages> <address> Portland, Oregon, </address> <year> 1989. </year>
Reference-contexts: The techniques presented are also capable of eliminating some memory-related dependences by dynamically privatizing scalars and arrays. Our methods are fully parallel, require no synchronization, and can be applied to any loop. Our methods can also be used for detecting access anomalies <ref> [30, 12] </ref> or race conditions [14] in parallel programs, i.e., when the same memory location is accessed by more than one concurrent thread without synchronization, and it is written in at least one of the threads. <p> In fact, our methods are more closely related to some of the techniques for detecting access anomalies <ref> [30] </ref>, than they are to the previous work mentioned above for finding valid execution schedules for a partially parallel loops. After presenting our methods, we discuss their relationship to the work done on detecting access anomalies in Section 8. We discuss our analysis techniques in Sections 2-7. <p> Since not all anomalies can be detected statically, and execution traces can require prohibitive amounts of memory, run-time access anomaly detection methods that minimize memory requirements are desirable <ref> [30, 12, 23] </ref>. In fact, a run-time anomaly detection method proposed by Snir, and optimized by Schonberg [30], bears similarities to the version of the DOALL test presented in Section 3 (i.e., the version without the privatization). <p> Since not all anomalies can be detected statically, and execution traces can require prohibitive amounts of memory, run-time access anomaly detection methods that minimize memory requirements are desirable [30, 12, 23]. In fact, a run-time anomaly detection method proposed by Snir, and optimized by Schonberg <ref> [30] </ref>, bears similarities to the version of the DOALL test presented in Section 3 (i.e., the version without the privatization). However, in order to identify the point in the execution 13 in which the anomaly occurred, their methods [30] require much more memory than the DOALL test, e.g., viewed in the <p> a run-time anomaly detection method proposed by Snir, and optimized by Schonberg <ref> [30] </ref>, bears similarities to the version of the DOALL test presented in Section 3 (i.e., the version without the privatization). However, in order to identify the point in the execution 13 in which the anomaly occurred, their methods [30] require much more memory than the DOALL test, e.g., viewed in the framework of the DOALL test, a separate shadow array for each iteration in a loop must be maintained.
Reference: [31] <author> J. E. Thornton. </author> <title> Design of a Computer:The Control Data 6600. </title> <type> Scott, </type> <institution> Foresman, Glenview, Illinois, </institution> <year> 1971. </year>
Reference-contexts: Run-time techniques have been used practically from the beginning of parallel computing. During the 1960s, relatively simple run-time techniques, used to detect parallelism between scalar operations, were implemented in the hardware of the CDC 6600 and the IBM 360/91 <ref> [31, 32] </ref>. Some of today's parallelizing compilers postpone part of the analysis to run-time by generating two-version loops. These consist of an if statement that selects either the original serial loop or its parallel version. The boolean expression in the if statement typically tests the value of a scalar variable.
Reference: [32] <author> R. M. Tomasulo. </author> <title> An efficient algorithm for exploiting multiple arithmetic units. </title> <journal> IBM Journal of Research and Development, </journal> <volume> 11 </volume> <pages> 25-33, </pages> <month> January </month> <year> 1967. </year>
Reference-contexts: Run-time techniques have been used practically from the beginning of parallel computing. During the 1960s, relatively simple run-time techniques, used to detect parallelism between scalar operations, were implemented in the hardware of the CDC 6600 and the IBM 360/91 <ref> [31, 32] </ref>. Some of today's parallelizing compilers postpone part of the analysis to run-time by generating two-version loops. These consist of an if statement that selects either the original serial loop or its parallel version. The boolean expression in the if statement typically tests the value of a scalar variable.
Reference: [33] <author> P. Tu and D. Padua. </author> <title> Array privatization for shared and distributed memory machines. </title> <booktitle> In Proceedings 2nd Workshop on Languages, Compilers, and Run-Time Environments for Distributed Memory Machines, </booktitle> <month> September </month> <year> 1992. </year>
Reference-contexts: In order to remove certain types of anti and output dependences a transformation called privatization can be applied to the loop. Privatization creates, for each processor cooperating on the execution of the loop, private copies of program variables that give rise to anti or output dependences (see, e.g., <ref> [24, 9, 20, 21, 33, 34] </ref>). <p> If only the elements that are written are privatized, it is possible that this technique might yield performance gains over privatizing the whole array (which is the traditional compile time privatization technique <ref> [20, 21, 33, 34] </ref>) for two reasons: First it may save work in the last value assignment step and second, if the data access pattern is sparse enough, the reduction in the size of the working set could improve the cache performance perhaps to the point of superlinear speedups.
Reference: [34] <author> P. Tu and D. Padua. </author> <title> Automatic array privatization. </title> <booktitle> In Proceedings 6th Annual Workshop on Programming Languages and Compilers for Parallel Computing, </booktitle> <address> Portland, OR, </address> <month> August </month> <year> 1993. </year>
Reference-contexts: In order to remove certain types of anti and output dependences a transformation called privatization can be applied to the loop. Privatization creates, for each processor cooperating on the execution of the loop, private copies of program variables that give rise to anti or output dependences (see, e.g., <ref> [24, 9, 20, 21, 33, 34] </ref>). <p> If only the elements that are written are privatized, it is possible that this technique might yield performance gains over privatizing the whole array (which is the traditional compile time privatization technique <ref> [20, 21, 33, 34] </ref>) for two reasons: First it may save work in the last value assignment step and second, if the data access pattern is sparse enough, the reduction in the size of the working set could improve the cache performance perhaps to the point of superlinear speedups.
Reference: [35] <author> M. Wolfe. </author> <title> Optimizing Compilers for Supercomputers. </title> <publisher> The MIT Press, </publisher> <address> Boston, MA, </address> <year> 1989. </year> <month> 22 </month>
Reference-contexts: Restructuring, or parallelizing, compilers address these problems by detecting and exploiting parallelism in sequential programs written in conventional languages. Although compiler techniques for the automatic detection of parallelism have been studied extensively over the last two decades <ref> [24, 35] </ref>, current parallelizing compilers cannot extract a significant fraction of the available parallelism in a loop if it has a complex and/or statically insufficiently defined access pattern. <p> In order to determine whether or not the execution order of the data accesses affects the semantics of the loop, the data dependence relations between the statements in the loop body must be analyzed <ref> [5, 17, 24, 35, 38] </ref>. There are three possible types of dependences between two statements that access the same memory location: flow (read after write), anti (write after read), and output (write after write).
Reference: [36] <author> J. Wu, J. Saltz, S. Hiranandani, and H. Berryman. </author> <title> Runtime compilation methods for multicomputers. In Dr. </title> <editor> H.D. Schwetman, editor, </editor> <booktitle> Proceedings of the 1991 International Conference on Parallel Processing, </booktitle> <pages> pages 26-30. </pages> <publisher> CRC Press, Inc., </publisher> <year> 1991. </year> <title> Vol. </title> <booktitle> II Software. </booktitle>
Reference-contexts: The boolean expression in the if statement typically tests the value of a scalar variable. During the last few years, new techniques have been developed for the run-time analysis and scheduling of loops with cross-iteration dependences <ref> [7, 11, 16, 19, 22, 25, 27, 28, 29, 36, 37] </ref>. The majority of this work has concentrated on developing run-time methods for constructing execution schedules for partially parallel loops, i.e., loops whose parallelization requires synchronization to ensure that the iterations are executed in the correct order. <p> This scheme relies heavily on synchronization, inserts an additional level of indirection into all memory accesses, and calls for dynamic shared memory allocation. The problem of analyzing and scheduling loops at run-time has been studied extensively by Saltz et al. <ref> [7, 27, 28, 29, 36] </ref>. In most of these methods, the original source loop is transformed into an inspector, which performs some run-time data dependence analysis and constructs a (preliminary) schedule, and an executor, which performs the scheduled work. The original source loop is assumed to have no output dependences.
Reference: [37] <author> C. Zhu and P. C. Yew. </author> <title> A scheme to enforce data dependence on large multiprocessor systems. </title> <journal> IEEE Trans. Softw. Eng., </journal> <volume> 13(6) </volume> <pages> 726-739, </pages> <month> June </month> <year> 1987. </year>
Reference-contexts: More powerful analysis techniques could remove this last limitation when the index arrays are computed using only statically-known values. However, nothing can be done at compile-time when the index arrays are a function of the input data <ref> [19, 29, 37] </ref>. Run-time techniques have been used practically from the beginning of parallel computing. During the 1960s, relatively simple run-time techniques, used to detect parallelism between scalar operations, were implemented in the hardware of the CDC 6600 and the IBM 360/91 [31, 32]. <p> The boolean expression in the if statement typically tests the value of a scalar variable. During the last few years, new techniques have been developed for the run-time analysis and scheduling of loops with cross-iteration dependences <ref> [7, 11, 16, 19, 22, 25, 27, 28, 29, 36, 37] </ref>. The majority of this work has concentrated on developing run-time methods for constructing execution schedules for partially parallel loops, i.e., loops whose parallelization requires synchronization to ensure that the iterations are executed in the correct order. <p> Stages formed by a regular pattern of iterations are named a wavefronts. The wavefronts themselves are executed sequentially by placing a synchronization barrier between each wavefront. One of the first run-time methods for scheduling partially parallel loops was proposed by Zhu and Yew <ref> [37] </ref>. It computes the stages one after the other in successive phases.
Reference: [38] <author> H. Zima. </author> <title> Supercompilers for Parallel and Vector Computers. </title> <publisher> ACM Press, </publisher> <address> New York, New York, </address> <year> 1991. </year> <pages> 23 24 25 </pages>
Reference-contexts: In order to determine whether or not the execution order of the data accesses affects the semantics of the loop, the data dependence relations between the statements in the loop body must be analyzed <ref> [5, 17, 24, 35, 38] </ref>. There are three possible types of dependences between two statements that access the same memory location: flow (read after write), anti (write after read), and output (write after write).
References-found: 38

