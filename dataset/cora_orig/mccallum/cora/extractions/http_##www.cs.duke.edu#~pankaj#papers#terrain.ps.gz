URL: http://www.cs.duke.edu/~pankaj/papers/terrain.ps.gz
Refering-URL: http://www.cs.duke.edu/~pkd/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: An Efficient Algorithm for Terrain Simplification  
Author: Pankaj K. Agarwal Pavan K. Desikan 
Abstract: Given a set S of n points in &lt; 3 , sampled from an unknown bivariate function f (x; y) (i.e., for each point p 2 S, z p = f (x p ; y p )), a piecewise-linear function g(x; y) is called an "-approximation of f (x; y) if for every p 2 S, jf (x; y) g(x; y)j ". The problem of computing an "-approximation with the minimum number of vertices is NP-Hard. We present a randomized algorithm that computes an "-approximation of size O(c 2 log 2 c) in O(n 2+ffi + c 3 log 2 c log n c ) expected time, where c is the size of the "-approximation with the minimum number of vertices and ffi is any arbitrarily small positive number. Under some reasonable assumptions, the size of the output is close to O(c log c) and the expected running time is O(n 2+ffi ). We have implemented a variant of this algorithm and include some empirical results. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P. K. Agarwal, </author> <title> Geometric partitioning and its applications, </title> <booktitle> DIMACS Series in Discrete Mathematics and Theoretical Computer Science (J. </booktitle> <editor> Good-man et al, eds), </editor> <volume> vol. 6, </volume> <year> 1991, </year> <pages> 1-37. </pages>
Reference: [2] <author> P. K. Agarwal and M. Sharir, </author> <title> Applications of a new space-partitioning technique, </title> <journal> Discrete and Comput. Geom., </journal> <volume> 9 (1993), </volume> <pages> 11-38. </pages>
Reference: [3] <author> P. K. Agarwal and S. Suri, </author> <title> Surface approximations and geometric partitions, </title> <booktitle> Proc. 5th Symp. on Discrete Algorithms 1994, </booktitle> <pages> 24-33. </pages> <note> (Also to appear in SIAM J. Comput.) </note>
Reference-contexts: Agar-wal and Suri give a polynomial-time algorithm that computes an "-approximation of S of size O (c log c), where c is the size of an optimal "-approximation <ref> [3] </ref>. But the running time of their algorithm is O (n 8 ). This raises the question whether there is a simpler and faster algorithm for computing a small size "- approximation of S. <p> As we will see below, the algorithm produces an "-approximation of size roughly O (c log c) in time O (n 2+ffi ), for some cases. We will be combining the ideas from the algorithms of Agarwal and Suri <ref> [3] </ref> and Clarkson [7] along with some new ideas to obtain the faster algorithm. As in [5, 7] we will formulate the problem as a two-dimensional hitting set problem and use a variant of Clarkson's randomized algorithm to compute a small hitting set. <p> The size of a simplicial partition is the number of disjoint triangles in the partition. The following simple observation is by Agarwal and Suri <ref> [3] </ref>. <p> Since may not cover the entire xy-plane, stitch together 1 ; 2 ; : : : ; c by adding O (c) new triangles as described in <ref> [3] </ref>. 2 We have thus reduced the terrain-approximation problem to computing a simplicial partition, which we formulate as a hitting-set problem for a certain set system.
Reference: [4] <author> J. Bloomenthal, </author> <title> Polygonalization of implicit surface, </title> <booktitle> Computer Aided Design, 5 (1988), </booktitle> <pages> 341-355. </pages>
Reference-contexts: Although there has been a lot of work on surface simplification in computer graphics, GIS, and scientific computing, most of the work is based on heuristic approaches <ref> [4, 11, 18, 19, 21, 25, 28, 29, 35, 39] </ref>. It is therefore not surprising that these algorithms do not guarantee any bounds on the quality of the simplification. In this paper, we study the surface-approximation problem for xy-monotone surfaces (i.e., for terrains).
Reference: [5] <author> H. Bronnimann and M. T. Goodrich, </author> <title> Almost optimal set covers in finite VC-dimension, </title> <journal> Discrete and Comput. Geom., </journal> <volume> 15 (1995), </volume> <pages> 463-479. </pages>
Reference-contexts: These bounds were subsequently improved by Clarkson [7] and Bronnimann and Goodrich <ref> [5] </ref>; the latter gave an algorithm, with O (nc (c + log n) log (n=c)) running time, to compute a polytope Q with O (c) vertices. It is an open question whether an approximate convex polytope with the minimum number of vertices can be computed in polynomial time. <p> We will be combining the ideas from the algorithms of Agarwal and Suri [3] and Clarkson [7] along with some new ideas to obtain the faster algorithm. As in <ref> [5, 7] </ref> we will formulate the problem as a two-dimensional hitting set problem and use a variant of Clarkson's randomized algorithm to compute a small hitting set. In order to expedite the running time, we do not construct the underlying set system explicitly. <p> We construct the hitting set using the algorithm by Clarkson [7] for polytope approximation, which was later generalized by Bronnimann and Goodrich <ref> [5] </ref> for computing set covers (or hitting sets) of set systems with a finite VC-dimension. Assume that the size of the smallest hitting set, denoted by c, is known.
Reference: [6] <author> K. L. Clarkson, </author> <title> New applications of random sampling in computational geometry, </title> <journal> Discrete and Comput. Geom., </journal> <volume> 2 (1987), </volume> <pages> 195-222. </pages>
Reference: [7] <author> K. L. Clarkson, </author> <title> Algorithms for polytope covering and approximation, </title> <booktitle> Proc. 3rd Workshop on Algorithms and Data Structures, Lecture Notes in Computer Science, </booktitle> <volume> vol. 709, </volume> <publisher> Springer Verlag, </publisher> <address> Berlin, </address> <year> 1993, </year> <pages> 246-252. </pages>
Reference-contexts: These bounds were subsequently improved by Clarkson <ref> [7] </ref> and Bronnimann and Goodrich [5]; the latter gave an algorithm, with O (nc (c + log n) log (n=c)) running time, to compute a polytope Q with O (c) vertices. <p> As we will see below, the algorithm produces an "-approximation of size roughly O (c log c) in time O (n 2+ffi ), for some cases. We will be combining the ideas from the algorithms of Agarwal and Suri [3] and Clarkson <ref> [7] </ref> along with some new ideas to obtain the faster algorithm. As in [5, 7] we will formulate the problem as a two-dimensional hitting set problem and use a variant of Clarkson's randomized algorithm to compute a small hitting set. <p> We will be combining the ideas from the algorithms of Agarwal and Suri [3] and Clarkson [7] along with some new ideas to obtain the faster algorithm. As in <ref> [5, 7] </ref> we will formulate the problem as a two-dimensional hitting set problem and use a variant of Clarkson's randomized algorithm to compute a small hitting set. In order to expedite the running time, we do not construct the underlying set system explicitly. <p> We construct the hitting set using the algorithm by Clarkson <ref> [7] </ref> for polytope approximation, which was later generalized by Bronnimann and Goodrich [5] for computing set covers (or hitting sets) of set systems with a finite VC-dimension. Assume that the size of the smallest hitting set, denoted by c, is known. <p> Assume that the size of the smallest hitting set, denoted by c, is known. This is no loss of generality because we can use the standard doubling trick to guess the value of c; see e.g., <ref> [7] </ref>. Let (B; R B ) be the set system induced by the basis B on (X; R), where X is the set of all valid triangles and R = ff j 2 X and p 2 g j p 2 Sg as defined in Section Section 2. <p> We call an iteration successful if the weights of triangles in p have been doubled (i.e., w ( p ) &lt; 1 2c w (B)). Clarkson has shown that the number of successful iterations is at most 4c log (n=c) <ref> [7] </ref>. It can be shown that the set system (B; R B ) has a finite VC-dimension. Therefore it follows from the "-net theory, that the probability of an iteration being successful is at least 1=2 [8, 26]. Hence, the expected number of iterations is O (c log (n=c)).
Reference: [8] <author> K. L. Clarkson and P. W. Shor, </author> <title> Applications of random sampling in computational geometry, </title> <journal> Discrete and Comput. Geom., </journal> <volume> 4 (1989), </volume> <pages> 387-421. </pages>
Reference-contexts: It can be shown that the set system (B; R B ) has a finite VC-dimension. Therefore it follows from the "-net theory, that the probability of an iteration being successful is at least 1=2 <ref> [8, 26] </ref>. Hence, the expected number of iterations is O (c log (n=c)). Intuitively, if a point p is not covered by R, then the number of triangles containing p is small, and one of these triangles belongs to the optimal hitting set.
Reference: [9] <author> B. Chazelle, M. Sharir, and E. Welzl, </author> <title> Quasi-optimal upper bounds for simplex range searching and new zone theorems Algorithmica, </title> <booktitle> 8 (1992), </booktitle> <pages> 407-429. </pages>
Reference-contexts: The algorithm works in three stages. In the first stage we compute a family of canonical subsets of S using a simplex range-searching data structure <ref> [9] </ref>, in the second stage we compute a set of canonical triangles from these canonical sets, and in the third stage we discard those canonical triangles that are not valid. <p> The First Stage: Let r = n ff be a parameter, for some ff &gt; 0. For computing the family of canonical subsets, we use the triangle range-searching data structure by Chazelle et al <ref> [9] </ref>. Their algorithm constructs in time O (n 2+ffi ) a multi-level partition tree on S for any ffi 6ff. Roughly speaking, it stores a family of subsets of S, called canonical subsets, into a tree-like data structure.
Reference: [10] <author> L. P. Chew, </author> <title> Constrained Delaunay triangulations, </title> <journal> Algorithmica, </journal> <volume> 4 (1989), </volume> <pages> 97-108. </pages>
Reference: [11] <author> J. Cohen, A. Varshney, D. Manocha, G. Turk, H. Weber, P. K. Agarwal, F. Brooks, and W. Wright, </author> <title> Simplification envelopes, </title> <booktitle> Proc. </booktitle> <address> SIG-GRAPH'96., </address> <year> 1996, </year> <pages> 119-128. </pages>
Reference-contexts: Although there has been a lot of work on surface simplification in computer graphics, GIS, and scientific computing, most of the work is based on heuristic approaches <ref> [4, 11, 18, 19, 21, 25, 28, 29, 35, 39] </ref>. It is therefore not surprising that these algorithms do not guarantee any bounds on the quality of the simplification. In this paper, we study the surface-approximation problem for xy-monotone surfaces (i.e., for terrains).
Reference: [12] <author> M. de Berg and K. Dobrindt, </author> <title> On levels of detail in terrain, </title> <booktitle> Proc. 11th Annual ACM Symp. on Comput. Geom. </booktitle> <year> 1995, </year> <month> C26-C27. </month>
Reference-contexts: They typically start with a single triangle (or tetrahedron for general surfaces) and refine it locally until the resulting surface becomes an "-approximation, or they start with a fine triangulation and coarsen it locally (by removing a vertex and filling the hole) until one can no longer remove a vertex <ref> [12, 13, 14, 15, 17, 16, 27, 33, 34, 36, 38] </ref>. The former method is called refinement, and the latter is called decimation. Some other approaches that extend to arbitrary surfaces have also been proposed.
Reference: [13] <author> L. De Floriani, </author> <title> A pyramidal data structure for triangle based surface description, </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> 9 (1989), </volume> <pages> 67-78. </pages>
Reference-contexts: They typically start with a single triangle (or tetrahedron for general surfaces) and refine it locally until the resulting surface becomes an "-approximation, or they start with a fine triangulation and coarsen it locally (by removing a vertex and filling the hole) until one can no longer remove a vertex <ref> [12, 13, 14, 15, 17, 16, 27, 33, 34, 36, 38] </ref>. The former method is called refinement, and the latter is called decimation. Some other approaches that extend to arbitrary surfaces have also been proposed.
Reference: [14] <author> L. De Floriani, B. Falcidieno and C. Pienovi, </author> <title> A Delaunay-based method for surface approximation, </title> <booktitle> Proc. </booktitle> <address> Eurographics'83, </address> <publisher> Elsevier Science, </publisher> <year> 1983, </year> <pages> 333-350. </pages>
Reference-contexts: They typically start with a single triangle (or tetrahedron for general surfaces) and refine it locally until the resulting surface becomes an "-approximation, or they start with a fine triangulation and coarsen it locally (by removing a vertex and filling the hole) until one can no longer remove a vertex <ref> [12, 13, 14, 15, 17, 16, 27, 33, 34, 36, 38] </ref>. The former method is called refinement, and the latter is called decimation. Some other approaches that extend to arbitrary surfaces have also been proposed.
Reference: [15] <author> L. De Floriani, B. Falcidieno, G. Nagy, and C. Pienovi, </author> <title> A hierarchical structure for surface approximation, </title> <journal> Computers and Graphics, </journal> <volume> 8 (1984), </volume> <pages> 183-193. </pages>
Reference-contexts: They typically start with a single triangle (or tetrahedron for general surfaces) and refine it locally until the resulting surface becomes an "-approximation, or they start with a fine triangulation and coarsen it locally (by removing a vertex and filling the hole) until one can no longer remove a vertex <ref> [12, 13, 14, 15, 17, 16, 27, 33, 34, 36, 38] </ref>. The former method is called refinement, and the latter is called decimation. Some other approaches that extend to arbitrary surfaces have also been proposed.
Reference: [16] <author> L. De Floriani, B. Falcidieno, and C. Pienovi, </author> <title> Delaunay based representation of surfaces defined over arbitrarily shaped domains, </title> <booktitle> Computer Vision, Graphics and Image Processing, </booktitle> <month> 32 </month> <year> (1985) </year> <month> 127-140. </month>
Reference-contexts: They typically start with a single triangle (or tetrahedron for general surfaces) and refine it locally until the resulting surface becomes an "-approximation, or they start with a fine triangulation and coarsen it locally (by removing a vertex and filling the hole) until one can no longer remove a vertex <ref> [12, 13, 14, 15, 17, 16, 27, 33, 34, 36, 38] </ref>. The former method is called refinement, and the latter is called decimation. Some other approaches that extend to arbitrary surfaces have also been proposed.
Reference: [17] <author> L. De Floriani and E. Puppo, </author> <title> A hierarchical triangle based model for terrain description, Theories and Methods of Spatio-Temporal Reasoning in Geographic Space (A. </title> <editor> U. Frank et al. eds.), </editor> <publisher> Springer Verlag, </publisher> <year> 1992, </year> <pages> 236-251. </pages>
Reference-contexts: They typically start with a single triangle (or tetrahedron for general surfaces) and refine it locally until the resulting surface becomes an "-approximation, or they start with a fine triangulation and coarsen it locally (by removing a vertex and filling the hole) until one can no longer remove a vertex <ref> [12, 13, 14, 15, 17, 16, 27, 33, 34, 36, 38] </ref>. The former method is called refinement, and the latter is called decimation. Some other approaches that extend to arbitrary surfaces have also been proposed.
Reference: [18] <author> M. DeHaemer and M. Zyda, </author> <title> Simplification of objects rendered by polygonal approximations, </title> <booktitle> Computers and Graphics 15 (1992), </booktitle> <pages> 175-184. </pages>
Reference-contexts: Although there has been a lot of work on surface simplification in computer graphics, GIS, and scientific computing, most of the work is based on heuristic approaches <ref> [4, 11, 18, 19, 21, 25, 28, 29, 35, 39] </ref>. It is therefore not surprising that these algorithms do not guarantee any bounds on the quality of the simplification. In this paper, we study the surface-approximation problem for xy-monotone surfaces (i.e., for terrains).
Reference: [19] <author> H. Delingette, </author> <title> Simplex meshes: A general representation for 3D shape reconstruction, </title> <booktitle> Proc. Int. Conf. on Computer Vision and Pattern Recognition, </booktitle> <year> 1994, </year> <pages> 856-859. </pages>
Reference-contexts: Although there has been a lot of work on surface simplification in computer graphics, GIS, and scientific computing, most of the work is based on heuristic approaches <ref> [4, 11, 18, 19, 21, 25, 28, 29, 35, 39] </ref>. It is therefore not surprising that these algorithms do not guarantee any bounds on the quality of the simplification. In this paper, we study the surface-approximation problem for xy-monotone surfaces (i.e., for terrains).
Reference: [20] <author> D. Dobkin and D. Kirkpatrick, </author> <title> Fast detection of polyhedral intersection, </title> <booktitle> Proc. 9th Int. Colloq. Automata, Languages and Programming, Lecture Notes in Computer Science 140, </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1982, </year> <pages> 154-165. </pages>
Reference-contexts: P i is a convex polyhedron with at most 2jS i j faces, and it can be computed in time O (jS i j log jS i j). We preprocess P i for point-location queries, using the Dobkin-Kirkpatrick hierarchy <ref> [20] </ref>. The total time spent in preprocessing S is once again O (n 2+ffi ). Let be any triangle in the plane. We determine whether is valid as follows. <p> For checking whether R covers all the points, we compute the the union U of the triangles in R, and preprocess it for efficient point-location queries in time O (c 2 log 2 c), so that a point-location query can be answered in O (log c) time <ref> [20] </ref>. For every point p 2 S, we perform a point-location query. If all the points lie in the union of R, then R is a hitting set. The total time spent in this step is O (c 2 log 2 c + n log c).
Reference: [21] <author> M. Eck, T. DeRose, T. Duchamp, H. Hoppe, M. Lounsbery, and W. Stuetzle, </author> <title> Multiresolu-tion analysis of arbitrary meshes, </title> <booktitle> Proc. </booktitle> <address> SIG-GRAPH'95, </address> <year> 1995, </year> <pages> 173-182. </pages>
Reference-contexts: Although there has been a lot of work on surface simplification in computer graphics, GIS, and scientific computing, most of the work is based on heuristic approaches <ref> [4, 11, 18, 19, 21, 25, 28, 29, 35, 39] </ref>. It is therefore not surprising that these algorithms do not guarantee any bounds on the quality of the simplification. In this paper, we study the surface-approximation problem for xy-monotone surfaces (i.e., for terrains). <p> The former method is called refinement, and the latter is called decimation. Some other approaches that extend to arbitrary surfaces have also been proposed. They include an optimization method that formulates the problem as an energy optimization problem [28, 29], and an approach based on wavelets <ref> [21, 24] </ref>. For a more comprehensive summary of known results on terrain simplification, see the survey by Heckbert and Garland [27]. However none of the above algorithms give any quantitative bound on the size of the approximation. Provable surface-approximation algorithms were recently developed for the case of convex surfaces.
Reference: [22] <author> D. Eppstein, </author> <title> Dynamic three dimensional linear programming, </title> <journal> ORSA J. Computing, </journal> <volume> 4 (1992), </volume> <pages> 360-368. </pages>
Reference-contexts: The intersection of k convex polyhedra can be computed in O (k 3 log 3 n) using the algorithm by Eppstein <ref> [22] </ref>. Therefore, we can check in time O (u 3 log 3 n) = O ((1=ff 3 ) log 3 n) whether a given can be lifted.
Reference: [23] <author> W. R. Franklin, </author> <title> Triangulated irregular network to approximate digital terrain, </title> <type> Tech. Report, </type> <institution> Electrical, Computer and Systems Enginnering Dept., Rensselaer Polytechnic Institute, </institution> <address> Troy, NY, </address> <year> 1994. </year>
Reference-contexts: We ran our experiments on a Digital AlphaStation 500/266 workstation, and each of them took between 30 and 45 seconds. In the Table 1, we summarize our results and compare them with the results of Franklin <ref> [23] </ref> and Silva, et al. [38] on the same data sets.
Reference: [24] <author> M. H. Gross, O. G. Staadt, and R. Gatti, </author> <title> Efficient triangular surface approximations using wavelets and quadtree data structures, </title> <journal> IEEE Trans. on Visualization and Computer Graphics 2 (1996), </journal> <pages> 130-143. </pages>
Reference-contexts: The former method is called refinement, and the latter is called decimation. Some other approaches that extend to arbitrary surfaces have also been proposed. They include an optimization method that formulates the problem as an energy optimization problem [28, 29], and an approach based on wavelets <ref> [21, 24] </ref>. For a more comprehensive summary of known results on terrain simplification, see the survey by Heckbert and Garland [27]. However none of the above algorithms give any quantitative bound on the size of the approximation. Provable surface-approximation algorithms were recently developed for the case of convex surfaces.
Reference: [25] <author> A. Gueziec and R. Hummel, </author> <title> Exploiting triangulated surface extraction using tetrahedral decomposition. </title> <journal> IEEE Trans. on Visualization and Computer Graphics 1 (1995), </journal> <pages> 328-342. </pages>
Reference-contexts: Although there has been a lot of work on surface simplification in computer graphics, GIS, and scientific computing, most of the work is based on heuristic approaches <ref> [4, 11, 18, 19, 21, 25, 28, 29, 35, 39] </ref>. It is therefore not surprising that these algorithms do not guarantee any bounds on the quality of the simplification. In this paper, we study the surface-approximation problem for xy-monotone surfaces (i.e., for terrains).
Reference: [26] <author> D. Haussler and E. Welzl, </author> <title> "-nets and simplex range queries, </title> <journal> Discrete Comput. Geom. </journal> <volume> 2 (1987), </volume> <pages> 127-151. </pages>
Reference-contexts: It can be shown that the set system (B; R B ) has a finite VC-dimension. Therefore it follows from the "-net theory, that the probability of an iteration being successful is at least 1=2 <ref> [8, 26] </ref>. Hence, the expected number of iterations is O (c log (n=c)). Intuitively, if a point p is not covered by R, then the number of triangles containing p is small, and one of these triangles belongs to the optimal hitting set.
Reference: [27] <author> P. S. Heckbert and M. </author> <title> Garland, Fast polygonal approximations of terrains and height fields, </title> <type> Tech. Report CMU-CS-95-181, </type> <institution> Carnegie Mellon University, Pittsburgh, </institution> <year> 1995. </year>
Reference-contexts: They typically start with a single triangle (or tetrahedron for general surfaces) and refine it locally until the resulting surface becomes an "-approximation, or they start with a fine triangulation and coarsen it locally (by removing a vertex and filling the hole) until one can no longer remove a vertex <ref> [12, 13, 14, 15, 17, 16, 27, 33, 34, 36, 38] </ref>. The former method is called refinement, and the latter is called decimation. Some other approaches that extend to arbitrary surfaces have also been proposed. <p> They include an optimization method that formulates the problem as an energy optimization problem [28, 29], and an approach based on wavelets [21, 24]. For a more comprehensive summary of known results on terrain simplification, see the survey by Heckbert and Garland <ref> [27] </ref>. However none of the above algorithms give any quantitative bound on the size of the approximation. Provable surface-approximation algorithms were recently developed for the case of convex surfaces.
Reference: [28] <author> H. Hoppe, T. DeRose, T. Duchamp, J. McDon-ald, and W. Stuetzle, </author> <title> Mesh optimization, </title> <booktitle> Proc. SIGGRAPH 93, </booktitle> <year> 1993, </year> <pages> 19-26. </pages>
Reference-contexts: Although there has been a lot of work on surface simplification in computer graphics, GIS, and scientific computing, most of the work is based on heuristic approaches <ref> [4, 11, 18, 19, 21, 25, 28, 29, 35, 39] </ref>. It is therefore not surprising that these algorithms do not guarantee any bounds on the quality of the simplification. In this paper, we study the surface-approximation problem for xy-monotone surfaces (i.e., for terrains). <p> The former method is called refinement, and the latter is called decimation. Some other approaches that extend to arbitrary surfaces have also been proposed. They include an optimization method that formulates the problem as an energy optimization problem <ref> [28, 29] </ref>, and an approach based on wavelets [21, 24]. For a more comprehensive summary of known results on terrain simplification, see the survey by Heckbert and Garland [27]. However none of the above algorithms give any quantitative bound on the size of the approximation.
Reference: [29] <author> M. Margaliot and C. Gotsman, </author> <title> Piecewise linear surface approximation from noisy scattered samples, </title> <booktitle> Proc. </booktitle> <address> Visualization'94, </address> <year> 1994, </year> <pages> 61-68. </pages>
Reference-contexts: Although there has been a lot of work on surface simplification in computer graphics, GIS, and scientific computing, most of the work is based on heuristic approaches <ref> [4, 11, 18, 19, 21, 25, 28, 29, 35, 39] </ref>. It is therefore not surprising that these algorithms do not guarantee any bounds on the quality of the simplification. In this paper, we study the surface-approximation problem for xy-monotone surfaces (i.e., for terrains). <p> The former method is called refinement, and the latter is called decimation. Some other approaches that extend to arbitrary surfaces have also been proposed. They include an optimization method that formulates the problem as an energy optimization problem <ref> [28, 29] </ref>, and an approach based on wavelets [21, 24]. For a more comprehensive summary of known results on terrain simplification, see the survey by Heckbert and Garland [27]. However none of the above algorithms give any quantitative bound on the size of the approximation.
Reference: [30] <author> N. Megiddo, </author> <title> Linear programming in linear time when the dimension is fixed, </title> <journal> J. ACM, </journal> <volume> 31 (1984), </volume> <pages> 114-127. </pages>
Reference-contexts: satisfy the following inequality z i " a i x p + b i y p + c i z i + " Since this is an instance of linear programming in &lt; 3 , h i and i can be computed in O (n) time, using Megiddo's linear-programming algorithm <ref> [30] </ref>.
Reference: [31] <author> J. Mitchell and S. Suri, </author> <title> Separation and approximation of polyhedral objects, </title> <journal> Computational Geometry | Theory and Applications, </journal> <volume> 5 (1995), </volume> <pages> 95-114. </pages>
Reference-contexts: 3 and a parameter ", Mitchell and Suri gave an O (n 3 )-time algorithm that computes a convex polytope Q with O (c log n) vertices such that (1")P Q (1+")P ; c is the size of the smallest polytope that lies between (1 ")P and (1 + ")P <ref> [31] </ref>. These bounds were subsequently improved by Clarkson [7] and Bronnimann and Goodrich [5]; the latter gave an algorithm, with O (nc (c + log n) log (n=c)) running time, to compute a polytope Q with O (c) vertices.
Reference: [32] <author> F. Preparata and M. I. Shamos, </author> <title> Computational Geometry: An Introduction, </title> <publisher> Springer-Verlag, </publisher> <year> 1985. </year>
Reference: [33] <author> S. Rippa, </author> <title> Adaptive approximation by piecewise linear polynomials on triangulations of subsets of scattered data, </title> <journal> SIAM J. on Scientific and Stat. Computing, </journal> <volume> 13 (1992), </volume> <pages> 1123-1141. </pages>
Reference-contexts: They typically start with a single triangle (or tetrahedron for general surfaces) and refine it locally until the resulting surface becomes an "-approximation, or they start with a fine triangulation and coarsen it locally (by removing a vertex and filling the hole) until one can no longer remove a vertex <ref> [12, 13, 14, 15, 17, 16, 27, 33, 34, 36, 38] </ref>. The former method is called refinement, and the latter is called decimation. Some other approaches that extend to arbitrary surfaces have also been proposed.
Reference: [34] <author> S. Rippa, </author> <title> Long and thin triangles can be good for linear interpolation, </title> <journal> SIAM J. Numer. Anal, </journal> <volume> 29 (1992), </volume> <pages> 257-270. </pages>
Reference-contexts: They typically start with a single triangle (or tetrahedron for general surfaces) and refine it locally until the resulting surface becomes an "-approximation, or they start with a fine triangulation and coarsen it locally (by removing a vertex and filling the hole) until one can no longer remove a vertex <ref> [12, 13, 14, 15, 17, 16, 27, 33, 34, 36, 38] </ref>. The former method is called refinement, and the latter is called decimation. Some other approaches that extend to arbitrary surfaces have also been proposed.
Reference: [35] <author> J. Rossingac and P. Borrel, </author> <title> Multiresolution 3D approximations for rendering complex scenes, Modeling in Computer Graphics: Methods and Applications (B. </title> <editor> Falcidieno and T. Kunii, eds), </editor> <publisher> Springer Verlag, </publisher> <year> 1993, </year> <pages> 455-465. </pages>
Reference-contexts: Although there has been a lot of work on surface simplification in computer graphics, GIS, and scientific computing, most of the work is based on heuristic approaches <ref> [4, 11, 18, 19, 21, 25, 28, 29, 35, 39] </ref>. It is therefore not surprising that these algorithms do not guarantee any bounds on the quality of the simplification. In this paper, we study the surface-approximation problem for xy-monotone surfaces (i.e., for terrains).
Reference: [36] <author> L. Scarlatos, T. Pavlidis, </author> <title> Hierarchical triangulation using cartographic coherence, CVGIP: Graphical models and image processing, </title> <booktitle> 54 (1992), </booktitle> <pages> 147-161. </pages>
Reference-contexts: They typically start with a single triangle (or tetrahedron for general surfaces) and refine it locally until the resulting surface becomes an "-approximation, or they start with a fine triangulation and coarsen it locally (by removing a vertex and filling the hole) until one can no longer remove a vertex <ref> [12, 13, 14, 15, 17, 16, 27, 33, 34, 36, 38] </ref>. The former method is called refinement, and the latter is called decimation. Some other approaches that extend to arbitrary surfaces have also been proposed.
Reference: [37] <author> R. </author> <title> Seidel Linear programming and convex hulls made easy, </title> <booktitle> 6th ACM Symp. on Comput. Geom., </booktitle> <year> 1990, </year> <pages> 211-215. </pages>
Reference-contexts: As a result the xy-projections of the vertices of the lifted triangles are points of S. For checking the validity of a canonical triangle, we use the linear-programming algorithm of Seidel <ref> [37] </ref>. We also consider the case in which the vertices of the lifted triangle are a subset of the input points. We use the greedy algorithm, instead of Clarkson's randomized algorithm, for computing a hitting set.
Reference: [38] <author> C. T. Silva, J, S. B. Mitchell, and A. E. Kauf-man, </author> <title> Automatic generation of triangular irregular networks using greedy cuts, </title> <booktitle> Proc. Visualization '95, </booktitle> <year> 1995, </year> <pages> 201-208. </pages>
Reference-contexts: They typically start with a single triangle (or tetrahedron for general surfaces) and refine it locally until the resulting surface becomes an "-approximation, or they start with a fine triangulation and coarsen it locally (by removing a vertex and filling the hole) until one can no longer remove a vertex <ref> [12, 13, 14, 15, 17, 16, 27, 33, 34, 36, 38] </ref>. The former method is called refinement, and the latter is called decimation. Some other approaches that extend to arbitrary surfaces have also been proposed. <p> Our implementation has about 2000 lines of C++ code. All the input data sets consisted of 120 fi 120 elevation arrays, as in <ref> [38] </ref>. We ran our experiments on a Digital AlphaStation 500/266 workstation, and each of them took between 30 and 45 seconds. In the Table 1, we summarize our results and compare them with the results of Franklin [23] and Silva, et al. [38] on the same data sets. <p> of 120 fi 120 elevation arrays, as in <ref> [38] </ref>. We ran our experiments on a Digital AlphaStation 500/266 workstation, and each of them took between 30 and 45 seconds. In the Table 1, we summarize our results and compare them with the results of Franklin [23] and Silva, et al. [38] on the same data sets. <p> The performance of our current implementation is slightly inferior to that of the algorithms by Silva et al. <ref> [38] </ref>. However, a better range-searching data structure and a more clever stitching process should improve the performance significantly.
Reference: [39] <author> G. Turk, </author> <title> Retiling of polygonal surfaces, </title> <booktitle> Computer Graphics 26 (1992), </booktitle> <pages> 55-64. </pages>
Reference-contexts: Although there has been a lot of work on surface simplification in computer graphics, GIS, and scientific computing, most of the work is based on heuristic approaches <ref> [4, 11, 18, 19, 21, 25, 28, 29, 35, 39] </ref>. It is therefore not surprising that these algorithms do not guarantee any bounds on the quality of the simplification. In this paper, we study the surface-approximation problem for xy-monotone surfaces (i.e., for terrains).
References-found: 39

