URL: http://c.gp.cs.cmu.edu:5103/afs/cs/project/nectar-adamb/ftp/ckpt_jpdc.ps.Z
Refering-URL: http://c.gp.cs.cmu.edu:5103/afs/cs/project/nectar-adamb/ftp/
Root-URL: http://www.cs.cmu.edu
Email: Email: fadamb,eriks,pstephang@cs.cmu.edu  
Phone: Phone: 412-268-5295 Fax: 412-268-5576  
Title: Application Level Fault Tolerance in Heterogeneous Networks of Workstations  
Author: Adam Beguelin Erik Seligman and Peter Stephan 
Note: Corresponding author. Joint appointment with the Pittsburgh Supercomputing Center. Currently at Intel Corporation.  
Address: Pittsburgh, PA 15213  
Affiliation: School of Computer Science Carnegie Mellon University  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Jose Nagib Cotrim Arabe, Adam Beguelin, Bruce Lowekamp, Erik Seligman, Michael Starkey, and Peter Stephan. Dome: </author> <title> Parallel programming in a heterogeneous multiuser environment. </title> <type> Technical Report CMU-CS-95-137, </type> <institution> Carnegie Mellon University, </institution> <month> April </month> <year> 1995. </year>
Reference-contexts: This paper discusses the implementation of fault tolerance mechanisms at various levels of programming abstraction and specifically describes the results of the initial implementation of some of these methods which have been developed for use with the Distributed object migration environment (Dome) <ref> [1, 2, 23] </ref>. Dome is a system that is designed to provide application programmers a simple and intuitive interface for parallel programming in a heterogeneous environment. It is implemented as a library of C++ classes and uses PVM [10, 9] for its process control and communication. <p> In the SPMD model the user program is replicated on each machine in the cluster, and each copy of the program, executing in parallel, performs its computations on a subset of the data in each Dome object. 3 For a more complete discussion of Dome, see <ref> [1] </ref>. A fault tolerance package for use with Dome can be implemented at various levels of programming abstraction. At the application level the programmer can call a set of C++ methods to checkpoint a program's data structures and to restart that program from the checkpointed data.
Reference: [2] <author> Jose Nagib Cotrim Arabe, Adam Beguelin, Bruce Lowekamp, Erik Seligman, Michael Starkey, and Peter Stephan. Dome: </author> <title> Parallel programming in a heterogeneous multi-user environment. </title> <booktitle> In International Parallel Processing Symposium 1996, </booktitle> <address> Honolulu, HI, </address> <month> April </month> <year> 1996. </year>
Reference-contexts: This paper discusses the implementation of fault tolerance mechanisms at various levels of programming abstraction and specifically describes the results of the initial implementation of some of these methods which have been developed for use with the Distributed object migration environment (Dome) <ref> [1, 2, 23] </ref>. Dome is a system that is designed to provide application programmers a simple and intuitive interface for parallel programming in a heterogeneous environment. It is implemented as a library of C++ classes and uses PVM [10, 9] for its process control and communication.
Reference: [3] <author> Francois Bodin, Peter Beckman, Dennis Gannon, Jacob Gotwals, Srinivas Narayana, Suresh Srinivas, and Beata Winnicka. Sage++: </author> <title> An object-oriented toolkit and class library for building Fortran and C++ restructuring tools. </title> <booktitle> In OONSKI'94, </booktitle> <year> 1994. </year>
Reference-contexts: More information can be found on the Dome home page, http://www.cs.cmu.edu/ dome.html. We would like to acknowledge Dennis Gannon's group for their work on the Sage++ compiler preprocessor toolkit <ref> [3] </ref>. This toolkit was used to build the preprocessor of Dome programs described in Section 2.3.
Reference: [4] <author> K. Chandy and L. Lamport. </author> <title> Distributed snapshots: Determining global states of distributed systems. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 3(1) </volume> <pages> 63-75, </pages> <month> February </month> <year> 1985. </year>
Reference-contexts: Synchronization is required at checkpoint time to ensure a consistent state, and a "snapshot" algorithm such as the one described by Chandy and Lamport <ref> [4] </ref> must be used to ensure that no messages are in transit. While this might be more expensive, it retains the advantage of completely machine-independent checkpoints, which should be very useful to PVM programmers. Finally, we are nearly finished integrating Dome with Condor [16].
Reference: [5] <author> Andrzej Duda. </author> <title> The effects of checkpointing on program execution time. </title> <journal> Information Processing Letters, </journal> <volume> 16 </volume> <pages> 221-229, </pages> <month> June </month> <year> 1983. </year>
Reference-contexts: These seem to be a reasonable set of assumptions for making estimates of machine failure rates. 22 Duda <ref> [5] </ref> has used this formulation to calculate the expected runtime of a program as follows: t = a 1 )(e (fla) 1)) (1) where t = total expected time for a run fl = Poisson parameter, or 1/(mean time between failures) T = program runtime in the absence of system failures
Reference: [6] <author> Elmootazbella Elnozahy, David Johnson, and Willy Zwaeneopoel. </author> <title> The performance of consistent checkpointing. </title> <booktitle> In Proceedings of the 11th Symposium on Reliable Distributed Systems, </booktitle> <pages> pages 39-47. </pages> <publisher> IEEE Computer Society Press, </publisher> <year> 1992. </year>
Reference-contexts: Silva, Veer, and Silva [25] have developed an application level checkpointing system for distributed programs. Their primary focus is also to minimize the cost of individual checkpoints. Some studies such as <ref> [6] </ref>, however, have suggested that checkpointing generally 28 tends to be an inexpensive operation. Therefore, our fault tolerance package focuses on other issues. The approach described in this paper uses object-oriented techniques to create a user-transparent and fully portable checkpoint and restart mechanism for distributed programs.
Reference: [7] <author> J. Choi et al. </author> <title> Scalapack: A scalable linear algebra library for distributed memory concurrent computers. </title> <booktitle> In 4th Symposium Frontiers of Massive Parallel Computers, </booktitle> <pages> pages 120-127, </pages> <year> 1992. </year>
Reference-contexts: Upon failure the parity processor is able to reconstruct the state of the failed processor from the parity and the state of the remaining processors. Application level information is used by the system to determine what state information to checkpoint. Their diskless checkpointing is integrated with the ScaLAPAK <ref> [7] </ref> linear algebra routines, allowing a user program to survive a fault that occurs while the program is within the instrumented ScaLAPAK library without incurring any disk access.
Reference: [8] <author> Geoffrey C. Fox. </author> <title> What have we learned from using real parallel machines to solve real problems? In Proceedings of the Third Conference on Hypercube Concurrent Computers and Applications, </title> <type> pages 897-955. </type> <institution> Association for Computing Machinery, </institution> <year> 1988. </year>
Reference-contexts: Of course, this is a very limited programming model. In particular, the requirement that the computational loop be called directly from main () may seem extremely restrictive. However, it has been observed in <ref> [8] </ref> that a majority of scientific programs are either fully or loosely synchronous, that is, all processes repeatedly execute a section of code and then 12 synchronize. Therefore, a large proportion of these applications can easily be adapted to this model.
Reference: [9] <author> A. Geist, A. Beguelin, J. J. Dongarra, W. Jiang, R. Manchek, and V. S. Sunderam. </author> <title> PVM 3 user's guide and reference manual. </title> <type> Technical Report ORNL/TM-12187, </type> <institution> Oak Ridge National Laboratory, </institution> <month> May </month> <year> 1993. </year>
Reference-contexts: Dome is a system that is designed to provide application programmers a simple and intuitive interface for parallel programming in a heterogeneous environment. It is implemented as a library of C++ classes and uses PVM <ref> [10, 9] </ref> for its process control and communication. When an object of one of these classes is instantiated, it is automatically partitioned and apportioned among the nodes of the workstation cluster. Dome uses a single program multiple data (SPMD) model to perform parallelization of the program.
Reference: [10] <author> Al Geist, Adam Beguelin, Jack Dongarra, Weicheng Jiang, Robert Manchek, and Vaidy Sunderam. </author> <title> PVM: Parallel Virtual Machine | A Users' Guide and Tutorial for Net-worked Parallel Computing. </title> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: Dome is a system that is designed to provide application programmers a simple and intuitive interface for parallel programming in a heterogeneous environment. It is implemented as a library of C++ classes and uses PVM <ref> [10, 9] </ref> for its process control and communication. When an object of one of these classes is instantiated, it is automatically partitioned and apportioned among the nodes of the workstation cluster. Dome uses a single program multiple data (SPMD) model to perform parallelization of the program.
Reference: [11] <author> Erol Gelenbe. </author> <title> On the optimum checkpoint interval. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 26(2) </volume> <pages> 259-270, </pages> <month> April </month> <year> 1979. </year>
Reference-contexts: Using this formula the expected runtime of a program can be computed based on the time to checkpoint, the total runtime if there are no failures, and an estimate of the failure rate. For additional mathematical treatments of program runtimes in the presence of failures, see <ref> [11, 26] </ref>. In order to get a general idea of the costs of our checkpointing package, short, successful runs of the Dome molecular dynamics application, md, were timed. The md application is based on a CM-Fortran program developed at the Pittsburgh Supercomputing Center.
Reference: [12] <author> Christine Hofmeister and James Purtilo. </author> <title> Dynamic reconfiguration in distributed systems: Adapting software modules for replacement. </title> <type> Technical Report UMIACS-TR-92-120, </type> <institution> University of Maryland, </institution> <month> November </month> <year> 1992. </year> <month> 33 </month>
Reference-contexts: Their approach suffers when the application is communication bound because it doubles the number of data messages. In contrast Dome's mechanism takes a more conventional approach by saving the checkpoints to stable storage rather than relying on shadow processes. 29 Hofmeister and Purtilo <ref> [12] </ref> have written a preprocessor for saving the state of programs which use their Polylith system.
Reference: [13] <author> Juan Leon, Allan Fisher, and Peter Steenkiste. </author> <title> Fail-safe PVM: A portable package for distributed programming with transparent recovery. </title> <type> Technical Report CMU-CS-93-124, </type> <institution> Carnegie Mellon University, </institution> <month> February </month> <year> 1993. </year>
Reference-contexts: This will produce significantly smaller checkpoint files. The Dome molecular dynamics ap plication, for example, running as a single process creates a 10KB file with the application level checkpoint method. Using code from <ref> [13] </ref>, the system level method, however, yields a 3.3MB file. Finally, the application level checkpointing methods have a distinct advantage over the system level methods since they use ordinary C++ code and do not require any system specific details. Thus, they are portable between architectures. <p> Silva and Silva [24] have designed a system to account for the latency between failure occurrence and failure detection. Another system, designed by Leon, Fisher, and Steenkiste <ref> [13] </ref>, is specifically tailored to checkpoint and restart multicomputer applications written in PVM. All of these systems depend on machine-specific code, however, and none provides checkpoints that are portable within a heterogeneous environment. Silva, Veer, and Silva [25] have developed an application level checkpointing system for distributed programs. <p> A Dome-compatible system level checkpointing system is also currently being sought for performance comparisons. There are a number of improvements to be made to our checkpointing system. Several of these improvements will help to reduce the checkpointing overhead further. These are described in studies such as <ref> [13, 14, 15, 24] </ref> and include checkpointing to memory rather than disk, using incremental or copy-on-write methods to reduce the amount of data saved, or creating "optimistic" local checkpoints at each process rather than synchronizing for a global checkpoint. The SPMD model makes this optimistic checkpointing very easy.
Reference: [14] <author> Kai Li, Jeffrey Naughton, and James Plank. </author> <title> Real-time, concurrent checkpoint for parallel programs. </title> <booktitle> In Proceedings of the Second ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <pages> pages 79-88. </pages> <institution> Association for Computing Machinery, </institution> <year> 1990. </year>
Reference-contexts: A Dome-compatible system level checkpointing system is also currently being sought for performance comparisons. There are a number of improvements to be made to our checkpointing system. Several of these improvements will help to reduce the checkpointing overhead further. These are described in studies such as <ref> [13, 14, 15, 24] </ref> and include checkpointing to memory rather than disk, using incremental or copy-on-write methods to reduce the amount of data saved, or creating "optimistic" local checkpoints at each process rather than synchronizing for a global checkpoint. The SPMD model makes this optimistic checkpointing very easy.
Reference: [15] <author> Kai Li, Jeffrey Naughton, and James Plank. </author> <title> Checkpointing multicomputer applications. </title> <booktitle> In Proceedings of the 10th Symposium on Reliable Distributed Systems, </booktitle> <pages> pages 2-11. </pages> <publisher> IEEE Computer Society Press, </publisher> <year> 1991. </year>
Reference-contexts: Furthermore, the portability of the checkpoints themselves has also been successfully accomplished by restarting md on Alpha workstations from checkpoints created on SGI workstations. 5 Related Work A number of systems targeted at system level interrupt-driven checkpointing for parallel programs have been developed recently. Li, Naughton, and Plank ([14], <ref> [15] </ref>, [20]) have concentrated on minimizing the overhead of the individual checkpoints by using system level techniques related to memory protection and designing special algorithms to take advantage of multicomputer architectures. Silva and Silva [24] have designed a system to account for the latency between failure occurrence and failure detection. <p> A Dome-compatible system level checkpointing system is also currently being sought for performance comparisons. There are a number of improvements to be made to our checkpointing system. Several of these improvements will help to reduce the checkpointing overhead further. These are described in studies such as <ref> [13, 14, 15, 24] </ref> and include checkpointing to memory rather than disk, using incremental or copy-on-write methods to reduce the amount of data saved, or creating "optimistic" local checkpoints at each process rather than synchronizing for a global checkpoint. The SPMD model makes this optimistic checkpointing very easy.
Reference: [16] <author> M. Litzkow, M. Livny, and M. </author> <title> Mutka. Condor | A hunter of idle workstations. </title> <booktitle> In Proceedings of the Eighth Conference on Distributed Computing Systems, </booktitle> <address> San Jose, California, </address> <month> June </month> <year> 1988. </year>
Reference-contexts: While this might be more expensive, it retains the advantage of completely machine-independent checkpoints, which should be very useful to PVM programmers. Finally, we are nearly finished integrating Dome with Condor <ref> [16] </ref>. Condor provides mechanisms for checkpointing and migrating sequential tasks. It allows efficient use of idle cycles in a NOW.
Reference: [17] <author> D.D.E. Long, J.L. Carroll, and C.J. Park. </author> <title> A study of the reliability of Internet sites. </title> <booktitle> In Proceedings of the 10th Symposium on Reliable Distributed Systems, </booktitle> <pages> pages 177-186. </pages> <publisher> IEEE Computer Society Press, </publisher> <year> 1991. </year>
Reference-contexts: In fact, the checkpointing cases would show additional improvement since the time to checkpoint is proportional to the problem size not the runtime. In an experiment measuring the failure rates of systems on the Internet, Long, Carroll, and Park <ref> [17] </ref> found that, depending on the system, the mean time between failures tended to be between 12 and 20 days. If 16 days is used as a rough estimate, a cluster of eight machines is likely to have a failure every 2 days on average.
Reference: [18] <author> Sun Microsystems. XDR: </author> <title> External Data Representation Standard. </title> <type> RFC 1014, </type> <month> June </month> <year> 1987. </year> <pages> 20 pages. </pages>
Reference-contexts: Furthermore, 17 checkpoint and restore methods are defined for all Dome objects. The checkpoint method for each Dome object is called when the dome_checkpoint () method is invoked. At this point the Dome objects write out their internal state in XDR <ref> [18] </ref> format. In the preprocessor case the stack is also written to the checkpoint file. Upon restart the Dome object constructors test a global restart flag, and initialize their state from a checkpoint file if the flag is set.
Reference: [19] <author> Michael Peercy and Prithviraj Bannerjee. </author> <title> Software Schemes of Reconfiguration and Recovery in Distributed Memory Multicomputers using the Actor Model. </title> <booktitle> In FTCS-25, </booktitle> <pages> pages 479-488, </pages> <address> Pasadena, CA, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: This work is similar to Dome's checkpointing mechanism in that it is integrated into a library and uses application level information. Peercy and Banerjee <ref> [19] </ref> have a fault tolerance mechanism that is similar to Dome in that they use high level information about the application's structure .
Reference: [20] <author> James Plank and Kai Li. </author> <title> ickp: A consistent checkpointer for multicomputers. </title> <booktitle> IEEE Parallel and Distributed Technology, </booktitle> <pages> pages 62-66, </pages> <month> Summer </month> <year> 1994. </year>
Reference-contexts: Li, Naughton, and Plank ([14], [15], <ref> [20] </ref>) have concentrated on minimizing the overhead of the individual checkpoints by using system level techniques related to memory protection and designing special algorithms to take advantage of multicomputer architectures. Silva and Silva [24] have designed a system to account for the latency between failure occurrence and failure detection.
Reference: [21] <author> James S. Plank, Youngbae Kim, and Jack J. Dongarra. </author> <title> Algorithm-Based Diskless Checkpointing for Fault Tolerant Matrix Operations. </title> <booktitle> In FTCS-25, </booktitle> <address> Pasadena, CA, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: Therefore, our fault tolerance package focuses on other issues. The approach described in this paper uses object-oriented techniques to create a user-transparent and fully portable checkpoint and restart mechanism for distributed programs. Plank et al. <ref> [21] </ref> have a unique approach which uses diskless checkpointing. They utilize a parity processor rather than a disk for storing processor state. Upon failure the parity processor is able to reconstruct the state of the failed processor from the parity and the state of the remaining processors.
Reference: [22] <author> Sheldon Ross. </author> <title> A First Course in Probability. </title> <publisher> Macmillan Publishing Company, </publisher> <year> 1988. </year>
Reference-contexts: Checkpointing in this situation ultimately reduces the time required for a program to run to completion. Thus, it is more useful to calculate the average total runtime of the application which is based on the checkpoint overhead and the failure rate. As discussed in <ref> [22] </ref>, a Poisson distribution serves as an accurate model for the expected failure rate during a computation if the following assumptions are made: first, the chance of a failure occurring in any sufficiently small time interval is proportional to the size of the interval, second, the probability of multiple failures in
Reference: [23] <author> Erik Seligman and Adam Beguelin. </author> <title> High level fault tolerance in distributed programs. </title> <type> Technical Report CMU-CS-94-223, </type> <institution> Carnegie Mellon University, </institution> <month> December </month> <year> 1994. </year>
Reference-contexts: This paper discusses the implementation of fault tolerance mechanisms at various levels of programming abstraction and specifically describes the results of the initial implementation of some of these methods which have been developed for use with the Distributed object migration environment (Dome) <ref> [1, 2, 23] </ref>. Dome is a system that is designed to provide application programmers a simple and intuitive interface for parallel programming in a heterogeneous environment. It is implemented as a library of C++ classes and uses PVM [10, 9] for its process control and communication.
Reference: [24] <author> Luis Silva and Jo~ao Silva. </author> <title> Global checkpointing for distributed programs. </title> <booktitle> In Proceedings of the 11th Symposium on Reliable Distributed Systems, </booktitle> <pages> pages 155-162. </pages> <publisher> IEEE Computer Society Press, </publisher> <year> 1992. </year>
Reference-contexts: Li, Naughton, and Plank ([14], [15], [20]) have concentrated on minimizing the overhead of the individual checkpoints by using system level techniques related to memory protection and designing special algorithms to take advantage of multicomputer architectures. Silva and Silva <ref> [24] </ref> have designed a system to account for the latency between failure occurrence and failure detection. Another system, designed by Leon, Fisher, and Steenkiste [13], is specifically tailored to checkpoint and restart multicomputer applications written in PVM. <p> A Dome-compatible system level checkpointing system is also currently being sought for performance comparisons. There are a number of improvements to be made to our checkpointing system. Several of these improvements will help to reduce the checkpointing overhead further. These are described in studies such as <ref> [13, 14, 15, 24] </ref> and include checkpointing to memory rather than disk, using incremental or copy-on-write methods to reduce the amount of data saved, or creating "optimistic" local checkpoints at each process rather than synchronizing for a global checkpoint. The SPMD model makes this optimistic checkpointing very easy.
Reference: [25] <author> Luis Silva, Bart Veer, and Jo~ao Silva. </author> <title> Checkpointing SPMD applications on transputer networks. </title> <booktitle> In Proceedings of the Scalable High Performance Computing Conference, </booktitle> <pages> pages 694-701, </pages> <month> May </month> <year> 1994. </year> <month> 34 </month>
Reference-contexts: Another system, designed by Leon, Fisher, and Steenkiste [13], is specifically tailored to checkpoint and restart multicomputer applications written in PVM. All of these systems depend on machine-specific code, however, and none provides checkpoints that are portable within a heterogeneous environment. Silva, Veer, and Silva <ref> [25] </ref> have developed an application level checkpointing system for distributed programs. Their primary focus is also to minimize the cost of individual checkpoints. Some studies such as [6], however, have suggested that checkpointing generally 28 tends to be an inexpensive operation. Therefore, our fault tolerance package focuses on other issues.
Reference: [26] <author> John W. Young. </author> <title> A first order approximation to the optimum checkpoint interval. </title> <journal> Com--munications of the ACM, </journal> <volume> 17(9) </volume> <pages> 530-531, </pages> <month> September </month> <year> 1974. </year> <month> 35 </month>
Reference-contexts: Using this formula the expected runtime of a program can be computed based on the time to checkpoint, the total runtime if there are no failures, and an estimate of the failure rate. For additional mathematical treatments of program runtimes in the presence of failures, see <ref> [11, 26] </ref>. In order to get a general idea of the costs of our checkpointing package, short, successful runs of the Dome molecular dynamics application, md, were timed. The md application is based on a CM-Fortran program developed at the Pittsburgh Supercomputing Center.
References-found: 26

