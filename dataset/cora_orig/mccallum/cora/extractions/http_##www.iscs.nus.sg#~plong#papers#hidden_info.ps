URL: http://www.iscs.nus.sg/~plong/papers/hidden_info.ps
Refering-URL: 
Root-URL: 
Title: Simulating Access to Hidden Information while Learning  
Author: Peter Auer Philip M. Long 
Address: Klosterwiesgasse 32/2 A-8010 Graz, Austria  P.O. Box 90129 Durham, NC 27708 USA  
Affiliation: Institute for Theoretical Computer Science Technische Universitat Graz  Computer Science Department Duke University  
Abstract: We introduce a new technique which enables a learner without access to hidden information to learn nearly as well as a learner with access to hidden information. We apply our technique to solve an open problem of Maass and Turan [18], showing that for any concept class F , the least number of queries sufficient for learning F by an algorithm which has access only to arbitrary equivalence queries is at most a factor of 1= log 2 (4=3) more than the least number of queries sufficient for learning F by an algorithm which has access to both arbitrary equivalence queries and membership queries. Previously known results imply that the 1= log 2 (4=3) in our bound is best possible. We describe analogous results for two generalizations of this model to function learning, and apply those results to bound the difficulty of learning in the harder of these models in terms of the difficulty of learning in the easier model. We bound the difficulty of learning unions of k concepts from a class F in terms of the difficulty of learning F . We bound the difficulty of learning in a noisy environment for deterministic algorithms in terms of the difficulty of learning in a noise-free environment. We apply a variant of our technique to develop an algorithm transformation that allows probabilistic learning algorithms to nearly optimally cope with noise. A second variant enables us to improve a general lower bound of Turan [19] for the PAC-learning model (with queries). Finally, we show that logarithmically many membership queries never help to obtain computationally efficient learning algorithms. fl Supported by Air Force Office of Scientific Research grant F49620-92-J-0515. Most of this work was done while this author was at TU Graz supported by a Lise Meitner Fellowship from the Fonds zur Forderung der wissenschaftlichen Forschung (Austria). 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. Angluin. </author> <title> Queries and concept learning. </title> <journal> Machine Learning, </journal> <volume> 2 </volume> <pages> 319-342, </pages> <year> 1988. </year>
Reference-contexts: In Section 6, we describe a general bound on the usefulness of boolean queries in designing computationally efficient algorithms. 2 On-line learning of concepts with and without boolean queries In the on-line learning model <ref> [1] </ref> (also often called the exact learning model) the learner has to learn a function f from some domain X to f0; 1g (called a target concept) from some class F f0; 1g X (called a concept class). The learner's interaction with its environment is modeled with queries.
Reference: [2] <author> D. Angluin and M. Kharitonov. </author> <booktitle> When won't membership queries help? In Proceedings of the 23rd Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 444-454, </pages> <address> New Orleans, </address> <month> May </month> <year> 1991. </year> <note> ACM. </note>
Reference-contexts: Our result shows that this is not the case. Angluin and Kharitonov <ref> [2] </ref> gave several natural examples of specific concept classes for which polynomially many membership queries did not help to obtain computationally efficient learning algorithms, modulo cryptographic assumptions. 3 The VC-dimension [21] of a class F is defined by VCdim (F ) = maxfd : 9x 1 ; :::; x d 2 <p> PAC learning using only boolean queries was studied by Kulkarni, Mitter and Tsitsiklis [13]. 6 Boolean queries and computa tionally efficient algorithms To discuss issues of computational efficiency, it is useful to chose an encoding scheme for elements of X and elements of F (see, e.g. <ref> [2] </ref>). For each n and s, an encoding scheme gives rise to the set X n of all elements of X whose encoding has length at most n and F s , the corresponding set for F and s. We assume boolean queries take constant time.
Reference: [3] <author> P. </author> <title> Auer and P.M. Long. Structural results for on-line learning models with and without queries, </title> <note> 1993. Submitted. </note>
Reference-contexts: Clearly all such additional information makes the task of the learner easier, but our results show that learning doesn't become much easier. We introduce our technique by tailoring it to what we think are the most interesting cases. More applications of the technique are given in <ref> [3] </ref>. Since queries are often substantially more expensive than computation time in practice, in this paper our primary focus is on the number of queries required by learning algorithms. The paper is organized as follows. <p> Also, it can be trivially generalized to functions with larger ranges, and to methods of combining elements of F other than taking ORs (see <ref> [3] </ref>). One obtains a more realistic model of learning if the information given to the learner is sometimes incorrect.
Reference: [4] <author> P. Auer, P.M. Long, W. Maass, and G.J. Woegin-ger. </author> <title> On the complexity of function learning. </title> <booktitle> The 1993 Workshop on Computational Learning Theory, </booktitle> <year> 1993. </year>
Reference-contexts: In one alternative (called weak reinforcement in <ref> [4] </ref>), the algorithm only discovers some x for which h (x) 6= f (x), but does not find out the value of f (x). This type of reinforcement is sometimes all that is available, for example in some control problems. <p> If the algorithm is allowed boolean queries on top of weak equivalence queries, denote the optimal number of queries required for learning F by opt EB;weak (F ). In a second alternative (called strong reinforcement in <ref> [4] </ref>), when the algorithm makes an equivalence query h for which h 6= f , the algorithm receives an x for which h (x) 6= f (x), and also receives f (x). This type of reinforcement also occurs naturally, for example in weather prediction. <p> Theorem 3.1 If F Y X , then opt E;strong (F ) opt EB;strong (F ) log 2 4=3 opt E;weak (F ) 1:39jY jopt EB;weak (F ); (2) opt E;weak (F ) 2 opt EB;weak (F ) 1: (3) A result similar to (1), but weaker, was proved in <ref> [4] </ref>. Of course, Theorem 2.3 implies that the constant 1= log 2 3 of (1) is optimal.
Reference: [5] <author> G. Benedek and A. Itai. </author> <title> Learnability with respect to fixed distributions. </title> <booktitle> Theoretical Computer Science 86(2) </booktitle> <pages> 377-389, </pages> <year> 1991. </year>
Reference-contexts: Then using similar techniques as above, together with by now standard Chernov-bound techniques from <ref> [6, 5] </ref>, one can prove that opt P (F; *; ffi) = O ((opt PB (F; *=2; ffi=2) + log (1=ffi))=*): If opt PM is defined similarly where membership queries replace boolean queries, Eisenberg and Rivest [11] showed that for all F with a certain property, opt PM (F; *; ffi)
Reference: [6] <author> A. Blumer, A. Ehrenfeucht, D. Haussler, and M.K. Warmuth. </author> <title> Learnability and the Vapnik-Chervonenkis dimension. </title> <journal> JACM, </journal> <volume> 36(4) </volume> <pages> 929-965, </pages> <year> 1989. </year>
Reference-contexts: Let us call the resulting class OR k (F ). Almost tight bounds on the PAC learning sample complexity of OR k (F ) in terms of k and the sample complexity of F have been obtained <ref> [6] </ref>, but the techniques used apparently cannot be applied to bound the relative dif ficulty of on-line learning of OR k (F ), and this problem had remained open. Using our technique, we obtain the following result. <p> There are well known lower and upper bounds on the number of random examples necessary for learning: the upper bounds are O VCdim (F )* 1 log * 1 + * 1 log ffi 1 <ref> [6] </ref> VCdim (F )* 1 log ffi 1 [12], and the lower bound [10] is VCdim (F )* 1 + * 1 log ffi 1 . <p> By taking logarithms and solving for M , we get M log 2 4=3 which, adding the number of random examples, implies the lemma. 2 The following lemma's proof uses ideas from <ref> [6, 19] </ref>. Lemma 5.5 Choose 0 * 1 and 0 ffi 1. <p> Then using similar techniques as above, together with by now standard Chernov-bound techniques from <ref> [6, 5] </ref>, one can prove that opt P (F; *; ffi) = O ((opt PB (F; *=2; ffi=2) + log (1=ffi))=*): If opt PM is defined similarly where membership queries replace boolean queries, Eisenberg and Rivest [11] showed that for all F with a certain property, opt PM (F; *; ffi)
Reference: [7] <author> N.H. Bshouty, S.A. Goldman, T.R. Hancock, and S. Matar. </author> <title> Asking questions to minimize errors. </title> <booktitle> The 1993 Workshop on Computational Learning Theory, </booktitle> <year> 1993. </year>
Reference-contexts: We say that an algorithm for F is efficient if the time required for learning any function f 2 F is bounded by a polynomial in the length of the encoding of the longest counterexample received and the encoding of f . Bshouty, Goldman, Hancock and Matar <ref> [7] </ref>, for many concrete classes F , proved tight bounds on the number of equivalence queries required by an algorithm that learns arbitrary functions in F using polynomially many membership queries. Their upper bounds were obtained using efficient algorithms.
Reference: [8] <author> N. Cesa-Bianchi, Y. Freund, D. Helmbold, and M.K. Warmuth. </author> <title> On-line prediction and conversion strategies. </title> <booktitle> The 1993 IMA European conference on Computational Learning Theory, </booktitle> <year> 1993. </year>
Reference-contexts: The proof of Theorem 2.1 thus gives the following result essentially without modification. Theorem 3.5 If F f0; 1g X then opt E (F; ) log 2 4=3 Cesa-Bianchi, et al <ref> [8] </ref> independently obtained a similar result which implies an improvement on Theorem 3.5 in which the constant is 4:41. Theorem 3.5 is optimal to within a constant factor since opt E (F; ) 2 + opt E (F; 0) [16].
Reference: [9] <author> N. Cesa-Bianchi, Y. Freund, D.P. Helmbold, D. Haussler, R.E. Schapire, and M.K. Warmuth. </author> <title> How to use expert advice. </title> <booktitle> Proceedings of the 25th ACM Symposium on the Theory of Computation, </booktitle> <year> 1993. </year>
Reference-contexts: Theorem 4.1 For any F f0; 1g X , and any ff; fi &gt; 0 with ff + fi &lt; 1, opt ER (F; ) 2 ln ( 2 2 ln ( 2 : Straightforward application of recent results on combining the predictions of experts <ref> [22, 16, 23, 9] </ref> yield bounds in terms of jF j instead of opt ER (F; 0). Choosing appropriate ff and fi we get the following bounds. <p> r (1 ff fi)) ; where r is the weight of the copies evaluating to 1 divided by the total weight of all copies. 5 (Observe that P ff;fi (1 r) = 1 P ff;fi (r).) 5 Essentially the same "transfer function" was used in a differ ent context in <ref> [22, 9] </ref>. Observe that the master algorithm splits all those sub-algorithms which predicted incorrectly for the last example (x t ; y t ), without regard to whether its own prediction was correct or not. <p> Thus ff opt E (F;0) fi t=1 because the weight of the special copy is at least ff opt E (F;0) fi . Some calculations, using the fact (see <ref> [9] </ref>) that 8r; 2 ln ( 2 1+ff+fi )P ff;fi (r) ln (1 r (1 ff fi)), complete the proof. 2 5 PAC learning with queries In the PAC learning model [20] the learner has to, with high probability, give a good approximation to a target concept f from some concept
Reference: [10] <author> A. Ehrenfeucht, D. Haussler, M. Kearns, and L.G. Valiant. </author> <title> A general lower bound on the number of examples needed for learning. </title> <journal> Information and Computation, </journal> <volume> 82(3) </volume> <pages> 247-251, </pages> <year> 1989. </year>
Reference-contexts: There are well known lower and upper bounds on the number of random examples necessary for learning: the upper bounds are O VCdim (F )* 1 log * 1 + * 1 log ffi 1 [6] VCdim (F )* 1 log ffi 1 [12], and the lower bound <ref> [10] </ref> is VCdim (F )* 1 + * 1 log ffi 1 . In this section we prove a lower bound for a variant of the PAC learning model proposed by Turan [19], where the learner may request random examples, ask equivalence queries, and ask boolean queries.
Reference: [11] <author> B. Eisenberg and R.L. Rivest. </author> <title> On the sample complexity of PAC-learning using random and chosen examples. </title> <booktitle> The 1990 Workshop on Computational Learning Theory, </booktitle> <pages> pages 154-162, </pages> <year> 1990. </year>
Reference-contexts: Then using similar techniques as above, together with by now standard Chernov-bound techniques from [6, 5], one can prove that opt P (F; *; ffi) = O ((opt PB (F; *=2; ffi=2) + log (1=ffi))=*): If opt PM is defined similarly where membership queries replace boolean queries, Eisenberg and Rivest <ref> [11] </ref> showed that for all F with a certain property, opt PM (F; *; ffi) = (log (1=ffi)=*).
Reference: [12] <author> D. Haussler, N. Littlestone, and M.K. Warmuth. </author> <title> Predicting f0; 1g-functions on randomly drawn points. </title> <type> Technical Report UCSC-CRL-90-54, </type> <institution> University of California Santa Cruz, Computer Research Laboratory, </institution> <month> December </month> <year> 1990. </year> <note> To appear in Information and Computation. </note>
Reference-contexts: There are well known lower and upper bounds on the number of random examples necessary for learning: the upper bounds are O VCdim (F )* 1 log * 1 + * 1 log ffi 1 [6] VCdim (F )* 1 log ffi 1 <ref> [12] </ref>, and the lower bound [10] is VCdim (F )* 1 + * 1 log ffi 1 .
Reference: [13] <author> S.R. Kulkarni, S.K. Mitter, and J.N. Tsitsiklis. </author> <title> Active learning using arbitrary binary valued queries. </title> <journal> Machine Learning, </journal> <volume> 11(1), </volume> <year> 1993. </year>
Reference-contexts: PAC learning using only boolean queries was studied by Kulkarni, Mitter and Tsitsiklis <ref> [13] </ref>. 6 Boolean queries and computa tionally efficient algorithms To discuss issues of computational efficiency, it is useful to chose an encoding scheme for elements of X and elements of F (see, e.g. [2]).
Reference: [14] <author> N. Littlestone. </author> <title> Learning quickly when irrelevant attributes abound: a new linear-threshold algorithm. </title> <journal> Machine Learning, </journal> <volume> 2 </volume> <pages> 285-318, </pages> <year> 1988. </year>
Reference-contexts: in Section 4.) In this section we compare the performance of the optimal learning algorithm which asks equivalence queries and boolean queries with the performance of the optimal learning algorithm which uses only equivalence queries. (The model in which only equivalence queries are allowed is equivalent to the mistake-bound model <ref> [14] </ref>.) For any concept class F we denote by opt EB (F ) the performance of an optimal learning algorithm for F which uses equivalence and boolean queries and we denote by opt E (F ) the performance of an optimal learning algorithm for F which uses only equivalence queries.
Reference: [15] <author> N. Littlestone. </author> <title> Mistake Bounds and Logarithmic Linear-threshold Learning Algorithms. </title> <type> PhD thesis, </type> <institution> UC Santa Cruz, </institution> <year> 1989. </year>
Reference: [16] <author> N. Littlestone and M.K. Warmuth. </author> <title> The weighted majority algorithm. </title> <type> Technical Report UCSC-CRL-91-28, </type> <institution> UC Santa Cruz, </institution> <month> October </month> <year> 1991. </year> <note> To appear, Information and Computation. </note>
Reference-contexts: The copies that predicted correctly for x fl are not modified and they don't receive a counterexample. They don't change their states and propose the same hypotheses as before. Since P P i:h i (x fl )6=h (x fl ) w i , arguing as in <ref> [16] </ref> we have for the modified weights w 0 i that P i P i + i:h i (x fl )6=h (x fl ) w 0 = 1 P P = 3 P 4 i:h i (x fl )=h (x fl ) w i 4 i:h i (x fl )6=h (x <p> One may simulate knowledge of hidden information using a tree like the above, "expanding" nodes when the subalgorithm needs information hidden from the master algorithm. The combination of the hypotheses of the leaves is done in the style of Weighted Majority <ref> [16] </ref>, but the main difference with the Weighted Majority algorithm is that the Weighted Majority algorithm uses a fixed set of subalgorithms, while our algorithm dynamically creates subalgorithms depending on previous outcomes to queries. 3 More applications of the basic technique When generalizing equivalence queries to functions taking on potentially more <p> Theorem 3.5 is optimal to within a constant factor since opt E (F; ) 2 + opt E (F; 0) <ref> [16] </ref>. Optimizing for the constant on the term in Theorem 3.5 yields the following. <p> Theorem 4.1 For any F f0; 1g X , and any ff; fi &gt; 0 with ff + fi &lt; 1, opt ER (F; ) 2 ln ( 2 2 ln ( 2 : Straightforward application of recent results on combining the predictions of experts <ref> [22, 16, 23, 9] </ref> yield bounds in terms of jF j instead of opt ER (F; 0). Choosing appropriate ff and fi we get the following bounds.
Reference: [17] <author> W. Maass. </author> <title> On-line learning with an oblivious environment and the power of randomization. </title> <booktitle> The 1991 Workshop on Computational Learning Theory, </booktitle> <pages> pages 167-175, </pages> <year> 1991. </year>
Reference-contexts: The model of this section is due to Maass <ref> [17] </ref>. <p> Proof of Theorem 4.1: We prove the first inequality. The second follows from the fact <ref> [17] </ref> that opt E (F; 0) 2opt ER (F; 0). The proof is like that of Theorem 2.1, except for the following differences. 1. The master algorithm A ER runs copies of an opti mal learning algorithm A E for the noise-free case. 2.
Reference: [18] <author> W. Maass and G. Turan. </author> <title> Lower bound methods and separation results for on-line learning models. </title> <journal> Machine Learning, </journal> <volume> 9 </volume> <pages> 107-145, </pages> <year> 1992. </year>
Reference-contexts: Theorem 2.1 If F f0; 1g X then opt E (F ) log 2 4=3 This result solves an open problem posed by Maass and Turan <ref> [18] </ref>. <p> a class F is defined by VCdim (F ) = maxfd : 9x 1 ; :::; x d 2 X; f (f (x 1 ); :::; f (x d )) : f 2 F g = f0; 1g d g: The fact that opt E (F ) VCdim (F ) <ref> [18] </ref> trivially yields the following corollary. Corollary 2.2 If F f0; 1g X , then opt EB (F ) log 2 (4=3)VCdim (F ): This improves on the opt EB (F ) VCdim (F )=7 bound of Maass and Turan.
Reference: [19] <author> G. Turan. </author> <title> Lower bounds for PAC learning with queries. </title> <booktitle> The 1993 Workshop on Computational Learning Theory, </booktitle> <year> 1993. </year>
Reference-contexts: Our bound improves on the constant of a recent result of Turan <ref> [19] </ref>, and our proof is somewhat simpler as well. <p> In this section we prove a lower bound for a variant of the PAC learning model proposed by Turan <ref> [19] </ref>, where the learner may request random examples, ask equivalence queries, and ask boolean queries. Then the learner has to output with high probability a good approximation of the target concept. <p> Then the learner has to output with high probability a good approximation of the target concept. The performance of the learner is measured by the number of random examples plus the number of equivalence queries plus the number of boolean queries. Turan <ref> [19] </ref> showed that the VC-dimension of the concept class (up to a constant factor) is a lower bound on the learning complexity in this model. <p> In this section, we apply our technique to improve on the constant of Turan's bound, using a somewhat simpler proof. For previous results in the PAC learning model and variants thereof, see the references in <ref> [19] </ref>. <p> By taking logarithms and solving for M , we get M log 2 4=3 which, adding the number of random examples, implies the lemma. 2 The following lemma's proof uses ideas from <ref> [6, 19] </ref>. Lemma 5.5 Choose 0 * 1 and 0 ffi 1.
Reference: [20] <author> L.G. Valiant. </author> <title> A theory of the learnable. </title> <journal> Communications of the ACM, </journal> <volume> 27(11) </volume> <pages> 1134-1142, </pages> <year> 1984. </year>
Reference-contexts: Initially the single copy is the special one. The copies and their weights are maintained by A E in the following way. eralizes to boolean queries. 3 In fact, they proved the difficulty of the easier problem of PAC learning with membership queries <ref> [20] </ref>. * If some copy A EB i wants to ask a boolean query Q, this copy is split into two copies, one copy receives the answer YES and the other copy receives the answer NO. The weight w i =2 is assigned to both copies. <p> Some calculations, using the fact (see [9]) that 8r; 2 ln ( 2 1+ff+fi )P ff;fi (r) ln (1 r (1 ff fi)), complete the proof. 2 5 PAC learning with queries In the PAC learning model <ref> [20] </ref> the learner has to, with high probability, give a good approximation to a target concept f from some concept class F f0; 1g X .
Reference: [21] <author> V.N. Vapnik and A.Y. Chervonenkis. </author> <title> On the uniform convergence of relative frequencies of events to their probabilities. </title> <journal> Theory of Probability and its Applications, </journal> <volume> 16(2) </volume> <pages> 264-280, </pages> <year> 1971. </year>
Reference-contexts: In Section 4 we give a nearly optimal randomized algorithm for on-line learning at a high level of noise. In Section 5 we exploit our technique to get lower bounds on the learning complexity in the PAC learning model with additional queries in terms of the Vapnik-Chervonenkis <ref> [21] </ref> dimension of the class, a well-known measure of the "richness" of the class. Our bound improves on the constant of a recent result of Turan [19], and our proof is somewhat simpler as well. <p> Our result shows that this is not the case. Angluin and Kharitonov [2] gave several natural examples of specific concept classes for which polynomially many membership queries did not help to obtain computationally efficient learning algorithms, modulo cryptographic assumptions. 3 The VC-dimension <ref> [21] </ref> of a class F is defined by VCdim (F ) = maxfd : 9x 1 ; :::; x d 2 X; f (f (x 1 ); :::; f (x d )) : f 2 F g = f0; 1g d g: The fact that opt E (F ) VCdim (F
Reference: [22] <author> V. Vovk. </author> <title> Aggregating strategies. </title> <booktitle> In Proceedings of the 3nd Workshop on Computational Learning Theory, </booktitle> <pages> pages 371-383. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1990. </year>
Reference-contexts: Theorem 4.1 For any F f0; 1g X , and any ff; fi &gt; 0 with ff + fi &lt; 1, opt ER (F; ) 2 ln ( 2 2 ln ( 2 : Straightforward application of recent results on combining the predictions of experts <ref> [22, 16, 23, 9] </ref> yield bounds in terms of jF j instead of opt ER (F; 0). Choosing appropriate ff and fi we get the following bounds. <p> r (1 ff fi)) ; where r is the weight of the copies evaluating to 1 divided by the total weight of all copies. 5 (Observe that P ff;fi (1 r) = 1 P ff;fi (r).) 5 Essentially the same "transfer function" was used in a differ ent context in <ref> [22, 9] </ref>. Observe that the master algorithm splits all those sub-algorithms which predicted incorrectly for the last example (x t ; y t ), without regard to whether its own prediction was correct or not.
Reference: [23] <author> V. Vovk. </author> <title> Universal forecasting algorithms. </title> <journal> Information and Computation, </journal> <volume> 96(2) </volume> <pages> 245-277, </pages> <year> 1992. </year>
Reference-contexts: Theorem 4.1 For any F f0; 1g X , and any ff; fi &gt; 0 with ff + fi &lt; 1, opt ER (F; ) 2 ln ( 2 2 ln ( 2 : Straightforward application of recent results on combining the predictions of experts <ref> [22, 16, 23, 9] </ref> yield bounds in terms of jF j instead of opt ER (F; 0). Choosing appropriate ff and fi we get the following bounds.
References-found: 23

