URL: http://www.cs.ucsb.edu/oocsb/papers/pldi94.ps
Refering-URL: http://www.csd.uu.se/~thomasl/wpo/oo-compilation-papers.html
Root-URL: 
Abstract: Object-oriented programs are difficult to optimize because they execute many dynamically-dispatched calls. These calls cannot easily be eliminated because the compiler does not know which callee will be invoked at runtime. We have developed a simple technique that feeds back type information from the runtime system to the compiler. With this type feedback, the compiler can inline any dynamically-dispatched call. Our compiler drastically reduces the call frequency of a suite of large SELF applications (by a factor of 3.6) and improves performance by a factor of 1.7. We believe that type feedback could significantly reduce call frequencies and improve performance for most other object-oriented languages (statically-typed or not) as well as for languages with type-dependent operations such as generic arithmetic. 
Abstract-found: 1
Intro-found: 1
Reference: [APS93] <author> Ole Agesen, Jens Palsberg, and Michael I. Schwartz-bach. </author> <title> Type Inference of SELF: Analysis of Objects with Dynamic and Multiple Inheritance. </title> <booktitle> In ECOOP '93 Conference Proceedings, p. </booktitle> <pages> 247-267. </pages> <address> Kaiserslautern, Germany, </address> <month> July </month> <year> 1993. </year>
Reference-contexts: disadvantage of such a system is that it still leaves the procedure call overhead 9 even for very simple callees, does not optimize polymorphic calls, and precludes extensibility through dynamic linking. (Srivastava and Wall [SW92] perform more extensive link-time optimization but do not optimize calls.) Some type inference systems (e.g., <ref> [APS93] </ref>, [PR94]) can determine the concrete receiver types of message sends. Compared to type feedback, a type inferencer may provide more precise information since it may be able to prove that only a single receiver type is possible at a given call site.
Reference: [App88] <institution> Apple Computer, Inc. </institution> <note> Object Pascal Users Manual. Cupertino, </note> <year> 1988. </year>
Reference-contexts: Based on measurements of C++ programs, Calder and Grunwald [CG94] argue that type feedback would be beneficial for C++; their proposed if conversion appears to be identical to inline caching [DS84] and PIC-based inlining [HCU91], except that it is performed statically. The Apple Object Pascal linker <ref> [App88] </ref> turned dynamically-dispatched calls into statically-bound calls if a type had exactly one implementation (e.g., the system contained only a Carte-sianPoint class and no PolarPoint class).
Reference: [CGZ94] <author> Brad Calder, Dirk Grunwald, and Benjamin Zorn. </author> <title> Quantifying Behavioral Differences Between C and C++ Programs. </title> <type> Technical Report CU-CS-698-94, </type> <institution> University of Colorado, Boulder, </institution> <month> January </month> <year> 1994. </year>
Reference-contexts: C++s execution behavior (and language philosophy) is much further away from SELF, but we believe it will nevertheless benefit from type feedback. First, measurements of large C++ programs <ref> [CGZ94] </ref> have shown that calls are almost five times more frequent in C++ programs than in C programs, and that the average size of a C++ virtual function is only 30 instructions, six times smaller than the average C function. <p> To give a concrete example, the DOC document editor measured in <ref> [CGZ94] </ref> performs a virtual call every 75 instructions; given that a C++ virtual call uses about 5 instructions and usually incurs two load stalls and a stall for the indirect function call, we estimate that this program spends roughly 10% of its time dispatching virtual functions.
Reference: [CG94] <author> Brad Calder and Dirk Grunwald. </author> <title> Reducing Indirect Function Call Overhead in C++ Programs. </title> <booktitle> In 21st Annual ACM Symposium on Principles of Programming Languages, p. </booktitle> <pages> 397-408, </pages> <month> January </month> <year> 1994. </year>
Reference-contexts: As a result, its speedup over a system without type feedback was modest (about 11%). Based on measurements of C++ programs, Calder and Grunwald <ref> [CG94] </ref> argue that type feedback would be beneficial for C++; their proposed if conversion appears to be identical to inline caching [DS84] and PIC-based inlining [HCU91], except that it is performed statically.
Reference: [Cha92] <author> Craig Chambers, </author> <title> The Design and Implementation of the SELF Compiler, an Optimizing Compiler for Object-Oriented Programming Languages. </title> <type> Ph.D. Thesis, </type> <institution> Stan-ford University, </institution> <month> April </month> <year> 1992 </year>
Reference-contexts: Another optimization, uncommon branch elimination, is more aggressive and preserves the improved dataow information throughout the caller. Uncommon branch elimination was first suggested to us by John Maloney and was implemented in Chambers SELF-91 compiler <ref> [Cha92] </ref> and (in a somewhat different and more aggressive form) in the SELF-93 compiler described in the next section. The main idea is that the optimized code handles only the predicted cases. <p> A simple usage-count based register allocator computes the register assignments, and the final machine code is generated in a single pass over the intermediate graph. The main differences between SELF-93 and the SELF-91 compiler described by Chambers <ref> [Cha92] </ref> are that we have substituted type feedback for iterative type analysis, and that our back end is less ambitious. As a result, SELF-93 is considerably simpler (11,000 vs. 4 26,000 lines of C++). However, compared to SELF-91, SELF-93 has several shortcomings: Inferior local code quality. <p> Since the compiler does not perform type analysis or full dataow analysis, a value may be tested repeatedly for its type even though only the first test is necessary. It is hard to estimate the performance impact of these shortcomings. However, based on Chambers analysis of the SELF-91 compiler <ref> [Cha92] </ref> and an inspection of the compiled code of several programs, we believe that they slow down the large object-oriented programs measured in this study by at least 10%. (For programs with small integer loops, the overhead can be much higher.) Therefore, the performance of type feedback as reported in the <p> SELF-93 nofeedback Same as SELF-93, but without type feedback and recompilation; all methods are always optimized from the beginning. SELF-91 Chambers SELF compiler <ref> [Cha92] </ref> using iterative type analysis; all methods are always optimized from the beginning. This compiler has been shown to achieve excellent performance for smaller programs. <p> Figure 10 shows the results. For DeltaBlue and Richards, SELF-93 runs 2.2 and 3.3 times faster than ParcPlace Smalltalk (generally regarded as the fastest commercially available Smalltalk system) even though SELFs language model is purer and thus harder to implement efficiently <ref> [Cha92] </ref>. For Richards, SELF-93 runs 2.6 times faster than an equivalent CommonLisp program compiled with maximum optimization and minimum safety (i.e., the Lisp code would not detect some runtime errors). In conclusion, for these two programs SELF-93 runs two to three times faster than languages with roughly comparable semantics.
Reference: [Cha93] <author> Craig Chambers. </author> <title> The Cecil Language - Specification and Rationale. </title> <type> Technical Report CSE-TR-93-03-05, </type> <institution> University of Washington, </institution> <year> 1993. </year>
Reference: [CUL89] <author> Craig Chambers, David Ungar, and Elgin Lee. </author> <title> An Efficient Implementation of SELF, a Dynamically-Typed Object-Oriented Language Based on Prototypes. </title> <booktitle> In OOPSLA 89 Conference Proceedings, p. </booktitle> <pages> 49-70, </pages> <address> New Orleans, LA, </address> <month> October </month> <year> 1989. </year> <note> Published as SIGPLAN Notices 24(10), </note> <month> October </month> <year> 1989. </year>
Reference-contexts: The front end of the compiler performs a variety of optimizations that are necessary to achieve good performance with pure object-oriented languagesinlining (based on type feedback), customization <ref> [CUL89] </ref>, and splitting [CU90]and generates a graph of intermediate code nodes. The back end performs only very few optimizations on the intermediate code before generating machine code. <p> Other systems have used some form of runtime type information for optimization, although not to the same extent as SELF-93 and not in combination with recompilation. For example, Mitchells system [Mit70] specialized arithmetic operations to the runtime types of the operands (similar to SELF-89s customization <ref> [CUL89] </ref>). Similarly, several APL compilers created specialized code for certain expressions (e.g. [Joh79], [Dyk77], [GW78]). Of these systems, the HP APL compiler [Dyk77] came closest to customization and type feedback. The system compiled code on a statement-by-statement basis.
Reference: [CU90] <author> Craig Chambers and David Ungar. </author> <title> Iterative Type Analysis and Extended Message Splitting: Optimizing Dynamically-Typed Object-Oriented Programs. </title> <booktitle> In Proceedings of the SIGPLAN 90 Conference on Programming Language Design and Implementation, p. </booktitle> <pages> 150-164, </pages> <address> White Plains, NY, </address> <month> June </month> <year> 1990. </year> <note> Published as SIGPLAN Notices 25(6), </note> <month> June </month> <year> 1990. </year>
Reference-contexts: Inlining not only eliminates the calling overhead but also enables the compiler to optimize the inlined code using dataow information particular to this call site. Some optimizations can enhance the benefits of inlining. Splitting <ref> [CU90] </ref> copies code following the if statement into the branches of the if, where it can profit from the more precise dataow (or type) information that is specific to the branches of the if.
Reference: [CU93] <author> Bay-Wei Chang and David Ungar. </author> <title> Animation: From cartoons to the user interface. </title> <booktitle> User Interface Software and Technology Conference Proceedings, </booktitle> <address> Atlanta, GA, </address> <month> November </month> <year> 1993. </year>
Reference: [CM+92] <author> Pohua P. Chang, Scott A. Mahlke, William Y. Chen, and Wen-Mei W. Hwu. </author> <title> Profile-guided automatic inline expansion for C programs. </title> <booktitle> SoftwarePractice and Experience 22 (5): </booktitle> <pages> 349-369, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: Studies of inlining for more conventional languages like C or Fortran have found that it often does not significantly increase execution speed but tends to significantly increase code size (e.g., [DH88], [HwC89], [CHT91], <ref> [CM+92] </ref>, [Hall91]). In contrast, inlining in SELF results in both significant speedups and only very moderate code growth.
Reference: [CK93] <author> Robert F. Cmelik and David Keppel. Shade: </author> <title> A Fast Instruction-Set Simulator for Execution Profiling. </title> <type> Technical Report SMLI TR-93-12, </type> <institution> Sun Microsystems Laboratories, </institution> <year> 1993. </year> <note> Also published as Technical Report CSE-TR-93-06-06, </note> <institution> University of Washington, </institution> <year> 1993. </year> <month> 10 </month>
Reference-contexts: techniques described in [DS84]) C/C++ GNU C and C++ compilers, version 2.4.5, using -O2 optimization Lisp Sun CommonLisp 4.0 using full optimization Table 1: Systems used for benchmarking 4.1 Methodology To accurately measure execution times, the programs were run under a SPARC simulator based on the Spa [Irl91] and Shade <ref> [CK93] </ref> tracing tools and the Dinero cache simulator [Hill87]. The simulator models the Cypress CY7C601 implementation of the SPARC architecture, i.e., the chip used in the SPARCstation-2 workstation. The simulator also accurately models the memory system of a SPARCstation-2, with the exception of the cache organization.
Reference: [HwC89] <author> W. W. Hwu and P. P. Chang. </author> <title> Inline function expansion for compiling C programs. </title> <booktitle> In Proceedings of the SIGPLAN 89 Conference on Programming Language Design and Implementation, p. </booktitle> <pages> 246-57, </pages> <address> Portland, OR, </address> <month> June </month> <year> 1989. </year> <note> Published as SIGPLAN Notices 24(7), </note> <month> July </month> <year> 1989. </year>
Reference-contexts: Studies of inlining for more conventional languages like C or Fortran have found that it often does not significantly increase execution speed but tends to significantly increase code size (e.g., [DH88], <ref> [HwC89] </ref>, [CHT91], [CM+92], [Hall91]). In contrast, inlining in SELF results in both significant speedups and only very moderate code growth.
Reference: [Irl91] <author> Gordon Irlam. </author> <title> SPASPARC analyzer tool set. </title> <note> Available via ftp from cs.adelaide.edu.au, </note> <year> 1991. </year>
Reference-contexts: system (based on techniques described in [DS84]) C/C++ GNU C and C++ compilers, version 2.4.5, using -O2 optimization Lisp Sun CommonLisp 4.0 using full optimization Table 1: Systems used for benchmarking 4.1 Methodology To accurately measure execution times, the programs were run under a SPARC simulator based on the Spa <ref> [Irl91] </ref> and Shade [CK93] tracing tools and the Dinero cache simulator [Hill87]. The simulator models the Cypress CY7C601 implementation of the SPARC architecture, i.e., the chip used in the SPARCstation-2 workstation. The simulator also accurately models the memory system of a SPARCstation-2, with the exception of the cache organization.
Reference: [Joh79] <author> Ronald L. Johnston. </author> <title> The Dynamic Incremental Compiler of APL"3000. In Proceedings of the APL 79 Conference. </title> <note> Published as APL Quote Quad 9(4), </note> <author> p. </author> <month> 82-87, </month> <year> 1979. </year>
Reference-contexts: For example, Mitchells system [Mit70] specialized arithmetic operations to the runtime types of the operands (similar to SELF-89s customization [CUL89]). Similarly, several APL compilers created specialized code for certain expressions (e.g. <ref> [Joh79] </ref>, [Dyk77], [GW78]). Of these systems, the HP APL compiler [Dyk77] came closest to customization and type feedback. The system compiled code on a statement-by-statement basis.
Reference: [KLS92] <author> Philip Koopman, Peter Lee, and Daniel Siewiorek. </author> <title> Cache behavior of combinator graph reduction. </title> <booktitle> ACM Transactions on Programming Languages and Systems 14 </booktitle> (2):265-297, April 1992. 
Reference-contexts: Write-allocate with subblock placement caches allocate a cache line when a store instruction references a location not currently residing in the cache. This organization is used in current workstations (e.g., the DECsta-tion 5000 series) and has been shown to be effective for programs with intensive heap allocation <ref> [KLS92] </ref>, [Rei93], [DTM94]. We do not use the original SPARCstation-2 cache configuration because it suffers from large variations in cache miss ratios caused by small differences in code and data positioning (we have observed variations of up to 15% of total execution time).
Reference: [LVC89] <author> Mark Linton, John Vlissides, and Paul Calder. </author> <title> Composing User Interfaces with Interviews. </title> <booktitle> IEEE Computer 22(2) </booktitle> <pages> 8-22, </pages> <month> February </month> <year> 1989. </year>
Reference-contexts: Third, we expect that C++ programmers will make even more use of virtual functions in the future as they become more familiar with object-oriented programming styles; for example, recent versions of the Interviews framework <ref> [LVC89] </ref> use virtual functions more frequently than previous versions.
Reference: [Mit70] <author> J. G. Mitchell, </author> <title> Design and Construction of Flexible and Efficient Interactive Programming Systems. </title> <type> Ph.D. Thesis, </type> <institution> Carnegie-Mellon University, </institution> <year> 1970. </year>
Reference-contexts: However, none of these systems predicted types adaptively as does SELF-93. Other systems have used some form of runtime type information for optimization, although not to the same extent as SELF-93 and not in combination with recompilation. For example, Mitchells system <ref> [Mit70] </ref> specialized arithmetic operations to the runtime types of the operands (similar to SELF-89s customization [CUL89]). Similarly, several APL compilers created specialized code for certain expressions (e.g. [Joh79], [Dyk77], [GW78]). Of these systems, the HP APL compiler [Dyk77] came closest to customization and type feedback.
Reference: [PR94] <author> Hemant D. Pande and Barbara G. Ryder. </author> <title> Static Type Determination for C++. </title> <type> Technical Report LCSR-TR-197a, </type> <institution> Rutgers University, </institution> <year> 1994. </year>
Reference-contexts: of such a system is that it still leaves the procedure call overhead 9 even for very simple callees, does not optimize polymorphic calls, and precludes extensibility through dynamic linking. (Srivastava and Wall [SW92] perform more extensive link-time optimization but do not optimize calls.) Some type inference systems (e.g., [APS93], <ref> [PR94] </ref>) can determine the concrete receiver types of message sends. Compared to type feedback, a type inferencer may provide more precise information since it may be able to prove that only a single receiver type is possible at a given call site.
Reference: [Rei93] <author> Mark Reinhold. </author> <title> Cache Performance of Garbage-Collected Programming Languages. </title> <type> Technical Report MIT/LCS/TR-581 (Ph.D. Thesis), </type> <institution> Massachusetts Institute of Technology, </institution> <month> September </month> <year> 1993. </year>
Reference-contexts: Write-allocate with subblock placement caches allocate a cache line when a store instruction references a location not currently residing in the cache. This organization is used in current workstations (e.g., the DECsta-tion 5000 series) and has been shown to be effective for programs with intensive heap allocation [KLS92], <ref> [Rei93] </ref>, [DTM94]. We do not use the original SPARCstation-2 cache configuration because it suffers from large variations in cache miss ratios caused by small differences in code and data positioning (we have observed variations of up to 15% of total execution time).
Reference: [SM+93] <author> Michael Sannella, John Maloney, Bjorn Freeman-Benson, and Alan Borning. </author> <title> Multi-way versus One-way Constraints in User Interfaces: Experience with the DeltaBlue Algorithm. </title> <booktitle> SoftwarePractice and Experience 23 (5): </booktitle> <pages> 529-566, </pages> <month> May </month> <year> 1993. </year>
Reference: [SW92] <author> Amitabh Srivastava and David Wall. </author> <title> A Practical System for Intermodule Code Optimization at Link Time. </title> <note> DEC WRL Research Report 92/6, </note> <month> December </month> <year> 1992. </year>
Reference-contexts: The disadvantage of such a system is that it still leaves the procedure call overhead 9 even for very simple callees, does not optimize polymorphic calls, and precludes extensibility through dynamic linking. (Srivastava and Wall <ref> [SW92] </ref> perform more extensive link-time optimization but do not optimize calls.) Some type inference systems (e.g., [APS93], [PR94]) can determine the concrete receiver types of message sends.
Reference: [US87] <author> David Ungar and Randall B. Smith. </author> <title> SELF: The Power of Simplicity. </title> <booktitle> In OOPSLA 87 Conference Proceedings, p. </booktitle> <pages> 227-241, </pages> <address> Orlando, FL, </address> <month> October </month> <year> 1987. </year> <note> Published as SIGPLAN Notices 22(12), </note> <month> December </month> <year> 1987. </year> <title> Also published in Lisp and Symbolic Computation 4(3), </title> <publisher> Kluwer Academic Publishers, </publisher> <month> June </month> <year> 1991. </year>
Reference-contexts: Pure object-oriented languages exacerbate this problem because every operation involves a dynamically-dispatched message send. For example, even very simple operations such as instance variable accesses, integer addition, and array accesses conceptually involve message sends in SELF <ref> [US87] </ref>, the programming language used for this study. Consequently, a pure object-oriented language like SELF offers an ideal test case for optimization techniques tackling the problem of frequent dynamically-dispatched calls. The rest of this paper describes our experience with a new optimization technique based on type feedback.
Reference: [Wall91] <author> David Wall. </author> <title> Predicting Program Behavior Using Real or Estimated Profiles. </title> <booktitle> In Proceedings of the SIGPLAN 91 Conference on Programming Language Design and Implementation, p. </booktitle> <pages> 59-70, </pages> <address> Toronto, Canada, </address> <month> June </month> <year> 1991. </year> <note> Published as SIGPLAN Notices 26(6), </note> <month> June </month> <year> 1991. </year>
Reference-contexts: The SELF-93 compiler described below implements both optimizations. Predicting future receiver types based on past receiver types is only an educated guess. Similar guesses are made by optimizing compilers that base decisions on execution profiles taken from previous runs <ref> [Wall91] </ref>. However, in our experience, type profiles are more stable than time profilesif a receiver type dominates a call site during one program execution, it also dominates during other executions.
Reference: [CHT91] <author> K. D. Cooper, M. W. Hall, and L. Torczon. </author> <title> An experiment with inline substitution. </title> <booktitle> SoftwarePractice and Experience 21 (6): </booktitle> <pages> 581-601, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: Studies of inlining for more conventional languages like C or Fortran have found that it often does not significantly increase execution speed but tends to significantly increase code size (e.g., [DH88], [HwC89], <ref> [CHT91] </ref>, [CM+92], [Hall91]). In contrast, inlining in SELF results in both significant speedups and only very moderate code growth.
Reference: [DH88] <author> Jack W. Davidson and Anne M. Holler. </author> <title> A study of a C function inliner. </title> <journal> SoftwarePractice and Experience 18(8): </journal> <pages> 775-90, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: Studies of inlining for more conventional languages like C or Fortran have found that it often does not significantly increase execution speed but tends to significantly increase code size (e.g., <ref> [DH88] </ref>, [HwC89], [CHT91], [CM+92], [Hall91]). In contrast, inlining in SELF results in both significant speedups and only very moderate code growth.
Reference: [DS84] <author> L. Peter Deutsch and Alan Schiffman. </author> <title> Efficient Implementation of the Smalltalk-80 System. </title> <booktitle> Proceedings of the 11th Symposium on the Principles of Programming Languages, </booktitle> <address> Salt Lake City, UT, </address> <year> 1984. </year>
Reference-contexts: SELF-91 Chambers SELF compiler [Cha92] using iterative type analysis; all methods are always optimized from the beginning. This compiler has been shown to achieve excellent performance for smaller programs. Smalltalk-80 ParcPlace Smalltalk-80 release 4.0, generally regarded as the fastest commercial Smalltalk system (based on techniques described in <ref> [DS84] </ref>) C/C++ GNU C and C++ compilers, version 2.4.5, using -O2 optimization Lisp Sun CommonLisp 4.0 using full optimization Table 1: Systems used for benchmarking 4.1 Methodology To accurately measure execution times, the programs were run under a SPARC simulator based on the Spa [Irl91] and Shade [CK93] tracing tools and <p> Since we are interested in the work done per type test sequence, the data excludes sends requiring no type test, i.e. sends whose receiver type was known with certainty. SELF-93-nofeedback executes some inlined type tests because it uses static type prediction <ref> [DS84] </ref> to predict the receiver type of certain very frequent messages. Static type prediction always predicts for a single type, except for sends to boolean receivers (true and false are two different types in SELF). Thus, the low average of 1.2 tests per send in SELF-93-nofeedback is not surprising. <p> A large fraction of call sites in C++ have this property [CG94][G+94], and it also holds in other object oriented programming languages (e.g., Smalltalk, SELF, Sather, and Eiffel); this is the reason that inline caching <ref> [DS84] </ref>, [HCU91] works well in these languages as an implementation of dynamic dispatch. Therefore, we expect type feedback to work well for these languages; the higher the frequency of dynamically-dispatched calls, the more beneficial type feedback could be. 6. <p> For example, Lisp systems usually inline the integer case of generic arithmetic and handle all other type combinations with a call to a routine in the runtime system. The Deutsch-Schiffman Smalltalk compiler was the first object-oriented system to predict integer receivers for common message names such as + <ref> [DS84] </ref>. However, none of these systems predicted types adaptively as does SELF-93. Other systems have used some form of runtime type information for optimization, although not to the same extent as SELF-93 and not in combination with recompilation. <p> As a result, its speedup over a system without type feedback was modest (about 11%). Based on measurements of C++ programs, Calder and Grunwald [CG94] argue that type feedback would be beneficial for C++; their proposed if conversion appears to be identical to inline caching <ref> [DS84] </ref> and PIC-based inlining [HCU91], except that it is performed statically. The Apple Object Pascal linker [App88] turned dynamically-dispatched calls into statically-bound calls if a type had exactly one implementation (e.g., the system contained only a Carte-sianPoint class and no PolarPoint class).
Reference: [DTM94] <author> Amer Diwan, David Tarditi, and Eliot Moss. </author> <title> Memory Subsystem Performance of Programs with Intensive Heap Allocation. </title> <booktitle> In 21st Annual ACM Symposium on Principles of Programming Languages, p. </booktitle> <pages> 1-14, </pages> <month> January </month> <year> 1994. </year>
Reference-contexts: Write-allocate with subblock placement caches allocate a cache line when a store instruction references a location not currently residing in the cache. This organization is used in current workstations (e.g., the DECsta-tion 5000 series) and has been shown to be effective for programs with intensive heap allocation [KLS92], [Rei93], <ref> [DTM94] </ref>. We do not use the original SPARCstation-2 cache configuration because it suffers from large variations in cache miss ratios caused by small differences in code and data positioning (we have observed variations of up to 15% of total execution time).
Reference: [Dri93] <author> Karel Driesen. </author> <title> Selector Table Indexing and Sparse Arrays. </title> <booktitle> OOPSLA 93 Conference Proceedings, p. </booktitle> <pages> 259-270, </pages> <address> Washington, D.C., </address> <year> 1993. </year> <note> Published as SIGPLAN Notices 28(10), </note> <month> September </month> <year> 1993. </year>
Reference-contexts: The latter are used because in dynamically-typed languages it is harder (but not impossible <ref> [Dri93] </ref>) to use indirect function calls for dynamically-dispatched calls. Instead, SELF uses Polymorphic Inline Caches [HCU91] which implement a dynamically-dispatched call as a typecase statement (to determine the receiver type) followed by a direct call.
Reference: [Dyk77] <author> Eric J. Van Dyke. </author> <title> A dynamic incremental compiler for an interpretative language. </title> <journal> HP Journal, </journal> <volume> p. </volume> <pages> 17-24, </pages> <month> July </month> <year> 1977. </year>
Reference-contexts: For example, Mitchells system [Mit70] specialized arithmetic operations to the runtime types of the operands (similar to SELF-89s customization [CUL89]). Similarly, several APL compilers created specialized code for certain expressions (e.g. [Joh79], <ref> [Dyk77] </ref>, [GW78]). Of these systems, the HP APL compiler [Dyk77] came closest to customization and type feedback. The system compiled code on a statement-by-statement basis. <p> For example, Mitchells system [Mit70] specialized arithmetic operations to the runtime types of the operands (similar to SELF-89s customization [CUL89]). Similarly, several APL compilers created specialized code for certain expressions (e.g. [Joh79], <ref> [Dyk77] </ref>, [GW78]). Of these systems, the HP APL compiler [Dyk77] came closest to customization and type feedback. The system compiled code on a statement-by-statement basis. In addition to performing APL-specific optimizations, compiled code was specialized according to the specific operand types (number of dimensions, size of each dimension, element type, etc.).
Reference: [G+94] <author> Charles D. Garrett, Jeffrey Dean, David Grove, and Craig Chambers. </author> <title> Measurement and Application of Dynamic Receiver Class Distributions. </title> <type> Technical Report CSE-TR-94-03-05, </type> <institution> University of Washington, </institution> <month> February </month> <year> 1994. </year>
Reference-contexts: However, in our experience, type profiles are more stable than time profilesif a receiver type dominates a call site during one program execution, it also dominates during other executions. A recent study by Garrett et al. <ref> [G+94] </ref> that measured the stability of type profiles in SELF, C++, and Cecil programs confirms our experience. 3.
Reference: [GKM83] <author> S. L. Graham, P. B. Kessler, and M. K. McKusick. </author> <title> An Execution Profiler for Modular Programs. </title> <journal> Software Practice and Experience 13 </journal> <pages> 671-685, </pages> <year> 1983. </year>
Reference-contexts: Thus, we believe that type feedback is probably easier to add to a conventional batch-style compilation system. In such a system, optimization would proceed in three phases (Figure 11). First, the executable is instrumented to record receiver types, for example with a gprof-like profiler <ref> [GKM83] </ref>. (The standard gprof With type feedback, it would be possible to customize less aggressively (thus reducing code size) since customization is no longer needed to enable inlining (i.e., with type feedback the main benefit of customization is that it can reduce the number of type tests required). bigger instrumented program
Reference: [GW78] <author> Leo J. Guibas and Douglas K. Wyatt. </author> <title> Compilation and Delayed Evaluation in APL. </title> <booktitle> In Fifth Annual ACM Symposium on Principles of Programming Languages, p. </booktitle> <pages> 1-8, </pages> <year> 1978. </year>
Reference-contexts: For example, Mitchells system [Mit70] specialized arithmetic operations to the runtime types of the operands (similar to SELF-89s customization [CUL89]). Similarly, several APL compilers created specialized code for certain expressions (e.g. [Joh79], [Dyk77], <ref> [GW78] </ref>). Of these systems, the HP APL compiler [Dyk77] came closest to customization and type feedback. The system compiled code on a statement-by-statement basis. In addition to performing APL-specific optimizations, compiled code was specialized according to the specific operand types (number of dimensions, size of each dimension, element type, etc.).
Reference: [Hall91] <author> Mary Wolcott Hall. </author> <title> Managing Interprocedural Optimization. </title> <type> Technical Report COMP TR91-157 (Ph.D. Thesis), </type> <institution> Computer Science Department, Rice University, </institution> <month> April </month> <year> 1991. </year>
Reference-contexts: Studies of inlining for more conventional languages like C or Fortran have found that it often does not significantly increase execution speed but tends to significantly increase code size (e.g., [DH88], [HwC89], [CHT91], [CM+92], <ref> [Hall91] </ref>). In contrast, inlining in SELF results in both significant speedups and only very moderate code growth.
Reference: [Hill87] <author> Mark D. Hill. </author> <title> Aspects of Cache Memory and Instruction Buffer Performance. </title> <type> Technical Report UCB/CSD 87/ 381, </type> <institution> Computer Science Division, University of Cali-fornia, Berkeley, </institution> <month> November </month> <year> 1987. </year>
Reference-contexts: C++ compilers, version 2.4.5, using -O2 optimization Lisp Sun CommonLisp 4.0 using full optimization Table 1: Systems used for benchmarking 4.1 Methodology To accurately measure execution times, the programs were run under a SPARC simulator based on the Spa [Irl91] and Shade [CK93] tracing tools and the Dinero cache simulator <ref> [Hill87] </ref>. The simulator models the Cypress CY7C601 implementation of the SPARC architecture, i.e., the chip used in the SPARCstation-2 workstation. The simulator also accurately models the memory system of a SPARCstation-2, with the exception of the cache organization.
Reference: [HCU91] <author> Urs Hlzle, Craig Chambers, and David Ungar. </author> <title> Optimizing Dynamically-Typed Object-Oriented Languages with Polymorphic Inline Caches. </title> <booktitle> In ECOOP91 Conference Proceedings, Geneva, 1991. Published as Springer Verlag Lecture Notes in Computer Science 512, </booktitle> <publisher> Springer Verlag, </publisher> <address> Berlin, </address> <year> 1991. </year>
Reference-contexts: In the SELF system, no additional mechanism is needed to record receiver types since the system uses polymorphic inline caches to speed up dynamic dispatch. As we have observed in <ref> [HCU91] </ref>, these caches record receiver types as a side-effect. Therefore, a programs type profile is readily available, and collecting the type feedback data does not incur any execution time overhead. <p> The latter are used because in dynamically-typed languages it is harder (but not impossible [Dri93]) to use indirect function calls for dynamically-dispatched calls. Instead, SELF uses Polymorphic Inline Caches <ref> [HCU91] </ref> which implement a dynamically-dispatched call as a typecase statement (to determine the receiver type) followed by a direct call. <p> A large fraction of call sites in C++ have this property [CG94][G+94], and it also holds in other object oriented programming languages (e.g., Smalltalk, SELF, Sather, and Eiffel); this is the reason that inline caching [DS84], <ref> [HCU91] </ref> works well in these languages as an implementation of dynamic dispatch. Therefore, we expect type feedback to work well for these languages; the higher the frequency of dynamically-dispatched calls, the more beneficial type feedback could be. 6. <p> In contrast, type feedback in SELF-93 is more lazy and adaptive. The system described in this paper was inspired by the experimental proof-of-concept system described in <ref> [HCU91] </ref>. That system was the first one to use type feedback (then called PIC-based inlining) for optimization purposes. However, being an experimental system, its structure and performance was very different. <p> As a result, its speedup over a system without type feedback was modest (about 11%). Based on measurements of C++ programs, Calder and Grunwald [CG94] argue that type feedback would be beneficial for C++; their proposed if conversion appears to be identical to inline caching [DS84] and PIC-based inlining <ref> [HCU91] </ref>, except that it is performed statically. The Apple Object Pascal linker [App88] turned dynamically-dispatched calls into statically-bound calls if a type had exactly one implementation (e.g., the system contained only a Carte-sianPoint class and no PolarPoint class).
Reference: [HCU92] <author> Urs Hlzle, Craig Chambers, and David Ungar. </author> <title> Debugging Optimized Code With Dynamic Deoptimization. </title> <booktitle> In Proceedings of the SIGPLAN 92 Conference on Programming Language Design and Implementation, p. </booktitle> <pages> 21-38, </pages> <address> San Francisco, </address> <year> 1992. </year> <note> Published as SIGPLAN Notices 27(6), </note> <month> June </month> <year> 1992. </year>
Reference-contexts: Sometimes, an optimized method is reoptimized to take advantage of additional type information or to adapt it to changes in the programs type profile. Combining the optimizing compiler with the fast non-optimizing compiler and dynamic recompilation unoptimized code source methods if executed often if needed for debugging <ref> [HCU92] </ref> is first invoked optimized code when method 3 allows SELF-93 to achieve high performance while keeping compilation pauses in the sub-second range [Hl94]. <p> If this is successful, the reoptimized method replaces the corresponding unoptimized methods on the stack, possibly replacing several unoptimized activation records with a single optimized activation record. (This process is the reverse of dynamic deoptimization as described in <ref> [HCU92] </ref>; that paper also describes how the compiler represents the source-level state of optimized code.) The system tries to optimize an entire call chain from the top recompilee down to the current execution point. (Usually, the recompiled call chain is only one or two compiled methods deep.) Thus, if the newly

References-found: 36

