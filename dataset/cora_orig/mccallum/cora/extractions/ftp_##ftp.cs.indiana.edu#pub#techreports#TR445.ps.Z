URL: ftp://ftp.cs.indiana.edu/pub/techreports/TR445.ps.Z
Refering-URL: http://www.cs.indiana.edu/trindex.html
Root-URL: 
Title: An Architecture for Parallel Symbolic Processing Based on Suspending Construction  
Author: Eric R. Jeschke 
Degree: Submitted to the faculty of the Graduate School in partial fulfillment of the requirements for the degree Doctor of Philosophy in the  
Date: April 1995  
Affiliation: Department of Computer Science Indiana University  
Abstract-found: 0
Intro-found: 1
Reference: [AAL88] <author> John Ellis Andrew Appel and Kai Lai. </author> <title> Real-time concurrent collection on stock multiprocessors. </title> <booktitle> In ACM SIGPLAN Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 11-20, </pages> <month> June </month> <year> 1988. </year>
Reference-contexts: These two minor phases correspond to the hash demon and files demon described in [Mil87]. 5.3.3 Garbage Collection: Observations Our garbage collection algorithm is neither efficient or full-featured compared to others described in the literature (e.g. <ref> [AAL88] </ref>), nevertheless we are encouraged by recent studies on the efficiency of mark-sweep collection [Zor90, HJBS91]. <p> Our system has the advantage of parallel collection in all phases, so that collection pauses increase according to the heap size divided by the total number of processors. Nevertheless, this still allows for significant pauses. I would like to incorporate an incremental garbage collector <ref> [AAL88, Moo84, Kie86] </ref> to avoid the latency penalties incurred by the current collector. The incremental collector should preserve locality of data as in the current scheme and not migrate data or processes to other processor nodes.
Reference: [AG94] <author> George S. Almasi and Allan Gottlieb. </author> <title> Highly Parallel Computing. </title> <address> Ben-jamin/Cummings, </address> <year> 1994. </year>
Reference-contexts: We distinguish between two shared memory designs: one in which accesses to memory from any processor have constant time (disregarding interprocessor contention and caching) and one that does not. Multiprocessor architectures using the latter type are called Non-Uniform Memory Access (NUMA) designs <ref> [AG94] </ref>. NUMA architectures are generally more scalable, since they are designed using a many processor-to-many memory network [LD88] as opposed to several processors attached to one or more memory banks on a bus, which limits scalability due to bandwidth limitations.
Reference: [AL91] <author> Andrew Appel and Kai Lai. </author> <title> Virtual memory primitives for user programs. </title> <booktitle> In ACM Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 96-107, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: In symbolic processing the dominant communication paradigm is shared memory; i.e. shared memory is the norm, rather than the exception. There has been some work in using shared virtual memory to support type-checking, memory barriers and other features needed by symbolic languages (e.g. <ref> [AL91] </ref>). This approach exploits the trapping aspect of memory management units on stock hardware for purposes that might also be handled by appropriate processor modifications. Finally, symbolic languages do not have visible pointers as traditional languages do.
Reference: [BH77] <author> Henry C. Baker and Carl Hewitt. </author> <title> The incremental garbage collection of processes. </title> <journal> ACM SIGPLAN Notices, </journal> <volume> 12(8) </volume> <pages> 55-59, </pages> <month> August </month> <year> 1977. </year>
Reference-contexts: This is usually coupled with a suitably-modified garbage collector to remove pointers to the speculative tasks from the scheduling infrastructure if they have been unreferenced from the programs data structures <ref> [BH77, Mil87] </ref>. 2.2.3 Device Management The third major area of kernel support is for device management. A number of lazy languages use a stream model of I/O interface [Hud89] in which data is read or written from devices in streams. <p> The approaches used by current parallel symbolic systems generally fall into two categories: explicit killing of tasks [GP81, Hem85] and garbage collection of tasks <ref> [BH77, Mil87] </ref>. 81 6.7 Conservative vs. Speculative Parallelism The first approach, explicit killing of tasks, relies on the kernel being able to determine when a task has become useless. <p> This is particularly true regarding the body of work centered around the future construct used in Multilisp [RHH85, RHH86, Osb90], and its offspring, MultiScheme [Mil87] and Mul-T [DAKM89]. There seems to have been a cross-fertilization of ideas in the genesis of suspensions and futures <ref> [BH77, RHH85] </ref>, although the work on suspensions seems to predate that of futures [FW76a, FW76b]. A number of other Scheme constructs like delay /force, continuations and engines share some characteristics with suspensions in various ways, but only futures share the inherent notion of concurrent process entities.
Reference: [Bur84] <author> F. Warren Burton. </author> <title> Annotations to control parallelism and reduction order in the distributed evaluation of functional programs. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 6(2) </volume> <pages> 159-174, </pages> <month> April </month> <year> 1984. </year>
Reference: [Bur85a] <author> F. Warren Burton. </author> <title> Controlling speculative computation in a parallel functional programming language. </title> <booktitle> In IEEE International Conference on Distributed Computing Systems, </booktitle> <pages> pages 453-457, </pages> <month> May </month> <year> 1985. </year>
Reference-contexts: The method used can have a large impact on performance; blocking synchronization, while generally considered more efficient, has inherent problems (see below) that require workarounds elsewhere in the system. An idea that has gained momentum in symbolic languages in recent years is the concept of speculative computation <ref> [Bur85a, Bur85b] </ref>. Speculative parallelism refers to scheduling parallel tasks that may not be needed (on the chance that they might) to increase available parallelism over that provided by regular conservative parallelism [Jon87].
Reference: [Bur85b] <author> F. Warren Burton. </author> <title> Speculative computation, parallelism and functional programming. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> c-34(12):1190-1193, </volume> <month> December </month> <year> 1985. </year>
Reference-contexts: The method used can have a large impact on performance; blocking synchronization, while generally considered more efficient, has inherent problems (see below) that require workarounds elsewhere in the system. An idea that has gained momentum in symbolic languages in recent years is the concept of speculative computation <ref> [Bur85a, Bur85b] </ref>. Speculative parallelism refers to scheduling parallel tasks that may not be needed (on the chance that they might) to increase available parallelism over that provided by regular conservative parallelism [Jon87].
Reference: [CJR91] <editor> William Clinger and Eds. Jonathan Rees. </editor> <title> Revised ^ 4 report on the algorithmic language scheme. </title> <type> Technical report, </type> <institution> Indiana University, </institution> <month> November </month> <year> 1991. </year> <type> Technical Report No. 341. 136 REFERENCES </type>
Reference-contexts: As for I/O, the language could easily provide stream I/O based on the kernel's device interface, but standard Scheme also provides imperative I/O; providing a proper superset of the Scheme standard <ref> [CJR91] </ref> might be beneficial. Communicating Sequential Processes Another language that would be particularly well suited to DSI's task and communication model would be a CSP-like language. A CSP language would be naturally implemented in DSI using streams for communication and signals for synchronization between processes.
Reference: [DAKM89] <author> Jr. David A. Kranz, Robert H. Halstead and Eric Mohr. Mul-t: </author> <title> A high-performance parallel lisp. </title> <booktitle> In ACM Symposium on Programming Language Design and Implementation, </booktitle> <pages> pages 81-90, </pages> <year> 1989. </year> <editor> [DW94] et. al. </editor> <title> D.S. Wise. Uniprocessor performance of reference-counting hardware heap. </title> <type> Technical Report 401, </type> <institution> Indiana University Computer Science Department, Bloomington, Indiana, </institution> <month> June </month> <year> 1994. </year>
Reference-contexts: This request/donate allocation mechanism stands in contrast to the shared heap state variables used in other systems <ref> [DAKM89, MRSL88] </ref>. Although the allocation block/suballocation technique can be (and is) used in these systems, processors must occasionally synchronize for access to shared global allocation pointers. <p> Our system of load-balancing stands in contrast to most other symbolic processing systems which actively move processes around to try to balance the system, or have processors steal tasks from other processor's ready queues <ref> [RHH85, DAKM89] </ref>. <p> Under normal circumstances allocation operations will eventually exhaust all avaliable free space in the heap and garbage collection must be performed to recover space. 3 On the other hand, the snoopy cache architecture used by these systems may be just as sensitive to locality as a NUMA design <ref> [DAKM89] </ref>. 63 5.3 Storage Reclamation 5.3.1 Garbage Collection DSI uses a distributed mark-sweep garbage collection algorithm. Garbage collection is triggered by a SIG GC signal delivered to all processors. The kernel process on each node responds to this signal by invoking a local dormant garbage collection process. <p> Rather, it should take up any dependence stacks that have been passed to it from other processors. Given a balanced distribution of suspensions and a small backlog of waiting dependence stacks, any processor should always have work to do. Kranz <ref> [DAKM89] </ref> briefly discusses the merits this kind of task backlog. 6.5 Static vs. Dynamic Parallelism We can classify parallelism in our system under two broad categories. Static parallelism is due to pre-existing multiple chains of demand. <p> Some Lisp-based systems address this issue through per-task storage based on fluid-binding [Mil87], first class environments, or extending deep binding to top-level environments <ref> [DAKM89] </ref>. A flexible module or package system for Daisy would address this problem in a more general way that might have benefits for other languages implemented on DSI. User-Defined Exceptions Daisy's treatment of errors is woefully inadequate for serious programming. <p> This is particularly true regarding the body of work centered around the future construct used in Multilisp [RHH85, RHH86, Osb90], and its offspring, MultiScheme [Mil87] and Mul-T <ref> [DAKM89] </ref>. There seems to have been a cross-fertilization of ideas in the genesis of suspensions and futures [BH77, RHH85], although the work on suspensions seems to predate that of futures [FW76a, FW76b]. <p> This example typifies the difference between Multilisp and Daisy, regarding low level hooks into the implementation, described earlier. 128 9.3 Related work Mul-T Mul-T is a extended version of Scheme augmented with futures and implemented on the Encore Multimax multiprocessor using a modified form of the ORBIT Scheme compiler <ref> [DAKM89] </ref>. For language and computation model comparisons with DSI, see the general remarks on parallel Lisp, above. Mul-T's run-time system, like most other implementations (except ours, it seems) queues blocked tasks into the task state of processes directly. <p> DSI's suspensions are also likely smaller than futures. In addition, DSI provides an additional speculative task queue and stack with corresponding lower priorities to keep speculative processes from disturbing conservative ones. DSI removes speculative tasks from the system implicitly. Kranz <ref> [DAKM89] </ref> provides no indication of how speculative computation is handled, if at all, in Mul-T. The techniques used in [Osb90] may be a possible direction for Mul-T in this regard. Mul-T's I/O also shares similarities with DSI's device management. <p> In DSI, all exception handling is accomplished via separate processes using signals (see chapter 3); our "distinguished exception handler task" is the kernel. DSI signals are also used to coordinate I/O, tracing and debugging, garbage collection, suspension detection, etc. Finally, Kranz <ref> [DAKM89] </ref> makes very good arguments for hardware support for tag-checking to accelerate future detection on stock hardware, validating similar remarks I made in section 2.1 and chapter 3. QLisp QLisp [GM84, GG88] is a eagerly parallel version of Lisp based on a shared-queuing discipline.
Reference: [FM90] <author> Marc Feeley and James S. Miller. </author> <title> A parallel virtual scheme machine for efficient scheme compilation. </title> <booktitle> In ACM Conference on Lisp and Functional Programming, </booktitle> <pages> pages 119-130, </pages> <year> 1990. </year>
Reference-contexts: DSI's virtual machine is quite low level, with registers and instructions that would have close correspondence to those on the target machine, as opposed to intermediate-level instructions that would be further compiled, such as in <ref> [FM90] </ref>. The special needs of a language or its computation model are often distilled into specific features or instructions in the virtual machine to facilitate and accelerate execution. <p> This may have 127 9.3 Related work motivated the work on lazy future creation [Moh90] used in Mul-T (see below). MultiScheme MultiScheme <ref> [Mil87, FM90] </ref> is a parallel dialect of MIT-Scheme, extended to support futures. Miller's dissertation [Mil87] concentrates on the details of extending MIT Scheme to support futures and the other features of MultiScheme.
Reference: [FW76a] <author> Daniel P. Friedman and David S. Wise. </author> <title> CONS should not evaluate its arguments. </title> <editor> In S. Michaelson and R. Milner, editors, </editor> <booktitle> Automata, Languages and Programming, </booktitle> <pages> pages 257-284. </pages> <publisher> Edinburgh University Press, Edinburgh, </publisher> <year> 1976. </year>
Reference-contexts: ] partition = "[p L]. rec:[part "[p L lo hi]. let:[[X ! Xs] L le?:[X p] part:[p Xs [X ! lo] hi] part:[p Xs lo [X ! hi]] ]] part: [p L [] []] ] 2.3.2 Semantics Daisy's laziness is a byproduct of list construction, not lazy interpretation or compilation <ref> [FW76a] </ref> (there are exceptions, such as the binding forms described above). 28 2.3 Daisy The evaluation of a list of expressions yields a list of suspensions for evaluating those expressions; in essence, lists are suspended-process builders. <p> There seems to have been a cross-fertilization of ideas in the genesis of suspensions and futures [BH77, RHH85], although the work on suspensions seems to predate that of futures <ref> [FW76a, FW76b] </ref>. A number of other Scheme constructs like delay /force, continuations and engines share some characteristics with suspensions in various ways, but only futures share the inherent notion of concurrent process entities. A high-level, denotational analysis of these constructs vs. suspensions can be found in [Joh89c].
Reference: [FW76b] <author> Daniel P. Friedman and David S. Wise. </author> <title> The impact of applicative programming on multiprocessing. </title> <booktitle> In International Conference on Parallel Processing, </booktitle> <pages> pages 263-272. </pages> <booktitle> IEEE, 1976. IEEE Cat. </booktitle> <volume> No. </volume> <month> 76CH1127-OC. </month>
Reference-contexts: There seems to have been a cross-fertilization of ideas in the genesis of suspensions and futures [BH77, RHH85], although the work on suspensions seems to predate that of futures <ref> [FW76a, FW76b] </ref>. A number of other Scheme constructs like delay /force, continuations and engines share some characteristics with suspensions in various ways, but only futures share the inherent notion of concurrent process entities. A high-level, denotational analysis of these constructs vs. suspensions can be found in [Joh89c].
Reference: [FW76c] <author> Daniel P. Friedman and David S. Wise. </author> <title> Output driven interpretation of recursive programs, or writing creates and destroys data structures. </title> <journal> Information Processing Letters 5, </journal> <pages> pages 155-160, </pages> <month> December </month> <year> 1976. </year>
Reference: [FW77] <author> Daniel P. Friedman and David S. Wise. </author> <title> An environment for multiple-valued recursive procedures. </title> <editor> In B. Robinet, editor, </editor> <booktitle> Programmation, </booktitle> <pages> pages 182-200. </pages> <institution> Dunod Informatique, Paris, </institution> <year> 1977. </year>
Reference: [FW78a] <author> Daniel P. Friedman and David S. Wise. </author> <title> Applicative multiprogramming. </title> <type> Technical Report 72, </type> <institution> Indiana University Computer Science Department, Bloomington, Indiana, </institution> <year> 1978. </year> <note> Revised: </note> <month> December, </month> <year> 1978. </year>
Reference: [FW78b] <author> Daniel P. Friedman and David S. Wise. </author> <title> Aspects of applicative programming for parallel processing. </title> <journal> IEEE Trans. Comput. C-27, </journal> <volume> 4, </volume> <pages> pages 289-296, </pages> <month> April </month> <year> 1978. </year> <note> 137 REFERENCES </note>
Reference: [FW78c] <author> Daniel P. Friedman and David S. Wise. </author> <title> Functional combination. </title> <booktitle> Computer Languages 3, </booktitle> <volume> 1, </volume> <pages> pages 31-35, </pages> <year> 1978. </year>
Reference: [FW78d] <author> Daniel P. Friedman and David S. Wise. Sting-unless: </author> <title> a conditional, interlock-free store instruction. </title> <editor> In M. B. Pursley and Jr. J. B. Cruz, editors, </editor> <booktitle> 16th Annual Allerton Conf. on Communication, Control, and Computing, </booktitle> <publisher> University of Illinois (Urbana-Champaign), </publisher> <pages> pages 578-584, </pages> <year> 1978. </year>
Reference-contexts: Like loads, there are conditional and unconditional versions of stores. The conditional versions will fail on any attempt to overwrite a non-suspension reference; this feature can be used to arbitrate interprocessor suspension scheduling (see <ref> [FW78d] </ref>), although DSI has more generalized primitives (e.g. atomic add/and/or) that can be used for more sophisticated coordination schemes. * Allocation instructions allocate cells from memory and initialize them using register contents in a single operation.
Reference: [FW78e] <author> Daniel P. Friedman and David S. Wise. </author> <title> Unbounded computational structures. </title> <journal> Software-Practice and Experience 8, </journal> <volume> 4, </volume> <pages> pages 407-416, </pages> <month> July-August </month> <year> 1978. </year>
Reference: [FW79] <author> Daniel P. Friedman and David S. Wise. </author> <title> An approach to fair applicative multiprogramming. </title> <editor> In G. Kahn and R. Milner, editors, </editor> <booktitle> Semantics of Concurrent Computation, </booktitle> <pages> pages 203-225. </pages> <address> Berlin, </address> <publisher> Springer, </publisher> <year> 1979. </year>
Reference-contexts: To do this we modify our demand-driven scheduling scheme to propagate demand 3 The algorithms are loosely based on those used for multisets <ref> [FW79, FW80b] </ref>; an indeterminate construct appearing in earlier versions of Daisy. 83 6.8 Sharing and Cycles coefficients and observe the limits of a process' computation bound. This essentially quantifies the demand propagating through the computation graph.
Reference: [FW80a] <author> Daniel P. Friedman and David S. Wise. </author> <title> A conditional, interlock-free store instruction. </title> <type> Technical Report 74, </type> <institution> Indiana University Computer Science Department, Bloomington, Indiana, </institution> <year> 1980. </year> <note> (revised 1980). </note>
Reference: [FW80b] <author> Daniel P. Friedman and David S. Wise. </author> <title> An indeterminate constructor for applicative multiprogramming. </title> <booktitle> In Record 7th ACM Symp. on Principles of Programming Languages (January, </booktitle> <year> 1980), </year> <pages> pages 245-250, </pages> <year> 1980. </year>
Reference-contexts: To do this we modify our demand-driven scheduling scheme to propagate demand 3 The algorithms are loosely based on those used for multisets <ref> [FW79, FW80b] </ref>; an indeterminate construct appearing in earlier versions of Daisy. 83 6.8 Sharing and Cycles coefficients and observe the limits of a process' computation bound. This essentially quantifies the demand propagating through the computation graph.
Reference: [FW81] <author> Daniel P. Friedman and David S. Wise. </author> <title> Fancy ferns require little care. </title> <editor> In S. Holmstrom, B. Nordstrom, and A. Wikstrom, editors, </editor> <booktitle> Symp. on Functional Languages and Computer Architecture, </booktitle> <institution> Lab for Programming Methodology, Goteborg, Sweden, </institution> <year> 1981. </year>
Reference: [GG88] <author> Ron Goldman and Richard P. Gabriel. </author> <title> Preliminary results with the initial implementation of qlisp. </title> <booktitle> In ACM Symposium on Lisp and Functional Programming, </booktitle> <pages> pages 143-152, </pages> <month> July </month> <year> 1988. </year>
Reference-contexts: DSI signals are also used to coordinate I/O, tracing and debugging, garbage collection, suspension detection, etc. Finally, Kranz [DAKM89] makes very good arguments for hardware support for tag-checking to accelerate future detection on stock hardware, validating similar remarks I made in section 2.1 and chapter 3. QLisp QLisp <ref> [GM84, GG88] </ref> is a eagerly parallel version of Lisp based on a shared-queuing discipline. The language is based on a version of Lucid Common Lisp and compiles Lisp code to machine instructions. <p> QLisp provides functions to create, acquire, release and test locks. It uses catch and throw to explicitly kill other tasks; that is, when a processor executes a throw, all other tasks created within the corresponding catch are killed. This feature can be used to manage OR-parallel speculation. Published details <ref> [GM84, GG88] </ref> are sketchy on the memory and process management used in QLisp. The language is implemented on an Alliant FX/8 multiprocessor 131 9.3 Related work (a non-NUMA design), which means QLisp probably does not micro-manage for locality purposes.
Reference: [GM84] <author> Richard P. Gabriel and John McCarthy. </author> <booktitle> Queue-based multi-processing lisp. In ACM Symposium on Lisp and Functional Programming, </booktitle> <pages> pages 25-43, </pages> <month> August </month> <year> 1984. </year> <note> 138 REFERENCES </note>
Reference-contexts: This mechanism must be dynamic, since the amount and type of parallelism all depend on the program and data. One technique to constraining parallelism is to tie process creation (i.e. granularity) to the load of the machine <ref> [GM84, Moh90] </ref>. For explicitly eager parallel languages (e.g. futures), this may be possible. For Daisy, the laziness of suspensions is a semantic requirement; there is no way to randomly "inline" a suspension without changing the semantics of the language 1 . <p> DSI signals are also used to coordinate I/O, tracing and debugging, garbage collection, suspension detection, etc. Finally, Kranz [DAKM89] makes very good arguments for hardware support for tag-checking to accelerate future detection on stock hardware, validating similar remarks I made in section 2.1 and chapter 3. QLisp QLisp <ref> [GM84, GG88] </ref> is a eagerly parallel version of Lisp based on a shared-queuing discipline. The language is based on a version of Lucid Common Lisp and compiles Lisp code to machine instructions. <p> QLisp provides functions to create, acquire, release and test locks. It uses catch and throw to explicitly kill other tasks; that is, when a processor executes a throw, all other tasks created within the corresponding catch are killed. This feature can be used to manage OR-parallel speculation. Published details <ref> [GM84, GG88] </ref> are sketchy on the memory and process management used in QLisp. The language is implemented on an Alliant FX/8 multiprocessor 131 9.3 Related work (a non-NUMA design), which means QLisp probably does not micro-manage for locality purposes. <p> The comparison remarks for DSI's memory management scheme verses QLisp are basically the same as for PSL, below. A comparison of process management is difficult, given the lack of details on QLisp's design. However, the authors <ref> [GM84] </ref> describe the use of a single shared queue for distributing work among processors, hence the name, QLisp. Butterfly Portable Standard Lisp A group at the University of Utah has also implemented Lisp on the BBN Butterfly [MRSL88].
Reference: [GP81] <author> Dale H. Grit and Rex L. </author> <title> Page. Deleting irrelevant tasks in an expression-oriented multiprocessor system. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 3(1) </volume> <pages> 49-59, </pages> <month> January </month> <year> 1981. </year>
Reference-contexts: Finally, systems with side-effects must also deal with the decision of whether to abort or to "roll-back" side-effects that are the result of useless speculation [Osb90]. One solution to these problem (assuming that the speculative tasks can be distinguished) is to spawn a "termination process" to kill them <ref> [GP81, Hem85] </ref>. Another approach is to implement some kind of priority mechanism that dynamically upgrades or downgrades the status of a speculative process and its descendants [Osb90]. <p> The approaches used by current parallel symbolic systems generally fall into two categories: explicit killing of tasks <ref> [GP81, Hem85] </ref> and garbage collection of tasks [BH77, Mil87]. 81 6.7 Conservative vs. Speculative Parallelism The first approach, explicit killing of tasks, relies on the kernel being able to determine when a task has become useless.
Reference: [Hal87] <author> Cordelia Hall. </author> <title> Strictness analysis applied to programs with lazy list constructors. </title> <type> PhD thesis, </type> <institution> Indiana University Computer Science Department, </institution> <year> 1987. </year>
Reference-contexts: Note that for lazy tasks, it is not the actual creation 1 Although this could be done with strict arguments, revealed by strictness analysis <ref> [Hal87, HW87] </ref>; see chapter 8. 76 6.6 Controlling Parallelism of tasks that leads to excess parallelism but rather the excess scheduling of tasks (i.e. by primitives). However, that there are other valid reasons to reduce granularity. This is discussed further in section 6.9. <p> We would like trivial suspensions to be eliminated or at least allocated locally and suspensions representing important parallelism to be allocated remotely, so that parallelism is migrated properly. 8.3.3 Strictness Analysis One way to address these problems at the language level is through the use of strictness analysis <ref> [Hal87, HW87] </ref>. The information from strictness analysis can be used to eliminate many "trivial" suspensions that do not need to be created. Unfortunately, strictness analysis does not discriminate between trivial suspensions and "important" suspensions that we want to preserve for parallelism's sake.
Reference: [Hem85] <author> David Hemmendinger. </author> <title> Lazy evaluation and cancellation of computations. </title> <booktitle> In IEEE International Conference on Parallel Processing, </booktitle> <pages> pages 840-842, </pages> <month> August </month> <year> 1985. </year>
Reference-contexts: Finally, systems with side-effects must also deal with the decision of whether to abort or to "roll-back" side-effects that are the result of useless speculation [Osb90]. One solution to these problem (assuming that the speculative tasks can be distinguished) is to spawn a "termination process" to kill them <ref> [GP81, Hem85] </ref>. Another approach is to implement some kind of priority mechanism that dynamically upgrades or downgrades the status of a speculative process and its descendants [Osb90]. <p> The approaches used by current parallel symbolic systems generally fall into two categories: explicit killing of tasks <ref> [GP81, Hem85] </ref> and garbage collection of tasks [BH77, Mil87]. 81 6.7 Conservative vs. Speculative Parallelism The first approach, explicit killing of tasks, relies on the kernel being able to determine when a task has become useless.
Reference: [HJBS91] <author> Alan J. Demers Hans-J. Boehm and Scott Shenker. </author> <title> Mostly parallel garbage collection. </title> <booktitle> In ACM SIGPLAN Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 157-175, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: These two minor phases correspond to the hash demon and files demon described in [Mil87]. 5.3.3 Garbage Collection: Observations Our garbage collection algorithm is neither efficient or full-featured compared to others described in the literature (e.g. [AAL88]), nevertheless we are encouraged by recent studies on the efficiency of mark-sweep collection <ref> [Zor90, HJBS91] </ref>. Our collector has some useful properties that contribute to the overall storage management strategy in DSI, the most important being that storage is not migrated from one processor to another, preserving locality conditions that are the basis for a number of design decisions (see sections 5.2.2 and 5.2.3).
Reference: [HS86] <author> Paul Hudak and L. Smith. </author> <title> Para-functional programming: a paradigm for programming multiprocessor systems. </title> <booktitle> In ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 243-254, </pages> <month> January </month> <year> 1986. </year>
Reference: [HS88] <author> Paul Hudak and Raman S. Sundaresh. </author> <title> On the expressiveness of purely functional i/o systems. </title> <type> Technical report, </type> <institution> Yale, </institution> <month> December </month> <year> 1988. </year> <note> Yale Technical Report YALEU/DCS/RR-665. </note>
Reference-contexts: The stream model of computing, while elegant, has its limitations. One of these is the difficulty of handling interactive terminal I/O, which must be synchronized by artificial strictness measures <ref> [HS88] </ref>. This problem may be quickly becoming irrelevant with the advent of modern GUI windowing shells. <p> One solution to this problem is to insert explicit point-source coercion or laziness operations into the code to achieve the proper interleaving of prompts, input, and output <ref> [HS88, p.2] </ref>. At best this is a trial and error, ad-hoc procedure. Fortunately this problem is alleviated to a great extent by the ubiquitous use of modern windowing shells.
Reference: [Hud86] <author> Paul Hudak. </author> <title> Para-functional programming. </title> <journal> Computer, </journal> <volume> 19(8) </volume> <pages> 60-71, </pages> <month> August </month> <year> 1986. </year>
Reference: [Hud89] <author> Paul Hudak. </author> <title> Conception, evolution, and application of functional programming languages. </title> <journal> ACM Computing Surveys, </journal> <volume> 21(3) </volume> <pages> 359-411, </pages> <month> Septem-ber </month> <year> 1989. </year>
Reference-contexts: A number of lazy languages use a stream model of I/O interface <ref> [Hud89] </ref> in which data is read or written from devices in streams. This model elegantly handles the interaction with demand driven computation, which would be difficult with an imperative, temporal I/O interface, such as that used in Lisp. <p> Lazy, side-effect-free programming also leads to similar styles of expressing data recursion, functional mappings and other functional programming hallmarks. At the same time, Daisy does not have many of the trappings of "modern" functional languages <ref> [Hud89] </ref> such as pattern matching, type inference, and algebraic or abstract data type constructors. In these areas Daisy remains very Lisp like, using lambda forms, dynamic typing, and standard Lisp data types.
Reference: [HW87] <author> Cordelia Hall and David S. Wise. </author> <title> Compiling strictness into streams. </title> <booktitle> In Fourteenth Annual ACM SIGACT-SIGPLAN Symposium on Principles of Programming Languages, </booktitle> <address> Munich, West Germany, </address> <month> January 21-23, </month> <pages> pages 132-143, </pages> <year> 1987. </year> <note> 139 REFERENCES </note>
Reference-contexts: Note that for lazy tasks, it is not the actual creation 1 Although this could be done with strict arguments, revealed by strictness analysis <ref> [Hal87, HW87] </ref>; see chapter 8. 76 6.6 Controlling Parallelism of tasks that leads to excess parallelism but rather the excess scheduling of tasks (i.e. by primitives). However, that there are other valid reasons to reduce granularity. This is discussed further in section 6.9. <p> We would like trivial suspensions to be eliminated or at least allocated locally and suspensions representing important parallelism to be allocated remotely, so that parallelism is migrated properly. 8.3.3 Strictness Analysis One way to address these problems at the language level is through the use of strictness analysis <ref> [Hal87, HW87] </ref>. The information from strictness analysis can be used to eliminate many "trivial" suspensions that do not need to be created. Unfortunately, strictness analysis does not discriminate between trivial suspensions and "important" suspensions that we want to preserve for parallelism's sake.
Reference: [HW92] <author> Brian C. Heck and David S. Wise. </author> <title> An implementation of an applicative file system. </title> <editor> In Y. Bekkers and J. Cohen, editors, </editor> <booktitle> Memory Management, </booktitle> <pages> pages 248-263. </pages> <booktitle> Lecture Notes in Computer Science 637, </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1992. </year>
Reference-contexts: A common solution to the problem is to endow the garbage collector with the capability to "close" the device, possibly through a generic finalization facility [Mil87]. This problem is an artifact of an underlying imperative model of I/O that could be avoided using a functional file system <ref> [HW92] </ref>. The stream model of computing, while elegant, has its limitations. One of these is the difficulty of handling interactive terminal I/O, which must be synchronized by artificial strictness measures [HS88]. This problem may be quickly becoming irrelevant with the advent of modern GUI windowing shells.
Reference: [JB88] <author> Steven D. Johnson and C. David Boyer. </author> <title> Modeling transistors applicatively. </title> <editor> In Jr. George J. Milne, editor, </editor> <title> Fusion of Hardware Design and Verification. </title> <publisher> North-Holland, </publisher> <year> 1988. </year> <booktitle> (Proceedings of the IFIP WG10.2 working conference on formal aspects of VLSI, </booktitle> <address> Strathclyde University, Glasgow, </address> <month> July, </month> <year> 1988). </year>
Reference: [JBB87] <author> Steven D. Johnson, Bhaskar Bose, and C. David Boyer. </author> <title> A tactical framework for digital design. </title> <editor> In Graham Birtwistle and P. A. Subramanyam, editors, </editor> <booktitle> VLSI Specification, Verification and Synthesis, </booktitle> <pages> pages 349-384. </pages> <publisher> Kluwer Academic Publishers, </publisher> <year> 1987. </year> <booktitle> Proceedings of the 1987 Calgary Hardware Verification Workshop. </booktitle>
Reference: [Jes] <author> Eric R. Jeschke. </author> <title> Dsi assembler reference manual. </title> <type> (draft, unpublished). </type>
Reference-contexts: Scheduling requests consist of distributed depen dence stacks, as described here. This implementation served as a prototype for the current design. The current system as described in this thesis (DSI V4.1) has been implemented sequentially. It includes a virtual machine assembler <ref> [Jes] </ref> implemented in Yacc/C, a host interface library (in C) and a set of DSI assembly modules comprising the DSI kernel and Daisy interpreter. A Daisy compiler, written in Daisy, translates Daisy code to DSI code.
Reference: [JK81] <author> Steven D. Johnson and Anne T. Kohlstaedt. </author> <title> Dsi program description. </title> <type> Technical Report 120, </type> <institution> Indiana University Computer Science Department, Bloomington, Indiana, </institution> <year> 1981. </year>
Reference: [Joh77] <author> Steven D. Johnson. </author> <title> An interpretive model for a language based on suspended construction. </title> <type> Master's thesis, </type> <institution> Indiana University Computer Science Department, </institution> <year> 1977. </year>
Reference: [Joh81] <author> Steven D. Johnson. </author> <title> Connection networks for output-driven list multiprocessing. </title> <type> Technical Report 114, </type> <institution> Indiana University Computer Science Department, Bloomington, Indiana, </institution> <year> 1981. </year>
Reference-contexts: LPE's have roughly the same architecture described for DSI processors in section 3.2 above, but lack multiple context windows and signals. LSE's are intelligent memory banks, participating actively with the network in supporting the LPE's. Johnson <ref> [Joh81] </ref> classifies memory access instructions into fetch (RSVP ), store (Sting ) and allocation (NEW ) requests, each having a distinct network transaction profile between LPE's and LSE's. RSVPs require a round-trip message from LPE to LSE and back to furnish the result. Stings are one-way requests requiring no acknowledgment. <p> The idea is to preserve locality under normal allocation rates, minimizing contention at the switches for loads and stores, but to disperse high allocation rates across the machine so as to minimize hot spots. Johnson presents simulation results of LiMP in <ref> [Joh81] </ref>. The fundamental motivation behind the NEW-sink is to move resource management problems from software into hardware. If the goal of the NEW-sink is to handle data distribution then the goal of the Process-sink [Joh89c] is to manage load balancing.
Reference: [Joh83] <author> Steven D. Johnson. </author> <title> Circuits and systems: Implementing communication with streams. </title> <journal> IMACS Transactions on Scientific Computation, </journal> <volume> Vol. II, </volume> <pages> pages 311-319, </pages> <year> 1983. </year> <note> 140 REFERENCES </note>
Reference: [Joh84a] <author> Steven D. Johnson. </author> <title> Applicative programming and digital design. </title> <booktitle> In Eleventh Annual ACM SIGACT-SIGPLAN Symposium on Principles of Programming Languages, </booktitle> <pages> pages 218-227, </pages> <month> January </month> <year> 1984. </year>
Reference: [Joh84b] <author> Steven D. Johnson. </author> <title> Synthesis of Digital Designs from Recursion Equations. </title> <booktitle> The ACM Distinguished Dissertation Series, </booktitle> <publisher> The MIT Press, </publisher> <address> Cam-bridge, MA, </address> <year> 1984. </year>
Reference: [Joh85] <author> Steven D. Johnson. </author> <title> Storage allocation for list multiprocessing. </title> <type> Technical Report 168, </type> <institution> Indiana University Computer Science Department, Bloom-ington, Indiana, </institution> <month> March </month> <year> 1985. </year>
Reference: [Joh86] <author> Steven D. Johnson. </author> <title> Digital design in a functional calculus. </title> <editor> In G. J. Milne and P. A. Subrahmanyam, editors, </editor> <booktitle> Workshop on Formal Aspects of VLSI Design (Proceedings of the Workshop on VLSI, </booktitle> <address> Edinburgh), 1985. </address> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <year> 1986. </year>
Reference: [Joh89a] <author> Steven D. Johnson. Daisy, dsi, and limp: </author> <title> architectural implications of suspending construction. </title> <type> Technical report, </type> <institution> Indiana University Computer Science Department, Bloomington, Indiana, </institution> <year> 1989. </year>
Reference: [Joh89b] <author> Steven D. Johnson. </author> <title> Daisy Programming Manual. </title> <institution> Indiana University Computer Science Department, Bloomington, </institution> <note> Indiana, second edition, 1989. (draft in progress, available by request). </note>
Reference-contexts: In this section we introduce Daisy and describe how suspending list construction gives rise to parallel programs. This description is necessarily brief; for a fuller description of the language, see The Daisy Programming Manual <ref> [Joh89b] </ref>. Daisy is a descendant of pure Lisp and is a contemporary of Scheme. It is a statically-scoped, lazy, applicative language. It provides a few atomic objects, such as numbers and literals (atoms). <p> A brief introduction to the language was given in section 2.3; for a full description of the language, see the Daisy Programming Manual <ref> [Joh89b] </ref>. 8.1 Demand Driven Computation It is instructive to understand the operation of the output-driven pipeline that is the conduit of demand in Daisy programs. Most Daisy programs are pipelined compositions of streams, terminated at either end by input and output devices.
Reference: [Joh89c] <author> Steven D. Johnson. </author> <title> How daisy is lazy. </title> <type> Technical report, </type> <institution> Indiana University Computer Science Department, Bloomington, Indiana, </institution> <year> 1989. </year>
Reference-contexts: Johnson presents simulation results of LiMP in [Joh81]. The fundamental motivation behind the NEW-sink is to move resource management problems from software into hardware. If the goal of the NEW-sink is to handle data distribution then the goal of the Process-sink <ref> [Joh89c] </ref> is to manage load balancing. The Process-sink is a complementary operation in which LPE's route free suspension blocks through the network to LSE's. <p> There also aren't any process termination interpretations such as the ubiquitous Control-C. Which process would this affect? DSI's process model is vastly different from conventional systems; there are many, many processes associated with any "job". The Daisy Programmer's Manual <ref> [Joh89c] </ref> has examples of how to do job control in Daisy using multisets. 7.4 Output Devices 97 7.4 Output Devices Output devices are symmetrically constructed to input devices. An output driver is a stream consumer of characters. <p> A number of other Scheme constructs like delay /force, continuations and engines share some characteristics with suspensions in various ways, but only futures share the inherent notion of concurrent process entities. A high-level, denotational analysis of these constructs vs. suspensions can be found in <ref> [Joh89c] </ref>. Conceptually, both suspensions and futures represent fine-grained tasks. However, most implementation descriptions of a future's state indicate a larger granularity than that of suspensions.
Reference: [Joh90] <author> Douglas Johnson. </author> <title> Trap architectures for lisp systems. </title> <booktitle> In ACM Conference on Lisp and Functional Programming, </booktitle> <pages> pages 79-86, </pages> <year> 1990. </year>
Reference-contexts: Such a feature would be a relatively minor enhancement to current microprocessor designs. By some estimates it could increase performance of Lisp programs by as much as 35 percent, at a cost of an additional 2 percent of CPU logic <ref> [Joh90] </ref>. By analyzing the design of DSI's virtual machine we can determine those architecture features that would accelerate the execution of fine-grained parallel symbolic programs; in particular, programs based on the suspending construction model of execution. <p> Tagged pointers are used to accelerate suspension detection and run-time type checking <ref> [Joh90, SH91] </ref> . We will hereafter refer to a tagged pointer as a reference or citation; a raw or untagged pointer is simply a pointer.
Reference: [Jon87] <editor> Simon L. Peyton Jones. </editor> <booktitle> The Implementation of Functional Programming Languages. </booktitle> <publisher> Prentice-Hall, </publisher> <year> 1987. </year>
Reference-contexts: An idea that has gained momentum in symbolic languages in recent years is the concept of speculative computation [Bur85a, Bur85b]. Speculative parallelism refers to scheduling parallel tasks that may not be needed (on the chance that they might) to increase available parallelism over that provided by regular conservative parallelism <ref> [Jon87] </ref>. For example, the two arms of a conditional might be scheduled in parallel with the evaluation of the predicate so that the system will have a head start on the overall result of the conditional regardless of the outcome of the predicate. <p> If the tenth element of the result is requested, one can assume that the expressions will be concurrently evaluated at least until ten of them have converged, and so forth. Many Daisy primitives have potential concurrency. add is an example of conservative parallelism <ref> [Jon87] </ref>; Daisy has many more opportunites for speculative parallelism [Jon87]. For example, a speculative OR-parallelism can be specified by 29 2.3 Daisy any?:[exp1 exp2 ... expN ] which returns true if any of its arguments are non-nil. <p> Many Daisy primitives have potential concurrency. add is an example of conservative parallelism <ref> [Jon87] </ref>; Daisy has many more opportunites for speculative parallelism [Jon87]. For example, a speculative OR-parallelism can be specified by 29 2.3 Daisy any?:[exp1 exp2 ... expN ] which returns true if any of its arguments are non-nil. Similarly, a speculative AND-parallelism is all?:[exp1 exp2 ... expN ] which returns nil if any of its arguments are nil. <p> This mechanism insures a timely interruption of the processor should a remote scheduling request become available. 6.7 Conservative vs. Speculative Parallelism Dynamic parallelism can be further classified into two types. Our hypothetical pcoerce primitive is a form of conservative parallelism <ref> [Jon87] </ref>, also called mandatory computation [Osb90]. In conservative parallelism the results of the parallel computations spawned are known to be needed (in the case of pcoerce because that's what the primitive requires). In contrast to conservative parallelism is speculative parallelism [Jon87] (also called 2 At least potentially so. <p> Our hypothetical pcoerce primitive is a form of conservative parallelism <ref> [Jon87] </ref>, also called mandatory computation [Osb90]. In conservative parallelism the results of the parallel computations spawned are known to be needed (in the case of pcoerce because that's what the primitive requires). In contrast to conservative parallelism is speculative parallelism [Jon87] (also called 2 At least potentially so. See section 5.2.2 and chapter 8. 78 6.7 Conservative vs. Speculative Parallelism speculative computation [Osb90]). The results of speculative processes are not known to be needed. Speculative processes are usually scheduled based on some probability of need. <p> This dissimilarity extends to the task model. Under graph reduction, a task is simply an available redex; this is just a pointer to a subgraph that can be reduced in parallel. The reduction machine will "spark" a parallel task <ref> [Jon87] </ref> by communicating this pointer to some other processor. In contrast, DSI's process decomposition occurs in list construction, not in reducing application redexes. Suspensions are implemented as a fine-grained process control records rather than as graph redexes.
Reference: [JP92a] <author> Suresh Jagannathan and Jim Philbin. </author> <title> A customizable substrate for concurrent languages. </title> <booktitle> In ACM SIGPLAN Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 55-67, </pages> <year> 1992. </year> <note> 141 REFERENCES </note>
Reference-contexts: DSI's kernel is independent of the Daisy language and could easily support other applicative languages (see section 9.2). In this regard, the DSI kernel can be compared to other generalized parallel symbolic processing kernels such as STING <ref> [JP92b, JP92a] </ref>, which was built around parallel Scheme, and Chare [KS88], which was motivated by concurrent Prolog. The DSI kernel differs from these systems, among other things, in that it is generally targeting a lower level of implementation. <p> Virtual machines for specific languages are not included here. Kernel issues relating to specific languages or implementations are described in the section 9.2.2. STING The STING project <ref> [JP92b, JP92a] </ref> lays claim to being a general purpose high-level parallel "substrate" for implementing parallel symbolic languages. The STING system offers a high-level programming environment (the system is based on a Scheme compiler) with a "concurrency toolkit" approach for implementing other languages.
Reference: [JP92b] <author> Suresh Jagannathan and Jim Philbin. </author> <title> A foundation for an efficient multi-threaded scheme system. </title> <booktitle> In ACM Conference on Lisp and Functional Programming, </booktitle> <pages> pages 345-355, </pages> <year> 1992. </year>
Reference-contexts: DSI's kernel is independent of the Daisy language and could easily support other applicative languages (see section 9.2). In this regard, the DSI kernel can be compared to other generalized parallel symbolic processing kernels such as STING <ref> [JP92b, JP92a] </ref>, which was built around parallel Scheme, and Chare [KS88], which was motivated by concurrent Prolog. The DSI kernel differs from these systems, among other things, in that it is generally targeting a lower level of implementation. <p> Virtual machines for specific languages are not included here. Kernel issues relating to specific languages or implementations are described in the section 9.2.2. STING The STING project <ref> [JP92b, JP92a] </ref> lays claim to being a general purpose high-level parallel "substrate" for implementing parallel symbolic languages. The STING system offers a high-level programming environment (the system is based on a Scheme compiler) with a "concurrency toolkit" approach for implementing other languages. <p> It also provides a great deal of flexibility for implementing other parallel languages on top of it, as in <ref> [JP92b] </ref>, although one implicitly inherits Scheme's control structures, memory management and other artifacts with this approach. Since these low-level hooks into the implementation exist, it is tempting to make them visible to the programmer, on the principle that it affords the programmer greater flexibility and capabilities.
Reference: [Kie86] <author> Richard B. Kieburtz. </author> <title> Incremental collection of dynamic, list-structure memories. </title> <type> Technical report, </type> <institution> Oregon Graduate Center, </institution> <month> January </month> <year> 1986. </year> <note> Technical Report CS/E-85-008. </note>
Reference-contexts: Our system has the advantage of parallel collection in all phases, so that collection pauses increase according to the heap size divided by the total number of processors. Nevertheless, this still allows for significant pauses. I would like to incorporate an incremental garbage collector <ref> [AAL88, Moo84, Kie86] </ref> to avoid the latency penalties incurred by the current collector. The incremental collector should preserve locality of data as in the current scheme and not migrate data or processes to other processor nodes.
Reference: [Koh81] <author> Anne T. Kohlstaedt. </author> <title> Daisy 1.0 reference manual. </title> <type> Technical Report 119, </type> <institution> Indiana University Computer Science Department, Bloomington, Indi-ana, </institution> <year> 1981. </year> <note> ([Joh89a] should be delivered implicitly). </note>
Reference: [KS88] <author> L.V. Kale and Wennie Shu. </author> <title> The chare-kernel language for parallel programming: A perspective. </title> <type> Technical report, </type> <institution> University of Illinois, </institution> <month> August </month> <year> 1988. </year>
Reference-contexts: DSI's kernel is independent of the Daisy language and could easily support other applicative languages (see section 9.2). In this regard, the DSI kernel can be compared to other generalized parallel symbolic processing kernels such as STING [JP92b, JP92a], which was built around parallel Scheme, and Chare <ref> [KS88] </ref>, which was motivated by concurrent Prolog. The DSI kernel differs from these systems, among other things, in that it is generally targeting a lower level of implementation. <p> STING's approach is to allow the programmer full control (and thus full responsibility) over process decomposition, mapping, etc. The Chare Kernel The Chare kernel <ref> [KS88] </ref> is closer in spirit to DSI than the STING system described above. The Chare kernel was developed to support the distributed execution of Prolog on message-passing multiprocessors, although it is touted as a general-purpose parallel programming environment. <p> It is not clear how speculative processing could be handled in the Chare kernel. Chares can be created with specific priorities, but termination is explicit (a chare kills 124 9.3 Related work itself). It is unclear from <ref> [KS88] </ref> whether or how chares are garbage collected (or for that matter, how storage management in general is handled). In summary, the Chare system bears a resemblance to DSI in that the process granularity is similar and the goals of the two systems are total process resource management.
Reference: [KW90] <author> Morry Katz and Daniel Weisse. </author> <title> Continuing into the future: On the interaction of futures and first-class continuations. </title> <booktitle> In ACM Conference on Lisp and Functional Programming, </booktitle> <pages> pages 176-184, </pages> <year> 1990. </year>
Reference-contexts: If side-effects are included, some general-purpose visible synchronization constructs will need to be provided in the language. Also, the interaction of continuations across process boundaries is troublesome <ref> [KW90] </ref>. If side-effects are not provided, the language is free to be parallel wherever possible in its primitives (including speculatively) 120 9.3 Related work just like Daisy.
Reference: [Lar91] <author> James R. Larus. </author> <title> Compiling lisp programs for parallel execution. </title> <journal> Lisp and Symbolic Computation, </journal> <volume> 4 </volume> <pages> 29-99, </pages> <year> 1991. </year>
Reference: [LD88] <author> Yue-Sheng Liu and Susan Dickey. </author> <title> Simulation and analysis of different switch architectures for interconnection networks in mimd shared memory machines. </title> <type> Technical report, </type> <institution> Courant Institute of Mathematical Sciences, </institution> <month> June </month> <year> 1988. </year> <note> Ultracomputer Note #141. </note>
Reference-contexts: Multiprocessor architectures using the latter type are called Non-Uniform Memory Access (NUMA) designs [AG94]. NUMA architectures are generally more scalable, since they are designed using a many processor-to-many memory network <ref> [LD88] </ref> as opposed to several processors attached to one or more memory banks on a bus, which limits scalability due to bandwidth limitations. <p> The rationale for this is that in the absence of any other useful metric we should distribute data as evenly as possible to prevent network hot spots <ref> [PCYL87, LD88, MRSL88] </ref>. The other logical benefit is simply to balance allocation across processors. The responsiveness of the allocation servers is deliberately underplayed. The server is not signal-activated (event-driven) like other system processes. <p> The interval between polls should be spent executing any other ready processes on the node. In some cases it may be necessary for the processor to artificially extend its polling interval with idle periods, since flagrant busy waiting could have deleterious effects on the processor network <ref> [LD88, PCYL87] </ref>. This might be the case, for example, early on in the computation before the program has established many parallel tasks. 4. Synchronization latency refers to the lag between the time that a suspension has converged and the time that a process depending on it is actually resumed.
Reference: [Liv88] <author> Brian K. Livesey. </author> <title> The aspen distributed stream processing environment. </title> <type> Technical report, </type> <institution> UCLA, </institution> <month> December </month> <year> 1988. </year> <note> UCLA Technical Report CSD-880102. </note>
Reference: [Mil87] <author> James S. Miller. Multischeme: </author> <title> A Parallel Processing System based on MIT Scheme. </title> <type> PhD thesis, </type> <month> September </month> <year> 1987. </year> <note> Also available as MIT Technical Report MIT/LCS/TR-402. 142 REFERENCES </note>
Reference-contexts: This is usually coupled with a suitably-modified garbage collector to remove pointers to the speculative tasks from the scheduling infrastructure if they have been unreferenced from the programs data structures <ref> [BH77, Mil87] </ref>. 2.2.3 Device Management The third major area of kernel support is for device management. A number of lazy languages use a stream model of I/O interface [Hud89] in which data is read or written from devices in streams. <p> A common solution to the problem is to endow the garbage collector with the capability to "close" the device, possibly through a generic finalization facility <ref> [Mil87] </ref>. This problem is an artifact of an underlying imperative model of I/O that could be avoided using a functional file system [HW92]. The stream model of computing, while elegant, has its limitations. <p> DSI must provide a way to remove identifiers that are not referenced outside of the hash table and recover the space. Most systems facing this problem use weak pointers or similar mechanisms <ref> [Mil87] </ref>. DSI takes a slightly different approach. The hash table is maintained as a global entity that is not reachable from any garbage collection root. During collection, the normal mark phase marks any identifiers that are reachable from live data. <p> A second minor phase devoted to collecting the device list is discussed in chapter 7. These two minor phases correspond to the hash demon and files demon described in <ref> [Mil87] </ref>. 5.3.3 Garbage Collection: Observations Our garbage collection algorithm is neither efficient or full-featured compared to others described in the literature (e.g. [AAL88]), nevertheless we are encouraged by recent studies on the efficiency of mark-sweep collection [Zor90, HJBS91]. <p> The approaches used by current parallel symbolic systems generally fall into two categories: explicit killing of tasks [GP81, Hem85] and garbage collection of tasks <ref> [BH77, Mil87] </ref>. 81 6.7 Conservative vs. Speculative Parallelism The first approach, explicit killing of tasks, relies on the kernel being able to determine when a task has become useless. <p> This approach assumes that useless tasks have become unreferenced from the computation graph. In order to keep them from being retained by scheduling references, weak pointers or weak cons cells <ref> [Mil87] </ref> must be used to build scheduling infrastructure containing pointers to tasks so that they aren't retained unnecessarily. A potential problem with this approach is that useless tasks continue to remain in the system until garbage collection [Osb90]. <p> The device list and the hash table are the only two structures that are collected specially by the garbage collector. The implementation is different, but the effect is identical to that of the files demon in MultiScheme <ref> [Mil87] </ref>. 7.3.4 Flavors of Input Devices This section describes the differences between the various kinds of of input devices supported by DSI. Disk Input DSI relies on the host filesystem to manage files. <p> While the current implementation is satisfactory for smaller single user sessions, a larger layered software architecture or multiuser environment will require the shared global namespace issue (see chapter 4) to be resolved. Some Lisp-based systems address this issue through per-task storage based on fluid-binding <ref> [Mil87] </ref>, first class environments, or extending deep binding to top-level environments [DAKM89]. A flexible module or package system for Daisy would address this problem in a more general way that might have benefits for other languages implemented on DSI. <p> This is particularly true regarding the body of work centered around the future construct used in Multilisp [RHH85, RHH86, Osb90], and its offspring, MultiScheme <ref> [Mil87] </ref> and Mul-T [DAKM89]. There seems to have been a cross-fertilization of ideas in the genesis of suspensions and futures [BH77, RHH85], although the work on suspensions seems to predate that of futures [FW76a, FW76b]. <p> This may have 127 9.3 Related work motivated the work on lazy future creation [Moh90] used in Mul-T (see below). MultiScheme MultiScheme <ref> [Mil87, FM90] </ref> is a parallel dialect of MIT-Scheme, extended to support futures. Miller's dissertation [Mil87] concentrates on the details of extending MIT Scheme to support futures and the other features of MultiScheme. <p> This may have 127 9.3 Related work motivated the work on lazy future creation [Moh90] used in Mul-T (see below). MultiScheme MultiScheme [Mil87, FM90] is a parallel dialect of MIT-Scheme, extended to support futures. Miller's dissertation <ref> [Mil87] </ref> concentrates on the details of extending MIT Scheme to support futures and the other features of MultiScheme. The MultiScheme sched-uler, written in Scheme, and presented in the thesis, uses a set of primitive functions to pass tasks to the underlying multiprocessing engine for distribution.
Reference: [Moh90] <author> Eric et. al. Mohr. </author> <title> Lazy task creation: A technique for increasing the granularity of parallel programs. </title> <booktitle> In ACM Conference on Lisp and Functional Programming, </booktitle> <pages> pages 185-197, </pages> <year> 1990. </year>
Reference-contexts: Once the machine is fully utilized it is counterproductive to schedule additional tasks. The additional parallelism causes higher peak memory usage and increased context switching, reducing throughput. If the language has eager semantics, one solution to the problem is to revert to in-lining the computation <ref> [Moh90] </ref>, thus increasing the grain size. If the language is lazy, there may be less choice in reducing granularity, but also less 23 2.2 Kernel Issues parallelism to contend with. In either case, the kernel should provide a way to automatically control the growth of parallelism in the system. <p> This mechanism must be dynamic, since the amount and type of parallelism all depend on the program and data. One technique to constraining parallelism is to tie process creation (i.e. granularity) to the load of the machine <ref> [GM84, Moh90] </ref>. For explicitly eager parallel languages (e.g. futures), this may be possible. For Daisy, the laziness of suspensions is a semantic requirement; there is no way to randomly "inline" a suspension without changing the semantics of the language 1 . <p> Halstead notes that under the LIFO scheduling strategy, once the system is saturated, futures complete before their parent task ever gets resumed; in essence, the future expression could have been evaluated on the stack. This may have 127 9.3 Related work motivated the work on lazy future creation <ref> [Moh90] </ref> used in Mul-T (see below). MultiScheme MultiScheme [Mil87, FM90] is a parallel dialect of MIT-Scheme, extended to support futures. Miller's dissertation [Mil87] concentrates on the details of extending MIT Scheme to support futures and the other features of MultiScheme. <p> DSI's use of a stack for local suspensions rather than a queue plus the lack of stealing may provide even more parallelism throttling than is available under Mul-T's queuing scheme. Note, however, that Mul-T uses a technique called lazy task creation <ref> [Moh90] </ref> to increase granularity of programs dynamically by inlining, and this probably reduces the need for kernel-based throttling. This technique is unlikely to be applicable to a lazy language like Daisy, which relies on suspension creation for laziness in addition to parallelism. DSI's suspensions are also likely smaller than futures.
Reference: [Moo84] <author> David Moon. </author> <title> Garbage collection in a large lisp system. </title> <booktitle> In ACM Conference on Lisp and Functional Programming, </booktitle> <pages> pages 235-346, </pages> <month> August </month> <year> 1984. </year>
Reference-contexts: This is reflected in DSI's use of context windows and demand driven scheduling traps in the virtual machine. Another major difference is in virtual memory support, or lack thereof. Studies of the interaction between virtual memory and heap-based, symbolic languages <ref> [Moo84] </ref> reveal that the large memory requirements of symbolic languages plus the non-locality of heap allocation and garbage collection do not mesh well with conventional virtual memory systems which depend heavily on spatial locality. <p> Our system has the advantage of parallel collection in all phases, so that collection pauses increase according to the heap size divided by the total number of processors. Nevertheless, this still allows for significant pauses. I would like to incorporate an incremental garbage collector <ref> [AAL88, Moo84, Kie86] </ref> to avoid the latency penalties incurred by the current collector. The incremental collector should preserve locality of data as in the current scheme and not migrate data or processes to other processor nodes.
Reference: [MRSL88] <author> Robert R. Kessler Mark R. Swanson and Gary Lindstrom. </author> <title> An implementation of portable standard lisp on the bbn butterfly. </title> <booktitle> In ACM Symposium on Lisp and Functional Programming, </booktitle> <pages> pages 132-141, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: The allocation vectors provide a general mechanism by which data can be allocated on any particular processor in the system. The technique of allocating larger blocks of free space and then suballocating out of it improves efficiency by reducing the frequency of communication costs between processors <ref> [MRSL88] </ref>. The free blocks pointed to by the allocation vector are preallocated and reserved ; there are no mutual exclusion problems to contend with to arbitrate access to the blocks. <p> This request/donate allocation mechanism stands in contrast to the shared heap state variables used in other systems <ref> [DAKM89, MRSL88] </ref>. Although the allocation block/suballocation technique can be (and is) used in these systems, processors must occasionally synchronize for access to shared global allocation pointers. <p> The rationale for this is that in the absence of any other useful metric we should distribute data as evenly as possible to prevent network hot spots <ref> [PCYL87, LD88, MRSL88] </ref>. The other logical benefit is simply to balance allocation across processors. The responsiveness of the allocation servers is deliberately underplayed. The server is not signal-activated (event-driven) like other system processes. <p> However, the authors [GM84] describe the use of a single shared queue for distributing work among processors, hence the name, QLisp. Butterfly Portable Standard Lisp A group at the University of Utah has also implemented Lisp on the BBN Butterfly <ref> [MRSL88] </ref>. PSL is a standard Lisp augmented with futures and fluid binding to support concurrent name spaces. The memory management described in [MRSL88] has some resemblance to DSI's. It divides the heap into segments across all processors. <p> Butterfly Portable Standard Lisp A group at the University of Utah has also implemented Lisp on the BBN Butterfly <ref> [MRSL88] </ref>. PSL is a standard Lisp augmented with futures and fluid binding to support concurrent name spaces. The memory management described in [MRSL88] has some resemblance to DSI's. It divides the heap into segments across all processors. Distributed allocation is accomplished by allocating chunks out of the global heap; suballocation occurs out of the chunk until it is exhausted, at which point another global chunk is allocated. <p> This supports our load-balancing scheme in which suspensions only execute locally (see section 5.2.2); under PSL, blocked tasks can be rescheduled on any processor. An interesting result in <ref> [MRSL88] </ref> supports our choice of distributed allocation of cells for the BBN Butterfly. They first tried a local allocation scheme, which fared poorly due to contention; a subsequent refinement to distributed round-robin allocation improved performance (see chapter 5). The garbage collector described in [MRSL88] is a monolithic and sequential (i.e. it <p> An interesting result in <ref> [MRSL88] </ref> supports our choice of distributed allocation of cells for the BBN Butterfly. They first tried a local allocation scheme, which fared poorly due to contention; a subsequent refinement to distributed round-robin allocation improved performance (see chapter 5). The garbage collector described in [MRSL88] is a monolithic and sequential (i.e. it runs on one processor) stop-and-copy design; DSI's mark-sweep collector is distributed and fully parallel in all phases.
Reference: [O'D] <author> John T. O'Donnell. </author> <title> An applicative programming environment. </title> <type> (draft, unpublished). </type>
Reference: [O'D85] <author> John T. O'Donnell. </author> <title> Dialogues: a basis for constructing programming environments. </title> <booktitle> In 1985 ACM SIGPLAN Symposium on Programming Languages and Programming Environments, in ACM SIGPLAN Notices, </booktitle> <volume> Vol. 20, No. 7, </volume> <month> July </month> <year> 1985. </year>
Reference: [O'D87] <author> John T. O'Donnell. </author> <title> Hardware description with recursion equations. </title> <booktitle> In Proc IFIP 8th International Symposium on Computer Hardware Description Languages and their Applications [CHDL], </booktitle> <year> 1987. </year>
Reference: [OH87] <author> John T. O'Donnell and Cordelia Hall. </author> <title> Debugging in applicative languages. </title> <type> Technical Report 223, </type> <institution> Indiana University Computer Science Department, Bloomington, Indiana, </institution> <month> June </month> <year> 1987. </year> <note> To appear in the International Journal on Lisp and Symbolic Computation. </note> <editor> [OK92] et. al. O. </editor> <title> Kaser. Fast parallel implementations of lazy languages: The equals experience. </title> <booktitle> In ACM Conference on Lisp and Functional Programming, </booktitle> <pages> pages 335-344, </pages> <year> 1992. </year>
Reference: [Osb90] <author> Randy B. Osborne. </author> <title> Speculative computation in multilisp-an overview. </title> <booktitle> In ACM Conference on Lisp and Functional Programming, </booktitle> <pages> pages 198-208, </pages> <year> 1990. </year> <title> REFERENCES </title>
Reference-contexts: Finally, systems with side-effects must also deal with the decision of whether to abort or to "roll-back" side-effects that are the result of useless speculation <ref> [Osb90] </ref>. One solution to these problem (assuming that the speculative tasks can be distinguished) is to spawn a "termination process" to kill them [GP81, Hem85]. Another approach is to implement some kind of priority mechanism that dynamically upgrades or downgrades the status of a speculative process and its descendants [Osb90]. <p> speculation <ref> [Osb90] </ref>. One solution to these problem (assuming that the speculative tasks can be distinguished) is to spawn a "termination process" to kill them [GP81, Hem85]. Another approach is to implement some kind of priority mechanism that dynamically upgrades or downgrades the status of a speculative process and its descendants [Osb90]. This is usually coupled with a suitably-modified garbage collector to remove pointers to the speculative tasks from the scheduling infrastructure if they have been unreferenced from the programs data structures [BH77, Mil87]. 2.2.3 Device Management The third major area of kernel support is for device management. <p> This mechanism insures a timely interruption of the processor should a remote scheduling request become available. 6.7 Conservative vs. Speculative Parallelism Dynamic parallelism can be further classified into two types. Our hypothetical pcoerce primitive is a form of conservative parallelism [Jon87], also called mandatory computation <ref> [Osb90] </ref>. In conservative parallelism the results of the parallel computations spawned are known to be needed (in the case of pcoerce because that's what the primitive requires). In contrast to conservative parallelism is speculative parallelism [Jon87] (also called 2 At least potentially so. <p> In contrast to conservative parallelism is speculative parallelism [Jon87] (also called 2 At least potentially so. See section 5.2.2 and chapter 8. 78 6.7 Conservative vs. Speculative Parallelism speculative computation <ref> [Osb90] </ref>). The results of speculative processes are not known to be needed. Speculative processes are usually scheduled based on some probability of need. <p> There are a number of useful applications of speculative computation; section 2.3 contains several examples. Osborne <ref> [Osb90] </ref> provides a partial taxonomy for classifying speculative computation types. 6.7.1 Managing Speculative Computation Speculative computation offers additional sources of parallelism over what may be available from conservative parallelism alone, but at the same time it introduces significant resource management problems: 1. <p> Speculative Parallelism Thus, once a task has been scheduled speculatively, neither it nor any of its descendants should be scheduled to a conservative queue. At first, this approach does not seem to provide for contagion <ref> [Osb90] </ref>; namely, if sharing relationships are such that a conservative process comes to depend on a speculative task (e.g. by probing it after it has been scheduled speculatively elsewhere, like our speculative conditional) the speculative process should be upgraded to conservative, and any tasks it depends on should be upgraded as <p> A potential problem with this approach is that useless tasks continue to remain in the system until garbage collection <ref> [Osb90] </ref>. One way to prevent this is through the use of priorities, especially if priorities are already being used to give conservative tasks preference. When a task is discovered to be useless, priorities can be propagated down through the speculative process subgraph to downgrade the status of all descendant tasks. <p> As with the killing approach, the kernel must be able to distinguish the useful from the useless as it descends the subtree; this may require a sophisticated priority combining scheme <ref> [Osb90] </ref>. 6.7.2 Demand Coefficients The methods described above are both rather active; that is, the kernel must proactively detect useless tasks and attempt to restructure the schedule to mirror the changing state of actual dependences occurring in the program. <p> In order to keep it going, the scheduling process must coax it again; a process may need to be coaxed a number of times before it finally converges. This approach supports a number of speculative models <ref> [Osb90] </ref>. Simple precom-puting speculation is accomplished by a single coax. This type of speculation simply channels some effort into executing a suspension on the chance that it's result will be needed later. <p> This handles the case where a suspension is scheduled speculatively by one process and later is probed by a conservative process. In this case the speculative process should be upgraded to conservative status, a situation Osborne calls contagion <ref> [Osb90] </ref>. The first time the process will be scheduled to a 84 6.8 Sharing and Cycles speculative queue (or stack), but the second probe will result in the process also being queued on a conservative queue (or stack). <p> That in itself is not surprising, since Lisp is the grandfather of symbolic processing, and the seminal research leading to the work presented here was conducted in Lisp. This is particularly true regarding the body of work centered around the future construct used in Multilisp <ref> [RHH85, RHH86, Osb90] </ref>, and its offspring, MultiScheme [Mil87] and Mul-T [DAKM89]. There seems to have been a cross-fertilization of ideas in the genesis of suspensions and futures [BH77, RHH85], although the work on suspensions seems to predate that of futures [FW76a, FW76b]. <p> Weak cons cells are used to build the waiting (blocking) queues used for tasks waiting on the value of a future (placeholder in MultiScheme), so that any speculative task that has been dereferenced elsewhere will not be retained following a garbage collection. Osborne <ref> [Osb90] </ref> notes that the success of this approach depends on the frequency of garbage collection, although priority propagation was later added to downgrade speculative tasks between collections. <p> DSI removes speculative tasks from the system implicitly. Kranz [DAKM89] provides no indication of how speculative computation is handled, if at all, in Mul-T. The techniques used in <ref> [Osb90] </ref> may be a possible direction for Mul-T in this regard. Mul-T's I/O also shares similarities with DSI's device management. Mul-T uses a "distinguished task" dedicated to terminal I/O to avoid the problems of shared, parallel I/O; this corresponds roughly with DSI's input device manager (see chapter 7).
Reference: [PCYL87] <author> Nian-Feng Tzeng Pen-Chung Yew and Duncan H. Lawrie. </author> <title> Distributed hot-spot addressing in large-scale multiprocessors. </title> <journal> IEEE Transactions on Computers, </journal> <volume> c-36(4):388-395, </volume> <month> April </month> <year> 1987. </year>
Reference-contexts: These concerns constrain the way that the heap is allocated, how objects are allocated within the heap, and how processors cooperate to manage the heap. In this regard, there are two relevant considerations for NUMA architectures. One is the presence of network "hot spots" <ref> [PCYL87] </ref> where excess memory contention between processors can degrade performance (non-NUMA designs also suffer from memory contention, but it is mitigated by the use of heavy coherent caching). A second concern with NUMA architectures is locality. <p> The rationale for this is that in the absence of any other useful metric we should distribute data as evenly as possible to prevent network hot spots <ref> [PCYL87, LD88, MRSL88] </ref>. The other logical benefit is simply to balance allocation across processors. The responsiveness of the allocation servers is deliberately underplayed. The server is not signal-activated (event-driven) like other system processes. <p> The interval between polls should be spent executing any other ready processes on the node. In some cases it may be necessary for the processor to artificially extend its polling interval with idle periods, since flagrant busy waiting could have deleterious effects on the processor network <ref> [LD88, PCYL87] </ref>. This might be the case, for example, early on in the computation before the program has established many parallel tasks. 4. Synchronization latency refers to the lag between the time that a suspension has converged and the time that a process depending on it is actually resumed.
Reference: [PRWM92] <author> Michael S. Lam Paul R. Wilson and Thomas G. Moher. </author> <title> Caching considerations for generational garbage collection. </title> <booktitle> In ACM Conference on Lisp and Functional Programming, </booktitle> <pages> pages 32-42, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: The development of generational garbage collection has reduced the problem somewhat <ref> [PRWM92] </ref>, but the issue is still a topic of active research. Lazy languages such as Daisy may have even worse virtual-memory locality than applicative-order languages such as Scheme, which can make heavy use of stack frames.
Reference: [Rep91] <author> John H. Reppy. </author> <title> Cml: A higher-order concurrent language. </title> <booktitle> In ACM Symposium on Programming Language Design and Implementation, </booktitle> <pages> pages 293-305, </pages> <year> 1991. </year>
Reference-contexts: This approach requires a working knowledge of the widget and drawing interfaces in C. The eXene environment for CML <ref> [Rep91] </ref> is an example of a more general lower level use of streams to control a GUI interface. eXene models each window as a collection of streams: mouse, keyboard and control streams.
Reference: [RHH85] <author> Jr. Robert H. Halstead. </author> <title> Multilisp: A language for concurrent symbolic computation. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 7(4) </volume> <pages> 501-538, </pages> <month> October </month> <year> 1985. </year>
Reference-contexts: The issue of process granularity is related to process creation; if creation is explicit in the surface language (e.g. futures <ref> [RHH85] </ref>), the grain size is generally larger than if process creation is implicit, such as in Daisy; in either case process granularity is finer and less stateful than in traditional languages. This finer granularity leads to increased amounts of context switching, which must be handled in an efficient way. <p> Our system of load-balancing stands in contrast to most other symbolic processing systems which actively move processes around to try to balance the system, or have processors steal tasks from other processor's ready queues <ref> [RHH85, DAKM89] </ref>. <p> This would cut down on the amount of interprocessor communication required to transfer execution requests to other processors, but would also require a new method of load balancing to be devised. Task stealing <ref> [RHH85] </ref> might be appropriate in this case. 5.3 Storage Reclamation Like many other heap-based symbolic processing systems, DSI uses garbage collection as its primary method of storage reclamation. <p> Then, when a process converges, the system could simply reschedule all suspensions in the wait queue. This is the approach used by Multilisp <ref> [RHH85] </ref> and most other implementations. There are several reasons why DSI does not do this. First, speculative computation renders all dependences to be potentially speculative. A given demand chain may be the result of a speculative computation. <p> These experiments would target: * Load-balancing effectiveness and performance compared to other systems. I am particularly interested in comparing my allocation-based system with the task-stealing mechanism used in Multilisp <ref> [RHH85] </ref> and its offshoots. * An analysis of the effects of allocation block size on parallelism and load bal ancing. * Our local task execution model should be analytically compared to systems which use task migration strategies or non-local process execution. <p> That in itself is not surprising, since Lisp is the grandfather of symbolic processing, and the seminal research leading to the work presented here was conducted in Lisp. This is particularly true regarding the body of work centered around the future construct used in Multilisp <ref> [RHH85, RHH86, Osb90] </ref>, and its offspring, MultiScheme [Mil87] and Mul-T [DAKM89]. There seems to have been a cross-fertilization of ideas in the genesis of suspensions and futures [BH77, RHH85], although the work on suspensions seems to predate that of futures [FW76a, FW76b]. <p> This is particularly true regarding the body of work centered around the future construct used in Multilisp [RHH85, RHH86, Osb90], and its offspring, MultiScheme [Mil87] and Mul-T [DAKM89]. There seems to have been a cross-fertilization of ideas in the genesis of suspensions and futures <ref> [BH77, RHH85] </ref>, although the work on suspensions seems to predate that of futures [FW76a, FW76b]. A number of other Scheme constructs like delay /force, continuations and engines share some characteristics with suspensions in various ways, but only futures share the inherent notion of concurrent process entities. <p> The information presented here is gleaned from various papers in the bibliography, cited here where appropriate. Multilisp Multilisp is a version of Scheme with futures implemented on the experimental Concert multiprocessor at MIT <ref> [RHH85, RHH86] </ref>. Multilisp was instrumental in starting the parallel Lisp revolution, providing one of the first working implementations of futures, and bringing many fine-grained parallel resource management issues to light. Multilisp's memory management is based on a copying, incremental collector. <p> Mul-T scheduling uses two queues per processor, one for new tasks and one for resumed blocked tasks. Blocked tasks are restarted on the processor on which they last executed, in an attempt to improve snoopy cache locality, but tasks may migrate around the system due to stealing <ref> [RHH85] </ref>. The scheduling priority is as follows: 1. Run a task from the processor's own suspended task queue. 2. Run a task from the processor's own new task queue. 129 9.3 Related work 3. Steal a task from the new task queue of another processor. 4.
Reference: [RHH86] <author> Jr. Robert H. Halstead. </author> <title> An assessment of multilisp: Lessons from experience. </title> <journal> International Journal of Parallel Programming, </journal> <volume> 15(6) </volume> <pages> 459-500, </pages> <year> 1986. </year>
Reference-contexts: That in itself is not surprising, since Lisp is the grandfather of symbolic processing, and the seminal research leading to the work presented here was conducted in Lisp. This is particularly true regarding the body of work centered around the future construct used in Multilisp <ref> [RHH85, RHH86, Osb90] </ref>, and its offspring, MultiScheme [Mil87] and Mul-T [DAKM89]. There seems to have been a cross-fertilization of ideas in the genesis of suspensions and futures [BH77, RHH85], although the work on suspensions seems to predate that of futures [FW76a, FW76b]. <p> The information presented here is gleaned from various papers in the bibliography, cited here where appropriate. Multilisp Multilisp is a version of Scheme with futures implemented on the experimental Concert multiprocessor at MIT <ref> [RHH85, RHH86] </ref>. Multilisp was instrumental in starting the parallel Lisp revolution, providing one of the first working implementations of futures, and bringing many fine-grained parallel resource management issues to light. Multilisp's memory management is based on a copying, incremental collector.
Reference: [RMKT84] <author> Frank C.H. Lin Robert M. Keller and Jiro Tanaka. </author> <title> Rediflow multiprocessing. </title> <booktitle> In IEEE COMPCON, </booktitle> <pages> pages 410-417, </pages> <year> 1984. </year>
Reference-contexts: The integration of the two styles would be very similar to that described for Rediflow <ref> [RMKT84] </ref>.
Reference: [SH91] <author> Peter Steenkiste and John Hennessy. </author> <title> Tags and type checking in lisp: Hardware and software approaches. </title> <booktitle> In ACM Conference on Architectural Support for Programming Languages and Systems, </booktitle> <pages> pages 50-59, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: This aspect of the virtual machine approach can identify architecture support that would be useful for accelerating language execution on actual hardware [Tra84, Veg84]. For example, dynamic tag-checking has long been considered a prime candidate for hardware support of Lisp programs <ref> [SH91] </ref>. Such a feature would be a relatively minor enhancement to current microprocessor designs. By some estimates it could increase performance of Lisp programs by as much as 35 percent, at a cost of an additional 2 percent of CPU logic [Joh90]. <p> Tagged pointers are used to accelerate suspension detection and run-time type checking <ref> [Joh90, SH91] </ref> . We will hereafter refer to a tagged pointer as a reference or citation; a raw or untagged pointer is simply a pointer.
Reference: [Sin91] <author> Satnam Singh. </author> <title> Using xview/x11 from miranda. </title> <booktitle> In Workshops in Computing, Functional Programming, </booktitle> <pages> pages 353-363, </pages> <year> 1991. </year>
Reference-contexts: The black windows are quiescent; the white windows are currently expecting input. As of this writing, xdsi only supports unidirectional text windows. An obvious extension to this approach is to allow other specialized types of windows, such as GUI widgets. The xvi system <ref> [Sin91] </ref> is a windowing interface for a lazy functional language that is also implemented using a server approach (although in a more tightly coupled way than xdsi).
Reference: [TK88] <author> Pete Tinker and Morry Katz. </author> <title> Parallel execution of sequential scheme with paratran. </title> <booktitle> In ACM Symposium on Lisp and Functional Programming, </booktitle> <pages> pages 28-39, </pages> <month> January </month> <year> 1988. </year>
Reference: [Tra84] <author> Kenneth R. Traub. </author> <title> An abstract architecture for parallel graph reduction. </title> <type> Technical report, </type> <institution> MIT, </institution> <month> September </month> <year> 1984. </year> <note> Also available as MIT Technical Report MIT/LCS/TR-317. 144 REFERENCES </note>
Reference-contexts: The special needs of a language or its computation model are often distilled into specific features or instructions in the virtual machine to facilitate and accelerate execution. This aspect of the virtual machine approach can identify architecture support that would be useful for accelerating language execution on actual hardware <ref> [Tra84, Veg84] </ref>. For example, dynamic tag-checking has long been considered a prime candidate for hardware support of Lisp programs [SH91]. Such a feature would be a relatively minor enhancement to current microprocessor designs.
Reference: [Tra91] <author> Kenneth R. Traub. </author> <title> Implementation of Non-Strict Functional Programming Languages. </title> <publisher> MIT Press, </publisher> <year> 1991. </year>
Reference: [Veg84] <author> Steven R. Vegdahl. </author> <title> A survey of proposed architectures for the execution of functional languages. </title> <journal> IEEE Transactions on Computers, </journal> <volume> c-33(12):1050-1071, </volume> <month> December </month> <year> 1984. </year>
Reference-contexts: The special needs of a language or its computation model are often distilled into specific features or instructions in the virtual machine to facilitate and accelerate execution. This aspect of the virtual machine approach can identify architecture support that would be useful for accelerating language execution on actual hardware <ref> [Tra84, Veg84] </ref>. For example, dynamic tag-checking has long been considered a prime candidate for hardware support of Lisp programs [SH91]. Such a feature would be a relatively minor enhancement to current microprocessor designs.
Reference: [WF87] <author> David S. Wise and John Franco. </author> <title> Costs of quadtree representation of non-dense matrices. </title> <type> Technical Report 229, </type> <institution> Indiana University Computer Science Department, Bloomington, Indiana, </institution> <month> October </month> <year> 1987. </year>
Reference: [Wis81] <author> David S. Wise. </author> <title> Compact layout of banyan/fft networks. </title> <editor> In H. Kung, B. Sproull, and G. Steele, editors, </editor> <booktitle> VLSI Systems and Computations, </booktitle> <pages> pages 186-195. </pages> <publisher> Computer Science Press, </publisher> <address> Rockville, MD, </address> <year> 1981. </year>
Reference-contexts: In a series of papers, Johnson ([Joh81, Joh85, Joh89c]) refines a buffered routing network as the basis for a DSI multiprocessor. Wise describes a layout scheme for implementing such a network in <ref> [Wis81] </ref>. The network described is a Banyan design (see figure 8) connecting a set of List Processing Elements (LPEs) to a corresponding set of List Storage Elements (LSE's). LPE's have roughly the same architecture described for DSI processors in section 3.2 above, but lack multiple context windows and signals.
Reference: [Wis84a] <author> David S. Wise. </author> <title> Parallel decomposition of matrix inversion using quadtrees. </title> <booktitle> In Proc. 1984 International Conference on Parallel Processing, </booktitle> <pages> pages 92-99, </pages> <year> 1984. </year> <note> (available as IEEE Cat. No. 86CH2355-6). </note>
Reference: [Wis84b] <author> David S. Wise. </author> <title> Representing matrices as quadtrees for parallel processors. </title> <journal> ACM SIGSAM Bulletin 18, </journal> <volume> 3, </volume> <pages> pages 24-25, </pages> <month> August </month> <year> 1984. </year> <note> (extended abstract). </note>
Reference: [Wis85a] <author> David S. Wise. </author> <title> Design for a multiprocessing heap with on-board reference counting. </title> <editor> In J. P. Jouannaud, editor, </editor> <booktitle> Functional Programming Languages and Computer Architecture, </booktitle> <pages> pages 289-304. </pages> <address> Springer-Berlin, </address> <year> 1985. </year>
Reference-contexts: Wise has identified a number of other features that would be useful for hardware-assisted heap management, such as support for reference counts <ref> [Wis85a, DW94] </ref>. 3.6 Summary 43 3.6 Summary 44 chapter four The DSI Kernel DSI refers not only to our virtual hardware architecture, but also to a kernel written for that architecture (see figure 4, p. 31).
Reference: [Wis85b] <author> David S. Wise. </author> <title> Representing matrices as quadtrees for parallel processors. </title> <journal> Information Processing Letters 20, </journal> <pages> pages 195-199, </pages> <month> May </month> <year> 1985. </year>
Reference: [Wis86a] <author> David S. Wise. </author> <title> An applicative programmer's approach to matrix algebra, lessons for hardware, </title> <booktitle> and software. In Workshop on Future Directions in Computer Architecture and Software, </booktitle> <institution> Army Research Office, </institution> <year> 1986. </year>
Reference: [Wis86b] <author> David S. Wise. </author> <title> Parallel decomposition of matrix inversion using quadtrees. </title> <booktitle> In Proc. 1986 IEEE Intl. Conf. on Parallel Processing. IEEE, </booktitle> <year> 1986. </year>
Reference: [Wis87] <author> David S. Wise. </author> <title> Matrix algebra and applicative programming. </title> <booktitle> In Functional Programming Languages and Computer Architecture, Lecture Notes in Computer Science 274, </booktitle> <pages> pages 134-153. </pages> <address> Springer-Berlin, </address> <year> 1987. </year>

References-found: 90

