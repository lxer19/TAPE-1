URL: ftp://ftp.cse.ucsc.edu/pub/ml/kw-pawllmbwfivr-95.ps.Z
Refering-URL: http://www.cse.ucsc.edu/~mark/ftp-ml-root/ExpertBibDir/kw-pawllmbwfivr-95.html
Root-URL: http://www.cse.ucsc.edu
Email: jkivinen@cs.helsinki.fi  manfred@cse.ucsc.edu  
Title: The Perceptron algorithm vs. Winnow: linear vs. logarithmic mistake bounds when few input variables are relevant  
Author: Jyrki Kivinen Manfred K. Warmuth 
Address: P.O. Box 26 (Teollisuuskatu 23) FIN-00014 University of Helsinki, Finland  Santa Cruz, CA 95064, USA  
Affiliation: Department of Computer Science  Computer and Information Sciences University of California, Santa Cruz  
Abstract: We give an adversary strategy that forces the Perceptron algorithm to make (N k + 1)=2 mistakes when learning k-literal disjunctions over N variables. Experimentally we see that even for simple random data, the number of mistakes made by the Perceptron algorithm grows almost linearly with N , even if the number k of relevant variable remains a small constant. In contrast, Littlestone's algorithm Winnow makes at most O(k log N ) mistakes for the same problem. Both algorithms use linear threshold functions as their hypotheses. However, Winnow does multiplicative updates to its weight vector instead of the additive up dates of the Perceptron algorithm.
Abstract-found: 1
Intro-found: 1
Reference: [BEHW89] <author> A. Blumer, A. Ehrenfeucht, D. Haussler, and M. K. Warmuth. </author> <title> Learnability and the Vapnik-Chervonenkis dimension. </title> <journal> J. ACM, </journal> <volume> 36(4) </volume> <pages> 929-965, </pages> <year> 1989. </year>
Reference-contexts: If the tuning is allowed to depend on k, the tighter bound O (k + k log (N=k)) is obtainable. This upper bound is optimal to within a constant factor since the Vapnik-Chervonenkis (VC) dimension <ref> [VC71, BEHW89] </ref> of the class of k-literal disjunctions is (k + k log (N=k)) [Lit88] and this dimension is always a lower bound for the optimal mistake bound. The best upper bound we know for learning k-literal monotone disjunctions with the Perceptron algorithm is O (kN ) mistakes.
Reference: [DH73] <author> R. O. Duda and P. E. Hart. </author> <title> Pattern Classification and Scene Analysis. </title> <publisher> Wiley, </publisher> <year> 1973. </year>
Reference-contexts: The best upper bound we know for learning k-literal monotone disjunctions with the Perceptron algorithm is O (kN ) mistakes. This bound comes from the Perceptron Convergence Theorem <ref> [DH73] </ref>, and we suspect it is not very tight for our case, particularly when k is large. <p> Thus when k is small, the mistake bound of the Perceptron algorithm is exponential in the optimal mistake bound (in this case essentially the VC dimension). This may be seen as an instance of what is called the curse of dimensionality in the literature of neural networks and statistics <ref> [DH73] </ref>. It may seem surprising that the Perceptron algorithm performs so badly for monotone disjunctions even though these concepts are simple linear threshold functions with small weights and threshold. <p> There are several other algorithms that make multiplicative weight updates and achieve similar mistake bounds [Lit89]. The best upper bound we know for the Perceptron algorithm comes from the Perceptron Convergence Theorem given, e.g, by Duda and Hart <ref> [DH73, pp. 142-145] </ref>. Assuming that the target is a monotone k-literal disjunctions and the instances x t 2 f 0; 1 g N satisfy P i x t;i X for some value X, the bound is O (kX) mistakes. Note that always X N . <p> Both of these upper bound proofs can be interpreted as using amortized analysis with a potential function. Different potential functions are used: an entropic distance for Winnow [Lit91] and the squared Euclidean distance in the Perceptron Convergence Theorem <ref> [DH73] </ref>. Our observations are analogous to the case of on-line linear regression. Again, there are two algorithms, and worst-case loss bounds for them can be proved using the two potential functions [KW94].
Reference: [Kha79] <author> L. G. Khachiyan. </author> <title> A polynomial algorithm in linear programming (in Russian). </title> <journal> Dok-lady Akademii Nauk SSSR, </journal> <volume> 244 </volume> <pages> 1093-1096, </pages> <year> 1979. </year> <title> (English translation: </title> <journal> Soviet Mathematics Doklady </journal> 20:191-194, 1979.) 
Reference-contexts: Note that always X N . As Maass and Turan [MT94] have pointed out, several linear programming methods can be transformed into efficient linear on-line prediction algorithms. Most notably, this applies to Khachiyan's ellipsoid algorithm <ref> [Kha79] </ref> and to a newer algorithm due to Vaidya [Vai89].
Reference: [KW94] <author> J. Kivinen and M. K. Warmuth. </author> <title> Exponentiated gradient versus gradient descent for linear predictors. </title> <type> Report UCSC-CRL-94-16, </type> <institution> University of California, Santa Cruz, </institution> <month> June </month> <year> 1994. </year>
Reference-contexts: The trade-off in which Winnow is able to take advantage of sparse targets and dense instances and the Perceptron algorithm is able to take advantage of sparse instances and dense targets is similar to the situation in on-line linear regression <ref> [KW94] </ref>. In the regression problem, the classical Gradient Descent algorithm makes Perceptron-style additive updates, and a new family of Exponentiated Gradient algorithms makes multiplicative Winnow-style updates. <p> Our observations are analogous to the case of on-line linear regression. Again, there are two algorithms, and worst-case loss bounds for them can be proved using the two potential functions <ref> [KW94] </ref>. In the case of linear regression it is even possible to derive the updates from the two potential functions in addition to using them in a worst-case analysis. It is an open problem to devise a framework for deriving updates from the potential functions in the linear thresholded case. <p> If only few variables are relevant then rotation invariant algorithms seem to use all the dimensions in a futile search for a good predictor. A cleaner comparison between the related algorithms has been obtained in the linear regression case <ref> [KW94] </ref>. When the targets are small disjunctions, the ellipsoid method also exhibits similar linear growth of its number of mistakes as the computationally trivial Perceptron algorithm. We do not know whether Vaidya's algorithm exhibits the linear growth.
Reference: [Lit88] <author> N. Littlestone. </author> <title> Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm. </title> <journal> Mach. Learning, </journal> <volume> 2 </volume> <pages> 285-318, </pages> <year> 1988. </year>
Reference-contexts: If the outcome differs from the prediction, we say that the algorithm made a mistake. Following Littlestone <ref> [Lit89, Lit88] </ref>, our goal is to minimize the total number of mistakes that the learning algorithm makes for certain sequences of trials. The standard on-line algorithm for learning with linear threshold functions is the simple Perceptron algorithm of Rosenblatt [Ros58]. An alternate algorithm called Winnow was introduced by Littlestone [Lit89, Lit88]. <p> Littlestone <ref> [Lit89, Lit88] </ref>, our goal is to minimize the total number of mistakes that the learning algorithm makes for certain sequences of trials. The standard on-line algorithm for learning with linear threshold functions is the simple Perceptron algorithm of Rosenblatt [Ros58]. An alternate algorithm called Winnow was introduced by Littlestone [Lit89, Lit88]. To see how the algorithms work, consider a binary vec tor x t 2 f 0; 1 g as an instance, and assume that the algorithm predicted 0 while the outcome was 1. <p> It is easy to tune Winnow so that it makes at most O (k log N ) mistakes when learning a k-literal disjunc tion <ref> [Lit88, Lit91] </ref>. If the tuning is allowed to depend on k, the tighter bound O (k + k log (N=k)) is obtainable. <p> If the tuning is allowed to depend on k, the tighter bound O (k + k log (N=k)) is obtainable. This upper bound is optimal to within a constant factor since the Vapnik-Chervonenkis (VC) dimension [VC71, BEHW89] of the class of k-literal disjunctions is (k + k log (N=k)) <ref> [Lit88] </ref> and this dimension is always a lower bound for the optimal mistake bound. The best upper bound we know for learning k-literal monotone disjunctions with the Perceptron algorithm is O (kN ) mistakes. <p> rate , the update of the Perceptron algorithm can be written componentwise as w t+1;i = w t;i t x t;i (1) and the update of Winnow as w t+1;i = w t;i e t x t;i : (2) Note that this basic version of Winnow (the algorithm Winnow2 of <ref> [Lit88] </ref>) only uses positive weights (assuming that the initial weights are positive). The algorithm can be generalized for negative weights by a simple re-duction [Lit88]. See Littlestone [Lit89] for a discussion on the learning rates and other parameters of Winnow. <p> update of Winnow as w t+1;i = w t;i e t x t;i : (2) Note that this basic version of Winnow (the algorithm Winnow2 of <ref> [Lit88] </ref>) only uses positive weights (assuming that the initial weights are positive). The algorithm can be generalized for negative weights by a simple re-duction [Lit88]. See Littlestone [Lit89] for a discussion on the learning rates and other parameters of Winnow. Here we just point out the standard method of allowing the threshold to be fixed to 0 at the cost of increasing the dimensionality of the problem by one. <p> This useful technique gives a method for effectively updating the threshold together with the components of the weight vector. It is known that if the target is a monotone k-literal disjunction, Winnow makes O (k log N ) mistakes <ref> [Lit88] </ref>. There are several other algorithms that make multiplicative weight updates and achieve similar mistake bounds [Lit89]. The best upper bound we know for the Perceptron algorithm comes from the Perceptron Convergence Theorem given, e.g, by Duda and Hart [DH73, pp. 142-145].
Reference: [Lit89] <author> N. Littlestone. </author> <title> Mistake Bounds and Logarithmic Linear-threshold Learning Algorithms. </title> <type> PhD thesis, Report UCSC-CRL-89-11, </type> <institution> University of California Santa Cruz, </institution> <year> 1989. </year>
Reference-contexts: If the outcome differs from the prediction, we say that the algorithm made a mistake. Following Littlestone <ref> [Lit89, Lit88] </ref>, our goal is to minimize the total number of mistakes that the learning algorithm makes for certain sequences of trials. The standard on-line algorithm for learning with linear threshold functions is the simple Perceptron algorithm of Rosenblatt [Ros58]. An alternate algorithm called Winnow was introduced by Littlestone [Lit89, Lit88]. <p> Littlestone <ref> [Lit89, Lit88] </ref>, our goal is to minimize the total number of mistakes that the learning algorithm makes for certain sequences of trials. The standard on-line algorithm for learning with linear threshold functions is the simple Perceptron algorithm of Rosenblatt [Ros58]. An alternate algorithm called Winnow was introduced by Littlestone [Lit89, Lit88]. To see how the algorithms work, consider a binary vec tor x t 2 f 0; 1 g as an instance, and assume that the algorithm predicted 0 while the outcome was 1. <p> The algorithm can be generalized for negative weights by a simple re-duction [Lit88]. See Littlestone <ref> [Lit89] </ref> for a discussion on the learning rates and other parameters of Winnow. Here we just point out the standard method of allowing the threshold to be fixed to 0 at the cost of increasing the dimensionality of the problem by one. <p> It is known that if the target is a monotone k-literal disjunction, Winnow makes O (k log N ) mistakes [Lit88]. There are several other algorithms that make multiplicative weight updates and achieve similar mistake bounds <ref> [Lit89] </ref>. The best upper bound we know for the Perceptron algorithm comes from the Perceptron Convergence Theorem given, e.g, by Duda and Hart [DH73, pp. 142-145].
Reference: [Lit91] <author> N. Littlestone. </author> <title> Redundant noisy attributes, attribute errors, and linear threshold learning using Winnow. </title> <booktitle> In Proc. 4th Workshop on Comput. Learning Theory, </booktitle> <pages> pages 147-156. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: It is easy to tune Winnow so that it makes at most O (k log N ) mistakes when learning a k-literal disjunc tion <ref> [Lit88, Lit91] </ref>. If the tuning is allowed to depend on k, the tighter bound O (k + k log (N=k)) is obtainable. <p> With this tuning Winnow is guaranteed to make at most O (k +log (N=k)) mistakes if the target is a k-literal monotone disjunction, and the algorithm is even robust against noise <ref> [Lit91] </ref>. For the Perceptron algorithm we have used zero initial weights and eliminated the threshold by the transformation given in Section 2. In this case the choice of the learning rate of the Perceptron algorithm makes no difference. As we see, in this sparse case Winnow made clearly fewer mistakes. <p> Bounds on the worst-case number of mistakes have ear-lier been obtained for both the Perceptron algorithm and Winnow. Both of these upper bound proofs can be interpreted as using amortized analysis with a potential function. Different potential functions are used: an entropic distance for Winnow <ref> [Lit91] </ref> and the squared Euclidean distance in the Perceptron Convergence Theorem [DH73]. Our observations are analogous to the case of on-line linear regression. Again, there are two algorithms, and worst-case loss bounds for them can be proved using the two potential functions [KW94].
Reference: [Lit95] <author> N. Littlestone. </author> <title> Comparing several linear-threshold learning algorithms on tasks involving superfluous attributes. </title> <booktitle> In Proc. 12th International Machine Learning Conference (ML-95), </booktitle> <month> July </month> <year> 1995. </year>
Reference-contexts: Studying this behavior will lead to a deeper understanding of how high dimensionality hurts the Perceptron algorithm. A more extensive experimental comparison of various on-line algorithms for learning disjunctions in the presence of attribute noise has recently been done by Littlestone <ref> [Lit95] </ref>. Bounds on the worst-case number of mistakes have ear-lier been obtained for both the Perceptron algorithm and Winnow. Both of these upper bound proofs can be interpreted as using amortized analysis with a potential function.
Reference: [LLW91] <author> N. Littlestone, P. M. Long, and M. K. War-muth. </author> <title> On-line learning of linear functions. </title> <booktitle> In Proc. 23rd ACM Symposium on Theory of Computing, </booktitle> <pages> pages 465-475, </pages> <year> 1991. </year>
Reference-contexts: Similar proofs have been devised for linear regression <ref> [LLW91] </ref>. The proofs presented here for the case of linear thresholding are slightly more involved. We also wish to point out that the behavior similar to that predicted by the worst-case lower bounds already takes place on random data.
Reference: [MT94] <author> W. Maass and G. Turan. </author> <title> How fast can a threshold gate learn. </title> <booktitle> In Computational Learning Theory and Natural Learning Systems, </booktitle> <volume> Volume I, </volume> <pages> pages 381-414. </pages> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: Assuming that the target is a monotone k-literal disjunctions and the instances x t 2 f 0; 1 g N satisfy P i x t;i X for some value X, the bound is O (kX) mistakes. Note that always X N . As Maass and Turan <ref> [MT94] </ref> have pointed out, several linear programming methods can be transformed into efficient linear on-line prediction algorithms. Most notably, this applies to Khachiyan's ellipsoid algorithm [Kha79] and to a newer algorithm due to Vaidya [Vai89].
Reference: [Ros58] <author> F. Rosenblatt. </author> <title> The perceptron: A probabilistic model for information storage and organization in the brain. </title> <journal> Psych. Rev., </journal> <volume> 65 </volume> <pages> 386-407, </pages> <year> 1958. </year> <note> (Reprinted in Neurocom-puting (MIT Press, 1988).). </note>
Reference-contexts: Following Littlestone [Lit89, Lit88], our goal is to minimize the total number of mistakes that the learning algorithm makes for certain sequences of trials. The standard on-line algorithm for learning with linear threshold functions is the simple Perceptron algorithm of Rosenblatt <ref> [Ros58] </ref>. An alternate algorithm called Winnow was introduced by Littlestone [Lit89, Lit88]. To see how the algorithms work, consider a binary vec tor x t 2 f 0; 1 g as an instance, and assume that the algorithm predicted 0 while the outcome was 1.
Reference: [SST91] <author> H. Sompolinsky, H. S. Seung, and N. Tishby. </author> <title> Learning curves in large neural networks. </title> <booktitle> In Proc. 4th Workshop on Com-put. Learning Theory, </booktitle> <pages> pages 112-127. </pages> <publisher> Mor-gan Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: However, it seems possible to obtain closed formulas for the expected total number of mistakes of the Perceptron algorithm on some thermodynamic limit (see, e.g, <ref> [SST91, WRB93] </ref>). We wish to study how these closed formulas relate to the worst-case upper bounds and the adversary lower bounds. Studying this behavior will lead to a deeper understanding of how high dimensionality hurts the Perceptron algorithm.
Reference: [Vai89] <author> P. M. Vaidya. </author> <title> A new algorithm for minimizing convex functions over convex sets. </title> <booktitle> In Proc. 30th Symposium on Foundations of Computer Science, </booktitle> <pages> pages 338-343. </pages> <publisher> IEEE Computer Society, </publisher> <year> 1989. </year>
Reference-contexts: Note that always X N . As Maass and Turan [MT94] have pointed out, several linear programming methods can be transformed into efficient linear on-line prediction algorithms. Most notably, this applies to Khachiyan's ellipsoid algorithm [Kha79] and to a newer algorithm due to Vaidya <ref> [Vai89] </ref>.
Reference: [Val84] <author> L. G. Valiant. </author> <title> A theory of the learnable. </title> <journal> Commun. ACM, </journal> <volume> 27(11) </volume> <pages> 1134-1142, </pages> <year> 1984. </year>
Reference-contexts: We believe that the sparseness of the instances is advantageous for the Perceptron algorithm. Note that if it is known that k is close to N , Winnow can be tuned so that it simulates the classical elimination algorithm for learning disjunctions <ref> [Val84] </ref>, in which case it makes at most N k mistakes for k literal monotone disjunctions but is not robust against noise.
Reference: [VC71] <author> V. N. Vapnik and A. Y. Chervonenkis. </author> <title> On the uniform convergence of relative frequencies of events to their probabilities. </title> <journal> Theory of Probab. and its Applications, </journal> <volume> 16(2) </volume> <pages> 264-280, </pages> <year> 1971. </year>
Reference-contexts: If the tuning is allowed to depend on k, the tighter bound O (k + k log (N=k)) is obtainable. This upper bound is optimal to within a constant factor since the Vapnik-Chervonenkis (VC) dimension <ref> [VC71, BEHW89] </ref> of the class of k-literal disjunctions is (k + k log (N=k)) [Lit88] and this dimension is always a lower bound for the optimal mistake bound. The best upper bound we know for learning k-literal monotone disjunctions with the Perceptron algorithm is O (kN ) mistakes.
Reference: [WRB93] <author> T. L. H. Watkin, A. Rau, and M. Biehl. </author> <title> The statistical mechanics of learning a rule. </title> <journal> Rev. Mod. Phys., </journal> <volume> 65 </volume> <pages> 499-556, </pages> <year> 1993. </year>
Reference-contexts: However, it seems possible to obtain closed formulas for the expected total number of mistakes of the Perceptron algorithm on some thermodynamic limit (see, e.g, <ref> [SST91, WRB93] </ref>). We wish to study how these closed formulas relate to the worst-case upper bounds and the adversary lower bounds. Studying this behavior will lead to a deeper understanding of how high dimensionality hurts the Perceptron algorithm.
References-found: 16

