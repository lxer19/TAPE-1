URL: http://www.ecs.umass.edu/ece/vspgroup/jung/WWW/paper/trvlsi.ps
Refering-URL: http://gate.ecs.umass.edu/ides/_vti_bin/shtml.dll/_knobas/00000003.htm
Root-URL: 
Title: Under revision for IEEE Transaction on VLSI Systems Efficient VLSI for Lempel-Ziv Data Compression in
Author: Bongjin Jung Wayne P. Burleson 
Keyword: Index Terms: Data Compression, Lempel-Ziv Encoding, Systolic Array, Low-Power.  
Address: Amherst, MA 01003  
Affiliation: Department of Electrical and Computer Engineering University of Massachusetts  
Abstract: We present a parallel algorithm, architecture, and implementation for efficient Lempel-Ziv-based data compression. The parallel algorithm exhibits a scalable, parameterized, and regular structure and is well suited for VLSI array implementation. Based on our parallel algorithm and systematic design methodologies [12], two semi-systolic array architectures have been developed which are low power and area efficient. The first architecture trades off the compression speed for the area and has a low run-time overhead for multi-channel compression. The second architecture achieves a high compression rate (one data symbol per clock) at the expense of the area due to a large clock load and global wiring. Compared to a recent state-of-art parallel architecture [20], our first array structure requires significantly less chip area (330K vs 36K transistors) and more than an order of magnitude less power (1:0W vs. 70mW ) while still providing the compression speed required for most data communication applications. Hence data compression can be adopted in portable data communication as well as wireless local area networks. The second architecture has at least three times less area and power compared to [20] while providing the same constant compression rate. To demonstrate the correctness of our design, a prototype module for the first architecture has been implemented using 1.2 CMOS technology. The compression module contains 32 simple and identical processors, has an average compression rate of 12.5 million Bytes/second, and consumes 18.34mW without the dictionary ( 70mW with a 4.1K SRAM for the dictionary) while operating at a 100 MHz clock rate (simulated). 
Abstract-found: 1
Intro-found: 1
Reference: [1] <institution> Anonymous reviewer </institution>
Reference-contexts: The complete layout of the compression module is shown in Figure-11. 8 Discussion Zito-Wolf has proposed a folded systolic architecture which is capable of compressing one symbol per clock cycle [20] and its VLSI implementation achieving up to 100 MBytes/sec at 100 Mhz clock has been reported <ref> [1] </ref>. Yet as shown in Table-4 the architecture contains N counters and 2N shift registers, which are always active, resulting in a large area and a high power consumption.
Reference: [2] <author> Burd, </author> <title> T, Low Power CMOS Library Design Methodology, </title> <type> Master Thesis, </type> <institution> University of California, Berkeley. </institution>
Reference-contexts: Table-2 shows the figures obtained from a SPICE simulation assuming 50 % input transition and a single 2-input gate load. The power consumption of the SRAM is based upon a SRAM compiler from U.C. Berkeley <ref> [2] </ref>. 3 A parallel algorithm for LZ data compression For Lempel-Ziv encoding, the encoding speed depends upon finding the maximum matching substring from the dictionary. For software implementations, a tree or hash data structure is popular. <p> Instead, we use exhaustive searching 6 # of transistors Power consumption (@100Mhz, 3.3 V) Equality compare (8-bit) 80 0:1594 mW Magnitude compare (5-bit) 82 0:2173 mW Shift registers (8-bit) 56 0:3508 mW Counter (5-bit) 60 0:1695 mW SRAM (512 8-bit) 30,000 52:408 mW <ref> [2] </ref> Priority encoder 7,058 10:384 mW (512 to -9) (1) Power is based on the assumption of an output load of a single 2-input gate. Table 2: Area and power estimation of major components of the dictionary for a parallel hardware implementation due to the simple dictionary management scheme.
Reference: [3] <author> Bell, T.C., Cleary, J.G., and Witten I.H. </author> <title> Text Compression, </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, N.J., </address> <year> 1990. </year>
Reference-contexts: [j]) length++; else break; /* failure, break from the inner loop */ if (length &gt; max_length) - max_length = length; /* update pointer & max_length if necessary */ pointer = i; - if (max_length == M) /* length &gt;= pre-defined maximum */ break; /* break from the outer loop */ <ref> [3] </ref> [18]. Figure-1 shows a pseudo-code for the compression procedure. <p> If the size of a substring is smaller than the size of the codeword to replace it, then the original data will be expanded rather than compressed <ref> [3] </ref>. Furthermore, the use of an explicit character (i.e. last symbol) in a codeword is wasteful because a character takes a finite number of bits to represent and could often be included in the next codeword. <p> Storer and Szymanski [16] proposed a modified scheme called LZSS where both codewords and explicit source symbols are used for representing compressed data. To further improve the compression performance, several different modifications have been made. LZB <ref> [3] </ref> achieves better compression than LZSS by statistically encoding both already encoded codewords and explicit characters since in practice some matching lengths or characters are more likely to occur than others.
Reference: [4] <author> Bunton, S. and Borriello, G., </author> <title> "Practical Dictionary management for Hardware Data Compression," </title> <booktitle> Proc. of the Sixth MIT Conference, </booktitle> <pages> pp. 33-50, </pages> <year> 1990. </year>
Reference-contexts: Recently, rapid growth in the area of applications for fast data compression combined with modern VLSI technology and parallel architectures has motivated extensive research in the design of special-purpose architectures for various lossless data compression techniques <ref> [4] </ref> [8] [13] [14] [15]. In this paper we present a novel algorithm, architecture, and VLSI implementation of a compact and low-power module which implements the first Lempel-Ziv algorithm. The organization of this paper is as follows. In Section 2 we briefly explain the Lempel-Ziv algorithm for data compression.
Reference: [5] <author> Burleson, W.P. and Jung, B., </author> <title> "Interactive Graphic Analysis Tool for VLSI Arrays," </title> <booktitle> Proc. of Int. Conf. on Application Specific Array Processors, </booktitle> <pages> pp 149-162, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: Furthermore a multiplexor consumes virtually no operating power since it can be implemented with current steering logic. Figure-2 shows the main body of our parallel algorithm expressed in a regular algorithm description language called SHDL <ref> [5] </ref> which can be easily compiled to VER-ILOG for simulation and/or synthesis. Figure-3 shows a two-dimensional dependence graph (DG) derived from the parallel algorithm. The dependence graph consists of N fl M processor nodes. <p> Based on our parallel algorithm, we developed an area/power-efficient VLSI architecture for LZ-based data compression using systematic design methodologies. To further improve the latency, we used a control variable to indicate early completion. Using an SHDL description allows the use of ARREST <ref> [5] </ref> for structured synthesis and VERILOG [7] for verification and rapid synthesis. The architecture is parameterized by the block length N , the size of look-ahead buffer M , and the symbol length w, to cover diverse applications, such as text compression and image data compression.
Reference: [6] <author> Burleson, W.P. and Scharf, L., </author> <title> "Input/Output Complexity of Bit-level VLSI Array Architectures", </title> <booktitle> Proc. Asilomar Conf., </booktitle> <year> 1989. </year>
Reference-contexts: Since the counter is in the critical path, the clock period is also minimized. In many cases, a word-parallel array implementation requires a large number of delay elements to provide a set of skewed inputs; therefore, it is expensive in hardware costs, especially for a linear array <ref> [6] </ref>. However, for Lempel-Ziv-based data compression, a new set of source symbols can not be shifted in until the present encoding is complete. The architecture fully exploits this to eliminate the need for registers required for skewed inputs.
Reference: [7] <institution> Cadence Design Systems Inc., </institution> <note> VERILOG-XL Manual, Version 1.6, </note> <month> March </month> <year> 1991. </year>
Reference-contexts: Based on our parallel algorithm, we developed an area/power-efficient VLSI architecture for LZ-based data compression using systematic design methodologies. To further improve the latency, we used a control variable to indicate early completion. Using an SHDL description allows the use of ARREST [5] for structured synthesis and VERILOG <ref> [7] </ref> for verification and rapid synthesis. The architecture is parameterized by the block length N , the size of look-ahead buffer M , and the symbol length w, to cover diverse applications, such as text compression and image data compression.
Reference: [8] <author> Craft, </author> <title> D.J., "ADLC and a Pre-processor Extension, BDLC, Provide Ultra Fast Compression for General-purpose and Bit-mapped Image Data," </title> <booktitle> Proc. Data Compression Conference, </booktitle> <pages> pp. 440, </pages> <year> 1995. </year>
Reference-contexts: Recently, rapid growth in the area of applications for fast data compression combined with modern VLSI technology and parallel architectures has motivated extensive research in the design of special-purpose architectures for various lossless data compression techniques [4] <ref> [8] </ref> [13] [14] [15]. In this paper we present a novel algorithm, architecture, and VLSI implementation of a compact and low-power module which implements the first Lempel-Ziv algorithm. The organization of this paper is as follows. In Section 2 we briefly explain the Lempel-Ziv algorithm for data compression. <p> The pointer (C p ) and the matching length (C l ) indicate the position and the length respectively of the longest matching substring. The last symbol (C s ) is the symbol that follows the longest matching substring. A recent study <ref> [8] </ref> shows that while the second algorithm performs well on highly compressible data, the first Lempel-Ziv algorithm outperforms the second LZ algorithm for smaller volumes of arbitrary data which typically characterize data communication network traffic. <p> This can be done by maintaining a separate context model (i.e. dictionary) for each communication channel. However, at the beginning of each frame, dictionary switching is required. 16 For CAM (content addressable memory) based architectures <ref> [8] </ref> [13], it is necessary to flush out the CAM and reload it with a new dictionary which can incur substantial delay and power consumption.
Reference: [9] <author> Halfhill, </author> <title> T, "How Safe is Data Compression," </title> <journal> BYTE, </journal> <volume> pp.56-74, </volume> <month> February </month> <year> 1994. </year>
Reference-contexts: For software implementations, a tree or hash data structure is popular. A current state-of-the-art software compressor called PKZIP achieves an average data rate of 1 MByte/sec on a Pentium system <ref> [9] </ref>. Yet, their updating and downdating of the sliding dictionary is not trivial in a hardware implementation and is also difficult to parallelize.
Reference: [10] <author> Jung, B. and Burleson, </author> <title> W.P., "Node Merging: A Transformation on Bit-Level Dependence Graphs for Efficient VLSI Array Design," </title> <booktitle> Proc. IEEE Int. Conf. on Application Specific Array Processors, </booktitle> <pages> pp. 442-453, </pages> <month> October </month> <year> 1993. </year>
Reference-contexts: Note that for a fine-grained architecture the delay of a pipelining register is significant compared to actual computations; hence, merging nodes will not double the clock period <ref> [10] </ref>. On the other hand, decreasing the number 14 of pipelining registers is particularly important because they can take up more than two-thirds of the total chip area. Optimizing the pipeline depth also substantially reduces the clock load thereby minimizing the power consumption of the clock buffer.
Reference: [11] <author> Jung, B., Jeong, Y., and Burleson, </author> <title> W.P., "Distributed Control Synthesis for Data-Dependent Iterative Algorithms," </title> <booktitle> IEEE Int. Conf. on Application Specific Array Processors, </booktitle> <year> 1994. </year>
Reference-contexts: Hence, we break the iteration loop into two iteration loops with one data-dependent break. We can convert a data-dependent iteration to a data-independent iteration by going through all iteration steps while disabling subsequent incrementing operations when a comparison fails <ref> [11] </ref>. disable = 0; for j := 1 to M 1 if (x index ==y j && disable==0) length = length + 1; else disable = 1; 7 Hence, a dlog M e-bit incrementing counter for each iteration is needed to compute length i , and when a comparison fails, the <p> 1 to M 1 match = match & (x index == y j ) & eof j ; if (match == 1) length = j else length = length; Instead, as shown in the above pesudo-code, we use loop indices with a one-bit control variable named match as implicit counters <ref> [11] </ref>. In each row, the variable match travels along the row while keeping a record of any previous failure of comparison.
Reference: [12] <author> Kung, S.Y., </author> <title> VLSI Array Processors, </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, N.J., </address> <year> 1988. </year>
Reference-contexts: Therefore, we can immediately start encoding a new set of data thereby improving average compression speed. 4 A naive systolic array architecture To implement the parallel algorithm, we have developed a word-parallel systolic array architecture using a systematic design methodology based on <ref> [12] </ref>. Advantages of the methodology include (1) parameterization, (2) estimation, (3) scalability, (4) and verification. 4.1 A systolic array for LZ-based data compression 9 An SFG can be designed by mapping the DG nodes to space and time.
Reference: [13] <author> Nusinov, E. and Pasco-Anderson, J., </author> <title> "High-Performance Multi-Channel Data Compression Chip," </title> <booktitle> Proc. of IEEE Custom Integrated Circuits Conference, </booktitle> <pages> pp. 203-206, </pages> <year> 1994. </year>
Reference-contexts: Recently, rapid growth in the area of applications for fast data compression combined with modern VLSI technology and parallel architectures has motivated extensive research in the design of special-purpose architectures for various lossless data compression techniques [4] [8] <ref> [13] </ref> [14] [15]. In this paper we present a novel algorithm, architecture, and VLSI implementation of a compact and low-power module which implements the first Lempel-Ziv algorithm. The organization of this paper is as follows. In Section 2 we briefly explain the Lempel-Ziv algorithm for data compression. <p> Unlike a point-to-point connection, general data communication networks multiplex several concurrent connections. Hence in order for data compression to be effectively used in communication networks, the performance of data compression needs to be independent of the frame size (typically a few hundred Bytes) <ref> [13] </ref>. This can be done by maintaining a separate context model (i.e. dictionary) for each communication channel. However, at the beginning of each frame, dictionary switching is required. 16 For CAM (content addressable memory) based architectures [8] [13], it is necessary to flush out the CAM and reload it with a <p> needs to be independent of the frame size (typically a few hundred Bytes) <ref> [13] </ref>. This can be done by maintaining a separate context model (i.e. dictionary) for each communication channel. However, at the beginning of each frame, dictionary switching is required. 16 For CAM (content addressable memory) based architectures [8] [13], it is necessary to flush out the CAM and reload it with a new dictionary which can incur substantial delay and power consumption.
Reference: [14] <author> Ranganathan, R. and Henriques, S., </author> <title> "High-Speed VLSI Design for Lempel-Ziv-Based Data Compression," </title> <journal> IEEE Trans. on Circuits and Systems, </journal> <volume> Vol. 40, No. 2, </volume> <pages> pp. 96-106, </pages> <month> February </month> <year> 1993. </year> <month> 23 </month>
Reference-contexts: Recently, rapid growth in the area of applications for fast data compression combined with modern VLSI technology and parallel architectures has motivated extensive research in the design of special-purpose architectures for various lossless data compression techniques [4] [8] [13] <ref> [14] </ref> [15]. In this paper we present a novel algorithm, architecture, and VLSI implementation of a compact and low-power module which implements the first Lempel-Ziv algorithm. The organization of this paper is as follows. In Section 2 we briefly explain the Lempel-Ziv algorithm for data compression. <p> For systolic architectures where the dictionary is mapped to the processor space <ref> [14] </ref> [20], saving and writing to internal memories of each processor is required thereby causing similar overhead. Figure-9 shows our complete multi-channel data compression system. The system consists of three major components: (1) compression module, (2) RAM for the dictionary, (3) I/O interface module.
Reference: [15] <author> Storer, J., Reif, J.H., and Markas, T., </author> <title> "A Massively Parallel VLSI Design for Data Compression Using a Compact Dynamic Dictionary," </title> <booktitle> Proc. IEEE Workshop on VLSI Signal Processing, </booktitle> <pages> pp. 329-338, </pages> <year> 1990. </year>
Reference-contexts: Recently, rapid growth in the area of applications for fast data compression combined with modern VLSI technology and parallel architectures has motivated extensive research in the design of special-purpose architectures for various lossless data compression techniques [4] [8] [13] [14] <ref> [15] </ref>. In this paper we present a novel algorithm, architecture, and VLSI implementation of a compact and low-power module which implements the first Lempel-Ziv algorithm. The organization of this paper is as follows. In Section 2 we briefly explain the Lempel-Ziv algorithm for data compression.
Reference: [16] <author> Storer, J. and Szymanski, T.G., </author> <title> "Data Compression via Textual Substitution," </title> <journal> Journal of ACM, </journal> <pages> pp. </pages> <month> 928-951 October, </month> <year> 1982. </year>
Reference-contexts: Furthermore, the use of an explicit character (i.e. last symbol) in a codeword is wasteful because a character takes a finite number of bits to represent and could often be included in the next codeword. Storer and Szymanski <ref> [16] </ref> proposed a modified scheme called LZSS where both codewords and explicit source symbols are used for representing compressed data. To further improve the compression performance, several different modifications have been made.
Reference: [17] <author> Welch, T., </author> <title> "A Technique for High-Performance data Compression," </title> <booktitle> Computer 17(6) </booktitle> <pages> 8-19, </pages> <month> June </month> <year> 1984. </year>
Reference: [18] <author> Ziv, J. and Lempel, A., </author> <title> "A Universal Algorithm for Sequential Data Compression," </title> <journal> IEEE Trans. on Information Theory, </journal> <volume> Vol. IT-23, NO. 3, </volume> <pages> pp. 337-343, </pages> <year> 1977. 1977. </year>
Reference-contexts: In section 8 we compare our semi-systolic array structures to the most recent parallel implementation of the LZ-based data compression system [20] in terms of area, latency, and period. Finally conclusions are given in Section 9. 2 Lempel-Ziv coding algorithm The Lempel-Ziv coding schemes <ref> [18] </ref> [19] are two of the most powerful, lossless, and universal data compressors. <p> length++; else break; /* failure, break from the inner loop */ if (length &gt; max_length) - max_length = length; /* update pointer & max_length if necessary */ pointer = i; - if (max_length == M) /* length &gt;= pre-defined maximum */ break; /* break from the outer loop */ [3] <ref> [18] </ref>. Figure-1 shows a pseudo-code for the compression procedure. Decompression of encoded data is just a memory access so is significantly simpler and faster than encoding [18] and can be easily implemented either by software or hardware. 2.2 Practical improvements to the first LZ encoding The output of LZ77 (the original <p> */ pointer = i; - if (max_length == M) /* length &gt;= pre-defined maximum */ break; /* break from the outer loop */ [3] <ref> [18] </ref>. Figure-1 shows a pseudo-code for the compression procedure. Decompression of encoded data is just a memory access so is significantly simpler and faster than encoding [18] and can be easily implemented either by software or hardware. 2.2 Practical improvements to the first LZ encoding The output of LZ77 (the original Lempel-Ziv algorithm) is a series of codewords which each consist of a pointer, a length, and a last symbol.
Reference: [19] <author> Ziv, J. and Lempel, A., </author> <title> "Compression of Individual Sequence Via Variable Rate Coding," </title> <journal> IEEE Trans. on Information Theory, </journal> <volume> Vol. IT-24, </volume> <pages> pp. 530-536, </pages> <year> 1978. </year>
Reference-contexts: In section 8 we compare our semi-systolic array structures to the most recent parallel implementation of the LZ-based data compression system [20] in terms of area, latency, and period. Finally conclusions are given in Section 9. 2 Lempel-Ziv coding algorithm The Lempel-Ziv coding schemes [18] <ref> [19] </ref> are two of the most powerful, lossless, and universal data compressors.
Reference: [20] <author> Zito-Wolf, R., </author> <title> "A Systolic Architecture for Sliding-Window data Compression," </title> <booktitle> Proc. IEEE Workshop on VLSI Signal Processing, </booktitle> <pages> pp. 339-351, </pages> <year> 1992. </year> <month> 24 </month>
Reference-contexts: In section 6 we apply a different mapping to the DG and show the resulting high-performance architecture. Section 7 shows a prototype implementation of the first architecture. In section 8 we compare our semi-systolic array structures to the most recent parallel implementation of the LZ-based data compression system <ref> [20] </ref> in terms of area, latency, and period. Finally conclusions are given in Section 9. 2 Lempel-Ziv coding algorithm The Lempel-Ziv coding schemes [18] [19] are two of the most powerful, lossless, and universal data compressors. <p> For systolic architectures where the dictionary is mapped to the processor space [14] <ref> [20] </ref>, saving and writing to internal memories of each processor is required thereby causing similar overhead. Figure-9 shows our complete multi-channel data compression system. The system consists of three major components: (1) compression module, (2) RAM for the dictionary, (3) I/O interface module. <p> Table-3 shows the summary of the prototype chip. The complete layout of the compression module is shown in Figure-11. 8 Discussion Zito-Wolf has proposed a folded systolic architecture which is capable of compressing one symbol per clock cycle <ref> [20] </ref> and its VLSI implementation achieving up to 100 MBytes/sec at 100 Mhz clock has been reported [1]. Yet as shown in Table-4 the architecture contains N counters and 2N shift registers, which are always active, resulting in a large area and a high power consumption. <p> The architecture is parameterized by the block length N , the size of look-ahead buffer M , and the symbol length w, to cover a broad range of applications, from text compression to lossless image compression. 20 Zito-Wolf <ref> [20] </ref> Architecture I Architecture II Compression rate 1 M N 1 (symbols/cycle) Clock period t m + t e + t c t m t p Latency N 2 M M Counters N dlog M e-bit one dlog M e-bit one dlog N e-bit Equality compare N w-bit M w-bit N
References-found: 20

