URL: http://www.cs.washington.edu/homes/tompa/papers/hashsiam.ps
Refering-URL: http://www.cs.washington.edu/research/computation/papers.html
Root-URL: 
Title: COMMUNICATION-SPACE TRADEOFFS FOR UNRESTRICTED PROTOCOLS  
Author: PAUL BEAME MARTIN TOMPA AND PEIYUAN YAN 
Keyword: Key words. Communication complexity, lower bound, tradeoff, branching program, universal family of hash functions  
Note: AMS subject classifications. 68Q05, 68Q10, 68Q22, 68Q25  
Abstract: This paper introduces communicating branching programs, and develops a general technique for demonstrating communication-space tradeoffs for pairs of communicating branching programs. This technique is then used to prove communication-space tradeoffs for any pair of communicating branching programs that hashes according to a universal family of hash functions. Other tradeoffs follow from this result. As an example, any pair of communicating Boolean branching programs that computes matrix-vector products over GF(2) requires communication-space product (n 2 ), provided the space used is o(n= log n). These are the first examples of communication-space tradeoffs on a completely general model of communicating processes. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> K. Abrahamson, </author> <title> A time-space tradeoff for boolean matrix multiplication, </title> <booktitle> in 31st Annual Symposium on Foundations of Computer Science, </booktitle> <address> St. Louis, MO, Oct. 1990, </address> <publisher> IEEE, </publisher> <pages> pp. 412-419. </pages>
Reference-contexts: In their model each straight-line program is augmented with send and receive instructions. They leave open the question of defining an appropriate nonoblivious model. Since branching programs have proved to be useful sequential models for the simultaneous measure of time and space <ref> [1, 2, 6, 7, 8, 27] </ref> it is natural to use them to model the communicating parties. Making the analogous changes to branching programs that Lam, Tiwari, and Tompa made to straight-line programs leads to the following model. <p> It is not too hard to see how the argument and Properties A and B can be modified to deal with R-way branching programs (Borodin and Cook [7]) or when the output values described in Properties A and B are of a restricted type (as in, for example, Abrahamson <ref> [1] </ref>). 8 P. BEAME, M. TOMPA, AND P. YAN 4. Hash Functions. We now apply the lower bound technique of the previous section to universal families of hash functions (Carter and Wegman [9, 10]). This will allow us to obtain lower bounds for a variety of interesting computational problems. <p> to proving such a bound would be to try to prove properties A and B for this problem using the distribution D employed by Babai, Frankl, and Simon [4] for proving a distributional communication complexity lower bound of ( n) for ^-_ dot product (i.e. set disjointness) and by Abrahamson <ref> [1] </ref> for proving a time-space tradeoff of T S = (n 1:5 ) on matrix-vector product.
Reference: [2] <author> K. Abrahamson, </author> <title> Time-space tradeoffs for algebraic problems on general sequential models, </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 43 (1991), </volume> <pages> pp. 269-289. </pages>
Reference-contexts: Thus, the lower bounds outlined above imply the corresponding time-space tradeoffs of Grigoryev [12] for straight-line programs and Abrahamson <ref> [2] </ref> for branching programs. The converse, however, is false. <p> Thus, the lower bounds outlined above imply the corresponding time-space tradeoffs of Grigoryev [12] for straight-line programs and Abrahamson [2] for branching programs. The converse, however, is false. Whereas the time T and space S must satisfy T S = (n 2 ) when computing the discrete Fourier transform <ref> [2, 21, 27] </ref> or sorting [6, 8, 21], Lam, Tiwari, and Tompa [15] demonstrated that both of these functions can be computed in linear communication steps and O (log n) space simultaneously. Thus, these results strictly generalize previous time-space tradeoffs. 2. Communicating Branching Programs. <p> In their model each straight-line program is augmented with send and receive instructions. They leave open the question of defining an appropriate nonoblivious model. Since branching programs have proved to be useful sequential models for the simultaneous measure of time and space <ref> [1, 2, 6, 7, 8, 27] </ref> it is natural to use them to model the communicating parties. Making the analogous changes to branching programs that Lam, Tiwari, and Tompa made to straight-line programs leads to the following model.
Reference: [3] <author> A. V. Aho, J. D. Ullman, and M. Yannakakis, </author> <title> On notions of information transfer in VLSI circuits, </title> <booktitle> in Proceedings of the Fifteenth Annual ACM Symposium on Theory of Computing, </booktitle> <address> Boston, MA, </address> <month> Apr. </month> <year> 1983, </year> <pages> pp. 133-139. </pages>
Reference-contexts: In addition, communication complexity has found surprising applications in the complexity of Boolean circuits (Karchmer and Wigderson [14], Raz and Wigderson [19]), Boolean decision trees (Hajnal, Maass, and Turan [13]), combinatorial optimization (Yannakakis [23]), VLSI (Aho, Ullman and Yannakakis <ref> [3] </ref>, Lipton and Sedgewick [16], Mehlhorn and Schmidt [18], Yao [25]), and pseudorandom number generators (Babai, Nisan, and Szegedy [5]). Nearly all previous work on the communication complexity of various problems has focused on their communication requirements alone, in the absence of any limitations on the individual processors.
Reference: [4] <author> L. Babai, P. Frankl, and J. Simon, </author> <title> Complexity classes in communication complexity theory, </title> <booktitle> in 27th Annual Symposium on Foundations of Computer Science, </booktitle> <address> Toronto, Ontario, Oct. 1986, </address> <publisher> IEEE, </publisher> <pages> pp. 337-347. </pages>
Reference-contexts: This will allow us to obtain lower bounds for a variety of interesting computational problems. We make use of a beautiful analog due to Mansour, Nisan, and Tiwari [17] of a lemma of Lindsey <ref> [4, 11] </ref> concerning Hadamard matrices. Our results (and those in [17]) use the more restrictive definition of a universal family of hash functions given by Carter and Wegman in [10] (which they called `strongly universal' in [10]) rather than the somewhat broader definition given in [9]. <p> A natural approach to proving such a bound would be to try to prove properties A and B for this problem using the distribution D employed by Babai, Frankl, and Simon <ref> [4] </ref> for proving a distributional communication complexity lower bound of ( n) for ^-_ dot product (i.e. set disjointness) and by Abrahamson [1] for proving a time-space tradeoff of T S = (n 1:5 ) on matrix-vector product. <p> fi Y given by F ((x 1 ; : : : ; x n ); y) = (f (x 1 ; y); : : : ; f (x n ; y)) have communication-space tradeoff (nD * )? As shown by Yao [24, 26] and extended by Babai, Frankl, and Simon <ref> [4] </ref>, a lower bound D * k can be obtained by showing that, for an appropriate distribution on X fi Y under which f takes on each value at least a constant fraction of the time, any rectangle R, in which the probability of f (x; y) taking on a particular
Reference: [5] <author> L. Babai, N. Nisan, and M. Szegedy, </author> <title> Multiparty protocols, pseudorandom generators for logspace, and time-space trade-offs, </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 45 (1992), </volume> <pages> pp. 204-232. </pages>
Reference-contexts: in the complexity of Boolean circuits (Karchmer and Wigderson [14], Raz and Wigderson [19]), Boolean decision trees (Hajnal, Maass, and Turan [13]), combinatorial optimization (Yannakakis [23]), VLSI (Aho, Ullman and Yannakakis [3], Lipton and Sedgewick [16], Mehlhorn and Schmidt [18], Yao [25]), and pseudorandom number generators (Babai, Nisan, and Szegedy <ref> [5] </ref>). Nearly all previous work on the communication complexity of various problems has focused on their communication requirements alone, in the absence of any limitations on the individual processors. Lam, Tiwari, and Tompa [15] initiated the study of communication complexity when the processors have limited work space.
Reference: [6] <author> P. Beame, </author> <title> A general sequential time-space tradeoff for finding unique elements, </title> <booktitle> in Proceedings of the Twenty First Annual ACM Symposium on Theory of Computing, </booktitle> <address> Seattle, WA, </address> <month> May </month> <year> 1989, </year> <pages> pp. 197-203. </pages>
Reference-contexts: The converse, however, is false. Whereas the time T and space S must satisfy T S = (n 2 ) when computing the discrete Fourier transform [2, 21, 27] or sorting <ref> [6, 8, 21] </ref>, Lam, Tiwari, and Tompa [15] demonstrated that both of these functions can be computed in linear communication steps and O (log n) space simultaneously. Thus, these results strictly generalize previous time-space tradeoffs. 2. Communicating Branching Programs. <p> In their model each straight-line program is augmented with send and receive instructions. They leave open the question of defining an appropriate nonoblivious model. Since branching programs have proved to be useful sequential models for the simultaneous measure of time and space <ref> [1, 2, 6, 7, 8, 27] </ref> it is natural to use them to model the communicating parties. Making the analogous changes to branching programs that Lam, Tiwari, and Tompa made to straight-line programs leads to the following model.
Reference: [7] <author> A. Borodin and S. A. Cook, </author> <title> A time-space tradeoff for sorting on a general sequential model of computation, </title> <journal> SIAM Journal on Computing, </journal> <volume> 11 (1982), </volume> <pages> pp. 287-297. </pages>
Reference-contexts: In this paper we remove the restrictions of straight-line computation and one-way communication, proving for the first time communication-space tradeoffs on a completely general model of communicating processes. This result is analogous to Borodin and Cook's time-space tradeoff for sorting on a general sequential model <ref> [7] </ref>. fl SIAM Journal on Computing, vol. 23, no. 3, June 1994, 652-661. <p> In their model each straight-line program is augmented with send and receive instructions. They leave open the question of defining an appropriate nonoblivious model. Since branching programs have proved to be useful sequential models for the simultaneous measure of time and space <ref> [1, 2, 6, 7, 8, 27] </ref> it is natural to use them to model the communicating parties. Making the analogous changes to branching programs that Lam, Tiwari, and Tompa made to straight-line programs leads to the following model. <p> The definitions can be generalized to communicating R-way branching programs for any R <ref> [7] </ref>. This model is a very natural one and a very general one as well. It can simulate, for example, two communicating space-bounded random access machines with a common write-only area for their output values. <p> The General Lower Bound. The technique we develop here is an extension of the technique of Borodin et al. <ref> [7, 8] </ref> for time-space tradeoffs on sequential branching programs. <p> The conclusion of the argument is exactly the same with C fl replacing C as required. It is not too hard to see how the argument and Properties A and B can be modified to deal with R-way branching programs (Borodin and Cook <ref> [7] </ref>) or when the output values described in Properties A and B are of a restricted type (as in, for example, Abrahamson [1]). 8 P. BEAME, M. TOMPA, AND P. YAN 4. Hash Functions.
Reference: [8] <author> A. Borodin, M. J. Fischer, D. G. Kirkpatrick, N. A. Lynch, and M. Tompa, </author> <title> A time-space tradeoff for sorting on non-oblivious machines, </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 22 (1981), </volume> <pages> pp. 351-364. </pages>
Reference-contexts: The converse, however, is false. Whereas the time T and space S must satisfy T S = (n 2 ) when computing the discrete Fourier transform [2, 21, 27] or sorting <ref> [6, 8, 21] </ref>, Lam, Tiwari, and Tompa [15] demonstrated that both of these functions can be computed in linear communication steps and O (log n) space simultaneously. Thus, these results strictly generalize previous time-space tradeoffs. 2. Communicating Branching Programs. <p> In their model each straight-line program is augmented with send and receive instructions. They leave open the question of defining an appropriate nonoblivious model. Since branching programs have proved to be useful sequential models for the simultaneous measure of time and space <ref> [1, 2, 6, 7, 8, 27] </ref> it is natural to use them to model the communicating parties. Making the analogous changes to branching programs that Lam, Tiwari, and Tompa made to straight-line programs leads to the following model. <p> The space of each branching program is the base 2 logarithm of the number of its nodes. (This is the standard definition for branching programs <ref> [8] </ref>, motivated by the fact that each node represents a different configuration of the program.) The space of the pair of programs is the maximum of the space of the two branching programs, and the communication is the length of the longest sequence of send-receive pairs executed on any input (x; <p> The General Lower Bound. The technique we develop here is an extension of the technique of Borodin et al. <ref> [7, 8] </ref> for time-space tradeoffs on sequential branching programs.
Reference: [9] <author> J. L. Carter and M. N. Wegman, </author> <title> Universal classes of hash functions, </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 18 (1979), </volume> <pages> pp. </pages> <month> 143-154. </month> <title> [10] , New hash functions and their use in authentication and set equality, </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 22 (1981), </volume> <pages> pp. 265-277. </pages>
Reference-contexts: BEAME, M. TOMPA, AND P. YAN More specifically, we introduce the notion of communicating branching programs. We use these to demonstrate that if one of the branching programs is given a member h of a universal family of hash functions (Carter and Wegman <ref> [9, 10] </ref>) and the other is given x, and their goal is to compute h (x) cooperatively, then their communication C and space S must satisfy the tradeoff CS = (nm), where h maps n-bit inputs to m-bit outputs, provided S = o (n= log m). <p> BEAME, M. TOMPA, AND P. YAN 4. Hash Functions. We now apply the lower bound technique of the previous section to universal families of hash functions (Carter and Wegman <ref> [9, 10] </ref>). This will allow us to obtain lower bounds for a variety of interesting computational problems. We make use of a beautiful analog due to Mansour, Nisan, and Tiwari [17] of a lemma of Lindsey [4, 11] concerning Hadamard matrices. <p> Our results (and those in [17]) use the more restrictive definition of a universal family of hash functions given by Carter and Wegman in [10] (which they called `strongly universal' in [10]) rather than the somewhat broader definition given in <ref> [9] </ref>. To emphasize the nature of this stronger requirement we will call such families pairwise universal. A pairwise universal family H of hash functions from a set X to a set Z satisfies the following two properties for h chosen uniformly at random from H: 1.
Reference: [11] <author> P. Erd os and J. Spencer, </author> <title> Probabilistic Methods in Combinatorics, </title> <publisher> Academic Press, </publisher> <year> 1974. </year>
Reference-contexts: This will allow us to obtain lower bounds for a variety of interesting computational problems. We make use of a beautiful analog due to Mansour, Nisan, and Tiwari [17] of a lemma of Lindsey <ref> [4, 11] </ref> concerning Hadamard matrices. Our results (and those in [17]) use the more restrictive definition of a universal family of hash functions given by Carter and Wegman in [10] (which they called `strongly universal' in [10]) rather than the somewhat broader definition given in [9].
Reference: [12] <author> D. Y. Grigoriev, </author> <title> An application of separability and independence notions for proving lower bounds of circuit complexity, </title> <booktitle> in Notes of Scientific Seminars, </booktitle> <volume> vol. </volume> <pages> 60, </pages> <institution> Steklov Mathematical Institute, Leningrad Department, </institution> <year> 1976, </year> <pages> pp. 38-48. </pages> <note> In Russian. </note>
Reference-contexts: Thus, the lower bounds outlined above imply the corresponding time-space tradeoffs of Grigoryev <ref> [12] </ref> for straight-line programs and Abrahamson [2] for branching programs. The converse, however, is false.
Reference: [13] <author> A. Hajnal, W. Maass, and G. </author> <title> Tur an, On the communication complexity of graph properties, </title> <booktitle> in Proceedings of the Twentieth Annual ACM Symposium on Theory of Computing, </booktitle> <address> Chicago, IL, </address> <month> May </month> <year> 1988, </year> <pages> pp. 186-191. </pages>
Reference-contexts: In addition, communication complexity has found surprising applications in the complexity of Boolean circuits (Karchmer and Wigderson [14], Raz and Wigderson [19]), Boolean decision trees (Hajnal, Maass, and Turan <ref> [13] </ref>), combinatorial optimization (Yannakakis [23]), VLSI (Aho, Ullman and Yannakakis [3], Lipton and Sedgewick [16], Mehlhorn and Schmidt [18], Yao [25]), and pseudorandom number generators (Babai, Nisan, and Szegedy [5]).
Reference: [14] <author> M. Karchmer and A. Wigderson, </author> <title> Monotone circuits for connectivity require super-logarithmic depth, </title> <booktitle> in Proceedings of the Twentieth Annual ACM Symposium on Theory of Computing, </booktitle> <address> Chicago, IL, </address> <month> May </month> <year> 1988, </year> <pages> pp. 539-550. </pages>
Reference-contexts: The amount of communication required among processors cooperatively performing a computation is often the dominant factor in determining the efficiency of parallel or distributed systems, in both practical and theoretical terms. In addition, communication complexity has found surprising applications in the complexity of Boolean circuits (Karchmer and Wigderson <ref> [14] </ref>, Raz and Wigderson [19]), Boolean decision trees (Hajnal, Maass, and Turan [13]), combinatorial optimization (Yannakakis [23]), VLSI (Aho, Ullman and Yannakakis [3], Lipton and Sedgewick [16], Mehlhorn and Schmidt [18], Yao [25]), and pseudorandom number generators (Babai, Nisan, and Szegedy [5]).
Reference: [15] <author> T. W. Lam, P. Tiwari, and M. Tompa, </author> <title> Trade-offs between communication and space, </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 45 (1992), </volume> <pages> pp. 296-315. </pages>
Reference-contexts: Nearly all previous work on the communication complexity of various problems has focused on their communication requirements alone, in the absence of any limitations on the individual processors. Lam, Tiwari, and Tompa <ref> [15] </ref> initiated the study of communication complexity when the processors have limited work space. As is customary, the systems studied consist of two communicating processors that are given private inputs x and y, respectively, and are to output some function f (x; y). <p> The converse, however, is false. Whereas the time T and space S must satisfy T S = (n 2 ) when computing the discrete Fourier transform [2, 21, 27] or sorting [6, 8, 21], Lam, Tiwari, and Tompa <ref> [15] </ref> demonstrated that both of these functions can be computed in linear communication steps and O (log n) space simultaneously. Thus, these results strictly generalize previous time-space tradeoffs. 2. Communicating Branching Programs. <p> A restricted model in which each party executes a straight-line program was defined by Lam, Tiwari, and Tompa <ref> [15] </ref>. In their model each straight-line program is augmented with send and receive instructions. They leave open the question of defining an appropriate nonoblivious model. <p> BEAME, M. TOMPA, AND P. YAN 5. Open Questions. It is an interesting question whether or not similar bounds hold for ^-_ matrix-vector product. The results of Lam, Tiwari, and Tompa <ref> [15] </ref> show that such results do hold in a more restricted model in which the programs are restricted to being oblivious, i.e. straight-line, and the communication is one-way.
Reference: [16] <author> R. J. Lipton and R. Sedgewick, </author> <title> Lower bounds for VLSI, </title> <booktitle> in Proceedings of the Thirteenth Annual ACM Symposium on Theory of Computing, </booktitle> <address> Milwaukee, WI, </address> <month> May </month> <year> 1981, </year> <pages> pp. 300-307. </pages>
Reference-contexts: In addition, communication complexity has found surprising applications in the complexity of Boolean circuits (Karchmer and Wigderson [14], Raz and Wigderson [19]), Boolean decision trees (Hajnal, Maass, and Turan [13]), combinatorial optimization (Yannakakis [23]), VLSI (Aho, Ullman and Yannakakis [3], Lipton and Sedgewick <ref> [16] </ref>, Mehlhorn and Schmidt [18], Yao [25]), and pseudorandom number generators (Babai, Nisan, and Szegedy [5]). Nearly all previous work on the communication complexity of various problems has focused on their communication requirements alone, in the absence of any limitations on the individual processors.
Reference: [17] <author> Y. Mansour, N. Nisan, and P. Tiwari, </author> <title> The computational complexity of universal hashing, </title> <booktitle> in Proceedings of the Twenty Second Annual ACM Symposium on Theory of Computing, </booktitle> <address> Baltimore, MD, </address> <month> May </month> <year> 1990. </year>
Reference-contexts: This will allow us to obtain lower bounds for a variety of interesting computational problems. We make use of a beautiful analog due to Mansour, Nisan, and Tiwari <ref> [17] </ref> of a lemma of Lindsey [4, 11] concerning Hadamard matrices. Our results (and those in [17]) use the more restrictive definition of a universal family of hash functions given by Carter and Wegman in [10] (which they called `strongly universal' in [10]) rather than the somewhat broader definition given in <p> This will allow us to obtain lower bounds for a variety of interesting computational problems. We make use of a beautiful analog due to Mansour, Nisan, and Tiwari <ref> [17] </ref> of a lemma of Lindsey [4, 11] concerning Hadamard matrices. Our results (and those in [17]) use the more restrictive definition of a universal family of hash functions given by Carter and Wegman in [10] (which they called `strongly universal' in [10]) rather than the somewhat broader definition given in [9]. <p> Of the two properties of a function required to apply our lower bound technique, Property B is the more difficult to prove. The following lemma on pairwise universal hash functions is critical in proving Property B for families of hash functions. Lemma 4.1 (Mansour, Nisan, and Tiwari <ref> [17] </ref>). Let H be a pairwise universal family of hash functions from X to Z. Let A X, B H, and E Z. Then fi fi x2A;h2B jEj fi fi s jAj jBj jZj This lemma is used by Mansour, Nisan, and Tiwari [17] to prove time-space tradeoffs for computing hash <p> Lemma 4.1 (Mansour, Nisan, and Tiwari <ref> [17] </ref>). Let H be a pairwise universal family of hash functions from X to Z. Let A X, B H, and E Z. Then fi fi x2A;h2B jEj fi fi s jAj jBj jZj This lemma is used by Mansour, Nisan, and Tiwari [17] to prove time-space tradeoffs for computing hash functions. A somewhat weaker form of this lemma was proved independently by Yan [22] for the special case when the family of hash functions is given by matrix-vector product over GF (2). Theorem 4.2. <p> The next two corollaries follow from Theorem 4.2 exactly as shown by Mansour, Nisan, and Tiwari <ref> [17] </ref> for time-space tradeoffs. Corollary 4.6. Any open pair of communicating branching programs computing the m bit convolution of an n bit string with an (n + m 1) bit string requires communication C and space S such that C S = (nm). Corollary 4.7. <p> It is not clear what conditions on f will allow the handling of general A as well. The technique of Mansour, Nisan, and Tiwari <ref> [17] </ref> and Yan [22] implies that it is sufficient to have not only a small probability of a value in such a rectangle R but also a small variance in the probability of the value occurring in the rows (or columns) of R. Acknowledgements.
Reference: [18] <author> K. Mehlhorn and E. M. Schmidt, </author> <title> Las Vegas is better than determinism in VLSI and distributed computing, </title> <booktitle> in Proceedings of the Fourteenth Annual ACM Symposium on Theory of Computing, </booktitle> <address> San Francisco, CA, </address> <month> May </month> <year> 1982, </year> <pages> pp. 330-337. </pages>
Reference-contexts: In addition, communication complexity has found surprising applications in the complexity of Boolean circuits (Karchmer and Wigderson [14], Raz and Wigderson [19]), Boolean decision trees (Hajnal, Maass, and Turan [13]), combinatorial optimization (Yannakakis [23]), VLSI (Aho, Ullman and Yannakakis [3], Lipton and Sedgewick [16], Mehlhorn and Schmidt <ref> [18] </ref>, Yao [25]), and pseudorandom number generators (Babai, Nisan, and Szegedy [5]). Nearly all previous work on the communication complexity of various problems has focused on their communication requirements alone, in the absence of any limitations on the individual processors.
Reference: [19] <author> R. Raz and A. Wigderson, </author> <title> Monotone circuits for matching require linear depth, </title> <journal> Journal of the ACM, </journal> <volume> 39 (1992), </volume> <pages> pp. 736-744. </pages>
Reference-contexts: In addition, communication complexity has found surprising applications in the complexity of Boolean circuits (Karchmer and Wigderson [14], Raz and Wigderson <ref> [19] </ref>), Boolean decision trees (Hajnal, Maass, and Turan [13]), combinatorial optimization (Yannakakis [23]), VLSI (Aho, Ullman and Yannakakis [3], Lipton and Sedgewick [16], Mehlhorn and Schmidt [18], Yao [25]), and pseudorandom number generators (Babai, Nisan, and Szegedy [5]).
Reference: [20] <author> A. A. Razborov, </author> <title> On the distributional complexity of disjointness, </title> <booktitle> in Automata, Languages, and Programming: 17th International Colloquium, vol. 443 of Lecture Notes in Computer Science, </booktitle> <institution> Warwick University, </institution> <address> England, July 1990, </address> <publisher> Springer-Verlag, </publisher> <pages> pp. 249-253. </pages>
Reference-contexts: An alternative approach would be to try to generalize the distribution on inputs that Razborov <ref> [20] </ref> used to prove that the distributional communication complexity of the set disjointness problem is (n).
Reference: [21] <author> M. Tompa, </author> <title> Time-space tradeoffs for computing functions, using connectivity properties of their circuits, </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 20 (1980), </volume> <pages> pp. 118-132. </pages>
Reference-contexts: Thus, the lower bounds outlined above imply the corresponding time-space tradeoffs of Grigoryev [12] for straight-line programs and Abrahamson [2] for branching programs. The converse, however, is false. Whereas the time T and space S must satisfy T S = (n 2 ) when computing the discrete Fourier transform <ref> [2, 21, 27] </ref> or sorting [6, 8, 21], Lam, Tiwari, and Tompa [15] demonstrated that both of these functions can be computed in linear communication steps and O (log n) space simultaneously. Thus, these results strictly generalize previous time-space tradeoffs. 2. Communicating Branching Programs. <p> The converse, however, is false. Whereas the time T and space S must satisfy T S = (n 2 ) when computing the discrete Fourier transform [2, 21, 27] or sorting <ref> [6, 8, 21] </ref>, Lam, Tiwari, and Tompa [15] demonstrated that both of these functions can be computed in linear communication steps and O (log n) space simultaneously. Thus, these results strictly generalize previous time-space tradeoffs. 2. Communicating Branching Programs.
Reference: [22] <author> P. Yan, </author> <title> A tradeoff between communication and space. </title> <type> Manuscript, </type> <year> 1989. </year>
Reference-contexts: Let A X, B H, and E Z. Then fi fi x2A;h2B jEj fi fi s jAj jBj jZj This lemma is used by Mansour, Nisan, and Tiwari [17] to prove time-space tradeoffs for computing hash functions. A somewhat weaker form of this lemma was proved independently by Yan <ref> [22] </ref> for the special case when the family of hash functions is given by matrix-vector product over GF (2). Theorem 4.2. Let P be an open pair of communicating branching programs computing a pairwise universal family of hash functions from X to Z using communication C and space S. <p> It is not clear what conditions on f will allow the handling of general A as well. The technique of Mansour, Nisan, and Tiwari [17] and Yan <ref> [22] </ref> implies that it is sufficient to have not only a small probability of a value in such a rectangle R but also a small variance in the probability of the value occurring in the rows (or columns) of R. Acknowledgements.
Reference: [23] <author> M. Yannakakis, </author> <title> Expressing combinatorial optimization problems by linear programs, </title> <booktitle> in Proceedings of the Twentieth Annual ACM Symposium on Theory of Computing, </booktitle> <address> Chicago, IL, </address> <month> May </month> <year> 1988, </year> <pages> pp. 223-228. </pages>
Reference-contexts: In addition, communication complexity has found surprising applications in the complexity of Boolean circuits (Karchmer and Wigderson [14], Raz and Wigderson [19]), Boolean decision trees (Hajnal, Maass, and Turan [13]), combinatorial optimization (Yannakakis <ref> [23] </ref>), VLSI (Aho, Ullman and Yannakakis [3], Lipton and Sedgewick [16], Mehlhorn and Schmidt [18], Yao [25]), and pseudorandom number generators (Babai, Nisan, and Szegedy [5]).
Reference: [24] <author> A. C. Yao, </author> <title> Some complexity questions related to distributive computing, </title> <booktitle> in Proceedings of the Eleventh Annual ACM Symposium on Theory of Computing, </booktitle> <address> Atlanta, GA, Apr.-May 12 P. </address> <publisher> BEAME, </publisher> <editor> M. TOMPA, AND P. </editor> <booktitle> YAN 1979, </booktitle> <pages> pp. </pages> <month> 209-213. </month> <title> [25] , The entropic limitations of VLSI computations, </title> <booktitle> in Proceedings of the Thirteenth Annual ACM Symposium on Theory of Computing, </booktitle> <address> Milwaukee, WI, </address> <month> May </month> <year> 1981, </year> <pages> pp. </pages> <month> 308-311. </month> <title> [26] , Lower bounds by probabilistic arguments, </title> <booktitle> in 24th Annual Symposium on Foundations of Computer Science, </booktitle> <address> Tucson, AZ, Nov. 1983, </address> <publisher> IEEE, </publisher> <pages> pp. 420-428. </pages>
Reference-contexts: It is also clear that if (x; y) reaches (u; v) then fl c (u;v) (x; y) = ff is defined and so (x; y) 2 R ff (u;v) . The fact that each R ff (u;v) is a rectangle follows by standard arguments in communication complexity (Yao <ref> [24] </ref>). It is proved inductively on the prefixes of ff. We are now ready to state properties of a function that make it possible to prove communication-space tradeoffs. These properties will depend on certain parameters p, m, fi, q, a, and K that will be set in later applications. <p> The question of the communication-space tradeoff for ^-_ matrix product and GF (2) matrix-vector product raises another interesting question. Suppose that function f on X fi Y has *-error distributional communication complexity (Yao <ref> [24, 26] </ref>) at least D * . <p> what circumstances does the function F on X n fi Y given by F ((x 1 ; : : : ; x n ); y) = (f (x 1 ; y); : : : ; f (x n ; y)) have communication-space tradeoff (nD * )? As shown by Yao <ref> [24, 26] </ref> and extended by Babai, Frankl, and Simon [4], a lower bound D * k can be obtained by showing that, for an appropriate distribution on X fi Y under which f takes on each value at least a constant fraction of the time, any rectangle R, in which the
Reference: [27] <author> Y. Yesha, </author> <title> Time-space tradeoffs for matrix multiplication and the discrete Fourier transform on any general sequential random-access computer, </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 29 (1984), </volume> <pages> pp. 183-197. </pages>
Reference-contexts: Thus, the lower bounds outlined above imply the corresponding time-space tradeoffs of Grigoryev [12] for straight-line programs and Abrahamson [2] for branching programs. The converse, however, is false. Whereas the time T and space S must satisfy T S = (n 2 ) when computing the discrete Fourier transform <ref> [2, 21, 27] </ref> or sorting [6, 8, 21], Lam, Tiwari, and Tompa [15] demonstrated that both of these functions can be computed in linear communication steps and O (log n) space simultaneously. Thus, these results strictly generalize previous time-space tradeoffs. 2. Communicating Branching Programs. <p> In their model each straight-line program is augmented with send and receive instructions. They leave open the question of defining an appropriate nonoblivious model. Since branching programs have proved to be useful sequential models for the simultaneous measure of time and space <ref> [1, 2, 6, 7, 8, 27] </ref> it is natural to use them to model the communicating parties. Making the analogous changes to branching programs that Lam, Tiwari, and Tompa made to straight-line programs leads to the following model.
References-found: 24

