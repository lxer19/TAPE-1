URL: http://www.cs.colostate.edu/~vision/ps/iuw94-rsta-piover.ps.gz
Refering-URL: http://www.cs.colostate.edu/~vision/html/publications.html
Root-URL: 
Email: ross@cs.colostate.edu  hanson@cs.umass.edu  panda@rtc.atk.com  
Title: and Alliant Techsystems Team used for initial target detection under daylight conditions and camouflage learned
Author: J. Ross Beveridge Allen Hanson Durga Panda 
Note: Color is  
Affiliation: RSTA Research of the Colorado State, University of Massachusetts  Colorado State University  University of Massachusetts  Alliant Techsystems Inc.  
Abstract: The complementary nature of LADAR, FLIR and color data for ATR is being exploited by new algorithms in a three stage recognition system. The stages are initial detection, target class and pose hypothesis generation, and precise model to multisensor coregistra-tion matching. Coregistration globally aligns 3D target models with range, IR and color imagery while simultaneously refining registration parameters between sensors. This model directed approach is expected to improve ATR performance for occluded targets, targets seen at unusual angles, and targets in cluttered settings. 
Abstract-found: 1
Intro-found: 1
Reference: [ Beveridge and Riseman, 1992 ] <author> J. Ross Beveridge and Edward M. Riseman. </author> <title> Hybrid Weak-Perspective and Full-Perspective Matching. </title> <booktitle> In Proceedings: IEEE 1992 Computer Society Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 432 - 438. </pages> <publisher> IEEE Computer Society, </publisher> <month> June </month> <year> 1992. </year>
Reference-contexts: Later versions utilized the 3D sensor pose work of Kumar [ Kumar, 1989; Kumar, 1992; Kumar and Hanson, 1994 ] to perform fitting of 3D object models to corresponding features in a 2D image <ref> [ Beveridge and Riseman, 1992; Beveridge and Rise-man, 1994 ] </ref> . Currently the work of Kumar is being extended to handle both registration between multiple sensors as well as 3D pose between the sensors and object model. The resulting least-squares fitting procedure is what we have chosen to call 'coregistration'.
Reference: [ Beveridge and Riseman, 1994 ] <author> J. Ross Beveridge and Edward M. Riseman. </author> <title> Optimal Geometric Model Matching Under Full 3D Perspective. </title> <booktitle> In Second CAD-Based Vision Workshop, </booktitle> <pages> pages 54 - 63. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> February </month> <year> 1994. </year> <note> (Submitted to CVGIP-IU). </note>
Reference-contexts: One repeatedly matches features to their nearest neighbors in object/sensor space and has been used successfully to match LADAR data [ Bevington et al., 1992; Bevington, 1992 ] . The other is to extend our local search matching work previously developed for single sensor problems <ref> [ Beveridge, 1993; Beveridge and Riseman, 1994 ] </ref> . These local search algorithms explore perturbations in correspondence space. They require more computation than the nearest neighbor techniques.
Reference: [ Beveridge et al., 1990 ] <author> J. Ross Beveridge, Rich Weiss, and Edward M. Riseman. </author> <title> Combinatorial Optimization Applied to Variable Scale 2D Model Matching. </title> <booktitle> In Proceedings of the IEEE International Conference on Pattern Recognition 1990, Atlantic City, </booktitle> <pages> pages 18 - 23. </pages> <publisher> IEEE, </publisher> <month> June </month> <year> 1990. </year>
Reference-contexts: Measures of match quality will thus account for global geometric consistency. Our past work on model matching [ Beveridge, 1993 ] has emphasized matching subject to global geometric consistency as enforced by a single least-squares constraint between all model and corresponding image features. In early versions of this work <ref> [ Beveridge et al., 1991; Beveridge et al., 1990 ] </ref> , essentially 2D models were fit to 2D image data subject to a single best-fit 2D similarity transformation.
Reference: [ Beveridge et al., 1991 ] <author> J. Ross Beveridge, Rich Weiss, and Edward M. Riseman. </author> <title> Optimization of 2-Dimensional Model Matching. </title> <editor> In Hatem Nasr, editor, </editor> <booktitle> Selected Papers on Automatic Object Recognition (originally appeared in DARPA Image Understanding Workshop, 1989), SPIE Milestone Series. SPIE, </booktitle> <address> Bellingham, WA, </address> <year> 1991. </year>
Reference-contexts: Measures of match quality will thus account for global geometric consistency. Our past work on model matching [ Beveridge, 1993 ] has emphasized matching subject to global geometric consistency as enforced by a single least-squares constraint between all model and corresponding image features. In early versions of this work <ref> [ Beveridge et al., 1991; Beveridge et al., 1990 ] </ref> , essentially 2D models were fit to 2D image data subject to a single best-fit 2D similarity transformation.
Reference: [ Beveridge et al., 1994 ] <author> J. Ross Beveridge, Durga P. Panda, and Theodore Yachik. </author> <title> November 1993 Fort Carson RSTA Data Collection Final Report. </title> <type> Technical Report CSS-94-118, </type> <institution> Colorado State University, </institution> <address> Fort Collins, CO, </address> <month> January </month> <year> 1994. </year>
Reference-contexts: The result of this data collection effort is over 400 LADAR, FLIR and color images of four different military vehicles. Vehicles are both out in the open and terrain occluded. This activity is described further in Section 5.1 and <ref> [ Beveridge et al., 1994 ] </ref> . Another major activity is to explore the use of color as an alternative to FLIR for daytime target detection. Results on Fort Carson data show that multivariate decision tree learning techniques can discriminate camouflage from outwardly similar terrain. <p> The data collection effort was highly constrained in terms of time, resources, vehicles and terrain. This limited the amount of data and ground truth information which could be collected. These limitations not withstanding, over 400 LADAR, FLIR and color images were collected. There is a 50 page report <ref> [ Beveridge et al., 1994 ] </ref> describing each image, vehicle array, and ancillary information such as time of day and weather conditions. It also includes a copy of the original data collection plan and examples of the data.
Reference: [ Beveridge, 1993 ] <author> J. Ross Beveridge. </author> <title> Local Search Algorithms for Geometric Obejct Recognition: Optimal Correspondence and Pose. </title> <type> PhD thesis, </type> <institution> University of Massachuesetts at Amherst, </institution> <month> May </month> <year> 1993. </year>
Reference-contexts: These coreg-istration algorithms will be used for matching models to multisensor data in a way which lets global model and sensor geometry constrain the relationship between matched features. Measures of match quality will thus account for global geometric consistency. Our past work on model matching <ref> [ Beveridge, 1993 ] </ref> has emphasized matching subject to global geometric consistency as enforced by a single least-squares constraint between all model and corresponding image features. <p> One repeatedly matches features to their nearest neighbors in object/sensor space and has been used successfully to match LADAR data [ Bevington et al., 1992; Bevington, 1992 ] . The other is to extend our local search matching work previously developed for single sensor problems <ref> [ Beveridge, 1993; Beveridge and Riseman, 1994 ] </ref> . These local search algorithms explore perturbations in correspondence space. They require more computation than the nearest neighbor techniques.
Reference: [ Bevington et al., 1992 ] <author> James Bevington, Randy John-ston, Joel Lee, and Richard Peters. </author> <title> A Modular Target Recognition Algorithm for LADAR. </title> <booktitle> In Proc of the 2nd Automatic Target Recognizer Systems and Technology Conference, </booktitle> <pages> pages 91 - 104, </pages> <address> Fort Belvoir, VA, </address> <month> March </month> <year> 1992. </year>
Reference-contexts: Two approaches are being explored. One repeatedly matches features to their nearest neighbors in object/sensor space and has been used successfully to match LADAR data <ref> [ Bevington et al., 1992; Bevington, 1992 ] </ref> . The other is to extend our local search matching work previously developed for single sensor problems [ Beveridge, 1993; Beveridge and Riseman, 1994 ] . These local search algorithms explore perturbations in correspondence space.
Reference: [ Bevington, 1992 ] <author> James Bevington. </author> <title> Laser Radar ATR Algorithms, Phase III Final Report. </title> <type> Technical report, </type> <institution> Alliant Techsystems, </institution> <month> May </month> <year> 1992. </year> <note> Prepared under CC-NVEO Contract No. DAAB07-87-C-F109. </note>
Reference-contexts: Two approaches are being explored. One repeatedly matches features to their nearest neighbors in object/sensor space and has been used successfully to match LADAR data <ref> [ Bevington et al., 1992; Bevington, 1992 ] </ref> . The other is to extend our local search matching work previously developed for single sensor problems [ Beveridge, 1993; Beveridge and Riseman, 1994 ] . These local search algorithms explore perturbations in correspondence space.
Reference: [ Brodley and Utgoff, 1994 ] <author> C. E. Brodley and P. E. Ut-goff. </author> <title> Goal-directed Classification Using Linear Machine Decision Trees. </title> <journal> Machine Learning, </journal> <note> page (to appear), </note> <year> 1994. </year>
Reference-contexts: However, they also find optimal solutions for a wider range of initial conditions. 5.3 Color Target Detection There are three basic reasons why it is important to study the use of color as a feature for performing target detection. First, new machine learning techniques have been developed <ref> [ Brodley and Utgoff, 1994 ] </ref> which learn non-parametric combinations of features and they have been successfully applied to difficult pixel classification tasks [ Draper et al., 1994 ] under varied lighting conditions.
Reference: [ Buluswar et al., 1994 ] <author> Shashi Buluswar, Bruce A. Draper, Allen Hanson, and Edward Riseman. </author> <title> Non-parametric Classification of Pixels Under Varying Outdoor Illumination. </title> <booktitle> In Proceedings: Image Understanding Workshop, page (to appear), </booktitle> <address> Los Altos, CA, </address> <month> November </month> <year> 1994. </year> <title> ARPA, </title> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: The current work uses non-parametric combination of the basic red, green and blue values of the color signal and realtime detection can be supported by encoding the decision tree as a lookup table. This subproject is described further in Section 5.3 and elsewhere in these proceedings <ref> [ Buluswar et al., 1994 ] </ref> . Past work of our team has shown that bounding contours in LADAR can be used to perform recognition. Adapting and extending this work to perform target class and pose hypothesis generation is now a major project activity. <p> This determination is based upon non-parametric combinations of red, green and blue values learned by a multivariate decision tree learning procedure described below and in more detail elsewhere in these proceedings <ref> [ Buluswar et al., 1994 ] </ref> . Following pixel classification, morphological techniques are used to discard single or several pixel target responses and leave target regions. Preliminary tests have shown generalization across vehicles and across lighting conditions, specifically direct sun versus overcast.
Reference: [ Draper et al., 1994 ] <author> B. Draper, C. E. Brodley, and P. Utgoff. </author> <title> Goal-directed Classification Using Linear Machine Decision Trees. </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, </journal> <note> 16(9):(to appear), </note> <month> September </month> <year> 1994. </year>
Reference-contexts: First, new machine learning techniques have been developed [ Brodley and Utgoff, 1994 ] which learn non-parametric combinations of features and they have been successfully applied to difficult pixel classification tasks <ref> [ Draper et al., 1994 ] </ref> under varied lighting conditions. Second, although most RSTA activities are conducted at night, for those conducted during daylight, it makes no sense to disregard visible light. Moreover, one can argue color is most useful precisely when FLIR is least useful.
Reference: [ Goss et al., 1994 ] <author> Michael E. Goss, J. Ross Beveridge, Mark Stevens, and Aaron Fuegi. </author> <title> Visualization and Verification of Automatic Target Recognition Results Using Combined Range and Optical Imagery. </title> <booktitle> In Proceedings: Image Understanding Workshop, page (to appear), </booktitle> <address> Los Altos, CA, </address> <month> November </month> <year> 1994. </year> <title> ARPA, </title> <publisher> Mor-gan Kaufmann. </publisher>
Reference-contexts: More interestingly, selection of corresponding points on object models and in multiple images permits the coreg-istration algorithm to be used to generate both the best placement of the object and the associated best registration between images. This tool is further described in Section 5.5 and elsewhere in these proceedings <ref> [ Goss et al., 1994 ] </ref> . 5.1 Fort Carson Data Collection A data collection effort was mounted by Martin Mari-etta, Colorado State University, and Alliant Techsystems in order to meet immediate needs of the the RSTA effort.
Reference: [ Kumar and Hanson, 1994 ] <author> Rakesh Kumar and Allen R. Hanson. </author> <title> Robust Methods for Estimating Pose and a Sensitivity Analysis. CVGIP:Image Understanding, </title> <note> 11:(to appear in November), </note> <year> 1994. </year>
Reference-contexts: In early versions of this work [ Beveridge et al., 1991; Beveridge et al., 1990 ] , essentially 2D models were fit to 2D image data subject to a single best-fit 2D similarity transformation. Later versions utilized the 3D sensor pose work of Kumar <ref> [ Kumar, 1989; Kumar, 1992; Kumar and Hanson, 1994 ] </ref> to perform fitting of 3D object models to corresponding features in a 2D image [ Beveridge and Riseman, 1992; Beveridge and Rise-man, 1994 ] . <p> This fitting process includes free variables to allow for refinement of sensor-to-sensor registration as well as the 6 pose parameters defining the position and orientation of the object relative to the sensor. This coreg-istration fitting process is based upon extending earlier single sensor pose work performed by Kumar <ref> [ Kumar, 1992; Kumar and Hanson, 1994 ] </ref> . Kumar proposed a set of equations for computing the "best" pose, given a matching between model edges and image edges of a single image.
Reference: [ Kumar, 1989 ] <author> Rakesh Kumar. </author> <title> Determination of Camera Location and Orientation. </title> <booktitle> In Proceedings: Image Understanding Workshop, </booktitle> <pages> pages 870 - 881, </pages> <address> Los Altos, CA, </address> <month> June </month> <year> 1989. </year> <title> DARPA, </title> <publisher> Morgan Kaufmann Publishers, Inc. </publisher>
Reference-contexts: In early versions of this work [ Beveridge et al., 1991; Beveridge et al., 1990 ] , essentially 2D models were fit to 2D image data subject to a single best-fit 2D similarity transformation. Later versions utilized the 3D sensor pose work of Kumar <ref> [ Kumar, 1989; Kumar, 1992; Kumar and Hanson, 1994 ] </ref> to perform fitting of 3D object models to corresponding features in a 2D image [ Beveridge and Riseman, 1992; Beveridge and Rise-man, 1994 ] .
Reference: [ Kumar, 1992 ] <author> Rakesh Kumar. </author> <title> Model Dependent Inference of 3D Information From a Sequence of 2D Images. </title> <type> PhD thesis, </type> <institution> University of Massachusetts, Amherst, </institution> <month> February </month> <year> 1992. </year>
Reference-contexts: In early versions of this work [ Beveridge et al., 1991; Beveridge et al., 1990 ] , essentially 2D models were fit to 2D image data subject to a single best-fit 2D similarity transformation. Later versions utilized the 3D sensor pose work of Kumar <ref> [ Kumar, 1989; Kumar, 1992; Kumar and Hanson, 1994 ] </ref> to perform fitting of 3D object models to corresponding features in a 2D image [ Beveridge and Riseman, 1992; Beveridge and Rise-man, 1994 ] . <p> This fitting process includes free variables to allow for refinement of sensor-to-sensor registration as well as the 6 pose parameters defining the position and orientation of the object relative to the sensor. This coreg-istration fitting process is based upon extending earlier single sensor pose work performed by Kumar <ref> [ Kumar, 1992; Kumar and Hanson, 1994 ] </ref> . Kumar proposed a set of equations for computing the "best" pose, given a matching between model edges and image edges of a single image.
Reference: [ Schwickerath and Beveridge, 1994 ] <author> Anthony N. A. Schwickerath and J. Ross Beveridge. </author> <title> Model to Multi-sensor Coregistration with Eight Degrees of Freedom. </title> <booktitle> In Proceedings: Image Understanding Workshop, page (to appear), </booktitle> <address> Los Altos, CA, </address> <month> November </month> <year> 1994. </year> <title> ARPA, </title> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: The resulting least-squares fitting procedure is what we have chosen to call 'coregistration'. Coregistra-tion is summarized in Section 5.2 and reported in more detail elsewhere in these proceedings <ref> [ Schwickerath and Beveridge, 1994 ] </ref> . To work with range, IR and color data, particularly since the geometric relationship between data and model is a primary concern, it is has been crucial to develop tools which permit these relationships to be visualized. <p> Given that objects at a distance are being viewed, these small sensor rotations may be approximated as small image translations. The image translation coregistration work is described in detail elsewhere in these proceedings <ref> [ Schwickerath and Beveridge, 1994 ] </ref> . Experiments have been conducted using synthetic data to test the robustness of the algorithm. It has also been used to perform coregistration on LADAR and CCD data collected at Fort Carson.
References-found: 16

