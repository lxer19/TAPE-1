URL: http://www.isi.edu/netstation/zcav/zcav.ps
Refering-URL: http://www.isi.edu/netstation/zcav/index.html
Root-URL: http://www.isi.edu
Title: Observing the Effects of Multi-Zone Disks  
Author: Rodney Van Meter 
Affiliation: Information Sciences Institute University of Southern California  
Web: http://www.isi.edu/netstation/zcav/  
Date: Jan. 1997  
Note: Appears in the Proc. Usenix 1997 Technical Conference, Anaheim, CA,  PostScript paper available at  
Abstract: Current generations of hard disk drives use a technique known as zoned constant angular velocity (ZCAV), taking advantage of the geometry to increase total disk capacity by varying the number of disk sectors per track with the distance from the spindle. A side effect of this is that the transfer rate also varies with sector address. We analytically estimated and measured this effect on file system performance on a BSD Fast File System, showing a drop of roughly 25% in peak transfer rate depending on head position. We also show that, while ZCAV effects cannot be ignored, a simple linear model adequately estimates the performance from the few parameters normally available in disk drive spec sheets. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> ANSI. </author> <booktitle> Information Technology Small Computer Systems Interface - 2 (X3T9.2 rev 10l), </booktitle> <month> Sept. </month> <year> 1993. </year>
Reference-contexts: The cylinders are grouped into zones that all have the same number of sectors per track. Some manufacturers refer to this as Zoned Bit Recording, ZBR. It is referred to as notches or a notched drive in the Small Computer Systems Interface (SCSI) specification <ref> [1] </ref>. As a side effect of this, since the time per rotation is constant, the number of sectors read per second (and hence the transfer rate) is higher on outer tracks. The read and write electronics must be able to keep up with the higher data rates required.
Reference: [2] <editor> W. J. Bolosky et al. </editor> <booktitle> The tiger video fileserver. In Proc. Sixth International Workshop on Network and Operating System Support for Digital Audio and Video, </booktitle> <month> Apr. </month> <year> 1996. </year> <note> available at ftp://ftp.research.microsoft.com/pub/tech-reports/Winter95-96/TR-96-09.ps. </note>
Reference-contexts: DABT63-93-C-0062. Views and conclusions contained in this report are the authors' and should not be interpreted as representing the official opinion or policies, either expressed or implied, of ARPA, the U.S. Government, or any person or agency connected with them. The Microsoft Tiger Video Server <ref> [2] </ref> uses a simple placement algorithm in which primary data is placed on outer tracks and secondary (redundant, infrequently-accessed) data is placed on inner tracks.
Reference: [3] <author> W. de Jonge, M. F. Kaashoek, and W. C. Hsieh. </author> <title> The logical disk: A new approach to improving file systems. </title> <booktitle> In Proc. Fourteenth ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 15-28, </pages> <month> Dec. </month> <year> 1993. </year>
Reference-contexts: Our work benefits from this work. Other possible file system structures, such as SGI's XFS [12], may depend on more dynamic, and hence complex, data structures, and may therefore not allocate blocks as predictably. A log-based file system [9] or disk device <ref> [3] </ref> clearly will not, in their present forms, allocate blocks in a fashion amenable to improving throughput by careful choice of blocks. 6.2 Impact on File System Allocation Policies As proposed by Ghandeharizadeh [4], the idea of including a measure of ZCAV effects into a dynamic file relocater is appealing.
Reference: [4] <author> S. Ghandeharizadeh, D. J. Ierardi, D. Kim, and R. Zimmerman. </author> <title> Placement of data in multi-zone disk drives. </title> <booktitle> rcvd from author, </booktitle> <month> June </month> <year> 1995. </year>
Reference-contexts: Worthington et al [13] built a disk model which includes zone information, but the emphasis of their work is on disk scheduling algorithms to reduce latency, rather than improve throughput. Ghandeharizadeh has suggested <ref> [4] </ref> that file placement be adjusted based on access history to take advantage of ZCAV effects, but no work has measured the effects directly. fl This research was sponsored by the Advanced Research Projects Agency under Contract No. DABT63-93-C-0062. <p> A log-based file system [9] or disk device [3] clearly will not, in their present forms, allocate blocks in a fashion amenable to improving throughput by careful choice of blocks. 6.2 Impact on File System Allocation Policies As proposed by Ghandeharizadeh <ref> [4] </ref>, the idea of including a measure of ZCAV effects into a dynamic file relocater is appealing. Such functionality could be included in a file system defragmenter, moving older, less-frequently-accessed files to lower-transfer-rate areas of the disk.
Reference: [5] <author> S. J. Le*er, M. K. McKusick, M. J. Karels, and J. S. Quarterman. </author> <title> The Design and Implementation of the 4.3BSD UNIX Operating System. </title> <publisher> Addison-Wesley, </publisher> <year> 1989. </year>
Reference-contexts: The drive rotates at 5,411 rpm. Write caching at the disk is disabled; all writes are synchronous. The file system is a SunOS UFS, essentially a BSD fast file system <ref> [5] </ref>. The partition used for these experiments begins at sector number 655,200 and extends 687MB to the end of the disk, as reported by dkinfo. Thus, according to table 2, the partition starts at a transfer rate of 3.24 MB/sec. and falls to 2.06, a drop of 36%.
Reference: [6] <author> L. W. McVoy and S. R. Kleiman. </author> <title> Extent-like performance from a UNIX file system. </title> <booktitle> In Proc. 1991 USENIX Winter Technical Conference, </booktitle> <pages> pages 33-43. </pages> <publisher> USENIX, </publisher> <year> 1991. </year>
Reference-contexts: Note that this does not mean that disk fragmentation is 9 10 not a general problem, only that once large areas of disk have been cleared of files, the reuse of that area is optimal (or at least predictable). McVoy showed that a UFS can achieve good write performance <ref> [6] </ref> 3 . The file blocks are allocated contiguously and I/Os are performed in clusters, much like an extent-based file system. Our work benefits from this work.
Reference: [7] <author> R. H. Patterson, G. A. Gibson, E. Gint-ing, D. Stodolsky, and J. Zelenka. </author> <title> Informed prefetching and caching. </title> <booktitle> In Proc. 15th Annual ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 79-95. </pages> <publisher> ACM, </publisher> <month> Dec. </month> <year> 1995. </year>
Reference-contexts: Large files accessed in small I/O requests also will not take good advantage of the transfer rate. Determining which files will take advantage of this may require cooperation from applications, perhaps via some form of hints <ref> [7] </ref>. Incorporating knowledge of the drive's ZCAV nature into the cleaner for a log-structured file system may be useful. Data should be packed toward the spindle, so that the open area for upcoming log writes will get to use the outer, faster regions of the disk.
Reference: [8] <author> P. V. Rangan and H. M. Vin. </author> <title> Designing file systems for digital video and audio. </title> <booktitle> In Proc. Thirteenth ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 81-94, </pages> <month> Oct. </month> <year> 1991. </year>
Reference-contexts: Such functionality could be included in a file system defragmenter, moving older, less-frequently-accessed files to lower-transfer-rate areas of the disk. It is clear that this effect needs to be taken into account for multimedia file systems and file systems (such as SGI's XFS [12] or Rangan's multimedia ropes <ref> [8] </ref>) that provide guaranteed throughput. However, to date these have all assumed disk bandwidth is fixed, rather than a function of block address.
Reference: [9] <author> M. Rosenblum and J. K. Ousterhout. </author> <title> The design and implementation of a log-structured file system. </title> <booktitle> In Proceedings of the 13th Symposium on Operating Systems Principles, </booktitle> <pages> pages 1-15. </pages> <publisher> ACM, </publisher> <month> Oct. </month> <year> 1991. </year>
Reference-contexts: Our work benefits from this work. Other possible file system structures, such as SGI's XFS [12], may depend on more dynamic, and hence complex, data structures, and may therefore not allocate blocks as predictably. A log-based file system <ref> [9] </ref> or disk device [3] clearly will not, in their present forms, allocate blocks in a fashion amenable to improving throughput by careful choice of blocks. 6.2 Impact on File System Allocation Policies As proposed by Ghandeharizadeh [4], the idea of including a measure of ZCAV effects into a dynamic file
Reference: [10] <author> C. Ruemmler and J. Wilkes. </author> <title> An introduction to disk drive modeling. </title> <journal> Computer, </journal> <volume> 27(3) </volume> <pages> 17-28, </pages> <month> Mar. </month> <year> 1994. </year>
Reference-contexts: A side effect of this is that the transfer rate also varies with block address. Despite some excellent recent work on modeling the behavior of disk drives <ref> [10, 14] </ref>, the effects of ZCAV have generally not been taken into account in the design of file systems. Worthington et al [13] built a disk model which includes zone information, but the emphasis of their work is on disk scheduling algorithms to reduce latency, rather than improve throughput. <p> A track consists of a number of sectors (occasionally called blocks), the smallest unit of data that can be read or written by the drive (typically 512 or 1024 bytes, but theoretically any number). The triple &lt;cylinder,head,sector&gt; uniquely defines a location on the drive. See <ref> [10, 13] </ref> for good introductions to disk architecture. ZCAV is a technique adopted by hard disk manufacturers to increase the capacity of disk drives. Outer tracks, which are longer, contain more sec 1 tors than the shorter inner tracks.
Reference: [11] <author> Seagate. </author> <title> Product Manual Hawk 1 Family SCSI-2 (Volume 1), </title> <journal> Rev. D, </journal> <year> 1994. </year>
Reference-contexts: Any read or write rate that exceeds that has clearly been the beneficiary of caching, either the file system's buffer cache or the disk drive's data block cache. According to the manual <ref> [11] </ref>, this disk drive has 23 zones, or notches, and an average (mean) of 73 sectors per track, 15 heads, 1,872 cylinders for a total of 28,080 tracks. The drive rotates at 5,411 rpm. Write caching at the disk is disabled; all writes are synchronous.
Reference: [12] <author> A. Sweeney, D. Doucette, W. Hu, C. Anderson, M. Nishimoto, and G. Peck. </author> <title> Scalability in the XFS file system. </title> <booktitle> In Proc. 1996 USENIX Technical Conference, </booktitle> <pages> pages 1-14. </pages> <publisher> USENIX, </publisher> <month> Jan. </month> <year> 1996. </year>
Reference-contexts: McVoy showed that a UFS can achieve good write performance [6] 3 . The file blocks are allocated contiguously and I/Os are performed in clusters, much like an extent-based file system. Our work benefits from this work. Other possible file system structures, such as SGI's XFS <ref> [12] </ref>, may depend on more dynamic, and hence complex, data structures, and may therefore not allocate blocks as predictably. <p> Such functionality could be included in a file system defragmenter, moving older, less-frequently-accessed files to lower-transfer-rate areas of the disk. It is clear that this effect needs to be taken into account for multimedia file systems and file systems (such as SGI's XFS <ref> [12] </ref> or Rangan's multimedia ropes [8]) that provide guaranteed throughput. However, to date these have all assumed disk bandwidth is fixed, rather than a function of block address.
Reference: [13] <author> B. L. Worthington, G. R. Ganger, and Y. N. Patt. </author> <title> Scheduling for modern disk drives and non-random workloads. </title> <type> Technical Report CSE-TR-194-94, </type> <institution> University of Michigan, </institution> <month> Mar. </month> <year> 1994. </year>
Reference-contexts: A side effect of this is that the transfer rate also varies with block address. Despite some excellent recent work on modeling the behavior of disk drives [10, 14], the effects of ZCAV have generally not been taken into account in the design of file systems. Worthington et al <ref> [13] </ref> built a disk model which includes zone information, but the emphasis of their work is on disk scheduling algorithms to reduce latency, rather than improve throughput. <p> A track consists of a number of sectors (occasionally called blocks), the smallest unit of data that can be read or written by the drive (typically 512 or 1024 bytes, but theoretically any number). The triple &lt;cylinder,head,sector&gt; uniquely defines a location on the drive. See <ref> [10, 13] </ref> for good introductions to disk architecture. ZCAV is a technique adopted by hard disk manufacturers to increase the capacity of disk drives. Outer tracks, which are longer, contain more sec 1 tors than the shorter inner tracks.
Reference: [14] <author> B. L. Worthington, G. R. Ganger, Y. N. Patt, and J. Wilkes. </author> <title> On-line extraction of SCSI disk drive parameters. </title> <booktitle> In Proc. ACM Sigmetrics Conference, </booktitle> <month> May </month> <year> 1995. </year> <title> Availability The code used for these measurements and data obtained is available on the web at http://www.isi.edu/netstation/zcav/ or on the author's home page at http://www.isi.edu/~rdv/ or http://alumni.caltech.edu/~rdv/. The author may be contacted via email at rdv@isi.edu or rdv@alumni.caltech.edu. </title> <type> 12 </type>
Reference-contexts: A side effect of this is that the transfer rate also varies with block address. Despite some excellent recent work on modeling the behavior of disk drives <ref> [10, 14] </ref>, the effects of ZCAV have generally not been taken into account in the design of file systems. Worthington et al [13] built a disk model which includes zone information, but the emphasis of their work is on disk scheduling algorithms to reduce latency, rather than improve throughput.
References-found: 14

