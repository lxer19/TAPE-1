URL: http://dworkin.wustl.edu/techreports/1996/96-01.ps.gz
Refering-URL: http://dworkin.wustl.edu/publications.html
Root-URL: 
Title: Simulation of Asynchronous Instruction Pipelines  
Author: Chia-Hsing Chien Mark A. Franklin 
Keyword: Key Words asynchronous, instruction pipeline, event simulation, performance visualization  
Address: Campus Box 1115  St. Louis, Missouri 63130-4899  
Affiliation: Computer and Communications Research Center  Washington University  
Note: For Submission as a Regular Paper to the 1996 Summer Computer Simulation Conference  This research has been funded in part by ARPA Contract DABT-93-C0057  
Email: justin@wuccrc.wustl.edu jbf@wuccrc.wustl.edu  
Phone: (314)935-8562 (314)935-6107  
Abstract: This paper presents the ARAS simulator with which asynchronous instruction pipelines can be modelled, simulated and displayed. ARAS allows one to construct instruction pipelines by preparing various configuration files. Using these files and a number of benchmark programs, performance of the instruction pipelines can be obtained. The performance of asynchronous instruction pipelines can also be compared to synchronous case. Thus, one can decide the optimal design for instruction pipelines in asynchronous or synchronous cases and explore the design space of asynchronous instruction pipeline architectures. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D.K. Arvind, R.D. Mullins, and V.E.F. Rebello. Micronets: </author> <title> A Model for Decentralising Control in Asynchronous Processor Architectures. </title> <booktitle> In 2nd Working Conference on Asynchronous Design Methodologies, </booktitle> <address> London, England, </address> <month> May </month> <year> 1995. </year>
Reference-contexts: The performance advantages associated with asynchronous design are discussed in more detail in [9, 10] At the Second Working Conference on Asynchronous Design Methodologies (1995), several additional asynchronous machine designs were proposed although the performance of these machines is still not clear <ref> [17, 1, 7] </ref>. The simulation tool ARAS is designed to help evaluated the performance of alternative asynchronous architectures. Thus, evaluations can be obtained prior to implementing the real machine. Section 2 below presents an overview of the ARAS simulator and how it is used.
Reference: [2] <author> Chia-Hsing Chien. ARAS: </author> <title> Asynchronous RISC Architecture Simulator. </title> <type> Technical Report WUCCRC-95-04, </type> <institution> Washington University, </institution> <address> St. Louis, MO, </address> <month> August </month> <year> 1995. </year>
Reference-contexts: The ARAS simulator can also simulate a clocked instruction pipeline if CLOCK MODE is selected. In this case, the clock rate is determined by the parameter CLOCK TIME. Details of the parameters in the operation delays file can be found in <ref> [2] </ref>. With ARAS, benchmark programs can be written in any programming language if these programs can be compiled as SPARC assembly code. However, before the benchmark programs are fed into ARAS, they need to be translated from SPARC assembly codes into the ARAS format.
Reference: [3] <editor> W.A. Clark. </editor> <booktitle> Macromodular Computer Systems. In Proc. Spring Joint Comput. Conf., </booktitle> <address> AFIP, </address> <year> 1967. </year>
Reference-contexts: If block i+1 is busy, the instruction waits in the current block until the successor block i+1 can accept a new instruction. The use of asynchronous modules in the design of processors goes back to the 1960's with work at Washington University in St. Louis <ref> [3] </ref>; however, an entire asynchronous microprocessor was not 3 developed until 1988 at the California Institute of Technology [16]. Later, an asynchronous version of the ARM processor, AMULET1, was built at University of Manchester (UK) [11].
Reference: [4] <author> L.W. Cotten. </author> <title> Circuit Implementation of High-Speed Pipeline Systems. </title> <booktitle> In Proc. AFIPS Fall Joint Computer Conference, </booktitle> <pages> pages 489-504, </pages> <year> 1965. </year> <month> 13 </month>
Reference-contexts: Other efficiency factors include reducing synchronization overhead and, where possible, exploiting instruction-level parallelism by having multiple parallel pipelines. Various RISC processors incorporate these and other techniques for improving overall instruction throughput and their effect on the performance of instruction pipelines has been studied in <ref> [4, 5, 6, 8, 12, 13, 14, 15, 20] </ref>. Although the idea of asynchronous design has been explored since 1950's, most digital systems are currently clocked.
Reference: [5] <author> P.K. Dubey and M.J. Flynn. </author> <title> Optimal Pipelining. </title> <editor> J. </editor> <booktitle> of Parallel and Distributed Computing, </booktitle> <pages> pages 10-19, </pages> <month> January </month> <year> 1990. </year>
Reference-contexts: Other efficiency factors include reducing synchronization overhead and, where possible, exploiting instruction-level parallelism by having multiple parallel pipelines. Various RISC processors incorporate these and other techniques for improving overall instruction throughput and their effect on the performance of instruction pipelines has been studied in <ref> [4, 5, 6, 8, 12, 13, 14, 15, 20] </ref>. Although the idea of asynchronous design has been explored since 1950's, most digital systems are currently clocked.
Reference: [6] <author> P.K. Dubey, G.B. Adams III, and M.J. Flynn. </author> <title> Evaluating Performance Tradeoffs Between Fine-Grained and Coarse-Grained Alternatives. </title> <journal> IEEE Trans. on Parallel and Distributed Systems, </journal> <pages> pages 17-27, </pages> <month> January </month> <year> 1995. </year>
Reference-contexts: Other efficiency factors include reducing synchronization overhead and, where possible, exploiting instruction-level parallelism by having multiple parallel pipelines. Various RISC processors incorporate these and other techniques for improving overall instruction throughput and their effect on the performance of instruction pipelines has been studied in <ref> [4, 5, 6, 8, 12, 13, 14, 15, 20] </ref>. Although the idea of asynchronous design has been explored since 1950's, most digital systems are currently clocked.
Reference: [7] <author> C.J. Elston, </author> <title> D.B. Christianson, P.A. Findlay, and G.B. Steve. Hades-Towards the Asynchronous Superscalar Processor. </title> <booktitle> In 2nd Working Conference on Asynchronous Design Methodologies, </booktitle> <address> London, England, </address> <month> May </month> <year> 1995. </year>
Reference-contexts: The performance advantages associated with asynchronous design are discussed in more detail in [9, 10] At the Second Working Conference on Asynchronous Design Methodologies (1995), several additional asynchronous machine designs were proposed although the performance of these machines is still not clear <ref> [17, 1, 7] </ref>. The simulation tool ARAS is designed to help evaluated the performance of alternative asynchronous architectures. Thus, evaluations can be obtained prior to implementing the real machine. Section 2 below presents an overview of the ARAS simulator and how it is used.
Reference: [8] <author> Fawcett. </author> <title> Maximal Clocking Rates for Pipelined Digital Systems. </title> <type> Master's thesis, </type> <institution> EE, UI-UC, </institution> <year> 1975. </year>
Reference-contexts: Other efficiency factors include reducing synchronization overhead and, where possible, exploiting instruction-level parallelism by having multiple parallel pipelines. Various RISC processors incorporate these and other techniques for improving overall instruction throughput and their effect on the performance of instruction pipelines has been studied in <ref> [4, 5, 6, 8, 12, 13, 14, 15, 20] </ref>. Although the idea of asynchronous design has been explored since 1950's, most digital systems are currently clocked.
Reference: [9] <author> M.A. Franklin and T. Pan. </author> <title> Clocked and Asynchronous Instruction Pipelines. </title> <booktitle> In Proc. 26th ACM/IEEE Symp. on Microarchitecture, </booktitle> <pages> pages 177-184, </pages> <address> Austin, TX, </address> <month> December </month> <year> 1993. </year>
Reference-contexts: Researchers have therefore been studying the benefits resulting from using asynchronous design techniques in microprocessors. With such techniques there is no clock skew, there is the potential for lower power levels, and there is the possibility of an increase in the overall instruction throughput <ref> [9, 10] </ref>. Consider the synchronous (clocked) DLX instruction pipeline of Figure 1. After an instruction has finished its operation in the current block, it enters its successor block under the control of a global clock. <p> Later, an asynchronous version of the ARM processor, AMULET1, was built at University of Manchester (UK) [11]. Currently, SUN Microsystems Inc. is developing an asynchronous microprocessor called the CounterFlow Pipeline Processor (CFPP) [19]. The performance advantages associated with asynchronous design are discussed in more detail in <ref> [9, 10] </ref> At the Second Working Conference on Asynchronous Design Methodologies (1995), several additional asynchronous machine designs were proposed although the performance of these machines is still not clear [17, 1, 7]. The simulation tool ARAS is designed to help evaluated the performance of alternative asynchronous architectures.
Reference: [10] <author> M.A. Franklin and T. Pan. </author> <title> Performance Comparison of Asynchronous Adders. </title> <booktitle> In Proc. Symp. on Advanced Research in Asynchronous Circuits and Systems, </booktitle> <address> Salt Lake City, Utah, </address> <month> November </month> <year> 1994. </year>
Reference-contexts: Researchers have therefore been studying the benefits resulting from using asynchronous design techniques in microprocessors. With such techniques there is no clock skew, there is the potential for lower power levels, and there is the possibility of an increase in the overall instruction throughput <ref> [9, 10] </ref>. Consider the synchronous (clocked) DLX instruction pipeline of Figure 1. After an instruction has finished its operation in the current block, it enters its successor block under the control of a global clock. <p> Later, an asynchronous version of the ARM processor, AMULET1, was built at University of Manchester (UK) [11]. Currently, SUN Microsystems Inc. is developing an asynchronous microprocessor called the CounterFlow Pipeline Processor (CFPP) [19]. The performance advantages associated with asynchronous design are discussed in more detail in <ref> [9, 10] </ref> At the Second Working Conference on Asynchronous Design Methodologies (1995), several additional asynchronous machine designs were proposed although the performance of these machines is still not clear [17, 1, 7]. The simulation tool ARAS is designed to help evaluated the performance of alternative asynchronous architectures. <p> To enable this, the simulator has been designed to handle control hazards resulting from branching instructions. The configuration files include three files specifying the structure of simulated pipeline models and a file (Table 1) denoting operation delays and other parameters of the pipeline. ARAS also supports two asynchronous adders <ref> [10] </ref>, the Ripple-Carry Adder (RCA) and the carry-SELect adder (SEL), with the parameter NUM BLKS used to specify the number of the blocks used to implement SEL. The ARAS simulator can also simulate a clocked instruction pipeline if CLOCK MODE is selected.
Reference: [11] <editor> S.B. Furber, P. Day, J.D. Garside, N.C. Paver, and J.V. Woods. A Micropipelined ARM. </editor> <booktitle> In Int'l Conf. on Very Large Scale Integration (VLSI'93), </booktitle> <month> September </month> <year> 1993. </year>
Reference-contexts: Louis [3]; however, an entire asynchronous microprocessor was not 3 developed until 1988 at the California Institute of Technology [16]. Later, an asynchronous version of the ARM processor, AMULET1, was built at University of Manchester (UK) <ref> [11] </ref>. Currently, SUN Microsystems Inc. is developing an asynchronous microprocessor called the CounterFlow Pipeline Processor (CFPP) [19].
Reference: [12] <author> T.G. Hallin and M.J. Flynn. </author> <title> Pipelining of Arithmetic Functions. </title> <journal> IEEE Trans. Computers, </journal> <pages> pages 880-886, </pages> <month> August </month> <year> 1972. </year>
Reference-contexts: Other efficiency factors include reducing synchronization overhead and, where possible, exploiting instruction-level parallelism by having multiple parallel pipelines. Various RISC processors incorporate these and other techniques for improving overall instruction throughput and their effect on the performance of instruction pipelines has been studied in <ref> [4, 5, 6, 8, 12, 13, 14, 15, 20] </ref>. Although the idea of asynchronous design has been explored since 1950's, most digital systems are currently clocked.
Reference: [13] <author> J.L. Hennessy and D.A. Patterson. </author> <title> Computer Architecture: A Quantitative Approach. </title> <publisher> Morgan Kaufmann Publishers, </publisher> <address> Palo Alto, CA, </address> <year> 1995. </year>
Reference-contexts: To achieve higher performance most contemporary computers use instruction pipelining techniques. By employing pipelining techniques, a computer can overlap the execution of several instructions and obtain higher throughput. For example, Figure 1 shows the high level view of the DLX <ref> [13, 18] </ref> instruction pipeline. The standard DLX instruction pipeline consists of five stages; Instruction Fetch (IF), Instruction Decode (ID), Execution (EX), Memory Access (MA), and Write Back (WB). <p> Other efficiency factors include reducing synchronization overhead and, where possible, exploiting instruction-level parallelism by having multiple parallel pipelines. Various RISC processors incorporate these and other techniques for improving overall instruction throughput and their effect on the performance of instruction pipelines has been studied in <ref> [4, 5, 6, 8, 12, 13, 14, 15, 20] </ref>. Although the idea of asynchronous design has been explored since 1950's, most digital systems are currently clocked. <p> The benchmark programs can be selected either from a library, or can be user supplied. As the simulation progresses results are displayed dynamically using the X-Window system and overall performance statistics are also presented. As an example, consider the five stage DLX <ref> [13, 18] </ref> instruction pipeline shown in Figure 4. Each rectangle in the display represents a pipeline block or stage. Each block executes a set of associated micro-operations which have been set by the user to reflect operations which should take place in that stage. <p> To make sure every model (more complex pipeline configurations than shown in the example can be constructed) can be simulated properly, a standard score-boarding technique <ref> [13] </ref> is used to prevent data hazards. The handshaking protocol automatically prevents resource hazards. While the simulator schedules the instruction and its micro-operations in the proper sequence, out-of 6 order execution is permitted after the Instruction Decode block.
Reference: [14] <author> P.M. Kogge. </author> <title> The Architecture of Pipelined Computers. </title> <publisher> Hemisphere Publishing Corporation, </publisher> <address> New York, NY, </address> <year> 1981. </year>
Reference-contexts: Other efficiency factors include reducing synchronization overhead and, where possible, exploiting instruction-level parallelism by having multiple parallel pipelines. Various RISC processors incorporate these and other techniques for improving overall instruction throughput and their effect on the performance of instruction pipelines has been studied in <ref> [4, 5, 6, 8, 12, 13, 14, 15, 20] </ref>. Although the idea of asynchronous design has been explored since 1950's, most digital systems are currently clocked.
Reference: [15] <author> S.R. Kunkel and J.E. Smith. </author> <title> Optimal Pipelining in Supercomputers. </title> <booktitle> In 13th Inter. Symp. Comput. Arch., </booktitle> <pages> pages 404-411, </pages> <address> Tokyo, Japan, </address> <month> June </month> <year> 1986. </year>
Reference-contexts: Other efficiency factors include reducing synchronization overhead and, where possible, exploiting instruction-level parallelism by having multiple parallel pipelines. Various RISC processors incorporate these and other techniques for improving overall instruction throughput and their effect on the performance of instruction pipelines has been studied in <ref> [4, 5, 6, 8, 12, 13, 14, 15, 20] </ref>. Although the idea of asynchronous design has been explored since 1950's, most digital systems are currently clocked.
Reference: [16] <author> A.J. Martin, S.M. Burns, T.K. Lee, D. Borkovic, and P.J. Hazewindus. </author> <title> The Design of an Asynchronous Microprocessor. </title> <booktitle> In Proc. Decennial Caltech Conf. on VLSI, </booktitle> <pages> pages 20-22. </pages> <publisher> The MIT Press, </publisher> <month> March </month> <year> 1989. </year>
Reference-contexts: The use of asynchronous modules in the design of processors goes back to the 1960's with work at Washington University in St. Louis [3]; however, an entire asynchronous microprocessor was not 3 developed until 1988 at the California Institute of Technology <ref> [16] </ref>. Later, an asynchronous version of the ARM processor, AMULET1, was built at University of Manchester (UK) [11]. Currently, SUN Microsystems Inc. is developing an asynchronous microprocessor called the CounterFlow Pipeline Processor (CFPP) [19].
Reference: [17] <author> S.V. Morton, S.S. Appleton, and M.J. Liebelt. ECSTAC: </author> <title> A Fast Asynchronous Microprocessor. </title> <booktitle> In 2nd Working Conference on Asynchronous Design Methodologies, </booktitle> <address> London, England, </address> <month> May </month> <year> 1995. </year>
Reference-contexts: The performance advantages associated with asynchronous design are discussed in more detail in [9, 10] At the Second Working Conference on Asynchronous Design Methodologies (1995), several additional asynchronous machine designs were proposed although the performance of these machines is still not clear <ref> [17, 1, 7] </ref>. The simulation tool ARAS is designed to help evaluated the performance of alternative asynchronous architectures. Thus, evaluations can be obtained prior to implementing the real machine. Section 2 below presents an overview of the ARAS simulator and how it is used.
Reference: [18] <author> Philip M. Sailer and David R. Kaeli. </author> <title> The DLX Instruction Set Architecture Handbook. </title> <publisher> Morgan Kaufmann Publishers, </publisher> <address> Palo Alto, CA, </address> <year> 1996. </year>
Reference-contexts: To achieve higher performance most contemporary computers use instruction pipelining techniques. By employing pipelining techniques, a computer can overlap the execution of several instructions and obtain higher throughput. For example, Figure 1 shows the high level view of the DLX <ref> [13, 18] </ref> instruction pipeline. The standard DLX instruction pipeline consists of five stages; Instruction Fetch (IF), Instruction Decode (ID), Execution (EX), Memory Access (MA), and Write Back (WB). <p> The benchmark programs can be selected either from a library, or can be user supplied. As the simulation progresses results are displayed dynamically using the X-Window system and overall performance statistics are also presented. As an example, consider the five stage DLX <ref> [13, 18] </ref> instruction pipeline shown in Figure 4. Each rectangle in the display represents a pipeline block or stage. Each block executes a set of associated micro-operations which have been set by the user to reflect operations which should take place in that stage.
Reference: [19] <author> R.F. Sproull, I.E. Sutherland, and C.E. Molnar. </author> <title> Counterflow Pipeline Processor Architecture. </title> <booktitle> IEEE Design and Test of Computers, </booktitle> <month> Fall </month> <year> 1994. </year>
Reference-contexts: Later, an asynchronous version of the ARM processor, AMULET1, was built at University of Manchester (UK) [11]. Currently, SUN Microsystems Inc. is developing an asynchronous microprocessor called the CounterFlow Pipeline Processor (CFPP) <ref> [19] </ref>. The performance advantages associated with asynchronous design are discussed in more detail in [9, 10] At the Second Working Conference on Asynchronous Design Methodologies (1995), several additional asynchronous machine designs were proposed although the performance of these machines is still not clear [17, 1, 7].

References-found: 19

