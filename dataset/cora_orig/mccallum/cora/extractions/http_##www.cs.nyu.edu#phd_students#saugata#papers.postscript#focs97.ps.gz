URL: http://www.cs.nyu.edu/phd_students/saugata/papers.postscript/focs97.ps.gz
Refering-URL: http://www.cs.nyu.edu/phd_students/saugata/index.html
Root-URL: http://www.cs.nyu.edu
Email: saugata@watson.ibm.com  
Title: An Improved Algorithm for Quantifier Elimination Over Real Closed Fields  
Author: Saugata Basu 
Address: Yorktown Heights, NY, 10598  
Affiliation: Mathematical Sciences Department IBM T.J.Watson Research Center  
Abstract: In this paper we give a new algorithm for quantifier elimination in the first order theory of real closed fields that improves the complexity of the best known algorithm for this problem till now. Unlike previously known algorithms [3, 25, 20] the combinatorial part of the complexity of this new algorithm is independent of the number of free variables. Moreover, under the assumption that each polynomial in the input depend only on a constant number of the free variables, the algebraic part of the complexity can also be made independent of the number of free variables. This new feature of our algorithm allows us to obtain a new algorithm for a variant of the quantifier elimination problem. We give an almost optimal algorithm for this new problem, which we call the uniform quantifier elimination problem and apply it to solve a problem arising in the field of constraint databases. No algorithm with reasonable complexity bound was known for this latter problem till now. We also point out interesting logical consequences of this algorithmic result, concerning the expressive power of a constraint query language over the reals. Moreover, our improved algorithm for performing quantifier elimination immediately leads to improved algorithms for several problems for which quantifier elimination is a basic step, for example, the problem of computing the closure of a given semi-algebraic set. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P.K. Agarwal, J. </author> <title> Matousek On range searching with semi-algebraic sets, </title> <booktitle> Discrete and Computational Geometry 11 </booktitle> <month> 393-418 </month> <year> (1994). </year>
Reference-contexts: Research at MSRI is supported in part by NSF grant DMS-9022140. We are also given a first-order formula of the form (Q ! X [!] ) : : : (Q 1 X <ref> [1] </ref> )F (P 1 ; : : : ; P s ) (henceforth denoted (Y )) where Q i 2 f8; 9g; Q i 6= Q i+1 , Y = (Y 1 ; : : : ; Y ` ) is a block of ` free variables, X [i] is a <p> [i] is a block of k i variables with P 1i! k i = k; and F (P 1 ; : : : ; P s ) is a quantifier-free Boolean formula with atomic predicates of the form sign (P i (Y; X [!] ; : : : ; X <ref> [1] </ref> )) = where 2 f0; 1; 1g; The quantifier elimination problem is to construct a quantifier-free Boolean formula, (Y ), such that for any y 2 R ` ; (y) is true if and only if (y) is true. <p> Recently however, there have been efforts to generalize computational geometry algorithms to problems where the constraints are low degree polynomials, not just linear ones (see, for example, <ref> [1, 27, 21, 22] </ref> and also the survey by Chazelle [8]). From this point of view it makes sense to separate out the roles of the parameters s and d in the complex ity analysis of algorithms in semi-algebraic geometry. <p> fP 1 ; : : : ; P s g; be a set of s polynomials each of degree at most d, in k + ` variables, with coefficients in a real closed field R and (Y ) = (Q ! X [!] ) : : : (Q 1 X <ref> [1] </ref> )F (P 1 ; : : : ; P s ); a first-order formula, where Q i 2 f8; 9g; Q i 6= Q i+1 , Y = (Y 1 ; : : : ; Y ` ) is a block of ` free variables, X [i] is a block <p> is a block of ` free variables, X [i] is a block of k i variables, P F (P 1 ; : : : ; P s ) is a quantifier-free Boolean formula with atomic predicates of the form P i (Y; X [!] ; : : : ; X <ref> [1] </ref> ) f&lt; ; &gt;; =g 0: Moreover, let every polynomial in P depend on at most t of the Y j 's. <p> n (T 1 ; : : : ; T l ; Y 1 ; : : : ; Y n ) = 1k 1 n : : : Q ! Let the number of different (l+!)-variate polynomials appearing in be s and let their degrees be bounded by d: T <ref> [1] </ref> ; : : : ; T [m] be a partition of the variables, T 1 ; : : : ; T l into m blocks of size l 1 ; : : : ; l m ; where P Then, there exists an algorithm that outputs a quantifier-free first order <p> We have the following theorem which is an easy consequence of theorem 2. Theorem 3 Let = (Q 1 X <ref> [1] </ref> ) : : : (Q ! X [!] ) (X [1] : : : ; X [!] ); be a query with natural domain semantics, where each Q i 2 f9; 8g; and is an L 0 -formula. <p> We have the following theorem which is an easy consequence of theorem 2. Theorem 3 Let = (Q 1 X <ref> [1] </ref> ) : : : (Q ! X [!] ) (X [1] : : : ; X [!] ); be a query with natural domain semantics, where each Q i 2 f9; 8g; and is an L 0 -formula. <p> For ease of exposition we first consider the case of eliminating a single block of existential quantifiers. The main idea is already present in this simple situation. 4.1 Case of a Single Block We follow the notation in theorem 1. Note that in this case, ! = 1; X <ref> [1] </ref> = (X 1 ; : : : ; X k ) and we can assume without loss of generality, Q 1 = 9: Consider the polynomials P 1 ; : : : ; P s as polynomials in X 1 ; : : : ; X k with parameters Y <p> ; : : : ; P s g be a set of s polynomials in k variables (X 1 ; : : : ; X k ), and let denote the partition of the set of variables (X 1 ; : : : ; X k ) into blocks, X <ref> [1] </ref> ; : : : ; X [!] , where the block X [i] is of size k i ; 1 i !. For x [!] 2 R k ! ; : : : ; x [1] 2 R k 1 ; let SIGN ;0 (P)(x [!] ; : : : <p> variables (X 1 ; : : : ; X k ) into blocks, X <ref> [1] </ref> ; : : : ; X [!] , where the block X [i] is of size k i ; 1 i !. For x [!] 2 R k ! ; : : : ; x [1] 2 R k 1 ; let SIGN ;0 (P)(x [!] ; : : : ; x [1] ) = (sign (P 1 (x [!] ; : : : ; x [1] )); : : : ; sign (P s (x [!] ; : : : ; x [1] ))): For <p> For x [!] 2 R k ! ; : : : ; x <ref> [1] </ref> 2 R k 1 ; let SIGN ;0 (P)(x [!] ; : : : ; x [1] ) = (sign (P 1 (x [!] ; : : : ; x [1] )); : : : ; sign (P s (x [!] ; : : : ; x [1] ))): For x [i+1] 2 R k i+1 ; : : : ; x [!] 2 R k ! <p> For x [!] 2 R k ! ; : : : ; x <ref> [1] </ref> 2 R k 1 ; let SIGN ;0 (P)(x [!] ; : : : ; x [1] ) = (sign (P 1 (x [!] ; : : : ; x [1] )); : : : ; sign (P s (x [!] ; : : : ; x [1] ))): For x [i+1] 2 R k i+1 ; : : : ; x [!] 2 R k ! , and for all i, 0 &lt; i !, we recursively define, SIGN ;i <p> ; x <ref> [1] </ref> 2 R k 1 ; let SIGN ;0 (P)(x [!] ; : : : ; x [1] ) = (sign (P 1 (x [!] ; : : : ; x [1] )); : : : ; sign (P s (x [!] ; : : : ; x [1] ))): For x [i+1] 2 R k i+1 ; : : : ; x [!] 2 R k ! , and for all i, 0 &lt; i !, we recursively define, SIGN ;i (P)(x [!] ; : : : ; x [i+1] ) = fSIGN ;i1 (P)(x [!] ; : <p> : ; x [i+1] ; x [i] )jx [i] 2 R k i g: Finally, we define SIGN (P) = SIGN ;! (P): It is easy to decide the truth or falsity of the formula, Q ! (X [!] )Q !1 (X [!1] ) : : : Q 1 (X <ref> [1] </ref> )F (P 1 ; : : : ; P s ); from the set SIGN (P) which we call the total list of signs of P = (P 1 ; : : : ; P s ) with respect to the partition of the variables, into the blocks, (X [!] <p> : ; P s ); from the set SIGN (P) which we call the total list of signs of P = (P 1 ; : : : ; P s ) with respect to the partition of the variables, into the blocks, (X [!] ; : : : ; X <ref> [1] </ref> ). Note that the set SIGN (P) is a set of nested sets, where the nesting is of depth !. When there is only one block of variables, we denote it by SIGN (P). <p> The input is a set of s polynomials, P = fP 1 ; : : : ; P s g D [X 1 ; : : : ; X k ], and a partition, ; of the variables into ! blocks, X <ref> [1] </ref> ; : : : ; X [!] . We denote by X [i] the variables (X [!] ; : : : ; X [i] ). There are ! stages in the Elimination Phase, one for each block of variables. <p> i we define the associated triangular system and the associated list of polynomials, T u and P u , as follows: Let [i] g k i+1 ( X [i+1] ; i ; ffi i ; t i )): For a polynomial P (X [!] ; : : : ; X <ref> [1] </ref> ), let P u (t 1 ; : : : ; t ! ) denote the polynomial obtained by successively replacing the blocks of variables X [i] , with the rational fractions associated with the tuple u i . <p> Define T u [i] (t ! ; : : : ; t i ) = f [i] T u = (T u [!1] (t ! ; t !1 ); ; <ref> [1] </ref> (t ! ; t !1 ; : : : ; t 1 )); Let Z u be the set fff 2 Rh1= 1 ; ffi 1 ; : : : ; 1= ! ; ffi ! i ! j ff a zero of T u g: We define Z and
Reference: [2] <author> S. </author> <title> Basu Uniform Quantifier Elimination and Constraint Query Processing, </title> <booktitle> Proc. International Symposium on Symbolic and Algebraic Computation, </booktitle> <year> 1997, </year> <pages> 21-27. </pages>
Reference-contexts: set is given by a single sign condition the length of the quantifier free formula output is s 2 (k+1) d O (k 2 ) : 2 Our technique is a basic ingredient in a new algorithm for solving a variant of the quantifier elimination problem which was introduced in <ref> [2] </ref> motivated by a problem in constraint databases. 2.2 Uniform Quantifier Elimination We call a sequence, f n (T 1 ; : : : ; T l ; Y 1 ; : : : ; Y n ) j n &gt; 0g of first-order formulas n in the language of ordered <p> Using our new technique it is possible to eliminate quantifiers from a uniform sequence of formulas and obtain another uniform sequence of quantifier free formulas. We call this procedure uniform quantifier elimination. We have the following theorem (announced without proof in <ref> [2] </ref>). <p> i +1) d ! i O (l 2 i ) ; and the size of the formula is s i (l i +1) d ! i O (l 2 2.3 Application to Constraint Databases We now describe the application of uniform quantifier elimination to the theory of constraint databases (see <ref> [2] </ref> for further details). In recent years, constraint databases, first introduced by Kanellakis, Kuper and Revesz [24] has attracted a lot of attention. Unlike traditional databases which are finite collections of data items, constraint databases permit infinite collections of items to be stored in the database. <p> Using the equivalence of natural domain and active domain semantics, a simpler and elementary proof of the parity conjecture was given in <ref> [2] </ref>. In fact it turns out that the properties of finite sets that are not definable over h!; i; that is over natural numbers with order but no arithmetic, are also not definable over the reals. Thus having arithmetic adds no extra expressive power over having only inequalities. <p> Thus having arithmetic adds no extra expressive power over having only inequalities. In this paper we modify slightly the proof appearing in <ref> [2] </ref> to prove this more general result.
Reference: [3] <author> S. Basu, R. Pollack, M.-F. </author> <title> Roy On the Combinatorial and Algebraic Complexity of Quantifier Elimination , Journal of the ACM, </title> <journal> Nov 1996, </journal> <volume> Vol. 43, Number 6, </volume> <pages> 1002-1045. </pages> <booktitle> (Extended Abstract in Proc. 35th Symposium on Foundations of Computer Science, </booktitle> <year> (1994).) </year>
Reference-contexts: All the computations of our algorithms take place in D. We define the complexity of our algorithms to be the number of arithmetic operations (additions, multiplications and sign determinations) in the ring D. Note that this ignores the cost of reading the input or writing the output formula (see <ref> [3] </ref>, section 1.3, page 1004, for further details). 1.2 History The existence of an algorithm for quantifier elimination was first proved by Tarski [28] (see also [26]). However, the complexity of his algorithm is not elementary recursive. <p> Heintz, Roy and Solerno [20] and Renegar [25] gave quantifier elimination algorithms which were doubly exponential only in the number of quantifier alternations. See also [30] for the lower bound proof. The best algorithm for this problem till now appeared in <ref> [3] </ref>, which has a complexity of s (`+1)(k i +1) d (`+1)O (k i ) : Moreover, the degrees of the polynomials appear-ing in the output formula are bounded by d i O (k i ) . <p> The classical algorithm for projecting semi-linear sets is the Fourier-Motzhkin algorithm (see [31] page 35) which requires s 2 arithmetic operations. However, if we use the general quantifier elimination algorithm in <ref> [3] </ref> in this special case, the complexity is easily seen to be s 2k d O (k) : Thus, the dependence on s is very far from optimal, and this is due to the fact that the exponent of s in the complexity depends on the number of free variables, `: <p> Of course, the caveat is that if the input itself is very large, the output formula by the new algorithm will be large too, while in the case of the algorithm in <ref> [3] </ref> the size of the output is bounded independent of the size of the input formula. The improvement in the combinatorial complexity immediately gives improved algorithm for certain problems where quantifier elimination is the basic step. <p> Using the algorithm in <ref> [3] </ref> the complexity is, s 2 (k+1)(k+1) d O (k 2 ) : Moreover, even if the original set is defined by a single sign condition, (say) P 1 0; : : : ; P s 0; the quantifier-free formula is of size s 2 (k+1)(k+1) d O (k 2 ) <p> We refer the reader to <ref> [3] </ref> for a detailed description of these subroutines. <p> We denote by Rh*i the field of Puiseux series in * with coefficients in R: We refer the reader to <ref> [3] </ref> (section 2.1, page 1008) for further details. 3.2 Parametrized Sample Points Subrou tine (For more details see [3], section 5.1.3, page 1036) The input is a set of s polynomials P = fP 1 ; : : : ; P s g R [Y 1 ; : : : ; <p> We denote by Rh*i the field of Puiseux series in * with coefficients in R: We refer the reader to <ref> [3] </ref> (section 2.1, page 1008) for further details. 3.2 Parametrized Sample Points Subrou tine (For more details see [3], section 5.1.3, page 1036) The input is a set of s polynomials P = fP 1 ; : : : ; P s g R [Y 1 ; : : : ; Y ` ][X 1 ; : : : ; X k ]; each of degree at most d: <p> The complexity is s k d O (`k+k) . 3.3 Block Elimination Subroutine (For more details see <ref> [3] </ref>, section 5.2, page 1037) The input is again set of s polynomials P = fP 1 ; : : : ; P s g R [Y 1 ; : : : ; Y ` ][X 1 ; : : : ; X k ]; each of degree at most d: <p> Then it is clear that, (9X 1 ; : : : ; X k )F (Y 1 ; : : : ; Y l ; X 1 ; : : : ; X k ) 1iN 1jd O (k) We now use the algorithm for performing quantifier elimination in <ref> [3] </ref> to independently remove the s k+1 d O (k) quantifiers on the right hand side, thus obtaining a quantifier-free formula equivalent to (9X 1 ; : : : ; X k )F (Y 1 ; : : : ; Y l ; X 1 ; : : : ; X <p> d O (l 0 k) : The dependence of the size of the output on the size of the input is also clear. 4.2 The Case of Many Blocks In the description of the algorithm we borrow heavily from the description of the algorithm for the general decision problem in <ref> [3] </ref> (section 5.3, page 1038). We also follow the notation used there. We use the first two phases of the algorithm for the general decision problem in [3] (section 5.3, page 1038), namely the Elimination Phase and the Substitution Phase. We first recall a definition which appears in [3] (section 1.3, <p> Many Blocks In the description of the algorithm we borrow heavily from the description of the algorithm for the general decision problem in <ref> [3] </ref> (section 5.3, page 1038). We also follow the notation used there. We use the first two phases of the algorithm for the general decision problem in [3] (section 5.3, page 1038), namely the Elimination Phase and the Substitution Phase. We first recall a definition which appears in [3] (section 1.3, page 1006). <p> problem in <ref> [3] </ref> (section 5.3, page 1038). We also follow the notation used there. We use the first two phases of the algorithm for the general decision problem in [3] (section 5.3, page 1038), namely the Elimination Phase and the Substitution Phase. We first recall a definition which appears in [3] (section 1.3, page 1006).
Reference: [4] <author> M. Benedikt, G. Dong, L. Libkin, L. </author> <title> Wong Relational Expressive Power of Constraint Query Languages, </title> <booktitle> Proc. of 15th ACM Symposium on Principles of Database Systems, </booktitle> <year> (1996). </year>
Reference-contexts: We apply our algorithmic result on uniform quanti-fier elimination to give an algorithm that given a query with natural domain semantics, outputs another query equivalent to it with active domain semantics. The equivalence of natural and active domain semantics over real closed fields was proved in <ref> [4] </ref>, [5]. However, their proofs are essentially non-constructive and one does not obtain an effective algorithm for converting a query with the natural domain semantics into an equivalent one with active domain semantics. Very recently, in [6] an algorithm was given for this problem, but complexity issues were not considered. <p> The problem of determining the expressive power of constraint queries has spurred a lot of research leading to several interesting inexpressibility results for constraint queries over various structures <ref> [16, 15, 4] </ref>. The parity of the cardinality of a set and the connectivity of a finite graph are well-known examples of queries that are not definable over finite models in a first order language with equality. <p> a query (that is a first order L 0 -sentence ) such that for every finite set S &lt; with jSj even, h&lt;; Si j= and for every finite set S &lt; with jSj odd, h&lt;; Si j= : ? This was answered in the negative by Benedikt et al. <ref> [4] </ref> (see also [5, 6] who used difficult techniques from non-standard analysis and model theory of ordered structures. Using the equivalence of natural domain and active domain semantics, a simpler and elementary proof of the parity conjecture was given in [2].
Reference: [5] <author> M. Benedikt, L. </author> <title> Libkin On the Structure of Queries in Constraint Query Languages, </title> <booktitle> Proc. of 11th Annual IEEE Symposium on Logic in Computer Science, </booktitle> <year> (1996). </year>
Reference-contexts: We apply our algorithmic result on uniform quanti-fier elimination to give an algorithm that given a query with natural domain semantics, outputs another query equivalent to it with active domain semantics. The equivalence of natural and active domain semantics over real closed fields was proved in [4], <ref> [5] </ref>. However, their proofs are essentially non-constructive and one does not obtain an effective algorithm for converting a query with the natural domain semantics into an equivalent one with active domain semantics. Very recently, in [6] an algorithm was given for this problem, but complexity issues were not considered. <p> Thus, we have a uniform algorithm to evaluate such a query independent of the set S: This will allow, for example, compile time query optimization that is possible in a classical database setting <ref> [5] </ref>. We have the following theorem which is an easy consequence of theorem 2. <p> is a first order L 0 -sentence ) such that for every finite set S &lt; with jSj even, h&lt;; Si j= and for every finite set S &lt; with jSj odd, h&lt;; Si j= : ? This was answered in the negative by Benedikt et al. [4] (see also <ref> [5, 6] </ref> who used difficult techniques from non-standard analysis and model theory of ordered structures. Using the equivalence of natural domain and active domain semantics, a simpler and elementary proof of the parity conjecture was given in [2]. <p> Thus having arithmetic adds no extra expressive power over having only inequalities. In this paper we modify slightly the proof appearing in [2] to prove this more general result. We note that this result is already implied in the work of Benedikt et al. <ref> [5, 6] </ref> but our proof is constructive and simpler. 3 Algorithmic Preliminaries 3.1 Thom Encodings and Univariate Rep resentations We give a few definitions, recall Thom's theorem, and describe the inputs, outputs and complexities of some subroutines that we will use in our algorithm.
Reference: [6] <author> M. Benedikt and L. </author> <title> Libkin Relational Languages over Interpreted Structure, Proceedings of PODS, </title> <note> (1997) (to appear). </note>
Reference-contexts: However, their proofs are essentially non-constructive and one does not obtain an effective algorithm for converting a query with the natural domain semantics into an equivalent one with active domain semantics. Very recently, in <ref> [6] </ref> an algorithm was given for this problem, but complexity issues were not considered. The advantage of having a query with active domain semantics over a finite database is clear. <p> is a first order L 0 -sentence ) such that for every finite set S &lt; with jSj even, h&lt;; Si j= and for every finite set S &lt; with jSj odd, h&lt;; Si j= : ? This was answered in the negative by Benedikt et al. [4] (see also <ref> [5, 6] </ref> who used difficult techniques from non-standard analysis and model theory of ordered structures. Using the equivalence of natural domain and active domain semantics, a simpler and elementary proof of the parity conjecture was given in [2]. <p> Thus having arithmetic adds no extra expressive power over having only inequalities. In this paper we modify slightly the proof appearing in [2] to prove this more general result. We note that this result is already implied in the work of Benedikt et al. <ref> [5, 6] </ref> but our proof is constructive and simpler. 3 Algorithmic Preliminaries 3.1 Thom Encodings and Univariate Rep resentations We give a few definitions, recall Thom's theorem, and describe the inputs, outputs and complexities of some subroutines that we will use in our algorithm.
Reference: [7] <author> J. Bochnak, M. Coste, M.-F. Roy Geometrie algebrique reelle. </author> <month> Springer-Verlag </month> <year> (1987). </year>
Reference-contexts: reals) and for every i; Rh 1 ih 2 i : : : h i i is the field of Puiseux series in 1 i with coefficients in Rh 1 ih 2 i : : : h i1 i: It is well known that the resulting field is real closed <ref> [7] </ref>.
Reference: [8] <author> B. </author> <title> Chazelle Computational Geometry: A Retrospective, </title> <booktitle> Proc. 26th ACM Symp. on Theory of Computing, </booktitle> <pages> 75-94, </pages> <year> (1994). </year>
Reference-contexts: Recently however, there have been efforts to generalize computational geometry algorithms to problems where the constraints are low degree polynomials, not just linear ones (see, for example, [1, 27, 21, 22] and also the survey by Chazelle <ref> [8] </ref>). From this point of view it makes sense to separate out the roles of the parameters s and d in the complex ity analysis of algorithms in semi-algebraic geometry.
Reference: [9] <author> G. E. Collins, </author> <title> Quantifier elimination for real closed fields by cylindrical algebraic decomposition, </title> <booktitle> Springer Lecture Notes in Computer Science 33, </booktitle> <pages> 515-532. </pages>
Reference-contexts: However, the complexity of his algorithm is not elementary recursive. The first algorithm with a reasonable worst-case time bound was given by Collins <ref> [9] </ref>. His algorithm had a worst case running time doubly exponential in the number of variables. Heintz, Roy and Solerno [20] and Renegar [25] gave quantifier elimination algorithms which were doubly exponential only in the number of quantifier alternations. See also [30] for the lower bound proof.
Reference: [10] <author> M. Coste, M.-.F Roy Thom's lemma, </author> <title> the coding of real algebraic numbers and the topology of semi-algebraic sets. </title> <journal> J. </journal> <note> of Symbolic Computation 5 121-129 (1988). </note>
Reference-contexts: For x 2 R and f 2 R [X] we write x;f for the sign vector (sign (f (0) (x)); sign (f (1) (x)); : : : ; sign (f (deg (f)) (x): It is a consequence of Thom's lemma ([7], <ref> [10] </ref>) that if f (x) = 0 then x;f distinguishes x from all the other roots of f and if x;f 6= y;f then these two sign vectors easily enable us to determine whether x &lt; y or y &lt; x.
Reference: [11] <author> A. </author> <title> Ehrenfeucht An application of games to the completeness problem for formalized theories, </title> <journal> Fund. Math, </journal> <volume> 49, </volume> <year> 1961. </year>
Reference-contexts: Their undefinability has been shown using different proof techniques such as locality [14], 0/1 laws [12, 13], Ehrenfeucht-Fraisse games <ref> [11] </ref>. These undefinability results also hold in the presence of an order relation [19]. Grumbach and Su [15] proved that parity is not definable over constraint databases with linear con straints.
Reference: [12] <author> R. </author> <title> Fagin Probabilities on finite models, </title> <journal> Journal of Symbolic Logic, </journal> <volume> 41(1) </volume> <pages> 50-58, </pages> <year> 1976. </year>
Reference-contexts: The parity of the cardinality of a set and the connectivity of a finite graph are well-known examples of queries that are not definable over finite models in a first order language with equality. Their undefinability has been shown using different proof techniques such as locality [14], 0/1 laws <ref> [12, 13] </ref>, Ehrenfeucht-Fraisse games [11]. These undefinability results also hold in the presence of an order relation [19]. Grumbach and Su [15] proved that parity is not definable over constraint databases with linear con straints.
Reference: [13] <author> R. </author> <title> Fagin Finite model theory a personal perspective, </title> <booktitle> Theoretical Computer Science, </booktitle> <pages> 116(1)3-31, </pages> <year> 1993. </year>
Reference-contexts: The parity of the cardinality of a set and the connectivity of a finite graph are well-known examples of queries that are not definable over finite models in a first order language with equality. Their undefinability has been shown using different proof techniques such as locality [14], 0/1 laws <ref> [12, 13] </ref>, Ehrenfeucht-Fraisse games [11]. These undefinability results also hold in the presence of an order relation [19]. Grumbach and Su [15] proved that parity is not definable over constraint databases with linear con straints.
Reference: [14] <author> H. </author> <title> Gaifman On local and non-local properties, </title> <booktitle> Proc. Herbrand Symposium Logic Colloquium, </booktitle> <pages> 105-35, </pages> <publisher> North Holland, </publisher> <year> 1981. </year>
Reference-contexts: The parity of the cardinality of a set and the connectivity of a finite graph are well-known examples of queries that are not definable over finite models in a first order language with equality. Their undefinability has been shown using different proof techniques such as locality <ref> [14] </ref>, 0/1 laws [12, 13], Ehrenfeucht-Fraisse games [11]. These undefinability results also hold in the presence of an order relation [19]. Grumbach and Su [15] proved that parity is not definable over constraint databases with linear con straints.
Reference: [15] <author> S. Grumbach, J. </author> <title> Su Queries with Arithmetical Constraints, </title> <booktitle> Proc. of Int. Conf. on Principles and Practice of Constraint Programming, </booktitle> <year> (1995). </year>
Reference-contexts: Unlike traditional databases which are finite collections of data items, constraint databases permit infinite collections of items to be stored in the database. They are a powerful generalization of Codd's relational model [29]. Different types of constraints have been considered by various authors <ref> [24, 23, 15] </ref> including dense linear order inequalities, real polynomial inequalities etc. Even though constraint databases permit infinite number of elements in the database, for the purposes of this paper it is enough to consider our database to be a finite set S of real numbers. <p> The problem of determining the expressive power of constraint queries has spurred a lot of research leading to several interesting inexpressibility results for constraint queries over various structures <ref> [16, 15, 4] </ref>. The parity of the cardinality of a set and the connectivity of a finite graph are well-known examples of queries that are not definable over finite models in a first order language with equality. <p> Their undefinability has been shown using different proof techniques such as locality [14], 0/1 laws [12, 13], Ehrenfeucht-Fraisse games [11]. These undefinability results also hold in the presence of an order relation [19]. Grumbach and Su <ref> [15] </ref> proved that parity is not definable over constraint databases with linear con straints. They also conjectured that parity is not definable is not definable over the reals with queries allowed to have polynomial equalities and inequalities. Let us pose this question more concretely.
Reference: [16] <author> S. Grumbach, J. </author> <title> Su Finitely Representable databases, </title> <booktitle> Proc. of 13th ACM Symposium on Principles of Database Systems, </booktitle> <year> (1994). </year>
Reference-contexts: The problem of determining the expressive power of constraint queries has spurred a lot of research leading to several interesting inexpressibility results for constraint queries over various structures <ref> [16, 15, 4] </ref>. The parity of the cardinality of a set and the connectivity of a finite graph are well-known examples of queries that are not definable over finite models in a first order language with equality.
Reference: [17] <author> S. Grumbach, J. </author> <title> Su Dense Order Constraint Databases, </title> <booktitle> Proc. of 14th ACM Symposium on Principles of Database Systems, </booktitle> <year> (1995). </year>
Reference: [18] <author> D. Grigor'ev, </author> <title> The Complexity of deciding Tarski algebra Journal of Symbolic Computation 5 (1988), </title> <type> 65-108. </type>
Reference: [19] <author> Y. </author> <title> Gurevich Logic and the challenge of computer science, </title> <booktitle> Current Trends in Theoretical Computer Science, </booktitle> <pages> 1-57, </pages> <publisher> Computer Science Press, </publisher> <year> 1988. </year>
Reference-contexts: Their undefinability has been shown using different proof techniques such as locality [14], 0/1 laws [12, 13], Ehrenfeucht-Fraisse games [11]. These undefinability results also hold in the presence of an order relation <ref> [19] </ref>. Grumbach and Su [15] proved that parity is not definable over constraint databases with linear con straints. They also conjectured that parity is not definable is not definable over the reals with queries allowed to have polynomial equalities and inequalities. Let us pose this question more concretely.
Reference: [20] <author> J. Heintz, M.-F. Roy, P. Solern o Sur la complexite du principe de Tarski-Seidenberg. </author> <title> Bull. </title> <publisher> Soc. Math. </publisher> <address> France 118 101-126 (1990). </address>
Reference-contexts: However, the complexity of his algorithm is not elementary recursive. The first algorithm with a reasonable worst-case time bound was given by Collins [9]. His algorithm had a worst case running time doubly exponential in the number of variables. Heintz, Roy and Solerno <ref> [20] </ref> and Renegar [25] gave quantifier elimination algorithms which were doubly exponential only in the number of quantifier alternations. See also [30] for the lower bound proof.
Reference: [21] <author> D. Halperin, M. </author> <title> Sharir New Bounds for Lower Envelopes in Three Dimensions, with Applications to Visibility in Terrains, </title> <booktitle> Discrete and Computational Geometry 12 </booktitle> <month> 313-326 </month> <year> (1994). </year>
Reference-contexts: Recently however, there have been efforts to generalize computational geometry algorithms to problems where the constraints are low degree polynomials, not just linear ones (see, for example, <ref> [1, 27, 21, 22] </ref> and also the survey by Chazelle [8]). From this point of view it makes sense to separate out the roles of the parameters s and d in the complex ity analysis of algorithms in semi-algebraic geometry.
Reference: [22] <author> D. Halperin, M. </author> <title> Sharir Almost Tight Upper Bounds for the Single Cell and Zone Problems in Three Dimensions, </title> <booktitle> Discrete and Computational Geometry 14 </booktitle> <month> 385-410 </month> <year> (1995). </year>
Reference-contexts: Recently however, there have been efforts to generalize computational geometry algorithms to problems where the constraints are low degree polynomials, not just linear ones (see, for example, <ref> [1, 27, 21, 22] </ref> and also the survey by Chazelle [8]). From this point of view it makes sense to separate out the roles of the parameters s and d in the complex ity analysis of algorithms in semi-algebraic geometry.
Reference: [23] <author> P. Kanellakis, D. Q. </author> <title> Goldin Constraint Programming and Database Query Languages, </title> <booktitle> Proc. 2nd Conf on Theoretical Aspects of Computer Software (TACS), </booktitle> <volume> LNCS Vol 789, </volume> <publisher> Springer-Verlag, </publisher> <year> (1994). </year>
Reference-contexts: Unlike traditional databases which are finite collections of data items, constraint databases permit infinite collections of items to be stored in the database. They are a powerful generalization of Codd's relational model [29]. Different types of constraints have been considered by various authors <ref> [24, 23, 15] </ref> including dense linear order inequalities, real polynomial inequalities etc. Even though constraint databases permit infinite number of elements in the database, for the purposes of this paper it is enough to consider our database to be a finite set S of real numbers.
Reference: [24] <author> P. Kanellakis, G. Kuper, P. </author> <title> Revesz Constraint Query Languages, </title> <booktitle> Proc. of 9th ACM Symposium on Principles of Database Systems, </booktitle> <year> (1990). </year>
Reference-contexts: In recent years, constraint databases, first introduced by Kanellakis, Kuper and Revesz <ref> [24] </ref> has attracted a lot of attention. Unlike traditional databases which are finite collections of data items, constraint databases permit infinite collections of items to be stored in the database. They are a powerful generalization of Codd's relational model [29]. <p> Unlike traditional databases which are finite collections of data items, constraint databases permit infinite collections of items to be stored in the database. They are a powerful generalization of Codd's relational model [29]. Different types of constraints have been considered by various authors <ref> [24, 23, 15] </ref> including dense linear order inequalities, real polynomial inequalities etc. Even though constraint databases permit infinite number of elements in the database, for the purposes of this paper it is enough to consider our database to be a finite set S of real numbers.
Reference: [25] <author> J. </author> <title> Renegar On the computational complexity and geometry of the first order theory of the reals, </title> <journal> J. of Symbolic Comput.13(3):255-352, </journal> <year> (1992). </year>
Reference-contexts: However, the complexity of his algorithm is not elementary recursive. The first algorithm with a reasonable worst-case time bound was given by Collins [9]. His algorithm had a worst case running time doubly exponential in the number of variables. Heintz, Roy and Solerno [20] and Renegar <ref> [25] </ref> gave quantifier elimination algorithms which were doubly exponential only in the number of quantifier alternations. See also [30] for the lower bound proof.
Reference: [26] <author> A. </author> <title> Seidenberg A new decision method for elementary algebra, </title> <journal> Annals of Mathematics, </journal> <volume> 60 </volume> <pages> 365-374, </pages> <year> (1954). </year>
Reference-contexts: Note that this ignores the cost of reading the input or writing the output formula (see [3], section 1.3, page 1004, for further details). 1.2 History The existence of an algorithm for quantifier elimination was first proved by Tarski [28] (see also <ref> [26] </ref>). However, the complexity of his algorithm is not elementary recursive. The first algorithm with a reasonable worst-case time bound was given by Collins [9]. His algorithm had a worst case running time doubly exponential in the number of variables.
Reference: [27] <author> M. </author> <title> Sharir Almost Tight Upper Bounds for Lower Envelopes in Higher Dimensions, </title> <booktitle> Discrete and Computational Geometry 12 </booktitle> <month> 327-345 </month> <year> (1994). </year>
Reference-contexts: Recently however, there have been efforts to generalize computational geometry algorithms to problems where the constraints are low degree polynomials, not just linear ones (see, for example, <ref> [1, 27, 21, 22] </ref> and also the survey by Chazelle [8]). From this point of view it makes sense to separate out the roles of the parameters s and d in the complex ity analysis of algorithms in semi-algebraic geometry.
Reference: [28] <author> A. </author> <title> Tarski A Decision method for elementary algebra and geometry, </title> <publisher> University of California Press (1951). </publisher>
Reference-contexts: Note that this ignores the cost of reading the input or writing the output formula (see [3], section 1.3, page 1004, for further details). 1.2 History The existence of an algorithm for quantifier elimination was first proved by Tarski <ref> [28] </ref> (see also [26]). However, the complexity of his algorithm is not elementary recursive. The first algorithm with a reasonable worst-case time bound was given by Collins [9]. His algorithm had a worst case running time doubly exponential in the number of variables.
Reference: [29] <author> J.D. </author> <title> Ullman Principles of Database Systems, </title> <publisher> Computer Science Press, </publisher> <year> 1983. </year>
Reference-contexts: Unlike traditional databases which are finite collections of data items, constraint databases permit infinite collections of items to be stored in the database. They are a powerful generalization of Codd's relational model <ref> [29] </ref>. Different types of constraints have been considered by various authors [24, 23, 15] including dense linear order inequalities, real polynomial inequalities etc.
Reference: [30] <author> V. </author> <title> Weispfenning The complexity of linear problems in fields, </title> <journal> Journal of Symbolic Computation 5(1988). </journal>
Reference-contexts: His algorithm had a worst case running time doubly exponential in the number of variables. Heintz, Roy and Solerno [20] and Renegar [25] gave quantifier elimination algorithms which were doubly exponential only in the number of quantifier alternations. See also <ref> [30] </ref> for the lower bound proof.
Reference: [31] <author> G.M. </author> <title> Ziegler Lectures on Polytopes Springer-Verlag, </title> <year> 1994. </year>
Reference-contexts: The classical algorithm for projecting semi-linear sets is the Fourier-Motzhkin algorithm (see <ref> [31] </ref> page 35) which requires s 2 arithmetic operations.
References-found: 31

