URL: http://www.cs.helsinki.fi/~oheinone/publications/Mining_in_the_Phrasal_Frontier_PKDD.ps.gz
Refering-URL: http://www.cs.helsinki.fi/research/rati/sid.html
Root-URL: 
Title: Mining in the Phrasal Frontier  
Author: Helena Ahonen, Oskari Heinonen, Mika Klemettinen, and A. Inkeri Verkamo 
Address: P.O. Box 26, FIN-00014 University of Helsinki, Finland  
Affiliation: University of Helsinki, Department of Computer Science  
Abstract: Data mining methods have been applied to a wide variety of domains. Surprisingly enough, only a few examples of data mining in text are available. However, considering the amount of existing document collections, text mining would be most useful. Traditionally, texts have been analysed using various information retrieval related methods and natural language processing. In this paper, we present our first experiments in applying general methods of data mining to discovering phrases and co-occurring terms. We also describe the text mining process developed. Our results show that data mining methods | with appropriate preprocessing | can be used in text processing, and that by shifting the focus the process can be used to obtain results for various purposes. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> R. Agrawal, H. Mannila, R. Srikant, H. Toivonen, and A. I. Verkamo. </author> <title> Fast discovery of association rules. </title> <booktitle> In Advances in Knowledge Discovery and Data Mining, </booktitle> <pages> pages 307-328. </pages> <publisher> AAAI Press, </publisher> <year> 1996. </year>
Reference-contexts: Let us first give a brief description of episodes and episode rules. Fig. 1. Knowledge discovery from Sgml representation into episodes and episode rules. 2.1 Episodes Episode rules and episodes are a modification of the concept of association rules and frequent sets (see, e.g., <ref> [1] </ref>), applied to sequential data. Sequential data can be seen as a sequence of events, where each event is a pair (event type, time). <p> take the episode (a) that occurs in the Chemical Act (statute #9) rather frequently then by looking at the rule (b) we can conclude that the phrase teollinen kasittely (a) 37: teollinen (A) kasittely (N) (c) 44: vesioikeus (N) paatos (N) (b) IF teollinen (A) THEN kasittely (N) WITH [0] <ref> [1] </ref> 0.0000 (0/38) [0] [2] 0.9737 (37/38) (d) IF vesioikeus (N) THEN paatos (N) WITH [0] [1] 0.0000 (0/558) [0] [2] 0.0681 (38/558) Fig. 3. <p> looking at the rule (b) we can conclude that the phrase teollinen kasittely (a) 37: teollinen (A) kasittely (N) (c) 44: vesioikeus (N) paatos (N) (b) IF teollinen (A) THEN kasittely (N) WITH [0] <ref> [1] </ref> 0.0000 (0/38) [0] [2] 0.9737 (37/38) (d) IF vesioikeus (N) THEN paatos (N) WITH [0] [1] 0.0000 (0/558) [0] [2] 0.0681 (38/558) Fig. 3.
Reference: 2. <author> D. R. Cutting, D. Karger, J. Pedersen, and J. W. Tukey. Scatter/Gather: </author> <title> A cluster-based approach to browsing large document collections. </title> <booktitle> In Proc. of the 15th Annual Int'l ACM/SIGIR Conference, </booktitle> <pages> pages 318-329, </pages> <address> Copenhagen, Denmark, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: In addition to simple queries, content descriptors can be used for various text classification tasks. For instance, documents can be clustered according to their similarity, to visualize a large document collection <ref> [2] </ref>. More elaborate ways of utilizing co-occurrent terms can be found in natural language processing techniques. A specific class of co-occurring terms are so-called collocations, i.e., recurrent combinations of words that correspond to arbitrary word usages [9]. <p> that occurs in the Chemical Act (statute #9) rather frequently then by looking at the rule (b) we can conclude that the phrase teollinen kasittely (a) 37: teollinen (A) kasittely (N) (c) 44: vesioikeus (N) paatos (N) (b) IF teollinen (A) THEN kasittely (N) WITH [0] [1] 0.0000 (0/38) [0] <ref> [2] </ref> 0.9737 (37/38) (d) IF vesioikeus (N) THEN paatos (N) WITH [0] [1] 0.0000 (0/558) [0] [2] 0.0681 (38/558) Fig. 3. <p> (b) we can conclude that the phrase teollinen kasittely (a) 37: teollinen (A) kasittely (N) (c) 44: vesioikeus (N) paatos (N) (b) IF teollinen (A) THEN kasittely (N) WITH [0] [1] 0.0000 (0/38) [0] <ref> [2] </ref> 0.9737 (37/38) (d) IF vesioikeus (N) THEN paatos (N) WITH [0] [1] 0.0000 (0/558) [0] [2] 0.0681 (38/558) Fig. 3.
Reference: 3. <author> U. M. Fayyad, G. Piatetsky-Shapiro, and P. Smyth. </author> <title> From data mining to knowledge discovery: An overview. </title> <booktitle> In Advances in Knowledge Discovery and Data Mining, </booktitle> <pages> pages 1-34. </pages> <publisher> AAAI Press, </publisher> <year> 1996. </year>
Reference-contexts: Referring to the results in different domain areas and applications, preprocessing can take as much as 80 per cent of the total effort [6]. In the context of our knowledge presentation formats, a Kdd process, adapted, e.g., from <ref> [3] </ref>, consists of (1) data preprocessing (selection, cleaning, etc.), (2) data transformation and input selection for discovery phase, (3) discovery of episodes and episode rules, (4) presentation of the results, and (5) interpretation and utilization of the results.
Reference: 4. <author> R. Feldman, I. Dagan, and W. Klosgen. </author> <title> Efficient algorithms for mining and manipulating associations in texts. </title> <journal> In Cybernetics and Systems, </journal> <volume> Vol. </volume> <booktitle> II, The 13th European Meeting on Cybernetics and Systems Research, </booktitle> <address> Vienna, Austria, </address> <month> April </month> <year> 1996. </year>
Reference-contexts: Therefore, data mining from existing document collections, including the World Wide Web, which contains large amounts of semi-structured text in Html format, would be most useful. Surprisingly enough, only a few examples of data mining in text analysis are available. The most notable are the Kdt and Fact systems <ref> [4] </ref> used in mining Reuters news articles. Their approach, however, requires a substantially large amount of background knowledge, and is not applicable as such to text analysis in general.
Reference: 5. <author> D. D. Lewis and K. Sparck Jones. </author> <title> Natural language processing for information retrieval. </title> <journal> CACM, </journal> <volume> 39(1) </volume> <pages> 92-101, </pages> <year> 1996. </year>
Reference-contexts: We thank Hannu Toivonen, Ph.D., for the episode rule algorithm imple mentation. Authors' e-mail: fhahonen,oheinone,mklemett,verkamog@cs.helsinki.fi. ?? To appear in Proceedings of PKDD'97 1st European Symposium on Principles of Data Mining and Knowledge Discovery, Trondheim, Norway, June 1997. to boost query processing <ref> [8, 5] </ref>. Consider a common information retrieval task: The user expresses his/her information needs, e.g., by giving a query, and the system executes the search by matching the query with the documents. With large collections simply scanning the text is not feasible. <p> Although indexing and selecting keywords are well-studied within information retrieval, new challenges have been recently set by the sudden appearance of very large heterogeneous full text document collections. Lewis and Sparck Jones <ref> [5] </ref> consider compound keyterms as one essential possibility to improve the quality of text retrieval in the new situation; they also emphasise the need of exhaustive experimenting. In this paper, we present our first experiments in applying general methods of data mining to discovering phrases and co-occurring terms.
Reference: 6. <author> H. Mannila. </author> <title> Data mining: machine learning, statistics, and databases. </title> <booktitle> In Proc. of the 8th Int'l Conference on Scientific and Statistical Database Management, </booktitle> <pages> pages 1-6, </pages> <address> Stockholm, Sweden, </address> <year> 1996. </year>
Reference-contexts: To get appropriate data for the analysis, substantial effort must usually be directed to the preprocessing phase. Referring to the results in different domain areas and applications, preprocessing can take as much as 80 per cent of the total effort <ref> [6] </ref>.
Reference: 7. <author> H. Mannila and H. Toivonen. </author> <title> Discovering generalized episodes using minimal occurrences. </title> <booktitle> In Proc. of the Second International Conference on Knowledge Discovery and Data Mining (KDD'96), </booktitle> <pages> pages 146-151, </pages> <address> Portland, Oregon, USA, </address> <month> August </month> <year> 1996. </year> <note> AAAI Press. </note>
Reference-contexts: The method that we have used to discover frequent episodes and episode rules in our data is described in <ref> [7] </ref>.
Reference: 8. <author> G. Salton. </author> <title> Automatic Text Processing: The Transformation, Analysis, and Retrieval of Information by Computer. </title> <publisher> Addison-Wesley, </publisher> <year> 1988. </year>
Reference-contexts: We thank Hannu Toivonen, Ph.D., for the episode rule algorithm imple mentation. Authors' e-mail: fhahonen,oheinone,mklemett,verkamog@cs.helsinki.fi. ?? To appear in Proceedings of PKDD'97 1st European Symposium on Principles of Data Mining and Knowledge Discovery, Trondheim, Norway, June 1997. to boost query processing <ref> [8, 5] </ref>. Consider a common information retrieval task: The user expresses his/her information needs, e.g., by giving a query, and the system executes the search by matching the query with the documents. With large collections simply scanning the text is not feasible.
Reference: 9. <author> F. Smadja. </author> <title> Retrieving collocations from text: </title> <journal> Xtract. Computational Linguistics, </journal> <volume> 19(1) </volume> <pages> 143-177, </pages> <year> 1993. </year> <title> This article was processed using the L A T E X macro package with LLNCS style </title>
Reference-contexts: More elaborate ways of utilizing co-occurrent terms can be found in natural language processing techniques. A specific class of co-occurring terms are so-called collocations, i.e., recurrent combinations of words that correspond to arbitrary word usages <ref> [9] </ref>. Opposite to typical phrases used in information retrieval, collocations may often contain prepositions and inflected words. In addition to the linguistic interest, collocations may be useful in retrieval tasks.
References-found: 9

