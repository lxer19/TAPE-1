URL: http://www.research.att.com/~wcohen/postscript/ml-90-repshift.ps
Refering-URL: http://www.research.att.com/~wcohen/
Root-URL: 
Title: An Analysis of Representation Shift In Concept Learning  
Author: William W. Cohen 
Address: New Brunswick, NJ 08903  
Affiliation: Computer Science Department Rutgers University  
Abstract: In spite of the importance of representation in learning, little progress has been made toward understanding what makes representations work. This paper describes a framework for knowledge-level analysis of changes in the representation of training examples in concept learning. This a very fundamental sort of representation change; such a change alters the very space over which learning occurs, and hence necessitates selection of a new hypothesis space and (probably) a new learning algorithm. The goals of this paper are first, to provide a framework for analysis of representation shifts; second, to make explicit the assumptions implicit in representation shifts that have actually been used in learning systems; and third, to suggest a procedure for finding the most appropriate representation shift, given some background knowledge about a learning problem. The analytic framework is used to analyze a class of hybrid EBL/SBL systems by characterizing the sorts of domain theories that can be used with these systems.
Abstract-found: 1
Intro-found: 1
Reference: [ Amarel, 1981 ] <author> Saul Amarel. </author> <title> On representations of problems of readings about actions. </title> <booktitle> In Readings in Artificial Intelligence. </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1981. </year>
Reference-contexts: Most prior analyses of representation change have focused on automatic reformulation of problem-solving strategies <ref> [ Amarel, 1981; Korf, 1981; Riddle, 1989; Subramanian, 1989 ] </ref> . Some of the formal models of representation change in problem solving, however, are general enough to serve as a model for representation change in learning.
Reference: [ Angluin, 1988 ] <author> Dana Angluin. </author> <title> Queries and concept learning. </title> <journal> Machine Learning, </journal> <volume> 2(4), </volume> <year> 1988. </year>
Reference-contexts: This fits many formal definitions of learn-ability, such as Gold's learnability in the limit [ Gold, 1967 ] , Littlestone's mistake-bounded learnability [ Lit-tlestone, 1988 ] , and Angluin's definitions of learning from queries <ref> [ Angluin, 1988 ] </ref> . An exception is the Valiant criterion of probably approximately correct (pac) learnability [ Valiant, 1984 ] , which requires only approximate identification of the target concept; this suggests that a probabilistic extension of this analytic framework may be worth investigating.
Reference: [ Chrisman, 1989 ] <author> Lonnie Chrisman. </author> <title> Evaluating bias during pac-learning. </title> <booktitle> In Proceedings of the Sixth International Workshop on Machine Learning, </booktitle> <address> Ithaca, New York, 1989. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: [ Cohen, 1988 ] <author> William W. Cohen. </author> <title> Generalizing number and learning from multiple examples in explanation-based learning. </title> <booktitle> In Proceedings of the Fifth International Conference on Machine Learning, </booktitle> <address> Ann Arbor, Michigan, 1988. </address> <publisher> Morgan Kauf-mann. </publisher>
Reference: [ Cohen, 1989 ] <author> William W. Cohen. </author> <title> Abductive explanation based learning: A solution to the multiple explanation problem. </title> <type> Technical Report ML-TR-26, </type> <institution> Rutgers University, </institution> <year> 1989. </year>
Reference-contexts: If P has hitset images 2 under f fl fi;O , then f fl fi;O is KL-equivalent to AB fi;O (P). Discussion of learning algorithms for the representation space which is the range of f fl is outside the scope of this paper; however, the A-EBL technique described in <ref> [ Cohen, 1989; Cohen, 1990a; Cohen, 1990b ] </ref> can be viewed such a learning algorithm. A few remarks are in order about the theorem above, in particular about the requirement that P have "hit-set images".
Reference: [ Cohen, 1990a ] <author> William W. Cohen. </author> <title> An analysis of representation shift in concept learning. </title> <booktitle> In Proceedings of the Seventh International Conference on Machine Learning, </booktitle> <address> Austin, Texas, 1990. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: If P has hitset images 2 under f fl fi;O , then f fl fi;O is KL-equivalent to AB fi;O (P). Discussion of learning algorithms for the representation space which is the range of f fl is outside the scope of this paper; however, the A-EBL technique described in <ref> [ Cohen, 1989; Cohen, 1990a; Cohen, 1990b ] </ref> can be viewed such a learning algorithm. A few remarks are in order about the theorem above, in particular about the requirement that P have "hit-set images".
Reference: [ Cohen, 1990b ] <author> William W. Cohen. </author> <title> Learning from textbook knowledge: A case study. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <address> Boston, Massachusetts, 1990. </address> <publisher> MIT Press. </publisher>
Reference-contexts: If P has hitset images 2 under f fl fi;O , then f fl fi;O is KL-equivalent to AB fi;O (P). Discussion of learning algorithms for the representation space which is the range of f fl is outside the scope of this paper; however, the A-EBL technique described in <ref> [ Cohen, 1989; Cohen, 1990a; Cohen, 1990b ] </ref> can be viewed such a learning algorithm. A few remarks are in order about the theorem above, in particular about the requirement that P have "hit-set images". <p> There have been several learning systems implemented that use changes of representation of the kind considered in this paper; some good examples are <ref> [ Cohen, 1990b ] </ref> and the systems discussed in [ Flann and Dietterich, 1989 ] . 3 The 3 It is important to keep in mind the difference between these systems and work on constructive induction, for example [ Drastal et al., 1989 ] : constructive induction is concerned with information-preserving
Reference: [ DeJong and Mooney, 1986 ] <author> Gerald DeJong and Ray-mond Mooney. </author> <title> EBL: An alternative view. </title> <journal> Machine Learning, </journal> <volume> 1(2), </volume> <year> 1986. </year>
Reference-contexts: The set of goals provable directly from this rule is the generalization of x. As an example of explanation based generalization, <ref> [ DeJong and Mooney, 1986 ] </ref> describes a simple theory of social interactions, under which the goal kill (john,john) is generalized to form the rule kill (X; X) depressed (X) ^ buy (X; W) ^ gun (W) which can be paraphrased as saying "X will kill himself if he is depressed
Reference: [ Drastal et al., 1989 ] <author> George Drastal, Gabor Czako, and Stan Raatz. </author> <title> Induction in abstraction spaces: A form of constructive induction. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <address> Detroit, Michigan, 1989. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: representation of the kind considered in this paper; some good examples are [ Cohen, 1990b ] and the systems discussed in [ Flann and Dietterich, 1989 ] . 3 The 3 It is important to keep in mind the difference between these systems and work on constructive induction, for example <ref> [ Drastal et al., 1989 ] </ref> : constructive induction is concerned with information-preserving transformations of training instances. framework was used to uncover the assumptions im-plicit in a commonly-used representation shift, and to derive a representation shift which is appropriate for a weak assumption about the correctness of EBL.
Reference: [ Flann and Dietterich, 1989 ] <author> Nicholas Flann and Thomas Dietterich. </author> <title> A study of explanation-based methods for inductive learning. </title> <journal> Machine Learning, </journal> <volume> 4(2), </volume> <year> 1989. </year>
Reference-contexts: plants using certain features known to be significant for the learning task at hand, as in [ Michalski and Chilausky, 1980 ] ; or X I might be a set of chess positions, and X R might be proofs that white has a forced exchange from that position, as in <ref> [ Flann and Dietterich, 1989 ] </ref> . 3.2 What is a learning problem? A definition of a "class of learning problems" must now be given. <p> been built that have the architecture of figure 1, and that use as a representation-shifting function some close variant of the function f (x) e O (p x ) These systems learn from a set of explanation structures using SBL techniques; they differ primarily in the learning methods used. (See <ref> [ Flann and Dietterich, 1989 ] </ref> for a discussion of some of these systems.) What assumptions are made by a learning program that that uses this representation shift? The answer AP P ROP (f; P) is correct, but not very meaningful. <p> There have been several learning systems implemented that use changes of representation of the kind considered in this paper; some good examples are [ Cohen, 1990b ] and the systems discussed in <ref> [ Flann and Dietterich, 1989 ] </ref> . 3 The 3 It is important to keep in mind the difference between these systems and work on constructive induction, for example [ Drastal et al., 1989 ] : constructive induction is concerned with information-preserving transformations of training instances. framework was used to uncover
Reference: [ Gold, 1967 ] <author> Mark Gold. </author> <title> Language identification in the limit. </title> <journal> Information and Control, </journal> <volume> 10, </volume> <year> 1967. </year>
Reference-contexts: The definition of potentially solvable assumes that the goal of learning is exact identification of the target concept. This fits many formal definitions of learn-ability, such as Gold's learnability in the limit <ref> [ Gold, 1967 ] </ref> , Littlestone's mistake-bounded learnability [ Lit-tlestone, 1988 ] , and Angluin's definitions of learning from queries [ Angluin, 1988 ] .
Reference: [ Hirsh, 1989 ] <author> Haym Hirsh. </author> <title> Incremental version space merging: A general framework for concept learning. </title> <type> PhD Thesis, </type> <institution> Stanford University Department of Computer Science, </institution> <year> 1989. </year>
Reference: [ Holte and Zimmer, 1989 ] <author> Robert Holte and Robert Zimmer. </author> <title> A mathematical framework for studying representations. </title> <booktitle> In Proceedings of the Sixth International Workshop on Machine Learning, </booktitle> <address> Ithaca, New York, 1989. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Some of the formal models of representation change in problem solving, however, are general enough to serve as a model for representation change in learning. In particular, our model of representation change in learning and notion of appropriateness is closely related to the models presented in <ref> [ Holte and Zimmer, 1989 ] </ref> and [ Lowry, 1988 ] ; in fact, it is a special case, in which the problem to be solved is required to be a learning problem.
Reference: [ Kedar-Cabelli and McCarty, 1987 ] <author> Smadar Kedar-Cabelli and L. Thorne McCarty. </author> <title> Explanation-based generalization as resolution theorem proving. </title> <booktitle> In Proceedings of the Fourth International Workshop on Machine Learning, </booktitle> <address> Irvine, California, 1987. </address> <publisher> Mor-gan Kaufmann. </publisher>
Reference-contexts: A short discussion of EBG precedes our analyses. 4.1 Explanation based generalization To avoid unnecessary detail, explanation based generalization will be discussed at a rather abstract level in this paper. Readers requiring more detail are referred to <ref> [ Kedar-Cabelli and McCarty, 1987; Mitchell et al., 1986 ] </ref> . Let fi be a theory, and for x 2 X I , let P ROOF S fi (x) denote the set of proofs of x in fi.
Reference: [ Keller, 1989 ] <author> Rich Keller. </author> <title> Compiling learning vocabulary from performance description. </title> <booktitle> In Proceedings of the Sixth International Workshop on Machine Learning, </booktitle> <address> Ithaca, New York, 1989. </address> <publisher> Morgan Kauf-mann. </publisher>
Reference: [ Korf, 1981 ] <author> Richard Korf. </author> <title> Toward a model of representation change. </title> <journal> Artificial Intelligence, </journal> <volume> 14 </volume> <pages> 41-78, </pages> <year> 1981. </year>
Reference-contexts: Most prior analyses of representation change have focused on automatic reformulation of problem-solving strategies <ref> [ Amarel, 1981; Korf, 1981; Riddle, 1989; Subramanian, 1989 ] </ref> . Some of the formal models of representation change in problem solving, however, are general enough to serve as a model for representation change in learning.
Reference: [ Littlestone, 1988 ] <author> Nick Littlestone. </author> <title> Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm. </title> <journal> Machine Learning, </journal> <volume> 2(4), </volume> <year> 1988. </year>
Reference: [ Lowry, 1988 ] <author> Michael Lowry. STRATA: </author> <title> Problem reformulation and abstract data types. In Change of Representation and Inductive Bias. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1988. </year>
Reference-contexts: In particular, our model of representation change in learning and notion of appropriateness is closely related to the models presented in [ Holte and Zimmer, 1989 ] and <ref> [ Lowry, 1988 ] </ref> ; in fact, it is a special case, in which the problem to be solved is required to be a learning problem.
Reference: [ Michalski and Chilausky, 1980 ] <author> R.S. Michalski and R. L. Chilausky. </author> <title> Learning from being told and learning from examples: an experimental comparision of the two methods of knowledge acquisition in the context of developing an expert system for soybean disease diagnosis. </title> <journal> Policy Analysis and Information Systems, </journal> <volume> 4, </volume> <year> 1980. </year>
Reference-contexts: For example X I might be a set of digitized photographs of soybean plants, and X R might consist of feature-vector representations of these plants using certain features known to be significant for the learning task at hand, as in <ref> [ Michalski and Chilausky, 1980 ] </ref> ; or X I might be a set of chess positions, and X R might be proofs that white has a forced exchange from that position, as in [ Flann and Dietterich, 1989 ] . 3.2 What is a learning problem? A definition of a
Reference: [ Mitchell et al., 1986 ] <author> T. Mitchell, R. Keller, and S. Kedar-Cabelli. </author> <title> Explanation-based generalization: A unifying view. </title> <journal> Machine Learning, </journal> <volume> 1(1), </volume> <year> 1986. </year>
Reference-contexts: Two applications are given of our framework. In section 4.2, we find the assumptions implicit in the use of a common representational shift: a shift from examples to the "explanation structures" generated by the explanation based generalization (EBG) algorithm <ref> [ Mitchell et al., 1986 ] </ref> . This shift is found to correspond to an assumption about the correctness of EBG. In section 4.3, we relax this assumption of correctness, and construct a new representation shift which is knowledge-level equivalent to the relaxed assumption. <p> A short discussion of EBG precedes our analyses. 4.1 Explanation based generalization To avoid unnecessary detail, explanation based generalization will be discussed at a rather abstract level in this paper. Readers requiring more detail are referred to <ref> [ Kedar-Cabelli and McCarty, 1987; Mitchell et al., 1986 ] </ref> . Let fi be a theory, and for x 2 X I , let P ROOF S fi (x) denote the set of proofs of x in fi.
Reference: [ Newell, 1982 ] <author> Allen Newell. </author> <title> The knowledge level. </title> <journal> Artificial Intelligence, </journal> <volume> 18 </volume> <pages> 87-127, </pages> <year> 1982. </year>
Reference-contexts: All analysis is done at the "knowledge level" <ref> [ Newell, 1982 ] </ref> ; consideration is given only to when learnabil-ity is made possible or impossible, not to when it is made easy or difficult.
Reference: [ Riddle, 1989 ] <author> Patricia Riddle. </author> <title> Reformulation from state space to reduction space. </title> <booktitle> In Proceedings of the Sixth International Workshop on Machine Learning, </booktitle> <address> Ithaca, New York, 1989. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Most prior analyses of representation change have focused on automatic reformulation of problem-solving strategies <ref> [ Amarel, 1981; Korf, 1981; Riddle, 1989; Subramanian, 1989 ] </ref> . Some of the formal models of representation change in problem solving, however, are general enough to serve as a model for representation change in learning.
Reference: [ Russell and Grosof, 1989 ] <author> Stuart Russell and Ben-jamin Grosof. </author> <title> Declarative bias for structural domains. </title> <booktitle> In Proceedings of the Sixth International Workshop on Machine Learning, </booktitle> <address> Ithaca, New York, 1989. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: [ Subramanian, 1989 ] <author> Devika Subramanian. </author> <title> Representational issues in machine learning. </title> <booktitle> In Proceedings of the Sixth International Workshop on Machine Learning, </booktitle> <address> Ithaca, New York, 1989. </address> <publisher> Morgan Kauf-mann. </publisher>
Reference-contexts: Most prior analyses of representation change have focused on automatic reformulation of problem-solving strategies <ref> [ Amarel, 1981; Korf, 1981; Riddle, 1989; Subramanian, 1989 ] </ref> . Some of the formal models of representation change in problem solving, however, are general enough to serve as a model for representation change in learning.
Reference: [ Utgoff, 1984 ] <author> Paul Utgoff. </author> <title> Shift of bias for inductive concept learning. </title> <type> Technical Report CBM-TR-145, </type> <institution> Rutgers University, </institution> <year> 1984. </year>
Reference: [ Valiant, 1984 ] <author> L. G. Valiant. </author> <title> A theory of the learnable. </title> <journal> Communications of the ACM, </journal> <volume> 27(11), </volume> <month> Novem-ber </month> <year> 1984. </year>
Reference-contexts: An exception is the Valiant criterion of probably approximately correct (pac) learnability <ref> [ Valiant, 1984 ] </ref> , which requires only approximate identification of the target concept; this suggests that a probabilistic extension of this analytic framework may be worth investigating. <p> Finally, the definition of the appropriateness of a representational shift assumes that the goal of learning is exact identification of the target concept; this is a more stringent identification criterion than the Valiant criterion of probably approximately correct learnability <ref> [ Valiant, 1984 ] </ref> , which requires only approximate identification of the target concept.
References-found: 26

