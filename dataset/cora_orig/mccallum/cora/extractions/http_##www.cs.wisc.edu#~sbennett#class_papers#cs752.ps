URL: http://www.cs.wisc.edu/~sbennett/class_papers/cs752.ps
Refering-URL: http://www.cs.wisc.edu/~sbennett/sbennett.html
Root-URL: 
Email: sbennett@cs.wisc.edu, bwang@ece.wisc.edu  
Title: Very-Wide-Issue Superscalar Microengine Configurations  
Author: Steve Bennett and Bin Wang CS/ECE Jim Smith 
Date: 8 May 1995  
Pubnum: Project Report  
Abstract: To continue microprocessor performance improvements made in the last 2 decades, instruction-level parallelism must be exploited across multiple basic block boundaries. This necessity has led to execution engines which dynamically predict a stream of instructions which are executed concurrently. As issue widths increase, former assumptions about requirements for execution resources such as internal buses, renaming structures, memory ports and bypass paths no longer hold. In this study, we have modeled an aggressive superscalar implementation and studied the effects of limiting certain resources on the overall performance, as measured by total execution cycles. We have3 main conclusions: (1) bypass paths for instructions to issue directly to the execution units from the fetch mechanism are unjustified if instruction fetch prediction is very good; (2) the number of reservation stations should be made as large as possible after balancing all other resources; and (3) the number of result buses needed to avoid handicapping the rest of the execution engine grows proportionally to the issue rate with a constant of proportionality of approximately 0.25. 
Abstract-found: 1
Intro-found: 0
Reference: [1] <author> M. Butler, et al., </author> <title> Instruction Stream Parallelism Is Greater Than Two, </title> <booktitle> Proceedings of the International Symposium on Computer Architecture , June 1991. </booktitle>
Reference-contexts: 99 Number RUU/Reservation Station Entries 128 Number of Load/Store Queue Entries 128 Number of RUU Dispatch Bypass Paths Same as Issue Width Branch Predictor Perfect Functional Units As Shown Above Data Cache 16kB, 16B Lines, Direct Mapped, Write-back Table 2 Default Machine Configuration 3.3 Benchmarks We used six SPEC benchmarks <ref> [1] </ref> as our test suite. The programs we chose and the inputs used are shown below in Table 3. Because of limited simulation time, we did not simulate each benchmark to completion. This is shown in the table as well. Using these benchmarks is reasonable.
Reference: [1] <author> B. </author> <title> Case, Updated SPEC Benchmarks Released, </title> <type> Microprocessor Report , vol. 6, </type> <month> September </month> <year> 1992. </year>
Reference-contexts: 99 Number RUU/Reservation Station Entries 128 Number of Load/Store Queue Entries 128 Number of RUU Dispatch Bypass Paths Same as Issue Width Branch Predictor Perfect Functional Units As Shown Above Data Cache 16kB, 16B Lines, Direct Mapped, Write-back Table 2 Default Machine Configuration 3.3 Benchmarks We used six SPEC benchmarks <ref> [1] </ref> as our test suite. The programs we chose and the inputs used are shown below in Table 3. Because of limited simulation time, we did not simulate each benchmark to completion. This is shown in the table as well. Using these benchmarks is reasonable.
Reference: [2] <author> Colwell and Steck, </author> <title> A 0.6 micron BiCMOS Processor with Dynamic Execution, </title> <booktitle> Proceedings of ISSCC , February 1995. </booktitle>
Reference-contexts: It is not clear exactly what form the hardware should take to realize performance improvements from this parallelism. Research work begun in the 1980s [7] [9] [6] has led to many commercial superscalar processors. Recent superscalar microprocessor releases from Intel <ref> [2] </ref>, AMD [8], DEC [4] and MIPS [5] display a vide variety of implementation techniques aimed at achieving high performance. They are based in part on exploiting instruction-level parallelism in the executing code. These processors expose parallelism by dynamically predicting branches to form a wide window of instructions.
Reference: [3] <author> T. Conte, et al, </author> <title> Optimization of Instruction Fetch Mechanisms for High Issue Rates, </title> <booktitle> to appear in Proceeding of the International Symposium on Computer Architecture , June 1995. </booktitle>
Reference-contexts: Issue Logic: Each cycle, the issue and dispatch logic are capable of decoding, resolving dependencies for, issuing and dispatching as many instructions as we desire. This is extremely ambitious and probably unrealistic. There is work being done to address these problems; some results may be seen in [11], <ref> [3] </ref> and [13]. Register Renaming: The issue unit performs perfect register renaming, eliminating anti and output dependencies.
Reference: [4] <author> L. Gwennap, </author> <title> Digital Leads the Pack with 21164, </title> <type> Microprocessor Report , vol. 8, </type> <month> October </month> <year> 1994. </year>
Reference-contexts: It is not clear exactly what form the hardware should take to realize performance improvements from this parallelism. Research work begun in the 1980s [7] [9] [6] has led to many commercial superscalar processors. Recent superscalar microprocessor releases from Intel [2], AMD [8], DEC <ref> [4] </ref> and MIPS [5] display a vide variety of implementation techniques aimed at achieving high performance. They are based in part on exploiting instruction-level parallelism in the executing code. These processors expose parallelism by dynamically predicting branches to form a wide window of instructions.
Reference: [5] <author> L. Gwennap, </author> <title> MIPS R10000 Uses Decoupled Architecture, </title> <type> Microprocessor Report , vol. 8, </type> <month> October </month> <year> 1994. </year>
Reference-contexts: It is not clear exactly what form the hardware should take to realize performance improvements from this parallelism. Research work begun in the 1980s [7] [9] [6] has led to many commercial superscalar processors. Recent superscalar microprocessor releases from Intel [2], AMD [8], DEC [4] and MIPS <ref> [5] </ref> display a vide variety of implementation techniques aimed at achieving high performance. They are based in part on exploiting instruction-level parallelism in the executing code. These processors expose parallelism by dynamically predicting branches to form a wide window of instructions.
Reference: [6] <author> M. Johnson, </author> <title> Superscalar Design , Englewood Cliffs, </title> <publisher> NJ; Prentice Hall, </publisher> <year> 1990. </year>
Reference-contexts: To capitalize on this parallelism, an execution engine must decode and execute instructions across a wide window which spans many basic blocks. It is not clear exactly what form the hardware should take to realize performance improvements from this parallelism. Research work begun in the 1980s [7] [9] <ref> [6] </ref> has led to many commercial superscalar processors. Recent superscalar microprocessor releases from Intel [2], AMD [8], DEC [4] and MIPS [5] display a vide variety of implementation techniques aimed at achieving high performance. They are based in part on exploiting instruction-level parallelism in the executing code.
Reference: [7] <author> Y. Patt, W. W. Hwu and M. Shebanow, HPS, </author> <title> A New Microarchitecture: Rationale and Introduction, </title> <booktitle> Proceedings of the 18th Annual Workshop on Microprogramming , December 1986. </booktitle>
Reference-contexts: To capitalize on this parallelism, an execution engine must decode and execute instructions across a wide window which spans many basic blocks. It is not clear exactly what form the hardware should take to realize performance improvements from this parallelism. Research work begun in the 1980s <ref> [7] </ref> [9] [6] has led to many commercial superscalar processors. Recent superscalar microprocessor releases from Intel [2], AMD [8], DEC [4] and MIPS [5] display a vide variety of implementation techniques aimed at achieving high performance. They are based in part on exploiting instruction-level parallelism in the executing code.
Reference: [8] <author> M. Slater, </author> <note> AMDs K5 Designed to Outrun Pentium, Microprocessor Report , vol. 8, </note> <month> October </month> <year> 1994. </year>
Reference-contexts: It is not clear exactly what form the hardware should take to realize performance improvements from this parallelism. Research work begun in the 1980s [7] [9] [6] has led to many commercial superscalar processors. Recent superscalar microprocessor releases from Intel [2], AMD <ref> [8] </ref>, DEC [4] and MIPS [5] display a vide variety of implementation techniques aimed at achieving high performance. They are based in part on exploiting instruction-level parallelism in the executing code. These processors expose parallelism by dynamically predicting branches to form a wide window of instructions.
Reference: [9] <author> J. E. Smith, </author> <title> Dynamic Instruction Scheduling and the Astronautics ZS-1, </title> <booktitle> IEEE Computer, </booktitle> <month> July </month> <year> 1989. </year>
Reference-contexts: To capitalize on this parallelism, an execution engine must decode and execute instructions across a wide window which spans many basic blocks. It is not clear exactly what form the hardware should take to realize performance improvements from this parallelism. Research work begun in the 1980s [7] <ref> [9] </ref> [6] has led to many commercial superscalar processors. Recent superscalar microprocessor releases from Intel [2], AMD [8], DEC [4] and MIPS [5] display a vide variety of implementation techniques aimed at achieving high performance. They are based in part on exploiting instruction-level parallelism in the executing code.
Reference: [10] <author> G. Sohi, </author> <title> Instruction Issue Logic for High-Performance, Interruptible, Multiple Functional Unit Pipelined Computers, </title> <journal> IEEE Transactions on Computers, </journal> <volume> vol. 39, no. 3, </volume> <month> March </month> <year> 1990. </year>
Reference: [11] <author> E. Sprangle and Y. Patt, </author> <title> Facilitating Superscalar Processing via a Combined Static/Dynamic Register Renaming Scheme, </title> <booktitle> Proceedings of the 27th International Symposium on Microarchitecture , December 1994. </booktitle>
Reference-contexts: Issue Logic: Each cycle, the issue and dispatch logic are capable of decoding, resolving dependencies for, issuing and dispatching as many instructions as we desire. This is extremely ambitious and probably unrealistic. There is work being done to address these problems; some results may be seen in <ref> [11] </ref>, [3] and [13]. Register Renaming: The issue unit performs perfect register renaming, eliminating anti and output dependencies. <p> Functional Units: All functional units are fully pipelined, capable of starting a new instruction every cycle. 3.1 Simulator We used a modified copy of SS, a superscalar simulator developed by Todd Austin in the Multiscalar group. The original simulator models an aggressive RUU <ref> [11] </ref> based superscalar implementation executing an extended MIPS ISA. Austins original simulator takes the very aggressive approach of not allowing some resource related issues to limit overall performance. For example, Austins simulator models an infinite number of functional units and result buses.
Reference: [12] <author> D. Wall, </author> <title> Limits of Instruction-Level Parallelism, </title> <type> DEC WRL Technical Report, </type> <month> November </month> <year> 1993. </year>
Reference-contexts: Because of limited simulation time, we did not simulate each benchmark to completion. This is shown in the table as well. Using these benchmarks is reasonable. It allows us to compare performance numbers with existing studies such as Wall <ref> [12] </ref>. We are able to compile these applications using f2c and Austins modified gcc and the Unix system calls they require are supported by the simulator. We note that these benchmarks represent an even mix of parallelism levels as reported in [12]. 3.4 Metrics Total execution cycles is our primary metric. <p> compare performance numbers with existing studies such as Wall <ref> [12] </ref>. We are able to compile these applications using f2c and Austins modified gcc and the Unix system calls they require are supported by the simulator. We note that these benchmarks represent an even mix of parallelism levels as reported in [12]. 3.4 Metrics Total execution cycles is our primary metric. Since we did not simulate the benchmarks to completion, we must calculate instructions per cycle (IPC) and use it as our primary performance measurement. <p> We did not simulate with a large enough reservation station pool to determine where the IPC stops increasing. Hence our results do not offer any concrete measurement of the appropriate number of dynamic renaming hardware. Other parallelism studies such as Wall <ref> [12] </ref> have noted parallelism numbers of 50 IPC or more for the benchmarks which our studies have in common. We also note that integer benchmarks outperform floating point benchmarks in these tests. We hypothesize that this is a result of our branch predicion method.
Reference: [13] <author> T. Y. Yeh, D. Marr and Y. Patt, </author> <title> Increasing the Instruction Fetch Rate via Multiple Branch Prediction and a Branch Address Cache, </title> <booktitle> Proceedings of the 7th International Conference on Supercomputing , July 1993. </booktitle>
Reference-contexts: This is extremely ambitious and probably unrealistic. There is work being done to address these problems; some results may be seen in [11], [3] and <ref> [13] </ref>. Register Renaming: The issue unit performs perfect register renaming, eliminating anti and output dependencies. <p> For example, Austins simulator models an infinite number of functional units and result buses. We modified Austins simulator in the following ways: Perfect Branch Prediction: Initially, our goal was to simulate a multiple branch predicting mechanism <ref> [13] </ref>. How ever, due to time constraints, we resorted to the perfect predictor. We implemented this predictor in SS. Functional Unit Limitations: We implemented a fully configurable functional unit configuration. Functional Units are divided into classes and subclasses.
References-found: 14

