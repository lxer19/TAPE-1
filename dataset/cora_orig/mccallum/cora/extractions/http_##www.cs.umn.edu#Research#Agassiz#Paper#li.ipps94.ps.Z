URL: http://www.cs.umn.edu/Research/Agassiz/Paper/li.ipps94.ps.Z
Refering-URL: http://www.cs.umn.edu/Research/Agassiz/agassiz_pubs.html
Root-URL: http://www.cs.umn.edu
Title: Software Assistance for Directory-Based Caches  
Author: Zhiyuan Li 
Address: 200 Union St. SE, Minneapolis 55455  
Affiliation: Department of Computer Science University of Minnesota at Minneapolis-St. Paul  
Abstract: We investigate the benefit of combining directory-based schemes with software schemes as a method for maintaining cache coherence on multiprocessors. The main idea is to maintain the directory hardware while allowing eligible write references to bypass the invalidation process. Static analysis is applied to parallel programs in order to mark those eligible write references. The sample results suggest that such reference marking can reduce invalidation requests significantly when it is combined with locality-preserving task scheduling and when the array subscripts are not complex. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A.V. Aho, R. Sethi, and J.D. Ullman. </author> <booktitle> Compilers: Principles, Techniques, and Tools. </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading, Mass., </address> <year> 1986. </year> <title> Table 6: Network Traffic for BALANCE Case rm-net wm-net coh-net % inv static 0.19 0.66 0.04 0 dynamic 0.19 0.66 0.06 0.006 hardware 0.19 0.66 0.19 0.08 </title>
Reference-contexts: In such cases, the involved last-writes should be conservatively marked as i-writes and the exposed reads marked as c-reads, which, in effect, leaves the invalidation hardware to resolve potential cache incoherence. Given exposed reads in the basic blocks <ref> [1] </ref>, Algorithm 1 in Figure 2 determines the definitely exposed reads of a given task block. Note that any exposed read in a basic block is definitely exposed in that basic block. Given the maybe-mod sets and the kill sets, the compiler uses the reaching definition algorithm [1] to decide whether <p> the basic blocks <ref> [1] </ref>, Algorithm 1 in Figure 2 determines the definitely exposed reads of a given task block. Note that any exposed read in a basic block is definitely exposed in that basic block. Given the maybe-mod sets and the kill sets, the compiler uses the reaching definition algorithm [1] to decide whether a last-write group of one task block reaches the top of another task block.
Reference: [2] <author> M. Berry, D. Chen, P. Koss, D. Kuck, and S. Lo. </author> <title> The perfect club benchmarks: Effective performance evaluation of supercomputers. </title> <type> Technical Report CSRD-827, </type> <institution> University of Illinois, Urbana, IL, </institution> <month> May </month> <year> 1989. </year>
Reference-contexts: When there are no outstanding cache copies to be invalidated, invalidation traffic involves only the requesting processor and the memory directory. Our simulation study [17] suggests that invalidation traffic can be quite significant, relative to data traffic. The benchmarks in the Perfect Suite <ref> [2] </ref> that we studied generate around 3 bytes of network traffic per variable reference, including the traffic for global data movement (with a word size of 4 bytes) and the traffic due to invalidation requests and acknowledgement.
Reference: [3] <author> L. M. Censier and P. Feautrier. </author> <title> A new solution to coherence problems in multicache systems. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-27(12):1112-1118, </volume> <month> Decem-ber </month> <year> 1978. </year>
Reference-contexts: Solving the cache coherence problem ensures that no processor ever uses an invalid data copy. For multiprocessors that are connected with multistage interconnection networks (MIN), solutions for the cache coherence problem have fallen into two categories, namely, compiler-assisted software solutions (see [8] and others) and directory-based solutions (see <ref> [3] </ref> and others). Each category is known to have limitations which cause unnecessary network traffic and data access delay. This paper investigates the benefit of combining the two approaches. The main idea is to retain the original directory hardware while allowing eligible write references to bypass the invalidation process. <p> In this work, we mainly consider the write-invalidate scheme, but the essence of our work applies to the write-update scheme as well. In a typical invalidation process <ref> [3] </ref>, when a processor writes to a variable for the first time in the current task, it sends out an invalidation request to the memory directory. <p> In order to do so, the read references need to be examined as well. We slightly modify the mechanism in a conventional directory scheme <ref> [3] </ref> by distinguishing two types of read operations (m-read and c-read) and three types of write operations (n-write, t-write, and i-write). The compiler marks on each reference to indicate which operation should be used when generating the machine code. <p> Our scheme, in contrast, marks such a read as a c-read and resolves the potential incoherence by marking the writes by other processors as i-writes. Thus, unlike software solutions, our method never results in a higher miss-ratio than the conventional hardware invalidation scheme <ref> [3] </ref>. An n-write writes into the private cache and performs no coherence actions. It is used when the compiler can guarantee that no other processor will use the values in the updated block. A t-write writes into both the private cache and the shared memory. <p> An i-write is used when the updated value may be used by other processors using c-reads. An i-write acts the same way as a write to a shared value in a conventional directory scheme <ref> [3] </ref>: A special bit on each cache block indicates whether an invalidation request has been sent out for that cache block. If not, then the i-write triggers an invalidation request to the directory.
Reference: [4] <author> Y. Chen and M. Dubois. </author> <title> Cache protocol with partial block invalidation. </title> <booktitle> In Proc. 7th International Parallel Processing Symposium, </booktitle> <year> 1993. </year>
Reference-contexts: This may increase the number of i-writes due to false sharing, but our scheme should suffer from false sharing no more than a conventional invalidation scheme. Our scheme can benefit from any optimization technique that reduces the effect of false sharing <ref> [4, 23] </ref>. 3.1 A marking example Before giving a formal presentation of the marking algorithm, we first illustrate the ideas through the program segment in Figure 1. In that segment, the scalars nr, nits and jmax are written only once, by processor p 0 .
Reference: [5] <author> Y. Chen and A. V. Veidenbaum. </author> <title> Comparison and analysis of software and directory coherence schemes. </title> <booktitle> In Proc. 1991 ACM International Conference on Supercomputing, </booktitle> <pages> pages 818-829, </pages> <year> 1991. </year>
Reference-contexts: Hence, we do not consider these types of techniques here. Overall, previous studies indicate that the over-invalidation by the software schemes increases both the miss ratio and the network traffic, compared to a mechanism that has complete run-time information <ref> [14, 5, 19] </ref> The software solutions are attractive because they do not generate invalidation traffic, but they risk a high miss-ratio and heavy overall traffic due to over-invalidation. This dilemma motivates our effort to find a combination of software solutions and directory-based solutions.
Reference: [6] <author> H. Cheong and A. V. Veidenbaum. </author> <title> A cache coherence scheme with fast selective invalidation. </title> <booktitle> In Proc. 15th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 299-307, </pages> <month> June </month> <year> 1988. </year>
Reference-contexts: The software solutions insert cache invalidation instructions which, when executed, either invalidate the whole data cache of the executing processor (termed indiscriminate invalidation in the literature <ref> [6] </ref>) or invalidate a selected cache block. Such local invalidating action normally occurs at the beginning of a new task which is created at the run time of a parallel program. Indiscriminate invalidation tends to grossly invalidate data which may actually be valid. <p> On the other hand, selective invalidation requires executing as many invalidating instructions as the number of cache blocks to be invalidated, which is quite a high overhead. Recently, a couple of remedies for indiscriminate invalidation have been proposed to reduce the degree of over-invalidation <ref> [6, 20] </ref>. Such remedies, termed fast selective invalidation, can be quite effective if the compiler is able to analyze the program's data flow with high precision. Unfortunately, a precise static analysis is known to be difficult, due to such complications in data access patterns as subscripted arrays and pointers. <p> ENDDOALL ENDDO ENDDO ENDDO attempts to read the cache first. An m-read is used when the compiler can guarantee that the read always takes a value written by other processors. In other cases, c-reads are issued. Certain software solutions <ref> [6] </ref> also use these two different types of reads. However, whenever it is unclear whether a read takes a value written by other processors, the software solutions let the read bypass the cache.
Reference: [7] <author> H. Cheong and A. V. Veidenbaum. </author> <title> A version control approach to cache coherence. </title> <booktitle> In Proc. 1989 ACM International Conference on Supercomputing, </booktitle> <pages> pages 322-330, </pages> <year> 1989. </year>
Reference-contexts: The inability of the compilers to predict run time execution paths also poses a major obstacle. Finally, dynamic task scheduling brings further difficulties to the static analysis. Some of these problems may be reduced by techniques such as version comparison <ref> [7] </ref> or time-stamp comparison [15]. However, it is still unclear whether the extra execution time introduced by such techniques would be practically acceptable. Hence, we do not consider these types of techniques here.
Reference: [8] <author> H. Cheong and A. V. Veidenbaum. </author> <title> Compiler-directed cache management in multiprocessors. </title> <journal> Computer, </journal> <volume> 23(6) </volume> <pages> 39-47, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: Solving the cache coherence problem ensures that no processor ever uses an invalid data copy. For multiprocessors that are connected with multistage interconnection networks (MIN), solutions for the cache coherence problem have fallen into two categories, namely, compiler-assisted software solutions (see <ref> [8] </ref> and others) and directory-based solutions (see [3] and others). Each category is known to have limitations which cause unnecessary network traffic and data access delay. This paper investigates the benefit of combining the two approaches.
Reference: [9] <author> S. J. Eggers and R. H. Katz. </author> <title> A characterization of sharing in parallel programs and its application to coherency protocol evaluation. </title> <booktitle> In Proc. International Symposium on Computer Architecture, </booktitle> <year> 1988. </year>
Reference-contexts: It is known that a cache block size greater than a single word may or may not bring better performance than the size of one word, due to the difficult tradeoff between spatial locality and the negative effect of false sharing <ref> [9, 11] </ref>. If the cache block size is greater than one word, then the compiler should mark i-writes conservatively: all write references to the same cache block must be marked as i-writes if any of these should be marked as an i-write.
Reference: [10] <author> T. Gross and P Steenkiste. </author> <title> Structured dataflow analysis for arrays and its use in an optimizing compiler. </title> <journal> Software Practice and Experience, </journal> <volume> 20(2) </volume> <pages> 133-155, </pages> <month> February </month> <year> 1990. </year>
Reference-contexts: DE (B) := de (start), where start is the start basic block of B. exposed reads compute the kill set and the last-write set precisely for all cases. For simple cases such as the one in Figure 1, however, these sets can be analyzed precisely (see <ref> [10, 12] </ref> and others). If these sets cannot be analyzed precisely, then reaching definitions (see below) involving certain last-writes and certain exposed reads will become obscure.
Reference: [11] <author> A. Gupta and W. Weber. </author> <title> Analysis of cache invalidation patterns in multiprocessors. </title> <booktitle> In Proc. International Symposium on Computer Architecture, </booktitle> <year> 1989. </year>
Reference-contexts: It is known that a cache block size greater than a single word may or may not bring better performance than the size of one word, due to the difficult tradeoff between spatial locality and the negative effect of false sharing <ref> [9, 11] </ref>. If the cache block size is greater than one word, then the compiler should mark i-writes conservatively: all write references to the same cache block must be marked as i-writes if any of these should be marked as an i-write.
Reference: [12] <author> Z. Li. </author> <title> Array privatization for parallel execution of loops. </title> <booktitle> In Proceedings of the 1992 International Conference on Supercomputing, </booktitle> <month> July </month> <year> 1992. </year>
Reference-contexts: DE (B) := de (start), where start is the start basic block of B. exposed reads compute the kill set and the last-write set precisely for all cases. For simple cases such as the one in Figure 1, however, these sets can be analyzed precisely (see <ref> [10, 12] </ref> and others). If these sets cannot be analyzed precisely, then reaching definitions (see below) involving certain last-writes and certain exposed reads will become obscure.
Reference: [13] <author> Z. Li. </author> <title> Analyzing scheduled fork-join programs to reduce cache invalidation traffic. </title> <type> Technical Report CSci-93-86, </type> <institution> Computer Science Department, University of Minnesota, Minneapolis, MN, </institution> <year> 1993. </year>
Reference-contexts: We assume that the compiler has annotated each DOALL loop with a directive that specifies the scheduling policy and, in the case of static scheduling, which processor executes which loop iterations. (A related paper describes a programming model that provides such a precise specification <ref> [13] </ref>.) The sequential regions in our fork-join model include all the code segments outside the DOALL loops, including the sequential DO loop headers. A parallel region consists of tasks derived from the DOALL loop iterations. <p> As mentioned in the beginning, our conservative choice is to mark the write of psi as an i-write and to mark the read as a c-read. The marking of loop indices requires special, but simple, treatment <ref> [13] </ref>. We do not address this trivial matter here. 3.2 The marking scheme The compiler partitions a fork-join program into sequential regions and parallel regions. The program control may transfer between sequential regions, bypassing parallel regions. <p> Mark all the unmarked writes as n-writes. 4. Mark all the unmarked, i.e. unexposed, reads as c-reads. 2 A related paper <ref> [13] </ref> discusses a few simple but useful methods to improve the basic scheme, which include the following: (1) When p 0 participates in executing a DOALL loop, mark the writes by p 0 as n-writes if they reach only the reads in sequential regions (which will be executed by p 0
Reference: [14] <author> S. L. Min and J. Baer. </author> <title> A performance comparison of directory-based and timestamp-based cache coherence schemes. </title> <booktitle> In Proc. 1990 International Conference on Parallel Processing, </booktitle> <pages> pages 305-311, </pages> <year> 1990. </year>
Reference-contexts: Hence, we do not consider these types of techniques here. Overall, previous studies indicate that the over-invalidation by the software schemes increases both the miss ratio and the network traffic, compared to a mechanism that has complete run-time information <ref> [14, 5, 19] </ref> The software solutions are attractive because they do not generate invalidation traffic, but they risk a high miss-ratio and heavy overall traffic due to over-invalidation. This dilemma motivates our effort to find a combination of software solutions and directory-based solutions.
Reference: [15] <author> S. L. Min and J. Baer. </author> <title> A timestamp-based cache coherence scheme. </title> <booktitle> In Proc. 1989 International Conference on Parallel Processing, </booktitle> <volume> Vol. I: Architecture, </volume> <pages> pages 23-32, </pages> <year> 1990. </year>
Reference-contexts: The inability of the compilers to predict run time execution paths also poses a major obstacle. Finally, dynamic task scheduling brings further difficulties to the static analysis. Some of these problems may be reduced by techniques such as version comparison [7] or time-stamp comparison <ref> [15] </ref>. However, it is still unclear whether the extra execution time introduced by such techniques would be practically acceptable. Hence, we do not consider these types of techniques here.
Reference: [16] <author> F. Mounes-Toussi, D. J. Lilja, and Z. Li. </author> <title> Compiler support for reducing the network traffic and the miss ratio in a directory-based cache coherence mechanism. </title> <type> Technical Report CSci-93-89, </type> <institution> Computer Science Department, University of Minnesota, Minneapolis, MN, </institution> <year> 1993. </year>
Reference-contexts: If not, then the i-write triggers an invalidation request to the directory. The updated value is not written into the memory until a cache replacement or a c-read by another processor forces write-back. Details of the hardware implementation of these read/write operations are provided in a subsequent paper <ref> [16] </ref>. In this work, we assume the cache block size of one word. <p> The instrumented programs are then executed to produce the traces. We use a simulator for a multiprocessor with private caches which takes the traces as input and reports the results <ref> [16] </ref>. We arbitrarily choose the number of processors to be 16. We locate the program segments which generate over 95% of the total write references. These segments are small and generally simple, allowing us to mark the references in the program by hand.
Reference: [17] <author> T. N. Nguyen, Z. Li, and D. J. Lilja. </author> <title> Efficient use of cache coherence directories through compiler analysis. </title> <type> Technical Report CSci-93-64, </type> <institution> Computer Science Department, University of Minnesota, Minneapolis, MN, </institution> <year> 1993. </year>
Reference-contexts: It is clear that the more cache copies need to be invalidated, the heavier the network traffic will be. When there are no outstanding cache copies to be invalidated, invalidation traffic involves only the requesting processor and the memory directory. Our simulation study <ref> [17] </ref> suggests that invalidation traffic can be quite significant, relative to data traffic.
Reference: [18] <author> T. N. Nguyen, Z. Li, and D. J. Lilja. </author> <title> Efficient use of dynamically tagged directories through compiler analysis. </title> <booktitle> In Proc. 1993 International Conference on Parallel Processing, </booktitle> <address> St. Charles, IL, </address> <year> 1993. </year>
Reference-contexts: Different Marking (D) Name %mr %cr %iw %tw %nw AMOEBA 3.9 79.8 4.1 1.3 10.7 BALANCE 0.9 82.3 0.04 0.8 15.9 SPLIE2 3.8 79.5 0.1 1.1 15.5 The Fortran programs are first parallelized by using the Parafrase 2 translator [21], and they are instrumented with statements which generate reference traces <ref> [18] </ref>. The instrumented programs are then executed to produce the traces. We use a simulator for a multiprocessor with private caches which takes the traces as input and reports the results [16]. We arbitrarily choose the number of processors to be 16.
Reference: [19] <author> S. Owicki and A. Agarwal. </author> <title> Evaluating the performance of software cache coherence. </title> <booktitle> In Proc. of International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 230-242, </pages> <year> 1989. </year>
Reference-contexts: Hence, we do not consider these types of techniques here. Overall, previous studies indicate that the over-invalidation by the software schemes increases both the miss ratio and the network traffic, compared to a mechanism that has complete run-time information <ref> [14, 5, 19] </ref> The software solutions are attractive because they do not generate invalidation traffic, but they risk a high miss-ratio and heavy overall traffic due to over-invalidation. This dilemma motivates our effort to find a combination of software solutions and directory-based solutions.
Reference: [20] <author> J. Peir, K. So, and J.H.Tang. </author> <title> Techniques to enhance cache performance across parallel program sections. </title> <booktitle> In Proc. 1993 International Conference on Parallel Processing, </booktitle> <volume> Vol. I: Architecture, </volume> <pages> pages 12-19, </pages> <year> 1993. </year>
Reference-contexts: On the other hand, selective invalidation requires executing as many invalidating instructions as the number of cache blocks to be invalidated, which is quite a high overhead. Recently, a couple of remedies for indiscriminate invalidation have been proposed to reduce the degree of over-invalidation <ref> [6, 20] </ref>. Such remedies, termed fast selective invalidation, can be quite effective if the compiler is able to analyze the program's data flow with high precision. Unfortunately, a precise static analysis is known to be difficult, due to such complications in data access patterns as subscripted arrays and pointers.
Reference: [21] <author> C. D. Polychronopoulos, M. B. Girkar, M. R. Haghighat, C. L. Lee, B. P. Leung, and D. A. Schouten. </author> <title> Parafrase-2: An environment for paral-lelizing, partitioning, synchronizing, and scheduling programs on multiprocessors. </title> <booktitle> In Proc. 1989 International Conference on Parallel Processing, </booktitle> <address> St. Charles, IL, </address> <month> August </month> <year> 1989. </year>
Reference-contexts: 15.9 SPLIE2 3.8 79.5 0 1.2 15.5 Table 3: Distribution of Different Marking (D) Name %mr %cr %iw %tw %nw AMOEBA 3.9 79.8 4.1 1.3 10.7 BALANCE 0.9 82.3 0.04 0.8 15.9 SPLIE2 3.8 79.5 0.1 1.1 15.5 The Fortran programs are first parallelized by using the Parafrase 2 translator <ref> [21] </ref>, and they are instrumented with statements which generate reference traces [18]. The instrumented programs are then executed to produce the traces. We use a simulator for a multiprocessor with private caches which takes the traces as input and reports the results [16].
Reference: [22] <author> W. H. Press, B. P. Flannery, S. A. Teukolsky, and W. T. Vetterling. </author> <title> Numerical Recipes: The Art of Scientific Computing (Fortran Version). </title> <publisher> Cambridge University Press, </publisher> <year> 1989. </year>
Reference-contexts: they reach only the reads in sequential regions (which will be executed by p 0 ); (2) Using pre-loading and loop peeling to avoid redundant m-reads (caused by repeated execution of the same statement which contains an m-read). 4 Sample Results We have chosen five programs from the Numerical Recipes <ref> [22] </ref> with which to examine the effect of our scheme. Table 1 lists the program names, the problems they solve, and the total number of writes at run time. Each program is chosen to meet two criteria.
Reference: [23] <author> J. Torrellas, M. S. Lam, and J. L. Hennessy. </author> <title> Shared data placement optimizations to reduce multiprocessor cache miss rates. </title> <booktitle> In Proc. International Conference on Parallel Processing, </booktitle> <year> 1990. </year>
Reference-contexts: This may increase the number of i-writes due to false sharing, but our scheme should suffer from false sharing no more than a conventional invalidation scheme. Our scheme can benefit from any optimization technique that reduces the effect of false sharing <ref> [4, 23] </ref>. 3.1 A marking example Before giving a formal presentation of the marking algorithm, we first illustrate the ideas through the program segment in Figure 1. In that segment, the scalars nr, nits and jmax are written only once, by processor p 0 .
References-found: 23

