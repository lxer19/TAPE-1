URL: ftp://speech.cse.ogi.edu/pub/docs/Fanty_Cityname_ICASSP93.ps.gz
Refering-URL: http://www.cse.ogi.edu/~philipp/vitae.html
Root-URL: http://www.cse.ogi.edu
Title: CITY NAME RECOGNITION OVER THE TELEPHONE  for Spoken Language Understanding  
Author: Mark Fanty Philipp Schmid Ronald Cole 
Address: 97006 1999 USA  
Affiliation: Center  Oregon Graduate Institute of Science Technology Beaverton, Oregon  
Abstract: We present a neural-network-based speech recognition system for telephone speech. A neural network classifier provides phoneme probabilities for each frame of the utterance. A dynamic programming algorithm finds the most probable sequence of words. The classifier was trained on a spoken name corpus which contained the test vocabulary and many other words. The test set consisted of 262 utterances containing 44 cities and 2 states. The best result obtained on the test set was 92.9% word accuracy (90.1% on just the city names). Removing phoneme duration constraints reduced recognition accuracy to 82%. Performance fell to 82.4% using a network trained on a large vocabulary, fluent-speech corpus. Several other experiments are reported which did not produce significant changes in system performance. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Cole, K. Roginski, and M. Fanty. </author> <title> A telephone speech database of spelled and spoken names. </title> <booktitle> In Proceedings of the International Conference on Spoken Language Processing, </booktitle> <year> 1992. </year>
Reference-contexts: The work reported here is a step in that direction. The task is city/state recognition; each utterance is either a single city name or a city/state pair. The utterances are from the Center for Spoken Language Understanding's telephone speech corpus of spelled and spoken names <ref> [1] </ref>. For this paper, we chose to test our system on 44 cities in Oregon and Washington. We first describe the recognition system and give results for our test set. <p> TRAINING AND TEST CORPUSUS We have collected a telephone speech corpus consisting of 3667 calls consisting mainly of spelled and spoken names <ref> [1] </ref>. For this study we used responses to the questions "What city are you calling from?", "What city and state did you grow up in?" and "What is your last name?" The phonetic classifier was trained on 910 hand-labeled responses|mostly city and state names. This is the "name" network.
Reference: [2] <author> H. Hermansky. </author> <title> Perceptual Linear Predictive (PLP) analysis of speech. </title> <journal> J. Acoust. Soc. Am., </journal> <volume> 87(4) </volume> <pages> 1738-1752, </pages> <year> 1990. </year>
Reference-contexts: Frame-Based Phonetic Classification. Telephone speech is sampled at 8 kHz at 14-bit resolution. Signal processing routines perform a seventh order PLP (Perceptual Linear Predictive) analysis <ref> [2] </ref> every 6 msec using a 10 msec window, yielding eight coefficients per frame. Frame-based phonetic classification provides estimates of phoneme probabilities. Classification is performed by a fully-connected three-layer feed-forward network that assigns 39 phonetic category scores to each 6 msec time frame.
Reference: [3] <author> N. Morgan and H. Bourlard. </author> <title> Continuous speech recognition using multilayer perceptrons with hidden markov models. </title> <booktitle> In Proceedings IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <pages> pages 413-416, </pages> <year> 1990. </year>
Reference-contexts: The network is trained using backpropagation. The outputs of the network are divided by the corresponding prior probabilities of the category labels in the training set <ref> [3] </ref>. 2.2. Broad-Phonetic Categories In addition to the phonetic output from the classifier, we compute probabilities for ten broad-phonetic categories by summing the outputs of phonemes in the broad class. This sum is divided by the summed prior probabilities. Table 1 shows the broad category definitions. 2.3.
Reference: [4] <author> P. Schmid, R. Cole, and M. Fanty. </author> <title> Automatically generated pronunciation models for segment based speech recognition. </title> <note> submitted to ICASSP 92, </note> <year> 1992. </year>
Reference-contexts: When these pronunciations were used, the word accuracy increased to 92.9% (90.1% on just the city names|see table 5). This increase was not significant (p = :11); however we still feel that matching expected pronunciations to the behavior of the classifier is a promising approach. See <ref> [4] </ref> in these proceedings for a report on automatically-derived pronunciation models. pronunciations all words just cities expert 92.0 88.2 hand-tuned to net 92.9 90.1 Table 5. Effect of hand-tuning pronunciations to match the behavior of the classifier. 5.5.
Reference: [5] <author> R. D. T. Janssen, M. Fanty, and R. A. Cole. </author> <title> Speaker-independent phonetic classification in continuous English letters. </title> <booktitle> In Proceedings of the International Joint Conference on Neural Networks, </booktitle> <address> Seattle, </address> <year> 1991. </year>
Reference-contexts: The second-pass neural network has as input a) the same PLP features used to train the first network and b) the average output of each phoneme from the first-pass net over the last 100 msec (an additional 39 features) <ref> [5] </ref>.
Reference: [6] <author> I. Lee Hetherington, Hong C. Leung, and Victor W. Zue. </author> <title> Toward vocabulary-independent recognition of telephone speech. </title> <booktitle> In Proceedings of the Second Euro-pean Conference on Speech Communication and Technology, </booktitle> <year> 1991. </year>
Reference-contexts: We also showed significant loss of performance when we removed the duration constraints (82%). We believe more accurate modeling of duration probabilities based on context will yield large improvements in recognition accuracy. This work is most similar to MIT's telephone city name system <ref> [6] </ref>. Using a vocabulary of 25 city names and data collected from real operator assistance calls, the authors achieved 93% performance when they trained on vocabulary words and 70.7% performance when they trained on out-of-vocabulary words [6]. <p> This work is most similar to MIT's telephone city name system <ref> [6] </ref>. Using a vocabulary of 25 city names and data collected from real operator assistance calls, the authors achieved 93% performance when they trained on vocabulary words and 70.7% performance when they trained on out-of-vocabulary words [6]. They improved the algorithm in [7] and achieved a very low error rate of 3%, or less if they allow rejections. MIT uses a segment-based approach to phoneme classification. The work described here uses a frame-based approach and has a mixed in- and out-of vocabulary training set.
Reference: [7] <author> Hong C. Leung, I. Lee Hetherington, and Victor W. Zue. </author> <title> Speech recognition using stochastic segment neural networks. </title> <booktitle> In Proceedings IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <pages> pages I 613-616, </pages> <year> 1992. </year>
Reference-contexts: Using a vocabulary of 25 city names and data collected from real operator assistance calls, the authors achieved 93% performance when they trained on vocabulary words and 70.7% performance when they trained on out-of-vocabulary words [6]. They improved the algorithm in <ref> [7] </ref> and achieved a very low error rate of 3%, or less if they allow rejections. MIT uses a segment-based approach to phoneme classification. The work described here uses a frame-based approach and has a mixed in- and out-of vocabulary training set. <p> There is growing evidence that fine phonetic distinctions can be performed using a segment-then-classify approach <ref> [7, 9] </ref>. Previous work on recognition of spoken English letters, a task that requires many fine phonetic distinctions (e.g., B/D, T/G, M/N), has used a segment-then-classify approach to first locate segments then reclassify them using linguistically motivated features.
Reference: [8] <author> Matthew Lennig, Douglas Sharp, Patrick Kenny, Vishwa Gupta, and Kristen Precoda. </author> <title> Flexible vocabulary recognition of speech. </title> <booktitle> In Proceedings International Conference on Spoken Language Processing, </booktitle> <pages> pages 93-96, </pages> <year> 1992. </year>
Reference-contexts: MIT uses a segment-based approach to phoneme classification. The work described here uses a frame-based approach and has a mixed in- and out-of vocabulary training set. Lennig et al. achieve very impressive results of 96% speaker-independent word recognition over the telephone using a 1561 word vocabulary <ref> [8] </ref>. They trained context-independent phoneme HMMs on data from the same task, but with a different vocabulary than the test set.
Reference: [9] <author> M. Fanty, R. A. Cole, and K. Roginski. </author> <title> English alphabet recognition with telephone speech. </title> <editor> In J. E. Moody, S. J. Hanson, and R. P. Lippman, editors, </editor> <booktitle> Advances in Neural Information Processing Systems 4. </booktitle> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann, </publisher> <year> 1992. </year>
Reference-contexts: There is growing evidence that fine phonetic distinctions can be performed using a segment-then-classify approach <ref> [7, 9] </ref>. Previous work on recognition of spoken English letters, a task that requires many fine phonetic distinctions (e.g., B/D, T/G, M/N), has used a segment-then-classify approach to first locate segments then reclassify them using linguistically motivated features.
Reference: [10] <author> R. A. Cole, M. Fanty, Y. Muthusamy, and M. Gopalakrishnan. </author> <title> Speaker-independent recognition of spoken English letters. </title> <booktitle> In Proceedings of the International Joint Conference on Neural Networks, </booktitle> <address> San Diego, CA, </address> <year> 1990. </year> <month> 4 </month>
References-found: 10

