URL: http://www.cs.tamu.edu/faculty/rwerger/pubs/1390.ps.gz
Refering-URL: http://www.cs.tamu.edu/faculty/rwerger/pubs/
Root-URL: http://www.cs.tamu.edu
Title: The LRPD Test: Speculative Run-Time Parallelization of Loops with Privatization and Reduction Parallelization  
Author: Lawrence Rauchwerger and David Padua 
Affiliation: University of Illinois at Urbana-Champaign  
Abstract: Current parallelizing compilers cannot identify a significant fraction of parallelizable loops because they have complex or statically insufficiently defined access patterns. As parallelizable loops arise frequently in practice, we advocate a novel framework for their identification: speculatively execute the loop as a doall, and apply a fully parallel data dependence test to determine if it had any cross-iteration dependences; if the test fails, then the loop is re-executed serially. Since, from our experience, a significant amount of the available parallelism in Fortran programs can be exploited by loops transformed through privatization and reduction paralleliza-tion, our methods can speculatively apply these transformations and then check their validity at run-time. Another important contribution of this paper is a novel method for reduction recognition which goes beyond syntactic pattern matching: it detects at run-time if the values stored in an array participate in a reduction operation, even if they are transferred through private variables and/or are affected by statically unpredictable control flow. We present experimental results on loops from the PERFECT Benchmarks which substantiate our claim that these techniques can yield significant speedups which are often superior to those obtainable by inspector/executor methods. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Abraham. </author> <title> Private communication, </title> <year> 1994. </year>
Reference-contexts: the phase ends. (Since we define (write) and use (read, but do not define) values stored at the same location in different iterations, there is at least one flow or anti dependence.) 3 any returns the OR of its vector operand's elements, i.e., any (v [1 : n]) = (v <ref> [1] </ref> _ v [2] _ : : : _ v [n]). (c) Else if tw (A) = tm (A), then the loop is a doall (without privatizing the array A). (Since we never overwrite any memory location, there are no output dependences.) (d) Else if any (A w [:] ^A np <p> Our basic strategy is to extend the LPD test to check all statically unverifiable reduction conditions. We first consider how the test 4 This fact was noted by Santosh Abraham <ref> [1] </ref>. 5 original shadow arrays PD test 1 2 3 4 tw tm A w 0 1 0 1 3 2 A np 1 1 1 1 A w (:) ^ A np (:) 0 1 0 1 new shadow arrays LPD test 1 2 3 4 tw tm A w
Reference: [2] <author> J. R. Allen, K. Kennedy, C. Porterfield, and J. Warren. </author> <title> Conversion of control dependence to data dependence. </title> <booktitle> In Proceedings of the 10th ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 177-189, </pages> <month> January </month> <year> 1983. </year>
Reference-contexts: (Since we define (write) and use (read, but do not define) values stored at the same location in different iterations, there is at least one flow or anti dependence.) 3 any returns the OR of its vector operand's elements, i.e., any (v [1 : n]) = (v [1] _ v <ref> [2] </ref> _ : : : _ v [n]). (c) Else if tw (A) = tm (A), then the loop is a doall (without privatizing the array A). (Since we never overwrite any memory location, there are no output dependences.) (d) Else if any (A w [:] ^A np [:]), then the <p> The general 7 strategy of our methods is a fairly straightforward demand driven forward substitution of all the variables on the RHS, a process by which all control flow dependences are substituted by data dependences as described in <ref> [2, 33] </ref>. Once this expression of the RHS is obtained it can be analyzed and validated by the methods described in the previous section.
Reference: [3] <institution> Alliant Computer Systems Corporation. FX/Series Architecture Manual, </institution> <year> 1986. </year>
Reference-contexts: Similarly, using hash tables the analysis phase and any needed last value assignments and/or processor-wise reduction operations can be performed in time O (na=p + log p). 5 Experimental Results In this section we present experimental results obtained on two modestly parallel machines with 8 (Alliant FX/80 <ref> [3] </ref>) and 14 processors (Alliant FX/2800 [4]) using a Fortran implementation of our run-time library. The codes have been manually instrumented with calls to the run-time library.
Reference: [4] <institution> Alliant Computers Systems Corporation. Alliant FX/2800 Series System Description, </institution> <year> 1991. </year> <month> 12 </month>
Reference-contexts: tables the analysis phase and any needed last value assignments and/or processor-wise reduction operations can be performed in time O (na=p + log p). 5 Experimental Results In this section we present experimental results obtained on two modestly parallel machines with 8 (Alliant FX/80 [3]) and 14 processors (Alliant FX/2800 <ref> [4] </ref>) using a Fortran implementation of our run-time library. The codes have been manually instrumented with calls to the run-time library.
Reference: [5] <author> R. Ballance, A. Maccabe, and K. Ottenstein. </author> <title> The Program Depen--dence Web: a Representation Supporting Control Data- and Demand-Driven Interpretation of Imperative Languages. </title> <booktitle> In Proceedings of the SIGPLAN'90 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 257-271, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: What is known, however, is the set of all possible RHS forms, which can be computed by following all potential paths in the control flow graph. A direct approach uses a gated static single assignment (GSSA) <ref> [5, 34] </ref> representation of the program. In such a representation, scalar variables are assigned only once.
Reference: [6] <author> U. Banerjee. </author> <title> Dependence Analysis for Supercomputing. </title> <publisher> Kluwer. </publisher> <address> Boston, MA., </address> <year> 1988. </year>
Reference-contexts: In order to determine whether or not the execution order of the data accesses affects the semantics of the loop, the data dependence relations between the statements in the loop body must be analyzed <ref> [6, 18, 25, 36, 39] </ref>. There are three possible types of dependences between two statements that access the same memory location: flow (read after write), anti (write after read), and output (write after write). Flow dependences express a fundamental relationship about the data flow in the program.
Reference: [7] <author> M. Berry, D. Chen, P. Koss, D. Kuck, S. Lo, Y. Pang, R. Roloff, A. Sameh, E. Clementi, S. Chin, D. Schneider, G. Fox, P. Messina, D. Walker, C. Hsiung, J. Schwarzmeier, K. Lue, S. Orzag, F. Seidl, O. Johnson, G. Swanson, R. Goodrum, and J. Martin. </author> <title> The PERFECT club benchmarks: Effective performance evaluation of supercomputers. </title> <type> Technical Report CSRD-827, </type> <institution> Center for Supercomputing Research and Development, University of Illinois, Urbana, IL, </institution> <month> May </month> <year> 1989. </year>
Reference-contexts: However, we remark that our results scale with the number of processors and the data size and thus they should be extrapolated for massively parallel processors (MPPs), the actual target of our run-time methods. We considered seven do loops from the PERFECT Benchmarks <ref> [7] </ref> that could not be parallelized by any compiler available to us. Our results are summarized in Table 1.
Reference: [8] <author> H. Berryman and J. Saltz. </author> <title> A manual for PARTI runtime primitives. </title> <type> Interim Report 90-13, </type> <institution> ICASE, </institution> <year> 1990. </year>
Reference-contexts: However, these methods are generally not appropriate for run-time loop parallelization since they are optimized for other purposes, e.g., for them minimizing memory requirements is more important than speed. i.e., without side effects <ref> [8, 20, 23, 26, 28, 29, 30, 37, 38, 12] </ref>. The inspection phase of these schemesusually yields a partitioning of the set of iterations into subsets that can be executed in parallel. These subsets, sometimes called wavefronts, are scheduled sequentially by placing synchronization barriers between them.
Reference: [9] <author> W. Blume and R. Eigenmann. </author> <title> Performance Analysis of Parallelizing Compilers on the Perfect Benchmarks T M Programs. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 3(6) </volume> <pages> 643-656, </pages> <month> November </month> <year> 1992. </year>
Reference-contexts: Thus, in order to realize the full potential of parallel computing it has become clear that static (compile-time) analysis must be complemented by new methods capable of automatically extracting parallelism at run-time <ref> [9, 11, 14] </ref>. Run-time techniques can succeed where static compilation fails because they have access to the input data. For example, input dependent or dynamic data distribution, memory accesses guarded by run-time dependent conditions, and subscript expressions can all be analyzed unambiguously at run-time.
Reference: [10] <author> M. Burke, R. Cytron, J. Ferrante, and W. Hsieh. </author> <title> Automatic generation of nested, fork-join parallelism. </title> <journal> Journal of Supercomputing, </journal> <pages> pages 71-88, </pages> <year> 1989. </year>
Reference-contexts: Privatization creates, for each processor cooperating on the execution of the loop, private copies of the program variables that give rise to anti or output dependences (see, e.g., <ref> [10, 21, 22, 32, 33] </ref>).
Reference: [11] <author> W. J. Camp, S. J. Plimpton, B. A. Hendrickson, and R. W. Leland. </author> <title> Massively parallel methods for engineering and science problems. </title> <journal> Comm. ACM, </journal> <volume> 37(4) </volume> <pages> 31-41, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: Typical examples are complex simulations such as SPICE for circuit simulation, DYNA-3D and PRONTO-3D for structural mechanics modeling, GAUSSIAN and DMOL for quantum mechanical simulation of molecules, CHARMM and DISCOVER for molecular dynamics simulation of organic systems, and FIDAP for modeling complex fluid flows <ref> [11] </ref>. Thus, in order to realize the full potential of parallel computing it has become clear that static (compile-time) analysis must be complemented by new methods capable of automatically extracting parallelism at run-time [9, 11, 14]. <p> Thus, in order to realize the full potential of parallel computing it has become clear that static (compile-time) analysis must be complemented by new methods capable of automatically extracting parallelism at run-time <ref> [9, 11, 14] </ref>. Run-time techniques can succeed where static compilation fails because they have access to the input data. For example, input dependent or dynamic data distribution, memory accesses guarded by run-time dependent conditions, and subscript expressions can all be analyzed unambiguously at run-time.
Reference: [12] <author> D. K. Chen, P. C. Yew, and J. Torrellas. </author> <title> An efficient algorithm for the run-time parallelization of doacross loops. </title> <booktitle> In Proceedings of Supercomputing 1994, </booktitle> <pages> pages 518-527, </pages> <month> Nov. </month> <year> 1994. </year>
Reference-contexts: However, these methods are generally not appropriate for run-time loop parallelization since they are optimized for other purposes, e.g., for them minimizing memory requirements is more important than speed. i.e., without side effects <ref> [8, 20, 23, 26, 28, 29, 30, 37, 38, 12] </ref>. The inspection phase of these schemesusually yields a partitioning of the set of iterations into subsets that can be executed in parallel. These subsets, sometimes called wavefronts, are scheduled sequentially by placing synchronization barriers between them.
Reference: [13] <author> A. Dinning and E. Schonberg. </author> <title> An empirical comparison of monitoring algorithms for access anomaly detection. </title> <booktitle> In Proc. of 2-nd ACM SIG-PLAN Symposium on Principles & Practice of Parallel Programming (PPOPP), </booktitle> <pages> pages 1-10, </pages> <year> 1990. </year>
Reference-contexts: Run-time analysis techniques have also been used to detect access anomalies or race conditions in parallel programs (see, e.g., <ref> [13, 24, 31] </ref>). However, these methods are generally not appropriate for run-time loop parallelization since they are optimized for other purposes, e.g., for them minimizing memory requirements is more important than speed. i.e., without side effects [8, 20, 23, 26, 28, 29, 30, 37, 38, 12].
Reference: [14] <author> R. Eigenmann, J. Hoeflinger, Z. Li, and D. Padua. </author> <title> Experience in the Automatic Parallelization of Four Perfect-Benchmark Programs. </title> <booktitle> Lecture Notes in Computer Science 589. Proceedings of the Fourth Workshop on Languagesand Compilers for Parallel Computing, </booktitle> <address> Santa Clara, CA, </address> <pages> pages 65-83, </pages> <month> August </month> <year> 1991. </year>
Reference-contexts: Thus, in order to realize the full potential of parallel computing it has become clear that static (compile-time) analysis must be complemented by new methods capable of automatically extracting parallelism at run-time <ref> [9, 11, 14] </ref>. Run-time techniques can succeed where static compilation fails because they have access to the input data. For example, input dependent or dynamic data distribution, memory accesses guarded by run-time dependent conditions, and subscript expressions can all be analyzed unambiguously at run-time. <p> One typical method is to transform the do loop into a doall and enclose the access to the reduction variable in an unordered critical section <ref> [14, 39] </ref>. Drawbacks of this method are that it is not scalable and requires synchronizations which can be very expensive in large multiprocessor systems.
Reference: [15] <author> V. Krothapalli and P. Sadayappan. </author> <title> An approach to synchronization of parallel computing. </title> <booktitle> In Proceedings of the 1988 International Conference on Supercomputing, </booktitle> <pages> pages 573-581, </pages> <month> June </month> <year> 1988. </year>
Reference-contexts: Compilers often transform programs to optimize performance. The two most effective transformations for increasing the amount of parallelism in a loop (i.e., removing certain types of data dependences) are array privatization and reduction parallelization. Krothapalli and Sadayappan <ref> [15] </ref> proposed an inspector method for run-time privatization which relies heavily on synchronization, inserts an additional level of indirection into all memory accesses, and calls for dynamic shared memory allocation.
Reference: [16] <author> C. Kruskal. </author> <title> Efficient parallel algorithms for graph problems. </title> <booktitle> In Proceedings of the 1985 International Conference on Parallel Processing, </booktitle> <month> August </month> <year> 1985. </year>
Reference-contexts: A scalable method can be obtained by noting that a reduction operation is an associative and commutative recurrence and can thus be parallelized using a recursive doubling algorithm <ref> [16, 17, 19] </ref>.
Reference: [17] <author> C. Kruskal. </author> <title> Efficient parallel algorithms for graph problems. </title> <booktitle> In Proceedings of the 1986 International Conference on Parallel Processing, </booktitle> <pages> pages 869-876, </pages> <month> August </month> <year> 1986. </year>
Reference-contexts: A scalable method can be obtained by noting that a reduction operation is an associative and commutative recurrence and can thus be parallelized using a recursive doubling algorithm <ref> [16, 17, 19] </ref>.
Reference: [18] <author> D. J. Kuck, R. H. Kuhn, D. A. Padua, B. Leasure, and M. Wolfe. </author> <title> Dependence graphs and compiler optimizations. </title> <booktitle> In Proceedings of the 8th ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 207-218, </pages> <month> January </month> <year> 1981. </year>
Reference-contexts: In order to determine whether or not the execution order of the data accesses affects the semantics of the loop, the data dependence relations between the statements in the loop body must be analyzed <ref> [6, 18, 25, 36, 39] </ref>. There are three possible types of dependences between two statements that access the same memory location: flow (read after write), anti (write after read), and output (write after write). Flow dependences express a fundamental relationship about the data flow in the program.
Reference: [19] <author> F. Thomson Leighton. </author> <title> Introduction to Parallel Algorithms and Architectures: Arrays, Trees, Hypercubes. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1992. </year>
Reference-contexts: A scalable method can be obtained by noting that a reduction operation is an associative and commutative recurrence and can thus be parallelized using a recursive doubling algorithm <ref> [16, 17, 19] </ref>. <p> The counting in Step 2 (a) can be done in parallel by giving each processor s=p values to add within its private memory, and then summing the p resulting values in global storage, which takes O (s=p + log p) time <ref> [19] </ref>. The comparisons in Step 2 (b) (2 (d)) of A w with A r (with A np and A nx ) take O (s=p + log p) time.
Reference: [20] <author> S. Leung and J. Zahorjan. </author> <title> Improving the performance of runtime parallelization. </title> <booktitle> In 4th PPOPP, </booktitle> <pages> pages 83-91, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: Although more powerful analysis techniques could remove this last limitation when the index arrays are computed using only statically-known values, nothing can be done at compile-time when the index arrays are a function of the input data <ref> [20, 30, 38] </ref>. <p> However, these methods are generally not appropriate for run-time loop parallelization since they are optimized for other purposes, e.g., for them minimizing memory requirements is more important than speed. i.e., without side effects <ref> [8, 20, 23, 26, 28, 29, 30, 37, 38, 12] </ref>. The inspection phase of these schemesusually yields a partitioning of the set of iterations into subsets that can be executed in parallel. These subsets, sometimes called wavefronts, are scheduled sequentially by placing synchronization barriers between them.
Reference: [21] <author> Zhiyuan Li. </author> <title> Array privatization for parallel execution of loops. </title> <booktitle> In Proceedings of the 19th International Symposium on Computer Architecture, </booktitle> <pages> pages 313-322, </pages> <year> 1992. </year>
Reference-contexts: Privatization creates, for each processor cooperating on the execution of the loop, private copies of the program variables that give rise to anti or output dependences (see, e.g., <ref> [10, 21, 22, 32, 33] </ref>).
Reference: [22] <author> D. E. Maydan, S. P. Amarasinghe, and M. S. Lam. </author> <title> Data dependence and data-flow analysis of arrays. </title> <booktitle> In Proceedings 5th Workshop on Programming Languages and Compilers for Parallel Computing, </booktitle> <month> August </month> <year> 1992. </year>
Reference-contexts: Privatization creates, for each processor cooperating on the execution of the loop, private copies of the program variables that give rise to anti or output dependences (see, e.g., <ref> [10, 21, 22, 32, 33] </ref>).
Reference: [23] <author> S. Midkiff and D. Padua. </author> <title> Compiler algorithms for synchronization. </title> <journal> IEEE Trans. Comput., </journal> <volume> C-36(12):1485-1495, </volume> <year> 1987. </year>
Reference-contexts: However, these methods are generally not appropriate for run-time loop parallelization since they are optimized for other purposes, e.g., for them minimizing memory requirements is more important than speed. i.e., without side effects <ref> [8, 20, 23, 26, 28, 29, 30, 37, 38, 12] </ref>. The inspection phase of these schemesusually yields a partitioning of the set of iterations into subsets that can be executed in parallel. These subsets, sometimes called wavefronts, are scheduled sequentially by placing synchronization barriers between them.
Reference: [24] <author> I. Nudler and L. Rudolph. </author> <title> Tools for the efficient developement of efficient parallel programs. </title> <booktitle> In Proc. 1st Israeli Conference on Computer System Engineering, </booktitle> <year> 1988. </year>
Reference-contexts: Run-time analysis techniques have also been used to detect access anomalies or race conditions in parallel programs (see, e.g., <ref> [13, 24, 31] </ref>). However, these methods are generally not appropriate for run-time loop parallelization since they are optimized for other purposes, e.g., for them minimizing memory requirements is more important than speed. i.e., without side effects [8, 20, 23, 26, 28, 29, 30, 37, 38, 12].
Reference: [25] <author> D. A. Padua and M. J. Wolfe. </author> <title> Advanced compiler optimizations for supercomputers. </title> <journal> Communications of the ACM, </journal> <volume> 29 </volume> <pages> 1184-1201, </pages> <month> De-cember </month> <year> 1986. </year>
Reference-contexts: This work is not necessarily representative of the positions or policies of the Army or the Government. Although compiler techniques for the automatic detection of parallelism have been studied extensively over the last two decades (see, e.g., <ref> [25, 36] </ref>), current parallelizing compilers cannot extract a significant fraction of the available parallelism in a loop if it has a complex and/or statically insufficiently defined access pattern. <p> In order to determine whether or not the execution order of the data accesses affects the semantics of the loop, the data dependence relations between the statements in the loop body must be analyzed <ref> [6, 18, 25, 36, 39] </ref>. There are three possible types of dependences between two statements that access the same memory location: flow (read after write), anti (write after read), and output (write after write). Flow dependences express a fundamental relationship about the data flow in the program.
Reference: [26] <author> L. Rauchwerger and D. Padua. </author> <title> The privatizing doall test: A run-time technique for doall loop identification and array privatization. </title> <booktitle> In Proceedingsof the 1994 International Conference on Supercomputing, </booktitle> <pages> pages 33-43, </pages> <month> July </month> <year> 1994. </year>
Reference-contexts: whose parallelization requires synchronization to ensure that the iterations are executed in the correct order. 1 These methods are centered around the extraction of an inspector loop that analyzes the data access pattern off-line, 1 The only exception of which we are aware is our inspector method for doall parallelization <ref> [26] </ref>. Run-time analysis techniques have also been used to detect access anomalies or race conditions in parallel programs (see, e.g., [13, 24, 31]). <p> However, these methods are generally not appropriate for run-time loop parallelization since they are optimized for other purposes, e.g., for them minimizing memory requirements is more important than speed. i.e., without side effects <ref> [8, 20, 23, 26, 28, 29, 30, 37, 38, 12] </ref>. The inspection phase of these schemesusually yields a partitioning of the set of iterations into subsets that can be executed in parallel. These subsets, sometimes called wavefronts, are scheduled sequentially by placing synchronization barriers between them. <p> from previous methods in two major points. * Instead of finding a valid parallel execution schedule for the loop, we focus on the problem of simply deciding if the loop is fully parallel, that is, determining whether or not the loop has cross-iteration dependences. (This approach was also taken in <ref> [26] </ref>.) * Instead of distributing the loop into inspector and executor loops, we speculatively execute the loop as a doall, i.e., execute all its iterations concurrently, and apply a run-time test to check if there were any cross-iteration dependences. <p> Krothapalli and Sadayappan [15] proposed an inspector method for run-time privatization which relies heavily on synchronization, inserts an additional level of indirection into all memory accesses, and calls for dynamic shared memory allocation. In our previous work <ref> [26] </ref> we gave an inspector method without these drawbacks for determining whether a do loop can be executed as a doall, perhaps by privatizing some shared variables. No previous run-time methods have been proposed for parallelizing reduction operations. <p> The new algorithms consider only data dependences caused by actual cross-iteration data-flow (a flow of values). Thus, they may potentially qualify more loops as parallel than the method in <ref> [26] </ref> which conservatively considered the dependences due to every memory reference even if no cross-iteration data-flow occurred at run-time. This situation could arise for example when a loop reads a shared variable, but then only uses it conditionally. <p> Since predicates seldom can be evaluated statically, the compiler must be conservative and conclude that the read access causes a dependence in every iteration of the loop. The test given here improves upon the Privatizing doall test described in <ref> [26] </ref> by checking only the dynamic data dependences caused by the actual cross-iteration flow of values stored in the shared arrays. This is accomplished using a technique we call dynamic dead reference elimination which is explained in detail following the description of the test. <p> As can be observed from the example in Fig. 3.1, this method allows the LPD test to qualify more loops for parallel execution then would be otherwise possible by just inspecting the memory references as in the original PD test <ref> [26] </ref>. In particular, after marking and counting we obtain the results depicted in the tables. The loop fails the PD test since A w (:) ^ A r (:) is not zero everywhere (Step 2 (b)).
Reference: [27] <author> Lawrence Rauchwerger and David A. Padua. </author> <title> Parallelizing WHILE Loops for MultiprocessorSystems. </title> <booktitle> In Proceedingsof 9th International Parallel Processing Symposium, </booktitle> <month> April </month> <year> 1995. </year>
Reference-contexts: The ideal speedup of loop 40 is not very large since the loop is small, imbalanced between iterations, and traverses a linked list. The linked list traversal was parallelized using techniques we developed for automatically parallelizing while loops <ref> [27] </ref>. Thus, although the obtained speedup is modest, it represents a significant fraction of the ideal speedup (see Fig. 14). Therefore, since loop 40 is one of the smallest loops in the LOAD subroutine, we expect to obtain better speedups on the larger loops (since they have larger ideal speedups).
Reference: [28] <author> J. Saltz and R. Mirchandaney. </author> <title> The preprocessed doacross loop. In Dr. </title> <editor> H.D. Schwetman, editor, </editor> <booktitle> Proceedings of the 1991 International Conference on Parallel Processing, </booktitle> <pages> pages 174-178. </pages> <publisher> CRC Press, Inc., </publisher> <year> 1991. </year> <title> Vol. </title> <booktitle> II Software. </booktitle>
Reference-contexts: However, these methods are generally not appropriate for run-time loop parallelization since they are optimized for other purposes, e.g., for them minimizing memory requirements is more important than speed. i.e., without side effects <ref> [8, 20, 23, 26, 28, 29, 30, 37, 38, 12] </ref>. The inspection phase of these schemesusually yields a partitioning of the set of iterations into subsets that can be executed in parallel. These subsets, sometimes called wavefronts, are scheduled sequentially by placing synchronization barriers between them.
Reference: [29] <author> J. Saltz, R. Mirchandaney, and K. Crowley. </author> <title> The doconsider loop. </title> <booktitle> In Proceedingsof the 1989 International Conference on Supercomputing, </booktitle> <pages> pages 29-40, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: However, these methods are generally not appropriate for run-time loop parallelization since they are optimized for other purposes, e.g., for them minimizing memory requirements is more important than speed. i.e., without side effects <ref> [8, 20, 23, 26, 28, 29, 30, 37, 38, 12] </ref>. The inspection phase of these schemesusually yields a partitioning of the set of iterations into subsets that can be executed in parallel. These subsets, sometimes called wavefronts, are scheduled sequentially by placing synchronization barriers between them.
Reference: [30] <author> J. Saltz, R. Mirchandaney, and K. Crowley. </author> <title> Run-time parallelization and scheduling of loops. </title> <journal> IEEE Trans. Comput., </journal> <volume> 40(5), </volume> <month> May </month> <year> 1991. </year>
Reference-contexts: Although more powerful analysis techniques could remove this last limitation when the index arrays are computed using only statically-known values, nothing can be done at compile-time when the index arrays are a function of the input data <ref> [20, 30, 38] </ref>. <p> However, these methods are generally not appropriate for run-time loop parallelization since they are optimized for other purposes, e.g., for them minimizing memory requirements is more important than speed. i.e., without side effects <ref> [8, 20, 23, 26, 28, 29, 30, 37, 38, 12] </ref>. The inspection phase of these schemesusually yields a partitioning of the set of iterations into subsets that can be executed in parallel. These subsets, sometimes called wavefronts, are scheduled sequentially by placing synchronization barriers between them.
Reference: [31] <author> E. Schonberg. </author> <title> On-the-fly detection of access anomalies. </title> <booktitle> In Proceedings of the SIGPLAN 1989 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 285-297, </pages> <address> Portland, Oregon, </address> <year> 1989. </year>
Reference-contexts: Run-time analysis techniques have also been used to detect access anomalies or race conditions in parallel programs (see, e.g., <ref> [13, 24, 31] </ref>). However, these methods are generally not appropriate for run-time loop parallelization since they are optimized for other purposes, e.g., for them minimizing memory requirements is more important than speed. i.e., without side effects [8, 20, 23, 26, 28, 29, 30, 37, 38, 12].
Reference: [32] <author> P. Tu and D. Padua. </author> <title> Array privatization for shared and distributed memory machines. </title> <booktitle> In Proceedings 2nd Workshop on Languages,Compilers, and Run-Time Environments for Distributed Memory Machines, </booktitle> <month> September </month> <year> 1992. </year>
Reference-contexts: Privatization creates, for each processor cooperating on the execution of the loop, private copies of the program variables that give rise to anti or output dependences (see, e.g., <ref> [10, 21, 22, 32, 33] </ref>).
Reference: [33] <author> P. Tu and D. Padua. </author> <title> Automatic array privatization. </title> <booktitle> In Proceedings 6th Annual Workshop on Languages and Compilers for Parallel Computing, </booktitle> <address> Portland, OR, </address> <month> August </month> <year> 1993. </year>
Reference-contexts: Privatization creates, for each processor cooperating on the execution of the loop, private copies of the program variables that give rise to anti or output dependences (see, e.g., <ref> [10, 21, 22, 32, 33] </ref>). <p> The general 7 strategy of our methods is a fairly straightforward demand driven forward substitution of all the variables on the RHS, a process by which all control flow dependences are substituted by data dependences as described in <ref> [2, 33] </ref>. Once this expression of the RHS is obtained it can be analyzed and validated by the methods described in the previous section.
Reference: [34] <author> Peng Tu and David Padua. </author> <title> GSA based demand-driven symbolic analysis. </title> <type> Technical Report 1339, </type> <institution> University of Illinois at Urbana-Champaign, Cntr for Supercomputing Res & Dev, </institution> <month> February </month> <year> 1994. </year>
Reference-contexts: What is known, however, is the set of all possible RHS forms, which can be computed by following all potential paths in the control flow graph. A direct approach uses a gated static single assignment (GSSA) <ref> [5, 34] </ref> representation of the program. In such a representation, scalar variables are assigned only once.
Reference: [35] <author> A. Vladimirescu. </author> <title> LSI Circuit Simulation on Vector Computers. </title> <type> PhD thesis, </type> <institution> Electronics Research Laboratory, University of California, Berkeley, </institution> <month> October </month> <year> 1982. </year> <note> Technical Rept. No. UCB/ERL M82/75. </note>
Reference-contexts: It is important to note that the loop in Fig. 6 exemplifies the type of loop found in the SPICE2G6 program (subroutine LOAD) which can account for 70% of the sequential execution time (Its vectorization has dealt with before <ref> [35] </ref>). Finally we mention that reductions such as min, max, etc., would first have to be syntactically pattern matched, and then substituted by the min and max functions. From this perspective, they are more difficult to recognize than simpler arithmetic reductions.
Reference: [36] <author> M. Wolfe. </author> <title> Optimizing Compilers for Supercomputers. </title> <publisher> The MIT Press, </publisher> <address> Boston, MA, </address> <year> 1989. </year>
Reference-contexts: This work is not necessarily representative of the positions or policies of the Army or the Government. Although compiler techniques for the automatic detection of parallelism have been studied extensively over the last two decades (see, e.g., <ref> [25, 36] </ref>), current parallelizing compilers cannot extract a significant fraction of the available parallelism in a loop if it has a complex and/or statically insufficiently defined access pattern. <p> In order to determine whether or not the execution order of the data accesses affects the semantics of the loop, the data dependence relations between the statements in the loop body must be analyzed <ref> [6, 18, 25, 36, 39] </ref>. There are three possible types of dependences between two statements that access the same memory location: flow (read after write), anti (write after read), and output (write after write). Flow dependences express a fundamental relationship about the data flow in the program.
Reference: [37] <author> J. Wu, J. Saltz, S. Hiranandani, and H. Berryman. </author> <title> Runtime compilation methods for multicomputers. In Dr. </title> <editor> H.D. Schwetman, editor, </editor> <booktitle> Proceedings of the 1991 International Conference on Parallel Processing, </booktitle> <pages> pages 26-30. </pages> <publisher> CRC Press, Inc., </publisher> <year> 1991. </year> <title> Vol. </title> <booktitle> II Software. </booktitle>
Reference-contexts: However, these methods are generally not appropriate for run-time loop parallelization since they are optimized for other purposes, e.g., for them minimizing memory requirements is more important than speed. i.e., without side effects <ref> [8, 20, 23, 26, 28, 29, 30, 37, 38, 12] </ref>. The inspection phase of these schemesusually yields a partitioning of the set of iterations into subsets that can be executed in parallel. These subsets, sometimes called wavefronts, are scheduled sequentially by placing synchronization barriers between them.
Reference: [38] <author> C. Zhu and P. C. Yew. </author> <title> A scheme to enforce data dependence on large multiprocessor systems. </title> <journal> IEEE Trans. Softw. Eng., </journal> 13(6) 726-739,June 1987. 
Reference-contexts: Although more powerful analysis techniques could remove this last limitation when the index arrays are computed using only statically-known values, nothing can be done at compile-time when the index arrays are a function of the input data <ref> [20, 30, 38] </ref>. <p> However, these methods are generally not appropriate for run-time loop parallelization since they are optimized for other purposes, e.g., for them minimizing memory requirements is more important than speed. i.e., without side effects <ref> [8, 20, 23, 26, 28, 29, 30, 37, 38, 12] </ref>. The inspection phase of these schemesusually yields a partitioning of the set of iterations into subsets that can be executed in parallel. These subsets, sometimes called wavefronts, are scheduled sequentially by placing synchronization barriers between them.
Reference: [39] <author> H. Zima. </author> <title> Supercompilers for Parallel and Vector Computers. </title> <publisher> ACM Press, </publisher> <address> New York, New York, </address> <year> 1991. </year> <pages> 13 14 15 </pages>
Reference-contexts: In order to determine whether or not the execution order of the data accesses affects the semantics of the loop, the data dependence relations between the statements in the loop body must be analyzed <ref> [6, 18, 25, 36, 39] </ref>. There are three possible types of dependences between two statements that access the same memory location: flow (read after write), anti (write after read), and output (write after write). Flow dependences express a fundamental relationship about the data flow in the program. <p> One typical method is to transform the do loop into a doall and enclose the access to the reduction variable in an unordered critical section <ref> [14, 39] </ref>. Drawbacks of this method are that it is not scalable and requires synchronizations which can be very expensive in large multiprocessor systems. <p> this problem has been handled at compile-time by syntactically pattern matching the loop statements with a template of a generic reduction, and then performing a data dependence analysis of the variable under scrutiny to guarantee that it is not used anywhere else in the loop except in the reduction statement <ref> [39] </ref>. 3 Speculative Parallel Execution of do Loops Consider a do loop for which the compiler cannot statically determine the access pattern of a shared array A that is referenced in the loop. <p> So far the problem of reduction variable recognition has been handled at compile-time by syntactically pattern matching the loop statements with a template of a generic reduction, and then performing a data dependence analysis of the variable under scrutiny to validate it as a reduction variable <ref> [39] </ref>. There are two major shortcomings of such pattern matching identification methods. 1. The data dependence analysis necessary to qualify a statement as a reduction cannot be performed statically in the presence of input-dependent access patterns. 2.
References-found: 39

