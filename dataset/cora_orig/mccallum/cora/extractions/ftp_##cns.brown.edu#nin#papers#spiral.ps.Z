URL: ftp://cns.brown.edu/nin/papers/spiral.ps.Z
Refering-URL: http://www.ph.tn.tudelft.nl/PRInfo/reports/msg00155.html
Root-URL: 
Title: Bootstrapping with Noise: An Effective Regularization Technique  
Author: Yuval Raviv Nathan Intrator 
Keyword: Noise Injection, Combining Estimators, Pattern Classification, Two Spiral Problem Clinical Data Analysis.  
Note: To appear: Connection Science Special Issue on Combining estimators,  
Address: Ramat Aviv 69978, Israel  
Affiliation: School of Mathematical Sciences Sackler Faculty of Exact Sciences Tel-Aviv University  
Email: fyuv,ning@math.tau.ac.il  
Date: July, 1996  1996.  
Abstract: Bootstrap samples with noise are shown to be an effective smoothness and capacity control technique for training feed-forward networks and for other statistical methods such as generalized additive models. It is shown that noisy bootstrap performs best in conjunction with weight decay regularization and ensemble averaging. The two-spiral problem, a highly non-linear noise-free data, is used to demonstrate these findings. The combination of noisy bootstrap and ensemble averaging is also shown useful for generalized additive modeling, and is also demonstrated on the well known Cleveland Heart Data [7].
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E. Baum and K. Lang. </author> <title> Constructing hidden units using examples and queries. </title> <editor> In R. P. Lipp-mann, J. E. Moody, and D. S. Touretzky, editors, </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> volume 3, </volume> <pages> pages 904-910. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1991. </year>
Reference-contexts: They used a variant of the quick-prop learning algorithm [10] with weight decay. They claimed that the problem could not be solved with simpler architecture (i.e. less layers or without short-cuts). Their result on the same data-set seems to give poor generalization results. Baum and Lang <ref> [1] </ref> demonstrated that there are many sets of weights that would cause a 2 50 1 network to be consistent with the training set, however, the single layer feed-forward architecture trained with error back-propagation was unable to find any of them when starting with random initial weights.
Reference: [2] <author> C. M. Bishop. </author> <title> Training with noise is equivalent to Tikhonov regularization. </title> <journal> Neural Computation, </journal> <volume> 7(1) </volume> <pages> 108-116, </pages> <year> 1995. </year>
Reference-contexts: For classification problems, the form y = f (x + *); may be more appropriate. In this case, using noise injection to the inputs during training, can improve the generalization properties of the estimator [28]. Recently, Bishop <ref> [2] </ref> have shown that training with small amounts of noise is locally equivalent to smoothness regularization.
Reference: [3] <author> P. Brazdil and R. Henery. </author> <title> Analysis of results (ch. 10). </title> <editor> In D. Michie, D. J. Spiegelhalter, and C. C. Taylor, editors, </editor> <booktitle> Machine Learning, Neural and Statistical Classification, </booktitle> <pages> pages 175-212. </pages> <publisher> Ellis Horwood, </publisher> <year> 1994. </year> <note> http://www.up.pt/liacc/ML/statlog/datasets/heart/heart.use.html. </note>
Reference-contexts: Robert Detrano 4 to the UCI Machine-Learning repository [25]. This data concerns diagnosis of coronary artery disease and has been used in the past by statisticians and by the machine learning community <ref> [7, 12, 29, 3, for review] </ref>. Further data and preprocessing details are given in Appendix B. The preprocessing, which included removal of missing values, sphering the data and creating dummy variables to replace categorial variables, resulted in a dramatic improvement over past results. <p> It is thus a very challenging problem to neural networks as deviation from linear structure is very small 6 , and highly nonlinear estimators such as CART, Radial-Basis Functions and K-NN did not do so well on this data <ref> [3] </ref>. The problem is complementary to the spiral problem that was considered before; There, we attempted to improve performance on a highly nonlinear data which required a large capacity network, while here we try to improve performance on a relatively linear problem using a small capacity network. <p> The cross-validation code is based 6 This is a classical problem in clinical data, in which variable selection was done by a linear method, and therefore, the data contains mostly variables with linear structure. 7 This is a standard use, see e.g. results under the STATLOG ESPRIT project <ref> [3] </ref>. 15 9 Hidden-Unit Network Right: ROC values. Noise injection is helpful in this case as well, while the overall performance is suboptimal. Noise levels represent the standard deviation (SD) of the zero-mean noise Gaussian. on the public domain version of Tibshirani in Statlib 8 .
Reference: [4] <author> L. Breiman. </author> <title> Bagging predictors. </title> <type> Technical Report TR-421, </type> <institution> Department of Statistics, University of California, Berkeley, </institution> <year> 1994. </year>
Reference-contexts: The success of ensemble averaging of neural networks in the past <ref> [15, 31, 4, 26] </ref> is due to the fact that neural networks have in general many local minima, and thus even with the same training set, different local minima are found when starting from different random initial conditions. <p> These different local minima lead to somewhat independent predictors, and thus, the averaging can reduce the variance. When a larger set of independent networks is needed, but no more data is available, data reuse methods can be of help. Bootstrapping <ref> [4] </ref> has been very helpful, since by resampling (with return) from the training data, the independence of the training sets is increased, and hence, the independence of the estimators, leading to improved ensemble results. <p> The large variance of each single network in the ensemble can be tempered with a regularization such as weight decay [21, 27, for review], but 5 again, the estimation of the optimal regularization factor should be done on the ensemble-averaged performance. Breiman <ref> [4] </ref> and Ripley [27] show compelling empirical evidence for the importance of weight decay as a single network stabilizer. Our results confirm this fact under the BEN model.
Reference: [5] <author> G. Deffuant. </author> <title> An algorithm for building regularized piecewise linear discrimination surfaces: The percpectron membrane. </title> <journal> Neural Computation, </journal> <volume> 7 </volume> <pages> 480-489, </pages> <year> 1995. </year>
Reference-contexts: Fahlman [9] used the Cascade-Correlation architecture for this problem. He got better results, but still little "spiralness". Recently Deffuant <ref> [5] </ref> suggested the "Perceptron Membrane" method that uses piecewise linear surfaces as discriminators, and applied it to the spiral problem. He used 29 perceptrons but had difficulties capturing the structure of the spirals due to the piecewise linearity of his decision boundaries.
Reference: [6] <author> R. Detrano. </author> <title> Accuracy curves: An alternative graphical representation of probability data. </title> <journal> Journal of Clinical Epidemiology, </journal> <volume> 42 </volume> <pages> 983-986, </pages> <year> 1989. </year>
Reference-contexts: The Receiver Operating Characteristic (ROC) [13, 14] is frequently used in such model comparisons, especially in clinical data [18, for review]. This measure has been used by the contributor of the data <ref> [6] </ref> and in assessing neural network performance on another heart disease data [24]. by error rate and ROC values are slightly worse (not statistically significant) compared with logistic regression, and can not be improved by weight decay regularization alone. architecture of 9 hidden units.
Reference: [7] <author> R. Detrano, A. Janosi, W. Steinbrunn, M. Pfisterer, J. Schmid, S. Sandhu, K. Guppy, S. Lee, and V. Froelicher. </author> <title> International application of a new probability algorithm for the diagnosis of coronary artery disease. </title> <journal> American Journal of Cardiology, </journal> <volume> 64 </volume> <pages> 304-310, </pages> <year> 1989. </year> <month> 20 </month>
Reference-contexts: In addition to demonstrating our method on a different class of predictors the generalized additive models, we also apply it to another well known data-set the Cleveland Heart Data <ref> [7] </ref>. 2 Theoretical considerations There are a number of factors that have to be applied carefully when trying to regularize an estimator. <p> Figure 5 depicts the results for various degrees of noise, added during training. It is clear that the bootstrap improves results, and furthermore, small values of the noise sharpen the result. 5 Cleveland Heart Data In this section, we analyze the Cleveland Heart data <ref> [7] </ref>, donated by Dr. Robert Detrano 4 to the UCI Machine-Learning repository [25]. This data concerns diagnosis of coronary artery disease and has been used in the past by statisticians and by the machine learning community [7, 12, 29, 3, for review]. <p> Robert Detrano 4 to the UCI Machine-Learning repository [25]. This data concerns diagnosis of coronary artery disease and has been used in the past by statisticians and by the machine learning community <ref> [7, 12, 29, 3, for review] </ref>. Further data and preprocessing details are given in Appendix B. The preprocessing, which included removal of missing values, sphering the data and creating dummy variables to replace categorial variables, resulted in a dramatic improvement over past results. <p> B Details and preprocessing of the Cleveland Heart data The data in the UCI repository contains 13 variables out of about 70 that were in the original study <ref> [7] </ref>. The task is to predict the existence of a coronary artery disease (CAD) based on the measurements. Data for 303 patients was obtained, 44% of the patients were diagnosed with CAD. The variable attributes are: 1. Age 3. Chest pain type (4 values converted to 3 binary variables) 4.
Reference: [8] <author> B. Efron and R. Tibshirani. </author> <title> An Introduction to the Bootstrap. </title> <publisher> Chapman and Hall, </publisher> <address> New York, </address> <year> 1993. </year>
Reference-contexts: 1 Introduction The bootstrap technique has become one of the major tools for producing empirical confidence intervals of estimated parameters or predictors <ref> [8] </ref>. One way to view bootstrap is as a method to simulate noise inherent in the data, and thus, increase effectively the number of training patterns. <p> Clearly, this approach can be easily extended to a smoothed bootstrap <ref> [8] </ref> by sampling from the empirical distribution defined by * i rather than just sampling from the set of * i 's. In such case, one can increase the size of each bootstrap set, since due to the noise, the different sets are sufficiently independent. <p> Bootstrapping [4] has been very helpful, since by resampling (with return) from the training data, the independence of the training sets is increased, and hence, the independence of the estimators, leading to improved ensemble results. Smoothed bootstrap <ref> [8] </ref> is potentially more useful since larger sets of independent training samples can be generated.
Reference: [9] <author> S. E. Fahlman and C. Lebiere. </author> <title> The cascade-correlation learning architecture. </title> <institution> Cmu-cs-90-100, Carnegie Mellon University, </institution> <year> 1990. </year>
Reference-contexts: Fahlman <ref> [9] </ref> used the Cascade-Correlation architecture for this problem. He got better results, but still little "spiralness". Recently Deffuant [5] suggested the "Perceptron Membrane" method that uses piecewise linear surfaces as discriminators, and applied it to the spiral problem.
Reference: [10] <author> S.E. Fahlman. </author> <title> Fast-learning variations on back-propagation: An empirical study. </title> <editor> In D. Touret-zky, G. Hinton, and T. Sejnowski, editors, </editor> <booktitle> Proceedings of the 1988 Connectionist Models Summer School, </booktitle> <pages> pages 38-51, </pages> <address> San Mateo, 1989. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: It is easy to see that the 2D points of the spirals could not be separated by small combination of linear separators. Lang and Witbrock [22] proposed a 2 5 5 5 1 network with short-cuts using 138 weights. They used a variant of the quick-prop learning algorithm <ref> [10] </ref> with weight decay. They claimed that the problem could not be solved with simpler architecture (i.e. less layers or without short-cuts). Their result on the same data-set seems to give poor generalization results.
Reference: [11] <author> S. Geman, E. Bienenstock, and R. Doursat. </author> <title> Neural networks and the bias-variance dilemma. </title> <journal> Neural Computation, </journal> <volume> 4 </volume> <pages> 1-58, </pages> <year> 1992. </year>
Reference-contexts: The regularization is aimed at finding an optimal tradeoff between the variance and bias of the estimator <ref> [11] </ref>, and for best performance, one has to utilize this decomposition of the 2 error function. <p> To further see the performance under MSE we decompose the error to bias and variance components <ref> [11] </ref> to get E D [(f D (x) E [yjx]) 2 ] = (E D [f D (x)] E [yjx]) 2 + E D [(f D (x) E D [f D (x)]) 2 ]: (1) The first RHS term is called the bias of the estimator and the second term is
Reference: [12] <author> J. H. Gennari, P. Langley, and D. Fisher. </author> <title> Models of incremental concept formation. </title> <journal> Artificial Intelligence, </journal> <volume> 40 </volume> <pages> 11-61, </pages> <year> 1988. </year>
Reference-contexts: Robert Detrano 4 to the UCI Machine-Learning repository [25]. This data concerns diagnosis of coronary artery disease and has been used in the past by statisticians and by the machine learning community <ref> [7, 12, 29, 3, for review] </ref>. Further data and preprocessing details are given in Appendix B. The preprocessing, which included removal of missing values, sphering the data and creating dummy variables to replace categorial variables, resulted in a dramatic improvement over past results.
Reference: [13] <author> D. J. Goodenough, K. Rossmann, and L. B. Lusted. </author> <title> Radiographic applications of receiver operating characteristic (ROC) curves. </title> <journal> Radiology, </journal> <volume> 110 </volume> <pages> 89-95, </pages> <year> 1974. </year>
Reference-contexts: For example, if one class represents only 10% of the data, then setting up the threshold to 1 will result in a trivial classifier that will produce zero regardless of the input and will have only 10% error. The Receiver Operating Characteristic (ROC) <ref> [13, 14] </ref> is frequently used in such model comparisons, especially in clinical data [18, for review].
Reference: [14] <author> J. A. Hanley and B. J. McNeil BJ. </author> <title> The meaning and use of the area under a reciever operating characteristic (ROC) curve. </title> <journal> Radiology, </journal> <volume> 143 </volume> <pages> 29-36, </pages> <year> 1982. </year>
Reference-contexts: For example, if one class represents only 10% of the data, then setting up the threshold to 1 will result in a trivial classifier that will produce zero regardless of the input and will have only 10% error. The Receiver Operating Characteristic (ROC) <ref> [13, 14] </ref> is frequently used in such model comparisons, especially in clinical data [18, for review].
Reference: [15] <author> L. K. Hansen and P. Salamon. </author> <title> Neural networks ensembles. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 12 </volume> <pages> 993-1001, </pages> <year> 1990. </year>
Reference-contexts: The success of ensemble averaging of neural networks in the past <ref> [15, 31, 4, 26] </ref> is due to the fact that neural networks have in general many local minima, and thus even with the same training set, different local minima are found when starting from different random initial conditions.
Reference: [16] <author> T. Hastie and R. Tibshirani. </author> <title> Generalized additive models. </title> <journal> Statistical Science, </journal> <volume> 1 </volume> <pages> 297-318, </pages> <year> 1986. </year>
Reference-contexts: Instead of analyzing a method that has hard time with the spiral data, we study a model that is very natural for it. We apply bootstrapping to a generalized additive model (GAM) <ref> [16, 17] </ref> with a polynomial fit of degree 1 on the same data. We had to optimize the degree of the polynomial and the span degree, which determines the smoothness and the degree of locality of the estimation 3 . <p> Our conclusions are not restricted to artificial neural network estimation. We show that similar conclusions can be obtained when using a highly flexible generalized additive model (GAM) <ref> [16] </ref>. Acknowledgements Stimulating discussions with Leo Breiman, Brian Ripley and Chris Bishop are greatfully acknowledged.
Reference: [17] <author> T. Hastie and R. Tibshirani. </author> <title> Generalized Additive Models. </title> <publisher> Chapman and Hall, </publisher> <address> London, </address> <year> 1990. </year>
Reference-contexts: Instead of analyzing a method that has hard time with the spiral data, we study a model that is very natural for it. We apply bootstrapping to a generalized additive model (GAM) <ref> [16, 17] </ref> with a polynomial fit of degree 1 on the same data. We had to optimize the degree of the polynomial and the span degree, which determines the smoothness and the degree of locality of the estimation 3 .
Reference: [18] <author> A. R. Henderson. </author> <title> Assessing test accuracy and its clinical consequences: a primer for receiver operating characteristic curve analysis. </title> <journal> Annals of Clinical Biochemistry, </journal> <volume> 30 </volume> <pages> 521-539, </pages> <year> 1993. </year>
Reference-contexts: The Receiver Operating Characteristic (ROC) [13, 14] is frequently used in such model comparisons, especially in clinical data <ref> [18, for review] </ref>.
Reference: [19] <author> D. C. Hoaglin, F. Mosteller, and J. W. Tukey. </author> <title> Understanding Robust and Exploratory Data Analysis. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1983. </year>
Reference-contexts: Noise injection is helpful in this case as well, while the overall performance is suboptimal. Noise levels represent the standard deviation (SD) of the zero-mean noise Gaussian. on the public domain version of Tibshirani in Statlib 8 . The results are summarized by boxplots 9 <ref> [19] </ref>. Each boxplot is based on 500-900 single network runs. As the ratio between the two classes is different than one, classification results are not a very robust measure for model comparison, since they are based on a single classification threshold.
Reference: [20] <author> R. V. Hogg and A. T. Craig. </author> <title> Introduction to Mathematical Statistics. </title> <publisher> Macmillan, </publisher> <address> Toronto, Canada, </address> <publisher> 3rd ed., </publisher> <year> 1970. </year>
Reference-contexts: We have been using both t statistic <ref> [20] </ref> and the Z statistic of Wilcoxon test [23] which uses a nonparametric rank to test difference in the medians, as it is more robust to outliers. The ROC results suggest that classification error of this model could be improved, possibly by averaging over a larger number of networks.
Reference: [21] <author> A. Krogh and J. A. Hertz. </author> <title> A simple weight decay can improve generalization. </title> <editor> In J.E. Moody, S.J Hanson, and R.P. Lippmann, editors, </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> volume 4, </volume> <pages> pages 950-957. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1992. </year>
Reference-contexts: This observation implies that the estimation of optimal noise levels should not be based on a single estimator performance, but rather based on the ensemble performance. The large variance of each single network in the ensemble can be tempered with a regularization such as weight decay <ref> [21, 27, for review] </ref>, but 5 again, the estimation of the optimal regularization factor should be done on the ensemble-averaged performance. Breiman [4] and Ripley [27] show compelling empirical evidence for the importance of weight decay as a single network stabilizer. Our results confirm this fact under the BEN model.
Reference: [22] <author> K. J. Lang and M. J. Witbrock. </author> <title> Learning to tell two spirals apart. </title> <editor> In D. S. Touretzky, J. L. Ellman, T. J. Sejnowski, and G. E. Hinton, editors, </editor> <booktitle> Proceedings of the 1988 Connectionists Models, </booktitle> <pages> pages 52-59. </pages> <year> 1988. </year>
Reference-contexts: It appears to be extremely hard for back-propagation networks due to its high non-linearity. It is easy to see that the 2D points of the spirals could not be separated by small combination of linear separators. Lang and Witbrock <ref> [22] </ref> proposed a 2 5 5 5 1 network with short-cuts using 138 weights. They used a variant of the quick-prop learning algorithm [10] with weight decay. They claimed that the problem could not be solved with simpler architecture (i.e. less layers or without short-cuts). <p> We show that similar conclusions can be obtained when using a highly flexible generalized additive model (GAM) [16]. Acknowledgements Stimulating discussions with Leo Breiman, Brian Ripley and Chris Bishop are greatfully acknowledged. Appendix A The Spiral data The two dimensional spiral data 10 <ref> [22] </ref> is given by a vector (x i ; y i ) defined by: x i = r i cos (ff i + k=2); y i = r i sin (ff i + k=2); ; (4) where ff i = i=16; r i = 0:5 + i=16; i = 0; :
Reference: [23] <author> E. L. Lehmann. Nonparametrics: </author> <title> Statistical Methods Based on Ranks. Holden and Day, </title> <address> San Francisco, </address> <year> 1975. </year> <month> 21 </month>
Reference-contexts: We have been using both t statistic [20] and the Z statistic of Wilcoxon test <ref> [23] </ref> which uses a nonparametric rank to test difference in the medians, as it is more robust to outliers. The ROC results suggest that classification error of this model could be improved, possibly by averaging over a larger number of networks.
Reference: [24] <author> R. P. Lippmann, L. Kukolich, and D. Shahian. </author> <title> Predicting the risk of complications in coronary artery bypass operations using neural networks. </title> <editor> In G. Tesauro, D. Touretzky, and T. Leen, editors, </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> volume 7, </volume> <pages> pages 1055-1062. </pages> <publisher> MIT Press, </publisher> <year> 1995. </year>
Reference-contexts: The Receiver Operating Characteristic (ROC) [13, 14] is frequently used in such model comparisons, especially in clinical data [18, for review]. This measure has been used by the contributor of the data [6] and in assessing neural network performance on another heart disease data <ref> [24] </ref>. by error rate and ROC values are slightly worse (not statistically significant) compared with logistic regression, and can not be improved by weight decay regularization alone. architecture of 9 hidden units. Noise levels in all the following graphs represent the standard deviation (SD) of the zero-mean Gaussian noise.
Reference: [25] <author> P. M. Murphy and D. W. Aha. </author> <title> UCI Repository of machine learning databases, 1992. </title> <institution> Department of Information and Computer Science. University of California at Irvine. </institution> <note> anonymous ftp from ics.uci.edu:/usr2/spool/ftp/pub/machine-learning-databases. </note>
Reference-contexts: In Section 5 we demonstrate our method on another well known machine learning problem the prediction of coronary artery disease based on the Cleveland Heart data which reside in the UCI machine learning repository <ref> [25] </ref>. 4 Results on the spiral data 4.1 Feed-forward network architecture We used Ripley's S-Plus 'nnet' package [27] which implements back-propagation. <p> It is clear that the bootstrap improves results, and furthermore, small values of the noise sharpen the result. 5 Cleveland Heart Data In this section, we analyze the Cleveland Heart data [7], donated by Dr. Robert Detrano 4 to the UCI Machine-Learning repository <ref> [25] </ref>. This data concerns diagnosis of coronary artery disease and has been used in the past by statisticians and by the machine learning community [7, 12, 29, 3, for review]. Further data and preprocessing details are given in Appendix B. <p> The variable attributes are: 1. Age 3. Chest pain type (4 values converted to 3 binary variables) 4. Resting blood pressure 5. Serum cholesterol in mg/dl 6. Fasting blood sugar &gt; 120 mg/dl 10 Can be obtained from <ref> [25] </ref>. 19 7. Resting electrocardiographic results (values 0,1,2) 8. Maximum heart rate achieved 9. Exercise induced angina 10. Oldpeak = ST depression induced by exercise relative to rest 11. The slope of the peak exercise ST segment (converted to 2 binary variables) 12.
Reference: [26] <author> M. P. Perrone. </author> <title> Improving Regression Estimation: Averaging Methods for Variance Reduction with Extensions to General Convex Measure Optimization. </title> <type> PhD thesis, </type> <institution> Brown University, Institute for Brain and Neural Systems, </institution> <month> May </month> <year> 1993. </year>
Reference-contexts: The success of ensemble averaging of neural networks in the past <ref> [15, 31, 4, 26] </ref> is due to the fact that neural networks have in general many local minima, and thus even with the same training set, different local minima are found when starting from different random initial conditions.
Reference: [27] <author> B. D. Ripley. </author> <title> Pattern Recognition and Neural Networks. </title> <publisher> Oxford Press, </publisher> <year> 1996. </year>
Reference-contexts: This observation implies that the estimation of optimal noise levels should not be based on a single estimator performance, but rather based on the ensemble performance. The large variance of each single network in the ensemble can be tempered with a regularization such as weight decay <ref> [21, 27, for review] </ref>, but 5 again, the estimation of the optimal regularization factor should be done on the ensemble-averaged performance. Breiman [4] and Ripley [27] show compelling empirical evidence for the importance of weight decay as a single network stabilizer. Our results confirm this fact under the BEN model. <p> The large variance of each single network in the ensemble can be tempered with a regularization such as weight decay [21, 27, for review], but 5 again, the estimation of the optimal regularization factor should be done on the ensemble-averaged performance. Breiman [4] and Ripley <ref> [27] </ref> show compelling empirical evidence for the importance of weight decay as a single network stabilizer. Our results confirm this fact under the BEN model. <p> Section 5 we demonstrate our method on another well known machine learning problem the prediction of coronary artery disease based on the Cleveland Heart data which reside in the UCI machine learning repository [25]. 4 Results on the spiral data 4.1 Feed-forward network architecture We used Ripley's S-Plus 'nnet' package <ref> [27] </ref> which implements back-propagation.
Reference: [28] <author> J. Sietsma and R. J. F. Dow. </author> <title> Creating artificial neural networks that generalize. </title> <booktitle> Neural Networks, </booktitle> <volume> 4 </volume> <pages> 67-79, </pages> <year> 1991. </year>
Reference-contexts: For classification problems, the form y = f (x + *); may be more appropriate. In this case, using noise injection to the inputs during training, can improve the generalization properties of the estimator <ref> [28] </ref>. Recently, Bishop [2] have shown that training with small amounts of noise is locally equivalent to smoothness regularization.
Reference: [29] <author> M. Stensmo. </author> <title> Adaptive Automated Diagnosis. </title> <type> PhD thesis, </type> <institution> Royal Institute of Technology, Stockholm, Sweden, </institution> <year> 1995. </year> <note> URL http://tesla.salk.edu/~magnus/papers-abs.html. </note>
Reference-contexts: Robert Detrano 4 to the UCI Machine-Learning repository [25]. This data concerns diagnosis of coronary artery disease and has been used in the past by statisticians and by the machine learning community <ref> [7, 12, 29, 3, for review] </ref>. Further data and preprocessing details are given in Appendix B. The preprocessing, which included removal of missing values, sphering the data and creating dummy variables to replace categorial variables, resulted in a dramatic improvement over past results. <p> Moreover, it revealed that in the new data representation, the structure is very linear since logistic regression was able to obtain 9-fold cross-validation error of about 15.2%. A similar error was obtained by using extensive preprocessing and a Temporal-Difference Reinforcement Learning <ref> [29] </ref>.
Reference: [30] <author> Ultragem Data Mining. </author> <title> Esprit statlog benchmarks. </title> <type> Technical report, </type> <institution> Ultragem Data Mining, </institution> <address> 450 Wildberry Drive, Boulder Creek, CA 95006, USA, </address> <year> 1996. </year> <note> http://www.ultragem.com. </note>
Reference-contexts: Medical Center, Long Beach and Cleveland Clinic Foundation. 5 Recent best result of 23.1% on non-normalized data was obtained by a company that provides classification with its own proprietary software <ref> [30] </ref>. 12 Summary of 40-Net Ensemble-Average Results Top right: Optimal weight decay ( = 3e 4) and no noise. Bottom left: Optimal noise (Gaussian SD=0:35) and zero weight decay. Bottom right: Optimal noise and optimal weight decay. 13 bootstrap samples with varying degree of noise.
Reference: [31] <author> D. H. Wolpert. </author> <title> Stacked generalization. </title> <booktitle> Neural Networks, </booktitle> <volume> 5 </volume> <pages> 241-259, </pages> <year> 1992. </year> <month> 22 </month>
Reference-contexts: The success of ensemble averaging of neural networks in the past <ref> [15, 31, 4, 26] </ref> is due to the fact that neural networks have in general many local minima, and thus even with the same training set, different local minima are found when starting from different random initial conditions.
References-found: 31

