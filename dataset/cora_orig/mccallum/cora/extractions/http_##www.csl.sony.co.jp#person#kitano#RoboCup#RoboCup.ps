URL: http://www.csl.sony.co.jp/person/kitano/RoboCup/RoboCup.ps
Refering-URL: http://www.csl.sony.co.jp/person/kitano/RoboCup/RoboCup-old.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: Mailing-list: RoboCup@csl.sony.co.jp  
Title: RoboCup: The Robot World Cup Initiative  
Author: Hiroaki Kitano Minoru Asada Yasuo Kuniyoshi Itsuki Noda Eiichi Osawa 
Address: 3-14-13 Higashi-Gotanda Osaka University 1-1-4 Umezono Shinagawa, Tokyo 141 Japan Suita, Osaka 565 Japan Tsukuba, 305 Japan  
Affiliation: Sony Computer Science Lab. 1 Dept. of Mechanical Engineering 2 Electrotechnical laboratory 3  
Abstract: The Robot World Cup Initiative (RoboCup) is an attempt to foster AI and intelligent robotics research by providing a standard problem where wide range of technologies can be integrated and examined. In order for a robot team to actually perform a soccer game, various technologies must be incorporated including: design principles of autonomous agents, multi-agent collaboration, strategy acquisition, real-time reasoning, robotics, and sensor-fusion. Unlike AAAI robot competition, which is tuned for a single heavy-duty slow-moving robot, RoboCup is a task for a team of multiple fast-moving robots under a dynamic environment. Although RoboCup's final target is a world cup with real robots, RoboCup offers a software platform for research on the software aspects of RoboCup. This paper describes technical challenges involved in RoboCup, rules, and simulation environment. 
Abstract-found: 1
Intro-found: 1
Reference: [Agre and Chapman 87] <author> P. Agre and D. Chapman. Pengi: </author> <title> An implementation of a theory of activity. </title> <booktitle> In Proceedings of the Sixth National Conference on Artificial Intelligence (AAAI-87), </booktitle> <pages> pp. 268-272, </pages> <year> 1987. </year>

Reference: [Asada et al. 95] <author> M. Asada, S. Noda, S. Tawaratsumida, and K. Hosoda. </author> <title> Vision-based reinforcement learning for purposive behavior acquisition. </title> <booktitle> In Proc. of IEEE Int. Conf. on Robotics and Automation, </booktitle> <year> 1995. </year>
Reference-contexts: intelligence and multi-agent research. 3 Research Issues for RoboCup with Real Robots In this section, we discuss several research issues involved in realizing real robots for RoboCup. * Design of RoboCup player and their control: Existing robot players have been designed to perform mostly single behavior actions, such as pushing/driblling/rolling <ref> [Connel and Mahadevan 93a, Asada et al. 95, Sahota 94] </ref>, juggling [Rizzi and Koditschek 93, Schaal and Atkeson 94], or hitting [Watanabe et al. 94].
Reference: [Asada et al 94a] <author> M. Asada, S. Noda, S. Tawaratsum-ida, and K. Hosoda. </author> <title> "purposive behavior acquisition on a real robot by vision-based reinforcement learning". </title> <booktitle> In Proc. of MLC-COLT (Machine Learning Conference and Computer Learning Theory) Workshop on Robot Learning, </booktitle> <pages> pages 1-9, </pages> <year> 1994. </year>
Reference-contexts: However, almost all of the existing applications have been done only with computer simulations in a virtual world, real robot applications are very few <ref> [Asada et al 94a, Connel and Mahadevan 93a] </ref>. Since the prominence of the reinforcement learning role is largely determined by the extent to which it can be scaled to larger and complex robot learning tasks, the RoboCup seems a very good platform.
Reference: [Asada et al 94b] <author> M. Asada, E. Uchibe, S. Noda, S. Tawaratsumida, and K. Hosoda. </author> <title> "coordination of multiple behaviors acquired by vision-based reinforcement learning". </title> <booktitle> In Proc. of IEEE/RSJ/GI International Conference on Intelligent Robots and Systems 1994 (IROS '94), </booktitle> <pages> pages 917-924, </pages> <year> 1994. </year>
Reference-contexts: Since the player has to take the opponent's motions into consideration, the complexity of the problem is much higher than that of simple shooting without an opponent. To reduce the complexity, task decomposition is often used. Asada et al. <ref> [Asada et al 94b] </ref> proposed a method for learning a shooting behavior avoiding a goal keeper. The shooting and avoiding behaviors are independently acquired and they are coordinated through the learning.
Reference: [Benda et al. 85] <author> M. Benda, V. Jagannathan, and R. Dodhiawalla. </author> <title> On Optimal Cooperation of Knowledge Sources. </title> <type> Technical Report BCS-G2010-28, </type> <institution> Boe-ing AI Center, </institution> <year> 1985. </year>
Reference: [Connel and Mahadevan 93a] <author> J. H. Connel and S. Ma-hadevan. </author> <title> "Rapid task learning for real robot". </title> <editor> In J. H. Connel and S. Mahadevan, editors, </editor> <title> Robot Learning, chapter 5. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1993. </year>
Reference-contexts: intelligence and multi-agent research. 3 Research Issues for RoboCup with Real Robots In this section, we discuss several research issues involved in realizing real robots for RoboCup. * Design of RoboCup player and their control: Existing robot players have been designed to perform mostly single behavior actions, such as pushing/driblling/rolling <ref> [Connel and Mahadevan 93a, Asada et al. 95, Sahota 94] </ref>, juggling [Rizzi and Koditschek 93, Schaal and Atkeson 94], or hitting [Watanabe et al. 94]. <p> However, almost all of the existing applications have been done only with computer simulations in a virtual world, real robot applications are very few <ref> [Asada et al 94a, Connel and Mahadevan 93a] </ref>. Since the prominence of the reinforcement learning role is largely determined by the extent to which it can be scaled to larger and complex robot learning tasks, the RoboCup seems a very good platform.
Reference: [Connel and Mahadevan 93b] <editor> J. H. Connel and S. Ma-hadevan, editors. </editor> <title> Robot Learning. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1993. </year>
Reference-contexts: As a method for robot learning, reinforcement learning has recently been receiving increased attention with little or no a priori knowledge giving higher capability of reactive and adaptive behaviors <ref> [Connel and Mahadevan 93b] </ref>. However, almost all of the existing applications have been done only with computer simulations in a virtual world, real robot applications are very few [Asada et al 94a, Connel and Mahadevan 93a].
Reference: [Durfee and Lesser 87] <author> E. Durfee and V. Lesser. </author> <title> Using Partial Global Plans to Coordinate Distributed Problem Solvers. </title> <booktitle> In Proceedings of the Tenth International Joint Conference on Artificial Intelligence (IJCAI-87), </booktitle> <year> 1987. </year>
Reference-contexts: The study of the relationship between the communication cost and processing cost concerning the reliability of the hypotheses in FA/C [Lesser and Erman 80], and the relationship between the modification cost of local plans and the accuracy of a global plan in PGP <ref> [Durfee and Lesser 87] </ref> illustrate this fact. Also, Korf addressed it theoretically in [Korf 87].
Reference: [Gasser et al. 89] <author> L. Gasser, N. Rouquette, R. Hill, and J. Lieb. </author> <title> Representing and Using Organizational Knowledge in Distributed AI Systems. </title> <editor> In Les Gasser and Michael N. Huhns, editors, </editor> <booktitle> Distributed Artificial Intelligence, </booktitle> <volume> Volume II, </volume> <pages> pp. 55-78. </pages> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <year> 1989. </year>
Reference: [Ishida and Korf 91] <author> T. Ishida and R. Korf. </author> <title> Moving Target Search. </title> <booktitle> In Proceedings of the Twelfth International Joint Conference on Artificial Intelligence (IJCAI-91), </booktitle> <pages> pp. 204-210, </pages> <year> 1991. </year>
Reference-contexts: However, the pursuit game is a relatively simple game. Tileworld [Pollack and Ringuette 90] was also proposed and studied <ref> [Kinny and Georgeff 91, Ishida and Korf 91] </ref>. However, the environment is basically for the study of a single agent arichtecture.
Reference: [Kinny and Georgeff 91] <author> D. Kinny and M. Georgeff. </author> <title> Commitment and Effectiveness of Situated Agents. </title> <booktitle> In Proceedings of the Twelfth International Joint Conference on Artificial Intelligence (IJCAI-91), </booktitle> <pages> pp. 82-88, </pages> <year> 1991. </year>
Reference-contexts: However, the pursuit game is a relatively simple game. Tileworld [Pollack and Ringuette 90] was also proposed and studied <ref> [Kinny and Georgeff 91, Ishida and Korf 91] </ref>. However, the environment is basically for the study of a single agent arichtecture.
Reference: [Korf 87] <author> R. Korf. </author> <title> Planning as Search: A Quantitative Approach. </title> <journal> Artificial Intelligence, </journal> <volume> Vol. 33, No. 1, pp.65-88, </volume> <year> 1987. </year>
Reference-contexts: Also, Korf addressed it theoretically in <ref> [Korf 87] </ref>. Schemes for reactive cooperative planning in dynamic problem spaces have been proposed and evaluated sometimes based on the pursuit game (predator-prey) [Benda et al. 85, Stephens and Merx 89, Gasser et al. 89, Levy and Rosenschein 92, Korf 92, Osawa 95].
Reference: [Korf 92] <author> R. Korf. </author> <title> A Simple Solution to Pursuit Games. </title> <booktitle> In Proceedings of the Eleventh International Workshop on Distributed Artificial Intelligence, </booktitle> <year> 1992. </year>
Reference: [Lesser and Erman 80] <author> V. Lesser and L. Erman. </author> <title> Distributed Interpretation: A Model and Experiment. </title> <journal> IEEE Transactions on Computers, </journal> <volume> Vol. 29, No. 12, pp.1144-1163, </volume> <year> 1980. </year>
Reference-contexts: The study of the relationship between the communication cost and processing cost concerning the reliability of the hypotheses in FA/C <ref> [Lesser and Erman 80] </ref>, and the relationship between the modification cost of local plans and the accuracy of a global plan in PGP [Durfee and Lesser 87] illustrate this fact. Also, Korf addressed it theoretically in [Korf 87].
Reference: [Levy and Rosenschein 92] <author> R. Levy and J. </author> <note> Rosenschein. </note>
References-found: 15

