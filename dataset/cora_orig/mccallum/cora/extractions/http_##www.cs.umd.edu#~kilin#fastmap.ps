URL: http://www.cs.umd.edu/~kilin/fastmap.ps
Refering-URL: http://www.cs.umd.edu/users/kilin/
Root-URL: 
Title: FastMap: A Fast Algorithm for Indexing, Data-Mining and Visualization of Traditional and Multimedia Datasets designing
Author: Christos Faloutsos King-Ip (David) Lin 
Note: However,  N while it manages to preserve distances and the overall structure of the data-set.  
Address: Murray Hill, NJ  College Park  
Affiliation: AT&T Bell Laboratories  Dept. of Computer Science Univ. of Maryland,  
Abstract: A very promising idea for fast searching in traditional and multimedia databases is to map objects into points in k-d space, using k feature-extraction functions, provided by a domain expert [25]. Thus, we can subsequently use highly fine-tuned spatial access methods (SAMs), to answer several types of queries, including the `Query By Example' type (which translates to a range query); the `all pairs' query (which translates to a spatial join [8]); the nearest-neighbor or best-match query, etc. This is exactly the topic of this paper. We describe a fast algorithm to map objects into points in some k-dimensional space (k is user-defined), such that the dis-similarities are preserved. There are two benefits from this mapping: (a) efficient retrieval, in conjunction with a SAM, as discussed before and (b) visualization and data-mining: the objects can now be plotted as points in 2-d or 3-d space, revealing potential clusters, correlations among attributes and other regularities that data-mining is looking for. We introduce an older method from pattern recognition, namely, Multi-Dimensional Scaling (MDS) [51]; although unsuitable for indexing, we use it as yardstick for our method. Then, we propose a much faster algorithm to solve the problem in hand, while in addition it allows for indexing. Experiments on real and synthetic data indeed show that the proposed algorithm is significantly faster than MDS, (being linear, as opposed to quadratic, on the database size fl On leave from Univ. of Maryland, College Park. This work was partially supported by the Institute of Systems Research and by the National Science Foundation under Grants No. CDR-8803012, EEC-94-02384, IRI-8958546 and IRI-9205273), with matching funds from Empress Software Inc. and Thinking Machines Inc. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Rakesh Agrawal, Christos Faloutsos, and Arun Swami. </author> <title> Efficient similarity search in sequence databases. </title> <booktitle> In Foundations of Data Organization and Algorithms (FODO) Conference, </booktitle> <address> Evanston, Illinois, </address> <month> October </month> <year> 1993. </year> <note> also available through anonymous ftp, from olym-pos.cs.umd.edu: ftp/pub/TechReports/fodo.ps. </note>
Reference-contexts: The goal is to aid forecasting, by examining similar patterns that may have appeared in the past. In <ref> [1] </ref> we used the Euclidean distance (sum of squared errors) as the distance function between two time series. * Similarity searching in string databases, as in the case of spelling, typing [30] and OCR error correction [26]. <p> Algorithm FastMap ( k, D (), O ) 1) if (k 0) f return; g else fcol# ++;g 2) /* choose pivot objects */ let O a and O b be the result of choose-distant-objects ( O, D ()); 3) /* record the ids of the pivot objects */ PA <ref> [1, col#] </ref> = a; PA [2, col#]= b; set X [ i, col#] =0 for every i and return /* since all inter-object distances are 0 */ 5) /* project objects on line (O a , O b ) */ for each object O i , compute x i using Eq. <p> Therefore, the i-th object is mapped to the point P i = (X <ref> [i; 1] </ref>, X [i; 2], : : : X [i; k]) where X [i; j] is the j-th co-ordinate P i , the image of the i-th object.
Reference: [2] <author> Rakesh Agrawal, Tomasz Imielinski, and Arun Swami. </author> <title> Mining association rules between sets of items in large databases. </title> <booktitle> Proc. ACM SIGMOD, </booktitle> <pages> pages 207-216, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: In all these applications, the distance is typically the editing distance ie., minimum number of insertions, deletions or substitutions that are needed to transform the first string to the second. * Data mining [3], <ref> [2] </ref> and visualization applications. For example, given records of patients (with attributes like gender, age, blood-pressure etc.), we would like to help the physician detect any clusters, or correlations among symptoms, demographic data and diseases. <p> (), O ) 1) if (k 0) f return; g else fcol# ++;g 2) /* choose pivot objects */ let O a and O b be the result of choose-distant-objects ( O, D ()); 3) /* record the ids of the pivot objects */ PA [1, col#] = a; PA <ref> [2, col#] </ref>= b; set X [ i, col#] =0 for every i and return /* since all inter-object distances are 0 */ 5) /* project objects on line (O a , O b ) */ for each object O i , compute x i using Eq. 3 and update the global <p> Therefore, the i-th object is mapped to the point P i = (X [i; 1], X <ref> [i; 2] </ref>, : : : X [i; k]) where X [i; j] is the j-th co-ordinate P i , the image of the i-th object.
Reference: [3] <author> Rakesh Agrawal and Ramakrishnan Srikant. </author> <title> Fast algo rithms for mining association rules in large databases. </title> <booktitle> Proc. of VLDB Conf., </booktitle> <pages> pages 487-499, </pages> <month> September </month> <year> 1994. </year>
Reference-contexts: In all these applications, the distance is typically the editing distance ie., minimum number of insertions, deletions or substitutions that are needed to transform the first string to the second. * Data mining <ref> [3] </ref>, [2] and visualization applications. For example, given records of patients (with attributes like gender, age, blood-pressure etc.), we would like to help the physician detect any clusters, or correlations among symptoms, demographic data and diseases.
Reference: [4] <author> S.F. Altschul, W. Gish, W. Miller, </author> <title> E.W. Myers, and D.J. Lipman. A basic local alignment search tool. </title> <journal> Journal of Molecular Biology, </journal> <volume> 215(3) </volume> <pages> 403-410, </pages> <year> 1990. </year>
Reference-contexts: Conceptually identical is the case of approximate matching in DNA databases, where there is a large collection of strings from a four-letter alphabet (A,G,C,T); a new string has to be matched against the old strings, to find the best candidates <ref> [4] </ref>. In all these applications, the distance is typically the editing distance ie., minimum number of insertions, deletions or substitutions that are needed to transform the first string to the second. * Data mining [3], [2] and visualization applications.
Reference: [5] <author> Manish Arya, William Cody, Christos Faloutsos, Joel Richardson, and Arthur Toga. Qbism: </author> <title> a prototype 3-d medical image database system. </title> <journal> IEEE Data Engineering Bulletin, </journal> <volume> 16(1) </volume> <pages> 38-42, </pages> <month> March </month> <year> 1993. </year>
Reference-contexts: Once the similarity (or dis-similarity) function has been determined, our proposed method can be immediately applied. * Medical databases, where 1-d objects (eg., ECGs), 2-d images (eg., X-rays) and 3-d images (eg., MRI brain scans) <ref> [5] </ref> are stored. Ability to retrieve quickly past cases with similar symptoms would be valuable for diagnosis, as well as for medical teaching and research purposes.
Reference: [6] <author> Ricardo A. Baeza-Yates, Walter Cunto, Udi Manber, and Sun Wu. </author> <title> Proximity matching using fixed queries trees. </title> <editor> In M. Crochemore and D. Gusfield, editors, </editor> <booktitle> 5th Combinatorial Pattern Matching, </booktitle> <volume> LNCS 807, </volume> <pages> pages 198-212. </pages> <publisher> Springer-Verlag, </publisher> <address> Asilomar, CA, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: There are also retrieval methods for the case where only the triangular inequality holds [10], [46], [47], <ref> [6] </ref>. All these methods try to exploit the triangular inequality in order to prune the search space on a range query. However, none of them tries to map objects into points in `target space', nor to provide a tool for visualization.
Reference: [7] <author> N. Beckmann, H.-P. Kriegel, R. Schneider, and B. Seeger. </author> <title> The r*-tree: an efficient and robust access method for points and rectangles. </title> <booktitle> ACM SIGMOD, </booktitle> <pages> pages 322-331, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: Such a mapping provides two major benefits: 1. It can accelerate the search time for queries. The reason is that we can employ highly fine-tuned Spatial Access Methods (SAMs), like the R fl -trees <ref> [7] </ref> and the z-ordering [37]. <p> The most popular methods form three classes: (a) tree-based methods like the R-tree [20], and its variants (R + tree [45], hB-tree [31], P-tree [24], R fl -tree <ref> [7] </ref>, Hilbert R-trees [27] etc.) (b) methods using linear quadtrees [18] or, equivalently, the z-ordering [37, 38], or other space-filling curves [14, 23] and finally (c) methods that use grid-files [36, 22]. There are also retrieval methods for the case where only the triangular inequality holds [10], [46], [47], [6]. <p> Firstly, it can accelerate searching for several types of queries (`query-by-example' or `range' queries, `all pairs' queries or spatial joins [9, 8], nearest neighbor queries [42] etc.), because several, highly optimized spatial access methods are readily available (R-trees [20], R fl -trees <ref> [7] </ref> etc.). Secondly, such a mapping is useful for data-mining, cluster analysis and visualization of a high-dimensionality dataset.
Reference: [8] <author> Thomas Brinkhoff, Hans-Peter Kriegel, Ralf Schneider, and Bernhard Seeger. </author> <title> Multi-step processing of spatial joins. </title> <booktitle> ACM SIGMOD, </booktitle> <pages> pages 197-208, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: It can accelerate the search time for queries. The reason is that we can employ highly fine-tuned Spatial Access Methods (SAMs), like the R fl -trees [7] and the z-ordering [37]. These methods provide fast searching for range queries as well as spatial joins <ref> [8] </ref>. 2. it can help with visualization, clustering and data mining: Plotting objects as points in k=2 or 3 dimensions can reveal much of the structure of the dataset, such as the existence of major clusters, the general shape of the distribution (linear versus curvilinear versus Gaussian) etc.. <p> Mapping objects into points has the following two applications. Firstly, it can accelerate searching for several types of queries (`query-by-example' or `range' queries, `all pairs' queries or spatial joins <ref> [9, 8] </ref>, nearest neighbor queries [42] etc.), because several, highly optimized spatial access methods are readily available (R-trees [20], R fl -trees [7] etc.). Secondly, such a mapping is useful for data-mining, cluster analysis and visualization of a high-dimensionality dataset.
Reference: [9] <author> Thomas Brinkhoff, Hans-Peter Kriegel, and Bernhard Seeger. </author> <title> Efficient processing of spatial joins using r-trees. </title> <booktitle> Proc. of ACM SIGMOD, </booktitle> <pages> pages 237-246, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: Mapping objects into points has the following two applications. Firstly, it can accelerate searching for several types of queries (`query-by-example' or `range' queries, `all pairs' queries or spatial joins <ref> [9, 8] </ref>, nearest neighbor queries [42] etc.), because several, highly optimized spatial access methods are readily available (R-trees [20], R fl -trees [7] etc.). Secondly, such a mapping is useful for data-mining, cluster analysis and visualization of a high-dimensionality dataset.
Reference: [10] <author> W.A. Burkhard and R.M. Keller. </author> <title> Some approaches to best-match file searching. </title> <journal> Comm. of the ACM (CACM), </journal> <volume> 16(4) </volume> <pages> 230-236, </pages> <month> April </month> <year> 1973. </year>
Reference-contexts: There are also retrieval methods for the case where only the triangular inequality holds <ref> [10] </ref>, [46], [47], [6]. All these methods try to exploit the triangular inequality in order to prune the search space on a range query. However, none of them tries to map objects into points in `target space', nor to provide a tool for visualization.
Reference: [11] <institution> Mathematical Committee on Physical and NSF En gineering Sciences. Grand Challenges: High Performance Computing and Communications. National Science Foundation, </institution> <year> 1992. </year> <booktitle> The FY 1992 U.S. Research and Development Program. </booktitle>
Reference-contexts: This warping makes it difficult to find features that would adequately describe each image (and therefore, map it into a point in feature space). * Time series, with, eg. financial data, such as stock prices, sales numbers etc., or scientific databases, with time series of sensor data, weather <ref> [11] </ref>, geological, environmental, astrophysics [53] data, etc., In such databases, typical queries would be `find companies whose stock prices move similarly', or `find past days in which the solar magnetic wind showed patterns similar to today's pattern' [53].
Reference: [12] <author> R.O. Duda and P.E. Hart. </author> <title> Pattern Classification and Scene Analysis. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1973. </year>
Reference-contexts: The optimal way to map n-dimensional points to k-dimensional points (k n) is the Karhunen-Loeve (`K-L') transform (eg., see <ref> [12] </ref>, [17]). <p> Again, the distance between two such points is the Euclidean distance. This dataset is a simplified version of the one used in a Pattern Recognition textbook [17, p. 46]. SPIRAL: 30 points on a 3-d spiral, as suggested by Duda and Hart <ref> [12, p. 243] </ref>: x 1 (i) = cos x 3 (i) x 3 (i) = i= 2; i = 0; 1; : : :29 (6) 4.1 Comparison with MDS In the first group of experiments, we compare our method with the traditional MDS, using the `WINE' dataset.
Reference: [13] <author> Susan T. Dumais. </author> <title> Latent semantic indexing (LSI) and TREC-2. </title> <editor> In D. K. Harman, editor, </editor> <booktitle> The Second Text Retrieval Conference (TREC-2), </booktitle> <pages> pages 105-115, </pages> <address> Gaithers-burg, MD, </address> <month> March </month> <year> 1994. </year> <note> NIST. Special Publication 500-215. </note>
Reference-contexts: the K-L transform suffers from two drawbacks: * it can not be applied at all on the `distance' case * even in the `features' case, it may be slow for large databases (N 1) with many attributes (n 1) The latter situation appears, eg., in information retrieval and filtering [16], <ref> [13] </ref>, where documents correspond to V -dimensional vectors (V being the vocabulary size of the collection, typically in the tens of thousands).
Reference: [14] <author> C. Faloutsos and S. Roseman. </author> <title> Fractals for sec ondary key retrieval. </title> <booktitle> Eighth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems (PODS), </booktitle> <pages> pages 247-252, </pages> <month> March </month> <year> 1989. </year> <note> also available as UMIACS-TR-89-47 and CS-TR-2242. </note>
Reference-contexts: The most popular methods form three classes: (a) tree-based methods like the R-tree [20], and its variants (R + tree [45], hB-tree [31], P-tree [24], R fl -tree [7], Hilbert R-trees [27] etc.) (b) methods using linear quadtrees [18] or, equivalently, the z-ordering [37, 38], or other space-filling curves <ref> [14, 23] </ref> and finally (c) methods that use grid-files [36, 22]. There are also retrieval methods for the case where only the triangular inequality holds [10], [46], [47], [6]. All these methods try to exploit the triangular inequality in order to prune the search space on a range query.
Reference: [15] <author> Christos Faloutsos and King-Ip (David) Lin. </author> <title> Fastmap: a fast algorithm for indexing, data-mining and visualization of traditional and multimedia datasets. </title> <type> Cs-tr-3383 umiacs-tr-94-132 isr tr 94-80, </type> <institution> Dept. of Computer Science, Univ. of Maryland, College Park, </institution> <year> 1994. </year> <note> also available from mosaic (URL ftp: //olympos.cs.umd.edu /pub/TechReports /sigmod95.ps). </note>
Reference-contexts: Due to space limitations, we omit an arithmetic example, as well as an illustration of how to apply our method for a collection of documents. The details are in a technical report <ref> [15] </ref>, also available on `mosaic'. 4 Experiments We implemented our method in `C++' and UNIX (TM) on a DECStation 5000/25 and run several experiments, in two groups. <p> The distance function is the Euclidean distance of the document vectors, after normalization to unit vectors; it is closely related to the popular `cosine-similarity' function of Information Retrieval (for more details, see the technical report <ref> [15] </ref>). WINE: N =154 records, with results of a chemical analysis of wines grown in the same region in Italy, but derived from three different cultivars. Thus, we expect to see 3 clusters.
Reference: [16] <author> Peter W. Foltz and Susan T. Dumais. </author> <title> Personalized in formation delivery: an analysis of information filtering methods. </title> <journal> Comm. of ACM (CACM), </journal> <volume> 35(12) </volume> <pages> 51-60, </pages> <month> De-cember </month> <year> 1992. </year>
Reference-contexts: However, the K-L transform suffers from two drawbacks: * it can not be applied at all on the `distance' case * even in the `features' case, it may be slow for large databases (N 1) with many attributes (n 1) The latter situation appears, eg., in information retrieval and filtering <ref> [16] </ref>, [13], where documents correspond to V -dimensional vectors (V being the vocabulary size of the collection, typically in the tens of thousands).
Reference: [17] <author> Keinosuke Fukunaga. </author> <title> Introduction to Statistical Pat tern Recognition. </title> <publisher> Academic Press, </publisher> <year> 1990. </year> <note> 2nd Edition. </note>
Reference-contexts: The optimal way to map n-dimensional points to k-dimensional points (k n) is the Karhunen-Loeve (`K-L') transform (eg., see [12], <ref> [17] </ref>). <p> n-d point and its k-d image. suggests: If we are allowed only k=1, the best direction to project on is the direction of x 0 ; the next best is y 0 etc. transformation the `best' axis to project is x 0 . `K-L' is often used in pattern matching <ref> [17] </ref> to choose the most important features (actually, linear combinations of features), for a given set of vectors. It computes the eigenvectors of the covariance matrix, sorts them in decreasing eigenvalue order, and approximates each data vector with its projections on the first k eigenvectors. <p> Again, the distance between two such points is the Euclidean distance. This dataset is a simplified version of the one used in a Pattern Recognition textbook <ref> [17, p. 46] </ref>.
Reference: [18] <author> I. </author> <title> Gargantini. An effective way to represent quadtrees. </title> <journal> Comm. of ACM (CACM), </journal> <volume> 25(12) </volume> <pages> 905-910, </pages> <month> December </month> <year> 1982. </year>
Reference-contexts: The most popular methods form three classes: (a) tree-based methods like the R-tree [20], and its variants (R + tree [45], hB-tree [31], P-tree [24], R fl -tree [7], Hilbert R-trees [27] etc.) (b) methods using linear quadtrees <ref> [18] </ref> or, equivalently, the z-ordering [37, 38], or other space-filling curves [14, 23] and finally (c) methods that use grid-files [36, 22]. There are also retrieval methods for the case where only the triangular inequality holds [10], [46], [47], [6].
Reference: [19] <author> G. H. Golub and C. F. Van Loan. </author> <title> Matrix Computations. </title> <publisher> The Johns Hopkins University Press, </publisher> <address> Baltimore, </address> <note> second edition, </note> <year> 1989. </year>
Reference-contexts: It computes the eigenvectors of the covariance matrix, sorts them in decreasing eigenvalue order, and approximates each data vector with its projections on the first k eigenvectors. The operation is closely related to the Singular Value Decomposition (SVD) <ref> [49, 39, 19] </ref> of the object-feature matrix. Our implementation of the K-L transform in Mathematica [54] is available in Appendix A, as well as on `mosaic' (URL: ftp: //olympos.cs.umd.edu /pub/SRC/ kl.m).
Reference: [20] <author> A. Guttman. R-trees: </author> <title> a dynamic index structure for spatial searching. </title> <booktitle> Proc. ACM SIGMOD, </booktitle> <pages> pages 47-57, </pages> <month> June </month> <year> 1984. </year>
Reference-contexts: The most popular methods form three classes: (a) tree-based methods like the R-tree <ref> [20] </ref>, and its variants (R + tree [45], hB-tree [31], P-tree [24], R fl -tree [7], Hilbert R-trees [27] etc.) (b) methods using linear quadtrees [18] or, equivalently, the z-ordering [37, 38], or other space-filling curves [14, 23] and finally (c) methods that use grid-files [36, 22]. <p> Mapping objects into points has the following two applications. Firstly, it can accelerate searching for several types of queries (`query-by-example' or `range' queries, `all pairs' queries or spatial joins [9, 8], nearest neighbor queries [42] etc.), because several, highly optimized spatial access methods are readily available (R-trees <ref> [20] </ref>, R fl -trees [7] etc.). Secondly, such a mapping is useful for data-mining, cluster analysis and visualization of a high-dimensionality dataset.
Reference: [21] <author> John A. Hartigan. </author> <title> Clustering Algorithms. </title> <publisher> John Wiley & Sons, </publisher> <year> 1975. </year>
Reference-contexts: However, none of them tries to map objects into points in `target space', nor to provide a tool for visualization. Finally, our work could be beneficial to research on clustering algorithms, where several approaches have been proposed. See, eg., [32], <ref> [21] </ref> for surveys, [34] for a recent application in GIS, [43] [52] for applications in Information Retrieval. 3 Proposed Method In the first part, we describe the proposed algorithm, which achieves a fast mapping of objects into points, so that distances are preserved well.
Reference: [22] <author> K. Hinrichs and J. Nievergelt. </author> <title> The grid file: a data structure to support proximity queries on spatial objects. </title> <booktitle> Proc. of the WG'83 (Intern. Workshop on Graph Theoretic Concepts in Computer Science), </booktitle> <pages> pages 100-113, </pages> <year> 1983. </year>
Reference-contexts: tree-based methods like the R-tree [20], and its variants (R + tree [45], hB-tree [31], P-tree [24], R fl -tree [7], Hilbert R-trees [27] etc.) (b) methods using linear quadtrees [18] or, equivalently, the z-ordering [37, 38], or other space-filling curves [14, 23] and finally (c) methods that use grid-files <ref> [36, 22] </ref>. There are also retrieval methods for the case where only the triangular inequality holds [10], [46], [47], [6]. All these methods try to exploit the triangular inequality in order to prune the search space on a range query.
Reference: [23] <author> H.V. Jagadish. </author> <title> Linear clustering of objects with multiple attributes. </title> <booktitle> ACM SIGMOD Conf., </booktitle> <pages> pages 332-342, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: The most popular methods form three classes: (a) tree-based methods like the R-tree [20], and its variants (R + tree [45], hB-tree [31], P-tree [24], R fl -tree [7], Hilbert R-trees [27] etc.) (b) methods using linear quadtrees [18] or, equivalently, the z-ordering [37, 38], or other space-filling curves <ref> [14, 23] </ref> and finally (c) methods that use grid-files [36, 22]. There are also retrieval methods for the case where only the triangular inequality holds [10], [46], [47], [6]. All these methods try to exploit the triangular inequality in order to prune the search space on a range query.
Reference: [24] <author> H.V. Jagadish. </author> <title> Spatial search with polyhedra. </title> <booktitle> Proc. Sixth IEEE Int'l Conf. on Data Engineering, </booktitle> <month> February </month> <year> 1990. </year>
Reference-contexts: The most popular methods form three classes: (a) tree-based methods like the R-tree [20], and its variants (R + tree [45], hB-tree [31], P-tree <ref> [24] </ref>, R fl -tree [7], Hilbert R-trees [27] etc.) (b) methods using linear quadtrees [18] or, equivalently, the z-ordering [37, 38], or other space-filling curves [14, 23] and finally (c) methods that use grid-files [36, 22].
Reference: [25] <author> H.V. Jagadish. </author> <title> A retrieval technique for similar shapes. </title> <booktitle> Proc. ACM SIGMOD Conf., </booktitle> <pages> pages 208-217, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: 1 Introduction The objective of this work is to provide a retrieval and visualization tool for large collections of traditional as well as `exotic' and multimedia datasets. An excellent idea, suggested by Jagadish <ref> [25] </ref>, was to rely on domain experts to derive k feature-extraction functions, thus mapping each object into a point in k-dimensional space. Then the problem is reduced to storing, retrieving and displaying k-dimensional points, for which there is a plethora of algorithms available. <p> Some of the applications that motivated the present work are listed next. Some distance functions are also described. * Image and, in general, multimedia databases: In a collection of shapes <ref> [25] </ref> we would like to find shapes similar to a give one; in a collection of color images, we would like to find images with similar colors, shapes or texture [35]. <p> In an earlier approach for similarity searching in non-traditional/multimedia databases <ref> [25] </ref>, a domain expert was expected to provide feature extraction functions. Thanks to the proposed `FastMap' algorithm, the domain expert need only provide a distance function, from which our algorithm will infer the appropriate features for each object. Mapping objects into points has the following two applications.
Reference: [26] <author> Mark A. Jones, Guy A. Story, and Bruce W. Ballard. </author> <title> Integrating multiple knowledge sources in a bayesian ocr post-processor. </title> <booktitle> In First International Conference on Document Analysis and Recognition, </booktitle> <address> Saint-Malo, France, </address> <month> September </month> <year> 1991. </year> <note> to appear. </note>
Reference-contexts: In [1] we used the Euclidean distance (sum of squared errors) as the distance function between two time series. * Similarity searching in string databases, as in the case of spelling, typing [30] and OCR error correction <ref> [26] </ref>. There, given a wrong string, we should search a dictionary to find the closest strings to it.
Reference: [27] <author> Ibrahim Kamel and Christos Faloutsos. </author> <title> Hilbert r tree: an improved r-tree using fractals. </title> <booktitle> In Proc. of VLDB Conference,, </booktitle> <pages> pages 500-509, </pages> <address> Santiago, Chile, </address> <month> September </month> <year> 1994. </year>
Reference-contexts: The most popular methods form three classes: (a) tree-based methods like the R-tree [20], and its variants (R + tree [45], hB-tree [31], P-tree [24], R fl -tree [7], Hilbert R-trees <ref> [27] </ref> etc.) (b) methods using linear quadtrees [18] or, equivalently, the z-ordering [37, 38], or other space-filling curves [14, 23] and finally (c) methods that use grid-files [36, 22]. There are also retrieval methods for the case where only the triangular inequality holds [10], [46], [47], [6].
Reference: [28] <author> Joseph B. Kruskal. </author> <title> Nonmetric multidimensional scal ing. </title> <journal> Psychometrika, </journal> <volume> 29 </volume> <pages> 1-27, </pages> <year> 1964. </year>
Reference-contexts: The above version of MDS is called metric multidimensional scaling [51], because the distances are given as numbers. Several generalizations and extensions have been proposed to the above basic algorithm: Kruskal [29] proposed a method that automatically determines a good value for k; Shepard [48], and Kruskal <ref> [28] </ref> proposed the non-metric MDS where the distance between items are specified qualitatively; Young [55] describes the individual difference MDS, which incorporates multiple distance measures, corresponding to different observers' perception of the data's difference.
Reference: [29] <author> Joseph B. Kruskal and Myron Wish. </author> <title> Multidimensional scaling. </title> <publisher> SAGE publications, </publisher> <address> Beverly Hills, </address> <year> 1978. </year>
Reference-contexts: There are several variations, but the basic method (eg., see <ref> [29] </ref>) is described next. Following the `distance' case setting, the method expects (a) a set of N items, (b) their pair-wise (dis)similarities and (c) the desirable dimensionality k. <p> The above version of MDS is called metric multidimensional scaling [51], because the distances are given as numbers. Several generalizations and extensions have been proposed to the above basic algorithm: Kruskal <ref> [29] </ref> proposed a method that automatically determines a good value for k; Shepard [48], and Kruskal [28] proposed the non-metric MDS where the distance between items are specified qualitatively; Young [55] describes the individual difference MDS, which incorporates multiple distance measures, corresponding to different observers' perception of the data's difference.
Reference: [30] <author> Karen Kukich. </author> <title> Techniques for automatically correcting words in text. </title> <journal> ACM Computing Surveys, </journal> <volume> 24(4) </volume> <pages> 377-440, </pages> <month> December </month> <year> 1992. </year>
Reference-contexts: The goal is to aid forecasting, by examining similar patterns that may have appeared in the past. In [1] we used the Euclidean distance (sum of squared errors) as the distance function between two time series. * Similarity searching in string databases, as in the case of spelling, typing <ref> [30] </ref> and OCR error correction [26]. There, given a wrong string, we should search a dictionary to find the closest strings to it.
Reference: [31] <author> David B. Lomet and Betty Salzberg. </author> <title> The hb-tree: a multiattribute indexing method with good guaranteed performance. </title> <journal> ACM TODS, </journal> <volume> 15(4) </volume> <pages> 625-658, </pages> <month> December </month> <year> 1990. </year>
Reference-contexts: The most popular methods form three classes: (a) tree-based methods like the R-tree [20], and its variants (R + tree [45], hB-tree <ref> [31] </ref>, P-tree [24], R fl -tree [7], Hilbert R-trees [27] etc.) (b) methods using linear quadtrees [18] or, equivalently, the z-ordering [37, 38], or other space-filling curves [14, 23] and finally (c) methods that use grid-files [36, 22].
Reference: [32] <author> F. Murtagh. </author> <title> A survey of recent advances in hierar chical clustering algorithms. </title> <journal> The Computer Journal, </journal> <volume> 26(4) </volume> <pages> 354-359, </pages> <year> 1983. </year>
Reference-contexts: However, none of them tries to map objects into points in `target space', nor to provide a tool for visualization. Finally, our work could be beneficial to research on clustering algorithms, where several approaches have been proposed. See, eg., <ref> [32] </ref>, [21] for surveys, [34] for a recent application in GIS, [43] [52] for applications in Information Retrieval. 3 Proposed Method In the first part, we describe the proposed algorithm, which achieves a fast mapping of objects into points, so that distances are preserved well.
Reference: [33] <author> A. Desai Narasimhalu and Stavros Christodoulakis. </author> <title> Multimedia information systems: the unfolding of a reality. </title> <journal> IEEE Computer, </journal> <volume> 24(10) </volume> <pages> 6-8, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: There we used the Euclidean distance between appropriately selected feature vectors (color attributes, moments of inertia for shape, etc.) Search-by-content is highly desirable in multimedia databases, with audio (voice, music), video etc. <ref> [33] </ref>. For example, users might want to retrieve, music scores, or video clips that are similar to a target music score or video clip.
Reference: [34] <author> Raymond T. Ng and Jiawei Han. </author> <title> Efficient and effective clustering methods for spatial data mining. </title> <booktitle> Proc. of VLDB Conf., </booktitle> <pages> pages 144-155, </pages> <month> September </month> <year> 1994. </year>
Reference-contexts: However, none of them tries to map objects into points in `target space', nor to provide a tool for visualization. Finally, our work could be beneficial to research on clustering algorithms, where several approaches have been proposed. See, eg., [32], [21] for surveys, <ref> [34] </ref> for a recent application in GIS, [43] [52] for applications in Information Retrieval. 3 Proposed Method In the first part, we describe the proposed algorithm, which achieves a fast mapping of objects into points, so that distances are preserved well.
Reference: [35] <author> Wayne Niblack, Ron Barber, Will Equitz, Myron Flickner, Eduardo Glasman, Dragutin Petkovic, Peter Yanker, Christos Faloutsos, and Gabriel Taubin. </author> <title> The QBIC project: Querying images by content using color, texture and shape. </title> <booktitle> SPIE 1993 Intl. Symposium on Electronic Imaging: Science and Technology, Conf. </booktitle> <year> 1908, </year> <title> Storage and Retrieval for Image and Video Databases, </title> <month> February </month> <year> 1993. </year> <note> Also available as IBM Research Report RJ 9203 (81511), </note> <month> Feb. 1, </month> <year> 1993, </year> <institution> Computer Science. </institution>
Reference-contexts: Some distance functions are also described. * Image and, in general, multimedia databases: In a collection of shapes [25] we would like to find shapes similar to a give one; in a collection of color images, we would like to find images with similar colors, shapes or texture <ref> [35] </ref>. There we used the Euclidean distance between appropriately selected feature vectors (color attributes, moments of inertia for shape, etc.) Search-by-content is highly desirable in multimedia databases, with audio (voice, music), video etc. [33].
Reference: [36] <author> J. Nievergelt, H. Hinterberger, and K.C. Sevcik. </author> <title> The grid file: an adaptable, symmetric multikey file structure. </title> <journal> ACM TODS, </journal> <volume> 9(1) </volume> <pages> 38-71, </pages> <month> March </month> <year> 1984. </year>
Reference-contexts: tree-based methods like the R-tree [20], and its variants (R + tree [45], hB-tree [31], P-tree [24], R fl -tree [7], Hilbert R-trees [27] etc.) (b) methods using linear quadtrees [18] or, equivalently, the z-ordering [37, 38], or other space-filling curves [14, 23] and finally (c) methods that use grid-files <ref> [36, 22] </ref>. There are also retrieval methods for the case where only the triangular inequality holds [10], [46], [47], [6]. All these methods try to exploit the triangular inequality in order to prune the search space on a range query.
Reference: [37] <author> J. Orenstein. </author> <title> Spatial query processing in an object oriented database system. </title> <booktitle> Proc. ACM SIGMOD, </booktitle> <pages> pages 326-336, </pages> <month> May </month> <year> 1986. </year>
Reference-contexts: Such a mapping provides two major benefits: 1. It can accelerate the search time for queries. The reason is that we can employ highly fine-tuned Spatial Access Methods (SAMs), like the R fl -trees [7] and the z-ordering <ref> [37] </ref>. <p> The most popular methods form three classes: (a) tree-based methods like the R-tree [20], and its variants (R + tree [45], hB-tree [31], P-tree [24], R fl -tree [7], Hilbert R-trees [27] etc.) (b) methods using linear quadtrees [18] or, equivalently, the z-ordering <ref> [37, 38] </ref>, or other space-filling curves [14, 23] and finally (c) methods that use grid-files [36, 22]. There are also retrieval methods for the case where only the triangular inequality holds [10], [46], [47], [6].
Reference: [38] <author> J.A. Orenstein. </author> <title> A comparison of spatial query process ing techniques for native and parameter spaces. </title> <booktitle> Proc. of ACM SIGMOD Conf., </booktitle> <pages> pages 343-352, </pages> <year> 1990. </year>
Reference-contexts: The most popular methods form three classes: (a) tree-based methods like the R-tree [20], and its variants (R + tree [45], hB-tree [31], P-tree [24], R fl -tree [7], Hilbert R-trees [27] etc.) (b) methods using linear quadtrees [18] or, equivalently, the z-ordering <ref> [37, 38] </ref>, or other space-filling curves [14, 23] and finally (c) methods that use grid-files [36, 22]. There are also retrieval methods for the case where only the triangular inequality holds [10], [46], [47], [6].
Reference: [39] <author> William H. Press, Brian P. Flannery, Saul A. Teukolsky, and William T. Vetterling. </author> <title> Numerical Recipes in C. </title> <publisher> Cambridge University Press, </publisher> <year> 1988. </year>
Reference-contexts: It computes the eigenvectors of the covariance matrix, sorts them in decreasing eigenvalue order, and approximates each data vector with its projections on the first k eigenvectors. The operation is closely related to the Singular Value Decomposition (SVD) <ref> [49, 39, 19] </ref> of the object-feature matrix. Our implementation of the K-L transform in Mathematica [54] is available in Appendix A, as well as on `mosaic' (URL: ftp: //olympos.cs.umd.edu /pub/SRC/ kl.m).
Reference: [40] <author> A. Ravishankar Rao and Jerry Lohse. </author> <title> Identifying high level features of texture perception. </title> <booktitle> In SPIE Conference, </booktitle> <address> San Jose, </address> <month> February </month> <year> 1992. </year>
Reference-contexts: structure analysis of 3 words; perceived personality trait relationships [41], operating on 60 different personality traits and people's perception of what goes together (like `warm' and `trusting'); physics (nuclear gamma-ray spectra pattern recognition, recognizing the different type of spins and their relationships); political science (determining ideological shifts) [55]; texture analysis <ref> [40] </ref>. However, for our applications, MDS suffers from two drawbacks: * It requires O (N 2 ) time, where N is the number of items. Thus, it is impractical for large datasets.
Reference: [41] <author> A. Kimball Romney, Roger N. Shepard, and Sara Beth Nerlove. </author> <title> Multidimensional scaling: </title> <booktitle> Theory and applications in the behavioral sciences : vol II Applications. </booktitle> <publisher> Seminar Press, </publisher> <address> New York, </address> <year> 1972. </year>
Reference-contexts: MDS has been used in numerous, diverse applications, including the following: semantic structure analysis of 3 words; perceived personality trait relationships <ref> [41] </ref>, operating on 60 different personality traits and people's perception of what goes together (like `warm' and `trusting'); physics (nuclear gamma-ray spectra pattern recognition, recognizing the different type of spins and their relationships); political science (determining ideological shifts) [55]; texture analysis [40].
Reference: [42] <author> Nick Roussopoulos, Steve Kelley, and F. Vincent. </author> <title> Nearest neighbor queries. </title> <booktitle> In Proc. of the 1995 ACM-SIGMOD Conference, </booktitle> <address> San Jose, CA, </address> <month> May </month> <year> 1995. </year> <note> to appear. </note>
Reference-contexts: Mapping objects into points has the following two applications. Firstly, it can accelerate searching for several types of queries (`query-by-example' or `range' queries, `all pairs' queries or spatial joins [9, 8], nearest neighbor queries <ref> [42] </ref> etc.), because several, highly optimized spatial access methods are readily available (R-trees [20], R fl -trees [7] etc.). Secondly, such a mapping is useful for data-mining, cluster analysis and visualization of a high-dimensionality dataset.
Reference: [43] <author> G. Salton and M.J. McGill. </author> <title> Introduction to Modern Information Retrieval. </title> <publisher> McGraw-Hill, </publisher> <year> 1983. </year>
Reference-contexts: Finally, our work could be beneficial to research on clustering algorithms, where several approaches have been proposed. See, eg., [32], [21] for surveys, [34] for a recent application in GIS, <ref> [43] </ref> [52] for applications in Information Retrieval. 3 Proposed Method In the first part, we describe the proposed algorithm, which achieves a fast mapping of objects into points, so that distances are preserved well.
Reference: [44] <author> David Sankoff and Joseph B. Kruskal. </author> <title> Time Warps, String Edits and Macromolecules: the Theory and Practice of Sequence Comparisons. </title> <publisher> Addison-Wesley Publishing Company, Inc., </publisher> <address> Reading, MA, </address> <year> 1983. </year>
Reference-contexts: It is not clear which the features should be in this case. Similarly, in matching digitized voice excerpts, we typically have to do some time-warping <ref> [44] </ref>, which makes it difficult to design feature-extraction functions. Overcoming these difficulties is exactly the motivation behind this work. Generalizing the approach by Ja-gadish, we try to map objects into k-dimensional points, assuming that a domain expert has only provided us with a distance/dis-similarity function D (fl; fl).
Reference: [45] <author> T. Sellis, N. Roussopoulos, and C. Faloutsos. </author> <title> The r+ tree: a dynamic index for multi-dimensional objects. </title> <booktitle> In Proc. 13th International Conference on VLDB, </booktitle> <pages> pages 507-518, </pages> <address> England,, </address> <month> September </month> <year> 1987. </year> <note> also available as SRC-TR-87-32, UMIACS-TR-87-3, CS-TR-1795. </note>
Reference-contexts: The most popular methods form three classes: (a) tree-based methods like the R-tree [20], and its variants (R + tree <ref> [45] </ref>, hB-tree [31], P-tree [24], R fl -tree [7], Hilbert R-trees [27] etc.) (b) methods using linear quadtrees [18] or, equivalently, the z-ordering [37, 38], or other space-filling curves [14, 23] and finally (c) methods that use grid-files [36, 22].
Reference: [46] <author> M. Shapiro. </author> <title> The choice of reference points in best match file searching. </title> <journal> Comm. of the ACM (CACM), </journal> <volume> 20(5) </volume> <pages> 339-343, </pages> <month> May </month> <year> 1977. </year>
Reference-contexts: There are also retrieval methods for the case where only the triangular inequality holds [10], <ref> [46] </ref>, [47], [6]. All these methods try to exploit the triangular inequality in order to prune the search space on a range query. However, none of them tries to map objects into points in `target space', nor to provide a tool for visualization.
Reference: [47] <author> Dennis Shasha and Tsong-Li Wang. </author> <title> New techniques for best-match retrieval. </title> <journal> ACM TOIS, </journal> <volume> 8(2) </volume> <pages> 140-158, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: There are also retrieval methods for the case where only the triangular inequality holds [10], [46], <ref> [47] </ref>, [6]. All these methods try to exploit the triangular inequality in order to prune the search space on a range query. However, none of them tries to map objects into points in `target space', nor to provide a tool for visualization.
Reference: [48] <author> R. N. Shepard. </author> <title> The analysis of proximities: Multidi mensional scaling with an unknown distance i and ii. </title> <journal> Psychometrika, </journal> <volume> 27 </volume> <pages> 125-140, 219-246, </pages> <year> 1962. </year>
Reference-contexts: The above version of MDS is called metric multidimensional scaling [51], because the distances are given as numbers. Several generalizations and extensions have been proposed to the above basic algorithm: Kruskal [29] proposed a method that automatically determines a good value for k; Shepard <ref> [48] </ref>, and Kruskal [28] proposed the non-metric MDS where the distance between items are specified qualitatively; Young [55] describes the individual difference MDS, which incorporates multiple distance measures, corresponding to different observers' perception of the data's difference.
Reference: [49] <author> Gilbert Strang. </author> <title> Linear Algebra and its Applications. </title> <publisher> Academic Press, </publisher> <year> 1980. </year> <note> 2nd edition. </note>
Reference-contexts: It computes the eigenvectors of the covariance matrix, sorts them in decreasing eigenvalue order, and approximates each data vector with its projections on the first k eigenvectors. The operation is closely related to the Singular Value Decomposition (SVD) <ref> [49, 39, 19] </ref> of the object-feature matrix. Our implementation of the K-L transform in Mathematica [54] is available in Appendix A, as well as on `mosaic' (URL: ftp: //olympos.cs.umd.edu /pub/SRC/ kl.m).
Reference: [50] <author> A.W. Toga, P.K. Banerjee, </author> <title> and E.M. Santori. Warping 3d models for interbrain comparisons. </title> <address> Neurosc. Abs., 16:247, </address> <year> 1990. </year>
Reference-contexts: Notice that the distance functions are complicated, typically requiring some warping of the two images, to make sure that the anatomical structures (eg., bones) are properly aligned, before we consider the differences <ref> [50] </ref>.
Reference: [51] <author> W. S. Torgerson. </author> <title> Multidimensional scaling: I. theory and method. </title> <journal> Psychometrika, </journal> <volume> 17 </volume> <pages> 401-419, </pages> <year> 1952. </year>
Reference-contexts: Intuitively, it treats each pair-wise distance as a `spring' between the two points; then, the algorithm tries to rearrange the positions of the k-d points to minimize the `stress' of the springs. The above version of MDS is called metric multidimensional scaling <ref> [51] </ref>, because the distances are given as numbers.
Reference: [52] <editor> C.J. Van-Rijsbergen. </editor> <booktitle> Information Retrieval. </booktitle> <address> Butter worths, London, England, </address> <year> 1979. </year> <note> 2nd edition. </note>
Reference-contexts: Finally, our work could be beneficial to research on clustering algorithms, where several approaches have been proposed. See, eg., [32], [21] for surveys, [34] for a recent application in GIS, [43] <ref> [52] </ref> for applications in Information Retrieval. 3 Proposed Method In the first part, we describe the proposed algorithm, which achieves a fast mapping of objects into points, so that distances are preserved well.
Reference: [53] <author> Dimitris Vassiliadis. </author> <title> The input-state space approach to the prediction of auroral geomagnetic activity from solar wind variables. </title> <booktitle> Int. Workshop on Applications of Artificial Intelligence in Solar Terrestrial Physics, </booktitle> <month> September </month> <year> 1993. </year>
Reference-contexts: makes it difficult to find features that would adequately describe each image (and therefore, map it into a point in feature space). * Time series, with, eg. financial data, such as stock prices, sales numbers etc., or scientific databases, with time series of sensor data, weather [11], geological, environmental, astrophysics <ref> [53] </ref> data, etc., In such databases, typical queries would be `find companies whose stock prices move similarly', or `find past days in which the solar magnetic wind showed patterns similar to today's pattern' [53]. <p> sales numbers etc., or scientific databases, with time series of sensor data, weather [11], geological, environmental, astrophysics <ref> [53] </ref> data, etc., In such databases, typical queries would be `find companies whose stock prices move similarly', or `find past days in which the solar magnetic wind showed patterns similar to today's pattern' [53]. The goal is to aid forecasting, by examining similar patterns that may have appeared in the past.
Reference: [54] <author> Stephen Wolfram. </author> <title> Mathematica. </title> <publisher> Addison Wesley, </publisher> <year> 1991. </year> <note> Second Edition. </note>
Reference-contexts: The operation is closely related to the Singular Value Decomposition (SVD) [49, 39, 19] of the object-feature matrix. Our implementation of the K-L transform in Mathematica <ref> [54] </ref> is available in Appendix A, as well as on `mosaic' (URL: ftp: //olympos.cs.umd.edu /pub/SRC/ kl.m). <p> Murphy and David W. Aha for maintaining the UC-Irvine Repository of Machine Learning Databases and Domain Theories; Prof. Howard Elman and Doug Oard for help with SVD algorithms. A Karhunen-Loeve Transform This is the code for the K-L transform in Mathemat-ica <ref> [54] </ref> (* given a matrix mat_ with $n$ vectors of $m$ attributes, it creates a matrix with $n$ vectors and their first $k$ most 'important' attributes (ie., the K-L expansions of these 10 $n$ vectors) *) KLexpansion [ mat_, k_:2] := mat .
Reference: [55] <author> Forrest W. Young. </author> <title> Multidimensional scaling : History, Theory and Applications. </title> <publisher> Lawrence Erlbaum associates, </publisher> <address> Hillsdale, New Jersey, </address> <year> 1987. </year> <month> 12 </month>
Reference-contexts: In section 5 we list the conclusions. 2 Survey Here we present some background information about older attempts to solve the problem. First we discuss the Multidimensional Scaling (MDS) method that has been used in several diverse fields (eg., social sciences, psychology, market research, physics <ref> [55] </ref>) to solve the `distance' case problem. Then, we present the Karhunen-Loeve (K-L) transform and the closely related Singular Value Decomposition (SVD) that has been used for dimensionality reduction (`features' case). <p> Several generalizations and extensions have been proposed to the above basic algorithm: Kruskal [29] proposed a method that automatically determines a good value for k; Shepard [48], and Kruskal [28] proposed the non-metric MDS where the distance between items are specified qualitatively; Young <ref> [55] </ref> describes the individual difference MDS, which incorporates multiple distance measures, corresponding to different observers' perception of the data's difference. <p> the following: semantic structure analysis of 3 words; perceived personality trait relationships [41], operating on 60 different personality traits and people's perception of what goes together (like `warm' and `trusting'); physics (nuclear gamma-ray spectra pattern recognition, recognizing the different type of spins and their relationships); political science (determining ideological shifts) <ref> [55] </ref>; texture analysis [40]. However, for our applications, MDS suffers from two drawbacks: * It requires O (N 2 ) time, where N is the number of items. Thus, it is impractical for large datasets.
References-found: 55

