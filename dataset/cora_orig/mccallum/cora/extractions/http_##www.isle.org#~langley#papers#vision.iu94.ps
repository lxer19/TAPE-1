URL: http://www.isle.org/~langley/papers/vision.iu94.ps
Refering-URL: http://www.isle.org/publications.html
Root-URL: 
Email: (langley@cs.stanford.edu)  (binford@cs.stanford.edu)  (levitt@flamingo.stanford.edu)  
Title: Learning Object Models From Visual Observation and Background Knowledge  
Author: Pat Langley Thomas O. Binford Tod S. Levitt 
Address: 2451 High Street, Palo Alto, CA 94301 USA  Stanford, CA 94305 USA  
Affiliation: Institute for the Study of Learning and Expertise  Robotics Laboratory, Computer Science Department Stanford University,  
Note: To appear in Proceedings of the ARPA Image Understanding Workshop (1994). Monterey, CA: Morgan Kaufmann.  
Abstract: This research project aims to use machine learning techniques to improve the performance of three-dimensional vision systems. Building on our earlier work, our approach represents and organizes models of object classes in a hierarchy of probabilistic concepts, and it uses Bayesian inference methods to focus attention, recognize objects in images, and make predictions about occluded parts. The learning process involves not only updating of the probabilistic descriptions in the concept hierarchy but also involves changes in the structure of memory, including the creation of novel categories, the merging of similar classes, and the elimination of unnecessary ones. An evaluation metric based on probability theory guides decisions about such structural changes, and background knowledge about function and generic object classes further constrains the learning process. We plan to carry out systematic experiments to determine the ability of this approach to improve both classification accuracy and predictive ability on novel images. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Beis, J. S., & Lowe, D. G. </author> <year> (1993). </year> <title> Learning indexing functions for 3D model-based object recognition. </title> <booktitle> Working Notes of the AAAI Fall Symposium on Machine Learning in Computer Vision (pp. </booktitle> <pages> 50-54). </pages> <address> Raleigh, NC: </address> <publisher> AAAI Press. </publisher>
Reference: <author> Binford, T. O., Levitt, T. S., & Mann, W. B. </author> <year> (1989). </year> <title> Bayesian inference in model-based machine vision. </title> <editor> In L. N. Kanal, T. S. Levitt, & J. F. Lemmer (Eds.), </editor> <booktitle> Uncertainty in artificial intelligence (Vol. </booktitle> <volume> 3). </volume> <publisher> North Holland. </publisher>
Reference-contexts: Representation and Organization of Object Models In order to develop programs that can learn from visual observations, we must first select some representation of physical objects. As in our previous work <ref> (Binford, Levitt, & Mann, 1989) </ref>, we represent object models in long-term memory at different levels of part/subpart aggregation. <p> Information about conditional probabilities, which is stored with the concepts in the hierarchy, is stored on the influence links in the Bayesian network. Our approach to visual recognition relies directly on this correspondence <ref> (Binford, Levitt, & Mann, 1989) </ref>. 3. Recognition of Object Classes In vision, one of the basic tasks is to recognize and infer the structure of three-dimensional objects from observational information that is present in imagery. <p> This task requires processing at the multiple levels described in the previous section, each of which introduces its own Learning Object Models 3 forms of uncertainty. In tackling the recognition problem we will draw on the methods we have used in our earlier work <ref> (Binford et al., 1989) </ref>, which incorporate both bottom-up processing (from pixels to edges to ribbons to cylinders to objects) and top-down processing. At each level, one maintains competing hypotheses about the proper interpretation for portions of the image. <p> Newly created nodes are shown in gray. 5. Contributions of the Research Although the proposed research will build on our previous work on computer vision <ref> (Binford et al., 1989) </ref> and machine learning (Gennari at al., 1989), it will address issues that go beyond the simple merging of these two traditionally separate paradigms.
Reference: <author> Conklin, D. </author> <year> (1993). </year> <title> Transformation-invariant indexing and machine discovery for computer vision. </title> <booktitle> Working Notes of the AAAI Fall Symposium on Machine Learning in Computer Vision (pp. </booktitle> <pages> 10-14). </pages> <address> Raleigh: </address> <publisher> AAAI Press. </publisher>
Reference: <author> Cook, D., Hall, L., Stark, L., & Bowyer, K. </author> <year> (1993). </year> <title> Learning combination of evidence functions in object recognition. </title> <booktitle> Working Notes of the AAAI Fall Symposium on Machine Learning in Computer Vision (pp. </booktitle> <pages> 139-143). </pages> <address> Raleigh, NC: </address> <publisher> AAAI Press. </publisher>
Reference: <author> Edwards, W. </author> <year> (1993). </year> <title> Utility theories: Measurements and applications. </title> <address> Boston: </address> <publisher> Kluwer. </publisher>
Reference-contexts: Our response to this problem relies on knowledge of objects' functions, embodied in a utility metric <ref> (Edwards, 1993) </ref> that influences the application of the four learning operators.
Reference: <author> Gros, P. </author> <year> (1993). </year> <title> Matching and clustering: Two steps towards automatic object model generation in computer vision. </title> <booktitle> Working Notes of the AAAI Fall Symposium on Machine Learning in Computer Vision (pp. </booktitle> <pages> 40-44). </pages> <address> Raleigh: </address> <publisher> AAAI Press. </publisher>
Reference: <author> Levitt, T. S., Binford, T. O., & Ettinger, G. J. </author> <year> (1990). </year> <title> Utility-based control for computer vision. </title> <editor> In R. </editor> <address> D. </address>
Reference-contexts: Partial matches along the part-of hierarchy are compared against the object models to predict locations of imagery features for other imaged object components. Decision-theoretic control algorithms order the actions with the highest predicted payoff to gather additional evidence in support or denial of hypothesized imagery interpretations <ref> (Levitt, Binford, & Ettinger, 1990) </ref>, thus directing attention to useful regions of the image. The instantiated network of matches forms a hierarchical Bayesian network in which nodes represent competing local interpretations and arcs represent hypothesized part-of relationships.
Reference: <editor> Schacter, T. S. Levitt, L. N. Kanal, & J. F. Lemmer (Eds.), </editor> <booktitle> Uncertainty in artificial intelligence (Vol. </booktitle> <volume> 4). </volume> <publisher> North Holland. </publisher>
Reference: <author> Gennari, J. H., Langley, P., & Fisher, D. H. </author> <year> (1989). </year> <title> Models of incremental concept formation. </title> <booktitle> Artificial Intelligence, </booktitle> <pages> 40 , 11-61. </pages>
Reference-contexts: As new nodes are instantiated from matches, and as additional image processing of 2D/3D geometric and material evidence is attached to existing nodes, algorithms for updating Bayesian networks propagate beliefs over the entire network. By contrast, the recognition module we have used in our work on machine learning <ref> (Gennari, Langley, & Fisher, 1989) </ref> starts with the most abstract concept in an is-hierarchy at a given level of aggregation, then estimates the probability for each specialized child of that concept. <p> Similarly, given generic models for vehicle components and images of particular components, acquire models for specific types of tires and doors, as well as models of individual components. To address this problem of learning specialized models, we are borrowing directly from our previous work on incremental, unsupervised concept learning <ref> (Gennari, Langley, & Fisher, 1989) </ref>. One can view generic object models as nodes at the top (most general) level of an is-a hierarchy. <p> Newly created nodes are shown in gray. 5. Contributions of the Research Although the proposed research will build on our previous work on computer vision (Binford et al., 1989) and machine learning <ref> (Gennari at al., 1989) </ref>, it will address issues that go beyond the simple merging of these two traditionally separate paradigms.
Reference: <author> Kibler, D., & Langley, P. </author> <year> (1988). </year> <title> Machine learning as an experimental science. </title> <booktitle> Proceedings of the Third Euro-pean Working Session on Learning (pp. </booktitle> <pages> 81-92). </pages> <note> Glas-gow: Pittman. Reprinted in J. </note> <editor> W. Shavlik & T. G. Di-etterich (Eds.), </editor> <booktitle> Readings in Machine Learning. </booktitle> <publisher> Mor-gan Kaufmann. </publisher>
Reference-contexts: The empirical studies of our learning algorithm, to which we now turn, must take the best from both of these worlds. 6. Plans for Experimental Evaluation In evaluating our system's ability to learn, we will draw upon experimental methods that are now commonly used within the machine learning community <ref> (Kibler & Langley, 1988) </ref>. In this framework, the goal of learning is to improve performance on some task, in this case the recognition and description of objects in images.
Reference: <author> McKusick, K. B., & Langley, P. </author> <year> (1991). </year> <title> Constraints on tree structure in concept formation. </title> <booktitle> Proceedings of the Twelfth International Joint Conference on Artificial Intelligence (pp. </booktitle> <pages> 810-816). </pages> <address> Sydney: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Pope, A. R., & Lowe, D. G. </author> <year> (1993). </year> <title> Learning 3D object recognition models from 2D images. </title> <booktitle> Working Notes of the AAAI Fall Symposium on Machine Learning in Computer Vision (pp. </booktitle> <pages> 35-39). </pages> <address> Raleigh: </address> <publisher> AAAI Press. </publisher>
Reference: <author> Segen, J. </author> <year> (1993). </year> <title> Learning shape models for a vision-based human-computer interface. </title> <booktitle> Working Notes of the AAAI Fall Symposium on Machine Learning in Computer Vision (pp. </booktitle> <pages> 120-124). </pages> <address> Raleigh, NC: </address> <publisher> AAAI Press. </publisher>
Reference: <author> Sengupta, K., & Boyer, K. L. </author> <year> (1993). </year> <title> Incremental model base updating: Learning new model sites. </title> <booktitle> Working Notes of the AAAI Fall Symposium on Machine Learning in Computer Vision (pp. </booktitle> <pages> 1-5). </pages> <address> Raleigh, NC: </address> <publisher> AAAI Press. </publisher>
Reference: <author> Thompson, K., & Langley, P. </author> <year> (1991). </year> <title> Concept formation in structured domains. </title> <editor> In D. Fisher, M. Pazzani, </editor> & <address> P. </address>
Reference-contexts: This approach should give the effects of sorting through a hierarchy of probabilistic concepts but provide both a cleaner semantics and consistency with our previous work on visual recognition. The scheme also provides a more coherent way to handle objects that have part-of structure, which our previous learning work <ref> (Thompson & Langley, 1991) </ref> addressed in a somewhat ad hoc manner. We will use the same probabilistic inference procedure to draw on functional knowledge during recognition. The random variables at these nodes will specify time-indexed parametric mappings among sets of random variables that represent objects. <p> In particular, we must: * Identify robust methods for unsupervised learning over structural descriptions and multiple levels of aggregation. Previous work on structural induction, including our own <ref> (Thompson & Langley, 1991) </ref> has used impoverished representations, and Bin-ford et al.'s (1989) formalism for representing physical objects provides a much richer description language but also a greater challenge than addressed in previous learning research. * Explore the use of background knowledge, including functional information, to constrain the learning process.
Reference: <author> Langley (Eds.), </author> <title> Computational approaches to concept formation. </title> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Winston, P. H., Binford, T. O., Katz, B., & Lowry, M. </author> <year> (1983). </year> <title> Learning physical descriptions from functional descriptions. </title> <booktitle> Proceedings of the Third National Conference on Artificial Intelligence (pp. </booktitle> <pages> 433-439). </pages> <address> Wash-ington, DC: </address> <publisher> AAAI Press. </publisher>
References-found: 17

