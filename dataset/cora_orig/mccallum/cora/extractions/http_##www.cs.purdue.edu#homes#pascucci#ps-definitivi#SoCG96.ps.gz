URL: http://www.cs.purdue.edu/homes/pascucci/ps-definitivi/SoCG96.ps.gz
Refering-URL: http://www.cs.purdue.edu/homes/pascucci/curriculum/node4.html
Root-URL: http://www.cs.purdue.edu
Title: Splitting a Complex of Convex Polytopes In Any Dimension  
Author: Chandrajit L. Bajaj Valerio Pascucci 
Address: West Lafayette, IN 47907  
Affiliation: Computer Sciences Department Purdue University  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> AGARWAL, P. K., AND MATOU SEK, J. </author> <title> On range searching with semialgebraic sets. </title> <journal> Discrete Comput. Geom. </journal> <volume> 11 (1994), </volume> <pages> 393-418. </pages>
Reference-contexts: The alternative scheme we use is to define the traversal of the search structure associated with the complex of poly-topes as a range search query <ref> [1, 18] </ref>. In particular, when we intersect two polyhedra, A and B, we wish to limit the computation of split cells in polyhedron A to the zones intersecting the boundary facets of B.
Reference: [2] <author> AGARWAL, P. K., AND MATOU SEK, J. </author> <title> Dynamic half-space range reporting and its applications. </title> <booktitle> Algorithmica 13 (1995), </booktitle> <pages> 325-345. </pages>
Reference-contexts: This is achieved by performing, for each face of B, some halfspace range reporting queries and an incremental update of the search structure (as described in <ref> [2] </ref>) when new vertices are introduced in A. Since we intersect the boundary facets of B with the poly-topes of A we avoid having to perform the detection [8] and computation of intersections between pairs of convex poly-topes [6, 7]. <p> Thus, the preliminary step can be reduced to a half-space range-reporting problem. We use the search structure described in <ref> [2] </ref>. For a set of m points, the construction of this search structure requires O (m 1+* ) time.
Reference: [3] <author> BAJAJ, C., AND DEY, T. K. </author> <title> Convex decomposition of polyhedra and robustness. </title> <journal> SIAM J. Comput. </journal> <volume> 21 (1992), </volume> <pages> 339-364. </pages>
Reference-contexts: The solution to this problem has several applications. One goal is to perform boolean set operations. The solution can also be used to decompose a polyhedron into convex polytopes <ref> [3] </ref> and to generate good meshes [4]. In higher dimensional spaces it can be used to efficiently compute isocontours of linear approximations of scalar fields (a basic technique of Scientific Visualization) [17, 19].
Reference: [4] <author> BERN, M., AND EPPSTEIN, D. </author> <title> Mesh generation and optimal triangulation. In Computing in Euclidean Geometry, </title> <editor> D.-Z. Du and F. K. Hwang, Eds., </editor> <volume> vol. </volume> <booktitle> 1 of Lecture Notes Series on Computing. World Scientific, </booktitle> <address> Singapore, </address> <year> 1992, </year> <pages> pp. 23-90. </pages>
Reference-contexts: The solution to this problem has several applications. One goal is to perform boolean set operations. The solution can also be used to decompose a polyhedron into convex polytopes [3] and to generate good meshes <ref> [4] </ref>. In higher dimensional spaces it can be used to efficiently compute isocontours of linear approximations of scalar fields (a basic technique of Scientific Visualization) [17, 19].
Reference: [5] <author> BRISSON, E. </author> <title> Representing geometric structures in d dimensions: Topology and order. </title> <journal> Discrete Comput. Geom. </journal> <volume> 9 (1993), </volume> <pages> 387-426. </pages>
Reference-contexts: The approach taken here can also be included in a set of robust algorithms [11, 13, 15, 20, 27, 28] based on finite precision arithmetic. It is also defined in a dimension independent framework <ref> [5, 16, 24, 25] </ref>.
Reference: [6] <author> CHAZELLE, B. </author> <title> An optimal algorithm for intersecting three-dimensional convex polyhedra. </title> <journal> SIAM J. Comput. </journal> <volume> 21, 4 (1992), </volume> <pages> 671-696. </pages>
Reference-contexts: Since we intersect the boundary facets of B with the poly-topes of A we avoid having to perform the detection [8] and computation of intersections between pairs of convex poly-topes <ref> [6, 7] </ref>. The basic step of our algorithm is the splitting of a convex polytope with a hyperplane. This has the ad 1 vantage of simplicity and known topological structure in any dimension [14].
Reference: [7] <author> CHAZELLE, B., AND DOBKIN, D. P. </author> <title> Intersection of convex objects in two and three dimensions. </title> <editor> J. </editor> <booktitle> ACM 34 (1987), </booktitle> <pages> 1-27. </pages>
Reference-contexts: Since we intersect the boundary facets of B with the poly-topes of A we avoid having to perform the detection [8] and computation of intersections between pairs of convex poly-topes <ref> [6, 7] </ref>. The basic step of our algorithm is the splitting of a convex polytope with a hyperplane. This has the ad 1 vantage of simplicity and known topological structure in any dimension [14].
Reference: [8] <author> DOBKIN, D. P., AND KIRKPATRICK, D. G. </author> <title> Fast detection of polyhedral intersection. </title> <type> Theoret. </type> <institution> Comput. Sci. </institution> <month> 27 </month> <year> (1983), </year> <pages> 241-253. </pages>
Reference-contexts: Since we intersect the boundary facets of B with the poly-topes of A we avoid having to perform the detection <ref> [8] </ref> and computation of intersections between pairs of convex poly-topes [6, 7]. The basic step of our algorithm is the splitting of a convex polytope with a hyperplane. This has the ad 1 vantage of simplicity and known topological structure in any dimension [14].
Reference: [9] <author> EDELSBRUNNER, H. </author> <title> Algorithms in Combinatorial Geometry, </title> <booktitle> vol. 10 of EATCS Monographs on Theoretical Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <address> Heidelberg, West Germany, </address> <year> 1987. </year>
Reference-contexts: In Section 3 we show how to take advantage of this fact. As final remark we should notice the similarity of this approach with the beneath-beyond <ref> [9] </ref> algorithm for the computation of the convex hull of a set of points. In fact both algorithms are based on the incremental update of the incidence graph of a polytope.
Reference: [10] <author> EDELSBRUNNER, H., AND M UCKE, E. P. </author> <title> Simulation of simplicity: a technique to cope with degenerate cases in geometric algorithms. </title> <journal> ACM Trans. Graph. </journal> <volume> 9 (1990), </volume> <pages> 66-104. </pages>
Reference-contexts: We first state some properties of G relating to h. Assume in the following that h does not contain any vertex of c. The configuration with h intersecting a vertex of c is a degenerate case. Following the SoS paradigm <ref> [10] </ref>, we ignore it. In practice this is a general position assumption (see [21]) by which we do not consider the cases that occur with zero probability. This does not mean that they are impossible but that they can be removed with a perturbation.
Reference: [11] <author> FORTUNE, S., AND MILENKOVIC, V. </author> <title> Numerical stability of algorithms for line arrangements. </title> <booktitle> In Proc. 7th Annu. ACM Sympos. </booktitle> <institution> Comput. Geom. </institution> <year> (1991), </year> <pages> pp. 334-341. </pages>
Reference-contexts: In higher dimensional spaces it can be used to efficiently compute isocontours of linear approximations of scalar fields (a basic technique of Scientific Visualization) [17, 19]. The approach taken here can also be included in a set of robust algorithms <ref> [11, 13, 15, 20, 27, 28] </ref> based on finite precision arithmetic. It is also defined in a dimension independent framework [5, 16, 24, 25].
Reference: [12] <author> GR UNBAUM, B. </author> <title> Convex Polytopes. </title> <publisher> Wiley, </publisher> <address> New York, NY, </address> <year> 1967. </year>
Reference-contexts: It is well known that a necessary and sufficient condition for a graph to represent the edges of a linear convex polytope in E 3 is that it must be planar and triply connected <ref> [12] </ref>. For k-dimensional polytopes it is also known that the edges form a k-connected graph (this condition is only necessary). In the case of the polytopes of a weak complex, these properties are not always satisfied be cause their faces can be partitioned.
Reference: [13] <author> HOPCROFT, J. E., AND KAHN, P. J. </author> <title> A paradigm for robust geometric algorithms. </title> <booktitle> Algorithmica 7 (1992), </booktitle> <pages> 339-380. </pages>
Reference-contexts: In higher dimensional spaces it can be used to efficiently compute isocontours of linear approximations of scalar fields (a basic technique of Scientific Visualization) [17, 19]. The approach taken here can also be included in a set of robust algorithms <ref> [11, 13, 15, 20, 27, 28] </ref> based on finite precision arithmetic. It is also defined in a dimension independent framework [5, 16, 24, 25]. <p> The main idea for robustness (similar to <ref> [13] </ref>) is to compute the result using mostly symbolic manipulations and further reduce any numerical computations as much as possible. *Supported in part by AFOSR grant F49620-93-10138, NSF grant CCR 92-22467 and ONR grant N00014-94-1-0370 The algorithm for splitting a polyhedral complex with a hy-perplane h is divided into three phases: <p> In this section we present a technique that can be used to force the primary numerical computations to be consistent with the symbolic structure of the input data. The technique adopted here is, basically, an extension of the approach introduced by Hopcroft and Kahn <ref> [13] </ref>. Our approach will also prevent the algorithm from generating (almost) degenerate polytopes in the result. 4.1 Consistent Classification In Section 2, we have assumed that the numerical computations were correct and we conceptually perturbed the splitting hyperplane h so that no vertex would belong to it. <p> Now we allow the input polytopes to lie on h; thereby avoiding the creation of very small features. To enforce the consistency of the classification performed in Step 1 of Split we apply the following property (in <ref> [13] </ref> the property was considered only for k = 2): Property 5 If k + 1 affinely independent vertices of a k polytope c lie on h then c lies on h. <p> We can map f 0 to cover all S without any overlapping. Then @c + is homeomorphic to a (k 1)- sphere. For c a similar argument holds. 7 4.2 Collapsing Polytopes Even if we assume, as in <ref> [13] </ref>, that the input data is an ff-representation so that we obtain in output a fi-representation, with fi suitably related to ff, we may need to remove some small polytopes to obtain a good decomposition under certain constraints.
Reference: [14] <author> KINCSES, J. </author> <title> On polytopes cut by flats. </title> <journal> Discrete Comput. Geom. </journal> <volume> 14 (1995), </volume> <pages> 287-294. </pages>
Reference-contexts: The basic step of our algorithm is the splitting of a convex polytope with a hyperplane. This has the ad 1 vantage of simplicity and known topological structure in any dimension <ref> [14] </ref>. Overview In Section 2 we outline the approach for a simplified context where only a single polytope is taken into account and numerical computations are considered exact. In Section 3 the method is extended for a complex of convex polytopes.
Reference: [15] <author> LI, Z., AND MILENKOVIC, V. </author> <title> Constructing strongly convex hulls using exact or rounded arithmetic. </title> <booktitle> In Proc. 6th Annu. ACM Sympos. </booktitle> <institution> Comput. Geom. </institution> <year> (1990), </year> <pages> pp. 235-243. </pages>
Reference-contexts: In higher dimensional spaces it can be used to efficiently compute isocontours of linear approximations of scalar fields (a basic technique of Scientific Visualization) [17, 19]. The approach taken here can also be included in a set of robust algorithms <ref> [11, 13, 15, 20, 27, 28] </ref> based on finite precision arithmetic. It is also defined in a dimension independent framework [5, 16, 24, 25].
Reference: [16] <author> LIENHARDT, P. </author> <title> N-dimensional generalized combinatorial maps and cellular quasi-manifolds. </title> <journal> International Journal of Computational Geometry & Applications 4, </journal> <volume> 3 (1994), </volume> <pages> 275-324. </pages>
Reference-contexts: The approach taken here can also be included in a set of robust algorithms [11, 13, 15, 20, 27, 28] based on finite precision arithmetic. It is also defined in a dimension independent framework <ref> [5, 16, 24, 25] </ref>.
Reference: [17] <author> LORENSEN, W., AND H.CLINE. </author> <title> Marching cubes: a high resolution 3d surface construction algorithm. </title> <journal> A.C.M. Computer Graphics 21, </journal> <volume> 4 (1987), </volume> <pages> 163-170. </pages>
Reference-contexts: The solution can also be used to decompose a polyhedron into convex polytopes [3] and to generate good meshes [4]. In higher dimensional spaces it can be used to efficiently compute isocontours of linear approximations of scalar fields (a basic technique of Scientific Visualization) <ref> [17, 19] </ref>. The approach taken here can also be included in a set of robust algorithms [11, 13, 15, 20, 27, 28] based on finite precision arithmetic. It is also defined in a dimension independent framework [5, 16, 24, 25].
Reference: [18] <author> MATOU SEK, J. </author> <title> Range searching with efficient hierarchical cuttings. </title> <journal> Discrete Comput. Geom. </journal> <volume> 10, 2 (1993), </volume> <pages> 157-182. </pages>
Reference-contexts: The alternative scheme we use is to define the traversal of the search structure associated with the complex of poly-topes as a range search query <ref> [1, 18] </ref>. In particular, when we intersect two polyhedra, A and B, we wish to limit the computation of split cells in polyhedron A to the zones intersecting the boundary facets of B.
Reference: [19] <author> MAX, N., HANRAHAN, P., AND CRAWFIS, R. </author> <title> Area and volume coherence for efficient visualization of 3d scalar functions. </title> <journal> A.C.M. Computer Graphics 24, </journal> <volume> 5 (1990), </volume> <pages> 27-33. </pages>
Reference-contexts: The solution can also be used to decompose a polyhedron into convex polytopes [3] and to generate good meshes [4]. In higher dimensional spaces it can be used to efficiently compute isocontours of linear approximations of scalar fields (a basic technique of Scientific Visualization) <ref> [17, 19] </ref>. The approach taken here can also be included in a set of robust algorithms [11, 13, 15, 20, 27, 28] based on finite precision arithmetic. It is also defined in a dimension independent framework [5, 16, 24, 25].
Reference: [20] <author> MILENKOVIC, V. </author> <title> Robust polygon modeling. </title> <booktitle> Computer-Aided Design 25, 9 (1993). (special issue on Uncertainties in Geometric Design). </booktitle>
Reference-contexts: In higher dimensional spaces it can be used to efficiently compute isocontours of linear approximations of scalar fields (a basic technique of Scientific Visualization) [17, 19]. The approach taken here can also be included in a set of robust algorithms <ref> [11, 13, 15, 20, 27, 28] </ref> based on finite precision arithmetic. It is also defined in a dimension independent framework [5, 16, 24, 25].
Reference: [21] <author> MULMULEY, K. </author> <title> Computational Geometry: An Introduction Through Randomized Algorithms. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1994. </year>
Reference-contexts: Assume in the following that h does not contain any vertex of c. The configuration with h intersecting a vertex of c is a degenerate case. Following the SoS paradigm [10], we ignore it. In practice this is a general position assumption (see <ref> [21] </ref>) by which we do not consider the cases that occur with zero probability. This does not mean that they are impossible but that they can be removed with a perturbation.
Reference: [22] <author> NAYLOR, B. </author> <title> Constructing good partitioning trees. </title> <booktitle> In Proc. Graphics Interface '93 (Toronto, ON, </booktitle> <year> 1993), </year> <pages> pp. 181-191. </pages>
Reference-contexts: This happens both on trees optimized with respect to the number of cells induced by the tree decomposition [26] and for trees optimized with respect to the expected traversal time <ref> [22] </ref>. Moreover, performing boolean set operations with a BSP [23, 29] involves many extraneous computations since each traversal of a face in a tree requires splitting the face at each visited node.
Reference: [23] <author> NAYLOR, B., AMANTIDES, J., AND THIBAULT, W. </author> <title> Merging bsp trees yields polyhedral set operations. </title> <journal> Comput. Graph. </journal> <volume> 24, 4 (1990), </volume> <pages> 115-126. </pages> <note> Proc. SIGGRAPH '90. </note>
Reference-contexts: It is also possible to collapse small undesired polytopes using symbolic postprocessing. A leading idea is the maintenance of a search structure. The difference of our approach is that we do not use partitioning trees <ref> [23, 26, 29, 31] </ref> as search trees structure since its optimization is lost as cascading computations are performed. This happens both on trees optimized with respect to the number of cells induced by the tree decomposition [26] and for trees optimized with respect to the expected traversal time [22]. <p> This happens both on trees optimized with respect to the number of cells induced by the tree decomposition [26] and for trees optimized with respect to the expected traversal time [22]. Moreover, performing boolean set operations with a BSP <ref> [23, 29] </ref> involves many extraneous computations since each traversal of a face in a tree requires splitting the face at each visited node. If the leaves of the tree reached by a face at the end of the traversal all have equal classification then the computed subdivisions are discarded.
Reference: [24] <author> PAOLUZZI, A., BERNARDINI, F., CATTANI, C., AND FER-RUCCI, V. </author> <title> Dimension-independent modeling with sim-plicial complexes. </title> <journal> ACM Transactions on Graphics 12, </journal> <month> 1 (Jan. </month> <year> 1993), </year> <pages> 56-102. </pages>
Reference-contexts: The approach taken here can also be included in a set of robust algorithms [11, 13, 15, 20, 27, 28] based on finite precision arithmetic. It is also defined in a dimension independent framework <ref> [5, 16, 24, 25] </ref>.
Reference: [25] <author> PASCUCCI, V., FERRUCCI, V., AND PAOLUZZI, A. </author> <title> Dimension-independent convex-cell based HPC: Representation scheme and implementation issues. In Solid Modeling '95, </title> <booktitle> Third ACM/IEEE Symposium on Solid Modeling and Applications (Salt Lake City, </booktitle> <address> Utah, </address> <year> 1995), </year> <editor> C. Hoffmann and J. Rossignac, Eds., </editor> <publisher> ACM Press, </publisher> <pages> pp. 163-174. </pages>
Reference-contexts: The approach taken here can also be included in a set of robust algorithms [11, 13, 15, 20, 27, 28] based on finite precision arithmetic. It is also defined in a dimension independent framework <ref> [5, 16, 24, 25] </ref>.
Reference: [26] <author> PATERSON, M. S., AND YAO, F. F. </author> <title> Efficient binary space partitions for hidden-surface removal and solid modeling. </title> <journal> Discrete Comput. Geom. </journal> <volume> 5 (1990), </volume> <pages> 485-503. </pages>
Reference-contexts: It is also possible to collapse small undesired polytopes using symbolic postprocessing. A leading idea is the maintenance of a search structure. The difference of our approach is that we do not use partitioning trees <ref> [23, 26, 29, 31] </ref> as search trees structure since its optimization is lost as cascading computations are performed. This happens both on trees optimized with respect to the number of cells induced by the tree decomposition [26] and for trees optimized with respect to the expected traversal time [22]. <p> The difference of our approach is that we do not use partitioning trees [23, 26, 29, 31] as search trees structure since its optimization is lost as cascading computations are performed. This happens both on trees optimized with respect to the number of cells induced by the tree decomposition <ref> [26] </ref> and for trees optimized with respect to the expected traversal time [22]. Moreover, performing boolean set operations with a BSP [23, 29] involves many extraneous computations since each traversal of a face in a tree requires splitting the face at each visited node.
Reference: [27] <author> STEWART, A. J. </author> <title> Local robustness and its application to polyhedral intersection. </title> <journal> International Journal of Computational Geometry & Applications 4, </journal> <volume> 1 (1994), </volume> <pages> 87-118. </pages>
Reference-contexts: In higher dimensional spaces it can be used to efficiently compute isocontours of linear approximations of scalar fields (a basic technique of Scientific Visualization) [17, 19]. The approach taken here can also be included in a set of robust algorithms <ref> [11, 13, 15, 20, 27, 28] </ref> based on finite precision arithmetic. It is also defined in a dimension independent framework [5, 16, 24, 25].
Reference: [28] <author> SUGIHARA, K. </author> <title> A robust and consistent algorithm for intersecting convex polyhedra. Comput. Graph. </title> <booktitle> Forum 13, 3 (1994), </booktitle> <pages> 45-54. </pages> <note> Proc. EUROGRAPHICS '94. </note>
Reference-contexts: In higher dimensional spaces it can be used to efficiently compute isocontours of linear approximations of scalar fields (a basic technique of Scientific Visualization) [17, 19]. The approach taken here can also be included in a set of robust algorithms <ref> [11, 13, 15, 20, 27, 28] </ref> based on finite precision arithmetic. It is also defined in a dimension independent framework [5, 16, 24, 25].
Reference: [29] <author> THIBAULT, W. C., AND NAYLOR, B. F. </author> <title> Set operations on polyhedra using binary space partitioning trees. </title> <booktitle> In Proc. SIGGRAPH'87 (1987), </booktitle> <pages> pp. 153-162. </pages>
Reference-contexts: It is also possible to collapse small undesired polytopes using symbolic postprocessing. A leading idea is the maintenance of a search structure. The difference of our approach is that we do not use partitioning trees <ref> [23, 26, 29, 31] </ref> as search trees structure since its optimization is lost as cascading computations are performed. This happens both on trees optimized with respect to the number of cells induced by the tree decomposition [26] and for trees optimized with respect to the expected traversal time [22]. <p> This happens both on trees optimized with respect to the number of cells induced by the tree decomposition [26] and for trees optimized with respect to the expected traversal time [22]. Moreover, performing boolean set operations with a BSP <ref> [23, 29] </ref> involves many extraneous computations since each traversal of a face in a tree requires splitting the face at each visited node. If the leaves of the tree reached by a face at the end of the traversal all have equal classification then the computed subdivisions are discarded.
Reference: [30] <author> TROTTER, W. T. </author> <title> Combinatorics and Partially Ordered Sets: Dimension Theory. </title> <booktitle> Johns Hopkins Series in the Mathematical Sciences. </booktitle> <publisher> The Johns Hopkins University Press, </publisher> <year> 1992. </year>
Reference-contexts: We can construct for the cell c a graph G with the same structure of the Hasse diagram <ref> [30] </ref> but with oriented arcs corresponding to the direction of the inclusion relation.
Reference: [31] <author> VAN E CEK JR., G. Brep-index: </author> <title> a multidimensional space partitioning tree. </title> <journal> Internat. J. Comput. Geom. Appl. </journal> <volume> 1, 3 (1991), </volume> <pages> 243-261. </pages>
Reference-contexts: It is also possible to collapse small undesired polytopes using symbolic postprocessing. A leading idea is the maintenance of a search structure. The difference of our approach is that we do not use partitioning trees <ref> [23, 26, 29, 31] </ref> as search trees structure since its optimization is lost as cascading computations are performed. This happens both on trees optimized with respect to the number of cells induced by the tree decomposition [26] and for trees optimized with respect to the expected traversal time [22].
References-found: 31

