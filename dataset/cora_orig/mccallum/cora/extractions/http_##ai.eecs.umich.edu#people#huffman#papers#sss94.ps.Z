URL: http://ai.eecs.umich.edu/people/huffman/papers/sss94.ps.Z
Refering-URL: http://ai.eecs.umich.edu/people/huffman/hufpubs.html
Root-URL: http://www.eecs.umich.edu
Email: huffman@umich.edu  
Title: The requirements of flexible instructability  
Author: Scott B. Huffman 
Address: 1101 Beal Ave. Ann Arbor, Michigan 48109-2110  
Affiliation: Artificial Intelligence Laboratory The University of Michigan  
Abstract: Tutorial natural language instruction consistently produces high quality human learning, and is a potentially powerful knowledge source for teaching artificial agents as well. Its power comes from being interactive, situated (focused on specific tasks), and highly flexible, allowing an instructor to communicate any type of knowledge in whatever situation it is needed. However, tutorial instruction has received little attention in machine learning. In particular, although some systems have learned from instruction-like input, there has been no attempt to identify and target the combination of capabilities required for fully flexible tutorability. In this paper, by analyzing the demands of the tutorial learning task from the learning agent's perspective, we identify a set of requirements to be met by a complete tutorable agent. The requirements fall into three categories, corresponding to comprehension, interaction, and learning. Identifying the requirements provides a target an evaluation metric for systems that purport to be tutorable via natural language instructions. A number of the requirements (but far from all) are met by an instructable agent called Instructo-Soar, which supports more flexible instruction than previous instructable systems (e.g., learning apprentices). An earlier version of this paper appears in Working notes of the 1994 AAAI Spring Symposium on Active Natural Language Processing, ed. C. Martin, J. Lehman, and K. Eiselt. 
Abstract-found: 1
Intro-found: 1
Reference: [Alterman and Carpenter, 1991] <author> Richard Alterman and Tamitha Carpenter. </author> <title> Reading instructions. </title> <booktitle> In Proceedings of the Thirteenth Annual Conference of the Cognitive Science Society, </booktitle> <pages> pages 653-657, </pages> <month> August </month> <year> 1991. </year>
Reference-contexts: It illustrates how the requirements can be used to measure an instructable system's tutorability. The comparison should not be viewed as an absolute evaluation, because of the three systems, only Instructo-Soar was designed for learning from interactive instruction. FLOBN <ref> [Alterman et al., 1991; Alterman and Carpenter, 1991] </ref> learns to alter past procedures for new situations, from recipe-like instructions. For instance, it learns to alter its procedure for using a pay phone to use an Airfone, from step-by-step instructions.
Reference: [Alterman et al., 1991] <author> Richard Alterman, Roland Zito-Wolf, and Tamitha Carpenter. </author> <title> Interaction, comprehension, and instruction usage. </title> <type> Technical Report CS-91-161, </type> <institution> Computer Science Department, Brandeis University, </institution> <month> July </month> <year> 1991. </year>
Reference-contexts: It illustrates how the requirements can be used to measure an instructable system's tutorability. The comparison should not be viewed as an absolute evaluation, because of the three systems, only Instructo-Soar was designed for learning from interactive instruction. FLOBN <ref> [Alterman et al., 1991; Alterman and Carpenter, 1991] </ref> learns to alter past procedures for new situations, from recipe-like instructions. For instance, it learns to alter its procedure for using a pay phone to use an Airfone, from step-by-step instructions.
Reference: [Chapman, 1990] <author> David Chapman. </author> <title> Vision, Instruction, and Action. </title> <type> PhD thesis, </type> <institution> Massachusetts Institute of Technology, Artificial Intelligence Laboratory, </institution> <month> April </month> <year> 1990. </year>
Reference: [Davis, 1979] <author> R. Davis. </author> <title> Interactive transfer of expertise: Acquisition of new inference rules. </title> <journal> Artificial Intelligence, </journal> <volume> 12(2) </volume> <pages> 409-427, </pages> <year> 1979. </year>
Reference-contexts: Teaching specific cases is less burdensome to the instructor than producing complete procedures that include general conditions for applicability of each step, handling of all possible contingencies, etc. A number of authors have described the advantages of situated knowledge elicitation (e.g., <ref> [Davis, 1979; Gruber, 1989] </ref>).
Reference: [DiEugenio and Webber, 1992] <author> B. DiEugenio and B. Webber. </author> <title> Plan recognition in understanding instructions. </title> <editor> In J. Hendler, editor, </editor> <booktitle> Proceedings of the First International Conference on Artificial Intelligence Planning Systems, </booktitle> <pages> pages 52-61, </pages> <address> College Park, MD, </address> <year> 1992. </year>
Reference: [DiEugenio and White, 1992] <author> B. DiEugenio and M. White. </author> <title> On the interpretation of natural language instructions. </title> <booktitle> In Proceedings COLING 92, </booktitle> <month> July </month> <year> 1992. </year>
Reference-contexts: As Table 1 shows, FLOBN uses im peratives; it does not support very flexible interaction (as it was not designed to take interactive instruction); and it meets many of complete tutorability's learning requirements. The AnimNL project <ref> [DiEugenio and White, 1992; DiEugenio and Web ber, 1992] </ref> has focused on the mapping problem, in an animated agent. It handles more complex language and mapping than the other two systems, 9 including some types of incompleteness and hypotheticals.
Reference: [DiEugenio, 1992] <author> B. DiEugenio. </author> <title> Understanding natural language instructions: The case of purpose clauses. </title> <booktitle> In Proceedings of Annual Meeting of the ACL, </booktitle> <month> July </month> <year> 1992. </year>
Reference-contexts: The mapping task can be difficult, involving all of the problems of linguistic interpretation. In general, it may involve reasoning about the task itself. For example, the agent may use task knowledge to find an operator with specified effects <ref> [DiEugenio, 1992] </ref>, or pragmatic knowledge to resolve referents. This is the mapping problem. 2. The agent must interact with the instructor in a flexible way to obtain instructions. This interaction may be driven by the agent, by the instructor, or both.
Reference: [Emihovich and Miller, 1988] <author> Catherine Emihovich and Gloria E. Miller. </author> <title> Talking to the turtle: A discourse analysis of Logo instruction. </title> <booktitle> Discourse Processes, </booktitle> <volume> 11 </volume> <pages> 183-201, </pages> <year> 1988. </year>
Reference-contexts: In human tutorial dialogues, initiation of instruction is mixed between student and teacher. One study indicates that teacher initiation is more prevalent early in instruction; student initiation increases as the student learns, and then drops off again as the task is mastered <ref> [Emihovich and Miller, 1988] </ref>. Instructor-initiated instruction is difficult to support because instruction events may interrupt the agent's ongoing processing. Thus, instructable systems to date have not fully supported instructor-initiated instruction. Agent-initiated instruction can be directed in (at least) two ways: by verification or by impasses.
Reference: [Frederking, 1988] <author> R. E. Frederking. </author> <title> Integrated natural language dialogue: A computational model. </title> <publisher> Kluwer Academic Press, </publisher> <address> Boston, </address> <year> 1988. </year>
Reference: [Gruber, 1989] <author> T. Gruber. </author> <title> Automated knowledge acquisition for strategic knowledge. </title> <booktitle> Machine Learning, </booktitle> <address> 4(3-4):293-336, </address> <year> 1989. </year>
Reference-contexts: Teaching specific cases is less burdensome to the instructor than producing complete procedures that include general conditions for applicability of each step, handling of all possible contingencies, etc. A number of authors have described the advantages of situated knowledge elicitation (e.g., <ref> [Davis, 1979; Gruber, 1989] </ref>).
Reference: [Huffman and Laird, 1992] <author> Scott B. Huffman and John E. Laird. </author> <title> Dimensions of complexity in learning from interactive instruction. </title> <editor> In Jon Erickson, editor, </editor> <booktitle> Proceedings of Cooperative Intelligent Robotics in Space III, SPIE Volume 1829, </booktitle> <month> November </month> <year> 1992. </year> <month> 11 </month>
Reference-contexts: A protocol of a student being taught to use a flight simulator revealed that 119 out of 508 instructions (23%) involved hypothetical situations, with the remainder applying to the current situation. Instructions that apply to the current situation are called implicitly situated <ref> [Huffman and Laird, 1992] </ref>; the situation they are intended to apply to is implicit rather than explicitly stated. These include typical imperative commands (e.g., "Move to the yellow table"). <p> Since the instruction itself says nothing about the situation it should be applied in, the current situation (the task being performed and the current state) is implied. In contrast, instructions that specify elements of the situation they are meant to apply to are explicitly situated <ref> [Huffman and Laird, 1992] </ref>; the language of the instruction explicitly indicates a hypothetical situation. These include conditionals and instructions with purpose clauses, such as: When using chocolate chips, add them to the coconut mixture before pressing into pan. To restart this, you can hit R or shift-R.
Reference: [Huffman and Laird, 1993] <author> Scott B. Huffman and John E. Laird. </author> <title> Learning procedures from interactive natural language instructions. </title> <editor> In P. Utgoff, editor, </editor> <booktitle> Machine Learning: Proceedings of the Tenth International Conference, </booktitle> <year> 1993. </year>
Reference-contexts: Identifying these requirements provides a target that is, a set of evaluation criteria for agents that purport to be instructable via tutorial natural language instruction. The task analysis for tutorial instruction grows out of work on Instructo-Soar <ref> [Huffman, 1994; Huffman and Laird, 1993] </ref>, a tutorable agent that can behave and learn from a variety of types of instructions. <p> It handles more complex language and mapping than the other two systems, 9 including some types of incompleteness and hypotheticals. AnimNL has not attempted other aspects of flexible interaction, and does no learning; it takes and fully executes instructions one by one. Instructo-Soar <ref> [Huffman, 1994; Huffman and Laird, 1993] </ref>, built within Soar [Laird et al., 1987], is a tutorable agent specifically designed for learning from highly flexible, interactive instruction.
Reference: [Huffman, 1994] <author> Scott B. Huffman. </author> <title> Instructable autonomous agents. </title> <type> PhD thesis, </type> <institution> University of Michigan, Dept. of Electrical Engineering and Computer Science, </institution> <month> January </month> <year> 1994. </year>
Reference-contexts: Identifying these requirements provides a target that is, a set of evaluation criteria for agents that purport to be instructable via tutorial natural language instruction. The task analysis for tutorial instruction grows out of work on Instructo-Soar <ref> [Huffman, 1994; Huffman and Laird, 1993] </ref>, a tutorable agent that can behave and learn from a variety of types of instructions. <p> After being told to "Move up," the agent is able to move above the red block. Supporting flexible interaction for commands gives the instructor a great amount of flexibility in teaching a set of tasks. A mathematical analysis <ref> [Huffman, 1994] </ref> revealed that a procedure with only 6 actions can be taught with over 100 possible instruction sequences; for 7 actions, the number grows to over 400. 3.2.3 Situation flexibility. <p> It handles more complex language and mapping than the other two systems, 9 including some types of incompleteness and hypotheticals. AnimNL has not attempted other aspects of flexible interaction, and does no learning; it takes and fully executes instructions one by one. Instructo-Soar <ref> [Huffman, 1994; Huffman and Laird, 1993] </ref>, built within Soar [Laird et al., 1987], is a tutorable agent specifically designed for learning from highly flexible, interactive instruction.
Reference: [Just and Carpenter, 1976] <author> Marcel A. Just and Patricia A. Carpenter. </author> <title> Verbal comprehension in instructional situations. </title> <editor> In David Klahr, editor, </editor> <title> Cognition and Instruction. </title> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hillsdale, NJ, </address> <year> 1976. </year>
Reference: [Kodratoff and Tecuci, 1987] <editor> Yves Kodratoff and Gheorghe Tecuci. </editor> <title> Techniques of design and DISCIPLE learning apprentice. </title> <journal> International Journal of Expert Systems, </journal> <volume> 1(1) </volume> <pages> 39-66, </pages> <year> 1987. </year>
Reference-contexts: Thus, instructable systems to date have not fully supported instructor-initiated instruction. Agent-initiated instruction can be directed in (at least) two ways: by verification or by impasses. Some learning apprentice systems, such as LEAP [Mitchell et al., 1990] and DISCIPLE <ref> [Kodratoff and Tecuci, 1987] </ref>, ask the instructor to verify or alter each reasoning step. The advantage is that each step is examined by the instructor; the disadvantage, of course, is that each step must be examined. An alternative is to drive instruction requests by impasses in the agent's task performance.
Reference: [Laird et al., 1987] <author> John E. Laird, Allen Newell, and Paul S. Rosenbloom. </author> <title> Soar: An architecture for general intelligence. </title> <journal> Artificial Intelligence, </journal> <volume> 33(1) </volume> <pages> 1-64, </pages> <year> 1987. </year>
Reference-contexts: AnimNL has not attempted other aspects of flexible interaction, and does no learning; it takes and fully executes instructions one by one. Instructo-Soar [Huffman, 1994; Huffman and Laird, 1993], built within Soar <ref> [Laird et al., 1987] </ref>, is a tutorable agent specifically designed for learning from highly flexible, interactive instruction. Applied to a simulated robotic domain, it can learn hierarchies of completely new procedures and a variety of other domain knowledge from interactive natural language instructions like those shown in Figure 1.
Reference: [Mann and Thompson, 1988] <author> William C. Mann and Sandra A. Thompson. </author> <title> Rhetorical structure theory: Toward a functional theory of text organization. </title> <booktitle> Text, </booktitle> <volume> 8(3) </volume> <pages> 243-281, </pages> <year> 1988. </year>
Reference-contexts: A complete tutorable agent must handle instruction events involving any knowledge that is applicable in some way within the ongoing task and discourse context. Similar to the notion of discourse coherence <ref> [Mann and Thompson, 1988] </ref>, a complete tutorable agent needs to support any instruction event with knowledge coherence; that is, any instruction event delivering knowledge that makes sense in current context.
Reference: [Martin and Firby, 1991] <author> Charles E. Martin and R. James Firby. </author> <title> Generating natural language expectations from a reactive execution system. </title> <booktitle> In Proceedings of the Thirteenth Annual Conference of the Cognitive Science Society, </booktitle> <pages> pages 811-815, </pages> <month> August </month> <year> 1991. </year>
Reference: [Miller and Johnson-Laird, 1976] <author> George A. Miller and Philip N. Johnson-Laird. </author> <title> Language and Perception. </title> <publisher> Cambridge Univ. Press, </publisher> <address> Cambridge, </address> <year> 1976. </year>
Reference-contexts: It would be desirable to lay out the entire space of action types and parameters that may need to be mapped from instruction. Unfortunately, such a complete characterization is hard to find. There have been some limited attempts in AI (e.g., [Schank, 1975; Wilks, 1975]) and linguistics (e.g, <ref> [Miller and Johnson-Laird, 1976] </ref>). Defining the requirement that the mapping problem places on a completely tutorable agent, in its most general form, is straightforward.
Reference: [Mitchell et al., 1990] <author> T. M. Mitchell, Sridhar Mahadevan, and Louis I. Steinberg. </author> <title> LEAP: A learning apprentice system for VLSI design. </title> <editor> In Yves Kodratoff and R. S. Michalski, editors, </editor> <booktitle> Machine Learning: An artificial intelligence approach, Vol. III. </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1990. </year>
Reference-contexts: Instructor-initiated instruction is difficult to support because instruction events may interrupt the agent's ongoing processing. Thus, instructable systems to date have not fully supported instructor-initiated instruction. Agent-initiated instruction can be directed in (at least) two ways: by verification or by impasses. Some learning apprentice systems, such as LEAP <ref> [Mitchell et al., 1990] </ref> and DISCIPLE [Kodratoff and Tecuci, 1987], ask the instructor to verify or alter each reasoning step. The advantage is that each step is examined by the instructor; the disadvantage, of course, is that each step must be examined.
Reference: [Newell et al., 1990] <author> Allen Newell, Gregg Yost, John E. Laird, Paul S. Rosen-bloom, and Erik Altmann. </author> <title> Formulating the problem space computational model. </title> <booktitle> In Proceedings of the 25th Anniversary Symposium, </booktitle> <institution> School of Computer Science, Carnegie Mellon University, </institution> <month> September </month> <year> 1990. </year>
Reference-contexts: Seven of the eleven requirements are met at least partially. Most distinguishing are: 1. Instructo-Soar can learn each type of knowledge it uses during task performance from instruction (T 5 ). Types are identified by the agent's computational model (the problem space computational model <ref> [Newell et al., 1990] </ref>). They include state inferences; operator proposals, effects, and terminations; and control knowledge. Thus, the agent can be termed complete w.r.t. instructability of its knowledge types. 2.
Reference: [Newell, 1981] <author> Allen Newell. </author> <title> The knowledge level. </title> <journal> AI Magazine, </journal> <volume> 2(2) </volume> <pages> 1-20, </pages> <year> 1981. </year>
Reference-contexts: For instance, a task requiring ten primitive steps may be taught as a flat sequence of the ten steps, as two subtasks of five steps each, etc. * Knowledge level: The instructor provides knowledge to the agent at the knowledge level <ref> [Newell, 1981] </ref>, because the instructions refer to objects and actions in the world, not to symbol-level structures (e.g., data structures) within the agent.
Reference: [Schank, 1975] <author> Roger C. Schank. </author> <title> Conceptual Information Processing. </title> <publisher> Amer--ican Elsevier, </publisher> <address> New York, </address> <year> 1975. </year>
Reference-contexts: It would be desirable to lay out the entire space of action types and parameters that may need to be mapped from instruction. Unfortunately, such a complete characterization is hard to find. There have been some limited attempts in AI (e.g., <ref> [Schank, 1975; Wilks, 1975] </ref>) and linguistics (e.g, [Miller and Johnson-Laird, 1976]). Defining the requirement that the mapping problem places on a completely tutorable agent, in its most general form, is straightforward.
Reference: [Wertsch, 1979] <author> James V. Wertsch. </author> <title> From social interaction to higher psychological processes: A clarification and application of Vygotsky's theory. </title> <booktitle> Human Development, </booktitle> <volume> 22 </volume> <pages> 1-22, </pages> <year> 1979. </year>
Reference: [Wilks, 1975] <author> Y.A. Wilks. </author> <title> A preferential, pattern-seeking, semantics for natural language inference. </title> <journal> Artificial Intelligence, </journal> <volume> 6, </volume> <year> 1975. </year> <month> 13 </month>
Reference-contexts: It would be desirable to lay out the entire space of action types and parameters that may need to be mapped from instruction. Unfortunately, such a complete characterization is hard to find. There have been some limited attempts in AI (e.g., <ref> [Schank, 1975; Wilks, 1975] </ref>) and linguistics (e.g, [Miller and Johnson-Laird, 1976]). Defining the requirement that the mapping problem places on a completely tutorable agent, in its most general form, is straightforward.
References-found: 25

