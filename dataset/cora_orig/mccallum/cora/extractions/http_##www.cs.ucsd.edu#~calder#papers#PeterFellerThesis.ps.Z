URL: http://www.cs.ucsd.edu/~calder/papers/PeterFellerThesis.ps.Z
Refering-URL: http://www.cs.ucsd.edu/~calder/papers.html
Root-URL: http://www.cs.ucsd.edu
Title: Value Profiling for Instructions and Memory Locations  
Degree: A thesis submitted in partial satisfaction of the requirements for the degree Master of Science in Computer Engineering by Peter T. Feller Committee in charge: Professor Bradley Calder, Chairperson Professor Dean Tullsen Professor Jeanne Ferrante  
Affiliation: UNIVERSITY OF CALIFORNIA, SAN DIEGO  
Abstract: UCSD Technical Report CS98-581, April 1998 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. M. Anderson, L. M. Berc, J. Dean, S. G. Ghemawat, M. R. Henzinger, S-T. A. Leung, R. L. Sites, M. T. Vandevoorde, C. A. Waldspurger, W. E. Weihl, and G. Chrysos. </author> <title> Continous profiling: </title> <booktitle> Where have all the cycles gone? In Proceedings of the Sixteenth ACM Symposium on Operating System Principles, </booktitle> <month> October </month> <year> 1997. </year>
Reference-contexts: Profiling a program can be a very time consuming process. To speed up that process, certain profilers select instructions to profile either randomly or on some selection criteria. The Continuous Profiling Infrastructure (CPI) implemented by Anderson et al <ref> [1] </ref> collects random samples at a rate of 5200 samples/sec with only 1-3% in profiling overhead. The profiling architecture works as follows. Each processor generates an interrupt after a specified number of events, allowing the interrupted instruction and the various event counters to be captured into a buffer. <p> On out-of-order processors, it is difficult to correlate the event counter information with the instruction that actually was responsible for the event. ProfileMe [14], which is an extension to the DEC CPI <ref> [1] </ref>, addresses that issue. Rather than counting events and sampling the PC, ProfileMe samples instructions. The authors also use paired sampling which provides concurrency information about the instructions currently being executed in the pipeline. <p> Register windows address this issue, however by predicting register values one could achieve some of the benefit that register windows offer. Gabbay [17] also showed that register file prediction worked particularly well for ALU instructions on a limited number of programs. The continuous profiling infrastructure (CPI) <ref> [1] </ref> could be extended to include value information. For continuous profiling to be a viable solution, it needs to be very effective. CPI addressed that by randomly sampling instructions. For doing accurate value profiling additional research is needed to determine if random sampling is sufficient for value profiling.
Reference: [2] <author> J. Auslander, M. Philipose, C. Chambers, S.J. Eggers, and B.N. Bershad. </author> <title> Fast, effective dynamic compilation. </title> <booktitle> In Proceedings of the ACM SIGPLAN '96 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 149-159. </pages> <publisher> ACM, </publisher> <month> May </month> <year> 1996. </year>
Reference-contexts: For these techniques to be effective the compiler must determine which sections of code to concentrate on for the adaptive execution. Existing techniques for dynamic compilation and adaptive execution require the user to identify run-time invariants using user guided annotations <ref> [2, 12, 15, 25, 26] </ref>. One of the goals of value profiling is to provide an automated approach for identifying semi-invariant variables and to use this to guide dynamic compilation and adaptive execution. <p> Consel and Noel [12] use partial evaluation techniques to automatically generate templates for run-time code generation, although their approach still requires the user to annotate arguments of the top-level procedures, global variables and a few data structures as run-time constants. Auslander et al <ref> [2] </ref> proposed a dynamic compilation system that uses a unique form of binding time analysis to generate templates for code sequences that have been identified as semi-invariant. Their approach currently uses user defined annotations to indicate which variables are semi-invariant.
Reference: [3] <author> T. Autrey and M. Wolfe. </author> <title> Initial results for glacial variable analysis. </title> <booktitle> In 9th International Workshop on Languages and Compilers for Parallel Computing, </booktitle> <month> August </month> <year> 1996. </year>
Reference-contexts: Code fragments can then be optimized by partitioning the invariant parts of the program fragment. Knoblock and Ruf [25] used a form of staging analysis and annotations to guide data specialization. Autrey and Wolfe <ref> [3] </ref> have started to investigate a form of staging analysis for automatic identification of semi-invariant variables.
Reference: [4] <author> T. Ball and J. Larus. </author> <title> Efficient path profiling. </title> <booktitle> In 29th International Symposium on Microarchitecture, </booktitle> <pages> pages 46-57, </pages> <month> December </month> <year> 1996. </year>
Reference-contexts: However, the profiles discussed in this section do not measure path frequencies. To determine the most frequently executed path, one would have to estimate the path from the basic block profile. This approach does not always give the correct result. Ball and Larus <ref> [4] </ref> introduce a method to efficiently profile a program's executed paths. IV.C.2 Code and Data Placement Pettis and Hansen [30] used profile information to guide code-positioning. The idea is to place frequently executed code sections next to each other in the address space, thereby reducing the chances of cache conflicts.
Reference: [5] <author> B. Calder and D. Grunwald. </author> <title> Reducing indirect function call overhead in C++ programs. </title> <booktitle> In 1994 ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 397-408, </pages> <month> January </month> <year> 1994. </year>
Reference-contexts: IV.C.3 C++ Profiling Providing run-time type feedback via a profile was the approach Holzle and Ungar [23] suggested for inlining virtual function calls. Calder et al [7] use profile information to quantify the difference of C++ programs and C programs, and in an independent study the authors <ref> [5] </ref> use profile feedback to help predict indirect function calls. Dean et al [13] use profiling information to selectively inline virtual functions, based on their execution count. IV.C.4 Miscellaneous Profiles have been used to aid the compiler in promoting variables, which are executed the most frequently, into registers [33, 37].
Reference: [6] <author> B. Calder, D. Grunwald, and A. Srivastava. </author> <title> The predictability of branches in libraries. </title> <booktitle> In 28th International Symposium on Microarchitecture, </booktitle> <pages> pages 24-34, </pages> <address> Ann Arbor, MI, </address> <month> November </month> <year> 1995. </year> <note> IEEE. </note>
Reference-contexts: The profiling information was used to determine if past runs of a program with certain input data could help in predicting branches for future runs with different input data. Young and Smith [40] used profiling to capture the path preceding each conditional branch in a program. Calder et al <ref> [6] </ref> used profiling to show that common C and FORTRAN library routines have predictable behavior between different applications. Optimizations which depend upon run-time profile data share one common objective. They intend to focus their optimizations on the most common executed code sections and program paths.
Reference: [7] <author> B. Calder, D. Grunwald, and B. Zorn. </author> <title> Quantifying behavioral differences between C and C++ programs. </title> <journal> Journal of Programming Languages, </journal> <volume> 2(4) </volume> <pages> 313-351, </pages> <year> 1994. </year>
Reference-contexts: There will be one general version of the code, and a special version of the code. The specialized version of the code will be conditioned on the invariant variable. A selection mechanism based on the invariant variable will choose which code to execute. Calder and Grunwald <ref> [7] </ref> found that up to 80% of all function calls in C++ languages are made indirectly. These indirect function calls are virtual function calls, also referred to as methods or dynamically dispatched functions. <p> Calder et al [8] use profiling and placement techniques from Gloy et al [20] to guide data placement. IV.C.3 C++ Profiling Providing run-time type feedback via a profile was the approach Holzle and Ungar [23] suggested for inlining virtual function calls. Calder et al <ref> [7] </ref> use profile information to quantify the difference of C++ programs and C programs, and in an independent study the authors [5] use profile feedback to help predict indirect function calls. Dean et al [13] use profiling information to selectively inline virtual functions, based on their execution count.
Reference: [8] <author> B. Calder, S. John, and T. Austin. </author> <title> Cache-concious data placement. </title> <type> Technical Report, </type> <institution> University of California, </institution> <address> San Diego, </address> <year> 1998. </year>
Reference-contexts: Along with the cache configuration and procedure sizes, the temporal ordering information is used to estimate the conflict cost of a potential procedure ordering. Calder et al <ref> [8] </ref> use profiling and placement techniques from Gloy et al [20] to guide data placement. IV.C.3 C++ Profiling Providing run-time type feedback via a profile was the approach Holzle and Ungar [23] suggested for inlining virtual function calls.
Reference: [9] <author> P. P. Chang and W. W. Hwu. </author> <title> Profile-guided automatic inline expansion for C programs. </title> <journal> Software Practice and Experience, </journal> <volume> 22(5) </volume> <pages> 349-376, </pages> <year> 1992. </year>
Reference-contexts: Reinman et al [31] used profile information to determine the load-store dependency in programs. A load which is directly dependent upon a store might be able to bypass memory by using the value of the store directly. Additional research <ref> [21, 9] </ref> focused on inlining functions given a run-time profile. Inlining functions permits the compiler to perform additional optimizations such as register allocation, code scheduling, common subexpression elimination, constant propagation, and dead code elimination. Profiles have also been used for instruction scheduling [11].
Reference: [10] <author> P. P. Chang, S. A. Mahlke, and W. W. Hwu. </author> <title> Using profile information to assist classic compiler code optimizations. </title> <journal> Software Practice and Experience, </journal> <volume> 21(12) </volume> <pages> 1301-1321, </pages> <year> 1991. </year>
Reference-contexts: Chen et al [11] used a control-flow profile to guide code motion. In addition, they used a memory-dependence profile to reorder loads and stores in a program. Other research has used profiles on a broader basis. Chang et al <ref> [10] </ref> used profile information to assist in several classic code optimizations, such as loop invariant code removal, global variable migration, loop induction variable migration etc. The advantage 24 Table IV.1: Basic Block Quantile Table.
Reference: [11] <author> W. C. Chen, S. A. Mahlke, N. J. Warter, S. Anik, and W. W. Hwu. </author> <title> Profile-assisted instruction scheduling. </title> <journal> International Journal for Parallel Programming, </journal> <volume> 22(2) </volume> <pages> 151-181, </pages> <year> 1994. </year> <month> 79 </month>
Reference-contexts: Additional research [21, 9] focused on inlining functions given a run-time profile. Inlining functions permits the compiler to perform additional optimizations such as register allocation, code scheduling, common subexpression elimination, constant propagation, and dead code elimination. Profiles have also been used for instruction scheduling <ref> [11] </ref>. The order in which instructions are executed, is largely dependent on the control flow of the program, and the data dependency between instructions. Chen et al [11] used a control-flow profile to guide code motion. <p> Profiles have also been used for instruction scheduling <ref> [11] </ref>. The order in which instructions are executed, is largely dependent on the control flow of the program, and the data dependency between instructions. Chen et al [11] used a control-flow profile to guide code motion. In addition, they used a memory-dependence profile to reorder loads and stores in a program. Other research has used profiles on a broader basis.
Reference: [12] <author> C. Consel and F. Noel. </author> <title> A general approach for run-time specialization and its application to C. </title> <booktitle> In Thirteenth ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 145-156. </pages> <publisher> ACM, </publisher> <month> January </month> <year> 1996. </year>
Reference-contexts: For these techniques to be effective the compiler must determine which sections of code to concentrate on for the adaptive execution. Existing techniques for dynamic compilation and adaptive execution require the user to identify run-time invariants using user guided annotations <ref> [2, 12, 15, 25, 26] </ref>. One of the goals of value profiling is to provide an automated approach for identifying semi-invariant variables and to use this to guide dynamic compilation and adaptive execution. <p> Knoblock and Ruf [25] used a form of staging analysis and annotations to guide data specialization. Autrey and Wolfe [3] have started to investigate a form of staging analysis for automatic identification of semi-invariant variables. Consel and Noel <ref> [12] </ref> use partial evaluation techniques to automatically generate templates for run-time code generation, although their approach still requires the user to annotate arguments of the top-level procedures, global variables and a few data structures as run-time constants.
Reference: [13] <author> J. Dean, C. Chambers, and D. Grove. </author> <title> Selective specialization for object-oriented languages. </title> <booktitle> In Proceedings of the ACM SIGPLAN '95 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 93-102. </pages> <publisher> ACM, </publisher> <month> June </month> <year> 1995. </year>
Reference-contexts: They also found that the performance gain achieved using procedure inlining in object oriented languages is higher than in FORTRAN or C. Dean et al <ref> [13, 21] </ref> extend the approach of customization by specializing only those cases where the highest benefit can be achieved. Selective specialization uses a run-time profile to determine exactly where customization would be most beneficial. <p> Calder et al [7] use profile information to quantify the difference of C++ programs and C programs, and in an independent study the authors [5] use profile feedback to help predict indirect function calls. Dean et al <ref> [13] </ref> use profiling information to selectively inline virtual functions, based on their execution count. IV.C.4 Miscellaneous Profiles have been used to aid the compiler in promoting variables, which are executed the most frequently, into registers [33, 37].
Reference: [14] <author> J. Dean, J. E. Hicks, C. A. Waldspurger, W. E. Weihl, and G. Chrysos. </author> <title> Pro-fileme:hardware support for instruction-level profiling on out-of-order processors. </title> <booktitle> In 30th International Symposium on Microarchitecture, </booktitle> <pages> pages 292-302, </pages> <month> December </month> <year> 1997. </year>
Reference-contexts: Upon overflow of that buffer a separate daemon collects that sampled data and stores it into a database. On out-of-order processors, it is difficult to correlate the event counter information with the instruction that actually was responsible for the event. ProfileMe <ref> [14] </ref>, which is an extension to the DEC CPI [1], addresses that issue. Rather than counting events and sampling the PC, ProfileMe samples instructions. The authors also use paired sampling which provides concurrency information about the instructions currently being executed in the pipeline.
Reference: [15] <author> D.R. Engler, W.C. Hsieh, and M.F. Kaashoek. </author> <title> `C: A language for high-level efficient, and machine-independent dynamic code generation. </title> <booktitle> In Thirteenth ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 131-144. </pages> <publisher> ACM, </publisher> <month> January </month> <year> 1996. </year>
Reference-contexts: For these techniques to be effective the compiler must determine which sections of code to concentrate on for the adaptive execution. Existing techniques for dynamic compilation and adaptive execution require the user to identify run-time invariants using user guided annotations <ref> [2, 12, 15, 25, 26] </ref>. One of the goals of value profiling is to provide an automated approach for identifying semi-invariant variables and to use this to guide dynamic compilation and adaptive execution.
Reference: [16] <author> J. A. Fisher and S. M. Freudenberger. </author> <title> Predicting conditional branch directions from previous runs of a program. </title> <booktitle> In Proceedings of the Fifth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS-V), </booktitle> <pages> pages 85-95, </pages> <address> Boston, Mass., </address> <month> October </month> <year> 1992. </year> <note> ACM. </note>
Reference-contexts: One common use is to use profiling information to hand tune existing software [36], which is a common technique employed by software developers. Other uses for profiling are discussed in the following paragraphs. IV.C.1 Branch Path Profiling Fisher and Freudenberger <ref> [16] </ref> used profiling to gather information on the branching behavior of several programs. The profiling information was used to determine if past runs of a program with certain input data could help in predicting branches for future runs with different input data.
Reference: [17] <author> F. Gabbay and A. Mendelson. </author> <title> Speculative execution based on value prediction. </title> <type> EE Department TR 1080, </type> <institution> Technion - Israel Institue of Technology, </institution> <month> November </month> <year> 1996. </year>
Reference-contexts: Value Profiling is an approach that can identify the invariance and the top N values of a variable. The invariance of a variable is also important when doing Value Prediction. Value prediction <ref> [17, 27, 28] </ref> enables programs to exceed the limits which are placed upon them by their data-dependencies. The goal is to predict at run-time the outcome value of instructions before they are executed, and forwarding these speculated values to instructions which depend on them. <p> Another use for value profiling is code specialization. Value profiling information could be used to identify invariant or semi-invariant variables and then apply code specialization to certain parts of the program as illustrated in Chapter X. II.A Value Prediction The recent publications on value prediction <ref> [17, 27, 28] </ref> in hardware provided motivation for our research into value profiling. Lipasti et al [27] introduced the term value locality, which describes the likely hood of the recurrence of a previously seen value within a storage location. <p> there is a high degree of temporal locality in the values produced by instructions, but this does not necessarily equate to the instruction's degree of invariance, which is needed for certain compiler optimizations. 3 4 Last value prediction is implemented in hardware using an N entry Value History Table (VHT) <ref> [17] </ref>. The VHT contains a value field and an optional tag, which would store the identity of the instruction which is mapped to the entry. The PC of the executing instruction will be used to hash into that table to retrieve the last value. <p> His motivation for using profiling information was to classify the instructions tendency to be value predictable. The opcodes of instructions found to be predictable were annotated. Only instructions marked predictable were considered for value prediction. The main advantage of this approach compared to the author's previous approach <ref> [17] </ref> was better usage of the prediction table, and decreased number of mispredictions. Value prediction can benefit in several ways from value profiling. By classifying instructions into semi/invariant, invariant or variant, one can determine which instructions not to value predict. <p> This is necessary so the called procedure can use the registers. When returning to the procedure those registers need to be restored. Register windows address this issue, however by predicting register values one could achieve some of the benefit that register windows offer. Gabbay <ref> [17] </ref> also showed that register file prediction worked particularly well for ALU instructions on a limited number of programs. The continuous profiling infrastructure (CPI) [1] could be extended to include value information. For continuous profiling to be a viable solution, it needs to be very effective.
Reference: [18] <author> F. Gabbay and A. Mendelson. </author> <booktitle> Can program profiling support value prediction? In 30th International Symposium on Microarchitecture, </booktitle> <pages> pages 270-280, </pages> <month> December </month> <year> 1997. </year>
Reference-contexts: If the stride is zero, the value is constant, and this equates to last value prediction. Several different value predictor models have been proposed <ref> [18, 34, 39] </ref>. Wang et. al [39] studied the performance of two different hybrid predictors in comparison to several stand-alone predictors. The first hybrid is a combination of a LVP and a stride predictor, the second one a combination of a stride predictor and a 2-level predictor. <p> Of all correctly predicted results, add/subtracts make up 41%, loads 32%, logic operations 3%, shift operations 10% and set operations 6.5%. They mention that different instruction types need to be studied separately, and therefore suggest a hybrid predictor based on different instruction types. 5 Gabbay et al <ref> [18] </ref> studied the applicability of program profiling to value prediction. His motivation for using profiling information was to classify the instructions tendency to be value predictable. The opcodes of instructions found to be predictable were annotated. Only instructions marked predictable were considered for value prediction.
Reference: [19] <author> D.M. Gallagher, W.Y. Chen, S.A. Mahlke, J.C. Gyllenhaal, and W.W. Hwu. </author> <title> Dynamic memory disambiguation using the memory conflict buffer. </title> <booktitle> In Six International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 183-193, </pages> <month> October </month> <year> 1994. </year>
Reference-contexts: By classifying instructions into semi/invariant, invariant or variant, one can determine which instructions not to value predict. This not only increases the utilization of the prediction table, but also reduces the number of mispredictions. II.A.1 Load Speculation The Memory Conflict Buffer (MCB) proposed by Gallagher et al <ref> [19] </ref> provides a hardware solution with compiler support to allow load instructions to speculatively execute before stores. The addresses of speculative loads are stored with a conflict bit in the MCB.
Reference: [20] <author> N. Gloy, T. Blackwell, M. D. Smith, and B. Calder. </author> <title> Procedure placement using temporal ordering information. </title> <booktitle> In 30th International Symposium on Microarchitecture, </booktitle> <pages> pages 303-313, </pages> <month> December </month> <year> 1997. </year>
Reference-contexts: By applying an algorithm which takes the cache size, cache line size and procedure size into account to intelligently place procedures, Hashemi et al [22] were able to reduce the cache miss rate by 17% compared to the mapping algorithm of Pettis and Hansen [30]. 23 Gloy et al <ref> [20] </ref> used profiling to collect temporal ordering information of procedure calls. Along with the cache configuration and procedure sizes, the temporal ordering information is used to estimate the conflict cost of a potential procedure ordering. Calder et al [8] use profiling and placement techniques from Gloy et al [20] to guide <p> et al <ref> [20] </ref> used profiling to collect temporal ordering information of procedure calls. Along with the cache configuration and procedure sizes, the temporal ordering information is used to estimate the conflict cost of a potential procedure ordering. Calder et al [8] use profiling and placement techniques from Gloy et al [20] to guide data placement. IV.C.3 C++ Profiling Providing run-time type feedback via a profile was the approach Holzle and Ungar [23] suggested for inlining virtual function calls.
Reference: [21] <author> D. Grove, J. Dean, C. Garret, and C. Chambers. </author> <title> Profile-guided receiver class prediction. </title> <booktitle> In Proceedings of the ACM Conference on Object-Oriented Programming Systems, Languages and Applications, </booktitle> <pages> pages 108-123. </pages> <publisher> ACM, </publisher> <month> October </month> <year> 1995. </year>
Reference-contexts: They also found that the performance gain achieved using procedure inlining in object oriented languages is higher than in FORTRAN or C. Dean et al <ref> [13, 21] </ref> extend the approach of customization by specializing only those cases where the highest benefit can be achieved. Selective specialization uses a run-time profile to determine exactly where customization would be most beneficial. <p> Reinman et al [31] used profile information to determine the load-store dependency in programs. A load which is directly dependent upon a store might be able to bypass memory by using the value of the store directly. Additional research <ref> [21, 9] </ref> focused on inlining functions given a run-time profile. Inlining functions permits the compiler to perform additional optimizations such as register allocation, code scheduling, common subexpression elimination, constant propagation, and dead code elimination. Profiles have also been used for instruction scheduling [11].
Reference: [22] <author> A. H. Hashemi, D. R. Kaeli, and B. Calder. </author> <title> Efficient procedure mapping using cache line size. </title> <booktitle> In Proceedings of the ACM SIGPLAN '97 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 171-182. </pages> <publisher> ACM, </publisher> <month> June </month> <year> 1997. </year>
Reference-contexts: Their approach to reordering procedures and basic-blocks led to an average reduction in execution time of 15%. By applying an algorithm which takes the cache size, cache line size and procedure size into account to intelligently place procedures, Hashemi et al <ref> [22] </ref> were able to reduce the cache miss rate by 17% compared to the mapping algorithm of Pettis and Hansen [30]. 23 Gloy et al [20] used profiling to collect temporal ordering information of procedure calls.
Reference: [23] <author> U. Holzle and D. Ungar. </author> <title> Optimizing dynamically-dispatched calls with run-time type feedback. </title> <booktitle> In Proceedings of the SIGPLAN'93 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 326-336. </pages> <publisher> ACM, </publisher> <month> June </month> <year> 1994. </year>
Reference-contexts: This process is referred to as customization. This allows the compiler to statically bind the specialized functions, and then perform optimizations on them. The drawback of that method is that the compile-time as well as code space requirements are increased. Holzle et al <ref> [23] </ref> implemented a run-time type feedback system. Using the type feedback information, the compiler can then inline any dynamically dispatched function calls, specializing the dispatch based on the frequently encountered object types. <p> Dean et al [13, 21] extend the approach of customization by specializing only those cases where the highest benefit can be achieved. Selective specialization uses a run-time profile to determine exactly where customization would be most beneficial. What sets this apart from type feedback <ref> [23] </ref> is knowledge of the formal parameters, which allows for additional optimizations. Richardson [32] studied the potential performance gain due to replacing a complex instruction with trivial operands, with a trivial instruction. He profiled the operands of arithmetic operations looking for trivial calculations. <p> Calder et al [8] use profiling and placement techniques from Gloy et al [20] to guide data placement. IV.C.3 C++ Profiling Providing run-time type feedback via a profile was the approach Holzle and Ungar <ref> [23] </ref> suggested for inlining virtual function calls. Calder et al [7] use profile information to quantify the difference of C++ programs and C programs, and in an independent study the authors [5] use profile feedback to help predict indirect function calls.
Reference: [24] <author> Urs Holzle, Craig Chambers, and David Ungar. </author> <title> Optimizing dynamically-types object-oriented languages with polymorhic inline caches. </title> <booktitle> In ECOOP'91, Fourth European Conference on Object-Oriented Programming, </booktitle> <pages> pages 21-38, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: Holzle et al [23] implemented a run-time type feedback system. Using the type feedback information, the compiler can then inline any dynamically dispatched function calls, specializing the dispatch based on the frequently encountered object types. The authors implemented their system in Self <ref> [24] </ref>, which dynamically compiles or recompiles the code applying the optimization with polymorphic inline caches. However, this type feedback can also be used off-line. They found that unlike in C, procedure inlining does 8 not add a lot of extra code space due to the smaller functions of C++.
Reference: [25] <author> T.B. Knoblock and E. Ruf. </author> <title> Data specialization. </title> <booktitle> In Proceedings of the ACM SIG-PLAN '96 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 215-225. </pages> <publisher> ACM, </publisher> <month> January </month> <year> 1996. </year> <month> 80 </month>
Reference-contexts: For these techniques to be effective the compiler must determine which sections of code to concentrate on for the adaptive execution. Existing techniques for dynamic compilation and adaptive execution require the user to identify run-time invariants using user guided annotations <ref> [2, 12, 15, 25, 26] </ref>. One of the goals of value profiling is to provide an automated approach for identifying semi-invariant variables and to use this to guide dynamic compilation and adaptive execution. <p> Their approach requires programmers to provide hints to the staging analysis to determine what arguments have semi-invariant behavior. Code fragments can then be optimized by partitioning the invariant parts of the program fragment. Knoblock and Ruf <ref> [25] </ref> used a form of staging analysis and annotations to guide data specialization. Autrey and Wolfe [3] have started to investigate a form of staging analysis for automatic identification of semi-invariant variables.
Reference: [26] <author> P. Lee and M. Leone. </author> <title> Optimizing ml with run-time code generation. </title> <booktitle> In Proceedings of the ACM SIGPLAN '96 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 137-148. </pages> <publisher> ACM, </publisher> <month> May </month> <year> 1996. </year>
Reference-contexts: For these techniques to be effective the compiler must determine which sections of code to concentrate on for the adaptive execution. Existing techniques for dynamic compilation and adaptive execution require the user to identify run-time invariants using user guided annotations <ref> [2, 12, 15, 25, 26] </ref>. One of the goals of value profiling is to provide an automated approach for identifying semi-invariant variables and to use this to guide dynamic compilation and adaptive execution. <p> One of the goals of value profiling is to provide an automated approach for identifying semi-invariant variables and to use this to guide dynamic compilation and adaptive execution. Staging analysis has been proposed by Lee and Leone <ref> [26] </ref> as an effective means for determining which computations can be performed early by the compiler and which optimizations should be performed late or postponed by the compiler for dynamic code generation. Their approach requires programmers to provide hints to the staging analysis to determine what arguments have semi-invariant behavior.
Reference: [27] <author> M.H. Lipasti and J.P. Shen. </author> <title> Exceeding the dataflow limit via value prediction. </title> <booktitle> In 29th International Symposium on Microarchitecture, </booktitle> <pages> pages 226-237, </pages> <month> December </month> <year> 1996. </year>
Reference-contexts: Value Profiling is an approach that can identify the invariance and the top N values of a variable. The invariance of a variable is also important when doing Value Prediction. Value prediction <ref> [17, 27, 28] </ref> enables programs to exceed the limits which are placed upon them by their data-dependencies. The goal is to predict at run-time the outcome value of instructions before they are executed, and forwarding these speculated values to instructions which depend on them. <p> This approach enables data-dependent instructions to execute non-sequentially and therefore to enhance the programs Instruction-Level-Parallelism (ILP). With modern micro processor word sizes of 32-64 bits, the predictability of register values would seem to have a very low probability. However, a property of programs called value locality <ref> [27] </ref> shows that many instructions have only very few distinct values. 1 2 In this thesis we will examine one potential type of value predictor, the Last-Value-Predictor (LVP). The LVP predicts the value of an instruction to be the same as the previously encountered value for that instruction. <p> Another use for value profiling is code specialization. Value profiling information could be used to identify invariant or semi-invariant variables and then apply code specialization to certain parts of the program as illustrated in Chapter X. II.A Value Prediction The recent publications on value prediction <ref> [17, 27, 28] </ref> in hardware provided motivation for our research into value profiling. Lipasti et al [27] introduced the term value locality, which describes the likely hood of the recurrence of a previously seen value within a storage location. <p> II.A Value Prediction The recent publications on value prediction [17, 27, 28] in hardware provided motivation for our research into value profiling. Lipasti et al <ref> [27] </ref> introduced the term value locality, which describes the likely hood of the recurrence of a previously seen value within a storage location.
Reference: [28] <author> M.H. Lipasti, C.B. Wilkerson, and J.P. Shen. </author> <title> Value locality and load value prediction. </title> <booktitle> In Seventh International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 138-147, </pages> <month> October </month> <year> 1996. </year>
Reference-contexts: Value Profiling is an approach that can identify the invariance and the top N values of a variable. The invariance of a variable is also important when doing Value Prediction. Value prediction <ref> [17, 27, 28] </ref> enables programs to exceed the limits which are placed upon them by their data-dependencies. The goal is to predict at run-time the outcome value of instructions before they are executed, and forwarding these speculated values to instructions which depend on them. <p> Another use for value profiling is code specialization. Value profiling information could be used to identify invariant or semi-invariant variables and then apply code specialization to certain parts of the program as illustrated in Chapter X. II.A Value Prediction The recent publications on value prediction <ref> [17, 27, 28] </ref> in hardware provided motivation for our research into value profiling. Lipasti et al [27] introduced the term value locality, which describes the likely hood of the recurrence of a previously seen value within a storage location.
Reference: [29] <author> M. Moudgill and J. H. Moreno. </author> <title> Run-time detection and recovery from incorrectly reordered memory operations. </title> <institution> IBM Research Report, </institution> <month> May </month> <year> 1997. </year>
Reference-contexts: The check instruction checks the speculative load's conflict bit in the MCB; if not set, the speculation was correct, otherwise the load was mis-speculated. A similar approach for software-based speculative load execution was proposed by Moudgill and Moreno <ref> [29] </ref>. Instead of using a hardware buffer to check addresses, they check values. They allow loads to be speculatively scheduled above stores, and in addition they execute the load in its original location. They then check the value of the speculative load with the correct value. <p> They then check the value of the speculative load with the correct value. If they are different a recovery sequence must be executed. Value profiling could support the approach of Moudgill and Moreno <ref> [29] </ref> to only reschedule loads with a high invariance. This could potentially decrease the number of mis-speculated loads. 6 II.B Compiler Analysis for Dynamic Compilation Dynamic compilation and adaptive execution are emerging directions for compiler research which provide improved execution performance by delaying part of the compilation process to run-time.
Reference: [30] <author> K. Pettis and R.C. Hansen. </author> <title> Profile guided code positioning. </title> <booktitle> In Proceedings of the ACM SIGPLAN '90 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 16-27. </pages> <publisher> ACM, </publisher> <month> June </month> <year> 1990. </year>
Reference-contexts: This approach does not always give the correct result. Ball and Larus [4] introduce a method to efficiently profile a program's executed paths. IV.C.2 Code and Data Placement Pettis and Hansen <ref> [30] </ref> used profile information to guide code-positioning. The idea is to place frequently executed code sections next to each other in the address space, thereby reducing the chances of cache conflicts. Their approach to reordering procedures and basic-blocks led to an average reduction in execution time of 15%. <p> By applying an algorithm which takes the cache size, cache line size and procedure size into account to intelligently place procedures, Hashemi et al [22] were able to reduce the cache miss rate by 17% compared to the mapping algorithm of Pettis and Hansen <ref> [30] </ref>. 23 Gloy et al [20] used profiling to collect temporal ordering information of procedure calls. Along with the cache configuration and procedure sizes, the temporal ordering information is used to estimate the conflict cost of a potential procedure ordering.
Reference: [31] <author> G. Reinman, B. Calder, D. Tullsen, G. Tyson, and T. Austin. </author> <title> Profile guided memory communication and speculative load execution. </title> <type> Technical Report, </type> <institution> University of California, </institution> <address> San Diego, </address> <year> 1998. </year>
Reference-contexts: Dean et al [13] use profiling information to selectively inline virtual functions, based on their execution count. IV.C.4 Miscellaneous Profiles have been used to aid the compiler in promoting variables, which are executed the most frequently, into registers [33, 37]. Reinman et al <ref> [31] </ref> used profile information to determine the load-store dependency in programs. A load which is directly dependent upon a store might be able to bypass memory by using the value of the store directly. Additional research [21, 9] focused on inlining functions given a run-time profile.
Reference: [32] <author> Stephen E. Richardson. </author> <title> Exploiting trivial and redundant computation. </title> <booktitle> In Proceedings of the Eleventh Symposium on Computer Arithmetic, </booktitle> <year> 1993. </year>
Reference-contexts: Selective specialization uses a run-time profile to determine exactly where customization would be most beneficial. What sets this apart from type feedback [23] is knowledge of the formal parameters, which allows for additional optimizations. Richardson <ref> [32] </ref> studied the potential performance gain due to replacing a complex instruction with trivial operands, with a trivial instruction. He profiled the operands of arithmetic operations looking for trivial calculations. A trivial instruction is defined as being able to complete in one cycle. <p> As in the case of the loads, these few procedures, that make up the bulk of the execution is where one would most likely want to optimize. Richardson <ref> [32] </ref> suggests keeping a memoization cache of recently executed function results with their inputs.
Reference: [33] <author> Vatsa Santhanan and Daryl Odnert. </author> <title> Register allocation accross procedure and module boundaries. </title> <booktitle> In Proceedings of the ACM SIGPLAN '90 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 28-39, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: Dean et al [13] use profiling information to selectively inline virtual functions, based on their execution count. IV.C.4 Miscellaneous Profiles have been used to aid the compiler in promoting variables, which are executed the most frequently, into registers <ref> [33, 37] </ref>. Reinman et al [31] used profile information to determine the load-store dependency in programs. A load which is directly dependent upon a store might be able to bypass memory by using the value of the store directly.
Reference: [34] <author> Y. Sazeides and James E. Smith. </author> <title> The predictability of data values. </title> <booktitle> In 30th International Symposium on Microarchitecture, </booktitle> <pages> pages 248-258, </pages> <month> December </month> <year> 1997. </year>
Reference-contexts: If the stride is zero, the value is constant, and this equates to last value prediction. Several different value predictor models have been proposed <ref> [18, 34, 39] </ref>. Wang et. al [39] studied the performance of two different hybrid predictors in comparison to several stand-alone predictors. The first hybrid is a combination of a LVP and a stride predictor, the second one a combination of a stride predictor and a 2-level predictor. <p> The authors show results for five different value predictors. The five predictors are LVP, stride, 2-level, hybrid (LVP, stride), and hybrid (stride, 2-level). Their average results over the six integer programs from the SPEC92 benchmark are 42%, 52%, 52%, 60%, 69% respectively. Sazeidas et. al <ref> [34] </ref> classifies two types of value predictors, computational predictors and context based predictors. A computational predictor is one which computes a value given information for the previous values. An example would be a stride predictor. A context-based predictor predicts values that follow a certain finite pattern.
Reference: [35] <author> A. Srivastava and A. Eustace. </author> <title> ATOM: A system for building customized program analysis tools. </title> <booktitle> In Proceedings of the Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 196-205. </pages> <publisher> ACM, </publisher> <year> 1994. </year>
Reference-contexts: We compiled the SPEC benchmark suite under OSF/1 V4.0 operating system using full compiler optimization (-O4 -ifo). Table III.A.1 shows the two data sets we used in gathering results for each program, and the number of instructions executed in millions. 12 We used ATOM <ref> [35] </ref> to instrument the programs and gather the value profiles. The ATOM instrumentation tool has an interface that allows the elements of the program executable, such as instructions, basic blocks, and procedures, to be queried and manipulated. <p> Then the average result, weighted by execution frequency, of each bucket is graphed. The y-axis entry is non-accumulative. III.E Profiling Instructions With the use of ATOM <ref> [35] </ref>, profiling instructions is straight-forward. Each instruction can be profiled either before or after the instruction is executed. The destination register value is passed to the function which records the profiling information. Within that function, we add the register value to the TNV table.
Reference: [36] <author> Ron van der Wal. </author> <title> Source-code profilers for win32. </title> <journal> Dr. Dobb's Journal, </journal> <pages> pages 78-88, </pages> <month> March </month> <year> 1998. </year>
Reference-contexts: In Chapter V we present results on how our value profiler performs using different input data sets. 22 IV.C Uses for Profiling There are many different uses for run-time profiles. One common use is to use profiling information to hand tune existing software <ref> [36] </ref>, which is a common technique employed by software developers. Other uses for profiling are discussed in the following paragraphs. IV.C.1 Branch Path Profiling Fisher and Freudenberger [16] used profiling to gather information on the branching behavior of several programs.
Reference: [37] <author> David W. Wall. </author> <title> Global register allocation at link-time. </title> <booktitle> In Proceedings of the SIG-PLAN'86 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 264-275, </pages> <month> June </month> <year> 1986. </year>
Reference-contexts: Dean et al [13] use profiling information to selectively inline virtual functions, based on their execution count. IV.C.4 Miscellaneous Profiles have been used to aid the compiler in promoting variables, which are executed the most frequently, into registers <ref> [33, 37] </ref>. Reinman et al [31] used profile information to determine the load-store dependency in programs. A load which is directly dependent upon a store might be able to bypass memory by using the value of the store directly.
Reference: [38] <author> D.W. Wall. </author> <title> Predicting program behavior using real or estimated profiles. </title> <booktitle> In Proceedings of the ACM SIGPLAN '91 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 59-70, </pages> <address> Toronto, Ontario, Canada, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: The different profilers and resulting profiles will also be described briefly. IV.A Introduction to Profiling ... a profile is a mapping from instances of some kind of program entity, like variables or procedures, into numeric weights. David Wall <ref> [38] </ref> Profiling a program gives information about a program's state during execution. The information a profile includes depends on the entity being profiled. <p> IV.B Different Input Data For a profile to be valuable in supporting compiler optimizations, the information contained within the profile needs to be representative for different input data sets. How well profile data of different runs correlate, was originally investigated by David Wall <ref> [38] </ref>. The author shows that a profile gathered with a given data set still outperforms static analysis of the program when run on a second data set, by more than a factor of two. <p> The percent zeroes and the percent invariance are very similar in both data sets. The results indicate that there is a high degree of similarity in the profile for the two data sets. This results confirms the observation made by David Wall <ref> [38] </ref>, that profiles from different data sets have a high correlation. 38 Table V.5: Results for Load Values of Test and Train Data Set. The results shown are LVP, I (t)=Inv-Top, I (a)=Inv-All and D (l/i)=Diff (L/I) for the two data sets. The metrics are described in xIII.C.
Reference: [39] <author> Kai Wang and Manoj Franklin. </author> <title> Highly accurate data value prediction using hybrid predictors. </title> <booktitle> In 30th International Symposium on Microarchitecture, </booktitle> <pages> pages 281-290, </pages> <month> December </month> <year> 1997. </year>
Reference-contexts: If the stride is zero, the value is constant, and this equates to last value prediction. Several different value predictor models have been proposed <ref> [18, 34, 39] </ref>. Wang et. al [39] studied the performance of two different hybrid predictors in comparison to several stand-alone predictors. The first hybrid is a combination of a LVP and a stride predictor, the second one a combination of a stride predictor and a 2-level predictor. <p> If the stride is zero, the value is constant, and this equates to last value prediction. Several different value predictor models have been proposed [18, 34, 39]. Wang et. al <ref> [39] </ref> studied the performance of two different hybrid predictors in comparison to several stand-alone predictors. The first hybrid is a combination of a LVP and a stride predictor, the second one a combination of a stride predictor and a 2-level predictor.
Reference: [40] <author> Cliff Young and Michael D. Smith. </author> <title> Improving the accuracy of static branch prediction using branch correlation. </title> <booktitle> In Six International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 232-241, </pages> <month> Octo-ber </month> <year> 1994. </year>
Reference-contexts: The profiling information was used to determine if past runs of a program with certain input data could help in predicting branches for future runs with different input data. Young and Smith <ref> [40] </ref> used profiling to capture the path preceding each conditional branch in a program. Calder et al [6] used profiling to show that common C and FORTRAN library routines have predictable behavior between different applications. Optimizations which depend upon run-time profile data share one common objective. <p> A load instruction or an add instruction is likely to increment by a constant amount, hence for instructions like that we would use some sort of a stride predictor. One could use an approach similar to Young and Smith <ref> [40] </ref> by using the path history when predicting values. This can be especially beneficial for procedures called from several locations in the program. Many improvements can also be made for the intelligent sampler. The intelligence examined in this thesis was a convergence criteria based upon a change in invariance.
References-found: 40

