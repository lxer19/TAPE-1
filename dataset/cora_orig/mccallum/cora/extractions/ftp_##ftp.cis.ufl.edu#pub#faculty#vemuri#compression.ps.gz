URL: ftp://ftp.cis.ufl.edu/pub/faculty/vemuri/compression.ps.gz
Refering-URL: http://www.cis.ufl.edu/~vemuri/vpcomp.html
Root-URL: http://www.cis.ufl.edu
Email: Email:sahni|vemuri|fchen@cise.ufl.edu  Email:leonard@ufbi.ufl.edu  Email:jfitz@uf3t.ufl.edu  
Title: State of The Art Lossless Image Compression Algorithms  
Author: S. Sahni, B. C. Vemuri, F. Chen, C. Kapoor, C. Leonard, and J. Fitzsimmons Sahni, Vemuri, Chen and Kapoor 
Address: Florida, Gainesville, Fl. 32611.  Gainesville, Fl. 32610.  Gainesville, Fl. 32610.  
Affiliation: Dept. of Computer Info. Science Engineering, Univ. of  Univ. of Florida,  Dept. of Radiology, Univ. of Florida,  
Note: are with the  Leonard is with the Dept. of Neuroscience,  Fitzsimmons is with the  This research was support, in part, by the National Institute of Health under grant R01LM05944-03. Document Submitted to the IEEE Transactions on Image Processing for review. October 30, 1997 DRAFT  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Rosenfeld and Kak, </author> <title> Digital Picture Processing, </title> <publisher> Academic Press, </publisher> <year> 1976. </year>
Reference: [2] <author> K. R. Castleman, </author> <title> Digital Image Processing, </title> <publisher> Prentice Hall, </publisher> <year> 1996. </year>
Reference: [3] <author> N.Ranganathan, S.G.Romaniuk and K.R.Namuduri, </author> <title> "A Lossless Image Compression Algorithm Using Variable Block Size Segmentation", </title> <journal> IEEE Transactions on Image Processing, </journal> <volume> vol 4, No. 10, pp.1396 - 1406, </volume> <month> October October 30, </month> <note> 1997 DRAFT 37 </note>
Reference-contexts: In the first stage, image segmentation schemes that have been used include partitioning the image into regular shapes (rectangles) or into irreg ular shapes. The former has the advantage that it takes less storage to code the shape <ref> [3] </ref> due to simplicity of the primitive used while the latter is comparitively storage intensive because of the generality and complexity of the shapes resulting from the segmentation algorithm. <p> In the following, we describe various state of the art image compression algorithms that primarily use spatial domain information either directly or in processed form (e.g., segmented data). A. Variable Block Size Compression In <ref> [3] </ref>, Ranganathan et al. developed a lossless image compression algorithm which exploits local and global redundancy present in most images. Their algorithm segments the image into variable size blocks and encodes them based on the properties exhibited by the pixels within a block. <p> In Table VIII, we present the results of applying three spatial domain compression algorithms to our 10 image suite. The methods chosen for comparison are JPEG lossless, the variable-block size compression scheme of Ranga et al. <ref> [3] </ref>, and our proposed interpolation scheme. Compression results for each algorithm are tabulated with and without the use of the mapping preprocessor. As is evident from the table, the proposed interpolation algorithm gives the best compression for all images in our test suite.
Reference: [4] <author> T. H. Cormen, C. E. Leiserson and R. L. Rivest, </author> <title> Introduction to Algorithms, </title> <publisher> McGraw Hill, </publisher> <year> 1990. </year>
Reference: [5] <author> I. H. Witten, R.M. Neal, and J. G. Cleary, </author> <title> "Arithmetic coding for data compression", </title> <journal> Commum. ACM, </journal> <volume> vol. 30, </volume> <pages> pp. 520-540, </pages> <month> June </month> <year> 1987. </year>
Reference-contexts: October 30, 1997 DRAFT 14 C. Arithmetic Coding In this method, a message is coded as a subinterval of the interval [0, 1), where [x, y) denotes a half open interval, which includes x but excludes y <ref> [5] </ref>. There are two fundamental concepts in arithmetic coding: the probability of a symbol, and encoding interval range for a symbol. The occurrence probabilities of source symbols determine the compression efficiency as well as the interval ranges of source symbols for the encoding process. <p> Although our preceding description of arithmetic coding uses high-precision floating point arithmetic, the scheme can be adapted to use integers alone <ref> [5] </ref>. Furthermore the coding scheme can be made adaptive, that is the probablilities and hence subranges of [0, 1) associated with each symbol can be made to depend on the symbol frequencies in the source file that is being coded.
Reference: [6] <author> Weidong Kou, </author> <title> Digital Image Compression Algorithms and Standards, </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1995. </year>
Reference-contexts: This coding scheme works well when we have many long segments and works poorly when we have many short segments. Since our test images do not have long segments, we did not experiment with run-length coding. More details about this coding method can be found in <ref> [6] </ref>. E. Variable Bit Length Coding In a traditionally stored source file, each symbol is stored using the same number of bits (usually 8). In variable bit length coding (VBL) different symbols are stored using a different number of bits.
Reference: [7] <author> R. J. Clarke, </author> <title> Digital Compression of Still Images and Video, </title> <address> New York, </address> <publisher> Academic Press, </publisher> <year> 1995. </year>
Reference: [8] <author> Wallace, G. K. </author> <title> "The JPEG still picture compression standard", </title> <journal> Communications of the ACM, </journal> <volume> vol 34, </volume> <pages> pp. 30-44, </pages> <month> April </month> <year> 1991. </year>
Reference: [9] <author> S. Takamura and M. Takagi, </author> <title> "Lossless image compression with lossy image using adaptive prediction and arithmetic coding", </title> <booktitle> Proc. Data Compress. Conf., </booktitle> <address> Snowbird, UT, </address> <month> Mar. </month> <year> 1994, </year> <pages> pp. 166-174. </pages>
Reference: [10] <author> E. H. Adelson, E. P. Simoncelli and R. Hingorani, </author> <title> "Orthogonal pyramid transforms for image coding,", </title> <booktitle> Proc. SPIE, </booktitle> <address> Cambridge, MA, </address> <month> Oct. </month> <journal> 1987, </journal> <volume> vol. 845, </volume> <pages> pp. 50-58. </pages>
Reference-contexts: Experimental results show that this transform yields far superior compression ratios than the single resolution linear predictive coding based schemes like the lossless JPEG and other spatial domain methods. The S transform which is similar to the multiresolution transform using Harr basis <ref> [10] </ref> can be represented by the following set of equations for a given input sequence of integers: l [n] = b 2 N 1; (1) N 1; (2) where c [n]; n = 0; :::; N 1 is a sequence of integers with an even N , bc denotes the floor
Reference: [11] <author> Gilbert and Strang, </author> <title> Wavelets and Filter Banks, </title> <publisher> Wellesley-Cambridge Press, </publisher> <year> 1996. </year>
Reference: [12] <author> A. Said and W. A. Pearlman, </author> <title> "An Image Multiresolution Representation for Lossless and Lossy Compression", </title> <journal> IEEE Trans. Image Process., </journal> <volume> vol. 5, no. 9, </volume> <month> Sept. </month> <year> 1996. </year>
Reference-contexts: In the following, we will breifly describe these two tranform based compression methods. October 30, 1997 DRAFT 31 A. S + P Transform based Compression Said and Pearlman <ref> [12] </ref> developed an image multiresolution transform that is suited for both lossless (reversible) and lossy compression. This tranform requires only integer addition and bit-shift operations. By using careful scaling and truncation, the number of bits used to represent the transformed image is kept low. <p> October 30, 1997 DRAFT 32 The performance of the S-transform can be improved by combining it with nonlinear predictive coding <ref> [12] </ref>. Instead of performing the prediction as a post transform operation, Said and Pearlman developed a scheme which predicts the high frequency components from a combination of computed low and high frequency components. <p> The coefficients a i ; b i in the above prediction equations can be obtained using filter design techniques and we refer the interested reader to <ref> [12] </ref>. B. Wavelet Transform based Compression Traditionally, the Wavelet transform is very popular for lossy compression [43], [44]. More recently, Wavelet transforms that map integers to integers were developed by several researchers [45], [17], [15]. <p> In Table IX, we present a comparison of the compression results obtained using the integer wavelet transform [15] and the S+P technique <ref> [12] </ref> on the same 10 images used earlier for comparing the spatial domain methods. Once again, the results are presented with and without the use of the mapping preprocessor. <p> Best overall compression of images is obtained using the S+P method of <ref> [12] </ref> coupled with the mapping perprocessor proposed here.
Reference: [13] <author> A.Said and W. A. Pearlman, </author> <title> "Reversible Image Compression via Multiresolution representation and predictive coding", </title> <journal> IEEE Trans. Image Processing, </journal> <volume> Vol. </volume> <year> 2094, </year> <pages> pp. 664-674, </pages> <month> Nov. </month> <year> 1993. </year> <title> [14] "Hierarchical Image Decomposition and Filtering Using teh S-Transform" Proc. </title> <booktitle> SPIE, Medical Imaging, </booktitle> <volume> vol 914, </volume> <pages> pp. 799-814, </pages> <year> 1988. </year>
Reference: [15] <author> A. R. Calderbank, I. Daubechies, W. M. Sweldens, and Boon-Lock Yeo, </author> <title> "Wavelet transforms that map integers to integers", </title> <institution> Department of Mathematics, Princeton University, </institution> <month> August, </month> <year> 1996. </year>
Reference-contexts: More recently, Said and Pearlman developed a novel multiresolution transform based scheme well suited for lossless and lossy compression of images. The transform is called the S + P transform where P denotes a prediction stage. Calderbank et al., <ref> [15] </ref> have recently developed wavelet transforms that maps integers to integers which prove to be quite useful for lossless image compression. In the following, we will breifly describe these two tranform based compression methods. October 30, 1997 DRAFT 31 A. <p> B. Wavelet Transform based Compression Traditionally, the Wavelet transform is very popular for lossy compression [43], [44]. More recently, Wavelet transforms that map integers to integers were developed by several researchers [45], [17], <ref> [15] </ref>. We will briefly describe the technique developed in Calderbank et al., [15] since October 30, 1997 DRAFT 33 it is the most general of all the integer wavelet transforms. Calderbank et al., describe two methods for achieving the mapping of integers to integers using wavelet transforms. <p> B. Wavelet Transform based Compression Traditionally, the Wavelet transform is very popular for lossy compression [43], [44]. More recently, Wavelet transforms that map integers to integers were developed by several researchers [45], [17], <ref> [15] </ref>. We will briefly describe the technique developed in Calderbank et al., [15] since October 30, 1997 DRAFT 33 it is the most general of all the integer wavelet transforms. Calderbank et al., describe two methods for achieving the mapping of integers to integers using wavelet transforms. <p> The inverse transform can be obtained by simply reversing the operations and flipping the signs. The lifting scheme implementation of the wavelet transform has numerous advantages over the traditional wavelet transform and we refer the reader to <ref> [15] </ref> for a detailed discussion on lifting schemes. In Table IX, we present a comparison of the compression results obtained using the integer wavelet transform [15] and the S+P technique [12] on the same 10 images used earlier for comparing the spatial domain methods. <p> The lifting scheme implementation of the wavelet transform has numerous advantages over the traditional wavelet transform and we refer the reader to <ref> [15] </ref> for a detailed discussion on lifting schemes. In Table IX, we present a comparison of the compression results obtained using the integer wavelet transform [15] and the S+P technique [12] on the same 10 images used earlier for comparing the spatial domain methods. Once again, the results are presented with and without the use of the mapping preprocessor.
Reference: [16] <author> E. Majani, </author> <title> "Biorthogonal Wavelets for Image Compression", </title> <booktitle> Proc. SPIE, VCIP 1994, </booktitle> <volume> Vol. 2308, </volume> <pages> pp. 478-488, </pages> <month> Sept. </month> <year> 1994. </year>
Reference: [17] <author> A. Zandi, M. Boliek, E. L. Schwartz, and M. J. Gormish, </author> <title> "CREW lossless/lossy medical image compression", </title> <type> Technical Report CRC-TR-9526, </type> <institution> RICOH California Research Center, </institution> <year> 1995. </year>
Reference-contexts: B. Wavelet Transform based Compression Traditionally, the Wavelet transform is very popular for lossy compression [43], [44]. More recently, Wavelet transforms that map integers to integers were developed by several researchers [45], <ref> [17] </ref>, [15]. We will briefly describe the technique developed in Calderbank et al., [15] since October 30, 1997 DRAFT 33 it is the most general of all the integer wavelet transforms. Calderbank et al., describe two methods for achieving the mapping of integers to integers using wavelet transforms.
Reference: [18] <author> G. R. Kuduvalli, </author> <title> "Performance Analysis of Reversible Image Compression Techniques for High Resolution Digital Teleradiology", </title> <journal> IEEE Trans. on Medical Imaging, </journal> <volume> vol. 11, No. 3, </volume> <month> Sept. </month> <year> 1992. </year> <title> [19] "MPEG, CCITT, H.261, JPEG : Image and Image sequence compression/decompression C software engines", Portable Video Research Group, </title> <publisher> Stanford, </publisher> <year> 1991. </year> <note> October 30, 1997 DRAFT 38 </note>
Reference: [20] <author> A. K. Cline, </author> <title> "Curve Fitting using Splines Under Tension", </title> <type> Technical report, Atmos. Tech 3, </type> <year> 1973. </year>
Reference: [21] <author> Demetri Terzopoulos, </author> <title> "The Computation of Visible-Surface Representations", </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> vol. 10, No. 4, </volume> <month> July </month> <year> 1988. </year>
Reference-contexts: Experiments were carried out using four and eight neighbors in performing the interpolation. More sophisticated interpolation schemes such as tensor product splines [23], membrane or thinplate splines <ref> [21] </ref> were also experminted with. The concept of interpolation with reuse can once again be applied in these cases. In addition to the subsampling and interpolation technqiues described above, we also developed a hierarchical subsampling and interpolation scheme that in conjunction with arithmetic coding yielded the best compression results.
Reference: [22] <author> A. K. Cline, </author> <title> "A Software Package for Curve and Surface Fitting Employing Splines Under Tension", </title> <institution> Univ. of Texas at Austin, </institution> <month> August, </month> <year> 1981. </year>
Reference: [23] <author> Paul Dierckx, </author> <title> Curve and Surface fitting with Splines, </title> <address> Oxford; New York: </address> <publisher> Clarendon, </publisher> <year> 1993. </year>
Reference-contexts: Experiments were carried out using four and eight neighbors in performing the interpolation. More sophisticated interpolation schemes such as tensor product splines <ref> [23] </ref>, membrane or thinplate splines [21] were also experminted with. The concept of interpolation with reuse can once again be applied in these cases.
Reference: [24] <author> Richard Szeliski, </author> <title> "Fast Surface Interpolation Using Hierarchical Basis Functions", </title> <journal> IEEE Trans., </journal> <year> 1990. </year>
Reference: [25] <editor> Gonzalez and Woods,Digital Image Processing, </editor> <publisher> Addison-Wesley, </publisher> <year> 1992. </year>
Reference: [26] <author> L. Portoni, C. Combi, G. Pozzi, F. Pinciroli, H. P. Fritsch and R. Brennecke, </author> <title> "Some irreversible compression methods and their application to angiocardiographic digital still images", </title> <month> May </month> <year> 1996. </year>
Reference-contexts: Different types of linearization schemes were used in our experiments and the one that yielded the best compression was adopted. The linearization schemes experimented with included row Major, column major, spiral, snake-like row major and Peano Hilbert <ref> [26] </ref>, all which were described earlier. 4. The Compression / Decompression Algorithms The following pseudo-algorithms incorporate ideas discussed in this section and give the outline of the interpolation-based scheme.
Reference: [27] <author> R.Sedgewick, </author> <title> Algorithms, </title> <publisher> Addison-Wesley, </publisher> <year> 1988. </year>
Reference: [28] <author> Michael J.Black and Anand Rangarajan, </author> <title> "The Outlier Process: Unifying Line Processes and Robust Statistics" IEEE, </title> <year> 1994. </year>
Reference-contexts: These outliers may represent the noise pixels in general and will cause an error in approximation by interpolation. In order to avoid using these noise pixels in averaging, the outliers need to be detected <ref> [28] </ref>. Several heuristics may be used for this October 30, 1997 DRAFT 26 purpose. Many different heuristics were experimented with and the following (illustrated in fig 5) was found to yield the best result. First, the points used for interpolation are sorted by gray value in an ascending order.
Reference: [29] <institution> V.K.Heer and H.E.Reinfelder "A comparison of reversible methods for data compression", </institution> <note> IEEE Transactions in Image Processing, vol 1233, </note> <year> 1990. </year>
Reference: [30] <author> Eli Shusterman and Meir Feder, </author> <title> "Image Compression via Improved Quadtree Decomposition Algorithms", </title> <booktitle> IEEE 1994. </booktitle>
Reference-contexts: Exact reconstruction is feasible at the decompressor end using the same concept of reuse. Better subsampling of points can be obtained by incorporating homogeneity constraints in the image via a quadtree decomposition or rectangle coverings <ref> [30] </ref>, [31], [35]. We experimented on subsampling via a quadtree decomposition followed by different quadtree traversal schemes and picked one that yielded better compression results. 2. Interpolation Strategies A good estimate of the original image is contingent on the kind of interpolation used.
Reference: [31] <author> C.H.Chien and J.K.Aggarwal, </author> <title> "A Normalized Quadtree Representation", Computer Vision, </title> <journal> Graphics and Image Processing, </journal> <volume> 26, </volume> <month> 331-346 </month> <year> (1984). </year>
Reference-contexts: Exact reconstruction is feasible at the decompressor end using the same concept of reuse. Better subsampling of points can be obtained by incorporating homogeneity constraints in the image via a quadtree decomposition or rectangle coverings [30], <ref> [31] </ref>, [35]. We experimented on subsampling via a quadtree decomposition followed by different quadtree traversal schemes and picked one that yielded better compression results. 2. Interpolation Strategies A good estimate of the original image is contingent on the kind of interpolation used.
Reference: [32] <author> Homer H.Chen and Thomas S.Huang, </author> <title> "Representation, Construction and Manipulation of Octrees", Survey, </title> <institution> Coordinated Science Laboratory, University of Illinois, </institution> <month> October </month> <year> 1985. </year>
Reference: [33] <author> D.Huffman, </author> <title> "A Method for the Construction of Minimum Redundancy Codes", </title> <journal> Proc. IRE, </journal> <volume> Vol 40, </volume> <pages> pp. 1098-1101, </pages> <year> 1952. </year>
Reference: [34] <author> J. Ziv and A. Lempel, </author> <title> "A Universal Algorithm for Sequential Data Compression", </title> <journal> IEEE Trans. on Information theory, </journal> <volume> Vol. 24, No. 5, </volume> <pages> pp. 530-536, </pages> <year> 1978. </year>
Reference-contexts: Image lenna man chall coral shuttle sphere brain1 slice15 head sag1 CR 1.09 1.09 1.17 1.16 1.18 1.25 1.60 1.57 1.79 1.60 B. LZW Coding Lempel and Ziv <ref> [34] </ref> and Welch [37] have proposed an adaptive coding method that does not require all the data to be compressed to be available at the start. Rather, their technique generates codes as it examines the source file from begin to end.
Reference: [35] <author> San-Yuan Wu and Sartaj Sahni, </author> <title> "Covering Rectilinear Polygons by Rectangles", </title> <journal> IEEE Trans. on Computer-Aided Design, </journal> <volume> Vol. 9, No. 4, </volume> <month> April </month> <year> 1990. </year>
Reference-contexts: Exact reconstruction is feasible at the decompressor end using the same concept of reuse. Better subsampling of points can be obtained by incorporating homogeneity constraints in the image via a quadtree decomposition or rectangle coverings [30], [31], <ref> [35] </ref>. We experimented on subsampling via a quadtree decomposition followed by different quadtree traversal schemes and picked one that yielded better compression results. 2. Interpolation Strategies A good estimate of the original image is contingent on the kind of interpolation used.
Reference: [36] <author> E. Horowitz, S. Sahni, and D. Mehta, </author> <title> Fundamentals of Data Structures in C++, </title> <editor> W. H. </editor> <publisher> Freeman, </publisher> <year> 1994. </year>
Reference-contexts: Assume that the data to be compressed has five symbols: fs1, s2, s3, s4, s5g with the following probabilities: f0.1, 0.3, 0.25, 0.15, 0.2g. The Huffman codes for n symbols can be computed in O (n log n) time time using a greedy algorithm (see <ref> [36] </ref>, for example). Using the greedy code construction algorithm, we obtain the following symbol codes: f100, 11, 01, 101, 00g.
Reference: [37] <author> T. Welch, </author> <title> "A Technique for High-Performance Data Compression", </title> <booktitle> IEEE Computer, </booktitle> <month> June </month> <year> 1994, </year> <pages> 8-19. </pages> <note> October 30, 1997 DRAFT 39 </note>
Reference-contexts: Image lenna man chall coral shuttle sphere brain1 slice15 head sag1 CR 1.09 1.09 1.17 1.16 1.18 1.25 1.60 1.57 1.79 1.60 B. LZW Coding Lempel and Ziv [34] and Welch <ref> [37] </ref> have proposed an adaptive coding method that does not require all the data to be compressed to be available at the start. Rather, their technique generates codes as it examines the source file from begin to end.
Reference: [38] <author> M. Rabbani and P. W. Jones, </author> <title> "Digital Image compression Techniques". </title> <type> Bellingham, </type> <institution> WA: SPIE, </institution> <year> 1991 </year>
Reference-contexts: Transform Domain Algorithms Transform domain algorithms exploit spatial frequency information contained in the image to achieve compression. For lossless compression, the most popular multiresolution transform-based scheme in the field of medical imaging has been the S-transform (sequential transform) <ref> [38] </ref>, [39], [40]. This transform is quite efficient however, the study by Kuduvalli and Rangayyan [41] shows that it may not be as effective as a predictive coding scheme. More recently, Said and Pearlman developed a novel multiresolution transform based scheme well suited for lossless and lossy compression of images.
Reference: [39] <author> V. K. Heer and H. E. Reinfelder, </author> <title> "A comparison of reversible methods for data compression", </title> <booktitle> Proc. SPIE-Med. Imaging IV, 1990. </booktitle> <volume> vol. 1233, </volume> <pages> pp. 354-365 </pages>
Reference-contexts: We will not focus on the latter techniques since most of the existing techniques in the literature in this category are lossy compression algorithms <ref> [39] </ref>. In the following, we describe various state of the art image compression algorithms that primarily use spatial domain information either directly or in processed form (e.g., segmented data). A. <p> Transform Domain Algorithms Transform domain algorithms exploit spatial frequency information contained in the image to achieve compression. For lossless compression, the most popular multiresolution transform-based scheme in the field of medical imaging has been the S-transform (sequential transform) [38], <ref> [39] </ref>, [40]. This transform is quite efficient however, the study by Kuduvalli and Rangayyan [41] shows that it may not be as effective as a predictive coding scheme. More recently, Said and Pearlman developed a novel multiresolution transform based scheme well suited for lossless and lossy compression of images.
Reference: [40] <author> S. Takamura and M. Takagi, </author> <title> "Lossless image compression with lossy image using adaptive prediction and arithmetic coding", </title> <booktitle> Proc. Data Compress. Conf., </booktitle> <address> Snowbird, UT, </address> <month> Mar. </month> <year> 1994, </year> <pages> pp. 155-174. </pages>
Reference-contexts: Transform Domain Algorithms Transform domain algorithms exploit spatial frequency information contained in the image to achieve compression. For lossless compression, the most popular multiresolution transform-based scheme in the field of medical imaging has been the S-transform (sequential transform) [38], [39], <ref> [40] </ref>. This transform is quite efficient however, the study by Kuduvalli and Rangayyan [41] shows that it may not be as effective as a predictive coding scheme. More recently, Said and Pearlman developed a novel multiresolution transform based scheme well suited for lossless and lossy compression of images.
Reference: [41] <author> G. R. Kuduvalli and R. M. Rangayyan, </author> <title> "Performance analysis of reversible image compression techniques for high-resolution digital teleradiology", </title> <journal> IEEE Trans. Med. Imaging, </journal> <volume> vol. 11, </volume> <pages> pp. 430-445, </pages> <month> Sept. </month> <year> 1992 </year>
Reference-contexts: For lossless compression, the most popular multiresolution transform-based scheme in the field of medical imaging has been the S-transform (sequential transform) [38], [39], [40]. This transform is quite efficient however, the study by Kuduvalli and Rangayyan <ref> [41] </ref> shows that it may not be as effective as a predictive coding scheme. More recently, Said and Pearlman developed a novel multiresolution transform based scheme well suited for lossless and lossy compression of images. The transform is called the S + P transform where P denotes a prediction stage.
Reference: [42] <author> Vasudev Bhaskaran and Konstantinos Konstantinides, </author> <title> Image and Video Compression Standards, </title> <booktitle> Algorithms and Architectures, </booktitle> <pages> pp. 47-49, </pages> <address> 1995, </address> <publisher> Kluwer Academic Publishers. </publisher>
Reference-contexts: When prediction methods (4) through (7) are used, values in the first row are predicted using method (1) and those in the first column are predicted using method (2). For more details on the JPEG lossless mode of operation, we refer the reader to <ref> [42] </ref>. Fig. 4. Image samples used in JPEG lossless prediction The JPEG lossless coding algorithm has several advantages. It involves very simple computations and hence is easy to implement. It can easily and efficiently be mapped to hardware because of the simplicity of the algorithm.
Reference: [43] <author> R. A. Devore, B. Jawerth, and B. J. Lucier. </author> <title> "Image compression through wavelet transform coding". </title> <journal> IEEE Trans. Inform. Theory, </journal> <volume> 38(2) </volume> <pages> 719-746, </pages> <year> 1992. </year>
Reference-contexts: The coefficients a i ; b i in the above prediction equations can be obtained using filter design techniques and we refer the interested reader to [12]. B. Wavelet Transform based Compression Traditionally, the Wavelet transform is very popular for lossy compression <ref> [43] </ref>, [44]. More recently, Wavelet transforms that map integers to integers were developed by several researchers [45], [17], [15]. We will briefly describe the technique developed in Calderbank et al., [15] since October 30, 1997 DRAFT 33 it is the most general of all the integer wavelet transforms.
Reference: [44] <author> Mladen Victor Wickerhauser, </author> <title> "High-Resolution Still Picture Compression", </title> <booktitle> DIGITAL SIGNAL PROCESSING, </booktitle> <volume> 2, </volume> <pages> 204-226(1992). </pages>
Reference-contexts: The coefficients a i ; b i in the above prediction equations can be obtained using filter design techniques and we refer the interested reader to [12]. B. Wavelet Transform based Compression Traditionally, the Wavelet transform is very popular for lossy compression [43], <ref> [44] </ref>. More recently, Wavelet transforms that map integers to integers were developed by several researchers [45], [17], [15]. We will briefly describe the technique developed in Calderbank et al., [15] since October 30, 1997 DRAFT 33 it is the most general of all the integer wavelet transforms.
Reference: [45] <author> S. Dewitte and J. Cornelis. </author> , <title> "Lossless integer wavelet transform", </title> <type> Technical Report IRIS-TR-0041, </type> <institution> Royal Meteorological Institute Belguim, </institution> <year> 1996. </year>
Reference-contexts: B. Wavelet Transform based Compression Traditionally, the Wavelet transform is very popular for lossy compression [43], [44]. More recently, Wavelet transforms that map integers to integers were developed by several researchers <ref> [45] </ref>, [17], [15]. We will briefly describe the technique developed in Calderbank et al., [15] since October 30, 1997 DRAFT 33 it is the most general of all the integer wavelet transforms. Calderbank et al., describe two methods for achieving the mapping of integers to integers using wavelet transforms.
Reference: [46] <author> R. Laroia, S. A. Tretter, and N. Farvardin. </author> <title> "A simple and effective precoding scheme for noise whitening on intersymbol interference channels", </title> <booktitle> IEEE International Symposium on Circuits and Systems, </booktitle> <volume> vol. 2, </volume> <pages> pp. 309-312, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: Calderbank et al., describe two methods for achieving the mapping of integers to integers using wavelet transforms. One method is a modification of the precoder developed by Laroia et al., <ref> [46] </ref> for information transmission. The second is a method which is a combination of the lifting scheme [47] and a reversible way of rounding. In this section, we will briefly discuss the latter scheme via an example involving a rewrite of the S-transform using the lifting scheme.
Reference: [47] <author> W. Sweldens, </author> <title> "The lifting scheme: A custom-design construction of biorthogonal wavelets", </title> <journal> Journal of Appl. and Comput. Harmonic Analysis, </journal> <volume> 3(2) </volume> <pages> 186-200, </pages> <year> 1996. </year> <note> October 30, 1997 DRAFT </note>
Reference-contexts: Calderbank et al., describe two methods for achieving the mapping of integers to integers using wavelet transforms. One method is a modification of the precoder developed by Laroia et al., [46] for information transmission. The second is a method which is a combination of the lifting scheme <ref> [47] </ref> and a reversible way of rounding. In this section, we will briefly discuss the latter scheme via an example involving a rewrite of the S-transform using the lifting scheme.
References-found: 45

