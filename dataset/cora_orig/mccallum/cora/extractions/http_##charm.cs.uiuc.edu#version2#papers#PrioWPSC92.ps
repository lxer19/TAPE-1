URL: http://charm.cs.uiuc.edu/version2/papers/PrioWPSC92.ps
Refering-URL: http://charm.cs.uiuc.edu/version2/papers/PrioWPSC92.html
Root-URL: http://www.cs.uiuc.edu
Title: Prioritization in Parallel Symbolic Computing  
Author: L. V. Kale 
Address: Urbana Champaign 1304 W. Springfield Ave., Urbana, IL-61801  
Affiliation: Department of Computer Science University of Illinois at  
Abstract: It is argued that scheduling is an important determinant of performance for many parallel symbolic computations, over and above the issues of dynamic load balancing and grainsize control. We propose associating unbounded levels of priorities with tasks and messages as the mechanism of choice for specifying scheduling strategies. We demonstrate how priorities can be used in par-allelizing computations in different search domains, and show how priorities can be implemented effectively in parallel systems. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Kale L.V. </author> <title> Parallel Execution of Logic Programs: The REDUCE-OR Process Model. </title> <booktitle> In International Conference on Logic Programming, </booktitle> <pages> pages 616-632, </pages> <address> Melbourne, </address> <month> May </month> <year> 1987. </year>
Reference-contexts: the parallelism between multiple literals of a clause (or, in problem-solving terminology: that between multiple subgoals of a particular method). 4.5.1 REDUCE/OR Process Model Our work on speculative computations in Parallel Logic Programming was conducted in the context of the REDUCE/OR process model (ROP M ), proposed and developed in <ref> [5, 1] </ref>. The past and ongoing work related to this model in our group includes development of a binding environment [6] and a compiler [11]. <p> It overcomes the limitations of AND/OR trees from the point of view of parallel execution. The detailed description of the process model can be found in <ref> [1] </ref>. What concerns us here is the process structure generated by ROPM. Each invocation of a clause corresponds to a process, called a REDUCE process. (with the exception of clauses and predicates explicitly marked sequential : these are used for granularity control).
Reference: [2] <author> Kale L.V. </author> <title> A Tree Representation for Parallel Problem Solving. </title> <booktitle> In National Conference on Artificial Intelligence (AAAI), </booktitle> <address> St. Paul, </address> <month> August </month> <year> 1988. </year>
Reference-contexts: The resultant work is described in Section 3.3. 4.5.2 Speedups for a First Solution The REDUCE/OR process model is based on REDUCE/OR trees <ref> [2] </ref>, which is an alternative to the traditional AND/OR trees. It overcomes the limitations of AND/OR trees from the point of view of parallel execution. The detailed description of the process model can be found in [1]. What concerns us here is the process structure generated by ROPM.
Reference: [3] <author> Kale L.V. </author> <title> The Chare-Kernel Parallel Programming Language and System. </title> <booktitle> In International Conference on Parallel Processing, </booktitle> <month> August </month> <year> 1990. </year>
Reference-contexts: Indeed, if one is looking for all solutions, this is as simple as that, except for the important problems of load balancing and grainsize control. Earlier, we worked on the all-solution problem using the Chare Kernel machine independent parallel programming system <ref> [3] </ref>, which provides dynamic load balancing among other facilities. With this, we were able to obtain very good speedups for many depth first search problems. Other work on dynamic load balancing for this problem includes that of Kumar and Rao [12, 8].
Reference: [4] <author> Kale L.V. and Saletore Vikram A. </author> <title> Parallel State-Space Search for a First Solution with Consistent Linear Speedups. </title> <type> Technical Report UIUCDCS-R-89-1549, </type> <institution> Dept. of Computer Science, University of Illinois at Urbana-Champaign, </institution> <month> October </month> <year> 1989. </year>
Reference-contexts: The complete scheme involves a few additional subtle points of strategy, and is described in <ref> [4] </ref>. In particular, a technique called delayed release is used to further reduce the wasted work, and reduce the memory requirement to roughly a sum of D + P where D is the depth of the tree, and P is the total number of processors. <p> This has to be done with some care, as work in iterations beyond the iteration containing the optimal solutions contributes further to wasted work. This was handled by assigning a non-empty increasing bit-vector priorities to the root nodes of successive iterations using an interesting encoding scheme. (See <ref> [4] </ref> for details.). This encoding scheme solves the problem of assigning increasing priorities to successive roots, without knowing an upper-bound on how many iterations there will be. The encoding must also ensure that each node in one iteration receives higher priority than all nodes in the next iteration.
Reference: [5] <author> Kale L.V. and Warren D.S. </author> <title> Class of Architectures for a PROLOG Machine. </title> <booktitle> In International Conference on Logic Programming, </booktitle> <pages> pages 171-182, </pages> <address> Stockholm, Sweden, </address> <month> June </month> <year> 1985. </year>
Reference-contexts: the parallelism between multiple literals of a clause (or, in problem-solving terminology: that between multiple subgoals of a particular method). 4.5.1 REDUCE/OR Process Model Our work on speculative computations in Parallel Logic Programming was conducted in the context of the REDUCE/OR process model (ROP M ), proposed and developed in <ref> [5, 1] </ref>. The past and ongoing work related to this model in our group includes development of a binding environment [6] and a compiler [11].
Reference: [6] <author> Kale L.V., Ramkumar B. and Shu W. </author> <title> A Memory Organization Independent Binding Environment for AND and OR Parallel Execution of Logic Programs. </title> <booktitle> In The 5th International Conference/Symposium on Logic Programming, </booktitle> <pages> pages 1223-1240, </pages> <address> Seattle, </address> <month> August </month> <year> 1988. </year>
Reference-contexts: The past and ongoing work related to this model in our group includes development of a binding environment <ref> [6] </ref> and a compiler [11]. The REDUCE/OR process model exploits AND as well as OR parallelism from Logic programs, and handles the interactions of AND and OR parallelism without losing parallelism. It is also designed so that it can use both shared and distributed memory machines.
Reference: [7] <author> Korf R.E. </author> <title> Optimal Path-Finding Algorithms. </title> <booktitle> In Search in Artificial Intelligence, </booktitle> <pages> pages 223-267. </pages> <publisher> Springer-Verlag, </publisher> <year> 1988. </year>
Reference-contexts: This process is continued until a solution is found. This algorithm was defined by Korf <ref> [7] </ref>, and is called IDA*. As in A*, the first solution found is an optimal solution in IDA* too. Very successive iterative duplicates all the work done by the previous iteration.
Reference: [8] <author> Kumar Vipin and Rao V. Nageshwar. </author> <title> Parallel Depth First Search. Part 2: Analysis. </title> <journal> International Journal of Parallel Programming, </journal> <pages> pages 501-519, </pages> <month> December </month> <year> 1987. </year>
Reference-contexts: With this, we were able to obtain very good speedups for many depth first search problems. Other work on dynamic load balancing for this problem includes that of Kumar and Rao <ref> [12, 8] </ref>. When one is interested in any one solution, this parallelization technique leads to problems. If we search two successors of a state (assume there are only two for simplicity), the solution may 4 lie in the sub-tree of either node.
Reference: [9] <author> Lai T.H. and Sahni Sartaj. </author> <title> Anomalies in Parallel Branch-and-Bound Algorithms. </title> <booktitle> In Communications of the ACM, </booktitle> <pages> pages 594-602, </pages> <month> June </month> <year> 1984. </year>
Reference-contexts: Exploring the two subtrees in parallel is thus speculative - we may not need both those sub-computations. This fact, and the resultant speedup anomalies were noted in a branch-and-bound search which is closely related to depth-first search, by Lai and Sahani <ref> [9] </ref>. One may get deceleration anomalies where adding a processor may slow down the search process in finding a solution. This may happen because the added processor may create some "red herring" work that other processors wasted there time on.
Reference: [10] <author> Nilsson N.J. </author> <booktitle> Principles of Artificial Intelligence. </booktitle> <publisher> Tioga Press, Inc., </publisher> <year> 1980. </year>
Reference-contexts: Moreover, at any moment, the set of "active" nodes form a characteristic shape resembling a broom with a long stick. 5 4.2 Iterative Deepening Sometimes, one is interested in an optimal solution to a search problem. If an admissible heuristics is available <ref> [10] </ref> one can use the A* algorithm, which ensures that the first solution found is the optimal one. However, A* requires large memory space on the average, and degenerates to breadth first search in the worst case.
Reference: [11] <author> Ramkumar B. and Kale L.V. </author> <title> Compiled Execution of the REDUCE-OR Process Model on Multiprocessors. </title> <booktitle> In North American Conference on Logic Programming, </booktitle> <pages> pages 313-331, </pages> <month> October </month> <year> 1989. </year>
Reference-contexts: The past and ongoing work related to this model in our group includes development of a binding environment [6] and a compiler <ref> [11] </ref>. The REDUCE/OR process model exploits AND as well as OR parallelism from Logic programs, and handles the interactions of AND and OR parallelism without losing parallelism. It is also designed so that it can use both shared and distributed memory machines.
Reference: [12] <author> Rao V. Nageshwara and Kumar Vipin. </author> <title> Parallel Depth First Search. Part 1: Implementation. </title> <journal> International Journal of Parallel Programming, </journal> <pages> pages 479-499, </pages> <month> December </month> <year> 1987. </year>
Reference-contexts: With this, we were able to obtain very good speedups for many depth first search problems. Other work on dynamic load balancing for this problem includes that of Kumar and Rao <ref> [12, 8] </ref>. When one is interested in any one solution, this parallelization technique leads to problems. If we search two successors of a state (assume there are only two for simplicity), the solution may 4 lie in the sub-tree of either node. <p> This can happen because the added processor picked a part of search tree that happened to contain the solution. Kumar et al noted this in the context of parallel depth-first search. they reported a speedup varying between 2.9 to 16 with 9 processors for a 15-puzzle problem <ref> [12] </ref>. We started with the dual objectives of (1) ensuring that speedups are consistent - i.e. do not vary from run to run and (2) ensuring that the speedups increase monotonically with the number of processors, preferably being as close to the number of processors as possible. <p> Even with a binary branching factor, the duplication cost is at most 100%, which is tolerable considering the significant memory savings. As each iteration of IDA* is a depth-first search, it can be parallelized using the techniques described above. Kumar et al in <ref> [12] </ref>. were the first to demonstrate parallel schemes for this problem. Their results did exhibit speedup anomalies, and they reported speedups to all solutions (as their primary interest was to demonstrate the efficacy of their load balancing scheme). Note that there may be multiple optimal solutions in the last level.
Reference: [13] <author> Saletore V.A. and Kale L.V. </author> <title> Obtaining First Solutions Faster in AND-OR Parallel Execution of Logic Programs. </title> <booktitle> In North American Conference on Logic Programming, </booktitle> <pages> pages 390-406, </pages> <month> October </month> <year> 1989. </year>
Reference-contexts: In addition, multiple instances of a single literal fired were prioritized so that the one fired earlier has higher priority than the ones fired later. For brevity, we will leave the description of this scheme at that, and refer the reader to <ref> [13] </ref> for a full description. Intuitively, the scheme represented the strategy of supporting the subcomputations that were closer to yielding a solution to the top level goal. ("Support the Leader" strategy).
Reference: [14] <author> Saletore Vikram A. </author> <title> Machine Independent Parallel Execution of Speculative Computations. </title> <type> PhD thesis, </type> <note> In preparation, </note> <institution> Dept. Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, Urbana, IL, </institution> <month> September </month> <year> 1990. </year> <month> 14 </month>
Reference-contexts: The complete details of this scheme can be found in <ref> [14] </ref>. <p> A synthesis of these is needed. We developed a simple scheme <ref> [14] </ref> that is sufficient to ensure consistent and linear speedups for many (but not all) AND/OR problems. We believe that schemes that involve dynamic changing of priorities are necessary to handle this class of problems. 4.7 Game Trees Alpha-beta search is an efficient game tree search procedure. <p> These strategies still have the drawback (to a smaller extent) we discussed earlier | priorities are not distributed uniformly over processors, hence low priority (wasteful) work gets done. For additional variants of this strategy and their performance on various machines we refer the reader to <ref> [14] </ref>. Centralized strategies provide good priority and load balancing. Their weakness is that the central pool of work becomes the bottleneck. We can solve the problem of a bottleneck by splitting the pool of work amongst a few processing elements | essentially creating some sort of a semi-distributed strategy.
Reference: [15] <author> Saletore Vikram A. and Kale L.V. </author> <title> Consistent Linear Speedups to a First Solution in Parallel State-Space Search. </title> <booktitle> In The Eighth National Conference on Artificial Intelligence (AAAI-90), </booktitle> <address> Boston, Mass., </address> <month> July </month> <year> 1990. </year> <month> 15 </month>
Reference-contexts: With that objective, it is clear that all the work that is done by the sequential program is "mandatory" whereas all the other nodes not explored by the sequential algorithm are "wastage". Our scheme, described in <ref> [15] </ref> is based on bit-vector priorities. Each node in the search tree is assigned a priority. Priority bit-vectors can be of arbitrary length, and their ordering is lexicographic the lexicographically smaller bit-vector indicates higher priority. The priority of the root is a bit-vector of length 0.
References-found: 15

