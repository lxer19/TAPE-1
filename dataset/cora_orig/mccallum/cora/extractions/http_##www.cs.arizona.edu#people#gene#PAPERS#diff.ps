URL: http://www.cs.arizona.edu/people/gene/PAPERS/diff.ps
Refering-URL: http://www.cs.arizona.edu/people/gene/vita.html
Root-URL: http://www.cs.arizona.edu
Title: An O(ND) Difference Algorithm and Its Variations  
Author: EUGENE W. MYERS 
Keyword: KEY WORDS longest common subsequence shortest edit script edit graph file comparison  
Address: Tucson, AZ 85721, U.S.A.  
Affiliation: Department of Computer Science, University of Arizona,  
Abstract: The problems of finding a longest common subsequence of two sequences A and B and a shortest edit script for transforming A into B have long been known to be dual problems. In this paper, they are shown to be equivalent to finding a shortest/longest path in an edit graph. Using this perspective, a simple O(ND) time and space algorithm is developed where N is the sum of the lengths of A and B and D is the size of the minimum edit script for A and B. The algorithm performs well when differences are small (sequences are similar) and is consequently fast in typical applications. The algorithm is shown to have O(N + D 2 ) expected-time performance under a basic stochastic model. A refinement of the algorithm requires only O(N) space, and the use of suffix trees leads to an O(NlgN + D 2 ) time variation. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Aho, A.V., Hirschberg, D.S., and Ullman, J.D. </author> <title> ``Bounds on the Complexity of the Longest Common Subsequence Problem.'' </title> <journal> Journal of ACM 23, </journal> <volume> 1 (1976), </volume> <pages> 1-12. </pages>
Reference-contexts: A later refinement by Hirschberg [7] delivers a longest common subsequence using only linear space. When algorithms are over arbitrary alphabets, use ``equalunequal'' comparisons, and are characterized in terms of the size of their input, it has been shown that W (N 2 ) time is necessary <ref> [1] </ref>. A ``Four Russians'' approach leads to slightly better O (N 2 lglgN/lgN) and O (N 2 /lgN) time algorithms for arbitrary and finite alphabets respectively [13]. The existence of faster algorithms using other comparison formats is still open. <p> Consequently, V is an array of integers where V [k] contains the row index of the endpoint of a furthest reaching path in diagonal k. Constant MAX [0,M+N] Var V: Array [- MAX .. MAX] of Integer 1. V <ref> [1] </ref> 0 3. For k -D to D in steps of 2 Do 4. If k = -D or k D and V [k - 1] &lt; V [ k + 1] Then 5. x V [ k + 1] 6. Else 7. x V [ k - 1]+1 9.
Reference: 2. <author> Aho, A.V., Hopcroft, J.E., and Ullman, J.D. </author> <title> Data Structures and Algorithms. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Mass. </address> <year> (1983), </year> <pages> 203-208. </pages>
Reference: 3. <author> Dijkstra, </author> <title> E.W. ``A Note on Two Problems in Connexion with Graphs.'' </title> <booktitle> Numerische Mathematik 1 (1959), </booktitle> <pages> 269-271. </pages>
Reference-contexts: As noted in Section 2, the LCS/SES problem can be viewed as an instance of the single-source shortest paths problem on a weighted edit graph. This suggests that an efficient algorithm can be obtained by specializing Dijkstra's algorithm <ref> [3] </ref>. A basic exercise [2: 207-208] shows that the algorithm takes O (ElgV) time where E is the number of edges and V is the number of vertices in the subject graph. For an edit graph E &lt; 3V since each point has outdegree at most three.
Reference: 4. <author> Gosling, J. </author> <title> ``A Redisplay Algorithm.'' </title> <booktitle> Proceedings ACM SIGPLAN/SIGOA Symposium on Text Manipulation (1981), </booktitle> <pages> 123-129. </pages>
Reference: 5. <author> Hall, P.A.V. and Dowling, </author> <title> G.R. ``Approximate String Matching.'' </title> <journal> Computing Surveys 12, </journal> <volume> 4 (1980), </volume> <pages> 381-402. </pages>
Reference: 6. <author> Harel, D. and Tarjan, R.E. </author> <title> ``Fast Algorithms for Finding Nearest Common Ancestors.'' </title> <journal> SIAM Journal on Computing 13, </journal> <volume> 2 (1984), </volume> <pages> 338-355. </pages>
Reference-contexts: The term sublist is used as opposed to subsequence to emphasize that the symbols must be contiguous. Second, a recent RAM-based algorithm for anwering Q on-line queries for the lowest common ancestors of vertices in a fixed V-vertex tree takes O (V+Q) time <ref> [6] </ref>. The efficient variation centers on quickly finding the length or endpoint of a maximal snake starting at point (x,y). This is shown to reduce to finding the lowest common ancestor of two leaves in a suffix tree. <p> In a linear preprocessing pass the sublist lengths to every vertex are computed and the auxiliary structures needed for the O (V+Q) lowest common ancestor algorithm of Harel and Tarjan <ref> [6] </ref> are constructed. This RAM-based algorithm requires O (V) preprocessing time but can then answer each on-line query in O (1) time.
Reference: 7. <author> Hirschberg, </author> <title> D.S. ``A Linear Space Algorithm for Computing Maximal Common Subsequences.'' </title> <journal> Communications of ACM 18, </journal> <volume> 6 (1975), </volume> <pages> 341-343. </pages>
Reference-contexts: One of the earliest algorithms is by Wagner & Fischer [20] and takes O (N 2 ) time and space to solve a generalization they call the string-to-string correction problem. A later refinement by Hirschberg <ref> [7] </ref> delivers a longest common subsequence using only linear space. When algorithms are over arbitrary alphabets, use ``equalunequal'' comparisons, and are characterized in terms of the size of their input, it has been shown that W (N 2 ) time is necessary [1]. <p> Second, the algorithm can be refined to use only linear space when reporting an edit script. The only other algorithm that has been shown to admit such a refinement is the basic O (MN) dynamic programming algorithm <ref> [7] </ref>. A linear space algorithm is of practical import since many large problems can reasonably be solved in O (D 2 ) time but not in O (D 2 ) space. <p> Since paths in opposing directions are in exact correspondence, the direction of a path is distinguished only when it is of operational importance. As in the linear space algorithm of Hirschberg <ref> [7] </ref>, a divide-and-conquer strategy is employed. A D-path has D+1 snakes some of which may be empty. The divide step requires finding the R D/2 H + 1 or middle snake of an optimal D-path.
Reference: 8. <author> Hirschberg, </author> <title> D.S. ``Algorithms for the Longest Common Subsequence Problem.'' </title> <journal> Journal of ACM 24, </journal> <volume> 4 (1977), </volume> <pages> 664-675. </pages>
Reference-contexts: L be the length of a longest common subsequence and let the dual parameter D = 2 (N - L) be the length of a shortest edit script. (It is assumed throughout this introduction that both strings have the same length N.) The two best output-sensitive algorithms are by Hirschberg <ref> [8] </ref> and take O (NL + NlgN) and O ( DLlgN) time. An algorithm by Hunt & Szymanski [11] takes O ( (R + N) lgN) time where the parameter R is the total number of ordered pairs of positions at which the two input strings match.
Reference: 9. <author> Hirschberg, </author> <title> D.S. ``An Information-Theoretic Lower Bound for the Longest Common Subsequence Problem.'' </title> <journal> Information Processing Letters 7, </journal> <volume> 1 (1978), </volume> <pages> 40-41. </pages>
Reference-contexts: The existence of faster algorithms using other comparison formats is still open. Indeed, for algorithms that use ``less thanequalgreater than'' comparisons, W (NlgN) time is the best lower bound known <ref> [9] </ref>. hhhhhhhhhhhhhhhhhh * This work was supported in part by the National Science Foundation under Grant MCS82-10096. - 1 - Recent work improves upon the basic O ( N 2 ) time arbitrary alphabet algorithm by being sensitive to other prob-lem size parameters.
Reference: 10. <author> Hunt, J.W. and McIlroy, </author> <title> M.D. ``An Algorithm for Differential File Comparison.'' </title> <type> Computing Science Technical Report 41, </type> <institution> Bell Laboratories (1975). </institution> - <month> 14 </month> - 
Reference-contexts: The basic O (ND) algorithm served as the basis for a new implementation of the UNIX diff program [15]. This version usually runs two to four times faster than the System 5 implementation based on the Hunt and Szymanski algorithm <ref> [10] </ref>. However, there are cases when D is large where their algorithm is superior (e.g. for files that are completely different, R=0 and D=2N).
Reference: 11. <author> Hunt, J.W. and Szymanski, T.G. </author> <title> ``A Fast Algorithm for Computing Longest Common Subsequences.'' </title> <booktitle> Com--munications of ACM 20, 5 (1977), </booktitle> <pages> 350-353. </pages>
Reference-contexts: An algorithm by Hunt & Szymanski <ref> [11] </ref> takes O ( (R + N) lgN) time where the parameter R is the total number of ordered pairs of positions at which the two input strings match. Note that all these algorithms are W (N 2 ) or worse in terms of N alone. <p> Biologists wish to know how one DNA strand has mutated into another. For these situations, an O (ND ) time algorithm is superior to Hirschberg's algorithms because L is O ( N) when D is small. Furthermore, the approach of Hunt and Szymanski <ref> [11] </ref> is predicated on the hypothesis that R is small in practice. While this is frequently true, it must be noted that R has no correlation with either the size of the input or the size of the output and can be O (N 2 ) in many situations. <p> The points (x,y) for which a x = b y are called match points. The total number of match points between A and B is the parameter R characterizing the Hunt & Szymanski algorithm <ref> [11] </ref>. It is also the number of diagonal edges in the edit graph as diagonal edges are in one-to-one correspondence with match points.
Reference: 12. <author> Knuth, D.E. </author> <booktitle> The Art of Computer Programming, </booktitle> <volume> Vol. </volume> <month> 3: </month> <title> Sorting and Searching. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Mass. </address> <year> (1983), </year> <pages> 490-493. </pages>
Reference: 13. <author> Masek, W.J. and Paterson, </author> <title> M.S. ``A Faster Algorithm for Computing String Edit Distances.'' </title> <journal> J. of Computer and Systems Sciences 20, </journal> <volume> 1 (1980), </volume> <pages> 18-31. </pages>
Reference-contexts: A ``Four Russians'' approach leads to slightly better O (N 2 lglgN/lgN) and O (N 2 /lgN) time algorithms for arbitrary and finite alphabets respectively <ref> [13] </ref>. The existence of faster algorithms using other comparison formats is still open.
Reference: 14. <author> McCreight, </author> <title> E.M. ``A Space-Economical Suffix Tree Construction Algorithm.'' </title> <journal> Journal of ACM 23, </journal> <volume> 2 (1976), </volume> <pages> 262-272. </pages>
Reference-contexts: Thus suffix trees can be stored in O (L) space. The efficient construction of suffix trees is beyond the scope of this paper. The reader is referred to a paper by McCreight <ref> [14] </ref> giving an algorithm that constructs a suffix tree in O (L) steps. Most of the steps are easily done in O (1) time but some require selecting an out-edge based on its first symbol.
Reference: 15. <author> Miller, W., and Myers, </author> <title> E.W. ``A File Comparison Program.'' </title> <journal> Software Practice & Experience 15, </journal> <volume> 11 (1985), </volume> <pages> 1025-1040. </pages>
Reference-contexts: With the exception of the O (NlgN + D 2 ) worst-case variation, the algorithms presented in this paper are practical. The basic O (ND) algorithm served as the basis for a new implementation of the UNIX diff program <ref> [15] </ref>. This version usually runs two to four times faster than the System 5 implementation based on the Hunt and Szymanski algorithm [10]. However, there are cases when D is large where their algorithm is superior (e.g. for files that are completely different, R=0 and D=2N).
Reference: 16. <author> Nakatsu, N., Kambayashi, Y., and Yajima, S. </author> <title> ``A Longest Common Subsequence Algorithm Suitable for Similar Text Strings.'' </title> <journal> Acta Informatica 18 (1982), </journal> <pages> 171-179. </pages>
Reference-contexts: Our algorithm is simple and based on an intuitive edit graph formalism. Unlike others it employs the ``greedy'' design paradigm and exposes the relationship of the longest common subsequence problem to the single-source shortest path problem. Another O (ND) algorithm has been presented elsewhere <ref> [16] </ref>. However, it uses a different design paradigm and does not share the following features. The algorithm can be refined to use only linear space, and its expected-case time behavior is shown to be O (N + D 2 ).
Reference: 17. <author> Rochkind, M.J. </author> <title> ``The Source Code Control System.'' </title> <journal> IEEE Transactions on Software Engineering 1, </journal> <volume> 4 (1975), </volume> <pages> 364-370. </pages>
Reference: 18. <author> Sankoff, D. and Kruskal, J.B. </author> <title> Time Warps, String Edits and Macromolecules: The Theory and Practice of Sequence Comparison. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Mass. </address> <year> (1983). </year>
Reference: 19. <author> Tichy, W. </author> <title> ``The String-to-String Correction Problem with Block Moves.'' </title> <journal> ACM Transactions on Computer Systems 2, </journal> <volume> 4 (1984), </volume> <pages> 309-321. </pages>
Reference: 20. <author> Wagner, R.A. and Fischer, M.J. </author> <title> ``The String-to-String Correction Problem.'' </title> <journal> Journal of ACM 21, </journal> <volume> 1 (1974), </volume> <pages> 168-173. </pages>
Reference-contexts: Formally, the problem statement is to find a longest common subsequence or, equivalently, to find the minimum ``script'' of symbol deletions and insertions that transform one sequence into the other. One of the earliest algorithms is by Wagner & Fischer <ref> [20] </ref> and takes O (N 2 ) time and space to solve a generalization they call the string-to-string correction problem. A later refinement by Hirschberg [7] delivers a longest common subsequence using only linear space.
References-found: 20

