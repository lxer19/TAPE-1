URL: http://www.cs.berkeley.edu/~fateman/papers/spief96.ps
Refering-URL: http://www.cs.berkeley.edu/~fateman/ocrpapers.html
Root-URL: 
Title: Progress in recognizing typeset mathematics distinct conflicting grammars are needed to cover variations in contemporary
Author: Richard J. Fateman, Taku Tokuyasu 
Keyword: Additional programs providing formula recognition and parsing  Keywords: optical character recognition, typeset mathematics, utility programs, Lisp.  
Note: also form a part of this system. It is important however to realize that  is not possible.  
Address: Berkeley, CA 94720-1776  
Affiliation: University of California at Berkeley Computer Science Division  
Abstract: Printed mathematics has a number of features which distinguish it from conventional text. These include structure in two dimensions (fractions, exponents, limits), frequent font changes, symbols with variable shape (quotient bars), and substantially differing notational conventions from source to source. When compounded with more generic problems such as noise and merged or broken characters, printed mathematics offers a challenging arena for recognition. Our project was initially driven by the goal of scanning and parsing some 5,000 pages of elaborate mathematics (tables of definite integrals). While our prototype system demonstrates success on translating noise-free typeset equations into Lisp expressions appropriate for further processing, a more semantic top-down approach appears necessary for higher levels of performance. Such an approach may benefit the incorporation of these programs into a more general document processing viewpoint. We intend to release to the public our somewhat refined prototypes as utility programs in the hope that they will be of general use in the construction of custom OCR packages. These utilities are quite fast even as originally prototyped in Lisp, where they may be of particular interest to those working on "intelligent" optical processing. Some routines have been re-written in C++ as well. 
Abstract-found: 1
Intro-found: 1
Reference: [BBY92] <author> H.S. Baird, H. Bunke, and K. Yamamoto, </author> <title> editors. Structured document image analysis, </title> <address> Berlin, 1992. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Good general references include Baird <ref> [BBY92] </ref> and O'Gorman [OK95], which provide keys to the literature. We have not been able to utilize commercial OCR software, which appears to be nearly helpless at recognizing glyphs placed within a mathematical context and not aligned on conventional text baselines.
Reference: [BF94] <author> B. P. Berman and R. J. Fateman. </author> <title> Optical character recognition for typset mathematics. </title> <booktitle> In ACM Proc. ISSAC '94, </booktitle> <address> Oxford, UK, </address> <month> July, </month> <year> 1994, </year> <pages> pages 348-353, </pages> <year> 1994. </year>
Reference-contexts: We expect a relatively small number of words (sin, cos, tan) to occur, and that many of the other symbols will be numbers, isolated italic characters, and scientific symbols. This project <ref> [BF94] </ref> originated from our interest in scanning and storing thousands of pages of historically interesting tables of integrals. This has allowed us to limit the horizon of possibilities somewhat. <p> Since our initial implementation of some of these programs was reported in <ref> [BF94] </ref>, we have reprogrammed components and achieved substantial speedups as indicated above. A recently completed (12/95) [HMRT95] student project writing code to a similar design but in C++ rather than Lisp has resulted in other timing data points for some, but not all components.
Reference: [Bok92] <author> M. Bokser. </author> <booktitle> Omnidocument technologies. Proceedings of the IEEE, </booktitle> <volume> 80(7), </volume> <month> July </month> <year> 1992. </year>
Reference-contexts: The Hausdorff distance is appealing, but we do not have evidence yet that it is significantly better for recognition, considering the expense [Tok95]. Another approach, which appears to be used by some commercial programs <ref> [Bok92] </ref>, has some appeal and is described below. We divide the area of a connected component, or some unit separated from the image as a potential character, into n by m regions and count the ratio of black vs. white bits in each region.
Reference: [dH39] <editor> D. Bierens de Haan. Nouvelles Tables d'Integrales De finies. G. E. </editor> <publisher> Stechert & Co., </publisher> <address> NY, 1867 corrected edition, </address> <month> October </month> <year> 1939. </year> <title> with an English Translation of the Introduction by J.F. </title> <publisher> Ritt. </publisher>
Reference-contexts: We are yet more likely to be faced with forms that require more devious parsers. Consider the expression sin ax cos bx, taken from an integral table <ref> [dH39] </ref>. Observe that there are two multiplication "symbols" in use. The center-dot is a low-precedence multiplication (lower binding than cos), but the "empty space" between b and x is also a multiplication, but of higher binding precedence than cos. <p> Our experiments have also shown, however, that a purely bottom-up approach is of limited use in the face of noisy data (such as, in our case, integral tables printed in 1939 <ref> [dH39] </ref>). We plan to incorporate routines for higher-level structure analysis, borrowing for example from ideas for page segmentation and classification [PZ92].
Reference: [FT] <author> R. Fateman and T. Tokuyasu. </author> <title> A suite of lisp programs for optical character recognition. manuscript in progress. </title>
Reference-contexts: This is sufficient for correcting small amounts of skew. Detailed analysis of the errors are given elsewhere <ref> [FT] </ref>. Occasionally papers are scanned either accidentally or purposely at right angles (or upside down). Scanning software can be adjusted for this, but sometimes with unattended operation it is not apparent that a figure or table has been scanned at an angle until later.
Reference: [FT96] <author> R. Fateman and T. Tokuyasu. </author> <title> Optical character recognition and parsing of typeset mathematics. </title> <journal> J. Vis. Commun. Image Represent., </journal> <note> 1996. to appear. </note>
Reference-contexts: We believe this is both a challenging and potentially fruitful area for optical character recognition (OCR) and document analysis research. A description of our overall approach and results so far can be found in <ref> [FT96] </ref>. In our ongoing efforts to learn what is required to create a robust mathematics recognition engine, we have developed a number of routines that we hope will be of general use to the public for the development of OCR systems. These are described in the following three sections. <p> We do not expect to be able to parse everything that can be perversely constructed. Nevertheless, these methods correctly recognize all the quotient and minus signs in numerous test cases <ref> [FT96] </ref> as well as the equal sign. Linearization In this phase we build horizontal and vertical hierarchical structures that encode the adjacency detected among the tokens in a non-numerical format. <p> Parsing of those mathematical formulas on which we have total success takes negligible time compared to the prior processing steps. For example, in tests on a 54-character formula <ref> [FT96] </ref>, heuristics to find plausible explanations and disambiguations of the horizontal lines (minus signs, divide bars, equal signs) took about 0.38 seconds, dividing up the space into super/subscript areas, matching parenthesis, and similar tasks took 0.15 seconds, and the final parsing an additional 0.01 seconds. <p> Many of our algorithms so far have been low-level routines appropriate for a bottom-up character recognition approach. Together with the parsing scheme given above, this is quite sufficient for the recognition of many relatively simple perfectly typeset images of mathematical formulas <ref> [FT96] </ref>. Our experiments have also shown, however, that a purely bottom-up approach is of limited use in the face of noisy data (such as, in our case, integral tables printed in 1939 [dH39]).
Reference: [HMRT95] <author> James Hopkin, Kathey Marsden, Archie Russell, and Cynthia Si Tian. Ocrchie: </author> <title> Optical character recognition library. CS169 term project, </title> <institution> U.C. Berkeley, </institution> <year> 1995. </year>
Reference-contexts: This is of course a matter of a programmer's experience in a system. 6. We find the speed of our Lisp routines to be quite satisfactory, and preliminary comparison timings of our C++ implementation <ref> [HMRT95] </ref> suggest we are not far off from the speed attainable in other languages. . The tasks for mathematical formula recognition are, at some levels, the same as for other types of document recognition. <p> Note that there are some unusually tall or wide characters in our domain of interest: divide bars for fractions, tall parentheses or integral signs, etc. An undergraduate team writing similar programs in C++ <ref> [HMRT95] </ref> also found that separately recognizing figures in categories based on absolute size improved accuracy, and that including two additional regions to the 5 by 5 grid, the top 10 percent and the bottom 10 percent of the figure, helped as well. 5 The Mathematics Operations Our initial approach was to <p> Since our initial implementation of some of these programs was reported in [BF94], we have reprogrammed components and achieved substantial speedups as indicated above. A recently completed (12/95) <ref> [HMRT95] </ref> student project writing code to a similar design but in C++ rather than Lisp has resulted in other timing data points for some, but not all components.
Reference: [OK95] <editor> Lawrence O'Gorman and Rangachar Kasturi, editors. </editor> <title> Document Image Analysis, </title> <address> Los Alami-tos, CA, 1995. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: Good general references include Baird [BBY92] and O'Gorman <ref> [OK95] </ref>, which provide keys to the literature. We have not been able to utilize commercial OCR software, which appears to be nearly helpless at recognizing glyphs placed within a mathematical context and not aligned on conventional text baselines. <p> Typically the angle will be less than 10 degrees. unskew (p d) given a picture and an angle, produces a new picture that is unskewed. There are a number of recent papers <ref> [OK95] </ref> written on deskewing algorithms. We use a simple (well-known) approach based on the following observation: the distribution of white and black bits is far more uniform when scanned along a slant instead of parallel to the text lines.
Reference: [PBM83] <author> Prudnikov, Brichkov, and Marichev. </author> <title> Integrals and Series, </title> <type> (volume 1). </type> <institution> Moscow gov't printing office, </institution> <year> 1983. </year>
Reference-contexts: The following two integral formulas were selected as representative of many similar formulas in a standard reference, <ref> [PBM83] </ref>.
Reference: [PZ92] <author> Theo Pavlidis and Jiangying Zhou. </author> <title> Page segmentation and classification. CVGIP: Graphical Models and Image Processing, </title> <type> 54(6), </type> <month> November </month> <year> 1992. </year>
Reference-contexts: We plan to incorporate routines for higher-level structure analysis, borrowing for example from ideas for page segmentation and classification <ref> [PZ92] </ref>. These tools can, we believe, be used in general document structure analysis, and so have a general payoff in development beyond the immediate objectives of mathematics recognition. 9 Acknowledgments This work was supported in part by Grants numbers CCR-9214963 and IRI-9411334, and by NSF Infrastructure Grant number CDA-8722788.
Reference: [Tok95] <author> Taku A. Tokuyasu. </author> <title> Optical character recognition of typeset mathematics. </title> <type> Master's thesis, </type> <institution> U.C. Berkeley, </institution> <month> May </month> <year> 1995. </year>
Reference-contexts: There are quite a few alternative possibilities. A useful metric must be fast to compute as well as likely to coincide with the human judgment. The Hausdorff distance is appealing, but we do not have evidence yet that it is significantly better for recognition, considering the expense <ref> [Tok95] </ref>. Another approach, which appears to be used by some commercial programs [Bok92], has some appeal and is described below.
References-found: 11

