URL: ftp://ftp.cs.huji.ac.il/users/transis/podc-96.ps
Refering-URL: http://www.cs.huji.ac.il/labs/transis/Abstracts/podc96.html
Root-URL: http://www.cs.huji.ac.il
Email: idish@cs.huji.ac.il  dolev@cs.huji.ac.il  
Title: Efficient Message Ordering in Dynamic Networks  
Author: Idit Keidar Danny Dolev 
Address: Jerusalem  Jerusalem  
Affiliation: Computer Science Institute The Hebrew University of  Computer Science Institute The Hebrew University of  
Abstract: We present an algorithm for totally ordering messages in the face of network partitions and site failures. The algorithm always allows a majority of connected processors in the network to make progress (i.e. to order messages), if they remain connected for sufficiently long, regardless of past failures. Furthermore, our algorithm always allows processors to initiate messages, even when they are not members of a connected majority component in the network. Thus, messages can eventually become totally ordered even if their initiator is never a member of a majority component. The algorithm guarantees that when a majority is connected, each message is ordered within two communication rounds, if no failures occur during these rounds. 
Abstract-found: 1
Intro-found: 1
Reference: [AAD93] <author> O. Amir, Y. Amir, and D. Dolev. </author> <title> A Highly Available Application in the Transis Environment. In Proceedings of the Hardware and Software Architectures for Fault Tolerance Workshop, </title> <institution> at Le Mont Saint-Michel, France, </institution> <month> June </month> <year> 1993. </year> <note> LNCS 774. </note>
Reference-contexts: When components merge, retransmitted messages from other components are inserted into the queue in an order that may interleave with local messages (but never preceding messages that were ordered already). COReL builds its knowledge about the order of messages at other processors. We use the colors model defined in <ref> [AAD93] </ref> to indicate the knowledge level associated with each message, as follows: green: Knowledge about the message's global total order. A processor marks a message as green when it knows that all the other members of the primary component know that the message is yellow.
Reference: [ADKM92a] <author> Y. Amir, D. Dolev, S. Kramer, and D. Malki. </author> <title> Membership Algorithms for Multicast Communication Groups. </title> <booktitle> In Intl. Workshop on Distributed Algorithms proceedings (WDAG-6), (LNCS, 647), number 6th, </booktitle> <pages> pages 292-312, </pages> <month> November </month> <year> 1992. </year>
Reference-contexts: Transis is a sophisticated transport layer (or group communication service layer) <ref> [ADKM92b, ADKM92a, DMS94, MADK94] </ref> that supplies omission fault free group multicast and membership services in an asynchronous environment. COReL uses Transis as a failure detector and as a building block for reliable communication within connected network components 3 .
Reference: [ADKM92b] <author> Y. Amir, D. Dolev, S. Kramer, and D. Malki. Transis: </author> <title> A Communication Sub-System for High Availability. </title> <booktitle> In FTCS conference, </booktitle> <volume> number 22, </volume> <month> July </month> <year> 1992. </year>
Reference-contexts: Our protocol uses an underlying group communication service. Group communication mechanisms that use hardware broadcast lead to simpler and more efficient solutions for replication than the traditional point-to-point mechanisms. Some of the leading systems for group communication today are: ISIS [BCG91, BSS91] and its new generation HORUS [VRCGS92], Transis <ref> [ADKM92b, MADK94] </ref>, Totem [AMMS + 93], Psync [PBS89], Newtop [EMS95] and the distributed operating system AMOEBA [KTHB89]. To increase availability, most of the group multicast algorithms mentioned above detect failures and extract faulty members from the membership. When processors reconnect, these algorithms do not recover the states of reconnected processors. <p> Transis is a sophisticated transport layer (or group communication service layer) <ref> [ADKM92b, ADKM92a, DMS94, MADK94] </ref> that supplies omission fault free group multicast and membership services in an asynchronous environment. COReL uses Transis as a failure detector and as a building block for reliable communication within connected network components 3 . <p> A framework for a partitionable membership service that fulfills these properties is described in [DMS95]. These properties are also fulfilled in the Agreed Communication service of the Extended Virtual Synchrony (EVS) model [MAMSA94]. The Transis <ref> [ADKM92b, MADK94] </ref> and Totem [AMMS + 93] systems implement partitionable membership and ordering services of this framework, and also support EVS. 3 The COReL Algorithm We present the COReL (Consistent Object Replication Layer) algorithm for reliable multicast and total ordering of messages.
Reference: [ADMSM94] <author> Y. Amir, D. Dolev, P. M. Melliar-Smith, and L. E. Moser. </author> <title> Robust and Efficient Replication using Group Communication. </title> <type> Technical Report CS94-20, </type> <institution> Institute of Computer Science, The Hebrew University of Jerusalem, Jerusalem, Israel, </institution> <year> 1994. </year>
Reference-contexts: The algorithm uses a rotating coordinator scheme among all the processors, and does not focus only on members of the current membership. When a majority is connected, the worst-case latency until ordering a single message can be O (n) communication rounds. The total ordering protocols in <ref> [MMSA93, MHS89, ADMSM94] </ref> also overcome network partitions. Total [MMSA93] incurs a high overhead: the maximum number of communication rounds required is not bounded, while our algorithm requires two communication rounds to order a message if no failures occur during these rounds. <p> The replication algorithm suggested 2 By "no failures occur" we implicitly mean that the underlying membership service does not report of failures. in [MHS89] is centralized, and thus highly increases the load on one server, while our protocol is decentralized and symmetric. The protocol in <ref> [ADMSM94] </ref> uses a majority-based scheme for message ordering, it decreases the requirement for end-to-end acknowledgments, but does not always allow a majority to make progress. 2 The Model COReL (the Consistent Object Replication Layer) is an algorithm for consistent order of messages, designed to implement a high-level replication service in the
Reference: [AMMS + 93] <author> Y. Amir, L. E. Moser, P. M. Melliar-Smith, D. A. Agarwal, and P. Ciarfella. </author> <title> Fast Message Ordering and Membership using a Logical Token-Passing Ring. </title> <booktitle> In International Conference on Distributed Computing Systems, number 13th, </booktitle> <pages> pages 551-560, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: Group communication mechanisms that use hardware broadcast lead to simpler and more efficient solutions for replication than the traditional point-to-point mechanisms. Some of the leading systems for group communication today are: ISIS [BCG91, BSS91] and its new generation HORUS [VRCGS92], Transis [ADKM92b, MADK94], Totem <ref> [AMMS + 93] </ref>, Psync [PBS89], Newtop [EMS95] and the distributed operating system AMOEBA [KTHB89]. To increase availability, most of the group multicast algorithms mentioned above detect failures and extract faulty members from the membership. When processors reconnect, these algorithms do not recover the states of reconnected processors. <p> A framework for a partitionable membership service that fulfills these properties is described in [DMS95]. These properties are also fulfilled in the Agreed Communication service of the Extended Virtual Synchrony (EVS) model [MAMSA94]. The Transis [ADKM92b, MADK94] and Totem <ref> [AMMS + 93] </ref> systems implement partitionable membership and ordering services of this framework, and also support EVS. 3 The COReL Algorithm We present the COReL (Consistent Object Replication Layer) algorithm for reliable multicast and total ordering of messages.
Reference: [BCG91] <author> K. Birman, R. Cooper, and B. Gleeson. </author> <title> Programming with Process Groups: Group and Multicast Semantics. </title> <type> TR 91-1185, </type> <institution> dept. of Computer Science, Cornell University, </institution> <month> Jan </month> <year> 1991. </year>
Reference-contexts: Our protocol uses an underlying group communication service. Group communication mechanisms that use hardware broadcast lead to simpler and more efficient solutions for replication than the traditional point-to-point mechanisms. Some of the leading systems for group communication today are: ISIS <ref> [BCG91, BSS91] </ref> and its new generation HORUS [VRCGS92], Transis [ADKM92b, MADK94], Totem [AMMS + 93], Psync [PBS89], Newtop [EMS95] and the distributed operating system AMOEBA [KTHB89]. To increase availability, most of the group multicast algorithms mentioned above detect failures and extract faulty members from the membership.
Reference: [BSS91] <author> K. Birman, A. Schiper, and P. Stephenson. </author> <title> Lightweight Causal and Atomic Group Multi-cast. </title> <journal> ACM Trans. Comp. Syst., </journal> <volume> 9(3) </volume> <pages> 272-314, </pages> <year> 1991. </year>
Reference-contexts: Our protocol uses an underlying group communication service. Group communication mechanisms that use hardware broadcast lead to simpler and more efficient solutions for replication than the traditional point-to-point mechanisms. Some of the leading systems for group communication today are: ISIS <ref> [BCG91, BSS91] </ref> and its new generation HORUS [VRCGS92], Transis [ADKM92b, MADK94], Totem [AMMS + 93], Psync [PBS89], Newtop [EMS95] and the distributed operating system AMOEBA [KTHB89]. To increase availability, most of the group multicast algorithms mentioned above detect failures and extract faulty members from the membership.
Reference: [CT] <author> T. D. Chandra and S. Toueg. </author> <title> Unreliable Failure Detectors for Asynchronous Systems. </title> <journal> Journal of ACM. </journal> <note> To appear. Previous version: PODC 1991 pp. 325-340. </note>
Reference-contexts: Failure Detection It is well known that reaching agreement in general, and total message ordering in particular, in asynchronous environments with a possibility of even one failure is impossible [FLP85]. To overcome this difficulty, Chandra and Toueg <ref> [CT] </ref> suggest to augment the model with failure detectors, and prove that in this case, agreement is possible. The failure detectors suggested in [CT] notify the "correct" processors which processors are "faulty". The definition does not capture network partitions. <p> To overcome this difficulty, Chandra and Toueg <ref> [CT] </ref> suggest to augment the model with failure detectors, and prove that in this case, agreement is possible. The failure detectors suggested in [CT] notify the "correct" processors which processors are "faulty". The definition does not capture network partitions. In [FKM + 95] these definitions are extended for the partitionable case. The algorithm we present uses an underlying transport layer with a membership protocol that serves as the failure detector. <p> When processors reconnect, these algorithms do not recover the states of reconnected processors. This is where our algorithm comes in: it extends the order achieved by such algorithms to a global total order. Chandra and Toueg <ref> [CT] </ref> suggest a consensus protocol that uses a failure detector, and tolerates crash failures, but does not tolerate network partitions. They suggest an atomic broadcast algorithm based on this consensus protocol. Their protocol could be extended to work in a partitionable environment [FKM + 95].
Reference: [DKYL] <author> Danny Dolev, Idit Keidar, and Esti Yeger-Lotem. </author> <title> Dynamic Voting for Consistent Primary Components. </title> <note> In preparation. </note>
Reference-contexts: When a partition occurs, a majority of the previous quorum may chosen as the new primary component. Thus, a primary component must not necessarily a majority of the processors. Dynamic voting may introduce inconsistencies, and therefore should be handled carefully. In <ref> [DKYL] </ref> we suggest an algorithm for consistently maintaining a primary component using dynamic voting. This algorithm may be easily incorporated into COReL. Finally, in [Kei94] we prove the correctness of the COReL algorithm. Acknowledgments Yair Amir greatly contributed to this work with his original ideas and insight.
Reference: [DMS94] <author> D. Dolev, D. Malki, and H. R. </author> <title> Strong. An Asynchronous Membership Protocol that Tolerates Partitions. </title> <type> Technical Report CS94-6, </type> <institution> Institute of Computer Science, The Hebrew University of Jerusalem, Jerusalem, Israel, </institution> <year> 1994. </year>
Reference-contexts: Transis is a sophisticated transport layer (or group communication service layer) <ref> [ADKM92b, ADKM92a, DMS94, MADK94] </ref> that supplies omission fault free group multicast and membership services in an asynchronous environment. COReL uses Transis as a failure detector and as a building block for reliable communication within connected network components 3 .
Reference: [DMS95] <author> D. Dolev, D. Malki, and H. R. </author> <title> Strong. A Framework for Partitionable Membership Service. </title> <type> TR 95-4, </type> <institution> Institute of Computer Science, The Hebrew University of Jerusalem, </institution> <month> March </month> <year> 1995. </year>
Reference-contexts: A framework for a partitionable membership service that fulfills these properties is described in <ref> [DMS95] </ref>. These properties are also fulfilled in the Agreed Communication service of the Extended Virtual Synchrony (EVS) model [MAMSA94].
Reference: [EMS95] <author> P. D. Ezhilchelvan, A. Macedo, and S. K. Shri-vastava. Newtop: </author> <title> a fault tolerant group communication protocol. </title> <booktitle> In International Conference on Distributed Computing Systems, number 15th, </booktitle> <month> June </month> <year> 1995. </year> <month> 8 </month>
Reference-contexts: Some of the leading systems for group communication today are: ISIS [BCG91, BSS91] and its new generation HORUS [VRCGS92], Transis [ADKM92b, MADK94], Totem [AMMS + 93], Psync [PBS89], Newtop <ref> [EMS95] </ref> and the distributed operating system AMOEBA [KTHB89]. To increase availability, most of the group multicast algorithms mentioned above detect failures and extract faulty members from the membership. When processors reconnect, these algorithms do not recover the states of reconnected processors.
Reference: [FKM + 95] <author> R. Friedman, I. Keidar, D. Malki, K. Bir--man, and D. Dolev. </author> <title> Deciding in Parti-tionable Networks. </title> <type> TR 95-16, </type> <institution> Institute of Computer Science, The Hebrew University of Jerusalem, Jerusalem, Israel, </institution> <month> November </month> <year> 1995. </year> <note> Also Cornell TR95-1554. Available via anonymous ftp at cs.huji.ac.il (132.65.16.10) in users/transis/TR95-16.ps.gz. </note>
Reference-contexts: To overcome this difficulty, Chandra and Toueg [CT] suggest to augment the model with failure detectors, and prove that in this case, agreement is possible. The failure detectors suggested in [CT] notify the "correct" processors which processors are "faulty". The definition does not capture network partitions. In <ref> [FKM + 95] </ref> these definitions are extended for the partitionable case. The algorithm we present uses an underlying transport layer with a membership protocol that serves as the failure detector. <p> Chandra and Toueg [CT] suggest a consensus protocol that uses a failure detector, and tolerates crash failures, but does not tolerate network partitions. They suggest an atomic broadcast algorithm based on this consensus protocol. Their protocol could be extended to work in a partitionable environment <ref> [FKM + 95] </ref>. However, their algorithm is optimized for the crash-only model and is less efficient if partitions occur. The algorithm uses a rotating coordinator scheme among all the processors, and does not focus only on members of the current membership.
Reference: [FLP85] <author> M. Fischer, N. Lynch, and M. Paterson. </author> <title> Impossibility of Distributed Consensus with One Faulty Process. </title> <journal> J. ACM, </journal> <volume> 32 </volume> <pages> 374-382, </pages> <month> April </month> <year> 1985. </year>
Reference-contexts: Failure Detection It is well known that reaching agreement in general, and total message ordering in particular, in asynchronous environments with a possibility of even one failure is impossible <ref> [FLP85] </ref>. To overcome this difficulty, Chandra and Toueg [CT] suggest to augment the model with failure detectors, and prove that in this case, agreement is possible. The failure detectors suggested in [CT] notify the "correct" processors which processors are "faulty". The definition does not capture network partitions.
Reference: [KD95] <author> I. Keidar and D. Dolev. </author> <title> Increasing the Resilience of Atomic Commit, at No Additional Cost. </title> <booktitle> In ACM Symp. on Prin. of Database Systems (PODS), </booktitle> <pages> pages 245-254, </pages> <month> May </month> <year> 1995. </year> <note> Previous version available as Technical Report CS94-18, </note> <institution> The Hebrew University, Jerusalem, Isreal. </institution>
Reference-contexts: The primary component is established in a three-phase agreement protocol, similar to Three Phase Commit protocols <ref> [Ske81, KD95] </ref>. The three phases are required in order to allow for recovery in case failures occur in the course of the establishing process. The three phases correlate to the three levels of colors in MQ. <p> Some of the principles presented in this protocol may be applied to make a variety of distributed algorithms more available, e.g. network management services and distributed database systems. In <ref> [KD95] </ref> we present an atomic commitment protocol for distributed database management based on such principles. In [Kei94] we suggest two extensions of the algorithm, optimizing it for highly unreliable networks, where a majority of the processors are rarely connected at once.
Reference: [Kei94] <author> I. Keidar. </author> <title> A Highly Available Paradigm for Consistent Object Replication. </title> <type> Master's thesis, </type> <institution> Institute of Computer Science, The Hebrew University of Jerusalem, Jerusalem, Israel, </institution> <year> 1994. </year> <note> Also available as Technical Report CS95-5, and via anonymous ftp at cs.huji.ac.il (132.65.16.10) in users/transis/thesis/keidar-msc.ps.gz. </note>
Reference-contexts: 1 Introduction Consistent order is a powerful paradigm for the design of fault tolerant applications, e.g. consistent replication <ref> [Sch90, Kei94] </ref>. We present an efficient algorithm for consistent message ordering in the face of network partitions and site failures. The network may partition into several components 1 , and remerge. The algorithm is most adequate for dynamic networks where failures are transient. <p> Processor q has m marked as yellow or green. 2. Prefix (MQ q ; m) = Prefix (MQ p ; m). In <ref> [Kei94] </ref> we formally prove that these invariants hold in COReL, and thus prove the correctness of COReL. 3.5 Handling Configuration Changes The main subtleties of the algorithm are in handling configuration changes. <p> Some of the principles presented in this protocol may be applied to make a variety of distributed algorithms more available, e.g. network management services and distributed database systems. In [KD95] we present an atomic commitment protocol for distributed database management based on such principles. In <ref> [Kei94] </ref> we suggest two extensions of the algorithm, optimizing it for highly unreliable networks, where a majority of the processors are rarely connected at once. <p> Thus, a primary component must not necessarily a majority of the processors. Dynamic voting may introduce inconsistencies, and therefore should be handled carefully. In [DKYL] we suggest an algorithm for consistently maintaining a primary component using dynamic voting. This algorithm may be easily incorporated into COReL. Finally, in <ref> [Kei94] </ref> we prove the correctness of the COReL algorithm. Acknowledgments Yair Amir greatly contributed to this work with his original ideas and insight. Special thanks to Dalia Malki and Catriel Beeri who suggested simplifications to the algorithm and presentation.
Reference: [KTHB89] <author> M. F. Kaashoek, A. S. Tanenbaum, S. F. Hum-mel, and E. H. Bal. </author> <title> An Efficient Reliable Broadcast Protocol. </title> <journal> Operating Systems Review, </journal> <volume> 23(4) </volume> <pages> 5-19, </pages> <month> October </month> <year> 1989. </year>
Reference-contexts: Some of the leading systems for group communication today are: ISIS [BCG91, BSS91] and its new generation HORUS [VRCGS92], Transis [ADKM92b, MADK94], Totem [AMMS + 93], Psync [PBS89], Newtop [EMS95] and the distributed operating system AMOEBA <ref> [KTHB89] </ref>. To increase availability, most of the group multicast algorithms mentioned above detect failures and extract faulty members from the membership. When processors reconnect, these algorithms do not recover the states of reconnected processors.
Reference: [Lam78] <author> L. Lamport. </author> <title> Time, Clocks, and the Ordering of Events in a Distributed System. </title> <journal> Communications of the ACM, </journal> <volume> 21(7) </volume> <pages> 558-565, </pages> <month> July 78. </month>
Reference-contexts: Then we say that m is delivered in the context of C. Or shorter, m is delivered in C. 2.2 Transport Layer's Total Order Properties This paper deals with the ordering of messages and events. The causal partial order <ref> [Lam78] </ref> is defined as the transitive closure of: m cause ! m 0 if deliver q (m) ! send q (m 0 ) or if send q (m) ! send q (m 0 ).
Reference: [MADK94] <author> D. Malki, Y. Amir, D. Dolev, and S. Kramer. </author> <title> The Transis Approach to High Availability Cluster Communication. </title> <type> TR CS94-14, </type> <institution> Institute of Computer Science, The Hebrew University of Jerusalem, </institution> <month> June </month> <year> 1994. </year>
Reference-contexts: Our protocol uses an underlying group communication service. Group communication mechanisms that use hardware broadcast lead to simpler and more efficient solutions for replication than the traditional point-to-point mechanisms. Some of the leading systems for group communication today are: ISIS [BCG91, BSS91] and its new generation HORUS [VRCGS92], Transis <ref> [ADKM92b, MADK94] </ref>, Totem [AMMS + 93], Psync [PBS89], Newtop [EMS95] and the distributed operating system AMOEBA [KTHB89]. To increase availability, most of the group multicast algorithms mentioned above detect failures and extract faulty members from the membership. When processors reconnect, these algorithms do not recover the states of reconnected processors. <p> Transis is a sophisticated transport layer (or group communication service layer) <ref> [ADKM92b, ADKM92a, DMS94, MADK94] </ref> that supplies omission fault free group multicast and membership services in an asynchronous environment. COReL uses Transis as a failure detector and as a building block for reliable communication within connected network components 3 . <p> A framework for a partitionable membership service that fulfills these properties is described in [DMS95]. These properties are also fulfilled in the Agreed Communication service of the Extended Virtual Synchrony (EVS) model [MAMSA94]. The Transis <ref> [ADKM92b, MADK94] </ref> and Totem [AMMS + 93] systems implement partitionable membership and ordering services of this framework, and also support EVS. 3 The COReL Algorithm We present the COReL (Consistent Object Replication Layer) algorithm for reliable multicast and total ordering of messages.
Reference: [MAMSA94] <author> L. E. Moser, Y. Amir, P. M. Melliar-Smith, and D. A. Agarwal. </author> <title> Extended Virtual Synchrony. </title> <booktitle> In International Conference on Distributed Computing Systems, number 14th, </booktitle> <month> June </month> <year> 1994. </year>
Reference-contexts: A framework for a partitionable membership service that fulfills these properties is described in [DMS95]. These properties are also fulfilled in the Agreed Communication service of the Extended Virtual Synchrony (EVS) model <ref> [MAMSA94] </ref>. The Transis [ADKM92b, MADK94] and Totem [AMMS + 93] systems implement partitionable membership and ordering services of this framework, and also support EVS. 3 The COReL Algorithm We present the COReL (Consistent Object Replication Layer) algorithm for reliable multicast and total ordering of messages.
Reference: [MHS89] <author> Tim Mann, Andy Hisgen, and Garret Swart. </author> <title> An Algorithm for Data Replication. </title> <type> Technical Report 46, </type> <institution> DEC Systems Research Center, </institution> <month> June </month> <year> 1989. </year>
Reference-contexts: The algorithm uses a rotating coordinator scheme among all the processors, and does not focus only on members of the current membership. When a majority is connected, the worst-case latency until ordering a single message can be O (n) communication rounds. The total ordering protocols in <ref> [MMSA93, MHS89, ADMSM94] </ref> also overcome network partitions. Total [MMSA93] incurs a high overhead: the maximum number of communication rounds required is not bounded, while our algorithm requires two communication rounds to order a message if no failures occur during these rounds. <p> The replication algorithm suggested 2 By "no failures occur" we implicitly mean that the underlying membership service does not report of failures. in <ref> [MHS89] </ref> is centralized, and thus highly increases the load on one server, while our protocol is decentralized and symmetric.
Reference: [MMSA93] <author> L. E. Moser, P. M. Melliar-Smith, and V. Agrawala. </author> <title> Asynchronous Fault-Tolerant Total Ordering Algorithms. </title> <journal> SIAM Journal of Computing, </journal> <volume> 22(4) </volume> <pages> 727-750, </pages> <month> August </month> <year> 1993. </year>
Reference-contexts: The algorithm uses a rotating coordinator scheme among all the processors, and does not focus only on members of the current membership. When a majority is connected, the worst-case latency until ordering a single message can be O (n) communication rounds. The total ordering protocols in <ref> [MMSA93, MHS89, ADMSM94] </ref> also overcome network partitions. Total [MMSA93] incurs a high overhead: the maximum number of communication rounds required is not bounded, while our algorithm requires two communication rounds to order a message if no failures occur during these rounds. <p> When a majority is connected, the worst-case latency until ordering a single message can be O (n) communication rounds. The total ordering protocols in [MMSA93, MHS89, ADMSM94] also overcome network partitions. Total <ref> [MMSA93] </ref> incurs a high overhead: the maximum number of communication rounds required is not bounded, while our algorithm requires two communication rounds to order a message if no failures occur during these rounds.
Reference: [PBS89] <author> L. L. Peterson, N. C. Buchholz, and R. D. Schlichting. </author> <title> Preserving and Using Context Information in Interprocess Communication. </title> <journal> ACM Trans. Comput. Syst., </journal> <volume> 7(3) </volume> <pages> 217-246, </pages> <month> August 89. </month>
Reference-contexts: Group communication mechanisms that use hardware broadcast lead to simpler and more efficient solutions for replication than the traditional point-to-point mechanisms. Some of the leading systems for group communication today are: ISIS [BCG91, BSS91] and its new generation HORUS [VRCGS92], Transis [ADKM92b, MADK94], Totem [AMMS + 93], Psync <ref> [PBS89] </ref>, Newtop [EMS95] and the distributed operating system AMOEBA [KTHB89]. To increase availability, most of the group multicast algorithms mentioned above detect failures and extract faulty members from the membership. When processors reconnect, these algorithms do not recover the states of reconnected processors.
Reference: [Sch90] <author> F. B. Schneider. </author> <title> Implementing Fault Tolerant Services Using The State Machine Approach: </title>
Reference-contexts: 1 Introduction Consistent order is a powerful paradigm for the design of fault tolerant applications, e.g. consistent replication <ref> [Sch90, Kei94] </ref>. We present an efficient algorithm for consistent message ordering in the face of network partitions and site failures. The network may partition into several components 1 , and remerge. The algorithm is most adequate for dynamic networks where failures are transient.
References-found: 24

