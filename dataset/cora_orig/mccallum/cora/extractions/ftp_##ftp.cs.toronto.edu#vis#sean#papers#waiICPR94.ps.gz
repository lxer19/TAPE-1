URL: ftp://ftp.cs.toronto.edu/vis/sean/papers/waiICPR94.ps.gz
Refering-URL: http://www.cs.toronto.edu/vis/publications/abstracts/waiICPR94.html
Root-URL: 
Email: email: tsotsos@vis.torotnto.edu  
Title: Directing Attention to Onset and Offset of Image Events for Eye-Head Movement Control  
Author: Winky Y. K. Wai and John K. Tsotsos 
Address: Toronto, Ontario, Canada M5S 1A4,  
Affiliation: Department of Computer Science, University of Toronto  
Abstract: This paper proposes a model that investigates a new avenue for attention control based on dynamic scenes. We have derived a computational model to detect abrupt changes and have examined how the most prominent change can be determined. With such a model, we explore the possibility of an attentional mechanism, in part guided by abrupt changes, for gaze control. The computational model is derived from the difference of Gaussian (DOG) model and it examines the change in the response of the DOG operator over time to determine if changes have occurred. On and off-DOG operators are used to detect "on" and "off" events respectively. The response of these operators is examined over various temporal window sizes so that changes at different rates can be found. The most salient "on" and "off" events are determined from the corresponding winner-take-all (WTA) network. The model has been tested with image sequences which have changes caused by brightness or motion and the results are satisfactory. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Culhane, S. M., </author> <title> "Implementation of an Attentional Prototype for Early Vision", </title> <type> Master's Thesis, </type> <institution> University of Toronto, </institution> <year> 1992. </year>
Reference-contexts: A winner is determined from each WTA network using the updating rule described by Tsotsos [10]. This WTA updating rule is an enhanced version from the Koch and Ullman scheme [5], and has been proven to converge quickly <ref> [1] </ref>, [6], [9]. But before the WTA processes are initiated, the response from different operator sizes are normalized. A normalization process is necessary because an operator of a larger scale may have a greater response over one with a smaller scale simply because of an increase in area. <p> Empirically, setting = 10 and fi = 1:3 (as suggested by Culhane <ref> [1] </ref>) seems to yield satisfactory results for our experiments. 5 Extending the temporal window When the temporal window is expended to a size T (T &gt; 2), our model would be looking for changes that occur at different rates.
Reference: [2] <author> Culhane, S. M. and Tsotsos, J. K., </author> <title> "An Attentional Prototype for Early Vision", </title> <booktitle> ECCV, p. </booktitle> <pages> 551-560, </pages> <year> 1992. </year>
Reference-contexts: Therefore, a mechanism has to be found to take a balance between the difference in size and response. The normalization function we use in our model is the one suggested by Culhane and Tsotsos <ref> [2] </ref>. Culhane and Tsotsos originally suggest a normalization function to select receptive fields (RF) among different sizes. Their normalization function is a function of the area of the RF, which is measured by the number of pixels in the RF.
Reference: [3] <author> Fleet, D. J., </author> <title> "The Early Processing of Spatio-Temporal Visual Information", </title> <type> Master's Thesis, </type> <institution> University of Toronto, </institution> <year> 1984. </year>
Reference-contexts: These Gaussian functions are weighted by integrated sensitivities ff c (for the centre) and ff s (for the surround). A detailed analysis of how the shape of the DOG operator is affected by varying the ratio c s and ff c ff s is given in <ref> [3] </ref>. <p> The algorithm to detect "on" and "off" events for a general temporal window size (T 2) is given in Algorithm 1 (Figure 1). 6 Determining parameter values The main parameters for the DOG operator are c , s , ff c and ff s . As Fleet <ref> [3] </ref> pointed out, it is sufficient to consider the ratio s c and ff c ff s . By keeping the ratio s c fixed and varying c (when s &gt; c ), the peak spatial frequency that the operator can detect is shifted.
Reference: [4] <author> Gershon, R., </author> <title> "The Use of Colour in Computational Vision", </title> <type> PhD Thesis, </type> <institution> University of Toronto, </institution> <year> 1987. </year>
Reference-contexts: Second, we assume that all kinds of changes, including changes caused by shadows, are equally worthy of attention as other changes with respect to objects. If the effect of shadow is undesirable, some colour processing should be applied to filter out shadows <ref> [4] </ref>. Thirdly, the correspondence problem is not being addressed by the model. There is no mechanism to identify the changes on the same object at different times. Fourthly, there is no top-down component in our model in its most original form.
Reference: [5] <author> Koch, C. and Ullman, S., </author> <title> "Shifts in Selective Visual Attention: Towards the Underlying Neural Circuitry", </title> <booktitle> Human Neurobi ology, </booktitle> <volume> Vol. 4, </volume> <pages> p. 219-277, </pages> <year> 1985. </year>
Reference-contexts: Units in each WTA network represent the response from all locations and spatial scales of the corresponding event. A winner is determined from each WTA network using the updating rule described by Tsotsos [10]. This WTA updating rule is an enhanced version from the Koch and Ullman scheme <ref> [5] </ref>, and has been proven to converge quickly [1], [6], [9]. But before the WTA processes are initiated, the response from different operator sizes are normalized.
Reference: [6] <author> Lai, Y. Z., </author> <title> "A Prototype for Finding Motion Patterns in Opti cal Flow", </title> <type> Master's Thesis, </type> <institution> University of Toronto, </institution> <year> 1992. </year>
Reference-contexts: A winner is determined from each WTA network using the updating rule described by Tsotsos [10]. This WTA updating rule is an enhanced version from the Koch and Ullman scheme [5], and has been proven to converge quickly [1], <ref> [6] </ref>, [9]. But before the WTA processes are initiated, the response from different operator sizes are normalized. A normalization process is necessary because an operator of a larger scale may have a greater response over one with a smaller scale simply because of an increase in area.
Reference: [7] <author> Posner, M. I. and Cohen, Y., </author> <title> "Components of Attention", in Attention and Performance X, </title> <booktitle> p. </booktitle> <pages> 531-556, </pages> <year> 1984. </year>
Reference-contexts: Furthermore, when the attention model is directing the motion of a robot head, we have to acquire a new set of images every time the head has moved. One aspect for an attention model that we have not addressed is the issue of inhibition of return <ref> [7] </ref>. It was found from psychological experiments that there is a temporary inhibition after attention shifts away from a position. However, there have been no experiments to study how receptive fields are inhibited when attention is guided by abrupt changes.
Reference: [8] <author> Tsotsos, J. K., </author> <title> "Analyzing Vision at the Complexity Level", </title> <journal> Behavioural and Brain Science, </journal> <volume> No. 13, </volume> <pages> p. 423-469, </pages> <year> 1990. </year>
Reference-contexts: 1 Introduction As solving computer vision problems always involve a huge amount of computation, an attentional mechanism is necessary in any computer vision systems that hope to have real-time performance <ref> [8] </ref>. Recently, Yantis and several coauthors revealed from some psychological experiments that the abrupt appearance of an object in the visual field draws visual attention, e.g., [11], [12], [13], [14], [15].
Reference: [9] <author> Tsotsos, J. K., </author> <title> "Localizing Stimuli in a Sensory Field Using an Inhibitory Attentional Beam", </title> <type> Technical Report RBCV-TR-91-37, </type> <institution> University of Toronto, </institution> <year> 1991. </year>
Reference-contexts: A winner is determined from each WTA network using the updating rule described by Tsotsos [10]. This WTA updating rule is an enhanced version from the Koch and Ullman scheme [5], and has been proven to converge quickly [1], [6], <ref> [9] </ref>. But before the WTA processes are initiated, the response from different operator sizes are normalized. A normalization process is necessary because an operator of a larger scale may have a greater response over one with a smaller scale simply because of an increase in area. <p> The output from Algorithm 1 is treated as a saliency measure for the input level of the processing hierarchy in Tsotsos' inhibitory attentional beam model <ref> [9] </ref>. The most conspicuous "on" and "off" events will compete with other attention attracting image events (e.g., events that deserve attention according to some task-driven guidance) and a higher order decision process is assumed to decide which event deserves attention.
Reference: [10] <author> Tsotsos, J. K., </author> <title> "An Inhibitory Beam for Attentional Selection", in Spatial Vision for Humans and Robots, </title> <publisher> Cambridge Univer sity Press, </publisher> <year> 1993. </year>
Reference-contexts: Units in each WTA network represent the response from all locations and spatial scales of the corresponding event. A winner is determined from each WTA network using the updating rule described by Tsotsos <ref> [10] </ref>. This WTA updating rule is an enhanced version from the Koch and Ullman scheme [5], and has been proven to converge quickly [1], [6], [9]. But before the WTA processes are initiated, the response from different operator sizes are normalized.
Reference: [11] <author> Yantis, S. and Hillstrom, A. P., </author> <title> "Stimulus-Driven Attentional Capture: Evidence From Equiluminant Visual Objects", Journal of Experimental Psychology: Human Perception Performance, </title> <publisher> in press. </publisher>
Reference-contexts: Recently, Yantis and several coauthors revealed from some psychological experiments that the abrupt appearance of an object in the visual field draws visual attention, e.g., <ref> [11] </ref>, [12], [13], [14], [15]. Inspired by this novel idea of attentional capture, we derive a computational model to find abrupt changes from a sequence of images.
Reference: [12] <author> Yantis, S. and Johnson, D. N., </author> <title> "Mechanisms of Attention Priority ", Journal of Experimental Psychology: </title> <journal> Human Per ception and Performance, </journal> <volume> Vol. 16, No. 4, </volume> <pages> p. 812-825, </pages> <year> 1990. </year>
Reference-contexts: Recently, Yantis and several coauthors revealed from some psychological experiments that the abrupt appearance of an object in the visual field draws visual attention, e.g., [11], <ref> [12] </ref>, [13], [14], [15]. Inspired by this novel idea of attentional capture, we derive a computational model to find abrupt changes from a sequence of images.
Reference: [13] <author> Yantis, S. and Jones, E., </author> <title> "Mechanisms of Attention Selection: Temporally Modulated Priority Tags", </title> <journal> Perception and Psychophysics, </journal> <volume> 50(2), p.166-178, </volume> <year> 1991. </year>
Reference-contexts: Recently, Yantis and several coauthors revealed from some psychological experiments that the abrupt appearance of an object in the visual field draws visual attention, e.g., [11], [12], <ref> [13] </ref>, [14], [15]. Inspired by this novel idea of attentional capture, we derive a computational model to find abrupt changes from a sequence of images.
Reference: [14] <author> Yantis, S. and Jonides, J., </author> <title> "Abrupt Visual Onsets and Selective Attention: Evidence from Visual Search ", Journal of Ex perimental Psychology: </title> <journal> Human Perception and Performance, </journal> <volume> Vol. 10, No. 5, </volume> <pages> p. 601-621, </pages> <year> 1984. </year>
Reference-contexts: Recently, Yantis and several coauthors revealed from some psychological experiments that the abrupt appearance of an object in the visual field draws visual attention, e.g., [11], [12], [13], <ref> [14] </ref>, [15]. Inspired by this novel idea of attentional capture, we derive a computational model to find abrupt changes from a sequence of images.
Reference: [15] <author> Yantis, S. and Jonides, J., </author> <title> "Abrupt Visual Onsets and Selective Attention: Voluntary Versus Automatic Allocation", </title> <journal> Journal of Experimental Psychology: Human Perception and Perfor mance, </journal> <volume> Vol. 16, No. 1, </volume> <pages> p. 121-134, </pages> <year> 1990. </year>
Reference-contexts: Recently, Yantis and several coauthors revealed from some psychological experiments that the abrupt appearance of an object in the visual field draws visual attention, e.g., [11], [12], [13], [14], <ref> [15] </ref>. Inspired by this novel idea of attentional capture, we derive a computational model to find abrupt changes from a sequence of images.
References-found: 15

