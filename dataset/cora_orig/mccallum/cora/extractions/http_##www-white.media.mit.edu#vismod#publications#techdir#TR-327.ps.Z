URL: http://www-white.media.mit.edu/vismod/publications/techdir/TR-327.ps.Z
Refering-URL: http://www.cs.gatech.edu/~irfan/publications/aaaifs95.html
Root-URL: 
Email: brand@media.mit.edu irfan@media.mit.edu  
Title: Causal Analysis for Visual Gesture Understanding  
Author: Matthew Brand Irfan Essa 
Address: Cambridge, MA 02139, U.S.A. Cambridge, MA 02139, U.S.A.  
Affiliation: Learning and Common Sense Group Perceptual Computing Group MIT Media Laboratory MIT Media Laboratory  
Abstract: M.I.T Media Laboratory Perceptual Computing Section Technical Report No. 327 To Appear in the Proceedings of AAAI Fall '95 Symposium on Computational Models for Integrating Language and Vision Abstract We are exploring the use of high-level knowledge about bodies in the visual understanding of gesture. Our hypothesis is that many gestures are metaphorically derived from the motor programs of our everyday interactions with objects and people. For example, many dismissive gestures look like an imaginary object is being brushed or tossed away. At the discourse level, this implicit mass represents a referent in the conversation; at the scene-formation level, the dismissive gesture obeys many of the kinematic and dynamic constraints that would shape an actual tossing. Thus this metaphor provides us with constraints for both discourse annotationand visual processing. In this paper we present some preliminary results interpreting complex gesture sequences in video. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> N. I. Badler and S. W. Smoliar. </author> <title> Digital representation of human movement. </title> <journal> ACM Computing Surveys, </journal> <volume> 11 </volume> <pages> 19-38, </pages> <month> March </month> <year> 1979. </year>
Reference-contexts: Similar attempts at understanding body movements in terms of model-based constraint propagation [12], and coding on the basis of joint-angles <ref> [4, 1] </ref> provide additional insight into the validity and a need for a higher level representation. 1.3 Gestures as metaphors of basic motor plans We are exploring the use of high-level knowledge about bodies in the visual understanding of gesture.
Reference: [2] <author> A. F. Bobick and A. D. Wilson. </author> <title> A state-based technique for the summarization and recognition of gesture. </title> <booktitle> In Proc. Fifth International Conference on Computer Vision, </booktitle> <pages> pages 382-388, </pages> <year> 1995. </year>
Reference-contexts: Gestures as communicative behavior have been studied intensely by linguists in recent years (e.g., see [11, 5]) but little is known about how they are perceived or interpreted. 1.1 Gesture recognition There is been a growing literature in body tracking and gesture recognition in computer vision (e.g., <ref> [7, 10, 15, 8, 13, 2] </ref>). Most of these efforts apply pattern recognition technologies to reduced-dimension codings of the image stream.
Reference: [3] <author> Matthew Brand, Lawrence Birnbaum, and Paul Cooper. </author> <title> Sensible scenes: Visual understanding of complex structures through causal analysis. </title> <booktitle> In Proc. National Conf. Artificial Intelligence, </booktitle> <year> 1993. </year>
Reference-contexts: This output will be useful for video editing and in virtual manipulation tasks, e.g. virtual CAD. In this paper we present some preliminary results interpreting complex gesture sequences in video. 2 Causal analysis and high-level vision The approach used here derives from work in scene analysis done by <ref> [3, 6] </ref>. The two central themes of this approach are explanation-mediated vision and causal analysis. In explanation-mediated vision, a high-level reasoning process directs and disambiguates low-level visual processes in the course of trying to assemble visual clues into a sensible explanation of what is going on in the scene. <p> In the case of co-articulations, filter drop-outs, and visual tracking mistakes, we will need this knowledge to boost and suppress filters and reconstruct lost data, much in the way that reasoning was used to predict image structures and tune visual routines in <ref> [3] </ref>. In another avenue of exploration, we are looking at the use of knowledge to actually construct filters on the fly, employing the same reasoning that we demonstrated for the lifting filter.
Reference: [4] <author> L. Campbell and A. Bobick. </author> <title> Recognition of human body motion using phase space constraints. </title> <booktitle> In Proceedings of IEEE International Conference on Computer Vision. IEEE Computer Society, </booktitle> <month> June </month> <year> 1995. </year> <note> To Appear. </note>
Reference-contexts: Similar attempts at understanding body movements in terms of model-based constraint propagation [12], and coding on the basis of joint-angles <ref> [4, 1] </ref> provide additional insight into the validity and a need for a higher level representation. 1.3 Gestures as metaphors of basic motor plans We are exploring the use of high-level knowledge about bodies in the visual understanding of gesture.
Reference: [5] <editor> J. Cassell and D. MacNeill. Gesture and ground. In K. Hall, J-P. Keonig, M. Meachman, S. Reinman, and L. Sutton, editors, </editor> <booktitle> Proc. 16th Annual Meeting of the Berkeley Linguistics Society, </booktitle> <pages> pages 57-68, </pages> <year> 1990. </year>
Reference-contexts: In the foreseeable future, computers will called on to obey commands, mediate teleconferences, and process videos in which gestures convey significant content. Gestures as communicative behavior have been studied intensely by linguists in recent years (e.g., see <ref> [11, 5] </ref>) but little is known about how they are perceived or interpreted. 1.1 Gesture recognition There is been a growing literature in body tracking and gesture recognition in computer vision (e.g., [7, 10, 15, 8, 13, 2]).
Reference: [6] <author> Paul Cooper, Lawrence Birnbaum, and Matthew Brand. </author> <title> Causal scene understanding. </title> <booktitle> Image Understanding, </booktitle> <year> 1995. </year> <note> In press. </note>
Reference-contexts: This output will be useful for video editing and in virtual manipulation tasks, e.g. virtual CAD. In this paper we present some preliminary results interpreting complex gesture sequences in video. 2 Causal analysis and high-level vision The approach used here derives from work in scene analysis done by <ref> [3, 6] </ref>. The two central themes of this approach are explanation-mediated vision and causal analysis. In explanation-mediated vision, a high-level reasoning process directs and disambiguates low-level visual processes in the course of trying to assemble visual clues into a sensible explanation of what is going on in the scene.
Reference: [7] <author> Trevor Darrell and Alex Pentland. </author> <title> Space-time gestures. </title> <booktitle> In Proc. Conf. on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 335-340, </pages> <year> 1993. </year>
Reference-contexts: Gestures as communicative behavior have been studied intensely by linguists in recent years (e.g., see [11, 5]) but little is known about how they are perceived or interpreted. 1.1 Gesture recognition There is been a growing literature in body tracking and gesture recognition in computer vision (e.g., <ref> [7, 10, 15, 8, 13, 2] </ref>). Most of these efforts apply pattern recognition technologies to reduced-dimension codings of the image stream.
Reference: [8] <author> J. W. Davis and M. Shah. </author> <title> Gesture recognition. </title> <booktitle> In Proc. European Conf. Computer Vision, </booktitle> <pages> pages 331-340, </pages> <address> Stockholm, Sweden, </address> <year> 1994. </year>
Reference-contexts: Gestures as communicative behavior have been studied intensely by linguists in recent years (e.g., see [11, 5]) but little is known about how they are perceived or interpreted. 1.1 Gesture recognition There is been a growing literature in body tracking and gesture recognition in computer vision (e.g., <ref> [7, 10, 15, 8, 13, 2] </ref>). Most of these efforts apply pattern recognition technologies to reduced-dimension codings of the image stream.
Reference: [9] <author> Irfan A. Essa and Alex Pentland. </author> <title> A vision system for observing and extracting facial action parameters. </title> <booktitle> In Proc. Conf. Computer Vision and Pattern Recognition, </booktitle> <pages> pages 76-83, </pages> <year> 1994. </year>
Reference-contexts: At some point, a high-level system of meaning must be applied to the low-level data, both to resolve ambiguities in the input and to produce a useful interpretation of the data. In between, there are also mid-level constraints that are very useful. For example, the work of Essa <ref> [9] </ref> is a promising step in the direction of having a theory of gesture that has computational value: in order to track facial expressions, the dimension is reduced through a causal reconstruction of how the scene was produced, specifically, face images are coded in terms of the muscle contractions needed to
Reference: [10] <author> Ioannis Kakadiaris, Dimitri Metaxas, and Ruzena Ba-jcsy. </author> <title> Active part-decomposition, shape, and motion estimation of articulated objects: A physics-based approach. </title> <booktitle> In Proc. Conf. on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 980-984, </pages> <year> 1994. </year>
Reference-contexts: Gestures as communicative behavior have been studied intensely by linguists in recent years (e.g., see [11, 5]) but little is known about how they are perceived or interpreted. 1.1 Gesture recognition There is been a growing literature in body tracking and gesture recognition in computer vision (e.g., <ref> [7, 10, 15, 8, 13, 2] </ref>). Most of these efforts apply pattern recognition technologies to reduced-dimension codings of the image stream.
Reference: [11] <author> David MacNeill. </author> <title> Iconic relationships between language and motor action revisited. In M.E. Landsberg, editor, Syntactic iconicity and freezes: The human dimension. </title> <publisher> Mouton de Gruyter, </publisher> <address> Berlin, </address> <year> 1993. </year>
Reference-contexts: In the foreseeable future, computers will called on to obey commands, mediate teleconferences, and process videos in which gestures convey significant content. Gestures as communicative behavior have been studied intensely by linguists in recent years (e.g., see <ref> [11, 5] </ref>) but little is known about how they are perceived or interpreted. 1.1 Gesture recognition There is been a growing literature in body tracking and gesture recognition in computer vision (e.g., [7, 10, 15, 8, 13, 2]).
Reference: [12] <author> J. O'Rourke and N. I. Badler. </author> <title> Model-based image analysis of human motion using constraint propagation. </title> <journal> IEEE Trans. Pattern Analysis and Machine Intelligence, </journal> <volume> PAMI-2:522-536, </volume> <year> 1980. </year>
Reference-contexts: Similar attempts at understanding body movements in terms of model-based constraint propagation <ref> [12] </ref>, and coding on the basis of joint-angles [4, 1] provide additional insight into the validity and a need for a higher level representation. 1.3 Gestures as metaphors of basic motor plans We are exploring the use of high-level knowledge about bodies in the visual understanding of gesture.
Reference: [13] <author> J. M. Rehg and T. Kanade. </author> <title> Visual tracking of high DOF articulated structures: an application to human hand tracking. </title> <booktitle> In Proc. European Conf. Computer Vision, </booktitle> <volume> volume 2, </volume> <pages> pages 35-46, </pages> <address> Stockholm, Sweden, </address> <year> 1994. </year>
Reference-contexts: Gestures as communicative behavior have been studied intensely by linguists in recent years (e.g., see [11, 5]) but little is known about how they are perceived or interpreted. 1.1 Gesture recognition There is been a growing literature in body tracking and gesture recognition in computer vision (e.g., <ref> [7, 10, 15, 8, 13, 2] </ref>). Most of these efforts apply pattern recognition technologies to reduced-dimension codings of the image stream.
Reference: [14] <author> Christopher R. Wren, Ali Azarbayejani, Trevor Dar-rell, Michael Johnson, Kenneth Russel, Thad Starner, and Alex Pentland. </author> <title> Hierarchical classification for human body tracking. In Integration Issues in Large Commercial Media Delivery Systems. </title> <booktitle> SPIE, </booktitle> <month> October </month> <year> 1995. </year> <note> to appear. </note>
Reference-contexts: At this point we identify causally significant arm motions by applying the gesture filters to the reconstructed motion data. We are working on a frame-subtraction system to identify and track shoulders and elbows using contours, and to track hands using color <ref> [14] </ref>. In the sequence in figure 1, a subject starts with hands on hips, makes an opening shrug, and then follows with a series of small patting gestures. In the audio track the subject expresses uncertainty and then talks about keeping things under control.
Reference: [15] <author> J. Yamato, J. Ohya, and K. Ishii. </author> <title> Recognizing human action in time-sequential images using a hidden markov model. </title> <booktitle> In Proc. Conf. Computer Vision and Pattern Recognition, </booktitle> <pages> pages 379-385, </pages> <year> 1992. </year> <month> 6 </month>
Reference-contexts: Gestures as communicative behavior have been studied intensely by linguists in recent years (e.g., see [11, 5]) but little is known about how they are perceived or interpreted. 1.1 Gesture recognition There is been a growing literature in body tracking and gesture recognition in computer vision (e.g., <ref> [7, 10, 15, 8, 13, 2] </ref>). Most of these efforts apply pattern recognition technologies to reduced-dimension codings of the image stream.
References-found: 15

