URL: http://www.csc.ncsu.edu/faculty/WStewart/Publications/PS_files/Rairo.ps
Refering-URL: http://www.csc.ncsu.edu/faculty/WStewart/Publications/Publications.html
Root-URL: http://www.csc.ncsu.edu
Email: E-mail: Paulo.Fernandes@imag.fr, Brigitte.Plateau@imag.fr, billy@csc.ncsu.edu  
Title: Optimizing Tensor Product Computations in Stochastic Automata Networks  
Author: Paulo Fernandes Brigitte Plateau and William J. Stewart 
Address: 38041 Grenoble cedex, France.  Raleigh, N.C. 27695-8206, USA.  
Affiliation: IMAG-LMC, 100 rue des Mathematiques,  Department of Computer Science, North Carolina State University,  
Abstract: In this paper we consider some numerical issues in computing solutions to networks of stochastic automata (SAN). In particular our concern is with keeping the amount of computation per iteration to a minimum, since iterative methods appear to be the most effective in determining numerical solutions. In a previous paper we presented complexity results concerning the vector-descriptor multiplication phase of the analysis. In this paper our concern is with optimizations related to the implementation of this algorithm. We also consider the possible benefits of grouping automata in a SAN with many small automata, to create an equivalent SAN having a smaller number of larger automata. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> K. </author> <month> Atif. </month> <institution> Modelisation du Parallelisme et de la Synchronisation. These de Docteur de l'Institut National Polytechnique de Grenoble, </institution> <month> 24 September </month> <year> 1992, </year> <institution> Grenoble, France. </institution>
Reference-contexts: In SANs, it is possible to make use of symmetries as well as lumping and various superpositioning of the automata to reduce the computational burden, <ref> [1, 4, 17] </ref>. Furthermore, in [9], structural properties of the Markov chain graph (specificially the occurrence of cycles) are used to compute steady state solutions. For very large problems, it is well-known that only iterative methods are viable.
Reference: [2] <author> F. Baccelli, A. Jean-Marie and I. Mitrani, </author> <title> Editors, Quantitative Methods in Parallel Systems, Part I: Stochastic Process Algebras; Basic Research Series, </title> <publisher> Springer, </publisher> <year> 1995. </year> <note> 26 Paulo Fernandes, </note> <author> Brigitte Plateau and William J. </author> <note> Stewart </note>
Reference: [3] <author> P. Buchholz. </author> <title> Equivalence Relations for Stochastic Automata Networks. Computations with Markov Chains; Proceedings of the 2nd International Meeting on the Numerical Solution of Markov Chains, </title> <editor> W.J. Stewart, Ed., </editor> <publisher> Kluwer International Publishers, </publisher> <address> Boston, </address> <year> 1995. </year>
Reference: [4] <author> P. Buchholz. </author> <title> Hierarchical Markovian Models Symmetries and Aggregation; Modelling Techniques and Tools for Computer Performance Evaluation, </title> <editor> Ed. R. Pooley, J.Hillston, </editor> <publisher> Edinburgh, Scotland, </publisher> <pages> pp. 234-246, </pages> <year> 1992. </year>
Reference-contexts: In SANs, it is possible to make use of symmetries as well as lumping and various superpositioning of the automata to reduce the computational burden, <ref> [1, 4, 17] </ref>. Furthermore, in [9], structural properties of the Markov chain graph (specificially the occurrence of cycles) are used to compute steady state solutions. For very large problems, it is well-known that only iterative methods are viable.
Reference: [5] <author> M. Davio. </author> <title> Kronecker Products and Shu*e Algebra. </title> <journal> IEEE Trans. Comput, </journal> <volume> Vol. C-30, No. 2, </volume> <pages> pp. 1099-1109, </pages> <year> 1981. </year>
Reference-contexts: The implication is that a considerable saving in memory is effected by storing the matrix in this fashion <ref> [5, 15] </ref>. Other modelling approaches such as Petri Nets [6] and Stochastic Process Algebras [10, 11] can benefit from this tensor representation of the transition matrix. <p> Automata state evaluation In order to evaluate the functions, the algorithm must compute the state of each individual automata using a global index in the global state vector. This function, "Automata-state", is a simple base decomposition as shown in <ref> [5] </ref> and can be implemented as such, using integer division and remainder (as in part 3 of Figure 3).
Reference: [6] <author> S. Donatelli. </author> <title> Superposed Stochastic Automata: A Class of Stochastic Petri Nets with Parallel Solution and Distributed State Space. </title> <journal> Performance Evaluation, </journal> <volume> Vol. 18, </volume> <pages> pp. 21-36, </pages> <year> 1993. </year>
Reference-contexts: The implication is that a considerable saving in memory is effected by storing the matrix in this fashion [5, 15]. Other modelling approaches such as Petri Nets <ref> [6] </ref> and Stochastic Process Algebras [10, 11] can benefit from this tensor representation of the transition matrix. But as far as we know, these approaches do not exploit the functional extension of tensor algebra that 1 2 Paulo Fernandes, Brigitte Plateau and William J. Stewart is extensively used in SANs.
Reference: [7] <author> P. Fernandes, B. Plateau and W.J. Stewart. </author> <title> Numerical Issues for Stochastic Automata Networks. Proceeding of the Fourth Process Algebras and Performance Modelling Workshop. Edited by Marina Ribaudo, </title> <note> Published by CLUT, </note> <institution> Torino, </institution> <month> July </month> <year> 1996. </year>
Reference-contexts: Additionally, we provided an algorithm that implements the multiplication procedure. The objective of this paper is to analyze the cost of implementing this new algorithm and to compare it to more usual sparse methods. In this way we extend the results reported in <ref> [7] </ref>. We show in these experiments, that the actual performance of the implementation is model dependant.
Reference: [8] <author> P. Fernandes, B. Plateau and W.J. Stewart. </author> <title> Efficient Vector-Descriptor Multiplications in Stochastic Automata Networks. </title> <note> INRIA Report # 2935. Anonymous ftp ftp ftp.inria.fr/INRIA/Publication/RR. </note>
Reference-contexts: In this paper we concentrate on procedures that allow us to keep the amount of computation per iteration, which is basically the cost of the matrix-vector multiplication, to a minimum. In a previous paper, <ref> [8] </ref>, we proved a theorem concerning the complexity of a matrix-vector multiplication when the matrix is stored as a compact SAN descriptor and has functional rates. This algorithm is an improvement of the one in [15] when functional rates must be handled. <p> Finally, we would like to draw our readers attention to the sparsity of the matrices presented above. 3 Algorithm Analysis 3.1 The Complexity Result and Algorithm We present without proof, the theorem concerning vector-descriptor multiplication and its accompanying algorithm, <ref> [8] </ref>. <p> Note that there may be more than one legal processing order for a term. Remark 2: Now consider an arbitrary permutation oe (oe i denotes the initial index of the automaton in the i-th position after permutation). In <ref> [8] </ref>, we show how to perform this simple transformation where the position of each automata in a list describing the SAN is changed. 2 A set of dependencies can be modeled with a directed graph, where the nodes are the automata and there is an arc from i to j if <p> We only consider acyclic sets of dependencies here. It is shown in <ref> [8] </ref> that if there is a cyclic set of dependencies in a term, this term can be exactly decomposed into a number of non-cyclic terms. 10 Paulo Fernandes, Brigitte Plateau and William J. Stewart Let us call this order a positioning order.
Reference: [9] <author> J-M. Fourneau and F. Quessette. </author> <title> Graphs and Stochastic Automata Networks. Computations with Markov Chains; Proceedings of the 2nd International Meeting on the Numerical Solution of Markov Chains, </title> <editor> W.J. Stewart, Ed., </editor> <publisher> Kluwer International Publishers, </publisher> <address> Boston, </address> <year> 1995. </year>
Reference-contexts: In SANs, it is possible to make use of symmetries as well as lumping and various superpositioning of the automata to reduce the computational burden, [1, 4, 17]. Furthermore, in <ref> [9] </ref>, structural properties of the Markov chain graph (specificially the occurrence of cycles) are used to compute steady state solutions. For very large problems, it is well-known that only iterative methods are viable.
Reference: [10] <author> H. Hermanns and M. Rettelbach. </author> <title> Syntax, Semantics, Equivalences, and Axioms for MTIPP. </title> <booktitle> Proc. of the 2nd Workshop on Process Algebras and Performance Modelling, </booktitle> <editor> U. Herzog, M. Rettelbach, Editors, Arbeitsberichte, </editor> <volume> Band 27, No. 4, </volume> <pages> Erlangen, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: The implication is that a considerable saving in memory is effected by storing the matrix in this fashion [5, 15]. Other modelling approaches such as Petri Nets [6] and Stochastic Process Algebras <ref> [10, 11] </ref> can benefit from this tensor representation of the transition matrix. But as far as we know, these approaches do not exploit the functional extension of tensor algebra that 1 2 Paulo Fernandes, Brigitte Plateau and William J. Stewart is extensively used in SANs.
Reference: [11] <author> J. Hillston. </author> <title> Computational Markovian Modelling using a Process Algebra. Computations with Markov Chains; Proceedings of the 2nd International Meeting on the Numerical Solution of Markov Chains, </title> <editor> W.J. Stewart, Ed., </editor> <publisher> Kluwer International Publishers, </publisher> <address> Boston, </address> <year> 1995. </year>
Reference-contexts: The implication is that a considerable saving in memory is effected by storing the matrix in this fashion [5, 15]. Other modelling approaches such as Petri Nets [6] and Stochastic Process Algebras <ref> [10, 11] </ref> can benefit from this tensor representation of the transition matrix. But as far as we know, these approaches do not exploit the functional extension of tensor algebra that 1 2 Paulo Fernandes, Brigitte Plateau and William J. Stewart is extensively used in SANs.
Reference: [12] <author> P. Kemper. </author> <title> Closing the Gap between Classical and Tensor Based Iteration Techniques. Computations with Markov Chains; Proceedings of the 2nd International Meeting on the Numerical Solution of Markov Chains, </title> <editor> W.J. Stewart, Ed., </editor> <publisher> Kluwer International Publishers, </publisher> <address> Boston, </address> <year> 1995. </year>
Reference-contexts: The size of the state space generated may become so large that it effectively prohibits the computation of a solution. This is true whether the Markov chain results from a stochastic Petri net formalism, or from a straightforward Markov chain analyzer <ref> [18, 12] </ref>. In many instances, the SAN formalism is an appropriate choice.
Reference: [13] <author> B. </author> <title> Plateau. On the Stochastic Structure of Parallelism and Synchronization Models for Distributed Algorithms. </title> <booktitle> Proc. ACM Sigmetrics Conference on Measurement and Mod-elling of Computer Systems, </booktitle> <address> Austin, Texas, </address> <month> August </month> <year> 1985. </year>
Reference-contexts: A synchronizing transition may be either functional or constant. In any given automaton, transitions that are not synchronizing transitions are said to be local transitions. As a general rule, it is shown in <ref> [13] </ref>, that stochastic automata networks may always be treated by separating out the local transitions, handling these in the usual fashion by means of a tensor sum and then incorporating the sum of two additional tensor products per synchronizing event.
Reference: [14] <author> B. Plateau and K. Atif. </author> <title> Stochastic Automata Network for Modelling Parallel Systems. </title> <journal> IEEE Trans. on Software Engineering, </journal> <volume> Vol. 17, No. 10, </volume> <pages> pp. 1093-1108, </pages> <year> 1991. </year>
Reference: [15] <author> B. Plateau and J.M. Fourneau. </author> <title> A Methodology for Solving Markov Models of Parallel Systems. </title> <journal> Journal of Parallel and Distributed Computing. </journal> <volume> Vol. 12, </volume> <pages> pp. 370-387, </pages> <year> 1991. </year>
Reference-contexts: Parallel and distributed systems are often viewed as collections of components that operate more or less independently, requiring only infrequent interaction such as synchronizing their actions, or operating at different rates depending on the state of parts of the overall system. This is exactly the viewpoint adopted by SANs <ref> [15, 20] </ref>. The components are modelled as individual stochastic automata that interact with each other. Furthermore, the state space explosion problem associated with Markov chain models is mitigated by the fact that the state transition matrix is not stored, nor even generated. <p> The implication is that a considerable saving in memory is effected by storing the matrix in this fashion <ref> [5, 15] </ref>. Other modelling approaches such as Petri Nets [6] and Stochastic Process Algebras [10, 11] can benefit from this tensor representation of the transition matrix. <p> In a previous paper, [8], we proved a theorem concerning the complexity of a matrix-vector multiplication when the matrix is stored as a compact SAN descriptor and has functional rates. This algorithm is an improvement of the one in <ref> [15] </ref> when functional rates must be handled. Additionally, we provided an algorithm that implements the multiplication procedure. The objective of this paper is to analyze the cost of implementing this new algorithm and to compare it to more usual sparse methods.
Reference: [16] <author> B. Plateau, J.M. Fourneau and K.H. Lee. PEPS: </author> <title> A Package for Solving Complex Markov Models of Parallel Systems. </title> <editor> In R. Puigjaner, D. Potier, Eds., </editor> <title> Modelling Techniques and Tools for Computer Performance Evaluation, </title> <address> Spain, </address> <month> September </month> <year> 1988. </year>
Reference-contexts: The next section shows comparative experiments with these 3 methods. 16 Paulo Fernandes, Brigitte Plateau and William J. Stewart 4.1 Implementation Details The various versions of vector multiplication with a generalized tensor product have been implemented in the software package PEPS, version 3.0 <ref> [16] </ref>. This version of PEPS is written in C++. Experiments have lead us to introduce some basic optimizations in the algorithm skeleton presented above.
Reference: [17] <author> M. Siegle. </author> <title> On Efficient Markov Modelling. </title> <booktitle> In Proc. QMIPS Workshop on Stochastic Petri Nets, </booktitle> <pages> pp. 213-225, </pages> <address> Sophia-Antipolis, France, </address> <month> November </month> <year> 1992. </year>
Reference-contexts: In SANs, it is possible to make use of symmetries as well as lumping and various superpositioning of the automata to reduce the computational burden, <ref> [1, 4, 17] </ref>. Furthermore, in [9], structural properties of the Markov chain graph (specificially the occurrence of cycles) are used to compute steady state solutions. For very large problems, it is well-known that only iterative methods are viable.
Reference: [18] <author> W.J. Stewart. </author> <title> An Introduction to the Numerical Solution of Markov Chains, </title> <publisher> Princeton University Press, </publisher> <address> New Jersey, </address> <year> 1994. </year>
Reference-contexts: The size of the state space generated may become so large that it effectively prohibits the computation of a solution. This is true whether the Markov chain results from a stochastic Petri net formalism, or from a straightforward Markov chain analyzer <ref> [18, 12] </ref>. In many instances, the SAN formalism is an appropriate choice. <p> It is much better to generate the small number of states using a standard sparse matrix approach <ref> [18, 19] </ref>. It may be argued that the best approach (at least for this particular example) is to combine all the automata into just two groups, for this allows us to avoid the state space explosion problem with just a minimal increase in CPU time over a purely sparse approach.
Reference: [19] <author> W.J. Stewart. Marca: </author> <title> Markov Chain Analyzer. </title> <journal> IEEE Computer Repository No. </journal> <volume> R76 232, </volume> <year> 1976. </year> <note> Also IRISA Publication Interne No. 45, </note> <institution> Universite de Rennes, France. </institution>
Reference-contexts: For each model, 20 iterations of each vector-descriptor multiplications were performed, and the CPU time in seconds for 1 iteration and for each part is reported here and compared with the sparse method. The sparse method is inspired from the version in MARCA <ref> [19] </ref>. The models are . The mutex example with numerical values (i) = 1: 0 and (i) = 0: 4 for all i. The values of N and P vary and are reported in the column "Models". . <p> It is much better to generate the small number of states using a standard sparse matrix approach <ref> [18, 19] </ref>. It may be argued that the best approach (at least for this particular example) is to combine all the automata into just two groups, for this allows us to avoid the state space explosion problem with just a minimal increase in CPU time over a purely sparse approach.
Reference: [20] <author> W.J. Stewart, K. Atif and B. </author> <title> Plateau. The Numerical Solution of Stochastic Automata Networks. </title> <journal> European Journal of Operations Research, </journal> <volume> Vol. 86, No. 3, </volume> <pages> pp. 503-525, </pages> <year> 1995. </year>
Reference-contexts: Parallel and distributed systems are often viewed as collections of components that operate more or less independently, requiring only infrequent interaction such as synchronizing their actions, or operating at different rates depending on the state of parts of the overall system. This is exactly the viewpoint adopted by SANs <ref> [15, 20] </ref>. The components are modelled as individual stochastic automata that interact with each other. Furthermore, the state space explosion problem associated with Markov chain models is mitigated by the fact that the state transition matrix is not stored, nor even generated. <p> Furthermore, in [9], structural properties of the Markov chain graph (specificially the occurrence of cycles) are used to compute steady state solutions. For very large problems, it is well-known that only iterative methods are viable. We have shown in <ref> [20] </ref> that projection methods (Arnoldi, GMRES) with preconditioning can be used with a gain of performance compared to the standard power method.
Reference: [21] <author> P. Kemper. </author> <title> Numerical analysis of superposed GSPNs. </title> <journal> IEEE Trans. on Software Engineering, </journal> <volume> Vol. 22(9), </volume> <month> Sept. 96. </month>
Reference-contexts: But as far as we know, these approaches do not exploit the functional extension of tensor algebra that 1 2 Paulo Fernandes, Brigitte Plateau and William J. Stewart is extensively used in SANs. For Superposed Petri Nets, in <ref> [21] </ref>, it has been shown that the structured tensor representation can also be efficiently used to reduce the storage space of the iteration vectors. There are two overriding concerns in the application of any Markovian modelling methodology, viz., memory requirements and computation time. <p> This means that the descriptor is now in the form D + P N+E g;i=1 Q j . The vector-matrix multiplication includes a dot product with the diagonal entries. This requires additional memory, which may however be reduced using the techniques introduced in <ref> [21] </ref>. Automata state evaluation In order to evaluate the functions, the algorithm must compute the state of each individual automata using a global index in the global state vector.
References-found: 21

