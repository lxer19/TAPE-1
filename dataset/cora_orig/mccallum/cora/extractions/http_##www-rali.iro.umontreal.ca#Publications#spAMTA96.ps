URL: http://www-rali.iro.umontreal.ca/Publications/spAMTA96.ps
Refering-URL: http://www-rali.iro.umontreal.ca/Publications.en.html
Root-URL: http://www.iro.umontreal.ca
Email: simard@citi.doc.ca plamondo@citi.doc.ca  
Phone: tel: (514) 973 5806 tel: (514) 973 5811  
Title: BILINGUAL SENTENCE ALIGNMENT: BALANCING ROBUSTNESS AND ACCURACY  
Author: Michel Simard Pierre Plamondon 
Keyword: sentence alignment, bitext, machine aided translation  
Address: 1575 Chomedey Blvd.  CANADA H7V 2X2  
Affiliation: Centre for Information Technology Innovation (CITI)  Laval (Qubec)  
Abstract: Sentence alignment is the problem of making explicit the relations that exist between the sentences of two texts that are known to be mutual translations. Automatic sentence alignment methods typically face two kinds of difficulties. First, there is the question of robustness. In real life, discrepancies between the source-text and its translation are quite common: differences in layout, omissions, inversions, etc. Sentence alignment programs must be ready to deal with such phenomena. Then, there is the question of accuracy. Even when translations are clean, alignment is still not a trivial matter: some decisions are hard to make, even for humans. We report here on the current state of our ongoing efforts to produce a sentence alignment program that is both robust and accurate. The method that we propose relies on two new alignment engines, and combines the robustness of so-called character-based methods with the accuracy of stochastic translation models. Experimental results are presented, that demonstrate the methods effectiveness, and highlight where problems remain to be solved. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Brown, Peter F., Stephen A. Della Pietra, Vincent J. Della Pietra and Robert L. </author> <title> Mercer (1993), The Mathematics of Machine Translation: Parameter Estimation, </title> <booktitle> in Computational Linguistics, </booktitle> <volume> Vol. 19, No 2. </volume>
Reference-contexts: Following the ideas of Chen [4] and Dagan et al. [6], we have developed a method that could probably be referred to as heavy artillery in this context: it is based on a statistical lexical translation model, namely Brown et al.s Model 1 <ref> [1] </ref>. Essentially, the model consists in a set of parameters , that estimate the probability of observing word f in one text, given that word e appears in the other.
Reference: [2] <author> Brown, Peter, J. Lai and R. </author> <title> Mercer (1991), Aligning Sentences in Parallel Corpora, </title> <booktitle> in Proceedings of ACL-91. </booktitle>
Reference-contexts: This work is described in the following pages. Background As far as we know, interest in bitext correspondence began sometime in the mid-eighties, at which time independent efforts were being pursued concurrently in many places, most notably at Xerox PARC [11], IBMs Thomas J. Watson research centre <ref> [2] </ref>, AT&T Bell Laboratories in Murray Hill [8] and in Geneva, at ISSCO [3]. Interestingly, all these early efforts focussed on sentence alignments rather than bitext maps. The first communications on the subject were published in 1991. <p> The main difference between the two approaches was how length was measured: while Brown et al. <ref> [2] </ref> counted words, Gale and Church [8] counted characters. alignment; arrows denote one possible bitext map. 7. Le dveloppement est maintenant apprhend dans la multiplicit de ses dimensions.
Reference: [3] <author> Catizone, Roberta, Graham Russell and Susan Warwick (1989), </author> <title> Deriving Translation Data from Bilingual Texts, </title> <booktitle> in Proceedings of the First International Lexical Acquisition Workshop, </booktitle> <address> Detroit. </address>
Reference-contexts: Watson research centre [2], AT&T Bell Laboratories in Murray Hill [8] and in Geneva, at ISSCO <ref> [3] </ref>. Interestingly, all these early efforts focussed on sentence alignments rather than bitext maps. The first communications on the subject were published in 1991.
Reference: [4] <author> Chen, Stanley F. </author> <year> (1993), </year> <title> Aligning Sentences in Bilingual Corpora Using Lexical Information, </title> <booktitle> in Proceedings of ACL-93, </booktitle> <address> Columbus OH. </address>
Reference-contexts: So far, the most promising avenues in dealing with this problem make use of stochastic translation models. For example, to compute sentence alignments, Chen <ref> [4] </ref> replaces the simple length-based models of earlier methods by a more elaborate model that takes into account the words of the text. Dagan et al [6] use a similar model to obtain word-level mappings. <p> Following the ideas of Chen <ref> [4] </ref> and Dagan et al. [6], we have developed a method that could probably be referred to as heavy artillery in this context: it is based on a statistical lexical translation model, namely Brown et al.s Model 1 [1]. <p> Most alignment methods that make use of lexical information assume that this information is not available a priori: Kay and Rscheisen [11], Fung and McKeown [7], Chen <ref> [4] </ref>, Dagan et al. [6] all go to great lengths to infer the parameters of their models directly from the pair of texts to align. This is a very interesting approach, especially when dealing with many language pairs.
Reference: [5] <author> Church, Kenneth W. </author> <year> (1993), </year> <title> Char_align: A Program for Aligning Parallel Texts at the Character Level, </title> <booktitle> in Proceedings of ACL-93, </booktitle> <address> Columbus OH. </address>
Reference-contexts: In this sense, it is both exhaustive and exact: for each segment of text, it says something like the translation of this segment is exactly that segment. The same cannot be said of bitext maps. Some methods, such as those proposed by Church <ref> [5] </ref> or Fung and McKeown [7], produce approximate maps (i.e. not exact), that say something like The translation of the text around this point is somewhere around that point.
Reference: [6] <author> Dagan, Ido, Kenneth W. Church and William A. </author> <title> Gale (1993), Robust Bilingual Word Alignment for Machine Aided Translation, </title> <booktitle> in Proceedings of the Workshop on Very Large Corpora: </booktitle> <publisher> Academic and Industrial Perspectives. </publisher>
Reference-contexts: Some methods, such as those proposed by Church [5] or Fung and McKeown [7], produce approximate maps (i.e. not exact), that say something like The translation of the text around this point is somewhere around that point. Other methods, such as those proposed by Dagan et al. <ref> [6] </ref> or Melamed [12] produce maps that are exact (the translation of the object at position x is the object at position y) but not exhaustive. <p> For example, to compute sentence alignments, Chen [4] replaces the simple length-based models of earlier methods by a more elaborate model that takes into account the words of the text. Dagan et al <ref> [6] </ref> use a similar model to obtain word-level mappings. To this day, most research on the BCP has focussed on either one of these two problems (robustness and accuracy). This work is an attempt to tackle the two together. <p> Following the ideas of Chen [4] and Dagan et al. <ref> [6] </ref>, we have developed a method that could probably be referred to as heavy artillery in this context: it is based on a statistical lexical translation model, namely Brown et al.s Model 1 [1]. <p> Most alignment methods that make use of lexical information assume that this information is not available a priori: Kay and Rscheisen [11], Fung and McKeown [7], Chen [4], Dagan et al. <ref> [6] </ref> all go to great lengths to infer the parameters of their models directly from the pair of texts to align. This is a very interesting approach, especially when dealing with many language pairs.
Reference: [7] <author> Fung, Pascale and Kathleen McKeown (1994), </author> <title> Aligning Noisy Parallel Corpora Across Language Groups: Word Pair Feature by Dynamic Time Warping, </title> <booktitle> in Proceedings of AMTA-94. </booktitle>
Reference-contexts: In this sense, it is both exhaustive and exact: for each segment of text, it says something like the translation of this segment is exactly that segment. The same cannot be said of bitext maps. Some methods, such as those proposed by Church [5] or Fung and McKeown <ref> [7] </ref>, produce approximate maps (i.e. not exact), that say something like The translation of the text around this point is somewhere around that point. <p> Using a dynamic programming scheme similar to those used in previous sentence alignment programs, Salign finds the alignment with the maximum overall probability. Most alignment methods that make use of lexical information assume that this information is not available a priori: Kay and Rscheisen [11], Fung and McKeown <ref> [7] </ref>, Chen [4], Dagan et al. [6] all go to great lengths to infer the parameters of their models directly from the pair of texts to align. This is a very interesting approach, especially when dealing with many language pairs.
Reference: [8] <author> Gale, William A. and Kenneth W. </author> <title> Church (1991), A Program for Aligning Sentences in Bilingual Corpora, </title> <booktitle> in Proceedings of ACL-91. </booktitle>
Reference-contexts: Background As far as we know, interest in bitext correspondence began sometime in the mid-eighties, at which time independent efforts were being pursued concurrently in many places, most notably at Xerox PARC [11], IBMs Thomas J. Watson research centre [2], AT&T Bell Laboratories in Murray Hill <ref> [8] </ref> and in Geneva, at ISSCO [3]. Interestingly, all these early efforts focussed on sentence alignments rather than bitext maps. The first communications on the subject were published in 1991. <p> The main difference between the two approaches was how length was measured: while Brown et al. [2] counted words, Gale and Church <ref> [8] </ref> counted characters. alignment; arrows denote one possible bitext map. 7. Le dveloppement est maintenant apprhend dans la multiplicit de ses dimensions.
Reference: [9] <author> Isabelle, Pierre et al. </author> <year> (1993), </year> <title> Translation Analysis and Translation Automation, </title> <booktitle> in Proceedings of the Fifth International Conference on Theoretical and Methodological Issues in Machine Translation, </booktitle> <address> Kyoto, Japan. </address>
Reference-contexts: The truth of the matter is that BCP is just one instance of the more general translation analysis problem (see <ref> [9] </ref>), which turns out to be AI-complete.
Reference: [10] <author> Isabelle, </author> <title> Pierre (1996), </title> <type> personal communication. </type>
Reference-contexts: The first halves (the training corpus) were used for the purpose of optimizing the various parameters of the program, while the second halves (the test corpus) were kept for computing the final results 1 . Performance was measured using a method based on a metric proposed by Pierre Isabelle <ref> [10] </ref>: Consider two texts, S and T, viewed as unordered sets of sentences: S = -s 1 ,s 2 ,...,s n - and T = -t 1 ,t 2 ,...,t n -.
Reference: [11] <author> Kay, Martin and Martin Rscheisen (1993), </author> <title> Text-Translation Alignment, </title> <booktitle> in Computational Linguistics, </booktitle> <volume> Vol. 19, No. </volume> <pages> 1. </pages>
Reference-contexts: This work is described in the following pages. Background As far as we know, interest in bitext correspondence began sometime in the mid-eighties, at which time independent efforts were being pursued concurrently in many places, most notably at Xerox PARC <ref> [11] </ref>, IBMs Thomas J. Watson research centre [2], AT&T Bell Laboratories in Murray Hill [8] and in Geneva, at ISSCO [3]. Interestingly, all these early efforts focussed on sentence alignments rather than bitext maps. The first communications on the subject were published in 1991. <p> Using a dynamic programming scheme similar to those used in previous sentence alignment programs, Salign finds the alignment with the maximum overall probability. Most alignment methods that make use of lexical information assume that this information is not available a priori: Kay and Rscheisen <ref> [11] </ref>, Fung and McKeown [7], Chen [4], Dagan et al. [6] all go to great lengths to infer the parameters of their models directly from the pair of texts to align. This is a very interesting approach, especially when dealing with many language pairs.
Reference: [12] <author> Melamed, I. </author> <title> Dan (1996), A Geometric Approach to Mapping Bitext Correspondence, </title> <booktitle> to appear in the Proceedings of the Conference on Empirical Methods in Natural Language Processing, </booktitle> <address> Philadelphia. </address>
Reference-contexts: Other methods, such as those proposed by Dagan et al. [6] or Melamed <ref> [12] </ref> produce maps that are exact (the translation of the object at position x is the object at position y) but not exhaustive. On the other hand, what they lack in exactness or exhaustiveness, bitext map usually make up for in resolution: they give a closer view on the correspondence. <p> First Step: Initial Bitext Mapping The initial bitext map is computed using a program that we call Jacal (just another cognate alignment program), which was itself inspired by Melameds SIMR program <ref> [12] </ref>. What Jacal does is match isolated cognates: We consider two word-forms of different language to be cognates if their four first characters are identical, disregarding letter-case or diacritics.
Reference: [13] <author> Macklovitch, Elliott et al. </author> <year> (1996), </year> <institution> BAF: un corpus de bi-texte anglais-franais annot la main, </institution> <note> to appear. </note>
Reference-contexts: We feel that this last aspect has been somewhat neglected in previous work, which makes it very hard to compare methods, or simply to know what to expect from a given program. The corpus we used is the BAF corpus (see <ref> [13] </ref>): this is a collection of French-English bitexts, hand-aligned to the sentence level. The corpus consists in a dozen pairs of text files, totalling a little over 400 000 words in each language.
Reference: [14] <author> Palmer, David D. and Marti A. </author> <title> Hearst (1994), Adaptive Sentence Boundary Disambiguation, </title> <type> Report No. </type> <institution> UCB/CSD 94/797, Computer Science Division (EECS), University of California, Berkeley. </institution>
Reference-contexts: From our experience, alignment errors resulting from over-segmentation usually separate unrelated portions of sentences, while under-segmentation simply results in a dilution of the information rather than in genuine misalignments. We are nevertheless exploring the possibility of using more sophisticated segmentation methods, such as those proposed by Palmer and Hearst <ref> [14] </ref> for disambiguating periods. However, it would seem that ambiguous periods is not the only issue at stake here.
Reference: [15] <author> Simard, Michel, George F. Foster and Pierre Isabelle (1992), </author> <title> Using Cognates to Align Sentences in Bilingual Corpora, </title> <booktitle> in Proceedings of TMI-92. </booktitle>
Reference-contexts: To deal with the robustness issue, Church took a very straightforward and intuitive approach, exploiting an alignment criterion that was first proposed by Simard et al <ref> [15] </ref>: cognate words. Cognates are pairs of words of different languages that have close etymological ties. Often this tie will be reflected both in the meanings and orthography of these words. <p> In spite of its simplicity, this operational definition of cognates works well for related pairs of languages such as French and English, as demonstrated by Simard et al. <ref> [15] </ref> We consider an occurrence of a word-form to be isolated if no occurrence of resembling word-forms appear within a certain window around this occurrence. This isolation window is measured in characters, and is set to cover a given fraction of the text considered, say 30%.
Reference: [16] <author> Simard, Michel, George F. Foster, </author> <note> Franois Perrault (1993), TransSearch : un concordancier bilingue, CITI Technical Report. </note>
Reference-contexts: There are many situations where alignments are preferable, however. In particular, this appears to be true of applications where the bitext correspondence is directly intended for a human. An example of such an application is the bilingual concordance system developed at CITI <ref> [16] </ref>. This system allows a user to query a large corpus of bitext for specific expressions in one or both languages. Most often, the purpose of the user is to find out how a given expression is translated.
References-found: 16

