URL: http://www.media.mit.edu/~vmb/papers/ica99.ps
Refering-URL: http://www.media.mit.edu/~vmb/
Root-URL: http://www.media.mit.edu
Email: westner@media.mit.edu, vmb@media.mit.edu  
Title: BLIND SEPARATION OF REAL WORLD AUDIO SIGNALS USING OVERDETERMINED MIXTURES  
Author: Alex Westner and V. Michael Bove, Jr. 
Address: 20 Ames Street Cambridge, MA 02142, USA  
Affiliation: MIT Media Laboratory  
Abstract: We discuss the advantages of using overdetermined mixtures to improve upon blind source separation algorithms that are designed to extract sound sources from acoustic mixtures. A study of the nature of room impulse responses helps us choose an adaptive filter architecture. We use ideal inverses of acquired room impulse responses to compare the effectiveness of different-sized separating filter configurations of various filter lengths. Using a multi-channel blind least-mean-square algorithm (MBLMS), we show that, by adding additional sensors, we can improve upon the separation of signals mixed with real world filters. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Amari, S., A. Cichocki and H. Yang. </author> <title> A New Learning Algorithm for Blind Signal Separation. </title> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> 8, </volume> <pages> pp. 757-763, </pages> <year> 1996. </year>
Reference-contexts: OVERDETERMINED BLIND SEPARATION Some of the more commonly used blind separation and deconvolution adaptation rules are constrained to only handling square matrices of filters <ref> [1] </ref>. For our experiment, we used the multichannel blind least-mean-square algorithm (MBLMS) described by Lambert [8].
Reference: [2] <author> Chan, Dominic. </author> <title> Blind signal separation audio demonstrations WWW page. </title> <address> www2.eng.cam.ac.uk/~dcbc1/research/demo.html </address>
Reference-contexts: The experiment proceeded as follows. First, we generated acoustic sound mixtures by convolving clean sound sources (downloaded from Dominic Chan's web site <ref> [2] </ref>) with a matrix of room impulse responses.
Reference: [3] <author> Cherry, E. Collin. </author> <title> Some Experiments on the Recognition of Speech, with One and with Two Ears. </title> <journal> Journal of the Acoustical Society of America, </journal> <volume> 24, </volume> <pages> pp. 975-979, </pages> <year> 1953. </year>
Reference: [4] <author> Ehlers, F. and Schuster, H. G. </author> <title> Blind separation of convolutive mixtures and an application in automatic speech recognition in a noisy environment. </title> <journal> IEEE Transactions on Signal Processing, </journal> <volume> 45(1) no.10, </volume> <pages> pp. 2608-2612, </pages> <year> 1997. </year>
Reference-contexts: The reverberation and absorption characteristics of a room can be modeled as a finite impulse response (FIR) filter and convolved with the original sound source to simulate the signal recorded by a microphone [11]. Several researchers have extended blind source separation algorithms to cope with delayed and convolved sources <ref> [15, 8, 9, 4] </ref>; most of these algorithms have only implemented N xN configurations, using N sensors to separate out N sources. (Lambert [8] implemented an M xN example with more sensors than sources.) Researchers often use beamforming microphone arrays when recording sounds in a reverberant environment.
Reference: [5] <author> Gardner, Bill and Keith Martin. </author> <title> HRTF Measurements of a KEMAR Dummy-Head Microphone. MIT Media Lab Perceptual Computing - Technical Report #280, </title> <year> 1994. </year>
Reference-contexts: In addition, we can more easily perform a quantitative analysis on our results. Using the system designed by Bill Gardner and Keith Martin <ref> [5] </ref>, we took impulse response measurements of a 3.5m x 7m x 3m conference room. Two and a half walls of the room are covered with whiteboards, one wall is covered with a projection screen and a large table sits in the middle of the room.
Reference: [6] <author> Haykin, Simon. </author> <title> Adaptive Filter Theory, Third Edition, Upper Saddle River, </title> <address> New Jersey: </address> <publisher> Pren-tice Hall, </publisher> <year> 1996. </year> <month> 5 </month>
Reference-contexts: In terms of blind separation algorithms, this means that we will be unable to use a feedback filter configuration, like the one suggested by Kari Torkkola [15], since they are only capable of inverting minimum phase filters <ref> [6] </ref>. 3.
Reference: [7] <author> Herault, Jeanny and Christian Jutten. </author> <title> Space or time adaptive signal processing by neural network models. </title> <booktitle> AIP Conference Proceedings, </booktitle> <volume> 151, </volume> <pages> pp. 206-211, </pages> <year> 1986. </year>
Reference-contexts: Furthermore, we do not know beforehand what the sounds are or how they are mixed together, so we must exclusively use the sound mixtures themselves to extract out the original sound sources, a process commonly known as blind source separation <ref> [7] </ref>. When using conventional source separation algorithms, we assume that the original signals are mixed This work has been supported by the Digital Life Consortium at the MIT Media Laboratory. together instantaneously [7]. Two microphones in a room, however, will record an acoustic sound at two different propagation delays. <p> sound mixtures themselves to extract out the original sound sources, a process commonly known as blind source separation <ref> [7] </ref>. When using conventional source separation algorithms, we assume that the original signals are mixed This work has been supported by the Digital Life Consortium at the MIT Media Laboratory. together instantaneously [7]. Two microphones in a room, however, will record an acoustic sound at two different propagation delays. In addition, the microphones will pick up several delayed and modified copies of the original sound source, as it reflects off of walls and objects in the room.
Reference: [8] <author> Lambert, Russell H. </author> <title> Multichannel Blind Decon-volution: FIR Matrix Algebra and Separation of Multipath Mixtures. </title> <type> PhD Thesis, </type> <institution> University of Southern California, </institution> <year> 1996. </year>
Reference-contexts: The reverberation and absorption characteristics of a room can be modeled as a finite impulse response (FIR) filter and convolved with the original sound source to simulate the signal recorded by a microphone [11]. Several researchers have extended blind source separation algorithms to cope with delayed and convolved sources <ref> [15, 8, 9, 4] </ref>; most of these algorithms have only implemented N xN configurations, using N sensors to separate out N sources. (Lambert [8] implemented an M xN example with more sensors than sources.) Researchers often use beamforming microphone arrays when recording sounds in a reverberant environment. <p> Several researchers have extended blind source separation algorithms to cope with delayed and convolved sources [15, 8, 9, 4]; most of these algorithms have only implemented N xN configurations, using N sensors to separate out N sources. (Lambert <ref> [8] </ref> implemented an M xN example with more sensors than sources.) Researchers often use beamforming microphone arrays when recording sounds in a reverberant environment. Beamforming arrays target their sound capture toward a desired spatial area, improving upon the signal-to-noise ratio (SNR) of the sounds recorded from that region. <p> vector of mixed signals, x (t): The goal is to determine W (t), the inverse of A (t), which we can use to convolve with x (t) to yield estimates, u (t), of the original sources: u (t) = W (t) fl x (t) As described in Russell Lambert's thesis <ref> [8] </ref>, we can apply standard scalar matrix algorithms to invert FIR polynomial matrices. The following shows how to in vert a 2x2 FIR matrix A. <p> OVERDETERMINED BLIND SEPARATION Some of the more commonly used blind separation and deconvolution adaptation rules are constrained to only handling square matrices of filters [1]. For our experiment, we used the multichannel blind least-mean-square algorithm (MBLMS) described by Lambert <ref> [8] </ref>. The MBLMS algorithm attempts to minimize the cost function J where u is the estimated output and g is the Bussgang nonlinearity that uses prior knowledge of the probability density function (pdf) of the sources. <p> We set the algorithm to learn 512-tap filters, and we used 200,000 gamma-distributed (speech-like) random samples. We used a Multichannel Intersymbol Interference (ISI) performance metric to determine how close the learned unmixing filters were to a scaled and/or per muted identity FIR matrix <ref> [8] </ref>: 4 MBLMS algorithm. The sampling rate was 11.025kHz. ISI i = j k js ij (k)j 2 max j;k js ij (k)j 2 where s ij are the filter elements of the mixing matrix, W convolved with the separating matrix, A.
Reference: [9] <author> Lee, Te-Won, Anthony J. Bell and Russell H. Lam-bert. </author> <title> Blind separation of delayed and convolved sources. </title> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> 9, </volume> <pages> pp. 758-764, </pages> <year> 1996. </year>
Reference-contexts: The reverberation and absorption characteristics of a room can be modeled as a finite impulse response (FIR) filter and convolved with the original sound source to simulate the signal recorded by a microphone [11]. Several researchers have extended blind source separation algorithms to cope with delayed and convolved sources <ref> [15, 8, 9, 4] </ref>; most of these algorithms have only implemented N xN configurations, using N sensors to separate out N sources. (Lambert [8] implemented an M xN example with more sensors than sources.) Researchers often use beamforming microphone arrays when recording sounds in a reverberant environment.
Reference: [10] <author> Neely, Stephen T. and Jont B. Allen. </author> <title> Invertibility of a room impulse response. </title> <journal> Journal of the Acoustical Society of America, </journal> <volume> 66(1), </volume> <pages> pp. 165-169, </pages> <year> 1979. </year>
Reference-contexts: Upon visual inspection of the room impulse response, we can see that it is non-minimum phase. In general, for a filter to be minimum phase, the first sample 2 should be larger than all other samples, and the re-sponse should decay rapidly <ref> [10] </ref>. In terms of blind separation algorithms, this means that we will be unable to use a feedback filter configuration, like the one suggested by Kari Torkkola [15], since they are only capable of inverting minimum phase filters [6]. 3.
Reference: [11] <author> Orfanidis, Sophocles J. </author> <title> Introduction to Signal processing, Upper Saddle River, </title> <address> New Jersey: </address> <publisher> Prentice Hall, </publisher> <year> 1996. </year>
Reference-contexts: The reverberation and absorption characteristics of a room can be modeled as a finite impulse response (FIR) filter and convolved with the original sound source to simulate the signal recorded by a microphone <ref> [11] </ref>.
Reference: [12] <author> Rabinkin, Daniel V., Richard J. Renomeron, Arthur Dahl, Joseph C. French, James L. Flana-gan and Michael H. Bianchi. </author> <title> A DSP Implementation of Source Location Using Microphone Arrays, </title> <booktitle> Proceedings of the SPIE, </booktitle> <volume> 2846, </volume> <pages> pp. 88-99, </pages> <year> 1996. </year>
Reference-contexts: After downsampling the data to a sampling rate of 11.025kHz, this equates to a 8,192-point response (See Figure 2). A strong characteristic low-frequency murmur, an artifact of the room configuration, dominates the impulse response. Following the example of Rabinkin et. al. <ref> [12] </ref>, we applied a 200Hz high-pass filter to the impulse responses to remove this "room mode noise." The resulting impulse response is both aurally and visually cleaner (See Figure 3).
Reference: [13] <author> Rabinkin, Daniel V., Richard J. Renomeron, Joseph C. French, and James L. Flanagan. </author> <title> Optimum microphone placement for array sound capture. </title> <booktitle> Proceedings of the SPIE, vol.3162, </booktitle> <pages> pp. 227-239, </pages> <year> 1997. </year>
Reference-contexts: Thus, signal components emanating from a desired location combine coherently, while components from other locations combine incoherently. This increases the gain of the desired signal over the undesired noise; the SNR is a monotonically increasing function of the number of sensors <ref> [13] </ref>. In an effort to take advantage of the SNR gains that microphone arrays can achieve, we propose to extend current blind sound source separation algorithms to that of the overdetermined case, where we have more sensors than sources. <p> Based upon the orientation of the lighting grid, we constructed two linear microphone arrays, each with four elements. The microphones within each array are spaced about a half-meter apart from one another, as suggested by Dan Rabinkin et. al. <ref> [13] </ref> in optimum sensor placement. We collected 8 impulse responses from 24 different locations around the room. To ensure that we would capture the full response of the room, we set the acquisition software to compute responses of approximately 750ms.
Reference: [14] <author> Roy, Deb K., Nitin Sawhney, Chris Schmandt and Alex Pentland. </author> <title> Wearable Audio Computing: A Survey of Interaction Techniques. </title> <type> Technical Report, </type> <institution> MIT Media Lab, </institution> <year> 1997. </year>
Reference-contexts: Digital audio systems, as well, would benefit from having this ability (termed by E. Collin Cherry in 1953 as the "cocktail-party effect."[3]); some potential applications include: instrument separation in a multitrack recording studio, speaker separation in a videoconferencing session, and audio stream segregation for a wearable audio computer <ref> [14] </ref>. In this work, we attempt to improve upon the extraction of acoustic sound signals by studying overdetermined mixtures, where we have more microphones than sound sources. These applications all have in common the task of source separation.
Reference: [15] <author> Torkkola, Kari. </author> <title> Blind Separation of Convolved Sources Based on Information Maximization. </title> <booktitle> Proceedings of the 1996 IEEE Workshop on Neural Networks for Signal Processing, </booktitle> <pages> pp. 423-432, </pages> <year> 1996. </year>
Reference-contexts: The reverberation and absorption characteristics of a room can be modeled as a finite impulse response (FIR) filter and convolved with the original sound source to simulate the signal recorded by a microphone [11]. Several researchers have extended blind source separation algorithms to cope with delayed and convolved sources <ref> [15, 8, 9, 4] </ref>; most of these algorithms have only implemented N xN configurations, using N sensors to separate out N sources. (Lambert [8] implemented an M xN example with more sensors than sources.) Researchers often use beamforming microphone arrays when recording sounds in a reverberant environment. <p> In terms of blind separation algorithms, this means that we will be unable to use a feedback filter configuration, like the one suggested by Kari Torkkola <ref> [15] </ref>, since they are only capable of inverting minimum phase filters [6]. 3.
Reference: [16] <author> Westner, Alexander G. </author> <title> Object-Based Audio Capture: Separating Acoustic Sounds. M.S. </title> <type> Thesis, </type> <institution> Massachusetts Institute of Technology Media Laboratory, </institution> <year> 1998. </year> <month> 6 </month>
Reference-contexts: A large projector and a lighting grid (to which the microphones are attached) hang from the ceiling. See Figure 1 for a photo of the room, and Alex Westner's thesis <ref> [16] </ref> for a more detailed diagram of the room layout. the lighting grid in the conference room. Based upon the orientation of the lighting grid, we constructed two linear microphone arrays, each with four elements.
References-found: 16

