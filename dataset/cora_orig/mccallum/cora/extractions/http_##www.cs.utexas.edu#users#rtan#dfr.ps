URL: http://www.cs.utexas.edu/users/rtan/dfr.ps
Refering-URL: http://www.cs.utexas.edu/users/rtan/dfr.html
Root-URL: 
Title: Dynamic File Replication  
Author: Yongxiang Gao, Rong Tan, Yingjun Wu 
Date: December 9, 1996  
Address: Austin  
Affiliation: Department of Computer Sciences University of Texas at  
Abstract: The growth of Internet makes it necessary to find a solution to increasing accessing latency. Traditional caching mechanism only made copies in the local machine. However, as we consider the hierarchical topology of the network and notice that the local subnet is always much faster than the internet links, we add a new cache level between local disk and the large-scale network, making copies and storing them in a nearby subnet. Dynamic file replication does this work well. We make router the main controller for our system. A router gathers file request information while it passes the requests to the remote server and makes a replica at its local subnet when the request frequency for such file at this router exceeds a threshold. Therefore the following requests will get faster response for they can reach the replica with a shorter path. On the other hand the server load will be relieved a great deal because the reduce of data request reaching it. We made a simulator to evaluate the performance of this strategy. The simulator assumes easy model for the network and make random requests to randomly distributed files. The result shows that our system performs better than the system without replication mechanism up to the factor of 4. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Sandberg, R., Goldberg, D., Kleiman, S., Walsh, D., Lyon, B., </author> <title> "Design and Implementation of the Sun Network File System" Proc. </title> <booktitle> USENIX Summer Conf., </booktitle> <year> 1985. </year>
Reference-contexts: The solution for this problem is caching and replication. Distributed file systems, such as NFS <ref> [1] </ref> and AFS [2], are convenient mechanisms for sharing and distributing files among small- and medium- size groups of computers [3]. They both adopt caching as a fundamental feature. The case is more complicated with a larger group such as the Internet.
Reference: [2] <author> Howard, J.H., Kazar, M.L., Menees, S.G., Nichols, D.A., Satyanaryanan, M., Sidebotham, R.N., West, M.J. </author> <title> "Scale and Performance in Distributed File Systems", </title> <journal> ACM Trans. Computing Systems, </journal> <volume> Vol. 6, No. 1, </volume> <year> 1988. </year>
Reference-contexts: The solution for this problem is caching and replication. Distributed file systems, such as NFS [1] and AFS <ref> [2] </ref>, are convenient mechanisms for sharing and distributing files among small- and medium- size groups of computers [3]. They both adopt caching as a fundamental feature. The case is more complicated with a larger group such as the Internet. <p> When a master copy is modified or unlinked, the host 3 holding the master copy will send invalidation messages to the hosts having replicas like the callback mechanism in AFS <ref> [2] </ref>. By some simple traceroutes it is easy to find out that the local network links are always much faster than the Internet links. The round trip time between two hosts ranges from tenth of a millisecond to approximately one second.
Reference: [3] <author> Blaze, M., Alonso, R., </author> <title> "Dynamic Hierarchical Caching in Large-Scale Distributed File Systems". </title>
Reference-contexts: The solution for this problem is caching and replication. Distributed file systems, such as NFS [1] and AFS [2], are convenient mechanisms for sharing and distributing files among small- and medium- size groups of computers <ref> [3] </ref>. They both adopt caching as a fundamental feature. The case is more complicated with a larger group such as the Internet. <p> Section 3 describes our simulator and analyzes the result of simulation. Section 4 presents further discussion on this project and outlines future work. Section 5 reviews some of the related works. The last section gives the conclusion. 2 System Design In Matthew Blaze's work <ref> [3] </ref>, they examined a trace of workstation file system activity, and showed that as a file is opened for reading more often, it is very unlikely that the next operation on that file will be write or unlink. <p> This is a fatal factor for our system. 5 Related Work A lot of works have been done concerning the dynamic caching and building distributed file system in a large-scale network <ref> [3] </ref>[4][5][6]. They are largely focusing on the scalability issue. In Blaze's dynamic Hierarchical caching in large-scale distributed file system [3], a strategy similar to our system is given, but the network topology is not considered in his work.
Reference: [4] <author> Dahlin, M.D., Mather, C.J., Wang, R.Y., Anderson, T.E., Patterson, D.A., </author> <title> "A Quantitative Analysis of Cache Policies for Scalable Network File Systems". </title>
Reference: [5] <author> Anderson, T.E., Dahlin, M.D., Neefe, J.M., Patterson, D.A., Roselli, D.S., Wang, R.Y., </author> <title> "Serverless Network File Systems", </title> <month> TOCS(February </month> <year> 1996) </year>
Reference: [6] <author> Blaze, M., Alonso, R., </author> <title> "Long Term Caching Strategies for Very Large Distributed File Systems". </title>
Reference: [7] <author> Guyton, J.D., Schwartz, M.F., </author> <title> "Locating Nearby Copies of Replicated Internet Servers", </title> <booktitle> In Proceedings of ACM SIGCOMM'95, </booktitle> <year> 1995. </year> <month> 11 </month>
Reference-contexts: Guyton and Schwartz focused their work on the locating of replicas in the Internet <ref> [7] </ref>, which happens to be what we ignored in our simulation and took for granted. We will base this part of future work on these ideas. 6 Conclusions Dynamic file replication system serves the internet clients with fewer replicas than the traditional cache systems.
References-found: 7

