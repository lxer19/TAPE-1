URL: http://www.cs.umass.edu/~immerman/pub/dynfo.ps
Refering-URL: http://www.cs.umass.edu/~immerman/pub_immerman.html
Root-URL: 
Email: patnaik@bear.com  immerman@cs.umass.edu  
Title: Dyn-FO: A Parallel, Dynamic Complexity Class  
Author: Sushant Patnaik Neil Immerman 
Note: is not in Dyn-FO unless all of P is contained in parallel linear time.  
Address: Amherst, MA 01003  Amherst, MA 01003  
Affiliation: Computer Science Dept. University. of Massachusetts  Computer Science Dept. University. of Massachusetts  
Abstract: For many applications of computers it is more appropriate to model the process as a dynamic one. There is a fairly large object being worked on over a period of time. The object is repeatedly modified by users and computations are performed. We develop a theory of Dynamic Complexity. We study the new complexity class, Dynamic First-Order Logic (Dyn-FO). This is the set of properties that can be maintained and queried in first-order logic, i.e. relational calculus, on a relational database. We show that many interesting properties are in Dyn-FO including multiplication, graph connectivity, bipartiteness, and the computation of minimum spanning trees. Note that none of these problems is in static FO, and this fact has been used to justify increasing the power of query languages beyond first-order. It is thus striking that these problems are indeed dynamic first-order, and thus, were computable in first-order database languages all along. We also define "bounded-expansion reductions" which honor dynamic complexity classes. We prove that certain standard complete problems for static complexity classes, such as REACH a for P, remain complete via these new reductions. On the other hand, we prove that other such problems including REACH for NL and REACH d for L are no longer complete via bounded-expansion reductions. Furthermore, we show that a version of REACH a , called REACH a 
Abstract-found: 1
Intro-found: 1
Reference: [A83] <author> M. </author> <title> Ajtai (1983), " 1 1 Formulae on Finite Structures," </title> <journal> Annals of Pure and Applied Logic 24, </journal> <pages> 1-48. </pages>
Reference-contexts: This is well known not to be in static FO 1 This expects that the complexity class C is closed under polynomial increases in the input size. For more restricted classes C, such as linear time, we insist that jjf n (r)jj = O (jjeval n; (r)jj). 6 <ref> [A83, FSS84] </ref>. The dynamic algorithm for PARITY maintains a bit b which is toggled after any change to the string. We also remember the input string so that we can tell if a request has actually changed the string.
Reference: [B89] <author> D.M. Barrington, </author> <title> "Bounded-Width Polynomial-Size Branching Programs Recog nize Exactly Those Languages in NC 1 ," J. </title> <journal> Comput. Sys. Sci. </journal> , <volume> 38 (1989), </volume> <pages> 150-164. </pages>
Reference-contexts: Let COLOR Q colorized version of the problem Q (S 5 ) iterated multiplication of elements of the symmetric group on five objects <ref> [IL94, B89] </ref>. This means that for each position there is a pair of group elements, 0 and 1 .
Reference: [BC89] <author> D.M. Barrington, J.C. Corbett, </author> <title> "On the Relative Complexity of some Languages in NC 1 ," Technical Report 89 22, </title> <institution> Department of Computer Science, University of Massachusetts, </institution> <address> Amherst (1989). </address>
Reference-contexts: Again this is easily accomplished by a first-order formula. 2 Proposition 4.8 For any constant, k, D k , the Dyck language on k parentheses is in Dyn-FO. Proof This is similar to the proof in <ref> [BC89] </ref> that D k is in ThC 0 the class of problems accepted by bounded-depth, polynomial-size threshold circuits. D k can be parsed using the level trick: assign a level to each parenthesis starting at one and ignoring the differences in parenthesis type.
Reference: [BRS91] <author> A. Borodin, R. Razborov, S. Smolensky. </author> <title> "On Lower Bounds for Read-k Times Branching Programs," </title> <type> Preprint, </type> <year> (1991). </year>
Reference: [CH82] <author> A. Chandra and D. Harel, </author> <title> "Structure and Complexity of Relational Queries," </title> <journal> J. Comput. Sys. Sci. </journal> , <volume> 25 (1982), </volume> <pages> 99-128. </pages>
Reference-contexts: to ask whether any data structure with a given set of operations is in Dyn-C. 4 Problems in Dyn-FO It is well known that the graph reachability problem is not first-order expressible and this has often been used as a justification for using database query languages more powerful than FO <ref> [CH82] </ref>. Thus, the following two theorems are striking. Theorem 4.1 REACH u is in Dyn-FO. Proof We maintain a spanning forest of the underlying graph via relations, F (x; y) and PV (x; y; u) and the input relation, E.
Reference: [CT91] <author> R. Cohen, R. Tamassia, </author> <title> "Dynamic Expression Trees and their applications," </title> <booktitle> Pro ceedings of the 2nd Annual ACM-SIAM SODA, </booktitle> <year> (1991). </year>
Reference-contexts: Other work on dynamic complexity for databases includes the theory of maintaining materialized views upon updates ([J92], [GMS93], [Io85]), and in integrity constraint simplification ([LST87], [N82]). The design of dynamic algorithms is an active field. See, for example, [E + 92], [E + 92b], [R94], <ref> [CT91] </ref>, [F85], [F91] among many others. There is also a large amount of work in the programming language community on incremental computation, see for example [RR96, LT94]. 2 This paper is organized as follows. In Section 2, we begin with some background on Descrip--tive Complexity.
Reference: [DS95] <author> G. Dong, J. Su, </author> <title> "Space-Bounded FOIES," </title> <booktitle> ACM Symp. Principles Database Sys tems (1995), </booktitle> <address> 139 -150. </address>
Reference-contexts: Quite recently Dong and Su have shown that the answer is yes <ref> [DS95] </ref>. They show that the arity three construction of PV can be replaced by a directed version of F and its transitive closure. They also use Ehrenfeucht-Frasse games to show that arity one does not suffice.
Reference: [DS93] <author> G. Dong, J. Su, </author> <title> "Incremental and Decremental Evaluation of Transitive Closure by First-Order Queries," </title> <booktitle> Information and Computation , 120(1) (1995), </booktitle> <pages> 101-106. 17 </pages>
Reference-contexts: The problems we show to be in Dyn-FO include: reachability in undirected graphs, maintaining a minimum spanning forest, k-edge connectivity and bipartiteness. All regular languages are shown to be in Dyn-FO. In [P94] it is shown that some NP-complete problems admit Dyn-FO approximation algorithms. Dong and Su <ref> [DS93] </ref> showed that reachability in directed, acyclic graphs and in function graphs is in Dyn-FO. The static versions of all these problems are not first-order. Related work on dynamic complexity appears in [MSV94]. In [DST93] first-order incremental evaluation system (FOIES) are defined.
Reference: [DST93] <author> G. Dong, J. Su, R. Topor. </author> <title> "First-Order Incremental Evaluation of Datalog Queries", </title> <booktitle> Proceedings of the 1992 International Conference on Database Theory, </booktitle> <publisher> LNCS 646, Springer Verlag. </publisher>
Reference-contexts: Dong and Su [DS93] showed that reachability in directed, acyclic graphs and in function graphs is in Dyn-FO. The static versions of all these problems are not first-order. Related work on dynamic complexity appears in [MSV94]. In <ref> [DST93] </ref> first-order incremental evaluation system (FOIES) are defined. A problem has an FOIES iff it is in Dyn-FO. In [TY79], Tarjan and Yao propose a dynamic model whose complexity measure is the number of probes into a data structure and any other computation is free.
Reference: [E + 92] <author> D. Eppstein, Z. Galil, G. F. Italiano, A. Nissenzweig. </author> <title> "Sparsification A technique for speeding up dynamic graph algorithms," </title> <booktitle> IEEE Found. of Comp. Sci. Symp. </booktitle> <year> (1992), </year> <pages> 60-69. </pages>
Reference-contexts: Other lower bounds [M93], [R94] have been proved using these methods. Other work on dynamic complexity for databases includes the theory of maintaining materialized views upon updates ([J92], [GMS93], [Io85]), and in integrity constraint simplification ([LST87], [N82]). The design of dynamic algorithms is an active field. See, for example, <ref> [E + 92] </ref>, [E + 92b], [R94], [CT91], [F85], [F91] among many others. There is also a large amount of work in the programming language community on incremental computation, see for example [RR96, LT94]. 2 This paper is organized as follows.
Reference: [E + 92b] <author> D. Eppstein, Z. Galil, G. F. Italiano, A. Nissenzweig. </author> <title> "Sparsification and Planarity Testing," </title> <booktitle> Proceedings of ACM Symposium on Theory of Computing (1992). </booktitle>
Reference-contexts: Other work on dynamic complexity for databases includes the theory of maintaining materialized views upon updates ([J92], [GMS93], [Io85]), and in integrity constraint simplification ([LST87], [N82]). The design of dynamic algorithms is an active field. See, for example, [E + 92], <ref> [E + 92b] </ref>, [R94], [CT91], [F85], [F91] among many others. There is also a large amount of work in the programming language community on incremental computation, see for example [RR96, LT94]. 2 This paper is organized as follows. In Section 2, we begin with some background on Descrip--tive Complexity.
Reference: [Fa74] <author> Ron Fagin, </author> <title> "Generalized First-Order Spectra and Polynomial-Time Recognizable Sets," in Complexity of Computation, </title> <editor> (ed. R. Karp), </editor> <booktitle> SIAM-AMS Proc. 7 (1974), </booktitle> <pages> 27-41. </pages>
Reference: [F85] <author> G.F. Frederickson, </author> <title> "Data structures for on-line updating of minimum spanning trees," </title> <journal> SIAM J. Comput. </journal> , <volume> 14 (1985), </volume> <pages> 781-798. </pages>
Reference-contexts: Other work on dynamic complexity for databases includes the theory of maintaining materialized views upon updates ([J92], [GMS93], [Io85]), and in integrity constraint simplification ([LST87], [N82]). The design of dynamic algorithms is an active field. See, for example, [E + 92], [E + 92b], [R94], [CT91], <ref> [F85] </ref>, [F91] among many others. There is also a large amount of work in the programming language community on incremental computation, see for example [RR96, LT94]. 2 This paper is organized as follows. In Section 2, we begin with some background on Descrip--tive Complexity.
Reference: [F91] <author> G.F. Frederickson, </author> <title> "Ambivalent data structures for dynamic 2-edge connectivity and k smallest spanning trees," </title> <booktitle> IEEE Found. of Comp. Sci. Symp. </booktitle> <year> (1991), </year> <pages> 632-641. </pages>
Reference-contexts: Other work on dynamic complexity for databases includes the theory of maintaining materialized views upon updates ([J92], [GMS93], [Io85]), and in integrity constraint simplification ([LST87], [N82]). The design of dynamic algorithms is an active field. See, for example, [E + 92], [E + 92b], [R94], [CT91], [F85], <ref> [F91] </ref> among many others. There is also a large amount of work in the programming language community on incremental computation, see for example [RR96, LT94]. 2 This paper is organized as follows. In Section 2, we begin with some background on Descrip--tive Complexity.
Reference: [FS89] <author> M. Fredman and M. Saks, </author> <title> "The Cell Probe Complexity of Dynamic Data Structures," </title> <booktitle> 21st ACM STOC Symp. </booktitle> <year> (1989), </year> <pages> 345-354. </pages>
Reference-contexts: In [TY79], Tarjan and Yao propose a dynamic model whose complexity measure is the number of probes into a data structure and any other computation is free. A log n= log log n lower bound on a dynamic prefix multiplication problem was proved in <ref> [FS89] </ref>. Other lower bounds [M93], [R94] have been proved using these methods. Other work on dynamic complexity for databases includes the theory of maintaining materialized views upon updates ([J92], [GMS93], [Io85]), and in integrity constraint simplification ([LST87], [N82]). The design of dynamic algorithms is an active field.
Reference: [FSS84] <author> M. Furst, J.B. Saxe, and M. Sipser, </author> <title> "Parity, Circuits, and the Polynomial-Time Hierarchy," Math. </title> <booktitle> Systems Theory 17 (1984), </booktitle> <pages> 13-27. </pages>
Reference-contexts: This is well known not to be in static FO 1 This expects that the complexity class C is closed under polynomial increases in the input size. For more restricted classes C, such as linear time, we insist that jjf n (r)jj = O (jjeval n; (r)jj). 6 <ref> [A83, FSS84] </ref>. The dynamic algorithm for PARITY maintains a bit b which is toggled after any change to the string. We also remember the input string so that we can tell if a request has actually changed the string.
Reference: [GMS93] <author> A. Gupta, I. S. Mumick, V. S. Subrahmanian, </author> <title> "Maintaining Views Incrementally," </title> <booktitle> Proceedings of the ACM SIGMOD (1993), </booktitle> <pages> 157-166. </pages>
Reference-contexts: A log n= log log n lower bound on a dynamic prefix multiplication problem was proved in [FS89]. Other lower bounds [M93], [R94] have been proved using these methods. Other work on dynamic complexity for databases includes the theory of maintaining materialized views upon updates ([J92], <ref> [GMS93] </ref>, [Io85]), and in integrity constraint simplification ([LST87], [N82]). The design of dynamic algorithms is an active field. See, for example, [E + 92], [E + 92b], [R94], [CT91], [F85], [F91] among many others.
Reference: [I89] <author> N. Immerman, </author> <title> "Descriptive and Computational Complexity," in Computational Complexity Theory, </title> <editor> ed. J. Hartmanis, </editor> <booktitle> Proc. Symp. in Applied Math., 38, American Mathematical Society (1989), </booktitle> <pages> 75-91. </pages>
Reference-contexts: In Section 5, we describe and investigate reductions honoring dynamic complexity. Finally, we suggest some future directions for the study of dynamic complexity. 2 Descriptive Complexity: Background and Definitions In this section we recall the notation of Descriptive Complexity. See <ref> [I89] </ref> for a survey and [IL94] for an extensive study of first-order reductions. In the development of descriptive complexity it has turned out that "natural" complexity classes have "natural" descriptive characterizations. For example, space corresponds to number of variables; and parallel time is linearly related to quantifier-depth.
Reference: [I89b] <author> Neil Immerman, </author> <title> "`Expressibility and Parallel Complexity," </title> <journal> SIAM J. of Comput, </journal> <volume> 18 (1989), </volume> <pages> 625-638. </pages>
Reference-contexts: Let CRAM [t (n)] be the set of problems computable by uniform CRCW-PRAMS using polynomially much hardware. It is known that FO = CRAM [1] <ref> [I89b] </ref>. Let CRAM + [t (n)] be CRAM [t (n)] with polynomial precomputation. Then Corollary 5.7 Dyn-FO CRAM [n] and Dyn-FO + CRAM + [n]. If REACH a 2 Dyn-FO + , then P = Dyn-FO + , and thus P = CRAM + [n].
Reference: [I87] <author> N. Immerman, </author> <title> "Languages That Capture Complexity Classes," </title> <journal> SIAM J. </journal> <volume> Com-put., </volume> <month> (16:4) </month> <year> (1987), </year> <pages> 760-778. </pages>
Reference-contexts: Recall that REACH a is complete for P via first-order reductions. Thus, so is PAD (REACH a ). Also, it is easy to see that REACH a is in FO [n] <ref> [I87] </ref>. It follows that a complete problem for P is in Dyn-FO: Theorem 5.14 PAD (REACH a ) is in Dyn-FO. 6 Conclusions We have defined dynamic complexity classes, and their reductions. In particular, we have begun an investigation of the rich dynamic complexity class Dyn-FO.
Reference: [I81] <author> N. Immerman, </author> <title> "Number of Quantifiers is Better than Number of Tape Cells," </title> <institution> J. Comput. Sys. Sci. </institution> , <month> (22:3) </month> <year> (1981), </year> <pages> 65-72. </pages>
Reference-contexts: We give one such example here: Proposition 5.5 REACH a and CVAL are complete for P via bfo + reductions. Proof REACH a is the reachability problem for alternating graphs. It is equivalent to CVAL the circuit value problem. In <ref> [I81] </ref>, it is shown that REACH a is complete for ASPACE [log n] via first-order reductions. Recall that ASPACE [log n] = P. The proof depends on the fact that REACH a is the natural complete problem for ASPACE [log n]. <p> The proof depends on the fact that REACH a is the natural complete problem for ASPACE [log n]. An alternating machine can put off looking at its input until the last step of its computation. Thus, each input bit is copied only once and the first-order reductions from <ref> [I81] </ref> become bounded expansion. 2 The reason that Proposition 5.5 requires bfo + reductions is that I (A n 0 ) contains more than a bounded number of edges and vertices marked "8" (or equivalently for CVAL, more than a bounded number of wires and nodes marked "and").
Reference: [IL94] <author> N. Immerman, S. Landau, </author> <title> "The Complexity of Iterated Multiplication," </title> <booktitle> Information and Computation , (116:1) (1995), </booktitle> <pages> 103-116. </pages>
Reference-contexts: In Section 5, we describe and investigate reductions honoring dynamic complexity. Finally, we suggest some future directions for the study of dynamic complexity. 2 Descriptive Complexity: Background and Definitions In this section we recall the notation of Descriptive Complexity. See [I89] for a survey and <ref> [IL94] </ref> for an extensive study of first-order reductions. In the development of descriptive complexity it has turned out that "natural" complexity classes have "natural" descriptive characterizations. For example, space corresponds to number of variables; and parallel time is linearly related to quantifier-depth. <p> First-order reductions are used in Section 5 to build new reductions that honor dynamic complexity. Furthermore, reductions are used in Section 3 as a motivation for the definition of Dynamic Complexity. More information about first-order reductions can be found in <ref> [IL94] </ref>. Recall that a first-order query is a first-order definable mapping from structures of one vocabulary to structures of another. A first-order reduction is simply a first-order query that is also a many-one reduction. We give an example and then the formal definition. <p> This dependency is oblivious, i.e., only depending on the numeric predicates: ; =; BIT and not on the input predicates. (This is similar to the definition of first-order projections <ref> [IL94] </ref> in which each output bit must depend on at most one input bit.) Furthermore, a bfo reduction is required to map the initial structure, A n 0 , to a structure with only a bounded number of tuples present. <p> Let COLOR Q colorized version of the problem Q (S 5 ) iterated multiplication of elements of the symmetric group on five objects <ref> [IL94, B89] </ref>. This means that for each position there is a pair of group elements, 0 and 1 .
Reference: [Io85] <author> Y. Ionanadis, </author> <title> "A Time Bound on the Materialization of Some Recursively Defined Views," </title> <booktitle> Proceedings of International Conference on Very Large Data Bases, </booktitle> <year> 1985. </year>
Reference-contexts: A log n= log log n lower bound on a dynamic prefix multiplication problem was proved in [FS89]. Other lower bounds [M93], [R94] have been proved using these methods. Other work on dynamic complexity for databases includes the theory of maintaining materialized views upon updates ([J92], [GMS93], <ref> [Io85] </ref>), and in integrity constraint simplification ([LST87], [N82]). The design of dynamic algorithms is an active field. See, for example, [E + 92], [E + 92b], [R94], [CT91], [F85], [F91] among many others.
Reference: [J92] <author> H. Jakobsson, </author> <title> "On Materializing Views and On-line Queries," </title> <booktitle> Proceedings of International Conference on Database Theory, </booktitle> <address> Berlin, </address> <year> (1992), </year> <pages> 407-420. </pages>
Reference: [LT94] <author> Y. Liu and T. Teitelbaum, </author> <title> "Systematic Derivation of Incremental Programs," </title> <booktitle> Science of Computer Programming 24 (1995), </booktitle> <pages> 1-39. </pages>
Reference-contexts: The design of dynamic algorithms is an active field. See, for example, [E + 92], [E + 92b], [R94], [CT91], [F85], [F91] among many others. There is also a large amount of work in the programming language community on incremental computation, see for example <ref> [RR96, LT94] </ref>. 2 This paper is organized as follows. In Section 2, we begin with some background on Descrip--tive Complexity. In Section 3, for any static complexity class C, we define the corresponding dynamic class, Dyn-C. The class Dyn-FO is the case we emphasize.
Reference: [LST87] <author> J. W. LLoyd, E. A. Sonenberg and R. W. Topor, </author> <title> "Integrity Constraint Checking in Stratified Databases," </title> <journal> Journal of Logic Programming, </journal> <volume> 4(4) </volume> <pages> 334-343, </pages> <year> 1987. </year> <month> 18 </month>
Reference: [MI94] <author> J.A. Medina and N. Immerman, </author> " <title> A Syntactic Characterization of NP--Completeness," </title> <booktitle> IEEE Symp. Logic In Comput. Sci. </booktitle> <year> (1994), </year> <pages> 241-250. </pages>
Reference-contexts: Bounded-expansion reductions with precomputation are an appropriate reduction for com paring the dynamic complexity of problems. We also note that most natural reductions for P-complete and NP-complete problems are either bounded expansion, or can be easily modified to be so (see [P94], <ref> [MI94] </ref>). We give one such example here: Proposition 5.5 REACH a and CVAL are complete for P via bfo + reductions. Proof REACH a is the reachability problem for alternating graphs. It is equivalent to CVAL the circuit value problem.
Reference: [M93] <author> P. B. Miltersen. </author> <title> "The Bit Probe Complexity Measure Revisited," </title> <booktitle> Proceedings of the Tenth Symposium on Theoretical Aspects of Computer Science (1993). </booktitle>
Reference-contexts: In [TY79], Tarjan and Yao propose a dynamic model whose complexity measure is the number of probes into a data structure and any other computation is free. A log n= log log n lower bound on a dynamic prefix multiplication problem was proved in [FS89]. Other lower bounds <ref> [M93] </ref>, [R94] have been proved using these methods. Other work on dynamic complexity for databases includes the theory of maintaining materialized views upon updates ([J92], [GMS93], [Io85]), and in integrity constraint simplification ([LST87], [N82]). The design of dynamic algorithms is an active field.
Reference: [MSV94] <author> Peter Bro Miltersen, Sairam Subramanian, Jeffrey Scott Vitter, and Roberto Tamassia, </author> <title> "Complexity Models for Incremental Computation," </title> <institution> Theo-ret. Comp. Sci. </institution> <month> (130:1) </month> <year> (1994), </year> <pages> 203-236. </pages>
Reference-contexts: For example: texing a file, compiling a program, processing a visual scene, performing a complicated calculation in Mathematica, etc. Yet an adequate theory of dynamic complexity is lacking. (Recently, there have been some significant contributions in this direction, e.g. <ref> [MSV94] </ref>. Note that dynamic complexity is different although somewhat related to on-line complexity which is receiving a great deal of attention lately.) We will define the complexity class Dyn-FO to be the set of dynamic problems that can be expressed in first-order logic. <p> In [P94] it is shown that some NP-complete problems admit Dyn-FO approximation algorithms. Dong and Su [DS93] showed that reachability in directed, acyclic graphs and in function graphs is in Dyn-FO. The static versions of all these problems are not first-order. Related work on dynamic complexity appears in <ref> [MSV94] </ref>. In [DST93] first-order incremental evaluation system (FOIES) are defined. A problem has an FOIES iff it is in Dyn-FO. In [TY79], Tarjan and Yao propose a dynamic model whose complexity measure is the number of probes into a data structure and any other computation is free. <p> For these classes first order reductions are too powerful. We restrict them by imposing the following expansion property, cf. <ref> [MSV94] </ref> for a similar restriction. Definition 5.1 Bounded expansion, first-order reductions (bfo) are first-order reductions (Definition 2.2) such that each tuple in a relation and each constant of the input structure affects at most a constant number of tuples and constants in the output structure. <p> The reason this mapping is not bounded expansion is that many different nodes in the computation tree might read a particular bit of w and thus have an edge to a next node according to the value of this bit. A variant of REACH called COLOR-REACH is invented in <ref> [MSV94] </ref> to finesse this 15 difficulty. An input to COLOR-REACH consists of a directed graph with outdegree at most two with the outgoing edges labeled zero and one. There is a given partition of the vertices V = V 0 [ V 1 [ [ V r . <p> Corollary 5.12 COLOR-REACH d is complete for L via bfo + reductions, and COLOR-Q (S 5 ) is complete for NC 1 via bfo + reductions. Another idea from <ref> [MSV94] </ref> indicates that dynamic complexity classes may not be as robust under changes to the form of the input as static classes are: Definition 5.13 ([MSV94]) For any problem S, define the padded form of S as follows: PAD (S) = fw 1 ; w 2 ; : : : ;
Reference: [N82] <author> J-M. Nicolas, </author> <title> "Logic for Improving Integrity Checking in Relational Databases," </title> <journal> Acta Informatica, </journal> <month> (18:3) </month> <year> (1982), </year> <pages> 227-253. </pages>
Reference-contexts: Other lower bounds [M93], [R94] have been proved using these methods. Other work on dynamic complexity for databases includes the theory of maintaining materialized views upon updates ([J92], [GMS93], [Io85]), and in integrity constraint simplification ([LST87], <ref> [N82] </ref>). The design of dynamic algorithms is an active field. See, for example, [E + 92], [E + 92b], [R94], [CT91], [F85], [F91] among many others.
Reference: [P94] <author> S. Patnaik, </author> <title> "The Dynamic Complexity of Approximation," </title> <type> Manuscript, </type> <institution> Computer Science Dept., University of Massachusetts (1994). </institution>
Reference-contexts: The problems we show to be in Dyn-FO include: reachability in undirected graphs, maintaining a minimum spanning forest, k-edge connectivity and bipartiteness. All regular languages are shown to be in Dyn-FO. In <ref> [P94] </ref> it is shown that some NP-complete problems admit Dyn-FO approximation algorithms. Dong and Su [DS93] showed that reachability in directed, acyclic graphs and in function graphs is in Dyn-FO. The static versions of all these problems are not first-order. Related work on dynamic complexity appears in [MSV94]. <p> Bounded-expansion reductions with precomputation are an appropriate reduction for com paring the dynamic complexity of problems. We also note that most natural reductions for P-complete and NP-complete problems are either bounded expansion, or can be easily modified to be so (see <ref> [P94] </ref>, [MI94]). We give one such example here: Proposition 5.5 REACH a and CVAL are complete for P via bfo + reductions. Proof REACH a is the reachability problem for alternating graphs. It is equivalent to CVAL the circuit value problem.
Reference: [PI94] <author> S. Patnaik and N. Immerman, </author> <title> "Dyn-FO: A Parallel, Dynamic Complexity Class," </title> <booktitle> ACM Symp. Principles Database Systems (1994), </booktitle> <pages> 210-221. </pages>
Reference-contexts: Also, new paths have to be added as a result of the insertion of a new edge in the forest. PV 0 (x; y; z) T (x; y; z) _ [(9u; v)(New (u; v) _ New (v; u)) ^ T (x; u; x) 2 In <ref> [PI94] </ref> we asked if the proof of Theorem 4.1 could be carried out using auxiliary relations of arity two instead of three. Quite recently Dong and Su have shown that the answer is yes [DS95].
Reference: [RR96] <author> G. Ramalingam and T. </author> <title> Reps "On the computational complexity of dynamic graph problems," </title> <type> Theoret. </type> <institution> Comp. Sci. </institution> <month> 158(1-2) </month> <year> (1996), </year> <pages> 233-277. </pages>
Reference-contexts: The design of dynamic algorithms is an active field. See, for example, [E + 92], [E + 92b], [R94], [CT91], [F85], [F91] among many others. There is also a large amount of work in the programming language community on incremental computation, see for example <ref> [RR96, LT94] </ref>. 2 This paper is organized as follows. In Section 2, we begin with some background on Descrip--tive Complexity. In Section 3, for any static complexity class C, we define the corresponding dynamic class, Dyn-C. The class Dyn-FO is the case we emphasize.
Reference: [R94] <author> M. Rauch. </author> " <title> Improved Data Structures for Fully Dynamic Biconnectivity," </title> <booktitle> ACM Symp. Theory Of Comput. </booktitle> <year> (1994), </year> <pages> 686-695. </pages>
Reference-contexts: In [TY79], Tarjan and Yao propose a dynamic model whose complexity measure is the number of probes into a data structure and any other computation is free. A log n= log log n lower bound on a dynamic prefix multiplication problem was proved in [FS89]. Other lower bounds [M93], <ref> [R94] </ref> have been proved using these methods. Other work on dynamic complexity for databases includes the theory of maintaining materialized views upon updates ([J92], [GMS93], [Io85]), and in integrity constraint simplification ([LST87], [N82]). The design of dynamic algorithms is an active field. <p> Other work on dynamic complexity for databases includes the theory of maintaining materialized views upon updates ([J92], [GMS93], [Io85]), and in integrity constraint simplification ([LST87], [N82]). The design of dynamic algorithms is an active field. See, for example, [E + 92], [E + 92b], <ref> [R94] </ref>, [CT91], [F85], [F91] among many others. There is also a large amount of work in the programming language community on incremental computation, see for example [RR96, LT94]. 2 This paper is organized as follows. In Section 2, we begin with some background on Descrip--tive Complexity.
Reference: [TY79] <author> R. Tarjan and A. Yao, </author> <title> "Storing a Sparse Table," </title> <booktitle> Communications of the ACM 22:11 (1979), </booktitle> <pages> 606-611. </pages>
Reference-contexts: The static versions of all these problems are not first-order. Related work on dynamic complexity appears in [MSV94]. In [DST93] first-order incremental evaluation system (FOIES) are defined. A problem has an FOIES iff it is in Dyn-FO. In <ref> [TY79] </ref>, Tarjan and Yao propose a dynamic model whose complexity measure is the number of probes into a data structure and any other computation is free. A log n= log log n lower bound on a dynamic prefix multiplication problem was proved in [FS89].
References-found: 35

