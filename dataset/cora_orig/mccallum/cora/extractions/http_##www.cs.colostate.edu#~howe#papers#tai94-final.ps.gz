URL: http://www.cs.colostate.edu/~howe/papers/tai94-final.ps.gz
Refering-URL: http://www.cs.colostate.edu/~howe/pubs.html
Root-URL: 
Email: howe@cs.colostate.edu  
Title: Methods for Finding Influences on Program Failure  
Author: Adele E. Howe Aaron D. Fuegi 
Address: Fort Collins, CO 80524  
Affiliation: Computer Science Department Colorado State University  
Abstract: This paper describes two approaches for detecting patterns of detrimental program behavior, called dependencies, over long periods of time; these dependencies indicate cases where previous events influence the occurrence of later failure. This research extends a previous approach that was limited to temporally adjacent events. The two approaches, heuristic search and local search, are demonstrated on several data sets from an AI planner and are compared on their efficiency and the dependencies they detect. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Peter C. Bates and Jack C. Wileden. </author> <title> High-level debugging of distributed systems: The behavioral abstraction approach. </title> <type> COINS Dept. TR 83-29, </type> <institution> Univ. of Mass., </institution> <month> March </month> <year> 1983. </year>
Reference-contexts: Two other approaches to modeling software bugs are a formal language for describing program failures <ref> [1] </ref> and a belief network of canonical bugs [2]. These models are constructed all or in large part by a programmer. Statistically Modeling Causal Influences Recent research has emphasized causal induction, inferring causal structure from observational data.
Reference: [2] <author> Lisa J. Burnell and Scott E. </author> <title> Talbot. Incorporating probabilistic reasoning in a reactive program debugging system. </title> <booktitle> In Proceedings of the Ninth Conference on Artificial Intelligence for Applications, pages 321 -327, </booktitle> <address> Orlando, FL, </address> <month> March 1-5 </month> <year> 1993. </year>
Reference-contexts: Two other approaches to modeling software bugs are a formal language for describing program failures [1] and a belief network of canonical bugs <ref> [2] </ref>. These models are constructed all or in large part by a programmer. Statistically Modeling Causal Influences Recent research has emphasized causal induction, inferring causal structure from observational data. One well-known approach [7] infers causal relationships from covariance data by testing conditional independence of variables.
Reference: [3] <author> Paul R. Cohen, Lisa A. Ballesteros, Dawn E. Gre-gory, and Robert St. Amant. </author> <title> Regression can build predictive causal models. </title> <type> TR 94-15, </type> <institution> Computer Science, Univ. of Mass., </institution> <year> 1994. </year>
Reference-contexts: Statistically Modeling Causal Influences Recent research has emphasized causal induction, inferring causal structure from observational data. One well-known approach [7] infers causal relationships from covariance data by testing conditional independence of variables. Another approach by Cohen et. al <ref> [3] </ref> extends statistical path analysis to construct the structure of the causal model (i.e., the relationships between variables and the directionality of the relationships) as well as to estimate the strength of those relationships.
Reference: [4] <author> Adele E. Howe. </author> <title> Analyzing failure recovery to improve planner design. </title> <booktitle> In Proceedings of the Tenth National Conference on Artificial Intelligence, </booktitle> <pages> pages 387-393, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: Local search appears to be an efficient method of finding highly significant relative order dependencies. 3 Summary Evaluation largely depends on whether models are found to be useful for characterizing behavior. Dependency detection was incorporated into a procedure for debugging Phoenix called Failure Recovery Analysis (FRA) <ref> [4] </ref>. Dependency detection identifies problematic sequences of events, which FRA relates to portions of the knowledge base and then generates explanations of how the knowledge base may have contributed to the observed dependencies.
Reference: [5] <author> Adele E. Howe and Paul R. Cohen. </author> <title> Isolating dependencies on failure by analyzing execution traces. </title> <booktitle> In Artificial Intelligence Planning Systems: Proceedings of the First International Conference, </booktitle> <address> College Park, MD, </address> <year> 1992. </year>
Reference-contexts: In this paper, we will describe two statistical methods for finding detrimental patterns (combinations of possible causes and failure) in execution traces. These methods extend previous work on finding discrete causal influences over short time horizons <ref> [5] </ref> and have been applied primarily to identifying causes of failure in a planning system. 1.1 Previous Approaches to Solution Generally speaking, the problem is modeling causal influences on failure. We wish to know whether one event influences the occurrence of another. <p> However, they do not allow cycles in the models and require covariance information, which means that the underlying variables should be numeric. 2 Dependency Detection An approach to modeling short-term categorical causal influences on failure is Dependency Detection <ref> [5] </ref>. Dependency Detection applies statistical techniques to build a set of simple models of failure. Like the above approaches to modeling failures, it relates 1 alternative paths to a particular failure; unlike these approaches, it does not do so a priori and a human is not involved in the process.
Reference: [6] <author> Nancy G. Leveson. </author> <title> Software safety: Why, what, and how. </title> <journal> Computing Surveys, </journal> <volume> 18(2) </volume> <pages> 125-163, </pages> <month> June </month> <year> 1986. </year>
Reference-contexts: Approaches to fault tolerance decide how to avoid or repair failures through a complete model, built by an expert, of failure and its causes; common techniques are time Petri net models, real-time logic and fault tree analysis <ref> [6] </ref>. Two other approaches to modeling software bugs are a formal language for describing program failures [1] and a belief network of canonical bugs [2]. These models are constructed all or in large part by a programmer.
Reference: [7] <author> Judea Pearl and T. S. Verma. </author> <title> A theory of inferred causation. </title> <booktitle> In Principles of Knowledge Representation and Reasoning: Proceedings of the Second International Conference, </booktitle> <address> April 1991. </address> <publisher> Morgan Kauf-mann. </publisher>
Reference-contexts: These models are constructed all or in large part by a programmer. Statistically Modeling Causal Influences Recent research has emphasized causal induction, inferring causal structure from observational data. One well-known approach <ref> [7] </ref> infers causal relationships from covariance data by testing conditional independence of variables.
References-found: 7

