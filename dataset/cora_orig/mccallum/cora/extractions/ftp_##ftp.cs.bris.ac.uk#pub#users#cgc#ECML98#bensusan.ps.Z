URL: ftp://ftp.cs.bris.ac.uk/pub/users/cgc/ECML98/bensusan.ps.Z
Refering-URL: http://www.cs.bris.ac.uk/~cgc/ECML98-WS/Summary.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: Email: hilanb@cogs.susx.ac.uk  
Title: Odd bites into bananas don't make you blind learning about simplicity and attribute addition  
Author: Hilan Bensusan 
Note: 30  
Address: Falmer, Brighton BN1 9QH, UK  
Affiliation: School of Cognitive and Computing Sciences University of Sussex  
Abstract: Once upon a time there was a little girl named Emma. She had never eaten banana in all her life nor had she ever taken a journey on a train. On one occasion circumstances made necessary for her to journey from New York to Pittsburgh alone. To relieve Emma's anxiety her mother gave her a large bag of bananas to eat on her railway journey west. At Emma's first bite of her banana, the train plunged into a tunnel. At the second bite, the train broke into the daylight again. Emma, being a bright little girl, takes a third bite. Lo! Into a tunnel. A fourth bite and into the daylight again. And so on all the way to Pittsburgh (and all the way to the bottom of the bag of bananas). Is Emma justified in saying to the people who met her at the station, "Every odd bite of a banana makes you blind; every even bite puts things right again?"N. H. Hanson, [12] p. 359 This paper shows how a meta-learning technique can be applied to decisions about pruning and representation adequacy. It describes a meta-learning technique that uses unpruned decision trees and information from decision tree construction to describe the learning tasks. Based on previous experience, a meta-learner decides which attribute addition strategy is the more appropriate for a given new learning problem. The technique is applied to simplicity and representation issues. In the simplicity camp, it is used to decide when to prune, how much pruning is appropriate and what the best pruning technique is for a given learning task. In constructive induction, it is used to decide between a pool of alternative new attribute constructors. Results suggest that induction on the connection between problems and simplicity and representation biases improves learning performance 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> H. Bensusan. </author> <title> God doesn't always shave with Occam's Razor learning when and how to prune. </title> <booktitle> Proceedings of the 10th European Conference on Machine Learning, </booktitle> <year> 1998. </year>
Reference-contexts: Their learning biases is attuned to their world. This paper explores the advantages of using a bias chosen by a meta-learner to take decisions about pruning and to improve the input representation. It describes how a meta-learning system (The Entrencher, see <ref> [1, 2] </ref>) that selects a bias from a pool can be used to find an appropriate attribute to be added to the original attribute vector and can decide if, how and how much pruning is needed.
Reference: [2] <author> H. Bensusan and P. Williams. </author> <title> Learning to learn boolean tasks by decision tree descriptors. </title> <editor> In M. V. Someren and G. Widmer, editors, </editor> <booktitle> Poster Papers 9th European Conference on Machine Learning, </booktitle> <pages> pages 1-11. </pages> <year> 1997. </year>
Reference-contexts: Their learning biases is attuned to their world. This paper explores the advantages of using a bias chosen by a meta-learner to take decisions about pruning and to improve the input representation. It describes how a meta-learning system (The Entrencher, see <ref> [1, 2] </ref>) that selects a bias from a pool can be used to find an appropriate attribute to be added to the original attribute vector and can decide if, how and how much pruning is needed. <p> The system acts as follows: 1. Applies all the learners in the bias pool to the training problems and tests their performance; 1 This is a development of the system described in <ref> [2] </ref>. 31 2. Classifies the problems in terms of the best performing bias; 3.
Reference: [3] <author> A. Blumer, A. Ehrenfeucht, D. Haussler, and M. Warmuth. </author> <title> Learnability and the Vapnik-Chervonenkis dimension. </title> <journal> Journal of the ACM, </journal> <volume> 36(4) </volume> <pages> 929-965, </pages> <year> 1989. </year>
Reference-contexts: The fundamental element of a system that re-represents by adding new attributes is a set of operators often called constructors to be applied to current attributes in order to produce the attributes to be added. Many systems have a fixed set 6 Refer to <ref> [3] </ref> about VC dimension 37 No pruning Cost-complexity pruning Error-based pruning Average peformance 71.96 68.59 72.17 Standard deviation 8.49 8.29 8.50 Table 1: Performance of the pruning options in all the problems of constructors [20, 18].
Reference: [4] <author> A. Blumer, A. Ehrenfeucht, D. Haussler, and M. K. Warmuth. </author> <title> Occam's razor. </title> <journal> Information Processing Letters, </journal> <volume> 24(6) </volume> <pages> 377-380, </pages> <year> 1987. </year>
Reference-contexts: If Occam razor is not a graal, we need to decide when to use it. We also need to establish, for each learning task, how and how much should we prune. There were various theoretical attempts to establish conditions under which simpler hypotheses are better, both in general <ref> [4] </ref> and within the context of decision tree induction [23, 10, 11]. These are to be considered within their own established limits and as worst case results. Under these limitations, these results can seldom be applied to the practitioner's decisions about how simple should the conjectured decision tree be.
Reference: [5] <author> P. Chan and S. Stolfo. </author> <title> Experiments on multistrategy learning by meta-learning. </title> <booktitle> In Proceedings of the second international conference on information and knowledge management, </booktitle> <pages> pages 314-323, </pages> <year> 1993. </year>
Reference-contexts: Section 5 reports results about representation improvement and section 6 concludes the paper. 1 The system The Entrencher system 1 learns to choose the best learning bias for a learning task among the ones provided in a bias pool. Therefore, it performs a kind of meta-learning. Chan & Stolfo <ref> [5] </ref> define meta-learning as "learning from information generated by learners". The Entrencher uses the decision tree generated from the training set and related information to describe a learning task. The Entrencher then performs a supervised meta-learning on a set of classified problems divided into training and test sets.
Reference: [6] <author> M. Craven and J. Shavlik. </author> <title> Investigating the value of a good input representation. </title> <editor> In T. Petsche, S. Judd, and S. Hanson, editors, </editor> <booktitle> Computational Learning Theory and Natural Learning Systems, </booktitle> <volume> volume 3. </volume> <publisher> MIT Press, </publisher> <address> Cambridge, Mass., USA, </address> <year> 1995. </year>
Reference-contexts: As the training set size increases The Entrencher's curve approaches "best" and when the training set size is greater than 160, the system consistently outperforms the fixed pruning alternatives. 36 4 Representation bias The input representation of a problem essentially influences the overall learning performance <ref> [6] </ref>. Since learning biases deal in representations, a good amount of effort has been put in finding appropriate strategies to improve the input description of a problem such that learning becomes easier for a given bias.
Reference: [7] <author> T. G. Dieterich and E. B. Kong. </author> <title> Machine learning bias, statistical bias, and statistical variance of decision tree algorithms. </title> <type> Technical report, </type> <institution> Department of Computer Science, Oregon State University, Corvallis, </institution> <address> OR, USA, </address> <year> 1995. </year>
Reference-contexts: One can ground the use of the razor on some sort of analysis of induction by appealing to the greater plausibility (or prior probability) of simpler hypotheses [13]. However, measures of simplicity are bound to be representation relative and therefore simplicity becomes a form of soft bias <ref> [27, 7] </ref>. In the context of decision tree induction, the Occam's principle is often mentioned to justify a preference for simpler trees. This has led to the idea that pruned decision trees are likely to exhibit better test set accuracy.
Reference: [8] <author> T. G. Dietterich. </author> <title> Machine learning research: Four current directions. </title> <publisher> In press, </publisher> <year> 1997. </year>
Reference-contexts: In both cases of learning pruning strategies and performing constructive induction, the system, when sufficiently trained, performs better than a fixed bias. Future work includes comparing meta-learning with The Entrencher to results achieved by other multi-bias strategies, especially with ensembling <ref> [8] </ref>. In any case, meta-learning seems to have a safe place among a repository of good mechanical induction procedures. The Entrencher implements a decisive feature of human successful inductive hypotheses: their roots are in our inductive knowledge of the environment. Emma didn't lack anything but inductive experience.
Reference: [9] <author> S. B. Thrun et al. </author> <title> The monk's problems a performance comparison of different learning algorithms. </title> <type> Technical Report CMU-CS-91-197, </type> <institution> School of Computer Science, Carnegie-Mellon University., </institution> <address> Pittsburgh, PA - USA, </address> <year> 1991. </year>
Reference-contexts: Section 1 describes the components of The Entrencher. and the Monkspace, a class of problems similar to the original Monk problems <ref> [9] </ref> and that is used in the experiments to be reported. Section 2 introduces the debates on simplicity and the different alternative pruning strategies. Section 3 reports experiments and results concerning simplicity choices. Section 4 introduces the issue of improving input representation and describes alternative new attribute constructors. <p> This artificial domain, that I shall refer hereafter as the Monkspace, consists of Monk-like problem types, including the 3 Monk problems reported in <ref> [9] </ref>. Given the original 6 attributes of the Monk problems, there are 2 432 possible classifications. For the current experiments, a number of classifications were chosen and 10 problems, composed by training and a test sets, were constructed for each classification.
Reference: [10] <author> U. M. Fayyad and K. B. Irani. </author> <title> What should be minimized in a decision tree? In William Dietterich, </title> <editor> Tom; Swartout, editor, </editor> <booktitle> Proceedings of the 8th National Conference on Artificial Intelligence, </booktitle> <pages> pages 749-754. </pages> <publisher> MIT Press, </publisher> <month> July 29-August 3 </month> <year> 1990. </year>
Reference-contexts: We also need to establish, for each learning task, how and how much should we prune. There were various theoretical attempts to establish conditions under which simpler hypotheses are better, both in general [4] and within the context of decision tree induction <ref> [23, 10, 11] </ref>. These are to be considered within their own established limits and as worst case results. Under these limitations, these results can seldom be applied to the practitioner's decisions about how simple should the conjectured decision tree be.
Reference: [11] <author> D. Gamberger and N. Lavrac. </author> <title> Conditions for Occam's Razor applicability and noise elimination. </title> <editor> In Marteen van Someren and Gerhard Widmer, editors, </editor> <booktitle> Proceedings of the 9th European Conference on Machine Learning, </booktitle> <pages> pages 108-123. </pages> <publisher> Springer, </publisher> <year> 1997. </year>
Reference-contexts: We also need to establish, for each learning task, how and how much should we prune. There were various theoretical attempts to establish conditions under which simpler hypotheses are better, both in general [4] and within the context of decision tree induction <ref> [23, 10, 11] </ref>. These are to be considered within their own established limits and as worst case results. Under these limitations, these results can seldom be applied to the practitioner's decisions about how simple should the conjectured decision tree be.
Reference: [12] <author> N. R. Hanson. </author> <title> Perception and Discovery. </title> <publisher> Freeman and Cooper Co, </publisher> <address> USA, </address> <year> 1969. </year>
Reference: [13] <author> P. S. </author> <title> Laplace. A Philosophical Essay on Probabilities. </title> <publisher> Dover, </publisher> <address> UK, </address> <year> 1952. </year>
Reference-contexts: In many contexts, both scientists and laymen would appeal to simplicity to decide between different alternatives. One can ground the use of the razor on some sort of analysis of induction by appealing to the greater plausibility (or prior probability) of simpler hypotheses <ref> [13] </ref>. However, measures of simplicity are bound to be representation relative and therefore simplicity becomes a form of soft bias [27, 7]. In the context of decision tree induction, the Occam's principle is often mentioned to justify a preference for simpler trees.
Reference: [14] <author> Y. Mansour. </author> <title> Pessimistic decision tree pruning based on tree size. </title> <booktitle> In Proc. 14th International Conference on Machine Learning, </booktitle> <pages> pages 195-201. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1997. </year>
Reference-contexts: The performances were compared to the best possible 4 Refer to [17] for an a slightly outdated overview and an experimental comparison. 5 Recently an alternative pessimistic pruning was reported to have similar performance and to enjoy sounder justification <ref> [14] </ref>. 35 pruning option available for each problem and with the fixed different pruning options. In the graphs that report the experiments, the Y -axis is the accuracy in the test sets of 50 problems and the X-axis represents the training set sizes.
Reference: [15] <author> C Matheus. </author> <title> Feature construction: an analytic framework and an application to decision trees. </title> <type> Technical Report CSR-89-1559, </type> <institution> Department of Computer Science, University of Illinois, Urbana, IL,USA, </institution> <year> 1989. </year> <month> 41 </month>
Reference-contexts: This effort is often conceived as part of the learning process since a better input representation is expected to emerge from the interaction between the problem and the learner <ref> [15, 24, 30] </ref>. Learners that have the ability to search for different input descriptions are often called constructive learners.
Reference: [16] <author> J. S. Mill. </author> <title> A system of logic. </title> <journal> Longmans, London, </journal> <volume> 1843. </volume>
Reference-contexts: J. S. Mill <ref> [16] </ref>, III, III, 3.205 The Entrencher successfully learns connections between tasks and biases. The results above show that the appeal to previously learned problems is an appropriate strategy 39 to improve performance (or to decrease the number of instances required for induction).
Reference: [17] <author> J. Mingers. </author> <title> An empirical comparison of pruning methods for decision tree induction. </title> <journal> Machine Learning, </journal> <volume> 4 </volume> <pages> 227-243, </pages> <year> 1989. </year>
Reference-contexts: The meta-learning system was trained on an increasing number of problems and then tested on different test sets of problems randomly drawn from the 1000 existing problems. The performances were compared to the best possible 4 Refer to <ref> [17] </ref> for an a slightly outdated overview and an experimental comparison. 5 Recently an alternative pessimistic pruning was reported to have similar performance and to enjoy sounder justification [14]. 35 pruning option available for each problem and with the fixed different pruning options.
Reference: [18] <author> P. Murphy and M. Pazzani. Id2of3: </author> <title> Constructive induction of m-of-n concepts for discriminators in decision trees. </title> <booktitle> In Proceedings of the Eight International Machine Learning Conference, </booktitle> <address> San Mateo, CA, USA, 1991. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Many systems have a fixed set 6 Refer to [3] about VC dimension 37 No pruning Cost-complexity pruning Error-based pruning Average peformance 71.96 68.59 72.17 Standard deviation 8.49 8.29 8.50 Table 1: Performance of the pruning options in all the problems of constructors <ref> [20, 18] </ref>. As a consequence, they have a fixed constructive bias and weaken the overall bias of the system always in the same manner. The Entrencher can be invoked to choose between different constructors within a constructive bias pool.
Reference: [19] <author> P. Murphy and M. Pazzani. </author> <title> Exploring the decision forest: An emprical imvestigation of occam's razor in decision tree induction. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 1 </volume> <pages> 257-275, </pages> <year> 1994. </year>
Reference-contexts: This has led to the idea that pruned decision trees are likely to exhibit better test set accuracy. However, recent experimental work has shown that larger trees sometimes perform better <ref> [25, 19, 26, 28] </ref>. The point was not only to show that the simplicity bias fails for some tasks but also to suggest that some of these tasks might belong to the so-called real world tasks class.
Reference: [20] <author> G. Pagallo and D. Haussler. </author> <title> Boolean feature discovery in empirical learning. </title> <journal> Machine Learning, </journal> <volume> 5 </volume> <pages> 71-100, </pages> <year> 1990. </year>
Reference-contexts: Many systems have a fixed set 6 Refer to [3] about VC dimension 37 No pruning Cost-complexity pruning Error-based pruning Average peformance 71.96 68.59 72.17 Standard deviation 8.49 8.29 8.50 Table 1: Performance of the pruning options in all the problems of constructors <ref> [20, 18] </ref>. As a consequence, they have a fixed constructive bias and weaken the overall bias of the system always in the same manner. The Entrencher can be invoked to choose between different constructors within a constructive bias pool.
Reference: [21] <author> J. R. Quinlan. </author> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1(1) </volume> <pages> 81-106, </pages> <year> 1986. </year>
Reference-contexts: Quinlan's C4.5 system popularised error-based pruning, the weakness of its heuristic-based justification notwithstanding 5 . A major alternative to the error-based approach is the cost-complexity pruning approach that has been adopted by some TDIDT systems such as Quinlan's ID3 <ref> [21] </ref>. It can be seen as a direct application of the minimal encoding principles, that involve the search for a balance between simplicity and consistency. For the experiments reported here, Quinlan's error-based strategy Sand a cost-complexity pruning strategy are considered.
Reference: [22] <author> J. R. Quinlan. C4.5: </author> <title> Programs for Machine Learning. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, USA, </address> <year> 1993. </year>
Reference-contexts: A meta-learner generates a bias classifier that selects a bias for each test problem among the ones in the bias pool. The Entrencher uses a TDIDT (top-down induction of decision trees) procedure as baseline learner. In fact, this baseline learner is similar to a non-pruning C4.5 <ref> [22] </ref>. The baseline learner provides a working representation of the problems as a decision tree which is encoded in terms of a descriptor vector that consists of the following real-valued descriptors: Tree nodes per attribute: The proportion of tree nodes per attribute. <p> Also, Quinlan's pruning requires no independent validation data set. Different levels of error-based pruning are given by different confidence levels in the reliability of the sample as an indicator of how many errors are to be expected by a given decision node <ref> [22] </ref>. The other strategy considered is a cost-complexity technique that has the two features of Quinlan's strategy mentioned above: the pruned tree is generated from the complete original tree and no validation data set is required.
Reference: [23] <author> J. R. Quinlan and R. L. Rivest. </author> <title> Inferring decision trees using the Minimum Description Length Principle. </title> <journal> Inform. Comput., </journal> <volume> 80(3) </volume> <pages> 227-248, </pages> <month> March </month> <year> 1989. </year> <note> (An early version appeared as MIT LCS Technical report MIT/LCS/TM-339 (September 1987).). </note>
Reference-contexts: We also need to establish, for each learning task, how and how much should we prune. There were various theoretical attempts to establish conditions under which simpler hypotheses are better, both in general [4] and within the context of decision tree induction <ref> [23, 10, 11] </ref>. These are to be considered within their own established limits and as worst case results. Under these limitations, these results can seldom be applied to the practitioner's decisions about how simple should the conjectured decision tree be.
Reference: [24] <author> L. Rendell and H. Cho. </author> <title> Empirical learning as a function of concept character. </title> <journal> Machine Learning, </journal> <volume> 5 </volume> <pages> 267-298, </pages> <year> 1990. </year>
Reference-contexts: This effort is often conceived as part of the learning process since a better input representation is expected to emerge from the interaction between the problem and the learner <ref> [15, 24, 30] </ref>. Learners that have the ability to search for different input descriptions are often called constructive learners.
Reference: [25] <author> C. Schaffer. </author> <title> Overfitting avoidance as bias. </title> <journal> Machine Learning, </journal> <volume> 10 </volume> <pages> 113-152, </pages> <year> 1993. </year>
Reference-contexts: This has led to the idea that pruned decision trees are likely to exhibit better test set accuracy. However, recent experimental work has shown that larger trees sometimes perform better <ref> [25, 19, 26, 28] </ref>. The point was not only to show that the simplicity bias fails for some tasks but also to suggest that some of these tasks might belong to the so-called real world tasks class.
Reference: [26] <author> W. M. Spears and D. F. Gordon. </author> <title> A simpler look at consistency. </title> <type> Technical Report AIC-94-018, </type> <institution> Naval Research Laboratory, Navy Center for Applied Research on Artificial Intelligence, </institution> <address> Washington, DC, USA, </address> <year> 1994. </year>
Reference-contexts: This has led to the idea that pruned decision trees are likely to exhibit better test set accuracy. However, recent experimental work has shown that larger trees sometimes perform better <ref> [25, 19, 26, 28] </ref>. The point was not only to show that the simplicity bias fails for some tasks but also to suggest that some of these tasks might belong to the so-called real world tasks class.
Reference: [27] <author> P. Utgoff. </author> <title> Shift of bias for inductive concept learning. </title> <booktitle> In Machine Learning: An Artificial Intelligence Approach, volume III. </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, USA, </address> <year> 1986. </year>
Reference-contexts: One can ground the use of the razor on some sort of analysis of induction by appealing to the greater plausibility (or prior probability) of simpler hypotheses [13]. However, measures of simplicity are bound to be representation relative and therefore simplicity becomes a form of soft bias <ref> [27, 7] </ref>. In the context of decision tree induction, the Occam's principle is often mentioned to justify a preference for simpler trees. This has led to the idea that pruned decision trees are likely to exhibit better test set accuracy.
Reference: [28] <author> G. Webb. </author> <title> Further experimental evidence against the utility of occam's razor. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 4 </volume> <pages> 397-417, </pages> <year> 1996. </year>
Reference-contexts: This has led to the idea that pruned decision trees are likely to exhibit better test set accuracy. However, recent experimental work has shown that larger trees sometimes perform better <ref> [25, 19, 26, 28] </ref>. The point was not only to show that the simplicity bias fails for some tasks but also to suggest that some of these tasks might belong to the so-called real world tasks class. <p> The point was not only to show that the simplicity bias fails for some tasks but also to suggest that some of these tasks might belong to the so-called real world tasks class. For example, Webb <ref> [28, 29] </ref> reports that his grafting procedures inductive processes that add complexity to a decision tree by considering global rather than local information enhance accuracy in the widely used UCI repository tasks. If Occam razor is not a graal, we need to decide when to use it.
Reference: [29] <author> G. Webb. </author> <title> Decision tree grafting. </title> <booktitle> In Proceedings of the Fifteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 846-851, </pages> <address> Nagoya, Japan, 1997. </address> <publisher> Morgan Kaufman. </publisher>
Reference-contexts: The point was not only to show that the simplicity bias fails for some tasks but also to suggest that some of these tasks might belong to the so-called real world tasks class. For example, Webb <ref> [28, 29] </ref> reports that his grafting procedures inductive processes that add complexity to a decision tree by considering global rather than local information enhance accuracy in the widely used UCI repository tasks. If Occam razor is not a graal, we need to decide when to use it.
Reference: [30] <author> J. Wnek and R. S. Michalski. </author> <title> Hypothesis- driven constructive induction in AQ17: A method and experiments. </title> <journal> Machine Learning, </journal> <volume> 14 </volume> <pages> 139-169, </pages> <year> 1994. </year> <month> 42 </month>
Reference-contexts: This effort is often conceived as part of the learning process since a better input representation is expected to emerge from the interaction between the problem and the learner <ref> [15, 24, 30] </ref>. Learners that have the ability to search for different input descriptions are often called constructive learners.
References-found: 30

