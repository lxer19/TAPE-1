URL: ftp://ftp.cs.umd.edu/pub/papers/papers/3211.1/3211.1.ps.Z
Refering-URL: http://www.cs.umd.edu/TRs/TR.html
Root-URL: 
Title: THE ORTHOGONAL QD-ALGORITHM shift strategy of the orthogonal qd-algorithm is based on Laguerre's method, which
Author: Urs von Matt 
Keyword: Key words. Generalized Givens transformation, implicit Cholesky decomposition, Laguerre's method, orthogonal qd-algorithm, singular value decomposition.  
Note: The  this shift.  AMS subject classifications. 65F20.  
Date: January, 1994 revised September, 1994  
Affiliation: University of Maryland College Park Institute for Advanced Computer Studies UMIACS-TR-94-9.1 Department of Computer Science  
Pubnum: CS-TR-3211.1  
Abstract: The orthogonal qd-algorithm is presented to compute the singular value decomposition of a bidiagonal matrix. This algorithm represents a modification of Rutishauser's qd-algorithm, and it is capable of determining all the singular values to high relative precision. A generalization of the Givens transformation is also introduced, which has applications besides the orthogonal qd-algorithm. fl This report is available by anonymous ftp from cs.umd.edu in the directory /pub/papers/TRs. y Institute for Advanced Computer Studies, University of Maryland, College Park, MD 20742; e-mail: na.vonmatt@na-net.ornl.gov. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E. Anderson, Z. Bai, C. Bischof, J. Demmel, J. Dongarra, J. Du Croz, A. Greenbaum, S. Hammarling, A. McKenney, S. Ostrouchov and D. Sorensen, </author> <title> LAPACK Users' Guide, </title> <publisher> SIAM Publications, </publisher> <address> Philadelphia, </address> <year> 1992. </year>
Reference-contexts: In Tables 3 and 4 we compare the orthogonal qd-algorithm with the subroutine sbdsqr from the LAPACK library <ref> [1] </ref>. This subroutine represents an implementation of the work of Demmel and Kahan [2]. We have also used the procedure dbdsqr, which is an implementation of sbdsqr in double precision, to assess the accuracy of the The Orthogonal QD-Algorithm 25 Table 3 Accuracy and Sweeps for Graded Matrices.
Reference: [2] <author> J. Demmel and W. Kahan, </author> <title> Accurate Singular Values of Bidiagonal Matrices, </title> <journal> SIAM J. Sci. Stat. Comput., </journal> <volume> 11 (1990), </volume> <pages> pp. 873-912. </pages>
Reference-contexts: For a general rectangular matrix it is common practice to first reduce it to the bidiagonal form (cf. [6]). In many applications one is also given a bidiagonal matrix right from the beginning. Furthermore, it is also known <ref> [2] </ref> that all the singular values of a bidiagonal matrix are determined to high relative precision by the entries of the matrix. We will give evidence that our algorithm can actually achieve this high relative accuracy. An outline of the paper is as follows. <p> Review of Related Work. In 1990 J. Demmel and W. Kahan presented a modified QR-algorithm which computes the smallest singular values to maximal relative accuracy and the others to maximal absolute accuracy <ref> [2] </ref>. As in the standard QR-algorithm the singular vectors are also available. Their work represents a major improvement over the original SVD-subroutine svdc as it has been implemented in the LINPACK linear algebra library [3]. On the other hand K. V. Fernando and B. N. <p> In matrix terms this process can be described by the equation 2 B 3 2 0 3 where P denotes an orthogonal (2n)-by-(2n) matrix, and Q denotes an orthogonal n-by-n matrix. In order to obtain rapid convergence the orthogonal qd-steps must preserve the grading of the bidiagonal matrix (cf. <ref> [2, p. 891] </ref>). For instance, if we have a lower bidiagonal matrix L with large entries in the top left corner and small entries in the lower right corner we will execute an orthogonal left lu-step. <p> In this case we use zero-shift qd-steps to determine the tiny singular values. We may expect these initial zero-shift qd-steps to converge rapidly. Our implementation sets an off-diagonal entry fi k or ffi k to zero as soon as the deflation criterion 1 by Demmel and Kahan <ref> [2, p. 889] </ref> is met. Note that two zero-shift qd-steps are equivalent to one zero-shift QR iteration. The Orthogonal QD-Algorithm 19 12. Shifts. The performance of the orthogonal qd-algorithm mainly depends on the choice of the shift s in each step. <p> Let us first consider the class of graded matrices B graded := 2 6 6 6 6 6 6 1 c c 2 c n2 3 7 7 7 7 7 7 ; which are also used as test matrices by Demmel and Kahan <ref> [2, Section 7] </ref> and by Fernando and Parlett [4, Section 9.3]. The singular values i of these matrices are of a vastly different size. The approximation i c i1 gives a rough estimate of the order of magnitude of i . <p> In Tables 3 and 4 we compare the orthogonal qd-algorithm with the subroutine sbdsqr from the LAPACK library [1]. This subroutine represents an implementation of the work of Demmel and Kahan <ref> [2] </ref>. We have also used the procedure dbdsqr, which is an implementation of sbdsqr in double precision, to assess the accuracy of the The Orthogonal QD-Algorithm 25 Table 3 Accuracy and Sweeps for Graded Matrices.
Reference: [3] <author> J. J. Dongarra, C. B. Moler, J. R. Bunch and G. W. Stewart, </author> <title> LINPACK Users' Guide, </title> <publisher> SIAM Publications, </publisher> <address> Philadelphia, </address> <year> 1979. </year>
Reference-contexts: As in the standard QR-algorithm the singular vectors are also available. Their work represents a major improvement over the original SVD-subroutine svdc as it has been implemented in the LINPACK linear algebra library <ref> [3] </ref>. On the other hand K. V. Fernando and B. N. Parlett discovered in 1992 a variant of the qd-algorithm for obtaining maximal relative accuracy for all the singular values [4]. Their approach is based on the so-called differential form of the progressive qd-algorithm. <p> By applying this step n times, we can compute the decomposition (3). This procedure is presented in pseudo-code as Algorithm 3. We describe the construction and application of ordinary Givens rotations by calls of the BLAS routines rotg and rot. Their precise definition is given in <ref> [3, 11] </ref>. We also postulate the procedure rotg2 which calculates a generalized Givens transformation according to Algorithm 2. More specifically, the call rotg2 (x 1 , x 2 , , c, s) determines the values of c and s such that equation (5) holds. <p> The name rotg3 stems from the BLAS subroutine rotg for the calculation of an ordinary Givens transformation <ref> [3, 11] </ref>. It is erroneous to call rotg3 with jj &gt; jx 1 j. It is planned to give an error analysis in a future paper. We will show that the matrix G is orthogonal up to a small multiple of the machine precision. <p> However Laguerre's shift always gives us a lower bound on the smallest singular value of the bidiagonal matrix, which is essential for the orthogonal qd-algorithm. Finally, Fernando and Parlett [4] also report significant speedups of their algorithm over the LINPACK-routine dsvdc <ref> [3] </ref>. Their performance advantage can be partly attributed to the fact that they use a root-free algorithm. However, this approach limits the domain of matrices to which it can be applied. Whether this is acceptable or not depends on the application. 14. Conclusions.
Reference: [4] <author> K. V. Fernando and B. N. Parlett, </author> <title> Accurate singular values and differential qd algorithms, </title> <journal> Numer. Math., </journal> <volume> 67 (1994), </volume> <pages> pp. 191-229. </pages>
Reference-contexts: On the other hand K. V. Fernando and B. N. Parlett discovered in 1992 a variant of the qd-algorithm for obtaining maximal relative accuracy for all the singular values <ref> [4] </ref>. Their approach is based on the so-called differential form of the progressive qd-algorithm. In contrast to the work of Demmel and Kahan their algorithm cannot compute the left and right singular vectors simultaneously with the singular values. 4. Progressive Quotient-Difference Step. <p> It is now possible to modify the qd-Algorithm 1 to directly compute the singular values of an upper bidiagonal matrix R. We get Algorithm 5, which corresponds to the differential qd-algorithm by Fernando and Parlett (cf. <ref> [4, Section 5] </ref>). This algorithm enables us to compute all the singular values of R to high relative accuracy (cf. [4, Section 7]). On the other hand, it is not suited to also compute the corresponding singular vectors simultaneously with the singular values. <p> We get Algorithm 5, which corresponds to the differential qd-algorithm by Fernando and Parlett (cf. [4, Section 5]). This algorithm enables us to compute all the singular values of R to high relative accuracy (cf. <ref> [4, Section 7] </ref>). On the other hand, it is not suited to also compute the corresponding singular vectors simultaneously with the singular values. The primary reason for this is that the matrix R is transposed in each step. <p> We will refer to the four transformations, that have been introduced in this section, by the generic term of orthogonal qd-steps. Fernando and Parlett also present a root-free version of the orthogonal left lu-step in <ref> [4] </ref>. However, such a root-free algorithm has the disadvantage that it operates on the squares of the singular values. Consequently, the largest singular value must not exceed the square root of the largest machine-representable number. <p> first consider the class of graded matrices B graded := 2 6 6 6 6 6 6 1 c c 2 c n2 3 7 7 7 7 7 7 ; which are also used as test matrices by Demmel and Kahan [2, Section 7] and by Fernando and Parlett <ref> [4, Section 9.3] </ref>. The singular values i of these matrices are of a vastly different size. The approximation i c i1 gives a rough estimate of the order of magnitude of i . <p> As we can see from Tables 3 and 6 the number of sweeps per singular value is also larger. However Laguerre's shift always gives us a lower bound on the smallest singular value of the bidiagonal matrix, which is essential for the orthogonal qd-algorithm. Finally, Fernando and Parlett <ref> [4] </ref> also report significant speedups of their algorithm over the LINPACK-routine dsvdc [3]. Their performance advantage can be partly attributed to the fact that they use a root-free algorithm. However, this approach limits the domain of matrices to which it can be applied.
Reference: [5] <author> W. Gander, L. Molinari and H. </author> <title> Svecov a, Numerische Prozeduren aus Nachlass und Lehre von Prof. Heinz Rutishauser, </title> <journal> Internat. Ser. Numer. Math., </journal> <volume> Vol. 33, </volume> <publisher> Birkhauser, </publisher> <address> Basel, </address> <year> 1977. </year>
Reference-contexts: By a progressive qd-step the eigenvalues are shifted by the amount of s, i.e. i (R 0 T All the eigenvalues of A can be computed by a proper shift strategy. Algorithm 1 presents Rutishauser's progressive qd-algorithm in matrix terms (see also <ref> [5, p. 100] </ref>). The performance of the qd-algorithm depends critically on the choice of the shifts s. In [23] Rutishauser shows that, for s 0, the matrices R converge to a diagonal matrix with the square roots of the eigenvalues of A.
Reference: [6] <author> G. H. Golub and W. Kahan, </author> <title> Calculating the singular values and pseudo-inverse of a matrix, </title> <journal> SIAM J. Numer. Anal., </journal> <volume> 2 (1965), </volume> <pages> pp. 205-224. </pages> <note> 28 Urs von Matt </note>
Reference-contexts: Since all the transformations consist of Givens rotations we call it the orthogonal qd-algorithm. We impose no restriction in only considering the singular value decomposition of a square bidiagonal matrix. For a general rectangular matrix it is common practice to first reduce it to the bidiagonal form (cf. <ref> [6] </ref>). In many applications one is also given a bidiagonal matrix right from the beginning. Furthermore, it is also known [2] that all the singular values of a bidiagonal matrix are determined to high relative precision by the entries of the matrix.
Reference: [7] <author> G. H. Golub and C. F. Van Loan, </author> <title> Matrix Computations, Second Edition, </title> <publisher> The Johns Hopkins University Press, </publisher> <address> Baltimore, </address> <year> 1989. </year>
Reference-contexts: Consequently, it is not possible to interpret Algorithm 5 as a sequence of orthogonal transformations applied from the left and the right to the matrix R, as it is the case with the ordinary QR-algorithm (cf. <ref> [7, Section 8.3] </ref>). In order to remedy this deficiency we will propose a new orthogonal qd-algorithm The Orthogonal QD-Algorithm 9 Algorithm 5. Differential qd-Algorithm. := 0 while fl k 6= 0 do Choose a shift s with 0 s min (R). <p> n j upper jfl 1 j jfl n j right ul-step jff 1 j jff n j bidiagonal jfl 1 j &lt; jfl n j left ul-step jff 1 j &lt; jff n j The orthogonal qd-steps are closely related to the QR-algorithm for calculating the singular value decomposition (cf. <ref> [7, Section 8.3] </ref>). If we execute an orthogonal left lu-step (8) with shift zero and an orthogonal right ul-step (14) in succession we get the same result as by applying one unshifted QR-step. This has also been observed in [14, 15].
Reference: [8] <author> E. Hansen and M. Patrick, </author> <title> A Family of Root Finding Methods, </title> <journal> Numer. Math., </journal> <volume> 27 (1977), </volume> <pages> pp. 257-269. </pages>
Reference-contexts: case of Laguerre's method we have k+1 = k p 0 ( k ) 1 nr p 0 ( k ) 2 p ( k )p 00 ( k ) : The value of r denotes the multiplicity of the zero that is being approached by the iteration (see also <ref> [8, 9, 10, 13, 16, 17] </ref> and [27, pp. 441-445]). If all the entries on the two diagonals of U are nonzero, then the eigenvalues of U T U must be distinct [18, p. 124]. <p> Unfortunately, the corresponding numerical multiplicity r is usually not known a priori. This is another reason why we will always set r = 1 in this section. We choose 0 = 0 as our initial value. It is well-known (cf. <ref> [8, 10, 16] </ref> and [27, pp. 443-445]) that both methods will then converge monotonically to the smallest zero of p ().
Reference: [9] <author> W. Kahan, </author> <title> Where does Laguerre's method come from?, </title> <booktitle> in Proceedings of the Fourth Annual Princeton Conference on Information Sciences and Systems, </booktitle> <institution> Department of Electrical Engineering, Princeton University, Princeton, </institution> <year> 1970, </year> <note> p. 143. </note>
Reference-contexts: case of Laguerre's method we have k+1 = k p 0 ( k ) 1 nr p 0 ( k ) 2 p ( k )p 00 ( k ) : The value of r denotes the multiplicity of the zero that is being approached by the iteration (see also <ref> [8, 9, 10, 13, 16, 17] </ref> and [27, pp. 441-445]). If all the entries on the two diagonals of U are nonzero, then the eigenvalues of U T U must be distinct [18, p. 124].
Reference: [10] <author> W. Kahan, </author> <title> Notes on Laguerre's Iteration, </title> <type> unpublished manuscript, </type> <institution> Berkeley, </institution> <year> 1992. </year>
Reference-contexts: case of Laguerre's method we have k+1 = k p 0 ( k ) 1 nr p 0 ( k ) 2 p ( k )p 00 ( k ) : The value of r denotes the multiplicity of the zero that is being approached by the iteration (see also <ref> [8, 9, 10, 13, 16, 17] </ref> and [27, pp. 441-445]). If all the entries on the two diagonals of U are nonzero, then the eigenvalues of U T U must be distinct [18, p. 124]. <p> Unfortunately, the corresponding numerical multiplicity r is usually not known a priori. This is another reason why we will always set r = 1 in this section. We choose 0 = 0 as our initial value. It is well-known (cf. <ref> [8, 10, 16] </ref> and [27, pp. 443-445]) that both methods will then converge monotonically to the smallest zero of p ().
Reference: [11] <author> C. L. Lawson, R. J. Hanson, D. R. Kincaid and F. T. Krogh, </author> <title> Basic Linear Algebra Subprograms for Fortran Usage, </title> <journal> ACM Trans. Math. Softw., </journal> <volume> 5 (1979), </volume> <pages> pp. 308-325. </pages>
Reference-contexts: By applying this step n times, we can compute the decomposition (3). This procedure is presented in pseudo-code as Algorithm 3. We describe the construction and application of ordinary Givens rotations by calls of the BLAS routines rotg and rot. Their precise definition is given in <ref> [3, 11] </ref>. We also postulate the procedure rotg2 which calculates a generalized Givens transformation according to Algorithm 2. More specifically, the call rotg2 (x 1 , x 2 , , c, s) determines the values of c and s such that equation (5) holds. <p> The name rotg3 stems from the BLAS subroutine rotg for the calculation of an ordinary Givens transformation <ref> [3, 11] </ref>. It is erroneous to call rotg3 with jj &gt; jx 1 j. It is planned to give an error analysis in a future paper. We will show that the matrix G is orthogonal up to a small multiple of the machine precision.
Reference: [12] <author> T. Y. Li and Z. Zeng, </author> <title> The Laguerre iteration in solving the symmetric tridiagonal eigenprob-lem, revisited, </title> <journal> SIAM J. Sci. Comput., </journal> <volume> 15 (1994), </volume> <pages> pp. 1145-1173. </pages>
Reference-contexts: In the rest of this section we will be concerned with the numerically stable evaluation of these shifts. In <ref> [12] </ref> T. Y. Li and Z. Zeng discuss the same problem when they evaluate Laguerre's shift for the symmetric tridiagonal eigenproblem. They avoid the calculation of the characteristic polynomial p and its derivatives since these values are likely to underflow or overflow.
Reference: [13] <author> H. J. Maehly, Zur iterativen Auflosung algebraischer Gleichungen, ZAMP, </author> <month> 5 </month> <year> (1954), </year> <pages> pp. 260-263. </pages>
Reference-contexts: case of Laguerre's method we have k+1 = k p 0 ( k ) 1 nr p 0 ( k ) 2 p ( k )p 00 ( k ) : The value of r denotes the multiplicity of the zero that is being approached by the iteration (see also <ref> [8, 9, 10, 13, 16, 17] </ref> and [27, pp. 441-445]). If all the entries on the two diagonals of U are nonzero, then the eigenvalues of U T U must be distinct [18, p. 124].
Reference: [14] <author> R. Mathias and G. W. Stewart, </author> <title> A Block QR Algorithm and the Singular Value Decomposition, </title> <journal> Linear Algebra Appl., </journal> <volume> 182 (1993), </volume> <pages> pp. 91-100. </pages>
Reference-contexts: If we execute an orthogonal left lu-step (8) with shift zero and an orthogonal right ul-step (14) in succession we get the same result as by applying one unshifted QR-step. This has also been observed in <ref> [14, 15] </ref>. The same transformations are also useful for refining a URV-decomposition (see [14, 25] for more details). 9. Orthogonal Quotient-Difference Algorithm. Now, we have available the full set of orthogonal qd-steps to introduce the orthogonal qd-algorithm. <p> If we execute an orthogonal left lu-step (8) with shift zero and an orthogonal right ul-step (14) in succession we get the same result as by applying one unshifted QR-step. This has also been observed in [14, 15]. The same transformations are also useful for refining a URV-decomposition (see <ref> [14, 25] </ref> for more details). 9. Orthogonal Quotient-Difference Algorithm. Now, we have available the full set of orthogonal qd-steps to introduce the orthogonal qd-algorithm. We start from a given n-by-n lower bidiagonal matrix B whose singular value decomposition is desired.
Reference: [15] <author> M. Moonen, P. Van Dooren and F. Vanpoucke, </author> <title> On the QR Algorithm and Updating the SVD and the URV Decomposition in Parallel, </title> <journal> Linear Algebra Appl., </journal> <volume> 188/189 (1993), </volume> <pages> pp. 549-568. </pages>
Reference-contexts: If we execute an orthogonal left lu-step (8) with shift zero and an orthogonal right ul-step (14) in succession we get the same result as by applying one unshifted QR-step. This has also been observed in <ref> [14, 15] </ref>. The same transformations are also useful for refining a URV-decomposition (see [14, 25] for more details). 9. Orthogonal Quotient-Difference Algorithm. Now, we have available the full set of orthogonal qd-steps to introduce the orthogonal qd-algorithm.
Reference: [16] <author> A. M. Ostrowski, </author> <title> Solution of Equations in Euclidean and Banach Spaces, Third Edition of "Solution of Equations and Systems of Equations", </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1973. </year>
Reference-contexts: case of Laguerre's method we have k+1 = k p 0 ( k ) 1 nr p 0 ( k ) 2 p ( k )p 00 ( k ) : The value of r denotes the multiplicity of the zero that is being approached by the iteration (see also <ref> [8, 9, 10, 13, 16, 17] </ref> and [27, pp. 441-445]). If all the entries on the two diagonals of U are nonzero, then the eigenvalues of U T U must be distinct [18, p. 124]. <p> Unfortunately, the corresponding numerical multiplicity r is usually not known a priori. This is another reason why we will always set r = 1 in this section. We choose 0 = 0 as our initial value. It is well-known (cf. <ref> [8, 10, 16] </ref> and [27, pp. 443-445]) that both methods will then converge monotonically to the smallest zero of p (). <p> In particular we have 0 = 0 1 min (U T U ): Laguerre's method enjoys cubic convergence provided that the multiplicity r is chosen properly (cf. <ref> [16, pp. 353-362] </ref> and [27, pp. 443-445]). On the other hand Newton's method will converge only quadratically [27, p. 441]. 20 Urs von Matt We intend to use p 1 as the shift in an orthogonal qd-step.
Reference: [17] <author> B. N. Parlett, </author> <title> Laguerre's Method Applied to the Matrix Eigenvalue Problem, </title> <journal> Math. Comp., </journal> <volume> 18 (1964), </volume> <pages> pp. 464-485. </pages>
Reference-contexts: case of Laguerre's method we have k+1 = k p 0 ( k ) 1 nr p 0 ( k ) 2 p ( k )p 00 ( k ) : The value of r denotes the multiplicity of the zero that is being approached by the iteration (see also <ref> [8, 9, 10, 13, 16, 17] </ref> and [27, pp. 441-445]). If all the entries on the two diagonals of U are nonzero, then the eigenvalues of U T U must be distinct [18, p. 124].
Reference: [18] <author> B. N. Parlett, </author> <title> The Symmetric Eigenvalue Problem, </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, </address> <year> 1980. </year>
Reference-contexts: e k+1 e T The Euclidean norms of the two perturbation matrices E 1 and E 2 are given by kE 1 k 2 = 2 q k + 4fi 2 kE 2 k 2 = 2 q k + 4fi 2 As a consequence of Weyl's monotonicity theorem (cf. <ref> [18, pp. 191-194] </ref> and [27, pp. 101-103]) the norms of the perturbations E 1 and E 2 represent an upper bound for the change of the eigenvalues in (21,22). <p> If all the entries on the two diagonals of U are nonzero, then the eigenvalues of U T U must be distinct <ref> [18, p. 124] </ref>. Consequently, p () has n distinct positive zeros, and we can always set r = 1. However, some of these zeros may lie so closely together that they seem to be a multiple zero numerically. Unfortunately, the corresponding numerical multiplicity r is usually not known a priori.
Reference: [19] <author> C. H. Reinsch and F. L. Bauer, </author> <title> Rational QR Transformation with Newton Shift for Symmetric Tridiagonal Matrices, </title> <journal> Numer. Math., </journal> <volume> 11 (1968), </volume> <pages> pp. 264-272. </pages>
Reference-contexts: We can obtain a much better rate of convergence by choosing the shifts s = trace (R T R) 1 : In [24, pp. 484-486] it is shown how this shift can be computed easily from the matrix R. Reinsch and Bauer observe in <ref> [19] </ref> that this shift can be seen as a Newton step for the solution of the characteristic polynomial p (s) = det (R T R sI ): The Orthogonal QD-Algorithm 3 Algorithm 1.
Reference: [20] <author> H. Rutishauser, Der Quotienten-Differenzen-Algorithmus, ZAMP, </author> <month> 5 </month> <year> (1954), </year> <pages> pp. 233-251. </pages>
Reference-contexts: 1. Introduction. In 1954 H. Rutishauser <ref> [20] </ref> introduced the qd-algorithm to compute the eigenvalues of a symmetric tridiagonal matrix. In this paper, we present a related algorithm to compute the singular values of a square bidiagonal matrix. Since all the transformations consist of Givens rotations we call it the orthogonal qd-algorithm.
Reference: [21] <author> H. </author> <type> Rutishauser, </type> <institution> Der Quotienten-Differenzen-Algorithmus, Mitteilungen aus dem Institut fur angewandte Mathematik Nr. </institution> <address> 7, </address> <publisher> Birkhauser, </publisher> <address> Basel, </address> <year> 1957. </year>
Reference: [22] <author> H. Rutishauser, Uber eine kubisch konvergente Variante der LR-Transformation, ZAMM, </author> <month> 40 </month> <year> (1960), </year> <pages> pp. 49-54. </pages>
Reference-contexts: R := (k 1)-by-(k 1) leading principal submatrix of R 0 end This observation also explains the quadratic convergence of this shift strategy. In <ref> [22] </ref> Rutishauser describes a shift strategy that even leads to an asymptotically cubic convergence. He uses trial qd-steps with shifts s &gt; min (R T R). Although these steps must fail one can usually extract enough information to obtain an improved lower bound on min (R T R). 3.
Reference: [23] <editor> H. Rutishauser, Les proprietes numeriques de l'algorithme quotient-difference, Rapport EUR 4083f, Communaute Europeenne de l'Energie Atomique - EURATOM, Luxembourg, </editor> <year> 1968. </year>
Reference-contexts: Algorithm 1 presents Rutishauser's progressive qd-algorithm in matrix terms (see also [5, p. 100]). The performance of the qd-algorithm depends critically on the choice of the shifts s. In <ref> [23] </ref> Rutishauser shows that, for s 0, the matrices R converge to a diagonal matrix with the square roots of the eigenvalues of A. The convergence is linear and becomes worse when the eigenvalues are clustered.
Reference: [24] <author> H. </author> <title> Rutishauser, Lectures on Numerical Mathematics, </title> <publisher> Birkhauser, </publisher> <address> Boston, </address> <year> 1990. </year>
Reference-contexts: Algorithm 1 is not suited for this shift strategy because, in general, its inner loop would not terminate. We can obtain a much better rate of convergence by choosing the shifts s = trace (R T R) 1 : In <ref> [24, pp. 484-486] </ref> it is shown how this shift can be computed easily from the matrix R.
Reference: [25] <author> G. W. Stewart, </author> <title> An Updating Algorithm for Subspace Tracking, </title> <journal> IEEE Trans. Signal Processing, </journal> <volume> 40 (1992), </volume> <pages> pp. 1535-1541. </pages>
Reference-contexts: If we execute an orthogonal left lu-step (8) with shift zero and an orthogonal right ul-step (14) in succession we get the same result as by applying one unshifted QR-step. This has also been observed in [14, 15]. The same transformations are also useful for refining a URV-decomposition (see <ref> [14, 25] </ref> for more details). 9. Orthogonal Quotient-Difference Algorithm. Now, we have available the full set of orthogonal qd-steps to introduce the orthogonal qd-algorithm. We start from a given n-by-n lower bidiagonal matrix B whose singular value decomposition is desired.
Reference: [26] <author> U. von Matt, </author> <title> Large Constrained Quadratic Problems, </title> <publisher> Verlag der Fachvereine, </publisher> <address> Zurich, </address> <year> 1993. </year>
Reference-contexts: In this case the explicit Cholesky decomposition breaks down. Also, if A is close to a singular matrix the explicit Cholesky decomposition may loose accuracy. The reader may find a more detailed comparison in <ref> [26, pp. 47-53] </ref>. 4.3. Bidiagonal Matrices.
Reference: [27] <author> J. H. Wilkinson, </author> <title> The Algebraic Eigenvalue Problem, </title> <publisher> Clarendon Press, Oxford, </publisher> <year> 1965. </year>
Reference-contexts: The Euclidean norms of the two perturbation matrices E 1 and E 2 are given by kE 1 k 2 = 2 q k + 4fi 2 kE 2 k 2 = 2 q k + 4fi 2 As a consequence of Weyl's monotonicity theorem (cf. [18, pp. 191-194] and <ref> [27, pp. 101-103] </ref>) the norms of the perturbations E 1 and E 2 represent an upper bound for the change of the eigenvalues in (21,22). <p> = k p 0 ( k ) 1 nr p 0 ( k ) 2 p ( k )p 00 ( k ) : The value of r denotes the multiplicity of the zero that is being approached by the iteration (see also [8, 9, 10, 13, 16, 17] and <ref> [27, pp. 441-445] </ref>). If all the entries on the two diagonals of U are nonzero, then the eigenvalues of U T U must be distinct [18, p. 124]. Consequently, p () has n distinct positive zeros, and we can always set r = 1. <p> Unfortunately, the corresponding numerical multiplicity r is usually not known a priori. This is another reason why we will always set r = 1 in this section. We choose 0 = 0 as our initial value. It is well-known (cf. [8, 10, 16] and <ref> [27, pp. 443-445] </ref>) that both methods will then converge monotonically to the smallest zero of p (). In particular we have 0 = 0 1 min (U T U ): Laguerre's method enjoys cubic convergence provided that the multiplicity r is chosen properly (cf. [16, pp. 353-362] and [27, pp. 443-445]). <p> 16] and <ref> [27, pp. 443-445] </ref>) that both methods will then converge monotonically to the smallest zero of p (). In particular we have 0 = 0 1 min (U T U ): Laguerre's method enjoys cubic convergence provided that the multiplicity r is chosen properly (cf. [16, pp. 353-362] and [27, pp. 443-445]). On the other hand Newton's method will converge only quadratically [27, p. 441]. 20 Urs von Matt We intend to use p 1 as the shift in an orthogonal qd-step. <p> In particular we have 0 = 0 1 min (U T U ): Laguerre's method enjoys cubic convergence provided that the multiplicity r is chosen properly (cf. [16, pp. 353-362] and [27, pp. 443-445]). On the other hand Newton's method will converge only quadratically <ref> [27, p. 441] </ref>. 20 Urs von Matt We intend to use p 1 as the shift in an orthogonal qd-step.
References-found: 27

