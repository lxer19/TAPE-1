URL: http://www.cs.purdue.edu/coast/archive/clife/CFS/docs/cfsc.ps.gz
Refering-URL: http://www.cs.purdue.edu/coast/archive/clife/CFS/docs/
Root-URL: http://www.cs.purdue.edu
Title: CFS-C: A Package of Domain Independent Subroutines for Implementing Classifier Systems in Arbitrary, User-Defined Environments.  
Author: Rick L. Riolo 
Note: Copyright 1986,1988 Rick L. Riolo. yThis work was supported in part by National Science Foundation Grants DCR 83-05830 and IRI 86-10225, and by a University of Michigan Presidential Initiaive Fund Grant to the BACH research group.  
Affiliation: Logic of Computers Group Division of Computer Science and Engineering University of Michigan  
Date: January 1986 Updated November 1988  
Abstract-found: 0
Intro-found: 1
Reference: [Booker, 1982] <editor> Booker, Lashon B. </editor> <title> "Intelligent Behavior as an Adaption to the Task Environment." </title> <type> Ph.D. Dissertation. </type> <institution> University of Michigan (1982). </institution>
Reference-contexts: Pick classifiers to be replaced, remove them from the classifier list, and replace them with the classifiers produced by step 2. Typically the the lower a classifier's strength, the more likely it will be replaced. Both analysis (Holland, 1975) and simulations ([Goldberg, 1983], <ref> [Booker, 1982] </ref>, [Wilson, 1986b]) have shown that genetic algorithms, when used with algorithms that apportion credit (strength) to useful members of a population (as the bucket-brigade algorithm does for classifiers), are a very powerful way to search for and discover useful populations. <p> One obvious alternative to this distribution mechanism would be to divide the reward amoung the classifiers active when the reward is received <ref> [Booker, 1982] </ref> [Wilson, 1986b]. This can be done by setting the ShareRew parameter to 1. Note that this would penalize classifiers that act in concert with others, since the larger the cluster of cooperating classifiers, the less reward each would receive. <p> Since it is imperative that the system attend to information about its environment (i.e., detector messages), a number of schemes have been proposed for handling unmatched detector messages <ref> [Booker, 1982] </ref>, [Wilson, 1986b], [Davis and Young, 1988], including schemes like the Cover Detector Messages operator used in CFS-C. The trigger condition for the Cover Detector Messages operator is the existence of a detector message that is not matched by any classifier during a given step. <p> I will say that unless some method is used, the system will not get very far if started with random rules or when faced with novel detector messages, as has been pointed out by <ref> [Booker, 1982] </ref>, [Wilson, 1986b], [Davis and Young, 1988] and others. 3.9.3 The Cover Effectors Operator Just as the Cover Detector Messages operator serves to keep the system responsive to information from the environment, the Cover Effectors operator acts to keep the system able to respond.
Reference: [Booker, 1988] <editor> Booker, Lashon B. </editor> <title> "Classifier Systems that Learn Empirical World Models." </title> <note> Submitted to Machine Learning, </note> <year> 1988. </year>
Reference-contexts: The problem is that these roles are sometimes in conflict, leading to lower than expected performance ([Riolo, 1987b], [Riolo, 1988d]) or to difficulties when working in domains where it would be useful for a system to build and utilize models that are both predictive and prescriptive <ref> [Booker, 1988] </ref> [Burks and Holland, 1988]. * Emergence of Co-Adapted Sets of Classifiers.
Reference: [Booker et al., 1987] <editor> Booker, Lashon B., David E. Goldberg and John H. </editor> <title> Holland. Classifiers and Genetic Algorithms. </title> <type> Technical Report No. 8, </type> <institution> Cognitive Science and Machine Intelligence Laboratory, University of Michigan, </institution> <address> Ann Arbor, MI (1987). </address>
Reference: [Burks, 1986a] <author> Burks, Arthur W. </author> <title> "The Logic of Evolution, and the Reduction of Holistic-Coherent Systems to Hierarchical-Feedback Systems." In Causation in Decision, Belief Change and Statistics, </title> <editor> William Harper and Bryan Skyrms (Eds). </editor> <publisher> Kluwer Academic Publishers, Dordrecht, Holland (1986). </publisher>
Reference: [Burks, 1986b] <author> Burks, Arthur W. </author> <title> "A Radically Non-Von Neumann Architecture For Learning and Discovery." </title> <booktitle> In CONPAR 86: Proceedings of a Conference on Algorithms for Parallel Processing, </booktitle> <pages> pp 1-17, </pages> <editor> Handler, Wolfgang (Ed). </editor> <address> Aachen, F.R. Germany, 17-19 September 1986. </address> <publisher> Springer-Verlag, </publisher> <address> Berlin. </address>
Reference: [Burks and Holland, 1988] <author> Burks, Arthur and Holland John. </author> <title> "Classifier Systems: Parallel Machine Learning with Higher-Level Building Blocks." Draft of proposal to NSF (1988). [Davis and Young, 1988] "Classifier Systems with Hamming Weights." </title> <editor> Davis, Lawarence, and Young, David K. </editor> <booktitle> In Proceedings of the Fifth International Conference on Machine Learning, </booktitle> <pages> pp 162-173. </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufman (1988). </publisher>
Reference-contexts: The problem is that these roles are sometimes in conflict, leading to lower than expected performance ([Riolo, 1987b], [Riolo, 1988d]) or to difficulties when working in domains where it would be useful for a system to build and utilize models that are both predictive and prescriptive [Booker, 1988] <ref> [Burks and Holland, 1988] </ref>. * Emergence of Co-Adapted Sets of Classifiers.
Reference: [DeJong, 1975] <author> DeJong, Kenneth. A. </author> <title> "An Analysis of the Behavior of a Class of Genetic Adaptive Systems." </title> <type> Ph.D. Dissertation, </type> <institution> University of Michigan (1975). </institution>
Reference-contexts: If it is 2, classifiers are picked using a uniform random selection procedure, but only from below average strength rules. 5. CrowdFac. This can be used to implement a crowding factor into the replacement algorithm, as described by <ref> [DeJong, 1975] </ref>. The default for CrowdFac is 1. If Crowd-Fac is set to say 4, then when new rule is to replace another one, 4 rules are chosen 31 as candidates for replacement, and the one that is syntacically most like the new one is actually replaced. <p> Some of the most important problem areas are: * Premature Convergence. The problem of the "premature convergence" of a population manipulated by a genetic algorthm (i.e., the loss of variation in many or most loci before a satisfactory solution is found) has been known for some time <ref> [DeJong, 1975] </ref>. This phenomena has also shown up in classifier systems that use genetic algorithms ([Robertson and Riolo, 1988], [Wilson, 1988]). One cause of convergence is the high fixed-point strengths of "generalist" rules, i.e., rules with low bid ratios (specifity).
Reference: [DeJong, 1988] <author> DeJong, Kenneth. A. </author> <title> "Using Genetic Algorithms to Learn Task Programs: the Pitt Approach." </title> <journal> Machine Learning, </journal> <volume> 3, </volume> <month> 2-3 </month> <year> (1988). </year>
Reference-contexts: One advantage of the Pitt approach is that the the "schema theorem" [Holland, 1976] rather naturally leads to the emergence of co-adapted sets of rules in the better members of the population of performance systems <ref> [DeJong, 1988] </ref>. Its not so clear that co-adapted sets of rules will emerge as readily in in systems (like CFS-C) based on the Michigan approach.
Reference: [Forrest, 1985] <editor> Forrest, Stephanie. </editor> <title> "A Study of Parallelism in the Classifier System and Its Application to Classification in KL-ONE Sematic Networks." </title> <type> Ph.D. Dissertation, </type> <institution> University of Michigan (1985). </institution> <month> [Goldberg, </month> <title> 1983] "Computer-Aided Gas Pipeline Operation Using Genetic Algorithms and Rule Learning." </title> <type> Ph.D. Dissertation, </type> <institution> University of Michigan (1983). </institution>
Reference: [Goldberg, 1988] <author> Goldberg, David E. </author> <title> "Genetic Algorithms in Search, Optimization, and Machine Learning." </title> <publisher> Addison Wesley, </publisher> <address> Reading MA (1988). </address> <month> 57 </month>
Reference-contexts: Thus the genetic algorithm is in effect constantly creating new high-level structures, using structures already in the system as building-blocks. For a further discussion of these and other issues, see [Holland, 1976], [Holland, 1986c] or <ref> [Goldberg, 1988] </ref>. Besides using a genetic algorithm to discover new rules, CFS-C also uses some other triggered algorithms [Holland, 1986c] to create new rules. <p> Why use an "effective bid" in the competition? The main reason is to make it possible to bias the probability of winning the competition to post messages without altering the redistribution of strength. See <ref> [Goldberg, 1988] </ref>, [Riolo, 1987b] and [Riolo, 1988d] for a further discussion of the issues involved. As each winning classifier is chosen, it is activated-that is, it generates new messages by applying its action-part to all the matches it is involved in.
Reference: [Goldberg and Richardson, 1987] <author> Goldberg, David E. and Richardson, Jon. </author> <title> "Genetic Al--gorithms with Sharing for Multimodal Function Optimization." </title> <booktitle> In Proceedings of the Second International Conference on Genetic Algorithms and their Applications, </booktitle> <pages> 41-49. </pages> <editor> John J. Grefenstette (Ed.). </editor> <address> Cambridge, Massachesetts, </address> <month> July 28-31, </month> <year> 1987. </year>
Reference: [Grefenstette, 1986] <author> Grefenstette, John J. </author> <title> "Optimization of Control Parameters for Genetic Algorithms." </title> <journal> IEEE Transactions of Systems, Man and Cybernetics, </journal> <volume> Vol. SMC-16, number 1 (1986). </volume>
Reference: [Grefenstette, 1987] <author> Grefenstette, John J. </author> <title> "Multilevel Credit Assignment in a Genetic Learning System." </title> <booktitle> In Proceedings of the Second International Conference on Genetic Algorithms and their Applications, </booktitle> <pages> 202-209. </pages> <editor> John J. Grefenstette (Ed.). </editor> <address> Cambridge, Massachesetts, </address> <month> July 28-31, </month> <year> 1987. </year>
Reference: [Holland, 1976] <author> Holland, John H. </author> <title> Adaptation in Natural and Artificial Systems. </title> <publisher> The University of Michigan Press, </publisher> <address> Ann Arbor, MI (1976). </address>
Reference-contexts: The CFS-C package also includes subroutines that implement learning algorithms that "discover" (generate) new, potentially useful classifiers. In particular, the CFS-C system includes subroutines to implement "genetic algorithms" like those described by <ref> [Holland, 1976] </ref> and other "triggered" algorithms like those described in [Holland, 1986c]. <p> Thus the genetic algorithm is in effect constantly creating new high-level structures, using structures already in the system as building-blocks. For a further discussion of these and other issues, see <ref> [Holland, 1976] </ref>, [Holland, 1986c] or [Goldberg, 1988]. Besides using a genetic algorithm to discover new rules, CFS-C also uses some other triggered algorithms [Holland, 1986c] to create new rules. <p> to be a bit of a mess! Perhaps in CFS-C 2 (or 3 or ...) some things will be "known" so the code can be simplified and cleaned up.] 3.9.1 The Genetic Algorithm The genetic algorithm (GA) used by CFS-C is basically a very standard type like that defined by <ref> [Holland, 1976] </ref> and [Holland, 1986c]. Basically, new classifiers are generated by: 1. Generating offspring (copies) of existing, high-strength classifiers; and 2. Crossing some of the offspring to produce new classifiers different from but similar to the parent classifiers. 3. Applying a mutation operator to some of the offspring. <p> A second approach is the Pitt approach, in which 53 each "individual" consists of a a set of rules, each of which is evaluated as a complete performance system. One advantage of the Pitt approach is that the the "schema theorem" <ref> [Holland, 1976] </ref> rather naturally leads to the emergence of co-adapted sets of rules in the better members of the population of performance systems [DeJong, 1988]. Its not so clear that co-adapted sets of rules will emerge as readily in in systems (like CFS-C) based on the Michigan approach.
Reference: [Holland,1984] <author> Holland, John H. </author> <title> "Genetic Algorithms and Adaptation." In Adaptive Control of Ill-Defined Systems, </title> <editor> p317-333. Selfridge, O. G., E. L. Rissland, and M. A. Arbib (Eds.), </editor> <publisher> Plenum Press, </publisher> <address> New York, </address> <year> 1984. </year>
Reference: [Holland,1985] <author> Holland, J. H. </author> <title> "Properties of the Bucket Brigade." </title> <booktitle> Proceedings of an International Conference on Genetic Algorithms and their Applications, </booktitle> <pages> 1-7. </pages> <editor> John J. Grefenstette (Ed.). </editor> <address> Carnegie-Mellon University, Pittsburg, </address> <year> 1985. </year>
Reference: [Holland, 1986a] <author> Holland, John H. </author> <title> "Escaping Brittleness: The Possibilities of General-Purpose Learning Algorithms Applied to Parallel Rule-Based Systems." In Machine Learning: An Artificial Intelligence Approach, Volume II, </title> <editor> Michalski, Ryszard S., Car-bonell, Jamie G., and Mitchell, Tom M. (Eds). </editor> <publisher> Morgan Kaufman Publishers, Inc., </publisher> <address> Los Altos, CA (1986). </address>
Reference: [Holland, 1986b] <author> Holland, John H. </author> <title> "A Mathematical Framework for Studying Learning in Classifier Systems." </title> <journal> Physica 22D, </journal> <month> 307-317 </month> <year> (1986). </year>
Reference: [Holland, 1986c] <author> Holland, John H., Holyoak, Keith J., Nisbett, Richard E. and Paul A. Thagard. </author> <title> Induction. Processes of Inference, Learning, and Discovery. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1986. </year>
Reference-contexts: The CFS-C package also includes subroutines that implement learning algorithms that "discover" (generate) new, potentially useful classifiers. In particular, the CFS-C system includes subroutines to implement "genetic algorithms" like those described by [Holland, 1976] and other "triggered" algorithms like those described in <ref> [Holland, 1986c] </ref>. <p> Thus the genetic algorithm is in effect constantly creating new high-level structures, using structures already in the system as building-blocks. For a further discussion of these and other issues, see [Holland, 1976], <ref> [Holland, 1986c] </ref> or [Goldberg, 1988]. Besides using a genetic algorithm to discover new rules, CFS-C also uses some other triggered algorithms [Holland, 1986c] to create new rules. <p> For a further discussion of these and other issues, see [Holland, 1976], <ref> [Holland, 1986c] </ref> or [Goldberg, 1988]. Besides using a genetic algorithm to discover new rules, CFS-C also uses some other triggered algorithms [Holland, 1986c] to create new rules. For example, a triggered chainging operator [Robertson and Riolo, 1988] is available in CFS-C, to make it possible for the system to discover useful chains of coupled classifiers. <p> This list is not meant to be complete|other useful algorithms could be (and probably should be) added to classifier systems to make them closer to "general" learning systems. See <ref> [Holland, 1986c] </ref> for some suggestions of other useful discovery algorithms. Also note that the particular implementations in CFS-C are not meant to be definitive descriptions of the discovery algorithms, either. <p> bit of a mess! Perhaps in CFS-C 2 (or 3 or ...) some things will be "known" so the code can be simplified and cleaned up.] 3.9.1 The Genetic Algorithm The genetic algorithm (GA) used by CFS-C is basically a very standard type like that defined by [Holland, 1976] and <ref> [Holland, 1986c] </ref>. Basically, new classifiers are generated by: 1. Generating offspring (copies) of existing, high-strength classifiers; and 2. Crossing some of the offspring to produce new classifiers different from but similar to the parent classifiers. 3. Applying a mutation operator to some of the offspring. <p> Thus the CFS-C system includes special Triggered Chaining operators designed to promote the formation of coupled rules. The implementation is similar to that proposed in <ref> [Holland, 1986c] </ref> and used in experiments described in [Robertson and Riolo, 1988] and [Riolo, 1988d]. There are actually two subroutines in CFS-C that form coupled rules: DscACPC () and DscCSS (). <p> As mentioned above, the string mmmm that is used to couple two classifiers can be constructed in a variety of ways <ref> [Holland, 1986c] </ref>. For example, one way is to just use the string xxxx from action-part of the parent classifier A. This is possible because in classifier systems like CFS-C both the condition-parts and the action-parts of classifiers are just strings build from the f0; 1; #g alphabet. <p> Also note that in some domains strength serves as a measure of the system's ability to reach specified goals, while in other it serves as a measure of predictive power <ref> [Holland, 1986c] </ref>.
Reference: [Holland and Reitman, 1978] <author> Holland, John, and Reitman, J. S. </author> <title> "Cognitive Systems Based on Adaptive Algorithms." In Pattern-Directed Inference Systems, </title> <editor> Waterman, D. A. and Hayes-Roth, F, (Eds.), </editor> <publisher> Academic Press, </publisher> <year> 1978. </year>
Reference: [Holland and Burks, 1987] <author> Holland, John H. and Burks, Arthur W. </author> <title> "Adaptive Computing Sustem Capable of Learning and Discovery." United States Patent 4,697,242. </title> <address> Septem-ber 29, </address> <year> 1987. </year>
Reference: [Mitchell et al, 1983] <author> Tom M. Mitchell, Paul E. Utgoff, and Ranan Banerji. </author> <title> "Learning by Experimentation: Acquiring and Refining Problem-Solving Heuristics." </title> <booktitle> In Machine 58 Learning: An Artificial Intelligence Approach, </booktitle> <volume> Volume I, </volume> <editor> Michalski, Ryszard S., Car--bonell, Jamie G., and Mitchell, Tom M. (Eds). </editor> <publisher> Tioga Publishing Company, </publisher> <address> Palo Alto, CA (1983). </address>
Reference-contexts: There is no need for complicated book-keeping or for high-level critics to analyze sequences of actions and assign credit accordingly. This is in contrast to systems like LEX <ref> [Mitchell et al, 1983] </ref>, in which full traces of system behavior are used to allocate credit to rules that are active early in a multi-step process.
Reference: [Riolo, 1987a] <editor> Riolo, Rick L. </editor> <title> "Bucket Brigade Performance: I. Long Sequences of Classifiers." </title> <booktitle> Genetic Algorithms and Their Applications: Proceedings of the Second International Conference on Genetic Algorithms, </booktitle> <pages> 184-195, </pages> <editor> John J. Grefenstette (Ed.). </editor> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hillsdale, New Jersey, </address> <year> 1987. </year>
Reference-contexts: One well known problem with the bucket brigade is the exponential fall-off of strength up chains in which one condition of each classifier matches a detector message while the other matches a message from its predecessor in the chain (see <ref> [Riolo, 1987a] </ref>). 4 See [Goldberg, 1983] for a derivation of a fixed-point strength for classifier strength. Actually the CFS-C system also provides for several types of "taxes", e.g., a tax on every classifier every step, a tax for bidding, and so on, which are described later in this chapter.
Reference: [Riolo, 1987b] <editor> Riolo, Rick L. </editor> <title> "Bucket Brigade Performance: II. Simple Default Hierarchies." </title> <booktitle> Genetic Algorithms and Their Applications: Proceedings of the Second International Conference on Genetic Algorithms, </booktitle> <pages> 196-201, </pages> <editor> John J. Grefenstette (Ed.). </editor> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hillsdale, New Jersey, </address> <year> 1987. </year>
Reference-contexts: Also note that as bids are defined here, both the BidRatio and support will alter the fixed-point strengths of classifiers (see the section on bidding for a discussion of fixed-point strengths). I am not sure this is a good idea (see <ref> [Riolo, 1987b] </ref>). <p> For example, if EBRP ow = 3, a specialist rule will tend to win a competition with a generalist rule, other things (i.e., strength) being equal. For a discussion of the use of this parameter to make default hierarchies perform as expected, see <ref> [Riolo, 1987b] </ref>. Why use an "effective bid" in the competition? The main reason is to make it possible to bias the probability of winning the competition to post messages without altering the redistribution of strength. See [Goldberg, 1988], [Riolo, 1987b] and [Riolo, 1988d] for a further discussion of the issues involved. <p> use of this parameter to make default hierarchies perform as expected, see <ref> [Riolo, 1987b] </ref>. Why use an "effective bid" in the competition? The main reason is to make it possible to bias the probability of winning the competition to post messages without altering the redistribution of strength. See [Goldberg, 1988], [Riolo, 1987b] and [Riolo, 1988d] for a further discussion of the issues involved. As each winning classifier is chosen, it is activated-that is, it generates new messages by applying its action-part to all the matches it is involved in.
Reference: [Riolo, 1988a] <editor> Riolo, Rick L. "CFS-C: </editor> <title> A Package if Domain Independent Subroutines for Implementing Classifier Systems in Arbitrary, User-Defined Environments." Logic of Computers Group, </title> <institution> Division of Computer Science and Engineering, University of Michi-gan, </institution> <address> Ann Arbor, </address> <year> 1988. </year>
Reference: [Riolo, 1988b] <editor> Riolo, Rick L. "LETSEQ1: </editor> <title> An Implementation of the CFS-C Classifier System in a Task-Domain that Involves Learning to Predict Letter Sequences." Logic of Computers Group, </title> <institution> Division of Computer Science and Engineering, University of Michigan, </institution> <address> Ann Arbor, </address> <year> 1988. </year>
Reference-contexts: This subroutine provides an easy way to invoke environment-specific utility commands, e.g., commands that can be used to debug the environment-dependent sub routines. The rest of this section describes the implementation requirements for these subroutines and for the environment state-space itself in more detail. The LETSEQ system, described in <ref> [Riolo, 1988b] </ref> was implemented using the CFS-C package. Thus the source-code files for the LETSEQ system contain examples of all the subroutines described in this section. Although that task-domain is very simple, it does show how to implement a specific environment for the CFS-C system.
Reference: [Riolo, 1988c] <editor> Riolo, Rick L. "CFS-C/FSW1: </editor> <title> An Implementation of the CFS-C Classifier System in a Domain that Involves Learning to Control a Markov Process." Logic of Computers Group, </title> <institution> Division of Computer Science and Engineering, University of Michigan, </institution> <address> Ann Arbor, </address> <year> 1988. </year>
Reference-contexts: Thus the source-code files for the LETSEQ system contain examples of all the subroutines described in this section. Although that task-domain is very simple, it does show how to implement a specific environment for the CFS-C system. The FSW1 domain <ref> [Riolo, 1988c] </ref>, also distributed with CFS-C, is another example of how to implement the domain-specific subroutines that must be linked to CFS-C. 4.1 Defining the Environment State-Space The environment state-space may be defined in whatever way seems best for the particular environment or task-domain being implemented.
Reference: [Riolo, 1988d] <editor> Riolo, Rick L. </editor> <title> "Empirical Studies of Default Hierarchies and Sequences of Rules in Learning Classifier Systems." </title> <type> Ph.D. Dissertation, </type> <institution> University of Michigan (1988). </institution>
Reference-contexts: Why use an "effective bid" in the competition? The main reason is to make it possible to bias the probability of winning the competition to post messages without altering the redistribution of strength. See [Goldberg, 1988], [Riolo, 1987b] and <ref> [Riolo, 1988d] </ref> for a further discussion of the issues involved. As each winning classifier is chosen, it is activated-that is, it generates new messages by applying its action-part to all the matches it is involved in. <p> Thus the CFS-C system includes special Triggered Chaining operators designed to promote the formation of coupled rules. The implementation is similar to that proposed in [Holland, 1986c] and used in experiments described in [Robertson and Riolo, 1988] and <ref> [Riolo, 1988d] </ref>. There are actually two subroutines in CFS-C that form coupled rules: DscACPC () and DscCSS (). The latter implements what I call the CSS (Couple Stage Setter) operator, which is a generalization of the former ACPC operator. <p> While chains can emerge and serve to increase performance on simple problems ([Riolo, 1987a], [Robertson and Riolo, 1988], <ref> [Riolo, 1988d] </ref>), chains longer than 4 or 5 rules are not very stable. <p> The problem is that these roles are sometimes in conflict, leading to lower than expected performance ([Riolo, 1987b], <ref> [Riolo, 1988d] </ref>) or to difficulties when working in domains where it would be useful for a system to build and utilize models that are both predictive and prescriptive [Booker, 1988] [Burks and Holland, 1988]. * Emergence of Co-Adapted Sets of Classifiers. <p> One problem with limiting the message list occurs when some classifiers are posting effector activating messages while other are posting messages to be used by other classifiers in chains <ref> [Riolo, 1988d] </ref>. If there are many classifiers of one type or another, or if rules of one type has generally higher strengths than rules of the other type, then the message list may be filled by messages of one type.
Reference: [Robertson, 1987] <author> Robertson, George G. </author> <title> "Parallel Implementation of Genetic Algorithms in a Classifier System." </title> <booktitle> In Proceedings of the Second International Conference on Genetic Algorithms and their Applications, </booktitle> <pages> 140-147. </pages> <editor> John J. Grefenstette (Ed.). </editor> <address> Cambridge, Massachesetts, </address> <month> July 28-31, </month> <year> 1987. </year>
Reference-contexts: Actually the CFS-C system also provides for several types of "taxes", e.g., a tax on every classifier every step, a tax for bidding, and so on, which are described later in this chapter. I have ignored those in this derivation of the fixed-point strength of a classifier. 5 Robertson <ref> [Robertson, 1987] </ref> has shown that almost all aspects of learning classifier systems are paral-lelizable by implementing a classifier system on a Connection Machine. 26 In order to alleviate that problem, I have introduced a new variable, DMShare (detector message share) into the CFS-C system.
Reference: [Robertson and Riolo, 1988] <editor> Robertson, George G. and Riolo, Rick L. </editor> <title> "A Tale of Two Classifier Systems." </title> <booktitle> Machine Learning,3, </booktitle> <month> 2-3 </month> <year> (1988) </year>
Reference-contexts: For a further discussion of these and other issues, see [Holland, 1976], [Holland, 1986c] or [Goldberg, 1988]. Besides using a genetic algorithm to discover new rules, CFS-C also uses some other triggered algorithms [Holland, 1986c] to create new rules. For example, a triggered chainging operator <ref> [Robertson and Riolo, 1988] </ref> is available in CFS-C, to make it possible for the system to discover useful chains of coupled classifiers. Other triggered algorithms provide ways for the system to create rules that match novel detector messages, generate new actions, and so on. <p> See <ref> [Robertson and Riolo, 1988] </ref> for a further discussion of the CEO. 3.9.4 Triggered Chaining Operators Chains of coupled classifiers are required if classifier systems are to get beyond simple stimulus-response paradigms, to maintain short-term memory of messages, to carry out arbitrary computations, and so on. (A classifier C 1 is said <p> Thus the CFS-C system includes special Triggered Chaining operators designed to promote the formation of coupled rules. The implementation is similar to that proposed in [Holland, 1986c] and used in experiments described in <ref> [Robertson and Riolo, 1988] </ref> and [Riolo, 1988d]. There are actually two subroutines in CFS-C that form coupled rules: DscACPC () and DscCSS (). The latter implements what I call the CSS (Couple Stage Setter) operator, which is a generalization of the former ACPC operator. <p> used, one of the first features you might want to implement is a environment-specific HELP command, i.e., a way for a user to get information about environment-specific variables, comamnds, and so on. 5 Future Research While classifier systems have been used successfully in a variety of settings (cf. [Wilson, 1986c], <ref> [Robertson and Riolo, 1988] </ref>, [Sannier and Goodman, 1988]), a number of problems have surfaced over the past couple of years. Some of the most important problem areas are: * Premature Convergence. <p> While chains can emerge and serve to increase performance on simple problems ([Riolo, 1987a], <ref> [Robertson and Riolo, 1988] </ref>, [Riolo, 1988d]), chains longer than 4 or 5 rules are not very stable.
Reference: [Samuel, 1959] <author> Samuel, A. L. </author> <title> "Some Studies in Machine Learning Using the Game of Checkers." </title> <journal> IBM Journal of Research and Development, </journal> <volume> 3, </volume> <month> 211-232 </month> <year> (1959). </year>
Reference: [Sannier and Goodman, 1988] <author> Sannier, Adrian V., III, and Goodman, Erik D. </author> <month> "Midgard: </month>
Reference-contexts: first features you might want to implement is a environment-specific HELP command, i.e., a way for a user to get information about environment-specific variables, comamnds, and so on. 5 Future Research While classifier systems have been used successfully in a variety of settings (cf. [Wilson, 1986c], [Robertson and Riolo, 1988], <ref> [Sannier and Goodman, 1988] </ref>), a number of problems have surfaced over the past couple of years. Some of the most important problem areas are: * Premature Convergence. <p> The problem with simple rules 54 is that it takes a lot of rules, sometimes coupled in very complex and brittle struc-tures, to do higher-level computations ([Forrest, 1985], <ref> [Sannier and Goodman, 1988] </ref>, [Davis and Young, 1988], [Schuurmans and Schaeffer, 1988]).
References-found: 32

