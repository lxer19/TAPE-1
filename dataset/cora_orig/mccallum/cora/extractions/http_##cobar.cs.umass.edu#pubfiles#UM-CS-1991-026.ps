URL: http://cobar.cs.umass.edu/pubfiles/UM-CS-1991-026.ps
Refering-URL: http://cobar.cs.umass.edu/pubfiles/
Root-URL: 
Email: NetAd herbordt@cs.umass.EDU  
Title: A Computational Framework and SIMD Algorithms for Low-Level Support of Intermediate Level Vision Processing 1
Author: Martin C. Herbordt Charles C. Weems Michael J. Scudder 
Address: Amherst, Massachusetts 01003  
Affiliation: Computer and Information Sciences Department University of Massachusetts at Amherst  
Abstract: Computation on and among data sets mapped to irregular, non-uniform, aggregates of processing elements (PEs) is a very important, but largely ignored, problem in parallel vision processing. Associative processing [11] is an effective means of applying parallel processing to these computations [33], but is often restricted to operating on one data set at a time. What we propose is an additional level of parallelism we call multi-associativity as a framework for performing associative computation on these data sets simultaneously. In this paper we introduce algorithms developed for the Content Addressable Array Parallel Processor (CAAPP) [35] to simulate efficiently within aggregates of PEs simultaneously the associative algorithms typically supported in hardware at the array level. Some of the results are: the efficient application of existing associative algorithms (e.g. [10, 11]) to arbitrary aggregates of PEs in parallel, and the development of new multi-associative algorithms, among them parallel prefix and convex hull. The multi-associative framework also extends the associative paradigm by allowing operation on and among aggregates themselves, operations not defined when the entity in question is always an entire array. Two consequences are: support of divide-and-conquer algorithms within aggregates, and communication among aggregates. The rest of the paper describes a mapping of multi-associativity onto the CAAPP, and numerous multi-associative algorithms. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Annaratone, E. Arnould, T. Gross, H.T. Kung, M.Lam, O. Menzilcioglu, J.A. </author> <title> Webb (1987): "The Warp Computer: Architecture, Implementation, and Performance," </title> <journal> IEEE Trans. on Computers, </journal> <volume> C-36 (12). </volume>
Reference-contexts: In turn, algorithmic development inspires new types of hardware support, bringing to light new computational possibilities, influencing the way we think about machine vision. Similar research efforts can be found in <ref> [32, 21, 20, 26, 1] </ref> and others, with more or less emphasis on either the architecture or the vision end of the research. A common thread in these studies is that low-level vision involves more than the window-based operations that dominated earlier research.
Reference: [2] <author> F. Annexstein, M. Baumslag, M.C. Herbordt, B. Obrenic, A. Rosenberg, C.C. </author> <month> Weems </month> <year> (1990): </year> <title> "Achieving Multigauge Behavior in Bit-Serial SIMD Architectures via Emulation," </title> <booktitle> Proc. of the 3rd Symp. on the Frontiers of Massively Parallel Computation. </booktitle>
Reference-contexts: The algorithm requires a number of iterations equal to the number of bins, and each iteration contains one CountSe lectedPEs operation. ParallelPrefix. Among the applications that use parallel prefix are: the enumeration of selected PEs, Radix Sort, parsing regular languages [16], and carry propagation in multi-gauge emulation <ref> [2] </ref>. See [18, 5] for many more. ParallelPrefix can be run multi-associatively if the regions consist of rectangles; this technique is also extendible to semi-convex regions, that is, regions convex in the horizontal or vertical direction.
Reference: [3] <author> K.E. </author> <title> Batcher (1980): "Design of the Massively Parallel Processor," </title> <journal> IEEE Trans. on Computers, </journal> <volume> C-29 (9). </volume>
Reference-contexts: Communication between PEs themselves can take place in two different ways: by using the nearest neighbor mesh interconnection network, and via a reconfigurable mesh called the coterie network. The first method is similar to that used by the CLIP-4 [8], the MPP <ref> [3] </ref>, and the DAP [17]. In the second method, PEs transmit information by writing to a specified register connected to the coterie network. PEs then read a register which will have been set to the OR of these signals, within a local group as defined by the network configuration.
Reference: [4] <author> J.R. Beveridge, J. Griffith, R.R. Kohler, A.R. Hanson, </author> <title> E.M. Riseman (1989): "Segmenting Images Using Localized Histograms and Region Merging," </title> <journal> Int. J. of Computer Vision, </journal> <volume> 2 (3). </volume>
Reference-contexts: This version of CreateBorder-CornerList can only be run on simple regions as specified above. GetAdjacentRegionLabels. This routine is used in building a feature adjacency graph, a process essential in creating complex intermediate-level data structures, as well as to the region-merging phase of the segmentation algorithm in <ref> [4] </ref>. The routine starts with the 22 boundary PEs fetching the labels of the adjacent regions.
Reference: [5] <author> G.E. </author> <title> Blelloch (1989): "Scans as Primitive Parallel Operations," </title> <journal> IEEE Trans. on Computers, </journal> <volume> C-38 (11). </volume>
Reference-contexts: The algorithm requires a number of iterations equal to the number of bins, and each iteration contains one CountSe lectedPEs operation. ParallelPrefix. Among the applications that use parallel prefix are: the enumeration of selected PEs, Radix Sort, parsing regular languages [16], and carry propagation in multi-gauge emulation [2]. See <ref> [18, 5] </ref> for many more. ParallelPrefix can be run multi-associatively if the regions consist of rectangles; this technique is also extendible to semi-convex regions, that is, regions convex in the horizontal or vertical direction.
Reference: [6] <author> J. Brolio, B.A. Draper, J.R. Beveridge, </author> <title> A.R. Hanson (1989): "ISR: A Database for Symbolic Processing of Computer Vision," </title> <booktitle> IEEE Computer, </booktitle> <month> December. </month>
Reference-contexts: When abstracted, these collections of pixels can be represented symbolically as edges, lines, curves, patches, blobs, regions, and their combinations and intersections <ref> [6] </ref>. In the case where a group of pixels is determined to be a line, for example, it could be represented by two endpoints. Certain algorithmic approaches to low-level vision are well established, although their massive computational requirements make them impractically slow. <p> In one such system, the Intermediate Symbolic Representation (ISR) <ref> [6] </ref>, collections of contiguous image data with similar properties are stored as named and typed symbolic entities called tokens. We now refine our model of vision computation.
Reference: [7] <author> B.A. Draper, R.T. Collins, J. Brolio, A.R. Hanson, </author> <title> E.M. Riseman (1989): "The Schema System," </title> <journal> Int. J. of Computer Vision, </journal> <volume> 2 (3). </volume>
Reference-contexts: The processor at that level (the CAAPP) is a SIMD array of processing elements (PEs). The highest level must support processing by, and information exchange between, diverse course-grained processes <ref> [7] </ref>, including manipulation of 2D and 3D object models, as well as the complex control strategies needed to apply those processes. The high-level processor (SPA) will therefore run a LISP-based black-board system [9], but the details have not yet been fully defined. The intermediate level must provide several functions.
Reference: [8] <author> M.J.B. </author> <title> Duff (1978): "Review of the CLIP Image Processing System," </title> <booktitle> Proc. of the National Computing Conference, AFIPS, </booktitle> <pages> pp. 1055-1060. </pages>
Reference-contexts: Communication between PEs themselves can take place in two different ways: by using the nearest neighbor mesh interconnection network, and via a reconfigurable mesh called the coterie network. The first method is similar to that used by the CLIP-4 <ref> [8] </ref>, the MPP [3], and the DAP [17]. In the second method, PEs transmit information by writing to a specified register connected to the coterie network. <p> PEs then read a register which will have been set to the OR of these signals, within a local group as defined by the network configuration. This scheme is a generalization of the "flash-through" mode of the ILLIAC III [23] and the propagate operation in the CLIP-4 <ref> [8] </ref>, and is similar to those proposed by [24, 20]. In order to distinguish broadcast by PEs from the usual broadcast by the controller, we refer to this operation as "coterie multicast". The coterie network is one powerful addition that the CAAPP has over conventional associative processors.
Reference: [9] <author> L. Erman, F. Hayes-Roth, V. Lesser, D. </author> <title> Reddy (1980): "The Hearsay-II Speech Understanding System: Integrating Knowledge to Resolve Uncertainty," </title> <journal> Computing Surveys 12 (2). </journal>
Reference-contexts: The highest level must support processing by, and information exchange between, diverse course-grained processes [7], including manipulation of 2D and 3D object models, as well as the complex control strategies needed to apply those processes. The high-level processor (SPA) will therefore run a LISP-based black-board system <ref> [9] </ref>, but the details have not yet been fully defined. The intermediate level must provide several functions. One is assisting the CAAPP with feature extraction by providing control and dynamic structures; shared memory is used 8 here. Another is supporting high-level queries.
Reference: [10] <author> A.D. </author> <title> Falkoff (1962): "Algorithms for Parallel Search Memories," </title> <journal> Journal of the ACM, </journal> <volume> 9 (4), </volume> <pages> pp. 488-511. </pages>
Reference-contexts: Select Max/Min. The goal is to select the PEs with the greatest value within a coterie. The method is to apply a standard associative array algorithm <ref> [10] </ref> to regions. At no extra cost, all the PEs in the coterie "listen in" on the process, and so know the greatest value itself at the end of the algorithm.
Reference: [11] <author> C.C. </author> <title> Foster (1976): Content Addressable Parallel Processors, </title> <publisher> Van Nostrand Reinhold Co. </publisher> <address> New York. </address>
Reference-contexts: However, it is exactly these operations that characterize associative processing (also called content addressable processing). There are four capabilities that are key for the classical model of associative computation <ref> [11] </ref>: 1. Global Broadcast/Local Compare/Activity Control 2. Some/None Response 3. Count Responders 4. Select a Single Responder The prototypical associative operation is for the controller to broadcast a query to the array, and to receive a response either in the form of Some/None (global OR) or a Count. <p> Although problems remain when there are tens of regions all with tens of local minima, the likelihood of such patterns arising as the output of an image segmentation is very small. GetMean. The next two algorithms are derived from the standard associative model <ref> [11] </ref>: they can now be applied multi-associatively as all of the basic operations have been implemented. The algorithm to find the mean is similar to SelectMax in that both are bit serial over a k-bit label, and both run from high to low order (k 1 to 0).
Reference: [12] <author> R.L. </author> <title> Graham (1972): "An Efficient Algorithm For Determining the Convex Hull of a 29 Planar Set," </title> <journal> Information Processing Letters, </journal> <volume> 1, </volume> <pages> pp. 132-133. </pages>
Reference-contexts: Intuitively, the convex hull in a plane can be found by conceptually wrapping S with a rubber band and eliminating the interior points [27]. Two leading methods for finding the convex hull on a serial processor are the Graham Scan <ref> [12] </ref> and the Jarvis March [19]. The Graham Scan works as follows: A point p known to be on the hull is chosen. Without loss of generality, let p be the point with the smallest X-coordinate, where smallest Y-coordinate breaks any ties.
Reference: [13] <author> A.R. Hanson and E.M. </author> <month> Riseman </month> <year> (1987): </year> <title> "The VISIONS Image Understanding System-1986," </title> <booktitle> in Advances in Computer Vision, </booktitle> <editor> C. Brown ed., </editor> <publisher> Erlbaum, </publisher> <address> Hillsdale, N.J. </address>
Reference-contexts: 1 Introduction According to one popular methodology <ref> [22, 13] </ref>, the task of low-level machine vision is to reduce the enormous amounts of input data to a manageable size, and to present those data in a format or representation that allows their easy manipulation.
Reference: [14] <author> M.C. Herbordt, </author> <title> C.C. Weems, D.B. </title> <booktitle> Shu (1990): "Routing on the CAAPP," Proc. of the 10th Int. Conf. on Pattern Recognition. </booktitle>
Reference-contexts: Other combine operations include MaxCombine and combine with boolean operators such as OrCombine. On the CAAPP, route and combine are implemented as software functions; more details are given in <ref> [14, 15] </ref>. OrCombine is also implemented using coterie multicast. As long as the distinct sets of sending and receiving PEs are members of the same coteries, the result of a multicast is precisely the logical OR of the transmitted values.
Reference: [15] <author> M.C. Herbordt, </author> <title> C.C. Weems, J.C. Corbett (1990): "Message Passing Algorithms for a SIMD Torus with Coteries," </title> <booktitle> Proc. of the 2nd ACM Symp. on Parallel Algorithms and Architectures. </booktitle>
Reference-contexts: Other combine operations include MaxCombine and combine with boolean operators such as OrCombine. On the CAAPP, route and combine are implemented as software functions; more details are given in <ref> [14, 15] </ref>. OrCombine is also implemented using coterie multicast. As long as the distinct sets of sending and receiving PEs are members of the same coteries, the result of a multicast is precisely the logical OR of the transmitted values.
Reference: [16] <author> W.D. Hillis and G.L. Steele Jr. </author> <year> (1986): </year> <title> "Data Parallel Algorithms," </title> <journal> Comm. of the ACM, </journal> <volume> 29 (12). </volume>
Reference-contexts: Run CountSelectedPEs to get the bin count. The algorithm requires a number of iterations equal to the number of bins, and each iteration contains one CountSe lectedPEs operation. ParallelPrefix. Among the applications that use parallel prefix are: the enumeration of selected PEs, Radix Sort, parsing regular languages <ref> [16] </ref>, and carry propagation in multi-gauge emulation [2]. See [18, 5] for many more. ParallelPrefix can be run multi-associatively if the regions consist of rectangles; this technique is also extendible to semi-convex regions, that is, regions convex in the horizontal or vertical direction.
Reference: [17] <author> D.J. </author> <title> Hunt (1981): "The ICL DAP and its Application to Image Processing," in Languages and Architectures for Image Processing, </title> <editor> M.J.B. Duff and S. Levialdi eds., </editor> <publisher> Academic Press, London. </publisher>
Reference-contexts: Communication between PEs themselves can take place in two different ways: by using the nearest neighbor mesh interconnection network, and via a reconfigurable mesh called the coterie network. The first method is similar to that used by the CLIP-4 [8], the MPP [3], and the DAP <ref> [17] </ref>. In the second method, PEs transmit information by writing to a specified register connected to the coterie network. PEs then read a register which will have been set to the OR of these signals, within a local group as defined by the network configuration.
Reference: [18] <author> R.M. Karp and V. </author> <title> Ramachandran (1988): "A Survey of Parallel Algorithms for Shared-Memory Machines," </title> <journal> TR 88.408, </journal> <note> U.C.B. </note>
Reference-contexts: The algorithm requires a number of iterations equal to the number of bins, and each iteration contains one CountSe lectedPEs operation. ParallelPrefix. Among the applications that use parallel prefix are: the enumeration of selected PEs, Radix Sort, parsing regular languages [16], and carry propagation in multi-gauge emulation [2]. See <ref> [18, 5] </ref> for many more. ParallelPrefix can be run multi-associatively if the regions consist of rectangles; this technique is also extendible to semi-convex regions, that is, regions convex in the horizontal or vertical direction.
Reference: [19] <author> R.A. </author> <title> Jarvis (1973): "On the Identification of the Convex Hull of a Finite Set of Points in the Plane," </title> <journal> Information Processing Letters, </journal> <volume> 2, </volume> <pages> pp. 18-21. </pages>
Reference-contexts: Intuitively, the convex hull in a plane can be found by conceptually wrapping S with a rubber band and eliminating the interior points [27]. Two leading methods for finding the convex hull on a serial processor are the Graham Scan [12] and the Jarvis March <ref> [19] </ref>. The Graham Scan works as follows: A point p known to be on the hull is chosen. Without loss of generality, let p be the point with the smallest X-coordinate, where smallest Y-coordinate breaks any ties.
Reference: [20] <author> H. Li and M. </author> <title> Maresca (1989): "The Polymorphic-Torus Architecture for Computer Vision," </title> <journal> IEEE Trans. on PAMI, </journal> <volume> PAMI-11 (3). </volume>
Reference-contexts: In turn, algorithmic development inspires new types of hardware support, bringing to light new computational possibilities, influencing the way we think about machine vision. Similar research efforts can be found in <ref> [32, 21, 20, 26, 1] </ref> and others, with more or less emphasis on either the architecture or the vision end of the research. A common thread in these studies is that low-level vision involves more than the window-based operations that dominated earlier research. <p> This scheme is a generalization of the "flash-through" mode of the ILLIAC III [23] and the propagate operation in the CLIP-4 [8], and is similar to those proposed by <ref> [24, 20] </ref>. In order to distinguish broadcast by PEs from the usual broadcast by the controller, we refer to this operation as "coterie multicast". The coterie network is one powerful addition that the CAAPP has over conventional associative processors. <p> However, the coterie network can also be set so that columns and rows are isolated. Once this is done, the row and column "buses" can be arbitrarily segmented still further. The coterie network can thus emulate the mesh with reconfigurable buses [24], and the polymorphic-torus <ref> [20] </ref>. In this mode, the coterie network is well suited for many algorithms designed for regular topologies, such as general routing, parallel prefix, emulation of various networks, and many other useful constructs.
Reference: [21] <author> J.J. Little, G.E. Blelloch, T.A. </author> <title> Cass (1989): "Algorithmic Techniques for Computer Vision on a Fine-Grained Parallel Machine," </title> <journal> IEEE Trans. on PAMI, </journal> <volume> PAMI-11 (3). </volume>
Reference-contexts: In turn, algorithmic development inspires new types of hardware support, bringing to light new computational possibilities, influencing the way we think about machine vision. Similar research efforts can be found in <ref> [32, 21, 20, 26, 1] </ref> and others, with more or less emphasis on either the architecture or the vision end of the research. A common thread in these studies is that low-level vision involves more than the window-based operations that dominated earlier research.
Reference: [22] <author> D. </author> <title> Marr (1982): Vision, W.H. </title> <publisher> Freeman, </publisher> <address> San Francisco, CA. </address>
Reference-contexts: 1 Introduction According to one popular methodology <ref> [22, 13] </ref>, the task of low-level machine vision is to reduce the enormous amounts of input data to a manageable size, and to present those data in a format or representation that allows their easy manipulation.
Reference: [23] <author> B.T. </author> <title> McCormick (1963): "The Illinois Pattern Recognition Computer - ILLIAC III," </title> <journal> IEEE Trans. on Elect. Computers, </journal> <volume> C-12 (12). </volume>
Reference-contexts: PEs then read a register which will have been set to the OR of these signals, within a local group as defined by the network configuration. This scheme is a generalization of the "flash-through" mode of the ILLIAC III <ref> [23] </ref> and the propagate operation in the CLIP-4 [8], and is similar to those proposed by [24, 20]. In order to distinguish broadcast by PEs from the usual broadcast by the controller, we refer to this operation as "coterie multicast".
Reference: [24] <author> R. Miller, V.K. Prasanna Kumar, D. Reisis, Q.F. </author> <title> Stout (1988): "Meshes With Reconfigurable Buses," </title> <booktitle> Proc. of the MIT Conf. on Advanced Research in VLSI. </booktitle>
Reference-contexts: This scheme is a generalization of the "flash-through" mode of the ILLIAC III [23] and the propagate operation in the CLIP-4 [8], and is similar to those proposed by <ref> [24, 20] </ref>. In order to distinguish broadcast by PEs from the usual broadcast by the controller, we refer to this operation as "coterie multicast". The coterie network is one powerful addition that the CAAPP has over conventional associative processors. <p> However, the coterie network can also be set so that columns and rows are isolated. Once this is done, the row and column "buses" can be arbitrarily segmented still further. The coterie network can thus emulate the mesh with reconfigurable buses <ref> [24] </ref>, and the polymorphic-torus [20]. In this mode, the coterie network is well suited for many algorithms designed for regular topologies, such as general routing, parallel prefix, emulation of various networks, and many other useful constructs.
Reference: [25] <author> D. Nassimi and S. </author> <title> Sahni (1980): "Finding Connected Components and Connected Ones on a Mesh-Connected Parallel Computer," </title> <journal> SIAM Journal of Computing, </journal> <volume> 9 (4). </volume> <pages> 30 </pages>
Reference-contexts: Precedents do exist, however, demonstrating that careful orchestration of SIMD communication can promote complex behavior: the sorting algorithms of Thompson and Kung [31] and the connected components algorithm of Nassimi and Sahni <ref> [25] </ref> are examples, though the communication is still regular. Willebeek-LeMair and Reeves [37] have embedded binary trees in meshes to implement broadcast and reduction primitives on non-uniform, arbitrarily, shaped contiguous regions, and applied those operations with great success to parallel region segmentation.
Reference: [26] <author> V.K. Prasanna Kumar and D. </author> <month> Reisis </month> <year> (1989): </year> <title> "Image Computations on Meshes with Multiple Broadcast," </title> <journal> IEEE Trans. on PAMI, </journal> <volume> PAMI-11 (11). </volume>
Reference-contexts: In turn, algorithmic development inspires new types of hardware support, bringing to light new computational possibilities, influencing the way we think about machine vision. Similar research efforts can be found in <ref> [32, 21, 20, 26, 1] </ref> and others, with more or less emphasis on either the architecture or the vision end of the research. A common thread in these studies is that low-level vision involves more than the window-based operations that dominated earlier research.
Reference: [27] <author> F.P. Preparata and M.I. </author> <title> Shamos (1985): Computational Geometry An Introduction, </title> <publisher> Springer-Verlag, </publisher> <address> New York. </address>
Reference-contexts: ConvexHull. The convex hull of a set of points S is defined as the smallest convex set contained in S. Intuitively, the convex hull in a plane can be found by conceptually wrapping S with a rubber band and eliminating the interior points <ref> [27] </ref>. Two leading methods for finding the convex hull on a serial processor are the Graham Scan [12] and the Jarvis March [19]. The Graham Scan works as follows: A point p known to be on the hull is chosen.
Reference: [28] <author> D. Rana and C.C. </author> <month> Weems </month> <year> (1990): </year> <title> "A Feedback Concentrator for the Image Understanding Architecture," </title> <booktitle> Proc. of the Int. Conf. on Application Specific Array Processors, </booktitle> <pages> pp. 579-590. </pages>
Reference-contexts: Therefore the CAAPP has been designed with specialized hardware for the rapid execution of Some/None, Response Count, and Select Single Responder (Select-First) <ref> [28] </ref>. Typical execution times of these operations are 0.1, 1.6, and 2.4 micro-seconds, respectively. For reference, the execution of a bit serial arithmetic operation takes between 1 and 6 microseconds. 2.3 Multi-Associative Processing Associative processing permits operations on any single selected subset of the data.
Reference: [29] <author> E.M. Riseman and A.R. </author> <title> Hanson (1989): </title> <journal> "Computer Vision Research at the University of Massachusetts-Themes," Int. J. of Computer Vision, </journal> <volume> 2 (3). </volume>
Reference-contexts: The work presented here is part of a machine vision research program to develop methodologies, determine their computational requirements, design hardware that meets those requirements, and provide algorithms for that hardware <ref> [29] </ref>. In turn, algorithmic development inspires new types of hardware support, bringing to light new computational possibilities, influencing the way we think about machine vision.
Reference: [30] <author> A. </author> <title> Rosenfeld (1984): "Image Analysis: Problems, Progress and Prospects," </title> <journal> Pattern Recognition, </journal> <volume> 17 (1), </volume> <pages> pp. 3-12. </pages>
Reference-contexts: Sensory data processing uses the image array representation 2 and includes line and region segmentation; stereo, motion, and texture analysis; shape from X, as well as other computations. An example of world knowledge processing might be constrained model matching between "stored models in the form of generalized relational structures <ref> [30] </ref>", and hypotheses created from the image data.
Reference: [31] <author> C.D. Thompson and H.T. </author> <title> Kung (1977): "Sorting on a Mesh Connected Computer," </title> <journal> Communications of the ACM, </journal> <volume> 20 (4). </volume>
Reference-contexts: Precedents do exist, however, demonstrating that careful orchestration of SIMD communication can promote complex behavior: the sorting algorithms of Thompson and Kung <ref> [31] </ref> and the connected components algorithm of Nassimi and Sahni [25] are examples, though the communication is still regular.
Reference: [32] <editor> L.W. </editor> <booktitle> Tucker (1988): "Architecture and Applications of the Connection Machine," IEEE Computer, </booktitle> <month> August, </month> <pages> pp. 26-38. </pages>
Reference-contexts: In turn, algorithmic development inspires new types of hardware support, bringing to light new computational possibilities, influencing the way we think about machine vision. Similar research efforts can be found in <ref> [32, 21, 20, 26, 1] </ref> and others, with more or less emphasis on either the architecture or the vision end of the research. A common thread in these studies is that low-level vision involves more than the window-based operations that dominated earlier research.
Reference: [33] <author> C.C. </author> <month> Weems </month> <year> (1984): </year> <title> "Image Processing on a Content Addressable Array Parallel Processor," </title> <type> COINS Tech. Rpt. 84-14 and Ph.D. Dissertation, </type> <institution> University of Massachusetts. </institution>
Reference-contexts: Only subsets of the data are involved in any particular operation, but all pixels and events with a given set of properties are processed in parallel. See <ref> [33, 35] </ref> for numerous examples of associative vision algorithms. Let us examine in more detail the fundamental operations required for associative processing, and the hardware support required to perform them efficiently.
Reference: [34] <editor> C.C. Weems, E.M. Riseman, A.R. Hanson, A. Rosenfeld (1988): </editor> <booktitle> "IU Parallel Processing Benchmark," Proc. of the Computer Society Conference on Computer Vision and Pattern Recognition. </booktitle>
Reference-contexts: Although this routine consists of a single application of multicast, it shows the versatility of the IUA model to include graphics functions. Assume that a list containing the color and the address of the leader PE of each region is known in the ICAP, a scenario that occurs in <ref> [34] </ref>. The ICAP loads the color into the memory of each leader. The leaders then multicast the color to their regions. TraceBorder. One of the steps required in [34] was identifying the outer perimeters of connected regions. <p> the color and the address of the leader PE of each region is known in the ICAP, a scenario that occurs in <ref> [34] </ref>. The ICAP loads the color into the memory of each leader. The leaders then multicast the color to their regions. TraceBorder. One of the steps required in [34] was identifying the outer perimeters of connected regions. The information locally available around a pixel is not sufficient to distinguish inner from outer borders, as occur, for example, in doughnut shaped regions.
Reference: [35] <author> C.C. Weems, S.P. Levitan, A.R. Hanson, E.M. Riseman, J.G. Nash, </author> <title> D.B. Shu (1989): "The Image Understanding Architecture," </title> <journal> Int. J. of Computer Vision, </journal> <volume> 2 (3). </volume>
Reference-contexts: Only subsets of the data are involved in any particular operation, but all pixels and events with a given set of properties are processed in parallel. See <ref> [33, 35] </ref> for numerous examples of associative vision algorithms. Let us examine in more detail the fundamental operations required for associative processing, and the hardware support required to perform them efficiently. <p> The philosophy behind the Image Understanding Architecture is that qualitatively different types of computation require qualitatively different types of architectures. A detailed discussion of requirements can be found elsewhere <ref> [35] </ref>; we summarize a few that are relevant here: the ability to process both pixel and symbol data in parallel, the ability to simultaneously maintain the representations and perform computations at the low, intermediate, and high levels, the ability to select particular subsets of data for varying types of processing, and
Reference: [36] <editor> C.C. Weems, E.M. Riseman, A.R. Hanson, A. Rosenfeld (1991): </editor> <title> "An Image Understanding Benchmark for Parallel Computers," </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 11 (1). </volume>
Reference-contexts: Until recently, our approach when confronted with the need to solve problems on mul 1 tiple irregular aggregates of PEs has been ad hoc: we have often achieved good results <ref> [36] </ref>, but have not previously used any uniform technique. Precedents do exist, however, demonstrating that careful orchestration of SIMD communication can promote complex behavior: the sorting algorithms of Thompson and Kung [31] and the connected components algorithm of Nassimi and Sahni [25] are examples, though the communication is still regular.
Reference: [37] <author> M. </author> <title> Willebeek-LeMair and A.P. Reeves (1990): "Solving Nonuniform Problems on SIMD Computers: Case Study on Region Growing," </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 8. </volume> <pages> 31 </pages>
Reference-contexts: Precedents do exist, however, demonstrating that careful orchestration of SIMD communication can promote complex behavior: the sorting algorithms of Thompson and Kung [31] and the connected components algorithm of Nassimi and Sahni [25] are examples, though the communication is still regular. Willebeek-LeMair and Reeves <ref> [37] </ref> have embedded binary trees in meshes to implement broadcast and reduction primitives on non-uniform, arbitrarily, shaped contiguous regions, and applied those operations with great success to parallel region segmentation. We begin with a brief review of the vision methodology and computational requirements driving our research.
References-found: 37

