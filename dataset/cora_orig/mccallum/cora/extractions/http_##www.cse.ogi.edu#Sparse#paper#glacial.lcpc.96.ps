URL: http://www.cse.ogi.edu/Sparse/paper/glacial.lcpc.96.ps
Refering-URL: http://www.cse.ogi.edu/~tito/research/
Root-URL: http://www.cse.ogi.edu
Author: Autrey and Michael Wolfe 
Address: P.O. Box 91000 Portland, Oregon 97291-1000, USA  
Affiliation: Department of Computer Science and Engineering Oregon Graduate Institute of Science and Technology  
Note: Tito  
Abstract: Initial Results for Glacial Variable Analysis Abstract. Run-time code generation that uses specific values to generate specialized code is called value-specific optimization. Variables which provide values for value-specific optimization are called candidate variables. They are modified much less frequently than they are referenced. In current systems that use run-time code generation, candidate variables are identified by programmer directives. We describe a novel technique, staging analysis, for automatically identifying candidate variables. We refer to such variables as glacial variables. Glacial variables are excellent candidate variables. Glacial Variable Analysis is an interprocedural analysis. We perform several experiments with glacial variable analysis to characterize the programs in the PERFECT benchmark suite. We explain the imprecision of our results due to procedure boundaries. We examine the structure of the programs to determine how often value-specific optimization might be applied. We will explain how staging analysis relates to run-time code generation; briefly describe Glacial Variable Analysis; and, present some initial results. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> J. Auslander, M. Philipose, C. Chambers, S. J. Eggers, and B. N. Bershad. </author> <title> Fast, effective dynamic compilation. </title> <booktitle> In PLDI96 [14], </booktitle> <pages> pages 149-159. </pages>
Reference-contexts: Current approaches to compiler-inserted RTCG require the programmer to insert directives into the program source code that identify candidate variables <ref> [1, 4, 5, 12] </ref>. We use a staging analysis, Glacial Variable Analysis, to automatically identify candidate variables from two pieces of information. One, it estimates the execution frequency of each block of code. Two, it labels each expression and subexpression with its estimated modification frequency. <p> We call the combination of the where analysis and the what-to-do rule set, a staging transformation system. Early work consists only of the rules, and we add the supporting analysis. There are several compiler-supported RTCG systems <ref> [1, 4, 5, 12] </ref>. All of them rely on programmer annotations to identify candidate variables for VSO. Leone and Lee's Fabius system [12] is the first RTCG system to identify staging transformations as a more powerful technique than partial evaluation, but they have not yet implemented staging transformations.
Reference: 2. <author> R. A. Ballance, A. B. Maccabe, and K. J. Ottenstein. </author> <title> The Program Dependence Web: A representation supporting control-, data-, and demand-driven interpretation of imperative languages. </title> <booktitle> In Proc. ACM SIGPLAN '90 Conf. on Programming Language Design and Implementation, </booktitle> <pages> pages 257-271, </pages> <address> White Plains, NY, </address> <month> June </month> <year> 1990. </year>
Reference-contexts: Assignments are labeled with the meet of the stage-level lattice elements of the right-hand side expression after operator folding. -functions are labeled with the VSL corresponding to the CSL of their containing block. Our SSA form is extended with and-functions in the manner of Gated Single Assignment (GSA) <ref> [2, 9] </ref>. - functions are -functions at loop headers. The VSL of a -function is labeled equivalently to a -function. The -function captures the stage-level for variables modified within a loop. At each loop exit there is an -function capturing the final value of a variable modified within the loop.
Reference: 3. <author> C. Consel and O. Danvy. </author> <title> Tutorial notes on partial evaluation. </title> <booktitle> In Conf. Record 20th Annual ACM Symp. Principles of Programming Languages, </booktitle> <pages> pages 493-501, </pages> <address> Charleston, SC, </address> <month> Jan. </month> <year> 1993. </year>
Reference-contexts: 1 Introduction Specialization is tailoring general-purpose procedures to a specific invocation or set of invocations. Specialization takes advantage of specific values of parameters. Functional language compilers use partial evaluation to produce specialized versions of functions <ref> [3] </ref>. Imperative language compilers use procedure cloning for the same purpose [7]. Value-specific optimization (VSO) uses run-time code generation (RTCG) to produce specialized code at run-time instead of compile-time [11]. Value-specific optimization is effective when the total run-time of the program is reduced.
Reference: 4. <author> C. Consel and F. Noel. </author> <title> A general approach to run-time specialization and its application to C. </title> <booktitle> In Conf. Record 23rd Annual ACM Symp. Principles of Programming Languages, </booktitle> <pages> pages 145-156, </pages> <address> St Petersburg, FL, </address> <month> Jan. </month> <year> 1996. </year>
Reference-contexts: Current approaches to compiler-inserted RTCG require the programmer to insert directives into the program source code that identify candidate variables <ref> [1, 4, 5, 12] </ref>. We use a staging analysis, Glacial Variable Analysis, to automatically identify candidate variables from two pieces of information. One, it estimates the execution frequency of each block of code. Two, it labels each expression and subexpression with its estimated modification frequency. <p> We call the combination of the where analysis and the what-to-do rule set, a staging transformation system. Early work consists only of the rules, and we add the supporting analysis. There are several compiler-supported RTCG systems <ref> [1, 4, 5, 12] </ref>. All of them rely on programmer annotations to identify candidate variables for VSO. Leone and Lee's Fabius system [12] is the first RTCG system to identify staging transformations as a more powerful technique than partial evaluation, but they have not yet implemented staging transformations.
Reference: 5. <author> D. R. Engler. </author> <title> Vcode: A retargetable, extensible, very fast dynamic code generation system. </title> <booktitle> In PLDI96 [14], </booktitle> <pages> pages 160-170. </pages>
Reference-contexts: Current approaches to compiler-inserted RTCG require the programmer to insert directives into the program source code that identify candidate variables <ref> [1, 4, 5, 12] </ref>. We use a staging analysis, Glacial Variable Analysis, to automatically identify candidate variables from two pieces of information. One, it estimates the execution frequency of each block of code. Two, it labels each expression and subexpression with its estimated modification frequency. <p> We call the combination of the where analysis and the what-to-do rule set, a staging transformation system. Early work consists only of the rules, and we add the supporting analysis. There are several compiler-supported RTCG systems <ref> [1, 4, 5, 12] </ref>. All of them rely on programmer annotations to identify candidate variables for VSO. Leone and Lee's Fabius system [12] is the first RTCG system to identify staging transformations as a more powerful technique than partial evaluation, but they have not yet implemented staging transformations.
Reference: 6. <author> A. Ershov. </author> <title> Mixed computation: The potential applications and problems for study. </title> <journal> Theoretical Computer Science, </journal> <volume> 18 </volume> <pages> 41-67, </pages> <year> 1982. </year>
Reference-contexts: Degrees of glacialness (Z-axis) by stage-level (X-axis) for PERFECT suite (ar-rays) run-time to compile-time [13]. This is very similar to partial evaluation. In fact, Ershov shows that what is traditionally called partial evaluation is a subset of what Jorring and Scherlis call staging transformations <ref> [6] </ref>. One of our results is that it is useful to separate the transformation rules from the decision of where to apply them. We call the combination of the where analysis and the what-to-do rule set, a staging transformation system.
Reference: 7. <author> M. Hall. </author> <title> Managing Interprocedural Optimization. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, Rice University, </institution> <year> 1991. </year>
Reference-contexts: 1 Introduction Specialization is tailoring general-purpose procedures to a specific invocation or set of invocations. Specialization takes advantage of specific values of parameters. Functional language compilers use partial evaluation to produce specialized versions of functions [3]. Imperative language compilers use procedure cloning for the same purpose <ref> [7] </ref>. Value-specific optimization (VSO) uses run-time code generation (RTCG) to produce specialized code at run-time instead of compile-time [11]. Value-specific optimization is effective when the total run-time of the program is reduced. The execution time savings must exceed the cost of RTCG.
Reference: 8. <author> M. Hall and K. Kennedy. </author> <title> Efficient call graph analysis. </title> <journal> Letters on Programming Languages and Systems, </journal> <volume> 1(3) </volume> <pages> 227-242, </pages> <month> September </month> <year> 1992. </year>
Reference-contexts: Following is summary of the full interprocedural GRLA: 1. Within each procedure, compute its natural loops and loop nest-levels. 2. Compute the complete call graph. We use Hall and Kennedy's algorithm <ref> [8] </ref>. 3. Assign CSLs to each procedure.
Reference: 9. <author> P. Havlak. </author> <title> Construction of Thinned Gated Single-Assignment form. </title> <editor> In U. Banerjee, D. Gelernter, A. Nicolau, and D. A. Padua, editors, </editor> <booktitle> Languages and Compilers for Parallel Computing, number 768 in Lecture Notes in Computer Science, </booktitle> <pages> pages 477 - 499. </pages> <publisher> Springer-Verlag, </publisher> <year> 1993. </year>
Reference-contexts: Assignments are labeled with the meet of the stage-level lattice elements of the right-hand side expression after operator folding. -functions are labeled with the VSL corresponding to the CSL of their containing block. Our SSA form is extended with and-functions in the manner of Gated Single Assignment (GSA) <ref> [2, 9] </ref>. - functions are -functions at loop headers. The VSL of a -function is labeled equivalently to a -function. The -function captures the stage-level for variables modified within a loop. At each loop exit there is an -function capturing the final value of a variable modified within the loop.
Reference: 10. <author> D. Keppel. </author> <title> Runtime Code Generation. </title> <type> PhD thesis, </type> <institution> University of Washington Department of Computer Science and Engineering, </institution> <month> Mar. </month> <year> 1996. </year>
Reference-contexts: The execution time savings must exceed the cost of RTCG. The cost is paid for when the # invocations fl savings=invocation is high enough. Value-specific optimization uses slowly changing variables to ensure effectiveness. Keppel refers to these variables as candidate variables <ref> [10] </ref>. We call them glacial variables because they vary glacially. A staging transformation system takes a source-language program and a set of transformation rules, and partitions a program into two stages. It moves computations from the late stage into the early one [13].
Reference: 11. <author> D. Keppel, S. Eggers, and R. Henry. </author> <title> Evaluating runtime-compiled value-specific optimizations. </title> <type> Technical Report UWCSE 93-11-02, </type> <institution> University of Washington Department of Computer Science and Engineering, </institution> <month> November </month> <year> 1993. </year>
Reference-contexts: Specialization takes advantage of specific values of parameters. Functional language compilers use partial evaluation to produce specialized versions of functions [3]. Imperative language compilers use procedure cloning for the same purpose [7]. Value-specific optimization (VSO) uses run-time code generation (RTCG) to produce specialized code at run-time instead of compile-time <ref> [11] </ref>. Value-specific optimization is effective when the total run-time of the program is reduced. The execution time savings must exceed the cost of RTCG. The cost is paid for when the # invocations fl savings=invocation is high enough. Value-specific optimization uses slowly changing variables to ensure effectiveness.
Reference: 12. <author> P. Lee and M. Leone. </author> <title> Optimizing ML with run-time code generation. </title> <booktitle> In PLDI96 [14], </booktitle> <pages> pages 137-148. </pages>
Reference-contexts: Current approaches to compiler-inserted RTCG require the programmer to insert directives into the program source code that identify candidate variables <ref> [1, 4, 5, 12] </ref>. We use a staging analysis, Glacial Variable Analysis, to automatically identify candidate variables from two pieces of information. One, it estimates the execution frequency of each block of code. Two, it labels each expression and subexpression with its estimated modification frequency. <p> We call the combination of the where analysis and the what-to-do rule set, a staging transformation system. Early work consists only of the rules, and we add the supporting analysis. There are several compiler-supported RTCG systems <ref> [1, 4, 5, 12] </ref>. All of them rely on programmer annotations to identify candidate variables for VSO. Leone and Lee's Fabius system [12] is the first RTCG system to identify staging transformations as a more powerful technique than partial evaluation, but they have not yet implemented staging transformations. <p> Early work consists only of the rules, and we add the supporting analysis. There are several compiler-supported RTCG systems [1, 4, 5, 12]. All of them rely on programmer annotations to identify candidate variables for VSO. Leone and Lee's Fabius system <ref> [12] </ref> is the first RTCG system to identify staging transformations as a more powerful technique than partial evaluation, but they have not yet implemented staging transformations. The programmer separates the arguments into an early-tuple and a late-tuple.
Reference: 13. <author> U. Jtrring and W. L. Scherlis. </author> <title> Compilers and staging transformations. </title> <booktitle> In Conf. Record 13th Annual ACM Symp. on Principles of Programming Languages, </booktitle> <pages> pages 86-96, </pages> <address> St. Petersburg Beach, </address> <month> Jan. </month> <year> 1986. </year>
Reference-contexts: We call them glacial variables because they vary glacially. A staging transformation system takes a source-language program and a set of transformation rules, and partitions a program into two stages. It moves computations from the late stage into the early one <ref> [13] </ref>. In classical work, the compiler is the first stage, and it evaluates expressions that use only compile-time values, such as constants. Consequently the cost of the first stage is treated as zero. The rules are syntax-based and are universally applied. <p> It can identify the computation stages by examining the control flow structure of the program. Staging transformations are syntactic rules used to move computations from Fig. 6. Degrees of glacialness (Z-axis) by stage-level (X-axis) for PERFECT suite (ar-rays) run-time to compile-time <ref> [13] </ref>. This is very similar to partial evaluation. In fact, Ershov shows that what is traditionally called partial evaluation is a subset of what Jorring and Scherlis call staging transformations [6].
Reference: 14. <editor> Proceedings ACM SIGPLAN '96 Conf. </editor> <booktitle> on Programming Language Design and Implementation, </booktitle> <address> Philadelphia, PA, </address> <month> May </month> <year> 1996. </year>
Reference: 15. <author> M. N. Wegman and F. K. Zadeck. </author> <title> Constant propagation with conditional branches. </title> <journal> ACM Trans. on Programming Languages and Systems, </journal> <volume> 13(2) </volume> <pages> 181-210, </pages> <month> Apr. </month> <year> 1991. </year> <title> This article was processed using the L A T E X macro package with LLNCS style </title>
Reference-contexts: Result Constant (v 1 )" Constant (v 2 ) Constant (v 1 ) if v 1 = v 2 , CSL () otherwise Constant "X X Stage-i " Stage-j Stage MAX (i; j) Glacial variable propagation is a minor modification of Wegman and Zadeck's sparse conditional constant propagation algorithm (WZ) <ref> [15] </ref>. We use a taller 3 GOTO statements in or out of loops may require constructing code blocks at particular stage-levels for -functions or the analysis may be abandoned for such procedures or programs. Table 2.
References-found: 15

