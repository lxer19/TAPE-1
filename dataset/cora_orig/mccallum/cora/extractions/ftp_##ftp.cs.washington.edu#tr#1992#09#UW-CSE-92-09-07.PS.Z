URL: ftp://ftp.cs.washington.edu/tr/1992/09/UW-CSE-92-09-07.PS.Z
Refering-URL: http://www.cs.washington.edu/research/tr/tr-by-title.html
Root-URL: 
Title: Improving the Performance of Message-Passing Applications by Multithreading  
Author: Edward W. Felten and Dylan McNamee 
Date: 92-09-07  
Affiliation: Department of Computer Science and Engineering University of Washington  
Pubnum: Technical Report  
Abstract: Achieving maximum performance in message-passing programs requires that calculation and communication be overlapped. However, the program transformations required to achieve this overlap are error-prone and add significant complexity to the application program. We argue that calculation/communication overlap can be achieved easily and consistently by executing multiple threads of control on each processor, and that this approach is practical on message-passing architectures without any special hardware support. We present timing data for a typical message-passing application, to demonstrate the advantages of our scheme. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Thomas E. Anderson, Brian N. Bershad, Edward D. Lazowska, and Henry M. Levy. </author> <title> Scheduler activations: Effective kernel support for the user-level management of parallelism. </title> <booktitle> In Proceedings of 13th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 95-109, </pages> <year> 1991. </year> <note> Also in ACM Transactions on Computer Systems (February 1992). </note>
Reference-contexts: Furthermore, we show this strategy is practical on ordinary message-passing hardware. Multiple threads of control, managed in software at the user level, are a well-known technique for expressing con-currency on uniprocessors and shared-memory multiprocessors <ref> [1] </ref>. Thread systems also have been implemented on message-passing machines. However, we believe we are the first to propose the routine use of threads for scientific applications on multicomputers. <p> This effectively hides the latency of requests to the work-heap. 3 Structure of the runtime system Our runtime system manages multiple threads of control on each node of the message-passing machine; our implementation of these functions is similar to previous thread systems for uniprocessors and shared-memory multiprocessors <ref> [1] </ref>. The system provides primitives to create and start threads, and to synchronize threads on the same node using standard synchronization primitives like locks and barriers. Our runtime system also allows threads to communicate via message-passing, either between nodes or on the same node. <p> though, is that the dramatically improved performance of most operations makes it possible to use multiple threads per node to efficiently overlap the calculation of one thread with the communication of others, yielding maximum performance in the context of a simple programming model. 7 Implications for kernel structure As Anderson <ref> [1] </ref> has argued, thread operations are inherently cheaper when implemented at the user-level rather than in the kernel. Intel's NX kernel, like most multicom-puter operating systems, provides no particular support for user-level threads. <p> Kernel support for blocking message-passing operations by threads would lower the overhead of our message-passing operations substantially. Supporting user-level scheduling in the presence of unpredictable events like message arrival or page faults presents a set of problems that have been described by Anderson <ref> [1] </ref>. Anderson's solution, called scheduler activations, solves these problems and would provide a suitable mechanism for a multicomputer kernel. Scheduler activations also provide a fast and flexible mechanism for delivering messages to the application.
Reference: [2] <author> Andrew D. Birrell and Bruce Jay Nelson. </author> <title> Implementing remote procedure calls. </title> <journal> ACM Trans. Comp. Sys., </journal> <volume> 2(1) </volume> <pages> 39-59, </pages> <month> Nov. </month> <year> 1984. </year>
Reference-contexts: A NewThreads programmer would create a distinct port for each of these types of messages, and might optionally decide to use separate threads to handle the messages arriving on these ports. 6.2.2 Remote procedure call Remote procedure call (RPC) <ref> [2] </ref> has been a popular and effective method of programming on distributed systems. For many purposes, RPC has advantages over direct message passing. RPC's semantics are already familiar to sequential programmers; an RPC invocation acts like a procedure call.
Reference: [3] <author> Intel Corporation. </author> <title> Paragon XP/S product overview, </title> <year> 1991. </year>
Reference-contexts: Scheduler activations also provide a fast and flexible mechanism for delivering messages to the application. A project to integrate scheduler activations into the Mach 3.0 microkernel is currently underway in our department. Since Intel's Paragon system <ref> [3] </ref> will run an operating system based on Mach 3.0, we are optimistic that this mechanism can be made available. 8 Conclusions Overlapping calculation and communication is essential if message-passing applications are to achieve maximum performance.
Reference: [4] <author> Geoffrey C. Fox, Mark A. Johnson, Gregory A. Lyzenga, Steve W. Otto, John K. Salmon, and David W. Walker. </author> <title> Solving Problems on Concurrent Processors. </title> <publisher> Prentice Hall, </publisher> <year> 1988. </year>
Reference-contexts: Such programs alternate between phases of pure calculation and pure communication. This approach is easy for the programmer to understand, so the resulting programs are relatively simple to debug and maintain <ref> [4] </ref>. Unfortunately, the performance of these programs suffers because they are unable to overlap communication with calculation. Programmers have responded to this performance problem by restructuring their programs to allow greater communication/calculation overlap.
Reference: [5] <author> Intel Corp. </author> <title> i860 64-bit Microprocessor Programmer's Reference Manual, </title> <year> 1990. </year>
Reference-contexts: Cache effects complicate the evaluation of multithread-ing. We believe that the large cache effects observed in our experiments are due to the iPSC/2 architecture, and will not be as large on future machines. High-performance RISC processors <ref> [5, 6] </ref> tend to have small first-level caches, and the most important cache statistic is the hit rate in this first-level cache. Since these fast processors will be working on larger datasets, it seems unlikely that one processor's dataset will fit entirely in the first-level cache.
Reference: [6] <author> Gerry Kane. </author> <title> MIPS R2000 RISC Architecture. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1987. </year>
Reference-contexts: Cache effects complicate the evaluation of multithread-ing. We believe that the large cache effects observed in our experiments are due to the iPSC/2 architecture, and will not be as large on future machines. High-performance RISC processors <ref> [5, 6] </ref> tend to have small first-level caches, and the most important cache statistic is the hit rate in this first-level cache. Since these fast processors will be working on larger datasets, it seems unlikely that one processor's dataset will fit entirely in the first-level cache.
Reference: [7] <author> Monica S. Lam, Edward E. Rothberg, and Michael E. Wolf. </author> <title> The cache performance and optimizations of blocked algorithms. </title> <booktitle> In Proceedings of 4th International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 63-74, </pages> <year> 1991. </year>
Reference-contexts: Since these fast processors will be working on larger datasets, it seems unlikely that one processor's dataset will fit entirely in the first-level cache. Efficient use of small first-level caches will require support in the compiler for blocking of array operations <ref> [7] </ref>. With only a few threads per processor, the compiler should be able to block the operations of each thread, and achieve comparable hit rates for single-threaded and multithreaded programs.
Reference: [8] <author> Colin Whitby-Strevens. </author> <title> The transputer. </title> <booktitle> In Proceedings of 12th International Symposium on Computer Architecture, </booktitle> <pages> pages 292-300, </pages> <year> 1985. </year>
Reference-contexts: Thread systems also have been implemented on message-passing machines. However, we believe we are the first to propose the routine use of threads for scientific applications on multicomputers. Processors like the transputer <ref> [8] </ref> provide hardware support for fast switching between threads of control; machines based on such processors are meant to be programmed in a multithreaded style.
References-found: 8

