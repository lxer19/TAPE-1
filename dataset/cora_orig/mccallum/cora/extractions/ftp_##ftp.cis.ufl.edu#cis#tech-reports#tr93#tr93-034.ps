URL: ftp://ftp.cis.ufl.edu/cis/tech-reports/tr93/tr93-034.ps
Refering-URL: http://www.cis.ufl.edu/tech-reports/tech-reports/tr93-abstracts.html
Root-URL: http://www.cis.ufl.edu
Title: Designing Distributed Search Structures with Lazy Updates  
Author: Theodore Johnson Padmashree Krishna 
Address: Gainesville, Fl 32611-2024  
Affiliation: Dept. of Computer and Information Science University of Florida  
Abstract: Very large database systems require distributed storage for expansibility and high throughput, which means that they need distributed search structures for fast and efficient access to the data. In a highly parallel distributed search structure, parts of the index must be replicated to avoid serialization bottlenecks. Designing distributed and replicated search structures is made difficult by the complex interaction of the search structure concurrency control and the replica coherency algorithms. In this paper, we present an approach to maintaining distributed data structures that uses lazy updates, which take advantage of the semantics of the search structure operations to allow for scalable and low-overhead replication. Lazy updates can be used to design distributed search structures that support very high levels of concurrency. The alternatives to lazy update algorithms (eager updates) use synchronization to ensure consistency, while lazy update algorithms avoid blocking. Since lazy updates avoid the use of synchronization, they are much easier to implement than eager update algorithms. We develop a correctness theory for lazy update algorithms, then present lazy update algorithms to maintain a dB tree, which is a distributed B + tree that replicates its interior nodes for highly parallel access. We show how the algorithms can be applied to the construction of other distributed search structures.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Krishna P. A. and Johnson T. </author> <title> Index replication in a distributed b-tree. </title> <booktitle> In Conference on Management of Data, </booktitle> <pages> pages 207-224, </pages> <year> 1994. </year> <month> 31 </month>
Reference-contexts: In the dB-tree the leaf nodes are stored on a single processor. We apply the rule that if a processor stores a leaf node, it stores every node on the path from the root to that leaf (a previous work <ref> [1] </ref> shows that this is a good strategy). An example of a dB-tree that uses this replication policy is shown in Figure 2. The dB-tree replication policy stores the root everywhere, the leaves at a single processor, and the intermediate nodes at a moderate level of replication. <p> When a server recovers, it recovers its message state, and applies the actions it received. 7 Conclusion We present algorithms for implementing lazy updates for distributed search structures. Lazy updates avoid the need for synchronization between copies, and permit concurrent searches and concurrent updates. In other works <ref> [1, 21] </ref> we discuss implementation and performance issues, while this work concentrates on algorithms and correctness proofs. The application of lazy updates is demonstrated by their application the the dB-tree, a distributed B-tree. After presenting algorithms and proof for lazy updates, we discuss methods for designing distributed search structures.
Reference: [2] <author> F.B. Bastani, S.S. Iyengar, and I-Ling Yen. </author> <title> Concurrent maintenance of data structures in a distributed environment. </title> <journal> The Computer Journal, </journal> <volume> 21(2) </volume> <pages> 165-174, </pages> <year> 1988. </year>
Reference-contexts: A common problem with distributed search structures is that they are single-rooted. If the root node is not replicated, it becomes a bottleneck and overwhelms the processor that stores it <ref> [2] </ref>. A search structure node can be replicated by one of several well-known algorithms [3, 8]. However, these algorithms synchronize operations, which reduces concurrency, and create a significant communications overhead. <p> Second, the B-link tree provides allows an operation to recover from a misnavigation. As a result, global co-ordination is not needed to restructure the index. The dB-tree [15, 16] implements the B-link tree algorithm as a distributed protocol (as in <ref> [2, 11, 26] </ref>). 4 An operation on the index (search, insert, or delete) is performed as a sequence of actions on the nodes in the search structure, which are distributed among the processors.
Reference: [3] <author> P.A. Bernstein, V. Hadzilacos, and N. Goodman. </author> <title> Concurrency Control and Recovery in Database Systems. </title> <publisher> Addison-Wesley, </publisher> <year> 1987. </year>
Reference-contexts: A common problem with distributed search structures is that they are single-rooted. If the root node is not replicated, it becomes a bottleneck and overwhelms the processor that stores it [2]. A search structure node can be replicated by one of several well-known algorithms <ref> [3, 8] </ref>. However, these algorithms synchronize operations, which reduces concurrency, and create a significant communications overhead. While some distributed search structure algorithms have been proposed (see section 1.1.1 for references), most work in concurrent or parallel-access search structures have assumed a shared-memory implementation (see [34, 18] for a survey). <p> Wang and Weihl [39, 41] have proposed that parallel B-trees be stored using Multi-version Memory, a special cache coherence algorithm for linked data structures. Multi-version Memory permits only a single update to occur on a replicated node at any point in time (analogous to value logging <ref> [40, 3] </ref> in transaction systems). Our algorithm permits concurrent updates on replicated nodes (analogous to transition logging [40, 3]). Peleg [12, 30] has proposed several structures for implementing a distributed dictionary. The concern of these papers is the message complexity of access and data balancing. <p> Multi-version Memory permits only a single update to occur on a replicated node at any point in time (analogous to value logging <ref> [40, 3] </ref> in transaction systems). Our algorithm permits concurrent updates on replicated nodes (analogous to transition logging [40, 3]). Peleg [12, 30] has proposed several structures for implementing a distributed dictionary. The concern of these papers is the message complexity of access and data balancing. However, the issues of efficiency and 3 concurrent access are not addressed. <p> The replication strategy for a dB-tree helps to reduce the cost of maintaining a distributed search structure, but the replication strategy alone is not enough. If every node update required the execution of an available-copies algorithm <ref> [3] </ref>, the overhead of maintaining replicated copies could be prohibitive. Instead, we take advantage of the semantics of the actions on the search structure nodes and use lazy updates to 5 maintain the replicated copies inexpensively. We note that many of the actions on a dB-tree node commute. <p> Intuitively, we want the replicated nodes of the search structure to contain the same value eventually. We can ensure the coherence of the copies by serializing the actions on the nodes (perhaps via an available-copies algorithm <ref> [3] </ref>). However, we want to be lazy about the maintenance. In addition, the replica update protocol should support the design of distributed search structure algorithms. In this section, we describe a model of distributed search structure computation and establish correctness criteria for lazy updates. <p> Insert u finally fires on copy c of node n, the relayed updates insert u are sent to the other copies of n. 2.1 Histories In order to capture the conditions under which actions on a copy commute, we model the value of a copy by its history (as in <ref> [3, 13, 42] </ref>). We note that our algorithms do not require that nodes be stored as history lists, we use histories only as a modeling technique.
Reference: [4] <author> A. Borg, W. Blau, W. Graetsch, F. Herrmann, and W. Oberle. </author> <title> Fault tolerance under UNIX. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 7(1) </volume> <pages> 1-24, </pages> <year> 1989. </year>
Reference-contexts: However, because lazy updates require little synchronization, a message recovery strategy (such as that discussed in <ref> [22, 36, 14, 35, 4] </ref> can be applied. When a server recovers, it recovers its message state, and applies the actions it received. 7 Conclusion We present algorithms for implementing lazy updates for distributed search structures.
Reference: [5] <author> K.M. Chandy and L. Lamport. </author> <title> Distributed snapshots: Determining global states of distributed systems. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 3(1) </volume> <pages> 63-75, </pages> <year> 1985. </year>
Reference-contexts: The specification of an action on a copy has two components: a final value c 0 and a subsequent action set SA. An action that modifies a node is 1 By "time", we mean an ordering on the events that occur in E that is consistent with causality <ref> [5] </ref>. 7 performed on one of the copies first, then is relayed to the remaining copies. The action that performs the first modification is an initial action, and the actions that are relayed to the other copies are the relayed actions. We distinguish between the initial and the relayed actions.
Reference: [6] <author> A. Colbrook, E.A. Brewer, C.N. Dellarocas, and W.E. Weihl. </author> <title> An algorithm for concurrent search trees. </title> <booktitle> In Proceedings of the 20th International Conference on Parallel Processing, </booktitle> <pages> pages III138-III141, </pages> <year> 1991. </year>
Reference-contexts: A search operation examines one node at a time to find its key, and an insert operation searches for the node that contains its key, performs the insert, then restructures the tree from the bottom up. Some work has been done to develop a distributed B-tree. Colbrook et al. <ref> [6] </ref> developed a pipelined algorithm. Wang and Weihl [39, 41] have proposed that parallel B-trees be stored using Multi-version Memory, a special cache coherence algorithm for linked data structures.
Reference: [7] <author> D. Comer. </author> <title> The ubiquitous B-tree. </title> <journal> ACM Comp. Surveys, </journal> <volume> 11 </volume> <pages> 121-137, </pages> <year> 1979. </year>
Reference-contexts: In a B + -tree, the keys are stored in the leaves and the non-leaf nodes serve as the index. A B-link tree is a B + -tree in which every node contains a pointer to its right sibling <ref> [7] </ref>. Previous work on parallel-access search structures (see [34] for a survey) has concentrated on concurrent or shared-memory implementations. Particularly notable are the B-link tree algorithms [24, 32, 23] which we use as a base for the dB-tree. <p> When a node is deleted, some care must be taken to preserve the double linked list in which it exists. That algorithm is described in [16]. One leaf node might transfer some of its key range to an adjacent leaf, in order to perform rebalancing <ref> [7] </ref>. The parent must be informed of the shift in the key range. This action is a link-change action, and is an ordered action.
Reference: [8] <author> S.B. Davidson, H. Garcia-Molina, and D. Skeen. </author> <title> Consistency in partitioned networks. </title> <journal> Computing Surveys, </journal> <volume> 17(3) </volume> <pages> 342-370, </pages> <year> 1985. </year>
Reference-contexts: A common problem with distributed search structures is that they are single-rooted. If the root node is not replicated, it becomes a bottleneck and overwhelms the processor that stores it [2]. A search structure node can be replicated by one of several well-known algorithms <ref> [3, 8] </ref>. However, these algorithms synchronize operations, which reduces concurrency, and create a significant communications overhead. While some distributed search structure algorithms have been proposed (see section 1.1.1 for references), most work in concurrent or parallel-access search structures have assumed a shared-memory implementation (see [34, 18] for a survey).
Reference: [9] <author> M. Dietzfelbinger and F. Meyer auf der Hyde. </author> <title> An optimal parallel dictionary. </title> <booktitle> In Proc. ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pages 360-368, </pages> <year> 1989. </year>
Reference-contexts: Matsliach and Shmueli [27] propose methods for distributing search structures in a way that has a high space utilization. The authors assume that the index is stored in shared memory, however, and don't address issues of concurrent restructuring. Deitzfelbinger and Meyer auf der Hyde <ref> [9] </ref> give algorithms for implementing a hash table on a synchronous network. Ranade [31] gives algorithms and performance bounds for implementing a search tree in a synchronous butterfly or mesh network. Some related work has been done to implement hash tables.
Reference: [10] <author> C.S. Ellis. </author> <title> Extendible hashing for concurrent operations and distributed data. </title> <booktitle> In Proceedings of the 2nd ACM SIGACT-SIGMOD Symposium on Principles of Database Systems, </booktitle> <pages> pages 106-116, </pages> <address> Portland, OR, </address> <year> 1983. </year>
Reference-contexts: If a bucket with label x tag becomes empty, it can merge with the bucket labeled !x tag, if it exists. Ellis observed that the extendible hashing algorithm can be made into a highly concurrent hash table by linking together the buckets <ref> [10] </ref>. Suppose that a bucket with label tag is ready to split, and tag is not one of the longest labels in the hash table (that is, jtagj &lt; l). Then there are directory entries with suffixes 0tag and 1tag, both of which point to the bucket labeled tag.
Reference: [11] <author> C.S. Ellis. </author> <title> Distributed data structures: A case study. </title> <journal> IEEE Transactions on Computing, </journal> <volume> C-34(12):1178-1185, </volume> <year> 1985. </year>
Reference-contexts: Some related work has been done to implement hash tables. Yen and Bastani [43] have developed algorithms for implementing a hash table on a SIMD parallel computer, such as a CM2. The authors examine the use of chaining, linear probing, and double hashing to handle bucket overflows. Ellis <ref> [11] </ref> has proposed algorithms for a distributed hash table. The directories of the table are replicated among several sites, and the data buckets are distributed among several sites. Ellis' algorithm for maintaining the replicated directories is similar in many ways to our lazy update algorithms. <p> These works include [37, 28, 33]. The contribution of this work is to present a method for constructing algorithms for distributed search structures. Unlike much of the previous work, our algorithms are explicitly designed for asynchronous distributed systems (or asynchronous parallel processors). While Ellis <ref> [11] </ref> and Litwin, Neimat, and Schneider [26, 38] have also proposed distributed search structure algorithms with a similar flavor, we present a structure for understanding, designing, and proving correct more complex distributed search structure algorithms. 1.1.2 The dB-tree We use the dB-tree as a running example to demonstrate the application of <p> Second, the B-link tree provides allows an operation to recover from a misnavigation. As a result, global co-ordination is not needed to restructure the index. The dB-tree [15, 16] implements the B-link tree algorithm as a distributed protocol (as in <ref> [2, 11, 26] </ref>). 4 An operation on the index (search, insert, or delete) is performed as a sequence of actions on the nodes in the search structure, which are distributed among the processors. <p> The AAS is the distributed analogue of the shared memory lock, and can be used to implement a similar kind of synchronization (as in <ref> [11] </ref>). However, lazy updates are preferable. Example To make the concepts more clear, let us consider a simple example of a distributed B-tree and write the specifications of the possible actions. The algorithm that we specify will implement a dB-tree along the lines discussed in Section 1.1. <p> We can also apply the techniques to search-structures that support multi-attribute range queries (such as the hB-tree [25]), provided that they support the link technique. To illustrate the application of these methods to other distributed search structures, we analyze a distributed hash table due to Ellis. In <ref> [11] </ref>, Ellis describes a distributed and concurrent extendible hash table. An extendible hash table is one type of hash table that increases the number of buckets available in the table in response to increasing storage demand (such hash tables are called dynamic hash tables). <p> As a result, bucket splitting can be performed concurrently with directory accesses. Ellis further observed that the concurrent extendible hash table can be made into a distributed extendible hash table in which multiple copies of the hash directories exist <ref> [11] </ref>. The key observation is that since operations can recover from misnavigation, the directory copies can contain outdated information. In this section we analyze the distributed algorithm using lazy updates. A picture (taken from [11]) of a distributed extendible hash table is shown in Figure 9. <p> made into a distributed extendible hash table in which multiple copies of the hash directories exist <ref> [11] </ref>. The key observation is that since operations can recover from misnavigation, the directory copies can contain outdated information. In this section we analyze the distributed algorithm using lazy updates. A picture (taken from [11]) of a distributed extendible hash table is shown in Figure 9. There are two copies of the directory, three active buckets, and one deleted bucket. The buckets are double linked.
Reference: [12] <author> K.Z Gilon and D. Peleg. </author> <title> Compact deterministic distributed dictionaries. </title> <booktitle> In Proceedings of the Tenth Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 81-94. </pages> <publisher> ACM, </publisher> <year> 1991. </year>
Reference-contexts: Multi-version Memory permits only a single update to occur on a replicated node at any point in time (analogous to value logging [40, 3] in transaction systems). Our algorithm permits concurrent updates on replicated nodes (analogous to transition logging [40, 3]). Peleg <ref> [12, 30] </ref> has proposed several structures for implementing a distributed dictionary. The concern of these papers is the message complexity of access and data balancing. However, the issues of efficiency and 3 concurrent access are not addressed.
Reference: [13] <author> M. Herlihy and J. Wing. </author> <title> Linearizability: A correctness condition for concurrent objects. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 12(3) </volume> <pages> 463-492, </pages> <year> 1990. </year>
Reference-contexts: Insert u finally fires on copy c of node n, the relayed updates insert u are sent to the other copies of n. 2.1 Histories In order to capture the conditions under which actions on a copy commute, we model the value of a copy by its history (as in <ref> [3, 13, 42] </ref>). We note that our algorithms do not require that nodes be stored as history lists, we use histories only as a modeling technique.
Reference: [14] <author> D.B. Johnson and W. Zwaenepoel. </author> <title> Recovery in distributed systems using optimistic message logging and checkpointing. </title> <journal> Journal of Algorithms, </journal> <volume> 11 </volume> <pages> 462-491, </pages> <year> 1990. </year> <month> 32 </month>
Reference-contexts: However, because lazy updates require little synchronization, a message recovery strategy (such as that discussed in <ref> [22, 36, 14, 35, 4] </ref> can be applied. When a server recovers, it recovers its message state, and applies the actions it received. 7 Conclusion We present algorithms for implementing lazy updates for distributed search structures.
Reference: [15] <author> T. Johnson and A. Colbrook. </author> <title> A distributed data-balanced dictionary based on the B-link tree. </title> <booktitle> In Proc. Int'l Parallel Processing Symp., </booktitle> <pages> pages 319-325, </pages> <year> 1992. </year>
Reference-contexts: We present in this paper general-purpose techniques for designing distributed search structures using lazy updates. We first present a framework for showing the correctness of lazy update algorithms. We next discuss an increasingly general set of lazy update algorithms for implementing a distributed B-tree, the dB-tree <ref> [15, 16] </ref>. Finally, we show how some additional distributed search structures can be written. 1.1 Distributed B-trees We initiated our study of distributed search structures by designing a distributed B-tree, the dB-tree. <p> In this section we briefly describe the dB-tree <ref> [15, 16] </ref>. The B-link tree protocol has two features that make it a promising starting point for designing a distributed search structure. First, all restructuring is performed as a sequence of local actions. Second, the B-link tree provides allows an operation to recover from a misnavigation. <p> First, all restructuring is performed as a sequence of local actions. Second, the B-link tree provides allows an operation to recover from a misnavigation. As a result, global co-ordination is not needed to restructure the index. The dB-tree <ref> [15, 16] </ref> implements the B-link tree algorithm as a distributed protocol (as in [2, 11, 26]). 4 An operation on the index (search, insert, or delete) is performed as a sequence of actions on the nodes in the search structure, which are distributed among the processors.
Reference: [16] <author> T. Johnson and A. Colbrook. </author> <title> A distributed, replicated, data-balanced search structure. </title> <note> To appear in the Int'l Journal of High-Speed Computing. Available at ftp.cis.ufl.edu:cis/tech-reports/tr93/tr93-028.ps.Z, </note> <year> 1992. </year>
Reference-contexts: We present in this paper general-purpose techniques for designing distributed search structures using lazy updates. We first present a framework for showing the correctness of lazy update algorithms. We next discuss an increasingly general set of lazy update algorithms for implementing a distributed B-tree, the dB-tree <ref> [15, 16] </ref>. Finally, we show how some additional distributed search structures can be written. 1.1 Distributed B-trees We initiated our study of distributed search structures by designing a distributed B-tree, the dB-tree. <p> In this section we briefly describe the dB-tree <ref> [15, 16] </ref>. The B-link tree protocol has two features that make it a promising starting point for designing a distributed search structure. First, all restructuring is performed as a sequence of local actions. Second, the B-link tree provides allows an operation to recover from a misnavigation. <p> First, all restructuring is performed as a sequence of local actions. Second, the B-link tree provides allows an operation to recover from a misnavigation. As a result, global co-ordination is not needed to restructure the index. The dB-tree <ref> [15, 16] </ref> implements the B-link tree algorithm as a distributed protocol (as in [2, 11, 26]). 4 An operation on the index (search, insert, or delete) is performed as a sequence of actions on the nodes in the search structure, which are distributed among the processors. <p> An insert or delete operation searches for the key that can contain the key to be inserted of deleted, then performs the operation. An insert might cause the node to become too full, in which case the node is half split. A delete might also cause similar restructuring <ref> [16] </ref>. If there is only one copy of the root, then access to the index is serialized. Therefore, we want to replicate the root widely in order to improve parallelism. As we increase the degree of replication, however, the cost of maintaining coherent copies of a node increases. <p> Instead, late actions are discarded. If an ordered action is not overwriting, then the later action must block until the earlier actions are executed. For example, if nodes can be deleted (as in <ref> [16] </ref>), then the insertion and the deletion of a pointer to a child are non-overwriting ordered actions. <p> The delayed delete action is remembered at the copy, and is executed immediately after the corresponding insert action is executed. When a node is deleted, some care must be taken to preserve the double linked list in which it exists. That algorithm is described in <ref> [16] </ref>. One leaf node might transfer some of its key range to an adjacent leaf, in order to perform rebalancing [7]. The parent must be informed of the shift in the key range. This action is a link-change action, and is an ordered action.
Reference: [17] <author> T. Johnson and D. Shasha. </author> <title> A framework for the performance analysis of concurrent B-tree algorithms. </title> <booktitle> In ACM Symp. on Principles of Database Systems, </booktitle> <pages> pages 273-287, </pages> <year> 1990. </year>
Reference-contexts: Particularly notable are the B-link tree algorithms [24, 32, 23] which we use as a base for the dB-tree. These algorithms have been found to provide the highest concurrency of all concurrent B-tree algorithms <ref> [17] </ref>. In addition, operations on a B-link tree access one node at a time. A B-link tree's high performance and node independence makes it the most attractive starting point for constructing a distributed search structure.
Reference: [18] <author> T. Johnson and D. Shasha. </author> <title> The performance of concurrent data structure algorithms. </title> <journal> Transactions on Database Systems, </journal> <pages> pages 51-101, </pages> <month> March </month> <year> 1993. </year>
Reference-contexts: However, these algorithms synchronize operations, which reduces concurrency, and create a significant communications overhead. While some distributed search structure algorithms have been proposed (see section 1.1.1 for references), most work in concurrent or parallel-access search structures have assumed a shared-memory implementation (see <ref> [34, 18] </ref> for a survey). One reason for the limited number of distributed search structures is the difficulty in designing them. A methodology for designing distributed search structures is needed before they can become popularly available. fl This work was partially supported by USRA grant number 5555-19.
Reference: [19] <author> T.A. Joseph and K.P. Birman. </author> <title> Low cost management of replicated data in fault-tolerant distributed systems. </title> <journal> ACM Trans. on Computer Systems, </journal> <volume> 4(1) </volume> <pages> 54-70, </pages> <year> 1986. </year>
Reference-contexts: Part of the work was performed while Theodore Johnson was an ASEE summer faculty fellow at the NASA's National Space Science Data Center 1 Techniques exist to reduce the cost of maintaining replicated data and for increasing concurrency. Joseph and Birman <ref> [19] </ref> propose a method in which updates in a distributed database are piggybacked on synchronization messages. Ladin, Liskov, and Shira propose lazy replication for maintaining replicated servers [22], making use of the dependencies in the operations to determine if a server's data is sufficiently up-to-date. <p> Since the lazy update commutes with other updates, there is no pressing need to inform the other copies of the update immediately. Instead, the lazy update can be piggybacked onto messages used for other purposes, greatly reducing the cost of replication management (as in <ref> [19, 22] </ref>). Second, index node searches and updates commute, so that one copy of a node may be read while another copy is being updated. Further, two updates to the copies of a node may proceed at the same time.
Reference: [20] <author> P. Krishna and T. Johnson. </author> <title> Implementing distributed search structures. </title> <note> Technical Report UF CIS TR92-032, Availiable at anonymous ftp site cis.ufl.edu, </note> <institution> University of Florida, Dept. of CIS, </institution> <year> 1992. </year>
Reference-contexts: As with the fixed-copies scenario, we propose an eager and a lazy algorithm to satisfy the protocol. We have implemented the lazy protocol, and found it effectively supports data balancing <ref> [20] </ref>. The eager algorithm ensures that a forwarding address exists until the processor is guaranteed that no message will arrive for it. Unfortunately, obtaining such a guarantee is complex and requires much message passing and synchronization. We omit the details of the eager algorithm to save space.
Reference: [21] <author> P.A. Krishna and T. Johnson. </author> <title> Highly scalable data balanced distributed b-trees. </title> <type> Technical Report 95-015, </type> <institution> University of Florida, Dept. of CISE, </institution> <year> 1995. </year> <note> Available at ftp.cis.ufl.edu:cis/tech-reports. </note>
Reference-contexts: When a server recovers, it recovers its message state, and applies the actions it received. 7 Conclusion We present algorithms for implementing lazy updates for distributed search structures. Lazy updates avoid the need for synchronization between copies, and permit concurrent searches and concurrent updates. In other works <ref> [1, 21] </ref> we discuss implementation and performance issues, while this work concentrates on algorithms and correctness proofs. The application of lazy updates is demonstrated by their application the the dB-tree, a distributed B-tree. After presenting algorithms and proof for lazy updates, we discuss methods for designing distributed search structures.
Reference: [22] <author> R. Ladin, B. Liskov, L. Shira, and S. Ghemewat. </author> <title> Providing high reliability using lazy replication. </title> <journal> ACM Trans. Computer Systems, </journal> <volume> 10(4) </volume> <pages> 360-391, </pages> <year> 1992. </year>
Reference-contexts: Joseph and Birman [19] propose a method in which updates in a distributed database are piggybacked on synchronization messages. Ladin, Liskov, and Shira propose lazy replication for maintaining replicated servers <ref> [22] </ref>, making use of the dependencies in the operations to determine if a server's data is sufficiently up-to-date. Lazy update algorithms are similar to lazy replication algorithms because both use the semantics of an operation to reduce the cost of maintaining replicated copies. <p> Since the lazy update commutes with other updates, there is no pressing need to inform the other copies of the update immediately. Instead, the lazy update can be piggybacked onto messages used for other purposes, greatly reducing the cost of replication management (as in <ref> [19, 22] </ref>). Second, index node searches and updates commute, so that one copy of a node may be read while another copy is being updated. Further, two updates to the copies of a node may proceed at the same time. <p> However, because lazy updates require little synchronization, a message recovery strategy (such as that discussed in <ref> [22, 36, 14, 35, 4] </ref> can be applied. When a server recovers, it recovers its message state, and applies the actions it received. 7 Conclusion We present algorithms for implementing lazy updates for distributed search structures.
Reference: [23] <author> V. Lanin and D. Shasha. </author> <title> A symmetric concurrent B-tree algorithm. </title> <booktitle> In 1986 Fall Joint Computer Conference, </booktitle> <pages> pages 380-389, </pages> <year> 1986. </year>
Reference-contexts: A B-link tree is a B + -tree in which every node contains a pointer to its right sibling [7]. Previous work on parallel-access search structures (see [34] for a survey) has concentrated on concurrent or shared-memory implementations. Particularly notable are the B-link tree algorithms <ref> [24, 32, 23] </ref> which we use as a base for the dB-tree. These algorithms have been found to provide the highest concurrency of all concurrent B-tree algorithms [17]. In addition, operations on a B-link tree access one node at a time.
Reference: [24] <author> P.L. Lehman and S.B. Yao. </author> <title> Efficient locking for concurrent operations on B-trees. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 6(4) </volume> <pages> 650-670, </pages> <year> 1981. </year>
Reference-contexts: A B-link tree is a B + -tree in which every node contains a pointer to its right sibling [7]. Previous work on parallel-access search structures (see [34] for a survey) has concentrated on concurrent or shared-memory implementations. Particularly notable are the B-link tree algorithms <ref> [24, 32, 23] </ref> which we use as a base for the dB-tree. These algorithms have been found to provide the highest concurrency of all concurrent B-tree algorithms [17]. In addition, operations on a B-link tree access one node at a time. <p> We assume that the processing of one action can't be interrupted by the processing of another action, so an action is implicitly atomic. All operations start by accessing the root of the search structure. A search operation follows the link protocol <ref> [24, 32] </ref> until it reaches the leaf that can contain the key for which it is searching, then reports the result of the search. An insert or delete operation searches for the key that can contain the key to be inserted of deleted, then performs the operation.
Reference: [25] <author> D.B. Litwin and B. Salzberg. </author> <title> The hB-tree: A multiattribute indexing method with good guaranteed performance. </title> <journal> ACM Trans. Database Systems, </journal> <volume> 14(4) </volume> <pages> 625-658, </pages> <year> 1990. </year>
Reference-contexts: In addition, the storage overhead per processor is limited by the shallow tree depth. We can also apply the techniques to search-structures that support multi-attribute range queries (such as the hB-tree <ref> [25] </ref>), provided that they support the link technique. To illustrate the application of these methods to other distributed search structures, we analyze a distributed hash table due to Ellis. In [11], Ellis describes a distributed and concurrent extendible hash table. <p> In addition to hash tables and B-link trees, additional concurrent search structures that use the link technique have been proposed. For example, Parker [29] gives an a link-type algorithm for a concurrent trie. A multiattribute range query search structure, such as the hB-tree <ref> [25] </ref> can also be modified to serve as a distributed search structure. 6 Failures and Recovery The algorithms in this paper have not explicitly accounted for processor failures and recovery.
Reference: [26] <author> W. Litwin, M. Neimat, and D.A Schneider. </author> <title> LH* linear hashing for distributed files. </title> <booktitle> In Proc. 1993 ACM SIGMOD, </booktitle> <pages> pages 327-336, </pages> <year> 1993. </year>
Reference-contexts: The directories of the table are replicated among several sites, and the data buckets are distributed among several sites. Ellis' algorithm for maintaining the replicated directories is similar in many ways to our lazy update algorithms. Litwin, Neimat, and Schneider <ref> [26] </ref> propose a simple yet effective algorithm for a distributed linear hash table that uses a form of a replicated directory. They extended this work [38] to the order-preserving RP* hash table. <p> The contribution of this work is to present a method for constructing algorithms for distributed search structures. Unlike much of the previous work, our algorithms are explicitly designed for asynchronous distributed systems (or asynchronous parallel processors). While Ellis [11] and Litwin, Neimat, and Schneider <ref> [26, 38] </ref> have also proposed distributed search structure algorithms with a similar flavor, we present a structure for understanding, designing, and proving correct more complex distributed search structure algorithms. 1.1.2 The dB-tree We use the dB-tree as a running example to demonstrate the application of lazy updates. <p> Second, the B-link tree provides allows an operation to recover from a misnavigation. As a result, global co-ordination is not needed to restructure the index. The dB-tree [15, 16] implements the B-link tree algorithm as a distributed protocol (as in <ref> [2, 11, 26] </ref>). 4 An operation on the index (search, insert, or delete) is performed as a sequence of actions on the nodes in the search structure, which are distributed among the processors.
Reference: [27] <author> G. Matsliach and O. Shmueli. </author> <title> An efficient method for distributing search structures. </title> <booktitle> In Symposium on Parallel and Distributed Information Systems, </booktitle> <pages> pages 159-166, </pages> <year> 1991. </year> <month> 33 </month>
Reference-contexts: Peleg [12, 30] has proposed several structures for implementing a distributed dictionary. The concern of these papers is the message complexity of access and data balancing. However, the issues of efficiency and 3 concurrent access are not addressed. Matsliach and Shmueli <ref> [27] </ref> propose methods for distributing search structures in a way that has a high space utilization. The authors assume that the index is stored in shared memory, however, and don't address issues of concurrent restructuring.
Reference: [28] <author> G. Matsliach and O. Shmueli. </author> <title> An efficient method for distributing search structures. </title> <booktitle> In Proceedings of the First International Conference on Parallel and Distributed Information Systems, </booktitle> <pages> pages 159-166, </pages> <year> 1991. </year>
Reference-contexts: The algorithms in these works are similar to the algorithms discussed here, but the updates are performed reactively instead of proactively. Other work on distributed search structures have primarily addressed distributing a search structure over several disks. These works include <ref> [37, 28, 33] </ref>. The contribution of this work is to present a method for constructing algorithms for distributed search structures. Unlike much of the previous work, our algorithms are explicitly designed for asynchronous distributed systems (or asynchronous parallel processors).
Reference: [29] <author> J.D. Parker. </author> <title> A concurrent search structure. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 7, </volume> <year> 1989. </year>
Reference-contexts: Determine the ordered actions and the commutativity between actions. 4. Apply the algorithms in section 2 to manage the node copies. In addition to hash tables and B-link trees, additional concurrent search structures that use the link technique have been proposed. For example, Parker <ref> [29] </ref> gives an a link-type algorithm for a concurrent trie. A multiattribute range query search structure, such as the hB-tree [25] can also be modified to serve as a distributed search structure. 6 Failures and Recovery The algorithms in this paper have not explicitly accounted for processor failures and recovery.
Reference: [30] <author> D. Peleg. </author> <title> Distributed data structures: A complexity oriented view. </title> <booktitle> In Fourth Int'l Workshop on Distributed Algorithms, </booktitle> <pages> pages 71-89, </pages> <address> Bari, Italy, </address> <year> 1990. </year>
Reference-contexts: Multi-version Memory permits only a single update to occur on a replicated node at any point in time (analogous to value logging [40, 3] in transaction systems). Our algorithm permits concurrent updates on replicated nodes (analogous to transition logging [40, 3]). Peleg <ref> [12, 30] </ref> has proposed several structures for implementing a distributed dictionary. The concern of these papers is the message complexity of access and data balancing. However, the issues of efficiency and 3 concurrent access are not addressed.
Reference: [31] <author> A. Ranade. </author> <title> Maintaining dynamic ordered sets on processor networks. </title> <booktitle> In Proc. ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pages 127-137, </pages> <year> 1992. </year>
Reference-contexts: The authors assume that the index is stored in shared memory, however, and don't address issues of concurrent restructuring. Deitzfelbinger and Meyer auf der Hyde [9] give algorithms for implementing a hash table on a synchronous network. Ranade <ref> [31] </ref> gives algorithms and performance bounds for implementing a search tree in a synchronous butterfly or mesh network. Some related work has been done to implement hash tables. Yen and Bastani [43] have developed algorithms for implementing a hash table on a SIMD parallel computer, such as a CM2.
Reference: [32] <author> Y. Sagiv. </author> <title> Concurrent operations on B fl -trees with overtaking. </title> <booktitle> In 4th ACM Symp. Principles of Database Systems, </booktitle> <pages> pages 28-37. </pages> <publisher> ACM, </publisher> <year> 1985. </year>
Reference-contexts: A B-link tree is a B + -tree in which every node contains a pointer to its right sibling [7]. Previous work on parallel-access search structures (see [34] for a survey) has concentrated on concurrent or shared-memory implementations. Particularly notable are the B-link tree algorithms <ref> [24, 32, 23] </ref> which we use as a base for the dB-tree. These algorithms have been found to provide the highest concurrency of all concurrent B-tree algorithms [17]. In addition, operations on a B-link tree access one node at a time. <p> We assume that the processing of one action can't be interrupted by the processing of another action, so an action is implicitly atomic. All operations start by accessing the root of the search structure. A search operation follows the link protocol <ref> [24, 32] </ref> until it reaches the leaf that can contain the key for which it is searching, then reports the result of the search. An insert or delete operation searches for the key that can contain the key to be inserted of deleted, then performs the operation. <p> The first step in designing a replication algorithm is to specify the commutativity relationships between actions. 1. Any two insert actions on a copy commute. As in Sagiv's algorithm <ref> [32] </ref>, we need to take care to perform out-of-order inserts properly. 2. Half-split operations do not commute. As an example, since a half-split action modifies the right-sibling pointer, the final value of a copy depends on the order in which the half-splits are processed. 3.
Reference: [33] <author> B. Seeger and Larson P. </author> <title> Multi-disk b-trees. </title> <booktitle> In Proceedings of the 1991 ACM SIGMOD Conference, </booktitle> <pages> pages 436-445, </pages> <year> 1991. </year>
Reference-contexts: The algorithms in these works are similar to the algorithms discussed here, but the updates are performed reactively instead of proactively. Other work on distributed search structures have primarily addressed distributing a search structure over several disks. These works include <ref> [37, 28, 33] </ref>. The contribution of this work is to present a method for constructing algorithms for distributed search structures. Unlike much of the previous work, our algorithms are explicitly designed for asynchronous distributed systems (or asynchronous parallel processors).
Reference: [34] <author> D. Shasha and N. Goodman. </author> <title> Concurrent search structure algorithms. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 13(1) </volume> <pages> 53-90, </pages> <year> 1988. </year>
Reference-contexts: However, these algorithms synchronize operations, which reduces concurrency, and create a significant communications overhead. While some distributed search structure algorithms have been proposed (see section 1.1.1 for references), most work in concurrent or parallel-access search structures have assumed a shared-memory implementation (see <ref> [34, 18] </ref> for a survey). One reason for the limited number of distributed search structures is the difficulty in designing them. A methodology for designing distributed search structures is needed before they can become popularly available. fl This work was partially supported by USRA grant number 5555-19. <p> In a B + -tree, the keys are stored in the leaves and the non-leaf nodes serve as the index. A B-link tree is a B + -tree in which every node contains a pointer to its right sibling [7]. Previous work on parallel-access search structures (see <ref> [34] </ref> for a survey) has concentrated on concurrent or shared-memory implementations. Particularly notable are the B-link tree algorithms [24, 32, 23] which we use as a base for the dB-tree. These algorithms have been found to provide the highest concurrency of all concurrent B-tree algorithms [17]. <p> Further, two updates to the copies of a node may proceed at the same time. As a result, the dB-tree not only supports concurrent read actions on different copies of its nodes, it supports concurrent reads and updates, and also concurrent updates. 6 2 Correctness Shasha and Goodman <ref> [34] </ref> provide a framework for showing that (non-replicated) concurrent search search structures are correct and serializable. We would like to show that when algorithms that have been validated by the methods of [34] are translated to replicated search structures, they are still correct. <p> its nodes, it supports concurrent reads and updates, and also concurrent updates. 6 2 Correctness Shasha and Goodman <ref> [34] </ref> provide a framework for showing that (non-replicated) concurrent search search structures are correct and serializable. We would like to show that when algorithms that have been validated by the methods of [34] are translated to replicated search structures, they are still correct. Here, we concentrate on the replica coherence protocols. In this section, we present the theory for the case when replicated nodes never increase their key range. That is, replicated nodes never merge. <p> Theorem 1 The synchronous split algorithm satisfies the complete, compatible, and ordered history requirements. Proof: We observe that nodes always split to the right, so if an action misnavigates, it can always recover its path (that is, Shasha and Goodman's fourth link-algorithm guideline is satisfied <ref> [34] </ref>). Therefore, the synchronous split algorithm satisfies the complete history requirement. Since there are no ordered actions, the synchronous split algorithm vacuously satisfies the ordered history requirement.
Reference: [35] <author> A.P. Sistla and J.L. Welch. </author> <title> Efficient distributed recovery using message logging. </title> <booktitle> In Proc. Symp. on Principles of Distributed Computing, </booktitle> <pages> pages 223-238, </pages> <year> 1989. </year>
Reference-contexts: However, because lazy updates require little synchronization, a message recovery strategy (such as that discussed in <ref> [22, 36, 14, 35, 4] </ref> can be applied. When a server recovers, it recovers its message state, and applies the actions it received. 7 Conclusion We present algorithms for implementing lazy updates for distributed search structures.
Reference: [36] <author> R.E. Strom and S. Yemeni. </author> <title> Optimistic recovery in distribtued systems. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 3(3) </volume> <pages> 204-226, </pages> <year> 1985. </year>
Reference-contexts: However, because lazy updates require little synchronization, a message recovery strategy (such as that discussed in <ref> [22, 36, 14, 35, 4] </ref> can be applied. When a server recovers, it recovers its message state, and applies the actions it received. 7 Conclusion We present algorithms for implementing lazy updates for distributed search structures.
Reference: [37] <author> R. Vingraek, Y. Breitbart, and G. Weikum. </author> <title> Distributed file organization with scalable cost/performance. </title> <booktitle> In Proceedings of the 1994 ACM SIGMOD conference, </booktitle> <pages> pages 253-264, </pages> <year> 1994. </year>
Reference-contexts: The algorithms in these works are similar to the algorithms discussed here, but the updates are performed reactively instead of proactively. Other work on distributed search structures have primarily addressed distributing a search structure over several disks. These works include <ref> [37, 28, 33] </ref>. The contribution of this work is to present a method for constructing algorithms for distributed search structures. Unlike much of the previous work, our algorithms are explicitly designed for asynchronous distributed systems (or asynchronous parallel processors).
Reference: [38] <author> Litwin W., Neimat M., and Schneider D. A. </author> <title> Rp* a family of order-preserving scalable distributed data structures. </title> <booktitle> In Proceedings of the 20th VLDB Conference, </booktitle> <pages> pages 342-353, </pages> <year> 1994. </year>
Reference-contexts: Ellis' algorithm for maintaining the replicated directories is similar in many ways to our lazy update algorithms. Litwin, Neimat, and Schneider [26] propose a simple yet effective algorithm for a distributed linear hash table that uses a form of a replicated directory. They extended this work <ref> [38] </ref> to the order-preserving RP* hash table. The algorithms in these works are similar to the algorithms discussed here, but the updates are performed reactively instead of proactively. Other work on distributed search structures have primarily addressed distributing a search structure over several disks. These works include [37, 28, 33]. <p> The contribution of this work is to present a method for constructing algorithms for distributed search structures. Unlike much of the previous work, our algorithms are explicitly designed for asynchronous distributed systems (or asynchronous parallel processors). While Ellis [11] and Litwin, Neimat, and Schneider <ref> [26, 38] </ref> have also proposed distributed search structure algorithms with a similar flavor, we present a structure for understanding, designing, and proving correct more complex distributed search structure algorithms. 1.1.2 The dB-tree We use the dB-tree as a running example to demonstrate the application of lazy updates.
Reference: [39] <author> P. Wang. </author> <title> An in-depth analysis of concurrent b-tree algorithms. </title> <type> Technical Report MIT/LCS/TR-496, </type> <institution> MIT Laboratory for Computer Science, </institution> <year> 1991. </year>
Reference-contexts: Some work has been done to develop a distributed B-tree. Colbrook et al. [6] developed a pipelined algorithm. Wang and Weihl <ref> [39, 41] </ref> have proposed that parallel B-trees be stored using Multi-version Memory, a special cache coherence algorithm for linked data structures. Multi-version Memory permits only a single update to occur on a replicated node at any point in time (analogous to value logging [40, 3] in transaction systems).
Reference: [40] <author> W.E. Weihl. </author> <title> The impact or recovery on concurrency control. </title> <type> Technical Report MIT/LCS/TM-382b, </type> <institution> MIT Laboratory for Computer Science, </institution> <year> 1989. </year> <month> 34 </month>
Reference-contexts: Wang and Weihl [39, 41] have proposed that parallel B-trees be stored using Multi-version Memory, a special cache coherence algorithm for linked data structures. Multi-version Memory permits only a single update to occur on a replicated node at any point in time (analogous to value logging <ref> [40, 3] </ref> in transaction systems). Our algorithm permits concurrent updates on replicated nodes (analogous to transition logging [40, 3]). Peleg [12, 30] has proposed several structures for implementing a distributed dictionary. The concern of these papers is the message complexity of access and data balancing. <p> Multi-version Memory permits only a single update to occur on a replicated node at any point in time (analogous to value logging <ref> [40, 3] </ref> in transaction systems). Our algorithm permits concurrent updates on replicated nodes (analogous to transition logging [40, 3]). Peleg [12, 30] has proposed several structures for implementing a distributed dictionary. The concern of these papers is the message complexity of access and data balancing. However, the issues of efficiency and 3 concurrent access are not addressed.
Reference: [41] <author> W.E. Weihl and P. Wang. </author> <title> Multi-version memory: Software cache management for concurrent B-trees. </title> <booktitle> In Proc. 2nd IEEE Symp. Parallel and Distributed Processing, </booktitle> <pages> pages 650-655, </pages> <year> 1990. </year>
Reference-contexts: Some work has been done to develop a distributed B-tree. Colbrook et al. [6] developed a pipelined algorithm. Wang and Weihl <ref> [39, 41] </ref> have proposed that parallel B-trees be stored using Multi-version Memory, a special cache coherence algorithm for linked data structures. Multi-version Memory permits only a single update to occur on a replicated node at any point in time (analogous to value logging [40, 3] in transaction systems).
Reference: [42] <author> M.H. Wong and D. Agrawal. </author> <title> Context-based synchroniczation: An approach beyond semantics for concurrency control. </title> <booktitle> In Proc. 1993 ACM SIGMOD, </booktitle> <pages> pages 278-287, </pages> <year> 1993. </year>
Reference-contexts: Insert u finally fires on copy c of node n, the relayed updates insert u are sent to the other copies of n. 2.1 Histories In order to capture the conditions under which actions on a copy commute, we model the value of a copy by its history (as in <ref> [3, 13, 42] </ref>). We note that our algorithms do not require that nodes be stored as history lists, we use histories only as a modeling technique.
Reference: [43] <author> I.L. Yen and F. Bastani. </author> <title> Hash tables in massively parallel systems. </title> <booktitle> In Int'l Parallel Processing Symposium, </booktitle> <pages> pages 660-664, </pages> <year> 1992. </year> <month> 35 </month>
Reference-contexts: Ranade [31] gives algorithms and performance bounds for implementing a search tree in a synchronous butterfly or mesh network. Some related work has been done to implement hash tables. Yen and Bastani <ref> [43] </ref> have developed algorithms for implementing a hash table on a SIMD parallel computer, such as a CM2. The authors examine the use of chaining, linear probing, and double hashing to handle bucket overflows. Ellis [11] has proposed algorithms for a distributed hash table.
References-found: 43

