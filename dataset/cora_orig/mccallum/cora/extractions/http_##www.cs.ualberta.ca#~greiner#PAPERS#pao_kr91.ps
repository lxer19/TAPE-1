URL: http://www.cs.ualberta.ca/~greiner/PAPERS/pao_kr91.ps
Refering-URL: http://www.cs.ualberta.ca/~greiner/PAPERS/
Root-URL: 
Title: Probably Approximately Optimal Derivation Strategies  
Author: Russell Greiner Pekka Orponen 
Date: May 1991.  
Note: Appears in the Proceedings of the Second International Conference on Knowledge Representation and Reasoning (KR-91), Boston,  
Address: Toronto, Ontario M5S 1A4  SF-00510 Helsinki, Finland  
Affiliation: Department of Computer Science University of Toronto  Department of Computer Science University of Helsinki  
Abstract: An inference graph can have many "derivation strategies", each a particular ordering of the steps involved in reducing a given query to a sequence of database retrievals. An "optimal strategy" for a given distribution of queries is a complete strategy whose "expected cost" is minimal, where the expected cost depends on the conditional probabilities that each requested retrieval succeeds, given that a member of this class of queries is posed. This paper describes the PAO algorithm that first uses a set of training examples to approximate these probability values, and then uses these estimates to produce a "probably approximately optimal" strategy | i.e., given any *; ffi &gt; 0, PAO produces a strategy whose cost is within * of the cost of the optimal strategy, with probability greater than 1 ffi. This paper also shows how to obtain these strategies in time polynomial in 1=*, 1=ffi and the size of the inference graph, for many important classes of graphs, including all and-or trees. 
Abstract-found: 1
Intro-found: 1
Reference: [Bar84] <author> J. A. Barnett. </author> <title> How much is control knowledge worth?: A primitive example. </title> <journal> Artificial Intelligence: An International Journal, </journal> <volume> 22 </volume> <pages> 77-89, </pages> <year> 1984. </year>
Reference-contexts: We consider such strategies to be optimal. There are several known algorithms for computing an optimal strategy for various classes of KBs (or for the related, more abstract task of finding the optimal sat-isficing search strategy for various general search structures [OG90]). Most, including <ref> [Gar73, Bar84, SK75, Nat86, Gre91a] </ref>, assume that the success probabilities are given initially. <p> It takes its framework, viewing a derivation process as a graph search, from the work on effective use of control information ([SG85], [TG87], [Smi89], etc.). Those works (like the work on satisficing search strategies from which they arose <ref> [Gar73, SK75, Bar84, Nat86, Gre91a] </ref>) require that the user supply specific probability values for the probabilistic arcs, or use methods for computing these values that are based on unlikely assumptions. Our work fills this gap, by providing an effective, efficient technique for finding good estimates of these values.
Reference: [Bol85] <author> B. Bollobas. </author> <title> Random Graphs. </title> <publisher> Academic Press, </publisher> <year> 1985. </year>
Reference-contexts: To show that GN AOG (G; *; ffi ) trials of each experiment is sufficient, we need only the assertion that these experiments are independent, and the following simple form of Cher noff's bound: Lemma 3.2 (from <ref> [Bol85, p. 12] </ref>) If M independent experiments are performed to obtain an estimate ^p for a probability p, and 0, then P r [ j ^p i p i j &gt; ] 2e 2M 2 Finally, this algorithm is efficient: Lemma 3.3 (PAO 0 's Efficiency) The PAO 0 algorithm runs
Reference: [Chv79] <author> V. Chvatal. </author> <title> A greedy heuristic for the set covering problem. </title> <journal> Mathematics of Operations Research, </journal> <volume> 4 </volume> <pages> 233-35, </pages> <year> 1979. </year>
Reference-contexts: Step 3: Let fi fl be the optimal strategy for T fl , found using [Smi89]'s polynomial algorithm. This uses the Greedy algorithm shown below, (a variant of Chvatal's algorithm for finding an approximately minimal set covering <ref> [Chv79] </ref>) to find a good enough subset, K fl A. Notice K fl must "cover" the entire fB j g set | i.e., for each B j , K fl must include at least one A i such that ~ A i B j is in the original DAG. <p> Step 2: Add k to K fl , replace each R j by R j R i and return to Step 1. Let m be the largest value of jR (A i )j, over all A i nodes. From <ref> [Chv79] </ref>, we see that this algorithm returns a tree 17 Notice we are not claiming that T [fi opt ] = T opt . whose tree cost is within a factor of H (m) = i=1 j of the cost of the optimal subtree. 18 We prove below that this means
Reference: [DeJ88] <author> Gerald DeJong. </author> <booktitle> AAAI workshop on Explanation-Based Learning. Sponsored by AAAI, </booktitle> <year> 1988. </year> <title> 18 We can actually get a tighter bound: C T (T fl ) C bs H(m)[C T (T opt ) C bs ], where C bs = L(c b + c s ) is the cost of the tree from the set of A i s down to the leaf S j s. </title>
Reference-contexts: In addition, most of their techniques insist on finding the "optimal" solution; this becomes problematic when that task is intractable. Our work implements the obvious way of sidestepping this limitation, by allowing near-optimal solutions. Our approach also resembles the work on EBL ("explanation-based learning") <ref> [DeJ88] </ref>, as it uses previous solutions to suggest an improved derivation system. Most EBL systems use only a single example to suggest a new strategy; we extend those works by showing how to use a set of samples and by describing, further, the exact number of samples required.
Reference: [DM86] <author> Gerald DeJong and Raymond Mooney. </author> <title> Explanation-based learning: An alternative view. </title> <journal> Machine Learning, </journal> <volume> 1(2) </volume> <pages> 145-76, </pages> <year> 1986. </year>
Reference-contexts: This basic observation is the key insight underlying "explanation-based learning" systems <ref> [MKKC86, DM86, MCK + 89] </ref>. Each of these systems analyzes the solutions found to certain previous problems, and many use this information to suggest new strategies. Most of these systems, however, use only a single training example. Empirical studies have confirmed that the resulting strategies are not always good [Min88].
Reference: [Gar73] <author> M. R. Garey. </author> <title> Optimal task sequencing with precedence constraints. </title> <journal> Discrete Mathematics, </journal> <volume> 4, </volume> <year> 1973. </year>
Reference-contexts: We consider such strategies to be optimal. There are several known algorithms for computing an optimal strategy for various classes of KBs (or for the related, more abstract task of finding the optimal sat-isficing search strategy for various general search structures [OG90]). Most, including <ref> [Gar73, Bar84, SK75, Nat86, Gre91a] </ref>, assume that the success probabilities are given initially. <p> It takes its framework, viewing a derivation process as a graph search, from the work on effective use of control information ([SG85], [TG87], [Smi89], etc.). Those works (like the work on satisficing search strategies from which they arose <ref> [Gar73, SK75, Bar84, Nat86, Gre91a] </ref>) require that the user supply specific probability values for the probabilistic arcs, or use methods for computing these values that are based on unlikely assumptions. Our work fills this gap, by providing an effective, efficient technique for finding good estimates of these values.
Reference: [GN87] <author> Michael R. Genesereth and Nils J. Nils-son. </author> <booktitle> Logical Foundations of Artificial Intelligence. </booktitle> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <address> Los Altos, CA, </address> <year> 1987. </year>
Reference-contexts: There can be an exponential number of potential "solution paths" for a given query/goal | as there can be many rules/operations that each reduce the goal to a new set of subgoals, and each of these subgoals can, itself, have many possible reductions, etc. <ref> [GN87] </ref>. It is obviously advantageous to explore these different paths in a good order, one that will lead to a solution fl This research was performed while this author was visiting the Department of Computer Science at the University of Toronto. quickly.
Reference: [GO91] <author> Russell Greiner and Pekka Orponen. </author> <title> Probably approximately optimal satisfic-ing strategies. </title> <type> Technical report, </type> <institution> University of Toronto, </institution> <year> 1991. </year>
Reference-contexts: PAO 0 then returns this value, fi ^ P = AOT (G; ^ P ). 3.3 Proof Sketches The critical claim underlying the PAO 0 algorithm is the formula in Equation 1, which is proven in <ref> [GO91, Theorem 1] </ref>. The basic ideas follow. Let G be an inference graph with n probabilistic arcs; and P = hp 1 ; : : : ; p n i be the real probability vector | i.e., p i is the (real) success probability of the i th probabilistic arc. <p> We can therefore use it for the class of DAGs discussed in Appendix B. 12 This is proven in <ref> [GO91, Lemma 3] </ref>. 13 In general, each Get-Number i (resp., Find-Probs i , Find-OptDS i ) is a variant of the Get-Number 0 (resp., Find-Probs 0 , Find-OptDS 0 ) algorithm discussed above. Each PAO i algorithm is composed on Get-Number i , Find-Probs i and Find-OptDS i . <p> Hence, the user could use this DP (3) system to answer his queries, efficiently, during PAO's "training mode". This process is discussed in detail in <ref> [GO91] </ref>.) 4.2 Other Classes of KBs While many standard derivation systems do correspond to and-or hyper-trees, there are exceptions. We can use the Get-Number 1 algorithm (defined above) to deal with such systems, provided the collection of fGN G g formulae includes these other classes of graphs. <p> Etc etc etc. (See <ref> [GO91] </ref> for further details of this process.) We can compute the expected cost of a strategy, given the c cost function and the success probability of each probabilistic arc. We define it recursively, in terms of the cost of the strategy subtree whose root is some node, m.
Reference: [Gol79] <author> A. Goldberg. </author> <title> An average case complexity analysis of the satisfiability problem. </title> <booktitle> In Proceedings of the 4th Workshop on Automated Deduction, </booktitle> <pages> pages 1-6, </pages> <address> Austin, TX, </address> <year> 1979. </year>
Reference-contexts: of queries that our DP will encounter, and that these queries are selected at random, according to some arbitrary but stationary distribution. (Notice this distribution will depend on the particular task our DP is addressing; n.b., we do not assume that it is a uniform distribution over all possible problems <ref> [Gol79] </ref>, nor that it will necessarily correspond to any particular collection of "benchmark challenge problems" [Kel87].
Reference: [Gre91a] <author> Russell Greiner. </author> <title> Finding an optimal satis-ficing strategy in an and-or tree. </title> <type> Technical report, </type> <institution> University of Toronto, </institution> <month> forthcoming </month> <year> 1991. </year>
Reference-contexts: to pursue this path (i.e., that none of the prior paths succeeded). 3 We can now state our objective: to find a graph traversal strategy that is complete (i.e., is guaranteed to find an solution if there is one) and has the minimal expected cost of all such complete strategies <ref> [Gre91a] </ref>. We consider such strategies to be optimal. There are several known algorithms for computing an optimal strategy for various classes of KBs (or for the related, more abstract task of finding the optimal sat-isficing search strategy for various general search structures [OG90]). <p> We consider such strategies to be optimal. There are several known algorithms for computing an optimal strategy for various classes of KBs (or for the related, more abstract task of finding the optimal sat-isficing search strategy for various general search structures [OG90]). Most, including <ref> [Gar73, Bar84, SK75, Nat86, Gre91a] </ref>, assume that the success probabilities are given initially. <p> That is, imagine the user asks a total of K BuyCar () queries over the lifetime of the sys 3 It is actually more complicated, as we need only consider the cost of the additional steps, to go from some already-visited nodes down to the retrievals. See <ref> [Gre91a] </ref>. <p> Find-OptDS 0 is simply the AOT (G; Q) algorithm (defined in <ref> [Gre91a] </ref>) that takes G, a general hyper-tree, and Q, a vector of (approximations to) the success probabilities of the retrievals, and returns the strategy that would be optimal, if these Q values were accurate; i.e., fi Q = AOT (G; Q) satisfies 8fi 2 S (G) E Q [fi] E Q <p> C; Find-Probs 0 requires only O ( 1 * ffi jGj 3 ) (i.e., O (jGj) to traverse the inference graph to perform the n retrievals for each of its M = O ( 1 * ffi jGj 2 ) tri als); and Find-OptDS 0 is O (jGj 2 ) <ref> [Gre91a] </ref>.) 4 Extensions to the PAO Algorithm For pedagogical reasons, the previous section presented a very simple algorithm, one that is both rela tively restricted (able to handle only inference hyper-trees 10 ) and relatively inefficient. This subsection 10 Technically, we should state "KBs whose inference graphs are hyper-trees". <p> It takes its framework, viewing a derivation process as a graph search, from the work on effective use of control information ([SG85], [TG87], [Smi89], etc.). Those works (like the work on satisficing search strategies from which they arose <ref> [Gar73, SK75, Bar84, Nat86, Gre91a] </ref>) require that the user supply specific probability values for the probabilistic arcs, or use methods for computing these values that are based on unlikely assumptions. Our work fills this gap, by providing an effective, efficient technique for finding good estimates of these values.
Reference: [Gre91b] <author> Russell Greiner. </author> <title> Finding the optimal derivation strategy in a redundant knowledge base. </title> <journal> Artificial Intelligence: </journal> <note> An International Journal, forthcoming 1991. </note>
Reference-contexts: This "best ordering" depends on the probabilities that each path will succeed; unfortunately, this information is usually unavailable. In addition, the task of finding the optimal strategy, even given these probabilities, can be very difficult; c.f., <ref> [Gre91b] </ref>. This report presents an efficient technique for finding good approximations to these probabilities, and then using them to produce near-optimal derivation systems. <p> The problem with most graphs that are more general than and-or trees is in computing the optimal strategy: It is NP-hard to compute the optimal strategy from a context whose structure is a DAG (rather than a tree) and probability vector <ref> [Sah74, Gre91b] </ref>. Hence, the Find-OptDS subroutine cannot simply find the optimal strategy for the graph and the frequency vector (as Find-OptDS 0 does, using AOT for and-or trees). Fortunately, there are efficient "approximation algorithms" for certain classes of such contexts. <p> + , plus 1 p q times the cost of the sub-strategy headed by m . (Notice: we need to use this same type of "strategy tree" structure even when considering simple (i.e., non-hyper) inference trees, when intermediate arcs are probabilistic.) B Efficient Algorithm for finding an Approximately Optimal Strategy <ref> [Gre91b] </ref> proves that the task of finding a minimal cost strategy for an arbitrary graph is NP-hard. This reduction proof uses the particular class of DAGs suggested by Figure 4. This appendix provides an efficient algorithm that produces an approximately optimal strategy for this class of structures. <p> We can, therefore, deal only with the case where 0 &lt; p j &lt; 1 holds for j. <ref> [Gre91b] </ref> proves, in general, that the optimal strategy for any DAG is an ordering of the arcs in some embedded tree.
Reference: [Kel87] <author> Richard M. Keller. </author> <title> Defining operationality for explanation-based learning. </title> <booktitle> In AAAI-87, </booktitle> <pages> pages 482-87, </pages> <address> Seattle, </address> <month> July </month> <year> 1987. </year>
Reference-contexts: according to some arbitrary but stationary distribution. (Notice this distribution will depend on the particular task our DP is addressing; n.b., we do not assume that it is a uniform distribution over all possible problems [Gol79], nor that it will necessarily correspond to any particular collection of "benchmark challenge problems" <ref> [Kel87] </ref>. Hence, we are using the same weak "distribution-free assumption" that underlies the current work in PAC-learning [Val84].) We can translate this query distribution into a set of probability values that specify the chance that each retrieval will succeed.
Reference: [MCK + 89] <author> Steven Minton, Jaime Carbonell, C.A. Knoblock, D.R. Kuokka, Oren Etzioni, and Y. Gil. </author> <title> Explanation-based learning: A problem solving perspective. </title> <journal> Artificial Intelligence: </journal> <note> An International Journal, 40(1-3):63-119, </note> <month> September </month> <year> 1989. </year>
Reference-contexts: This basic observation is the key insight underlying "explanation-based learning" systems <ref> [MKKC86, DM86, MCK + 89] </ref>. Each of these systems analyzes the solutions found to certain previous problems, and many use this information to suggest new strategies. Most of these systems, however, use only a single training example. Empirical studies have confirmed that the resulting strategies are not always good [Min88].
Reference: [Min88] <author> Steven Minton. </author> <title> Quantitative results concerning the utility of explanation-based learning. </title> <booktitle> In AAAI-88, </booktitle> <pages> pages 564-69, </pages> <address> San Mateo, CA, August 1988. </address> <publisher> Morgan Kauf-mann Publishers, Inc. </publisher>
Reference-contexts: Each of these systems analyzes the solutions found to certain previous problems, and many use this information to suggest new strategies. Most of these systems, however, use only a single training example. Empirical studies have confirmed that the resulting strategies are not always good <ref> [Min88] </ref>. By contrast, this research uses a set of examples, and can guarantee that the resulting strategy will usually be arbitrarily close to optimal.
Reference: [MKKC86] <author> Thomas M. Mitchell, Richard M. Keller, and Smadar T. Kedar-Cabelli. </author> <title> Example-based generalization: A unifying view. </title> <journal> Machine Learning, </journal> <volume> 1(1) </volume> <pages> 47-80, </pages> <year> 1986. </year>
Reference-contexts: This basic observation is the key insight underlying "explanation-based learning" systems <ref> [MKKC86, DM86, MCK + 89] </ref>. Each of these systems analyzes the solutions found to certain previous problems, and many use this information to suggest new strategies. Most of these systems, however, use only a single training example. Empirical studies have confirmed that the resulting strategies are not always good [Min88].
Reference: [Nat86] <author> K. S. Natarajan. </author> <title> Optimizing depth-first search of AND-OR trees. </title> <type> Technical report, </type> <institution> Research report RC-11842, IBM T. J. Watson Research Center, </institution> <month> January </month> <year> 1986. </year>
Reference-contexts: We consider such strategies to be optimal. There are several known algorithms for computing an optimal strategy for various classes of KBs (or for the related, more abstract task of finding the optimal sat-isficing search strategy for various general search structures [OG90]). Most, including <ref> [Gar73, Bar84, SK75, Nat86, Gre91a] </ref>, assume that the success probabilities are given initially. <p> It takes its framework, viewing a derivation process as a graph search, from the work on effective use of control information ([SG85], [TG87], [Smi89], etc.). Those works (like the work on satisficing search strategies from which they arose <ref> [Gar73, SK75, Bar84, Nat86, Gre91a] </ref>) require that the user supply specific probability values for the probabilistic arcs, or use methods for computing these values that are based on unlikely assumptions. Our work fills this gap, by providing an effective, efficient technique for finding good estimates of these values.
Reference: [OG90] <author> Pekka Orponen and Russell Greiner. </author> <title> On the sample complexity of finding good search strategies. </title> <booktitle> In Proceedings of COLT-90, </booktitle> <pages> pages 352-58, </pages> <address> Rochester, </address> <month> August </month> <year> 1990. </year>
Reference-contexts: We consider such strategies to be optimal. There are several known algorithms for computing an optimal strategy for various classes of KBs (or for the related, more abstract task of finding the optimal sat-isficing search strategy for various general search structures <ref> [OG90] </ref>). Most, including [Gar73, Bar84, SK75, Nat86, Gre91a], assume that the success probabilities are given initially.
Reference: [Sah74] <author> S. Sahni. </author> <title> Computationally related prob-lems. </title> <journal> SIAM Journal on Computing, </journal> <volume> 3(4) </volume> <pages> 262-279, </pages> <year> 1974. </year>
Reference-contexts: The problem with most graphs that are more general than and-or trees is in computing the optimal strategy: It is NP-hard to compute the optimal strategy from a context whose structure is a DAG (rather than a tree) and probability vector <ref> [Sah74, Gre91b] </ref>. Hence, the Find-OptDS subroutine cannot simply find the optimal strategy for the graph and the frequency vector (as Find-OptDS 0 does, using AOT for and-or trees). Fortunately, there are efficient "approximation algorithms" for certain classes of such contexts.
Reference: [SG85] <author> David E. Smith and Michael R. Gene-sereth. </author> <title> Ordering conjunctive queries. </title> <journal> Artificial Intelligence: An International Journal, </journal> <volume> 26(2) </volume> <pages> 171-215, </pages> <month> May </month> <year> 1985. </year>
Reference: [SK75] <author> H. A. Simon and J. B. Kadane. </author> <title> Optimal problem-solving search: All-or-none solutions. </title> <journal> Artificial Intelligence: An International Journal, </journal> <volume> 6 </volume> <pages> 235-247, </pages> <year> 1975. </year>
Reference-contexts: We consider such strategies to be optimal. There are several known algorithms for computing an optimal strategy for various classes of KBs (or for the related, more abstract task of finding the optimal sat-isficing search strategy for various general search structures [OG90]). Most, including <ref> [Gar73, Bar84, SK75, Nat86, Gre91a] </ref>, assume that the success probabilities are given initially. <p> 1 = hR bc D c R bp D p i strategy, will stop if the D c retrieval is successful, ignoring the remaining hR bp D p i.) Notice this means that our DPs are seeking only a single solution; this type of search is called a "satisficing search" <ref> [SK75] </ref>. 8 Strategies are considerably more complicated when dealing with non-disjunctive KBs; see Appendix A. * Each query (i.e., each member of Q) corresponds to an instantiation of the root node of G. Hence, each DP fi is given a query, q, as its input. <p> It takes its framework, viewing a derivation process as a graph search, from the work on effective use of control information ([SG85], [TG87], [Smi89], etc.). Those works (like the work on satisficing search strategies from which they arose <ref> [Gar73, SK75, Bar84, Nat86, Gre91a] </ref>) require that the user supply specific probability values for the probabilistic arcs, or use methods for computing these values that are based on unlikely assumptions. Our work fills this gap, by providing an effective, efficient technique for finding good estimates of these values.
Reference: [Smi89] <author> David E. Smith. </author> <title> Controlling backward inference. </title> <journal> Artificial Intelligence: An International Journal, </journal> <volume> 39(2) </volume> <pages> 145-208, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: Most, including [Gar73, Bar84, SK75, Nat86, Gre91a], assume that the success probabilities are given initially. Unfortunately, these probabilities are, in general, not known initially (e.g., we usually do not know that 60% of the queries will be BuyCar (C1), etc.). <ref> [Smi89] </ref> presents one way of approximating their values, based on the (questionable) assumption that these probabilities are correlated with the distribution of facts in the database. <p> It takes its framework, viewing a derivation process as a graph search, from the work on effective use of control information ([SG85], [TG87], <ref> [Smi89] </ref>, etc.). Those works (like the work on satisficing search strategies from which they arose [Gar73, SK75, Bar84, Nat86, Gre91a]) require that the user supply specific probability values for the probabilistic arcs, or use methods for computing these values that are based on unlikely assumptions.
Reference: [TG87] <author> Richard J. Treitel and Michael R. Gene-sereth. </author> <title> Choosing orders for rules. </title> <journal> Journal of Automated Reasoning, </journal> <volume> 3(4) </volume> <pages> 395-432, </pages> <month> December </month> <year> 1987. </year>
Reference-contexts: It takes its framework, viewing a derivation process as a graph search, from the work on effective use of control information ([SG85], <ref> [TG87] </ref>, [Smi89], etc.). Those works (like the work on satisficing search strategies from which they arose [Gar73, SK75, Bar84, Nat86, Gre91a]) require that the user supply specific probability values for the probabilistic arcs, or use methods for computing these values that are based on unlikely assumptions.
Reference: [Val84] <author> Leslie G. Valiant. </author> <title> A theory of the learnable. </title> <journal> Communications of the ACM, </journal> <volume> 27(11) </volume> <pages> 1134-42, </pages> <year> 1984. </year>
Reference-contexts: Hence, we are using the same weak "distribution-free assumption" that underlies the current work in PAC-learning <ref> [Val84] </ref>.) We can translate this query distribution into a set of probability values that specify the chance that each retrieval will succeed. <p> While most EBL systems are purely heuristic in nature, we use techniques from mathematical statistics to guarantee that our new strategies will (usually) be close to optimal. Finally, this work borrows those statistical methods (as well as its title) from the field of "probably approximately correct learning" <ref> [Val84] </ref>. We provide a concrete application of these theoretical techniques. To recapitulate: this work describes a technique for improving the efficiency of a derivation system.
References-found: 23

