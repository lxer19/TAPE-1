URL: http://www.ai.mit.edu/projects/transit/papers/dpga+proc-fccm94.ps.Z
Refering-URL: http://www.ai.mit.edu/projects/transit/reconfigurable_computing.html
Root-URL: 
Title: FCCM '94 --IEEE Workshop on FPGAs for Custom Computing Machines April 10-13, Napa, CA DPGA-Coupled
Author: Andr e DeHon 
Address: Cambridge, MA, 02139  
Affiliation: Artificial Intelligence Laboratory Massachusetts Institute of Technology  
Abstract: During the past decade the microprocessor has become a key commodity component for building all kinds of computational systems. During this time frame large, reconfigurable logic arrays have exploited the same advances in IC fabrication technology to emerge as viable system building blocks. Looking at both the technology prospects and application requirements, there is compelling evidence that microprocessors with integrated reconfigurable logic arrays will be a primary building block for future computing systems. In this paper, we look at the role such components can play in building high-performance and economical systems, as well as the ripe technological outlook. We note how the tight integration of reconfigurable logic into the processor can overcome some of the major limitations of contemporary, attached reconfigurable compute engines. We specifically consider the use of integrated Dynamically Programmable Gate Array structures for the configurable logic and examine the advantages rapid reconfiguration provides in this application. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Anant Agarwal, Beng-Hong Lim, David Kranz, and John Kubiatowicz. </author> <month> APRIL: </month> <title> A Processor Architecture for Multiprocessing. </title> <booktitle> In Proceedings of the 17th International Symposium on Computer Architecture, </booktitle> <pages> pages 104-114. </pages> <publisher> IEEE, </publisher> <month> May </month> <year> 1990. </year>
Reference-contexts: This allows computational functions to be placed where intermediate data resides in the reconfigurable array, taking further advantage of application-specific locality and data flow. Finally, DPGAs are naturally suited to conventional multitasking or fine-grained multithreading (e.g. April <ref> [1] </ref>, *T [19]). In these applications, each thread or context may require a different array personality. By partitioning the DPGA contexts and assigning a different context, or sets of contexts, to each thread or task, array reconfiguration will not complicate sharing the processor between tasks or threads.
Reference: [2] <institution> Algotronix Ltd., Edinburgh, </institution> <address> UK. </address> <booktitle> The Configurable Logic Data Book, </booktitle> <year> 1990. </year>
Reference-contexts: The DEC team has demonstrated significant performance improvements on many applications by appropriate specialization of the PAM accelerator. * Algotronix's CH2x4 provides a 2fi4 array of CAL 1024 FPGAs along with memory in an ISA, PC-compatible card form factor <ref> [2] </ref>. Numerous other reconfigurable computing engines have been and continue to be built due to their favorable cost/performance ratios. 4.2 Application Sampling Reconfigurable computing engines such as these have been effectively employed in a wide-rage of applications, including: 1.
Reference: [3] <author> Thomas Anderson, Henry Levy, Brian Bershad, and Edward Lazowska. </author> <title> The Interaction of Architectures and Operating System Design. </title> <booktitle> In Fourth International Conference on Architectural Support for Programming Languages, </booktitle> <pages> pages 108-120. </pages> <publisher> ACM, </publisher> <month> April </month> <year> 1991. </year>
Reference-contexts: Careful relocation of this interaction logic into the reconfigurable logic allows later binding and post-fabrication modification of interaction behavior. * The fault, interrupt, and system call behavior of many, modern microprocessors is often quite mismatched with the needs of the operating system <ref> [3] </ref>.
Reference: [4] <author> P. Bertin, D. Roncin, and J. Vuillemin. </author> <title> Programmable Active Memories: A Performance Assessment. </title> <type> Prl report, </type> <institution> DEC Paris Reserch Laboratory, </institution> <address> 85, Av. Victor Hugo, 92563 Rueil-Malmaison Cedex, France, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: Arithmetic When the arithmetic operations required by a computation do not exactly match those provided by the ALU/FPU in conventional microprocessors or when the arithmetic operations admit to substantial bit-level parallelism, there is ample room to specialize reconfigurable logic to provide higher performance [11] [20] <ref> [4] </ref> [9]. 3. Encryption/Decryption/Compression Encryption/decryption and compression applications require application of simple sequences of arithmetic and logic operations to large datasets. The operations required are often not native to typical microprocessors. <p> The operations required are often not native to typical microprocessors. Specialized computing engines can provide the appropriate operators and make use of the parallelism and regularity in the application to extract high per formance [20] <ref> [4] </ref>. 4. Sequence and string matching By recognizing the application's natural structure and specializing a configurable compute engine to take advantage of the structure, researchers have managed to achieve very high performance at modest costs [14] [12] [16]. 5. Sorting Sorting tasks exhibit natural, fine-grained parallelism. <p> Physical system simulation Simulating physical phenomena often require repeated evaluation of state-variables using very regular computations, often of limited precision. Compute engines specialized to evaluating particular systems of equations can achieve significant advantage over general-purpose processors <ref> [4] </ref>. 7. Video and image processing The fine-grained, bit-level parallelism available in most image processing applications make it highly amenable to acceleration using fine-grained processing arrays (e.g. [4] [11]). <p> Compute engines specialized to evaluating particular systems of equations can achieve significant advantage over general-purpose processors <ref> [4] </ref>. 7. Video and image processing The fine-grained, bit-level parallelism available in most image processing applications make it highly amenable to acceleration using fine-grained processing arrays (e.g. [4] [11]). A common theme in these applications is that application-specific specialization of a reconfigurable computing system provides orders of magnitude higher performance than FCCM '94 --IEEE Workshop on FPGAs for Custom Computing Machines April 10-13, Napa, CA general-purpose microprocessors or workstations.
Reference: [5] <author> Patrice Bertin, Didier Roncin, and Jean Vuillemin. </author> <title> Introduction to Programmable Active Memories. </title> <type> PRL Report 3, </type> <institution> DEC Paris Reserch Laboratory, </institution> <address> 85, Av. Victor Hugo, 92563 Rueil-Malmaison Cedex, France, </address> <month> June </month> <year> 1989. </year>
Reference-contexts: SPLASH has seen heavy use in genome sequence matching applications [16]. * DEC Paris's PAM (Programmable Active Memories) is an array of Xilinx FPGAs attached to a host workstation <ref> [5] </ref>. The DEC team has demonstrated significant performance improvements on many applications by appropriate specialization of the PAM accelerator. * Algotronix's CH2x4 provides a 2fi4 array of CAL 1024 FPGAs along with memory in an ISA, PC-compatible card form factor [2].
Reference: [6] <author> Michael Bolotski, Andr e DeHon, and Thomas F. Knight Jr. </author> <title> Unifying FPGAs and SIMD Arrays. </title> <type> Transit Note 95, </type> <institution> MIT Artificial Intelligence Laboratory, </institution> <month> September </month> <year> 1993. </year>
Reference-contexts: By reducing the communication overhead between the base microprocessor and the reconfigurable logic, we can greatly increase the kinds of application-specific specialization which provide significant acceleration. 5 Dynamically Programmed Gate Arrays The Dynamically Programmable Gate Array (DPGA) architecture <ref> [6] </ref> is particularly well-suited for reconfigurable computing. Unlike normal Field-Programmable Gate Arrays (FPGAs) where the function of each array element is fixed between relatively slow reconfiguration sequences, the DPGA array elements may switch rapidly among several, pre-programmed configurations.
Reference: [7] <author> D. A. Buell. </author> <title> A Splash 2 Tutorial. </title> <type> Technical Report SRC-TR-92-087, </type> <institution> Supercomputing Research Center, Bowie, Maryland, </institution> <month> December </month> <year> 1992. </year>
Reference-contexts: The reconfigurable logic can be configured to perform common operations which are ill-suited to the fine-grained SIMD processing elements in the CM-2. * The Supercomputing Research Center has built a series of programmable systolic arrays known as SPLASH [18] <ref> [7] </ref>. Each SPLASH array attaches to a host workstations and is composed from a number of Xilinx FPGAs in an array fashion along with support memory.
Reference: [8] <author> Robert P. Colwell. </author> <title> Latent Design Faults in the Development of Multiflow's TRACE/200. </title> <booktitle> In Proceedings FCCM '94 --IEEE Workshop on FPGAs for Custom Computing Machines April 10-13, Napa, CA of The Twenty-Second International Symposium on Fault Tolerant Computing Systems, </booktitle> <pages> pages 468-474. </pages> <publisher> IEEE Computer Society, </publisher> <month> July </month> <year> 1992. </year>
Reference-contexts: This migration can provide considerable flexibility and a number of practical advantages, including: * Feature interaction, particularly with exception and error conditions, have a history of being one of the hardest parts of a processor design to get correct (e.g. <ref> [8] </ref> [15]). Careful relocation of this interaction logic into the reconfigurable logic allows later binding and post-fabrication modification of interaction behavior. * The fault, interrupt, and system call behavior of many, modern microprocessors is often quite mismatched with the needs of the operating system [3].
Reference: [9] <author> Steven A. Cuccaro and Craig F. Reese. </author> <title> The CM-2X: A Hybrid CM-2/Xilinx Prototype. </title> <editor> In Duncan A. Buell and Kenneth L. Pocek, editors, </editor> <booktitle> Proceedings of the IEEE Workshop on FPGAs for Custom Computing Machines, </booktitle> <pages> pages 121-130, </pages> <address> Los Alamitos, California, April 1993. </address> <publisher> IEEE Computer Society, IEEE Computer Society Press. </publisher>
Reference-contexts: PRISM-I and PRISM-II prototypes have been built which couple common microprocessors with Xilinx FPGAs [23]. * Cuccaro and Reese at the Supercomputing Research Center augmented a CM-2 with reconfigurable logic units by using Xilinx FPGAs in place of the CM-2 floating point processors <ref> [9] </ref>. The reconfigurable logic can be configured to perform common operations which are ill-suited to the fine-grained SIMD processing elements in the CM-2. * The Supercomputing Research Center has built a series of programmable systolic arrays known as SPLASH [18] [7]. <p> Arithmetic When the arithmetic operations required by a computation do not exactly match those provided by the ALU/FPU in conventional microprocessors or when the arithmetic operations admit to substantial bit-level parallelism, there is ample room to specialize reconfigurable logic to provide higher performance [11] [20] [4] <ref> [9] </ref>. 3. Encryption/Decryption/Compression Encryption/decryption and compression applications require application of simple sequences of arithmetic and logic operations to large datasets. The operations required are often not native to typical microprocessors.
Reference: [10] <author> William J. Dally et al. </author> <title> The Message-Driven Processor: A Multicomputer Processing Node with Efficient Mechanisms. </title> <booktitle> IEEE Micro, </booktitle> <pages> pages 23-39, </pages> <month> April </month> <year> 1992. </year>
Reference-contexts: Part of the reconfigurable logic can be em ployed as system-specific glue logic. * Multiprocessor Systems - DPGA-coupled processors can be employed in a variety of ways to produce high-performance multiprocessors. Part of the DPGA logic array could be used to build a tightly-integrated network interface (e.g. <ref> [10] </ref> [19]) to adapt the microprocessor for multiprocessing. Part of the DPGA logic could be used to construct application-specific synchronization primitives or communication networks. Each node may employ the DPGA logic for task acceleration in the same manner as single processor special- and general-purpose computers.
Reference: [11] <author> Frederick Furtek. </author> <title> Arithmetic Benchmarks for the CLi6000. </title> <editor> In Duncan A. Buell and Kenneth L. Pocek, editors, </editor> <booktitle> Proceedings of the IEEE Workshop on FP-GAs for Custom Computing Machines, </booktitle> <address> Los Alami-tos, California, </address> <month> April </month> <year> 1993. </year> <journal> IEEE Computer Society, IEEE Computer Society Press. </journal> <note> Paper does not appear in printed proceedings; contact author fred@clogic.com. </note>
Reference-contexts: Arithmetic When the arithmetic operations required by a computation do not exactly match those provided by the ALU/FPU in conventional microprocessors or when the arithmetic operations admit to substantial bit-level parallelism, there is ample room to specialize reconfigurable logic to provide higher performance <ref> [11] </ref> [20] [4] [9]. 3. Encryption/Decryption/Compression Encryption/decryption and compression applications require application of simple sequences of arithmetic and logic operations to large datasets. The operations required are often not native to typical microprocessors. <p> Compute engines specialized to evaluating particular systems of equations can achieve significant advantage over general-purpose processors [4]. 7. Video and image processing The fine-grained, bit-level parallelism available in most image processing applications make it highly amenable to acceleration using fine-grained processing arrays (e.g. [4] <ref> [11] </ref>). A common theme in these applications is that application-specific specialization of a reconfigurable computing system provides orders of magnitude higher performance than FCCM '94 --IEEE Workshop on FPGAs for Custom Computing Machines April 10-13, Napa, CA general-purpose microprocessors or workstations.
Reference: [12] <author> Maya Gokhale, William Holmes, Andrew Kopser, Sara Lucas, Ronald Minnich, Douglas Sweely, and Daniel Lopresti. </author> <title> Building and Using a Highly Programmable Logic Array. </title> <journal> IEEE Computer, </journal> <volume> 24(1) </volume> <pages> 81-89, </pages> <month> January </month> <year> 1991. </year>
Reference-contexts: Sequence and string matching By recognizing the application's natural structure and specializing a configurable compute engine to take advantage of the structure, researchers have managed to achieve very high performance at modest costs [14] <ref> [12] </ref> [16]. 5. Sorting Sorting tasks exhibit natural, fine-grained parallelism. By exploiting this parallelism, large sorting tasks can be performed efficiently with sorting networks built from configurable logic [17]. 6. Physical system simulation Simulating physical phenomena often require repeated evaluation of state-variables using very regular computations, often of limited precision.
Reference: [13] <author> Maya Gokhale and Ron Minnich. </author> <title> FPGA Computing in a Data Parallel C. </title> <editor> In Duncan A. Buell and Kenneth L. Pocek, editors, </editor> <booktitle> Proceedings of the IEEE Workshop on FPGAs for Custom Computing Machines, </booktitle> <pages> pages 94-101, </pages> <address> Los Alamitos, California, April 1993. </address> <publisher> IEEE Computer Society, IEEE Computer Society Press. </publisher>
Reference-contexts: Increasingly, the behavior for these reconfigurable computing engines is described at a behavioral level in hardware description languages (e.g. VHDL, Verilog). In contemporary cases, experts familiar with the reconfigurable architecture develop the configurations for accelerating each application. PRISM [21] and dbC <ref> [13] </ref> demonstrate that conventional programming languages can be restricted or extended to allow programmers more comfortable with programming languages to express computations in a way which can be readily compiled for implementation on reconfigurable FCCM '94 --IEEE Workshop on FPGAs for Custom Computing Machines April 10-13, Napa, CA logic.
Reference: [14] <author> Dzung T. Hoang. </author> <title> Searching Genetic Databases on Splash 2. </title> <editor> In Duncan A. Buell and Kenneth L. Pocek, editors, </editor> <booktitle> Proceedings of the IEEE Workshop on FPGAs for Custom Computing Machines, </booktitle> <pages> pages 185-191, </pages> <address> Los Alamitos, California, April 1993. </address> <publisher> IEEE Computer Society, IEEE Computer Society Press. </publisher>
Reference-contexts: Sequence and string matching By recognizing the application's natural structure and specializing a configurable compute engine to take advantage of the structure, researchers have managed to achieve very high performance at modest costs <ref> [14] </ref> [12] [16]. 5. Sorting Sorting tasks exhibit natural, fine-grained parallelism. By exploiting this parallelism, large sorting tasks can be performed efficiently with sorting networks built from configurable logic [17]. 6.
Reference: [15] <author> Intel Corporation. A90960CA16,S V594 A-4 Stepping, </author> <title> Errors and Exceptions, </title> <note> rev. 2 edition, </note> <month> April </month> <year> 1990. </year>
Reference-contexts: This migration can provide considerable flexibility and a number of practical advantages, including: * Feature interaction, particularly with exception and error conditions, have a history of being one of the hardest parts of a processor design to get correct (e.g. [8] <ref> [15] </ref>). Careful relocation of this interaction logic into the reconfigurable logic allows later binding and post-fabrication modification of interaction behavior. * The fault, interrupt, and system call behavior of many, modern microprocessors is often quite mismatched with the needs of the operating system [3].
Reference: [16] <author> Daniel Lopresti. </author> <title> Rapid Implementation of a Genetic Sequence Comparator Using Field-Programmable Logic Arrays. </title> <editor> In Carlo H. S equin, editor, </editor> <booktitle> Advanced Research in VLSI, </booktitle> <pages> pages 138-152, </pages> <address> Cambridge, MA, April 1991. </address> <publisher> MIT Press. </publisher>
Reference-contexts: Each SPLASH array attaches to a host workstations and is composed from a number of Xilinx FPGAs in an array fashion along with support memory. SPLASH has seen heavy use in genome sequence matching applications <ref> [16] </ref>. * DEC Paris's PAM (Programmable Active Memories) is an array of Xilinx FPGAs attached to a host workstation [5]. <p> Sequence and string matching By recognizing the application's natural structure and specializing a configurable compute engine to take advantage of the structure, researchers have managed to achieve very high performance at modest costs [14] [12] <ref> [16] </ref>. 5. Sorting Sorting tasks exhibit natural, fine-grained parallelism. By exploiting this parallelism, large sorting tasks can be performed efficiently with sorting networks built from configurable logic [17]. 6. Physical system simulation Simulating physical phenomena often require repeated evaluation of state-variables using very regular computations, often of limited precision.
Reference: [17] <author> Wayne Luk, Vincent Lok, and Ian Page. </author> <title> Hardware Acceleration of Divide-and-Conquer Paradigms: a Case Study. </title> <editor> In Duncan A. Buell and Kenneth L. Pocek, editors, </editor> <booktitle> Proceedings of the IEEE Workshop on FPGAs for Custom Computing Machines, </booktitle> <pages> pages 192-1201, </pages> <address> Los Alamitos, California, April 1993. </address> <publisher> IEEE Computer Society, IEEE Computer Society Press. </publisher> <editor> [18] et. al. M. </editor> <title> Gokhale. SPLASH: A Reconfigurable Linear Logic Array. </title> <booktitle> In Proceedings of the International Conference on Parallel Processing, </booktitle> <pages> pages 526-532, </pages> <month> August </month> <year> 1990. </year>
Reference-contexts: Sorting Sorting tasks exhibit natural, fine-grained parallelism. By exploiting this parallelism, large sorting tasks can be performed efficiently with sorting networks built from configurable logic <ref> [17] </ref>. 6. Physical system simulation Simulating physical phenomena often require repeated evaluation of state-variables using very regular computations, often of limited precision. Compute engines specialized to evaluating particular systems of equations can achieve significant advantage over general-purpose processors [4]. 7.
Reference: [19] <author> Rishiyur S. Nikhil, Gregory M. Papadopoulous, and Arvind. </author> <title> *T: A Multithreaded Massively Parallel Architecture. </title> <booktitle> In Proceedings of the 19th International Symposium on Computer Architecture. ACM, </booktitle> <month> May </month> <year> 1992. </year>
Reference-contexts: This allows computational functions to be placed where intermediate data resides in the reconfigurable array, taking further advantage of application-specific locality and data flow. Finally, DPGAs are naturally suited to conventional multitasking or fine-grained multithreading (e.g. April [1], *T <ref> [19] </ref>). In these applications, each thread or context may require a different array personality. By partitioning the DPGA contexts and assigning a different context, or sets of contexts, to each thread or task, array reconfiguration will not complicate sharing the processor between tasks or threads. <p> Part of the reconfigurable logic can be em ployed as system-specific glue logic. * Multiprocessor Systems - DPGA-coupled processors can be employed in a variety of ways to produce high-performance multiprocessors. Part of the DPGA logic array could be used to build a tightly-integrated network interface (e.g. [10] <ref> [19] </ref>) to adapt the microprocessor for multiprocessing. Part of the DPGA logic could be used to construct application-specific synchronization primitives or communication networks. Each node may employ the DPGA logic for task acceleration in the same manner as single processor special- and general-purpose computers.
Reference: [20] <author> M. Shand and J. Vuillemin. </author> <title> Fast Implementations of RSA Cryptography. </title> <editor> In Earl Swartzlander Jr., Mary Jane Irwin, and Graham Julien, editors, </editor> <booktitle> Proceedings of the 11th Symposium on Computer Arithmetic, </booktitle> <pages> pages 252-259, </pages> <address> Los Alamitos, California, June 1993. </address> <publisher> IEEE Computer Society, IEEE Computer Society Press. </publisher>
Reference-contexts: Arithmetic When the arithmetic operations required by a computation do not exactly match those provided by the ALU/FPU in conventional microprocessors or when the arithmetic operations admit to substantial bit-level parallelism, there is ample room to specialize reconfigurable logic to provide higher performance [11] <ref> [20] </ref> [4] [9]. 3. Encryption/Decryption/Compression Encryption/decryption and compression applications require application of simple sequences of arithmetic and logic operations to large datasets. The operations required are often not native to typical microprocessors. <p> The operations required are often not native to typical microprocessors. Specialized computing engines can provide the appropriate operators and make use of the parallelism and regularity in the application to extract high per formance <ref> [20] </ref> [4]. 4. Sequence and string matching By recognizing the application's natural structure and specializing a configurable compute engine to take advantage of the structure, researchers have managed to achieve very high performance at modest costs [14] [12] [16]. 5. Sorting Sorting tasks exhibit natural, fine-grained parallelism.
Reference: [21] <author> Harvey F. Silverman. </author> <title> Processor Reconfiguration Through Instruction-Set Metamorphosis. </title> <journal> IEEE Computer, </journal> <volume> 26(3) </volume> <pages> 11-18, </pages> <month> March </month> <year> 1993. </year>
Reference-contexts: 4.1 Reconfigurable Compute Engines Several research groups have built reconfigurable compute engines to extract high application performance at low costs by specializing the computing engine to the computation task. * Athanas and Silverman introduce the PRISM (Processor Reconfiguration through Instruction-Set Metamorphosis) architecture which couples a programmable element with a microprocessor <ref> [21] </ref>. From each application program, new processor instructions are synthesized in the reconfigurable element which are designed to accelerate the application. <p> The earliest reconfigurable compute engines were configured through explicit, human-crafted gate-designs. Increasingly, the behavior for these reconfigurable computing engines is described at a behavioral level in hardware description languages (e.g. VHDL, Verilog). In contemporary cases, experts familiar with the reconfigurable architecture develop the configurations for accelerating each application. PRISM <ref> [21] </ref> and dbC [13] demonstrate that conventional programming languages can be restricted or extended to allow programmers more comfortable with programming languages to express computations in a way which can be readily compiled for implementation on reconfigurable FCCM '94 --IEEE Workshop on FPGAs for Custom Computing Machines April 10-13, Napa, CA
Reference: [22] <author> M. Wazlowski, L. Agarwal, T. Lee, A. Smith, E. Lam, P. Athanas, H. SIlverman, and S. Ghosh. </author> <title> PRISM-II Compiler and Architecture. </title> <editor> In Duncan A. Buell and Kenneth L. Pocek, editors, </editor> <booktitle> Proceedings of the IEEE Workshop on FPGAs for Custom Computing Machines, </booktitle> <pages> pages 9-16, </pages> <address> Los Alamitos, California, April 1993. </address> <publisher> IEEE Computer Society, IEEE Computer Society Press. </publisher>
Reference-contexts: When applications require the evaluation of large, regular binary operations, reconfigurable compute engines can offer significant advantage over the fixed logic available in typical processors. The PRISM research project demonstrates the kinds of advantages provided by this class of special ization <ref> [22] </ref>. 2. Arithmetic When the arithmetic operations required by a computation do not exactly match those provided by the ALU/FPU in conventional microprocessors or when the arithmetic operations admit to substantial bit-level parallelism, there is ample room to specialize reconfigurable logic to provide higher performance [11] [20] [4] [9]. 3.
Reference: [23] <author> Xilinx, Inc., </author> <title> 2100 Logic Drive, </title> <address> San Jose, CA 95124. </address> <publisher> The Programmable Gate Array Databook, </publisher> <year> 1989. </year>
Reference-contexts: From each application program, new processor instructions are synthesized in the reconfigurable element which are designed to accelerate the application. PRISM-I and PRISM-II prototypes have been built which couple common microprocessors with Xilinx FPGAs <ref> [23] </ref>. * Cuccaro and Reese at the Supercomputing Research Center augmented a CM-2 with reconfigurable logic units by using Xilinx FPGAs in place of the CM-2 floating point processors [9].
Reference: [24] <author> Xilinx, Inc., </author> <title> 2100 Logic Drive, San Jose, CA 95124. Product Description and Selection Guide, </title> <month> April </month> <year> 1993. </year>
Reference-contexts: We may also see the emergence of hybrid solutions like the Xilinx HardWire Gate Arrays <ref> [24] </ref>. In systems where the configured logic is employed in a fixed manner, stable designs can migrate from the reconfigurable microprocessor to a microprocessor with an equivalent gate array which can be programmed at the mask level.
References-found: 23

