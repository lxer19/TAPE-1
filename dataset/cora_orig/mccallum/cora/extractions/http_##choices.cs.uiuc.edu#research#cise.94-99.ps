URL: http://choices.cs.uiuc.edu/research/cise.94-99.ps
Refering-URL: http://choices.cs.uiuc.edu/research/other.html
Root-URL: http://www.cs.uiuc.edu
Email: Professor  roy@cs.uiuc.edu  achien@cs.uiuc.edu  kaplan@cs.uiuc.edu  Professor  
Phone: Telephone: (217) 333-0215 Fax: (217) 333-3501  Telephone: (217) 333-6844 Fax: (217) 333-3501  Telephone: (217) 244-0392 Fax: (217) 333-3501  Telephone: (217) 333-3807 Fax: (217) 333-3501  Telephone: (217) 333-0028 Fax: (217) 333-3501  
Title: A Proposal for a Broadband Network Infrastructure (High-Speed Networks, Data Archives, and Collaborative Work)  
Author: Submitting Technical Contacts: Roy H. Campbell, Andrew A. Chien, Simon M. Kaplan, Daniel A. Reed, Richard F. Canaday 
Address: 1304 West Springfield Avenue Urbana, Illinois 61801  Science  
Affiliation: Directorate for Computer and Information Science and Engineering  Department of Computer Science Organization: University of Illinois at Urbana-Champaign  Director of Budget Planning Department of Computer  
Note: INSTITUTIONAL INFRASTRUCTURE PROPOSAL National Science Foundation  Electronic Mail:  Assistant Professor  Electronic Mail:  Associate Professor  Electronic Mail:  Electronic Mail: reed@cs.uiuc.edu Administrative Contact:  
Abstract-found: 0
Intro-found: 0
Reference: [1] <author> Agha, G. </author> <title> ACTORS: A Model of Concurrent Computation in Distributed Systems. </title> <publisher> M.I.T. Press, </publisher> <address> Cambridge, Mass., </address> <year> 1986. </year>
Reference-contexts: This model allows for the concise visual description of many programming problems, as well as the expression of the semantics of complex concurrent programming languages such Actor systems <ref> [1, 64] </ref>. Simon M. Kaplan is a Associate Professor and Director of the Human-Computer Interaction Laboratory in the Department of Computer Science at the University of Ilinois at Urbana-Champaign. This laboratory employs approximately 5 Ph.D and 5 MS students, several undergraduates and a research programmer.
Reference: [2] <author> Ahuja, S., Ensor, R., and Horn, D. </author> <title> The Rapport Multimedia Conferencing System. </title> <booktitle> In Proceedings 1990 ACM Conference on Office Information Systems (1990). </booktitle>
Reference-contexts: The third is the CAVECAT project [92]at the University of Toronto, which was started by (amongst others) Bill Buxton, who designed the EuroPARC media space. The final two are the Cruiser project [34] at BellCore and the Rapport system at AT&T Bell Labs <ref> [2] </ref>. All are investigating various technical and social aspects of using multimedia spaces to provide affordances for virtual co-location. More important, all of them are analog media spaces. The technical issues that arise when investigating real-time media spaces are strongly intertwined with social issues.
Reference: [3] <author> Aoyama, K., and Chien, A. A. </author> <title> The Cost of Adaptivity and Virtual Lanes in a Wormhole Router. </title> <note> submitted for publication (1993). </note>
Reference-contexts: These results are published in <ref> [23, 3] </ref>, and have had major impact in the routing network community, allowing (and forcing) designers to weigh the benefits of adaptive routing directly against its cost. Chien's other work in this area addresses the use of routing networks, particularly if packetization is desirable [70].
Reference: [4] <author> Arendt, J. W. </author> <title> Parallel Genome Sequence Comparison Using an iPSC/2 with a Concurrent File System. </title> <type> Master's thesis, </type> <institution> University of Illinois at Urbana-Champaign, Department of Computer Science, </institution> <month> Jan. </month> <year> 1991. </year>
Reference-contexts: Hence, resource management and performance measurement are inextricably connected. 62 During the lifetime of the Tapestry project, our work included studies of resource man-agement algorithms for distributed memory parallel systems (i.e., dynamic task scheduling [37, 39, 94, 38], parallel input/output <ref> [4, 50] </ref>, and adaptive message routing [40, 37]), operating system instrumentation and performance analysis of Choices [72], and performance data instrumentation, data analysis, and presentation for distributed memory parallel systems [105, 104, 90, 88, 102], shared memory parallel systems [91], traditional vector supercomputers [86], and machine-independent instrumentation [84, 101, 99]. <p> For example, we used our tools to measure the performance of the iPSC/2 Concurrent File System (CFS) [96] using both synthetic benchmarks and realistic applications (e.g., parallel genome sequencing <ref> [4] </ref>). Experience showed that only execution traces could reveal such details as the time varying performance of disk block caching and file directory management. Drawing on these insights, we extended our input/output study to include the tertiary store at NCSA [50]. <p> To study the potential benefits of parallel input/output, we conducted parametric performance studies of the Intel iPSC/2 disk array and its Concurrent File System (CFS) using our performance instrumentation tools <ref> [4] </ref>. Via the Intel CFS software, one can view the I/O node disks as one large, logical disk with large files distributed (striped) across all disks. <p> We studied the Concurrent File System's performance using both synthetic file system benchmarks and a parallel genome sequence program <ref> [4] </ref>. For concurrent file access by multiple nodes, CFS performance was adequate if the concurrent accesses had sufficient temporal and spatial locality; these requests could be satisfied from the disk cache. <p> In general, we observed that it was difficult to achieve good application performance with the CFS file system without detailed, application-level knowledge of the data distribution across disks and the intended data access pattern; see <ref> [4] </ref> for additional details. I.3 Significant Accomplishments Several important research contributions resulted from the Tapestry project. * We developed a prototype set of performance analysis tools for distributed memory parallel systems that stimulated vendors to include more powerful performance analysis tools in their product offerings.
Reference: [5] <author> Banerjea, A., and Mah, B. </author> <title> The Real-Time Channel Administration Protocol. </title> <booktitle> In 2nd Int'l. Workshop on Network and Operating System Support for Digital Audio and Video (November 1991). </booktitle>
Reference-contexts: New kernel data structures are needed to represent multimedia data streams and new operating system application interfaces. 29 Previous work in operating systems issues for multimedia support have focused on trans-port protocols. Much work has been done on real time transport protocols for isochronous traffic such as RTP <ref> [5] </ref>. While efficient real time transport protocols are essential for multimedia communications, we seek efficient algorithms within the operating system kernel that support images and multiple video and audio streams.
Reference: [6] <author> Bogia, D. P., Tolone, W. J., Bignoli, E., and Kaplan, S. M. </author> <title> Issues in the Design of Collaborative Systems: Lessons from ConversationBuilder. </title> <booktitle> In Proceedings Schaerding International Workshop on Design of CSCW Systems (1993). </booktitle>
Reference-contexts: Indeed, in certain cases the absence of this infrastructure will effectively make it impossible for us to realize our plans. ConversationBuilder and VSE ConversationBuilder (CB) <ref> [66, 67, 6, 65, 57, 59, 58, 62] </ref> is Professor Kaplan's vehicle for investigating the problems that arise when providing support for collaboration via the computer.
Reference: [7] <author> Bradley, D. K. </author> <title> First and Second Generation Hypercube Performance. </title> <type> Master's thesis, </type> <institution> University of Illinois at Urbana-Champaign, Department of Computer Science, </institution> <month> Sept. </month> <year> 1988. </year>
Reference-contexts: Professor Reed's research in the area of distributed memory parallel systems predates the emergence of commercial systems; it began in the early 1980's with analytic performance models of 51 interconnection networks, followed by a series of synthetic benchmarks <ref> [7] </ref>, investigation of techniques to to reduce software message passing latency [100], and the analysis and simulation of adaptive, circuit-switched routing algorithms. The the results of the latter aided the design of the JPL hyperswitch, a message router for the JPL Mark III hypercube [26].
Reference: [8] <author> Campbell, R., Dorward, S., Iyengar, A., Kalmanek, C., Murakami, G., Sethi, R., Shieh, C.-K., and Tan, S.-M. </author> <title> "Control Software for Virtual-Circuit Switches: Call Processing". </title> <booktitle> Lecture Notes in Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1992. </year>
Reference-contexts: The Blanca Project uses AT&T's Experimental University Network (XUNET). As part of effort, he contributed towards the design of the switch controller software <ref> [8] </ref>. He has also examined new switch architectures [93]. He is currently a Professor in the Department of Computer Science and Electrical and Computer Engineering at the University of Illinois at Urbana-Champaign.
Reference: [9] <author> Campbell, R., Islam, N., Madany, P., and Raila, D. </author> <title> Designing and Implementing Choices:an Object-Oriented System in C++. </title> <journal> Communications of the ACM (Sept. </journal> <year> 1993). </year>
Reference-contexts: His most recent research is in distributed parallel operating systems and ATM networks. As co-director of the NSF-funded CISE/RI Tapestry project, he designed the Choices object-oriented operating system <ref> [9] </ref>. Choices runs on several different hardware platforms including both distributed and shared memory parallel processor machines. The project demonstrated that operating systems can be customized for specific application performance through the use of object-oriented techniques. <p> Generic components are customized through object-oriented inheritance and specialization to match the specific concurrency requirements of applications. Choices has, as its kernel, a dynamic collection of objects <ref> [9, 12, 78, 10] </ref>. System resources, mechanisms, and policies are represented as objects that belong to a class hierarchy [108]. The object-oriented application interface has a name server that implements inheritance and polymorphism and provides access to system services, local and remote servers, and persistent objects.
Reference: [10] <author> Campbell, R. H., Hine, J. J., and Russo, V. F. </author> <title> "Choices for Mission Critical Computing". In Studies in Computer and Communication Systems , A. Agrawala, </title> <editor> K. Gordon, and P. Hwang, Eds. </editor> <publisher> IOS Press, </publisher> <year> 1992, </year> <pages> pp. 11-20. </pages>
Reference-contexts: Generic components are customized through object-oriented inheritance and specialization to match the specific concurrency requirements of applications. Choices has, as its kernel, a dynamic collection of objects <ref> [9, 12, 78, 10] </ref>. System resources, mechanisms, and policies are represented as objects that belong to a class hierarchy [108]. The object-oriented application interface has a name server that implements inheritance and polymorphism and provides access to system services, local and remote servers, and persistent objects.
Reference: [11] <author> Campbell, R. H., and Islam, N. </author> <title> "A Technique for Documenting the Framework of an Object-Oriented System". </title> <booktitle> In Proceedings Second International Workshop on Object-Orientation in Operating Systems (Paris, </booktitle> <address> France, </address> <month> Sept. </month> <year> 1992), </year> <pages> pp. 288-300. </pages>
Reference-contexts: While supporting operating system layers, frameworks also encourage design and code reuse [51, 12] and the consistent imposition of design constraints on all software, independent of the level at which it may be used <ref> [15, 11] </ref>. The framework for the system provides generalized components and constraints to which the specialized subframeworks must conform. Conformance is enforced in the subframeworks by reusing the classes and constraints defined within the framework. The subframeworks introduce additional components and constraints and subclass components of the framework.
Reference: [12] <author> Campbell, R. H., and Islam, N. </author> " <title> Choices: A Parallel Object-Oriented Operating System". In Research Directions in Concurrent Object-Oriented Programming (1993), </title> <editor> G. Agha, P. Wegner, and A. Yonezawa, Eds., </editor> <publisher> MIT Press. </publisher> <pages> 66 </pages>
Reference-contexts: Each of these efforts is briefly summarized below. I.1 Operating System Infrastructure To accommodate diverse parallel applications, Choices supports a large set of components that may be combined to support different models of parallel and concurrent programming <ref> [12, 48, 45, 46, 16, 15] </ref>. Generic components are customized through object-oriented inheritance and specialization to match the specific concurrency requirements of applications. Choices has, as its kernel, a dynamic collection of objects [9, 12, 78, 10]. <p> Generic components are customized through object-oriented inheritance and specialization to match the specific concurrency requirements of applications. Choices has, as its kernel, a dynamic collection of objects <ref> [9, 12, 78, 10] </ref>. System resources, mechanisms, and policies are represented as objects that belong to a class hierarchy [108]. The object-oriented application interface has a name server that implements inheritance and polymorphism and provides access to system services, local and remote servers, and persistent objects. <p> In the design of Choices, the concept of a framework subsumes the more conventional organization of an operating system into layers [108, 14]. While supporting operating system layers, frameworks also encourage design and code reuse <ref> [51, 12] </ref> and the consistent imposition of design constraints on all software, independent of the level at which it may be used [15, 11]. The framework for the system provides generalized components and constraints to which the specialized subframeworks must conform. <p> The subframeworks introduce additional components and constraints and subclass components of the framework. We believe this way of building systems greatly simplifies experiments involving the comparison of many different policies [15]. 61 Choices has frameworks for parallel processing <ref> [47, 15, 12] </ref>, virtual memory [109, 106, 12], distributed shared virtual memory [52, 111], message passing systems [47, 45, 15], remote procedure calls [31], TCP/IP [116, 117], hardware exceptions [107], multiple processors [108, 12, 15], device management [74], schedulers [47], file systems [79, 83, 82] and persistent objects [18, 80]. <p> The subframeworks introduce additional components and constraints and subclass components of the framework. We believe this way of building systems greatly simplifies experiments involving the comparison of many different policies [15]. 61 Choices has frameworks for parallel processing [47, 15, 12], virtual memory <ref> [109, 106, 12] </ref>, distributed shared virtual memory [52, 111], message passing systems [47, 45, 15], remote procedure calls [31], TCP/IP [116, 117], hardware exceptions [107], multiple processors [108, 12, 15], device management [74], schedulers [47], file systems [79, 83, 82] and persistent objects [18, 80]. <p> greatly simplifies experiments involving the comparison of many different policies [15]. 61 Choices has frameworks for parallel processing [47, 15, 12], virtual memory [109, 106, 12], distributed shared virtual memory [52, 111], message passing systems [47, 45, 15], remote procedure calls [31], TCP/IP [116, 117], hardware exceptions [107], multiple processors <ref> [108, 12, 15] </ref>, device management [74], schedulers [47], file systems [79, 83, 82] and persistent objects [18, 80]. <p> The systems that we have built could not only be optimized using object-oriented customization techniques, but the systems were also of comparable performance to commercially available, optimized systems written in C [108, 110, 79, 72]. * We classified operating system algorithms, data structures, and resource management schemes <ref> [108, 79, 12, 15] </ref>. and developed an approach to reusing and customizing operating system designs based on the notion of a framework [14, 12, 15]. We also compared a variety of message passing implementations and showed that application performance depends strongly on the implementation of the message passing system. 65 <p> also of comparable performance to commercially available, optimized systems written in C [108, 110, 79, 72]. * We classified operating system algorithms, data structures, and resource management schemes [108, 79, 12, 15]. and developed an approach to reusing and customizing operating system designs based on the notion of a framework <ref> [14, 12, 15] </ref>. We also compared a variety of message passing implementations and showed that application performance depends strongly on the implementation of the message passing system. 65
Reference: [13] <author> Campbell, R. H., and Islam, N. </author> <title> A Technique for Documenting the Framework of an Object-Oriented System. </title> <booktitle> Computing Systems 6, </booktitle> <month> 4 </month> <year> (1993). </year>
Reference-contexts: The project demonstrated that operating systems can be customized for specific application performance through the use of object-oriented techniques. A variety of different message passing customizations for shared memory machines are discussed in [45]. A design technique based on frameworks simplified the customization of the Choices operating system <ref> [13] </ref>. Professor Campbell's interests in network architectures started in 1980 and led to an early design and implementation of a high-bandwidth token ring called Illinet [20].
Reference: [14] <author> Campbell, R. H., Islam, N., Johnson, R., Kougiouris, P., and Madany, P. </author> <title> Choices, Frameworks and Refinement. </title> <booktitle> In Object-Orientation in Operating Systems (Palo Alto, </booktitle> <address> CA, </address> <month> Oct. </month> <year> 1991), </year> <editor> Luis-Felipe Cabrera and Vincent Russo, and Marc Shapiro, Ed., </editor> <publisher> IEEE Computer Society Press, </publisher> <pages> pp. 9-15. </pages>
Reference-contexts: The object-oriented application interface has a name server that implements inheritance and polymorphism and provides access to system services, local and remote servers, and persistent objects. In the design of Choices, the concept of a framework subsumes the more conventional organization of an operating system into layers <ref> [108, 14] </ref>. While supporting operating system layers, frameworks also encourage design and code reuse [51, 12] and the consistent imposition of design constraints on all software, independent of the level at which it may be used [15, 11]. <p> also of comparable performance to commercially available, optimized systems written in C [108, 110, 79, 72]. * We classified operating system algorithms, data structures, and resource management schemes [108, 79, 12, 15]. and developed an approach to reusing and customizing operating system designs based on the notion of a framework <ref> [14, 12, 15] </ref>. We also compared a variety of message passing implementations and showed that application performance depends strongly on the implementation of the message passing system. 65
Reference: [15] <author> Campbell, R. H., Islam, N., and Madany, P. </author> <title> Choices, Frameworks and Refinement. </title> <booktitle> Computing Systems 5, 3 (1992), </booktitle> <pages> 217-257. </pages>
Reference-contexts: We next discuss how operating systems are customized. Customized Operating Systems The Choices operating system, built in the Tapestry Laboratory, demonstrates the feasibility of customizing an operating system for an application. It is an object-oriented operating system in which design frameworks <ref> [15] </ref> support alternative implementations of key services. Each framework separates implementation details from the design of a subsystem which is expressed as a set of abstract classes and their interrelationships. <p> Each of these efforts is briefly summarized below. I.1 Operating System Infrastructure To accommodate diverse parallel applications, Choices supports a large set of components that may be combined to support different models of parallel and concurrent programming <ref> [12, 48, 45, 46, 16, 15] </ref>. Generic components are customized through object-oriented inheritance and specialization to match the specific concurrency requirements of applications. Choices has, as its kernel, a dynamic collection of objects [9, 12, 78, 10]. <p> While supporting operating system layers, frameworks also encourage design and code reuse [51, 12] and the consistent imposition of design constraints on all software, independent of the level at which it may be used <ref> [15, 11] </ref>. The framework for the system provides generalized components and constraints to which the specialized subframeworks must conform. Conformance is enforced in the subframeworks by reusing the classes and constraints defined within the framework. The subframeworks introduce additional components and constraints and subclass components of the framework. <p> Conformance is enforced in the subframeworks by reusing the classes and constraints defined within the framework. The subframeworks introduce additional components and constraints and subclass components of the framework. We believe this way of building systems greatly simplifies experiments involving the comparison of many different policies <ref> [15] </ref>. 61 Choices has frameworks for parallel processing [47, 15, 12], virtual memory [109, 106, 12], distributed shared virtual memory [52, 111], message passing systems [47, 45, 15], remote procedure calls [31], TCP/IP [116, 117], hardware exceptions [107], multiple processors [108, 12, 15], device management [74], schedulers [47], file systems [79, <p> The subframeworks introduce additional components and constraints and subclass components of the framework. We believe this way of building systems greatly simplifies experiments involving the comparison of many different policies [15]. 61 Choices has frameworks for parallel processing <ref> [47, 15, 12] </ref>, virtual memory [109, 106, 12], distributed shared virtual memory [52, 111], message passing systems [47, 45, 15], remote procedure calls [31], TCP/IP [116, 117], hardware exceptions [107], multiple processors [108, 12, 15], device management [74], schedulers [47], file systems [79, 83, 82] and persistent objects [18, 80]. <p> We believe this way of building systems greatly simplifies experiments involving the comparison of many different policies [15]. 61 Choices has frameworks for parallel processing [47, 15, 12], virtual memory [109, 106, 12], distributed shared virtual memory [52, 111], message passing systems <ref> [47, 45, 15] </ref>, remote procedure calls [31], TCP/IP [116, 117], hardware exceptions [107], multiple processors [108, 12, 15], device management [74], schedulers [47], file systems [79, 83, 82] and persistent objects [18, 80]. <p> greatly simplifies experiments involving the comparison of many different policies [15]. 61 Choices has frameworks for parallel processing [47, 15, 12], virtual memory [109, 106, 12], distributed shared virtual memory [52, 111], message passing systems [47, 45, 15], remote procedure calls [31], TCP/IP [116, 117], hardware exceptions [107], multiple processors <ref> [108, 12, 15] </ref>, device management [74], schedulers [47], file systems [79, 83, 82] and persistent objects [18, 80]. <p> The results of the comparison showed many advantages for application-oriented message passing systems that are customized to support specific applications on specific hardware. A classification of message passing schemes has been published <ref> [15] </ref>. Early results from distributed shared virtual memory experiments convinced us to redesign the virtual memory and distributed shared virtual memory systems [111] to permit parallelism in the paging system. <p> The systems that we have built could not only be optimized using object-oriented customization techniques, but the systems were also of comparable performance to commercially available, optimized systems written in C [108, 110, 79, 72]. * We classified operating system algorithms, data structures, and resource management schemes <ref> [108, 79, 12, 15] </ref>. and developed an approach to reusing and customizing operating system designs based on the notion of a framework [14, 12, 15]. We also compared a variety of message passing implementations and showed that application performance depends strongly on the implementation of the message passing system. 65 <p> also of comparable performance to commercially available, optimized systems written in C [108, 110, 79, 72]. * We classified operating system algorithms, data structures, and resource management schemes [108, 79, 12, 15]. and developed an approach to reusing and customizing operating system designs based on the notion of a framework <ref> [14, 12, 15] </ref>. We also compared a variety of message passing implementations and showed that application performance depends strongly on the implementation of the message passing system. 65
Reference: [16] <author> Campbell, R. H., Johnston, G., Kenny, K., Murakami, G., and Russo, V. </author> <title> "Choices (Class Hierarchical Open Interface for Custom Embedded Systems)". </title> <booktitle> Operating Systems Review 21, </booktitle> <month> 3 (July </month> <year> 1987), </year> <pages> 9-17. </pages>
Reference-contexts: Each of these efforts is briefly summarized below. I.1 Operating System Infrastructure To accommodate diverse parallel applications, Choices supports a large set of components that may be combined to support different models of parallel and concurrent programming <ref> [12, 48, 45, 46, 16, 15] </ref>. Generic components are customized through object-oriented inheritance and specialization to match the specific concurrency requirements of applications. Choices has, as its kernel, a dynamic collection of objects [9, 12, 78, 10].
Reference: [17] <author> Campbell, R. H., and Kolstad, R. B. </author> <title> "Path Expressions in Pascal". </title> <booktitle> In Proceedings of the Fourth International Conference on Software Engineering (Munich, </booktitle> <month> September </month> <year> 1979), </year> <pages> pp. 212-219. </pages>
Reference-contexts: After his Ph.D., he developed the "Path Pascal" language, an extension of Pascal that included abstract data types, path expressions, and processes. His first experience with distributed computing was an implementation of a simple message passing system between two PDP11s using Path Pascal <ref> [17] </ref>. Later, Path Pascal was extended with remote procedure calls for distributed processing. In the early 1980s, his contributions were in the area of software reliability and fault-tolerance.
Reference: [18] <author> Campbell, R. H., and Madany, P. W. </author> <title> Considerations of Persistence and Security in Choices, an Object-Oriented Operating System. In Security and Persistence, </title> <editor> J. Rosenberg and J. L. Keedy, Eds., </editor> <booktitle> Workshops in Computing. </booktitle> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1990, </year> <pages> pp. 289-300. </pages> <booktitle> Proceedings of the International Workshop on Computer Architectures to Support Security and Persistence of Information, </booktitle> <institution> Bremen, Federal Republic of Germany, </institution> <month> May </month> <year> 1990. </year>
Reference-contexts: parallel processing [47, 15, 12], virtual memory [109, 106, 12], distributed shared virtual memory [52, 111], message passing systems [47, 45, 15], remote procedure calls [31], TCP/IP [116, 117], hardware exceptions [107], multiple processors [108, 12, 15], device management [74], schedulers [47], file systems [79, 83, 82] and persistent objects <ref> [18, 80] </ref>. The system runs on shared memory multiprocessor Encore Multimaxes [108], MC68030s [74], Intel 80386 and 80486 personal computers [76], SUN SPARCstation I and II architectures [98] as well as the Tapestry Intel iPSC/2 hypercubes.
Reference: [19] <author> Campbell, R. H., and Randell, B. </author> <title> "Error Recovery in Asynchronous Systems". </title> <journal> IEEE Transactions on Software Engineering 12, </journal> <month> 8 (August </month> <year> 1986), </year> <pages> 811-826. </pages>
Reference-contexts: He introduced a fault-tolerant deadline mechanism and, with Liestman, worked out a fault-tolerant scheme for scheduling deadline processes in periodic real-time systems [77]. On sabbatical, he developed a general mechanism for handling asynchronous exceptions in concurrent systems <ref> [19] </ref> and later developed, with Jalote, an example CSP implementation of the concepts [49]. Subsequently, he worked in the Software Engineering area on syntax-directed editors, developed object-oriented approaches to configuration and project management, helped Professor Kaplan develop the notions of Delta grammars, and developed a system for executable specifications.
Reference: [20] <author> Cheng, W. Y., Ray, S., Kolstad, R., Luhukay, J., Campbell, R. H., and Lui, J. W.-S. </author> <title> "ILLINET-A 32 Mbits/sec. local-area network". </title> <booktitle> In Proceedings of the 1981 National Computer Conference (Chicago IL, </booktitle> <month> May </month> <year> 1981), </year> <pages> pp. 209-214. </pages>
Reference-contexts: A design technique based on frameworks simplified the customization of the Choices operating system [13]. Professor Campbell's interests in network architectures started in 1980 and led to an early design and implementation of a high-bandwidth token ring called Illinet <ref> [20] </ref>. Currently, he is a co-principal invesigator in the Blanca Project, a gigabit testbed funded by NSF and ARPA through the Center for National Research Initiatives.
Reference: [21] <author> Chien, A., Karamcheti, V., and Plevyak, J. </author> <title> The Concert system Compiler and Runtime Support for Efficient Fine-Grained Concurrent Object-Oriented Programs. </title> <type> Tech. Rep. </type> <institution> UIUCDCS-R-93-1815, Department of Computer Science, University of Illinois, Urbana, Illinois, </institution> <month> June </month> <year> 1993. </year>
Reference-contexts: This work has formed the basis for much work in the area, notably the pC++ project [75] and the parallel software efforts in the nascent Japanese Real World Computing Project (RWC) [73]. For the last two years, Professor Chien has led the Illinois Concert project <ref> [21] </ref>, whose goal is to develop efficient implementation techniques for fine-grained concurrent object-oriented languages. The Concert system supports concurrent objects and the multi-access 48 data abstraction tools described in [22].
Reference: [22] <author> Chien, A. A. </author> <title> Concurrent Aggregates: Supporting Modularity in Massively-Parallel Programs. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1993. </year>
Reference-contexts: The J-Machine [29, 30] pioneered a number of techniques which are now being widely used in parallel architectures: message-driven execution, hardware support for message dispatch, and direct access instruction set access to the network at level of registers. Professor Chien's work on concurrent object-oriented programming systems for fine-grained machines <ref> [22, 24, 43] </ref> demonstrated the practicality of such approaches for fine-grained machines with thousands of processors. His work identified the critical need for multi-access data abstraction tools for modularizing parallel programs with constraining concurrency. <p> For the last two years, Professor Chien has led the Illinois Concert project [21], whose goal is to develop efficient implementation techniques for fine-grained concurrent object-oriented languages. The Concert system supports concurrent objects and the multi-access 48 data abstraction tools described in <ref> [22] </ref>. The basic approach is to achieve portable execution by analyzing and transforming the programs to increase "execution grain size." This compiler system uses sophisticated analysis to merges fine-grained tasks into larger units, increasing execution efficiency and matching it to the underlying machine.
Reference: [23] <author> Chien, A. A. </author> <title> A Cost and Performance Model for k-ary n-cube Wormhole Routers. </title> <booktitle> In Proceedings of Hot Interconnects Workshop (August 1993). </booktitle>
Reference-contexts: These results are published in <ref> [23, 3] </ref>, and have had major impact in the routing network community, allowing (and forcing) designers to weigh the benefits of adaptive routing directly against its cost. Chien's other work in this area addresses the use of routing networks, particularly if packetization is desirable [70].
Reference: [24] <author> Chien, A. A., and Dally, W. J. </author> <title> Concurrent Aggregates (CA). </title> <booktitle> In Proceedings of Second Symposium on Principles and Practice of Parallel Programming (March 1990), ACM. </booktitle> <pages> 67 </pages>
Reference-contexts: The J-Machine [29, 30] pioneered a number of techniques which are now being widely used in parallel architectures: message-driven execution, hardware support for message dispatch, and direct access instruction set access to the network at level of registers. Professor Chien's work on concurrent object-oriented programming systems for fine-grained machines <ref> [22, 24, 43] </ref> demonstrated the practicality of such approaches for fine-grained machines with thousands of processors. His work identified the critical need for multi-access data abstraction tools for modularizing parallel programs with constraining concurrency.
Reference: [25] <author> Chien, A. A., and Kim, J. H. </author> <title> Planar-Adaptive Routing: Low-Cost Adaptive Net--works for Multiprocessors. </title> <booktitle> In Proceedings of the International Symposium on Computer Architecture (May 1992), </booktitle> <pages> pp. 268-77. </pages>
Reference-contexts: Based on this work, he has developed adaptive routing algorithms which not only support fault tolerance and in-order delivery, but allow routing freedom to be traded directly for hardware simplicity <ref> [25, 69] </ref>.
Reference: [26] <author> Chow, E., Madan, H., Peterson, J., Grunwald, D. C., and Reed, D. A. </author> <title> Hyperswitch Network for the Hypercube Computer. </title> <journal> IEEE Tranactions on Computers (1990, </journal> <note> to appear). </note>
Reference-contexts: The the results of the latter aided the design of the JPL hyperswitch, a message router for the JPL Mark III hypercube <ref> [26] </ref>. At present, Professor Reed directs the Pablo project, a ARPA-funded effort to develop portable performance data capture and presentation tools for scalable parallel systems [101, 99].
Reference: [27] <author> Condry, M. W., Lim, S. B., and Lee, L. Y. </author> <title> "The Object-Oriented Advantage in Prototyping a Remote File System". </title> <booktitle> In Proceedings Second International Workshop on Object-Orientation in Operating Systems (Paris, </booktitle> <address> France, </address> <month> Sept. </month> <year> 1992), </year> <pages> pp. 190-199. </pages>
Reference-contexts: Early results from distributed shared virtual memory experiments convinced us to redesign the virtual memory and distributed shared virtual memory systems [111] to permit parallelism in the paging system. Early results from implementing a flexible caching strategy for distributed file systems have encouraged us to explore these issues further <ref> [27] </ref>. Using the Choices instrumentation system [72], we have traced the execution of parallel applications on Choices.
Reference: [28] <author> Cormen, T., Leiserson, C., and Rivest, R. </author> <title> Alogrithms. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1990. </year>
Reference-contexts: Our approach has similarities with other computer science research except that we examine complex systems issues. For example, classification of the performance of algorithms is an established research program in computational complexity <ref> [28] </ref>. However, the application of computational complexity to operating system performance is difficult because of the many interactions between the system components, the hardware, and the applications. Our research program therefore combines practical experimentation and measurement with analysis.
Reference: [29] <author> Dally, W. J., Chao, L., Chien, A., Hassoun, S., Horwat, W., Kaplan, J., Song, P., Totty, B., and Wills, S. </author> <title> Architecture of a Message-Driven Processor. </title> <booktitle> In Proceedings of the 14th ACM/IEEE Symposium on Computer Architecture (June 1987), IEEE, </booktitle> <pages> pp. 189-196. </pages>
Reference-contexts: Professor Chien's work on the Message-Driven Processor, a fine-grained message-passing machine, has contributed to the design of a full-scale prototype, the J-Machine, which has been installed at Argonne National Laboratories and the California Institute of Technology. The J-Machine <ref> [29, 30] </ref> pioneered a number of techniques which are now being widely used in parallel architectures: message-driven execution, hardware support for message dispatch, and direct access instruction set access to the network at level of registers.
Reference: [30] <author> Dally, W. J., Chien, A., Fiske, S., Horwat, W., Keen, J., Larivee, M., Lethin, R., Nuth, P., Wills, S., Carrick, P., and Fyler, G. </author> <title> The J-Machine: </title>
Reference-contexts: Professor Chien's work on the Message-Driven Processor, a fine-grained message-passing machine, has contributed to the design of a full-scale prototype, the J-Machine, which has been installed at Argonne National Laboratories and the California Institute of Technology. The J-Machine <ref> [29, 30] </ref> pioneered a number of techniques which are now being widely used in parallel architectures: message-driven execution, hardware support for message dispatch, and direct access instruction set access to the network at level of registers.
References-found: 30

