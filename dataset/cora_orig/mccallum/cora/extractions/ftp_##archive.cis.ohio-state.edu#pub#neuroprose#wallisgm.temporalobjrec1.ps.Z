URL: ftp://archive.cis.ohio-state.edu/pub/neuroprose/wallisgm.temporalobjrec1.ps.Z
Refering-URL: http://www.ph.tn.tudelft.nl/PRInfo/reports/msg00035.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: Email:  
Title: Optimal, Unsupervised Learning in Invariant Object Recognition  
Author: Guy Wallis Roland Baddeley 
Web: guy@mpik-tueb.mpg.de  
Address: biologische Kybernetik, Spemannstrae 38, 72076 Tubingen, Germany.  Oxford, South Parks Road, Oxford OX1 3UD, United Kingdom.  
Affiliation: Max-Planck Institute fur  Dept. Experimental Psychology, University of  
Abstract: A means for establishing transformation invariant representations of objects at the single cell level is proposed and analysed. The association of views of objects is achieved by using both the temporal order of the presentation of these views, as well as their spatial similarity. Assuming knowledge of the distribution of presentation times, an optimal linear learning rule is derived. If we assume that objects are viewed with presentation times that are approximately Jeffrey's distributed (P (t ) t 1 ), then the optimal learning rule is very well approximated using a simple exponential temporal trace. Simulations of a competitive network trained on a character recognition task are then used to highlight the success of this learning rule in relation to simple Hebbian learning, and to show that the theory can give quantitative predictions for the optimal parameters for such networks. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Bulthoff, H., & Edelman, S. </author> <year> 1992. </year> <title> Psychophysical support for a two-dimensional view interpolation theory of object recognition. </title> <booktitle> Pages 60-64 of: Proceedings 13 of the National Academy of Science, USA, </booktitle> <volume> vol. </volume> <pages> 92. </pages>
Reference: <author> Desimone, R. </author> <year> 1991. </year> <title> Face-selective cells in the temporal cortex of monkeys. </title> <journal> Journal of Cognitive Neuroscience, </journal> <volume> 3, </volume> <pages> 1-8. </pages>
Reference: <author> Edelman, S., & Weinshall, D. </author> <year> 1991. </year> <title> A self-organising multiple-view representation of 3D objects. </title> <journal> Biological Cybernetics, </journal> <volume> 64, </volume> <pages> 209-219. </pages>
Reference: <author> Foldiak, P. </author> <year> 1991. </year> <title> Learning invariance from transformation sequences. </title> <journal> Neural Computation, </journal> <volume> 3, </volume> <pages> 194-200. </pages>
Reference-contexts: The simple recursive form of the learning rule may also be important in that it lends itself to implementation locally within a cortical neuron (Wallis et al., 1993). The learning rule has a long history but was used most recently in invariant object recognition for orthogonal images <ref> (Foldiak, 1991) </ref> and non-orthogonal images (Wallis et al., 1993), and can be summarized as follows: w ij (t) :x j : j 2 = 1 f or each i th neuron and (t) = (1 )y i (t1) where x j is the j th input to the neuron, y i
Reference: <author> Jaynes, E.T. </author> <year> 1983. </year> <title> Papers on Probability, Statistics and Statistical Physics. </title> <address> Synthese library. </address> <publisher> Reidel, Dordrecht. </publisher>
Reference-contexts: Since presentation time is a scale parameter, it is reasonable to propose that the presentation times are Jeffrey's distributed (P (t ) / 1=t or equivalently that log presentation times are uniformly distributed, see <ref> (Jaynes, 1983) </ref>), which implies that objects tend to be seen for short periods but are occasionally seen for much longer periods.
Reference: <author> LeCun, Y., Boser, B., Denker, J.S., Henderson, D., Howard, R.E., Hubbard, W., & Jackel, L.D. </author> <year> 1989. </year> <title> Backpropagation applied to handwritten zip code recognition. </title> <journal> Neural Computation, </journal> <volume> 1, </volume> <pages> 541-551. </pages>
Reference: <author> Miyashita, Y. </author> <year> 1988. </year> <title> Neuronal correlate of visual associative long-term memory in the primate temporal cortex. </title> <journal> Nature, </journal> <volume> 335, </volume> <pages> 817-820. </pages>
Reference-contexts: Cells in this region exhibit invariance to combinations of the types of transformations discussed here (Rolls, 1992; Desimone, 1991; Tanaka et al., 1991). Work by <ref> (Miyashita, 1988) </ref> has illustrated that stimuli can be arbitrarily associated together by a single IT neuron distinct from many other spatially similar images. The key to the training he used was the association of these images, not in space, but in time.
Reference: <author> Poggio, T., & Edelman, S. </author> <year> 1990. </year> <title> A network that learns to recognize three-dimensional objects. </title> <journal> Nature, </journal> <volume> 343, </volume> <pages> 263-266. </pages>
Reference-contexts: A broadly tuned feature based system would be sufficient to perform recognition over small transformations <ref> (Poggio & Edelman, 1990) </ref>, and the form of the necessary receptive fields might be learnt via a simple competitive network with Hebbian learning. However, large shape transformations would either require separate pre-normalisation for size and translation, or separate feature detectors feeding into a final arbitration layer.
Reference: <author> Press, W.H. </author> <year> 1992. </year> <title> Numerical Recipes in C : The Art of Scientific Computing. </title> <publisher> Cambridge: Cambridge University Press. </publisher>
Reference: <author> Rolls, E.T. </author> <year> 1992. </year> <title> Neurophysiological mechanisms underlying face processing within and beyond the temporal cortical areas. </title> <journal> Philosophical Transactions of the Royal Society, London [B], </journal> <volume> 335, </volume> <pages> 11-21. </pages>
Reference: <author> Tanaka, K., Saito, H., Fukada, Y., & Moriya, M. </author> <year> 1991. </year> <title> Coding visual images of objects in the inferotemporal cortex of the macaque monkey. </title> <journal> Journal of Neurophysiology, </journal> <volume> 66, </volume> <pages> 170-189. </pages>
Reference: <author> Tarr, M.J., & Pinker, S. </author> <year> 1989. </year> <title> Mental rotation and orientation-dependence in shape recognition. </title> <journal> Cognitive Psycholgy, </journal> <volume> 21, </volume> <pages> 233-282. </pages>
Reference: <author> Wallis, G. </author> <year> 1995. </year> <title> Using spatio-temporal corrolations to learn invariant object recognition. </title> <note> To appear in Neural Networks. www: ftp://ftp.mpik-tueb.mpg.de/pub/guy/nn.ps.Z. </note>
Reference-contexts: Note that for = 0 the results correspond to simple Hebbian learning in the final layer. These results are clearly much worse than that those achieved with use of an optimal version of the trace rule. Further comparisons, with other architectures and other learning rules are described elsewhere <ref> (Wallis, 1995) </ref>. The exact calculations depend on the errors being approximateley random. from a random starting point to the point at which a steady state response had been achieved, for each of the three presentation paradigms.
Reference: <author> Wallis, G., & Rolls, E.T. </author> <year> 1995. </year> <title> A Model of Invariant Object Recognition in The Visual System. </title> <note> Submitted to Journal of Computational Neuroscience for Review. www: ftp://ftp.mpik-tueb.mpg.de/pub/guy/jcns7.ps.Z. </note>
Reference-contexts: Note that for = 0 the results correspond to simple Hebbian learning in the final layer. These results are clearly much worse than that those achieved with use of an optimal version of the trace rule. Further comparisons, with other architectures and other learning rules are described elsewhere <ref> (Wallis, 1995) </ref>. The exact calculations depend on the errors being approximateley random. from a random starting point to the point at which a steady state response had been achieved, for each of the three presentation paradigms.
Reference: <author> Wallis, G., Rolls, E.T., & Foldiak, P. </author> <year> 1993. </year> <title> Learning invariant responses to the natural transformations of objects. </title> <booktitle> Pages 1087-1090 of: International Joint Conference on Neural Networks, </booktitle> <volume> vol. 2. 14 Wiener, </volume> <editor> N. </editor> <year> 1949. </year> <title> Extrapolation, Interpolation, and Smoothing of Stationary Time Series : with Engineering Applications. </title> <address> New York: </address> <publisher> John Wiley & Sons. </publisher> <pages> 15 </pages>
Reference-contexts: The simple recursive form of the learning rule may also be important in that it lends itself to implementation locally within a cortical neuron <ref> (Wallis et al., 1993) </ref>. The learning rule has a long history but was used most recently in invariant object recognition for orthogonal images (Foldiak, 1991) and non-orthogonal images (Wallis et al., 1993), and can be summarized as follows: w ij (t) :x j : j 2 = 1 f or each <p> recursive form of the learning rule may also be important in that it lends itself to implementation locally within a cortical neuron <ref> (Wallis et al., 1993) </ref>. The learning rule has a long history but was used most recently in invariant object recognition for orthogonal images (Foldiak, 1991) and non-orthogonal images (Wallis et al., 1993), and can be summarized as follows: w ij (t) :x j : j 2 = 1 f or each i th neuron and (t) = (1 )y i (t1) where x j is the j th input to the neuron, y i is the output of the
References-found: 15

