URL: ftp://coast.cs.purdue.edu/pub/doc/genetic_algorithms/GA/GA-Alife.ps.Z
Refering-URL: http://www.cs.purdue.edu/coast/archive/data/categ20.html
Root-URL: http://www.cs.purdue.edu
Email: mm@santafe.edu  forrest@cs.unm.edu  
Title: Genetic Algorithms and Artificial Life  
Author: Melanie Mitchell Stephanie Forrest 
Note: Working Paper 93-11-072 To appear in Artificial Life  
Address: 1660 Old Pecos Tr., Suite A Santa Fe, N.M. 87501  Albuquerque, N.M. 87131-1386  
Affiliation: Santa Fe Institute  Dept. of Computer Science University of New Mexico  Santa Fe Institute  
Abstract: Genetic algorithms are computational models of evolution that play a central role in many artificial-life models. We review the history and current scope of research on genetic algorithms in artificial life, using illustrative examples in which the genetic algorithm is used to study how learning and evolution interact, and to model ecosystems, immune system, cognitive systems, and social systems. We also outline a number of open questions and future directions for genetic algorithms in artificial-life research.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. H. Ackley and M. L. Littman. </author> <title> Interactions between learning and evolution. </title> <editor> In C. G. Langton, C. Taylor, J. D. Farmer, and S. Rasmussen, editors, </editor> <booktitle> Artificial Life II, </booktitle> <pages> pages 487-507, </pages> <address> Reading, MA, 1992. </address> <publisher> Addison-Wesley. </publisher>
Reference-contexts: GAs have been used to study questions in population genetics, such as "under what conditions will a gene for recombination be evolutionarily viable?" (e.g., [15, 33, 69, 88]). * Interactions between evolution and learning: GAs have been used to study how individual learning and species evolution affect one another (e.g., <ref> [1, 2, 12, 35, 49, 77, 71, 79, 96, 97] </ref>). * Models of social systems: GAs have been used to study evolutionary aspects of social systems, such as the evolution of cooperation [6, 7, 68, 73, 74], the evolution of communication (e.g., [67, 98]), and trail-following behavior in ants (e.g., [26, <p> Computer simulations such as theirs can help us to understand and to measure such tradeoffs. More detailed analyses of this model were performed by Belew [12] and Harvey [45]. 3.3 Evolutionary Reinforcement Learning (ERL) A second computational demonstration of the Baldwin effect was given by Ackley and Littman <ref> [1] </ref>. In their Evolutionary Reinforcement Learning (ERC) model, adaptive individuals ("agents") move randomly on a two-dimensional lattice, encountering food, predators, hiding places, and other types of entities. Each agent's state includes the entities in its visual range, the level of its internal energy store, and other parameters. <p> Ackley and Littman observed many interesting phenomena in their experiments with this model. The main emergent phenomena they describe are a version of the Baldwin effect and an effect they call "shielding." Here we will describe the former; see <ref> [1] </ref> for details on other phenomena.
Reference: [2] <author> D. H. Ackley and M. L. Littman. </author> <title> A case for Lamarckian evolution. </title> <editor> In C. G. Langton, editor, </editor> <booktitle> Artificial Life III, </booktitle> <address> Reading, MA, 1993. </address> <publisher> Addison-Wesley. </publisher>
Reference-contexts: GAs have been used to study questions in population genetics, such as "under what conditions will a gene for recombination be evolutionarily viable?" (e.g., [15, 33, 69, 88]). * Interactions between evolution and learning: GAs have been used to study how individual learning and species evolution affect one another (e.g., <ref> [1, 2, 12, 35, 49, 77, 71, 79, 96, 97] </ref>). * Models of social systems: GAs have been used to study evolutionary aspects of social systems, such as the evolution of cooperation [6, 7, 68, 73, 74], the evolution of communication (e.g., [67, 98]), and trail-following behavior in ants (e.g., [26, <p> A survey of this work is given in [89]. Other researchers are investigating the benefits of adding "Lamarckian" learning to the GA, and have found in some cases that it leads to significant improvements in GA performance <ref> [2, 40] </ref>. 4.
Reference: [3] <author> J. Andreoni and J. H. Miller. </author> <title> Auctions with adaptive artificial agents. </title> <type> Technical Report 91-01-004, </type> <institution> Santa Fe Institute, </institution> <address> Santa Fe, New Mexico 87501, </address> <year> 1991. </year>
Reference-contexts: For an overview of GAs in machine learning, see [59, 60]. * Economic models: GAs have been used by to model processes of innovation, the development of bidding strategies, and the emergence of economic markets (e.g., <ref> [3, 54, 4] </ref>). * Immune system models: GAs have been used to model various aspects of the natural immune system [16, 36, 47], including somatic mutation during an individual's lifetime and the discovery of multi-gene families during evolutionary time. * Ecological models: GAs have been used to model ecological phenomena such
Reference: [4] <author> J. Andreoni and J. H. Miller. </author> <title> Auction experiments in artificial worlds. </title> <publisher> Cuadernos, In press. </publisher> <pages> 19 </pages>
Reference-contexts: For an overview of GAs in machine learning, see [59, 60]. * Economic models: GAs have been used by to model processes of innovation, the development of bidding strategies, and the emergence of economic markets (e.g., <ref> [3, 54, 4] </ref>). * Immune system models: GAs have been used to model various aspects of the natural immune system [16, 36, 47], including somatic mutation during an individual's lifetime and the discovery of multi-gene families during evolutionary time. * Ecological models: GAs have been used to model ecological phenomena such
Reference: [5] <author> R. Axelrod. </author> <title> The evolution of cooperation. </title> <publisher> Basic Books, </publisher> <address> New York, N.Y., </address> <year> 1984. </year>
Reference-contexts: to evolve strategies for interaction in the context of the Prisoner's Dilemma. 14 The Prisoner's Dilemma (PD) is a simple two-person game that has been studied exten-sively in game theory, economics, and political science because it can be seen as an idealized model for real-world phenomena such as arms races <ref> [5] </ref>. On a given turn, each player independently decides whether to "cooperate" or "defect." The game is summarized by the payoff matrix shown in Table 1. If both players cooperate, they each get three points. <p> How can reciprocal cooperation be induced? This question takes on special significance when the notions of "cooperating" and "defecting" correspond to actions in the real world, such as a real-world arms race. Axelrod has studied the PD and related games extensively <ref> [5] </ref>. Early work, including the results of two tournaments that played pairs of human-designed strategies against each other, suggested that the best strategy for playing the iterated PD is one of the simplest: TIT FOR TAT.
Reference: [6] <author> R. Axelrod. </author> <title> An evolutionary approach to norms. </title> <journal> The American Political Science Review, </journal> <volume> 80, </volume> <year> 1986. </year>
Reference-contexts: and learning: GAs have been used to study how individual learning and species evolution affect one another (e.g., [1, 2, 12, 35, 49, 77, 71, 79, 96, 97]). * Models of social systems: GAs have been used to study evolutionary aspects of social systems, such as the evolution of cooperation <ref> [6, 7, 68, 73, 74] </ref>, the evolution of communication (e.g., [67, 98]), and trail-following behavior in ants (e.g., [26, 63]). This list is by no means exhaustive, but it gives a flavor of the kinds of things for which GAs have been used, both for problem-solving and for modeling.
Reference: [7] <author> R. Axelrod. </author> <title> The evolution of strategies in the iterated Prisoner's Dilemma. </title> <editor> In L. D. Davis, editor, </editor> <title> Genetic Algorithms and Simulated Annealing, </title> <booktitle> Research Notes in Artificial Intelligence, </booktitle> <address> Los Altos, CA, 1987. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: and learning: GAs have been used to study how individual learning and species evolution affect one another (e.g., [1, 2, 12, 35, 49, 77, 71, 79, 96, 97]). * Models of social systems: GAs have been used to study evolutionary aspects of social systems, such as the evolution of cooperation <ref> [6, 7, 68, 73, 74] </ref>, the evolution of communication (e.g., [67, 98]), and trail-following behavior in ants (e.g., [26, 63]). This list is by no means exhaustive, but it gives a flavor of the kinds of things for which GAs have been used, both for problem-solving and for modeling. <p> That is, it offers cooperation and then reciprocates it, but if the other player defects, TIT FOR TAT will retaliate with a defection. Axelrod performed a series of experiments to see if a GA could evolve strategies to play this game successfully <ref> [7] </ref>. Strategies were encoded as look-up tables, with each entry (C or D) being the action to be taken given the outcomes of three previous turns.
Reference: [8] <author> R. Back, F. Hoffmeister, and H.-P. Schwefel. </author> <title> A survey of evolution strategies. </title> <editor> In R. K. Belew and L. B. Booker, editors, </editor> <booktitle> Proceedings of the Fourth International Conference on Genetic Algorithms, </booktitle> <pages> pages 2-9, </pages> <address> San Mateo, CA, 1991. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: This idea was further developed by Schwefel [91], and the field of evolution strategies has remained an active area of research, developing in parallel to GA research, until recently when the two communities have begun to interact. For a review of evolution strategies, see <ref> [8] </ref>. Also in the 1960s Fogel, Owens, and Walsh developed "evolutionary programming" [34]. Candidate solutions to given tasks are represented as finite-state machines, and the evolutionary operators are selection and mutation. Evolutionary programming also remains an area of active research.
Reference: [9] <author> J. M. Baldwin. </author> <title> A new factor in evolution. </title> <journal> American Naturalist, </journal> <volume> 30 </volume> <pages> 441-451, 1896. </pages>
Reference-contexts: However, some evolutionary biologists (e.g., [92]) have discussed an indirect effect of learning 4 on evolution, inspired by ideas about evolution due to Baldwin <ref> [9] </ref>. The idea behind this so-called "Baldwin effect" is that if learning helps survival, then organisms best able to learn will have the most offspring, thus increasing the frequency of the genes responsible for learning.
Reference: [10] <author> M. A. Bedau and N. H. Packard. </author> <title> Measurement of evolutionary activity, teleology, and life. </title> <editor> In C. G. Langton, C. Taylor, J. D. Farmer, and S. Rasmussen, editors, </editor> <booktitle> Artificial Life II, </booktitle> <pages> pages 431-461, </pages> <address> Reading, MA, 1992. </address> <publisher> Addison-Wesley. </publisher>
Reference-contexts: been very little mathematical analysis of artificial-life simulations in which fitness is endogenous. 4.2 Measuring evolutionary activity How can we decide if an observed system is evolving? And how can we measure the rate of evolution in such a system? Bedau and Packard developed an artificial-life model, called "Strategic Bugs" <ref> [10] </ref>, to address these questions. Their model is simpler than both ERL and Echo. The Strategic Bugs world is a two-dimensional lattice, containing only adaptive agents ("bugs") and food. The food supply is renewable; it is refreshed periodically and distributed randomly across the lattice. <p> The only time a counter is initialized to 0 is when a new gene is created through mutation. Thus a gene's counter value reflects the usage of that gene over many generations. When a bug dies, its genes (and their counters) die with it. In <ref> [10] </ref>, Bedau and Packard plot, for each time step during a run, histograms of the number of genes in the population displaying a given usage value (i.e., a given counter value).
Reference: [11] <author> M. A. Bedau, F. Ronneburg, and M. Zwick. </author> <title> Dynamics of diversity in an evolving population. </title> <editor> In R. Manner and B. Manderick, editors, </editor> <booktitle> Parallel Problem Solving from Nature 2, </booktitle> <pages> pages 95-104, </pages> <address> Amsterdam, 1992. </address> <publisher> North Holland. </publisher>
Reference-contexts: Bedau, Ronneburg, and Zwick have extended this work to propose several measures of population diversity and to measure them and characterize their dynamics in the context of the Strategic Bugs model <ref> [11] </ref>. The important contribution of Bedau and Packard's paper is the attempt to define a 10 macroscopic quantity such as evolutionary activity.
Reference: [12] <author> R. K. Belew. </author> <title> Evolution, learning, and culture: Computational metaphors for adaptive algorithms. </title> <journal> Complex Systems, </journal> <volume> 4 </volume> <pages> 11-49, </pages> <year> 1990. </year>
Reference-contexts: GAs have been used to study questions in population genetics, such as "under what conditions will a gene for recombination be evolutionarily viable?" (e.g., [15, 33, 69, 88]). * Interactions between evolution and learning: GAs have been used to study how individual learning and species evolution affect one another (e.g., <ref> [1, 2, 12, 35, 49, 77, 71, 79, 96, 97] </ref>). * Models of social systems: GAs have been used to study evolutionary aspects of social systems, such as the evolution of cooperation [6, 7, 68, 73, 74], the evolution of communication (e.g., [67, 98]), and trail-following behavior in ants (e.g., [26, <p> Such tradeoffs occur in evolution and can be seen even in Hinton and Nowlan's simple model. Computer simulations such as theirs can help us to understand and to measure such tradeoffs. More detailed analyses of this model were performed by Belew <ref> [12] </ref> and Harvey [45]. 3.3 Evolutionary Reinforcement Learning (ERL) A second computational demonstration of the Baldwin effect was given by Ackley and Littman [1]. In their Evolutionary Reinforcement Learning (ERC) model, adaptive individuals ("agents") move randomly on a two-dimensional lattice, encountering food, predators, hiding places, and other types of entities.
Reference: [13] <author> R. K. Belew. </author> <title> Interposing an ontogenic model between genetic algorithms and neural networks. </title> <editor> In J. Cowan, editor, </editor> <booktitle> Advances in Neural Information Processing (NIPS5), </booktitle> <address> San Mateo, CA, 1993. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: The grammar is then used to produce a legal object in the language it specifies (the development step), and this string (the phenotype) is then evaluated by the fitness function. Examples of this exploratory work include <ref> [13, 43, 62, 102] </ref>. Related to the question of representation is the choice of genetic operators for introducing variation into a population. One reason that binary linearly ordered representations are so popular is that the standard mutation and crossover operators can be applied in a problem-independent way.
Reference: [14] <author> R. K. Belew, J. McInerney, and N. N. Schraudolph. </author> <title> Evolving networks: Using the genetic algorithm with connectionist learning. </title> <editor> In C. G. Langton, C. Taylor, J. D. Farmer, and S. Ras-mussen, editors, </editor> <booktitle> Artificial Life II, Santa Fe Institute Studies in the Sciences of Complexity, </booktitle> <pages> pages 511-547, </pages> <address> Reading, MA, 1992. </address> <publisher> Addison-Wesley. </publisher>
Reference-contexts: GAs have also been used to design neural networks (e.g., <ref> [14, 24, 43, 44, 62, 72, 76, 89, 99] </ref>), to evolve rules for learning classifier systems (e.g., [50, 53]) or symbolic production systems (e.g., [42]), and to design and control robots (e.g., [28, 30, 46]).
Reference: [15] <author> A. Bergman and M. W. Feldman. </author> <title> Recombination dynamics and the fitness landscape. </title> <journal> Physica D, </journal> <volume> 56 </volume> <pages> 57-67, </pages> <year> 1992. </year>
Reference-contexts: host-parasite co-evolution, symbiosis, and resource flow in ecologies (e.g., [10, 11, 25, 27, 48, 52, 57, 65, 66, 78, 82, 83, 95]). * Population genetics models: GAs have been used to study questions in population genetics, such as "under what conditions will a gene for recombination be evolutionarily viable?" (e.g., <ref> [15, 33, 69, 88] </ref>). * Interactions between evolution and learning: GAs have been used to study how individual learning and species evolution affect one another (e.g., [1, 2, 12, 35, 49, 77, 71, 79, 96, 97]). * Models of social systems: GAs have been used to study evolutionary aspects of social
Reference: [16] <author> H. Bersini and F. J. Varela. </author> <title> The immune recruitment mechanism: A selective evolutionary strategy. </title> <editor> In R. K. Belew and L. B. Booker, editors, </editor> <booktitle> Proceedings of the Fourth International Conference on Genetic Algorithms, </booktitle> <pages> pages 520-526, </pages> <address> San Mateo, CA, 1991. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: machine learning, see [59, 60]. * Economic models: GAs have been used by to model processes of innovation, the development of bidding strategies, and the emergence of economic markets (e.g., [3, 54, 4]). * Immune system models: GAs have been used to model various aspects of the natural immune system <ref> [16, 36, 47] </ref>, including somatic mutation during an individual's lifetime and the discovery of multi-gene families during evolutionary time. * Ecological models: GAs have been used to model ecological phenomena such as biological arms races, host-parasite co-evolution, symbiosis, and resource flow in ecologies (e.g., [10, 11, 25, 27, 48, 52, 57, <p> Immune systems Immune systems are adaptive systems in which learning takes place by evolutionary mechanisms similar to biological evolution. Immune systems have been studied by the artificial-life community both because of their intrinsic scientific interest and because of potential applications of ideas from immunology to computational problems (e.g., <ref> [16] </ref>). The immune system is capable of recognizing virtually any foreign cell or molecule. To do this, it must distinguish the body's own cells and molecules which are created and circulated internally (estimated to consist of on the order of 10 5 different proteins) from those that are foreign.
Reference: [17] <author> W. W. Bledsoe. </author> <title> The use of biological concepts in the analytical study of systems, November 1961. </title> <booktitle> Paper presented at the ORSA-TIMS National Meeting, </booktitle> <address> San Francisco, CA. </address>
Reference-contexts: Overview of Genetic Algorithms In the 1950s and 1960s several computer scientists independently studied evolutionary systems with the idea that evolution could be used as an optimization tool for engineering problems. In Goldberg's short history of computational evolution ([38], Chapter 4), the names of Box [20], Friedman [37], Bledsoe <ref> [17] </ref>, and Bremermann [21] are associated with a variety of work in the late 1950s and early 1960s, some of which presages the later development of GAs.
Reference: [18] <author> L. Booker. </author> <title> Instinct as an inductive bias for learning behavioral sequences. </title> <editor> In J.A. Meyer and S. W. Wilson, editors, </editor> <booktitle> From animals to animats: Proceedings of the first international conference on simulation of adaptive behavior, </booktitle> <pages> pages 230-237, </pages> <address> Cambridge, MA, 1991. </address> <publisher> MIT Press. </publisher>
Reference-contexts: In classifier systems, default hierarchies are represented using clusters of rules of different specificities. In [53], the concept of a "quasi-morphism" is introduced to describe this modeling process formally. There have been several modeling efforts based on learning classifier systems, including <ref> [18, 19, 31, 85, 86, 100, 101] </ref>. Each of these is a variation on the standard classifier system as described above, but each of the variations captures the major principles of classifier systems.
Reference: [19] <author> L. B. Booker. </author> <title> Intelligent Behavior as an Adaptation to the Task Environment. </title> <type> PhD thesis, </type> <institution> The University of Michigan, </institution> <address> Ann Arbor, MI, </address> <year> 1982. </year> <month> 20 </month>
Reference-contexts: In classifier systems, default hierarchies are represented using clusters of rules of different specificities. In [53], the concept of a "quasi-morphism" is introduced to describe this modeling process formally. There have been several modeling efforts based on learning classifier systems, including <ref> [18, 19, 31, 85, 86, 100, 101] </ref>. Each of these is a variation on the standard classifier system as described above, but each of the variations captures the major principles of classifier systems.
Reference: [20] <author> G. E. P. </author> <title> Box. Evolutionary operation: A method for increasing industrial productivity. </title> <journal> Jour--nal of the Royal Statistical Society C, </journal> <volume> 6(2) </volume> <pages> 81-101, </pages> <year> 1957. </year>
Reference-contexts: Overview of Genetic Algorithms In the 1950s and 1960s several computer scientists independently studied evolutionary systems with the idea that evolution could be used as an optimization tool for engineering problems. In Goldberg's short history of computational evolution ([38], Chapter 4), the names of Box <ref> [20] </ref>, Friedman [37], Bledsoe [17], and Bremermann [21] are associated with a variety of work in the late 1950s and early 1960s, some of which presages the later development of GAs.
Reference: [21] <author> H. J. Bremermann. </author> <title> Optimization through evolution and recombination. </title> <editor> In M. C. Yovits, G. T. Jacobi, and G. D. Goldstein, editors, </editor> <booktitle> Self-organizing systems, </booktitle> <pages> pages 93-106, </pages> <address> Washing-ton, D.C., 1962. </address> <publisher> Spartan Books. </publisher>
Reference-contexts: In Goldberg's short history of computational evolution ([38], Chapter 4), the names of Box [20], Friedman [37], Bledsoe [17], and Bremermann <ref> [21] </ref> are associated with a variety of work in the late 1950s and early 1960s, some of which presages the later development of GAs.
Reference: [22] <author> L. W. Buss. </author> <title> The Evolution of Individuality. </title> <publisher> Princeton University Press, </publisher> <address> Princeton, N.J., </address> <year> 1987. </year>
Reference-contexts: Buss, among others, has pointed out that the principle of evolution by natural selection is applicable at many levels besides that of the individual, and in particular, that natural selection controls development (e.g., embryology) and interacts with selection at the level of the individual <ref> [22] </ref>. Related to this point, and to the observation that evolution and learning can interact, are several recent studies of GAs which include a "development" cycle which translates the genotype through a series of steps into the phenotype.
Reference: [23] <author> F. Celada and P. E. Seiden. </author> <title> A computer model of cellular interactions in the immune system. </title> <journal> Immunology Today, </journal> <volume> 13(2) </volume> <pages> 56-62, </pages> <year> 1992. </year>
Reference-contexts: Different approaches to modeling the immune system have included differential-equation-based models (e.g., see [81, 80]), cellular-automata models <ref> [23] </ref>, classifier systems [32], and GAs [36].
Reference: [24] <author> D. J. Chalmers. </author> <title> The evolution of learning: An experiment in genetic connectionism. </title> <editor> In D. S. Touretzky et al., editor, </editor> <booktitle> Proceedings of the 1990 Connectionist Models Summer School, </booktitle> <address> San Mateo, CA, 1990. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: GAs have also been used to design neural networks (e.g., <ref> [14, 24, 43, 44, 62, 72, 76, 89, 99] </ref>), to evolve rules for learning classifier systems (e.g., [50, 53]) or symbolic production systems (e.g., [42]), and to design and control robots (e.g., [28, 30, 46]).
Reference: [25] <author> R. J. Collins and D. R. Jefferson. </author> <title> Selection in massively parallel genetic algorithms. </title> <editor> In R. K. Belew and L. B. Booker, editors, </editor> <booktitle> Proceedings of the Fourth International Conference on Genetic Algorithms, </booktitle> <pages> pages 249-256, </pages> <address> San Mateo, CA, 1991. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: [26] <author> R. J. Collins and D. R. Jefferson. AntFarm: </author> <title> Towards simulated evolution. </title> <editor> In C. G. Langton, C. Taylor, J. D. Farmer, and S. Rasmussen, editors, </editor> <booktitle> Artificial Life II, </booktitle> <pages> pages 579-601, </pages> <address> Reading, MA, 1992. </address> <publisher> Addison-Wesley. </publisher>
Reference-contexts: [1, 2, 12, 35, 49, 77, 71, 79, 96, 97]). * Models of social systems: GAs have been used to study evolutionary aspects of social systems, such as the evolution of cooperation [6, 7, 68, 73, 74], the evolution of communication (e.g., [67, 98]), and trail-following behavior in ants (e.g., <ref> [26, 63] </ref>). This list is by no means exhaustive, but it gives a flavor of the kinds of things for which GAs have been used, both for problem-solving and for modeling. The range of GA applications continues to increase.
Reference: [27] <author> R. J. Collins and D. R. Jefferson. </author> <title> The evolution of sexual selection and female choice. </title> <editor> In F. J. Varela and P. Bourgine, editors, </editor> <booktitle> Toward a Practice of Autonomous Systems: Proceedings of the First European Conference on Artificial Life, </booktitle> <pages> pages 327-336, </pages> <address> Cambridge, MA, 1992. </address> <publisher> MIT Press/Bradford Books. </publisher>
Reference: [28] <author> Y. Davidor. </author> <booktitle> Genetic algorithms and robotics. Robotics and Automated Systems. World Scientific, </booktitle> <address> Singapore, </address> <year> 1991. </year>
Reference-contexts: GAs have also been used to design neural networks (e.g., [14, 24, 43, 44, 62, 72, 76, 89, 99]), to evolve rules for learning classifier systems (e.g., [50, 53]) or symbolic production systems (e.g., [42]), and to design and control robots (e.g., <ref> [28, 30, 46] </ref>).
Reference: [29] <editor> L. D. Davis, editor. </editor> <booktitle> The Handbook of Genetic Algorithms. </booktitle> <publisher> Van Nostrand Reinhold, </publisher> <year> 1991. </year>
Reference-contexts: It should be noted that researchers interested in engineering applications have long advocated the use of simple "higher-cardinality alphabets," including for example, real numbers as alleles <ref> [29] </ref>. Given the fact that GA performance is heavily dependent on the representation chosen, this lack of diversity is surprising. More extended mappings between the genotypic representation and the phenotype are another promising direction.
Reference: [30] <author> M. Dorigo and E. Sirtori. </author> <title> Alecsys: A parallel laboratory for learning classifier systems. </title> <editor> In R. K. Belew and L. B. Booker, editors, </editor> <booktitle> Proceedings of the Fourth International Conference on Genetic Algorithms, </booktitle> <pages> pages 296-302, </pages> <address> San Mateo, CA, 1991. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: GAs have also been used to design neural networks (e.g., [14, 24, 43, 44, 62, 72, 76, 89, 99]), to evolve rules for learning classifier systems (e.g., [50, 53]) or symbolic production systems (e.g., [42]), and to design and control robots (e.g., <ref> [28, 30, 46] </ref>).
Reference: [31] <author> R. Dumeur. </author> <title> Extended classifiers for simulation of adaptive behavior. </title> <editor> In J.A. Meyer and S. W. Wilson, editors, </editor> <booktitle> From animals to animats: Proceedings of the first international conference on simulation of adaptive behavior, </booktitle> <pages> pages 58-65, </pages> <address> Cambridge, MA, 1991. </address> <publisher> MIT Press. </publisher>
Reference-contexts: In classifier systems, default hierarchies are represented using clusters of rules of different specificities. In [53], the concept of a "quasi-morphism" is introduced to describe this modeling process formally. There have been several modeling efforts based on learning classifier systems, including <ref> [18, 19, 31, 85, 86, 100, 101] </ref>. Each of these is a variation on the standard classifier system as described above, but each of the variations captures the major principles of classifier systems.
Reference: [32] <author> J. D. Farmer, N. H. Packard, and A. S. Perelson. </author> <title> The immune system, adaptation, </title> <journal> and machine learning. Physica D, </journal> <volume> 22 </volume> <pages> 187-204, </pages> <year> 1986. </year>
Reference-contexts: Different approaches to modeling the immune system have included differential-equation-based models (e.g., see [81, 80]), cellular-automata models [23], classifier systems <ref> [32] </ref>, and GAs [36].
Reference: [33] <author> D. B. Fogel and J. W. Atmar. </author> <title> Comparing genetic operators with Gaussian mutations in simulated evolutionary processes using linear search. </title> <journal> Biological Cybernetics, </journal> <volume> 63 </volume> <pages> 111-114, </pages> <year> 1990. </year>
Reference-contexts: host-parasite co-evolution, symbiosis, and resource flow in ecologies (e.g., [10, 11, 25, 27, 48, 52, 57, 65, 66, 78, 82, 83, 95]). * Population genetics models: GAs have been used to study questions in population genetics, such as "under what conditions will a gene for recombination be evolutionarily viable?" (e.g., <ref> [15, 33, 69, 88] </ref>). * Interactions between evolution and learning: GAs have been used to study how individual learning and species evolution affect one another (e.g., [1, 2, 12, 35, 49, 77, 71, 79, 96, 97]). * Models of social systems: GAs have been used to study evolutionary aspects of social
Reference: [34] <author> L. J. Fogel, A. J. Owens, and M. J. Walsh. </author> <title> Artificial Intelligence Through Simulated Evolution. </title> <publisher> John Wiley, </publisher> <address> New York, </address> <year> 1966. </year>
Reference-contexts: For a review of evolution strategies, see [8]. Also in the 1960s Fogel, Owens, and Walsh developed "evolutionary programming" <ref> [34] </ref>. Candidate solutions to given tasks are represented as finite-state machines, and the evolutionary operators are selection and mutation. Evolutionary programming also remains an area of active research. For a more detailed description of the work of Fogel et al., see [38], Chapter 4.
Reference: [35] <author> J. F. Fontanari and R. Meir. </author> <title> The effect of learning on the evolution of asexual populations. </title> <journal> Complex Systems, </journal> <volume> 4 </volume> <pages> 401-414, </pages> <year> 1990. </year> <month> 21 </month>
Reference-contexts: GAs have been used to study questions in population genetics, such as "under what conditions will a gene for recombination be evolutionarily viable?" (e.g., [15, 33, 69, 88]). * Interactions between evolution and learning: GAs have been used to study how individual learning and species evolution affect one another (e.g., <ref> [1, 2, 12, 35, 49, 77, 71, 79, 96, 97] </ref>). * Models of social systems: GAs have been used to study evolutionary aspects of social systems, such as the evolution of cooperation [6, 7, 68, 73, 74], the evolution of communication (e.g., [67, 98]), and trail-following behavior in ants (e.g., [26,
Reference: [36] <author> S. Forrest, B. Javornik, R. Smith, and A. Perelson. </author> <title> Using genetic algorithms to explore pattern recognition in the immune system. Evolutionary Computation, </title> <publisher> in press. </publisher>
Reference-contexts: machine learning, see [59, 60]. * Economic models: GAs have been used by to model processes of innovation, the development of bidding strategies, and the emergence of economic markets (e.g., [3, 54, 4]). * Immune system models: GAs have been used to model various aspects of the natural immune system <ref> [16, 36, 47] </ref>, including somatic mutation during an individual's lifetime and the discovery of multi-gene families during evolutionary time. * Ecological models: GAs have been used to model ecological phenomena such as biological arms races, host-parasite co-evolution, symbiosis, and resource flow in ecologies (e.g., [10, 11, 25, 27, 48, 52, 57, <p> Different approaches to modeling the immune system have included differential-equation-based models (e.g., see [81, 80]), cellular-automata models [23], classifier systems [32], and GAs <ref> [36] </ref>. <p> The GA models of Forrest et al. <ref> [36] </ref> are based on a universe in which antigens (foreign material) and antibodies (the cells that perform the recognition) are represented by binary strings. <p> The binary immune system has been used to study several different aspects of the immune system, including (1) its ability to detect common patterns (schemas) in the noisy environment of randomly presented antigens <ref> [36] </ref>; (2) its ability to discover and maintain coverage of the diverse antigen population [93]; and (3) its ability to learn effectively, even when not all antibodies are expressed and not all antigens are presented [47].
Reference: [37] <author> G. J. Friedman. </author> <title> Digital simulation of an evolutionary process. </title> <journal> General Systems Yearbook, </journal> <volume> 4 </volume> <pages> 171-184, </pages> <year> 1959. </year>
Reference-contexts: Overview of Genetic Algorithms In the 1950s and 1960s several computer scientists independently studied evolutionary systems with the idea that evolution could be used as an optimization tool for engineering problems. In Goldberg's short history of computational evolution ([38], Chapter 4), the names of Box [20], Friedman <ref> [37] </ref>, Bledsoe [17], and Bremermann [21] are associated with a variety of work in the late 1950s and early 1960s, some of which presages the later development of GAs.
Reference: [38] <author> D. E. Goldberg. </author> <title> Genetic Algorithms in Search, Optimization, and Machine Learning. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1989. </year>
Reference-contexts: Candidate solutions to given tasks are represented as finite-state machines, and the evolutionary operators are selection and mutation. Evolutionary programming also remains an area of active research. For a more detailed description of the work of Fogel et al., see <ref> [38] </ref>, Chapter 4. GAs as they are known today were first described by John Holland in the 1960s and further developed by Holland and his students and colleagues at the University of Michigan in the 1960s and 1970s. <p> For implementation details such as these, see <ref> [38] </ref>. Introducing a population-based algorithm with crossover and inversion was a major innovation. Just as significant is the theoretical foundation Holland developed based on the notion of "schemata" [51, 38]. <p> For implementation details such as these, see [38]. Introducing a population-based algorithm with crossover and inversion was a major innovation. Just as significant is the theoretical foundation Holland developed based on the notion of "schemata" <ref> [51, 38] </ref>. This theoretical foundation has been the basis of almost all subsequent theoretical work on GAs, although recently the usefulness of this notion has been debated (see, e.g., [41]). Holland's work was the first attempt to put computational evolution on a firm theoretical footing. <p> Although it is relatively easy to implement endogenous or co-evolutionary fitness strategies, there is virtually no theory describing the behavior of GAs under these circumstances. In particular, a theory about how building blocks are processed (cf. <ref> [51, 38] </ref>) under these circumstances would be helpful. Perhaps the most obvious area for extending the GA is to the study of evolution itself.
Reference: [39] <author> D. E. Goldberg, B. Korb, and K. Deb. </author> <title> Messy genetic algorithms: Motivation, analysis, and first results. </title> <journal> Complex Systems, </journal> <volume> 3 </volume> <pages> 493-530, </pages> <year> 1990. </year>
Reference-contexts: For this reason, the "representation problem" is especially important for GAs. Although the representation problem has been acknowledged for many years, there have been surprisingly few innovative representations, the recent work on genetic programming [64] and messy GAs <ref> [39] </ref> being notable exceptions. In genetic programming, individuals are represented as S-expressions|small programs written in a subset of Lisp. Although S-expressions can be written as linear strings, they are naturally viewed as trees, and the genetic operators operate on trees. Crossover for example, swaps subtrees between S-expressions. <p> In genetic programming, individuals are represented as S-expressions|small programs written in a subset of Lisp. Although S-expressions can be written as linear strings, they are naturally viewed as trees, and the genetic operators operate on trees. Crossover for example, swaps subtrees between S-expressions. Messy GAs were developed by Goldberg <ref> [39] </ref> to allow variable-length strings which can be either over- or under-specified with respect to the problem being solved. This allows the GA to manipulate short strings early in a run, and over time, to combine short well-tested building blocks into longer, more complex strings.
Reference: [40] <author> J. J. Grefenstette. </author> <title> Lamarckian learning in multi-agent environments. </title> <editor> In R. K. Belew and L. B. Booker, editors, </editor> <booktitle> Proceedings of the Fourth International Conference on Genetic Algorithms, </booktitle> <pages> pages 303-310, </pages> <address> San Mateo, CA, 1991. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: A survey of this work is given in [89]. Other researchers are investigating the benefits of adding "Lamarckian" learning to the GA, and have found in some cases that it leads to significant improvements in GA performance <ref> [2, 40] </ref>. 4.
Reference: [41] <author> J. J. Grefenstette and J. E. Baker. </author> <title> How genetic algorithms work: A critical look at implicit parallelism. </title> <editor> In J. D. Schaffer, editor, </editor> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <address> San Mateo, CA, 1989. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Just as significant is the theoretical foundation Holland developed based on the notion of "schemata" [51, 38]. This theoretical foundation has been the basis of almost all subsequent theoretical work on GAs, although recently the usefulness of this notion has been debated (see, e.g., <ref> [41] </ref>). Holland's work was the first attempt to put computational evolution on a firm theoretical footing.
Reference: [42] <author> J. J. Grefenstette, C. L. Ramsey, and A. C. Schultz. </author> <title> Learning sequential decision rules using simulation models and competition. </title> <journal> Machine Learning, </journal> <volume> 5(4) </volume> <pages> 355-381, </pages> <year> 1990. </year>
Reference-contexts: GAs have also been used to design neural networks (e.g., [14, 24, 43, 44, 62, 72, 76, 89, 99]), to evolve rules for learning classifier systems (e.g., [50, 53]) or symbolic production systems (e.g., <ref> [42] </ref>), and to design and control robots (e.g., [28, 30, 46]).
Reference: [43] <author> F. Gruau. </author> <title> Genetic synthesis of Boolean neural networks with a cell rewriting developmental process. </title> <editor> In L. D. Whitley and J. D. Schaffer, editors, </editor> <booktitle> International Workshop on Combinations of Genetic Algorithms and Neural Networks, </booktitle> <pages> pages 55-72, </pages> <address> Los Alamitos, CA, 1992. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: GAs have also been used to design neural networks (e.g., <ref> [14, 24, 43, 44, 62, 72, 76, 89, 99] </ref>), to evolve rules for learning classifier systems (e.g., [50, 53]) or symbolic production systems (e.g., [42]), and to design and control robots (e.g., [28, 30, 46]). <p> The grammar is then used to produce a legal object in the language it specifies (the development step), and this string (the phenotype) is then evaluated by the fitness function. Examples of this exploratory work include <ref> [13, 43, 62, 102] </ref>. Related to the question of representation is the choice of genetic operators for introducing variation into a population. One reason that binary linearly ordered representations are so popular is that the standard mutation and crossover operators can be applied in a problem-independent way.
Reference: [44] <author> S. A. Harp and T. Samad. </author> <title> Genetic synthesis of neural network architecture. </title> <editor> In L. D. Davis, editor, </editor> <booktitle> Handbook of Genetic Algorithms, </booktitle> <pages> pages 202-221. </pages> <publisher> Van Nostrand Reinhold, </publisher> <year> 1991. </year>
Reference-contexts: GAs have also been used to design neural networks (e.g., <ref> [14, 24, 43, 44, 62, 72, 76, 89, 99] </ref>), to evolve rules for learning classifier systems (e.g., [50, 53]) or symbolic production systems (e.g., [42]), and to design and control robots (e.g., [28, 30, 46]).
Reference: [45] <author> I. Harvey. </author> <title> The puzzle of the persistent question marks: A case study of genetic drift. </title> <editor> In S. Forrest, editor, </editor> <booktitle> Proceedings of the Fifth International Conference on Genetic Algorithms, </booktitle> <pages> pages 15-22, </pages> <address> San Mateo, CA, 1993. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Such tradeoffs occur in evolution and can be seen even in Hinton and Nowlan's simple model. Computer simulations such as theirs can help us to understand and to measure such tradeoffs. More detailed analyses of this model were performed by Belew [12] and Harvey <ref> [45] </ref>. 3.3 Evolutionary Reinforcement Learning (ERL) A second computational demonstration of the Baldwin effect was given by Ackley and Littman [1]. In their Evolutionary Reinforcement Learning (ERC) model, adaptive individuals ("agents") move randomly on a two-dimensional lattice, encountering food, predators, hiding places, and other types of entities.
Reference: [46] <author> I. Harvey, P. Husbands, and D. Cliff. </author> <title> Issues in evolutionary robotics. </title> <editor> In J.-A. Meyer, H. L. Roitblat, and S. W. Wilson, editors, </editor> <booktitle> From Animals to Animats 2: Proceedings of the second international conference on simulation of adaptive behavior, </booktitle> <pages> pages 364-373, </pages> <address> Cambridge, MA, 1993. </address> <publisher> MIT Press. </publisher>
Reference-contexts: GAs have also been used to design neural networks (e.g., [14, 24, 43, 44, 62, 72, 76, 89, 99]), to evolve rules for learning classifier systems (e.g., [50, 53]) or symbolic production systems (e.g., [42]), and to design and control robots (e.g., <ref> [28, 30, 46] </ref>).
Reference: [47] <author> R. Hightower, S. Forrest, and A. Perelson. </author> <title> The evolution of secondary organization in immune system gene libraries. </title> <booktitle> In Proceedings of the Second European Conference on Artificial Life, </booktitle> <publisher> (in press). </publisher>
Reference-contexts: machine learning, see [59, 60]. * Economic models: GAs have been used by to model processes of innovation, the development of bidding strategies, and the emergence of economic markets (e.g., [3, 54, 4]). * Immune system models: GAs have been used to model various aspects of the natural immune system <ref> [16, 36, 47] </ref>, including somatic mutation during an individual's lifetime and the discovery of multi-gene families during evolutionary time. * Ecological models: GAs have been used to model ecological phenomena such as biological arms races, host-parasite co-evolution, symbiosis, and resource flow in ecologies (e.g., [10, 11, 25, 27, 48, 52, 57, <p> its ability to detect common patterns (schemas) in the noisy environment of randomly presented antigens [36]; (2) its ability to discover and maintain coverage of the diverse antigen population [93]; and (3) its ability to learn effectively, even when not all antibodies are expressed and not all antigens are presented <ref> [47] </ref>. This last experiment is particularly relevant to the more general question of how selection pressures operating only at the global, phenotypic level can produce appropriate low-level, genetic structures. The question is most interesting when the connection between phenotype and genotype is more than a simple, direct mapping. <p> The multigene families (V-region libraries) of the immune system provide a good subject for experimentation from this point of view|the phenotype is not a direct mapping from the genotype, but the connection is simple enough that it can be studied analytically and experimentally. In <ref> [47] </ref>, all antigens were exactly 64 bits. The V-region library was modeled as a set of four libraries, each with eight entries of length 16 (producing a genome with 512 bits). <p> In a co-evolutionary system such as this, the populations evolve towards relatively uncorrelated parts of the phenotype landscape where mutations have a relatively large effect on the secondary structure, thus facilitating the process of continuous adaptation itself. This is a similar point to that raised in <ref> [47] </ref>. The idea of exploiting variations in the phenotype through mutations at the genetic level is a recurring theme in evolution, and the immune system provides a clear example of where such exploitation might occur. 6.
Reference: [48] <author> W. D. Hillis. </author> <title> Co-evolving parasites improve simulated evolution as an optimization procedure. </title> <journal> Physica D, </journal> <volume> 42 </volume> <pages> 228-234, </pages> <year> 1990. </year>
Reference-contexts: variety of optimization tasks, including numerical optimization (e.g., [58]), and combinatorial optimization problems such as circuit design and job shop scheduling. * Automatic Programming: GAs have been used to evolve computer programs for specific tasks (e.g., [64]) and to design other computational structures, e.g., cellular automata [75] and sorting networks <ref> [48] </ref>. * Machine and robot learning: GAs have been used for many machine-learning applications, including classification and prediction tasks such as the prediction of dynamical systems [70], weather prediction [87], and prediction of protein structure (e.g., [90]).
Reference: [49] <author> G. E. Hinton and S. J. Nowlan. </author> <title> How learning can guide evolution. </title> <journal> Complex Systems, </journal> <volume> 1 </volume> <pages> 495-502, </pages> <year> 1987. </year>
Reference-contexts: GAs have been used to study questions in population genetics, such as "under what conditions will a gene for recombination be evolutionarily viable?" (e.g., [15, 33, 69, 88]). * Interactions between evolution and learning: GAs have been used to study how individual learning and species evolution affect one another (e.g., <ref> [1, 2, 12, 35, 49, 77, 71, 79, 96, 97] </ref>). * Models of social systems: GAs have been used to study evolutionary aspects of social systems, such as the evolution of cooperation [6, 7, 68, 73, 74], the evolution of communication (e.g., [67, 98]), and trail-following behavior in ants (e.g., [26, <p> In this indirect way, learning can affect evolution, even if what is learned cannot be transmitted genetically. 3.2 Capturing the Baldwin effect in a simple model Hinton and Nowlan used a GA to model the Baldwin effect <ref> [49] </ref>. Their goal was to demonstrate this effect empirically and to measure its magnitude, using the simplest possible model. A simple neural-network learning algorithm modeled learning, and the GA played the role of evolution, evolving a population of neural networks with varying learning capabilities.
Reference: [50] <author> J. H. Holland. </author> <title> Escaping brittleness: The possibilities of general-purpose learning algorithms applied to parallel rule-based systems. </title> <editor> In R. S. Michalski, J. G. Carbonell, and T. M. Mitchell, editors, </editor> <booktitle> Machine Learning II, </booktitle> <pages> pages 593-623, </pages> <address> San Mateo, CA, 1986. </address> <publisher> Morgan Kaufmann. </publisher> <pages> 22 </pages>
Reference-contexts: GAs have also been used to design neural networks (e.g., [14, 24, 43, 44, 62, 72, 76, 89, 99]), to evolve rules for learning classifier systems (e.g., <ref> [50, 53] </ref>) or symbolic production systems (e.g., [42]), and to design and control robots (e.g., [28, 30, 46]).
Reference: [51] <author> J. H. Holland. </author> <title> Adaptation in Natural and Artificial Systems. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1992. </year> <note> Second edition (First edition, </note> <year> 1975). </year>
Reference-contexts: GAs as they are known today were first described by John Holland in the 1960s and further developed by Holland and his students and colleagues at the University of Michigan in the 1960s and 1970s. Holland's 1975 book Adaptation in Natural and Artificial Systems <ref> [51] </ref> presents the GA as an abstraction of biological evolution and gives a theoretical framework for adaptation under the GA. <p> For implementation details such as these, see [38]. Introducing a population-based algorithm with crossover and inversion was a major innovation. Just as significant is the theoretical foundation Holland developed based on the notion of "schemata" <ref> [51, 38] </ref>. This theoretical foundation has been the basis of almost all subsequent theoretical work on GAs, although recently the usefulness of this notion has been debated (see, e.g., [41]). Holland's work was the first attempt to put computational evolution on a firm theoretical footing. <p> such models which use GAs: Holland's Echo system, meant to allow a large range of ecological interactions to be modeled, and Bedau and Packard's Strategic Bugs system, for which a measure of evolutionary activity is defined and studied. 4.1 Echo Echo is a model of ecological systems formulated by Holland <ref> [51, 52] </ref>. Echo models ecologies in the same sense that the GA models population genetics [52]. It abstracts away virtually all of the physical details of real ecological systems and concentrates on a small set of primitive agent-agent and agent-environment interactions. <p> surprisingly complex behavior (including something resembling a biological "arms race" in which two competing species develop progressively more complex offensive and defensive combat strategies), ecological dependencies among different species (e.g., a symbiotic "ant-caterpillar-fly" triangle), and sensitivity (in terms of the number of different phenotypes) to differing levels of renewable resources <ref> [51] </ref>. <p> Although it is relatively easy to implement endogenous or co-evolutionary fitness strategies, there is virtually no theory describing the behavior of GAs under these circumstances. In particular, a theory about how building blocks are processed (cf. <ref> [51, 38] </ref>) under these circumstances would be helpful. Perhaps the most obvious area for extending the GA is to the study of evolution itself.
Reference: [52] <author> J. H. Holland. </author> <title> Echoing emergence: Objectives, rough definitions, and speculations for Echo-class models. </title> <type> Technical Report 93-04-023, </type> <institution> Santa Fe Institute, </institution> <year> 1993. </year> <note> To appear in Integrative Themes, </note> <editor> G. Cowan, D. Pines and D. Melzner, </editor> <address> Reading, MA: </address> <publisher> Addison-Wesley. </publisher>
Reference-contexts: such models which use GAs: Holland's Echo system, meant to allow a large range of ecological interactions to be modeled, and Bedau and Packard's Strategic Bugs system, for which a measure of evolutionary activity is defined and studied. 4.1 Echo Echo is a model of ecological systems formulated by Holland <ref> [51, 52] </ref>. Echo models ecologies in the same sense that the GA models population genetics [52]. It abstracts away virtually all of the physical details of real ecological systems and concentrates on a small set of primitive agent-agent and agent-environment interactions. <p> Echo models ecologies in the same sense that the GA models population genetics <ref> [52] </ref>. It abstracts away virtually all of the physical details of real ecological systems and concentrates on a small set of primitive agent-agent and agent-environment interactions. <p> reproduce as a unit; this capacity will allow for the study of individual agent specialization and the evolution of multi-cellularity; (3) studying the evolutionary dynamics of schemata in the population; and (4) using the results from (3) to formulate a generalization of the well-known Schema Theorem based on endogenous fitness <ref> [52] </ref>.
Reference: [53] <author> J. H. Holland, K. J. Holyoak, R. E. Nisbett, and P. Thagard. </author> <title> Induction: Processes of Inference, Learning, and Discovery. </title> <publisher> MIT Press, </publisher> <year> 1986. </year>
Reference-contexts: GAs have also been used to design neural networks (e.g., [14, 24, 43, 44, 62, 72, 76, 89, 99]), to evolve rules for learning classifier systems (e.g., <ref> [50, 53] </ref>) or symbolic production systems (e.g., [42]), and to design and control robots (e.g., [28, 30, 46]). <p> The idea of exploiting variations in the phenotype through mutations at the genetic level is a recurring theme in evolution, and the immune system provides a clear example of where such exploitation might occur. 6. Learning classifier systems Learning classifier systems <ref> [53] </ref> are one of the earliest examples of how GAs have been incorporated into models of living systems, in this case cognitive systems. Classifier systems have been used as models of stimulus-response behavior and of more complex cognitive processes. <p> In classifier systems, default hierarchies are represented using clusters of rules of different specificities. In <ref> [53] </ref>, the concept of a "quasi-morphism" is introduced to describe this modeling process formally. There have been several modeling efforts based on learning classifier systems, including [18, 19, 31, 85, 86, 100, 101].
Reference: [54] <author> J. H. Holland and J. H. Miller. </author> <title> Artificial adaptive agents in economic theory. </title> <type> Technical Report 91-05-025, </type> <institution> Santa Fe Institute, </institution> <address> Santa Fe, New Mexico, </address> <year> 1991. </year>
Reference-contexts: For an overview of GAs in machine learning, see [59, 60]. * Economic models: GAs have been used by to model processes of innovation, the development of bidding strategies, and the emergence of economic markets (e.g., <ref> [3, 54, 4] </ref>). * Immune system models: GAs have been used to model various aspects of the natural immune system [16, 36, 47], including somatic mutation during an individual's lifetime and the discovery of multi-gene families during evolutionary time. * Ecological models: GAs have been used to model ecological phenomena such
Reference: [55] <author> M. Huynen. </author> <title> Evolutionary dynamics and pattern generation in the sequence and secondary structure of RNA. </title> <type> PhD thesis, </type> <institution> Universiteit Utrecht, </institution> <address> The Netherlands, </address> <year> 1993. </year>
Reference-contexts: Recent work on the kind of genotype-phenotype relations that might be expected between a sequence (e.g., an RNA sequence) and its corresponding higher-order structure (e.g., its secondary structure) may also apply to modeling the immune system <ref> [55] </ref>. For example, the interaction between the immune system and a rapidly evolving pathogen can be regarded as a system with rapidly changing fitness criteria at the level of the secondary structure. Yet, the immune system and pathogen are both co-evolving through mutations at the genetic level.
Reference: [56] <author> J. K. Inman. </author> <title> The antibody combining region: Speculations on the hypothesis of general multispecificity. </title> <editor> In G. I. Bell, A. S. Perelson, and G. H. Pimbley Jr., editors, </editor> <booktitle> Theoretical Immunology, </booktitle> <pages> pages 243-278. </pages> <editor> M. </editor> <publisher> Dekker, </publisher> <address> NY, </address> <year> 1978. </year>
Reference-contexts: It has been estimated that the immune system is capable of recognizing on the order of 10 16 different foreign molecules <ref> [56] </ref>. From a pattern-recognition perspective these are staggering numbers, particularly when one considers that the human genome, which encodes the "program" for constructing the immune system, only contains about 10 5 genes, and further, that the immune system is distributed throughout the body with no central organ to control it.
Reference: [57] <author> D. Jefferson, R. Collins, C. Cooper, M. Dyer, M. Flowers, R. Korf, C. Taylor, and A. Wang. </author> <title> Evolution as a theme in artificial life: The Genesys/Tracker system. </title> <editor> In C. G. Langton, C. Taylor, J. D. Farmer, and S. Rasmussen, editors, </editor> <booktitle> Artificial Life II, </booktitle> <pages> pages 549-577, </pages> <address> Reading, MA, 1992. </address> <publisher> Addison-Wesley. </publisher>
Reference: [58] <author> K. A. De Jong. </author> <title> An Analysis of the Behavior of a Class of Genetic Adaptive Systems. </title> <type> PhD thesis, </type> <institution> The University of Michigan, </institution> <address> Ann Arbor, MI, </address> <year> 1975. </year>
Reference-contexts: Holland's work was the first attempt to put computational evolution on a firm theoretical footing. GAs in various forms have been applied to many scientific and engineering problems, including the following: * Optimization: GAs have been used in a wide variety of optimization tasks, including numerical optimization (e.g., <ref> [58] </ref>), and combinatorial optimization problems such as circuit design and job shop scheduling. * Automatic Programming: GAs have been used to evolve computer programs for specific tasks (e.g., [64]) and to design other computational structures, e.g., cellular automata [75] and sorting networks [48]. * Machine and robot learning: GAs have been
Reference: [59] <author> K. A. De Jong. </author> <title> Genetic-algorithm-based learning. </title> <editor> In Y. Kodratoff and R. Michalski, editors, </editor> <booktitle> Machine Learning, </booktitle> <volume> volume 3, </volume> <pages> pages 611-638, </pages> <year> 1990. </year>
Reference-contexts: For an overview of GAs in machine learning, see <ref> [59, 60] </ref>. * Economic models: GAs have been used by to model processes of innovation, the development of bidding strategies, and the emergence of economic markets (e.g., [3, 54, 4]). * Immune system models: GAs have been used to model various aspects of the natural immune system [16, 36, 47], including
Reference: [60] <author> K. A. De Jong. </author> <title> Introduction to second special issue on genetic algorithms. </title> <journal> Machine Learning, </journal> <volume> 5(4) </volume> <pages> 351-353, </pages> <year> 1990. </year>
Reference-contexts: For an overview of GAs in machine learning, see <ref> [59, 60] </ref>. * Economic models: GAs have been used by to model processes of innovation, the development of bidding strategies, and the emergence of economic markets (e.g., [3, 54, 4]). * Immune system models: GAs have been used to model various aspects of the natural immune system [16, 36, 47], including
Reference: [61] <author> K. De Jong. </author> <title> Editorial introduction. </title> <journal> Evolutionary Computation, </journal> <volume> 1(1), </volume> <year> 1993. </year>
Reference-contexts: However, all of these methods have a "family resemblance" in that they take some inspiration from biological evolution and from Holland's original GA. A new term, "Evolutionary Computation," has been introduced to cover these various members of the GA family, evolutionary programming, and evolution strategies <ref> [61] </ref>. In the following sections we describe a number of examples illustrating the use of GAs in artificial life.
Reference: [62] <author> H. Kitano. </author> <title> Designing neural networks using genetic algorithms with graph generation system. </title> <journal> Complex Systems, </journal> <volume> 4 </volume> <pages> 461-476, </pages> <year> 1990. </year>
Reference-contexts: GAs have also been used to design neural networks (e.g., <ref> [14, 24, 43, 44, 62, 72, 76, 89, 99] </ref>), to evolve rules for learning classifier systems (e.g., [50, 53]) or symbolic production systems (e.g., [42]), and to design and control robots (e.g., [28, 30, 46]). <p> The grammar is then used to produce a legal object in the language it specifies (the development step), and this string (the phenotype) is then evaluated by the fitness function. Examples of this exploratory work include <ref> [13, 43, 62, 102] </ref>. Related to the question of representation is the choice of genetic operators for introducing variation into a population. One reason that binary linearly ordered representations are so popular is that the standard mutation and crossover operators can be applied in a problem-independent way.
Reference: [63] <author> J. R. Koza. </author> <title> Genetic evolution and co-evolution of computer programs. </title> <editor> In C. G. Langton, C. Taylor, J. D. Farmer, and S. Rasmussen, editors, </editor> <booktitle> Artificial Life II, </booktitle> <pages> pages 603-629, </pages> <address> Reading, MA, 1992. </address> <publisher> Addison-Wesley. </publisher>
Reference-contexts: [1, 2, 12, 35, 49, 77, 71, 79, 96, 97]). * Models of social systems: GAs have been used to study evolutionary aspects of social systems, such as the evolution of cooperation [6, 7, 68, 73, 74], the evolution of communication (e.g., [67, 98]), and trail-following behavior in ants (e.g., <ref> [26, 63] </ref>). This list is by no means exhaustive, but it gives a flavor of the kinds of things for which GAs have been used, both for problem-solving and for modeling. The range of GA applications continues to increase.
Reference: [64] <author> J. R. Koza. </author> <title> Genetic programming: On the programming of computers by means of natural selection. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1993. </year>
Reference-contexts: engineering problems, including the following: * Optimization: GAs have been used in a wide variety of optimization tasks, including numerical optimization (e.g., [58]), and combinatorial optimization problems such as circuit design and job shop scheduling. * Automatic Programming: GAs have been used to evolve computer programs for specific tasks (e.g., <ref> [64] </ref>) and to design other computational structures, e.g., cellular automata [75] and sorting networks [48]. * Machine and robot learning: GAs have been used for many machine-learning applications, including classification and prediction tasks such as the prediction of dynamical systems [70], weather prediction [87], and prediction of protein structure (e.g., [90]). <p> For this reason, the "representation problem" is especially important for GAs. Although the representation problem has been acknowledged for many years, there have been surprisingly few innovative representations, the recent work on genetic programming <ref> [64] </ref> and messy GAs [39] being notable exceptions. In genetic programming, individuals are represented as S-expressions|small programs written in a subset of Lisp. Although S-expressions can be written as linear strings, they are naturally viewed as trees, and the genetic operators operate on trees.
Reference: [65] <author> K. Lindgren. </author> <title> Evolutionary phenomena in simple dynamics. </title> <editor> In C. G. Langton, C. Taylor, J. D. Farmer, and S. Rasmussen, editors, </editor> <booktitle> Artificial Life II, </booktitle> <pages> pages 295-312, </pages> <address> Reading, MA, 1992. </address> <publisher> Addison-Wesley. </publisher>
Reference-contexts: The reciprocators score better than average, so they spread in the population, resulting in more and more cooperation and increasing fitness. Lindgren performed a series of experiments similar to Axelrod's second experiment, but included the possibility of noise, in which players can make mistakes in following their strategies <ref> [65] </ref>. He also allowed a more open-ended kind of evolution in which a "gene duplication" operator allowed the amount of memory available to a given strategy to increase.
Reference: [66] <author> K. Lindgren and M. G. Nordhal. </author> <title> Artificial food webs. </title> <editor> In C. G. Langton, editor, </editor> <booktitle> Artificial Life III, </booktitle> <address> Reading, MA, 1993. </address> <publisher> Addison-Wesley. </publisher> <pages> 23 </pages>
Reference: [67] <author> B. MacLennan. </author> <title> Synthetic ethology: An approach to the study of communication. </title> <editor> In C. G. Langton, C. Taylor, J. D. Farmer, and S. Rasmussen, editors, </editor> <booktitle> Artificial Life II, </booktitle> <pages> pages 631-655, </pages> <address> Reading, MA, 1992. </address> <publisher> Addison-Wesley. </publisher>
Reference-contexts: learning and species evolution affect one another (e.g., [1, 2, 12, 35, 49, 77, 71, 79, 96, 97]). * Models of social systems: GAs have been used to study evolutionary aspects of social systems, such as the evolution of cooperation [6, 7, 68, 73, 74], the evolution of communication (e.g., <ref> [67, 98] </ref>), and trail-following behavior in ants (e.g., [26, 63]). This list is by no means exhaustive, but it gives a flavor of the kinds of things for which GAs have been used, both for problem-solving and for modeling. The range of GA applications continues to increase.
Reference: [68] <author> R. E. Marks. </author> <title> Breeding hybrid strategies: optimal behavior for oligopolists. </title> <journal> Journal of Evolutionary Economics, </journal> <volume> 2 </volume> <pages> 17-38, </pages> <year> 1992. </year>
Reference-contexts: and learning: GAs have been used to study how individual learning and species evolution affect one another (e.g., [1, 2, 12, 35, 49, 77, 71, 79, 96, 97]). * Models of social systems: GAs have been used to study evolutionary aspects of social systems, such as the evolution of cooperation <ref> [6, 7, 68, 73, 74] </ref>, the evolution of communication (e.g., [67, 98]), and trail-following behavior in ants (e.g., [26, 63]). This list is by no means exhaustive, but it gives a flavor of the kinds of things for which GAs have been used, both for problem-solving and for modeling. <p> Other work using computational evolution to discover PD strategies in the presence of noise or imperfect information about the past (both making the PD a more realistic model of social or political interactions) has been done by Miller [74] and Marks <ref> [68] </ref>, among others. 8. Open problems and future directions In the previous sections we have briefly described some representative examples of artificial-life projects that use the GA in a significant way.
Reference: [69] <author> F. Menczer and D. Parisi. </author> <title> A model for the emergence of sex in evolving networks: Adaptive advantage or random drift? In F. </title> <editor> J. Varela and P. Bourgine, editors, </editor> <booktitle> Toward a Practice of Autonomous Systems: Proceedings of the First European Conference on Artificial Life, </booktitle> <address> Cambridge, MA, 1992. </address> <publisher> MIT Press/Bradford Books. </publisher>
Reference-contexts: host-parasite co-evolution, symbiosis, and resource flow in ecologies (e.g., [10, 11, 25, 27, 48, 52, 57, 65, 66, 78, 82, 83, 95]). * Population genetics models: GAs have been used to study questions in population genetics, such as "under what conditions will a gene for recombination be evolutionarily viable?" (e.g., <ref> [15, 33, 69, 88] </ref>). * Interactions between evolution and learning: GAs have been used to study how individual learning and species evolution affect one another (e.g., [1, 2, 12, 35, 49, 77, 71, 79, 96, 97]). * Models of social systems: GAs have been used to study evolutionary aspects of social
Reference: [70] <author> T. P. Meyer and N. H. Packard. </author> <title> Local forcasting of high dimensional chaotic dynamics. </title> <type> Technical Report CCSR-91-1, </type> <institution> Center for Complex Systems Research, Beckman Institute, University of Illinois at Urbana Champaign, </institution> <year> 1991. </year>
Reference-contexts: been used to evolve computer programs for specific tasks (e.g., [64]) and to design other computational structures, e.g., cellular automata [75] and sorting networks [48]. * Machine and robot learning: GAs have been used for many machine-learning applications, including classification and prediction tasks such as the prediction of dynamical systems <ref> [70] </ref>, weather prediction [87], and prediction of protein structure (e.g., [90]).
Reference: [71] <author> G. F. Miller and P. M. Todd. </author> <title> Exploring adaptive agency I: Theory and methods for simulating the evolution of learning. </title> <editor> In D. S. Touretzky et al., editor, </editor> <booktitle> Proceedings of the 1990 Connectionist Models Summer School, </booktitle> <address> San Mateo, CA, 1990. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: GAs have been used to study questions in population genetics, such as "under what conditions will a gene for recombination be evolutionarily viable?" (e.g., [15, 33, 69, 88]). * Interactions between evolution and learning: GAs have been used to study how individual learning and species evolution affect one another (e.g., <ref> [1, 2, 12, 35, 49, 77, 71, 79, 96, 97] </ref>). * Models of social systems: GAs have been used to study evolutionary aspects of social systems, such as the evolution of cooperation [6, 7, 68, 73, 74], the evolution of communication (e.g., [67, 98]), and trail-following behavior in ants (e.g., [26,
Reference: [72] <author> G. F. Miller, P. M. Todd, and S. U. Hegde. </author> <title> Designing neural networks using genetic algorithms. </title> <editor> In J. D. Schaffer, editor, </editor> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <pages> pages 379-384. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1989. </year>
Reference-contexts: GAs have also been used to design neural networks (e.g., <ref> [14, 24, 43, 44, 62, 72, 76, 89, 99] </ref>), to evolve rules for learning classifier systems (e.g., [50, 53]) or symbolic production systems (e.g., [42]), and to design and control robots (e.g., [28, 30, 46]).
Reference: [73] <author> J. H. Miller. </author> <title> Two Essays on the Economics of Imperfect Information. </title> <type> PhD thesis, </type> <institution> The University of Michigan, </institution> <address> Ann Arbor, MI, </address> <year> 1988. </year>
Reference-contexts: and learning: GAs have been used to study how individual learning and species evolution affect one another (e.g., [1, 2, 12, 35, 49, 77, 71, 79, 96, 97]). * Models of social systems: GAs have been used to study evolutionary aspects of social systems, such as the evolution of cooperation <ref> [6, 7, 68, 73, 74] </ref>, the evolution of communication (e.g., [67, 98]), and trail-following behavior in ants (e.g., [26, 63]). This list is by no means exhaustive, but it gives a flavor of the kinds of things for which GAs have been used, both for problem-solving and for modeling.
Reference: [74] <author> J. H. Miller. </author> <title> The coevolution of automata in the repeated prisoner's dilemma. </title> <type> Technical Report 89-003, </type> <institution> Santa Fe Institute, </institution> <address> Santa Fe, New Mexico 87501, </address> <year> 1989. </year>
Reference-contexts: and learning: GAs have been used to study how individual learning and species evolution affect one another (e.g., [1, 2, 12, 35, 49, 77, 71, 79, 96, 97]). * Models of social systems: GAs have been used to study evolutionary aspects of social systems, such as the evolution of cooperation <ref> [6, 7, 68, 73, 74] </ref>, the evolution of communication (e.g., [67, 98]), and trail-following behavior in ants (e.g., [26, 63]). This list is by no means exhaustive, but it gives a flavor of the kinds of things for which GAs have been used, both for problem-solving and for modeling. <p> Other work using computational evolution to discover PD strategies in the presence of noise or imperfect information about the past (both making the PD a more realistic model of social or political interactions) has been done by Miller <ref> [74] </ref> and Marks [68], among others. 8. Open problems and future directions In the previous sections we have briefly described some representative examples of artificial-life projects that use the GA in a significant way.
Reference: [75] <author> M. Mitchell, J. P. Crutchfield, and P. T. Hraber. </author> <title> Evolving cellular automata to perform computations: Mechanisms and impediments. </title> <journal> Submitted to Physica D, </journal> <year> 1993. </year>
Reference-contexts: used in a wide variety of optimization tasks, including numerical optimization (e.g., [58]), and combinatorial optimization problems such as circuit design and job shop scheduling. * Automatic Programming: GAs have been used to evolve computer programs for specific tasks (e.g., [64]) and to design other computational structures, e.g., cellular automata <ref> [75] </ref> and sorting networks [48]. * Machine and robot learning: GAs have been used for many machine-learning applications, including classification and prediction tasks such as the prediction of dynamical systems [70], weather prediction [87], and prediction of protein structure (e.g., [90]).
Reference: [76] <author> D. J. Montana and L. D. Davis. </author> <title> Training feedforward networks using genetic algorithms. </title> <booktitle> In Proceedings of the International Joint Conference on Artificial Intelligence, </booktitle> <address> San Mateo, CA, 1989. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: GAs have also been used to design neural networks (e.g., <ref> [14, 24, 43, 44, 62, 72, 76, 89, 99] </ref>), to evolve rules for learning classifier systems (e.g., [50, 53]) or symbolic production systems (e.g., [42]), and to design and control robots (e.g., [28, 30, 46]).
Reference: [77] <author> S. Nolfi, J. L. Elman, and D. Parisi. </author> <title> Learning and evolution in neural networks. </title> <type> Technical Report CRL 9019, </type> <institution> Center for Research in Language, University of California, </institution> <address> San Diego, </address> <year> 1990. </year>
Reference-contexts: GAs have been used to study questions in population genetics, such as "under what conditions will a gene for recombination be evolutionarily viable?" (e.g., [15, 33, 69, 88]). * Interactions between evolution and learning: GAs have been used to study how individual learning and species evolution affect one another (e.g., <ref> [1, 2, 12, 35, 49, 77, 71, 79, 96, 97] </ref>). * Models of social systems: GAs have been used to study evolutionary aspects of social systems, such as the evolution of cooperation [6, 7, 68, 73, 74], the evolution of communication (e.g., [67, 98]), and trail-following behavior in ants (e.g., [26,
Reference: [78] <author> N. H. Packard. </author> <title> Intrinsic adaptation in a simple model for evolution. </title> <editor> In C. G. Langton, editor, </editor> <booktitle> Artificial Life, </booktitle> <pages> pages 141-155, </pages> <address> Reading, MA, 1989. </address> <publisher> Addison-Wesley. </publisher>
Reference: [79] <author> D. Parisi, S. Nolfi, and F. Cecconi. </author> <title> Learning, behavior, and evolution. </title> <booktitle> In Proceedings of the First European Conference on Artificial Life, </booktitle> <address> Cambridge, MA, 1992. </address> <publisher> MIT Press/Bradford Books. </publisher>
Reference-contexts: GAs have been used to study questions in population genetics, such as "under what conditions will a gene for recombination be evolutionarily viable?" (e.g., [15, 33, 69, 88]). * Interactions between evolution and learning: GAs have been used to study how individual learning and species evolution affect one another (e.g., <ref> [1, 2, 12, 35, 49, 77, 71, 79, 96, 97] </ref>). * Models of social systems: GAs have been used to study evolutionary aspects of social systems, such as the evolution of cooperation [6, 7, 68, 73, 74], the evolution of communication (e.g., [67, 98]), and trail-following behavior in ants (e.g., [26,
Reference: [80] <author> A. S. Perelson. </author> <title> Immune network theory. </title> <journal> Immunol. Rev., </journal> <volume> 110 </volume> <pages> 5-36, </pages> <year> 1989. </year>
Reference-contexts: Different approaches to modeling the immune system have included differential-equation-based models (e.g., see <ref> [81, 80] </ref>), cellular-automata models [23], classifier systems [32], and GAs [36].
Reference: [81] <editor> A. S. Perelson, G. Weisbuch, and A. Coutinho, editors. </editor> <title> Theoretical and Experimental Insights into Immunology. </title> <publisher> Springer-Verlag, </publisher> <address> NY, </address> <year> 1992. </year> <month> 24 </month>
Reference-contexts: Different approaches to modeling the immune system have included differential-equation-based models (e.g., see <ref> [81, 80] </ref>), cellular-automata models [23], classifier systems [32], and GAs [36].
Reference: [82] <author> T. S. Ray. </author> <title> Is it alive, or is it GA? In R. </title> <editor> K. Belew and L. B. Booker, editors, </editor> <booktitle> Proceedings of the Fourth International Conference on Genetic Algorithms, </booktitle> <pages> pages 527-534, </pages> <address> San Mateo, CA, 1991. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: [83] <author> T. S. Ray. </author> <title> An approach to the synthesis of life. </title> <editor> In C. G. Langton, C. Taylor, J. D. Farmer, and S. Rasmussen, editors, </editor> <booktitle> Artificial Life II, </booktitle> <pages> pages 371-408, </pages> <address> Reading, MA, 1992. </address> <publisher> Addison-Wesley. </publisher>
Reference: [84] <editor> I. Rechenberg. Evolutionstrategie. Frommann-Holzboog, </editor> <address> Stuttgart, </address> <year> 1973. </year>
Reference-contexts: None used recombination, and very little mathematical analysis was provided to account for how these models worked. In the later 1960s, Rechenberg introduced "evolution strategies," a method first designed to optimize real-valued parameters <ref> [84] </ref>. This idea was further developed by Schwefel [91], and the field of evolution strategies has remained an active area of research, developing in parallel to GA research, until recently when the two communities have begun to interact. For a review of evolution strategies, see [8].
Reference: [85] <author> R. Riolo. </author> <title> Lookahead planning and latent learning in a classifier system. </title> <editor> In J.A. Meyer and S. W. Wilson, editors, </editor> <booktitle> From animals to animats: Proceedings of the first international conference on simulation of adaptive behavior, </booktitle> <pages> pages 316-326, </pages> <address> Cambridge, MA, 1991. </address> <publisher> MIT Press. </publisher>
Reference-contexts: In classifier systems, default hierarchies are represented using clusters of rules of different specificities. In [53], the concept of a "quasi-morphism" is introduced to describe this modeling process formally. There have been several modeling efforts based on learning classifier systems, including <ref> [18, 19, 31, 85, 86, 100, 101] </ref>. Each of these is a variation on the standard classifier system as described above, but each of the variations captures the major principles of classifier systems. <p> There have been several modeling efforts based on learning classifier systems, including [18, 19, 31, 85, 86, 100, 101]. Each of these is a variation on the standard classifier system as described above, but each of the variations captures the major principles of classifier systems. For example, in <ref> [85] </ref> Riolo used a classifier system to model the kind of latent learning and look-ahead behavior of the type observed in rats. For this work, Riolo designed a simple maze, similar to those in latent-learning experiments on rats. The maze has one start point and several end points.
Reference: [86] <author> R. Riolo. </author> <title> Modeling simple human category learning with a classifier system. </title> <editor> In R.K. Belew and L.B. Booker, editors, </editor> <booktitle> Proceedings of the Fifth International Conference on Genetic Algorithms, </booktitle> <pages> pages 324-333, </pages> <address> San Mateo, CA, 1991. </address> <publisher> Morgan-Kaufmann. </publisher>
Reference-contexts: In classifier systems, default hierarchies are represented using clusters of rules of different specificities. In [53], the concept of a "quasi-morphism" is introduced to describe this modeling process formally. There have been several modeling efforts based on learning classifier systems, including <ref> [18, 19, 31, 85, 86, 100, 101] </ref>. Each of these is a variation on the standard classifier system as described above, but each of the variations captures the major principles of classifier systems.
Reference: [87] <author> D. Rogers. </author> <title> Weather prediction using a genetic memory. </title> <type> Technical Report 90.6, </type> <institution> Research Institute for Advanced Computer Science, NASA Ames Research Center, Moffett Field, </institution> <address> CA, </address> <year> 1990. </year>
Reference-contexts: evolve computer programs for specific tasks (e.g., [64]) and to design other computational structures, e.g., cellular automata [75] and sorting networks [48]. * Machine and robot learning: GAs have been used for many machine-learning applications, including classification and prediction tasks such as the prediction of dynamical systems [70], weather prediction <ref> [87] </ref>, and prediction of protein structure (e.g., [90]).
Reference: [88] <editor> J. D. Schaffer and L. J. Eshelman. </editor> <title> On crossover as an evolutionarily viable strategy. </title> <editor> In R. K. Belew and L. B. Booker, editors, </editor> <booktitle> Proceedings of the Fourth International Conference on Genetic Algorithms, </booktitle> <pages> pages 61-68, </pages> <address> San Mateo, CA, 1991. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: host-parasite co-evolution, symbiosis, and resource flow in ecologies (e.g., [10, 11, 25, 27, 48, 52, 57, 65, 66, 78, 82, 83, 95]). * Population genetics models: GAs have been used to study questions in population genetics, such as "under what conditions will a gene for recombination be evolutionarily viable?" (e.g., <ref> [15, 33, 69, 88] </ref>). * Interactions between evolution and learning: GAs have been used to study how individual learning and species evolution affect one another (e.g., [1, 2, 12, 35, 49, 77, 71, 79, 96, 97]). * Models of social systems: GAs have been used to study evolutionary aspects of social
Reference: [89] <editor> J. D. Schaffer, D. Whitley, and L. J. Eshelman. </editor> <title> Combinations of genetic algorithms and neural networks: A survey of the state of the art. </title> <editor> In L. D. Whitley and J. D. Schaffer, editors, </editor> <booktitle> International Workshop on Combinations of Genetic Algorithms and Neural Networks, </booktitle> <pages> pages 1-37, </pages> <address> Los Alamitos, CA, 1992. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: GAs have also been used to design neural networks (e.g., <ref> [14, 24, 43, 44, 62, 72, 76, 89, 99] </ref>), to evolve rules for learning classifier systems (e.g., [50, 53]) or symbolic production systems (e.g., [42]), and to design and control robots (e.g., [28, 30, 46]). <p> A growing community of GA researchers is studying ways to apply GAs to optimize neural networks to solve practical problems|a practical application of the interaction between learning and evolution. A survey of this work is given in <ref> [89] </ref>. Other researchers are investigating the benefits of adding "Lamarckian" learning to the GA, and have found in some cases that it leads to significant improvements in GA performance [2, 40]. 4.
Reference: [90] <author> S. Schulze-Kremer. </author> <title> Genetic algorithms for protein tertiary structure prediction. </title> <editor> In R. Manner and B. Manderick, editors, </editor> <booktitle> Parallel Problem Solving from Nature 2, </booktitle> <pages> pages 391-400, </pages> <address> Amster-dam, 1992. </address> <publisher> North Holland. </publisher>
Reference-contexts: [64]) and to design other computational structures, e.g., cellular automata [75] and sorting networks [48]. * Machine and robot learning: GAs have been used for many machine-learning applications, including classification and prediction tasks such as the prediction of dynamical systems [70], weather prediction [87], and prediction of protein structure (e.g., <ref> [90] </ref>). GAs have also been used to design neural networks (e.g., [14, 24, 43, 44, 62, 72, 76, 89, 99]), to evolve rules for learning classifier systems (e.g., [50, 53]) or symbolic production systems (e.g., [42]), and to design and control robots (e.g., [28, 30, 46]).
Reference: [91] <author> H.-P. Schwefel. </author> <title> Evolutionsstrategie und numerische Optimierung. </title> <type> PhD thesis, </type> <institution> Technische Universitat Berlin, </institution> <address> Berlin, </address> <year> 1975. </year>
Reference-contexts: None used recombination, and very little mathematical analysis was provided to account for how these models worked. In the later 1960s, Rechenberg introduced "evolution strategies," a method first designed to optimize real-valued parameters [84]. This idea was further developed by Schwefel <ref> [91] </ref>, and the field of evolution strategies has remained an active area of research, developing in parallel to GA research, until recently when the two communities have begun to interact. For a review of evolution strategies, see [8]. Also in the 1960s Fogel, Owens, and Walsh developed "evolutionary programming" [34].
Reference: [92] <author> J. Maynard Smith. </author> <title> When learning guides evolution. </title> <journal> Nature, </journal> <volume> 329, </volume> <year> 1987. </year>
Reference-contexts: However, some evolutionary biologists (e.g., <ref> [92] </ref>) have discussed an indirect effect of learning 4 on evolution, inspired by ideas about evolution due to Baldwin [9].
Reference: [93] <author> R. Smith, S. Forrest, and A. S. Perelson. </author> <title> Searching for diverse, cooperative populations with genetic algorithms. </title> <journal> Evolutionary Computation, </journal> <volume> 1(2) </volume> <pages> 127-149, </pages> <year> 1993. </year>
Reference-contexts: The binary immune system has been used to study several different aspects of the immune system, including (1) its ability to detect common patterns (schemas) in the noisy environment of randomly presented antigens [36]; (2) its ability to discover and maintain coverage of the diverse antigen population <ref> [93] </ref>; and (3) its ability to learn effectively, even when not all antibodies are expressed and not all antigens are presented [47]. This last experiment is particularly relevant to the more general question of how selection pressures operating only at the global, phenotypic level can produce appropriate low-level, genetic structures.
Reference: [94] <author> G. Syswerda. </author> <title> Uniform crossover in genetic algorithms. </title> <editor> In J. D. Schaffer, editor, </editor> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <pages> pages 2-9, </pages> <address> San Mateo, CA, 1989. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: This allows the GA to manipulate short strings early in a run, and over time, to combine short well-tested building blocks into longer, more complex strings. New versions of the crossover operator (e.g., <ref> [94] </ref>) can reduce the inherent bias in standard crossover of breaking up correlated genes that are widely separated on the chromosome (referred to as "positional bias"). These approaches are promising in some cases, especially since the strong positional dependence of most current representations is an artifact introduced by GAs.
Reference: [95] <author> C. E. Taylor, D. R. Jefferson, S. R. Turner, and S. R. Goldman. RAM: </author> <title> Artificial life for the exploration of complex biological systems. </title> <editor> In C. G. Langton, editor, </editor> <booktitle> Artificial Life, </booktitle> <pages> pages 275-295, </pages> <address> Reading, MA, 1989. </address> <publisher> Addison-Wesley. </publisher>
Reference: [96] <author> P. M. Todd and G. F. Miller. </author> <title> Exploring adaptive agency III: Simulating the evolution of habituation and sensitization. </title> <editor> In H.-P. Schwefel and R. Manner, editors, </editor> <title> Parallel Problem Solving from Nature, </title> <address> Berlin, </address> <year> 1990. </year> <note> Springer-Verlag (Lecture Notes in Computer Science). 25 </note>
Reference-contexts: GAs have been used to study questions in population genetics, such as "under what conditions will a gene for recombination be evolutionarily viable?" (e.g., [15, 33, 69, 88]). * Interactions between evolution and learning: GAs have been used to study how individual learning and species evolution affect one another (e.g., <ref> [1, 2, 12, 35, 49, 77, 71, 79, 96, 97] </ref>). * Models of social systems: GAs have been used to study evolutionary aspects of social systems, such as the evolution of cooperation [6, 7, 68, 73, 74], the evolution of communication (e.g., [67, 98]), and trail-following behavior in ants (e.g., [26,
Reference: [97] <author> P. M. Todd and G. F. Miller. </author> <title> Exploring adaptive agency II: Simulating the evolution of associative learning. </title> <editor> In J.-A. Meyer and S. W. Wilson, editors, </editor> <booktitle> From animals to animats: Proceedings of the first international conference on simulation of adaptive behavior, </booktitle> <pages> pages 306-315, </pages> <address> Cambridge, MA, 1991. </address> <publisher> MIT Press. </publisher>
Reference-contexts: GAs have been used to study questions in population genetics, such as "under what conditions will a gene for recombination be evolutionarily viable?" (e.g., [15, 33, 69, 88]). * Interactions between evolution and learning: GAs have been used to study how individual learning and species evolution affect one another (e.g., <ref> [1, 2, 12, 35, 49, 77, 71, 79, 96, 97] </ref>). * Models of social systems: GAs have been used to study evolutionary aspects of social systems, such as the evolution of cooperation [6, 7, 68, 73, 74], the evolution of communication (e.g., [67, 98]), and trail-following behavior in ants (e.g., [26,
Reference: [98] <author> G. M. Werner and M. G. Dyer. </author> <title> Evolution of communication in artificial organisms. </title> <editor> In C. G. Langton, C. Taylor, J. D. Farmer, and S. Rasmussen, editors, </editor> <booktitle> Artificial Life II, </booktitle> <pages> pages 659-687, </pages> <address> Reading, MA, 1992. </address> <publisher> Addison-Wesley. </publisher>
Reference-contexts: learning and species evolution affect one another (e.g., [1, 2, 12, 35, 49, 77, 71, 79, 96, 97]). * Models of social systems: GAs have been used to study evolutionary aspects of social systems, such as the evolution of cooperation [6, 7, 68, 73, 74], the evolution of communication (e.g., <ref> [67, 98] </ref>), and trail-following behavior in ants (e.g., [26, 63]). This list is by no means exhaustive, but it gives a flavor of the kinds of things for which GAs have been used, both for problem-solving and for modeling. The range of GA applications continues to increase.
Reference: [99] <author> L. D. Whitley, S. Dominic, and R. Das. </author> <title> Genetic reinforcement learning with multilayer neural networks. </title> <editor> In R. K. Belew and L. B. Booker, editors, </editor> <booktitle> Proceedings of the Fourth International Conference on Genetic Algorithms, </booktitle> <pages> pages 562-569, </pages> <address> San Mateo, CA, 1991. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: GAs have also been used to design neural networks (e.g., <ref> [14, 24, 43, 44, 62, 72, 76, 89, 99] </ref>), to evolve rules for learning classifier systems (e.g., [50, 53]) or symbolic production systems (e.g., [42]), and to design and control robots (e.g., [28, 30, 46]).
Reference: [100] <author> S. W. Wilson. </author> <title> Knowledge growth in an artificial animal. </title> <editor> In J. Grefenstette, editor, </editor> <booktitle> Proceedings of the First International Conference on Genetic Algorithms and Their Applications, </booktitle> <address> Hillsdale, New Jersey, 1985. </address> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference-contexts: In classifier systems, default hierarchies are represented using clusters of rules of different specificities. In [53], the concept of a "quasi-morphism" is introduced to describe this modeling process formally. There have been several modeling efforts based on learning classifier systems, including <ref> [18, 19, 31, 85, 86, 100, 101] </ref>. Each of these is a variation on the standard classifier system as described above, but each of the variations captures the major principles of classifier systems.
Reference: [101] <author> S. W. Wilson. </author> <title> Classifier systems and the animat problem. </title> <journal> Machine Learning, </journal> <volume> 2 </volume> <pages> 199-228, </pages> <year> 1987. </year>
Reference-contexts: In classifier systems, default hierarchies are represented using clusters of rules of different specificities. In [53], the concept of a "quasi-morphism" is introduced to describe this modeling process formally. There have been several modeling efforts based on learning classifier systems, including <ref> [18, 19, 31, 85, 86, 100, 101] </ref>. Each of these is a variation on the standard classifier system as described above, but each of the variations captures the major principles of classifier systems.
Reference: [102] <author> S. W. Wilson. </author> <title> The genetic algorithm and simulated evolution. </title> <editor> In C. G. Langton, editor, </editor> <booktitle> Artificial Life, </booktitle> <pages> pages 157-165, </pages> <address> Reading, MA, 1989. </address> <publisher> Addison-Wesley. </publisher> <pages> 26 </pages>
Reference-contexts: The grammar is then used to produce a legal object in the language it specifies (the development step), and this string (the phenotype) is then evaluated by the fitness function. Examples of this exploratory work include <ref> [13, 43, 62, 102] </ref>. Related to the question of representation is the choice of genetic operators for introducing variation into a population. One reason that binary linearly ordered representations are so popular is that the standard mutation and crossover operators can be applied in a problem-independent way.
References-found: 102

