URL: ftp://softlib.rice.edu/pub/CRPC-TRs/reports/CRPC-TR95514-S.ps.gz
Refering-URL: http://www.crpc.rice.edu/CRPC/softlib/TRs_online.html
Root-URL: 
Title: Efficient Derivative Codes through Automatic Differentiation and Interface Contraction: An Application in Biostatistics  
Author: by Paul Hovland, Christian Bischof, Donna Spiegelman, and Mario Casella. 
Abstract: Developing code for computing the first- and higher-order derivatives of a function by hand can be very time-consuming and is prone to errors. Automatic differentiation has proven capable of producing derivative codes with very little effort on the part of the user. Automatic differentiation avoids the truncation errors characteristic of divided-difference approximations. However, the derivative code produced by automatic differentiation can be significantly less efficient than one produced by hand. This shortcoming may be overcome by utilizing insight into the high-level structure of a computation. This paper focuses on how to take advantage of the fact that the number of variables passed between subroutines frequently is small compared with the number of the variables with respect to which we wish to differentiate. Such an "interface contraction," coupled with the associativity of the chain rule for differentiation, allows us to apply automatic differentiation in a more judicious fashion, resulting in much more efficient code for the computation of derivatives. A case study involving a program for maximizing a logistic-normal likelihood function developed from a problem in nutritional epidemiology is examined, and performance figures are presented. We conclude with some directions for future study. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Brett Averick, Jorge More, Christian Bischof, Alan Carle, and Andreas Griewank. </author> <title> Computing large sparse Jacobian matrices using automatic differentiation. </title> <journal> SIAM Journal on Scientific Computing, </journal> <volume> 15(2) </volume> <pages> 285-294, </pages> <year> 1994. </year>
Reference-contexts: "dependent" variables with respect to differentiation, ADIFOR produces portable Fortran 77 code that allows the computation of the derivatives of the dependent variables with respect to the independent ones. 3 Interface Contraction Automatic differentiation tools such as ADIFOR produce derivative code that typically outperforms divided difference approximations (see, for example, <ref> [1, 3, 5, 6, 18] </ref>), but, not surprisingly, is usually much less efficient than a hand-derived code probably could be. fl We introduce a technique, called "interface contraction," that can dramatically reduce the runtime and storage requirements for computing derivatives via automatic differentiation.
Reference: [2] <author> Christian Bischof, Alan Carle, George Corliss, Andreas Griewank, and Paul Hovland. ADIFOR: </author> <title> Generating derivative codes from Fortran programs. </title> <journal> Scientific Programming, </journal> <volume> 1(1) </volume> <pages> 11-29, </pages> <year> 1992. </year>
Reference-contexts: In particular, we mention GRESS [13], PADRE-2 [17], Odyssee [20], and ADIFOR <ref> [2] </ref> for Fortran programs and ADOL-C [11] and ADIC [4] for C programs. We employed the ADIFOR tool in our experiments. ADIFOR (Automatic Differentiation of Fortran) [2] provides automatic differentiation for programs written in Fortran 77. <p> In particular, we mention GRESS [13], PADRE-2 [17], Odyssee [20], and ADIFOR <ref> [2] </ref> for Fortran programs and ADOL-C [11] and ADIC [4] for C programs. We employed the ADIFOR tool in our experiments. ADIFOR (Automatic Differentiation of Fortran) [2] provides automatic differentiation for programs written in Fortran 77. <p> We can then perform the matrix multiplication rf (1:n) = y1bar * ry (1:n,1) + y2bar * ry (1:n, 2) + y5bar * ry (1:n, 5) This hybrid mode of automatic differentiation is employed by ADIFOR <ref> [2] </ref>. We see that interface contraction is mainly responsible for the lower complexity of ADIFOR-generated code compared with divided-difference approximations.
Reference: [3] <author> Christian Bischof, George Corliss, Larry Green, Andreas Griewank, Kara Haigler, and Perry Newman. </author> <title> Automatic differentiation of advanced CFD codes for multidisciplinary design. </title> <journal> Journal on Computing Systems in Engineering, </journal> <volume> 3(6) </volume> <pages> 625-638, </pages> <year> 1992. </year>
Reference-contexts: "dependent" variables with respect to differentiation, ADIFOR produces portable Fortran 77 code that allows the computation of the derivatives of the dependent variables with respect to the independent ones. 3 Interface Contraction Automatic differentiation tools such as ADIFOR produce derivative code that typically outperforms divided difference approximations (see, for example, <ref> [1, 3, 5, 6, 18] </ref>), but, not surprisingly, is usually much less efficient than a hand-derived code probably could be. fl We introduce a technique, called "interface contraction," that can dramatically reduce the runtime and storage requirements for computing derivatives via automatic differentiation.
Reference: [4] <author> Christian Bischof and Andrew Mauer. </author> <type> Private communication. </type> <institution> Argonne National Laboratory, </institution> <year> 1995. </year>
Reference-contexts: In particular, we mention GRESS [13], PADRE-2 [17], Odyssee [20], and ADIFOR [2] for Fortran programs and ADOL-C [11] and ADIC <ref> [4] </ref> for C programs. We employed the ADIFOR tool in our experiments. ADIFOR (Automatic Differentiation of Fortran) [2] provides automatic differentiation for programs written in Fortran 77.
Reference: [5] <author> Christian Bischof, Greg Whiffen, Christine Shoemaker, Alan Carle, and Aaron Ross. </author> <title> Application of automatic differentiation to groundwater transport models. </title> <editor> In Alexander Peters et al., editor, </editor> <booktitle> Computational Methods in Water Resources X, </booktitle> <pages> pages 173-182, </pages> <address> Dordrecht, 1994. </address> <publisher> Kluwer Academic Publishers. </publisher>
Reference-contexts: "dependent" variables with respect to differentiation, ADIFOR produces portable Fortran 77 code that allows the computation of the derivatives of the dependent variables with respect to the independent ones. 3 Interface Contraction Automatic differentiation tools such as ADIFOR produce derivative code that typically outperforms divided difference approximations (see, for example, <ref> [1, 3, 5, 6, 18] </ref>), but, not surprisingly, is usually much less efficient than a hand-derived code probably could be. fl We introduce a technique, called "interface contraction," that can dramatically reduce the runtime and storage requirements for computing derivatives via automatic differentiation.
Reference: [6] <author> Alan Carle, Lawrence Green, Christian Bischof, and Perry Newman. </author> <title> Applications of automatic differentiation in CFD. </title> <booktitle> In Proceedings of the 25th AIAA Fluid Dynamics Conference, </booktitle> <institution> AIAA Paper 94-2197. American Institute of Aeronautics and Astronautics, </institution> <year> 1994. </year>
Reference-contexts: "dependent" variables with respect to differentiation, ADIFOR produces portable Fortran 77 code that allows the computation of the derivatives of the dependent variables with respect to the independent ones. 3 Interface Contraction Automatic differentiation tools such as ADIFOR produce derivative code that typically outperforms divided difference approximations (see, for example, <ref> [1, 3, 5, 6, 18] </ref>), but, not surprisingly, is usually much less efficient than a hand-derived code probably could be. fl We introduce a technique, called "interface contraction," that can dramatically reduce the runtime and storage requirements for computing derivatives via automatic differentiation.
Reference: [7] <author> Bruce W. Char, Keith O. Geddes, Gaston H. Gonnet, Michael B. Monagan, and Stephen M. Watt. </author> <title> MAPLE Reference Manual. </title> <publisher> Watcom Publications, </publisher> <address> Waterloo, Ontario Canada, </address> <year> 1988. </year>
Reference-contexts: For problems of limited size, symbolic manipulators, such as Maple <ref> [7] </ref>, are available. These programs can simplify the task of deriving an expression for derivatives and converting this expression into code, but they are typically unable to handle functions that are large or contain branches, loops, or subroutines. An alternative to these techniques is automatic differentiation [9,19].
Reference: [8] <author> E. A. C. Crouch and D. Spiegelman. </author> <title> The evaluation of integrals of the form R dt. Application to logistic-normal models. </title> <journal> Journal of the American Statistical Association, </journal> <volume> 85 </volume> <pages> 464-469, </pages> <year> 1990. </year>
Reference-contexts: The likelihood functions take into account measurement error in total energy and binary misclassification in saturated fat and alcohol intake, and include an integral that is evaluated numerically by using the algorithm of Crouch and Spiegelman <ref> [8] </ref>. The Hessian and gradient are needed for optimization of these nonlinear likelihood functions, and the Hessian is again needed to evaluate the variance-covariance matrix of the resulting maximum likelihood estimates. Two likelihood functions were fit to these data, a 33-parameter function and a 17-parameter function.
Reference: [9] <author> Andreas Griewank. </author> <title> On automatic differentiation. </title> <booktitle> In Mathematical Programming: Recent Developments and Applications, </booktitle> <pages> pages 83-108, </pages> <address> Amsterdam, 1989. </address> <publisher> Kluwer Academic Publishers. </publisher>
Reference-contexts: Automatic differentiation provides a mechanism for the automatic generation of code for the computation of derivatives, using the program for the evaluation of the function as input <ref> [9, 19] </ref>. However, when automatic differentiation is applied without insight into the program being processed, the derivative computation can be almost as expensive as divided differences, especially if the so-called forward mode is being used. <p> Thus, if we compute y = @ f @ y first, we can compute rf = y fi ry more efficiently. For computing the derivatives of scalar functions, the reverse mode of automatic differentiation is more efficient than the forward mode <ref> [9, 19] </ref>, so we can use it to compute the values of y.
Reference: [10] <author> Andreas Griewank, Christian Bischof, George Corliss, Alan Carle, and Karen Williamson. </author> <title> Derivative convergence of iterative equation solvers. </title> <journal> Optimization Methods and Software, </journal> <volume> 2 </volume> <pages> 321-355, </pages> <year> 1993. </year>
Reference-contexts: Its goal is the generation of efficient derivative codes with minimal human effort, Future research in CD will further explore how a computational scientist can exploit knowledge about a program (such as interface contraction) or an underlying algorithm (such as the solution of a nonlinear system of equations <ref> [10] </ref>) to reduce the cost of computing derivatives. Research in CD will also lead to the 8 development of a tool infrastructure to make it easier to employ this knowledge in building derivative codes.
Reference: [11] <author> Andreas Griewank, David Juedes, and Jay Srinivasan. ADOL-C, </author> <title> a package for the automatic differentiation of algorithms written in C/C++. </title> <type> Preprint MCS-P180-1190, </type> <institution> Mathematics and Computer Science Division, Argonne National Laboratory, </institution> <year> 1990. </year>
Reference-contexts: In particular, we mention GRESS [13], PADRE-2 [17], Odyssee [20], and ADIFOR [2] for Fortran programs and ADOL-C <ref> [11] </ref> and ADIC [4] for C programs. We employed the ADIFOR tool in our experiments. ADIFOR (Automatic Differentiation of Fortran) [2] provides automatic differentiation for programs written in Fortran 77.
Reference: [12] <author> J. J. Hack. </author> <title> Peak vs. sustained performance in highly concurrent vector machines. </title> <journal> Computing, </journal> <volume> 19(9) </volume> <pages> 9-19, </pages> <year> 1986. </year>
Reference-contexts: The 17 fi 17 (33 fi 33) Hessian is obtained at the cost of about 55 (260) function evaluations. The fact that interface contraction does worse, in comparison with the analytic approach, for Hessians is due to an effect akin to that described by Amdahl's law <ref> [12] </ref>. For the 17-parameter problem, the cost of the black-box version of the first- (second-) derivative code of integr can be expected to be approximately 17 2 = 8:5 ( (2fl2) 75) times that of the interface contraction version.
Reference: [13] <author> Jim E. Horwedel. GRESS: </author> <title> A preprocessor for sensitivity studies on Fortran programs. </title> <editor> In Andreas Griewank and George F. Corliss, editors, </editor> <title> Automatic Differentiation of Algorithms: Theory, </title> <booktitle> Implementation, and Application, </booktitle> <pages> pages 243-250. </pages> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1991. </year>
Reference-contexts: There is also a reverse mode of automatic differentiation, which propagates derivatives of the dependent variables with respect to the intermediate variables. 2 Several tools have been developed that use automatic differentiation for the computation of derivatives [16]. In particular, we mention GRESS <ref> [13] </ref>, PADRE-2 [17], Odyssee [20], and ADIFOR [2] for Fortran programs and ADOL-C [11] and ADIC [4] for C programs. We employed the ADIFOR tool in our experiments. ADIFOR (Automatic Differentiation of Fortran) [2] provides automatic differentiation for programs written in Fortran 77.
Reference: [14] <author> Paul Hovland, Christian Bischof, and Alan Carle. </author> <title> Using ADIFOR to compute Hessians. </title> <type> Technical Report ANL/MCS-TM-192, </type> <institution> Mathematics and Computer Science Division, Argonne National Laboratory, </institution> <note> 1995 (in press). </note>
Reference-contexts: Two likelihood functions were fit to these data, a 33-parameter function and a 17-parameter function. Although the current version of ADIFOR does not support second derivatives, we were able to apply ADIFOR twice to produce code for computing the Hessian (see <ref> [14] </ref> for more details). This method for computing second derivatives is somewhat tedious, and not optimal from a complexity point of view, but does produce correct results. Direct support for second derivatives will be provided in a future release of ADIFOR.
Reference: [15] <author> Masao Iri. </author> <title> History of Automatic Differentiation and Rounding Estimation. </title> <editor> In Andreas Griewank and George F. Corliss, editors, </editor> <title> Automatic Differentiation of Algorithms: Theory, </title> <booktitle> Implementation, and Application, </booktitle> <pages> pages 1-16. </pages> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1991. </year>
Reference-contexts: Hence, the potential speedup due to interface contraction is (n=m) 2 rather than just n=m. We note that a similar approach to interface contraction was mentioned by Iri <ref> [15] </ref> as a "vertex cut" when considering automatic differentiation as applied to a computational graph representation of a program. 3.1 Microscopic Interface Contraction A simple case of interface contraction occurs for every complex assignment statement in a program.
Reference: [16] <author> David Juedes. </author> <title> A taxonomy of automatic differentiation tools. </title> <editor> In Andreas Griewank and George Corliss, editors, </editor> <booktitle> Proceedings of the Workshop on Automatic Differentiation of Algorithms: Theory, Implementation, and Application, </booktitle> <pages> pages 315-330, </pages> <address> Philadelphia, </address> <year> 1991. </year> <note> SIAM. </note>
Reference-contexts: There is also a reverse mode of automatic differentiation, which propagates derivatives of the dependent variables with respect to the intermediate variables. 2 Several tools have been developed that use automatic differentiation for the computation of derivatives <ref> [16] </ref>. In particular, we mention GRESS [13], PADRE-2 [17], Odyssee [20], and ADIFOR [2] for Fortran programs and ADOL-C [11] and ADIC [4] for C programs. We employed the ADIFOR tool in our experiments. ADIFOR (Automatic Differentiation of Fortran) [2] provides automatic differentiation for programs written in Fortran 77.
Reference: [17] <author> Koichi Kubota. PADRE2, </author> <title> a FORTRAN precompiler yielding error estimates and second derivatives. </title> <editor> In Andreas Griewank and George F. Corliss, editors, </editor> <title> Automatic Differentiation of Algorithms: Theory, </title> <booktitle> Implementation, and Application, </booktitle> <pages> pages 251-262. </pages> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1991. </year>
Reference-contexts: There is also a reverse mode of automatic differentiation, which propagates derivatives of the dependent variables with respect to the intermediate variables. 2 Several tools have been developed that use automatic differentiation for the computation of derivatives [16]. In particular, we mention GRESS [13], PADRE-2 <ref> [17] </ref>, Odyssee [20], and ADIFOR [2] for Fortran programs and ADOL-C [11] and ADIC [4] for C programs. We employed the ADIFOR tool in our experiments. ADIFOR (Automatic Differentiation of Fortran) [2] provides automatic differentiation for programs written in Fortran 77.
Reference: [18] <author> Seon Ki Park, Kelvin Droegemeier, Christian Bischof, and Tim Knauff. </author> <title> Sensitivity analysis of numerically-simulated convective storms using direct and adjoint methods. </title> <booktitle> In Preprints, 10th Conference on Numerical Weather Prediction, Portland, Oregon, </booktitle> <pages> pages 457-459. </pages> <publisher> American Meteorological Society, </publisher> <year> 1994. </year>
Reference-contexts: "dependent" variables with respect to differentiation, ADIFOR produces portable Fortran 77 code that allows the computation of the derivatives of the dependent variables with respect to the independent ones. 3 Interface Contraction Automatic differentiation tools such as ADIFOR produce derivative code that typically outperforms divided difference approximations (see, for example, <ref> [1, 3, 5, 6, 18] </ref>), but, not surprisingly, is usually much less efficient than a hand-derived code probably could be. fl We introduce a technique, called "interface contraction," that can dramatically reduce the runtime and storage requirements for computing derivatives via automatic differentiation.
Reference: [19] <author> Louis B. Rall. </author> <title> Automatic Differentiation: Techniques and Applications, </title> <booktitle> volume 120 of Lecture Notes in Computer Science. </booktitle> <publisher> Springer Verlag, </publisher> <address> Berlin, </address> <year> 1981. </year>
Reference-contexts: Automatic differentiation provides a mechanism for the automatic generation of code for the computation of derivatives, using the program for the evaluation of the function as input <ref> [9, 19] </ref>. However, when automatic differentiation is applied without insight into the program being processed, the derivative computation can be almost as expensive as divided differences, especially if the so-called forward mode is being used. <p> Thus, if we compute y = @ f @ y first, we can compute rf = y fi ry more efficiently. For computing the derivatives of scalar functions, the reverse mode of automatic differentiation is more efficient than the forward mode <ref> [9, 19] </ref>, so we can use it to compute the values of y.
Reference: [20] <author> Nicole Rostaing, Stephane Dalmas, and Andre Galligo. </author> <title> Automatic differentiation in Odyssee. </title> <address> Tellus, 45a(5):558-568, </address> <month> October </month> <year> 1993. </year>
Reference-contexts: There is also a reverse mode of automatic differentiation, which propagates derivatives of the dependent variables with respect to the intermediate variables. 2 Several tools have been developed that use automatic differentiation for the computation of derivatives [16]. In particular, we mention GRESS [13], PADRE-2 [17], Odyssee <ref> [20] </ref>, and ADIFOR [2] for Fortran programs and ADOL-C [11] and ADIC [4] for C programs. We employed the ADIFOR tool in our experiments. ADIFOR (Automatic Differentiation of Fortran) [2] provides automatic differentiation for programs written in Fortran 77.
Reference: [21] <author> W. C. Willett, et al. </author> <title> Dietary fat and fiber in relation to risk of breast cancer. </title> <journal> Journal of the American Medical Association, </journal> <volume> 268 </volume> <pages> 2037-2044, </pages> <year> 1992. </year> <month> 10 </month>
Reference-contexts: These functions were motivated by a problem in nutritional epidemiology investigating the relationships of age and dietary intakes of saturated fat, total energy, and alcohol with the four-year risk of developing breast cancer in a prospective cohort of 89,538 nurses <ref> [21] </ref>. The likelihood functions take into account measurement error in total energy and binary misclassification in saturated fat and alcohol intake, and include an integral that is evaluated numerically by using the algorithm of Crouch and Spiegelman [8].
References-found: 21

