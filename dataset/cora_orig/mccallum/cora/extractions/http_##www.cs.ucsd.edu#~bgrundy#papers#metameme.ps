URL: http://www.cs.ucsd.edu/~bgrundy/papers/metameme.ps
Refering-URL: http://www.cs.ucsd.edu/~bgrundy/papers/metameme.html
Root-URL: http://www.cs.ucsd.edu
Email: bgrundy@cs.ucsd.edu  tbailey@sdsc.edu  elkan@cs.ucsd.edu  mbaker@ucsd.edu  
Phone: FAX (619) 534-7029  FAX (619) 534-5127  FAX (619) 534-7029  FAX (619) 534-1424  
Title: Meta-MEME: Motif-based Hidden Markov Models of Protein Families  
Author: William N. Grundy Timothy L. Bailey Charles P. Elkan Michael E. Baker 
Note: Computer Applications in the Biosciences, 13(4):397-406, 1997. Corresponding author.  
Address: San Diego (619) 453-4364 La Jolla, California 92093-0114  P.O. Box 85608 (619) 534-8350 San Diego, California 92186-9784  San Diego (619) 534-8897 La Jolla, California 92093-0114  San Diego (619) 534-4164 La Jolla, CA 92093-0623  
Affiliation: Department of Computer Science and Engineering University of California,  San Diego Supercomputer Center  Department of Computer Science and Engineering University of California,  Department of Medicine University of California,  
Abstract-found: 0
Intro-found: 1
Reference: <institution> References </institution>
Reference: [Altschul et al., 1989] <author> Altschul, S. F., Carroll, R. J., and Lipman, D. J. </author> <year> (1989). </year> <title> Weights for data related by a tree. </title> <journal> Journal of Molecular Biology, </journal> 207(4) 647-53. 
Reference: [Bailey and Elkan, 1995a] <author> Bailey, T. L. and Elkan, C. P. </author> <year> (1995a). </year> <title> Unsupervised learning of multiple motifs in biopolymers using EM. Machine Learning, </title> <publisher> 21(1-2):51-80. </publisher>
Reference-contexts: This paper addresses that need by developing hidden Markov models which precisely model only the highly conserved regions of a family of sequences. These motif-based HMMs consist primarily of motif models generated by MEME (Multiple EM for Motif Elicitation) <ref> [Bailey and Elkan, 1995a, Bailey and Elkan, 1995b] </ref>. Meta-MEME is a software tool for combining MEME motif models within a standard linear HMM framework. Because Meta-MEME operates in an automated fashion, it is particularly useful for analyzing the increasingly large sequence databases becoming available.
Reference: [Bailey and Elkan, 1995b] <author> Bailey, T. L. and Elkan, C. P. </author> <year> (1995b). </year> <title> The value of prior knowledge in discovering motifs with MEME. </title> <editor> In Rawlings, C., Clark, D., Altman, R., Hunter, L. C., and Rawlings, L. C., editors, </editor> <booktitle> Proceedings of the Third International Conference on Intelligent Systems for Molecular Biology, </booktitle> <pages> pages 21-29. </pages> <publisher> AAAI Press. </publisher>
Reference-contexts: This paper addresses that need by developing hidden Markov models which precisely model only the highly conserved regions of a family of sequences. These motif-based HMMs consist primarily of motif models generated by MEME (Multiple EM for Motif Elicitation) <ref> [Bailey and Elkan, 1995a, Bailey and Elkan, 1995b] </ref>. Meta-MEME is a software tool for combining MEME motif models within a standard linear HMM framework. Because Meta-MEME operates in an automated fashion, it is particularly useful for analyzing the increasingly large sequence databases becoming available.
Reference: [Bailey and Gribskov, 1996] <author> Bailey, T. L. and Gribskov, M. </author> <year> (1996). </year> <title> The megaprior heuristic for discovering protein sequence patterns. </title> <editor> In States, D. J., Agarwal, P., Gaasterland, T., Hunter, L., and Smith, R., editors, </editor> <booktitle> Proceedings of the Fourth International Conference on Intelligent Systems for Molecular Biology, </booktitle> <pages> pages 15-24. </pages> <publisher> AAAI Press. </publisher>
Reference-contexts: We use Dirichlet mixtures for prior probabilities, modified by the megaprior heuristic <ref> [Bailey and Gribskov, 1996] </ref>. The minimum width of a motif is specified as 12 (although the motifs returned may be shorter than this, due to a shortening heuristic in MEME), and the maximum width is 55.
Reference: [Bailey and Gribskov, 1997] <author> Bailey, T. L. and Gribskov, M. </author> <year> (1997). </year> <title> Combining evidence using p-values: application to sequence homology searches. </title> <note> Computer Applications in the Biosciences. To appear. </note>
Reference-contexts: In order to use the standard HMM framework, the motifs must be arranged in a linear fashion. Ideally, the order and spacing of motifs should reflect the canonical order and spacing of motifs in the family. The Motif Annotation and Search Tool (MAST) <ref> [Bailey and Gribskov, 1997] </ref> is part of the MEME software distribution [MEME, 1996]. MAST searches a database for motif occurrences and assigns a score to each sequence based upon the sequence's most likely match to each of the given motifs.
Reference: [Bairoch, 1992] <author> Bairoch, A. </author> <year> (1992). </year> <title> PROSITE: a dictionary of sites and patterns in proteins. </title> <journal> Nucleic Acids Research, </journal> <volume> 20 </volume> <pages> 2013-2018. </pages>
Reference-contexts: We also applied Meta-MEME to a set of 4Fe-4S ferredoxins. The family members are listed in Appendix B. These 159 sequences comprise all known 4Fe-4S ferredoxins in SWISSPROT release 33 [Bairoch, 1994]. Family members were selected using PROSITE 13.1 <ref> [Bairoch, 1992] </ref>. Ten additional members were added to the family, based upon ROC analysis and sequence comparisons. The SWISSPROT identifiers for all 159 sequences, as well as the justifications for including the ten additional sequences, are given in Appendix B.
Reference: [Bairoch, 1994] <author> Bairoch, A. </author> <year> (1994). </year> <title> The SWISS-PROT protein sequence data bank: current status. </title> <journal> Nucleic Acids Research, </journal> <volume> 22(17) </volume> <pages> 3578-3580. </pages>
Reference-contexts: These thirty-eight sequences represent a small portion of the approximately 650 known dehydrogenases in genpept release 95 [GenBank, 1997]. We also applied Meta-MEME to a set of 4Fe-4S ferredoxins. The family members are listed in Appendix B. These 159 sequences comprise all known 4Fe-4S ferredoxins in SWISSPROT release 33 <ref> [Bairoch, 1994] </ref>. Family members were selected using PROSITE 13.1 [Bairoch, 1992]. Ten additional members were added to the family, based upon ROC analysis and sequence comparisons. The SWISSPROT identifiers for all 159 sequences, as well as the justifications for including the ten additional sequences, are given in Appendix B.
Reference: [Baker, 1975] <author> Baker, J. K. </author> <year> (1975). </year> <title> The Dragon system | an overview. </title> <journal> IEEE Trans. Acoust. Speech Signal Processing, ASSP-23(1):24-29. </journal>
Reference-contexts: 1 Introduction A hidden Markov model describes a series of observations by a "hidden" stochastic process. Although introduced relatively recently to computational molecular biology [Churchill, 1989], HMMs have been in use for speech recognition for many years <ref> [Baker, 1975] </ref>. In speech recognition, the series of observations being modeled is a spoken utterance; in computational biology, the series of observations is a biological sequence. One immediately apparent difference between these two domains is the amount of available training data.
Reference: [Baker, 1994] <author> Baker, M. E. </author> <year> (1994). </year> <title> Sequence analysis of steroid and prostaglandin metabolizing enzymes: application to understanding catalysis. </title> <journal> Steroids, </journal> <volume> 59 </volume> <pages> 248-258. </pages>
Reference-contexts: We chose this data set because it is large and phylogenetically diverse <ref> [Persson et al., 1991, Baker, 1994, Baker, 1996] </ref>, providing a good test of the sensitivity and selectivity of Meta-MEME on a protein family of biological interest. The thirty-eight sequences used in the training set are listed in Appendix A.
Reference: [Baker, 1996] <author> Baker, M. E. </author> <year> (1996). </year> <title> Unusual evolution of mammalian 11fi- and 17fi-hydroxysteroid and retinol dehydrogenases. </title> <journal> Bioessays, </journal> <volume> 18 </volume> <pages> 63-70. </pages>
Reference-contexts: We chose this data set because it is large and phylogenetically diverse <ref> [Persson et al., 1991, Baker, 1994, Baker, 1996] </ref>, providing a good test of the sensitivity and selectivity of Meta-MEME on a protein family of biological interest. The thirty-eight sequences used in the training set are listed in Appendix A.
Reference: [Baldi et al., 1994] <author> Baldi, P., Chauvin, Y., Hunkapiller, T., and McClure, M. A. </author> <year> (1994). </year> <title> Hidden Markov models of biological primary sequence information. </title> <booktitle> Proceedings of the National Academy of Sciences of the United States of America, </booktitle> <volume> 91(3) </volume> <pages> 1059-1063. </pages>
Reference-contexts: Although this type of model may fail to accurately model genetic copying events, the enforced linearity allows for efficient training of the models. Standard HMMs have been most successfully applied to the task of characterizing families of proteins containing a relatively large number of known sequences <ref> [Krogh et al., 1994, Baldi et al., 1994, Eddy, 1995] </ref>. For families in which fewer sequences are known, a standard HMM contains too many parameters to be trained to precision.
Reference: [BLOCKS, 1997] <institution> BLOCKS (1997). </institution> <note> Blocks WWW server. http://www.blocks.fhcrc.org. </note>
Reference-contexts: Since motifs (and blocks) are supposed to model ungapped regions, MEME generally produces more accurate models. The BLOCKS database <ref> [BLOCKS, 1997] </ref> contains, for each known protein family, an ordered set of blocks along with the minimum and maximum observed spacings between the blocks in the training set.
Reference: [Branden and Tooze, 1991] <author> Branden, C. and Tooze, J. </author> <year> (1991). </year> <title> Introduction to protein structure. </title> <publisher> Garland. </publisher>
Reference: [Brown et al., 1995] <author> Brown, M., Hughey, R., Krogh, A., Mian, I., Sjolander, K., and Haussler, D. </author> <year> (1995). </year> <title> Using dirichlet mixture priors to derive hidden Markov models for protein families. </title> <editor> In et al., C. R., editor, </editor> <booktitle> Proceedings of the Third International Conference on Intelligent Systems for Molecular Biology, </booktitle> <pages> pages 47-55. </pages> <publisher> AAAI Press. </publisher>
Reference-contexts: A model based upon a smaller data set may overfit the data, modelling details specific to the training set but not to the larger protein family. In order to avoid overfitting, standard HMMs often rely upon a set of Bayesian prior probabilities <ref> [Brown et al., 1995, Sjolander et al., 1996] </ref>. In this case, however, with a small training set and a large model, the trained model may depend upon the prior probabilities more than it reflects the training sequences.
Reference: [Chothia and Lesk, 1986] <author> Chothia, C. and Lesk, A. M. </author> <year> (1986). </year> <title> The relation between the divergence of sequence and structure in proteins. </title> <journal> EMBO Journal, </journal> <volume> 5 </volume> <pages> 823-826. </pages>
Reference-contexts: Error bars represent standard error. tiates homologs from unrelated proteins which contain isolated fragments resembling sequences in the training set. Comparison of protein 3D structures is the most sensitive method for determining homology <ref> [Chothia and Lesk, 1986] </ref>. This explains Meta-MEME's excellent ability to recognize alcohol dehydrogenase homologs as seen in Figure 4 (a). The motifs discovered using smaller training sets correspond strongly to the original motifs found using the largest training set.
Reference: [Churchill, 1989] <author> Churchill, G. A. </author> <year> (1989). </year> <title> Stochastic models for heterogeneous DNA sequences. </title> <journal> Bulletin of Mathematical Biology, </journal> <volume> 51 </volume> <pages> 79-94. </pages>
Reference-contexts: 1 Introduction A hidden Markov model describes a series of observations by a "hidden" stochastic process. Although introduced relatively recently to computational molecular biology <ref> [Churchill, 1989] </ref>, HMMs have been in use for speech recognition for many years [Baker, 1975]. In speech recognition, the series of observations being modeled is a spoken utterance; in computational biology, the series of observations is a biological sequence. <p> Standard HMMs for molecular biology Hidden Markov models were first applied to problems in molecular biology by <ref> [Churchill, 1989] </ref>. [Krogh et al., 1994] applied HMMs to protein modeling and brought widespread recognition to the approach. We refer to the linear HMMs described in that paper as "standard HMMs". The structure of these HMMs attempts to reflect the process of evolution.
Reference: [Eddy, 1995] <author> Eddy, S. R. </author> <year> (1995). </year> <title> Multiple alignment using hidden Markov models. </title> <editor> In et al., C. R., editor, </editor> <booktitle> Proceedings of the Third International Conference on Intelligent Systems for Molecular Biology, </booktitle> <pages> pages 114-120. </pages> <publisher> AAAI Press. </publisher>
Reference-contexts: Although this type of model may fail to accurately model genetic copying events, the enforced linearity allows for efficient training of the models. Standard HMMs have been most successfully applied to the task of characterizing families of proteins containing a relatively large number of known sequences <ref> [Krogh et al., 1994, Baldi et al., 1994, Eddy, 1995] </ref>. For families in which fewer sequences are known, a standard HMM contains too many parameters to be trained to precision. <p> An ideal HMM would pick out all and only the members of the family from the rest of the database. This database search can be carried out using existing software. Two standard HMM packages are freely available, SAM [Hughey and Krogh, 1996, SAM, 1997] and HMMER <ref> [Eddy, 1995, HMMER, 1997] </ref>. Although the SAM package allows for slightly more complicated models, HMMER is more appropriate for our needs because it includes a variety of searching algorithms. 4 2 ALGORITHM the gray background nodes would appear in a standard HMM but are unreachable in this HMM.
Reference: [Eddy et al., 1995] <author> Eddy, S. R., Mitchison, G., and Durbin, R. </author> <year> (1995). </year> <title> Maximum discrimination hidden Markov models of sequence consensus. </title> <journal> Journal of Computational Biology, </journal> <volume> 2 </volume> <pages> 9-23. </pages>
Reference-contexts: Several researchers have shown that weighting schemes, which attempt to compensate for bias in the training set by assigning weights to individual sequences, may significantly improve the performance of database searching algorithms [Henikoff and Henikoff, 1994a, Altschul et al., 1989, Sibbald and Argos, 1990, Thompson et al., 1994]. <ref> [Eddy et al., 1995] </ref> have developed a maximum discrimination training algorithm for hidden Markov models which addresses the same problem. Use of such methods may also provide a means of improving Meta-MEME's performance. We hope to improve Meta-MEME's models in several ways.
Reference: [GenBank, 1997] <institution> GenBank (1997). </institution> <note> GenBank overview. http://www.ncbi.nlm.nih.gov/Web/Genbank/- index.html. REFERENCES 13 </note>
Reference-contexts: Many sequences are less than 20% identical after use of gaps and insertions. These thirty-eight sequences represent a small portion of the approximately 650 known dehydrogenases in genpept release 95 <ref> [GenBank, 1997] </ref>. We also applied Meta-MEME to a set of 4Fe-4S ferredoxins. The family members are listed in Appendix B. These 159 sequences comprise all known 4Fe-4S ferredoxins in SWISSPROT release 33 [Bairoch, 1994]. Family members were selected using PROSITE 13.1 [Bairoch, 1992].
Reference: [Gribskov et al., 1990] <author> Gribskov, M., Luthy, R., and Eisenberg, D. </author> <year> (1990). </year> <title> Profile analysis. </title> <booktitle> Methods in Enzymology, </booktitle> <volume> 183 </volume> <pages> 146-159. </pages>
Reference-contexts: The core of the standard model is a sequence of states, called "match states," which represent the canonical sequence for this family. Each match state corresponds to one position in the canonical sequence. This series of states is similar to a profile <ref> [Gribskov et al., 1990] </ref>, since each state contains a frequency distribution across the entire alphabet. The probabilities that a given state emits each possible base are taken from this frequency distribution and are called the "emission probabilities" for that state.
Reference: [Gribskov and Robinson, 1996] <author> Gribskov, M. and Robinson, N. L. </author> <year> (1996). </year> <title> Use of receiver operating characteristic (ROC) analysis to evaluate sequence matching. </title> <journal> Computers and Chemistry, </journal> <volume> 20(1) </volume> <pages> 25-33. </pages>
Reference-contexts: Unfortunately, for large database searches, the number of negatives far exceeds the number of positives, so ROC values must be computed to a high degree of precision. A similar statistic, ROC 50 <ref> [Gribskov and Robinson, 1996] </ref>, provides a wider spread of values. ROC 50 is the area under the ROC curve plotted until 50 false positives are found.
Reference: [Grundy et al., 1996] <author> Grundy, W. N., Bailey, T. L., and Elkan, C. P. </author> <year> (1996). </year> <title> ParaMEME: A parallel implementation and a web interface for a DNA and protein motif discovery tool. </title> <booktitle> Computer Applications in the Biosciences, </booktitle> <volume> 12(4) </volume> <pages> 303-310. </pages>
Reference-contexts: Given such a set of sequences, MEME outputs one or more probabilistic models of motifs found in the data. The models consist of a frequency matrix and are therefore similar to a gapless profile. A parallelized version of MEME running on a supercomputer is available on the World-Wide Web <ref> [Grundy et al., 1996, MEME, 1997] </ref>. MEME motifs provide reliable indicators of family membership. If trained on a set of related sequences, MEME will build motif models of the most highly conserved regions in that data set.
Reference: [Henikoff and Henikoff, 1996] <author> Henikoff, J. G. and Henikoff, S. </author> <year> (1996). </year> <title> Blocks database and its applications. </title> <booktitle> Methods in Enzymology, </booktitle> <pages> 266. </pages>
Reference-contexts: Meta-MEME focuses on these regions and does not attempt to model the less-conserved, intermediate regions in detail. In many ways, Meta-MEME resembles the BLOCKS method for protein family classification <ref> [Henikoff and Henikoff, 1994b, Henikoff and Henikoff, 1996] </ref>. The BLOCKMAKER program discovers highly conserved regions of protein families by combining motifs found by either the 2 1 INTRODUCTION MOTIF algorithm [Smith et al., 1990] or the Gibbs sampling algorithm [Lawrence et al., 1993].
Reference: [Henikoff and Henikoff, 1994a] <author> Henikoff, S. and Henikoff, J. G. </author> <year> (1994a). </year> <title> Position-based sequence weights. </title> <journal> Journal of Molecular Biology, </journal> <volume> 243 </volume> <pages> 574-578. </pages>
Reference: [Henikoff and Henikoff, 1994b] <author> Henikoff, S. and Henikoff, J. G. </author> <year> (1994b). </year> <title> Protein family classification based on searching a database of blocks. </title> <journal> Genomics, </journal> <volume> 19 </volume> <pages> 97-107. </pages>
Reference-contexts: Meta-MEME focuses on these regions and does not attempt to model the less-conserved, intermediate regions in detail. In many ways, Meta-MEME resembles the BLOCKS method for protein family classification <ref> [Henikoff and Henikoff, 1994b, Henikoff and Henikoff, 1996] </ref>. The BLOCKMAKER program discovers highly conserved regions of protein families by combining motifs found by either the 2 1 INTRODUCTION MOTIF algorithm [Smith et al., 1990] or the Gibbs sampling algorithm [Lawrence et al., 1993].
Reference: [Henikoff et al., 1995] <author> Henikoff, S., Henikoff, J. G., Alford, W. J., and Pietrokovski, S. </author> <year> (1995). </year> <title> Automated construction and graphical presentation of protein blocks from unaligned sequences. Gene-COMBIS, Gene, </title> <publisher> 163(GC):17-26. </publisher>
Reference-contexts: The BLOCKS database [BLOCKS, 1997] contains, for each known protein family, an ordered set of blocks along with the minimum and maximum observed spacings between the blocks in the training set. The BLIMPS program <ref> [Henikoff et al., 1995] </ref> searches this database using a single sequence as a query, thus taking into account the order and spacing of blocks. Clearly, Meta-MEME and the BLOCKS method share many features.
Reference: [HMMER, 1997] <author> HMMER (1997). S. R. </author> <title> Eddy group, </title> <institution> Dept. of Genetics, Washington University. </institution> <address> http://- genome.wustl.edu/eddy/hmm.html. </address>
Reference-contexts: An ideal HMM would pick out all and only the members of the family from the rest of the database. This database search can be carried out using existing software. Two standard HMM packages are freely available, SAM [Hughey and Krogh, 1996, SAM, 1997] and HMMER <ref> [Eddy, 1995, HMMER, 1997] </ref>. Although the SAM package allows for slightly more complicated models, HMMER is more appropriate for our needs because it includes a variety of searching algorithms. 4 2 ALGORITHM the gray background nodes would appear in a standard HMM but are unreachable in this HMM.
Reference: [Hughey and Krogh, 1996] <author> Hughey, R. and Krogh, A. </author> <year> (1996). </year> <title> Hidden Markov models for sequence analysis: Extension and analysis of the basic method. </title> <booktitle> Computer Applications in the Biosciences, </booktitle> <volume> 12(2) </volume> <pages> 95-107. </pages>
Reference-contexts: An ideal HMM would pick out all and only the members of the family from the rest of the database. This database search can be carried out using existing software. Two standard HMM packages are freely available, SAM <ref> [Hughey and Krogh, 1996, SAM, 1997] </ref> and HMMER [Eddy, 1995, HMMER, 1997].
Reference: [Krogh et al., 1994] <author> Krogh, A., Brown, M., Mian, I., Sjolander, K., and Haussler, D. </author> <year> (1994). </year> <title> Hidden Markov models in computational biology: Applications to protein modeling. </title> <journal> Journal of Molecular Biology, </journal> <volume> 235 </volume> <pages> 1501-1531. </pages>
Reference-contexts: Standard HMMs for molecular biology Hidden Markov models were first applied to problems in molecular biology by [Churchill, 1989]. <ref> [Krogh et al., 1994] </ref> applied HMMs to protein modeling and brought widespread recognition to the approach. We refer to the linear HMMs described in that paper as "standard HMMs". The structure of these HMMs attempts to reflect the process of evolution. <p> Although this type of model may fail to accurately model genetic copying events, the enforced linearity allows for efficient training of the models. Standard HMMs have been most successfully applied to the task of characterizing families of proteins containing a relatively large number of known sequences <ref> [Krogh et al., 1994, Baldi et al., 1994, Eddy, 1995] </ref>. For families in which fewer sequences are known, a standard HMM contains too many parameters to be trained to precision. <p> Many small families of biological sequences contain less than this number of characters in all known family members combined. Small families such as these cannot effectively train a standard linear HMM because reliable training requires that the number of samples greatly exceeds the number of free parameters. For example, <ref> [Krogh et al., 1994] </ref> mention a lower limit of approximately 70 carefully selected training sequences in order to adequately model the globin family. A model based upon a smaller data set may overfit the data, modelling details specific to the training set but not to the larger protein family.
Reference: [Lawrence et al., 1993] <author> Lawrence, C. E., Altschul, S. F., Boguski, M. S., Liu, J. S., Neuwald, A. F., and Wootton, J. C. </author> <year> (1993). </year> <title> Detecting subtle sequence signals: A Gibbs sampling strategy for multiple alignment. </title> <journal> Science, </journal> <volume> 262(5131) </volume> <pages> 208-214. </pages>
Reference-contexts: The BLOCKMAKER program discovers highly conserved regions of protein families by combining motifs found by either the 2 1 INTRODUCTION MOTIF algorithm [Smith et al., 1990] or the Gibbs sampling algorithm <ref> [Lawrence et al., 1993] </ref>. Individual blocks may be represented as ungapped position-specific scoring matrices, similar to the motif models created by MEME.
Reference: [MEME, 1996] <author> MEME (1996). </author> <title> MEME ANSI C source code. </title> <publisher> ftp://cs.ucsd.edu/pub/tbailey/meme. </publisher>
Reference-contexts: Ideally, the order and spacing of motifs should reflect the canonical order and spacing of motifs in the family. The Motif Annotation and Search Tool (MAST) [Bailey and Gribskov, 1997] is part of the MEME software distribution <ref> [MEME, 1996] </ref>. MAST searches a database for motif occurrences and assigns a score to each sequence based upon the sequence's most likely match to each of the given motifs.
Reference: [MEME, 1997] <author> MEME (1997). </author> <title> MEME multiple EM for motif elicitation. </title> <address> http://www.sdsc.edu/MEME. </address>
Reference-contexts: Given such a set of sequences, MEME outputs one or more probabilistic models of motifs found in the data. The models consist of a frequency matrix and are therefore similar to a gapless profile. A parallelized version of MEME running on a supercomputer is available on the World-Wide Web <ref> [Grundy et al., 1996, MEME, 1997] </ref>. MEME motifs provide reliable indicators of family membership. If trained on a set of related sequences, MEME will build motif models of the most highly conserved regions in that data set.
Reference: [Neuwald and Green, 1994] <author> Neuwald, A. F. and Green, P. </author> <year> (1994). </year> <title> Detecting patterns in protein sequences. </title> <journal> Journal of Molecular Biology, </journal> <volume> 239(5) </volume> <pages> 698-712. </pages>
Reference-contexts: These biases would explain the relatively large standard error bars in Figure 4 (b). Such biases could have been reduced by first removing highly similar sequences using a program such as PURGE <ref> [Neuwald and Green, 1994] </ref>. In addition to reducing training set bias, this approach reduces the amount of computation required during training.
Reference: [Persson et al., 1991] <author> Persson, B., Krook, M., and Jornvall, H. </author> <year> (1991). </year> <title> Characteristics of short chain alcohol dehydrogenases and related enzymes. </title> <journal> European Journal of Biochemistry, </journal> 200(53) 7-543. 
Reference-contexts: We chose this data set because it is large and phylogenetically diverse <ref> [Persson et al., 1991, Baker, 1994, Baker, 1996] </ref>, providing a good test of the sensitivity and selectivity of Meta-MEME on a protein family of biological interest. The thirty-eight sequences used in the training set are listed in Appendix A.
Reference: [Rabiner, 1995] <author> Rabiner, L. R. </author> <year> (1995). </year> <title> A tutorial on hidden Markov models and selected applications in speech recognition. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 77(2) </volume> <pages> 257-286. </pages>
Reference-contexts: These two probability distributions, when combined with the initial state distribution, completely characterize an HMM. A useful HMM tutorial was written by Rabiner <ref> [Rabiner, 1995] </ref>, and more detailed information is available in [Rabiner and Juang, 1993].
Reference: [Rabiner and Juang, 1993] <author> Rabiner, L. R. and Juang, B. </author> <year> (1993). </year> <title> Fundamentals of speech recognition. </title> <publisher> Pren-tice Hall. </publisher>
Reference-contexts: These two probability distributions, when combined with the initial state distribution, completely characterize an HMM. A useful HMM tutorial was written by Rabiner [Rabiner, 1995], and more detailed information is available in <ref> [Rabiner and Juang, 1993] </ref>.
Reference: [SAM, 1997] <author> SAM (1997). SAM: </author> <title> sequence alignment and modeling system. </title> <address> http://www.cse.ucsc.edu/- research/compbio/sam.html. </address>
Reference-contexts: An ideal HMM would pick out all and only the members of the family from the rest of the database. This database search can be carried out using existing software. Two standard HMM packages are freely available, SAM <ref> [Hughey and Krogh, 1996, SAM, 1997] </ref> and HMMER [Eddy, 1995, HMMER, 1997].
Reference: [Sibbald and Argos, 1990] <author> Sibbald, P. R. and Argos, P. </author> <year> (1990). </year> <title> Weighting aligned protein or nucleic acid sequences to correct for unequal representation. </title> <journal> Journal of Molecular Biology, </journal> <volume> 216(4) </volume> <pages> 813-8. </pages>
Reference: [Sjolander et al., 1996] <author> Sjolander, K., Karplus, K., Brown, M., Hughey, R., Krogh, A., Mian, I. S., and Haussler, D. </author> <year> (1996). </year> <title> Dirichlet mixtures: A method for improving detection of weak but significant protein sequence homology. COS. </title> <type> 14 REFERENCES </type>
Reference-contexts: A model based upon a smaller data set may overfit the data, modelling details specific to the training set but not to the larger protein family. In order to avoid overfitting, standard HMMs often rely upon a set of Bayesian prior probabilities <ref> [Brown et al., 1995, Sjolander et al., 1996] </ref>. In this case, however, with a small training set and a large model, the trained model may depend upon the prior probabilities more than it reflects the training sequences.
Reference: [Smith et al., 1990] <author> Smith, H. O., Annau, T. M., and Chandrasegaran, S. </author> <year> (1990). </year> <title> Finding sequence motifs in groups of functionally related proteins. </title> <booktitle> Proceedings of the National Academy of Sciences of the United States of America, </booktitle> <volume> 87 </volume> <pages> 826-830. </pages>
Reference-contexts: In many ways, Meta-MEME resembles the BLOCKS method for protein family classification [Henikoff and Henikoff, 1994b, Henikoff and Henikoff, 1996]. The BLOCKMAKER program discovers highly conserved regions of protein families by combining motifs found by either the 2 1 INTRODUCTION MOTIF algorithm <ref> [Smith et al., 1990] </ref> or the Gibbs sampling algorithm [Lawrence et al., 1993]. Individual blocks may be represented as ungapped position-specific scoring matrices, similar to the motif models created by MEME.
Reference: [Thompson et al., 1994] <author> Thompson, J. D., Higgins, D. G., and Gibson, T. J. </author> <year> (1994). </year> <title> Improved sensitivity of profile searches through the use of sequence weights and gap excision. </title> <booktitle> Computer Applications in the Biosciences, </booktitle> <volume> 10(1) </volume> <pages> 19-29. </pages>
Reference: [Wierenga et al., 1985] <author> Wierenga, R. K., Maeyer, M. C. D., and Hol, W. G. J. </author> <year> (1985). </year> <title> Interaction of pyrophosphate moieties with ff-helices in dinucleotide binding proteins. </title> <journal> Biochemistry, </journal> <volume> 24 </volume> <pages> 1346-1357. </pages>
Reference: [Wierenga et al., 1986] <author> Wierenga, R. K., Terpstra, P. P., and Hol, W. G. J. </author> <year> (1986). </year> <title> Prediction of the occurrence of the ADP-binding fi-ff-fi-fold in proteins using an amino acid sequence fingerprint. </title> <journal> Journal of Molecular Biology, </journal> <volume> 187 </volume> <pages> 101-107. </pages>
Reference: [Woodland et al., 1994] <author> Woodland, P. C., Odell, J. J., Valtchev, V., and Young, S. J. </author> <year> (1994). </year> <title> Large vocabulary continuous speech recognition using HTK. </title> <booktitle> In IEEE International Conference on Acoustics, Speech and Signal Processing, </booktitle> <volume> volume 2, </volume> <pages> pages 125-128. </pages> <publisher> IEEE. </publisher> <pages> 15 </pages>
Reference-contexts: Even for speech recognition systems, for which the training set size is relatively large, researchers attempt to simplify their models in order to reduce the number of trainable parameters <ref> [Woodland et al., 1994] </ref>. When modeling biological sequences, the need for smaller models is even more pronounced. This paper addresses that need by developing hidden Markov models which precisely model only the highly conserved regions of a family of sequences.
References-found: 45

