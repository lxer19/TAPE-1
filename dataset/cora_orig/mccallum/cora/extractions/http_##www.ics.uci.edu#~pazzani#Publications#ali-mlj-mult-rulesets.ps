URL: http://www.ics.uci.edu/~pazzani/Publications/ali-mlj-mult-rulesets.ps
Refering-URL: http://www.ics.uci.edu/~mlearn/MLPapers.html
Root-URL: 
Email: ali@ics.uci.edu, pazzani@ics.uci.edu  
Title: Error Reduction through Learning Multiple Descriptions  
Author:  K. ALI AND M. PAZZANI KAMAL M. ALI AND MICHAEL J. PAZZANI Editor: Lorenza Saitta 
Keyword: Multiple models, Combining classifiers  
Address: Irvine, CA 92717.  
Affiliation: Department of Information and Computer Science, University of California,  
Abstract: Learning multiple descriptions for each class in the data has been shown to reduce generalization error but the amount of error reduction varies greatly from domain to domain. This paper presents a novel empirical analysis that helps to understand this variation. Our hypothesis is that the amount of error reduction is linked to the "degree to which the descriptions for a class make errors in a correlated manner." We present a precise and novel definition for this notion and use twenty-nine data sets to show that the amount of observed error reduction is negatively correlated with the degree to which the descriptions make errors in a correlated manner. We empirically show that it is possible to learn descriptions that make less correlated errors in domains in which many ties in the search evaluation measure (e.g. information gain) are experienced during learning. The paper also presents results that help to understand when and why multiple descriptions are a help (irrelevant attributes) and when they are not as much help (large amounts of class noise). 
Abstract-found: 1
Intro-found: 1
Reference: <author> Ali, K., & Pazzani, M. </author> <year> (1992.) </year> <title> Reducing the small disjuncts problem by learning probabilistic concept descriptions. </title> <editor> In Petsche, T., Judd, S. & Hanson, S. (Eds.), </editor> <booktitle> Computational Learning Theory and Natural Learning Systems, </booktitle> <volume> Vol. </volume> <pages> 3. </pages> <address> Cambridge, Massachusetts: </address> <publisher> MIT Press. </publisher>
Reference-contexts: The remainder of the paper is organized as follows. After an examination of the main issues in learning multiple models, we present our core learning algorithm HYDRA <ref> (Ali & Pazzani 1992,1993,1994) </ref> which we modify in various ways to learn multiple models. Next, we present results of experiments designed to answer the following questions: 1.
Reference: <author> Ali, K., & Pazzani, M. </author> <year> (1993.) </year> <title> HYDRA: </title> <booktitle> A Noise-tolerant Relational Concept Learning Algorithm In Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence Chambery, </booktitle> <address> France: </address> <publisher> Morgan Kaufmann. </publisher> <editor> Ali, K. & Pazzani, M. </editor> <year> (1995.) </year> <title> HYDRA-MM: Learning Multiple Descriptions to Improve Classification Accuracy International Journal on Artificial Intelligence Tools, </title> <type> 1 & 2, </type> <pages> 115-133. </pages>
Reference-contexts: Although these methods are not new, our goal is to show that our results pertaining to error reduction, correlatedness of errors and gain ties apply to more than one method of generating multiple models. We use HYDRA <ref> (Ali & Pazzani, 1993) </ref> to learn a single model consisting of a description for each class. HYDRA is based on extensions to FOIL 2 (Quinlan, 1990) proposed in Ali & Pazzani (1993) and Pazzani et al. (1991). HYDRA is then further modified to learn several models. <p> This is the algorithm used in HYDRA <ref> (Ali & Pazzani, 1993) </ref>.
Reference: <author> Ali, K., & Pazzani, M. </author> <year> (1995.) </year> <title> Learning Multiple Relational Rule-based Models. </title> <editor> In Fisher, D., & Lenz, H. (Eds.), </editor> <title> Learning from Data: </title> <journal> Artificial Intelligence and Statistics, </journal> <volume> Vol. </volume> <pages> 5. </pages> <address> Fort Lauderdale, FL: </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Briefly, models whose class descriptions are syntactically-compact and are well able to separate the training examples of different classes end up with higher posterior probabilities. Appendix 2 and <ref> (Ali & Pazzani, 1995) </ref> detail how Buntine's form for the posterior probability of a decision tree (Buntine, 1990) is adapted for the kinds of models described in this paper. The general Bayesian method is used in our "single, most reliable rule" framework as follows. <p> Modified-boosting (Freund & Schapire, 1995) designed to work with small data sets has not been proved empirically and may end up concentrating noisy examples in subsequent training sets. The only previous work involving learning relational multiple models <ref> (apart from our own, Ali & Pazzani, 1995) </ref> has been done by Kovacic (1994). Kovacic shows that learning multiple models by running mFOIL (Dzeroski, 1992) several times using simulated annealing yields significantly lower error rates than mFOIL on the KRK and Finite-element mesh data sets. 126 K. ALI AND M. <p> Dzeroski & Bratko, 1992). We present results on the interaction of inductive logic programming and learning multiple models in <ref> (Ali & Pazzani, 1995) </ref>. 130 K. ALI AND M. PAZZANI 3. Ali & Pazzani (1995) presents details on how to deal with recursive concepts in the "single, most reliable rule" framework. 4.
Reference: <author> Baxt, W.G. </author> <year> (1992.) </year> <title> Improving the Accuracy of an Artificial Neural Network Using Multiple Differently Trained Networks Neural Computation, </title> <booktitle> 4, </booktitle> <pages> 772-780. </pages>
Reference: <author> Brazdil, P., & Torgo, L. </author> <year> (1990.) </year> <title> Knowledge Acquisition via Knowledge Integration In Current Trends in Knowledge Acquisition : IOS Press. </title>
Reference: <author> Bernardo, J.M. & Smith, A.F.M. </author> <year> (1994.) </year> <title> Bayesian Theory. </title> : <publisher> John Wiley. </publisher>
Reference-contexts: On the other hand, on the primary-tumor data set, the error obtained by the identical multiple models procedure is the same as that obtained by using a single description. Much of the work on learning multiple models is motivated by Bayesian learning theory <ref> (e.g. Bernardo & Smith, 1994) </ref> which dictates that to maximize predictive accuracy, instead of making classifications based on a single learned model, one should ideally use all hypotheses (models) in the hypothesis space.
Reference: <author> Breiman, L. </author> <year> (1994.) </year> <title> Heuristics of instability in model selection. </title> <institution> (Technical Report University of California, Berkeley). Statistics Department, . Breiman, L. </institution> <note> (in press.) Bagging Predictors Machine Learning, </note> ?, ?. 
Reference: <author> Buntine W. </author> <year> (1990.) </year> <title> A Theory of Learning Classification Rules. </title> <type> Doctoral dissertation. </type> <institution> School of Computing Science, University of Technology, </institution> <address> Sydney, Australia. </address>
Reference-contexts: LS is the degree of logical sufficiency of that rule (explained under "Likelihood Combination" in Section 4). 4. Methods for combining evidence Our experiments compare four evidence combination methods: Uniform Voting, weighted combination according to Bayesian probability theory <ref> (Buntine, 1990) </ref>, weighted combination according to Distribution Summation (Clark & Boswell, 1991) and Likelihood Combination (Duda et al., 1979). Results using all four evidence combination methods and both learning methods are given in the first appendix. <p> Uniform Voting then randomly chooses between the classes with the highest scores. Uniform Voting is not competitive with the other methods when using just a single model but it is competitive once several models are used. * Bayesian Combination <ref> (Buntine, 1990) </ref> In Bayesian Combination, there are weights associated with models (the posterior probability of the model) and weights associated with rules (the accuracy of the rule). When only 1 model is being used, only the rule-weights are relevant. <p> Briefly, models whose class descriptions are syntactically-compact and are well able to separate the training examples of different classes end up with higher posterior probabilities. Appendix 2 and (Ali & Pazzani, 1995) detail how Buntine's form for the posterior probability of a decision tree <ref> (Buntine, 1990) </ref> is adapted for the kinds of models described in this paper. The general Bayesian method is used in our "single, most reliable rule" framework as follows. <p> This experiment suggests that although theory prescribes evidence combination from all models in the model or hypothesis space <ref> (Buntine, 1990) </ref>, in practice only a small number of models are learned and so it may be necessary to screen out less accurate models in order to maximize overall accuracy. <p> Appendix 1 The appendix contains a table of accuracies for all four evidence combination methods crossed with the two multiple model learning methods and the single model, deterministic hill-climbing method. Appendix 2 The posterior probability of a model, p (T j~x; ~c), is computed as follows <ref> (this presentation follows that in Buntine, 1990) </ref>: Using Bayes' rule, we can write: p (T j~x; ~c) / p (~x; ~cjT ) fi p (T ) (2.1) p (T ) is the prior probability of the model T . <p> One can then show <ref> (Buntine, 1990) </ref> that the contribution to the posterior from the k-th subset can be modeled by: B C (ff; . . . ; ff) where B C is the C-dimensional beta function and ff is a parameter which denotes the "weight" (in number of examples) that should be associated with the
Reference: <author> Clark, P., & Boswell, R. </author> <year> (1991.) </year> <title> Rule Induction with CN2: Some Recent Improvements In Proceedings of the European Working Session on Learning, </title> <publisher> 1991 : Pitman. </publisher>
Reference-contexts: LS is the degree of logical sufficiency of that rule (explained under "Likelihood Combination" in Section 4). 4. Methods for combining evidence Our experiments compare four evidence combination methods: Uniform Voting, weighted combination according to Bayesian probability theory (Buntine, 1990), weighted combination according to Distribution Summation <ref> (Clark & Boswell, 1991) </ref> and Likelihood Combination (Duda et al., 1979). Results using all four evidence combination methods and both learning methods are given in the first appendix. Our goal is to empirically demonstrate that our hypotheses about error reduction apply for a wide variety of evidence combination methods. methods. <p> Class b only has one satisfied rule so its accuracy (0.88) is used. Bayesian Combination predicts the class with the higher score class b in this situation. * Distribution Summation <ref> (Clark & Boswell, 1991) </ref> This method associates a k-component vector (the distribution) with each rule. k denotes the number of classes. The vector consists of the numbers of training examples from all k classes covered by that rule.
Reference: <author> Danyluk, A., & Provost, F. </author> <year> (1993.) </year> <title> Small Disjuncts in Action: </title> <booktitle> Learning to Diagnose Errors in the Local Loop of the Telephone Network In Proceedings of the Tenth International Conference on Machine Learning Amherst, </booktitle> <address> MA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> De Groot M.H. </author> <year> (1986.) </year> <title> Probability and Statistics. </title> <publisher> Reading,MA: Addison-Wesley. </publisher>
Reference-contexts: A '+' indicates a significant (using the paired 2-tailed t-test at the 95% confidence level) reduction in error, a '-' indicates a significant increase. For the DNA domain, the t-test is not applicable because we used leave-one-out testing. For this domain, we used a sign-test <ref> (DeGroot, 1986) </ref>. The data sets are grouped as follows: the first group contains noise-free training data from artificial concepts (for which we know the true class descriptions), the second group contains noisy data from artificial concepts the third contains data ERROR REDUCTION THROUGH LEARNING MULTIPLE DESCRIPTIONS 113 Table 3.
Reference: <author> Drobnic, M. & Gams, M. </author> <year> (1992.) </year> <title> Analysis of Classification with Two Classifiers. </title> <editor> In B. du Boulay and V.Sgurev, </editor> <booktitle> Artificial Intelligence 5: Methodology, Systems, and Applications. </booktitle> : <publisher> North-Holland. </publisher>
Reference: <author> Drobnic, M. & Gams, M. </author> <year> (1993.) </year> <title> Multistrategy Learning: An Analytical Approach In Proc. </title> <booktitle> 2nd Intern. Workshop on Multistrategy Learning Harpers Ferry, </booktitle> <address> WV: </address> ?. 
Reference: <author> Drucker, H., Cortes, C., Jackel, L., LeCun, Y. & Vapnik V. </author> <year> (1994.) </year> <title> Boosting and Other Machine Learning Algorithms In Machine Learning: </title> <booktitle> Proceedings of the Eleventh International Conference New Brunswick, NJ: </booktitle> <editor> Morgan Kaufmann. </editor> <title> ERROR REDUCTION THROUGH LEARNING MULTIPLE DESCRIPTIONS 131 Duda, </title> <editor> R., Gaschnig, J., & Hart, P. </editor> <year> (1979.) </year> <title> Model design in the Prospector consultant system for mineral exploration. </title> <editor> In D. Michie (ed.), </editor> <booktitle> Expert systems in the micro-electronic age. </booktitle> <address> Edinburgh, England: </address> <publisher> Edinburgh University Press. </publisher>
Reference: <author> Freund, Y. & Schapire, R.E. </author> <year> (1995.) </year> <title> A Decision-Theoretic Generalization of On-Line Learning and an application to Boosting. </title> <editor> In Vitanyi, P. (Ed.), </editor> <booktitle> Lecture Notes in Artificial Intelligence, </booktitle> <volume> Vol. </volume> <pages> 904. </pages> <address> Berlin, Germany: </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: The idea is to concentrate on the difficult examples. However, Schapire's method could not be used to learn many models on the modest training set sizes used in this paper because the number of training examples required rapidly increases as a function of the accuracy of earlier models. Modified-boosting <ref> (Freund & Schapire, 1995) </ref> designed to work with small data sets has not been proved empirically and may end up concentrating noisy examples in subsequent training sets. The only previous work involving learning relational multiple models (apart from our own, Ali & Pazzani, 1995) has been done by Kovacic (1994).
Reference: <author> Dzeroski, S., & Bratko, </author> <year> (1992.) </year> <booktitle> Handling noise in Inductive Logic Programming In Proceedings of the International Workshop on Inductive Logic Programming Tokyo, </booktitle> <address> Japan: </address> <publisher> ICOT Press. </publisher>
Reference-contexts: The only previous work involving learning relational multiple models (apart from our own, Ali & Pazzani, 1995) has been done by Kovacic (1994). Kovacic shows that learning multiple models by running mFOIL <ref> (Dzeroski, 1992) </ref> several times using simulated annealing yields significantly lower error rates than mFOIL on the KRK and Finite-element mesh data sets. 126 K. ALI AND M. PAZZANI Previous work related to the effect of noise and multiple models includes that of Kovacic (1994) and Gams (1990). <p> Although FOIL is an algorithm that learns class descriptions consisting of relational (first-order) clauses, in this paper we are not concerned with issues pertaining to relational learning or inductive logic programming <ref> (e.g. Dzeroski & Bratko, 1992) </ref>. We present results on the interaction of inductive logic programming and learning multiple models in (Ali & Pazzani, 1995). 130 K. ALI AND M. PAZZANI 3.
Reference: <author> Gams, M., & Petkovsek, M. </author> <year> (1988.) </year> <title> Learning From Examples in the Presence of Noise In 8th International Workshop; Expert Systems and their applications, </title> <booktitle> Vol. </booktitle> <address> 2 Avignon, France: </address> . 
Reference: <author> Gams, M. </author> <year> (1989.) </year> <title> New Measurements Highlight the Importance of Redundant Knowledge In European Working Session on Learning (4th: </title> <address> 1989) Montpeiller, France: </address> <publisher> Pitman. </publisher>
Reference: <author> Hansen, L.K, & Salamon, P. </author> <year> (1990.) </year> <journal> Neural Network Ensembles IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 12, 10, </volume> <pages> 993-1001. </pages>
Reference-contexts: Each model consists of a description for each class. Each description is a set of rules for that class (i.e. each class description is a set of first-order Horn clauses 1 for that class). The set of learned models is called an ensemble <ref> (Hansen & Salamon, 1990) </ref>. Previous work in learning multiple models has mainly been concerned with demonstrating that the multiple models approach reduces error as opposed to the goal of this paper which is to explain the variation in error reduction from domain to domain. <p> Previous theoretical work in learning multiple models includes Buntine's formulation of general Bayesian learning theory, Schapire's (1990) Boosting algorithm and the results from Hansen & Salamon (1990) and Drobnic & Gams (1992, 1993). Schapire's work proceeds on the basis <ref> (proved in Hansen & Salamon, 1990) </ref> that models that make errors in a completely independent manner will produce lower ensemble error. His Boosting algorithm is the only learning algorithm which incorporates the goal of minimizing correlated errors during learning.
Reference: <author> Holte, R., Acker, L., & Porter, B. </author> <year> (1989.) </year> <booktitle> Concept Learning and the Problem of Small Disjuncts In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence Detroit, </booktitle> <address> MI: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Howell, D. </author> <year> (1987.) </year> <title> Statistical Methods for Psychology. </title> <address> Boston, MA: </address> <publisher> Duxbury Press. </publisher>
Reference: <author> Kong, E.B., & Dietterich, T. </author> <year> (1995.) </year> <title> Error-Correcting Output Coding Corrects Bias and Variance In Machine Learning: </title> <booktitle> Proceedings of the Twelfth International Conference on Machine Learning Tahoe City, </booktitle> <address> CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Kononenko, I., & Kovacic, M. </author> <year> (1992.) </year> <title> Learning as Optimization: Stochastic Generation of Multiple Knowledge In Machine Learning: </title> <booktitle> Proceedings of the Ninth International Workshop Ab-erdeen, </booktitle> <address> Scotland: </address> <publisher> Morgan Kaufmann. </publisher> <editor> Kovacic, </editor> <booktitle> M (1994.) MILP a stochastic approach to Inductive Logic Programming In Proceedings of the Fourth International Workshop on Inductive Logic Programming Bad Honnef/Bonn, </booktitle> <address> Germany: </address> <publisher> GMD Press. </publisher>
Reference-contexts: Previous work in learning multiple models has mainly been concerned with demonstrating that the multiple models approach reduces error as opposed to the goal of this paper which is to explain the variation in error reduction from domain to domain. Previous work has compared different search strategies <ref> (Kononenko & Kovacic, 1992) </ref> compared different search evaluation measures (Gams, 1989; Smyth & Goodman, 1992), evaluated the effects of pruning (Kwok & Carter, 1990; Bun-tine, 1990) and compared different ways of generating models (nearly all authors).
Reference: <editor> Kruskal W.H. </editor> <booktitle> and Tanur J.M (1978.) International encyclopedia of statistics. </booktitle> <address> New York, NY: </address> <publisher> Free Press. </publisher>
Reference: <author> Kwok, S., & Carter, C. </author> <year> (1990.) </year> <booktitle> Multiple decision trees Uncertainty in Artificial Intelligence, </booktitle> <volume> 4, </volume> <pages> 327-335. </pages>
Reference: <author> Lavrac, N. & Dzeroski, S. </author> <year> (1991.) </year> <title> Inductive learning of relational descriptions from noisy examples In Proceedings of International Workshop on Inductive Logic Programming ILP-91 Viana de Castelo, </title> <address> Portugal: </address> . 
Reference: <author> Lloyd J.W. </author> <year> (1984.) </year> <title> Foundations of Logic Programming. </title> : <publisher> Springer-Verlag. </publisher>
Reference-contexts: FOIL learns a class description only for the class identified as the "positive" class. Thus, FOIL learns a single model consisting of a single class description. FOIL uses the closed-world assumption <ref> (Lloyd, 1984) </ref> for classification: if the test example matches the body of any clause learned for class "positive" then the example is assigned to class "positive." If it fails to match any clause, FOIL uses the closed-world assumption and assigns the example to class "negative." The way we extend FOIL to
Reference: <author> Madigan, D., & York, J. </author> <year> (1993.) </year> <title> Bayesian Graphical Models for Discrete Data. </title> <type> (Technical Report UW-93-259). </type> <institution> University of Washington, Statistics Department. </institution>
Reference: <author> Michalski, R.S., & Stepp, R. </author> <year> (1983.) </year> <title> Learning from Observation: Conceptual Clustering. </title> <editor> In Michalski, R.S., Carbonell, J.G., & Mitchell T.M. (Ed.s), </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach. </booktitle> : <publisher> Tioga Publishing Co. </publisher>
Reference-contexts: The pseudo-code for FOIL is presented in Table 1. FOIL learns one clause (rule) at a time, removing positive training examples covered by that clause in order to learn subsequent clauses. This is referred to as the "separate and conquer" (Quinlan, 1990) or "covering" <ref> (Michalski & Stepp, 1983) </ref> strategy. The basic FOIL procedure learns as follows. A clause for a given class such as class-a is learned by a greedy search strategy. It starts with an empty clause body which covers all remaining positive and negative examples.
Reference: <author> Muggleton, S., Bain, M., Hayes-Michie, J., & Michie, D. </author> <year> (1989.) </year> <booktitle> An experimental comparison of human and machine-learning formalisms In Proceedings of the Sixth International Workshop on Machine Learning Ithaca, </booktitle> <address> NY: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Muggleton, S. & Feng, C. </author> <year> (1990.) </year> <title> Efficient Induction of Logic Programs In Proceedings of the Workshop on Algorithmic Learning Theory : Japanese Society for Artificial Intelligence. </title>
Reference: <author> Muggleton, S., Srinivasan, A., & Bain, M. </author> <year> (1992.) </year> <title> Compression, Significance and Accuracy In Machine Learning: </title> <booktitle> Proceedings of the Ninth International Workshop Aberdeen, </booktitle> <address> Scotland: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Murphy, P.M., & Aha D.W. </author> <year> (1992.) </year> <title> UCI repository of machine learning databases (a machine-readable data repository). </title> <institution> Maintained at the Department of Information and Computer Science, University of Clifornia, </institution> <address> Irvine, CA. </address> <note> Data sets are available by anonymous ftp at ics.uci.edu in the directory pub/machine-learning-databases. </note>
Reference-contexts: Therefore, this evidence combination method will assign the example to class a. ERROR REDUCTION THROUGH LEARNING MULTIPLE DESCRIPTIONS 111 5. Empirical Analyses For our experiments we chose domains from the UCI repository of machine learning databases <ref> (Murphy & Aha, 1992) </ref> ensuring that at least one domain from each of the major groups (molecular biology, medical diagnosis ...) was chosen.
Reference: <author> Lavrac, N. & Dzeroski, S. </author> <year> (1992.) </year> <title> Background knowledge and declarative bias in inductive concept learning. </title> <editor> In Oantke, K., </editor> <booktitle> Proceedings of the Third International Workshop on Analogical and Inductive Inference. </booktitle> <address> Berlin, Germany: Springer. </address> <note> 132 K. </note> <author> ALI AND M. PAZZANI Pazzani, M., & Brunk, C. </author> <year> (1991.) </year> <title> Detecting and correcting errors in rule-based expert systems: an integration of empirical and explanation-based learning Knowledge Acquisition, </title> <booktitle> 3, </booktitle> <pages> 157-173. </pages>
Reference: <author> Pazzani, M., Brunk, C., & Silverstein, G. </author> <year> (1991.) </year> <title> A knowledge-intensive approach to learning relational concepts In Machine Learning: </title> <booktitle> Proceedings of the Eighth International Workshop (ML91) Ithaca, </booktitle> <address> NY: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Perrone, M. </author> <year> (1993.) </year> <title> Improving Regression Estimation: Averaging Methods for Variance Reduction with Extensions to General Convex Measure Optimization. </title> <type> Doctoral dissertation. </type> <institution> Department of Physics, Brown University, </institution> . 
Reference: <author> Quinlan, R. </author> <year> (1986.) </year> <title> Induction of Decision Trees Machine Learning, </title> <journal> 1, </journal> <volume> 1, </volume> <pages> 81-106. </pages>
Reference-contexts: In our experiments, we have seen no exceptions to this trend. However, if the number of gain ties is small, the amount of error reduction cannot be predicted. As Figure 5 shows, these gain-ties results are not just true for HYDRA they are also true for ID3 <ref> (Quinlan, 1986) </ref> the canonical decision tree learning algorithm. 5.4.
Reference: <author> Quinlan, R. </author> <year> (1990.) </year> <title> Learning logical definitions from relations Machine Learning, </title> <journal> 5, </journal> <volume> 3, </volume> <pages> 239-266. </pages>
Reference-contexts: We use HYDRA (Ali & Pazzani, 1993) to learn a single model consisting of a description for each class. HYDRA is based on extensions to FOIL 2 <ref> (Quinlan, 1990) </ref> proposed in Ali & Pazzani (1993) and Pazzani et al. (1991). HYDRA is then further modified to learn several models. The pseudo-code for FOIL is presented in Table 1. <p> HYDRA is then further modified to learn several models. The pseudo-code for FOIL is presented in Table 1. FOIL learns one clause (rule) at a time, removing positive training examples covered by that clause in order to learn subsequent clauses. This is referred to as the "separate and conquer" <ref> (Quinlan, 1990) </ref> or "covering" (Michalski & Stepp, 1983) strategy. The basic FOIL procedure learns as follows. A clause for a given class such as class-a is learned by a greedy search strategy. It starts with an empty clause body which covers all remaining positive and negative examples. <p> It starts with an empty clause body which covers all remaining positive and negative examples. Next, the strategy considers all literals that it can add to the clause body and ranks each by the information gained <ref> (Quinlan, 1990) </ref> if that literal were to be added to the current clause body. Briefly, the information gain measure favors the literal whose addition to the clause body would result in a clause that would cover many positive examples and exclude many negative examples.
Reference: <author> Quinlan, R. </author> <year> (1991.) </year> <title> Technical note: Improved Estimates for the Accuracy of Small Disjuncts Machine Learning, </title> <journal> 6, </journal> <volume> 1, </volume> <pages> 93-98. </pages>
Reference: <author> Ripley, B.D. </author> <year> (1987.) </year> <title> Stochastic Simulation. </title> : <publisher> John Wiley & Sons. </publisher>
Reference: <author> Schapire, R. </author> <year> (1990.) </year> <title> The strength of Weak Learnability Machine Learning, </title> <journal> 5, </journal> <volume> 2, </volume> <pages> 197-227. </pages>
Reference-contexts: This work differs from ours in that we provide a characterization of domains for which the multiple models approach will be beneficial (many irrelevant attributes, low noise levels) whereas Breiman characterizes the learning algorithm. Schapire's Boosting algorithm <ref> (Schapire, 1990) </ref> is the only learning algorithm which explicitly attempts to learn models that make errors statistically independently. Boosting learns from an on-line "stream" of examples. Subsequent models are constructed on training sets that amplify the number of examples misclassified by earlier models.
Reference: <author> Smyth, P., Goodman, R.M., & Higgins, C. </author> <year> (1990.) </year> <booktitle> A Hybrid Rule-Based/Bayesian Classifier In Proceedings of the 1990 European Conference on Artificial Intelligence London, </booktitle> <address> UK: </address> <publisher> Pitman. </publisher>
Reference: <author> Smyth, P. & Goodman, R. </author> <year> (1992.) </year> <title> Rule Induction Using Information Theory. </title> <editor> In G. Piatetsky-Shapiro (ed.), </editor> <booktitle> Knowledge Discovery in Databases. </booktitle> <address> Menlo Park, CA: </address> <publisher> AAAI Press, MIT Press. </publisher>
Reference: <author> Spackman, K. </author> <year> (1988.) </year> <booktitle> Learning Categorical Decision Criteria in Biomedical Domains In Proceedings of the Fifth International Conference on Machine Learning Ann Arbor, </booktitle> <address> MI: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: We chose a variety of domains for this study: LED-8 and KRK 100 are noise-free, Diabetes and Iris may contain class and attribute noise and the Splice domain may contain classes which can be succintly described with "m of n" rules <ref> (e.g. Spackman, 1988) </ref>. Table 9 shows the accuracies obtained by combining eleven stochastically generated models using the Uniform Voting evidence combination method. Our hope is that increasing the bucket size will lead to an increase in ensemble accuracy.
Reference: <author> Torgo, L. </author> <year> (1993.) </year> <title> Rule Combination in Inductive Learning In Machine Learning: </title> <address> ECML 93 Vienna, Austria: </address> <publisher> Springer-Verlag. </publisher>
Reference: <author> Towell, G., Shavlik, J., & Noordewier, M. </author> <year> (1990.) </year> <booktitle> Refinement of Approximate Domain Theories by Knowledge-Based Artificial Neural Networks In Proceedings of the Eighth National Conference on Artificial Intelligence (AAAI-90) Boston, </booktitle> <address> MA: </address> <publisher> AAAI Press. </publisher>
References-found: 46

