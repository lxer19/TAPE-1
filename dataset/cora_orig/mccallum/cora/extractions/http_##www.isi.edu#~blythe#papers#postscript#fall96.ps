URL: http://www.isi.edu/~blythe/papers/postscript/fall96.ps
Refering-URL: http://www.isi.edu/~blythe/papers/fall96.html
Root-URL: http://www.isi.edu
Email: fjblythe,mmvg@cs.cmu.edu  
Title: Learning to Improve Uncertainty Handling in a Hybrid Planning System  
Author: Jim Blythe and Manuela Veloso 
Address: Pittsburgh PA 15213  
Affiliation: Computer Science Department Carnegie Mellon University  
Abstract: Weaver is a hybrid planning algorithm that can create plans in domains that include uncertainty, modelled either as incomplete knowledge of the initial state of the world, of the effects of plan steps or of the possible external events. The plans are guaranteed to exceed some given threshold probability of success. Weaver creates a Bayesian network representation of a plan to evaluate it, in which links corresponding to sequences of events are computed with Markov models. As well as the probability of success, evaluation produces a set of flaws in the candidate plan, which are used by the planner to improve it. We describe a learning method that generates control knowledge compiled from this probabilistic evaluation of plans. The output of the learner is search control knowledge for the planning domain that helps the planner select alternatives that have previously lead to plans with high probability of success. The learned control knowledge is incrementally refined by a combined deductive and inductive mechanism. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Blythe, J., and Veloso, M. </author> <year> 1996. </year> <title> Using analogy in conditional planners. </title> <type> Technical Report forthcoming, </type> <institution> Computer Science Department, Carnegie Mellon University. </institution>
Reference-contexts: Some of the machine learning methods used in classical planners find new uses for the conditional plans now considered. Analogy, for example, can be used very efficiently for the specific problem of re-using planning effort across conditional branches of a plan <ref> (Blythe & Veloso 1996) </ref>. In addition, Weaver offers several other opportunities for speed-up learning in its modules. The Bayesian net construction module, for example, re-creates certain model fragments many times in a particular domain, as specific sub-plans and event interactions recur. These could be generalised and cached. <p> Rather than work with this model, our approach is to use the commitments already made in an emerging plan to restrict attention to only the sources of change in the world that are relevant to the plan. In <ref> (Blythe 1996) </ref> we show how to build reduced models of the domain that can be used to compute the correct probability of success of a given plan much more efficiently than can usually be done with the full model.
Reference: <author> Blythe, J. </author> <year> 1994. </year> <title> Planning with external events. </title> <editor> In de Man-taras, R. L., and Poole, D., eds., </editor> <booktitle> Proc. Tenth Conference on Uncertainty in Artificial Intelligence, 94101. </booktitle> <address> Seattle, WA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Blythe, J. </author> <year> 1996. </year> <title> Decompositions of markov chains for reasoning about external change in planners. </title> <editor> In Drabble, B., ed., </editor> <booktitle> Proc. Third International Conference on Artificial Intelligence Planning Systems. </booktitle> <publisher> University of Edinburgh: AAAI Press. </publisher>
Reference-contexts: Some of the machine learning methods used in classical planners find new uses for the conditional plans now considered. Analogy, for example, can be used very efficiently for the specific problem of re-using planning effort across conditional branches of a plan <ref> (Blythe & Veloso 1996) </ref>. In addition, Weaver offers several other opportunities for speed-up learning in its modules. The Bayesian net construction module, for example, re-creates certain model fragments many times in a particular domain, as specific sub-plans and event interactions recur. These could be generalised and cached. <p> Rather than work with this model, our approach is to use the commitments already made in an emerging plan to restrict attention to only the sources of change in the world that are relevant to the plan. In <ref> (Blythe 1996) </ref> we show how to build reduced models of the domain that can be used to compute the correct probability of success of a given plan much more efficiently than can usually be done with the full model.
Reference: <author> Borrajo, D., and Veloso, M. </author> <year> 1994. </year> <title> Incremental learning of control knowledge for nonlinear problem solving. </title> <booktitle> In Proceedings of the European Conference on Machine Learning, ECML-94, </booktitle> <volume> 6482. </volume> <publisher> Springer Verlag. </publisher>
Reference: <author> Borrajo, D., and Veloso, M. </author> <year> 1996. </year> <title> Lazy incremental learning of control knowledge for efficiently obtaining quality plans. </title> <note> Artificial Intelligence Review in press. </note>
Reference-contexts: This example illustrates the learning opportunities available in planning under uncertainty. In general, our learning method allows Weaver to learn from experience which features of the problem to pay attention to in choosing the steps in a plan. The method is based on HAMLET <ref> (Borrajo & Veloso 1996) </ref> which is a learning algorithm that combines deductive and inductive techniques to acquire control rules to improve the planning efficiency and the quality of the plans generated. 1 In this section, we briefly introduce HAMLET's learning technique and then present how we apply and HAMLET as an <p> HAMLET has been tested in a variety of experiments involving complex planning problems. The empirical results support the effectiveness of HAMLET's learning approach, in terms of improvement in planning efficiency, in the quality of plans generated, and in its incremental convergence towards the correct knowledge <ref> (Borrajo & Veloso in press forthcoming 1996) </ref>. We realize that HAMLET's learning power comes most directly from its overall lazy learning approach. Extending HAMLET to a hybrid planner HAMLET's incremental inductive refinement of the learned knowledge seems appropriate for compiling experience obtained from probabilistic planning episodes. <p> Extensive empirical studies have been performed to analyze HAMLET's convergence behavior in classical domains. In the domains used, HAMLET consistently showed that the set of control rules converged to an increasingly correct set of rules <ref> (Borrajo & Veloso 1996) </ref>. An equivalent empirical study as well as an analytical one in the probabilistic framework is on-going research.
Reference: <editor> Borrajo, D., and Veloso, M. </editor> <publisher> in press, </publisher> <month> forthcoming </month> <year> 1996. </year> <title> Lazy incremental learning of control knowledge for efficiently obtaining quality plans. </title> <journal> Journal of Artificial Intelligence Review. </journal>
Reference-contexts: This example illustrates the learning opportunities available in planning under uncertainty. In general, our learning method allows Weaver to learn from experience which features of the problem to pay attention to in choosing the steps in a plan. The method is based on HAMLET <ref> (Borrajo & Veloso 1996) </ref> which is a learning algorithm that combines deductive and inductive techniques to acquire control rules to improve the planning efficiency and the quality of the plans generated. 1 In this section, we briefly introduce HAMLET's learning technique and then present how we apply and HAMLET as an <p> HAMLET has been tested in a variety of experiments involving complex planning problems. The empirical results support the effectiveness of HAMLET's learning approach, in terms of improvement in planning efficiency, in the quality of plans generated, and in its incremental convergence towards the correct knowledge <ref> (Borrajo & Veloso in press forthcoming 1996) </ref>. We realize that HAMLET's learning power comes most directly from its overall lazy learning approach. Extending HAMLET to a hybrid planner HAMLET's incremental inductive refinement of the learned knowledge seems appropriate for compiling experience obtained from probabilistic planning episodes. <p> Extensive empirical studies have been performed to analyze HAMLET's convergence behavior in classical domains. In the domains used, HAMLET consistently showed that the set of control rules converged to an increasingly correct set of rules <ref> (Borrajo & Veloso 1996) </ref>. An equivalent empirical study as well as an analytical one in the probabilistic framework is on-going research.
Reference: <author> Boutilier, C.; Dean, T.; and Hanks, S. </author> <year> 1995. </year> <title> Planning under uncertainty: structural assumptions and computational leverage. </title> <editor> In Ghallab, M., and Milani, A., eds., </editor> <title> New Directions in AI Planning. </title> <address> Assissi, Italy: </address> <publisher> IOS Press. </publisher>
Reference: <author> Cohen, W. W. </author> <year> 1990. </year> <title> Learning approximate control rules of high utility. </title> <booktitle> In Proceedings of the Seventh International Conference on Machine Learning, </booktitle> <pages> 268276. </pages>
Reference: <author> Collins, G., and Pryor, L. </author> <year> 1995. </year> <title> Planning under uncertainty: Some key issues. </title> <booktitle> In Proc. 14th International Joint Conference on Artificial Intelligence, 15671573. </booktitle> <address> Montreal, Quebec: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> DeJong, G. F., and Mooney, R. </author> <year> 1986. </year> <title> Explanation-based learning: An alternative view. </title> <booktitle> Machine Learning 1(2):145176. </booktitle>
Reference: <author> Desimone, R. V., and Agosta, J. M. </author> <year> 1994. </year> <title> Oil spill response simulation: </title> <booktitle> the application of artificial intelligence planning technology. In Simulation Multiconference. </booktitle>
Reference-contexts: We illustrate this learning method in a challenging planning domain that has a very large state space, real-valued as well as nominal attributes and complex interactions between goals <ref> (Desimone & Agosta 1994) </ref>. This domain is of potential interest as a bench-mark for learning to act in dynamic, uncertain worlds, and we briefly discuss it in the next section. <p> The oil-spill domain We illustrate the planner and the learning technique with a planning domain for dealing with oil spilled from tankers at sea. This domain was originally developed at SRI for use with the SIPE planner <ref> (Desimone & Agosta 1994) </ref>, but in our version we have added information about uncertain external events that control the weather and the spread over time of spilled oil.
Reference: <author> Estlin, T., and Mooney, R. </author> <year> 1996. </year> <title> Multi-strategy learning of search control for partial-order planning. </title> <booktitle> In Proc. Thirteenth National Conference on Artificial Intelligence. </booktitle> <publisher> AAAI Press. </publisher>
Reference: <author> Katukam, S., and Kambhampati, S. </author> <year> 1994. </year> <title> Learning explanation-based search control rules for partial order planning. </title> <booktitle> In Proc. Twelfth National Conference on Artificial Intelligence. </booktitle> <publisher> AAAI Press. </publisher>
Reference: <author> Kushmerick, N.; Hanks, S.; and Weld, D. </author> <year> 1995. </year> <title> An algorithm for probabilistic planning. </title> <booktitle> Artificial Intelligence 76:239 286. </booktitle>
Reference-contexts: The planning system, called Weaver (Blythe 1994; 1996), uses an AI planner (Veloso et al. 1995) and a probabilistic reasoner that models the probability of success of the plan. Our action model is similar to Buridan's <ref> (Kushmerick, Hanks, & Weld 1995) </ref>, which is a generalisation of that of classical planning (eg (Minton et al. 1989)) to include uncertainty in the initial state, and in the outcomes of actions. We also model external events which can be predicted only with some probability.
Reference: <author> Laird, J. E.; Rosenbloom, P. S.; and Newell, A. </author> <year> 1986. </year> <title> Chunking in SOAR: The anatomy of a general learning mechanism. </title> <booktitle> Machine Learning 1:1146. </booktitle>
Reference: <author> Leckie, C., and Zukerman, I. </author> <year> 1991. </year> <title> Learning search control rules for planning: An inductive approach. </title> <booktitle> In Proceedings of Machine Learning Workshop, </booktitle> <pages> 422426. </pages>
Reference: <author> Minton, S.; Carbonell, J. G.; Knoblock, C. A.; Kuokka, D. R.; Etzioni, O.; and Gil, Y. </author> <year> 1989. </year> <title> Explanation-based learning: A problem solving perspective. </title> <journal> Artificial Intelligence 40:63118. </journal>
Reference-contexts: Our action model is similar to Buridan's (Kushmerick, Hanks, & Weld 1995), which is a generalisation of that of classical planning (eg <ref> (Minton et al. 1989) </ref>) to include uncertainty in the initial state, and in the outcomes of actions. We also model external events which can be predicted only with some probability. Weaver iterates between a planning phase and an evaluation phase.
Reference: <author> Minton, S. </author> <year> 1988. </year> <title> Learning Effective Search Control Knowledge: An Explanation-Based Approach. </title> <address> Boston, MA: </address> <publisher> Kluwer. </publisher>
Reference: <author> Mitchell, T. M.; Keller, R. M.; and Kedar-Cabelli, S. T. </author> <year> 1986. </year> <title> Explanation-based generalization: A unifying view. </title> <booktitle> Machine Learning 1:4780. </booktitle>
Reference: <author> Perez, A. M., and Etzioni, O. </author> <year> 1992. </year> <title> Dynamic: A new role for training problems in ebl. </title> <editor> In Sleeman, D., and Edwards, P., eds., </editor> <booktitle> Machine Learning: Proceedings of the Ninth International Conference, 367372. </booktitle> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Tadepalli, P. </author> <year> 1989. </year> <title> Lazy explanation-based learning: A solution to the intractable theory problem. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, 694700. </booktitle> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: These explanation-based techniques follow a deductive approach and invest a substantial explanation effort to produce proven correct and complete control rules from a single (or few) problem solving examples and a correct and complete underlying domain theory. There has been work on learning with incomplete, or intractable theories, (e.g., <ref> (Tadepalli 1989) </ref>) applied to simple problem solving scenarios.
Reference: <author> Veloso, M., and Borrajo, D. </author> <year> 1994. </year> <title> Learning strategy knowledge incrementally. </title> <booktitle> In Proceedings of the 6th International Conference on Tools with Artificial Intelligence, </booktitle> <pages> 484490. </pages>
Reference: <author> Veloso, M.; Carbonell, J.; Perez, A.; Borrajo, D.; Fink, E.; and Blythe, J. </author> <year> 1995. </year> <title> Integrating planning and learning: The prodigy architecture. </title> <journal> Journal of Experimental and Theoretical AI 7:81120. </journal>
Reference-contexts: Introduction We describe a machine learning technique that can be used to improve efficiency and potentially plan quality in a hybrid system for planning under uncertainty. The planning system, called Weaver (Blythe 1994; 1996), uses an AI planner <ref> (Veloso et al. 1995) </ref> and a probabilistic reasoner that models the probability of success of the plan.
Reference: <author> Veloso, M. M. </author> <year> 1994. </year> <title> Planning and Learning by Analogical Reasoning. </title> <publisher> Springer Verlag. </publisher>
References-found: 24

