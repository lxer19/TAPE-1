URL: ftp://mancos.cs.utah.edu/papers/munin-design.ps.Z
Refering-URL: http://www.cs.utah.edu/projects/flux/papers.html
Root-URL: 
Title: Design of the Munin Distributed Shared Memory System  
Author: John B. Carter 
Note: This research was supported in part by the National Science Foundation under Grants CDA-8619893, CCR-9010351, CCR-9116343, by the IBM Corporation under Research Agreement No. 20170041, by the Texas Advanced Technology Program under Grants 003604014 and 003604012, and by a NASA Graduate Fellowship.  
Address: Salt Lake City, UT 84112  
Affiliation: Department of Computer Science University of Utah  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> A. Agarwal and A. Gupta. </author> <title> Memory-reference characteristics of multiprocessor applications under MACH. </title> <booktitle> In Proceedings of the 15th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 215-225, </pages> <month> June </month> <year> 1988. </year>
Reference-contexts: To understand how shared memory programs characteristically access shared data, we studied the access behavior of a suite of shared memory parallel programs. The results of this study [4] and others <ref> [12, 22, 1, 26, 24] </ref> support the notion that using the flexibility of a software implementation to support multiple consistency protocols can improve the performance of DSM. They also suggest the types of access patterns that should be supported. <p> A single mechanism cannot optimally support all data access patterns, and the most important distinction between the observed data access patterns is between those best handled via some form of invalidate protocol and those best handled via some form of update protocol <ref> [12, 22, 1, 26, 4, 24] </ref>. 2. The number of characteristic sharing patterns is small and most shared data can be characterized as being accessed in one of these ways [26, 4]. 3.
Reference: [2] <author> M. Ahamad, P.W. Hutto, and R. John. </author> <title> Implementing and programming causal distributed shared memory. </title> <booktitle> In Proceedings of the 11th International Conference on Distributed Computing Systems, </booktitle> <pages> pages 274-281, </pages> <month> May </month> <year> 1991. </year>
Reference: [3] <author> H.E. Bal and A.S. Tanenbaum. </author> <title> Distributed programming with shared data. </title> <booktitle> In Proceedings of the 1988 International Conference on Computer Languages, </booktitle> <pages> pages 82-91, </pages> <month> October </month> <year> 1988. </year>
Reference: [4] <author> J.K. Bennett, J.B. Carter, and W. Zwaenepoel. </author> <title> Adaptive software cache management for distributed shared memory architectures. </title> <booktitle> In Proceedings of the 17th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 125-134, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: To understand how shared memory programs characteristically access shared data, we studied the access behavior of a suite of shared memory parallel programs. The results of this study <ref> [4] </ref> and others [12, 22, 1, 26, 24] support the notion that using the flexibility of a software implementation to support multiple consistency protocols can improve the performance of DSM. They also suggest the types of access patterns that should be supported. <p> A single mechanism cannot optimally support all data access patterns, and the most important distinction between the observed data access patterns is between those best handled via some form of invalidate protocol and those best handled via some form of update protocol <ref> [12, 22, 1, 26, 4, 24] </ref>. 2. The number of characteristic sharing patterns is small and most shared data can be characterized as being accessed in one of these ways [26, 4]. 3. <p> The number of characteristic sharing patterns is small and most shared data can be characterized as being accessed in one of these ways <ref> [26, 4] </ref>. 3. Synchronization variables are accessed in an inherently different way than data vari ables, and are more sensitive to increased access latency [26, 4]. 4. <p> The number of characteristic sharing patterns is small and most shared data can be characterized as being accessed in one of these ways <ref> [26, 4] </ref>. 3. Synchronization variables are accessed in an inherently different way than data vari ables, and are more sensitive to increased access latency [26, 4]. 4. The characteristic access pattern of individual variables does not change frequently during execution [4, 24], so a static protocol selection policy suffices in most cases. <p> Synchronization variables are accessed in an inherently different way than data vari ables, and are more sensitive to increased access latency [26, 4]. 4. The characteristic access pattern of individual variables does not change frequently during execution <ref> [4, 24] </ref>, so a static protocol selection policy suffices in most cases. The first three results strongly suggest that a DSM system that supports a small number of consistency protocols will outperform conventional DSM systems that support a single 5 static protocol. <p> writes to input data, and (ii) to conserve memory by loading on demand only the portion of the read-only data that a given node requires. 3.3 Migratory For migratory data, a single thread performs multiple accesses to the data, including one or more writes, before another thread accesses the data <ref> [26, 4] </ref>. This access pattern is typical of shared data that is accessed only inside a critical section or via a work queue. <p> In the case of Munin, this means that updates to shared data can be buffered and combined between release points. A single processor often performs a series of writes to a shared block within a critical section <ref> [4] </ref>. When this occurs, the write-shared protocol transmits a single update message containing all of the changes performed within the critical section to each node caching a copy of the data, rather than sending a stream of updates as each write occurs. <p> It is an attractive alternative for systems that do not support fast page fault handling, such as the iPSC-i860 hypercube. However, if the number of writes to a particular data item between DUQ flushes is high, as is often the case <ref> [4] </ref>, this approach will perform relatively poorly because each write to a shared variable is slower. 4 Performance Summary We present a summary of Munin's performance here to illustrate the value of Munin's design. More detailed evaluations appear elsewhere [9, 7, 8].
Reference: [5] <author> B.N. Bershad, M.J. Zekauskas, </author> <title> and W.A. </title> <booktitle> Sawdon. The Midway distributed shared memory system. In COMPCON '93, </booktitle> <pages> pages 528-537, </pages> <month> February </month> <year> 1993. </year>
Reference-contexts: We considered implementing write detection by having the compiler add code to log writes to replicated data as part of the write, as is done in Emerald [15] and Midway <ref> [5] </ref>.
Reference: [6] <author> R. Bisiani and M. Ravishankar. </author> <title> PLUS: A distributed shared-memory system. </title> <booktitle> In Proceedings of the 17th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 115-124, </pages> <month> May </month> <year> 1990. </year>
Reference: [7] <author> J.B. Carter. </author> <title> Efficient Distributed Shared Memory Based On Multi-Protocol Release Consistency. </title> <type> PhD thesis, </type> <institution> Rice University, </institution> <month> August </month> <year> 1993. </year>
Reference-contexts: Furthermore, for the five applications in which there was a moderate to high degree of sharing, the programs run under Munin achieved from 25% to over 100% higher speedups than their conventional DSM counterparts. Munin's performance on a variety of application programs is evaluated elsewhere <ref> [9, 7, 8] </ref> this paper concentrates on the design of Munin, especially its major data structures and the protocols used to maintain memory consistency. Also included are a number of lessons that we garnered from our experience with the prototype implementation that are relevant to the implementation of future DSMs. <p> The remainder of this section describes the implementation of Munin's consistency mechanisms. More detailed descriptions, including pseudo-code of the algorithms, can be found elsewhere <ref> [7] </ref>. 3.1 Conventional Conventional shared variables are replicated on demand and are kept consistent using an invalidation-based protocol that requires a writer to be the sole owner before it can modify the data. <p> More detailed evaluations appear elsewhere <ref> [9, 7, 8] </ref>. Seven application programs were used in the evaluation of Munin: Matrix Multiply (MULT), Finite Differencing (DIFF), Traveling Salesman Problem (both fine-grained, TSP-F, and coarse-grained, TSP-C), Quicksort (QSORT), Fast Fourier Transform (FFT), and Gaussian Elimination with Partial Pivoting (GAUSS).
Reference: [8] <author> J.B. Carter, J.K. Bennett, and W. Zwaenepoel. </author> <title> Techniques for reducing consistency-related communication in distributed shared memory systems. </title> <journal> ACM Transactions on Computer Systems. </journal> <note> To appear. </note>
Reference-contexts: Furthermore, for the five applications in which there was a moderate to high degree of sharing, the programs run under Munin achieved from 25% to over 100% higher speedups than their conventional DSM counterparts. Munin's performance on a variety of application programs is evaluated elsewhere <ref> [9, 7, 8] </ref> this paper concentrates on the design of Munin, especially its major data structures and the protocols used to maintain memory consistency. Also included are a number of lessons that we garnered from our experience with the prototype implementation that are relevant to the implementation of future DSMs. <p> More detailed evaluations appear elsewhere <ref> [9, 7, 8] </ref>. Seven application programs were used in the evaluation of Munin: Matrix Multiply (MULT), Finite Differencing (DIFF), Traveling Salesman Problem (both fine-grained, TSP-F, and coarse-grained, TSP-C), Quicksort (QSORT), Fast Fourier Transform (FFT), and Gaussian Elimination with Partial Pivoting (GAUSS). <p> For the other three applications (TSP-F, QSORT and GAUSS), the performance of the Munin variants is between 66% and 71% of their message-passing equivalents. Support for explicit RPC improves the performance of these applications to within 90% of their message passing equivalents <ref> [8, 9] </ref>.
Reference: [9] <author> J.B. Carter, J.K. Bennett, and W. Zwaenepoel. </author> <title> Implementation and performance of Munin. </title> <booktitle> In Proceedings of the 13th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 152-164, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: Furthermore, for the five applications in which there was a moderate to high degree of sharing, the programs run under Munin achieved from 25% to over 100% higher speedups than their conventional DSM counterparts. Munin's performance on a variety of application programs is evaluated elsewhere <ref> [9, 7, 8] </ref> this paper concentrates on the design of Munin, especially its major data structures and the protocols used to maintain memory consistency. Also included are a number of lessons that we garnered from our experience with the prototype implementation that are relevant to the implementation of future DSMs. <p> More detailed evaluations appear elsewhere <ref> [9, 7, 8] </ref>. Seven application programs were used in the evaluation of Munin: Matrix Multiply (MULT), Finite Differencing (DIFF), Traveling Salesman Problem (both fine-grained, TSP-F, and coarse-grained, TSP-C), Quicksort (QSORT), Fast Fourier Transform (FFT), and Gaussian Elimination with Partial Pivoting (GAUSS). <p> For the other three applications (TSP-F, QSORT and GAUSS), the performance of the Munin variants is between 66% and 71% of their message-passing equivalents. Support for explicit RPC improves the performance of these applications to within 90% of their message passing equivalents <ref> [8, 9] </ref>.
Reference: [10] <author> J.S. Chase, F.G. Amador, E.D. Lazowska, H.M. Levy, and R.J. Littlefield. </author> <title> The Amber system: Parallel programming on a network of multiprocessors. </title> <booktitle> In Proceedings of the 12th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 147-158, </pages> <month> December </month> <year> 1989. </year>
Reference: [11] <author> D.R. Cheriton and W. Zwaenepoel. </author> <title> The distributed V kernel and its performance for diskless workstations. </title> <booktitle> In Proceedings of the 9th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 129-140, </pages> <month> October </month> <year> 1983. </year> <month> 17 </month>
Reference-contexts: Munin programmers write parallel programs using threads, as they would on a uniprocessor or shared memory multiprocessor. prototype was implemented on a collection of sixteen SUN 3/60 workstations running the V operating system <ref> [11] </ref>. On each participating node, the Munin runtime is linked into the same address space as the user program and thus can access user data directly.
Reference: [12] <author> S.J. Eggers and R.H. Katz. </author> <title> A characterization of sharing in parallel programs and its appli-cation to coherency protocol evaluation. </title> <booktitle> In Proceedings of the 15th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 373-383, </pages> <month> May </month> <year> 1988. </year>
Reference-contexts: To understand how shared memory programs characteristically access shared data, we studied the access behavior of a suite of shared memory parallel programs. The results of this study [4] and others <ref> [12, 22, 1, 26, 24] </ref> support the notion that using the flexibility of a software implementation to support multiple consistency protocols can improve the performance of DSM. They also suggest the types of access patterns that should be supported. <p> A single mechanism cannot optimally support all data access patterns, and the most important distinction between the observed data access patterns is between those best handled via some form of invalidate protocol and those best handled via some form of update protocol <ref> [12, 22, 1, 26, 4, 24] </ref>. 2. The number of characteristic sharing patterns is small and most shared data can be characterized as being accessed in one of these ways [26, 4]. 3.
Reference: [13] <author> B. Fleisch and G. Popek. </author> <title> Mirage: A coherent distributed shared memory design. </title> <booktitle> In Proceedings of the 12th Symposium on Operating Systems Principles, </booktitle> <pages> pages 211-223, </pages> <month> December </month> <year> 1989. </year>
Reference-contexts: The thread that generated the miss blocks until 6 all invalidation messages are acknowledged. We based Munin's conventional protocol on Ivy's distributed dynamic manager protocol [16]. This protocol is typical of what existing DSM systems provide <ref> [16, 13, 20] </ref>, and is the conventional DSM protocol evaluated in our performance study. <p> We based Munin's conventional protocol on Ivy's distributed dynamic manager protocol [16]. This protocol is typical of what existing DSM systems provide [16, 13, 20], and is the conventional DSM protocol evaluated in our performance study. We incorporated a simplified version of the freezing mechanism from Mirage <ref> [13] </ref> so that after a node acquires ownership of a conventional data item, it does not reply to requests from other nodes for a period of time (100 msecs). This mechanism guarantees that the node performing the write makes progress even in the face of heavy sharing.
Reference: [14] <author> K. Gharachorloo, D. Lenoski, J. Laudon, P. Gibbons, A. Gupta, and J. Hennessy. </author> <title> Memory consistency and event ordering in scalable shared-memory multiprocessors. </title> <booktitle> In Proceedings of the 17th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 15-26, </pages> <address> Seattle, Washington, </address> <month> May </month> <year> 1990. </year>
Reference-contexts: The two major data structures used by the Munin runtime are an object directory that maintains the state of the shared data being used by local user threads and the delayed update queue (DUQ), which manages Munin's software implementation of release consistency <ref> [14] </ref>. Munin installs itself as the default page fault handler for the Munin program so that the underlying V kernel will forward all memory exceptions to it for handling. <p> Unlike existing update protocols, the write-shared protocol buffers and combines update messages, as shown in Figure 2. The reason that Munin can buffer updates, rather than send them as soon as they are generated, is that it supports the release consistency memory model <ref> [14] </ref>.
Reference: [15] <author> E. Jul, H. Levy, N. Hutchinson, and A. Black. </author> <title> Fine-grained mobility in the Emerald system. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 6(1) </volume> <pages> 109-133, </pages> <month> February </month> <year> 1988. </year>
Reference-contexts: The specific protocol varied from system to system, e.g., Ivy [16] supported a page-based emulation of a conventional hardware protocol while Emerald <ref> [15] </ref> used object-oriented language support to handle shared object invocations, but each system treated all shared data identically. <p> We considered implementing write detection by having the compiler add code to log writes to replicated data as part of the write, as is done in Emerald <ref> [15] </ref> and Midway [5].
Reference: [16] <author> K. Li and P. Hudak. </author> <title> Memory coherence in shared virtual memory systems. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 7(4) </volume> <pages> 321-359, </pages> <month> November </month> <year> 1989. </year>
Reference-contexts: The probable owner is used to determine the identity of the Munin node that currently owns the data <ref> [16] </ref>. The owner node is used by the conventional and migratory protocols to arbitrate the decision of which node has write access to the data. <p> This approach is analogous to the copy of last resort used in cache-only multiprocessors [25]. 3 Multiple Consistency Protocols Previous DSM systems have employed a single protocol to maintain the consistency of all shared data. The specific protocol varied from system to system, e.g., Ivy <ref> [16] </ref> supported a page-based emulation of a conventional hardware protocol while Emerald [15] used object-oriented language support to handle shared object invocations, but each system treated all shared data identically. <p> When a thread attempts to write to replicated data, a message is transmitted to invalidate all other copies of the data. The thread that generated the miss blocks until 6 all invalidation messages are acknowledged. We based Munin's conventional protocol on Ivy's distributed dynamic manager protocol <ref> [16] </ref>. This protocol is typical of what existing DSM systems provide [16, 13, 20], and is the conventional DSM protocol evaluated in our performance study. <p> The thread that generated the miss blocks until 6 all invalidation messages are acknowledged. We based Munin's conventional protocol on Ivy's distributed dynamic manager protocol [16]. This protocol is typical of what existing DSM systems provide <ref> [16, 13, 20] </ref>, and is the conventional DSM protocol evaluated in our performance study.
Reference: [17] <author> R.G. Minnich and D.J. Farber. </author> <title> The Mether system: A distributed shared memory for SunOS 4.0. </title> <booktitle> In Proceedings of the Summer 1989 USENIX Conference, </booktitle> <pages> pages 51-60, </pages> <month> June </month> <year> 1989. </year>
Reference: [18] <author> Myrias Corporation. </author> <title> System overview. </title> <address> Edmonton, Alberta, </address> <year> 1990. </year>
Reference-contexts: The prob owner chain is used to find this copy of last resort the "owner" in the write-shared protocol is this copy. A technique similar to the delayed update queue was used by the Myrias SPS multiprocessor <ref> [18] </ref>. It performed the copy-on-write and diff in hardware, but required a restricted form of parallelism to ensure correctness. Specifically, only one processor could modify a cache line at a time, and the only form of parallelism that could exploit this mechanism was a form of Fortran doall statement.
Reference: [19] <author> B. Nitzberg and V. Lo. </author> <title> Distributed shared memory: A survey of issues and algorithms. </title> <journal> IEEE Computer, </journal> <volume> 24(8) </volume> <pages> 52-60, </pages> <month> August </month> <year> 1991. </year>
Reference: [20] <author> U. Ramachandran, M. Ahamad, and Y.A. Khalidi. </author> <title> Unifying synchronization and data transfer in maintaining coherence of distributed shared memory. </title> <type> Technical Report GIT-CS-88/23, </type> <institution> Georgia Institute of Technology, </institution> <month> June </month> <year> 1988. </year>
Reference-contexts: The thread that generated the miss blocks until 6 all invalidation messages are acknowledged. We based Munin's conventional protocol on Ivy's distributed dynamic manager protocol [16]. This protocol is typical of what existing DSM systems provide <ref> [16, 13, 20] </ref>, and is the conventional DSM protocol evaluated in our performance study. <p> This pragma is particularly useful for associating migratory data accessed within a critical section with the lock controlling the critical section. It reduces the number of faults and messages needed to migrate the data, as in Clouds <ref> [20] </ref>. 3.4 Write Shared Write-shared variables are frequently written by multiple threads concurrently, without intervening synchronization to order the accesses, because the programmer knows that each thread reads from and writes to independent portions of the data.
Reference: [21] <author> S.K. Reinhardt, J.R. Larus, and D.A. Wood. Tempest and Typhoon: </author> <title> User-level shared memory. </title> <booktitle> In Proceedings of the 21st Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 325-336, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: Finally, fine-grained write detection hardware <ref> [21] </ref> could eliminate the largest component of software overhead, diff creation. These issues are subjects of ongoing research at the University of Utah.
Reference: [22] <author> R.L. Sites and A.Agarwal. </author> <title> Multiprocessor cache analysis using ATUM. </title> <booktitle> In Proceedings of the 15th Annual Intl Symposium on Computer Architecture, </booktitle> <pages> pages 186-195, </pages> <month> June </month> <year> 1988. </year>
Reference-contexts: To understand how shared memory programs characteristically access shared data, we studied the access behavior of a suite of shared memory parallel programs. The results of this study [4] and others <ref> [12, 22, 1, 26, 24] </ref> support the notion that using the flexibility of a software implementation to support multiple consistency protocols can improve the performance of DSM. They also suggest the types of access patterns that should be supported. <p> A single mechanism cannot optimally support all data access patterns, and the most important distinction between the observed data access patterns is between those best handled via some form of invalidate protocol and those best handled via some form of update protocol <ref> [12, 22, 1, 26, 4, 24] </ref>. 2. The number of characteristic sharing patterns is small and most shared data can be characterized as being accessed in one of these ways [26, 4]. 3.
Reference: [23] <author> M. Stumm and S. Zhou. </author> <title> Algorithms implementing distributed shared memory. </title> <journal> IEEE Computer, </journal> <volume> 24(5) </volume> <pages> 54-64, </pages> <month> May </month> <year> 1990. </year>
Reference: [24] <author> J.E. Veenstra and R.J. Fowler. </author> <title> A performance evaluation of optimal hybrid cache coherency protocols. </title> <booktitle> In Proceedings of the 5th Symposium on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 149-160, </pages> <month> September </month> <year> 1992. </year>
Reference-contexts: To understand how shared memory programs characteristically access shared data, we studied the access behavior of a suite of shared memory parallel programs. The results of this study [4] and others <ref> [12, 22, 1, 26, 24] </ref> support the notion that using the flexibility of a software implementation to support multiple consistency protocols can improve the performance of DSM. They also suggest the types of access patterns that should be supported. <p> A single mechanism cannot optimally support all data access patterns, and the most important distinction between the observed data access patterns is between those best handled via some form of invalidate protocol and those best handled via some form of update protocol <ref> [12, 22, 1, 26, 4, 24] </ref>. 2. The number of characteristic sharing patterns is small and most shared data can be characterized as being accessed in one of these ways [26, 4]. 3. <p> Synchronization variables are accessed in an inherently different way than data vari ables, and are more sensitive to increased access latency [26, 4]. 4. The characteristic access pattern of individual variables does not change frequently during execution <ref> [4, 24] </ref>, so a static protocol selection policy suffices in most cases. The first three results strongly suggest that a DSM system that supports a small number of consistency protocols will outperform conventional DSM systems that support a single 5 static protocol.
Reference: [25] <author> D.H.D. Warren and S. Haridi. </author> <title> The Data Diffusion machine A shared virtual memory architecture for parallel execution of logic programs. </title> <booktitle> In Proceedings of the 1988 International Conference on Fifth Generation Computer Systems, </booktitle> <pages> pages 943-952, </pages> <month> December </month> <year> 1988. </year>
Reference-contexts: This approach is analogous to the copy of last resort used in cache-only multiprocessors <ref> [25] </ref>. 3 Multiple Consistency Protocols Previous DSM systems have employed a single protocol to maintain the consistency of all shared data.
Reference: [26] <author> W.-D. Weber and A. Gupta. </author> <title> Analysis of cache invalidation patterns in multiprocessors. </title> <booktitle> In Proceedings of the 3rd Symposium on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 243-256, </pages> <month> April </month> <year> 1989. </year>
Reference-contexts: To understand how shared memory programs characteristically access shared data, we studied the access behavior of a suite of shared memory parallel programs. The results of this study [4] and others <ref> [12, 22, 1, 26, 24] </ref> support the notion that using the flexibility of a software implementation to support multiple consistency protocols can improve the performance of DSM. They also suggest the types of access patterns that should be supported. <p> A single mechanism cannot optimally support all data access patterns, and the most important distinction between the observed data access patterns is between those best handled via some form of invalidate protocol and those best handled via some form of update protocol <ref> [12, 22, 1, 26, 4, 24] </ref>. 2. The number of characteristic sharing patterns is small and most shared data can be characterized as being accessed in one of these ways [26, 4]. 3. <p> The number of characteristic sharing patterns is small and most shared data can be characterized as being accessed in one of these ways <ref> [26, 4] </ref>. 3. Synchronization variables are accessed in an inherently different way than data vari ables, and are more sensitive to increased access latency [26, 4]. 4. <p> The number of characteristic sharing patterns is small and most shared data can be characterized as being accessed in one of these ways <ref> [26, 4] </ref>. 3. Synchronization variables are accessed in an inherently different way than data vari ables, and are more sensitive to increased access latency [26, 4]. 4. The characteristic access pattern of individual variables does not change frequently during execution [4, 24], so a static protocol selection policy suffices in most cases. <p> writes to input data, and (ii) to conserve memory by loading on demand only the portion of the read-only data that a given node requires. 3.3 Migratory For migratory data, a single thread performs multiple accesses to the data, including one or more writes, before another thread accesses the data <ref> [26, 4] </ref>. This access pattern is typical of shared data that is accessed only inside a critical section or via a work queue.
Reference: [27] <author> M.J. Zekauskas, </author> <title> W.A. Sawdon, and B.N. Bershad. Software write detection for distributed shared memory. </title> <booktitle> In Proceedings of the First Symposium on Operating System Design and Implementation, </booktitle> <pages> pages 87-100, </pages> <month> November </month> <year> 1994. </year> <month> 18 </month>
Reference-contexts: We considered implementing write detection by having the compiler add code to log writes to replicated data as part of the write, as is done in Emerald [15] and Midway [5]. However, although recent results indicate that compiler-based write detection can outperform VM-based detection <ref> [27] </ref>, we chose not to explore this approach in the prototype because we 13 did not want to modify the compiler and we are concerned with the portability constraints imposed by the requirement that DSM programmers use a special compiler.
References-found: 27

