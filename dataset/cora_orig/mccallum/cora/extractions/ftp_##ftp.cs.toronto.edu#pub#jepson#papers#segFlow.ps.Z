URL: ftp://ftp.cs.toronto.edu/pub/jepson/papers/segFlow.ps.Z
Refering-URL: http://www.cs.toronto.edu/vis/publications/abstracts/segFlow.html
Root-URL: 
Email: email: black@parc.xerox.com  email: jepson@vis.toronto.edu  
Phone: Phone: (415)812-4745, FAX: (415)812-4334,  Phone: (416)978-6488, FAX: (416)978-1455,  
Title: Estimating Optical Flow in Segmented Images using Variable-order Parametric Models with Local Deformations  
Author: Michael J. Black and Allan Jepson 
Note: To appear IEEE PAMI.  
Date: Submitted: July 1994 Revised: June 1996  
Address: 3333 Coyote Hill Road, Palo Alto, CA 94304  Toronto, Toronto, Ontario M5S 1A4, Canada  
Affiliation: Xerox Palo Alto Research Center,  Department of Computer Science, University of  
Abstract: This paper presents a new model for estimating optical flow based on the motion of planar regions plus local deformations. The approach exploits brightness information to organize and constrain the interpretation of the motion by using segmented regions of piecewise smooth brightness to hypothesize planar regions in the scene. Paramet- ric flow models are estimated in these regions in a two step process which first computes a coarse fit and estimates the appropriate parameterization of the motion of the region (two, six, or eight parameters). The initial fit is refined using a generalization of the standard area-based regression approaches. Since the assumption of planarity is likely to be violated, we allow local deformations from the planar assumption in the same spirit as physically-based approaches which model shape using coarse parametric models plus local deformations. This parametric+deformation model exploits the strong constraints of parametric approaches while retaining the adaptive nature of regularization approaches. Experimental results on a variety of images indicate that the parametric+deformation model produces accurate flow estimates while the incorporation of brightness segmentation provides precise localization of motion boundaries. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> G. Adiv. </author> <title> Determining three-dimensional motion and structure from optical flow generated by several moving objects. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> PAMI-7(4):384-401, </volume> <month> July </month> <year> 1985. </year>
Reference-contexts: Like our approach, they use parameterized motion models within segmented regions but unlike our method they use motion rather than brightness information to extract these regions. Another set of approaches apply parametric models to coarse flow fields by grouping the flow vectors into consistent regions. Adiv <ref> [1] </ref> uses a Hough technique to group flow measurements into regions consistent with the motion of planar surfaces. The approach of Wang and Adelson [46] is similar but uses a k-means clustering algorithm to group the flow vectors into layers of consistent affine motion. <p> These regions become our planar-surface hypotheses. Issues relating to under- and over-segmentation are addressed in Section 7. 4.1 Fitting Parametric Models to Flow Estimates The image motion of a rigid planar region of the scene can be described by the following eight- parameter model <ref> [1, 48] </ref>: u (x; y) = a 0 + a 1 x + a 2 y + a 6 x 2 + a 7 xy; (4) 11 where the a i are parameters to be estimated and where u (x; y) and v (x; y) are the horizontal and vertical components
Reference: [2] <author> P. Anandan. </author> <title> A computational framework and an algorithm for the measurement of visual motion. </title> <journal> International Journal of Computer Vision, </journal> <volume> 2 </volume> <pages> 283-310, </pages> <year> 1989. </year>
Reference-contexts: The largest angular errors occur in regions which were in fact non-planar (most of the scene contains rolling hills). The vector differ <p>- 21 Technique Average Standard Density Error Deviation Anandan <ref> [2] </ref> 15:84 ffi 13:46 ffi 100% Singh [41] 13:16 ffi 12:07 ffi 100% Nagel [36] 11:71 ffi 10:59 ffi 100% Horn and Schunck (modified) [21] 11:26 ffi 16:41 ffi 100% Uras et al. [45] 10:44 ffi 15:00 ffi 100% Fleet and Jepson [17] 4:29 ffi 11:24 ffi 34:1% Lucas and Kanade
Reference: [3] <author> S. Ayer and H. Sawhney. </author> <title> Layered representation of motion video using robust maximumlikelihood estimation of mixture models and MDL encoding. </title> <booktitle> In Fifth International Conference on Computer Vision, </booktitle> <pages> pages 777-784, </pages> <address> Boston, MA, </address> <year> 1995. </year>
Reference-contexts: The motion estimation method, on the other hand, is not very sensitive to the choice of parameters as has been demonstrated elsewhere [12]. In nearly all the experiments, the parameters for the motion estimation are identical and standard statistical techniques can be used to estimated these parameters automatically <ref> [3, 28, 30, 39] </ref>. Additionally, statistical measures of the accuracy of the motion estimation within a region might be used to provide a confidence measure. Finally, this paper has presented the fitting and deformation process as a one-shot algorithm.
Reference: [4] <author> S. Ayer, P. Schroeter, and J. Bigun. </author> <title> Segmentation of moving objects by robust motion pa-rameter estimation over multiple frames. </title> <editor> In J. Eklundh, editor, </editor> <booktitle> European Conf. on Computer Vision, ECCV-94, volume 801 of LNCS-Series, </booktitle> <pages> pages 317-327, </pages> <address> Stockholm, Sweden, 1994. </address> <publisher> Springer-Verlag. </publisher> <pages> 30 </pages>
Reference-contexts: Koch [26] segments regions using disparity and brightness and then regularizes depth estimates within the regions. While this approach preserves depth boundaries it uses a weak model within regions instead of fitting a model with a small number of parameters. Ayer et al. <ref> [4] </ref> describe a method with similar motivations to the one presented here in that they combine static segmentation with motion information. They first robustly estimate a global parametric motion for the scene and detect regions which do not match this motion. <p> This process significantly improves the coarse motion estimates but we use this only as an initialization step. The motion of the regions is refined directly using brightness constraints from the images in a generalization of the standard global regression approaches [6]. Unlike the approach of Ayer et al. <ref> [4] </ref> we estimate the motion directly in these segmented regions and do not attempt to perform segmentation based on motion. Finally, we treat the assumption of planar patches as a 5 coarse approximation and allow local deformations to the motion estimates using an energy mini-mizing approach. <p> Due to over-segmentation based on brightness, the localization of objects, as opposed to surfaces patches, may require grouping patches together based on common motion. The approaches of Ayer et al. <ref> [4] </ref> and Wang and Adelson [46] present possible methods for achieving this grouping and do not appear to exhibit the kinds over-segmentation we see with our method. <p> Finally, this paper has presented the fitting and deformation process as a one-shot algorithm. In fact, it may be useful for this process to iterate in the context of an incremental estimation scheme where estimates are refined over an image sequence (cf. <ref> [4, 10, 35] </ref>). 8 Conclusion This paper has presented a new model for estimating optical flow based on the motion of planar regions plus local deformations.
Reference: [5] <author> J.L. Barron, D. J. Fleet, and S. S. Beauchemin. </author> <title> Performance of optical flow techniques. </title> <journal> In-ternational Journal of Computer Vision, </journal> <volume> 12(1), </volume> <year> 1994. </year>
Reference-contexts: The horizontal and vertical components of the coarse flow are shown in Figure 3. This coarse flow estimate is very noisy and since the sequence is synthetic, we can compute the error in the flow using using the angular error measure of Barron et al. <ref> [5] </ref>. They represent image velocities as 3-D unit direction vectors v 1 p u 2 +v 2 +1 (u; v; 1) T . The error between the true velocity v t and the estimated velocity v e is given by arccos (v t v e ). <p> The error in the estimate may be a result of choosing a model which is too simple. The results of the planar+deformation approach are compared with other published results for the Yosemite sequence in Table 1 (cf. <ref> [5] </ref>). The accuracy of the approach is in the range of the most accurate approaches but with 100% density (not counting the sky). Methods followed by a fl have errors computed without the sky region while the other methods include the sky. In [5] the error for Lucas and Kanade [31] <p> the Yosemite sequence in Table 1 (cf. <ref> [5] </ref>). The accuracy of the approach is in the range of the most accurate approaches but with 100% density (not counting the sky). Methods followed by a fl have errors computed without the sky region while the other methods include the sky. In [5] the error for Lucas and Kanade [31] and Fleet and Jepson [17] improves to 3:37 ffi and 2:97 ffi respectively when the sky is omitted though the density remains low. <p> The accuracy of the other approaches might also be expected to improve in accuracy by approximately 25% if the sky is ignored (see <ref> [5] </ref>) which still remains well below the accuracy of the planar+deformation model. 6.2 Nap-Of-the-Earth Sequence The next experiment considers a natural image sequence, similar to the Yosemite sequence, taken by a helicopter flying through a canyon (Figure 13a).
Reference: [6] <author> J. R. Bergen, P. Anandan, K. J. Hanna, and R. Hingorani. </author> <title> Hierarchical model-based motion estimation. </title> <editor> In G. Sandini, editor, </editor> <booktitle> Proc. of Second European Conference on Computer Vision, ECCV-92, volume 588 of LNCS-Series, </booktitle> <pages> pages 237-252. </pages> <publisher> Springer-Verlag, </publisher> <month> May </month> <year> 1992. </year>
Reference-contexts: These techniques use regression or a Hough transform to estimate a few parameters (eg. two, six, or eight) given hundreds or thousands of constraints computed over the entire image or some pre-selected region <ref> [6, 16, 17, 25, 31, 49] </ref>; when the image motion conforms to the model assumptions this produces accurate flow estimates. <p> This process significantly improves the coarse motion estimates but we use this only as an initialization step. The motion of the regions is refined directly using brightness constraints from the images in a generalization of the standard global regression approaches <ref> [6] </ref>. Unlike the approach of Ayer et al. [4] we estimate the motion directly in these segmented regions and do not attempt to perform segmentation based on motion. <p> Using the notation from <ref> [6] </ref> let: X (x) = 1 x y x 2 xy 0 0 0 # a = a 0 a 1 a 2 a 6 a 7 a 3 a 4 a 5 : (7) To robustly estimate the motion a r of a region r 2 R we minimize min <p> To minimize Eqn. (11) we use exactly the same continuation method described above in which is gradually lowered and at each stage we apply one step in Newton's method. Since the initial flow estimates are fairly accurate we do not need to use a coarse-to-fine strategy as in <ref> [6] </ref>. The results of refining the flow for the Yosemite sequence are shown in Figure 7. For this ex <br>- periment began at 20:0 p 3 and was lowered by a factor of 0.85 at each iteration to a minimum of 10:0 3.
Reference: [7] <author> J. R. Bergen, P. J. Burt, R. Hingorani, and S. Peleg. </author> <title> A three-frame algorithm for estimating two-component image motion. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 14(9) </volume> <pages> 886-896, </pages> <month> September </month> <year> 1992. </year>
Reference-contexts: Approaches have been devised which ameliorate some of the problems of global parametric models. Bergen et al. <ref> [7] </ref> use an iterative registration algorithm to account for multiple global motions in the scene. Jepson and Black [23] assume that the motion in the scene can be represented by a mixture of distributions and they use the EM algorithm to decompose the motion into a fixed number of layers.
Reference: [8] <author> P. J. Besl and J. Jain. </author> <title> Segmentation through variable-order surface fitting. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 10(2), </volume> <month> March </month> <year> 1988. </year>
Reference-contexts: To avoid over-fitting the motion of a region we use a variable-order fitting approach <ref> [8, 29] </ref> 5 We could have chosen any of a number of error norms with redescending influence functions; for example the Lorentzian norm of the previous section.
Reference: [9] <author> M. J. Black. </author> <title> Combining intensity and motion for incremental segmentation and tracking over long image sequences. </title> <editor> In G. Sandini, editor, </editor> <booktitle> Proc. of Second European Conference on Computer Vision, ECCV-92, volume 588 of LNCS-Series, </booktitle> <pages> pages 485-493. </pages> <publisher> Springer-Verlag, </publisher> <month> May </month> <year> 1992. </year>
Reference-contexts: Thompson [44] describes a region merging technique which uses similarity constraints on brightness and motion for segmentation. Heitz and Bouthemy [20] combine gradient- based and edge-based motion estimation and realize improved motion estimates and the localization of motion discontinuities. Black <ref> [9] </ref> jointly estimates piecewise smooth motion and brightness over an image sequence. Discontinuities are detected using motion and brightness simultaneously and are classified as either structural boundaries or surface markings. Recently, motion segmentation and color segmentation have been combined to improve the localization of moving object contours [15].
Reference: [10] <author> M. J. Black. </author> <title> Recursive non-linear estimation of discontinuous flow fields. </title> <editor> In J. Eklundh, editor, </editor> <booktitle> European Conf. on Computer Vision, ECCV-94, volume 800 of LNCS-Series, </booktitle> <pages> pages 138-145, </pages> <address> Stockholm, Sweden, 1994. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Finally, this paper has presented the fitting and deformation process as a one-shot algorithm. In fact, it may be useful for this process to iterate in the context of an incremental estimation scheme where estimates are refined over an image sequence (cf. <ref> [4, 10, 35] </ref>). 8 Conclusion This paper has presented a new model for estimating optical flow based on the motion of planar regions plus local deformations.
Reference: [11] <author> M. J. Black and P. Anandan. </author> <title> A framework for the robust estimation of optical flow. </title> <booktitle> In Proc. Int. Conf. on Computer Vision, ICCV-93, </booktitle> <pages> pages 231-236, </pages> <address> Berlin, Germany, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: The exact methods used for these early processes are not crucial to the optical flow model described in this paper, so the algorithms are described only briefly and the reader is referred to [13] for a complete description of the segmentation approach and to <ref> [11] </ref> for the coarse flow estimation. The static image segmentation method described below is just one of many possibilities. Any other method that gives connected regions could be employed and the better the static segmentation results, the better the motion estimates will be. <p> To estimate the horizontal and vertical image velocity u (x) = [u (x); v (x)] T at a point x = (x; y) we minimize an objective function composed of a data term and a spatial smoothness term <ref> [11] </ref>: E M (u) = x S X (ku (x) u (z)k; S )]; (2) where is the Lorentzian error norm [13]. <p> In general, using a robust error norm may cause E M to be non-convex. To obtain the coarse estimate, the values of the fl are chosen so that the objective function is convex and the function is minimized using Newton's method <ref> [11] </ref>. A coarse to fine strategy, with warping between layers, is used to estimate large motions within the differential framework. Consider the Yosemite image sequence whose first image is shown in Figure 2a. <p> While we have not used this 17 parallax to recover local structure, the application of plane+parallax methods to local image regions is an interesting area for further exploration. We estimate local deformation, or parallax, using the robust optical flow estimation technique described in <ref> [11] </ref> with the addition of a new term now coupling the flow estimate to the parametric- prediction of the flow.
Reference: [12] <author> M. J. Black and P. Anandan. </author> <title> The robust estimation of multiple motions: Parametric and piecewise-smooth flow fields. </title> <booktitle> Computer Vision and Image Understanding, </booktitle> <volume> 63(1) </volume> <pages> 75-104, </pages> <month> January </month> <year> 1996. </year>
Reference-contexts: In the second step, the parametric fit from the initial estimate is used to warp the image regions into alignment. Gradient-based optical flow constraints are computed from these registered regions and are used to refine the initial parametric fit by performing regression over each region. Robust regression techniques <ref> [12, 19] </ref> are used to compute both the initial and refined estimates if the motion parameters. <p> In similar work, Darrell and Pentland [14] use a stochastic approach to segment the motion into a set of layers with support maps which assign pixels to layers. Additionally they use a minimum description length encoding principle to automatically choose the appropriate number of layers. Black and Anandan <ref> [12] </ref> use robust statistics to estimate a dominant motion in the scene and then fit additional motions to outlying measurements. All of these approaches are formulated as global techniques which can cope with a small number of global motions but not with general flow fields. <p> Measurements with residual errors which fall beyond this point we refer to as outliers. In the case of the Lorentzian, if the absolute value of the residual error is greater than p surement is considered an outlier <ref> [12] </ref>. To derive the coarse estimate we choose to be sufficiently large that no measurements are treated as outliers. In general, using a robust error norm may cause E M to be non-convex. <p> One possibility is to use the local deformation as a measure of strain and introduce breaks when the strain is too great [24]. An alternative way to cope with undersegmentation is to allow multiple motions within a region and use either a robust estimation approach <ref> [12] </ref> or a mixture model approach [23] to recover the multiple motions. The segmentation approach presented here is merely used to illustrate the idea of exploiting 28 static segmentation in motion estimation. <p> The motion estimation method, on the other hand, is not very sensitive to the choice of parameters as has been demonstrated elsewhere <ref> [12] </ref>. In nearly all the experiments, the parameters for the motion estimation are identical and standard statistical techniques can be used to estimated these parameters automatically [3, 28, 30, 39].
Reference: [13] <author> M. J. Black and A. Rangarajan. </author> <title> The outlier process: Unifying line processes and robust statis-tics. </title> <booktitle> In Proc. Computer Vision and Pattern Recognition, CVPR-94, </booktitle> <pages> pages 15-22, </pages> <address> Seattle, WA, </address> <month> June </month> <year> 1994. </year> <month> 31 </month>
Reference-contexts: The exact methods used for these early processes are not crucial to the optical flow model described in this paper, so the algorithms are described only briefly and the reader is referred to <ref> [13] </ref> for a complete description of the segmentation approach and to [11] for the coarse flow estimation. The static image segmentation method described below is just one of many possibilities. <p> We choose this method to provide examples which illustrate the interplay between brightness segmentation and motion estimation. 3.1 Segmentation For the experiments described here we have used a weak-membrane model of image brightness described in <ref> [13] </ref>. The goal is to reconstruct a piecewise smooth brightness image i given noisy data d by minimizing an objective function using a continuation method. Both spatial discontinuities and texture are treated as outlying measurements and rejected using analog outlier processes. <p> goes to 0 (that is, we pay an infinite penalty for introducing a complete discontinuity) and (l s;t ) ! 0 when there is no discontinuity (l s;t ! 1). 1 For these experiments we take (z) = z 1 log z; which is derived from the Lorentzian error norm <ref> [13] </ref>. Additionally, we introduce a measurement outlier process m s 2 m on the data term which treats image texture as outliers with respect to the piecewise smooth reconstruction. <p> The spatial outliers will be used for region segmentation at the medium level. 3 1 We could also choose a penalty function such that (l s;t ) ! 1 as l s;t ! 0 (see <ref> [13] </ref>). 2 This sequence was generated by Lynn Quam and provided by David Heeger. 3 The approach described here is equivalent to minimizing E I (i; d) = s2S 1 X (i s i t ; S )] a b 3.2 Coarse Optical Flow Let I (x; y; t) be the <p> (x) = [u (x); v (x)] T at a point x = (x; y) we minimize an objective function composed of a data term and a spatial smoothness term [11]: E M (u) = x S X (ku (x) u (z)k; S )]; (2) where is the Lorentzian error norm <ref> [13] </ref>.
Reference: [14] <author> T. Darrell and A. Pentland. </author> <title> Robust estimation of a multi-layer motion representation. </title> <booktitle> In Proc. IEEE Workshop on Visual Motion, </booktitle> <pages> pages 173-178, </pages> <address> Princeton, NJ, </address> <month> October </month> <year> 1991. </year>
Reference-contexts: Jepson and Black [23] assume that the motion in the scene can be represented by a mixture of distributions and they use the EM algorithm to decompose the motion into a fixed number of layers. In similar work, Darrell and Pentland <ref> [14] </ref> use a stochastic approach to segment the motion into a set of layers with support maps which assign pixels to layers. Additionally they use a minimum description length encoding principle to automatically choose the appropriate number of layers.
Reference: [15] <author> M. Dubuisson and A. K. Jain. </author> <title> Object contour extraction using color and motion. </title> <booktitle> In Proc. Computer Vision and Pattern Recognition, CVPR-93, </booktitle> <pages> pages 471-476, </pages> <address> New York, </address> <month> June </month> <year> 1993. </year>
Reference-contexts: Black [9] jointly estimates piecewise smooth motion and brightness over an image sequence. Discontinuities are detected using motion and brightness simultaneously and are classified as either structural boundaries or surface markings. Recently, motion segmentation and color segmentation have been combined to improve the localization of moving object contours <ref> [15] </ref>.
Reference: [16] <author> C. L. Fennema and W. B. Thompson. </author> <title> Velocity determination in scenes containing several moving objects. </title> <journal> Computer Graphics and Image Processing, </journal> <volume> 9 </volume> <pages> 301-315, </pages> <year> 1979. </year>
Reference-contexts: These techniques use regression or a Hough transform to estimate a few parameters (eg. two, six, or eight) given hundreds or thousands of constraints computed over the entire image or some pre-selected region <ref> [6, 16, 17, 25, 31, 49] </ref>; when the image motion conforms to the model assumptions this produces accurate flow estimates.
Reference: [17] <author> D.J. Fleet and A.D. Jepson. </author> <title> Computation of component image velocity from local phase in-formation. </title> <journal> International Journal of Computer Vision, </journal> <volume> 5 </volume> <pages> 77-104, </pages> <year> 1990. </year>
Reference-contexts: These techniques use regression or a Hough transform to estimate a few parameters (eg. two, six, or eight) given hundreds or thousands of constraints computed over the entire image or some pre-selected region <ref> [6, 16, 17, 25, 31, 49] </ref>; when the image motion conforms to the model assumptions this produces accurate flow estimates. <p> 21 Technique Average Standard Density Error Deviation Anandan [2] 15:84 ffi 13:46 ffi 100% Singh [41] 13:16 ffi 12:07 ffi 100% Nagel [36] 11:71 ffi 10:59 ffi 100% Horn and Schunck (modified) [21] 11:26 ffi 16:41 ffi 100% Uras et al. [45] 10:44 ffi 15:00 ffi 100% Fleet and Jepson <ref> [17] </ref> 4:29 ffi 11:24 ffi 34:1% Lucas and Kanade [31] 4:10 ffi 9:58 ffi 35:1% Weber and Malik [50] 3:42 ffi 5:35 ffi 45:2% Black and Anandan [11]fl 4:47 ffi 3:90 ffi 100% Black [10]fl 3:52 ffi 3:25 ffi 100% Parametric+Deformationfl 2:29 ffi 2:25 ffi 100% Table 1: Comparison of various <p> Methods followed by a fl have errors computed without the sky region while the other methods include the sky. In [5] the error for Lucas and Kanade [31] and Fleet and Jepson <ref> [17] </ref> improves to 3:37 ffi and 2:97 ffi respectively when the sky is omitted though the density remains low.
Reference: [18] <author> D. Geman, S. Geman, C. Graffigne, and P. Dong. </author> <title> Boundary detection by constrained opti-mization. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 12(7) </volume> <pages> 609-628, </pages> <month> July </month> <year> 1990. </year>
Reference-contexts: The segmentation method actually produces regions with small variations around the mean brightness within the region. This variation is controlled by the parameters and is necessary for reliable motion estimation. Future work should explore the use of texture segmentation techniques (e.g. <ref> [18] </ref>) which would yield regions with adequate texture for motion estimation. The segmentation and motion approaches presented here rely on a number of parameters, particularly the scale parameters .
Reference: [19] <author> F. R. Hampel, E. M. Ronchetti, P. J. Rousseeuw, and W. A. Stahel. </author> <title> Robust Statistics: The Approach Based on Influence Functions. </title> <publisher> John Wiley and Sons, </publisher> <address> New York, NY, </address> <year> 1986. </year>
Reference-contexts: In the second step, the parametric fit from the initial estimate is used to warp the image regions into alignment. Gradient-based optical flow constraints are computed from these registered regions and are used to refine the initial parametric fit by performing regression over each region. Robust regression techniques <ref> [12, 19] </ref> are used to compute both the initial and refined estimates if the motion parameters. <p> This -function characterizes the influence that a particular measurement has on the solution <ref> [19] </ref>. Error norms like the Lorentzian have the property that beyond a particular point (where the second derivative of the norm is zero) the influence of a measurement on the solution begins to decrease. Measurements with residual errors which fall beyond this point we refer to as outliers. <p> Since the coarse optical flow estimates are expected to have gross errors it is important that the estimation of the motion parameters be performed robustly. For this reason we take to be an error norm with a redescending influence function <ref> [19] </ref> which has the property of reducing the influence of outlying measurements on the solution.
Reference: [20] <author> F. Heitz and P. Bouthemy. </author> <title> Multimodal motion estimation of discontinuous optical flow using Markov random fields. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <pages> pages 1217-1232, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: Thompson [44] describes a region merging technique which uses similarity constraints on brightness and motion for segmentation. Heitz and Bouthemy <ref> [20] </ref> combine gradient- based and edge-based motion estimation and realize improved motion estimates and the localization of motion discontinuities. Black [9] jointly estimates piecewise smooth motion and brightness over an image sequence. Discontinuities are detected using motion and brightness simultaneously and are classified as either structural boundaries or surface markings.
Reference: [21] <author> B. K. P. Horn and B. G. Schunck. </author> <title> Determining optical flow. </title> <journal> Artificial Intelligence, </journal> <volume> 17(13) </volume> <pages> 185-203, </pages> <month> August </month> <year> 1981. </year>
Reference-contexts: The vector differ <p>- 21 Technique Average Standard Density Error Deviation Anandan [2] 15:84 ffi 13:46 ffi 100% Singh [41] 13:16 ffi 12:07 ffi 100% Nagel [36] 11:71 ffi 10:59 ffi 100% Horn and Schunck (modified) <ref> [21] </ref> 11:26 ffi 16:41 ffi 100% Uras et al. [45] 10:44 ffi 15:00 ffi 100% Fleet and Jepson [17] 4:29 ffi 11:24 ffi 34:1% Lucas and Kanade [31] 4:10 ffi 9:58 ffi 35:1% Weber and Malik [50] 3:42 ffi 5:35 ffi 45:2% Black and Anandan [11]fl 4:47 ffi 3:90 ffi 100%
Reference: [22] <author> M. Irani, B. Rousso, and S. Peleg. </author> <title> Detecting and tracking multiple moving objects using tem-poral integration. </title> <editor> In G. Sandini, editor, </editor> <booktitle> Proc. of Second European Conference on Computer Vision, ECCV-92, volume 588 of LNCS-Series, </booktitle> <pages> pages 282-287. </pages> <publisher> Springer-Verlag, </publisher> <month> May </month> <year> 1992. </year>
Reference-contexts: As global approaches, they do not address how to select appropriate image regions in which to apply the parametric models. In related work, Irani and Peleg <ref> [22] </ref> fit a dominant motion to the scene using a least squares method and they detect outlying measurements which are grouped together and segmented. These groups hopefully correspond to independently moving objects and their motion is estimated independently.
Reference: [23] <author> A. Jepson and M. J. Black. </author> <title> Mixture models for optical flow computation. </title> <editor> In Ingmer Cox, Pierre Hansen, and Bela Julesz, editors, </editor> <title> Partitioning Data Sets: With Applications to Psychology, Vision and Target Tracking, </title> <booktitle> pages 271-286, DIMACS Workshop, </booktitle> <address> April 1993. </address> <publisher> AMS Pub., </publisher> <address> Providence, RI. </address> <month> 32 </month>
Reference-contexts: Approaches have been devised which ameliorate some of the problems of global parametric models. Bergen et al. [7] use an iterative registration algorithm to account for multiple global motions in the scene. Jepson and Black <ref> [23] </ref> assume that the motion in the scene can be represented by a mixture of distributions and they use the EM algorithm to decompose the motion into a fixed number of layers. <p> But large, arbitrarily shaped, regions may have multiple motions within them or may not satisfy the assumptions of the parameterized model (eg. planarity). We have referred to this problem of choosing the appropriate region for integration as the generalized aperture problem <ref> [23] </ref>. The second aspect of the work involves the use of static brightness information to improve the estimation of image motion. Previous attempts to integrate motion and brightness have often focused on using brightness discontinuities to improve the localization of motion discontinuities. <p> An alternative way to cope with undersegmentation is to allow multiple motions within a region and use either a robust estimation approach [12] or a mixture model approach <ref> [23] </ref> to recover the multiple motions. The segmentation approach presented here is merely used to illustrate the idea of exploiting 28 static segmentation in motion estimation. It is interesting to note that the idealized brightness model used for segmentation is one of piecewise constant brightness.
Reference: [24] <author> I. A. Kakadiaris, D. Metaxas, and R. </author> <title> Bajcsy. Active part-decomposition, shape and motion estimations of articulated objects: A physics-based approach. In Computer Vision and Pattern Recognition, </title> <booktitle> CVPR-94, </booktitle> <pages> pages 980-984, </pages> <address> Seattle, WA, </address> <year> 1994. </year>
Reference-contexts: One possibility is to use the local deformation as a measure of strain and introduce breaks when the strain is too great <ref> [24] </ref>. An alternative way to cope with undersegmentation is to allow multiple motions within a region and use either a robust estimation approach [12] or a mixture model approach [23] to recover the multiple motions.
Reference: [25] <author> J. K. Kearney, W. B. Thompson, and D. L. Boley. </author> <title> Optical flow estimation: An error analysis of gradient-based methods with local optimization. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 9 </volume> <pages> 229-244, </pages> <year> 1987. </year>
Reference-contexts: These techniques use regression or a Hough transform to estimate a few parameters (eg. two, six, or eight) given hundreds or thousands of constraints computed over the entire image or some pre-selected region <ref> [6, 16, 17, 25, 31, 49] </ref>; when the image motion conforms to the model assumptions this produces accurate flow estimates.
Reference: [26] <author> R. Koch. </author> <title> Automatic reconstruction of buildings from stereoscopic image sequences. </title> <journal> EUROGRPHICS'93, </journal> <volume> 12(3) </volume> <pages> 339-350, </pages> <year> 1993. </year>
Reference-contexts: The accuracy of this approach is affected by the accuracy of the initial disparity estimates. Koch <ref> [26] </ref> segments regions using disparity and brightness and then regularizes depth estimates within the regions. While this approach preserves depth boundaries it uses a weak model within regions instead of fitting a model with a small number of parameters.
Reference: [27] <author> R. Kumar, P. Anandan, and K. Hanna. </author> <title> Shape recovery from multiple views: A parallax based approach. </title> <booktitle> In ARPA Image Understanding Workshop, </booktitle> <year> 1994. </year>
Reference-contexts: This simple relationship to 3D structure has been used for recovering structure from motion <ref> [27, 40] </ref>. Unlike these planar parallax approaches we do not stabilize the entire scene based on a single planar motion but, rather, stabilize an isolated patch based on its motion.
Reference: [28] <author> R. Kumar and A. R. Hanson. </author> <title> Analysis of different robust methods for pose refinement. </title> <booktitle> In Proc. Int. Workshop on Robust Computer Vision, </booktitle> <pages> pages 167-182, </pages> <address> Seattle, WA, </address> <month> October </month> <year> 1990. </year>
Reference-contexts: The motion estimation method, on the other hand, is not very sensitive to the choice of parameters as has been demonstrated elsewhere [12]. In nearly all the experiments, the parameters for the motion estimation are identical and standard statistical techniques can be used to estimated these parameters automatically <ref> [3, 28, 30, 39] </ref>. Additionally, statistical measures of the accuracy of the motion estimation within a region might be used to provide a confidence measure. Finally, this paper has presented the fitting and deformation process as a one-shot algorithm.
Reference: [29] <author> A. Leonardis, A. Gupta, and R. </author> <title> Bajcsy. Segmentation as the search for the best description of the image in terms of primitives. </title> <type> Technical Report MS-CIS-90-30, </type> <institution> GRASP LAB 215, </institution> <month> May </month> <year> 1990. </year>
Reference-contexts: To avoid over-fitting the motion of a region we use a variable-order fitting approach <ref> [8, 29] </ref> 5 We could have chosen any of a number of error norms with redescending influence functions; for example the Lorentzian norm of the previous section.
Reference: [30] <author> G. Li. </author> <title> Robust regression. </title> <editor> In F. Mosteller and J. W. Tukey, editors, </editor> <title> Exploring Data, Tables, Trends and Shapes. </title> <publisher> John Wiley & Sons, </publisher> <address> New York, </address> <year> 1985. </year>
Reference-contexts: The motion estimation method, on the other hand, is not very sensitive to the choice of parameters as has been demonstrated elsewhere [12]. In nearly all the experiments, the parameters for the motion estimation are identical and standard statistical techniques can be used to estimated these parameters automatically <ref> [3, 28, 30, 39] </ref>. Additionally, statistical measures of the accuracy of the motion estimation within a region might be used to provide a confidence measure. Finally, this paper has presented the fitting and deformation process as a one-shot algorithm.
Reference: [31] <author> B. D. Lucas and T. Kanade. </author> <title> An iterative image registration technique with an application to stereo vision. </title> <booktitle> In Proc. 7th IJCAI, </booktitle> <pages> pages 674-679, </pages> <address> Vancouver, </address> <publisher> B. </publisher> <address> C., Canada, </address> <year> 1981. </year>
Reference-contexts: These techniques use regression or a Hough transform to estimate a few parameters (eg. two, six, or eight) given hundreds or thousands of constraints computed over the entire image or some pre-selected region <ref> [6, 16, 17, 25, 31, 49] </ref>; when the image motion conforms to the model assumptions this produces accurate flow estimates. <p> 15:84 ffi 13:46 ffi 100% Singh [41] 13:16 ffi 12:07 ffi 100% Nagel [36] 11:71 ffi 10:59 ffi 100% Horn and Schunck (modified) [21] 11:26 ffi 16:41 ffi 100% Uras et al. [45] 10:44 ffi 15:00 ffi 100% Fleet and Jepson [17] 4:29 ffi 11:24 ffi 34:1% Lucas and Kanade <ref> [31] </ref> 4:10 ffi 9:58 ffi 35:1% Weber and Malik [50] 3:42 ffi 5:35 ffi 45:2% Black and Anandan [11]fl 4:47 ffi 3:90 ffi 100% Black [10]fl 3:52 ffi 3:25 ffi 100% Parametric+Deformationfl 2:29 ffi 2:25 ffi 100% Table 1: Comparison of various optical flow algorithms. ence image gives another look at <p> The accuracy of the approach is in the range of the most accurate approaches but with 100% density (not counting the sky). Methods followed by a fl have errors computed without the sky region while the other methods include the sky. In [5] the error for Lucas and Kanade <ref> [31] </ref> and Fleet and Jepson [17] improves to 3:37 ffi and 2:97 ffi respectively when the sky is omitted though the density remains low. <p> The approach produces good results on a wide variety of image sequences for two primary reasons. The first is that the segmented regions provide large areas for integrating multiple constraints and, as opposed to methods which choose a particular fixed region size/shape (eg. <ref> [31] </ref>), the segmented regions are less likely in general to contain multiple motions; or, said another way, are more likely to correspond to actual planar surfaces in the scene.
Reference: [32] <author> W. Luo and H. Matre. </author> <title> Using surface model to correct and fit disparity data in stereo vision. </title> <booktitle> In Proc. IEEE Int. Conf. on Pattern Recognition, </booktitle> <pages> pages 60-64, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: The motion information available over an entire region, particularly if it is reasonably textured, provides additional constraints which can improve the accuracy of the recovered motion. In the context of stereo reconstruction, Luo and Matre <ref> [32] </ref> use a segmented intensity image to correct and improve disparity estimates by fitting a plane to the disparities within a region of uniform brightness. The accuracy of this approach is affected by the accuracy of the initial disparity estimates. <p> For each static region the error of using each of these parametric motions is evaluated. The regions are finally labeled with the motion parameters that give the lowest error. 2.3 The Proposed Method The approach described here is similar in its first stage to that of <ref> [32] </ref> in that coarse flow estimates are computed and then parametric models are fit to the estimates within the segmented brightness regions. This process significantly improves the coarse motion estimates but we use this only as an initialization step.
Reference: [33] <author> W. J. MacLean, A. D. Jepson, and R. C. Frecker. </author> <title> Recovery of egomotion and segmentation of independent object motion using the em algorithm. </title> <booktitle> In Proc. British Machine Vision Conf., </booktitle> <address> York, U.K., </address> <year> 1994. </year>
Reference-contexts: A rigid-body assumption could be incorporated into the flow estimation to constrain the motion of patches to be consistent with a rigid scene. An immediate application of this would be the detection of independently moving regions in the scene whose motion is inconsistent with a rigid 3D interpretation <ref> [33] </ref>. Due to over-segmentation based on brightness, the localization of objects, as opposed to surfaces patches, may require grouping patches together based on common motion.
Reference: [34] <author> G.J. McLachlan and K.E. Basford. </author> <title> Mixture Models: Inference and Applications to Clustering. </title> <publisher> Marcel Dekker Inc., </publisher> <address> N.Y., </address> <year> 1988. </year> <month> 33 </month>
Reference-contexts: The objective function is minimized using an algorithm similar to the EM-algorithm <ref> [34] </ref> in which at each iteration we solve for the m s and l s;t in closed form and then update the i s using one step of Newton's method. The initial estimate for is just taken to be d.
Reference: [35] <author> F. G. Meyer and P. Bouthemy. </author> <title> Region based tracking using affine motion models in long image sequences. CVGIP: </title> <booktitle> Image Understanding, </booktitle> <volume> 60(2) </volume> <pages> 119-140, </pages> <month> September </month> <year> 1994. </year>
Reference-contexts: This approach begins to deal with the issue of estimating the motion of segmented regions but, like the other global parametric approaches it assumes a single dominant motion and a 3 small number of outlying motions. Meyer and Bouthemy <ref> [35] </ref> use a motion segmentation technique to extract regions corresponding to independently moving objects. The optical flow within these regions is then modeled and estimated using a parametric flow model (eg. affine). The regions and their boundaries are tracked and updated over time. <p> Finally, this paper has presented the fitting and deformation process as a one-shot algorithm. In fact, it may be useful for this process to iterate in the context of an incremental estimation scheme where estimates are refined over an image sequence (cf. <ref> [4, 10, 35] </ref>). 8 Conclusion This paper has presented a new model for estimating optical flow based on the motion of planar regions plus local deformations.
Reference: [36] <author> H. H. Nagel. </author> <title> On the estimation of optical flow: Relations between different approaches and some new results. </title> <journal> Artificial Intelligence, </journal> <volume> 33(3) </volume> <pages> 299-324, </pages> <month> November </month> <year> 1987. </year>
Reference-contexts: The largest angular errors occur in regions which were in fact non-planar (most of the scene contains rolling hills). The vector differ <p>- 21 Technique Average Standard Density Error Deviation Anandan [2] 15:84 ffi 13:46 ffi 100% Singh [41] 13:16 ffi 12:07 ffi 100% Nagel <ref> [36] </ref> 11:71 ffi 10:59 ffi 100% Horn and Schunck (modified) [21] 11:26 ffi 16:41 ffi 100% Uras et al. [45] 10:44 ffi 15:00 ffi 100% Fleet and Jepson [17] 4:29 ffi 11:24 ffi 34:1% Lucas and Kanade [31] 4:10 ffi 9:58 ffi 35:1% Weber and Malik [50] 3:42 ffi 5:35 ffi
Reference: [37] <author> M. Otte and H. H. Nagel. </author> <title> Optical flow estimation: Advances and comparisons. </title> <editor> In J. Eklundh, editor, </editor> <booktitle> European Conf. on Computer Vision, ECCV-94, volume 800 of LNCS-Series, </booktitle> <pages> pages 51-60, </pages> <address> Stockholm, Sweden, 1994. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: For an additional point of comparison we also compute the mean of the absolute vector difference in pixels between the estimated and the true 9 a b downward motion = white). (c) Actual vector field. (d) Computed coarse vector field. flow vectors <ref> [37] </ref>.
Reference: [38] <author> A. Pentland and S. Sclaroff. </author> <title> Closed-form solutions for physically based shape modeling and recognition. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 13(7):715729, </volume> <month> July </month> <year> 1991. </year>
Reference-contexts: This is similar to work which uses superquadrics to compute a coarse parametric description of 3D shape and then allows local deformations to account for fine structure <ref> [38, 43] </ref>. It is also related to work on decomposing rigid image motion into the motion of a plane plus residual motion parallax [40]. 3 Early Processing At the low level there are two processes which examine the input images: segmentation and coarse motion estimation.
Reference: [39] <author> P. J. Rousseeuw and A. M. Leroy. </author> <title> Robust Regression and Outlier Detection. </title> <publisher> John Wiley & Sons, </publisher> <address> New York, </address> <year> 1987. </year>
Reference-contexts: The motion estimation method, on the other hand, is not very sensitive to the choice of parameters as has been demonstrated elsewhere [12]. In nearly all the experiments, the parameters for the motion estimation are identical and standard statistical techniques can be used to estimated these parameters automatically <ref> [3, 28, 30, 39] </ref>. Additionally, statistical measures of the accuracy of the motion estimation within a region might be used to provide a confidence measure. Finally, this paper has presented the fitting and deformation process as a one-shot algorithm.
Reference: [40] <author> H. S. Sawhney. </author> <title> 3D geometry from planar parallax. In Computer Vision and Pattern Recognition, </title> <booktitle> CVPR-94, </booktitle> <pages> pages 929-934, </pages> <address> Seattle, WA, </address> <year> 1994. </year>
Reference-contexts: It is also related to work on decomposing rigid image motion into the motion of a plane plus residual motion parallax <ref> [40] </ref>. 3 Early Processing At the low level there are two processes which examine the input images: segmentation and coarse motion estimation. <p> This notion of modeling optical flow using a planar motion plus a general flow field has recently been used for recover 3D structure <ref> [40] </ref>. In a rigid scene the image motion of an arbitrary plane can be estimated and used to stabilize two images in the sequence effectively removing the rigid camera rotation. <p> This simple relationship to 3D structure has been used for recovering structure from motion <ref> [27, 40] </ref>. Unlike these planar parallax approaches we do not stabilize the entire scene based on a single planar motion but, rather, stabilize an isolated patch based on its motion.
Reference: [41] <author> A. Singh. </author> <title> Optic Flow Computation: A Unified Perspective. </title> <publisher> IEEE Computer Society Press, </publisher> <year> 1992. </year>
Reference-contexts: The largest angular errors occur in regions which were in fact non-planar (most of the scene contains rolling hills). The vector differ <p>- 21 Technique Average Standard Density Error Deviation Anandan [2] 15:84 ffi 13:46 ffi 100% Singh <ref> [41] </ref> 13:16 ffi 12:07 ffi 100% Nagel [36] 11:71 ffi 10:59 ffi 100% Horn and Schunck (modified) [21] 11:26 ffi 16:41 ffi 100% Uras et al. [45] 10:44 ffi 15:00 ffi 100% Fleet and Jepson [17] 4:29 ffi 11:24 ffi 34:1% Lucas and Kanade [31] 4:10 ffi 9:58 ffi 35:1% Weber
Reference: [42] <author> S. Sull and N. Ahuja. </author> <title> Segmentation, matching and estimation of structure and motion of tex-tured piecewise planar surfaces. </title> <booktitle> In Proc. IEEE Workshop on Visual Motion, </booktitle> <pages> pages 274-279, </pages> <address> Princeton, NJ, </address> <month> October </month> <year> 1991. </year>
Reference-contexts: There are numerous feature-based schemes which estimate motion by tracking points, edges, or 4 region contours computed from the brightness image (eg. [47]). Sull and Ahuja <ref> [42] </ref> estimate the motion of region boundaries and follow this with a Hough technique that groups the regions into planar surfaces. These approaches use information about image brightness to constrain the motion estimation, but brightness contours alone are an impoverished representation.
Reference: [43] <author> D. Terzopoulos and D. Metaxas. </author> <title> Dynamic 3D models with local and global deformations: Deformable superquadrics. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 13(7) </volume> <pages> 703-714, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: This is similar to work which uses superquadrics to compute a coarse parametric description of 3D shape and then allows local deformations to account for fine structure <ref> [38, 43] </ref>. It is also related to work on decomposing rigid image motion into the motion of a plane plus residual motion parallax [40]. 3 Early Processing At the low level there are two processes which examine the input images: segmentation and coarse motion estimation.
Reference: [44] <author> W. B. Thompson. </author> <title> Combining motion and contrast for segmentation. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> PAMI-2:543-549, </volume> <year> 1980. </year>
Reference-contexts: Addi- tionally they fail to exploit information present in the image brightness about the nature of surfaces in the scene. 2.2 Exploiting Image Brightness To improve motion segmentation a number of researchers have attempted to combine intensity and motion information. Thompson <ref> [44] </ref> describes a region merging technique which uses similarity constraints on brightness and motion for segmentation. Heitz and Bouthemy [20] combine gradient- based and edge-based motion estimation and realize improved motion estimates and the localization of motion discontinuities.
Reference: [45] <author> S. Uras, F. Girosi, A. Verri, and V. Torre. </author> <title> A computational approach to motion perception. </title> <journal> Biological Cybernetics, </journal> <volume> 60 </volume> <pages> 79-97, </pages> <year> 1989. </year> <month> 34 </month>
Reference-contexts: The vector differ <p>- 21 Technique Average Standard Density Error Deviation Anandan [2] 15:84 ffi 13:46 ffi 100% Singh [41] 13:16 ffi 12:07 ffi 100% Nagel [36] 11:71 ffi 10:59 ffi 100% Horn and Schunck (modified) [21] 11:26 ffi 16:41 ffi 100% Uras et al. <ref> [45] </ref> 10:44 ffi 15:00 ffi 100% Fleet and Jepson [17] 4:29 ffi 11:24 ffi 34:1% Lucas and Kanade [31] 4:10 ffi 9:58 ffi 35:1% Weber and Malik [50] 3:42 ffi 5:35 ffi 45:2% Black and Anandan [11]fl 4:47 ffi 3:90 ffi 100% Black [10]fl 3:52 ffi 3:25 ffi 100% Parametric+Deformationfl 2:29
Reference: [46] <author> J. Y. A. Wang and E. H. Adelson. </author> <title> Representing moving images with layers. </title> <journal> IEEE Transactions on Image Processing, </journal> <volume> 3(5) </volume> <pages> 625-638, </pages> <month> September </month> <year> 1994. </year>
Reference-contexts: Another set of approaches apply parametric models to coarse flow fields by grouping the flow vectors into consistent regions. Adiv [1] uses a Hough technique to group flow measurements into regions consistent with the motion of planar surfaces. The approach of Wang and Adelson <ref> [46] </ref> is similar but uses a k-means clustering algorithm to group the flow vectors into layers of consistent affine motion. These approaches, like the regression approaches, are essentially global techniques in that they assume the image motion can be represented by a small number of global layers. <p> Due to over-segmentation based on brightness, the localization of objects, as opposed to surfaces patches, may require grouping patches together based on common motion. The approaches of Ayer et al. [4] and Wang and Adelson <ref> [46] </ref> present possible methods for achieving this grouping and do not appear to exhibit the kinds over-segmentation we see with our method. <p> The addition of temporal integration might also improve the accuracy, efficiency, and robustness of the method. Moreover, it may be possible to incorporate a layered representation which can represent occluded portions of regions viewed over many frames as in the work of Wang and Adelson <ref> [46] </ref>. This segmented and layered representation of a video stream might be useful for video coding; for example, MPEG-4. Under-segmentation is also an issue. For example, in our experiments with moving people, their legs are often segmented into a single region based on brightness.
Reference: [47] <author> A. Waxman. </author> <title> An image flow paradigm. </title> <booktitle> In Proc. IEEE Workshop on Computer Vision: Representation and Control, </booktitle> <pages> pages 49-55, </pages> <address> Annapolis, MD, </address> <year> 1984. </year>
Reference-contexts: There are numerous feature-based schemes which estimate motion by tracking points, edges, or 4 region contours computed from the brightness image (eg. <ref> [47] </ref>). Sull and Ahuja [42] estimate the motion of region boundaries and follow this with a Hough technique that groups the regions into planar surfaces. These approaches use information about image brightness to constrain the motion estimation, but brightness contours alone are an impoverished representation.
Reference: [48] <author> A. M. Waxman, B. Kamgar-Parsi, and M. Subbarao. </author> <title> Close-form solutions to image flow equa-tions forr 3D-structure and motion. </title> <journal> International Journal of Computer Vision, </journal> (3):239-258, 1987. 
Reference-contexts: These regions become our planar-surface hypotheses. Issues relating to under- and over-segmentation are addressed in Section 7. 4.1 Fitting Parametric Models to Flow Estimates The image motion of a rigid planar region of the scene can be described by the following eight- parameter model <ref> [1, 48] </ref>: u (x; y) = a 0 + a 1 x + a 2 y + a 6 x 2 + a 7 xy; (4) 11 where the a i are parameters to be estimated and where u (x; y) and v (x; y) are the horizontal and vertical components
Reference: [49] <author> A. M. Waxman and K. Wohn. </author> <title> Contour evolution, neighbourhood deformation and global image flow: Planar surfaces in motion. </title> <journal> Int. J. of Robotics Research, </journal> <volume> 4 </volume> <pages> 95-108, </pages> <year> 1985. </year>
Reference-contexts: These techniques use regression or a Hough transform to estimate a few parameters (eg. two, six, or eight) given hundreds or thousands of constraints computed over the entire image or some pre-selected region <ref> [6, 16, 17, 25, 31, 49] </ref>; when the image motion conforms to the model assumptions this produces accurate flow estimates.
Reference: [50] <author> J. Weber and J. Malik. </author> <title> Robust computation of optical flow in a multi-scale differential frame-work. </title> <booktitle> In Proc. Int. Conf. on Computer Vision, ICCV-93, </booktitle> <pages> pages 12-20, </pages> <address> Berlin, Germany, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: 12:07 ffi 100% Nagel [36] 11:71 ffi 10:59 ffi 100% Horn and Schunck (modified) [21] 11:26 ffi 16:41 ffi 100% Uras et al. [45] 10:44 ffi 15:00 ffi 100% Fleet and Jepson [17] 4:29 ffi 11:24 ffi 34:1% Lucas and Kanade [31] 4:10 ffi 9:58 ffi 35:1% Weber and Malik <ref> [50] </ref> 3:42 ffi 5:35 ffi 45:2% Black and Anandan [11]fl 4:47 ffi 3:90 ffi 100% Black [10]fl 3:52 ffi 3:25 ffi 100% Parametric+Deformationfl 2:29 ffi 2:25 ffi 100% Table 1: Comparison of various optical flow algorithms. ence image gives another look at the performance.
References-found: 50

