URL: http://www.ri.cmu.edu/afs/cs.cmu.edu/project/phrensy/pub/papers/ColeMS94.ps
Refering-URL: http://www.ri.cmu.edu/afs/cs.cmu.edu/user/bmm/public/www/papers.html
Root-URL: 
Title: RECONFIGURING ARRAYS WITH FAULTS PART I: WORST-CASE FAULTS  
Author: RICHARD J. COLE BRUCE M. MAGGS AND RAMESH K. SITARAMAN 
Keyword: Key words. fault tolerance, array-based network, mesh network, network emulation  
Note: AMS subject classifications. 68M07, 68M10, 68M15, 68Q68  
Abstract: In this paper we study the ability of array-based networks to tolerate worst-case faults. We show that an N fi N two-dimensional array can sustain N 1* worst-case faults, for any fixed * &gt; 0, and still emulate T steps of a fully functioning N fi N array in O(T + N ) steps, i.e., with only constant slowdown. Previously it was known only that an array could tolerate a constant number of faults with constant slowdown. We also show that if faulty nodes are allowed to communicate, but not compute, then an N -node one-dimensional array can tolerate log k N worst-case faults, for any constant k &gt; 0, and still emulate a fault-free array with constant slowdown, and this bound is tight. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Ajtai, N. Alon, J. Bruck, R. Cypher, C. T. Ho, M. Naor, and E. Szemeredi. </author> <title> Fault tolerant graphs, perfect hash functions and disjoint paths. </title> <booktitle> In Proceedings of the 33rd Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 693-702, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: He also showed how to construct a bounded-degree network with the property that even if N (12 d )=d worst-case faults are placed in the network, the network is guaranteed to contain an N -node d-dimensional array as a subgraph. Ajtai et al. <ref> [1] </ref> analyzed the technique of adding spare nodes to larger classes of networks that include meshes. In all of these constructions the VLSI layout area requirements of the networks with spare nodes and edges are much larger than those of the arrays that they contain as subgraphs.
Reference: [2] <author> Y. Aumann and M. Ben-Or. </author> <title> Computing with faulty arrays. </title> <booktitle> In Proceedings of the 24th Annual ACM Symposium on the Theory of Computing, </booktitle> <pages> pages 162-169, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: They also showed that, with high probability, an N fi N mesh with constant-probability failures can emulate a fault- free N p p log N mesh with O (log N ) slowdown. (Throughout this paper the base of the function log is 2.) Aumann and Ben-Or <ref> [2] </ref> used Rabin's information dispersal technique [19] to show 4 R. J. COLE AND B. M. MAGGS AND R. K.
Reference: [3] <author> T. Blank. </author> <title> The maspar mp-1 architecture. </title> <booktitle> In compcon90, </booktitle> <pages> pages 20-24, </pages> <month> February </month> <year> 1990. </year> <title> RECONFIGURING ARRAYS WITH FAULTS PART I: WORST-CASE FAULTS 31 </title>
Reference-contexts: The solution to this problem depends on the communication topology of the computer. One of the most popular ways to construct a parallel computer is to arrange the processors as a two-dimensional or three-dimensional array. Commercial machines including the Cray T3D [10] and MasPar MP-1 <ref> [3] </ref> have this topology, as do experimental machines such as iWarp [4] and the J-Machine [18]. In this paper we study the ability of machines like these to tolerate faults.
Reference: [4] <author> S. Borkar, R. Cohn, G. Cox, S. Gleason, T. Gross, H. T. Kung, M. Lam, B. Moore, C. Peterson, J. Pieper, L. Rankin, P.S. Tseng, J. Sutton, J. Urbanski, and J Webb. </author> <title> iWarp, an integrated solution to high-speed parallel computing. </title> <booktitle> In Proceedings Supercomputing '88, </booktitle> <pages> pages 330339, </pages> <month> November </month> <year> 1988. </year>
Reference-contexts: One of the most popular ways to construct a parallel computer is to arrange the processors as a two-dimensional or three-dimensional array. Commercial machines including the Cray T3D [10] and MasPar MP-1 [3] have this topology, as do experimental machines such as iWarp <ref> [4] </ref> and the J-Machine [18]. In this paper we study the ability of machines like these to tolerate faults.
Reference: [5] <author> J. Bruck, R. Cypher, and C.-T. Ho. </author> <title> Fault-tolerant meshes with small degree. </title> <booktitle> In Proceedings of the 5th Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 1-10, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: Bruck, Cypher, and Ho <ref> [5] </ref> showed that by adding some spare nodes and edges to a mesh, it is possible for the mesh to sustain many faults and still contain a working fault-free N fiN mesh as a subgraph.
Reference: [6] <author> M. R. Fellows. </author> <title> Encoding Graphs in Graphs. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of California, </institution> <address> San Diego, CA, </address> <year> 1985. </year>
Reference-contexts: The technique of redundant computation was previously used to tolerate faults in hypercubic networks [13], and to construct work-preserving emulations in fault-free networks <ref> [6, 9, 15, 16, 17, 21] </ref>. 1.4. Previous work. A large number of researchers have studied the ability of arrays and other networks to tolerate faults. The most relevant papers are described below. Raghavan [20] devised a randomized algorithm for solving one-to-one routing problems on N fi N meshes. <p> some host node such that for each guest time step the same instance v 0 sends a packet for the edge e to u 0 . (Note that v 0 may also send packets to other instances of u.) The emulations that use redundant computation in this paper and in <ref> [6, 9, 13, 21] </ref> are all static. 2. A simple method for tolerating worst-case faults on the mesh.
Reference: [7] <author> J. W. Greene and A. El Gamal. </author> <title> Configuration of VLSI arrays in the presence of defects. </title> <journal> Journal of the ACM, </journal> <volume> 31(4) </volume> <pages> 694-717, </pages> <month> October </month> <year> 1984. </year>
Reference-contexts: faults in an N -node 2- or 3-dimensional array H, where f (N ) is any function that is !(1), it is possible to force either the load, congestion, or dilation of every embedding of an array G of the same size and dimension to be larger than a constant <ref> [7, 8, 12] </ref>. Similarly, if fi (N ) faults are placed in H at random, then with high probability every embedding of G in H will have !(1) load, congestion, or dilation.
Reference: [8] <author> C. Kaklamanis, A. R. Karlin, F. T. Leighton, V. Milenkovic, P. Raghavan, S. Rao, C. Thomborson, and A. Tsantilas. </author> <title> Asymptotically tight bounds for computing with faulty arrays of processors. </title> <booktitle> In Proceedings of the 31st Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 285-296. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> October </month> <year> 1990. </year>
Reference-contexts: faults in an N -node 2- or 3-dimensional array H, where f (N ) is any function that is !(1), it is possible to force either the load, congestion, or dilation of every embedding of an array G of the same size and dimension to be larger than a constant <ref> [7, 8, 12] </ref>. Similarly, if fi (N ) faults are placed in H at random, then with high probability every embedding of G in H will have !(1) load, congestion, or dilation. <p> Mathies [14] improved the p :29 bound to p :4. Kaklamanis et al. <ref> [8] </ref> improved Raghavan's result by devising a deterministic routing algorithm. For almost all random fault patterns, the algorithm guarantees that any packet that can reach its destination does so within O (N ) steps. This algorithm can also tolerate worst-case faults.
Reference: [9] <author> R. Koch, T. Leighton, B. Maggs, S. Rao, and A. Rosenberg. </author> <title> Work-preserving emulations of fixed-connection networks. </title> <booktitle> In Proceedings of the 21st Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 227-240, </pages> <month> May </month> <year> 1989. </year>
Reference-contexts: The technique of redundant computation was previously used to tolerate faults in hypercubic networks [13], and to construct work-preserving emulations in fault-free networks <ref> [6, 9, 15, 16, 17, 21] </ref>. 1.4. Previous work. A large number of researchers have studied the ability of arrays and other networks to tolerate faults. The most relevant papers are described below. Raghavan [20] devised a randomized algorithm for solving one-to-one routing problems on N fi N meshes. <p> some host node such that for each guest time step the same instance v 0 sends a packet for the edge e to u 0 . (Note that v 0 may also send packets to other instances of u.) The emulations that use redundant computation in this paper and in <ref> [6, 9, 13, 21] </ref> are all static. 2. A simple method for tolerating worst-case faults on the mesh.
Reference: [10] <author> R. K. Koeninger, M. Furtney, and M. Walker. </author> <title> A shared MPP from Cray research. </title> <journal> Digital Technical Journal, </journal> <volume> 6(2) </volume> <pages> 8-21, </pages> <month> Spring </month> <year> 1994. </year>
Reference-contexts: The solution to this problem depends on the communication topology of the computer. One of the most popular ways to construct a parallel computer is to arrange the processors as a two-dimensional or three-dimensional array. Commercial machines including the Cray T3D <ref> [10] </ref> and MasPar MP-1 [3] have this topology, as do experimental machines such as iWarp [4] and the J-Machine [18]. In this paper we study the ability of machines like these to tolerate faults.
Reference: [11] <author> F. T. Leighton, B. M. Maggs, and S. B. Rao. </author> <title> Packet routing and job-shop scheduling in O(congestion + dilation) steps. </title> <journal> Combinatorica, </journal> <volume> 14(2) </volume> <pages> 167-180, </pages> <year> 1994. </year>
Reference-contexts: The dilation is the maximum length of any path. Given an embedding of G into H, H can emulate each step of the computation of G by routing a packet for each edge of G along the corresponding path in H. Leighton, Maggs, and Rao <ref> [11] </ref> showed that if the embedding has load l, congestion c, and dilation d, then the packets can be routed so that the slowdown of the emulation is O (l + c + d).
Reference: [12] <author> T. Leighton and C. E. Leiserson. </author> <title> Wafer-scale integration of systolic arrays. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-34(5):448-461, </volume> <month> May </month> <year> 1985. </year>
Reference-contexts: faults in an N -node 2- or 3-dimensional array H, where f (N ) is any function that is !(1), it is possible to force either the load, congestion, or dilation of every embedding of an array G of the same size and dimension to be larger than a constant <ref> [7, 8, 12] </ref>. Similarly, if fi (N ) faults are placed in H at random, then with high probability every embedding of G in H will have !(1) load, congestion, or dilation.
Reference: [13] <author> T. Leighton, B. Maggs, and R. Sitaraman. </author> <title> On the fault tolerance of some popular boundeddegree networks. </title> <booktitle> In Proceedings of the 33rd Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 542-552, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: This extra freedom makes it possible to tolerate more faults, but it adds the complication of ensuring that different emulations of the same node of G remain consistent over time. The technique of redundant computation was previously used to tolerate faults in hypercubic networks <ref> [13] </ref>, and to construct work-preserving emulations in fault-free networks [6, 9, 15, 16, 17, 21]. 1.4. Previous work. A large number of researchers have studied the ability of arrays and other networks to tolerate faults. The most relevant papers are described below. <p> In all of these constructions the VLSI layout area requirements of the networks with spare nodes and edges are much larger than those of the arrays that they contain as subgraphs. Leighton, Maggs, and Sitaraman <ref> [13] </ref> showed that an N -node butterfly can tolerate N 1* worst-case faults, for any fixed * &gt; 0, and still emulate a fault-free N - node butterfly with constant slowdown. They proved the same result for the shu*e- exchange network. <p> some host node such that for each guest time step the same instance v 0 sends a packet for the edge e to u 0 . (Note that v 0 may also send packets to other instances of u.) The emulations that use redundant computation in this paper and in <ref> [6, 9, 13, 21] </ref> are all static. 2. A simple method for tolerating worst-case faults on the mesh.
Reference: [14] <author> T. R. Mathies. </author> <title> Percolation theory and computing with faulty arrays of processors. </title> <booktitle> In Proceedings of the 3rd Annual ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <pages> pages 100-103, </pages> <month> January </month> <year> 1992. </year>
Reference-contexts: He showed that even if each node fails with some fixed probability p :29, then for almost all random fault patterns, any packet that can reach its destination does so in O (N log N ) steps, with high probability. Mathies <ref> [14] </ref> improved the p :29 bound to p :4. Kaklamanis et al. [8] improved Raghavan's result by devising a deterministic routing algorithm. For almost all random fault patterns, the algorithm guarantees that any packet that can reach its destination does so within O (N ) steps.
Reference: [15] <editor> F. Meyer auf der Heide. </editor> <title> Efficiency of universal parallel computers. </title> <journal> Acta Informatica, </journal> <volume> 19:269296, </volume> <year> 1983. </year>
Reference-contexts: The technique of redundant computation was previously used to tolerate faults in hypercubic networks [13], and to construct work-preserving emulations in fault-free networks <ref> [6, 9, 15, 16, 17, 21] </ref>. 1.4. Previous work. A large number of researchers have studied the ability of arrays and other networks to tolerate faults. The most relevant papers are described below. Raghavan [20] devised a randomized algorithm for solving one-to-one routing problems on N fi N meshes.
Reference: [16] <editor> F. Meyer auf der Heide. </editor> <title> Efficient simulations among several models of parallel computers. </title> <journal> SIAM Journal on Computing, </journal> <volume> 15(1) </volume> <pages> 106-119, </pages> <month> February </month> <year> 1986. </year>
Reference-contexts: The technique of redundant computation was previously used to tolerate faults in hypercubic networks [13], and to construct work-preserving emulations in fault-free networks <ref> [6, 9, 15, 16, 17, 21] </ref>. 1.4. Previous work. A large number of researchers have studied the ability of arrays and other networks to tolerate faults. The most relevant papers are described below. Raghavan [20] devised a randomized algorithm for solving one-to-one routing problems on N fi N meshes.
Reference: [17] <editor> F. Meyer auf der Heide and R. </editor> <title> Wanka. Time-optimal simulations of networks by universal par-allel computers. </title> <booktitle> In Proceedings of the 6th Symposium on Theoretical Aspects of Computer Science, </booktitle> <pages> pages 120-131, </pages> <year> 1989. </year>
Reference-contexts: The technique of redundant computation was previously used to tolerate faults in hypercubic networks [13], and to construct work-preserving emulations in fault-free networks <ref> [6, 9, 15, 16, 17, 21] </ref>. 1.4. Previous work. A large number of researchers have studied the ability of arrays and other networks to tolerate faults. The most relevant papers are described below. Raghavan [20] devised a randomized algorithm for solving one-to-one routing problems on N fi N meshes.
Reference: [18] <author> M. D. Noakes, D. A. Wallach, and W. J. Dally. </author> <title> The J-Machine multicomputer: an architectural evaluation. </title> <booktitle> In Proceedings of the 20th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 224-235, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: One of the most popular ways to construct a parallel computer is to arrange the processors as a two-dimensional or three-dimensional array. Commercial machines including the Cray T3D [10] and MasPar MP-1 [3] have this topology, as do experimental machines such as iWarp [4] and the J-Machine <ref> [18] </ref>. In this paper we study the ability of machines like these to tolerate faults.
Reference: [19] <author> M. O. Rabin. </author> <title> Efficient dispersal of information for security, load balancing, and fault tolerance. </title> <journal> Journal of the ACM, </journal> <volume> 36(2), </volume> <month> April </month> <year> 1989. </year>
Reference-contexts: showed that, with high probability, an N fi N mesh with constant-probability failures can emulate a fault- free N p p log N mesh with O (log N ) slowdown. (Throughout this paper the base of the function log is 2.) Aumann and Ben-Or [2] used Rabin's information dispersal technique <ref> [19] </ref> to show 4 R. J. COLE AND B. M. MAGGS AND R. K.
Reference: [20] <author> P. Raghavan. </author> <title> Robust algorithms for packet routing in a mesh. </title> <booktitle> In Proceedings of the 1989 ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 344-350, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: Previous work. A large number of researchers have studied the ability of arrays and other networks to tolerate faults. The most relevant papers are described below. Raghavan <ref> [20] </ref> devised a randomized algorithm for solving one-to-one routing problems on N fi N meshes.
Reference: [21] <author> E. J. Schwabe. </author> <title> On the computational equivalence of hypercube-derived networks. </title> <booktitle> In Proceedings of the 2nd Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 388397, </pages> <month> July </month> <year> 1990. </year>
Reference-contexts: The technique of redundant computation was previously used to tolerate faults in hypercubic networks [13], and to construct work-preserving emulations in fault-free networks <ref> [6, 9, 15, 16, 17, 21] </ref>. 1.4. Previous work. A large number of researchers have studied the ability of arrays and other networks to tolerate faults. The most relevant papers are described below. Raghavan [20] devised a randomized algorithm for solving one-to-one routing problems on N fi N meshes. <p> some host node such that for each guest time step the same instance v 0 sends a packet for the edge e to u 0 . (Note that v 0 may also send packets to other instances of u.) The emulations that use redundant computation in this paper and in <ref> [6, 9, 13, 21] </ref> are all static. 2. A simple method for tolerating worst-case faults on the mesh.
Reference: [22] <author> H. Tamaki. </author> <title> Efficient self-embedding of butterfly networks with random faults. </title> <booktitle> In Proceedings of the 33rd Annual Symposium on Foundations of Computer Science, </booktitle> <month> October </month> <year> 1992. </year> <pages> 533-541. </pages>
Reference-contexts: Tamaki independently showed that, with high probability, an N -node butterfly can be embedded in an N -node butterfly containing constant- probability node failures with load O (1), congestion O ((log log N ) 8:2 ), and dilation O ((log log N ) 2:6 ) <ref> [22] </ref>. In [23], he proved a similar result for a class of networks called cube-connected arrays. 1.5. Our results.
Reference: [23] <author> H. Tamaki. </author> <title> Robust bounded-degree networks with small diameters. </title> <booktitle> In Proceedings of the 4th Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 247-256, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: Tamaki independently showed that, with high probability, an N -node butterfly can be embedded in an N -node butterfly containing constant- probability node failures with load O (1), congestion O ((log log N ) 8:2 ), and dilation O ((log log N ) 2:6 ) [22]. In <ref> [23] </ref>, he proved a similar result for a class of networks called cube-connected arrays. 1.5. Our results.
Reference: [24] <author> H. Tamaki. </author> <title> Construction of the mesh and the torus tolerating a large number of faults. </title> <booktitle> In Proceedings of the 6th Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 268-277, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: In both cases, the networks have bounded degree. Tamaki <ref> [24] </ref> showed how to construct an O (N )-node network with degree O (log log N ) with the property that, for any d 2, even if every node fails with constant probability, with high probability the network contains a fault-free N -node d-dimensional array as a subgraph.
References-found: 24

