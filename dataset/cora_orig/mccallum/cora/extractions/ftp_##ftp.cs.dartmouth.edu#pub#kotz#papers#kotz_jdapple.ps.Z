URL: ftp://ftp.cs.dartmouth.edu/pub/kotz/papers/kotz:jdapple.ps.Z
Refering-URL: http://www.cs.dartmouth.edu/~dfk/papers/jdapple.html
Root-URL: http://www.cs.dartmouth.edu
Note: Running head: DAPPLE This research was supported under grant DUE-9352796 by the National Science Foundation ILI-LLD program.  
Abstract: This paper will be typeset and appear in 'Computer Science Education' 6(2), copyright 1996 by Ablex Publishing. Earlier versions appeared in SIGCSE'95 and as Dartmouth PCS-TR95-235. Available at ftp://ftp.cs.dartmouth.edu/pub/kotz/papers/kotz:jdapple.ps.Z A DAta-Parallel Programming Library for Education (DAPPLE) David Kotz Department of Computer Science Dartmouth College Hanover, NH 03755-3510 dfk@cs.dartmouth.edu Acknowledgements. Many thanks to all of those who made suggestions about the language or this paper, or helped with subtle points of C++ technique, including Owen Astrachan, Tom Cormen, Fillia Makedon, Takis Metaxas, Nils Nieuwejaar, Sam Rebelsky, Scott Silver, and Cliff Stein. Thanks to Naval Ravikant for developing the wonderful animations, and to Prasad Jayanti and Cliff Stein for letting me experiment with their classes. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Miller, </author> <booktitle> "The status of parallel processing education" IEEE Computer, </booktitle> <volume> Vol. 27, No. 8, </volume> <month> August </month> <year> 1994, </year> <pages> pp. 40-43. </pages>
Reference-contexts: 1 Introduction Parallel computing, having been considered an advanced topic suitable only for graduate students, is slowly migrating into the undergraduate curriculum <ref> [1] </ref>. We believe parallelism should be introduced early in the curriculum, before the habits of sequential thinking are ingrained. Indeed, some have had success teaching the elementary concepts to high-school students [2].
Reference: [2] <author> A. Rifkin, </author> <title> "Teaching parallel programming and software engineering concepts to high school students", </title> <booktitle> SIGCSE Technical Symposium on Computer Science Education, </booktitle> <year> 1994, </year> <pages> pp. 26-30. </pages>
Reference-contexts: We believe parallelism should be introduced early in the curriculum, before the habits of sequential thinking are ingrained. Indeed, some have had success teaching the elementary concepts to high-school students <ref> [2] </ref>. When limited resources constrained our original plan to replace our CS2 data-structures and programming course with a course centered on parallel computing [3], we focused on the addition of a week-long module about parallel computing to the existing CS2 course. <p> More interestingly, the class was divided on whether the "live" demonstrations, where students acted out algorithms, were useful. Other researchers have successfully used such live demonstrations to teach parallel computing [19], even to high-school students <ref> [2] </ref>. Most of our students liked the demonstrations, but one even said they were "degrading," yet another example of how students prefer to learn in different ways. Students were also mixed on the use of HTML/Netscape lecture notes.
Reference: [3] <author> D. Johnson, D. Kotz, and F. Makedon, </author> <title> "Teaching parallel computing to freshmen", Conference on Parallel Computing for Undergraduates. Edited by C. </title> <institution> Nevison, Colgate University, </institution> <month> June </month> <year> 1994. </year>
Reference-contexts: Indeed, some have had success teaching the elementary concepts to high-school students [2]. When limited resources constrained our original plan to replace our CS2 data-structures and programming course with a course centered on parallel computing <ref> [3] </ref>, we focused on the addition of a week-long module about parallel computing to the existing CS2 course. We used the techniques described in this paper to teach parallel computing to first-year undergraduates in CS2. When teaching parallel computing to first-year undergraduates, one must carefully consider the approach.
Reference: [4] <author> G. E. Blelloch, "NESL: </author> <title> a nested data-parallel language", </title> <type> Technical Report CMU-CS-93-129, </type> <institution> Carnegie Mellon University, </institution> <address> Pittsburgh, PA, </address> <month> April </month> <year> 1993. </year>
Reference-contexts: Although many data-parallel languages exist, including C*, Fortran90, NESL <ref> [4] </ref>, and HPF [5], they are difficult to use, are not similar to C++, or are not easily portable to student computers. We found many research projects designing parallel C++ variants. <p> It restricts the context to the left partition and recurses, and then restricts the context to the right partition and recurses. The quicksort example demonstrates one weakness of DAPPLE, its inability to support nested data parallelism <ref> [4] </ref>. The two recursive calls to quicksort () must be done sequentially, each with only a small subset of the virtual processors active. Given this model, other sorting algorithms would be more appropriate.
Reference: [5] <author> D. B. Loveman, </author> <title> "High Performance Fortran" IEEE Parallel and Distributed Technology, </title> <journal> Vol. </journal> <volume> 1, No. 1, </volume> <month> February </month> <year> 1993, </year> <pages> pp. 25-42. </pages>
Reference-contexts: Although many data-parallel languages exist, including C*, Fortran90, NESL [4], and HPF <ref> [5] </ref>, they are difficult to use, are not similar to C++, or are not easily portable to student computers. We found many research projects designing parallel C++ variants.
Reference: [6] <author> J. R. Larus, B. Richards, and G. Viswanathan, </author> <title> "C**: A large-grain, object-oriented, data-parallel programming language", </title> <type> Technical Report #1126, </type> <institution> University of Wisconsin-Madison, </institution> <month> November </month> <year> 1992. </year>
Reference-contexts: Although many data-parallel languages exist, including C*, Fortran90, NESL [4], and HPF [5], they are difficult to use, are not similar to C++, or are not easily portable to student computers. We found many research projects designing parallel C++ variants. C** <ref> [6] </ref> is perhaps the closest candidate, in that it supports a data-parallel model, but it requires a new compiler and is not yet available. pC++ [7] can also provide a data-parallel model, using only a preprocessor and library, but its syntax is a little complicated for beginners. <p> A nested loop computes each element of the result matrix C as an inner product (dot product) of the appropriate row of A and the appropriate column of B, demonstrating DAPPLE's capability to work with matrix slices <ref> [6] </ref>. Here, A [r][_] is a row slice, representing row r of matrix A, and B [_][c] is a column slice, representing column c of matrix B. Slices may be used anywhere vectors may be used, including on the left-hand side of an assignment operator.
Reference: [7] <author> F. Bodin, P. Beckman, D. Gannon, S. Narayana, and S. X. Yang, </author> <title> "Distributed pC++: basic ideas for an object parallel language" Scientific Programming, </title> <journal> Vol. </journal> <volume> 2, No. 3, </volume> <month> Fall </month> <year> 1993, </year> <pages> pp. 7-22. </pages>
Reference-contexts: We found many research projects designing parallel C++ variants. C** [6] is perhaps the closest candidate, in that it supports a data-parallel model, but it requires a new compiler and is not yet available. pC++ <ref> [7] </ref> can also provide a data-parallel model, using only a preprocessor and library, but its syntax is a little complicated for beginners. Other data-parallel options like Presto++ [8] and Compositional C++ [9] are also rather complex for beginners.
Reference: [8] <author> M. F. Kilian, </author> <title> Parallel Sets: An Object-oriented Methodology for Massively Parallel Programming, </title> <type> PhD thesis, </type> <institution> Harvard University, </institution> <address> Cambridge, MA, </address> <year> 1992. </year>
Reference-contexts: Other data-parallel options like Presto++ <ref> [8] </ref> and Compositional C++ [9] are also rather complex for beginners. Others, like Mentat [10], CHARM++ [11], and COOL [12], are more task-parallel than data-parallel.
Reference: [9] <author> K. M. Chandy and C. Kesselman, </author> <title> "Compositional C++: Compositional parallel programming", </title> <type> Technical Report CS-TR-92-13, </type> <institution> California Institute of Technology, Pasadena, </institution> <address> CA, </address> <year> 1992. </year>
Reference-contexts: Other data-parallel options like Presto++ [8] and Compositional C++ <ref> [9] </ref> are also rather complex for beginners. Others, like Mentat [10], CHARM++ [11], and COOL [12], are more task-parallel than data-parallel.
Reference: [10] <author> A. S. Grimshaw, </author> <booktitle> "Easy-to-use object-oriented parallel processing with Mentat" IEEE Computer, </booktitle> <volume> Vol. 26, No. 5, </volume> <month> May </month> <year> 1993, </year> <pages> pp. 39-51. </pages>
Reference-contexts: Other data-parallel options like Presto++ [8] and Compositional C++ [9] are also rather complex for beginners. Others, like Mentat <ref> [10] </ref>, CHARM++ [11], and COOL [12], are more task-parallel than data-parallel. Recent efforts [13, 14, 15] are only in early stages of development. 1 Finding no suitable existing language, we decided to design and implement our own language as a set of macros and classes that extended C++.
Reference: [11] <author> L. Kale and S. Krishnan, "CHARM++: </author> <title> A portable concurrent object oriented system based on C++", </title> <booktitle> Proceedings of the Conference on Object Oriented Programming Systems, Languages and Applications, </booktitle> <year> 1993. </year> <month> 13 </month>
Reference-contexts: Other data-parallel options like Presto++ [8] and Compositional C++ [9] are also rather complex for beginners. Others, like Mentat [10], CHARM++ <ref> [11] </ref>, and COOL [12], are more task-parallel than data-parallel. Recent efforts [13, 14, 15] are only in early stages of development. 1 Finding no suitable existing language, we decided to design and implement our own language as a set of macros and classes that extended C++.
Reference: [12] <author> R. Chandra, A. Gupta, and J. L. Hennessey, </author> <title> "COOL: </title> <booktitle> an object-based language for parallel programming" IEEE Computer, </booktitle> <volume> Vol. 27, No. 8, </volume> <month> August </month> <year> 1994, </year> <pages> pp. 14-26. </pages>
Reference-contexts: Other data-parallel options like Presto++ [8] and Compositional C++ [9] are also rather complex for beginners. Others, like Mentat [10], CHARM++ [11], and COOL <ref> [12] </ref>, are more task-parallel than data-parallel. Recent efforts [13, 14, 15] are only in early stages of development. 1 Finding no suitable existing language, we decided to design and implement our own language as a set of macros and classes that extended C++.
Reference: [13] <author> E. A. West and A. S. Grimshaw, </author> <title> "Braid: Integrating task and data parallelism", </title> <booktitle> Proceedings of the Fifth Symposium on the Frontiers of Massively Parallel Computation, </booktitle> <month> February </month> <year> 1995, </year> <pages> pp. 211-219. </pages>
Reference-contexts: Other data-parallel options like Presto++ [8] and Compositional C++ [9] are also rather complex for beginners. Others, like Mentat [10], CHARM++ [11], and COOL [12], are more task-parallel than data-parallel. Recent efforts <ref> [13, 14, 15] </ref> are only in early stages of development. 1 Finding no suitable existing language, we decided to design and implement our own language as a set of macros and classes that extended C++. The result is DAPPLE, a DAta-Parallel Programming Library for Education.
Reference: [14] <author> T. J. She*er and S. Chatterjee, </author> <title> "An object-oriented approach to nested data parallelism", </title> <booktitle> Proceedings of the Fifth Symposium on the Frontiers of Massively Parallel Computation, </booktitle> <month> February </month> <year> 1995, </year> <pages> pp. 203-210. </pages>
Reference-contexts: Other data-parallel options like Presto++ [8] and Compositional C++ [9] are also rather complex for beginners. Others, like Mentat [10], CHARM++ [11], and COOL [12], are more task-parallel than data-parallel. Recent efforts <ref> [13, 14, 15] </ref> are only in early stages of development. 1 Finding no suitable existing language, we decided to design and implement our own language as a set of macros and classes that extended C++. The result is DAPPLE, a DAta-Parallel Programming Library for Education.
Reference: [15] <author> T. J. She*er, </author> <title> "A portable MPI-based parallel vector template library", </title> <type> Technical Report 95.04, </type> <institution> RIACS, NASA Ames Research Center, Moffett Field, </institution> <address> CA, </address> <year> 1995. </year>
Reference-contexts: Other data-parallel options like Presto++ [8] and Compositional C++ [9] are also rather complex for beginners. Others, like Mentat [10], CHARM++ [11], and COOL [12], are more task-parallel than data-parallel. Recent efforts <ref> [13, 14, 15] </ref> are only in early stages of development. 1 Finding no suitable existing language, we decided to design and implement our own language as a set of macros and classes that extended C++. The result is DAPPLE, a DAta-Parallel Programming Library for Education.
Reference: [16] <author> M. A. Ellis and B. Stroustrup, </author> <title> The Annotated C++ Reference Manual, </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1990, </year> <title> Ninth printing. </title>
Reference-contexts: The functional style makes it easier to compose operations, e.g., B = shift (B,1) + B + shift (B,-1), than if shift () modified B. Recommended by the ARM <ref> [16, page 249] </ref>, the functional syntax shift (B,1) makes it clear that the operand B is not modified, while in B.shift (1) it is not as clear.
Reference: [17] <author> M. </author> <title> Gardner, </title> <journal> "Mathematical games" Scientific American, </journal> <volume> Vol. 223, No. 10, </volume> <month> October </month> <year> 1970, </year> <pages> pp. 120-123. </pages>
Reference-contexts: First, the students were asked to comment on the efficiency of the quicksort algorithm, which clearly loses parallelism in the lower levels of the recursion. Then the students were asked to write a new DAPPLE program to simulate Conway's Game of Life <ref> [17, 18] </ref>, as in Figure 6. As this program has a structure similar to Canny's algorithm, most students had little difficulty. Students used DAPPLE on the Macintosh, in the same programming environment they had used for all of their previous programming.
Reference: [18] <author> M. </author> <title> Gardner, </title> <journal> "Mathematical games" Scientific American, </journal> <volume> Vol. 224, No. 2, </volume> <month> February </month> <year> 1971, </year> <pages> pp. 112-117. </pages>
Reference-contexts: First, the students were asked to comment on the efficiency of the quicksort algorithm, which clearly loses parallelism in the lower levels of the recursion. Then the students were asked to write a new DAPPLE program to simulate Conway's Game of Life <ref> [17, 18] </ref>, as in Figure 6. As this program has a structure similar to Canny's algorithm, most students had little difficulty. Students used DAPPLE on the Macintosh, in the same programming environment they had used for all of their previous programming.

References-found: 18

