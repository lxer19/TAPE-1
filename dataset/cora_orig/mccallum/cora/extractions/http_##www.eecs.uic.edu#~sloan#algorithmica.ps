URL: http://www.eecs.uic.edu/~sloan/algorithmica.ps
Refering-URL: http://www.eecs.uic.edu/~sloan/papers.html
Root-URL: 
Email: Net address: sloan@eecs.uic.edu.  
Phone: Algorithmica 14: 70-84, 1995.  
Title: Can PAC Learning Algorithms Tolerate Random Attribute Noise?  
Author: Sally A. Goldman Robert H. Sloan 
Note: Supported in part by NSF grant CCR-9108753. Part of this research was conducted while the author was at Harvard and supported by ARO grant DAAL 03-86-K-0171.  
Address: St. Louis, Missouri 63130  Chicago, IL 60607  
Affiliation: Department of Computer Science Washington University  Dept. of Electrical Engineering and Computer Science University of Illinois at Chicago  
Abstract: This paper studies the robustness of PAC learning algorithms when the instance space is f0; 1g n , and the examples are corrupted by purely random noise affecting only the attributes (and not the labels). For uniform attribute noise, in which each attribute is flipped independently at random with the same probability, we present an algorithm that PAC learns monomials for any (unknown) noise rate less than 1=2. Contrasting this positive result, we show that product random attribute noise, where each attribute i is flipped randomly and independently with its own probability p i , is nearly as harmful as malicious noise|no algorithm can tolerate more than a very small amount of such noise. fl Supported in part by a GE Foundation Junior Faculty Grant and NSF grant CCR-9110108. Part of this research was conducted while the author was at the M.I.T. Laboratory for Computer Science and supported by NSF grant DCR-8607494 and a grant from the Siemens Corporation. Net address: sg@cs.wustl.edu. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Dana Angluin and Philip Laird. </author> <title> Learning from noisy examples. </title> <journal> Machine Learning, </journal> <volume> 2(4) </volume> <pages> 343-370, </pages> <year> 1988. </year>
Reference-contexts: Previously, both random classification noise <ref> [1] </ref> and arbitrary, malicious attribute noise [5] have been conclusively studied within the PAC model. Note that the previous results on random classification noise can be combined with the new results presented here in a relatively straightforward manner. <p> On the whole, these results are surprising. Intuitively, one would think that random labeling noise destroys much more information than random attribute noise, but, in fact, PAC learning is possible with large amounts of random labeling noise <ref> [1] </ref>. We discuss this matter further in Section 7 2 PAC Learning Model We begin by describing the PAC ("probably approximately correct"), or distribution-free, learning model introduced by Valiant [11]. <p> The "desired," noiseless output of each oracle would thus be a correctly labeled example (x; s), where x is drawn according to D. We now describe the actual outputs from the following noise oracles: MAL - [12], RMC - <ref> [1] </ref>, URA - [10], and PRA -. * When MAL is called, with probability 1 -, it does indeed return a correctly labeled (x; s) where x is drawn according to D. With probability it returns an example (x; s) about which no assumptions whatsoever may be made. <p> It has been shown that for both discrete <ref> [1] </ref> and continuous [6] instance spaces, the hypothesis that minimizes disagreements meets the PAC criterion when the examples are modified by random labeling noise. Sloan [10] has extended those results to the case of malicious labeling noise. <p> this paper) about PAC learning monomials and k-DNF formulas from the noise oracles discussed in the Section 3. 5 Noise Model Monomials k-DNF Formulas Malicious Noise: E poly M AL * * [5] * * [5] 1+* [5] &lt; * Random Misclassification Noise: E poly RM C 1 2 ! <ref> [1] </ref> E RM C &lt; 1=2 [1] &lt; 1=2 [1] Uniform Random Attribute Noise: (noise rate known) E poly U RA 1 [9] 1 [9] Uniform Random Attribute Noise: (noise rate not known) E poly U RA 1 2 ! [x 5] open for any ! &gt; 0 Product Random Attribute <p> and k-DNF formulas from the noise oracles discussed in the Section 3. 5 Noise Model Monomials k-DNF Formulas Malicious Noise: E poly M AL * * [5] * * [5] 1+* [5] &lt; * Random Misclassification Noise: E poly RM C 1 2 ! <ref> [1] </ref> E RM C &lt; 1=2 [1] &lt; 1=2 [1] Uniform Random Attribute Noise: (noise rate known) E poly U RA 1 [9] 1 [9] Uniform Random Attribute Noise: (noise rate not known) E poly U RA 1 2 ! [x 5] open for any ! &gt; 0 Product Random Attribute Noise: E P RA &lt; 2* <p> from the noise oracles discussed in the Section 3. 5 Noise Model Monomials k-DNF Formulas Malicious Noise: E poly M AL * * [5] * * [5] 1+* [5] &lt; * Random Misclassification Noise: E poly RM C 1 2 ! <ref> [1] </ref> E RM C &lt; 1=2 [1] &lt; 1=2 [1] Uniform Random Attribute Noise: (noise rate known) E poly U RA 1 [9] 1 [9] Uniform Random Attribute Noise: (noise rate not known) E poly U RA 1 2 ! [x 5] open for any ! &gt; 0 Product Random Attribute Noise: E P RA &lt; 2* [x 6] &lt; <p> Then for 0 fl 1, the following holds: Pr [jS pmj &gt; flm] 2e 2mfl 2 Also, for 0 ff p, Pr [S ffm] e 2m (ffp) 2 Once we know how to obtain a good estimate for the noise rate, we can apply Angluin and Laird's <ref> [1] </ref> technique of successive approximation to obtain an upper bound on the noise rate that is sufficiently close to the actual noise rate. Finally, using this estimate of the noise rate, we apply Shackelford and Volper's [9] algorithm when specialized to the case of monomials. <p> Finally, in step 6 the algorithm outputs as its hypothesis the conjunctions of all literals that occur infrequently enough in the positive examples. It follows from Theorem 3 of Angluin and Laird <ref> [1] </ref> that with probability at least 1 ffi=2, step 1 of Algorithm A terminates with r 1 + l 1 m 8 Inputs: n, *, ffi, access to URA - (unknown). Output: Some monomial (possibly "FALSE"). 1.
Reference: [2] <author> Anselm Blumer, Andrzej Ehrenfeucht, David Haussler, and Manfred K. War-muth. </author> <title> Learnability and the Vapnik-Chervonenkis dimension. </title> <journal> Journal of the ACM, </journal> <volume> 36(4) </volume> <pages> 929-965, </pages> <year> 1989. </year> <month> 15 </month>
Reference-contexts: In this setting polynomial time means polynomial in n, 1=* and 1=ffi. More detailed discussions of the PAC model, and of the motivations behind it, can be found in many articles (eg. <ref> [2, 3] </ref>), including, of course, Valiant's original article [11]. 3 Models for Learning with Noise The ordinary definition of PAC learning (from noiseless data) assumes that EX returns correct data. <p> So these results specify the amount of noise that can be tolerated ignoring the issue of computation time. (Of course, if a hypothesis minimizing disagreements can be found in polynomial time then the above techniques produce efficient learning algorithms.) Finally, as Blumer et al. mention <ref> [2] </ref>, their VC dimension methods can be used to prove that this minimal disagreement method also works for handling small amounts of malicious noise in continuous instance spaces.
Reference: [3] <author> David Haussler, Michael Kearns, Nick Littlestone, and Manfred K. Warmuth. </author> <title> Equivalence of models for polynomial learnability. </title> <journal> Information and Computation, </journal> <volume> 95(2) </volume> <pages> 129-161, </pages> <month> December </month> <year> 1991. </year>
Reference-contexts: In this setting polynomial time means polynomial in n, 1=* and 1=ffi. More detailed discussions of the PAC model, and of the motivations behind it, can be found in many articles (eg. <ref> [2, 3] </ref>), including, of course, Valiant's original article [11]. 3 Models for Learning with Noise The ordinary definition of PAC learning (from noiseless data) assumes that EX returns correct data.
Reference: [4] <author> Wassily Hoeffding. </author> <title> Probability inequalities for sums of bounded random variables. </title> <journal> Journal of the American Statistical Association, </journal> <volume> 58(301) </volume> <pages> 13-30, </pages> <month> March </month> <year> 1963. </year>
Reference-contexts: Thus we will estimate the noise rate to be the minimum, over all literals, of the ratio specified in (1) for the literal v 1 . To compute the actual sample size needed to make these estimates, we use Ho-effding's Inequality <ref> [4] </ref> (also referred as a form of Chernoff bounds) as stated below: Lemma 1 (Hoeffding's Inequality) Let Y 1 ; : : : ; Y m be a sequence of m independent Bernoulli trials, each succeeding with probability p.
Reference: [5] <author> Michael Kearns and Ming Li. </author> <title> Learning in the presence of malicious errors. </title> <journal> SIAM Journal on Computing, </journal> <volume> 22(4) </volume> <pages> 807-837, </pages> <month> August </month> <year> 1993. </year>
Reference-contexts: Previously, both random classification noise [1] and arbitrary, malicious attribute noise <ref> [5] </ref> have been conclusively studied within the PAC model. Note that the previous results on random classification noise can be combined with the new results presented here in a relatively straightforward manner. <p> This malicious noise oracle models the situation where the learner usually gets a correct example, but some small fraction of the time the learner gets noisy examples and the nature of the noise is unknown or unpredictable. As introduced by Kearns and Li <ref> [5] </ref>, we shall use E MAL (C n ) (respectively, E poly MAL (C n )) to denote the largest malicious noise rate that can be tolerated by any learning algorithm (respectively, polynomial time learning algorithm)for C n . * When RMC is called, with probability 1-, it returns a correctly <p> It has been shown that for both discrete [1] and continuous [6] instance spaces, the hypothesis that minimizes disagreements meets the PAC criterion when the examples are modified by random labeling noise. Sloan [10] has extended those results to the case of malicious labeling noise. Similarly, Kearns and Li <ref> [5] </ref> have shown that this method of minimizing disagreements can tolerate a small amount of malicious noise in discrete instance spaces. <p> We note that for arbitrary adversarial malicious noise, that is the maximum noise rate that any algorithm can tolerate <ref> [5] </ref>. Although the method of minimizing disagreements is not effective against random attribute noise, there are techniques for coping with uniform random attribute noise. In particular, Shackelford and Volper [9] have an algorithm that tolerates large amounts of random attribute noise for learning k-DNF formulas. <p> In Table 1 we summarize the results (from previous work and this paper) about PAC learning monomials and k-DNF formulas from the noise oracles discussed in the Section 3. 5 Noise Model Monomials k-DNF Formulas Malicious Noise: E poly M AL * * <ref> [5] </ref> * * [5] 1+* [5] &lt; * Random Misclassification Noise: E poly RM C 1 2 ! [1] E RM C &lt; 1=2 [1] &lt; 1=2 [1] Uniform Random Attribute Noise: (noise rate known) E poly U RA 1 [9] 1 [9] Uniform Random Attribute Noise: (noise rate not known) <p> In Table 1 we summarize the results (from previous work and this paper) about PAC learning monomials and k-DNF formulas from the noise oracles discussed in the Section 3. 5 Noise Model Monomials k-DNF Formulas Malicious Noise: E poly M AL * * <ref> [5] </ref> * * [5] 1+* [5] &lt; * Random Misclassification Noise: E poly RM C 1 2 ! [1] E RM C &lt; 1=2 [1] &lt; 1=2 [1] Uniform Random Attribute Noise: (noise rate known) E poly U RA 1 [9] 1 [9] Uniform Random Attribute Noise: (noise rate not known) E poly U <p> In Table 1 we summarize the results (from previous work and this paper) about PAC learning monomials and k-DNF formulas from the noise oracles discussed in the Section 3. 5 Noise Model Monomials k-DNF Formulas Malicious Noise: E poly M AL * * <ref> [5] </ref> * * [5] 1+* [5] &lt; * Random Misclassification Noise: E poly RM C 1 2 ! [1] E RM C &lt; 1=2 [1] &lt; 1=2 [1] Uniform Random Attribute Noise: (noise rate known) E poly U RA 1 [9] 1 [9] Uniform Random Attribute Noise: (noise rate not known) E poly U RA 1 <p> Kearns and Li <ref> [5] </ref> defined a concept class C to be distinct if there exist concepts c 2 ; c 2 2 C and instance u; v; w; x 2 X satisfying that u 2 c 1 ; u 62 c 2 ; v 2 c 1 ; v 2 c 2 ; w <p> Theorem 2 Let C be any distinct concept class over f0; 1g n . It is possible to PAC learn C to accuracy * with examples from PRA only if - &lt; 2*. Proof: We use the method of induced distributions <ref> [5] </ref>. Let c 1 ; c 2 be the concepts that exist in C according to the definition of a distinct concept class. For ease of exposition we shall let c 1 = v 1 (the first attribute) and c 2 = v 2 ( the second attribute). <p> We would like to find a way to convert any correct PAC learning algorithm into one that is robust against noise. Kearns and Li have such an algorithm for very small amounts of malicious noise <ref> [5] </ref>. This problem is open, however, for both random classification noise and uniform attribute noise. Acknowledgments We would like to thank Les Valiant for suggesting this line of research.
Reference: [6] <author> Philip D. Laird. </author> <title> Learning from Good and Bad Data. </title> <booktitle> Kluwer international series in engineering and computer science. </booktitle> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, </address> <year> 1988. </year>
Reference-contexts: It has been shown that for both discrete [1] and continuous <ref> [6] </ref> instance spaces, the hypothesis that minimizes disagreements meets the PAC criterion when the examples are modified by random labeling noise. Sloan [10] has extended those results to the case of malicious labeling noise.
Reference: [7] <author> Nicholas Littlestone. </author> <title> Redundant noisy attributes, attribute errors, and lineary-threshold learning using winnow. </title> <booktitle> In Fourth Workshop on Computational Learning Theory, </booktitle> <pages> pages 147-156, </pages> <year> 1991. </year>
Reference-contexts: That algorithm, however, has one very unpleasant requirement: it must be given the exact noise rate (or at least a very good estimate of the noise rate) as an input. Littlestone <ref> [7] </ref> has looked at how his Winnow algorithm can tolerate several different models of attribute noise. He first considers an adversarial model of attribute noise.
Reference: [8] <author> J. Ross Quinlan. </author> <title> The effect of noise on concept learning. </title> <booktitle> In Machine Learning, An Artificial Intelligence Approach (Volume II), chapter 6, </booktitle> <pages> pages 149-166. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1986. </year>
Reference-contexts: Yet, one would expect that labeling noise would be worse than random attribute noise. 7.1 An empirical test Indeed, one empirical test of the effects of random noise on concept learning from examples by the ID-3 system concluded that in practice, classification noise is much more harmful than attribute noise <ref> [8] </ref>. Unfortunately, that experiment was not directly comparable to our work. One can view learning from examples as consisting of two phases: a training phase (in our case, getting examples from the oracle EX), and a performance phase where the learner's output is evaluated for accuracy. <p> Note that this is the only sensible paradigm for studying malicious noise; for random noise, this is one of several reasonable possibilities. Quinlan's empirical study took a different approach: He assumed that the same random noise was present in both the training and performance phases of the learning <ref> [8] </ref>. That approach virtually guarantees that classification noise will seem to be the most harmful, since each percentage point increase in classification noise for the data 14 for the performance phase should lead to roughly a full percentage point decrease in the learner's performance.
Reference: [9] <author> George Shackelford and Dennis Volper. </author> <title> Learning k-DNF with noise in the attributes. </title> <booktitle> In First Workshop on Computatinal Learning Theory, </booktitle> <pages> pages 97-103, </pages> <address> Cambridge, Mass. August 1988. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: However, Sloan [10] has show that this "best-agreement" rule can only tolerate very small amounts of random attribute noise|suggesting that random attribute noise may be difficult to overcome. On the other hand, by using a different strategy, Shackelford and Volper <ref> [9] </ref> have obtained an algorithm that tolerates a large amount of random attribute noise (at a known noise rate) for learning k-DNF formulas. Thus their result suggests that random attribute noise may be like random classification noise, where large amounts of noise can sometimes be tolerated. <p> We note that for arbitrary adversarial malicious noise, that is the maximum noise rate that any algorithm can tolerate [5]. Although the method of minimizing disagreements is not effective against random attribute noise, there are techniques for coping with uniform random attribute noise. In particular, Shackelford and Volper <ref> [9] </ref> have an algorithm that tolerates large amounts of random attribute noise for learning k-DNF formulas. That algorithm, however, has one very unpleasant requirement: it must be given the exact noise rate (or at least a very good estimate of the noise rate) as an input. <p> k-DNF Formulas Malicious Noise: E poly M AL * * [5] * * [5] 1+* [5] &lt; * Random Misclassification Noise: E poly RM C 1 2 ! [1] E RM C &lt; 1=2 [1] &lt; 1=2 [1] Uniform Random Attribute Noise: (noise rate known) E poly U RA 1 <ref> [9] </ref> 1 [9] Uniform Random Attribute Noise: (noise rate not known) E poly U RA 1 2 ! [x 5] open for any ! &gt; 0 Product Random Attribute Noise: E P RA &lt; 2* [x 6] &lt; 2* [x 6] Table 1: This table summarizes the results known about learning <p> Malicious Noise: E poly M AL * * [5] * * [5] 1+* [5] &lt; * Random Misclassification Noise: E poly RM C 1 2 ! [1] E RM C &lt; 1=2 [1] &lt; 1=2 [1] Uniform Random Attribute Noise: (noise rate known) E poly U RA 1 <ref> [9] </ref> 1 [9] Uniform Random Attribute Noise: (noise rate not known) E poly U RA 1 2 ! [x 5] open for any ! &gt; 0 Product Random Attribute Noise: E P RA &lt; 2* [x 6] &lt; 2* [x 6] Table 1: This table summarizes the results known about learning monomials and <p> Finally, using this estimate of the noise rate, we apply Shackelford and Volper's <ref> [9] </ref> algorithm when specialized to the case of monomials. However, the correctness proof provided by Shackelford and Volper assumes the exact noise rate is provided.
Reference: [10] <author> Robert H. Sloan. </author> <title> Types of noise in data for concept learning. </title> <booktitle> In First Workshop on Computational Learning Theory, </booktitle> <pages> pages 91-96. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1988. </year>
Reference-contexts: For dealing with random noise affecting only the classification, the "best-agreement" rule, according to which one draws a large sample of data and then outputs the hypothesis that mislabels the fewest examples from that sample, works quite well (ignoring the issue of computation time). However, Sloan <ref> [10] </ref> has show that this "best-agreement" rule can only tolerate very small amounts of random attribute noise|suggesting that random attribute noise may be difficult to overcome. <p> The "desired," noiseless output of each oracle would thus be a correctly labeled example (x; s), where x is drawn according to D. We now describe the actual outputs from the following noise oracles: MAL - [12], RMC - [1], URA - <ref> [10] </ref>, and PRA -. * When MAL is called, with probability 1 -, it does indeed return a correctly labeled (x; s) where x is drawn according to D. With probability it returns an example (x; s) about which no assumptions whatsoever may be made. <p> It has been shown that for both discrete [1] and continuous [6] instance spaces, the hypothesis that minimizes disagreements meets the PAC criterion when the examples are modified by random labeling noise. Sloan <ref> [10] </ref> has extended those results to the case of malicious labeling noise. Similarly, Kearns and Li [5] have shown that this method of minimizing disagreements can tolerate a small amount of malicious noise in discrete instance spaces. <p> In the case of uniform random attribute noise, if one uses the minimal disagreement method, then the minimum error rate obtainable (i.e. the minimum "epsilon") is bounded below by the noise rate <ref> [10] </ref>. We note that for arbitrary adversarial malicious noise, that is the maximum noise rate that any algorithm can tolerate [5]. Although the method of minimizing disagreements is not effective against random attribute noise, there are techniques for coping with uniform random attribute noise. <p> In fact, product random attribute noise is significantly more harmful than malicious labeling noise generated by a powerful adversary <ref> [10] </ref>, and nearly as harmful as truly malicious noise. This result was surprising to the authors. One expects to only be able to tolerate a small amount of truly malicious noise|it is obviously the worst sort of noise possible.
Reference: [11] <author> Leslie G. Valiant. </author> <title> A theory of the learnable. </title> <journal> Communications of the ACM, </journal> <volume> 27(11) </volume> <pages> 1134-1142, </pages> <month> November </month> <year> 1984. </year>
Reference-contexts: We discuss this matter further in Section 7 2 PAC Learning Model We begin by describing the PAC ("probably approximately correct"), or distribution-free, learning model introduced by Valiant <ref> [11] </ref>. This model aims to give a precise precise model for the problem of concept learning from examples, including a definition of what it means to "do well" at learning from examples. For convenience' sake, the model is normally restricted to the case where there are only two possible classes. <p> In this setting polynomial time means polynomial in n, 1=* and 1=ffi. More detailed discussions of the PAC model, and of the motivations behind it, can be found in many articles (eg. [2, 3]), including, of course, Valiant's original article <ref> [11] </ref>. 3 Models for Learning with Noise The ordinary definition of PAC learning (from noiseless data) assumes that EX returns correct data. In this paper we are concerned with the case in which our instances come from some noise oracle, instead of the usual noise-free oracle, EX.
Reference: [12] <author> Leslie G. Valiant. </author> <title> Learning disjunctions of conjunctions. </title> <booktitle> In Proceedings IJCAI-85, </booktitle> <pages> pages 560-566. </pages> <booktitle> International Joint Committee for Artificial Intelligence, </booktitle> <publisher> Mor-gan Kaufmann, </publisher> <month> August </month> <year> 1985. </year> <month> 16 </month>
Reference-contexts: The output from the noise process is all the learner can observe. The "desired," noiseless output of each oracle would thus be a correctly labeled example (x; s), where x is drawn according to D. We now describe the actual outputs from the following noise oracles: MAL - <ref> [12] </ref>, RMC - [1], URA - [10], and PRA -. * When MAL is called, with probability 1 -, it does indeed return a correctly labeled (x; s) where x is drawn according to D.
References-found: 12

