URL: file://ftp.cis.ohio-state.edu/pub/tech-report/1996/TR25.ps.gz
Refering-URL: ftp://ftp.cis.ohio-state.edu/pub/tech-report/TRList.html
Root-URL: 
Email: fgrother,harroldg@cis.ohio-state.edu  
Title: A Safe, Efficient Regression Test Selection Technique  
Author: Gregg Rothermel and Mary Jean Harrold 
Keyword: software maintenance, regression testing, selective retest, regression test selection.  
Date: April 22, 1996  
Address: 395 Dreese Lab, 2015 Neil Avenue Columbus, OH 43210-1277  
Affiliation: Department of Computer and Information Science The Ohio State University  
Abstract: Regression testing is an expensive but necessary maintenance activity performed on modified software to provide confidence that changes are correct and do not adversely affect other portions of the software. A regression test selection technique chooses, from an existing test set, tests that are deemed necessary to validate modified software. Most regression test selection techniques depend on a particular test adequacy criterion or require prior knowledge of where code has been modified. We present a new technique for regression test selection that is neither adequacy-based, nor requires prior knowledge of modifications. Our algorithms construct control flow graphs for a procedure or program and its modified version, and use these graphs to select tests, from the original test set, that execute changed code. We prove that under certain conditions, the set of tests our algorithms select includes every test, from the original test suite, that can expose faults in the modified procedure or program. Thus, under these conditions, the algorithms are safe. Moreover, although our algorithms may select some tests that cannot expose faults, they are at least as precise as other safe regression test selection algorithms. Unlike many other regression test selection algorithms, our algorithms handle all language constructs, and all types of program modifications. We have implemented our algorithms; initial empirical studies indicate that our technique can significantly reduce the cost of regression testing modified software. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> H. Agrawal, J. Horgan, E. Krauser, and S. </author> <title> London. Incremental regression testing. </title> <booktitle> In Proceedings of the Conference on Software Maintenance - 1993, </booktitle> <pages> pages 348-357, </pages> <month> September </month> <year> 1993. </year>
Reference-contexts: The coverage-based selective retest techniques cited above can omit such "fault-revealing" tests in significant situations [42]. Some selective retest techniques place less emphasis on coverage criteria <ref> [1, 11, 28, 32, 31, 48, 49] </ref>. One drawback of these techniques is that they require prior knowledge of where the modified program has been changed.
Reference: [2] <author> A.V. Aho, R. Sethi, and J.D. Ullman. </author> <booktitle> Compilers: Principles, Techniques, and Tools. </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1986. </year>
Reference-contexts: A unique entry node and a unique exit node represent entry to and exit from P . The CFG for a procedure P has size, and can be constructed in time, linear in the number of simple and conditional statements in P <ref> [2] </ref>. To facilitate the presentation and discussion of our algorithms, we think of unlabeled CFG edges as having the label "*"; we also assume initially that case statements are rendered as nested if-else statements. <p> Let n be the number of statements in P , and n 0 the number of statements in P 0 . CFG construction is an O (n) operation <ref> [2] </ref>. We obtain an upper bound on the number of calls to Compare by assuming that Compare can be called with each pair of nodes N and N 0 in G and G 0 , respectively.
Reference: [3] <author> M. Balcer, W. Hasling, and T. </author> <title> Ostrand. Automatic generation of test scripts from formal test specifications. </title> <booktitle> In Proceedings of the Third Symposium on Software Testing, Analysis, and Verification, </booktitle> <pages> pages 210-218, </pages> <month> December </month> <year> 1989. </year>
Reference-contexts: The Siemens researchers created test pools "according to good testing practices, based on the tester's understanding of the program's functionality and knowledge of : : : the code." The researchers initially generated tests using the category partition method and the Siemens TSL (Test Specification Language) tool <ref> [3, 36] </ref>; they then added additional tests to the test suites, to ensure that each coverage unit (statement, 24 edge, and du-pair) in the base program and versions was exercised by at least 30 tests.
Reference: [4] <author> S. Bates and S. Horwitz. </author> <title> Incremental program testing using program dependence graphs. </title> <booktitle> In Proceedings of the 20th ACM Symposium on Principles of Programming Languages, </booktitle> <month> January </month> <year> 1993. </year>
Reference-contexts: Many other regression test selection techniques <ref> [4, 7, 14, 18, 20, 23, 37, 45] </ref> omit t2 or t3. If, for avg and avg2, the deletion of S7 had been the only change, SelectTests would have returned only ft3g. If the addition of S5a had been the only change, SelectTests would have returned only ft2g. <p> Additionally, for certain classes of expressions such as assignment statements, Equivalent can determine equivalence using techniques such as polynomial interpolation or symbolic computation [50]. At further expense, Equivalent can use algorithms, such as those described in References <ref> [4, 8, 26, 53] </ref>, that conservatively determine statement equivalence. Improving Equivalent increases the precision of our test selection algorithms, but also increases the cost of the algorithms. In practice, we expect that some improvements to Equivalent will produce precision improvements sufficient to justify this added cost, while others will not.
Reference: [5] <author> B. Beizer. </author> <title> Software Testing Techniques. </title> <publisher> Van Nostrand Reinhold, </publisher> <address> New York, NY, </address> <year> 1990. </year>
Reference-contexts: Hence, in this work, we substitute the more neutral term "controlled". 11 The importance of controlled regression testing is stated well by Beizer <ref> [5] </ref>, who writes: "It must be possible to precisely recreate the entire test situation or else it may be impossible to resolve some of the nastiest configuration dependent bugs that show up in the field." 13 Our final theorem is as follows: Theorem 3: SelectTests terminates.
Reference: [6] <author> B. Beizer. </author> <title> Black-Box Testing. </title> <publisher> John Wiley and Sons, </publisher> <address> New York, NY, </address> <year> 1995. </year>
Reference-contexts: In the 1970s, typical industry expenditures on software maintenance comprised 35 to 40 percent of total software budget. In the 1980s, expenditures rose to between 40 and 60 percent of total budget, and in the 1990s the figure exceeds 70 percent. Beizer presents similar statistics <ref> [6] </ref>. Because regression testing constitutes a significant percentage of maintenance costs, there are good reasons to seek improvements in regression testing processes. Both development testing and regression testing are expensive. <p> At present, however, according to Beizer, regression testing is often overlooked or performed inadequately: either the testing of new features, or the revalidation of old features, or both, are sacrificed. As a result, software reliability decreases over the software's lifetime <ref> [6] </ref>. Practical, effective selective retest techniques promote software quality. We have discovered several promising directions for future work in this area. First, while the empirical results reported in this paper are encouraging, they are also preliminary.
Reference: [7] <author> P. Benedusi, A. Cimitile, and U. De Carlini. </author> <title> Post-maintenance testing based on path change analysis. </title> <booktitle> In Proceedings of the Conference on Software Maintenance - 1988, </booktitle> <pages> pages 352-361, </pages> <month> October </month> <year> 1988. </year>
Reference-contexts: Many other regression test selection techniques <ref> [4, 7, 14, 18, 20, 23, 37, 45] </ref> omit t2 or t3. If, for avg and avg2, the deletion of S7 had been the only change, SelectTests would have returned only ft3g. If the addition of S5a had been the only change, SelectTests would have returned only ft2g.
Reference: [8] <author> D. Binkley. </author> <title> Using semantic differencing to reduce the cost of regression testing. </title> <booktitle> In Proceedings of the Conference on Software Maintenance - 1992, </booktitle> <pages> pages 41-50, </pages> <month> November </month> <year> 1992. </year> <month> 34 </month>
Reference-contexts: i in T traversed edge (n 1 ; n 2 ) in G. 2.2 Regression Testing Research on regression testing spans a wide variety of topics, including test environments and automation [10, 12, 25, 24, 55], capture-playback mechanisms [34], test suite management [16, 23, 34, 45, 51], program size reduction <ref> [8] </ref>, and regression testability [30]. Most recent research on regression testing, however, concerns selective retest techniques. Selective retest techniques reduce the cost of regression testing by reusing existing tests, and identifying portions of the modified program or its specification that should be tested. <p> Additionally, for certain classes of expressions such as assignment statements, Equivalent can determine equivalence using techniques such as polynomial interpolation or symbolic computation [50]. At further expense, Equivalent can use algorithms, such as those described in References <ref> [4, 8, 26, 53] </ref>, that conservatively determine statement equivalence. Improving Equivalent increases the precision of our test selection algorithms, but also increases the cost of the algorithms. In practice, we expect that some improvements to Equivalent will produce precision improvements sufficient to justify this added cost, while others will not.
Reference: [9] <author> D. Binkley. </author> <title> Reducing the cost of regression testing by semantics guided test case selection. </title> <booktitle> In Proceedings of the Conference on Software Maintenance - 1995, </booktitle> <month> October </month> <year> 1995. </year>
Reference: [10] <author> P.A. Brown and D. Hoffman. </author> <title> The application of module regression testing at TRIUMF. Nuclear Instruments and Methods in Physics Research, Section A, </title> <address> .A293(1-2):377-381, </address> <month> August </month> <year> 1990. </year>
Reference-contexts: of size jT j bits, such that the ith bit in v is set if and only if test i in T traversed edge (n 1 ; n 2 ) in G. 2.2 Regression Testing Research on regression testing spans a wide variety of topics, including test environments and automation <ref> [10, 12, 25, 24, 55] </ref>, capture-playback mechanisms [34], test suite management [16, 23, 34, 45, 51], program size reduction [8], and regression testability [30]. Most recent research on regression testing, however, concerns selective retest techniques.
Reference: [11] <author> Y.F. Chen, D.S. Rosenblum, and K.P. Vo. TestTube: </author> <title> A system for selective regression testing. </title> <booktitle> In Proceedings of the 16th International Conference on Software Engineering, </booktitle> <pages> pages 211-222, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: The coverage-based selective retest techniques cited above can omit such "fault-revealing" tests in significant situations [42]. Some selective retest techniques place less emphasis on coverage criteria <ref> [1, 11, 28, 32, 31, 48, 49] </ref>. One drawback of these techniques is that they require prior knowledge of where the modified program has been changed. <p> We also use our framework to evaluate our technique and compare it to existing techniques. Here, we summarize the results reported in that work. Inclusiveness. Our test selection algorithms are safe for controlled regression testing. Only three other techniques <ref> [11, 23, 28] </ref> can also make this claim. Moreover, all of these safe techniques depend, for their safety, upon the same assumptions on which our algorithms depend. Thus, at present, with existing regression test selection techniques, safe test selection is possible only for controlled regression testing. Precision.
Reference: [12] <author> T. Dogsa and I. Rozman. </author> <title> CAMOTE computer aided module testing and design environment. </title> <booktitle> In Proceedings of the Conference on Software Maintenance - 1988, </booktitle> <pages> pages 404-408, </pages> <month> October </month> <year> 1988. </year>
Reference-contexts: of size jT j bits, such that the ith bit in v is set if and only if test i in T traversed edge (n 1 ; n 2 ) in G. 2.2 Regression Testing Research on regression testing spans a wide variety of topics, including test environments and automation <ref> [10, 12, 25, 24, 55] </ref>, capture-playback mechanisms [34], test suite management [16, 23, 34, 45, 51], program size reduction [8], and regression testability [30]. Most recent research on regression testing, however, concerns selective retest techniques.
Reference: [13] <author> K.F. Fischer. </author> <title> A test case selection method for the validation of software maintenance modifications. </title> <booktitle> In Proceedings of COMPSAC '77, </booktitle> <pages> pages 421-426, </pages> <month> November </month> <year> 1977. </year>
Reference: [14] <author> K.F. Fischer, F. Raji, and A. Chruscicki. </author> <title> A methodology for retesting modified software. </title> <booktitle> In Proceedings of the National Telecommunications Conference B-6-3, </booktitle> <pages> pages 1-6, </pages> <month> November </month> <year> 1981. </year>
Reference-contexts: Many other regression test selection techniques <ref> [4, 7, 14, 18, 20, 23, 37, 45] </ref> omit t2 or t3. If, for avg and avg2, the deletion of S7 had been the only change, SelectTests would have returned only ft3g. If the addition of S5a had been the only change, SelectTests would have returned only ft2g.
Reference: [15] <author> R. Gupta, M.J. Harrold, </author> <title> and M.L. Soffa. An approach to regression testing using slicing. </title> <booktitle> In Proceedings of the Conference on Software Maintenance - 1992, </booktitle> <pages> pages 299-308, </pages> <month> November </month> <year> 1992. </year>
Reference: [16] <author> M.J. Harrold, R. Gupta, </author> <title> and M.L. Soffa. A methodology for controlling the size of a test suite. </title> <journal> ACM Transactions on Software Engineering and Methodology, </journal> <volume> 2(3) </volume> <pages> 270-285, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: v is set if and only if test i in T traversed edge (n 1 ; n 2 ) in G. 2.2 Regression Testing Research on regression testing spans a wide variety of topics, including test environments and automation [10, 12, 25, 24, 55], capture-playback mechanisms [34], test suite management <ref> [16, 23, 34, 45, 51] </ref>, program size reduction [8], and regression testability [30]. Most recent research on regression testing, however, concerns selective retest techniques.
Reference: [17] <author> M.J. Harrold, L. Larsen, J. Lloyd, D. Nedved, M. Page, G. Rothermel, M. Singh, and M. Smith. Aristotle: </author> <title> a system for the development of program-analysis-based tools. </title> <booktitle> In Proceedings of the 33rd Annual Southeast Conference, </booktitle> <pages> pages 110-119, </pages> <month> March </month> <year> 1995. </year>
Reference-contexts: Furthermore, the source code for the base programs and versions is standard C, amenable to analysis and instrumentation by our prototype tools. Finally, the Siemens subjects have served previously as a basis for published empirical results. Empirical Procedure To obtain our empirical results, we initially used an analysis tool <ref> [17] </ref> on the base programs and modified versions to create control flow graphs for those versions. We then ran a code instrumentation tool to generate instrumented versions of the base programs.
Reference: [18] <author> M.J. Harrold and M.L. Soffa. </author> <title> An incremental approach to unit testing during maintenance. </title> <booktitle> In Proceedings of the Conference on Software Maintenance - 1988, </booktitle> <pages> pages 362-367, </pages> <month> October </month> <year> 1988. </year>
Reference-contexts: Many other regression test selection techniques <ref> [4, 7, 14, 18, 20, 23, 37, 45] </ref> omit t2 or t3. If, for avg and avg2, the deletion of S7 had been the only change, SelectTests would have returned only ft3g. If the addition of S5a had been the only change, SelectTests would have returned only ft2g.
Reference: [19] <author> M.J. Harrold and M.L. Soffa. </author> <title> An incremental data flow testing tool. </title> <booktitle> In Proceedings of the Sixth International Conference on Testing Computer Software, </booktitle> <month> May </month> <year> 1989. </year>
Reference: [20] <author> M.J. Harrold and M.L. Soffa. </author> <title> Interprocedural data flow testing. </title> <booktitle> In Proceedings of the Third Testing, Analysis, and Verification Symposium, </booktitle> <pages> pages 158-167, </pages> <month> December </month> <year> 1989. </year>
Reference-contexts: Many other regression test selection techniques <ref> [4, 7, 14, 18, 20, 23, 37, 45] </ref> omit t2 or t3. If, for avg and avg2, the deletion of S7 had been the only change, SelectTests would have returned only ft3g. If the addition of S5a had been the only change, SelectTests would have returned only ft2g.
Reference: [21] <author> J. Hartmann and D.J. Robson. </author> <title> Revalidation during the software maintenance phase. </title> <booktitle> In Proceedings of the Conference on Software Maintenance - 1989, </booktitle> <pages> pages 70-79, </pages> <month> October </month> <year> 1989. </year>
Reference: [22] <author> J. Hartmann and D.J. Robson. </author> <title> RETEST development of a selective revalidation prototype environment for use in software maintenance. </title> <booktitle> In Proceedings of the Twenty-Third Hawaii International Conference on System Sciences, </booktitle> <pages> pages 92-101, </pages> <month> January </month> <year> 1990. </year>
Reference: [23] <author> J. Hartmann and D.J. Robson. </author> <title> Techniques for selective revalidation. </title> <journal> IEEE Software, </journal> <volume> 16(1) </volume> <pages> 31-38, </pages> <month> January </month> <year> 1990. </year>
Reference-contexts: v is set if and only if test i in T traversed edge (n 1 ; n 2 ) in G. 2.2 Regression Testing Research on regression testing spans a wide variety of topics, including test environments and automation [10, 12, 25, 24, 55], capture-playback mechanisms [34], test suite management <ref> [16, 23, 34, 45, 51] </ref>, program size reduction [8], and regression testability [30]. Most recent research on regression testing, however, concerns selective retest techniques. <p> Many other regression test selection techniques <ref> [4, 7, 14, 18, 20, 23, 37, 45] </ref> omit t2 or t3. If, for avg and avg2, the deletion of S7 had been the only change, SelectTests would have returned only ft3g. If the addition of S5a had been the only change, SelectTests would have returned only ft2g. <p> We also use our framework to evaluate our technique and compare it to existing techniques. Here, we summarize the results reported in that work. Inclusiveness. Our test selection algorithms are safe for controlled regression testing. Only three other techniques <ref> [11, 23, 28] </ref> can also make this claim. Moreover, all of these safe techniques depend, for their safety, upon the same assumptions on which our algorithms depend. Thus, at present, with existing regression test selection techniques, safe test selection is possible only for controlled regression testing. Precision.
Reference: [24] <author> D. Hoffman. </author> <title> A CASE study in module testing. </title> <booktitle> In Proceedings of the Conference on Software Maintenance - 1989, </booktitle> <pages> pages 100-105, </pages> <month> October </month> <year> 1989. </year>
Reference-contexts: of size jT j bits, such that the ith bit in v is set if and only if test i in T traversed edge (n 1 ; n 2 ) in G. 2.2 Regression Testing Research on regression testing spans a wide variety of topics, including test environments and automation <ref> [10, 12, 25, 24, 55] </ref>, capture-playback mechanisms [34], test suite management [16, 23, 34, 45, 51], program size reduction [8], and regression testability [30]. Most recent research on regression testing, however, concerns selective retest techniques.
Reference: [25] <author> D. Hoffman and C. Brealey. </author> <title> Module test case generation. </title> <booktitle> In Proceedings of the Third Workshop on Software Testing, Analysis, and Verification, </booktitle> <pages> pages 97-102, </pages> <month> December </month> <year> 1989. </year>
Reference-contexts: of size jT j bits, such that the ith bit in v is set if and only if test i in T traversed edge (n 1 ; n 2 ) in G. 2.2 Regression Testing Research on regression testing spans a wide variety of topics, including test environments and automation <ref> [10, 12, 25, 24, 55] </ref>, capture-playback mechanisms [34], test suite management [16, 23, 34, 45, 51], program size reduction [8], and regression testability [30]. Most recent research on regression testing, however, concerns selective retest techniques.
Reference: [26] <author> S. Horwitz and T. Reps. </author> <title> The use of program dependence graphs in software engineering. </title> <booktitle> In Proceedings of the 14th International Conference on Software Enginnering, </booktitle> <pages> pages 392-411, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: When Compare considers P 4 and P 4 0 , it first seeks a true child 8 The phrase "may be" is important here, because the problem of determining semantic equivalence of statements is, in general, undecidable <ref> [26] </ref>. 9 of P 4 0 to compare with S5; it finds S5a and calls Equivalent with S5 and S5a. <p> Additionally, for certain classes of expressions such as assignment statements, Equivalent can determine equivalence using techniques such as polynomial interpolation or symbolic computation [50]. At further expense, Equivalent can use algorithms, such as those described in References <ref> [4, 8, 26, 53] </ref>, that conservatively determine statement equivalence. Improving Equivalent increases the precision of our test selection algorithms, but also increases the cost of the algorithms. In practice, we expect that some improvements to Equivalent will produce precision improvements sufficient to justify this added cost, while others will not.
Reference: [27] <author> M. Hutchins, H. Foster, T. Goradia, and T. </author> <title> Ostrand. Experiments on the effectiveness of dataflow- and controlflow-based test adequacy criteria. </title> <booktitle> In Proceedings of the 16th International Conference on Software Engineering, </booktitle> <pages> pages 191-200, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: Subjects Hutchins, Foster, Goradia, and Ostrand <ref> [27] </ref> report the results of an experiment on the effectiveness of dataflow- and controlflow-based test adequacy criteria. To conduct their study, the authors obtained seven C programs, that ranged in size from 141 to 512 lines of code, and 8 to 21 procedures. <p> researchers to manufacture test suites and 12 We describe the requirements for our tools, and their design and implementation, in Reference [39]. 13 SPARCstation is a trademark of Sun Microsystems, Inc. 14 There are a few differences between the numbers reported in Table 1 and the numbers reported in Reference <ref> [27] </ref>. Hutchins et al. report 39 versions of tcas; their distribution to us contained 41.
Reference: [28] <author> J. Laski and W. Szermer. </author> <title> Identification of program modifications and its applications in software maintentance. </title> <booktitle> In Proceedings of the Conference on Software Maintenance - 1992, </booktitle> <pages> pages 282-290, </pages> <month> November </month> <year> 1992. </year>
Reference-contexts: The coverage-based selective retest techniques cited above can omit such "fault-revealing" tests in significant situations [42]. Some selective retest techniques place less emphasis on coverage criteria <ref> [1, 11, 28, 32, 31, 48, 49] </ref>. One drawback of these techniques is that they require prior knowledge of where the modified program has been changed. <p> One drawback of these techniques is that they require prior knowledge of where the modified program has been changed. This knowledge must be obtained either by a programming environment that tracks changes as they are made, or by algorithms <ref> [28, 52] </ref> that determine corresponding program components. The assumption of a programming environment that tracks changes may be unreasonable given current practice. The algorithms for determining corresponding components may be unnecessarily costly for this application. <p> We also use our framework to evaluate our technique and compare it to existing techniques. Here, we summarize the results reported in that work. Inclusiveness. Our test selection algorithms are safe for controlled regression testing. Only three other techniques <ref> [11, 23, 28] </ref> can also make this claim. Moreover, all of these safe techniques depend, for their safety, upon the same assumptions on which our algorithms depend. Thus, at present, with existing regression test selection techniques, safe test selection is possible only for controlled regression testing. Precision.
Reference: [29] <author> J.A.N. Lee and X. </author> <title> He. A Methodology for Test Selection. </title> <journal> The Journal of Systems and Software, </journal> <volume> 13(1) </volume> <pages> 177-185, </pages> <month> September </month> <year> 1990. </year>
Reference: [30] <author> H.K.N. Leung and L. White. </author> <title> Insights Into Regression Testing. </title> <booktitle> In Proceedings of the Conference on Software Maintenance - 1989, </booktitle> <pages> pages 60-69, </pages> <month> October </month> <year> 1989. </year>
Reference-contexts: One necessary maintenance activity, regression testing, is performed on modified soft ware to provide confidence that the software behaves correctly, and that modifications have not adversely impacted the software's quality. Regression testing is expensive; it can account for as much as one-half of the cost of software maintenance <ref> [30] </ref>. An important difference between regression testing and development testing is that during regression testing, we may have an established suite of tests available for reuse. One regression testing strategy reruns all such tests, but this retest all approach may consume inordinate time and resources. <p> edge (n 1 ; n 2 ) in G. 2.2 Regression Testing Research on regression testing spans a wide variety of topics, including test environments and automation [10, 12, 25, 24, 55], capture-playback mechanisms [34], test suite management [16, 23, 34, 45, 51], program size reduction [8], and regression testability <ref> [30] </ref>. Most recent research on regression testing, however, concerns selective retest techniques. Selective retest techniques reduce the cost of regression testing by reusing existing tests, and identifying portions of the modified program or its specification that should be tested.
Reference: [31] <author> H.K.N. Leung and L. White. </author> <title> Insights into testing and regression testing global variables. </title> <journal> Journal of Software Maintenance, </journal> <volume> 2 </volume> <pages> 209-222, </pages> <month> December </month> <year> 1990. </year> <month> 35 </month>
Reference-contexts: The coverage-based selective retest techniques cited above can omit such "fault-revealing" tests in significant situations [42]. Some selective retest techniques place less emphasis on coverage criteria <ref> [1, 11, 28, 32, 31, 48, 49] </ref>. One drawback of these techniques is that they require prior knowledge of where the modified program has been changed.
Reference: [32] <author> H.K.N. Leung and L.J. White. </author> <title> A study of integration testing and software regression at the integration level. </title> <booktitle> In Proceedings of the Conference on Software Maintenance - 1990, </booktitle> <pages> pages 290-300, </pages> <month> November </month> <year> 1990. </year>
Reference-contexts: The coverage-based selective retest techniques cited above can omit such "fault-revealing" tests in significant situations [42]. Some selective retest techniques place less emphasis on coverage criteria <ref> [1, 11, 28, 32, 31, 48, 49] </ref>. One drawback of these techniques is that they require prior knowledge of where the modified program has been changed. <p> The preliminary phase of regression testing begins after the release of some version of the software; during this phase, 4 For examples of specification-based techniques, see References <ref> [32] </ref> and [46]. 5 programmers enhance and correct the software. When corrections are complete, the critical phase of regres-sion testing begins; during this phase regression testing is the dominating activity, and its time is limited by the deadline for product release.
Reference: [33] <author> H.K.N. Leung and L.J. White. </author> <title> A cost model to compare regression test strategies. </title> <booktitle> In Proceedings of the Conference on Software Maintenance - 1991, </booktitle> <pages> pages 201-208, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: Selective retest techniques reduce the cost of regression testing by reusing existing tests, and identifying portions of the modified program or its specification that should be tested. Selective retest techniques differ from the retest-all technique, which runs all tests in the existing test suite. Leung and White <ref> [33] </ref> show that a selective retest technique is more economical than the retest-all technique if the cost of selecting a reduced 4 subset of tests to run is less than the cost of running the tests that the selective retest technique lets us omit.
Reference: [34] <author> R. Lewis, D.W. Beck, and J. Hartmann. </author> <title> Assay a tool to support regression testing. </title> <booktitle> In ESEC '89. 2nd European Software Engineering Conference Proceedings, </booktitle> <pages> pages 487-496, </pages> <month> September </month> <year> 1989. </year>
Reference-contexts: the ith bit in v is set if and only if test i in T traversed edge (n 1 ; n 2 ) in G. 2.2 Regression Testing Research on regression testing spans a wide variety of topics, including test environments and automation [10, 12, 25, 24, 55], capture-playback mechanisms <ref> [34] </ref>, test suite management [16, 23, 34, 45, 51], program size reduction [8], and regression testability [30]. Most recent research on regression testing, however, concerns selective retest techniques. <p> v is set if and only if test i in T traversed edge (n 1 ; n 2 ) in G. 2.2 Regression Testing Research on regression testing spans a wide variety of topics, including test environments and automation [10, 12, 25, 24, 55], capture-playback mechanisms [34], test suite management <ref> [16, 23, 34, 45, 51] </ref>, program size reduction [8], and regression testability [30]. Most recent research on regression testing, however, concerns selective retest techniques.
Reference: [35] <author> U. Linnenkugel and M. Mullerburg. </author> <title> Test data selection criteria for (software) integration testing. In Systems Integration '90. </title> <booktitle> Proceedings of the First International Conference on Systems Integration, </booktitle> <pages> pages 709-717, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: Moreover, in the interprocedural context, the problem of regression test selection is even more differentiable from the problem of coverage identification than in the intraprocedural context. Structural coverage criteria, if employed at all, are typically applied only during intraprocedural testing. Although integration and system-level coverage criteria have been proposed <ref> [35] </ref>, in practice, most system and integration testing is functional or specification-based. It is precisely with functional and specification-based tests that we are most interested in running all tests that may reveal faults, without regard to coverage considerations.
Reference: [36] <author> T.J. Ostrand and M.J. Balcer. </author> <title> The category-partition method for specifying and generating functional tests. </title> <journal> Communications of the ACM, </journal> <volume> 31(6), </volume> <month> June </month> <year> 1988. </year>
Reference-contexts: The Siemens researchers created test pools "according to good testing practices, based on the tester's understanding of the program's functionality and knowledge of : : : the code." The researchers initially generated tests using the category partition method and the Siemens TSL (Test Specification Language) tool <ref> [3, 36] </ref>; they then added additional tests to the test suites, to ensure that each coverage unit (statement, 24 edge, and du-pair) in the base program and versions was exercised by at least 30 tests.
Reference: [37] <author> T.J. Ostrand and E.J. Weyuker. </author> <title> Using dataflow analysis for regression testing. </title> <booktitle> In Sixth Annual Pacific Northwest Software Quality Conference, </booktitle> <pages> pages 233-247, </pages> <month> September </month> <year> 1988. </year>
Reference-contexts: Many other regression test selection techniques <ref> [4, 7, 14, 18, 20, 23, 37, 45] </ref> omit t2 or t3. If, for avg and avg2, the deletion of S7 had been the only change, SelectTests would have returned only ft3g. If the addition of S5a had been the only change, SelectTests would have returned only ft2g.
Reference: [38] <author> R. Pressman. </author> <title> Software Engineering: A Practitioner's Approach. </title> <publisher> McGraw-Hill, </publisher> <address> New York, NY, </address> <year> 1987. </year>
Reference-contexts: 1 Introduction Software maintenance activities may account for as much as two-thirds of the overall cost of software production <ref> [38, 43] </ref>. One necessary maintenance activity, regression testing, is performed on modified soft ware to provide confidence that the software behaves correctly, and that modifications have not adversely impacted the software's quality. <p> The algorithms are efficient, and handle both intraprocedural and interprocedural regression test selection. Our empirical studies suggest that in practice, our technique can reduce the cost of regression testing a modified program. This work is important for two reasons. According to Pressman <ref> [38] </ref>, the cost of software maintenance dominates the overall cost of software. Moreover, the cost of maintenance, measured in terms of the percentage of software budget spent on maintenance, is increasing. In the 1970s, typical industry expenditures on software maintenance comprised 35 to 40 percent of total software budget.
Reference: [39] <author> G. Rothermel. </author> <title> Efficient, Effective Regression Testing Using Safe Test Selection Techniques. </title> <type> Ph.D. dissertation, </type> <institution> Clemson University, </institution> <month> May </month> <year> 1996. </year>
Reference-contexts: Figure 7 shows the traversal traces, 9 This is not surprising, because the problem of precisely identifying these tests in general is PSPACE-hard; thus unless P=NP, no efficient algorithm will always identify precisely the tests that are modification-traversing for P and P 0 <ref> [39] </ref>. 11 which correspond to the execution traces, for the tests on the two versions. Test t1 has equivalent execution traces for the two versions, whereas test t2 does not: the traces for t2 differ in their fifth terms. <p> Thus, t1 is not modification-traversing for the two versions, and SelectTests chooses it unnecessarily. 3.1.2 Efficiency, effectiveness, and correctness of the algorithm In this section, we summarize results that are presented in detail in Reference <ref> [39] </ref>. 12 We define controlled regression testing 10 as the practice of testing P 0 under conditions equivalent to those that were used to test P . <p> This result is significant, because we can show that for cases where controlled regression testing is practiced, if t 2 T is modification-traversing, then SelectTests selects t. Thus, the following theorem holds: Theorem 1: SelectTests is safe for controlled regression testing. Proof: See Reference <ref> [39] </ref>, pages 77-81. Theorem 1 is important, because although we cannot find an algorithm that is safe in general, we know from the theorem that SelectTests is safe in situations in which controlled regression testing is possible. <p> Proof: see Reference <ref> [39] </ref>, pages 82-85. Theorem 2 gives us a way to characterize the class of programs and modified versions for which SelectTests selects non-modification-traversing tests. The theorem is significant for two reasons. First, procedures like pathological and pathological 0 , which cause the multiply-visited-node condition to hold, are atypical. <p> Thus, we conjecture that in practice, given P , P 0 , and T , SelectTests selects exactly the tests in T that are modification-traversing for P and P 0 . 10 In earlier work <ref> [39, 42] </ref> we used the phrase "proper regression testing" in this context; however, the term "proper" has a pejorative connotation that we do not intend to imply. <p> Proof: The proof proceeds by showing that (1) the number of recursive calls made to Compare is bounded, and (2) the work required by a call to Compare is bounded. See Reference <ref> [39] </ref>, page 81, for details. 3.1.3 Complexity of the algorithm The running time of SelectTests is bounded by the time required to construct CFGs for P and P 0 , plus the number and cost of calls to Compare. <p> There are several ways in which to increase the efficiency or precision of the basic algorithm. We discuss three improvements here; Reference <ref> [39] </ref> discusses additional improvements. <p> In cases where the multiply-visited-node condition does hold, we can prove that SelectTests and SelectInterTests are more precise than two of the other three test selection techniques, and we have strong evidence to suggest that our algorithms are more precise than the third technique <ref> [39] </ref>. Efficiency. As we discussed previously, our algorithms run in time O (jT jn 2 ) for procedures or programs of n statements, and test set size jT j. This is an improvement over the efficiency of two of the other safe techniques. <p> The use of faulty versions also lets us make observations about error detection during regression testing. Hutchins et al.[27] describe the process used by the Siemens researchers to manufacture test suites and 12 We describe the requirements for our tools, and their design and implementation, in Reference <ref> [39] </ref>. 13 SPARCstation is a trademark of Sun Microsystems, Inc. 14 There are a few differences between the numbers reported in Table 1 and the numbers reported in Reference [27]. Hutchins et al. report 39 versions of tcas; their distribution to us contained 41. <p> Next, consider version 19 of replace. Although 4658 of the 5542 tests of replace are modification-traversing for this version, only 3 of these tests 17 Reference <ref> [39] </ref> lists results for all programs and modified versions individually. 31 are fault-revealing for the version. A minimization test selection technique that selects only one of the 4658 tests that cover this modification has only a .00064% chance of selecting a test that exposes the fault.
Reference: [40] <author> G. Rothermel and M.J. Harrold. </author> <title> A safe, efficient algorithm for regression test selection. </title> <booktitle> In Proceedings of the Conference on Software Maintenance - 1993, </booktitle> <pages> pages 358-367, </pages> <month> September </month> <year> 1993. </year>
Reference-contexts: Although many selective retest techniques have been proposed, most of these techniques emphasize the use of structural coverage criteria [4, 7, 9, 13, 14, 15, 18, 19, 20, 21, 23, 22, 29, 37, 44, 45, 54]. These 1 A preliminary version of this work appeared in Reference <ref> [40] </ref>. This work was partially supported by a grant from Microsoft, Inc., and by NSF under Grant CCR-9357811 to Clemson University and Ohio State University. 1 techniques identify changed or affected program components, such as statements or paths, and attempt to select tests that exercise these components. <p> Next, the algorithm calls Compare with E and E 0 . Compare ultimately places tests that are modification-traversing for P and P 0 into T 0 . SelectTests returns these tests. 7 7 An earlier version of this algorithm <ref> [40] </ref> was based on control dependence graphs for P and P 0 . The possibility of performing that algorithm on CFGs was suggested by Weibao Wu (personal communication).
Reference: [41] <author> G. Rothermel and M.J. Harrold. </author> <title> Selecting regression tests for object-oriented software. </title> <booktitle> In Proceedings of the Conference on Software Maintenance - 1994, </booktitle> <pages> pages 14-25, </pages> <month> September </month> <year> 1994. </year>
Reference: [42] <author> G. Rothermel and M.J. Harrold. </author> <title> Analyzing regression test selection techniques. </title> <type> Technical Report OSU-CISRC-4/96-TR23, </type> <institution> The Ohio State University, </institution> <month> February </month> <year> 1996. </year>
Reference-contexts: The coverage-based selective retest techniques cited above can omit such "fault-revealing" tests in significant situations <ref> [42] </ref>. Some selective retest techniques place less emphasis on coverage criteria [1, 11, 28, 32, 31, 48, 49]. One drawback of these techniques is that they require prior knowledge of where the modified program has been changed. <p> Thus, we conjecture that in practice, given P , P 0 , and T , SelectTests selects exactly the tests in T that are modification-traversing for P and P 0 . 10 In earlier work <ref> [39, 42] </ref> we used the phrase "proper regression testing" in this context; however, the term "proper" has a pejorative connotation that we do not intend to imply. <p> Section 4.1 presents an analytical evaluation and comparison; Section 4.2 presents empirical results. 4.1 Analytical Evaluation In Reference <ref> [42] </ref>, we present a framework for analyzing regression test selection techniques, that consists of four categories: inclusiveness, precision, efficiency, and generality. Inclusiveness measures the extent to which a technique selects tests that reveal faults in a modified program; a 100% inclusive technique is safe.
Reference: [43] <author> S. Schach. </author> <title> Software Engineering. </title> <publisher> Aksen Associates, </publisher> <address> Boston, MA, </address> <year> 1992. </year>
Reference-contexts: 1 Introduction Software maintenance activities may account for as much as two-thirds of the overall cost of software production <ref> [38, 43] </ref>. One necessary maintenance activity, regression testing, is performed on modified soft ware to provide confidence that the software behaves correctly, and that modifications have not adversely impacted the software's quality.
Reference: [44] <author> B. Sherlund and B. Korel. </author> <title> Modification oriented software testing. </title> <booktitle> In Conference Proceedings: Quality Week 1991, </booktitle> <pages> pages 1-17, </pages> <year> 1991. </year>
Reference: [45] <author> A.B. Taha, S.M. Thebaut, and S.S. Liu. </author> <title> An approach to software fault localization and revalidation based on incremental data flow analysis. </title> <booktitle> In Proceedings of the 13th Annual International Computer Software and Applications Conference, </booktitle> <pages> pages 527-534, </pages> <month> September </month> <year> 1989. </year>
Reference-contexts: v is set if and only if test i in T traversed edge (n 1 ; n 2 ) in G. 2.2 Regression Testing Research on regression testing spans a wide variety of topics, including test environments and automation [10, 12, 25, 24, 55], capture-playback mechanisms [34], test suite management <ref> [16, 23, 34, 45, 51] </ref>, program size reduction [8], and regression testability [30]. Most recent research on regression testing, however, concerns selective retest techniques. <p> Many other regression test selection techniques <ref> [4, 7, 14, 18, 20, 23, 37, 45] </ref> omit t2 or t3. If, for avg and avg2, the deletion of S7 had been the only change, SelectTests would have returned only ft3g. If the addition of S5a had been the only change, SelectTests would have returned only ft2g.
Reference: [46] <author> A. von Mayrhauser, R.T. Mraz, and J. </author> <title> Walls. Domain based regression testing. </title> <booktitle> In Proceedings of the Conference on Software Maintenance - 1994, </booktitle> <pages> pages 26-35, </pages> <month> September </month> <year> 1994. </year>
Reference-contexts: The preliminary phase of regression testing begins after the release of some version of the software; during this phase, 4 For examples of specification-based techniques, see References [32] and <ref> [46] </ref>. 5 programmers enhance and correct the software. When corrections are complete, the critical phase of regres-sion testing begins; during this phase regression testing is the dominating activity, and its time is limited by the deadline for product release.
Reference: [47] <author> E.J. Weyuker. </author> <title> Empirical techniques for assessing testing strategies,. (Panel discussion at the International Symposium on Software Testing and Analysis), </title> <month> August </month> <year> 1994. </year>
Reference-contexts: As Weyuker states, however, when our subject population is the universe of software systems, we do not know what it means to select a fair cross-section of that population <ref> [47] </ref>. Nor do we know what it means to select a fair cross-section of the universe of modified versions or test suites for software. Weyuker concludes that software engineers typically perform "empirical studies," rather than experiments.
Reference: [48] <author> L.J. White and H.K.N. Leung. </author> <title> A firewall concept for both control-flow and data-flow in regression integration testing. </title> <booktitle> In Proceedings of the Conference on Software Maintenance - 1992, </booktitle> <pages> pages 262-270, </pages> <month> November </month> <year> 1992. </year>
Reference-contexts: The coverage-based selective retest techniques cited above can omit such "fault-revealing" tests in significant situations [42]. Some selective retest techniques place less emphasis on coverage criteria <ref> [1, 11, 28, 32, 31, 48, 49] </ref>. One drawback of these techniques is that they require prior knowledge of where the modified program has been changed.
Reference: [49] <author> L.J. White, V. Narayanswamy, T. Friedman, M. Kirschenbaum, P. Piwowarski, and M. Oha. </author> <title> Test Manager: a regression testing tool. </title> <booktitle> In Proceedings of the Conference on Software Maintenance - 1993, </booktitle> <pages> pages 338-347, </pages> <month> September </month> <year> 1993. </year>
Reference-contexts: The coverage-based selective retest techniques cited above can omit such "fault-revealing" tests in significant situations [42]. Some selective retest techniques place less emphasis on coverage criteria <ref> [1, 11, 28, 32, 31, 48, 49] </ref>. One drawback of these techniques is that they require prior knowledge of where the modified program has been changed.
Reference: [50] <author> S. Wolfram. </author> <title> Mathematica: A System for Doing Mathematics on a Computer. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <note> second edition, </note> <year> 1991. </year>
Reference-contexts: For example, Equivalent can easily ignore comments when it performs lexicographic comparisons of statements. Additionally, for certain classes of expressions such as assignment statements, Equivalent can determine equivalence using techniques such as polynomial interpolation or symbolic computation <ref> [50] </ref>. At further expense, Equivalent can use algorithms, such as those described in References [4, 8, 26, 53], that conservatively determine statement equivalence. Improving Equivalent increases the precision of our test selection algorithms, but also increases the cost of the algorithms.
Reference: [51] <author> W. E. Wong, J. R. Horgan, S. London, and A. P. Mathur. </author> <title> Effect of test set minimization on fault detection effectiveness. </title> <booktitle> In 17th International Conference on Software Engineering, </booktitle> <pages> pages 41-50, </pages> <month> April </month> <year> 1995. </year>
Reference-contexts: v is set if and only if test i in T traversed edge (n 1 ; n 2 ) in G. 2.2 Regression Testing Research on regression testing spans a wide variety of topics, including test environments and automation [10, 12, 25, 24, 55], capture-playback mechanisms [34], test suite management <ref> [16, 23, 34, 45, 51] </ref>, program size reduction [8], and regression testability [30]. Most recent research on regression testing, however, concerns selective retest techniques.
Reference: [52] <author> W. Yang. </author> <title> Identifying syntactic differences between two programs. </title> <journal> Software|Practice and Experience, </journal> <volume> 21(7) </volume> <pages> 739-755, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: One drawback of these techniques is that they require prior knowledge of where the modified program has been changed. This knowledge must be obtained either by a programming environment that tracks changes as they are made, or by algorithms <ref> [28, 52] </ref> that determine corresponding program components. The assumption of a programming environment that tracks changes may be unreasonable given current practice. The algorithms for determining corresponding components may be unnecessarily costly for this application.
Reference: [53] <author> W. Yang, S. Horwitz, and T. Reps. </author> <title> A program integration algorithm that accomodates semantics-preserving transformations. </title> <journal> ACM Transactions on Software Engineering and Methodology, </journal> <volume> 1(3) </volume> <pages> 311-54, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: Additionally, for certain classes of expressions such as assignment statements, Equivalent can determine equivalence using techniques such as polynomial interpolation or symbolic computation [50]. At further expense, Equivalent can use algorithms, such as those described in References <ref> [4, 8, 26, 53] </ref>, that conservatively determine statement equivalence. Improving Equivalent increases the precision of our test selection algorithms, but also increases the cost of the algorithms. In practice, we expect that some improvements to Equivalent will produce precision improvements sufficient to justify this added cost, while others will not.
Reference: [54] <author> S.S. Yau and Z. Kishimoto. </author> <title> A method for revalidating modified programs in the maintenance phase. </title> <booktitle> In COMP-SAC '87: The Eleventh Annual International Computer Software and Applications Conference, </booktitle> <pages> pages 272-277, </pages> <month> October </month> <year> 1987. </year>
Reference: [55] <author> J. Ziegler, J.M. Grasso, and L.G. Burgermeister. </author> <title> An Ada based real-time closed-loop integration and regression test tool. </title> <booktitle> In Proceedings of the Conference on Software Maintenance - 1989, </booktitle> <pages> pages 81-90, </pages> <month> October </month> <year> 1989. </year> <month> 36 </month>
Reference-contexts: of size jT j bits, such that the ith bit in v is set if and only if test i in T traversed edge (n 1 ; n 2 ) in G. 2.2 Regression Testing Research on regression testing spans a wide variety of topics, including test environments and automation <ref> [10, 12, 25, 24, 55] </ref>, capture-playback mechanisms [34], test suite management [16, 23, 34, 45, 51], program size reduction [8], and regression testability [30]. Most recent research on regression testing, however, concerns selective retest techniques.
References-found: 55

