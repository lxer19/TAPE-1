URL: http://www.bell-labs.com/user/seung/papers/annealed.ps.gz
Refering-URL: http://www.bell-labs.com/user/seung/entropic.html
Root-URL: 
Email: E-mail: seung@physics.att.com  
Title: ANNEALED THEORIES OF LEARNING  
Author: H. S. Seung 
Address: Murray Hill, NJ 07974  
Affiliation: AT&T Bell Laboratories  
Abstract: We study annealed theories of learning boolean functions using a concept class of finite cardinality. The naive annealed theory can be used to derive a universal learning curve bound for zero temperature learning, similar to the inverse square root bound from the Vapnik-Chervonenkis theory. Tighter, nonuniversal learning curve bounds are also derived. A more refined annealed theory leads to still tighter bounds, which in some cases are very similar to results previously obtained using one-step replica symmetry breaking. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> D. B. Schwartz, V. K. Samalam, J. S. Denker, and S. A. Solla. </author> <title> Exhaustive learning. </title> <journal> Neural Comput., </journal> <volume> 2 </volume> <pages> 374-385, </pages> <year> 1990. </year>
Reference: 2. <author> H. S. Seung, H. Sompolinsky, and N. Tishby. </author> <title> Statistical mechanics of learning from examples. </title> <journal> Phys. Rev., </journal> <volume> A45:6056-6091, </volume> <year> 1992. </year>
Reference: 3. <author> K. Kang, J.-H. Oh, C. Kwon, and Y. Park. </author> <title> Generalization in a two-layer neural network. </title> <journal> Physical Review E, </journal> <volume> 48 </volume> <pages> 4805-4809, </pages> <year> 1993. </year>
Reference: 4. <author> H. Schwarze and J. Hertz. </author> <title> Generalization in fully connected committee machines. </title> <journal> Europhys. Lett., </journal> <volume> 21 </volume> <pages> 785-790, </pages> <year> 1993. </year>
Reference: 5. <author> V. N. Vapnik. </author> <title> Estimation of Dependences based on Empirical Data. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1982. </year>
Reference: 6. <author> D. Haussler, M. Kearns, H. S. Seung, and N. Tishby. </author> <title> Rigorous learning curve bounds from statistical mechanics. </title> <editor> In M. K. Warmuth, editor, </editor> <booktitle> Proceedings of the Seventh Annual ACM Conference on Computational Learning Theory, </booktitle> <pages> pages 76-87, </pages> <address> New York, 1994. </address> <publisher> ACM. </publisher>
Reference: 7. <author> G. Gyorgyi and N. Tishby. </author> <title> Statistical theory of learning a rule. </title> <editor> In W. K. Theumann and R. Koberle, editors, </editor> <booktitle> Neural Networks and Spin Glasses, </booktitle> <pages> pages 3-36, </pages> <address> Singapore, 1990. </address> <publisher> World Scientific. </publisher>
Reference: 8. <author> Y. Kabashima and S. Shinomoto. </author> <title> Learning curves for error minimum and maximum likelihood algorithms. </title> <journal> Neural Comput., </journal> <volume> 4 </volume> <pages> 712-719, </pages> <year> 1992. </year>
Reference: 9. <author> S. Amari, N. Fujita, and S. Shinomoto. </author> <title> Four types of learning curves. </title> <journal> Neural Comput., </journal> <volume> 4 </volume> <pages> 605-618, </pages> <year> 1992. </year>
Reference: 10. <author> A. Engel and C. Van den Broeck. </author> <title> Systems that can learn from examples: replica calculation of uniform convergence bounds for the perceptron. </title> <journal> Phys. Rev. Lett., </journal> <volume> 71 </volume> <pages> 1772-1775, </pages> <year> 1993. </year>
References-found: 10

