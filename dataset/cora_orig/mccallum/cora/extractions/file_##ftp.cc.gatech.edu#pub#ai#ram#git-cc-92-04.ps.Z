URL: file://ftp.cc.gatech.edu/pub/ai/ram/git-cc-92-04.ps.Z
Refering-URL: http://www.cs.gatech.edu/faculty/ashwin/projects/goal-driven-learning.html
Root-URL: 
Email: E-mail: ashwin@cc.gatech.edu  E-mail: hunter@nlm.nih.gov  
Phone: (404) 853-9372  (301) 496-9300  
Title: The Use of Explicit Goals for Knowledge to Guide Inference and Learning  
Author: Ashwin Ram Lawrence Hunter 
Note: Journal of Applied Intelligence, 2(1):47-73, 1992.  
Address: Atlanta, Georgia 30332-0280  Library of Medicine Building 38A, Mail Stop 54 Bethesda, MD 20894  
Affiliation: College of Computing Georgia Institute of Technology  National  
Abstract: Combinatorial explosion of inferences has always been a central problem in artificial intelligence. Although the inferences that can be drawn from a reasoner's knowledge and from available inputs is very large (potentially infinite), the inferential resources available to any reasoning system are limited. With limited inferential capacity and very many potential inferences, reasoners must somehow control the process of inference. Not all inferences are equally useful to a given reasoning system. Any reasoning system that has goals (or any form of a utility function) and acts based on its beliefs indirectly assigns utility to its beliefs. Given limits on the process of inference, and variation in the utility of inferences, it is clear that a reasoner ought to draw the inferences that will be most valuable to it. This paper presents an approach to this problem that makes the utility of a (potential) belief an explicit part of the inference process. The method is to generate explicit desires for knowledge. The question of focus of attention is thereby transformed into two related problems: How can explicit desires for knowledge be used to control inference and facilitate resource-constrained goal pursuit in general? and, Where do these desires for knowledge come from? We present a theory of knowledge goals, or desires for knowledge, and their use in the processes of understanding and learning. The theory is illustrated using two case studies, a natural language understanding program that learns by reading novel or unusual newspaper stories, and a differential diagnosis program that improves its accuracy with experience. 
Abstract-found: 1
Intro-found: 1
Reference: [Birnbaum and Collins, 1984] <author> L. Birnbaum and G. Collins. </author> <title> Opportunistic Planning and Freudian Slips. </title> <booktitle> In Proceedings of the Sixth Annual Conference of the Cognitive Science Society, </booktitle> <pages> pages 124-127, </pages> <address> Boulder, CO, </address> <year> 1984. </year> <institution> Institute of Cognitive Science and University of Colorado, Boulder. </institution>
Reference-contexts: Our work is closer to research in opportunistic planning (e.g., [Hayes-Roth and Hayes-Roth, 1979; Hammond, 1988]), and deals with the opportunistic pursuit of cognitive goals (e.g., <ref> [Birnbaum and Collins, 1984; Dehn, 1989] </ref>), and the use of such goals to focus inference and learning.
Reference: [Cox and Ram, 1991] <author> M. Cox and A. Ram. </author> <title> Using Introspective Reasoning to Select Learning Strategies. </title> <editor> In R. S. Michalski and G. Tecuci, editors, </editor> <booktitle> Proceedings of the First International Workshop on Multi-Strategy Learning, </booktitle> <pages> pages 217-230, </pages> <address> Harpers Ferry, WV, </address> <month> November </month> <year> 1991. </year> <institution> Center for Artificial Intelligence, George Mason University, Fairfax, VA. </institution>
Reference-contexts: These issues are being explored further in the INVESTIGATOR [Hunter, 1990b; Hunter, 1990a] and META-AQUA <ref> [Cox and Ram, 1991; Ram and Cox, 1992] </ref> projects. 7 Comparison to other approaches Other cognitive theories have also included reference to desires for knowledge, although there are significant differences between those prior theories and our theory of knowledge goals.
Reference: [Dehn, 1989] <author> N. Dehn. </author> <title> Computer Story Writing: The Role of Reconstructive and Dynamic Memory. </title> <type> Ph.D. thesis, </type> <institution> Yale University, Department of Computer Science, </institution> <address> New Haven, CT, </address> <year> 1989. </year> <note> Research Report #792. </note>
Reference-contexts: Our work is closer to research in opportunistic planning (e.g., [Hayes-Roth and Hayes-Roth, 1979; Hammond, 1988]), and deals with the opportunistic pursuit of cognitive goals (e.g., <ref> [Birnbaum and Collins, 1984; Dehn, 1989] </ref>), and the use of such goals to focus inference and learning.
Reference: [DeJong, 1979] <author> G. F. DeJong. </author> <title> Skimming Stories in Real Time: An Experiment in Integrated Understanding. </title> <type> Ph.D. thesis, </type> <institution> Yale University, Department of Computer Science, </institution> <address> New Haven, CT, </address> <month> May </month> <year> 1979. </year> <note> Research Report #158. </note>
Reference-contexts: In addition to the empirical psychological findings, consideration of the differences between how existing computer programs parse newspaper stories (e.g., FRUMP <ref> [DeJong, 1979] </ref>) and how people read them supports this approach. These differences include: Subjectivity: People are biased. They interpret stories in a manner that suits them. They jump to conclusions. <p> In contrast, computer programs are designed to attend to every aspect of a story that is within the scope of their knowledge structures. Consequently, they either process the entire story in great depth (e.g., BORIS [Dyer, 1982]), or else they skim everything in the story (e.g., FRUMP <ref> [DeJong, 1979] </ref>). They can not decide which aspects to process in detail and which ones to ignore. 3 Learning and change: People change as they read. They never read the same story twice in the same way. They notice different things the second time around, or they simply get bored.
Reference: [Dennett, 1987] <author> D. Dennett. </author> <title> The Intentional Stance. </title> <publisher> Bradford Books/MIT Press, </publisher> <address> Boston, MA, </address> <year> 1987. </year>
Reference-contexts: Curiosity involves specific (although often abstract) desires for knowledge, not merely a diffuse drive of some sort. When to attribute goals to computer programs is a 25 difficult philosophical question (see, e.g., <ref> [Dennett, 1987] </ref>), but we believe that programs that make decisions about what to learn and how to learn it have taken an important step toward genuine automated curiosity.
Reference: [Dietterich, 1989] <author> T. G. Dietterich. </author> <title> Limitations on Inductive Learning. </title> <booktitle> In Proceedings of Sixth International Workshop on Machine Learning, </booktitle> <pages> pages 125-128, </pages> <address> Ithaca, NY, June 1989. </address> <publisher> Morgan Kaufman. </publisher>
Reference-contexts: Another instance of the inference control problem arises in the design of machine learning systems in general. It can be formally demonstrated that far more inferences are licensed by induction over a set of experiences than can be distinguished among using those experiences <ref> [Dietterich, 1989] </ref>. In general, an inductive system must have a method for preferring some inferences over others.
Reference: [Doyle, 1979] <author> J. Doyle. </author> <title> A Truth Maintenance System. </title> <journal> Artificial Intelligence, </journal> <volume> 12 </volume> <pages> 231-272, </pages> <year> 1979. </year>
Reference-contexts: specification looks like any other memory structure, except that it is marked with the label hypothesized, hypothesized-in or hypothesized-out, as appropriate. 1 When the question is answered, the concept becomes in or out. 1 The labels in and out are used to represent belief as in most truth maintenance systems <ref> [Doyle, 1979] </ref>. 14 3.2 Task specification The task specification represents what to do with the answer once it comes in, which depends on why the question was asked.
Reference: [Dyer, 1982] <author> M. G. Dyer. </author> <title> In-Depth Understanding: A Computer Model of Integrated Processing for Narrative Comprehension. </title> <type> Ph.D. thesis, </type> <institution> Yale University, Department of Computer Science, </institution> <address> New Haven, CT, </address> <month> May </month> <year> 1982. </year> <note> Research Report #116. </note>
Reference-contexts: In contrast, computer programs are designed to attend to every aspect of a story that is within the scope of their knowledge structures. Consequently, they either process the entire story in great depth (e.g., BORIS <ref> [Dyer, 1982] </ref>), or else they skim everything in the story (e.g., FRUMP [DeJong, 1979]). They can not decide which aspects to process in detail and which ones to ignore. 3 Learning and change: People change as they read. They never read the same story twice in the same way.
Reference: [Hammond, 1988] <author> K. J. Hammond. </author> <title> Opportunistic Memory: </title> <editor> Storing and Recalling Suspended Goals. In J. L. Kolodner, editor, </editor> <booktitle> Proceedings of a Workshop on Case-Based Reasoning, </booktitle> <pages> pages 154-168, </pages> <address> Clearwater Beach, FL, May 1988. </address> <publisher> Morgan Kaufmann, Inc., </publisher> <address> San Mateo, CA. </address>
Reference-contexts: Our process of planning to learn does not involve detailed reasoning about subproblem interactions (e.g., [Sussman, 1975; Sacerdoti, 1975]) and constraint propagation (e.g., [Stefik, 1981]) that is the focus of much work in conventional planning and problem solving. Our work is closer to research in opportunistic planning (e.g., <ref> [Hayes-Roth and Hayes-Roth, 1979; Hammond, 1988] </ref>), and deals with the opportunistic pursuit of cognitive goals (e.g., [Birnbaum and Collins, 1984; Dehn, 1989]), and the use of such goals to focus inference and learning.
Reference: [Hayes-Roth and Hayes-Roth, 1979] <author> B. Hayes-Roth and F. Hayes-Roth. </author> <title> A Cognitive Model of Planning. </title> <journal> Cognitive Science, </journal> <volume> 2 </volume> <pages> 275-310, </pages> <year> 1979. </year>
Reference-contexts: Our process of planning to learn does not involve detailed reasoning about subproblem interactions (e.g., [Sussman, 1975; Sacerdoti, 1975]) and constraint propagation (e.g., [Stefik, 1981]) that is the focus of much work in conventional planning and problem solving. Our work is closer to research in opportunistic planning (e.g., <ref> [Hayes-Roth and Hayes-Roth, 1979; Hammond, 1988] </ref>), and deals with the opportunistic pursuit of cognitive goals (e.g., [Birnbaum and Collins, 1984; Dehn, 1989]), and the use of such goals to focus inference and learning.
Reference: [Hayes-Roth and Lesser, 1976] <author> F. Hayes-Roth and V. Lesser. </author> <title> Focus of attention in a distributed logic speech understanding system. </title> <booktitle> In Proceedings of the IEEE International Conference on Accoustics, Speech and Signal Processing, </booktitle> <pages> pages 416-420, </pages> <address> Philadephia, PA, April 1976. </address> <publisher> IEEE, </publisher> <address> New York, NY. </address>
Reference-contexts: In AQUA, interest in a concept is triggered by its likely relevance to questions or knowledge goals, and continuing interest is determined by its continuing significance to these goals. This is related to the "goal satisfaction principle" of <ref> [Hayes-Roth and Lesser, 1976] </ref>, which states that more processing should be given to knowledge sources whose responses are most likely to satisfy processing goals, and to the "relevance principle" of [Sperber and Wilson, 1986], which states that humans pay attention only to information that seems relevant to them.
Reference: [Hidi and Baird, 1986] <author> S. Hidi and W. Baird. </author> <title> Interestingness | A Neglected Variable in Discourse Processing. </title> <journal> Cognitive Science, </journal> <volume> 10 </volume> <pages> 179-194, </pages> <year> 1986. </year>
Reference-contexts: Thus the interestingness heuristics described below are indeed heuristics rather than precise measures of the value of thinking about a fact or a question. This is a functional approach to the problem of interestingness <ref> [Hidi and Baird, 1986; Schank, 1979] </ref> from the perspective of our theory of knowledge goals.
Reference: [Hoffman et al., 1981] <author> C. Hoffman, W. Mischel, and K. Mazze. </author> <title> The role of purpose in the organization of information about behavior: Trait-based versus goal-based categories in person cognition. </title> <journal> Journal of Personality and Social Psychology, </journal> <volume> 39 </volume> <pages> 211-255, </pages> <year> 1981. </year>
Reference: [Horvitz et al., 1989] <author> E. Horvitz, G. Cooper, and D. Heckerman. </author> <title> Reflection and action under scarce resources: Theoretical principles and empirical study. </title> <type> Report KSL-89-1, </type> <institution> Knowledge Systems Laboratory, Stanford University, </institution> <year> 1989. </year>
Reference: [Hunter, 1989] <author> L. E. Hunter. </author> <title> Knowledge Acquisition Planning: Gaining Expertise Through Experience. </title> <type> Ph.D. thesis, </type> <institution> Yale University, Department of Computer Science, </institution> <address> New Haven, CT, </address> <month> January </month> <year> 1989. </year> <note> Research Report #678. </note>
Reference-contexts: As we shall see, this requires that the system be able to represent and reason about its own reasoning processes, and about the knowledge needed during these processes. Another, rather different, example is IVY, a program that does differential diagnoses and is intended to improve its accuracy with experience <ref> [Hunter, 1989] </ref>. The basic idea was to design a program that improves its accuracy by storing information from the cases it diagnoses correctly. The problem is that there is a huge amount of information in the correctly diagnosed cases.
Reference: [Hunter, 1990a] <author> L. E. Hunter. </author> <title> Knowledge Acquisition Planning for Inference from Large Datasets. </title> <editor> In B. D. Shriver, editor, </editor> <booktitle> Proceedings of the Twenty Third Annual Hawaii International Conference on System Sciences, </booktitle> <pages> pages 35-45, </pages> <address> Kona, HI, 1990. </address> <publisher> IEEE Computer Society Press, Los Alamitos, </publisher> <address> CA. </address>
Reference-contexts: IVY's planning abilities were limited to selection among and instantiation of eight different plan schemas. Knowledge goal skeletons had from one to three plan schemas associated with them. INVESTIGATOR <ref> [Hunter, 1990b; Hunter, 1990a] </ref> uses a more flexible knowledge planner. Depending on the specifics of the knowledge goal (i.e., characteristics of the variable bindings in the goal skeletons) one or more of the plan schemata are instantiated. Consider the following example. <p> These issues are being explored further in the INVESTIGATOR <ref> [Hunter, 1990b; Hunter, 1990a] </ref> and META-AQUA [Cox and Ram, 1991; Ram and Cox, 1992] projects. 7 Comparison to other approaches Other cognitive theories have also included reference to desires for knowledge, although there are significant differences between those prior theories and our theory of knowledge goals.
Reference: [Hunter, 1990b] <author> L. E. Hunter. </author> <title> Planning to Learn. </title> <booktitle> In Proceedings of the Twelvth Annual Conference of the Cognitive Science Society, </booktitle> <pages> pages 26-34, </pages> <address> Boston, MA, </address> <month> July </month> <year> 1990. </year>
Reference-contexts: IVY's planning abilities were limited to selection among and instantiation of eight different plan schemas. Knowledge goal skeletons had from one to three plan schemas associated with them. INVESTIGATOR <ref> [Hunter, 1990b; Hunter, 1990a] </ref> uses a more flexible knowledge planner. Depending on the specifics of the knowledge goal (i.e., characteristics of the variable bindings in the goal skeletons) one or more of the plan schemata are instantiated. Consider the following example. <p> These issues are being explored further in the INVESTIGATOR <ref> [Hunter, 1990b; Hunter, 1990a] </ref> and META-AQUA [Cox and Ram, 1991; Ram and Cox, 1992] projects. 7 Comparison to other approaches Other cognitive theories have also included reference to desires for knowledge, although there are significant differences between those prior theories and our theory of knowledge goals.
Reference: [Kass et al., 1986] <author> A. Kass, D. Leake, and C. Owens. SWALE: </author> <title> A Program That Explains, </title> <address> pages 232-254. </address> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hillsdale, NJ, </address> <year> 1986. </year>
Reference-contexts: First, a content theory of volitional explanations for motivational analysis 9 is proposed. Second, a graph-based representation of the structure of explanation patterns is introduced. Third, the process of case-based explanation, while similar to that used by the SWALE program <ref> [Kass et al., 1986] </ref>, is formulated in a knowledge goal-based framework. Our emphasis is on the knowledge goals that underly the creation, verification and learning of explanations. Further details of the explanation process may be found in Ram [1990a; 1989].
Reference: [Lenat, 1976] <author> D. B. Lenat. </author> <title> A.M.: An artificial intelligence approach to discovery in mathematics as heuristic search. </title> <type> Ph.D. thesis, </type> <institution> Stanford University, Artificial Intelligence Laboratory, </institution> <year> 1976. </year>
Reference: [Livesey, 1986] <author> P. Livesey. </author> <title> Learning and emotion: A biological synthesis, </title> <booktitle> volume 1 of Evolutionary Processes. </booktitle> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hillsdale, NJ, </address> <year> 1986. </year>
Reference: [Luria, 1968] <author> A. Luria. </author> <title> The Mind of a Mnemonist. </title> <address> New York, </address> <year> 1968. </year>
Reference-contexts: Even people who are considered gluttons for knowledge do not infer everything that can be inferred; they focus on particular aspects of their environment. There is a well known psychiatric case of a person who had immense recall, but did not distinguish between relevant and irrelevant material <ref> [Luria, 1968] </ref>; his pathology is not considered a kind of wild curiosity. Humanlike curiosity seems to us to require motivated pursuit of knowledge, or active learning, and not just the simple absorption of data and their consequences.
Reference: [Minton, 1988] <author> S. Minton. </author> <title> Learning effective search control knowledge: An explanation-based approach. </title> <type> Ph.D. thesis, </type> <institution> Carnegie-Mellon University, Computer Science Department, </institution> <address> Pittsburgh, PA, </address> <year> 1988. </year> <note> Technical Report CMU-CS-88-133. </note>
Reference-contexts: The problem arises in noninductive learning systems as well. For example, the questions of "when to generalize" and "how far to generalize" are among the central issues in explanation-based learning. Again, most of the approaches to this problem thus far involve syntactic solutions. An exception is Minton's PRODIGY system <ref> [Minton, 1988] </ref>, which evaluated each explanation's effect on the average reasoning process before integrating it into permanent memory.
Reference: [Ram and Cox, 1992] <author> A. Ram and M. Cox. </author> <title> Introspective Reasoning using Meta-Explanations for Multistrat-egy Learning. </title> <editor> In R. Michalski and G. Tecuci, editors, </editor> <title> Machine Learning IV: A Multistrategy Approach. </title> <publisher> Morgan Kaufman Publishers, Inc., </publisher> <year> 1992. </year> <note> In preparation. </note>
Reference-contexts: These issues are being explored further in the INVESTIGATOR [Hunter, 1990b; Hunter, 1990a] and META-AQUA <ref> [Cox and Ram, 1991; Ram and Cox, 1992] </ref> projects. 7 Comparison to other approaches Other cognitive theories have also included reference to desires for knowledge, although there are significant differences between those prior theories and our theory of knowledge goals.
Reference: [Ram and Leake, 1991] <author> A. Ram and D. Leake. </author> <title> Evaluation of Explanatory Hypotheses. </title> <booktitle> In Proceedings of the Thirteenth Annual Conference of the Cognitive Science Society, </booktitle> <address> Chicago, IL, </address> <month> August </month> <year> 1991. </year>
Reference-contexts: Abduction, the construction of causal explanations, is often viewed as inference to the "best" explanation. However, the definition of "best" is, as before, dependent on the goals of the reasoner in forming the explanation and not just on the correctness of the causal chain underlying the explanation <ref> [Ram and Leake, 1991] </ref>. In situations where there is not just a single correct explanation, the best explanation must address the reason that the explanation was required in the first place.
Reference: [Ram, 1987] <author> A. Ram. </author> <title> AQUA: Asking Questions and Understanding Answers. </title> <booktitle> In Proceedings of the Sixth Annual National Conference on Artificial Intelligence, </booktitle> <pages> pages 312-316, </pages> <address> Seattle, WA, July 1987. </address> <publisher> Morgan Kaufman Publishers, Inc., </publisher> <address> Los Altos, CA. </address>
Reference-contexts: One of our examples is AQUA, a story understanding program that learns from what it reads <ref> [Ram, 1987; Ram, 1989] </ref>. In order to understand text, the performance system must integrate the text, which is often 4 ambiguous, elliptic and vague, with its world knowledge, which is often incomplete and possibly incorrect.
Reference: [Ram, 1989] <author> A. Ram. </author> <title> Question-driven understanding: An integrated theory of story understanding, memory and learning. </title> <type> Ph.D. thesis, </type> <institution> Yale University, Department of Computer Science, </institution> <address> New Haven, CT, </address> <month> May </month> <year> 1989. </year> <note> Research Report #710. </note>
Reference-contexts: One of our examples is AQUA, a story understanding program that learns from what it reads <ref> [Ram, 1987; Ram, 1989] </ref>. In order to understand text, the performance system must integrate the text, which is often 4 ambiguous, elliptic and vague, with its world knowledge, which is often incomplete and possibly incorrect.
Reference: [Ram, 1990a] <author> A. Ram. </author> <title> Decision Models: A Theory of Volitional Explanation. </title> <booktitle> In Proceedings of the Twelvth Annual Conference of the Cognitive Science Society, </booktitle> <pages> pages 198-205, </pages> <address> Cambridge, MA, July 1990. </address> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference-contexts: For the purpose of understanding stories involving motivations of people, we have developed a taxonomy of motivational questions that focus on those motivational aspects of stories that are needed to build volitional explanations based on the planning/decision model that underlies AQUA's theory of explanation <ref> [Ram, 1990a] </ref>. A small part of this taxonomy is shown in figure 3, which depicts basic questions the system asks in explaining an agent's actions. The taxonomy of questions is based on the understanding tasks that AQUA needs to perform when it reads a story.
Reference: [Ram, 1990b] <author> A. Ram. </author> <title> Incremental Learning of Explanation Patterns and their Indices. </title> <editor> In B. W. Porter and R. J. Mooney, editors, </editor> <booktitle> Proceedings of the Seventh International Conference on Machine Learning, </booktitle> <pages> pages 313-320, </pages> <address> Austin, TX, June 1990. </address> <publisher> Morgan Kaufman Publishers, Inc. </publisher>
Reference-contexts: maintain an explicit model of what it needs to know to complete its understanding of the problem, i.e., of the "gaps" in its knowledge base, (c) learn by filling in these gaps when the information it needs becomes available, and hence (d) gradually evolve a better understanding of the domain <ref> [Ram, 1990b; Ram, 1992] </ref>. Thus the learning process is focussed by the knowledge goals of the system. Reading can be thought of as one type of knowledge action.
Reference: [Ram, 1990c] <author> A. Ram. </author> <title> Knowledge Goals: A Theory of Interestingness. </title> <booktitle> In Proceedings of the Twelvth Annual Conference of the Cognitive Science Society, </booktitle> <pages> pages 206-214, </pages> <address> Cambridge, MA, July 1990. </address> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference-contexts: AQUA uses heuristics of this kind, called interestingness heuristics, to decide which knowledge goals to generate and pursue <ref> [Ram, 1990c] </ref>. A somewhat less direct relationship between the goals that an entity is pursuing and the generation of new knowledge goals can be found in goals generated in response to failures. <p> Implementational details may be found in Ram [1989]. 5 Knowledge goals as a theory of interestingness One interesting outcome of this work is the formulation of a functional theory of interestingness <ref> [Ram, 1990c] </ref>.
Reference: [Ram, 1991] <author> A. Ram. </author> <title> A Theory of Questions and Question Asking. </title> <journal> The Journal of the Learning Sciences, </journal> <volume> 1(3&4), </volume> <year> 1991. </year> <note> In press. </note>
Reference-contexts: The intent is not to have the program acquire the "right" understanding of terrorism, but rather to be able to wonder about unusual things it reads about and ask questions about them. As it learns more about the domain, it asks better and more detailed questions <ref> [Ram, 1991] </ref>.
Reference: [Ram, 1992] <author> A. Ram. </author> <title> Indexing, Elaboration and Refinement: Incremental Learning of Explanatory Cases. </title> <booktitle> Machine Learning, </booktitle> <year> 1992. </year> <note> To appear. Also available as Technical Report GIT-CC-92/03, </note> <institution> College of Computing, Georgia Institute of Technology, </institution> <address> Atlanta, GA. </address> <month> 28 </month>
Reference-contexts: maintain an explicit model of what it needs to know to complete its understanding of the problem, i.e., of the "gaps" in its knowledge base, (c) learn by filling in these gaps when the information it needs becomes available, and hence (d) gradually evolve a better understanding of the domain <ref> [Ram, 1990b; Ram, 1992] </ref>. Thus the learning process is focussed by the knowledge goals of the system. Reading can be thought of as one type of knowledge action.
Reference: [Rieger, 1975] <author> C. Rieger. </author> <title> Conceptual Memory and Inference. </title> <editor> In R. C. Schank, editor, </editor> <booktitle> Conceptual Information Processing. </booktitle> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <year> 1975. </year>
Reference-contexts: How can that be done? Several methods of controlling inference have been proposed. Perhaps the simplest is constrained forward chaining: making as many inferences as possible within the resource constraints. For example, MARGIE <ref> [Rieger, 1975] </ref> made all the justified inferences that required the chaining of no more than 5 of 17 rules.
Reference: [Sacerdoti, 1975] <author> E. D. Sacerdoti. </author> <title> A structure for plans and behavior. </title> <type> Technical Report 109, </type> <institution> Stanford Research Institute, Artificial Intelligence Center, </institution> <year> 1975. </year>
Reference-contexts: Our work focusses, not so much on the truth or correctness of inferences, as on the utility of these inferences for reasoning and learning. Our process of planning to learn does not involve detailed reasoning about subproblem interactions (e.g., <ref> [Sussman, 1975; Sacerdoti, 1975] </ref>) and constraint propagation (e.g., [Stefik, 1981]) that is the focus of much work in conventional planning and problem solving.
Reference: [Schank and Abelson, 1977] <author> R. C. Schank and R. Abelson. </author> <title> Scripts, Plans, Goals and Understanding: An Inquiry into Human Knowledge Structures. </title> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hillsdale, NJ, </address> <year> 1977. </year>
Reference: [Schank, 1979] <author> R. C. Schank. Interestingness: </author> <title> Controlling Inferences. </title> <journal> Artificial Intelligence, </journal> <volume> 12 </volume> <pages> 273-297, </pages> <year> 1979. </year>
Reference-contexts: Thus the interestingness heuristics described below are indeed heuristics rather than precise measures of the value of thinking about a fact or a question. This is a functional approach to the problem of interestingness <ref> [Hidi and Baird, 1986; Schank, 1979] </ref> from the perspective of our theory of knowledge goals.
Reference: [Schank, 1982] <author> R. C. Schank. </author> <title> Dynamic Memory: A Theory of Learning in Computers and People. </title> <publisher> Cambridge University Press, </publisher> <address> New York, NY, </address> <year> 1982. </year>
Reference-contexts: The generation of D-KNOW goals was always tied very specifically to a physical supergoal (e.g., satisfy hunger), and were not mentioned in the author's later theories of learning (e.g., <ref> [Schank, 1982] </ref>). Other theories, particularly from the animal learning psychology literature, have proposed diffuse motivations to learn: a "will to perceive" (Thorpe), a "motivation for learning" (Thacker), and a "search by an information hungry organism" (Pribram, all reported in Livesey [1986], p. 20-21).
Reference: [Schank, 1986] <author> R. C. Schank. </author> <title> Explanation Patterns: Understanding Mechanically and Creatively. </title> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hillsdale, NJ, </address> <year> 1986. </year>
Reference: [Sperber and Wilson, 1986] <author> D. Sperber and D. Wilson. </author> <title> Relevance: Communication and Cognition. </title> <booktitle> Language and Thought Series. </booktitle> <publisher> Harvard University Press, </publisher> <address> Cambridge, MA, </address> <year> 1986. </year>
Reference-contexts: This is related to the "goal satisfaction principle" of [Hayes-Roth and Lesser, 1976], which states that more processing should be given to knowledge sources whose responses are most likely to satisfy processing goals, and to the "relevance principle" of <ref> [Sperber and Wilson, 1986] </ref>, which states that humans pay attention only to information that seems relevant to them. These principles make sense because cognitive processes are geared to achieving a large cognitive effect for a small effort. <p> These principles make sense because cognitive processes are geared to achieving a large cognitive effect for a small effort. To achieve this, the understander must focus its attention on what seems to it to be the most relevant information available <ref> [Sperber and Wilson, 1986] </ref>. The Hayes-Roth and Lesser paper prefigures the approach presented here. The additional step suggested here is to mediate the influence of processing goals on attentional decisions by using explicit characterizations of desirable knowledge.
Reference: [Srull and Wyer, 1986] <author> T. Srull and R. Wyer. </author> <title> The Role of Chronic and Temporary Goals in Social Information Processing. </title> <editor> In R. Sorrentino and E. Higgins, editors, </editor> <booktitle> Handbook of Motivation and Cognition: Foundations of Social Behavior, </booktitle> <pages> pages 503-549. </pages> <publisher> The Guilford Press, </publisher> <address> Guilford, CT, </address> <year> 1986. </year>
Reference: [Stefik, 1981] <author> M. J. Stefik. </author> <title> Planning with constraints (MOLGEN: Part 1). </title> <journal> Artificial Intelligence, </journal> <volume> 16(2) </volume> <pages> 111-140, </pages> <year> 1981. </year>
Reference-contexts: Our work focusses, not so much on the truth or correctness of inferences, as on the utility of these inferences for reasoning and learning. Our process of planning to learn does not involve detailed reasoning about subproblem interactions (e.g., [Sussman, 1975; Sacerdoti, 1975]) and constraint propagation (e.g., <ref> [Stefik, 1981] </ref>) that is the focus of much work in conventional planning and problem solving.
Reference: [Sussman, 1975] <author> G. J. Sussman. </author> <title> A Computer Model Of Skill Acquisition, </title> <booktitle> volume 1 of Artificial Intelligence Series. </booktitle> <publisher> American Elsevier, </publisher> <address> New York, </address> <year> 1975. </year>
Reference-contexts: Our work focusses, not so much on the truth or correctness of inferences, as on the utility of these inferences for reasoning and learning. Our process of planning to learn does not involve detailed reasoning about subproblem interactions (e.g., <ref> [Sussman, 1975; Sacerdoti, 1975] </ref>) and constraint propagation (e.g., [Stefik, 1981]) that is the focus of much work in conventional planning and problem solving.
Reference: [Tong, 1987] <author> C. Tong. </author> <title> Towards An Engineering Science Of Knowledge-Based Design. </title> <note> Ai/Vlsi Project Working Paper 49, </note> <institution> Rutgers University, Department Of Computer Science, </institution> <address> New Brunswick, Nj, </address> <year> 1987. </year>
Reference-contexts: Goal-directed planning has been investigated in the context of other reasoning tasks. For example, Tong's work on goal-directed planning in knowledge-based design addresses issues in task prioritization and inference control in the context of the design task <ref> [Tong, 1987] </ref>.
Reference: [Utgoff, 1986] <author> P. Utgoff. </author> <title> Shift Of Bias For Inductive Concept Learning. </title> <editor> In R. S. Michalshi, J. G. Carbonell, and T. M. Mitchell, editors, </editor> <booktitle> Machine Learning, </booktitle> <pages> page 107. </pages> <publisher> Morgan Kaufman, </publisher> <address> Los Altos, Ca, </address> <year> 1986. </year>
Reference-contexts: In general, an inductive system must have a method for preferring some inferences over others. Existing machine learning methods have done this by applying inductive biases (e.g., <ref> [Utgoff, 1986] </ref>), or by a priori limitations on the structure of the inferences they can make, through, for example, the use of decision trees or neural networks. These approaches can be considered syntactic, in that they constrain the form of the hypotheses considered, rather than their content.
Reference: [Wilensky, 1986] <author> R. Wilensky. </author> <title> Knowledge Representation | A Critique and A Proposal. </title> <editor> In J. L. Kolod-ner and C. K. Riesbeck, editors, </editor> <booktitle> Experience, Memory and Reasoning, chapter 2, </booktitle> <pages> pages 15-28. </pages> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hilldale, NJ, </address> <year> 1986. </year>
Reference-contexts: For example, the results slot specifies a causal relation of a particular kind between an action and a state. Similarly, the actor slot in an action frame specifies a participatory relation between the action and a volitional-agent. Relations are themselves represented as frames in memory (e.g., see <ref> [Wilensky, 1986] </ref>), allowing AQUA to reason about the relations themselves. Knowledge goals seeking relations between concepts are indexed in the appropriate slots in the frames representing these concepts.
Reference: [Yesner and Carter, 1982] <author> R. Yesner and D. Carter. </author> <title> Pathology of Carcinoma of the Lung: Changing Patterns. </title> <journal> Clinics in Chest Medicine, </journal> <volume> 3(2) </volume> <pages> 257-289, </pages> <year> 1982. </year>
Reference-contexts: Two of the three "lessons" that IVY learned in response to its knowledge goals were identified by the domain expert, Dr. Yesner, as good teaching cases. One of the images IVY selected had been previously used as an example in one of Dr. Yesner's publications <ref> [Yesner and Carter, 1982] </ref>. Dr. Yesner considered the third case discovered by IVY "quite useful" for showing how to avoid a subtle diagnostic error.
Reference: [Zukier, 1986] <author> H. Zukier. </author> <title> The Paradigmatic and Narrative Modes in Goal-Guided Inference. </title> <editor> In R. Sorrentino and E. Higgins, editors, </editor> <booktitle> Handbook of Motivation and Cognition: Foundations of Social Behavior, </booktitle> <pages> pages 465-502. </pages> <publisher> Guilford Press, </publisher> <address> Guilford, CT, </address> <year> 1986. </year> <month> 29 </month>
References-found: 46

