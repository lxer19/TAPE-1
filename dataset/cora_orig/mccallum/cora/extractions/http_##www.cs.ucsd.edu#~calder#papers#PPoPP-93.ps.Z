URL: http://www.cs.ucsd.edu/~calder/papers/PPoPP-93.ps.Z
Refering-URL: http://www.cs.ucsd.edu/~calder/papers.html
Root-URL: http://www.cs.ucsd.edu
Title: Leapfrogging: A Portable Technique for Implementing Efficient Futures  
Author: David B. Wagner Bradley G. Calder 
Note: C++.  
Address: Campus Box #430  Boulder 80309-0430  
Affiliation: Department of Computer Science  University of Colorado,  
Abstract: A future is a language construct that allows programmers to expose parallelism in applicative languages such as MultiLisp [5] with minimal effort. In this paper we describe a technique for implementing futures, which we call leapfrogging, that reduces blocking due to load imbalance. The utility of leapfrogging is enhanced by the fact that it is completely platform-independent, is free from deadlock, and places a bound on stack sizes that is at most a small constant times the maximum stack size encountered during a sequential execution of the same computation. We demonstrate the performance of leapfrogging using a prototype implementation written in 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Cooper, E., and Draves, R. C-Threads. </author> <type> Tech. Rep. </type> <institution> CMU-CS-88-154, Carnegie-Mellon University, </institution> <month> Feb. </month> <year> 1988. </year> <title> 5 This is one scenario in which LTC has a clear advantage over leapfrogging. </title> <note> October 7, 1992 PPoPP '93 MANUSCRIPT 12 </note>
Reference-contexts: The parallel processing requirements of the software are satisfied by any system that provides a mechanism for thread creation (Cthreads, Posix threads, even heavyweight processes with shared memory such as are provided by Dynix's m fork ()) and locks. Our current implementation is based on Cthreads <ref> [1] </ref>. The techniques are most efficient using spin-waiting locks, but the implementation can be modified easily to work with blocking locks. All lock routines are accessed indirectly through macros that are declared in a single header file. <p> In addition, it is provably free from deadlocks and worker stack sizes are kept within a constant factor of the maximum stack size that a sequential execution of the computation would encounter. We have demonstrated the performance of leapfrogging using a prototype system implemented in C++ using Cthreads <ref> [1] </ref> to manage parallelism and synchronization. However, the implementation is easily portable to any platform that provides thread creation primitives, shared memory, and mutual-exclusion locks.
Reference: [2] <author> Ellis, M. A., and Stroustrup, B. </author> <title> The Annotated C++ Reference Manual. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1990. </year>
Reference-contexts: One way to implement this (in C++) is to have the programmer encapsulate the futurized function in a subclass of a special base class, which in turn overloads the member selection operator <ref> [2] </ref>. This enables the base class to track every call to the function.
Reference: [3] <author> Goldman, R., and Gabriel, R. </author> <title> Preliminary results with the initial implementation of Qlisp. </title> <booktitle> In Proc. 1989 Conf. on Lisp and Functional Programming (July 1989), ACM SIGPLAN, ACM, </booktitle> <pages> pp. 143-152. </pages>
Reference-contexts: The idea is to dynamically monitor the load and create a new task to compute a future only when processors are idle. Otherwise, the future is executed inline by the task that creates it. This keeps the number of tasks created close to the number of processors available. Qlisp <ref> [3, 4] </ref> provides the programmer with primitives that inspect the state of the system, and allows the programmer to specify an arbitrary predicate to control the inlining of futures. One problem with any type of inlining is that a decision to inline a future cannot be revoked.
Reference: [4] <author> Goldman, R., and Gabriel, R. </author> <title> Qlisp: </title> <booktitle> Parallel procesing in Lisp. IEEE Software (July 1989), </booktitle> <pages> 51-59. </pages>
Reference-contexts: The idea is to dynamically monitor the load and create a new task to compute a future only when processors are idle. Otherwise, the future is executed inline by the task that creates it. This keeps the number of tasks created close to the number of processors available. Qlisp <ref> [3, 4] </ref> provides the programmer with primitives that inspect the state of the system, and allows the programmer to specify an arbitrary predicate to control the inlining of futures. One problem with any type of inlining is that a decision to inline a future cannot be revoked.
Reference: [5] <author> Halstead, Jr., R. </author> <title> Multilisp: A language for concurrent symbolic computation. </title> <journal> ACM Transactions on Programming Languages and Systems 7, </journal> <month> 4 (Oct. </month> <year> 1985), </year> <pages> 501-538. </pages>
Reference: [6] <author> Mohr, E., Kranz, D., and Halstead, Jr., R. </author> <title> Lazy task creation: A technique for increasing the granularity of parallel programs. </title> <journal> IEEE Transactions on Parallel and Distributed Systems 2, </journal> <month> 3 (July </month> <year> 1991), </year> <pages> 264-280. </pages>
Reference-contexts: The principal design rationale behind futures is that "the programmer takes on the burden of identifying what can be computed safely in parallel, leaving the decision of exactly how the division [of work] will take place to the runtime system" <ref> [6] </ref>. Another nice feature of futures is that all synchronization is implicit. The programmer never explicitly checks to see if the value of a computation is ready; if it is not, the thread of control trying to use that value is transparently blocked. <p> Even worse, a careless implementation can lead to very subtle deadlock problems in realistic (not contrived) computations. A very elegant, but complicated, solution to these problems was presented by Mohr, Krantz and Halstead <ref> [6] </ref>. Their system, which we will explore in more detail in the next section, is based on continuations. In this paper we present an alternative technique for implementing efficient futures, leapfrogging, that also is very portable. <p> The crucial point is that leapfrogging provides efficiency similar to that of more complex techniques such as LTC, but can be ported with very little effort to any system that provides process creation, shared memory, and lock synchronization primitives. 2 Performance Issues 2.1 Basic issues The sum-tree example from <ref> [6] </ref> 1 provides a good illustration of how difficult it is to get good load distribution and minimal blocking using futures, because it contains a plethora of potential parallelism. <p> Unfortunately, in the WorkCrew approach there is no other task to switch to! We conclude that a naive WorkCrew approach would be considerably faster than the one-task-per-future approach for balanced computations, but could be arbitrarily bad for unbalanced computations. 2.3 Lazy Task Creation Mohr et al. <ref> [6] </ref> have devised a clever scheme that they call Lazy Task Creation (LTC) that solves the problems just discussed. Their technique is built into a compiler for Mul-T, a parallel dialect of Scheme. <p> In Mul-T, (K (future X)) is interpreted to mean, "Start evaluating X in the current task, but save enough information so that its continuation K can be moved to a separate task if another processor becomes idle" <ref> [6] </ref>. This effectively makes the decision to inline any future a revocable one, so the default behavior is that every future is inlined. There are exactly as many tasks as processors, and continuations are stolen (i.e., moved to another processor) only when a processor becomes idle. <p> When such a case arises, the scheduler selects another continuation from the blocked task's stack to work on and cuts the stack again. The authors claim that the costs of doing this are low enough to meet their performance goals. For more details see <ref> [6] </ref>. Obviously, LTC is a completely general approach with the potential for very good performance. If the load is well-balanced, continuation-stealing will happen infrequently, if at all, and the computation will proceed much faster than if the futures had not been inlined. <p> to guarantee good performance with load-based inlining is through experimenting with some work queue limits until one is found that best fits the application. 4.1 A synthetic benchmark In order to test out how our futures perform with different granularities we ran a synthetic benchmark, similar to the one in <ref> [6] </ref>. The synthetic benchmark is a modification of the sum-tree program. The only difference is that before a leaf returns its value, a for loop is executed that delays the leaf node for a specified number of machine instructions. <p> However, efficiency exceeds 90% for granularities larger than about 750 instructions. Our performance is comparable to but not quite as good as the Encore implementation of Lazy Task Creation reported in <ref> [6] </ref>. <p> However, this is somewhat misleading, because certain futures-related overheads, which are built into the Mul-T compiler, are present in the sequential times reported in that paper; these overheads reportedly cause dilations of the execution times of sequential programs in the range of 1.4 to 2.2 <ref> [6, Table 1] </ref>. 4.2 Gamma Gamma is a recursive, adaptive quadrature algorithm that computes the gamma function: (n) = 0 The basic subroutine in Gamma computes the area under the integrand over a given interval using trapezoidal rule.
Reference: [7] <author> Vandevoorde, M. T., and Roberts, E. S. Workcrews: </author> <title> An abstraction for controlling parallelism. </title> <journal> Int. Journal of Parallel Programming 17, </journal> <volume> 4 (1988), </volume> <pages> 347-366. </pages>
Reference-contexts: October 7, 1992 PPoPP '93 MANUSCRIPT 3 2.2 WorkCrews The "obvious" solution to the granularity vs. load balancing dilemma is to note that there is really no need to create a separate task for every future. Instead, a WorkCrew-style approach can be adopted <ref> [7] </ref>: a future is implemented as a passive object that contains enough information to carry out the computation. These passive objects are then picked up by worker tasks and executed. The number of workers is fixed and is equal to the number of processors.
Reference: [8] <author> Wagner, D., and Calder, B. </author> <title> Portable, efficient futures. </title> <institution> Computer Sci. Dept. </institution> <type> Tech. Rep. </type> <institution> #CU-CS-609-92, University of Colorado, Boulder, CO, </institution> <month> Aug. </month> <year> 1992. </year> <note> (To be submitted, probably to IEEE TPDS). </note>
Reference-contexts: To solve the latter October 7, 1992 PPoPP '93 MANUSCRIPT 4 problem, Mohr et al. implemented a linked-list call-stack, which exacerbates the former problem. Practically speaking, this will likely limit the use of LTC to a narrow community of users. Our experience in <ref> [8] </ref> has convinced us that futures have a much wider domain of application than they have usually been credited with, and our motivation is thus to "spread the word" about them to as wide a community of users as possible. <p> This assumption is certainly true of all recursive computations, and many non-recursive computations as well. Space constraints prevent us from including any proofs here; the full proofs can be found in <ref> [8] </ref>. We show that, under the assumptions given, the leapfrog depth rule not only is a sufficient condition for P1 and P2 to hold, but also is a necessary one. 3.3 Portability It should be clear from the discussion in this section that our techniques are not platform- or language-dependent. <p> However, the implementation is easily portable to any platform that provides thread creation primitives, shared memory, and mutual-exclusion locks. Additional information on our implementation and our experiences using futures on a variety of parallel program structures can be found in the unabridged version of this paper <ref> [8] </ref>.
References-found: 8

