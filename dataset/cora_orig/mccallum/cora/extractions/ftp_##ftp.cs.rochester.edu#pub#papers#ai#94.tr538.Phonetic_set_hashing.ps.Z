URL: ftp://ftp.cs.rochester.edu/pub/papers/ai/94.tr538.Phonetic_set_hashing.ps.Z
Refering-URL: http://www.cs.rochester.edu/trs/ai-trs.html
Root-URL: 
Title: Phonetic Set Hashing: A Novel Scheme For Transforming Phone Sequences To Words  
Note: This material is based upon work supported by the National Science Foundation under Grant number IRI-8903582, and NIH/PHS research grant no. 1 R24 RR06853-02. The Government has certain rights in this material.  
Abstract: Ramesh R. Sarukkai & Dana H. Ballard The University of Rochester Computer Science Department Rochester, New York 14627 Technical Report 538 November 1994 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Chuck Wooters, and Andreas Stolcke, </author> <title> "Multiple-Pronunciation Lexical Modeling in a Speaker Independent Speech System Understanding System", </title> <note> to appear in Proc. of ICSLP-94. </note>
Reference-contexts: Conventional HMM based recognition systems use a single transcription per word as provided by the lexicon. Some researchers have recently explored data-driven multiple pronunciation lexical modeling <ref> [1] </ref>. How useful is the single transcription of each word for recognition using hashing schemes? In order to examine this, the lexicon transcriptions of the TIMIT dr1 test and train sentences were hashed in as before.
Reference: [2] <author> Kai-Fu Lee, </author> <title> Automatic Speech Recognition: The Development of the SPHINX System, </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1989. </year>
Reference-contexts: The TIMIT database consists of a lexicon of 6229 words. The 61 TIMIT phones were reduced to 48 phones as in Lee <ref> [2] </ref>. For each word, a single transcription is listed in the lexicon. Each phonetic transcription of the word was transformed into the corresponding phone set. The phone set will consist of all the phones that are present in the phonetic transcription of the word.
Reference: [3] <author> Kai-Fu Lee, </author> <title> "Context-Dependent Phonetic Hidden Markov Models for Speaker-Independent Continuous Speech Recognition", </title> <journal> IEEE Trans. on Acoustics, Speech, and Signal Processing, </journal> <month> April </month> <year> 1990. </year>
Reference: [4] <author> Rabiner, </author> <title> L.R., "A tutorial on Hidden Markov Models and Selected applications in speech recognition", </title> <journal> Proc. IEEE, </journal> <volume> 77(2) </volume> <pages> 257-286, </pages> <year> 1989. </year>
Reference: [5] <author> L. R. Bahl, P. V. de Souza, P. S. Gopalakrishnan, D. Nahamoo, and M. A. Picheny, </author> <title> "A Fast Match For Continuous Speech Recognition Using Allophonic Models", </title> <booktitle> IEEE ICASSP, </booktitle> <address> I-17-I-20, </address> <year> 1992. </year>
Reference-contexts: Finding such a set of words is called lexical access, and the search is termed as a fast match. Many fast match schemes have been proposed: Bahl et al have proposed a fast match using allophonic models <ref> [5] </ref>. Other search techniques include N-best recognition techniques, and progressive search techniques [6]. It is clear that in order to achieve fast, on-line continuous speech recognitions, it is important to develop an efficient and accurate bottom-up word pre-selection method.
Reference: [6] <author> Hy Murveit, John Butzberger, Vassilios Digalakis, and Mitch Weintraub, </author> <title> "Large-Vocabulary Dictation Using SRI's DECIPHER Speech Recognition System: Progressive Search Techniques", </title> <booktitle> Proc. IEEE ICASSP, </booktitle> <address> II-319-II322, </address> <year> 1993. </year>
Reference-contexts: Finding such a set of words is called lexical access, and the search is termed as a fast match. Many fast match schemes have been proposed: Bahl et al have proposed a fast match using allophonic models [5]. Other search techniques include N-best recognition techniques, and progressive search techniques <ref> [6] </ref>. It is clear that in order to achieve fast, on-line continuous speech recognitions, it is important to develop an efficient and accurate bottom-up word pre-selection method.
Reference: [7] <author> T. Kohonen, H. Riittinen, E. Reuhkala, and S. Haltsonen, </author> <title> "On-line Recognition of Spoken Words from a Large Vocabulary", </title> <booktitle> Information Sciences 33, </booktitle> <month> pp.3-20 </month> <year> (1984). </year>
Reference-contexts: Other search techniques include N-best recognition techniques, and progressive search techniques [6]. It is clear that in order to achieve fast, on-line continuous speech recognitions, it is important to develop an efficient and accurate bottom-up word pre-selection method. Kohonen <ref> [7] </ref> has proposed a redundant hash addressing method that recognizes an isolated spoken word based on reference to a dictionary using "features" extracted from an input phoneme sequence. Two or three consecutive phonemes (bigrams or trigrams) are used as features.
Reference: [8] <author> Akinori Ito, and Shozo Makino, </author> <title> "A New Word Pre-selection Method Based on an Extended Redundant Addressing For Continuous Speech Recognition", </title> <booktitle> Proc. IEEE ICASSP, </booktitle> <address> II-299-II-302, </address> <year> 1993. </year>
Reference-contexts: Next, the trigrams are extracted from a phoneme sequence recognized from the input speech. The extracted trigram votes to word candidates using hash search, and the word with the highest number of votes is chosen as the recognition result. The redundant hash addressing method has been extended <ref> [8] </ref> for continuous speech recognition to incorporate additional features such as utilization of confusion matrix of the phoneme recognition to make dictionary reference more accurate, and activation point matching for spotting words using the references from trigrams by applying a restricted dynamic programming match.
References-found: 8

