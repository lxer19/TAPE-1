URL: http://www.isi.edu/soar/jihie/papers/aaai96.ps
Refering-URL: http://www.isi.edu/soar/jihie/chunking.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Learning Efficient Rules by Maintaining the Explanation Structure  
Author: Jihie Kim and Paul S. Rosenbloom 
Keyword: Key words: utility problem, EBL, Soar  
Address: 4676 Admiralty Way Marina del Rey, CA 90292, U.S.A.  
Affiliation: Information Sciences Institute and Computer Science Department University of Southern California  
Note: In Proceedings of the Thirteenth National Conference on Artificial Intelligence (to appear).  
Email: jihie@isi.edu, rosenbloom@isi.edu  
Phone: (310) 822-1510  
Web: (x769)  
Abstract: Many learning systems suffer from the utility problem; that is, that time after learning is greater than time before learning. Discovering how to assure that learned knowledge will in fact speed up system performance has been a focus of research in explanation-based learning (EBL). One way to analyze the utility problem is by examining the differences between the match process (match search) of the learned rule and the problem-solving process from which it is learned. Prior work along these lines examined one such difference. It showed that if the search-control knowledge used during problem solving is not maintained in the match process for learned rules, then learning can engender a slowdown; but that this slowdown could be eliminated if the match is constrained by the original search-control knowledge. This article examines a second difference | when the structure of the problem solving differs from the structure of the match process for the learned rules, time after learning can be greater than time before learning. This article also shows that this slowdown can be eliminated by making the learning mechanism sensitive to the problem-solving This research was supported under subcontract to the University of Southern California Information Sciences Institute from the University of Michigan, as part of contract N00014-92-K-2015 from the Advanced Systems Technology Office (ASTO) of the Advanced Research Projects Agency (ARPA) and the Naval Research Laboratory (NRL); and under contract N66001-95-C-6013 from the Advanced Systems Technology Office (ASTO) of the Advanced Research Projects Agency (ARPA) and the Naval Command and Ocean Surveillance Center, RDT&E division (NRaD). We would like to thank Jon Gratch and Milind Tambe for helpful comments on this work. structure; i.e., by reflecting such structure in the match of the learned rule.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> T. M. Mitchell, R. M. Keller, and S. T. Kedar-Cabelli. </author> <title> Explanation-based generalization - a unifying view. </title> <journal> Machine Learning, </journal> <volume> 1(1) </volume> <pages> 47-80, </pages> <year> 1986. </year>
Reference: [2] <author> G. F. DeJong and R. Mooney. </author> <title> Explanation-based learning: An alternative view. </title> <journal> Machine Learning, </journal> <volume> 1(2) </volume> <pages> 145-176, </pages> <year> 1986. </year>
Reference: [3] <author> J. E. Laird, A. Newell, and P. S. Rosenbloom. </author> <title> Soar: An architecture for general intelligence. </title> <journal> Artificial Intelligence, </journal> <volume> 33 </volume> <pages> 1-64, </pages> <year> 1987. </year>
Reference-contexts: Unfortunately, EBL suffers from the utility problem, so that the cost of using learned rules often overwhelms their benefit. Research on the utility problem can be divided up into two key issues. The first issue is the expensive chunk 2 problem <ref> [3, 4] </ref>, in which individual learned rules are so expensive to match that the system suffers a slow down from learning [5, 6, 7, 8, 9]. <p> Prior work on this topic has examined one such difference: in chunking (and other EBL systems which use search control in problem solving), eliminating search control in learning can increase the cost of the learned rules [17]. For example, PRODIGY/EBL [18] and Soar <ref> [3, 4] </ref> | two problem solvers that learn rules by variants of EBL | ignore many of the search-control rules during learning in order to increase the generality of the learned rules.
Reference: [4] <author> P. S. Rosenbloom, J. E. Laird, A. Newell, and R. McCarl. </author> <title> A preliminary analysis of the Soar architecture as a basis for general intelligence. </title> <journal> Artificial Intelligence, </journal> <volume> 47(1-3):289-325, </volume> <year> 1991. </year>
Reference-contexts: Unfortunately, EBL suffers from the utility problem, so that the cost of using learned rules often overwhelms their benefit. Research on the utility problem can be divided up into two key issues. The first issue is the expensive chunk 2 problem <ref> [3, 4] </ref>, in which individual learned rules are so expensive to match that the system suffers a slow down from learning [5, 6, 7, 8, 9]. <p> Prior work on this topic has examined one such difference: in chunking (and other EBL systems which use search control in problem solving), eliminating search control in learning can increase the cost of the learned rules [17]. For example, PRODIGY/EBL [18] and Soar <ref> [3, 4] </ref> | two problem solvers that learn rules by variants of EBL | ignore many of the search-control rules during learning in order to increase the generality of the learned rules.
Reference: [5] <author> S. Minton. </author> <title> Quantitative results concerning the utility of explanation-based learning. </title> <booktitle> In Proceedings of the Seventh National Conference on Artificial Intelligence, </booktitle> <pages> pages 564-569, </pages> <year> 1988. </year>
Reference-contexts: Research on the utility problem can be divided up into two key issues. The first issue is the expensive chunk 2 problem [3, 4], in which individual learned rules are so expensive to match that the system suffers a slow down from learning <ref> [5, 6, 7, 8, 9] </ref>. The second issue is the average growth effect [10], in which the interactions across the rules slow down the system, even if none of the rules individually are all that expensive. <p> In this article we focus on the expensive chunk problem. Previous work on the expensive chunk problem has investigated how to produce cheaper rules <ref> [12, 5, 8, 13, 7] </ref> and how to filter out expensive rules [5, 14, 15, 16]. However, none of these approaches can generally guarantee that the cost of using the learned rules will always be bounded by the cost of the problem solving episode from which they are learned. <p> In this article we focus on the expensive chunk problem. Previous work on the expensive chunk problem has investigated how to produce cheaper rules [12, 5, 8, 13, 7] and how to filter out expensive rules <ref> [5, 14, 15, 16] </ref>. However, none of these approaches can generally guarantee that the cost of using the learned rules will always be bounded by the cost of the problem solving episode from which they are learned.
Reference: [6] <author> M. Tambe. </author> <title> Eliminating combinatorics from production match. </title> <type> PhD thesis, </type> <institution> Carnegie-Mellon University, </institution> <year> 1991. </year>
Reference-contexts: Research on the utility problem can be divided up into two key issues. The first issue is the expensive chunk 2 problem [3, 4], in which individual learned rules are so expensive to match that the system suffers a slow down from learning <ref> [5, 6, 7, 8, 9] </ref>. The second issue is the average growth effect [10], in which the interactions across the rules slow down the system, even if none of the rules individually are all that expensive. <p> That is, the cost of a learned rule can be greater than the cost of solving the problem with the original set of rules. There has been developed a technique for restricting the expressiveness of the rules to bound the match cost of the rules <ref> [6] </ref>. However, the restriction reduces the expressibility of the rules, requiring a large number of rules to encode tasks. Also, the learned rules may become very specific. <p> This is a generalization of the term used in the Soar system. 3 What is referred to as k-search in <ref> [6] </ref>. 2 during problem solving, thus creating more appropriately constrained rules. In this article, we focus on a second difference | when the structure of the problem solving differs from the structure of the match process for the learned rules, time after learning can be greater than time before learning. <p> Beta memories store partial instantiations of productions; that is, instantiations of initial subsequences of conditions. The partial instantiations are called tokens. Because match time per token is known to be approximately constant in Rete <ref> [24, 6] </ref> | and because counting tokens yields a measure that is independent of machines, optimizations, and implementation details | we will follow the standard practice established within the match-algorithm community and use the number of tokens as a comparative measure of match cost in addition to time. 3 A Source <p> Also, 9 we have introduced decision sub-nodes into Rete. We have applied the resulting experimental system to the Grid task <ref> [6] </ref> (Figure 8), which is one of the known expensive-chunk tasks. The results shown here are all from Soar6 (version 6.0.4), a C-based release of Soar [25] on a Sun SPARCstation-20. Each problem in the Grid task is to find a path between two points in a two dimensional grid. <p> The shared conditions across the different sub-parts reflect the multiple usage of those conditions in the original problem solving. This multiple usage keeps the cost bounded by constraining the sub-parts as they were in the problem solving. We also applied the system to the Magic Square task <ref> [6] </ref> (Figure 11), another known expensive-chunk task. The task involves placing tiles 1 through 9 in empty squares one at a time.
Reference: [7] <author> O. Etzioni. </author> <title> Why Prodigy/EBL works. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pages 916-922, </pages> <year> 1990. </year>
Reference-contexts: Research on the utility problem can be divided up into two key issues. The first issue is the expensive chunk 2 problem [3, 4], in which individual learned rules are so expensive to match that the system suffers a slow down from learning <ref> [5, 6, 7, 8, 9] </ref>. The second issue is the average growth effect [10], in which the interactions across the rules slow down the system, even if none of the rules individually are all that expensive. <p> In this article we focus on the expensive chunk problem. Previous work on the expensive chunk problem has investigated how to produce cheaper rules <ref> [12, 5, 8, 13, 7] </ref> and how to filter out expensive rules [5, 14, 15, 16]. However, none of these approaches can generally guarantee that the cost of using the learned rules will always be bounded by the cost of the problem solving episode from which they are learned.
Reference: [8] <author> P. Shell and J. Carbonell. </author> <title> Empirical and analytical performance of iterative operators. </title> <booktitle> In The 13th Annual Conference of The Cognitive Science Society, </booktitle> <pages> pages 898-902. </pages> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1991. </year>
Reference-contexts: Research on the utility problem can be divided up into two key issues. The first issue is the expensive chunk 2 problem [3, 4], in which individual learned rules are so expensive to match that the system suffers a slow down from learning <ref> [5, 6, 7, 8, 9] </ref>. The second issue is the average growth effect [10], in which the interactions across the rules slow down the system, even if none of the rules individually are all that expensive. <p> In this article we focus on the expensive chunk problem. Previous work on the expensive chunk problem has investigated how to produce cheaper rules <ref> [12, 5, 8, 13, 7] </ref> and how to filter out expensive rules [5, 14, 15, 16]. However, none of these approaches can generally guarantee that the cost of using the learned rules will always be bounded by the cost of the problem solving episode from which they are learned.
Reference: [9] <author> D. Subramanian and R. Feldman. </author> <title> The utility of EBL in recursive domain theories. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pages 942-949, </pages> <year> 1990. </year>
Reference-contexts: Research on the utility problem can be divided up into two key issues. The first issue is the expensive chunk 2 problem [3, 4], in which individual learned rules are so expensive to match that the system suffers a slow down from learning <ref> [5, 6, 7, 8, 9] </ref>. The second issue is the average growth effect [10], in which the interactions across the rules slow down the system, even if none of the rules individually are all that expensive.
Reference: [10] <author> B. Doorenbos, M. Tambe, and A. </author> <title> Newell. </title> <booktitle> Learning 10,000 chunks: What's it like out there? In Proceedings of the Tenth National Conference on Artificial Intelligence, </booktitle> <pages> pages 830-836, </pages> <year> 1992. </year>
Reference-contexts: The first issue is the expensive chunk 2 problem [3, 4], in which individual learned rules are so expensive to match that the system suffers a slow down from learning [5, 6, 7, 8, 9]. The second issue is the average growth effect <ref> [10] </ref>, in which the interactions across the rules slow down the system, even if none of the rules individually are all that expensive. Recent work on the average growth effect has shown that it is possible to learn over one million rules while still allowing their efficient use [10, 11]. <p> Recent work on the average growth effect has shown that it is possible to learn over one million rules while still allowing their efficient use <ref> [10, 11] </ref>. In this article we focus on the expensive chunk problem. Previous work on the expensive chunk problem has investigated how to produce cheaper rules [12, 5, 8, 13, 7] and how to filter out expensive rules [5, 14, 15, 16].
Reference: [11] <author> B. Doorenbos. </author> <title> Matching 100,000 learned rules. </title> <booktitle> In Proceedings of the Eleventh National Conference on Artificial Intelligence, </booktitle> <year> 1993. </year>
Reference-contexts: Recent work on the average growth effect has shown that it is possible to learn over one million rules while still allowing their efficient use <ref> [10, 11] </ref>. In this article we focus on the expensive chunk problem. Previous work on the expensive chunk problem has investigated how to produce cheaper rules [12, 5, 8, 13, 7] and how to filter out expensive rules [5, 14, 15, 16].
Reference: [12] <author> A. E. Prieditis and J. Mostow. PROLEARN: </author> <title> Towards a Prolog interpreter that learns. </title> <booktitle> In Proceedings of the Sixth National Conference on Artificial Intelligence, </booktitle> <pages> pages 494-498, </pages> <year> 1987. </year>
Reference-contexts: In this article we focus on the expensive chunk problem. Previous work on the expensive chunk problem has investigated how to produce cheaper rules <ref> [12, 5, 8, 13, 7] </ref> and how to filter out expensive rules [5, 14, 15, 16]. However, none of these approaches can generally guarantee that the cost of using the learned rules will always be bounded by the cost of the problem solving episode from which they are learned.
Reference: [13] <author> Jude W. Shavlik. </author> <title> Aquiring recursive and iterative concepts with explanation-based learning. </title> <journal> Machine Learning, </journal> <volume> 5 </volume> <pages> 39-70, </pages> <year> 1990. </year>
Reference-contexts: In this article we focus on the expensive chunk problem. Previous work on the expensive chunk problem has investigated how to produce cheaper rules <ref> [12, 5, 8, 13, 7] </ref> and how to filter out expensive rules [5, 14, 15, 16]. However, none of these approaches can generally guarantee that the cost of using the learned rules will always be bounded by the cost of the problem solving episode from which they are learned.
Reference: [14] <author> R. Greiner and I. Jurisica. </author> <title> A statistical approach to solving the EBL utility problem. </title> <booktitle> In Proceedings of the Tenth National Conference on Artificial Intelligence, </booktitle> <pages> pages 241-248, </pages> <year> 1992. </year>
Reference-contexts: In this article we focus on the expensive chunk problem. Previous work on the expensive chunk problem has investigated how to produce cheaper rules [12, 5, 8, 13, 7] and how to filter out expensive rules <ref> [5, 14, 15, 16] </ref>. However, none of these approaches can generally guarantee that the cost of using the learned rules will always be bounded by the cost of the problem solving episode from which they are learned.
Reference: [15] <author> J. Gratch and G. Dejong. COMPOSER: </author> <title> A probabilistic solution to the utility problem in speed-up learning. </title> <booktitle> In Proceedings of the Tenth National Conference on Aritificial Intelligence, </booktitle> <pages> pages 235-240, </pages> <year> 1992. </year> <month> 14 </month>
Reference-contexts: In this article we focus on the expensive chunk problem. Previous work on the expensive chunk problem has investigated how to produce cheaper rules [12, 5, 8, 13, 7] and how to filter out expensive rules <ref> [5, 14, 15, 16] </ref>. However, none of these approaches can generally guarantee that the cost of using the learned rules will always be bounded by the cost of the problem solving episode from which they are learned.
Reference: [16] <author> S. Markovitch and P. D. Scott. </author> <title> Information filtering : Selection mechanism in learning systems. </title> <journal> Machine Learning, </journal> <volume> 10(2) </volume> <pages> 113-151, </pages> <year> 1993. </year>
Reference-contexts: In this article we focus on the expensive chunk problem. Previous work on the expensive chunk problem has investigated how to produce cheaper rules [12, 5, 8, 13, 7] and how to filter out expensive rules <ref> [5, 14, 15, 16] </ref>. However, none of these approaches can generally guarantee that the cost of using the learned rules will always be bounded by the cost of the problem solving episode from which they are learned.
Reference: [17] <author> J. Kim and P. S. Rosenbloom. </author> <title> Constraining learning with search control. </title> <booktitle> In Proceedings of the Tenth International Conference on Machine Learning, </booktitle> <pages> pages 174-181, </pages> <year> 1993. </year>
Reference-contexts: Prior work on this topic has examined one such difference: in chunking (and other EBL systems which use search control in problem solving), eliminating search control in learning can increase the cost of the learned rules <ref> [17] </ref>. For example, PRODIGY/EBL [18] and Soar [3, 4] | two problem solvers that learn rules by variants of EBL | ignore many of the search-control rules during learning in order to increase the generality of the learned rules. <p> This problem was solved in <ref> [17] </ref> by extending the explanation to include the search-control rules used 1 EBL can also be used to acquire other types of structures, such as macro-operators, but we focus on search-control rules here. 2 Chunk means any learned rule. <p> In this context, <ref> [17] </ref> examined an approach that is based on incorporating search-control knowledge into the learned rule. That analysis showed that omitting search control in learning (i.e., in the explanation) can increase the cost of learned rules. <p> The consequence of this omission is that the learned rules are not constrained by the path actually taken in the problem space, and thus can perform an exponential amount of search even when the original problem-space search was highly directed (by the control rules). <ref> [17] </ref> extended the explanation to include search-control rules, thus creating more constrained rules. <p> This change can increase the number of tokens. 2. Loss of sharing: By losing sharing that existed in the problem-solving structure, the number of tokens can increase. 6 The results presented in <ref> [17] </ref> are based on chunking in Soar, not Soar/EBL. Because chunking's rule generalization is based on the explanation (instead of the explanation structure and regression), it can create overspecialized rules. The overspecialization of the rules can avoid part of this problem. 12 3.
Reference: [18] <author> S. Minton. </author> <type> Personal communication. </type> <year> 1993. </year>
Reference-contexts: Prior work on this topic has examined one such difference: in chunking (and other EBL systems which use search control in problem solving), eliminating search control in learning can increase the cost of the learned rules [17]. For example, PRODIGY/EBL <ref> [18] </ref> and Soar [3, 4] | two problem solvers that learn rules by variants of EBL | ignore many of the search-control rules during learning in order to increase the generality of the learned rules.
Reference: [19] <author> J. Kim and P.S. Rosenbloom. </author> <title> Mapping explanation-based learning onto Soar: The sequel. Technical Report :Transformation analyses of learning in SOAR. </title> <institution> ISI/RR-95-4221, Information Science Institute and Computer Science Department University of Southern California, </institution> <year> 1995. </year>
Reference-contexts: If instead, the learning mechanism is made sensitive to the problem-solving structure | i.e., by reflecting such hierarchical structure in the match of the learned rule | this source of expensiveness can be avoided. The focus of the analysis in this paper is Soar/EBL <ref> [19] </ref>. Although our prior work is based on chunking [20] in Soar, we analyze an implementation of EBL in Soar here to be able to more easily generalize the resulting analysis to other EBL systems. Soar/EBL is a little different from the standard version of Soar with chunking.
Reference: [20] <author> J. E. Laird, P. S. Rosenbloom, and A. Newell. </author> <title> Chunking in Soar: The anatomy of a general learning mechanism. </title> <journal> Machine Learning, </journal> <volume> 1, </volume> <year> 1985. </year>
Reference-contexts: The focus of the analysis in this paper is Soar/EBL [19]. Although our prior work is based on chunking <ref> [20] </ref> in Soar, we analyze an implementation of EBL in Soar here to be able to more easily generalize the resulting analysis to other EBL systems. Soar/EBL is a little different from the standard version of Soar with chunking.
Reference: [21] <author> C. L. Forgy. </author> <title> Rete: A fast algorithm for the many pattern/many object pattern match problem. </title> <journal> Artificial Intelligence, </journal> <volume> 19(1) </volume> <pages> 17-37, </pages> <year> 1982. </year>
Reference-contexts: Section 2 of this article briefly reviews Soar/EBL and the Rete match algorithm <ref> [21] </ref> used in Soar/EBL. The match algorithm is critical in computing both the cost of problem solving and the cost of matching learned rules. Section 3 then describes and analyzes the difference between the match structure which reflects the problem-solving structure, and the simplified match structure which ignores the structure.
Reference: [22] <author> R. J. Mooney and S. W. Bennett. </author> <title> A domain independent explanaion-based generalization. </title> <booktitle> In Proceedings of the Fifth National Conference on Artificial Intelligence, </booktitle> <pages> pages 551-555, </pages> <year> 1986. </year>
Reference-contexts: The instantiations in the explanation are replaced by rules which have unique names for the variables across the rules. This new structure is called the explanation structure. A regression algorithm (our algorithm is inspired by the EGGS generalization algorithm <ref> [22] </ref>) is applied to this explanation structure. A set of substitutions is computed by unifying each connected action-condition pair, and the substitutions are then applied to the variables in the explanation structure. The operational conditions become the conditions of the new rule.
Reference: [23] <author> P. Nayak, A. Gupta, and P. S. Rosenbloom. </author> <title> Comparison of the Rete and Treat production matchers for Soar (a summary). </title> <booktitle> In Proceedings of the Seventh National Conference on Artificial Intelligence, </booktitle> <pages> pages 693-698, </pages> <year> 1988. </year>
Reference-contexts: However, we will not explicitly focus on this factor here because it drops out in the learning process. 4 ordered by a heuristic algorithm before the rule is compiled. Rete is one of the most efficient rule-match algorithms presently known <ref> [23] </ref>. Its efficiency stems primarily from two key optimizations: sharing and state saving. Sharing of common conditions in a production, or across a set of productions, reduces the number of tests performed during match. State saving preserves the previous (partial) matches for use in the future.
Reference: [24] <author> M. Tambe, D. Kalp, A. Gupta, C. L. Forgy, B. G. Milnes, and A. Newell. Soar/PSM-E: </author> <title> Investigating match parallelism in a learning production system. </title> <booktitle> In Proceedings of the ACM/SIGPLAN Symposium on Parallel Programming: Experience with applications, languages, and systems, </booktitle> <pages> pages 146-160, </pages> <year> 1988. </year>
Reference-contexts: Beta memories store partial instantiations of productions; that is, instantiations of initial subsequences of conditions. The partial instantiations are called tokens. Because match time per token is known to be approximately constant in Rete <ref> [24, 6] </ref> | and because counting tokens yields a measure that is independent of machines, optimizations, and implementation details | we will follow the standard practice established within the match-algorithm community and use the number of tokens as a comparative measure of match cost in addition to time. 3 A Source
Reference: [25] <author> B. Doorenbos. </author> <note> Soar6 release notes. </note> <year> 1992. </year>
Reference-contexts: Also, 9 we have introduced decision sub-nodes into Rete. We have applied the resulting experimental system to the Grid task [6] (Figure 8), which is one of the known expensive-chunk tasks. The results shown here are all from Soar6 (version 6.0.4), a C-based release of Soar <ref> [25] </ref> on a Sun SPARCstation-20. Each problem in the Grid task is to find a path between two points in a two dimensional grid. For example, finding a path from point F to point O is a Grid task.
Reference: [26] <author> D. P. Miranker. </author> <title> Treat: A better match algorithm for AI production systems. </title> <booktitle> In Proceedings of the Sixth National Conference on Artificial Intelligence, </booktitle> <pages> pages 42-47, </pages> <year> 1987. </year>
Reference-contexts: Avoiding those identified sources should lead to relative boundedness in the match. (Time after learning would be bounded by time before learning.) Match algorithms are critical in computing both the cost of problem solving and the cost of matching learned rules. Rete and Treat <ref> [26] </ref> are the best known rule match algorithms. We performed an analysis based on Rete. We conjecture that EBL with Treat might suffer similar problems because a Treat network doesn't have hierarchical structure; however, we have not yet done the analysis.
Reference: [27] <author> D. J. </author> <title> Scales. Efficient matching algorithms for the Soar/Ops5 production system. </title> <type> Technical Report KSL-86-47, </type> <institution> Knowledge Systems Laboratory, Department of Computer Science, Stanford University, </institution> <year> 1986. </year>
Reference-contexts: We performed an analysis based on Rete. We conjecture that EBL with Treat might suffer similar problems because a Treat network doesn't have hierarchical structure; however, we have not yet done the analysis. There has been prior work done on nonlinear match to improve sharing <ref> [27, 28, 29, 30] </ref>. Although this work was not based on learning a new rule from problem solving, the work shares the same idea: improve the match performance by nonlinearity. One essential issue in this work is finding a general criterion for determining which form of nonlinearity is best.
Reference: [28] <author> M. Tambe, D. Kalp, and P. S. Rosenbloom. Uni-Rete: </author> <title> Specializing the Rete match algorithm for the unique-attribute representation. </title> <type> Technical Report CMU-CS-91-180, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <year> 1991. </year>
Reference-contexts: We performed an analysis based on Rete. We conjecture that EBL with Treat might suffer similar problems because a Treat network doesn't have hierarchical structure; however, we have not yet done the analysis. There has been prior work done on nonlinear match to improve sharing <ref> [27, 28, 29, 30] </ref>. Although this work was not based on learning a new rule from problem solving, the work shares the same idea: improve the match performance by nonlinearity. One essential issue in this work is finding a general criterion for determining which form of nonlinearity is best.
Reference: [29] <author> H. S. Lee and M. I. Schor. </author> <title> Match algorithms for generalized Rete networks. </title> <journal> Artificial Intelligence, </journal> <volume> 54 </volume> <pages> 249-274, </pages> <year> 1992. </year>
Reference-contexts: We performed an analysis based on Rete. We conjecture that EBL with Treat might suffer similar problems because a Treat network doesn't have hierarchical structure; however, we have not yet done the analysis. There has been prior work done on nonlinear match to improve sharing <ref> [27, 28, 29, 30] </ref>. Although this work was not based on learning a new rule from problem solving, the work shares the same idea: improve the match performance by nonlinearity. One essential issue in this work is finding a general criterion for determining which form of nonlinearity is best.
Reference: [30] <author> E. N. Hanson and M. S. Hasan. Gator: </author> <title> An optimized discrimination network for active database rule condition testing. </title> <type> Technical Report TR-93-036, </type> <institution> CIS Department, University of Florida, </institution> <year> 1993. </year> <month> 15 </month>
Reference-contexts: We performed an analysis based on Rete. We conjecture that EBL with Treat might suffer similar problems because a Treat network doesn't have hierarchical structure; however, we have not yet done the analysis. There has been prior work done on nonlinear match to improve sharing <ref> [27, 28, 29, 30] </ref>. Although this work was not based on learning a new rule from problem solving, the work shares the same idea: improve the match performance by nonlinearity. One essential issue in this work is finding a general criterion for determining which form of nonlinearity is best.
References-found: 30

