URL: ftp://cns.brown.edu/nin/papers/kurt.ps.Z
Refering-URL: http://www.math.tau.ac.il/~nin/research.html
Root-URL: 
Email: fbblais,nin,hzs,lncg@cns.brown.edu  
Title: Receptive field formation in natural scene environments: comparison of single cell learning rules  
Author: Brian S. Blais N. Intrator H. Shouval Leon N Cooper 
Date: July 24, 1997  
Address: Providence, RI 02912  
Affiliation: Brown University Physics Department and Institute for Brain and Neural Systems Brown University  
Abstract: We study several statistically and biologically motivated learning rules using the same visual environment and neuronal architecture. This allows us to concentrate on the feature extraction and neuronal coding properties of these rules. Included in these rules are kurtosis and skew maximization, the quadratic form of the BCM learning rule, and single cell ICA. We find that the quadratic form of the BCM rule behaves in a manner similar to a kurtosis maximization rule when the distribution contains kurtotic directions, although the BCM modification equations are computationally simpler.
Abstract-found: 1
Intro-found: 1
Reference: <author> Bell, A. J. and Sejnowski, T. J. </author> <year> (1995). </year> <title> An information-maximisation approach to blind separation and blind deconvolution. </title> <journal> Neural Computation, </journal> <volume> 7(6) </volume> <pages> 1129-1159. </pages>
Reference: <author> Bell, A. J. and Sejnowski, T. J. </author> <year> (1997). </year> <title> The independent components of natural scenes are edge filters. Vision Research. </title> <publisher> in press. </publisher>
Reference-contexts: different form of stabilization, and therefore cannot be so easily identified as BCM-like, but they do share many of the general properties of BCM modification. 4 Independent Components and Receptive Fields Recently it has been claimed that the independent components of natural scenes are the edges found in simple cells <ref> (Bell and Sejnowski, 1997) </ref>. This was achieved through the maximization of the mutual entropy of a set of mixed signals. Others (Hyvarinen and Oja, 1997) have claimed that maximizing kurtosis, with the proper constraints, can also lead to the separation of mixed signals into independent components.
Reference: <author> Bienenstock, E. L., Cooper, L. N., and Munro, P. W. </author> <year> (1982). </year> <title> Theory for the development of neuron selectivity: orientation specificity and binocular interaction in visual cortex. </title> <journal> Journal Neuroscience, </journal> <volume> 2 </volume> <pages> 32-48. </pages>
Reference-contexts: The details of these rules are different as well as their computational reasoning, however they are all characterized by learning rules that depend on statistics of order higher than second order and they all produce sparse distributions. BCM synaptic modification functions <ref> (Bienenstock et al., 1982) </ref> are characterized by a negative region for small post-synaptic depolarization, a positive region for large post-synaptic depolarization, and a threshold which moves so as to stabilize the learning.
Reference: <author> Daugman, J. G. </author> <year> (1988). </year> <title> Complete discrete 2D Gabor transforms by neural networks for image analysis and compression. </title> <journal> IEEE Transactions on ASSP, </journal> <volume> 36 </volume> <pages> 1169-1179. </pages>
Reference: <author> Delfosse, N. and Loubaton, P. </author> <year> (1995). </year> <title> Adaptive blind separation of independent sources: a deflation approach. </title> <booktitle> Signal Processing, </booktitle> <volume> 45 </volume> <pages> 59-83. </pages>
Reference-contexts: 2 (m T As) = K 2 (z T s) = j=1 j K 2 (s j ) (4.13) The extremal points of Equation 4.13 with respect to z under the constraint E fi occur when one component z j of z is 1 and all the rest are zero <ref> (Delfosse and Loubaton, 1995) </ref>. In other words, finding the extremal points of kurtosis leads to projections where m d m T d = z T s equals, up to a sign, a single component s j of s.
Reference: <author> Diaconis, P. and Freedman, D. </author> <year> (1984). </year> <title> Asymptotics of graphical projection pursuit. </title> <journal> Annals of Statistics, </journal> <volume> 12 </volume> <pages> 793-815. </pages>
Reference: <author> Field, D. J. </author> <year> (1994). </year> <title> What is the goal of sensory coding. </title> <journal> Neural Computation, </journal> <volume> 6 </volume> <pages> 559-601. </pages>
Reference-contexts: It has further been argued that local linear transformations such as Gabor filters or center-surround produce exponential-tailed histogram (Ruderman, 1994). Reasons for that vary from the specific arrangements of the Fourier phases of fl On leave, School of Mathematical Sciences, Tel-Aviv University. 1 natural images <ref> (Field, 1994) </ref> or the existence of edges.
Reference: <author> Friedman, J. H. </author> <year> (1987). </year> <title> Exploratory projection pursuit. </title> <journal> Journal of the American Statistical Association, </journal> <volume> 82 </volume> <pages> 249-266. </pages>
Reference: <author> Friedman, J. H. and Tukey, J. W. </author> <year> (1974). </year> <title> A projection pursuit algorithm for exploratory data analysis. </title> <journal> IEEE Transactions on Computers, C(23):881-889. </journal>
Reference: <author> Huber, P. J. </author> <year> (1985). </year> <title> Projection pursuit. (with discussion). </title> <journal> The Annals of Statistics, </journal> <volume> 13 </volume> <pages> 435-475. </pages>
Reference-contexts: the assumption of positive and fixed average activity (Ruderman, 1994; Levy and Baxter, 1996; Intrator, 1996), it is a natural candidate for detailed study in conjunction with neuronal learning rules. 3 Exploratory projection pursuit and feature extraction Projection pursuit (PP) methods seek features which emphasize the non-Gaussian nature of distributions <ref> (Huber, 1985, for review) </ref>. Using a projection index (PI), they seek structure that is exhibited by (semi) linear projections of the data.
Reference: <author> Hyvarinen, A. and Oja, E. </author> <year> (1997). </year> <title> A fast fixed-point algorithm for independent component analysis. Neural Computation. </title> <note> To appear. </note>
Reference-contexts: This was achieved through the maximization of the mutual entropy of a set of mixed signals. Others <ref> (Hyvarinen and Oja, 1997) </ref> have claimed that maximizing kurtosis, with the proper constraints, can also lead to the separation of mixed signals into independent components. This alternate connection between kurtosis and receptive fields leads us into a discussion of ICA.
Reference: <author> Intrator, N. </author> <year> (1990). </year> <title> A neural network for feature extraction. </title> <editor> In Touretzky, D. S. and Lippmann, R. P., editors, </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> volume 2, </volume> <pages> pages 719-726. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA. </address>
Reference: <author> Intrator, N. </author> <year> (1996). </year> <title> Neuronal goals: Efficient coding and coincidence detection. </title> <editor> In Amari, S., Xu, L., Chan, L. W., King, I., and Leung, K. S., editors, </editor> <booktitle> Proceedings of ICONIP Hong Kong. Progress in Neural Information Processing, </booktitle> <volume> volume 1, </volume> <pages> pages 29-34. </pages> <publisher> Springer. </publisher>
Reference-contexts: This turns out to be an important property, since additional information can then be transmitted using the resulting norm of the weight vector m <ref> (Intrator, 1996) </ref>. It is important to note that the Quadratic BCM rule is only one of many possible forms for BCM modification. In fact, both skewness measures clearly follow the same criteria initially proposed by BCM and thus can be seen as statistically motivated variants of BCM.
Reference: <author> Intrator, N. and Cooper, L. N. </author> <year> (1992). </year> <title> Objective function formulation of the BCM theory of visual cortical plasticity: Statistical connections, stability conditions. </title> <booktitle> Neural Networks, </booktitle> <volume> 5 </volume> <pages> 3-17. </pages>
Reference-contexts: Several of these, such as skewness and kurtosis, are standard statistical measures (Kendall and Stuart, 1977) based on polynomial moments. We compare these with the quadratic form of BCM <ref> (Intrator and Cooper, 1992) </ref>. <p> The multiplicative forms of both kurtosis and skewness do not require an extra stabilization constraint, due to the normalizing factor 1=fi M p in each rule. Quadratic BCM The Quadratic BCM (QBCM) measure as given in <ref> (Intrator and Cooper, 1992) </ref> is of the form QBCM = 1 E [c 3 ] 4 3 Maximizing this form using gradient ascent gives the learning rule: rQBCM = E fi fl Unlike the measures S 2 and K 2 above, the Quadratic BCM rule does not require any additional stabilization.
Reference: <author> Jones, M. C. and Sibson, R. </author> <year> (1987). </year> <title> What is projection pursuit? (with discussion). </title> <journal> J. Roy. Statist. Soc., Ser. A(150):1-36. </journal>
Reference-contexts: In particular it holds for the kurtosis projection index, since a linear mixture will be less kurtotic than its original components. As the general information-theoretic measure of deviation from Gaussian distribution negative entropy - can be approximated by skewness and kurtosis <ref> (Jones and Sibson, 1987) </ref> it becomes relevant to study the ability of these two measures to extract relevant information from high-dimensional data, in particular from natural scenes. A difference between different measures would appear when the original signals are not independent as is likely in the case of natural scenes.
Reference: <author> Kendall, M. and Stuart, A. </author> <year> (1977). </year> <journal> The Advanced Theory of Statistics, </journal> <volume> volume 1. </volume> <publisher> MacMillan Publishing, </publisher> <address> New York. </address> <note> 10 Law, </note> <author> C. and Cooper, L. </author> <year> (1994). </year> <title> Formation of receptive fields according to the BCM theory in realistic visual environments. </title> <booktitle> Proceedings National Academy of Sciences, </booktitle> <volume> 91 </volume> <pages> 7797-7801. </pages>
Reference-contexts: In what follows we investigate several specific modification functions that have these general properties and study their feature extraction properties in a natural scene environment. Several of these, such as skewness and kurtosis, are standard statistical measures <ref> (Kendall and Stuart, 1977) </ref> based on polynomial moments. We compare these with the quadratic form of BCM (Intrator and Cooper, 1992). <p> We also demonstrate later that the rectification makes little difference on learning rules that depend on even moments. 2 We study the following measures: Skewness 1 This measures the deviation from symmetry <ref> (Kendall and Stuart, 1977, for review) </ref> and is of the form: S 1 = E [c 3 ]=E 1:5 [c 2 ]: (3.1) A maximization of this measure via gradient ascent gives rS 1 = fi M fi fl 1 1:5 E c c E [c 3 ]=fi M 0 d
Reference: <author> Levy, W. B. and Baxter, R. A. </author> <year> (1996). </year> <title> Energy efficient neural codes. </title> <journal> Neural Computation, </journal> <volume> 8 </volume> <pages> 531-543. </pages>
Reference: <author> Oja, E. </author> <year> (1995). </year> <title> The nonlinear pca learning rule and signal separation mathematical analysis. </title> <type> Technical Report A26, </type> <institution> Helsinki University, CS and Inf. Sci. Lab. </institution>
Reference: <author> Olshausen, B. A. and Field, D. J. </author> <year> (1996). </year> <title> Emergence of simple cell receptive field properties by learning a sparse code for natural images. </title> <journal> Nature, </journal> <volume> 381 </volume> <pages> 607-609. </pages>
Reference: <author> Press, W. and Lee, C. W. </author> <year> (1996). </year> <title> Searching for optimal visual codes: Projection pursuit analysis of the statistical structure in natural scenes. </title> <booktitle> In The Neurobiology of Computation: Proceedings of the fifth annual Computation and Neural Systems conference. </booktitle> <publisher> Plenum Publishing Corporation. </publisher>
Reference-contexts: For a related study discussing projection pursuit and BCM see <ref> (Press and Lee, 1996) </ref>. We have used natural scenes to gain some more insight about the statistics underlying natural images. There are several outcomes from this study: * All rules used found kurtotic distributions.
Reference: <author> Ruderman, D. L. </author> <year> (1994). </year> <title> The statistics of natural images. </title> <journal> Network, </journal> <volume> 5(4) </volume> <pages> 517-548. </pages>
Reference-contexts: It has further been argued that local linear transformations such as Gabor filters or center-surround produce exponential-tailed histogram <ref> (Ruderman, 1994) </ref>. Reasons for that vary from the specific arrangements of the Fourier phases of fl On leave, School of Mathematical Sciences, Tel-Aviv University. 1 natural images (Field, 1994) or the existence of edges. <p> There are several outcomes from this study: * All rules used found kurtotic distributions. This should not come as a surprise as there are suggestions that a large family of linear filters can find kurtotic distributions <ref> (Ruderman, 1994) </ref>. * The single cell ICA rule we considered, used the subtractive form of kurtosis as a measure for deviation from Gaussian distributions, achieved receptive fields qualitatively similar to other rules discussed. * The Quadratic BCM and the multiplicative version of kurtosis are less sensitive to the second moments of
Reference: <author> Shouval, H. and Liu, Y. </author> <year> (1996). </year> <title> Principal component neurons in a realistic visual environment. </title> <journal> Network, </journal> <volume> 7(3) </volume> <pages> 501-515. 11 </pages>
Reference-contexts: Every learning rule developed oriented receptive fields, though some were more sensitive to the preprocessing than others. This behavior, as well as the resemblance of the receptive fields to those obtained from PCA <ref> (Shouval and Liu, 1996) </ref>, suggest that these measures have a strong dependence on the second moment. The multiplicative versions of kurtosis and skew, as well as Quadratic BCM, sampled from many orientations regardless of the preprocessing suggesting that they did not have as strong a dependence on second order statistics.
References-found: 22

