URL: ftp://whitechapel.media.mit.edu/pub/tech-reports/TR-465.ps.Z
Refering-URL: http://www-white.media.mit.edu/cgi-bin/tr_pagemaker/
Root-URL: http://www.media.mit.edu
Email: ftestarne,bernt,sandyg@media.mit.edu  
Title: Visual Contextual Awareness in Wearable Computing  
Author: Thad Starner, Bernt Schiele, and Alex Pentland 
Address: Cambridge, MA 02139  
Affiliation: Media Laboratory, Massachusetts Institute of Technology  
Abstract: M.I.T Media Laboratory Perceptual Computing Section Technical Report No. 465 To appear IEEE ISWC '98 Abstract Small, body-mounted video cameras enable a different style of wearable computing interface. As processing power increases, a wearable computer can spend more time observing its user to provide serendipitous information, manage interruptions and tasks, and predict future needs without being directly commanded by the user. This paper introduces an assistant for playing the real-space game Patrol. This assistant tracks the wearer's location and current task through computer vision techniques and without off-body infrastructure. In addition, this paper continues augmented reality research, started in 1995, for binding virtual data to physical locations. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Feiner, B. MacIntyre, and D. Seligmann. </author> <title> Knowledge-based augmented reality. </title> <journal> Communications of the ACM, </journal> <volume> 36(7) </volume> <pages> 52-62, </pages> <year> 1993. </year>
Reference-contexts: all these techniques could be applied to create an automatic map of a new building as the Patrol player explored it. 3.3 User Tasks By identifying the user's current task, the computer can assist actively in that task by displaying timely information or automatically reserving resources that may be needed <ref> [1, 16, 19] </ref>. However, a wearable computer might also take a more passive role, simply determining the importance of potential interruptions (phone, e-mail, paging, etc.) and presenting the interruption in the most socially graceful manner possible.
Reference: [2] <author> X. Huang, Y. Ariki, and M. A. Jack. </author> <title> Hidden Markov Models for Speech Recognition. </title> <publisher> Edinburgh University Press, </publisher> <year> 1990. </year>
Reference-contexts: Prior knowledge about the mean time spent in each area may also be used to weight the probability of a given hypothesis. HMM's fully exploit these attributes. A full review of HMM's is not appropriate here, but the reader should see <ref> [17, 2, 11] </ref> for HMM implementation details and tutorials. As a first attempt, the mean colors of three video patches are used to construct a feature vector in real-time. One patch is taken from approximately the center of the image of the forward looking camera.
Reference: [3] <author> T. Jebara, B. Schiele, N. Oliver, and A. Pentland. Dypers: </author> <title> dynamic and personal enhanced reality system. Number 463, </title> <year> 1998. </year>
Reference-contexts: Using this strategy, the user is not overwhelmed upon walking into a room but can explore interesting objects at leisure. This idea continues to develop. The DyPERS system <ref> [3] </ref> demonstrates how visual tags become unnecessary when a more sophisticated object recognition system (similar to what is used in a later section for gesture tracking) is employed.
Reference: [4] <author> M. Lamming and M. Flynn. Forget-me-not: </author> <booktitle> Inti mate computing in support of human memory. In FRIEND21: Inter. Symp. on Next Generation Human Interface, </booktitle> <pages> pages 125-128, </pages> <address> Meguro Gajoen, Japan, </address> <year> 1994. </year>
Reference-contexts: Today, most outdoor positioning is performed in relation to the Global Positioning System (GPS). Differential systems can obtain accuracies of less than one meter, and update rates of one second are common. However, indoor systems require different methods. Current systems such as active badges <ref> [21, 15, 4, 10] </ref> and beacon architectures [6, 14, 18] require increased infrastructure for higher accuracy. This increased infrastructure implies increased installation and maintenance. However, in the Patrol task, we attempt to determine location based solely on the images provided by the Patrol hat cameras, which are fixed-cost on-body equipment.
Reference: [5] <author> J. Levine. </author> <title> Real-time target and pose recognition for 3-d graphical overlay. </title> <type> Master's thesis, </type> <institution> MIT, EECS, </institution> <month> May </month> <year> 1997. </year>
Reference-contexts: In the past, the MIT Wearable Computing Project has used computer vision identification to create a physically-based hypertext demonstration platform <ref> [19, 5] </ref> as shown in Figure 1. While this system uses the processing power of an SGI, it maintains the feel of a wearable computer by sending video to and from the SGI and head-mount wirelessly. In this system, visual "tags" uniquely identify each active object.
Reference: [6] <author> S. Long, R. Kooper, G. Abowd, and C. Atkeson. </author> <title> Rapid prototyping of mobile context-aware applications: The cyberguide case study. In MobiCom. </title> <publisher> ACM Press, </publisher> <year> 1996. </year>
Reference-contexts: Differential systems can obtain accuracies of less than one meter, and update rates of one second are common. However, indoor systems require different methods. Current systems such as active badges [21, 15, 4, 10] and beacon architectures <ref> [6, 14, 18] </ref> require increased infrastructure for higher accuracy. This increased infrastructure implies increased installation and maintenance. However, in the Patrol task, we attempt to determine location based solely on the images provided by the Patrol hat cameras, which are fixed-cost on-body equipment.
Reference: [7] <author> S. Mann. Smart clothing: </author> <title> The wearable computer and wearcam. </title> <type> Personal Technologies, </type> <month> March </month> <year> 1997. </year> <note> Volume 1, Issue 1. </note>
Reference-contexts: Once an object is uniquely labeled, the user's wearable computer can note its presence or assign virtual properties to the object. Hypertext links, annotations, or Java-defined behaviors can be assigned to the object based on its physical location <ref> [19, 7, 8] </ref>. This form of ubiquitous computing [22] concentrates infrastructure mainly on the wearer as opposed to the environment, reducing costs and maintenance, and avoiding some privacy issues. Objects can be identified in a number of different ways.
Reference: [8] <author> K. Nagao and J. Rekimoto. </author> <title> Ubiquitous talker: Spoken language interaction with real world objects. </title> <booktitle> In Proc. of Inter. Joint Conf. on Artifical Intelligence (IJCAI), </booktitle> <pages> pages 1284-1290, </pages> <address> Montreal, </address> <year> 1995. </year>
Reference-contexts: Once an object is uniquely labeled, the user's wearable computer can note its presence or assign virtual properties to the object. Hypertext links, annotations, or Java-defined behaviors can be assigned to the object based on its physical location <ref> [19, 7, 8] </ref>. This form of ubiquitous computing [22] concentrates infrastructure mainly on the wearer as opposed to the environment, reducing costs and maintenance, and avoiding some privacy issues. Objects can be identified in a number of different ways. <p> In this system, visual "tags" uniquely identify each active object. These tags consist of two red squares bounding a pattern of green squares representing a binary number unique to that room. A similar identification system has been demonstrated by Nagao and Rekimoto <ref> [8] </ref> for a tethered, hand-held system. These visual patterns are robust in the presence of similar background colors and can be distinguished from each other in the same visual field.
Reference: [9] <author> J. Orwant. </author> <title> Doppelganger goes to school: Machine learning for user modeling. </title> <type> Master's thesis, </type> <institution> MIT, Media Laboratory, </institution> <month> September </month> <year> 1993. </year>
Reference-contexts: By gathering data over many days, the user's motions throughout the day might be modeled. This model may then be used to predict when the user will be in a certain location and for how long <ref> [9] </ref>. Such information is invaluable for network caching in case the user's wireless network does not provide coverage everywhere on a campus. Today, most outdoor positioning is performed in relation to the Global Positioning System (GPS).
Reference: [10] <author> J. Orwant. </author> <title> For want of a bit the user was lost: Cheap user modeling. </title> <journal> IBM Systems Journal, </journal> <volume> 35(3), </volume> <year> 1996. </year>
Reference-contexts: Today, most outdoor positioning is performed in relation to the Global Positioning System (GPS). Differential systems can obtain accuracies of less than one meter, and update rates of one second are common. However, indoor systems require different methods. Current systems such as active badges <ref> [21, 15, 4, 10] </ref> and beacon architectures [6, 14, 18] require increased infrastructure for higher accuracy. This increased infrastructure implies increased installation and maintenance. However, in the Patrol task, we attempt to determine location based solely on the images provided by the Patrol hat cameras, which are fixed-cost on-body equipment.
Reference: [11] <author> L. Rabiner. </author> <title> A tutorial on hidden markov models and selected applications in speech recognition. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 77(2) </volume> <pages> 257-286, </pages> <month> Feb </month> <year> 1989. </year>
Reference-contexts: Prior knowledge about the mean time spent in each area may also be used to weight the probability of a given hypothesis. HMM's fully exploit these attributes. A full review of HMM's is not appropriate here, but the reader should see <ref> [17, 2, 11] </ref> for HMM implementation details and tutorials. As a first attempt, the mean colors of three video patches are used to construct a feature vector in real-time. One patch is taken from approximately the center of the image of the forward looking camera.
Reference: [12] <author> B. Schiele. </author> <title> Object Recognition using Multidimen sional Receptive Field Histograms. </title> <type> PhD thesis, </type> <institution> I.N.P.Grenoble, </institution> <month> July </month> <year> 1997. </year> <note> English translation. </note>
Reference-contexts: By feeding the calculated probabilities as feature vectors to a set of hidden Markov models (HMM's), it is possible to recognize different user tasks such as aiming and reloading. Preliminary results are described in the next section. 3.4 Probabilistic Image Patch Recognition Schiele and Crowley <ref> [13, 12] </ref> presented a technique to determine the identity of an object in a scene using multidimensional histograms of responses of vectors of local neighborhood operators. They showed that matching such histograms can be used to determine the most probable object, independent of its position, scale and image-plane rotation. <p> The system runs at approximately 10Hz on a Silicon Graphics machine O2 using the OpenGL extension for real-time image convolution. Local Characteristics based on Gaussian Derivatives: Multidimensional receptive field histograms can be constructed using a vector of any linear filter. Schiele <ref> [12] </ref> experimentally compares the invariant properties for a number of receptive field functions, including Ga-bor filter and local derivative operators. Those experiments showed that Gaussian derivatives provided the most robust and equi-variant recognition results.
Reference: [13] <author> B. Schiele and J. Crowley. </author> <title> Recognition wothout cor respondence using multidimensional receptive field his tograms. </title> <type> Technical Report 453, </type> <institution> M.I.T. Media Labora tory, Perceptual Computing Section, </institution> <month> December </month> <year> 1997. </year>
Reference-contexts: In this section we describe a computer vision system for the recognition of such user tasks. The system is based on a generic object recognition system recently proposed by Schiele and Crowley <ref> [13] </ref>. A major result of their work is that a statistical representation based on local object descriptors provides a reliable means for the representation and recognition of object appearances. <p> By feeding the calculated probabilities as feature vectors to a set of hidden Markov models (HMM's), it is possible to recognize different user tasks such as aiming and reloading. Preliminary results are described in the next section. 3.4 Probabilistic Image Patch Recognition Schiele and Crowley <ref> [13, 12] </ref> presented a technique to determine the identity of an object in a scene using multidimensional histograms of responses of vectors of local neighborhood operators. They showed that matching such histograms can be used to determine the most probable object, independent of its position, scale and image-plane rotation. <p> They showed that matching such histograms can be used to determine the most probable object, independent of its position, scale and image-plane rotation. Furthermore, they showed the robustness of the approach to changes in viewpoint. This technique has been extended to probabilistic object recognition <ref> [13] </ref> in order to determine the probability of each object in an image based only on multidimensional receptive field histograms. Experiments showed that only a relatively small portion of the image (between 15% and 30%) is needed in order to recognize 100 objects correctly.
Reference: [14] <author> W. Schilit. </author> <title> System architecture for context-aware mo bile computing. </title> <type> PhD thesis, </type> <institution> Columbia University, </institution> <year> 1995. </year>
Reference-contexts: Differential systems can obtain accuracies of less than one meter, and update rates of one second are common. However, indoor systems require different methods. Current systems such as active badges [21, 15, 4, 10] and beacon architectures <ref> [6, 14, 18] </ref> require increased infrastructure for higher accuracy. This increased infrastructure implies increased installation and maintenance. However, in the Patrol task, we attempt to determine location based solely on the images provided by the Patrol hat cameras, which are fixed-cost on-body equipment.
Reference: [15] <author> C. Schmandt. </author> <title> Voice Communication with Computers. </title> <publisher> Van Nostrand Reinhold, </publisher> <address> New York, </address> <year> 1994. </year>
Reference-contexts: Today, most outdoor positioning is performed in relation to the Global Positioning System (GPS). Differential systems can obtain accuracies of less than one meter, and update rates of one second are common. However, indoor systems require different methods. Current systems such as active badges <ref> [21, 15, 4, 10] </ref> and beacon architectures [6, 14, 18] require increased infrastructure for higher accuracy. This increased infrastructure implies increased installation and maintenance. However, in the Patrol task, we attempt to determine location based solely on the images provided by the Patrol hat cameras, which are fixed-cost on-body equipment.
Reference: [16] <author> R. Sharma and J. Molineros. </author> <title> Computer vision-based augmented reality for guiding manual assembly. </title> <journal> Pres ence, </journal> <volume> 6(3), </volume> <year> 1997. </year>
Reference-contexts: all these techniques could be applied to create an automatic map of a new building as the Patrol player explored it. 3.3 User Tasks By identifying the user's current task, the computer can assist actively in that task by displaying timely information or automatically reserving resources that may be needed <ref> [1, 16, 19] </ref>. However, a wearable computer might also take a more passive role, simply determining the importance of potential interruptions (phone, e-mail, paging, etc.) and presenting the interruption in the most socially graceful manner possible.
Reference: [17] <author> T. Starner. </author> <title> Visual recognition of American Sign Lan guage using hidden Markov models. </title> <type> Master's thesis, </type> <institution> MIT, Media Laboratory, </institution> <month> February </month> <year> 1995. </year>
Reference-contexts: Prior knowledge about the mean time spent in each area may also be used to weight the probability of a given hypothesis. HMM's fully exploit these attributes. A full review of HMM's is not appropriate here, but the reader should see <ref> [17, 2, 11] </ref> for HMM implementation details and tutorials. As a first attempt, the mean colors of three video patches are used to construct a feature vector in real-time. One patch is taken from approximately the center of the image of the forward looking camera.
Reference: [18] <author> T. Starner, D. Kirsch, and S. Assefa. </author> <title> The locust swarm: An environmentally-powered, networkless location and messaging system. </title> <type> Technical Report 431, </type> <institution> MIT Media Lab, Perceptual Computing Group, </institution> <month> April </month> <year> 1997. </year> <note> Pre sented ISWC'97. </note>
Reference-contexts: This idea continues to develop. The DyPERS system [3] demonstrates how visual tags become unnecessary when a more sophisticated object recognition system (similar to what is used in a later section for gesture tracking) is employed. By determining user location and head orientation using the Locust indoor location system <ref> [18] </ref> and inertial sensors, strong priors can be established on which objects may be visible. A similar methodology may be used outside with GPS. <p> Differential systems can obtain accuracies of less than one meter, and update rates of one second are common. However, indoor systems require different methods. Current systems such as active badges [21, 15, 4, 10] and beacon architectures <ref> [6, 14, 18] </ref> require increased infrastructure for higher accuracy. This increased infrastructure implies increased installation and maintenance. However, in the Patrol task, we attempt to determine location based solely on the images provided by the Patrol hat cameras, which are fixed-cost on-body equipment.
Reference: [19] <author> T. Starner, S. Mann, B. Rhodes, J. Levine, J. Healey, D. Kirsch, R. Picard, and A. Pentland. </author> <title> Augmented re ality through wearable computing. Presence, </title> <address> 6(4):386 398, </address> <month> Winter </month> <year> 1997. </year>
Reference-contexts: Once an object is uniquely labeled, the user's wearable computer can note its presence or assign virtual properties to the object. Hypertext links, annotations, or Java-defined behaviors can be assigned to the object based on its physical location <ref> [19, 7, 8] </ref>. This form of ubiquitous computing [22] concentrates infrastructure mainly on the wearer as opposed to the environment, reducing costs and maintenance, and avoiding some privacy issues. Objects can be identified in a number of different ways. <p> In the past, the MIT Wearable Computing Project has used computer vision identification to create a physically-based hypertext demonstration platform <ref> [19, 5] </ref> as shown in Figure 1. While this system uses the processing power of an SGI, it maintains the feel of a wearable computer by sending video to and from the SGI and head-mount wirelessly. In this system, visual "tags" uniquely identify each active object. <p> all these techniques could be applied to create an automatic map of a new building as the Patrol player explored it. 3.3 User Tasks By identifying the user's current task, the computer can assist actively in that task by displaying timely information or automatically reserving resources that may be needed <ref> [1, 16, 19] </ref>. However, a wearable computer might also take a more passive role, simply determining the importance of potential interruptions (phone, e-mail, paging, etc.) and presenting the interruption in the most socially graceful manner possible.
Reference: [20] <author> T. Starner, J. Weaver, and A. Pentland. </author> <title> Real-time American Sign Language recognition using desk and wearable computer-based video. </title> <journal> IEEE Trans. Patt. Analy. and Mach. Intell., </journal> <note> To appear 1998. </note>
Reference-contexts: Others emphasize stealth, team play, or holding "territory." Originally, Patrol provided an entertaining way to test the robustness of wearable computing techniques and apparatus for other projects, such as hand tracking for the sign language recognizer <ref> [20] </ref>. However, it quickly became apparent that the gestures and actions in Patrol provided a relatively well defined language and goal structure in a very harsh "real-life" sensing environment. As such, Patrol became a context-sensing project within itself.
Reference: [21] <author> R. Want and A. Hopper. </author> <title> Active badges and personal interactive computing objects. </title> <journal> IEEE Trans. on Con sumer Electronics, </journal> <volume> 38(1) </volume> <pages> 10-20, </pages> <month> Feb. </month> <year> 1992. </year>
Reference-contexts: Today, most outdoor positioning is performed in relation to the Global Positioning System (GPS). Differential systems can obtain accuracies of less than one meter, and update rates of one second are common. However, indoor systems require different methods. Current systems such as active badges <ref> [21, 15, 4, 10] </ref> and beacon architectures [6, 14, 18] require increased infrastructure for higher accuracy. This increased infrastructure implies increased installation and maintenance. However, in the Patrol task, we attempt to determine location based solely on the images provided by the Patrol hat cameras, which are fixed-cost on-body equipment.
Reference: [22] <author> M. Weiser. </author> <title> The computer for the 21st century. </title> <journal> Scien tific American, </journal> <volume> 265(3) </volume> <pages> 94-104, </pages> <month> September </month> <year> 1991. </year>
Reference-contexts: Once an object is uniquely labeled, the user's wearable computer can note its presence or assign virtual properties to the object. Hypertext links, annotations, or Java-defined behaviors can be assigned to the object based on its physical location [19, 7, 8]. This form of ubiquitous computing <ref> [22] </ref> concentrates infrastructure mainly on the wearer as opposed to the environment, reducing costs and maintenance, and avoiding some privacy issues. Objects can be identified in a number of different ways.
Reference: [23] <author> S. Young. </author> <title> HTK: Hidden Markov Model Toolkit V1.5. </title> <institution> Cambridge Univ. Eng. Dept. Speech Group and En tropic Research Lab. Inc., </institution> <address> Washington DC, </address> <year> 1993. </year>
Reference-contexts: Whenever the player steps into a new area, the video frame number and area name are recorded. Both the data and the transcription are converted to Entropic's HTK <ref> [23] </ref> format for training and testing. For this experiment, 24.5 minutes of video, comprising 87 area transitions, are used for training the HMMs. As part of the training, a statistical (bigram) grammar is generated.
References-found: 23

