URL: http://www.math.ntnu.no/preprint/statistics/1998/S6-1998.ps
Refering-URL: http://www.stats.bris.ac.uk/MCMC/pages/list.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: EMAIL: havard.rue@math.ntnu.no  
Title: EXACT SIMULATION USING MARKOV CHAINS  
Author: MORTEN FISMEN 
Address: 7034 Trondheim, Norway.  
Affiliation: Department for Mathematical Sciences, The Norwegian University of Technology and Science,  
Note: ADDRESS FOR CORRESPONDENCE: Havard Rue,  
Date: DECEMBER 1997  
Abstract: This reports gives a review of the new exact simulation algorithms using Markov chains. The first part covers the discrete case. We consider two different algorithms, Propp and Wilsons coupling from the past (CFTP) technique and Fills rejection sampler. The algorithms are tested on the Ising model, with and without an external field. The second part covers continuous state spaces. We present several algorithms developed by Murdoch and Green, all based on coupling from the past. We discuss the applicability of these methods on a Bayesian analysis problem of surgical failure rates. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Stephen P. Brooks. </author> <title> Markov Chain Monte Carlo and its Application. </title> <note> Available at http://www.stats.bris.ac.uk/. </note>
Reference-contexts: should we iterate until the samples approximate with desired accuracy? And second, since the values in a Markov chain are dependent, how should we proceed if inference should be based on a number of independent samples? To decide the number of iterations various convergence tests have been proposed (see Brooks <ref> [1] </ref> for further references). Suppose we can determine a convergence rate or a bound on a such rate. <p> A lot of work has therefore been performed in the development of convergence diagnostics methods ( <ref> [1] </ref>). These methods uses eigenvalue estimation, plots of the sample paths, autocorrelation and quantiles and other techniques to a posteriori or during run time decide if the Markov chain has converged or not. But these methods all suffer from the possibility that the Markov chain reaches a metastable state.
Reference: [2] <author> J. A. Fill. </author> <title> An Interruptible Algorithm for Perfect Sampling via Markov Chains, </title> <year> 1997. </year>
Reference-contexts: The stationary distribution may be found by solving the equations (x) = y X (y) = 1 (5) Some Markov chains exhibits the property of monotonicity, which depends on the existence of a partial ordering of the state space S (see <ref> [2] </ref>). Suppose S has dimension n, such that x = (x 1 ; : : : ; x n ) for all x 2 S. <p> This is denoted EXACT or PERFECT SAMPLING, and their pioneer work has attracted considerable interest. Their idea is based on coupling, or coalescence, of Markov chains. Later Fill <ref> [2] </ref> has devised another perfect sampling algorithm based on rejection sampling. Additionally, both these methods return independent samples. 4.1 THE PROPP-WILSON ALGORITHM We now will introduce the algorithm of Propp and Wilson, which is based on an intuitive idea. <p> However, this will not yield a correct algorithm. To see this, consider Markov chains with states with a unique predecessor. If the above algorithm were run, we would obtain samples that were biased. EXAMPLE 4.1 This example is collected from <ref> [2] </ref>. Consider a Markov chain with state space S = f0,1g, with the following transition matrix 0 1 1 1.0 0.0 From state 0 the chain moves to 0 or 1 with probability 1/2 each, and from state 1 the chain moves deterministically to state 0. <p> If a simulation is interrupted if no output is received during a fixed number of iterations, then the samples will be biased in favour of configurations that take short time to generate. EXAMPLE 4.2 Fill <ref> [2] </ref> sketch an example of why interrupting the simulation leads to biased samples, and we give here the details. <p> To overcome this problem Fill <ref> [2] </ref> has devised an interruptible exact algorithm which gives both independent and unbiased samples, even if long runs are aborted. <p> observing ~ Y t = ^ 0 in fact is ~ P t (1; ^ 0)= ~ P t (z; ^ 0). 19 LEMMA 4.1 Prob ~ P t ^ 1; ^ 0 ~ P t z; ^ 0 PROOF: We fill in some of the details sketched in Fill <ref> [2] </ref>. Consider first the stochastic process n o = ( ~ X 0 ; ~ Y 0 ); ( ~ X 1 ; ~ Y 1 ); : : : . <p> Now Prob Prob Prob (34) Since ~ Y t = ^ 0 entails ~ X t = ^ 0, this equals Prob Prob = (35) as desired. 2 4.4 FILL'S ALGORITHM APPLIED TO THE ISING MODEL The implementation of Fill's method requires some more investigation, and Fill <ref> [2] </ref> describes how this may be done. <p> updating function (x; U 1 ; U 2 ) such that ~ P (x; x 0 ) = Prob ((x; U 1 ; U 2 ) = x 0 ). ~ Y gets a new y 0 value with probability K x;y (x 0 ; y 0 ), and Fill <ref> [2] </ref> suggest we may use K x;y (x 0 ; y 0 ) = Prob ((y; U 1 ; U 2 ) = y 0 j (x; U 1 ; U 2 ) = 20 x 0 ). <p> To prove this we show that this gives a correct distribution for ( ^ U 1 ; ^ U 2 ) (this proof is only mentioned in Fill <ref> [2] </ref>). Consider the case where U 0 1 = and U 0 1jx - ) such that x = x 0 with x - = 1.
Reference: [3] <author> S. G. Foss and R. L. Tweedie. </author> <title> Perfect simulation and backward coupling. to appear in Stochastic Models, </title> <year> 1997. </year>
Reference-contexts: Wilson at http://dimacs.rutgers.edu/dbwilson Together with the original paper [11] on coupling from the past Propp and Wilson have written a user's guide on perfect sampling and some papers on generating random spanning tree of a directed graph. Foss and Tweedie <ref> [3] </ref> place the coupling from the past algorithm in the context of stochastically recursive sequences. The also show that successful CFTP can be constructed if and only if the chain is uniformly geometric ergodic. Kendall [7] shows how to apply perfect sampling algorithms for simulation of point processes.
Reference: [4] <author> O. Haggstrom and K. Nelander. </author> <title> Exact sampling from anti-monotone systems. </title> <note> Available at http://dimacs.rutgers.edu/dbwilson, 1997. </note>
Reference-contexts: Considers also repulsive point processes, which are not monotone. Haggstrom, Lieshout and Mller [10] presents a faster algorithm than Kendall, applied to spatial point processes. Mller [8] also give a review of spatial point processes including perfect simulation. Haggstrom and Nelander <ref> [4] </ref> shows how to use coupling from the past on anti-monotone systems. Johnson [6] uses coupling in the study of convergence of Markov chains. 48 10 CONCLUSION This report gives a review of the basic ideas in the new methods of perfect sampling using Markov chains.
Reference: [5] <author> W. K. Hastings. </author> <title> Monte Carlo sampling methods using Markov chains and their applications. </title> <journal> Biometrika, </journal> <volume> 57 </volume> <pages> 97-109, </pages> <year> 1970. </year>
Reference-contexts: Until further, we leave the problem of deciding the size of M. The task is now to construct a Markov chain with transition matrix P which has as its stationary distribution. Hastings <ref> [5] </ref> show that reversible Markov chains, i.e. chains with (x)P (x; y) = (y)P (y; x); 8x; y 2 S; (6) fulfil the equation system (5). For reversible chains it is impossible to distinguish between forward and backward running of the chain. <p> Hastings <ref> [5] </ref> show that by choosing the acceptance probabilities to be ff xy = min 1; (x)q (x; y) (9) the stationary distribution is obtained. This algorithm is called the METROPOLIS-HASTINGS algorithm, and a simplification is the METROPOLIS-algorithm with q (x; y) = q (y; x).
Reference: [6] <author> V. E. Johnson. </author> <title> Studying convergence of markov chain monte carlo algorithms using coupled sample paths. </title> <journal> Journal of the American Statistical Association, </journal> <volume> 91(433) </volume> <pages> 154-166, </pages> <year> 1996. </year>
Reference-contexts: Haggstrom, Lieshout and Mller [10] presents a faster algorithm than Kendall, applied to spatial point processes. Mller [8] also give a review of spatial point processes including perfect simulation. Haggstrom and Nelander [4] shows how to use coupling from the past on anti-monotone systems. Johnson <ref> [6] </ref> uses coupling in the study of convergence of Markov chains. 48 10 CONCLUSION This report gives a review of the basic ideas in the new methods of perfect sampling using Markov chains. The first part covers the discrete case, and we consider the algorithms of Propp-Wilson and Fill.
Reference: [7] <author> W. S. Kendall. </author> <title> Perfect simulation for the area-interaction point process. </title> <booktitle> In Proceedings of the Symposium on Probability Towards the Year 2000. </booktitle> <publisher> World Scientific Press, </publisher> <year> 1996. </year> <note> To appear in C.C. </note> <editor> Heyde and L. Accardi, editors, </editor> <booktitle> Probability Perspective,. </booktitle>
Reference-contexts: Foss and Tweedie [3] place the coupling from the past algorithm in the context of stochastically recursive sequences. The also show that successful CFTP can be constructed if and only if the chain is uniformly geometric ergodic. Kendall <ref> [7] </ref> shows how to apply perfect sampling algorithms for simulation of point processes. A modification of the monotone CFTP is made, since the state space is infinite with no top state. Considers also repulsive point processes, which are not monotone.
Reference: [8] <author> J. Mller. </author> <title> Markov chain monte carlo and spatial point processes. </title> <editor> In W. S. Kendall O. Barndorff-Nielsen and M. N. M. van Lieshout, editors, </editor> <title> Proceedings Seminaire Europen de Statistiqe, Stochastic geometry, likelihood, and computation. </title> <publisher> Chapman and Hall. </publisher>
Reference-contexts: A modification of the monotone CFTP is made, since the state space is infinite with no top state. Considers also repulsive point processes, which are not monotone. Haggstrom, Lieshout and Mller [10] presents a faster algorithm than Kendall, applied to spatial point processes. Mller <ref> [8] </ref> also give a review of spatial point processes including perfect simulation. Haggstrom and Nelander [4] shows how to use coupling from the past on anti-monotone systems.
Reference: [9] <author> D. J. Murdoch and P. J. Green. </author> <title> Exact Sampling from a Continuous State Space. </title> <note> Available at http://www.stats.bris.ac.uk/MCMC. </note>
Reference-contexts: However, one problem immediately arises since the state space consists of an infinite number of possible states, and chains with different starting values will therefore not coalesce in finite time. Murdoch and Green <ref> [9] </ref> has therefore developed several exact sampling algorithms which introduces a discreteness into the state space. Their idea is to construct algorithms that update sets of states into one single state. <p> the updating at a random step in the iteration is done through an updating function such that (x; U t ) = (U t ) for all x, then all chains will simultaneously coalesce at this step. 7.1 THE ALGORITHMS We will now introduce the algorithms of Murdoch and Green <ref> [9] </ref>. Assume we are starting a Markov chain in every possible state at time M . Since we have a continuous state space, the set of current states which the Markov chains possess at this point will be uncountable. <p> Murdoch and Green <ref> [9] </ref> show how to apply partitioning in advance to the state space, similar to the partitioned multi-gamma coupler. 1 Note a minor inaccuracy in the paper of Murdoch and Green [9], since they say that B j consists of the intersection of those states which would give accept for y j <p> Murdoch and Green <ref> [9] </ref> show how to apply partitioning in advance to the state space, similar to the partitioned multi-gamma coupler. 1 Note a minor inaccuracy in the paper of Murdoch and Green [9], since they say that B j consists of the intersection of those states which would give accept for y j and all those states which not would give accept for y j1 . 37 7.1.4 THE PARTITIONED REJECTION COUPLER Suppose we can partition the state space S into m disjoint <p> Since q (yjx) &gt; 0 8x; y, with probability 1 the set R t will be finite, and since irreducibility is required R t will shrink to a single state in finite time. For a general pseudo-code, see Murdoch and Green <ref> [9] </ref>. To apply this algorithm we must calculate the set C t and, as Murdoch and Green [9] point out, this is not always simple. <p> For a general pseudo-code, see Murdoch and Green <ref> [9] </ref>. To apply this algorithm we must calculate the set C t and, as Murdoch and Green [9] point out, this is not always simple. We therefore consider the special case with the INDEPENDENCE SAMPLER with q (yjx) = q (y), i.e. a proposal distribution that do not depend on the current state. <p> To see this, just consider the algorithm as an rejection sampler with proposal q and acceptance probability qL . 7.2 THE GIBBS SAMPLER FOR THE CONTINUOUS CASE Murdoch and Green <ref> [9] </ref> also show how the multi-gamma coupler and rejection coupler may be applied as building blocks for sampling a vector X = (X 1 ; : : : ; X n ), with state space S = S 1 fi fi S n , using a cyclic Gibbs sampler. <p> Hence we cannot use this methods without imposing a bound on the state space of or b. This is the same conclusion as Murdoch and Green reached in their paper ( <ref> [9] </ref>) for their application, and it is a general problem when the state spaces are unbounded. Murdoch and Green then showed how to apply an approximative algorithm by imposing a bound on some of their parameters, and they made the algorithm more effective by partitioning the state space.
Reference: [10] <author> M. N. M. van Lieshout O. Haggstrom and J. Mller. </author> <title> Characterisation results and Markov chain Monte Carlo algorithms including exact simulation for some spatial point processes. </title> <type> Technical Report R-96-2040, </type> <institution> Aalborg University, </institution> <year> 1996. </year>
Reference-contexts: Kendall [7] shows how to apply perfect sampling algorithms for simulation of point processes. A modification of the monotone CFTP is made, since the state space is infinite with no top state. Considers also repulsive point processes, which are not monotone. Haggstrom, Lieshout and Mller <ref> [10] </ref> presents a faster algorithm than Kendall, applied to spatial point processes. Mller [8] also give a review of spatial point processes including perfect simulation. Haggstrom and Nelander [4] shows how to use coupling from the past on anti-monotone systems.
Reference: [11] <author> J. G. Propp and D. B. Wilson. </author> <title> Exact sampling with coupled Markov chains and applications to statistical mechanics. Random Structures and Algorithms, </title> <booktitle> 9 </booktitle> <pages> 223-252, </pages> <year> 1996. </year>
Reference-contexts: This is a difficult task, and the choice of the initial state can greatly affect the time to equilibrium. Recently Propp and Wilson <ref> [11] </ref> came up with an algorithm that eliminates the question about the size of M , by introducing a method that receives samples which are distributed exactly according to the target distribution . This is denoted EXACT or PERFECT SAMPLING, and their pioneer work has attracted considerable interest. <p> It is important that the variables U t are the same in each iteration and also for each of the N chains. If not, biased samples would again be obtained (see <ref> [11] </ref>). The algorithm presented will not be feasible if the state space S is large . Efficient simulation is possible only if we can reduce the number of chains to run. Recall the definition 2.2 of a monotone transition matrix. <p> A useful guide to the topic is the homepage of D.B. Wilson at http://dimacs.rutgers.edu/dbwilson Together with the original paper <ref> [11] </ref> on coupling from the past Propp and Wilson have written a user's guide on perfect sampling and some papers on generating random spanning tree of a directed graph. Foss and Tweedie [3] place the coupling from the past algorithm in the context of stochastically recursive sequences.
Reference: [12] <author> B. D. Ripley. </author> <title> Stochastic Simulation. </title> <publisher> John Wiley & Sons. </publisher>
Reference-contexts: The idea is to find an upper bound L on the ratio (z)=P t ( ^ 0; z) and accept the output z as an observation from with probability L 1 (z)=P t ( ^ 0; z). This can be seen as a form of rejection sampling <ref> [12] </ref>. 4.3.1 BACKGROUND Fill's method requires knowledge to some special results and definitions ([2]). Suppose we have a monotone transition matrix P such that P (x; ) P (y; ) stochastically for all x y.
Reference: [13] <author> D. Spiegelhalter, A. Thomas, N. Best, and W. Gilks. </author> <title> BUGS 0.5*Bayesian inference Using Gibbs Sampling Manual, </title> <year> 1996. </year>
Reference-contexts: Murdoch and Green then showed how to apply an approximative algorithm by imposing a bound on some of their parameters, and they made the algorithm more effective by partitioning the state space. To find a bound on (90) we performed a 40000 iteration run with the simulation program BUGS <ref> [13] </ref>, monitoring the value of this ratio at each step. A trace plot and histogram over the observed values (denoted ratio) is shown in Figure 14. The maximum value observed where 2:8 fi 10 14 , and thus we 45 imposed the bound 3fi10 14 on the ratio.
Reference: [14] <author> D. Spiegelhalter, A. Thomas, N. Best, and W. </author> <title> Gilks. </title> <journal> BUGS 0.5*Examples, </journal> <volume> Volume 1, </volume> <year> 1996. </year>
Reference-contexts: , else we set R it to the set of samples we receive by sampling X i conditional on the states in R jt . 40 8 A CASE STUDY: SURGICAL FAILURE RATES 8.1 THE PROBLEM The data and model for this example is collected from the BUGS example manual <ref> [14] </ref>, and considers mortality rates for cardiac surgery in hospitals. Data are collected from k = 12 hospitals, and these data are shown in Table 4. The number of operations is n i , and we model the number r i of deaths as Table 4: SURGICAL DATA.
Reference: [15] <author> H. M. Taylor and K. Samuel. </author> <title> An Introduction To Stochastic Modeling. </title> <publisher> Academic Press, Inc., </publisher> <year> 1984. </year>
Reference-contexts: In such circumstances we can use MARKOV CHAIN MONTE CARLO SIM ULATION (MCMC). This method is based on the theory of Markov chains, and we first review some basics facts (see for example Taylor and Karlin <ref> [15] </ref>). We consider the discrete case, but the same results can with slight modifications be extended to the continuous case. 2.1 MARKOV CHAINS Consider the stochastic process fX (t) g = X (0) ; X (1) ; X (2) ; ::: with X (t) 2 S, S discrete and finite.
Reference: [16] <author> G. Winkler. </author> <title> Image Analysis, Random Fields and Dynamic Monte Carlo Methods. </title> <publisher> Springer, </publisher> <address> Berlin, </address> <year> 1995. </year> <month> 50 </month>
Reference-contexts: Then each pixel, independent of all other pixels, will have a false value with some probability *. This kind of degradation is called CHANNEL NOISE. Stochastic image processing will typically adapt the Bayesian paradigm (see Winkler <ref> [16] </ref>). A priori, we state that an image is distributed according to a Markov random field, and we will see that the Ising model has shown to be useful.
References-found: 16

