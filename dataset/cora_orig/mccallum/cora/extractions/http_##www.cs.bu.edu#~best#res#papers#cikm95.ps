URL: http://www.cs.bu.edu/~best/res/papers/cikm95.ps
Refering-URL: http://cs-www.bu.edu/faculty/best/res/Home.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: (best@cs.bu.edu)  
Title: Using Speculation to Reduce Server Load and Service Time on the WWW  
Author: Azer Bestavros 
Address: Boston, MA 02215  
Affiliation: Computer Science Department Boston University  
Date: Nov 1995.  
Note: In Proceedings of CIKM'95: The 4th ACM InternationalConference on Information and Knowledge Management, Baltimore,MD,  
Abstract: Speculative service implies that a client's request for a document is serviced by sending, in addition to the document requested, a number of other documents (or pointers thereto) that the server speculates will be requested by the client in the near future. This speculation is based on statistical information that the server maintains for each document it serves. The notion of speculative service is analogous to prefetching, which is used to improve cache performance in distributed/parallel shared memory systems, with the exception that servers (not clients) control when and what to prefetch. Using extensive trace simulations based on the logs of our departmental HTTP server http://cs-www.bu.edu, we show that both server load and service time could be reduced considerably, if speculative service is used. This is above and beyond what is currently achievable using client-side caching [3] and server-side dissemination [2]. We identify a number of parameters that could be used to fine-tune the level of server speculation and we discuss variations of speculative service that involve cooperation with clients. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Swarup Acharya and Stanley B. Zdonik. </author> <title> An efficient scheme for dynamic data replication. </title> <type> Technical Report CS-93-43, </type> <institution> Brown University, </institution> <address> Providence, Rhode Island 02912, </address> <month> September </month> <year> 1993. </year>
Reference-contexts: In this study, a hierarchical caching system that caches files at Core Nodal Switching Subsystems is shown to reduce the NSFNET backbone traffic by 21%. The effect of data placement and replication on network traffic was also studied in <ref> [1] </ref>, where file access patterns are used to suggest a distributed dynamic replication scheme. A more static solution based on fixed network and storage costs was suggested in [12]. Multi-level caching was studied in [11], where a two-level caching system is shown to reduce both network and server loads.
Reference: [2] <author> Azer Bestavros. </author> <title> Demand-based document dissemination to reduce traffic and balance load in distributed information systems. </title> <booktitle> In Proceedings of SPDP'95: The 7 th IEEE Symposium on Parallel and Distributed Processing, </booktitle> <address> San Anotonio, Texas, </address> <month> October </month> <year> 1995. </year>
Reference-contexts: This aging mechanism depends highly (among other things) on the frequency and pattern of document updates on the server. The relative stability of P and P fl observed in the above experiments reinforces our findings in <ref> [2] </ref> that for WWW documents the popularity profile tends to be stable and updates tend to be infrequent. Effect of Document Size: The benefits of speculation are most pronounced when documents serviced speculatively are small. <p> A similar cooperative caching idea was suggested in [7]. A different approach to reducing server load and service time is based on the popularity-based dissemination of information from servers to proxies, which are closer to clients. Our work in <ref> [2] </ref> allows this dissemination to be done so as to make the distance between a client and a document server (or proxy thereof) inversly proportional to the popularity of that document. A similar philosophy was sketched in [9].
Reference: [3] <author> Azer Bestavros, Robert Carter, Mark Crovella, Carlos Cunha, Abdelsalam Heddaya, and Sulaiman Mirdad. </author> <title> Application level document caching in the internet. </title> <booktitle> In IEEE SDNE'96: The Second International Workshop on Services in Distributed and Networked Environments, </booktitle> <address> Whistler, British Columbia, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: By controlling the value of SessionTimeout, we can emulate various caching policies. In particular, setting SessionTimeout to 1 could be used to emulate a client with an infinite-size multi-session cache (e.g., the LAN cache proposed in <ref> [3] </ref>). Setting SessionTimeout to (say) 60 minutes could be used to emulate a client with an infinite-size single-session cache. Setting SessionTimeout to 0 could be used to emulate a client with no cache. <p> Using 10% extra bandwidth results in a reduction of 35%, 27%, and 23% in these metrics, respectively. These performance improvements are above and beyond what is achievable by performing caching at the clients <ref> [3] </ref>. Figures 3 and 4 suggest that speculation is most effective when done conservatively. Beyond some point, speculation does not seem to pay off.
Reference: [4] <author> Azer Bestavros and Carlos Cunha. </author> <title> A prefetching protocol using client speculation for the www. Technical Report TR-95-011, </title> <institution> Boston University, CS Dept, </institution> <address> Boston, MA 02215, </address> <month> April </month> <year> 1995. </year>
Reference-contexts: Also, it is possible to adopt a hybrid protocol whereby server-initiated speculative service is restricted to documents that have a very high probability of being accessed in the near future (e.g. embedded documents), leaving less probable future accesses to client-initiated prefetching. In an on-going study <ref> [4] </ref>, we evaluated client-initiated prefetching protocols. In that study, extensive user logs [6] are analyzed to obtain a per-user relationship similar to the P and P fl relationships (i.e. a user profile). Such a relationship is used to initiate document prefetching.
Reference: [5] <author> Matthew Addison Blaze. </author> <title> Caching in Large Scale Distributed File Systems. </title> <type> PhD thesis, </type> <institution> Princeton University, </institution> <month> January </month> <year> 1993. </year>
Reference-contexts: A more static solution based on fixed network and storage costs was suggested in [12]. Multi-level caching was studied in [11], where a two-level caching system is shown to reduce both network and server loads. In <ref> [5] </ref>, a dynamic hierarchical file system, which supports demand-driven replication is proposed, whereby clients are allowed to service requests issued by other clients from the local disk cache. A similar cooperative caching idea was suggested in [7].
Reference: [6] <author> Carlos Cunha, Azer Bestavros, and Mark Crovella. </author> <title> Characteristics of www client-based traces. </title> <type> Technical Report TR-95-010, </type> <institution> Boston University, CS Dept, </institution> <address> Boston, MA 02215, </address> <month> April </month> <year> 1995. </year>
Reference-contexts: In an on-going study [4], we evaluated client-initiated prefetching protocols. In that study, extensive user logs <ref> [6] </ref> are analyzed to obtain a per-user relationship similar to the P and P fl relationships (i.e. a user profile). Such a relationship is used to initiate document prefetching.
Reference: [7] <author> Michael D. Dahlin, Randolph Y. Wang, Thomas E. An-derson, and Dacid A. Patterson. </author> <title> Cooperative caching: Using remote client memory to improve file system performance. </title> <booktitle> In First Symposium on Operating systems Design and Implementation (OSDI), </booktitle> <pages> pages 267-280, </pages> <year> 1994. </year>
Reference-contexts: In [5], a dynamic hierarchical file system, which supports demand-driven replication is proposed, whereby clients are allowed to service requests issued by other clients from the local disk cache. A similar cooperative caching idea was suggested in <ref> [7] </ref>. A different approach to reducing server load and service time is based on the popularity-based dissemination of information from servers to proxies, which are closer to clients.
Reference: [8] <author> Peter Danzig, Richard Hall, and Michael Schwartz. </author> <title> A case for cashing file objects inside internetworks. </title> <type> Technical Report CU-CS-642-93, </type> <institution> University of Colorado at Boulder, Boulder, Colorado 80309-430, </institution> <month> March </month> <year> 1993. </year>
Reference-contexts: Traditionally, this has been done in the realms of distributed file systems [10]. Caching to reduce the bandwidth requirements for the FTP protocol on the NSFNET has been studied in <ref> [8] </ref>. In this study, a hierarchical caching system that caches files at Core Nodal Switching Subsystems is shown to reduce the NSFNET backbone traffic by 21%.
Reference: [9] <author> James Gwertzman and Margo Seltzer. </author> <title> The case for geographical push-caching. </title> <type> Technical Report HU TR-34-94 (excerpt), </type> <institution> Harvard University, DAS, </institution> <address> Cambridge, MA 02138, </address> <year> 1994. </year>
Reference-contexts: Our work in [2] allows this dissemination to be done so as to make the distance between a client and a document server (or proxy thereof) inversly proportional to the popularity of that document. A similar philosophy was sketched in <ref> [9] </ref>. In this paper we assumed that servers (and not clients) are the ones to initiate speculative services.
Reference: [10] <author> John H. Howard, Michael L. Kazar, Sherri G. Menees, David A. Nichols, M. Satyanarayanan, Robert N. Side-botham, and Michael J. West. </author> <title> Scale and performance in a distributed file system. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 6(1) </volume> <pages> 51-81, </pages> <month> February </month> <year> 1988. </year>
Reference-contexts: Traditionally, this has been done in the realms of distributed file systems <ref> [10] </ref>. Caching to reduce the bandwidth requirements for the FTP protocol on the NSFNET has been studied in [8]. In this study, a hierarchical caching system that caches files at Core Nodal Switching Subsystems is shown to reduce the NSFNET backbone traffic by 21%.
Reference: [11] <author> D. Muntz and P. Honeyman. </author> <title> Multi-level caching in distributed file systems or your cache ain't nuthing but trash. </title> <booktitle> In Proceedings of the Winter 1992 USENIX, </booktitle> <pages> pages 305-313, </pages> <month> January </month> <year> 1992. </year>
Reference-contexts: The effect of data placement and replication on network traffic was also studied in [1], where file access patterns are used to suggest a distributed dynamic replication scheme. A more static solution based on fixed network and storage costs was suggested in [12]. Multi-level caching was studied in <ref> [11] </ref>, where a two-level caching system is shown to reduce both network and server loads. In [5], a dynamic hierarchical file system, which supports demand-driven replication is proposed, whereby clients are allowed to service requests issued by other clients from the local disk cache.
Reference: [12] <author> Christos H. Papadimitriou, Srinivas Ramanathan, and P. Venkat Rangan. </author> <title> Information caching for delivery of personalized video programs on home entertainment channels. </title> <booktitle> In Proceedings of the International Confrence on Multimedia Computing and Systems, </booktitle> <pages> pages 214-223, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: The effect of data placement and replication on network traffic was also studied in [1], where file access patterns are used to suggest a distributed dynamic replication scheme. A more static solution based on fixed network and storage costs was suggested in <ref> [12] </ref>. Multi-level caching was studied in [11], where a two-level caching system is shown to reduce both network and server loads. In [5], a dynamic hierarchical file system, which supports demand-driven replication is proposed, whereby clients are allowed to service requests issued by other clients from the local disk cache.
References-found: 12

