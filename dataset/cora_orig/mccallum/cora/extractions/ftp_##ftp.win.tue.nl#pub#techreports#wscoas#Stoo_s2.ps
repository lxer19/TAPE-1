URL: ftp://ftp.win.tue.nl/pub/techreports/wscoas/Stoo_s2.ps
Refering-URL: http://as.win.tue.nl/publieng.html
Root-URL: http://www.win.tue.nl
Email: wscoas@win.tue.nl  J.H.van.Schuppen@cwi.nl  
Title: Approximation Problems with the Divergence Criterion for Gaussian Variables and Gaussian Processes  
Author: A.A. Stoorvogel J.H. van Schuppen 
Address: P.O. Box 513, 5600 MB Eindhoven, The Netherlands  P.O. Box 94079, 1090 GB Amsterdam, The Netherlands  
Affiliation: Department of Mathematics and Computing Science, Eindhoven University of Technology  CWI  
Abstract: System identification for stationary Gaussian processes includes an approximation problem. Currently the subspace algorithm for this problem enjoys much attention. This algorithm is based on a transformation of a finite time series to canonical variable form followed by a truncation. There is no proof that this algorithm is the optimal solution to an approximation problem with a specific criterion. In this paper it is shown that the optimal solution to an approximation problem for Gaussian random variables with the divergence criterion is identical to the main step of the subspace algorithm. An approximation problem for stationary Gaussian processes with the divergence criterion is formulated. Keywords and Phrases: System identification, Gaussian processes, divergence criterion, canonical variable form, subspace identification algorithm. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> H. Akaike. </author> <title> Information theory and an extension of the maximum likelihood principle. In B.N. </title> <editor> Petrov and F. Csaki, editors, </editor> <booktitle> Proceedings 2nd International Symposium Information Theory, </booktitle> <pages> pages 267-281. </pages> <publisher> Akademia Kiado, </publisher> <address> Budapest, </address> <year> 1973. </year>
Reference-contexts: The problem has been motivated above. The divergence criterion is related to the likelihood function as is well known. Apparently H. Akaike in <ref> [1, 2, 3] </ref> first published about this relation. In this regard, see also [12]. The problem is also motivated by the subspace algorithm for the approximation of stationary Gaussian processes. The nucleus of the subspace identification algorithm is an algorithm for the approximation problem of Gaussian random variables.
Reference: [2] <author> H. Akaike. </author> <title> Canonical correlation analysis of time series and the use of an information criterion. </title> <editor> In R.K. Mehra and D.G. Lainiotis, editors, </editor> <booktitle> System identification Advances and case studies, </booktitle> <pages> pages 27-96. </pages> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1976. </year>
Reference-contexts: The problem has been motivated above. The divergence criterion is related to the likelihood function as is well known. Apparently H. Akaike in <ref> [1, 2, 3] </ref> first published about this relation. In this regard, see also [12]. The problem is also motivated by the subspace algorithm for the approximation of stationary Gaussian processes. The nucleus of the subspace identification algorithm is an algorithm for the approximation problem of Gaussian random variables. <p> The nucleus of the subspace identification algorithm is an algorithm for the approximation problem of Gaussian random variables. The latter problem is like Problem 3.4, but the divergence criterion is not used. The subspace algorithm was proposed by H. Akaike, see <ref> [2] </ref>. It is based on stochastic realization theory. The algorithm was later extended and improved by many researchers, see [8, 10, 9, 13]. Approximation problems for Gaussian random variables have been considered already by C.R.
Reference: [3] <author> H. Akaike. </author> <title> On entropy maximization principle. In P.R. Krishnaiah, editor, </title> <journal> Applications of statistics, </journal> <pages> pages 27-41. </pages> <publisher> North-Holland Publ. Co., </publisher> <address> Amsterdam, </address> <year> 1977. </year>
Reference-contexts: The problem has been motivated above. The divergence criterion is related to the likelihood function as is well known. Apparently H. Akaike in <ref> [1, 2, 3] </ref> first published about this relation. In this regard, see also [12]. The problem is also motivated by the subspace algorithm for the approximation of stationary Gaussian processes. The nucleus of the subspace identification algorithm is an algorithm for the approximation problem of Gaussian random variables.
Reference: [4] <author> T.W. Anderson. </author> <title> An introduction to multivariate statistical analysis. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1958. </year>
Reference-contexts: Theorem 3.2 <ref> [4, 11] </ref>. Let y 1 : ! R k 1 and y 2 : ! R k 2 be jointly Gaussian random variables with (y 1 ; y 2 ) 2 G (0; Q). <p> Uniqueness occurs only if the canonical correlation coefficients are all different and k 12 = k 1 = k 2 . The remaining invariance of the canonical variable form will not be stated here because of space limitation. For additional results on canonical variables the reader is referred to <ref> [4, 5] </ref>. Note that Q &gt; 0 implies that the canonical correlation coefficients satisfy 1 &gt; 1 . The divergence of two Gaussian measures on R n is stated below. Proposition 3.3 [12, Appendix D].
Reference: [5] <author> R.D. Gittens. </author> <title> Canonical analysis A review with applications in ecology. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1985. </year>
Reference-contexts: Uniqueness occurs only if the canonical correlation coefficients are all different and k 12 = k 1 = k 2 . The remaining invariance of the canonical variable form will not be stated here because of space limitation. For additional results on canonical variables the reader is referred to <ref> [4, 5] </ref>. Note that Q &gt; 0 implies that the canonical correlation coefficients satisfy 1 &gt; 1 . The divergence of two Gaussian measures on R n is stated below. Proposition 3.3 [12, Appendix D].
Reference: [6] <author> K. Glover. </author> <title> All optimal Hankel-norm approximations of linear multivariable systems and their L 1 -error bounds. </title> <journal> Int. J. Control, </journal> <volume> 39 </volume> <pages> 1115-1193, </pages> <year> 1984. </year>
Reference-contexts: The authors are currently investigating this problem. 5 Conclusions Model reduction based on truncation after transformation in a suitable basis is a widely used technique. However, in several cases there is little theoretical foundation for this approximation technique. In <ref> [6] </ref> model approximation for finite-dimensional linear systems in the Hankel norm was studied in detail. It was shown that truncation in a particular canonical form yields an optimal approximation in the Hankel norm. This paper is a first attempt to perform a similar technique for Gaussian processes.
Reference: [7] <author> R.A. Horn and C.R. Johnson. </author> <title> Topics in matrix analysis. </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge, </address> <year> 1991. </year>
Reference-contexts: It follows from <ref> [7, Th. 3.3.16] </ref> and from e fl = ( C + e fl) + ( C) that i+j1 ( e fl) i ( C T + e fl) + j ( C T ); for all i; j 2 Z k with i + j k + 1.
Reference: [8] <author> A. Lindquist and G. Picci. </author> <title> Canonical correlation analysis, approximate covariance extension, and identification of stationary time series. </title> <type> Report TRITA/MAT-94-32, </type> <institution> Department of Mathematics, Royal Institute of Technology, Stockholm, </institution> <year> 1995. </year>
Reference-contexts: The latter problem is like Problem 3.4, but the divergence criterion is not used. The subspace algorithm was proposed by H. Akaike, see [2]. It is based on stochastic realization theory. The algorithm was later extended and improved by many researchers, see <ref> [8, 10, 9, 13] </ref>. Approximation problems for Gaussian random variables have been considered already by C.R. Rao in [11], but apparently not with the decomposition (7) and not with the divergence criterion. The problem above was first formulated by the second author in [15], see also [12]. Mr. M.
Reference: [9] <author> A. Lindquist and G. Picci. </author> <title> Geometric methods for state space identification. </title> <editor> In S. Bit-tanti and G. Picci, editors, </editor> <booktitle> Identification, adaption, learning, </booktitle> <pages> pages 1-69. </pages> <publisher> Springer, </publisher> <address> London, </address> <year> 1996. </year> <month> 17 </month>
Reference-contexts: The latter problem is like Problem 3.4, but the divergence criterion is not used. The subspace algorithm was proposed by H. Akaike, see [2]. It is based on stochastic realization theory. The algorithm was later extended and improved by many researchers, see <ref> [8, 10, 9, 13] </ref>. Approximation problems for Gaussian random variables have been considered already by C.R. Rao in [11], but apparently not with the decomposition (7) and not with the divergence criterion. The problem above was first formulated by the second author in [15], see also [12]. Mr. M.
Reference: [10] <author> P. Van Overschee and B. De Moor. </author> <title> Subspace algorithms for the stochastic identification problem. </title> <journal> Automatica, </journal> <volume> 29 </volume> <pages> 649-660, </pages> <year> 1993. </year>
Reference-contexts: The latter problem is like Problem 3.4, but the divergence criterion is not used. The subspace algorithm was proposed by H. Akaike, see [2]. It is based on stochastic realization theory. The algorithm was later extended and improved by many researchers, see <ref> [8, 10, 9, 13] </ref>. Approximation problems for Gaussian random variables have been considered already by C.R. Rao in [11], but apparently not with the decomposition (7) and not with the divergence criterion. The problem above was first formulated by the second author in [15], see also [12]. Mr. M.
Reference: [11] <author> C.R. Rao. </author> <title> The use and interpretation of principal component analysis in applied research. </title> <journal> Sankhya, Series A, </journal> <volume> 26 </volume> <pages> 329-358, </pages> <year> 1964. </year>
Reference-contexts: Theorem 3.2 <ref> [4, 11] </ref>. Let y 1 : ! R k 1 and y 2 : ! R k 2 be jointly Gaussian random variables with (y 1 ; y 2 ) 2 G (0; Q). <p> The subspace algorithm was proposed by H. Akaike, see [2]. It is based on stochastic realization theory. The algorithm was later extended and improved by many researchers, see [8, 10, 9, 13]. Approximation problems for Gaussian random variables have been considered already by C.R. Rao in <ref> [11] </ref>, but apparently not with the decomposition (7) and not with the divergence criterion. The problem above was first formulated by the second author in [15], see also [12]. Mr. M. <p> The Algorithm 3.5 has been known for a long time, it is already stated in <ref> [11] </ref>. Novel is here only that it is the optimal solution to the approximation problem with the divergence criterion.
Reference: [12] <author> A.A. Stoorvogel and J.H. van Schuppen. </author> <title> System identification with information theoretic criteria. </title> <editor> In S. Bittanti and G. Picci, editors, </editor> <title> Identification, adaptation, </title> <booktitle> learning, </booktitle> <pages> pages 289-338. </pages> <publisher> Springer, </publisher> <address> Berlin, </address> <year> 1996. </year>
Reference-contexts: This problem was formulated by the second author in [15] and restated in <ref> [12] </ref>. Two approximation problems are discussed in this paper. The first approximation problem concerns a pair of finite-dimensional Gaussian random variables. This problem is motivated by the main approximation step of the subspace algorithm. <p> For additional results on canonical variables the reader is referred to [4, 5]. Note that Q &gt; 0 implies that the canonical correlation coefficients satisfy 1 &gt; 1 . The divergence of two Gaussian measures on R n is stated below. Proposition 3.3 <ref> [12, Appendix D] </ref>. Let G (m 1 ; Q 1 ) and G (m 2 ; Q 2 ) be two Gaussian measures on R n . Assume that Q 1 &gt; 0 and Q 2 &gt; 0. <p> The problem has been motivated above. The divergence criterion is related to the likelihood function as is well known. Apparently H. Akaike in [1, 2, 3] first published about this relation. In this regard, see also <ref> [12] </ref>. The problem is also motivated by the subspace algorithm for the approximation of stationary Gaussian processes. The nucleus of the subspace identification algorithm is an algorithm for the approximation problem of Gaussian random variables. The latter problem is like Problem 3.4, but the divergence criterion is not used. <p> Approximation problems for Gaussian random variables have been considered already by C.R. Rao in [11], but apparently not with the decomposition (7) and not with the divergence criterion. The problem above was first formulated by the second author in [15], see also <ref> [12] </ref>. Mr. M. Stohr first performed research on the problem at CWI in 1989 under supervision of the second author of this paper. Problem 3.4 is difficult because it is an optimization problem over a space which is not convex. <p> The divergence rate between the measures induced by the processes exists and is given by the formula D r (P 0 kP 1 ) 1 Z ln det ^ W 1 (e i ) ! i j For details on this see <ref> [12, Appendix E] </ref>.
Reference: [13] <author> P. van Overschee. </author> <title> Subspace identification. </title> <type> PhD thesis, </type> <institution> Katholieke Universiteit Leuven, Leuven, </institution> <year> 1995. </year>
Reference-contexts: The latter problem is like Problem 3.4, but the divergence criterion is not used. The subspace algorithm was proposed by H. Akaike, see [2]. It is based on stochastic realization theory. The algorithm was later extended and improved by many researchers, see <ref> [8, 10, 9, 13] </ref>. Approximation problems for Gaussian random variables have been considered already by C.R. Rao in [11], but apparently not with the decomposition (7) and not with the divergence criterion. The problem above was first formulated by the second author in [15], see also [12]. Mr. M.
Reference: [14] <author> C. van Putten and J.H. van Schuppen. </author> <title> The weak and strong gaussian probabilistic realization problem. </title> <journal> J. Multivariate Anal., </journal> <volume> 13 </volume> <pages> 118-137, </pages> <year> 1983. </year>
Reference-contexts: An example of such a state x is x = Q 12 Q 1 22 y 2 where (y 1 ; y 2 ) 2 G (0; Q) with Q = Q 11 Q 12 12 Q 22 : There are many such state variables, see <ref> [14] </ref> for the details. The space in which the state variable x takes values, R n , has minimal dimension iff n = rank (Q 12 ).
Reference: [15] <author> J.H. van Schuppen. </author> <title> Stochastic realization problems. </title> <editor> In J.M. Schumacher H. Nijmeijer, editor, </editor> <title> Three decades of mathematical system theory, </title> <booktitle> volume 135 of Lecture Notes in Control and Information Sciences, </booktitle> <pages> pages 480-523. </pages> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1989. </year> <month> 18 </month>
Reference-contexts: This problem was formulated by the second author in <ref> [15] </ref> and restated in [12]. Two approximation problems are discussed in this paper. The first approximation problem concerns a pair of finite-dimensional Gaussian random variables. This problem is motivated by the main approximation step of the subspace algorithm. <p> Approximation problems for Gaussian random variables have been considered already by C.R. Rao in [11], but apparently not with the decomposition (7) and not with the divergence criterion. The problem above was first formulated by the second author in <ref> [15] </ref>, see also [12]. Mr. M. Stohr first performed research on the problem at CWI in 1989 under supervision of the second author of this paper. Problem 3.4 is difficult because it is an optimization problem over a space which is not convex.
References-found: 15

