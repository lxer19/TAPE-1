URL: http://www.cs.umass.edu/~jensen/papers/aaaiws97b.ps
Refering-URL: http://www.cs.umass.edu/~jensen/papers/aaaiss97-aaaiws97b.html
Root-URL: 
Email: jensen@cs.umass.edu  
Title: Abstract Unique Challenges of Managing Inductive Knowledge produc ing statistical significance inductive bias Executive Summary
Author: David Jensen 
Address: Amherst, MA 01003-4610  
Affiliation: Experimental Knowledge Systems Lab Computer Science Department University of Massachusetts  
Date: 1996)  
Note: e.g., respectively: The Third International Conference on Knowledge Discovery and Data Mining (KDD-97) and the International Symposium on Intelligent Data Analysis (IDA-97); (Kluwer) and (Elsevier); and (Fayyad  been developed and fielded, and these systems are being actively applied by hundreds of organizations (Fayyad, Piatetsky-Shapiro, Smyth 1996). This increasing interest has also been reflected in the research community, where knowledge discovery and data mining are the subject of several new conferences, journals, and books. Typically, these systems are concerned with If  that any  
Abstract: are becoming increasingly important to organizations in business, government, and science. However, relatively little attention has been paid to the long-term management of induced knowledge. Induced knowledge presents unique challenges, including managing statistical significance and inductive bias. These challenges have important implications for valid and efficient knowledge management. knowledge. They analyze a data sample to produce a set of inductive inferences that are then applied directly by human users or encoded into other software. However, knowledge-based systems are increasingly coming into long-term use within organizations. This implies the need to explicitly maintain and manage all knowledge, including knowledge that is derived inductively. This paper argues that induced knowledge has at least two unique characteristics, and that these characteristics impose special requirements on knowledge management systems. The first characteristic concerns , characterized by a nonzero probability that any observed relationship may be due to random variation alone. The need to evaluate statistical significance implies that knowledge management systems must be at least loosely coupled with systems for two other functions: data management and induction. Knowledge cannot simply be induced and then permanently transferred to a knowledge management system. Instead, continued communication between these systems is necessary to effectively manage induced knowledge. The second unique characteristic of induced knowledge is , the ordering of possible models imposed by a search procedure. Inductive bias provides additional reasons that knowledge management systems should be coupled with systems for induction. 
Abstract-found: 1
Intro-found: 0
Reference: <author> Cohen, P. R., and Jensen, D. </author> <year> 1997. </year> <note> Overfitting explained. In , 115-122. </note>
Reference: <author> Cohen, P. R. </author> <title> 1996. </title> . <publisher> MIT Press. </publisher>
Reference: <editor> Fayyad, U.; Piatetsky-Shapiro, G.; Smyth, P.; and Uthurusamy, R. </editor> <booktitle> 1996. </booktitle> . <publisher> AAAI Press/MIT Press. </publisher>
Reference: <author> Fayyad, U.; Piatetsky-Shapiro, G.; and Smyth, P. </author> <year> 1996. </year> <title> From data mining to knowledge discovery in databases. </title> <publisher> Fall:37-54. </publisher>
Reference: <author> Gaines, B. </author> <year> 1989. </year> <title> An ounce of knowledge is worth a ton of data: Quantitative studies of the trade-off between expertise and data based on statistically well-founded empirical induction. In , 156-159. </title> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Gordon, D., and Desjardins, M. </author> <year> 1996. </year> <title> Evaluation and selection of biases in machine learning. </title> <booktitle> 20 </booktitle> <pages> 5-22. </pages>
Reference: <author> Jensen, D. </author> <year> 1992. </year> . <type> Ph.D. Dissertation, </type> <institution> Washington University. </institution>
Reference: <author> Jensen, D. </author> <year> 1997. </year> <title> Adjusting for multiple testing in decision tree pruning. </title> <note> In , 295-302. </note>
Reference: <author> Kass, G. </author> <year> 1980. </year> <title> An exploratory technique for investigating large quantities of categorical data. </title> <booktitle> 29 </booktitle> <pages> 119-127. </pages>
Reference: <author> Kohavi, R. </author> <year> 1995. </year> <title> A study of cross-validation and bootstrap for accuracy estimation and model selection. </title> <booktitle> In </booktitle> . 
Reference: <author> Mann, C. </author> <year> 1990. </year> <booktitle> Meta-analysis in the breech. </booktitle> <volume> 249 </volume> <pages> 476-480. </pages>
Reference: <author> Mitchell, T. </author> <year> 1980. </year> <title> The need for biases in learning generalizations. </title> <type> Technical Report CBM-TR-117, </type> <institution> Rutgers University. </institution>
Reference: <author> Murthy, S. K., and Salzberg, S. </author> <year> 1995. </year> <title> Lookahead and pathology in decision tree induction. In , 1025-1031. </title> <publisher> Mor-gan Kaufmann. </publisher>
Reference: <author> Quinlan, J. R., and Cameron-Jones, R. M. </author> <year> 1995. </year> <title> Oversearching and layered search in empirical learning. In , 1019-1024. </title> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Selvin, H., and Stuart, A. </author> <year> 1966. </year> <title> Data-dredging procedures in survey analysis. </title> <publisher> June:20-23. </publisher>
Reference: <author> Sterling, T. </author> <year> 1959. </year> <title> Publication decisions and their possible effects on inferences drawn from tests of significance | or vice-versa. </title> <booktitle> 54 </booktitle> <pages> 30-34. </pages>
References-found: 16

