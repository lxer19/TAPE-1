URL: http://L2R.cs.uiuc.edu/~danr/Papers/aaai98.ps.gz
Refering-URL: http://L2R.cs.uiuc.edu/~danr/publications.html
Root-URL: http://www.cs.uiuc.edu
Email: danr@cs.uiuc.edu  
Title: Learning to Resolve Natural Language Ambiguities: A Unified Approach  
Author: Dan Roth 
Address: Urbana, IL 61801  
Affiliation: Department of Computer Science University of Illinois at Urbana-Champaign  
Note: To Appear in AAAI-98  
Abstract: We analyze a few of the commonly used statistics based and machine learning algorithms for natural language disambiguation tasks and observe that they can be recast as learning linear separators in the feature space. Each of the methods makes a priori assumptions, which it employs, given the data, when searching for its hypothesis. Nevertheless, as we show, it searches a space that is as rich as the space of all linear separators. We use this to build an argument for a data driven approach which merely searches for a good linear separator in the feature space, without further assumptions on the domain or a specific problem. We present such an approach a sparse network of linear separators, utilizing the Winnow learning algorithm and show how to use it in a variety of ambiguity resolution problems. The learning approach presented is attribute-efficient and, therefore, appropriate for domains having very large number of attributes. In particular, we present an extensive experimental comparison of our approach with other methods on several well studied lexical disambiguation tasks such as context-sensitive spelling correction, prepositional phrase attachment and part of speech tagging. In all cases we show that our approach either outperforms other methods tried for these tasks or performs comparably to the best. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Blum, A. </author> <year> 1995. </year> <title> Empirical support for Winnow and weighted-majority based algorithms: results on a calendar scheduling domain. </title> <booktitle> In Proc. 12th International Conference on Machine Learning, </booktitle> <pages> 64-72. </pages> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: as the hypothesis class (i.e., in TBL) an effort is made to discard many of the features and by that reduce the complexity of the space; however, this process, which is data driven and does not a-priori restrict the function class can be employed by other methods as well (e.g., <ref> (Blum 1995) </ref>) and is therefore orthogonal to these arguments. The SNOW Approach The SNOW architecture is a network of threshold gates. Nodes in the first layer of the network are allocated to input features in a data-driven way, given the input sentences.
Reference: <author> Brill, E., and Resnik, P. </author> <year> 1994. </year> <title> A rule-based approach to prepositional phrase attachment disambiguation. </title> <booktitle> In Proc. of COLING. </booktitle>
Reference-contexts: The reason is that the truth value of the condition of the ith rule may change while evaluating one of the preceding rules. However, in many applications and, in particular, in Spell (Mangu & Brill 1997) and PPA <ref> (Brill & Resnik 1994) </ref> which we discuss later, this is not the case. There, the conditions do not depend on the labels, and therefore the output hypothesis of the TBL method can be viewed as a classifier. The following analysis applies only for this case.
Reference: <author> Brill, E. </author> <year> 1995. </year> <title> Transformation-based error-driven learning and natural language processing: A case study in part of speech tagging. </title> <booktitle> Computational Linguistics 21(4) </booktitle> <pages> 543-565. </pages>
Reference-contexts: A partial list consists of Bayesian classifiers (Gale, Church, & Yarowsky 1993), decision lists (Yarowsky 1994), Bayesian hybrids (Golding 1995), HMMs (Charniak 1993), inductive logic methods (Zelle & Mooney 1996), memory-based methods (Zavrel, Daelemans, & Veenstra 1997) and transformation-based learning <ref> (Brill 1995) </ref>. Most of these have been developed in the context of a specific task although claims have been made as to their applicativity to others. <p> It is important to notice that the assumptions made in the BO estimation method result in a linear decision surface that is, in general, different from the one derived in the NB method. Transformation Based Learning (TBL) Transformation based learning <ref> (Brill 1995) </ref> is a machine learning approach for rule learning. It has been applied to a number of natural language disambiguation tasks, often achieving state-of-the-art accuracy. The learning procedure is a mistake-driven algorithm that produces a set of rules. <p> This process goes on until the last rule in the list is evaluated. The last label is the output of the hypothesis. In its most general setting, the TBL hypothesis is not a classifier <ref> (Brill 1995) </ref>. The reason is that the truth value of the condition of the ith rule may change while evaluating one of the preceding rules. <p> The results presented for the TBL and BO are on the same data set, taken from (Collins & Brooks 1995). Part of Speech Tagging A part of speech tagger assigns each word in a sentence the part of speech that it assumes in that sentence. See <ref> (Brill 1995) </ref> for a survey of much of the work that has been done on POS in the past few years. Typically, in English there will be between 30 and 150 different parts of speech depending on the tagging scheme. In the study presented here, following (Brill 1995) and many other <p> See <ref> (Brill 1995) </ref> for a survey of much of the work that has been done on POS in the past few years. Typically, in English there will be between 30 and 150 different parts of speech depending on the tagging scheme. In the study presented here, following (Brill 1995) and many other studies there are 47 different tags. Part-of-speech tagging suggests a special challenge to our approach, as the problem is a multi-class prediction problem (Roth & Zelenko 1998). <p> All algorithms were trained on 550; 000 words of the tagged WSJ corpus. Baseline simply predicts according to the most common pos tag for the word in the training corpus. Test Baseline TBL SNOW cases 250,000 94.4 96.9 96.8 context and collocation features as in <ref> (Brill 1995) </ref>. Given a sentence, each word in the sentence is assigned an initial tag, based on the most common part of speech in the training corpus. Then, for each word in the sentence, the network processes the sentence, and makes a suggestion for the pos of this word.
Reference: <author> Cardie, C. </author> <year> 1996. </year> <title> Embedded Machine Learning Systems for natural language processing: A general framework. </title> <publisher> Springer. </publisher> <pages> 315-328. </pages>
Reference-contexts: A large number of different kinds of ambiguities are to be re-solved simultaneously in performing any higher level natural language inference <ref> (Cardie 1996) </ref>. Naturally, these processes, acting on the same input and using the same "memory", will interact.
Reference: <author> Charniak, E. </author> <year> 1993. </year> <title> Statistical Language Learning. </title> <publisher> MIT Press. </publisher>
Reference-contexts: Developing learning techniques for language disambiguation has been an active field in recent years and a number of statistics based and machine learning techniques have been proposed. A partial list consists of Bayesian classifiers (Gale, Church, & Yarowsky 1993), decision lists (Yarowsky 1994), Bayesian hybrids (Golding 1995), HMMs <ref> (Charniak 1993) </ref>, inductive logic methods (Zelle & Mooney 1996), memory-based methods (Zavrel, Daelemans, & Veenstra 1997) and transformation-based learning (Brill 1995). Most of these have been developed in the context of a specific task although claims have been made as to their applicativity to others.
Reference: <author> Chen, S., and Goodman, J. </author> <year> 1996. </year> <title> An empirical study of smoothing techniques for language modeling. </title> <booktitle> In Proc. of the Annual Meeting of the ACL. </booktitle>
Reference: <author> Collins, M., and Brooks, J. </author> <year> 1995. </year> <title> Prepositional phrase attachment through a backed-off model. </title> <booktitle> In Proceedings of Third the Workshop on Very Large Corpora. </booktitle>
Reference-contexts: Many variation of the method exist; we describe a fairly general one and then present the version used in <ref> (Collins & Brooks 1995) </ref>, which we compare with experimentally. When applied to a disambiguation task, BO assumes that the sentence itself (the basic unit processed) is a feature 6 of maximal order f = f (k) 2 F. <p> Various smoothing techniques can be employed to get more robust estimations but these considerations will not affect our discussion and we disregard them. 6 The assumption that the maximal order feature is the classified sentence is made, for example, in <ref> (Collins & Brooks 1995) </ref>. In general, the method deals with multiple features of the maximal order by assuming their conditional independence, and superimposing the NB approach. The sum is over all features f which are more general (and thus occur more frequently) than f (k) . <p> For computational reasons, various simplifying assumptions are made in order to estimate the coefficients f ; we describe here the method used in <ref> (Collins & Brooks 1995) </ref> 7 . We denote by N (f (j) ) the number of occurrences of the jth order feature f (j) in the training data. <p> The results presented in Table 2 for NB and SNOW are the results of our system on the 3097 test examples. The results presented for the TBL and BO are on the same data set, taken from <ref> (Collins & Brooks 1995) </ref>. Part of Speech Tagging A part of speech tagger assigns each word in a sentence the part of speech that it assumes in that sentence. <p> The methods compared use 15 SNOW was evaluated with an enhanced feature set (Krymolovsky & Roth 1998) with improved results of 84.8%. <ref> (Collins & Brooks 1995) </ref> reports results of 84.4% on a different enhanced set of features, but other systems were not evaluated on these sets. Table 3: POS System comparison. The first column gives the number of test cases.
Reference: <author> Duda, R. O., and Hart, P. E. </author> <year> 1973. </year> <title> Pattern Classification and Scene Analysis. </title> <publisher> Wiley. </publisher>
Reference-contexts: Different probabilistic assumptions give rise to difference learning methods and we describe two popular methods below. The naive Bayes estimation (NB) The naive Bayes estimation (e.g., <ref> (Duda & Hart 1973) </ref>) assumes that given the class value c 2 C the features values are statistically independent.
Reference: <author> Gale, W. A.; Church, K. W.; and Yarowsky, D. </author> <year> 1993. </year> <title> A method for disambiguating word senses in a large corpus. </title> <booktitle> Computers and the Humanities 26 </booktitle> <pages> 415-439. </pages>
Reference-contexts: Developing learning techniques for language disambiguation has been an active field in recent years and a number of statistics based and machine learning techniques have been proposed. A partial list consists of Bayesian classifiers <ref> (Gale, Church, & Yarowsky 1993) </ref>, decision lists (Yarowsky 1994), Bayesian hybrids (Golding 1995), HMMs (Charniak 1993), inductive logic methods (Zelle & Mooney 1996), memory-based methods (Zavrel, Daelemans, & Veenstra 1997) and transformation-based learning (Brill 1995).
Reference: <author> Golding, A. R., and Roth, D. </author> <year> 1996. </year> <title> Applying winnow to context-sensitive spelling correction. </title> <booktitle> In Proc. of the International Conference on Machine Learning, </booktitle> <pages> 182-190. </pages>
Reference-contexts: In addition, very few of the features in F are active in every example, yielding more efficient evaluation techniques (e.g., (Valiant 1998)) 11 This is hard to define in the context of natural language; typically, this is understood as texts of similar nature; see a discussion of this issue in <ref> (Golding & Roth 1996) </ref>. In the absence of this knowledge a learning method merely attempts to make correct predictions. <p> Links from the first to the second layer have weights; each target node is thus defined as a (linear) function of the lower level nodes. (A similar architecture which consists of an additional layer is described in <ref> (Golding & Roth 1996) </ref>. Here we do not use the "cloud" level described there.) For example, in Spell, target nodes represent members of the confusion sets; in POS, target nodes correspond to different pos tags. <p> Notice that even when there are only two target nodes and the cloud size <ref> (Golding & Roth 1996) </ref> is 1 SNOW behaves differently than pure Winnow. While each of the target nodes is learned using a positive Winnow algorithm, a winner-take-all policy is used to determine the prediction. Thus, we do not use the learning algorithm here simply as a discriminator. <p> A confusion set C = fc 1 ; : : : ; c n g means that each word c i in the set is ambiguous with each other word. All the results reported here use the same pre-defined set of confusion sets <ref> (Golding & Roth 1996) </ref>. We compare SNOW against TBL (Mangu & Brill 1997) and a naive-Bayes based system (NB). <p> The latter system presents a few augmentations over the simple naive Bayes (but still shares the same basic assumptions) and is among the most successful methods tried for the problem (Golding 1995). An indication that a Winnow-based algorithm performs well on this problem was presented in <ref> (Golding & Roth 1996) </ref>. However, the system presented there was more involved than SNOW and allows more expressive output representation than we allow here. The output representation of all the approaches compared is a linear separator.
Reference: <author> Golding, A. R., and Roth, D. </author> <year> 1998. </year> <title> A winnow-based approach to word correction. </title> <journal> Machine Learning. </journal> <note> Special issue on Machine Learning and Natural Language; to appear. </note>
Reference: <author> Golding, A. R. </author> <year> 1995. </year> <title> A bayesian hybrid method for context-sensitive spelling correction. </title> <booktitle> In Proceedings of the 3rd workshop on very large corpora, </booktitle> <address> ACL-95. </address>
Reference-contexts: Developing learning techniques for language disambiguation has been an active field in recent years and a number of statistics based and machine learning techniques have been proposed. A partial list consists of Bayesian classifiers (Gale, Church, & Yarowsky 1993), decision lists (Yarowsky 1994), Bayesian hybrids <ref> (Golding 1995) </ref>, HMMs (Charniak 1993), inductive logic methods (Zelle & Mooney 1996), memory-based methods (Zavrel, Daelemans, & Veenstra 1997) and transformation-based learning (Brill 1995). Most of these have been developed in the context of a specific task although claims have been made as to their applicativity to others. <p> We compare SNOW against TBL (Mangu & Brill 1997) and a naive-Bayes based system (NB). The latter system presents a few augmentations over the simple naive Bayes (but still shares the same basic assumptions) and is among the most successful methods tried for the problem <ref> (Golding 1995) </ref>. An indication that a Winnow-based algorithm performs well on this problem was presented in (Golding & Roth 1996). However, the system presented there was more involved than SNOW and allows more expressive output representation than we allow here.
Reference: <author> Hoffgen, K., and Simon, H. </author> <year> 1992. </year> <title> Robust trainability of single neurons. </title> <booktitle> In Proc. 5th Annu. Workshop on Comput. Learning Theory, </booktitle> <pages> 428-439. </pages> <address> New York, New York: </address> <publisher> ACM Press. </publisher>
Reference-contexts: The optimality criterion we seek is described in Eq. 1. A linear classifier that minimizes the number of disagreements (the sum of the false positives and false negatives classifications). This task, however, is known to be NP-hard <ref> (Hoffgen & Simon 1992) </ref>, so we need to resort to heuristics. In searching for good heuristics we are guided by computational issues that are relevant to the natural language domain. An essential property of an algorithm is being feature-efficient.
Reference: <author> Katz, S. M. </author> <year> 1987. </year> <title> Estimation of probabilities from sparse data for the language model component of a speech recog-nizer. </title> <booktitle> IEEE Transactions on Acoustics, speech, and Signal Processing 35(3) </booktitle> <pages> 400-401. </pages>
Reference: <author> Kearns, M., and Schapire, R. </author> <year> 1994. </year> <title> Efficient distribution-free learning of probabilistic concepts. </title> <journal> Journal of Computer and System Sciences 48 </journal> <pages> 464-497. </pages>
Reference-contexts: The implication is that a method that merely searches for the optimal linear decision surface given the training data may, in general, outperform all these methods also on the test data. This argument can be made formal by appealing to a result of <ref> (Kearns & Schapire 1994) </ref>, which shows that even when there is no perfect classifier, the optimal linear separator on a polynomial size set of training examples is optimal (in a precise sense) also on the test data. The optimality criterion we seek is described in Eq. 1.
Reference: <author> Kearns, M., and Vazirani, U. </author> <year> 1992. </year> <title> Introduction to computational Learning Theory. </title> <publisher> MIT Press. </publisher>
Reference: <author> Kivinen, J., and Warmuth, M. K. </author> <year> 1995. </year> <title> Exponentiated gradient versus gradient descent for linear predictors. </title> <booktitle> In Proceedings of the Annual ACM Symp. on the Theory of Computing. </booktitle>
Reference: <author> Krymolovsky, Y., and Roth, D. </author> <year> 1998. </year> <title> Prepositional phrase attachment. </title> <note> In Preparation. </note>
Reference-contexts: The classifiers then compete for deciding the pos of this word, and the node that records the highest activity for a given word in a sentence determines its pos. The methods compared use 15 SNOW was evaluated with an enhanced feature set <ref> (Krymolovsky & Roth 1998) </ref> with improved results of 84.8%. (Collins & Brooks 1995) reports results of 84.4% on a different enhanced set of features, but other systems were not evaluated on these sets. Table 3: POS System comparison. The first column gives the number of test cases.
Reference: <author> Littlestone, N. </author> <year> 1988. </year> <title> Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm. </title> <booktitle> Machine Learning 2 </booktitle> <pages> 285-318. </pages>
Reference-contexts: At prediction time, given an input sentence which activates a subset of the input nodes, the information propagates through all the subnetworks; the one which produces the highest activity gets to determine the prediction. A local learning algorithm, Winnow <ref> (Littlestone 1988) </ref>, is used at each target node to learn its dependence on other nodes. Winnow is a mistake driven on-line algorithm, which updates its weights in a multiplicative fashion.
Reference: <author> Littlestone, N. </author> <year> 1991. </year> <title> Redundant noisy attributes, attribute errors, and linear threshold learning using Winnow. </title> <booktitle> In Proc. 4th Annu. Workshop on Comput. Learning Theory, </booktitle> <pages> 147-156. </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: An essential property of an algorithm is being feature-efficient. Consequently, the approach describe in the next section makes use of the Winnow algorithm which is known to produce good results when a linear separator exists, as well as under certain more relaxed assumptions <ref> (Littlestone 1991) </ref>. 12 In practice, when using p1-DL as the hypothesis class (i.e., in TBL) an effort is made to discard many of the features and by that reduce the complexity of the space; however, this process, which is data driven and does not a-priori restrict the function class can be
Reference: <author> Mangu, L., and Brill, E. </author> <year> 1997. </year> <title> Automatic rule acquisition for spelling correction. </title> <booktitle> In Proc. of the International Conference on Machine Learning, </booktitle> <pages> 734-741. </pages>
Reference-contexts: In its most general setting, the TBL hypothesis is not a classifier (Brill 1995). The reason is that the truth value of the condition of the ith rule may change while evaluating one of the preceding rules. However, in many applications and, in particular, in Spell <ref> (Mangu & Brill 1997) </ref> and PPA (Brill & Resnik 1994) which we discuss later, this is not the case. There, the conditions do not depend on the labels, and therefore the output hypothesis of the TBL method can be viewed as a classifier. <p> All the results reported here use the same pre-defined set of confusion sets (Golding & Roth 1996). We compare SNOW against TBL <ref> (Mangu & Brill 1997) </ref> and a naive-Bayes based system (NB). The latter system presents a few augmentations over the simple naive Bayes (but still shares the same basic assumptions) and is among the most successful methods tried for the problem (Golding 1995). <p> The results presented in Table 1 for NB and SNOW are the (weighted) average results of 21 confusion sets, 19 of them are of size 2, and two of size 3. The results presented for the TBL 14 method are taken from <ref> (Mangu & Brill 1997) </ref> and represent an average on a subset of 14 of these, all of size 2. <p> Prepositional Phrase Attachment The problem is to decide whether the Prepositional Phrase (PP) attaches to the noun phrase, as in Buy the car with 14 Systems are compared on the same feature set. TBL was also used with an enhanced feature set <ref> (Mangu & Brill 1997) </ref> with improved results of 93.3% but we have not run the other systems with this set of features. Table 2: PPA System comparison.
Reference: <author> Ratnaparkhi, A.; Reynar, J.; and Roukos, S. </author> <year> 1994. </year> <title> A maximum entropy model for prepositional phrase attachment. </title> <booktitle> In ARPA. </booktitle>
Reference: <author> Rivest, R. L. </author> <year> 1987. </year> <title> Learning decision lists. </title> <booktitle> Machine Learning 2(3) </booktitle> <pages> 229-246. </pages>
Reference-contexts: Let x i j be the first active feature in the list (i.e., the largest j). Then the hypothesis predicts c i j . Alternatively, the TBL hypothesis can be represented as a (positive) 1-Decision-List (p1-DL) <ref> (Rivest 1987) </ref>, over the set F of features 9 . Given the p1-DL represen If x i k is active then predict c k . Else If x i k1 is active then predict c k1 .
Reference: <author> Roth, D., and Zelenko, D. </author> <year> 1998. </year> <title> Part of speech tagging using a network of linear separators. </title> <note> Submitted. </note>
Reference-contexts: This representation immediately implies that this predictor is optimal also in situations in which the conditional independence assumption does no hold. However, a more important consequence to our discussion here is the fact that not all linearly separable functions can be represented using this predictor <ref> (Roth 1998) </ref>. The back-off estimation (BO) Back-off estimation is another method for estimating the conditional probabilities P r (c i js). It has been used in many disambiguation tasks and in learning models for speech recognition (Katz 1987; Chen & Goodman 1996; Collins & Brooks 1995). <p> Fact 3: The VC dimension of the class of linear separators derived by either NB or BO over n variables is bounded below by n. Fact 1 is well known; 2 and 3 can be derived directly from the definition <ref> (Roth 1998) </ref>. The implication is that a method that merely searches for the optimal linear decision surface given the training data may, in general, outperform all these methods also on the test data. <p> In the study presented here, following (Brill 1995) and many other studies there are 47 different tags. Part-of-speech tagging suggests a special challenge to our approach, as the problem is a multi-class prediction problem <ref> (Roth & Zelenko 1998) </ref>. In the SNOW architecture, we devote one linear separator to each pos tag and each sub network learns to separate its corresponding pos tag from all others. At run time, all class nodes process the given sentence, applying many classifiers simultaneously. <p> The classifiers then compete for deciding the pos of this word, and the node that records the highest activity for a given word in a sentence determines its pos. The methods compared use 15 SNOW was evaluated with an enhanced feature set <ref> (Krymolovsky & Roth 1998) </ref> with improved results of 84.8%. (Collins & Brooks 1995) reports results of 84.4% on a different enhanced set of features, but other systems were not evaluated on these sets. Table 3: POS System comparison. The first column gives the number of test cases. <p> Each time the input to the predictors is expected to be slightly less noisy. In the results presented here, however, we present the performance without the recycling process, so that we maintain the linear function expressivity (see <ref> (Roth & Zelenko 1998) </ref> for details). The results presented in Table 3 are based on experiments using 800; 000 words of the Penn Treebank Tagged WSJ corpus. About 550; 000 words were used for training and 250; 000 for testing.
Reference: <author> Roth, D. </author> <year> 1998. </year> <title> Learning to resolve natural language ambiguities:a unified approach. </title> <note> Long Version, in Preparation. </note>
Reference-contexts: This representation immediately implies that this predictor is optimal also in situations in which the conditional independence assumption does no hold. However, a more important consequence to our discussion here is the fact that not all linearly separable functions can be represented using this predictor <ref> (Roth 1998) </ref>. The back-off estimation (BO) Back-off estimation is another method for estimating the conditional probabilities P r (c i js). It has been used in many disambiguation tasks and in learning models for speech recognition (Katz 1987; Chen & Goodman 1996; Collins & Brooks 1995). <p> Fact 3: The VC dimension of the class of linear separators derived by either NB or BO over n variables is bounded below by n. Fact 1 is well known; 2 and 3 can be derived directly from the definition <ref> (Roth 1998) </ref>. The implication is that a method that merely searches for the optimal linear decision surface given the training data may, in general, outperform all these methods also on the test data. <p> In the study presented here, following (Brill 1995) and many other studies there are 47 different tags. Part-of-speech tagging suggests a special challenge to our approach, as the problem is a multi-class prediction problem <ref> (Roth & Zelenko 1998) </ref>. In the SNOW architecture, we devote one linear separator to each pos tag and each sub network learns to separate its corresponding pos tag from all others. At run time, all class nodes process the given sentence, applying many classifiers simultaneously. <p> The classifiers then compete for deciding the pos of this word, and the node that records the highest activity for a given word in a sentence determines its pos. The methods compared use 15 SNOW was evaluated with an enhanced feature set <ref> (Krymolovsky & Roth 1998) </ref> with improved results of 84.8%. (Collins & Brooks 1995) reports results of 84.4% on a different enhanced set of features, but other systems were not evaluated on these sets. Table 3: POS System comparison. The first column gives the number of test cases. <p> Each time the input to the predictors is expected to be slightly less noisy. In the results presented here, however, we present the performance without the recycling process, so that we maintain the linear function expressivity (see <ref> (Roth & Zelenko 1998) </ref> for details). The results presented in Table 3 are based on experiments using 800; 000 words of the Penn Treebank Tagged WSJ corpus. About 550; 000 words were used for training and 250; 000 for testing.
Reference: <author> Samuelsson, C. </author> <year> 1996. </year> <title> Handling sparse data by successive abstraction. </title> <booktitle> In Proc. of COLING. </booktitle>
Reference-contexts: The conditional probabilities on the right are empirical estimates measured on the training data, and the coefficients f are also estimated given the training data. (Usually, these are maximum likelihood estimates evaluated using iterative methods, e.g. <ref> (Samuelsson 1996) </ref>).
Reference: <author> Valiant, L. G. </author> <year> 1984. </year> <title> A theory of the learnable. </title> <journal> Communications of the ACM 27(11) </journal> <pages> 1134-1142. </pages>
Reference: <author> Valiant, L. G. </author> <year> 1994. </year> <title> Circuits of the Mind. </title> <publisher> Oxford University Press. </publisher>
Reference-contexts: While each of the target nodes is learned using a positive Winnow algorithm, a winner-take-all policy is used to determine the prediction. Thus, we do not use the learning algorithm here simply as a discriminator. One reason is that the SNOW architecture, influenced by the Neu-roidal system <ref> (Valiant 1994) </ref>, is being used in a system 13 Although for the purpose of the experimental study we do not update the network while testing. Table 1: Spell System comparison. The second column gives the number of test cases.
Reference: <author> Valiant, L. G. </author> <year> 1998. </year> <title> Projection learning. </title> <booktitle> In Proc. of the Annual ACM Workshop on Computational Learning Theory, </booktitle> <address> xxx-xxx. </address>
Reference-contexts: In addition, very few of the features in F are active in every example, yielding more efficient evaluation techniques (e.g., <ref> (Valiant 1998) </ref>) 11 This is hard to define in the context of natural language; typically, this is understood as texts of similar nature; see a discussion of this issue in (Golding & Roth 1996). In the absence of this knowledge a learning method merely attempts to make correct predictions.
Reference: <author> Vapnik, V. N. </author> <year> 1982. </year> <title> Estimation of Dependences Based on Empirical Data. </title> <address> New York: </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: This complexity is measured in terms of a combinatorial parameter the VC-dimension of the class H <ref> (Vapnik 1982) </ref> which measures the richness of the function class. (See (Vapnik 1995; Kearns & Vazirani 1992)) for details). We have shown that all the methods considered here look for a linear decision surface. However, they do make further assumptions which seem to restrict the function space they search in.
Reference: <author> Vapnik, V. N. </author> <year> 1995. </year> <title> The Nature of Statistical Learning Theory. </title> <address> New York: </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: However, all learning methods are statistical in the sense that they attempt to make inductive generalization from observed data and use it to make inferences with respect to previously unseen data; as such, the statistical based theories of learning <ref> (Vapnik 1995) </ref> apply equally to both. The difference may be that symbolic methods do not explicitly use probabilities in the hypothesis. To stress the equivalence of the approaches further in the following discussion we will analyze two "statistical" and two "symbolic" approaches.
Reference: <author> Yarowsky, D. </author> <year> 1994. </year> <title> Decision lists for lexical ambiguity resolution: application to accent restoration in Spanish and French. </title> <booktitle> In Proc. of the Annual Meeting of the ACL, </booktitle> <pages> 88-95. </pages>
Reference-contexts: Developing learning techniques for language disambiguation has been an active field in recent years and a number of statistics based and machine learning techniques have been proposed. A partial list consists of Bayesian classifiers (Gale, Church, & Yarowsky 1993), decision lists <ref> (Yarowsky 1994) </ref>, Bayesian hybrids (Golding 1995), HMMs (Charniak 1993), inductive logic methods (Zelle & Mooney 1996), memory-based methods (Zavrel, Daelemans, & Veenstra 1997) and transformation-based learning (Brill 1995).
Reference: <author> Yarowsky, D. </author> <year> 1995. </year> <title> Unsupervised word sense disambiguation rivaling supervised methods. </title> <booktitle> In Proceedings of ACL-95. </booktitle>
Reference-contexts: Decision Lists (p1-DL) It is easy to see (details omitted), that the above analysis applies to p1-DL, a method used, for example, in <ref> (Yarowsky 1995) </ref>. The BO and p1-DL differ only in that they keep the rules in reversed order, due to different evaluation methods.
Reference: <author> Zavrel, J.; Daelemans, W.; and Veenstra, J. </author> <year> 1997. </year> <title> Resolving pp attachment ambiguities with memory based learning. </title>
Reference-contexts: A partial list consists of Bayesian classifiers (Gale, Church, & Yarowsky 1993), decision lists (Yarowsky 1994), Bayesian hybrids (Golding 1995), HMMs (Charniak 1993), inductive logic methods (Zelle & Mooney 1996), memory-based methods <ref> (Zavrel, Daelemans, & Veenstra 1997) </ref> and transformation-based learning (Brill 1995). Most of these have been developed in the context of a specific task although claims have been made as to their applicativity to others.
Reference: <author> Zelle, J. M., and Mooney, R. J. </author> <year> 1996. </year> <title> Learning to parse database queries using inductive logic proramming. </title> <booktitle> In Proc. National Conference on Artificial Intelligence, </booktitle> <pages> 1050-1055. </pages>
Reference-contexts: A partial list consists of Bayesian classifiers (Gale, Church, & Yarowsky 1993), decision lists (Yarowsky 1994), Bayesian hybrids (Golding 1995), HMMs (Charniak 1993), inductive logic methods <ref> (Zelle & Mooney 1996) </ref>, memory-based methods (Zavrel, Daelemans, & Veenstra 1997) and transformation-based learning (Brill 1995). Most of these have been developed in the context of a specific task although claims have been made as to their applicativity to others.
References-found: 35

