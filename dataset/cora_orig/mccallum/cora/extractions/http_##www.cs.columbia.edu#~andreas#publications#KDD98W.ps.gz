URL: http://www.cs.columbia.edu/~andreas/publications/KDD98W.ps.gz
Refering-URL: http://www.cs.columbia.edu/~andreas/publications/publications.html
Root-URL: http://www.cs.columbia.edu
Email: fandreas,salg@cs.columbia.edu  
Title: Pruning Meta-Classifiers in a Distributed Data Mining System  
Author: Andreas L. Prodromidis and Salvatore J. Stolfo 
Address: 1214 Amsterdam Ave. 450 CSB New York, NY 10027  
Affiliation: Department of Computer Science Columbia University  
Abstract: JAM is a powerful and portable agent-based distributed data mining system that employs meta-learning techniques to integrate a number of independent classifiers (models) derived in parallel from independent and (possibly) inherently distributed databases. Although meta-learning promotes scalability and accuracy in a simple and straightforward manner, brute force meta-learning techniques can result in large, redundant, inefficient and some times inaccurate meta-classifier hierarchies. In this paper we explore several methods for evaluating classifiers and composing meta-classifiers, we expose their limitations and we demonstrate that meta-learning combined with certain pruning methods has the potential to achieve similar or even better performance results in a much more cost effective manner. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Ali, K., and Pazzani, M. </author> <year> 1996. </year> <title> Error reduction through learning multiple descriptions. </title> <booktitle> Machine Learning 24 </booktitle> <pages> 173-202. </pages>
Reference-contexts: Next, we focus on the diversity and specialty met-rics. Accuracy, correlation error and coverage are other metrics metrics explored in the literature. For example, Ali and Pazzani <ref> (Ali & Pazzani 1996) </ref> define correlation error as the fraction of instances for which a pair of classifiers make the same incorrect predictions and Brodley and Lane (Brodley & Lane 1996) measure coverage by computing the fraction of instances for which at least one of the classifiers produces the correct prediction. <p> classifiers. (When the predictions of the classifiers are distributed evenly across the possible classes, the entropy is higher and the set of classifiers more diverse.) Kwok and Carter (Kwok & Carter 1990) correlate the error rates of a set of decision trees to their syntactical diversity, while Ali and Pazzani <ref> (Ali & Pazzani 1996) </ref> studied the impact of the number of gain ties 4 on the accuracy of an ensemble of classifiers.
Reference: <author> Breiman, L.; Friedman, J. H.; Olshen, R. A.; and Stone, C. J. </author> <year> 1984. </year> <title> Classification and Regression Trees. </title> <address> Belmont, CA: </address> <publisher> Wadsworth. </publisher>
Reference-contexts: Experiments and Results Learning algorithms Five learning algorithms are used in our experiments. ID3, its successor C4.5, and Cart <ref> (Breiman et al. 1984) </ref> are decision tree algorithms, Bayes (Minksy & Papert 1969), is a naive Bayesian algorithm and Ripper (Cohen 1995) is a rule induction algorithm. Learning tasks Two data sets of real credit card transactions were used in our experiments provided by the Chase and First Union Banks.
Reference: <author> Breiman, L. </author> <year> 1996. </year> <title> Stacked regressions. </title> <booktitle> Machine Learning 24 </booktitle> <pages> 41-48. </pages>
Reference-contexts: The last section concludes the paper. Evaluating and Selecting Classifiers One can employ several different measures and methods to analyze and compare ensembles of classifiers. First, we summarize the previous and current research within the Machine Learning and KDD communities. Leo Breiman <ref> (Breiman 1996) </ref> and LeBlanc and Tib-shirani (LeBlanc & Tibshirani 1993) acknowledge the value of using multiple predictive models to increase accuracy, but they view the problem from a different perspective.
Reference: <author> Brodley, C., and Lane, T. </author> <year> 1996. </year> <title> Creating and exploiting coverage and diversity. In Work. </title> <booktitle> Notes AAAI-96 Workshop Integrating Multiple Learned Models, </booktitle> <pages> 8-14. </pages> <address> C.Brodley. </address> <year> 1993. </year> <title> Addressing the selective superiority problem: Automatic algorithm/model class selection. </title> <booktitle> In Proc. 10th Intl. Conf. Machine Learning, </booktitle> <pages> 17-24. </pages> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Accuracy, correlation error and coverage are other metrics metrics explored in the literature. For example, Ali and Pazzani (Ali & Pazzani 1996) define correlation error as the fraction of instances for which a pair of classifiers make the same incorrect predictions and Brodley and Lane <ref> (Brodley & Lane 1996) </ref> measure coverage by computing the fraction of instances for which at least one of the classifiers produces the correct prediction.
Reference: <author> Chan, P., and Stolfo, S. </author> <year> 1993. </year> <title> Meta-learning for mul-tistrategy and parallel learning. </title> <booktitle> In Proc. Second Intl. Work. Multistrategy Learning, </booktitle> <pages> 150-165. </pages>
Reference-contexts: We call the problem of learning useful new information from large and inherently distributed databases, the scaling problem for machine learning. Meta-learning <ref> (Chan & Stolfo 1993) </ref>, a technique similar to stacking (Wolpert 1992), was developed recently to deal with the scaling problem.
Reference: <author> Chan, P., and Stolfo, S. </author> <year> 1996. </year> <title> Sharing learned models among remote database partitions by local meta-learning. </title> <booktitle> In Proc. Second Intl. Conf. Knowledge Discovery and Data Mining, </booktitle> <pages> 2-7. </pages>
Reference-contexts: Retaining a large number of base classifiers and meta-classifiers may not be practical nor feasible. Meta classifiers are defined recursively as collections of classifiers structured in multi-level trees <ref> (Chan & Stolfo 1996) </ref>, hence determining the optimal set of classifiers is a combinatorial problem. <p> Diversity Brodley (C.Brodley 1993) defines diversity by measuring the classification overlap of a pair of classifiers, i.e. the percentage of the instances classified the same way by two classifiers, while Chan <ref> (Chan 1996) </ref> associates it with the entropy in the predictions of the base classifiers. (When the predictions of the classifiers are distributed evenly across the possible classes, the entropy is higher and the set of classifiers more diverse.) Kwok and Carter (Kwok & Carter 1990) correlate the error rates of a
Reference: <author> Chan, P. </author> <year> 1996. </year> <title> An Extensible Meta-Learning Approach for Scalable and Accurate Inductive Learning. </title> <type> Ph.D. Dissertation, </type> <institution> Department of Computer Science, Columbia University, </institution> <address> New York, NY. </address>
Reference-contexts: Retaining a large number of base classifiers and meta-classifiers may not be practical nor feasible. Meta classifiers are defined recursively as collections of classifiers structured in multi-level trees <ref> (Chan & Stolfo 1996) </ref>, hence determining the optimal set of classifiers is a combinatorial problem. <p> Diversity Brodley (C.Brodley 1993) defines diversity by measuring the classification overlap of a pair of classifiers, i.e. the percentage of the instances classified the same way by two classifiers, while Chan <ref> (Chan 1996) </ref> associates it with the entropy in the predictions of the base classifiers. (When the predictions of the classifiers are distributed evenly across the possible classes, the entropy is higher and the set of classifiers more diverse.) Kwok and Carter (Kwok & Carter 1990) correlate the error rates of a
Reference: <author> Cohen, W. </author> <year> 1995. </year> <title> Fast effective rule induction. </title> <booktitle> In Proc. 12th Intl. Conf. Machine Learning, </booktitle> <pages> 115-123. </pages>
Reference-contexts: Experiments and Results Learning algorithms Five learning algorithms are used in our experiments. ID3, its successor C4.5, and Cart (Breiman et al. 1984) are decision tree algorithms, Bayes (Minksy & Papert 1969), is a naive Bayesian algorithm and Ripper <ref> (Cohen 1995) </ref> is a rule induction algorithm. Learning tasks Two data sets of real credit card transactions were used in our experiments provided by the Chase and First Union Banks. The two sets contain .5 million of credit card transactions labeled as fraudulent or legitimate spanning one year.
Reference: <author> Dietterich, T. </author> <year> 1997. </year> <title> Machine learning research: Four current directions. </title> <journal> AI Magazine 18(4) </journal> <pages> 97-136. </pages>
Reference-contexts: In fact, the performance of sub-optimal yet diverse models can be substantially improved when combined together and even surpass that 3 Very similar to Principal Component Analysis of the best single models. In other related work, Margineantu and Diet-terich <ref> (Margineantu & Dietterich 1997) </ref> studied the problem of pruning the ensemble of classifiers (i.e. the set of hypothesis (classifiers)) obtained by the boosting algorithm ADABOOST (Freund & Schapire 1996).
Reference: <author> E.R.Carson, and U.Fischer. </author> <year> 1990. </year> <title> Models and computers in diabetes research and diabetes care. Computer methods and programs in biomedicine, </title> <note> special issue 32. </note>
Reference: <author> Freund, Y., and Schapire, R. </author> <year> 1996. </year> <title> Experiments with a new boosting algorithm. </title> <booktitle> In Proc. Thirteenth Conf. Machine Learning, </booktitle> <pages> 148-156. </pages>
Reference-contexts: In other related work, Margineantu and Diet-terich (Margineantu & Dietterich 1997) studied the problem of pruning the ensemble of classifiers (i.e. the set of hypothesis (classifiers)) obtained by the boosting algorithm ADABOOST <ref> (Freund & Schapire 1996) </ref>. According to their findings, by examining the diversity and accuracy of the available classifiers, it is possible for a subset of classifiers to achieve similar levels of performance as the entire set. <p> As we have already noted, the more diverse the set of base-classifiers is, the more room for improvement the meta-classifier has. For example, to obtain diverse classifiers from a single learning program Freund and Schapire <ref> (Freund & Schapire 1996) </ref> introduced the boosting algorithm for re-sampling the data set to artificially generate diverse training subsets. In our experiments, the diversity of the base classifiers is attributed, first, to the use of disparate learning algorithms, and second, to the degree the training sets are different.
Reference: <author> Hansen, L., and Salamon, P. </author> <year> 1990. </year> <title> Neural network ensembles. </title> <journal> IEEE Trans. Pattern Analysis and Mach. Itell. </journal> <volume> 12 </volume> <pages> 993-1001. </pages>
Reference: <author> K.Lang. </author> <year> 1995. </year> <title> News weeder: Learning to filter net news. </title> <editor> In A.Prieditis, and S.Russel., eds., </editor> <booktitle> Proc. 12th Intl. Conf. Machine Learning, </booktitle> <pages> 331-339. </pages> <publisher> Morgan Kauf-mann. </publisher>
Reference-contexts: driving autonomously on highways at 70 miles/hour (Pomerleau 1992), in predicting stock option pricing (M.Malliaris fl Supported in part by an IBM fellowship This research is supported by the Intrusion Detection Program (BAA9603) from DARPA (F30602-96-1-0311), NSF (IRI-96-32225, CDA-96-25374) and NYSSTF (423115-445). & L.Salchenberger 1993) and in customized electronic newspapers <ref> (K.Lang 1995) </ref> to name a few applications. Large businesses and market analysis firms attempt to distinguish the low-risk (high profit) potential customers by learning simple categorical classifications of their customer database. <p> Experiments and Results Learning algorithms Five learning algorithms are used in our experiments. ID3, its successor C4.5, and Cart (Breiman et al. 1984) are decision tree algorithms, Bayes (Minksy & Papert 1969), is a naive Bayesian algorithm and Ripper <ref> (Cohen 1995) </ref> is a rule induction algorithm. Learning tasks Two data sets of real credit card transactions were used in our experiments provided by the Chase and First Union Banks. The two sets contain .5 million of credit card transactions labeled as fraudulent or legitimate spanning one year.
Reference: <author> Kwok, S., and Carter, C. </author> <year> 1990. </year> <title> Multiple decision trees. </title> <booktitle> In Uncertainty in Aritificial Intelligence 4, </booktitle> <pages> 327-335. </pages>
Reference-contexts: classified the same way by two classifiers, while Chan (Chan 1996) associates it with the entropy in the predictions of the base classifiers. (When the predictions of the classifiers are distributed evenly across the possible classes, the entropy is higher and the set of classifiers more diverse.) Kwok and Carter <ref> (Kwok & Carter 1990) </ref> correlate the error rates of a set of decision trees to their syntactical diversity, while Ali and Pazzani (Ali & Pazzani 1996) studied the impact of the number of gain ties 4 on the accuracy of an ensemble of classifiers.
Reference: <author> LeBlanc, M., and Tibshirani, R. </author> <year> 1993. </year> <title> Combining estimates in regression and classification. </title> <type> Technical Report 9318, </type> <institution> Department of Statistics, University of Toronto, Toronto, </institution> <note> ON. </note>
Reference-contexts: The last section concludes the paper. Evaluating and Selecting Classifiers One can employ several different measures and methods to analyze and compare ensembles of classifiers. First, we summarize the previous and current research within the Machine Learning and KDD communities. Leo Breiman (Breiman 1996) and LeBlanc and Tib-shirani <ref> (LeBlanc & Tibshirani 1993) </ref> acknowledge the value of using multiple predictive models to increase accuracy, but they view the problem from a different perspective. They rely on cross-validation data and analytical methods, (e.g. least squares regression), to estimate the best linear combination of the available hypotheses (models).
Reference: <author> Margineantu, D., and Dietterich, T. </author> <year> 1997. </year> <title> Pruning adaptive boosting. </title> <booktitle> In Proc. Fourteenth Intl. Conf. Machine Learning, </booktitle> <pages> 211-218. </pages>
Reference-contexts: In fact, the performance of sub-optimal yet diverse models can be substantially improved when combined together and even surpass that 3 Very similar to Principal Component Analysis of the best single models. In other related work, Margineantu and Diet-terich <ref> (Margineantu & Dietterich 1997) </ref> studied the problem of pruning the ensemble of classifiers (i.e. the set of hypothesis (classifiers)) obtained by the boosting algorithm ADABOOST (Freund & Schapire 1996).
Reference: <author> Merz, C. </author> <year> 1998. </year> <title> Using correspondence analysis to combine classifiers. </title> <journal> Machine Learning. </journal> <note> to appear. </note>
Reference-contexts: Meta-learning has the advantage of employing an arbitrary learning algorithm for computing non-linear relations among the classifiers (at the expense, perhaps, of generating less intuitive representations). In a related study, Merz's SCAN N algorithm <ref> (Merz 1998) </ref> employs correspondence analysis 3 to map the predictions of the available classifiers onto a new scaled space that clusters similar prediction behaviors and then uses the nearest neighbor algorithm to meta-learn the transformed predictions of the individual classifiers.
Reference: <author> Michalski, R. </author> <year> 1983. </year> <title> A theory and methodology of inductive learning. </title> <editor> In Michalski, R.; Carbonell, J.; and Mitchell, T., eds., </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach. </booktitle> <publisher> Morgan Kaufmann. </publisher> <pages> 83-134. </pages>
Reference-contexts: Defense and intelligence operations utilize similar methodologies on vast information sources to predict a wide range of conditions in various contexts. Machine learning or Inductive learning (or learning from examples <ref> (Michalski 1983) </ref>) aims to identify regularities in a given set of training examples with little or no knowledge about the domain from which the examples are drawn.
Reference: <author> Minksy, M., and Papert, S. </author> <year> 1969. </year> <title> Perceptrons: An Introduction to Computation Geometry. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher> <address> (Expanded edition, </address> <year> 1988). </year>
Reference-contexts: Experiments and Results Learning algorithms Five learning algorithms are used in our experiments. ID3, its successor C4.5, and Cart (Breiman et al. 1984) are decision tree algorithms, Bayes <ref> (Minksy & Papert 1969) </ref>, is a naive Bayesian algorithm and Ripper (Cohen 1995) is a rule induction algorithm. Learning tasks Two data sets of real credit card transactions were used in our experiments provided by the Chase and First Union Banks.
Reference: <author> Mitchell, T. </author> <year> 1982. </year> <title> Generalization as search. </title> <booktitle> Artificial Intelligence 18 </booktitle> <pages> 203-226. </pages>
Reference-contexts: Meta-learning, is scalable because meta-classifiers are classifiers that can be similarly combined into higher level meta-classifiers in a distributed fashion. Furthermore, it improves accuracy by combining classifiers with inductive bias (e.g representation, search heuristics, search space) <ref> (Mitchell 1982) </ref>. By combining separately learned classifiers, meta-learning is expected to derive a higher level model that explains a large database more accurately than any individual learner. The JAM system (Java Agents for Meta-learning) (Stolfo et al. 1997b) is a distributed agent-based data mining system that implements meta-learning.
Reference: <author> Mitchell, T. M. </author> <year> 1997. </year> <title> Does machine learning really work? AI Magazine 18(3) </title> <type> 11-20. </type> <institution> M.Malliaris, and L.Salchenberger. </institution> <year> 1993. </year> <title> A neural network model for estimating option prices. </title> <booktitle> Applied Intelligence </booktitle> 3(3):193-206. 
Reference-contexts: Over the past decade, machine learning has evolved from a field of laboratory demonstrations to a field of significant commercial value <ref> (Mitchell 1997) </ref>.
Reference: <author> Pomerleau, D. </author> <year> 1992. </year> <title> Neural network perception for mobile robot guidance. </title> <type> Ph.D. Dissertation, </type> <institution> School of Computer Sci., Carnegie Mellon Univ., Pittsburgh, PA. </institution> <type> (Tech. Rep. </type> <institution> CMU-CS-92-115). </institution>
Reference-contexts: Machine-learning algorithms have been deployed in heart disease diagnosis (R.Detrano et al. 1989) and, in predicting glucose levels for diabetics (E.R.Carson & U.Fischer 1990), in detecting credit card fraud (Stolfo et al. 1997a), in steering vehicles driving autonomously on highways at 70 miles/hour <ref> (Pomerleau 1992) </ref>, in predicting stock option pricing (M.Malliaris fl Supported in part by an IBM fellowship This research is supported by the Intrusion Detection Program (BAA9603) from DARPA (F30602-96-1-0311), NSF (IRI-96-32225, CDA-96-25374) and NYSSTF (423115-445). & L.Salchenberger 1993) and in customized electronic newspapers (K.Lang 1995) to name a few applications.
Reference: <author> Prodromidis, A. L. </author> <year> 1997. </year> <title> On the management of distributed learning agents. </title> <type> Technical Report CUCS-032-97 (PhD Thesis proposal), </type> <institution> Department of Computer Science, Columbia University, </institution> <address> New York, NY. </address>
Reference: <author> Provost, F., and Fawcett, T. </author> <year> 1997. </year> <title> Analysis and visualization of classifier performance: Comparison under imprecise class and cost distributions. </title> <booktitle> In Proc. Third Intl. Conf. Knowledge Discovery and Data Mining, </booktitle> <pages> 43-48. </pages>
Reference-contexts: Furthermore, the pruning methods presented in this paper preceed the meta-learning phase and, as such, can be used in conjunction with SCAN N or any other algorithm if computational constraints pose no problem. Provost and Fawcett <ref> (Provost & Fawcett 1997) </ref> introduced the ROC convex hull method for its intuitiveness and flexibility. The method evaluates models for binary classification problems, by mapping them onto a True Positive/False Positive plane and by allowing comparisons under different metrics (TP/FP rates, accuracy, cost, etc.). <p> In comparing the classifiers, one can replace the (T P F P ) spread, which defines a certain family of curves in the ROC plot, with a different metric or even with a complete analysis <ref> (Provost & Fawcett 1997) </ref> in the ROC space.
Reference: <author> Quinlan, J. R. </author> <year> 1986. </year> <title> Induction of decision trees. </title> <booktitle> Machine Learning 1 </booktitle> <pages> 81-106. </pages>
Reference: <author> Quinlan, J. R. </author> <year> 1993. </year> <title> C4.5: programs for machine learning. </title> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher> <editor> R.Detrano; A.Janosi; W.Steinbrunn; M.Pfisterer; J.Schmid; S.Sandhu; K.Guppy; S.Lee; and V.Froelicher. </editor> <year> 1989. </year> <title> International application of a new probability algorithm for the diagnosis of coronary artery disease. </title> <journal> American Journal of Cardiology 64 </journal> <pages> 304-310. </pages>
Reference: <author> Stolfo, S.; Fan, W.; Lee, W.; Prodromidis, A.; and Chan, P. </author> <year> 1997a. </year> <title> Credit card fraud detection using meta-learning: Issues and initial results. </title> <booktitle> Working notes of AAAI Workshop on AI Approaches to Fraud Detection and Risk Management. </booktitle>
Reference-contexts: Machine-learning algorithms have been deployed in heart disease diagnosis (R.Detrano et al. 1989) and, in predicting glucose levels for diabetics (E.R.Carson & U.Fischer 1990), in detecting credit card fraud <ref> (Stolfo et al. 1997a) </ref>, in steering vehicles driving autonomously on highways at 70 miles/hour (Pomerleau 1992), in predicting stock option pricing (M.Malliaris fl Supported in part by an IBM fellowship This research is supported by the Intrusion Detection Program (BAA9603) from DARPA (F30602-96-1-0311), NSF (IRI-96-32225, CDA-96-25374) and NYSSTF (423115-445). & L.Salchenberger <p> For example, one possible approach would be to combine the (base-) classifiers with high coverage and low correlation error. In another study <ref> (Stolfo et al. 1997a) </ref> concerning credit card fraud detection we employed evaluation formulas for selecting classifiers that are based on diversity, coverage and correlated error and their combinations. Pruning algorithms Pruning refers to the evaluation and selection of classifiers before they are used for the training of the meta-classifier.
Reference: <author> Stolfo, S.; Prodromidis, A.; Tselepis, S.; Lee, W.; Fan, W.; and Chan, P. </author> <year> 1997b. </year> <title> JAM: Java agents for meta-learning over distributed databases. </title> <booktitle> In Proc. 3rd Intl. Conf. Knowledge Discovery and Data Mining, </booktitle> <pages> 74-81. </pages>
Reference-contexts: By combining separately learned classifiers, meta-learning is expected to derive a higher level model that explains a large database more accurately than any individual learner. The JAM system (Java Agents for Meta-learning) <ref> (Stolfo et al. 1997b) </ref> is a distributed agent-based data mining system that implements meta-learning.
Reference: <author> Wolpert, D. </author> <year> 1992. </year> <title> Stacked generalization. </title> <booktitle> Neural Networks 5 </booktitle> <pages> 241-259. </pages>
Reference-contexts: We call the problem of learning useful new information from large and inherently distributed databases, the scaling problem for machine learning. Meta-learning (Chan & Stolfo 1993), a technique similar to stacking <ref> (Wolpert 1992) </ref>, was developed recently to deal with the scaling problem. The basic idea is to execute a number of machine learning processes on a number of data subsets in parallel, and then to combine their collective results (classifiers) through an additional phase of learning.
References-found: 29

