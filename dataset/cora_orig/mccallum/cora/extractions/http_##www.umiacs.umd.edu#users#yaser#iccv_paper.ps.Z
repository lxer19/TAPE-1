URL: http://www.umiacs.umd.edu/users/yaser/iccv_paper.ps.Z
Refering-URL: http://www.cs.gatech.edu/computing/classes/cs7322_98_spring/readings.html
Root-URL: 
Email: yaser@umiacs.umd.edu, black@parc.xerox.com  
Title: Parameterized Modeling and Recognition of Activities  
Author: Yaser Yacoob Michael J. Black 
Address: College Park, MD 20742  3333 Coyote Hill Road, Palo Alto, CA 94304  
Affiliation: Computer Vision Laboratory, University of Maryland,  Xerox Palo Alto Research Center,  
Note: To Appear in ICCV-98, Mumbai-India, Subject to IEEE Copy-Rights  
Abstract: A framework for modeling and recognition of temporal activities is proposed. The modeling of sets of exemplar activities is achieved by parameterizing their representation in the form of principal components. Recognition of spatio-temporal variants of modeled activities is achieved by parameterizing the search in the space of admissible transformations that the activities can undergo. Experiments on recognition of articulated and deformable object motion from image motion parameters are presented. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Allmen and C.R. Dyer. </author> <title> Cyclic Motion Detection Using Spatiotemporal Surfaces and Curves, </title> <address> ICPR, </address> <year> 1990, </year> <pages> 365-370. </pages>
Reference-contexts: and scaled version of an instance of one of the modeled activities. 2 Previous Work Approaches that have been recently employed for modeling and recognizing activities can be divided into data-fitting (e.g., neural networks [14], Dynamic Time Warping (DTW) [7, 8], and regression [12]) feature localization (e.g., scale-space curve analysis <ref> [1, 13] </ref>) and statistical approaches (e.g., Hidden Markov Models (HMMs) [11, 15]). It is common in these approaches to develop a separate model for each activity, match an observed activity to all models and choose the model that explains it best.
Reference: [2] <author> M. Black and P. Anandan. </author> <title> The robust estimation of multiple motions: Parametric and piecewise-smooth flow fields. </title> <booktitle> Computer Vision and Image Understanding, </booktitle> <volume> 63(1), </volume> <year> 1996, </year> <pages> 75-104. </pages>
Reference-contexts: Equation (4) can be approximated as E (c; a) = j=1 q X c l U l;j ; ) Equation (6) can be minimized with respect to a and c using a gradient descent scheme with a continuation method that gradually lowers (see <ref> [2] </ref>). Initial projection of the observation on the eigenspace provides a set of coefficients c that are used to determine an initial estimate of a that is used to warp the observation into the eigenspace. The algorithm alternately minimizes the errors of the eigenspace parameterization and the transformation parameterization. <p> The training set for this experiment consists of 130 image sequences containing a single speaker who utters thirteen letters ten times (Figure 8). The duration of each utterance is 25 frames. We computed the image motion for each sequence in the training set using a robust optical flow algorithm <ref> [2] </ref>. The robust method is essential as it allows violations of the brightness constancy assumption that occur due to the appearance/disappearance of the teeth, tongue, and mouth cavity. We then randomly chose a subset of 793 flow fields from the training set of 3120 flow fields and de Horizontal trans.
Reference: [3] <author> M. J. Black and A. Jepson. EigenTracking: </author> <title> Robust matching and tracking of articulated objects using a view-based representation. </title> <booktitle> Proc. ECCV , 1996, </booktitle> <pages> 328-342. </pages>
Reference-contexts: Let also [D] j denote the j-th (j = 1::nT) element of the vector [D]. By projecting this vector on the activity basis we recover a vector of coefficients, c, that approximates the activity as a linear combination of activity basis. Black and Jepson <ref> [3] </ref> recently pointed out that projection gives a least squares fit which is not robust. Instead, they employed robust regression to minimize the matching error in an eigenspace of intensity images. <p> This robustness is effective in coping with random or structured noise. Black and Jepson <ref> [3] </ref> also parameterized the search to allow an affine transformation of the observation to be used to improve the matching between images and principal images. In our context, a similar transformation allows an observation to be better matched to the exemplars. <p> To deal with larger transformations a coarse-to-fine strategy can be used to compute the coefficients and transformation parameters at coarse resolution and project their values to finer resolutions similar to what is described in <ref> [3] </ref>. This coarse-to-fine strategy does not eliminate the need for approximate localization of the curves even at coarse levels.
Reference: [4] <author> M. J. Black, Y. Yacoob, A. Jepson, and D. </author> <title> Fleet. Learning parameterized models of image motion. </title> <booktitle> Proc. </booktitle> <address> CVPR, Puerto Rico, </address> <month> June </month> <year> 1997. </year>
Reference-contexts: They account for 90% of the variance in the 3120 training flow fields. rived a low-dimensional representation using principal component analysis (for a detailed description see <ref> [4] </ref>). Since the image motion of the mouth in our training sequence is constrained, much of the information in the training flow fields is redundant and hence the singular values drop off quickly. <p> Image motion is represented as a linear combination of the basis flow templates: P 8 flow template defined over a fixed rectangular region). Using this model, we estimate the motion coefficients m i as described in <ref> [4] </ref>. We then use the eight motion coefficients computed between consecutive images to construct a joint temporal model for the letters. We consider each spoken letter to be an activity of 25 frames in duration where eight measurements are computed at each time instant. <p> linear combination of the motion Letter A Letter B Letter C Letter D Letter E Letter F Letter G Letter H Letter I Letter J Letter K Letter L Letter M Variation captured basis vectors of the 130 sequences (bottom left graph) templates that best describes the intensity variation (see <ref> [4] </ref>) and use these parameters in recognition. The confusion matrix for the test sequences is shown in Table 4. The columns indicate the recognized letter relative to the correct one. Each column sums to 10, the number of each letter's utterances.
Reference: [5] <author> A. Bobick and A. Wilson. </author> <title> A state-based technique for the summarization and recognition of gesture. </title> <booktitle> ICCV , 1995, </booktitle> <pages> 382-388. </pages>
Reference: [6] <author> A. Bobick and J. Davis. </author> <title> An appearance-based representation of action. </title> <address> ICPR, </address> <year> 1996, </year> <pages> 307-312. </pages>
Reference-contexts: This representation is amenable to matching by global transforms (such as the affine transformation we consider). Also, this global feature allows recognition based on partial or corrupted data (including missing beginning and ending). The most closely related work to the work reported here is that of Bobick and Davis <ref> [6] </ref> and Ju et al. [9], both proposed using principal component analysis to model parameters computed from activities but did not demonstrate modeling and recognition of activities. <p> The objective here is to demonstrate that a correct classification of the direction of walking of the subjects can be achieved. Since the change in motion trajectories with the change of viewpoint is smooth (see <ref> [6] </ref>) we use four primary directions in the recognition tabulation. the principal components for a single person's walking as viewed from ten different viewing directions. The angles include walking perpendicular to the camera (towards and away from it).
Reference: [7] <author> T. Darrell and A. Pentland. </author> <title> Space-time gestures. </title> <booktitle> Proc. </booktitle> <volume> CVPR 93, </volume> <pages> 335-340. </pages>
Reference-contexts: of the figure shows an observed activity that is a translated and scaled version of an instance of one of the modeled activities. 2 Previous Work Approaches that have been recently employed for modeling and recognizing activities can be divided into data-fitting (e.g., neural networks [14], Dynamic Time Warping (DTW) <ref> [7, 8] </ref>, and regression [12]) feature localization (e.g., scale-space curve analysis [1, 13]) and statistical approaches (e.g., Hidden Markov Models (HMMs) [11, 15]).
Reference: [8] <author> D.M. Gavrila and L.S. Davis. </author> <title> Towards 3-D model-based tracking and recognition of human movement: a multi-view approach. </title> <booktitle> Proc. Workshop on Face and Gesture, </booktitle> <year> 1995, </year> <pages> 272-277. </pages>
Reference-contexts: of the figure shows an observed activity that is a translated and scaled version of an instance of one of the modeled activities. 2 Previous Work Approaches that have been recently employed for modeling and recognizing activities can be divided into data-fitting (e.g., neural networks [14], Dynamic Time Warping (DTW) <ref> [7, 8] </ref>, and regression [12]) feature localization (e.g., scale-space curve analysis [1, 13]) and statistical approaches (e.g., Hidden Markov Models (HMMs) [11, 15]).
Reference: [9] <author> S. X. Ju, M. Black, and Y. Yacoob. </author> <title> Cardboard people: A parameterized model of articulated image motion. </title> <booktitle> Proc. Int. Conference on Face and Gesture, </booktitle> <address> Vermont, </address> <year> 1996, </year> <pages> 561-567. </pages>
Reference-contexts: Also, this global feature allows recognition based on partial or corrupted data (including missing beginning and ending). The most closely related work to the work reported here is that of Bobick and Davis [6] and Ju et al. <ref> [9] </ref>, both proposed using principal component analysis to model parameters computed from activities but did not demonstrate modeling and recognition of activities. <p> The exemplar activity coefficients that score the smallest distance is considered the best match to the observed activity. 5 Experiments 5.1 Modeling and Recognition of Walking We employ a recently proposed approach for tracking human motion using parameterized optical flow <ref> [9] </ref>. This approach assumes that an initial segmentation of the body into parts is given and tracks the motion of each part using a chain-like model that exploits the attachments between parts to achieve tracking of body parts in the presence of non-rigid deformations of clothing that cover the parts. <p> Let D (t) be the n dimensional signals of an observed activity. A total of five body parts (arm, torso, thigh, calf and foot) were tracked using 8 motion parameters for each part (i.e., n=40). In <ref> [9] </ref> the observation that the following transformation does not change the activity D (t) was made, S fl D (fft + L) This transformation captures the temporal translation, L, of the curve and the scaling, S, in the magnitude of the signal in addition to the speedup factor ff.
Reference: [10] <author> N. Li, S. Dettmer, and M. Shah. </author> <title> Visually recognizing speech using eigensequences. </title> <editor> M. Shah and R. Jain (Eds.), </editor> <booktitle> Motion-Based Recognition, </booktitle> <publisher> Klwer Academic Publishing, </publisher> <year> 1997, </year> <pages> 345-371. </pages>
Reference-contexts: The most closely related work to the work reported here is that of Bobick and Davis [6] and Ju et al. [9], both proposed using principal component analysis to model parameters computed from activities but did not demonstrate modeling and recognition of activities. Also, Li et al. <ref> [10] </ref> proposed a PCA-based modeling and recognition approach of whole image sequences of speech. 3 Modeling Activities Activities will be represented using examples from various activity classes (walking, running etc.). Each example consists of a set of signals.
Reference: [11] <author> C. Morimoto, Y. Yacoob and L.S. Davis. </author> <title> Recognition of head gestures using Hidden Markov Models International Conference on Pattern Recognition, </title> <address> Vienna, Austria, </address> <month> August </month> <year> 1996, </year> <pages> 461-465. </pages>
Reference-contexts: modeled activities. 2 Previous Work Approaches that have been recently employed for modeling and recognizing activities can be divided into data-fitting (e.g., neural networks [14], Dynamic Time Warping (DTW) [7, 8], and regression [12]) feature localization (e.g., scale-space curve analysis [1, 13]) and statistical approaches (e.g., Hidden Markov Models (HMMs) <ref> [11, 15] </ref>). It is common in these approaches to develop a separate model for each activity, match an observed activity to all models and choose the model that explains it best.
Reference: [12] <author> S.A. Niyogi and E.H. Adelson. </author> <title> "Analyzing and recognizing walking figures in XYT." </title> <address> CVPR, </address> <year> 1994, </year> <pages> 469-474. </pages>
Reference-contexts: an observed activity that is a translated and scaled version of an instance of one of the modeled activities. 2 Previous Work Approaches that have been recently employed for modeling and recognizing activities can be divided into data-fitting (e.g., neural networks [14], Dynamic Time Warping (DTW) [7, 8], and regression <ref> [12] </ref>) feature localization (e.g., scale-space curve analysis [1, 13]) and statistical approaches (e.g., Hidden Markov Models (HMMs) [11, 15]). It is common in these approaches to develop a separate model for each activity, match an observed activity to all models and choose the model that explains it best.
Reference: [13] <author> K. Rangarajan, W. Allen and M. Shah. </author> <title> Matching motion trajectories using scale-space. </title> <journal> Pattern recognition, </journal> <volume> 26(4), </volume> <year> 1993, </year> <pages> 595-610. </pages>
Reference-contexts: and scaled version of an instance of one of the modeled activities. 2 Previous Work Approaches that have been recently employed for modeling and recognizing activities can be divided into data-fitting (e.g., neural networks [14], Dynamic Time Warping (DTW) [7, 8], and regression [12]) feature localization (e.g., scale-space curve analysis <ref> [1, 13] </ref>) and statistical approaches (e.g., Hidden Markov Models (HMMs) [11, 15]). It is common in these approaches to develop a separate model for each activity, match an observed activity to all models and choose the model that explains it best.
Reference: [14] <author> M. Rosenblum, Y. Yacoob and L.S. Davis. </author> <title> Human Expression Recognition from Motion Using a Radial Basis Function Network Architecture, </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> Vol. 7, No. 5, </volume> <year> 1996, </year> <pages> 1121-1138. </pages>
Reference-contexts: The left side of the figure shows an observed activity that is a translated and scaled version of an instance of one of the modeled activities. 2 Previous Work Approaches that have been recently employed for modeling and recognizing activities can be divided into data-fitting (e.g., neural networks <ref> [14] </ref>, Dynamic Time Warping (DTW) [7, 8], and regression [12]) feature localization (e.g., scale-space curve analysis [1, 13]) and statistical approaches (e.g., Hidden Markov Models (HMMs) [11, 15]).
Reference: [15] <author> T. Starner and A. Pentland. </author> <title> Visual Recognition of American Sign Language Using Hidden Markov Models. </title> <booktitle> In International Workshop on Automatic Face and Gesture Recognition, </booktitle> <year> 1995, </year> <pages> 189-194. </pages>
Reference-contexts: modeled activities. 2 Previous Work Approaches that have been recently employed for modeling and recognizing activities can be divided into data-fitting (e.g., neural networks [14], Dynamic Time Warping (DTW) [7, 8], and regression [12]) feature localization (e.g., scale-space curve analysis [1, 13]) and statistical approaches (e.g., Hidden Markov Models (HMMs) <ref> [11, 15] </ref>). It is common in these approaches to develop a separate model for each activity, match an observed activity to all models and choose the model that explains it best.
References-found: 15

