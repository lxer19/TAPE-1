URL: http://www.cs.cmu.edu/afs/cs/user/fp/courses/95-lp/papers/vanroy-paper.ps
Refering-URL: http://www.cs.cmu.edu/afs/cs/user/fp/courses/95-lp/papers/
Root-URL: 
Title: 36  The Wonder Years of Sequential Prolog Implementation  
Author: Peter Van Roy 
Date: December 1993  1983-1993:  
Affiliation: PARIS RESEARCH LABORATORY  
Abstract-found: 0
Intro-found: 1
Reference: 1. <author> Abderrahmane Aggoun and Nicolas Beldiceanu. </author> <title> Time Stamps Techniques for the Trailed Data in Constraint Logic Programming Systems. In Actes du S eminaire 1990-Programmation en Logique, </title> <address> CNET, Tregastel, France, </address> <month> May </month> <year> 1990. </year>
Reference-contexts: For more complex constraints, the condition is wasteful because a variable's value is often modified several times between two choice points. The CHIP system reduces memory usage by introducing a different trail condition called time-stamping <ref> [1] </ref>. Each data term is marked with an identifier of the choice point segment the term belongs to (see Section 2.3.1). Trailing is only necessary if the current choice point segment is different from the segment stored in the term. <p> System Machine (Year) Clock Benchmark (MHz) N Q D S R mean yPLM compiler [148] PLM [43] (1985) 10. 19 12 9 12 8 11 ESP PSI-II (1986) 6.45 41 25 12 18 10 16 KCM-SEPIA [112] KCM (1989) 12.5 83 57 37 33 15 32 yPegasus compiler [125] Pegasus-II <ref> (1990) </ref> 10. 91 69 39 40 19 39 yAquarius [63] VLSI-BAM (1991) 20. 270 260 75 57 32 72 Machine (Architecture) zDEC-10 Prolog [159] DEC-10 (1977) 1 1 1 1 1 1 XSB 1.3 SPARCstation 1+ (SPARC) 25 7 4 2 4 3 3 Quintus 2.0 [63] Sun 3/60 (MC68020) 20
Reference: 2. <author> Abderrahmane Aggoun and Nicolas Beldiceanu. </author> <title> Overview of the CHIP Compiler System. </title> <booktitle> In 8th ICLP, </booktitle> <pages> pages 775-789, </pages> <publisher> MIT Press, </publisher> <month> June </month> <year> 1991. </year>
Reference-contexts: CHIP constraint system, which interfaces the WAM with three constraint solvers. * The clp (FD) constraint system, which implements a glass box approach that allows constraint solvers to be written at the user level. * The SLG-WAM, which extends the WAM with memoization. 2.3.1 CHIP CHIP (Constraint Handling In Prolog) <ref> [2] </ref> is a constraint logic language developed at ECRC (see Section 3.1.7 for more information on ECRC). The system has been commercialized by Cosytec to solve industrial optimization problems. CHIP is the first compiled constraint language.
Reference: 3. <author> Alfred V. Aho, Ravi Sethi, and Jeffrey D. Ullman. </author> <booktitle> Compilers: Principles, Techniques, and Tools. </booktitle> <publisher> Addison-Wesley, </publisher> <year> 1986. </year>
Reference-contexts: This section concisely explains the original WAM. In particular, the many optimizations of the WAM are given a uniform justification. This section assumes a basic knowledge of how Prolog executes [85, 115, 130] and of how imperative languages are compiled <ref> [3] </ref>. For several years, Warren's report was the sole source of information on the WAM, and its terse style gave the WAM an aura of inscrutability. Many people learned the WAM by osmosis, gradually absorbing its meaning.
Reference: 4. <author> Hassan At-Kaci. </author> <title> Warren's Abstract Machine, A Tutorial Reconstruction. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1991. </year>
Reference-contexts: Many people learned the WAM by osmosis, gradually absorbing its meaning. Nowadays, there are texts that give lucid explanations of the WAM and WAM-like systems <ref> [4, 85] </ref>. There are two main approaches to efficient Prolog implementation: emulated code and native code. Emulated code compiles to an abstract machine and is interpreted at run-time. Native code compiles to the target machine and is executed directly. <p> The switch on constant and switch on structure instructions fall through if A 1 is not in the hash table. The original WAM report does not talk about the cut operation, which removes all choice points created since entering the current predicate. Implementations of cut are presented in <ref> [4, 85] </ref>. A variable stored in the current environment (pointed to by E) is denoted by Y i . A variable stored in a register is denoted by X i or A i . A register used to pass arguments is denoted by A i .
Reference: 5. <author> Hassan At-Kaci and Andreas Podelski. </author> <title> Towards a Meaning of LIFE. </title> <note> DEC PRL Research Report 11, </note> <institution> Digital Equipment Corporation, Paris Research Laboratory, </institution> <month> June </month> <year> 1991 </year> <month> (Revised October </month> <year> 1992). </year>
Reference-contexts: Constraint languages: a language that does incremental global constraint solving in a particular domain is called a constraint language. These languages come in two flavors. The general-purpose languages (such as Prolog, Trilogy [157], and LIFE <ref> [5] </ref>) provide domains that are useful for most programming tasks. For example, unification in Prolog handles equality constraints over finite trees.
Reference: 6. <author> Hassan At-Kaci and Andreas Podelski. </author> <title> Functions as Passive Constraints in LIFE. </title> <note> DEC PRL Research Report 13, </note> <institution> Digital Equipment Corporation, Paris Research Laboratory, </institution> <month> June </month> <year> 1991 </year> <month> (Revised November </month> <year> 1992). </year>
Reference-contexts: An important advantage of the primitive constraint representation over the WAM is that the constraints may be executed in any order. In addition to providing a powerful conceptual description of the WAM, primitive constraints are useful in compiling more advanced logic languages <ref> [6, 84, 117] </ref>. The WAM compiles unification as a single sequence of instructions (see Figure 6). This has several problems: * Write mode is not propagated to subterms. For example, the unification X=f (g (a)) is compiled as X=f (T), T=g (a). These two unifications are compiled independently.
Reference: 7. <author> Hassan At-Kaci, Bruno Dumant, Richard Meyer, Andreas Podelski, and Peter Van Roy. </author> <title> The Wild LIFE Handbook. </title> <institution> Digital Equipment Corporation, Paris Research Laboratory, </institution> <year> 1994. </year>
Reference-contexts: Recent developments indicate that it is more practical to enforce single-threadedness syntactically (through source transformation) than to use an analyzer-compiler combination [65]. See for example the use of monads in functional programming [158] and the Extended Definite Clause Grammar notation of [151, 153] which is extended in <ref> [7] </ref>. * Dynamic to static conversion. All data in Prolog is allocated dynamically, i.e., at run-time. It is accessed through tagged pointers. Often, it is necessary to follow a chain of pointers to find the data.
Reference: 8. <author> Mohamed Amraoui. </author> <title> Une Exp erience de Compilation de PrologII sur MALI (in French). </title> <type> Doctoral dissertation, </type> <institution> Universite de Rennes I, France, </institution> <month> January </month> <year> 1988. </year>
Reference-contexts: This algorithm was independently reinvented at least four times by different people at about the same time: Mohamed Amraoui at the Universite de Rennes I <ref> [8] </ref>, Andre Marien and Bart Demoen at BIM and KUL [86, 88], Kent Boortz at SICS [16], and Micha Meier at ECRC [94]. Write mode propagation was discussed earlier by Andrew Turk [146]. <p> This is a single-chip implementation of the PLM. * The Xenologic X-1. This is a commercial version of the PLM, designed as a coprocessor for the Sun-3. Due to weaknesses in its system software, this system was not commercially successful. * The VLSI-BAM [63] <ref> (1988-91) </ref>. The VLSI Berkeley Abstract Machine. This is a single-chip RISC processor with extensions for Prolog. The PLM was wire-wrapped and ran a few small programs in 1985. The Xenologic X-1 has been running at 10 MHz since 1987.
Reference: 9. <author> Andrew W. Appel. </author> <title> Compiling with Continuations. </title> <publisher> Cambridge University Press, </publisher> <year> 1992. </year>
Reference-contexts: The technique has recently received a boost by Tarau's highly efficient implementation. Functional languages have more often been implemented by means of continuations. A good example is the Standard ML of New Jersey system, which uses an intermediate representation in which all continuations are explicit (Continuation-Passing Style) <ref> [9] </ref>. The idea of BinProlog is to transform each Prolog clause into a binary clause, i.e., a clause containing only one body goal. Predicates that are expanded inline (such as simple built-ins) are not considered as goals.
Reference: 10. <editor> Bilbo Baggins and Frodo Baggins. </editor> <booktitle> The Memoirs of Bilbo and Frodo of the Shire, Supplemented by the Accounts of Their Friends and the Learning of the Wise. The Shire, Arnor, </booktitle> <pages> 3021 TA. </pages>
Reference-contexts: 1 Introduction This report is a personal view of the progress made in sequential Prolog implementation from 1983 to 1993, supplemented with learning of the wise <ref> [10] </ref>. 1983 was a serendipitous year in two ways, one important and one personal. In this year David H. D.
Reference: 11. <author> Joachim Beer. </author> <title> Concepts, Design, and Performance Analysis of a Parallel Prolog Machine. </title> <type> Ph.D. dissertation, </type> <institution> Technische Universitat Berlin, </institution> <month> September </month> <year> 1987. </year>
Reference-contexts: Berkeley (with its commercial offspring, Xenologic Inc.), and the IPP project at Hitachi. All these groups built working systems. The POPE (Parallel Operating Prolog Engine) design is based on extracting fine-grain parallelism in WAM instructions <ref> [11] </ref>. The POPE was built in Berlin at the GMD (Gesellschaft f ur Mathematik und Datenverarbeitung) in the late 1980's. The machine is a ring of up to seven tightly coupled sequential Prolog processors. Parallelism is achieved at each call by interleaving argument setup with head unification.
Reference: 12. <author> Joachim Beer. </author> <title> The Occur-Check Problem Revisited. In JLP, </title> <journal> Elsevier North-Holland, </journal> <volume> vol. 5, no. 3, </volume> <pages> pages 243-261, </pages> <month> September </month> <year> 1988. </year>
Reference-contexts: An uninitialized variable can be represented more efficiently than a standard WAM variable. Beer first proposed the idea of uninitialized variables after he noticed that most unbound variables in the WAM are bound soon afterwards <ref> [12] </ref>. For example, this is true for output arguments of predicates. WAM variables are created as self-referencing pointers in memory, and need to be dereferenced and trailed before being bound. This is time-consuming. Beer represents variables as pointers to memory words that have not been initialized.
Reference: 13. <editor> Judit Bendl, Peter Koves, and Peter Szeredi. </editor> <booktitle> The MPROLOG System. In Logic Programming Workshop, </booktitle> <pages> pages 201-209, </pages> <address> Debrecen, Hungary, </address> <year> 1980. </year>
Reference-contexts: For each system are listed some of the more interesting such problems. 3.1.1 MProlog The first commercial Prolog system was MProlog. 11 MProlog was developed in Hungary starting in 1978 at NIMIGUSZI (Computer Center of the Ministry of Heavy Industries) <ref> [13, 47] </ref>. The main developer is Peter Szeredi, aided by Zsuzsa Farkas and Peter Koves. MProlog was completed at SZKI (Computer Research and Innovation Center), a computer company set up a few years before. The implementation is based on Warren's pre-WAM three-stack model of DEC-10 Prolog.
Reference: 14. <author> Hans Benker, J. M. Beacco, S. Bescos, M. Dorochevsky, Th. Jeffre, A. Pohimann, J. Noye, B. Poterie, A. Sexton, J. C. Syre, O. Thibault, and G. Watzlawik. KCM: </author> <title> A Knowledge Crunching Machine. </title> <booktitle> In 16th ISCA, </booktitle> <pages> pages 186-194, </pages> <publisher> IEEE Computer Society Press, </publisher> <month> May </month> <year> 1989. </year>
Reference-contexts: The microcode was ported from the PSI-II by an automatic translator. Its average performance is 2 to 3 times that of the upgraded PSI-II. 3.2.2 ECRC and the KCM The architecture work at ECRC culminated in the KCM (Knowledge Crunching Machine) project, which started in 1987 <ref> [14, 112] </ref>. The KCM was probably the most sophisticated Prolog machine of the late 1980's. It had an innovative architecture and significant compiler design was done for it. It was preceded by two years of preliminary studies (the ICM, ICM3, and ICM4 architectures) [111, 165].
Reference: 15. <author> J. Bocca. </author> <title> MegaLog-A Platform for Developing Knowledge Base Management Systems. </title> <booktitle> In 2nd International Symposium on Database Systems for Advanced Applications, </booktitle> <pages> pages 374-380, </pages> <address> Tokyo, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: At the time, ECRC-Prolog had the fastest implementation of delaying. The next system, SEPIA (Standard ECRC Prolog Integrating Advanced Features), first released in 1988, was a major improvement [93]. Other systems are Opium [44], an extensible debugging environment, and MegaLog <ref> [15] </ref>, a WAM-based system with extensions to manage databases (e.g., persistence). The most recent system, ECLiPSe (ECRC Common Logic Programming System) [45, 95], integrates the facilities of SEPIA, MegaLog, CHIP, and Opium.
Reference: 16. <author> Kent Boortz. </author> <title> SICStus Maskinkodskompilering (in Swedish). </title> <type> SICS Technical Report T91:13, </type> <month> August </month> <year> 1991. </year> <title> December 1993 Digital PRL 1983-1993: The Wonder Years of Sequential Prolog Implementation 57 </title>
Reference-contexts: This algorithm was independently reinvented at least four times by different people at about the same time: Mohamed Amraoui at the Universite de Rennes I [8], Andre Marien and Bart Demoen at BIM and KUL [86, 88], Kent Boortz at SICS <ref> [16] </ref>, and Micha Meier at ECRC [94]. Write mode propagation was discussed earlier by Andrew Turk [146]. Figures 6 and 8 show how the unification X=f (g (A),h (B)) is compiled in the WAM and by the two-stream algorithm.
Reference: 17. <author> David L. Bowen, Lawrence M. Byrd, and William F. Clocksin. </author> <title> A Portable Prolog Compiler. </title> <booktitle> In Logic Programming Workshop, </booktitle> <pages> pages 74-83, </pages> <address> Algarve, Portugal, </address> <year> 1983. </year>
Reference-contexts: It did much to create a Prolog programming community and to establish the Edinburgh standard. It is cheap, robust, portable (it is written in C), and fast enough for real programs. There were several compiled systems that bridged the gap between the DEC-10 compiler (1977-1980) and the WAM (1983) <ref> [17, 28] </ref>. They include Prolog-X and NIP (New Implementation of Prolog). David Bowen, Lawrence Byrd, William Clocksin, and Fernando Pereira at Edinburgh were the main contributors in this work.
Reference: 18. <author> Kenneth A. Bowen, Kevin A. Buettner, Ilyas Cicekli, and Andrew K. Turk. </author> <title> The Design and Implementation of a High-Speed Incremental Portable Prolog Compiler. </title> <booktitle> In 3rd ICLP, </booktitle> <pages> pages 650-656, </pages> <publisher> Springer-Verlag LNCS 225, </publisher> <month> July </month> <year> 1986. </year>
Reference: 19. <author> Roger S. Boyer and Jay S. Moore. </author> <title> The Sharing of Structure in Theorem Proving Programs. </title> <booktitle> In Machine Intelligence 7, </booktitle> <pages> pages 101-116, </pages> <publisher> Edinburgh University Press, </publisher> <address> New York, </address> <year> 1972. </year>
Reference-contexts: Section 2.4 highlights recent developments that break through its performance barrier. Section 2.5 presents some promising execution models different from the WAM. Prolog systems can be divided into two categories: structure-sharing or structure-copying. The idea of structure sharing is due to Boyer and Moore <ref> [19] </ref>. Structure copying was first described by Bruynooghe [21, 22]. The distinction is based on how compound terms are December 1993 Digital PRL 1983-1993: The Wonder Years of Sequential Prolog Implementation 3 represented.
Reference: 20. <author> Pascal Brisset and Olivier Ridoux. </author> <title> The Compilation of Prolog and its Execution with MALI. </title> <publisher> IRISA Publication Interne 687, Rennes, </publisher> <address> France, </address> <month> November </month> <year> 1992. </year> <note> Also published as INRIA Rapport de Recherche 1831, </note> <month> January </month> <year> 1993. </year>
Reference-contexts: Performance is reasonable partly because SICStus provides efficient support for coroutining. If the language is sufficiently different from Prolog, then it is better to design a new abstract machine. For example, the Prolog language [100] was implemented with MALI <ref> [20] </ref>. Prolog generalizes Prolog with predicate and function variables and typed -terms, while keeping the familiar operational and least fixpoint semantics. MALI is a general-purpose memory management library that has been optimized for logic programming systems. 1.2 Organization of the Survey The survey is divided into four parts.
Reference: 21. <author> Maurice Bruynooghe. </author> <title> An Interpreter for Predicate Logic Programs. </title> <type> Report CW 10, </type> <institution> Department of Computer Science, Katholieke Universiteit Leuven, Belgium, </institution> <month> October </month> <year> 1976. </year>
Reference-contexts: Section 2.5 presents some promising execution models different from the WAM. Prolog systems can be divided into two categories: structure-sharing or structure-copying. The idea of structure sharing is due to Boyer and Moore [19]. Structure copying was first described by Bruynooghe <ref> [21, 22] </ref>. The distinction is based on how compound terms are December 1993 Digital PRL 1983-1993: The Wonder Years of Sequential Prolog Implementation 3 represented.
Reference: 22. <author> Maurice Bruynooghe. </author> <title> The Memory Management of Prolog Implementations. In Logic Programming, </title> <editor> ed. K. Clark and S. </editor> <booktitle> Tarnlund, </booktitle> <pages> pages 83-98, </pages> <publisher> Academic Press, </publisher> <year> 1982. </year>
Reference-contexts: Section 2.5 presents some promising execution models different from the WAM. Prolog systems can be divided into two categories: structure-sharing or structure-copying. The idea of structure sharing is due to Boyer and Moore [19]. Structure copying was first described by Bruynooghe <ref> [21, 22] </ref>. The distinction is based on how compound terms are December 1993 Digital PRL 1983-1993: The Wonder Years of Sequential Prolog Implementation 3 represented.
Reference: 23. <author> Mats Carlsson. </author> <title> On Implementing Prolog in Functional Programming. </title> <booktitle> In 1st ICLP, </booktitle> <pages> pages 154-159, </pages> <publisher> IEEE Computer Society Press, </publisher> <month> February </month> <year> 1984. </year>
Reference-contexts: The resulting instruction set is essentially a simplified subset of the WAM. Implementing Prolog by means of continuations is an old technique. It was used to implement Prolog on Lisp machines and in Pop-11, see for example <ref> [23, 97] </ref>. The technique has recently received a boost by Tarau's highly efficient implementation. Functional languages have more often been implemented by means of continuations. A good example is the Standard ML of New Jersey system, which uses an intermediate representation in which all continuations are explicit (Continuation-Passing Style) [9].
Reference: 24. <author> Mats Carlsson. </author> <title> Freeze, Indexing, and Other Implementation Issues in the WAM. </title> <booktitle> In 4th ICLP, </booktitle> <pages> pages 40-58, </pages> <publisher> MIT Press, </publisher> <month> May </month> <year> 1987. </year>
Reference-contexts: In the general case, predicates can be compiled to create at most one choice point between entry and the execution of the first clause <ref> [24, 148] </ref>. The original WAM report describes a two-level indexing scheme which creates up to two choice points [163]. Many programs cannot profit from first-argument selection. For example, selection may depend on more than one argument. The following example is extracted from an actual program. <p> The parts of a dereference chain in the same choice point segment are removed. This lets the garbage collector recover more memory. This is essential for Prologs that have freeze or similar coroutining programming constructs <ref> [24] </ref>, since the intermediate variables in a dereference chain may contain large frozen goals that can be recovered. Among the scalability problems encountered during the development of SICStus are those listed below. * Interface with malloc/free, the Unix memory allocation library.
Reference: 25. <author> Mats Carlsson. </author> <title> On the Efficiency of Optimising Shallow Backtracking in Compiled Prolog. </title> <booktitle> In 6th ICLP, </booktitle> <pages> pages 3-16, </pages> <publisher> MIT Press, </publisher> <month> June </month> <year> 1989. </year>
Reference-contexts: The algorithm compiles clauses with four entry points, depending on whether or not there are alternative clauses, and whether or not a previously executed clause has created a choice point. The algorithm was not implemented. * Carlsson <ref> [25] </ref> has implemented a restricted version of the above algorithm in SICStus Prolog. Meier [92] has done a similar implementation in KCM-SEPIA. Choice point creation is split into two parts.
Reference: 26. <author> M. Carlsson, J. Widen, J. Andersson, S. Andersson, K. Boortz, H. Nilsson, and T. Sjoland. </author> <title> SICStus Prolog User's Manual. SICS, </title> <address> Box 1263, 164 28 Kista, Sweden, </address> <year> 1991. </year>
Reference: 27. <author> Weidong Chen and David Scott Warren. </author> <title> Query Evaluation under the Well-Founded Semantics. </title> <booktitle> In 12th Symposium on Principles of Database Systems (PODS '93), ACM, </booktitle> <year> 1993. </year>
Reference-contexts: For example, the recursive definition of the Fibonacci function runs in linear time rather than exponential time. More realistic examples are parsing and dynamic programming. One realization of memoization is OLDT resolution (Ordered Linear resolution of Definite clauses with Tabulation) [131]. A recent generalization, SLG resolution <ref> [27] </ref>, handles negation as well. This has been implemented in an abstract machine, the SLG-WAM (previously called the OLDT-WAM), and realized in the XSB system (see Section 3.1.8).
Reference: 28. <author> William F. Clocksin. </author> <title> Design and Simulation of a Sequential Prolog Machine. </title> <journal> In Journal of New Generation Computing (NGC), pages 101-120, </journal> <volume> vol. 3, no. 1, </volume> <year> 1985. </year>
Reference-contexts: It did much to create a Prolog programming community and to establish the Edinburgh standard. It is cheap, robust, portable (it is written in C), and fast enough for real programs. There were several compiled systems that bridged the gap between the DEC-10 compiler (1977-1980) and the WAM (1983) <ref> [17, 28] </ref>. They include Prolog-X and NIP (New Implementation of Prolog). David Bowen, Lawrence Byrd, William Clocksin, and Fernando Pereira at Edinburgh were the main contributors in this work.
Reference: 29. <author> Philippe Codognet and Daniel Diaz. </author> <title> Boolean Constraint Solving using clp(FD). </title> <booktitle> In 10th ILPS, </booktitle> <pages> pages 525-539, </pages> <publisher> MIT Press, </publisher> <month> October </month> <year> 1993. </year>
Reference-contexts: Trailing is only necessary if the current choice point segment is different from the segment stored in the term. Time-stamping is an essential technique for any practical constraint solver. 2.3.2 clp (FD) The clp (FD) system <ref> [29, 40] </ref> is a finite domain solver integrated into a WAM emulator. It was built by Daniel Diaz and Philippe Codognet at INRIA (Rocquencourt, France). It uses a glass box approach.
Reference: 30. <author> Helder Coelho and Jose C. Cotta. </author> <title> Prolog by Example: How to Learn, Teach and Use It. </title> <publisher> Springer-Verlag, </publisher> <year> 1988. </year>
Reference-contexts: The system had reasonable performance and was very influential in convincing people that programming in logic was a viable idea. In particular, David Warren from the University of Edinburgh was convinced. He wrote the Warplan program during his two month stay in Marseilles in 1974 <ref> [30] </ref>.
Reference: 31. <author> A. Colmerauer, H. Kanoui, and M. V. </author> <title> Caneghem. Prolog, </title> <booktitle> Theoretical Principles and Current Trends. In Technology and Science of Informatics, </booktitle> <volume> 2(4) </volume> <pages> 255-292, </pages> <year> 1983. </year>
Reference: 32. <author> A. Colmerauer. </author> <title> The Birth of Prolog. </title> <booktitle> In The Second ACM-SIGPLAN History of Programming Languages Conference, </booktitle> <pages> pages 37-52, </pages> <booktitle> ACM SIGPLAN Notices, </booktitle> <month> March </month> <year> 1993. </year>
Reference-contexts: It is hard to imagine the leap of faith this required back then: to consider a logical description of a problem as a program that could be executed efficiently. The early history is presented in <ref> [32] </ref>, and interested readers should look there for more detail. The work on Prolog was preceded by the Absys system. Absys (from Aberdeen System) was designed and implemented at the University of Aberdeen in 1967. This system was an implementation of pure Prolog [46].
Reference: 33. <author> Vitor Santos Costa, David H. D. Warren, and Rong Yang. Andorra-I: </author> <title> A Parallel Prolog System that transparently exploits both And- and Or-parallelism. </title> <booktitle> In Proc. 3rd ACM SIGPLAN Conference on Principles and Practice of Parallel Programming, </booktitle> <pages> pages 83-93, </pages> <month> August </month> <year> 1991. </year> <note> Research Report No. 36 December 1993 58 Peter Van Roy </note>
Reference-contexts: A call will delay until its when declarations are true. This is called one-way unification or matching. NU-Prolog contains an analyzer that derives when declarations. 7 This heuristic is closely related to the Andorra principle <ref> [33, 55] </ref>. The main difference is that the heuristic is applied at analysis time whereas the Andorra principle is applied at run-time. <p> These can be roughly subdivided into three main families. The families overlap, but the division is still useful. Concurrent languages: these languages include the committed-choice languages [126] (e.g., Parlog, FGHC, and FCP) and languages based on the Andorra princi ple <ref> [33, 55] </ref> (an elegant synthesis of Prolog and committed-choice languages). Constraint languages: a language that does incremental global constraint solving in a particular domain is called a constraint language. These languages come in two flavors.
Reference: 34. <author> Patrick Cousot and Radhia Cousot. </author> <title> Abstract Interpretation: A Unified Lattice Model for Static Analysis of Programs by Construction or Approximation of Fixpoints. </title> <booktitle> In 4th POPL, </booktitle> <pages> pages 238-252, </pages> <month> January </month> <year> 1977. </year>
Reference-contexts: Both type and control information can be derived and used to increase speed and reduce code size. The analysis algorithms studied so far are all instances of a general method called abstract interpretation <ref> [34, 35, 69] </ref>. The idea is to execute the program over a simpler domain. If a small set of conditions are satisfied, this execution terminates and its results provide a correct approximation of information about the original program.
Reference: 35. <author> Patrick Cousot and Radhia Cousot. </author> <title> Abstract Interpretation and Application to Logic Programs. In JLP, </title> <publisher> Elsevier North-Holland, </publisher> <pages> pages 103-179, </pages> <booktitle> vol. </booktitle> <volume> 13, </volume> <pages> nos. 2-3, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: Both type and control information can be derived and used to increase speed and reduce code size. The analysis algorithms studied so far are all instances of a general method called abstract interpretation <ref> [34, 35, 69] </ref>. The idea is to execute the program over a simpler domain. If a small set of conditions are satisfied, this execution terminates and its results provide a correct approximation of information about the original program.
Reference: 36. <author> Koen De Bosschere and Paul Tarau. </author> <title> Continuation Passing Style Prolog-to-C Mapping at Native WAM-speed. </title> <type> ELIS Technical Report DG 93-15, </type> <institution> Universiteit Gent, Vakgroep Elektronica en Infor-matiesystemen, </institution> <month> November </month> <year> 1993. </year> <booktitle> Summary in ACM Symposium on Applied Computing (SAC '94), </booktitle> <month> March </month> <year> 1994 </year> <month> (forthcoming). </month>
Reference-contexts: Currently, the VAM 2p is a practical implementation, whereas the VAM 1p is not because of code size explosion. 2.5.2 BinProlog BinProlog 10 is a high performance C-based emulator developed by Paul Tarau at the Uni-versite de Moncton (Canada) <ref> [36, 136, 137] </ref>. BinProlog has two key ideas: transforming clauses to binary clauses and passing success continuations. The resulting instruction set is essentially a simplified subset of the WAM. Implementing Prolog by means of continuations is an old technique. <p> This will change in the future. For example, because of its first-class labels and global register declarations, the recently released GNU C 2.X compiler has a smaller performance loss than other C compilers <ref> [36, 57] </ref>. Recent work shows that the overhead of compilation to C can be reduced to less than 30%, while keeping the system portable [99]. C is becoming a portable assembly language. Research Report No. 36 December 1993 52 Peter Van Roy * Type inference and operational types.
Reference: 37. <author> Saumya Debray. </author> <title> Global Optimization of Logic Programs. </title> <type> Ph.D. dissertation, </type> <institution> Computer Science Department, SUNY Stony Brook, </institution> <month> September </month> <year> 1986. </year>
Reference-contexts: Neither it nor XSB does garbage collection. The worst problem regarding portability was the use of the BSD Unix syscall system call which supports arbitrary system calls through a single interface. SB-Prolog was the basis for much exploration related to language and implementation (e.g., <ref> [37] </ref>): backtrackable assert, existential variables in asserted clauses, memoizing evaluation, register allocation, mode and type inferencing (see Section 2.4.5), module systems, and compilation. The most recent system, XSB, is SB-Prolog extended with memoization (tabling) and HiLog syntax [119]. The resulting engine is the SLG-WAM (see Section 2.3.3).
Reference: 38. <author> Saumya Debray. </author> <title> A Simple Code Improvement Scheme for Prolog. In JLP, </title> <publisher> Elsevier North-Holland, </publisher> <pages> pages 57-88, </pages> <booktitle> vol. </booktitle> <volume> 13, no. 1, </volume> <month> May </month> <year> 1992. </year>
Reference-contexts: As Prolog compilers approach imperative language performance, the standard optimizations of imperative language compilers (global register allocation, code motion, instruction reordering, and so forth) become important. Some of these are being implemented in current systems <ref> [38] </ref>. One approach is to compile to C. This shortens development time, gains portability, and (to a lesser degree) takes advantage of what the C compiler does (e.g., register allocation). This approach has traditionally had a performance loss over native code of a factor of two to three.
Reference: 39. <author> Saumya Debray. </author> <title> Implementing Logic Programming Systems: The Quiche-Eating Approach. </title> <booktitle> In ICLP '93 Workshop on Practical Implementations and Systems Experience, </booktitle> <address> Budapest, Hungary, </address> <month> June </month> <year> 1993. </year>
Reference-contexts: Research Report No. 36 December 1993 2 Peter Van Roy Prolog. In the past, the quickest way to get an efficient implementation was usually to extend the WAM. Nowadays, it is often better to compile the language into an existing implementation. For example, the QD-Janus system <ref> [39] </ref> is a sequential implementation of Janus (a flat committed-choice language) on top of SICStus Prolog (see Section 3.1.9). Performance is reasonable partly because SICStus provides efficient support for coroutining. If the language is sufficiently different from Prolog, then it is better to design a new abstract machine.
Reference: 40. <author> Daniel Diaz and Philippe Codognet. </author> <title> A Minimal Extension of the WAM for clp(FD). </title> <booktitle> In 10th ICLP, </booktitle> <pages> pages 774-790, </pages> <address> Budapest, Hungary, </address> <publisher> MIT Press, </publisher> <month> June </month> <year> 1993. </year>
Reference-contexts: Trailing is only necessary if the current choice point segment is different from the segment stored in the term. Time-stamping is an essential technique for any practical constraint solver. 2.3.2 clp (FD) The clp (FD) system <ref> [29, 40] </ref> is a finite domain solver integrated into a WAM emulator. It was built by Daniel Diaz and Philippe Codognet at INRIA (Rocquencourt, France). It uses a glass box approach. <p> Arithmetic constraints such as X=Y+Z and boolean constraints such as X=Y and Z can be written in terms of indexical range constraints. Indexical range constraints are smoothly integrated into the WAM by providing support for domain variables and suspension queues for the various indexical functions <ref> [40] </ref>. The time-stamping technique of CHIP is used to reduce trailing. 2.3.3 SLG-WAM Memoization is a technique that caches already-computed answers to a predicate. By adding memoization to Prolog's resolution mechanism, one obtains an execution model that can do both top-down and bottom-up execution.
Reference: 41. <author> M. Dincbas, P. Van Hentenryck, H. Simonis, A. Aggoun, T. Graf, and F. Berthier. </author> <title> The Constraint Logic Programming Language CHIP. </title> <booktitle> In FGCS '88, </booktitle> <pages> pages 693-702, </pages> <address> Tokyo, </address> <month> November </month> <year> 1988. </year>
Reference: 42. <author> T. P. Dobry. </author> <title> Performance Studies of a Prolog Machine Architecture. </title> <booktitle> In 12th ISCA, </booktitle> <publisher> IEEE Computer Society Press, </publisher> <month> June </month> <year> 1985. </year>
Reference-contexts: At ECRC a scientist from East Berlin came to me after the talk. He explained that they had typed in the source code of the PLM compiler from the appendix of the report. Research Report No. 36 December 1993 48 Peter Van Roy * The PLM <ref> [42, 43] </ref> (1983-87). The Programmed Logic Machine. 18 This is a microcoded WAM. * The VLSI-PLM [128, 129] (1985-89). This is a single-chip implementation of the PLM. * The Xenologic X-1. This is a commercial version of the PLM, designed as a coprocessor for the Sun-3.
Reference: 43. <author> T. P. Dobry. </author> <title> A High Performance Architecture for Prolog. </title> <type> Ph.D. dissertation, </type> <institution> Department of Computer Science, U.C. Berkeley, </institution> <note> Report UCB/CSD 87/352, April 1987. Also published by Kluwer Academic Publishers, </note> <year> 1990. </year>
Reference-contexts: At ECRC a scientist from East Berlin came to me after the talk. He explained that they had typed in the source code of the PLM compiler from the appendix of the report. Research Report No. 36 December 1993 48 Peter Van Roy * The PLM <ref> [42, 43] </ref> (1983-87). The Programmed Logic Machine. 18 This is a microcoded WAM. * The VLSI-PLM [128, 129] (1985-89). This is a single-chip implementation of the PLM. * The Xenologic X-1. This is a commercial version of the PLM, designed as a coprocessor for the Sun-3. <p> For example, IBM Prolog is about 1.5 times faster with mode declarations. Research Report No. 36 December 1993 50 Peter Van Roy System Machine (Year) Clock Benchmark (MHz) N Q D S R mean yPLM compiler [148] PLM <ref> [43] </ref> (1985) 10. 19 12 9 12 8 11 ESP PSI-II (1986) 6.45 41 25 12 18 10 16 KCM-SEPIA [112] KCM (1989) 12.5 83 57 37 33 15 32 yPegasus compiler [125] Pegasus-II (1990) 10. 91 69 39 40 19 39 yAquarius [63] VLSI-BAM (1991) 20. 270 260 75 57
Reference: 44. <author> Mireille Ducasse. Opium: </author> <title> An Advanced Debugging System. </title> <booktitle> In 2nd Logic Programming Summer School, Esprit Network of Excellence in Computational Logic (COMPULOG-NET), </booktitle> <editor> ed. G. Comyn and N. Fuchs, </editor> <publisher> Springer-Verlag LNAI 636, </publisher> <month> September </month> <year> 1992. </year>
Reference-contexts: An early system is ECRC-Prolog (1984-1986), a Prolog-to-C compiler for an enhanced MU-Prolog. At the time, ECRC-Prolog had the fastest implementation of delaying. The next system, SEPIA (Standard ECRC Prolog Integrating Advanced Features), first released in 1988, was a major improvement [93]. Other systems are Opium <ref> [44] </ref>, an extensible debugging environment, and MegaLog [15], a WAM-based system with extensions to manage databases (e.g., persistence). The most recent system, ECLiPSe (ECRC Common Logic Programming System) [45, 95], integrates the facilities of SEPIA, MegaLog, CHIP, and Opium.
Reference: 45. <author> ECRC. </author> <title> ECLiPSe 3.2 User Manual. </title> <month> August </month> <year> 1992. </year>
Reference-contexts: Other systems are Opium [44], an extensible debugging environment, and MegaLog [15], a WAM-based system with extensions to manage databases (e.g., persistence). The most recent system, ECLiPSe (ECRC Common Logic Programming System) <ref> [45, 95] </ref>, integrates the facilities of SEPIA, MegaLog, CHIP, and Opium. The system supports rational tree unification and indefinite 13 Curiously, both systems are written mostly in assembly code, several hundred thousand lines worth. December 1993 Digital PRL 1983-1993: The Wonder Years of Sequential Prolog Implementation 41 precision rational arithmetic.
Reference: 46. <author> E. W. Elcock. Absys: </author> <title> The First Logic Programming Language-A Retrospective and a Commentary. In JLP, </title> <publisher> Elsevier North-Holland, </publisher> <pages> pages 1-17, </pages> <booktitle> vol. </booktitle> <volume> 9, no. 1, </volume> <month> July </month> <year> 1990. </year> <note> Also published as Technical Report #210, </note> <institution> Department of Computer Science, University of Western Ontario, </institution> <month> July </month> <year> 1988. </year>
Reference-contexts: The early history is presented in [32], and interested readers should look there for more detail. The work on Prolog was preceded by the Absys system. Absys (from Aberdeen System) was designed and implemented at the University of Aberdeen in 1967. This system was an implementation of pure Prolog <ref> [46] </ref>. For reasons that are unclear but that are probably cultural, Absys did not become widespread. Several systems were developed by Colmerauer's group. The first system was an interpreter written in Algol-W by Philippe Roussel in 1972.
Reference: 47. <author> Zsuzsa Farkas, Peter Koves, and Peter Szeredi. MProlog: </author> <title> An Implementation Overview. </title> <booktitle> In ICLP '93 Workshop on Practical Implementations and Systems Experience, </booktitle> <address> Budapest, Hungary, </address> <month> June </month> <year> 1993. </year>
Reference-contexts: For each system are listed some of the more interesting such problems. 3.1.1 MProlog The first commercial Prolog system was MProlog. 11 MProlog was developed in Hungary starting in 1978 at NIMIGUSZI (Computer Center of the Ministry of Heavy Industries) <ref> [13, 47] </ref>. The main developer is Peter Szeredi, aided by Zsuzsa Farkas and Peter Koves. MProlog was completed at SZKI (Computer Research and Innovation Center), a computer company set up a few years before. The implementation is based on Warren's pre-WAM three-stack model of DEC-10 Prolog.
Reference: 48. <editor> Herve Gallaire. </editor> <booktitle> Boosting Logic Programming. In 4th ICLP, </booktitle> <pages> pages 962-988, </pages> <address> Melbourne, Australia, </address> <month> May </month> <year> 1987. </year>
Reference-contexts: First, the low level trends. What will be the basic improvements in implementation technology for Prolog and related languages? Second, the high level trends. What will be the new tools, new languages, and programming paradigms? Finally, what will be the relation between Prolog and the mainstream computing community? See <ref> [48] </ref> for an early but still useful discussion of these issues. 5.1 Low Level Trends There are many ways in which Prolog implementation technology can be improved. Here are some of the important ones, given in order of increasing difficulty: * Overlap with mainstream compiler technology.
Reference: 49. <author> M. Garca de la Banda and M. Hermenegildo. </author> <title> A Practical Approach to the Global Analysis of CLP Programs. </title> <booktitle> In 10th ILPS, </booktitle> <pages> pages 435-455, </pages> <publisher> MIT Press, </publisher> <month> October </month> <year> 1993. </year> <title> December 1993 Digital PRL 1983-1993: The Wonder Years of Sequential Prolog Implementation 59 </title>
Reference-contexts: This was the first practical application of abstract interpretation to logic programs. The &-Prolog system both derives information and uses it for optimization. PLAI, the successor to MA 3 , subsumes it and has been extended to analyze programs in constraint languages <ref> [49] </ref> and languages with delaying [90]. * The FCP (:,?) compiler (Flat Concurrent Prolog with Ask and Tell guards and read-only variables), written by Shmuel Kliger, has a global analysis phase [72]. * The Parma system, written by Andrew Taylor, is an implementation of Prolog with global analysis targeted to the
Reference: 50. <author> Thomas Walter Getzinger. </author> <title> Abstract Interpretation for the Compile-Time Analysis of Logic Programs. </title> <type> Ph.D. dissertation, </type> <institution> Advanced Computer Architecture Laboratory, University of Southern California, Report ACAL-TR-93-09, </institution> <month> September </month> <year> 1993. </year>
Reference-contexts: If a small set of conditions are satisfied, this execution terminates and its results provide a correct approximation of information about the original program. Le Charlier et al [80, 81] have performed an extensive study of abstract interpretation algorithms and domains and their effectiveness in deriving types. Getzinger <ref> [50] </ref> has recently presented an extensive taxonomy of analysis domains and studied their effects on execution time and code size. Since Mellish's early work in 1981 and 1985 [96, 98], global analysis has been considered useful for Prolog implementation. <p> of Sequential Prolog Implementation 29 System Speedup factor Code size reduction Small Medium Small Medium Aquarius 1.5 1.2 2.2 1.8 Parma 3.0 2.1 2.9 2.0 Table 3: The Effectiveness of Analysis for Small and Medium-Size Programs study of improved analyzers and their integration in the Aquarius system is given in <ref> [50] </ref>. * The MU-Prolog analyzer generates wait declarations for coroutining [106]. Its im proved NU-Prolog version generates when declarations. * The IBM Prolog analyzer. It determines whether choice points have been created or destroyed during execution of a predicate, and whether there are pointers into the local stack.
Reference: 51. <author> Michael M. Gorlick and Carl F. Kesselman. </author> <title> Gauge: A Workbench for the Performance Analysis of Logic Programs. </title> <booktitle> In 5th ICSLP, </booktitle> <pages> pages 548-561, </pages> <publisher> MIT Press, </publisher> <month> August </month> <year> 1988. </year>
Reference-contexts: For example, many systems including Quintus, SICStus, BIM, and ECLiPSe, have a foreign language interface that allows arbitrary calls between Prolog and C, to any level of nesting. Debugging has improved, and several systems now have source-level debuggers and profilers <ref> [51] </ref>. Many systems have eased the strict control flow by including coroutining facilities (such as freeze). There is an ISO standard for Prolog that is essentially complete [122].
Reference: 52. <author> David Gudeman. </author> <title> Representing Type Information in Dynamically Typed Languages. </title> <institution> University of Arizona, Department of Computer Science, Report TR93-27, </institution> <month> September </month> <year> 1993. </year>
Reference-contexts: The tag field contains the type of the term (atom, number, list, or structure). See <ref> [52] </ref> for an exhaustive presentation of alternative tagging schemes. <p> Pragmas are not executable but give information that improves the translation to machine code. In the SPARC code, tags are represented as the low two bits of a 32-bit word. This is a common representation that has low overhead for integer arithmetic and pointer dereferencing <ref> [52] </ref>. The tag of a pointer is always known at compile-time (it is put in a pragma). When following a pointer, the tag is subtracted off at zero cost with the SPARC's register+displacement addressing mode.
Reference: 53. <author> Yi-Ke Guo and Hendrik C. R. </author> <title> Lock. A Classification Scheme for Declarative Programming Languages. GMD-Studien Nr. </title> <type> 182, </type> <institution> GMD, Germany, </institution> <month> August </month> <year> 1990. </year>
Reference-contexts: For example, linear arithmetic inequalities on real numbers and membership in finite domains. These languages allow practical solutions to many problems previously considered intractable such as optimization problems with large search spaces. Synthesis languages: there are now serious attempts to make syntheses of different styles of programming <ref> [53] </ref>. For example, Prolog [100] and languages based on narrowing are syntheses of logic and functional programming, LIFE is a synthesis of logic, functional, and object-oriented programming, and AKL [55] is a synthesis of concurrent and constraint languages [121].
Reference: 54. <author> S. Habata, R. Nakazaki, A. Atarashi, and M. Umemara. </author> <title> Co-operative High Performance Sequential Inference Machine: CHI. </title> <booktitle> In International Conference on Computer Design (ICCD '87), </booktitle> <pages> pages 601-604, </pages> <publisher> IEEE Computer Society Press, </publisher> <month> October </month> <year> 1987. </year>
Reference-contexts: Two series of sequential machines were built: the PSI (Personal Sequential Inference) machines (PSI-I, PSI-II, and PSI-III) and the CHI (Cooperative High performance sequential Inference) machines (CHI-I and CHI-II) <ref> [54] </ref>. I will limit the discussion to the PSI machines, which were the most popular. All the PSI machines are horizontally microprogrammed and have 40-bit data words with 8-bit tag and 32-bit value fields. The PSI-I was developed before the WAM [133].
Reference: 55. <author> Seif Haridi and Sverker Janson. </author> <title> Kernel Andorra Prolog and its Computation Model. </title> <booktitle> In 7th ICLP, </booktitle> <pages> pages 31-48, </pages> <publisher> MIT Press, </publisher> <address> Cambridge, </address> <month> June </month> <year> 1990. </year>
Reference-contexts: A call will delay until its when declarations are true. This is called one-way unification or matching. NU-Prolog contains an analyzer that derives when declarations. 7 This heuristic is closely related to the Andorra principle <ref> [33, 55] </ref>. The main difference is that the heuristic is applied at analysis time whereas the Andorra principle is applied at run-time. <p> These can be roughly subdivided into three main families. The families overlap, but the division is still useful. Concurrent languages: these languages include the committed-choice languages [126] (e.g., Parlog, FGHC, and FCP) and languages based on the Andorra princi ple <ref> [33, 55] </ref> (an elegant synthesis of Prolog and committed-choice languages). Constraint languages: a language that does incremental global constraint solving in a particular domain is called a constraint language. These languages come in two flavors. <p> Synthesis languages: there are now serious attempts to make syntheses of different styles of programming [53]. For example, Prolog [100] and languages based on narrowing are syntheses of logic and functional programming, LIFE is a synthesis of logic, functional, and object-oriented programming, and AKL <ref> [55] </ref> is a synthesis of concurrent and constraint languages [121].
Reference: 56. <author> Arie Harsat and Ran Ginosar. CARMEL-2: </author> <title> A Second Generation VLSI Architecture for Flat Concurrent Prolog. </title> <booktitle> In FGCS '88, </booktitle> <pages> pages 962-969, </pages> <address> Tokyo, </address> <month> November </month> <year> 1988. </year>
Reference-contexts: Its performance is comparable to Aquarius Prolog on a SPARCstation 1+ (see Table 7). In the late 1980's came the first efforts to build RISC processors for Prolog. These include Pegasus, LIBRA [101], and Carmel-2 <ref> [56] </ref> (the latter supports Flat Concurrent Prolog). For lack of appropriate compiler technology, these systems executed macro-expanded WAM code or hand-coded assembly code. December 1993 Digital PRL 1983-1993: The Wonder Years of Sequential Prolog Implementation 45 The Pegasus project began in 1986 at Mitsubishi.
Reference: 57. <author> Bogumi Hausman. </author> <title> Turbo Erlang. </title> <booktitle> In 10th ILPS, </booktitle> <pages> page 662, </pages> <publisher> MIT Press, </publisher> <month> October </month> <year> 1993. </year>
Reference-contexts: This will change in the future. For example, because of its first-class labels and global register declarations, the recently released GNU C 2.X compiler has a smaller performance loss than other C compilers <ref> [36, 57] </ref>. Recent work shows that the overhead of compilation to C can be reduced to less than 30%, while keeping the system portable [99]. C is becoming a portable assembly language. Research Report No. 36 December 1993 52 Peter Van Roy * Type inference and operational types.
Reference: 58. <author> Ralph Clarke Haygood. </author> <title> Aquarius Prolog User Manual. In Aquarius Prolog 1.0 documentation, </title> <institution> U.C. Berkeley, </institution> <month> April </month> <year> 1993. </year>
Reference-contexts: Kliger, has a global analysis phase [72]. * The Parma system, written by Andrew Taylor, is an implementation of Prolog with global analysis targeted to the MIPS processor [140]. * The Aquarius system is an implementation of Prolog with global analysis targeted to the VLSI-BAM processor and various general-purpose processors <ref> [58, 153] </ref>. <p> in the spring of December 1993 Digital PRL 1983-1993: The Wonder Years of Sequential Prolog Implementation 43 1991, Ralph Haygood (the main developer of the back-end, run-time system, and built-ins) and I decided to continue part-time work on the software so that it could be released to the general public <ref> [58, 70] </ref>. We were joined by Tom Getzinger at USC. The system achieved 1.1 MLIPS on a SPARCstation 1+ in February 1991. It first successfully compiled itself in February 1992. It was completed and released as Aquarius Prolog 1.0 in April 1993.
Reference: 59. <author> John L. Hennessy and David A. Patterson. </author> <title> Computer Architecture: A Quantitative Approach. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1990. </year>
Reference-contexts: All data in Prolog is allocated dynamically, i.e., at run-time. It is accessed through tagged pointers. Often, it is necessary to follow a chain of pointers to find the data. Since CPU speed is increasing faster than memory speed <ref> [59] </ref>, the overhead of memory access will become relatively more important in the future. The software and hardware approaches to speed up memory access are complementary: A future compiler could statically allocate part of the dynamically allocated data to reduce access time and improve locality.
Reference: 60. <author> Manuel Hermenegildo, Richard Warren, and Saumya Debray. </author> <title> Global Flow Analysis as a Practical Compilation Tool. In JLP, </title> <publisher> Elsevier North-Holland, </publisher> <pages> pages 349-367, </pages> <booktitle> vol. </booktitle> <volume> 13, no. 4, </volume> <month> August </month> <year> 1992. </year>
Reference-contexts: Research Report No. 36 December 1993 28 Peter Van Roy In 1988, Richard Warren, Manuel Hermenegildo, and Saumya Debray did the first measurements of the practicality of global analysis in logic programming <ref> [60, 164] </ref>. They measured two systems, MA 3 , the MCC And-parallel Analyzer and Annotator, and Ms, an experimental analysis scheme developed for SB-Prolog. The paper concludes that both dataflow analyzers are effective in deriving types and do not unduly increase compilation time. <p> Three (MA 3 , Parma, and Aquarius) have been integrated into Prolog systems and their effects on performance evaluated and published <ref> [60, 140, 153] </ref>. The analysis domains of Aquarius and Parma are shown in Figure 10. For both analyzers the analysis time is linear in program size and performance is adequate. Four analyzers (MA 3 , FCP (:,?), Aquarius, and IBM Prolog) are robust enough for day-to-day programming.
Reference: 61. <author> Timothy Hickey and Shyam Mudambi. </author> <title> Global Compilation of Prolog. In JLP, </title> <publisher> Elsevier North-Holland, </publisher> <pages> pages 193-230, </pages> <booktitle> vol. </booktitle> <volume> 7, no. 3, </volume> <month> November </month> <year> 1989. </year>
Reference-contexts: A neck instruction is only included in the first case. In SICStus, this algorithm results in a performance improvement of 7% to 15% for four large programs, at a cost of a 5% to 10% increase in code size. * Hickey and Mudambi <ref> [61] </ref> present compilation algorithms to generate a tree of tests and to minimize work done in backtracking. One of their selection algorithms results in a tree that has a quadratic worst-case size. They improve choice point management. The try instruction only stores registers needed in clauses after the first clause.
Reference: 62. <author> P. M. Hill and J. W. Lloyd. </author> <title> The G odel Programming Language. </title> <type> Technical Report CSTR-92-27, </type> <institution> Department of Computer Science, University of Bristol, </institution> <month> October </month> <year> 1992 </year> <month> (Revised May </month> <year> 1993). </year>
Reference-contexts: It is not yet obvious whether this is possible without losing expressivity and performance. This group includes the MU-Prolog and NU-Prolog family [104] (see Section 3.1.3), xpProlog [83], and the G odel language <ref> [62] </ref>. * Other logic programming languages. These can be roughly subdivided into three main families. The families overlap, but the division is still useful.
Reference: 63. <author> Bruce K. Holmer, Barton Sano, Michael Carlton, Peter Van Roy, Ralph Haygood, Joan M. Pendleton, T. P. Dobry, William R. Bush, and Alvin M. Despain. </author> <title> Fast Prolog with an Extended General Purpose Architecture. </title> <booktitle> In 17th ISCA, </booktitle> <pages> pages 282-291, </pages> <publisher> IEEE Computer Society Press, </publisher> <month> May </month> <year> 1990. </year>
Reference-contexts: The second paper presents December 1993 Digital PRL 1983-1993: The Wonder Years of Sequential Prolog Implementation 25 performance results for Parma on a MIPS processor. The first results for Aquarius were presented in <ref> [63] </ref>, which describes the VLSI-BAM processor and its simulated performance. A second paper measures the effectiveness of global analysis in Aquarius [152]. Both the Parma and Aquarius systems vastly outperform existing implementations. <p> The general unify instruction is expanded into code that handles inline the cases where one or both of the arguments are variables. Measurements of the dynamic behavior of unification on four real programs show that one or both of the arguments are variables about 85% of the time <ref> [63] </ref>. A subroutine call is made only if both arguments are nonvariables. 2.5 Beyond the WAM: Radically Different Execution Models Some recent developments in Prolog implementation are based on novel models of execution very different from the WAM. <p> It provides compound instructions (pop & jump, push & jump, pop & move, push & move) to exploit data path parallelism. By 1990, the appropriate compiler technology was developed on two RISC machines. The VLSI-BAM, a special-purpose processor, ran Aquarius Prolog <ref> [63] </ref>. The MIPS R3000, a general-purpose processor, ran Parma [139]. The VLSI-BAM has a modest amount of architectural support for Prolog (10.6% of active chip area). Parma achieves a somewhat greater performance on a general-purpose processor at the same clock rate (see Table 7). <p> This is a single-chip implementation of the PLM. * The Xenologic X-1. This is a commercial version of the PLM, designed as a coprocessor for the Sun-3. Due to weaknesses in its system software, this system was not commercially successful. * The VLSI-BAM <ref> [63] </ref> (1988-91). The VLSI Berkeley Abstract Machine. This is a single-chip RISC processor with extensions for Prolog. The PLM was wire-wrapped and ran a few small programs in 1985. The Xenologic X-1 has been running at 10 MHz since 1987. <p> The processor is extended with support for Prolog and for multiprocessing, which together form 10.6% of the active chip area and improve Prolog performance by a factor of 1.70 <ref> [63] </ref>. The VLSI-BAM executes the same Prolog program in one third the cycles of the VLSI-PLM, a gain due to improved compilation. <p> Except for dereference, the instructions are all single-cycle. There are two- and three-way tagged branches to support unification and a conditional push to support trailing. The instructions for data structure creation (write-mode unification) were derived automatically using constrained exhaustive search [64]. VLSI-BAM measurements <ref> [63] </ref> show that with advanced compilation techniques, multiway branches for general unification are effective only up to a three-way branch. 19 Multiple-cycle (primarily dereference) and conditional instructions are implemented by logic to insert or remove opcodes in the pipeline. <p> S R mean yPLM compiler [148] PLM [43] (1985) 10. 19 12 9 12 8 11 ESP PSI-II (1986) 6.45 41 25 12 18 10 16 KCM-SEPIA [112] KCM (1989) 12.5 83 57 37 33 15 32 yPegasus compiler [125] Pegasus-II (1990) 10. 91 69 39 40 19 39 yAquarius <ref> [63] </ref> VLSI-BAM (1991) 20. 270 260 75 57 32 72 Machine (Architecture) zDEC-10 Prolog [159] DEC-10 (1977) 1 1 1 1 1 1 XSB 1.3 SPARCstation 1+ (SPARC) 25 7 4 2 4 3 3 Quintus 2.0 [63] Sun 3/60 (MC68020) 20 11 4 3 4 3 4 zMProlog 2.3 IBM <p> yPegasus compiler [125] Pegasus-II (1990) 10. 91 69 39 40 19 39 yAquarius <ref> [63] </ref> VLSI-BAM (1991) 20. 270 260 75 57 32 72 Machine (Architecture) zDEC-10 Prolog [159] DEC-10 (1977) 1 1 1 1 1 1 XSB 1.3 SPARCstation 1+ (SPARC) 25 7 4 2 4 3 3 Quintus 2.0 [63] Sun 3/60 (MC68020) 20 11 4 3 4 3 4 zMProlog 2.3 IBM PC clone (386) 33 13 6 5 5 2 5 ECLiPSe 3.3.7 SPARCstation 1+ (SPARC) 25 11 6 4 6 3 5 NU-Prolog 1.5.38 SPARCstation 1+ (SPARC) 25 22 7 5 7 2 5 SICStus 2.1 DECstation
Reference: 64. <author> Bruce K. Holmer. </author> <title> Automatic Design of Computer Instruction Sets. </title> <type> Ph.D. dissertation, </type> <institution> Department of Computer Science, U.C. Berkeley, </institution> <year> 1993. </year>
Reference-contexts: Except for dereference, the instructions are all single-cycle. There are two- and three-way tagged branches to support unification and a conditional push to support trailing. The instructions for data structure creation (write-mode unification) were derived automatically using constrained exhaustive search <ref> [64] </ref>. VLSI-BAM measurements [63] show that with advanced compilation techniques, multiway branches for general unification are effective only up to a three-way branch. 19 Multiple-cycle (primarily dereference) and conditional instructions are implemented by logic to insert or remove opcodes in the pipeline.
Reference: 65. <author> Paul Hudak. </author> <title> Reflections on Program Optimization. Invited talk, </title> <booktitle> 1993 Workshop on Static Analysis (WSA '93), </booktitle> <pages> page 193, </pages> <publisher> Springer-Verlag LNCS 724, </publisher> <month> September </month> <year> 1993. </year>
Reference-contexts: For example, a program that uses an array can destructively update the array if it is unaliased (see Section 2.4.4). Unaliased arrays are called single-threaded. Recent developments indicate that it is more practical to enforce single-threadedness syntactically (through source transformation) than to use an analyzer-compiler combination <ref> [65] </ref>. See for example the use of monads in functional programming [158] and the Extended Definite Clause Grammar notation of [151, 153] which is extended in [7]. * Dynamic to static conversion. All data in Prolog is allocated dynamically, i.e., at run-time. It is accessed through tagged pointers.
Reference: 66. <author> Gerard Huet. </author> <title> R esolution d' Equations dans des Langages d'Ordre 1, 2, : : : , ! (in French). </title> <institution> These de Doctorat d' Etat, Universite Paris VII, </institution> <month> September </month> <year> 1976. </year>
Reference-contexts: IF/Prolog, SNI-Prolog, IBM Prolog, SEPIA, ECLiPSe, and SICStus support rational tree unification. Rational trees account for term equations which express cycles. For example, the term equation X=f (X) has a solution over rational trees, but does not over finite trees <ref> [66, 68] </ref>. All of the compiled systems except MProlog and Aquarius are based on the WAM instruction set, but modified and extended to increase performance. MProlog, BIM, IBM Prolog, SEPIA, ECLiPSe, and Aquarius support mode declarations and multiple-argument indexing. The other systems do not support mode declarations.
Reference: 67. <author> IBM. </author> <title> IBM SAA AD/Cycle Prolog/MVS & VM Programmer's Guide and Language Reference, </title> <type> Release 1, </type> <month> December </month> <year> 1992. </year> <note> Research Report No. 36 December 1993 60 Peter Van Roy </note>
Reference-contexts: Nothing has been published about the implementation. The following information is due to Gillet and the system documentation <ref> [67] </ref>. The first version, a structure-sharing system, was written in 1983-1984 and commercialized in 1985 as VM/Prolog. A greatly rewritten and extended version was commercialized in 1989 as IBM Prolog. 13 It runs on system 370 under the VM and MVS operating systems.
Reference: 68. <author> Joxan Jaffar. </author> <title> Efficient Unification over Infinite Terms. </title> <journal> In Journal of New Generation Computing (NGC), pages 207-219, </journal> <volume> vol. 2, no. 3, </volume> <year> 1984. </year>
Reference-contexts: IF/Prolog, SNI-Prolog, IBM Prolog, SEPIA, ECLiPSe, and SICStus support rational tree unification. Rational trees account for term equations which express cycles. For example, the term equation X=f (X) has a solution over rational trees, but does not over finite trees <ref> [66, 68] </ref>. All of the compiled systems except MProlog and Aquarius are based on the WAM instruction set, but modified and extended to increase performance. MProlog, BIM, IBM Prolog, SEPIA, ECLiPSe, and Aquarius support mode declarations and multiple-argument indexing. The other systems do not support mode declarations.
Reference: 69. <author> Gerda Janssens and Maurice Bruynooghe. </author> <title> Deriving Descriptions of Possible Values of Program Variables by means of Abstract Interpretation. In JLP, </title> <publisher> Elsevier North-Holland, </publisher> <pages> pages 205-258, </pages> <booktitle> vol. </booktitle> <volume> 13, </volume> <pages> nos. 2-3, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: Both type and control information can be derived and used to increase speed and reduce code size. The analysis algorithms studied so far are all instances of a general method called abstract interpretation <ref> [34, 35, 69] </ref>. The idea is to execute the program over a simpler domain. If a small set of conditions are satisfied, this execution terminates and its results provide a correct approximation of information about the original program.
Reference: 70. <author> Mark Kantrowitz. </author> <title> Prolog Resource Guide. </title> <note> Regularly posted on Internet newsgroups comp.lang.prolog and comp.answers. </note>
Reference-contexts: Section 3.1 talks about software systems and Section 3.2 talks about hardware systems. 3.1 Software Sagas Since the development of the WAM in 1983 there have been many software implementations of Prolog. At the end of 1993, more than fifty systems were listed in the Prolog Resource Guide <ref> [70] </ref>. The systems discussed here are MProlog, IF/Prolog, SNI-Prolog, MU-Prolog, NU-Prolog, Quintus, BIM, IBM Prolog, SEPIA, ECLiPSe, SB-Prolog, XSB, SICStus, and Aquarius. All of these systems are substantially compatible with the Edinburgh standard. They have been released to users and used to build applications. <p> in the spring of December 1993 Digital PRL 1983-1993: The Wonder Years of Sequential Prolog Implementation 43 1991, Ralph Haygood (the main developer of the back-end, run-time system, and built-ins) and I decided to continue part-time work on the software so that it could be released to the general public <ref> [58, 70] </ref>. We were joined by Tom Getzinger at USC. The system achieved 1.1 MLIPS on a SPARCstation 1+ in February 1991. It first successfully compiled itself in February 1992. It was completed and released as Aquarius Prolog 1.0 in April 1993.
Reference: 71. <author> Shmuel Kliger and Ehud Shapiro. </author> <title> From Decision Trees to Decision Graphs. </title> <booktitle> In NACLP90, </booktitle> <pages> pages 97-116, </pages> <publisher> MIT Press, </publisher> <month> October </month> <year> 1990. </year>
Reference-contexts: The latter operation lets the garbage collector recover more memory. The technique of improved choice point management was independently invented earlier by Andrew Turk [146] and later by Van Roy [153]. The technique has not yet been quantitatively evaluated. * Kliger <ref> [71, 72] </ref> presents a compilation algorithm that generates a directed acyclic graph of tests (a decision graph). The algorithm was extended by Korsloot and Tick for nondeterminate (don't know) predicates [74]. The graph has two important properties. First, it never does worse than first-argument selection.
Reference: 72. <author> Shmuel Kliger. </author> <title> Compiling Concurrent Logic Programming Languages. </title> <type> Ph.D. dissertation, </type> <institution> Weiz-mann Institute, Rehovot, </institution> <month> October </month> <year> 1992. </year>
Reference-contexts: The latter operation lets the garbage collector recover more memory. The technique of improved choice point management was independently invented earlier by Andrew Turk [146] and later by Van Roy [153]. The technique has not yet been quantitatively evaluated. * Kliger <ref> [71, 72] </ref> presents a compilation algorithm that generates a directed acyclic graph of tests (a decision graph). The algorithm was extended by Korsloot and Tick for nondeterminate (don't know) predicates [74]. The graph has two important properties. First, it never does worse than first-argument selection. <p> PLAI, the successor to MA 3 , subsumes it and has been extended to analyze programs in constraint languages [49] and languages with delaying [90]. * The FCP (:,?) compiler (Flat Concurrent Prolog with Ask and Tell guards and read-only variables), written by Shmuel Kliger, has a global analysis phase <ref> [72] </ref>. * The Parma system, written by Andrew Taylor, is an implementation of Prolog with global analysis targeted to the MIPS processor [140]. * The Aquarius system is an implementation of Prolog with global analysis targeted to the VLSI-BAM processor and various general-purpose processors [58, 153].
Reference: 73. <author> H. Komatsu, N. Tamura, Y. Asakawa, and T. Kurokawa. </author> <title> An Optimizing Prolog Compiler. </title> <booktitle> In Logic Programming '86, </booktitle> <pages> pages 104-115, </pages> <publisher> Springer-Verlag LNCS 264, </publisher> <month> June </month> <year> 1986. </year>
Reference-contexts: As the number of instructions increases, the system becomes increasingly unwieldy. The main insight in speeding up Prolog execution is to represent the code in terms of simple instructions. The first published experiments using this idea were done in 1986 by Komatsu et al <ref> [73, 135] </ref> at IBM Japan. These experiments gave the first demonstration that specialized hardware is not essential for high-performance execution of Prolog. Compilation is done in three steps. The first step is to compile Prolog into a WAM-like intermediate code.
Reference: 74. <author> M. Korsloot and E. Tick. </author> <title> Compilation Techniques for Nondeterminate Flat Concurrent Logic Programming Languages. </title> <booktitle> In 8th ICLP, </booktitle> <pages> pages 457-471, </pages> <publisher> MIT Press, </publisher> <month> June </month> <year> 1991. </year>
Reference-contexts: The technique has not yet been quantitatively evaluated. * Kliger [71, 72] presents a compilation algorithm that generates a directed acyclic graph of tests (a decision graph). The algorithm was extended by Korsloot and Tick for nondeterminate (don't know) predicates <ref> [74] </ref>. The graph has two important properties. First, it never does worse than first-argument selection. Second, it has size linear in the number of clauses. This follows from the property that each clause corresponds to a unique path through the graph.
Reference: 75. <author> Peter Koves and Peter Szeredi. </author> <title> Getting the Most Out of Structure-Sharing. </title> <booktitle> In Collection of Papers on Logic Programming, </booktitle> <pages> pages 69-84, </pages> <address> SZKI, Budapest, </address> <year> 1988 </year> <month> (Revised November </month> <year> 1993). </year>
Reference-contexts: The first public demonstration was in 1980 and the first sale in September 1982. MProlog is a full-featured structure-sharing system with all Edinburgh built-ins, debugging, foreign language interface, and sophisticated I/O. It shows that structure-sharing is as efficient as structure-copying <ref> [75] </ref>. Its implementation was among the most advanced of its day. Early on, it had a native code compiler, memory recovery on forward execution (including tail recursion optimization) and support for mode declarations (including multiple-argument indexing). It had garbage collection for the symbol table and code area.
Reference: 76. <author> Andreas Krall, Tim Lindholm, et al. </author> <title> Net Talk: Term Comparisons with Variables. </title> <booktitle> In ALP Newsletter, </booktitle> <pages> pages 18-21, </pages> <month> November </month> <year> 1992. </year> <title> From Internet newsgroup comp.lang.prolog, </title> <month> July </month> <year> 1992. </year>
Reference-contexts: The symbol table and code area are not put on the heap, because their modifications (i.e., newly interned atoms and asserted clauses) are permanent. Measurements have been done of the unsafe variable trade-off for Quintus Prolog (see Section 3.1.4) and the VAM (see Section 2.5.1) <ref> [76] </ref>. Tim Lindholm measured the increase of peak heap usage for Quintus on a set of programs including Chat-80 [161] and the Quintus test suite and compiler. He found that the first alternative increases peak heap usage by 50 to 100% for Quintus (see Section 3.1.4).
Reference: 77. <author> Andreas Krall and Ulrich Neumerkel. </author> <title> The Vienna Abstract Machine. </title> <booktitle> In PLILP '90, </booktitle> <pages> pages 121-135, </pages> <publisher> Springer-Verlag LNCS 456, </publisher> <month> August </month> <year> 1990. </year>
Reference-contexts: The Vienna Abstract Machine (VAM) is based on partial evaluation of each call. The BinProlog system is based on the explicit passing of success continuations. 2.5.1 The Vienna Abstract Machine (VAM) The VAM is an execution model developed by Andreas Krall at the Technische Universitat Wien (Vienna, Austria) <ref> [77] </ref>. The VAM is considerably faster than the WAM. The insight of the VAM is that the WAM's separation of argument setup from argument unification is wasteful. In the WAM, all of a predicate's arguments are built before the predicate is called.
Reference: 78. <author> K. Kurosawa, S. Yamaguchi, S. Abe, and T. Bandoh. </author> <title> Instruction Architecture for a High Performance Integrated Prolog Processor IPP. </title> <booktitle> In 5th ICSLP, </booktitle> <pages> pages 1506-1530, </pages> <publisher> MIT Press, </publisher> <month> August </month> <year> 1988. </year>
Reference-contexts: Parallelism is achieved at each call by interleaving argument setup with head unification. The head unification is done on the next machine in the ring. In this fashion, the machine is automatically load balanced and achieves a speedup of up to seven. The IPP (Integrated Prolog Processor) <ref> [78] </ref> is a Hitachi ECL superminicomputer of cycle time 23ns ( 43.5 MHz) with 3% added hardware support for Prolog. The IPP was built in the late 1980's. The support comprises an increased microcode memory of 2 KW and tag manipulation hardware.
Reference: 79. <author> Peter Kursawe. </author> <title> How to Invent a Prolog Machine. </title> <booktitle> In 3rd ICLP, </booktitle> <pages> pages 134-148, </pages> <publisher> Springer-Verlag LNCS 225, </publisher> <month> July </month> <year> 1986. </year> <journal> Also in Journal of New Generation Computing, </journal> <volume> vol. 5, </volume> <pages> pages 97-114, </pages> <year> 1987. </year>
Reference-contexts: It is remarkable that the simplification principle has continued to hold to the present day. It is valid for WAM-based systems, native code systems, and systems that do global analysis. In the WAM the simplification is done statically (at compile-time) and locally <ref> [79] </ref>. The simplification can also be done dynamically (with run-time tests) and globally. An example of dynamic simplification is clause selection (see Section 2.4.3). Examples of global simplification are global analysis (see Sections 2.4.5 and 2.4.6) and the two-stream unification algorithm (see Section 2.4.2).
Reference: 80. <author> Baudouin Le Charlier, Kaninda Musumbu, and Pascal Van Hentenryck. </author> <title> A Generic Abstract Interpretation Algorithm and its Complexity Analysis (Extended Abstract). </title> <booktitle> In 8th ICLP, </booktitle> <pages> pages 64-78, </pages> <publisher> MIT Press, </publisher> <month> June </month> <year> 1991. </year>
Reference-contexts: The idea is to execute the program over a simpler domain. If a small set of conditions are satisfied, this execution terminates and its results provide a correct approximation of information about the original program. Le Charlier et al <ref> [80, 81] </ref> have performed an extensive study of abstract interpretation algorithms and domains and their effectiveness in deriving types. Getzinger [50] has recently presented an extensive taxonomy of analysis domains and studied their effects on execution time and code size.
Reference: 81. <author> Baudouin Le Charlier, Olivier Degimbe, Laurent Michel, and Pascal Van Hentenryck. </author> <title> Optimization Techniques for General Purpose Fixpoint Algorithms: Practical Efficiency for the Abstract Interpretation of Prolog. </title> <booktitle> In 1993 Workshop on Static Analysis (WSA '93), </booktitle> <pages> pages 15-26, </pages> <publisher> Springer-Verlag LNCS 724, </publisher> <month> September </month> <year> 1993. </year>
Reference-contexts: The idea is to execute the program over a simpler domain. If a small set of conditions are satisfied, this execution terminates and its results provide a correct approximation of information about the original program. Le Charlier et al <ref> [80, 81] </ref> have performed an extensive study of abstract interpretation algorithms and domains and their effectiveness in deriving types. Getzinger [50] has recently presented an extensive taxonomy of analysis domains and studied their effects on execution time and code size.
Reference: 82. <author> Tim Lindholm and Richard A. O'Keefe. </author> <title> Efficient Implementation of a Defensible Semantics for Dynamic Prolog Code. </title> <booktitle> In 4th ICLP, </booktitle> <pages> pages 21-39, </pages> <publisher> MIT Press, </publisher> <month> May </month> <year> 1987. </year>
Reference-contexts: It provides tools for the user including source-level debugging on compiled code and an Emacs interface. * It was the first system to provide a clean and justified semantics for self-modifying code (assert and retract), namely the logical view <ref> [82] </ref>. A predicate in the process of being executed sees the definition that existed at the time of the call. * It is the system that comes with the largest set of libraries of useful utilities.
Reference: 83. <author> Peter Ludemann. xpProlog: </author> <title> High Performance Extended Pure Prolog. </title> <type> Master's thesis, </type> <institution> University of British Columbia, </institution> <year> 1988. </year>
Reference-contexts: It is not yet obvious whether this is possible without losing expressivity and performance. This group includes the MU-Prolog and NU-Prolog family [104] (see Section 3.1.3), xpProlog <ref> [83] </ref>, and the G odel language [62]. * Other logic programming languages. These can be roughly subdivided into three main families. The families overlap, but the division is still useful.
Reference: 84. <author> Michael J. Maher. </author> <title> Logic Semantics for a Class of Committed-Choice Programs. </title> <booktitle> In 4th ICLP, </booktitle> <pages> pages 858-876, </pages> <publisher> MIT Press, </publisher> <year> 1987. </year> <title> December 1993 Digital PRL 1983-1993: The Wonder Years of Sequential Prolog Implementation 61 </title>
Reference-contexts: An important advantage of the primitive constraint representation over the WAM is that the constraints may be executed in any order. In addition to providing a powerful conceptual description of the WAM, primitive constraints are useful in compiling more advanced logic languages <ref> [6, 84, 117] </ref>. The WAM compiles unification as a single sequence of instructions (see Figure 6). This has several problems: * Write mode is not propagated to subterms. For example, the unification X=f (g (a)) is compiled as X=f (T), T=g (a). These two unifications are compiled independently.
Reference: 85. <author> David Maier and David Scott Warren. </author> <title> Computing with Logic-Logic Programming with Prolog. </title> <address> Benjamin/Cummings, </address> <year> 1988. </year>
Reference-contexts: The WAM defines a high-level instruction set that maps closely to Prolog source code. This section concisely explains the original WAM. In particular, the many optimizations of the WAM are given a uniform justification. This section assumes a basic knowledge of how Prolog executes <ref> [85, 115, 130] </ref> and of how imperative languages are compiled [3]. For several years, Warren's report was the sole source of information on the WAM, and its terse style gave the WAM an aura of inscrutability. Many people learned the WAM by osmosis, gradually absorbing its meaning. <p> Many people learned the WAM by osmosis, gradually absorbing its meaning. Nowadays, there are texts that give lucid explanations of the WAM and WAM-like systems <ref> [4, 85] </ref>. There are two main approaches to efficient Prolog implementation: emulated code and native code. Emulated code compiles to an abstract machine and is interpreted at run-time. Native code compiles to the target machine and is executed directly. <p> The switch on constant and switch on structure instructions fall through if A 1 is not in the hash table. The original WAM report does not talk about the cut operation, which removes all choice points created since entering the current predicate. Implementations of cut are presented in <ref> [4, 85] </ref>. A variable stored in the current environment (pointed to by E) is denoted by Y i . A variable stored in a register is denoted by X i or A i . A register used to pass arguments is denoted by A i .
Reference: 86. <author> Andre Marien. </author> <title> An Optimal Intermediate Code for Structure Creation in a WAM-based Prolog Implementation. </title> <institution> Katholieke Universiteit Leuven, Belgium, </institution> <month> May </month> <year> 1988. </year>
Reference-contexts: This algorithm was independently reinvented at least four times by different people at about the same time: Mohamed Amraoui at the Universite de Rennes I [8], Andre Marien and Bart Demoen at BIM and KUL <ref> [86, 88] </ref>, Kent Boortz at SICS [16], and Micha Meier at ECRC [94]. Write mode propagation was discussed earlier by Andrew Turk [146]. Figures 6 and 8 show how the unification X=f (g (A),h (B)) is compiled in the WAM and by the two-stream algorithm.
Reference: 87. <author> Andre Marien, Gerda Janssens, Anne Mulkers, and Maurice Bruynooghe. </author> <title> The Impact of Abstract Interpretation: An Experiment in Code Generation. </title> <booktitle> In 6th ICLP, </booktitle> <pages> pages 33-47, </pages> <publisher> MIT Press, </publisher> <month> June </month> <year> 1989. </year>
Reference-contexts: They measured two systems, MA 3 , the MCC And-parallel Analyzer and Annotator, and Ms, an experimental analysis scheme developed for SB-Prolog. The paper concludes that both dataflow analyzers are effective in deriving types and do not unduly increase compilation time. In 1989, Andre Marien et al <ref> [87] </ref> performed an interesting experiment in which several small Prolog predicates (recursive list operations) were hand-compiled with four levels of optimization based on information derivable from a global analysis.
Reference: 88. <author> Andre Marien and Bart Demoen. </author> <title> A New Scheme for Unification in WAM. </title> <booktitle> In ILPS, </booktitle> <pages> pages 257-271, </pages> <publisher> MIT Press, </publisher> <month> October </month> <year> 1991. </year>
Reference-contexts: This algorithm was independently reinvented at least four times by different people at about the same time: Mohamed Amraoui at the Universite de Rennes I [8], Andre Marien and Bart Demoen at BIM and KUL <ref> [86, 88] </ref>, Kent Boortz at SICS [16], and Micha Meier at ECRC [94]. Write mode propagation was discussed earlier by Andrew Turk [146]. Figures 6 and 8 show how the unification X=f (g (A),h (B)) is compiled in the WAM and by the two-stream algorithm.
Reference: 89. <author> Andre Marien. </author> <title> Improving the Compilation of Prolog in the Framework of the Warren Abstract Machine. </title> <type> Ph.D. dissertation, </type> <institution> Katholieke Universiteit Leuven, </institution> <month> September </month> <year> 1993. </year>
Reference-contexts: Other people have contributed to the implementation. Because BIM Prolog only ran on a few machines, it was possible for different implementation ideas to be tried over the years. For more information on the internals of BIM Prolog, see <ref> [89] </ref>. BIM Prolog made several notable contributions, including those listed below. * It was the first WAM-based system: To do native code compilation. To do heap garbage collection. The Morris constant-space pointer-reversal algo rithm was available in release 1.0 in 1985.
Reference: 90. <author> Kim Marriott, Maria Garca de la Banda, and Manuel Hermenegildo. </author> <title> Analyzing Logic Programs with Dynamic Scheduling. </title> <booktitle> In 20th POPL, ACM, </booktitle> <year> 1994. </year>
Reference-contexts: This was the first practical application of abstract interpretation to logic programs. The &-Prolog system both derives information and uses it for optimization. PLAI, the successor to MA 3 , subsumes it and has been extended to analyze programs in constraint languages [49] and languages with delaying <ref> [90] </ref>. * The FCP (:,?) compiler (Flat Concurrent Prolog with Ask and Tell guards and read-only variables), written by Shmuel Kliger, has a global analysis phase [72]. * The Parma system, written by Andrew Taylor, is an implementation of Prolog with global analysis targeted to the MIPS processor [140]. * The
Reference: 91. <author> K. Mehlhorn and A. Tsakalidis. </author> <title> Data Structures. </title> <booktitle> Chapter 6 of Handbook of Theoretical Computer Science, Volume A: Algorithms and Complexity, </booktitle> <pages> pages 301-341, </pages> <publisher> MIT Press/Elsevier, </publisher> <year> 1990. </year>
Reference-contexts: (the PDL) to support unification, one stack (the trail) to support the interaction of unification and backtracking, one area as code space, and one area as a symbol table. 4 Unless the type can be determined at compile-time. 5 More precisely, variable-variable unification can be implemented with a Union-Find algorithm <ref> [91] </ref>. With this algorithm, unifying n variables requires O (nff (n)) time, where ff (n) is the inverse Ackermann function. Research Report No. 36 December 1993 8 Peter Van Roy * The global stack or heap.
Reference: 92. <author> Micha Meier. </author> <title> Shallow Backtracking in Prolog Programs. </title> <type> Internal report, </type> <institution> ECRC, Munich, Germany, </institution> <month> February </month> <year> 1987. </year>
Reference-contexts: The algorithm was not implemented. * Carlsson [25] has implemented a restricted version of the above algorithm in SICStus Prolog. Meier <ref> [92] </ref> has done a similar implementation in KCM-SEPIA. Choice point creation is split into two parts. The try and try me else instructions are modified to create a partial choice point that only contains P and TR. A new instruction, neck, is added. <p> Sequential Prolog Implementation 47 Feature Benefit (%) multiway tag branch (MWAC) 23.1 context dependent execution (flags) 11.4 dereferencing support 10.0 trail support 7.2 load term 5.7 fast choice point creation/restoration 2.3 Total 59.7 Table 5: The Benefits of Prolog-Specific Features in the KCM evolved greatly from Warren's original design (see <ref> [92, 112] </ref>). The KCM supports the delayed creation of choice points. The KCM runs KCM-SEPIA, a large subset of SEPIA that was ported to it (see Section 3.1.7). The Prolog support on the KCM improves its performance by a factor of 1.60 [112, 141].
Reference: 93. <author> M. Meier, A. Aggoun, D. Chan, P. Dufresne, R. Enders, D. Henry de Villeneuve, A. Herold, P. Kay, B. Perez, E. van Rossum, and J. Schimpf. </author> <title> SEPIA-An Extendible Prolog System. </title> <booktitle> In Proceedings of the 11th World Computer Congress IFIP'89, </booktitle> <pages> pages 1127-1132, </pages> <address> San Francisco, </address> <month> August </month> <year> 1989. </year>
Reference-contexts: Several Prolog systems were built at ECRC. An early system is ECRC-Prolog (1984-1986), a Prolog-to-C compiler for an enhanced MU-Prolog. At the time, ECRC-Prolog had the fastest implementation of delaying. The next system, SEPIA (Standard ECRC Prolog Integrating Advanced Features), first released in 1988, was a major improvement <ref> [93] </ref>. Other systems are Opium [44], an extensible debugging environment, and MegaLog [15], a WAM-based system with extensions to manage databases (e.g., persistence). The most recent system, ECLiPSe (ECRC Common Logic Programming System) [45, 95], integrates the facilities of SEPIA, MegaLog, CHIP, and Opium.
Reference: 94. <author> Micha Meier. </author> <title> Compilation of Compound Terms in Prolog. </title> <booktitle> In NACLP90, </booktitle> <pages> pages 63-79, </pages> <publisher> MIT Press, </publisher> <month> October </month> <year> 1990. </year>
Reference-contexts: This algorithm was independently reinvented at least four times by different people at about the same time: Mohamed Amraoui at the Universite de Rennes I [8], Andre Marien and Bart Demoen at BIM and KUL [86, 88], Kent Boortz at SICS [16], and Micha Meier at ECRC <ref> [94] </ref>. Write mode propagation was discussed earlier by Andrew Turk [146]. Figures 6 and 8 show how the unification X=f (g (A),h (B)) is compiled in the WAM and by the two-stream algorithm.
Reference: 95. <author> Micha Meier. </author> <title> Better Late Than Never. </title> <type> Internal report, </type> <institution> ECRC, Munich, Germany, </institution> <year> 1993. </year> <booktitle> In ICLP '93 Workshop on Practical Implementations and Systems Experience, </booktitle> <address> Budapest, Hungary, </address> <month> June </month> <year> 1993. </year>
Reference-contexts: Other systems are Opium [44], an extensible debugging environment, and MegaLog [15], a WAM-based system with extensions to manage databases (e.g., persistence). The most recent system, ECLiPSe (ECRC Common Logic Programming System) <ref> [45, 95] </ref>, integrates the facilities of SEPIA, MegaLog, CHIP, and Opium. The system supports rational tree unification and indefinite 13 Curiously, both systems are written mostly in assembly code, several hundred thousand lines worth. December 1993 Digital PRL 1983-1993: The Wonder Years of Sequential Prolog Implementation 41 precision rational arithmetic. <p> December 1993 Digital PRL 1983-1993: The Wonder Years of Sequential Prolog Implementation 41 precision rational arithmetic. It provides libraries that implement constraint solvers for atomic finite domains and linear inequalities. ECLiPSe is a WAM-based emulator with extensive support for delaying <ref> [95] </ref>. This makes it easy to write constraint solvers in the language itself. ECLiPSe supports this with two concepts: metaterms and suspensions. A metaterm is a variable with a set of user-defined attributes. The set of attributes is similar to a Lisp property list. A suspension is a closure.
Reference: 96. <author> C. S. Mellish. </author> <title> Automatic Generation of Mode Declarations for Prolog Programs (draft). </title> <institution> Department of Artificial Intelligence, University of Edinburgh, </institution> <month> August </month> <year> 1981. </year>
Reference-contexts: Getzinger [50] has recently presented an extensive taxonomy of analysis domains and studied their effects on execution time and code size. Since Mellish's early work in 1981 and 1985 <ref> [96, 98] </ref>, global analysis has been considered useful for Prolog implementation. This section summarizes the work that has been done in making analysis part of a real system. By type we denote any information known (at compile-time or at run-time) about a variable's value at run-time.
Reference: 97. <author> C. S. Mellish and S. Hardy. </author> <title> Integrating Prolog in the POPLOG environment. In Implementations of PROLOG, </title> <editor> ed. J. A. Campbell, </editor> <year> 1984, </year> <pages> pages 147-162. </pages>
Reference-contexts: The resulting instruction set is essentially a simplified subset of the WAM. Implementing Prolog by means of continuations is an old technique. It was used to implement Prolog on Lisp machines and in Pop-11, see for example <ref> [23, 97] </ref>. The technique has recently received a boost by Tarau's highly efficient implementation. Functional languages have more often been implemented by means of continuations. A good example is the Standard ML of New Jersey system, which uses an intermediate representation in which all continuations are explicit (Continuation-Passing Style) [9].
Reference: 98. <author> C. S. Mellish. </author> <title> Some Global Optimizations for a Prolog Compiler. In JLP, </title> <publisher> Elsevier North-Holland, </publisher> <pages> pages 43-66, </pages> <note> vol. 1, </note> <year> 1985. </year>
Reference-contexts: Getzinger [50] has recently presented an extensive taxonomy of analysis domains and studied their effects on execution time and code size. Since Mellish's early work in 1981 and 1985 <ref> [96, 98] </ref>, global analysis has been considered useful for Prolog implementation. This section summarizes the work that has been done in making analysis part of a real system. By type we denote any information known (at compile-time or at run-time) about a variable's value at run-time. <p> Research Report No. 36 December 1993 48 Peter Van Roy * The PLM [42, 43] (1983-87). The Programmed Logic Machine. 18 This is a microcoded WAM. * The VLSI-PLM [128, 129] <ref> (1985-89) </ref>. This is a single-chip implementation of the PLM. * The Xenologic X-1. This is a commercial version of the PLM, designed as a coprocessor for the Sun-3. Due to weaknesses in its system software, this system was not commercially successful. * The VLSI-BAM [63] (1988-91). <p> For example, IBM Prolog is about 1.5 times faster with mode declarations. Research Report No. 36 December 1993 50 Peter Van Roy System Machine (Year) Clock Benchmark (MHz) N Q D S R mean yPLM compiler [148] PLM [43] <ref> (1985) </ref> 10. 19 12 9 12 8 11 ESP PSI-II (1986) 6.45 41 25 12 18 10 16 KCM-SEPIA [112] KCM (1989) 12.5 83 57 37 33 15 32 yPegasus compiler [125] Pegasus-II (1990) 10. 91 69 39 40 19 39 yAquarius [63] VLSI-BAM (1991) 20. 270 260 75 57 32

References-found: 98

