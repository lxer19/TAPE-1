URL: http://www.wi.leidenuniv.nl/~gusz/adapt.ps.gz
Refering-URL: http://www.wi.leidenuniv.nl/~gusz/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Adaptation in Evolutionary Computation: A Survey  
Author: Robert Hinterding, Zbigniew Michalewicz, and Agoston E. Eiben 
Abstract: Adaptation of parameters and operators is one of the most important and promising areas of research in evolutionary computation; it tunes the algorithm to the problem while solving the problem. In this paper we develop a classification of adaptation on the basis of the mechanisms used, and the level at which adaptation operates within the evolutionary algorithm. The classification covers all forms of adaptation in evolutionary computation and suggests further research. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P.J. Angeline. </author> <title> Adaptive and self-adaptive evolutionary computation. </title> <editor> In M. Palaniswami, Y. Attikiouzel, R.J.II Marks, D. Fogel, and T. Fukuda, editors, </editor> <title> Computational Intelligence, A Dynamic System Perspective. </title> <publisher> IEEE Press, </publisher> <year> 1995. </year> <month> pp.152-161. </month>
Reference-contexts: We give classifications of adaptation in Table I; this classification is based on the mechanism of adaptation (adaptation type) and on which level inside the EA adaptation occurs (adaptation level). These classifications are orthogonal and encompass all forms of adaptation within EAs. Angeline's classification <ref> [1] </ref> is from a different perspective and forms a subset of our classifications. The Type of adaptation consists of two main categories: static (no change) and dynamic, with the latter divided further into deterministic (D), adaptive (A), and self-adaptive (SA) mechanisms.
Reference: [2] <author> J. Arabas, Z. Michalewicz, and J. Mulawka. </author> <title> GAVaPS | a genetic algorithm with varying population size. </title> <booktitle> In Proceedings of the First IEEE Conference on Evolutionary Computation. </booktitle> <publisher> IEEE Press, </publisher> <year> 1994. </year> <pages> pp. 73-78. </pages>
Reference-contexts: The number of produced offspring N (t) is proportional to the size of the population at given generation t, whereas the number of individuals "to die" D (t) depends on age of individual chromosomes. There are several heuristics one can use for the age allocation for individuals <ref> [2] </ref>; all of them require a feedback from the current state of the search. D. Component Level Adaption Component-level adaptation adjusts strategy parameters local to some component or gene of an individual in the population.
Reference: [3] <author> T. </author> <title> Back. </title> <booktitle> Self-adaption in genetic algorithms. In Proceedings of the First European Conference on Artificial Life, </booktitle> <address> Cambridge, 1992. </address> <publisher> MIT Press. </publisher> <pages> pp. 263-271. </pages>
Reference-contexts: Theoretical analysis of -control (and the 1/5-Rule) done by Beyer can be found in [5]. Self-adaptation was extended to EP by Fogel et al. [14] and to GAs by Back <ref> [3] </ref>, Hinterding [19] and Smith & Fogarty [34].
Reference: [4] <author> J.C. Bean and A.B. Hadj-Alouane. </author> <title> A dual genetic algorithm for bounded integer programs. </title> <type> Tr 92-53, </type> <institution> Department of Industrial and Operations Engineering, The University of Michigan, </institution> <year> 1992. </year>
Reference-contexts: An extensive study of this kind of "learning-rule" mechanisms was done by Tuson & Ross [37]. Adaption was also used to change the objective function by increasing or decreasing penalty coefficients for violated constraints. For example, Bean & Hadj-Alouane <ref> [4] </ref> designed a penalty function where its one component takes a feedback from the search process.
Reference: [5] <author> H.-G. Beyer. </author> <title> Toward a theory of evolution strategies. </title> <journal> Evolutionary Computation, </journal> <volume> 1(2) </volume> <pages> 165-188, </pages> <year> 1993. </year>
Reference-contexts: Schwefel [31], [32] developed this method to self-adapt the mutation step size and the mutation rotation angles in Evolution Strategies. Theoretical analysis of -control (and the 1/5-Rule) done by Beyer can be found in <ref> [5] </ref>. Self-adaptation was extended to EP by Fogel et al. [14] and to GAs by Back [3], Hinterding [19] and Smith & Fogarty [34].
Reference: [6] <author> P Darwen and X. Yao. </author> <title> Every niching mehtod has its niche: Fitness sharing and implicit sharing compared. </title> <editor> In H-M. Voigt, W. Ebeling, I. Rechenberg, and H-P. Schwefel, editors, </editor> <booktitle> Parel-lel Problem Solving from Nature - PPSV IV, volume 1141 of Lecture Notes in Computer Science. </booktitle> <publisher> Springer, </publisher> <address> Berlin, </address> <year> 1996. </year> <pages> pp. 398-407. </pages>
Reference-contexts: Darwen & Yao <ref> [6] </ref>, explore both deterministic environmental adaptation and adaptive environmental adaptation in their paper comparing fitness sharing methods. B. Population Level Adaption In EAs some (or all in simple EAs) of the parameters are global, modifying these parameters when they apply to all members of the population is population level adaptation.
Reference: [7] <author> L. Davis. </author> <title> Adapting operator probabilities in genetic algorithms. </title> <booktitle> In Proceedings of the 3rd International Conference on Genetic Algorithms. </booktitle> <publisher> Morgan Kaufmann, </publisher> <month> pp.61-69 </month> <year> 1989. </year>
Reference: [8] <editor> L. Davis, editor. </editor> <booktitle> Handbook of Genetic Algorithms. </booktitle> <publisher> Van Nostrand Reinhold, </publisher> <year> 1991. </year>
Reference-contexts: An example for GAs is Davis's `adaptive operator fitness': where feedback on the success of a larger number of reproduction operators is utilised to adjust their probability of being used <ref> [8] </ref>. Julstrom's adaptive mechanism regulates the ratio between crossovers and mutations based on their performance [23]. An extensive study of this kind of "learning-rule" mechanisms was done by Tuson & Ross [37]. Adaption was also used to change the objective function by increasing or decreasing penalty coefficients for violated constraints.
Reference: [9] <author> K. A. De Jong. </author> <title> An Analysis of the Behaviour of a Class of Genetic Adaptive System. </title> <type> Doctoral dissertation, </type> <institution> University of Michigan, </institution> <year> 1975. </year> <note> Dissertation Abstract International, 36(10), 5140B. (University Microfilms No 76-9381). </note>
Reference-contexts: Typically this happens by running numerous tests and trying to find a link between parameter values and EA performance. This method is commonly used for most of the strategy parameters. De Jong <ref> [9] </ref> put considerable effort into finding parameter values which were good for a number of numeric test problems using a traditional GA. He determined experimentally recommended values for the probability of using single-point crossover and bit mutation.
Reference: [10] <author> A.E. Eiben and Zs. Ruttkay. </author> <title> Self-adaptivity for constraint satisfaction: Learning penalty functions. </title> <booktitle> In Proceedings of the 3rd IEEE International Conference on Evolutionary Computation. </booktitle> <publisher> IEEE Press, </publisher> <year> 1996. </year> <pages> pp. 258-261. </pages>
Reference-contexts: In both cases, functions f j measure the violation of the j-th constraint. Eiben & Ruttkay <ref> [10] </ref> described an implementation of an evolutionary algorithm for constraint satisfaction problems, where the penalty coefficients of violated constraints were increased after each run and used in a following run on the same problem.
Reference: [11] <author> A.E. Eiben and J.K. van der Hauw. </author> <title> Graph coloring with adaptive evolutionary algorithms. </title> <type> Technical Report TR-96-11, </type> <institution> Leiden University, </institution> <month> August </month> <year> 1996. </year> <note> also available as http://www.wi.leidenuniv.nl/~gusz/graphcol.ps.gz. </note>
Reference-contexts: Recent work of Eiben & van der Hauw on solving (discrete) constraint satisfaction problems is also based on an adaptive penalty technique that periodically increases the penalty of those constraints that are violated. This mechanism highly improved GA performance on 3-SAT problems, [12], and on graph 3-colouring problems <ref> [11] </ref>. Other examples include adaptation of probabilities of eight operators for adaptive planner/navigator [39], where the feedback from the evolutionary process includes, through the operator performance index, effectiveness of operators in improving the fitness of a path, their opera tion time, and their side effect to future generations.
Reference: [12] <author> A.E. Eiben and J.K. van der Hauw. </author> <title> Solving 3-SAT by GAs adapting constraint weights. </title> <booktitle> In Proceedings of the 4th IEEE International Conference on Evolutionary Computation. </booktitle> <publisher> IEEE Press, </publisher> <year> 1997. </year>
Reference-contexts: Recent work of Eiben & van der Hauw on solving (discrete) constraint satisfaction problems is also based on an adaptive penalty technique that periodically increases the penalty of those constraints that are violated. This mechanism highly improved GA performance on 3-SAT problems, <ref> [12] </ref>, and on graph 3-colouring problems [11].
Reference: [13] <author> T. Fogarty. </author> <title> Varying the probability of mutation in the genetic algorithm. </title> <editor> In J.D. Schaffer, editor, </editor> <booktitle> Proceedings of the 3rd International Conference on Genetic Algorithms, </booktitle> <pages> pages 104-109. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1989. </year>
Reference-contexts: Here the mutation probability mut% will decrease from 0:5 to 0:2 as the number of generations increases to G. Early examples of this approach are the varying mutation rates as used by Fogarty <ref> [13] </ref>, or Hesser & Manner [18] in GAs. This method of adaptation was used also in defining a mutation operator for floating-point representations [25]: non-uniform mutation.
Reference: [14] <editor> D.B. Fogel, L.J. Fogel, and J.W. Atmar. </editor> <title> Meta-evolutionary programming. In R.R. </title> <editor> Chen, editor, </editor> <booktitle> Proc. of the 25th Asilomar Conf. on Signals, Systems, and Computers, </booktitle> <address> San Jose, 1991. </address> <publisher> Maple Press. </publisher> <pages> pp. 540-545. </pages>
Reference-contexts: Schwefel [31], [32] developed this method to self-adapt the mutation step size and the mutation rotation angles in Evolution Strategies. Theoretical analysis of -control (and the 1/5-Rule) done by Beyer can be found in [5]. Self-adaptation was extended to EP by Fogel et al. <ref> [14] </ref> and to GAs by Back [3], Hinterding [19] and Smith & Fogarty [34].
Reference: [15] <editor> L.J. Fogel, P.J. Angeline, and D.B. Fogel. </editor> <title> An evolutionary programming approach to self-adaption on finite state machines. </title> <editor> In J.R. McDonnell, R.G. Reynolds, and D.B. Fogel, editors, </editor> <booktitle> Proceedings of the Forth Annual Conference on Evolutionary Programming, </booktitle> <address> Massachusetts, 1995. </address> <publisher> MIT Press. </publisher> <pages> pp. 355-365. </pages>
Reference-contexts: This has been the case when single chromosome representations are used (which is the overwhelming case), as otherwise numerical and non-numerical representations would need to be combined on the same chromosome. Examples of self-adaptation for non-numerical problems are Fogel et al. <ref> [15] </ref> where they self-adapted the relative probabilities of five mutation operators for the components of a finite state machine. The other example is Hinterding [20], where a multi-chromosome GA is used to implement the self-adaptation in the Cutting Stock Problem with contiguity.
Reference: [16] <author> D.E. Goldberg, K. Deb, and B. Korb. </author> <title> Do not worry, be messy. </title> <booktitle> In Proceedings of the 4th International Conference on Genetic Algorithms. </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year> <pages> pp. 24-30. </pages>
Reference: [17] <author> J.J. Grefenstette. </author> <title> Optimization of control parameters for genetic algorithms. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> vol. 16(1):pp. </volume> <pages> 122-128, </pages> <year> 1986. </year>
Reference-contexts: De Jong [9] put considerable effort into finding parameter values which were good for a number of numeric test problems using a traditional GA. He determined experimentally recommended values for the probability of using single-point crossover and bit mutation. Grefenstette <ref> [17] </ref> used a GA as a meta-algorithm to optimise some of the parameter values. B. Dynamic Dynamic adaptation happens if there is some mechanism which modifies a strategy parameter without external control.
Reference: [18] <author> J. Hesser and R. </author> <title> Manner. Towards an optimal mutation probability for genetic algorithms. </title> <editor> In H.-P. Schwefel and R. Manner, editors, </editor> <booktitle> Proceedings of the 1st Conference on Parallel Problem Solving from Nature, number 496 in Lecture Notes in Computer Science, </booktitle> <pages> pages 23-32. </pages> <publisher> Springer-Verlag, </publisher> <year> 1990. </year>
Reference-contexts: Here the mutation probability mut% will decrease from 0:5 to 0:2 as the number of generations increases to G. Early examples of this approach are the varying mutation rates as used by Fogarty [13], or Hesser & Manner <ref> [18] </ref> in GAs. This method of adaptation was used also in defining a mutation operator for floating-point representations [25]: non-uniform mutation.
Reference: [19] <author> R. Hinterding. </author> <title> Gaussian mutation and self-adaption in numeric genetic algorithms. </title> <booktitle> In IEEE International Conference on Evolutionary Computation. </booktitle> <publisher> IEEE Press, </publisher> <year> 1995. </year> <pages> pp 384-389. </pages>
Reference-contexts: Theoretical analysis of -control (and the 1/5-Rule) done by Beyer can be found in [5]. Self-adaptation was extended to EP by Fogel et al. [14] and to GAs by Back [3], Hinterding <ref> [19] </ref> and Smith & Fogarty [34].
Reference: [20] <author> R Hinterding. </author> <title> Self-adaptation using multi-chromosomes. </title> <booktitle> In Proceedings of the 4th IEEE International Conference on Evolutionary Computation. </booktitle> <publisher> IEEE Press, </publisher> <year> 1997. </year>
Reference-contexts: Examples of self-adaptation for non-numerical problems are Fogel et al. [15] where they self-adapted the relative probabilities of five mutation operators for the components of a finite state machine. The other example is Hinterding <ref> [20] </ref>, where a multi-chromosome GA is used to implement the self-adaptation in the Cutting Stock Problem with contiguity. Here self-adaptation is used to adapt the probability of using one of the two available mutation operators, and the strength of the group mutation operator. 4 IV.
Reference: [21] <author> R. Hinterding, Z. Michalewicz, </author> <title> and T.C. Peachey. Self-adaptive genetic algorithm for numeric functions. </title> <editor> In H-M. Voigt, W. Ebel-ing, I. Rechenberg, and H-P. Schwefel, editors, </editor> <booktitle> Parellel Problem Solving from Nature - PPSV IV, volume 1141 of Lecture Notes in Computer Science, </booktitle> <address> Berlin, 1996. </address> <publisher> Springer. </publisher> <pages> pp. 420-429. </pages>
Reference: [22] <author> J.A. Joines and C.R. Houck. </author> <title> On the use of non-stationary penalty functions to solve nonlinear constrained optimization problems with gas. </title> <booktitle> In Proceedings of the First IEEE Conference on Evolutionary Computation. </booktitle> <publisher> IEEE Press, </publisher> <year> 1994. </year> <pages> pp. 579-584. </pages>
Reference-contexts: Deterministic dynamic adaptation was also used for changing the objective function of the problem. For constrained problems it can be applied by increasing the penalties for violated constraints with evolution time <ref> [22] </ref>, [26]. Joines & Houck used the following formula: F (~x) = f (~x) + (C fi t) ff P m fi whereas Michalewicz & Attia experimented with F (~x; t ) = f (~x) + 1 P m j (~x).
Reference: [23] <author> B.A. Julstrom. </author> <title> What have you done for me lately? adapting operator probabilities in a steady-state genetic algorithm. </title> <booktitle> In Proceedings of the Sixth International Conference on Genetic Algorithms. </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1995. </year> <pages> pp. 81-87. </pages>
Reference-contexts: An example for GAs is Davis's `adaptive operator fitness': where feedback on the success of a larger number of reproduction operators is utilised to adjust their probability of being used [8]. Julstrom's adaptive mechanism regulates the ratio between crossovers and mutations based on their performance <ref> [23] </ref>. An extensive study of this kind of "learning-rule" mechanisms was done by Tuson & Ross [37]. Adaption was also used to change the objective function by increasing or decreasing penalty coefficients for violated constraints.
Reference: [24] <author> J. </author> <title> Lis. Parallel genetic algorithm with dynamic control parameter. </title> <booktitle> In Proceedings of the 1996 IEEE Conference on Evolutionary Computation, Piscataway,NY, 1996. </booktitle> <publisher> IEEE Press. </publisher> <pages> pp. 324-329. </pages>
Reference-contexts: The example of deterministic modification of the mutation rate given above is deterministic population level adaptation, and Rechenberg's `1=5 success rule' is an example of adaptive population level adaptation. Population level adaptation also covers cases where a number of populations are used in a parallel EA or otherwise, Lis <ref> [24] </ref> uses feedback from a number of parallel populations to dynamically adapt the mutation rate. The feedback from populations with different mutation probabilities was used to adjust the mutation probabilities of all the populations up or down.
Reference: [25] <author> Z. Michalewicz. </author> <title> Genetic Algorithms + Data Structures = Evolution Programs. </title> <publisher> Springer - Verlag, </publisher> <address> New York, </address> <note> 3rd edition, </note> <year> 1996. </year>
Reference-contexts: Early examples of this approach are the varying mutation rates as used by Fogarty [13], or Hesser & Manner [18] in GAs. This method of adaptation was used also in defining a mutation operator for floating-point representations <ref> [25] </ref>: non-uniform mutation. <p> population after single iteration is P opSize (t + 1) = P opSize (t) + N (t) D (t), where D (t) is the number of chromosomes which die off during generation t and N (t) is the number of offspring produced during the generation t (for details, see Michale-wicz <ref> [25] </ref>). The number of produced offspring N (t) is proportional to the size of the population at given generation t, whereas the number of individuals "to die" D (t) depends on age of individual chromosomes.
Reference: [26] <author> Z. Michalewicz and N. Attia. </author> <title> Evolutionary optimization of constrained problems. In A.V. </title> <editor> Sebald and L.J. Fogel, editors, </editor> <booktitle> Proceedings of the Third Annual Conference on Evolutionary Programming. World Scientific, </booktitle> <year> 1994. </year> <pages> pp. 98-108. </pages>
Reference-contexts: Deterministic dynamic adaptation was also used for changing the objective function of the problem. For constrained problems it can be applied by increasing the penalties for violated constraints with evolution time [22], <ref> [26] </ref>. Joines & Houck used the following formula: F (~x) = f (~x) + (C fi t) ff P m fi whereas Michalewicz & Attia experimented with F (~x; t ) = f (~x) + 1 P m j (~x).
Reference: [27] <editor> R. Rechenberg. Evolutionsstrategie: Optimierung technischer Syseme nach Prinzipien der biologischen Evolution. Frommann-Holzboog, </editor> <address> Stuttgart, </address> <year> 1973. </year>
Reference-contexts: Early examples of this type of adaptation include Rechenberg's `1=5 success rule' in Evolution Strategies, which was used to vary the step size of mutation <ref> [27] </ref>. This rule states that the ratio of successful mutations to all mutations should be 1=5, hence if the ratio is greater than 1=5 then increase the step size, and if the ratio is less than 1=5 then decrease the step size.
Reference: [28] <author> J.D. Schaffer and A. Morishima. </author> <title> An adaptive crossover distribution mechanism for genetic algorithms. </title> <booktitle> In Proceedings of the 2nd International Conference on Genetic Algorithms. </booktitle> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1987. </year> <pages> pp. 36-40. </pages>
Reference-contexts: C. Individual Level Adaption Individual level adaptation adjusts strategy parameters held within individuals and whose value affects only that individual. Examples are: the adaptation of the mutation step size in ESs, EP, and GAs; the adaptation of crossover points in GAs <ref> [28] </ref> and [38].
Reference: [29] <author> D. Schlierkamp-Voosen and Muhlenbein. </author> <title> Adaption of population sizes by competing subpopulations. </title> <booktitle> In Proceedings of the 1996 IEEE Conference on Evolutionary Computation, Piscat-away,NY, 1996. </booktitle> <publisher> IEEE Press. </publisher> <pages> pp. 330-335. </pages>
Reference-contexts: The feedback from populations with different mutation probabilities was used to adjust the mutation probabilities of all the populations up or down. Schlierkamp-Voosen & Muhlenbein <ref> [29] </ref> use competition between sup-populations to determine which populations will lose or gain individuals. Hinterding et al.[21] use feedback from three sub-populations with different population sizes to adaptively change some or all of the sub-population sizes. C.
Reference: [30] <author> N. Schraudolph and R. Belew. </author> <title> Dynamic parameter encoding for genetic algorithms. </title> <journal> Machine Learning, </journal> <volume> vol. 9(1):pp. </volume> <pages> 9-21, </pages> <year> 1992. </year>
Reference: [31] <author> H-P. Schwefel. </author> <title> Numerische Optimierung von Computer-Modellen mittels der Evolutionsstrategie, </title> <booktitle> volume 26 of Interdisciplinary systems research. </booktitle> <address> Birhauser, Basel, </address> <year> 1977. </year>
Reference-contexts: These encoded parameters do not affect the fitness of individuals directly, but "better" values will lead to "better" individuals and these individuals will be more likely to survive and produce offspring and hence propagate these "better" parameter values. Schwefel <ref> [31] </ref>, [32] developed this method to self-adapt the mutation step size and the mutation rotation angles in Evolution Strategies. Theoretical analysis of -control (and the 1/5-Rule) done by Beyer can be found in [5]. <p> is in ESs, where the algorithm can be configured for individual level adaptation (one mutation step size per individual), component level adaptation (one mutation step size per component) or with two types of component level adaptation where both the mutation step size and rotation angle is self-adapted for individual components <ref> [31] </ref>. Hinterding et al.[21] combine global-level adaptation of the population size with individual level self-adaptation of the mutation step size for optimising numeric functions. Combining forms of adaptation has not been used much as the interactions are complex, hence deterministic or adaptive rules will be difficult to work out.
Reference: [32] <author> H-P. Schwefel. </author> <title> Evolution and Optimum Seeking. </title> <booktitle> Sixth-Generation Computer Technology Series. </booktitle> <publisher> Wiley, </publisher> <year> 1995. </year>
Reference-contexts: These encoded parameters do not affect the fitness of individuals directly, but "better" values will lead to "better" individuals and these individuals will be more likely to survive and produce offspring and hence propagate these "better" parameter values. Schwefel [31], <ref> [32] </ref> developed this method to self-adapt the mutation step size and the mutation rotation angles in Evolution Strategies. Theoretical analysis of -control (and the 1/5-Rule) done by Beyer can be found in [5].
Reference: [33] <author> C.G. Shaefer. </author> <title> The argot strategy: Adaptive representation genetic optimizer technique. </title> <booktitle> In Proceedings of the 2nd International Conference on Genetic Algorithms. </booktitle> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1987. </year> <pages> pp. 50-55. </pages>
Reference: [34] <author> J. Smith and T. Fogarty. </author> <title> Self-adaptation of mutation rates in a steady-state genetic algorithm. </title> <booktitle> In Proceedings of the 3rd IEEE International Conference on Evolutionary Computation. </booktitle> <publisher> IEEE Press, </publisher> <year> 1996. </year> <pages> pp. 318-323. </pages>
Reference-contexts: Theoretical analysis of -control (and the 1/5-Rule) done by Beyer can be found in [5]. Self-adaptation was extended to EP by Fogel et al. [14] and to GAs by Back [3], Hinterding [19] and Smith & Fogarty <ref> [34] </ref>.
Reference: [35] <author> W.M. Spears. </author> <title> Adapting crossover in evolutionary algorithms. </title> <editor> In J.R. McDonnell, R.G. Reynolds, and D.B. Fogel, editors, </editor> <booktitle> Proceedings of the Fourth Annual Conference on Evolutionary Programming. </booktitle> <publisher> The MIT Press, </publisher> <year> 1995. </year> <pages> pp. 367-384. </pages>
Reference: [36] <author> M. Srinivas and L.M. Patnaik. </author> <title> Adaptive probabilities of crossover and mutation in genetic algorithms. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> vol. 24(4):pp. </volume> <pages> 17-26, </pages> <year> 1994. </year>
Reference: [37] <author> A. Tuson and P. Ross. </author> <title> Cost based operator rate adaptation: An investigation. </title> <editor> In H.-M. Voigt, W. Ebeling, I. Rechenberg, and H.-P. Schwefel, editors, </editor> <booktitle> Proceedings of the 4th Conference on Parallel Problem Solving from Nature, number 1141 in Lecture Notes in Computer Science, </booktitle> <pages> pages 461-469. </pages> <publisher> Springer, </publisher> <address> Berlin, </address> <year> 1996. </year>
Reference-contexts: Julstrom's adaptive mechanism regulates the ratio between crossovers and mutations based on their performance [23]. An extensive study of this kind of "learning-rule" mechanisms was done by Tuson & Ross <ref> [37] </ref>. Adaption was also used to change the objective function by increasing or decreasing penalty coefficients for violated constraints. For example, Bean & Hadj-Alouane [4] designed a penalty function where its one component takes a feedback from the search process.
Reference: [38] <author> T. White and F. Oppacher. </author> <title> Adaptive crossover using automata. </title> <editor> In H.-P. Schwefel Y. Davidor and R. Manner, editors, </editor> <booktitle> Proceedings of the 3rd Conference on Parallel Problem Solving from Nature, number 866 in Lecture Notes in Computer Science, </booktitle> <pages> pages 229-238. </pages> <publisher> Springer-Verlag, </publisher> <year> 1994. </year>
Reference-contexts: C. Individual Level Adaption Individual level adaptation adjusts strategy parameters held within individuals and whose value affects only that individual. Examples are: the adaptation of the mutation step size in ESs, EP, and GAs; the adaptation of crossover points in GAs [28] and <ref> [38] </ref>.
Reference: [39] <author> J. Xiao, Z. Michalewicz, and L. Zhang. </author> <title> Evolutionary planner/navigator: Operator performance and self-tuning. </title> <booktitle> In Proceedings of the 3rd IEEE International Conference on Evolutionary Computation. </booktitle> <publisher> IEEE Press, </publisher> <month> May 20-22 </month> <year> 1996. </year> <pages> pp. 366-371. </pages>
Reference-contexts: This mechanism highly improved GA performance on 3-SAT problems, [12], and on graph 3-colouring problems [11]. Other examples include adaptation of probabilities of eight operators for adaptive planner/navigator <ref> [39] </ref>, where the feedback from the evolutionary process includes, through the operator performance index, effectiveness of operators in improving the fitness of a path, their opera tion time, and their side effect to future generations.
References-found: 39

