URL: http://http.cs.berkeley.edu/~bregler/quals.ps.gz
Refering-URL: http://http.cs.berkeley.edu/~bregler/pubs.html
Root-URL: http://www.cs.berkeley.edu
Title: Probabilistic Recognition of Human Actions  
Author: Christoph Bregler 
Date: May 28, 1996 1 Overview  
Abstract: The goal of this research is the development of a computer vision system that is able to model and recognize humans and their actions in image sequences. This is a problem of basic scientific interest and has a wide range of applications. Unlike previous approaches, which either fit detailed 3D models to images or work in a purely bottom up fashion, we plan to attack this problem with a layered framework consisting of probabilistic models of various types. The system will be unique in the way it integrates multiple cues of motion, color, texture, and shape, and iteratively updates hypotheses at various levels of abstraction in bottom-up and top-down fashion. Low level hypotheses capture coherent motion, texture, and color regions. Mid-level hypotheses represent body segments, segment pairs, simple actions, and motion cycles. And high-level hypotheses categorize complex actions like gestures, gaits, or dance-styles. Learning probabilistic models at various abstraction levels from example image sequences is another central idea in our proposed architecture. In recognition mode, the input to the system is a series of novel images and the output is a description of the scene at various degrees of abstraction. The system should locate a person and recognize the performed action. Examples are transcribing figure-skating scenes, recognizing action scenes in movies, or providing a gestural user interface. We believe that a system that is able to accomplish these tasks will dramatically advance the state-of-the-art in general object recognition and specific recognition of human actions. Recent developments in low and intermediate level vision, Bayesian inference and learning methodologies provide a substrate for our ambitious research goals. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Serge Ayer and Harpreet S. Sawhney. </author> <title> Layered representation of motion video using robust maximum-likelihood estimation of mixture models and mdl encoding. </title> <booktitle> In Int. Conf. Computer Vision, </booktitle> <pages> pages 777-784, </pages> <address> Cambridge, MA., </address> <year> 1995. </year>
Reference-contexts: Both examples involve local decisions. In complex noisy domains global optimization across several levels of abstraction is desired instead. 6 Recent trends in estimation of complex motion have led to probabilistic formulations that give a fresh start to the idea of bottom-up and top-down integration. For example Layered motion <ref> [47, 26, 1] </ref> assigns each pixel a probability value that it belongs to a specific motion model. The pixel probabilities and the motion models are updated in an iterative bottom-up and top-down phase using a maximum likelihood optimization following the E-M methodology [16]. <p> We could justify this in our probabilistic framework with an additional MDL prior, which prefers smaller number of hypothesis. The merging can be seen as a greedy search in the space of model numbers, which is similar to related techniques in layered motion <ref> [1] </ref>, first-best-model-merging [36], AutoClass [12], or techniques for inducing the structural component of Bayesian Belief networks [15]. It does not have to be a decreasing search order.
Reference: [2] <author> M.J. Black and Y. Yacoob. </author> <title> Tracking and recognizing rigid and non-rigid facial motions using local parametric models of image motion. </title> <booktitle> In ICCV, </booktitle> <year> 1995. </year>
Reference-contexts: Ekman and Friesen [17] developed such a language for facial expression called Facial Action Coding System 7 (FACS). Essa and Pentland [18] and Black and Yacoob <ref> [2] </ref> recognize prim-itive facial expression categories using motion models. We plan to develop a Body Action Coding System.
Reference: [3] <author> A. Blake, M. Isard, and D. Reynard. </author> <title> Learning to track the visual motion of contours. </title> <editor> In J. </editor> <booktitle> Artificial Intelligence, </booktitle> <year> 1995. </year>
Reference-contexts: The simplest of all representations, by Freeman and Roth [20], achieved good performance in measuring spatiotemporal angle histograms of simple hand gestures. Other more general techniques based on linear subspace estimations (PCA) are reported for learning 2D outlines [49] of bodies and other articulated objects, contours of facial features <ref> [30, 3] </ref>, and graylevel appearance of faces and other objects [46, 39, 33, 44].
Reference: [4] <author> A.F. Bobick and A.D. Wilson. </author> <title> A state-based technique for the summarization and recognition of gesture. </title> <booktitle> In Proc. Int. Conf. Computer Vision, </booktitle> <year> 1995. </year>
Reference-contexts: Motion blobs of people walking front-to-parallel to the image plane are estimated using difference detection and are matched to the parametric spatiotemporal surfaces. Bobick and Wilson <ref> [4] </ref> and Starner and Pentland [45] estimate spatiotemporal hand gestures with Hidden Markov Models from example data. The used features are eigen images or blob configurations. Polana and Nelson propose a technique that does not use any spatiotemporal model.
Reference: [5] <author> H.A. Bourlard and Morgan N. </author> <title> Connectionist Speech Recognition, A Hybrid Approach. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1993. </year>
Reference-contexts: Assuming conditional independence we also combined the feature modalities in a Bayesian way at a higher phonetic level. 22 5.3 Multiple Levels of Abstraction Current speech recognition systems are prime examples where multiple levels of abstraction are integrated successfully. In the lip-reading project, we used a hybrid system <ref> [5] </ref> that combines the various levels in a probabilistic way. The lowest level were features obtained from Eigen-Images. The mid-level where categories similar to phonemes. We developed a set of smallest visual units called visemes and composed higher-level word models using such a coding.
Reference: [6] <author> C. Bregler, H. Hild, S. Manke, and A. Waibel. </author> <title> Improving connected letter recognition by lipreading. </title> <booktitle> In Int. Conf. Acoustics, Speech, and Signal Processing, </booktitle> <volume> volume 1, </volume> <pages> pages 557-560, </pages> <address> Minneapolis, 1993. </address> <publisher> IEEE. </publisher>
Reference-contexts: Like other human actions, visual speech is described as configurations over time. We already developed two lipreading systems <ref> [6, 7] </ref> where we demonstrated connected word recognition using active contour models, Eigen-Images, Multi-Layer-Perceptrons, and Hidden Markov Models in domains with varying complexity. Lip configurations like body configurations span only a very low dimensional sub-manifold embedded in some high dimensional feature space. <p> Both techniques can be applied to human actions in a similar way, although the spaces will be much more complex. 5.2 Multiple Cue Integration To achieve robustness in our lipreading system, we integrated visual and acoustic cues. Entropy-Weights <ref> [6] </ref> is one example where the different modalities are weighted according to their confidence value.
Reference: [7] <author> C. Bregler and Y. Konig. </author> <title> Eigenlips for robust speech recognition. </title> <booktitle> In Int. Conf. Acoustics, Speech, and Signal Processing, </booktitle> <pages> pages 669-672, </pages> <address> Adelaide, </address> <year> 1994. </year>
Reference-contexts: Like other human actions, visual speech is described as configurations over time. We already developed two lipreading systems <ref> [6, 7] </ref> where we demonstrated connected word recognition using active contour models, Eigen-Images, Multi-Layer-Perceptrons, and Hidden Markov Models in domains with varying complexity. Lip configurations like body configurations span only a very low dimensional sub-manifold embedded in some high dimensional feature space.
Reference: [8] <author> C. Bregler and J. Malik. </author> <title> Learning Appearance Based Models: Hierarchical Mixtures of Experts Approach based on Generalized Second Moments. </title> <type> Technical Report UCB//CSD-96-897, </type> <institution> Comp. Sci. Dep., U.C. </institution> <address> Berke-ley, http://www.cs/ bregler/soft.html, </address> <year> 1996. </year>
Reference-contexts: In a top-down phase the confidence values of the local features detectors were updated by the new high-level geometric hypothesis. 5.5 Learning in Vision Besides the Manifold Learning technique, Multi-Layer-Perceptrons, and Hidden Markov Model Estimation, we applied a related learning architecture to vehicle classification <ref> [8] </ref>. We used Hierarchical Mixtures of Experts [28], which also fit a smooth surface to example data. In this case the surface represents a mapping from input to output, which is a so called Regression Surface. The major advantage is the discriminant nature.
Reference: [9] <author> C. Bregler and S.M. Omohundro. </author> <title> Surface learning with applications to lipreading. </title> <editor> In Alspector Cowan, Tesauro, editor, </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <address> San Francisco, 1994. </address> <publisher> Morgan Kaufman. </publisher> <pages> 24 </pages>
Reference-contexts: Handcoded domain knowledge obtained from physiological studies could be used as initial values, but to achieve the best classification performance, we plan to adapt the parametric representation to labeled image sequence databases. Adaptive manifold representations <ref> [35, 9] </ref> or Hidden Markov Models [40] are two techniques that might be useful learning architectures for estimating configuration spaces and sequences. <p> Such priors can be classified as additional kinematic priors. The joint-angles of a pair of legs lie in a constrained manifold space. We can represent and estimate such spaces from data, using techniques reported in <ref> [9] </ref>. These representations are piecewise linear approximations of a nonlinear space. The maximization process can be decoupled in a similar fashion to how we simplified the HMM-based maximization. <p> Lip configurations like body configurations span only a very low dimensional sub-manifold embedded in some high dimensional feature space. We demonstrated how such model spaces can be induced from data using a technique called Manifold Learning <ref> [9] </ref>. To model configurations over time in this manifold representation we induced temporal statistical models using Hidden Markov Models.
Reference: [10] <author> C. Bregler, S.M. Omohundro, J. Shi, and Y. Konig. </author> <title> Towards a Robust Speechreading Dialog System. </title> <booktitle> In NATO Advanced Study Institute on Speechreading by Man and Machine, </booktitle> <year> 1995. </year>
Reference-contexts: In order to find the lips we investigated an iterative technique that incorporates the position of other facial parts in a probabilistic way <ref> [10] </ref>. Finding the lip position purely based on local low level information can not be achieved in a robust way. We also updated a higher-level hypothesis of the geometry between the facial parts. This hypothesis was guided by all low level facial feature extractors in a bottom-up phase.
Reference: [11] <author> L.W. Campbell and A.F. Bobick. </author> <title> Recognition of human body motion using phase space constraints. </title> <booktitle> In ICCV, </booktitle> <year> 1995. </year>
Reference-contexts: Campbell and Bobick <ref> [11] </ref> developed a system that recognizes ballet moves based on 3D point locations of joints. The locations are estimated using a marker based 3D tracking system. Similar to earlier reported systems, the constraints are estimated from data and represented as typical trajectories in phase space.
Reference: [12] <author> P. Cheeseman, J. Kelly, M Self, J.Stutz, W. Taylor, and D. Freeman. Auto-class: </author> <title> A bayesian classification system. </title> <booktitle> In Proc. of fifth Int. Conf. on Machine Learning, </booktitle> <year> 1988. </year>
Reference-contexts: We could justify this in our probabilistic framework with an additional MDL prior, which prefers smaller number of hypothesis. The merging can be seen as a greedy search in the space of model numbers, which is similar to related techniques in layered motion [1], first-best-model-merging [36], AutoClass <ref> [12] </ref>, or techniques for inducing the structural component of Bayesian Belief networks [15]. It does not have to be a decreasing search order.
Reference: [13] <author> E. Clergue, M. Goldber, N. Madrane, and B. Merialdo. </author> <title> Automatic face and gestual recognition for video indexing. </title> <booktitle> In Proc. of the Int. Workshop on Automatic Face- and Gesture-Recognition, </booktitle> <address> Zurich, </address> <year> 1995. </year>
Reference-contexts: the arm and background have to be sufficiently different. 2 Examples of more complex 3D body models based on super-quadrics and a larger number of degrees of freedom (DOF) are presented by Gavrila and Davis [21], and 3D mesh model of planar surface patches is presented by Clergue et al <ref> [13] </ref>. To match the model to edge features, Gavrila and Davis use a multi-camera approach, known initial pose, and a best-first search strategy (no inverse kinematical model is applied, the search is done in a generate-and-test fashion).
Reference: [14] <author> L. Concalves, E.D. Bernardo, E. Ursella, and P. Perona. </author> <title> Monocular tracking of the human arm in 3d. </title> <booktitle> In Proc. Int. Conf. Computer Vision, </booktitle> <year> 1995. </year>
Reference-contexts: The initial location is found using optical flow information, and the initial pose is found with a search over a complete walking cycle. Incremental matching is done using Kalman filter tracking. A similar approach based on cylinder models, edge matching, and Kalman filters is demonstrated by Goncalves and Perona <ref> [14] </ref> on unconstrained arm configurations.
Reference: [15] <author> G.F. Cooper and E. Herskovits. </author> <title> A bayesian method for the induction of probabilistic networks from data. </title> <journal> Machine Learning, </journal> <volume> 9, </volume> <year> 1992. </year>
Reference-contexts: The merging can be seen as a greedy search in the space of model numbers, which is similar to related techniques in layered motion [1], first-best-model-merging [36], AutoClass [12], or techniques for inducing the structural component of Bayesian Belief networks <ref> [15] </ref>. It does not have to be a decreasing search order.
Reference: [16] <author> A.P. Dempster, N.M. Laird, and D.B. Rubin. </author> <title> Maximum likelihood from incomplete data via the EM algorithm. </title> <journal> Journal of the Royal Statistical Society B, </journal> <volume> 39, </volume> <year> 1977. </year>
Reference-contexts: For example Layered motion [47, 26, 1] assigns each pixel a probability value that it belongs to a specific motion model. The pixel probabilities and the motion models are updated in an iterative bottom-up and top-down phase using a maximum likelihood optimization following the E-M methodology <ref> [16] </ref>. Bayesian Belief Networks [38] are another framework that allows one to model bottom-up, top-down, and the integration of multiple cues in a Bayesian way. Inference in a probabilistic domain is potentially exponential. <p> Now we are able to apply the well known Expectation Maximization Procedure <ref> [16] </ref> to find the maximum likelihood hypothesis for each image frame. We start with an initial guess of and then iteratively optimize the hypothesis with E- and M-steps. The initial guess at time 1 could be obtained from clustering the output of a standard optical flow procedure plus priors.
Reference: [17] <author> P. Ekman and W.V. Friesen. </author> <title> Facial Action Coding System. </title> <publisher> Consulting Psychologists Press Inc., </publisher> <address> 577 College Ave., Palo Alto, CA 94306, </address> <year> 1978. </year>
Reference-contexts: Human motion is caused by neural feed-back loops and is constrained by kinematics. This results in very characteristic joint-angle variations over time. It might be possible to decompose most complex human actions into a canonical set of primitive action units similar to phonemes in speech recognition. Ekman and Friesen <ref> [17] </ref> developed such a language for facial expression called Facial Action Coding System 7 (FACS). Essa and Pentland [18] and Black and Yacoob [2] recognize prim-itive facial expression categories using motion models. We plan to develop a Body Action Coding System.
Reference: [18] <author> I.A. Essa and A.P. Pentland. </author> <title> Facial expression recognition using a dynamic model and motion energy. </title> <booktitle> In ICCV, </booktitle> <year> 1995. </year>
Reference-contexts: It might be possible to decompose most complex human actions into a canonical set of primitive action units similar to phonemes in speech recognition. Ekman and Friesen [17] developed such a language for facial expression called Facial Action Coding System 7 (FACS). Essa and Pentland <ref> [18] </ref> and Black and Yacoob [2] recognize prim-itive facial expression categories using motion models. We plan to develop a Body Action Coding System.
Reference: [19] <author> M. Fleck, D. Forsyth, and C Bregler. </author> <title> Finding Naked People. </title> <publisher> ECCV96. </publisher>
Reference-contexts: In a first phase, 2D ribbon representations are extracted based on a combination static and motion edge histories (coincidence edge detector). In a second phase the body parts are labeled using the ribbon estimates, the body models, and structural constraints. Fleck and Forsyth <ref> [19] </ref> propose a new recognition strategy for naked people (and other articulated objects with uniform color or texture appearance), where the geometric body model consists of constraints only. 2D ribbon representations are estimated using the outline of skin-color based region groupings.
Reference: [20] <author> W. Freeman and M. Roth. </author> <title> Orientation histogrmas for hand gesture recognition. </title> <booktitle> In International Workshop on Automatic Face- and Gesture-Recognition, </booktitle> <year> 1995. </year>
Reference-contexts: A periodicity index for each grid location is computed over a sequence of images, and combination of all 4x4 periodicity indices is thresholded to decide if a periodic object is present. The simplest of all representations, by Freeman and Roth <ref> [20] </ref>, achieved good performance in measuring spatiotemporal angle histograms of simple hand gestures.
Reference: [21] <author> D.M. Gavrila and L.S. Davis. </author> <title> Towards 3-d model-based tracking and recognition of human movement: a multi-view approach. </title> <booktitle> In Proc. of the Int. Workshop on Automatic Face- and Gesture-Recognition, </booktitle> <address> Zurich, </address> <year> 1995. </year> <month> 25 </month>
Reference-contexts: The color of the arm and background have to be sufficiently different. 2 Examples of more complex 3D body models based on super-quadrics and a larger number of degrees of freedom (DOF) are presented by Gavrila and Davis <ref> [21] </ref>, and 3D mesh model of planar surface patches is presented by Clergue et al [13].
Reference: [22] <author> N. H. Goddard. </author> <title> The Perception of Articulated Motion: Recgonizing Moving Light Displays. </title> <type> PhD thesis, </type> <institution> Dept. of Comp.Sci., Univ. Rochester, </institution> <year> 1992. </year>
Reference-contexts: A 2D PCA projection of the data is performed in the higher dimensional space of joint angle sets over time. In the 2D subspace cubic polynomials are estimated and used for matching in recognition. Goddard <ref> [22] </ref> uses a structured connectionist system that recognizes human gaits from Moving Light Display data. No explicit human model is used. Cyclic gaits are represented as scenarios, which are sequences of events. No location information is coded in scenarios, only motion features.
Reference: [23] <author> Peter J. Green. </author> <title> On use of the EM algorithm for penalized likelihood estimation. </title> <journal> Journal of the Royal Statistical Society, B, </journal> <volume> 52(3) </volume> <pages> 443-452, </pages> <year> 1990. </year>
Reference-contexts: Optimizing these priors and the previous likelihoods leads to the maximum a 13 kinematic priors. b: Example of body segment motions and joint motions with high and with low kinematic priors posteriori estimation. An extension of the EM algorithm to maximum a posteriori is described in <ref> [23] </ref>. In the pure maximum likelihood estimation the M-step was decomposed into small independent terms that could be maximized in a straight forward manner. We also can decompose the posteriors in simple maximization terms, but can only guarantee that the expected posteriors increase but not achieve the maximum value.
Reference: [24] <author> D. Hogg. </author> <title> A program to see a walking person. </title> <journal> Image Vision Computing, </journal> <volume> 5(20), </volume> <year> 1983. </year>
Reference-contexts: The focus of this work was the demonstration of classical AI techniques for bottom-up and top-down integration. The used input were very simple synthetic images. Several systems that deal with real input data and 3D volumetric models follow the classical methology of CAD-model based edge fitting. Hogg <ref> [24] </ref> and Rohr [42] demonstrate on the domain of walking human subjects two similar systems. We briefly describe the more advanced approach of Rohr.
Reference: [25] <author> T.S. Huang and V.I. Pavlovic. </author> <title> Hand gesture modeling, analysis, and synthesis. </title> <booktitle> In Proc. of the Int. Workshop on Automatic Face- and Gesture-Recognition, </booktitle> <address> Zurich, </address> <year> 1995. </year>
Reference-contexts: The initial pose is assumed to be known, the background has to be uniform (black), and the finger parts are matched using graylevel templates or profiles. A survey of other hand tracking systems can be found in a paper by Huang and Pavlovic <ref> [25] </ref>. A different strategy and representation is introduced by Leung and Yang [31]. Two versions of body models are used: (i) the basic body model that is similar to the classical 3D cylinder based representation, (ii) the extended body model which models only the body outline.
Reference: [26] <author> A. Jepson and M.J. Black. </author> <title> Mixture models for ptical flow computation. </title> <booktitle> In Proc. IEEE Conf. Computer VIsion Pattern Recognition, </booktitle> <pages> pages 760-761, </pages> <address> New York, </address> <year> 1993. </year>
Reference-contexts: Both examples involve local decisions. In complex noisy domains global optimization across several levels of abstraction is desired instead. 6 Recent trends in estimation of complex motion have led to probabilistic formulations that give a fresh start to the idea of bottom-up and top-down integration. For example Layered motion <ref> [47, 26, 1] </ref> assigns each pixel a probability value that it belongs to a specific motion model. The pixel probabilities and the motion models are updated in an iterative bottom-up and top-down phase using a maximum likelihood optimization following the E-M methodology [16].
Reference: [27] <author> G. Johansson. </author> <title> Visual perception of biological motion and a model for its analysis. </title> <journal> Perception and Psychophysics, </journal> <volume> 14 </volume> <pages> 201-211, </pages> <year> 1973. </year>
Reference-contexts: Last but not least the major motivation for most the the described work should be mentioned: The classic Moving Light Display experiments by Johansson <ref> [27] </ref>.
Reference: [28] <author> M.I. Jordan and R. A. Jacobs. </author> <title> Hierarchical mixtures of experts and the em algorithm. </title> <journal> Neural Computation, </journal> <volume> 6(2), </volume> <month> March </month> <year> 1994. </year>
Reference-contexts: We used Hierarchical Mixtures of Experts <ref> [28] </ref>, which also fit a smooth surface to example data. In this case the surface represents a mapping from input to output, which is a so called Regression Surface. The major advantage is the discriminant nature.
Reference: [29] <author> J.J. Kuch and T.S. Huang. </author> <title> Vision based hand modelling and tracking. </title> <booktitle> In Proc. Int. Conf. Computer Vision, </booktitle> <year> 1995. </year>
Reference-contexts: The human subjects can perform unconstrained actions, but need to wear tight clothes, where each body segment contains a uniform color. Currently they use 5 calibrated camera views to estimate the 3D body configuration. Related high DOF models are presented for hand tracking by Kuch and Huang <ref> [29] </ref> and Rehg and Kanade [41]. Rehg and Kanade employ an inverse kinematic model and occlusion reasoning for tracking. The initial pose is assumed to be known, the background has to be uniform (black), and the finger parts are matched using graylevel templates or profiles.
Reference: [30] <author> A. Lanitis, Taylor C.J., Cootes T.F., and Ahmed T. </author> <title> Automatic interpretation of human faces and hand gestures using flexible models. </title> <booktitle> In International Workshop on Automatic Face- and Gesture-Recognition, </booktitle> <year> 1995. </year>
Reference-contexts: The simplest of all representations, by Freeman and Roth [20], achieved good performance in measuring spatiotemporal angle histograms of simple hand gestures. Other more general techniques based on linear subspace estimations (PCA) are reported for learning 2D outlines [49] of bodies and other articulated objects, contours of facial features <ref> [30, 3] </ref>, and graylevel appearance of faces and other objects [46, 39, 33, 44].
Reference: [31] <author> M.K. Leung and Y.H. Yang. </author> <title> First sight: A human body outline labeling system. </title> <journal> IEEE Trans. Pattern Anal. Mach. Intell., </journal> <volume> 17(4) </volume> <pages> 359-377, </pages> <month> April </month> <year> 1995. </year>
Reference-contexts: A survey of other hand tracking systems can be found in a paper by Huang and Pavlovic [25]. A different strategy and representation is introduced by Leung and Yang <ref> [31] </ref>. Two versions of body models are used: (i) the basic body model that is similar to the classical 3D cylinder based representation, (ii) the extended body model which models only the body outline.
Reference: [32] <author> B.D. Lucas and T. Kanade. </author> <title> An iterative image registration technique with an application to stereo vision. </title> <booktitle> Proc. 7th Int. Joinnt Conf. on Art. Intell., </booktitle> <year> 1981. </year>
Reference-contexts: Minimizing (8) is equal to computing the weighted means and covariances for each segment/joint model. The weights are the S k;x;y values. (9) can be minimized using an extension of the Lucas-Kanade motion estimation <ref> [32] </ref> described by Shi and Tomasi [43]. Our experiments have shown that with just a few E and M steps, we converge already to a stable estimate. As you see, each iteration step is a very straight forward computation.
Reference: [33] <author> H. Murase and S.K. Nayar. </author> <title> Learning and recognition of 3-d objects from brightness images. </title> <booktitle> In Proc. AAAI Fall Symposium: Machine Learning in Computer Vision: What, Why, and How?, </booktitle> <year> 1993. </year> <month> 26 </month>
Reference-contexts: Other more general techniques based on linear subspace estimations (PCA) are reported for learning 2D outlines [49] of bodies and other articulated objects, contours of facial features [30, 3], and graylevel appearance of faces and other objects <ref> [46, 39, 33, 44] </ref>.
Reference: [34] <author> S. A. Niyogi and E.H. Adelson. </author> <title> Analyzing and recognizing walking figures in xyt. </title> <journal> In Proc. IEEE Comput. Soc. Conf. Comput. Vision and Pattern Recogn., </journal> <pages> pages 469-474, </pages> <address> Seattle, </address> <month> June, </month> <year> 1994. </year>
Reference-contexts: Techniques that don't use such explicit model knowledge are usually estimated from example image sequences. A common representation is generic space time curves. Niyogi and Adelson <ref> [34] </ref> propose the detection of characteristic gait cycles in representing spatiotemporal surfaces 3 (superquadrics) in XYT image space (XY is the static pixel location, and T is the temporal index).
Reference: [35] <author> S. Omohundro. </author> <title> Fundamentals of Geometric Learning. </title> <type> Technical Report UIUCDCS-R-88-1408, </type> <institution> University of Illinois at Urbana-Champaign, </institution> <year> 1988. </year>
Reference-contexts: Handcoded domain knowledge obtained from physiological studies could be used as initial values, but to achieve the best classification performance, we plan to adapt the parametric representation to labeled image sequence databases. Adaptive manifold representations <ref> [35, 9] </ref> or Hidden Markov Models [40] are two techniques that might be useful learning architectures for estimating configuration spaces and sequences.
Reference: [36] <author> S.M. Omohundro. </author> <title> Best-first model merging for dynamic learning and recognition. </title> <booktitle> In NIPS, </booktitle> <volume> volume 4, </volume> <year> 1992. </year>
Reference-contexts: We could justify this in our probabilistic framework with an additional MDL prior, which prefers smaller number of hypothesis. The merging can be seen as a greedy search in the space of model numbers, which is similar to related techniques in layered motion [1], first-best-model-merging <ref> [36] </ref>, AutoClass [12], or techniques for inducing the structural component of Bayesian Belief networks [15]. It does not have to be a decreasing search order.
Reference: [37] <author> J. O'Rourke and N. I. Badler. </author> <title> Model-based image analysis of human motion using constraint propagation. </title> <journal> IEEE Trans. Pattern Anal. Mach. Intell., </journal> <volume> 2(6) </volume> <pages> 522-536, </pages> <month> November </month> <year> 1980. </year>
Reference-contexts: lights attached to the joints of an actor, human subjects were able to distinguish human gaits, dance styles, stair climbing, or even can identify gender or the person itself. 2.1 Explicit Model based Representations The earliest computer vision attempt to recognition of human movements was reported by O'Rouke and Badler <ref> [37] </ref> using a 3D structure of rigid segments, joints, and constraints between them. Low level features were tracked in a feedback loop with a high-level model using constraint propagation. The focus of this work was the demonstration of classical AI techniques for bottom-up and top-down integration.
Reference: [38] <author> Judea Pearl. </author> <title> Probabilistic Reasoning in Intelligent Systems. </title> <publisher> Morgan Kauf-man, </publisher> <year> 1988. </year>
Reference-contexts: The pixel probabilities and the motion models are updated in an iterative bottom-up and top-down phase using a maximum likelihood optimization following the E-M methodology [16]. Bayesian Belief Networks <ref> [38] </ref> are another framework that allows one to model bottom-up, top-down, and the integration of multiple cues in a Bayesian way. Inference in a probabilistic domain is potentially exponential. The key idea of Bayesian Belief Networks is the exploitation of Conditional Independence in order to achieve feasible non-exponential inference techniques.
Reference: [39] <author> A. Pentland, B. Moghaddam, and T. Starner. </author> <title> View-based and modular eigenspaces for face recognition. </title> <journal> Proc. IEEE Comput. Soc. Conf. Comput. Vision and Pattern Recogn., </journal> <year> 1994. </year>
Reference-contexts: Other more general techniques based on linear subspace estimations (PCA) are reported for learning 2D outlines [49] of bodies and other articulated objects, contours of facial features [30, 3], and graylevel appearance of faces and other objects <ref> [46, 39, 33, 44] </ref>.
Reference: [40] <author> L. R. Rabiner. </author> <title> A tutorial on hidden markov models and selected applications in speech recogntion. </title> <booktitle> In Readings in Speech Recogntion, </booktitle> <year> 1989. </year>
Reference-contexts: Handcoded domain knowledge obtained from physiological studies could be used as initial values, but to achieve the best classification performance, we plan to adapt the parametric representation to labeled image sequence databases. Adaptive manifold representations [35, 9] or Hidden Markov Models <ref> [40] </ref> are two techniques that might be useful learning architectures for estimating configuration spaces and sequences.
Reference: [41] <author> J.M. Regh and T. Kanade. </author> <title> Model-based tracking of self-occluding articulated objects. </title> <booktitle> In Proc. Int. Conf. Computer Vision, </booktitle> <year> 1995. </year>
Reference-contexts: Currently they use 5 calibrated camera views to estimate the 3D body configuration. Related high DOF models are presented for hand tracking by Kuch and Huang [29] and Rehg and Kanade <ref> [41] </ref>. Rehg and Kanade employ an inverse kinematic model and occlusion reasoning for tracking. The initial pose is assumed to be known, the background has to be uniform (black), and the finger parts are matched using graylevel templates or profiles.
Reference: [42] <author> K. Rohr. </author> <title> Incremental recognition of pedestrians from image sequences. </title> <journal> In Proc. IEEE Comput. Soc. Conf. Comput. Vision and Pattern Recogn., </journal> <pages> pages 8-13, </pages> <address> New York City, </address> <month> June, </month> <year> 1993. </year>
Reference-contexts: The used input were very simple synthetic images. Several systems that deal with real input data and 3D volumetric models follow the classical methology of CAD-model based edge fitting. Hogg [24] and Rohr <ref> [42] </ref> demonstrate on the domain of walking human subjects two similar systems. We briefly describe the more advanced approach of Rohr. Each body segment like the upper and lower arms and legs, the hands and feet, the torso and the head, are approximated by rigid connected 3D cylinders.
Reference: [43] <author> J. Shi and C. Tomasi. </author> <title> Good features to track. </title> <booktitle> In CVPR, </booktitle> <year> 1994. </year>
Reference-contexts: Minimizing (8) is equal to computing the weighted means and covariances for each segment/joint model. The weights are the S k;x;y values. (9) can be minimized using an extension of the Lucas-Kanade motion estimation [32] described by Shi and Tomasi <ref> [43] </ref>. Our experiments have shown that with just a few E and M steps, we converge already to a stable estimate. As you see, each iteration step is a very straight forward computation. Figure 2 shows blob hypotheses of an example run after a 3 EM iterations.
Reference: [44] <author> P. Simard, Y. LeCun, and J. Denker. </author> <title> Efficient pattern recognition using a new transformation distance. </title> <booktitle> In Advances in Neural Information Processing Systems, </booktitle> <year> 1993. </year>
Reference-contexts: Other more general techniques based on linear subspace estimations (PCA) are reported for learning 2D outlines [49] of bodies and other articulated objects, contours of facial features [30, 3], and graylevel appearance of faces and other objects <ref> [46, 39, 33, 44] </ref>.
Reference: [45] <author> T. Starner and A. Pentland. </author> <title> Visual recognition of american sign language using hidden markov models. </title> <booktitle> In Proc. of the Int. Workshop on Automatic Face- and Gesture-Recognition, </booktitle> <address> Zurich, </address> <year> 1995. </year> <month> 27 </month>
Reference-contexts: Motion blobs of people walking front-to-parallel to the image plane are estimated using difference detection and are matched to the parametric spatiotemporal surfaces. Bobick and Wilson [4] and Starner and Pentland <ref> [45] </ref> estimate spatiotemporal hand gestures with Hidden Markov Models from example data. The used features are eigen images or blob configurations. Polana and Nelson propose a technique that does not use any spatiotemporal model.
Reference: [46] <author> M. Turk and A. Pentland. </author> <title> Eigenfaces for recognition. </title> <journal> Journal of Cognitive Neuroscience, </journal> <volume> 3(1) </volume> <pages> 71-86, </pages> <year> 1991. </year>
Reference-contexts: Other more general techniques based on linear subspace estimations (PCA) are reported for learning 2D outlines [49] of bodies and other articulated objects, contours of facial features [30, 3], and graylevel appearance of faces and other objects <ref> [46, 39, 33, 44] </ref>.
Reference: [47] <author> Yair Weiss and Edward H. Adelson. </author> <title> Perceptually organized ed: A framework for motion segmentaiton that combines information about form and motion. </title> <type> Technical Report 315, </type> <institution> M.I.T Media Lab, </institution> <year> 1995. </year>
Reference-contexts: Both examples involve local decisions. In complex noisy domains global optimization across several levels of abstraction is desired instead. 6 Recent trends in estimation of complex motion have led to probabilistic formulations that give a fresh start to the idea of bottom-up and top-down integration. For example Layered motion <ref> [47, 26, 1] </ref> assigns each pixel a probability value that it belongs to a specific motion model. The pixel probabilities and the motion models are updated in an iterative bottom-up and top-down phase using a maximum likelihood optimization following the E-M methodology [16].
Reference: [48] <author> C. Wren, A. Azarbayejani, T. Darrell, and A. Pentland. Pfinder: </author> <title> Real-time tracking of the human body. </title> <booktitle> In SPIE Conference on Integration Issues in Large Commercial Media Delivery Systems, </booktitle> <volume> volume 2615, </volume> <year> 1995. </year>
Reference-contexts: One of the most recent techniques for locating people and estimating their pose based on probabilistic color blob estimation and figure-ground-segmentation is developed by Wreng et. al. <ref> [48] </ref>. 2.3 High-level Human Motion Models without Computer Vision Some systems ignore the low-level feature extraction and only focus on higher level representations and recognition strategies. Campbell and Bobick [11] developed a system that recognizes ballet moves based on 3D point locations of joints.
Reference: [49] <author> S.C. Zhu and A.L. Yuille. </author> <title> Forms: a flexible objecy recognition and modelling system. </title> <booktitle> In Proc. Int. Conf. Computer Vision, </booktitle> <year> 1995. </year> <month> 28 </month>
Reference-contexts: The simplest of all representations, by Freeman and Roth [20], achieved good performance in measuring spatiotemporal angle histograms of simple hand gestures. Other more general techniques based on linear subspace estimations (PCA) are reported for learning 2D outlines <ref> [49] </ref> of bodies and other articulated objects, contours of facial features [30, 3], and graylevel appearance of faces and other objects [46, 39, 33, 44].
References-found: 49

