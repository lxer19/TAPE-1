URL: http://www.cit.gu.edu.au/~sosic/papers/rok-thesis.ps.Z
Refering-URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/user/mcox/Public/Www/Personal/introspect.html
Root-URL: 
Title: THE MANY FACES OF INTROSPECTION  
Author: by Rok Sosic 
Degree: A dissertation submitted to the faculty of The University of Utah in partial fulfillment of the requirements for the degree of Doctor of Philosophy  
Date: June 1992  
Affiliation: Department of Computer Science The University of Utah  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> H. Abelson and G. J. Sussman. </author> <title> Structure and Interpretation of Computer Programs. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1985. </year>
Reference-contexts: If the verification process using one agent is too slow, the modeler can be sampled at a higher rate by interleaving several processors. 3.5.3 Real-Time Garbage Collection Garbage collection is an important feature of sophisticated programming environments and languages <ref> [1, 90] </ref>. A lack of efficient, real-time, methods for garbage collection restricts the use of garbage collection in industrial applications [7, 16]. A real-time garbage collection algorithm can be implemented in an introspective computer. 3.5.3.1 Copying Garbage Collection Garbage collection involves two processes: a mutator and a collector [14, 173]. <p> The code is shown in Figure 4.18. Array f represents the logical AND operation. It is initialized to f [0] = 0, f <ref> [1] </ref> = 0, f [2] = 0, and f [3] = 1. Because array f can be initialized to any Boolean operation, f is evaluated in an interpreted fashion. The code for the Unison algorithm is shown in Figure 4.19. <p> Elements df [N ] to df [2 fl N 1] contain values of independent input variables. Intermediate total differentials are stored in elements df [2] to df [N 1]. 32 bits of element df <ref> [1] </ref> contain the final total differentials for all 32 Boolean expressions. The values of partial derivatives F x and F y for all operations are represented by the heap f p with 2 fl N 1 array elements. <p> Procedure initialize initializes all three heaps, df, fp, and fxy. The results of Boolean expressions with all their independent inputs being set to 0 represent 32 initial values. They are put in 32 bits of element df <ref> [1] </ref>. The value of this element is stored in variable td. After the initialization stage, the expressions are evaluated for each new set of inputs. The procedure newinput sets all 32 bits of elements df [N] to df [2*N-1] to the new values of inputs. <p> The procedure newinput sets all 32 bits of elements df [N] to df [2*N-1] to the new values of inputs. The core of the algorithm is procedure evaluate which stores the results in 32 bits of element df <ref> [1] </ref>. Because results represent differences from initial values, an Exclusive-OR operation is performed on the corresponding 32 bits in td and the corresponding 32 bits in df [1]. These final results are stored in 32 bits of the variable result. <p> The core of the algorithm is procedure evaluate which stores the results in 32 bits of element df <ref> [1] </ref>. Because results represent differences from initial values, an Exclusive-OR operation is performed on the corresponding 32 bits in td and the corresponding 32 bits in df [1]. These final results are stored in 32 bits of the variable result. Each bit in the variable result is a result of one Boolean expression. After procedure initialize, procedure evaluate can be Boolean_Evaluation () - int td, result; initialize (df,fp,fxy); /* initialization stage */ td = df [1]; /* get <p> in df <ref> [1] </ref>. These final results are stored in 32 bits of the variable result. Each bit in the variable result is a result of one Boolean expression. After procedure initialize, procedure evaluate can be Boolean_Evaluation () - int td, result; initialize (df,fp,fxy); /* initialization stage */ td = df [1]; /* get initial value */ while ("not end of input") - newinput (df); /* get input */ evaluate (df,fp,fxy); /* evaluation stage */ result = td ^ df [1]; /* get final results */ - Figure B.3. <p> procedure initialize, procedure evaluate can be Boolean_Evaluation () - int td, result; initialize (df,fp,fxy); /* initialization stage */ td = df <ref> [1] </ref>; /* get initial value */ while ("not end of input") - newinput (df); /* get input */ evaluate (df,fp,fxy); /* evaluation stage */ result = td ^ df [1]; /* get final results */ - Figure B.3. The Overview of Algorithm 174 repeated for an arbitrary number of times to evaluate Boolean expressions for different inputs. Procedure initialize (Figure B.4) consists of procedures values and derivatives. It initializes heaps df, fp, and fxy. <p> It initializes heaps df, fp, and fxy. Procedure values evaluates all Boolean expressions with their independent variables being set to 0. This can be done by any conventional method. Procedure values stores the 32 initial values in 32 bits of element df <ref> [1] </ref> and stores the intermediate results in elements df [2] to df [N-1]. Inputs, being 0 in this case, are stored in elements df [N] to df [2*N-1]. <p> Procedure derivatives initializes heaps fp and fxy that keep partial derivatives F x , F y , and F xy , according to the intermediate results of heap df and partial differentials in Table B.1. Procedure evaluate calculates dF for elements df [N-1] to df <ref> [1] </ref> by applying Equation 4.1, as described in Figure B.5. initialize (df,fp,fxy) int df [2*N-1], fp [2*N-1], fxy [N-1]; values (df); /* initialize values */ derivatives (fp,fxy); /* initialize partial derivatives */ - Figure B.4.
Reference: [2] <author> G. Agha. </author> <title> Actors. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1986. </year>
Reference-contexts: Because they do not want to give up the forks they already hold, they can wait an arbitrary long amount of time. Solutions to the dining philosophers problem include special protocols to reach agreement among the philosophers <ref> [2] </ref> or the introduction of a servant [21]. In the first case, protocols place cognitive load on philosophers. Therefore, philosophers are not as effective at thinking as without these protocols. Philosophers are not happy with the servant either. <p> The code is shown in Figure 4.18. Array f represents the logical AND operation. It is initialized to f [0] = 0, f [1] = 0, f <ref> [2] </ref> = 0, and f [3] = 1. Because array f can be initialized to any Boolean operation, f is evaluated in an interpreted fashion. The code for the Unison algorithm is shown in Figure 4.19. <p> Elements df [N ] to df [2 fl N 1] contain values of independent input variables. Intermediate total differentials are stored in elements df <ref> [2] </ref> to df [N 1]. 32 bits of element df [1] contain the final total differentials for all 32 Boolean expressions. The values of partial derivatives F x and F y for all operations are represented by the heap f p with 2 fl N 1 array elements. <p> Procedure values evaluates all Boolean expressions with their independent variables being set to 0. This can be done by any conventional method. Procedure values stores the 32 initial values in 32 bits of element df [1] and stores the intermediate results in elements df <ref> [2] </ref> to df [N-1]. Inputs, being 0 in this case, are stored in elements df [N] to df [2*N-1].
Reference: [3] <author> H. Agrawal, R. A. DeMillo, and E. H. Spafford. </author> <title> An execution-backtracking approach to debugging. </title> <journal> IEEE Software, </journal> <volume> 8(3) </volume> <pages> 21-26, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: Details are presented in Section 5.4. An important feature of this integrated support is that reverse execution is implemented at the hardware level. Reverse execution is therefore available for any program and it is not limited to a particular programming environment as in more traditional implementations <ref> [3, 99, 168, 180] </ref>. Sample measurements show that the execution of one million instructions produces around 30 Kbytes of history. A 50 MIPS 51 processor would generate 1.5 Mbytes of history per second. The history of 100 seconds of execution can be saved on 150 Mbytes of disk space. <p> The code is shown in Figure 4.18. Array f represents the logical AND operation. It is initialized to f [0] = 0, f [1] = 0, f [2] = 0, and f <ref> [3] </ref> = 1. Because array f can be initialized to any Boolean operation, f is evaluated in an interpreted fashion. The code for the Unison algorithm is shown in Figure 4.19.
Reference: [4] <author> A. V. Aho, J. E. Hopcroft, and J. D. Ullman. </author> <title> The Design and Analysis of Computer Programs. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1974. </year>
Reference-contexts: The mathematical paradigm is helpful in building structural hierarchies, because abstractions are a major object of study. However, computer descriptions are abstracted away from physical reality. For example, if a Turing machine incorporates 10 or 10 million states, one step has the same cost <ref> [4] </ref>. This is not true in the real world. Because in a computer each state occupies some space, it is impossible to build a machine with 10 million states that has the same cost per step as a machine with only 10 states.
Reference: [5] <author> A. V. Aho, R. Sethi, and J. D. Ullman. </author> <booktitle> Compilers: Principles, Techniques, and Tools. </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1986. </year>
Reference-contexts: Because function calls are a time consuming operation, the program seems a good candidate for optimization. It is expected that the elimination of function calls significantly reduces the execution time. Applying optimization techniques used in compilers <ref> [5] </ref>, the program source was manually optimized to varying degrees and the performance of resulting programs was measured. Results in the order of increasing optimization are shown in Table 3.1. Original Version is the original program. In Instantiated Functions, a separate function was written for each level of recursion.
Reference: [6] <author> S. B. Akers. </author> <title> On a theory of Boolean functions. </title> <journal> J. Soc. Ind. Appl. Math., </journal> <volume> 7 </volume> <pages> 487-498, </pages> <month> December </month> <year> 1959. </year>
Reference-contexts: The derivation of Equation 4.1 is presented in [165]. The symbols F x , F y , and F xy in Equation 4.1 are partial derivatives of F with respect to x, y, and xy. The partial derivative of F with respect to x is defined in <ref> [6, 165] </ref> as: F x = F (x; y; x = 1) F (x; y; x = 0): Function F x is obtained by an Exclusive-OR operation between two functions which are formed from F by setting x once to 0 and once to 1.
Reference: [7] <author> J. R. Allard and L. B. Hawkinson. </author> <title> Real-time programming in Lisp. </title> <journal> Communications of the ACM, </journal> <volume> 34(9) </volume> <pages> 64-69, </pages> <month> September </month> <year> 1991. </year>
Reference-contexts: A lack of efficient, real-time, methods for garbage collection restricts the use of garbage collection in industrial applications <ref> [7, 16] </ref>. A real-time garbage collection algorithm can be implemented in an introspective computer. 3.5.3.1 Copying Garbage Collection Garbage collection involves two processes: a mutator and a collector [14, 173]. The mutator allocates objects and performs operations on them. The collector returns un 56 accessible objects to free space.
Reference: [8] <author> T. F. H. Allen and T. B. Starr. </author> <title> Hierarchy: Perspectives for Ecological Complexity. </title> <publisher> University of Chicago Press, </publisher> <address> Chicago, </address> <year> 1982. </year>
Reference-contexts: Hierarchical systems are composed of levels which introduce a partial order on subsystems. A general discussion on hierarchical systems can be found in [43, 128, 139]. Two types of hierarchies can be observed in complex systems, a structural hierarchy and a control hierarchy <ref> [8, 43, 139] </ref>. In a structural hierarchy, each level is contained in the level above. For example, levels of structural hierarchy in computers can be divided into: gates, functional units, subsystems, computers, local area networks, wide area networks, and worldwide networks.
Reference: [9] <author> A. W. Appel, J. R. Ellis, and K. Li. </author> <title> Real-time concurrent collection on stock multiprocessors. </title> <booktitle> In Proceedings of SIGPLAN'88 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 11-20. </pages> <publisher> ACM, </publisher> <year> 1988. </year>
Reference-contexts: After the traversal of grey objects is finished, all objects are black and FromSpace and ToSpace can be reversed. This process of scavenging can be implemented efficiently, provided that the mutator checks each pointer reference for a forwarding pointer. 57 3.5.3.2 Real-Time Enhancement Existing real-time garbage collection algorithms <ref> [9, 14, 23, 124] </ref> impose two limitations. First, the latency of the algorithm is limited by the time that it takes to copy the largest object. Second, the mutator is not allowed to store a FromSpace reference in an object. Both limitations can be removed in an introspective computer.
Reference: [10] <author> Z. Aral, I. Gertner, and G. Schaffer. </author> <title> Efficient debugging primitives for multiprocessors. </title> <booktitle> In Proc. of the 3nd International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 87-95. </pages> <publisher> ACM, </publisher> <year> 1989. </year>
Reference-contexts: Events provide significantly more power than stepwise execution. During a stepwise execution, the program is stopped after every executed instruction so that the process state can be examined. Because a direct stepwise execution slows down the execution more than five orders of magnitude <ref> [10, 87] </ref>, a stepwise execution is more efficiently implemented in an interpreted system [48]. Although stepwise execution provides complete information about the program behavior, this information describes static behavior. <p> Recursive calls are normally not available in conventional debuggers. Only recently, some debuggers with this functionality have appeared [125]. The director to check register allocation examines every executed instruction. It is extremely expensive to examine every executed instruction using regular debuggers. Using numbers from <ref> [10, 87] </ref>, if an examination of 46 Check_Register_Allocation () - Mark_All_Registers; do - event = Read_Next_Event (); if (event-&gt;evinst == CALL) - Record_Register_Values; Check_Register_Allocation (); Mark_Registers_Whose_Values_Differ_From_Recorded_Values; -; if (event-&gt;evinst_Modifies_Register_i) Unmark_Register_i; if (event-&gt;evinst_Reads_Register_i && Register_i_Is_Marked) Debugger (); while (event-&gt;evinst != RETURN); -; every instruction is required, it is estimated that regular debuggers
Reference: [11] <author> J. E. Archer Jr., R. Conway, and F. B. Schneider. </author> <title> User recovery and reversal in interactive systems. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 6(1) </volume> <pages> 1-19, </pages> <month> January </month> <year> 1984. </year>
Reference-contexts: This section discusses two applications of the history. 3.4.1 Reverse Execution in Human-Computer Interaction A generic undo operation is an important construct in human-computer interaction and programming environments <ref> [11, 66, 99] </ref>. Because it supports reverse execution, an introspective computer can return any program to a state in the past regardless of the programming language or the programming environment. A common application of reverse execution is debugging [15, 50, 121, 182]. <p> It is a well established concept in computer science used in program development and debugging [15, 50, 121, 126, 164, 168, 182], in programming environments and human-computer interaction <ref> [11, 66, 99, 101, 180] </ref>, in fault-tolerant computing [34, 51, 97, 98] and in speculative computation [57, 80]. In computer architecture, techniques of reverse execution are used to provide precise interrupts [77, 147].
Reference: [12] <author> W. R. Ashby. </author> <title> An Introduction to Cybernetics. </title> <publisher> Chapman and Hall, </publisher> <address> London, </address> <year> 1956. </year>
Reference-contexts: This operation in 1972 is not yet done in man-made computers - metaprogramming is done outside the big solid-state computers by the human programmers, or more properly, the human metaprogrammers. Another approach to intelligent behavior that involves several communicating systems is cybernetics <ref> [12, 179] </ref>. Cybernetics is the study of communication and control. A basic concept of cybernetics is a feedback loop in which the description of the behavior of system A is communicated to system B. System B uses this description to control the future behavior of A.
Reference: [13] <author> M. J. Bach. </author> <title> The Design of the Unix Operating System. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1986. </year>
Reference-contexts: The communication between the executor and the director is performed through sockets, a standard interprocess communication feature in BSD Unix and Mach <ref> [13, 162] </ref>. If necessary, an equivalent interprocess communication method could be used instead. Because the executor and the director are two separate programs, they could execute on different computers. This feature has not been implemented, although it would be easy to add to the system.
Reference: [14] <author> H. G. Baker Jr. </author> <title> List processing in real time on a serial computer. </title> <journal> Communications of the ACM, </journal> <volume> 21(4) </volume> <pages> 280-294, </pages> <month> April </month> <year> 1978. </year> <month> 178 </month>
Reference-contexts: A lack of efficient, real-time, methods for garbage collection restricts the use of garbage collection in industrial applications [7, 16]. A real-time garbage collection algorithm can be implemented in an introspective computer. 3.5.3.1 Copying Garbage Collection Garbage collection involves two processes: a mutator and a collector <ref> [14, 173] </ref>. The mutator allocates objects and performs operations on them. The collector returns un 56 accessible objects to free space. Copying garbage collectors use two spaces: FromSpace and ToSpace. At the beginning, FromSpace contains objects to be copied and ToSpace is empty. <p> After the traversal of grey objects is finished, all objects are black and FromSpace and ToSpace can be reversed. This process of scavenging can be implemented efficiently, provided that the mutator checks each pointer reference for a forwarding pointer. 57 3.5.3.2 Real-Time Enhancement Existing real-time garbage collection algorithms <ref> [9, 14, 23, 124] </ref> impose two limitations. First, the latency of the algorithm is limited by the time that it takes to copy the largest object. Second, the mutator is not allowed to store a FromSpace reference in an object. Both limitations can be removed in an introspective computer.
Reference: [15] <author> R. M. Balzer. </author> <title> EXDAMS EXtendable Debugging and Monitoring System. </title> <booktitle> In AFIPS Conference Proceeedings, </booktitle> <volume> Vol. 34, </volume> <pages> pages 567-580. SJCC, </pages> <year> 1969. </year>
Reference-contexts: The purpose of breakpoint registers is similar to that of IBM's program event recording with a limited functionality. Discussions on architectural support for debugging are given in [82, 113]. Sophisticated debugging environments are presented in <ref> [15, 121] </ref>. An interpreter of machine instructions that functions as a debugger is described in [48]. Recent efforts in debugging concentrate on parallel programs [83, 111]. Debugging represents a subset of conversational programming with the emphasis on finding errors in programs. Debugging environments provide only limited monitoring and controlling capabilities. <p> Therefore, the decision was made to use C. Each step is described by an event. The use of events in monitoring process behavior is common <ref> [15, 64, 66, 111, 120, 121, 150, 168] </ref>. Usually events provide only that subset of process behavior which is important for a particular application. For example, Hanson [64] provides the following events: variable referencing, statement execution, program interruption, function call and return, and execution time errors. <p> Because it supports reverse execution, an introspective computer can return any program to a state in the past regardless of the programming language or the programming environment. A common application of reverse execution is debugging <ref> [15, 50, 121, 182] </ref>. When a program exhibits incorrect behavior we often want to see previous states of the program execution to find the error. This can be easily provided using the history. <p> The approach using the history buffer has the same underlying concept as a history cache explained in the next section. 5.4 Reverse Execution Reverse execution provides access to old states of an executing process. It is a well established concept in computer science used in program development and debugging <ref> [15, 50, 121, 126, 164, 168, 182] </ref>, in programming environments and human-computer interaction [11, 66, 99, 101, 180], in fault-tolerant computing [34, 51, 97, 98] and in speculative computation [57, 80]. In computer architecture, techniques of reverse execution are used to provide precise interrupts [77, 147].
Reference: [16] <author> R. Barber and G. Imlah. </author> <title> Delivering the goods with Lisp. </title> <journal> Communications of the ACM, </journal> <volume> 34(9) </volume> <pages> 61-63, </pages> <month> September </month> <year> 1991. </year>
Reference-contexts: A lack of efficient, real-time, methods for garbage collection restricts the use of garbage collection in industrial applications <ref> [7, 16] </ref>. A real-time garbage collection algorithm can be implemented in an introspective computer. 3.5.3.1 Copying Garbage Collection Garbage collection involves two processes: a mutator and a collector [14, 173]. The mutator allocates objects and performs operations on them. The collector returns un 56 accessible objects to free space.
Reference: [17] <editor> C. Gordon Bell. High-Tech Ventures. </editor> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1991. </year>
Reference-contexts: Similar growth is expected in the future <ref> [17] </ref>. This increase in capacity leads to an increase in the complexity of computer systems. Problems in developing and maintaining software are one consequence of this complexity [22]. A way to solve the problem of the complexity of computer systems is to construct computers that manage themselves.
Reference: [18] <editor> L. Bic and A. C. Shaw. </editor> <booktitle> The Logical Design of Operating Systems. </booktitle> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1988. </year>
Reference-contexts: Deadlock occurs if processes compete for common resources and block each other. Deadlocks are studied in operating systems <ref> [18, 63] </ref>, databases [42], and distributed systems [33]. It is impossible for executors themselves to resolve deadlocks without access to global information about other processes.
Reference: [19] <author> T. E. Bihari and K. Schwan. </author> <title> Dynamic adaptation of real-time software. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 9(2) </volume> <pages> 143-174, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: An operating system does not interfere with the internal control of a process, only with its use of resources. Recently, simple hierarchies have been implemented in complex distributed applications <ref> [19, 108, 110] </ref>. The control in these applications is limited, because it is specialized for a particular application. The limitations of specialized approaches are removed in an introspective computer system, which provides a general framework to build hierarchical computer systems.
Reference: [20] <author> J. R. Bitner and E. M. Reingold. </author> <title> Backtrack programming techniques. </title> <journal> Communications of the ACM, </journal> <volume> 18(11) </volume> <pages> 651-656, </pages> <month> November </month> <year> 1975. </year>
Reference-contexts: It is used to return a part of the process state to its state in the past. Backtracking is fundamental in search and in logic programming <ref> [20, 160] </ref>. Because it is not known in advance which part of the process will be changed in the future, the entire relevant state is usually saved at each step of backtracking.
Reference: [21] <author> S. D. Brookes and A. W. Roscoe. </author> <title> Deadlock analysis in networks of communicating processes. </title> <editor> In K. R. Apt, editor, </editor> <booktitle> Logics and Models of Concurrent Systems, Vol. 13 of NATO ASI Series F, </booktitle> <pages> pages 305-323. </pages> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1985. </year>
Reference-contexts: Because they do not want to give up the forks they already hold, they can wait an arbitrary long amount of time. Solutions to the dining philosophers problem include special protocols to reach agreement among the philosophers [2] or the introduction of a servant <ref> [21] </ref>. In the first case, protocols place cognitive load on philosophers. Therefore, philosophers are not as effective at thinking as without these protocols. Philosophers are not happy with the servant either. They must follow the directions of the servant and they feel restricted in their freedom.
Reference: [22] <author> F. P. Brooks. </author> <title> No silver bullet: </title> <journal> Essence and accidents of software engineering. IEEE Computer, </journal> <volume> 20(4) </volume> <pages> 10-19, </pages> <month> April </month> <year> 1987. </year>
Reference-contexts: Similar growth is expected in the future [17]. This increase in capacity leads to an increase in the complexity of computer systems. Problems in developing and maintaining software are one consequence of this complexity <ref> [22] </ref>. A way to solve the problem of the complexity of computer systems is to construct computers that manage themselves. This chapter discusses a framework for self-managing computers provided by introspective systems. The first part of the chapter describes hierarchical systems.
Reference: [23] <author> R. A. Brooks. </author> <title> Trading data space for reduced time and code space in real-time garbage collection on stock hardware. </title> <booktitle> In Proceedings of ACM SIGSOFT/SIGPLAN Software Engineering Symposium on Practical Software Development Environments, </booktitle> <pages> pages 256-262. </pages> <publisher> ACM, </publisher> <year> 1984. </year>
Reference-contexts: After the traversal of grey objects is finished, all objects are black and FromSpace and ToSpace can be reversed. This process of scavenging can be implemented efficiently, provided that the mutator checks each pointer reference for a forwarding pointer. 57 3.5.3.2 Real-Time Enhancement Existing real-time garbage collection algorithms <ref> [9, 14, 23, 124] </ref> impose two limitations. First, the latency of the algorithm is limited by the time that it takes to copy the largest object. Second, the mutator is not allowed to store a FromSpace reference in an object. Both limitations can be removed in an introspective computer.
Reference: [24] <author> M. H. Brown. </author> <title> Algorithm Animation. </title> <publisher> ACM Distinguished Dissertation. MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1988. </year>
Reference-contexts: For example, Hanson [64] provides the following events: variable referencing, statement execution, program interruption, function call and return, and execution time errors. Events have been implemented in interpretive environments [64, 121], or by augmenting source code to emit events <ref> [24, 168] </ref>. Although the content of events used to monitor programs in high level programming languages is often at a high level [24, 64, 89, 121, 168], high level events are not the most appropriate choice for introspective computer systems. <p> Events have been implemented in interpretive environments [64, 121], or by augmenting source code to emit events [24, 168]. Although the content of events used to monitor programs in high level programming languages is often at a high level <ref> [24, 64, 89, 121, 168] </ref>, high level events are not the most appropriate choice for introspective computer systems. In many cases, high level events are not able to describe the complete computational behavior, because they are restricted to the most common monitoring operations. <p> Because previous approaches must access the entire data structure in order to find changes, their performance decreases with the increasing size of the data structure. Incremental and dynamic updates can be achieved in regular computers by manually inserting event emitting code in the executor's program <ref> [24] </ref>. This approach is error prone, because it requires programmer's detailed knowledge of the executor's program. The number of events that must be inserted in the program can be prohibitively large for practical use or events can be incorrectly inserted.
Reference: [25] <author> R. E. Bryant, D. Beatty, K. Brace, K. Cho, and T. She*er. COSMOS: </author> <title> A compiled simulator for MOS circuits. </title> <booktitle> 24th ACM/IEEE Design Automation Conference, </booktitle> <pages> pages 9-16, </pages> <year> 1987. </year>
Reference-contexts: Efficient evaluation of Boolean expressions has other important applications. Some of these applications include database search [135], programming 97 environments [66], modeling of digital circuits and software systems <ref> [25] </ref>, debugging [121], and event recording [135]. The usual approach to the evaluation of Boolean expressions in software involves interpretation which is expensive in execution time. Improvements include compiled evaluation [25], special-purpose circuits [41, 135], and reduction in the number of evaluations [121]. <p> Some of these applications include database search [135], programming 97 environments [66], modeling of digital circuits and software systems <ref> [25] </ref>, debugging [121], and event recording [135]. The usual approach to the evaluation of Boolean expressions in software involves interpretation which is expensive in execution time. Improvements include compiled evaluation [25], special-purpose circuits [41, 135], and reduction in the number of evaluations [121]. The compiled evaluation is the fastest method to evaluate Boolean expressions in software. Boolean expressions are stated as a program in a high-level programming language. To obtain results the program is compiled and executed with given inputs.
Reference: [26] <author> A. W. Burks. </author> <title> Computation, behavior, and structure in fixed and growing automata. </title> <booktitle> Behavioral Science, </booktitle> <volume> 6 </volume> <pages> 5-22, </pages> <year> 1961. </year>
Reference-contexts: Automata whose computing elements change over time, growing automata, have been introduced by Burks <ref> [26] </ref>. His discussion focuses on growing automata with a fixed framework of computational elements. In a fixed framework, elements do not change their positions, but their functionality can be changed. The connectivity pattern between computational elements is also fixed.
Reference: [27] <editor> A. W. Burks, editor. </editor> <booktitle> Essays on Cellular Automata. </booktitle> <publisher> University of Illinois Press, </publisher> <address> Urbana, IL, </address> <year> 1970. </year>
Reference-contexts: The development of kinematic automata has been largely overshadowed by cellular automata where the position and the functionality of computing elements are fixed. An overview of results in kinematic automata theory is presented in [93]. A survey of results in early cellular automata theory has been compiled by Burks <ref> [27] </ref>. One consequence of the ability to create new computational elements is the possibility of a limited exponential growth in the number of computational elements. A well established formalism capable of exponential growth is the model of L-systems, introduced 151 by Lindenmayer [103]. An extensive bibliography is published in [95].
Reference: [28] <author> J. Campbell. Winston Churchill's Afternoon Nap: </author> <title> A Wide-Awake Inquiry into the Human Nature of Time. </title> <publisher> Simon and Schuster, </publisher> <address> New York, </address> <year> 1986. </year>
Reference-contexts: For example, anticipation enables humans to significantly decrease their reaction time <ref> [28, 161] </ref>. Anticipation of the future requires that the system operates to a large degree autonomously from the environment. In the study of complex natural systems, autonomy is becoming one of the major identifying properties of living organisms [109, 175].
Reference: [29] <author> T. A. Cargill and B. N. Locanthi. </author> <title> Cheap hardware support for software debugging and profiling. </title> <booktitle> In Proc. of the 2nd International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 82-83. </pages> <publisher> ACM, </publisher> <year> 1987. </year>
Reference-contexts: It is set to zero at the beginning of the 18 process execution and incremented for each executed instruction. This counter determines internal logical time in the process history [94]. The instruction counter can be provided as a hardware or a software addition to an existing system <ref> [29, 115] </ref> or as a special register in the processor. The instruction set emulated on the interpreter is assumed to be a load/store model [67]. In this model, load and store are the only instructions that access main memory.
Reference: [30] <author> R. P. Case and A. Padegs. </author> <title> Architecture of the IBM system/370. </title> <journal> Communications of the ACM, </journal> <volume> 21(1) </volume> <pages> 73-96, </pages> <month> January </month> <year> 1978. </year> <month> 179 </month>
Reference-contexts: Peripheral processors could be used to monitor the central processor [79]. No facility for describing the computational behavior of central processors is provided in CDC 6600. The IBM 370 includes program event recording that can be invoked without any preplanning in the design of the program <ref> [30] </ref>. Program event recording can cause an interrupt on branch execution, change in register contents, fetch of certain instructions or the change in the value in certain locations. Program event recording is the most expensive facility provided in the instruction set of the IBM 360.
Reference: [31] <author> C. Chambers and D. Ungar. </author> <title> Customization: Optimizing compiler technology for SELF, a dynamically-typed object-oriented programming language. </title> <booktitle> In Proceedings of SIGPLAN'89 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 146-160. </pages> <publisher> ACM, </publisher> <year> 1989. </year>
Reference-contexts: Other approaches, an example was memoing, must be combined with these techniques to achieve significant reductions in the execution time. Dynamic program optimization is more promising in languages that perform complex runtime operations <ref> [31, 46] </ref>. Table 3.1. <p> Also, the first program execution is not optimized. The second approach, common to speed up the execution of object oriented languages, uses the combination of static program analysis and runtime information to perform dynamic program customization <ref> [31, 46] </ref>. A problem of this approach is that its runtime overhead can be greater than its savings in the execution time. None of the approaches is as powerful as the approach with directors in introspective computer systems.
Reference: [32] <author> K. M. Chandy and J. Misra. </author> <title> A paradigm for detecting quiescent properties in distributed computations. </title> <editor> In K. R. Apt, editor, </editor> <booktitle> Logics and Models of Concurrent Systems, Vol. 13 of NATO ASI Series F, </booktitle> <pages> pages 325-341. </pages> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1985. </year>
Reference-contexts: The director uses introspective features to perform deadlock detection and deadlock resolution. Deadlock detection is especially difficult in distributed systems. One approach introduces a special process, called a detector and an observation period for each executing process <ref> [32] </ref>. The detector is similar to the director. The difference is that the detector uses regular communication channels in the system. Therefore, all processes must be constructed to recognize detector's messages and to respond to them as requested by the detector.
Reference: [33] <author> K. M. Chandy, J. Misra, and L. M. Haas. </author> <title> Distributed deadlock detection. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 1(2) </volume> <pages> 144-156, </pages> <month> May </month> <year> 1983. </year>
Reference-contexts: Deadlock occurs if processes compete for common resources and block each other. Deadlocks are studied in operating systems [18, 63], databases [42], and distributed systems <ref> [33] </ref>. It is impossible for executors themselves to resolve deadlocks without access to global information about other processes.
Reference: [34] <author> K. M. Chandy and C. V. Ramamoorthy. </author> <title> Rollback and recovery strategies for computer programs. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 21(6) </volume> <pages> 546-556, </pages> <month> June </month> <year> 1972. </year>
Reference-contexts: It is a well established concept in computer science used in program development and debugging [15, 50, 121, 126, 164, 168, 182], in programming environments and human-computer interaction [11, 66, 99, 101, 180], in fault-tolerant computing <ref> [34, 51, 97, 98] </ref> and in speculative computation [57, 80]. In computer architecture, techniques of reverse execution are used to provide precise interrupts [77, 147]. Because computer processes are in general not reversible, special history information must be recorded in order to be able to restore earlier states.
Reference: [35] <author> P. P. Chang, S. A. Mahlke, and W.-M. W. Hwu. </author> <title> Using profile information to assist classic code optimizations. </title> <journal> Software-Practice and Experience, </journal> <volume> 21(12) </volume> <pages> 1301-1321, </pages> <month> December </month> <year> 1991. </year>
Reference-contexts: Using the first approach, the program execution is profiled and the profile information is supplied to the compiler during the next compilation <ref> [35] </ref>. This approach has a limitation that the optimization is not applied to the program that generated the profiling information, but to the next program execution. If programs significantly differ in their dynamic behavior, the compiler might make wrong optimizations. Also, the first program execution is not optimized.
Reference: [36] <author> C. C. Charlton, P. H. Leng, and D. M. Wilkinson. </author> <title> Program monitoring and analysis: Software structures and architectural support. </title> <journal> Software-Practice and Experience, </journal> <volume> 20(9) </volume> <pages> 859-867, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: Different degrees of correspondence between levels can be achieved. ... dsldobject (filename); dslink (filename,funcname); ... 92 Previous approaches to a high level description of program behavior include methods to compose low level events, special event description languages, and a direct generation of high level events <ref> [36, 38, 89, 96, 104, 125, 150, 168, 170] </ref>. Because the execution stream provides a complete executor's behavior and a director can use arbitrary programming constructs, an introspective computer system provides a more general method of dealing with program behavior than previous approaches.
Reference: [37] <author> P. Chow. </author> <title> The MIPS-X RISC Microprocessor. </title> <publisher> Kluwer Academic Publishers, Norwell, </publisher> <address> MA, </address> <year> 1989. </year>
Reference-contexts: One example can be found in the implementation of arithmetic logic units (ALU). A part of the ALU is the general logic function block <ref> [37, 114] </ref> which is essentially an implementation of a multiplexer with switches (see Figure 5.6). Four control signals, f 0 , f 1 , f 2 , and f 3 , are needed to specify the operation performed by the ALU.
Reference: [38] <author> J. Cohen and N. Carpenter. </author> <title> A language for inquiring about the run-time behaviour of programs. </title> <journal> Software-Practice and Experience, </journal> <volume> 7(4) </volume> <pages> 445-460, </pages> <month> July/August </month> <year> 1977. </year>
Reference-contexts: Different degrees of correspondence between levels can be achieved. ... dsldobject (filename); dslink (filename,funcname); ... 92 Previous approaches to a high level description of program behavior include methods to compose low level events, special event description languages, and a direct generation of high level events <ref> [36, 38, 89, 96, 104, 125, 150, 168, 170] </ref>. Because the execution stream provides a complete executor's behavior and a director can use arbitrary programming constructs, an introspective computer system provides a more general method of dealing with program behavior than previous approaches.
Reference: [39] <author> M. Conrad. </author> <title> The importance of molecular hierarchy in information processing. </title> <editor> In C. H. Waddington, editor, </editor> <booktitle> Towards a Theoretical Biology, </booktitle> <volume> Vol. 4: </volume> <booktitle> Essays, </booktitle> <pages> pages 222-228. </pages> <publisher> Edinburgh University Press, Edinburgh, </publisher> <year> 1972. </year>
Reference-contexts: This section discusses the design of control hierarchies in computer systems. The design is based on introspective capabilities presented in this thesis. Most existing computer systems are either flat or exhibit a limited degree of control hierarchy <ref> [39] </ref>. A flat system is a collection of subsystems without centralized control. Interactions between subsystems in a flat system are local. The resulting behavior of a flat system of processes is called emergent computation. An emergent computation is not programmed explicitly, but it emerges from local interactions. <p> If a system executes a task in a million years instead a minute, it is not efficient. The abstraction of real space and time is a serious shortcoming of mathematical paradigm for building complex computer systems. Similar observations are made by <ref> [39] </ref>.
Reference: [40] <author> M. Conrad. </author> <title> On design principles for a molecular computer. </title> <journal> Communications of the ACM, </journal> <volume> 28(5) </volume> <pages> 464-480, </pages> <month> May </month> <year> 1985. </year>
Reference-contexts: In principle, the same technology used by living organisms could be used to implement growing computations [159]. A discussion on design issues of molecular computers is provided in <ref> [40, 84] </ref>. 6.4 Paradigms in Computer Science This section gives a general view on the role of complex systems in computer science. Three paradigms and their approach to problems in computer science are discussed: mathematical, physics, and systems science.
Reference: [41] <author> W. J. Dally and R. E. Bryant. </author> <title> A hardware architecture for switch-level simulation. </title> <journal> IEEE Transactions on Computer Aided Design, </journal> <volume> 4(3) </volume> <pages> 239-250, </pages> <month> July </month> <year> 1985. </year>
Reference-contexts: The usual approach to the evaluation of Boolean expressions in software involves interpretation which is expensive in execution time. Improvements include compiled evaluation [25], special-purpose circuits <ref> [41, 135] </ref>, and reduction in the number of evaluations [121]. The compiled evaluation is the fastest method to evaluate Boolean expressions in software. Boolean expressions are stated as a program in a high-level programming language. To obtain results the program is compiled and executed with given inputs.
Reference: [42] <author> C. J. Date. </author> <title> An Introduction to Database Systems. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1983. </year>
Reference-contexts: Deadlock occurs if processes compete for common resources and block each other. Deadlocks are studied in operating systems [18, 63], databases <ref> [42] </ref>, and distributed systems [33]. It is impossible for executors themselves to resolve deadlocks without access to global information about other processes.
Reference: [43] <author> R. Dawkins. </author> <title> Hierarchical organisation: a candidate principle for ethology. </title> <editor> In P. P. G. Bateson and R. A. Hinde, editors, </editor> <booktitle> Growing Points in Ethology, </booktitle> <pages> pages 7-54. </pages> <publisher> Cambridge University Press, </publisher> <address> Cambridge, </address> <year> 1976. </year>
Reference-contexts: Hierarchical systems are composed of levels which introduce a partial order on subsystems. A general discussion on hierarchical systems can be found in <ref> [43, 128, 139] </ref>. Two types of hierarchies can be observed in complex systems, a structural hierarchy and a control hierarchy [8, 43, 139]. In a structural hierarchy, each level is contained in the level above. <p> Hierarchical systems are composed of levels which introduce a partial order on subsystems. A general discussion on hierarchical systems can be found in [43, 128, 139]. Two types of hierarchies can be observed in complex systems, a structural hierarchy and a control hierarchy <ref> [8, 43, 139] </ref>. In a structural hierarchy, each level is contained in the level above. For example, levels of structural hierarchy in computers can be divided into: gates, functional units, subsystems, computers, local area networks, wide area networks, and worldwide networks.
Reference: [44] <author> D. C. Dennett. Brainstorms: </author> <title> Philosophical Essays on Mind and Psychology. </title> <publisher> Bradford Books, </publisher> <address> Montgomery, VT, </address> <year> 1978. </year>
Reference-contexts: However, there seems to be a consensus that "it takes two to invent anything." The title of this section is a paraphrase of poet Valery taken from <ref> [44] </ref>. It means that our mind is composed of at least two parts: one part to make decisions and one part to carry them out.
Reference: [45] <author> J. des Rivieres and B. C. Smith. </author> <title> The implementation of procedurally reflective languages. </title> <type> Technical Report ISL-84-4, </type> <note> Xerox PARC, 1984. 180 </note>
Reference-contexts: They are not designed to feed symbolic data back to themselves in real-time. 7 1.2.3 Meta-Level Architectures and Reflection Reflection and meta-level architectures, well-developed areas of artificial intelligence, deal with computer programs that manipulate their own representation including the interpreter on which they are running <ref> [45, 107, 145] </ref>. Smith [146] divides self-referential programs into four classes. <p> Smith developed the LISP-3 programming language <ref> [45, 145] </ref>. A LISP-3 program is interpreted on a metacircular interpreter which is also a LISP-3 program. The program can dynamically create another interpreter. This gives an illusion of an infinite tower of interpreters. Each interpreter has access to structures at the levels below.
Reference: [46] <author> L. P. Deutsch and A. M. Schiffman. </author> <title> Efficient implementation of the Smalltalk-80 system. </title> <booktitle> In Proceedings of the 11th Annual ACM Symposium on the Principles of Programming Languages, </booktitle> <pages> pages 297-302. </pages> <publisher> ACM, </publisher> <year> 1984. </year>
Reference-contexts: Other approaches, an example was memoing, must be combined with these techniques to achieve significant reductions in the execution time. Dynamic program optimization is more promising in languages that perform complex runtime operations <ref> [31, 46] </ref>. Table 3.1. <p> Also, the first program execution is not optimized. The second approach, common to speed up the execution of object oriented languages, uses the combination of static program analysis and runtime information to perform dynamic program customization <ref> [31, 46] </ref>. A problem of this approach is that its runtime overhead can be greater than its savings in the execution time. None of the approaches is as powerful as the approach with directors in introspective computer systems.
Reference: [47] <author> D. P. </author> <title> Dobkin. </title> <type> private communication, </type> <year> 1991. </year>
Reference-contexts: This is especially important for interactive modelers where the slowdown forced by the verification process can make them impractical. One method to handle degenerate cases involves the construction of agents which verify the geometric model only periodically <ref> [47] </ref>. In regular computers, these agents would considerably interfere with the execution, because their activity must be synchronized with the modeler. In introspective computers, unobtrusive agents can be constructed.
Reference: [48] <author> R. E. Fairley. ALADDIN: </author> <title> Assembly language assertion driven debugging interpreter. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 5(4) </volume> <pages> 426-428, </pages> <month> July </month> <year> 1979. </year>
Reference-contexts: Discussions on architectural support for debugging are given in [82, 113]. Sophisticated debugging environments are presented in [15, 121]. An interpreter of machine instructions that functions as a debugger is described in <ref> [48] </ref>. Recent efforts in debugging concentrate on parallel programs [83, 111]. Debugging represents a subset of conversational programming with the emphasis on finding errors in programs. Debugging environments provide only limited monitoring and controlling capabilities. <p> During a stepwise execution, the program is stopped after every executed instruction so that the process state can be examined. Because a direct stepwise execution slows down the execution more than five orders of magnitude [10, 87], a stepwise execution is more efficiently implemented in an interpreted system <ref> [48] </ref>. Although stepwise execution provides complete information about the program behavior, this information describes static behavior.
Reference: [49] <author> S. Fang and B. Bruderlin. </author> <title> Robustness in geometric modeling - tolerance-based methods. </title> <booktitle> In Proceedings of the 7th Workshop on Computational Geometry, </booktitle> <publisher> LNCS. Springer-Verlag, </publisher> <year> 1991. </year>
Reference-contexts: The problem of dealing with degenerate cases in geometric modeling is hard and it requires sophisticated algorithms <ref> [49] </ref>. In principle, the model could be verified by the executor itself at every update of the geometric model. The problem with this approach is that verification can be a time consuming process. Although degenerate cases occur infrequently, all updates to the model would be slowed down.
Reference: [50] <author> S. I. Feldman and C. B. Brown. IGOR: </author> <title> A system for program debugging via reversible execution. </title> <booktitle> In Proceedings SIGPLAN/SIGOPS Workshop on Parallel and Distributed Debugging, </booktitle> <pages> pages 112-123. </pages> <publisher> ACM, </publisher> <year> 1988. </year>
Reference-contexts: Because it supports reverse execution, an introspective computer can return any program to a state in the past regardless of the programming language or the programming environment. A common application of reverse execution is debugging <ref> [15, 50, 121, 182] </ref>. When a program exhibits incorrect behavior we often want to see previous states of the program execution to find the error. This can be easily provided using the history. <p> For real-time systems, it is important that the latency is bounded and as small as possible. Some existing real-time algorithms for checkpoints use a paging mechanism to achieve latency on the order of 0.1 seconds <ref> [50, 100] </ref>. The ability of reverse execution in introspective computers provides a real-time checkpoint with a minimal latency. The algorithm for a real-time checkpoint consists of three phases: the copying of the internal processor state, the copying of the state in the main memory, and the application of history. <p> The approach using the history buffer has the same underlying concept as a history cache explained in the next section. 5.4 Reverse Execution Reverse execution provides access to old states of an executing process. It is a well established concept in computer science used in program development and debugging <ref> [15, 50, 121, 126, 164, 168, 182] </ref>, in programming environments and human-computer interaction [11, 66, 99, 101, 180], in fault-tolerant computing [34, 51, 97, 98] and in speculative computation [57, 80]. In computer architecture, techniques of reverse execution are used to provide precise interrupts [77, 147].
Reference: [51] <author> A. M. Feridun and K. G. Shin. </author> <title> A fault-tolerant multiprocessor system with rollback recovery capabilities. </title> <booktitle> In Proc. 2nd Int. Conf. Distributed Comput. Sys., </booktitle> <pages> pages 283-298. </pages> <publisher> IEEE, </publisher> <year> 1981. </year>
Reference-contexts: It is a well established concept in computer science used in program development and debugging [15, 50, 121, 126, 164, 168, 182], in programming environments and human-computer interaction [11, 66, 99, 101, 180], in fault-tolerant computing <ref> [34, 51, 97, 98] </ref> and in speculative computation [57, 80]. In computer architecture, techniques of reverse execution are used to provide precise interrupts [77, 147]. Because computer processes are in general not reversible, special history information must be recorded in order to be able to restore earlier states.
Reference: [52] <author> D. Ferrari. </author> <title> Computer Systems Performance Evaluation. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1978. </year>
Reference-contexts: During execution, the speed of the filter with the Unison algorithm is close to the speed of compiled filters. A common functionality of a filter is to evaluate Boolean expressions on the values from events <ref> [52, 112, 133, 134] </ref>. Depending on the purpose of monitoring, different Boolean functions are evaluated at different time periods. To facilitate monitoring, a new approach for efficient evaluation of Boolean expressions has been developed. <p> This approach is suitable for complex introspective systems with many processors, because it may not be feasible to slow down some processors. 116 5.2.2 Universal Boolean Element Monitoring involves the evaluation of Boolean functions based on the real-time behavior of the system being monitored <ref> [52, 112, 133, 134] </ref>. The problem is how to develop an efficient approach to formulate and evaluate an arbitrary Boolean expression in real-time. <p> Some solutions to this monitoring problem include using a fixed set of Boolean expressions (fixed hardware tools), the manual rewiring of the monitor (wired program tools), and the use of a high speed programmable monitor (stored program tools) <ref> [52, 112] </ref>. Stored program tools are the most flexible and satisfactory, but they impose a high cost on the monitor because the monitor must operate at a much faster rate than that of the system being monitored. An extensive survey of monitoring tools is presented in [138].
Reference: [53] <author> A. J. Field and P. G. Harrison. </author> <title> Functional Programming. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1988. </year>
Reference-contexts: If the function is called again with the same parameters, the result can be returned immediately and further evaluation of the function is cancelled. Memoing is restricted to purely applicative functions. It is an important construct in machine learning [116] and logic programming <ref> [53, 177] </ref>. 40 Memoing has been implemented on a program to evaluate Fibonacci numbers. A straightforward recursive program to evaluate Fibonacci numbers is shown in Figure 3.5.
Reference: [54] <editor> S. Forrest, editor. </editor> <booktitle> Emergent Computation, Proceedings of the Ninth Annual Center for Nonlinear Studies and Computing Divison Conference. </booktitle> <address> Physica D, 42:1, </address> <year> 1990. </year>
Reference-contexts: The resulting behavior of a flat system of processes is called emergent computation. An emergent computation is not programmed explicitly, but it emerges from local interactions. Emergent computations are important to study self-organizing and cooperative behaviors of collections of computer processes <ref> [54, 75] </ref>. An example of emergent computations is computer networks which often exhibit unexpected effects. Computers today do not provide extensive monitoring capabilities. They are not well suited for the construction of hierarchical systems, such as the director-executor system in the introspective computer.
Reference: [55] <author> C. W. Fraser and D. R. Hanson. </author> <title> A code generation interface for ANSI C. </title> <journal> Software-Practice and Experience, </journal> <volume> 21(9) </volume> <pages> 963-988, </pages> <month> September </month> <year> 1991. </year>
Reference-contexts: The interpreter maintains a history stream which records the history of the executor. The history stream enables reverse execution of the executor. 4.1.1 Dynascope Compiler The compiler translates ANSI C programs to Dynascope code. It is based on the lcc compiler <ref> [55, 56] </ref>. The lcc compiler consists of a processor-independent front end and a processor-specific back end. The compiler provides a simple interface between them. A special back end has been written for the Dynascope processor. 4.1.2 Dynascope Interpreter The interpreter represents the central part of Dynascope.
Reference: [56] <author> C. W. Fraser and D. R. Hanson. </author> <title> A retargetable compiler for ANSI C. </title> <journal> SIGPLAN Notices, </journal> <volume> 26(10) </volume> <pages> 29-43, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: The interpreter maintains a history stream which records the history of the executor. The history stream enables reverse execution of the executor. 4.1.1 Dynascope Compiler The compiler translates ANSI C programs to Dynascope code. It is based on the lcc compiler <ref> [55, 56] </ref>. The lcc compiler consists of a processor-independent front end and a processor-specific back end. The compiler provides a simple interface between them. A special back end has been written for the Dynascope processor. 4.1.2 Dynascope Interpreter The interpreter represents the central part of Dynascope.
Reference: [57] <author> R. M. Fujimoto, J.-J. Tsai, and G. C. Gopalakrishnan. </author> <title> Design and evaluation of the rollback chip: Special purpose hardware for time warp. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 41(1) </volume> <pages> 68-82, </pages> <month> January </month> <year> 1992. </year>
Reference-contexts: It is a well established concept in computer science used in program development and debugging [15, 50, 121, 126, 164, 168, 182], in programming environments and human-computer interaction [11, 66, 99, 101, 180], in fault-tolerant computing [34, 51, 97, 98] and in speculative computation <ref> [57, 80] </ref>. In computer architecture, techniques of reverse execution are used to provide precise interrupts [77, 147]. Because computer processes are in general not reversible, special history information must be recorded in order to be able to restore earlier states. <p> When the entire state of the process must be recreated, the search process must be repeated for each location. To improve efficiency, forward methods usually work at the granularity of one page instead of single locations. The search can be sped up by sophisticated data structures <ref> [57, 180] </ref>. The search of the history is avoided if a backward method is used to save the history. By saving old values instead of new values, the history essentially contains operations that are inverse to the process execution.
Reference: [58] <author> D. Gifford and A. Spector. </author> <title> Case study: </title> <journal> IBM's system/360-370 architecture. Communications of the ACM, </journal> <volume> 30(4) </volume> <pages> 291-307, </pages> <month> April </month> <year> 1987. </year>
Reference-contexts: It is always the first one on the list of things that might be removed from the system during revisions. So far, that has not happened, because according to an IBM computer architect, program event recording has been justified more times than any other single feature in the system <ref> [58] </ref>. The architecture of first microprocessors did not provide any support for debugging. Debugging features of microprocessors have advanced with each new generation. The simplest support is the inclusion of a single step mode.
Reference: [59] <author> K. </author> <title> Godel. Uber formal unentscheidbare satze der Principia Mathematica und verwandter systeme I. </title> <journal> Monatshefte fur Mathematik und Physik, </journal> <volume> 38 </volume> <pages> 173-198, </pages> <year> 1931. </year>
Reference-contexts: This section presents an overview of major relevant areas. 1.2.1 Self-referential Systems Self-referential systems play a prominent role in the scientific heritage of the twentieth century. This is the theme of two of the greatest intellectual achievements in this century. The first is the result of Godel <ref> [59] </ref> which shows that any sufficiently complex formal mathematical system is incomplete. A proof of this result involves a mathematical system that can express both propositions and metalevel propositions about the system. Metalevel propositions are propositions about propositions in this system.
Reference: [60] <author> A. Goldberg and D. Robson. </author> <title> Smalltalk-80: The Language and Its Implementation. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1983. </year>
Reference-contexts: Because (besides developing foundations) one objective was to build a working introspective system, a programming language for executors had to be selected. Three languages were main candidates: C, Lisp and Smalltalk <ref> [60, 86, 181] </ref>. The execution of 16 programs in Lisp and Smalltalk can be nicely decomposed into smaller steps. This property made them attractive, but a satisfactory way to incorporate garbage collection and a sophisticated run time environment in introspective systems was not found.
Reference: [61] <author> R. L. Graham, D. E. Knuth, and O. Patashnik. </author> <title> Concrete Mathematics. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1989. </year> <month> 181 </month>
Reference-contexts: A straightforward recursive program to evaluate Fibonacci numbers is shown in Figure 3.5. The number of recursive function calls to function f grows exponentially with a factor of 1 p (1+ 5) 2 with increasing n <ref> [61] </ref>. Fibonacci numbers were evaluated using two methods, a compiled program without memoing and an interpreted program with memoing. The compiled program was a regular program executing the program in Figure 3.5. In the interpreted version, the program in stream and performed memoing for the executor.
Reference: [62] <author> J. Gray. </author> <title> Notes on data base operating systems. </title> <editor> In R. Bayer, R. M. Graham, and G. Seegmuller, editors, </editor> <title> Operating Systems: An Advanced Course. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1978. </year>
Reference-contexts: Deadlock resolution methods are used in database systems, since it is impractical to avoid deadlocks in large scale databases. Basic operation steps in database systems are transactions. If a transaction successfully finishes, then it is committed, otherwise it is rolled back and must start from the beginning <ref> [62] </ref>. Transactions caught in a deadlock cannot finish successfully. Some of the transactions in the deadlock are thus restarted from the beginning so that others can continue. Deadlock resolution methods in database systems are therefore all or nothing.
Reference: [63] <author> A. N. Habermann. </author> <title> Prevention of system deadlocks. </title> <journal> Communications of the ACM, </journal> <volume> 12(7) </volume> <pages> 373-377, </pages> <month> July </month> <year> 1969. </year>
Reference-contexts: Deadlock occurs if processes compete for common resources and block each other. Deadlocks are studied in operating systems <ref> [18, 63] </ref>, databases [42], and distributed systems [33]. It is impossible for executors themselves to resolve deadlocks without access to global information about other processes.
Reference: [64] <author> D. R. Hanson. </author> <title> Event association in SNOBOL4 for program debugging. </title> <journal> Software-Practice and Experience, </journal> <volume> 8(2) </volume> <pages> 115-129, </pages> <month> March/April </month> <year> 1978. </year>
Reference-contexts: Therefore, the decision was made to use C. Each step is described by an event. The use of events in monitoring process behavior is common <ref> [15, 64, 66, 111, 120, 121, 150, 168] </ref>. Usually events provide only that subset of process behavior which is important for a particular application. For example, Hanson [64] provides the following events: variable referencing, statement execution, program interruption, function call and return, and execution time errors. <p> Each step is described by an event. The use of events in monitoring process behavior is common [15, 64, 66, 111, 120, 121, 150, 168]. Usually events provide only that subset of process behavior which is important for a particular application. For example, Hanson <ref> [64] </ref> provides the following events: variable referencing, statement execution, program interruption, function call and return, and execution time errors. Events have been implemented in interpretive environments [64, 121], or by augmenting source code to emit events [24, 168]. <p> Usually events provide only that subset of process behavior which is important for a particular application. For example, Hanson [64] provides the following events: variable referencing, statement execution, program interruption, function call and return, and execution time errors. Events have been implemented in interpretive environments <ref> [64, 121] </ref>, or by augmenting source code to emit events [24, 168]. Although the content of events used to monitor programs in high level programming languages is often at a high level [24, 64, 89, 121, 168], high level events are not the most appropriate choice for introspective computer systems. <p> Events have been implemented in interpretive environments [64, 121], or by augmenting source code to emit events [24, 168]. Although the content of events used to monitor programs in high level programming languages is often at a high level <ref> [24, 64, 89, 121, 168] </ref>, high level events are not the most appropriate choice for introspective computer systems. In many cases, high level events are not able to describe the complete computational behavior, because they are restricted to the most common monitoring operations.
Reference: [65] <author> D. Harel and A. Pnueli. </author> <title> On the development of reactive systems. </title> <editor> In K. R. Apt, editor, </editor> <booktitle> Logics and Models of Concurrent Systems, Vol. 13 of NATO ASI Series F, </booktitle> <pages> pages 477-498. </pages> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1985. </year>
Reference-contexts: Debugging environments provide only limited monitoring and controlling capabilities. Another 10 limitation of debuggers is that the language used in debuggers is different than the language used in the debugged program. Monitors and debuggers are a part of a class of systems called reactive systems <ref> [65] </ref>. A reactive system monitors its computational, synthetic environment and reacts to it. An application of reactive systems to distributed application management is described in [108]. A reactive system monitors the environment through sensors and responds through actuators.
Reference: [66] <author> J. Heering and P. Klint. </author> <title> Towards monolingual programming environments. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 7(2) </volume> <pages> 183-213, </pages> <month> April </month> <year> 1985. </year>
Reference-contexts: Therefore, the decision was made to use C. Each step is described by an event. The use of events in monitoring process behavior is common <ref> [15, 64, 66, 111, 120, 121, 150, 168] </ref>. Usually events provide only that subset of process behavior which is important for a particular application. For example, Hanson [64] provides the following events: variable referencing, statement execution, program interruption, function call and return, and execution time errors. <p> This section discusses two applications of the history. 3.4.1 Reverse Execution in Human-Computer Interaction A generic undo operation is an important construct in human-computer interaction and programming environments <ref> [11, 66, 99] </ref>. Because it supports reverse execution, an introspective computer can return any program to a state in the past regardless of the programming language or the programming environment. A common application of reverse execution is debugging [15, 50, 121, 182]. <p> In hardware implementations, the same approach reduces the complexity and the size of the filter as compared to filters in previous solutions (see Section 5.2.2). Efficient evaluation of Boolean expressions has other important applications. Some of these applications include database search [135], programming 97 environments <ref> [66] </ref>, modeling of digital circuits and software systems [25], debugging [121], and event recording [135]. The usual approach to the evaluation of Boolean expressions in software involves interpretation which is expensive in execution time. <p> It is a well established concept in computer science used in program development and debugging [15, 50, 121, 126, 164, 168, 182], in programming environments and human-computer interaction <ref> [11, 66, 99, 101, 180] </ref>, in fault-tolerant computing [34, 51, 97, 98] and in speculative computation [57, 80]. In computer architecture, techniques of reverse execution are used to provide precise interrupts [77, 147].
Reference: [67] <author> J. L. Hennessy and D. A. Patterson. </author> <title> Computer Architecture: A Quantitative Approach. </title> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos, CA, </address> <year> 1990. </year>
Reference-contexts: The instruction counter can be provided as a hardware or a software addition to an existing system [29, 115] or as a special register in the processor. The instruction set emulated on the interpreter is assumed to be a load/store model <ref> [67] </ref>. In this model, load and store are the only instructions that access main memory. Another assumption is that instructions take at most two operands and they produce at most one result. This last assumption provides a limit to the amount of data describing one execution step. <p> Another assumption is that instructions take at most two operands and they produce at most one result. This last assumption provides a limit to the amount of data describing one execution step. Assumptions are valid for generic RISC processors such as DLX <ref> [67] </ref>. 2.2.3 Representation of Steps Because each event represents the execution of one machine instruction, the size of events is bounded by a small number. <p> code or machine code of executors requires no changes in order to be subjected to directing. 4.1 Description The Dynascope programming environment is built around a hypothetical Dynascope processor which is a generic RISC type processor with 32 32-bit registers and a simple load/store architecture, similar to the DLX processor <ref> [67] </ref>. Dynascope consists of three parts: a Dynascope C compiler, a Dynascope interpreter, and a library of directing routines. 64 Dynascope is used as follows. <p> A practical alternative is to record in the history only those history elements that contain changes to the main memory. Statistics of executed instructions in many applications show that a Store operation to the main memory constitutes around 10% of all executed instructions <ref> [67, 131] </ref>. Because each Store to the main memory is represented in the history by two words containing the memory address and the previous value at that address, this approach generates 0.8 Mbytes of history for 1 million executed instructions, a 15-fold compaction over a straightforward approach. <p> Saving the history influences the speed of the processor, because every Store to memory must be implemented as a Read/Modify/Write operation. To estimate this overhead in systems without a cache, the following assumptions are made in the model <ref> [67, 131] </ref>: (a) Read/Modify/Write takes twice the time of a Store, (b) Load from memory represents 20% of executed instructions, and (c) Store to memory represents 10% of executed instructions. 138 Size of Problem Under these assumptions, the traffic from the processor to the memory for n executed instructions consists of
Reference: [68] <author> W. D. Hillis. </author> <title> New computer architectures and their relationship to physics or why computer science is no good. </title> <journal> International Journal of Theoretical Physics, </journal> 21(3/4):255-262, 1982. 
Reference-contexts: By developing abstractions, the tools of mathematics are helpful in building structural hierarchies in computers, but this is not sufficient to deal with exponentially increasing complexity of computers. 6.4.2 Physics Paradigm With the increasing acceptance of massively parallel computer systems, physics is becoming a paradigm of computer science <ref> [68, 75] </ref>. Cellular automata are replacing Turing machines [167]. In this paradigm, computers are composed of a large number of locally interacting simple processors. Real space and time are important. Physical placement of processes and processors is significant, because local communication is much cheaper than communication at distance.
Reference: [69] <author> W. W. Ho and R. A. Olsson. </author> <title> An approach to genuine dynamic linking. </title> <journal> Software-Practice and Experience, </journal> <volume> 21(4) </volume> <pages> 375-390, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: Besides the time for loading and linking, dynamically linked code does not impose any execution time overhead over regularly linked code. Because dynamic linking is performed by directly modifying corresponding references in the code, this avoids the cost of indirection usually associated with the execution of dynamically linked code <ref> [69] </ref>. Directing is supported on Dynascope code, but this code runs on the interpreter at a slower speed. Host code runs at full host speed, but directing is only partially supported. <p> Because linking modifies references in executor's code, the approach in Dynascope does not impose the penalty of indirect function calls usually present in implementations of dynamic linking <ref> [69] </ref>. The implementation of mixed references is described in the next section. 4.2.2 Mixing of Dynascope Code and Host Code The interpreter provides support for mixed references which are references from Dy-nascope code to host code and reference from host code to Dynascope code.
Reference: [70] <author> C. A. R. Hoare. </author> <title> Communicating Sequential Processes. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1985. </year>
Reference-contexts: This is illustrated by a classical example of a deadlock: the problem of the dining philosophers <ref> [70] </ref>. 2.3.2.1 Dining Philosophers In a room, there is a table with five philosophers sitting around. On the table is a large bowl of spaghetti and five forks. The spaghetti bowl is kept full. Each philosopher either thinks or eats spaghetti. Two forks are required to eat. <p> In denotational semantics, steps are functions and states are domains of these functions. This division prevents a uniform treatment of states and steps. Another approach to describe process behavior is communicating sequential processes (CSP) <ref> [70] </ref>. A similar formalism is trace theory [149]. In CSP, the primary objects of 161 study are processes and events. Events in CSP correspond to steps in our terminology. A process is described as a sequence of events.
Reference: [71] <author> C. M. Hoffmann. </author> <title> The problems of accuracy and robustness in geometric computation. </title> <journal> IEEE Computer, </journal> <volume> 22(3) </volume> <pages> 31-41, </pages> <month> March </month> <year> 1989. </year>
Reference-contexts: An important class of agents checks for the consistency of data structures. These agents periodically verify that data structures of the executor satisfy specified criteria. An example can be found in geometric modeling. Because computer arithmetic is finite, 55 manipulation of geometric models can easily produce degenerate cases <ref> [71] </ref>. These cases violate the rules of the underlying geometry.
Reference: [72] <author> D. R. Hofstadter. </author> <title> Godel, Escher, Bach: An Eternal Golden Braid. </title> <publisher> Basic Books, </publisher> <address> New York, </address> <year> 1979. </year>
Reference-contexts: A proof of this result involves a mathematical system that can express both propositions and metalevel propositions about the system. Metalevel propositions are propositions about propositions in this system. An extensive discussion of this result can be found in <ref> [72, 129] </ref>. Although Godel's result is negative, it is encouraging. It demonstrates that any sufficiently complex formal system can be extended in a consistent way by adding new axioms to the system.
Reference: [73] <author> J. E. Hopcroft and J. D. Ullman. </author> <title> Introduction to Automata Theory, Languages, and Computation. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1979. </year>
Reference-contexts: In other words, a computer system capable of learning will never finish its task. It can always learn more and improve itself. The second result, closely related to Godel's work, is the "halting theorem" by Turing <ref> [73, 171] </ref>. This result shows that a Turing machine cannot predict whether an arbitrary Turing machine will halt or not.
Reference: [74] <author> S. Horwitz. </author> <title> Identifying the semantic and textual differences between two versions of a program. </title> <booktitle> In Proceedings of SIGPLAN'90 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 234-245. </pages> <publisher> ACM, </publisher> <year> 1990. </year>
Reference-contexts: This direction was not pursued any further since it is a considerable research topic in itself. Some recent methods that identify differences between two programs are described in <ref> [74] </ref>. 96 4.6 Unison Algorithm The Unison algorithm was developed to provide an alternative to compiled and interpreted filters. Although the latest version of Dynascope supports compiled filters which are fast and flexible, these filters have some deficiencies.
Reference: [75] <author> B. A. Huberman, </author> <title> editor. The Ecology of Computation. </title> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <year> 1988. </year>
Reference-contexts: The resulting behavior of a flat system of processes is called emergent computation. An emergent computation is not programmed explicitly, but it emerges from local interactions. Emergent computations are important to study self-organizing and cooperative behaviors of collections of computer processes <ref> [54, 75] </ref>. An example of emergent computations is computer networks which often exhibit unexpected effects. Computers today do not provide extensive monitoring capabilities. They are not well suited for the construction of hierarchical systems, such as the director-executor system in the introspective computer. <p> By developing abstractions, the tools of mathematics are helpful in building structural hierarchies in computers, but this is not sufficient to deal with exponentially increasing complexity of computers. 6.4.2 Physics Paradigm With the increasing acceptance of massively parallel computer systems, physics is becoming a paradigm of computer science <ref> [68, 75] </ref>. Cellular automata are replacing Turing machines [167]. In this paradigm, computers are composed of a large number of locally interacting simple processors. Real space and time are important. Physical placement of processes and processors is significant, because local communication is much cheaper than communication at distance.
Reference: [76] <author> K. Hwang and F. A. Briggs. </author> <title> Computer Architecture and Parallel Processing. </title> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <year> 1984. </year>
Reference-contexts: Inputs of the bottommost UBEs supply values of independent variables. Output from the topmost UBE (the root of the tree) produces the total differential of the entire Boolean function. Besides trees, UBEs can be connected in other topologies, such as butterfly networks <ref> [76] </ref>. 118 5.2.2.2 Performance Considerations Because an UBE is a combinational circuit, a single evaluation of a Boolean expression could be done in a single clock cycle. For large network structures, it is necessary to divide this single evaluation into many smaller steps.
Reference: [77] <author> W.-M. W. Hwu and Y. N. Patt. </author> <title> Checkpoint repair for high-performance out-of-order execution machines. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 36(12) </volume> <pages> 1496-1514, </pages> <month> December </month> <year> 1987. </year> <month> 182 </month>
Reference-contexts: Using this solution, the executor can proceed with the full speed regardless of the filter latency. The mechanism to reverse the effect of the last n instructions is the same mechanism that is required to provide precise interrupts in processors whose instructions execute 127 out of order <ref> [77, 147] </ref>. Precise interrupts enable the restoration of the processor state at the time of an interrupt. One way to provide precise interrupts is to maintain a history buffer. The history buffer stores the reverse operations to the last n instructions. <p> In computer architecture, techniques of reverse execution are used to provide precise interrupts <ref> [77, 147] </ref>. Because computer processes are in general not reversible, special history information must be recorded in order to be able to restore earlier states. Implementations of reverse execution fall into roughly two classes: hardware and software approaches. Hardware approaches impose little overhead on program execution.
Reference: [78] <author> Intel. </author> <title> 80386 programmer's reference manual. </title> <publisher> Intel Corporation, </publisher> <year> 1986. </year>
Reference-contexts: Debugging features of microprocessors have advanced with each new generation. The simplest support is the inclusion of a single step mode. One of the microprocessors providing improved debugging support is the Intel 80386, which provides four breakpoint registers to set various traps <ref> [78] </ref>. The purpose of breakpoint registers is similar to that of IBM's program event recording with a limited functionality. Discussions on architectural support for debugging are given in [82, 113]. Sophisticated debugging environments are presented in [15, 121].
Reference: [79] <author> S. Jasik. </author> <title> Monitoring program execution on the CDC6000 machines. </title> <editor> In R. Rustin, editor, </editor> <booktitle> Design and Optimization of Compilers, </booktitle> <pages> pages 129-136. </pages> <publisher> Prentice-Hall, </publisher> <address> En-glewood Cliffs, NJ, </address> <month> August </month> <year> 1972. </year>
Reference-contexts: They are not integrated into the same environment as the monitored program. The CDC 6600 consists of central processors and peripheral processors [166]. Central and peripheral processors communicate through the common memory. Peripheral processors could be used to monitor the central processor <ref> [79] </ref>. No facility for describing the computational behavior of central processors is provided in CDC 6600. The IBM 370 includes program event recording that can be invoked without any preplanning in the design of the program [30].
Reference: [80] <author> D. R. Jefferson. </author> <title> Virtual time. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 7(3) </volume> <pages> 404-425, </pages> <month> July </month> <year> 1985. </year>
Reference-contexts: It is a well established concept in computer science used in program development and debugging [15, 50, 121, 126, 164, 168, 182], in programming environments and human-computer interaction [11, 66, 99, 101, 180], in fault-tolerant computing [34, 51, 97, 98] and in speculative computation <ref> [57, 80] </ref>. In computer architecture, techniques of reverse execution are used to provide precise interrupts [77, 147]. Because computer processes are in general not reversible, special history information must be recorded in order to be able to restore earlier states.
Reference: [81] <author> M. S. Johnson. </author> <title> Translator design to support run-time debugging. </title> <journal> Software-Practice and Experience, </journal> <volume> 9(12) </volume> <pages> 1035-1041, </pages> <month> December </month> <year> 1979. </year>
Reference-contexts: This section describes techniques that provide, for variables and the program, a correspondence between low level and high level representations. An extensive discussion on these techniques can be found in <ref> [81, 140] </ref>. 4.5.1.1 Variables In order to access a simple or a composite variable in the executor, the director needs the name, the address, and the type of the variable. The name and the address are maintained in internal interpreter tables.
Reference: [82] <author> M. S. Johnson. </author> <title> Some requirements for architectural support of software debugging. </title> <booktitle> In Proc. Symp. Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 140-148. </pages> <publisher> ACM, </publisher> <year> 1982. </year>
Reference-contexts: One of the microprocessors providing improved debugging support is the Intel 80386, which provides four breakpoint registers to set various traps [78]. The purpose of breakpoint registers is similar to that of IBM's program event recording with a limited functionality. Discussions on architectural support for debugging are given in <ref> [82, 113] </ref>. Sophisticated debugging environments are presented in [15, 121]. An interpreter of machine instructions that functions as a debugger is described in [48]. Recent efforts in debugging concentrate on parallel programs [83, 111]. Debugging represents a subset of conversational programming with the emphasis on finding errors in programs.
Reference: [83] <author> J. Joyce, G. Lomow, K. Slind, and B. Unger. </author> <title> Monitoring distributed systems. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 5(2) </volume> <pages> 121-150, </pages> <month> May </month> <year> 1987. </year>
Reference-contexts: Discussions on architectural support for debugging are given in [82, 113]. Sophisticated debugging environments are presented in [15, 121]. An interpreter of machine instructions that functions as a debugger is described in [48]. Recent efforts in debugging concentrate on parallel programs <ref> [83, 111] </ref>. Debugging represents a subset of conversational programming with the emphasis on finding errors in programs. Debugging environments provide only limited monitoring and controlling capabilities. Another 10 limitation of debuggers is that the language used in debuggers is different than the language used in the debugged program.
Reference: [84] <author> T. Kaminuma and G. Matsumoto. Biocomputers: </author> <title> The Next Generation from Japan. </title> <publisher> Chapman and Hall, </publisher> <address> London, </address> <year> 1991. </year>
Reference-contexts: In principle, the same technology used by living organisms could be used to implement growing computations [159]. A discussion on design issues of molecular computers is provided in <ref> [40, 84] </ref>. 6.4 Paradigms in Computer Science This section gives a general view on the role of complex systems in computer science. Three paradigms and their approach to problems in computer science are discussed: mathematical, physics, and systems science.
Reference: [85] <author> J. G. Kemeny. </author> <title> Man viewed as a machine. </title> <journal> Scientific American, </journal> 192(4) 58-67, April 1955. 
Reference-contexts: The tools of physics help us to increase the power of computers, but do not help to reduce computer's complexity. 6.4.3 Systems Science Paradigm Complex systems, especially living organisms, are often seen as machines <ref> [85] </ref>. To view complex systems as machines emphasizes the qualities of machines at the expense of the qualities of complex systems. Machines are good at narrowly defined and clearly specified tasks. Airplanes are faster than birds, trucks are stronger than elephants, computers invert matrices faster than humans.
Reference: [86] <author> B. W. Kernighan and D. M. Ritchie. </author> <title> The C Programming Language. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1978. </year>
Reference-contexts: Because (besides developing foundations) one objective was to build a working introspective system, a programming language for executors had to be selected. Three languages were main candidates: C, Lisp and Smalltalk <ref> [60, 86, 181] </ref>. The execution of 16 programs in Lisp and Smalltalk can be nicely decomposed into smaller steps. This property made them attractive, but a satisfactory way to incorporate garbage collection and a sophisticated run time environment in introspective systems was not found.
Reference: [87] <author> P. B. Kessler. </author> <title> Fast breakpoints: </title> <booktitle> Design and implementation. In Proceedings of SIGPLAN'90 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 78-84. </pages> <publisher> ACM, </publisher> <year> 1990. </year>
Reference-contexts: Events provide significantly more power than stepwise execution. During a stepwise execution, the program is stopped after every executed instruction so that the process state can be examined. Because a direct stepwise execution slows down the execution more than five orders of magnitude <ref> [10, 87] </ref>, a stepwise execution is more efficiently implemented in an interpreted system [48]. Although stepwise execution provides complete information about the program behavior, this information describes static behavior. <p> The increase in the program's code size due to the event emitting code is estimated to be more than 200%, using state of the art methods described in <ref> [87] </ref>. 37 3.1.3 Prediction of Termination Time The halting theorem by Turing demonstrates that it is impossible to predict if an arbitrary program will terminate. Nevertheless, there is a large class of programs for which it is possible to show that programs terminate. <p> Recursive calls are normally not available in conventional debuggers. Only recently, some debuggers with this functionality have appeared [125]. The director to check register allocation examines every executed instruction. It is extremely expensive to examine every executed instruction using regular debuggers. Using numbers from <ref> [10, 87] </ref>, if an examination of 46 Check_Register_Allocation () - Mark_All_Registers; do - event = Read_Next_Event (); if (event-&gt;evinst == CALL) - Record_Register_Values; Check_Register_Allocation (); Mark_Registers_Whose_Values_Differ_From_Recorded_Values; -; if (event-&gt;evinst_Modifies_Register_i) Unmark_Register_i; if (event-&gt;evinst_Reads_Register_i && Register_i_Is_Marked) Debugger (); while (event-&gt;evinst != RETURN); -; every instruction is required, it is estimated that regular debuggers
Reference: [88] <author> G. Kiczales and D. G. Bobrow. </author> <title> The Art of Metaobject Protocol. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1991. </year>
Reference-contexts: In this model, the program has one thread of control at any moment regardless of the number of interpreters in the tower. The work on metainterpreters whose behavior can be changed under the direction of the interpreted program is described in <ref> [88] </ref>. Reflection in object oriented languages is described in [106]. These approaches address self-referential systems from the point of view of programming languages and data representation. The program and the metaprogram are limited in that they share a single thread of control.
Reference: [89] <author> A. Kishon, P. Hudak, and C. Consel. </author> <title> Monitoring semantics: A formal framework for specifying, implementing, and reasoning about execution monitors. </title> <booktitle> In Proceedings of SIGPLAN'91 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 338-352. </pages> <publisher> ACM, </publisher> <year> 1991. </year>
Reference-contexts: Events have been implemented in interpretive environments [64, 121], or by augmenting source code to emit events [24, 168]. Although the content of events used to monitor programs in high level programming languages is often at a high level <ref> [24, 64, 89, 121, 168] </ref>, high level events are not the most appropriate choice for introspective computer systems. In many cases, high level events are not able to describe the complete computational behavior, because they are restricted to the most common monitoring operations. <p> Different degrees of correspondence between levels can be achieved. ... dsldobject (filename); dslink (filename,funcname); ... 92 Previous approaches to a high level description of program behavior include methods to compose low level events, special event description languages, and a direct generation of high level events <ref> [36, 38, 89, 96, 104, 125, 150, 168, 170] </ref>. Because the execution stream provides a complete executor's behavior and a director can use arbitrary programming constructs, an introspective computer system provides a more general method of dealing with program behavior than previous approaches.
Reference: [90] <author> D. E. Knuth. </author> <booktitle> The Art of Computer Programming, </booktitle> <volume> Vol. 1: </volume> <booktitle> Fundamental Algorithms. </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1973. </year>
Reference-contexts: If the verification process using one agent is too slow, the modeler can be sampled at a higher rate by interleaving several processors. 3.5.3 Real-Time Garbage Collection Garbage collection is an important feature of sophisticated programming environments and languages <ref> [1, 90] </ref>. A lack of efficient, real-time, methods for garbage collection restricts the use of garbage collection in industrial applications [7, 16]. A real-time garbage collection algorithm can be implemented in an introspective computer. 3.5.3.1 Copying Garbage Collection Garbage collection involves two processes: a mutator and a collector [14, 173].
Reference: [91] <author> A. Koestler. </author> <title> The Ghost in the Machine. </title> <publisher> Hutchinson, </publisher> <address> London, </address> <year> 1967. </year>
Reference-contexts: This is demonstrated by the way the human body works. A similar argument is presented in <ref> [91] </ref>. The human body has reflexes that act through senses and muscles at the bottom of the hierarchy and consciousness at the top with intermediate levels in between (see Reflexes interact directly with the environment. They act mostly automatically and immediately.
Reference: [92] <author> R. A. Kowalski and M. J. Sergot. </author> <title> A logic-based calculus of events. </title> <journal> New Generation Computing, </journal> <volume> 4 </volume> <pages> 67-95, </pages> <year> 1986. </year>
Reference-contexts: Such a differentiated description would provide an efficient way to find out the effect of the event on the process state. The calculus of events developed by Kowalski and Sergot <ref> [92] </ref> is an approach to formalize events in the context of database applications. The calculus of events includes the notion of transitions from one state to another, but it does not provide the measure of the degree of state similarity.
Reference: [93] <author> R. Laing. </author> <title> Machines as organisms: An exploration of the relevance of recent results. </title> <journal> BioSystems, </journal> <volume> 11 </volume> <pages> 201-215, </pages> <year> 1979. </year> <month> 183 </month>
Reference-contexts: The model of kinematic automata is concerned with kinematic and geometric properties of computational elements. The development of kinematic automata has been largely overshadowed by cellular automata where the position and the functionality of computing elements are fixed. An overview of results in kinematic automata theory is presented in <ref> [93] </ref>. A survey of results in early cellular automata theory has been compiled by Burks [27]. One consequence of the ability to create new computational elements is the possibility of a limited exponential growth in the number of computational elements.
Reference: [94] <author> L. Lamport. </author> <title> Time, clocks, and the ordering of events in a distributed system. </title> <journal> Communications of the ACM, </journal> <volume> 21(7) </volume> <pages> 558-565, </pages> <month> July </month> <year> 1978. </year>
Reference-contexts: The instruction counter counts the number of executed instructions. It is set to zero at the beginning of the 18 process execution and incremented for each executed instruction. This counter determines internal logical time in the process history <ref> [94] </ref>. The instruction counter can be provided as a hardware or a software addition to an existing system [29, 115] or as a special register in the processor. The instruction set emulated on the interpreter is assumed to be a load/store model [67].
Reference: [95] <editor> C. G. Langton, editor. </editor> <booktitle> Artificial Life, The Proceedings of an Interdisciplinary Workshop on the Synthesis and Simulation of Living Systems, </booktitle> <address> Los Alamos, 1987, Reading, MA, 1989. </address> <publisher> Addison-Wesley. </publisher>
Reference-contexts: One consequence of the ability to create new computational elements is the possibility of a limited exponential growth in the number of computational elements. A well established formalism capable of exponential growth is the model of L-systems, introduced 151 by Lindenmayer [103]. An extensive bibliography is published in <ref> [95] </ref>. L-systems are based on the parallel transformation of strings. Extensions of L-systems to two and three dimensions are called map L-systems and cellworks.
Reference: [96] <author> B. Lazzerini and L. Lopriore. </author> <title> Abstraction mechanisms for event control in program debugging. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 15(7) </volume> <pages> 890-901, </pages> <month> July </month> <year> 1989. </year>
Reference-contexts: Different degrees of correspondence between levels can be achieved. ... dsldobject (filename); dslink (filename,funcname); ... 92 Previous approaches to a high level description of program behavior include methods to compose low level events, special event description languages, and a direct generation of high level events <ref> [36, 38, 89, 96, 104, 125, 150, 168, 170] </ref>. Because the execution stream provides a complete executor's behavior and a director can use arbitrary programming constructs, an introspective computer system provides a more general method of dealing with program behavior than previous approaches.
Reference: [97] <author> P. A. Lee, N. Ghani, and K. Heron. </author> <title> A recovery cache for the PDP-11. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 29(6) </volume> <pages> 546-549, </pages> <month> June </month> <year> 1980. </year>
Reference-contexts: It is a well established concept in computer science used in program development and debugging [15, 50, 121, 126, 164, 168, 182], in programming environments and human-computer interaction [11, 66, 99, 101, 180], in fault-tolerant computing <ref> [34, 51, 97, 98] </ref> and in speculative computation [57, 80]. In computer architecture, techniques of reverse execution are used to provide precise interrupts [77, 147]. Because computer processes are in general not reversible, special history information must be recorded in order to be able to restore earlier states.
Reference: [98] <author> Y.-H. Lee and K. G. Shin. </author> <title> Design and evaluation of a fault-tolerant multiprocessor using hardware recovery blocks. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 33(2) </volume> <pages> 113-124, </pages> <month> February </month> <year> 1984. </year>
Reference-contexts: It is a well established concept in computer science used in program development and debugging [15, 50, 121, 126, 164, 168, 182], in programming environments and human-computer interaction [11, 66, 99, 101, 180], in fault-tolerant computing <ref> [34, 51, 97, 98] </ref> and in speculative computation [57, 80]. In computer architecture, techniques of reverse execution are used to provide precise interrupts [77, 147]. Because computer processes are in general not reversible, special history information must be recorded in order to be able to restore earlier states.
Reference: [99] <author> G. B. Leeman Jr. </author> <title> A formal approach to undo operations in programming languages. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 8(1) </volume> <pages> 50-87, </pages> <month> January </month> <year> 1986. </year>
Reference-contexts: This section discusses two applications of the history. 3.4.1 Reverse Execution in Human-Computer Interaction A generic undo operation is an important construct in human-computer interaction and programming environments <ref> [11, 66, 99] </ref>. Because it supports reverse execution, an introspective computer can return any program to a state in the past regardless of the programming language or the programming environment. A common application of reverse execution is debugging [15, 50, 121, 182]. <p> Details are presented in Section 5.4. An important feature of this integrated support is that reverse execution is implemented at the hardware level. Reverse execution is therefore available for any program and it is not limited to a particular programming environment as in more traditional implementations <ref> [3, 99, 168, 180] </ref>. Sample measurements show that the execution of one million instructions produces around 30 Kbytes of history. A 50 MIPS 51 processor would generate 1.5 Mbytes of history per second. The history of 100 seconds of execution can be saved on 150 Mbytes of disk space. <p> It is a well established concept in computer science used in program development and debugging [15, 50, 121, 126, 164, 168, 182], in programming environments and human-computer interaction <ref> [11, 66, 99, 101, 180] </ref>, in fault-tolerant computing [34, 51, 97, 98] and in speculative computation [57, 80]. In computer architecture, techniques of reverse execution are used to provide precise interrupts [77, 147].
Reference: [100] <author> K. Li, J. F. Naughton, and J. S. Plank. </author> <title> Concurrent real-time checkpoint for parallel programs. </title> <booktitle> In Second ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <pages> pages 79-88. </pages> <publisher> ACM, </publisher> <year> 1990. </year>
Reference-contexts: For real-time systems, it is important that the latency is bounded and as small as possible. Some existing real-time algorithms for checkpoints use a paging mechanism to achieve latency on the order of 0.1 seconds <ref> [50, 100] </ref>. The ability of reverse execution in introspective computers provides a real-time checkpoint with a minimal latency. The algorithm for a real-time checkpoint consists of three phases: the copying of the internal processor state, the copying of the state in the main memory, and the application of history.
Reference: [101] <author> Henry Lieberman. </author> <title> Reversible object-oriented interpreters. </title> <booktitle> In European Conference on Object-Oriented Programming, </booktitle> <pages> pages 11-19, </pages> <month> June </month> <year> 1987. </year>
Reference-contexts: It is a well established concept in computer science used in program development and debugging [15, 50, 121, 126, 164, 168, 182], in programming environments and human-computer interaction <ref> [11, 66, 99, 101, 180] </ref>, in fault-tolerant computing [34, 51, 97, 98] and in speculative computation [57, 80]. In computer architecture, techniques of reverse execution are used to provide precise interrupts [77, 147].
Reference: [102] <author> J. C. Lilly. </author> <title> Programming and Metaprogramming in the Human Biocomputer. </title> <publisher> Julian Press, </publisher> <address> New York, </address> <year> 1967. </year>
Reference-contexts: From the neurophysiology point of view, Lilly describes human beings as biocomputers in which subsystems are controlled by a central control <ref> [102] </ref>. In the preface to the second edition, Lilly says: . . . metaprogramming is an operation in which a central control system controls hundreds of thousands of programs operating in parallel simultaneously.
Reference: [103] <author> A. Lindenmayer. </author> <title> Mathematical models for cellular interactions in development, parts I and II. </title> <journal> Journal of Theoretical Biology, </journal> <volume> 18 </volume> <pages> 280-315, </pages> <year> 1968. </year>
Reference-contexts: One consequence of the ability to create new computational elements is the possibility of a limited exponential growth in the number of computational elements. A well established formalism capable of exponential growth is the model of L-systems, introduced 151 by Lindenmayer <ref> [103] </ref>. An extensive bibliography is published in [95]. L-systems are based on the parallel transformation of strings. Extensions of L-systems to two and three dimensions are called map L-systems and cellworks.
Reference: [104] <author> L. Lopriore. </author> <title> A user interface specification for a program debugging and measuring environment. </title> <journal> Software-Practice and Experience, </journal> <volume> 19(5) </volume> <pages> 437-460, </pages> <month> May </month> <year> 1989. </year>
Reference-contexts: Another advantage of directors for debugging is that directors can be programmed in any available programming language, because introspective capabilities are provided in library routines. This alleviates the need for specialized debugging languages and their programming tools that are present in traditional programming environments <ref> [104, 125] </ref>. Because directors can use regular compilers and programming tools, this significantly simplifies the development of debugging environments. 3.3.2 Conversational Computing Computers were originally developed as machines for the execution of long series of symbol manipulation without human intervention. Main types of applications were number crunching and data manipulation. <p> Different degrees of correspondence between levels can be achieved. ... dsldobject (filename); dslink (filename,funcname); ... 92 Previous approaches to a high level description of program behavior include methods to compose low level events, special event description languages, and a direct generation of high level events <ref> [36, 38, 89, 96, 104, 125, 150, 168, 170] </ref>. Because the execution stream provides a complete executor's behavior and a director can use arbitrary programming constructs, an introspective computer system provides a more general method of dealing with program behavior than previous approaches.
Reference: [105] <author> J. E. Lumpp Jr., T. L. Casavant, H. J. Siegel, and D. C. Marinescu. </author> <title> Specification and identification of events for debugging and performance monitoring of distributed multiprocessor systems. </title> <booktitle> In Proceedings of the 10th International Conference on Distributed Computing Systems, </booktitle> <pages> pages 476-483. </pages> <publisher> IEEE, </publisher> <year> 1990. </year>
Reference-contexts: The overhead of generating high level events that describe the complete computational behavior by modifying program code is prohibitive. Introspective computer systems require events that are capable of describing the complete computational behavior without interfering with program execution. One solution that provides such events is real-time hardware monitors <ref> [105, 133, 138, 169] </ref>. Even these events can be incomplete, because hardware monitors might watch buses without access to the internal operation of the processor. Several false starts were attempted before the final solution was found.
Reference: [106] <author> P. Maes. </author> <title> Concepts and experiments in computational reflection. OOPSLA '87 Proceedings, </title> <journal> Sigplan Notices, </journal> <volume> 22(12) </volume> <pages> 147-155, </pages> <year> 1987. </year>
Reference-contexts: The work on metainterpreters whose behavior can be changed under the direction of the interpreted program is described in [88]. Reflection in object oriented languages is described in <ref> [106] </ref>. These approaches address self-referential systems from the point of view of programming languages and data representation. The program and the metaprogram are limited in that they share a single thread of control. It is an unresolved problem when the control should switch from the program to the metaprogram.
Reference: [107] <editor> P. Maes and D. Nardi, editors. </editor> <title> Meta-Level Architectures and Reflection. </title> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <year> 1988. </year>
Reference-contexts: They are not designed to feed symbolic data back to themselves in real-time. 7 1.2.3 Meta-Level Architectures and Reflection Reflection and meta-level architectures, well-developed areas of artificial intelligence, deal with computer programs that manipulate their own representation including the interpreter on which they are running <ref> [45, 107, 145] </ref>. Smith [146] divides self-referential programs into four classes.
Reference: [108] <author> K. Marzullo, R. Cooper, M. D. Wood, and K. P. Birman. </author> <title> Tools for distributed application environment. </title> <journal> IEEE Computer, </journal> <volume> 24(8) </volume> <pages> 42-51, </pages> <month> August </month> <year> 1991. </year> <month> 184 </month>
Reference-contexts: Monitors and debuggers are a part of a class of systems called reactive systems [65]. A reactive system monitors its computational, synthetic environment and reacts to it. An application of reactive systems to distributed application management is described in <ref> [108] </ref>. A reactive system monitors the environment through sensors and responds through actuators. <p> An operating system does not interfere with the internal control of a process, only with its use of resources. Recently, simple hierarchies have been implemented in complex distributed applications <ref> [19, 108, 110] </ref>. The control in these applications is limited, because it is specialized for a particular application. The limitations of specialized approaches are removed in an introspective computer system, which provides a general framework to build hierarchical computer systems.
Reference: [109] <editor> H. R. Maturana and F. J. Varela. Autopoiesis and Cognition. D. </editor> <publisher> Reidel, </publisher> <address> Boston, </address> <year> 1980. </year>
Reference-contexts: For example, anticipation enables humans to significantly decrease their reaction time [28, 161]. Anticipation of the future requires that the system operates to a large degree autonomously from the environment. In the study of complex natural systems, autonomy is becoming one of the major identifying properties of living organisms <ref> [109, 175] </ref>. Autonomous operation in complex systems is achieved through hierarchical organization, because higher hierarchical levels are freed from real-time constraints. Hierarchical systems have the time to evolve [144]. By learning, the system optimizes itself for the future.
Reference: [110] <author> R. A. Maxion. </author> <title> Toward diagnosis as an emergent behavior in a network ecosystem. </title> <editor> In S. Forrest, editor, </editor> <booktitle> Emergent Computation, Proceedings of the Ninth Annual Center for Nonlinear Studies and Computing Divison Conference, Physica D, </booktitle> <volume> Vol. 42, 1, </volume> <pages> pages 66-84, </pages> <year> 1990. </year>
Reference-contexts: An operating system does not interfere with the internal control of a process, only with its use of resources. Recently, simple hierarchies have been implemented in complex distributed applications <ref> [19, 108, 110] </ref>. The control in these applications is limited, because it is specialized for a particular application. The limitations of specialized approaches are removed in an introspective computer system, which provides a general framework to build hierarchical computer systems.
Reference: [111] <author> C. E. McDowell and D. P. Helmbold. </author> <title> Debugging concurrent programs. </title> <journal> ACM Computing Surveys, </journal> <volume> 21(4) </volume> <pages> 593-622, </pages> <month> December </month> <year> 1989. </year>
Reference-contexts: Discussions on architectural support for debugging are given in [82, 113]. Sophisticated debugging environments are presented in [15, 121]. An interpreter of machine instructions that functions as a debugger is described in [48]. Recent efforts in debugging concentrate on parallel programs <ref> [83, 111] </ref>. Debugging represents a subset of conversational programming with the emphasis on finding errors in programs. Debugging environments provide only limited monitoring and controlling capabilities. Another 10 limitation of debuggers is that the language used in debuggers is different than the language used in the debugged program. <p> Therefore, the decision was made to use C. Each step is described by an event. The use of events in monitoring process behavior is common <ref> [15, 64, 66, 111, 120, 121, 150, 168] </ref>. Usually events provide only that subset of process behavior which is important for a particular application. For example, Hanson [64] provides the following events: variable referencing, statement execution, program interruption, function call and return, and execution time errors.
Reference: [112] <author> P. McKerrow. </author> <title> Performance Measurement of Computer Systems. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1988. </year>
Reference-contexts: This section surveys existing solutions. 9 A description of monitoring techniques for purposes of testing, debugging, performance measurement, and program optimization can be found in <ref> [112, 134] </ref>. Hardware monitors provide a flexible monitoring environment, but are used for special purposes. They are not integrated into the same environment as the monitored program. The CDC 6600 consists of central processors and peripheral processors [166]. Central and peripheral processors communicate through the common memory. <p> During execution, the speed of the filter with the Unison algorithm is close to the speed of compiled filters. A common functionality of a filter is to evaluate Boolean expressions on the values from events <ref> [52, 112, 133, 134] </ref>. Depending on the purpose of monitoring, different Boolean functions are evaluated at different time periods. To facilitate monitoring, a new approach for efficient evaluation of Boolean expressions has been developed. <p> This approach is suitable for complex introspective systems with many processors, because it may not be feasible to slow down some processors. 116 5.2.2 Universal Boolean Element Monitoring involves the evaluation of Boolean functions based on the real-time behavior of the system being monitored <ref> [52, 112, 133, 134] </ref>. The problem is how to develop an efficient approach to formulate and evaluate an arbitrary Boolean expression in real-time. <p> Some solutions to this monitoring problem include using a fixed set of Boolean expressions (fixed hardware tools), the manual rewiring of the monitor (wired program tools), and the use of a high speed programmable monitor (stored program tools) <ref> [52, 112] </ref>. Stored program tools are the most flexible and satisfactory, but they impose a high cost on the monitor because the monitor must operate at a much faster rate than that of the system being monitored. An extensive survey of monitoring tools is presented in [138].
Reference: [113] <author> R. E. McLear, D. M. Scheibelhut, and E. Tammaru. </author> <title> Guidelines for creating a debuggable processor. </title> <booktitle> In Proc. Symp. Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 100-106. </pages> <publisher> ACM, </publisher> <year> 1982. </year>
Reference-contexts: One of the microprocessors providing improved debugging support is the Intel 80386, which provides four breakpoint registers to set various traps [78]. The purpose of breakpoint registers is similar to that of IBM's program event recording with a limited functionality. Discussions on architectural support for debugging are given in <ref> [82, 113] </ref>. Sophisticated debugging environments are presented in [15, 121]. An interpreter of machine instructions that functions as a debugger is described in [48]. Recent efforts in debugging concentrate on parallel programs [83, 111]. Debugging represents a subset of conversational programming with the emphasis on finding errors in programs.
Reference: [114] <author> C. Mead and L. Conway. </author> <title> Introduction to VLSI Systems. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1980. </year>
Reference-contexts: One example can be found in the implementation of arithmetic logic units (ALU). A part of the ALU is the general logic function block <ref> [37, 114] </ref> which is essentially an implementation of a multiplexer with switches (see Figure 5.6). Four control signals, f 0 , f 1 , f 2 , and f 3 , are needed to specify the operation performed by the ALU. <p> Many existing Boolean formulas can be treated as special cases of the Unison algorithm. Two such formulas are a 4-input multiplexer <ref> [114] </ref> and the Reed-Muller expansion [137].
Reference: [115] <author> J. M. Mellor-Crummey and T. J. LeBlanc. </author> <title> A software instruction counter. </title> <booktitle> In Proc. of the 3nd International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 78-86. </pages> <publisher> ACM, </publisher> <year> 1989. </year>
Reference-contexts: It is set to zero at the beginning of the 18 process execution and incremented for each executed instruction. This counter determines internal logical time in the process history [94]. The instruction counter can be provided as a hardware or a software addition to an existing system <ref> [29, 115] </ref> or as a special register in the processor. The instruction set emulated on the interpreter is assumed to be a load/store model [67]. In this model, load and store are the only instructions that access main memory.
Reference: [116] <author> D. Michie. </author> <title> Memo functions and machine learning. </title> <journal> Nature, </journal> <volume> 218(1) </volume> <pages> 19-22, </pages> <month> April </month> <year> 1968. </year>
Reference-contexts: If the function is called again with the same parameters, the result can be returned immediately and further evaluation of the function is cancelled. Memoing is restricted to purely applicative functions. It is an important construct in machine learning <ref> [116] </ref> and logic programming [53, 177]. 40 Memoing has been implemented on a program to evaluate Fibonacci numbers. A straightforward recursive program to evaluate Fibonacci numbers is shown in Figure 3.5.
Reference: [117] <author> J. G. Miller. </author> <title> Living Systems. </title> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <year> 1978. </year>
Reference-contexts: For example, levels of structural hierarchy in computers can be divided into: gates, functional units, subsystems, computers, local area networks, wide area networks, and worldwide networks. Another example are levels of structural hierarchy in living systems: cells, organs, organism, group, organization, society, and supranational system <ref> [117] </ref>. In a control hierarchy, levels are physically distinct. They interact through communication. An example of a control hierarchy is military organization. <p> Central control is a top level subsystem in control hierarchy. It gets information from other subsystems and sends back control information. This provides coordinated actions of subsystems. Central control is the most important subsystem of complex systems, because it essentially defines the system <ref> [117] </ref>. It functions as an amplifier of control information. Central control selects only a part of information available from other subsystems and amplifies the selected part through controlling actions [132].
Reference: [118] <author> C. Mills, S. C. Ahalt, and J. Fowler. </author> <title> Compiled instruction set simulation. </title> <journal> Software-Practice and Experience, </journal> <volume> 21(8) </volume> <pages> 877-889, </pages> <month> August </month> <year> 1991. </year>
Reference-contexts: The emulation of Dynascope instructions is implemented in a straightforward manner. No attempt has been made to use special optimization methods, such as those described in <ref> [118] </ref>, to speed up the interpretation. 4.3.2 Event Transfer There are two methods of event transfer, synchronous and asynchronous. After an event is transferred in synchronous mode, the interpreter waits for a directive from the director.
Reference: [119] <author> M. Minsky. </author> <title> The Society of Mind. </title> <publisher> Simon and Schuster, </publisher> <address> New York, </address> <year> 1985. </year>
Reference-contexts: One part of the system generates hypotheses. Another part of the system tests these hypotheses. A model of the organization of the human mind close to the introspective framework in this work is proposed by Minsky <ref> [119] </ref>. He proposes to divide brain into two parts: A and B. The B-brain monitors and controls the A-brain. The A-brain is connected to the real world. The activity of the A-brain represents the external world to the B-brain.
Reference: [120] <author> M. L. </author> <title> Model. Monitoring system behavior in a complex computational environment. </title> <type> Technical Report CSL-79-1, </type> <note> Xerox PARC, </note> <year> 1979. </year>
Reference-contexts: Therefore, the decision was made to use C. Each step is described by an event. The use of events in monitoring process behavior is common <ref> [15, 64, 66, 111, 120, 121, 150, 168] </ref>. Usually events provide only that subset of process behavior which is important for a particular application. For example, Hanson [64] provides the following events: variable referencing, statement execution, program interruption, function call and return, and execution time errors.
Reference: [121] <author> T. G. Moher. </author> <title> PROVIDE: A process visualization and debugging environment. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 14(6) </volume> <pages> 849-857, </pages> <month> June </month> <year> 1988. </year>
Reference-contexts: The purpose of breakpoint registers is similar to that of IBM's program event recording with a limited functionality. Discussions on architectural support for debugging are given in [82, 113]. Sophisticated debugging environments are presented in <ref> [15, 121] </ref>. An interpreter of machine instructions that functions as a debugger is described in [48]. Recent efforts in debugging concentrate on parallel programs [83, 111]. Debugging represents a subset of conversational programming with the emphasis on finding errors in programs. Debugging environments provide only limited monitoring and controlling capabilities. <p> Therefore, the decision was made to use C. Each step is described by an event. The use of events in monitoring process behavior is common <ref> [15, 64, 66, 111, 120, 121, 150, 168] </ref>. Usually events provide only that subset of process behavior which is important for a particular application. For example, Hanson [64] provides the following events: variable referencing, statement execution, program interruption, function call and return, and execution time errors. <p> Usually events provide only that subset of process behavior which is important for a particular application. For example, Hanson [64] provides the following events: variable referencing, statement execution, program interruption, function call and return, and execution time errors. Events have been implemented in interpretive environments <ref> [64, 121] </ref>, or by augmenting source code to emit events [24, 168]. Although the content of events used to monitor programs in high level programming languages is often at a high level [24, 64, 89, 121, 168], high level events are not the most appropriate choice for introspective computer systems. <p> Events have been implemented in interpretive environments [64, 121], or by augmenting source code to emit events [24, 168]. Although the content of events used to monitor programs in high level programming languages is often at a high level <ref> [24, 64, 89, 121, 168] </ref>, high level events are not the most appropriate choice for introspective computer systems. In many cases, high level events are not able to describe the complete computational behavior, because they are restricted to the most common monitoring operations. <p> Because it supports reverse execution, an introspective computer can return any program to a state in the past regardless of the programming language or the programming environment. A common application of reverse execution is debugging <ref> [15, 50, 121, 182] </ref>. When a program exhibits incorrect behavior we often want to see previous states of the program execution to find the error. This can be easily provided using the history. <p> Efficient evaluation of Boolean expressions has other important applications. Some of these applications include database search [135], programming 97 environments [66], modeling of digital circuits and software systems [25], debugging <ref> [121] </ref>, and event recording [135]. The usual approach to the evaluation of Boolean expressions in software involves interpretation which is expensive in execution time. Improvements include compiled evaluation [25], special-purpose circuits [41, 135], and reduction in the number of evaluations [121]. <p> [66], modeling of digital circuits and software systems [25], debugging <ref> [121] </ref>, and event recording [135]. The usual approach to the evaluation of Boolean expressions in software involves interpretation which is expensive in execution time. Improvements include compiled evaluation [25], special-purpose circuits [41, 135], and reduction in the number of evaluations [121]. The compiled evaluation is the fastest method to evaluate Boolean expressions in software. Boolean expressions are stated as a program in a high-level programming language. To obtain results the program is compiled and executed with given inputs. <p> The approach using the history buffer has the same underlying concept as a history cache explained in the next section. 5.4 Reverse Execution Reverse execution provides access to old states of an executing process. It is a well established concept in computer science used in program development and debugging <ref> [15, 50, 121, 126, 164, 168, 182] </ref>, in programming environments and human-computer interaction [11, 66, 99, 101, 180], in fault-tolerant computing [34, 51, 97, 98] and in speculative computation [57, 80]. In computer architecture, techniques of reverse execution are used to provide precise interrupts [77, 147].
Reference: [122] <author> B. A. Myers. Incense: </author> <title> A system for displaying data structures. </title> <journal> Computer Graphics, </journal> <volume> 17(3) </volume> <pages> 115-125, </pages> <month> July </month> <year> 1983. </year>
Reference-contexts: Because the display is updated incrementally, the director handles in principle arbitrarily large lists without any degradation in performance. Details on the construction of the director are described in Section 4.4. Other approaches to visualize data structures are described in <ref> [122, 143] </ref>. In [143], Shi-momura and Isoda found that users of their system could find program errors about 30% faster than by using regular debuggers without visualization. Although the capabilities 34 provided by introspective computer systems may seem similar to previous approaches, they are qualitatively different.
Reference: [123] <author> A. Newell and H. A. Simon. </author> <title> Human Problem Solving. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1972. </year>
Reference-contexts: Therefore, a combined system of D and C where D is monitoring and controlling C is more expressive than C alone. The position that an intelligent system consists of two parts is advocated by pioneers of artificial intelligence, Newell and Simon <ref> [123] </ref>. They propose a generate and test paradigm 6 as the basis of intelligent behavior. One part of the system generates hypotheses. Another part of the system tests these hypotheses.
Reference: [124] <author> S. C. North and J. H. Reppy. </author> <title> Concurrent garbage collection on stock hardware. </title> <editor> In G. Kahn, editor, </editor> <booktitle> Functional Programming Languages and Computer Architecture, </booktitle> <volume> LNCS 274, </volume> <pages> pages 113-133. </pages> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1987. </year> <month> 185 </month>
Reference-contexts: After the traversal of grey objects is finished, all objects are black and FromSpace and ToSpace can be reversed. This process of scavenging can be implemented efficiently, provided that the mutator checks each pointer reference for a forwarding pointer. 57 3.5.3.2 Real-Time Enhancement Existing real-time garbage collection algorithms <ref> [9, 14, 23, 124] </ref> impose two limitations. First, the latency of the algorithm is limited by the time that it takes to copy the largest object. Second, the mutator is not allowed to store a FromSpace reference in an object. Both limitations can be removed in an introspective computer.
Reference: [125] <author> R. A. Olsson, R. H. Crawford, and W. W. Ho. </author> <title> A dataflow approach to event-based debugging. </title> <journal> Software-Practice and Experience, </journal> <volume> 21(2) </volume> <pages> 209-229, </pages> <month> February </month> <year> 1991. </year>
Reference-contexts: The director has several advantages over conventional debuggers. Because the director calls itself recursively, it can match the dynamic behavior of the executor. Recursive calls are normally not available in conventional debuggers. Only recently, some debuggers with this functionality have appeared <ref> [125] </ref>. The director to check register allocation examines every executed instruction. It is extremely expensive to examine every executed instruction using regular debuggers. <p> Another advantage of directors for debugging is that directors can be programmed in any available programming language, because introspective capabilities are provided in library routines. This alleviates the need for specialized debugging languages and their programming tools that are present in traditional programming environments <ref> [104, 125] </ref>. Because directors can use regular compilers and programming tools, this significantly simplifies the development of debugging environments. 3.3.2 Conversational Computing Computers were originally developed as machines for the execution of long series of symbol manipulation without human intervention. Main types of applications were number crunching and data manipulation. <p> Different degrees of correspondence between levels can be achieved. ... dsldobject (filename); dslink (filename,funcname); ... 92 Previous approaches to a high level description of program behavior include methods to compose low level events, special event description languages, and a direct generation of high level events <ref> [36, 38, 89, 96, 104, 125, 150, 168, 170] </ref>. Because the execution stream provides a complete executor's behavior and a director can use arbitrary programming constructs, an introspective computer system provides a more general method of dealing with program behavior than previous approaches.
Reference: [126] <author> D. Z. Pan and M. A. Linton. </author> <title> Supporting reverse execution of parallel programs. </title> <booktitle> In Proceedings SIGPLAN/SIGOPS Workshop on Parallel and Distributed Debugging, </booktitle> <pages> pages 124-129. </pages> <publisher> ACM, </publisher> <year> 1988. </year>
Reference-contexts: The approach using the history buffer has the same underlying concept as a history cache explained in the next section. 5.4 Reverse Execution Reverse execution provides access to old states of an executing process. It is a well established concept in computer science used in program development and debugging <ref> [15, 50, 121, 126, 164, 168, 182] </ref>, in programming environments and human-computer interaction [11, 66, 99, 101, 180], in fault-tolerant computing [34, 51, 97, 98] and in speculative computation [57, 80]. In computer architecture, techniques of reverse execution are used to provide precise interrupts [77, 147].
Reference: [127] <author> C. N. Parkinson. </author> <title> Parkinson's Law and Other Studies in Administration. </title> <publisher> Houghton Mi*in, </publisher> <address> Boston, </address> <year> 1957. </year>
Reference-contexts: Hierarchical systems have the time to evolve [144]. By learning, the system optimizes itself for the future. In doing this, higher levels automatize some activities by moving them to lower levels <ref> [127] </ref>. Because the processing power of each subsystem is limited, this provides a way to maintain the load in higher levels within bounds. An example is human learning. When we learn new things, conscious effort is required.
Reference: [128] <author> H. H. Pattee. </author> <title> Hierarchy Theory: The Challenge of Complex Systems. </title> <address> George Braziller, New York, </address> <year> 1973. </year>
Reference-contexts: Hierarchical systems are composed of levels which introduce a partial order on subsystems. A general discussion on hierarchical systems can be found in <ref> [43, 128, 139] </ref>. Two types of hierarchies can be observed in complex systems, a structural hierarchy and a control hierarchy [8, 43, 139]. In a structural hierarchy, each level is contained in the level above.
Reference: [129] <author> R. Penrose. </author> <title> The Emperors New Mind. </title> <publisher> Oxford University Press, Oxford, </publisher> <address> England, </address> <year> 1989. </year>
Reference-contexts: A proof of this result involves a mathematical system that can express both propositions and metalevel propositions about the system. Metalevel propositions are propositions about propositions in this system. An extensive discussion of this result can be found in <ref> [72, 129] </ref>. Although Godel's result is negative, it is encouraging. It demonstrates that any sufficiently complex formal system can be extended in a consistent way by adding new axioms to the system.
Reference: [130] <author> A. Perlis. </author> <title> The synthesis of algorithmic systems. </title> <booktitle> In ACM Turing Award Lectures, </booktitle> <pages> pages 5-16. </pages> <publisher> Anthology Series, ACM Press, </publisher> <year> 1987. </year>
Reference-contexts: The first to foresee the use of computers as a tool for developing models, solutions, and simulations of complex problems was von Neumann [176]. The term conversational computing was introduced by Perlis in his Turing award lecture <ref> [130] </ref>. It denotes the process of interaction between the programmer and the program in which the program is constantly being developed and improved. In his lecture, Perlis discusses requirements for a computer system to efficiently support conversational computing. <p> In his lecture, Perlis discusses requirements for a computer system to efficiently support conversational computing. One of the requirements is the ability of programs to monitor other programs <ref> [130] </ref>: "Process A continuously monitors process B so that when B attains a certain state, A intervenes to control the future activity of the process." Another requirement is the systematic modification of data and program code. <p> Main types of applications were number crunching and data manipulation. Eventually, another important type of computer applications emerged: using computers as general purpose modeling and simulation tools. This type of computer application is called conversational computing <ref> [130] </ref>. Applications in conversational computing demand a close coupling between the user and the computer. 47 Conversational computing includes highly interactive tasks in the development and exploration of complex models of natural and artificial systems.
Reference: [131] <author> B. L. Peuto and L. J. Shustek. </author> <title> An instruction timing model of CPU performance. </title> <booktitle> In Proceedings of the 4th Annual Symposium on Computer Architecture, </booktitle> <pages> pages 165-178, </pages> <year> 1977. </year>
Reference-contexts: A practical alternative is to record in the history only those history elements that contain changes to the main memory. Statistics of executed instructions in many applications show that a Store operation to the main memory constitutes around 10% of all executed instructions <ref> [67, 131] </ref>. Because each Store to the main memory is represented in the history by two words containing the memory address and the previous value at that address, this approach generates 0.8 Mbytes of history for 1 million executed instructions, a 15-fold compaction over a straightforward approach. <p> Saving the history influences the speed of the processor, because every Store to memory must be implemented as a Read/Modify/Write operation. To estimate this overhead in systems without a cache, the following assumptions are made in the model <ref> [67, 131] </ref>: (a) Read/Modify/Write takes twice the time of a Store, (b) Load from memory represents 20% of executed instructions, and (c) Store to memory represents 10% of executed instructions. 138 Size of Problem Under these assumptions, the traffic from the processor to the memory for n executed instructions consists of
Reference: [132] <author> J. R. Platt. </author> <title> Amplification aspects of biological response and mental activity. </title> <journal> American Scientist, </journal> <volume> 44 </volume> <pages> 180-197, </pages> <year> 1956. </year>
Reference-contexts: Central control is the most important subsystem of complex systems, because it essentially defines the system [117]. It functions as an amplifier of control information. Central control selects only a part of information available from other subsystems and amplifies the selected part through controlling actions <ref> [132] </ref>. Due to this selection and the amplification process, central control enables faster communication of critical data between distant subsystems than is possible in nonhierarchical systems. Effective communication between subsystems enables them to specialize, which leads to further improvements in the system operation.
Reference: [133] <author> B. Plattner. </author> <title> Real-time execution monitoring. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 10(6) </volume> <pages> 756-764, </pages> <month> November </month> <year> 1984. </year>
Reference-contexts: The overhead of generating high level events that describe the complete computational behavior by modifying program code is prohibitive. Introspective computer systems require events that are capable of describing the complete computational behavior without interfering with program execution. One solution that provides such events is real-time hardware monitors <ref> [105, 133, 138, 169] </ref>. Even these events can be incomplete, because hardware monitors might watch buses without access to the internal operation of the processor. Several false starts were attempted before the final solution was found. <p> During execution, the speed of the filter with the Unison algorithm is close to the speed of compiled filters. A common functionality of a filter is to evaluate Boolean expressions on the values from events <ref> [52, 112, 133, 134] </ref>. Depending on the purpose of monitoring, different Boolean functions are evaluated at different time periods. To facilitate monitoring, a new approach for efficient evaluation of Boolean expressions has been developed. <p> This approach to real-time monitoring requires that the director is significantly faster than the executor. It is estimated that the required ratio in processing power between the director and the executor is from 10 to 15 <ref> [133] </ref>. Because it is desirable to have a hierarchy of directors, where a director can be monitored by another director, an approach that requires the difference in processing power between the executor and the director is unacceptable. <p> This approach is suitable for complex introspective systems with many processors, because it may not be feasible to slow down some processors. 116 5.2.2 Universal Boolean Element Monitoring involves the evaluation of Boolean functions based on the real-time behavior of the system being monitored <ref> [52, 112, 133, 134] </ref>. The problem is how to develop an efficient approach to formulate and evaluate an arbitrary Boolean expression in real-time.
Reference: [134] <author> B. Plattner and J. Nievergelt. </author> <title> Monitoring program execution: A survey. </title> <journal> IEEE Computer, </journal> <volume> 14(11) </volume> <pages> 76-93, </pages> <month> November </month> <year> 1981. </year>
Reference-contexts: This section surveys existing solutions. 9 A description of monitoring techniques for purposes of testing, debugging, performance measurement, and program optimization can be found in <ref> [112, 134] </ref>. Hardware monitors provide a flexible monitoring environment, but are used for special purposes. They are not integrated into the same environment as the monitored program. The CDC 6600 consists of central processors and peripheral processors [166]. Central and peripheral processors communicate through the common memory. <p> During execution, the speed of the filter with the Unison algorithm is close to the speed of compiled filters. A common functionality of a filter is to evaluate Boolean expressions on the values from events <ref> [52, 112, 133, 134] </ref>. Depending on the purpose of monitoring, different Boolean functions are evaluated at different time periods. To facilitate monitoring, a new approach for efficient evaluation of Boolean expressions has been developed. <p> Events include information such as the program counter, instructions executed, memory accesses, and so on. Because certain conditions of a computer system that occur during the execution are interesting, events are postprocessed to detect these conditions. The conditions are specified as Boolean expressions <ref> [134] </ref>. An example that is used here is to find all events where a chosen procedure sets a chosen variable to a nonzero value. Such a condition can be useful in checking the synchronization of concurrent processes. <p> This approach is suitable for complex introspective systems with many processors, because it may not be feasible to slow down some processors. 116 5.2.2 Universal Boolean Element Monitoring involves the evaluation of Boolean functions based on the real-time behavior of the system being monitored <ref> [52, 112, 133, 134] </ref>. The problem is how to develop an efficient approach to formulate and evaluate an arbitrary Boolean expression in real-time.
Reference: [135] <author> V. M. Plavsic and P. E. Danielsson. </author> <title> Sequential evaluation of Boolean functions. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 28(12) </volume> <pages> 879-887, </pages> <month> December </month> <year> 1979. </year>
Reference-contexts: In hardware implementations, the same approach reduces the complexity and the size of the filter as compared to filters in previous solutions (see Section 5.2.2). Efficient evaluation of Boolean expressions has other important applications. Some of these applications include database search <ref> [135] </ref>, programming 97 environments [66], modeling of digital circuits and software systems [25], debugging [121], and event recording [135]. The usual approach to the evaluation of Boolean expressions in software involves interpretation which is expensive in execution time. <p> Efficient evaluation of Boolean expressions has other important applications. Some of these applications include database search <ref> [135] </ref>, programming 97 environments [66], modeling of digital circuits and software systems [25], debugging [121], and event recording [135]. The usual approach to the evaluation of Boolean expressions in software involves interpretation which is expensive in execution time. Improvements include compiled evaluation [25], special-purpose circuits [41, 135], and reduction in the number of evaluations [121]. The compiled evaluation is the fastest method to evaluate Boolean expressions in software. <p> The usual approach to the evaluation of Boolean expressions in software involves interpretation which is expensive in execution time. Improvements include compiled evaluation [25], special-purpose circuits <ref> [41, 135] </ref>, and reduction in the number of evaluations [121]. The compiled evaluation is the fastest method to evaluate Boolean expressions in software. Boolean expressions are stated as a program in a high-level programming language. To obtain results the program is compiled and executed with given inputs.
Reference: [136] <author> K. R. </author> <title> Popper. Indeterminism in quantum physics and in classical physics (two parts). </title> <journal> The British Journal for the Philosophy of Science, </journal> <pages> 1(2-3), </pages> <month> August, November </month> <year> 1950. </year>
Reference-contexts: One of the first to think in a formal way about limitations of a system with a single thread of control in monitoring itself was Popper <ref> [136] </ref>: . . . although C may describe its own t i state in detail, it can never complete this description before t i has passed; it therefore can describe completely its own past, but not its own future.
Reference: [137] <author> I. S. Reed. </author> <title> A class of multiple error correcting codes and the decoding scheme. </title> <journal> IRE Trans. Inform. Theory, </journal> <volume> IT-4:38-49, </volume> <month> September </month> <year> 1954. </year>
Reference-contexts: Many existing Boolean formulas can be treated as special cases of the Unison algorithm. Two such formulas are a 4-input multiplexer [114] and the Reed-Muller expansion <ref> [137] </ref>.
Reference: [138] <author> M. H. Reilly. </author> <title> A Performance Monitor for Parallel Programs. </title> <publisher> Academic Press, </publisher> <address> Boston, </address> <year> 1990. </year>
Reference-contexts: The overhead of generating high level events that describe the complete computational behavior by modifying program code is prohibitive. Introspective computer systems require events that are capable of describing the complete computational behavior without interfering with program execution. One solution that provides such events is real-time hardware monitors <ref> [105, 133, 138, 169] </ref>. Even these events can be incomplete, because hardware monitors might watch buses without access to the internal operation of the processor. Several false starts were attempted before the final solution was found. <p> Stored program tools are the most flexible and satisfactory, but they impose a high cost on the monitor because the monitor must operate at a much faster rate than that of the system being monitored. An extensive survey of monitoring tools is presented in <ref> [138] </ref>. This section presents a new technique that enables fast evaluation of Boolean expressions in hardware. This technique uses the same notion of the total differential of a Boolean function as the Unison algorithm described in Section 4.6. <p> Its design is similar to the filter described in [169]. A more sophisticated design with a filter implemented as a microprogrammable processor is described in <ref> [138] </ref>. A block diagram describing the functionality of a generic filter is shown in Figure 5.8. An actual implementation can be an expanded or a restricted version of the generic filter.
Reference: [139] <author> S. N. Salthe. </author> <title> Evolving Hierarchical Systems. </title> <publisher> Columbia University Press, </publisher> <address> New York, </address> <year> 1985. </year>
Reference-contexts: Hierarchical systems are composed of levels which introduce a partial order on subsystems. A general discussion on hierarchical systems can be found in <ref> [43, 128, 139] </ref>. Two types of hierarchies can be observed in complex systems, a structural hierarchy and a control hierarchy [8, 43, 139]. In a structural hierarchy, each level is contained in the level above. <p> Hierarchical systems are composed of levels which introduce a partial order on subsystems. A general discussion on hierarchical systems can be found in [43, 128, 139]. Two types of hierarchies can be observed in complex systems, a structural hierarchy and a control hierarchy <ref> [8, 43, 139] </ref>. In a structural hierarchy, each level is contained in the level above. For example, levels of structural hierarchy in computers can be divided into: gates, functional units, subsystems, computers, local area networks, wide area networks, and worldwide networks.
Reference: [140] <author> E. Satterthwaite. </author> <title> Debugging tools for high level languages. </title> <journal> Software-Practice and Experience, </journal> <volume> 2(3) </volume> <pages> 197-217, </pages> <month> July-September </month> <year> 1972. </year>
Reference-contexts: This section describes techniques that provide, for variables and the program, a correspondence between low level and high level representations. An extensive discussion on these techniques can be found in <ref> [81, 140] </ref>. 4.5.1.1 Variables In order to access a simple or a composite variable in the executor, the director needs the name, the address, and the type of the variable. The name and the address are maintained in internal interpreter tables.
Reference: [141] <author> D. A. Schmidt. </author> <title> Denotational Semantics. </title> <publisher> Allyn and Bacon, </publisher> <address> Boston, </address> <year> 1986. </year> <month> 186 </month>
Reference-contexts: It provides a formal background for process monitoring. This appendix is an introduction to execution calculus. A.2 Formal Approaches to Program Behavior A common formal approach to describe program behavior is denotational semantics <ref> [141] </ref>. Denotational semantics takes a high level view of programs; a program is a function. The object of study is program text from which program behavior is derived. Denotational semantics is useful for formal program development.
Reference: [142] <author> F. Sellers Jr., M. Y. Hsiao, and L. W. Bearnson. </author> <title> Analyzing errors with the Boolean difference. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 17 </volume> <pages> 676-683, </pages> <month> July </month> <year> 1968. </year>
Reference-contexts: In a practical application, the Unison algorithm performs with execution speed comparable to compiled evaluation while it retains the flexibility of an interpreted evaluation. 4.6.1 Total Differential The total differential is a part of the classical Boolean differential calculus theory <ref> [142, 165] </ref>. The theory has been applied in various areas of circuit design, including hazard and fault detection, Boolean function decomposition, and circuit synthesis [165]. The evaluation of arbitrary Boolean expressions is a new application of the classical Boolean differential calculus theory.
Reference: [143] <author> T. Shimomura and S. Isoda. </author> <title> Linked-list visualization for debugging. </title> <journal> IEEE Software, </journal> <volume> 8(3) </volume> <pages> 44-51, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: Because the display is updated incrementally, the director handles in principle arbitrarily large lists without any degradation in performance. Details on the construction of the director are described in Section 4.4. Other approaches to visualize data structures are described in <ref> [122, 143] </ref>. In [143], Shi-momura and Isoda found that users of their system could find program errors about 30% faster than by using regular debuggers without visualization. Although the capabilities 34 provided by introspective computer systems may seem similar to previous approaches, they are qualitatively different. <p> Because the display is updated incrementally, the director handles in principle arbitrarily large lists without any degradation in performance. Details on the construction of the director are described in Section 4.4. Other approaches to visualize data structures are described in [122, 143]. In <ref> [143] </ref>, Shi-momura and Isoda found that users of their system could find program errors about 30% faster than by using regular debuggers without visualization. Although the capabilities 34 provided by introspective computer systems may seem similar to previous approaches, they are qualitatively different.
Reference: [144] <author> H. A. Simon. </author> <title> The architecture of complexity. </title> <journal> Proceedings of the American Philosophical Society, </journal> <volume> 106(6) </volume> <pages> 467-482, </pages> <month> December </month> <year> 1962. </year>
Reference-contexts: This chapter discusses a framework for self-managing computers provided by introspective systems. The first part of the chapter describes hierarchical systems. Because complex artificial and natural systems are hierarchical, this is a good indication that hierarchical 141 organization is required for complex systems <ref> [144] </ref>. The second part describes a parallel introspective computer as a platform to build complex hierarchical computer systems. By being able to self-manage itself at the software level, an introspective computer provides an architecture for a software self-managing system. <p> Due to space constraints, the discussion presented is necessarily limited. 6.1 Hierarchical Systems A system that consists of a large number of interacting subsystems is called a complex system <ref> [144] </ref>. Hierarchical systems are composed of levels which introduce a partial order on subsystems. A general discussion on hierarchical systems can be found in [43, 128, 139]. Two types of hierarchies can be observed in complex systems, a structural hierarchy and a control hierarchy [8, 43, 139]. <p> In the study of complex natural systems, autonomy is becoming one of the major identifying properties of living organisms [109, 175]. Autonomous operation in complex systems is achieved through hierarchical organization, because higher hierarchical levels are freed from real-time constraints. Hierarchical systems have the time to evolve <ref> [144] </ref>. By learning, the system optimizes itself for the future. In doing this, higher levels automatize some activities by moving them to lower levels [127]. Because the processing power of each subsystem is limited, this provides a way to maintain the load in higher levels within bounds.
Reference: [145] <author> B. C. Smith. </author> <title> Reflection and semantics in a procedural language. </title> <type> Technical Report MIT-TR-272, </type> <institution> MIT Laboratory for Computer Science, </institution> <year> 1982. </year>
Reference-contexts: They are not designed to feed symbolic data back to themselves in real-time. 7 1.2.3 Meta-Level Architectures and Reflection Reflection and meta-level architectures, well-developed areas of artificial intelligence, deal with computer programs that manipulate their own representation including the interpreter on which they are running <ref> [45, 107, 145] </ref>. Smith [146] divides self-referential programs into four classes. <p> Smith developed the LISP-3 programming language <ref> [45, 145] </ref>. A LISP-3 program is interpreted on a metacircular interpreter which is also a LISP-3 program. The program can dynamically create another interpreter. This gives an illusion of an infinite tower of interpreters. Each interpreter has access to structures at the levels below.
Reference: [146] <author> B. C. Smith. </author> <title> Self-reference. </title> <editor> In S. Shapiro, editor, </editor> <booktitle> Encyclopedia of Artificial Intelligence. </booktitle> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1987. </year>
Reference-contexts: They are not designed to feed symbolic data back to themselves in real-time. 7 1.2.3 Meta-Level Architectures and Reflection Reflection and meta-level architectures, well-developed areas of artificial intelligence, deal with computer programs that manipulate their own representation including the interpreter on which they are running [45, 107, 145]. Smith <ref> [146] </ref> divides self-referential programs into four classes.
Reference: [147] <author> J. E. Smith and A. R. Plezkun. </author> <title> Implementing precise interrupts in pipelined processors. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 37(5) </volume> <pages> 562-573, </pages> <month> May </month> <year> 1988. </year>
Reference-contexts: Using this solution, the executor can proceed with the full speed regardless of the filter latency. The mechanism to reverse the effect of the last n instructions is the same mechanism that is required to provide precise interrupts in processors whose instructions execute 127 out of order <ref> [77, 147] </ref>. Precise interrupts enable the restoration of the processor state at the time of an interrupt. One way to provide precise interrupts is to maintain a history buffer. The history buffer stores the reverse operations to the last n instructions. <p> In computer architecture, techniques of reverse execution are used to provide precise interrupts <ref> [77, 147] </ref>. Because computer processes are in general not reversible, special history information must be recorded in order to be able to restore earlier states. Implementations of reverse execution fall into roughly two classes: hardware and software approaches. Hardware approaches impose little overhead on program execution. <p> The history cache can be efficiently implemented as well in systems with a memory cache. One of the methods for implementing precise interrupts in pipelined processors involves a history buffer <ref> [147] </ref>. The history buffer contains exactly the information needed 139 by the history cache, although over a much shorter time period. The history buffer imposes as little as 3% overhead on the performance of the processor. <p> Even if the history buffer is not implemented, the history might not impose any time overhead on the cache subsystem, since in many cache implementations the Read of a value from the cache can be done in parallel with the cache hit check <ref> [147] </ref>. Taking together the performance overhead on the processor and on the memory subsystem, the support for history should slow down the entire system at most 10% and probably less than 5% in practice. This overhead is insignificant in light of the powerful new features enabled by the process history.
Reference: [148] <author> J. M. Smith. </author> <title> Concurrent Execution of Mutually Exclusive Alternatives. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, Columbia University, </institution> <year> 1989. </year>
Reference-contexts: Often it is not known in advance which algorithm is the best for a particular 44 instance of the problem. Therefore, it seems plausible to apply to the same problem simultaneously several processes with different algorithms. The usual method to implement the competition of processes is called "fastest first" <ref> [148] </ref>. The main process creates several subprocesses that attempt to solve the problem with different algorithms. The main process then waits for the first solution from a subprocess. This solution is selected as a result. The computations in other subprocesses are cancelled.
Reference: [149] <author> J. L. A. van de Snepscheut. </author> <title> Trace Theory and VLSI Design. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1985. </year>
Reference-contexts: In denotational semantics, steps are functions and states are domains of these functions. This division prevents a uniform treatment of states and steps. Another approach to describe process behavior is communicating sequential processes (CSP) [70]. A similar formalism is trace theory <ref> [149] </ref>. In CSP, the primary objects of 161 study are processes and events. Events in CSP correspond to steps in our terminology. A process is described as a sequence of events. Although CSP is better suited for the purpose of monitoring than denotational semantics, it still has limitations.
Reference: [150] <author> R. Snodgrass. </author> <title> A relational approach to monitoring complex systems. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 6(2) </volume> <pages> 157-196, </pages> <month> May </month> <year> 1988. </year>
Reference-contexts: Therefore, the decision was made to use C. Each step is described by an event. The use of events in monitoring process behavior is common <ref> [15, 64, 66, 111, 120, 121, 150, 168] </ref>. Usually events provide only that subset of process behavior which is important for a particular application. For example, Hanson [64] provides the following events: variable referencing, statement execution, program interruption, function call and return, and execution time errors. <p> The inverse trace is a sequence of modifications that are inverse operations to trace. It consists of the address of the result and the old value at this address. The execution stream provides a solution to the problem mentioned by Snodgrass <ref> [150] </ref>: It might be desirable to have the monitor play a greater part in sensor specification (e.g., allow it to substitute sampling for tracing to lower the data-collection overhead) and sensor installation (e.g., allow it to install the sensors at execution time by using conventional breakpointing mechanisms). <p> Different degrees of correspondence between levels can be achieved. ... dsldobject (filename); dslink (filename,funcname); ... 92 Previous approaches to a high level description of program behavior include methods to compose low level events, special event description languages, and a direct generation of high level events <ref> [36, 38, 89, 96, 104, 125, 150, 168, 170] </ref>. Because the execution stream provides a complete executor's behavior and a director can use arbitrary programming constructs, an introspective computer system provides a more general method of dealing with program behavior than previous approaches.
Reference: [151] <author> R. Sosic. </author> <title> Living computer systems. </title> <note> In preparation. </note>
Reference-contexts: The study of general complex systems is called systems science. The tools of systems science will enable us to harness the increasing power of computers by constructing self-managing computers. It is not that complex systems should be viewed as machines, but machines should incorporate more properties of complex systems <ref> [151] </ref>. Comment. Mathematical, physics, and systems science paradigms of computer science mutually support each other. Each of them provides a set of tools and a mind-set of their believers that solve important aspects of computer science problems.
Reference: [152] <author> R. Sosic. </author> <title> Reverse execution using a history cache. </title> <note> Submitted for publication, </note> <institution> Dept. of Computer Science, University of Utah. </institution>
Reference-contexts: The section on controlling discusses techniques to solve this problem. Space to store history information is the main constraint in reverse execution. Without a significant compaction, the amount of history quickly becomes large. The section on reverse execution describes a history cache, a novel approach to history compaction <ref> [152] </ref>. 5.1 Overview This section surveys main architectural features of an introspective processor (see filter, a history buffer and interfaces for a history cache, execution stream and directives. The processor core emits the execution stream describing the processor's computational 114 behavior. The stream is processed by the filter.
Reference: [153] <author> R. Sosic. Dynascope: </author> <title> A tool for program directing. </title> <booktitle> In Proceedings of SIGPLAN'92 Conference on Programming Language Design and Implementation. ACM, </booktitle> <year> 1992. </year>
Reference-contexts: No need to grope, a real sand castle - Dynascope. The Dynascope programming environment is a software introspective system. It provides a framework and building blocks for easy construction of sophisticated directors <ref> [153] </ref>. Directors are programs that direct executors through Dynascope primitives. Executors are directed from outside.
Reference: [154] <author> R. Sosic and J. Gu. </author> <title> Efficient local search with conflict minimization: A case study of the n-queens problem. </title> <note> to appear in IEEE Transactions on Knowledge and Data Engineering. </note>
Reference-contexts: This enabled the statistics of very long traces with billions of executed instructions. Two programs were chosen to measure the performance of the history cache on real programs. The first program is a linear time algorithm to solve the N-queens problem <ref> [154, 155] </ref>. This program exhibits a random pattern of memory accesses with little computation at each access. The N-queens program represents a bad case for the performance of the history cache. The second program is a complex scientific simulation which is the artificial life simulation partially described in Section 3.3.2.
Reference: [155] <author> R. Sosic and J. Gu. </author> <title> 3,000,000 queens in less than one minute. </title> <journal> SIGART Bulletin, </journal> <volume> 2(2) </volume> <pages> 22-24, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: This enabled the statistics of very long traces with billions of executed instructions. Two programs were chosen to measure the performance of the history cache on real programs. The first program is a linear time algorithm to solve the N-queens problem <ref> [154, 155] </ref>. This program exhibits a random pattern of memory accesses with little computation at each access. The N-queens program represents a bad case for the performance of the history cache. The second program is a complex scientific simulation which is the artificial life simulation partially described in Section 3.3.2.
Reference: [156] <author> R. Sosic, J. Gu, and R. Johnson. </author> <title> The Unison algorithm: Fast evaluation of boolean expressions. </title> <note> Submitted for publication, </note> <institution> Dept. of Computer Science, University of Utah. </institution>
Reference-contexts: An alternative implementation supports interpreted filters. The functionality of these filters is easier to change dynamically by the director than the functionality of compiled filters. An algorithm to evaluate Boolean expressions in software, called the Unison algorithm, was developed to support fast interpreted filters <ref> [156] </ref>. The Unison algorithm is described in Section 4.6. 4.2.4 Reverse Execution Routines for reverse execution provide support to return the state of the executor to some state in the past. Routine dshistory switches the recording of the history on and off.
Reference: [157] <author> R. Sosic, J. Gu, and R. Johnson. </author> <title> A universal boolean evaluator. </title> <note> Submitted for publication, </note> <institution> Dept. of Computer Science, University of Utah. </institution>
Reference-contexts: The most basic operation of the filter is to evaluate Boolean expressions. The Unison algorithm described in Section 4.6 uses the total differential to evaluate Boolean expressions. The total differential can also be used as a basis to implement a Universal Boolean Element (UBE), a special purpose circuit <ref> [157] </ref>. The UBE can efficiently evaluate any Boolean function and has a compact hardware implementation. The UBE and some filter designs are described in this section. 5.2.1 Real-Time Monitoring Although Heisenberg's principle states that any physical phenomenon changes if observed, this principle can be partially avoided in computers.
Reference: [158] <author> R. Sosic and R. R. Johnson. </author> <title> Growing computations. </title> <note> Submitted for publication, </note> <institution> Dept. of Computer Science, University of Utah. </institution> <month> 187 </month>
Reference-contexts: The 152 actual shape of a growing computation depends on the topology of the underlying space. The shape is not predetermined, but it emerges during the execution. A detailed discussion of the properties of growing computations can be found in <ref> [158] </ref>. A brief summary of the most interesting conclusions is presented here. Self-reproduction of computational elements in growing computations allows for an exponential increase in computational power. Data can be communicated to an exponentially increasing number of processors without increasing the communication speed or communication distance.
Reference: [159] <author> R. Sosic, A. Sali, and D. Sali. </author> <title> Computing with proteins. </title> <type> Unpublished manuscript, </type> <institution> Dept. of Computer Science, University of Utah, </institution> <year> 1991. </year>
Reference-contexts: Living organisms have the properties of growing computations. They are capable of limited exponential growth, they provide a flexible framework, and they can partially modify their structure, as individuals and through evolution. In principle, the same technology used by living organisms could be used to implement growing computations <ref> [159] </ref>. A discussion on design issues of molecular computers is provided in [40, 84]. 6.4 Paradigms in Computer Science This section gives a general view on the role of complex systems in computer science.
Reference: [160] <author> L. Sterling and E. Shapiro. </author> <title> The Art of Prolog. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1986. </year>
Reference-contexts: It is used to return a part of the process state to its state in the past. Backtracking is fundamental in search and in logic programming <ref> [20, 160] </ref>. Because it is not known in advance which part of the process will be changed in the future, the entire relevant state is usually saved at each step of backtracking.
Reference: [161] <author> D. Stern. </author> <title> The First Relationship. </title> <publisher> Harvard University Press, </publisher> <address> Cambridge, MA, </address> <year> 1977. </year>
Reference-contexts: For example, anticipation enables humans to significantly decrease their reaction time <ref> [28, 161] </ref>. Anticipation of the future requires that the system operates to a large degree autonomously from the environment. In the study of complex natural systems, autonomy is becoming one of the major identifying properties of living organisms [109, 175].
Reference: [162] <author> W. R. Stevens. </author> <title> Unix Networking Programming. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1990. </year>
Reference-contexts: The communication between the executor and the director is performed through sockets, a standard interprocess communication feature in BSD Unix and Mach <ref> [13, 162] </ref>. If necessary, an equivalent interprocess communication method could be used instead. Because the executor and the director are two separate programs, they could execute on different computers. This feature has not been implemented, although it would be easy to add to the system.
Reference: [163] <author> T. G. Stockham, Jr. </author> <title> Some methods of graphical debugging. </title> <booktitle> In Proc. IBM Scientific Computing Symposium on Man-Machine Communication, </booktitle> <pages> pages 57-71, </pages> <year> 1965. </year>
Reference-contexts: In introspective computer systems, no modifications to the executor's code are required. 3.1.2 Visualizing Control Flow Besides data structures, another important source of information about program behavior is control flow. Although the importance of dynamic visualization of control flow was recognized and implemented in research environments long ago <ref> [163] </ref>, the visualization of control flow is still not commonly available in traditional programming environments. The utility of introspective systems is demonstrated by constructing a director that dynamically builds the control flow graph of the executor. The graph showing control flow is displayed in Figure 3.2.
Reference: [164] <author> T. Teitelbaum and T. Reps. </author> <title> The Cornell program synthesizer: A syntax directed programming environment. </title> <journal> Communications of the ACM, </journal> <volume> 24(9) </volume> <pages> 563-573, </pages> <month> Septem-ber </month> <year> 1981. </year>
Reference-contexts: This is especially the case with optimizing compilers [183]. A partial solution is to maintain a parse tree describing the abstract syntax of the program <ref> [164] </ref>. This parsing tree can provide a detailed link between source code and machine code. Unfortunately in common compiled languages, the parsing tree is thrown away after the compilation process is done. <p> The approach using the history buffer has the same underlying concept as a history cache explained in the next section. 5.4 Reverse Execution Reverse execution provides access to old states of an executing process. It is a well established concept in computer science used in program development and debugging <ref> [15, 50, 121, 126, 164, 168, 182] </ref>, in programming environments and human-computer interaction [11, 66, 99, 101, 180], in fault-tolerant computing [34, 51, 97, 98] and in speculative computation [57, 80]. In computer architecture, techniques of reverse execution are used to provide precise interrupts [77, 147].
Reference: [165] <author> A. Thayse and M. Davio. </author> <title> Boolean differential calculus and its application to switching theory. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 22 </volume> <pages> 409-420, </pages> <month> April </month> <year> 1973. </year>
Reference-contexts: In a practical application, the Unison algorithm performs with execution speed comparable to compiled evaluation while it retains the flexibility of an interpreted evaluation. 4.6.1 Total Differential The total differential is a part of the classical Boolean differential calculus theory <ref> [142, 165] </ref>. The theory has been applied in various areas of circuit design, including hazard and fault detection, Boolean function decomposition, and circuit synthesis [165]. The evaluation of arbitrary Boolean expressions is a new application of the classical Boolean differential calculus theory. <p> The theory has been applied in various areas of circuit design, including hazard and fault detection, Boolean function decomposition, and circuit synthesis <ref> [165] </ref>. The evaluation of arbitrary Boolean expressions is a new application of the classical Boolean differential calculus theory. A Boolean function is a mapping from one or more Boolean variables to a Boolean value. A Boolean operation denotes a binary Boolean function of two input variables. <p> The derivation of Equation 4.1 is presented in <ref> [165] </ref>. The symbols F x , F y , and F xy in Equation 4.1 are partial derivatives of F with respect to x, y, and xy. <p> The derivation of Equation 4.1 is presented in [165]. The symbols F x , F y , and F xy in Equation 4.1 are partial derivatives of F with respect to x, y, and xy. The partial derivative of F with respect to x is defined in <ref> [6, 165] </ref> as: F x = F (x; y; x = 1) F (x; y; x = 0): Function F x is obtained by an Exclusive-OR operation between two functions which are formed from F by setting x once to 0 and once to 1.
Reference: [166] <author> J.E. Thornton. </author> <title> Design of a Computer, the Control Data 6600. Scott, </title> <address> Foresman, Glenview, IL, </address> <year> 1970. </year>
Reference-contexts: Hardware monitors provide a flexible monitoring environment, but are used for special purposes. They are not integrated into the same environment as the monitored program. The CDC 6600 consists of central processors and peripheral processors <ref> [166] </ref>. Central and peripheral processors communicate through the common memory. Peripheral processors could be used to monitor the central processor [79]. No facility for describing the computational behavior of central processors is provided in CDC 6600.
Reference: [167] <author> T. Toffoli and N. Margolus. </author> <title> Cellular Automata Machines. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1987. </year>
Reference-contexts: Data can be communicated to an exponentially increasing number of processors without increasing the communication speed or communication distance. This is impossible to achieve in computational models that rely on a fixed computational structures, like cellular automata <ref> [167] </ref>. As new computational elements are added to an existing structure, the size of the computational structure with a flexible framework grows linearly in the number of elements. The increase in the size in a computational structure with a fixed framework is quadratic. <p> Cellular automata are replacing Turing machines <ref> [167] </ref>. In this paradigm, computers are composed of a large number of locally interacting simple processors. Real space and time are important. Physical placement of processes and processors is significant, because local communication is much cheaper than communication at distance.
Reference: [168] <author> A. P. Tolmach and A. W. Appel. </author> <title> Debugging standard ML without reverse engineering. </title> <booktitle> In Proc. ACM Lisp and Functional Programming Conference '90. ACM, </booktitle> <year> 1990. </year>
Reference-contexts: Therefore, the decision was made to use C. Each step is described by an event. The use of events in monitoring process behavior is common <ref> [15, 64, 66, 111, 120, 121, 150, 168] </ref>. Usually events provide only that subset of process behavior which is important for a particular application. For example, Hanson [64] provides the following events: variable referencing, statement execution, program interruption, function call and return, and execution time errors. <p> For example, Hanson [64] provides the following events: variable referencing, statement execution, program interruption, function call and return, and execution time errors. Events have been implemented in interpretive environments [64, 121], or by augmenting source code to emit events <ref> [24, 168] </ref>. Although the content of events used to monitor programs in high level programming languages is often at a high level [24, 64, 89, 121, 168], high level events are not the most appropriate choice for introspective computer systems. <p> Events have been implemented in interpretive environments [64, 121], or by augmenting source code to emit events [24, 168]. Although the content of events used to monitor programs in high level programming languages is often at a high level <ref> [24, 64, 89, 121, 168] </ref>, high level events are not the most appropriate choice for introspective computer systems. In many cases, high level events are not able to describe the complete computational behavior, because they are restricted to the most common monitoring operations. <p> Details are presented in Section 5.4. An important feature of this integrated support is that reverse execution is implemented at the hardware level. Reverse execution is therefore available for any program and it is not limited to a particular programming environment as in more traditional implementations <ref> [3, 99, 168, 180] </ref>. Sample measurements show that the execution of one million instructions produces around 30 Kbytes of history. A 50 MIPS 51 processor would generate 1.5 Mbytes of history per second. The history of 100 seconds of execution can be saved on 150 Mbytes of disk space. <p> Different degrees of correspondence between levels can be achieved. ... dsldobject (filename); dslink (filename,funcname); ... 92 Previous approaches to a high level description of program behavior include methods to compose low level events, special event description languages, and a direct generation of high level events <ref> [36, 38, 89, 96, 104, 125, 150, 168, 170] </ref>. Because the execution stream provides a complete executor's behavior and a director can use arbitrary programming constructs, an introspective computer system provides a more general method of dealing with program behavior than previous approaches. <p> The approach using the history buffer has the same underlying concept as a history cache explained in the next section. 5.4 Reverse Execution Reverse execution provides access to old states of an executing process. It is a well established concept in computer science used in program development and debugging <ref> [15, 50, 121, 126, 164, 168, 182] </ref>, in programming environments and human-computer interaction [11, 66, 99, 101, 180], in fault-tolerant computing [34, 51, 97, 98] and in speculative computation [57, 80]. In computer architecture, techniques of reverse execution are used to provide precise interrupts [77, 147].
Reference: [169] <author> J. J. P. Tsai, K.-Y. Fang, and H.-Y. Chen. </author> <title> A noninvasive architecture to monitor real-time distributed systems. </title> <journal> IEEE Computer, </journal> <volume> 23(3) </volume> <pages> 11-23, </pages> <month> March </month> <year> 1990. </year>
Reference-contexts: The overhead of generating high level events that describe the complete computational behavior by modifying program code is prohibitive. Introspective computer systems require events that are capable of describing the complete computational behavior without interfering with program execution. One solution that provides such events is real-time hardware monitors <ref> [105, 133, 138, 169] </ref>. Even these events can be incomplete, because hardware monitors might watch buses without access to the internal operation of the processor. Several false starts were attempted before the final solution was found. <p> The speed of the modified ALU depends on the system design and can not be determined without more detailed specifications. 5.2.4 Real-Time Filter The filter presented here executes fast evaluation of Boolean expressions as a basic operation. Its design is similar to the filter described in <ref> [169] </ref>. A more sophisticated design with a filter implemented as a microprogrammable processor is described in [138]. A block diagram describing the functionality of a generic filter is shown in Figure 5.8. An actual implementation can be an expanded or a restricted version of the generic filter.
Reference: [170] <author> J. J. P. Tsai, K.-Y. Fang, H.-Y. Chen, and Y.-D. Bi. </author> <title> A noninterference monitoring and replay mechanism for real-time software testing and debugging. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 16(8) </volume> <pages> 897-916, </pages> <month> August </month> <year> 1990. </year>
Reference-contexts: Different degrees of correspondence between levels can be achieved. ... dsldobject (filename); dslink (filename,funcname); ... 92 Previous approaches to a high level description of program behavior include methods to compose low level events, special event description languages, and a direct generation of high level events <ref> [36, 38, 89, 96, 104, 125, 150, 168, 170] </ref>. Because the execution stream provides a complete executor's behavior and a director can use arbitrary programming constructs, an introspective computer system provides a more general method of dealing with program behavior than previous approaches.
Reference: [171] <author> A. M. </author> <title> Turing. On computable numbers, with an application to the entschei-dungsproblem. </title> <journal> Proceedings of the London Mathematical Society, ser. </journal> <volume> 2, 42 </volume> <pages> 230-265, </pages> <year> 1937. </year>
Reference-contexts: In other words, a computer system capable of learning will never finish its task. It can always learn more and improve itself. The second result, closely related to Godel's work, is the "halting theorem" by Turing <ref> [73, 171] </ref>. This result shows that a Turing machine cannot predict whether an arbitrary Turing machine will halt or not.
Reference: [172] <author> L. </author> <title> Uhr. </title> <booktitle> Multi-Computer Architectures for Artificial Intelligence. </booktitle> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1987. </year>
Reference-contexts: The architecture of introspective processor can be easily extended, so that each processor controls more than one processor. This organization leads to a pyramidal hierarchy of the introspective computer (see Figure 6.4). Although numerous computers with a pyramidal organization of processors have been designed <ref> [172] </ref>, they differ significantly from the pyramidal construction of the introspective computer. In a traditional computer, 149 the method of communication between processors at the same level is the same as the method of communication between processors at different levels in the pyramid.
Reference: [173] <author> D. M. Ungar. </author> <title> The Design and Evaluation of a High Performance Smalltalk System. </title> <publisher> ACM Distinguished Dissertation. MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1987. </year>
Reference-contexts: A lack of efficient, real-time, methods for garbage collection restricts the use of garbage collection in industrial applications [7, 16]. A real-time garbage collection algorithm can be implemented in an introspective computer. 3.5.3.1 Copying Garbage Collection Garbage collection involves two processes: a mutator and a collector <ref> [14, 173] </ref>. The mutator allocates objects and performs operations on them. The collector returns un 56 accessible objects to free space. Copying garbage collectors use two spaces: FromSpace and ToSpace. At the beginning, FromSpace contains objects to be copied and ToSpace is empty.
Reference: [174] <author> P. Valery. </author> <title> Variety: </title> <booktitle> Second Series. </booktitle> <address> Hartcourt, </address> <publisher> Brace, </publisher> <address> New York, </address> <year> 1938. </year>
Reference-contexts: It means that our mind is composed of at least two parts: one part to make decisions and one part to carry them out. In Valery's own words <ref> [174] </ref>: "The working of our mind may be considered a series . . . of unconscious productions and of conscious interventions." A system with one thread of control cannot divide its thread of control between two tasks, the task the system is supposed to do and the task of controlling itself.
Reference: [175] <editor> F. J. Varela. </editor> <booktitle> Principles of Biological Autonomy. </booktitle> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <year> 1979. </year>
Reference-contexts: For example, anticipation enables humans to significantly decrease their reaction time [28, 161]. Anticipation of the future requires that the system operates to a large degree autonomously from the environment. In the study of complex natural systems, autonomy is becoming one of the major identifying properties of living organisms <ref> [109, 175] </ref>. Autonomous operation in complex systems is achieved through hierarchical organization, because higher hierarchical levels are freed from real-time constraints. Hierarchical systems have the time to evolve [144]. By learning, the system optimizes itself for the future.
Reference: [176] <author> J. von Neumann. </author> <title> Theory of Self-Reproducing Automata. </title> <publisher> University of Illinois Press, </publisher> <address> Urbana, IL, </address> <year> 1966. </year> <month> 188 </month>
Reference-contexts: Such use of computers requires close coupling between the computer and a human user. The first to foresee the use of computers as a tool for developing models, solutions, and simulations of complex problems was von Neumann <ref> [176] </ref>. The term conversational computing was introduced by Perlis in his Turing award lecture [130]. It denotes the process of interaction between the programmer and the program in which the program is constantly being developed and improved. <p> The fluid is filled with building blocks. These building blocks provide constituents of computational elements and form the basic structural level for growing computations. This is one of the representations suggested by von Neumann for kinematic automata <ref> [176] </ref>. Computational models, related to growing computations, are described in the next section. 6.3.1 Related Models Von Neumann studied computational structures, the organization of systems of computing elements as a basis for the design of effective computers [176]. He set foundations for kinematic automata, cellular automata, and self-reproducing automata. <p> This is one of the representations suggested by von Neumann for kinematic automata <ref> [176] </ref>. Computational models, related to growing computations, are described in the next section. 6.3.1 Related Models Von Neumann studied computational structures, the organization of systems of computing elements as a basis for the design of effective computers [176]. He set foundations for kinematic automata, cellular automata, and self-reproducing automata. Growing computations are a class of kinematic automata. The model of kinematic automata is concerned with kinematic and geometric properties of computational elements.
Reference: [177] <author> D. S. Warren. </author> <title> Memoing for logic programs. </title> <journal> Communications of the ACM, </journal> <volume> 35(3) </volume> <pages> 93-111, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: If the function is called again with the same parameters, the result can be returned immediately and further evaluation of the function is cancelled. Memoing is restricted to purely applicative functions. It is an important construct in machine learning [116] and logic programming <ref> [53, 177] </ref>. 40 Memoing has been implemented on a program to evaluate Fibonacci numbers. A straightforward recursive program to evaluate Fibonacci numbers is shown in Figure 3.5.
Reference: [178] <author> P. Wegner. </author> <title> Programming language semantics. </title> <editor> In R. Rustin, editor, </editor> <booktitle> Formal Semantics of Programming Languages, </booktitle> <pages> pages 149-248. </pages> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1972. </year>
Reference-contexts: The word interpreter is used in the thesis to denote a hardware processor or a software emulator, capable of executing instructions. A program executed by the interpreter is called a process. A process state consists of program instructions, program data, and the internal state of the interpreter <ref> [178] </ref>. The internal state of the interpreter includes the program counter and other registers accessible to the program. The computational behavior of a process is a combination of two sequences, the execution sequence and the computation sequence [178]. The execution sequence is the sequence of executed instructions. <p> consists of program instructions, program data, and the internal state of the interpreter <ref> [178] </ref>. The internal state of the interpreter includes the program counter and other registers accessible to the program. The computational behavior of a process is a combination of two sequences, the execution sequence and the computation sequence [178]. The execution sequence is the sequence of executed instructions. The computation sequence is a sequence of state snapshots taken after each executed instruction. Each executed instruction represents one step in program execution. A step is an atomic transition between two successive states. <p> APPENDIX A EXECUTION CALCULUS A.1 Introduction Execution calculus is a novel formal model developed to describe the computational behavior of a process. The computational behavior of a process is a combination of two sequences, the execution sequence and the computation sequence <ref> [178] </ref>. The execution sequence is the sequence of executed instructions. The computation sequence is the sequence of states taken after each executed instruction. Each executed instruction represents one step in the program execution. Execution calculus is able to express the execution sequence and the computation sequence in a uniform way. <p> As control, time in the calculus of events is supplied externally. For monitoring, process time must be generated in synchrony with process execution, since two different events might otherwise appear as one event. Operational semantics describes the program behavior by hypothetically running the program on an interpreter <ref> [178] </ref>. Operational semantics is concentrated on the behavior of programs in a high level language. Therefore, the program behavior is highly structured. This complicates a computer analysis of the behavior. Execution calculus was developed to provide a formal model of process behavior suitable for monitoring. <p> The interpreter can be a hardware processor or a software emulator. A program executed by the interpreter is called a process. A process state consists of program instructions, program data, and the internal state of the interpreter <ref> [178] </ref>. The internal state of the interpreter includes the program counter and other registers accessible to the program. At any given moment during the execution, a process is determined by its state. The execution of a program is a sequence of process states, called the computation sequence.
Reference: [179] <author> N. Wiener. </author> <title> Cybernetics or Control and Communication in the Animal and the Machine. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1948. </year>
Reference-contexts: This operation in 1972 is not yet done in man-made computers - metaprogramming is done outside the big solid-state computers by the human programmers, or more properly, the human metaprogrammers. Another approach to intelligent behavior that involves several communicating systems is cybernetics <ref> [12, 179] </ref>. Cybernetics is the study of communication and control. A basic concept of cybernetics is a feedback loop in which the description of the behavior of system A is communicated to system B. System B uses this description to control the future behavior of A.
Reference: [180] <author> P. R. Wilson and T. G. Moher. </author> <title> Demonic memory for process histories. </title> <booktitle> In Proceedings of SIGPLAN'89 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 330-343. </pages> <publisher> ACM, </publisher> <year> 1989. </year>
Reference-contexts: Details are presented in Section 5.4. An important feature of this integrated support is that reverse execution is implemented at the hardware level. Reverse execution is therefore available for any program and it is not limited to a particular programming environment as in more traditional implementations <ref> [3, 99, 168, 180] </ref>. Sample measurements show that the execution of one million instructions produces around 30 Kbytes of history. A 50 MIPS 51 processor would generate 1.5 Mbytes of history per second. The history of 100 seconds of execution can be saved on 150 Mbytes of disk space. <p> It is a well established concept in computer science used in program development and debugging [15, 50, 121, 126, 164, 168, 182], in programming environments and human-computer interaction <ref> [11, 66, 99, 101, 180] </ref>, in fault-tolerant computing [34, 51, 97, 98] and in speculative computation [57, 80]. In computer architecture, techniques of reverse execution are used to provide precise interrupts [77, 147]. <p> When the entire state of the process must be recreated, the search process must be repeated for each location. To improve efficiency, forward methods usually work at the granularity of one page instead of single locations. The search can be sped up by sophisticated data structures <ref> [57, 180] </ref>. The search of the history is avoided if a backward method is used to save the history. By saving old values instead of new values, the history essentially contains operations that are inverse to the process execution.
Reference: [181] <author> P. H. Winston and B. K. P. Horn. </author> <title> Lisp. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1984. </year>
Reference-contexts: Because (besides developing foundations) one objective was to build a working introspective system, a programming language for executors had to be selected. Three languages were main candidates: C, Lisp and Smalltalk <ref> [60, 86, 181] </ref>. The execution of 16 programs in Lisp and Smalltalk can be nicely decomposed into smaller steps. This property made them attractive, but a satisfactory way to incorporate garbage collection and a sophisticated run time environment in introspective systems was not found.
Reference: [182] <author> M. V. Zelkowitz. </author> <title> Reversible execution. </title> <journal> Communications of the ACM, </journal> <volume> 16(9):566, </volume> <month> September </month> <year> 1973. </year>
Reference-contexts: Because it supports reverse execution, an introspective computer can return any program to a state in the past regardless of the programming language or the programming environment. A common application of reverse execution is debugging <ref> [15, 50, 121, 182] </ref>. When a program exhibits incorrect behavior we often want to see previous states of the program execution to find the error. This can be easily provided using the history. <p> The approach using the history buffer has the same underlying concept as a history cache explained in the next section. 5.4 Reverse Execution Reverse execution provides access to old states of an executing process. It is a well established concept in computer science used in program development and debugging <ref> [15, 50, 121, 126, 164, 168, 182] </ref>, in programming environments and human-computer interaction [11, 66, 99, 101, 180], in fault-tolerant computing [34, 51, 97, 98] and in speculative computation [57, 80]. In computer architecture, techniques of reverse execution are used to provide precise interrupts [77, 147].
Reference: [183] <author> P. T. Zellweger. </author> <title> Interactive source-level debugging of optimized programs. </title> <type> Technical Report CSL-84-5, </type> <note> Xerox PARC, </note> <year> 1984. </year>
Reference-contexts: This section discusses debugging and conversational computing. 3.3.1 Debugging Introspective capabilities are useful in debugging. Using the mechanisms of introspection, a director that serves as a powerful debugger can be implemented. An extensive survey of the debugger's functionality is provided by Zellweger <ref> [183] </ref>. In an introspective system, the executor is the program being debugged and the director functions as a debugger. An introspective framework has several features that are useful in debugging: unobtrusive monitoring, reverse execution, and high level modifications of the executor's state. <p> Some constructs from the source code are impossible to detect, because they are not represented in machine code or they are mixed with other constructs. This is especially the case with optimizing compilers <ref> [183] </ref>. A partial solution is to maintain a parse tree describing the abstract syntax of the program [164]. This parsing tree can provide a detailed link between source code and machine code. Unfortunately in common compiled languages, the parsing tree is thrown away after the compilation process is done.
References-found: 183

