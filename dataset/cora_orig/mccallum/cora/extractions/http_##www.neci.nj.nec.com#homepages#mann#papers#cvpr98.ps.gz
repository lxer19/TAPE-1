URL: http://www.neci.nj.nec.com/homepages/mann/papers/cvpr98.ps.gz
Refering-URL: http://www.neci.nj.nec.com/homepages/mann/papers-available.html
Root-URL: http://www.neci.nj.nec.com
Title: Towards the Computational Perception of Action  
Author: Richard Mann Allan Jepson 
Address: 4 Independence Way, Princeton, NJ 08540 USA  Toronto, Toronto M5S-1A4 CANADA  
Affiliation: NEC Research Institute, Inc.,  Department of Computer Science, University of  
Abstract: Understanding observations of interacting objects requires one to reason about qualitative scene dynamics. For example, on observing a hand lifting a can, we may infer that an `active' hand is applying an upwards force (by grasping) to lift a `passive' can. In previous work [6] we presented a system that infers qualitative scene dynamics from the instantaneous motion of objects. However, since that analysis only considered single frames in isolation, there were often multiple interpretations for each frame. In this work we show how the dynamic information inferred at each frame can be integrated over time to reduce ambiguity. Our approach to integrating information is to extend our representation to describe objects by a set of properties or capabilities that are assumed to persist over time. Given this extended representation we find interpretations that require the smallest set(s) of properties over the whole image sequence. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Matthew Brand. </author> <title> Understanding manipulation in video. </title> <booktitle> In Proceedings, 2nd International Conference on Face and Gesture Recognition, </booktitle> <address> Killington, VT, </address> <year> 1996. </year>
Reference-contexts: Our approach to continuous sequence processing by choosing minimal sets of properties over time is similar to [8], except that instead of using qualitative physics, our system uses an explicit theory based Newtonian mechanics. Our approach to discontinuity detection is similar to that described in <ref> [1] </ref> except rather than detecting and classifying isolated frames containing discontinuities, we attempt to infer object properties over the entire sequence.
Reference: [2] <author> Matthew Brand and Nuria Oliver. </author> <title> Coupled hidden markov models for complex action recognition. </title> <booktitle> In CVPR96, </booktitle> <year> 1996. </year>
Reference-contexts: Unfortunately, these approaches have not used dynamic information. Instead, they have either relied on specific domain knowledge (such as traffic scenes [7]), or have used some form of recognition model based on either predefined templates [4] or hidden markov models <ref> [9, 2] </ref>. In constrast, we focus on the first two components above.
Reference: [3] <author> Allan D. Jepson and Jacob Feldman. </author> <title> A biased view of perceivers. </title> <editor> In David Knill and Whitman Richards, editors, </editor> <title> Perception as Bayesian Inference, pages 229235. </title> <publisher> Cambridge University Press, </publisher> <year> 1996. </year>
Reference-contexts: In particular, it should be possible to extend our sequence processing by looking at frames in the neighborhood of motion discontinuities to determine the category from amongst several possibilities (collisions, starts and stops). Such a set of motion categories is presented in <ref> [3] </ref>, however, these categories would have to be expanded to deal with polygons contacting in various ways.
Reference: [4] <author> Yasuo Kuniyoshi and Hirochika Inoue. </author> <title> Qualitative recognition of ongoing human action sequences. </title> <booktitle> In Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 16001609, </pages> <address> Chambery, France, </address> <month> August </month> <year> 1993. </year>
Reference-contexts: Unfortunately, these approaches have not used dynamic information. Instead, they have either relied on specific domain knowledge (such as traffic scenes [7]), or have used some form of recognition model based on either predefined templates <ref> [4] </ref> or hidden markov models [9, 2]. In constrast, we focus on the first two components above.
Reference: [5] <author> Richard Mann. </author> <title> Computational Perception of Scene Dynamics. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Toronto. </institution> <note> In preparation. </note>
Reference-contexts: This occurs, for example, when an object tips towards or away from a surface (see Figure 7). The full details of the implementation are described in <ref> [5] </ref>. A&gt;0 (b) V~=0 V~=0 A&lt;0 t that is accelerating from rest (starting). Stopping can usually be explained by sliding friction (a tangential force opposing the direction of motion), while starting requires the presence of a motor to generate a forward force.
Reference: [6] <author> Richard Mann, Allan Jepson, and Jeffrey Mark Siskind. </author> <title> The computational perception of scene dynamics. </title> <booktitle> Computer Vision and Image Understanding, </booktitle> <volume> 65(2), </volume> <month> February </month> <year> 1997. </year>
Reference-contexts: In constrast, we focus on the first two components above. In particular, we attempt to perform a bottom-up inference of physical descriptions of the actions depicted in image sequences in terms of the force-dynamic properties of objects. 2 Integrating information over time In earlier work <ref> [6] </ref> we presented a system that made inferences of scene dynamics based on the instantaneous motion taken at particular frames of an image sequence. Our approach is based on the analysis of the Newtonian mechanics of a simplified scene model. <p> Given this representation, we seek interpretations that require the smallest set (s) of properties over the whole sequence. As in <ref> [6] </ref>, we assign priorities to minimization of the various properties. <p> Note that, unlike the earlier system that performed the search on single frames, for each set of properties chosen, all valid frames of the sequence are tested. 3 Results We tested the system given tracking data from several sequences (cf <ref> [6] </ref>). Figure 4 shows the results for the coke sequence. Below each frame of the sequence we show the minimal set (s) of object properties (FLYERs, DRIVERs, ROTORs, and GRASPERs) sufficient to explain the instantaneous motion in that frame. <p> The problem is that while the displacement of the hand near frame 30 changes over time, the velocity is too small to reliably detect the direction of motion, so this frame is removed. 4 Discussion and Conclusions We have shown that to extend our previous system <ref> [6] </ref> to integrate information over time we need to: 1. Remove frames where the instantaneous motion is either discontinuous, or contains insufficient information to reliably identify the object properties. 2. Ascribe properties to objects and minimize these properties over the entire sequence.
Reference: [7] <author> H-H Nagel. </author> <title> From image sequences to conceptual descriptions. Image and Vision Computing, </title> <address> 6(2):5979, </address> <month> May </month> <year> 1988. </year>
Reference-contexts: Most previous work on motion understanding has focused on only the third problem, recognizing events from image sequences. Unfortunately, these approaches have not used dynamic information. Instead, they have either relied on specific domain knowledge (such as traffic scenes <ref> [7] </ref>), or have used some form of recognition model based on either predefined templates [4] or hidden markov models [9, 2]. In constrast, we focus on the first two components above.
Reference: [8] <author> Jeffrey Mark Siskind. </author> <title> Naive Physics, Event Perception, Lexical Semantics, and Language Acquisition. </title> <type> PhD thesis, </type> <institution> Massachusetts Institute of Technology, </institution> <address> Cambridge, MA, </address> <month> January </month> <year> 1992. </year>
Reference-contexts: Remove frames where the instantaneous motion is either discontinuous, or contains insufficient information to reliably identify the object properties. 2. Ascribe properties to objects and minimize these properties over the entire sequence. Our approach to continuous sequence processing by choosing minimal sets of properties over time is similar to <ref> [8] </ref>, except that instead of using qualitative physics, our system uses an explicit theory based Newtonian mechanics. Our approach to discontinuity detection is similar to that described in [1] except rather than detecting and classifying isolated frames containing discontinuities, we attempt to infer object properties over the entire sequence. <p> In particular, such structure should allow the representation of various internal states, intentions, and goals for the participant objects. Finally, as described in the Introduction, we need a way to translate the inferred force-dynamic descriptions into natural event categories. (See <ref> [8] </ref> for such a proposal based on recognizing specific sequences of force-dynamic descriptions.) In summary, while the results reported here are preliminary, they indicate that the integration of information over time can significantly reduce ambiguity in sequence interpretation.

References-found: 8

