URL: http://www.isi.edu/sims/papers/91-abs-ebl.ps
Refering-URL: http://www.isi.edu/~knoblock/
Root-URL: 
Email: minton@pluto.arc.nasa.gov etzioni@cs.washington.edu  
Title: Integrating Abstraction and Explanation-Based Learning in PRODIGY  
Author: Craig A. Knoblock Steven Minton Oren Etzioni 
Date: 1991  
Note: Proceedings of the Ninth National Conference on Artificial Intelligence, AAAI Press,  
Address: Pittsburgh, PA 15213 Mail Stop: 244-17 and Engineering, FR-35 cak@cs.cmu.edu Moffett Field, CA 94035 Seattle, WA 98195  Menlo Park, CA,  
Affiliation: Carnegie Mellon University Sterling Federal Systems University of Washington School of Computer Science NASA Ames Research Center Department of Computer Science  
Abstract: This paper describes the integration of abstraction and explanation-based learning (ebl) in the context of the prodigy system. prodigy's abstraction module creates a hierarchy of abstract problem spaces, so problem solving can proceed in a more directed fashion. The ebl module acquires search control knowledge by analyzing problem-solving traces. When the two modules are integrated, they tend to complement each other's capabilities, resulting in performance improvements that neither system can achieve independently. We present empirical results showing the effect of combining the two modules and describe the factors that influence the overall performance of the integrated system. 
Abstract-found: 1
Intro-found: 1
Reference: [ Bhatnagar and Mostow, 1990 ] <author> Neeraj Bhatnagar and Jack Mostow. </author> <title> Adaptive search by explanation-based learning of heuristic censors. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pages 895-901, </pages> <address> Boston, MA, </address> <year> 1990. </year>
Reference-contexts: recent work has explored the use of simplified or in 2 Minor syntactic variations on the problem space specification, required to integrate the two modules, degrade alpine's performance slightly relative to the results reported in [ Knoblock, 1990 ] . complete explanations to address the intractable the-ory problem in ebl <ref> [ Chien, 1989, Tadepalli, 1989, Bhatnagar and Mostow, 1990 ] </ref> . The most closely related work is by Unruh and Rosenbloom [ 1989 ] , who developed an automatic abstraction mechanism in soar.
Reference: [ Carbonell et al., 1991 ] <author> Jaime G. Carbonell, Craig A. Knoblock, and Steven Minton. </author> <title> PRODIGY: An integrated architecture for planning and learning. </title> <editor> In Kurt VanLehn, editor, </editor> <booktitle> Architectures for Intelligence, </booktitle> <pages> pages 241-278. </pages> <publisher> Lawrence Erlbaum, </publisher> <address> Hillsdale, NJ, </address> <year> 1991. </year>
Reference-contexts: In this paper, we study the integration of abstraction and explanation-based learning (ebl) in the context of the prodigy system <ref> [ Carbonell et al., 1991 ] </ref> . prodigy consists of a central planner, and a set of distinct modules for abstraction generation, explanation-based learning, static problem-space analysis, analogical reasoning, etc. prodigy's ebl module acquires search fl The first author was supported by an Air Force Laboratory Graduate Fellowship through the Human
Reference: [ Chien, 1989 ] <author> Steve A. Chien. </author> <title> Using and refining simplifications: Explanation-based learning of plans in intractable domains. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 590-595, </pages> <address> Detroit, MI, </address> <year> 1989. </year>
Reference-contexts: recent work has explored the use of simplified or in 2 Minor syntactic variations on the problem space specification, required to integrate the two modules, degrade alpine's performance slightly relative to the results reported in [ Knoblock, 1990 ] . complete explanations to address the intractable the-ory problem in ebl <ref> [ Chien, 1989, Tadepalli, 1989, Bhatnagar and Mostow, 1990 ] </ref> . The most closely related work is by Unruh and Rosenbloom [ 1989 ] , who developed an automatic abstraction mechanism in soar.
Reference: [ Etzioni, 1990 ] <author> Oren Etzioni. </author> <title> A Structural Theory of Explanation-Based Learning. </title> <type> PhD thesis, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <year> 1990. </year> <note> Available as Technical Report CMU-CS-90-185. </note>
Reference-contexts: Finally, we compare the sources of power used by the two mechanisms in order to describe why this synergistic effect occurs, and identify when we can expect the two modules to work well together. 1 prodigy also includes a problem space compiler, static <ref> [ Etzioni, 1990 ] </ref> , that carries out a similar, but more restricted, version of ebl's analysis. While we have not yet explored the integration of static and abstraction, we would expect the use of abstraction to similarly benefit static. <p> Because the cost of matching control rules learned from recursive explanations is exponential in the depth of the recursions encountered, and because such rules are recursion-depth specific, ebl is often ineffective when its explanations are recursive <ref> [ Etzioni, 1990 ] </ref> . Abstraction can help ebl overcome this "problem of recursive explanations" by partitioning a recursive problem space into a nonrecur-sive abstract space, and a lower-level recursive space. Thus, ebl will at least perform well at the abstract space.
Reference: [ Knoblock, 1990 ] <author> Craig A. Knoblock. </author> <title> Learning abstraction hierarchies for problem solving. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pages 923-928, </pages> <address> Boston, MA, </address> <year> 1990. </year>
Reference-contexts: As shown in the picture, the problem is to find a sequence of operators to move the three disks from the first peg to the third peg. Abstraction in PRODIGY prodigy's abstraction module, alpine, takes an initial problem-space specification and automatically generates a hierarchy of abstraction spaces <ref> [ Knoblock, 1990, Knoblock, 1991 ] </ref> . Each abstraction space in the hierarchy is formed by dropping conditions from the original problem space. An abstraction space is defined by a set of abstract operators and states. <p> More recent work has explored the use of simplified or in 2 Minor syntactic variations on the problem space specification, required to integrate the two modules, degrade alpine's performance slightly relative to the results reported in <ref> [ Knoblock, 1990 ] </ref> . complete explanations to address the intractable the-ory problem in ebl [ Chien, 1989, Tadepalli, 1989, Bhatnagar and Mostow, 1990 ] . The most closely related work is by Unruh and Rosenbloom [ 1989 ] , who developed an automatic abstraction mechanism in soar.
Reference: [ Knoblock, 1991 ] <author> Craig A. Knoblock. </author> <title> Automatically Generating Abstractions for Problem Solving. </title> <type> PhD thesis, </type> <institution> School of Computer Science, Carnegie Mel-lon University, </institution> <year> 1991. </year> <note> Available as Technical Report CMU-CS-91-120. </note>
Reference-contexts: As shown in the picture, the problem is to find a sequence of operators to move the three disks from the first peg to the third peg. Abstraction in PRODIGY prodigy's abstraction module, alpine, takes an initial problem-space specification and automatically generates a hierarchy of abstraction spaces <ref> [ Knoblock, 1990, Knoblock, 1991 ] </ref> . Each abstraction space in the hierarchy is formed by dropping conditions from the original problem space. An abstraction space is defined by a set of abstract operators and states. <p> The potential interactions define a set of constraints on the final abstraction hierarchy that are sufficient to guarantee the ordered monotonicity property. The detailed algorithm is described in <ref> [ Knoblock, 1991 ] </ref> . alpine automatically constructs an abstraction hierarchy for the Tower of Hanoi by partitioning the conditions for each of the three different-sized disks into three abstraction levels. <p> In such cases ebl will not be able to form useful control rules in the abstract problem space. The information necessary to explain the appropriate control choices is "hidden" by the abstraction. Since, alpine usually produces "good" abstractions in the problem spaces studied <ref> [ Knoblock, 1991 ] </ref> , this scenario is atypical. Nonetheless, to the extent that the planner does backtrack across abstraction levels, it can cause ebl to perform poorly (relative to its performance in the original space).
Reference: [ Minton, 1988 ] <author> Steven Minton. </author> <title> Learning Search Control Knowledge: An Explanation-Based Approach. </title> <publisher> Kluwer, </publisher> <address> Boston, MA, </address> <year> 1988. </year>
Reference-contexts: Explanation-Based Learning in PRODIGY prodigy's explanation-based learning module produces search control knowledge by analyzing the planner's experiences <ref> [ Minton, 1988 ] </ref> . After each planning episode, the ebl module examines the control choices that were made, as recorded in a trace produced by the planner. By explaining why a control choice was appropriate or inappropriate, the system can learn a general search control rule. <p> In contrast, the combination of the two approaches eliminates all search from the problem and produces optimal solutions. Results This section compares the performance of prodigy individually and in combination with the abstraction and ebl modules in a machine-shop scheduling domain <ref> [ Minton, 1988 ] </ref> . The various configurations were each run on one-hundred randomly-generated problems that were originally used for testing the ebl system.
Reference: [ Sacerdoti, 1974 ] <author> Earl D. Sacerdoti. </author> <title> Planning in a hierarchy of abstraction spaces. </title> <journal> Artificial Intelligence, </journal> <volume> 5(2) </volume> <pages> 115-135, </pages> <year> 1974. </year>
Reference: [ Segre et al., 1991 ] <author> Alberto Segre, Charles Elkan, and Alex Russell. </author> <title> A critical look at experimental evaluations of EBL. </title> <journal> Machine Learning, </journal> <volume> 6(2), </volume> <year> 1991. </year>
Reference-contexts: Comparing the results of the different configurations on the set of test problems is complicated by the fact that some of the problems cannot be solved within the 600 CPU second time limit. Since the choice of a time bound can affect the relative performance of the different configurations <ref> [ Segre et al., 1991 ] </ref> , Figure 3 shows the total time expended for each configuration as the time bound increases. The slope at each point in a given curve indicates the relative portion of the problems that remain unsolved.
Reference: [ Tadepalli, 1989 ] <author> Prasad Tadepalli. </author> <title> Lazy explanation-baserd learning: A solution to the intractable theory problem. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 694-700, </pages> <address> Detroit, MI, </address> <year> 1989. </year>
Reference-contexts: recent work has explored the use of simplified or in 2 Minor syntactic variations on the problem space specification, required to integrate the two modules, degrade alpine's performance slightly relative to the results reported in [ Knoblock, 1990 ] . complete explanations to address the intractable the-ory problem in ebl <ref> [ Chien, 1989, Tadepalli, 1989, Bhatnagar and Mostow, 1990 ] </ref> . The most closely related work is by Unruh and Rosenbloom [ 1989 ] , who developed an automatic abstraction mechanism in soar.
Reference: [ Unruh and Rosenbloom, 1989 ] <author> Amy Unruh and Paul S. Rosenbloom. </author> <title> Abstraction in problem solving and learning. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 681-687, </pages> <address> Detroit, MI, </address> <year> 1989. </year>
Reference: [ VanLehn, 1989 ] <author> Kurt VanLehn. </author> <title> Discovering problem solving strategies: What humans do and machines don't (yet). </title> <booktitle> In Proceedings of the Sixth International Workshop on Machine Learning, </booktitle> <pages> pages 215-217, </pages> <address> Ithaca, NY, </address> <year> 1989. </year>
References-found: 12

