URL: http://www.cs.brandeis.edu/~bukatin/draft.ps.gz
Refering-URL: http://www.cs.brandeis.edu/~bukatin/papers.html
Root-URL: http://www.cs.brandeis.edu
Email: bukatin@cs.brandeis.edu  
Title: Continuous Functions as Models for Programs: Mathematics and Applications  
Author: Michael Bukatin 
Address: Waltham, MA 02254, USA.  
Affiliation: Department of Computer Science, Brandeis University,  
Note: PhD Thesis Proposal. The list of references is not quite complete yet. Supported by NSF Grant CCR-9216185 and Office of Naval Research Grant ONR N00014-93-1-1015  
Date: April 15, 1996  
Abstract: We present evidence of continuous nature of many computational processes. We argue that, therefore, powerful techniques of continuous mathematics should be applicable in the studies of computational processes and, moreover, in the design of tools for software engineers. We see the potential for both theoretical and applied advances along these lines, and we would like to incorporate both into our Thesis. Ideally theoretical advances should lead at once to the new applications, however, given the state of the art it does not seem feasible. Therefore we opt for the research program consisting of two parts. Part 1 consists of advancing the mathematics of topological models of computation. It does take potential applications into account, but we do not expect to incorporate any such applications in this Thesis. The internal mathematical motivations will mostly guide the theoretical part. Part 2 consists of applying the existing body of knowledge to software engineering, and, in particular, to the design and implementation of programming languages. We have found that paradigms employed in the design of most modern "academic" programming languages seem to be incompatible with mathematical models of computations we prefer. Therefore, we will perform experimental explorations in the design and implementation of programming languages. We will take into account both their conformity to the desired mathematical properties and potential practical usability. We will restrict ourselves to small prototypes of the real systems, so we do not expect to incorporate any "commercially usable" systems in this Thesis. Preliminary results of the author are reviewed and the Appendices contain more technical details. The Conclusion contains the list of problems the Thesis will try to address. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Abadi and L. Cardelli. </author> <title> A theory of primitive objects: untyped and first-order systems. </title> <booktitle> In Proc. Theor. Aspects of Computer Software, </booktitle> <pages> pages 296-320. </pages> <publisher> Springer-Verlag LNCS 789, </publisher> <year> 1994. </year>
Reference-contexts: This means that the object-oriented programming is strictly more powerful than the current functional programming (the relationship between lambda calculus and Abadi-Cardelly object calculus confirms this <ref> [1] </ref>). Moreover, the notion of subtyping in Curry-Howard systems is extremely well suited to express the inheritance notion in object-oriented programming [11]. <p> While both addition and multiplication on interval numbers form commutative monoids, operations of taking the inverse work less well, and only a weak distributivity property holds. We concentrate here on an addition operation. Unary minus is a quasi-inverse operation: x + (x) v 0. E.g. <ref> [1; 2] </ref> + ([1; 2]) = [1; 2] + [2; 1] = [1; 1] v [0; 0]. Not only does this prevent us from literally transferring results from classical mathematics, it is not trivial to define interval unary minus just by looking at the interval plus. <p> We concentrate here on an addition operation. Unary minus is a quasi-inverse operation: x + (x) v 0. E.g. <ref> [1; 2] </ref> + ([1; 2]) = [1; 2] + [2; 1] = [1; 1] v [0; 0]. Not only does this prevent us from literally transferring results from classical mathematics, it is not trivial to define interval unary minus just by looking at the interval plus. <p> We concentrate here on an addition operation. Unary minus is a quasi-inverse operation: x + (x) v 0. E.g. [1; 2] + ([1; 2]) = [1; 2] + <ref> [2; 1] </ref> = [1; 1] v [0; 0]. Not only does this prevent us from literally transferring results from classical mathematics, it is not trivial to define interval unary minus just by looking at the interval plus. <p> We concentrate here on an addition operation. Unary minus is a quasi-inverse operation: x + (x) v 0. E.g. [1; 2] + ([1; 2]) = [1; 2] + [2; 1] = <ref> [1; 1] </ref> v [0; 0]. Not only does this prevent us from literally transferring results from classical mathematics, it is not trivial to define interval unary minus just by looking at the interval plus. Indeed, x + y v 0 iff intervals y and x have non-empty intersection.
Reference: [2] <author> Harold Abelson, Gerald Jay Sussman, and Julie Sussman. </author> <title> Structure and Interpretation of Computer Programs. </title> <publisher> Springer, </publisher> <year> 1991. </year>
Reference-contexts: Old meaning is that the texts of programs ("functions") are first-class objects one can handle program texts as ordinary data and apply interpreter (e.g. eval) to them when necessary. This is the meaning in LISP <ref> [2] </ref>. The ideal meaning is that mathematical functions associated with programs and mapping inputs to outputs are first-class objects one can treat them as ordinary data. <p> In both models we view computed functions as closures (we argue that this is true for substitution models either just look at the implementation of lazy computations under applicative order <ref> [2] </ref>), i.e. as delayed evaluations, not as new functions. On the other hand when a mathematician thinks about a function he means its graph, or, in fact, he has some simplified representation of the graph in mind. <p> The logical conclusion is that if we stay with the current paradigm we might as well switch to civilized versions of object-oriented programming; as it is now, too many of functional programs simulate something which is naturally expressible in the object programs (iteration, state, message passing etc. <ref> [2] </ref>). The inverse simulation is rare, and the object-oriented languages are probably augmentable with functional features with ease (it should be possible to accomplish a lot here just on the level of syntactic sugar). <p> While both addition and multiplication on interval numbers form commutative monoids, operations of taking the inverse work less well, and only a weak distributivity property holds. We concentrate here on an addition operation. Unary minus is a quasi-inverse operation: x + (x) v 0. E.g. <ref> [1; 2] </ref> + ([1; 2]) = [1; 2] + [2; 1] = [1; 1] v [0; 0]. Not only does this prevent us from literally transferring results from classical mathematics, it is not trivial to define interval unary minus just by looking at the interval plus. <p> We concentrate here on an addition operation. Unary minus is a quasi-inverse operation: x + (x) v 0. E.g. <ref> [1; 2] </ref> + ([1; 2]) = [1; 2] + [2; 1] = [1; 1] v [0; 0]. Not only does this prevent us from literally transferring results from classical mathematics, it is not trivial to define interval unary minus just by looking at the interval plus. <p> We concentrate here on an addition operation. Unary minus is a quasi-inverse operation: x + (x) v 0. E.g. [1; 2] + ([1; 2]) = [1; 2] + <ref> [2; 1] </ref> = [1; 1] v [0; 0]. Not only does this prevent us from literally transferring results from classical mathematics, it is not trivial to define interval unary minus just by looking at the interval plus.
Reference: [3] <author> S. Abramsky. </author> <title> Domain theory in logical form. </title> <journal> Annals of Pure and Applied Logic, </journal> <volume> 51 </volume> <pages> 1-77, </pages> <year> 1991. </year>
Reference-contexts: One was invented by Sazonov and Sviridenko [33] and involves infinitary logic. Another was invented by Hoofman [26] and further extended by the author [9] (see also Appendix 1). It involves non-reflexive logic. Also there are studies generalizing information systems to non-lattice structures, like SFP domains <ref> [3] </ref>. It is necessary to include finite disjunctions of elementary statements in the logical calculi for this purpose.
Reference: [4] <author> Samson Abramsky and Achim Jung. </author> <title> Domain theory. </title> <editor> In S. Abramsky, D. Gabbay, and T. S. E. Maibaum, editors, </editor> <booktitle> Handbook of Logic in Computer Science Volume 3, </booktitle> <pages> pages 1-168. </pages> <publisher> Oxford University Press, </publisher> <year> 1994. </year> <month> 22 </month>
Reference-contexts: one has to deal with noncontinuous functions, they have to be partially defined points of discontinuity cannot belong to their domain (although see [10]). 2.3 Continuity in denotational semantics of programming languages The most important and mathematically rich example of continuous approach to computation is denotational semantics (see, for example, <ref> [36, 35, 38, 40, 42, 4] </ref>). We briefly introduce its main ideas here. Denotational semantics of a formal language is a map S from the space of formal texts to the certain space of meanings (semantic space).
Reference: [5] <author> Errett Bishop and D. </author> <title> Bridges. Constructive Analysis. </title> <publisher> Springer-Verlag, </publisher> <year> 1985. </year>
Reference-contexts: We think that such approach to software design is potentially more promising than the concept of fully verified software. 2.2 Continuity in constructive mathematics Another evidence of continuity of computations comes from effective versions of mathematical analysis (constructive, recursive, or intuitionistic analysis - e.g. <ref> [5, 23] </ref>). All constructive functions from constructive real numbers to constructive real numbers must be continuous. It is impossible to properly treat computations at the points of discontinuity.
Reference: [6] <author> Anton Bohm. </author> <title> Dataflow Computations, volume 6 of CWI tract. </title> <publisher> Centrum voor Wiskunde en Informatica, </publisher> <address> Amsterdam, </address> <year> 1984. </year>
Reference-contexts: Dataflow architecture of the compiler design fits this ideal perfectly <ref> [6, 22] </ref>. Unfortunately, in the current state of the semantics of programming languages it is inevitable that the programmers will think about their programs operationally pretty frequently if not all the time. So let them think in terms of a dataflow implementation. <p> So far our advances in this direction are totally "ad hoc". If anyone who reads this is aware of a systematic approach to this problem, the author would greatly appreciate any leads. A limited version of dynamic data flow graphs is described in <ref> [6] </ref>. It has fixed targets and localized subgraphs (i.e. when a new subgraph is created, all vertices are new except for the target and source vertices), and this version is quite manageable.
Reference: [7] <author> Michael Bukatin. </author> <title> Information Systems and Retractions: an Elementary Treatment. </title> <note> Available via e-mail requests to bukatin@cs.brandeis.edu, De-cember 1994. </note>
Reference-contexts: This often leads to studies which are more difficult to understand and use than they would be if the information systems were utilized. The author's experience is that information systems help to obtain useful results as well <ref> [8, 7, 9] </ref> (see also subsection 7.1 and Appendix 1). One seemingly unexplored direction is to study information systems as programming languages they seem to be well suitable for distributed non-deterministic implementations. <p> We were able to give a new criterion of finitarity for retractions of Scott information systems urw ) 9v:urv; vrv; vrw, and to study the domains isomorphic to their sets of fixed points <ref> [7] </ref>. We also studied the domains of finitary projections and finitary retractions. We were able to explain the intuition behind R.Hoofman's construction [26] of continuous information systems [7, 9]. <p> We also studied the domains of finitary projections and finitary retractions. We were able to explain the intuition behind R.Hoofman's construction [26] of continuous information systems <ref> [7, 9] </ref>. We found that our results on subdo-mains and finitary retractions for classical information systems have very natural explanations from this point of view. We have also made steps to generalize Hoofman's approach to the case of complete lattices.
Reference: [8] <author> Michael Bukatin. </author> <title> Subdomains for Algebraic Information Systems. </title> <note> Available via e-mail requests to bukatin@cs.brandeis.edu, </note> <month> November </month> <year> 1994. </year>
Reference-contexts: This often leads to studies which are more difficult to understand and use than they would be if the information systems were utilized. The author's experience is that information systems help to obtain useful results as well <ref> [8, 7, 9] </ref> (see also subsection 7.1 and Appendix 1). One seemingly unexplored direction is to study information systems as programming languages they seem to be well suitable for distributed non-deterministic implementations. <p> So the author believes that if we fail to explore and exploit potential mathematical advantages of functional programming the switch to object-oriented programming is inevitable. 6.3 Requirements for type systems On pages 5 and 6 of <ref> [8] </ref> we explain why Curry-Howard type systems require the use of multiple representations for the same function f : A ! B in the denotational semantics. <p> Unfortunately, its expressive power is quite limited. 7 Overview of Preliminary Results 7.1 Information systems The author has a number of results on information systems (see Appendix 1). We were able to describe the notion of a subdomain for Scott information system <ref> [8] </ref>. A subdomain of a Scott domain jAj is simply a subset S of jAj, such that there is an information system B, such that S = jBj (it is essential that this is an equality and not an isomorphism). <p> So while quasi-inverse operations on domains attract our curiosity, it seems unlikely that their studies could contribute significantly to the development of analysis on domains. 3 The main theorem of <ref> [8] </ref> is the Theorem 3.1. The paper [8] contains a complicated inductive proof of this theorem the technique used most frequently in the theoretical computer science. <p> So while quasi-inverse operations on domains attract our curiosity, it seems unlikely that their studies could contribute significantly to the development of analysis on domains. 3 The main theorem of <ref> [8] </ref> is the Theorem 3.1. The paper [8] contains a complicated inductive proof of this theorem the technique used most frequently in the theoretical computer science.
Reference: [9] <author> Michael Bukatin. </author> <title> Information systems and complete lattices. </title> <booktitle> In 11th Summer Conference on General Topology and Applications. </booktitle> <month> August 10-13, </month> <year> 1995, </year> <institution> University of Southern Maine, Gorham, Maine. ABSTRACTS, </institution> <year> 1995. </year>
Reference-contexts: This often leads to studies which are more difficult to understand and use than they would be if the information systems were utilized. The author's experience is that information systems help to obtain useful results as well <ref> [8, 7, 9] </ref> (see also subsection 7.1 and Appendix 1). One seemingly unexplored direction is to study information systems as programming languages they seem to be well suitable for distributed non-deterministic implementations. <p> There are two approaches to generalize information systems so that they would yield continuous and complete lattices. One was invented by Sazonov and Sviridenko [33] and involves infinitary logic. Another was invented by Hoofman [26] and further extended by the author <ref> [9] </ref> (see also Appendix 1). It involves non-reflexive logic. Also there are studies generalizing information systems to non-lattice structures, like SFP domains [3]. It is necessary to include finite disjunctions of elementary statements in the logical calculi for this purpose. <p> We also studied the domains of finitary projections and finitary retractions. We were able to explain the intuition behind R.Hoofman's construction [26] of continuous information systems <ref> [7, 9] </ref>. We found that our results on subdo-mains and finitary retractions for classical information systems have very natural explanations from this point of view. We have also made steps to generalize Hoofman's approach to the case of complete lattices.
Reference: [10] <author> Ho Chun-Kuen. </author> <title> Beyond recursive real functions. </title> <journal> Information and Computation, </journal> <volume> 124 </volume> <pages> 113-126, </pages> <year> 1995. </year>
Reference-contexts: It is impossible to properly treat computations at the points of discontinuity. If one has to deal with noncontinuous functions, they have to be partially defined points of discontinuity cannot belong to their domain (although see <ref> [10] </ref>). 2.3 Continuity in denotational semantics of programming languages The most important and mathematically rich example of continuous approach to computation is denotational semantics (see, for example, [36, 35, 38, 40, 42, 4]). We briefly introduce its main ideas here.
Reference: [11] <author> Marshall Cline and Greg A. Lomow. C++ FAQs: </author> <title> Frequently Asked Questions. </title> <publisher> Addison-Wesley, </publisher> <year> 1994. </year>
Reference-contexts: This means that the object-oriented programming is strictly more powerful than the current functional programming (the relationship between lambda calculus and Abadi-Cardelly object calculus confirms this [1]). Moreover, the notion of subtyping in Curry-Howard systems is extremely well suited to express the inheritance notion in object-oriented programming <ref> [11] </ref>. The logical conclusion is that if we stay with the current paradigm we might as well switch to civilized versions of object-oriented programming; as it is now, too many of functional programs simulate something which is naturally expressible in the object programs (iteration, state, message passing etc. [2]). <p> On the other hand we would like to have only one piece of code for a polymorphic function, unless some very special optimization is desirable, not a separate piece of code for each possible use as in C++ templates <ref> [11] </ref>. The optimum is somewhere between Curry-Howard polymorphism and C++ templates, only it should be more powerful than the both of them. For example, we would like to be able to write ... function f (... type t ...) ... ... ...
Reference: [12] <author> William Clinger and Jonathan A. Rees. </author> <title> The revised 4 report on the algorithmic language scheme. </title> <journal> ACM LISP Pointers, </journal> <volume> 4(3), </volume> <year> 1991. </year>
Reference-contexts: So the switch to the current meaning happened (e.g. in ML [24]; Scheme combines both meanings but leans toward the new one, especially since the eval function was excluded from the canonical Scheme recently <ref> [12] </ref>). Current meaning is often said to be ideal at least this was one of the important goals of this switch. We here try to argue, that it in fact closer to the old meaning (despite the loss of certain flexibility, the old meaning allowed), than to the ideal one.
Reference: [13] <author> E. W. Dijkstra. </author> <title> A Discipline of Programming. </title> <publisher> Prentice-Hall, </publisher> <year> 1976. </year>
Reference-contexts: The school of formal verification of software maintains that in the future all important software will be precise and absolutely correct <ref> [13, 25] </ref>.
Reference: [14] <author> James Donahue and Alan Demers. </author> <title> Data type are values. </title> <type> Technical report, </type> <institution> Xerox Corporation, </institution> <year> 1984. </year>
Reference-contexts: The same can be said about types <ref> [39, 14] </ref>. It is mathematically attractive to be able to compute a type and then to use it to declare a variable. <p> Domain equations of denotational semantics should help us to provide meaning for type systems which conform to goals 6.3.3-6.3.5, as they helped to provide meaning for programming languages which allow functions to be run-time computable values. The approaches to goals 6.3.3-6.3.5 known to the author <ref> [39, 14] </ref> involve the idea of typing an untyping world in the style of Curry-Howard systems and, thus, multiple representations of functions in function spaces, which is something we are trying to avoid. 6.4 Dataflow and incrementality, or how declarative are declarative programming languages? The ideal of declarative (non-imperative) programming is
Reference: [15] <author> Abbas Edalat. </author> <title> Domain theory and integration. </title> <journal> Theoretical Computer Science, </journal> <volume> 151 </volume> <pages> 163-193, </pages> <year> 1995. </year>
Reference-contexts: Then we will be able to see what is expressible via such distances. The second of these developments is the connection between domains and the theory of measure and integration discovered by A.Edalat <ref> [15, 17] </ref>. The main emphasis of this development is so far on the applications of domains to the problems of computational measure theory (including fractals and integration), but some applications to computer science theory were developed as well (e.g. [16]). <p> This approach came from the author's desire to import as much of classical topological algebra into domains as possible. It turns out, however, that metric and measure structures need just ordered commutative monoids (essentially, some version of non-negative numbers) <ref> [29, 15] </ref>, while the ability to compute inverses and even to multiply seems not to be too important.
Reference: [16] <author> Abbas Edalat. </author> <title> Domain theory in learning processes. </title> <editor> In S. Brooks et al., editor, </editor> <booktitle> Mathematical Foundations of Programming Semantics, volume 1 of Electronic Notes in Theoretical Computer Science. </booktitle> <publisher> Elsevier, </publisher> <year> 1995. </year>
Reference-contexts: The main emphasis of this development is so far on the applications of domains to the problems of computational measure theory (including fractals and integration), but some applications to computer science theory were developed as well (e.g. <ref> [16] </ref>).
Reference: [17] <author> Abbas Edalat. </author> <title> Dynamical systems, measures and fractals via domain theory. </title> <journal> Information and Computation, </journal> <volume> 120(1) </volume> <pages> 32-48, </pages> <month> July </month> <year> 1995. </year>
Reference-contexts: Then we will be able to see what is expressible via such distances. The second of these developments is the connection between domains and the theory of measure and integration discovered by A.Edalat <ref> [15, 17] </ref>. The main emphasis of this development is so far on the applications of domains to the problems of computational measure theory (including fractals and integration), but some applications to computer science theory were developed as well (e.g. [16]).
Reference: [18] <author> Abbas Edalat and Michael B. Smyth. </author> <title> Categories of information systems. </title> <editor> In D. Pitt et al., editor, </editor> <booktitle> Category Theory and Computer Science, volume 530 of Lecture Notes in Computer Science, </booktitle> <pages> pages 37-52. </pages> <publisher> Springer-Verlag, </publisher> <year> 1991. </year>
Reference-contexts: It involves non-reflexive logic. Also there are studies generalizing information systems to non-lattice structures, like SFP domains [3]. It is necessary to include finite disjunctions of elementary statements in the logical calculi for this purpose. We should also mention the work of Edalat and Smyth <ref> [18, 19] </ref> on information categories. 5.2 Analysis The author is aware of two major developments in this direction, though in fairness we should say that analysis on domains is only making its first steps. 9 The first of such developments is generalized metrization.
Reference: [19] <author> Abbas Edalat and Michael B. Smyth. </author> <title> I-categories as a framework for solving domain equations. </title> <journal> Theoretical Computer Science, </journal> <volume> 115 </volume> <pages> 77-106, </pages> <year> 1993. </year> <month> 23 </month>
Reference-contexts: It involves non-reflexive logic. Also there are studies generalizing information systems to non-lattice structures, like SFP domains [3]. It is necessary to include finite disjunctions of elementary statements in the logical calculi for this purpose. We should also mention the work of Edalat and Smyth <ref> [18, 19] </ref> on information categories. 5.2 Analysis The author is aware of two major developments in this direction, though in fairness we should say that analysis on domains is only making its first steps. 9 The first of such developments is generalized metrization.
Reference: [20] <author> Bob Flagg and Ralph Kopperman. </author> <title> Fixed points and reflexive domain equa-tions in categories of continuity spaces. </title> <editor> In S. Brooks et al., editor, </editor> <booktitle> Mathematical Foundations of Programming Semantics, volume 1 of Electronic Notes in Theoretical Computer Science. </booktitle> <publisher> Elsevier, </publisher> <year> 1995. </year>
Reference-contexts: R.Kopperman explained how to obtain any topology via a generalized metric [28]. Then R.Flagg and R.Kopperman developed more intuitive generalized metrics for various classes of domains <ref> [29, 20] </ref>. A lot remains to be done along these lines. First, the purpose of generalized metrics is to make abstract topology easier, in particular, to make the notions of continuity and convergence more intuitive.
Reference: [21] <author> Jean-Yves Girard. </author> <title> Proofs and types, </title> <booktitle> volume 7 of Cambridge tracts in theoretical computer science. </booktitle> <publisher> Cambridge University Press, </publisher> <year> 1989. </year>
Reference-contexts: In the main text we always use the notion of formal approximation explicitly, and the unqualified term "approximation" means informal approximation. In appendices "approximation" means formal approximation. Also we use the term "Curry-Howard type systems" as a collective name for type systems which satisfy Curry-Howard isomorphism <ref> [21] </ref>. 4 2 Background on Continuity in Computations Here we present evidence of continuous nature of computations. 2.1 Continuity in software engineering It seems appropriate to start with a real life observation before dealing with mathematical models. <p> One might say that this difference is very scholastic how does one put it into scientifically expressed statements? Here we disagree with <ref> [21] </ref> webelieve that thinking in terms of function graphs is preferable to intensional thinking. The first alarming sign is when the denotational semantics and its formulas become too close to an implementation (I mean the "main" semantics, not the derivative ones specially produced to achieve the bridge with an implementation).
Reference: [22] <editor> Hugh Glazer, Chris Hankin, and David Till. </editor> <booktitle> Principles of Functional Programming. Prentice-Hall International, </booktitle> <year> 1984. </year>
Reference-contexts: Dataflow architecture of the compiler design fits this ideal perfectly <ref> [6, 22] </ref>. Unfortunately, in the current state of the semantics of programming languages it is inevitable that the programmers will think about their programs operationally pretty frequently if not all the time. So let them think in terms of a dataflow implementation.
Reference: [23] <author> R. L. Goodstein. </author> <title> Recursive Analysis. </title> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <year> 1961. </year>
Reference-contexts: We think that such approach to software design is potentially more promising than the concept of fully verified software. 2.2 Continuity in constructive mathematics Another evidence of continuity of computations comes from effective versions of mathematical analysis (constructive, recursive, or intuitionistic analysis - e.g. <ref> [5, 23] </ref>). All constructive functions from constructive real numbers to constructive real numbers must be continuous. It is impossible to properly treat computations at the points of discontinuity.
Reference: [24] <author> M. Gordon, R. Milner, and C. Wadsworth. </author> <title> Edinburgh LCF, </title> <booktitle> volume 78 of Lecture Notes in Computer Science. </booktitle> <publisher> Springer Verlag, </publisher> <year> 1979. </year>
Reference-contexts: The functional language community recognized the necessity to abstract from representations and the fact that the old meaning of functional programming is too representation-oriented. So the switch to the current meaning happened (e.g. in ML <ref> [24] </ref>; Scheme combines both meanings but leans toward the new one, especially since the eval function was excluded from the canonical Scheme recently [12]). Current meaning is often said to be ideal at least this was one of the important goals of this switch. <p> The author would like to treat polymorphic types and functions as having types as extra parameters, not as 14 something that works blindly for any type substituted instead of a type variable as in ML <ref> [24] </ref>. On the other hand we would like to have only one piece of code for a polymorphic function, unless some very special optimization is desirable, not a separate piece of code for each possible use as in C++ templates [11].
Reference: [25] <editor> David Gries. </editor> <booktitle> The Science of Programming. </booktitle> <publisher> Springer, </publisher> <address> New York, </address> <year> 1981. </year>
Reference-contexts: The school of formal verification of software maintains that in the future all important software will be precise and absolutely correct <ref> [13, 25] </ref>.
Reference: [26] <author> R. Hoofman. </author> <title> Continuous information systems. </title> <journal> Information and Computation, </journal> <volume> 105(1) </volume> <pages> 42-71, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: There are two approaches to generalize information systems so that they would yield continuous and complete lattices. One was invented by Sazonov and Sviridenko [33] and involves infinitary logic. Another was invented by Hoofman <ref> [26] </ref> and further extended by the author [9] (see also Appendix 1). It involves non-reflexive logic. Also there are studies generalizing information systems to non-lattice structures, like SFP domains [3]. It is necessary to include finite disjunctions of elementary statements in the logical calculi for this purpose. <p> We also studied the domains of finitary projections and finitary retractions. We were able to explain the intuition behind R.Hoofman's construction <ref> [26] </ref> of continuous information systems [7, 9]. We found that our results on subdo-mains and finitary retractions for classical information systems have very natural explanations from this point of view. We have also made steps to generalize Hoofman's approach to the case of complete lattices.
Reference: [27] <author> Paris C. Kanellakis, Harry G. Mairson, and John C. Mitchell. </author> <title> Unification and ML Type Reconstruction, </title> <address> pages 444-478. </address> <publisher> MIT Press, </publisher> <year> 1991. </year>
Reference-contexts: Let us now create a wish list of more practical and immediate nature for type systems (and we will see that unfortunately Curry-Howard systems do not satisfy this wish list even closely). 6.3.1 Effectiveness The exponential lower bound for ML type checking <ref> [27] </ref> and undecidability of type checking for system F [41] are hardly acceptable.
Reference: [28] <author> Ralph Kopperman. </author> <title> All topologies come from generalized metrics. </title> <journal> American Mathematical Monthly, </journal> <volume> 95 </volume> <pages> 89-97, </pages> <year> 1988. </year>
Reference-contexts: R.Kopperman explained how to obtain any topology via a generalized metric <ref> [28] </ref>. Then R.Flagg and R.Kopperman developed more intuitive generalized metrics for various classes of domains [29, 20]. A lot remains to be done along these lines. First, the purpose of generalized metrics is to make abstract topology easier, in particular, to make the notions of continuity and convergence more intuitive.
Reference: [29] <author> Ralph Kopperman and Bob Flagg. </author> <title> The asymmetric topology of computer science. </title> <editor> In S. Brooks et al., editor, </editor> <booktitle> Mathematical Foundations of Programming Semantics, volume 802 of Lecture Notes in Computer Science, </booktitle> <pages> pages 544-553. </pages> <publisher> Springer-Verlag, </publisher> <year> 1993. </year>
Reference-contexts: R.Kopperman explained how to obtain any topology via a generalized metric [28]. Then R.Flagg and R.Kopperman developed more intuitive generalized metrics for various classes of domains <ref> [29, 20] </ref>. A lot remains to be done along these lines. First, the purpose of generalized metrics is to make abstract topology easier, in particular, to make the notions of continuity and convergence more intuitive. <p> This approach came from the author's desire to import as much of classical topological algebra into domains as possible. It turns out, however, that metric and measure structures need just ordered commutative monoids (essentially, some version of non-negative numbers) <ref> [29, 15] </ref>, while the ability to compute inverses and even to multiply seems not to be too important.
Reference: [30] <author> K. G. Larsen and G. Winskel. </author> <title> Using information systems to solve recursive domain equations effectively. </title> <editor> In D. B. MacQueen G. Kahn and G. Plotkin, editors, </editor> <booktitle> Semantics of Data Types, </booktitle> <pages> pages 109-130, </pages> <address> Berlin, </address> <year> 1984. </year> <note> Springer-Verlag. Lecture Notes in Computer Science Vol. 173. </note>
Reference-contexts: We will try to remedy this situation somewhat and to explore desirable properties of programming languages. We will try to incorporate implementation issues and practical usability concerns into this part as well. 5 Mathematics of Domains Latest Develop ments and Problems 5.1 Information systems We believe that information systems <ref> [38, 30, 31] </ref> is the most important development in the domain theory since its inception in the late sixties and early seventies. This development allows us to use finite and understandable methods to study domains, lowers the level of abstraction, and provides necessary intuition.
Reference: [31] <author> Kim Guldstrand Larsen and Glynn Winskel. </author> <title> Using information systems to solve recursive domain equations. </title> <journal> Information and Computation, </journal> <volume> 91(2) </volume> <pages> 232-258, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: We will try to remedy this situation somewhat and to explore desirable properties of programming languages. We will try to incorporate implementation issues and practical usability concerns into this part as well. 5 Mathematics of Domains Latest Develop ments and Problems 5.1 Information systems We believe that information systems <ref> [38, 30, 31] </ref> is the most important development in the domain theory since its inception in the late sixties and early seventies. This development allows us to use finite and understandable methods to study domains, lowers the level of abstraction, and provides necessary intuition.
Reference: [32] <author> Julia L. Lawall and Harry G. Mairson. </author> <title> Optimality and Inefficiency: What Isn't a Cost Model of the Lambda Calculus? to appear, </title> <year> 1996. </year>
Reference-contexts: abstract from the less important details and not to find another way to describe what happens with every bit. 8.3.3 Computational complexity Is there a simple way to express computational complexity in the denotational framework? We would like to note that this question is similarly open for the lambda calculus <ref> [32] </ref>. There are at least two ways to deal with it in denotational 4 We do not object against the use of probabilistic powerdomains 20 semantics to include resource consumption counters in the semantics, or to explore the expressability of the complexity of inference in the informations systems.
Reference: [33] <author> Vladimir Sazonov and Dmitri Sviridenko. </author> <title> Abstract deducibility and domain theory. </title> <type> Technical report, </type> <institution> Rutgers University, </institution> <year> 1996. </year> <note> Expected to be published as DIMACS Technical Report in 1996. </note>
Reference-contexts: We will just talk about lattices below for simplicity of speech, but we will always mean that algebraic tops can be removed. There are two approaches to generalize information systems so that they would yield continuous and complete lattices. One was invented by Sazonov and Sviridenko <ref> [33] </ref> and involves infinitary logic. Another was invented by Hoofman [26] and further extended by the author [9] (see also Appendix 1). It involves non-reflexive logic. Also there are studies generalizing information systems to non-lattice structures, like SFP domains [3]. <p> We have also made steps to generalize Hoofman's approach to the case of complete lattices. Right now we are trying to describe relationships between this approach and Sazonov and Sviridenko's description of continuous and complete lattices via infinitary logic <ref> [33] </ref>. 7.2 Analysis We made very modest advances in the development of topological algebra for domains. Our approach was as follows. The difficulties in the development of algebra are well illustrated by interval numbers.
Reference: [34] <author> Martin Schechter. </author> <title> Principles of Functional Analysis. </title> <publisher> Academic Press, </publisher> <year> 1971. </year> <month> 24 </month>
Reference-contexts: Optimization methods in continuous mathematics require more than just topological structure. They require various structures of analysis which are usually built over ordinary metric topology (e.g. <ref> [34, 43] </ref>). Thus we need analysis over domain topology. Only the first steps of building analysis over domain topology were made. We will give their overview in the next section of this Proposal.
Reference: [35] <author> Dana Scott. </author> <title> Lattice theory, data types and semantics. </title> <editor> In Randall Rustin, editor, </editor> <booktitle> Formal Semantics of Algorithmic Languages, </booktitle> <pages> pages 65-106. </pages> <publisher> Prentice Hall, </publisher> <year> 1972. </year>
Reference-contexts: one has to deal with noncontinuous functions, they have to be partially defined points of discontinuity cannot belong to their domain (although see [10]). 2.3 Continuity in denotational semantics of programming languages The most important and mathematically rich example of continuous approach to computation is denotational semantics (see, for example, <ref> [36, 35, 38, 40, 42, 4] </ref>). We briefly introduce its main ideas here. Denotational semantics of a formal language is a map S from the space of formal texts to the certain space of meanings (semantic space).
Reference: [36] <author> Dana Scott and Christopher Strachey. </author> <title> Towards a mathematical semantics for computer languages. </title> <booktitle> In Proceedings, 21st Symposium on Computers and Automata, </booktitle> <pages> pages 19-46. </pages> <institution> Polytechnic Institute of Brooklyn, </institution> <year> 1971. </year> <note> Also, </note> <institution> Programming Research Group Technical Monograph PRG-6, Oxford University. </institution>
Reference-contexts: one has to deal with noncontinuous functions, they have to be partially defined points of discontinuity cannot belong to their domain (although see [10]). 2.3 Continuity in denotational semantics of programming languages The most important and mathematically rich example of continuous approach to computation is denotational semantics (see, for example, <ref> [36, 35, 38, 40, 42, 4] </ref>). We briefly introduce its main ideas here. Denotational semantics of a formal language is a map S from the space of formal texts to the certain space of meanings (semantic space).
Reference: [37] <author> Dana S. Scott. </author> <title> Continuous lattices. </title> <editor> In F. William Lawvere, editor, </editor> <booktitle> Toposes, Algebraic Geometry, and Logic, volume 274 of Lecture Notes in Computer Science, </booktitle> <pages> pages 97-136. </pages> <publisher> Springer-Verlag, </publisher> <address> Berlin, Heidelberg, and New York, </address> <year> 1972. </year>
Reference-contexts: Topological ideas gave the solution <ref> [37, 40] </ref>. Continuity in computations always relates closely to the idea of formal approximation. Interval numbers formally approximate one another, partially defined functions do the same, etc. The relation of formal approximation usually is a partial order, usually denoted as v.
Reference: [38] <author> Dana S. Scott. </author> <title> Domains for denotational semantics. </title> <editor> In M. Nielsen and E. M. Schmidt, editors, </editor> <booktitle> Automata, Languages and Programming, volume 140 of Lecture Notes in Computer Science, </booktitle> <pages> pages 577-613. </pages> <publisher> Springer-Verlag, </publisher> <year> 1982. </year>
Reference-contexts: one has to deal with noncontinuous functions, they have to be partially defined points of discontinuity cannot belong to their domain (although see [10]). 2.3 Continuity in denotational semantics of programming languages The most important and mathematically rich example of continuous approach to computation is denotational semantics (see, for example, <ref> [36, 35, 38, 40, 42, 4] </ref>). We briefly introduce its main ideas here. Denotational semantics of a formal language is a map S from the space of formal texts to the certain space of meanings (semantic space). <p> We will try to remedy this situation somewhat and to explore desirable properties of programming languages. We will try to incorporate implementation issues and practical usability concerns into this part as well. 5 Mathematics of Domains Latest Develop ments and Problems 5.1 Information systems We believe that information systems <ref> [38, 30, 31] </ref> is the most important development in the domain theory since its inception in the late sixties and early seventies. This development allows us to use finite and understandable methods to study domains, lowers the level of abstraction, and provides necessary intuition.
Reference: [39] <author> A. Shamir and W. W. Wadge. </author> <title> Data types as objects. </title> <booktitle> In Automata, Languages and Programming, volume 52 of Lecture Notes in Computer Science, </booktitle> <pages> pages 465-479. </pages> <publisher> Springer-Verlag, </publisher> <year> 1977. </year>
Reference-contexts: The same can be said about types <ref> [39, 14] </ref>. It is mathematically attractive to be able to compute a type and then to use it to declare a variable. <p> Domain equations of denotational semantics should help us to provide meaning for type systems which conform to goals 6.3.3-6.3.5, as they helped to provide meaning for programming languages which allow functions to be run-time computable values. The approaches to goals 6.3.3-6.3.5 known to the author <ref> [39, 14] </ref> involve the idea of typing an untyping world in the style of Curry-Howard systems and, thus, multiple representations of functions in function spaces, which is something we are trying to avoid. 6.4 Dataflow and incrementality, or how declarative are declarative programming languages? The ideal of declarative (non-imperative) programming is
Reference: [40] <author> J. E. Stoy. </author> <title> Denotational Semantics: The Scott-Strachey Approach to Programming Language Semantics. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1977. </year>
Reference-contexts: one has to deal with noncontinuous functions, they have to be partially defined points of discontinuity cannot belong to their domain (although see [10]). 2.3 Continuity in denotational semantics of programming languages The most important and mathematically rich example of continuous approach to computation is denotational semantics (see, for example, <ref> [36, 35, 38, 40, 42, 4] </ref>). We briefly introduce its main ideas here. Denotational semantics of a formal language is a map S from the space of formal texts to the certain space of meanings (semantic space). <p> Topological ideas gave the solution <ref> [37, 40] </ref>. Continuity in computations always relates closely to the idea of formal approximation. Interval numbers formally approximate one another, partially defined functions do the same, etc. The relation of formal approximation usually is a partial order, usually denoted as v.
Reference: [41] <author> Joe Wells. </author> <title> Typability and type checking in the second-order -calculus are equivalent and undecidable. </title> <booktitle> In Proceedings, Ninth Annual IEEE Symposium on Logic in Computer Science, </booktitle> <pages> pages 176-185, </pages> <address> Paris, France, July 4-6, 1994. </address> <publisher> The IEEE Computer Society Press. </publisher>
Reference-contexts: us now create a wish list of more practical and immediate nature for type systems (and we will see that unfortunately Curry-Howard systems do not satisfy this wish list even closely). 6.3.1 Effectiveness The exponential lower bound for ML type checking [27] and undecidability of type checking for system F <ref> [41] </ref> are hardly acceptable.
Reference: [42] <author> Glynn Winskel. </author> <title> The Formal Semantics of Programming Languages. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1993. </year>
Reference-contexts: one has to deal with noncontinuous functions, they have to be partially defined points of discontinuity cannot belong to their domain (although see [10]). 2.3 Continuity in denotational semantics of programming languages The most important and mathematically rich example of continuous approach to computation is denotational semantics (see, for example, <ref> [36, 35, 38, 40, 42, 4] </ref>). We briefly introduce its main ideas here. Denotational semantics of a formal language is a map S from the space of formal texts to the certain space of meanings (semantic space).

References-found: 42

