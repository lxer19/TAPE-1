URL: http://www.iscs.nus.sg/~plong/papers/distdrift.ps
Refering-URL: 
Root-URL: 
Title: On the Complexity of Learning from Drifting Distributions  
Author: Rakesh D. Barve Philip M. Long 
Address: P.O. Box 90129  27708 USA Singapore 119260, Republic of Singapore  
Affiliation: Department of Computer Science ISCS Department Duke University,  National University of Singapore Durham, North Carolina  
Abstract-found: 0
Intro-found: 1
Reference: [AB92] <author> Martin Anthony and Norman Biggs. </author> <title> Computational learning theory: an introduction, </title> <booktitle> volume 30 of Cambridge Tracts in Theoretical Computer Science. </booktitle> <publisher> Cambridge University Press, </publisher> <year> 1992. </year>
Reference-contexts: For examples of the VC-dimension, see <ref> [BEHW89, Nat91, AB92] </ref>. 2.2 Tools The following is a special case of Fubini's Theorem.
Reference: [ABS90] <author> M. Anthony, N. Biggs, and J. Shawe-Taylor. </author> <title> The learnability of formal concepts. </title> <booktitle> The 1990 Workshop on Computational Learning Theory, </booktitle> <pages> pages 246-257, </pages> <year> 1990. </year>
Reference-contexts: To prove the second inequality of Theorem 6, we will need the following lemma, written down in this form by Bartlett and Long [BL95], which is implicit in the work of Anthony, Biggs and Shawe-Taylor <ref> [ABS90] </ref>.
Reference: [ABSS93] <author> S. Arora, L. Babai, J. Stern, and Z. Sweedyk. </author> <title> The hardness of approximate optima in lattices, codes, and systems of linear equations. </title> <booktitle> Proceedings of the 34th Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 724-733, </pages> <year> 1993. </year>
Reference-contexts: The algorithms for agnostic learning analyzed in this paper work by minimizing disagreements with some of the most recent examples. For many simple concept classes, such as monomials [AL88] and halfspaces [HS92], this has been shown to be NP-hard, and even a nonapproximability result for the latter is known <ref> [ABSS93] </ref>.
Reference: [AL88] <author> D. Angluin and P.D. Laird. </author> <title> Learning from noisy examples. </title> <journal> Machine Learning, </journal> <volume> 2 </volume> <pages> 343-370, </pages> <year> 1988. </year>
Reference-contexts: The algorithms for agnostic learning analyzed in this paper work by minimizing disagreements with some of the most recent examples. For many simple concept classes, such as monomials <ref> [AL88] </ref> and halfspaces [HS92], this has been shown to be NP-hard, and even a nonapproximability result for the latter is known [ABSS93].
Reference: [AW95] <author> P. Auer and M. K. Warmuth. </author> <title> Tracking the best disjunction. </title> <booktitle> Proceedings of the 36th Annual Symposium on the Foundations of Computer Science, </booktitle> <year> 1995. </year>
Reference-contexts: Littlestone and Warmuth [LW94], Kuh, Petsche and Rivest [KPR90, KPR91], Blum and Chalisani 3 [BC92], Herbster and Warmuth [HW95], and Auer and Warmuth <ref> [AW95] </ref> also studied learning in a changing environment, but in frameworks substantially different from that considered here. The main new idea in our proof of the sufficient conditions is in where the assumption that the distributions are close to each other is applied.
Reference: [Bar92] <author> P.L. Bartlett. </author> <title> Learning with a slowly changing distribution. </title> <booktitle> The 1992 Workshop on Computational Learning Theory, </booktitle> <pages> pages 243-252, </pages> <year> 1992. </year>
Reference-contexts: However, results for one type of model often yield related results for the other. We will consider two models for prediction problems, both introduced by Bartlett <ref> [Bar92] </ref>. <p> In this paper, we show that if fl = O * 3 VCdim (F ) ln (1=*) ! then F is (*; fl)-agnostically learnable. This improves on the O (* 5 =(VCdim (F ) 2 ln (1=*))) bound that follows from the work of Bartlett <ref> [Bar92] </ref>, as pointed out by Bartlett and Helmbold in [BH95]. We also show that if F is (*; fl)-agnostically learnable, then fl = O (* 3 =VCdim (F )), matching our sufficient condition for each F to within a log factor. <p> Finally, we show that if fl = O (* 2 =(VCdim (F ) ln (1=*))), then F is (*; fl)-solidly learnable, improving on the O (* 3 =(VCdim (F ) 2 ln (1=*))) bound of Bartlett <ref> [Bar92] </ref>. Bartlett and Helmbold [BH95] have described an algorithm for learning in a drifting environment. <p> A relative strength of our solid learnability result is that their algorithm requires time that is in general exponential in VCdim (F ) whereas in many concrete cases, efficient algorithms for finding consistent hypotheses are known. For all classes F , both our result and theirs match Bartlett's <ref> [Bar92] </ref> fl = O (* 2 =VCdim (F )) necessary condition up to log factors. <p> Pollard [Pol84] calls this the symmetrization step. The "two-sample" probability is then bounded, making use of the resulting symmetry. Bartlett's <ref> [Bar92] </ref> analysis proceeded by showing that the product distribution on a suitably small sequence of the most recent examples was close to the product distribution where these examples were drawn from the "current" distribution. <p> V (D 1 ; D 2 ), is defined to be the largest difference in the probabilities that D 1 and D 2 assign to any event, i.e. by d T V (D 1 ; D 2 ) = sup jD 1 (U ) D 2 (U )j: Following Bartlett <ref> [Bar92] </ref>, we say a sequence D 1 ; D 2 ; ::: of probability distributions on Z is fl-admissible if for all t 2 N, d T V (D t ; D t+1 ) fl. For the remainder of this subsection, fix a countable 1 set X. <p> This model was studied by Bartlett <ref> [Bar92] </ref>. The sample complexity of agnostic learning from fixed distributions was first studied by Haussler [Hau92]. <p> Results for this model follow from the work of Bartlett <ref> [Bar92] </ref>.
Reference: [BBK96] <author> P.L. Bartlett, S. Ben-David, and S.R. Kulkarni. </author> <title> Learning changing concepts by exploiting the structure of change. </title> <booktitle> The 1995 Conference on Computational Learning Theory, </booktitle> <pages> pages 131-139, </pages> <year> 1996. </year>
Reference-contexts: A similar bound has been proved by Simon [Sim93], who appealed to the central limit theorem. Our bound has the advantage that it yields specific constants. In independent work, Bartlett, Ben-David and Kulkarni <ref> [BBK96] </ref> studied learning a drifting concept with a variety of constraints on the drift, including models which allowed large but infrequent changes in the target concept. In addition to prediction models like those studied here, they also studied estimating the entire trace of target concept positions.
Reference: [BBM89] <author> S. Ben-David, G. M. Benedek, and Y. Mansour. </author> <title> A parametrization scheme for classifying models of learnability. </title> <booktitle> In Proc. 2nd Annu. Workshop on Comput. Learning Theory, </booktitle> <pages> pages 285-302, </pages> <address> San Mateo, CA, 1989. </address> <publisher> Morgan Kaufmann. </publisher> <pages> 22 </pages>
Reference-contexts: It therefore is a flexible but clean way to capture gradual variation in a learner's environment. The second model we consider is the analogue of Ben-David, Benedek and Mansour's solid learn-ability <ref> [BBM89] </ref> with drifting distributions. In this model, there is a fixed function f 2 F that maps each x t to y t , but the distribution on the domain changes by at most fl between trials. <p> but significantly weaker assumptions, like those of Pol lard's [Pol84] Appendix C, are enough. 5 the following holds: t Y D i fhx i i t i=1 ))(x t ) 6= f (x t )g *: This is a natural extension of the definition discussed by Ben-David, Benedek and Mansour <ref> [BBM89] </ref>, which itself extended the PAC model [Val84]. Results for this model follow from the work of Bartlett [Bar92].
Reference: [BC92] <author> A. Blum and P. Chalasani. </author> <title> Learning switching concepts. </title> <booktitle> Proceedings of the Fifth Annual Workshop on Computational Learning Theory, </booktitle> <pages> pages pages 231-242, </pages> <year> 1992. </year>
Reference-contexts: For all classes F , both our result and theirs match Bartlett's [Bar92] fl = O (* 2 =VCdim (F )) necessary condition up to log factors. Littlestone and Warmuth [LW94], Kuh, Petsche and Rivest [KPR90, KPR91], Blum and Chalisani 3 <ref> [BC92] </ref>, Herbster and Warmuth [HW95], and Auer and Warmuth [AW95] also studied learning in a changing environment, but in frameworks substantially different from that considered here.
Reference: [BEHW89] <author> A. Blumer, A. Ehrenfeucht, D. Haussler, and M.K. Warmuth. </author> <title> Learnability and the Vapnik-Chervonenkis dimension. </title> <journal> JACM, </journal> <volume> 36(4) </volume> <pages> 929-965, </pages> <year> 1989. </year>
Reference-contexts: The proofs use Blumer, Ehrenfeucht, Haussler and Warmuth's idea of learning by estimating the error of all the hypotheses in the class from a single sample <ref> [BEHW89] </ref>. To bound how hard this is in our setting, we follow the outline of the proof of Vapnik and Chervonenkis [VC71]. <p> For examples of the VC-dimension, see <ref> [BEHW89, Nat91, AB92] </ref>. 2.2 Tools The following is a special case of Fubini's Theorem. <p> We will make use of the following version of Sauer's lemma [Sau72], due to Blumer, Ehrenfeucht, Haussler and Warmuth <ref> [BEHW89] </ref>. Lemma 8 ([Sau72, BEHW89]) Choose a finite set Z, and a set F of functions from Z to f0; 1g. Let d = VCdim (F ). Then jF j (ejZj=d) d : Now we are ready for the second part of the proof. <p> Now we are ready for the second part of the proof. This closely follows the corresponding part of the proof of the main result of <ref> [BEHW89] </ref>. 12 Lemma 13 Choose a countable set Z, and a set G of functions from Z to f0; 1g. Let d = VCdim (G). Choose &gt; 0. Choose m 2 N. Choose distributions D 1 ; :::; D m on Z. <p> Applying the fact ln 2 2=3 completes the proof. Now we are ready for the proofs of the sufficient conditions of learning in a drifting environ ment. These proofs borrow ideas from the work of Blumer, Ehrenfeucht, Haussler and Warmuth <ref> [BEHW89] </ref> and Haussler [Hau92]. Proof of Theorem 3: Since jF j 2, VCdim (F ) 1. Let m = b*=(16fl)c. Consider the algorithm A which, at each trial t &gt; m returns a hypothesis h 2 F that minimizes disagreements with the last m examples. <p> Clearly, VCdim (` F ) VCdim (F ) (see <ref> [BEHW89] </ref>). Fix a trial t &gt; m. Denote the (random) hypothesis output by A on the tth trial by h.
Reference: [BH95] <author> P.L. Bartlett and D.P. Helmbold, </author> <year> 1995. </year> <type> Manuscript. </type>
Reference-contexts: This improves on the O (* 5 =(VCdim (F ) 2 ln (1=*))) bound that follows from the work of Bartlett [Bar92], as pointed out by Bartlett and Helmbold in <ref> [BH95] </ref>. We also show that if F is (*; fl)-agnostically learnable, then fl = O (* 3 =VCdim (F )), matching our sufficient condition for each F to within a log factor. <p> Finally, we show that if fl = O (* 2 =(VCdim (F ) ln (1=*))), then F is (*; fl)-solidly learnable, improving on the O (* 3 =(VCdim (F ) 2 ln (1=*))) bound of Bartlett [Bar92]. Bartlett and Helmbold <ref> [BH95] </ref> have described an algorithm for learning in a drifting environment. <p> Helmbold and Long [HL94] and Bartlett and Helmbold <ref> [BH95] </ref> studied modifications of the one-inclusion graph strategy [HLW94]. In our analysis, we apply the fact that the distributions are moving slowly in the symmetrization step.
Reference: [BL95] <author> P. L. Bartlett and P. M. </author> <title> Long. Prediction, learning, uniform convergence, and scale-sensitive dimensions, </title> <note> 1995. Submitted. </note>
Reference-contexts: To prove the second inequality of Theorem 6, we will need the following lemma, written down in this form by Bartlett and Long <ref> [BL95] </ref>, which is implicit in the work of Anthony, Biggs and Shawe-Taylor [ABS90].
Reference: [Daw84] <author> A. Dawid. </author> <title> Statistical theory: The prequential approach. </title> <journal> Journal of the Royal Statistical Society (Series A), </journal> <pages> pages 278-292, </pages> <year> 1984. </year>
Reference-contexts: 1 Introduction In prediction models <ref> [Daw84, HLW94] </ref> like that studied in this paper, learning proceeds in trials, where in the tth trial, the algorithm (1) is given x t chosen from some set X, (2) is required to output a prediction ^y t 2 f0; 1g, and (3) discovers y t 2 f0; 1g.
Reference: [DH73] <author> R. O. Duda and P. E. Hart. </author> <title> Pattern Classification and Scene Analysis. </title> <publisher> Wiley, </publisher> <year> 1973. </year>
Reference-contexts: Then A is an optimal online algorithm. That is, if the sequence of probability distributions is chosen randomly as described above, any other online algorithm will have probability of mistake at least that of A. Proof: As is well known (see <ref> [DH73] </ref>), the optimal algorithm is obtained by choosing the hypothesis to minimize the a posteriori probability of making a mistake.
Reference: [EHKV89] <author> A. Ehrenfeucht, D. Haussler, M. Kearns, and L.G. Valiant. </author> <title> A general lower bound on the number of examples needed for learning. </title> <journal> Information and Computation, </journal> <volume> 82(3) </volume> <pages> 247-251, </pages> <year> 1989. </year>
Reference-contexts: For our proof of the necessary condition, we make use of techniques due to Simon [Sim93], Ehren-feucht, Haussler, Kearns and Valiant <ref> [EHKV89] </ref> and Helmbold and Long [HL94]. The main new idea required to prove this paper's result was how to drift efficiently from a joint distribution with no information to a hard joint distribution of the type useful in arguments of the type of Simon. <p> For each class F , if d is the VC-dimension of F , we show that F is not agnostically (*; fl)-learnable if fl = 1100000* 3 d . Our proof uses ideas of Ehrenfeucht, Haussler, Kearns and Valiant <ref> [EHKV89] </ref>, Helmbold and Long [HL94], and Simon [Sim93]. At a high level, it proceeds as follows. For some trial t, we will choose a sequence of drifting distributions that drifts only during the last m trials. <p> Now we apply the trick of Ehrenfeucht, Haussler, Kearns and Valiant <ref> [EHKV89] </ref>.
Reference: [FM97] <author> Y. Freund and Y. Mansour. </author> <title> Learning under persistent drift. </title> <booktitle> Proceedings of the 1997 European Conference on Computational Learning Theory, </booktitle> <year> 1997. </year>
Reference-contexts: In addition to prediction models like those studied here, they also studied estimating the entire trace of target concept positions. Recently, Freund and Mansour <ref> [FM97] </ref> studied a model of learning in which, instead of assuming that the position of the state of the environment is approximately constant (i.e. that drift is slow), they assume that the rate and direction of change is approximately constant (i.e. that drift is "persistent"). 4 2 Preliminaries 2.1 Definitions Denote
Reference: [Hau92] <author> D. Haussler. </author> <title> Decision theoretic generalizations of the PAC model for neural net and other learning applications. </title> <journal> Inform. Comput., </journal> <volume> 100(1) </volume> <pages> 78-150, </pages> <year> 1992. </year>
Reference-contexts: This model was studied by Bartlett [Bar92]. The sample complexity of agnostic learning from fixed distributions was first studied by Haussler <ref> [Hau92] </ref>. <p> Applying the fact ln 2 2=3 completes the proof. Now we are ready for the proofs of the sufficient conditions of learning in a drifting environ ment. These proofs borrow ideas from the work of Blumer, Ehrenfeucht, Haussler and Warmuth [BEHW89] and Haussler <ref> [Hau92] </ref>. Proof of Theorem 3: Since jF j 2, VCdim (F ) 1. Let m = b*=(16fl)c. Consider the algorithm A which, at each trial t &gt; m returns a hypothesis h 2 F that minimizes disagreements with the last m examples. <p> Then algorithm A returns a hypothesis on trial t minimizing P t1 Let ` F = f` f : f 2 F g. It is known (see <ref> [Hau92] </ref>) that VCdim (` F ) VCdim (F ). Choose a fl-admissible sequence P 1 ; P 2 ; ::: of probability distributions, f 2 F and a trial t &gt; m. Denote the (random) hypothesis output by A on the tth trial by h.
Reference: [HL91] <author> D.P. </author> <title> Helmbold and P.M. Long. Tracking drifting concepts using random examples. </title> <booktitle> The 1991 Workshop on Computational Learning Theory, </booktitle> <pages> pages 13-23, </pages> <year> 1991. </year>
Reference-contexts: Bartlett's [Bar92] analysis proceeded by showing that the product distribution on a suitably small sequence of the most recent examples was close to the product distribution where these examples were drawn from the "current" distribution. Helmbold and Long <ref> [HL91] </ref>, who studied learning drifting concepts from a fixed distribution, applied the fact that the functions were slowly changing in the two-sample step.
Reference: [HL94] <author> D.P. </author> <title> Helmbold and P.M. Long. Tracking drifting concepts by minimizing disagreements. </title> <journal> Machine Learning, </journal> <volume> 14(1) </volume> <pages> 27-46, </pages> <year> 1994. </year>
Reference-contexts: Helmbold and Long [HL91], who studied learning drifting concepts from a fixed distribution, applied the fact that the functions were slowly changing in the two-sample step. In their journal version <ref> [HL94] </ref>, they presented an analysis using the fact that, again for a small sequence of the most recent examples, what the learner saw was likely to be close to what it would have seen had the target not been moving. Helmbold and Long [HL94] and Bartlett and Helmbold [BH95] studied modifications <p> In their journal version <ref> [HL94] </ref>, they presented an analysis using the fact that, again for a small sequence of the most recent examples, what the learner saw was likely to be close to what it would have seen had the target not been moving. Helmbold and Long [HL94] and Bartlett and Helmbold [BH95] studied modifications of the one-inclusion graph strategy [HLW94]. In our analysis, we apply the fact that the distributions are moving slowly in the symmetrization step. <p> For our proof of the necessary condition, we make use of techniques due to Simon [Sim93], Ehren-feucht, Haussler, Kearns and Valiant [EHKV89] and Helmbold and Long <ref> [HL94] </ref>. The main new idea required to prove this paper's result was how to drift efficiently from a joint distribution with no information to a hard joint distribution of the type useful in arguments of the type of Simon. <p> For each class F , if d is the VC-dimension of F , we show that F is not agnostically (*; fl)-learnable if fl = 1100000* 3 d . Our proof uses ideas of Ehrenfeucht, Haussler, Kearns and Valiant [EHKV89], Helmbold and Long <ref> [HL94] </ref>, and Simon [Sim93]. At a high level, it proceeds as follows. For some trial t, we will choose a sequence of drifting distributions that drifts only during the last m trials. <p> For many simple concept classes, such as monomials [AL88] and halfspaces [HS92], this has been shown to be NP-hard, and even a nonapproximability result for the latter is known [ABSS93]. Helmbold and Long <ref> [HL94] </ref> showed that approximation algorithms for minimizing disagreements could be applied for "noise-free" learning of drifting concepts, but their techniques do not apparently 21 extend to the agnostic case, at least not to bound the difference between the learner's error and that of the best function in F , as in
Reference: [HLW94] <author> D. Haussler, N. Littlestone, and M. K. Warmuth. </author> <title> Predicting f0; 1g-functions on randomly drawn points. </title> <journal> Information and Computation, </journal> <volume> 115(2) </volume> <pages> 129-161, </pages> <year> 1994. </year>
Reference-contexts: 1 Introduction In prediction models <ref> [Daw84, HLW94] </ref> like that studied in this paper, learning proceeds in trials, where in the tth trial, the algorithm (1) is given x t chosen from some set X, (2) is required to output a prediction ^y t 2 f0; 1g, and (3) discovers y t 2 f0; 1g. <p> Helmbold and Long [HL94] and Bartlett and Helmbold [BH95] studied modifications of the one-inclusion graph strategy <ref> [HLW94] </ref>. In our analysis, we apply the fact that the distributions are moving slowly in the symmetrization step. <p> Choose a fl-admissible sequence P 1 ; P 2 ; ::: of probability distributions, f 2 F and a trial t &gt; m. Denote the (random) hypothesis output by A on the tth trial by h. Applying Lemma 1 as in <ref> [HLW94] </ref>, @ i=tm 1 Z (Xfif0;1g) m P t f (x t ; y t ) : h (x t ) 6= y t g d ( i=tm 14 Since t1 X ` h (x i ; y i ) i=tm if then either fi fi fi fi 1 t1 X <p> It also seems possible that the lower bound of Haussler, Littlestone and Warmuth <ref> [HLW94] </ref> for solid learning in a fixed environment can be adapted to show that the bound given here for solid learning in a drifting environment cannot be improved in general by more than a constant factor.
Reference: [HS92] <author> K. Hoffgen and H. Simon. </author> <title> Robust trainability of single neurons. </title> <booktitle> The 1992 Workshop on Computational Learning Theory, </booktitle> <pages> pages 428-439, </pages> <year> 1992. </year>
Reference-contexts: The algorithms for agnostic learning analyzed in this paper work by minimizing disagreements with some of the most recent examples. For many simple concept classes, such as monomials [AL88] and halfspaces <ref> [HS92] </ref>, this has been shown to be NP-hard, and even a nonapproximability result for the latter is known [ABSS93].
Reference: [HW95] <author> M. Herbster and M.K. Warmuth. </author> <title> Tracking the best expert. </title> <booktitle> Proceedings of of the Twelvth International Conference on Machine Learning, </booktitle> <year> 1995. </year>
Reference-contexts: For all classes F , both our result and theirs match Bartlett's [Bar92] fl = O (* 2 =VCdim (F )) necessary condition up to log factors. Littlestone and Warmuth [LW94], Kuh, Petsche and Rivest [KPR90, KPR91], Blum and Chalisani 3 [BC92], Herbster and Warmuth <ref> [HW95] </ref>, and Auer and Warmuth [AW95] also studied learning in a changing environment, but in frameworks substantially different from that considered here. The main new idea in our proof of the sufficient conditions is in where the assumption that the distributions are close to each other is applied.
Reference: [KPR90] <author> T. Kuh, T. Petsche, and R. Rivest. </author> <title> Learning time varying concepts. </title> <booktitle> In NIPS 3. </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1990. </year>
Reference-contexts: For all classes F , both our result and theirs match Bartlett's [Bar92] fl = O (* 2 =VCdim (F )) necessary condition up to log factors. Littlestone and Warmuth [LW94], Kuh, Petsche and Rivest <ref> [KPR90, KPR91] </ref>, Blum and Chalisani 3 [BC92], Herbster and Warmuth [HW95], and Auer and Warmuth [AW95] also studied learning in a changing environment, but in frameworks substantially different from that considered here.
Reference: [KPR91] <author> T. Kuh, T. Petsche, and R. Rivest. </author> <title> Mistake bounds of incremental learners when concepts drift with applications to feedforward networks. </title> <booktitle> In NIPS 4. </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: For all classes F , both our result and theirs match Bartlett's [Bar92] fl = O (* 2 =VCdim (F )) necessary condition up to log factors. Littlestone and Warmuth [LW94], Kuh, Petsche and Rivest <ref> [KPR90, KPR91] </ref>, Blum and Chalisani 3 [BC92], Herbster and Warmuth [HW95], and Auer and Warmuth [AW95] also studied learning in a changing environment, but in frameworks substantially different from that considered here.
Reference: [Lit90] <author> N. Littlestone. </author> <title> On the derivation and quality of Chernoff bounds, </title> <note> 1990. Submitted. </note>
Reference-contexts: Our proof required us to prove a new lower bound on the fatness of a tail of the binomial distribution. For this, we built upon a technique of Littlestone <ref> [Lit90] </ref>, lower bounding the sum of the largest few terms instead of the largest term as he did. A similar bound has been proved by Simon [Sim93], who appealed to the central limit theorem. Our bound has the advantage that it yields specific constants. <p> Set m 0 = d40d=(c 1 * 2 )e. Note that since * 1=1100, 40d 41d 2 This proof requires us to lower bound the tail of the binomial distribution. As is apparently required, our lower bound is stronger than what follows from the more general bound of Littlestone <ref> [Lit90] </ref>. A similar lower bound was proved by Simon [Sim93], who appealed to the central limit theorem. Our bound has the advantage that it yields concrete constants. 19 Define p as it is earlier in this section.
Reference: [LW94] <author> N. Littlestone and M.K. Warmuth. </author> <title> The weighted majority algorithm. </title> <journal> Information and Computation, </journal> <volume> 108 </volume> <pages> 212-261, </pages> <year> 1994. </year> <month> 23 </month>
Reference-contexts: For all classes F , both our result and theirs match Bartlett's [Bar92] fl = O (* 2 =VCdim (F )) necessary condition up to log factors. Littlestone and Warmuth <ref> [LW94] </ref>, Kuh, Petsche and Rivest [KPR90, KPR91], Blum and Chalisani 3 [BC92], Herbster and Warmuth [HW95], and Auer and Warmuth [AW95] also studied learning in a changing environment, but in frameworks substantially different from that considered here.
Reference: [Nat91] <author> B.K. Natarajan. </author> <title> Machine Learning: A Theoretical Approach. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, California, </address> <year> 1991. </year>
Reference-contexts: For examples of the VC-dimension, see <ref> [BEHW89, Nat91, AB92] </ref>. 2.2 Tools The following is a special case of Fubini's Theorem.
Reference: [Pol84] <author> D. Pollard. </author> <title> Convergence of Stochastic Processes. </title> <publisher> Springer Verlag, </publisher> <year> 1984. </year>
Reference-contexts: In proofs of this type, the probability that the error of some hypothesis is badly estimated is bounded by the probability that two samples give rise to substantially different estimates. Pollard <ref> [Pol84] </ref> calls this the symmetrization step. The "two-sample" probability is then bounded, making use of the resulting symmetry. <p> * for all f 2 F * for all fl-admissible sequences D 1 ; D 2 ; ::: of probability distributions on X, * for all t 2 N; t t 0 1 We assume that X is countable for convenience, but significantly weaker assumptions, like those of Pol lard's <ref> [Pol84] </ref> Appendix C, are enough. 5 the following holds: t Y D i fhx i i t i=1 ))(x t ) 6= f (x t )g *: This is a natural extension of the definition discussed by Ben-David, Benedek and Mansour [BBM89], which itself extended the PAC model [Val84]. <p> Then Z f (z 1 ; z 2 ) d (D 1 fi D 2 )(z 1 ; z 2 ) = Z 1 Z 2 = Z 2 Z 1 We also record the standard Hoeffding bound for reference. Lemma 2 (see <ref> [Pol84] </ref>) Choose a &lt; b and a countable set Z. Let D be a probability distribution on Z, and let f 1 ; :::; f m be independent random variables taking values in [a; b].
Reference: [Roy63] <author> H.L. Royden. </author> <title> Real Analysis. </title> <publisher> Macmillan, </publisher> <year> 1963. </year>
Reference-contexts: For examples of the VC-dimension, see [BEHW89, Nat91, AB92]. 2.2 Tools The following is a special case of Fubini's Theorem. Lemma 1 (see <ref> [Roy63] </ref>) Choose countable sets Z 1 and Z 2 , a function f : Z 1 fi Z 2 ! [0; 1] and probability distributions D 1 over Z 1 and D 2 over Z 2 .
Reference: [Sau72] <author> N. Sauer. </author> <title> On the density of families of sets. </title> <journal> J. Combinatorial Theory (A), </journal> <volume> 13 </volume> <pages> 145-147, </pages> <year> 1972. </year>
Reference-contexts: We will make use of the following version of Sauer's lemma <ref> [Sau72] </ref>, due to Blumer, Ehrenfeucht, Haussler and Warmuth [BEHW89]. Lemma 8 ([Sau72, BEHW89]) Choose a finite set Z, and a set F of functions from Z to f0; 1g. Let d = VCdim (F ).
Reference: [Sim93] <author> H.U. Simon. </author> <title> General lower bounds on the number of examples needed for learning probabilistic concepts. </title> <booktitle> The 1993 Conference on Computational Learning Theory, </booktitle> <pages> pages 402-412, </pages> <year> 1993. </year>
Reference-contexts: Once this is the case, the resulting two-sample product distribution is invariant with respect to the usual pair-swapping permutations, and the remainder of the VC proof can go through almost without modification. For our proof of the necessary condition, we make use of techniques due to Simon <ref> [Sim93] </ref>, Ehren-feucht, Haussler, Kearns and Valiant [EHKV89] and Helmbold and Long [HL94]. The main new idea required to prove this paper's result was how to drift efficiently from a joint distribution with no information to a hard joint distribution of the type useful in arguments of the type of Simon. <p> For this, we built upon a technique of Littlestone [Lit90], lower bounding the sum of the largest few terms instead of the largest term as he did. A similar bound has been proved by Simon <ref> [Sim93] </ref>, who appealed to the central limit theorem. Our bound has the advantage that it yields specific constants. <p> For each class F , if d is the VC-dimension of F , we show that F is not agnostically (*; fl)-learnable if fl = 1100000* 3 d . Our proof uses ideas of Ehrenfeucht, Haussler, Kearns and Valiant [EHKV89], Helmbold and Long [HL94], and Simon <ref> [Sim93] </ref>. At a high level, it proceeds as follows. For some trial t, we will choose a sequence of drifting distributions that drifts only during the last m trials. <p> The corresponding probability of error is 1=2 i 0 fl=2, where i 0 = maxf0; i kg. A similar observation to the following lemma was made by Simon <ref> [Sim93] </ref>. Lemma 15 Consider the algorithm A which ignores information from all samples seen prior to and including the kth sample, the drift initiating sample. For i k, A behaves arbitrarily. <p> Note that since * 1=1100, 40d 41d 2 This proof requires us to lower bound the tail of the binomial distribution. As is apparently required, our lower bound is stronger than what follows from the more general bound of Littlestone [Lit90]. A similar lower bound was proved by Simon <ref> [Sim93] </ref>, who appealed to the central limit theorem. Our bound has the advantage that it yields concrete constants. 19 Define p as it is earlier in this section. Consider the time at which the tth sample is drawn as per the distribution P t of our distribution sequence.
Reference: [Tal94] <author> M. Talagrand. </author> <title> Sharper bounds for Gaussian and empirical processes. </title> <journal> Annals of Probability, </journal> <volume> 22 </volume> <pages> 28-76, </pages> <year> 1994. </year>
Reference-contexts: One direction for future research would be to search for efficient algorithms for agnostic learning in a drifting environment. Another obvious problem is to try to close the log factor gaps that remain in these models. It seems possible that modifying the proof of a result of Talagrand <ref> [Tal94] </ref> in a manner analogous to the modification of the proof of Vapnik and Chervonenkis given here might improve the general bound on the rate of drift sufficient for agnostic learning by a log factor.
Reference: [Val84] <author> L.G. Valiant. </author> <title> A theory of the learnable. </title> <journal> Communications of the ACM, </journal> <volume> 27(11) </volume> <pages> 1134-1142, </pages> <year> 1984. </year>
Reference-contexts: The focus of these models differs from those like the PAC model <ref> [Val84] </ref> in that prediction models are tailored to situations where learning is an ongoing process. However, results for one type of model often yield related results for the other. We will consider two models for prediction problems, both introduced by Bartlett [Bar92]. <p> Pol lard's [Pol84] Appendix C, are enough. 5 the following holds: t Y D i fhx i i t i=1 ))(x t ) 6= f (x t )g *: This is a natural extension of the definition discussed by Ben-David, Benedek and Mansour [BBM89], which itself extended the PAC model <ref> [Val84] </ref>. Results for this model follow from the work of Bartlett [Bar92].
Reference: [VC71] <author> V.N. Vapnik and A.Y. Chervonenkis. </author> <title> On the uniform convergence of relative frequencies of events to their probabilities. </title> <journal> Theory of Probability and its Applications, </journal> <volume> 16(2) </volume> <pages> 264-280, </pages> <year> 1971. </year>
Reference-contexts: The proofs use Blumer, Ehrenfeucht, Haussler and Warmuth's idea of learning by estimating the error of all the hypotheses in the class from a single sample [BEHW89]. To bound how hard this is in our setting, we follow the outline of the proof of Vapnik and Chervonenkis <ref> [VC71] </ref>. In proofs of this type, the probability that the error of some hypothesis is badly estimated is bounded by the probability that two samples give rise to substantially different estimates. Pollard [Pol84] calls this the symmetrization step. The "two-sample" probability is then bounded, making use of the resulting symmetry. <p> A subset fx 1 ; :::; x d g of some set X is shattered by a set F of functions from X to f0; 1g if f (f (x 1 ); :::; f (x d )) : f 2 F g = f0; 1g d : The VC-dimension <ref> [VC71] </ref> of F is the size of the largest set shattered by F . For examples of the VC-dimension, see [BEHW89, Nat91, AB92]. 2.2 Tools The following is a special case of Fubini's Theorem. <p> Let d = VCdim (F ). Then jF j (ejZj=d) d : Now we are ready for the second part of the proof. The proof of this part follows that of Vapnik and Chervonenkis <ref> [VC71] </ref>. Lemma 9 Choose a countable set Z, and a set G of functions from Z to f0; 1g. Let d = VCdim (G). Choose &gt; 0. Choose m 2 N. Choose distributions D 1 ; :::; D m on Z.
References-found: 34

