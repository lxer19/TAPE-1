URL: http://www.cs.unc.edu/Research/mi/ftp/proving.ps
Refering-URL: http://www.cs.unc.edu/Research/mi/mi-publications.html
Root-URL: http://www.cs.unc.edu
Note: TABLE OF CONTENTS  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Allen, P.E., Bose, S., Clarke, E.M., and Michaylov, S., PARTHENON: </author> <title> A parallel theorem prover for non-Horn clauses, system abstract, </title> <booktitle> Proceedings of the 9th International Conference on Automated Deduction, </booktitle> <editor> E. Lusk and R. Overbeek, eds., </editor> <booktitle> Lecture Notes in Computer Science vol. </booktitle> <volume> 310, </volume> <editor> G. Goos and J. Hartmanis, eds. </editor> <publisher> (Springer-Verlag, </publisher> <address> New York, </address> <year> 1988), </year> <pages> pp. 764 - 765. </pages>
Reference-contexts: This method was used successfully in the Franz lisp resolution prover of Greenbaum and Plaisted [39] as well as in the Otter theorem prover of McCune. The use of concurrency can speed up a prover; for some work in this area see <ref> [1] </ref>. It is important for the prover to have good default switch settings so that a naive user can still obtain good results. In developing a theorem prover, empirical testing is valuable. <p> It uses ``negation normal form'' rather than clause form to express the assertions. Mark Stickel has recently implemented a ``Prolog technology theorem prover'' that implements a version of model elimination and can perform several thousand inferences per second. Ed Clarke's PARTHENON prover <ref> [1] </ref> implements essentially the same strategy on 15 processors and obtains tens of thousands of inferences per second. Both provers are very impressive. However, the fact that the same subgoal may be solved many times without remembering the previous solutions, may be a drawback.
Reference: [2] <author> Andrews, P.B., </author> <title> Theorem proving via general matings, </title> <journal> J. </journal> <note> ACM 28 (1981)193 - 214. </note>
Reference-contexts: Andrews' matings <ref> [2] </ref> are similar to connection graphs, but do not perform any unifications until a possible proof is found. Andrews [65] has implemented a higher order theorem prover using these ideas, and has obtained some impressive results.
Reference: [3] <author> Andrews, P.B., </author> <title> An Introduction to Mathematical Logic and Type Theory: To Truth Through Proof (Academic Press, </title> <address> New York, </address> <year> 1986). </year>
Reference-contexts: For a general discussion of sorts in theorem proving, see [112]; for an example of increased efficiency due to sorts, see [111]. A theoretical discussion is given in <ref> [3] </ref>. Another extension is mathematical induction. Certain theorems are not provable without mathematical induction. For example, in first order logic it is not possible to prove that addition is commutative from the axioms defining addition in terms of the successor relation.
Reference: [4] <author> Ballantyne, A., and Bledsoe, W., </author> <title> On generating and using examples in proof discovery, </title> <booktitle> Machine Intelligence 10 (Harwood, </booktitle> <address> Chichester, </address> <year> 1982) </year> <month> 3-39. </month>
Reference-contexts: There are trivial uses of semantics, having to do with choosing signs for various predicates, but we are concerned instead with semantics that are natural and based on realistic interpretations. Closely related to the use of semantics is the use of examples; see <ref> [4] </ref> for a discussion of the use of examples. 7.5 Abstraction It would seem to be useful for a theorem prover to learn from experience.
Reference: [5] <author> Bibel, W., </author> <title> Automated Theorem Proving, </title> <publisher> Vieweg, </publisher> <year> 1982. </year>
Reference-contexts: There are a number of connection-graph based methods that perform the search in a completely different way, keeping track of possible unifications or ``connections'' between literals. This avoids certain search redundancies due to the order in which unifications are performed. For a description of such procedures, see Bibel <ref> [5] </ref>; for some completeness and incompleteness results, see [27]; for a description of a connection graph based prover on which a large number of examples have been run and in which a large amount of effort has been invested, see [28].
Reference: [6] <author> Bledsoe, </author> <title> W.W., The sup-inf method in Presburger arithmetic, </title> <institution> Memo ATP-18, Mathematics Dept., University of Texas at Austin, </institution> <year> 1974. </year>
Reference-contexts: A faster method has been developed by Karmakar [50] and seems to be practically useful. A decision procedure for the quantifier-free theory of reals with addition that is based on intervals has been given by Bledsoe <ref> [6] </ref>; this method often works well on small formulas, though in general it may take exponential time. Another well known decidable theory is that of the integers with addition, or Presburger arithmetic. This is like the reals with addition except that the domain is the integers instead of the reals.
Reference: [7] <author> Bledsoe, </author> <title> W.W., Ground resolution using anti-clauses, </title> <type> Report No. </type> <institution> ATP-72, Departments of Mathematics and Computer Sciences, The University of Texas at Austin, </institution> <month> April, </month> <year> 1983. </year>
Reference-contexts: This method runs in approximately O (2 .25n ) time for a formula with n occurrences of propositions. Another interesting and novel method is that of Bledsoe <ref> [7] </ref>. This is based on the idea of counting the number of interpretations in which S is false. It turns out that this can be done very efficiently if the number of predicates in S is not too large.
Reference: [8] <author> Bledsoe, W., </author> <title> Some automatic proofs in analysis, in Automated Theorem Proving: After 25 Years, </title> <editor> W. Bledsoe and Donald Loveland, eds., </editor> <booktitle> Contemporary Mathematics, </booktitle> <volume> Vol. 29, </volume> <publisher> American Mathematical Society, </publisher> <year> 1984, </year> <pages> pp. 89-118. </pages>
Reference-contexts: Also, these provers do not permit term rewriting or any specialized inference rules. Bledsoe's group at the University of Texas at Austin has proven a number of respectable theorems in set theory, calculus (limit theorems), intermediate analysis, and elementary topology <ref> [8] </ref>. Most of this work has been done on ``natural deduction'' provers; by this term, Bledsoe denotes what 61 Loveland calls ``problem reduction formats,'' that is, provers that decompose a goal into subgoals and work on the subgoals recursively.
Reference: [9] <editor> Bledsoe, W.W., and Loveland, D.W., eds., </editor> <title> Automated Theorem Proving: After 25 64 Years (American Math. </title> <publisher> Society, </publisher> <address> Providence, R.I., </address> <year> 1984). </year>
Reference-contexts: Still, some interesting proofs have been found. For an excellent survey of the history of theorem proving to 1984 and a collection of papers illustrating the state of the art at that time, see Bledsoe and Loveland <ref> [9] </ref> and the survey article by Loveland [56]. One of the earliest results is from Guard et al [41]. Their interactive semi-automated reasoning program derived a lemma in lattice theory, known as SAM's lemma, which had not been proven previously, and which was the key to an open problem.
Reference: [10] <author> Boyer, R., </author> <title> Locking, a restriction of resolution, </title> <type> Ph.D. thesis, </type> <institution> University of Texas at Austin, </institution> <address> TX (1971). </address>
Reference-contexts: Locking resolution <ref> [10] </ref> adds indices to the literals which may be used to order them. Definition. A unit clause is a clause containing exactly one literal. Unit resolution is the restriction in which resolutions are only performed between a unit clause and another clause. <p> This gives a fairly natural and intuitive measure of proof complexity which enables this prover to get some fairly hard problems automatically. This prover is essentially a combination of locking resolution <ref> [10] </ref> and set of support, and may be viewed as a refinement of ordinary resolution. <p> Many of the proofs found by Bledsoe's provers were obtained using rewrite rules, and some of them also required specialized inference rules or heuristics for inequalities or limits. T. C. Wang has implemented a hierarchical deduction prover [114], which is essentially a combination of locking resolution <ref> [10] </ref> and set of support. This prover has obtained some impressive proofs fully automatically, without any specialized inference rules. His prover has a fairly sophisticated measure of proof complexity, which is largely responsible for its success. However, on some easier problems it does not perform as well.
Reference: [11] <author> Boyer, R. and Moore, J., </author> <title> A Computational Logic, </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1979. </year>
Reference-contexts: The most notable example of a prover using induction is the Boyer-Moore prover <ref> [11] </ref>. This prover requires guidance from the user in the statement of a series of lemmas leading up to the theorem. The lemmas need to be chosen carefully to make proper use of the heuristics used by the program. In this prover, theorems are rewrite rules, nicely constraining the search.
Reference: [12] <author> Boyer, R. and Moore, J.S., </author> <title> Proof checking, theorem proving, and program verification, in Automated Theorem Proving: After 25 Years, </title> <editor> W. Bledsoe and Donald Loveland, eds., </editor> <booktitle> Contemporary Mathematics, </booktitle> <volume> Vol. 29, </volume> <publisher> American Mathematical Society, </publisher> <year> 1984, </year> <pages> pp. 119 - 167. </pages>
Reference-contexts: Hunt [48] has used the Boyer-Moore theorem prover to give a correctness proof for a microcoded central processing unit called the FM8501. This prover has also been used (with human guidance) to prove mathematical theorems <ref> [12] </ref>, such as the law of quadratic 49 reciprocity in number theory, G .. odel's incompleteness theorem, the Church-Rosser theorem for term rewriting systems [95], and the unsolvability of the halting problem for lisp programs. In addition, a property of the RSA encryption algorithm has been shown on this prover.
Reference: [13] <author> Boyer, R. and Moore, J.S., </author> <title> The addition of bounded quantifiers and partial functions to a computational logic and its theorem prover, </title> <journal> J. </journal> <note> Automated Reasoning 4 (1988) 117 - 172. </note>
Reference-contexts: Major Theorem Proving Programs We now discuss some of the more well known theorem proving programs, while omitting many others. We have already mentioned the Boyer-Moore theorem prover several times. This prover has recently been extended <ref> [13] </ref> to handle bounded quantifiers and partial functions. In this prover, priorities are not as important as in other provers, since rewriting controls the search fairly well. Some care is necessary, however, in stating the theorem in such a way that the prover will obtain a proof.
Reference: [14] <author> Boyer, R., Lusk, E., McCune, W., Overbeek, R., Stickel, M., and Wos, L., </author> <title> Set theory in first order logic: clauses for Godel's axioms, </title> <note> Journal of Automated Reasoning 2 (1986) 287 - 327. </note>
Reference-contexts: Not only formal mathematics but many other technical areas can be so expressed. First order logic is a particularly simple and well understood language which is adequate for many problems. It is even possible to express a version of set theory, von Neumann-Bernays-G .. odel set theory <ref> [14] </ref>, in first order logic, curiously enough, and this version of set theory is at least as powerful as Zermelo-Fraenkel set theory. However, this method of expressing set theory in first order logic is somewhat unnatural. <p> Finally, set theory itself is useful in a prover; it is convenient to be able to directly refer to sets of elements and prove their properties. An interesting way of embedding set theory in first order logic is given in <ref> [14] </ref>; however, this encoding is unnatural. Possibly more natural such encodings exist. 60 There are so many possible extensions and features for theorem provers that it becomes a problem to know how to combine them in the best way.
Reference: [15] <author> Brand, D., </author> <title> Proving theorems with the modification method, </title> <journal> SIAM J. Comput. </journal> <month> 4 </month> <year> (1975) </year> <month> 412-430. </month>
Reference-contexts: Similarly, (C fi [v fi] n/ D fi) is a paramodulant of C [t] and ((v = u) n/ D). For example, the clause (P (g (a)) n/ Q (b)) is a paramodulant of P (f (x)) and ((f (a) = g (a)) n/ Q (b)). Brand <ref> [15] </ref> showed that if Eq is the set of equality axioms given above and S is a set of clauses, then S U Eq is unsatisfiable iff there is a proof of the empty clause from S U fx = xg using resolution and paramodulation as inference rules.
Reference: [16] <author> Brock, B., Cooper, S., and Pierce, W., </author> <title> Anological reasoning and proof discovery, </title> <booktitle> Proceedings of the 9th International Conference on Automated Deduction, </booktitle> <editor> E. Lusk and R. Overbeek, eds., </editor> <booktitle> Lecture Notes in Computer Science vol. </booktitle> <volume> 310, </volume> <editor> G. Goos and J. Hartmanis, eds. </editor> <publisher> (Springer-Verlag, </publisher> <address> New York, </address> <year> 1988), </year> <pages> pp. 454 - 468. </pages>
Reference-contexts: Early work in this area was done by Kling [52]. The Austin group has done some more recent work in this area <ref> [16] </ref>, although the analogies used so far are fairly restrictive and the improvement in search time is not dramatic.
Reference: [17] <author> Bundy, A., </author> <title> The Computer Modelling of Mathematical Reasoning (Academic Press, </title> <address> New York, </address> <year> 1983). </year>
Reference-contexts: A proof that any decision procedure for this theory takes nondeterministic exponential time is given in [43]. The quantifier-free theory of reals with addition is essentially the same as linear programming. This is called ``Bledsoe real arithmetic'' by Bundy <ref> [17] </ref>. For this, the simplex method [67] is often used. Recently a polynomial time method was found by Khachian [51], but this method seems to be too slow for practical use. A faster method has been developed by Karmakar [50] and seems to be practically useful.
Reference: [18] <author> Bundy, A., </author> <title> The use of explicit proof plans to guide inductive proofs, </title> <booktitle> Proceedings of the 9th International Conference on Automated Deduction, </booktitle> <editor> E. Lusk and R. Over-beek, eds., </editor> <booktitle> Lecture Notes in Computer Science vol. </booktitle> <volume> 310, </volume> <editor> G. Goos and J. Hartmanis, eds. </editor> <publisher> (Springer-Verlag, </publisher> <address> New York, </address> <year> 1988), </year> <pages> pp. 111 - 120. </pages>
Reference-contexts: Some work has been done recently on algorithms for unifying formulae with explicit quantifiers. Also, there are a number of provers which have languages in which the user can specify his own proof strategies. A recent example is <ref> [18] </ref>. This is an attractive idea because it provides one way of building knowledge into the theorem prover. However, it places an additional burden on the user who must be familiar enough with theorem proving strategies to state a method for attempting a proof.
Reference: [19] <author> Cantone, D., Ghelfo, S., and Omodeo, E., </author> <title> The automation of syllogistic I. Syllogistic normal forms, </title> <journal> J. </journal> <note> Symbolic Computation 6 (1988) 83 - 98. </note>
Reference-contexts: Some decision procedures for fragments of set theory have been developed; see for example <ref> [19] </ref>. A decision procedure for some graph theory formulas is given in Moser [69]. A method of representing modal logic statements in first order logic with a special unification procedure is presented in Ohlbach [75]. Decision procedures for a number of temporal logics are known; see for example [100].
Reference: [20] <author> Chang, C.L., </author> <title> The unit proof and the input proof in theorem proving, </title> <journal> J. </journal> <note> ACM 17 (1970) 698 - 707. </note>
Reference-contexts: Input resolution is the strategy in which one of the clauses resolved must always be an input clause. This is also not complete but is often useful. An equivalence between unit and input resolution is mentioned in <ref> [20] </ref>. There are also restrictions on factoring. These are restrictions on the size of the subsets of resolution or their contents. A particularly severe but still complete restriction is given in [90].
Reference: [21] <author> Chang, C. and Lee, R., </author> <title> Symbolic Logic and Mechanical Theorem Proving (Academic Press, </title> <address> New York, </address> <year> 1973). </year>
Reference-contexts: The clause form of this is 32 ffP (a, y)g,f:P (x, b)gg, which represents the conjunction of two clauses, each containing a single literal. The details of this process are given in many standard texts, such as <ref> [21] </ref> and [55]. For a proof that Skolemization preserves satisfiability, see [55]; validity is not necessarily preserved. Note that this process removes the distinction between a set of axioms and the theorem to be proven; all are on a common footing.
Reference: [22] <author> Chou, S.-C., </author> <title> Proving elementary geometry theorems using Wu's algorithm, in Automated Theorem Proving: After 25 Years, </title> <editor> W. Bledsoe and Donald Loveland, eds., </editor> <booktitle> Contemporary Mathematics, </booktitle> <volume> Vol. 29, </volume> <publisher> American Mathematical Society, </publisher> <year> 1984, </year> <pages> pp. 243 - 286. </pages>
Reference-contexts: Quite a number of theorems have been proven using this procedure, and some possibly new theorems have been shown (although in a field as old as geometry it is hard to know for sure that something is new). For an easy introduction to this method, see Chou <ref> [22] </ref>. Wu's method has also been used to generate theorems in geometry. Wang [113] has recently developed a specialized theorem proving method for ring theory, and using it he has solved an open problem in this area.
Reference: [23] <editor> Constable, R.L., Allen, S.F., Bromley, H.M. et al, </editor> <title> Implementing Mathematics with the Nuprl Proof Development System (Prentice-Hall, </title> <address> Englewood Cliffs, N.J., </address> <year> 1986). </year>
Reference-contexts: For example, program verifiers have been used to verify fairly complex programs. Examples of such verifiers include SRI's STP verifier [96], Stanford's verifier [108], and the Gypsy verifier [36] at the University of Texas at Austin. Also, the NuPrl system at Cornell <ref> [23] </ref> is really a logical system with a declarative and procedural interpretation in which guaranteed correct programs can be constructed; this system has certain automated reasoning features, but the search is primarily guided by human interaction. <p> This prover has obtained some impressive proofs fully automatically, without any specialized inference rules. His prover has a fairly sophisticated measure of proof complexity, which is largely responsible for its success. However, on some easier problems it does not perform as well. The NuPrl system at Cornell <ref> [23] </ref> is used for program development in a constructive logic, and is more a proof checker than a proof finder. It permits the user to specify methods to be applied to subgoals of various forms.
Reference: [24] <author> Davis, M. and Putnam, H., </author> <title> A computing procedure for quantification theory, </title> <journal> J. </journal> <note> ACM 7:3 (1960) 201 - 215. </note>
Reference-contexts: As mentioned above, it is of equivalent complexity to decide whether a formula is unsatisfiable. One of the earliest and best is the method of Davis and Putnam <ref> [24] </ref>. For this we assume S is in clause form. This method is like a recursive case analysis, where for a proposition P, the cases are P being true or false.
Reference: [25] <author> Dershowitz, N., </author> <title> Orderings for term-rewriting systems, </title> <note> Theoretical Computer Science 17(1982)279-301. </note>
Reference-contexts: Suppose C [t] is a clause containing a non-variable term t and u = v is another unit clause. Suppose v is ``simpler'' than u, in a sense too technical to precisely describe here. (See <ref> [25] </ref> for a discussion of ``simplification orderings'' and related topics.) Suppose these two clauses have no common variables (since variables can always be renamed). Suppose t is an instance of u, and let fi be such that t is u fi.
Reference: [26] <author> Digricoli, V. and Harrison, M., </author> <title> Equality-based binary resolution, </title> <journal> J. </journal> <note> ACM 33 (1986) 253 - 289. 65 </note>
Reference-contexts: Recent work has concerned systematic methods for combining unification algorithms for various theories; see for example [94]. Another paper in this volume deals with equational unification. There are also a number of other equality-based theorem proving methods, such as equality-based binary resolution <ref> [26] </ref>. 4.4 Other Proof Procedures There are some problems with resolution style proof precedures as we have described them. The conversion to clause form often destroys the structure of a formula, and this structure can be important.
Reference: [27] <author> Eisinger, N., </author> <title> What you always wanted to know about clause graph resolution, </title> <booktitle> Proceedings of the 8th International Conference on Automated Deduction, </booktitle> <editor> J. Siek-mann, ed., </editor> <booktitle> Lecture Notes in Computer Science vol. </booktitle> <volume> 230, </volume> <editor> G. Goos and J. Hartmanis, eds. </editor> <publisher> (Springer-Verlag, </publisher> <address> New York, </address> <year> 1986), </year> <pages> pp. 316 - 336. </pages>
Reference-contexts: This avoids certain search redundancies due to the order in which unifications are performed. For a description of such procedures, see Bibel [5]; for some completeness and incompleteness results, see <ref> [27] </ref>; for a description of a connection graph based prover on which a large number of examples have been run and in which a large amount of effort has been invested, see [28].
Reference: [28] <author> Eisinger, N. and Ohlbach, H.J., </author> <title> The Markgraf Karl refutation procedure, </title> <booktitle> Proceedings of the 8th International Conference on Automated Deduction, </booktitle> <editor> J. Siekmann, ed., </editor> <booktitle> Lecture Notes in Computer Science vol. </booktitle> <volume> 230, </volume> <editor> G. Goos and J. Hartmanis, eds. </editor> <publisher> (Springer-Verlag, </publisher> <address> New York, </address> <year> 1986), </year> <pages> pp. 681 - 682. </pages>
Reference-contexts: For a description of such procedures, see Bibel [5]; for some completeness and incompleteness results, see [27]; for a description of a connection graph based prover on which a large number of examples have been run and in which a large amount of effort has been invested, see <ref> [28] </ref>. Andrews' matings [2] are similar to connection graphs, but do not perform any unifications until a possible proof is found. Andrews [65] has implemented a higher order theorem prover using these ideas, and has obtained some impressive results. <p> We have also found an automatic subgoal reordering method which reduces the average proof time for the examples we have tested. This prover is remarkably compact, in addition, and is designed to be reliable with a minimum of user guidance. The Markgraph Karl prover <ref> [28] </ref> has been mentioned earlier. In addition, there are many other provers which various researchers (including the author) have developed and which we cannot cover here. 9. Implications for Artificial Intelligence We comment on the implications of theorem proving research for the field of artificial intelligence.
Reference: [29] <author> Fischer, M. and Rabin, M., </author> <title> Super-exponential complexity of Presburger arithmetic, </title> <booktitle> Proc. Symposium on the Complexity of Real Computation Processes (1973). </booktitle>
Reference-contexts: Another well known decidable theory is that of the integers with addition, or Presburger arithmetic. This is like the reals with addition except that the domain is the integers instead of the reals. This is decidable, but requires nondeterministic double exponential time to decide <ref> [29] </ref>. Other decidable theories include the theory of equality [73], in which the only predicate is =, the theory of lisp list structure, and the theory of arrays. All these theories permit uninterpreted function symbols. For a discussion of these theories see [43].
Reference: [30] <author> Gallier, J., </author> <title> Logic for Computer Science: Foundations of Automatic Theorem Proving (Harper and Row, </title> <address> Philadelphia, </address> <year> 1986). </year>
Reference-contexts: Such systems are attractive for backward chaining reasoning for this reason. For a discussion of these systems, see Gallier <ref> [30] </ref>. A discussion of the 8 or 9 principle kinds of proof systems is given in [64]. ``Natural deduction proofs'' are something like sequent style proofs, except that there are ``discharge'' rules for removing assumptions. <p> This method performs impressively well on some examples. Finally, there are many methods that are not based on anything similar to clause form. We do not discuss these methods much. In general, the sequent style methods of Gentzen <ref> [30] </ref> have a lot to recommend them. Some work has been done recently on algorithms for unifying formulae with explicit quantifiers. Also, there are a number of provers which have languages in which the user can specify his own proof strategies. A recent example is [18].
Reference: [31] <author> Gallier, J., Narendran, P., Plaisted, D., and Snyder, W., </author> <title> Rigid E-unification is NP-complete, </title> <booktitle> Proceedings of the Third Annual Symposium on Logic in Computer Science (IEEE, </booktitle> <address> Piscataway, N.J., </address> <year> 1988), </year> <pages> pp. 218 - 227. </pages>
Reference-contexts: A variation called ``rigid E-unification'' was introduced by Gallier et al [32] and shown to be NP complete <ref> [31] </ref>; this is interesting because the general E-unification problem is undecidable. 7. General Issues in Automatic Theorem Proving We now discuss a number of general issues concerning theorem provers, such as search strategies, simplification, semantics, abstraction and analogy, finding relevant 52 axioms, and some general software engineering issues.
Reference: [32] <author> Gallier, J., Raatz, S., and Snyder, W., </author> <title> Theorem proving using rigid E-unification: equational matings, invited paper, Colloquium on the Resolution of Equations in Algebraic Structures, </title> <month> May 4-6, </month> <year> 1987, </year> <institution> Austin, Texas. </institution>
Reference-contexts: A variation called ``rigid E-unification'' was introduced by Gallier et al <ref> [32] </ref> and shown to be NP complete [31]; this is interesting because the general E-unification problem is undecidable. 7.
Reference: [33] <author> Garey, M. and Johnson, D., </author> <title> Computers and Intractability: A Guide to the Theory of NP-Completeness (Freeman, </title> <address> San Francisco, </address> <year> 1979). </year>
Reference-contexts: Since A is valid iff not (A) is unsatisfiable, it is of equivalent difficulty to decide unsatisfiability. The sat-isfiability problem is the most basic of the famous NP-complete problems <ref> [33] </ref>, which no one can prove are hard but most people believe are. Many other problems of practical importance are also NP-complete. The best known methods to solve such problems take exponential time in the worst case.
Reference: [34] <author> Gelernter, H., Hansen, J.R., and Loveland, D.W., </author> <title> Empirical explorations of the geometry theorem proving machine, </title> <editor> in: E. Feigenbaum and J. Feldman, eds., </editor> <booktitle> Computers and Thought (McGraw-Hill, </booktitle> <address> New York, </address> <year> 1963) </year> <month> 153 - 167. </month>
Reference-contexts: We evaluate these procedures based on the following criteria: 1) Do they support back chaining with caching? 2) Are they genuine support strategies? 3) Do they permit semantic deletion as in Gelernter's theorem prover <ref> [34] </ref>? 4) Is the cut rule or its equivalent well controlled during back chaining? 5) Does the procedure apply to an arbitrary first order formula in clause form? We now explain these features, which we feel are basic in a decision procedure for first order logic, though some good procedures may <p> There have been some notably successful attempts in this direction, such as the geometry theorem prover of Gelernter <ref> [34] </ref>, but so far it seems that not much has been gained in this way in other provers. The use 55 of semantics corresponds to examples or pictures that people use to determine whether a lemma they are attempting, is true.
Reference: [35] <author> Genesereth, M. and Nilsson, N., </author> <booktitle> Logical Foundations of Artificial Intelligence (Kaufmann, </booktitle> <address> Los Altos, Calif., </address> <year> 1987). </year>
Reference: [36] <author> Good, D.I., </author> <title> London, R.L., and Bledsoe, W.W., An interactive program verification system, </title> <booktitle> Proceedings of International Conference on Reliable Software, </booktitle> <address> Los Angeles, California, </address> <month> April, </month> <year> 1975. </year>
Reference-contexts: A number of applications of automated reasoning systems are already in existence. For example, program verifiers have been used to verify fairly complex programs. Examples of such verifiers include SRI's STP verifier [96], Stanford's verifier [108], and the Gypsy verifier <ref> [36] </ref> at the University of Texas at Austin. Also, the NuPrl system at Cornell [23] is really a logical system with a declarative and procedural interpretation in which guaranteed correct programs can be constructed; this system has certain automated reasoning features, but the search is primarily guided by human interaction.
Reference: [37] <author> Green, C., </author> <title> Theorem proving by resolution as a basis for question-answering systems, </title> <booktitle> Machine Intelligence 4 (American Elsevier, </booktitle> <address> New York, </address> <year> 1969), </year> <pages> pp. 183 - 205. </pages>
Reference-contexts: Resolution can also be used for answer extraction. This idea was mentioned early by Green <ref> [37] </ref>. The idea is that if we prove a theorem of the form (9x)P (x), then from the proof it is sometimes possible to construct a term t such that P (t). <p> This latter case is called an ``indefinite answer.'' Sometimes it is possible also to find conditions under which each answer t i will be correct. For a discussion of answer extraction, see <ref> [37] </ref>. There are a multitude of refinements to resolution which preserve completeness, and a number of other clausal theorem proving strategies. For example, one such is tautology deletion. Recall that a clause C is a tautology if for some atom L, C contains both L and not (L).
Reference: [38] <author> Green, C., </author> <title> Application of theorem proving to problem solving, </title> <editor> in Webber, B.L. and Nilsson, N.J., eds., </editor> <booktitle> Readings in Artificial Intelligence (Kaufmann, </booktitle> <address> Los Altos, Calif., </address> <year> 1981). </year>
Reference-contexts: This representation may also help to mechanize reasoning relative to various contexts. The representation is based on the situation calculus <ref> [38] </ref>. The ``frame problem''[35] is to find a good method of specifying what does not change when an action is performed. A straightforward representation is awkward, requiring many separate ``frame axioms'' stating what does not change when each action is performed.
Reference: [39] <author> Greenbaum, S., and Plaisted, D., </author> <title> The Illinois prover: a general purpose resolution theorem prover, extended abstract, </title> <booktitle> Eighth Conference on Automated Deduction, </booktitle> <month> July, </month> <year> 1986. </year>
Reference-contexts: The idea of ``structure sharing'' is important to prevent the prover from using too much memory on hard problems. Some kind of ``discrimination net'' is useful to rapidly locate potentially unifiable pairs of literals. This method was used successfully in the Franz lisp resolution prover of Greenbaum and Plaisted <ref> [39] </ref> as well as in the Otter theorem prover of McCune. The use of concurrency can speed up a prover; for some work in this area see [1]. It is important for the prover to have good default switch settings so that a naive user can still obtain good results.
Reference: [40] <author> Grigor'ev, D. Y. and N. N. Vorobjov, </author> <title> Solving systems of polynomial inequalities in subexponential time, </title> <journal> J. </journal> <note> Symbolic Computation 5 (1988) 37 - 64. </note>
Reference-contexts: The standard interpretation is assumed. This theory essentially involves statements of the form p (x) 0, where p is a polynomial, and was shown to be decidable by Tarski [109]. A recent, more efficient decision procedure for this problem is given in <ref> [40] </ref>. Another decidable theory is that of reals with addition, which is as above except that the multiplication operator may not appear. A proof that any decision procedure for this theory takes nondeterministic exponential time is given in [43].
Reference: [41] <author> Guard, J.R., Oglesby, F.C., Bennett, J.H., and Settle, L.G., </author> <note> Semi-automated mathematics, J. ACM 18 (1969) 49 - 62. </note>
Reference-contexts: For an excellent survey of the history of theorem proving to 1984 and a collection of papers illustrating the state of the art at that time, see Bledsoe and Loveland [9] and the survey article by Loveland [56]. One of the earliest results is from Guard et al <ref> [41] </ref>. Their interactive semi-automated reasoning program derived a lemma in lattice theory, known as SAM's lemma, which had not been proven previously, and which was the key to an open problem. The Argonne prover [58] has also solved some open problem in mathematics, with human assistance.
Reference: [42] <author> Henschen, L. and Wos, L., </author> <title> Unit refutations and Horn sets, </title> <journal> J. </journal> <note> ACM 21 (1974) 590-605. </note>
Reference-contexts: Such clauses are used in Prolog, and certain restricted strategies are complete for Horn clauses. For example, input resolution is complete for Horn clauses. Also, positive resolution without factoring is complete for Horn clauses <ref> [42] </ref>; this is a strategy in which 40 clauses C 1 and C 2 are resolved only if C 1 or C 2 is a positive unit clause.
Reference: [43] <author> Hopcroft, J. and Ullman, J., </author> <title> Introduction to Automata Theory, Languages, </title> <publisher> and Computation (Addison-Wesley, </publisher> <address> Reading, Mass., </address> <year> 1979). </year>
Reference-contexts: Another decidable theory is that of reals with addition, which is as above except that the multiplication operator may not appear. A proof that any decision procedure for this theory takes nondeterministic exponential time is given in <ref> [43] </ref>. The quantifier-free theory of reals with addition is essentially the same as linear programming. This is called ``Bledsoe real arithmetic'' by Bundy [17]. For this, the simplex method [67] is often used. <p> Other decidable theories include the theory of equality [73], in which the only predicate is =, the theory of lisp list structure, and the theory of arrays. All these theories permit uninterpreted function symbols. For a discussion of these theories see <ref> [43] </ref>. Under fairly general conditions, the combination of two theories is decidable if the two theories are decidable separately [72]. For an easy description of a method for deciding combinations of theories, see Nelson [71]. If the theories have the property of ``convexity,'' this method is especially efficient.
Reference: [44] <author> Hsiang, J., </author> <title> Refutational theorem proving using term rewriting systems, </title> <booktitle> Artificial 66 Intelligence 25 (1985) 255 - 300. </booktitle>
Reference-contexts: However, if ``not'', ``and'', and ``exclusive or'' are used instead to express an arbitrary boolean formula, it is possible to define a conjunctive normal form that is unique, interestingly enough. This idea goes back a long way, and a recent use of it may 8 be found in <ref> [44] </ref> and [45]. 2.1 Proof Procedures We now consider methods of deciding whether a formula is valid. Since A is valid iff not (A) is unsatisfiable, it is of equivalent difficulty to decide unsatisfiability. <p> Since unit clauses are used in such simplifications, it makes sense to adjust the search to favor the genaration of unit clauses. Such unit simplification is done automatically in rewrite based methods such as that of Hsiang <ref> [44] </ref>. Deleting clauses that are subsumed may be viewed as another kind of simplification. Still another kind of simplification is the replacement of predicates by their definitions. For example, the predicate subset (X,Y) can be replaced by the formula (8 Z)((Z in X) (Z in Y)).
Reference: [45] <author> Hsiang, J. and Dershowitz, N., </author> <title> Rewrite methods for clausal and non-clausal theorem proving, </title> <booktitle> Proc. 10th EATCS Intl. Colloq. on Automata, Languages, and Programming, </booktitle> <address> Barcelona, Spain, </address> <year> 1983. </year>
Reference-contexts: This idea goes back a long way, and a recent use of it may 8 be found in [44] and <ref> [45] </ref>. 2.1 Proof Procedures We now consider methods of deciding whether a formula is valid. Since A is valid iff not (A) is unsatisfiable, it is of equivalent difficulty to decide unsatisfiability.
Reference: [46] <author> Hsiang, J. and Rusinowitch, M., </author> <title> A new method for establishing refutational completeness in theorem proving, </title> <booktitle> Proceedings of the 8th International Conference on Automated Deduction, </booktitle> <editor> J. Siekmann, ed., </editor> <booktitle> Lecture Notes in Computer Science vol. </booktitle> <volume> 230, </volume> <editor> G. Goos and J. Hartmanis, eds. </editor> <publisher> (Springer-Verlag, </publisher> <address> New York, </address> <year> 1986), </year> <pages> pp. 141 - 152. </pages>
Reference-contexts: Thus, paramodulation allows us to dispense with all the equality axioms except x = x. A simpler proof was given by Peterson [78] and more recent and more general proofs are found in Hsiang and Rusinowitch <ref> [46] </ref> and elsewhere. These more recent proofs often show the refinement of restricted versions of paramodulation which considerably reduce the search space. Some early versions of paramodulation required the use of the functionally reflexive axioms, but this is now known not to be necessary.
Reference: [47] <author> Huet, G., </author> <title> A unification algorithm for typed lambda calculus, </title> <note> Theoretical Computer Science 1 (1975) 27-57. </note>
Reference-contexts: One of the more well known provers with some higher order logic capability is the prover of Andrews [65] at Carnegie-Mellon University. This prover uses Huet's unification algorithm <ref> [47] </ref> to unify higher order expressions. Lambda calculus permits higher order functions to be expressed; the lambda-Prolog system of [70] permits lambda calculus expressions to be used. This is valuable because it provides a formalism for bound variables, which are useful for formalising logic and computer programs.
Reference: [48] <author> Hunt, Warren A., FM8501: </author> <title> A Verified Microprocessor, </title> <institution> Institute for Computing Science, The University of Texas at Austin, Austin, Texas 78712, </institution> <type> Technical Report 47, </type> <month> February, </month> <year> 1986, </year> <pages> 254 pp. </pages>
Reference-contexts: These proofs have made use of some specialized methods to handle reasoning about real numbers. Hunt <ref> [48] </ref> has used the Boyer-Moore theorem prover to give a correctness proof for a microcoded central processing unit called the FM8501.
Reference: [49] <author> Jefferson, S. and Plaisted, D., </author> <title> Implementation of an improved relevance criterion, </title> <booktitle> First Conference on Artificial Intelligence Applications, </booktitle> <address> Denver, Colorado, Decem-ber, </address> <year> 1984, </year> <pages> 7 pp. </pages>
Reference-contexts: By looking at theorems proven in the past, it might be possible to select facts likely to be relevant. The relevance criterion of Plaisted [79], implemented by Jef-ferson <ref> [49] </ref>, is another possible approach. This method was strikingly successful in finding relevant clauses from a set of hundreds of input clauses in a couple of common sense reasoning problems, in which the proofs were fairly simple. <p> This idea also can be used to detect and generate relavant instances of a set of clauses. Attempts to extend this methodology to more mathematical problems with longer proofs have not yet been successful. A graph based relevance method such as that of Jefferson and Plaisted <ref> [49] </ref> seems most useful when the proofs are fairly short but there are many input clauses. 7.8. General Software Engineering Issues Since theorem provers are computer programs, general software engineering issues arise in their design.
Reference: [50] <author> Karmakar, N., </author> <title> A new polynomial time algorithm for linear programming, </title> <note> Combi-natorica 4 (1984) 373 - 395. </note>
Reference-contexts: This is called ``Bledsoe real arithmetic'' by Bundy [17]. For this, the simplex method [67] is often used. Recently a polynomial time method was found by Khachian [51], but this method seems to be too slow for practical use. A faster method has been developed by Karmakar <ref> [50] </ref> and seems to be practically useful. A decision procedure for the quantifier-free theory of reals with addition that is based on intervals has been given by Bledsoe [6]; this method often works well on small formulas, though in general it may take exponential time.
Reference: [51] <author> Khachian, L.G., </author> <title> A polynomial algorithm in linear programming, </title> <journal> Doklady Akademii Nauk, USSR, </journal> <note> Nova Seria, 244 (1979) 1093 - 1096, translated in Soviet Mathematics Doklady 20 (1979) 191 - 194. </note>
Reference-contexts: The quantifier-free theory of reals with addition is essentially the same as linear programming. This is called ``Bledsoe real arithmetic'' by Bundy [17]. For this, the simplex method [67] is often used. Recently a polynomial time method was found by Khachian <ref> [51] </ref>, but this method seems to be too slow for practical use. A faster method has been developed by Karmakar [50] and seems to be practically useful.
Reference: [52] <author> Kling, R., </author> <title> A paradigm for reasoning by analogy, </title> <booktitle> Artificial Intelligence 2 (1971) 147-178. </booktitle>
Reference-contexts: One way of learning is learning by analogy: when a theorem is attempted, similar theorems that have been proven in the past may furnish information useful in guiding the search. Early work in this area was done by Kling <ref> [52] </ref>. The Austin group has done some more recent work in this area [16], although the analogies used so far are fairly restrictive and the improvement in search time is not dramatic.
Reference: [53] <author> Korf, R.E., </author> <title> Depth-first iterative deepening: an optimal admissible tree search, </title> <booktitle> Artificial Intelligence 27 (1985) 97 - 109. </booktitle>
Reference: [54] <author> Loveland, D., </author> <title> A simplified format for the model elimination procedure, </title> <journal> J. </journal> <note> ACM 16 (1969) 349 - 363. </note>
Reference-contexts: Still, resolution has many advantages, and is often the strategy of choice. We mention some clausal proof procedures that do implement back chaining. One of the earliest is the model elimination strategy of Loveland <ref> [54] </ref>. This is also a set of support strategy as defined in section 2.1, and permits a flexible ordering of the literals, giving this strategy many advantages.
Reference: [55] <author> Loveland, D., </author> <title> Automated Theorem Proving: A Logical Basis (North-Holland, </title> <address> New York, </address> <year> 1978). </year>
Reference-contexts: The semantic variant of the simplified problem reduction format does not control the cut rule well, 17 however. The semantic modified problem reduction format has all the desired properties, but the fact that the antecedent may contain literals false in I may be a disadvantage. The MESON procedure of <ref> [55] </ref>, related to the model elimination strategy, is a support strategy and controls the cut rule well. However, caching cannot be done as directly with this method, and semantic deletion of subgoals is not possible. This strategy is the one which Stickel [106] has recently implemented so efficiently. <p> However, for a formula with n propositional constants, the storage required is 2 n bits, so the applicability of this method is limited for large n. We now present a possibly original method similar to the semantic tree method <ref> [55] </ref> but with lemma generation; this can dramatically speed it up in some cases. The idea is to check all interpretations and see if any satisfy S. <p> The clause form of this is 32 ffP (a, y)g,f:P (x, b)gg, which represents the conjunction of two clauses, each containing a single literal. The details of this process are given in many standard texts, such as [21] and <ref> [55] </ref>. For a proof that Skolemization preserves satisfiability, see [55]; validity is not necessarily preserved. Note that this process removes the distinction between a set of axioms and the theorem to be proven; all are on a common footing. <p> The clause form of this is 32 ffP (a, y)g,f:P (x, b)gg, which represents the conjunction of two clauses, each containing a single literal. The details of this process are given in many standard texts, such as [21] and <ref> [55] </ref>. For a proof that Skolemization preserves satisfiability, see [55]; validity is not necessarily preserved. Note that this process removes the distinction between a set of axioms and the theorem to be proven; all are on a common footing. Thus, if a theorem is of the form (H R), its negation is of the form (H /n :R). <p> One of the earliest is the model elimination strategy of Loveland [54]. This is also a set of support strategy as defined in section 2.1, and permits a flexible ordering of the literals, giving this strategy many advantages. The MESON procedure of Loveland <ref> [55] </ref> is an adaptation of this strategy that is more like Prolog, and may be viewed as an extension of Prolog to full first order logic. In Plaisted [84], a sequent-style refinement of the MESON procedure is given that is even closer to Prolog in the structure of the proofs.
Reference: [56] <author> Loveland, D., </author> <title> Automated theorem proving: a quarter century review, in Automated Theorem Proving: After 25 Years, </title> <editor> W. Bledsoe and D. Loveland, eds., </editor> <publisher> (American Mathematical Society, </publisher> <address> Providence, RI, </address> <year> 1984), </year> <pages> pp. 1-45. </pages>
Reference-contexts: Still, some interesting proofs have been found. For an excellent survey of the history of theorem proving to 1984 and a collection of papers illustrating the state of the art at that time, see Bledsoe and Loveland [9] and the survey article by Loveland <ref> [56] </ref>. One of the earliest results is from Guard et al [41]. Their interactive semi-automated reasoning program derived a lemma in lattice theory, known as SAM's lemma, which had not been proven previously, and which was the key to an open problem.
Reference: [57] <author> Loveland, D., </author> <title> Near-Horn Prolog, </title> <booktitle> Proceedings of the Fourth International Conference on Logic Programming, </booktitle> <address> Melbourne, Australia, </address> <year> 1987, </year> <pages> pp. 456 - 469. </pages>
Reference-contexts: However, caching cannot be done as directly with this method, and semantic deletion of subgoals is not possible. This strategy is the one which Stickel [106] has recently implemented so efficiently. Loveland's near-Horn Prolog <ref> [57] </ref> permits back chaining and controls the cut rule well. However, it does not seem to be a true support strategy and does not permit semantic deletion. This strategy is intended primarily as a programming language, not a theorem prover. <p> For example, input resolution is complete for Horn clauses. Also, positive resolution without factoring is complete for Horn clauses [42]; this is a strategy in which 40 clauses C 1 and C 2 are resolved only if C 1 or C 2 is a positive unit clause. Loveland <ref> [57] </ref> has developed methods good for near-Horn clauses, that is, clauses having not many positive literals, in the context of logic programming. <p> In fact, this refinement of the MESON procedure may be viewed as a simple, satisfiabil-ity-preserving translation of an arbitrary set of first order clauses into a set of Horn clauses. Loveland's near-Horn Prolog <ref> [57] </ref> has already been mentioned. This permits back chaining but not set of support as defined in section 2.1, and avoids the need for contrapositives. For a definition and discussion of contrapositives, see Plaisted [83].
Reference: [58] <editor> Lusk, E., McCune, W., and Overbeek, R., </editor> <booktitle> ITP at Argonne National Laboratory, 8th International Conference on Automated Deduction, </booktitle> <address> Oxford, England, </address> <year> 1986, </year> <pages> pp. 697 - 698. </pages>
Reference-contexts: One of the earliest results is from Guard et al [41]. Their interactive semi-automated reasoning program derived a lemma in lattice theory, known as SAM's lemma, which had not been proven previously, and which was the key to an open problem. The Argonne prover <ref> [58] </ref> has also solved some open problem in mathematics, with human assistance. Some early examples are given in [115]. Although these problems are mostly fairly obscure, this is still an impressive achievement.
Reference: [59] <author> Malachi, Y., Manna, Z., and Waldinger, R., </author> <title> TABLOG: </title> <booktitle> The deductive-tableau programming language, in ACM Symp. LISP and Functional Prog., </booktitle> <address> Austin, Texas, </address> <year> 1984, </year> <pages> pp. 323-330. </pages>
Reference-contexts: Difficulties with back chaining in the context of resolution have been mentioned in section 2.1. Mathematical induction does not naturally combine with resolution; for example, Manna and Waldinger use a non-clausal proof procedure to allow induction in their TABLOG system <ref> [59] </ref>. Explicit quantifiers are sometimes useful. If a predicate P (x) is defined using quantifiers, say as (9y)Q (x, y), then it is useful to be able 43 to replace occurences of P by their definition. This is not possible if quantifiers are not explicitly represented.
Reference: [60] <author> Malachi, Y., Manna, Z., and Waldinger, </author> <title> R.J., TABLOG: The deductive tableau programming language, in Logic Programming, </title> <editor> D. DeGroot and G. Lindstrom, eds. </editor> <publisher> (Prentice-Hall, </publisher> <address> Englewood Cliffs, N.J., </address> <year> 1986), </year> <pages> pp. 365 - 394. </pages>
Reference-contexts: The lemmas need to be chosen carefully to make proper use of the heuristics used by the program. In this prover, theorems are rewrite rules, nicely constraining the search. Also, general existential quantifiers cannot be used in this prover. The non-clausal theorem prover used in the TABLOG system <ref> [60] </ref> also permits mathematical induction. Another extension is higher order logic, which permits quantification over functions and predicates, and permits some theorems to be stated much more naturally than first order logic.
Reference: [61] <author> Martelli, A., and Montanari, U., </author> <title> An efficient unification algorithm, </title> <journal> ACM Trans. </journal> <note> 67 Programming Languages and Systems 4 (1982) 258 - 282. </note>
Reference-contexts: Thus the number of possible inferences before the search is exhausted is O (c b (d+1) ). Each such inference takes polynomial time at most using typical unification algorithms <ref> [61] </ref>. The total time is O (b k c b (d+1) ) for some k, which is O (a bd ) for some constant a. Since b is n as in the definition of EXPATOM, the first part of the theorem follows.
Reference: [62] <author> McCharen, J., Overbeek, R., and Wos, L., </author> <title> Problems and experiments for and with automated theorem proving programs, </title> <note> IEEE Transactions on Computers C - 25 (1976) 773 - 782. </note>
Reference-contexts: In our work, we have found that caching sometimes helps a lot on hard problems. The Argonne group has had significant success with UR (unit resulting) resolution <ref> [62] </ref> for Horn sets and even for many non-Horn sets. This method is polynomial for propositional Horn sets, but is not entirely a goal directed strategy.
Reference: [63] <author> McCune, W. and Wos, L., </author> <title> A case study in automated theorem proving: finding sages in combinatory logic, </title> <note> Journal of Automated Reasoning 3 (1987) 91 - 107. </note>
Reference-contexts: An open problem in ring theory was recently solved automatically using a special theorem prover developed by Wang [113]. The Argonne group has used their theorem prover to suggest and verify some new results about solutions of equations in com-binatory logic <ref> [63] </ref>. The fast theorem prover OTTER written by McCune found fully automatic proofs of a number of hard theorems in implicational logic. For a list of challenge problems for current theorem provers, see the last four papers in the 1988 International Conference on Automated Deduction [88].
Reference: [64] <author> McRobbie, M., Meyer, R., and Thistlewaite, P., </author> <title> Towards efficient ``knowledge based'' automated theorem proving for non-standard logics, </title> <booktitle> Proceedings of the 9th International Conference on Automated Deduction, </booktitle> <editor> E. Lusk and R. Overbeek, eds., </editor> <booktitle> Lecture Notes in Computer Science vol. </booktitle> <volume> 310, </volume> <editor> G. Goos and J. Hartmanis, eds. </editor> <publisher> (Springer-Verlag, </publisher> <address> New York, </address> <year> 1988), </year> <pages> pp. 197 - 217. </pages>
Reference-contexts: Such systems are attractive for backward chaining reasoning for this reason. For a discussion of these systems, see Gallier [30]. A discussion of the 8 or 9 principle kinds of proof systems is given in <ref> [64] </ref>. ``Natural deduction proofs'' are something like sequent style proofs, except that there are ``discharge'' rules for removing assumptions. In the theorem proving community, the term ``natural deduction'' is sometimes used to refer to any backward chaining, subgoal oriented prover, that is, to any problem reduction format. <p> Human mathematicians often do not attempt to prove a theorem until they are convinced on semantic grounds that it is true. The use of semantics and finite models has been beneficial in nonstandard logic theorem provers <ref> [64] </ref>; the provers mentioned in [64] use a problem reduction format and Gentzen-style proof systems. Wang's hierarchical deduction prover also can use semantics, but it seems to do pretty well without semantics. <p> Human mathematicians often do not attempt to prove a theorem until they are convinced on semantic grounds that it is true. The use of semantics and finite models has been beneficial in nonstandard logic theorem provers <ref> [64] </ref>; the provers mentioned in [64] use a problem reduction format and Gentzen-style proof systems. Wang's hierarchical deduction prover also can use semantics, but it seems to do pretty well without semantics.
Reference: [65] <author> Miller, D., Cohen, E., and Andrews, P.B., </author> <title> A look at TPS, </title> <booktitle> Proceedings of the 6th Conference on Automated Deduction, </booktitle> <editor> D.W. Loveland, ed., </editor> <booktitle> Lecture Notes in Computer Science vol. </booktitle> <volume> 138, </volume> <editor> G. Goos and J. Hartmanis, eds. </editor> <publisher> (Springer-Verlag, </publisher> <address> New York, </address> <year> 1982), </year> <pages> pp. 50 - 69. </pages>
Reference-contexts: Andrews' matings [2] are similar to connection graphs, but do not perform any unifications until a possible proof is found. Andrews <ref> [65] </ref> has implemented a higher order theorem prover using these ideas, and has obtained some impressive results. <p> The Argonne prover [58] has also solved some open problem in mathematics, with human assistance. Some early examples are given in [115]. Although these problems are mostly fairly obscure, this is still an impressive achievement. Andrews' prover <ref> [65] </ref> has some higher order logic capability and has found a fully automatic proof of Cantor's theorem that the powerset of a set is larger than the set, even for infinite sets. It is remarkable that this proof is found in under a minute of computer time. <p> Another extension is higher order logic, which permits quantification over functions and predicates, and permits some theorems to be stated much more naturally than first order logic. One of the more well known provers with some higher order logic capability is the prover of Andrews <ref> [65] </ref> at Carnegie-Mellon University. This prover uses Huet's unification algorithm [47] to unify higher order expressions. Lambda calculus permits higher order functions to be expressed; the lambda-Prolog system of [70] permits lambda calculus expressions to be used.
Reference: [66] <author> Mitchell, T.M., Keller, R.M., and Kedar-Cabelli, S.T., </author> <title> Explanation-bsed generalization: a unifying view, </title> <booktitle> Machine Learning 1 (1986) 47 - 80. </booktitle>
Reference-contexts: Another problem with DFID is to combine it with a priority system. In best-first search it is easy to choose the most promising subgoal at every step and work on it. This is not so easy with depth-first iterative deepening. Some kind of explanation based 53 generalization <ref> [66] </ref> is also useful with back chaining, to ensure that solutions are as general as possible. Another issue with back chaining is to do subgoal reordering intelligently. We found that this can be very important for some problems.
Reference: [67] <author> Mitra, G., Tamiz, M., and Yadegar, J., </author> <title> Experimental investigation of an interior search method within a simplex framework, </title> <address> C. </address> <note> ACM 31 (1988) 1474 - 1482. </note>
Reference-contexts: A proof that any decision procedure for this theory takes nondeterministic exponential time is given in [43]. The quantifier-free theory of reals with addition is essentially the same as linear programming. This is called ``Bledsoe real arithmetic'' by Bundy [17]. For this, the simplex method <ref> [67] </ref> is often used. Recently a polynomial time method was found by Khachian [51], but this method seems to be too slow for practical use. A faster method has been developed by Karmakar [50] and seems to be practically useful.
Reference: [68] <author> Moore, </author> <title> R.C., A formal theory of knowledge and action, </title> <editor> in Hobbs, J.R. and Moore, R.C., eds., </editor> <title> Formal Theories of the Commonsense World (Ablex, </title> <address> Norwood, N.J., </address> <year> 1985). </year>
Reference-contexts: Though his method is not always applicable, it seems to be often applicable on typical problems, and has obtained a number of hard proofs fairly quickly. We mention a number of other specialized methods: Moore <ref> [68] </ref> has found a way to encode logics of knowledge and belief in first order logic, making it possible to use first order systems to reason about knowledge and belief. Some decision procedures for fragments of set theory have been developed; see for example [19].
Reference: [69] <author> Moser, L., </author> <title> A decision procedure for unquantified formulas of graph theory, </title> <booktitle> Proceedings of the 9th International Conference on Automated Deduction, </booktitle> <editor> E. Lusk and R. Overbeek, eds., </editor> <booktitle> Lecture Notes in Computer Science vol. </booktitle> <volume> 310, </volume> <editor> G. Goos and J. Hartmanis, eds. </editor> <publisher> (Springer-Verlag, </publisher> <address> New York, </address> <year> 1988), </year> <pages> pp. 344 - 357. </pages>
Reference-contexts: Some decision procedures for fragments of set theory have been developed; see for example [19]. A decision procedure for some graph theory formulas is given in Moser <ref> [69] </ref>. A method of representing modal logic statements in first order logic with a special unification procedure is presented in Ohlbach [75]. Decision procedures for a number of temporal logics are known; see for example [100].
Reference: [70] <author> Nadathur, G. and Miller, D., </author> <title> An overview of lambda Prolog, </title> <booktitle> in 5th International Logic Programming Conference, </booktitle> <address> Seattle, Wash., </address> <month> August, </month> <year> 1988, </year> <pages> pp. 810 - 827. </pages>
Reference-contexts: One of the more well known provers with some higher order logic capability is the prover of Andrews [65] at Carnegie-Mellon University. This prover uses Huet's unification algorithm [47] to unify higher order expressions. Lambda calculus permits higher order functions to be expressed; the lambda-Prolog system of <ref> [70] </ref> permits lambda calculus expressions to be used. This is valuable because it provides a formalism for bound variables, which are useful for formalising logic and computer programs.
Reference: [71] <author> Nelson, G., </author> <title> Combining satisfiability procedures by equality sharing, in Automated Theorem Proving: After 25 Years, </title> <editor> W. Bledsoe and D. Loveland, eds., </editor> <booktitle> Contemporary Mathematics, </booktitle> <volume> Vol. 29, </volume> <publisher> American Mathematical Society, </publisher> <pages> pp. 201 - 211. </pages>
Reference-contexts: Often quantifier-free formulas are studied; these are prenex normal form formulas in which all variables are universally quantified. For such formulas the 50 validity problem is often much easier than for formulas with an arbitrary quantifier structure. Also, some general results are known <ref> [76, 71] </ref> about decision procedures for combinations of decidable theories. When specialized methods can be used, they are typically much more efficient than general first-order proof procedures. However, the cost for using them is the extra complexity of including a number of specialized decision procedures in a theorem prover. <p> All these theories permit uninterpreted function symbols. For a discussion of these theories see [43]. Under fairly general conditions, the combination of two theories is decidable if the two theories are decidable separately [72]. For an easy description of a method for deciding combinations of theories, see Nelson <ref> [71] </ref>. If the theories have the property of ``convexity,'' this method is especially efficient. For another method of combining decision procedures using rewrite rules, see Shostak 51 A decision procedure for a subclass of elementary geometry was recently developed by Wu [121].
Reference: [72] <author> Nelson, G. and Oppen, D., </author> <title> Simplification by cooperating decision procedures, </title> <booktitle> ACM Transactions on Programming Languages and Systems 1 (1979) 245-257. </booktitle>
Reference-contexts: All these theories permit uninterpreted function symbols. For a discussion of these theories see [43]. Under fairly general conditions, the combination of two theories is decidable if the two theories are decidable separately <ref> [72] </ref>. For an easy description of a method for deciding combinations of theories, see Nelson [71]. If the theories have the property of ``convexity,'' this method is especially efficient.
Reference: [73] <author> Nelson, G. and Oppen, D. </author> <title> Fast decision procedures based on congruence closure, </title> <journal> J. </journal> <note> ACM 27(1980)356 - 364. </note>
Reference-contexts: This is like the reals with addition except that the domain is the integers instead of the reals. This is decidable, but requires nondeterministic double exponential time to decide [29]. Other decidable theories include the theory of equality <ref> [73] </ref>, in which the only predicate is =, the theory of lisp list structure, and the theory of arrays. All these theories permit uninterpreted function symbols. For a discussion of these theories see [43].
Reference: [74] <author> Nilsson, </author> <title> N.J., </title> <booktitle> Principles of Artificial Intelligence (Tioga, </booktitle> <address> Palo Alto, Calif., </address> <year> 1980). </year>
Reference-contexts: Now, back chaining is not complete without a proper search strategy because it is possible to get into infinite loops and miss the proof. Therefore something like breadth-first search, best-first search, or depth-first iterative deepening [53,107] is needed. See <ref> [74] </ref> for a discussion of search methods.
Reference: [75] <author> Ohlbach, H., </author> <title> A resolution calculus for modal logics, </title> <booktitle> Proceedings of the 9th International Conference on Automated Deduction, </booktitle> <editor> E. Lusk and R. Overbeek, eds., </editor> <booktitle> Lecture Notes in Computer Science vol. </booktitle> <volume> 310, </volume> <editor> G. Goos and J. Hartmanis, eds. </editor> <publisher> (Springer-Verlag, </publisher> <address> New York, </address> <year> 1988), </year> <pages> pp. 500 - 516. </pages>
Reference-contexts: Some decision procedures for fragments of set theory have been developed; see for example [19]. A decision procedure for some graph theory formulas is given in Moser [69]. A method of representing modal logic statements in first order logic with a special unification procedure is presented in Ohlbach <ref> [75] </ref>. Decision procedures for a number of temporal logics are known; see for example [100].
Reference: [76] <author> Oppen, D., </author> <title> Complexity, convexity, and combinations of theories, </title> <note> Theoretical Computer Science 12 (1980) 291 - 302. </note>
Reference-contexts: Often quantifier-free formulas are studied; these are prenex normal form formulas in which all variables are universally quantified. For such formulas the 50 validity problem is often much easier than for formulas with an arbitrary quantifier structure. Also, some general results are known <ref> [76, 71] </ref> about decision procedures for combinations of decidable theories. When specialized methods can be used, they are typically much more efficient than general first-order proof procedures. However, the cost for using them is the extra complexity of including a number of specialized decision procedures in a theorem prover.
Reference: [77] <author> Overbeek, R., </author> <title> A new class of automated theorem-proving algorithms, </title> <journal> J. </journal> <note> ACM 21 (1974) 191-200. </note>
Reference-contexts: It is not clear at this point how efficient this method is compared to resolution. Another novel equality-based method is that of Overbeek <ref> [77] </ref>, which involves an efficient enumeration of the set of ground instances of a set of clauses using equations to simplify as much as possible. This method performs impressively well on some examples. Finally, there are many methods that are not based on anything similar to clause form.
Reference: [78] <author> Peterson, G.E., </author> <title> A technique for establishing completeness results in theorem 68 proving with equality, </title> <note> SIAM J. Computing 12 (1983) 82-100. </note>
Reference-contexts: Thus, paramodulation allows us to dispense with all the equality axioms except x = x. A simpler proof was given by Peterson <ref> [78] </ref> and more recent and more general proofs are found in Hsiang and Rusinowitch [46] and elsewhere. These more recent proofs often show the refinement of restricted versions of paramodulation which considerably reduce the search space.
Reference: [79] <author> Plaisted, D., </author> <title> An efficient relevance criterion for mechanical theorem proving, </title> <booktitle> Proceedings of the First Annual National Conference on Artificial Intelligence, </booktitle> <address> Stan-ford University, </address> <month> August, </month> <year> 1980, </year> <pages> pp. 79-83. </pages>
Reference-contexts: Set of support methods tend to choose relevant facts because they only perform inferences that depend on the theorem, directly or indirectly. By looking at theorems proven in the past, it might be possible to select facts likely to be relevant. The relevance criterion of Plaisted <ref> [79] </ref>, implemented by Jef-ferson [49], is another possible approach. This method was strikingly successful in finding relevant clauses from a set of hundreds of input clauses in a couple of common sense reasoning problems, in which the proofs were fairly simple.
Reference: [80] <author> Plaisted, D., </author> <title> Theorem proving with abstraction, </title> <booktitle> Artificial Intelligence 16 (1981) 47 - 108. </booktitle>
Reference-contexts: Even if Q is solved, it is possible that the solutions to Q will fail to map back to a solution to P. Still, the idea seems attractive. Some early work in this area was done by Sacerdoti [93] and Plaisted <ref> [80] </ref>. Another method of abstraction was given in Plaisted [82]. More recently, D. Plummer has used abstractions to help decide which definitions will be useful in proving a theorem, with moderate success.
Reference: [81] <author> Plaisted, D., </author> <title> A simplified problem reduction format, </title> <booktitle> Artificial Intelligence 18 (1982) 227-261. </booktitle>
Reference-contexts: For Horn clauses, these methods are essentially the same as Prolog-style back chaining. We discuss a number of systems but only give the inference rules for one, for the sake of brevity. The ``simplified problem reduction format'' of <ref> [81] </ref> has one inference rule per clause. This is essentially a sequent style system in which the sequents are of the form ! L where is a list of positive literals and L is a positive literal. <p> Loveland's near-Horn Prolog [57] has already been mentioned. This permits back chaining but not set of support as defined in section 2.1, and avoids the need for contrapositives. For a definition and discussion of contrapositives, see Plaisted [83]. Similar methods are given in [83] and <ref> [81] </ref>, where the emphasis is on complete theorem proving strategies rather than logic programming languages using depth-first search. There are a number of connection-graph based methods that perform the search in a completely different way, keeping track of possible unifications or ``connections'' between literals.
Reference: [82] <author> Plaisted, D., </author> <title> Abstraction using generalization functions, </title> <booktitle> Eighth Conference on Automated Deduction, </booktitle> <address> Oxford, England, </address> <month> July, </month> <year> 1986. </year>
Reference-contexts: Still, the idea seems attractive. Some early work in this area was done by Sacerdoti [93] and Plaisted [80]. Another method of abstraction was given in Plaisted <ref> [82] </ref>. More recently, D. Plummer has used abstractions to help decide which definitions will be useful in proving a theorem, with moderate success. It is also possible to use more than one abstraction at the same time, or to use more than one level of abstraction.
Reference: [83] <author> Plaisted, D., </author> <title> Non-Horn clause logic programming without contrapositives, </title> <note> Journal of Automated Reasoning 4 (1988) 287 - 325. </note>
Reference-contexts: This system permits semantic deletion and back chaining with caching, but is not a genuine support strategy. Also, the cut rule is not well controlled. The ``modified problem reduction format'' of <ref> [83] </ref> is an attempt to improve on the simplified problem reduction format by controlling the cut rule better. This system implements back chaining with caching and semantic deletion, and the cut rule is controlled. However, the system is not a genuine support strategy. <p> Loveland's near-Horn Prolog [57] has already been mentioned. This permits back chaining but not set of support as defined in section 2.1, and avoids the need for contrapositives. For a definition and discussion of contrapositives, see Plaisted <ref> [83] </ref>. Similar methods are given in [83] and [81], where the emphasis is on complete theorem proving strategies rather than logic programming languages using depth-first search. <p> Loveland's near-Horn Prolog [57] has already been mentioned. This permits back chaining but not set of support as defined in section 2.1, and avoids the need for contrapositives. For a definition and discussion of contrapositives, see Plaisted <ref> [83] </ref>. Similar methods are given in [83] and [81], where the emphasis is on complete theorem proving strategies rather than logic programming languages using depth-first search. There are a number of connection-graph based methods that perform the search in a completely different way, keeping track of possible unifications or ``connections'' between literals. <p> The NuPrl system at Cornell [23] is used for program development in a constructive logic, and is more a proof checker than a proof finder. It permits the user to specify methods to be applied to subgoals of various forms. The Prolog theorem prover of Plaisted <ref> [83] </ref> uses true back chaining, depth-first iterative deepening, and caching of solutions to subgoals to avoid repeated work. This prover solves almost as many problems as does Stickel's prover from his test set [106], but usually takes longer.
Reference: [84] <author> Plaisted, D., </author> <title> A sequent style model elimination strategy and a positive refinement, </title> <month> May, </month> <year> 1988, </year> <note> to appear in Journal of Automated Reasoning. </note>
Reference-contexts: The MESON procedure of Loveland [55] is an adaptation of this strategy that is more like Prolog, and may be viewed as an extension of Prolog to full first order logic. In Plaisted <ref> [84] </ref>, a sequent-style refinement of the MESON procedure is given that is even closer to Prolog in the structure of the proofs.
Reference: [85] <author> Plaisted, D., and Greenbaum, S., </author> <title> A structure-preserving clause form translation, </title> <note> Journal of Symbolic Computation 2 (1986) 293 - 304. </note>
Reference-contexts: There are, however, disadvantages with clause form. The conversion to clause form can increase the size of a formula by an exponential amount. This can be avoided by introducing new propositional constants; for a discussion of this see for example <ref> [85] </ref>. Another disadvantage is that the structure of a formula is sometimes helpful in guiding the search for a proof; this structure is largely lost by the conversion to clause form. So, it is not evident that clause form is always the right representation of a formula. <p> The conversion to clause form often destroys the structure of a formula, and this structure can be important. The conversion to clause form can increase the size of a formula by an exponential amount, but this can be avoided by adding new predicate symbols <ref> [85] </ref>. Difficulties with back chaining in the context of resolution have been mentioned in section 2.1. Mathematical induction does not naturally combine with resolution; for example, Manna and Waldinger use a non-clausal proof procedure to allow induction in their TABLOG system [59]. Explicit quantifiers are sometimes useful.
Reference: [86] <author> Plotkin, G.D., </author> <title> Building-in equational theories, Machine Intelligence 7 (Meltzer and Michie, </title> <editor> eds.), </editor> <publisher> Halsted Press, </publisher> <address> New York, </address> <year> 1972, </year> <pages> 73 - 90. </pages>
Reference-contexts: These are formally equivalent to first order clauses having at least one equality literal, but concepts similar to demodulation can be extended to them as well [122]. Still another approach to equality is to build an equational theory into the unification procedure. This idea was suggested by Plotkin <ref> [86] </ref>, and leads to fairly efficient theorem provers. However, this approach also increases the complexity of the prover, and a large number of unification procedures for various equational theories are known [98,99]. Recent work has concerned systematic methods for combining unification algorithms for various theories; see for example [94].
Reference: [87] <author> Potter, R. and Plaisted, D., </author> <title> Term rewriting: some experimental results, </title> <booktitle> Proceedings of the 9th International Conference on Automated Deduction, </booktitle> <editor> E. Lusk and R. Overbeek, eds., </editor> <booktitle> Lecture Notes in Computer Science vol. </booktitle> <volume> 310, </volume> <editor> G. Goos and J. Hart-manis, eds. </editor> <publisher> (Springer-Verlag, </publisher> <address> New York, </address> <year> 1988), </year> <pages> pp. 435 - 453. </pages>
Reference-contexts: This is not possible if quantifiers are not explicitly represented. A method that comes close, however, is given in Potter and Plaisted <ref> [87] </ref>. The set of support restriction is often essential, but it is not complete when used together with P1 deduction or hyper-resolution or locking resolution. Still, resolution has many advantages, and is often the strategy of choice. We mention some clausal proof procedures that do implement back chaining. <p> One way to partially overcome this problem in a quantifier-free setting is given in Potter and Plaisted <ref> [87] </ref>. Also, it is not always best to replace predicates by their definitions, since this can unnecessarily complicate the search. 7.3 Priorities The use of priorities to control the search is also important. <p> By incorporating a priority system to favor small subgoals, we can obtain three moderately hard theorems that we cannot prove otherwise. This prover also has specialized inference rules for equality and rewriting. Richard Potter <ref> [87] </ref> has obtained a number of simple set theory theorems automatically on this prover using a special method of rewriting. We have also found an automatic subgoal reordering method which reduces the average proof time for the examples we have tested.
Reference: [88] <institution> Proceedings of the 9th International Conference on Automated Deduction, </institution> <note> E. </note> <editor> Lusk and R. Overbeek, eds., </editor> <booktitle> Lecture Notes in Computer Science vol. </booktitle> <volume> 310, </volume> <editor> G. Goos and J. Hartmanis, eds. </editor> <publisher> (Springer-Verlag, </publisher> <address> New York, </address> <year> 1988), </year> <pages> pp. 704 - 734. </pages>
Reference-contexts: The fast theorem prover OTTER written by McCune found fully automatic proofs of a number of hard theorems in implicational logic. For a list of challenge problems for current theorem provers, see the last four papers in the 1988 International Conference on Automated Deduction <ref> [88] </ref>. It appears that theorem provers can be respectable aids to human mathematicians, although most of the significant results still require careful user guidance. 6. Specialized Decision Procedures We now discuss a number of specialized decision procedures.
Reference: [89] <author> Quaife, A., </author> <title> Automated proofs of L .. ob's theorem and G .. odel's two incompleteness theorems, </title> <journal> J. </journal> <note> Automated Reasoning 4 (1988) 219 - 231. </note>
Reference-contexts: Using techniques based on rewrite rules, Stickel [104] found an automatic and natural proof that in a ring, if x 3 = x for all x, then the ring is commutative. Some incompleteness results in logic have been found fairly automatically on the Argonne prover <ref> [89] </ref>. An open problem in ring theory was recently solved automatically using a special theorem prover developed by Wang [113]. The Argonne group has used their theorem prover to suggest and verify some new results about solutions of equations in com-binatory logic [63].
Reference: [90] <author> Rabinov, A., </author> <title> A restriction of factoring in binary resolution, </title> <booktitle> Proceedings of the 9th International Conference on Automated Deduction, </booktitle> <editor> E. Lusk and R. Overbeek, eds., </editor> <booktitle> Lecture Notes in Computer Science vol. </booktitle> <volume> 310, </volume> <editor> G. Goos and J. Hartmanis, eds. </editor> <publisher> (Springer-Verlag, </publisher> <address> New York, </address> <year> 1988), </year> <pages> pp. 582 - 591. </pages>
Reference-contexts: An equivalence between unit and input resolution is mentioned in [20]. There are also restrictions on factoring. These are restrictions on the size of the subsets of resolution or their contents. A particularly severe but still complete restriction is given in <ref> [90] </ref>. For P1 deduction, it is never necessary that a subset of resolution consisting of negative literals, contain more than one literal, for example. 4.3. Specialized Strategies We now discuss theorem proving strategies suitable for certain subclasses of first order logic.
Reference: [91] <author> Robinson, J., </author> <title> A machine oriented logic based on the resolution principle, </title> <journal> J. </journal> <note> ACM 12 (1965) 23-41. </note>
Reference-contexts: There are a fair number of algorithms known for finding most general unifiers. Probably the earliest unification algorithm known to computer science was due to Robinson <ref> [91] </ref>, although unification was known earlier. The algorithm we present in figure 6 is one of the simplest such algorithms, while also permitting a reasonably efficient implementation. Our algorithm is based on an equation solving paradigm. Suppose we are unifying two literals L and M.
Reference: [92] <author> Robinson, J., </author> <title> Automatic deduction with hyper-resolution, </title> <journal> Int. J. Comput. Math. </journal> <month> 1 </month> <year> (1965) </year> <month> 227-234. </month>
Reference-contexts: Theorem 6. If S is unsatisfiable then there is a resolution refutation from S in which each resolution is between clauses C 1 and C 2 such that C 1 is positive or C 2 is positive. This strategy is called P1-deduction <ref> [92] </ref> or positive resolution. Similarly, one can define negative resolution and prove its completeness; more general such restrictions can also be defined. <p> The set of support strategy of [117] is a way of getting nearly the same effect without the need to use I explicitly. A sequence of positive resolutions can be combined into a hyper-resolution <ref> [92] </ref>, which avoids explicitly generating intermediate results. This strategy is often used by the Argonne group. Many refinements are based on some method of ordering the literals in a clause and restricting resolution so that the subset of resolution may only contain clauses that are maximal in the ordering. <p> There is some advantage in using larger inference steps, since then fewer intermediate lemmas will be saved and the search space will not grow so rapidly. Hyper-resolution <ref> [92] </ref> is one way of doing this to some extent. Another such approach is the linked inference of [119]. The theory resolution of Stickel [105] is also a realization of this concept. 7.7 Relevance Tests Choosing relevant axioms is also essential for a mechanical theorem prover.
Reference: [93] <author> Sacerdoti, E., </author> <title> Planning in a hierarchy of abstraction spaces, </title> <booktitle> Artificial Intelligence 5 (1974) 115-135. </booktitle>
Reference-contexts: Even if Q is solved, it is possible that the solutions to Q will fail to map back to a solution to P. Still, the idea seems attractive. Some early work in this area was done by Sacerdoti <ref> [93] </ref> and Plaisted [80]. Another method of abstraction was given in Plaisted [82]. More recently, D. Plummer has used abstractions to help decide which definitions will be useful in proving a theorem, with moderate success.
Reference: [94] <author> Schmidt-Schauss, M., </author> <title> Unification in a combination of arbitrary disjoint equational theories, </title> <booktitle> Proceedings of the 9th International Conference on Automated Deduction, </booktitle> <editor> E. Lusk and R. Overbeek, eds., </editor> <booktitle> Lecture Notes in Computer Science vol. </booktitle> <volume> 310, </volume> <editor> G. Goos and J. Hartmanis, eds. </editor> <publisher> (Springer-Verlag, </publisher> <address> New York, </address> <year> 1988), </year> <pages> pp. 378 - 396. </pages>
Reference-contexts: However, this approach also increases the complexity of the prover, and a large number of unification procedures for various equational theories are known [98,99]. Recent work has concerned systematic methods for combining unification algorithms for various theories; see for example <ref> [94] </ref>. Another paper in this volume deals with equational unification. There are also a number of other equality-based theorem proving methods, such as equality-based binary resolution [26]. 4.4 Other Proof Procedures There are some problems with resolution style proof precedures as we have described them.
Reference: [95] <author> Shankar, N., </author> <title> A mechanical proof of the Church-Rosser theorem, </title> <journal> J. </journal> <note> ACM 35 (1988) 475 - 522. </note>
Reference-contexts: This prover has also been used (with human guidance) to prove mathematical theorems [12], such as the law of quadratic 49 reciprocity in number theory, G .. odel's incompleteness theorem, the Church-Rosser theorem for term rewriting systems <ref> [95] </ref>, and the unsolvability of the halting problem for lisp programs. In addition, a property of the RSA encryption algorithm has been shown on this prover.
Reference: [96] <author> Shostak, R., Schwartz, R., and Melliar-Smith, </author> <title> P.M., STP: a mechanizable logic for specification and verification, </title> <booktitle> Proceedings of the 6th Conference on Automated 69 Deduction, </booktitle> <editor> D.W. Loveland, ed., </editor> <booktitle> Lecture Notes in Computer Science vol. </booktitle> <volume> 138, </volume> <editor> G. Goos and J. Hartmanis, eds. </editor> <publisher> (Springer-Verlag, </publisher> <address> New York, </address> <year> 1982), </year> <pages> pp. 32 - 49 </pages>
Reference-contexts: A number of applications of automated reasoning systems are already in existence. For example, program verifiers have been used to verify fairly complex programs. Examples of such verifiers include SRI's STP verifier <ref> [96] </ref>, Stanford's verifier [108], and the Gypsy verifier [36] at the University of Texas at Austin.
Reference: [97] <author> Shostak, R.E., </author> <title> Deciding combinations of theories, </title> <journal> J. </journal> <note> ACM 31 (1984) 1 - 12. </note>
Reference: [98] <author> Siekmann, J, </author> <title> Unification theory, </title> <booktitle> Proceedings of European Conference on Artificial Intelligence, </booktitle> <year> 1986. </year>
Reference: [99] <author> Siekmann, J. and Szabo, P., </author> <title> Universal unification and a classification of equational theories, </title> <booktitle> 6th Conference on Automated Deduction, </booktitle> <address> New York, </address> <year> 1982, </year> <note> in Lecture Notes in Computer Science 138, </note> <editor> G. Goos and J. Hartmanis, eds. </editor> <publisher> (Springer-Verlag, </publisher> <address> New York, </address> <year> 1982), </year> <pages> pp. 369-389. </pages>
Reference: [100] <author> Sistla, A.P. and Clarke, </author> <title> E.M., The complexity of propositional linear temporal logics, </title> <journal> J. </journal> <note> ACM 32 (1985) 733 - 749. </note>
Reference-contexts: A decision procedure for some graph theory formulas is given in Moser [69]. A method of representing modal logic statements in first order logic with a special unification procedure is presented in Ohlbach [75]. Decision procedures for a number of temporal logics are known; see for example <ref> [100] </ref>. Special unification algorithms are often used to deal with particular sets of equations in theorem provers, the most notable being associative and commutative operators [103], but the technique is much more general than this; see another chapter in the present volume for a more detailed discussion of equational unification.
Reference: [101] <author> Slagle, J.R., </author> <title> Automatic theorem proving with renamable and semantic resolution, </title> <journal> J. </journal> <note> ACM 14 (1967) 687 - 697. </note>
Reference-contexts: For example, for an arbitrary interpretation I, one can require that when two clauses C 1 and C 2 are resolved, one of them must be false in I. This is the ``semantic resolution'' of <ref> [101] </ref>. If I is chosen as a standard model of the axioms of the theory being considered, this restriction prevents axioms from resolving together. <p> One such ordering is to order literals by their predicate symbols, some predicate symbols being considered as ``smaller than'' others. The A-orderings of <ref> [101] </ref> are another ordering method. For P1 deduction, it is possible to use 39 such orderings in a different way.
Reference: [102] <author> Smith, M. and Plaisted, D., </author> <title> Term-rewriting techniques for logic programming I: completion, </title> <type> Report No. </type> <institution> TR88 - 019, University of North Carolina at Chapel Hill, </institution> <month> April, </month> <year> 1988. </year>
Reference-contexts: Therefore it is often better to use specialized methods for equality. We have found, however, that for one prover, the equality axioms performed better than specialized methods on some problems from combinatory logic <ref> [102] </ref>. Some specialized methods require the use of the following ``functionally reflexive'' axioms for each function symbol f: f (x 1 ... x n ) = f (x 1 ... x n ) Such axioms, being instances of x = x, should be avoided when possible.
Reference: [103] <author> Stickel, M., </author> <title> A unification algorithm for associative-commutative functions, </title> <journal> J. </journal> <note> ACM 28 (1981)423 - 434. </note>
Reference-contexts: Decision procedures for a number of temporal logics are known; see for example [100]. Special unification algorithms are often used to deal with particular sets of equations in theorem provers, the most notable being associative and commutative operators <ref> [103] </ref>, but the technique is much more general than this; see another chapter in the present volume for a more detailed discussion of equational unification.
Reference: [104] <author> Stickel, M., </author> <title> A case study of theorem proving by the Knuth-Bendix Method: discovering that x 3 = x implies ring commutativity, </title> <booktitle> Proceedings of the 7th Conference in Automated Deduction, </booktitle> <editor> R. Shostak, ed., </editor> <booktitle> Lecture Notes in Computer Science 170, </booktitle> <editor> G. Goos and J. Hartmanis, eds. </editor> <publisher> (Springer-Verlag, </publisher> <address> New York, </address> <year> 1984), </year> <pages> pp. 248-258. </pages>
Reference-contexts: In addition, a property of the RSA encryption algorithm has been shown on this prover. Using techniques based on rewrite rules, Stickel <ref> [104] </ref> found an automatic and natural proof that in a ring, if x 3 = x for all x, then the ring is commutative. Some incompleteness results in logic have been found fairly automatically on the Argonne prover [89].
Reference: [105] <author> Stickel, M., </author> <title> Automated deduction by theory resolution, </title> <note> Journal of Automated Reasoning 1 (1985) 333 - 355. </note>
Reference-contexts: Hyper-resolution [92] is one way of doing this to some extent. Another such approach is the linked inference of [119]. The theory resolution of Stickel <ref> [105] </ref> is also a realization of this concept. 7.7 Relevance Tests Choosing relevant axioms is also essential for a mechanical theorem prover.
Reference: [106] <author> Stickel, M., </author> <title> A PROLOG technology theorem prover: implementation by an extended PROLOG compiler, </title> <booktitle> Proceedings of the Eight International Conference in Automated Deduction, </booktitle> <address> Oxford, England, </address> <month> July </month> <year> 1986, </year> <pages> pp. 573-587. </pages>
Reference-contexts: The MESON procedure of [55], related to the model elimination strategy, is a support strategy and controls the cut rule well. However, caching cannot be done as directly with this method, and semantic deletion of subgoals is not possible. This strategy is the one which Stickel <ref> [106] </ref> has recently implemented so efficiently. Loveland's near-Horn Prolog [57] permits back chaining and controls the cut rule well. However, it does not seem to be a true support strategy and does not permit semantic deletion. This strategy is intended primarily as a programming language, not a theorem prover. <p> The Prolog theorem prover of Plaisted [83] uses true back chaining, depth-first iterative deepening, and caching of solutions to subgoals to avoid repeated work. This prover solves almost as many problems as does Stickel's prover from his test set <ref> [106] </ref>, but usually takes longer. By incorporating a measure of proof complexity similar to that of Wang, we are able to find proofs for many of his theorems too, such as gcd, lcm, and am8.
Reference: [107] <author> Stickel, M. and Tyson, W.M., </author> <title> An analysis of consecutively bounded depth-first search with applications in automated deduction. </title> <booktitle> Proceedings of the Ninth International Joint Conference on Artificial Intelligence, </booktitle> <address> Los Angeles, California, </address> <month> August, </month> <year> 1985, </year> <pages> pp. 1073 - 1075. </pages>
Reference: [108] <author> Suzuki, N., </author> <title> Verifying programs by algebraic and logical reduction, </title> <booktitle> Proceedings of International Conference on Reliable Software, </booktitle> <address> Los Angeles, California, </address> <month> April, </month> <year> 1975, </year> <pages> pp. 473 - 481. </pages>
Reference-contexts: A number of applications of automated reasoning systems are already in existence. For example, program verifiers have been used to verify fairly complex programs. Examples of such verifiers include SRI's STP verifier [96], Stanford's verifier <ref> [108] </ref>, and the Gypsy verifier [36] at the University of Texas at Austin.
Reference: [109] <author> Tarski, A., </author> <title> A Decision Method for Ordinary Algebra and Geometry, </title> <institution> (University of California Press, </institution> <year> 1951). </year>
Reference-contexts: The standard interpretation is assumed. This theory essentially involves statements of the form p (x) 0, where p is a polynomial, and was shown to be decidable by Tarski <ref> [109] </ref>. A recent, more efficient decision procedure for this problem is given in [40]. Another decidable theory is that of reals with addition, which is as above except that the multiplication operator may not appear.
Reference: [110] <author> Van Gelder, A., </author> <title> A satisfiability tester for non-clausal propositional calculus, </title> <booktitle> Proceedings of the 7th International Conference on Automated Deduction, </booktitle> <editor> R. E. Shostak, ed., </editor> <booktitle> Lecture Notes in Computer Science vol. </booktitle> <volume> 170, </volume> <editor> G. Goos and J. Hartma-nis, eds. </editor> <publisher> (Springer-Verlag, </publisher> <address> New York, </address> <year> 1984). </year>
Reference-contexts: There are also some refinements: If fPg or fnot (P)g is a clause then only one case for P needs to be considered. Similarly, if P only occurs positively or negatively, only one case for P needs to be considered. Van Gelder <ref> [110] </ref> has developed a method that may be considered as a generalization of the Davis and Put-nam method to non-clausal formulas. This method runs in approximately O (2 .25n ) time for a formula with n occurrences of propositions. Another interesting and novel method is that of Bledsoe [7].
Reference: [111] <author> Walther, C., </author> <title> Schubert's Steamroller a case study in many sorted resolution, </title> <type> technical report, </type> <institution> Institut for Informatik, </institution> <month> May, </month> <year> 1984. </year>
Reference-contexts: For a general discussion of sorts in theorem proving, see [112]; for an example of increased efficiency due to sorts, see <ref> [111] </ref>. A theoretical discussion is given in [3]. Another extension is mathematical induction. Certain theorems are not provable without mathematical induction. For example, in first order logic it is not possible to prove that addition is commutative from the axioms defining addition in terms of the successor relation.
Reference: [112] <author> Walther, C., </author> <title> A Many-sorted Calculus Based on Resolution and Paramodulation, </title> <booktitle> Research Notes in Artificial Intelligence (Kaufmann, </booktitle> <address> Los Altos, Calif., </address> <year> 1987). </year>
Reference-contexts: One extension is that of sorts and order sorted algebra. The use of sorts can significantly improve the efficiency of a theorem prover, as well as permitting simpler axiomatizations, although order sorted logic requires a more complicated unification algorithm. For a general discussion of sorts in theorem proving, see <ref> [112] </ref>; for an example of increased efficiency due to sorts, see [111]. A theoretical discussion is given in [3]. Another extension is mathematical induction. Certain theorems are not provable without mathematical induction.
Reference: [113] <author> Wang, </author> <title> T.C., Elements of Z module reasoning, </title> <booktitle> Proceedings of the 9th International 70 Conference on Automated Deduction, </booktitle> <editor> E. Lusk and R. Overbeek, eds., </editor> <booktitle> Lecture Notes in Computer Science vol. </booktitle> <volume> 310, </volume> <editor> G. Goos and J. Hartmanis, eds. </editor> <publisher> (Springer-Verlag, </publisher> <address> New York, </address> <year> 1988), </year> <pages> pp. 21 - 40. </pages>
Reference-contexts: Some incompleteness results in logic have been found fairly automatically on the Argonne prover [89]. An open problem in ring theory was recently solved automatically using a special theorem prover developed by Wang <ref> [113] </ref>. The Argonne group has used their theorem prover to suggest and verify some new results about solutions of equations in com-binatory logic [63]. The fast theorem prover OTTER written by McCune found fully automatic proofs of a number of hard theorems in implicational logic. <p> For an easy introduction to this method, see Chou [22]. Wu's method has also been used to generate theorems in geometry. Wang <ref> [113] </ref> has recently developed a specialized theorem proving method for ring theory, and using it he has solved an open problem in this area. Though his method is not always applicable, it seems to be often applicable on typical problems, and has obtained a number of hard proofs fairly quickly.
Reference: [114] <author> Wang, </author> <title> T.C. and Bledsoe, W.W., Hierarchical deduction, </title> <note> Journal of Automated Reasoning 3 (1987) 35 - 77. </note>
Reference-contexts: The Argonne provers generally permit the user to assign these weights. Another good idea is to prefer clauses containing function symbols and predicates that occur in the theorem, since they are more likely to be relevant. The hierarchical deduction prover of Wang <ref> [114] </ref> has an especially interesting priority structure. It measures the complexity of a proof by taking into account how the variables are bound in the unifications. This gives a fairly natural and intuitive measure of proof complexity which enables this prover to get some fairly hard problems automatically. <p> Many of the proofs found by Bledsoe's provers were obtained using rewrite rules, and some of them also required specialized inference rules or heuristics for inequalities or limits. T. C. Wang has implemented a hierarchical deduction prover <ref> [114] </ref>, which is essentially a combination of locking resolution [10] and set of support. This prover has obtained some impressive proofs fully automatically, without any specialized inference rules. His prover has a fairly sophisticated measure of proof complexity, which is largely responsible for its success.
Reference: [115] <author> Winker, S., </author> <title> Generation and verification of finite models and counterexamples using an automated theorem prover answering two open questions, </title> <journal> J. </journal> <note> ACM 29 (1982) 273 - 284. </note>
Reference-contexts: The Argonne prover [58] has also solved some open problem in mathematics, with human assistance. Some early examples are given in <ref> [115] </ref>. Although these problems are mostly fairly obscure, this is still an impressive achievement. Andrews' prover [65] has some higher order logic capability and has found a fully automatic proof of Cantor's theorem that the powerset of a set is larger than the set, even for infinite sets.
Reference: [116] <author> Wos, L., Overbeek, R., Lusk, E., and Boyle, J., </author> <title> Automated Reasoning: Introduction and Applications (Prentice-Hall, </title> <address> New Jersey, </address> <year> 1984). </year>
Reference: [117] <author> Wos, L., Robinson, G., and Carson, D., </author> <title> Efficiency and completeness of the set of support strategy in theorem proving, </title> <journal> J. </journal> <note> ACM 12 (1965) 536 - 541. </note>
Reference-contexts: However, testing if a clause is false in I can be expensive or impossible if I is non-trivial. The set of support strategy of <ref> [117] </ref> is a way of getting nearly the same effect without the need to use I explicitly. A sequence of positive resolutions can be combined into a hyper-resolution [92], which avoids explicitly generating intermediate results. This strategy is often used by the Argonne group.
Reference: [118] <author> Wos, L., Robinson, G., Carson, D., and Shalla, L., </author> <title> The concept of demodulation in theorem proving, </title> <journal> J. </journal> <note> ACM 14 (1967) 698-709. </note>
Reference-contexts: When D is empty, paramodulation is similar to ``narrowing'', which has been much studied in the context of logic programming and term rewriting. Similar to paramodulation is the rewriting or ``demodulation'' rule <ref> [118] </ref>, which is essentially a method of simplification: Definition. Suppose C [t] is a clause containing a non-variable term t and u = v is another unit clause.
Reference: [119] <author> Wos, L., Veroff, R., Smith, B., and McCune, W., </author> <title> The linked inference principle, II: the user's viewpoint, </title> <booktitle> Proceedings of the 9th International Conference on Automated Deduction, </booktitle> <editor> E. Lusk and R. Overbeek, eds., </editor> <booktitle> Lecture Notes in Computer Science vol. </booktitle> <volume> 310, </volume> <editor> G. Goos and J. Hartmanis, eds. </editor> <publisher> (Springer-Verlag, </publisher> <address> New York, </address> <year> 1988), </year> <pages> pp. 316 - 332. </pages>
Reference-contexts: There is some advantage in using larger inference steps, since then fewer intermediate lemmas will be saved and the search space will not grow so rapidly. Hyper-resolution [92] is one way of doing this to some extent. Another such approach is the linked inference of <ref> [119] </ref>. The theory resolution of Stickel [105] is also a realization of this concept. 7.7 Relevance Tests Choosing relevant axioms is also essential for a mechanical theorem prover.
Reference: [120] <author> Wos, L. and Winker, S., </author> <title> Open questions solved with the assistance of AURA, in Automated Theorem Proving: After 25 Years, </title> <editor> W. Bledsoe and D. Loveland, eds., </editor> <publisher> American Mathematical Society, </publisher> <address> Providence, RI, </address> <year> 1984, </year> <pages> pp. 73-88. </pages>
Reference: [121] <author> Wu, Went-ts .. un, </author> <title> On the decision problem and the mechanization of theorem proving in elementary geometry, </title> <note> Scientia Sinica 21 (1978) 159 - 172. </note>
Reference-contexts: If the theories have the property of ``convexity,'' this method is especially efficient. For another method of combining decision procedures using rewrite rules, see Shostak 51 A decision procedure for a subclass of elementary geometry was recently developed by Wu <ref> [121] </ref>. This is a very efficient method that transforms geometry theorems into systems of polynomial equations and applies algebraic methods. This method can also automatically find degenerate cases of theorems, that is, special cases in which the theorem is false.
Reference: [122] <author> Zhang, H. and Kapur, D., </author> <title> First order theorem proving using conditional rewrite rules, </title> <booktitle> Proceedings of the 9th International Conference on Automated Deduction, </booktitle> <editor> E. Lusk and R. Overbeek, eds., </editor> <booktitle> Lecture Notes in Computer Science vol. </booktitle> <volume> 310, </volume> <editor> G. Goos and J. Hartmanis, eds. </editor> <publisher> (Springer-Verlag, </publisher> <address> New York, </address> <year> 1988), </year> <pages> pp. 1 - 20. </pages>
Reference-contexts: Another approach is to consider conditional equations such as x/x = 1 if x 6= 0. These are formally equivalent to first order clauses having at least one equality literal, but concepts similar to demodulation can be extended to them as well <ref> [122] </ref>. Still another approach to equality is to build an equational theory into the unification procedure. This idea was suggested by Plotkin [86], and leads to fairly efficient theorem provers.
References-found: 122

