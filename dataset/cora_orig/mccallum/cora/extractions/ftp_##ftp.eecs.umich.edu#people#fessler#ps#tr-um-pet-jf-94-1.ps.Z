URL: ftp://ftp.eecs.umich.edu/people/fessler/ps/tr-um-pet-jf-94-1.ps.Z
Refering-URL: http://www.eecs.umich.edu/~fessler/papers/tech-report.html
Root-URL: http://www.cs.umich.edu
Title: EM and Gradient Algorithms for Transmission Tomography with Background Contamination  
Date: 15, 1994  
Note: December  
Abstract: Jeffrey A. Fessler 3480 Kresge III, Box 0552, University of Michigan, Ann Arbor, MI 48109-0552 email: fessler@umich.edu, phone: 313-763-1434, fax: 313-764-0288 Technical Report UM-PET-JF-94-1 ABSTRACT This report describes slight extensions of the expectation-maximization (EM) algorithm and the gradient algorithm [1] for penalized-likelihood transmission reconstruction but that accommodates nonzero additive background contamination in the Poisson model. For definitions of the notation, etc., see [2, 1]. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> K Lange and J A Fessler. </author> <title> Globally convergent algorithms for maximum a posteriori transmission tomography, </title> <note> 1994. Submitted to IEEE Trans. Im. Proc. </note>
Reference-contexts: 1 Gradient Algorithm Lange <ref> [3, 4, 1] </ref> has proposed an iterative gradient algorithm that has the desirable property that it automatically enforces nonnegativity. In this paper we present a slightly modified version of this algorithm that accommodates nonzero r n factors. <p> When one includes a smoothness penalty, the M-step of Ollinger's (or Lange and Carson's) method would require simultaneous solution of p coupled equations. 1 Lange <ref> [1] </ref> has adapted a clever convexity method due to De Pierro [7, 8] to the M-step of [5]. We have adapted this same convexity method to the M-step of Ollinger [6]. For completeness we summarize the approach here; see [5, 6] for additional details.
Reference: [2] <author> J A Fessler. </author> <title> Hybrid Poisson/polynomial objective functions for tomographic image reconstruction from transmission scans. </title> <journal> IEEE Trans. Im. Proc., </journal> <volume> 0(0) </volume> <pages> 0-0, </pages> <month> 0 </month> <year> 1994. </year> <note> Accepted. </note>
Reference-contexts: The key difference between the coordinate-ascent update in <ref> [2] </ref> and (4) is that the latter uses a simultaneous update, and as such it is more amenable to parallel implementations.
Reference: [3] <author> K Lange, M Bahn, and R Little. </author> <title> A theoretical study of some maximum likelihood algorithms for emission and transmission tomography. </title> <journal> IEEE Trans. Med. Im., </journal> <volume> 6(2) </volume> <pages> 106-114, </pages> <month> June </month> <year> 1987. </year>
Reference-contexts: 1 Gradient Algorithm Lange <ref> [3, 4, 1] </ref> has proposed an iterative gradient algorithm that has the desirable property that it automatically enforces nonnegativity. In this paper we present a slightly modified version of this algorithm that accommodates nonzero r n factors.
Reference: [4] <author> K Lange. </author> <title> Convergence of EM image reconstruction algorithms with Gibbs smoothing. </title> <journal> IEEE Trans. Med. Im., </journal> <volume> 9(4) </volume> <pages> 439-446, </pages> <month> December </month> <year> 1990. </year> <title> Corrections, </title> <month> June </month> <year> 1991. </year>
Reference-contexts: 1 Gradient Algorithm Lange <ref> [3, 4, 1] </ref> has proposed an iterative gradient algorithm that has the desirable property that it automatically enforces nonnegativity. In this paper we present a slightly modified version of this algorithm that accommodates nonzero r n factors.
Reference: [5] <author> K Lange and R Carson. </author> <title> EM reconstruction algorithms for emission and transmission tomography. </title> <journal> J. Comp. Assisted Tomo., </journal> <volume> 8(2) </volume> <pages> 306-316, </pages> <month> April </month> <year> 1984. </year>
Reference-contexts: This has never been necessary in our experiments with this algorithm to date. We refer to (2) as the gradient algorithm. 2 EM Algorithm Lange and Carson <ref> [5] </ref> proposed an EM algorithm for transmission tomography using a Taylor series approximation for the M-step. Ollinger [6] reported that the EM algorithm did not completely converge with this approximation, and proposed a 1-D Newton's method for the M-step in the pure maximum likelihood case (no smoothness penalty). <p> When one includes a smoothness penalty, the M-step of Ollinger's (or Lange and Carson's) method would require simultaneous solution of p coupled equations. 1 Lange [1] has adapted a clever convexity method due to De Pierro [7, 8] to the M-step of <ref> [5] </ref>. We have adapted this same convexity method to the M-step of Ollinger [6]. For completeness we summarize the approach here; see [5, 6] for additional details. <p> We have adapted this same convexity method to the M-step of Ollinger [6]. For completeness we summarize the approach here; see <ref> [5, 6] </ref> for additional details. <p> = n j=1 where X nj = fl i nj + y n fl i fl i ! fl i j Y e a nk i k : The function Q EM corresponds to the conditional log-likelihood of a complete-data space for transmission tomography, and as such one can show <ref> [9, 5] </ref> that L () L ( i ) Q EM (; i ) Q EM ( i ; i ): Therefore, if we define EM (; i ) = Q EM (; i ) fiP ? (; i ); (3) then one can show that () ( i ) EM
Reference: [6] <author> J M Ollinger. </author> <title> Maximum likelihood reconstruction of transmission images in emission computed tomography via the EM algorithm. </title> <journal> IEEE Trans. Med. Im., </journal> <volume> 13(1) </volume> <pages> 89-101, </pages> <month> March </month> <year> 1994. </year>
Reference-contexts: This has never been necessary in our experiments with this algorithm to date. We refer to (2) as the gradient algorithm. 2 EM Algorithm Lange and Carson [5] proposed an EM algorithm for transmission tomography using a Taylor series approximation for the M-step. Ollinger <ref> [6] </ref> reported that the EM algorithm did not completely converge with this approximation, and proposed a 1-D Newton's method for the M-step in the pure maximum likelihood case (no smoothness penalty). <p> We have adapted this same convexity method to the M-step of Ollinger <ref> [6] </ref>. For completeness we summarize the approach here; see [5, 6] for additional details. <p> We have adapted this same convexity method to the M-step of Ollinger [6]. For completeness we summarize the approach here; see <ref> [5, 6] </ref> for additional details. <p> The convenient aspect of EM (; i ) is that it is a separable function of 1 ; : : : ; p , so maximizing EM (; i ) requires p separate 1-D maximizations. Unfortunately, those maximizations do not have a closed form, so following Ollinger <ref> [6] </ref> we apply New ton's method to each parameter.
Reference: [7] <author> A R De Pierro. </author> <title> On the relation between the ISRA and the EM algorithm for positron emission tomography. </title> <journal> IEEE Trans. Med. Im., </journal> <volume> 12(2) </volume> <pages> 328-333, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: When one includes a smoothness penalty, the M-step of Ollinger's (or Lange and Carson's) method would require simultaneous solution of p coupled equations. 1 Lange [1] has adapted a clever convexity method due to De Pierro <ref> [7, 8] </ref> to the M-step of [5]. We have adapted this same convexity method to the M-step of Ollinger [6]. For completeness we summarize the approach here; see [5, 6] for additional details.
Reference: [8] <author> A R De Pierro. </author> <title> A modified expectation maximization algorithm for penalized likelihood estimation in emission tomography, </title> <note> 1994. To appear in IEEE Trans. Med. Im. </note>
Reference-contexts: When one includes a smoothness penalty, the M-step of Ollinger's (or Lange and Carson's) method would require simultaneous solution of p coupled equations. 1 Lange [1] has adapted a clever convexity method due to De Pierro <ref> [7, 8] </ref> to the M-step of [5]. We have adapted this same convexity method to the M-step of Ollinger [6]. For completeness we summarize the approach here; see [5, 6] for additional details.
Reference: [9] <author> A P Dempster, N M Laird, and D B Rubin. </author> <title> Maximum likelihood from incomplete data via the EM algorithm. </title> <journal> J. Royal Stat. Soc. Ser. B, </journal> <volume> 39(1) </volume> <pages> 1-38, </pages> <year> 1977. </year> <month> 2 </month>
Reference-contexts: = n j=1 where X nj = fl i nj + y n fl i fl i ! fl i j Y e a nk i k : The function Q EM corresponds to the conditional log-likelihood of a complete-data space for transmission tomography, and as such one can show <ref> [9, 5] </ref> that L () L ( i ) Q EM (; i ) Q EM ( i ; i ): Therefore, if we define EM (; i ) = Q EM (; i ) fiP ? (; i ); (3) then one can show that () ( i ) EM
References-found: 9

