URL: ftp://ftpipr.ira.uka.de/pub/papers/1995/sirs95rd.ps.gz
Refering-URL: ftp://ftpipr.ira.uka.de/.public_html/papersna.html
Root-URL: 
Email: E-Mail: fdillmannjkaiserjudeg@ira.uka.de  
Phone: Phone: +49 721 6084051 Fax: +49 721 606740  
Title: In: International Symposium on Intelligent Robotic Systems (SIRS '95), Pisa, Italy Acquisition of Elementary Robot
Author: R. Dillmann, M. Kaiser, A. Ude 
Address: 76128 Karlsruhe, Germany  
Affiliation: University of Karlsruhe, Institute for Real-Time Computer Systems Robotics,  
Abstract: Similarly to human voluntary movements, a robot's elementary skills can coarsely be divided into two main categories: rapid transfer movements that are executed in an open loop with no opportunity for correction and slower controlled movements guided by sensorial feedback [6]. In this paper we consider two particular problems which arise when acquiring open-loop and closed-loop elementary skills: the segmentation of the trajectory into time intervals corresponding to different classes of the operator's motion and the preprocessing of the possibly bad examples that were recorded during a demonstration in order to make them suitable for skill learning. The proposed methods are based on the fuzzy set theory, statistics, and Shannon's information theory. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> H. Asada and S. Liu. </author> <title> Transfer of human skills to neural net robot controllers. </title> <booktitle> In Proceedings of the 1991 IEEE International Conference on Robotics and Automation, </booktitle> <year> 1991. </year>
Reference-contexts: Let m be the number of detected trajectory segments and let U = ( ij ) denote the m fi n matrix which coefficients are equal to the grade of membership of the j-th data point to the i-th trajectory segment. It is easy to see that ij 2 <ref> [0; 1] </ref> and that P m i=1 ij = 1; 1 j n. Hence U can be viewed as a fuzzy partition matrix. Let x j = [t j ; v j ] T ; 1 j n. <p> In this scenario, the usual model of the skill acquisition process comprising the phases of example generation, "strategy extraction" (learning), and skill application <ref> [1, 15, 17, 16] </ref> must be extended. In particular, the steps of example preprocessing aiming at training data generation as well as the need for on-line skill enhancement must be explicitely considered (Fig. 5). Fig. 5.: Different phases of the skill acquisition process.
Reference: 2. <author> C. Baroglio, A. Giordana, M. Kaiser, M. Nuttin, and R. Piola. </author> <title> Learning controllers for industrial robots. </title> <booktitle> Machine Learning, </booktitle> <year> 1995. </year>
Reference-contexts: Right: Actions (D x ; D y ; D z ) (commanded translation offsets) recorded from a human demonstration of the peg-into-hole task, including the extraction of the peg from the hole. rules, or a regression tree <ref> [2] </ref>. These techniques work well if the presented examples are "good," i.e., not contradictory, goal-oriented and sufficiently distributed over the input space. <p> Based on the preprocessed data, the network representing the insertion skill was constructed using a clustering algorithm <ref> [2] </ref>, which generated a network featuring 50 clusters. Afterwards, the network was trained using conventional error backpropagation until convergence was achieved.
Reference: 3. <author> N. Delson and H. West. </author> <title> Robot programming by human demonstration: The use of human inconsistency in improving 3D robot trajectories. </title> <booktitle> In Proc. IEEE/RSJ/GI Int. Conf. Intelligent Robots and Systems, </booktitle> <pages> pages 1248-1255, </pages> <address> Munich, Germany, </address> <month> September </month> <year> 1994. </year>
Reference-contexts: We have developed a stereo vision system [20] to monitor the demonstrated motion (see Fig. 1). Motions that can be specified in this way are typically used for the navigation of a robot from one place to another. Recent research in this area comprises among others Delson and West <ref> [3] </ref>, Tso and Liu [18] and Ogata and Takahashi [13]. Let # denote the demonstrated trajectory. Its functional form is of course not known in advance. The vision system returns a sequence of poses p j measured at time instants t j . <p> If more than one demonstration is available, the presented method can be used for improving trajectories obtained from each single demonstration. The improved trajectories and the method of Delson and West <ref> [3] </ref> can be employed afterwards to combine multiple demonstrations. 3 Acquisition of elementary sensor-based skills Elementary sensor-based skills can be defined as operations that are realized through a direct coupling between the robot's sensors and its actuators and require a constant focus of attention during execution.
Reference: 4. <author> A. Giordana, M. Kaiser, and M. Nuttin. </author> <title> On the reduction of costs for robot controller synthesis. </title> <booktitle> In International Symposium on Intelligent Robotic Systems (IRS '94), </booktitle> <pages> pages 187 - 197, </pages> <address> Grenoble, France, </address> <year> 1994. </year>
Reference-contexts: This reduction to the necessary information, i.e., to those components of the actionvector u that were relevant during the demonstration, as well as to those inputs y i that were actually used by the operator, significantly eases the task of learning the skill <ref> [4] </ref>. We have already shown [8, 7] that an information gain measure is a suitable mean for performing this identification task. However, this approach requires both a sufficient amount of samples taken during the demonstration, and a minimum quality of the demonstration in terms of consistency of the commanded actions.
Reference: 5. <author> R. Heise. </author> <title> Demonstration instead of programming: Focussing attention in robot task acquisition. Research report no. </title> <type> 89/360/22, </type> <institution> Department of Computer Science, University of Calgary, </institution> <year> 1989. </year>
Reference-contexts: Since one of the major cost factors in robotic application is the cost of robot programming, the idea of robots becoming consumer products lets the interest in intuitive programming methods such as iconic programming and especially Robot Programming by Human Demonstration (RPD) <ref> [5, 10] </ref> grow rapidly. Since humans can carry out motions with no apparent difficulty, one would expect the generation of elementary skills to be a relatively simple problem.
Reference: 6. <author> P. N. Johnson-Laird. </author> <title> The Computer and the Mind: An Introduction to Cognitive Science. </title> <publisher> Harvard University Press, </publisher> <address> Cambridge, </address> <year> 1988. </year>
Reference: 7. <author> M. Kaiser, H. Friedrich, and R. Dillmann. </author> <title> Obtaining good performance from a bad teacher. </title> <booktitle> In International Conference on Machine Learning, Workshop on Programming by Demonstration, </booktitle> <address> Tahoe City, California, </address> <year> 1995. </year>
Reference-contexts: The noisy translation offsets sampled from a demonstration and shown in Fig. 4 can be considered the rule rather than the exception. This suboptimality of sampled data with respect to the task to approximate the function C originates from different sources <ref> [7] </ref>, the most prominent being 1. unnecessary actions that do not contribute to achieving the final goal, 2. incorrect actions that require corrective actions at a later point in time, and 3. unmotivated actions that are in no detectable way linked to the sensorial input. <p> This reduction to the necessary information, i.e., to those components of the actionvector u that were relevant during the demonstration, as well as to those inputs y i that were actually used by the operator, significantly eases the task of learning the skill [4]. We have already shown <ref> [8, 7] </ref> that an information gain measure is a suitable mean for performing this identification task. However, this approach requires both a sufficient amount of samples taken during the demonstration, and a minimum quality of the demonstration in terms of consistency of the commanded actions.
Reference: 8. <author> M. Kaiser, A. Retey, and R. Dillmann. </author> <title> Robot skill acquisition via human demonstration. </title> <booktitle> In Proceedings of the International Conference on Advanced Robotics (ICAR '95), </booktitle> <year> 1995. </year>
Reference-contexts: This reduction to the necessary information, i.e., to those components of the actionvector u that were relevant during the demonstration, as well as to those inputs y i that were actually used by the operator, significantly eases the task of learning the skill [4]. We have already shown <ref> [8, 7] </ref> that an information gain measure is a suitable mean for performing this identification task. However, this approach requires both a sufficient amount of samples taken during the demonstration, and a minimum quality of the demonstration in terms of consistency of the commanded actions.
Reference: 9. <editor> H. Kollnig and H.-H. Nagel. Ermittlung von begri*ichen Beschreibungen von Geschehen in Straenverkehrs-szenen mit Hilfe unscharfer Mengen. Informatik Forsch. Entw., </editor> <volume> 8 </volume> <pages> 186-196, </pages> <year> 1993. </year>
Reference-contexts: It can be calculated with the help of finite differences. The transition from quantitative attributes like v j to qualitative abstractions can be achieved by use of the fuzzy set theory. Such an approach was employed in <ref> [9] </ref> to classify vehicle motions. One possible classification of the operator's hand motion is: zero, slow, normal, fast and very fast.
Reference: 10. <author> Y. Kuniyoshi, M. Inaba, and H. Inoue. </author> <title> Learning by watching: Extracting reusable task knowledge from visual observation of human performance. </title> <journal> IEEE Transactions on Robotics and Automation, </journal> <volume> 10(6) </volume> <pages> 799-822, </pages> <year> 1995. </year>
Reference-contexts: Since one of the major cost factors in robotic application is the cost of robot programming, the idea of robots becoming consumer products lets the interest in intuitive programming methods such as iconic programming and especially Robot Programming by Human Demonstration (RPD) <ref> [5, 10] </ref> grow rapidly. Since humans can carry out motions with no apparent difficulty, one would expect the generation of elementary skills to be a relatively simple problem.
Reference: 11. <author> J.-C. Latombe. </author> <title> Robot Motion Planning. </title> <publisher> Kluwer, </publisher> <address> Boston, </address> <year> 1991. </year>
Reference-contexts: Since humans can carry out motions with no apparent difficulty, one would expect the generation of elementary skills to be a relatively simple problem. However, it turns out that it is extremely difficult to duplicate this elementary operative intelligence, which is used by humans unconsciously, in a computer-controlled robot <ref> [11] </ref>. This fact gives rise to an idea to use human demonstrations to learn elementary skills, leading to a natural extension of the traditionally task-level oriented RPD. 2 Acquisition of robot trajectories Let us first consider the specification of open-loop trajectories.
Reference: 12. <author> J. Moody and C. Darken. </author> <title> Learning with localized receptive fields. </title> <editor> In T. Sejnowski D. Touretzky, G. Hinton, editor, </editor> <booktitle> Proceedings of the Connectionist Models Summer School. </booktitle> <institution> Carnegie Mellon University, </institution> <year> 1988. </year>
Reference-contexts: Because of their support of incremental learning, the possibility to represent alternative actions, the existence of algorithms that allows the network construction given a set of samples, and the straightforward symbolic interpretation, radial-basis function networks <ref> [12, 14] </ref> were chosen for this task. Based on the preprocessed data, the network representing the insertion skill was constructed using a clustering algorithm [2], which generated a network featuring 50 clusters. Afterwards, the network was trained using conventional error backpropagation until convergence was achieved.
Reference: 13. <author> H. Ogata and T. Takahashi. </author> <title> A geometric approach to task understanding for robot assembly operations. </title> <booktitle> In IEEE International Conference on Robotics and Automation, </booktitle> <volume> volume 1, </volume> <pages> pages 58 - 64, </pages> <year> 1993. </year>
Reference-contexts: Motions that can be specified in this way are typically used for the navigation of a robot from one place to another. Recent research in this area comprises among others Delson and West [3], Tso and Liu [18] and Ogata and Takahashi <ref> [13] </ref>. Let # denote the demonstrated trajectory. Its functional form is of course not known in advance. The vision system returns a sequence of poses p j measured at time instants t j .
Reference: 14. <author> T. Poggio and F. Girosi. </author> <title> Networks for approximation and learning. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 78(9) </volume> <pages> 1481-1497, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: Because of their support of incremental learning, the possibility to represent alternative actions, the existence of algorithms that allows the network construction given a set of samples, and the straightforward symbolic interpretation, radial-basis function networks <ref> [12, 14] </ref> were chosen for this task. Based on the preprocessed data, the network representing the insertion skill was constructed using a clustering algorithm [2], which generated a network featuring 50 clusters. Afterwards, the network was trained using conventional error backpropagation until convergence was achieved.
Reference: 15. <author> D. A. Pomerleau. </author> <title> Efficient training of artificial neural networks for autonomous navigation. </title> <journal> Neural Computation, </journal> <volume> 3:88 - 97, </volume> <year> 1991. </year>
Reference-contexts: In this scenario, the usual model of the skill acquisition process comprising the phases of example generation, "strategy extraction" (learning), and skill application <ref> [1, 15, 17, 16] </ref> must be extended. In particular, the steps of example preprocessing aiming at training data generation as well as the need for on-line skill enhancement must be explicitely considered (Fig. 5). Fig. 5.: Different phases of the skill acquisition process.
Reference: 16. <author> P. Reignier, V. Hansen, and J.L. Crowley. </author> <title> Incremental supervised learning for mobile robot reactive control. </title> <booktitle> In Intelligent Autonomous Systems 4 (IAS-4), </booktitle> <pages> pages 287 - 294. </pages> <publisher> IOS Press, </publisher> <year> 1995. </year>
Reference-contexts: In this scenario, the usual model of the skill acquisition process comprising the phases of example generation, "strategy extraction" (learning), and skill application <ref> [1, 15, 17, 16] </ref> must be extended. In particular, the steps of example preprocessing aiming at training data generation as well as the need for on-line skill enhancement must be explicitely considered (Fig. 5). Fig. 5.: Different phases of the skill acquisition process.
Reference: 17. <author> J. G. Schneider and C. M. Brown. </author> <title> Robot skill learning, basis functions, and control regimes. </title> <booktitle> In Proceedings of the IEEE International Conference on Robotics and Automation, </booktitle> <address> Atlanta, Georgia, </address> <year> 1993. </year>
Reference-contexts: In this scenario, the usual model of the skill acquisition process comprising the phases of example generation, "strategy extraction" (learning), and skill application <ref> [1, 15, 17, 16] </ref> must be extended. In particular, the steps of example preprocessing aiming at training data generation as well as the need for on-line skill enhancement must be explicitely considered (Fig. 5). Fig. 5.: Different phases of the skill acquisition process.
Reference: 18. <author> S. K. Tso and K. P. Liu. </author> <title> Visual programming for capturing of human manipulation skill. </title> <booktitle> In Proc. IEEE/RSJ Int. Conf. Intelligent Robots and Systems, </booktitle> <pages> pages 42-48, </pages> <address> Yokohama, Japan, </address> <month> July </month> <year> 1993. </year>
Reference-contexts: Motions that can be specified in this way are typically used for the navigation of a robot from one place to another. Recent research in this area comprises among others Delson and West [3], Tso and Liu <ref> [18] </ref> and Ogata and Takahashi [13]. Let # denote the demonstrated trajectory. Its functional form is of course not known in advance. The vision system returns a sequence of poses p j measured at time instants t j .
Reference: 19. <author> A. Ude. </author> <title> Trajectory generation from noisy positions of object features for teaching robot paths. </title> <booktitle> Robotics and Autonomous Systems, </booktitle> <volume> 11(2) </volume> <pages> 113-127, </pages> <month> September </month> <year> 1993. </year>
Reference-contexts: The proper modelling of sensor noise is essential for the accurate trajectory reconstruction. A comprehensive discussion of this problem is given in <ref> [19] </ref>. The recorded motion usually exhibits different characteristics throughout the demonstration. For instance, its beginning and its end often consist of time intervals where no motion takes place. Such parts should be removed from the trajectory. <p> Therefore we have extended the approximating techniques for scalar measurements to the case of vector measurements with multidimensional covariance matrices (see <ref> [19] </ref>). In general, separately reconstructed neighbouring trajectories do not end in a common point. To assure the smooth transition between them, the neighbouring trajectories must be glued together.
Reference: 20. <author> A. Ude, H. Brode, and R. Dillmann. </author> <title> Object localization using perceptual organization and structural stereopsis. </title> <booktitle> In Proc. Third Int. Conf. Automation, Robotics and Computer Vision, </booktitle> <pages> pages 197-201, </pages> <address> Singapore, </address> <month> November </month> <year> 1994. </year>
Reference-contexts: To demonstrate a desired trajectory, the human operator simply moves the object to be manipulated or, alternatively, a specially designed teaching tool along it. We have developed a stereo vision system <ref> [20] </ref> to monitor the demonstrated motion (see Fig. 1). Motions that can be specified in this way are typically used for the navigation of a robot from one place to another.
Reference: 21. <author> G. Wahba. </author> <title> Spline Models for Observational Data. </title> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1990. </year>
Reference-contexts: There are many ways to determine the optimal smoothing parameter k and the optimal trajectory h k in 2 Actually, some more simple technicalities are needed to enforce this. the case of scalar measurements. The most notable among them are the cross-validation and the generalized cross-validation <ref> [21] </ref>. However, it is well known that the error in the measurements provided by a stereo vision system can be adequately modelled only by use of full multidimensional probability distributions.
Reference: 22. <author> H.-J. Zimmermann. </author> <title> Fuzzy Set Theory | and its Applications. </title> <publisher> Kluwer, </publisher> <address> Boston, </address> <year> 1991. </year> <title> This article was processed using the T E X macro package with SIRS95 style </title>
Reference-contexts: U and x j can be used as an input to one of the general fuzzy clustering algorithms. They can be employed for the refinement of the initial segmentation of the trajectory. We have obtained good results with the help of the so called fuzzy-c-means-algorithm (see Zimmermann <ref> [22] </ref>). This algorithm is based on the minimization of the criterion m X n X w over all partition matrices U . The center u i of each fuzzy cluster is defined as u i = j=1 w P n ij We omit the details of the actual minimization procedure.
References-found: 22

