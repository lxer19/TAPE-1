URL: http://wwwis.win.tue.nl/~dignum/modelage97.ps
Refering-URL: http://wwwis.win.tue.nl/~dignum/papers.html
Root-URL: http://www.win.tue.nl
Title: Social Interactions of Autonomous Agents; Private and Global Views on Communication  
Author: F. Dignum 
Keyword: Multi-Agent Systems, Multi-Modal logic, Communication, Speech acts.  
Note: Submission: original and also intended for post-proceedings.  
Address: P.O. Box 513, 5600 MB Eindhoven, The Netherlands  
Affiliation: Fac. of Maths. Comp. Sc., Eindhoven University of Technology  
Email: e-mail: dignum@win.tue.nl  
Phone: phone: +31-402473705, fax: +31-402463992  
Abstract: In describing the interactions between agents we can take either a global view, where the set of all agents is seen as one big system, or a private view, where the system is identified with a single agent and the other agents form a part of the environment. Often a global view is taken to fix some protocols (like contract net) for all the possible social interactions between agents within the system. Privately the agents then have fixed reaction rules to respond to changes in the environment. In a sense the agents are no longer autonomous in that they always respond in a fixed way and their behaviour can be completely determined by other agents. In this paper we investigate the case where there might not be a (or one) fixed protocol for the social interaction and where the agents do not necessarily react in the same way to each message from other agents. We distinguish between the agents perception of the world and the "real" state of the world and show how these views can be related. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> C. Boutilier. </author> <title> Toward a Logic for Qualitative Decision Theory. </title> <editor> In Jon Doyle, Erik Sandewall and Pietro Torasso (eds.), </editor> <booktitle> Principles of Knowledge Representation and Reasoning, proceedings of the fourth international conference, </booktitle> <pages> pages 75-86, </pages> <address> 1994, </address> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Francisco, California. </address>
Reference-contexts: The most fundamental of these notions is that of conditional preferences.(See also <ref> [1, 17] </ref>). Formally, (conditional) preferences are defined as the combination of implicit and explicit preferences, which allows us to avoid all kinds of problems that plague other formalisations of motivational attitudes.
Reference: [2] <author> P. Cohen and H. Levesque. </author> <title> Intention is choice with commitment. </title> <journal> Artificial Intelligence, </journal> <volume> vol.42, </volume> <pages> pages 213-261, </pages> <year> 1990. </year>
Reference-contexts: The last concept that we consider at the motivational level is that of commitment. Many interpretations have been given to the concept of commitment (see e.g. <ref> [2, 14, 16] </ref>). We chose a deontic interpretation of commitment. That is, a commitment of an agent to reach a goal is expressed as an obligation of the agent towards itself to reach the goal.
Reference: [3] <author> P. Cohen and H. Levesque. </author> <title> Teamwork Nous, </title> <booktitle> vol.35, </booktitle> <pages> pages 487-512, </pages> <year> 1991. </year>
Reference-contexts: Most of the cooperation between agents is based on the assumption that they have some joint goal or intention. Such a joint goal enforces some type of cooperative behaviour on all agents (see e.g. <ref> [3, 14, 23] </ref>). The conventions according to which the agents coordinate their behaviour is hard-wired into the protocols that the agents use to react to the behaviour (cq. messages) of other agents. This raises several issues.
Reference: [4] <author> R. Davis and R. Smith. </author> <title> Negotiation as a metaphor for distributed problem solving. </title> <journal> Artificial Intelligence, </journal> <volume> vol.20, </volume> <pages> pages 63-109, </pages> <year> 1983. </year>
Reference-contexts: 1 Introduction In the area of Multi-Agent Systems much research is devoted to the coordination of the agents. Many papers have been written about protocols (like contract net) that allow agents to negotiate and cooperate (e.g. <ref> [20, 4] </ref>). Most of the cooperation between agents is based on the assumption that they have some joint goal or intention. Such a joint goal enforces some type of cooperative behaviour on all agents (see e.g. [3, 14, 23]).
Reference: [5] <author> F. Dignum. </author> <title> Using Transactions in Integrity Constraints: Looking forward or backwards, what is the difference? In First International Workshop on Applied Logic: Logic at Work, </title> <address> Amsterdam, </address> <year> 1992. </year>
Reference-contexts: That is, we can use true &lt; ff &gt; to indicate that the present state can have been reached by performing ff in a previous state. However, to denote the actual previous action a new operator is needed! See <ref> [5] </ref> for a more in depth discussion of this issue. The same holds for the N EXT operator for actions. We also define a more traditional N EXT operator on formulas in terms of the N EXT operator on events.
Reference: [6] <author> F. Dignum and H. Weigand. </author> <title> Communication and deontic logic. </title> <editor> In R. Wieringa and R. Feen-stra, editors, </editor> <booktitle> Information Systems, Correctness and Reusability, </booktitle> <pages> pages 242-260. </pages> <publisher> World Scientific, </publisher> <address> Singapore, </address> <year> 1995. </year>
Reference-contexts: Besides the implicit way to create authorizations, they can also be created explicitly by a separate speech act which is formally a declaration that the authorization is true. The speech acts themselves are formalised as meta-actions (based on earlier work <ref> [6] </ref>): * DIR (x; i; j; ff) formalises that agent i directs agent j to perform ff on the basis of x, where x can be either peer, power or authority. * DECL (i; f) models the declaration of i that f holds. * ASS (x; i; j; f) formalises the
Reference: [7] <author> F. Dignum. </author> <title> Autonomous Agents and Social Norms. </title> <note> Submitted to ICMAS workshop on Norms, Obligations and Conventions. </note>
Reference-contexts: This relation connects each world with the set of ideal worlds with respect to that world. More details about the formal semantics of this deontic operator can be found in [8].) The second consequence of registering a commitment as an obligation is, as we argued in <ref> [7] </ref>, that obligations lead to (conditional) preferences which are ordered. From this it follows that an agent will be very committed to a goal if the preference following from a commitment has a very high ranking.
Reference: [8] <author> F. Dignum, J.-J.Ch. Meyer, R. Wieringa and R. Kuiper. </author> <title> A modal approach to intentions, commitments and obligations: intention plus commitment yields obligation. In M.A. </title> <editor> Brown and J. Carmo (eds.) </editor> <booktitle> DEON'96 Workshop on deontic logic in computer science, </booktitle> <pages> pages 174-193, </pages> <address> Lisbon, </address> <month> Jan. </month> <year> 1996. </year>
Reference-contexts: This relation connects each world with the set of ideal worlds with respect to that world. More details about the formal semantics of this deontic operator can be found in <ref> [8] </ref>.) The second consequence of registering a commitment as an obligation is, as we argued in [7], that obligations lead to (conditional) preferences which are ordered.
Reference: [9] <author> F. Dignum and B. van Linder. </author> <title> Modelling Rational Agents in a Dynamic Environment: Putting Humpty Dumpty Together Again. </title> <editor> In J.L. Fiadeiro and P.-Y. Schobbens (eds.) ModelAge-96, pages 81-92,Sesimbra, </editor> <address> Portugal, </address> <year> 1996. </year>
Reference-contexts: In section 5 we give a sketch of a formalisation of the framework given in the previous sections. We give some conclusions in section 6. 2 Communicating Agents The definition of the agents is based on the framework developed in <ref> [9, 10] </ref>. However, we added a private view on the actions. The concepts that we formalise can roughly be divided over four different components: the informational component, the action component, the motivational component and the social component.
Reference: [10] <author> F. Dignum and B. van Linder. </author> <title> Modelling Social Agents in a Dynamic Environment: Making Agents Talk In J. Mueller, </title> <editor> M. Wooldridge and N. Jennings (eds.) </editor> <booktitle> Intelligent Agents III Proceedings of the Third International Workshop on Agent Theories, Architectures, and Languages (ATAL-96), </booktitle> <pages> pages 83-93, </pages> <address> Budapest, Hungary, </address> <year> 1996. </year>
Reference-contexts: In section 5 we give a sketch of a formalisation of the framework given in the previous sections. We give some conclusions in section 6. 2 Communicating Agents The definition of the agents is based on the framework developed in <ref> [9, 10] </ref>. However, we added a private view on the actions. The concepts that we formalise can roughly be divided over four different components: the informational component, the action component, the motivational component and the social component.
Reference: [11] <author> J. Habermas. </author> <title> The Theory of Communicative Action: Reason and Rationalization of Society. </title> <publisher> Polity Press, </publisher> <address> Cambridge, </address> <year> 1984. </year>
Reference-contexts: Often agent j can also not check the authority directly. Therefore, we think that in each protocol it should be possible for j to question the authority of i if j cannot check this authority himself. This is conform the theory from Habermas about communication protocols <ref> [11] </ref> where this is classified as an attack on the validity claims. Agent j can attack the validity of the authority of i by directing agent i to make the authority available for inspection of agent j.
Reference: [12] <author> D. Harel. </author> <title> First Order Dynamic Logic. </title> <publisher> LNCS 68 Springer, </publisher> <year> 1979. </year>
Reference-contexts: We let ff (i) indicate that agent i performs the action ff. We can reason about the results of actions on both a private level and a global level. The global level reasoning is the "standard" one using dynamic logic as described by Harel in <ref> [12] </ref>. We use [ff (i)]OE to indicate that if agent i performs the action indicated by ff the result will be OE. I.e. no matter what happens, if agent i performs ff the system will change to a state where OE holds.
Reference: [13] <author> W. van der Hoek, B. van Linder and J.-J.Ch. Meyer. </author> <title> A logic of capabilities. </title> <editor> In Nerode and Matiyasevich, eds, </editor> <booktitle> Proceedings of LFCS'94, </booktitle> <volume> LNCS 813, </volume> <pages> pages 366-378, </pages> <year> 1994. </year>
Reference-contexts: The main dynamic notion that we consider is that of actions, which we interpret as functions that map some some state of affairs into another one. Following <ref> [13, 26] </ref> we use parameterised actions to describe the event consisting of a particular agent's execution of an action. We let ff (i) indicate that agent i performs the action ff. We can reason about the results of actions on both a private level and a global level.
Reference: [14] <author> N. Jennings. </author> <title> Commitments and Conventions: The foundation of coordination in Multi-Agent systems. </title> <journal> Knowledge Engineering Review, </journal> <volume> vol. 8(3), </volume> <pages> pages 223-250, </pages> <year> 1993. </year> <month> 16 </month>
Reference-contexts: Most of the cooperation between agents is based on the assumption that they have some joint goal or intention. Such a joint goal enforces some type of cooperative behaviour on all agents (see e.g. <ref> [3, 14, 23] </ref>). The conventions according to which the agents coordinate their behaviour is hard-wired into the protocols that the agents use to react to the behaviour (cq. messages) of other agents. This raises several issues. <p> The last concept that we consider at the motivational level is that of commitment. Many interpretations have been given to the concept of commitment (see e.g. <ref> [2, 14, 16] </ref>). We chose a deontic interpretation of commitment. That is, a commitment of an agent to reach a goal is expressed as an obligation of the agent towards itself to reach the goal.
Reference: [15] <author> N. Jennings, P. Faratin, M. Johnson, P. O'Brien and M. Wiegand. </author> <title> Using Intelligent Agents to Manage Business Processes. </title> <booktitle> In Proceedings The Practical Application of Intelligent Agents and Multi-Agent Technology, </booktitle> <pages> pages 345-360, </pages> <address> London, </address> <year> 1996. </year>
Reference-contexts: We distinguish three types of relations between agents: peer relation, power relation and authorization relation. The first two relations are similar to the ones used in the ADEPT system <ref> [22, 15] </ref>. The power relation is used to model hierarchical relations between agents. We assume that these relations are fixed during the lifecycle of the agents. Within such a relation less negotiation is possible about requests and demands.
Reference: [16] <author> D. Kinny and M. Georgeff. </author> <title> Commitment and Effectiveness of Situated Agents. </title> <booktitle> In Proceedings Int. Joint Conf. on Artificial Intelligence, </booktitle> <pages> pages 82-88, </pages> <address> Sydney, Australia, </address> <year> 1991. </year>
Reference-contexts: The last concept that we consider at the motivational level is that of commitment. Many interpretations have been given to the concept of commitment (see e.g. <ref> [2, 14, 16] </ref>). We chose a deontic interpretation of commitment. That is, a commitment of an agent to reach a goal is expressed as an obligation of the agent towards itself to reach the goal.
Reference: [17] <author> J. Lang. </author> <title> Conditional Desires and Utilities an alternative logical approach to qualitative decision theory. </title> <editor> In W. Wahlster, editor, </editor> <booktitle> Proceedings of ECAI-96, </booktitle> <pages> pages 318-327, </pages> <address> Budapest, Hungary, 1996, </address> <publisher> John Wiley & Sons Ltd. </publisher>
Reference-contexts: The most fundamental of these notions is that of conditional preferences.(See also <ref> [1, 17] </ref>). Formally, (conditional) preferences are defined as the combination of implicit and explicit preferences, which allows us to avoid all kinds of problems that plague other formalisations of motivational attitudes.
Reference: [18] <author> B. van Linder, W. van der Hoek and J.-J.Ch. Meyer. </author> <title> Tests as Epistemic Updates. Pursuit of Knowledge. </title> <type> Technical Report, </type> <institution> UU-CS-1994-08, Utrecht University, </institution> <year> 1994. </year>
Reference-contexts: There are two actions that take a special place in the action component. These are the test action and the Reveal action. Both actions have an epistemic character. Although the test action is already introduced in standard dynamic logic, we give it an epistemic flavour conform <ref> [18] </ref>. I.e. after i tests the truth of a formula i knows whether the formula is true or not. The test action on formula OE is written as OE?. So, more formally we have: OE ! [OE?(i)]K i (OE) As we argued before, an agent cannot test every possible formula. <p> The result of the test is a model and state such that i knows OE if OE is true in the original model and i knows that :OE if OE did not hold in the original model. See <ref> [18] </ref> for a formal definition of this meta-action. Reveal The precondition for execution of Reveal (i; j; OE) is that K i OE _ K i :OE. That is, agent i knows about the status of OE.
Reference: [19] <author> J.-J.Ch. Meyer. </author> <title> A different approach to deontic logic. </title> <journal> In Notre Dame Journal of Formal Logic, </journal> <volume> vol.29, </volume> <pages> pages 109-136, </pages> <year> 1988. </year>
Reference-contexts: Ri (i; s) fff j Sf (i; ff; s) 6= ;g and for all s 2 some s 0 2 exists with (s; s 0 ) 2 Ro. The complete semantics contains an algebraic semantics of action expresses, based on the action semantics of Meyer <ref> [19] </ref>. In this paper we will abstract from the algebraic interpretation of actions and instead interpret actions as functions on states of affairs. For the meta-actions the state-transition interpretation is not adequate, because meta-actions do not change states but they change relations between states.
Reference: [20] <author> J. Muller. </author> <title> A cooperation model for autonomous agents. </title> <editor> In J. Muller, M. Wooldridge and N. Jennings, eds, </editor> <booktitle> Intelligent Agents III Proceedings of the Third International Workshop on Agent Theories, Architectures, and Languages (ATAL-96), </booktitle> <pages> pages 135-147, </pages> <address> Budapest, Hungary, </address> <year> 1996. </year>
Reference-contexts: 1 Introduction In the area of Multi-Agent Systems much research is devoted to the coordination of the agents. Many papers have been written about protocols (like contract net) that allow agents to negotiate and cooperate (e.g. <ref> [20, 4] </ref>). Most of the cooperation between agents is based on the assumption that they have some joint goal or intention. Such a joint goal enforces some type of cooperative behaviour on all agents (see e.g. [3, 14, 23]).
Reference: [21] <author> P. Noriega and C. Sierra. </author> <title> Towards layered Dialogical Agents In J. </title> <editor> Muller, M. Wooldridge and N. Jennings, eds, </editor> <booktitle> Intelligent Agents III Proceedings of the Third International Workshop on Agent Theories, Architectures, and Languages (ATAL-96), </booktitle> <pages> pages 69-82, </pages> <address> Budapest, Hungary, </address> <year> 1996. </year>
Reference-contexts: It is possible to incorporate some general translation rules in the system that indicate how terms can be translated from one agent's language to another's. In this paper we will assume that all agents use the same language in order not to complicate the formalisation to much. See <ref> [21] </ref> for an example how an agent system can be described in which agents can use different languages. Ad.3. The last part that plays a role in the privatization of communication is the checking of the pre-conditions and effects of communication.
Reference: [22] <author> T. Norman, N. Jennings, P. Faratin and E. </author> <title> Mamdani Designing and Implementing a Multi-Agent Architecture for business process management. </title> <editor> In J. Mueller, M. Wooldridge and N. Jennings (eds.) </editor> <booktitle> Intelligent Agents III Proceedings of the Third International Workshop on Agent Theories, Architectures, and Languages (ATAL-96), </booktitle> <pages> pages 149-162, </pages> <address> Budapest, Hungary, </address> <year> 1996. </year>
Reference-contexts: In general it is difficult (if not impossible) for agents to react to violations of the conventions by other agents. As was also argued in <ref> [22] </ref>, autonomous agents need a richer communication protocol than contract net (or similar protocols) to be able to retain their autonomy. A greater autonomy of the agent places a higher burden on the communication. An autonomous agent might negotiate over every request it gets. <p> A greater autonomy of the agent places a higher burden on the communication. An autonomous agent might negotiate over every request it gets. In this paper we will describe a mechanism to avoid excessive communication. It is similar to the one employed in <ref> [22] </ref>, but defined more formally and still more generally applicable. Negotiation between autonomous agents is only necessary if the agents do not have complete knowledge of the state of the world. <p> We distinguish three types of relations between agents: peer relation, power relation and authorization relation. The first two relations are similar to the ones used in the ADEPT system <ref> [22, 15] </ref>. The power relation is used to model hierarchical relations between agents. We assume that these relations are fixed during the lifecycle of the agents. Within such a relation less negotiation is possible about requests and demands.
Reference: [23] <author> G. Sandu. </author> <title> Reasoning about collective goals. </title> <editor> In J. Muller, M. Wooldridge and N. Jennings, eds, </editor> <booktitle> Intelligent Agents III Proceedings of the Third International Workshop on Agent Theories, Architectures, and Languages (ATAL-96), </booktitle> <pages> pages 35-47, </pages> <address> Budapest, Hungary, </address> <year> 1996. </year>
Reference-contexts: Most of the cooperation between agents is based on the assumption that they have some joint goal or intention. Such a joint goal enforces some type of cooperative behaviour on all agents (see e.g. <ref> [3, 14, 23] </ref>). The conventions according to which the agents coordinate their behaviour is hard-wired into the protocols that the agents use to react to the behaviour (cq. messages) of other agents. This raises several issues.
Reference: [24] <author> J.R. Searle. </author> <title> Speech Acts. </title> <publisher> Cambridge University Press. </publisher> <year> 1969. </year>
Reference-contexts: In that case the commitment forms a part of the social component. We will say more about the social component in the next section. 2.4 The social component The COM M IT described in the previous section is one of the four types of speech acts <ref> [24] </ref> that play a role in the social component. Speech acts are used to communicate between agents. The result of a speech act is a change in the doxastic or deontic state of an agent, or in some cases a change in the state of the world.
Reference: [25] <author> H. Weigand, E. Verharen and F. Dignum. </author> <title> Interoperable Transactions in Business Models: A Structured Approach. </title> <editor> In P. Constantopoulos, J. Mylopoulos and Y. Vassiliou, eds, </editor> <booktitle> Advanced Information Systems Engineering (LNCS 1080), </booktitle> <pages> pages 193-209, </pages> <publisher> Springer, </publisher> <year> 1996. </year>
Reference-contexts: Creating the authorizations is an important part of the negotiation between agents when they are establishing some type of contract. On the basis of the authorizations that are created during the negotiation some protocol for the transactions between the agents can be followed quick and efficiently. (See <ref> [25] </ref> for more details on contracts between agents).
Reference: [26] <author> R. Wieringa, J.-J.Ch. Meyer and H. Weigand. </author> <title> Specifying dynamic and deontic integrity constraints. </title> <journal> Data & knowledge engineering, </journal> <volume> vol.4, </volume> <pages> pages 157-189, </pages> <year> 1989. </year> <month> 17 </month>
Reference-contexts: The main dynamic notion that we consider is that of actions, which we interpret as functions that map some some state of affairs into another one. Following <ref> [13, 26] </ref> we use parameterised actions to describe the event consisting of a particular agent's execution of an action. We let ff (i) indicate that agent i performs the action ff. We can reason about the results of actions on both a private level and a global level.
References-found: 26

