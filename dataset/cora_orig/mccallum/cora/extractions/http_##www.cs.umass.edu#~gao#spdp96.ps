URL: http://www.cs.umass.edu/~gao/spdp96.ps
Refering-URL: http://www.cs.umass.edu/~gao/
Root-URL: 
Title: An Empirical Study of Dynamic Scheduling on Rings of Processors Extended Abstract  
Author: Dawn E. Gregory Lixin Gao Arnold L. Rosenberg Paul R. Cohen 
Address: Amherst, MA 01003, USA  
Affiliation: Department of Computer Science, University of Massachusetts  
Abstract: We empirically analyze and compare two distributed, low-overhead policies for scheduling dynamic tree- structured computations on rings of identical PEs. Our experiments show that both policies give significant parallel speedup on large classes of computations, and that one yields almost optimal speedup on moderate size rings. We believe that our methodology of experiment design and analysis will prove useful in other such studies. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P.R. </author> <title> Cohen (1995): Empirical Methods for Artificial Intelligence. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference: [2] <author> L.-X. Gao and A.L. </author> <title> Rosenberg (1996): Toward efficient scheduling of evolving computations on rings of processors. </title> <journal> J. </journal> <note> Parallel Distr. Comput., to appear. </note>
Reference-contexts: The first motivating result asserts that policy KOSO schedules BTs that ultimately grow into complete binary trees asymptotically optimally. Theorem 1 Under policy KOSO, R p executes any BT that grows into the height-n complete binary tree T n within time (2 n 1)=p + (low-order terms). <ref> [2] </ref> The second motivating result focuses on how KOSO and KOSO ? distribute work to the PEs of R p while the evolving BT keeps growing. <p> Theorem 2 Focus on an evolving BT in which every executed task spawns two new tasks. (a) After N p 1 steps of policy KOSO, the numbers of unexecuted tasks residing in the heaviest and lightest loaded PEs of R p differ by p 2. <ref> [2] </ref> (b) After N (p1) 2 steps of policy KOSO ? , the numbers of unexecuted tasks residing in the heaviest and lightest loaded PEs of R p differ by 1. 4.
Reference: [3] <author> L.-X. Gao, A.L. Rosenberg, R.K. </author> <title> Sitaraman (1995): Optimal architecture-independent scheduling of fine-grain tree-sweep computations. </title> <booktitle> 7th IEEE Symp. on Parallel and Distr. Processing, </booktitle> <pages> 620-629. </pages>
Reference-contexts: In this paper, we study the problem of efficiently scheduling evolving binary-tree-structured computations on a ring-structured parallel computer. We thus face the challenge of efficiently scheduling a computation whose ultimate shape is unknown (precluding offline planning as in <ref> [3, 4, 7] </ref>), on an architecture that has a large diameter (precluding efficient random placements as in [6]) and small bisection bandwidth (precluding efficient massive data transmission as in [5]). We empirically analyze and compare two distributed, low-overhead dynamic-scheduling policies.
Reference: [4] <author> S.L. </author> <title> Johnsson (1987): Communication efficient basic linear algebra computations on hypercube architectures. </title> <journal> J. Parallel Distr. Comput. </journal> <volume> 4, </volume> <pages> 133-172. </pages>
Reference-contexts: In this paper, we study the problem of efficiently scheduling evolving binary-tree-structured computations on a ring-structured parallel computer. We thus face the challenge of efficiently scheduling a computation whose ultimate shape is unknown (precluding offline planning as in <ref> [3, 4, 7] </ref>), on an architecture that has a large diameter (precluding efficient random placements as in [6]) and small bisection bandwidth (precluding efficient massive data transmission as in [5]). We empirically analyze and compare two distributed, low-overhead dynamic-scheduling policies.
Reference: [5] <author> R.M. Karp and Y. </author> <title> Zhang (1988): Randomized parallel algo-rithms for backtrack search and branch-and-bound computa-tion. </title> <editor> J. </editor> <booktitle> ACM 40, </booktitle> <pages> 765-789. </pages>
Reference-contexts: We thus face the challenge of efficiently scheduling a computation whose ultimate shape is unknown (precluding offline planning as in [3, 4, 7]), on an architecture that has a large diameter (precluding efficient random placements as in [6]) and small bisection bandwidth (precluding efficient massive data transmission as in <ref> [5] </ref>). We empirically analyze and compare two distributed, low-overhead dynamic-scheduling policies.
Reference: [6] <author> A.G. </author> <title> Ranade (1994): Optimal speedup for backtrack search on a butterfly network. </title> <journal> Math. Syst. Theory 27, </journal> <pages> 85-101. </pages>
Reference-contexts: We thus face the challenge of efficiently scheduling a computation whose ultimate shape is unknown (precluding offline planning as in [3, 4, 7]), on an architecture that has a large diameter (precluding efficient random placements as in <ref> [6] </ref>) and small bisection bandwidth (precluding efficient massive data transmission as in [5]). We empirically analyze and compare two distributed, low-overhead dynamic-scheduling policies.
Reference: [7] <author> T. Yang and A. </author> <title> Gerasoulis (1991): A fast static scheduling algorithm for dags on an unbounded number of processors. </title> <booktitle> Supercomputing '91, </booktitle> <pages> 633-642. </pages>
Reference-contexts: In this paper, we study the problem of efficiently scheduling evolving binary-tree-structured computations on a ring-structured parallel computer. We thus face the challenge of efficiently scheduling a computation whose ultimate shape is unknown (precluding offline planning as in <ref> [3, 4, 7] </ref>), on an architecture that has a large diameter (precluding efficient random placements as in [6]) and small bisection bandwidth (precluding efficient massive data transmission as in [5]). We empirically analyze and compare two distributed, low-overhead dynamic-scheduling policies.
References-found: 7

