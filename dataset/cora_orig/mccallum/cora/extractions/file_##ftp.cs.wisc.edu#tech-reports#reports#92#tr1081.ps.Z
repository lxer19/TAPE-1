URL: file://ftp.cs.wisc.edu/tech-reports/reports/92/tr1081.ps.Z
Refering-URL: http://www.cs.wisc.edu/~lists/archive/shore_support/0181.html
Root-URL: 
Title: Crash Recovery in Client-Server EXODUS  
Author: Michael J. Franklin Michael J. Zwilling C. K. Tan Michael J. Carey David J. DeWitt 
Affiliation: Computer Sciences Department University of Wisconsin-Madison  
Date: June 1992.  
Note: To Appear: ACM SIGMOD International Conference on the Management of Data, San Diego,  This work was partially supported by the Defense Advanced Research Projects Agency under contracts N00014-88-K-0303 and NAG-2 618, by the National Science Foundation under grant IRI-8657323, and by a grant from IBM Corporation.  
Abstract: Computer Sciences Technical Report #1081 March 1992 
Abstract-found: 1
Intro-found: 1
Reference: [BHG87] <author> Bernstein, P., Hadzilacos, V., and Goodman, N., </author> <title> Concurrency Control and Recovery in Database Systems, </title> <publisher> Addison-Wesley, </publisher> <year> 1987. </year>
Reference-contexts: As a result, most recent commercial and experimental DBMSs have been constructed to run in such environments. These systems are referred to as client-server DBMSs. Recovery has long been studied in centralized and distributed database systems <ref> [Gray78, Lind79, Gray81, Moha90, BHG87, GR92] </ref> and more recently in architectures such as shared-disk systems [MN91, Lome90, Rahm91] and distributed transaction facilities [DST87, HMSC88]. However, little has been published about recovery issues for client-server database systems. <p> During normal operation, checkpoints are taken periodically. ARIES uses a form of fuzzy checkpoints <ref> [BHG87] </ref> which are extremely inexpensive. When a checkpoint is taken, a checkpoint record (or possibly several, if there are constraints on log record size) is constructed which includes the contents of the Transaction Table and the Dirty Page Table.
Reference: [Bhid88] <author> Bhide, A., </author> <title> "An Analysis of Three Transaction Processing Architectures", </title> <booktitle> Proc. 14th VLDB Conf., </booktitle> <address> Los Angeles, </address> <month> Aug. </month> <year> 1988. </year>
Reference-contexts: However, since ARIES/RRH can avoid redoing some work during Redo, ESM-CS could benefit by including full RRH support; this extension would require only slight modifications to the existing system. 6.2. Recovery in Shared-Disk Systems In a shared-disk system <ref> [Bhid88] </ref> there are multiple processing nodes, each with its own memory, that share a common pool of disks and communicate using messages. This environment has some similarities with the page-server environment.
Reference: [Catt91] <author> Cattell, R., </author> <title> "An Engineering Database Benchmark", The Benchmark Handbook: For Database and Transaction Processing Systems, </title> <editor> Gray, J., ed., </editor> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: For performance, database objects are "swizzled" into a main memory representation and cached in the client's memory so that they can be accessed directly by application programs. A workload which demonstrates the performance advantages of data-shipping architectures is described in <ref> [Catt91] </ref>. Implementing recovery in query-shipping architectures raises few new issues over traditional recovery approaches since the architecture of the database engine remains largely unchanged. In contrast, data-shipping architectures present a new set of problems and issues for the design of the recovery and logging subsystems of a DBMS.
Reference: [CDRS89] <author> Carey, M., DeWitt, D., Richardson, J., Shekita, E., </author> <title> "Storage Management for Objects in EXODUS," in Object-Oriented Concepts, Databases, and Applications, </title> <editor> W. Kim and F. Lochovsky, eds., </editor> <publisher> Addison-Wesley, </publisher> <year> 1989. </year>
Reference-contexts: However, little has been published about recovery issues for client-server database systems. This paper describes the implementation challenges and performance tradeoffs involved in implementing recovery in such a system, based on our experience in building the client-server implementation of the EXODUS storage manager <ref> [CDRS89, Exod91a, Exod91b] </ref>. Client-server DBMS architectures can be categorized according to whether they send requests to a server as queries or as requests for specific data items. We refer to systems of the former type as query-shipping systems and to those of the latter type as data-shipping systems. <p> In addition to supporting these new features, ESM-CS provides support for all of the features provided previously by the EXODUS storage manager, such as large and versioned objects <ref> [CDRS89] </ref>. The system runs under UNIX (tm) on DECstation, SPARCstation, and SUN-4 workstations.
Reference: [CFLS91] <author> Carey, M., Franklin, M., Livny, M., and Shekita, E., </author> <title> "Data Caching Tradeoffs in Client-Server DBMS Architectures", </title> <booktitle> Proc. ACM SIGMOD Int'l Conf. on Management of Data, </booktitle> <address> Denver, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: Before committing a transaction, the client sends all the pages modified by the transaction to the server. In the current implementation, a client's cache is purged upon the completion (commit or abort) of a transaction. Future enhancements will allow inter-transaction caching of pages <ref> [CFLS91] </ref>. Clients initiate transactions by sending a start transaction message to the server and can request the commit or abort of a transaction by sending a message to the server. The server can decide to abort a transaction due to a system error or deadlock. <p> Coarse-grained locking is provided as an option in ESM-CS and is used for performance enhancement in other systems such as the VAXcluster version of Rdb/VMS [Josh91]. Second, this solution would preclude the use of non-centralized locking algorithms in the page-server environment such as those described in <ref> [CFLS91, WR91] </ref>. It was shown in these papers that the overhead of centralized locking in the page-server environment can have a major performance impact under many workloads.
Reference: [Comm90] <author> The Committee for Advanced DBMS Function, </author> <title> "Third Generation Data Base System Manifesto", </title> <journal> SIG-MOD Record, </journal> <volume> Vol. 19, No. 3, </volume> <month> Sept. </month> <year> 1990. </year>
Reference-contexts: There is still much debate about the relative advantages of the different architectures with respect to current technology trends <ref> [Ston90, Comm90, DFMV90] </ref>. Most commercial relational database systems have adopted query-shipping architectures.
Reference: [DFMV90] <author> DeWitt, D., Futtersack, P., Maier, D., Velez, F., </author> <title> "A Study of Three Alternative Workstation-Server Architectures for Object-Oriented Database Systems," </title> <booktitle> Proc. 16th VLDB Conf., </booktitle> <address> Brisbane, Australia, </address> <month> Aug. </month> <year> 1990. </year>
Reference-contexts: Data-shipping systems can be further categorized as page-servers, which interact using physical units of data (e.g. individual pages or groups of pages such as segments) and object-servers, which interact using logical units of data (e.g. tuples or objects) <ref> [DFMV90] </ref>. There is still much debate about the relative advantages of the different architectures with respect to current technology trends [Ston90, Comm90, DFMV90]. Most commercial relational database systems have adopted query-shipping architectures. <p> There is still much debate about the relative advantages of the different architectures with respect to current technology trends <ref> [Ston90, Comm90, DFMV90] </ref>. Most commercial relational database systems have adopted query-shipping architectures.
Reference: [DST87] <author> Daniels, D., Spector, A., Thompson, D., </author> <title> "Distributed Logging for Transaction Processing", </title> <booktitle> Proc. ACM SIGMOD Int'l Conf. on Management of Data, </booktitle> <address> San Francisco, </address> <month> May, </month> <year> 1987. </year>
Reference-contexts: These systems are referred to as client-server DBMSs. Recovery has long been studied in centralized and distributed database systems [Gray78, Lind79, Gray81, Moha90, BHG87, GR92] and more recently in architectures such as shared-disk systems [MN91, Lome90, Rahm91] and distributed transaction facilities <ref> [DST87, HMSC88] </ref>. However, little has been published about recovery issues for client-server database systems. This paper describes the implementation challenges and performance tradeoffs involved in implementing recovery in such a system, based on our experience in building the client-server implementation of the EXODUS storage manager [CDRS89, Exod91a, Exod91b]. <p> Recovery in Distributed Transaction Facilities Recovery is also a concern in systems which provide general transaction support in a network computing environment. These systems include the distributed logging facility of CMU's Camelot <ref> [DST87] </ref> and IBM Almaden's QuickSilver system [HMSC88]. Both are intended to run in a hardware environment similar to the one for which ESM-CS was designed. However, both of these systems have fundamentally different software architectures than ESM-CS.
Reference: [Deux91] <editor> Deux, O., et al., </editor> <title> "The O2 System", </title> <journal> CACM, </journal> <volume> Vol. 34, No. 10, </volume> <month> Oct. </month> <year> 1991. </year>
Reference-contexts: In contrast to the relational DBMS systems, virtually all commercial object-oriented database systems (OODBMS) and many recent research prototypes have adopted some variant of the data-shipping approach (e.g., O2 <ref> [Deux91] </ref>, ObjectStore [LLOW91], ORION [KGBW90]). Data-shipping architectures have the potential advantage of avoiding bottlenecks at the server by exploiting the processing power and memory of the client machines. <p> This is due in part to the fact that many of the systems are commercial systems with proprietary implementations. The O2 system <ref> [Deux91] </ref> employs an ARIES-based approach that uses shadowing in order to avoid undo. The ORION-1SX system (an object-server version of ORION) [KGBW90] uses a FORCE policy and therefore keeps only an undo log.
Reference: [Exod91a] <author> EXODUS Project Group, </author> <title> EXODUS Storage Manager Architectural Overview, EXODUS Project Document, </title> <institution> University of Wisconsin - Madison, </institution> <month> Nov. </month> <year> 1991. </year>
Reference-contexts: However, little has been published about recovery issues for client-server database systems. This paper describes the implementation challenges and performance tradeoffs involved in implementing recovery in such a system, based on our experience in building the client-server implementation of the EXODUS storage manager <ref> [CDRS89, Exod91a, Exod91b] </ref>. Client-server DBMS architectures can be categorized according to whether they send requests to a server as queries or as requests for specific data items. We refer to systems of the former type as query-shipping systems and to those of the latter type as data-shipping systems. <p> A more detailed description of the architecture can be found in <ref> [Exod91a] </ref>. 2.1. Architecture Overview ESM-CS is a multi-user system with full support for indexing, concurrency control, and recovery, which is designed for use in a client-server environment.
Reference: [Exod91b] <author> EXODUS Project Group, </author> <title> Using the EXODUS Storage Manager V2.0, EXODUS Project Document, </title> <institution> University of Wisconsin - Madison, </institution> <month> Nov. </month> <year> 1991. </year>
Reference-contexts: However, little has been published about recovery issues for client-server database systems. This paper describes the implementation challenges and performance tradeoffs involved in implementing recovery in such a system, based on our experience in building the client-server implementation of the EXODUS storage manager <ref> [CDRS89, Exod91a, Exod91b] </ref>. Client-server DBMS architectures can be categorized according to whether they send requests to a server as queries or as requests for specific data items. We refer to systems of the former type as query-shipping systems and to those of the latter type as data-shipping systems.
Reference: [Gray78] <author> Gray, J., </author> <title> "Notes on Data Base Operating Systems", Operating Systems An advanced Course, </title> <editor> R. Bayer, R.M. Graham, G. Seegmuller, eds. </editor> <publisher> Springer-Verlag, </publisher> <address> N.Y., </address> <year> 1978. </year>
Reference-contexts: As a result, most recent commercial and experimental DBMSs have been constructed to run in such environments. These systems are referred to as client-server DBMSs. Recovery has long been studied in centralized and distributed database systems <ref> [Gray78, Lind79, Gray81, Moha90, BHG87, GR92] </ref> and more recently in architectures such as shared-disk systems [MN91, Lome90, Rahm91] and distributed transaction facilities [DST87, HMSC88]. However, little has been published about recovery issues for client-server database systems.
Reference: [Gray81] <author> Gray, J., et al., </author> <title> "The Recovery Manager of the System R Database Manager", </title> <journal> ACM Computing Surveys, </journal> <volume> Vol. 13, No. 2, </volume> <month> June, </month> <year> 1981. </year>
Reference-contexts: As a result, most recent commercial and experimental DBMSs have been constructed to run in such environments. These systems are referred to as client-server DBMSs. Recovery has long been studied in centralized and distributed database systems <ref> [Gray78, Lind79, Gray81, Moha90, BHG87, GR92] </ref> and more recently in architectures such as shared-disk systems [MN91, Lome90, Rahm91] and distributed transaction facilities [DST87, HMSC88]. However, little has been published about recovery issues for client-server database systems.
Reference: [Gray91] <author> Gray, J., </author> <type> personal communication, </type> <month> December </month> <year> 1991. </year>
Reference-contexts: First, it is clear from the results that reducing the amount of logged information can result in significant performance improvements, especially for small updates. The current log record overhead size of 64 bytes is slightly larger than the typical log record header size of approximately 50 bytes <ref> [Gray91, GR92] </ref>. With sufficient coding effort, the ESM-CS log record overhead could be reduced to 56 bytes (but not much smaller).
Reference: [GR92] <author> Gray, J., Reuter, A., </author> <title> Transaction Processing: Concepts and Techniques, </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <note> to appear 1992. </note>
Reference-contexts: As a result, most recent commercial and experimental DBMSs have been constructed to run in such environments. These systems are referred to as client-server DBMSs. Recovery has long been studied in centralized and distributed database systems <ref> [Gray78, Lind79, Gray81, Moha90, BHG87, GR92] </ref> and more recently in architectures such as shared-disk systems [MN91, Lome90, Rahm91] and distributed transaction facilities [DST87, HMSC88]. However, little has been published about recovery issues for client-server database systems. <p> First, it is clear from the results that reducing the amount of logged information can result in significant performance improvements, especially for small updates. The current log record overhead size of 64 bytes is slightly larger than the typical log record header size of approximately 50 bytes <ref> [Gray91, GR92] </ref>. With sufficient coding effort, the ESM-CS log record overhead could be reduced to 56 bytes (but not much smaller).
Reference: [HMSC88] <author> Haskin, R., Malachi, Y., Sawdon, W., Chan, G., </author> <title> "Recovery Management in QuickSilver", </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> Vol. 6, No. 1, </volume> <month> February, </month> <year> 1988. </year>
Reference-contexts: These systems are referred to as client-server DBMSs. Recovery has long been studied in centralized and distributed database systems [Gray78, Lind79, Gray81, Moha90, BHG87, GR92] and more recently in architectures such as shared-disk systems [MN91, Lome90, Rahm91] and distributed transaction facilities <ref> [DST87, HMSC88] </ref>. However, little has been published about recovery issues for client-server database systems. This paper describes the implementation challenges and performance tradeoffs involved in implementing recovery in such a system, based on our experience in building the client-server implementation of the EXODUS storage manager [CDRS89, Exod91a, Exod91b]. <p> Recovery in Distributed Transaction Facilities Recovery is also a concern in systems which provide general transaction support in a network computing environment. These systems include the distributed logging facility of CMU's Camelot [DST87] and IBM Almaden's QuickSilver system <ref> [HMSC88] </ref>. Both are intended to run in a hardware environment similar to the one for which ESM-CS was designed. However, both of these systems have fundamentally different software architectures than ESM-CS.
Reference: [HR83] <author> Haerder, T., Reuter, A., </author> <title> "Principles of Transaction Oriented Database Recovery A Taxonomy", </title> <journal> Computing Surveys, </journal> <volume> Vol. 15, No. 4, </volume> <month> December, </month> <year> 1983. </year>
Reference-contexts: The implementation of recovery also involves close cooperation with the buffer manager and the lock manager. The recovery algorithm is based on ARIES [Moha90]. ARIES was chosen because of its simplicity and flexibility, its ability to support the efficient STEAL/NO FORCE buffer management policy <ref> [HR83] </ref>, its support for savepoints and nested-top-level actions, and its ability to support fine-grained concurrency control and logical Undo.
Reference: [Josh91] <author> Joshi, A., </author> <title> "Adaptive Locking Strategies in a Multi-Node Data Sharing Environment", </title> <booktitle> Proc. 17th Int'l Conference on Very Large Data Bases, </booktitle> <address> Barcelona, </address> <month> September, </month> <year> 1991. </year> <month> - 26 </month> - 
Reference-contexts: First, the use of the GLM to store dirty page information would negate many of the performance benefits of using coarse-grained (e.g., file-level) locking. Coarse-grained locking is provided as an option in ESM-CS and is used for performance enhancement in other systems such as the VAXcluster version of Rdb/VMS <ref> [Josh91] </ref>. Second, this solution would preclude the use of non-centralized locking algorithms in the page-server environment such as those described in [CFLS91, WR91]. It was shown in these papers that the overhead of centralized locking in the page-server environment can have a major performance impact under many workloads.
Reference: [KGBW90] <author> Kim, W., Garza, J., Ballou, N., Woelk, D., </author> <title> "Architecture of the ORION Next-Generation Database Sys--tem", </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> Vol. 2, No. 1, </volume> <month> March, </month> <year> 1990. </year>
Reference-contexts: In contrast to the relational DBMS systems, virtually all commercial object-oriented database systems (OODBMS) and many recent research prototypes have adopted some variant of the data-shipping approach (e.g., O2 [Deux91], ObjectStore [LLOW91], ORION <ref> [KGBW90] </ref>). Data-shipping architectures have the potential advantage of avoiding bottlenecks at the server by exploiting the processing power and memory of the client machines. This is important for performance, since the majority of the processing power and memory in a client-server environment is likely to be at the client workstations. <p> This is due in part to the fact that many of the systems are commercial systems with proprietary implementations. The O2 system [Deux91] employs an ARIES-based approach that uses shadowing in order to avoid undo. The ORION-1SX system (an object-server version of ORION) <ref> [KGBW90] </ref> uses a FORCE policy and therefore keeps only an undo log. We are unaware of any systems which have implemented the STEAL/NO FORCE policy for a page-server (or object-server) system. 7.
Reference: [Lind79] <editor> Lindsay, B. et al, </editor> <booktitle> "Notes on Distributed Databases, </booktitle> <institution> IBM Research Report RJ2571, </institution> <address> San Jose, </address> <month> July </month> <year> 1979. </year>
Reference-contexts: As a result, most recent commercial and experimental DBMSs have been constructed to run in such environments. These systems are referred to as client-server DBMSs. Recovery has long been studied in centralized and distributed database systems <ref> [Gray78, Lind79, Gray81, Moha90, BHG87, GR92] </ref> and more recently in architectures such as shared-disk systems [MN91, Lome90, Rahm91] and distributed transaction facilities [DST87, HMSC88]. However, little has been published about recovery issues for client-server database systems. <p> An alternative solution we considered was to log the receipt of dirty pages at the server (similar to the logging of buffer operations in <ref> [Lind79] </ref>), and then during restart Analysis, to add pages encountered in such log records to the dirty page table. While this solution is also a correct one, we felt that the additional log overhead during normal operation could prove to be unacceptable.
Reference: [LLOW91] <author> Lamb, C., Landis, G., Orenstein, J. Weinreb, D., </author> <title> "The ObjectStore Database System", </title> <journal> CACM, </journal> <volume> Vol. 34, No. 10, </volume> <month> Oct. </month> <year> 1991. </year>
Reference-contexts: In contrast to the relational DBMS systems, virtually all commercial object-oriented database systems (OODBMS) and many recent research prototypes have adopted some variant of the data-shipping approach (e.g., O2 [Deux91], ObjectStore <ref> [LLOW91] </ref>, ORION [KGBW90]). Data-shipping architectures have the potential advantage of avoiding bottlenecks at the server by exploiting the processing power and memory of the client machines.
Reference: [Lome90] <author> Lomet, D., </author> <title> "Recovery for Shared Disk Systems Using Multiple Redo Logs", </title> <type> Technical Report CRL 90/4, </type> <institution> DEC Cambridge Research Lab, </institution> <address> Cambridge, MA, </address> <month> Oct. </month> <year> 1990. </year>
Reference-contexts: These systems are referred to as client-server DBMSs. Recovery has long been studied in centralized and distributed database systems [Gray78, Lind79, Gray81, Moha90, BHG87, GR92] and more recently in architectures such as shared-disk systems <ref> [MN91, Lome90, Rahm91] </ref> and distributed transaction facilities [DST87, HMSC88]. However, little has been published about recovery issues for client-server database systems. <p> Also described in [MP91] are locking protocols that allow fine-grained (e.g. record-level) locking in a data-sharing system; similar ideas could be used to allow fine-grained locking in ESM-CS. 6.2.2. Other Shared Disk Algorithms <ref> [Lome90] </ref> describes an algorithm for recovery in systems with multiple logs. This algorithm stores the previous "State Identifier" of an updated page (similar to a pageLSN or pageLRC) in the log record for the update, thereby allowing logs to be easily merged during redo. <p> As described in Section 2.1, we chose not to implement client logging for several reasons, including the unreliability of clients compared to the server and the expense of extra client disks. <ref> [Lome90] </ref> acknowledges the reliability problem and suggests possible approaches towards addressing it. Another algorithm for recovery in shared-disk systems with multiple logs is presented in [Rahm91].
Reference: [Moha90] <author> Mohan, C., Haderle, D., Lindsay, B., Pirahesh, H., and Schwarz, P., </author> <title> "ARIES: A Transaction Method Supporting Fine-Granularity Locking and Partial Rollbacks Using Write-Ahead Logging", </title> <institution> IBM Research Report RJ6649, IBM Almaden Research Center, </institution> <month> November, </month> <year> 1990, </year> <note> to appear in ACM Transactions on Database Systems. </note>
Reference-contexts: As a result, most recent commercial and experimental DBMSs have been constructed to run in such environments. These systems are referred to as client-server DBMSs. Recovery has long been studied in centralized and distributed database systems <ref> [Gray78, Lind79, Gray81, Moha90, BHG87, GR92] </ref> and more recently in architectures such as shared-disk systems [MN91, Lome90, Rahm91] and distributed transaction facilities [DST87, HMSC88]. However, little has been published about recovery issues for client-server database systems. <p> The recovery subsystem uses the information in the log to provide transaction rollback (e.g., abort) and system restart (i.e., crash recovery). The implementation of recovery also involves close cooperation with the buffer manager and the lock manager. The recovery algorithm is based on ARIES <ref> [Moha90] </ref>. ARIES was chosen because of its simplicity and flexibility, its ability to support the efficient STEAL/NO FORCE buffer management policy [HR83], its support for savepoints and nested-top-level actions, and its ability to support fine-grained concurrency control and logical Undo. However, the algorithm as specified in [Moha90] cannot be directly implemented <p> is based on ARIES <ref> [Moha90] </ref>. ARIES was chosen because of its simplicity and flexibility, its ability to support the efficient STEAL/NO FORCE buffer management policy [HR83], its support for savepoints and nested-top-level actions, and its ability to support fine-grained concurrency control and logical Undo. However, the algorithm as specified in [Moha90] cannot be directly implemented in a page-server architecture because the architecture violates some of the explicit and implicit assumptions upon which the original algorithm is based. <p> ESM-CS uses strict two-phase locking for data and non-two-phase locking for indexes. Data is locked at a page or coarser granularity. Index page splits are logged as nested top level actions <ref> [Moha90] </ref> so they are committed regardless of whether or not their enclosing transaction commits. During a transaction, clients cache data and index pages in their local buffer pool. Before committing a transaction, the client sends all the pages modified by the transaction to the server. <p> This discussion concentrates on the features of the algorithm that are pertinent to the ESM-CS environment. For a complete discussion of the algorithm, the reader is referred to <ref> [Moha90] </ref>. ARIES is a fairly recent refinement of the Write-Ahead-Logging (WAL) protocol (see Section 2.2.1 above). <p> Repeating history greatly simplifies the implementation of fine grained locking and the use of logical undo operations as described in <ref> [Moha90, MP91] </ref>. Also, as will be described in later sections, the resulting simplicity allows ARIES to be adapted for use in many computing environments. ARIES uses a three pass algorithm for restart recovery. The first pass is the Analysis pass, which processes the log forward from the most recent checkpoint.
Reference: [MN91] <author> Mohan, C., Narang, I., </author> <title> "Recovery and Coherency-Control Protocols for Fast Intersystem Page Transfer and Fine-Granularity Locking in a Shared Disks Transaction Environment", </title> <booktitle> Proc. 17th Int'l Conference on Very Large Data Bases, </booktitle> <address> Barcelona, </address> <month> September, </month> <year> 1991. </year>
Reference-contexts: These systems are referred to as client-server DBMSs. Recovery has long been studied in centralized and distributed database systems [Gray78, Lind79, Gray81, Moha90, BHG87, GR92] and more recently in architectures such as shared-disk systems <ref> [MN91, Lome90, Rahm91] </ref> and distributed transaction facilities [DST87, HMSC88]. However, little has been published about recovery issues for client-server database systems. <p> The algorithm used in ESM-CS required a similar extension, not for efficiency, but in order to operate correctly in the page-server environment. [MNP90] and <ref> [MN91] </ref> describe extensions to ARIES for the shared-disk environment. As would be expected, some of the solutions in that environment are applicable to the page-server environment, while others are not (for both correctness and efficiency reasons). We discuss these extensions and other related work in Section 6.
Reference: [MNP90] <author> Mohan, C., Narang, I., Palmer, J., </author> <title> "A Case Study of Problems in Migrating to Distributed Computing: Page Recovery Using Multiple Logs in the Shared Disks Environment", </title> <institution> IBM Research Report RJ7343, IBM Almaden Research Center, </institution> <month> March, </month> <year> 1990. </year>
Reference-contexts: The algorithm used in ESM-CS required a similar extension, not for efficiency, but in order to operate correctly in the page-server environment. <ref> [MNP90] </ref> and [MN91] describe extensions to ARIES for the shared-disk environment. As would be expected, some of the solutions in that environment are applicable to the page-server environment, while others are not (for both correctness and efficiency reasons). We discuss these extensions and other related work in Section 6. <p> ARIES Shared Disk Extensions ARIES has been extended to the shared disk environment as described in two recent papers. <ref> [MNP90] </ref> addresses the problems of migrating a single-site database system to the shared disk environment. The problem relevant to our work is the lack of monotonically increasing LSNs due to the use of a separate log for each node in the system.
Reference: [MP91] <author> Mohan, C., Pirahesh, H., "ARIES-RRH: </author> <title> Restricted Repeating of History in the ARIES Recovery Method", </title> <booktitle> Proc. 7th Int'l Conference on Data Engineering, </booktitle> <address> Kobe, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: We also discuss several engineering decisions that were made in the design of the ESM-CS log-ging and recovery subsystems. It should be noted that the ARIES algorithm has recently been extended in ways that are similar to some of the extensions we describe in this paper. <ref> [MP91] </ref> describes an extension of the algorithm which can reduce the work performed during system restart. The algorithm used in ESM-CS required a similar extension, not for efficiency, but in order to operate correctly in the page-server environment. [MNP90] and [MN91] describe extensions to ARIES for the shared-disk environment. <p> Repeating history greatly simplifies the implementation of fine grained locking and the use of logical undo operations as described in <ref> [Moha90, MP91] </ref>. Also, as will be described in later sections, the resulting simplicity allows ARIES to be adapted for use in many computing environments. ARIES uses a three pass algorithm for restart recovery. The first pass is the Analysis pass, which processes the log forward from the most recent checkpoint. <p> RELATED WORK In this section, we describe related work including: extensions to the ARIES algorithm, recovery algorithms that have been proposed for shared-disk architectures, recovery in distributed transaction facilities, and recovery in other page-server and object-server systems. 6.1. ARIES/RRH Extensions The recent ARIES/RRH (Restricted Repeating of History) algorithm <ref> [MP91] </ref> relaxes the ARIES requirement that history be repeated for all transactions during restart Redo. Under certain conditions explained in [MP91], updates for transactions that were in progress at the time of a crash need not be redone during restart. Restricted repeating of history requires the notion of conditional undo. <p> ARIES/RRH Extensions The recent ARIES/RRH (Restricted Repeating of History) algorithm <ref> [MP91] </ref> relaxes the ARIES requirement that history be repeated for all transactions during restart Redo. Under certain conditions explained in [MP91], updates for transactions that were in progress at the time of a crash need not be redone during restart. Restricted repeating of history requires the notion of conditional undo. <p> We used LRCs to solve a similar problem in ESM-CS, but due to the lack of synchronized clocks and local logs, our solution uses the estimated end-of-log LSN and approximate recoveryLSNs as described in Section 4. In <ref> [MP91] </ref> protocols are discussed for transferring pages between nodes in a shared-disk system where each node has its own log. <p> It was shown in these papers that the overhead of centralized locking in the page-server environment can have a major performance impact under many workloads. Also described in <ref> [MP91] </ref> are locking protocols that allow fine-grained (e.g. record-level) locking in a data-sharing system; similar ideas could be used to allow fine-grained locking in ESM-CS. 6.2.2. Other Shared Disk Algorithms [Lome90] describes an algorithm for recovery in systems with multiple logs.
Reference: [Rahm91] <author> Rahm, E. </author> , <title> "Recovery Concepts for Data Sharing Systems", </title> <booktitle> Proc. 21st Int'l Symposium of Fault-Tolerant Computing, </booktitle> <address> Montreal, </address> <month> June, </month> <year> 1991. </year>
Reference-contexts: These systems are referred to as client-server DBMSs. Recovery has long been studied in centralized and distributed database systems [Gray78, Lind79, Gray81, Moha90, BHG87, GR92] and more recently in architectures such as shared-disk systems <ref> [MN91, Lome90, Rahm91] </ref> and distributed transaction facilities [DST87, HMSC88]. However, little has been published about recovery issues for client-server database systems. <p> Another algorithm for recovery in shared-disk systems with multiple logs is presented in <ref> [Rahm91] </ref>. This algorithm is defined for a NO STEAL buffer management policy and thus uses logging only for Redo. - 24 - The algorithm differs from the ones described previously in that it assigns responsibility for recovery of certain partitions of the database to particular systems.
Reference: [RC89] <author> Richardson, J., Carey, M., </author> <title> "Persistence in the E Language: Issues and Implementation", </title> <journal> Software Practice and Experience, </journal> <volume> Vol. 19, </volume> <month> Dec. </month> <year> 1989. </year>
Reference-contexts: The system runs under UNIX (tm) on DECstation, SPARCstation, and SUN-4 workstations. The storage manager can be accessed through a C procedure call interface or through the E programming language <ref> [RC89, RCS91] </ref>, a persistent programming language based on C++. performance, and reliability characteristics of the clients, server, and the network.
Reference: [RCS91] <author> Richardson, J., Carey, M., and Schuh, D., </author> <title> The Design of the E Programming Language, </title> <note> submitted for publication. </note>
Reference-contexts: The system runs under UNIX (tm) on DECstation, SPARCstation, and SUN-4 workstations. The storage manager can be accessed through a C procedure call interface or through the E programming language <ref> [RC89, RCS91] </ref>, a persistent programming language based on C++. performance, and reliability characteristics of the clients, server, and the network.
Reference: [Ston90] <author> Stonebraker, M., </author> <title> "Architecture of Future Data Base Systems", </title> <journal> Data Engineering, </journal> <volume> Vol. 13, No. 4., </volume> <month> Dec. </month> <year> 1990. </year>
Reference-contexts: There is still much debate about the relative advantages of the different architectures with respect to current technology trends <ref> [Ston90, Comm90, DFMV90] </ref>. Most commercial relational database systems have adopted query-shipping architectures.
Reference: [WR91] <author> Wang, Y., Rowe, L., </author> <title> "Cache Consistency and Concurrency Control in a Client/Server DBMS Architecture", </title> <booktitle> Proc. ACM SIGMOD Int'l Conf. on Management of Data, </booktitle> <address> Denver, </address> <month> June </month> <year> 1991. </year> <month> - 27 </month> - 
Reference-contexts: Coarse-grained locking is provided as an option in ESM-CS and is used for performance enhancement in other systems such as the VAXcluster version of Rdb/VMS [Josh91]. Second, this solution would preclude the use of non-centralized locking algorithms in the page-server environment such as those described in <ref> [CFLS91, WR91] </ref>. It was shown in these papers that the overhead of centralized locking in the page-server environment can have a major performance impact under many workloads.
References-found: 31

