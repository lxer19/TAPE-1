URL: ftp://dis.cs.umass.edu/pub/team-aaai-ss.ps
Refering-URL: http://dis.cs.umass.edu/research/roles.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Learning Organizational Roles in a Heterogeneous Multi-agent System  
Author: M V Nagendra Prasad, Victor R Lesser and Susan Lander 
Address: Amherst, MA 01003.  
Affiliation: Computer Science Department, University of Massachusetts,  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Susan E. Lander and Victor R. Lesser. </author> <title> Sharing meta-information to guide cooperative search among heterogeneous reusable agents. </title> <institution> Computer Science Technical Report 94-48, University of Massachusetts, </institution> <year> 1994. </year> <note> To appear in IEEE Transactions on Knowledge and Data Engineering, </note> <year> 1996. </year>
Reference-contexts: Reusability of legacy systems and heterogeneity of agent representations demand a reexamination of many of the key assumptions about the amount of sharable information and the types of protocols for coordination. Lander and Lesser <ref> [1] </ref> developed the TEAM framework to examine cooperative search among a set of heterogeneous reusable agents. TEAM is an open system assembled through minimally customized integration of a dynamically selected subset from a catalogue of existing agents. <p> An agent may detect conflicts during this process and communicate feedback to the relevant agents; augmenting their local view of the composite search space with meta-level information about its local search space to minimize the likelihood of generating conflicting solutions <ref> [1] </ref>. For a composite solution in a given state, an agent can play one of a set of organizational roles (in TEAM, these roles are solution-initiator, solution-extender, or solution-critic). An organizational role represents a set of operators an agent can apply to a composite solution. <p> Learning algorithm for the potential of an operator again uses supervised-learning approach to prediction learning and is similar to that for utility. 4. Experiments To demonstrate the effectiveness of the mechanisms in L-TEAM and compare them to those in TEAM, we used the same domain as in <ref> [1] </ref> parametric design of steam condensers. The prototype multi-agent system for this domain, built on top of the TEAM framework, consists of seven agents: pump-agent, heat-exchanger-agent, motor-agent, vbelt-agent, shaft-agent, platform-agent, and frequency-critic. Problem specification consists of three parameters required capacity, platform side length, and maximum platform deflection.
Reference: [2] <author> M V NagendraPrasad, V. R. Lesser, and S. E. Lander. </author> <title> Learning organizational roles in a heterogeneous multi-agent system. </title> <institution> Computer Science Technical Report 95-35, University of Massachusetts, </institution> <year> 1995. </year>
Reference: [3] <author> M V Nagendra Prasad, Victor R Lesser, and Susan E Lander. </author> <title> Learning experiments in a heterogeneous multi-agent system. </title> <booktitle> In Proceedings of the IJCAI-95 Workshop on Adaptation and Learning in Multi-Agent Systems, </booktitle> <address> Montreal, CA., </address> <month> August </month> <year> 1995. </year>
Reference-contexts: The objective of this paper is to investigate the utility of machine learning techniques as an aid to the decision processes of agents that may be involved in problem-solving situations not necessarily known at the time of their design. The results in our previous paper <ref> [3] </ref> demonstrated the promise of learning techniques for such a task in L-TEAM, which is a learning version of TEAM. In this paper, we present further experimental details of our results and some new results since. 2.
Reference: [4] <author> R. Sutton. </author> <title> Learning to predict by the methods of temporal differences. </title> <journal> Machine Learning, </journal> <volume> 3 </volume> <pages> 9-44, </pages> <year> 1988. </year>
Reference-contexts: Depending on the objective function to be maximized, these UPC vectors are used to choose a role to be performed next. We use the supervised-learning approach to prediction learning (see <ref> [4] </ref>) to learn estimates for the UPC vectors for each of the states 1 . Obtaining measures of potential is a more involved process requiring a certain understanding of the system.
Reference: [5] <author> R. Whitehair and V. R. Lesser. </author> <title> A framework for the analysis of sophisticated control in interpretation systems. </title> <institution> Computer Science Technical Report 93-53, University of Massachusetts, </institution> <year> 1993. </year>
Reference-contexts: Roles for the agents are chosen based on the present problem solving situation (we will discuss situations in more detail in the following section). 3. Learning Organizational Roles The formal basis for learning search strategies adopted in this paper is derived from the UPC formalism for search control (see <ref> [5] </ref>) that relies on the calculation and use of the Utility, Probability and Cost (UPC) values associated with each hstate; op; f inal statei tuple. The Utility component represents the present state's estimate of the final state's expected value or utility if we apply operator op in the present state.
References-found: 5

