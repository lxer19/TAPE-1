URL: http://www.cs.yale.edu/HTML/YALE/CS/Linda/papers/report969.ps
Refering-URL: http://www.cs.yale.edu/HTML/YALE/CS/Linda/CM-5-Piranha.html
Root-URL: http://www.cs.yale.edu
Title: Adaptive Parallelism on Multiprocessors: Preliminary Experience with Piranha on the CM-5  
Author: Nicholas Carriero, Eric Freeman, and David Gelernter 
Date: May 20, 1993  
Address: New Haven, CT 06520  
Affiliation: Department of Computer Science Yale University  
Abstract: Mechanisms for sharing multiprocessors among users are still in their infancy|typical approaches include simple space-sharing and inefficient, restricted forms of time-sharing. In this work we investigate a new alternative: adaptive parallelism [2]. Adaptively parallel programs can execute over a dynamically changing set of processors; many such codes can easily and dynamically share a multiprocessor by individually adapting to execute in separate groups of processors that may vary with time. Adaptive parallelism has been successfully used in Piranha, an execution model for Linda 1 programs that turns idle networked workstations into a significant computing resource [4]. This work explores Piranha on the Connection Machine CM-5 multiprocessor. Our preliminary results suggest that adaptive parallelism provides not only substantial computing power for parallel programs but also an attractive alternative to traditional methods for sharing multiprocessors among users.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Nicholas Carriero and David Gelernter, </author> <title> How to write parallel programs: A first course. </title> <publisher> (Cam-bridge: MIT Press, </publisher> <year> 1990). </year>
Reference-contexts: In some cases, supercomputer-equivalents of computing power can be achieved merely by recycling the garbage. 3 Piranha The Piranha programming model is an adaptive version of master-worker parallelism <ref> [1] </ref>. Programmers specify in effect a single general purpose worker function, called piranha (). They do not explicitly create processes and their applications do not rely on any particular number of active processes.
Reference: [2] <author> Nicholas Carriero, David Gelernter, David Kaminsky, and Jeffrey Westbrook. </author> <title> "Adaptive Parallelism with Piranha", </title> <address> YALEU/DCS/RR-954, </address> <month> February </month> <year> 1993. </year>
Reference-contexts: 1 Introduction Large, scalable, multiprocessor computers are the emerging dominant species of supercomputer. How do we share such a machine among its users? Solutions are still in their infancy|space-sharing through static partitions and inefficient, restricted forms of time-sharing are currently common. In this paper we explore the adaptive parallelism <ref> [2] </ref> alternative. Adaptive parallelism refers to a parallel application that executes over a set of dynamically changing processors. Adaptive parallelism has been used successfully in Piranha, an execution model that harnesses the computing power of idle network workstations [4]. <p> The underlying Piranha system itself uses another tuple space to coordinate user and system activity. The Piranha system is discussed in greater detail and compared to alternative models in <ref> [2] </ref>. 4 Adaptive Parallelism on Multiprocessors How should large distributed-memory multiprocessors be shared? Most current approaches to the sharing of such machines center on space-sharing. The machine's nodes are typically paritioned into disjoint sets. A user grabs one set to run his job.
Reference: [3] <institution> The Connection Machine CM-5 Technical Summary, Thinking Machines Corporation, </institution> <address> Cam-bridge, MA, </address> <year> 1992. </year>
Reference-contexts: Adaptive parallelism refers to a parallel application that executes over a set of dynamically changing processors. Adaptive parallelism has been used successfully in Piranha, an execution model that harnesses the computing power of idle network workstations [4]. Specifically we discuss Piranha on the CM-5 multiprocessor <ref> [3] </ref>. 2 Our results suggest that adaptive parallelism can provide an alternative to traditional methods of sharing multiprocessors. fl This work is supported by Air Force Grant AFOSR-91-0098 and NASA Graduate Research Fellowship NGT-50858.
Reference: [4] <author> David Gelernter and David Kaminsky. </author> <title> "Supercomputing out of Recycled Garbage: Preliminary Experience with Piranha", </title> <booktitle> Proceedings of the ACM, International Conference on Supercomputing, </booktitle> <month> July 19-23, </month> <year> 1992. </year> <month> 10 </month>
Reference-contexts: In this paper we explore the adaptive parallelism [2] alternative. Adaptive parallelism refers to a parallel application that executes over a set of dynamically changing processors. Adaptive parallelism has been used successfully in Piranha, an execution model that harnesses the computing power of idle network workstations <ref> [4] </ref>. Specifically we discuss Piranha on the CM-5 multiprocessor [3]. 2 Our results suggest that adaptive parallelism can provide an alternative to traditional methods of sharing multiprocessors. fl This work is supported by Air Force Grant AFOSR-91-0098 and NASA Graduate Research Fellowship NGT-50858. <p> Work on the Piranha system (discussed in the next section) has shown that a variety of coarse-grain parallel applications can indeed be run effectively as adaptive applications on LANs <ref> [4] </ref>. In some cases, supercomputer-equivalents of computing power can be achieved merely by recycling the garbage. 3 Piranha The Piranha programming model is an adaptive version of master-worker parallelism [1]. Programmers specify in effect a single general purpose worker function, called piranha (). <p> wasted in batch mode to good use. 6.1 Preliminary Results Two Piranha programs developed in collaboration with other departments at Yale are used in our tests: a physics code for computing propagation of neutrinos and an electrical engineering code for finding dipole localization in biomagnetic imaging; both are described in <ref> [4] </ref>. The neutrino code is an "unordered bag of tasks" program. A number of tasks are generated and computed by the piranhas. The dipole code is also a bag of tasks program, but with two phases. The first phase locates minima and the second phase further localizes them [4]. <p> described in <ref> [4] </ref>. The neutrino code is an "unordered bag of tasks" program. A number of tasks are generated and computed by the piranhas. The dipole code is also a bag of tasks program, but with two phases. The first phase locates minima and the second phase further localizes them [4]. We present the sequential and parallel execution times of these programs in figure 4. The sequential version ran on a Sparc processor with the same performance as a CM-5 node. The piranhafied version ran on a 64-node CM-5 partition.
References-found: 4

