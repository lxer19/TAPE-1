URL: http://www.cs.pitt.edu/~gupta/research/SE/icse96.ps
Refering-URL: http://www.cs.pitt.edu/~gupta/research/testing.html
Root-URL: 
Email: fduester,gupta,soffag@cs.pitt.edu  
Title: A Demand-Driven Analyzer for Data Flow Testing at the Integration Level  
Author: Evelyn Duesterwald Rajiv Gupta Mary Lou Soffa 
Address: Pittsburgh, Pittsburgh, PA 15260  
Affiliation: Department of Computer Science University of  
Abstract: Data flow testing relies on static analysis for computing the def-use pairs that serve as the test case requirements for a program. When testing large programs, the individual procedures are first tested in isolation during unit testing. Integration testing is performed to specifically test the procedure interfaces. The procedures in a program are integrated and tested in several steps. Since each integration step requires data flow analysis to determine the new test requirements, the accumulated cost of repeatedly analyzing a program can considerably contribute to the overhead of testing. Data flow analysis is typically computed using an exhaustive approach or by using incremental data flow updates. This paper presents a new and more efficient approach to data flow integration testing that is based on demand-driven analysis. We developed and implemented a demand-driven analyzer and experimentally compared its performance during integration testing with the performance of (i) a traditional exhaustive analyzer and (ii) an incremental analyzer. Our experiments show that demand-driven analysis is faster than exhaustive analysis by up to a factor of 25. The demand-driven analyzer also outperforms the incremental analyzer in 80% of the test programs by up to a factor of 5. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> H. Agrawal, J. Horgan, E. Krauser, and S. </author> <title> London. Incremental regression testing. </title> <booktitle> In Conf. on Software Maintenance, </booktitle> <pages> pages 348-357, </pages> <month> Sept. `93. </month>
Reference-contexts: Another related field is regression testing. The analysis task in regression testing is to determine the test requirements for a modified program to ensure that no errors are introduced into previously tested code. Selective regression testing <ref> [12, 20, 6, 1] </ref> attempts to re-test only those def-use pairs that are affected by the modification. Note that the integration of a procedure could be viewed as a program modification.
Reference: [2] <author> D. Callahan. </author> <title> The program summary graph and flow-sensitive interprocedural data flow analysis. </title> <booktitle> In SIG-PLAN `88 Conf. on Programming Design and Implementation, </booktitle> <pages> pages 47-56, </pages> <month> June `88. </month>
Reference-contexts: We follow the two phase approach to interprocedural data flow analysis that accurately accounts for the calling context of each procedure <ref> [19, 2, 8] </ref>. During the first phase the side effects of (possibly recursive) procedures are analyzed independent of their calling con texts. The second phase determines the effect of a call by appropriately adjusting the side effect information to the context of the call. <p> The second phase determines the effect of a call by appropriately adjusting the side effect information to the context of the call. Unlike previous approaches that compute side effects exhaustively for all procedures <ref> [2, 8] </ref>, we compute the side effect variables in a demand-driven fashion as they are needed during the query evaluation.
Reference: [3] <author> K. Cooper. </author> <title> Analyzing aliases of reference formal parameters. </title> <booktitle> In 12th ACM Symp. on Principles of Programming Languages, </booktitle> <pages> pages 281-290, `85. </pages>
Reference-contexts: Ignoring aliasing during the analysis may lead to unsafe query responses; some of the def-use pairs may be missed. In [4] we discussed analysis refinements for safely handling aliasing in constant propagation using separately computed alias information <ref> [3] </ref>. We can use the same approach for safely refining the propagation rules from Figure 3 to handle reference parameters. According to these refinements P res v n is set to true if v or any alias of v is preserved during the execution of n.
Reference: [4] <author> E. Duesterwald, R. Gupta, </author> <title> and M.L. Soffa. Demand-driven computation of interprocedural data flow. </title> <booktitle> In 22nd ACM Symp. on Principles on Programming Languages, </booktitle> <pages> pages 37-48, </pages> <month> Jan. `95. </month>
Reference-contexts: Another approach, and the one advocated in this paper, uses demand-driven analysis. Demand-driven analysis avoids the shortcomings of previous analysis approaches. Exhaustive information propagation is entirely avoided and replaced with a goal-oriented search. We previously presented a general framework for demand-driven analysis <ref> [4] </ref> and showed that the demand-driven search can formally be modeled as the functional reversal of an originally exhaustive analysis. By its goal-oriented nature, the search can bypass the code regions that are of no interest to the current data flow demands. <p> Ignoring aliasing during the analysis may lead to unsafe query responses; some of the def-use pairs may be missed. In <ref> [4] </ref> we discussed analysis refinements for safely handling aliasing in constant propagation using separately computed alias information [3]. We can use the same approach for safely refining the propagation rules from Figure 3 to handle reference parameters. <p> Analogously, the set Def v n is determined by collecting the definitions not only for v but also for any alias of v. Further details can be found in <ref> [4] </ref>. 4.3 Caching The query evaluation of algorithm Compute RD can result in at most D fi N requests for side effect variables. <p> Queries for global variables may require much longer propagation paths than queries for locals, which explains why demand-driven analysis does not per form as well. 6 Related Work The demand-driven algorithm presented in this paper is a specialized and optimized instance of our formal framework for demand-driven interprocedural analy sis <ref> [4] </ref>. Other general frameworks for demand-driven analysis were presented by Reps, Horwitz and Sagiv [15, 10, 17]. Their recent approach [10, 17] transforms a data flow problem into a special kind of graph-reachability problem.
Reference: [5] <author> P.G. Frankl and E.J. Weyuker. </author> <title> An applicable family of data flow testing criteria. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-14(10):1483-1498, </volume> <month> Oct. `88. </month>
Reference-contexts: To demonstrate the benefits of demand-driven analysis, we consider its application in data flow integration testing and show how the cost of integration testing can be reduced through a demand-driven analysis design. Data flow testing uses coverage criteria <ref> [14, 5] </ref> to select the sets of definition-use (def-use) pairs in a program that serve as the test case requirements. Def-use pairs are determined by solving the data flow problem of reaching definitions. The testing of large programs usually takes place at several levels. <p> Hence, (y 5 ; y 7 ) is an intraprocedural pair. 3 Integration Testing In data flow testing, after the def-use pairs in a program have been computed, test cases are generated manually or automatically to exercise def-use pairs according to a selected coverage criterion <ref> [14, 5] </ref>. For example, the all-defs criterion requires that for each definition a path to at least one reachable use is exercised in some test case.
Reference: [6] <author> R. Gupta, M.J. Harrold, </author> <title> and M.L. Soffa. An approach to regression testing using slicing. </title> <booktitle> In Conf. on Software Maintenance, </booktitle> <pages> pages 299-308, </pages> <month> Nov. `92. </month>
Reference-contexts: Another related field is regression testing. The analysis task in regression testing is to determine the test requirements for a modified program to ensure that no errors are introduced into previously tested code. Selective regression testing <ref> [12, 20, 6, 1] </ref> attempts to re-test only those def-use pairs that are affected by the modification. Note that the integration of a procedure could be viewed as a program modification.
Reference: [7] <author> R. Gupta and M.L. Soffa. </author> <title> A framework for partial data flow analysis. </title> <booktitle> In Int. Conf. on Software Maintenance, </booktitle> <pages> pages 4-13, </pages> <month> Sept. `94. </month>
Reference-contexts: A framework for partial data flow analysis by Gupta and Soffa <ref> [7] </ref> yields search algorithms that are similar to our demand-driven algorithm, but are limited to intraprocedural analysis. Def-use pairs also play an important role in program slicing [21]. Interprocedu-ral def-use pairs are implicitly determined as part of an interprocedural program slice [21, 9].
Reference: [8] <author> M.J. Harrold and M.L. Soffa. </author> <title> Interprocedural data flow testing. </title> <booktitle> In 3rd Testing, Analysis and Verification Symp., </booktitle> <pages> pages 158-167, </pages> <month> Dec. `89. </month>
Reference-contexts: Def-use pairs are determined by solving the data flow problem of reaching definitions. The testing of large programs usually takes place at several levels. The individual program units are tested first in isolation during unit testing. Then, their interfaces are tested during one or more integration steps <ref> [8] </ref>. Each integration step requires the computation of the def-use pairs that cross the most recently integrated procedure interfaces to establish the new test requirements. Exhaustively recomputing reaching definitions and def-use pairs at the beginning of each integration step is inefficient and may easily result in overly high analysis times. <p> We follow the two phase approach to interprocedural data flow analysis that accurately accounts for the calling context of each procedure <ref> [19, 2, 8] </ref>. During the first phase the side effects of (possibly recursive) procedures are analyzed independent of their calling con texts. The second phase determines the effect of a call by appropriately adjusting the side effect information to the context of the call. <p> The second phase determines the effect of a call by appropriately adjusting the side effect information to the context of the call. Unlike previous approaches that compute side effects exhaustively for all procedures <ref> [2, 8] </ref>, we compute the side effect variables in a demand-driven fashion as they are needed during the query evaluation. <p> To handle more general types of program changes the incremental algorithms in [16, 13] perform additions, deletions and structural updates of the solution. Data flow testing at the integration level was previously discussed by Harrold and Soffa <ref> [8] </ref>. The authors presented an interprocedural data flow analysis to compute def-use pairs (exhaustively) over the complete program. Another related field is regression testing.
Reference: [9] <author> S. Horwitz, T. Reps, and D. Binkley. </author> <title> Interprocedural slicing using dependence graphs. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 12(1) </volume> <pages> 26-61, </pages> <year> 1990. </year>
Reference-contexts: Def-use pairs also play an important role in program slicing [21]. Interprocedu-ral def-use pairs are implicitly determined as part of an interprocedural program slice <ref> [21, 9] </ref>. However, previous precise interprocedural algorithms [9] are not suitable for computing interprocedural def-use pairs since their computation is not explicit but interleaved with the slice construction. Incremental data flow analysis [16, 13] addresses the problem of updating an existing exhaustive solution in response to program changes. <p> Def-use pairs also play an important role in program slicing [21]. Interprocedu-ral def-use pairs are implicitly determined as part of an interprocedural program slice [21, 9]. However, previous precise interprocedural algorithms <ref> [9] </ref> are not suitable for computing interprocedural def-use pairs since their computation is not explicit but interleaved with the slice construction. Incremental data flow analysis [16, 13] addresses the problem of updating an existing exhaustive solution in response to program changes.
Reference: [10] <author> S. Horwitz, T. Reps, and M. Sagiv. </author> <title> Demand inter-procedural dataflow analysis. </title> <booktitle> In 3rd ACM SIGSOFT Symp. on the Foundations of Software Engineering, </booktitle> <month> Oct. `95. </month>
Reference-contexts: Other general frameworks for demand-driven analysis were presented by Reps, Horwitz and Sagiv <ref> [15, 10, 17] </ref>. Their recent approach [10, 17] transforms a data flow problem into a special kind of graph-reachability problem. The graph for the reachability problem, the exploded supergraph, is obtained as an expansion of a program's control flow graph. <p> Other general frameworks for demand-driven analysis were presented by Reps, Horwitz and Sagiv [15, 10, 17]. Their recent approach <ref> [10, 17] </ref> transforms a data flow problem into a special kind of graph-reachability problem. The graph for the reachability problem, the exploded supergraph, is obtained as an expansion of a program's control flow graph.
Reference: [11] <author> G.J. Myers. </author> <title> Software reliability: principles and practices. </title> <publisher> Wiley-Interscience, </publisher> <address> New York, </address> <month> `76. </month>
Reference-contexts: The integration takes place in several integration steps. During each step, one or more procedures are selected for integration according to an integration strategy, such as bottom-up or top-down integration <ref> [11] </ref>. Testing at each integration step involves only def-use pairs that cross one of the currently integrated procedures. We assume for simplicity that during each step a single procedure q is integrated with one of its calling procedures p.
Reference: [12] <author> T.J. Ostrand and E.J. Weyuker. </author> <title> Using dataflow analysis for regression testing. </title> <booktitle> In 6th Annual Pacific Northwest Software Quality Conf., </booktitle> <pages> pages 233-247, </pages> <month> Sept. `88. </month>
Reference-contexts: Another related field is regression testing. The analysis task in regression testing is to determine the test requirements for a modified program to ensure that no errors are introduced into previously tested code. Selective regression testing <ref> [12, 20, 6, 1] </ref> attempts to re-test only those def-use pairs that are affected by the modification. Note that the integration of a procedure could be viewed as a program modification.
Reference: [13] <author> L. Pollock and M.L. Soffa. </author> <title> An incremental version of iterative data flow analysis. </title> <journal> IEEE Trans. on Software Engineering, </journal> <volume> 15(12) </volume> <pages> 1537-1549, </pages> <month> Dec. `89. </month>
Reference-contexts: The problem of avoiding the costly re-computation of exhaustive data flow solutions is not unique to integration testing. It arises in virtually all data flow applications that deal with evolving software. Previously, incremental data flow algorithms have been proposed to address this problem <ref> [16, 13] </ref>. Incremen Copyright 1996 IEEE. Published in the Proceedings of the 18th International Conference on Software Engineering (ICSE-18), March 25-29, 1996, Berlin, Germany. Personal use of this material is permitted. <p> When the query is propagated across the call proc3 (x) at node 4, the side effect variables Pres x 4 and 4 are computed. Pres x 4 = P x proc3 <ref> [13] </ref> = true in dicates that the query is preserved. Hence the new query ?RD (x; 4; P ) is generated and the definition Def x proc3 [13] = fx 15 g is collected. <p> Pres x 4 = P x proc3 <ref> [13] </ref> = true in dicates that the query is preserved. Hence the new query ?RD (x; 4; P ) is generated and the definition Def x proc3 [13] = fx 15 g is collected. Next, the query ?RD (x; 4; P ) is propagated through node 3 re sulting in the new query ?RD (x; 3; P ). <p> Interprocedu-ral def-use pairs are implicitly determined as part of an interprocedural program slice [21, 9]. However, previous precise interprocedural algorithms [9] are not suitable for computing interprocedural def-use pairs since their computation is not explicit but interleaved with the slice construction. Incremental data flow analysis <ref> [16, 13] </ref> addresses the problem of updating an existing exhaustive solution in response to program changes. Thus, in contrast to demand-driven analysis, incremental analysis requires the computation and maintenance of an exhaustive solution. As pointed out earlier, the incremental update problem that arises during intergration testing is particularly simple. <p> Thus, in contrast to demand-driven analysis, incremental analysis requires the computation and maintenance of an exhaustive solution. As pointed out earlier, the incremental update problem that arises during intergration testing is particularly simple. To handle more general types of program changes the incremental algorithms in <ref> [16, 13] </ref> perform additions, deletions and structural updates of the solution. Data flow testing at the integration level was previously discussed by Harrold and Soffa [8]. The authors presented an interprocedural data flow analysis to compute def-use pairs (exhaustively) over the complete program. Another related field is regression testing.
Reference: [14] <author> S. Rapps and E. Weyuker. </author> <title> Selecting software test data using data flow information. </title> <journal> IEEE Trans. on Software Engineering, </journal> <volume> 11(4) </volume> <pages> 367-375, </pages> <month> Apr. `85. </month>
Reference-contexts: To demonstrate the benefits of demand-driven analysis, we consider its application in data flow integration testing and show how the cost of integration testing can be reduced through a demand-driven analysis design. Data flow testing uses coverage criteria <ref> [14, 5] </ref> to select the sets of definition-use (def-use) pairs in a program that serve as the test case requirements. Def-use pairs are determined by solving the data flow problem of reaching definitions. The testing of large programs usually takes place at several levels. <p> Hence, (y 5 ; y 7 ) is an intraprocedural pair. 3 Integration Testing In data flow testing, after the def-use pairs in a program have been computed, test cases are generated manually or automatically to exercise def-use pairs according to a selected coverage criterion <ref> [14, 5] </ref>. For example, the all-defs criterion requires that for each definition a path to at least one reachable use is exercised in some test case.
Reference: [15] <author> T. Reps. </author> <title> Solving demand versions of interprocedu-ral analysis problems. </title> <booktitle> In 5th Int. Conf. on Compiler Construction, </booktitle> <pages> pages 389-403. </pages> <publisher> Springer Verlag, LNCS 786, </publisher> <month> Apr. `94. </month>
Reference-contexts: Other general frameworks for demand-driven analysis were presented by Reps, Horwitz and Sagiv <ref> [15, 10, 17] </ref>. Their recent approach [10, 17] transforms a data flow problem into a special kind of graph-reachability problem. The graph for the reachability problem, the exploded supergraph, is obtained as an expansion of a program's control flow graph.
Reference: [16] <author> B.G. Ryder and M.C. Paull. </author> <title> Incremental data flow analysis algorithms. </title> <journal> ACM Trans. Programming Languages and Systems, </journal> <volume> 10(1) </volume> <pages> 1-50, `88. </pages>
Reference-contexts: The problem of avoiding the costly re-computation of exhaustive data flow solutions is not unique to integration testing. It arises in virtually all data flow applications that deal with evolving software. Previously, incremental data flow algorithms have been proposed to address this problem <ref> [16, 13] </ref>. Incremen Copyright 1996 IEEE. Published in the Proceedings of the 18th International Conference on Software Engineering (ICSE-18), March 25-29, 1996, Berlin, Germany. Personal use of this material is permitted. <p> Interprocedu-ral def-use pairs are implicitly determined as part of an interprocedural program slice [21, 9]. However, previous precise interprocedural algorithms [9] are not suitable for computing interprocedural def-use pairs since their computation is not explicit but interleaved with the slice construction. Incremental data flow analysis <ref> [16, 13] </ref> addresses the problem of updating an existing exhaustive solution in response to program changes. Thus, in contrast to demand-driven analysis, incremental analysis requires the computation and maintenance of an exhaustive solution. As pointed out earlier, the incremental update problem that arises during intergration testing is particularly simple. <p> Thus, in contrast to demand-driven analysis, incremental analysis requires the computation and maintenance of an exhaustive solution. As pointed out earlier, the incremental update problem that arises during intergration testing is particularly simple. To handle more general types of program changes the incremental algorithms in <ref> [16, 13] </ref> perform additions, deletions and structural updates of the solution. Data flow testing at the integration level was previously discussed by Harrold and Soffa [8]. The authors presented an interprocedural data flow analysis to compute def-use pairs (exhaustively) over the complete program. Another related field is regression testing.
Reference: [17] <author> M. Sagiv, T. Reps, and S. Horwitz. </author> <title> Precise inter-procedural dataflow analysis with applications to constant propagation. </title> <booktitle> In FASE 95: Colloquim on Formal Approaches in Software Engineering, </booktitle> <pages> pages 651-665. </pages> <publisher> Springer Verlag, LNCS 915, </publisher> <month> May `95. </month>
Reference-contexts: Other general frameworks for demand-driven analysis were presented by Reps, Horwitz and Sagiv <ref> [15, 10, 17] </ref>. Their recent approach [10, 17] transforms a data flow problem into a special kind of graph-reachability problem. The graph for the reachability problem, the exploded supergraph, is obtained as an expansion of a program's control flow graph. <p> Other general frameworks for demand-driven analysis were presented by Reps, Horwitz and Sagiv [15, 10, 17]. Their recent approach <ref> [10, 17] </ref> transforms a data flow problem into a special kind of graph-reachability problem. The graph for the reachability problem, the exploded supergraph, is obtained as an expansion of a program's control flow graph. <p> During experimentation with the graph-reachability analyzer for copy constant propagation, the analyzer ran out of virtual memory for some C programs of about 1,300 lines [18]. Although their two-phase variation of the initial graph-reachability algorithm <ref> [17] </ref> resulted in a more compacted version of the exploded supergraphs for copy constant propagation, the size of the graph remains the same in problems such as reaching definitions or reachable uses.
Reference: [18] <author> M. Sagiv, T. Reps, and S. Horwitz. </author> <title> Precise interproce--dural dataflow analysis with applications to constant propagation. </title> <type> Technical Report TR-1284, </type> <institution> Computer Science Department, University of Wisconsin, Madi-son, WI, </institution> <month> Aug. `95. </month>
Reference-contexts: During experimentation with the graph-reachability analyzer for copy constant propagation, the analyzer ran out of virtual memory for some C programs of about 1,300 lines <ref> [18] </ref>. Although their two-phase variation of the initial graph-reachability algorithm [17] resulted in a more compacted version of the exploded supergraphs for copy constant propagation, the size of the graph remains the same in problems such as reaching definitions or reachable uses.
Reference: [19] <author> M. Sharir and A. Pnueli. </author> <title> Two approaches to interpro-cedural data flow analysis. </title> <editor> In S. Muchnick and N.D. Jones, editors, </editor> <title> Program Flow Analysis: </title> <booktitle> Theory and Applications, </booktitle> <pages> pages 189-234. </pages> <publisher> Prentice-Hall, </publisher> <pages> `81. </pages>
Reference-contexts: We follow the two phase approach to interprocedural data flow analysis that accurately accounts for the calling context of each procedure <ref> [19, 2, 8] </ref>. During the first phase the side effects of (possibly recursive) procedures are analyzed independent of their calling con texts. The second phase determines the effect of a call by appropriately adjusting the side effect information to the context of the call. <p> Importantly, the worst case complexity is no worse than for a standard exhaustive algorithm for interprocedural reaching definitions based on the Sharir/Pnueli framework <ref> [19] </ref>. 5 Experiments We implemented the demand-driven algorithm presented in the previous section in the context of bottom-up integration testing. The procedures in a program are integrated in depth-first (bottom-up) order of the program's call graph. <p> Two versions of each analyzer were implemented: a caching and a non-caching version. * The exhaustive analyzer The exhaustive interprocedural reaching definition analysis is based on a standard iterative fixed point algorithm of Sharir and Pnueli's functional approach to interprocedural analysis <ref> [19] </ref>. The exhaustive analyzer, that is implemented based on bitvectors, recomputes the reaching definitions in the program from scratch at the beginning of each integration step. However, we optimized the computation by performing exhaustive analysis only over the procedures that are affected by the current integration step.
Reference: [20] <author> A.M. Taha, S.M. Thebut, and S.S. Liu. </author> <title> An approach to software fault localization and revalidation based on incremental data flow analysis. </title> <booktitle> In COMPSAC`89, </booktitle> <pages> pages 527-534, </pages> <month> Sept. `89. </month>
Reference-contexts: Another related field is regression testing. The analysis task in regression testing is to determine the test requirements for a modified program to ensure that no errors are introduced into previously tested code. Selective regression testing <ref> [12, 20, 6, 1] </ref> attempts to re-test only those def-use pairs that are affected by the modification. Note that the integration of a procedure could be viewed as a program modification.
Reference: [21] <author> M. Weiser. </author> <title> Program slicing. </title> <journal> IEEE Trans. on Software Engineering, </journal> <volume> SE-10(4):352-357, </volume> <month> Jul. `84. </month>
Reference-contexts: A framework for partial data flow analysis by Gupta and Soffa [7] yields search algorithms that are similar to our demand-driven algorithm, but are limited to intraprocedural analysis. Def-use pairs also play an important role in program slicing <ref> [21] </ref>. Interprocedu-ral def-use pairs are implicitly determined as part of an interprocedural program slice [21, 9]. However, previous precise interprocedural algorithms [9] are not suitable for computing interprocedural def-use pairs since their computation is not explicit but interleaved with the slice construction. <p> Def-use pairs also play an important role in program slicing [21]. Interprocedu-ral def-use pairs are implicitly determined as part of an interprocedural program slice <ref> [21, 9] </ref>. However, previous precise interprocedural algorithms [9] are not suitable for computing interprocedural def-use pairs since their computation is not explicit but interleaved with the slice construction. Incremental data flow analysis [16, 13] addresses the problem of updating an existing exhaustive solution in response to program changes.
References-found: 21

