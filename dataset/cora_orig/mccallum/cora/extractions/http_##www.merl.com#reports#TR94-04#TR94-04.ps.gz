URL: http://www.merl.com/reports/TR94-04/TR94-04.ps.gz
Refering-URL: http://www.merl.com/reports/TR94-04/index.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: The Audio Interactive Tutor  
Author: Richard C. Waters 
Address: Cambridge, Massachusetts 02139  
Note: Copyright c Mitsubishi Electric Research Laboratories, 1994 201 Broadway,  
Date: April, 1994  
Affiliation: MITSUBISHI ELECTRIC RESEARCH LABORATORIES CAMBRIDGE RESEARCH CENTER  
Pubnum: MERL-TR-94-04  
Abstract: The Audio Interactive Tutor (Tait) is an interactive audio/oral computer-aided study device. It is most easily understood in comparison to the familiar notion of self-study audio tapes, which are non-interactive audio study devices. A self-study tape presents information and typically solicits responses from the user; however, it continues with a set pattern of instruction no matter what the user does, since it has no means of even detecting whether the user makes a response. Tait presents the same kind of output, but listens to the responses made by the user and alters the course of study depending on whether the responses are correct or incorrect. Tait supports an efficient approach to study that relies on This work may not be copied or reproduced in whole or in part for any commercial purpose. Permission to copy in whole or in part without payment of fee is granted for nonprofit educational and research purposes provided that all such whole or partial copies include the following: a notice that such copying is by permission of Mitsubishi Electric Research Laboratories of Cambridge, Massachusetts; an acknowledgment of the authors and individual contributions to the work; and all applicable portions of the copyright notice. Copying, reproduction, or republishing for any other purpose shall require a license with payment of fee to Mitsubishi Electric Research Laboratories. All rights reserved. sparse repetition carefully spread over time, rather than copious repetition.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Bernstein, </author> <title> "Speech Recognition Technology for Language Education", Speech Research & Technology Program note, </title> <booktitle> SRI International, </booktitle> <address> Menlo Park CA, </address> <month> November </month> <year> 1993. </year>
Reference-contexts: This has lead to the development of two systems based on their DECIPHER [2] speech recognition system. Like Summit, Decipher is a research prototype, workstation based, real-time, moderate size vocabulary, speaker independent, continuous speech recognition system. The Autograder system <ref> [1] </ref> extends DECIPHER so that it can be used to determine how well a person has spoken a foreign language utterance. As used in Autograder, DECIPHER is tuned to determine how accurately and how fluently a phrase has been uttered. <p> However, it is not clear whether the capabilities of Autograder can be achieved with commercially available, PC-based speech recognizers. The SRI VILI system: The second foreign language education system developed at SRI, called VILI <ref> [1] </ref>, bares more resemblance to Tait. Based an a database of stored utterances, and a `dialog grammar', VILI can engage a foreign language student in a simple dialog. This allows the student to practice listening to native speakers and replying.
Reference: [2] <author> M. Cohen, H. Murveit, J. Bernstein, P. Price, and M. Weintraub, </author> <title> "The DECIPHER Speech Recognition System", </title> <booktitle> Proc. International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <pages> 77-80, </pages> <year> 1990. </year>
Reference-contexts: The SRI Autograder system: Researchers in SRI International's Speech Research and Technology Program have also been investigating the application of speech recognition technology to foreign language education. This has lead to the development of two systems based on their DECIPHER <ref> [2] </ref> speech recognition system. Like Summit, Decipher is a research prototype, workstation based, real-time, moderate size vocabulary, speaker independent, continuous speech recognition system. The Autograder system [1] extends DECIPHER so that it can be used to determine how well a person has spoken a foreign language utterance.
Reference: [3] <author> Dragon Systems inc., </author> <title> "DragonDictate Speech Recognition Application Program Interface", beta release documentation, </title> <institution> Dragon Systems inc., </institution> <year> 1992. </year>
Reference-contexts: It would be easy to obtain high levels of sound quality in a commercial implementation of Tait. Speech recognizer. The beta test version of the DragonDictate 1k Speech Recognition Application Program Interface (Dragon API) <ref> [3] </ref> is used as the speech recognizer in the Tait prototype. The Dragon API is more or less typical of the state of the art of commercially available speech recognizers.
Reference: [4] <author> Hewlett-Packard Co., </author> <title> "Using the Audio Application Program Interface", user's manual, </title> <institution> Hewlett-Packard Co., </institution> <year> 1991. </year>
Reference-contexts: Using two different computers introduced the need for inter-machine networked communication; however, it made it possible to utilize a readily available commercial speech recognition system, without losing the benefits of a powerful programming environment for the rest of the implementation. Audio output. The HP-UX Audio Application Program Interface <ref> [4] </ref> in conjunction with the A/D and D/A hardware built into recent HP-700 series machines is used to support prerecorded sound in the Tait prototype.
Reference: [5] <editor> G.P. Kearsley (ed.), </editor> <booktitle> Artificial Intelligence & Instruction: Applications and Methods, </booktitle> <publisher> Addison Wesley, </publisher> <address> Reading MA, </address> <year> 1987. </year>
Reference-contexts: As with self-study tapes, all of Tait's output is prerecorded|speech generation is not required. Another point of comparison with Tait is other computer-aided instruction (CAI) systems (see for example <ref> [5] </ref>). Tait clearly fits the traditional outline of such systems. In particular, like essentially all CAI systems, Tait creates a model of what the user knows and has a controller that varies its behavior based on the evolving model.
Reference: [6] <author> M. McCandless, </author> <title> Word Rejection for a Literacy Tutor, </title> <type> SB Thesis, </type> <institution> MIT, </institution> <address> Cambridge MA, </address> <month> May </month> <year> 1992. </year>
Reference-contexts: However, in the past couple of years a few such systems have been developed. Most of these systems focus on foreign language education. The Summit Literacy Tutor: Members of the Spoken Language Systems Group at MIT have been working on a tutor for teaching people to read English <ref> [6] </ref>. This tutor is based on the group's Summit speech recognition system [9]. Summit is a research prototype of a workstation based, real-time, moderate size vocabulary, speaker independent, continuous speech recognizer. The goal of the Summit Literacy Tutor is to monitor a person who is reading aloud.
Reference: [7] <author> M. Phillips, et.al., </author> <title> "Language Tutor: An Interactive Aid for Teaching English and Japanese", </title> <editor> in V. Zue (editor), </editor> <booktitle> Annual Research Summary, Spoken Language Systems Group, </booktitle> <institution> MIT Laboratory for Computer Science, </institution> <address> Cambridge MA, </address> <month> November </month> <year> 1993. </year>
Reference-contexts: The Summit Language Tutor: Recently, the Spoken Language Systems Group at MIT has investigated using the technology underlying their Literacy Tutor as the basis for Foreign Language instruction <ref> [7] </ref>. In their initial prototype of a Language Tutor, the user is presented with written sentences in English or Japanese. The Tutor can read these sentences aloud for the user using a speech synthesizer and can monitor and comment on the user's pronunciation if he/she chooses to read the sentences.
Reference: [8] <author> P. Pimsleur, </author> <title> Speak & Read Essential Spanish, </title> <publisher> Heinle & Heinle Enterprises Inc., publishers 1988. </publisher>
Reference-contexts: In Tait, this is done by observing a user's responses and estimated how well he knows the item in question. It is interesting to note that the foreign language self-study tapes created by Pimsleur (see MERL-TR-94-04 April, 1994 The Audio Interactive Tutor 3 for example <ref> [8] </ref>) are based on the same basic theory of learning and retention. However, due to the inflexible nature of self-study tapes, the practice schedule used for each item has to be fixed in advance for all users.
Reference: [9] <author> V. Zue, et.al., </author> <title> "The SUMMIT Speech Recognition System; Phonological Modeling and Lexical Access", </title> <booktitle> Proc. International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <pages> 49-52, </pages> <address> Albuquerque NM, </address> <month> April </month> <year> 1990. </year> <month> MERL-TR-94-04 April, </month> <year> 1994 </year>
Reference-contexts: Most of these systems focus on foreign language education. The Summit Literacy Tutor: Members of the Spoken Language Systems Group at MIT have been working on a tutor for teaching people to read English [6]. This tutor is based on the group's Summit speech recognition system <ref> [9] </ref>. Summit is a research prototype of a workstation based, real-time, moderate size vocabulary, speaker independent, continuous speech recognizer. The goal of the Summit Literacy Tutor is to monitor a person who is reading aloud.
References-found: 9

