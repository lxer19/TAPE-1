URL: ftp://alife.santafe.edu/pub/USER-AREA/EC/GA/papers/over93.ps.gz
Refering-URL: http://alife.santafe.edu/~joke/encore/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: An Overview of Genetic Algorithms Part 1, Fundamentals  
Author: David Beasley David R. Bull Ralph R. Martin 
Note: c Inter-University Committee on Computing. All rights reserved. No part of this article may be reproduced for commercial purposes.  
Date: 1993, 15(2) 58-69.  
Address: Cardiff, Cardiff, CF2 4YN, UK  BS8 1TR, UK  Cardiff, Cardiff, CF2 4YN, UK  
Affiliation: Department of Computing Mathematics, University of  Department of Electrical and Electronic Engineering, University of Bristol, Bristol,  Department of Computing Mathematics, University of  
Pubnum: University Computing,  
Abstract-found: 0
Intro-found: 1
Reference: [Ack87] <author> D.H. Ackley. </author> <title> An empirical study of bit vector function optimization. </title> <editor> In L. Davis, editor, </editor> <title> Genetic Algorithms and Simulated Annealing, </title> <booktitle> chapter 13, </booktitle> <pages> pages 170-204. </pages> <publisher> Pitman, </publisher> <year> 1987. </year>
Reference-contexts: This is a disadvantage if the maximum is in a small region, surrounded on all sides by regions of low fitness. This kind of function is difficult to optimise by any method, and here the simplicity of the iterated search usually wins the day <ref> [Ack87] </ref>. 3.4 Simulated annealing This technique was invented by Kirkpatrick in 1982, and a good overview is given in [Rut89]. It is essentially a modified version of hill climbing. Starting from a random point in the search space, a random move is made.
Reference: [Axe87] <author> R. Axelrod. </author> <title> The evolution of strategies in the iterated prisoner's dilemma. </title> <editor> In L. Davis, editor, </editor> <title> Genetic Algorithms and Simulated Annealing, </title> <booktitle> chapter 3, </booktitle> <pages> pages 32-41. </pages> <publisher> Pitman, </publisher> <year> 1987. </year>
Reference-contexts: Machine learning. There are many applications of GAs to learning systems, the usual paradigm being that of a classifier system. The GA tries to evolve (i.e. learn) a set of if : : : then rules to deal with some particular situation. This has been applied to game playing <ref> [Axe87] </ref> and maze solving, as well as political and economic modelling [FMK91]. 13 A major use of machine learning techniques has been in the field of control [DeJ80, Hun92, KG90].
Reference: [Bak85] <author> J.E. Baker. </author> <title> Adaptive selection methods for genetic algorithms. </title> <editor> In J.J. Grefenstette, editor, </editor> <booktitle> Proceedings of the First International Conference on Genetic Algorithms, </booktitle> <pages> pages 101-111. </pages> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1985. </year>
Reference-contexts: As mentioned in Section 5.2.1, we do not want to allocate trials to individuals in direct proportion to raw fitness. Many alternative methods for remapping raw fitness, so as to prevent premature convergence, have been suggested. Several are described in <ref> [Bak85] </ref>. The major ones are described below. Fitness scaling is a commonly employed method. In this, the maximum number of reproductive trials allocated to an individual is set to a certain value, typically 2.0. <p> Performance will suffer if the extreme individual is exceptionally extreme. Fitness ranking is another commonly employed method, which overcomes the reliance on an extreme individual. Individuals are sorted in order of raw fitness, and then reproductive fitness values are assigned according to rank. This may be done linearly <ref> [Bak85] </ref>, or exponentially [Dav89]. This gives a similar result to fitness scaling, in that the ratio of the maximum to average fitness is normalised to a particular value. However it also ensures that the remapped fitnesses of intermediate individuals are regularly spread out. <p> The number of reproductive trials allocated to, say, the fifth best individual will always be the same, whatever the raw fitness values of those above (or below). The effect is that overcompression ceases to be a problem. Several experiments have shown ranking to be superior to fitness scaling <ref> [Bak85, Whi89] </ref>. Other methods (hybrid methods including using a dynamic population size) are described in [Bak85], but were found not to perform well. 5.3.2 Implicit fitness remapping Implicit fitness remapping methods fill the mating pool without passing through the intermediate stage of remapping the fitness. <p> The effect is that overcompression ceases to be a problem. Several experiments have shown ranking to be superior to fitness scaling [Bak85, Whi89]. Other methods (hybrid methods including using a dynamic population size) are described in <ref> [Bak85] </ref>, but were found not to perform well. 5.3.2 Implicit fitness remapping Implicit fitness remapping methods fill the mating pool without passing through the intermediate stage of remapping the fitness. Tournament selection [Bri81, GD91] is such a technique. There are several variants.
Reference: [Bak87] <author> J.E. Baker. </author> <title> Reducing bias and inefficiency in the selection algorithm. </title> <editor> In J.J. Grefenstette, editor, </editor> <booktitle> Proceedings of the Second International Conference on Genetic Algorithms, </booktitle> <pages> pages 14-21. </pages> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1987. </year>
Reference-contexts: A great deal of work has gone into finding the best way of doing this [Gol89a, p121]. A widely used method is known as stochastic remainder sampling without replacement. A better method, stochastic universal sampling was devised by Baker <ref> [Bak87] </ref>, and is elegantly simple and theoretically perfect. It is important not to confuse the sampling method with the parent selection method. Different parent selection methods may have advantages in different applications. But a good sampling method (such as Baker's) is always good, for all selection methods, in all applications.
Reference: [Bel57] <author> R. Bellman. </author> <title> Dynamic Programming. </title> <publisher> Princeton University Press, </publisher> <year> 1957. </year>
Reference-contexts: a fitness function, which must be maximised. (All techniques can also deal with minimisation tasks|but to avoid confusion we will assume, without loss of generality, that maximisation is the aim.) There are a great many optimisation techniques, some of which are only applicable to limited domains, for example, dynamic programming <ref> [Bel57] </ref>. This is a method for solving multi-step control problems which is only applicable where the overall fitness function is the sum of the fitness functions for each stage of the problem, and there is no interaction between stages.
Reference: [Boo87] <author> L. Booker. </author> <title> Improving search in genetic algorithms. </title> <editor> In L. Davis, editor, </editor> <title> Genetic Algorithms and Simulated Annealing, </title> <booktitle> chapter 5, </booktitle> <pages> pages 61-73. </pages> <publisher> Pitman, </publisher> <year> 1987. </year>
Reference-contexts: Assumption (1) can never be satisfied in practice. Because of this the performance of a GA will always be subject to stochastic errors. One such problem, which is also found in nature, is that of genetic drift <ref> [Boo87, GS87] </ref>. Even in the absence of any selection pressure (i.e. a constant fitness function), members of the population will still converge to some point in the solution space. This happens simply because of the accumulation of stochastic errors.
Reference: [Bri81] <author> A. Brindle. </author> <title> Genetic algorithms for function optimization. </title> <type> PhD thesis, </type> <institution> University of Alberta, </institution> <year> 1981. </year>
Reference-contexts: Other methods (hybrid methods including using a dynamic population size) are described in [Bak85], but were found not to perform well. 5.3.2 Implicit fitness remapping Implicit fitness remapping methods fill the mating pool without passing through the intermediate stage of remapping the fitness. Tournament selection <ref> [Bri81, GD91] </ref> is such a technique. There are several variants. In the simplest, binary tournament selection, pairs of individuals are picked at random from the population. Whichever has the higher fitness is copied into a mating pool (and then both are replaced in the original population).
Reference: [BUMK91] <author> S. Bagchi, S. Uckun, Y. Miyabe, and K. Kawamura. </author> <title> Exploring problem-specific recombination operators for job shop scheduling. </title> <editor> In R.K. Belew and L.B. Booker, editors, </editor> <booktitle> Proceedings of the Fourth International Conference on Genetic Algorithms, </booktitle> <pages> pages 10-17. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: Closely related is job shop scheduling, or time-tabling, where the task is to allocate efficiently a set of resources (machines, people, rooms, facilities) to carry out a set of tasks, such as the manufacture of a number of batches of machine components <ref> [BUMK91, Dav85b, Sys91, WSF89] </ref>. There are obvious constraints: for example, the same machine cannot be used for doing two different things at the same time. The optimum allocation has the earliest overall completion time, or the minimum amount of "idle time" for each resource.
Reference: [Bun84] <author> B.D. Bunday. </author> <title> Basic Optimisation methods. </title> <editor> Edward Arnold, </editor> <year> 1984. </year>
Reference-contexts: Points in the search space are selected randomly, or in some systematic way, and their fitness evaluated. This is a very unintelligent strategy, and is rarely used by itself. 3.2 Gradient methods A number of different methods for optimising well-behaved continuous functions have been developed <ref> [Bun84] </ref> which rely on using information about the gradient of the function to guide the direction of search. If the derivative of the function cannot be computed, because it is discontinuous, for example, these methods often fail. Such methods are generally referred to as hillclimbing.
Reference: [Chi89] <author> P-C. Chi. </author> <title> Genetic search with proportion estimates. </title> <editor> In J.D. Schaffer, editor, </editor> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <pages> pages 92-97. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1989. </year>
Reference-contexts: But each game will be different, so it is only ever possible to determine an approximation of the fitness of the rule set <ref> [Chi89] </ref>. Goldberg [Gol89a, p206-8] describes other techniques for approximate function evaluation, for example using an incremental computation based on the parents' fitness. 5.2 Fitness Range Problems At the start of a run, the values for each gene for different members of the population are randomly distributed.
Reference: [CJ91] <author> C. </author> <title> Caldwell and V.S. Johnston. Tracking a criminal suspect through "face-space" with a genetic algorithm. </title> <editor> In R.K. Belew and L.B. Booker, editors, </editor> <booktitle> Proceedings of the Fourth International Conference on Genetic Algorithms, </booktitle> <pages> pages 416-421. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year> <month> 14 </month>
Reference-contexts: By comparing a random sample of points on the two images, a GA can efficiently find a set of equations which transform one image to fit onto the other [Gol89a, p138]. A more unusual image processing task is that of producing pictures of criminal suspects <ref> [CJ91] </ref>. The GA replaces the role of the traditional photo-fit system, but uses a similar coding scheme. The GA generates a number of random faces, and the witness selects the two which are most similar to the suspect's face.
Reference: [Cra85] <author> N.L. Cramer. </author> <title> A representation for the adaptive generation of simple sequential programs. </title> <editor> In J.J. Grefenstette, editor, </editor> <booktitle> Proceedings of the First International Conference on Genetic Algorithms, </booktitle> <pages> pages 183-187. </pages> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1985. </year>
Reference-contexts: We have to know where the valid chromosomes are to ensure that nearby points can also be given good fitness values, and far away points given poor fitness values. But, if we don't know where the valid chromosomes are, this can't be done. Cramer <ref> [Cra85] </ref> suggested that if the natural goal of the problem is all-or-nothing, better results can be obtained if we invent meaningful sub-goals, and reward those. In the timetable problem, for example, we might give a reward for each of the classes which has its lessons allocated in a valid way.
Reference: [Dav85a] <author> L. Davis. </author> <title> Applying adaptive algorithms to epistatic domains. </title> <booktitle> In 9th Int. Joint Conf. on AI, </booktitle> <pages> pages 162-164, </pages> <year> 1985. </year>
Reference-contexts: Near optimal tours of several hundred cities can be determined. Bin packing, the task of determining how to fit a number of objects into a limited space, has many applications in industry, and has been widely studied <ref> [Dav85a, Jul92] </ref>. A particular example is the layout of VLSI integrated circuits [Fou85].
Reference: [Dav85b] <author> L. Davis. </author> <title> Job shop scheduling with genetic algorithms. </title> <editor> In J.J. Grefenstette, editor, </editor> <booktitle> Proceedings of the First International Conference on Genetic Algorithms, </booktitle> <pages> pages 136-140. </pages> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1985. </year>
Reference-contexts: Closely related is job shop scheduling, or time-tabling, where the task is to allocate efficiently a set of resources (machines, people, rooms, facilities) to carry out a set of tasks, such as the manufacture of a number of batches of machine components <ref> [BUMK91, Dav85b, Sys91, WSF89] </ref>. There are obvious constraints: for example, the same machine cannot be used for doing two different things at the same time. The optimum allocation has the earliest overall completion time, or the minimum amount of "idle time" for each resource.
Reference: [Dav87] <author> L. Davis. </author> <title> Genetic Algorithms and Simulated Annealing. </title> <publisher> Pitman, </publisher> <year> 1987. </year>
Reference-contexts: They can also be used for online process control, such as in a chemical plant, or load balancing on a multi-processor computer system. The basic principles of GAs were first laid down rigourously by Holland [Hol75], and are well described in many texts (e.g. <ref> [Dav87, Dav91, Gre86, Gre90, Gol89a, Mic92] </ref>). GAs simulate those processes in natural populations which are essential to evolution. Exactly which biological processes are essential for evolution, and which processes have little or no role to play is still a matter for research; but the foundations are clear.
Reference: [Dav89] <author> L. Davis. </author> <title> Adapting operator probabilities in genetic algorithms. </title> <editor> In J.D. Schaffer, editor, </editor> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <pages> pages 61-69. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1989. </year>
Reference-contexts: Fitness ranking is another commonly employed method, which overcomes the reliance on an extreme individual. Individuals are sorted in order of raw fitness, and then reproductive fitness values are assigned according to rank. This may be done linearly [Bak85], or exponentially <ref> [Dav89] </ref>. This gives a similar result to fitness scaling, in that the ratio of the maximum to average fitness is normalised to a particular value. However it also ensures that the remapped fitnesses of intermediate individuals are regularly spread out. <p> Most work has used a generation gap of 1|i.e. the whole population is replaced in each generation. This value is supported by the investigations of Grefenstette [Gre86]. However, a more recent trend has favoured steady-state replacement <ref> [Whi87, Whi89, Sys89, Dav89, Dav91] </ref>. This operates at the other extreme|in each generation only a few (typically two) individuals are replaced. This may be a better model of what happens in nature. In short-lived species, including some insects, parents lay eggs, and then die before their offspring hatch.
Reference: [Dav91] <author> L. Davis. </author> <title> Handbook of Genetic Algorithms. </title> <publisher> Van Nostrand Reinhold, </publisher> <year> 1991. </year>
Reference-contexts: They can also be used for online process control, such as in a chemical plant, or load balancing on a multi-processor computer system. The basic principles of GAs were first laid down rigourously by Holland [Hol75], and are well described in many texts (e.g. <ref> [Dav87, Dav91, Gre86, Gre90, Gol89a, Mic92] </ref>). GAs simulate those processes in natural populations which are essential to evolution. Exactly which biological processes are essential for evolution, and which processes have little or no role to play is still a matter for research; but the foundations are clear. <p> Most work has used a generation gap of 1|i.e. the whole population is replaced in each generation. This value is supported by the investigations of Grefenstette [Gre86]. However, a more recent trend has favoured steady-state replacement <ref> [Whi87, Whi89, Sys89, Dav89, Dav91] </ref>. This operates at the other extreme|in each generation only a few (typically two) individuals are replaced. This may be a better model of what happens in nature. In short-lived species, including some insects, parents lay eggs, and then die before their offspring hatch.
Reference: [DC87] <author> L. Davis and S. Coombs. </author> <title> Genetic algorithms and communication link speed design: theoretical considerations. </title> <editor> In J.J. Grefenstette, editor, </editor> <booktitle> Proceedings of the Second International Conference on Genetic Algorithms, </booktitle> <pages> pages 252-256. </pages> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1987. </year>
Reference-contexts: Goldberg modelled a gas pipeline system to determine a set of rules for controlling compressor stations and detecting leaks [Gol89a, p288]. Davis and Coombs used a similar approach to design communication network links <ref> [DC87] </ref>. 7 Summary GAs are a very broad and deep subject area, and most of our knowledge about them is empirical. This article has described the fundamental aspects of GAs; how they work, theoretical and practical aspects which underlie them, and how they compare with other techniques.
Reference: [DeJ75] <author> K. DeJong. </author> <title> The Analysis and behaviour of a Class of Genetic Adaptive Systems. </title> <type> PhD thesis, </type> <institution> University of Michigan, </institution> <year> 1975. </year>
Reference-contexts: Convergence is the progression towards increasing uniformity. A gene is said to have converged when 95% of the population share the same value <ref> [DeJ75] </ref>. The population is said to have converged when all of the genes have converged. approach that of the best individual. 3 Comparison with other techniques A number of other general purpose techniques have been proposed for use in connection with search and optimisation problems. <p> Some of these applications have been used in practice, while others remain as research topics. Numerical function optimisation. Most traditional GA research has concentrated in this area. GAs have been shown to be able to outperform conventional optimisation techniques on difficult, discontinuous, multimodal, noisy functions <ref> [DeJ75] </ref>. Image processing. With medical X-rays or satellite images, there is often a need to align two images of the same area, taken at different times.
Reference: [DeJ80] <author> K. DeJong. </author> <title> Adaptive system design: a genetic approach. </title> <journal> IEE Trans SMC, </journal> <volume> 10 </volume> <pages> 566-574, </pages> <year> 1980. </year>
Reference-contexts: This has been applied to game playing [Axe87] and maze solving, as well as political and economic modelling [FMK91]. 13 A major use of machine learning techniques has been in the field of control <ref> [DeJ80, Hun92, KG90] </ref>. In a large, complex system, such as a chemical plant, there may be many control parameters to be adjusted to keep the system running in an optimal way. Generally, the classifier system approach is used, so that rules are developed for controlling the system.
Reference: [DS89] <author> K. DeJong and W.M. Spears. </author> <title> Using genetic algorithms to solve NP-complete problems. </title> <editor> In J.D. Schaffer, editor, </editor> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <pages> pages 124-132. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1989. </year>
Reference-contexts: Good penalty functions, they say, can be constructed from the expected completion cost. That is, given an invalid chromosome, how much will it "cost" to turn it into a valid one? DeJong & Spears <ref> [DS89] </ref> describe a method suitable for optimising boolean logic expressions. There is much scope for work in this area. Approximate function evaluation is a technique which can sometimes be used if the fitness function is excessively slow or complex to evaluate.
Reference: [FMK91] <author> S. Forrest and G. Mayer-Kress. </author> <title> Genetic algorithms, nonlinear dynamical systems, and models of international security. </title> <editor> In L. Davis, editor, </editor> <booktitle> Handbook of Genetic Algorithms, chapter 13, </booktitle> <pages> pages 166-185. </pages> <publisher> Van Nostrand Reinhold, </publisher> <year> 1991. </year>
Reference-contexts: The GA tries to evolve (i.e. learn) a set of if : : : then rules to deal with some particular situation. This has been applied to game playing [Axe87] and maze solving, as well as political and economic modelling <ref> [FMK91] </ref>. 13 A major use of machine learning techniques has been in the field of control [DeJ80, Hun92, KG90]. In a large, complex system, such as a chemical plant, there may be many control parameters to be adjusted to keep the system running in an optimal way.
Reference: [Fog88] <author> T.C. Fogarty. </author> <title> Rule-based optimization of combustion in multiple burner furnaces and boiler plants. </title> <journal> Engineering Applications of Artificial Intelligence, </journal> <volume> 1(3) </volume> <pages> 203-209, </pages> <year> 1988. </year>
Reference-contexts: Generally, the classifier system approach is used, so that rules are developed for controlling the system. The fitness of a set of rules may be assessed by judging their performance either on the real system itself, or on a computer model of it. Fogarty <ref> [Fog88] </ref> used the former method to develop rules for controlling the optimum gas/air mixture in furnaces. Goldberg modelled a gas pipeline system to determine a set of rules for controlling compressor stations and detecting leaks [Gol89a, p288].
Reference: [Fou85] <author> M.P. Fourman. </author> <title> Compaction of symbolic layout using genetic algorithms. </title> <editor> In J.J. Grefenstette, editor, </editor> <booktitle> Proceedings of the First International Conference on Genetic Algorithms, </booktitle> <pages> pages 141-153. </pages> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1985. </year>
Reference-contexts: Near optimal tours of several hundred cities can be determined. Bin packing, the task of determining how to fit a number of objects into a limited space, has many applications in industry, and has been widely studied [Dav85a, Jul92]. A particular example is the layout of VLSI integrated circuits <ref> [Fou85] </ref>. Closely related is job shop scheduling, or time-tabling, where the task is to allocate efficiently a set of resources (machines, people, rooms, facilities) to carry out a set of tasks, such as the manufacture of a number of batches of machine components [BUMK91, Dav85b, Sys91, WSF89].
Reference: [GD91] <author> D.E. Goldberg and K. Deb. </author> <title> A comparative analysis of selection schemes used in genetic algorithms. </title> <editor> In G.J.E. Rawlins, editor, </editor> <booktitle> Foundations of Genetic Algorithms, </booktitle> <pages> pages 69-93. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: Other methods (hybrid methods including using a dynamic population size) are described in [Bak85], but were found not to perform well. 5.3.2 Implicit fitness remapping Implicit fitness remapping methods fill the mating pool without passing through the intermediate stage of remapping the fitness. Tournament selection <ref> [Bri81, GD91] </ref> is such a technique. There are several variants. In the simplest, binary tournament selection, pairs of individuals are picked at random from the population. Whichever has the higher fitness is copied into a mating pool (and then both are replaced in the original population). <p> By adjusting tournament size or win probability, the selection pressure can be made arbitrarily large or small. Goldberg & Deb <ref> [GD91] </ref> compare four different schemes; proportionate selection, fitness ranking, tournament selection and steady state selection (see Section 5.4). <p> Such a GA therefore has the opportunity to exploit a promising individual as soon as it is created. However, Goldberg & Deb's investigations <ref> [GD91] </ref> found that the advantages claimed for steady-state selection seem to be related to the high initial growth rate. The same effects could be obtained, they claim, using exponential fitness ranking, or large-size tournament selection.
Reference: [Gol85] <author> D.E. Goldberg. </author> <title> Alleles, loci, and the TSP. </title> <editor> In J.J. Grefenstette, editor, </editor> <booktitle> Proceedings of the First International Conference on Genetic Algorithms, </booktitle> <pages> pages 154-159. </pages> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1985. </year>
Reference-contexts: Combinatorial optimisation tasks require solutions to problems involving arrangements of discrete objects. This is quite unlike function optimisation, and different coding, recombination, and fitness function techniques are required. Probably the most widely studied combinatorial task is the travelling salesperson problem <ref> [Gol85, GS89, LHPM87] </ref>. Here the task is to find the shortest route for visiting a specified group of cities. Near optimal tours of several hundred cities can be determined.
Reference: [Gol89a] <author> D.E. Goldberg. </author> <title> Genetic Algorithms in search, optimization and machine learning. </title> <publisher> Addison-Wesley, </publisher> <year> 1989. </year>
Reference-contexts: They can also be used for online process control, such as in a chemical plant, or load balancing on a multi-processor computer system. The basic principles of GAs were first laid down rigourously by Holland [Hol75], and are well described in many texts (e.g. <ref> [Dav87, Dav91, Gre86, Gre90, Gol89a, Mic92] </ref>). GAs simulate those processes in natural populations which are essential to evolution. Exactly which biological processes are essential for evolution, and which processes have little or no role to play is still a matter for research; but the foundations are clear. <p> This property is known as implicit parallelism, and is one of the explanations for the good performance of GAs. 4.2 Building Block Hypothesis According to Goldberg <ref> [Gol89a, p41] </ref>, the power of the GA lies in it being able to find good building blocks. These are schemata of short defining length consisting of bits which work well together, and tend to lead to improved performance when incorporated into an individual. <p> it is difficult to know where the best balance lies (i.e. how much exploitation do we perform before giving up and exploring further?) Holland [Hol75] showed that a GA combines both exploration and exploitation at the same time in an optimal way (using a k-armed bandit analogy, also described in <ref> [Gol89a, p36] </ref>). However, although this may be theoretically true for a GA, there are inevitably problems in practice. <p> Another approach which has been taken in this situation is to use a penalty function, which represents how poor the chromosome is, and construct the fitness as (constant penalty) <ref> [Gol89a, p84] </ref>. Richardson et al [RPLH89] give some guidelines for constructing penalty functions. They say that those which represent the amount by which the constraints are violated are better than those which are based simply on the number of constraints which are violated. <p> A GA is robust enough to be able to converge in the face of the noise represented by the approximation. This technique was used in a medical image registration system, described by Goldberg <ref> [Gol89a, p138] </ref>. In attempting to align two images, it was found that optimum results were obtained when only 1/1000th of the pixels were tested. Approximate fitness techniques have to be used in cases where the fitness function is stochastic. <p> But each game will be different, so it is only ever possible to determine an approximation of the fitness of the rule set [Chi89]. Goldberg <ref> [Gol89a, p206-8] </ref> describes other techniques for approximate function evaluation, for example using an incremental computation based on the parents' fitness. 5.2 Fitness Range Problems At the start of a run, the values for each gene for different members of the population are randomly distributed. <p> Since only an integral number of copies of each individual can be placed in the mating pool, we have to convert the number to an integer in a way that does not introduce bias. A great deal of work has gone into finding the best way of doing this <ref> [Gol89a, p121] </ref>. A widely used method is known as stochastic remainder sampling without replacement. A better method, stochastic universal sampling was devised by Baker [Bak87], and is elegantly simple and theoretically perfect. It is important not to confuse the sampling method with the parent selection method. <p> By comparing a random sample of points on the two images, a GA can efficiently find a set of equations which transform one image to fit onto the other <ref> [Gol89a, p138] </ref>. A more unusual image processing task is that of producing pictures of criminal suspects [CJ91]. The GA replaces the role of the traditional photo-fit system, but uses a similar coding scheme. <p> Fogarty [Fog88] used the former method to develop rules for controlling the optimum gas/air mixture in furnaces. Goldberg modelled a gas pipeline system to determine a set of rules for controlling compressor stations and detecting leaks <ref> [Gol89a, p288] </ref>. Davis and Coombs used a similar approach to design communication network links [DC87]. 7 Summary GAs are a very broad and deep subject area, and most of our knowledge about them is empirical.
Reference: [Gol89b] <author> D.E. Goldberg. </author> <title> Sizing populations for serial and parallel genetic algorithms. </title> <editor> In J.D. Schaffer, editor, </editor> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <pages> pages 70-79. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1989. </year>
Reference-contexts: Once the population has converged, the ability of the GA to continue to search for better solutions is effectively eliminated: crossover of almost identical chromosomes produces little that is new. Only mutation remains to explore entirely new ground, and this simply performs a slow, random search <ref> [Gol89b] </ref>. The schema theorem says that we should allocate reproductive trials (or opportunities) to individuals in proportion to their relative fitness. But when we do this, premature convergence occurs|because the population is not infinite.
Reference: [Gre84] <author> J.J. Grefenstette. </author> <title> GENESIS: A system for using genetic search procedures. </title> <booktitle> In Proceedings of the 1984 Conference on Intelligent Systems and Machines, </booktitle> <pages> pages 161-165, </pages> <year> 1984. </year>
Reference-contexts: As mentioned above, if the fitness function is too flat, genetic drift will become a problem, so overcompression may lead not just to slower performance, but also to drift away from the maximum. Fitness windowing is used in Grefenstette's GENESIS GA package <ref> [Gre84] </ref>. This is the same as fitness scaling, except the the amount to be subtracted is chosen differently. The minimum fitness in each generation 11 is recorded, and the amount subtracted is the minimum fitness observed during the previous n generations, where n is typically 10.
Reference: [Gre86] <author> J.J. Grefenstette. </author> <title> Optimization of control parameters for genetic algorithms. </title> <journal> IEEE Trans SMC, </journal> <volume> 16 </volume> <pages> 122-128, </pages> <year> 1986. </year>
Reference-contexts: They can also be used for online process control, such as in a chemical plant, or load balancing on a multi-processor computer system. The basic principles of GAs were first laid down rigourously by Holland [Hol75], and are well described in many texts (e.g. <ref> [Dav87, Dav91, Gre86, Gre90, Gol89a, Mic92] </ref>). GAs simulate those processes in natural populations which are essential to evolution. Exactly which biological processes are essential for evolution, and which processes have little or no role to play is still a matter for research; but the foundations are clear. <p> Much research has concentrated on optimising all the other parts of a GA, since improvements can be applied to a variety of problems. Frequently, however, it has been found that only small improvements in performance can be made. Grefenstette <ref> [Gre86] </ref> sought an ideal set of parameters (in terms of crossover and mutation probabilities, population size, etc.) for a GA, but concluded that the basic mechanism of a GA was so robust that, within fairly wide margins, parameter settings were not critical. <p> Most work has used a generation gap of 1|i.e. the whole population is replaced in each generation. This value is supported by the investigations of Grefenstette <ref> [Gre86] </ref>. However, a more recent trend has favoured steady-state replacement [Whi87, Whi89, Sys89, Dav89, Dav91]. This operates at the other extreme|in each generation only a few (typically two) individuals are replaced. This may be a better model of what happens in nature.
Reference: [Gre87] <author> J.J. Grefenstette. </author> <title> Incorporating problem specific knowledge into genetic algorithms. </title> <editor> In L. Davis, editor, </editor> <title> Genetic Algorithms and Simulated Annealing, </title> <booktitle> chapter 4, </booktitle> <pages> pages 42-60. </pages> <publisher> Pitman, </publisher> <year> 1987. </year>
Reference-contexts: Most of the steps in the traditional GA (Figure 1) can be implemented using a number of different algorithms. For example, the initial population may be generated randomly, or using some heuristic method <ref> [Gre87, SG90] </ref>. In this section we describe different techniques for selecting two individuals to be mated. To understand the motivation behind these techniques, we must first describe the problems which they are trying to overcome.
Reference: [Gre90] <author> J.J. Grefenstette. </author> <title> Genetic algorithms and their applications. </title> <editor> In A. Kent and J.G. Williams, editors, </editor> <booktitle> Encyclopaedia of Computer Science and Technology, </booktitle> <pages> pages 139-152. </pages> <publisher> Marcel Dekker, </publisher> <year> 1990. </year>
Reference-contexts: They can also be used for online process control, such as in a chemical plant, or load balancing on a multi-processor computer system. The basic principles of GAs were first laid down rigourously by Holland [Hol75], and are well described in many texts (e.g. <ref> [Dav87, Dav91, Gre86, Gre90, Gol89a, Mic92] </ref>). GAs simulate those processes in natural populations which are essential to evolution. Exactly which biological processes are essential for evolution, and which processes have little or no role to play is still a matter for research; but the foundations are clear.
Reference: [GS87] <author> D.E. Goldberg and P. Segrest. </author> <title> Finite markov chain analysis of genetic algorithms. </title> <editor> In J.J. Grefen-stette, editor, </editor> <booktitle> Proceedings of the Second International Conference on Genetic Algorithms, </booktitle> <pages> pages 1-8. </pages> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1987. </year>
Reference-contexts: Assumption (1) can never be satisfied in practice. Because of this the performance of a GA will always be subject to stochastic errors. One such problem, which is also found in nature, is that of genetic drift <ref> [Boo87, GS87] </ref>. Even in the absence of any selection pressure (i.e. a constant fitness function), members of the population will still converge to some point in the solution space. This happens simply because of the accumulation of stochastic errors.
Reference: [GS89] <author> M. Gorges-Schleuter. </author> <title> ASPARAGOS: an asychronous parallel genetic optimization strategy. </title> <editor> In J.D. Schaffer, editor, </editor> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <pages> pages 422-427. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1989. </year>
Reference-contexts: Combinatorial optimisation tasks require solutions to problems involving arrangements of discrete objects. This is quite unlike function optimisation, and different coding, recombination, and fitness function techniques are required. Probably the most widely studied combinatorial task is the travelling salesperson problem <ref> [Gol85, GS89, LHPM87] </ref>. Here the task is to find the shortest route for visiting a specified group of cities. Near optimal tours of several hundred cities can be determined.
Reference: [Hol75] <author> J.H. Holland. </author> <title> Adaptation in Natural and Artificial Systems. </title> <publisher> MIT Press, </publisher> <year> 1975. </year>
Reference-contexts: They can also be used for online process control, such as in a chemical plant, or load balancing on a multi-processor computer system. The basic principles of GAs were first laid down rigourously by Holland <ref> [Hol75] </ref>, and are well described in many texts (e.g. [Dav87, Dav91, Gre86, Gre90, Gol89a, Mic92]). GAs simulate those processes in natural populations which are essential to evolution. <p> These parameters (known as genes) are joined together to form a string of values (often referred to as a chromosome). (Holland <ref> [Hol75] </ref> first showed, and many still believe, that the ideal is to use a binary alphabet for the string. <p> Nevertheless, several hypotheses have been put forward which can partially explain the success of GAs. These can be used to help us implement good GA applications. 4.1 Schemata and the Schema theorem Holland's schema theorem <ref> [Hol75] </ref> was the first rigourous explanation of how GAs work. A schema is a pattern of gene values which may be represented (in a binary coding) by a string of characters in the alphabet f0 1 #g. <p> Combinations of these two strategies can be quite effective, but it is difficult to know where the best balance lies (i.e. how much exploitation do we perform before giving up and exploring further?) Holland <ref> [Hol75] </ref> showed that a GA combines both exploration and exploitation at the same time in an optimal way (using a k-armed bandit analogy, also described in [Gol89a, p36]). However, although this may be theoretically true for a GA, there are inevitably problems in practice.
Reference: [HS91] <author> S.A. Harp and T. Samad. </author> <title> Genetic synthesis of neural network architecture. </title> <editor> In L. Davis, editor, </editor> <booktitle> Handbook of Genetic Algorithms, chapter 15, </booktitle> <pages> pages 202-221. </pages> <publisher> Van Nostrand Reinhold, </publisher> <year> 1991. </year>
Reference-contexts: They can be used for a variety of classification tasks, such as pattern recognition, machine learning, image processing and expert systems. Their area of application partly overlaps that of GAs. The use of GAs for the design of neural networks is a current research area <ref> [HS91] </ref>. Simulated annealing is a search technique which is based on physical, rather than biological processes, and this is described in Section 3.4.
Reference: [Hun92] <author> K.J. Hunt. </author> <title> Polynimial LQG and h 1 controller synthesis: a genetic algorithm aolution. </title> <booktitle> In Proc. IEEE Conf. Decision and Control, </booktitle> <month> pages -, </month> <year> 1992. </year>
Reference-contexts: This has been applied to game playing [Axe87] and maze solving, as well as political and economic modelling [FMK91]. 13 A major use of machine learning techniques has been in the field of control <ref> [DeJ80, Hun92, KG90] </ref>. In a large, complex system, such as a chemical plant, there may be many control parameters to be adjusted to keep the system running in an optimal way. Generally, the classifier system approach is used, so that rules are developed for controlling the system.
Reference: [Jul92] <author> K. Juliff. </author> <title> Using a multi chromosome genetic algorithm to pack a truck. </title> <type> Technical Report RMIT CS TR 92-2, </type> <institution> Royal Melbourne Institute of Technology, </institution> <month> August </month> <year> 1992. </year>
Reference-contexts: Near optimal tours of several hundred cities can be determined. Bin packing, the task of determining how to fit a number of objects into a limited space, has many applications in industry, and has been widely studied <ref> [Dav85a, Jul92] </ref>. A particular example is the layout of VLSI integrated circuits [Fou85].
Reference: [KG90] <author> K. Krishnakumar and D.E. Goldberg. </author> <title> Genetic algorithms in control system optimization. </title> <booktitle> In AIAA Guidance, Navigation, Control Conf., </booktitle> <pages> pages 1568-1577, </pages> <year> 1990. </year>
Reference-contexts: This has been applied to game playing [Axe87] and maze solving, as well as political and economic modelling [FMK91]. 13 A major use of machine learning techniques has been in the field of control <ref> [DeJ80, Hun92, KG90] </ref>. In a large, complex system, such as a chemical plant, there may be many control parameters to be adjusted to keep the system running in an optimal way. Generally, the classifier system approach is used, so that rules are developed for controlling the system.
Reference: [LHPM87] <author> G.E. Liepins, M.R. Hilliard, M. Palmer, and M. Morrow. </author> <title> Greedy genetics. </title> <editor> In J.J. Grefenstette, editor, </editor> <booktitle> Proceedings of the Second International Conference on Genetic Algorithms, </booktitle> <pages> pages 90-99. </pages> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1987. </year>
Reference-contexts: Combinatorial optimisation tasks require solutions to problems involving arrangements of discrete objects. This is quite unlike function optimisation, and different coding, recombination, and fitness function techniques are required. Probably the most widely studied combinatorial task is the travelling salesperson problem <ref> [Gol85, GS89, LHPM87] </ref>. Here the task is to find the shortest route for visiting a specified group of cities. Near optimal tours of several hundred cities can be determined.
Reference: [Mic92] <author> Z. Michalewicz. </author> <title> Genetic Algorithms + Data Structures = Evolution Programs. </title> <publisher> Springer-Verlag, </publisher> <year> 1992. </year>
Reference-contexts: They can also be used for online process control, such as in a chemical plant, or load balancing on a multi-processor computer system. The basic principles of GAs were first laid down rigourously by Holland [Hol75], and are well described in many texts (e.g. <ref> [Dav87, Dav91, Gre86, Gre90, Gol89a, Mic92] </ref>). GAs simulate those processes in natural populations which are essential to evolution. Exactly which biological processes are essential for evolution, and which processes have little or no role to play is still a matter for research; but the foundations are clear.
Reference: [RPLH89] <author> J.T. Richardson, M.R. Palmer, G.E. Liepins, </author> <title> and M.R. Hilliard. Some guidelines for genetic algorithms with penalty functions. </title> <editor> In J.D. Schaffer, editor, </editor> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <pages> pages 191-197. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1989. </year>
Reference-contexts: Another approach which has been taken in this situation is to use a penalty function, which represents how poor the chromosome is, and construct the fitness as (constant penalty) [Gol89a, p84]. Richardson et al <ref> [RPLH89] </ref> give some guidelines for constructing penalty functions. They say that those which represent the amount by which the constraints are violated are better than those which are based simply on the number of constraints which are violated.
Reference: [Rut89] <author> R.A Rutenbar. </author> <title> Simulated annealing algorithms: An overview. </title> <journal> IEEE Circuits and Devices Magazine, </journal> <pages> pages 19-26, </pages> <month> January </month> <year> 1989. </year>
Reference-contexts: This kind of function is difficult to optimise by any method, and here the simplicity of the iterated search usually wins the day [Ack87]. 3.4 Simulated annealing This technique was invented by Kirkpatrick in 1982, and a good overview is given in <ref> [Rut89] </ref>. It is essentially a modified version of hill climbing. Starting from a random point in the search space, a random move is made. If this move takes us to a higher point, it is accepted. <p> No information is saved from previous moves to guide the selection of new moves. This technique is still the topic of much active research (e.g. fast re-annealing, parallel annealing), and it has been used successfully in many applications, for example, VLSI circuit layout <ref> [Rut89] </ref>. 4 Why GAs work Most research into GAs has so far concentrated on finding empirical rules for getting them to perform well. There is no accepted "general theory" which explains exactly why GAs have the properties they do.
Reference: [SG90] <author> A.C. Schultz and J.J. Grefenstette. </author> <title> Improving tactical plans with genetic algorithms. </title> <booktitle> In Proc. IEEE Conf. Tools for AI, </booktitle> <pages> pages 328-344. </pages> <publisher> IEEE Society Press, </publisher> <year> 1990. </year>
Reference-contexts: Most of the steps in the traditional GA (Figure 1) can be implemented using a number of different algorithms. For example, the initial population may be generated randomly, or using some heuristic method <ref> [Gre87, SG90] </ref>. In this section we describe different techniques for selecting two individuals to be mated. To understand the motivation behind these techniques, we must first describe the problems which they are trying to overcome.
Reference: [Sys89] <author> G. Syswerda. </author> <title> Uniform crossover in genetic algorithms. </title> <editor> In J.D. Schaffer, editor, </editor> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <pages> pages 2-9. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1989. </year>
Reference-contexts: Most work has used a generation gap of 1|i.e. the whole population is replaced in each generation. This value is supported by the investigations of Grefenstette [Gre86]. However, a more recent trend has favoured steady-state replacement <ref> [Whi87, Whi89, Sys89, Dav89, Dav91] </ref>. This operates at the other extreme|in each generation only a few (typically two) individuals are replaced. This may be a better model of what happens in nature. In short-lived species, including some insects, parents lay eggs, and then die before their offspring hatch.
Reference: [Sys91] <author> G. Syswerda. </author> <title> Schedule optimization using genetic algorithms. </title> <editor> In L. Davis, editor, </editor> <booktitle> Handbook of Genetic Algorithms, chapter 21, </booktitle> <pages> pages 332-349. </pages> <publisher> Van Nostrand Reinhold, </publisher> <year> 1991. </year>
Reference-contexts: Closely related is job shop scheduling, or time-tabling, where the task is to allocate efficiently a set of resources (machines, people, rooms, facilities) to carry out a set of tasks, such as the manufacture of a number of batches of machine components <ref> [BUMK91, Dav85b, Sys91, WSF89] </ref>. There are obvious constraints: for example, the same machine cannot be used for doing two different things at the same time. The optimum allocation has the earliest overall completion time, or the minimum amount of "idle time" for each resource.
Reference: [Whi87] <author> D. Whitley. </author> <title> Using reproductive evaluation to improve genetic search and heuristic discovery. </title> <editor> In J.J. Grefenstette, editor, </editor> <booktitle> Proceedings of the Second International Conference on Genetic Algorithms, </booktitle> <pages> pages 108-115. </pages> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1987. </year>
Reference-contexts: Most work has used a generation gap of 1|i.e. the whole population is replaced in each generation. This value is supported by the investigations of Grefenstette [Gre86]. However, a more recent trend has favoured steady-state replacement <ref> [Whi87, Whi89, Sys89, Dav89, Dav91] </ref>. This operates at the other extreme|in each generation only a few (typically two) individuals are replaced. This may be a better model of what happens in nature. In short-lived species, including some insects, parents lay eggs, and then die before their offspring hatch.
Reference: [Whi89] <author> D. Whitley. </author> <title> The GENITOR algorithm and selection pressure: why rank-based allocation of reproductive trials is best. </title> <editor> In J.D. Schaffer, editor, </editor> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <pages> pages 116-121. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1989. </year>
Reference-contexts: The number of reproductive trials allocated to, say, the fifth best individual will always be the same, whatever the raw fitness values of those above (or below). The effect is that overcompression ceases to be a problem. Several experiments have shown ranking to be superior to fitness scaling <ref> [Bak85, Whi89] </ref>. Other methods (hybrid methods including using a dynamic population size) are described in [Bak85], but were found not to perform well. 5.3.2 Implicit fitness remapping Implicit fitness remapping methods fill the mating pool without passing through the intermediate stage of remapping the fitness. <p> Most work has used a generation gap of 1|i.e. the whole population is replaced in each generation. This value is supported by the investigations of Grefenstette [Gre86]. However, a more recent trend has favoured steady-state replacement <ref> [Whi87, Whi89, Sys89, Dav89, Dav91] </ref>. This operates at the other extreme|in each generation only a few (typically two) individuals are replaced. This may be a better model of what happens in nature. In short-lived species, including some insects, parents lay eggs, and then die before their offspring hatch. <p> Several schemes are possible, including: 1. selection of parents according to fitness, and selection of replacements at random 2. selection of parents at random, and selection of replacements by inverse fitness 3. selection of both parents and replacements according to fitness/inverse fitness For example, Whitley's GENITOR algorithm <ref> [Whi89] </ref>, selects parents according to their ranked fitness score, and the offspring replace the the two worst members of the population.
Reference: [WSF89] <author> D. Whitley, T. Starkweather, and D. Fuquay. </author> <title> Scheduling problems and travelling salesmen: The genetic edge recombination operator. </title> <editor> In J.D. Schaffer, editor, </editor> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <pages> pages 133-140. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1989. </year> <month> 16 </month>
Reference-contexts: Closely related is job shop scheduling, or time-tabling, where the task is to allocate efficiently a set of resources (machines, people, rooms, facilities) to carry out a set of tasks, such as the manufacture of a number of batches of machine components <ref> [BUMK91, Dav85b, Sys91, WSF89] </ref>. There are obvious constraints: for example, the same machine cannot be used for doing two different things at the same time. The optimum allocation has the earliest overall completion time, or the minimum amount of "idle time" for each resource.
References-found: 49

