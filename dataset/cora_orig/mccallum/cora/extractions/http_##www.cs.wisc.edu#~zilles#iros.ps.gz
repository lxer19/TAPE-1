URL: http://www.cs.wisc.edu/~zilles/iros.ps.gz
Refering-URL: http://www.cs.wisc.edu/~zilles/zilles.html
Root-URL: 
Title: A Constraint-based God-object Method For Haptic Display  
Author: C. B. Zilles J. K. Salisbury 
Address: Cambridge, MA  
Affiliation: Department of Mechanical Engineering Artificial Intelligence Laboratory Massachusetts Institute of Technology  
Abstract: A haptic display system has three main components. The first is the haptic interface, or display device - generally some type of electro-mechanical system able to exert controllable forces on the user with one or more degrees of freedom. The second is the object model a mathematical representation of the object containing its shape and other properties related to the way it feels. The third component, the haptic rendering algorithm, joins the first two components to compute, in real time, the model-based forces to give the user the sensation of touching the simulated objects. This paper focuses on a new haptic rendering algorithm for generating convincing interaction forces for objects modeled as rigid polyhedra (Fig. 1). We create a virtual model of the haptic interface, called the god-object, which conforms to the virtual environment. The haptic interface can then be servo-ed to this virtual model. This algorithm is extensible to other functional descriptions and lays the groundwork for displaying not only shape information, but surface properties such as friction and compliance. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> N. Durlach et al, </author> <title> Virtual Reality: Scientific and Technological Challenges, </title> <institution> Report produced for the National Research Council, National Academy of Sciences, </institution> <address> Washington D.C. </address> <month> December </month> <year> 1994. </year>
Reference-contexts: 1 Introduction The process of feeling objects through a force-generating interface is familiar in the context of using teleoperator master devices to touch and interact with remotely located objects [7]. Recent interest in enabling interaction with virtual objects <ref> [1] </ref> has led us to investigate devices and algorithms which permit touch and manipulative interaction collectively, haptic interactions with these virtual objects. The PHANToM haptic interface [4] permits users to feel and control the forces arising from point inter made up of 616 polygons.
Reference: [2] <author> P. Dworkin and D. Zeltzer, </author> <title> "A New Model for Efficient Dynamic Simulation", </title> <booktitle> Proceedings Fourth Eurographics Workshop on Animation and Simulation, </booktitle> <address> pp.135-147, </address> <year> 1993. </year>
Reference-contexts: The term god-object has been previously used <ref> [2] </ref> in a similar spirit to describe a virtual object controlled by a human user in physical simulations. Using the history (the god-object location calculated in the previous servo cycle) and the current haptic interface point, a set of surfaces currently impeding motion can be found.
Reference: [3] <author> M. C. Lin, D. Manocha, and J. Canny, </author> <title> "Fast Collision Detection between Geometric Models," </title> <type> Tech Report TR93-004, </type> <institution> Department of Computer Science, University of North Carolina, </institution> <year> 1993. </year>
Reference-contexts: For objects with about 600 triangular facets the simulation runs at about 1 kHz. Much of the time is spent running the simple collision detection algorithm. With an improved collision detection algorithm <ref> [3] </ref> significant speedups can be expected.
Reference: [4] <author> T. Massie, </author> <title> "Design of a Force Reflecting Fingertip Stimulator", </title> <type> SB thesis, </type> <institution> MIT EECS Department, </institution> <month> May, </month> <year> 1993. </year>
Reference-contexts: Recent interest in enabling interaction with virtual objects [1] has led us to investigate devices and algorithms which permit touch and manipulative interaction collectively, haptic interactions with these virtual objects. The PHANToM haptic interface <ref> [4] </ref> permits users to feel and control the forces arising from point inter made up of 616 polygons. This is an example of the complexity of objects the god-object algorithm can allow the user to touch. actions with simulated objects.
Reference: [5] <author> T. Massie and K. Salisbury, </author> <title> "The PHANToM Haptic Interface: A Device for Probing Virtual Objects," </title> <booktitle> Proceedings of the ASME Winter Annual Meeting, Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems, </booktitle> <address> Chicago, IL, </address> <month> November </month> <year> 1994. </year>
Reference-contexts: Finally c) when the surfaces are almost parallel the force is too large by a factor of 2. forces, could have been taken to reach the same internal location (Figure 2a). One method <ref> [5] </ref> suggests subdividing the object volume and associating a sub-volume with each surface (Figure 2b). When inside a sub-volume the force is normal to the associated surface and the magnitude is a function of the distance from the surface, such as with Hooke's law, F x = kx.
Reference: [6] <author> K. Salisbury, D. Brock, T. Massie, N. Swarup, C. </author> <title> Zilles "Haptic Rendering: Programming Touch Interaction with Virtual Objects," </title> <booktitle> to appear in the Proceedings of the ACM 1995 Symposium on Interactive 3D Graphics, </booktitle> <address> Monterey CA, </address> <month> April </month> <year> 1995. </year>
Reference-contexts: Furthermore, the god-object implementation provides, with no additional computation, coordinates of the contact point suitable for visual display of haptic interactions. Our current research focuses on adding a number of important haptic effects to the above algorithm. <ref> [6] </ref> While the current algorithm faithfully reproduces the sharpness occuring at the discontinuity between adjacent surfaces, we have found that it is possible to interpolate surface normals between surfaces to smooth out these transitions in much the same way as is currently the practice with visual shading algorithms (e.g.
Reference: [7] <author> T. Sheridan, Telerobotics, </author> <title> Automation, and Supervisory Control, </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1992. </year>
Reference-contexts: 1 Introduction The process of feeling objects through a force-generating interface is familiar in the context of using teleoperator master devices to touch and interact with remotely located objects <ref> [7] </ref>. Recent interest in enabling interaction with virtual objects [1] has led us to investigate devices and algorithms which permit touch and manipulative interaction collectively, haptic interactions with these virtual objects.
Reference: [8] <author> C. Zilles, </author> <title> "Haptic Rendering using the Toolhandle Haptic Interface", </title> <type> MS-SB thesis, </type> <institution> MIT Mechanical Engineering Department, </institution> <month> May, </month> <year> 1995. </year>
References-found: 8

