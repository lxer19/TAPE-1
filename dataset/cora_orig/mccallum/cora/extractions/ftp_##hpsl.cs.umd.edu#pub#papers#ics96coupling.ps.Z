URL: ftp://hpsl.cs.umd.edu/pub/papers/ics96coupling.ps.Z
Refering-URL: http://www.cs.umd.edu/projects/hpsl/papers.brandnew/LocalResources/tech-10-23.htm
Root-URL: 
Email: franga,acha,edjlali,als,saltzg@cs.umd.edu  
Title: Runtime Coupling of Data-parallel Programs  
Author: M. Ranganathan, A. Acharya, G. Edjlali, A. Sussman and J. Saltz 
Address: College Park MD 20742  
Affiliation: Dept. of Computer Science and UMIACS University of Maryland,  
Abstract: We consider the problem of efficiently coupling multiple data-parallel programs at runtime. We propose an approach that establishes mappings between data structures in different data-parallel programs and implements a user-specified consistency model. Mappings are established at runtime and can be added and deleted while the programs being coupled are in execution. Mappings, or the identity of the processors involved, do not have to be known at compile-time or even link-time. Programs can be made to interact with different granularities of interaction without requiring any re-coding. A-priori knowledge of consistency requirements allows buffering of data as well as concurrent execution of the coupled applications. Efficient data movement is achieved by pre-computing an optimized schedule. We describe our prototype implementation and evaluate its performance using a set of synthetic benchmarks. We examine the variation of performance with variation in the consistency requirement. We demonstrate that the cost of the flexibility provided by our coupling scheme is not prohibitive when compared with a monolithic program that performs the same computation. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Francois Bodin, Peter Beckman, Dennis Gannon, Srinivas Narayana, and Shelby X. Yang. </author> <title> Distributed pC++: Basic ideas for an object parallel language. </title> <journal> Scientific Programming, </journal> <volume> 2(3), </volume> <month> Fall </month> <year> 1993. </year>
Reference-contexts: Efficient data movement is achieved by pre-computing an optimized plan (schedule) for data movement. Our prototype implementation uses a generalized data movement library called Meta-Chaos [3] and is able to couple data-parallel programs written in different languages (including High Performance Fortran (HPF) [2], C and pC++ <ref> [1] </ref>) and using different communication libraries (including Multiblock PARTI [12] and CHAOS [6]). By coupling multiple concurrently executing data parallel applications, we gain the added benefit of combining task and data parallelism.
Reference: [2] <author> C.Koebel, D.Loveman, R.Schreiber, G.Steele Jr., and M.Zosel. </author> <title> The High Performance Fortran Handbook. </title> <publisher> The MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: Efficient data movement is achieved by pre-computing an optimized plan (schedule) for data movement. Our prototype implementation uses a generalized data movement library called Meta-Chaos [3] and is able to couple data-parallel programs written in different languages (including High Performance Fortran (HPF) <ref> [2] </ref>, C and pC++ [1]) and using different communication libraries (including Multiblock PARTI [12] and CHAOS [6]). By coupling multiple concurrently executing data parallel applications, we gain the added benefit of combining task and data parallelism.
Reference: [3] <author> Guy Edjlali et. al. </author> <title> Meta-Chaos an inter-operability layer for data-parallel programs. </title> <note> Technical Report In Preparation., Center For Research on Parallel Computation, </note> <year> 1996. </year>
Reference-contexts: A-priori knowledge of the consistency requirements at run-time allows concurrent execution of interacting programs by buffering the data being communicated. Efficient data movement is achieved by pre-computing an optimized plan (schedule) for data movement. Our prototype implementation uses a generalized data movement library called Meta-Chaos <ref> [3] </ref> and is able to couple data-parallel programs written in different languages (including High Performance Fortran (HPF) [2], C and pC++ [1]) and using different communication libraries (including Multiblock PARTI [12] and CHAOS [6]). <p> In contrast to other approaches that require language extensions to achieve this [4, 11], our approach can work with off-the-shelf language implementations as long as the implementations provide a small number of query functions about the distributions of data structures <ref> [3] </ref>. We have developed a prototype implementation based on this approach. Our implementation currently runs on a cluster of four-processor Digital Alpha Server 4/2100 symmetric multiprocessors. <p> The nodes are connected by an FDDI network. The primary goals of our implementation were language independence and efficiency. The concern for language independence prompted the use of the Meta-Chaos library <ref> [3] </ref>, which we describe below. For efficiency, we used three techniques. First, we used asynchronous, one-sided message-passing for inter-application data transfer; the goal being to overlap data transfer with computation. <p> A simple distributed protocol that guarantees that the consumer sees a consistent version of the source array has been implemented and is described in greater detail in [8]. 4.2 Data Transfer For inter-application data transfer, our library is built on a more basic data movement library called Meta-Chaos <ref> [3] </ref>. Meta-Chaos is able to manage data movement between data-parallel programs written in different languages (including HPF, C and pC++) and using different communication libraries (including Multiblock PARTI and CHAOS).
Reference: [4] <author> I. Foster, M. Wu, B. Avalani, and A. Choudhari. </author> <title> A compilation system that integrates High Performance Fortran and Fortran M. </title> <booktitle> In Proceedings of the 1994 Scalable High Performance Computing Conference. </booktitle> <publisher> IEEE Computer Society Press, </publisher> <year> 1994. </year>
Reference-contexts: By coupling multiple concurrently executing data parallel applications, we gain the added benefit of combining task and data parallelism. In contrast to other approaches that require language extensions to achieve this <ref> [4, 11] </ref>, our approach can work with off-the-shelf language implementations as long as the implementations provide a small number of query functions about the distributions of data structures [3]. We have developed a prototype implementation based on this approach.
Reference: [5] <author> A. Geist, A. Beguelin, J. Dongarra, W. Jiang, R. Manchek, and V. Sunderam. </author> <title> PVM 3 user's guide and reference manual. </title> <type> Technical Report ORNL/TM-12187, </type> <institution> Oak Ridge National Laboratory, </institution> <month> May </month> <year> 1993. </year>
Reference-contexts: These functions include queries on index ownership, location and mapping between global and local indices. For the underlying messaging layer between applications, we used PVM <ref> [5] </ref>. Each data parallel program is assigned a distinct PVM group. Asynchronous data transfer is achieved by using a dedicated thread for receiving messages.
Reference: [6] <author> Yuan-Shin Hwang, Bongki Moon, Shamik D. Sharma, Ravi Ponnusamy, Raja Das, and Joel H. Saltz. </author> <title> Runtime and language support for compiling adaptive irregular programs. </title> <journal> Software Practise and Experience, </journal> <volume> 25(6) </volume> <pages> 597-621, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: Our prototype implementation uses a generalized data movement library called Meta-Chaos [3] and is able to couple data-parallel programs written in different languages (including High Performance Fortran (HPF) [2], C and pC++ [1]) and using different communication libraries (including Multiblock PARTI [12] and CHAOS <ref> [6] </ref>). By coupling multiple concurrently executing data parallel applications, we gain the added benefit of combining task and data parallelism.
Reference: [7] <author> Message Passing Interface Forum. </author> <title> Document for a standard Message-Passing Interface. </title> <type> Technical Report CS-93-214, </type> <institution> University of Tennessee, </institution> <month> November </month> <year> 1993. </year>
Reference-contexts: Given that our assumption is that the source code for the individual applications is not available at the time the applications are to be composed, the performance would probably not be as good as our implementation. Communication libraries like PVM and MPI <ref> [7] </ref> may be used by the programmer to directly transfer messages from one data parallel task to another. However, such an approach burdens the programmer with having to understand low level details about data distributions and message passing.
Reference: [8] <author> M.Ranganathan, A.Acharya, G.Edjlali, A.Sussman, and J.Saltz. </author> <title> Run-time coupling of data-parallel programs. </title> <type> Technical Report CS-TR-3565, </type> <institution> UMIACS TR-95-116, University of Maryland, </institution> <year> 1995. </year>
Reference-contexts: Because of space limitations, we defer the description of dynamic mapping to a technical report <ref> [8] </ref>. 3.3 A simple example In this section, we illustrate the use of the proposed programming model with a simple example. Consider the two programs in Figure 1. Data parallel program pgm 1 registers its distributed array A with the global name A and the in mode. <p> These are not always detectable by looking at the mappings alone. In our implementation, we expect the programmer to be aware of these problems when building an interconnection of applications. We address these issues in greater detail in a technical report <ref> [8] </ref>. 4 Implementation We have implemented our system on a network of four-processor SMP Digital Alpha Server 4/2100 workstations running Digital Unix 3.2. The nodes are connected by an FDDI network. The primary goals of our implementation were language independence and efficiency. <p> Some coordination between the producer peers is required to ensure that this situation does not happen. A simple distributed protocol that guarantees that the consumer sees a consistent version of the source array has been implemented and is described in greater detail in <ref> [8] </ref>. 4.2 Data Transfer For inter-application data transfer, our library is built on a more basic data movement library called Meta-Chaos [3].
Reference: [9] <author> N.Carriero and D.Gelertner. </author> <title> Linda in context. </title> <journal> Communications of the ACM, </journal> <volume> 32(4), </volume> <year> 1989. </year>
Reference-contexts: Data parallel components can interact not only at their entry and exit points but also concurrently when they are in execution. However, we do not provide a means for remotely invoking procedures. Indeed, a software bus approach could complement our work extending it to allow this facility. Linda <ref> [9] </ref> offers a tuple-space-oriented programming model which could be used to couple programs. A stream-oriented model such as ours could be implemented on top of Linda.
Reference: [10] <author> James Purtillo. </author> <title> The Polylith software toolbus. </title> <type> Technical Report CS-TR-2469, </type> <institution> University of Maryland, Department of Computer Science and UMIACS, </institution> <month> March </month> <year> 1990. </year>
Reference-contexts: This shows that even in this case, only one of the programs, the consumer pays an significant cost. 6 Related Work Our approach is similar in some respects to the software bus approach used in Polylith <ref> [10] </ref>. Our approach differs from Polylith in that it is data-stream-driven rather than remote-procedure-call-driven. Data parallel components can interact not only at their entry and exit points but also concurrently when they are in execution. However, we do not provide a means for remotely invoking procedures.
Reference: [11] <author> J. Subhlok, D. O'Hallaron, and T. Gross. </author> <title> Task parallel programming in Fx. </title> <type> Technical report, </type> <institution> School of Computer Science, Carnegie Mellon University, Pittsburg, </institution> <year> 1994. </year>
Reference-contexts: By coupling multiple concurrently executing data parallel applications, we gain the added benefit of combining task and data parallelism. In contrast to other approaches that require language extensions to achieve this <ref> [4, 11] </ref>, our approach can work with off-the-shelf language implementations as long as the implementations provide a small number of query functions about the distributions of data structures [3]. We have developed a prototype implementation based on this approach.
Reference: [12] <author> Alan Sussman, Gagan Agrawal, and Joel Saltz. </author> <title> A manual for the multiblock PARTI runtime primitives, revision 4.1. </title> <institution> Technical Report CS-TR-3070.1 and UMIACS-TR-93-36.1, University of Maryland, Department of Computer Science and UMIACS, </institution> <month> December </month> <year> 1993. </year> <month> 8 </month>
Reference-contexts: Our prototype implementation uses a generalized data movement library called Meta-Chaos [3] and is able to couple data-parallel programs written in different languages (including High Performance Fortran (HPF) [2], C and pC++ [1]) and using different communication libraries (including Multiblock PARTI <ref> [12] </ref> and CHAOS [6]). By coupling multiple concurrently executing data parallel applications, we gain the added benefit of combining task and data parallelism.
References-found: 12

