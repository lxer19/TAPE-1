URL: http://www.cs.cornell.edu/Info/People/vladimir/ics97-sparse.ps.gz
Refering-URL: http://www.cs.cornell.edu/Info/People/vladimir/papers.html
Root-URL: 
Email: fvladimir,pingalig@cs.cornell.edu  
Title: Sparse code generation for imperfectly nested loops with dependences  
Author: Vladimir Kotlyar Keshav Pingali 
Address: Ithaca, NY 14853  
Affiliation: Department of Computer Science Cornell University,  
Abstract: Standard restructuring compiler tools are based on polyhedral algebra and cannot be used to analyze or restructure sparse matrix codes. We have recently shown that tools based on relational algebra can be used to generate an efficient sparse matrix program from the corresponding dense matrix program and a specification of the sparse matrix format. This work was restricted to DO-ALL loops and loops with reductions. In this paper, we extend this approach to loops with dependences. Although our results are restricted to Compressed Hyperplane Storage formats, they apply to both perfectly nested loops and imperfectly nested loops. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Bik, A. </author> <title> Compiler Support for Sparse Matrix Computations. </title> <type> PhD thesis, </type> <institution> Leiden University, </institution> <address> The Netherlands, </address> <month> May </month> <year> 1996. </year>
Reference-contexts: Dense loop nests are converted to relational queries as in (4). Array access functions generate appropriate se lection predicates. 2. A sparsity predicate is computed as described in <ref> [1, 5] </ref> and is converted into a selection in terms of the N Z (: : : ) predicates as in (5). 3. Equi-joins are discovered by "pushing" selections with equality predicates "through" cross-products. 4.
Reference: [2] <author> Bik, A. J., Knijnenburg, P. M., and Wijshoff, H. A. </author> <title> Reshaping access patterns for generating sparse codes. </title> <booktitle> In Seventh Annual Workshop on Languages and Compilers for Parallel Computing (Aug. </booktitle> <year> 1994). </year>
Reference-contexts: However, we improve on their access reshaping and guard encapsulation techniques as follows. The access reshaping method of <ref> [2] </ref> generates the final loop transformation by composing a sequence of legal transformations for each loop of the original loop nest.
Reference: [3] <author> Bik, A. J., and Wijshoff, H. A. </author> <title> Non-zero structure analysis. </title> <booktitle> In International Conference on Supercomputing (1994), </booktitle> <pages> pp. 226 - 235. </pages>
Reference: [4] <author> Bik, A. J., and Wijshoff, H. A. </author> <title> Advanced compiler optimizations for sparse computations. </title> <journal> Journal of Parallel and Distributed Computing 31 (1995), </journal> <pages> 14-24. </pages>
Reference: [5] <author> Bik, A. J., and Wijshoff, H. A. </author> <title> Automatic data structure selection and transformation for sparse matrix computations. </title> <journal> IEEE Transactions on Parallel and Distributed Systems 7, </journal> <volume> 2 (1996), 109 - 126. </volume>
Reference-contexts: Dense loop nests are converted to relational queries as in (4). Array access functions generate appropriate se lection predicates. 2. A sparsity predicate is computed as described in <ref> [1, 5] </ref> and is converted into a selection in terms of the N Z (: : : ) predicates as in (5). 3. Equi-joins are discovered by "pushing" selections with equality predicates "through" cross-products. 4.
Reference: [6] <author> Bik, A. J., and Wijshoff, H. A. </author> <title> The use of iteration sparse partitioning to construct representative simple sections. </title> <journal> Journal of Parallel and Distributed Computing 34 (1996), </journal> <volume> 95 - 110. </volume>
Reference: [7] <author> Jones, M. T., and Plassmann, P. E. </author> <title> BlockSolve95 users manual: Scalable library software for the parallel solution of sparse linear systems. </title> <type> Tech. Rep. </type> <institution> ANL-95/48, Argonne National Laboratory, </institution> <month> Dec. </month> <year> 1995. </year>
Reference-contexts: However, the sparse matrices that arise in PDE solvers often have many rows with the same non-zero structure, and are best represented as a collection of small dense matrices in which each dense matrix arises from gathering data from rows with the same non-zero structure <ref> [7] </ref>. Formats like the jagged-diagonal format are used when the target architecture is a vector machine [11]. We have chosen to make the programmer responsible for specifying sparse formats. <p> While this allows us to generate sparse code automatically for a variety of formats, these simple storage formats are inadequate if we want to exploit special structure in the matrices as is done, for example, in the BlockSolve package <ref> [7] </ref>. We are currently exploring ways of extending our techniques to such data structures.
Reference: [8] <author> Kodukula, I., and Pingali, K. </author> <title> Transformations for imperfectly nested loops. In Supercomputing (Nov. 1996), </title> <journal> ACM SIGARCH and IEEE Computer Society, </journal> <note> ACM Press. (http://www.supercomp.org). </note>
Reference-contexts: Consider the code fragment in Figure 5 that computes a solution to a lower triangular system. We assume that x and b are dense. According to the abstract syntax tree numbering scheme of <ref> [8] </ref>, the iteration vectors for the statements are: i S1 = B i 1 1 A i S2 = B i 0 1 A (32) These iteration vectors encode both iteration numbers and statement order. <p> = w b w L fl v x DO k = 1; n DO l = 1; k 1 ENDDO ENDDO S2 : A (k; k) = sqrt (A (k; k)) DO i = k + 1; n ENDDO ENDDO 4.2 GENERAL FRAMEWORK The imperfectly nested loop transformation framework of <ref> [8] </ref> allows for transformations which are combinations of statement reorderings and linear transformations along disjoint downward paths of the abstract syntax tree (AST) for the loop. For example, consider the loop nest in Figure 8, that computes Cholesky factorization of a matrix. <p> For example, consider the loop nest in Figure 8, that computes Cholesky factorization of a matrix. The AST for this loop is shown on the left in Figure 10. <ref> [8] </ref> allows transformations which would combine (e.g. permute or skew) the k, j and l loops, but not j and i loops. A transformation into right-looking code is an example of a valid transformation. It permutes the k, j and l loops and reorders the children of the root. <p> The resulting code is shown in Figure 9, and the AST for this loop nest is shown on the right in Figure 10. The dashed line marks the path in the AST along which the loop variables were combined. <ref> [8] </ref> provides a completion procedure to build a full legal transformation out of the first few rows. This procedure is similar to the one used for perfectly nested loops in [10]. <p> This procedure is similar to the one used for perfectly nested loops in [10]. The main difference is the necessity to maintain a special structure for the transformation matrix, that reflects the reordering of the AST. This point is discussed in more detail in <ref> [8] </ref>. For lack of space, we do not describe our extension of the completion procedure here, but illustrate its behavior using the Cholesky factorization example. We start with the loop nest in Figure 8. <p> It is not clear how such sequence can be derived automatically. 6 CONCLUSIONS AND FUTURE WORK In this paper, we have shown how the sparse compilation techniques of [9] can be extended to handle imperfectly nested loops with dependences by using the loop transformation framework of <ref> [8] </ref>. Our method is based on the following observations: * Two different permuted echelon forms (having the same row permutation) of a matrix are related by a lower triangular matrix. <p> This allows us to start with an illegal transformation and modify it into a legal one. * The completion procedure of <ref> [8] </ref> can be extended to compute a legal transformation that brings the data access matrix into a desired echelon form. Currently we only allow compressed hyper-plane storage formats in the compilation of loops with dependences.
Reference: [9] <author> Kotlyar, V., Pingali, K., and Stodghill, P. </author> <title> A relational approach to sparse matrix compilation. </title> <note> Submitted to Eu-roPar (1997). Also available as Cornell Computer Science Tech. Report 97-1627 (http://cs-tr.cs.cornell.edu). </note>
Reference-contexts: Therefore, our compiler must solve the problem of generating efficient sparse code, given a loop nest containing dense matrix computations and a specification of sparse matrix formats. In an earlier paper, we used techniques from relational algebra to solve this problem for the special case of DO-ANY loop nests <ref> [9] </ref>. As Table 1 shows, many common programs such as matrix-vector product and matrix-matrix product are included in this class, but other programs of great practical importance such as triangular solve and Cholesky factorization are not in this class. <p> More generally, we perform the following steps to expose joins and generate code; the interested reader can find the details in <ref> [9] </ref>. 1. Dense loop nests are converted to relational queries as in (4). Array access functions generate appropriate se lection predicates. 2. <p> Notice that H always has full column rank. It is easy to see that the following data access equation holds: a = f + Hi (8) As described in <ref> [9] </ref>, we view the arrays A k as relations with the following attributes: * a k , which stands for the vector of array indices * v k , which is the value of A k (a k ) Given all of the above, the sparse loop nest can be thought <p> More precisely, we discover affine joins between pairs of attributes that are related by affine equalities for all values of i. In <ref> [9] </ref> this is done by computing the permuted echelon form of the data access matrix H: H = PHU (10) where P is the matrix of row permutations and U is the uni-modular matrix of "zeroing" transformations. <p> For lack of space, we omit the proof. This theorem suggests the following algorithm: 1. Find an echelon form H 0 = PHU of H as described in <ref> [9] </ref>. 2. Find a non-singular lower-triangular matrix M such that MU 1 D - 0 (29) The method for finding M is a simple modification of the completion procedure of [10]. 3. The new transformation is V = UM 1 . <p> This gives us the following algorithm for finding a legal r-partial echelon form of H for a given r: 1. Find some r-partial echelon form (30) by doing row permutations and column operations as in <ref> [9] </ref>. 2. Find a non-singular matrix B with the structure as in (31) such that: BU 1 D - 0 The method for finding B to satisfy this equation is similar to the completion procedure of [10]. <p> If such B exists, then V = UB 1 gives us a legal transformation. 3.3 THE SEARCH PROBLEM In <ref> [9] </ref>, the problem is to find the best permutation P, which gives the ordering between different joins. Our case is complicated by the fact that different P's can lead to legal r-partial echelon forms of different sizes (r's). Therefore the best permutation P from the point of view of [9] might <p> In <ref> [9] </ref>, the problem is to find the best permutation P, which gives the ordering between different joins. Our case is complicated by the fact that different P's can lead to legal r-partial echelon forms of different sizes (r's). Therefore the best permutation P from the point of view of [9] might not lead to the fullest r-partial echelon form. In general, we might have to explore the space of all permutations P and all r-partial echelon forms (for each permutation). <p> Therefore, a brute force enumeration might be prohibitively expensive. We have found the following strategy to work well: * Find a permutation P and the corresponding echelon form as described in <ref> [9] </ref>. <p> Guard encapsulation performs enumeration over exactly one data structure per loop in a loop nest, and generates searches (possibly speeded up by access pattern expansion) for the rest of the data structures. In our framework, this is equivalent to performing a Hash-Join. However, as we have shown in <ref> [9] </ref>, the Merge-Join algorithm might be a better alternative in some contexts, but the guard encapsulation technique does not explore this option. Finally, Bik and Wijshoff do not have a unified framework for dealing with imperfectly nested loops. <p> It is not clear how such sequence can be derived automatically. 6 CONCLUSIONS AND FUTURE WORK In this paper, we have shown how the sparse compilation techniques of <ref> [9] </ref> can be extended to handle imperfectly nested loops with dependences by using the loop transformation framework of [8]. Our method is based on the following observations: * Two different permuted echelon forms (having the same row permutation) of a matrix are related by a lower triangular matrix.
Reference: [10] <author> Li, W., and Pingali, K. </author> <title> Access Normalization: Loop restructuring for NUMA compilers. </title> <journal> ACM Transactions on Computer Systems 11, </journal> <volume> 4 (Nov. </volume> <year> 1993), </year> <pages> 353-375. </pages>
Reference-contexts: . . 1 C A 0 B B B B B B B B B c 1 0 0 0 2 c 2 0 : : : 0 3 c 3 0 . . . r c r C C C C C C C C C A Matrix Following <ref> [10] </ref>, the matrix H is called a data access matrix. Notice that H always has full column rank. <p> Find an echelon form H 0 = PHU of H as described in [9]. 2. Find a non-singular lower-triangular matrix M such that MU 1 D - 0 (29) The method for finding M is a simple modification of the completion procedure of <ref> [10] </ref>. 3. The new transformation is V = UM 1 . The fact that H 00 = PHV is in echelon form follows from Theorem 1 and the fact that the inverse of a lower triangular matrix is also lower triangular. <p> Find a non-singular matrix B with the structure as in (31) such that: BU 1 D - 0 The method for finding B to satisfy this equation is similar to the completion procedure of <ref> [10] </ref>. If such B exists, then V = UB 1 gives us a legal transformation. 3.3 THE SEARCH PROBLEM In [9], the problem is to find the best permutation P, which gives the ordering between different joins. <p> The dashed line marks the path in the AST along which the loop variables were combined. [8] provides a completion procedure to build a full legal transformation out of the first few rows. This procedure is similar to the one used for perfectly nested loops in <ref> [10] </ref>. The main difference is the necessity to maintain a special structure for the transformation matrix, that reflects the reordering of the AST. This point is discussed in more detail in [8].
Reference: [11] <author> Saad, Y. </author> <title> Krylov subspace methods on supercomputers. </title> <journal> SIAM Journal on Scientific and Statistical Computing 10, </journal> <volume> 6 (Nov. </volume> <year> 1989), </year> <pages> 1200-1232. </pages>
Reference-contexts: Formats like the jagged-diagonal format are used when the target architecture is a vector machine <ref> [11] </ref>. We have chosen to make the programmer responsible for specifying sparse formats. Therefore, our compiler must solve the problem of generating efficient sparse code, given a loop nest containing dense matrix computations and a specification of sparse matrix formats.
Reference: [12] <author> Ullman, J. D. </author> <title> Principles of Database and Knowledge-Base Systems, v. I and II. </title> <publisher> Computer Science Press, </publisher> <year> 1988. </year>
Reference-contexts: (i) ./ R X (i; v x ) ./ R Y (i; v y )) = P (R X (i; v x ) ./ i R Y (i; v y )) (6) Once equi-joins in the query are exposed, we can apply one of three algorithms for computing equi-joins (see <ref> [12] </ref>, for example): * Enumerate-Search: Walk over the tuples of one relation and search for the common attribute in the other. 1 is the relational algebra selection operator.
References-found: 12

