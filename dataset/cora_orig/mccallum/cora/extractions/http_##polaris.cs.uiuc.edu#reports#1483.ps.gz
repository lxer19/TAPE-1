URL: http://polaris.cs.uiuc.edu/reports/1483.ps.gz
Refering-URL: http://polaris.cs.uiuc.edu/tech_reports.html
Root-URL: http://www.cs.uiuc.edu
Email: lchoi@mipos2.intel.com yew@cs.umn.edu  
Title: PROGRAM ANALYSIS FOR CACHE COHERENCE: BEYOND PROCEDURAL BOUNDARIES  
Author: Lynn Choi Pen-Chung Yew 
Address: Santa Clara, CA 95052 Minneapolis, MN 55455  
Affiliation: Microprocessor Group Department of Computer Science Intel Corporation University of Minnesota  
Note: To Appear in the 1996 International Conference on Parallel Processing  
Abstract: The presence of procedures and procedure calls introduces side effects, which complicates the analysis of stale reference detection in compiler-directed cache coherence schemes [4, 6, 8]. Previous compiler algorithms use cache invalidation at procedure boundary [5, 7] or inlining [7] to avoid reference marking interprocedurally. In this paper, we introduce a full interprocedural algorithm, which performs bottom-up and top-down analysis on the procedure call graph. This avoids unnecessary cache misses for subroutine local data and exploits locality across procedure boundaries. The result of execution-driven simulations on Perfect benchmarks demonstrates that, the interprocedural algorithm eliminates up to 36.8% of the cache misses for a compiler-directed scheme compared to an existing invalidation-based algorithm [7]. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Ballance, A. Maccabe, and K. Ottenstein. </author> <title> The Program Dependence Web: a Representation Sup porting Control Data- and Demand-Driven Inter pretation of Imperative Languages. </title> <booktitle> Proceedings of the SIGPLAN '90 Conference on Programming Lan guage Design and Implementation, </booktitle> <pages> pages 257-271, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: For this purpose, we use the gated single assignment (GSA) form <ref> [1] </ref> to treat arrays with different access regions as different symbolic variables. * Epoch Flow Graph This is a modified flow graph to represent the epoch boundary information as well as different control flows due to the parallel execution [7].
Reference: [2] <author> M. Berry and others. </author> <title> The Perfect Club Benchmarks: Effective Performance Evaluation of Supercomputers. </title> <journal> International Journal of Supercomputer Applications, </journal> <volume> 3(3) </volume> <pages> 5-40, </pages> <month> Fall, </month> <year> 1989. </year>
Reference-contexts: In addition, we treat all the array variables with dimensional reshaping as scalar variables. 4 EXPERIMENTATION We use six programs from the Perfect Club benchmark suite <ref> [2] </ref> as our target benchmarks. The Perfect benchmarks are first parallelized by the Polaris compiler. In the parallelized codes, the parallelism is expressed in terms of DOALL loops.
Reference: [3] <author> D. Callahan and K. Kennedy. </author> <title> Analysis of Interproce dural Side Effects in a Parallel Programming Environ ment. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 5 </volume> <pages> 517-550, </pages> <year> 1988. </year>
Reference-contexts: The notion of the subarray we use is an extension to the regular section used in <ref> [3, 9, 13] </ref>. * Gated Single Assignment (GSA) form To perform effective array flow analysis, symbolic manipulation of expressions is necessary since the computation of array regions often involves the equality and comparison tests between symbolic expressions. <p> Procedure calls can introduce side effects at a call site and hidden context at the beginning of a procedure, which limit existing compiler-directed cache coherence schemes <ref> [3, 6, 4, 8, 10] </ref> to exploit locality only within procedure boundaries. Previous algorithms use cache invalidation [5, 7] or selective in-lining [7] to solve the problem. However, invalidation at procedure boundaries incur significant performance penalty especially if a program contains many small procedures in its critical path.
Reference: [4] <author> H. Cheong. </author> <title> Life Span Strategy A Compiler-Based Approach to Cache Coherence. </title> <booktitle> Proceedings of the 1992 International Conference on Supercomputing, </booktitle> <month> July </month> <year> 1992. </year>
Reference-contexts: 1 INTRODUCTION Procedure calls introduce complications in most global program analysis and optimizations due to side effects and potential aliasing caused by parameter passing. Stale access detection [5, 7] is a compile time analysis technique to identify data references that may violate cache coherence in compile-directed coherence schemes <ref> [6, 4, 8] </ref>. By identifying these potentially stale references at compile time, cache coherence can be maintained by forcing those references to get up-to-date data directly from the main memory, instead of from the cache. <p> The compiler reference marking algorithms developed here are general enough to be applicable to other compiler-directed coherence schemes <ref> [4, 6] </ref>. 1.1 Stale reference sequence We view the execution of a parallel program as a sequence of epochs. An epoch is either a parallel loop (parallel epoch) or a serial section of the code (serial epoch) between parallel loops. <p> Procedure calls can introduce side effects at a call site and hidden context at the beginning of a procedure, which limit existing compiler-directed cache coherence schemes <ref> [3, 6, 4, 8, 10] </ref> to exploit locality only within procedure boundaries. Previous algorithms use cache invalidation [5, 7] or selective in-lining [7] to solve the problem. However, invalidation at procedure boundaries incur significant performance penalty especially if a program contains many small procedures in its critical path.
Reference: [5] <author> H. Cheong and A. Veidenbaum. </author> <title> Stale Data Detec tion and Coherence Enforcement Using Flow Analy sis. </title> <booktitle> Proceedings of the 1988 International Conference on Parallel Processing, I, Architecture:138-145, Au gust 1988. </booktitle>
Reference-contexts: 1 INTRODUCTION Procedure calls introduce complications in most global program analysis and optimizations due to side effects and potential aliasing caused by parameter passing. Stale access detection <ref> [5, 7] </ref> is a compile time analysis technique to identify data references that may violate cache coherence in compile-directed coherence schemes [6, 4, 8]. <p> By identifying these potentially stale references at compile time, cache coherence can be maintained by forcing those references to get up-to-date data directly from the main memory, instead of from the cache. In stale reference detection, procedure boundaries force all previous algorithms <ref> [5, 7] </ref> to use conservative approaches, such as cache invalidation or inlining, to avoid reference marking across procedure calls. However, both approaches have their own problems. Frequent invalidations at procedure call boundaries incur cold-start effects. <p> In addition, this also causes a problem at the beginning of each procedure since any global COMMON variables and formal parameters could have been previously modified before entering the procedure. To avoid such complications caused by procedure calls, previous algorithms <ref> [5, 7] </ref> use cache invalidation both at the beginning of a procedure and after each call site. Since the algorithms assume a clean cache at procedure boundaries, their analysis can guarantee the correctness of reference marking. <p> For a target reference which does not have a reaching definition inside a procedure, we issue a Time-Read with the minimum offset, implying that the referenced data item can be potentially modified before entering the procedure. This is an improvement over previous algorithms <ref> [5, 7] </ref> which use cache invalidation at the beginning of a procedure since only global and formal variables are affected by the unknown context information. We propagate definitions through the flow graph and increment their offsets when they cross scheduling edges. <p> Procedure calls can introduce side effects at a call site and hidden context at the beginning of a procedure, which limit existing compiler-directed cache coherence schemes [3, 6, 4, 8, 10] to exploit locality only within procedure boundaries. Previous algorithms use cache invalidation <ref> [5, 7] </ref> or selective in-lining [7] to solve the problem. However, invalidation at procedure boundaries incur significant performance penalty especially if a program contains many small procedures in its critical path.
Reference: [6] <author> H. Cheong and A. Veidenbaum. </author> <title> A Cache Coherence Scheme with Fast Selective Invalidation. </title> <booktitle> Proceedings of the 15th Annual International Symposium on Com puter Architecture, </booktitle> <month> June </month> <year> 1988. </year>
Reference-contexts: 1 INTRODUCTION Procedure calls introduce complications in most global program analysis and optimizations due to side effects and potential aliasing caused by parameter passing. Stale access detection [5, 7] is a compile time analysis technique to identify data references that may violate cache coherence in compile-directed coherence schemes <ref> [6, 4, 8] </ref>. By identifying these potentially stale references at compile time, cache coherence can be maintained by forcing those references to get up-to-date data directly from the main memory, instead of from the cache. <p> The compiler reference marking algorithms developed here are general enough to be applicable to other compiler-directed coherence schemes <ref> [4, 6] </ref>. 1.1 Stale reference sequence We view the execution of a parallel program as a sequence of epochs. An epoch is either a parallel loop (parallel epoch) or a serial section of the code (serial epoch) between parallel loops. <p> Procedure calls can introduce side effects at a call site and hidden context at the beginning of a procedure, which limit existing compiler-directed cache coherence schemes <ref> [3, 6, 4, 8, 10] </ref> to exploit locality only within procedure boundaries. Previous algorithms use cache invalidation [5, 7] or selective in-lining [7] to solve the problem. However, invalidation at procedure boundaries incur significant performance penalty especially if a program contains many small procedures in its critical path.
Reference: [7] <author> L. Choi and P.-C. Yew. </author> <title> Eliminating Stale Data Ref erences through Array Data-Flow Analysis. </title> <booktitle> Proceed ings of the 10th IEEE International Parallel Process ing Symposium, </booktitle> <pages> pages 4-13, </pages> <month> April. </month> <year> 1996. </year>
Reference-contexts: 1 INTRODUCTION Procedure calls introduce complications in most global program analysis and optimizations due to side effects and potential aliasing caused by parameter passing. Stale access detection <ref> [5, 7] </ref> is a compile time analysis technique to identify data references that may violate cache coherence in compile-directed coherence schemes [6, 4, 8]. <p> By identifying these potentially stale references at compile time, cache coherence can be maintained by forcing those references to get up-to-date data directly from the main memory, instead of from the cache. In stale reference detection, procedure boundaries force all previous algorithms <ref> [5, 7] </ref> to use conservative approaches, such as cache invalidation or inlining, to avoid reference marking across procedure calls. However, both approaches have their own problems. Frequent invalidations at procedure call boundaries incur cold-start effects. <p> To obtain more precise array access information, we compute the array region referenced by each array reference <ref> [7] </ref>. The interprocedural algorithm performs bottom-up and top-down analysis on the procedure call graph to exploit cache locality across procedure boundaries. First, the bottom-up side effect analysis takes into account side effects by summarizing the access information at each call site. <p> We have implemented both the intraprocedural and interprocedural algorithms on the Polaris parallelizing compiler [11] and demonstrate the performance driven by these algorithms by running execution-driven simulations of two compiler-directed coherence schemes <ref> [7, 8] </ref> using Perfect benchmarks. The compiler reference marking algorithms developed here are general enough to be applicable to other compiler-directed coherence schemes [4, 6]. 1.1 Stale reference sequence We view the execution of a parallel program as a sequence of epochs. <p> However, the read might access the existing cache copy in P j rather than the new copy created in P i . This memory reference pattern is called a stale reference sequence, and the last read reference is called a potentially stale data reference <ref> [7] </ref>. In the example, the read references to X in epochs 3 and 4 can cause stale data accesses at runtime since the variable has been modified in epoch 2. <p> In addition, this also causes a problem at the beginning of each procedure since any global COMMON variables and formal parameters could have been previously modified before entering the procedure. To avoid such complications caused by procedure calls, previous algorithms <ref> [5, 7] </ref> use cache invalidation both at the beginning of a procedure and after each call site. Since the algorithms assume a clean cache at procedure boundaries, their analysis can guarantee the correctness of reference marking. <p> This limitation led us to develop more precise program analysis algorithms which can avoid such invalidations. In section 2, we first briefly describe our program representation methods: epoch flow graph, array descriptors, and gated single assignment (GSA) <ref> [7] </ref>. Then, we present an improved intraprocedural stale reference marking algorithm which can detect stale data references in the presence of procedure calls without cache invalidation or inlining. <p> The performance results from our execution-driven simulations follow in section 4. Section 5 concludes the paper. 2 INTRAPROCEDURAL ALGORITHM 2.1 Data-Flow Framework We use the following three techniques as a framework for our array data-flow analysis. A more detailed description can be found in <ref> [7] </ref>. * Regular Section Analysis The data-flow information propagated during the flow analysis are implemented as sets of data descriptors D, which consists of three data fields: name (D), subar-ray (D), and offset (D). <p> For this purpose, we use the gated single assignment (GSA) form [1] to treat arrays with different access regions as different symbolic variables. * Epoch Flow Graph This is a modified flow graph to represent the epoch boundary information as well as different control flows due to the parallel execution <ref> [7] </ref>. Figure 2 shows the epoch flow graph for a program example. Bold arcs denote scheduling edges, which represent epoch boundaries, while the remaining arcs denote normal control flow edges. <p> To consider the temporal reuse in each task, we mark only the first occurrence of upwardly-exposed uses in each epoch. These references are called tar-get references. A detailed array data-flow algorithm to find such target references is shown in <ref> [7] </ref>, and for the following discussion, we assume that those target references are already computed. 2.2 Stale reference detection The intraprocedural algorithm for stale reference detection is an improved version of the previous algorithm we developed in [7]. <p> A detailed array data-flow algorithm to find such target references is shown in <ref> [7] </ref>, and for the following discussion, we assume that those target references are already computed. 2.2 Stale reference detection The intraprocedural algorithm for stale reference detection is an improved version of the previous algorithm we developed in [7]. We refine the algorithm to eliminate cache invalidations by considering both side effects and hidden contexts at procedural boundaries. Each definition of a variable v, denoted as d v offset , is associated with an offset. <p> For a target reference which does not have a reaching definition inside a procedure, we issue a Time-Read with the minimum offset, implying that the referenced data item can be potentially modified before entering the procedure. This is an improvement over previous algorithms <ref> [5, 7] </ref> which use cache invalidation at the beginning of a procedure since only global and formal variables are affected by the unknown context information. We propagate definitions through the flow graph and increment their offsets when they cross scheduling edges. <p> Compiler algorithms We use three different compiler algorithms to generate memory operations for the software cache-bypass scheme (SC) and the two-phase invalidation scheme (TPI). 1. Invalidation-based intraprocedural algorithm (ALG1) This algorithm performs stale reference detection on a per-procedure basis <ref> [7] </ref>. To avoid the complications caused by unknown side effects, cache invalidation operations are inserted after each call site and at the beginning of a procedure. 2. A simple interprocedural algorithm with no cache invalidation (ALG2) Instead of the intraproce-dural algorithm in section 2.2, we use a more sophisticated algorithm. <p> Procedure calls can introduce side effects at a call site and hidden context at the beginning of a procedure, which limit existing compiler-directed cache coherence schemes [3, 6, 4, 8, 10] to exploit locality only within procedure boundaries. Previous algorithms use cache invalidation <ref> [5, 7] </ref> or selective in-lining [7] to solve the problem. However, invalidation at procedure boundaries incur significant performance penalty especially if a program contains many small procedures in its critical path. <p> Procedure calls can introduce side effects at a call site and hidden context at the beginning of a procedure, which limit existing compiler-directed cache coherence schemes [3, 6, 4, 8, 10] to exploit locality only within procedure boundaries. Previous algorithms use cache invalidation [5, 7] or selective in-lining <ref> [7] </ref> to solve the problem. However, invalidation at procedure boundaries incur significant performance penalty especially if a program contains many small procedures in its critical path. Inlining allows the most precise analysis but it is often prohibitive due to potential code size expansion as well as the compile time increase. <p> The results show that by avoiding cache invalidations, the intraprocedural algorithm eliminates up to 26.0% of the cache misses for a compiler-directed scheme compared to an existing invalidation-based algorithm <ref> [7] </ref>. With the full inter-procedural analysis, up to 10.8% of additional cache misses can be removed. Acknowledgments The research described in this paper was supported in part by the NSF Grant No. MIP 89-20891, MIP 93-07910 and ARPA contract #DABT63-95-C-0097.
Reference: [8] <author> L. Choi and P.-C. Yew. </author> <title> Compiler and Hardware Support for Cache Coherence in Large-Sca le Multi processors: Design Considerations and Performance Study. </title> <booktitle> Proceedings of the 23rd Annual ACM Inter national Symposium on Computer Architecture, </booktitle> <month> May </month> <year> 1996. </year>
Reference-contexts: 1 INTRODUCTION Procedure calls introduce complications in most global program analysis and optimizations due to side effects and potential aliasing caused by parameter passing. Stale access detection [5, 7] is a compile time analysis technique to identify data references that may violate cache coherence in compile-directed coherence schemes <ref> [6, 4, 8] </ref>. By identifying these potentially stale references at compile time, cache coherence can be maintained by forcing those references to get up-to-date data directly from the main memory, instead of from the cache. <p> We have implemented both the intraprocedural and interprocedural algorithms on the Polaris parallelizing compiler [11] and demonstrate the performance driven by these algorithms by running execution-driven simulations of two compiler-directed coherence schemes <ref> [7, 8] </ref> using Perfect benchmarks. The compiler reference marking algorithms developed here are general enough to be applicable to other compiler-directed coherence schemes [4, 6]. 1.1 Stale reference sequence We view the execution of a parallel program as a sequence of epochs. <p> Second, the read reference to X (f (i)) in epoch 4 cannot be analyzed precisely at compile time due to the unknown index value. To overcome these limitations, we proposed a hardware scheme, called the two-phase invalidation scheme that keeps track of the local cache states at runtime <ref> [8] </ref>. Two-phase invalidation scheme (TPI) In this scheme, each epoch is assigned a unique epoch number. The epoch number is stored in an n-bit register in each processor, called epoch counter (R counter ), and is incremented at the end of every epoch by each processor individually. <p> Procedure calls can introduce side effects at a call site and hidden context at the beginning of a procedure, which limit existing compiler-directed cache coherence schemes <ref> [3, 6, 4, 8, 10] </ref> to exploit locality only within procedure boundaries. Previous algorithms use cache invalidation [5, 7] or selective in-lining [7] to solve the problem. However, invalidation at procedure boundaries incur significant performance penalty especially if a program contains many small procedures in its critical path.
Reference: [9] <author> P. Havlak. </author> <title> Interprocedural Symbolic Analysis. </title> <type> Tech nical report, </type> <institution> Rice University, Dept. of Computer Sci ence, </institution> <month> May </month> <year> 1994. </year> <type> Ph.D. Thesis. </type>
Reference-contexts: The notion of the subarray we use is an extension to the regular section used in <ref> [3, 9, 13] </ref>. * Gated Single Assignment (GSA) form To perform effective array flow analysis, symbolic manipulation of expressions is necessary since the computation of array regions often involves the equality and comparison tests between symbolic expressions.
Reference: [10] <author> A. Louri and H. Sung. </author> <title> A Compiler Directed Cache Coherence Scheme with Fast and Parallel Explicit Invalidation. </title> <booktitle> Proceedings of the 1992 International Conference on Parallel Processing, </booktitle> <volume> I, Architecture:2 9, </volume> <month> August </month> <year> 1992. </year>
Reference-contexts: Procedure calls can introduce side effects at a call site and hidden context at the beginning of a procedure, which limit existing compiler-directed cache coherence schemes <ref> [3, 6, 4, 8, 10] </ref> to exploit locality only within procedure boundaries. Previous algorithms use cache invalidation [5, 7] or selective in-lining [7] to solve the problem. However, invalidation at procedure boundaries incur significant performance penalty especially if a program contains many small procedures in its critical path.
Reference: [11] <author> D. A. Padua, R. Eigenmann, J. Hoeflinger, P. Peter son, P. Tu, S. Weatherford, and K. Faign. </author> <note> Polaris: </note>
Reference-contexts: This two-pass analysis avoids redundant computation by performing incremental update of reference marking with a minimal number of computations per procedure. We have implemented both the intraprocedural and interprocedural algorithms on the Polaris parallelizing compiler <ref> [11] </ref> and demonstrate the performance driven by these algorithms by running execution-driven simulations of two compiler-directed coherence schemes [7, 8] using Perfect benchmarks. <p> In addition, the top-down pass updates the reference marking result of the side effect analysis incrementally, and thus minimize the compilation time. We have implemented these algorithms on the Po-laris parallelizing compiler <ref> [11] </ref>, and demonstrated the performance driven by the new compiler algorithms by running execution-driven simulations of five Perfect benchmarks. The results show that by avoiding cache invalidations, the intraprocedural algorithm eliminates up to 26.0% of the cache misses for a compiler-directed scheme compared to an existing invalidation-based algorithm [7].
References-found: 11

