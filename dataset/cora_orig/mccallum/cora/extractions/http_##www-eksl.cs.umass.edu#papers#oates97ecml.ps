URL: http://www-eksl.cs.umass.edu/papers/oates97ecml.ps
Refering-URL: http://eksl-www.cs.umass.edu/publications.html
Root-URL: 
Email: foates,schmill,coheng@cs.umass.edu  
Title: Parallel and Distributed Search for Structure in Multivariate Time Series  
Author: Tim Oates, Matthew D. Schmill and Paul R. Cohen 
Address: Box 34610 Amherst, MA 01003-4610  
Affiliation: Computer Science Department, LGRC University of Massachusetts  
Abstract: Efficient data mining algorithms are crucial for effective knowledge discovery. We present the Multi-Stream Dependency Detection (msdd) data mining algorithm that performs a systematic search for structure in multivariate time series of categorical data. The systematicity of msdd's search makes implementation of both parallel and distributed versions straightforward. Distributing the search for structure over multiple processors or networked machines makes mining of large numbers of databases or very large databases feasible. We present results showing that msdd efficiently finds complex structure in multivariate time series, and that the distributed version finds the same structure in approximately 1=n of the time required by msdd, where n is the number of machines across which the search is distributed.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> R. Agrawal and J. C. Shafer. </author> <title> Parallel mining of association rules: Design, implementation and experience. </title> <type> Technical Report RJ 10004, </type> <institution> IBM, </institution> <year> 1996. </year>
Reference-contexts: The newly constructed features are then passed to a standard (serial) inductive learning algorithm. While parallelism speeds the search for new features, it does not affect the speed with which rules using those features can be learned. Agrawal and Shafer <ref> [1] </ref> explore several parallel algorithms for mining association rules from very large databases, and Dehaspe and De Raedt [4] present a parallel implementation of the claudien clausal discovery system.
Reference: 2. <author> John M. Aronis and Foster J. Provost. </author> <title> Efficiently constructing relational features from background knowledge for inductive machine learning. </title> <booktitle> In Working Notes of the Knowledge Discovery in Databases Workshop, </booktitle> <pages> pages 347-358, </pages> <year> 1994. </year>
Reference-contexts: However, their system is limited to classification rules (a conjunct of literals predicting a single literal), and it can miss high quality rules due to the use of beam search. Aronis and Provost developed a parallel algorithm that builds new features from existing features in relational databases <ref> [2] </ref>. The newly constructed features are then passed to a standard (serial) inductive learning algorithm. While parallelism speeds the search for new features, it does not affect the speed with which rules using those features can be learned.
Reference: 3. <author> Donald J. Berndt and James Clifford. </author> <title> Using dynamic time warping to find patterns in time series. </title> <booktitle> In Working Notes of the Knowledge Discovery in Databases Workshop, </booktitle> <pages> pages 359-370, </pages> <year> 1994. </year>
Reference-contexts: Agrawal and Shafer [1] explore several parallel algorithms for mining association rules from very large databases, and Dehaspe and De Raedt [4] present a parallel implementation of the claudien clausal discovery system. Berndt and Clifford describe a dynamic programming algorithm for finding recurring patterns in univariate time series <ref> [3] </ref>, and Mannila et al. [6] developed an algorithm that finds frequently occurring episodes in event-based data (e.g. event logs generated by telecommunications networks). 7 Conclusion In this paper we presented the msdd data mining algorithm which performs a systematic search for structure in multivariate time series. msdd discovers the k
Reference: 4. <author> Luc Dehaspe and Luc De Raedt. </author> <title> Parallel inductive logic programming. </title> <booktitle> In Proceedings of the MLnet Familiarization Workshop on Statistics, Machine Learning and Knowledge Discovery in Databases, </booktitle> <year> 1995. </year>
Reference-contexts: While parallelism speeds the search for new features, it does not affect the speed with which rules using those features can be learned. Agrawal and Shafer [1] explore several parallel algorithms for mining association rules from very large databases, and Dehaspe and De Raedt <ref> [4] </ref> present a parallel implementation of the claudien clausal discovery system.
Reference: 5. <author> Marcel Holsheimer and Martin L. Kersten. </author> <title> Architectural support for data mining. </title> <booktitle> In Working Notes of the Knowledge Discovery in Databases Workshop, </booktitle> <pages> pages 217-228, </pages> <year> 1994. </year>
Reference-contexts: Holsheimer and Kersten describe a system for inducing rules from large relational databases that performs a parallelized beam search over the space of possible rules and accesses the data through a parallel DBMS <ref> [5] </ref>. However, their system is limited to classification rules (a conjunct of literals predicting a single literal), and it can miss high quality rules due to the use of beam search. Aronis and Provost developed a parallel algorithm that builds new features from existing features in relational databases [2].
Reference: 6. <author> Heikki Mannila, Hannu Toivonen, and A. Inkeri Verkamo. </author> <title> Discovering frequent episodes in sequences. </title> <booktitle> In Proceedings of the First International Conference on Knowledge Discovery and Data Mining, </booktitle> <pages> pages 210-215, </pages> <year> 1995. </year>
Reference-contexts: Berndt and Clifford describe a dynamic programming algorithm for finding recurring patterns in univariate time series [3], and Mannila et al. <ref> [6] </ref> developed an algorithm that finds frequently occurring episodes in event-based data (e.g. event logs generated by telecommunications networks). 7 Conclusion In this paper we presented the msdd data mining algorithm which performs a systematic search for structure in multivariate time series. msdd discovers the k strongest dependencies between pairs of
Reference: 7. <author> S. Muggleton. </author> <title> Inverse entailment and progol. </title> <journal> New Generation Computing, </journal> <volume> 13 </volume> <pages> 245-286, </pages> <year> 1995. </year>
Reference-contexts: Pruning based on optimistic estimates of the value of the descendants of a node has been used infrequently in rule induction algorithms, with itrule [13], opus [14] and progol <ref> [7] </ref> being notable exceptions. In practice, we use the G statistic computed for 2x2 contingency tables to measure dependency strength, and we have derived bounds on the value of G for the descendants of a node, making it an ideal candidate for f .
Reference: 8. <author> Tim Oates and Paul R. Cohen. </author> <title> Searching for structure in multiple streams of data. </title> <booktitle> In Proceedings of the Thirteenth International Conference on Machine Learning, </booktitle> <pages> pages 346 - 354, </pages> <year> 1996. </year>
Reference-contexts: The interested 1 The definition of a multitoken given here is an extension of the one given in previous descriptions of the algorithm [9]. reader is referred to <ref> [8] </ref> for more details. 4 Parallel and Distributed MSDD In the same way msdd guarantees non-redundant generation of search nodes, msdd guarantees that distinct nodes at the same depth in the search tree are parent to completely disjoint sets of children.
Reference: 9. <author> Tim Oates, Dawn E. Gregory, and Paul R. Cohen. </author> <title> Detecting complex dependencies in categorical data. </title> <booktitle> In Preliminary Papers of the Fifth International Workshop on Artificial Intelligence and Statistics, </booktitle> <pages> pages 417-423, </pages> <year> 1994. </year>
Reference-contexts: The interested 1 The definition of a multitoken given here is an extension of the one given in previous descriptions of the algorithm <ref> [9] </ref>. reader is referred to [8] for more details. 4 Parallel and Distributed MSDD In the same way msdd guarantees non-redundant generation of search nodes, msdd guarantees that distinct nodes at the same depth in the search tree are parent to completely disjoint sets of children.
Reference: 10. <author> Patricia Riddle, Richard Segal, and Oren Etzioni. </author> <title> Representation design and brute-force induction in a boeing manufacturing domain. </title> <journal> Applied Artificial Intelligence, </journal> <volume> 8 </volume> <pages> 125-147, </pages> <year> 1994. </year>
Reference: 11. <author> Ron Rymon. </author> <title> Search through systematic set enumeration. </title> <booktitle> In Proceedings of the Third International Conference on Principles of Knowledge Representation and Reasoning, </booktitle> <year> 1992. </year>
Reference: 12. <author> Jeffrey C. Schlimmer. </author> <title> Efficiently inducing determinations: A complete and systematic search algorithm that uses optimal pruning. </title> <booktitle> In Proceedings of the Tenth International Conference on Machine Learning, </booktitle> <pages> pages 284-290, </pages> <year> 1993. </year>
Reference: 13. <author> Padhraic Smyth and Rodney M. Goodman. </author> <title> An information theoretic approach to rule induction from databases. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 4(4) </volume> <pages> 301-316, </pages> <year> 1992. </year>
Reference-contexts: Pruning based on optimistic estimates of the value of the descendants of a node has been used infrequently in rule induction algorithms, with itrule <ref> [13] </ref>, opus [14] and progol [7] being notable exceptions. In practice, we use the G statistic computed for 2x2 contingency tables to measure dependency strength, and we have derived bounds on the value of G for the descendants of a node, making it an ideal candidate for f . <p> Our use of optimistic bounds on the value of the node evaluation function for pruning systematic search spaces is similar to the opus algorithm [14], which in turn is a generalization of the same idea as applied to non-systematic search in the itrule induction algorithm <ref> [13] </ref>. msdd and itrule return the k best rules, whereas opus returns a single goal node or the single node with the highest value. Both parallel algorithms and consideration of data with a temporal component are rare in the KDD and data mining literature.
Reference: 14. <author> Geoffrey I. Webb. </author> <title> OPUS: An efficient admissible algorithm for unordered search. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 3 </volume> <pages> 45-83, </pages> <year> 1996. </year>
Reference-contexts: Systematic search expands the children of search nodes in a manner that ensures that no node can ever be generated more than once <ref> [9-12, 14] </ref>. Because non-redundant expansion is achieved without access to large, rapidly changing data structures, such as lists of open and closed nodes, the search space can be divided between multiple processes on multiple machines. <p> Systematic search non-redundantly enumerates the elements of search spaces for which the value or semantics of any given node are independent of the path from the root to that node. Webb calls such search spaces unordered <ref> [14] </ref>. Consider the space of disjunctive concepts over the set of literals fA; B; Cg. <p> Pruning based on optimistic estimates of the value of the descendants of a node has been used infrequently in rule induction algorithms, with itrule [13], opus <ref> [14] </ref> and progol [7] being notable exceptions. In practice, we use the G statistic computed for 2x2 contingency tables to measure dependency strength, and we have derived bounds on the value of G for the descendants of a node, making it an ideal candidate for f . <p> Comparison of msdd and d-msdd on three dataset. 6 Related Work Several systematic search algorithms have appeared in the literature <ref> [9-12, 14] </ref>, all of them variations on the basic idea of imposing an order on search operators, and applying only those operators at a node that are higher in the order than all other operators that have been applied on the path from the root to the node. <p> Our use of optimistic bounds on the value of the node evaluation function for pruning systematic search spaces is similar to the opus algorithm <ref> [14] </ref>, which in turn is a generalization of the same idea as applied to non-systematic search in the itrule induction algorithm [13]. msdd and itrule return the k best rules, whereas opus returns a single goal node or the single node with the highest value.
References-found: 14

