URL: http://www.cs.ucla.edu/~stott/pop/greed.ps
Refering-URL: http://www.cs.ucla.edu/~stott/pop/
Root-URL: http://www.cs.ucla.edu
Title: Greed and Majorization  
Author: D. Stott Parker Prasad Ram 
Date: September 7, 1997  
Address: Los Angeles, CA 90095-1596  
Affiliation: UCLA Computer Science Department University of California  
Abstract: We present a straightforward linear algebraic model of greed, based only on extensions of classical majorization and convexity theory. This gives an alternative to other models of greedy-solvable problems such as matroids, greedoids, submodular functions, etc., and it is able to express established examples of greedy-solvable optimization problems that they cannot. The linear algebraic approach is also much closer in spirit to established practice in operations research and numerical optimization. The essence of the approach is to model `exchanges' with certain linear transformations. Modeling solutions as vectors also, we then exploit the fact that these exchanges define an ordering on solutions. When the exchanges are doubly-stochastic matrices, this ordering is the majorization ordering developed by Hardy, Littlewood, and Polya in their pioneering work on inequality theory. We generalize majoriza-tion to permit any matrix semigroup of exchanges, but find that several kinds of stochastic matrices make particularly useful families of exchanges. We also show that greedy-solvable problems can be formalized as optimization problems in which the objective preserves an exchange ordering (i.e., is monotone with respect to it). We outline greedy algorithms for such problems, including those that exploit additional properties of the objective, such as convexity or submodularity. Examples from the literature illustrate how several well-known applications of greed can be expressed.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> G. Birkhoff. </author> <title> Tres observaciones sobre el algebra lineal. </title> <journal> Univ. Nac. Tacuman Rev. Ser., </journal> <volume> 5 </volume> <pages> 147-151, </pages> <year> 1946. </year>
Reference-contexts: For example, matroids deal explicitly only with problems which seek to maximize a linear objective function, such as in the Continuous Knapsack problem knapsack value = n X w i x i where w i is the weight (value) of the i-th commodity, and x i 2 <ref> [0; 1] </ref> is the fraction of the knapsack volume devoted to it. Matroids do not support objective functions that reflect the ordering of choices made over 1 Copyright c fl1994, 1997 D. Stott Parker, Prasad Ram 2 the execution of the greedy algorithm. <p> Proof Each clearly contains the identity matrix. That they are closed under multiplication follows from the basic property that each kind of matrix is a convex sum of elementary matrices, and products of these convex sums are convex sums. For example, the Birkhoff-von Neumann theorem <ref> [1, 12] </ref> states that for any DSM A can be decomposed as A = 1 P 1 + + m P m where 0 &lt; i 1, P m i=1 i = 1, and each P i is a permutation matrix. <p> Stott Parker, Prasad Ram 4 In both greedy problem solving and economics more generally, it is important to investigate (like Dalton) the properties of pairwise exchanges: Definition 3.1 The pairwise exchange UTSMs U pq (*) and pairwise exchange DSMs D pq (*) 1 p &lt; q n, * 2 <ref> [0; 1] </ref>, are matrices differing from the identity only in the fp; qg fi fp; qg submatrix: U pq (*) = B B B B . . . . . . . . . <p> C &lt; + n iff @z k @G (z) 4.4 Classical Majorization Classical majorization is often defined as a binary relation `' on `unsorted sequences' [12]: For x; y 2 &lt; + n , ( P k P k P n P n where sort# ( z ) = [z <ref> [1] </ref> ; : : :; z [n] ] denotes a descendingly-sorted permutation of z = [z 1 ; : : : ; z n ]. <p> A feasible solution y 2 C is called the optimal solution if for all x 2 C, G (x) G (y): G (y) is called the optimal answer. Example 5.1 (Continuous Knapsack) maximize G (x) = P n subject to <ref> [0; 0; : : :; 0; 1] </ref> UT SM [x 1 ; : : :; x n ] 0 x i c i where commodities are ordered by their values w i in descending order, so that w 1 : : : w n , and c i 2 [0; 1] <p> to [0; 0; : : :; 0; 1] UT SM [x 1 ; : : :; x n ] 0 x i c i where commodities are ordered by their values w i in descending order, so that w 1 : : : w n , and c i 2 <ref> [0; 1] </ref> is the maximum permissible proportion of the i-th commodity. The majorization constraint expresses the requirement that the proportions x i total to 1. <p> For example, the set of UTSMs is a convex space, since any convex combination of UTSMs is a UTSM, and any UTSM is a convex sum of upper triangular 0-1 matrices that have exactly one 1 in each row. Birkhoff <ref> [1] </ref> proved the set of DSMs is a convex space, whose extremal points are PMs. In other words, every DSM is a convex sum of permutation matrices. Finally, G (x) = P i w i (x i ) is convex when it meets the conditions of Theorem 4.6. <p> If a = <ref> [0; 0; : : :; 0; 1] </ref> as in the knapsack problem earlier, the optimal selections are * ik = &lt; c k =( j&lt;k (1 * nj )) i = n; k r P r Q 0 otherwise: 6 Conclusion We have described a class of optimization problems, for which
Reference: [2] <author> A. Dechter and R. Dechter. </author> <title> On the Greedy Solution of Ordering Problems. </title> <journal> ORSA Journal on Computing, </journal> <volume> 1(3) </volume> <pages> 181-189, </pages> <month> Summer </month> <year> 1989. </year>
Reference-contexts: This problem can be represented easily with greedoids, but not matroids. However, neither matroids nor greedoids can cope with situations where the objective function uses different weights than the weights of the objects. Dechter & Dechter stress in <ref> [2] </ref> that the ordering used by the greedy algorithm in its selection need not necessarily correspond to the weights used in the optimal solution. <p> The majorization relation here is not equivalent to the classical majorization relation studied in [12]; cf. Section 4.4. Copyright c fl1994, 1997 D. Stott Parker, Prasad Ram 6 For instance: <ref> [2; 4] </ref> [3; 3] [4; 2] Theorem 4.1 [17] A necessary and a sufficient condition that x y is that there exist a LTSM L such that x = L y. Equivalently, there must exist an UTSM U such that U x = y. <p> The majorization relation here is not equivalent to the classical majorization relation studied in [12]; cf. Section 4.4. Copyright c fl1994, 1997 D. Stott Parker, Prasad Ram 6 For instance: [2; 4] [3; 3] <ref> [4; 2] </ref> Theorem 4.1 [17] A necessary and a sufficient condition that x y is that there exist a LTSM L such that x = L y. Equivalently, there must exist an UTSM U such that U x = y. <p> Although this definition is similar to the earlier definition of majorization on sequences, it is inequivalent. For example: <ref> [2; 4] </ref> 6 [3; 3] [4; 2] [2; 4] [4; 2] [2; 4]: Classical majorization is only a preorder on sequences (it fails to be a partial order by lacking antisymmetry, since any sequence is majorized by any of its permutations). <p> Although this definition is similar to the earlier definition of majorization on sequences, it is inequivalent. For example: [2; 4] 6 [3; 3] <ref> [4; 2] </ref> [2; 4] [4; 2] [2; 4]: Classical majorization is only a preorder on sequences (it fails to be a partial order by lacking antisymmetry, since any sequence is majorized by any of its permutations). <p> Although this definition is similar to the earlier definition of majorization on sequences, it is inequivalent. For example: <ref> [2; 4] </ref> 6 [3; 3] [4; 2] [2; 4] [4; 2] [2; 4]: Classical majorization is only a preorder on sequences (it fails to be a partial order by lacking antisymmetry, since any sequence is majorized by any of its permutations). <p> Although this definition is similar to the earlier definition of majorization on sequences, it is inequivalent. For example: [2; 4] 6 [3; 3] <ref> [4; 2] </ref> [2; 4] [4; 2] [2; 4]: Classical majorization is only a preorder on sequences (it fails to be a partial order by lacking antisymmetry, since any sequence is majorized by any of its permutations). <p> Although this definition is similar to the earlier definition of majorization on sequences, it is inequivalent. For example: <ref> [2; 4] </ref> 6 [3; 3] [4; 2] [2; 4] [4; 2] [2; 4]: Classical majorization is only a preorder on sequences (it fails to be a partial order by lacking antisymmetry, since any sequence is majorized by any of its permutations).
Reference: [3] <author> G.H. Hardy, J.E. Littlewood, and G. Polya. </author> <title> Inequalities. </title> <publisher> Cambridge University Press, </publisher> <year> 1978. </year>
Reference-contexts: Viewing problem solutions as vectors (or equivalently, sequences), we seek consecutive exchanges that move us from an initial feasible solution to a final, optimal solution of the problem. This idea leads to a natural generalization of the theory of majorization of Hardy-Littlewood-Polya used in the study of inequalities <ref> [3] </ref>. The improvement ordering on exchanges is the majorization ordering when exchanges are defined by doubly-stochastic matrices. Other semigroups of matrices define other orderings. <p> Copyright c fl1994, 1997 D. Stott Parker, Prasad Ram 5 4 Generalized Ma jorization Majorization was first defined by Muirhead [13], and was popularized by Hardy, Littlewood and Polya in their study of symmetric means <ref> [3] </ref>. Classical majorization has found several applications in stochastic scheduling [12], optimal coding [16], etc. The book by Marshall and Olkin [12] provides a very good account of the classical theory and its applications. <p> The majorization relation here is not equivalent to the classical majorization relation studied in [12]; cf. Section 4.4. Copyright c fl1994, 1997 D. Stott Parker, Prasad Ram 6 For instance: [2; 4] <ref> [3; 3] </ref> [4; 2] Theorem 4.1 [17] A necessary and a sufficient condition that x y is that there exist a LTSM L such that x = L y. Equivalently, there must exist an UTSM U such that U x = y. <p> Although this definition is similar to the earlier definition of majorization on sequences, it is inequivalent. For example: [2; 4] 6 <ref> [3; 3] </ref> [4; 2] [2; 4] [4; 2] [2; 4]: Classical majorization is only a preorder on sequences (it fails to be a partial order by lacking antisymmetry, since any sequence is majorized by any of its permutations). <p> Corresponding to Theorem 4:1 for UTSMs and majorization on sequences is a direct analogue for doubly stochastic matrices (DSMs) and classical majorization: Copyright c fl1994, 1997 D. Stott Parker, Prasad Ram 7 Theorem 4.3 (Hardy-Littlewood-Polya <ref> [3, p.45-49] </ref>) For x; y 2 &lt; + n , x y if and only if there is a doubly stochastic matrix D such that x = D y. Definition 4.5 [12] A Schur convex function is a function that is monotone with respect to . <p> Stated more generally: Theorem 4.5 (Hardy-Littlewood-Polya <ref> [3, p.89] </ref>; also [12, p.11], [18, pp.320-321]) If : I ! &lt; + is a continuous convex function (resp. continuous increasing convex function) defined on an interval I &lt; + , then for all x; y 2 I n , P n P n i=1 (y i ) iff x DSM
Reference: [4] <author> P. Helman, B.M.E. Moret, and H.D. Shapiro. </author> <title> An Exact Characterization of Greedy Structures. </title> <journal> SIAM J. Disc. Math., </journal> <volume> 6(2) </volume> <pages> 274-283, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: Space-time tradeoffs with optimality favor greedy algorithms as good heuristics. Characterizing the class of easy problems could aid in the discovery of more efficient algorithms for several problems that have not yet been proven to be hard. Many studies of greed <ref> [4, 6, 8, 9, 11, 15] </ref> have focused on greedy algorithms for specific classes of optimization problems. A common element among these studies is formalization of some notion of exchange, with which a hill-climbing approach produces optimal solutions. <p> The majorization relation here is not equivalent to the classical majorization relation studied in [12]; cf. Section 4.4. Copyright c fl1994, 1997 D. Stott Parker, Prasad Ram 6 For instance: <ref> [2; 4] </ref> [3; 3] [4; 2] Theorem 4.1 [17] A necessary and a sufficient condition that x y is that there exist a LTSM L such that x = L y. Equivalently, there must exist an UTSM U such that U x = y. <p> The majorization relation here is not equivalent to the classical majorization relation studied in [12]; cf. Section 4.4. Copyright c fl1994, 1997 D. Stott Parker, Prasad Ram 6 For instance: [2; 4] [3; 3] <ref> [4; 2] </ref> Theorem 4.1 [17] A necessary and a sufficient condition that x y is that there exist a LTSM L such that x = L y. Equivalently, there must exist an UTSM U such that U x = y. <p> Although this definition is similar to the earlier definition of majorization on sequences, it is inequivalent. For example: <ref> [2; 4] </ref> 6 [3; 3] [4; 2] [2; 4] [4; 2] [2; 4]: Classical majorization is only a preorder on sequences (it fails to be a partial order by lacking antisymmetry, since any sequence is majorized by any of its permutations). <p> Although this definition is similar to the earlier definition of majorization on sequences, it is inequivalent. For example: [2; 4] 6 [3; 3] <ref> [4; 2] </ref> [2; 4] [4; 2] [2; 4]: Classical majorization is only a preorder on sequences (it fails to be a partial order by lacking antisymmetry, since any sequence is majorized by any of its permutations). <p> Although this definition is similar to the earlier definition of majorization on sequences, it is inequivalent. For example: <ref> [2; 4] </ref> 6 [3; 3] [4; 2] [2; 4] [4; 2] [2; 4]: Classical majorization is only a preorder on sequences (it fails to be a partial order by lacking antisymmetry, since any sequence is majorized by any of its permutations). <p> Although this definition is similar to the earlier definition of majorization on sequences, it is inequivalent. For example: [2; 4] 6 [3; 3] <ref> [4; 2] </ref> [2; 4] [4; 2] [2; 4]: Classical majorization is only a preorder on sequences (it fails to be a partial order by lacking antisymmetry, since any sequence is majorized by any of its permutations). <p> Although this definition is similar to the earlier definition of majorization on sequences, it is inequivalent. For example: <ref> [2; 4] </ref> 6 [3; 3] [4; 2] [2; 4] [4; 2] [2; 4]: Classical majorization is only a preorder on sequences (it fails to be a partial order by lacking antisymmetry, since any sequence is majorized by any of its permutations).
Reference: [5] <author> F.K. Hwang. </author> <title> Majorization On A Partially Ordered Set. </title> <journal> Proc. American Math. Soc., </journal> <volume> 76 </volume> <pages> 227-237, </pages> <year> 1979. </year>
Reference-contexts: One situation where (T ; G)-majorization is useful is where T is a set of permutations, in which case optimizing G (z) amounts to sorting z (permuting z into optimal order) with respect to G. Recently majorization has been generalized in other useful ways. For example, Hwang <ref> [5] </ref> and Lih [10] generalized it to a relation on what can be called `partially ordered sequences', and make direct connections with submodularity. Copyright c fl1994, 1997 D.
Reference: [6] <author> B. Korte and L. Lovasz. </author> <title> Mathematical Structures Underlying Greedy Algorithms. </title> <editor> In ed. F. Gecseg, editor, </editor> <booktitle> Fundamentals of Computation Theory (LNCS # 117), </booktitle> <pages> pages 205-209. </pages> <publisher> Springer-Verlag, </publisher> <year> 1981. </year>
Reference-contexts: Space-time tradeoffs with optimality favor greedy algorithms as good heuristics. Characterizing the class of easy problems could aid in the discovery of more efficient algorithms for several problems that have not yet been proven to be hard. Many studies of greed <ref> [4, 6, 8, 9, 11, 15] </ref> have focused on greedy algorithms for specific classes of optimization problems. A common element among these studies is formalization of some notion of exchange, with which a hill-climbing approach produces optimal solutions.
Reference: [7] <author> B. Korte, L. Lovasz, and R. </author> <title> Schrader. </title> <publisher> Greedoids. Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1991. </year>
Reference-contexts: Matroids do not support objective functions that reflect the ordering of choices made over 1 Copyright c fl1994, 1997 D. Stott Parker, Prasad Ram 2 the execution of the greedy algorithm. This limitation is perhaps the main reason that greedoids <ref> [7] </ref> were developed. For example, average file access time = 1 n X 0 i X ` j A is the objective in the problem Optimal Storage on Files on Tape, where ` j is the length of the j-th file on the tape.
Reference: [8] <author> E.L. Lawler. </author> <title> Combinatorial Optimization: Networks and Matroids. </title> <publisher> Holt, Rinehart & Winston, </publisher> <address> New York, </address> <year> 1976. </year> <title> Copyright c fl1994, </title> <address> 1997 D. </address> <note> Stott Parker, Prasad Ram 12 </note>
Reference-contexts: Space-time tradeoffs with optimality favor greedy algorithms as good heuristics. Characterizing the class of easy problems could aid in the discovery of more efficient algorithms for several problems that have not yet been proven to be hard. Many studies of greed <ref> [4, 6, 8, 9, 11, 15] </ref> have focused on greedy algorithms for specific classes of optimization problems. A common element among these studies is formalization of some notion of exchange, with which a hill-climbing approach produces optimal solutions.
Reference: [9] <author> E.L. Lawler. </author> <title> Submodular Functions and Polymatroid Optimization. </title> <editor> In A.H.G. Rinnooy Kan (eds.) M. O'hEigeartaigh, J.K. Lenstra, editor, </editor> <booktitle> Combinatorial Optimization: Annotated Bibliographies, </booktitle> <pages> pages 32-38. </pages> <editor> J. </editor> <publisher> Wiley & Sons, </publisher> <year> 1985. </year>
Reference-contexts: Space-time tradeoffs with optimality favor greedy algorithms as good heuristics. Characterizing the class of easy problems could aid in the discovery of more efficient algorithms for several problems that have not yet been proven to be hard. Many studies of greed <ref> [4, 6, 8, 9, 11, 15] </ref> have focused on greedy algorithms for specific classes of optimization problems. A common element among these studies is formalization of some notion of exchange, with which a hill-climbing approach produces optimal solutions.
Reference: [10] <author> K. Lih. </author> <title> Majorization On Finite Partially Ordered Sets. </title> <journal> SIAM J. Alg. Disc. Meth., </journal> <volume> 3(4) </volume> <pages> 495-503, </pages> <month> December </month> <year> 1982. </year>
Reference-contexts: Recently majorization has been generalized in other useful ways. For example, Hwang [5] and Lih <ref> [10] </ref> generalized it to a relation on what can be called `partially ordered sequences', and make direct connections with submodularity. Copyright c fl1994, 1997 D. Stott Parker, Prasad Ram 8 4.6 Connections Between Majorization and Convexity Connections with convexity can make a class of optimization problems efficiently solvable.
Reference: [11] <author> L. Lovasz. </author> <title> Submodular functions and convexity. </title> <editor> In B. Korte A. Bachem, M. Groetschel, editor, </editor> <booktitle> Mathematical Programming: The State of the Art, </booktitle> <pages> pages 235-257. </pages> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1983. </year>
Reference-contexts: Space-time tradeoffs with optimality favor greedy algorithms as good heuristics. Characterizing the class of easy problems could aid in the discovery of more efficient algorithms for several problems that have not yet been proven to be hard. Many studies of greed <ref> [4, 6, 8, 9, 11, 15] </ref> have focused on greedy algorithms for specific classes of optimization problems. A common element among these studies is formalization of some notion of exchange, with which a hill-climbing approach produces optimal solutions.
Reference: [12] <author> A.W. Marshall and I. Olkin. </author> <title> Inequalities: Theory of Majorization and Its Applications. </title> <publisher> Academic Press Inc., </publisher> <year> 1979. </year>
Reference-contexts: Proof Each clearly contains the identity matrix. That they are closed under multiplication follows from the basic property that each kind of matrix is a convex sum of elementary matrices, and products of these convex sums are convex sums. For example, the Birkhoff-von Neumann theorem <ref> [1, 12] </ref> states that for any DSM A can be decomposed as A = 1 P 1 + + m P m where 0 &lt; i 1, P m i=1 i = 1, and each P i is a permutation matrix. <p> A good summary is in chapter 1 of <ref> [12] </ref>. In 1905 Lorenz noted that one distribution could be said to more uneven than another precisely when it always dominates the other (assuming the underlying densities are arranged to be monotone nonincreasing (descending), emphasizing their disparity from a uniform distribution). <p> Transposing the final result gives the stated product for U = L &gt; . 2 While a similar theorem holds for LTSMs, no such decomposition exists for arbitrary DSMs <ref> [12, p.23] </ref>. <p> Transposing the final result gives the stated product for U = L &gt; . 2 While a similar theorem holds for LTSMs, no such decomposition exists for arbitrary DSMs [12, p.23]. However: Theorem 3.2 <ref> [12, p.21] </ref>; [17] For x; y 2 &lt; + n , and T is any of UTSM, LTSM, DSM, or wDSM: If x = T y for some T 2 T then there also exists a T 0 2 T such that x = T 0 y and T 0 is <p> Copyright c fl1994, 1997 D. Stott Parker, Prasad Ram 5 4 Generalized Ma jorization Majorization was first defined by Muirhead [13], and was popularized by Hardy, Littlewood and Polya in their study of symmetric means [3]. Classical majorization has found several applications in stochastic scheduling <ref> [12] </ref>, optimal coding [16], etc. The book by Marshall and Olkin [12] provides a very good account of the classical theory and its applications. This theory is complex, however; our work is based on our treatment of majorization in [17], which relies only on linear algebra and convexity. <p> Classical majorization has found several applications in stochastic scheduling <ref> [12] </ref>, optimal coding [16], etc. The book by Marshall and Olkin [12] provides a very good account of the classical theory and its applications. This theory is complex, however; our work is based on our treatment of majorization in [17], which relies only on linear algebra and convexity. <p> For simplicity, though, we consider only the nonnegative sequences &lt; + n here. 2 The primary reference on the majorization literature, <ref> [12] </ref>, uses row vectors and matrix multiplication on the right, while we now use the more standard column vectors and matrix multiplication on the left. The majorization relation here is not equivalent to the classical majorization relation studied in [12]; cf. Section 4.4. Copyright c fl1994, 1997 D. <p> + n here. 2 The primary reference on the majorization literature, <ref> [12] </ref>, uses row vectors and matrix multiplication on the right, while we now use the more standard column vectors and matrix multiplication on the left. The majorization relation here is not equivalent to the classical majorization relation studied in [12]; cf. Section 4.4. Copyright c fl1994, 1997 D. Stott Parker, Prasad Ram 6 For instance: [2; 4] [3; 3] [4; 2] Theorem 4.1 [17] A necessary and a sufficient condition that x y is that there exist a LTSM L such that x = L y. <p> Theorem 4.2 [17] A differentiable function G : &lt; + n ! &lt; + is majorization-order preserving on C &lt; + n iff @z k @G (z) 4.4 Classical Majorization Classical majorization is often defined as a binary relation `' on `unsorted sequences' <ref> [12] </ref>: For x; y 2 &lt; + n , ( P k P k P n P n where sort# ( z ) = [z [1] ; : : :; z [n] ] denotes a descendingly-sorted permutation of z = [z 1 ; : : : ; z n ]. <p> Stott Parker, Prasad Ram 7 Theorem 4.3 (Hardy-Littlewood-Polya [3, p.45-49]) For x; y 2 &lt; + n , x y if and only if there is a doubly stochastic matrix D such that x = D y. Definition 4.5 <ref> [12] </ref> A Schur convex function is a function that is monotone with respect to . Since all permutation matrices P are DSMs, it is always true that P x x, and as mentioned above the permutations of x define an equivalence class under . <p> DSM-majorization: x DSM y iff x y. wDSM-majorization: x wDSM y iff x = Dy for some wDSM D. An equivalent definition is x wDSM y iff x vec Dy for some DSM D. This is called weak majorization (x w y) in ch.2.C of <ref> [12] </ref>. <p> We will show later that they ultimately make greedy methods possible here. With UTSM-majorization or DSM-majorization, convexity can be connected with majorization in several ways. Although Schur convexity is just monotonicity with respect to , there are many convexity results for Schur convex functions <ref> [12, 18] </ref>. For example, any symmetric function G that is convex is necessarily Schur convex. <p> Stated more generally: Theorem 4.5 (Hardy-Littlewood-Polya [3, p.89]; also <ref> [12, p.11] </ref>, [18, pp.320-321]) If : I ! &lt; + is a continuous convex function (resp. continuous increasing convex function) defined on an interval I &lt; + , then for all x; y 2 I n , P n P n i=1 (y i ) iff x DSM y (resp. x
Reference: [13] <author> R.F. Muirhead. </author> <title> Some methods applicable to identities and inequalities of symmetric algebraic functions of n letters. </title> <journal> Proc. Edinburgh Math. Soc., </journal> <volume> 21 </volume> <pages> 144-157, </pages> <year> 1903. </year>
Reference-contexts: The final matrix shows how much income each of the five individuals ultimately transfers to the others. Copyright c fl1994, 1997 D. Stott Parker, Prasad Ram 5 4 Generalized Ma jorization Majorization was first defined by Muirhead <ref> [13] </ref>, and was popularized by Hardy, Littlewood and Polya in their study of symmetric means [3]. Classical majorization has found several applications in stochastic scheduling [12], optimal coding [16], etc. The book by Marshall and Olkin [12] provides a very good account of the classical theory and its applications.
Reference: [14] <author> A.M. Ostrowski. </author> <title> Sur quelques applications des fonctions convexes et concaves au sens de I. Schur. </title> <journal> J. Math. Pures Appl., </journal> <volume> 31(9) </volume> <pages> 253-292, </pages> <year> 1952. </year>
Reference-contexts: Theorem 4.4 (Schur [20] and Ostrowski <ref> [14] </ref>) For z = [z 1 ; : : : ; z n ] 2 &lt; + n , a symmetric function G is Schur convex if and only if (z i z j ) @G (z) @z j 0 (1 i; j n): For example, the function G (z) =
Reference: [15] <author> C.H. Papadimitriou and K.S. Stieglitz. </author> <title> Combinatorial Optimization. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1982. </year>
Reference-contexts: Space-time tradeoffs with optimality favor greedy algorithms as good heuristics. Characterizing the class of easy problems could aid in the discovery of more efficient algorithms for several problems that have not yet been proven to be hard. Many studies of greed <ref> [4, 6, 8, 9, 11, 15] </ref> have focused on greedy algorithms for specific classes of optimization problems. A common element among these studies is formalization of some notion of exchange, with which a hill-climbing approach produces optimal solutions.
Reference: [16] <author> D.S. Parker. </author> <title> Conditions for Optimality of the Huffman Algorithm. </title> <journal> SIAM J. Comput., </journal> <volume> 9(3) </volume> <pages> 470-489, </pages> <month> August </month> <year> 1980. </year>
Reference-contexts: Copyright c fl1994, 1997 D. Stott Parker, Prasad Ram 5 4 Generalized Ma jorization Majorization was first defined by Muirhead [13], and was popularized by Hardy, Littlewood and Polya in their study of symmetric means [3]. Classical majorization has found several applications in stochastic scheduling [12], optimal coding <ref> [16] </ref>, etc. The book by Marshall and Olkin [12] provides a very good account of the classical theory and its applications. This theory is complex, however; our work is based on our treatment of majorization in [17], which relies only on linear algebra and convexity.
Reference: [17] <author> D.S. Parker and Prasad Ram. </author> <title> Majorization on Sequences. </title> <type> Technical report, </type> <institution> UCLA Computer Science Dept., </institution> <address> Los Angeles, CA 90024-1596, </address> <month> July </month> <year> 1994. </year>
Reference-contexts: C C C C : The pairwise exchange LTSMs L pq (*) are defined by L pq (*) = R U pq (*) R, where R is the reflection permutation that maps i to (n i + 1), for 1 i n. Theorem 3.1 <ref> [17] </ref> Every UTSM U is equal to a product of n (n 1)=2 pairwise exchange UTSMs. Specifically U = (` ij ) = k=n1 i=k+1 where * ik = u ki = Q if u ki &gt; 0, and 0 otherwise. <p> Transposing the final result gives the stated product for U = L &gt; . 2 While a similar theorem holds for LTSMs, no such decomposition exists for arbitrary DSMs [12, p.23]. However: Theorem 3.2 [12, p.21]; <ref> [17] </ref> For x; y 2 &lt; + n , and T is any of UTSM, LTSM, DSM, or wDSM: If x = T y for some T 2 T then there also exists a T 0 2 T such that x = T 0 y and T 0 is a product <p> Classical majorization has found several applications in stochastic scheduling [12], optimal coding [16], etc. The book by Marshall and Olkin [12] provides a very good account of the classical theory and its applications. This theory is complex, however; our work is based on our treatment of majorization in <ref> [17] </ref>, which relies only on linear algebra and convexity. In our context here, majorization is important since it is the natural ordering on probability densities. <p> The majorization relation here is not equivalent to the classical majorization relation studied in [12]; cf. Section 4.4. Copyright c fl1994, 1997 D. Stott Parker, Prasad Ram 6 For instance: [2; 4] [3; 3] [4; 2] Theorem 4.1 <ref> [17] </ref> A necessary and a sufficient condition that x y is that there exist a LTSM L such that x = L y. Equivalently, there must exist an UTSM U such that U x = y. <p> Theorem 4.2 <ref> [17] </ref> A differentiable function G : &lt; + n ! &lt; + is majorization-order preserving on C &lt; + n iff @z k @G (z) 4.4 Classical Majorization Classical majorization is often defined as a binary relation `' on `unsorted sequences' [12]: For x; y 2 &lt; + n , (
Reference: [18] <author> J.E. Pecaric, F. Proschan, and Y.L. Tong. </author> <title> Convex Functions, Partial Orderings, and Statistical Applications. </title> <publisher> Academic Press, </publisher> <address> San Diego, </address> <year> 1992. </year>
Reference-contexts: We will show later that they ultimately make greedy methods possible here. With UTSM-majorization or DSM-majorization, convexity can be connected with majorization in several ways. Although Schur convexity is just monotonicity with respect to , there are many convexity results for Schur convex functions <ref> [12, 18] </ref>. For example, any symmetric function G that is convex is necessarily Schur convex. <p> Another connection between convexity and majorization with many facets is that, given an interval I &lt; + and continuous : I ! &lt; + , the function G (z) = P i (z i ) is Schur convex if and only if is convex on I ([12, p.68], <ref> [18, p.333] </ref>). <p> Stated more generally: Theorem 4.5 (Hardy-Littlewood-Polya [3, p.89]; also [12, p.11], <ref> [18, pp.320-321] </ref>) If : I ! &lt; + is a continuous convex function (resp. continuous increasing convex function) defined on an interval I &lt; + , then for all x; y 2 I n , P n P n i=1 (y i ) iff x DSM y (resp. x wDSM y). <p> This is the `majorization theorem'. An important further generalization is as follows: Theorem 4.6 (Pecaric-Proschan-Tong <ref> [18, pp.323-324] </ref>) If : I ! &lt; + is a continuous convex function (resp. continuous increasing convex function) defined on an interval I &lt; + , then for all decreasing sequences x; y 2 I n and sequences w such that k X w i x i i=1 and i=1 w
Reference: [19] <author> G.-C. Rota. </author> <title> On the Foundations of Combinatory Theory I. Theory of Mobius Functions. </title> <journal> Z. Wahrschein-lichkeitstheorie, </journal> <volume> 2 </volume> <pages> 340-368, </pages> <year> 1964. </year>
Reference-contexts: The theory of Mobius inversion <ref> [19] </ref> gives a generalized notion of differential on partially-ordered domains (although here we consider only totally-ordered sequences).
Reference: [20] <author> I. </author> <title> Schur. Uber eine Klasse von Mittelbildungen mit Anwendungen auf die Determinantentheorie. </title> <journal> Sitzungsber. Berl. Math. Ges., </journal> <volume> 22 </volume> <pages> 9-20, </pages> <year> 1923. </year>
Reference-contexts: Theorem 4.4 (Schur <ref> [20] </ref> and Ostrowski [14]) For z = [z 1 ; : : : ; z n ] 2 &lt; + n , a symmetric function G is Schur convex if and only if (z i z j ) @G (z) @z j 0 (1 i; j n): For example, the function
References-found: 20

