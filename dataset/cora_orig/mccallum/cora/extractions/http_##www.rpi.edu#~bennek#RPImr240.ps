URL: http://www.rpi.edu/~bennek/RPImr240.ps
Refering-URL: http://www.rpi.edu/~bennek/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Hybrid Extreme Point Tabu Search for suggesting the use of tabu search for the global
Author: Jennifer A. Blue Kristin P. Bennett 
Keyword: Key Words: tabu search, global optimization, bilinear programming, machine learning,  
Note: classification. Knowledge Discovery and Data  This material is based on research supported by National Science Foundation Grant 949427. The authors wish to thank Fred Glover  
Address: Troy, NY 12180  Troy, NY 12180.  
Affiliation: Department of Mathematical Sciences Rensselaer Polytechnic Institute  R.P.I. Math  Mining Group, Department of Mathematical Sciences, Rensselaer Polytechnic Institute,  
Pubnum: Report No. 240  
Email: Email bennek@rpi.edu, bluej@rpi.edu.  
Date: April 1996  
Abstract: We develop a new hybrid tabu search method for optimizing a continuous differentiable function over the extreme points of a polyhedron. The method combines extreme point tabu search with traditional descent algorithms based on linear programming. The tabu search algorithm utilizes both recency-based and frequency-based memory and oscillates between local improvement and diversification phases. The hybrid algorithm iterates between using the descent algorithm to find a local minimum and using tabu search to improve locally and then move to a new area of the search space. This algorithm can be used on many important classes of problems in global optimization including bilinear programming, multilinear programming, multiplicative programming, concave minimization, and complementarity problems. The algorithm is applied to two practical problems: the quasistatic multi-rigid-body contact problem in robotics and the global tree optimization problem in machine learning. Computational results show that the hybrid algorithm outperforms the descent and tabu search algorithms used alone. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Aboudi and K. J-ornsten. </author> <title> Tabu search for general zero-one integer programs using the pivot and complement heuristic. </title> <journal> ORSA Journal on Computing, </journal> <volume> 6(1) </volume> <pages> 82-936, </pages> <year> 1994. </year>
Reference-contexts: Frequency memory is incorporated by keeping track of how often variables appear in the basis. Tabu search algorithms using extreme points have been successfully applied to integer programming and bilinear programming applications <ref> [3, 12, 1, 14] </ref>. One limitation of extreme point tabu search is that if the evaluation of the objective function is expensive and the neighborhoods are large, then tabu search can be slow when compared with the local descent methods described above. <p> Other versions of tabu search applied to extreme points can be found in <ref> [12, 1, 14] </ref>. We begin with a description of the features of the algorithm and recommended parameter choices. The resulting algorithm is summarized in Algorithm 3.1. The tabu search neighborhood of each extreme point consists of the adjacent extreme points.
Reference: [2] <author> M. Bazaraa, H. Sherali, and C. Shetty. </author> <title> Nonlinear Programming Theory and Algorithms. </title> <publisher> John Wiley & Sons, </publisher> <address> New York, </address> <year> 1993. </year>
Reference-contexts: One strategy used for bilinear and other differentiable objective functions is to iteratively linearize the objective and solve the resulting linear program. Examples of these algorithms are the uncoupled bilinear programming algorithm [7, 19], Frank-Wolfe type algorithms [7, 10], and successive linear programming <ref> [2] </ref>. These iterative linear programming algorithms relatively quickly find a local minimum and then stop. Powerful simplex method codes such as MINOS [17] can be used quickly and efficiently to solve the linear subproblems. The algorithms are simple and have few parameters.
Reference: [3] <author> K. Bennett and J. </author> <title> Blue. An extreme point tabu search method for data mining. R.P.I. Math Report No. </title> <type> 228, </type> <institution> Rensselaer Polytechnic Institute, </institution> <address> Troy, NY, </address> <year> 1996. </year>
Reference-contexts: Frequency memory is incorporated by keeping track of how often variables appear in the basis. Tabu search algorithms using extreme points have been successfully applied to integer programming and bilinear programming applications <ref> [3, 12, 1, 14] </ref>. One limitation of extreme point tabu search is that if the evaluation of the objective function is expensive and the neighborhoods are large, then tabu search can be slow when compared with the local descent methods described above. <p> The basis is then updated. The basic feasible solutions and the pivot operation provide a natural definition for the neighborhood and memory structures needed for tabu search. 3 3 Extreme Point Tabu Search Our version of extreme point tabu search (EPTS) is an extension of the algorithm described in <ref> [3] </ref>. Other versions of tabu search applied to extreme points can be found in [12, 1, 14]. We begin with a description of the features of the algorithm and recommended parameter choices. The resulting algorithm is summarized in Algorithm 3.1. <p> Computational results showed that the quality of solutions found were very good in terms of generalization, but the global minima were frequently not found. We explored constructing trees with three decisions (seven total nodes) and seven decisions (fifteen total nodes). The reader should consult <ref> [6, 3] </ref> for details on how the problems 8 1 w 1 x fl 1 &gt; 0 w 1 x fl 1 0 A B A B w 2 x fl 2 &gt; 0 1 w 2 x fl 2 0 1 w 2 x fl 2 0 w 3 x <p> Also, alternate objective functions may produce better generalization. One benefit of tabu search methods is that we have the flexibility to use alternate objective functions. For example, we could use an objective that counts the number of points misclassified during the EPTS cycle of the HEPTS algorithm <ref> [3] </ref>.
Reference: [4] <author> K. P. Bennett. </author> <title> Decision tree construction via linear programming. </title> <editor> In M. Evans, editor, </editor> <booktitle> Proceedings of the 4th Midwest Artificial Intelligence and Cognitive Science Society Conference, </booktitle> <pages> pages 97-101, </pages> <address> Utica, Illinois, </address> <year> 1992. </year>
Reference-contexts: Each weight and threshold were uniformly generated between -1 and 1. Then points were randomly generated in the unit cube and classified using the generated tree. Since a starting point is required for FW, an initial tree was generated using the greedy MSMT decision tree algorithm <ref> [4] </ref>. MSMT used a linear program to recursively construct the decisions. The tree was then pruned to the appropriate number of decisions. We compared the performance of HEPTS, FW, and EPTS. To evaluate their effectiveness as global optimization methods, we compared the optimal objective obtained.
Reference: [5] <author> K. P. Bennett. </author> <title> Global tree optimization: A non-greedy decision tree algorithm. </title> <journal> Computing Science and Statistics, </journal> <volume> 26 </volume> <pages> 156-160, </pages> <year> 1994. </year>
Reference-contexts: This NP-complete problem is an uncoupled linear complementarity problem that can be formulated as an uncoupled bilinear program [19]. The second problem is global tree optimization in machine learning <ref> [5] </ref>. In this problem, we try to construct a decision tree with a given structure to correctly classify points from two classes. This NP-complete problem can be posed as an extended linear complementarity problem that can be formulated as a coupled multilinear program [6]. This paper is organized as follows. <p> However, this is beyond the scope of this paper. 6.2 Global Tree Optimization In global tree optimization (GTO), the problem of constructing a decision tree with a given structure to recognize points from two classes is formulated as a multilinear program <ref> [5] </ref>. If a tree with the given structure exists that completely classifies the points in the two sets then the solution satisfies an extended linear complementarity problem [21, 6]. Even a problem using a tree with only two decisions is NP-Complete [15, 7].
Reference: [6] <author> K. P. Bennett. </author> <title> Optimal decision trees through multilinear programming. R.P.I. Math Report No. </title> <type> 214, </type> <institution> Rensselaer Polytechnic Institute, </institution> <address> Troy, NY, </address> <year> 1996. </year> <note> Revised. </note>
Reference-contexts: In this problem, we try to construct a decision tree with a given structure to correctly classify points from two classes. This NP-complete problem can be posed as an extended linear complementarity problem that can be formulated as a coupled multilinear program <ref> [6] </ref>. This paper is organized as follows. In Section 2 we define the problem we are interested in and discuss its possible applications. Our version of EPTS is described in Section 3. A brief review of two local descent techniques is provided in Section 4. <p> If a tree with the given structure exists that completely classifies the points in the two sets then the solution satisfies an extended linear complementarity problem <ref> [21, 6] </ref>. Even a problem using a tree with only two decisions is NP-Complete [15, 7]. If a tree cannot be constructed to completely classify the points, a tree that minimizes the classification error is desired. <p> Computational results showed that the quality of solutions found were very good in terms of generalization, but the global minima were frequently not found. We explored constructing trees with three decisions (seven total nodes) and seven decisions (fifteen total nodes). The reader should consult <ref> [6, 3] </ref> for details on how the problems 8 1 w 1 x fl 1 &gt; 0 w 1 x fl 1 0 A B A B w 2 x fl 2 &gt; 0 1 w 2 x fl 2 0 1 w 2 x fl 2 0 w 3 x
Reference: [7] <author> K. P. Bennett and O. L. Mangasarian. </author> <title> Bilinear separation of two sets in n-space. </title> <journal> Computational Optimization and Applications, </journal> <volume> 2 </volume> <pages> 207-227, </pages> <year> 1993. </year>
Reference-contexts: One strategy used for bilinear and other differentiable objective functions is to iteratively linearize the objective and solve the resulting linear program. Examples of these algorithms are the uncoupled bilinear programming algorithm <ref> [7, 19] </ref>, Frank-Wolfe type algorithms [7, 10], and successive linear programming [2]. These iterative linear programming algorithms relatively quickly find a local minimum and then stop. Powerful simplex method codes such as MINOS [17] can be used quickly and efficiently to solve the linear subproblems. <p> One strategy used for bilinear and other differentiable objective functions is to iteratively linearize the objective and solve the resulting linear program. Examples of these algorithms are the uncoupled bilinear programming algorithm [7, 19], Frank-Wolfe type algorithms <ref> [7, 10] </ref>, and successive linear programming [2]. These iterative linear programming algorithms relatively quickly find a local minimum and then stop. Powerful simplex method codes such as MINOS [17] can be used quickly and efficiently to solve the linear subproblems. The algorithms are simple and have few parameters. <p> Perform move and update frequency and recency memories. 6. Go to step 2. 5 4 Review of Descent Algorithms Many descent algorithms can be used within hybrid EPTS. We looked at two algorithms: the uncoupled bilinear programming algorithm (UBPA) and a Frank-Wolfe type algorithm (FW). UBPA <ref> [7] </ref> can be applied to uncoupled bilinear problems with the following form: min xy X := fxjAx = b; x 0g s:t: y 2 Y Y := fyjCy = d; y 0g (4) The problem is called uncoupled because the constraint sets X and Y are independent. <p> UBPA takes advantage of the fact that the constraints are uncoupled. Algorithm 4.1 (Uncoupled bilinear program algorithm (UBPA) <ref> [7] </ref>) Start with any feasible point (x 0 ; y 0 ) for (4). <p> Stop when impossible. In the above algorithm, "arg vertex min" denotes an extreme point in the solution set of the indicated linear program. UBPA terminates at a local minimum satisfying the minimum principle necessary optimality condition <ref> [7] </ref>. FW can be applied to any instance of Problem (1) provided f has continuous first partial derivatives on X and f is bounded below on X . In [7], FW was shown to terminate at a local minimum satisfying the minimum principle necessary optimality condition. <p> UBPA terminates at a local minimum satisfying the minimum principle necessary optimality condition <ref> [7] </ref>. FW can be applied to any instance of Problem (1) provided f has continuous first partial derivatives on X and f is bounded below on X . In [7], FW was shown to terminate at a local minimum satisfying the minimum principle necessary optimality condition. Algorithm 4.2 (Frank-Wolfe algorithm (FW) [10, 7]) Start with any x 0 2 X . 1. v i 2 arg vertex min x2X 5 f (x i )x 2. <p> In [7], FW was shown to terminate at a local minimum satisfying the minimum principle necessary optimality condition. Algorithm 4.2 (Frank-Wolfe algorithm (FW) <ref> [10, 7] </ref>) Start with any x 0 2 X . 1. v i 2 arg vertex min x2X 5 f (x i )x 2. <p> FW can be applied to bilinear programs with uncoupled or coupled constraints. FW is slightly more expensive because it requires a line search. In practice both algorithms find a local minimum after a small number of linear programs <ref> [7, 19] </ref>. 6 5 Hybrid Extreme Point Tabu Search Hybrid EPTS combines a fast local descent method with the robust global optimization properties of EPTS. The basic idea is to use a descent algorithm such as UBPA or FW to get to a local minimum. <p> If a tree with the given structure exists that completely classifies the points in the two sets then the solution satisfies an extended linear complementarity problem [21, 6]. Even a problem using a tree with only two decisions is NP-Complete <ref> [15, 7] </ref>. If a tree cannot be constructed to completely classify the points, a tree that minimizes the classification error is desired. The goal is to construct trees that generalize well, i.e., trees that correctly predict future points. GTO can be used in nongreedy algorithms to construct multivariate decision trees.
Reference: [8] <author> R. Cottle, J. Pang, and R. Stone. </author> <title> The Linear Complementarity Problem. </title> <publisher> Academic Press, </publisher> <address> San Diego, </address> <year> 1992. </year> <month> 13 </month>
Reference-contexts: There are many global optimization problems with nonlinear objectives and linear constraints in which an optimal extreme point solution is desired or known to exist. Examples can be found in bilinear programming, multilinear programming, multiplicative programming, concave minimization, and complementarity problems <ref> [13, 8] </ref>. Our goal is to develop an algorithm for nonlinear objective problems that searches the extreme points for an optimal or near-optimal solution. One strategy used for bilinear and other differentiable objective functions is to iteratively linearize the objective and solve the resulting linear program.
Reference: [9] <author> R. Detrano, A. Janosi, W. Steinbrunn, M. Pfisterer, J. Schmid, S. Sandhu, K. Guppy, S. Lee, and V. Froelicher. </author> <title> International application of a new probability algorithm for the diagnosis of coronary artery disease. </title> <journal> American Journal of Cardiology, </journal> <volume> 64 </volume> <pages> 304-310, </pages> <year> 1989. </year>
Reference-contexts: The datasets are: the BUPA Liver Disease dataset (Liver); the PIMA Indians Diabetes dataset (Diabetes), the Wisconsin Breast Cancer Database (Cancer) [23], and the Cleveland Heart Disease Database (Heart) <ref> [9] </ref>. We used 5-fold cross validation. Each dataset was divided into 5 parts. The decision tree was constructed using 4/5 of the data and tested on the remaining 1/5. This was repeated for each of the 5 parts and the results were averaged.
Reference: [10] <author> M. Frank and P. Wolfe. </author> <title> An algorithm for quadratic programming. </title> <journal> Naval Research Logistics Quarterly, </journal> <volume> 3 </volume> <pages> 95-110, </pages> <year> 1956. </year>
Reference-contexts: One strategy used for bilinear and other differentiable objective functions is to iteratively linearize the objective and solve the resulting linear program. Examples of these algorithms are the uncoupled bilinear programming algorithm [7, 19], Frank-Wolfe type algorithms <ref> [7, 10] </ref>, and successive linear programming [2]. These iterative linear programming algorithms relatively quickly find a local minimum and then stop. Powerful simplex method codes such as MINOS [17] can be used quickly and efficiently to solve the linear subproblems. The algorithms are simple and have few parameters. <p> In [7], FW was shown to terminate at a local minimum satisfying the minimum principle necessary optimality condition. Algorithm 4.2 (Frank-Wolfe algorithm (FW) <ref> [10, 7] </ref>) Start with any x 0 2 X . 1. v i 2 arg vertex min x2X 5 f (x i )x 2.
Reference: [11] <author> F. Glover. </author> <title> Tabu search fundamentals and uses. </title> <type> Technical report, </type> <institution> School of Business, University of Colorado, Boulder, Colorado, </institution> <year> 1995. </year>
Reference-contexts: For frequency-based memory, we keep count of the number of times each variable is used in the basis. We increment the count of the variables in this basis at every iteration, not just for critical events as suggested in <ref> [11] </ref>. We explored the critical event strategy but found it did not enhance the quality of our results. The best solution found so far in terms of the given objective function is used as the aspiration criterion. Moves can become tabu in two ways. <p> EPTS oscillates between a local improvement mode and a diversification mode. In the local improvement mode, the objective function is used to evaluate the qualities of the move. The diversification strategy is a variation of the approach suggested in <ref> [11] </ref>.
Reference: [12] <author> F. Glover and A. Ltkketangen. </author> <title> Probabilistic tabu search for zero-one mixed integer programming problems. </title> <type> Manuscript, </type> <institution> School of Business, University of Colorado, </institution> <year> 1994. </year>
Reference-contexts: Frequency memory is incorporated by keeping track of how often variables appear in the basis. Tabu search algorithms using extreme points have been successfully applied to integer programming and bilinear programming applications <ref> [3, 12, 1, 14] </ref>. One limitation of extreme point tabu search is that if the evaluation of the objective function is expensive and the neighborhoods are large, then tabu search can be slow when compared with the local descent methods described above. <p> Other versions of tabu search applied to extreme points can be found in <ref> [12, 1, 14] </ref>. We begin with a description of the features of the algorithm and recommended parameter choices. The resulting algorithm is summarized in Algorithm 3.1. The tabu search neighborhood of each extreme point consists of the adjacent extreme points.
Reference: [13] <author> R. Horst and P. Pardalos, </author> <title> editors. Global Optimization. </title> <publisher> Kluwer Academic, </publisher> <address> New York, </address> <year> 1995. </year>
Reference-contexts: There are many global optimization problems with nonlinear objectives and linear constraints in which an optimal extreme point solution is desired or known to exist. Examples can be found in bilinear programming, multilinear programming, multiplicative programming, concave minimization, and complementarity problems <ref> [13, 8] </ref>. Our goal is to develop an algorithm for nonlinear objective problems that searches the extreme points for an optimal or near-optimal solution. One strategy used for bilinear and other differentiable objective functions is to iteratively linearize the objective and solve the resulting linear program.
Reference: [14] <author> A. Ltkketangen, K. J-ornsten, and S. Storty. </author> <title> Tabu search within a pivot and complement framework. </title> <journal> International Transactions of Operations Research, </journal> <volume> 1(3) </volume> <pages> 305-316, </pages> <year> 1994. </year>
Reference-contexts: Frequency memory is incorporated by keeping track of how often variables appear in the basis. Tabu search algorithms using extreme points have been successfully applied to integer programming and bilinear programming applications <ref> [3, 12, 1, 14] </ref>. One limitation of extreme point tabu search is that if the evaluation of the objective function is expensive and the neighborhoods are large, then tabu search can be slow when compared with the local descent methods described above. <p> Other versions of tabu search applied to extreme points can be found in <ref> [12, 1, 14] </ref>. We begin with a description of the features of the algorithm and recommended parameter choices. The resulting algorithm is summarized in Algorithm 3.1. The tabu search neighborhood of each extreme point consists of the adjacent extreme points.
Reference: [15] <author> N. Megiddo. </author> <title> On the complexity of polyhedral separability. </title> <journal> Discrete and Computational Geometry, </journal> <volume> 3 </volume> <pages> 325-337, </pages> <year> 1988. </year>
Reference-contexts: If a tree with the given structure exists that completely classifies the points in the two sets then the solution satisfies an extended linear complementarity problem [21, 6]. Even a problem using a tree with only two decisions is NP-Complete <ref> [15, 7] </ref>. If a tree cannot be constructed to completely classify the points, a tree that minimizes the classification error is desired. The goal is to construct trees that generalize well, i.e., trees that correctly predict future points. GTO can be used in nongreedy algorithms to construct multivariate decision trees.
Reference: [16] <author> P.M. Murphy and D.W. Aha. </author> <title> UCI repository of machine learning databases. </title> <institution> Department of Information and Computer Science, University of California, Irvine, California, </institution> <year> 1992. </year>
Reference-contexts: Improvement is the percent improvement of HEPTS over FW averaged over the 5 trials. better than FW. To assess the practicality of these methods for actual problems we experimented with four datasets available via anonymous ftp from the Machine Learning Repository at the University of California at Irvine <ref> [16] </ref>. The datasets are: the BUPA Liver Disease dataset (Liver); the PIMA Indians Diabetes dataset (Diabetes), the Wisconsin Breast Cancer Database (Cancer) [23], and the Cleveland Heart Disease Database (Heart) [9]. We used 5-fold cross validation. Each dataset was divided into 5 parts.
Reference: [17] <author> B.A. Murtagh and M.A. Saunders. </author> <title> MINOS 5.4 user's guide. </title> <type> Technical Report SOL 83.20, </type> <institution> Stanford University, </institution> <year> 1993. </year>
Reference-contexts: The most common example of this problem is linear programming. Fast and powerful techniques developed for linear programming exist for traversing the extreme points of a polyhedral constraint region to an optimal solution <ref> [18, 17] </ref>. There are many global optimization problems with nonlinear objectives and linear constraints in which an optimal extreme point solution is desired or known to exist. Examples can be found in bilinear programming, multilinear programming, multiplicative programming, concave minimization, and complementarity problems [13, 8]. <p> Examples of these algorithms are the uncoupled bilinear programming algorithm [7, 19], Frank-Wolfe type algorithms [7, 10], and successive linear programming [2]. These iterative linear programming algorithms relatively quickly find a local minimum and then stop. Powerful simplex method codes such as MINOS <ref> [17] </ref> can be used quickly and efficiently to solve the linear subproblems. The algorithms are simple and have few parameters. Searches of adjacent extreme points have been added to make such algorithms more robust [19]. But their functionality is limited on global optimization problems. <p> The MINOS linear programming package <ref> [17] </ref> was customized to perform all four algorithms. Both applications can be formulated as complementarity problems. The multi-rigid-body contact problem requires the solution of an uncoupled bilinear program.
Reference: [18] <author> K.G. Murty. </author> <title> Linear Programming. </title> <publisher> John Wiley & Sons, </publisher> <address> New York, New York, </address> <year> 1983. </year>
Reference-contexts: The most common example of this problem is linear programming. Fast and powerful techniques developed for linear programming exist for traversing the extreme points of a polyhedral constraint region to an optimal solution <ref> [18, 17] </ref>. There are many global optimization problems with nonlinear objectives and linear constraints in which an optimal extreme point solution is desired or known to exist. Examples can be found in bilinear programming, multilinear programming, multiplicative programming, concave minimization, and complementarity problems [13, 8]. <p> There is a natural neighborhood structure. Each extreme point corresponds to a basic feasible solution. We can examine an adjacent extreme point by exchanging a variable outside the basis for a variable inside the basis. This is the pivot used in the simplex method for linear programming <ref> [18] </ref>. Recency memory is maintained by keeping track of when variables are pivoted in and out of the basis. Frequency memory is incorporated by keeping track of how often variables appear in the basis. <p> In general, continuity and differentiability are not required for extreme point tabu search. We assume without loss of generality that the constraints are in the "standard form" used in linear programming <ref> [18] </ref>. Thus the problem becomes: min f (x) X := fxjAx = b; x 0g (1) where x 2 R n ; A 2 R mfin , b 2 R m , and f : R n ! R. For this paper we will assume that n &gt; m. <p> The set X is a polyhedron. We do not assume that X is bounded. The linear constraints in X form a simplex. We review briefly the properties of the simplex and advise the reader to consult a text on linear programming for more details <ref> [18] </ref>. Any point in X that cannot be written as a linear combination of any two other distinct points in X is called an extreme point. Each extreme point corresponds to a basic feasible solution (BFS). Each BFS consists of n variables. Thus, the polyhedron has n! m!(nm)! extreme points.
Reference: [19] <author> J. Pang, J. Trinkle, and G. Lo. </author> <title> A complementarity approach to a quasistatic multi-rigid-body contact problem. </title> <journal> Computational Optimization and Applications, </journal> <volume> 5 </volume> <pages> 139-154, </pages> <year> 1996. </year>
Reference-contexts: One strategy used for bilinear and other differentiable objective functions is to iteratively linearize the objective and solve the resulting linear program. Examples of these algorithms are the uncoupled bilinear programming algorithm <ref> [7, 19] </ref>, Frank-Wolfe type algorithms [7, 10], and successive linear programming [2]. These iterative linear programming algorithms relatively quickly find a local minimum and then stop. Powerful simplex method codes such as MINOS [17] can be used quickly and efficiently to solve the linear subproblems. <p> Powerful simplex method codes such as MINOS [17] can be used quickly and efficiently to solve the linear subproblems. The algorithms are simple and have few parameters. Searches of adjacent extreme points have been added to make such algorithms more robust <ref> [19] </ref>. But their functionality is limited on global optimization problems. Tabu search is well-suited for minimizing nonlinear functions with linear constraints. There is a natural neighborhood structure. Each extreme point corresponds to a basic feasible solution. <p> The quasistatic multi-rigid-body contact problem is used to predict the motion of a passive rigid 2 body in contact with robot manipulators [22]. This NP-complete problem is an uncoupled linear complementarity problem that can be formulated as an uncoupled bilinear program <ref> [19] </ref>. The second problem is global tree optimization in machine learning [5]. In this problem, we try to construct a decision tree with a given structure to correctly classify points from two classes. <p> FW can be applied to bilinear programs with uncoupled or coupled constraints. FW is slightly more expensive because it requires a line search. In practice both algorithms find a local minimum after a small number of linear programs <ref> [7, 19] </ref>. 6 5 Hybrid Extreme Point Tabu Search Hybrid EPTS combines a fast local descent method with the robust global optimization properties of EPTS. The basic idea is to use a descent algorithm such as UBPA or FW to get to a local minimum. <p> The goal is to use QCP to aid in automatically planning the motion of a robot manipulating an object. We briefly describe QCP and refer the reader to <ref> [22, 19] </ref> for more details. Since QCP is NP-complete and has extreme point solutions, it is an ideal problem for hybrid EPTS. Our computational results in this paper are limited to the problems with datasets given in [19]. <p> We briefly describe QCP and refer the reader to [22, 19] for more details. Since QCP is NP-complete and has extreme point solutions, it is an ideal problem for hybrid EPTS. Our computational results in this paper are limited to the problems with datasets given in <ref> [19] </ref>. In the future, we hope to obtain all the datasets from the results given in [19] so we can make a more detailed evaluation of this problem. In [19], QCP was formulated as an uncoupled complementarity problem (4). <p> Since QCP is NP-complete and has extreme point solutions, it is an ideal problem for hybrid EPTS. Our computational results in this paper are limited to the problems with datasets given in <ref> [19] </ref>. In the future, we hope to obtain all the datasets from the results given in [19] so we can make a more detailed evaluation of this problem. In [19], QCP was formulated as an uncoupled complementarity problem (4). An algorithm, we will call QCPA minimized an uncoupled bilinear program to find a solution of 7 QCP. QCPA uses the above UBPA (4.1) as a subproblem. <p> Our computational results in this paper are limited to the problems with datasets given in <ref> [19] </ref>. In the future, we hope to obtain all the datasets from the results given in [19] so we can make a more detailed evaluation of this problem. In [19], QCP was formulated as an uncoupled complementarity problem (4). An algorithm, we will call QCPA minimized an uncoupled bilinear program to find a solution of 7 QCP. QCPA uses the above UBPA (4.1) as a subproblem. <p> QCPA performed very well on this problem. It successfully solved 78 problems out of 82 problems attempted. We tested Hybrid EPTS, EPTS, and UBPA on three problems successfully solved by QCPA (Data Set 1, Data Set 2, and Data Set 3 in <ref> [19, p. 151] </ref>). The problems have 18 variables and 9 constraints. On Data Set 2, a global optimal complementary solution was found by the descent algorithm UBPA and therefore also HEPTS. For Data Set 1 and Data Set 3, UBPA failed to find a global minimum. <p> The Hybrid EPTS, however, was able to find the global minima for both problems in one cycle of UBPA and EPTS. EPTS performed as well as HEPTS on all three problems, finding the complementary solution in each case. In <ref> [19] </ref>, QCPA solved problems with up to 120 variables. Eventually we hope to compare the results of HEPTS and QCPA on these problems, especially the 4 problems where UCPA did not find a complementary solution.
Reference: [20] <author> J. R. Quinlan. C4.5: </author> <title> Programs for Machine Learning. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1992. </year>
Reference-contexts: We call w 1 2 R N the weights and fl 1 2 R the threshold of the decision. The error of the entire tree is formulated as a bilinear or multilinear program and the error is minimized. This contrasts with greedy decision tree methods such as C4.5 <ref> [20] </ref> that construct a decision tree one decision at a time until a desired accuracy is reached. Both algorithms, FW and EPTS, have been applied with reasonable success to the GTO problem.
Reference: [21] <author> B. De Schutter and B. De Moor. </author> <title> The extended linear complementarity problem. </title> <journal> Mathematical Programming, </journal> <volume> 71 </volume> <pages> 289-325, </pages> <year> 1995. </year>
Reference-contexts: If a tree with the given structure exists that completely classifies the points in the two sets then the solution satisfies an extended linear complementarity problem <ref> [21, 6] </ref>. Even a problem using a tree with only two decisions is NP-Complete [15, 7]. If a tree cannot be constructed to completely classify the points, a tree that minimizes the classification error is desired.
Reference: [22] <author> J. Trinkle and D. Zeng. </author> <title> Planar quasistatic motion of a contacted rigid body. </title> <journal> IEEE Transactions on Robotics and Automation, </journal> <volume> 11 </volume> <pages> 229-246, </pages> <year> 1995. </year>
Reference-contexts: The frequency-based memory allows us to target new areas of the search space. To illustrate the practicality of this approach we experimented with two applications. The quasistatic multi-rigid-body contact problem is used to predict the motion of a passive rigid 2 body in contact with robot manipulators <ref> [22] </ref>. This NP-complete problem is an uncoupled linear complementarity problem that can be formulated as an uncoupled bilinear program [19]. The second problem is global tree optimization in machine learning [5]. <p> The goal is to use QCP to aid in automatically planning the motion of a robot manipulating an object. We briefly describe QCP and refer the reader to <ref> [22, 19] </ref> for more details. Since QCP is NP-complete and has extreme point solutions, it is an ideal problem for hybrid EPTS. Our computational results in this paper are limited to the problems with datasets given in [19].
Reference: [23] <author> W. H. Wolberg and O.L. Mangasarian. </author> <title> Multisurface method of pattern separation for medical diagnosis applied to breast cytology. </title> <booktitle> Proceedings of the National Academy of Sciences,U.S.A., </booktitle> <volume> 87 </volume> <pages> 9193-9196, </pages> <year> 1990. </year> <month> 14 </month>
Reference-contexts: The datasets are: the BUPA Liver Disease dataset (Liver); the PIMA Indians Diabetes dataset (Diabetes), the Wisconsin Breast Cancer Database (Cancer) <ref> [23] </ref>, and the Cleveland Heart Disease Database (Heart) [9]. We used 5-fold cross validation. Each dataset was divided into 5 parts. The decision tree was constructed using 4/5 of the data and tested on the remaining 1/5.
References-found: 23

