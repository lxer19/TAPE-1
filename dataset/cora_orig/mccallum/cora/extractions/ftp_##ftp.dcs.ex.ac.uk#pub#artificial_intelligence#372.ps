URL: ftp://ftp.dcs.ex.ac.uk/pub/artificial_intelligence/372.ps
Refering-URL: http://www.dcs.ex.ac.uk/reports/reports.html
Root-URL: http://www.dcs.ex.ac.uk
Email: Email: fdbradley,ajitg@dcs.ex.ac.uk  
Title: Genetic algorithms for knowledge discovery in continuous data  
Author: Dane Bradley-Carter and Ajit Narayanan 
Address: Exeter EX4 4PT United Kingdom  
Affiliation: Department of Computer Science University of Exeter  
Abstract-found: 0
Intro-found: 1
Reference: <author> A. </author> <month> Al-Attar </month> <year> (1994). </year> <title> A Hybrid GA-heuristic search strategy. </title> <journal> AI Expert, </journal> <volume> 9 (9), </volume> <pages> 34. </pages>
Reference: <author> J. </author> <title> Catlett (1991). On changing continuous attributes into ordered discrete attributes. </title> <booktitle> Machine Learning: Proceedings of European Working Session on Learning. Lecture Notes in Artificial Intelligence (EWSI-91), </booktitle> <publisher> Springer Verlag, </publisher> <pages> 164 - 178. </pages>
Reference-contexts: Existing global methods include D-2 <ref> (Catlett, 1991) </ref>, 1R (Holte, 1993) and ChiMerge (Kerber, 1992), while C4.5 employs local discretization. Fayyad (1997) writes that local methods of clustering (e.g. decision trees and association rules) promise the user a new way of thinking about data modelling in general.
Reference: <author> J. Dougherty, R. Kohavi and M. </author> <title> Sahami (1995). Supervised and unsupervised discretiza-tion of continuous features. </title> <booktitle> Proceedings of Twelfth International Conference on Machine Learning. </booktitle>
Reference-contexts: GID3* and O-BTree | another ID3-derived algorithm (Fayyad and Irani, 1994) | provide multiple intervals. There is therefore evidence to support the view that ID3 has limitations, particularly with regard to continuous data and the necessary discretization process. Discretization procedures fall into the categories of supervised/unsupervised and global/local <ref> (Dougherty, 1 Kohavi and Sahami, 1995) </ref>.
Reference: <author> U. M. </author> <title> Fayyad (1994). Branching on attribute values in decision tree generation. </title> <booktitle> In Proceedings of the Twelfth National Conference on Artificial Intelligence (AAAI-94), </booktitle> <pages> 601-606. </pages>
Reference-contexts: Further pruning techniques may be achieved by converting the decision tree into a rule set. Fayad et al. also refer to GID3* <ref> (Fayyad, 1994) </ref>, which was primarily developed to tackle the over-branching problem. <p> V h , &gt; V h ). While being precise, this method requires a sizable amount of computation, particularly if more than one continuous attribute is present in the data set. GID3* and O-BTree | another ID3-derived algorithm <ref> (Fayyad and Irani, 1994) </ref> | provide multiple intervals. There is therefore evidence to support the view that ID3 has limitations, particularly with regard to continuous data and the necessary discretization process. Discretization procedures fall into the categories of supervised/unsupervised and global/local (Dougherty, 1 Kohavi and Sahami, 1995).
Reference: <author> U. M. </author> <title> Fayyad (1997). Editorial. </title> <booktitle> Data Mining and Knowledge Discovery, </booktitle> <volume> 1 (3), </volume> <pages> 237-239. </pages>
Reference: <author> U. M. Fayyad, S. G. Djorgovski and N. </author> <title> Weir (1996). Automating the analysis and cataloging of sky surveys. </title> <editor> In U. M. Fayyad, G. Piatetsky-Shapiro, P. Smyth and R. Uthurusamy (Eds.), </editor> <title> it Advances In Knowledge Discovery and Data Mining., </title> <publisher> MIT Press. </publisher> <pages> 471-494. </pages>
Reference: <author> U. M. Fayyad and K. B. </author> <title> Irani (1994). The attribute selection problem in decision tree generation. </title> <booktitle> Proceedings of the Tenth National Conference on Artificial Intelligence (AAAI-92), </booktitle> <pages> 104-110. </pages>
Reference-contexts: Further pruning techniques may be achieved by converting the decision tree into a rule set. Fayad et al. also refer to GID3* <ref> (Fayyad, 1994) </ref>, which was primarily developed to tackle the over-branching problem. <p> V h , &gt; V h ). While being precise, this method requires a sizable amount of computation, particularly if more than one continuous attribute is present in the data set. GID3* and O-BTree | another ID3-derived algorithm <ref> (Fayyad and Irani, 1994) </ref> | provide multiple intervals. There is therefore evidence to support the view that ID3 has limitations, particularly with regard to continuous data and the necessary discretization process. Discretization procedures fall into the categories of supervised/unsupervised and global/local (Dougherty, 1 Kohavi and Sahami, 1995).
Reference: <author> I.W. Flockhart and N. J. </author> <title> Radcliffe (1996). A genetic algorithm-based approach to data mining. </title> <booktitle> Second International Conference in Knowledge Discovery and Data Mining (KDD-96), </booktitle> <pages> 299-302. </pages>
Reference: <author> K. M. Ho and P. D. </author> <title> Scott (1997). Zeta: A global method for discretization of continuous variables. </title> <booktitle> Proceedings of Third International Conference on Knowledge Discovery and Data Mining (KDD-97). </booktitle> <volume> 191 - 194. </volume>
Reference: <author> J. </author> <month> Hekanaho </month> <year> (1997). </year> <title> GA-based rule enhancement in concept learning. </title> <booktitle> Proceedings of Third International Conference on Knowledge Discovery and Data Mining (KDD-97). </booktitle> <address> 9 N. </address> <note> Hondo, </note> <author> K. Naruse and Y. </author> <title> Kakazu (1995). ID3-GA for the dependant attribute problem. </title> <booktitle> Information Processing Society of Japan. </booktitle>
Reference: <author> R. C. </author> <title> Holte (1993). Very simple classification rules perform well on most commonly used data sets. </title> <journal> Machine Learning, </journal> <volume> 11, </volume> <pages> 63-91. </pages>
Reference-contexts: Existing global methods include D-2 (Catlett, 1991), 1R <ref> (Holte, 1993) </ref> and ChiMerge (Kerber, 1992), while C4.5 employs local discretization. Fayyad (1997) writes that local methods of clustering (e.g. decision trees and association rules) promise the user a new way of thinking about data modelling in general.
Reference: <author> R. </author> <title> Kerber (1992). ChiMerge: Discretization of numeric attributes. </title> <booktitle> Proceedings of Tenth National Conference on Artificial Intelligence (AAAI-92), </booktitle> <pages> 123-128. </pages>
Reference-contexts: Existing global methods include D-2 (Catlett, 1991), 1R (Holte, 1993) and ChiMerge <ref> (Kerber, 1992) </ref>, while C4.5 employs local discretization. Fayyad (1997) writes that local methods of clustering (e.g. decision trees and association rules) promise the user a new way of thinking about data modelling in general.
Reference: <author> Z. Michalewics. </author> <year> (1996). </year> <title> Genetic Algorithms + Data Structures = Evolution Pograms. </title> <publisher> Springer Verlag, 3rd edition. </publisher>
Reference: <author> J. R. </author> <title> Quinlan (1986). The induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1, </volume> <pages> 81-106. </pages>
Reference: <author> J. R. </author> <title> Quinlan (1990). Probabilistic decision structures. </title> <editor> In Y. Kodratoff and R. S. Michal-ski (Eds.), </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach Vol. III, Maugan Kauf-mann. </booktitle> <pages> 63-111. </pages>
Reference: <author> P. H. </author> <title> Winston (1993). </title> <journal> Artificial Intelligence, </journal> <note> 3rd Edition. Addison Wesley, Chapters 21 and 25. 10 </note>
References-found: 16

