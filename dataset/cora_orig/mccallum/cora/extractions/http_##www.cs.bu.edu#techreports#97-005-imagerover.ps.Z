URL: http://www.cs.bu.edu/techreports/97-005-imagerover.ps.Z
Refering-URL: http://cs-www.bu.edu/techreports/Home.html
Root-URL: 
Title: on Content-based Access of Image and Video Libraries, 6/97. ImageRover: A Content-Based Image Browser for
Author: Stan Sclaroff, Leonid Taycher, and Marco La Cascia 
Keyword: Image databases, query by image content, content-based retrieval, world wide web search engines.  
Address: Boston, MA 02215  
Affiliation: Image and Video Computing Group Computer Science Department Boston University  
Note: BU CS TR97-005. Appears in Proc. IEEE Workshop  
Abstract: ImageRover is a search by image content navigation tool for the world wide web. To gather images expediently, the image collection subsystem utilizes a distributed fleet of WWW robots running on different computers. The image robots gather information about the images they find, computing the appropriate image decompositions and indices, and store this extracted information in vector form for searches based on image content. At search time, users can iteratively guide the search through the selection of relevant examples. Search performance is made efficient through the use of an approximate, optimized k-d tree algorithm. The system employs a novel relevance feedback algorithm that selects the distance metrics appropriate for a particular query. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Sclaroff. </author> <title> World wide web image search engines. </title> <booktitle> position paper presented at The NSF/ARPA Visual Information Management Workshop TR95-016, </booktitle> <address> Boston University, </address> <year> 1995. </year>
Reference-contexts: What is needed are equivalent web image search engines that crawl the web collecting information about the images they find, computing the appropriate image decompositions and indices, and storing this extracted information for searches based on image content <ref> [1] </ref>. Web image search engines could be applied profitably in many areas; e.g., in searching on-line catalogs of consumer goods and services, museums, libraries, and medical or other scientific data collections. Such engines might also be useful in the areas of erotica-on-demand, image copyright enforcement, forensics and intelligence gathering.
Reference: [2] <author> M. Flickner, H. Sawhney, W. Niblack, J. Ashley, Q. Huang, D. Dom, M. Gorkani, J. Hafner, D. Lee, D. Petkovic, D. Steele, and P. Yanker. </author> <title> Query by image and video content: </title> <booktitle> The QBIC system. IEEE Computer, </booktitle> <pages> pages 2330, </pages> <year> 1995. </year>
Reference-contexts: The resulting information is stored in vector form. At search time, users can select a weighted subset of these decompositions to be used for computing image similarity measurements <ref> [2; 3; 4] </ref>. This approach is taken in Im-ageRover, the system described in this paper. The resulting search tool provides a powerful method for data exploration or browsing. The user typically makes queries like find more things like this. In exploration mode, interactivity is essential or the user looses interest. <p> ImageRover employs a novel approach to this relevance feedback problem. 2.1 Related Work To date, there have been a number of query-by-image content (QBIC) demos available via the web; e.g., Virage [3], IBM QBIC <ref> [2] </ref>, Cypress [9], Photobook [10], VisualSeek [11], Jacob [12], etc. Nearly all systems include some form of color and texture-based image similarity measures. In addition, some systems provide search on image composition [3], shape [2; 10], faces [10], and/or groupings of colored blobs [13]. <p> Nearly all systems include some form of color and texture-based image similarity measures. In addition, some systems provide search on image composition [3], shape <ref> [2; 10] </ref>, faces [10], and/or groupings of colored blobs [13]. None of these systems provides a web search engine, in that each only operates on a local demo database of a few thousand images stored at the host web site. <p> The interface is presented via a Web browser as an HTML document. ImageRover employs a query by example paradigm along the lines of <ref> [2; 3; 10] </ref>. To get the search going, a set of randomly selected images are shown to the user. The user can ask the system for another set of random images, or he/she can mark example relevant images from those presented.
Reference: [3] <author> A. Gupta. </author> <title> Visual information retrieval technology: A virage perspective. </title> <type> TR 3A, </type> <institution> Virage Inc., </institution> <address> 177 Bovet Road, Suite 540, San Mateo, CA 94403, </address> <year> 1996. </year>
Reference-contexts: The resulting information is stored in vector form. At search time, users can select a weighted subset of these decompositions to be used for computing image similarity measurements <ref> [2; 3; 4] </ref>. This approach is taken in Im-ageRover, the system described in this paper. The resulting search tool provides a powerful method for data exploration or browsing. The user typically makes queries like find more things like this. In exploration mode, interactivity is essential or the user looses interest. <p> ImageRover employs a novel approach to this relevance feedback problem. 2.1 Related Work To date, there have been a number of query-by-image content (QBIC) demos available via the web; e.g., Virage <ref> [3] </ref>, IBM QBIC [2], Cypress [9], Photobook [10], VisualSeek [11], Jacob [12], etc. Nearly all systems include some form of color and texture-based image similarity measures. In addition, some systems provide search on image composition [3], shape [2; 10], faces [10], and/or groupings of colored blobs [13]. <p> have been a number of query-by-image content (QBIC) demos available via the web; e.g., Virage <ref> [3] </ref>, IBM QBIC [2], Cypress [9], Photobook [10], VisualSeek [11], Jacob [12], etc. Nearly all systems include some form of color and texture-based image similarity measures. In addition, some systems provide search on image composition [3], shape [2; 10], faces [10], and/or groupings of colored blobs [13]. None of these systems provides a web search engine, in that each only operates on a local demo database of a few thousand images stored at the host web site. <p> The interface is presented via a Web browser as an HTML document. ImageRover employs a query by example paradigm along the lines of <ref> [2; 3; 10] </ref>. To get the search going, a set of randomly selected images are shown to the user. The user can ask the system for another set of random images, or he/she can mark example relevant images from those presented.
Reference: [4] <author> R. Picard, T. P. Minka, and M. Szummer. </author> <title> Modeling user subjectivity in image libraries. </title> <booktitle> In Proc. ICIP, </booktitle> <year> 1996. </year>
Reference-contexts: The resulting information is stored in vector form. At search time, users can select a weighted subset of these decompositions to be used for computing image similarity measurements <ref> [2; 3; 4] </ref>. This approach is taken in Im-ageRover, the system described in this paper. The resulting search tool provides a powerful method for data exploration or browsing. The user typically makes queries like find more things like this. In exploration mode, interactivity is essential or the user looses interest.
Reference: [5] <author> C. Cunha, A. Bestavros, and M. Crovella. </author> <title> Characteristics of www client-based traces. </title> <address> TR-95-010, Boston U., </address> <year> 1995. </year>
Reference-contexts: The total number of documents on the WWW is estimated currently at 50-100 million, with 20-30% of the documents being images <ref> [5; 6] </ref>. The gargantuan size of a complete web image index presents challenges on a number of fronts: 1. Image Collection. In our experiments it has been observed that a single-threaded robot can traverse the web gathering images at an average rate of one image every 82 seconds.
Reference: [6] <author> C. Frankel, M. Swain, and V. Athitsos. Webseer: </author> <title> An image search engine for the world wide web. </title> <type> TR 96-14, </type> <institution> U. Chicago, </institution> <year> 1996. </year>
Reference-contexts: The total number of documents on the WWW is estimated currently at 50-100 million, with 20-30% of the documents being images <ref> [5; 6] </ref>. The gargantuan size of a complete web image index presents challenges on a number of fronts: 1. Image Collection. In our experiments it has been observed that a single-threaded robot can traverse the web gathering images at an average rate of one image every 82 seconds. <p> However, the algorithms developed in these and other QBIC systems serve as an excellent starting point for building WWW image search engines. ImageRover is joined by others in the first wave of image search engines: Yahoo's Image Surfer, Lycos media search tool, WebSeer <ref> [6] </ref>, and WebSeek [11]. Both Yahoo's Image Surfer (by Interpix Software) and WebSeek provide primarily keyword-based browsing tool for WWW images that are grouped together by category and subcategory. Example categories are: actors and actresses, animals, architecture, arts, comics, dance, rock, sports, supermodels, toys, etc. <p> Unfortunately, semi-automatic algorithms or entry of metadata is infeasible given that millions of images will populate an index that evolves daily. Two systems, Lycos and WebSeer extract keywords automatically from the image URL and possibly from captions imbedded in the document that contains the image. The WebSeer system <ref> [6] </ref> supplements keyword extraction with cues about image content: grayscale vs. color, image dimensions, file type and size, file date. In addition, their system includes a face detector that stores the number of faces and largest face size.
Reference: [7] <author> D. White and R. Jain. </author> <title> Algorithms and strategies for similarity retrieval. </title> <type> TR VCL-96-101, UCSD, </type> <year> 1996. </year>
Reference-contexts: This places severe constraints on the methods and metrics employed in searching for matches in the high-dimensional vector space of extracted image statistics for millions of images. As pointed out by White and Jain <ref> [7] </ref>, search time is actually dependent on the intrinsic dimensionality of the space. This intrinsic dimensionality can be approximated through a principal components analysis and a dimensionality reduction. Speed is further enhanced via use of an approximate k-nearest neighbors indexing scheme. 4. User Interface. <p> In the current system, the vectors have dimension 768. As pointed out by White and Jain <ref> [7] </ref>, the data has intrinsic dimension that is significantly less than this. Furthermore, while it may be reasonable to assume a Gaussian distribution in the space, the distribution of samples may not be distributed uniformly across all dimensions. <p> With disk caching, the performance should be almost the same as storing the data in memory <ref> [7; 22] </ref>. Due to the computational scaling properties of k-d search in high-dimensional spaces, expected performance of search in the optimized k-d tree is not better than brute-force nearest neighbor search if k is significantly greater than log (number of records in database).
Reference: [8] <author> S. Arya, D. M. Mount, N. S. Netanyahu, R. Silver-man, and A. Y. Wu. </author> <title> An optimal algorithm for approximate nearest neighbor seaching in fixed dimensions. </title> <booktitle> In Proc. ACM-SIAM Symp. on Discrete Alg., </booktitle> <pages> pages 573582, </pages> <year> 1994. </year>
Reference-contexts: Therefore, Im-ageRover employs an approximation factor in the optimized k-d search algorithm along the lines of <ref> [8] </ref>. The k-d tree bounds overlap ball test is modified to include an approximation factor *. The output of the approximate algorithm is a set of data points. <p> The output of the approximate algorithm is a set of data points. It has been proven that each of these output points is at a distance from the query point that is at most a factor (1 + *) greater than the true nearest neighbor distances <ref> [8] </ref>. Once initialized, the index server runs as a process separate from the database query server, possibly on a different computer. For each query, a client connects to the server to send the query data and then waits for the resulting k nearest neighbors. <p> Image statistics are extracted and stored as vectors in a high-dimensional space. The system employs dimensionality reduction via a PCA on the original higher-dimensional vector space and then stores the result in an optimized k-d tree. An approximate k-d search algorithm <ref> [8] </ref>, can allow the user to specify an approximation level for the nearest neighbors. The user can specify the level of approximation desired, allowing control of the tradeoff between speed and accuracy.
Reference: [9] <author> D. A. Forsyth, J. Malik, M. M. Fleck, H. Greenspan, T. Leung, S. Belongie, C. Carson, and C. Bregler. </author> <title> Finding pictures of objects in large collections of images. </title> <booktitle> In Proc. ECCV 96 Workshop on Object Rep., </booktitle> <year> 1996. </year>
Reference-contexts: ImageRover employs a novel approach to this relevance feedback problem. 2.1 Related Work To date, there have been a number of query-by-image content (QBIC) demos available via the web; e.g., Virage [3], IBM QBIC [2], Cypress <ref> [9] </ref>, Photobook [10], VisualSeek [11], Jacob [12], etc. Nearly all systems include some form of color and texture-based image similarity measures. In addition, some systems provide search on image composition [3], shape [2; 10], faces [10], and/or groupings of colored blobs [13].
Reference: [10] <author> A. Pentland, R. Picard, and S. Sclaroff. Photo-book: </author> <title> Tools for content-based manipulation of image databases. </title> <address> IJCV, 18(3):233254, </address> <year> 1996. </year>
Reference-contexts: ImageRover employs a novel approach to this relevance feedback problem. 2.1 Related Work To date, there have been a number of query-by-image content (QBIC) demos available via the web; e.g., Virage [3], IBM QBIC [2], Cypress [9], Photobook <ref> [10] </ref>, VisualSeek [11], Jacob [12], etc. Nearly all systems include some form of color and texture-based image similarity measures. In addition, some systems provide search on image composition [3], shape [2; 10], faces [10], and/or groupings of colored blobs [13]. <p> Nearly all systems include some form of color and texture-based image similarity measures. In addition, some systems provide search on image composition [3], shape <ref> [2; 10] </ref>, faces [10], and/or groupings of colored blobs [13]. None of these systems provides a web search engine, in that each only operates on a local demo database of a few thousand images stored at the host web site. <p> query-by-image content (QBIC) demos available via the web; e.g., Virage [3], IBM QBIC [2], Cypress [9], Photobook <ref> [10] </ref>, VisualSeek [11], Jacob [12], etc. Nearly all systems include some form of color and texture-based image similarity measures. In addition, some systems provide search on image composition [3], shape [2; 10], faces [10], and/or groupings of colored blobs [13]. None of these systems provides a web search engine, in that each only operates on a local demo database of a few thousand images stored at the host web site. <p> The interface is presented via a Web browser as an HTML document. ImageRover employs a query by example paradigm along the lines of <ref> [2; 3; 10] </ref>. To get the search going, a set of randomly selected images are shown to the user. The user can ask the system for another set of random images, or he/she can mark example relevant images from those presented.
Reference: [11] <author> J. R. Smith and S.-F. Chang. Visualseek: </author> <title> a fully automated content-based image query system. </title> <booktitle> In Proc. ACM Multimedia '96, </booktitle> <year> 1996. </year>
Reference-contexts: ImageRover employs a novel approach to this relevance feedback problem. 2.1 Related Work To date, there have been a number of query-by-image content (QBIC) demos available via the web; e.g., Virage [3], IBM QBIC [2], Cypress [9], Photobook [10], VisualSeek <ref> [11] </ref>, Jacob [12], etc. Nearly all systems include some form of color and texture-based image similarity measures. In addition, some systems provide search on image composition [3], shape [2; 10], faces [10], and/or groupings of colored blobs [13]. <p> However, the algorithms developed in these and other QBIC systems serve as an excellent starting point for building WWW image search engines. ImageRover is joined by others in the first wave of image search engines: Yahoo's Image Surfer, Lycos media search tool, WebSeer [6], and WebSeek <ref> [11] </ref>. Both Yahoo's Image Surfer (by Interpix Software) and WebSeek provide primarily keyword-based browsing tool for WWW images that are grouped together by category and subcategory. Example categories are: actors and actresses, animals, architecture, arts, comics, dance, rock, sports, supermodels, toys, etc.
Reference: [12] <author> E. Ardizzone and M. La Cascia. </author> <title> Automatic video database indexing and retrieval. </title> <booktitle> Multimedia Tools and Applications, </booktitle> <month> Jan. </month> <year> 1997. </year>
Reference-contexts: ImageRover employs a novel approach to this relevance feedback problem. 2.1 Related Work To date, there have been a number of query-by-image content (QBIC) demos available via the web; e.g., Virage [3], IBM QBIC [2], Cypress [9], Photobook [10], VisualSeek [11], Jacob <ref> [12] </ref>, etc. Nearly all systems include some form of color and texture-based image similarity measures. In addition, some systems provide search on image composition [3], shape [2; 10], faces [10], and/or groupings of colored blobs [13].
Reference: [13] <author> V. Ogle and Stonebreaker. Chabot: </author> <title> Retrieval from a relational database of images. </title> <journal> IEEE Computer, </journal> <volume> 28(2):4956, </volume> <year> 1995. </year>
Reference-contexts: Nearly all systems include some form of color and texture-based image similarity measures. In addition, some systems provide search on image composition [3], shape [2; 10], faces [10], and/or groupings of colored blobs <ref> [13] </ref>. None of these systems provides a web search engine, in that each only operates on a local demo database of a few thousand images stored at the host web site.
Reference: [14] <author> J. Mao and A. K. Jain. </author> <title> Texture classification and segmentation using multiresolution simultaneous au-toregressive models. </title> <journal> Pattern Recognition, </journal> <volume> 25(2):173 188, </volume> <year> 1992. </year>
Reference-contexts: Thus M = 2 in the current system. Efforts are currently underway to expand the system to include additional texture measures of multi-resolution simultaneous autoregressive models <ref> [14] </ref> and shift-invariant eigenvector models [15], and face detection and description using eigenfaces [16; 17]. Color distributions are calculated as follows.
Reference: [15] <author> R. Picard and T. Minka. </author> <title> Vision texture for annotation. Multimedia Systems, </title> <address> 3(3):314, </address> <year> 1995. </year>
Reference-contexts: Thus M = 2 in the current system. Efforts are currently underway to expand the system to include additional texture measures of multi-resolution simultaneous autoregressive models [14] and shift-invariant eigenvector models <ref> [15] </ref>, and face detection and description using eigenfaces [16; 17]. Color distributions are calculated as follows. Image color histograms are computed in the CIE L fl u fl v fl color space, which has been shown to correspond closely to the human perception of color [18]. <p> The histogram is then normalized to have unit sum. Once computed, the histogram must be circularly blurred to obviate aliasing effects and to allow for fuzzy matching of histograms during image search <ref> [15] </ref>. In practice, there must be a lower bound placed on the accepted orientation strength allowed to contribute to the distribution.
Reference: [16] <author> A. Pentland, B. Moghaddam, T. Starner, O. Oliyide, and M. Turk. </author> <title> View-based and modular eigenspaces for face recognition. </title> <booktitle> In Proc. CVPR, </booktitle> <pages> pp. 8491, </pages> <year> 1994. </year>
Reference-contexts: Thus M = 2 in the current system. Efforts are currently underway to expand the system to include additional texture measures of multi-resolution simultaneous autoregressive models [14] and shift-invariant eigenvector models [15], and face detection and description using eigenfaces <ref> [16; 17] </ref>. Color distributions are calculated as follows. Image color histograms are computed in the CIE L fl u fl v fl color space, which has been shown to correspond closely to the human perception of color [18].
Reference: [17] <author> M. Turk and A. Pentland. </author> <title> Eigenfaces for recognition. </title> <journal> J. Cognitive Neuroscience, </journal> <volume> 3(1):7186, </volume> <year> 1991. </year>
Reference-contexts: Thus M = 2 in the current system. Efforts are currently underway to expand the system to include additional texture measures of multi-resolution simultaneous autoregressive models [14] and shift-invariant eigenvector models [15], and face detection and description using eigenfaces <ref> [16; 17] </ref>. Color distributions are calculated as follows. Image color histograms are computed in the CIE L fl u fl v fl color space, which has been shown to correspond closely to the human perception of color [18].
Reference: [18] <author> U. Gargi and R. Kasturi. </author> <title> An evaluation of color histogram based methods in video indexing. </title> <booktitle> In Proc. of Int. Workshop on Image Databases and Multi-media Search, </booktitle> <year> 1996. </year>
Reference-contexts: Color distributions are calculated as follows. Image color histograms are computed in the CIE L fl u fl v fl color space, which has been shown to correspond closely to the human perception of color <ref> [18] </ref>.
Reference: [19] <author> J. Hafner, Harpreet Sawney, W. Equitz, M. Flickner, and W. Niblack. </author> <title> Efficient color histogram indexing for quadratic form distance functions. </title> <journal> IEEE T-PAMI, </journal> <volume> 1(7):729736, </volume> <year> 1995. </year>
Reference-contexts: For each of the subimages, the color distribution is then calculated using the histogram method <ref> [19] </ref>. Each histogram quantizes the color space into 64 (4 for each axis) bins. The over all histogram is normalized to have unit sum and then blurred. The texture direction distribution is calculated using steerable pyramids [20; 21].
Reference: [20] <author> W. Freeman and E. H. Adelson. </author> <title> The Design and Use of Steerable Filters. </title> <journal> IEEE T-PAMI, </journal> <volume> 13(9):891906, </volume> <year> 1991. </year>
Reference-contexts: Each histogram quantizes the color space into 64 (4 for each axis) bins. The over all histogram is normalized to have unit sum and then blurred. The texture direction distribution is calculated using steerable pyramids <ref> [20; 21] </ref>. For this application, a steer-able pyramid of 4 levels was found to be sufficient. At each level, texture direction and strength at each pixel is calculated using the outputs of seven X-Y separable, steerable quadrature pair basis filters. <p> The separable basis set and interpolation functions for the second derivative of a Gaussian were implemented directly using the nine-tap formulation provided in Appendix H (tables IV and VI) of <ref> [20] </ref>. The resulting basis is comprised of three G 2 filters to steer the second derivative of a Gaussian, and four H 2 filters to steer the Hilbert transform of the second derivative of a Gaussian. <p> the Fourier series for oriented energy E G 2 H 2 as a function of angle : E G 2 H 2 = C 1 + C 2 cos (2) + C 3 sin (2); (8) where the terms C 1 ,C 2 , C 3 are as prescribed in <ref> [20] </ref>, Ap pendix I. Dominant orientation angle d and the orientation strength m at a given pixel are calculated via the following formulae: d = 2 m = C 2 3 : (10) Orientation histograms are then computed for each level in the pyramid.
Reference: [21] <author> M. Gorkani and R. </author> <title> Picard. Texture orientation for sorting photos at a glance. </title> <booktitle> In Proc. IEEE CVPR, </booktitle> <year> 1994. </year>
Reference-contexts: Each histogram quantizes the color space into 64 (4 for each axis) bins. The over all histogram is normalized to have unit sum and then blurred. The texture direction distribution is calculated using steerable pyramids <ref> [20; 21] </ref>. For this application, a steer-able pyramid of 4 levels was found to be sufficient. At each level, texture direction and strength at each pixel is calculated using the outputs of seven X-Y separable, steerable quadrature pair basis filters.
Reference: [22] <author> J. H. Friedman, J. H. Bentley, and R. A. Finkel. </author> <title> An algorithm for finding best matches in logarithmic expected time. </title> <journal> ACM Trans. on Math. Software, </journal> <volume> 3(3):209226, </volume> <year> 1977. </year>
Reference-contexts: At startup, the server first performs a dimensionality reduction, and then builds an optimized k-d tree <ref> [22] </ref>, maintaining the data structure in main memory if possible. If it is not possible to store the complete data structure in memory, then the vectors are organized in a file using the same disk block for all the records belonging to the same bucket. <p> With disk caching, the performance should be almost the same as storing the data in memory <ref> [7; 22] </ref>. Due to the computational scaling properties of k-d search in high-dimensional spaces, expected performance of search in the optimized k-d tree is not better than brute-force nearest neighbor search if k is significantly greater than log (number of records in database).
Reference: [23] <author> R. O. Duda and P. E. Hart. </author> <title> Pattern Recognition and Scene Analysis. </title> <publisher> John Wiley, </publisher> <address> New York, </address> <year> 1973. </year> <month> 8 </month>
Reference-contexts: In this particular example, ImageRover ranked five more sport team photographs as closest to the user-provided examples. The other returned images share similar color and orientation distributions. It is difficult to determine in advance which ~ L m distance metric is best suited for a particular similarity detection task <ref> [23] </ref>. Therefore, our system selects the appropriate ~ L m metric each time a query is made, based on relevance feedback from the user.
References-found: 23

