URL: http://www.cse.ogi.edu/CSLU/publications/eurospeech97/johans.ps
Refering-URL: http://www.cse.ogi.edu/CSLU/publications/publications.html
Root-URL: http://www.cse.ogi.edu
Title: CSLUsh: AN EXTENDIBLE RESEARCH ENVIRONMENT  
Author: Johan Schalkwyk, Jacques de Villiers, Sarel van Vuuren and Pieter Vermeulen 
Address: 20000 N.W. Walker Road, P.O. Box 91000, Portland, OR 97291-1000, USA  
Affiliation: Center for Spoken Language Understanding, Oregon Graduate Institute of Science and Technology,  
Abstract: The CSLU shell (CSLUsh), is a collection of modular building blocks which aim to provide the user with a powerful, extendible, research, development and implementation environment. Implemented in C with standardized Tcl/Tk interfaces to provide a scripting and visualization environment, it allows a flexible cast for both research algorithms and system deployment. This shell is the architecture on which the CSLU Toolkit is built and may be downloaded for non-commercial use from http://www.cse.ogi.edu/CSLU/toolkit. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M.Fanty, J.Pochmara, and R.A.Cole, </author> <title> "An interactive environment for speech recognition research," </title> <booktitle> Proceedings of the International Conference on Spoken Language Processing, </booktitle> <month> October </month> <year> 1992. </year>
Reference-contexts: A single transparent research and implementation tool would stimulate research by creating an environment in which ideas could be shared by the exchange of code without consideration of issues such as cross platform portability. Our solution to this problem built on previous efforts <ref> [1] </ref>, was to implement real-time systems and to let researchers share in, and incorporate the latest advances effortlessly. Great care was taken to design all of the core components to operate in as efficient and consistent a manner as possible, with special attention given to modularity, portability and extendibility. <p> process of building a recognizer in an easily readable and understandable format. prototype mono numstate 5 mixtures 3 transp 0.000 1.000 0.000 0.000 0.000 0.000 0.600 0.400 0.000 0.000 0.000 0.000 0.000 0.000 0.000; 0.000 0.500 0.500 define mono &lt;w&gt; <ah> <n> <sil>; define onestate &lt;sp&gt;; tie &lt;sil&gt;.state [2] <sp>.state <ref> [1] </ref>; prototype onestate numstate 3 mixtures 3 transp All of the above mentioned functionality is integrated within the CSLUsh environment. A stand-alone application such as HMM embedded training is therefore just another CSLUsh script which reads a set of predefined input files and performs embedded training.
Reference: [2] <author> J. K. Ousterhout, </author> <title> Tcl and the Tk Toolkit. </title> <publisher> Addison-Wesley, </publisher> <year> 1994. </year>
Reference-contexts: In addition, implementation considerations such as pipelining, networked sharing of computing and input/output resources for real time systems have been addressed. Implemented in Tcl/Tk <ref> [2] </ref> and C, CSLUsh supports a wide range of research activities, including data capture and analysis, corpus development, research in multi-lingual recognition and understanding, dialogue design [3], speaker recognition and language identification, among others. <p> documents the process of building a recognizer in an easily readable and understandable format. prototype mono numstate 5 mixtures 3 transp 0.000 1.000 0.000 0.000 0.000 0.000 0.600 0.400 0.000 0.000 0.000 0.000 0.000 0.000 0.000; 0.000 0.500 0.500 define mono &lt;w&gt; <ah> <n> <sil>; define onestate &lt;sp&gt;; tie &lt;sil&gt;.state <ref> [2] </ref> <sp>.state [1]; prototype onestate numstate 3 mixtures 3 transp All of the above mentioned functionality is integrated within the CSLUsh environment. A stand-alone application such as HMM embedded training is therefore just another CSLUsh script which reads a set of predefined input files and performs embedded training.
Reference: [3] <author> S.Sutton, D.Novick, R.Cole, P.Vermeulen, J.H.de Vil-liers, J.Schalkwyk, and M.Fanty, </author> <title> "Building 10000 spoken dialogue systems," </title> <booktitle> Proceedings of the International Conference on Spoken Language Processing, </booktitle> <month> October </month> <year> 1996. </year>
Reference-contexts: Implemented in Tcl/Tk [2] and C, CSLUsh supports a wide range of research activities, including data capture and analysis, corpus development, research in multi-lingual recognition and understanding, dialogue design <ref> [3] </ref>, speaker recognition and language identification, among others. CSLUsh has also been used to implement real-time speech recognition systems capable of handling multiple telephone conversations [4]. In this paper we describe the architectural foundation of the CSLU shell. Section 2 describes the software architec ture.
Reference: [4] <author> R.A.Cole, D.G.Novick, P.J.E.Vermeulen, S.Sutton, M.Fanty, L.F.A.Wessels, J.H.de Villiers, J.Schalkwyk, B.Hansen, and D.Burnett, </author> <title> "Experiments with a spoken dialogue system for taking the u.s. census," </title> <journal> Free Speech Journal, </journal> <note> http://www.cse.ogi.edu/CSLU/fsj/html, vol. I, </note> <year> 1997. </year>
Reference-contexts: CSLUsh has also been used to implement real-time speech recognition systems capable of handling multiple telephone conversations <ref> [4] </ref>. In this paper we describe the architectural foundation of the CSLU shell. Section 2 describes the software architec ture. Section 3 discusses each of the core components. 2.
Reference: [5] <author> S.van Vuuren and H.Hermansky, </author> <title> "Data driven design of rasta-like filters," </title> <booktitle> this proceedings, </booktitle> <year> 1997. </year>
Reference-contexts: Another module provides robust speech/non-speech detection by adaptively tracking the noise floor in a speech signal. A further module provides uni- and multi-dimensional FIR filtering (in time and frequency) as well as LDA-based analysis <ref> [5] </ref>. Modeling Modeling includes neural networks (classifiers and regression models), vector quantization, gaussian mixture modeling and hidden Markov modeling (CSLUhmm). These modeling techniques are to a large extent interchangeable.
Reference: [6] <author> Y.Yan, M.Fanty, and R.Cole, </author> <title> "Speech recognition using neural networks with forward-backward probability generated targets," </title> <booktitle> Proceedings of the International Conference on Acoustic, Speech and Signal Processing, </booktitle> <volume> vol. IV, </volume> <pages> pp. 3241-3244, </pages> <year> 1997. </year>
Reference-contexts: Modeling Modeling includes neural networks (classifiers and regression models), vector quantization, gaussian mixture modeling and hidden Markov modeling (CSLUhmm). These modeling techniques are to a large extent interchangeable. For example the embedded reestimation algorithm provided by the main HMM library may also be used to reestimate neural network targets <ref> [6] </ref>. Parameter tying may be done at either the model, state, mixture component, mean and/or covariance level.
Reference: [7] <author> F.Alleva, X.Huang, and M.Hwang, </author> <title> "An improved search algorithm using incremental knowledge for continuous speech recognition," </title> <booktitle> Proceedings of the International Conference on Acoustic, Speech and Signal Processing, </booktitle> <volume> vol. II, </volume> <pages> pp. 307-310, </pages> <year> 1993. </year>
Reference-contexts: Currently these algorithms are being used to build the OGI large vocabulary recognizer and the OGI speaker recognition system. Decoding Decoding incorporates Viterbi decoders for word spotting and finite state grammars, within the CSLUsh framework. Currently under development is a three pass (Forward, Backward, A*) search <ref> [7] </ref> which works with HMMs and Neural Network hybrids interchangeably. In this implementation the Backward/A* search is used as a framework in which to incorporate N -gram language models. For large vocabulary tasks (5k 65k words) we are also working on a dedicated decoder based on pronunciation prefix trees. 4.
References-found: 7

