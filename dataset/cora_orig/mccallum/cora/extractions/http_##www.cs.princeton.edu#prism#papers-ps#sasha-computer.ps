URL: http://www.cs.princeton.edu/prism/papers-ps/sasha-computer.ps
Refering-URL: http://www.cs.princeton.edu/prism/html/all-papers.html
Root-URL: http://www.cs.princeton.edu
Title: "Applications for Shared-Memory Multiprocessors" Parallel Probabilistic Inference on Cache-coherent Multiprocessors  
Author: Alexander V. Kozlov Jaswinder Pal Singh 
Keyword: shared-address-space machines, expert systems, probabilistic inference, exact probabilistic inference, parallel programming, task scheduling, data locality.  
Address: Stanford, CA 94305-4090 Princeton, NJ 08544  
Affiliation: Department of Applied Physics Department of Computer Science Stanford University Princeton University  
Note: Submitted to the special issue of IEEE Computers  
Email: email: alexvk@cs.stanford.edu email: jps@cs.princeton.edu  
Phone: phone: (415) 725-8814 phone: (609) 258 5329 fax: (415) 725-1449 fax: (609) 258 1771  
Date: (December 1996)  
Abstract: Probabilistic inference is a technique used in expert systems for reasoning under uncertainty. A typical inference task is to determine the probability of some events (say diseases) given evidence about other events (say findings). Inference is conveniently represented as the propagation of evidence in a graph called a belief network. Probabilistic inference is computationally very expensive (NP-hard in general), but is very important both in itself and to calibrate less expensive approximate schemes. It is therefore natural to explore speeding up inference exploiting parallelism. Probabilistic inference affords concurrency at two different levels and presents interesting tradeoffs between load balance and data locality. We present two parallel implementations of probabilistic inference in belief networks. One uses a static assignment of work to processors but sacrifices some available concurrency, while the other uses dynamic assignment to obtain both forms of concurrency but sacrifices some types of data locality. We provide detailed performance measurements and analysis for both implementations on two cache-coherent shared-address-space multiprocessors: a 32-processor Stanford DASH multiprocessor with physically distributed main memory, and a 16-processor bus based SGI Challenge XL with centralized main memory. We find that the static assignment scheme produces better results uniformly over all input networks on both machines since it has better locality properties. To understand scalability with problem size, number of processors and cache organization, we perform software simulations of the multiprocessor execution and provide a detailed characterization of the spatial and temporal data locality. We find that temporal locality is low due to both large size of the working sets and low reuse of data, while spatial locality is high. Our results suggest that probabilistic inference is both successful on moderate-scale cache-coherent machines, as well as a good benchmark for testing the memory and communication architectures of these machines due to its emphasis on the data locality. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. T. Cox. </author> <title> Probability, frequency, and reasonable expectation. </title> <journal> Am. Jour. Phys., </journal> <volume> 14:1 - 13, </volume> <year> 1946. </year>
Reference-contexts: In Section 4 we briefly describe the Stanford DASH and SGI Challenge 1 By self-consistency we mean that a robot using this technique will be consistent in its actions. As was shown <ref> [1, 2] </ref>, any other self-consistent technique has to be isomorphic to the probabilistic method. For a more detailed definition of consistency and the proofs see [2]. 1 Submitted to the special issue of IEEE Computers (December 1996) "Applications for Shared-Memory Multiprocessors" XL multiprocessors.
Reference: [2] <author> Edward T. Jaynes. </author> <title> Probability theory: </title> <journal> The logic of science. </journal> <note> Unpublished, but publicly available through ftp://bayes.wustl.edu/Jaynes.book, </note> <year> 1995. </year>
Reference-contexts: In Section 4 we briefly describe the Stanford DASH and SGI Challenge 1 By self-consistency we mean that a robot using this technique will be consistent in its actions. As was shown <ref> [1, 2] </ref>, any other self-consistent technique has to be isomorphic to the probabilistic method. For a more detailed definition of consistency and the proofs see [2]. 1 Submitted to the special issue of IEEE Computers (December 1996) "Applications for Shared-Memory Multiprocessors" XL multiprocessors. <p> As was shown [1, 2], any other self-consistent technique has to be isomorphic to the probabilistic method. For a more detailed definition of consistency and the proofs see <ref> [2] </ref>. 1 Submitted to the special issue of IEEE Computers (December 1996) "Applications for Shared-Memory Multiprocessors" XL multiprocessors. In Section 5 we discuss the available parallelism, and in Section 6 possible parallelization strategies. In Section 7 we provide the results of our performance measurements and locality characterization.
Reference: [3] <author> Alexander V. Kozlov and Jaswinder Pal Singh. </author> <title> Approximate probabilistic inference in Bayesian belief networks based on sensitivities. </title> <note> submitted to the Journal of Artificial Intelligence Research, </note> <year> 1995. </year>
Reference-contexts: Since the accuracy and effectiveness of these methods are unclear, performing exact probabilistic inference on realistic problems is important not only in itself, but also to evaluate approximate methods by comparison. Moreover, many structural features of exact inference algorithms are also features of approximate inference techniques <ref> [3] </ref>, so many of the results obtained for speeding up exact inference can carry over to speeding up approximate inference as well. Parallelism is a promising avenue for speeding up both types of inference.
Reference: [4] <author> Edward Eric Rothberg. </author> <title> Exploiting the memory hierarchy in sequential and parallel sparse Cholesky factorization. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <year> 1993. </year>
Reference-contexts: Probabilistic inference is a very data-intensive application. Unlike many scientific applications for high performance computing, where the number of operations grows as O (n 3=2 ) (as in many linear algebra algorithms <ref> [4] </ref>) or as O (n log n) with large constants (as in hierarchical N-body methods [5]), where n is the size of the data set, the number of operations to perform probabilistic inference is only a small constant multiple of the data set size (both the data set size and the
Reference: [5] <author> Jaswinder Pal Singh. </author> <title> Parallel hierarchical N-body methods and their implications for multiprocessors. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <year> 1993. </year>
Reference-contexts: Probabilistic inference is a very data-intensive application. Unlike many scientific applications for high performance computing, where the number of operations grows as O (n 3=2 ) (as in many linear algebra algorithms [4]) or as O (n log n) with large constants (as in hierarchical N-body methods <ref> [5] </ref>), where n is the size of the data set, the number of operations to perform probabilistic inference is only a small constant multiple of the data set size (both the data set size and the number of operations can grow exponentially with the number of nodes in the belief network).
Reference: [6] <author> S. S. Lauritzen and D. J. Spiegelhalter. </author> <title> Local computations with probabilities on graphical structures and their application to expert systems. </title> <journal> Journal of the Royal Statistical Society, </journal> <volume> B 50:253 - 258, </volume> <year> 1988. </year>
Reference-contexts: All nodes are binary (can have only two possible values). the original network can appear in several adjoining cliques in the join tree. All conditional probabilities in the original networks are wholly contained within one of the cliques. For example, Fig. 1 shows the well-known "Asia" network <ref> [6] </ref>, all of whose nodes have two possible values. For example, the node x F ("Smoking") has values "Smokes" and "Doesn't smoke". <p> Thus, in the well-known Lauritzen-Spiegelhalter (LS) algorithm <ref> [6] </ref>, as in most other algorithms for probabilistic inference, a general network is first converted to a join tree and the summation is represented as a propagation of messages in this tree. <p> The join tree nodes are traditionally called cliques since they were obtained as completely interconnected subsets, or cliques, of a moralized (with interconnected parents) and triangulated network <ref> [6] </ref>. One of the possible join trees for the "Asia" network is shown in Fig. 2. A simple node from the original network can appear in several adjacent join tree nodes. <p> The joint probability summation algorithm presented here represents the structure of computations in the modern algorithms for probabilistic inference. The two most popular algorithms are the Lauritzen-Spiegelhalter (LS) algorithm <ref> [6] </ref> and the Symbolic Probabilistic Inference (SPI) algorithm [7] based on the optimal factoring approach described above.
Reference: [7] <author> Zhaoyu Li and Bruce D'Ambrosio. </author> <title> Efficient inference in Bayes networks as a combinatorial optimization problem. </title> <journal> International Journal of Approximate Reasoning, </journal> <volume> 11(1):55 - 81, </volume> <year> 1994. </year>
Reference-contexts: A ) or p (x F ) as conditional probabilities conditioned on an empty set of nodes. 2 Submitted to the special issue of IEEE Computers (December 1996) "Applications for Shared-Memory Multiprocessors" Probabilistic inference in a belief network can be most generally understood as an evaluation of joint probability sums <ref> [7] </ref>. Let X i be the set of query nodes, the nodes whose probabilities we want to obtain. <p> The joint probability summation algorithm presented here represents the structure of computations in the modern algorithms for probabilistic inference. The two most popular algorithms are the Lauritzen-Spiegelhalter (LS) algorithm [6] and the Symbolic Probabilistic Inference (SPI) algorithm <ref> [7] </ref> based on the optimal factoring approach described above.
Reference: [8] <author> Alexander V. Kozlov and Jaswinder Pal Singh. Sensitivities: </author> <title> an alternative to conditional probabilities for Bayesian belief networks. </title> <editor> In Philippe Besnard and Steve Hanks, editors, </editor> <booktitle> Proceedings of the Eleventh Conference on Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 376 - 385. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1995. </year>
Reference-contexts: It is based on a lazy algorithm that updates the join tree in depth-first search order <ref> [8] </ref>. It is more economical than the original LS algorithm in that it updates only a part of the tree for simple queries|given precomputation of the clique potentials|as opposed to the whole tree, and can perform incremental probabilistic inference. 4 Clique potentials are updated only if necessary.
Reference: [9] <author> Alexander V. Kozlov and Jaswinder Pal Singh. </author> <title> A parallel Lauritzen-Spiegelhalter algorithm for probabilistic inference. </title> <booktitle> In Proceedings of the Supercomputing'94 conference, pages 320 - 329, held in November 1994, </booktitle> <address> Washinton, DC, 1994. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: Since different queries are likely to require different computation time, the experimental results in this paper are for the complete update of the join tree. The uniprocessor program we constructed is substantially faster than the program for the Lauritzen-Spiegelhalter algorithm that we originally obtained and used in <ref> [9] </ref>. The speedup is largely due to the optimization of two bottlenecks in the original program. First, the original program spent most of its execution time evaluating the mapping between clique potentials and message entries, i.e. determining which potentials should be multiplied by which incoming message entries. <p> Thus, there are no "remote" misses and no data placement problem, and communication is not much more expensive then capacity misses. 5 Available Parallelism There are two types of parallelism available in belief networks: topological and in-clique <ref> [9] </ref>. Topological parallelism is due to the fact that computations in cliques that do not have an ancestor-descendent relationship in the join tree are independent. <p> It represents an optimized version of the dynamic scheduler we used in our parallel Lauritzen-Spiegelhalter algorithm implementation <ref> [9] </ref>. To allow more concurrency at the topological level, we subdivide the update of one clique potentials by another clique potentials into two stages. <p> These are the same networks that we used in <ref> [9] </ref>. 7 Submitted to the special issue of IEEE Computers (December 1996) "Applications for Shared-Memory Multiprocessors" Table 1: Parameters of the networks we used to test the multiprocessor implementation. n number of nodes, e average number of edges per node, v number of values per node, c number of cliques, l
Reference: [10] <author> Dan Lenoski, James Laudon, Kourosh Gharachorloo, Anoop Gupta, and John Hennessy. </author> <title> The directory-based cache coherence protocol for the DASH multiprocessor. </title> <booktitle> In Proceedings of the 17th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 148 - 159, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: Our parallel programs are written in C using the parmacs macro package from Argonne National Laboratories for parallelism constructs. 4.1 The Stanford DASH Multiprocessor The DASH machine <ref> [10] </ref> is an experimental multiprocessor built at Stanford University. The machine we used has 32 processors (33 MHz clock speed) organized in 8 clusters. 5 A cluster comprises 4 MIPS R3000 processors and 32MB local memory connected by a shared bus, and clusters are connected together in a mesh network.
Reference: [11] <author> Steve Cameron Woo, Moriyoshi Ohara, Evan Torrie, Jaswinder Pal Singh, and Anoop Gupta. </author> <title> The SPLASH-2 programs: Characterization and methodological considerations. </title> <booktitle> In Proceedings of the 22nd Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 24 - 36, </pages> <year> 1995. </year> <month> 13 </month>
Reference-contexts: It is very flexible and divides cache miss rates according to a classification described in <ref> [11] </ref>. To analyze temporal locality, we measure the working sets of the program by plotting the miss rate versus the size of the per-processor cache used in the simulations, assuming a sixteen processor execution and 4-way set-associative caches with a 64-byte cache line size.
References-found: 11

