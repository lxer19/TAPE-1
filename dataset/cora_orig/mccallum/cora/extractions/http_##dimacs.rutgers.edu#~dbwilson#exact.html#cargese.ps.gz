URL: http://dimacs.rutgers.edu/~dbwilson/exact.html/cargese.ps.gz
Refering-URL: http://dimacs.rutgers.edu/~dbwilson/exact.html/
Root-URL: http://www.cs.rutgers.edu
Email: E-mail: SOKAL@NYU.EDU  
Phone: 4  
Title: Monte Carlo Methods in Statistical Mechanics: Foundations and New Algorithms  "Functional Integration: Basics and Applications"  
Author: Alan D. Sokal 
Date: September 1996  
Note: Lectures at the Cargese Summer School on  
Address: New York University  New York, NY 10003 USA  
Affiliation: Department of Physics  Washington Place  
Abstract: These notes are an updated version of lectures given at the Cours de Troisieme Cycle de la Physique en Suisse Romande (Lausanne, Switzerland) in June 1989. We thank the Troisieme Cycle de la Physique en Suisse Romande and Professor Michel Droz for kindly giving permission to reprint these notes. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> N. Bakhvalov, Methodes Numeriques (MIR, Moscou, </author> <year> 1976), </year> <title> Chapter 5. 41 Note Added 1996: See also [137], which recovers the bound (8.49) by a much simpler argument using the Poincare inequality [131]. 42 Note Added 1996: There has been great progress on this problem in recent years: </title> <note> see [138, 139, 140, 141, 142, 143] and references cited therein. y Deceased. 67 </note>
Reference-contexts: Firstly, there are deterministic methods better than Simpson's rule; and there are also sophisticated Monte Carlo methods whose asymptotic behavior (on smooth integrands) behaves as n p with p strictly greater than 1=2 <ref> [1, 2] </ref>. Secondly, for all these algorithms (except standard Monte Carlo), the asymptotic behavior as n ! 1 may be irrelevant in practice, because it is achieved only at ridiculously large values of n. <p> In this case, the spectrum of 6 Our discussion of this topic in [12] is incorrect. 7 For the physical significance of this term, see Kemeny and Snell [4, section 5.3] or Iosifescu [5, section 4.5]. 8 P is real and lies in the closed interval <ref> [1; 1] </ref>; we define min = inf spec (P j n 1 ? ) (2.28) max = sup spec (P j n 1 ? ) (2.29) From (2.12) we have t exp = log max [j min j; max ] For many purposes, only the spectrum near +1 matters, so it <p> But this is easily arranged: just set a xy = F y p (0) x p xy ; (4.4) where F : [0; +1] ! <ref> [0; 1] </ref> is any function satisfying F (z) = z for all z: (4.5) The choice suggested by Metropolis et al. is F (z) = min (z; 1) ; (4.6) this is the maximal function satisfying (4.5). <p> That is, we choose a random number r uniformly distributed on <ref> [0; 1] </ref>, and we accept the proposal if r e fiE . But there is nothing special about P (0) being symmetric; any proposal matrix P (0) is perfectly legitimate, and the Metropolis-Hastings procedure is defined quite generally by (4.4). <p> Now P acts naturally on functions (observables) according to (P f )(x) y In particular, when acting on the space l 2 () of -square-integrable functions, the operator P is a self-adjoint contraction. Its spectrum therefore lies in the interval <ref> [1; 1] </ref>. Moreover, P has an eigenvalue 1 with eigenvector equal to the constant function 1. Let be the orthogonal projector in l 2 () onto the constant functions.
Reference: [2] <author> J.M. </author> <title> Hammersley and D.C. Handscomb, Monte Carlo Methods (Methuen, </title> <address> Lon--don, </address> <year> 1964), </year> <note> Chapter 5. </note>
Reference-contexts: Firstly, there are deterministic methods better than Simpson's rule; and there are also sophisticated Monte Carlo methods whose asymptotic behavior (on smooth integrands) behaves as n p with p strictly greater than 1=2 <ref> [1, 2] </ref>. Secondly, for all these algorithms (except standard Monte Carlo), the asymptotic behavior as n ! 1 may be irrelevant in practice, because it is achieved only at ridiculously large values of n. <p> How is this to be done? Monte Carlo methods can be classified as static or dynamic. Static methods are those that generate a sequence of statistically independent samples from the desired probability distribution . These techniques are widely used in Monte Carlo numerical integration in spaces of not-too-high dimension <ref> [2] </ref>. But they are unfeasible for most applications in statistical physics and quantum field theory, where is the Gibbs measure of some rather complicated system (extremely many coupled degrees of freedom).
Reference: [3] <author> W.W. Wood and J.J. </author> <title> Erpenbeck, </title> <journal> Ann. Rev. Phys. Chem. </journal> <volume> 27, </volume> <month> 319 </month> <year> (1976). </year>
Reference-contexts: But such systems are precisely the ones of greatest interest in statistical mechanics and quantum field theory! It is appropriate to close this introduction with a general methodological observation, ably articulated by Wood and Erpenbeck <ref> [3] </ref>: : : : these [Monte Carlo] investigations share some of the features of ordinary experimental work, in that they are susceptible to both statistical and systematic errors. With regard to these matters, we believe that papers should meet much the same standards as are normally required for experimental investigations.
Reference: [4] <author> J. G. Kemeny and J. L. Snell, </author> <title> Finite Markov Chains (Springer, </title> <address> New York, </address> <year> 1976). </year>
Reference-contexts: process) with state space S is a sequence of S-valued random variables X 0 ; X 1 ; X 2 ; : : : such that successive transitions X t ! X t+1 are statistically independent ("the future depends on the past only 2 The books of Kemeny and Snell <ref> [4] </ref> and Iosifescu [5] are excellent references on the theory of Markov chains with finite state space. At a somewhat higher mathematical level, the books of Chung [6] and Nummelin [7] deal with the cases of countable and general state space, respectively. 3 through the present"). <p> In the physics literature, and in the mathematics literature on Markov chains with finite state space, "ergodic" is typically used as a synonym for "irreducible" <ref> [4, Section 2.4] </ref> [5, Chapter 4]. <p> In this case, the spectrum of 6 Our discussion of this topic in [12] is incorrect. 7 For the physical significance of this term, see Kemeny and Snell <ref> [4, section 5.3] </ref> or Iosifescu [5, section 4.5]. 8 P is real and lies in the closed interval [1; 1]; we define min = inf spec (P j n 1 ? ) (2.28) max = sup spec (P j n 1 ? ) (2.29) From (2.12) we have t exp =
Reference: [5] <author> M. Iosifescu, </author> <title> Finite Markov Processes and Their Applications (Wiley, </title> <address> Chichester, </address> <year> 1980). </year>
Reference-contexts: space S is a sequence of S-valued random variables X 0 ; X 1 ; X 2 ; : : : such that successive transitions X t ! X t+1 are statistically independent ("the future depends on the past only 2 The books of Kemeny and Snell [4] and Iosifescu <ref> [5] </ref> are excellent references on the theory of Markov chains with finite state space. At a somewhat higher mathematical level, the books of Chung [6] and Nummelin [7] deal with the cases of countable and general state space, respectively. 3 through the present"). <p> In the physics literature, and in the mathematics literature on Markov chains with finite state space, "ergodic" is typically used as a synonym for "irreducible" [4, Section 2.4] <ref> [5, Chapter 4] </ref>. <p> In this case, the spectrum of 6 Our discussion of this topic in [12] is incorrect. 7 For the physical significance of this term, see Kemeny and Snell [4, section 5.3] or Iosifescu <ref> [5, section 4.5] </ref>. 8 P is real and lies in the closed interval [1; 1]; we define min = inf spec (P j n 1 ? ) (2.28) max = sup spec (P j n 1 ? ) (2.29) From (2.12) we have t exp = log max [j min j;
Reference: [6] <author> K. L. Chung, </author> <title> Markov Chains with Stationary Transition Probabilities, 2 nd ed. </title> <publisher> (Springer, </publisher> <address> New York, </address> <year> 1967). </year>
Reference-contexts: At a somewhat higher mathematical level, the books of Chung <ref> [6] </ref> and Nummelin [7] deal with the cases of countable and general state space, respectively. 3 through the present"). More precisely, a Markov chain is specified by two ingredients: * The initial distribution ff. <p> Moreover, under the conditions of this theorem much more can be proven | for example, a strong law of large numbers, a central limit theorem, and a law of the iterated logarithm. For statements and proofs of all these theorems, we refer the reader to Chung <ref> [6] </ref>. We can now see how to set up a dynamic Monte Carlo method for generating samples from the probability distribution .
Reference: [7] <author> E. Nummelin, </author> <title> General Irreducible Markov Chains and Non-Negative Operators (Cambridge Univ. </title> <publisher> Press, </publisher> <address> Cambridge, </address> <year> 1984). </year>
Reference-contexts: At a somewhat higher mathematical level, the books of Chung [6] and Nummelin <ref> [7] </ref> deal with the cases of countable and general state space, respectively. 3 through the present"). More precisely, a Markov chain is specified by two ingredients: * The initial distribution ff. <p> However, in the mathematics literature on Markov chains with general state space, "ergodic" is used as a synonym for "irreducible, aperiodic and positive Harris recurrent" <ref> [7, p. 114] </ref> [8, p. 169]. 5 and unnormalized autocorrelation function 4 C ff (t) hf s f s+t i 2 = x;y xy x y ] f (y): The normalized autocorrelation function is then ff (t) C ff (t)=C ff (0): (2.9) Typically ff (t) decays exponentially (~ e jtj=t
Reference: [8] <author> D. Revuz, </author> <title> Markov Chains (North-Holland, </title> <address> Amsterdam, </address> <year> 1975). </year>
Reference-contexts: However, in the mathematics literature on Markov chains with general state space, "ergodic" is used as a synonym for "irreducible, aperiodic and positive Harris recurrent" [7, p. 114] <ref> [8, p. 169] </ref>. 5 and unnormalized autocorrelation function 4 C ff (t) hf s f s+t i 2 = x;y xy x y ] f (y): The normalized autocorrelation function is then ff (t) C ff (t)=C ff (0): (2.9) Typically ff (t) decays exponentially (~ e jtj=t ) for large
Reference: [9] <author> Z. </author> <title> Sidak, </title> <journal> Czechoslovak Math. J. </journal> <volume> 14, </volume> <month> 438 </month> <year> (1964). </year>
Reference-contexts: Facts (a)-(c) are a generalized Perron-Frobenius theorem <ref> [9] </ref>; fact (d) is a consequence of a generalized spectral radius formula [10, Propositions 2.3-2.5]. The rate of convergence to equilibrium from an initial nonequilibrium distribution can be bounded above in terms of R (and hence t exp ).
Reference: [10] <author> A. D. Sokal and L. E. Thomas, J. </author> <title> Stat. </title> <journal> Phys. </journal> <volume> 54, </volume> <month> 797 </month> <year> (1989). </year>
Reference-contexts: Facts (a)-(c) are a generalized Perron-Frobenius theorem [9]; fact (d) is a consequence of a generalized spectral radius formula <ref> [10, Propositions 2.3-2.5] </ref>. The rate of convergence to equilibrium from an initial nonequilibrium distribution can be bounded above in terms of R (and hence t exp ). <p> When either low-order interpolation (e.g. piecewise-constant) or fl = 1 (the V-cycle) is used, the convergence proofs become much more 18 For a detailed exposition of multi-grid convergence proofs, see <ref> [32, Chapters 6-8, 10, 11] </ref>, [40] and the references cited therein. The additional work needed to handle the piecewise-constant interpolation can be found in [41]. 34 delicate. <p> Thus, the autocorrelation time ought to be of order hN 2 i, or equivalently hN i 2 . This heuristic argument can be turned into a rigorous proof of a lower bound t const fi hN i 2 <ref> [10] </ref>. However, as an argument for an upper bound of the same form, it is not entirely convincing, as it assumes without proof that the slowest mode is the one represented by N (t). <p> With considerably more work, it is possible to prove an upper bound on t that is only slightly weaker than the heuristic prediction: t constfihN i 1+fl <ref> [10, 77] </ref>. 36 (Note that the critical exponent fl is believed to equal 43=32 in dimension d = 2, 1:16 in d = 3, and 1 in d 4.) In fact, we suspect [78] that the true behavior is t ~ hN i p for some exponent p strictly between 2 <p> Using this fact, Lawler and Sokal [77] used Cheeger's inequality to prove t 0 exp const fi hN i 2fl (8.48) for the Berretti-Sokal algorithm for SAWs. A very different proof of an upper bound on t 0 exp in the Berretti-Sokal algorithm was given by Sokal and Thomas <ref> [10] </ref>. Their method is to study in detail the exponential moments of the hitting times from an arbitrary walk ! to the empty walk.
Reference: [11] <author> P.C. Hohenberg and B.I. Halperin, </author> <title> Rev. Mod. </title> <journal> Phys. </journal> <volume> 49, </volume> <month> 435 </month> <year> (1977). </year>
Reference-contexts: But this is not true in general. In fact, in statistical-mechanical problems near a critical point, one usually expects the autocorrelation function ff (t) to obey a dynamic scaling law <ref> [11] </ref> of the form ff (t; fi) ~ jtj a F (fi fi c ) jtj b (2.22) valid in the region jtj 1; jfi fi c j t 1; jfi fi c j jtj b bounded. (2.23) Here a; b &gt; 0 are dynamic critical exponents and F is a <p> When either low-order interpolation (e.g. piecewise-constant) or fl = 1 (the V-cycle) is used, the convergence proofs become much more 18 For a detailed exposition of multi-grid convergence proofs, see <ref> [32, Chapters 6-8, 10, 11] </ref>, [40] and the references cited therein. The additional work needed to handle the piecewise-constant interpolation can be found in [41]. 34 delicate.
Reference: [12] <author> S. Caracciolo and A.D. Sokal, J. Phys. A19, </author> <month> L797 </month> <year> (1986). </year>
Reference-contexts: In this case, the spectrum of 6 Our discussion of this topic in <ref> [12] </ref> is incorrect. 7 For the physical significance of this term, see Kemeny and Snell [4, section 5.3] or Iosifescu [5, section 4.5]. 8 P is real and lies in the closed interval [1; 1]; we define min = inf spec (P j n 1 ? ) (2.28) max = sup <p> The critical slowing-down in the BFACF algorithm is quite subtle. On the one hand, Sokal and Thomas [81] have proven the surprising result that t exp = +1 for all fi 6= 0 (see Section 8). On the other hand, numerical experiments <ref> [12, 82] </ref> show that t int;N ~ hN i 3:00:4 (in d = 2). Clearly, the BFACF dynamics is not well understood at present: further work, both theoretical and numerical, is needed.
Reference: [13] <author> D. Goldsman, </author> <type> Ph.D. thesis, </type> <institution> School of Operations Research and Industrial Engineering, Cornell University (1984); L. Schruben, Oper. Res. </institution> <note> 30, 569 (1982) and 31, 1090 (1983). </note>
Reference-contexts: So it is usual to determine empirically when "equilibrium" has been achieved, by plotting selected observables as a function of time and noting when the initial transient appears to end. More sophisticated statistical tests for initialization bias can also be employed <ref> [13] </ref>. In all empirical methods of determining when "equilibrium" has been achieved, a serious danger is the possibility of metastability.
Reference: [14] <author> M.B. Priestley, </author> <title> Spectral Analysis and Time Series, 2 vols. </title> <publisher> (Academic, </publisher> <address> London, </address> <year> 1981), </year> <month> Chapters 5-7. </month>
Reference-contexts: What is involved here is a branch of mathematical statistics called time-series analysis. An excellent exposition can be found in the books of of Priestley <ref> [14] </ref> and Anderson [15]. <p> As will become clear, this distinction is also of practical importance. b C (t) is an unbiased estimator of C (t), and b b C (t) is almost unbiased (the bias is of order 1=n) [15, p. 463]. Their variances and covariances are [15, pp. 464-471] <ref> [14, pp. 324-328] </ref> 1 1 X h i n (3.10) 1 1 X [C (m)C (m + u t) + C (m + u)C (m t) n (3.11) where t; u 0 and is the connected 4-point autocorrelation function (r; s; t) h (f i )(f i+r )(f i+s )(f i+t <p> estimator of t int would seem to be b t int 2 t = (n 1) (or the analogous thing with b b ), but this is wrong! The estimator defined in (3.15) has a variance that does not go to zero as the sample size n goes to infinity <ref> [14, pp. 420-431] </ref>, so it is clearly a very bad estimator of t int . <p> Roughly speaking, this is because the sample autocorrelations b (t) for jtj t contain much "noise" but little "signal"; and there are so many of them (order n) that the noise adds up to a total variance of order 1. (For a more detailed discussion, see <ref> [14, pp. 432-437] </ref>.) The solution is to cut off the sum in (3.15) using a "window" (t) which is 1 for jtj ~ &lt; t but 0 for jtj t : 1 n 1 X (t) b (t) : (3.16) This retains most of the "signal" but discards most of the
Reference: [15] <author> T.W. Anderson, </author> <title> The Statistical Analysis of Time Series (Wiley, </title> <address> New York, </address> <year> 1971). </year>
Reference-contexts: What is involved here is a branch of mathematical statistics called time-series analysis. An excellent exposition can be found in the books of of Priestley [14] and Anderson <ref> [15] </ref>. <p> As will become clear, this distinction is also of practical importance. b C (t) is an unbiased estimator of C (t), and b b C (t) is almost unbiased (the bias is of order 1=n) <ref> [15, p. 463] </ref>. <p> As will become clear, this distinction is also of practical importance. b C (t) is an unbiased estimator of C (t), and b b C (t) is almost unbiased (the bias is of order 1=n) [15, p. 463]. Their variances and covariances are <ref> [15, pp. 464-471] </ref> [14, pp. 324-328] 1 1 X h i n (3.10) 1 1 X [C (m)C (m + u t) + C (m + u)C (m t) n (3.11) where t; u 0 and is the connected 4-point autocorrelation function (r; s; t) h (f i )(f i+r )(f
Reference: [16] <author> N. </author> <title> Madras and A.D. </title> <journal> Sokal, J. Stat. Phys. </journal> <volume> 50, </volume> <month> 109 </month> <year> (1988). </year>
Reference-contexts: M = a few times t usually suffices), while the variance is kept small by taking M to be no larger than necessary consistent with this constraint. We have found the following "automatic windowing" algorithm <ref> [16] </ref> to be convenient: choose M to be the smallest integer such that M c b t int (M ). If (t) were roughly a pure exponential, then it would suffice to take c 4 (since e 4 &lt; 2%). <p> So the recent proof [85] that all such algorithms are nonergodic (= not irreducible) comes as a slight embarrassment. Fortunately, there does exist a non-local fixed-N algorithm which is ergodic: the "pivot" algorithm, invented by Lal [86] and independently reinvented by MacDonald et al. [87] and by Madras <ref> [16] </ref>. <p> The resulting walk is accepted if it is self-avoiding; otherwise it is rejected and the walk ! is counted once more in the sample. It can be proven <ref> [16] </ref> that this algorithm is ergodic and preserves the equal-weight probability distribution. At first thought the pivot algorithm sounds terrible (at least it did to me): for N large, nearly all the proposed moves will get rejected. <p> At first thought the pivot algorithm sounds terrible (at least it did to me): for N large, nearly all the proposed moves will get rejected. This is in fact true: the acceptance fraction behaves N p as N ! 1, where p 0:19 in d = 2 <ref> [16] </ref>. On the other hand, the pivot moves are very radical: after very few (5 or 10) accepted moves the SAW will have reached an "essentially new" conformation. One conjectures, therefore, that t ~ N p . <p> Thus, the slowest mode is expected to behave as t exp ~ N 1+p . For the pivot algorithm applied to ordinary random walk one can calculate the dynamical behavior exactly <ref> [16] </ref>: for global observables f the 57 autocorrelation function behaves roughly like ff (t) ~ i=1 1 n ; (7.12) from which it follows that t int;f ~ log N (7.13) | in agreement with our heuristic argument modulo logarithms. For the SAW, it is found numerically [16] that t int;f <p> dynamical behavior exactly <ref> [16] </ref>: for global observables f the 57 autocorrelation function behaves roughly like ff (t) ~ i=1 1 n ; (7.12) from which it follows that t int;f ~ log N (7.13) | in agreement with our heuristic argument modulo logarithms. For the SAW, it is found numerically [16] that t int;f ~ N 0:20 in d = 2, also in close agreement with the heuristic argument. <p> Thus, with a modest computational effort (300 hours on a Cyber 170-730), Madras and I found - = 0:7496 0:0007 (95% confidence limits) for 2-dimensional SAWs of lengths 200 N 10000 <ref> [16] </ref>. We hope to carry out soon a convincing numerical test of hyperscaling in the three-dimensional SAW. 37 8 Rigorous Analysis of Dynamic Monte Carlo Al gorithms In this final lecture, we discuss techniques for proving rigorous lower and upper bounds on the autocorrelation times of dynamic Monte Carlo algorithms.
Reference: [17] <author> N. Metropolis, A.W. Rosenbluth, M.N. Rosenbluth, A.H. Teller and E. Teller, J. </author> <title> Chem. </title> <journal> Phys. </journal> <volume> 21, </volume> <month> 1087 </month> <year> (1953). </year>
Reference-contexts: For each pair x; y 2 S; x p xy = y p yx . A very general method for constructing transition matrices satisfying detailed balance for a given distribution was introduced in 1953 by Metropolis et al. <ref> [17] </ref>, with a slight extension two decades later by Hastings [18]. The idea is the following: Let 9 We have also assumed that the only strong peaks in the Fourier transform of C (t) are at zero frequency.
Reference: [18] <author> W.K. Hastings, </author> <type> Biometrika 57, </type> <month> 97 </month> <year> (1970). </year>
Reference-contexts: For each pair x; y 2 S; x p xy = y p yx . A very general method for constructing transition matrices satisfying detailed balance for a given distribution was introduced in 1953 by Metropolis et al. [17], with a slight extension two decades later by Hastings <ref> [18] </ref>. The idea is the following: Let 9 We have also assumed that the only strong peaks in the Fourier transform of C (t) are at zero frequency.
Reference: [19] <author> J. Goodman and N. </author> <title> Madras, </title> <journal> Lin. Alg. Appl. </journal> <volume> 216, </volume> <month> 61 </month> <year> (1995). </year>
Reference-contexts: The factor ~ z could, however, conceivably be reduced 12 Indeed, for the Gaussian model this random-walk picture can be made rigorous: see <ref> [19] </ref> combined with [20, Section 8]. 13 Clearly one must take L ~ &gt; ~ in order to avoid severe finite-size effects. Typically one approaches the critical point with L c~, where c 24, and then uses finite-size scaling [22, 23] to extrapolate to the infinite-volume limit. <p> This takes a time of order L 2 , in agreement with (5.13). In fact, this random-walk picture can be made rigorous <ref> [19] </ref>. This is an example of a critical phenomenon, in precisely the same sense that the term is used in statistical mechanics.
Reference: [20] <author> J. Goodman and A.D. </author> <title> Sokal, </title> <journal> Phys. Rev. </journal> <volume> D40, </volume> <year> 2035 (1989). </year>
Reference-contexts: The factor ~ z could, however, conceivably be reduced 12 Indeed, for the Gaussian model this random-walk picture can be made rigorous: see [19] combined with <ref> [20, Section 8] </ref>. 13 Clearly one must take L ~ &gt; ~ in order to avoid severe finite-size effects. Typically one approaches the critical point with L c~, where c 24, and then uses finite-size scaling [22, 23] to extrapolate to the infinite-volume limit. <p> Specific implementations of the collective-mode idea are thus highly model-dependent. At least three such algorithms have been invented so far: * Fourier acceleration [24] * Multi-grid Monte Carlo (MGMC) <ref> [25, 20, 26] </ref> * The Swendsen-Wang algorithm [27] and its generalizations Fourier acceleration and MGMC are very similar in spirit (though quite different technically). Their performance is thus probably qualitatively similar, in the sense that they probably work well for the same models and work badly for the same models. <p> Both MG and MGMC are discussed in detail in <ref> [20] </ref>. 15 For further discussion, see [20, Section 10.1]. 23 Consider, for purposes of exposition, the lattice Poisson equation ' = f in a region Z d with zero Dirichlet data. <p> Both MG and MGMC are discussed in detail in [20]. 15 For further discussion, see <ref> [20, Section 10.1] </ref>. 23 Consider, for purposes of exposition, the lattice Poisson equation ' = f in a region Z d with zero Dirichlet data. <p> See, for example, [32] and <ref> [20, Section 2] </ref>. 27 compute H l1 ( ) H l (' + p l;l1 ) 0 for j = 1 until fl l do mgm (l 1; ; H l1 ) ' ' + p l;l1 endif ' S post l ('; H l ) Here is what is going <p> Unigrid could, however, be of interest in cases where true multi-grid is unfeasible, as may occur for non-Abelian lattice gauge theories. Multi-grid algorithms can also be devised for some models in which state space is a nonlinear manifold, such as nonlinear -models and lattice gauge theories <ref> [20, Sections 3-5] </ref>. The simplest case is the XY model: both the fine-grid and coarse-grid field variables are angles, and the interpolation operator is piecewise-constant (with angles added modulo 2). <p> Therefore, we advocate unigrid only as a conceptual device, not as a computational algorithm. How well does MGMC perform? The answer is highly model-dependent: * For the Gaussian model , it can be proven rigorously <ref> [25, 20, 41] </ref> that t is bounded as criticality is approached (empirically t 1 2); therefore, critical slowing-down is completely eliminated . <p> This behavior can be understood <ref> [20, Section 9.1] </ref> as due to the double-well nature of the ' 4 potential, which makes MGMC ineffective on large blocks. <p> For a W-cycle we find that z 0:6 (I emphasize that these data are very preliminary!). Previously, Goodman and I had argued heuristically <ref> [20, Section 9.3] </ref> that for asymptotically free theories with a continuous symmetry group, MGMC (with a W-cycle) should completely eliminate critical slowing-down except for a possible logarithm. <p> Note Added 1996: For work on multi-grid Monte Carlo covering the period 1992-96, see [106, 107, 108, 103] and the references cited therein. 40 5.3 Stochastic Linear Iterations for the Gaussian Model In this section we analyze an important class of Markov chains, the stochastic linear iterations for Gaussian models <ref> [20, Section 8] </ref>. 20 This class includes, among others, the single-site heat-bath algorithm (with deterministic sweep of the sites), the stochastic SOR algorithm [44, 45] and the multi-grid Monte Carlo algorithm | all, of course, in the Gaussian case only. <p> Hermite polynomials.) Then the transition probability P (' (n) ! ' (n+1) ) induces on the Fock space an operator P = (M T ) I M T (M T M T ) (5.55) that is the second quantization of the operator M T on the energy Hilbert space (see <ref> [20, Section 8] </ref> for details).
Reference: [21] <institution> G.F. Mazenko and O.T. Valls, Phys. </institution> <note> Rev. B24, 1419 (1981); C. Kalle, J. Phys. A17, L801 (1984); J.K. Williams, J. Phys. A18, 49 (1985); R.B. </note> <author> Pearson, J.L. Richardson and D. </author> <title> Toussaint, </title> <journal> Phys. Rev. B31, 4472 (1985); S. Wansleben and D.P. Landau, J. Appl. Phys. </journal> <volume> 61, </volume> <month> 3968 </month> <year> (1987). </year> <month> 68 </month>
Reference-contexts: In any case, for most models of interest, the dynamic critical exponent for local algorithms is close to 2 (usually somewhat higher) <ref> [21] </ref>. <p> Table 1 shows some preliminary data [61] on a two-dimensional Ising model at the bulk critical temperature. These data are consistent with the estimate t SW ~ L 0:35 [27]. 25 By contrast, the conventional single-spin-flip algorithms for the two-dimensional Ising model have t conv ~ L 2:1 <ref> [21] </ref>. So the advantage of Swendsen-Wang over conventional algorithms (for this model) grows asymptotically like L 1:75 .
Reference: [22] <author> M.N. Barber, </author> <title> in Phase Transitions and Critical Phenomena, </title> <journal> vol. </journal> <volume> 8, </volume> <editor> ed. C. Domb and J.L. </editor> <publisher> Lebowitz (Academic Press, </publisher> <address> London, </address> <year> 1983). </year>
Reference-contexts: Typically one approaches the critical point with L c~, where c 24, and then uses finite-size scaling <ref> [22, 23] </ref> to extrapolate to the infinite-volume limit. Note Added 1996: Recently, radical advances have been made in applying finite-size scaling to Monte Carlo simulations (see [97, 98] and especially [99, 100, 101, 102, 103]); the preceding two sentences can now be seen to be far too pessimistic.
Reference: [23] <author> K. Binder, J. </author> <title> Comput. </title> <journal> Phys. </journal> <volume> 59, </volume> <month> 1 </month> <year> (1985). </year>
Reference-contexts: Typically one approaches the critical point with L c~, where c 24, and then uses finite-size scaling <ref> [22, 23] </ref> to extrapolate to the infinite-volume limit. Note Added 1996: Recently, radical advances have been made in applying finite-size scaling to Monte Carlo simulations (see [97, 98] and especially [99, 100, 101, 102, 103]); the preceding two sentences can now be seen to be far too pessimistic.

Reference: [25] <author> J. Goodman and A.D. </author> <title> Sokal, </title> <journal> Phys. Rev. Lett. </journal> <volume> 56, </volume> <month> 1015 </month> <year> (1986). </year>
Reference-contexts: Specific implementations of the collective-mode idea are thus highly model-dependent. At least three such algorithms have been invented so far: * Fourier acceleration [24] * Multi-grid Monte Carlo (MGMC) <ref> [25, 20, 26] </ref> * The Swendsen-Wang algorithm [27] and its generalizations Fourier acceleration and MGMC are very similar in spirit (though quite different technically). Their performance is thus probably qualitatively similar, in the sense that they probably work well for the same models and work badly for the same models. <p> In the 1980's, multi-grid methods have become an active area of research in numerical analysis, and have been applied to a wide variety of problems in classical physics [32, 33]. Very recently <ref> [25] </ref> it was shown how a stochastic generalization of the 22 multi-grid method | multi-grid Monte Carlo (MGMC) | can be applied to problems in statistical , and hence also Euclidean quantum, physics. <p> Therefore, we advocate unigrid only as a conceptual device, not as a computational algorithm. How well does MGMC perform? The answer is highly model-dependent: * For the Gaussian model , it can be proven rigorously <ref> [25, 20, 41] </ref> that t is bounded as criticality is approached (empirically t 1 2); therefore, critical slowing-down is completely eliminated . <p> The proof is a simple Fock-space argument, combined with the convergence proof for deterministic MG; this will be discussed in Section 5.3. * For the ' 4 model , numerical experiments <ref> [25] </ref> show that t diverges with the same dynamic critical exponent as in the heat-bath algorithm; the gain in efficiency thus approaches a constant factor F () near the critical point.
Reference: [26] <author> R.G. Edwards, J. Goodman and A.D. </author> <month> Sokal, </month> <institution> Nucl. Phys. B354, </institution> <month> 289 </month> <year> (1991). </year>
Reference-contexts: Specific implementations of the collective-mode idea are thus highly model-dependent. At least three such algorithms have been invented so far: * Fourier acceleration [24] * Multi-grid Monte Carlo (MGMC) <ref> [25, 20, 26] </ref> * The Swendsen-Wang algorithm [27] and its generalizations Fourier acceleration and MGMC are very similar in spirit (though quite different technically). Their performance is thus probably qualitatively similar, in the sense that they probably work well for the same models and work badly for the same models. <p> modes at long length scales are nonlinear excitations not well modelled by ' ! ' + t B . (See Section 6 for an algorithm that appears to model these excitations well, at least for not too small.) * For the d = 2 XY model , our numerical data <ref> [26] </ref> show a more complicated behavior: As the critical temperature is approached from above, t diverges with a dynamic critical exponent z = 1:4 0:3 for the MGMC algorithm (in either V-cycle or W-cycle), compared to z = 2:1 0:3 for the heat-bath algorithm.
Reference: [27] <author> R.H. Swendsen and J.-S. Wang, </author> <title> Phys. </title> <journal> Rev. Lett. </journal> <volume> 58, </volume> <month> 86 </month> <year> (1987). </year>
Reference-contexts: Specific implementations of the collective-mode idea are thus highly model-dependent. At least three such algorithms have been invented so far: * Fourier acceleration [24] * Multi-grid Monte Carlo (MGMC) [25, 20, 26] * The Swendsen-Wang algorithm <ref> [27] </ref> and its generalizations Fourier acceleration and MGMC are very similar in spirit (though quite different technically). Their performance is thus probably qualitatively similar, in the sense that they probably work well for the same models and work badly for the same models. <p> That is, the autocorrelation time t of the MGMC method is bounded as criticality is approached (empirically t 1 2). 6 Swendsen-Wang Algorithms A very different type of collective-mode algorithm was proposed two years ago 22 by Swendsen and Wang <ref> [27] </ref> for Potts spin models. Since then, there has been an explosion of work trying to understand why this algorithm works so well (and why it does not work even better), and trying to improve or generalize it. <p> On the other hand, Swendsen and Wang <ref> [27] </ref> exploited facts (b)-(e) to devise a radically new type of Monte Carlo algorithm. <p> These relations were rediscovered several times during the subsequent two decades [59]. Surprisingly, however, no one seems to have noticed the joint probability distribution F KSW that underlay all these identities; this was discovered implicitly by Swendsen and Wang <ref> [27] </ref>, and was made explicit by Edwards and Sokal [60]. It is certainly plausible that the SW algorithm might have less critical slowing-down than the conventional (single-spin-update) algorithms: the reason is that a local move in one set of variables can have highly nonlocal effects in the other. <p> Table 1 shows some preliminary data [61] on a two-dimensional Ising model at the bulk critical temperature. These data are consistent with the estimate t SW ~ L 0:35 <ref> [27] </ref>. 25 By contrast, the conventional single-spin-flip algorithms for the two-dimensional Ising model have t conv ~ L 2:1 [21]. So the advantage of Swendsen-Wang over conventional algorithms (for this model) grows asymptotically like L 1:75 . <p> Estimates are taken from <ref> [27] </ref> for d = 2; 3, q = 2; [62] for d = 2, q = 3; 4; and [63] for d = 4, q = 2.
Reference: [28] <author> R.P. Fedorenko, Zh. </author> <title> Vychisl. </title> <journal> i Mat. Fiz. 4, 559 (1964) [USSR Comput. Math. and Math. Phys. </journal> <volume> 4, </volume> <month> 227 </month> <year> (1964)]. </year>
Reference-contexts: An ingenious solution, now called the multi-grid (MG) method, was proposed in 1964 by the Soviet numerical analyst Fedorenko <ref> [28] </ref>: the idea is to consider, in addition to the original ("fine-grid") problem, a sequence of auxiliary "coarse-grid" problems that approximate the behavior of the original problem for excitations at successively longer length scales (a sort of "coarse-graining" procedure). <p> An algorithm of precisely this form was proposed in 1964 by the Soviet numerical analyst Fedorenko <ref> [28] </ref>, and is now called the multi-grid method .
Reference: [29] <editor> L.P. Kadanoff, </editor> <booktitle> Physics 2, </booktitle> <month> 263 </month> <year> (1966). </year>
Reference-contexts: The local updates of the traditional algorithms are then supplemented by coarse-grid updates. To a present-day physicist, this philosophy is remarkably reminiscent of the renormalization group | so it is all the more remarkable that it was invented two years before the work of Kadanoff <ref> [29] </ref> and seven years before the work of Wilson [30]! After a decade of dormancy, multi-grid was revived in the mid-1970's [31], and was shown to be an extremely efficient computational method.
Reference: [30] <author> K.G. </author> <title> Wilson, </title> <journal> Phys. Rev. B4, </journal> <volume> 3174, </volume> <month> 3184 </month> <year> (1971). </year>
Reference-contexts: To a present-day physicist, this philosophy is remarkably reminiscent of the renormalization group | so it is all the more remarkable that it was invented two years before the work of Kadanoff [29] and seven years before the work of Wilson <ref> [30] </ref>! After a decade of dormancy, multi-grid was revived in the mid-1970's [31], and was shown to be an extremely efficient computational method.
Reference: [31] <author> A. Brandt, </author> <booktitle> in Proceedings of the Third International Conference on Numerical Methods in Fluid Mechanics (Paris, </booktitle> <month> July </month> <year> 1972), </year> <editor> ed. H. Cabannes and R. </editor> <booktitle> Temam (Lecture Notes in Physics #18) (Springer, </booktitle> <address> Berlin, </address> <note> 1973); R.A. Nicolaides, J. Com-put. Phys. 19, 418 (1975) and Math. Comp. 31, 892 (1977); A. Brandt, Math. Comp. 31, 333 (1977); W. </note> <author> Hackbusch, </author> <title> in Numerical Treatment of Differential Equations (Oberwolfach, </title> <month> July </month> <year> 1976), </year> <editor> ed. R. Bulirsch, R.D. Griegorieff and J. </editor> <booktitle> Schroder (Lecture Notes in Mathematics #631) (Springer, </booktitle> <address> Berlin, </address> <year> 1978). </year>
Reference-contexts: physicist, this philosophy is remarkably reminiscent of the renormalization group | so it is all the more remarkable that it was invented two years before the work of Kadanoff [29] and seven years before the work of Wilson [30]! After a decade of dormancy, multi-grid was revived in the mid-1970's <ref> [31] </ref>, and was shown to be an extremely efficient computational method. In the 1980's, multi-grid methods have become an active area of research in numerical analysis, and have been applied to a wide variety of problems in classical physics [32, 33].
Reference: [32] <author> W. Hackbusch, </author> <title> Multi-Grid Methods and Applications (Springer, </title> <address> Berlin, </address> <year> 1985). </year>
Reference-contexts: In the 1980's, multi-grid methods have become an active area of research in numerical analysis, and have been applied to a wide variety of problems in classical physics <ref> [32, 33] </ref>. Very recently [25] it was shown how a stochastic generalization of the 22 multi-grid method | multi-grid Monte Carlo (MGMC) | can be applied to problems in statistical , and hence also Euclidean quantum, physics. <p> Multi-Grid In this section we give a pedagogical introduction to multi-grid methods in the simplest case, namely the solution of deterministic linear or nonlinear systems of equations. 14 For an excellent introduction to the deterministic multi-grid method, see Briggs [34]; more advanced topics are covered in the book of Hackbusch <ref> [32] </ref>. Both MG and MGMC are discussed in detail in [20]. 15 For further discussion, see [20, Section 10.1]. 23 Consider, for purposes of exposition, the lattice Poisson equation ' = f in a region Z d with zero Dirichlet data. <p> See, for example, <ref> [32] </ref> and [20, Section 2]. 27 compute H l1 ( ) H l (' + p l;l1 ) 0 for j = 1 until fl l do mgm (l 1; ; H l1 ) ' ' + p l;l1 endif ' S post l ('; H l ) Here is what <p> We now discuss briefly each of these ingredients; more details can be found in Chapter 3 of the book of Hackbusch <ref> [32] </ref>. Coarse grids. Most commonly one uses a uniform factor-of-2 coarsening between each grid l and the next coarser grid l1 . The coarse-grid points could be either a subset of the fine-grid points (Fig. 1) or a subset of the dual lattice (Fig. 2). <p> The only reason we introduced damped Jacobi at all is that it is easier to understand and to analyze. Many other smoothing iterations can be considered, and can be advantageous in anisotropic or otherwise singular problems <ref> [32, Section 3.3 and Chapters 10-11] </ref>. But we shall stick to ordinary Gauss-Seidel, usually with red-black ordering. Thus, S pre post l will consist, respectively, of m 1 and m 2 iterations of the Gauss-Seidel algorithm. <p> When either low-order interpolation (e.g. piecewise-constant) or fl = 1 (the V-cycle) is used, the convergence proofs become much more 18 For a detailed exposition of multi-grid convergence proofs, see <ref> [32, Chapters 6-8, 10, 11] </ref>, [40] and the references cited therein. The additional work needed to handle the piecewise-constant interpolation can be found in [41]. 34 delicate. <p> On the other hand, the multi-grid method uses square-wave (or triangular-wave) updates, which are not exactly the "correct" collective modes. Nevertheless, the multi-grid convergence proofs <ref> [32, 40, 41] </ref> assure us that they are "close enough": the norm of the multi-grid iteration matrix M l is bounded away from 1, uniformly in the lattice size, so that an accurate solution is reached in a very few MG iterations (in particular, critical slowing-down is completely eliminated). <p> In other words, the (worst-case) convergence rate of the Monte Carlo algorithm is precisely equal to the (worst-case) convergence rate of the corresponding deterministic iteration. In particular, for Gaussian MGMC, the convergence proofs for deterministic multi-grid <ref> [32, 40, 41] </ref> combined with the arguments of the present section prove rigorously that critical slowing-down is completely eliminated (at least for a W-cycle).

Reference: [34] <author> W.L. Briggs, </author> <title> A Multigrid Tutorial (SIAM, </title> <address> Philadelphia, </address> <year> 1987). </year>
Reference-contexts: unfortunately led to much confusion in the literature. 15 5.1 Deterministic Multi-Grid In this section we give a pedagogical introduction to multi-grid methods in the simplest case, namely the solution of deterministic linear or nonlinear systems of equations. 14 For an excellent introduction to the deterministic multi-grid method, see Briggs <ref> [34] </ref>; more advanced topics are covered in the book of Hackbusch [32].
Reference: [35] <author> R.S. Varga, </author> <title> Matrix Iterative Analysis (Prentice-Hall, </title> <address> Englewood Cliffs, N.J., </address> <year> 1962). </year>
Reference-contexts: It can be shown <ref> [35] </ref> that the spectral radius (M DJ;! ) of the damped Jacobi iteration matrix is less than 1, so that the iteration (5.10) converges exponentially to the solution '. This would appear to be a happy situation.
Reference: [36] <author> H.R. Schwarz, H. Rutishauer and E. </author> <title> Stiefel, Numerical Analysis of Symmetric Matrices (Prentice-Hall, </title> <address> Englewood Cliffs, N.J., </address> <year> 1973). </year>
Reference-contexts: 1;x 2 + ' x 1 ;x 2 +1 + ' x 1 ;x 2 1 + f x 1 ;x 2 ]: (5.32) 17 It is amusing to note that "Gauss did not use a cyclic order of relaxation, and : : : Seidel specifically recommended against using it" <ref> [36, p. 44n] </ref>. <p> For the SAW, it is found numerically [16] that t int;f ~ N 0:20 in d = 2, also in close agreement with the heuristic argument. A careful analysis of the computational complexity of the pivot algorithm <ref> [36] </ref> shows that one "effectively independent" sample (at least as regards global observables) can be produced in a computer time of order N .
Reference: [37] <institution> A.M. Ostrowski, Rendiconti Mat. e Appl. </institution> <note> 13, 140 (1954) at p. </note> <editor> 141n [A. Ostrowski, </editor> <booktitle> Collected Mathematical Papers, </booktitle> <volume> vol. </volume> <pages> 1 (Birkhauser, </pages> <address> Basel, </address> <year> 1983), </year> <note> p. 169n]. </note>
Reference-contexts: See also <ref> [37] </ref>. 32 Another convenient ordering is the red-black (or checkerboard ) ordering, in which the "red" sublattice r = fx 2 : x 1 + + x d is eveng is swept first, followed by the "black" sublattice b = fx 2 : x 1 + + x d is oddg.
Reference: [38] <author> J.M. Ortega and W.C. Rheinboldt, </author> <title> Iterative Solution of Nonlinear Equations in Several Variables (Academic Press, </title> <address> New York-London, </address> <year> 1970). </year>
Reference-contexts: this variational definition: ' 0 x should be the absolute minimizer of H (') = H (' x ; f' y g y6=x ). [If the absolute minimizer is non-unique, then one such minimizer is chosen by some arbitrary rule.] This algorithm is called nonlinear Gauss-Seidel with exact minimization (NL-GSEM) <ref> [38] </ref>. This definition of the algorithm presupposes, of course, that it is feasible to carry out the requisite exact one-dimensional minimizations. For example, for a ' 4 theory it would be necessary to compute the absolute minimum of a quartic polynomial in one variable. <p> For a suitable choice of the direction vectors p 0 ; p 1 ; :::, this method can be proven to converge to the global minimum of H <ref> [38, pp. 513-520] </ref>. Now, some iterative algorithms for minimizing H (') can be recognized as special cases of the directional method.
Reference: [39] <author> S.F. McCormick and J. </author> <title> Ruge, </title> <journal> Math. Comp. </journal> <volume> 41, </volume> <month> 43 </month> <year> (1983). </year>
Reference-contexts: : : : ; e N (i.e. vectors which take the value 1 at a single grid point and zero at all others), where N = dim U . [One step of the Gauss-Seidel iteration corresponds to N steps of the directional method.] Similarly, it is not hard to see <ref> [39] </ref> that the multi-grid iteration with the variational choices of restriction and coarse-grid operators, and with Gauss-Seidel smoothing at each level, is itself a directional method: some of the direction vectors are the unit vectors e (M) (M) (M) N M of the fine-grid space, but other direction vectors are the <p> Similarly, if p l;l1 is linear interpolation, then the direction vectors are triangular waves of various widths. The multi-grid algorithm has thus an alternative interpretation as a collective-mode algorithm working solely in the fine-grid space U . We emphasize that this "unigrid" viewpoint <ref> [39] </ref> is mathematically fully equivalent to the recursive definition given earlier. But it gives, we think, an important additional insight into what the multi-grid algorithm is really doing. <p> We remark that McCormick and Ruge <ref> [39] </ref> have advocated the "unigrid" idea not just as an alternate point of view on the multi-grid algorithm, but as an alternate computational procedure. To be sure, the unigrid method is somewhat simpler to program, and this could have pedagogical advantages.
Reference: [40] <author> J. Mandel, S. McCormick and R. Bank, </author> <title> in Multigrid Methods, </title> <editor> ed. </editor> <address> S.F. </address> <publisher> McCormick (SIAM, </publisher> <address> Philadelphia, </address> <year> 1987), </year> <note> Chapter 5. </note>
Reference-contexts: When either low-order interpolation (e.g. piecewise-constant) or fl = 1 (the V-cycle) is used, the convergence proofs become much more 18 For a detailed exposition of multi-grid convergence proofs, see [32, Chapters 6-8, 10, 11], <ref> [40] </ref> and the references cited therein. The additional work needed to handle the piecewise-constant interpolation can be found in [41]. 34 delicate. <p> On the other hand, the multi-grid method uses square-wave (or triangular-wave) updates, which are not exactly the "correct" collective modes. Nevertheless, the multi-grid convergence proofs <ref> [32, 40, 41] </ref> assure us that they are "close enough": the norm of the multi-grid iteration matrix M l is bounded away from 1, uniformly in the lattice size, so that an accurate solution is reached in a very few MG iterations (in particular, critical slowing-down is completely eliminated). <p> In other words, the (worst-case) convergence rate of the Monte Carlo algorithm is precisely equal to the (worst-case) convergence rate of the corresponding deterministic iteration. In particular, for Gaussian MGMC, the convergence proofs for deterministic multi-grid <ref> [32, 40, 41] </ref> combined with the arguments of the present section prove rigorously that critical slowing-down is completely eliminated (at least for a W-cycle).
Reference: [41] <author> J. Goodman and A.D. Sokal, </author> <note> unpublished. </note>
Reference-contexts: The additional work needed to handle the piecewise-constant interpolation can be found in <ref> [41] </ref>. 34 delicate. <p> On the other hand, the multi-grid method uses square-wave (or triangular-wave) updates, which are not exactly the "correct" collective modes. Nevertheless, the multi-grid convergence proofs <ref> [32, 40, 41] </ref> assure us that they are "close enough": the norm of the multi-grid iteration matrix M l is bounded away from 1, uniformly in the lattice size, so that an accurate solution is reached in a very few MG iterations (in particular, critical slowing-down is completely eliminated). <p> Therefore, we advocate unigrid only as a conceptual device, not as a computational algorithm. How well does MGMC perform? The answer is highly model-dependent: * For the Gaussian model , it can be proven rigorously <ref> [25, 20, 41] </ref> that t is bounded as criticality is approached (empirically t 1 2); therefore, critical slowing-down is completely eliminated . <p> In other words, the (worst-case) convergence rate of the Monte Carlo algorithm is precisely equal to the (worst-case) convergence rate of the corresponding deterministic iteration. In particular, for Gaussian MGMC, the convergence proofs for deterministic multi-grid <ref> [32, 40, 41] </ref> combined with the arguments of the present section prove rigorously that critical slowing-down is completely eliminated (at least for a W-cycle).
Reference: [42] <author> R.G. Edwards, S.J. Ferreira, J. Goodman and A.D. </author> <month> Sokal, </month> <institution> Nucl. Phys. B380, </institution> <month> 621 </month> <year> (1992). </year>
Reference-contexts: which are well handled by MGMC (as in the Gaussian model); but near the critical temperature the important excitations are widely separated vortex-antivortex pairs, which are apparently not easily created by the MGMC updates. * For the O (4) nonlinear -model in two dimensions, which is asymptotically free, preliminary data <ref> [42] </ref> show a very strong reduction, but not the total elimination, of critical slowing-down. For a W-cycle we find that z 0:6 (I emphasize that these data are very preliminary!).
Reference: [43] <author> S.L. </author> <title> Adler, </title> <journal> Phys. Rev. Lett. </journal> <volume> 60, </volume> <month> 1243 </month> <year> (1988). </year>
Reference-contexts: That is: (a) The linear deterministic problem is the zero-temperature limit of the Gaussian stochastic problem; and the first-order stationary linear deterministic iteration is the 20 Some of this material appears also in <ref> [43] </ref>. 41 zero-temperature limit of the first-order stationary linear stochastic iteration.
Reference: [44] <author> S.L. </author> <title> Adler, </title> <journal> Phys. Rev. </journal> <volume> D23, </volume> <year> 2091 (1981). </year>
Reference-contexts: 40 5.3 Stochastic Linear Iterations for the Gaussian Model In this section we analyze an important class of Markov chains, the stochastic linear iterations for Gaussian models [20, Section 8]. 20 This class includes, among others, the single-site heat-bath algorithm (with deterministic sweep of the sites), the stochastic SOR algorithm <ref> [44, 45] </ref> and the multi-grid Monte Carlo algorithm | all, of course, in the Gaussian case only. We show that the behavior of the stochastic algorithm is completely determined by the behavior of the corresponding deterministic algorithm for solving linear equations. <p> It is straightforward to verify that (5.44a,b) are satisfied. 21 The single-site heat-bath algorithm is clearly the stochastic generalization of the Gauss-Seidel algorithm. 2. Stochastic SOR. For models which are Gaussian (or more generally, "multi-Gaussian"), Adler <ref> [44] </ref> and Whitmer [45] have shown that the successive over-relaxation (SOR) iteration admits a stochastic generalization, namely ' i = (1 !)' i + !a 1 0 X a ij ' j j&gt;i (n) 1 a ii ~ i ; 21 We remark that this verification never uses the fact that
Reference: [45] <author> C. </author> <title> Whitmer, </title> <journal> Phys. Rev. </journal> <volume> D29, </volume> <month> 306 </month> <year> (1984). </year>
Reference-contexts: 40 5.3 Stochastic Linear Iterations for the Gaussian Model In this section we analyze an important class of Markov chains, the stochastic linear iterations for Gaussian models [20, Section 8]. 20 This class includes, among others, the single-site heat-bath algorithm (with deterministic sweep of the sites), the stochastic SOR algorithm <ref> [44, 45] </ref> and the multi-grid Monte Carlo algorithm | all, of course, in the Gaussian case only. We show that the behavior of the stochastic algorithm is completely determined by the behavior of the corresponding deterministic algorithm for solving linear equations. <p> It is straightforward to verify that (5.44a,b) are satisfied. 21 The single-site heat-bath algorithm is clearly the stochastic generalization of the Gauss-Seidel algorithm. 2. Stochastic SOR. For models which are Gaussian (or more generally, "multi-Gaussian"), Adler [44] and Whitmer <ref> [45] </ref> have shown that the successive over-relaxation (SOR) iteration admits a stochastic generalization, namely ' i = (1 !)' i + !a 1 0 X a ij ' j j&gt;i (n) 1 a ii ~ i ; 21 We remark that this verification never uses the fact that D is diagonal
Reference: [46] <author> E. Nelson, </author> <title> in Constructive Quantum Field Theory, </title> <editor> ed. G. Velo and A. </editor> <booktitle> Wightman (Lecture Notes in Physics #25) (Springer, </booktitle> <address> Berlin, </address> <year> 1973). </year>
Reference-contexts: Thus, the matrix M determines the autocorrelation functions of the Monte Carlo algorithm. Another way to state these relationships is to recall <ref> [46, 47] </ref> that the Hilbert space L 2 () is isomorphic to the bosonic Fock space F (U ) built on the "energy Hilbert space" (U; A): the "n-particle states" are the homogeneous Wick polynomials of degree n in the shifted field e ' = ' A 1 f . (If
Reference: [47] <author> B. Simon, </author> <title> The P (') 2 Euclidean (Quantum) Field Theory (Princeton Univ. </title> <publisher> Press, </publisher> <address> Princeton, N.J., </address> <year> 1974), </year> <note> Chapter I. </note>
Reference-contexts: Thus, the matrix M determines the autocorrelation functions of the Monte Carlo algorithm. Another way to state these relationships is to recall <ref> [46, 47] </ref> that the Hilbert space L 2 () is isomorphic to the bosonic Fock space F (U ) built on the "energy Hilbert space" (U; A): the "n-particle states" are the homogeneous Wick polynomials of degree n in the shifted field e ' = ' A 1 f . (If
Reference: [48] <author> R.B. </author> <title> Potts, </title> <journal> Proc. Camb. Phil. Soc. </journal> <volume> 48, </volume> <month> 106 </month> <year> (1952). </year>
Reference-contexts: In this lecture we describe the Swendsen-Wang (SW) algorithm and review some of the proposed variants and generalizations. Let us first recall that the q-state Potts model <ref> [48, 49] </ref> is a generalization of the Ising model in which each spin i can take q distinct values rather than just two ( i = 1; 2; : : : ; q); here q is an integer 2.
Reference: [49] <author> F.Y. Wu, </author> <title> Rev. Mod. </title> <journal> Phys. </journal> <volume> 54, 235 (1982); 55, </volume> <booktitle> 315 (E) (1983). </booktitle>
Reference-contexts: In this lecture we describe the Swendsen-Wang (SW) algorithm and review some of the proposed variants and generalizations. Let us first recall that the q-state Potts model <ref> [48, 49] </ref> is a generalization of the Ising model in which each spin i can take q distinct values rather than just two ( i = 1; 2; : : : ; q); here q is an integer 2. <p> Instead of a critical point, the model undergoes a first-order phase transition: in two dimensions, this occurs when q &gt; 4, while in three or more dimensions, it is believed to occur already when q 3 <ref> [49] </ref>. At a first-order transition, both the conventional algorithms and the Swendsen-Wang algorithm have an extremely severe slowing-down (much more severe than the slowing-down at a critical point): right at the transition temperature, we expect t ~ exp (cL d1 ).
Reference: [50] <author> K. Krickeberg, </author> <title> Probability Theory (Addison-Wesley, </title> <address> Reading, Mass., </address> <year> 1965), </year> <note> Sections 4.2 and 4.5. </note>
Reference-contexts: (6.10) and E ( j fng) denotes conditional expectation given fng. 23 For the Ising model with the usual convention = 1, (6.9) can be written more simply as h i j i Ising = hfl ij i RC;q=2 : (6.11) 23 For an excellent introduction to conditional expectations, see <ref> [50] </ref>. 47 Similar identities can be proven for higher-order correlation functions, and can be em-ployed to prove Griffiths-type correlation inequalities for the Potts model [51, 52]. On the other hand, Swendsen and Wang [27] exploited facts (b)-(e) to devise a radically new type of Monte Carlo algorithm.
Reference: [51] <author> R.H. </author> <title> Schonmann, </title> <journal> J. Stat. Phys. </journal> <volume> 52, </volume> <month> 61 </month> <year> (1988). </year>
Reference-contexts: be written more simply as h i j i Ising = hfl ij i RC;q=2 : (6.11) 23 For an excellent introduction to conditional expectations, see [50]. 47 Similar identities can be proven for higher-order correlation functions, and can be em-ployed to prove Griffiths-type correlation inequalities for the Potts model <ref> [51, 52] </ref>. On the other hand, Swendsen and Wang [27] exploited facts (b)-(e) to devise a radically new type of Monte Carlo algorithm.
Reference: [52] <author> A.D. Sokal, </author> <note> unpublished. 70 </note>
Reference-contexts: be written more simply as h i j i Ising = hfl ij i RC;q=2 : (6.11) 23 For an excellent introduction to conditional expectations, see [50]. 47 Similar identities can be proven for higher-order correlation functions, and can be em-ployed to prove Griffiths-type correlation inequalities for the Potts model <ref> [51, 52] </ref>. On the other hand, Swendsen and Wang [27] exploited facts (b)-(e) to devise a radically new type of Monte Carlo algorithm.
Reference: [53] <author> E.M. Reingold, J. Nievergelt and N. Deo, </author> <title> Combinatorial Algorithms: </title> <booktitle> Theory and Practice (Prentice-Hall, </booktitle> <address> Englewood Cliffs, N.J., </address> <year> 1977), </year> <title> Chapter 8; A. Gibbons, Algorithmic Graph Theory (Cambridge University Press, 1985), Chapter 1; S. Even, Graph Algorithms (Computer Science Press, </title> <address> Potomac, Maryland, </address> <year> 1979), </year> <note> Chapter 3. </note>
Reference-contexts: In some sense, therefore, the SW algorithm is a collective-mode algorithm in which the collective modes are chosen by the system 24 Determining the connected components of an undirected graph is a classic problem of computer science. The depth-first-search and breadth-first-search algorithms <ref> [53] </ref> have a running time of order V , while the Fischer-Galler-Hoshen-Kopelman algorithm (in one of its variants) [54] has a worst-case running time of order V log V , and an observed mean running time of order V in percolation-type problems [55]. Both of these algorithms are non-vectorizable.
Reference: [54] <author> B.A. Galler and M.J. </author> <title> Fischer, </title> <journal> Commun. ACM 7, </journal> <volume> 301, </volume> <booktitle> 506 (1964); D.E. Knuth, The Art of Computer Programming, </booktitle> <volume> vol. </volume> <pages> 1, </pages> <address> 2 nd ed., </address> <publisher> (Addison-Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1973), </year> <pages> pp. 353-355, </pages> <note> 360, 572; J. </note> <editor> Hoshen and R. Kopelman, Phys. Rev. B14, </editor> <month> 3438 </month> <year> (1976). </year>
Reference-contexts: The depth-first-search and breadth-first-search algorithms [53] have a running time of order V , while the Fischer-Galler-Hoshen-Kopelman algorithm (in one of its variants) <ref> [54] </ref> has a worst-case running time of order V log V , and an observed mean running time of order V in percolation-type problems [55]. Both of these algorithms are non-vectorizable.
Reference: [55] <author> K. Binder and D. Stauffer, </author> <title> in Applications of the Monte Carlo Method in Statistical Physics, </title> <editor> ed. K. </editor> <publisher> Binder (Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1984), </year> <title> section 8.4; D. Stauffer, Introduction to Percolation Theory (Taylor & Francis, </title> <address> London, </address> <year> 1985). </year>
Reference-contexts: The depth-first-search and breadth-first-search algorithms [53] have a running time of order V , while the Fischer-Galler-Hoshen-Kopelman algorithm (in one of its variants) [54] has a worst-case running time of order V log V , and an observed mean running time of order V in percolation-type problems <ref> [55] </ref>. Both of these algorithms are non-vectorizable. Shiloach and Vishkin [56] have invented a SIMD parallel algorithm, and we have very recently vectorized it for the Cyber 205, obtaining a speedup of a factor of 11 over scalar mode.
Reference: [56] <author> Y. Shiloach and U. Vishkin, J. </author> <booktitle> Algorithms 3, </booktitle> <month> 57 </month> <year> (1982). </year>
Reference-contexts: Both of these algorithms are non-vectorizable. Shiloach and Vishkin <ref> [56] </ref> have invented a SIMD parallel algorithm, and we have very recently vectorized it for the Cyber 205, obtaining a speedup of a factor of 11 over scalar mode.
Reference: [57] <author> R.G. Edwards, X.-J. Li and A.D. Sokal, </author> <title> Sequential and vectorized algorithms for computing the connected components of an undirected graph, </title> <note> unpublished (and uncompleted) notes. </note>
Reference-contexts: We are currently carrying out a comparative test of these three algorithms, as a function of lattice size and bond density <ref> [57] </ref>.
Reference: [58] <author> P.W. </author> <title> Kasteleyn and C.M. </title> <journal> Fortuin, J. Phys. Soc. </journal> <note> Japan 26 (Suppl.), 11 (1969); C.M. Fortuin and P.W. Kasteleyn, Physica 57, 536 (1972); C.M. Fortuin, Physica 58, 393 (1972); C.M. Fortuin, Physica 59, 545 (1972). </note>
Reference-contexts: It is also an algorithm for simulating the Potts and random-cluster models, since expectations in these two models are equal to the corresponding expectations in the FKSW model. Historical remark. The random-cluster model was introduced in 1969 by Fortuin and Kasteleyn <ref> [58] </ref>; they derived the identity Z P otts = Z RC , along with the correlation-function identity (6.9) and some generalizations. These relations were rediscovered several times during the subsequent two decades [59].
Reference: [59] <author> C.-K. Hu, </author> <note> Phys. Rev. B29, 5103 (1984); T.A. Larsson, J. Phys. A19, 2383 (1986) and A20, 2239 (1987). </note>
Reference-contexts: Historical remark. The random-cluster model was introduced in 1969 by Fortuin and Kasteleyn [58]; they derived the identity Z P otts = Z RC , along with the correlation-function identity (6.9) and some generalizations. These relations were rediscovered several times during the subsequent two decades <ref> [59] </ref>. Surprisingly, however, no one seems to have noticed the joint probability distribution F KSW that underlay all these identities; this was discovered implicitly by Swendsen and Wang [27], and was made explicit by Edwards and Sokal [60].
Reference: [60] <author> R.G. Edwards and A.D. </author> <title> Sokal, </title> <journal> Phys. Rev. </journal> <volume> D38, </volume> <year> 2009 (1988). </year>
Reference-contexts: These relations were rediscovered several times during the subsequent two decades [59]. Surprisingly, however, no one seems to have noticed the joint probability distribution F KSW that underlay all these identities; this was discovered implicitly by Swendsen and Wang [27], and was made explicit by Edwards and Sokal <ref> [60] </ref>. It is certainly plausible that the SW algorithm might have less critical slowing-down than the conventional (single-spin-update) algorithms: the reason is that a local move in one set of variables can have highly nonlocal effects in the other. <p> In the past year there has been a flurry of papers trying to generalize the SW algorithm to non-Potts models. Interesting proposals for a direct generalization of the SW algorithm were made by Edwards and Sokal <ref> [60] </ref> and by Niedermayer [70]. But the most promising ideas at present seem to be the embedding algorithms proposed by Brower and Tamayo [71] for one-component ' 4 models and by Wolff [65, 72] for multi-component O (n)-invariant models.
Reference: [61] <author> A.D. Sokal, </author> <title> in Computer Simulation Studies in Condensed Matter Physics: Recent Developments (Athens, </title> <address> Georgia, </address> <month> 15-26 February </month> <year> 1988), </year> <editor> ed. D.P. Landau, K.K. Mon and H.-B. </editor> <publisher> Schuttler (Springer-Verlag, </publisher> <address> Berlin-Heidelberg, </address> <year> 1988). </year>
Reference-contexts: Table 1 shows some preliminary data <ref> [61] </ref> on a two-dimensional Ising model at the bulk critical temperature. These data are consistent with the estimate t SW ~ L 0:35 [27]. 25 By contrast, the conventional single-spin-flip algorithms for the two-dimensional Ising model have t conv ~ L 2:1 [21].
Reference: [62] <author> X.-J. Li and A.D. </author> <title> Sokal, </title> <journal> Phys. Rev. Lett. </journal> <volume> 63, </volume> <month> 827 </month> <year> (1989). </year>
Reference-contexts: Estimates are taken from [27] for d = 2; 3, q = 2; <ref> [62] </ref> for d = 2, q = 3; 4; and [63] for d = 4, q = 2. <p> This suggests (but of course does not prove) that z SW = 1 for Ising models (q = 2) in dimension d 4. b) A rigorous proof that z SW ff=- <ref> [62] </ref>. This bound, while valid for all d and q, is extremely far from sharp for the Ising models in dimensions 3 and higher. <p> spin ) t N ) = (N ; (P spin P bond P spin ) t N ) (8.29) It follows that N N (t) N N (1) jtj (1 const=C H ) jtj (8.30) and hence t int;N const fi C H : (8.31) This proves a lower bound <ref> [62] </ref> on the dynamic critical exponent z SW , namely z SW ff=-. (Here ff and are the static critical exponents for the susceptibility and correlation length, respectively.) For the two-dimensional Potts models with q = 2; 3; 4, it is known exactly (but non-rigorously!) that ff=- = 0; 2 5 <p> The bound on z SW may be conceivably be sharp (or sharp up to a logarithm) for q = 4 <ref> [62] </ref>. Example 3. Berretti-Sokal algorithm for SAWs. Let us consider the observable f (!) = j!j (= N ) ; (8.32) the total number of bonds in the walk.
Reference: [63] <author> W. Klein, T. Ray and P. </author> <title> Tamayo, </title> <journal> Phys. Rev. Lett. </journal> <volume> 62, </volume> <month> 163 </month> <year> (1989). </year>
Reference-contexts: Estimates are taken from [27] for d = 2; 3, q = 2; [62] for d = 2, q = 3; 4; and <ref> [63] </ref> for d = 4, q = 2.
Reference: [64] <author> T.S. Ray, P. Tamayo and W. Klein, </author> <note> Phys. Rev. A39, 5949 (1989). </note>
Reference-contexts: But the remainder of our understanding is very murky. Two principal insights have been obtained so far: a) A calculation yielding z SW = 1 in a mean-field (Curie-Weiss) Ising model <ref> [64] </ref>. This suggests (but of course does not prove) that z SW = 1 for Ising models (q = 2) in dimension d 4. b) A rigorous proof that z SW ff=- [62].
Reference: [65] <author> U. </author> <title> Wolff, </title> <journal> Phys. Rev. Lett. </journal> <volume> 62, </volume> <month> 361 </month> <year> (1989). </year>
Reference-contexts: These data appear to be consistent with sharpness modulo a logarithm, i.e. t SW =C H ~ log L. 50 configurations that contain interfaces of surface area ~ L d1 and therefore have an equilibrium probability ~ exp (cL d1 ). 28 Wolff <ref> [65] </ref> has proposed a interesting modification of the SW algorithm, in which one builds only a single cluster (starting at a randomly chosen site) and flips it. <p> Interesting proposals for a direct generalization of the SW algorithm were made by Edwards and Sokal [60] and by Niedermayer [70]. But the most promising ideas at present seem to be the embedding algorithms proposed by Brower and Tamayo [71] for one-component ' 4 models and by Wolff <ref> [65, 72] </ref> for multi-component O (n)-invariant models. The idea of the embedding algorithms is to find Ising-like variables underlying a general spin variable, and then to update the resulting Ising model using the ordinary SW algorithm (or the single-cluster variant).
Reference: [66] <author> U. </author> <title> Wolff, </title> <journal> Phys. Lett. </journal> <note> B228, 379 (1989); P. Tamayo, R.C. </note> <author> Brower and W. Klein, J. </author> <title> Stat. </title> <journal> Phys. </journal> <volume> 58, </volume> <booktitle> 1083 (1990) and 60, </booktitle> <month> 889 </month> <year> (1990). </year>
Reference-contexts: So it would not be surprising if z 1cluster;CP U were smaller than z SW . Preliminary measurements indicate that z 1cluster;CP U is about the same as z SW for the two-dimensional Ising model, but is significantly smaller for the three- and four-dimensional Ising models <ref> [66] </ref>. But a convincing theoretical understanding of this behavior is lacking.
Reference: [67] <author> D. Kandel, E. Domany, D. Ron, A. Brandt and E. </author> <title> Loh, </title> <journal> Phys. Rev. Lett. </journal> <note> 60, 1591 (1988); D. </note> <author> Kandel, E. Domany and A. </author> <title> Brandt, </title> <journal> Phys. Rev. B40, </journal> <volume> 330 (1989). </volume> <pages> 71 </pages>
Reference-contexts: Several other generalizations of the SW algorithm for Potts models have been proposed. 29 One is a multi-grid extension of the SW algorithm: the idea is to carry out only a partial FKSW transformation, but then to apply this concept recursively <ref> [67] </ref>.
Reference: [68] <author> R.G. Edwards and A.D. Sokal, </author> <title> Swendsen-Wang algorithm augmented by duality transformations for the two-dimensional Potts model, </title> <note> in preparation. </note>
Reference-contexts: Thus, the critical slowing-down is not completely eliminated in any model in which the specific heat is divergent. 51 generalization, which works only in two dimensions, augments the SW algorithm by transformations to the dual lattice <ref> [68] </ref>. This algorithm appears to achieve a modest improvement in critical slowing-down in the scaling region jfi fi c j ~ L 1=- .
Reference: [69] <author> R. Ben-Av, D. Kandel, E. Katznelson, P.G. Lauwers and S. Solomon, J. </author> <title> Stat. </title> <journal> Phys. </journal> <volume> 58, 125 (1990); R.C. </volume> <editor> Brower and S. Huang, Phys. Rev. B41, </editor> <month> 708 </month> <year> (1990). </year>
Reference-contexts: Preliminary results for the three-dimensional Z 2 gauge theory yield a dynamic critical exponent roughly equal to that of the ordinary SW algorithm for the three-dimensional Ising model (to which the gauge theory is dual) <ref> [69] </ref>. In the past year there has been a flurry of papers trying to generalize the SW algorithm to non-Potts models. Interesting proposals for a direct generalization of the SW algorithm were made by Edwards and Sokal [60] and by Niedermayer [70].
Reference: [70] <author> F. </author> <title> Niedermayer, </title> <journal> Phys. Rev. Lett. </journal> <volume> 61, </volume> <year> 2026 (1988). </year>
Reference-contexts: In the past year there has been a flurry of papers trying to generalize the SW algorithm to non-Potts models. Interesting proposals for a direct generalization of the SW algorithm were made by Edwards and Sokal [60] and by Niedermayer <ref> [70] </ref>. But the most promising ideas at present seem to be the embedding algorithms proposed by Brower and Tamayo [71] for one-component ' 4 models and by Wolff [65, 72] for multi-component O (n)-invariant models.
Reference: [71] <author> R.C. Brower and P. </author> <title> Tamayo, </title> <journal> Phys. Rev. Lett. </journal> <volume> 62, </volume> <month> 1087 </month> <year> (1989). </year>
Reference-contexts: Interesting proposals for a direct generalization of the SW algorithm were made by Edwards and Sokal [60] and by Niedermayer [70]. But the most promising ideas at present seem to be the embedding algorithms proposed by Brower and Tamayo <ref> [71] </ref> for one-component ' 4 models and by Wolff [65, 72] for multi-component O (n)-invariant models. The idea of the embedding algorithms is to find Ising-like variables underlying a general spin variable, and then to update the resulting Ising model using the ordinary SW algorithm (or the single-cluster variant). <p> Therefore, the f"g model can be updated by the Swendsen-Wang algorithm. (Heat-bath or MGMC sweeps must also be performed, in order to update the magnitudes.) For the two-dimensional ' 4 model, Brower and Tamayo <ref> [71] </ref> find a dynamic critical behavior identical to that of the SW algorithm for the two-dimensional Ising model | just as one would expect based on the idea that the "important" collective modes in the ' 4 model are spin flips.
Reference: [72] <author> U. </author> <type> Wolff, </type> <institution> Nucl. Phys. B322, 759 (1989); Phys. Lett. B222, 473 (1989); Nucl. Phys. B334, </institution> <month> 581 </month> <year> (1990). </year>
Reference-contexts: Interesting proposals for a direct generalization of the SW algorithm were made by Edwards and Sokal [60] and by Niedermayer [70]. But the most promising ideas at present seem to be the embedding algorithms proposed by Brower and Tamayo [71] for one-component ' 4 models and by Wolff <ref> [65, 72] </ref> for multi-component O (n)-invariant models. The idea of the embedding algorithms is to find Ising-like variables underlying a general spin variable, and then to update the resulting Ising model using the ordinary SW algorithm (or the single-cluster variant). <p> So it is quite plausible that critical slowing-down could be eliminated or almost eliminated. In fact, tests of this algorithm on the two-dimensional XY (n = 2), classical Heisenberg (n = 3) and O (4) models are consistent with the complete absence of critical slowing-down <ref> [72, 73] </ref>. In view of the extraordinary success of the Wolff algorithm for spin models, it is tempting to try to extend it to lattice gauge theories with continuous gauge group [for example, U (1), SU (N ) or SO (N )].
Reference: [73] <author> R.G. Edwards and A.D. </author> <title> Sokal, </title> <journal> Phys. Rev. </journal> <volume> D40, </volume> <month> 1374 </month> <year> (1989). </year>
Reference-contexts: So it is quite plausible that critical slowing-down could be eliminated or almost eliminated. In fact, tests of this algorithm on the two-dimensional XY (n = 2), classical Heisenberg (n = 3) and O (4) models are consistent with the complete absence of critical slowing-down <ref> [72, 73] </ref>. In view of the extraordinary success of the Wolff algorithm for spin models, it is tempting to try to extend it to lattice gauge theories with continuous gauge group [for example, U (1), SU (N ) or SO (N )].
Reference: [74] <author> P.G. DeGennes, </author> <title> Scaling Concepts in Polymer Physics (Cornell Univ. </title> <publisher> Press, </publisher> <address> Ithaca NY, </address> <year> 1979). </year>
Reference-contexts: The SAW has direct application in polymer physics <ref> [74] </ref>, and is indirectly relevant to ferromagnetism and quantum field theory by virtue of its equivalence with the n ! 0 limit of the n-vector model [75].
Reference: [75] <author> C. Arag~ao de Carvalho, S. Caracciolo and J. </author> <month> Frohlich, </month> <institution> Nucl. Phys. B215 [FS7], </institution> <month> 209 </month> <year> (1983). </year>
Reference-contexts: The SAW has direct application in polymer physics [74], and is indirectly relevant to ferromagnetism and quantum field theory by virtue of its equivalence with the n ! 0 limit of the n-vector model <ref> [75] </ref>. <p> The connective constant and the critical exponent ff sing can be estimated from the Monte Carlo data, using the method of maximum likelihood. A dynamic Monte Carlo algorithm for this ensemble was proposed by Berg and Foerster [79] and Arag~ao de Carvalho, Caracciolo and Frohlich (BFACF) <ref> [75, 80] </ref>. The elementary moves are local deformations of the chain, with N = 0; 2. The critical slowing-down in the BFACF algorithm is quite subtle.
Reference: [76] <author> A. Berretti and A.D. Sokal, J. </author> <title> Stat. </title> <journal> Phys. </journal> <volume> 40, </volume> <month> 483 </month> <year> (1985). </year>
Reference-contexts: As fi approaches the critical activity fi c , the average walk length hN i tends to infinity. The connective constant and the critical exponent fl can be estimated from the Monte Carlo data, using the method of maximum likelihood <ref> [76] </ref>. A dynamic Monte Carlo algorithm for this ensemble was proposed by Berretti and Sokal [76]. <p> The connective constant and the critical exponent fl can be estimated from the Monte Carlo data, using the method of maximum likelihood <ref> [76] </ref>. A dynamic Monte Carlo algorithm for this ensemble was proposed by Berretti and Sokal [76]. The algorithm's elementary moves are as follows: either one attempts to append a new step to the walk, with equal probability in each of the q possible directions (here q is the coordination number of the lattice); or else one deletes the last step from the walk.
Reference: [77] <author> G. Lawler and A.D. </author> <title> Sokal, </title> <journal> Trans. Amer. Math. Soc. </journal> <volume> 309, </volume> <month> 557 </month> <year> (1988). </year>
Reference-contexts: With considerably more work, it is possible to prove an upper bound on t that is only slightly weaker than the heuristic prediction: t constfihN i 1+fl <ref> [10, 77] </ref>. 36 (Note that the critical exponent fl is believed to equal 43=32 in dimension d = 2, 1:16 in d = 3, and 1 in d 4.) In fact, we suspect [78] that the true behavior is t ~ hN i p for some exponent p strictly between 2 <p> The only general method (to my knowledge) for proving upper bounds on the autocorrelation time is Cheeger's inequality <ref> [77, 92, 93] </ref>, the basic idea of which is to search for "bottlenecks" in the state space. 40 Consider first the rate of probability flow, in 40 Note Added 1996: There is now an extensive literature (largely by probabilists and theoretical computer scientists) on upper bounds on the autocorrelation time for <p> The precise statement is the following <ref> [77, Theorem 2.1] </ref>: Theorem 3 Let P be a transition probability matrix satisfying detailed balance for , and let k be defined as above. <p> The most tractable case seems to be when the state space is a tree: then A can always be chosen so that it is connected to A c by a single bond. Using this fact, Lawler and Sokal <ref> [77] </ref> used Cheeger's inequality to prove t 0 exp const fi hN i 2fl (8.48) for the Berretti-Sokal algorithm for SAWs. A very different proof of an upper bound on t 0 exp in the Berretti-Sokal algorithm was given by Sokal and Thomas [10].
Reference: [78] <author> G. Lawler and A.D. Sokal, </author> <note> in preparation. </note>
Reference-contexts: upper bound on t that is only slightly weaker than the heuristic prediction: t constfihN i 1+fl [10, 77]. 36 (Note that the critical exponent fl is believed to equal 43=32 in dimension d = 2, 1:16 in d = 3, and 1 in d 4.) In fact, we suspect <ref> [78] </ref> that the true behavior is t ~ hN i p for some exponent p strictly between 2 and 1 + fl. A deeper understanding of the dynamic critical behavior of the Berretti-Sokal algorithm would be of definite value.
Reference: [79] <author> B. Berg and D. </author> <title> Foerster, </title> <journal> Phys. Lett. </journal> <volume> 106B, </volume> <month> 323 </month> <year> (1981). </year>
Reference-contexts: The connective constant and the critical exponent ff sing can be estimated from the Monte Carlo data, using the method of maximum likelihood. A dynamic Monte Carlo algorithm for this ensemble was proposed by Berg and Foerster <ref> [79] </ref> and Arag~ao de Carvalho, Caracciolo and Frohlich (BFACF) [75, 80]. The elementary moves are local deformations of the chain, with N = 0; 2. The critical slowing-down in the BFACF algorithm is quite subtle.
Reference: [80] <author> C. Arag~ao de Carvalho and S. Caracciolo, J. </author> <type> Physique 44, </type> <month> 323 </month> <year> (1983). </year>
Reference-contexts: The connective constant and the critical exponent ff sing can be estimated from the Monte Carlo data, using the method of maximum likelihood. A dynamic Monte Carlo algorithm for this ensemble was proposed by Berg and Foerster [79] and Arag~ao de Carvalho, Caracciolo and Frohlich (BFACF) <ref> [75, 80] </ref>. The elementary moves are local deformations of the chain, with N = 0; 2. The critical slowing-down in the BFACF algorithm is quite subtle.
Reference: [81] <author> A. D. Sokal and L. E. Thomas, J. </author> <title> Stat. </title> <journal> Phys. </journal> <volume> 51, </volume> <month> 907 </month> <year> (1988). </year>
Reference-contexts: The elementary moves are local deformations of the chain, with N = 0; 2. The critical slowing-down in the BFACF algorithm is quite subtle. On the one hand, Sokal and Thomas <ref> [81] </ref> have proven the surprising result that t exp = +1 for all fi 6= 0 (see Section 8). On the other hand, numerical experiments [12, 82] show that t int;N ~ hN i 3:00:4 (in d = 2). <p> we have hN i 1 fi hN 2 i 1 fi asymptotically as fi " fi c = 1 , and hence t int;N const fi hN i 2 : (8.37) A very different approach to proving lower bounds on the autocorrelation time t exp is the minimum hitting-time argument <ref> [81] </ref>. Consider a Markov chain with transition matrix P satisfying detailed balance for some probability measure . If A and B are subsets of the state space S, let T AB be the minimum time for getting from A to B with nonzero probability, i.e. <p> Using Chebyshev polynomials, a stronger bound can be proven: roughly speaking, t exp is bounded below by the square of the RHS of (8.39). For details, see <ref> [81, Theorem 3.1] </ref>. Let us apply this theorem to the BFACF algorithm for variable-length fixed-endpoint SAWs. Let ! fl be a fixed short walk from 0 to x, and let ! n be a quasi-rectangular walk from 0 to x of linear size n.
Reference: [82] <author> S. Caracciolo, A. Pelissetto and A.D. Sokal, J. </author> <title> Stat. </title> <journal> Phys. </journal> <volume> 60, </volume> <month> 1 </month> <year> (1990). </year>
Reference-contexts: The critical slowing-down in the BFACF algorithm is quite subtle. On the one hand, Sokal and Thomas [81] have proven the surprising result that t exp = +1 for all fi 6= 0 (see Section 8). On the other hand, numerical experiments <ref> [12, 82] </ref> show that t int;N ~ hN i 3:00:4 (in d = 2). Clearly, the BFACF dynamics is not well understood at present: further work, both theoretical and numerical, is needed. <p> On the other hand, numerical experiments [12, 82] show that t int;N ~ hN i 3:00:4 (in d = 2). Clearly, the BFACF dynamics is not well understood at present: further work, both theoretical and numerical, is needed. In addition, Caracciolo, Pelissetto and Sokal <ref> [82] </ref> are studying a "hybrid" algorithm that combines local (BFACF) moves with non-local (cut-and-paste) moves. The critical slowing-down, measured in CPU units, appears to be reduced slightly compared to the pure BFACF algorithm: t ~ hN i 2:3 in d = 2. Canonical ensemble.
Reference: [83] <author> M. Delbruck, </author> <title> in Mathematical Problems in the Biological Sciences (Proc. </title> <journal> Symp. Appl. Math., </journal> <volume> vol. 14), </volume> <editor> ed. R.E. </editor> <publisher> Bellman (American Math. Soc., </publisher> <address> Providence RI, </address> <year> 1962). </year>
Reference-contexts: Canonical ensemble. Algorithms for this ensemble, based on local deformations of the chain, have been used by polymer physicists for more than 25 years <ref> [83, 84] </ref>. So the recent proof [85] that all such algorithms are nonergodic (= not irreducible) comes as a slight embarrassment.
Reference: [84] <author> P.H. Verdier and W.H. Stockmayer, J. </author> <title> Chem. </title> <journal> Phys. </journal> <volume> 36, </volume> <month> 227 </month> <year> (1962). </year>
Reference-contexts: Canonical ensemble. Algorithms for this ensemble, based on local deformations of the chain, have been used by polymer physicists for more than 25 years <ref> [83, 84] </ref>. So the recent proof [85] that all such algorithms are nonergodic (= not irreducible) comes as a slight embarrassment.
Reference: [85] <author> N. </author> <title> Madras and A.D. </title> <journal> Sokal, J. Stat. Phys. </journal> <volume> 47, </volume> <month> 573 </month> <year> (1987). </year>
Reference-contexts: Canonical ensemble. Algorithms for this ensemble, based on local deformations of the chain, have been used by polymer physicists for more than 25 years [83, 84]. So the recent proof <ref> [85] </ref> that all such algorithms are nonergodic (= not irreducible) comes as a slight embarrassment. Fortunately, there does exist a non-local fixed-N algorithm which is ergodic: the "pivot" algorithm, invented by Lal [86] and independently reinvented by MacDonald et al. [87] and by Madras [16].
Reference: [86] <author> M. </author> <title> Lal, </title> <journal> Molec. Phys. </journal> <volume> 17, </volume> <month> 57 </month> <year> (1969). </year>
Reference-contexts: So the recent proof [85] that all such algorithms are nonergodic (= not irreducible) comes as a slight embarrassment. Fortunately, there does exist a non-local fixed-N algorithm which is ergodic: the "pivot" algorithm, invented by Lal <ref> [86] </ref> and independently reinvented by MacDonald et al. [87] and by Madras [16].
Reference: [87] <editor> B. MacDonald et al., J. Phys. A18, </editor> <month> 2627 </month> <year> (1985). </year>
Reference-contexts: So the recent proof [85] that all such algorithms are nonergodic (= not irreducible) comes as a slight embarrassment. Fortunately, there does exist a non-local fixed-N algorithm which is ergodic: the "pivot" algorithm, invented by Lal [86] and independently reinvented by MacDonald et al. <ref> [87] </ref> and by Madras [16].
Reference: [88] <author> K. </author> <title> Kawasaki, </title> <journal> Phys. Rev. </journal> <volume> 148, </volume> <month> 375 </month> <year> (1966). </year>
Reference-contexts: If we measure time in hits per site, then we conclude that t int;M 2V This proves a lower bound <ref> [88, 89, 90] </ref> on the dynamic critical exponent z, namely z fl=-. (Here fl and are the static critical exponents for the susceptibility and correlation length, respectively. Note that by the usual static scaling law, fl=- = 2 ; and for most models is very close to zero.
Reference: [89] <author> B.I. </author> <title> Halperin, </title> <journal> Phys. Rev. B8, </journal> <volume> 4437 (1973). </volume> <pages> 72 </pages>
Reference-contexts: If we measure time in hits per site, then we conclude that t int;M 2V This proves a lower bound <ref> [88, 89, 90] </ref> on the dynamic critical exponent z, namely z fl=-. (Here fl and are the static critical exponents for the susceptibility and correlation length, respectively. Note that by the usual static scaling law, fl=- = 2 ; and for most models is very close to zero.
Reference: [90] <author> R. Alicki, M. Fannes and A. Verbeure, J. </author> <title> Stat. </title> <journal> Phys. </journal> <volume> 41, </volume> <month> 263 </month> <year> (1985). </year>
Reference-contexts: If we measure time in hits per site, then we conclude that t int;M 2V This proves a lower bound <ref> [88, 89, 90] </ref> on the dynamic critical exponent z, namely z fl=-. (Here fl and are the static critical exponents for the susceptibility and correlation length, respectively. Note that by the usual static scaling law, fl=- = 2 ; and for most models is very close to zero.
Reference: [91] <author> M.P.M. den Nijs, J. Phys. A12, </author> <month> 1857 </month> <year> (1979); </year> <month> J.L. </month> <title> Black and V.J. Emery, </title> <journal> Phys. Rev. B23, 429 (1981); B. Nienhuis, J. Stat. Phys. </journal> <volume> 34, </volume> <month> 731 </month> <year> (1984). </year>
Reference-contexts: SW ff=-. (Here ff and are the static critical exponents for the susceptibility and correlation length, respectively.) For the two-dimensional Potts models with q = 2; 3; 4, it is known exactly (but non-rigorously!) that ff=- = 0; 2 5 ; 1, with multiplicative logarithmic corrections for q = 4 <ref> [91] </ref>. The bound on z SW may be conceivably be sharp (or sharp up to a logarithm) for q = 4 [62]. Example 3. Berretti-Sokal algorithm for SAWs. Let us consider the observable f (!) = j!j (= N ) ; (8.32) the total number of bonds in the walk.
Reference: [92] <author> A. Sinclair and M. </author> <title> Jerrum, </title> <booktitle> Information and Computation 82, </booktitle> <month> 93 </month> <year> (1989). </year>
Reference-contexts: The only general method (to my knowledge) for proving upper bounds on the autocorrelation time is Cheeger's inequality <ref> [77, 92, 93] </ref>, the basic idea of which is to search for "bottlenecks" in the state space. 40 Consider first the rate of probability flow, in 40 Note Added 1996: There is now an extensive literature (largely by probabilists and theoretical computer scientists) on upper bounds on the autocorrelation time for
Reference: [93] <author> R. Brooks, P. Doyle and R. Kohn, </author> <note> in preparation. </note>
Reference-contexts: The only general method (to my knowledge) for proving upper bounds on the autocorrelation time is Cheeger's inequality <ref> [77, 92, 93] </ref>, the basic idea of which is to search for "bottlenecks" in the state space. 40 Consider first the rate of probability flow, in 40 Note Added 1996: There is now an extensive literature (largely by probabilists and theoretical computer scientists) on upper bounds on the autocorrelation time for
Reference: [94] <author> L.N. Vasershtein, </author> <title> Prob. </title> <journal> Inform. Transm. </journal> <volume> 5, </volume> <month> 64 </month> <year> (1969). </year>
Reference-contexts: For the single-site heat-bath dynamics, it is easy to show that t exp &lt; 1 (uniformly in the volume) above the Dobrushin uniqueness temperature; indeed, this is precisely what the standard proof of the Dobrushin uniqueness theorem <ref> [94, 95] </ref> does.
Reference: [95] <author> O.E. Lanford III, </author> <title> in Statistical Mechanics and Mathematical Problems (Lecture Notes in Physics #20), </title> <editor> ed. A. </editor> <publisher> Lenard (Springer, </publisher> <address> Berlin, </address> <year> 1973). </year>
Reference-contexts: For the single-site heat-bath dynamics, it is easy to show that t exp &lt; 1 (uniformly in the volume) above the Dobrushin uniqueness temperature; indeed, this is precisely what the standard proof of the Dobrushin uniqueness theorem <ref> [94, 95] </ref> does.
Reference: [96] <author> M. Aizenman and R. Holley, </author> <title> in Percolation Theory and Ergodic Theory of Infinite Particle Systems, </title> <editor> ed. H. </editor> <publisher> Kesten (Springer, </publisher> <address> New York, </address> <year> 1987). </year> <note> ADDED BIBLIOGRAPHY (DECEMBER 1996): </note>
Reference-contexts: One expects the same result to hold for all temperatures above critical, but this remains an open problem, despite recent progress by Aizenman and Holley <ref> [96] </ref>. 42 Acknowledgments Many of the ideas reported here have grown out of joint work with my colleagues Al-berto Berretti, Frank Brown, Sergio Caracciolo, Robert Edwards, Jonathan Goodman, Tony Guttmann, Greg Lawler, Xiao-Jian Li, Neal Madras, Andrea Pelissetto, Larry Thomas and Dan Zwanziger.
Reference: [97] <author> M. Luscher, P. Weisz and U. </author> <type> Wolff, </type> <institution> Nucl. Phys. B359, </institution> <month> 221 </month> <year> (1991). </year>
Reference-contexts: Typically one approaches the critical point with L c~, where c 24, and then uses finite-size scaling [22, 23] to extrapolate to the infinite-volume limit. Note Added 1996: Recently, radical advances have been made in applying finite-size scaling to Monte Carlo simulations (see <ref> [97, 98] </ref> and especially [99, 100, 101, 102, 103]); the preceding two sentences can now be seen to be far too pessimistic.
Reference: [98] <author> J.-K. Kim, </author> <title> Phys. </title> <journal> Rev. Lett. 70, 1735 (1993); Nucl. Phys. B (Proc. </journal> <volume> Suppl.) </volume> <pages> 34, </pages> <note> 702 (1994); Phys. Rev. D50, 4663 (1994); Europhys. Lett. 28, 211 (1994); Phys. Lett. B345, 469 (1995). </note>
Reference-contexts: Typically one approaches the critical point with L c~, where c 24, and then uses finite-size scaling [22, 23] to extrapolate to the infinite-volume limit. Note Added 1996: Recently, radical advances have been made in applying finite-size scaling to Monte Carlo simulations (see <ref> [97, 98] </ref> and especially [99, 100, 101, 102, 103]); the preceding two sentences can now be seen to be far too pessimistic.
Reference: [99] <author> S. Caracciolo, R.G. Edwards, S.J. Ferreira, A. Pelissetto and A.D. </author> <title> Sokal, </title> <journal> Phys. Rev. Lett. </journal> <volume> 74, </volume> <month> 2969 </month> <year> (1995). </year>
Reference-contexts: Typically one approaches the critical point with L c~, where c 24, and then uses finite-size scaling [22, 23] to extrapolate to the infinite-volume limit. Note Added 1996: Recently, radical advances have been made in applying finite-size scaling to Monte Carlo simulations (see [97, 98] and especially <ref> [99, 100, 101, 102, 103] </ref>); the preceding two sentences can now be seen to be far too pessimistic.
Reference: [100] <author> S.J. Ferreira and A.D. </author> <title> Sokal, </title> <journal> Phys. Rev. </journal> <volume> B51, </volume> <month> 6720 </month> <year> (1995). </year>
Reference-contexts: Typically one approaches the critical point with L c~, where c 24, and then uses finite-size scaling [22, 23] to extrapolate to the infinite-volume limit. Note Added 1996: Recently, radical advances have been made in applying finite-size scaling to Monte Carlo simulations (see [97, 98] and especially <ref> [99, 100, 101, 102, 103] </ref>); the preceding two sentences can now be seen to be far too pessimistic. <p> See [115, 116, 117, 118, 119] for reviews. 29 Note Added 1996: In addition to the generalizations discussed below, see [120, 112] for SW-type algorithms for the Ashkin-Teller model; see [121] for a clever SW-type algorithm for the fully frustrated Ising model; and see <ref> [122, 123, 124, 100] </ref> for a very interesting SW-type algorithm for antiferromagnetic Potts models, based on the "embedding" idea to be described below. 30 Note Added 1996: For at least some versions of the multi-grid SW algorithm, it can be proven [125] that the bound z MGSW ff=- holds.
Reference: [101] <author> S. Caracciolo, R.G. Edwards, A. Pelissetto and A.D. </author> <title> Sokal, </title> <journal> Phys. Rev. Lett. </journal> <volume> 75, </volume> <month> 1891 </month> <year> (1995). </year>
Reference-contexts: Typically one approaches the critical point with L c~, where c 24, and then uses finite-size scaling [22, 23] to extrapolate to the infinite-volume limit. Note Added 1996: Recently, radical advances have been made in applying finite-size scaling to Monte Carlo simulations (see [97, 98] and especially <ref> [99, 100, 101, 102, 103] </ref>); the preceding two sentences can now be seen to be far too pessimistic. <p> In practice, reliable infinite-volume values (with both statistical and systematic errors of order a few percent) can be obtained at ~ ~ 10 5 from lattices of size L ~ 10 2 , at least in some models <ref> [101, 102, 103] </ref>. or eliminated by a more clever algorithm. What is to be done? Our knowledge of the physics of critical slowing-down tells us that the slow modes are the long-wavelength modes, if the updating is purely local.
Reference: [102] <author> G. Mana, A. Pelissetto and A.D. </author> <title> Sokal, </title> <journal> Phys. Rev. </journal> <volume> D54, </volume> <month> R1252 </month> <year> (1996). </year>
Reference-contexts: Typically one approaches the critical point with L c~, where c 24, and then uses finite-size scaling [22, 23] to extrapolate to the infinite-volume limit. Note Added 1996: Recently, radical advances have been made in applying finite-size scaling to Monte Carlo simulations (see [97, 98] and especially <ref> [99, 100, 101, 102, 103] </ref>); the preceding two sentences can now be seen to be far too pessimistic. <p> In practice, reliable infinite-volume values (with both statistical and systematic errors of order a few percent) can be obtained at ~ ~ 10 5 from lattices of size L ~ 10 2 , at least in some models <ref> [101, 102, 103] </ref>. or eliminated by a more clever algorithm. What is to be done? Our knowledge of the physics of critical slowing-down tells us that the slow modes are the long-wavelength modes, if the updating is purely local.
Reference: [103] <author> G. Mana, A. Pelissetto and A.D. Sokal, hep-lat/9610021, </author> <note> submitted to Phys. Rev. D. </note>
Reference-contexts: Typically one approaches the critical point with L c~, where c 24, and then uses finite-size scaling [22, 23] to extrapolate to the infinite-volume limit. Note Added 1996: Recently, radical advances have been made in applying finite-size scaling to Monte Carlo simulations (see [97, 98] and especially <ref> [99, 100, 101, 102, 103] </ref>); the preceding two sentences can now be seen to be far too pessimistic. <p> In practice, reliable infinite-volume values (with both statistical and systematic errors of order a few percent) can be obtained at ~ ~ 10 5 from lattices of size L ~ 10 2 , at least in some models <ref> [101, 102, 103] </ref>. or eliminated by a more clever algorithm. What is to be done? Our knowledge of the physics of critical slowing-down tells us that the slow modes are the long-wavelength modes, if the updating is purely local. <p> But our reasoning may now need to be re-examined! 19 19 Note Added 1996: For work on multi-grid Monte Carlo covering the period 1992-96, see <ref> [106, 107, 108, 103] </ref> and the references cited therein. 40 5.3 Stochastic Linear Iterations for the Gaussian Model In this section we analyze an important class of Markov chains, the stochastic linear iterations for Gaussian models [20, Section 8]. 20 This class includes, among others, the single-site heat-bath algorithm (with deterministic
Reference: [104] <author> C.-R. Hwang and S.-J. Sheu, </author> <title> in Stochastic Models, Statistical Methods, </title> <booktitle> and Algorithms in Image Analysis (Lecture Notes in Statistics #74), </booktitle> <editor> ed. P. Barone, A. Frigessi and M. </editor> <publisher> Piccioni (Springer, </publisher> <address> Berlin, </address> <year> 1992). </year>
Reference-contexts: g j6=i ) = const (f j g j6=i ) fi exp 2 X j 5 : (4.19) 10 Note Added 1996: This statement is wrong!!! For the Metropolis acceptance probability F (z) = min (z; 1), one may construct examples of nonergodicity for sequential site updating at any fi <ref> [104, 105] </ref>: the idea is to construct configurations for which every proposed update (working sequentially) has E = 0 and is thus accepted.
Reference: [105] <author> B. Gidas, </author> <title> private communication (1991). </title>
Reference-contexts: g j6=i ) = const (f j g j6=i ) fi exp 2 X j 5 : (4.19) 10 Note Added 1996: This statement is wrong!!! For the Metropolis acceptance probability F (z) = min (z; 1), one may construct examples of nonergodicity for sequential site updating at any fi <ref> [104, 105] </ref>: the idea is to construct configurations for which every proposed update (working sequentially) has E = 0 and is thus accepted.
Reference: [106] <author> T. </author> <title> Mendes and A.D. </title> <journal> Sokal, Phys. Rev. </journal> <volume> D53, </volume> <month> 3438 </month> <year> (1996). </year>
Reference-contexts: But our reasoning may now need to be re-examined! 19 19 Note Added 1996: For work on multi-grid Monte Carlo covering the period 1992-96, see <ref> [106, 107, 108, 103] </ref> and the references cited therein. 40 5.3 Stochastic Linear Iterations for the Gaussian Model In this section we analyze an important class of Markov chains, the stochastic linear iterations for Gaussian models [20, Section 8]. 20 This class includes, among others, the single-site heat-bath algorithm (with deterministic
Reference: [107] <author> G. Mana, T. Mendes, A. Pelissetto and A.D. Sokal, </author> <title> Nucl. </title> <journal> Phys. B (Proc. </journal> <volume> Suppl.) 47, </volume> <month> 796 </month> <year> (1996). </year>
Reference-contexts: But our reasoning may now need to be re-examined! 19 19 Note Added 1996: For work on multi-grid Monte Carlo covering the period 1992-96, see <ref> [106, 107, 108, 103] </ref> and the references cited therein. 40 5.3 Stochastic Linear Iterations for the Gaussian Model In this section we analyze an important class of Markov chains, the stochastic linear iterations for Gaussian models [20, Section 8]. 20 This class includes, among others, the single-site heat-bath algorithm (with deterministic
Reference: [108] <author> T. Mendes and A. Pelissetto and A.D. </author> <month> Sokal, </month> <institution> Nucl. Phys. B477, </institution> <month> 203 </month> <year> (1996). </year>
Reference-contexts: But our reasoning may now need to be re-examined! 19 19 Note Added 1996: For work on multi-grid Monte Carlo covering the period 1992-96, see <ref> [106, 107, 108, 103] </ref> and the references cited therein. 40 5.3 Stochastic Linear Iterations for the Gaussian Model In this section we analyze an important class of Markov chains, the stochastic linear iterations for Gaussian models [20, Section 8]. 20 This class includes, among others, the single-site heat-bath algorithm (with deterministic
Reference: [109] <author> A.D. Sokal, </author> <title> Nucl. </title> <journal> Phys. B (Proc. </journal> <volume> Suppl.) 20, </volume> <month> 55 </month> <year> (1991). </year>
Reference-contexts: See also <ref> [109, 110] </ref> for reviews that are slightly more up-to-date than the present notes (1990 rather than 1989). 45 = fg 2 X hiji J ij (ffi i ; j 1) 5 X Y hiji [(1 p ij ) + p ij ffi i ; j ] (6.2) where we have defined
Reference: [110] <author> J.-S. Wang and R.H. Swendsen, Physica A167, </author> <month> 565 </month> <year> (1990). </year>
Reference-contexts: See also <ref> [109, 110] </ref> for reviews that are slightly more up-to-date than the present notes (1990 rather than 1989). 45 = fg 2 X hiji J ij (ffi i ; j 1) 5 X Y hiji [(1 p ij ) + p ij ffi i ; j ] (6.2) where we have defined
Reference: [111] <author> C.F. </author> <title> Baillie and P.D. </title> <journal> Coddington, Phys. Rev. Lett. </journal> <volume> 68, </volume> <booktitle> 962 (1992); and private communication. </booktitle>
Reference-contexts: Even with lattices up to L = 512, we are unable to distinguish convincingly between z 0:35 and z 0. Note Added 1996: For more recent and much more precise data, see <ref> [111, 112] </ref>. These data are consistent with t SW ~ L 0:24 , but they are also consistent with t SW ~ log 2 L [112]. It is extremely difficult to distinguish a small power from a logarithm. 26 Note Added 1996: For more recent data, see [111, 112] for d <p> precise data, see <ref> [111, 112] </ref>. These data are consistent with t SW ~ L 0:24 , but they are also consistent with t SW ~ log 2 L [112]. It is extremely difficult to distinguish a small power from a logarithm. 26 Note Added 1996: For more recent data, see [111, 112] for d = 2, q = 2; [113] for d = 2, q = 3; and [112, 114] for d = 2, q = 4.
Reference: [112] <author> J. </author> <title> Salas and A.D. </title> <journal> Sokal, J. Stat. Phys. </journal> <volume> 85, </volume> <month> 297 </month> <year> (1996). </year>
Reference-contexts: Even with lattices up to L = 512, we are unable to distinguish convincingly between z 0:35 and z 0. Note Added 1996: For more recent and much more precise data, see <ref> [111, 112] </ref>. These data are consistent with t SW ~ L 0:24 , but they are also consistent with t SW ~ log 2 L [112]. It is extremely difficult to distinguish a small power from a logarithm. 26 Note Added 1996: For more recent data, see [111, 112] for d <p> Note Added 1996: For more recent and much more precise data, see [111, 112]. These data are consistent with t SW ~ L 0:24 , but they are also consistent with t SW ~ log 2 L <ref> [112] </ref>. It is extremely difficult to distinguish a small power from a logarithm. 26 Note Added 1996: For more recent data, see [111, 112] for d = 2, q = 2; [113] for d = 2, q = 3; and [112, 114] for d = 2, q = 4. <p> precise data, see <ref> [111, 112] </ref>. These data are consistent with t SW ~ L 0:24 , but they are also consistent with t SW ~ log 2 L [112]. It is extremely difficult to distinguish a small power from a logarithm. 26 Note Added 1996: For more recent data, see [111, 112] for d = 2, q = 2; [113] for d = 2, q = 3; and [112, 114] for d = 2, q = 4. <p> It is extremely difficult to distinguish a small power from a logarithm. 26 Note Added 1996: For more recent data, see [111, 112] for d = 2, q = 2; [113] for d = 2, q = 3; and <ref> [112, 114] </ref> for d = 2, q = 4. <p> This is because sets of configurations typical of the ordered and disordered phases are separated by free-energy barriers of order L d1 , i.e. by sets of intermediate 27 Note Added 1996: See <ref> [112, 113, 114] </ref> for more recent data on the possible sharpness of the Li-Sokal bound for two-dimensional models with q = 2; 3; 4. <p> See [115, 116, 117, 118, 119] for reviews. 29 Note Added 1996: In addition to the generalizations discussed below, see <ref> [120, 112] </ref> for SW-type algorithms for the Ashkin-Teller model; see [121] for a clever SW-type algorithm for the fully frustrated Ising model; and see [122, 123, 124, 100] for a very interesting SW-type algorithm for antiferromagnetic Potts models, based on the "embedding" idea to be described below. 30 Note Added 1996:
Reference: [113] <author> J. Salas and A.D. Sokal, </author> <title> Dynamic critical behavior of the Swendsen-Wang algorithm: The two-dimensional 3-state Potts model revisited, </title> <journal> hep-lat/9605018, J. Stat. Phys. </journal> <volume> 87, no. </volume> <month> 1/2 (April </month> <year> 1997). </year>
Reference-contexts: It is extremely difficult to distinguish a small power from a logarithm. 26 Note Added 1996: For more recent data, see [111, 112] for d = 2, q = 2; <ref> [113] </ref> for d = 2, q = 3; and [112, 114] for d = 2, q = 4. <p> This is because sets of configurations typical of the ordered and disordered phases are separated by free-energy barriers of order L d1 , i.e. by sets of intermediate 27 Note Added 1996: See <ref> [112, 113, 114] </ref> for more recent data on the possible sharpness of the Li-Sokal bound for two-dimensional models with q = 2; 3; 4.
Reference: [114] <author> J. Salas and A.D. Sokal, </author> <title> Logarithmic corrections and finite-size scaling in the two-dimensional 4-State Potts model, </title> <journal> hep-lat/9607030, </journal> <note> submitted to J. </note> <institution> Stat. Phys. </institution>
Reference-contexts: It is extremely difficult to distinguish a small power from a logarithm. 26 Note Added 1996: For more recent data, see [111, 112] for d = 2, q = 2; [113] for d = 2, q = 3; and <ref> [112, 114] </ref> for d = 2, q = 4. <p> This is because sets of configurations typical of the ordered and disordered phases are separated by free-energy barriers of order L d1 , i.e. by sets of intermediate 27 Note Added 1996: See <ref> [112, 113, 114] </ref> for more recent data on the possible sharpness of the Li-Sokal bound for two-dimensional models with q = 2; 3; 4.
Reference: [115] <author> G.M. Torrie and J.P. Valleau, </author> <title> Chem. </title> <journal> Phys. Lett. </journal> <note> 28, 578 (1974); J. Comput. Phys. 23, 187 (1977); J. </note> <institution> Chem. Phys. </institution> <month> 66, 1402 </month> <year> (1977). </year>
Reference-contexts: The exponential slowing-down t ~ exp (cL d1 ) resulting from barrier penetration is replaced by a power-law slowing-down t ~ L p resulting from diffusion, provided that the distribution to be simulated is suitably chosen. See <ref> [115, 116, 117, 118, 119] </ref> for reviews. 29 Note Added 1996: In addition to the generalizations discussed below, see [120, 112] for SW-type algorithms for the Ashkin-Teller model; see [121] for a clever SW-type algorithm for the fully frustrated Ising model; and see [122, 123, 124, 100] for a very interesting
Reference: [116] <author> B.A. Berg and T. </author> <title> Neuhaus, </title> <journal> Phys. Lett. B267, 249 (1991); Phys. Rev. Lett. </journal> <volume> 68, </volume> <month> 9 </month> <year> (1992). </year>
Reference-contexts: The exponential slowing-down t ~ exp (cL d1 ) resulting from barrier penetration is replaced by a power-law slowing-down t ~ L p resulting from diffusion, provided that the distribution to be simulated is suitably chosen. See <ref> [115, 116, 117, 118, 119] </ref> for reviews. 29 Note Added 1996: In addition to the generalizations discussed below, see [120, 112] for SW-type algorithms for the Ashkin-Teller model; see [121] for a clever SW-type algorithm for the fully frustrated Ising model; and see [122, 123, 124, 100] for a very interesting
Reference: [117] <author> B.A. Berg, </author> <title> Int. </title> <journal> J. Mod. Phys. </journal> <volume> C4, </volume> <month> 249 </month> <year> (1993). </year>
Reference-contexts: The exponential slowing-down t ~ exp (cL d1 ) resulting from barrier penetration is replaced by a power-law slowing-down t ~ L p resulting from diffusion, provided that the distribution to be simulated is suitably chosen. See <ref> [115, 116, 117, 118, 119] </ref> for reviews. 29 Note Added 1996: In addition to the generalizations discussed below, see [120, 112] for SW-type algorithms for the Ashkin-Teller model; see [121] for a clever SW-type algorithm for the fully frustrated Ising model; and see [122, 123, 124, 100] for a very interesting
Reference: [118] <author> A.D. Kennedy, </author> <title> Nucl. </title> <journal> Phys. B (Proc. </journal> <volume> Suppl.) 30, </volume> <month> 96 </month> <year> (1993). </year>
Reference-contexts: The exponential slowing-down t ~ exp (cL d1 ) resulting from barrier penetration is replaced by a power-law slowing-down t ~ L p resulting from diffusion, provided that the distribution to be simulated is suitably chosen. See <ref> [115, 116, 117, 118, 119] </ref> for reviews. 29 Note Added 1996: In addition to the generalizations discussed below, see [120, 112] for SW-type algorithms for the Ashkin-Teller model; see [121] for a clever SW-type algorithm for the fully frustrated Ising model; and see [122, 123, 124, 100] for a very interesting
Reference: [119] <author> W. Janke, </author> <title> in Computer Simulations in Condensed Matter Physics VII , eds. D.P. Landau, </title> <editor> K.K. Mon and H.-B. </editor> <publisher> Schuttler (Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1994). </year>
Reference-contexts: The exponential slowing-down t ~ exp (cL d1 ) resulting from barrier penetration is replaced by a power-law slowing-down t ~ L p resulting from diffusion, provided that the distribution to be simulated is suitably chosen. See <ref> [115, 116, 117, 118, 119] </ref> for reviews. 29 Note Added 1996: In addition to the generalizations discussed below, see [120, 112] for SW-type algorithms for the Ashkin-Teller model; see [121] for a clever SW-type algorithm for the fully frustrated Ising model; and see [122, 123, 124, 100] for a very interesting
Reference: [120] <author> S. Wiseman and E. </author> <title> Domany, </title> <journal> Phys. Rev. </journal> <volume> E 48, </volume> <month> 4080 </month> <year> (1993). </year>
Reference-contexts: See [115, 116, 117, 118, 119] for reviews. 29 Note Added 1996: In addition to the generalizations discussed below, see <ref> [120, 112] </ref> for SW-type algorithms for the Ashkin-Teller model; see [121] for a clever SW-type algorithm for the fully frustrated Ising model; and see [122, 123, 124, 100] for a very interesting SW-type algorithm for antiferromagnetic Potts models, based on the "embedding" idea to be described below. 30 Note Added 1996:
Reference: [121] <author> D. Kandel, R. Ben-Av and E. </author> <title> Domany, </title> <journal> Phys. Rev. Lett. </journal> <note> 65, 941 (1990) and Phys. Rev. B45, 4700 (1992). </note>
Reference-contexts: See [115, 116, 117, 118, 119] for reviews. 29 Note Added 1996: In addition to the generalizations discussed below, see [120, 112] for SW-type algorithms for the Ashkin-Teller model; see <ref> [121] </ref> for a clever SW-type algorithm for the fully frustrated Ising model; and see [122, 123, 124, 100] for a very interesting SW-type algorithm for antiferromagnetic Potts models, based on the "embedding" idea to be described below. 30 Note Added 1996: For at least some versions of the multi-grid SW algorithm,
Reference: [122] <author> J.-S. Wang, R.H. Swendsen and R. </author> <title> Kotecky, </title> <journal> Phys. Rev. Lett. </journal> <volume> 63, </volume> <month> 109 </month> <year> (1989). </year>
Reference-contexts: See [115, 116, 117, 118, 119] for reviews. 29 Note Added 1996: In addition to the generalizations discussed below, see [120, 112] for SW-type algorithms for the Ashkin-Teller model; see [121] for a clever SW-type algorithm for the fully frustrated Ising model; and see <ref> [122, 123, 124, 100] </ref> for a very interesting SW-type algorithm for antiferromagnetic Potts models, based on the "embedding" idea to be described below. 30 Note Added 1996: For at least some versions of the multi-grid SW algorithm, it can be proven [125] that the bound z MGSW ff=- holds.
Reference: [123] <author> J.-S. Wang, R.H. Swendsen and R. </author> <title> Kotecky, </title> <journal> Phys. Rev. </journal> <volume> B42, </volume> <month> 2465 </month> <year> (1990). </year>
Reference-contexts: See [115, 116, 117, 118, 119] for reviews. 29 Note Added 1996: In addition to the generalizations discussed below, see [120, 112] for SW-type algorithms for the Ashkin-Teller model; see [121] for a clever SW-type algorithm for the fully frustrated Ising model; and see <ref> [122, 123, 124, 100] </ref> for a very interesting SW-type algorithm for antiferromagnetic Potts models, based on the "embedding" idea to be described below. 30 Note Added 1996: For at least some versions of the multi-grid SW algorithm, it can be proven [125] that the bound z MGSW ff=- holds.
Reference: [124] <author> M. Lubin and A.D. </author> <title> Sokal, </title> <journal> Phys. Rev. Lett. </journal> <volume> 71, </volume> <month> 1778 </month> <year> (1993). </year>
Reference-contexts: See [115, 116, 117, 118, 119] for reviews. 29 Note Added 1996: In addition to the generalizations discussed below, see [120, 112] for SW-type algorithms for the Ashkin-Teller model; see [121] for a clever SW-type algorithm for the fully frustrated Ising model; and see <ref> [122, 123, 124, 100] </ref> for a very interesting SW-type algorithm for antiferromagnetic Potts models, based on the "embedding" idea to be described below. 30 Note Added 1996: For at least some versions of the multi-grid SW algorithm, it can be proven [125] that the bound z MGSW ff=- holds.
Reference: [125] <author> X.-J. Li and A.D. </author> <title> Sokal, </title> <journal> Phys. Rev. Lett. </journal> <volume> 67, </volume> <month> 1482 </month> <year> (1991). </year>
Reference-contexts: algorithm for the fully frustrated Ising model; and see [122, 123, 124, 100] for a very interesting SW-type algorithm for antiferromagnetic Potts models, based on the "embedding" idea to be described below. 30 Note Added 1996: For at least some versions of the multi-grid SW algorithm, it can be proven <ref> [125] </ref> that the bound z MGSW ff=- holds. Thus, the critical slowing-down is not completely eliminated in any model in which the specific heat is divergent. 51 generalization, which works only in two dimensions, augments the SW algorithm by transformations to the dual lattice [68].
Reference: [126] <author> S. Caracciolo, R.G. Edwards, A. Pelissetto and A.D. </author> <month> Sokal, </month> <institution> Nucl. Phys. B403, </institution> <month> 475 </month> <year> (1993). </year>
Reference-contexts: for Monte Carlo work: Firstly, one can work directly with SAWs on an infinite lattice; there are no systematic errors due to 32 This picture of the action of the Wolff algorithm on vortex-antivortex pairs was developed in discussions with Richard Brower and Robert Swendsen. 33 Note Added 1996: See <ref> [126] </ref> for a general theory of Wolff-type embedding algorithms as applied to nonlinear -models (spin models taking values in a Riemannian manifold M ).
Reference: [127] <author> A.D. Sokal, </author> <title> in Monte Carlo and Molecular Dynamics Simulations in Polymer Science, </title> <editor> ed. K. </editor> <publisher> Binder (Oxford University Press, </publisher> <address> New York, </address> <year> 1995). </year> <month> 74 </month>
Reference-contexts: In particular, we do not expect Wolff-type embedding algorithms to work well for -models taking values in SU (N ) for N 3. 34 Note Added 1996: An extensive and up-to-date review of Monte Carlo algorithms for the self avoiding walk can be found in <ref> [127] </ref>. A briefer version is [128]. 54 finite-volume corrections. Secondly, there is no L d (or ~ d ) factor in the computational work, so one can go closer to criticality. Thus, the SAW is an exceptionally advantageous "laboratory" for the numerical study of critical phenomena.
Reference: [128] <author> A.D. Sokal, </author> <title> Nucl. </title> <journal> Phys. B (Proc. </journal> <volume> Suppl.) 47, </volume> <month> 172 </month> <year> (1996). </year>
Reference-contexts: A briefer version is <ref> [128] </ref>. 54 finite-volume corrections. Secondly, there is no L d (or ~ d ) factor in the computational work, so one can go closer to criticality. Thus, the SAW is an exceptionally advantageous "laboratory" for the numerical study of critical phenomena.
Reference: [129] <author> B. Li, N. </author> <title> Madras and A.D. </title> <journal> Sokal, J. Stat. Phys. </journal> <volume> 80, </volume> <month> 661 </month> <year> (1995). </year>
Reference-contexts: But these proofs are, I believe, also of some importance for practical Monte Carlo work, as they give insight into the physical basis of critical slowing-down and may point towards improved algorithms with reduced critical slowing-down. 37 Note Added 1996: This study has now been carried out <ref> [129] </ref>, and yields - = 0:5877 0:0006 (subjective 68% confidence limits), based on SAWs of length up to 80000 steps. Proper treatment of corrections to scaling is crucial in obtaining this estimate. <p> We also show that the interpenetration ratio approaches its limiting value fl = 0:2471 0:0003 from above, contrary to the prediction of the two-parameter renormalization-group theory. We have critically reexamined this theory and shown where the error lies <ref> [130, 129] </ref>. 58 There is a big difference between the techniques used for proving lower and upper bounds, and it is easy to understand this physically.
Reference: [130] <author> A.D. Sokal, </author> <title> Europhys. </title> <journal> Lett. </journal> <volume> 27, </volume> <month> 661 </month> <year> (1994). </year>
Reference-contexts: We also show that the interpenetration ratio approaches its limiting value fl = 0:2471 0:0003 from above, contrary to the prediction of the two-parameter renormalization-group theory. We have critically reexamined this theory and shown where the error lies <ref> [130, 129] </ref>. 58 There is a big difference between the techniques used for proving lower and upper bounds, and it is easy to understand this physically.
Reference: [131] <author> P. Diaconis and D. </author> <title> Stroock, </title> <journal> Ann. Appl. Prob. </journal> <volume> 1, </volume> <month> 36 </month> <year> (1991). </year>
Reference-contexts: For reviews, see e.g. <ref> [131, 132, 133, 134, 135, 136] </ref>. the stationary Markov chain, from a set A to its complement A c , normalized by the invariant probabilities of A and A c : k (A) x2A; y2A c (A) (A c ) ( A ; P A c ) l 2 () :
Reference: [132] <author> A.J. Sinclair, </author> <title> Randomised Algorithms for Counting and Generating Combinatorial Structures (Birkhauser, </title> <address> Boston, </address> <year> 1993). </year>
Reference-contexts: For reviews, see e.g. <ref> [131, 132, 133, 134, 135, 136] </ref>. the stationary Markov chain, from a set A to its complement A c , normalized by the invariant probabilities of A and A c : k (A) x2A; y2A c (A) (A c ) ( A ; P A c ) l 2 () :
Reference: [133] <author> P. Diaconis and L. </author> <title> Saloff-Coste, </title> <journal> Ann. Appl. Prob. </journal> <volume> 3, </volume> <month> 696 </month> <year> (1993). </year>
Reference-contexts: For reviews, see e.g. <ref> [131, 132, 133, 134, 135, 136] </ref>. the stationary Markov chain, from a set A to its complement A c , normalized by the invariant probabilities of A and A c : k (A) x2A; y2A c (A) (A c ) ( A ; P A c ) l 2 () :
Reference: [134] <author> P. Diaconis and L. </author> <title> Saloff-Coste, </title> <journal> Ann. Appl. Prob. </journal> <volume> 6, </volume> <month> 695 </month> <year> (1996). </year>
Reference-contexts: For reviews, see e.g. <ref> [131, 132, 133, 134, 135, 136] </ref>. the stationary Markov chain, from a set A to its complement A c , normalized by the invariant probabilities of A and A c : k (A) x2A; y2A c (A) (A c ) ( A ; P A c ) l 2 () :
Reference: [135] <author> P. Diaconis and L. </author> <title> Saloff-Coste, </title> <journal> J. Theoret. Prob. </journal> <volume> 9, </volume> <month> 459 </month> <year> (1996). </year>
Reference-contexts: For reviews, see e.g. <ref> [131, 132, 133, 134, 135, 136] </ref>. the stationary Markov chain, from a set A to its complement A c , normalized by the invariant probabilities of A and A c : k (A) x2A; y2A c (A) (A c ) ( A ; P A c ) l 2 () :
Reference: [136] <author> M. Jerrum and A. Sinclair, </author> <title> in Approximation Algorithms for NP-Hard Problems, </title> <editor> ed. D.S. </editor> <publisher> Hochbaum (PWS Publishing, </publisher> <address> Boston, </address> <year> 1996). </year>
Reference-contexts: For reviews, see e.g. <ref> [131, 132, 133, 134, 135, 136] </ref>. the stationary Markov chain, from a set A to its complement A c , normalized by the invariant probabilities of A and A c : k (A) x2A; y2A c (A) (A c ) ( A ; P A c ) l 2 () :
Reference: [137] <author> D. Randall and A.J. Sinclair, </author> <booktitle> in Proceedings of the 5th Annual ACM-SIAM Symposium on Discrete Algorithms (ACM Press, </booktitle> <address> New York, </address> <year> 1994). </year>
Reference: [138] <author> D.W. Stroock and B. Zegarlinski, J. </author> <title> Funct. </title> <journal> Anal. </journal> <volume> 104, </volume> <month> 299 </month> <year> (1992). </year>
Reference: [139] <author> D.W. Stroock and B. </author> <title> Zegarlinski, </title> <journal> Commun. Math. Phys. </journal> <volume> 144, </volume> <month> 303 </month> <year> (1992). </year>
Reference: [140] <author> D.W. Stroock and B. </author> <title> Zegarlinski, </title> <journal> Commun. Math. Phys. </journal> <volume> 149, </volume> <month> 175 </month> <year> (1992). </year>
Reference: [141] <author> S.L. Lu and H.T. </author> <title> Yau, </title> <journal> Commun. Math. Phys. </journal> <volume> 156, </volume> <month> 399 </month> <year> (1993). </year>
Reference: [142] <author> F. Martinelli and E. </author> <title> Olivieri, </title> <journal> Commun. Math. Phys. </journal> <volume> 161, 447, </volume> <month> 487 </month> <year> (1994). </year>
Reference: [143] <author> D.W. Stroock and B. Zegarlinski, J. </author> <title> Stat. </title> <journal> Phys. </journal> <volume> 81, </volume> <month> 1007 </month> <year> (1995). </year> <month> 75 </month>
References-found: 141

