URL: http://www.cs.princeton.edu/~psa/multi.ics.ps
Refering-URL: http://www.cs.princeton.edu/~psa/resume.html
Root-URL: http://www.cs.princeton.edu
Email: fpsa,skadron,dougg@cs.princeton.edu, mrm@ee.princeton.edu  
Title: Multipath Execution: Opportunities and Limits  
Author: Pritpal S. Ahuja, Kevin Skadron, Margaret Martonosi Douglas W. Clark 
Address: Princeton, New Jersey 08544  
Affiliation: Depts. of Computer Science and Electrical Engineering Princeton University  
Abstract: Even sophisticated branch-prediction techniques necessarily suffer some mispredictions, and even relatively small mispredict rates hurt performance substantially in current-generation processors. In this paper, we investigate schemes for improving performance in the face of imperfect branch predictors by having the processor simultaneously execute code from both the taken and not-taken outcomes of a branch. This paper presents data regarding the limits of multipath execution, considers fetch-bandwidth needs for multipath execution, and discusses various dynamic confidence-prediction schemes that gauge the likelihood of branch mispredictions. Our evaluations consider executing along several (28) paths at once. Using 4 paths and a relatively simple confidence predictor, multipath execution garners speedups of up to 30% compared to the single-path case, with an average speedup of 14.4% for the SPECint suite. While associated increases in instruction-fetch-bandwidth requirements are not too surprising, a less expected result is the significance of having a separate return-address stack for each forked path. Overall, our results indicate that multipath execution offers significant improvements over single-path performance, and could be especially useful when combined with multithreading so that hardware costs can be amortized over both approaches. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. Burger, T. M. Austin, and S. Bennett. </author> <title> Evaluating future microprocessors: the SimpleScalar tool set. </title> <type> Tech. Report TR-1308, </type> <institution> Univ. of Wisconsin-Madison Computer Sciences Dept., </institution> <month> July </month> <year> 1996. </year>
Reference-contexts: Wallace, Calder, and Tullsen examine consider a combined SMT/multipath organization in [18]. 3 Methods 3.1 Simulator We evaluate our ideas using HydraScalar, a detailed, multipath, cycle-level simulator we have derived from Wisconsin's Simple-Scalar toolset <ref> [1] </ref>. HydraScalar interprets executables compiled by gcc version 2.6.3 for a virtual instruction set closely resembling MIPS IV. HydraScalar instantiates a virtual machine and emulates the object program's execution in order to accurately simulate behavior on mis-speculated paths.
Reference: [2] <author> I.-C. Chen, J. T. Coffey, and T. N. Mudge. </author> <title> Analysis of branch prediction via data compression. </title> <booktitle> In Proc. ASPLOS-VII, </booktitle> <pages> pages 12837, </pages> <month> Oct. </month> <year> 1996. </year>
Reference-contexts: As issue widths increase and processor pipelines deepen, the mis-prediction penalty increases. Many programs suffer a substantial number of mispredictions. Since the delays caused by conditional-branch mispredictions remain a serious problem and more sophisticated prediction techniques still encounter information-theoretic limits <ref> [2] </ref>, we investigate a different kind of remedy: the simultaneous execution of both the taken and not-taken instruction sequences following a conditional branch, with cancelation of the one that turns out to be incorrect when the branch is finally resolved.
Reference: [3] <author> L. Gwennap. </author> <title> Digital 21264 sets new standard. </title> <type> Microprocessor Report, </type> <pages> pages 1116, </pages> <month> Oct. 28, </month> <year> 1996. </year>
Reference-contexts: Because instructions from multiple threads are interleaved in the instruction window, squashed instructions leave holes that are eventually freed at commit. 3.2 Baseline Processor For a baseline CPU, our simulator models an advanced processor resembling in many respects the Alpha 21264 <ref> [3] </ref>. Integer ALU instructions execute according to an 8-stage pipeline. Instruction fetch takes 2 cycles; decode, register mapping, and queueing take 1 cycle each; the out-of-order back end requires 1 cycle each for register fetch, execute, and writeback; and commit is in-order and takes one more cycle. <p> Since the success of multipath execution relies partly on the failure of the branch predictor, a key aspect of the processor model is the branch predictor we use. Except where mentioned otherwise, we use a hybrid, McFarling-style branch-prediction scheme [10] similar to that in the 21264 <ref> [3] </ref>. The scheme uses a 4K table of 2-bit saturating counters to choose between two component branch predictors. Both components are two-level predictors [14], and neither combines PC bits with history bits in indexing the tables of up-down counters.
Reference: [4] <author> T. H. Heil and J. E. Smith. </author> <title> Selective dual path execution. </title> <type> Tech. report, </type> <institution> Univ. of Wisconsin-Madison Dept. of Elec. & Comp. Eng., </institution> <month> Nov. </month> <year> 1996. </year>
Reference-contexts: Klauser, Paithankar, and Grunwald describe Selective Eager Execution, a multipath organization similar to our own, and report similar speedups [8]. In earlier work, Heil and Smith used trace-driven simulation to study the performance of dual-path execution <ref> [4] </ref>. Tyson, Lick, and Farrens described how to use state from a two-level branch predictor's history table as a dynamic confidence predictor [16]. Mechanisms for dynamically computing branch-prediction confidence were also investigated by Jacobsen, Rotenberg, and Smith [6].
Reference: [5] <author> S. Hily and A. Seznec. </author> <title> Branch prediction and simultaneous multi-threading. </title> <booktitle> In Proc. PACT '96, </booktitle> <pages> pages 16973, </pages> <month> Oct. </month> <year> 1996. </year>
Reference-contexts: Per-path copies of the return-address stack are the best solution [12]. Multipath execution already requires path contexts; the return-address stack is merely an additional element in the path context, and something that multithreading also requires <ref> [5] </ref>. Copying the stack should be no more expensive than saving and restoring the register map. All the other studies in this paper have assumed per-path return-address stacks. 6 Confidence Predictors Forking accuracy is crucial to multipath performance.
Reference: [6] <author> E. Jacobsen, E. Rotenberg, and J. E. Smith. </author> <title> Assigning confidence to conditional branch predictions. </title> <booktitle> In Proc. Micro-29, </booktitle> <pages> pages 14252, </pages> <month> Dec. </month> <year> 1996. </year>
Reference-contexts: Each time multipath execution forks successfully, it eliminates a misprediction, although possibly with the expense of increased hardware contention. Ideally, forking would happen only on mispredicted branches. A confidence predictor <ref> [6] </ref> attempts to evaluate the likelihood that a branch has been correctly predicted. Multipath execution uses confidence prediction to reduce hardware contention: instead of forking, the processor speculates conventionally past higher-confidence branches, following only the predicted path. Multipath execution requires additional hardware throughout the processor, of course. <p> Tyson, Lick, and Farrens described how to use state from a two-level branch predictor's history table as a dynamic confidence predictor [16]. Mechanisms for dynamically computing branch-prediction confidence were also investigated by Jacobsen, Rotenberg, and Smith <ref> [6] </ref>. Still earlier, Uht and Sindagi [17] investigated disjoint eager execution, in which static probabilities were attached to each branch outcome, and forking decisions made in favor of the path having the highest likelihood. <p> Hardware State. First we consider ways to count mispredic-tions; these basic policies were first discussed in <ref> [6] </ref>. No Hardware Table. First, and most simply, if no hardware state is kept, then we either revert to the naive policy discussed earlier or use a static profile-based scheme discussed below. Ones Counter. The simple hardware-based confidence predictors considered here use a table indexed by the branch PC.
Reference: [7] <author> S. Jourdan, J. Stark, T.-H. Hsing, and Y. N. Patt. </author> <title> Recovery requirements of branch prediction storage structures in the presence of mispredicted-path execution. </title> <booktitle> Int'l J. Parallel Programming, </booktitle> <address> 25(5):36383, </address> <month> Oct. </month> <year> 1997. </year>
Reference-contexts: For example, after a fork, both paths might encounter calls to printf (). Both push a return address, even though only one return address belongs on the stack (only one call to printf () eventually commits). Neither mechanisms for repairing a return-address stack after mis-speculation <ref> [7, 12] </ref> nor per-path copies of the top-of-stack pointer can prevent this sort of corruption. Per-path copies of the return-address stack are the best solution [12].
Reference: [8] <author> A. Klauser, V. Paithankar, and D. Grunwald. </author> <title> Selective eager execution on the PolyPath Architecture. </title> <booktitle> In Proc. ISCA 25, </booktitle> <month> July </month> <year> 1998. </year>
Reference-contexts: Klauser, Paithankar, and Grunwald describe Selective Eager Execution, a multipath organization similar to our own, and report similar speedups <ref> [8] </ref>. In earlier work, Heil and Smith used trace-driven simulation to study the performance of dual-path execution [4]. Tyson, Lick, and Farrens described how to use state from a two-level branch predictor's history table as a dynamic confidence predictor [16]. <p> Squashed instructions turn themselves into NOPs. The resulting 2 holes propagate like normal instructions but are ignored until commit, when they are reclaimed. A similar idea was independently proposed by Klauser, Paithankar, and Grunwald <ref> [8] </ref>. The path IDs are implemented as circular bitmaps, with a global head pointer and a per-instruction tail pointer. The global head pointer indicates the oldest active forked branch. An instruction's tail pointer indicates how many subsequent branches have forked.
Reference: [9] <author> J. Laudon, A. Gupta, and M. Horowitz. </author> <title> Interleaving: A multithread-ing technique targeting multiprocessors and workstations. </title> <booktitle> In Proc. ASPLOS-IV, </booktitle> <pages> pages 308318, </pages> <month> Oct. </month> <year> 1994. </year>
Reference-contexts: For these reasons, our work has proposed multipath-execution schemes and evaluated their performance on a range of programs. While the hardware requirements of a 4-path approach are not insignificant, this technique substantially complements other likely directions for future microprocessors. These include clustered approaches, multithreaded processors <ref> [9] </ref>, and particularly simultaneous multithreading (SMT) [15]. Multipath speculation at conditional branches is largely an orthogonal way to make use of this hardware at times when other multithreading mechanisms do not. For example, Wallace, Calder, and Tullsen describe a system that combines SMT with multipath execution in [18].
Reference: [10] <author> S. McFarling. </author> <title> Combining branch predictors. </title> <type> Tech. </type> <note> Note TN-36, DEC WRL, </note> <month> June </month> <year> 1993. </year>
Reference-contexts: Since the success of multipath execution relies partly on the failure of the branch predictor, a key aspect of the processor model is the branch predictor we use. Except where mentioned otherwise, we use a hybrid, McFarling-style branch-prediction scheme <ref> [10] </ref> similar to that in the 21264 [3]. The scheme uses a 4K table of 2-bit saturating counters to choose between two component branch predictors. Both components are two-level predictors [14], and neither combines PC bits with history bits in indexing the tables of up-down counters.
Reference: [11] <author> J. Pierce and T. Mudge. </author> <title> Wrong-path instruction prefetching. </title> <booktitle> In Proc. Micro-29, </booktitle> <pages> pages 16575, </pages> <month> Dec. </month> <year> 1996. </year>
Reference-contexts: Wrong-path prefetching, which prefetches the first block on the unpredicted path of a branch, was explored by Pierce and Mudge <ref> [11] </ref> and can be considered a much simpler form of multipath execution. Machines from the late 1970s (the IBM 3033 and 3168) actually incorporated a form of wrong-path prefetching. The remainder of this paper is structured as follows. Section 2 discusses our proposal for multipath execution in more detail.
Reference: [12] <author> K. Skadron, P. S. Ahuja, M. Martonosi, and D. W. Clark. </author> <title> Improving prediction for procedure returns with return-address-stack repair mechanisms. </title> <type> Tech. Report TR-577-98, </type> <institution> Princeton Dept. of Comp. Sci., </institution> <month> Mar. </month> <year> 1998. </year>
Reference-contexts: For example, after a fork, both paths might encounter calls to printf (). Both push a return address, even though only one return address belongs on the stack (only one call to printf () eventually commits). Neither mechanisms for repairing a return-address stack after mis-speculation <ref> [7, 12] </ref> nor per-path copies of the top-of-stack pointer can prevent this sort of corruption. Per-path copies of the return-address stack are the best solution [12]. <p> Neither mechanisms for repairing a return-address stack after mis-speculation [7, 12] nor per-path copies of the top-of-stack pointer can prevent this sort of corruption. Per-path copies of the return-address stack are the best solution <ref> [12] </ref>. Multipath execution already requires path contexts; the return-address stack is merely an additional element in the path context, and something that multithreading also requires [5]. Copying the stack should be no more expensive than saving and restoring the register map.
Reference: [13] <author> K. Skadron, P. S. Ahuja, M. Martonosi, and D. W. Clark. </author> <title> Tradeoffs among branch prediction, instruction-window size, and cache size. </title> <type> Tech. Report TR-578-98, </type> <institution> Princeton Dept. of Comp. Sci., </institution> <month> April </month> <year> 1998. </year>
Reference-contexts: Simulations from initial phases, on the other hand, can give substantially different results. Interval misprediction-rate traces for the other SPECint benchmarks can be found in <ref> [13] </ref>, along with a more detailed discussion of placing a 50M-instruction simulation window. In particular, these 50M windows should suffice for studying branch prediction. The simulations run in a fast instruction-level warmup mode, simulating only caches and branch predictor/confidence structures, until shortly before the simulation window is reached.
Reference: [14] <author> T.-Y. Teh and Y. N. Patt. </author> <title> A comparison of dynamic branch predictors that use two levels of branch history. </title> <booktitle> In Proc. ISCA-20, </booktitle> <pages> pages 25766, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: Except where mentioned otherwise, we use a hybrid, McFarling-style branch-prediction scheme [10] similar to that in the 21264 [3]. The scheme uses a 4K table of 2-bit saturating counters to choose between two component branch predictors. Both components are two-level predictors <ref> [14] </ref>, and neither combines PC bits with history bits in indexing the tables of up-down counters. The first component is a per-address-history scheme with a 1K table of 10-bit branch-history registers, and a 1K table of 3-bit saturating counters.
Reference: [15] <author> D. Tullsen, S. Eggers, J. Emer, et al. </author> <title> Exploiting choice: Instruction fetch and issue on an implementable simultaneous multitheading processor. </title> <booktitle> In Proc. </booktitle> <address> ISCA-23, </address> <month> May </month> <year> 1996. </year>
Reference-contexts: For programs with very high accuracies which are unlikely to benefit from multipath execution, our experiments show that performance does not decrease. Although 4-path speculation would have a significant hardware cost, there are extensive overlaps with the hardware required by multithreading approaches such as simultaneous multithreading (SMT) <ref> [15] </ref>, and combinations of multipath and multithreading make efficient use of such hardware [18]. We also demonstrate that total instruction fetch bandwidth is a key lever on performance, and that heuristics to devote extra fetch resources to probably-correct execution paths can help further improve performance. <p> Then in Section 7, we consider cases with more limited back-end capacity. The hardware, as described thus far, is similar to that used for simultaneous multithreading <ref> [15] </ref>. Although SMT is a complementary strategy that could be used in conjunction with multipath execution, we do not consider it here. This paper focuses solely on the performance benefits of multipath execution at branches, and corresponding fetch-bandwidth and confidence-prediction requirements, rather than other aspects of program or workload parallelism. <p> While the hardware requirements of a 4-path approach are not insignificant, this technique substantially complements other likely directions for future microprocessors. These include clustered approaches, multithreaded processors [9], and particularly simultaneous multithreading (SMT) <ref> [15] </ref>. Multipath speculation at conditional branches is largely an orthogonal way to make use of this hardware at times when other multithreading mechanisms do not. For example, Wallace, Calder, and Tullsen describe a system that combines SMT with multipath execution in [18].
Reference: [16] <author> G. Tyson, K. Lick, and M. Farrens. </author> <title> Limited dual path execution. </title> <type> Tech. Report CSE-TR-346-97, </type> <institution> University of Michigan, EECS Dept., </institution> <year> 1991. </year>
Reference-contexts: In earlier work, Heil and Smith used trace-driven simulation to study the performance of dual-path execution [4]. Tyson, Lick, and Farrens described how to use state from a two-level branch predictor's history table as a dynamic confidence predictor <ref> [16] </ref>. Mechanisms for dynamically computing branch-prediction confidence were also investigated by Jacobsen, Rotenberg, and Smith [6]. Still earlier, Uht and Sindagi [17] investigated disjoint eager execution, in which static probabilities were attached to each branch outcome, and forking decisions made in favor of the path having the highest likelihood.
Reference: [17] <author> A. Uht and V. Sindagi. </author> <title> Disjoint eager execution: An optimal form of speculative execution. </title> <booktitle> In Proc. Micro-28, </booktitle> <pages> pages 31325, </pages> <month> Dec. </month> <year> 1995. </year>
Reference-contexts: Tyson, Lick, and Farrens described how to use state from a two-level branch predictor's history table as a dynamic confidence predictor [16]. Mechanisms for dynamically computing branch-prediction confidence were also investigated by Jacobsen, Rotenberg, and Smith [6]. Still earlier, Uht and Sindagi <ref> [17] </ref> investigated disjoint eager execution, in which static probabilities were attached to each branch outcome, and forking decisions made in favor of the path having the highest likelihood.
Reference: [18] <author> S. Wallace, B. Calder, and D. M. Tullsen. </author> <title> Threaded multiple path execution. </title> <booktitle> In Proc. ISCA 25, </booktitle> <month> July </month> <year> 1998. </year> <month> 8 </month>
Reference-contexts: Although 4-path speculation would have a significant hardware cost, there are extensive overlaps with the hardware required by multithreading approaches such as simultaneous multithreading (SMT) [15], and combinations of multipath and multithreading make efficient use of such hardware <ref> [18] </ref>. We also demonstrate that total instruction fetch bandwidth is a key lever on performance, and that heuristics to devote extra fetch resources to probably-correct execution paths can help further improve performance. Two recent papers are closely related to our work. <p> Two recent papers are closely related to our work. Wallace, Calder, and Tullsen show significant speedups with a processor organization that combines SMT with multipath execution: thread 1 contexts not used for program-level threads are used for multipath execution <ref> [18] </ref>. Klauser, Paithankar, and Grunwald describe Selective Eager Execution, a multipath organization similar to our own, and report similar speedups [8]. In earlier work, Heil and Smith used trace-driven simulation to study the performance of dual-path execution [4]. <p> This paper focuses solely on the performance benefits of multipath execution at branches, and corresponding fetch-bandwidth and confidence-prediction requirements, rather than other aspects of program or workload parallelism. Wallace, Calder, and Tullsen examine consider a combined SMT/multipath organization in <ref> [18] </ref>. 3 Methods 3.1 Simulator We evaluate our ideas using HydraScalar, a detailed, multipath, cycle-level simulator we have derived from Wisconsin's Simple-Scalar toolset [1]. HydraScalar interprets executables compiled by gcc version 2.6.3 for a virtual instruction set closely resembling MIPS IV. <p> Multipath speculation at conditional branches is largely an orthogonal way to make use of this hardware at times when other multithreading mechanisms do not. For example, Wallace, Calder, and Tullsen describe a system that combines SMT with multipath execution in <ref> [18] </ref>. From this work, we draw the following conclusions: First, by exploring performance trends for up to eight paths, we have shown that multipath execution can in the limit approach the performance of an idealized scheme in which conditional branches are predicted with 100% direction accuracy.
References-found: 18

