URL: http://www.csc.ncsu.edu/eos/users/s/stamant/www/papers/ida99-htn.ps
Refering-URL: http://www.csc.ncsu.edu/eos/users/s/stamant/www/home.html
Root-URL: http://www.csc.ncsu.edu
Email: stamant@csc.ncsu.edu  
Title: A planning perspective on strategic data analysis  
Author: Robert St. Amant 
Web: http://www.csc.ncsu.edu/eos/users/s/stamant/www/index.html  
Address: EGRC-CSC Box 7534 Raleigh, NC 27695-7534  
Affiliation: Department of Computer Science North Carolina State University  
Abstract: Over the past fifteen years a variety of interactive IDA systems have been developed to support strategic reasoning for data analysis. We present an AI framework, hierarchical task network planning, that provides a unifying view of these efforts. We describe a taxonomy of strategic approaches to IDA, based on the planning framework, and discuss the strengths and weaknesses associated with each approach. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Shamsul Chowdhury, Ove Wigertz, and Bo Sundgren. </author> <title> Artificial intelligence methods in data analysis and interpretation. </title> <editor> In M. Schader and W. Gaul, editors, </editor> <booktitle> Knowledge, Data and Computer Assisted Decisions, </booktitle> <pages> pages 199-208, </pages> <year> 1990. </year>
Reference-contexts: Like levels, stages may contain more detailed stages: data cleaning, transformation, and estimation are all components of the numerical processing stage. Others have proposed similar descriptions of data analysis as stages <ref> [1, 2] </ref>, differing mainly in the level of granularity. 2 Robert St. Amant These two perspectives can be combined into a single account of data analysis [9]. Stages at a high operational level are abstract tasks that we must translate into procedures we can actually carry out.
Reference: [2] <author> E. Dambroise and P. Massotte. </author> <title> Muse: An expert system in statistics. </title> <booktitle> In COMPSTAT-86, </booktitle> <pages> pages 271-276, </pages> <year> 1986. </year>
Reference-contexts: Like levels, stages may contain more detailed stages: data cleaning, transformation, and estimation are all components of the numerical processing stage. Others have proposed similar descriptions of data analysis as stages <ref> [1, 2] </ref>, differing mainly in the level of granularity. 2 Robert St. Amant These two perspectives can be combined into a single account of data analysis [9]. Stages at a high operational level are abstract tasks that we must translate into procedures we can actually carry out.
Reference: [3] <author> Cuthbert Daniel and Fred S. Wood. </author> <title> Fitting Equations to Data. </title> <publisher> John Wiley & Sons, Inc., </publisher> <year> 1980. </year>
Reference-contexts: Others descriptions of the levels of data analysis have been proposed, all largely compatible <ref> [3, 21, 25] </ref>. Hand gives a different account, describing data analysis as four stages [11]. In the first stage we formulate the general aims of the analysis.
Reference: [4] <author> A. Famili, Wei-Min Shen, Richard Weber, and Evangelos Simoudis. </author> <title> Data preprocessing and intelligent data analysis. </title> <journal> Intelligent Data Analysis, </journal> <volume> 1(1), </volume> <year> 1997. </year>
Reference-contexts: Consider systems that automate some part of the data analysis process, Lecture Notes in Computer Science 5 such as data preprocessing <ref> [4] </ref>. These refocus the decision process on operators with properties very different from those of conventional primitives. Local search. Closely related to the introduction of novel operators to the planning process is local automated search.
Reference: [5] <author> Julian J. Faraway. </author> <title> On the cost of data analysis. </title> <journal> Journal of Computational and Graphical Statistics, </journal> <volume> 1(3) </volume> <pages> 213-229, </pages> <year> 1992. </year>
Reference-contexts: These may be 6 Robert St. Amant comparative measures (is Model y better than Model x?) or absolute measures (does Model x reach a given threshold?) Faraway's systems for regression strategy are representative of work in incremental model search and evaluation <ref> [5, 6] </ref>. A rap is a regression analytic procedure that performs tests and generates repairs for such flaws in a regression model as skewness, outliers, influential points, nonconstant variance, curvature, and so forth. Each rap is a single operator in the regression modeling task.
Reference: [6] <author> Julian J. Faraway. </author> <title> Choice of order in regression strategy. </title> <editor> In P. Cheeseman and R. W. Oldford, editors, </editor> <title> Building Models from Data: </title> <booktitle> Artificial Intelligence and Statistics IV. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1994. </year>
Reference-contexts: The structural information in a more abstract data representation informs the application of operators far more then is possible with a generic array-based representation. The approach of improving strategy by improving data representation is reflected in modern systems such ViSta and Quail, among others <ref> [6, 8, 26] </ref>. Primitive operators. <p> These may be 6 Robert St. Amant comparative measures (is Model y better than Model x?) or absolute measures (does Model x reach a given threshold?) Faraway's systems for regression strategy are representative of work in incremental model search and evaluation <ref> [5, 6] </ref>. A rap is a regression analytic procedure that performs tests and generates repairs for such flaws in a regression model as skewness, outliers, influential points, nonconstant variance, curvature, and so forth. Each rap is a single operator in the regression modeling task.
Reference: [7] <author> W. A. Gale. </author> <title> REX review. </title> <editor> In W. A. Gale, editor, </editor> <booktitle> Artificial Intelligence and Statistics. </booktitle> <publisher> Addison-Wesley Publishing Company, </publisher> <year> 1986. </year> <title> 1 The former view, however, is plausible. Our interest in this conceptual framework first arose when we found ourselves re-implementing useful parts of existing systems (Rex, Tess, and others) in the planning framework of Aide. </title> <address> 10 Robert St. Amant </address>
Reference-contexts: These systems make decisions and execute operators that would ordinarily be the responsibility of the user, taking active part in the data analysis process. Rex, the Regression EXpert system, is the grandfather of these systems and has led to a number of successors <ref> [7, 20, 8] </ref>. Silvers et al. have developed a statistical advisory system for biomedical researchers, which we will call Biomed [12, 21]. The domain of Biomed is the correct application of methods for group mean comparisons. The system guides the user in checking assumptions for comparison of means problems. <p> Other systems take a more active approach in recording user actions and decisions by maintaining a model of the decision process, as with Dinde, Rex <ref> [7, 20] </ref>, and Aide [22]. Developers of such systems walk a fine line between making unwarranted inferences and missing obvious implications. Conservative approaches, being more predictable and more easily guided, have generally met with greater acceptance.
Reference: [8] <author> William A. Gale, David J. Hand, and Anthony E. Kelly. </author> <booktitle> Statistical applications of artificial intelligence. </booktitle> <editor> In C. R. Rao, editor, </editor> <booktitle> Handbook of Statistics, </booktitle> <volume> volume 9, chapter 16, </volume> <pages> pages 535-576. </pages> <publisher> Elsevier Science, </publisher> <year> 1993. </year>
Reference-contexts: The structural information in a more abstract data representation informs the application of operators far more then is possible with a generic array-based representation. The approach of improving strategy by improving data representation is reflected in modern systems such ViSta and Quail, among others <ref> [6, 8, 26] </ref>. Primitive operators. <p> These systems make decisions and execute operators that would ordinarily be the responsibility of the user, taking active part in the data analysis process. Rex, the Regression EXpert system, is the grandfather of these systems and has led to a number of successors <ref> [7, 20, 8] </ref>. Silvers et al. have developed a statistical advisory system for biomedical researchers, which we will call Biomed [12, 21]. The domain of Biomed is the correct application of methods for group mean comparisons. The system guides the user in checking assumptions for comparison of means problems. <p> Aide's plans cover only a tiny subset of techniques for exploratory data analysis, but are effective despite their limitations of scope. The most significant problem faced by these systems|and it remains largely unsolved today|is the representation of strategic statistical knowledge <ref> [8, 10] </ref>. Recording. Building a plan is not the entirety of planning, just as carrying out a statistical procedure is not all of data analysis. Data analysis is interactive and constructive by its nature; in order to understand a result we often need to follow its derivation. <p> Estes is thus unobtrusive when there are no problems with the data, but can provide additional support if problems do surface. The IDA literature is filled with descriptions of statistical advisory systems like Estes, most based on expert systems concepts <ref> [8] </ref> (Kens is a notable ex Lecture Notes in Computer Science 9 ception [].) From a planning perspective the issues here are comparable to those of recording user actions by understanding the changing context of analysis activity. Two further issues in developing a data analysis advisor are correctness and scope.
Reference: [9] <author> William A. Gale and David J. Lubinsky. </author> <title> A comparison of representations for statistical strategies. </title> <booktitle> In Proceedings of the American Statistical Association, </booktitle> <year> 1986. </year>
Reference-contexts: Others have proposed similar descriptions of data analysis as stages [1, 2], differing mainly in the level of granularity. 2 Robert St. Amant These two perspectives can be combined into a single account of data analysis <ref> [9] </ref>. Stages at a high operational level are abstract tasks that we must translate into procedures we can actually carry out. The stage-based description imposes a temporal or sequential ordering on these abstract tasks.
Reference: [10] <author> David J. </author> <title> Hand. Intelligent data analysis: Issues and opportunities. In Advances in Intelligent Data Analysis: Reasoning about Data. </title> <publisher> Springer, </publisher> <year> 1997. </year> <pages> 1-14. </pages>
Reference-contexts: Aide's plans cover only a tiny subset of techniques for exploratory data analysis, but are effective despite their limitations of scope. The most significant problem faced by these systems|and it remains largely unsolved today|is the representation of strategic statistical knowledge <ref> [8, 10] </ref>. Recording. Building a plan is not the entirety of planning, just as carrying out a statistical procedure is not all of data analysis. Data analysis is interactive and constructive by its nature; in order to understand a result we often need to follow its derivation.
Reference: [11] <author> D.J. </author> <title> Hand. Patterns in statistical strategy. In W.A. Gale, editor, </title> <journal> Artificial Intelligence and Statistics, </journal> <pages> pages 355-387. </pages> <publisher> Addison-Wesley Publishing Company, </publisher> <year> 1986. </year>
Reference-contexts: Others descriptions of the levels of data analysis have been proposed, all largely compatible [3, 21, 25]. Hand gives a different account, describing data analysis as four stages <ref> [11] </ref>. In the first stage we formulate the general aims of the analysis. This stage is critical to success: in it we decide which variables should be considered, how they are related, and which research questions are relevant.
Reference: [12] <author> Nira Herrmann, Abraham Silvers, Katherine Godfrey, Bruce Roberts, and Daniel Cerys. </author> <title> A prototype statistical advisory system for biomedical researchers II: Development of a statistical strategy. </title> <journal> Computational Statistics and Data Analysis, </journal> <volume> 18 </volume> <pages> 357-369, </pages> <year> 1994. </year>
Reference-contexts: Rex, the Regression EXpert system, is the grandfather of these systems and has led to a number of successors [7, 20, 8]. Silvers et al. have developed a statistical advisory system for biomedical researchers, which we will call Biomed <ref> [12, 21] </ref>. The domain of Biomed is the correct application of methods for group mean comparisons. The system guides the user in checking assumptions for comparison of means problems. It gives warnings of possible pitfalls and indicates alternative directions when problems occur.
Reference: [13] <author> P. Hietala. </author> <title> Inside a statistical expert system: statistical methods employed in the ESTES system. </title> <booktitle> In COMPSTAT-88, </booktitle> <pages> pages 163-168, </pages> <year> 1988. </year>
Reference-contexts: Estes, the Expert System for Time Series analysis, provides guidance to the inexperienced time series analyst in the preliminary stages of the analysis <ref> [13] </ref>. In terms of Oldford and Peters's taxonomy, Estes operates during the first two stages of data analysis, in which aims are formulated and refined into specific statistical terms. The system works at a relatively high operational level, however, offering only incomplete coverage for the difficult tasks.
Reference: [14] <author> Peter J. Huber. </author> <title> Data analysis implications for command language design. </title> <editor> In K. Hopper and I. A. Newman, editors, </editor> <title> Foundation for Human-Computer Communication. </title> <publisher> Elsevier Science Publishers, </publisher> <year> 1986. </year>
Reference-contexts: What is needed is something closer to a laboratory assistant than to a programming environment. Huber describes the requirements of such a strategic assistant in some detail, which can be met with the help of a formal model of the steps in a data analysis session <ref> [14, 15] </ref>. In this model each step is represented 8 Robert St. Amant as a transformation from some set of inputs to a set of outputs.
Reference: [15] <author> Peter J. Huber. </author> <title> Languages for statistics and data analysis. </title> <editor> In Peter Dirschedl and Ruediger Ostermann, editors, </editor> <booktitle> Computational Statistics. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1994. </year>
Reference-contexts: Data analysis is interactive and constructive by its nature; in order to understand a result we often need to follow its derivation. Huber has likened data analysis to the process of writing programs <ref> [15] </ref>. One of the natural responsibilities of a strategic system is to record decisions made by the user. This is more difficult than it might sound. <p> What is needed is something closer to a laboratory assistant than to a programming environment. Huber describes the requirements of such a strategic assistant in some detail, which can be met with the help of a formal model of the steps in a data analysis session <ref> [14, 15] </ref>. In this model each step is represented 8 Robert St. Amant as a transformation from some set of inputs to a set of outputs.
Reference: [16] <author> David Lubinsky and Daryl Pregibon. </author> <title> Data analysis as search. </title> <journal> Journal of Econometrics, </journal> <volume> 38 </volume> <pages> 247-268, </pages> <year> 1988. </year>
Reference-contexts: This style of interaction results in an "accommodation" of the user's judgment and subject-matter knowledge <ref> [16] </ref>. Rather than trying to derive complete and final results based on limited, machine-based representation of context, the system instead gives the user intermediate results intended to be in the neighborhood of good solutions, and lets the user do the fine-tuning to decide how to proceed. Model evaluation.
Reference: [17] <author> R. W. Oldford and S. C. Peters. DINDE: </author> <title> Towards more sophisticated software environments for statistics. </title> <journal> SIAM Journal on Scientific Computing, </journal> <volume> 9(1) </volume> <pages> 191-211, </pages> <year> 1988. </year>
Reference-contexts: Amant Data representation. Data values are conventionally stored in arrays, which supports generic formats and consistency in data manipulation. There is no overriding statistical reason, however, for this representation <ref> [17] </ref>; though com-putationally convenient, it is not ideal for capturing the real-world knowledge we might find in richer, more structured representations of data. Dinde was an influential early system aimed at professional statisticians [17]. <p> There is no overriding statistical reason, however, for this representation <ref> [17] </ref>; though com-putationally convenient, it is not ideal for capturing the real-world knowledge we might find in richer, more structured representations of data. Dinde was an influential early system aimed at professional statisticians [17]. Dinde represents data objects in terms of individuals, on which measurements can be taken, variates, which are the measurements that can be taken, datum objects, which represent the actual values of variates, and collections and associations, which impose organization on the data.
Reference: [18] <author> R. Wayne Oldford and Stephen C. Peters. </author> <title> Implementation and study of statistical strategy. In W.A. Gale, editor, </title> <journal> Artificial Intelligence and Statistics, </journal> <pages> pages 335-349. </pages> <publisher> Addison-Wesley Publishing Company, </publisher> <year> 1986. </year>
Reference-contexts: 1 Introduction A number of researchers have constructed explicit models of the data analysis process, usually with an eye toward automating some portion of it. Oldford and Peters describe data analysis in terms of operational levels <ref> [18] </ref>. At the highest level in a hierarchy of abstraction, we have strategies for dealing with general concerns, such as designing experiments or deciding how to analyze archival data.
Reference: [19] <author> G. Ostrouchov and E. Frome. </author> <title> A model search procedure for hierarchical models. </title> <journal> Computational Statistics and Data Analysis, </journal> <volume> 15 </volume> <pages> 285-296, </pages> <year> 1993. </year>
Reference-contexts: At that point the user evaluates the results and decides how to proceed, once again in the planning framework. Ostrouchov and Frome provide an extensive example of this approach <ref> [19] </ref>. Their system searches through a space of log-linear hierarchical models with an evaluation criterion based on deviance: D A = 2 (L A L 0 ).
Reference: [20] <author> Daryl Pregibon. </author> <title> Incorporating statistical expertise into data analysis software. </title> <booktitle> In The Future of Statistical Software, </booktitle> <pages> pages 51-62. </pages> <institution> National Research Council, National Academy Press, </institution> <year> 1991. </year>
Reference-contexts: These systems make decisions and execute operators that would ordinarily be the responsibility of the user, taking active part in the data analysis process. Rex, the Regression EXpert system, is the grandfather of these systems and has led to a number of successors <ref> [7, 20, 8] </ref>. Silvers et al. have developed a statistical advisory system for biomedical researchers, which we will call Biomed [12, 21]. The domain of Biomed is the correct application of methods for group mean comparisons. The system guides the user in checking assumptions for comparison of means problems. <p> Other systems take a more active approach in recording user actions and decisions by maintaining a model of the decision process, as with Dinde, Rex <ref> [7, 20] </ref>, and Aide [22]. Developers of such systems walk a fine line between making unwarranted inferences and missing obvious implications. Conservative approaches, being more predictable and more easily guided, have generally met with greater acceptance.
Reference: [21] <author> Abraham Silvers, Nira Herrmann, Katherine Godfrey, Bruce Roberts, and Daniel Cerys. </author> <title> A prototype statistical advisory system for biomedical researchers I: Overview. </title> <journal> Computational Statistics and Data Analysis, </journal> <volume> 18, </volume> <year> 1994. </year>
Reference-contexts: Others descriptions of the levels of data analysis have been proposed, all largely compatible <ref> [3, 21, 25] </ref>. Hand gives a different account, describing data analysis as four stages [11]. In the first stage we formulate the general aims of the analysis. <p> Rex, the Regression EXpert system, is the grandfather of these systems and has led to a number of successors [7, 20, 8]. Silvers et al. have developed a statistical advisory system for biomedical researchers, which we will call Biomed <ref> [12, 21] </ref>. The domain of Biomed is the correct application of methods for group mean comparisons. The system guides the user in checking assumptions for comparison of means problems. It gives warnings of possible pitfalls and indicates alternative directions when problems occur.
Reference: [22] <author> Robert St. Amant and Paul R. Cohen. </author> <title> Intelligent support for exploratory data analysis. </title> <journal> Journal of Computational and Graphical Statistics, </journal> <volume> 7(4) </volume> <pages> 545-558, </pages> <year> 1998. </year>
Reference-contexts: This approach is common in interactive statistical systems like those mentioned above. The Aide system takes operator abstraction a step further <ref> [22] </ref>. In addition to conventional statistical functions, Aide defines three higher-order operations that take functions and relationships as input: reduction, transformation, and decomposition. A reduction summarizes a relationship by mapping it to a scalar value, such as the mean of a sequence of numbers. <p> Other systems take a more active approach in recording user actions and decisions by maintaining a model of the decision process, as with Dinde, Rex [7, 20], and Aide <ref> [22] </ref>. Developers of such systems walk a fine line between making unwarranted inferences and missing obvious implications. Conservative approaches, being more predictable and more easily guided, have generally met with greater acceptance. <p> doing planning, but rather to show that most of the work we are familar with fits naturally into the planning framework. 1 Our current work involves the testing and refinement of this viewpoint through the development of data analysis assistant, based on planning techniques, to succeed our earlier system Aide <ref> [23, 22] </ref>.
Reference: [23] <author> Robert St. Amant and Paul R. Cohen. </author> <title> Interaction with a mixed-initiative system for exploratory data analysis. </title> <journal> Knowledge-Based Systems, </journal> <volume> 10(5) </volume> <pages> 265-273, </pages> <year> 1998. </year>
Reference-contexts: Inference in these systems thus relies most heavily on knowledge that can be derived directly from the data, with little or no assumptions or extraneous information needed. As recording techniques become more comprehensive, they begin to converge with work in navigation through complex information spaces <ref> [23] </ref>. The choices we consider at every step an analysis can be interpreted as the branching nodes in a directed graph representing decision points. Navigation is an effective metaphor for managing the generation and traversal of the graph. <p> doing planning, but rather to show that most of the work we are familar with fits naturally into the planning framework. 1 Our current work involves the testing and refinement of this viewpoint through the development of data analysis assistant, based on planning techniques, to succeed our earlier system Aide <ref> [23, 22] </ref>.
Reference: [24] <author> John Tukey. </author> <title> An alphabet for statisticians' expert systems. In W.A. Gale, editor, </title> <journal> Artificial Intelligence and Statistics, </journal> <pages> pages 401-409. </pages> <publisher> Addison-Wesley Publishing Company, </publisher> <year> 1986. </year>
Reference: [25] <author> John W. Tukey. </author> <title> Styles of data analysis, and their implications for statistical computing. </title> <booktitle> In COMPSTAT-80, </booktitle> <year> 1980. </year>
Reference-contexts: Others descriptions of the levels of data analysis have been proposed, all largely compatible <ref> [3, 21, 25] </ref>. Hand gives a different account, describing data analysis as four stages [11]. In the first stage we formulate the general aims of the analysis.
Reference: [26] <author> Forrest W. Young and David J. Lubinsky. </author> <title> Guiding data analysts with visual statistical strategies. </title> <journal> Journal of Computational and Graphical Statistics, </journal> <volume> 4(4) </volume> <pages> 229-250, </pages> <year> 1995. </year>
Reference-contexts: The structural information in a more abstract data representation informs the application of operators far more then is possible with a generic array-based representation. The approach of improving strategy by improving data representation is reflected in modern systems such ViSta and Quail, among others <ref> [6, 8, 26] </ref>. Primitive operators.
References-found: 26

