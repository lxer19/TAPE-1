URL: http://www.cs.toronto.edu/~greiner/PAPERS/superfluous-journal.ps
Refering-URL: http://www.cs.toronto.edu/~greiner/PAPERS/
Root-URL: 
Email: greiner@scr.siemens.com  grove@research.nj.nec.com  kogan@rutcor.rutgers.edu  
Title: Knowing What Doesn't Matter: Exploiting the Omission of Irrelevant Data  
Author: Russell Greiner Adam J. Grove Alexander Kogan 
Keyword: irrelevant values, blocked attributes, learnability, decision trees, DNF, diagnosis, theory revision, adversarial noise  
Address: 755 College Road East Princeton, NJ 08540-6632  4 Independence Way Princeton, NJ 08540  Newark, NJ 07102 and New Brunswick, NJ 08903  
Affiliation: Siemens Corporate Research  NEC Research Institute  Rutgers University Faculty of Management and RUTCOR  
Abstract: Most learning algorithms work most effectively when their training data contain completely specified labeled samples. In many diagnostic tasks, however, the data will include the values of only some of the attributes; we model this as a blocking process that hides the values of those attributes from the learner. While blockers that remove the values of critical attributes can handicap a learner, this paper instead focuses on blockers that remove only irrelevant attribute values, i.e., values that are not needed to classify an instance, given the values of the other unblocked attributes. We first motivate and formalize this model of "superfluous-value blocking," and then demonstrate that these omissions can be useful, by proving that certain classes that seem hard to learn in the general PAC model | viz., decision trees and DNF formulae | are trivial to learn in this setting. We also show that this model can be extended to deal with (1) theory revision (i.e., modifying an existing formula); (2) blockers that occasionally include superfluous values or exclude required values; and (3) other corruptions of the training data. fl This is an extended version of the paper, "Dealing with (Intentionally) Omitted Data: Exploiting Relative Irrelevancies", which appears in working notes of the 1994 AAAI Fall Symposium on "Relevance", New Orleans, November 1994. We gratefully acknowledge receiving helpful comments from R. Bharat Rao, Tom Hancock, Dan Roth, Dale Schuurmans and George Drastal. 
Abstract-found: 1
Intro-found: 1
Reference: [Ang92] <author> D. Angluin. </author> <title> Computational learning theory: survey and selected bibliography. </title> <booktitle> In Proc. 24th Annu. ACM Sympos. Theory Comput., </booktitle> <pages> pages 351-369. </pages> <publisher> ACM Press, </publisher> <address> New York, NY, </address> <year> 1992. </year> <title> Knowing What Doesn't Matter 32 </title>
Reference-contexts: Notice also Learn-DNF uses only positive samples. By contrast, learning arbitrary DNF formulae in the standard model is one of the major open challenges of PAC-learning in general <ref> [Ang92] </ref>. Many learnability results are expressed in terms of the size of the smallest DNF formula for a concept.
Reference: [AS91] <author> D. Angluin and D. K. </author> <title> Slonim. Learning monotone DNF with an incomplete membership oracle. </title> <booktitle> In Proc. 4th Annu. Workshop on Comput. Learning Theory, </booktitle> <pages> pages 139-146. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1991. </year>
Reference-contexts: Our final comments help to place our model within the framework of existing computational learning results: First, in our model, certain attribute values are omitted; this differs from models where the class label is omitted <ref> [AS91, FGMP94] </ref>, or where some attribute values are changed [SV88, Lit91, GS95]. Second, as our blocker is providing additional information to the learner, its role is similar to that of a benevolent teacher.
Reference: [BFOS84] <author> L. Breiman, J. Friedman, J. Olshen, and C. Stone. </author> <title> Classification and Regression Trees. </title> <publisher> Wadsworth and Brooks, </publisher> <address> Monterey, CA, </address> <year> 1984. </year>
Reference-contexts: His model allows the performance system to use test-cost to decide which tests to omit. By contrast, in our model, the environment/teacher uses test-relevance to decide which tests to present. While there are several learning systems which are designed to handle incomplete information in the samples (cf., <ref> [BFOS84, Qui92, LR87] </ref>), they all appear to be based on a different learning context, which is appropriate for a different situation [SG93, SG94]: After the world produces a completely-specified sample at random, a second process (which also could be "nature") then hides the values of certain attributes, perhaps changing the complete <p> However, as we see later, the interesting cases arise where most or all of the superfluous attributes are in fact blocked. To motivate our model, consider the behavior of a classifier d t using a standard decision tree, a la cart <ref> [BFOS84] </ref> or c4.5 [Qui92]. Here, given any instance, d t will perform (and record) only the tests on a single path through the tree.
Reference: [BHL91] <author> A. Blum, L. Hellerstein, and N. Littlestone. </author> <title> Learning in the presence of finitely or infinitely many irrelevant attributes. </title> <booktitle> In Proc. 4th Annu. Workshop on Comput. Learning Theory, </booktitle> <pages> pages 157-166. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1991. </year>
Reference-contexts: John et al. [JKP94] would therefore consider x 1 to be "weakly irrelevant"; by contrast, they say an attribute is "strongly irrelevant" if its value never plays a role in the classification, under any circumstance (i.e., independent of the values of any other attributes); cf., <ref> [Lit88, Blu92, BHL91] </ref>. Our situation differs from those models of learning as our environment explicitly identifies which attributes are weakly irrelevant in each instance.
Reference: [Blu92] <author> A. Blum. </author> <title> Learning boolean functions in an infinite attribute space. </title> <journal> Machine Learning, </journal> <volume> 9(4) </volume> <pages> 373-386, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: John et al. [JKP94] would therefore consider x 1 to be "weakly irrelevant"; by contrast, they say an attribute is "strongly irrelevant" if its value never plays a role in the classification, under any circumstance (i.e., independent of the values of any other attributes); cf., <ref> [Lit88, Blu92, BHL91] </ref>. Our situation differs from those models of learning as our environment explicitly identifies which attributes are weakly irrelevant in each instance.
Reference: [DB88] <author> Thomas Dean and Mark Boddy. </author> <title> An analysis of time-dependent planning. </title> <booktitle> In Proceedings of AAAI-88, </booktitle> <pages> pages 49-54, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: It is easy to see that that Modify-DNF algorithm also works if we use this fi fl blocker. Finally, it is easy to connect this theory revision idea with the notions of "on-line algorithms" and "anytime algorithms" <ref> [DB88] </ref>. Here, we begin with an empty initial theory then use blocked and labeled instances to produce a good DNF formula. Earlier (in the Learn-DNF case), we were forced to wait until receiving a sufficient number of samples before producing a formula.
Reference: [EH89] <author> A. Ehrenfeucht and D. Haussler. </author> <title> Learning decision trees from random examples. </title> <journal> Information and Computation, </journal> <volume> 82(3) </volume> <pages> 231-246, </pages> <year> 1989. </year>
Reference-contexts: Moreover, Learn-DT requires O ( s * ln n ffi ) blocked labeled samples and returns a tree of size jd 0 j jdj. 3 2 The most general known algorithms run in pseudo-polynomial time, i.e., they learn an s-leaf decision tree in time polynomial in s O (log s) <ref> [EH89, Riv87] </ref>. 3 All proofs are in the Appendix. <p> Let s (*) be the number of trees (of size s) that have at least * error, and note that s (*) is bounded by the total number of distinct trees of size s, which is at most (8n) s <ref> [EH89] </ref>.
Reference: [FGMP94] <author> Mike Frazier, Sally Goldman, Nina Mishra, and Leonard Pitt. </author> <title> Learning from a consistently ignorant teacher. </title> <booktitle> In Proceedings of the Seventh Annual ACM Conference on Computational Learning Theory, </booktitle> <pages> pages 328-339, </pages> <year> 1994. </year>
Reference-contexts: Our final comments help to place our model within the framework of existing computational learning results: First, in our model, certain attribute values are omitted; this differs from models where the class label is omitted <ref> [AS91, FGMP94] </ref>, or where some attribute values are changed [SV88, Lit91, GS95]. Second, as our blocker is providing additional information to the learner, its role is similar to that of a benevolent teacher.
Reference: [GM93] <author> S. Golman and D. Mathias. </author> <title> Teaching a smarter learner. </title> <booktitle> In Proceedings of the Sixth Annual ACM Conference on Computational Learning Theory, </booktitle> <pages> pages 67-76. </pages> <publisher> ACM Press, </publisher> <address> New York, NY, </address> <year> 1993. </year>
Reference-contexts: Second, as our blocker is providing additional information to the learner, its role is similar to that of a benevolent teacher. However, other teaching models, such as Goldman and Mathias <ref> [GM93] </ref>, allow the teacher to present arbitrary instances to the learner, without regard to an underlying real-world distribution. By contrast, our blocker/teacher is forced to deal with the instances selected by the distribution, but can help the learner by declaring certain attribute values, within those instances, to be irrelevant.
Reference: [GS95] <author> Sally A. Goldman and Robert A. Sloan. </author> <title> Can PAC learning algorithms tolerate random attribute noise? Algorithmica, </title> <note> page to appear, </note> <year> 1995. </year>
Reference-contexts: Our final comments help to place our model within the framework of existing computational learning results: First, in our model, certain attribute values are omitted; this differs from models where the class label is omitted [AS91, FGMP94], or where some attribute values are changed <ref> [SV88, Lit91, GS95] </ref>. Second, as our blocker is providing additional information to the learner, its role is similar to that of a benevolent teacher.
Reference: [HKLW91] <author> D. Haussler, M. Kearns, N. Littlestone, and M. K. Warmuth. </author> <title> Equivalence of models for polynomial learnability. </title> <journal> Inform. Comput., </journal> <volume> 95(2) </volume> <pages> 129-161, </pages> <month> December </month> <year> 1991. </year>
Reference-contexts: i NT.If0 = Build-DT ( S 0 ) NT.If1 = Build-DT ( S 1 ) Return ( NT ) End Build-DT While this algorithm is parameterized by the size of the tree s, it is possible to use the standard technique of repeated attempts, with successively doubled estimates of s <ref> [HKLW91] </ref>, to produce an algorithm that does not have to know s in advance. Here, the learning algorithm Learn-DT 0 first draws a set of samples based on the assumption that s = 1, then calls Build-DT on this set. <p> ` , where 4 Actually, Learn-DT 0 will have to request slightly more than Equation 1's m DT:n;s samples when considering each value of s, as it has to consider the possibility of making a mistake on any of the log (2 n ) = n values of s; see <ref> [HKLW91] </ref>. 5 I.e., every poly-sized decision tree is logically equivalent to a poly-sized DNF formula, but not vice versa.
Reference: [JKP94] <author> George H. John, Ron Kohavi, and Karl Pfleger. </author> <title> Irrelevant features and the subset selection problem. </title> <booktitle> In Proceedings of the Eleventh International Machine Learning Conference, </booktitle> <pages> pages 121-129, </pages> <address> N.J., 1994. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Of course, if x 1 is negative, other tests may then be relevant for the diagnosis; perhaps a negative x 2 and a positive x 3 will be sufficient to establish diseaseX, etc. John et al. <ref> [JKP94] </ref> would therefore consider x 1 to be "weakly irrelevant"; by contrast, they say an attribute is "strongly irrelevant" if its value never plays a role in the classification, under any circumstance (i.e., independent of the values of any other attributes); cf., [Lit88, Blu92, BHL91].
Reference: [KL93] <author> Michael Kearns and Ming Li. </author> <title> Learning in the presence of malicious errors. </title> <journal> SIAM J. Comput., </journal> <volume> 22 </volume> <pages> 807-837, </pages> <year> 1993. </year>
Reference-contexts: It is possible to learn DN F n;s with k/negative-instance degradation fl (A; inst) k , for any constant k. This holds even in the presence of (0; O (ln n=n); 1; 1) attribute degradation. A quite different type of degradation occurs if an adversary can arbitrarily change instances <ref> [KL93] </ref>. However, we assume that the adversary has to pass a certain fraction of instances unchanged: i.e., on each instance the adversary will, with probability 1 , show the learner exactly the appropriate blocked instance.
Reference: [KLPV87] <author> Michael Kearns, Ming Li, Leonard Pitt, and Leslie Valiant. </author> <title> On the learnability of boolean formulae. </title> <booktitle> In Proceedings of the 19th Symposium on the Theory of Computations, </booktitle> <pages> pages 285-295, </pages> <address> New York, </address> <month> May </month> <year> 1987. </year>
Reference-contexts: We use the standard "Probably Approximately Correct" (PAC) criterion <ref> [Val84, KLPV87] </ref> to specify the desired performance of our learners: Definition 2 (PAC-learning) An algorithm L PAC-learns a set of concepts C if, for some polynomial function p ( ), for all target concepts ' 2 C, distributions P , and error parameters *; ffi &gt; 0, L runs in time
Reference: [KMR + 94] <author> M. Kearns, Y. Mansour, D. Ron, R. Rubinfeld, R. Schapire, and L. Sellie. </author> <title> On the learnabilty of discrete distributions. </title> <booktitle> In Proceedings of Twenty-sixth ACM Symposium on Theory of Computing, </booktitle> <pages> pages 273-282, </pages> <year> 1994. </year> <title> Knowing What Doesn't Matter 33 </title>
Reference-contexts: This degradation is sufficiently large that we may not ever see an entirely correct (i.e., completely undegraded) term, within polynomially many samples. However, we can recover terms by collecting subsets of 2k positive samples, and "voting" (for use of a similar technique, see <ref> [KMR + 94] </ref>). That is, we construct a term from the subsample by considering each variable x i in turn, and setting it to 0, 1, or fl according to which value is given most often to x i in the subsample (ties can be broken in an arbitrary fashion).
Reference: [KR93] <author> E. Kushilevitz and D. Roth. </author> <title> On learning visual concepts and DNF formulae. </title> <booktitle> In Proc. 6th Annu. Workshop on Comput. Learning Theory, </booktitle> <pages> pages 317-326. </pages> <publisher> ACM Press, </publisher> <address> New York, NY, </address> <year> 1993. </year>
Reference-contexts: For fl (A; +inst) k , we need only enumerate all the terms from which the degraded positive examples might have come (note there are polynomially many of these), and then filter using negative examples. This is an application of the idea of polynomial explainability <ref> [KR93] </ref>. Theorem 11 It is possible to learn DN F n;s with k/positive-instance degradation fl (A; +inst) k , for any constant k. This holds even if there is also (n 1 k =8; n 1 k =8; *=(8m - ); 1) attribute degradation.
Reference: [LDRG94] <author> Pat Langley, George Drastal, R. Bharat Rao, and Russell Greiner. </author> <title> Theory revision in fault hierarchies. </title> <booktitle> In Proceedings of The Fifth International Workshop on Principles of Diagnosis (DX-94), </booktitle> <address> New Paltz, NY, </address> <year> 1994. </year>
Reference-contexts: We let B T R refer to this model (for DNF formulae) where the T R designates "Theory Revision", corresponding to the many existing systems that perform essentially the same task, albeit in the framework of Horn-clause based reasoning systems; cf., <ref> [Tow91, WP93, MB88, OM90, LDRG94] </ref>. After this, we consider theory revision for decision trees, B (DT ) There are several obvious advantages to theory revision over the "grow from scratch" approach discussed in the previous section. <p> Langley et al. <ref> [LDRG94] </ref> describes our implementation, together with a corpus of experiments, within this model. 10 Of course, this "' cor ' init " is the set-difference between the set of terms in ' cor and the set in ' init .
Reference: [Lit88] <author> Nick Littlestone. </author> <title> Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm. </title> <journal> Machine Learning Journal, </journal> <volume> 2 </volume> <pages> 285-318, </pages> <year> 1988. </year>
Reference-contexts: John et al. [JKP94] would therefore consider x 1 to be "weakly irrelevant"; by contrast, they say an attribute is "strongly irrelevant" if its value never plays a role in the classification, under any circumstance (i.e., independent of the values of any other attributes); cf., <ref> [Lit88, Blu92, BHL91] </ref>. Our situation differs from those models of learning as our environment explicitly identifies which attributes are weakly irrelevant in each instance.
Reference: [Lit91] <author> N. Littlestone. </author> <title> Redundant noisy attributes, attribute errors, and linear threshold learning using Winnow. </title> <booktitle> In Proc. 4th Annu. Workshop on Comput. Learning Theory, </booktitle> <pages> pages 147-156. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1991. </year>
Reference-contexts: Our final comments help to place our model within the framework of existing computational learning results: First, in our model, certain attribute values are omitted; this differs from models where the class label is omitted [AS91, FGMP94], or where some attribute values are changed <ref> [SV88, Lit91, GS95] </ref>. Second, as our blocker is providing additional information to the learner, its role is similar to that of a benevolent teacher.
Reference: [LR87] <author> J. A. Little and D. B. Rubin. </author> <title> Statistical Analysis with Missing Data. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1987. </year>
Reference-contexts: His model allows the performance system to use test-cost to decide which tests to omit. By contrast, in our model, the environment/teacher uses test-relevance to decide which tests to present. While there are several learning systems which are designed to handle incomplete information in the samples (cf., <ref> [BFOS84, Qui92, LR87] </ref>), they all appear to be based on a different learning context, which is appropriate for a different situation [SG93, SG94]: After the world produces a completely-specified sample at random, a second process (which also could be "nature") then hides the values of certain attributes, perhaps changing the complete
Reference: [MB88] <author> S. Muggleton and W. Buntine. </author> <title> Machine invention of first order predicates by inverting resolution. </title> <booktitle> In Proceedings of IML-88, </booktitle> <pages> pages 339-51. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1988. </year>
Reference-contexts: We let B T R refer to this model (for DNF formulae) where the T R designates "Theory Revision", corresponding to the many existing systems that perform essentially the same task, albeit in the framework of Horn-clause based reasoning systems; cf., <ref> [Tow91, WP93, MB88, OM90, LDRG94] </ref>. After this, we consider theory revision for decision trees, B (DT ) There are several obvious advantages to theory revision over the "grow from scratch" approach discussed in the previous section.
Reference: [OM90] <author> Dirk Ourston and Raymond J. Mooney. </author> <title> Changing the rules: A comprehensive approach to theory refinement. </title> <booktitle> In Proceedings of AAAI-90, </booktitle> <pages> pages 815-20, </pages> <year> 1990. </year>
Reference-contexts: We let B T R refer to this model (for DNF formulae) where the T R designates "Theory Revision", corresponding to the many existing systems that perform essentially the same task, albeit in the framework of Horn-clause based reasoning systems; cf., <ref> [Tow91, WP93, MB88, OM90, LDRG94] </ref>. After this, we consider theory revision for decision trees, B (DT ) There are several obvious advantages to theory revision over the "grow from scratch" approach discussed in the previous section.
Reference: [PBH90] <author> B. W. Porter, R. Bareiss, and R. C. Holte. </author> <title> Concept learning and heuristic classification in weak-theory domains. </title> <journal> Artificial Intelligence, </journal> <volume> 45(1-2):229-63, </volume> <year> 1990. </year>
Reference-contexts: Motivation and Related Work: Most implemented learning systems tend to work effectively when very few features are missing, and when these missing features are randomly distributed across the samples. However, recent studies <ref> [PBH90, RCJ88] </ref> have shown that in practice many datasets are missing more than half of the feature values! Moreover, these attribute values are not randomly blocked, but in fact "are missing [blocked] when they are known to be irrelevant for classification or redundant with features already present in the case description" <p> RCJ88] have shown that in practice many datasets are missing more than half of the feature values! Moreover, these attribute values are not randomly blocked, but in fact "are missing [blocked] when they are known to be irrelevant for classification or redundant with features already present in the case description" <ref> [PBH90] </ref>, which is precisely the situation considered in this paper (see Definition 1).
Reference: [Qui92] <author> J. Ross Quinlan. C4.5: </author> <title> Programs for Machine Learning. </title> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, </address> <year> 1992. </year>
Reference-contexts: His model allows the performance system to use test-cost to decide which tests to omit. By contrast, in our model, the environment/teacher uses test-relevance to decide which tests to present. While there are several learning systems which are designed to handle incomplete information in the samples (cf., <ref> [BFOS84, Qui92, LR87] </ref>), they all appear to be based on a different learning context, which is appropriate for a different situation [SG93, SG94]: After the world produces a completely-specified sample at random, a second process (which also could be "nature") then hides the values of certain attributes, perhaps changing the complete <p> However, as we see later, the interesting cases arise where most or all of the superfluous attributes are in fact blocked. To motivate our model, consider the behavior of a classifier d t using a standard decision tree, a la cart [BFOS84] or c4.5 <ref> [Qui92] </ref>. Here, given any instance, d t will perform (and record) only the tests on a single path through the tree.
Reference: [RCJ88] <author> K. Ruberg, S.M. Cornick, and K.A. James. </author> <title> House calls: Building and maintaining a diagnostic rule-base. </title> <booktitle> In Proceedings Third Knowledge Acquistion for Knowledge-Based Systems Workshop, </booktitle> <year> 1988. </year>
Reference-contexts: Motivation and Related Work: Most implemented learning systems tend to work effectively when very few features are missing, and when these missing features are randomly distributed across the samples. However, recent studies <ref> [PBH90, RCJ88] </ref> have shown that in practice many datasets are missing more than half of the feature values! Moreover, these attribute values are not randomly blocked, but in fact "are missing [blocked] when they are known to be irrelevant for classification or redundant with features already present in the case description"
Reference: [Riv87] <author> R. Rivest. </author> <title> Learning decision lists. </title> <journal> Machine Learning, </journal> <volume> 2 </volume> <pages> 229-246, </pages> <year> 1987. </year>
Reference-contexts: Moreover, Learn-DT requires O ( s * ln n ffi ) blocked labeled samples and returns a tree of size jd 0 j jdj. 3 2 The most general known algorithms run in pseudo-polynomial time, i.e., they learn an s-leaf decision tree in time polynomial in s O (log s) <ref> [EH89, Riv87] </ref>. 3 All proofs are in the Appendix.
Reference: [SG93] <author> Dale Schuurmans and Russell Greiner. </author> <title> Learning to classify incomplete examples. </title> <booktitle> In Fourth Annual Workshop on Computational Learning Theory and `Natural' Learning Systems (CLNL93), </booktitle> <address> Provincetown MA, </address> <year> 1993. </year>
Reference-contexts: While there are several learning systems which are designed to handle incomplete information in the samples (cf., [BFOS84, Qui92, LR87]), they all appear to be based on a different learning context, which is appropriate for a different situation <ref> [SG93, SG94] </ref>: After the world produces a completely-specified sample at random, a second process (which also could be "nature") then hides the values of certain attributes, perhaps changing the complete tuple h1; 0; 0; 1i to the partial tuple hfl; 0; fl; 1i, where "fl" means this value is hidden.
Reference: [SG94] <author> Dale Schuurmans and Russell Greiner. </author> <title> Learning default concepts. </title> <booktitle> In CSCSI-94, </booktitle> <pages> pages 519-523, </pages> <year> 1994. </year>
Reference-contexts: While there are several learning systems which are designed to handle incomplete information in the samples (cf., [BFOS84, Qui92, LR87]), they all appear to be based on a different learning context, which is appropriate for a different situation <ref> [SG93, SG94] </ref>: After the world produces a completely-specified sample at random, a second process (which also could be "nature") then hides the values of certain attributes, perhaps changing the complete tuple h1; 0; 0; 1i to the partial tuple hfl; 0; fl; 1i, where "fl" means this value is hidden.
Reference: [SV88] <author> G. Shackelford and D. Volper. </author> <title> Learning k-DNF with noise in the attributes. </title> <booktitle> In Proceedings COLT-88, </booktitle> <pages> pages 97-103, </pages> <year> 1988. </year>
Reference-contexts: Our final comments help to place our model within the framework of existing computational learning results: First, in our model, certain attribute values are omitted; this differs from models where the class label is omitted [AS91, FGMP94], or where some attribute values are changed <ref> [SV88, Lit91, GS95] </ref>. Second, as our blocker is providing additional information to the learner, its role is similar to that of a benevolent teacher.
Reference: [Tow91] <author> Geoff Towell. </author> <title> Symbolic Knowledge and Neural Networks: Insertion, Refinement and Extraction. </title> <type> PhD thesis, </type> <institution> University of Wisconsin, Madison, </institution> <year> 1991. </year> <title> Knowing What Doesn't Matter 34 </title>
Reference-contexts: We let B T R refer to this model (for DNF formulae) where the T R designates "Theory Revision", corresponding to the many existing systems that perform essentially the same task, albeit in the framework of Horn-clause based reasoning systems; cf., <ref> [Tow91, WP93, MB88, OM90, LDRG94] </ref>. After this, we consider theory revision for decision trees, B (DT ) There are several obvious advantages to theory revision over the "grow from scratch" approach discussed in the previous section.
Reference: [Tur95] <author> Peter D. Turney. </author> <title> Cost-sensitive classification: Empirical evaluation of a hybrid genetic decision tree induction algorithm. </title> <journal> Journal of AI Research, </journal> <note> (accepted subject to revision), </note> <year> 1995. </year>
Reference-contexts: Our model of learning can, therefore, be applicable to many diagnostic tasks, and will be especially useful where experts are unavailable or are unable to articulate the classification process they are using. Knowing What Doesn't Matter 3 Turney <ref> [Tur95] </ref> discusses a model that also assumes that experts intentionally perform only a subset of the possible tests. His model allows the performance system to use test-cost to decide which tests to omit. By contrast, in our model, the environment/teacher uses test-relevance to decide which tests to present.
Reference: [Val84] <author> Leslie G. Valiant. </author> <title> A theory of the learnable. </title> <journal> Communications of the ACM, </journal> <volume> 27(11) </volume> <pages> 1134-42, </pages> <year> 1984. </year>
Reference-contexts: We use the standard "Probably Approximately Correct" (PAC) criterion <ref> [Val84, KLPV87] </ref> to specify the desired performance of our learners: Definition 2 (PAC-learning) An algorithm L PAC-learns a set of concepts C if, for some polynomial function p ( ), for all target concepts ' 2 C, distributions P , and error parameters *; ffi &gt; 0, L runs in time
Reference: [WP93] <author> James Wogulis and Michael J. Pazzani. </author> <title> A methodology for evaluating theory revision systems: Results with Audrey II. </title> <booktitle> In Proceedings of IJCAI-93, </booktitle> <pages> pages 1128-1134, </pages> <year> 1993. </year>
Reference-contexts: We let B T R refer to this model (for DNF formulae) where the T R designates "Theory Revision", corresponding to the many existing systems that perform essentially the same task, albeit in the framework of Horn-clause based reasoning systems; cf., <ref> [Tow91, WP93, MB88, OM90, LDRG94] </ref>. After this, we consider theory revision for decision trees, B (DT ) There are several obvious advantages to theory revision over the "grow from scratch" approach discussed in the previous section.
References-found: 33

