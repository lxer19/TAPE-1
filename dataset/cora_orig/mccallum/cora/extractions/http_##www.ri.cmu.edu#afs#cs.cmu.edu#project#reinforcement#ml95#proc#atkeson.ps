URL: http://www.ri.cmu.edu/afs/cs.cmu.edu/project/reinforcement/ml95/proc/atkeson.ps
Refering-URL: http://www.ri.cmu.edu/afs/cs.cmu.edu/project/reinforcement/ml95/proceedings.html
Root-URL: 
Email: cga@cc.gatech.edu  
Title: Using Local Trajectory Optimizers To Speed Up Global Optimization In Dynamic Programming  
Author: Christopher G. Atkeson 
Date: July 28, 1995  
Address: 801 Atlantic Drive Atlanta, GA, 30332-0280  
Affiliation: College of Computing Georgia Institute of Technology  
Abstract: Dynamic programming provides a methodology to develop planners and controllers for nonlinear systems. However, general dynamic programming is computationally intractable. We have developed procedures that allow more complex planning and control problems to be solved. We use second order local trajectory optimization to generate locally optimal plans and local models of the value function and its derivatives. We maintain global consistency of the local models of the value function, guaranteeing that our locally optimal plans are actually globally optimal, up to the resolution of our search procedures.
Abstract-found: 1
Intro-found: 1
Reference: <author> Bellman, R., </author> <title> (1957) Dynamic Programming, </title> <publisher> Princeton University Press, </publisher> <address> Princeton, NJ. </address>
Reference: <author> Bertsekas, </author> <title> D.P., (1987) Dynamic Programming: Deterministic and Stochastic Models, </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ. </address>
Reference: <author> Dyer, P. and S.R. McReynolds, </author> <title> (1970) The Computation and Theory of Optimal Control, </title> <publisher> Academic Press, </publisher> <address> New York, NY. </address>
Reference-contexts: local models of the value function, guaranteeing that our locally optimal plans are actually globally optimal, up to the resolution of our search procedures. 2 Local Trajectory Optimization We base our local optimization process on dynamic programming within a tube surrounding our current best estimate of a locally optimal trajectory <ref> (Dyer and McReynolds 1970, Ja-cobson and Mayne 1970) </ref>.
Reference: <author> Jacobson, D.H. and D.Q. Mayne, </author> <title> (1970) Differential Dynamic Programming, </title> <publisher> Elsevier, </publisher> <address> New York, NY. </address>
Reference: <author> Larson, R.E., </author> <title> (1968) State Increment Dynamic Programming, </title> <publisher> Elsevier, </publisher> <address> New York, NY. </address> <month> 6 </month>
Reference-contexts: Larson's state increment dynamic programming <ref> (Larson 1968) </ref> is a good example of this type of approach. We want to minimize the number of cells used in dynamic programming by making the cells as large as possible.
References-found: 5

