URL: ftp://ftp-pubs.lcs.mit.edu/pub/lcs-pubs/tr.outbox/MIT-LCS-TR-690.ps.gz
Refering-URL: ftp://ftp-pubs.lcs.mit.edu/pub/lcs-pubs/listings/tr600.html
Root-URL: 
Title: Learning from Imperfect Data in Theory and Practice  
Author: by Donna Karen Slonim Ronald L. Rivest 
Degree: Submitted to the Department of Electrical Engineering and Computer Science in partial fulfillment of the requirements for the degree of Doctor of Philosophy at the  c Donna Karen Slonim, 1996. All rights reserved. The author hereby grants to MIT permission to reproduce and to distribute publicly paper and electronic copies of this thesis document in whole or in part. Signature of Author  Certified by  Professor of Computer Science Thesis Supervisor Accepted by F. R. Morgenthaler Chairman, Departmental Committee on Graduate Students  
Note: B.S., Yale University  
Date: (1991)  (1990)  May 1996  May 3, 1996  
Address: Berkeley  
Affiliation: M.S., University of California at  MASSACHUSETTS INSTITUTE OF TECHNOLOGY  Department of Electrical Engineering and Computer Science  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> K.J. Abel, et al. </author> <title> A radiation hybrid map of the BRCA1 region of chromosome 17q12-q21. </title> <journal> Genomics, </journal> <volume> 17 </volume> <pages> 632-641, </pages> <year> 1993. </year>
Reference-contexts: We expect that this goal of a 30,000-marker map will be reached well ahead of schedule, in part due to the work described in this chapter. 4.2 Radiation Hybrid Mapping Radiation hybrid mapping [43] is a technique that has been used for small-scale mapping since 1990 <ref> [61, 1, 62] </ref>. The experimental method involves exposing human cells to gamma radiation, which breaks each chromosome into random fragments. The DNA fragments are then "rescued" by fusion with healthy hamster cells that incorporate or retain a random subset of the human DNA fragments.
Reference: [2] <author> Farid Alizadeh, Richard M. Karp, Lee A. Newberg, and Deborah K. Weisser. </author> <title> Physical mapping of chromosomes: A combinatorial problem in molecular biology. </title> <booktitle> In Proceedings of the 4th ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <pages> pages 371-381, </pages> <year> 1993. </year>
Reference-contexts: Thus, the real matrix might look more like that in Figure 4.2c. Solving the "almost-consecutive-ones" problem that arises in the error-prone case is much harder. In fact, Alizadeh, Karp, Newberg and Weisser prove that a formalization of the almost-consecutive-ones problem is NP-complete <ref> [2] </ref>. They reduce the problem to a variant of the traveling salesman problem. The key concept behind their approach is the notion of gap minimization.
Reference: [3] <author> Farid Alizadeh, Richard M. Karp, Deborah K. Weisser, and Geoffrey Zweig. </author> <title> Physical mapping of chromosomes using unique probes. </title> <journal> Journal of Computational Biology, </journal> <volume> 2(2) </volume> <pages> 159-184, </pages> <year> 1995. </year>
Reference-contexts: They obtain fairly accurate maps for simulated data with a false-negative rate of 0.1% <ref> [3] </ref>. However, building large-scale maps by STS-content mapping alone has proven to be difficult in practice because of the high rate of false positives and the frequency of repeated DNA. <p> Gap Minimization Finally, we reinforce the conclusions of Boehnke [29] that gap-minimization produces worse results than maximum-likelihood methods for radiation hybrid mapping. We used the gap-minimization software that Karp's group has written and successfully applied to STS-content mapping <ref> [3] </ref>. However, gap-minimization is particularly sensitive to false-positive errors, since each such error produces an additional gap. The STS-content data in Karp's project were carefully filtered to remove as many false-positive errors as possible, at the expense of adding some false-negative errors.
Reference: [4] <author> Dana Angluin. </author> <title> A note on the number of queries needed to identify regular languages. </title> <journal> Information and Control, </journal> <volume> 51 </volume> <pages> 76-87, </pages> <year> 1981. </year>
Reference-contexts: It then runs several copies of Angluin's algorithm [5] for learning DFAs given a reset. Angluin has shown that any algorithm for actively learning DFAs requires an equivalence oracle <ref> [4] </ref>. In this chapter, we introduce a new type of homing sequence for two robots. Because of the strength of the homing sequence, our algorithm does not require an equivalence oracle. For any graph, the expected running time of our algorithm is O (d 2 n 5 ). <p> In fact, two robots on a graph define a DFA whose states are pairs of nodes in G and whose edges correspond to pairs of actions. Since the automata defined in this way form a restricted class of DFAs, our results are not inconsistent with Angluin's work <ref> [4] </ref> showing that a teacher is necessary for learning general DFAs. Theorem 6 Every strongly-connected directed graph has a two-robot homing sequence. Proof: The following algorithm (based on that of Kohavi [69, 93]) constructs a homing sequence: Initially, let h be empty.
Reference: [5] <author> Dana Angluin. </author> <title> Learning regular sets from queries and counterexamples. </title> <journal> Information and Computation, </journal> <volume> 75 </volume> <pages> 87-106, </pages> <month> November </month> <year> 1987. </year>
Reference-contexts: If such an object exists, it is a counterexample to h; otherwise, h is probably approximately correct. Thus, any class C that is learnable by equivalence queries alone is also PAC-learnable <ref> [5] </ref>, though the converse is not true [22]. We use PAC-memb to refer to the variation of the PAC model in which the learner can make membership queries. Likewise we say that a concept class is exactly learnable if it is learnable with membership and equivalence queries. <p> To address this problem, Goldman, Kearns, and Schapire [53] consider a model of persistent noise in membership queries that is related to the model we adopt here. Overview of the Model Our model relies on the definition of a minimally adequate teacher <ref> [5] </ref>, in which a learner tries to learn a target concept f from a known concept class C. In this (error-free) model, the learner is assisted by a teacher that answers two types of queries. <p> They present an algorithm for a single robot to learn minimal deterministic finite automata. With the help of an equivalence oracle, their algorithm learns a homing sequence, which it uses in place of a reset function. It then runs several copies of Angluin's algorithm <ref> [5] </ref> for learning DFAs given a reset. Angluin has shown that any algorithm for actively learning DFAs requires an equivalence oracle [4]. In this chapter, we introduce a new type of homing sequence for two robots.
Reference: [6] <author> Dana Angluin. </author> <title> Queries and concept learning. </title> <journal> Machine Learning, </journal> <volume> 2(4) </volume> <pages> 319-342, </pages> <month> April </month> <year> 1988. </year>
Reference-contexts: The set of 2-descendants is the union of the set of 1-descendants with 0111's grandchildren: 0001, 0010, and 0100. Figure 2.2 shows the set of 2-descendants of the vector 0111. 2.2.3 Using Incomplete Membership Queries A key subprocedure in the monotone DNF algorithm of Angluin <ref> [6] </ref> takes a positive example v of the target concept f and uses membership queries to reduce v to a minimum positive example of f . The algorithm starts with the empty formula and uses equivalence queries to generate new positive counterexamples to reduce. <p> Finally, we extend these definitions to the exact learning model by requiring that counterexamples to equivalence queries not be chosen from the boundary region. 2.3.3 Related Work There has been a great deal of theoretical work on PAC or mistake-bound learning in cases where the training examples may be mislabeled <ref> [6, 70, 101, 64] </ref> and additional work in models that allow attribute noise [99, 52, 75]. The p-concepts model of Kearns and Schapire [65] also falls somewhat into this category. There have also been a number of results on learning with randomly generated noisy responses to membership queries.
Reference: [7] <author> Dana Angluin. </author> <title> Negative results for equivalence queries. </title> <journal> Machine Learning, </journal> <volume> 5 </volume> <pages> 121-150, </pages> <year> 1990. </year>
Reference-contexts: However, the choice of counterexample may not depend on the answers to membership queries not yet made. This adversary is strong enough to generate the "worst-case" counterexamples used to provide lower bounds for equivalence queries <ref> [7] </ref>, but it cannot predict the blind spots of the incomplete membership oracle. Discussion of the Model It may at first seem odd to assume that membership queries are flawed while equivalence queries remain correct. <p> However, there is no algorithm that runs in time polynomial in n and m and exactly identifies any monotone DNF formula using equivalence queries only <ref> [7] </ref>. Thus, the quantification of "with high probability" is necessary in the statement of our main result. 2.2.2 Preliminaries The target concepts are monotone formulas in disjunctive normal form (DNF) over the variables x 1 ; : : : ; x n for some positive integer n.
Reference: [8] <author> Dana Angluin. </author> <title> Exact learning of -DNF formulas with malicious membership queries. </title> <type> Technical Report YALEU/DCS/TR-1020, </type> <institution> Yale University, </institution> <month> March </month> <year> 1994. </year>
Reference-contexts: Angluin and Kri~kis [10] introduce a similar model of malicious membership queries in which the adversary may respond with incorrect answers instead of "don't know". Their paper proves that the class of monotone DNF formulas is learnable in this model. Angluin <ref> [8] </ref> has shown that read-once DNF formulas are also learnable with malicious membership queries. The main difference in motivation between our model and those above is that most previous work supposes that there is a clear boundary between the positive and negative examples with some noise included.
Reference: [9] <author> Dana Angluin and Michael Kharitonov. </author> <booktitle> When won't membership queries help? In Proceedings of the Twenty-Third Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 444-454, </pages> <address> New Orleans, Louisiana, </address> <month> May </month> <year> 1991. </year> <month> 167 </month>
Reference-contexts: We may then derive some measure of the "importance" of membership queries to the learning algorithm as we vary the failure probability p from 0 (complete information from membership queries) to 1 (no information from membership queries.) Angluin and Kharitonov <ref> [9] </ref> explore a number of cryptographic limitations on the power of membership queries.
References-found: 9

