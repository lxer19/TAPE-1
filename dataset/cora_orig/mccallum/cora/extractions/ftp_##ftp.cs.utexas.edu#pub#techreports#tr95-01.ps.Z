URL: ftp://ftp.cs.utexas.edu/pub/techreports/tr95-01.ps.Z
Refering-URL: http://www.cs.utexas.edu/users/ajohn/publications.html
Root-URL: 
Email: email: fajohn,browneg@cs.utexas.edu  
Title: Experiments in Extraction of Coarse Grain Parallelism from Constraint Programs  
Author: Ajita John and J.C. Browne 
Date: May 1, 1995  
Address: Austin, TX 78701  
Affiliation: Dept. of Computer Science University of Texas,  
Pubnum: TR95-1  
Abstract: This paper reports on experimental research on extraction of coarse grain parallelism from constraint systems. Constraint specifications are compiled into task level procedural parallel programs in C. Three issues found to be important are: (i) inclusion of operations over structured types as primitives in the representation, (ii) inclusion of modularity in the constraint systems, and (iii) use of functions in the constraint representation. The role of these issues is described. The compilation process focuses on determining the parallel structure defined by the constraints and creates a parallel program in the format of the CODE 2.0 parallel programming environment. The compilation algorithm is described. An example compilation of a constraint system defining a simple numerical algorithm to a parallel C program is given and performance results are reported. Directions for future enhancement of the compilation process are suggested. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Doug Baldwin. </author> <title> Consul: A Parallel Constraint Language. </title> <booktitle> IEEE Software 1989. </booktitle>
Reference-contexts: Previous efforts at parallel execution of constraint systems <ref> [1] </ref> have, to our knowledge focused on partitioning the constraint systems and applying standard constraint resolution algorithms in parallel. This approach, while interesting conceptually, has little hope of generating programs which will be of competitive efficiency with programs compiled to procedural representations of the same computations.
Reference: [2] <author> Freeman-Benson, </author> <title> B.N. Constraint Imperative Programming Technical Report 91-07-02 University of Washington, </title> <institution> Department of Computer Science and Engineering, </institution> <month> August, </month> <year> 1991. </year>
Reference-contexts: There has been considerable research in compiling constraint systems to sequential procedural representations [3, 10, 5]. Our work is similar in that procedural statements are extracted from a constraint specification. But the difference lies in our focus on extracting parallelism out of constraints. Recent work by Borning <ref> [2, 12] </ref> and others have integrated constraint and imperative models of programming with a view towards attaining the advantages of both. <p> But the difference lies in our focus on extracting parallelism out of constraints. Recent work by Borning [2, 12] and others have integrated constraint and imperative models of programming with a view towards attaining the advantages of both. Benson <ref> [2] </ref> gives a useful survey of constraint programming models and their relationships. 1.2 Compilation of Parallel Programs from Constraint Systems There are both motivation for continuing research in this direction and reasons for some optimism concerning success. Constraint systems have attractive properties for compilation to parallel computation structures.
Reference: [3] <author> Bjorn N. Freeman-Benson. </author> <title> A Module Compiler for Thinglab II. </title> <booktitle> Proc. 1989 ACM Conference on Object-Oriented Programming Systems, Languages, and Applications, </booktitle> <address> New Orleans, </address> <month> October </month> <year> 1989. </year> <note> ACM. </note>
Reference-contexts: We adopt the store-as-valuation concept as in the imperative programming paradigm as opposed to the store-as-constraint [16] notion in concurrent constraint programming. There has been considerable research in compiling constraint systems to sequential procedural representations <ref> [3, 10, 5] </ref>. Our work is similar in that procedural statements are extracted from a constraint specification. But the difference lies in our focus on extracting parallelism out of constraints.
Reference: [4] <author> Alan Borning, Robert Duisberg,Bjorn N. Freeman-Benson, Axel Kramer, and Michael Woolf. </author> <title> Constraint Hierarchies. </title> <booktitle> Proc. 1987 ACM Conference on Object-Oriented Programming Systems, Languages, and Applications, </booktitle> <month> October </month> <year> 1987, </year> <note> ACM. </note>
Reference-contexts: and computation to advantage for applications such as visualization, image analysis and adaptive computational algorithms. d) To validate the compiler by measurement of performance of the applications on several parallel architectures. e) Provide compiler optimizations which take advantage of architectural characteristics of specific execution environments. f) To include constraint hierarchies <ref> [4] </ref>.
Reference: [5] <author> Alan Borning. </author> <title> The Programming Language Aspects of ThingLab, a Constraint-Oriented Simulation Laboratory. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> Vol. 3, No. 4, </volume> <month> October </month> <year> 1981, </year> <pages> pp 353-387. </pages>
Reference-contexts: We adopt the store-as-valuation concept as in the imperative programming paradigm as opposed to the store-as-constraint [16] notion in concurrent constraint programming. There has been considerable research in compiling constraint systems to sequential procedural representations <ref> [3, 10, 5] </ref>. Our work is similar in that procedural statements are extracted from a constraint specification. But the difference lies in our focus on extracting parallelism out of constraints.
Reference: [6] <author> Chandy, K.M and Misra, J. </author> <title> Parallel Program Design : A Foundation Addison-Wesley, </title> <address> Reading, </address> <year> 1989. </year> <month> 17 </month>
Reference-contexts: Constraint systems have attractive properties for compilation to parallel computation structures. A constraint system gives the minimum specification (See <ref> [6] </ref> for an explanation of the benefits which derive from postponing imposition of program struc 2 ture.) for a computation and thus offers the compiler great freedom of choice for derivation of control structure.
Reference: [7] <author> Collins, T.S. and Browne, </author> <title> J.C. MaTrix++; An Object-Oriented Approach to the Hierarchical Matrix Algebra In Proceedings of the Second Annual Object-Oriented Numerics Conference , Sun River, </title> <address> OR, </address> <month> April, </month> <year> 1994. </year>
Reference-contexts: There are several promising approaches: object- oriented formulations of data structures are 15 16 one possibility. A simpler and more algorithmic basis for definition of constraints over partitions of matrices is to utilize the hierarchical type theory for matrices recently published by Collins and Browne <ref> [7] </ref>. The hierarchical type model for matrices establishes a compilable semantics for computations over hierarchical matrices. Collins and Browne [8] have designed and implemented a translator which transforms pseudo-equational representations for computations expressed in the hierarchical type model for matrices into parallel programs.
Reference: [8] <editor> Collins, T.S. and Browne J.C. </editor> <booktitle> MaTrix++; An Object-Oriented Environment for Parallel High-Performance Matrix Computations To appear in the Proceedings of the 1995 Hawaii International Conference on Systems and Software </booktitle>
Reference-contexts: A simpler and more algorithmic basis for definition of constraints over partitions of matrices is to utilize the hierarchical type theory for matrices recently published by Collins and Browne [7]. The hierarchical type model for matrices establishes a compilable semantics for computations over hierarchical matrices. Collins and Browne <ref> [8] </ref> have designed and implemented a translator which transforms pseudo-equational representations for computations expressed in the hierarchical type model for matrices into parallel programs.
Reference: [9] <author> J.J. Dongarra and D.C. Sorenson. </author> <title> SCHEDULE: Tools for Developing and Analyzing Parallel Fortran Programs. </title> <note> Argonne National Laboratory MCSD Technical Memorandum No. 86, </note> <month> Nov. </month> <year> 1986. </year>
Reference-contexts: It solves the Ax = b linear algebra problem for a known lower triangular matrix A and vector b. The parallel algorithm <ref> [9] </ref> is quite simple and involves dividing the matrix into blocks as shown in Figure 7 (a). Figure 7 (b) shows the dataflow of the algorithm.
Reference: [10] <author> Dan Ingalls, Scott Wallace, Yu-Ying Chow, Frank Ludolph, Ken Doyle. </author> <title> Fabrik : A Visual Programming Environment. </title> <booktitle> Proc. 1988 ACM Conference on Object-Oriented Programming Systems, Languages, and Applications, </booktitle> <month> September </month> <year> 1988. </year> <note> ACM. </note>
Reference-contexts: We adopt the store-as-valuation concept as in the imperative programming paradigm as opposed to the store-as-constraint [16] notion in concurrent constraint programming. There has been considerable research in compiling constraint systems to sequential procedural representations <ref> [3, 10, 5] </ref>. Our work is similar in that procedural statements are extracted from a constraint specification. But the difference lies in our focus on extracting parallelism out of constraints.
Reference: [11] <author> William Leler. </author> <title> Constraint Programming Languages. </title> <publisher> Addison-Wesley, </publisher> <year> 1988. </year>
Reference-contexts: Phase 1: The textually expressed constraint system is transformed to an undirected graph representation as for example given by Leler <ref> [11] </ref>. Phase 2: A depth-first search algorithm is used to transform the undirected graph to a directed graph.
Reference: [12] <author> Gus Lopez, Bjorn Freeman-Benson, Alan Borning. </author> <title> Kaleidoscope : A Constraint Imperative Programming Language. Constraint Programming, </title> <editor> B. Mayoh, E. Tougu, J. Penjam (Eds.), </editor> <booktitle> NATO Advanced Science Institute Series, Series F: Computer and System Sciences, </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1993. </year>
Reference-contexts: There has been considerable research in compiling constraint systems to sequential procedural representations [3, 10, 5]. Our work is similar in that procedural statements are extracted from a constraint specification. But the difference lies in our focus on extracting parallelism out of constraints. Recent work by Borning <ref> [2, 12] </ref> and others have integrated constraint and imperative models of programming with a view towards attaining the advantages of both.
Reference: [13] <author> P. Newton and J. C. Browne. </author> <title> The Code 2.0 Graphical Parallel Programming Environment. </title> <booktitle> Proceedings of the 1992 International Conference on Supercomputing (Wash-ington, </booktitle> <address> DC, </address> <month> July </month> <year> 1992), </year> <pages> pp 167-177. </pages>
Reference-contexts: The constraint specification can be reused for generating programs for different sets of inputs. Our translation exploits the AND-OR parallelism in the constraint specification. The dataflow graph is mapped to the execution environment of the CODE 2.0 graphical parallel programming system <ref> [13] </ref> and parallel programs in C are generated. CODE 2.0 generates programs for the shared memory Sequent machine as well as the distributed memory PVM system. <p> Phase 4: The data flow graph is mapped to the CODE 2.0 parallel programming environment <ref> [13] </ref>. CODE 2.0 accepts generalized dependence graphs of the form generated herein as source and produces parallel programs in C as executable for different parallel architectures. 4.1 Phase 1 The textual source program is transformed into a source graph for the compiler. <p> These can be invoked by the corresponding call nodes in the program. 5 Programming Example: Block Triangular Solver The example chosen is the solution of a triangular matrix which is a commonly used example for illustration of parallel computations <ref> [13] </ref>. It solves the Ax = b linear algebra problem for a known lower triangular matrix A and vector b. The parallel algorithm [9] is quite simple and involves dividing the matrix into blocks as shown in Figure 7 (a). Figure 7 (b) shows the dataflow of the algorithm.
Reference: [14] <author> P. Newton and J.C. Browne. </author> <title> A Graphical Retargetable Parallel Programming Environment and its Efficient Implementation. </title> <type> Technical Report TR93-28, </type> <institution> Dept. of Computer Sciences, Univ. of Texas at Austin, </institution> <year> 1993. </year>
Reference-contexts: The target language is CODE 2.0 <ref> [14] </ref> which represents parallel computation structures as generalized dependence graphs. <p> The CODE 2.0 programming system <ref> [14] </ref>, which expresses parallel structure over sequential units of computation declaratively in terms of a generalized dependence graph, provides a natural target language for compilation of parallel computation structures from constraint systems.
Reference: [15] <author> Vijay A. Saraswat. </author> <title> Concurrent Constraint Programming Languages. </title> <type> PhD thesis, </type> <institution> Carnegie Mellon, Pittsburgh, 1989. School of Computer Science. </institution>
Reference-contexts: This approach, while interesting conceptually, has little hope of generating programs which will be of competitive efficiency with programs compiled to procedural representations of the same computations. There has also been considerable work in the logic programming community in concurrent constraint programming <ref> [15] </ref>. Our programming model is significantly different from the ask and tell framework of CCP languages. We adopt the store-as-valuation concept as in the imperative programming paradigm as opposed to the store-as-constraint [16] notion in concurrent constraint programming.
Reference: [16] <author> Vijay A. Saraswat, M. Rinard, and Prakash Panangadan. </author> <title> Semantic foundations of Concurrent constraint programming. </title> <booktitle> Proc. Principles of Programming Languages Conf., </booktitle> <pages> pages 333-352, </pages> <year> 1991. </year> <month> 18 </month>
Reference-contexts: There has also been considerable work in the logic programming community in concurrent constraint programming [15]. Our programming model is significantly different from the ask and tell framework of CCP languages. We adopt the store-as-valuation concept as in the imperative programming paradigm as opposed to the store-as-constraint <ref> [16] </ref> notion in concurrent constraint programming. There has been considerable research in compiling constraint systems to sequential procedural representations [3, 10, 5]. Our work is similar in that procedural statements are extracted from a constraint specification. But the difference lies in our focus on extracting parallelism out of constraints.
References-found: 16

