URL: ftp://cse.ogi.edu/pub/tech-reports/1998/98-005.ps.gz
Refering-URL: ftp://cse.ogi.edu/pub/tech-reports/README.html
Root-URL: http://www.cse.ogi.edu
Title: Pitch Estimation  Center for Spoken Language Understanding  
Author: Sarel van Vuuren 
Address: P.O. Box 91000, Portland, Oregon 97291-1000  
Affiliation: Anthropic Speech Processing Group Department of Electrical and Computer Engineering  Department of Computer Science and Engineering Oregon Graduate Institute of Science and Technology  
Date: February 4, 1998  
Pubnum: Technical Report CSE-98-005  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> S. H. J. van Vuuren, </author> <title> "Pitch detection." Course project report, </title> <institution> University of Pretoria, Pretoria, </institution> <month> Oct. </month> <year> 1992. </year>
Reference-contexts: Moreover, these techniques have not been thoroughly compared with each other because of their widely differing nature and the difficulty associated with obtaining a reference pitch estimate. This report draws strongly from an earlier one <ref> [1] </ref> and is intended mainly to make the material presented there more accessible. While some of the techniques mentioned in this report has since been surpassed by more powerful statistical modeling techniques, they still provide useful information on the issues involved in estimating pitch.
Reference: [2] <author> S. H. J. van Vuuren, </author> <title> "Speech coding in the 4-10kb/s domain." Course project report, </title> <institution> University of Pretoria, Pretoria, </institution> <month> Aug. </month> <year> 1992. </year>
Reference-contexts: 1 Introduction Robust pitch estimation is important in many areas of speech processing. Pitch estimation is necessary for coding and recognition of speech. For example it is used in modern speech coders <ref> [2] </ref>, technology for the hearing impaired and speaker recognition systems [3]. In this report, depending on the context, pitch is used refer to either the pitch period, or pitch frequency.
Reference: [3] <institution> Speaker Recognition Workshop Notebook, NIST, </institution> <year> 1997. </year> <title> NIST speaker recognition evaluation on the Switchboard Corpus. </title>
Reference-contexts: 1 Introduction Robust pitch estimation is important in many areas of speech processing. Pitch estimation is necessary for coding and recognition of speech. For example it is used in modern speech coders [2], technology for the hearing impaired and speaker recognition systems <ref> [3] </ref>. In this report, depending on the context, pitch is used refer to either the pitch period, or pitch frequency.
Reference: [4] <author> L. R. Rabiner, M. J. Cheng, A. E. Rosenberg, and C. A. Mcgonega, </author> <title> "A comparative performance study of several pitch detection algorithms," </title> <journal> IEEE Trans. Acoust., Speech, Signal Processing, </journal> <volume> vol. 24, </volume> <pages> pp. 399-418, </pages> <month> Oct. </month> <year> 1976. </year>
Reference-contexts: While there exist a large number of different pitch estimation techniques, none are clearly superior <ref> [4] </ref>. Moreover, these techniques have not been thoroughly compared with each other because of their widely differing nature and the difficulty associated with obtaining a reference pitch estimate. This report draws strongly from an earlier one [1] and is intended mainly to make the material presented there more accessible. <p> Section 5 presents various results relating to the cepstrum-based pitch estimator. These results are discussed in more detail in Section 6. Section 7 concludes. 5 2 Background Rabiner et al. <ref> [4] </ref> performed in 1976 a comparative study of pitch estimation algorithms for telephone, microphone and wide band recording conditions against a reference pitch signal. The techniques of pitch estimation were regarded as widely representative at the time. These together with more recent techniques are briefly surveyed here. <p> Also, pitch resolution is low due to the pattern quantization. 2.7 Pitch estimation with a neural-net classifier This technique is a time domain technique [11] using a neural network. It is essentially and extension of an earlier 'data reduction' technique described by Rabiner <ref> [4] </ref>. In the original technique, the speech signal is lowpass filtered and excursion cycles between the zero crossings extracted. Additional energy measurements are made for speech or non-speech and voiced or unvoiced classification. Ad hoc logic is used to place pitch markers on the signal peaks corresponding to pitch. <p> A 5'th order median filter is typically used. 12 2.9 Estimation error Rabiner <ref> [4] </ref> defined four types of errors when comparing a pitch estimate and reference signal of the pitch periods. In the voiced region: e = j ^ P P j where e is the error, ^ P the estimated pitch period and P the reference pitch period. <p> Based on these errors, gross error count, mean of fine pitch error and standard deviation of fine pitch error are useful statistics. We repeat the conclusions of Rabiner's comparison of the pitch estimation techniques briefly. For more details the reader are referred to <ref> [4] </ref>. Gross pitch errors The cepstrum technique performed best at low pitch frequencies and overall. The parallel processing technique performed well at higher frequencies. Fine pitch errors No technique exhibited significant bias so that fine pitch errors were difficult to estimate. <p> 0 4 8 12 zero crossings unvoiced voiced (a) magnitude (b) zero crossings Fig. 14: The pdfs of voiced vs. unvoiced speech as a function of (a) magnitude and (b) zero crossings. 15 4 Cepstrum technique with variable analysis win- dow length We implement the cepstrum technique of pitch estimation <ref> [16, 4, 17, 18] </ref>.
Reference: [5] <author> D. A. Krubsack and R. J. Niederjohn, </author> <title> "An autocorrelation pitch detector and voicing decision with confidence measures developed for noise-corrupted speech," </title> <journal> IEEE Transactions on Signal Processing, </journal> <volume> vol. 39, </volume> <pages> pp. 319-329, </pages> <month> Feb. </month> <year> 1991. </year>
Reference-contexts: A confidence estimate in noisy conditions for the voicing estimate is intro duced by Krubsack in <ref> [5] </ref>. Three features are used: 6 * The RMS energy of a speech segment. * The normalized value of the maximum correlation over the pitch range. * The normalized energy of the correlation over the pitch range.
Reference: [6] <author> J. D. Markel and A. H. Gray, </author> <title> Linear prediction of speech. </title> <address> New York: </address> <publisher> Springer, </publisher> <year> 1976. </year>
Reference-contexts: A silence detector is also used. Markel and Gray <ref> [6] </ref> pointed out a weakness of spectral flattening which is that flattening with the spectral estimate for nasals tends to corrupt the pitch information. This is due to the fact that the LPC spectral estimate for nasals is poor because of the presence of zeros [7].
Reference: [7] <author> S. H. J. van Vuuren, </author> <title> "Detection of nasals in speech." Course project report, </title> <institution> University of Pretoria, Pretoria, </institution> <month> Aug. </month> <year> 1992. </year>
Reference-contexts: Markel and Gray [6] pointed out a weakness of spectral flattening which is that flattening with the spectral estimate for nasals tends to corrupt the pitch information. This is due to the fact that the LPC spectral estimate for nasals is poor because of the presence of zeros <ref> [7] </ref>. This algorithm requires special bandpass filtering to limit the sensitivity to zeros of the spectral estimate.
Reference: [8] <author> B. Gold and L. R. Rabiner, </author> <title> "Parallel processing techniques for estimating pitch periods of speech in the time domain," </title> <journal> J. Acoust. Soc. Am., </journal> <volume> vol. 46, </volume> <pages> pp. 442-448, </pages> <month> Aug. </month> <year> 1969. </year>
Reference-contexts: Additional silence or speech classification is done according to the amplitude energy. This technique can be regarded as a frequency technique because of the deconvolution that occurs in the frequency domain. 2.5 Parallel processing technique This time-domain technique <ref> [8] </ref> has found widespread application in real-time systems. The signal is lowpass filtered to 900 Hz. See Fig. 9. Six impulse function signals denoting peaks and valleys are measured. Pitch periods are obtained from each function.
Reference: [9] <author> H. Hassanein and B. Bryden, </author> <title> "Implementation of the gold-rabiner pitch detector in real time environment using an improved voicing detector," </title> <journal> IEEE Trans. Acoust., Speech, Signal Processing, </journal> <volume> vol. 33, </volume> <pages> pp. 319-320, </pages> <month> Feb. </month> <year> 1985. </year>
Reference-contexts: If there is wide disagreement among the preliminary pitch estimates the speech is classified as unvoiced. The algorithm is reported to work well if the pitch frequency is below 220 Hz. This technique was recently reimplemented by Hassanein <ref> [9] </ref>. He adapts the window lengths according to the pitch estimate and uses additional zero crossing and energy information to decide whether the speech is voiced or unvoiced.
Reference: [10] <author> T. Funada, T. Suzuki, and L. Yu, </author> <title> "A pitch extraction method using a bank of bandpass filter-pairs," </title> <journal> Speech Communication, </journal> <volume> vol. 9, </volume> <pages> pp. 203-216, </pages> <year> 1990. </year>
Reference-contexts: He implemented his parallel processing technique on a TMS320 for a 2400bits/s LPC vocoder. 10 2.6 Pitch estimation with banks of bandpass filter-pairs This technique <ref> [10] </ref> is a frequency domain approach and is based on modern vector quantization techniques. One thousand bandpass filter-pairs are used to extract spectral information relating to the harmonics below a frequency of 1000 Hz.
Reference: [11] <author> E. Barnard, R. A. Cole, M. P. Vea, and F. </author> <title> Alleva, </title> <journal> "Ieee transactions on signal processing," IEEE Transactions on Signal Processing, </journal> <volume> vol. 39, no. 2, </volume> <pages> pp. 298-307, </pages> <year> 1991. </year>
Reference-contexts: A poor voiced or unvoiced decision, based on this multiplicity of candidates at higher harmonics, are reported to be the draw back of this technique. Also, pitch resolution is low due to the pattern quantization. 2.7 Pitch estimation with a neural-net classifier This technique is a time domain technique <ref> [11] </ref> using a neural network. It is essentially and extension of an earlier 'data reduction' technique described by Rabiner [4]. In the original technique, the speech signal is lowpass filtered and excursion cycles between the zero crossings extracted.
Reference: [12] <author> E. Barnard. </author> <type> Personal communication. </type>
Reference-contexts: Using the waveform peaks, the lowest obtained error rate using peak information against visually estimated pitch is reported to be 2 %. The authors noted that this technique fails on band-limited telephone speech <ref> [12] </ref>. They report errors due to ambiguous peaks, weak signals and transitions.
Reference: [13] <author> D. G. Childers, M. Hahn, and J. N. Larar, </author> <title> "Silent and voiced/unvoiced/mixed excitation (fourway) classification of speech," </title> <journal> IEEE Trans. Acoust., Speech, Signal Processing, </journal> <volume> vol. 37, no. 11, </volume> <pages> pp. 1771-1773, </pages> <year> 1989. </year>
Reference-contexts: did best at low pitch frequencies because fewer harmonics of the fundamental were included in the relatively short analysis window. 13 3 Detection of voiced speech Before pitch can be estimated it is necessary to decide if the speech signal is speech and then if speech, if it is voiced <ref> [13] </ref>. This decision is based on a statistical approach. Features on which these decisions can be based include: short-time energy, zero-crossing rate and the residual from eg. LPC-filtered speech. In the following we use short-time energy and zero-crossing rate.
Reference: [14] <author> Y. Lau and C. Chan, </author> <title> "Speech recognition based on zero crossing rate and energy," </title> <journal> IEEE Trans. Acoust., Speech, Signal Processing, </journal> <volume> vol. 33, </volume> <pages> pp. 320-323, </pages> <month> Feb. </month> <year> 1985. </year>
Reference-contexts: Similarly the zero-crossing rate is computed for each frame <ref> [14] </ref>. The number of zero crossings in a window is defined as Z (n) = m=nN+1 These features are estimated from a large number of speakers in the TIMIT corpus [15] excluding those on which the pitch are to be derived (refer Section 5).
Reference: [15] <author> V. Zue, S. Seneff, and J. Glass, </author> <title> "Speech database development at mit: Timit and beyond," </title> <journal> Speech Communication, </journal> <volume> vol. 9, </volume> <pages> pp. 351-356, </pages> <year> 1990. </year>
Reference-contexts: Similarly the zero-crossing rate is computed for each frame [14]. The number of zero crossings in a window is defined as Z (n) = m=nN+1 These features are estimated from a large number of speakers in the TIMIT corpus <ref> [15] </ref> excluding those on which the pitch are to be derived (refer Section 5). Analysis then allows the choice of thresholds and decision boundaries according to probability density. Fig. 12 shows a scatter plot of non-speech, voiced and unvoiced samples as a function of magnitude and zero crossings.
Reference: [16] <author> L. R. Rabiner and R. W. Schafer, </author> <title> Digital Processing of Speech Signals. </title> <address> New Jersey: </address> <publisher> Prentice-Hall, </publisher> <year> 1978. </year>
Reference-contexts: 0 4 8 12 zero crossings unvoiced voiced (a) magnitude (b) zero crossings Fig. 14: The pdfs of voiced vs. unvoiced speech as a function of (a) magnitude and (b) zero crossings. 15 4 Cepstrum technique with variable analysis win- dow length We implement the cepstrum technique of pitch estimation <ref> [16, 4, 17, 18] </ref>. <p> This technique is generally regarded as being more robust to noise and channel effects as present in telephone speech. 4.1 Cepstrum In the technique, the cepstrum <ref> [16] </ref> is used as a means of deconvolving the glottal excitation and vocal tract filter responses according to the model of speech production (refer Fig. 1). Fig. 15 depicts this process. ^^ F F log [ ] [ ][ ] Fig. 15: A block diagram for obtaining the cepstrum.
Reference: [17] <author> F. Wang and P. Yip, </author> <title> "Cepstrum analysis using discrete trigonometric transforms," </title> <journal> IEEE Transactions on Signal Processing, </journal> <volume> vol. 39, </volume> <pages> pp. 538-541, </pages> <month> Feb. </month> <year> 1991. </year>
Reference-contexts: 0 4 8 12 zero crossings unvoiced voiced (a) magnitude (b) zero crossings Fig. 14: The pdfs of voiced vs. unvoiced speech as a function of (a) magnitude and (b) zero crossings. 15 4 Cepstrum technique with variable analysis win- dow length We implement the cepstrum technique of pitch estimation <ref> [16, 4, 17, 18] </ref>.
Reference: [18] <author> H. Indefrey, W. Hess, and G. Seeser, </author> <title> "Design and evaluation of double-transform pitch determination algorithms with nonlinear distortion in the frequency domain preliminary results," </title> <booktitle> in ICASSP, </booktitle> <address> (Tampa, FL), </address> <pages> pp. 415-418, </pages> <year> 1985. </year>
Reference-contexts: 0 4 8 12 zero crossings unvoiced voiced (a) magnitude (b) zero crossings Fig. 14: The pdfs of voiced vs. unvoiced speech as a function of (a) magnitude and (b) zero crossings. 15 4 Cepstrum technique with variable analysis win- dow length We implement the cepstrum technique of pitch estimation <ref> [16, 4, 17, 18] </ref>.
Reference: [19] <author> R. W. Schafer and L. R. Rabiner, </author> <title> "System for automatic formant analysis of voiced speech," </title> <journal> J. Acoust. Soc. Am., </journal> <volume> vol. 47, </volume> <pages> pp. 634-648, </pages> <month> Feb. </month> <year> 1970. </year>
Reference-contexts: Fig. 16 shows the cep strum for a speech signal. 4.2 Adapting the analysis window length It is known that to obtain a reasonable estimate of the pitch period it is necessary for the analysis window to include more than one pitch period <ref> [19, 20] </ref>. <p> However, if the length of the analysis window is much longer than two pitch periods then the analysis no longer agrees with the short-time stationarity assumption made of the speech signal and the estimates may become noisy and smeared. In <ref> [19, 20] </ref> the length of the analysis window was adapted based on previous estimates of the pitch period. Accordingly, here we use a short-time analysis window length of 16 to 64 ms corresponding to a window of 256 to 1024 samples at a 16 kHz sampling rate.
Reference: [20] <author> L. R. Rabiner, </author> <title> "On the use of autocorrelation for pitch detection," </title> <journal> IEEE Trans. Acoust., Speech, Signal Processing, </journal> <volume> vol. 26, </volume> <pages> pp. 24-33, </pages> <month> Feb. </month> <year> 1977. </year>
Reference-contexts: Fig. 16 shows the cep strum for a speech signal. 4.2 Adapting the analysis window length It is known that to obtain a reasonable estimate of the pitch period it is necessary for the analysis window to include more than one pitch period <ref> [19, 20] </ref>. <p> However, if the length of the analysis window is much longer than two pitch periods then the analysis no longer agrees with the short-time stationarity assumption made of the speech signal and the estimates may become noisy and smeared. In <ref> [19, 20] </ref> the length of the analysis window was adapted based on previous estimates of the pitch period. Accordingly, here we use a short-time analysis window length of 16 to 64 ms corresponding to a window of 256 to 1024 samples at a 16 kHz sampling rate.
Reference: [21] <author> J. A. Marks, </author> <title> "Real time classification and pitch detection," </title> <booktitle> in COMSIG, </booktitle> <pages> pp. 1-6, </pages> <year> 1988. </year>
Reference-contexts: The too long analysis window includes the longer period and causes the error. This phenomenon is a problem in most of the frequency domain and autocorrelation type techniques. A peak picking scheme or the proposed analysis window length adaptation helps to alleviate such errors. Marks <ref> [21] </ref> pointed out that pitch is difficult to estimate for nasals. We remarked previously that time-domain techniques are in particularly affected by the presence of zeros in the signal due to the nasals. A nasal phoneme with cepstral-estimated pitch is shown in Fig. 27.
References-found: 21

