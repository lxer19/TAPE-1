URL: http://www.research.att.com/~yoav/papers/majp.ps.Z
Refering-URL: http://www.research.att.com/~yoav/talks/boostforstat.html
Root-URL: 
Title: Boosting a weak learning algorithm by majority To be published in Information and Computation  
Author: Yoav Freund 
Date: July 21, 1995  
Address: New Jersey  
Affiliation: AT&T Bell Laboratories  
Abstract: We present an algorithm for improving the accuracy of algorithms for learning binary concepts. The improvement is achieved by combining a large number of hypotheses, each of which is generated by training the given learning algorithm on a different set of examples. Our algorithm is based on ideas presented by Schapire in his paper "The strength of weak learnability", and represents an improvement over his results. The analysis of our algorithm provides general upper bounds on the resources required for learning in Valiant's polynomial PAC learning framework, which are the best general upper bounds known today. We show that the number of hypotheses that are combined by our algorithm is the smallest number possible. Other outcomes of our analysis are results regarding the representational power of threshold circuits, the relation between learnability and compression, and a method for parallelizing PAC learning algorithms. We provide extensions of our algorithms to cases in which the concepts are not binary and to the case where the accuracy of the learning algorithm depends on the distribution of the instances. 
Abstract-found: 1
Intro-found: 1
Reference: [AD93] <author> J. A. Aslam and S. E. Decatur. </author> <title> General bounds on statistical query learning 43 and PAC learning with noise via hypothesis boosting. </title> <booktitle> In Proc. 35th Annu. IEEE Sympos. </booktitle> <institution> Found. Comput. Sci., </institution> <month> November </month> <year> 1993. </year>
Reference-contexts: The use of boosting in the context of p-concepts [KS90] is another long standing open problem. Some progress on the problem of boosting in the context of independent label noise has been achieved in a recent work by Aslam and Decatur <ref> [AD93] </ref> about boosting learning algorithms in the statistical query model introduced by Kearns [Kea93]. Last but not least, boosting has been successfully applied to some practical machine learning problems [DSS93]. Further experimentation with boosting methods will hopefully achieve even better results.
Reference: [BEHW87] <author> A. Blumer, A. Ehrenfeucht, D. Haussler, and M. K. Warmuth. </author> <title> Occam's razor. </title> <journal> Inform. Proc. Lett., </journal> <volume> 24 </volume> <pages> 377-380, </pages> <month> April </month> <year> 1987. </year>
Reference-contexts: The size of H M is jHj c log m , where c = 1=(2fl 2 ). Following the well-known analysis of the Occam's razor principle <ref> [BEHW87] </ref> we get that the probability that the final hypothesis is consistent with a random sample of size m but has error larger than * is smaller than jH M j (1 *) m = jHj c log m (1 *) m . This quantity decreases rapidly with m.
Reference: [BEHW89] <author> A. Blumer, A. Ehrenfeucht, D. Haussler, and M. K. Warmuth. </author> <title> Learnability and the Vapnik-Chervonenkis dimension. </title> <journal> J. ACM, </journal> <volume> 36(4) </volume> <pages> 929-965, </pages> <year> 1989. </year>
Reference-contexts: Theorem 3.11 shows that for any learnable concept class there exists a learning algorithm in RP for which the dependence of the sample size on the required accuracy, when all other parameters are fixed, is O (1=*(log 1=*) 3=2 ). A general lower bound of (1=*) is given in <ref> [BEHW89] </ref> for learning any "non-trivial" concept class. This lower bound holds without regard to computational constraints on the learning algorithm.
Reference: [Dru93] <author> H. </author> <title> Drucker. private correspondence, </title> <type> 1992-1993. </type>
Reference-contexts: The analysis of this variant is quite straightforward, and its performance is close to the best performance we achieve. It also seems to be the variant whose application to practical learning problems is more efficient <ref> [Dru93] </ref>. The major drawback of this method is that it requires storage of the whole training set, which yield a space complexity dependence on * of O ((log 1=*) 2 =*) (assuming that the concept class is fixed and that its VC dimension is finite). <p> One undesired property of our boosting algorithm is that it requires prior knowledge of a distribution-independent bound on the accuracy of the hypotheses that WeakLearn generates. While guessing a bound is a theoretically feasible solution, it is expensive in practical applications <ref> [Dru93] </ref>. Recently, Freund and Schapire [FS95] have developed a boosting algorithm which does not require such prior knowledge. The number of weak hypotheses that need to be combined to reach a given level of accuracy is almost as small as the number achieved here.
Reference: [DSS93] <author> Harris Drucker, Robert Schapire, and Patrice Simard. </author> <title> Improving performance in neural networks using a boosting algorithm. </title> <booktitle> In Advances in Neural Informations Processing Systems 5, </booktitle> <pages> pages 42-49, </pages> <address> San Mateo, CA, 1993. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Last but not least, boosting has been successfully applied to some practical machine learning problems <ref> [DSS93] </ref>. Further experimentation with boosting methods will hopefully achieve even better results.
Reference: [FS95] <author> Yoav Freund and Robert E. Schapire. </author> <title> A decision-theoretic generalization of on-line learning and an application to boosting. </title> <booktitle> In eurocolt95, </booktitle> <year> 1995. </year>
Reference-contexts: One undesired property of our boosting algorithm is that it requires prior knowledge of a distribution-independent bound on the accuracy of the hypotheses that WeakLearn generates. While guessing a bound is a theoretically feasible solution, it is expensive in practical applications [Dru93]. Recently, Freund and Schapire <ref> [FS95] </ref> have developed a boosting algorithm which does not require such prior knowledge. The number of weak hypotheses that need to be combined to reach a given level of accuracy is almost as small as the number achieved here. <p> The number of weak hypotheses that need to be combined to reach a given level of accuracy is almost as small as the number achieved here. A deeper problem is that the assumption of distribution-independent bounds for learning algorithms often seems to be unreasonable. The results in <ref> [FS95] </ref> and Theorem 4.4 are encouraging in this respect because they shows that boosting can be achieved even without uniform bounds. This might be a sign that a richer, and maybe more realistic theory of learning can be developed in which performance bounds are distribution dependent.
Reference: [FW93] <author> Sally Floyd and Manfred Warmuth. </author> <title> Sample compressions, learnability, and the vapnik-chervonenkis dimension. </title> <type> Technical Report UCSC-CRL-93-13, </type> <institution> Computer and Information Sciences, University of California, Santa Cruz, </institution> <year> 1993. </year>
Reference-contexts: This strengthens the relationship between compression and learning which has been studied by Floyd and Warmuth <ref> [FW93] </ref>. The second implication was found together with Eli Shamir [Sha92]. <p> The saved sequences of examples are used by WeakLearn to regenerate the weak hypotheses; 10 then using these weak hypotheses, h M (x) is reconstructed. Representing hypotheses by means of a subset of the training examples has been further studied by Littlestone, Warmuth and Floyd <ref> [LW86, FW93] </ref>. We now use prove a bound on the size of the sample that B Samp has to use in order to guarantee that the final hypothesis has error smaller than *. <p> In the proof of this theorem we use a technique invented by Littlestone and Warmuth [LW86] in the above mentioned work which appears as Appendix A in <ref> [FW93] </ref>. Theorem 3.2 Let WeakLearn be a deterministic learning algorithm that generates, with probability &gt; 0 over the random training examples with which it is trained, a deterministic hypothesis whose error is smaller than 1=2 fl, for some fl &gt; 0.
Reference: [GHR92] <author> Goldmann, Hastad, and Razborov. </author> <title> Majority gates vs. general weighted threshold gates. Computational Complexity, </title> <type> 2, </type> <year> 1992. </year>
Reference-contexts: Schapire [Sch92], noted that the results presented in this paper can be used to show an interesting relationship between representation and approximation using majority gates. These results were independently discovered by Goldmann, Hastad and Razborov <ref> [GHR92] </ref>. However, while their proof technique is very elegant, our proof is more constructive (for details see Section 2.2). It is surprising to note that the boosting algorithm uses only a small fraction of the examples in the training set. <p> This application of boosting has been discovered by Schapire [Sch92]. A slightly weaker version of this result was independently proven by Goldmann, Hastad, and Razborov <ref> [GHR92] </ref> using a completely different proof technique. In the following presentation we follow their notation. Let f denote a Boolean function whose domain is f1; 1g n and range is f1; 1g. Let H be a set of Boolean functions defined over the same domain and range. <p> However, their proof does not show how one can find the functions h i 2 H. On the other hand, our proof is constructive in that it shows how to generate the distributions that correspond to the desired functions. For completeness we give a simple lemma (Lemma 4 in <ref> [GHR92] </ref>) that gives an approximate converse to Theorem 2.6. Lemma 2.7 Let f and H be as in Theorem 2.6.
Reference: [GKP91] <author> Ronald L. Graham, Donald E. Knuth, and Oren Patashnik. </author> <title> Concrete mathematics, a foundation for computer science. </title> <publisher> Addison-Wesley, </publisher> <year> 1991. </year>
Reference: [HKLW91] <author> D. Haussler, M. Kearns, N. Littlestone, and M. K. Warmuth. </author> <title> Equivalence of models for polynomial learnability. </title> <journal> Inform. Comput., </journal> <volume> 95(2) </volume> <pages> 129-161, </pages> <month> December </month> <year> 1991. </year>
Reference-contexts: The probability that the algorithm fails is measured with respect to the random choice of the examples given to the learning algorithm and possible internal randomization of the algorithm. 1 As was recognized by Haussler et. al. <ref> [HKLW91] </ref>, increasing the reliability of any learning algorithm is easy. This can be done by testing the hypothesis generated by the algorithm on an independent set of examples to validate its accuracy. If the accuracy is not sufficient, the algorithm is run again, on a new set of random examples. <p> In order for the algorithm B Filt to work successfully, we need the reliability of WeakLearn to be high. However, as noted by Haussler et. al. <ref> [HKLW91] </ref>, it is easy to 25 boost the reliability of a learning algorithm. We give the performance of one possible reliability-boosting algorithm, B Rel in the following lemma. The proof of the lemma and the description of the algorithm are given in Appendix B. <p> This framework is one of the most studied frameworks in computational learning theory. In this section we show the implications of our results in this framework. We start by presenting some notation following Haussler et. al. <ref> [HKLW91] </ref>. Assume that the sample space is a union of sample spaces of increasing complexity: X = [ 1 n=1 X n . <p> A simple application of Theorem 3.8 gives the following upper bound on the resources required for PAC learning. Theorem 3.11 If C is a weakly PAC learnable concept class, parameterized by n and s in the standard way <ref> [HKLW91] </ref>, then there exists a PAC learning algorithm for C that learns with accuracy * and reliability ffi and: * requires a sample of size (1=*)(log 1=*) 3=2 (log log 1=* + log 1=ffi)p 1 (n; s), * halts in time (1=*)(log 1=*) 5=2 (log log 1=* + log 1=ffi)p 2
Reference: [HLW88] <author> D. Haussler, N. Littlestone, and M. K. Warmuth. </author> <title> Predicting f0,1g functions on randomly drawn points. </title> <booktitle> In Proceedings of the 29th Annual IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pages 100-109. </pages> <publisher> IEEE Computer Society Press, </publisher> <year> 1988. </year>
Reference: [Kea93] <author> M. Kearns. </author> <title> Efficient noise-tolerant learning from statistical queries. </title> <booktitle> In Proc. 25th Annu. ACM Sympos. Theory Comput., </booktitle> <pages> pages 392-401. </pages> <publisher> ACM Press, </publisher> <address> New York, NY, </address> <year> 1993. </year>
Reference-contexts: Some progress on the problem of boosting in the context of independent label noise has been achieved in a recent work by Aslam and Decatur [AD93] about boosting learning algorithms in the statistical query model introduced by Kearns <ref> [Kea93] </ref>. Last but not least, boosting has been successfully applied to some practical machine learning problems [DSS93]. Further experimentation with boosting methods will hopefully achieve even better results.
Reference: [KS90] <author> M. J. Kearns and R. E. Schapire. </author> <title> Efficient distribution-free learning of probabilistic concepts. </title> <booktitle> In Proc. of the 31st Symposium on the Foundations of Comp. Sci., </booktitle> <pages> pages 382-391. </pages> <publisher> IEEE Computer Society Press, Los Alamitos, </publisher> <address> CA, </address> <year> 1990. </year>
Reference-contexts: However, the results regarding real-valued concept classes are still rather weak, and one would hope that stronger types of boosting can be achieved in that context. The use of boosting in the context of p-concepts <ref> [KS90] </ref> is another long standing open problem. Some progress on the problem of boosting in the context of independent label noise has been achieved in a recent work by Aslam and Decatur [AD93] about boosting learning algorithms in the statistical query model introduced by Kearns [Kea93].
Reference: [KV88] <author> M. Kearns and L.G. Valiant. </author> <title> Learning boolean formulae or finite automata is as hard as factoring. </title> <type> Technical Report TR-14-88, </type> <institution> Harvard University Aiken Computation Laboratory, </institution> <address> Cambridge, MA, </address> <year> 1988. </year>
Reference-contexts: Kearns and Valiant <ref> [KV88, KV94] </ref> introduced a weaker form of learnability in which the error cannot necessarily be made arbitrarily small.
Reference: [KV94] <author> Kearns and Valiant. </author> <title> Cryptographic limitations on learning boolean formulae and finite automata. </title> <journal> Journal of the ACM, </journal> <volume> 41(1) </volume> <pages> 67-95, </pages> <year> 1994. </year>
Reference-contexts: Two different variants of the PAC model were introduced by Kearns and Valiant <ref> [KV94] </ref> to address this issue. In strong PAC learning, which is the more common model, the learner is given the required accuracy, *, as input, and is required to generate a hypothesis whose error is smaller than *. <p> When learning with respect to a given distribution over the instances, weak and strong learning are not equivalent. Kearns and Valiant <ref> [KV94] </ref> proved that monotone boolean functions can be learned weakly, but not strongly, with respect to the uniform distribution. This seemed to indicate that weak and strong distribution-free learning should also be separated. However, Schapire [Sch90] proved that weak and strong PAC learning are equivalent in the distribution-free case. <p> Kearns and Valiant <ref> [KV88, KV94] </ref> introduced a weaker form of learnability in which the error cannot necessarily be made arbitrarily small.
Reference: [LW86] <author> Nick Littlestone and Manfred Warmuth. </author> <title> Relating data compression and learnability. </title> <note> This early and hard-to-locate work is referenced and partly re-written in FW93, 1986. 44 </note>
Reference-contexts: The saved sequences of examples are used by WeakLearn to regenerate the weak hypotheses; 10 then using these weak hypotheses, h M (x) is reconstructed. Representing hypotheses by means of a subset of the training examples has been further studied by Littlestone, Warmuth and Floyd <ref> [LW86, FW93] </ref>. We now use prove a bound on the size of the sample that B Samp has to use in order to guarantee that the final hypothesis has error smaller than *. <p> We now use prove a bound on the size of the sample that B Samp has to use in order to guarantee that the final hypothesis has error smaller than *. In the proof of this theorem we use a technique invented by Littlestone and Warmuth <ref> [LW86] </ref> in the above mentioned work which appears as Appendix A in [FW93]. <p> We now give the formal proof, which is an adaptation of a technique used by War-muth and Littlestone in <ref> [LW86] </ref>. Fix any concept c 2 C.
Reference: [Nat91] <author> B. K. Natarajan. </author> <title> Machine Learning: A Theoretical Approach. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1991. </year>
Reference-contexts: described in the next section might be more relevant. 4.3 Boosting real valued concepts A modification of the boosting algorithm can be used for boosting learning algorithms for concept classes whose range is a real number (for a review of algorithms for learning real valued functions, see Chapter 5 in <ref> [Nat91] </ref>). This variant of the boosting algorithm transforms learning algorithms that generate hypotheses whose expected error, with respect to the input distribution, is small to algorithms that generate hypotheses whose error is small for most of the input domain.
Reference: [Sch90] <author> R. E. Schapire. </author> <title> The strength of weak learnability. </title> <journal> Machine Learning, </journal> <volume> 5(2) </volume> <pages> 197-227, </pages> <year> 1990. </year>
Reference-contexts: Kearns and Valiant [KV94] proved that monotone boolean functions can be learned weakly, but not strongly, with respect to the uniform distribution. This seemed to indicate that weak and strong distribution-free learning should also be separated. However, Schapire <ref> [Sch90] </ref> proved that weak and strong PAC learning are equivalent in the distribution-free case. <p> The concept of a boosting algorithm was first presented by Schapire in <ref> [Sch90] </ref>. A boosting algorithm is a learning algorithm that uses as a subroutine a different learning algorithm. The goal of the boosting algorithm is to efficiently generate high-accuracy hypotheses using a learning algorithm that can efficiently generate only low-accuracy hypotheses. The boosting algorithm invented by Schapire [Sch90], was a breakthrough in <p> presented by Schapire in <ref> [Sch90] </ref>. A boosting algorithm is a learning algorithm that uses as a subroutine a different learning algorithm. The goal of the boosting algorithm is to efficiently generate high-accuracy hypotheses using a learning algorithm that can efficiently generate only low-accuracy hypotheses. The boosting algorithm invented by Schapire [Sch90], was a breakthrough in that it showed that any polynomial time learning algorithm that generates hypotheses whose error is just slightly smaller than 1=2 can be transformed into a polynomial time learning algorithm that generates hypotheses whose error is arbitrarily small. <p> In many cases this size is very large, moreover, often H is infinite or even uncountable. These cases can be analyzed using the notion of VC-dimension. However, Schapire <ref> [Sch90] </ref>, suggested the following elegant proof that is based only on the assumption that the size of the sample used by WeakLearn is uniformly bounded. <p> This avoids storing many examples in memory and decreases the space complexity to O (log (1=*)). Selecting examples directly out of the input stream is the basis of Schapire's boosting algorithm <ref> [Sch90] </ref>. Schapire used the term "filtering" to describe this process. The selection is viewed as a "filter" that lies between the source of examples, EX, and the weak learning algorithm. <p> In other words, a weak learning algorithm produces a prediction rule that performs just slightly better than random guessing. Schapire <ref> [Sch90] </ref> has shown that the notions of weak and strong PAC learning are equivalent. Moreover, the boosting algorithm he invented provides an effective way for translating any weak learning algorithm into a strong learning algorithm. <p> The time and space complexity of the boosted algorithm, as well as the size of the final hypothesis follow from the discussion of the resources required by B Filt which follows Theorem 3.8. We now compare this theorem to Theorem 4 in <ref> [Sch90] </ref>. The statement there is that the dependence of the sample and time complexity on * is O (1=* poly (1=*)), and that the other dependencies on 1=* are poly-logarithmic. Our theorem tightens these bounds by giving the explicit powers in the polynomials over log (1=*) and log (1=ffi).
Reference: [Sch91] <author> Robert E. Schapire. </author> <title> The Design and Analysis of Efficient Learning Algorithms. </title> <type> PhD thesis, </type> <institution> M.I.T., </institution> <year> 1991. </year>
Reference-contexts: To avoid this problem the required error has to be set to a smaller value, thus making the detection of a good hypothesis easier. We omit the details of this variant of the boosting algorithm. 4.2 Boosting multiple valued concepts As was noted by Schapire <ref> [Sch91] </ref>, the generalization of the equivalence between strong and weak learning to concepts with more than two labels does not enjoy the same tightness as the two label case. <p> In this case, using a random coin flip to choose one of the two possible labels will give a correct answer half of the time, but the concept class might still be unlearnable <ref> [Sch91] </ref>. 40 k is replaced by k t: ff i 8 &gt; &gt; : 2 kti1 2 c r ( 1 2 c r ( 1 2 e i1+r if i kt 2 2 It is interesting to note that the resources required are completely independent of j, the number of
Reference: [Sch92] <author> Robert E. Schapire. </author> <title> private correspondence, </title> <month> January </month> <year> 1992. </year>
Reference-contexts: However, in real world problems, A's accuracy usually depends on the distribution of the examples. We show that if A's accuracy degradation is not too abrupt, then boosting can still be used to generate a hypothesis whose accuracy is better than 1 *. Schapire <ref> [Sch92] </ref>, noted that the results presented in this paper can be used to show an interesting relationship between representation and approximation using majority gates. These results were independently discovered by Goldmann, Hastad and Razborov [GHR92]. <p> While it needs (1=*) examples to generate a hypothesis that has accuracy *, only O (log 1=*) of them are passed to the weak learners. Two interesting implications arise from this fact. The first implication was pointed out to us by Schapire <ref> [Sch92] </ref>. <p> This application of boosting has been discovered by Schapire <ref> [Sch92] </ref>. A slightly weaker version of this result was independently proven by Goldmann, Hastad, and Razborov [GHR92] using a completely different proof technique. In the following presentation we follow their notation. Let f denote a Boolean function whose domain is f1; 1g n and range is f1; 1g.
Reference: [Sha92] <author> E. Shamir. </author> <title> private correspondence, </title> <year> 1992. </year>
Reference-contexts: This strengthens the relationship between compression and learning which has been studied by Floyd and Warmuth [FW93]. The second implication was found together with Eli Shamir <ref> [Sha92] </ref>. We observed 4 that if training examples can be accumulated in parallel by several parallel processors, then our methods can translate any PAC learning algorithm to a version that runs in time O (log 1=*) on a parallel computer with fi (1=*) processors.
Reference: [Val84] <author> L. G. Valiant. </author> <title> A theory of the learnable. </title> <journal> Commun. ACM, </journal> <volume> 27(11) </volume> <pages> 1134-1142, </pages> <month> November </month> <year> 1984. </year>
Reference-contexts: One of the main results of this paper is an upper bound on the resources required for learning in the distribution-free model of learnability introduced by Valiant <ref> [Val84] </ref>. In Valiant's model, commonly referred to as the PAC (Probably Approximately Correct) learning model, or the distribution-free learning model, the quality of a learning algorithm is defined as follows. <p> However, most learning algorithms can be used for a family of concept classes, and one is then interested in the way the performance of the learning algorithm depends on the complexity of the concept class. Valiant <ref> [Val84] </ref> presented a framework, called the PAC 13 learning framework, in which such quantification can be done. This framework is one of the most studied frameworks in computational learning theory. In this section we show the implications of our results in this framework.
References-found: 22

