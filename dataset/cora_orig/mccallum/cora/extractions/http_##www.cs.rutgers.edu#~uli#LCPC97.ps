URL: http://www.cs.rutgers.edu/~uli/LCPC97.ps
Refering-URL: http://www.cs.rutgers.edu/~uli/pubs.html
Root-URL: http://www.cs.rutgers.edu
Email: email: uli@cs.rutgers.edu  
Title: Automatic Data Layout With Read-Only Replication and Memory Constraints  
Author: Ulrich Kremer 
Affiliation: Department of Computer Science Rutgers University  
Abstract: The memory requirement characteristics of a data layout are particularly important for applications that are executed on a parallel machine mainly because of the amount of main memory that the machine provides, rather than its computation power. It may not be feasible to execute such a memory intensive program on a conventional uniprocessor due to the lack of the necessary memory resources. Data layouts that specify arrays with multiple read-only copies | each copy with a different data mapping | can significantly reduce the overall execution time of a program since otherwise necessary communication is avoided. However, read-only replication increases a program's memory requirements and therefore should only be applied selectively, in particular for memory intensive applications. This short paper discusses an extension to our previous framework for automatic data layout that considers read-only data replication and minimizes the overall execution time under given memory constraints. 
Abstract-found: 1
Intro-found: 1
Reference: [AW96] <author> T. Autrey and M. Wolfe. </author> <title> Initial results for glacial variable analysis. </title> <booktitle> In Proceedings of the Nineth Workshop on Languages and Compilers for Parallel Computing, </booktitle> <address> San Jose, CA, </address> <month> August </month> <year> 1996. </year>
Reference-contexts: In fact, some researchers argue that machines with a large main memory should always have multiple processors in order to make cost-effective use of the memory's capacity and bandwidth [WH95]. Many scientific applications contain array variables that are much less frequently modified than they are referenced (glacial variables <ref> [AW96] </ref>). A read-only region of an array variable is a program region where the array is not modified and all references to the array within the region refer to the same array value.
Reference: [Kre95] <author> U. Kremer. </author> <title> Automatic Data Layout for Distributed Memory Machines. </title> <type> PhD thesis, </type> <institution> Rice University, </institution> <month> October </month> <year> 1995. </year> <note> Available as CRPC-TR95-559-S. </note>
Reference-contexts: Nodes and edges are weighted with their estimated execution times. A solution to the data layout selection problem picks exactly one candidate data layout for each phase such that the overall cost of the resulting path is minimal. Finding an optimal solution has been shown to be NP-complete <ref> [Kre95] </ref>. The previous DLG construction algorithm was based on the assumption that only a single copy of an array can exist at any time during program execution. <p> The following section discusses the new framework for simple read-only regions. 2.1 Simple Read-Only Regions A simple read-only region is a subgraph in the phase control flow graph (PCFG). The PCFG is an augmented control flow graph where each phase is represented by a single node <ref> [Kre95] </ref>. A simple read-only region consists of a single phase that defines the value of a read-only variable and a singly nested loop in the PCFG that contains phases referencing the read-only variable. Figure 3 shows partial DLGs for the simple read-only region for array "a" in our Adi example.
Reference: [Kre96] <author> U. Kremer. </author> <title> Automatic data layout with read-only replication and memory constraints. </title> <type> Technical Report LCSR-TR93-283, </type> <institution> Department of Computer Science, Rutgers University, </institution> <month> December </month> <year> 1996. </year>
Reference-contexts: The formulation of memory constraints assumes that the sizes of all arrays are known at compile or tool invocation time. A more detailed discussion can be found in <ref> [Kre96] </ref>. 2.2 Experiments To compare the efficiency of the old and new framework, 10 instances of the DLG for our Adi example were generated, where each phase was represented by five possible candidate data layouts. Each problem instance had different node and edge weights.
Reference: [WH95] <author> D. Wood and M. Hill. </author> <title> Cost-effective parallel computing. </title> <booktitle> IEEE Computer, </booktitle> <month> Feb </month> <year> 1995. </year> <title> 2 CPLEX is a trademark of CPLEX Optimization, </title> <publisher> Inc. </publisher>
Reference-contexts: Using a parallel machine instead of a uniprocessor is often the only choice for running memory intensive applications. In fact, some researchers argue that machines with a large main memory should always have multiple processors in order to make cost-effective use of the memory's capacity and bandwidth <ref> [WH95] </ref>. Many scientific applications contain array variables that are much less frequently modified than they are referenced (glacial variables [AW96]).
References-found: 4

