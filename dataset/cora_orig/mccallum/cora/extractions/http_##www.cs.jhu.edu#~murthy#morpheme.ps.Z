URL: http://www.cs.jhu.edu/~murthy/morpheme.ps.Z
Refering-URL: http://www.cs.jhu.edu/~murthy/
Root-URL: 
Title: Discovering Morphemic Suffixes A Case Study In MDL Induction  
Author: Michael R. Brent, Sreerama K. Murthy Andrew Lundberg 
Abstract: This paper reports experiments in the automatic discovery of linguistically significant regularities in text. The minimum description length principle is exploited to evaluate linguistic hypotheses with respect to a corpus and a theory of the types of regularities to be found in it. The domain of inquiry in this paper is the discovery of morphemic suffixes such as English -ing and -ly, but the technique is widely applicable to language learning problems.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Lloyd Allison. </author> <title> Minimum message length encoding, evolutionary trees and multiple alignment. </title> <type> Technical report, </type> <institution> Department of Computer Science, Monash University, Clayton, </institution> <address> Victoria, Australia, </address> <year> 1991. </year>
Reference-contexts: MDL induction has been successfully applied to a large number of learning problems in the past. Examples include hand-printed character recognition [14], decision tree induction [20], molecular evolution <ref> [1, 18] </ref>, analysing dynamic systems [8], learning engineering models [21], clustering [6], computer vision [13] and constructive induction [19]. In the context of automated concept acquisition from linguistic corpora, however, applications of the MDL principle have been relatively few.
Reference: [2] <author> Michael R. Brent. </author> <title> From grammar to lexicon: Unsupervised learning of lexical syntax. </title> <journal> Computational Linguistics, </journal> <volume> 19 </volume> <pages> 243-262, </pages> <year> 1993. </year>
Reference-contexts: In the context of automated concept acquisition from linguistic corpora, however, applications of the MDL principle have been relatively few. MDL principle has been explored for lexical knowledge acquisition <ref> [2] </ref>, speech segmentation [3, 7], and to phonology [10, 11]. Conceptually, induction can be viewed in terms of a module that enumerates a set of hypotheses, and another independent module that determines the most plausible hypothesis.
Reference: [3] <author> M.R. Brent, A. Gafos, and T.A. Cartwright. </author> <title> Phonotactics and the lexicon: Beyond bootstrapping. </title> <editor> In E. Clark, editor, </editor> <booktitle> Proceedings of the 1994 Stan-ford Child Language Research Forum, </booktitle> <address> Cambridge, UK, 1994. </address> <publisher> Cambridge University Press. </publisher>
Reference-contexts: In the context of automated concept acquisition from linguistic corpora, however, applications of the MDL principle have been relatively few. MDL principle has been explored for lexical knowledge acquisition [2], speech segmentation <ref> [3, 7] </ref>, and to phonology [10, 11]. Conceptually, induction can be viewed in terms of a module that enumerates a set of hypotheses, and another independent module that determines the most plausible hypothesis.
Reference: [4] <author> Eric Brill, David Magerman, Mitchell Marcus, and Beatrice Santorini. </author> <title> Deducing linguistic structure from the statistics of large corpora. </title> <booktitle> In Proceedings of the DARPA Speech and Natural Language Workshop, </booktitle> <month> June </month> <year> 1990, </year> <pages> pages 275-282, </pages> <address> Harriman, NY, </address> <year> 1990. </year> <pages> DARPA. </pages>
Reference-contexts: Most of these exploit statistics based on information theory to measure how likely two linguistic entities are to co-occur. Co-occurrence statistics have been used to assess semantic similarity [15], PP attachment preference [16], linguistically significant collocations [23], syntactic categories <ref> [4] </ref>, and syntactic rules [5].
Reference: [5] <author> Eric Brill and Mitchell Marcus. </author> <title> Automatically acquiring phrase structure using distributional analysis. </title> <booktitle> In Darpa Workshop on Speech and Natural Language, </booktitle> <address> Harriman, NY, </address> <year> 1992. </year> <pages> DARPA. </pages>
Reference-contexts: Most of these exploit statistics based on information theory to measure how likely two linguistic entities are to co-occur. Co-occurrence statistics have been used to assess semantic similarity [15], PP attachment preference [16], linguistically significant collocations [23], syntactic categories [4], and syntactic rules <ref> [5] </ref>.
Reference: [6] <author> P. Bryant. </author> <title> On detecting clusters using the MDL principle. </title> <booktitle> In Proceedings of the 4th Conference of the International Federation of Classification Societies, </booktitle> <pages> pages 154-155, </pages> <year> 1993. </year>
Reference-contexts: MDL induction has been successfully applied to a large number of learning problems in the past. Examples include hand-printed character recognition [14], decision tree induction [20], molecular evolution [1, 18], analysing dynamic systems [8], learning engineering models [21], clustering <ref> [6] </ref>, computer vision [13] and constructive induction [19]. In the context of automated concept acquisition from linguistic corpora, however, applications of the MDL principle have been relatively few. MDL principle has been explored for lexical knowledge acquisition [2], speech segmentation [3, 7], and to phonology [10, 11].
Reference: [7] <author> T.A. Cartwright and M.R. Brent. </author> <title> Segmenting speech without a lexicon: The roles of phonotactics and the speech source. </title> <booktitle> In Proceedings of the First Meeting of the ACL Special Interest Group in Computational Phonology, </booktitle> <pages> pages 83-91. </pages> <institution> Association for Computational Linguistics, </institution> <year> 1994. </year>
Reference-contexts: In the context of automated concept acquisition from linguistic corpora, however, applications of the MDL principle have been relatively few. MDL principle has been explored for lexical knowledge acquisition [2], speech segmentation <ref> [3, 7] </ref>, and to phonology [10, 11]. Conceptually, induction can be viewed in terms of a module that enumerates a set of hypotheses, and another independent module that determines the most plausible hypothesis.
Reference: [8] <author> R. M. Chen. </author> <title> State and parameter estimation for dynamic systems with colored noise using MDL. </title> <journal> IEEE Trans on Automatic Control, </journal> <volume> 36 </volume> <pages> 813-823, </pages> <year> 1991. </year>
Reference-contexts: MDL induction has been successfully applied to a large number of learning problems in the past. Examples include hand-printed character recognition [14], decision tree induction [20], molecular evolution [1, 18], analysing dynamic systems <ref> [8] </ref>, learning engineering models [21], clustering [6], computer vision [13] and constructive induction [19]. In the context of automated concept acquisition from linguistic corpora, however, applications of the MDL principle have been relatively few.
Reference: [9] <author> K. Church. </author> <title> A Stochastic Parts Program and Noun Phrase Parser for Unrestricted Text. </title> <booktitle> In Proceedings of the 2nd ACL Conference on Applied NLP. ACL, </booktitle> <year> 1988. </year>
Reference: [10] <author> T. Mark Ellison. </author> <title> Discovering planar segregations. </title> <booktitle> In AAAI Spring Symposium on Machine Learning of Natural Language and Ontology. AAAI, </booktitle> <year> 1991. </year>
Reference-contexts: In the context of automated concept acquisition from linguistic corpora, however, applications of the MDL principle have been relatively few. MDL principle has been explored for lexical knowledge acquisition [2], speech segmentation [3, 7], and to phonology <ref> [10, 11] </ref>. Conceptually, induction can be viewed in terms of a module that enumerates a set of hypotheses, and another independent module that determines the most plausible hypothesis. MDL is a criterion for evaluating hypotheses in terms of how well they explain the regularities in the input.
Reference: [11] <author> T. Mark Ellison. </author> <title> The iterative learning of phonological rules. </title> <journal> Computational Linguistics, 1994. </journal> <volume> Forthcoming. </volume> <pages> 11 </pages>
Reference-contexts: In the context of automated concept acquisition from linguistic corpora, however, applications of the MDL principle have been relatively few. MDL principle has been explored for lexical knowledge acquisition [2], speech segmentation [3, 7], and to phonology <ref> [10, 11] </ref>. Conceptually, induction can be viewed in terms of a module that enumerates a set of hypotheses, and another independent module that determines the most plausible hypothesis. MDL is a criterion for evaluating hypotheses in terms of how well they explain the regularities in the input.
Reference: [12] <author> Steven Finch and Nick Chater. </author> <title> Bootstrapping syntactic categories using statistical methods. </title> <editor> In Walter Daelmans and David Powers, editors, </editor> <booktitle> Background and Experiments in Machine Learning of Natural Language: Proceedings of the 1st shoe Workshop, </booktitle> <year> 1992. </year>
Reference-contexts: Email: murthy@cs.jhu.edu 1 1. How should statistical measures be interpreted? Church (1988) and Hindle (1993) use co-occurrence statistics for lexical and syntactic disambiguation, so their numbers are interpreted operationally by disambiguation systems. But other researchers have collected numbers without providing any objective interpretation. For example, <ref> [12] </ref> describes a hierarchical cluster analysis on word-adjacency statistics. The authors claim that some of the thousands of resulting classes correspond roughly to familiar syntactic or semantic classes. But this interpretation of classes lacks semantics, operational or otherwise. 2.
Reference: [13] <author> Noah S. Friedland. </author> <title> Utilizing Energy Function and Description Length Minimization for Integrated Delineation, Representation and Classification of Objects. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Mary-land, College Park, </institution> <year> 1993. </year>
Reference-contexts: MDL induction has been successfully applied to a large number of learning problems in the past. Examples include hand-printed character recognition [14], decision tree induction [20], molecular evolution [1, 18], analysing dynamic systems [8], learning engineering models [21], clustering [6], computer vision <ref> [13] </ref> and constructive induction [19]. In the context of automated concept acquisition from linguistic corpora, however, applications of the MDL principle have been relatively few. MDL principle has been explored for lexical knowledge acquisition [2], speech segmentation [3, 7], and to phonology [10, 11].
Reference: [14] <author> Q. Gao and M. Li. </author> <title> The minimum description length principle and its application to online learning of handprinted characters. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 843-848, </pages> <address> Los Altos, CA, 1989. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: The MDL Approach Minimum description length (MDL) induction procedures [22, 17] have a generative semantics within which disparate information sources can be "naturally" combined. MDL induction has been successfully applied to a large number of learning problems in the past. Examples include hand-printed character recognition <ref> [14] </ref>, decision tree induction [20], molecular evolution [1, 18], analysing dynamic systems [8], learning engineering models [21], clustering [6], computer vision [13] and constructive induction [19]. In the context of automated concept acquisition from linguistic corpora, however, applications of the MDL principle have been relatively few.
Reference: [15] <author> D. Hindle. </author> <title> Noun classification from predicate argument structures. </title> <booktitle> In Proceedings of the 28th Annual Meeting of the ACL, </booktitle> <pages> pages 268-275. </pages> <booktitle> ACL, </booktitle> <year> 1990. </year>
Reference-contexts: 1 Introduction Many recent papers have reported work on the automatic discovery of linguistic regularities in text. Most of these exploit statistics based on information theory to measure how likely two linguistic entities are to co-occur. Co-occurrence statistics have been used to assess semantic similarity <ref> [15] </ref>, PP attachment preference [16], linguistically significant collocations [23], syntactic categories [4], and syntactic rules [5].
Reference: [16] <author> Don Hindle and Mats Rooth. </author> <title> Structural ambiguity and lexical relations. </title> <booktitle> Computational Linguistics, </booktitle> <pages> pages 103-120, </pages> <year> 1993. </year>
Reference-contexts: 1 Introduction Many recent papers have reported work on the automatic discovery of linguistic regularities in text. Most of these exploit statistics based on information theory to measure how likely two linguistic entities are to co-occur. Co-occurrence statistics have been used to assess semantic similarity [15], PP attachment preference <ref> [16] </ref>, linguistically significant collocations [23], syntactic categories [4], and syntactic rules [5].
Reference: [17] <author> Ming Li and Paul M. B. Vitanyi. </author> <title> Inductive reasoning and kolmogorov complexity. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 44 </volume> <pages> 342-384, </pages> <year> 1992. </year>
Reference-contexts: But it is nontrivial to combine these two measurements. Arbitrary combinations, such as addition or multiplication, can yield meaningless numbers. The MDL Approach Minimum description length (MDL) induction procedures <ref> [22, 17] </ref> have a generative semantics within which disparate information sources can be "naturally" combined. MDL induction has been successfully applied to a large number of learning problems in the past.
Reference: [18] <author> A. Milosavljevic and J. Jurka. </author> <title> Discovery by minimal length encoding: A case study in molecular evolution. </title> <journal> Machine Learning, </journal> <volume> 12 </volume> <pages> 69-89, </pages> <year> 1993. </year>
Reference-contexts: MDL induction has been successfully applied to a large number of learning problems in the past. Examples include hand-printed character recognition [14], decision tree induction [20], molecular evolution <ref> [1, 18] </ref>, analysing dynamic systems [8], learning engineering models [21], clustering [6], computer vision [13] and constructive induction [19]. In the context of automated concept acquisition from linguistic corpora, however, applications of the MDL principle have been relatively few.
Reference: [19] <author> B. Pfahringer. </author> <title> Controlling constructive induction in ciPF: An MDL approach. </title> <editor> In F. Bergadano and L. de Raedt, editors, </editor> <booktitle> Proceedings of the European Conference on Machine Learning, </booktitle> <pages> pages 242-256, </pages> <address> Berlin, 1994. </address> <publisher> Springer. </publisher>
Reference-contexts: MDL induction has been successfully applied to a large number of learning problems in the past. Examples include hand-printed character recognition [14], decision tree induction [20], molecular evolution [1, 18], analysing dynamic systems [8], learning engineering models [21], clustering [6], computer vision [13] and constructive induction <ref> [19] </ref>. In the context of automated concept acquisition from linguistic corpora, however, applications of the MDL principle have been relatively few. MDL principle has been explored for lexical knowledge acquisition [2], speech segmentation [3, 7], and to phonology [10, 11].
Reference: [20] <author> J. Ross Quinlan and Ronald L. Rivest. </author> <title> Inferring decision trees using the minimum description length principle. </title> <journal> Information and Computation, </journal> <volume> 80 </volume> <pages> 227-248, </pages> <year> 1989. </year>
Reference-contexts: The MDL Approach Minimum description length (MDL) induction procedures [22, 17] have a generative semantics within which disparate information sources can be "naturally" combined. MDL induction has been successfully applied to a large number of learning problems in the past. Examples include hand-printed character recognition [14], decision tree induction <ref> [20] </ref>, molecular evolution [1, 18], analysing dynamic systems [8], learning engineering models [21], clustering [6], computer vision [13] and constructive induction [19]. In the context of automated concept acquisition from linguistic corpora, however, applications of the MDL principle have been relatively few.
Reference: [21] <author> R. B. Rao and S.C. Lu. </author> <title> Learning engineering models with the minimum description length principle. </title> <booktitle> In Proceedings of the Tenth National Conference on Artificial Intelligence, </booktitle> <pages> pages 717-722, </pages> <address> Menlo Park, CA, 1992. </address> <publisher> AAAI Press/MIT Press. </publisher>
Reference-contexts: MDL induction has been successfully applied to a large number of learning problems in the past. Examples include hand-printed character recognition [14], decision tree induction [20], molecular evolution [1, 18], analysing dynamic systems [8], learning engineering models <ref> [21] </ref>, clustering [6], computer vision [13] and constructive induction [19]. In the context of automated concept acquisition from linguistic corpora, however, applications of the MDL principle have been relatively few. MDL principle has been explored for lexical knowledge acquisition [2], speech segmentation [3, 7], and to phonology [10, 11].
Reference: [22] <author> Jorma Rissanen. </author> <title> Modeling by shortest data description. </title> <journal> Automatica, </journal> <volume> 14 </volume> <pages> 465-471, </pages> <year> 1978. </year>
Reference-contexts: But it is nontrivial to combine these two measurements. Arbitrary combinations, such as addition or multiplication, can yield meaningless numbers. The MDL Approach Minimum description length (MDL) induction procedures <ref> [22, 17] </ref> have a generative semantics within which disparate information sources can be "naturally" combined. MDL induction has been successfully applied to a large number of learning problems in the past.
Reference: [23] <author> Frank Smadja. </author> <title> Retrieving lexical collocations from text: </title> <booktitle> Xtract. Computational Linguistics, </booktitle> <pages> pages 143-177, </pages> <year> 1993. </year> <month> 12 </month>
Reference-contexts: Most of these exploit statistics based on information theory to measure how likely two linguistic entities are to co-occur. Co-occurrence statistics have been used to assess semantic similarity [15], PP attachment preference [16], linguistically significant collocations <ref> [23] </ref>, syntactic categories [4], and syntactic rules [5].
References-found: 23

