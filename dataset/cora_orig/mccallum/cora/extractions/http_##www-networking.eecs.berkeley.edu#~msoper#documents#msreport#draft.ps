URL: http://www-networking.eecs.berkeley.edu/~msoper/documents/msreport/draft.ps
Refering-URL: http://www-networking.eecs.berkeley.edu/~msoper/research.html
Root-URL: 
Title: Network Measurement and Analysis System  
Author: (NMAS) 
Abstract: M.S. Project Report Mark Soper May 23, 1997 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Richard Edell, Nick McKeown, and My T Le. </author> <title> The Bay Bridge: A High Speed Bridge/Router. </title> <booktitle> IFIP PfHSN Workshop. </booktitle> <address> Stockholm, Sweden. </address> <year> 1992. </year>
Reference-contexts: It became clear that recording network traffic statistics in this way for any extended period of time is not practical <ref> [1] </ref>. Since these packet headers were recorded, the BayBridge researchers have received requests for the data from both network statistics analysts and campus network administrators.
Reference: [2] <author> Richard Edell, Nick McKeown, and Pravin Varaiya. </author> <title> Billing users and pricing for TCP. </title> <journal> IEEE Journal on Selected Areas in Communications. Sept. 1995. </journal> <volume> vol. 13 (no. 7): 1162 - 75. </volume>
Reference-contexts: Apparently such network trace repositories, while useful, are not widely available, and machines which facilitate their collection are prohibitively expensive or not easily adapted to different networks or analysis needs <ref> [2] </ref>. 1.3 Motivation for the Pro ject The experience of the BayBridge researchers demonstrates a need for an inexpensive, high-performance network analysis system, flexible enough to operate on a wide range of traffic characteristics, robust enough to run continuously with little intervention without dropping packets, and compatible with a variety of
Reference: [3] <author> V. Jacobson, C. Leres, and S. </author> <title> McCanne The Tcpdump Manual Page. </title> <institution> Lawrence Berkeley Laboratory. Berkeley, </institution> <address> CA. </address> <year> 1992. </year>
Reference-contexts: Filter (BPF), a "kernel agent" which sends copies of only those packets which match configurable filter characteristics toward interested user level processes [5], and tcpdump, a program which runs at user level on top of BPF and provides an intuitive interface and data formatting capabilities to the underlying filtering functionality <ref> [3] </ref>. 5 Chapter 2 Technical Description of NMAS 2.1 System Overview The goal of this project is to build a measurement and analysis system that meets the following criteria: * High-Performance the system must provide access to every packet traversing the network to as many interested analysis modules as possible. <p> be disregarded. 2.3.3 Tcpdump for SBM Perhaps one of the most useful analysis module scenarios envisioned for this system is a version of tcpdump modified to run on top of SBM, with additional functionality to send records 20 containing statistical information about the network traffic to a database management system <ref> [3] </ref>. Achieving this requires two distinct steps: Modifying libpcap to work with the Shared Memory BPF The libpcap library abstracts away the interfaces of a number of different packet capture mechanisms analogous to BPF.
Reference: [4] <author> Steven McCanne and Van Jacobson. </author> <title> The Bpf Manual Page. </title> <institution> Lawrence Berkeley Laboratory. Berkeley, </institution> <address> CA. </address> <year> 1990. </year>
Reference-contexts: Much of the startup functionality is unchanged, including opening a BPF file descriptor, attaching to a particular interface, determining the appropriate read buffer size, placing the interface in promiscuous mode, enabling immediate mode, and setting the characteristics of the packet filter <ref> [4] </ref> [5]. * Registering with SBM before an analysis module can work with the SBM modified BPF, it must register. See Section 2.2.2 for more information about what goes on in the kernel, and see A for the specifics of the registration call.
Reference: [5] <author> Steven McCanne and Van Jacobson. </author> <title> The BSD Packet Filter: A New Architecture for User-level Packet Capture. </title> <booktitle> Winter USENIX conference. </booktitle> <address> San Diego, CA. </address> <year> 1993. </year>
Reference-contexts: Examples of these facilities include the BSD Packet Filter (BPF), a "kernel agent" which sends copies of only those packets which match configurable filter characteristics toward interested user level processes <ref> [5] </ref>, and tcpdump, a program which runs at user level on top of BPF and provides an intuitive interface and data formatting capabilities to the underlying filtering functionality [3]. 5 Chapter 2 Technical Description of NMAS 2.1 System Overview The goal of this project is to build a measurement and analysis <p> A significant portion of that challenge involves performing the actual filtering of packets, and fortunately an excellent facility for doing just that already exists: the BSD Packet Filter <ref> [5] </ref>. So our kernel facilities for presenting the window of packets is essentially a modified version of BPF supporting our shared buffer manager. The next section contains a description of standard BPF, followed by an account of the modifications we make to achieve the shared memory extension. <p> Much of the startup functionality is unchanged, including opening a BPF file descriptor, attaching to a particular interface, determining the appropriate read buffer size, placing the interface in promiscuous mode, enabling immediate mode, and setting the characteristics of the packet filter [4] <ref> [5] </ref>. * Registering with SBM before an analysis module can work with the SBM modified BPF, it must register. See Section 2.2.2 for more information about what goes on in the kernel, and see A for the specifics of the registration call.
Reference: [6] <author> Marshall McKusick, Keith Bostic, Michael Karels, and John Quarterman. </author> <title> The Design and Implementation of the 4.4 BSD Operating System. </title> <publisher> Addison-Wesley. </publisher> <address> New York. </address> <year> 1996. </year>
Reference-contexts: Some consideration was given to Linux, and although hardware support was quite good, we found little reason to go with an unsupported operating system when BSDI is offering BSD/OS, an inexpensive, supported, and solid commercial variant of 4.4 BSD <ref> [6] </ref>. So we decided to go with BSD/OS 2.1 and as soon as it was released, upgrade to BSD/OS 3.0. Availability of source code for this operating system is excellent, and a wide variety of hardware is supported. <p> Under normal operation, BPF runs within the OS kernel, takes a copy of a incoming packet and is able to filter, or selectively output, only certain packets based on a variety of characteristics, including port number, source host, destination host, protocol, size, etc. <ref> [6] </ref> 10 A network driver must be written to support BPF. Upon receipt of each incoming packet, the driver must notify BPF and send it a copy of the packet. <p> The task of allocating kernel memory for the working space and sharing this memory with user level is accomplished through the following sequence: <ref> [6] </ref> * Initialize We develop a kernel routine sbminit (), which is run when the user level initialization module (see Section 2.3) calls into the kernel with the initial parameters regarding the number and size of the packets to be allocated for each packet size class. * Register We develop a <p> Under normal operation, the tulip driver, as drivers for the DEC 21140 Ethernet chip are called [9], fulfills this duty by requesting mbuf 's, a certain type of buffering structure, from the BSD/OS kernel <ref> [6] </ref>. The mbuf 's buffer memory is allocated by the kernel from its general memory pool. Under SBM operation, we don't want the kernel arbitrarily choosing memory for packet storage, but we specifically require that packets be written into our working space memory buffers.
Reference: [7] <author> W. Richard Stevens. </author> <title> UNIX Network Programming. </title> <publisher> Prentice Hall. </publisher> <address> Englewood Cliffs, New Jersey. </address> <year> 1990. </year>
Reference-contexts: Let us make one last comment regarding timestamps. Originally our idea was to convert from the clockstamp processor clock cycle counter reading to a UNIX timeval structure, which contains a 32 bit integer representing seconds and a 32 bit integer representing microseconds, at the time of stamping within SBM <ref> [7] </ref>. This would allow the system to provide the analysis modules with a real time timestamp instead of the processor clock cycle value. <p> descriptor and makes the appropriate ioctl () system call, passing in a set of parameters indicating the sizes and counts for each packet size class, the sbminit () (see Section 2.2.2) routine is called within the kernel, pinning down the working space and getting everything ready to go with SBM <ref> [7] </ref>. Initialization can only occur once between system reboots, only one working space can be extant, and once SBM is running it can't be removed without rebooting the machine.
Reference: [8] <author> Gary R. Wright and W. Richard Stevens. </author> <title> TCP/IP Illustrated, Volume 2. </title> <publisher> Addison-Wesley. </publisher> <address> Reading, Massachusetts. </address> <year> 1995. </year>
Reference-contexts: IP in turn makes copies of the packet for the subsequent layer of the protocol stack (eg: TCP). Eventually a copy of the packet is sent up to appropriate user level applications <ref> [8] </ref>. In order to achieve real time performance, we change this model significantly. We use the shared memory working space to allow user level applications to access the memory where the driver initially writes the packet.
Reference: [9] <author> Digital Equipment Corporation. </author> <title> DEC 21140A PCI Fast Ethernet LAN Controller: Hardware Reference Manual. </title> <institution> Maynard, Massachusetts. </institution> <year> 1996. </year> <month> 28 </month>
Reference-contexts: This section briefly describes the necessary modifications. The driver has the responsibility of providing to the interface card a continuous supply of memory locations in which it can write packets. Under normal operation, the tulip driver, as drivers for the DEC 21140 Ethernet chip are called <ref> [9] </ref>, fulfills this duty by requesting mbuf 's, a certain type of buffering structure, from the BSD/OS kernel [6]. The mbuf 's buffer memory is allocated by the kernel from its general memory pool.
References-found: 9

