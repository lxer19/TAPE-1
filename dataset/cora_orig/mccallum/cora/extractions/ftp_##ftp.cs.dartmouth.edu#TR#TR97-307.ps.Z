URL: ftp://ftp.cs.dartmouth.edu/TR/TR97-307.ps.Z
Refering-URL: http://www.cs.dartmouth.edu/reports/abstracts/TR97-307/
Root-URL: http://www.cs.dartmouth.edu
Title: Automatic Video Pause Detection Filter  
Author: Xiaowen Liu, Charles B. Owen, Fillia S. Makedon 
Affiliation: Department of Computer Science Dartmouth College  
Note: PCS-TR97-307  
Abstract: Dartmouth College Computer Science Technical Report Abstract Increasing interest in multimedia research has been drawn upon the development of video indexing and content-based image retrieval techniques. In this report, we proposed several pause detection algorithms, which instead of searching for significant visual transitions, the algorithms detect significant pauses in video streams. A realization of the algorithms was implemented using ImageTcl toolkit developed at Dartmouth Experimental Visualization Laboratory. In addition to proposing and studying the effectiveness of the pause detection algorithms, another major goal will be to incorporate our algorithms into ImageTcl and test the stability and applicability of the ImageTcl environment. Priliminary experiments showed relatively good results of our pause detection algorithms.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> H. Aoki, S. Shimotsuji, and O. Hori. </author> <title> "A shot classification method of selecting effective key-frames of video browsing.". </title> <booktitle> In Proceedings of ACM Multimedia '96. </booktitle> <address> Boston, MA, </address> <month> November </month> <year> 1996. </year>
Reference-contexts: On the other hand, applying the algorithms with corresponding sub-image sections should be able to capture small-scale object movements. In a recent paper <ref> [1] </ref>, Aoki et al. used both color analysis and layout analysis to calculate and compare similar shots.
Reference: [2] <author> A. Hampapur, R. Jain, and T. E. Weymouth. </author> <title> "Production model based digital video segmentation." </title>
Reference-contexts: Zhang et al. [5] proposed a partitioning system to detect video segment boundaries. A cut in a video stream can be defined as a sudden transition (or discontinuity) of visual properties across the transition <ref> [2] </ref>. The transition of visual properties of a cut can be significant or minimal depending on how the director controls and organizes shots. Visual properties of a shot may include factors like camera motion, object shapes, color, brightness distribution, etc.
Reference: [3] <author> W. Niblack, R. Barber, W. Equitz, M. Flickner, E. Glasman, D. Petkovic, P. Yanker, and C. Faloutsos. </author> <title> "The QBIC project: querying images by content using color, texture, and shape." In Storage and Retrieval for Image and Video Databases. </title> <booktitle> SPIE vol. </booktitle> <year> 1908, </year> <month> February </month> <year> 1993. </year>
Reference: [4] <author> Akio Nagasaka and Yuzuru Tanaka. </author> <title> "Automatic video indexing and full-video search for object appearances." </title> <booktitle> In 2nd Working Conference on Visual Database Systems. </booktitle> <pages> pp. 119-133, </pages> <address> Budapest, Hungary, </address> <publisher> IFIP WG 2.6, </publisher> <month> October </month> <year> 1991. </year>
Reference-contexts: Section 5 gives some preliminary experiment results to compare the effectiveness of the algorithms, while Sective 6 gives the conclusions. 2 Pause detection algorithms Our pause detection algorithms are built upon the cut detection algorithms. Many methods of calculating difference between video frames have been proposed. Nagasaka and Tanaka <ref> [4] </ref> studied several methods to automatically detect cuts so as to index video streams. Zhang et al. [5] proposed a partitioning system to detect video segment boundaries. A cut in a video stream can be defined as a sudden transition (or discontinuity) of visual properties across the transition [2]. <p> The algorithm is essentially the same as the template matching algorithm, describe in <ref> [4] </ref>. However, the pointwise difference between pixels of consecutive frames is normalized. <p> = y=0 x=0 jgraylevel (f 1 ; x; y) graylevel (f 2 ; x; y)j maxfgraylevel (f 1 ; x; y); graylevel (f 2 ; x; y)g 2.3 2 histogram comparison between consecutive frames Our third pause detection algorithm uses the histogram comparison algorithm developed by Na gasaka and Tanaka <ref> [4] </ref>. The essence of their algorithm rely on the color space of the frames to identify a discontinuity. <p> As pointed out in <ref> [4] </ref>, the 2 value more strongly reflects the degree of the difference between the two frames. The use of division normalizes the significance of the difference. There is a slight difference between our algorithm and the algorithm developed in [4]. <p> As pointed out in <ref> [4] </ref>, the 2 value more strongly reflects the degree of the difference between the two frames. The use of division normalizes the significance of the difference. There is a slight difference between our algorithm and the algorithm developed in [4]. In our algorithm, instead of using fixed denominator H (f 2 ; i), we pick the maximum of the two frames to eliminate the preference of the second frame. Also, the common divided-by-zero error must be specially taken care of. In our experiments, we use 256 gray-scale levels. <p> As we can see from the figures, the difference between the peaks and valleys are enlarged while the neutral positions are still kept relatively constant. Observed by Nagasaka and Tanaka <ref> [4] </ref>, the 2 histogram comparison reduces the sensitivity to camera panning and zooming. While 2 algorithms obtain much clear peaks at cutting points, they also obscure the difference between pauses and movements, which are represented by object movements, camera movements like panning and zooming, etc.
Reference: [5] <author> H. Zhang, A. Kankanhalli, and W. Smoliar. </author> <title> "Automatic partitioning of full-motion video." Multimedia System (1993), </title> <journal> Springer-Verlag, </journal> <volume> vol. 1, </volume> <pages> pp. 10-28, </pages> <year> 1993. </year> <month> 9 </month>
Reference-contexts: Many methods of calculating difference between video frames have been proposed. Nagasaka and Tanaka [4] studied several methods to automatically detect cuts so as to index video streams. Zhang et al. <ref> [5] </ref> proposed a partitioning system to detect video segment boundaries. A cut in a video stream can be defined as a sudden transition (or discontinuity) of visual properties across the transition [2].
References-found: 5

