URL: http://www.research.att.com/~wcohen/postscript/aaai-98-ws.ps
Refering-URL: http://www.research.att.com/~wcohen/
Root-URL: 
Email: wcohen@research.att.com  
Title: The WHIRL Approach to Integration: An Overview  
Author: William W. Cohen 
Address: 180 Park Avenue Florham Park, NJ 07932  
Affiliation: AT&T Labs-Research  
Abstract: We describe a new integration system, in which information sources are converted into a highly structured collection of small fragments of text. Database-like queries to this structured collection of text fragments are approximated using a novel logic called WHIRL, which combines inference in the style of deductive databases with ranked retrieval methods from information retrieval. WHIRL allows queries that integrate information from information sources, without requiring the extraction and normalization of object identifiers that can be used as keys; instead, operations that in conventional databases require equality tests on keys are approximated using IR similarity metrics for text. This leads to a reduction in the amount of human engineering required to field an integration system. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Arens, Y.; Knoblock, C. A.; and Hsu, C.-N. </author> <year> 1996. </year> <title> Query processing in the SIMS information mediator. </title>
Reference: <editor> In Tate, A., ed., </editor> <booktitle> Advanced Planning Technology. </booktitle> <address> Menlo Park, CA: </address> <publisher> AAAI Press. </publisher>
Reference: <author> Atzeni, P.; Mecca, G.; and Merialdo, P. </author> <year> 1997. </year> <title> Semistructured and structured data on the Web: going back and forth. </title> <editor> In Suciu, D., ed., </editor> <booktitle> Proceedings of the Workshop on Management of Semistruc-tured Data. </booktitle> <address> Tucson, Arizona: </address> <note> Available on-line from http://www.research.att.com/ suciu/workshop-papers.html. </note>
Reference: <author> Cohen, W. W., and Hirsh, H. </author> <year> 1998. </year> <title> Joins that generalize: Text categorization using WHIRL. </title> <note> Submitted to KDD-98. </note>
Reference-contexts: Minimal feature selection was used for C4.5 (terms appearing in less than three examples were discarded) and no feature selection was used for the remaining learning methods. Standard experimental methodology was used to assess the accuracy of the predictions; for details see <ref> (Cohen & Hirsh 1998) </ref>. The results are shown in Table 3. WHIRL outperforms C4.5 eight of nine times, and outperforms RIPPER seven of nine times. The competing method that is closest in performance to WHIRL is Yang's method, which is closely related to WHIRL.
Reference: <author> Cohen, W. W., and Singer, Y. </author> <year> 1996. </year> <title> Context-sensitive learning methods for text categorization. </title> <booktitle> In Proceedings of the 19th Annual International ACM Conference on Research and Development in Information Retrieval, </booktitle> <pages> 307-315. </pages> <address> Zurich, Switzerland: </address> <publisher> ACM Press. </publisher>
Reference: <author> Cohen, W. W. </author> <year> 1995. </year> <title> Fast effective rule induction. </title> <booktitle> In Machine Learning: Proceedings of the Twelfth International Conference. </booktitle> <address> Lake Tahoe, California: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Cohen, W. W. </author> <year> 1997. </year> <title> Knowledge integration for structured information sources containing text (extended abstract). </title> <booktitle> In The SIGIR-97 Workshop on Networked Information Retrieval. </booktitle>
Reference-contexts: The results for three such pairs of relations are summarized in Table 2. On these domains, similarity joins are extremely accurate, relative to the secondary keys (Cohen 1998a). In another set of experiments <ref> (Cohen 1997) </ref>, we looked at constrained similarity joins|queries of the form p (X 1 ; : : : ; X i ; : : : ; X a ) ^ X i ~ Y j ^ X k ~ "constraint" In this case the similarity join is restricted to tuples for <p> are somewhat difficult to evaluate automatically in general, so we were careful about choosing the additional "selectional criteria"; in the movie domain, for instance, the queries specified that the review must be similar to a plot description which was intended to pick out one particular movie. (For more details see <ref> (Cohen 1997) </ref>.) The average precision for these queries is lower, but still respectable| between 36% and 100%, and averaging around 56%.
Reference: <author> Cohen, W. W. </author> <year> 1998a. </year> <title> Integration of heterogeneous databases without common domains using queries based on textual similarity. </title> <booktitle> In Proceedings of ACM SIGMOD-98. </booktitle>
Reference-contexts: As a consequence, "soft joins" based on IR-style similarity metrics can be quite accurate in practice. Elsewhere we report experimental results with "soft joins" on actual movie listing and movie review data extracted from the Web <ref> (Cohen 1998a) </ref>. We checked each proposed pairing using the hand-coded normalization and extraction procedures used in a working demonstration of the Information Manifold (Levy, Rajaraman, & Or-dille 1996). <p> The size of the intermediate table is limited to K rows for efficiency reasons. WHIRL also supports disjunctive views. Views are discussed in more detail in <ref> (Cohen 1998a) </ref>. Experiments with WHIRL Efficiency and Scalability A detailed description of the inference algorithm used in WHIRL is beyond the scope of this paper (but see (Cohen 1998a) for a detailed description). The current inference algorithm exploits a number of features to make inference efficient. <p> WHIRL also supports disjunctive views. Views are discussed in more detail in <ref> (Cohen 1998a) </ref>. Experiments with WHIRL Efficiency and Scalability A detailed description of the inference algorithm used in WHIRL is beyond the scope of this paper (but see (Cohen 1998a) for a detailed description). The current inference algorithm exploits a number of features to make inference efficient. <p> Predicate names have been abbreviated for formatting reasons. candidates. For more detail on these experiments, see <ref> (Cohen 1998a) </ref>. Accuracy of Integration Inferences We also evaluated the accuracy of similarity joins, again using data taken from the Web. We selected pairs of relations which contained two or more plausible "key" fields. One of these fields, the "primary key", was used in the similarity literal in the join. <p> The results for three such pairs of relations are summarized in Table 2. On these domains, similarity joins are extremely accurate, relative to the secondary keys <ref> (Cohen 1998a) </ref>.
Reference: <author> Cohen, W. W. </author> <year> 1998b. </year> <title> A Web-based information system that reasons with structured collections of text. </title> <booktitle> In Proceedings of Autonomous Agents-98. </booktitle>
Reference-contexts: This information is provided to show that the interpreter is much more efficient than simply reordering all possible tuples from the cross-product of the relations; clearly, WHIRL is quite fast, even when computing three- and four-way joins <ref> (Cohen 1998b) </ref>. <p> The main additional components of this system are an HTTP server interface to WHIRL, which allows conjunctive queries to WHIRL to be easily formulated using HTML forms; and a spider program which allows one to easily extract STIR relations from HTML pages. These components are described in detail elsewhere <ref> (Cohen 1998b) </ref>; here we will simply observe that the ability to work effectively with incompletely extracted data makes extraction from HTML pages much easier.
Reference: <author> Garcia-Molina, H.; Papakonstantinou, Y.; Quass, D.; Rajaraman, A.; Sagiv, Y.; Ullman, J.; and Widom, J. </author> <year> 1995. </year> <title> The TSIMMIS approach to mediation: Data models and languages (extended abstract). </title> <booktitle> In Next Generation Information Technologies and Systems (NGITS-95). </booktitle>
Reference: <author> Levy, A. Y.; Rajaraman, A.; and Ordille, J. J. </author> <year> 1996. </year> <title> Querying heterogeneous information sources using source descriptions. </title> <booktitle> In Proceedings of the 22nd International Conference on Very Large Databases (VLDB-96). </booktitle>
Reference-contexts: Introduction Knowledge integration systems like the Information Manifold <ref> (Levy, Rajaraman, & Ordille 1996) </ref>, TSIM-MIS (Garcia-Molina et al. 1995), and others (Arens, Knoblock, & Hsu 1996; Atzeni, Mecca, & Merialdo 1997) allow complex database-like queries to be posed; in particular queries that integrate information from multiple Web sites can be formulated and answered. <p> Elsewhere we report experimental results with "soft joins" on actual movie listing and movie review data extracted from the Web (Cohen 1998a). We checked each proposed pairing using the hand-coded normalization and extraction procedures used in a working demonstration of the Information Manifold <ref> (Levy, Rajaraman, & Or-dille 1996) </ref>. We discovered that every pairing considered "correct" by the hand-coded procedures was ranked ahead of every "incorrect" pairing|the best possible result for such a ranking system.
Reference: <author> Porter, M. F. </author> <year> 1980. </year> <title> An algorithm for suffix stripping. </title> <booktitle> Program 14(3) </booktitle> <pages> 130-137. </pages>
Reference-contexts: We will summarize this representation below, for the sake of completeness. We assume a vocabulary T of terms, which will be treated as atomic. In the current implementation of WHIRL, the terms are "word stems" (morphologically inspired prefixes) produced by the Porter stemming algorithm <ref> (Porter 1980) </ref>. A simple text is then represented as a vector of real numbers v 2 R jT j , each component of which sure of the quality of a ranking.
Reference: <author> Quinlan, J. R. </author> <year> 1994. </year> <title> C4.5: programs for machine learning. </title> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: We compared the generalization accuracy of WHIRL to the accuracy of several other inductive learning methods, including Yang's method, C4.5 <ref> (Quinlan 1994) </ref> using a binary representation, and Ripper (Cohen 1995; Cohen & Singer 1996) using set-valued features. We used K = 30 for WHIRL and Yang's method.
Reference: <author> Salton, G., ed. </author> <year> 1989. </year> <title> Automatic Text Processing. </title> <address> Reading, Massachusetts: </address> <publisher> Addison Welsley. </publisher>
Reference-contexts: A document vector is a represention for text that is commonly used in the information retrieval community <ref> (Salton 1989) </ref>. We will summarize this representation below, for the sake of completeness. We assume a vocabulary T of terms, which will be treated as atomic. In the current implementation of WHIRL, the terms are "word stems" (morphologically inspired prefixes) produced by the Porter stemming algorithm (Porter 1980). <p> Two generally useful heuristics are to assign higher weights to terms that are frequent in the document, and to terms that are infrequent in the collection as a whole; the latter terms often correspond to proper names and other particularly informative terms. We use the TF-IDF weighting scheme <ref> (Salton 1989) </ref> and define v t to be zero if the term t does not occur in text represented by v, and otherwise (log (TF v;t ) + 1) log (IDF t ) In this formula, TF v;t is the number of times that term t occurs in the document represented
Reference: <author> Turtle, H., and Flood, J. </author> <year> 1995. </year> <title> Query evaluation: strategies and optimizations. </title> <booktitle> Information processing and management 31(6) </booktitle> <pages> 831-850. </pages>
Reference-contexts: This leads to a substantial speedup in answering complex queries. The current implementation of WHIRL combines Afl search methods with various optimization methods used in more conventional IR systems, notably the "maxscore" optimization method proposed by Turtle and Flood <ref> (Turtle & Flood 1995) </ref>. Table 1 summarizes the runtime performance 4 of WHIRL on 10 sample queries in one implemented domain. (The bird domain described in Section .) For each query, the top 20 answers were retrieved. <p> This approach uses inverted indices, but employs no special query optimizations. The second strawman is the maxscore method for similarity joins; this method is analogous to the naive method described above, except that the maxscore optimization <ref> (Turtle & Flood 1995) </ref> is used in finding the best K results from each "primitive" query. As noted above, WHIRL is closely related this optimization method. The results are shown in Figure 2.
Reference: <author> Ullman, J., and Widom, J. </author> <year> 1997. </year> <title> A first course in database systems. Upper Saddle River, </title> <address> New Jersey: </address> <publisher> Prentice Hall. </publisher>
Reference-contexts: The semantics of WHIRL are best described in terms of substitutions. 3 The answer to a Datalog query is 2 Datalog refers to Prolog with no function symbols, other than constants appearing in ground literal <ref> (Ullman & Widom 1997) </ref>. 3 A substitution is a mapping from variables to document vectors. We will write a substitution as = fX i = v i ; : : : ; X n = v n g, where each X i is mapped to the vector v i .
Reference: <author> Yang, Y., and Chute, C. </author> <year> 1994. </year> <title> An example-based mapping method for text classification and retrieval. </title> <journal> ACM Transactions on Information Systems 12(3). </journal>
Reference-contexts: This query associates labels with X based on X's similarity to instances Y in the training data. Used in this manner, WHIRL is a sort of nearest-neighbour classifier, algorithmically similar to the vector space distance-weighted K-NN method investigated by Yang <ref> (Yang & Chute 1994) </ref>; however, WHIRL uses a different scheme is used to combine the weights associated with the K closest neighbours of an unclassified instance.
References-found: 17

