URL: ftp://cl-ftp.dfki.uni-sb.de/pub/papers/local/ebl-acl97.ps.gz
Refering-URL: http://cl-www.dfki.uni-sb.de/cl/papers/cl-abstracts.html
Root-URL: 
Email: neumann@dfki.uni-sb.de  
Title: Applying Explanation-based Learning to Control and Speeding-up Natural Language Generation  
Author: Gunter Neumann 
Address: Stuhlsatzenhausweg 3 66123 Saarbrucken, Germany  
Affiliation: DFKI GmbH  
Abstract: This paper presents a method for the automatic extraction of subgrammars to control and speeding-up natural language generation NLG. The method is based on explanation-based learning EBL. The main advantage for the proposed new method for NLG is that the complexity of the grammatical decision making process during NLG can be vastly reduced, because the EBL method supports the adaption of a NLG system to a particular use of a lan guage.
Abstract-found: 1
Intro-found: 1
Reference: <author> Copestake, A., D. Flickinger, R. Malouf, S. Riehe-mann, and I. Sag. </author> <year> 1996. </year> <title> Translation using minimal recursion semantics. </title> <booktitle> In Proceedings, 6th International Conference on Theoretical and Methodological Issues in Machine Translation. </booktitle>
Reference-contexts: In our current system we are using the framework called minimal recursion semantics (MRS) described in <ref> (Copestake et al., 1996) </ref>. Using their typed feature structure notation figure 1 displays a possible MRS of the string "Sandy gives a chair to Kim" (abbreviated where convenient). The value of the feature liszt is actually treated like a set, i.e., the relative order of the elements is immaterial. <p> The value of the feature liszt is actually treated like a set, i.e., the relative order of the elements is immaterial. The feature handel is used to represent scope information, and index plays much the same role as a lambda variable in conventional representations (for more details see <ref> (Copestake et al., 1996) </ref>). 3 Overview of the method The above figure displays the overall architecture of the EBL learning method. The right-hand part of the diagram shows the linguistic competence base (LCB) and the left the EBL-based subgrammar processing component (SGP).
Reference: <author> Dale, R., W. Finkler, R. Kittredge, N. Lenke, G. Neumann, C. Peters, and M. Stede. </author> <year> 1994. </year> <title> Report from working group 2: Lexicalization and architecture. </title> <editor> In W. Hoeppner, H. Horacek, and J. Moore, editors, </editor> <booktitle> Principles of Natural Language Generation, Dagstuhl-Seminar-Report; 93. Schlo Dagstuhl, Saarland, Germany, Europe, </booktitle> <pages> pages 30-39. </pages>
Reference-contexts: The tests have been performed using a Sun UltraSparc. "actually been used or uttered". However, complete-ness is preserved. We view generation systems which are based on "canned text" and linguistically-based systems simply as two endpoints of a contiguous scale of possible system architectures (see also <ref> (Dale et al., 1994) </ref>). Thus viewed, our approach is directed towards the automatic creation of application-specific generation systems. 7 Conclusion and Future Directions We have presented a method of automatic extraction of subgrammars for controlling and speeding up natural language generation (NLG).
Reference: <author> Kay, M. </author> <year> 1996. </year> <title> Chart generation. </title> <booktitle> In 34th Annual Meeting of the Association for Computational Linguistics, </booktitle> <address> Santa Cruz, Ca. </address>
Reference: <author> Krieger, Hans-Ulrich and Ulrich Schafer. </author> <year> 1994. </year> <title> TDL|a type description language for constraint-based grammars. </title> <booktitle> In Proceedings of the 15th International Conference on Computational Linguistics, COLING-94, </booktitle> <pages> pages 893-899. </pages>
Reference-contexts: In our current implementation we are using TDL, a typed feature-based language and inference system for constraint-based grammars <ref> (Krieger and Schafer, 1994) </ref>. TDL allows the user to define hierarchically-ordered types consisting of type and feature constraints. As shown later, a systematic use of type information leads to a very compact representation of the extracted data and supports an elegant but efficient generalization step.
Reference: <author> Minton, S., J. G. Carbonell, C. A. Knoblock, D. R.Kuokka, O. Etzioni, and Y.Gi. </author> <year> 1989. </year> <title> Explanation-based learning: A problem solving perspective. </title> <journal> Artificial Intelligence, </journal> <volume> 40 </volume> <pages> 63-115. </pages>
Reference: <author> Mitchell, T., R. Keller, and S. Kedar-Cabelli. </author> <year> 1986. </year> <title> Explanation-based generalization: a unifying view. </title> <journal> Machine Learning, </journal> <volume> 1 </volume> <pages> 47-80. </pages>
Reference: <author> Neumann, G. </author> <year> 1994a. </year> <title> Application of explanation-based learning for efficient processing of constraint based grammars. </title> <booktitle> In Proceedings of the Tenth IEEE Conference on Artificial Intelligence for Applications, </booktitle> <pages> pages 208-215, </pages> <address> San Antonio, Texas, </address> <month> March. </month>
Reference: <author> Neumann, G. </author> <year> 1994b. </year> <title> A Uniform Computational Model for Natural Language Parsing and Generation. </title> <type> Ph.D. thesis, </type> <institution> Universitat des Saarlandes, Germany, Europe, </institution> <month> November. </month>
Reference: <author> Neumann, G. and G. van Noord. </author> <year> 1994. </year> <title> Re-versibility and self-monitoring in natural language generation. </title> <editor> In Tomek Strzalkowski, editor, </editor> <booktitle> Reversible Grammar in Natural Language Processing. </booktitle> <publisher> Kluwer, </publisher> <pages> pages 59-96. </pages>
Reference: <author> Pollard, C. and I. M. Sag. </author> <year> 1994. </year> <title> Head-Driven Phrase Structure Grammar. Center for the Study of Language and Information Stanford. </title>
Reference-contexts: We concentrate on constraint-based grammar formalism following a sign-based approach considering linguistic objects (i.e., words and phrases) as utterance-meaning associations <ref> (Pollard and Sag, 1994) </ref>. Thus viewed, a grammar is a formal statement of the relation between utterances in a natural language and representations of their meanings in some logical or other artificial language, where such representations are usually called logical forms (Shieber, 1993).
Reference: <author> Rayner, M. </author> <year> 1988. </year> <title> Applying explanation-based generalization to natural language processing. </title> <booktitle> In Proceedings of the International Conference on Fifth Generation Computer Systems, </booktitle> <address> Tokyo. </address>
Reference: <author> Rayner, M. and D. Carter. </author> <year> 1996. </year> <title> Fast parsing using pruning and grammar specialization. </title> <booktitle> In 34th Annual Meeting of the Association for Computational Linguistics, </booktitle> <address> Morristown, New Jersey. </address>
Reference-contexts: EBL has primarily been used for parsing to automatically specialize a given source grammar to a specific domain. In that case, EBL is used as a method for adapting a general grammar and/or parser to the sub-language defined by a suitable training corpus <ref> (Rayner and Carter, 1996) </ref>. A specialized grammar can be seen as describing a domain-specific set of prototypical constructions. Therefore, the EBL approach is also very interesting for natural language generation (NLG). <p> These filters serve the same means as the "chunking criteria" described in <ref> (Rayner and Carter, 1996) </ref>. During the training phase it is recognized for each phrasal template templ s whether the decision tree already contains a path pointing to a previously extracted and already stored phrasal template templ 0 such that templ s = templ 0 s .
Reference: <author> Samuelsson, C. </author> <year> 1994. </year> <title> Fast Natural-Language Parsing Using Explanation-Based Learning. </title> <type> Ph.D. thesis, </type> <institution> Swedish Institute of Computer Science, Kista, Sweden, Europe. </institution>
Reference: <author> Samuelsson, C. </author> <year> 1995a. </year> <title> An efficient algorithm for surface generation. </title> <booktitle> In Proceedings of the 14th International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 1414-1419, </pages> <address> Montreal, Canada. </address>
Reference: <author> Samuelsson, C. </author> <year> 1995b. </year> <title> Example-based optimiza-tion of surface-generation tables. </title> <booktitle> In Proceedings of Recent Advances in Natural Language Processing, </booktitle> <address> Velingrad, Bulgaria, </address> <publisher> Europe. </publisher>
Reference: <author> Samuelsson, C. and M. Rayner. </author> <year> 1991. </year> <title> Quantitative evaluation of explanation-based learning as an optimization tool for a large-scale natural language system. </title> <booktitle> In IJCAI-91, </booktitle> <pages> pages 609-615, </pages> <address> Syd-ney, Australia. </address>
Reference: <author> Shemtov, H. </author> <year> 1996. </year> <title> Generation of Paraphrases from Ambiguous Logical Forms. </title> <booktitle> In Proceedings of the 16th International Conference on Computational Linguistics (COLING), </booktitle> <pages> pages 919-924, </pages> <address> Kopen-hagen, Denmark, </address> <publisher> Europe. </publisher>
Reference: <author> Shieber, S. M. </author> <year> 1993. </year> <title> The problem of logical-form equivalence. </title> <journal> Computational Linguistics, </journal> <volume> 19 </volume> <pages> 179-190. </pages>
Reference-contexts: Thus viewed, a grammar is a formal statement of the relation between utterances in a natural language and representations of their meanings in some logical or other artificial language, where such representations are usually called logical forms <ref> (Shieber, 1993) </ref>. The result of the tactical generator is a feature structure (or a set of such structures in the case of multiple paraphrases) containing among others the input logical form, the computed string, and a representation of the derivation.
Reference: <author> Srinivas, B. and A. Joshi. </author> <year> 1995. </year> <title> Some novel applications of explanation-based learning to parsing lexicalized tree-adjoining grammars. </title> <booktitle> In 33th Annual Meeting of the Association for Computational Linguistics, </booktitle> <address> Cambridge, MA. </address> <publisher> van Harmelen, </publisher> <editor> F. and A. Bundy. </editor> <year> 1988. </year> <title> Explanation-based generalization=partial evaluation. </title> <journal> Artificial Intelligence, </journal> <volume> 36 </volume> <pages> 401-412. </pages>
References-found: 19

