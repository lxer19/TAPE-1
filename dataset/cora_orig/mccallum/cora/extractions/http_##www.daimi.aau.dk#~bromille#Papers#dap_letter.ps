URL: http://www.daimi.aau.dk/~bromille/Papers/dap_letter.ps
Refering-URL: http://www.daimi.aau.dk/~bromille/Papers/index.html
Root-URL: http://www.daimi.aau.dk
Title: Lower bounds for dynamic algebraic problems lower bound for dynamic polynomial multiplication (convolution), providing a
Author: Gudmund Skovbjerg Frandsen Johan P. Hansen Peter Bro Miltersen p 
Note: n)  
Abstract: We consider dynamic evaluation of algebraic functions (matrix multiplication, determinant, convolution, Fourier transform, etc.) in the model of Reif and Tate; i.e., if f (x 1 ; : : : ; x n ) = (y 1 ; : : : ; y m ) is an algebraic problem, we consider serving on-line requests of the form "change input x i to value v" or "what is the value of output y i ?". We present techniques for showing lower bounds on the worst case time complexity per operation for such problems. The first gives lower bounds in a wide range of rather powerful models (for instance history dependent algebraic computation trees over any infinite subset of a field, the integer RAM, and the generalized real RAM model of Ben-Amram and Galil). Using this technique, we show optimal (n) bounds for dynamic matrix-vector product, dynamic matrix multiplication and dynamic discriminant and an ( n log n) upper bound. We also show linear lower bounds for dynamic determinant, matrix adjoint and matrix inverse and an ( p n) lower bound for the elementary symmetric functions. The second technique is the communication complexity technique of Miltersen, Nisan, Safra, and Wigderson which we apply to the setting of dynamic algebraic problems, obtaining similar lower bounds in the word RAM model. The third technique gives lower bounds in the weaker straight line program model. Using this technique, we show an ((log n) 2 = log log n) lower bound for dynamic discrete Fourier transform. Technical ingredients of our techniques are the incompressibility technique of Ben-Amram and Galil and the lower bound for depth-two superconcentrators of Radhakrishnan and Ta-Shma. The incompressibility technique is extended to arithmetic computation in arbitrary fields. A technical algebraic lemma, which may be of independent interest is the following: The n fi n discrete Fourier transform matrix contains a large (size n (1) ) submatrix which is totally regular, i.e. all its minors are non-zero.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Andersson, T. Hagerup, S. Nilsson, and R. Raman. </author> <title> Sorting in linear time? In Proc. </title> <booktitle> STOC'95, </booktitle> <pages> pages 427-436, </pages> <year> 1995. </year>
Reference-contexts: The word RAM has been extensively studied as a model for sorting and searching. For instance, Andersson et al <ref> [1] </ref> show that sorting n words can be done in time O (n log log n) on a word RAM. The survey of Hagerup [10] gives a good overview of these results. <p> change i (v) : assume x i = v k for [v k ; n k ] 2 L; if n k &gt; 1 then n k := n k 1 else D := (1) jLj1 D= Y (v j v k ) 2 ; L := L n f <ref> [v k ; 1] </ref>g; if v = v l for some [v l ; n l ] 2 L then n l := n l + 1 else D := (1) jLj D Y (v j v) 2 ; L := L [ f [v; 1]g; Theorem 4 There is an <p> ) 2 ; L := L n f [v k ; 1]g; if v = v l for some [v l ; n l ] 2 L then n l := n l + 1 else D := (1) jLj D Y (v j v) 2 ; L := L <ref> [ f [v; 1] </ref>g; Theorem 4 There is an straight line program solution of complexity O (n) for symmetric. The solution works over any commutative ring. Proof. <p> ; L := L n f [v k ; 1]g; if v = v l for some [v l ; n l ] 2 L then n l := n l + 1 else D := (1) jLj D Y (v j v) 2 ; L := L [ f <ref> [v; 1] </ref>g; Theorem 4 There is an straight line program solution of complexity O (n) for symmetric. The solution works over any commutative ring. Proof.
Reference: [2] <author> Amir M. Ben-Amram and Zvi Galil. </author> <title> Lower bounds for data structure problems on RAMs. </title> <booktitle> In Proc. </booktitle> <address> FOCS'91, </address> <year> 1991. </year>
Reference-contexts: Reif and Tate provided two general techniques for the design of efficient dynamic algebraic algorithms. They also presented lower bounds and time-space trade-offs for several problems. Apart from Reif and Tate's work, we also meet dynamic algebraic problems in the literature on the prefix sum problem <ref> [5, 6, 25, 11, 7, 2] </ref>; the specific case of f i (x) = P i The aim of this paper is to present three techniques for showing lower bounds for dynamic algebraic problems.
Reference: [3] <author> Amir M. Ben-Amram and Zvi Galil. </author> <title> On pointers versus addresses. </title> <journal> JACM, </journal> <volume> 39 </volume> <pages> 617-648, </pages> <year> 1992. </year>
Reference-contexts: When we execute an operation, we find the tree corresponding to the current history and execute that. The complexity of a solution is the depth of its deepest tree. Random access machine models. A very general way of defining RAM models is outlined by Ben-Amram and Galil <ref> [3] </ref>. Here, we will only give an informal discussion. A RAM has an infinite number of registers, indexed by the integers. It also has a finite number of CPU-registers with proper names. <p> Each instruction is executed at unit cost. When the domain of the registers is the set of integers and the atomic operations are +; ; fl, we get the integer RAM. Another model of interest is the generalized real RAM <ref> [3] </ref>. Here, the registers contain arbitrary reals and as atomic operations we allow any set of functions R c 7! R for a constant c, with the property that for some countable closed set C ae R c , each function is continuous in R c n C. <p> In particular, it holds under a wide range on assumptions about the algebraic domain and the operations allowed, and even if the algorithm is allowed to control the flow of computation in strong ways. The technique is closely related to the incompressibility technique of Ben-Amram and Galil <ref> [3] </ref>. The second technique holds only for the word RAM model (where the first technique fails). It is a modest extension of communication complexity techniques of Miltersen et al [17]. <p> Thus, it is closely related to the technique of Ben-Amram and Galil, who applied incompressibility in various domains to show a gap between the power of random access machines and pointer machines <ref> [3] </ref>. First, a technical lemma stating a generalization of the above fact. Let k be an algebraically closed field. <p> Thus, the lower bounds we obtained for polynomial functions apply to the integer RAM as well. To show the lower bound for the generalized real RAM, we have to replace the use of Lemma 5 with results of Ben-Amram and Galil <ref> [3] </ref> regarding the incompressibility of real numbers using almost continuous operations. Let c be a positive integer. <p> Fact 12 (Ben-Amram and Galil <ref> [3, Theorem 6] </ref>) Let f 2 F fl c . Then there is a non-empty open set O such that f is continuous in O. <p> Fact 12 (Ben-Amram and Galil [3, Theorem 6]) Let f 2 F fl c . Then there is a non-empty open set O such that f is continuous in O. Fact 13 (Ben-Amram and Galil <ref> [3, Theorem 10] </ref>) Let f 2 F fl c ; f : R n 7! R m with m &lt; n. Then f is not injective.
Reference: [4] <author> David Eisenbud. </author> <title> Commutative Algebra, volume 150 of Graduate Texts in Mathematics. </title> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference-contexts: Otherwise we obtain a contradiction by choosing for each P 2 X a h P 2 M P n P and considering 0 = Q As k is algebraically closed, Hilbert's Nullstellensatz (cf. <ref> [4] </ref>, Theorem 1.6) gives that A (X) = k [x 1 ; : : : ; x m ]=Rad (f 1 ; : : : ; f n ) where Rad (f 1 ; : : : ; f n ) is the radical ideal of (f 1 ; : : <p> According to Krull's Principal Ideal Theorem (cf. <ref> [4] </ref>, Theorem 10.2) we have that m = dim k [x 1 ; : : : ; x m ] n We shall also need the following version of the well-known "Schwartz-Zippel Lemma". Lemma 7 Let k be a field. (i) Let T ae k be finite.
Reference: [5] <author> M. L. Fredman. </author> <title> The complexity of maintaining an array and computing its partial sums. </title> <journal> J. ACM, </journal> <volume> 29 </volume> <pages> 250-260, </pages> <year> 1979. </year>
Reference-contexts: Reif and Tate provided two general techniques for the design of efficient dynamic algebraic algorithms. They also presented lower bounds and time-space trade-offs for several problems. Apart from Reif and Tate's work, we also meet dynamic algebraic problems in the literature on the prefix sum problem <ref> [5, 6, 25, 11, 7, 2] </ref>; the specific case of f i (x) = P i The aim of this paper is to present three techniques for showing lower bounds for dynamic algebraic problems. <p> The natural model to consider is history independent computation trees, with the allowed branching instructions being arbitrary predicates on two variables. In this model, Fredman <ref> [5] </ref> showed a lower bound of (log n= log log n) for the prefix sum-problem over F 2 . By reduction, one gets the same lower bound for matrix-vector multiplication and the related problems.
Reference: [6] <author> M.L Fredman. </author> <title> Lower bounds on the complexity of some optimal data structures. </title> <journal> SIAM Journal on Computing, </journal> <year> 1981. </year>
Reference-contexts: Reif and Tate provided two general techniques for the design of efficient dynamic algebraic algorithms. They also presented lower bounds and time-space trade-offs for several problems. Apart from Reif and Tate's work, we also meet dynamic algebraic problems in the literature on the prefix sum problem <ref> [5, 6, 25, 11, 7, 2] </ref>; the specific case of f i (x) = P i The aim of this paper is to present three techniques for showing lower bounds for dynamic algebraic problems.
Reference: [7] <author> M.L. Fredman and M.E. Saks. </author> <title> The cell probe complexity of dynamic data structures. </title> <booktitle> In Proc. STOC'89, </booktitle> <pages> pages 345-354, </pages> <year> 1989. </year>
Reference-contexts: Reif and Tate provided two general techniques for the design of efficient dynamic algebraic algorithms. They also presented lower bounds and time-space trade-offs for several problems. Apart from Reif and Tate's work, we also meet dynamic algebraic problems in the literature on the prefix sum problem <ref> [5, 6, 25, 11, 7, 2] </ref>; the specific case of f i (x) = P i The aim of this paper is to present three techniques for showing lower bounds for dynamic algebraic problems.
Reference: [8] <author> M.L. Fredman and D.E. Willard. </author> <title> Surpassing the information theoretic bound with fusion trees. </title> <journal> J. Comput. System Sci., </journal> <volume> 47 </volume> <pages> 424-436, </pages> <year> 1993. </year>
Reference-contexts: The word RAM <ref> [8, 9, 10] </ref> has a somewhat different flavor from the integer RAM and the real RAM. The integer RAM can be considered unreasonably powerful, since it can handle arbitrary integers with unit cost.
Reference: [9] <author> M.L. Fredman and D.E. Willard. </author> <title> Trans-dichotomous algorithms for mimimum spanning trees and shortest paths. </title> <journal> J. Comput. System Sci., </journal> <volume> 48 </volume> <pages> 533-551, </pages> <year> 1994. </year>
Reference-contexts: The word RAM <ref> [8, 9, 10] </ref> has a somewhat different flavor from the integer RAM and the real RAM. The integer RAM can be considered unreasonably powerful, since it can handle arbitrary integers with unit cost.
Reference: [10] <author> Torben Hagerup. </author> <title> Sorting and searching on the Word RAM. </title> <booktitle> In Proceedings of STACS'98, Springer Lecture Notes in Computer Science, </booktitle> <volume> volume 1373, </volume> <pages> pages 366-398, </pages> <year> 1998. </year>
Reference-contexts: The word RAM <ref> [8, 9, 10] </ref> has a somewhat different flavor from the integer RAM and the real RAM. The integer RAM can be considered unreasonably powerful, since it can handle arbitrary integers with unit cost. <p> The word RAM has been extensively studied as a model for sorting and searching. For instance, Andersson et al [1] show that sorting n words can be done in time O (n log log n) on a word RAM. The survey of Hagerup <ref> [10] </ref> gives a good overview of these results. When considered as a model for dynamic algebraic problems, the word RAM is appropriate when the function in question is a constant degree polynomial over the integers.
Reference: [11] <author> H. </author> <title> Hampapuram and M.L. Fredman. Optimal bi-weighted binary trees and the complexity of maintaining partial sums. </title> <booktitle> In Proc. 34th IEEE Symposium on Foundations of Computer Science (FOCS), </booktitle> <pages> pages 480-485, </pages> <year> 1993. </year>
Reference-contexts: Reif and Tate provided two general techniques for the design of efficient dynamic algebraic algorithms. They also presented lower bounds and time-space trade-offs for several problems. Apart from Reif and Tate's work, we also meet dynamic algebraic problems in the literature on the prefix sum problem <ref> [5, 6, 25, 11, 7, 2] </ref>; the specific case of f i (x) = P i The aim of this paper is to present three techniques for showing lower bounds for dynamic algebraic problems.
Reference: [12] <author> G. H. Hardy and E. M. Wright. </author> <title> An Introduction to the Theory of Numbers. (Third Edition). </title> <publisher> Oxford University Press, </publisher> <year> 1954. </year>
Reference-contexts: Proof. Let l = b 3 p OE (n)c, where OE (n) denotes the Euler phi function, which is also the number of distinct primitive n'th roots of unity. It is known that lim inf n!1 OE (n) ln ln n Hardy and Wright <ref> [12] </ref> page 267, theorem 328), so l = ( 3 q log log n ) as required. Let z be a variable and let C (z) be the l fi l matrix with the ij'th entry being c ij = z ij .
Reference: [13] <author> Thomas W. Hungerford. </author> <title> Algebra. </title> <publisher> Springer-Verlag, </publisher> <year> 1974. </year>
Reference-contexts: This implies that the minors of B = C (!) are nonzero. To see this, observe that ! is a root of the nth cyclotomic polynomial which has degree OE (n) and is irreducible over the field Q (see Hungerford <ref> [13] </ref>, page 299, Proposition 8.3). Therefore ! is not root of any polynomial with integer coefficients and of degree strictly smaller than OE (n), as k has characteristic 0. We now show that no minor in the matrix C (z) is the zero-polynomial.
Reference: [14] <author> Eyal Kushilevitz and Noam Nisan. </author> <title> Communication Complexity. </title> <publisher> Cambridge University Press, </publisher> <year> 1996. </year>
Reference-contexts: For an exposition of the communication complexity technique and this example in particular, we refer to the book of Kushilevitz and Nisan <ref> [14] </ref>. We present the lower bound proof as a series of reductions. First, assume, to the contrary, that the following holds. * There is a solution to dynamic matrix-vector multiplication on the word RAM with worst case time o (n) per operation.
Reference: [15] <author> Roy Meshulam. </author> <title> A geometric construction of a superconcentrator of depth 2. </title> <journal> Theoret. Comput. Sci., </journal> <volume> 32 </volume> <pages> 215-219, </pages> <year> 1984. </year>
Reference-contexts: Any solution to dynamic convolution has complexity ( p 4 Lower bounds based on superconcentrators For the purposes of our paper, we shall use the following definition of a superconcentrator of depth 2. The equivalence of this definition to the standard definition is due to Meshulam <ref> [15] </ref>.
Reference: [16] <author> P.B. Miltersen. </author> <title> Lower bounds for Union-Split-Find related problems on random access machines. </title> <booktitle> In Proc. 26th ACM Symposium on Theory of Computing (STOC), </booktitle> <pages> pages 625-634, </pages> <year> 1994. </year>
Reference-contexts: Using perfect hashing to compress the representation, as explained, for instance, in <ref> [16] </ref>, we get * There is a scheme for representing n fi n word matrices so that a matrix can be stored in s = O (t 1 n 2 ) = o (n 3 ) words so that, given an n-vector x of words, we can compute Ax in time
Reference: [17] <author> Peter Bro Miltersen, Noam Nisan, Shmuel Safra, and Avi Wigderson. </author> <title> On data structures and asymmetric communication complexity. </title> <booktitle> In Proc. Twenty-seventh Ann. ACM Symp. Theor. Comput., </booktitle> <pages> pages 103-111, </pages> <year> 1995. </year> <note> To appear in Journal of Computer and System Sciences. 18 </note>
Reference-contexts: The technique is closely related to the incompressibility technique of Ben-Amram and Galil [3]. The second technique holds only for the word RAM model (where the first technique fails). It is a modest extension of communication complexity techniques of Miltersen et al <ref> [17] </ref>. <p> A solution to the problem should work no matter how w and n relate, as long as w log n. This fact is exploited in the lower bound proof. 13 The technique used is the communication complexity technique of Miltersen et al <ref> [17] </ref> and the proof is in fact a reduction from a variation of the span-problem from that paper. For an exposition of the communication complexity technique and this example in particular, we refer to the book of Kushilevitz and Nisan [14]. <p> The following lemma now gives us a contradiction, if we put w = (n log n), as we are allowed to do. The same lemma was shown in <ref> [17] </ref> for the case p = 2. The proof here is an immediate generalization. Lemma 16 In any protocol for G 2 , either Alice sends (nw) bits or Bob sends (n 2 w) bits. 14 Proof. <p> A 0-1 matrix M is called (u; v)-rich if at least v columns contain at least u 1-entries. Miltersen et al <ref> [17] </ref> showed that if a communication problem has a (u; v)-rich communication matrix and a protocol where Alice sends a bits and Bob sends b bits, then M contains a submatrix of dimensions at least u=2 a+2 fi v=2 a+b+2 containing only 1-entries. Using this, it suffices to show 1.
Reference: [18] <author> W. Paul and J. Simon. </author> <title> Decision trees and random access machines. In Logic and Algorithmic, monographie no. </title> <institution> 30 de l'enseignement mathematique. Universite de Geneve, </institution> <year> 1982. </year>
Reference-contexts: Now, if an integer RAM solution of a certain complexity exists, we can "fold out" the solution to a solution in the history dependent algebraic computation tree model. Similar unfoldings have been done in several papers, see, for instance, Paul and Simon <ref> [18] </ref>.
Reference: [19] <author> Jaikumar Radhakrishnan and Amnon Ta-Shma. </author> <title> Tight bounds for depth-two superconcentra-tors. </title> <booktitle> In Proc. 38th Ann. Symp. Found. Comput. Sci., </booktitle> <pages> pages 585-594, </pages> <year> 1997. </year>
Reference-contexts: Also, our technique applies to a wider variety of problems in a uniform way. Our third technique is more fragile. It only works in the model of history independent straight line programs. A technical ingredient of the technique is the lower bound for depth-two supercon-centrators by Radhakrishnan and Ta-Shma <ref> [19] </ref>. <p> 1 Y with jX 1 j = jY 1 j = l, we have jN (X 1 ) " N (Y 1 )j l, where N (X 1 ); N (Y 1 ) V denote the neighbors to X 1 ; Y 1 . 15 Fact 18 (Radhakrishnan and Ta-Shma <ref> [19] </ref>) The number of edges in an n-superconcentrator of depth 2 is at least (n log 2 n log log n ). Definition 19 Let k be an algebraically closed field. Let f : k n 7! k n be a function.
Reference: [20] <author> John H. Reif and Stephen R. Tate. </author> <title> On dynamic algorithms for algebraic problems. </title> <journal> Journal of Algorithms, </journal> <volume> 22 </volume> <pages> 347-371, </pages> <year> 1997. </year>
Reference-contexts: 1 Introduction 1.1 Setup Reif and Tate <ref> [20] </ref> considered the following setup of dynamic algebraic algorithms. Let f 1 ; f 2 ; : : : ; f m be a system of n-variate polynomials over a commutative ring or rational functions over a field. <p> Interestingly, the linear upper bound does not seem to be implementable in the straight line program model. The lower bound for convolution has a fairly good match in the O ( p n log n) upper bound of Reif and Tate <ref> [20] </ref> for the same problem.
Reference: [21] <author> J.E. Savage. </author> <title> An algorithm for the computation of linear forms. </title> <journal> SIAM J. Comp., </journal> <volume> 3 </volume> <pages> 150-158, </pages> <year> 1974. </year>
Reference-contexts: However, this argument does not seem to generalize to show, for instance, the linear lower bound for straight line programs over a finite field (where matrices requiring (n 2 ) arithmetic operations do not exist <ref> [21] </ref>), nor to show any lower bound for the generalized real RAM or the word RAM. Also, our technique applies to a wider variety of problems in a uniform way. Our third technique is more fragile. It only works in the model of history independent straight line programs.
Reference: [22] <author> J. T. Schwartz. </author> <title> Fast probabilistic algorithms for verification of polynomial identities. </title> <journal> Journal of the ACM, </journal> <volume> 27 </volume> <pages> 701-717, </pages> <year> 1980. </year>
Reference-contexts: Let p be a multivariate polynomial in n variables. If p is identically zero as a function restricted to S n n W , then p is the zero-polynomial. 7 Proof. The statement of part (i) is adapted from a paper by Schwartz <ref> [22] </ref>.
Reference: [23] <author> S. Winograd. </author> <title> On the number of multiplications required to compute certain functions. </title> <journal> Proc. Nat. Acad. Sc., </journal> <volume> 58 </volume> <pages> 1840-1842, </pages> <year> 1967. </year>
Reference-contexts: For instance, we can show a lower bound for dynamic matrix-vector multiplication over the reals using arithmetic operations as follows: It is well known <ref> [23, 24] </ref> that n fi n matrices A over the reals exist so that computing x ! Ax requires (n 2 ) arithmetic operations. Now, given an alleged dynamic algorithm for dynamic matrix-vector multiplication with complexity o (n) per operation, we can initialize the matrix input to this matrix.
Reference: [24] <author> S. Winograd. </author> <title> On the number of multiplications necessary to compute certain functions. </title> <journal> Comm. Pure and Appl. Math., </journal> <volume> 23 </volume> <pages> 165-179, </pages> <year> 1970. </year>
Reference-contexts: For instance, we can show a lower bound for dynamic matrix-vector multiplication over the reals using arithmetic operations as follows: It is well known <ref> [23, 24] </ref> that n fi n matrices A over the reals exist so that computing x ! Ax requires (n 2 ) arithmetic operations. Now, given an alleged dynamic algorithm for dynamic matrix-vector multiplication with complexity o (n) per operation, we can initialize the matrix input to this matrix.
Reference: [25] <author> A.C. Yao. </author> <title> On the complexity of maintaining partial sums. </title> <journal> SIAM J. Computing, </journal> <volume> 14 </volume> <pages> 277-288, </pages> <year> 1985. </year>
Reference-contexts: Reif and Tate provided two general techniques for the design of efficient dynamic algebraic algorithms. They also presented lower bounds and time-space trade-offs for several problems. Apart from Reif and Tate's work, we also meet dynamic algebraic problems in the literature on the prefix sum problem <ref> [5, 6, 25, 11, 7, 2] </ref>; the specific case of f i (x) = P i The aim of this paper is to present three techniques for showing lower bounds for dynamic algebraic problems.
References-found: 25

